{"cell_type":{"32c5c294":"code","07b373e9":"code","61e8611d":"code","8d866f35":"code","12d09a98":"code","4317f916":"code","7edbf8d4":"code","227174ac":"code","c64d34e5":"code","091a5694":"code","3a5427a0":"code","8f2ec9da":"code","b6882499":"code","a4ab04fe":"code","33b807d6":"code","d85cb6e1":"code","fd7e4ab0":"code","ebf634c0":"code","9244bfde":"code","828a095c":"code","1eacdec4":"code","7f60f6c1":"code","999b532b":"code","00be1e87":"code","95d2d1dd":"code","f786fc77":"code","102dcd39":"code","5b530c44":"code","64042abf":"code","9f228c18":"code","dbf98c9e":"code","ac6b6228":"code","4a192ed4":"code","4777b290":"code","febe2069":"code","d4dfb11e":"code","3d2a101e":"code","29ce2b16":"code","767bf737":"code","474dd31d":"code","86f22fe5":"code","544dcfca":"code","c4063e99":"code","de392626":"code","546658cd":"code","ed8af4c4":"code","eb48af29":"code","ab3e6f34":"code","56d4f6ee":"code","ac59e49c":"code","87cea4ef":"code","0c6f2f5e":"code","99b0db25":"code","60ddf61d":"code","9b44266e":"code","7fa1f667":"code","f03a2cad":"code","35f89534":"code","429eaf4c":"code","e6b32722":"code","d032e0c5":"code","ffd89c3a":"code","82d459e0":"code","4bada21b":"code","919d62d7":"code","0e80bbe5":"code","95909266":"code","90bb1e8b":"code","10ce4bc4":"code","95958eb2":"code","f7c54f13":"code","50311529":"code","1cc2dae4":"code","6bd0512d":"code","247b67c7":"code","a54c3299":"code","e87383e5":"code","7668edc3":"code","675cdca4":"code","fc19e10d":"code","dcf4bba4":"code","e79eff7e":"code","1cd28fe0":"code","671f0304":"code","7c04a904":"code","b30cbdd3":"code","8973682c":"code","eae5ef01":"code","e7e8a5a4":"code","a118373e":"code","c587c5b9":"code","6c6dffc8":"code","6fed1685":"code","b34542b2":"code","05486858":"code","ab09f5f5":"code","4fa7b4bc":"code","053a707f":"code","b94e703e":"code","27ba3e1d":"code","808a9ff7":"code","43f4c442":"markdown","59fd1adf":"markdown","09c342e0":"markdown","738a15d8":"markdown","3afb62c3":"markdown"},"source":{"32c5c294":"#\ub370\uc774\ud130 \ud30c\uc77c \uacbd\ub85c\ub4e4\uc744 \ud655\uc778\ud569\ub2c8\ub2e4.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","07b373e9":"#\uc0ac\uc6a9\ub420 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub4e4\uc744 import\ud569\ub2c8\ub2e4.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#\uacbd\uace0 \ubb38\uad6c \ubb34\uc2dc\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#matplotlib \uc2a4\ud0c0\uc77c \uc815\uc758\nplt.style.use('fivethirtyeight')","61e8611d":"#bureau.csv \ud30c\uc77c\uc744 import\ud569\ub2c8\ub2e4.\nbureau = pd.read_csv('..\/input\/home-credit-default-risk\/bureau.csv')\nbureau.head()\n\n#Credit Bureau: \uac1c\uc778\uc2e0\uc6a9\ud3c9\uac00\uae30\uad00 -> bureau.csv: Credit Bureau(CB)\uc5d0 \uae30\ub85d\ub41c \ud0c0 \uae08\uc735 \uae30\uad00\uc5d0\uc11c \uc81c\uacf5\ubc1b\uc740 \ubaa8\ub4e0 \uace0\uac1d\uc758 \uc774\uc804 \uc2e0\uc6a9 \uac70\ub798","8d866f35":"previous_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\nprevious_loan_counts.head()\n#SK_ID_CURR = \uace0\uac1d ID\n#\uace0\uac1d ID\ub97c \uae30\uc900\uc73c\ub85c GROUPBY \uba54\uc11c\ub4dc \uc2e4\ud589\ud558\uc5ec \uc774\uc804 \ub300\ucd9c \uac1c\uc218\ub97c \ud30c\uc545\ud558\uace0 SK_ID_BUREAU feature\uc758 \uc774\ub984\uc744 previous_loan_counts\ub85c \ubcc0\uacbd","12d09a98":"#application_train.csv\uc5d0 previous_loan_counts\ub97c merge\ud568. \uc67c\ucabd\uc5d0\ub294 SK_ID_CURR, \uc624\ub978\ucabd \ub05d\uc5d0\ub294 previous_loan_counts.\ntrain = pd.read_csv('..\/input\/home-credit-default-risk\/application_train.csv')\ntrain = train.merge(previous_loan_counts, on='SK_ID_CURR', how='left')\n\n#previous_loan_counts feature\uc758 \ub110\uac12\uc744 0\uc73c\ub85c \ub300\uce58\ntrain['previous_loan_counts'] = train['previous_loan_counts'].fillna(0)\ntrain.head()","4317f916":"#KDE(Kernal Density Estimate, \ucee4\ub110 \ubc00\ub3c4 \ucd94\uc815) -> \ub2e8\uc77c \ubcc0\uc218\uc758 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90c. \ndef kde_target(var_name, df):\n    #var_name: \ubcc0\uc218\uac00 \ub418\ub294 feature name\n    #df: \ub300\uc0c1 dataframe\n    \n    #\uc0c8\ub86d\uac8c \uc0dd\uc131\ub41c \ubcc0\uc218\uc640 TARGET\uac04\uc758 \uc0c1\uad00 \uacc4\uc218 \uacc4\uc0b0\n    corr = df['TARGET'].corr(df[var_name])\n    \n    #\ub300\ucd9c \uc0c1\ud658 \uadf8\ub8f9\uacfc \uc0c1\ud658\ud558\uc9c0 \uc54a\uc740 \uadf8\ub8f9\uc758 \uc911\uac04\uac12 \uacc4\uc0b0\n    avg_repaid = df.loc[df['TARGET']==0, var_name].median()\n    avg_not_repaid = df.loc[df['TARGET']==1, var_name].median()\n    \n    #TARGET\uac12\uc5d0 \ub530\ub77c \uadf8\ub798\ud504 \uc791\uc131\n    sns.kdeplot(df.loc[df['TARGET']==0, var_name], label='TARGET == 0')\n    sns.kdeplot(df.loc[df['TARGET']==1, var_name], label='TARGET == 1')\n    \n    #\uadf8\ub798\ud504 \ub77c\ubca8\ub9c1, X\ucd95\uc740 feature name, Y\ucd95\uc740 Density\n    plt.xlabel(var_name)\n    plt.ylabel('Density')\n    plt.title('%s Distribution' % var_name)\n    plt.legend()\n    \n    #\uc0c1\uad00\uacc4\uc218 \ucd9c\ub825\n    print('The correlation between %s and the TARGET is %0.4f' % (var_name, corr))\n    \n    #\uc911\uac04\uac12 \ucd9c\ub825\n    print('Median value for loan that was not repaid = %0.4f' % avg_not_repaid)\n    print('Median value for loan that was repaid =     %0.4f' % avg_repaid)","7edbf8d4":"#Random Forest \ubc0f Gradient Boosting Machine\uc5d0 \uc758\ud574 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc788\uc5b4\uc11c \uc911\uc694\ud55c \ubcc0\uc218\ub85c \ud310\uba85\ub41c EXT_SOURCE_3\ub97c \ud65c\uc6a9\ud558\uc5ec \ud14c\uc2a4\ud2b8. \n#(\uc800\uc790\uc758 \uc774\uc804 \ub178\ud2b8\ubd81\uc5d0\uc11c \uc2e4\ud5d8\uc744 \ud1b5\ud574 \uc99d\uba85\ub418\uc5b4 \uc788\uc74c. \ub2e8\uc21c \uc2e4\ud589)\n#EXT_SOURCE_3\ub294 Feature name \uc911 \ud558\ub098\uc784.\nkde_target('EXT_SOURCE_3', train)","227174ac":"kde_target('previous_loan_counts', train)\n#\uc0c1\uad00\uacc4\uc218\uac00 \ub108\ubb34 \uc791\uace0, target\uac12\uc5d0 \ub530\ub978 \ubd84\ud3ec\uc758 \ucc28\uc774\ub3c4 \uac70\uc758 \uc5c6\uc74c -> \uc0c8\ub85c\uc6b4 \ubcc0\uc218 previous_loan_counts\ub294 \uc911\uc694\ud558\uc9c0 \uc54a\uc74c.","c64d34e5":"#_agg \uc811\ubbf8\uc0ac\ub294 aggregation\uc758 \uc904\uc784\ub9d0. '\uc9d1\uacc4'\ub77c\ub294 \ub73b(ex. count, max, min, ...etc)\nbureau_agg = bureau.drop(columns=['SK_ID_BUREAU']).groupby('SK_ID_CURR', as_index=False).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\nbureau_agg.head()\n#\uace0\uac1d ID\uc5d0 \ub530\ub77c dataframe\uc744 \uadf8\ub8f9\ud654\ud558\uace0, \ub300\ud45c\uac12(count, mean, max, min, sum)\ub4e4\uc744 \uacc4\uc0b0.","091a5694":"#\uc704\uc758 \ub300\ud45c\uac12\ub4e4\uc744 \uac01\uac01 \ud558\ub098\uc758 feature\ub85c \ubd84\ub9ac \ud6c4 \uc800\uc7a5 (ex. ~~~_count, ~~~-mean etc.)\ncolumns = ['SK_ID_CURR']\n\nfor var in bureau_agg.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in bureau_agg.columns.levels[1][:-1]:\n            columns.append('bureau_%s_%s' %(var, stat))","3a5427a0":"#bureau_agg dataframe \uc0b4\ud3b4\ubcf4\uae30\nbureau_agg.columns = columns\nbureau_agg.head()","8f2ec9da":"train = train.merge(bureau_agg, on='SK_ID_CURR', how='left')\ntrain.head()\n#\uc6d0\ubcf8 train data\uc640 \ubcd1\ud569","b6882499":"#\uc0c8\ub86d\uac8c \uc0dd\uc131\ub41c \uac12\ub4e4\uacfc TARGET\uacfc\uc758 \uc0c1\uad00\uacc4\uc218 \ubd84\uc11d\nnew_corrs = []\n\nfor col in columns:\n    corr = train['TARGET'].corr(train[col])\n    new_corrs.append((col, corr))","a4ab04fe":"#\uc0c1\uad00\uacc4\uc218\ub97c \uc808\ub300\uac12\uc5d0 \ub530\ub77c \uc815\ub82c\nnew_corrs = sorted(new_corrs, key=lambda x: abs(x[1]), reverse=True)\nnew_corrs[:15]","33b807d6":"kde_target('bureau_DAYS_CREDIT_mean', train)\n#bureau_DAYS_CREDIT -> \uace0\uac1d\uc774 \uc2e0\uc6a9\uad00\ub9ac\uad6d \uc2e0\uc6a9\ub4f1\uae09\uc744 \uc2e0\uccad\ud55c \ub0a0\ub85c\ubd80\ud130 \ub300\ucd9c\uc2e0\uccad\uae4c\uc9c0 \uac78\ub9b0 \uae30\uac04 = \uc774\uc804 \ub300\ucd9c\uc744 \ubc1b\uace0\ub098\uc11c 'Home Credit'\uc5d0\uc11c \ub300\ucd9c\uc744 \ubc1b\uae30 \uc804\uae4c\uc9c0 \uac78\ub9b0 \uc77c\uc218\n#\uc74c\uc218\uac12\uc774 \ud06c\ub2e4\ub294 \uac83\uc740 \uc774\uc804 \ub300\ucd9c\uc774 \uc774\ub8e8\uc5b4\uc9c4 \uc2dc\uc810\uc774 \ub354 \uc624\ub798\ub42c\uc74c\uc744 \uc758\ubbf8. \n#\ubcc0\uc218\ub97c \ub9ce\uc774 \ub9cc\ub4e4 \ub54c\ub294 \uc8fc\uc758\ud558\uc790. -> \uc624\ubc84\ud53c\ud305 \ubb38\uc81c\ub97c \uc77c\uc73c\ud0ac \uc218 \uc788\ub2e4.","d85cb6e1":"#\uc218\uce58\ub370\uc774\ud130\uc758 \ub300\ud45c\uac12 \uc5f0\uc0b0\uc744 \uc704\ud55c \ud568\uc218 \uc0dd\uc131\n#\uadf8\ub0e5 \uc704\uc5d0\uc11c \ud588\ub358 \uac83\uacfc \ub611\uac19\uc740 \uc791\uc5c5\uc744 \ud558\ub294 \ud568\uc218\ub97c \uc815\uc758\ud55c \uac83. (\uc774\ud558\ub85c \uac19\uc740 \ub0b4\uc6a9\uc784.)\ndef agg_numeric(df, group_var, df_name):\n    #df: \uc5f0\uc0b0\uc758 \ub300\uc0c1\uc774 \ub418\ub294 dataframe\n    #group_var: groupby\uc758 \uae30\uc900\uc774 \ub418\ub294 column(feature name)\n    #df_name: column \uc774\ub984\uc744 \uc7ac\uc815\uc758\ud558\ub294 \ub370 \uc4f0\uc774\ub294 \ubcc0\uc218\n    \n    #agg(\ucd9c\ub825\uac12): \ubaa8\ub4e0 \uc218\uce58\ub370\uc774\ud130 column\ub4e4\uc758 \ub300\ud45c\uac12\uc774 \uc5f0\uc0b0 \ub41c dataframe\n    \n    #\uadf8\ub8f9\ud654 \ub300\uc0c1\uc774 \uc544\ub2cc ID\ub4e4 \uc81c\uac70\n    for col in df:\n        if col != group_var and 'SK_ID' in col:\n            df = df.drop(columns=col)\n    \n    group_ids = df[group_var]\n    numeric_df = df.select_dtypes('number')\n    numeric_df[group_var] = group_ids\n    \n    #\ud2b9\uc815 \ubcc0\uc218\ub4e4\uc744 \uadf8\ub8f9\ud654 \ud6c4 \ud574\ub2f9 \ub300\ud45c\uac12\ub4e4 \uacc4\uc0b0\n    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n    \n    #\uc0c8\ub85c\uc6b4 coulmn \uc774\ub984 \uc0dd\uc131\n    columns = [group_var]\n    \n    #\ubcc0\uc218\ub4e4\uc5d0 \ub300\ud574 \ubc18\ubcf5\n    for var in agg.columns.levels[0]:\n        if var != group_var:\n            for stat in agg.columns.levels[1][:-1]:\n                columns.append('%s_%s_%s' % (df_name, var, stat))\n    \n    agg.columns = columns\n    \n    return agg","fd7e4ab0":"bureau_agg_new = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_agg_new.head()","ebf634c0":"bureau_agg.head()","9244bfde":"#\uc704\uc5d0\uc11c\uc640 \ub9c8\ucc2c\uac00\uc9c0\uc778 \uc0c1\uad00\uacc4\uc218 \uacc4\uc0b0 \ud568\uc218\ub97c \uc0dd\uc131\ndef target_corrs(df):\n    corrs = []\n    \n    for col in df.columns:\n        print(col)\n        \n        if col != 'TARGET':\n            corr = df['TARGET'].corr(df[col])\n            corrs.append((col, corr))\n    \n    corrs = sorted(corrs, key=lambda x:abs(x[1]), reverse=True)\n    \n    return corrs","828a095c":"#\uace0\uac1d\uc758 \ubc94\uc8fc\ubcc4 \ub300\ucd9c \uac2f\uc218\ub97c \ud655\uc778\ud574 count. -> \uc774\ub4e4\uc744 \uc815\uaddc\ud654 (\uace0\uac1d\ubcc4 \ub300\ucd9c \ud69f\uc218\uc758 \ud569\uacc4\ub97c 1\ub85c\ud574 \uacc4\uc0b0)\n\n#dataframe\uc758 \ubc94\uc8fc\ud615 feature\ub4e4(dtype=='object')\uc5d0 \ub300\ud574 one-hot encoding \uc9c4\ud589\n#ex) CREDIT_ACTIVE\uc5d0\ub294 Active, Bad debt, Closed, Sold \ub124 \uac00\uc9c0\uc758 \uac12\uc774 \uc788\ub294\ub370 \uc774\ub97c \ub124 \uac1c\ub85c \ubd84\ub9ac\ud574\uc11c 0, 1\uc758 \uac12\uc73c\ub85c \ub098\ud0c0\ub0b8 \uac83\uc744 \uc54c \uc218 \uc788\uc74c.\n\ncategorical = pd.get_dummies(bureau.select_dtypes('object'))\ncategorical['SK_ID_CURR'] = bureau['SK_ID_CURR'] #SK_ID_CURR feature \ucd94\uac00\ncategorical.head()","1eacdec4":"categorical_grouped = categorical.groupby('SK_ID_CURR').agg(['sum', 'mean'])\ncategorical_grouped.head()\n\n#sum\uc740 \uace0\uac1d\ubcc4 \ud574\ub2f9 \ubc94\uc8fc\uc5d0 \uc18d\ud55c \ub300\ucd9c\uc758 \ucd1d \ud69f\uc218. mean\uc740 \uc774\ub97c \uc815\uaddc\ud654\uc2dc\ud0a8 \uac83","7f60f6c1":"#.columns.levels[0] -> \uac00\uc7a5 \uc704\uc758 name (CREDIT_ACTIVE_active...)\ncategorical_grouped.columns.levels[0][:10]","999b532b":"#.columns.levels[1] -> \uadf8 \ubc11\uc758 name (sum, mean)\ncategorical_grouped.columns.levels[1]","00be1e87":"#\uc704\uc758 \ud45c\uc5d0\uc11c LEVEL\uc744 \uc5c6\uc560 \uac01\uac01 \ud558\ub098\uc758 FEATURE\ub85c \ubd84\ub9ac \uc2dc\ud0a8 \uac83.\n#LEVEL? -> sum, count\ub85c \ub098\ub220\uc838\uc788\ub294 \uce35\n\ngroup_var = 'SK_ID_CURR'\n\ncolumns = []\n\nfor var in categorical_grouped.columns.levels[0]:\n    if var != group_var:\n        for stat in ['count', 'count_norm']:\n            columns.append('%s_%s' % (var, stat))\n\ncategorical_grouped.columns = columns\n\ncategorical_grouped.head()","95d2d1dd":"#\uc6d0\ub798 train\uc5d0 \ud569\ubcd1\ntrain = train.merge(categorical_grouped, left_on='SK_ID_CURR', right_index=True, how='left')\ntrain.head()","f786fc77":"train.shape","102dcd39":"#10\ubc88\uc9f8\uae4c\uc9c0\uc758 featur\uc640 123\ubc88\uca30\ubd80\ud130\uc758 feature\ub97c \ub098\ud0c0\ub0b8 \uac83(\ub2e8\uc21c \uc5f4\ub78c\uc6a9. \uc758\ubbf8 \uc5c6\uc74c.)\ntrain.iloc[:10, 123:]","5b530c44":"#\uc704\uc5d0\uc11c \ud55c \uac83\uc744 \ucc98\ub9ac\ud558\ub294 \ud568\uc218 \uc0dd\uc131\ndef count_categorical(df, group_var, df_name):\n    #parameter\ub4e4\uc740 \uc77c\uc804\uc758 parameter\uc640 \ub3d9\uc77c\ud55c \ub290\ub08c\n    #categorical(\ucd9c\ub825\uac12): group_var\uc5d0 \ub300\ud574 \uac01 \uace0\uc720 \ubc94\uc8fc\ub4e4\uc758 counts \ubc0f normalized counts \uac12\uc774 \ud3ec\ud568\ub41c dataframe\n    \n    categorical = pd.get_dummies(df.select_dtypes('object'))\n    categorical[group_var] = df[group_var]\n    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n    \n    column_names = []\n    \n    for var in categorical.columns.levels[0]:\n        for stat in ['count', 'count_norm']:\n            column_names.append('%s_%s_%s' % (df_name, var, stat))\n    \n    categorical.columns = column_names\n    \n    return categorical","64042abf":"#\ud568\uc218\ub97c \ud1b5\ud574 \uac19\uc740 \ub3d9\uc791 \uc2e4\ud589. \uac19\uc740 \uac12\uc774 \ub098\uc634\uc744 \uc54c \uc218 \uc788\ub2e4.\nbureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_counts.head()","9f228c18":"#bureau_balance.csv dataframe \ubd88\ub7ec\uc624\uae30\n#\ud574\ub2f9 dataframe\uc740 \uc6d4\ubcc4 \uac01 \uace0\uac1d\uc758 \uacfc\uac70 \ud0c0 \uae08\uc735\uae30\uad00 \ub300\ucd9c \ub370\uc774\ud130\ub97c \uac00\uc9c0\uace0 \uc788\uc74c.\n#bureau_balance.csv -> \uac1c\uc778\uc2e0\uc6a9\ud3c9\uac00\uae30\uad00\uc5d0 \uc788\ub294 \uc774\uc804 \uc2e0\uc6a9 \uac70\ub798 \uc6d4 \uc794\uc561\nbureau_balance = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/bureau_balance.csv')\nbureau_balance.head()","dbf98c9e":"# \uc774\ud558\uc758 \ub0b4\uc6a9\ub4e4\uc740 \ub2e4\uc74c\uacfc \uac19\ub2e4.\n# \uac01\uac01\uc758 \ub300\ucd9c\uc5d0 \ub300\ud574 \uc218\uce58\ud615 \ub300\ud45c\uac12\ub4e4 \uacc4\uc0b0 -> \uac01\uac01\uc758 \ub300\ucd9c\uc5d0 \ub300\ud574 \ubc94\uc8fc\ud615 \ub370\uc774\ud130\ub4e4\uc758 \uac1c\uc218 \ud30c\uc545 -> \n# \uac01\uac01\uc758 \ub300\ucd9c\uc5d0 \ub300\ud55c \ub300\ud45c\uac12\ub4e4\uacfc \uac1c\uc218\ub97c \ubcd1\ud569 -> \uac01 \uace0\uac1d\ubcc4\ub85c \uc774\uc804\uc758 \uacb0\uacfc\uc5d0 \ub300\ud55c \uc218\uce58\ud615 \ub300\ud45c\uac12\ub4e4\uc744 \uacc4\uc0b0\n\n#\uac01\uac01\uc758 \ub300\ucd9c\ubcc4 \uc0c1\ud0dc\uc758 \uac2f\uc218 \ud30c\uc545 (\uc774\uc804\uc5d0 \uc791\uc131\ud55c \ud568\uc218 \uc774\uc6a9)\nbureau_balance_counts = count_categorical(bureau_balance, group_var='SK_ID_BUREAU', df_name='bureau_balance')\nbureau_balance_counts.head()","ac6b6228":"#\uac01\uac01 'SK_ID_BUREAU'\ubcc4 \ub300\ud45c\uac12\ub4e4 \uacc4\uc0b0 (\uc774\uc804\uc5d0 \uc791\uc131\ud55c \ud568\uc218 \uc774\uc6a9)\nbureau_balance_agg = agg_numeric(bureau_balance, group_var='SK_ID_BUREAU', df_name='bureau.balance')\nbureau_balance_agg.head()","4a192ed4":"#\ub300\ucd9c\uc744 \uae30\uc900\uc73c\ub85c dataframe \uadf8\ub8f9\ud654\nbureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index=True, left_on='SK_ID_BUREAU', how='outer')\n\n#SK_ID_CURR\uc744 \ud3ec\ud568\ud558\uc5ec \ubcd1\ud569\nbureau_by_loan = bureau_by_loan.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], on='SK_ID_BUREAU', how='left')\nbureau_by_loan.head()","4777b290":"bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns=['SK_ID_BUREAU']), group_var='SK_ID_CURR', df_name='client')\nbureau_balance_by_client.head()","febe2069":"#\uc0c8\ub85c \uc9dc\uae30 \uc704\ud574 \uc774\uc804 \ub370\uc774\ud130 \uc0ad\uc81c(\uc704\uc5d0\uc11c \uc0dd\uc131\ud55c \ud568\uc218\ub4e4\uc744 \uc774\uc6a9\ud574 \ucc98\uc74c\ubd80\ud130 \ub2e4\uc2dc \uc218\ud589\ud568.) -> \uc0dd\uc131\ub41c \ud568\uc218\ub4e4 \ubcd1\ud569\nimport gc\ngc.enable()\n\ndel train, bureau, bureau_balance, bureau_agg, bureau_agg_new, bureau_balance_agg, bureau_balance_counts, bureau_by_loan, bureau_balance_by_client, bureau_counts\ngc.collect()","d4dfb11e":"train = pd.read_csv('..\/input\/home-credit-default-risk\/application_train.csv')\nbureau = pd.read_csv('..\/input\/home-credit-default-risk\/bureau.csv')\nbureau_balance = pd.read_csv('..\/input\/home-credit-default-risk\/bureau_balance.csv')","3d2a101e":"#Bureau dataframe \ub0b4 \ubc94\uc8fc\ud615 \ub370\uc774\ud130\uc758 \uac2f\uc218 \uc138\uae30\nbureau_counts = count_categorical(bureau, group_var='SK_ID_CURR', df_name='bureau')\nbureau_counts.head()","29ce2b16":"#Bureau dataframe\uc758 \ub300\ud45c\uac12 \uacc4\uc0b0\nbureau_agg = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_agg.head()","767bf737":"#Bureau Balance dataframe\uc758 \uac01 \ub300\ucd9c\ubcc4 \ubc94\uc8fc\ud615 \ub370\uc774\ud130 \uac1c\uc218 \uc138\uae30\nbureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_counts.head()","474dd31d":"#Bureau balance dataframe\uc758 \uac01 \ub300\ucd9c\ubcc4 \ub300\ud45c\uac12 \uacc4\uc0b0\nbureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_agg.head()","86f22fe5":"#bureau balance dataframe\uc758 \uac01 \uace0\uac1d\ubcc4 \ub300\ud45c\uac12 \uacc4\uc0b0\nbureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\nbureau_by_loan = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_by_loan, on = 'SK_ID_BUREAU', how = 'left')\nbureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')","544dcfca":"#\uc6d0\ub798 train\uc5d0 \uc788\ub358 column\ub4e4 \ub9ac\uc2a4\ud2b8 \uc800\uc7a5(\ub2e8\uc21c \uc5f4\ub78c\uc6a9)\noriginal_features = list(train.columns)\nprint('Original Number of Features: ', len(original_features))","c4063e99":"#bureau counts, bureau_agg, bureau_balance_by_client\uc640 \ubcd1\ud569\ntrain = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\ntrain = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\ntrain = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')","de392626":"#122\uac1c\uc5d0\uc11c 333\uac1c\ub85c feature \uc218\uac00 \ub298\uc5b4\ub0ac\uc74c\uc744 \uc54c \uc218 \uc788\ub2e4.\nnew_features = list(train.columns)\nprint('Number of features using previous loans from other institutions data: ', len(new_features))","546658cd":"#\ub204\ub77d\ub41c \uac12 \ud655\uc778\n\ndef missing_values_table(df):\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns= {0: 'Missing Values', 1: '% of total values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of total values', ascending=False).round(1)\n    \n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n    \n    return mis_val_table_ren_columns","ed8af4c4":"#333\uac1c\uc758 feature \uc911 278\uac1c\uc758 feature\uac00 \uacb0\uce21\uac12\uc744 \uac00\uc9c0\uace0 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\ub2e4.\nmissing_train = missing_values_table(train)\nmissing_train.head(10)","eb48af29":"#90% \uc774\uc0c1\uc758 \ub204\ub77d\uac12\uc744 \uac00\uc9c4 feature\uc81c\uac70\ud558\uace0\uc790 \ud568.\nmissing_train_vars = list(missing_train.index[missing_train['% of total values'] > 90])\nlen(missing_train_vars)","ab3e6f34":"#\uc81c\uac70\ud558\uae30\uc5d0 \uc55e\uc11c \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0\uc11c\uc758 \ub204\ub77d\ub41c \uac12\uc758 \ube44\uc728 \uc0b4\ud3b4\ubcf4\uae30\uc704\ud574 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc14b setting\n\ntest = pd.read_csv('..\/input\/home-credit-default-risk\/application_test.csv')\n\ntest = test.merge(bureau_counts, on='SK_ID_CURR', how='left')\ntest = test.merge(bureau_agg, on='SK_ID_CURR', how='left')\ntest = test.merge(bureau_balance_by_client, on='SK_ID_CURR', how='left')","56d4f6ee":"print('Shape of Testing Data: ', test.shape)","ac59e49c":"#train data\uc640 test data\uac00 \uac19\uc740 feature\ub4e4\uc744(\uc21c\uc11c\ub97c) \uac00\uc9c0\ub3c4\ub85d \uc870\uc815. (align = \ub450 \uac1d\uccb4 \uc815\ub82c method, align \uc2dc target\uc774 \uc5c6\uc5b4\uc9c0\uae30 \ub54c\ubb38\uc5d0 \ubbf8\ub9ac \uc800\uc7a5\ud574\ub193\uace0 train\uc5d0 \ub2e4\uc2dc \ucd94\uac00\n#\uc65c target\uc774 \uc5c6\uc5b4\uc9c0\ub098? test data\uc5d0\ub294 target\uc774 \uc5c6\uae30 \ub54c\ubb38\ntrain_labels = train['TARGET']\ntrain, test = train.align(test, join='inner', axis=1)\ntrain['TARGET'] = train_labels","87cea4ef":"#train, test data \ud06c\uae30 \ucd9c\ub825\nprint('Training Data Shape: ', train.shape)\nprint('Testing Data Shape: ', test.shape)","0c6f2f5e":"#\uacb0\uce21\uce58 \ucc3e\uae30 \uc218\ud589\nmissing_test = missing_values_table(test)\nmissing_test.head(10)","99b0db25":"#test data\uc5d0\uc11c 90%\uc774\uc0c1\uc758 \uacb0\uce21\uce58\ub97c \uac16\ub294 feature\ub294 \uba87 \uac1c?\nmissing_test_vars = list(missing_test.index[missing_test['% of total values'] > 90])\nlen(missing_test_vars)","60ddf61d":"missing_columns = list(set(missing_test_vars + missing_train_vars))\nprint('There are %d columns with more than 90%% missing in either the training or testing data.' % len(missing_columns))","9b44266e":"#90% \uc774\uc0c1 \uacb0\uce21\uce58\ub97c \uac00\uc9c0\ub294 feature\uac00 \uc5c6\uae30 \ub54c\ubb38\uc5d0 \uc544\ubb34\uac83\ub3c4 \uc548 \uc9c0\uc6cc\uc9d0.\ntrain = train.drop(columns = missing_columns)\ntest = test.drop(columns = missing_columns)","7fa1f667":"#\uc911\uac04\uc800\uc7a5 (\uc5c6\uc5b4\ub3c4 \uc601\ud5a5 \uc5c6\uc74c)\ntrain.to_csv('train_bureau_raw.csv', index = False)\ntest.to_csv('test_bureau_raw.csv', index = False)","f03a2cad":"#dataframe \uc0c1\uc758 \ubaa8\ub4e0 \uc0c1\uad00\uacc4\uc218\ub4e4 \uacc4\uc0b0\ncorrs = train.corr()","35f89534":"corrs = corrs.sort_values('TARGET', ascending=False)\n#\uc0c1\uc704 10\uac1c \uc591\uc758 \uc0c1\uad00\uacc4\uc218 (TARGET\uacfc\uc758)\npd.DataFrame(corrs['TARGET'].head(10))","429eaf4c":"#\uc0c1\uc704 10\uac1c \uc74c\uc758 \uc0c1\uad00\uacc4\uc218\npd.DataFrame(corrs['TARGET'].dropna().tail(10))","e6b32722":"#\uc0c1\uad00\uacc4\uc218\uac00 \ub192\ub2e4\ub294 \uac83\uc774 \uadf8 \ubcc0\uc218\uac00 \uc720\uc6a9\ud558\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud558\uc9c0\ub294 \uc54a\uc74c. \uc218\ubc31\uac1c\uc758 \ubcc0\uc218\ub4e4\uc744 \uc0dd\uc131\ud588\uc744 \ub54c\ub294 \n#random\ud55c noise \ub54c\ubb38\uc5d0 \ud574\ub2f9 \ubcc0\uc218\ub4e4\uc774 \uc0c1\uad00\uad00\uacc4\uc5d0 \uc788\ub294 \uac83\ucc98\ub7fc \ubcf4\uc77c \uc218\ub3c4 \uc788\uc74c.\n\n#feature\ub4e4\uc758 \uc720\uc6a9\uc131\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \ud559\uc2b5\ub41c \ubaa8\ub378\ub85c\ubd80\ud130 feature importance\ub4e4\uc744 \uc0b4\ud3b4\ubcf4\uae30\n\n#client_bureau_balance_MONTHS_BALANCE_count_mean Feature\uc740 \uac01 \uace0\uac1d\uc758 \ub300\ucd9c\ubcc4 \uc6d4\ubcc4 \uae30\ub85d\uc5d0 \ub300\ud55c \ud3c9\uade0\uc744 \uc758\ubbf8\ud568.\n#\ud574\ub2f9 feature\ub294 \ub354 \ub9ce\uc740 \uc2e0\uc6a9 \uae30\ub85d\uc744 \uac00\uc9c0\uace0 \uc788\ub294 \uace0\uac1d\uc774 \uc77c\ubc18\uc801\uc73c\ub85c \ub300\ucd9c\uae08\uc744 \uc0c1\ud658\ud560 \uac00\ub2a5\uc131\uc774 \ub192\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90c.\nkde_target(var_name='client_bureau_balance_MONTHS_BALANCE_count_mean', df=train)","d032e0c5":"kde_target(var_name='bureau_CREDIT_ACTIVE_Active_count_norm', df=train)\n#\ubcc0\uc218\uac00 \ubaa8\ub4e0 \uacf3\uc5d0\uc11c \ubd88\uaddc\uce59 -> \uc0c1\uad00\uad00\uacc4 \ub9e4\uc6b0 \uc57d\ud568","ffd89c3a":"#\ubaa9\ud45c\uac12(TARGET)\uacfc\uc758 \uc0c1\uad00\uacc4\uc218\ub9cc \uacc4\uc0b0\ud558\ub294 \uac83\uc774 \uc544\ub2c8\ub77c, \uac01 \ubcc0\uc218\uac04\uc758 \uc0c1\uad00\uacc4\uc218 \uacc4\uc0b0 \n#\uc774\ub97c \ud1b5\ud574 \uc81c\uac70\ud574\uc57c \ud560 \uc218\ub3c4 \uc788\ub294 co-linear\ud55c \uad00\uacc4\ub4e4\uc744 \uac00\uc9c0\ub294 \ubcc0\uc218\ub4e4\uc758 \uc874\uc7ac \uc5ec\ubd80\ub97c \uc54c \uc218 \uc788\uc74c.\n#co-linear\ud55c \uad00\uacc4\uac00 \uc65c \uc88b\uc9c0 \uc54a\uc740\uac00? -> feature\ub4e4\uc740 \ub3c5\ub9bd\uc801\uc774\uc5b4\uc57c \ud55c\ub2e4(\ub3c5\ub9bd\ubcc0\uc218), \n#co-linear\uc131\uc774 \ub192\ub2e4\ub294 \uac83\uc740 feature\uc758 \ubd88\ud544\uc694\ud55c \uc911\ubcf5\uc774 \uc788\ub2e4\ub294 \ub73b.\n\n#0.8\uc774\uc0c1\uc758 \uc0c1\uad00\uacc4\uc218 \uac00\uc9c0\ub294 \ubcc0\uc218\ub4e4 \ucc3e\uae30 (THRESHOLD:\uae30\uc900\uc810)\nthreshold = 0.8\n\nabove_threshold_vars = {}\n\nfor col in corrs:\n    above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])","82d459e0":"#\ub192\uc740 \uc0c1\uad00\uad00\uacc4\ub97c \uac00\uc9c0\ub294 \ubcc0\uc218\ub4e4\uc758 \uc30d\uc5d0 \ub300\ud574, \uadf8 \uc30d \uc911 \ud558\ub098\uc758 \ubcc0\uc218\ub4e4\ub9cc \uc81c\uac70.\n\ncols_to_remove = []\ncols_seen = []\ncols_to_remove_pair = []\n\nfor key, value in above_threshold_vars.items():\n    cols_seen.append(key)\n    for x in value:\n        if x == key:\n            next\n        else:\n            if x not in cols_seen:\n                cols_to_remove.append(x)\n                cols_to_remove_pair.append(key)\ncols_to_remove = list(set(cols_to_remove))\nprint('Number of columns to remove: ', len(cols_to_remove))","4bada21b":"#train data\uc640 test data\ub4e4\uc5d0\uc11c \ud574\ub2f9 feature \uc81c\uac70\n\ntrain_corrs_removed = train.drop(columns=cols_to_remove)\ntest_corrs_removed = test.drop(columns=cols_to_remove)\nprint('Training Corrs Removed Shape: ', train_corrs_removed.shape)\nprint('Testing Corrs Removed Shape: ', test_corrs_removed.shape)","919d62d7":"#\uc911\uac04\uc800\uc7a5\ntrain_corrs_removed.to_csv('train_bureau_corrs_removed.csv', index = False)\ntest_corrs_removed.to_csv('test_bureau_corrs_removed.csv', index = False)","0e80bbe5":"#Model\uc740 Kaggle\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 LightGBM\uc744 \uc0ac\uc6a9\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nimport gc\n\nimport matplotlib.pyplot as plt","95909266":"def model(features, test_features, encoding='one', n_folds=5):\n    #features: \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\ub294\ub370 \uc0ac\uc6a9\ub418\ub294 feature\ub4e4\uc758 dataframe (TARGET \ud3ec\ud568)\n    #test_features: \ubaa8\ub378\uc744 \ud65c\uc6a9\ud574 \uc608\uce21\ud558\ub294\ub370 \uc0ac\uc6a9\ub418\ub294 feature\ub4e4\uc758 dataframe\n    #encoding: \ubc94\uc8fc\ud615 \ub370\uc774\ud130\ub97c \uc778\ucf54\ub529\ud558\ub294 \ub370 \uc0ac\uc6a9\ud558\ub294 \ubc29\uc2dd(\uc6d0\ud56b\uc778\ucf54\ub529->one, integer label encoding->le)\n    #n_folds: cross validation\uc5d0 \ud65c\uc6a9\ud560 fold\uc758 \uac2f\uc218\n    \n    train_ids = features['SK_ID_CURR']\n    test_ids = test_features['SK_ID_CURR']\n    \n    labels = features['TARGET']\n    \n    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n    \n    #One hot encoding\n    if encoding == 'one':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        \n        #column \uc77c\uce58\uc2dc\ud0a4\uae30\n        features, test_features = features.align(test_features, join='inner', axis=1)\n        \n        #\uae30\ub85d\ud560 \ubc94\uc8fc\ud615 \uc778\ub371\uc2a4 \uc5c6\uc74c\n        cat_indices = 'auto'\n        \n    #Label Encoding: \ubc94\uc8fc\ud615 feature\uc5d0 \uc54c\ud30c\ubcb3 \uc21c\uc73c\ub85c \ubc88\ud638\ub97c \ub9e4\uae30\ub294 \uac83(one-hot\ucc98\ub7fc featur\uc218\uac00 \ub298\uc5b4\ub098\uc9c0 \uc54a\uc74c. 0, 1, 2,...)\n    elif encoding == 'le':\n        label_encoder = LabelEncoder()\n        cat_indices = []\n        \n        for i, col in enumerate(features):\n            if features[col].dtype == 'object':\n                #\ubc94\uc8fc\ud615 \ub370\uc774\ud130\ub97c \uc815\uc218\ub85c mapping\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n                cat_indices.append(i)\n    else:\n        raise ValueError('Encoding must be either \"ohe\" or \"le\"')\n    \n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)    \n    \n    feature_names = list(features.columns)\n    \n    features = np.array(features)\n    test_features = np.array(test_features)\n    \n    #kfold object \uc0dd\uc131\n    k_fold = KFold(n_splits=n_folds, shuffle=False, random_state=50)\n    \n    #feature importance \uc800\uc7a5\ud558\uae30 \uc704\ud55c \ubc30\uc5f4 \uc0dd\uc131\n    feature_importance_values = np.zeros(len(feature_names))\n    \n    #\uc608\uce21\uac12 \uc800\uc7a5\ud558\ub294 array \uc0dd\uc131\n    test_predictions = np.zeros(test_features.shape[0])\n    \n    #out of fold validation predictions\uc744 \uc704\ud55c array \uc0dd\uc131\n    out_of_fold = np.zeros(features.shape[0])\n    \n    #validation \ubc0f training \uc810\uc218\ub97c \uc800\uc7a5\ud558\uadc0 \uc704\ud55c \ub9ac\uc2a4\ud2b8 \uc0dd\uc131\n    valid_scores = []\n    train_scores = []\n    \n    #fold\ubcc4 \ubc18\ubcf5\ubb38 \uc2e4\ud589\n    for train_indices, valid_indices in k_fold.split(features):\n        train_features, train_labels = features[train_indices], labels[train_indices]\n        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n    \n        #\ubaa8\ub378 \uc0dd\uc131\n        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n                                   class_weight = 'balanced', learning_rate = 0.05, \n                                   reg_alpha = 0.1, reg_lambda = 0.1, \n                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n    \n        #\ubaa8\ub378 fit\n        model.fit(train_features, train_labels, eval_metric = 'auc',\n                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n                  early_stopping_rounds = 100, verbose = 200)\n    \n        #\uac00\uc7a5 \uc88b\uc558\ub358 iteration \uc800\uc7a5\n        best_iteration = model.best_iteration_\n    \n        #feature importance \uc800\uc7a5\n        feature_importance_values += model.feature_importances_ \/ k_fold.n_splits\n    \n        #\uc608\uce21\n        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] \/ k_fold.n_splits\n    \n        #out of fold prediction \uc800\uc7a5\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n    \n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        \n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n    \n        #\uba54\ubaa8\ub9ac \ucd08\uae30\ud654\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n    \n    #\uc81c\ucd9c\uc6a9 dataframe \uc0dd\uc131\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    \n    #feature importance dataframe \uc0dd\uc131\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    \n    valid_auc = roc_auc_score(labels, out_of_fold)\n    \n    #\uc804\uccb4 \ub370\uc774\ud130\uc5d0 \ub300\ud55c score\ub97c metric\uc5d0 \ucd94\uac00\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    \n    #validation scores\ub97c \uc704\ud55c dataframe \uc0dd\uc131\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    \n    #training \ubc0f validation score\uac00 \uc800\uc7a5\ub41c dataframe \uc0dd\uc131\n    metrics = pd.DataFrame({'fold': fold_names,\n                            'train': train_scores,\n                            'valid': valid_scores}) \n\n    return submission, feature_importances, metrics","90bb1e8b":"#feature importance plot \ud568\uc218\ndef plot_feature_importance(df):\n    #df: feature importance\ub4e4\uc774 \uc800\uc7a5\ub41c dataframe (features\/importances)\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    #\uc815\uaddc\ud654\n    df['importance_normalized'] = df['importance'] \/ df['importance'].sum()\n    \n    #\ubc14 \ucc28\ud2b8 \uc0dd\uc131\n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot()\n    \n    ax.barh(list(reversed(list(df.index[:15]))), df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    return df","10ce4bc4":"#\uc6d0\ub798 \ubc84\uc804 \ub370\uc774\ud130(\uc6d0\ubcf8)\ntrain_control = pd.read_csv('..\/input\/home-credit-default-risk\/application_train.csv')\ntest_control = pd.read_csv('..\/input\/home-credit-default-risk\/application_test.csv')","95958eb2":"#submission: \uc81c\ucd9c\ud560 dataframe\n#fi: feature importance\uac00 \uc800\uc7a5\ub41c dataframe\n#metrics: validation \ubc0f test \uc810\uc218\uac00 \uc800\uc7a5\ub41c dataframe\nsubmission, fi, metrics = model(train_control, test_control)\n\n#training \uc810\uc218\uac00 validation \uc810\uc218\ubcf4\ub2e4 \ub192\ub2e4 -> overfit\n#submission \uc810\uc218\ub294 0.745 \uae30\ub85d","f7c54f13":"fi_sorted = plot_feature_importance(fi)","50311529":"metrics","1cc2dae4":"#feature engineering\uc744 \uc801\uc6a9\ud55c \uac83\nsubmission_raw, fi_raw, metrics_raw = model(train, test)\n#\uc81c\ucd9c\ubb3c -> 0.759 (\uc6d0\ubcf8\uc758 0.745\ubcf4\ub2e4 \ub192\ub2e4.)","6bd0512d":"fi_raw_sorted = plot_feature_importance(fi_raw)","247b67c7":"metrics_raw","a54c3299":"#importance \uc0c1\uc704 100\uac1c\uc758 feature \uc911 \uc0c8\ub85c \ub9cc\ub4e0 feature\uac00 \uc5bc\ub9c8\ub098 \uc788\uc744\uae4c? -> 51\uac1c. feature engineering GOOD!\ntop_100 = list(fi_raw_sorted['feature'])[:100]\nnew_features = [x for x in top_100 if x not in list(fi['feature'])]\n\nprint('%% of Top 100 Features created from the bureau data = %d.00' % len(new_features))","e87383e5":"#\uac15\ud55c co-linear\uad00\uacc4\ub97c \uac00\uc9c4 feature \uc81c\uac70 \ub370\uc774\ud130\nsubmission_corrs, fi_corrs, metrics_corr = model(train_corrs_removed, test_corrs_removed)\n#\uc81c\ucd9c\ubb3c -> 0.753 (\uc6d0\ubcf8 0.745\ubcf4\ub2e4 \ub192\uc9c0\ub9cc \ub2e8\uc21c feature engineering\ud55c \uc810\uc218\uc778 0.759\ubcf4\ub2e4\ub294 \ub0ae\ub2e4.)","7668edc3":"metrics_corr","675cdca4":"fi_corrs_sorted = plot_feature_importance(fi_corrs)","fc19e10d":"#\uc790\ub3d9 \ud53c\uccd0 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1? -> \uc704\uc5d0\uc11c \ud588\ub358 \uac83\uacfc \ube44\uc2b7\ud55c \ub3d9\uc791\uc744 \uc218\ud589\ud558\ub294 \ud30c\uc774\uc36c \ub77c\uc774\ube0c\ub7ec\ub9ac featuretools\n#\ub370\uc774\ud130\ubca0\uc774\uc2a4\uc5d0 \uc801\uc6a9\ub418\ub294 \uc5d4\ud2f0\ud2f0-\uad00\uacc4(ER) \ubaa8\ub378\uc5d0 \ub300\ud55c \uc120\ud589 \uc774\ud574\uac00 \ud544\uc694.\n#\uc5d4\ud2f0\ud2f0\uc640 \uad00\uacc4\ub97c \uc815\uc758\ud558\uba74 \uc790\ub3d9\uc801\uc73c\ub85c \uad00\uacc4\uc5d0 \ub9de\uac8c \ub0b4\uc7a5 primitives(\uc0c8\ub85c\uc6b4 \uacc4\uc0b0\uac12, \ucd94\ud6c4 \uc124\uba85)\ub97c \uc801\uc6a9\ud574 \uc0c8\ub85c\uc6b4 feature \uc0dd\uc131\n\nimport featuretools as ft\n\n#\ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30 (1000\uac1c\ub9cc)\napp_train = pd.read_csv('..\/input\/home-credit-default-risk\/application_train.csv').sort_values('SK_ID_CURR').reset_index(drop = True).loc[:1000, :]\napp_test = pd.read_csv('..\/input\/home-credit-default-risk\/application_test.csv').sort_values('SK_ID_CURR').reset_index(drop = True).loc[:1000, :]\nbureau = pd.read_csv('..\/input\/home-credit-default-risk\/bureau.csv').sort_values(['SK_ID_CURR', 'SK_ID_BUREAU']).reset_index(drop = True).loc[:1000, :]\nbureau_balance = pd.read_csv('..\/input\/home-credit-default-risk\/bureau_balance.csv').sort_values('SK_ID_BUREAU').reset_index(drop = True).loc[:1000, :]\ncash = pd.read_csv('..\/input\/home-credit-default-risk\/POS_CASH_balance.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index(drop = True).loc[:1000, :]\ncredit = pd.read_csv('..\/input\/home-credit-default-risk\/credit_card_balance.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index(drop = True).loc[:1000, :]\nprevious = pd.read_csv('..\/input\/home-credit-default-risk\/previous_application.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index(drop = True).loc[:1000, :]\ninstallments = pd.read_csv('..\/input\/home-credit-default-risk\/installments_payments.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index(drop = True).loc[:1000, :]","dcf4bba4":"# column\napp_train['set'] = 'train'\napp_test['set'] = 'test'\napp_test[\"TARGET\"] = np.nan\n\n# \ub370\uc774\ud130\ud504\ub808\uc784\uc5d0 append (train + test)\napp = app_train.append(app_test, ignore_index = True)","e79eff7e":"#\uc5d4\ud2f0\ud2f0 \ub9cc\ub4e4\uae30\n#\uc5d4\ud2f0\ud2f0\ub780? \ud14c\uc774\ube14 \uac1c\uccb4\uc640 \ube44\uc2b7\ud558\ub2e4. \ub370\uc774\ud130\ubca0\uc774\uc2a4\uc758 \uc5d4\ud2f0\ud2f0\uc640 \uac19\uc740 \uc758\ubbf8\ub77c\uace0 \ubcf4\uba74 \ud3b8\ud558\ub2e4.\nes = ft.EntitySet(id = 'clients')","1cd28fe0":"#\uc720\ub2c8\ud06c\ud55c index\ub97c \uac00\uc9c0\ub294 \uac83\uc5d0 \ub300\ud55c \uc5d4\ud2f0\ud2f0(\uc911\ubcf5 \uac12 \ube44\ud5c8\uc6a9, \uace0\uc720ID \ub4f1)\nes = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR')\n\nes = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n\nes = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV')\n\n# \uc720\ub2c8\ud06c\ud55c index\ub97c \uac00\uc9c0\uc9c0 \uc54a\ub294 \uac83\uc5d0 \ub300\ud55c \uc5d4\ud2f0\ud2f0(\uc911\ubcf5 \uac12 \ud5c8\uc6a9, \ubcf4\uc720 \uc790\uc0b0 \ub4f1)\nes = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n                              make_index = True, index = 'bureaubalance_index')\n\nes = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n                              make_index = True, index = 'cash_index')\n\nes = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n                              make_index = True, index = 'installments_index')\n\nes = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n                              make_index = True, index = 'credit_index')","671f0304":"#\uc5d4\ud2f0\ud2f0 \uac04\uc758 \uad00\uacc4 \uc815\uc758\nr_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n\nr_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n\nr_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n\nr_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\nr_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\nr_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])","7c04a904":"#\uc815\uc758\ub41c \uad00\uacc4\ub97c \uc5d4\ud2f0\ud2f0\uc14b\uc5d0 \ucd94\uac00\nes = es.add_relationships([r_app_bureau, r_bureau_balance, r_app_previous,\n                           r_previous_cash, r_previous_installments, r_previous_credit])\nes","b30cbdd3":"#primitives? \uc0c8\ub85c\uc6b4 \uac12 \uc0dd\uc131\ud558\ub294 \ubc29\ubc95\ub4e4. \ub0b4\uc7a5\ub418\uc5b4 \uc788\ub294 \uac83\uc784.\n\nprimitives = ft.list_primitives()\npd.options.display.max_colwidth = 100\nprimitives[primitives['type'] == 'aggregation'].head(10)","8973682c":"#featuretools\uc5d0 \ub0b4\uc7a5\ub41c \uae30\ubcf8 primitives\n#primitives\ub294 feature\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud574 \ud14c\uc774\ube14\uc5d0 \uc801\uc6a9\ub418\ub294 \uc791\uc5c5\ndefault_agg_primitives =  [\"sum\", \"std\", \"max\", \"skew\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\ndefault_trans_primitives =  [\"day\", \"year\", \"month\", \"weekday\", \"haversine\", \"num_words\", \"num_characters\"]\n\n# Deep Feature Synthesis\nfeature_names = ft.dfs(entityset = es, target_entity = 'app',\n                       trans_primitives = default_trans_primitives,\n                       agg_primitives=default_agg_primitives, max_depth = 2, features_only=True)\n\nprint('%d Total Features' % len(feature_names))","eae5ef01":"#\uc704\uc5d0 \uc815\uc758\ud55c primitivies \uc0ac\uc6a9\nfeature_matrix, feature_names = ft.dfs(entityset = es, target_entity = 'app',\n                                       trans_primitives = default_trans_primitives,\n                                       agg_primitives=default_agg_primitives, \n                                        max_depth = 2, features_only=False, verbose = True)\n\npd.options.display.max_columns = 1700\nfeature_matrix.head(10)","e7e8a5a4":"feature_names[-20:]","a118373e":"feature_matrix_spec, feature_names_spec = ft.dfs(entityset = es, target_entity = 'app',  \n                                                 agg_primitives = ['sum', 'count', 'min', 'max', 'mean', 'mode'], \n                                                 max_depth = 2, features_only = False, verbose = True)","c587c5b9":"pd.options.display.max_columns = 1000\nfeature_matrix_spec.head(10)","6c6dffc8":"#\uc800\uc790\uac00 \ubbf8\ub9ac \uc791\uc131\ud574 \ub193\uc740 \uc704\uc758 featuretools\ub97c \ud1b5\ud574 \uc0dd\uc131\ub41c feature\ub4e4\uc758 correlations\ub4e4\uc744 \uacc4\uc0b0\ud574 \ub193\uc740 \uac12\ub4e4\uc774 \uc800\uc7a5\ub41c csv \ud30c\uc77c \uc0ac\uc6a9\ncorrelations = pd.read_csv('..\/input\/home-credit-default-risk-feature-tools\/correlations_spec.csv', index_col = 0)\ncorrelations.index.name = 'Variable'\ncorrelations.head()","6fed1685":"correlations_target = correlations.sort_values('TARGET')['TARGET']\n# \uac00\uc7a5 \uc74c\uc758 \uc0c1\uad00\uacc4\uc218\ub97c \uac00\uc9c0\ub294 feature\ncorrelations_target.head()","b34542b2":"#\uac00\uc7a5 \uc591\uc758 \uc0c1\uad00\uacc4\uc218\ub97c \uac00\uc9c0\ub294 feature\ncorrelations_target.dropna().tail()","05486858":"#\uc0c1\uad00 \uad00\uacc4\ub97c \uac00\uc9c0\ub294 \ubcc0\uc218 \ubd84\ud3ec \uc2dc\uac01\ud654\nfeatures_sample = pd.read_csv('..\/input\/home-credit-default-risk-feature-tools\/feature_matrix.csv', nrows = 20000)\nfeatures_sample = features_sample[features_sample['set'] == 'train']\nfeatures_sample.head()","ab09f5f5":"def kde_target_plot(df, feature):\n    \"\"\"Kernel density estimate plot of a feature colored\n    by value of the target.\"\"\"\n    \n    df = df.reset_index()\n    plt.figure(figsize = (10, 6))\n    plt.style.use('fivethirtyeight')\n    \n    sns.kdeplot(df.loc[df['TARGET'] == 0, feature], label = 'target == 0')\n    # plot loans that were not repaid\n    sns.kdeplot(df.loc[df['TARGET'] == 1, feature], label = 'target == 1')\n    \n    plt.title('Distribution of Feature by Target Value')\n    plt.xlabel('%s' % feature); plt.ylabel('Density');\n    plt.show()","4fa7b4bc":"kde_target_plot(features_sample, feature = 'MAX(previous_app.MEAN(credit.CNT_DRAWINGS_ATM_CURRENT))')\n#\ub9e4\uc6b0 \uc57d\ud55c \uc0c1\uad00\uad00\uacc4\ub97c \uc9c0\ub2c8\uace0 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\ub2e4. \uad6c\ubd84\uc774 \uc548\ub418\ub294 \uac12\uc774\uae30 \ub54c\ubb38.","053a707f":"#\uc704\uc5d0\uc11c \ud55c \uac83\ucc98\ub7fc \uac15\ud55c co-linear\uc131\uc744 \uac00\uc9c4 feature\ub4e4\ub3c4 \uc81c\uac70\ud560 \ud544\uc694\uac00 \uc788\uc744 \uc218 \uc788\uc74c.\nthreshold = 0.9\n\ncorrelated_pairs = {}\n\nfor col in correlations:\n    above_threshold_vars = [x for x in list(correlations.index[correlations[col] > threshold]) if x != col]\n    correlated_pairs[col] = above_threshold_vars","b94e703e":"correlated_pairs['MEAN(credit.AMT_PAYMENT_TOTAL_CURRENT)']","27ba3e1d":"correlations['MEAN(credit.AMT_PAYMENT_TOTAL_CURRENT)'].sort_values(ascending=False).head()","808a9ff7":"plt.plot(features_sample['MEAN(credit.AMT_PAYMENT_TOTAL_CURRENT)'], features_sample['MEAN(previous_app.MEAN(credit.AMT_PAYMENT_CURRENT))'], 'bo')\nplt.title('Highly Correlated Features');\n\n#\uac15\ud55c co-linear \uc131\uc744 \ub744\uace0 \uc788\uc74c. \uc81c\uac70\ub97c \ud560 \uc0dd\uac01\uc744 \ud574\uc57c\ud568.\n\n#\uc774\ud6c4 \ud574\ub2f9 notebook\uc758 \ub0b4\uc6a9\uc740 \uc704\uc758 feature engineering notebook\ub0b4\uc6a9\uacfc \ub3d9\uc77c\ud55c \ud750\ub984\uc73c\ub85c \uc9c4\ud589\ub418\uae30\uc5d0 \uae30\uc220\ud558\uc9c0 \uc54a\uc74c.\n#feature importance \ud655\uc778, feature selection \uc9c4\ud589, modeling...","43f4c442":"### \uc6d0\ubb38: https:\/\/www.kaggle.com\/willkoehrsen\/introduction-to-manual-feature-engineering\n\n#### Dataset feature name \uc815\ub9ac\ubcf8: https:\/\/chocoffee20.tistory.com\/6, https:\/\/chocoffee20.tistory.com\/8?category=911962 \ucc38\uace0","59fd1adf":"# \uc790\ub3d9 \ud53c\uccd0 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1\nhttps:\/\/www.kaggle.com\/willkoehrsen\/automated-feature-engineering-basics","09c342e0":"## \uc774 \ub300\ud68c\uc758 \ubaa9\uc801\uc740? -> \uac01 \uace0\uac1d\uc758 \uc815\ubcf4\ub97c \uae30\ubc18\uc73c\ub85c \ud574\ub2f9 \uace0\uac1d\uc774 \ub300\ucd9c\ud55c \ub3c8\uc744 \uac1a\uc744 \uc218 \uc788\uc744\uc9c0 \uc5c6\uc744\uc9c0\uc5d0 \ub300\ud55c \ud655\ub960\uc744 \uc608\uce21","738a15d8":"## Feature Engineering\uc774 \uc5bc\ub9c8\ub098 \uc720\uc6a9\ud588\ub294\uc9c0 \uc54c\uc544\ubcf4\uae30 (\uc6d0\ubcf8 \ub370\uc774\ud130, \uc801\uc6a9 \ub370\uc774\ud130, co-linear\uae4c\uc9c0 \uc81c\uac70\ud55c \ub370\uc774\ud130)","3afb62c3":"# Modeling"}}