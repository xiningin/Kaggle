{"cell_type":{"175d5b76":"code","080b9f02":"code","9894c85a":"code","56b80aa8":"code","79d525c2":"code","f9348987":"code","561827e6":"code","72e02375":"code","85042c06":"code","283c5e10":"code","d65a59df":"code","a6c7c1ab":"code","6ef6c47a":"markdown","64712a0e":"markdown","dfc7c3d4":"markdown","d8519e37":"markdown","32f64d97":"markdown","879addc3":"markdown"},"source":{"175d5b76":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n\nimport numpy as np\nimport pandas as pd","080b9f02":"!pip install -U pandas_profiling","9894c85a":"df_train = pd.read_csv('..\/input\/dauphine-datascience-ecommerce-2021-1\/train.csv')\ndf_test = pd.read_csv('..\/input\/dauphine-datascience-ecommerce-2021-1\/test.csv')\n\ndf_train.shape, df_test.shape","56b80aa8":"from pandas_profiling import ProfileReport\n\n# Sample, we don't need all of this big data\nprofile = ProfileReport(df_train.sample(10000), title=\"Pandas Profiling Report\")","79d525c2":"%%time\nprofile.to_notebook_iframe()","f9348987":"df_train.sample(5)","561827e6":"df_test['conversion_rate'] = 0.01\nmy_submission = df_test[['id', 'conversion_rate']]\nmy_submission.to_csv('submission.csv', index=False)\n\n# Now save your notebook, then make a submit\n# See your leaderboard ranking\n# ~ 15' setup","72e02375":"# Respect the following step to gradually improve your pipeline \n# ~ 15'\n# 1 - predict with the mean\n# 2 - predict with the weighted mean\n# 3 - what would be a good naive strategy? \n\n# Rules of ML by Google https:\/\/developers.google.com\/machine-learning\/guides\/rules-of-ml\n# Rule #1: Don\u2019t be afraid to launch a product without machine learning.","85042c06":"# 4 - what happens if you predict the past performance for each product? \n# what are the problem to this strategy? which less problematic heuristic could we use?\n# 5 - implement your first ML pipeline based with the minimal amount of features and a linear \n# regression from sklearn ~20'\n# 6 - add a train\/validation and measure the error on your validation set. ~20'\n# Is it the same magnitude order than on leaderboard? If it is not the case this is an alarm of a mistake\n\n# Rule #3: Choose machine learning over a complex heuristic.","283c5e10":"# # Add feature engineering\n# def fe_learning(df):\n#   # TODO improve this overtime\n#   return df\n\n# target = 'TODO'\n\n# # list(df_learning.select_dtypes('object'))\n# to_drop = [\n#     # TODO\n# ]\n\n# def get_X_y(df):\n#     df = fe_learning(df)\n#     X = df.drop(columns=TODO, errors='ignore')\n#     if target in df:\n#         y = df[target]\n#     else:\n#         y = None\n#     return X, y\n\n# X_train, y_train = get_X_y(train)\n# X_test, _ = get_X_y(test)","d65a59df":"# # 7 - Handle high dimension categorical data\n# def target_encoding(data, cols_group, target):\n#     # Remove line where target is Na otherwise count values wouldn't be good\n#     data = data[~data[target].isnull()].copy()\n#     data[cols_group] = data[cols_group].fillna(\"dont_drop_na\")\n#     agg_func = {target: [\"TODO\", \"TODO\"]} # Fill with desired function\n#     res = data.groupby(cols_group).agg(agg_func)\n#     # Find a meaningfull group_name, eg: COL1_&_COL2_...\n#     group_name = \"TODO\"\n#     res.columns = [group_name + \"_\" + \"_\".join(col) for col in res.columns]\n#     res = res.reset_index()\n#     res = res.replace(\"dont_drop_na\", np.nan)\n#     return res\n\n\n# def oof_dataframe(data, col_fold, function, **kwargs):\n#     folders = data[col_fold].unique()\n#     res = []\n#     for f in folders:\n#         # apply the function to data except current fold\n#         # res_tmp = function(...)\n#         # Assign folder back\n#         # res_tmp[col_fold] = \n#         # Add to list res\n#         # res = \n\n#     # concat res and return\n        \n#     return res","a6c7c1ab":"# np.random.seed(1)\n# train[\"fold\"] = np.random.randint(0, 5, train.shape[0])\n\n# list_col_groups = [\n#     # TODO\n#     # [\"col1\"],\n#     # [\"col1\", \"col2\"],\n# ]\n\n# list_te = []\n# for cols_group in list_col_groups:\n#     df_target_encoding = oof_dataframe('TODO')\n#     list_te.append(df_target_encoding)\n\n    \n# for df_target_encoding in list_te:\n#     # merge dataset\n#     print('TODO')","6ef6c47a":"# Submit from kernel\n\n![](https:\/\/i.ibb.co\/zRq3L9x\/kaggle-submit-from-notebook.png)","64712a0e":"# First machine learning pipeline","dfc7c3d4":"# Improve your heuristic","d8519e37":"# Dummy submission","32f64d97":"# Exploratory Data Analysis (EDA)","879addc3":"# Continuous improvement of your machine learning pipeline"}}