{"cell_type":{"4af849f8":"code","3c4a3293":"code","ecf95bf3":"code","2d46fabf":"code","bc41a88a":"code","4929db64":"code","6304be54":"code","30afc81d":"code","4c1254ae":"code","81d8c338":"code","a4d56e47":"code","637e1f64":"code","88db87a6":"code","f3617789":"code","cfa5b508":"code","15d72b32":"code","e69dd908":"code","9b8172cc":"code","b40e4490":"code","5e77cfcf":"code","318076a6":"code","83fa5bfa":"code","76e277a8":"code","662effdf":"code","29dc1190":"code","65ddfec5":"code","6f6d1f3d":"code","3f0acfdb":"code","6441af5b":"code","52b0cf4d":"code","d2ac0441":"code","c58bd109":"code","f479c818":"code","fe2b0429":"code","a7d6f85a":"code","120d8769":"code","bf9298ff":"code","34e2cec4":"code","7bb658b3":"code","a4df1247":"code","5cc10b46":"code","4ab64dda":"code","3ceb6699":"code","ef6f34eb":"code","0b5dcf14":"code","770e6d00":"code","247e59d6":"code","69e98049":"code","e48af228":"code","7b70fe07":"code","32e35d9e":"code","55f5c313":"code","9b10f7fb":"code","ab980188":"code","b7447bde":"code","f5191cbe":"code","57c248b5":"code","08de8caf":"code","2816189e":"code","f7b144ab":"code","ee853caa":"code","03c4b13a":"code","3d26aaf5":"code","5edec912":"code","99da2c94":"code","5226ff14":"code","bda7a6a9":"code","a443cacd":"code","27e153cb":"code","9c3c5c91":"code","003755a9":"code","04fb306c":"code","591396fe":"code","a3f955ad":"code","6273c9dd":"code","41ac05b6":"code","5d52f0b0":"code","bcc91b7d":"code","22709897":"code","83bf314b":"code","c4f47bea":"code","229f2af2":"code","e864ccab":"code","919f0d37":"code","507f82a6":"code","ae1e1611":"code","9fa294fd":"code","5aa984e9":"code","64ff6987":"code","242d8ff2":"code","6e4d2278":"code","2c0140bc":"code","d56b9bfd":"code","be92b0c2":"code","810a19a9":"code","cd1494fe":"code","f463f544":"code","4b33f495":"code","b8c2685e":"code","2267195e":"code","6a35b8ba":"code","9a9042f9":"code","f9c3d0af":"code","ac77e886":"code","3a590e36":"code","65aa413e":"code","6dfff817":"code","4fa535b4":"code","20f16f6a":"code","fe562629":"code","8b92eb0e":"code","05065f28":"code","aefd8690":"code","a7b8366a":"code","63361024":"code","9b7cea47":"code","c2f92601":"code","de88289c":"code","82d4a15c":"code","c806ae1f":"code","b9743d36":"code","92144186":"code","432305fe":"code","d2d3452f":"code","fa8b23b3":"code","9723b7e5":"code","ac56f41c":"code","f316e268":"code","07efe1ec":"code","891f60e9":"code","bbbbd9d3":"code","69bc6414":"code","20fd3329":"code","e6ce847b":"code","37989a7f":"code","a3f3a19f":"code","2d61ceed":"code","72bd07be":"code","7d29ebe7":"code","5d4a7475":"code","251d5171":"code","44c87b03":"code","9efa7685":"code","6a4a124e":"code","88b809f1":"code","9c4f8b35":"code","4360de20":"code","244f57ed":"code","7fc13289":"code","a2225fdd":"code","14a56a3e":"code","433f8210":"code","ca69483e":"code","b42e5dcd":"code","ac98f95f":"code","b21c6bc0":"code","a9571b7f":"code","af4d20f8":"code","03c8e479":"markdown","2103f890":"markdown","74d9d325":"markdown","7bee2f6e":"markdown","08ced4f7":"markdown","ad42950a":"markdown","c54db9a1":"markdown","37433949":"markdown","e6df8594":"markdown","a6606f97":"markdown","9fa84fc3":"markdown","119c3120":"markdown","b955e66b":"markdown","92b86736":"markdown","89f2698b":"markdown","0c2600e4":"markdown","74846b15":"markdown","f4b6c459":"markdown","54895443":"markdown","83f20a8e":"markdown","c3a2edaf":"markdown","66180de4":"markdown","483a7427":"markdown","10b7ab7c":"markdown","4fb992f1":"markdown","bcfb35ae":"markdown","6d6d37fc":"markdown","695f7cd2":"markdown","eee43c27":"markdown","b246ab9b":"markdown","b2150be2":"markdown","1cbf7613":"markdown","9c69e8c9":"markdown","303681e2":"markdown","dee5fbb2":"markdown","b13b7770":"markdown","d0e072bd":"markdown","7c758e43":"markdown","674b2c79":"markdown","58f51356":"markdown","9d9b58df":"markdown","6e4fd21f":"markdown","1dad5a22":"markdown","b0bdda6c":"markdown","b77e8bfb":"markdown","db665616":"markdown","cabef6d3":"markdown","e022d379":"markdown","aa96f38a":"markdown","3fc14cd4":"markdown","58aeb484":"markdown","a068e21f":"markdown","06b25a3f":"markdown","9df7d637":"markdown","d6463e94":"markdown","1bde8978":"markdown","25aad992":"markdown","636ac784":"markdown","6ece6785":"markdown","4f74cc8c":"markdown","e7373141":"markdown","f9278733":"markdown","d0b3eab8":"markdown","5e040ef7":"markdown","1b0bfb46":"markdown","b6564098":"markdown"},"source":{"4af849f8":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\nimport statistics as st\nfrom scipy import stats\n\n#from imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\n\nfrom matplotlib import colors as mcolors\n\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import plot_tree, DecisionTreeClassifier","3c4a3293":"pd.options.display.max_columns = None\n\nsns.set(font_scale=1.4)\nsns.set_style({'font.family': 'serif',\n               'fontname': 'Times New Roman'})","ecf95bf3":"# Paths\npath_Dados_Teste = '..\/input\/mla1-t1-tf\/Dados_Teste.csv'\npath_Dados_Treino = '..\/input\/mla1-t1-tf\/Dados_Treino.csv'\npath_Template_Submissao = '..\/input\/mla1-t1-tf\/Template_Submissao.csv'\npath_Dicionario_de_Dados =  '..\/input\/mla1-t1-tf\/Dicionario_de_Dados.csv'","2d46fabf":"df_teste_original = pd.read_csv(path_Dados_Teste)\n\ndf_treino_original = pd.read_csv(path_Dados_Treino)\n\ndf_template = pd.read_csv(path_Template_Submissao)\n\ndf_dic = pd.read_csv(path_Dicionario_de_Dados)","bc41a88a":"df_teste = df_teste_original.copy()\ndf_treino = df_treino_original.copy()","4929db64":"df_teste.head()","6304be54":"df_treino.head()","30afc81d":"# Gera\u00e7\u00e3o de uma tabela contendo as seguintes informa\u00e7\u00f5es, dado um dataframe:\n# nomes das colunas | seus respectivos tipos | qntd. de valores nulos | qntd. de valores n\u00e3o nulos.\n\ndef get_resumo_dataset(_df):\n    info_treino = {'colunas': _df.columns,\n                   'tipos': _df.dtypes,\n                   'qntd_nulos': _df.isnull().sum(),\n                   'qntd_nao_nulos': _df.notnull().sum()}\n    return pd.DataFrame (info_treino, columns = ['colunas',\n                                                 'tipos', \n                                                 'qntd_nulos', \n                                                 'qntd_nao_nulos']).reset_index(drop=True)","4c1254ae":"# Fun\u00e7\u00e3o de renderiza\u00e7\u00e3o para a tabela gerada por get_resumo_dataset().\ndef print_tabulate_resumo_dataset(resumo_dataset):\n    print(tabulate(resumo_dataset, headers = 'keys', tablefmt = 'psql')) ","81d8c338":"# Retorna uma series com NaNs preenchidos de acordo com o tipo de dado da series.\n# Retorna a pr\u00f3pria series recebida caso n\u00e3o haja NaN.\n# O preenchimento de NaNs \u00e9 explicado a seguir: \n#   Serie do tipo float64 recebe a sua respectiva mediana;\n#   Serie do tipo object recebe a string \"Uninformed\";\n#   Serie do tipo int64 recebe a sua respectiva moda.\n\ndef fill_nans(_series):\n    sum = _series.isnull().sum()\n\n    if sum > 0:\n        if _series.dtype == 'float64':\n            return ( _series.fillna( _series.median() ))\n        elif _series.dtype == 'object':\n            return ( _series.fillna(\"Uninformed\"))\n        else: #int64\n            return ( _series.fillna(st.mode(_series) ))\n    else: #series passada n\u00e3o tem dados faltantes\n        return _series","a4d56e47":"# Gera\u00e7\u00e3o do encoding (formato de series) de dada series especificada\n# Pelos par\u00e2metros recebidos: 1 dataframe, 1 string (nome da coluna).\ndef encode_object_att(_df, _column):\n    label_encoder = LabelEncoder()\n    serie_aux = label_encoder.fit_transform(list(_df[_column].values))\n    return serie_aux","637e1f64":"# Normaliza\u00e7\u00e3o da series especificada pelos par\u00e2metros recebidos.\n# Se o maior valor num\u00e9rico da series for 0 (zero), a pr\u00f3pria series \u00e9 retornada.\n\ndef normalize_numeric_att(_df, _column):\n  series_aux = _df[_column]\n\n  #if series_aux.dtype == 'object':\n    #series_aux = series_aux.astype(int)\n  \n  if np.max(series_aux) != 0:\n      return series_aux \/ np.max(series_aux)\n  else:\n    return series_aux","88db87a6":"df_treino.head()","f3617789":"df_treino.describe()","cfa5b508":"print(\"Qntd. Linhas:\", df_treino.shape[0])\nprint(\"Qntd. Colunas:\", df_treino.shape[1])","15d72b32":"df_treino.info(verbose = True)","e69dd908":"resumo_dataset_treino = get_resumo_dataset(df_treino)\n\n# Retirada de coluna desnecess\u00e1ria para esta subse\u00e7\u00e3o.\nresumo_dataset_treino.drop(['tipos'], axis=1, inplace=True)\n\nprint_tabulate_resumo_dataset(resumo_dataset_treino)","9b8172cc":"limpo_treino = df_treino.dropna()","b40e4490":"print(\"Quantidade de linhas do dataframe de treino, com NaN:\", df_treino.shape[0])\nprint(\"Quantidade de linhas do dataframe de treino, sem NaN:\", limpo_treino.shape[0])","5e77cfcf":"duplicados_treino = df_treino[df_treino.duplicated(keep = 'first')]\nprint(\"Quantia de duplicatas:\", duplicados_treino.shape[0])","318076a6":"df_teste.head()","83fa5bfa":"df_teste.describe()","76e277a8":"print(\"Qntd. Linhas:\", df_teste.shape[0])\nprint(\"Qntd. Colunas:\", df_teste.shape[1])","662effdf":"df_teste.info(verbose = True)","29dc1190":"resumo_dataset_teste = get_resumo_dataset(df_teste)\n\n# Retirada de coluna desnecess\u00e1ria para esta subse\u00e7\u00e3o.\nresumo_dataset_teste.drop(['tipos'], axis = 1, inplace = True)\n\nprint_tabulate_resumo_dataset(resumo_dataset_teste)","65ddfec5":"limpo_teste = df_teste.dropna()","6f6d1f3d":"print(\"Quantidade de linhas do dataframe de teste, com NaN:\", df_teste.shape[0])\nprint(\"Quantidade de linhas do dataframe de teste, sem NaN:\", limpo_teste.shape[0])","3f0acfdb":"duplicados_teste = df_teste[df_teste.duplicated(keep = 'first')]\nprint(\"Quantia de duplicatas:\", duplicados_teste.shape[0])","6441af5b":"correlacoes = df_treino.corr(\"pearson\")\ncor_variaveis = correlacoes.nlargest(177,'diabetes_mellitus')[\"diabetes_mellitus\"][(correlacoes['diabetes_mellitus'] > 0.1) & (correlacoes['diabetes_mellitus'] < 1)]\ncor_variaveis","52b0cf4d":"print(\"Qntd. Colunas:\",len(cor_variaveis))","d2ac0441":"# Verifica\u00e7\u00e3o de padr\u00f5es de valores faltantes dentro as colunas.\n# A verifica\u00e7\u00e3o inclui decis\u00e3o dos pr\u00f3ximos passos, dada situa\u00e7\u00e3o.\n\ndef inspect_missing_data(df, data_type = \"Train\"):\n    \n    print(\"--- Dataframe de {} ---\".format(data_type))\n    \n    missing_data = df.isna().sum().reset_index().sort_values(by=0, ascending=False)\n    no_missing = missing_data[missing_data[0] != 0].shape[0]\n    total_cols = df.shape[1]\n    total_rows = df.shape[0]\n    \n    missing_data.columns = [\"name\", \"missing appearences\"]\n    missing_data[\"%missing from total\"] = missing_data[missing_data[\"missing appearences\"]!=0][\"missing appearences\"]\/total_rows\n    \n    too_much_miss = missing_data[missing_data[\"%missing from total\"] > 0.5].shape[0]\n    to_drop = missing_data[missing_data[\"%missing from total\"] > 0.5][\"name\"].values\n    \n    print(\"H\u00e1 {}\/{} colunas com dados faltantes.\".format(no_missing, total_cols))\n    print(\"H\u00e1 {}\/{} colunas com mais de 50% de dados faltantes. Estas ser\u00e3o retiradas.\".format(too_much_miss,\n                                                                                                           no_missing))\n    \n    return missing_data, to_drop","c58bd109":"_, to_drop_train = inspect_missing_data(df = df_treino, data_type = \"Treino\")\n_, to_drop_test = inspect_missing_data(df = df_teste, data_type = \"Teste\")","f479c818":"df_treino.drop(labels = to_drop_test, axis = 1,inplace = True)\ndf_teste.drop(labels = to_drop_test, axis = 1, inplace = True)","fe2b0429":"to_drop = ['encounter_id', 'hospital_id', 'icu_id']\ndf_treino.drop(labels = to_drop, axis = 1, inplace = True)\ndf_teste.drop(labels = to_drop, axis = 1, inplace = True)","a7d6f85a":"#Adquirindo os nomes das colunas do tipo float64.\ncolunas_float = df_treino.columns[df_treino.dtypes == 'float64']\ncolunas_float = colunas_float.values\ncolunas_float = colunas_float.tolist()","120d8769":"# Execu\u00e7\u00e3o do teste de Shapiro Wilk\n# Primeiro argumento: resultado da estat\u00edstica.\n# O segundo argumento \u00e9 o valor de p.\n# Ho = Os dados apresentam distribui\u00e7\u00e3o\n# H1 = Os dados n\u00e3o apresentam distribui\u00e7\u00e3o normal\n# Se o segundo termo (p-valor) \u00e9 menor que 0,05 (5%) rejeita-se a hip\u00f3tese nula.\n\nprint(\"A(s) seguinte(s) coluna(s) n\u00e3o apresenta(m) distribui\u00e7\u00e3o normal:\")\nfor col in colunas_float:\n    result_stats = stats.shapiro(df_treino[col])\n    if result_stats[1] < 0.05:\n        print(\"-- {}: {}\".format(col, result_stats[1]))","bf9298ff":"# Adquirindo os nomes de todas as colunas.\ncolunas = df_treino.columns\ncolunas = colunas.values\ncolunas = colunas.tolist()\ncolunas.pop() #retirando o atributo target da lista","34e2cec4":"# Preenchimento dos NaNs aplicado aos dataframes.\nfor col in colunas:\n    df_treino[col] = fill_nans(df_treino[col])\n    df_teste[col] = fill_nans(df_teste[col])","7bb658b3":"#Adquirindo os nomes das colunas do tipo object.\ncolunas_object = df_treino.columns[df_treino.dtypes == 'object']\ncolunas_object = colunas_object.values\ncolunas_object = colunas_object.tolist()","a4df1247":"colunas_object","5cc10b46":"for col in colunas_object:\n    df_treino[col] = encode_object_att(df_treino, col)\n    df_teste[col] = encode_object_att(df_teste, col)","4ab64dda":"resumo_dataset_treino = get_resumo_dataset(df_treino[colunas_object])\nprint(\"Tabela de Colunas do tipo `object` (df_treino):\")\nprint_tabulate_resumo_dataset(resumo_dataset_treino)","3ceb6699":"resumo_dataset_teste = get_resumo_dataset(df_teste[colunas_object])\nprint(\"Tabela de Colunas do tipo `object` (df_teste):\")\nprint_tabulate_resumo_dataset(resumo_dataset_teste)","ef6f34eb":"colunas_float = df_treino.columns[df_treino.dtypes == 'float64']\ncolunas_float = colunas_float.values\ncolunas_float = colunas_float.tolist()","0b5dcf14":"for col in colunas_float:\n    df_treino[col] = normalize_numeric_att(df_treino, col)\n    df_teste[col] = normalize_numeric_att(df_teste, col)","770e6d00":"df_treino.head()","247e59d6":"df_teste.head()","69e98049":"print(\"Dataframe de Treino:\")\nresumo_afterTreat_treino = get_resumo_dataset(df_treino)\nprint_tabulate_resumo_dataset(resumo_afterTreat_treino)","e48af228":"print(\"Dataframe de Teste:\")\nresumo_afterTreat_teste = get_resumo_dataset(df_teste)\nprint_tabulate_resumo_dataset(resumo_afterTreat_teste)","7b70fe07":"# Contagem da quantidade de registros de acordo com a confirma\u00e7\u00e3o\n# de presen\u00e7a ou aus\u00eancia de diabetes.\ndf_treino.diabetes_mellitus.value_counts()","32e35d9e":"X = df_treino.loc[:,df_treino.columns[0]:df_treino.columns[len(df_treino.columns)-2]].values\n# df_treino.columns[0] -> primeira coluna do dataframe\n# df_treino.columns[len(df_treino.columns)-2] -> pen\u00faltima coluna do dataframe\n\ny = df_treino['diabetes_mellitus'].values","55f5c313":"# Definindo estrat\u00e9gia de Over Sample\noversample = RandomOverSampler(sampling_strategy = 'minority')\nX_samp, y_samp = oversample.fit_resample(X, y)","9b10f7fb":"X_train, X_test, y_train, y_test = train_test_split(X_samp,\n                                                    y_samp,\n                                                    test_size = 0.25,\n                                                    random_state = 0)","ab980188":"print('Amostras de treino:')\nprint(f' * X_train: {X_train.shape}')\nprint(f' * y_train: {y_train.shape}')\n\nprint('Amostras de teste:')\nprint(f' * X_test: {X_test.shape}')\nprint(f' * y_test: {y_test.shape}')","b7447bde":"reglog_model = LogisticRegression(max_iter = 900,\n                                  multi_class = 'multinomial',\n                                  solver = 'saga',\n                                  penalty = 'none')","f5191cbe":"cv = KFold(n_splits = 3, \n           shuffle = True, \n           random_state = 0)\n\nn_scores = cross_val_score(reglog_model, \n                           X_train, \n                           y_train, \n                           scoring = 'roc_auc', \n                           cv = cv)","57c248b5":"print('Valida\u00e7\u00e3o Cruzada - Regress\u00e3o Log\u00edstica:\\n')\nprint(f'AUC Scores: {n_scores}\\n')\nprint(f'AUC (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'AUC (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","08de8caf":"reglog_model.fit(X_train, y_train)","2816189e":"print(f'AUC (Treino): {round(roc_auc_score(y_train, reglog_model.predict(X_train)), 5)}')\nprint(f'AUC (Teste): {round(roc_auc_score(y_test, reglog_model.predict(X_test)), 5)}')","f7b144ab":"print(\"Classification Report:\")\nprint(classification_report(y_test, reglog_model.predict(X_test), target_names=['No', 'Yes']))","ee853caa":"fig, ax = plt.subplots(figsize = (5,5))\n \ncm = confusion_matrix(y_test, reglog_model.predict(X_test), labels = reglog_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                              display_labels = pd.Series(reglog_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nplt.show()","03c4b13a":"print(\"Acur\u00e1cia Geral da Regress\u00e3o Log\u00edstica:\")\nround(reglog_model.score(X, y), 5) ","3d26aaf5":"print(\"AUC (Treino) da Regress\u00e3o Log\u00edstica aplicada ao dados de treino:\")\nreglog_auc_treino = round(roc_auc_score(y_train, reglog_model.predict_proba(X_train)[:, 1]), 5)\nreglog_auc_treino","5edec912":"print(\"AUC (Teste) da Regress\u00e3o Log\u00edstica aplicada ao dados de teste:\")\nreglog_auc_teste = round(roc_auc_score(y_test, reglog_model.predict_proba(X_test)[:, 1]), 5)\nreglog_auc_teste","99da2c94":"# Aplicando modelo nos dados de teste:\ny_pred_reglog = reglog_model.predict_proba(df_teste)","5226ff14":"y_pred_reglog","bda7a6a9":"# Gerando o documento.csv contendo o resultado da predi\u00e7\u00e3o probabil\u00edstica\n#df_template['diabetes_mellitus'] = y_pred_reglog[:,1]\n#df_template.to_csv('\/kaggle\/working\/pred_reglog.csv', index = False)","a443cacd":"knn_model = KNeighborsClassifier(n_neighbors = 19, \n                                 weights = 'distance', \n                                 p = 1, \n                                 metric = 'chebyshev',\n                                 leaf_size = 40,\n                                 algorithm = 'kd_tree') ","27e153cb":"cv = KFold(n_splits = 3, \n           shuffle = True, \n           random_state = 0)\n\nn_scores = cross_val_score(knn_model, \n                           X_train, \n                           y_train, \n                           scoring = 'roc_auc', \n                           cv = cv)","9c3c5c91":"print('Valida\u00e7\u00e3o Cruzada - KNN:\\n')\nprint(f'Acur\u00e1cias AUC: {n_scores}\\n')\nprint(f'Acur\u00e1cia AUC (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cia AUC (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","003755a9":"knn_model.fit(X_train, y_train)","04fb306c":"print(f'AUC (Treino): {round(roc_auc_score(y_train, knn_model.predict(X_train)), 5)}')\nprint(f'AUC (Teste): {round(roc_auc_score(y_test, knn_model.predict(X_test)), 5)}')","591396fe":"print(\"Classification Report:\")\nprint(classification_report(y_test, knn_model.predict(X_test), target_names=['No', 'Yes']))","a3f955ad":"fig, ax = plt.subplots(figsize = (5,5))\n\ncm = confusion_matrix(y_test, knn_model.predict(X_test), labels=knn_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                              display_labels = pd.Series(knn_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nplt.show()","6273c9dd":"print(\"Acur\u00e1cia Geral do KNN:\")\nround(knn_model.score(X, y), 5)","41ac05b6":"print(\"AUC (Treino) do KNN:\")\nknn_auc_treino = round(roc_auc_score(y_train, knn_model.predict_proba(X_train)[:, 1]), 5)\nknn_auc_treino","5d52f0b0":"# ROC AUC score do modelo aplicado no dados de teste do df_treino_aux\nprint(\"AUC predict_proba(amostra de TESTE) do KNN:\")\nknn_auc_teste = round(roc_auc_score(y_test, knn_model.predict_proba(X_test)[:, 1]), 5)\nknn_auc_teste","bcc91b7d":"# Aplicando modelo nos dados de teste:\ny_pred_knn = knn_model.predict_proba(df_teste)","22709897":"y_pred_knn","83bf314b":"dec_tree_model = DecisionTreeClassifier(criterion = 'entropy',\n                                    max_depth = 20,\n                                    min_samples_split = 2,\n                                    random_state = 0)","c4f47bea":"cv = KFold(n_splits = 3, \n           shuffle = True, \n           random_state = 0)\n\nn_scores = cross_val_score(dec_tree_model, \n                           X_train, \n                           y_train, \n                           scoring = 'roc_auc', \n                           cv = cv)","229f2af2":"print('Valida\u00e7\u00e3o Cruzada - \u00c1rvore de Decis\u00e3o:\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 5)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 5)}')","e864ccab":"dec_tree_model.fit(X_train, y_train)","919f0d37":"print(f'Curva ROC (Treino): {round(roc_auc_score(y_train, dec_tree_model.predict(X_train)), 5)}')\nprint(f'Curva ROC (Teste): {round(roc_auc_score(y_test, dec_tree_model.predict(X_test)), 5)}')","507f82a6":"print(classification_report(y_test, dec_tree_model.predict(X_test), target_names=['No', 'Yes']))","ae1e1611":"fig, ax = plt.subplots(figsize = (5,5))\n\ncm = confusion_matrix(y_test, dec_tree_model.predict(X_test), labels = dec_tree_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                              display_labels = pd.Series(dec_tree_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nplt.show()","9fa294fd":"print(\"Acur\u00e1cia Geral da \u00c1rvore de Decis\u00e3o:\")\nround(dec_tree_model.score(X, y), 5) ","5aa984e9":"print(\"AUC (Treino) da \u00c1rvore de Decis\u00e3o:\")\ndec_tree_auc_treino = round(roc_auc_score(y_train, dec_tree_model.predict_proba(X_train)[:, 1]), 5)\ndec_tree_auc_treino","64ff6987":"print(\"AUC (Teste) da \u00c1rvore de Decis\u00e3o:\")\ndec_tree_auc_teste = round(roc_auc_score(y_test, dec_tree_model.predict_proba(X_test)[:, 1]), 5)\ndec_tree_auc_teste","242d8ff2":"# Aplicando modelo nos dados de teste:\ny_pred_dec_tree = dec_tree_model.predict_proba(df_teste)","6e4d2278":"y_pred_dec_tree","2c0140bc":"#df_template['diabetes_mellitus'] = y_pred_dec_tree[:,1]\n#df_template.to_csv('\/kaggle\/working\/pred_decisiontree.csv', index = False)","d56b9bfd":"random_forest_model = RandomForestClassifier(n_estimators = 30, \n                                             criterion = 'entropy',\n                                             max_depth = 15,\n                                             min_samples_split = 2,\n                                             random_state = 0)","be92b0c2":"cv = KFold(n_splits = 3, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(random_forest_model, \n                           X_train, \n                           y_train, \n                           scoring = 'roc_auc', \n                           cv = cv)","810a19a9":"print('Valida\u00e7\u00e3o Cruzada - Random Forest:\\n')\nprint(f'Acur\u00e1cias AUC: {n_scores}\\n')\nprint(f'Acur\u00e1cia AUC (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias AUC (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","cd1494fe":"random_forest_model.fit(X_train, y_train)","f463f544":"print(f'AUC Treino: {round(roc_auc_score(y_train, random_forest_model.predict(X_train)), 5)}')\nprint(f'AUC Teste: {round(roc_auc_score(y_test, random_forest_model.predict(X_test)), 5)}')","4b33f495":"print(classification_report(y_test, random_forest_model.predict(X_test), target_names=['No', 'Yes']))","b8c2685e":"fig, ax = plt.subplots(figsize = (5,5))\n\ncm = confusion_matrix(y_test, random_forest_model.predict(X_test), labels = random_forest_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                              display_labels = pd.Series(random_forest_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nplt.show()","2267195e":"print(\"Acur\u00e1cia Geral da Random Forest:\")\nround(random_forest_model.score(X, y), 5)","6a35b8ba":"print(\"AUC (Treino) da Random Forest:\")\nrandom_forest_auc_treino = round(roc_auc_score(y_train, random_forest_model.predict_proba(X_train)[:, 1]), 5)\nrandom_forest_auc_treino","9a9042f9":"print(\"AUC (Teste) da Random Forest:\")\nrandom_forest_auc_teste = round(roc_auc_score(y_test, random_forest_model.predict_proba(X_test)[:, 1]), 5)\nrandom_forest_auc_teste","f9c3d0af":"y_pred_randomForest = random_forest_model.predict_proba(df_teste)","ac77e886":"y_pred_randomForest","3a590e36":"#df_template['diabetes_mellitus'] = y_pred_randomForest[:,1]\n#df_template.to_csv('\/kaggle\/working\/pred_randomforest.csv', index = False)","65aa413e":"bagging_model = BaggingClassifier(n_estimators = 100, max_samples = 3000)","6dfff817":"cv = KFold(n_splits = 3, \n           shuffle = True, \n           random_state = 0)\n\nn_scores = cross_val_score(bagging_model, \n                           X_train, \n                           y_train, \n                           scoring = 'roc_auc', \n                           cv = cv)","4fa535b4":"print('Valida\u00e7\u00e3o Cruzada\\n')\nprint(f'AUCs: {n_scores}\\n')\nprint(f'AUC (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'AUCs (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","20f16f6a":"bagging_model.fit(X_train, y_train)","fe562629":"print(f'AUC (Treino): {round(roc_auc_score(y_train, bagging_model.predict(X_train)), 4)}')\nprint(f'AUC (Teste): {round(roc_auc_score(y_test, bagging_model.predict(X_test)), 4)}')","8b92eb0e":"print(classification_report(y_test, bagging_model.predict(X_test), target_names = ['No', 'Yes']))","05065f28":"fig, ax = plt.subplots(figsize = (5,5))\n\ncm = confusion_matrix(y_test, bagging_model.predict(X_test), labels = bagging_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                              display_labels = pd.Series(bagging_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nplt.show()","aefd8690":"print(\"Acur\u00e1cia Geral do Modelo Bagging:\")\nround(bagging_model.score(X, y), 5) ","a7b8366a":"print(\"AUC (Treino) do Bagging:\")\nbagging_auc_treino = round(roc_auc_score(y_train, bagging_model.predict_proba(X_train)[:, 1]), 5)\nbagging_auc_treino","63361024":"print(\"AUC (Teste) do Bagging:\")\nbagging_auc_teste = round(roc_auc_score(y_test, bagging_model.predict_proba(X_test)[:, 1]), 5)\nbagging_auc_teste","9b7cea47":"y_pred_bag = bagging_model.predict_proba(df_teste)","c2f92601":"y_pred_bag","de88289c":"#df_template['diabetes_mellitus'] = y_pred_bag[:,1]\n#df_template.to_csv('kaggle\/working\/pred_bagging.csv', index = False)","82d4a15c":"ada_model = AdaBoostClassifier(n_estimators = 500, \n                               learning_rate = 0.5)","c806ae1f":"cv = KFold(n_splits = 3, \n           shuffle = True, \n           random_state = 0)\n\nn_scores = cross_val_score(ada_model, \n                           X_train, \n                           y_train, \n                           scoring = 'roc_auc', \n                           cv = cv)","b9743d36":"print('Valida\u00e7\u00e3o Cruzada - AdaBoost:\\n')\nprint(f'AUCs: {n_scores}\\n')\nprint(f'AUC (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'AUC (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","92144186":"ada_model.fit(X_train, y_train)","432305fe":"print(f'AUC (Treino): {round(roc_auc_score(y_train, ada_model.predict(X_train)), 4)}')\nprint(f'AUC (Teste): {round(roc_auc_score(y_test, ada_model.predict(X_test)), 4)}')","d2d3452f":"print(classification_report(y_test, ada_model.predict(X_test), target_names = ['No', 'Yes']))","fa8b23b3":"fig, ax = plt.subplots(figsize = (5,5))\n\ncm = confusion_matrix(y_test, ada_model.predict(X_test), labels = ada_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix =cm,\n                              display_labels = pd.Series(ada_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nplt.show()","9723b7e5":"print(\"Acur\u00e1cia Geral do Modelo AdaBoost:\")\nround(ada_model.score(X, y), 5) ","ac56f41c":"print(\"AUC (Treino) do AdaBoost:\")\nboosting_auc_treino = round(roc_auc_score(y_train, ada_model.predict_proba(X_train)[:, 1]), 5)\nboosting_auc_treino","f316e268":"print(\"AUC (Teste) do AdaBoost:\")\nboosting_auc_teste = round(roc_auc_score(y_test, ada_model.predict_proba(X_test)[:, 1]), 5)\nboosting_auc_teste","07efe1ec":"y_pred_adaboost = ada_model.predict_proba(df_teste)","891f60e9":"y_pred_adaboost","bbbbd9d3":"#df_template['diabetes_mellitus'] = y_pred_adaboost[:,1]\n#df_template.to_csv('\/kaggle\/working\/pred_adaboost.csv', index = False)","69bc6414":"soft_voting_model = VotingClassifier(estimators = [('reglog_model', reglog_model),\n                                                   ('random_forest_model', random_forest_model),\n                                                   ('bagging_model', bagging_model),\n                                                   ('ada_model', ada_model)], \n                                     voting = 'soft')","20fd3329":"cv = KFold(n_splits = 3, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(soft_voting_model, \n                           X_train, \n                           y_train, \n                           scoring = 'roc_auc', \n                           cv = cv)","e6ce847b":"print('Valida\u00e7\u00e3o Cruzada - Soft Voting:\\n')\nprint(f'Acur\u00e1cias AUC: {n_scores}\\n')\nprint(f'Acur\u00e1cia AUC (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias AUC (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","37989a7f":"soft_voting_model.fit(X_train, y_train)","a3f3a19f":"print(f'AUC Treino: {round(roc_auc_score(y_train, soft_voting_model.predict(X_train)), 5)}')\nprint(f'AUC Teste: {round(roc_auc_score(y_test, soft_voting_model.predict(X_test)), 5)}')","2d61ceed":"print(classification_report(y_test, soft_voting_model.predict(X_test), target_names = ['No', 'Yes']))","72bd07be":"fig, ax = plt.subplots(figsize = (5,5))\n\ncm = confusion_matrix(y_test, soft_voting_model.predict(X_test), labels = soft_voting_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                              display_labels = pd.Series(soft_voting_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nplt.show()","7d29ebe7":"print(\"Acur\u00e1cia do Modelo Soft Voting:\")\nround(soft_voting_model.score(X, y), 5) ","5d4a7475":"print(\"AUC (Treino) do Soft Voting:\")\nsoft_voting_auc_treino = round(roc_auc_score(y_train, soft_voting_model.predict_proba(X_train)[:, 1]), 5)\nsoft_voting_auc_treino","251d5171":"print(\"AUC (Teste) do Soft Voting:\")\nsoft_voting_auc_teste = round(roc_auc_score(y_test, soft_voting_model.predict_proba(X_test)[:, 1]), 5)\nsoft_voting_auc_teste","44c87b03":"y_pred_soft = soft_voting_model.predict_proba(df_teste)","9efa7685":"y_pred_soft","6a4a124e":"#df_template['diabetes_mellitus'] = y_pred_soft[:,1]\n#df_template.to_csv('\/kaggle\/working\/pred_softVoting.csv', index = False)","88b809f1":"mlp_model = MLPClassifier(max_iter = 600,\n                          random_state = 0,\n                          verbose = 0,\n                          learning_rate_init = 0.010)","9c4f8b35":"cv = KFold(n_splits = 3, \n           shuffle = True, \n           random_state=0)\n\nn_scores = cross_val_score(mlp_model, \n                           X_train, \n                           y_train, \n                           scoring = 'roc_auc', \n                           cv = cv)","4360de20":"print('Valida\u00e7\u00e3o Cruzada - Multilayer Perceptron:\\n')\nprint(f'Acur\u00e1cias: {n_scores}\\n')\nprint(f'Acur\u00e1cias (m\u00e9dia): {round(np.mean(n_scores), 4)}')\nprint(f'Acur\u00e1cias (desvio padr\u00e3o): {round(np.std(n_scores), 4)}')","244f57ed":"mlp_model.fit(X_train, y_train)","7fc13289":"print(f'AUC (Treino): {round(roc_auc_score(y_train, mlp_model.predict(X_train)), 4)}')\nprint(f'AUC (Teste): {round(roc_auc_score(y_test, mlp_model.predict(X_test)), 4)}')","a2225fdd":"print(classification_report(y_test, mlp_model.predict(X_test), target_names = ['No', 'Yes']))","14a56a3e":"fig, ax = plt.subplots(figsize = (5,5))\n\ncm = confusion_matrix(y_test, mlp_model.predict(X_test), labels=mlp_model.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=pd.Series(mlp_model.classes_).map({0: 'No', 1: 'Yes'}))\n\ndisp.plot(cmap = plt.cm.Blues, ax = ax)\n\nplt.show()","433f8210":"print(\"Acur\u00e1cia do Modelo Multilayer Perceptron:\")\nround(mlp_model.score(X, y), 5) ","ca69483e":"print(\"AUC (Treino) do MLP:\")\nmlp_auc_treino =round(roc_auc_score(y_train, mlp_model.predict_proba(X_train)[:, 1]), 2)\nmlp_auc_treino","b42e5dcd":"print(\"AUC (Teste) do MLP:\")\nmlp_auc_teste = round(roc_auc_score(y_test, mlp_model.predict_proba(X_test)[:, 1]), 2)\nmlp_auc_teste","ac98f95f":"y_pred_mlp = mlp_model.predict_proba(df_teste)","b21c6bc0":"y_pred_mlp","a9571b7f":"#df_template['diabetes_mellitus'] = y_pred_mlp[:,1]\n#df_template.to_csv('\/kaggle\/working\/pred_mlp.csv', index = False)","af4d20f8":"aucs = [['Regress\u00e3o Log\u00edstica', reglog_auc_treino, reglog_auc_teste],\n        ['KNN', knn_auc_treino, knn_auc_teste],\n        ['\u00c1rvore de Decis\u00e3o', dec_tree_auc_treino, dec_tree_auc_teste],\n        ['Random Forest', random_forest_auc_treino, random_forest_auc_teste],\n        ['Bagging', bagging_auc_treino, bagging_auc_teste],\n        ['Boosting', boosting_auc_treino, boosting_auc_teste],\n        ['Soft Voting', soft_voting_auc_treino, soft_voting_auc_teste],\n        ['Multilayer Perceptron', mlp_auc_treino, mlp_auc_teste]\n       ]\n\nprint (\"{:<25} {:<25} {:<15}\".format('Modelo', 'AUC Treino','AUC Teste'))\n\nfor auc in aucs:\n    modelo, treino, teste = auc\n    print (\"{:<25} {:<25} {:<15}\".format( modelo, treino, teste))","03c8e479":"Assim como no dataframe para treino, a retirada de registros contendo pelo menos um valor faltante foi desconsiderada pela dr\u00e1stica diminui\u00e7\u00e3o na quantidade de linhas, como \u00e9 observado abaixo:","2103f890":"A quantia de colunas que apresentam dados faltantes, independente da porcentagem, e as que apresentam mais de 50% pode ser observada a seguir:","74d9d325":"Esta subse\u00e7\u00e3o trata do preenchimento de lacunas vazias presentes no dataset. \n\nSua realiza\u00e7\u00e3o inclui primeiramente a identifica\u00e7\u00e3o do tipo de dado do atributo em quest\u00e3o.\n\n> Atributo do tipo `float64` recebe a mediana dos valores presentes na coluna.\n\n> Atributo do tipo `object` recebe o valor `\"Uninformed\"`.\n\n> Atributo do tipo `int64` recebe a moda dos valores presentes na coluna.","7bee2f6e":"## 5.2 Preenchimento de NaNs","08ced4f7":"A equipe desenvolvedora realizou um experimento onde o tamanho do dataset de 179 colunas foi reduzido para as 18 colunas retornadas pelo filtro da an\u00e1lise. Neste experimento, o dataframe reduzido foi submetido ao tratamento de dados (Se\u00e7\u00e3o 5) e, ent\u00e3o, servido aos modelos desenvolvidos (Se\u00e7\u00e3o 6) como bases de treinamento e teste.\n\nAp\u00f3s a an\u00e1lise da performance, isto \u00e9, a compara\u00e7\u00e3o entre m\u00e9tricas de avalia\u00e7\u00e3o, conclu\u00edram que n\u00e3o foi satisfat\u00f3ria: os scores apresentavam valores baixos (0.50 a 0.69)\n\nPortanto, a an\u00e1lise de correla\u00e7\u00e3o n\u00e3o foi considerada para o presente Trabalho Pr\u00e1tico.","ad42950a":"Dentre os modelos aplicados, foi observado que os que apresentaram melhor desempenho atrav\u00e9s do score AUC exibido pela plataforma Kaggle foram **Random Forest**, **Soft Voting** e **Multilayer Perceptron**. \n\nOs melhores scores AUC, desconsiderando o valor apresentado pelo Kaggle, foram os dos modelos **KNN**, **Random Forest**, **\u00c1rvore de Decis\u00e3o** e **Soft Voting**. Apesar disso, o KNN foi um dos modelos com menores scores submetidos ao Kaggle, al\u00e9m de mostrar ter dificuldade em identificar corretamente os n\u00e3o diab\u00e9ticos (ver matriz de confus\u00e3o e valores de *recall* no *classification report*).\n\nLevando em considera\u00e7\u00e3o os scores obtidos, os valores no classification report e as matrizes de confus\u00e3o, o modelo ***Soft Voting*** \u00e9 o melhor para o problema. O voto por este modelo tamb\u00e9m \u00e9 embasado nos modelos utilizados como `estimators`, que n\u00e3o incluem aqueles que tiveram maiores dificuldades em identificar os n\u00e3o-diab\u00e9ticos (KNN e \u00c1rvore de Decis\u00e3o).","c54db9a1":"Obter uma compreens\u00e3o r\u00e1pida do contexto da sa\u00fade geral de um paciente \u00e9 importante, uma vez que pode auxiliar profissionais de sa\u00fade no diagn\u00f3stico de doen\u00e7as.\n\nO conhecimento sobre condi\u00e7\u00f5es cr\u00f4nicas, como diabetes, pode informar as decis\u00f5es cl\u00ednicas sobre o atendimento ao paciente e, em \u00faltima an\u00e1lise, melhorar os resultados do mesmo.\n\nNeste sentido, os registros m\u00e9dicos s\u00e3o necess\u00e1rios para a avalia\u00e7\u00e3o do paciente.\n\nNeste trabalho, voc\u00ea deve prever a probabilidade de um paciente estar com diabetes a partir de informa\u00e7\u00f5es cl\u00ednicas.","37433949":"Como pode ser observado abaixo, o dataset est\u00e1 pronto para ser aplicado aos modelos de ML.","e6df8594":"## 3.2 Dados de Teste","a6606f97":"## 3.1 Dados de Treino","9fa84fc3":"## 6.7 Boosting","119c3120":"## 6.8 Soft Voting *","b955e66b":"## 6.2 Regress\u00e3o Log\u00edstica","92b86736":"O modelo RandomForestClassifier recebeu os seguintes par\u00e2metros:\n\n* `n_estimators = 30`, valor menor que o padr\u00e3o (100), mas mostrou melhor performance em rela\u00e7\u00e3o a valores mais altos;\n* `criterion = 'entropy'`, pois \u00e9 favor\u00e1vel o ganho de informa\u00e7\u00e3o ao medir a qualidade do split da \u00e1rvore;\n* `max_depth = 15` e `min_samples_split = 2`, pois esta combina\u00e7\u00e3o resultou em maiores scores;\n* `random_state = 0`, pois n\u00e3o queremos que o estimador permute splits de forma aleat\u00f3ria. ","89f2698b":"Foi considerada a possibilidade de retirar todas as linhas (registros) que possu\u00edssem pelo menos um dado faltante. O resultado dessa investiga\u00e7\u00e3o \u00e9 observado abaixo:","0c2600e4":"# 6 - Aplica\u00e7\u00e3o de Modelos de ML","74846b15":"# Bibliotecas Utilizadas","f4b6c459":"O primeiro passo realizado foi a identifica\u00e7\u00e3o e exclus\u00e3o de colunas que apresentam mais de 50% de dados faltantes.","54895443":"Definindo o *Test Size* de 25%, as amostras de treino e teste foram criadas:","83f20a8e":"### 3.1.3 Verifica\u00e7\u00e3o de Registros Duplicados","c3a2edaf":"## 6.4 \u00c1rvore de Decis\u00e3o","66180de4":"O modelo KNeighborsClassifier recebeu os seguintes par\u00e2metros:\n\n* `n_neighbors = 19`, pois *n* baixos repercutiam em *scores* baixos;\n* `weights = 'distance'`, pois o valor padr\u00e3o \"uniform\" aumentava as taxas de erros observ\u00e1veis pela matriz de confus\u00e3o;\n* `p = 1` para que o *power parameter* utilize a Dist\u00e2ncia de Manhattan; o valor deste par\u00e2metro \u00e9 necess\u00e1ria para o `metric`;\n* `metric = 'chebyshev'`, pois apresentou maiores acertos de classes corretas;\n* `leaf_size = 40`, pois o par\u00e2metro `algorithm` definido para o modelo requer no m\u00ednimo o valor 40, sendo que o padr\u00e3o para leaf_size \u00e9 30; \n* `algorithm = 'kd_tree'`, pois o algoritmo KDTree tem a finalidade de reduzir o n\u00famero necess\u00e1rio de c\u00e1lculos de dist\u00e2ncia, codificando de forma eficiente as informa\u00e7\u00f5es de dist\u00e2ncia agregadas para a amostra.","483a7427":"As fun\u00e7\u00f5es abaixo foram criadas para auxiliar no desenvolvimento do notebook e s\u00e3o de uso extenso em todo o documento. Est\u00e3o situados em uma se\u00e7\u00e3o separada para que sua localiza\u00e7\u00e3o seja de mais r\u00e1pida.","10b7ab7c":"A decis\u00e3o de preencher colunas do tipo `float64` com a mediana \u00e9 pela melhor  representatividade do valor t\u00edpico em uma amostra. A mediana n\u00e3o \u00e9 distorcida por valores extremamente altos ou baixos. Somente um atributo (`pre_icu_los_days`) possui n\u00e3o possui distribui\u00e7\u00e3o normal. Por\u00e9m, o tratamento foi aplicado a todos. ","4fb992f1":"Ap\u00f3s o encoding das colunas do tipo `object`, as colunas do tipo `float64` foram normalizadas. \n\nA normaliza\u00e7\u00e3o se deu pela divis\u00e3o de cada valor pelo maior existente na respectiva coluna. Esta foi realizada pela fun\u00e7\u00e3o criada `normalize_numeric_att()`.","bcfb35ae":"O m\u00e9todo de preenchimento para `object` e `int64` foi escolhido para que o dataset n\u00e3o sofresse altera\u00e7\u00e3o grande considerando o seu \"intervalo\" de poss\u00edveis valores.\n\nO preenchimento \u00e9 responsabilidade da fun\u00e7\u00e3o criada `fill_nans()`.","6d6d37fc":"# 3 - Explorando o Dataset","695f7cd2":"### 3.2.3 Verifica\u00e7\u00e3o de Registros Duplicados","eee43c27":"## 5.4 Normaliza\u00e7\u00e3o das Colunas `float64`","b246ab9b":"Diante da desigualdade na quantia de registros, foi optado pelo *random oversample* da classe minorit\u00e1ria:","b2150be2":"O modelo VotingClassifier foi utilizado com o par\u00e2metro `voting = soft` e com os modelos anteriormente utilizados de Regress\u00e3o Log\u00edstica, Random Forest, Bagging e AdaBoost. O uso dos modelos de KNN e \u00c1rvore de Decis\u00e3o diminui e sobrecarrega o VotingClassifier. ","1cbf7613":"A retirada de registros contendo pelo menos um NaN foi desconsiderada dada a quantia de registros remanescentes.","9c69e8c9":"### 3.2.1 Verifica\u00e7\u00e3o dos Tipos de Dados","303681e2":"### 3.1.2 Verifica\u00e7\u00e3o de Valores Nulos","dee5fbb2":"O modelo MLPClassifier recebeu os seguintes par\u00e2metros:\n* `max_iter = 600` e `random_state = 0` foram mantidas pela performance e taxas de acerto;\n* `verbose = 0`, para que mensagens n\u00e3o sejam renderizadas;\n* `learning_rate_init = 0.010`, para aumentar levemente a taxa de aprendizado em rela\u00e7\u00e3o ao padr\u00e3o (0.001).","b13b7770":"### 3.1.1 Verifica\u00e7\u00e3o dos Tipos de Dados","d0e072bd":"Ap\u00f3s o encoding, as colunas do tipo `object` agora s\u00e3o do tipo `int64`, como pode ser verificado nas tabelas abaixo:","7c758e43":"## 6.1 Modelos n\u00e3o aplicados","674b2c79":"Estas colunas n\u00e3o passaram por mais nenhum tratamento.","58f51356":"# 5 - Tratamento dos Dados","9d9b58df":"Uma an\u00e1lise de correla\u00e7\u00e3o foi realizada antes do tratamento dos dados, que se encontra na Se\u00e7\u00e3o 5.\n\nA correla\u00e7\u00e3o de Pearson foi aplicada ao dataframe de treino. Filtrando os valores de 0.1 \u00e0 1, foram selecionadas apenas 18 colunas, como pode ser observado:","6e4fd21f":"## 6.9 Multilayer Perceptron *","1dad5a22":"O modelo DecisionTreeClassifier recebeu os seguintes par\u00e2metros:\n\n* `criterion = 'entropy'`, pois \u00e9 favor\u00e1vel o ganho de informa\u00e7\u00e3o ao medir a qualidade do split da \u00e1rvore;\n* `max_depth = 20` e `min_samples_split = 2`, pois esta combina\u00e7\u00e3o resultou em maiores scores;\n* `random_state = 0`, pois n\u00e3o queremos que o estimador permute splits de forma aleat\u00f3ria. ","b0bdda6c":"A Se\u00e7\u00e3o 5 apresenta os m\u00e9todos de Tratamento dos Dados aplicados no dataset.","b77e8bfb":"Para o dataframe de teste, foi observado que n\u00e3o existem registros duplicados, como \u00e9 explicitado abaixo:","db665616":"O modelo AdaBoostClassifier recebeu os seguintes par\u00e2metros:\n* `n_estimators = 500`, `learning_rate = 0.5` e `base_estimator` padr\u00e3o (DecisionTreeClassifier) , pois o modelo faz a predi\u00e7\u00e3o de forma mais acertiva e o desempenho \u00e9 mais r\u00e1pido. O estimador anterior, KNeighborsClassifier, obteve desempenho contr\u00e1rio ao DecisionTreeClassifier. ","cabef6d3":"# 1 - Carregando o Dataset","e022d379":"Ap\u00f3s o preenchimento de NaNs, as colunas (de ambos os dataframes) do tipo `object` passaram pelo processo de encoding. ","aa96f38a":"Para o dataframe de treino, foi observado que n\u00e3o existem registros duplicados, como explicitado abaixo:","3fc14cd4":"### 3.2.2 Verifica\u00e7\u00e3o de Valores Nulos","58aeb484":"## 5.3 Encoding das Colunas `object`","a068e21f":"O \u00faltimo passo desta subse\u00e7\u00e3o representa a retirada de colunas ID: `encounter_id`,`hospital_id` e `icu_id`.","06b25a3f":"## 6.5 Random Forest *","9df7d637":"Antes da aplica\u00e7\u00e3o dos modelos, \u00e9 necess\u00e1rio definir as vari\u00e1veis necess\u00e1rias para o treino e teste dos modelos.\n\nNo entanto, foi constatado que h\u00e1 uma grande desigualdade na quantidade de registros em uma classes, como evidenciado na c\u00e9lula abaixo. Isso foi percebido tamb\u00e9m ap\u00f3s a aplica\u00e7\u00e3o dos modelos, ao avaliar *scores*, *classification reports* e matriz de confus\u00e3o. ","d6463e94":"O modelo LogisticRegression recebeu os seguintes par\u00e2metros:\n\n* `max_iter` recebeu um valor alto levando em conta a \nquantidade elevada de registros e colunas e ao *warning* de que o par\u00e2metro era insuficiente; \n\n* `multi_class = \"multinominal'`, pois minimiza perda para perda de entropia cruzada e prev\u00ea a distribui\u00e7\u00e3o de probabilidade para uma distribui\u00e7\u00e3o de probabilidade multinomial, com o intuito de oferecer suporte nativo a problemas de classifica\u00e7\u00e3o de v\u00e1rias classes. Setando este par\u00e2metro com \"multinominal\" impossibilita alguns valores de outros par\u00e2metros; \n\n* `solver` \u00e9 um dos par\u00e2metros com valores reduzidos pelo `multi_class`. Seu valor \u00e9 \"saga\", pois este algoritmo tamb\u00e9m lida com perda multinominal; \n\n* `penalty` recebeu \"none\", pois o padr\u00e3o (\"l2\") e os demais poss\u00edveis valores n\u00e3o aceitam o `solver = saga`. ","1bde8978":"## 6.3 KNN Classifier","25aad992":"Tendo definido as colunas a serem retiradas, as mesmas s\u00e3o \"dropadas\":","636ac784":"O modelo BaggingClassifier recebeu os seguintes par\u00e2metros:\n\n* `n_estimators = 100` e `max_samples = 3000`, pois esta configura\u00e7\u00e3o apresentou maior performance do modelo, em compara\u00e7\u00e3o aos valores padr\u00f5es. ","6ece6785":"# 2 - Fun\u00e7\u00f5es Originais","4f74cc8c":"Esta se\u00e7\u00e3o procura explorar o dataset integral (dataframes de treino e teste), a fim de definir o tratamento de dados necess\u00e1rio. Os dataframes foram investigados separadamente, dividos em duas subse\u00e7\u00f5es.","e7373141":"# 7 - Conclus\u00e3o","f9278733":"## 6.6 Bagging","d0b3eab8":"# Introdu\u00e7\u00e3o","5e040ef7":"## 5.1 Redu\u00e7\u00e3o do Dataset","1b0bfb46":"Os modelos que n\u00e3o possuem o m\u00e9todo `predict_proba()` n\u00e3o s\u00e3o aplic\u00e1veis ao Trabalho Pr\u00e1tico, s\u00e3o eles:\n*   \u00c1rvore de Regress\u00e3o (DecisionTreeRegressor)\n*   Regress\u00e3o Log\u00edstica (com M\u00e9todo do Gradiente Estoc\u00e1stico)\n*   Regress\u00e3o Linear\n*   Hard Voting\n*   Perceptron","b6564098":"# 4 - An\u00e1lise de Correla\u00e7\u00e3o dos Dados"}}