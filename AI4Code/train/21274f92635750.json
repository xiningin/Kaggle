{"cell_type":{"98e1c845":"code","24e7fc43":"code","67641d7a":"code","49f52852":"code","27af9007":"code","0bcba627":"code","ae27b69b":"code","d7ac1ec5":"code","736a71c4":"code","7fea885a":"code","87ca0777":"code","f6d58e90":"code","708503e4":"code","ede1087a":"code","b1efc8df":"code","8ddf2d30":"code","a5a2b726":"code","a8fe1742":"code","8bb27f48":"code","d72aad22":"code","4e381d08":"code","2d174bdc":"code","f966b58f":"code","633f68d5":"code","8f3c0815":"code","1a436f80":"code","8398d057":"code","1af88351":"code","9a54c31a":"code","28face66":"code","0d56db14":"code","630f19b4":"code","bee1b804":"code","e3e9b406":"code","3df52d84":"code","1b52f5f0":"code","daa6e8ff":"code","cd479a3d":"code","b370c368":"code","f4778750":"code","9ff5b539":"code","76ffc00a":"code","37f02724":"code","ad3382e5":"code","dabeee4f":"code","5fcf1d50":"code","8590c3e7":"code","b73fa46f":"code","16502f72":"code","a03ada36":"code","04dca6d7":"code","aff3fc47":"code","7e5f9ce7":"code","391d689e":"code","a938980d":"code","710a5d0b":"code","fd56ba9e":"markdown","f5fe068c":"markdown"},"source":{"98e1c845":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","24e7fc43":"india = pd.read_csv('\/kaggle\/input\/youtube-new\/INvideos.csv')\nus = pd.read_csv('\/kaggle\/input\/youtube-new\/USvideos.csv')","67641d7a":"india.head()","49f52852":"us.head()","27af9007":"india.shape,us.shape","0bcba627":"## most watched video in India\n\nmax_views_india = india['views'].max()\nindia.loc[india[india['views'] == max_views_india].index[0]]","ae27b69b":"# which video is most liked video in India\n\nmax_likes_india = india['likes'].max()\nindia.loc[india[india['likes'] == max_likes_india].index[0]]","d7ac1ec5":"# which video is most disliked video in India\n\nmax_dislikes_india = india['dislikes'].max()\nindia.loc[india[india['dislikes'] == max_dislikes_india].index[0]]","736a71c4":"## most watched video in US\n\nmax_views_us = us['views'].max()\nus.loc[us[us['views'] == max_views_us].index[0]]","7fea885a":"# which video is most liked video in India\n\nmax_likes_us = us['likes'].max()\nus.loc[us[us['likes'] == max_likes_us].index[0]]","87ca0777":"# which video is most disliked video in India\n\nmax_dislikes_us = us['dislikes'].max()\nus.loc[us[us['dislikes'] == max_dislikes_us].index[0]]","f6d58e90":"## videos having more dislikes then likes in India\n\ndislikes_greater_then_likes = india[india['likes'] < india['dislikes']]","708503e4":"dislikes_greater_then_likes = dislikes_greater_then_likes.sort_values(by='dislikes',ascending=False)\ndislikes_greater_then_likes[['channel_title','publish_time','views','likes','dislikes']].head(10)","ede1087a":"## most watched YT channel in India\n\nmost_popular_YT_channel = india.groupby(['channel_title']).agg({'views':'mean'})\nmost_popular_YT_channel = most_popular_YT_channel.sort_values(by='views',ascending=False)\nmost_popular_YT_channel.head(20)","b1efc8df":"india.head()","8ddf2d30":"## number of videos in which rating is disabled\n\nindia[india['ratings_disabled'] == True].shape","a5a2b726":"## let's check for rating disabled but likes and dislikes are not zero\n\nprint(india[(india['ratings_disabled'] == True) & (india['likes'] != 0)].shape)\nprint(india[(india['ratings_disabled'] == True) & (india['dislikes'] != 0)].shape)","a8fe1742":"def ispangram(str): \n    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n    for char in alphabet: \n        if char in str.lower(): \n            return True\n  \n    return False","8bb27f48":"%%time\n\nenglish_title = list()\ncount_english = 0\ncount_non_english = 0\nnon_english_title = list()\n\nfor i in range(india.shape[0]):\n    res = ispangram(india.loc[i,'title'])\n    if res == True:\n        count_english += 1\n        english_title.append(india.loc[i,'title'])\n    else:\n        count_non_english += 1\n        non_english_title.append(india.loc[i,'title'])","d72aad22":"print(\"length of english titles is:\",count_english)\nprint(\"length of non english titles is:\",count_non_english)","4e381d08":"english_title[:5]","2d174bdc":"non_english_title[:5]","f966b58f":"india['publish_time'][:10]","633f68d5":"temp = pd.DataFrame({\n    'Name':['MohdTAzeem007','AbrarTPd008','SufiyanTGhori009','MalikTDev005','WajidTFlutter00Z']\n})","8f3c0815":"temp","1a436f80":"def split_and_join_string(string): \n\n    list_string = string.split('T') \n    string = ' '.join(list_string)\n    return string","8398d057":"temp['new_name'] = np.nan\nfor i in range(temp.shape[0]):\n    temp.loc[i,'new_name'] = split_and_join_string(temp.loc[i,'Name'])","1af88351":"temp","9a54c31a":"def split_and_join_string_dot(string): \n\n    list_string = string.split('.') \n    return list_string[0]","28face66":"for i in range(temp.shape[0]):\n    temp.loc[i,'new_name'] = split_and_join_string_dot(temp.loc[i,'Name'])","0d56db14":"%%time\n\nindia['new_publish_time'] = np.nan\nfor i in range(india.shape[0]):\n    india.loc[i,'new_publish_time'] = split_and_join_string(india.loc[i,'publish_time'])","630f19b4":"india['new_publish_time'].head()","bee1b804":"%%time\n\nfor i in range(india.shape[0]):\n    india.loc[i,'new_publish_time'] = split_and_join_string_dot(india.loc[i,'new_publish_time'])","e3e9b406":"india['new_publish_time'].head()","3df52d84":"from datetime import datetime\nimport time","1b52f5f0":"def timeToUnix(t):\n    #we have a time in the format \"YYYY-MM-DD HH:MM:SS\", which is a string\n    change = datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\") #this will convert the String time into datetime format\n    t_tuple = change.timetuple() #this will convert the datetime formatted time into structured time\n    return time.mktime(t_tuple) + 3600  #this will convert structured time into unix-time.\n    #Now why, I have added 3600 in the above unix times. NOW, UNIX TIMESTAMP MEANS HOW MANY SECONDS HAVE ELAPSED SINCE 1 JAN 1970\n    #(EPOCH) CALCULATED FROM THE REFERENCE OF GMT. I HAVE MADE THIS PROJECT IN GERMANY WHICH IS 1HR\/3600SECS AHEAD OF GMT TIME, \n    #AND HERE \"time.mktime()\" FUNCTION RETURNS UNIX TIMESTAMP FROM THE REFERENCE OF LOCAL TIME. SO, THEREFORE, IN ORDER TO \n    #COMPENSATE FOR 1HR AHEAD, \"time.mktime\" SUBTRACTED 3600 SECONDS MEANS 1HR FROM UNIX TIME STAMP IN ORDER TO CATER TO \n    #LOCAL TIME. SO, THEREFORE, IF WE WANT OUR UNIX TIME TO BE EXACTLY EQUAL TO GMT TIME, WE HAVE TO ADD 3600 SECONDS \n    #MEANS 1HR TO UNIX TIME. lET SAY AT 12:00AM ON 1st JAN 1970, TIME ELAPSED AT GMT IS 0, THE TIME ELAPSED IN GERMANY IS \n    #3600SEC. NOW ON 1st JAN 2015, ELASPED SECONDS AT GMT IS 'X', SO THE EQUIVALENT ELAPSED SECONDS IN GERMANY WILL BE X+3600. \n    #NOW \"time.mktime()\" SUBTRACT THIS 3600 EXTRA IN GERMAN TIME WHICH WE HAVE TO ADD IN ORDER TO MAKE IT EQUAL TO GMT.","daa6e8ff":"%%time\n\nindia['new_publish_time_v2'] = np.nan\nfor i in range(india.shape[0]):\n    india.loc[i,'new_publish_time_v2'] = timeToUnix(india.loc[i,'new_publish_time'])","cd479a3d":"india['new_publish_time_v2'].head()","b370c368":"india.drop(['publish_time','new_publish_time'],axis=1,inplace=True)","f4778750":"india.head()","9ff5b539":"## which channel frequency is more in India\n\nindia['channel_title'].value_counts()","76ffc00a":"len(india['channel_title'].value_counts())","37f02724":"VikatanTV = india[india['channel_title'] == 'VikatanTV']","ad3382e5":"VikatanTV.head()","dabeee4f":"for i in range(5):\n    print('tags:','*'*10)\n    print(india.loc[i,'tags'])\n    print('description:','*'*10)\n    print(india.loc[i,'description'])\n    print('*'*50)","5fcf1d50":"import plotly.express as px\n\nfig = px.line(VikatanTV, x='new_publish_time_v2', y=\"views\")\nfig.show()","8590c3e7":"fig = px.line(VikatanTV, x='trending_date', y=\"views\")\nfig.show()","b73fa46f":"etvteluguindia = india[india['channel_title'] == 'etvteluguindia']","16502f72":"fig = px.line(etvteluguindia, x='trending_date', y=\"views\")\nfig.show()","a03ada36":"etvteluguindia.loc[etvteluguindia[etvteluguindia['views'] > 8000000].index[0]]","04dca6d7":"etvteluguindia.loc[etvteluguindia[etvteluguindia['views'] > 8000000].index[0],'description']","aff3fc47":"india","7e5f9ce7":"import matplotlib.pyplot as plt\nimport seaborn as sns","391d689e":"sns.distplot(india['views'])","a938980d":"india['likes_log'] = np.log(india['likes'] + 1)\nindia['views_log'] = np.log(india['views'] + 1)\nindia['dislikes_log'] = np.log(india['dislikes'] + 1)\nindia['comment_log'] = np.log(india['comment_count'] + 1)","710a5d0b":"plt.figure(figsize = (12,6))\n\nplt.subplot(221)\ng1 = sns.distplot(india['views_log'])\ng1.set_title(\"VIEWS LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(224)\ng2 = sns.distplot(india['likes_log'],color='green')\ng2.set_title('LIKES LOG DISTRIBUITION', fontsize=16)\n\nplt.subplot(223)\ng3 = sns.distplot(india['dislikes_log'], color='r')\ng3.set_title(\"DISLIKES LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(222)\ng4 = sns.distplot(india['comment_log'])\ng4.set_title(\"COMMENTS LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 0.9)\n\nplt.show()","fd56ba9e":"### according to this dataset the most viewed, most liked and most disliked video is ****\"YouTube rewind 2017\"****","f5fe068c":"##### we see a sudden spike in views for the YT channel \"etvteluguindia\"."}}