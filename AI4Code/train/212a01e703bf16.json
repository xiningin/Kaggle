{"cell_type":{"b092f0c1":"code","cd9a253d":"code","65e3298a":"code","1c69a759":"code","46d2ab66":"code","5829d73a":"code","e8f586d7":"code","14c7d5d0":"code","c5ae17de":"code","42281d60":"code","5763e456":"code","9af9ce85":"code","dbb23604":"code","b46baecd":"code","11dd88ae":"code","841d4f97":"code","290533a1":"code","4d8a3047":"code","30f5167c":"code","dbe7fd3c":"code","10d577ff":"code","098cb0d8":"markdown","3f98c5c2":"markdown","28d57bb5":"markdown","2960c963":"markdown","3c313a22":"markdown","b5d3a4af":"markdown","39728ca4":"markdown","be8dad2b":"markdown","ac7d916e":"markdown","c1571c4d":"markdown","5afa330f":"markdown","5207b58c":"markdown","4a402949":"markdown","ab43e23d":"markdown","00fdcbe4":"markdown","09ea4d9d":"markdown","08f4125b":"markdown","ff5d7ca0":"markdown","a2fdeef2":"markdown","2731f1f9":"markdown","8336b109":"markdown","04dc471e":"markdown","05ce5ada":"markdown","b82dcc63":"markdown","501db104":"markdown","3c447758":"markdown","ff469ccf":"markdown"},"source":{"b092f0c1":"!pip install sentence-transformers\n!pip install annoy\n!pip install bert-extractive-summarizer","cd9a253d":"from sentence_transformers import SentenceTransformer\nfrom annoy import AnnoyIndex\nimport pandas as pd\nimport torch\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")","65e3298a":"input_file = '\/kaggle\/input\/combining-csvfiles\/combined_dataset.csv'\ndata = pd.read_csv(input_file)\ndata = data.fillna('')\ntitle = data['combined_title']\nabstract = data['abstract']\ntext = data['text']\npaper_id = data['paper_id']\nauthors = data['authors']\nprint(data.info())\n","1c69a759":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","46d2ab66":"sentence_model = SentenceTransformer('bert-base-nli-mean-tokens')\nsentence_model.to(device)\nprint()","5829d73a":"sentence_embeddings = sentence_model.encode(title.values.tolist())\nprint('Dimensionality of the embeddings: ', len(sentence_embeddings[0]))","e8f586d7":"embed_dim = 768\ntree = AnnoyIndex(embed_dim, \"dot\")\n\nfor i, vec in enumerate(sentence_embeddings):\n    tree.add_item(i, vec)\n\ntree.build(20)\ntree.save('\/kaggle\/working\/titles_bert_emb.ann')\ndel sentence_embeddings[:]","14c7d5d0":"questions = {\n    'q_1' : [\"what are the effects of COVID-19 or coronavirus on pregnant women?\"],\n    'q_2' : [\"what are the effects of COVID-19 or coronavirus on new born babies?\"],\n    'q_3' : ['what are the effects of COVID-19 or coronavirus on cancer patients?'],\n    'q_4' : ['Which age group is more vulnerable to covid-19?'],\n    'q_5' : ['what are most common underlying diseases in covid-19 patients?'],\n    'q_6' : ['What are the effects of social distancing?'],\n    'q_7' : ['What are the psychological effects of covid-19 on medical staff?'],\n    'q_8' : ['What are the control strategies to curtail transmission of covid-19?'],\n    'q_9' : ['what are the public health mitigation measures that could be effective for control of covid-19?'],\n    'q_10' : ['What are the economic and behavioral impacts of covid-19 pandemic or coronavirus, what are different socio-economic and behavioral factors arised as a result of covid-19 that can affect economy? What is the difference between groups for risk for COVID-19 by education level? by income? by race and ethnicity? by contact with wildlife markets? by occupation? household size? for institutionalized vs. non-institutionalized populations (long-term hospitalizations, prisons)?'],\n    'q_11' : ['what are the transmission dynamics of the covid-19, including the basic reproductive number, incubation period, serial interval, modes of transmission and environmental factors?'],\n    'q_12' : ['what are the public measures to control the spread of covid-19?']\n}","c5ae17de":"tree = AnnoyIndex(embed_dim, 'dot')\ntree.load('\/kaggle\/working\/titles_bert_emb.ann')","42281d60":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_1']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_1'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'pregnant_women.csv'\noutput.to_csv(output_file, index=False)","5763e456":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_2']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_2'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'neonates.csv'\noutput.to_csv(output_file, index=False)","9af9ce85":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_3']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_3'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'cancer_patients.csv'\noutput.to_csv(output_file, index=False)","dbb23604":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_4']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_4'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'vulnerable_groups.csv'\noutput.to_csv(output_file, index=False)","b46baecd":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_5']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_5'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'underlying_diseases.csv'\noutput.to_csv(output_file, index=False)","11dd88ae":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_6']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_6'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'social_distancing.csv'\noutput.to_csv(output_file, index=False)","841d4f97":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_7']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_7'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'medical_staff.csv'\noutput.to_csv(output_file, index=False)","290533a1":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_8']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_8'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'controlling_spread.csv'\noutput.to_csv(output_file, index=False)","4d8a3047":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_9']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_9'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'public_health_measures.csv'\noutput.to_csv(output_file, index=False)","30f5167c":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_10']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_10'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'economic_impacts.csv'\noutput.to_csv(output_file, index=False)","dbe7fd3c":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_11']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_11'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'transmission_dynamics.csv'\noutput.to_csv(output_file, index=False)","10d577ff":"output = pd.DataFrame(columns=['paper_id', 'authors', 'title'])\nquestion = questions['q_12']\nquestion_emb = sentence_model.encode(question)\ntitle_output = tree.get_nns_by_vector(question_emb[0], 10) #top 10 results\nprint('QUESTION: ',questions['q_12'][0])\ntitle_list = title.values.tolist()\nfor i, o in enumerate(title_output):\n  print('-------')\n  print(i)\n  print('Title: ',title_list[o])\n  print('Paper Id: ', paper_id[o])\n  print('Authors: ', authors[o])\n  print('\\n')\n  df = pd.DataFrame([[paper_id[o], authors[o], title[o]]], columns=['paper_id', 'authors', 'title'])\n  output = output.append(df, ignore_index=True)\n\noutput_file = 'public_measures_controlling_spread.csv'\noutput.to_csv(output_file, index=False)","098cb0d8":"# Risk Factors of COVID-19","3f98c5c2":"### COVID-19 and Neonates <a id= 11><\/a>","28d57bb5":"### Using the GPU <a id= 4><\/a>","2960c963":"### Underlying Diseases in COVID-19 Patients <a id= 14><\/a>","3c313a22":"### Public Health Measures for Control of COVID-19 <a id= 18><\/a>","b5d3a4af":"### Building the Trees of Title Embeddings Using Annoy and Saving the Index File <a id= 7><\/a>","39728ca4":"### Loading the Data <a id= 3><\/a>","be8dad2b":"### Psychological Effects of COVID-19 on Medical Staff <a id= 16><\/a>","ac7d916e":"### Downloading the Pretrained SentenceTransformer Model <a id= 5><\/a>","c1571c4d":"### Data Preparation\n1. We used  [cord-19-eda-parse-json-and-generate-clean-csv](https:\/\/www.kaggle.com\/muhammadhassan\/cord-19-eda-parse-json-and-generate-clean-csv) notebook to read the json files and convert them to csv files.\n2. We used [combining-csvfiles](https:\/\/www.kaggle.com\/massiq\/combining-csvfiles) notebook to generate a single csv file of the dataset.","5afa330f":"### Controlling the Spread of COVID-19  <a id= 17><\/a>","5207b58c":"### COVID-19 and Cancer Patients <a id= 12><\/a>","4a402949":"### Install\/Load Packages <a id= 1><\/a>","ab43e23d":"### Extracting the Sentence Embeddings of all Titles <a id= 6><\/a>","00fdcbe4":"### COVID-19 and Social Distaning <a id= 15><\/a>","09ea4d9d":"### Age Groups Vulnerable to COVID-19 <a id= 13><\/a>","08f4125b":"### COVID-19 and Pregnant Women <a id= 10><\/a>","ff5d7ca0":"### Import Libraries\/Packages <a id= 2><\/a>","a2fdeef2":"### Loading the Annoy Index File <a id= 9><\/a>","2731f1f9":"### References:\n* [xhlulu\/cord-19-eda-parse-json-and-generate-clean-csv](https:\/\/www.kaggle.com\/xhlulu\/cord-19-eda-parse-json-and-generate-clean-csv)\n* [muhammadhassan\/cord-19-eda-parse-json-and-generate-clean-csv](https:\/\/www.kaggle.com\/muhammadhassan\/cord-19-eda-parse-json-and-generate-clean-csv)","8336b109":"### Table of Contents:\n* [Install\/Load Packages](#1)\n* [Import Libraries\/Packages](#2)\n* [Loading the Data](#3)\n* [Using the GPU](#4)\n* [Downloading the Pretrained SentenceTransformer Model](#5)\n* [Extracting the Sentence Embeddings of all Titles](#6)\n* [Building the Trees of Title Embeddings Using Annoy and Saving the Index File](#7)\n* [Questions](#8)\n* [Loading the Annoy Index File](#9)\n* [COVID-19 and Pregnant Women](#10)\n* [COVID-19 and Neonates](#11)\n* [COVID-19 and Cancer Patients](#12)\n* [Age Groups Vulnerable to COVID-19](#13)\n* [Underlying Diseases in COVID-19 Patients](#14)\n* [COVID-19 and Social Distaning](#15)\n* [Psychological Effects of COVID-19 on Medical Staff](#16)\n* [Controlling the Spread of COVID-19](#17)\n* [Public Health Measures for Control of COVID-19](#18)\n* [Economic Impacts of COVID-19](#19)\n* [Transmission Dynamics of COVID-19](#20)\n* [Public Measures to Control the Spread of COVID-19](#21)","04dc471e":"### Approach:\n1. Learn the sentence embeddings of all titles using [bert-sentence-transformer](https:\/\/pypi.org\/project\/sentence-transformers\/).\n2. Use the [Annoy](https:\/\/github.com\/spotify\/annoy) library to build a forest of trees using title embeddings.\n3. Save the index file of embeddings to the disk.\n4. Learn the sentence embedding of the given question.\n5. Load the index file from disk and find k nearest neighbours of questions from title embeddings.","05ce5ada":"### Economic Impacts of COVID-19 <a id= 19><\/a>","b82dcc63":"### Transmission Dynamics of COVID-19 <a id= 20><\/a>","501db104":"### Public Measures to Control the Spread of COVID-19 <a id= 21><\/a>","3c447758":"## Introduction\nIn this notebook we have answered different questions related to the risk factors of COVID-19 using different machine learning techniques. The core techniques being used are BERT Sentence Embeddings and Approximate Nearest Neighbors. We learn the sentence embeddings of the titles of the papers and cluster them based on the given question. Finally we pick k titles from the cluster nearest to the given question.\nWe used [xhlulu](https:\/\/www.kaggle.com\/xhlulu)'s notebook [cord-19-eda-parse-json-and-generate-clean-csv](https:\/\/www.kaggle.com\/xhlulu\/cord-19-eda-parse-json-and-generate-clean-csv) to read the json files and convert them to csv files. It saved us a lot of time.","ff469ccf":"### Questions <a id= 8><\/a>"}}