{"cell_type":{"ce488051":"code","0c78b893":"code","b7af3c71":"code","68216b4a":"code","7a74d970":"code","64be7884":"code","10c956b5":"code","acb24c5b":"code","6a01c4b1":"code","1f463f82":"code","7a0319e9":"markdown","e7f425d2":"markdown","6c6e8290":"markdown","9b8336af":"markdown","9a5659d9":"markdown","c39bfe0b":"markdown","c236dbf1":"markdown","4bf6fcdd":"markdown","2f20d34b":"markdown"},"source":{"ce488051":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0c78b893":"import pandas as pd\naccidents = pd.read_csv(\"..\/input\/us-accidents\/US_Accidents_Dec19.csv\")\naccidents.head()","b7af3c71":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","68216b4a":"state_wise= accidents.State.value_counts()\nplt.figure(figsize=(30,6))\nsns.barplot(x=state_wise.index[:15,], y=state_wise[:15,])","7a74d970":"import datetime","64be7884":"times = pd.DatetimeIndex(accidents.Start_Time)\nt = times.hour.value_counts()\nt= t.sort_values(ascending=False)\nplt.figure(figsize=(30,6))\nsns.barplot(x=t.index, y=t)","10c956b5":"import geopandas as gpd\nfrom shapely.geometry import LineString\nimport folium\nfrom folium import Choropleth, Circle, Marker\nfrom folium.plugins import HeatMap, MarkerCluster","acb24c5b":"# Function for displaying the map\ndef embed_map(m, file_name):\n    from IPython.display import IFrame\n    m.save(file_name)\n    return IFrame(file_name, width='100%', height='500px')","6a01c4b1":"#Getting the world map for base\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\namericas = world.loc[world['continent'].isin(['North America', 'South America'])]\n\nUSA = world.loc[world['name'].isin(['United States of America'])]\nUSA.head()","1f463f82":"# Create a base map\nm_1 = folium.Map(location=[42.32,-71.0589], tiles='cartodbpositron', zoom_start=4)\n\n# Add a heatmap to the base map\nHeatMap(data=accidents[['Start_Lat', 'Start_Lng']], radius=10).add_to(m_1)\n\n# Display the map\nembed_map(m_1, 'm_1.html')","7a0319e9":"**A routine function to view the maps in a notebook window. Just need it here is all i would say:-**","e7f425d2":"**Importing the data file to do the tango with...**","6c6e8290":"**1. Which is the bloodiest state? which state has the highest acccident count**","9b8336af":"**This map will show you accidents on a heat map**","9a5659d9":"**Top five rows give us idea of exactly what monstrosity of a data are we looking at. \nNotice the bottom left info about data. 49 columns describing where, what, when, how, and at what condition an accident occured in USA. Now lets get to business. Plotting stuff. Firstly importing required library to plot stuff**","c39bfe0b":"**Next up- 2. What god forsaken time do motorist are on road to meet accidents with! For that the time from data needs to be readable. Rescue 'Time'**","c236dbf1":"**Peak hours are risky then after all! **","4bf6fcdd":"**California guilty as charged**","2f20d34b":"**3. Now to map the locations and see the result on map. We need maps for that. To the import counter we head out**"}}