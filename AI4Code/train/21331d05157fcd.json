{"cell_type":{"f9799e25":"code","7b167b07":"code","79177dc4":"code","e7036f05":"code","24936076":"code","3ac3cbc8":"code","39b3497c":"code","01614399":"code","c17f3eb0":"code","0ff75d5e":"code","e9db0532":"code","c4c80af4":"code","4bf3f857":"code","7a37c5c1":"code","020ae633":"code","a1fcbb9d":"code","de898c7b":"code","cb234f0a":"code","ee6beee8":"code","d94f8d86":"code","9ac33f6e":"code","15317fd6":"code","a42413e7":"code","15a35e9f":"markdown","061e48cd":"markdown","def7ad31":"markdown","31eb5e5a":"markdown","1d7f7882":"markdown","271f85c8":"markdown","1ed7b2f3":"markdown","9079e15a":"markdown","3c271535":"markdown","fc2e720f":"markdown","feb30491":"markdown","3e021845":"markdown","44d51d45":"markdown","8531dbe8":"markdown","7669cbd9":"markdown","a28db982":"markdown","63f755dc":"markdown","e4d65ccd":"markdown","a5a7b9a3":"markdown"},"source":{"f9799e25":"import random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nimport torch.utils.data\nimport matplotlib.pyplot as plt\n\n# set all seed to 0\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\ntorch.backends.cudnn.deterministic = True","7b167b07":"# read data\nall_data = pd.read_csv(\"..\/input\/fer2013\/fer2013.csv\")","79177dc4":"# split to 3 parts\ngroups = [g for _, g in all_data.groupby('Usage')]\ntraining_data = groups[2]\nvalidation_data = groups[1]\ntesting_data = groups[0]","e7036f05":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nlabel_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\ndef make_dataloader(data, batch_size, shuffle):\n    images, labels = data['pixels'], data['emotion']\n    images = np.array([np.fromstring(image, np.uint8, sep=' ') for image in images]) \/ 255.0 # normalizing data to be between 0 and 1\n    images = torch.FloatTensor(images.reshape(images.shape[0], 1, 48, 48)).to(device) # 1 color channel, 48x48 images\n    dataset = torch.utils.data.TensorDataset(images, torch.LongTensor(np.array(labels)).to(device))\n    return torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle)","24936076":"train_loader = make_dataloader(training_data, 100, True)\nvalid_loader = make_dataloader(validation_data, 100, False)","3ac3cbc8":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\nprint(label_names[labels[1]])\nplt.imshow(images[1].view(48, 48).cpu());","39b3497c":"import torch.nn as nn\ndef adjust_model(model):\n    model.conv1 = nn.Conv2d(1, 64, model.conv1.kernel_size, model.conv1.stride, model.conv1.padding, bias=False)\n    model.fc = nn.Linear(model.fc.in_features, 7, bias=False)\n    return model","01614399":"epochs = 100","c17f3eb0":"def eval_model(model, data_loader, criterion):\n    model.eval()\n    with torch.no_grad():\n        accuracy = 0\n        loss = 0\n        for data, labels in data_loader:\n            output = model(data)\n            _, preds = torch.max(output.data, 1)\n            equals = (preds == labels).cpu()\n            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n            loss += criterion(output, labels).data.cpu()\n        return accuracy\/len(data_loader), loss\/len(data_loader)\n        \ndef train_model(model, criterion, optimizer, data_loader, eval_loader):\n    model = model.to(device)\n    test_accuracy_history = []\n    test_loss_history = []\n    for epoch in range(epochs):\n        model.train()\n        for data, labels in data_loader:\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n            \n        accuracy, loss = eval_model(model, eval_loader, criterion)\n        test_accuracy_history.append(accuracy)\n        test_loss_history.append(loss)\n    return test_accuracy_history, test_loss_history","0ff75d5e":"from torch import optim\nfrom torchvision import models\ncriterion = nn.CrossEntropyLoss()\nlrs = [0.1, 0.01, 0.001, 0.0001, 0.000001]\nmodels_1 = [adjust_model(models.resnet18()) for i in range(len(lrs))]\noptimizers = [optim.SGD(models_1[i].parameters(), lr=lrs[i], momentum=0.9) for i in range(len(lrs))]","e9db0532":"for i in range(len(lrs)):\n    accuracy, loss = train_model(models_1[i], criterion, optimizers[i], train_loader, valid_loader)\n    torch.save(accuracy, 'ResNet18_lr_'+ str(lrs[i]) + '_accuracy.pt')\n    torch.save(loss, 'ResNet18_lr_'+ str(lrs[i]) + '_loss.pt') \n    torch.save(models_1[i], 'ResNet18_lr_'+ str(lrs[i]) + '_model.pt')","c4c80af4":"resnet18_accuracy = [torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_0.1_accuracy.pt\"), \n            torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_0.01_accuracy.pt\"),\n            torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_0.001_accuracy.pt\"),\n            torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_0.0001_accuracy.pt\"),\n            torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_1e-06_accuracy.pt\")]\n\nresnet18_loss = [torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_0.1_loss.pt\"),\n                 torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_0.01_loss.pt\"),\n                 torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_0.001_loss.pt\"),\n                 torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_0.0001_loss.pt\"),\n                 torch.load(\"..\/input\/fer2013-results\/results\/ResNet18_lr_1e-06_loss.pt\")]","4bf3f857":"colors = ['skyblue', 'red', 'green', 'violet', 'magenta']\n\ndef make_plots(accuracy, losses, title1, title2, lbls):\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax1.title.set_text(title1)\n    for i in range(len(accuracy)):\n        ax1.plot(range(epochs),accuracy[i], color=colors[i],label=lbls[i])\n    ax1.set_xlabel('epochs');\n    ax1.set_ylabel('accuracy')\n    ax1.legend(loc='lower right')\n\n    ax2 = fig.add_subplot(1, 2, 2)\n    ax2.title.set_text(title2)\n    for i in range(len(losses)):\n        ax2.plot(range(epochs),losses[i], color=colors[i],label=lbls[i])\n    ax2.set_xlabel('epochs');\n    ax2.set_ylabel('loss')\n    ax2.legend(loc='upper left')\n    plt.subplots_adjust(wspace=0.35, right=2.0)\n    plt.show()","7a37c5c1":"title1 = 'ResNet18 accuracy with different larning rates'\ntitle2 = 'ResNet18 loss with different larning rates'\nmake_plots(resnet18_accuracy, resnet18_loss, title1, title2, [str(lr) for lr in lrs])","020ae633":"def print_acc_loss_results(name_tag, var_s, accs, losses):\n    min_inds = []\n    print(\"Min losses:\")\n    for i in range (len(losses)):\n        min_v = min(losses[i])\n        min_ind = losses[i].index(min_v)\n        min_inds.append(min_ind)\n        print(name_tag + ' {}: Loss {:.5f} at the epoch # {}'.format(var_s[i],min_v, min_ind+1))\n    print(\"\\nResulting accuracies:\")\n    for i in range (len(accs)):\n        print(name_tag + ' {}: Accuracy {:.2f}'.format(var_s[i],np.mean(accs[i][-10:-1]) * 100.0))\n    print(\"\\nAccuracies at minimal loss epoch:\")\n    for i in range (len(accs)):\n        print(name_tag + ' {}: Accuracy {:.2f} at the epoch # {}'.format(var_s[i],accs[i][min_inds[i]] * 100, min_inds[i]+1))","a1fcbb9d":"print_acc_loss_results('Learning rate', lrs, resnet18_accuracy, resnet18_loss)","de898c7b":"models_2 = [adjust_model(models.resnet50()), adjust_model(models.resnet152())]\noptimizers_2 = [optim.SGD(models_2[i].parameters(), lr=0.1, momentum=0.9) for i in range(2)]\nnames = ['ResNet50', 'ResNet152']","cb234f0a":"for i in range(len(names)):\n    accuracy, loss = train_model(models_2[i], criterion, optimizers_2[i], train_loader, valid_loader)\n    torch.save(accuracy, names[i] + '_0.1_accuracy.pt')\n    torch.save(loss, names[i] + '_0.1_loss.pt') \n    torch.save(models_2[i], names[i] + '_0.1_model.pt')","ee6beee8":"resnet50_152_accuracy = [torch.load(\"..\/input\/fer2013-results\/results\/ResNet50_0.1_accuracy.pt\"), \n            torch.load(\"..\/input\/fer2013-results\/results\/ResNet152_0.1_accuracy.pt\")]\n\nresne50_152_loss = [torch.load(\"..\/input\/fer2013-results\/results\/ResNet50_0.1_loss.pt\"),\n                 torch.load(\"..\/input\/fer2013-results\/results\/ResNet152_0.1_loss.pt\")]","d94f8d86":"title1 = 'Accuracy for ResNet50 and ResNet152'\ntitle2 = 'Loss for ResNet50 and ResNet152'\nmake_plots(resnet50_152_accuracy, resne50_152_loss, title1, title2, names)","9ac33f6e":"print_acc_loss_results('Model', names, resnet50_152_accuracy, resne50_152_loss)","15317fd6":"test_loader = make_dataloader(testing_data, 100, False)\nmodel_best = torch.load('..\/input\/fer2013-results\/results\/ResNet18_lr_0.1_model.pt')\nacc, losses = eval_model(model_best, test_loader, criterion)","a42413e7":"print('Test accuracy: ' + str(acc*100))","15a35e9f":"We start with loading packages and setting seeds to 0 for reproducible results","061e48cd":"ResNet50 and ResNet152 showed worse results compared to ResNet18: resulting accuracy was 48.3.79% and 49.75% for ResNet50 and ResNet152 respectivly.","def7ad31":"Since it takes very long time to train model, it was done offline and the results were saved in files, that we can load now.","31eb5e5a":"From the loss data we can see, that first model reach minimum loss at epoch 11. The second and third models reach minimum losses at 3d and 4th epochs. Even though loss starts to increase after this, the accuracy with the validation set is also growing for all three models. The model with 0.1 learning rate shows the best accuracy of all models - 57.81%.\nThe model with 0.0001 learing rate has minimum loss at epoch 19, and model with least learning rate of 1e-06 doesn't reach minimum (the loss will keep going down if we increase number of epochs).\n\nThe results show that lower learning rate results in lower accuracy with ResNet18:","1d7f7882":"We start with ResNet18 model and five different learning rates:","271f85c8":"**MODELS TRAINING**","1ed7b2f3":"Let's look at data:","9079e15a":"The learning rate of 0.1 showed best results with ResNet18. We will use it to train ResNet50 and ResNet152 models and compare results with previously trained ResNet18 at the same learning rate.","3c271535":"Each model will be trained with 100 epoches","fc2e720f":"**DATA PREPARATION**","feb30491":"In this project we will be using ResNet models from torchvision package.\nModels will be trained in two steps:\n    1. ResNet18 model trained with different learning rate\n    2. ResNet50 and ResNet152 models trained with learning rate that showed the best result with ResNet18\nFor all models, we will be using CrossEntropyLoss loss function and SGD optimizer.\nResults of training of different models will be compared and the best performing one will be selected for final tests.\n\nWe will need to change the first convolutional layer and the last fully connected layer n the loaded models to fit our data (1 color channel for pictures and 7 classes).","3e021845":"This kernel uses data from [Challenges in Representation Learning: Facial Expression Recognition Challenge](https:\/\/www.kaggle.com\/c\/challenges-in-representation-learning-facial-expression-recognition-challenge\/overview)","44d51d45":"We import data from csv file and split it into 3 groups: training - for our models training, validation - for models' evaluation  and tuning hyperparametrs during training, testing - for evaluation of the final model.","8531dbe8":"**Testing best model on Test dataset**","7669cbd9":"ResNet18 with learning rate 0.1 showed best results on validation dataset. Therefore it was chosen as our final model and will be tested with test dataset ","a28db982":"The test accuracy of ResNet18 model trained with 0.1 learing rate on FER2013 dataset is 58.6%.","63f755dc":"**PART1: Same model - different learning rate**","e4d65ccd":"As last step of data preparation, we process groups: transform Dataframes to DataLoader and reshape images array from 1D to 2D. At the same time data will be moved to GPU if it is available:","a5a7b9a3":"**PART2: ResNet50 and ResNet152 models with best learning rate**"}}