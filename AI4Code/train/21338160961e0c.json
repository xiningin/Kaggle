{"cell_type":{"1c14b728":"code","a83e4590":"code","d4597db6":"code","a8d3f39b":"code","ead37b1a":"code","62be8790":"code","c0f60e0d":"code","82f190fd":"code","40319f2a":"code","c22381ad":"code","d1e7725f":"code","30f69362":"code","5c10f7db":"code","b91bea29":"code","ca4f1895":"markdown","579b5540":"markdown","6be22bf3":"markdown","64dcdede":"markdown","dc3862de":"markdown","88e6c516":"markdown","12072329":"markdown","e557832e":"markdown","ce8e6e44":"markdown"},"source":{"1c14b728":"%reset\n# Load libraries\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn import datasets\n# Import train_test_split function\nfrom sklearn.model_selection import train_test_split\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis","a83e4590":"def CopiarDatabase(database,treino = True):\n  data_temp = pd.DataFrame()\n  database.columns = [column.strip() for column in database.columns]\n  database = database.dropna(axis='rows') #remove NaN\n  data_temp[\"Game\"] = database['Game']\n  data_temp['H_Team']=data['H_Team']\n  #data_temp['A_Team']=data['A_Team']\n  if treino == True :\n\n    data_temp['WinOrLose']=database['WinOrLose']\n  \n  data_temp['H_FG%']=database['H_FG%']\n  data_temp['A_FG%']=database['A_FG%']\n  \n  return data_temp\n","d4597db6":"def PCA_feature(train, treino = True):\n    train3 = pd.DataFrame()\n    train2 = train.select_dtypes(include = np.int64).copy() # obt\u00e9m os colunas com valores int64 \n    if treino == True :\n      train2[\"WinOrLose\"] = train[\"WinOrLose\"] # coluna nova\n      train3[\"WinOrLose\"]=train[\"WinOrLose\"]\n    train2 # novo dataframe\n    \n\n    pca = PCA(n_components=4) # n\u00famer de componentes da PCA\n    X = np.matrix(train2.iloc[:,0:15]) # pega as counas tirando WinOrLose\n    pca.fit(X) # fita o PCA\n    pca.components_ # valores das componentes\n\n    np.round(pca.explained_variance_ratio_,5) # vari\u00e2ncia explicada\n    #transforma\u00e7\u00f5es lineares\n    PCA1 = pca.transform(X)[:,0]\n    PCA2 = pca.transform(X)[:,1]\n    PCA3 = pca.transform(X)[:,2]\n    PCA4 = pca.transform(X)[:,3]\n    #Coloca as novas colunas ao dataframe\n    train3[\"Component 1\"] = PCA1\n    train3[\"Component 2\"] = PCA2\n    train3[\"Component 3\"] = PCA3\n    train3[\"Component 4\"] = PCA4\n    #if treino == True :\n     # print(\"entrou\")\n      #train3[\"WinOrLose\"]=train[\"WinOrLose\"]\n    return train3","a8d3f39b":"def pre_clean_dataset(tratamento, treino = 1):\n    df_temp = tratamento.copy()\n    df_temp = df_temp.dropna(axis='rows') #remove NaN\n    df_temp = df_temp.drop_duplicates()\n    if treino :\n      df_temp['WinOrLose'] = df_temp.WinOrLose.str.replace('L', '0', regex=True)\n      df_temp['WinOrLose'] = df_temp.WinOrLose.str.replace('W', '1', regex=True)\n    #df_temp.drop(['Game'],axis=1,inplace=True)\n    #df_temp.drop(['Data'],axis=1,inplace=True)\n    return df_temp","ead37b1a":"def clean_dataset(df):\n    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n    df.fillna(0, inplace=True)\n    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n    return df[indices_to_keep].astype(np.float64)","62be8790":"def categorical_to_count(df_train, df_test, treino=True):\n    #copia do dataframe original\n    df_train_temp = df_train.copy()\n    df_test_temp = df_test.copy()\n    #dicionario para mapear observa\u00e7\u00f5es\n    old_to_new = {\"New Jersey Nets\": \"Brooklyn Nets\",\n              \"New Orleans Hornets\": \"New Orleans Pelicans\",\n              \"Charlotte Bobcats\": \"Charlotte Hornets\"}\n    df_train_temp.loc[df_train_temp[\"H_Team\"].isin((\"New Jersey Nets\", \"New Orleans Hornets\", \"Charlotte Bobcats\")), \"H_Team\"] = df_train_temp.loc[df_train_temp[\"H_Team\"].isin((\"New Jersey Nets\", \"New Orleans Hornets\", \"Charlotte Bobcats\"))][\"H_Team\"].map(old_to_new)\n    df_test_temp.loc[df_test_temp[\"H_Team\"].isin((\"New Jersey Nets\", \"New Orleans Hornets\", \"Charlotte Bobcats\")), \"H_Team\"] = df_test_temp.loc[df_test_temp[\"H_Team\"].isin((\"New Jersey Nets\", \"New Orleans Hornets\", \"Charlotte Bobcats\"))][\"H_Team\"].map(old_to_new)\n\n    for col in ['H_Team']: \n                #'A_Team']:\n                #\"Data\"]:\n       x_frequency_map = df_train_temp[col].value_counts(normalize=True).to_dict()\n       \n        #substui os dados pela frequencia\n       df_train_temp[col]=df_train_temp[col].map(x_frequency_map)\n       df_test_temp[col]=df_test_temp[col].map(x_frequency_map)\n    #retira-se o target do Dataset\n    if treino :\n      df_train_temp.drop(['WinOrLose'], axis=1, inplace=True)\n      df_test_temp.drop(['WinOrLose'], axis=1, inplace=True)\n    df_train_temp = clean_dataset(df_train_temp)\n    df_test_temp = clean_dataset(df_test_temp)\n    return df_train_temp, df_test_temp","c0f60e0d":"data = pd.read_csv('..\/input\/task-03\/train_full.csv', header=(0)) #Linha para sem PCA\ndata_test = pd.read_csv('..\/input\/task-03\/train_full.csv', header=(0)) #Linha para sem PCA\n\ndata = data.dropna(axis='rows') #remove NaN\ndata = CopiarDatabase(data)\n\ndata_test = CopiarDatabase(data_test,False)\n\ndata.sample(18)\n","82f190fd":"\ndata = pre_clean_dataset(data) # limpa a database de treino\n\np = 0.9 # fracao de elementos no conjunto de treinamento\nx_train, x_test, y_train, y_test = train_test_split(data, data['WinOrLose'], train_size = p, random_state=1978)\nx_train_C, x_test_C = categorical_to_count(x_train, x_test) #transforma os dados categoricos em contagem\n","40319f2a":"data_test = pre_clean_dataset(data_test,False)\ndata_test,data_test1 = categorical_to_count(data_test,data_test, False)\n","c22381ad":"names = [\"Nearest Neighbors\", \n         \"Linear SVM\", \n         \"RBF SVM\", \n         \"Gaussian Process\",\n         \"Decision Tree\", \n         \"Random Forest\", \n         \"Neural Net\", \n         \"AdaBoost\",\n         \"Naive Bayes\", \n         \"QDA\"]\n         \nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=None),\n    RandomForestClassifier(max_depth=None, n_estimators=100, max_features=3),\n    MLPClassifier(alpha=1, max_iter=1000, activation='logistic'),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]\nscore=0\natual = 0\nnomemaior=\"\"\nacuraciamaior=0\npredicao=pd.DataFrame()\npredicao['Game']=data_test['Game']\npredicao.head()\nfor name, clf in zip(names, classifiers):\n  clf.fit(x_train_C, y_train)\n  #score = clf.score(x_test_C, y_test)\n  #print(name,\"Score: \",score,\"\\n\")\n  y_pred = clf.predict(x_test_C)\n  test_pred= clf.predict(data_test)\n  acuracia=metrics.accuracy_score(y_test, y_pred)\n  print(name, \"Accuracy:\",acuracia,\"\\n\")\n  if atual < acuracia:\n    nomemaior=name\n    acuraciamaior=acuracia\n    atual = acuracia\n    predicao['WinOrLose']=test_pred\nprint(\"Maior acuracia \u00e9 \", nomemaior,\"com \",acuraciamaior)    \n","d1e7725f":"predicao.sample(17)","30f69362":"predicao['Game']=pd.to_numeric(predicao['Game'], downcast='integer')\npredicao.sample(17)","5c10f7db":"predicao['WinOrLose'] = predicao.WinOrLose.str.replace('0', 'L', regex=True)\npredicao['WinOrLose'] = predicao.WinOrLose.str.replace('1','W', regex=True)\npredicao.sample(17)","b91bea29":"predicao.to_csv('submission_PCA.csv', index=False)","ca4f1895":"# Fun\u00e7\u00f5es de limpeza e transforma\u00e7\u00e3o de dados\nA func\u00e3o abaixo recebe como parametros a base de dados a copiar e se a database \u00e9 treino ou n\u00e3o, e retorna a database copiada s\u00f3 com as features de interesse.\nEssa fun\u00e7\u00e3o tamb\u00e9m faz uma primeira limpeza na base, excluindo os espa\u00e7os no fim do nome da coluna.","579b5540":"A fun\u00e7\u00e3o abaixo transforma as features categoricas em Numerais (Contagem)","6be22bf3":"Foram usados apenas 5 fatures para a fazer a predi\u00e7\u00e3o desses dados, pois foi notado, e depois confirmado via PCA, que um pequeno numero de features j\u00e1 explica a base de dados toda.\n\nPois lendo a base nota-se que a maioria dos dadoa \u00e9 referente aos times no campeonato apesentando essas estatiticas alta correla\u00e7\u00e3o com o time.\n\nSendo assim foram selecionadas apenas as features que fazem mais sentido se um time perde ou ganha o jogo.\n\nA vantangem de usar poucas features \u00e9 o tempo de processamento reduzido e uma melhor predi\u00e7\u00e3o dos resultados","64dcdede":"Essa fun\u00e7\u00e3o abaixo foi usada para fazer uma pr\u00e9 limpeza dos dados, excluindo dados duplicados, removendo NA's e tranformando W e L em 0 e 1","dc3862de":"Volta a coluna WinOrLose para string de novo","88e6c516":"O Bloco abaixo prepara a base de teste para Submiss\u00e3o","12072329":"# # Preparando os dados obtidos para submiss\u00e3o\nUm amostra da predi\u00e7\u00e3o","e557832e":"# Rodando o C\u00f3digo","ce8e6e44":"A Fun\u00e7\u00e3o abaixo \u00e9 usada para fazer a transforma\u00e7\u00e3o PCA nas Bases\nN\u00e3o foi usada no c\u00f3digo final, e sim apenas como ferramenta na constru\u00e7\u00e3o do c\u00f3digo"}}