{"cell_type":{"f8767c2d":"code","c353892c":"code","88847710":"code","85a16391":"code","90193739":"code","336c694e":"code","269a8b4b":"code","be671273":"code","4f374234":"markdown","01e73719":"markdown","75ef6aab":"markdown","de1c34c5":"markdown","57ede815":"markdown","bffb4952":"markdown","07a138e0":"markdown","7628ccec":"markdown","31848636":"markdown","1657ff19":"markdown"},"source":{"f8767c2d":"! wget https:\/\/github.com\/cornellius-gp\/gpytorch\/archive\/v0.3.5.zip","c353892c":"! unzip v0.3.5.zip","88847710":"from pathlib import Path\nimport shutil\n\nnon_required_files = (\n    \".conda\",\n    \".github\",\n    \"docs\",\n    \"examples\",\n    \"test\",\n    \"environment.yml\",\n    \"LICENSE\",\n    \"pyproject.toml\",\n    \"readthedocs.yml\",\n)\n\nsrc_folder = Path(\"gpytorch-0.3.5\")\nfor fname in non_required_files:\n    target = src_folder \/ fname\n    if target.is_dir():\n        shutil.rmtree(target)\n    else:\n        target.unlink()","85a16391":"! ls -lh {src_folder}","90193739":"import tarfile\nimport base64\nimport io\n\n\ndef pack_folder(target):\n    buff = io.BytesIO()\n    with tarfile.open(fileobj=buff, mode='w:xz') as tar:\n        tar.add(target, arcname='.', recursive=True)\n\n    buff.seek(0)\n    return base64.b85encode(buff.getbuffer()) \n\n\ndata = pack_folder(src_folder)\n# data variable contains the encoded bytes\n\n\n#print(data)","336c694e":"print(len(data))","269a8b4b":"from IPython.core.display import HTML\nimport html\n\ndata_id = str(hash(data)).zfill(8)[-8:]\nescaped = html.escape(str(data))\njs = \"\"\"\nfunction copy_cb(hash) {\n  var inp = document.getElementById(\"i\" + hash)\n  inp.select()\n  inp.setSelectionRange(0, inp.value.length + 1)\n  document.execCommand('copy')\n}\"\"\"\n\ndisplay(HTML(f\"\"\"\n<script type=\"text\/javascript\">\n{js}\n<\/script>\n<div name=\"resultstring\" id=\"resultstring\">\n    <input id=\"i{data_id}\" type=\"text\" value=\"{escaped}\"\/>\n    <button onclick=\"copy_cb({data_id})\">Copy to clipboard<\/button>\n<\/div>\"\"\"))","be671273":"# cleanup\n! rm -r gpytorch-0.3.5\n! rm v0.3.5.zip","4f374234":"## Cleanup\nIn order to reduce our final archive's size, we are about to remove non required files (like tests, docs, ...).  \nPlease note it's *optional* and that the following list is very **specific** to gpytorch, other packages may not work if we delete the same files","01e73719":"extract it","75ef6aab":"# Pack sources and encode to string\nnow we can compress the sources to a *tar.xz* file and encode it with *base85* to be shared \/ imported as a python bytes","de1c34c5":"# The result string\ncopy paste the following cell's **result** into another notebook (without internet access for instance) in order to import gpytorch source code","57ede815":"display the ~ bytes size","bffb4952":"# Intro\nThe goal of this kernel is to export an entire python package into a single string.  \nThis may be usefull for kernels without internet.  \nIf you're just looking to use the [string](#resultstring) then [use this kernel](https:\/\/www.kaggle.com\/maxisoft\/install-packed-package)\n\n## disclaimer\nIn case you use this in a competition, you should double **check** that it is **allowed by the rules**\n\n## notes\n- you still have to install all the required package's dependencies on the target kernel first. In some case they're already preinstalled on kaggle. For other cases, you may be able to use this very technique on the missing dependencies.\n- it may not works for large package or package binds with uninstalled native libraries\n\nHere, we'll use [gpytorch](https:\/\/gpytorch.ai\/) package as exemple for this process","07a138e0":"This is the end of this notebook.\n\nTake a look at [install-packed-package notebook](https:\/\/www.kaggle.com\/maxisoft\/install-packed-package) to see how to install the package","7628ccec":"list remaining files","31848636":"## download package\nlets download the source of gpytorch v0.3.5 from github","1657ff19":"notice that it's a relatively large string"}}