{"cell_type":{"8e1bc467":"code","b3186810":"code","ae5f2ef8":"code","5750a257":"code","a96abca6":"code","7338521e":"code","7d222b83":"code","6254c137":"code","7c026f7e":"code","4ffbc68b":"code","4ac6035d":"code","f11d925b":"code","9d140e11":"code","f32c5913":"code","22a443e4":"code","8e975c06":"code","c1ca94cc":"code","5bdb204c":"code","75c1daeb":"code","47f00f1e":"code","c7b76b0f":"code","6f0b4b98":"markdown","0946d928":"markdown","03f8a312":"markdown","63d31a30":"markdown","5fa76df0":"markdown","f67043a4":"markdown","f57e3ac8":"markdown"},"source":{"8e1bc467":"# Required for node embeddings\n!pip install node2vec","b3186810":"from pathlib import Path\nimport pickle\nfrom time import time\nfrom typing import List, Dict, Set, Tuple\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn\n\nimport gensim\nimport networkx as nx\nfrom node2vec import Node2Vec\n\nfrom pandas_profiling import ProfileReport\n\nattrition_data = '..\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv'\ndf_attrition = pd.read_csv(attrition_data)\ndf_attrition","ae5f2ef8":"# %%time\n# profile = ProfileReport(df_attrition, title='Attirition profiling')\n# profile.to_widgets()\n# alternative way of displaying the report\n# profile.to_notebook_iframe()","5750a257":"target_column = 'Attrition'\nselected_columns = ['EmployeeNumber', 'BusinessTravel', 'Gender', 'JobRole', \\\n                    'MaritalStatus', 'OverTime', 'Attrition']\n\ndf_attrition = df_attrition.loc[:, selected_columns]\ndf_attrition","a96abca6":"class GraphLoader:\n    def __init__(self):\n        self.graph = None\n        self.title = None\n        \n    def build_graph(self, \n                    dataframe: pd.DataFrame, \n                    columns: List, \n                    edge_list: List,\n                    verbose: bool = True,\n                    title: str = 'Unnamed'):\n        self.title = title\n        t0 = time()\n        self.graph = nx.Graph(name = self.title)\n\n        # Add Nodes to the graph.\n        for column in columns:\n            self.graph.add_nodes_from(dataframe[column].values, label=column)\n\n        # Add remaining columns as Node attributes. Optional\n        remaining = dataframe.columns.difference(columns)\n        for node, data in self.graph.nodes(data=True):\n            if data[\"label\"] == \"EmployeeNumber\":\n                self.graph.nodes[node][\"attributes\"] = dataframe.loc[dataframe[\"EmployeeNumber\"] == int(node), remaining].squeeze().to_dict()\n\n        # Add Edges.\n        for _, row in dataframe.loc[:, columns].iterrows():\n            for edge in edge_list:\n                self.graph.add_edge(row[edge[0]], row[edge[1]])\n        \n        if verbose:\n            print(f\"FINISHED in {np.round(time() - t0, 3)} seconds.\")\n            print(nx.info(self.graph))\n        \n        return self.graph\n\n    def draw_graph(self, graph: nx.Graph, node_colors: dict, node: str = None, radius: int = 1) -> None:\n        def assign_colors(graph: nx.Graph) -> List:\n            # Assign Colors to nodes\n            colors = []\n            for n, data in graph.nodes(data=True):\n                node = data[\"label\"]\n                colors.append(node_colors.get(node, \"black\"))\n            return colors\n\n        f = plt.figure(figsize = (20,12), facecolor=\"darkgray\")\n        ax = f.add_subplot()\n\n        if not node:    \n            plt.title(self.title)\n        else:\n            plt.title(f\"Ego Graph around the node {node}, (radius={radius})\")\n            graph = nx.ego_graph(graph, node, radius = radius)\n        \n        colors = assign_colors(graph)\n        nx.draw_networkx(graph, node_size = 800, node_color = colors, with_labels = True)\n        # Add an empty plot to set custom legends\n        from matplotlib.lines import Line2D\n        ax.scatter([],[])\n        legend_elements = [\n            Line2D([0], [0], marker='o', color='w', label='employee no', markerfacecolor = node_colors['EmployeeNumber'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='travel', markerfacecolor = node_colors['BusinessTravel'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='gender', markerfacecolor = node_colors['Gender'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='job role', markerfacecolor = node_colors['JobRole'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='marital status', markerfacecolor = node_colors['MaritalStatus'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='overtime', markerfacecolor = node_colors['OverTime'], markersize=15),\n\n        ]\n        ax.legend(handles=legend_elements, loc='best')\n        plt.show()","7338521e":"nodes = selected_columns[:-1] # Do not select Attrition as a feature node\nedges = [(\"EmployeeNumber\",\"BusinessTravel\"),\n         (\"EmployeeNumber\",\"Gender\"),\n         (\"EmployeeNumber\",\"JobRole\"),\n         (\"EmployeeNumber\",\"MaritalStatus\"),\n         (\"EmployeeNumber\",\"OverTime\")]\n\nnode_colors = { # freestyle, update any color.\n    \"EmployeeNumber\": \"dodgerblue\", \n    \"BusinessTravel\":\"lightgreen\", \n    \"Gender\":\"tan\", \n    \"JobRole\":\"salmon\",\n    \"MaritalStatus\":\"darkcyan\",\n    \"OverTime\":\"lightblue\"\n}","7d222b83":"graph_loader = GraphLoader()\ndemo_graph = graph_loader.build_graph(\n            dataframe = df_attrition.loc[:5, selected_columns[:-1]],\n            columns = nodes, \n            edge_list = edges,\n            verbose = True,\n            title = 'Employe Attrition graph with only 5 samples of data'\n        )\n# graph_loader.draw_graph(demo_graph, node_colors, node = 5, radius = 2) # show only the nodes that are at a distance of 2 edges from the employee 5.\ngraph_loader.draw_graph(demo_graph, node_colors) # Show the whole graph","6254c137":"graph = graph_loader.build_graph(\n            dataframe = df_attrition.loc[:, selected_columns[:-1]],\n            columns = nodes, \n            edge_list = edges,\n            verbose = True,\n            title = 'Employe Attrition Graph'\n)","7c026f7e":"CWD = Path().cwd()\nEMBEDDINGS_DIR = CWD \/ 'embeddings'\nEMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\nSEED = 12\n\nclass VectorizerConfig:\n    dimensions = 64\n    walk_length = 30\n    num_walks = 50\n    window = 10\n    min_count = 1\n    batch_words = 4\n\nclass NodeEmbedding:\n\n    def __init__(self) -> None:\n        self.vectorizer = None\n        self.model = None\n        \n    def generate_random_walks(self, graph: nx.Graph, **params) -> None:\n        self.vectorizer = Node2Vec(graph, **params)\n        # return self.vectorizer\n\n    def fit(self, **params) -> gensim.models.Word2Vec:\n        if self.vectorizer is None:\n            raise Exception(\"No random walks. Generate Random walks by calling generate_random_walks() method first.\")\n        self.model = self.vectorizer.fit(**params)\n        \n        return self.model\n\n    def save_model(self, model: gensim.models.Word2Vec, save_to: Path = EMBEDDINGS_DIR, prefix: str = None) -> None:\n        d = VectorizerConfig.dimensions\n        w = VectorizerConfig.walk_length\n        n = VectorizerConfig.num_walks\n\n        embeddings_filename = f\"{prefix}_embeddings_{d}_{w}_{n}.txt\"\n        model_filename = f\"{prefix}_model_{d}_{w}_{n}.pkl\"\n        # Save only the embeddings in a txt file.\n        self.model.wv.save_word2vec_format(str(EMBEDDINGS_DIR\/embeddings_filename))\n        # Save the entire model.\n        self.model.save(str(EMBEDDINGS_DIR\/model_filename))\n        print(f\"Model and embeddings saved to: {str(EMBEDDINGS_DIR\/model_filename)}\")\n\n    def load_model(self, model_filename: str = None, load_from: Path = EMBEDDINGS_DIR) -> gensim.models.Word2Vec:\n        if Path(EMBEDDINGS_DIR \/ model_filename).exists():\n            print(\"Loaded Model: \", model_filename)\n            with Path(EMBEDDINGS_DIR \/ model_filename).open(mode=\"r+b\") as file:\n                self.model = pickle.load(file)\n        else:\n            raise FileNotFoundError(f\"NOT found: {EMBEDDINGS_DIR \/ model_filename}\")\n        \n        return self.model\n","4ffbc68b":"import multiprocessing\n\nembedder = NodeEmbedding()","4ac6035d":"embedder.generate_random_walks(\n    graph,\n    dimensions = VectorizerConfig.dimensions,\n    walk_length = VectorizerConfig.walk_length,\n    num_walks = VectorizerConfig.num_walks,\n    workers = multiprocessing.cpu_count()\n)","f11d925b":"%%time\nmodel = embedder.fit(\n    window = VectorizerConfig.window,\n    min_count = VectorizerConfig.min_count,\n    batch_words = VectorizerConfig.batch_words\n)","9d140e11":"embedder.save_model(model, save_to = EMBEDDINGS_DIR, prefix = \"attrition\")","f32c5913":"model2 = embedder.load_model(\"attrition_model_64_30_50.pkl\", load_from = EMBEDDINGS_DIR)","22a443e4":"with open(EMBEDDINGS_DIR \/ 'attrition_embeddings_64_30_50.txt', 'r') as embeddings_file:\n    embeddings = embeddings_file.readlines()","8e975c06":"embeddings[:3]","c1ca94cc":"# This function is requred since embeddings are out of order with the target. They were not matched correctly.\ndef align_features_and_target(df: pd.DataFrame, embeddings_file: str = None):\n    vectors = []\n    with Path(EMBEDDINGS_DIR \/ embeddings_file).open(mode=\"r\") as file:\n        results = file.readlines()\n        for person in df[\"EmployeeNumber\"].values:\n            for line in results[1:]:\n                if line.split()[0] == str(person):\n                    vectors.append(line.split()[1:])\n    \n    return np.array(vectors).astype(np.float64)","5bdb204c":"%%time\nembeddings_filename = \"attrition_embeddings_64_30_50.txt\"\nfeature_vectors = align_features_and_target(df_attrition, embeddings_file = embeddings_filename)","75c1daeb":"feature_vectors.shape","47f00f1e":"node_targets = np.array(list(map(lambda label: 1 if label == \"Yes\" else 0, df_attrition[\"Attrition\"])))\n# node_targets = df_attrition_encoded['Attrition'].values\nnode_targets.shape\n","c7b76b0f":"from collections import Counter\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nprint(f'Original target value counts: {Counter(node_targets)}')\nprint(f'Train vectors shape: ', feature_vectors.shape)\n\nx_train, x_test, y_train, y_test = train_test_split(\n    feature_vectors, \n    node_targets, \n    test_size = 0.25,\n    random_state = 12, \n    stratify = node_targets\n)\n\nclassifiers = {\n        'LogisticReg': LogisticRegression(), \n        'SVC': SVC(), \n        'GBC': GradientBoostingClassifier(),\n        'kNN': KNeighborsClassifier()\n}\n\nscores = dict()\nfor name, classifier in classifiers.items():\n        print(f'\\n<------------- MODEL: {name} ----------->')\n        classifier.fit(x_train, y_train)\n        print(classification_report(y_test, classifier.predict(x_test), zero_division = 0))\n        print(f'<------------- END ----------->\\n')\n","6f0b4b98":"# **Third Part - Node Embeddings**\n\nI will give a brief(again no irony) information on the node2vec algorithm then move onto fitting the embedding model.\n\n**CAUTION**: If you are not really into definitions\/theory behind the model and\/or want to see only the implementation, skip this section right away.\n\n(Pisst! are you still here, yes you, then let's move on)\n\nFor each node in the graph network, vector embeddings were obtained by using the complete graph. Starting from each node in the graph, algorithm moves over one of the adjacent edges to walk towards to a node based on a precomputed probability distribution. The number of steps that needs to be taken is a hyper parameter. After this process is repeated in a predefined number of times, a list of Random Walks is obtained for each node as below. These lists are fed into the word representation model along with the size of the embedding vectors. Finally, the vectors in the Embeddings list are obtained by giving this random walks' list into the Word2Vec model from gensim. \n\nRandom Walks = {   \n\n\"Node1\": [ [\"Node1\", \"Node4\", \"Node55\", . . .],   \n\n        [\"Node1\", \"Node33\", \"Node77\"], ...],  \n\n\"Node2\": [ [\u201cNode2\u201d, \u201cNode17\u201d, \u201cNode88\u201d, . . .],   \n\n         [\u201cNode2\u201d, \u201cNode7\u201d, \u201cNode79\u201d], ...], ...   \n\n} \n\n\nEmbeddings = {   \n\n \"Node1\": [0.121, -0.215, 1.564, ...],   \n\n \"Node2\": [0.151, 0.251, -0.516, ...],   \n\n ...   \n\n}   \n\n\nThe two parameters that are effective in probability calculations required before Random Walks are p and q. The type of graph (Directed\/Undirected) determines which parameter will be used.  \n\nP: The parameter that controls the probability of immediate return to the node walked over in the last step. \n\n\nQ: On directed graph networks, where the edges allow moving either inward or outward, q is the parameter that determines which type of edge has the higher probability to be selected.\n\n(This is my definition of brief. I am assuming you did not close the notebook so far. maybe you will soon.)\n","0946d928":"# **Utilization of Node Embeddings in Predicting Employee Attrition (Or another strange title which i have no idea)**\n\n**NOTE**: You can copy or edit this notebook. You can propose an update, point out the weak parts of the notebook or more. All are appreciated. Everyting that I wrote in this notebook came from the free sources on the internet so this is another free source you can learn from. \n\n**Why does this notebook even exist** :)\n\nI was reading the networkx(you know the python library) docs to get an idea of how to analyze a graph network containing employee information of a company, then I ran across the node2vec(you also know this, don't you) library. Long story short, I wanted to write a notebook that demonstrates the use of node embeddings which will be used (or should i say 'utilized') on the HR data I was working.\n\n# **Summary**\n\n**First**, there will be a brief introduction about the methods of transforming the data to a numeric form.\n\n**Second**, we will be seeing a networkx graph built on the IBM HR dataset,\n\n**Third**, we will be fitting a node embedding model on the graph we just created,\n\n**Fourth**, we will use the embeddings from the third step in predicting the attrition (I will not build fully optimized models since that is not the main point of this notebook. Also I have no intention of doing it. sad!)\n\n**Conclusion**, I will summarize what has just happened in this notebook.\n\n\nLet's get started.\n\n# **First Part - Introduction (as i said, it will be brief, no irony)**\n\nIn order for most machine learning models to work, the information in the dataset needs to be represented numerically. After the dataset is represented numerically only then it can be fed into the models.My goal is to use a different transformation method called node embedding for evaluating the feature vectors. We will transform the categorical features in the dataset with the help of node2vec algorithm fitted on a graph network, instead of transforming the dataset using onehot, label or ordinal encoders.\n\nWe will explore the use of node vectors for predicting the employee attrition. This is an experimental work and it is intented to provide an alternative way of representing the data numerically and it needs further tuning. After getting the node vectors we can utilize them in any machine learning model and process as we wish.","03f8a312":"# **Fourth Part - Training the Models on Node Vectors**\n\nWe will first split the vectors into train and test sets. We will try 4 different classifier model from scikit-learn on the train sets then evaluate on the test sets. (Possible improvement point. Oversampling can be tried since the data is unbalanced.)","63d31a30":"\nWhen we look at the graph info below, we can see that there are 1489 nodes, 7350 edges. An every node has approximately 10 neighbors on average. Node number is different than the row number in the data since we are counting each unique value in all the feature columns, not just employee's but their attributes as well. We are drawing edges only between the employee and their attributes.\n","5fa76df0":"Embeddings were written to a txt file with the format:\n\n[\n\nnode_count vector_dimension,\n\nfirst_node_name value1_1 value1_2 ... value1_64\n\nsecond_node_name value2_1 value2_2 ... value2_64\n\n...\n\n]\n\nSo the first element in the list is just information about the content hence not required. Also, we will only be taking the vectors of employee's not the vectors for their attributes.\n    ","f67043a4":"# **Conclusion**\n\n(You still reading? huh!)\n\nFrom the classification report, we can say that model performs poorly on the positive class but the overall results are not that horrible i could say. And as I mentioned in the summary, main point was to showcase the use of node embeddings. We saw how to create a graph with networkx configure it for visualization purposes. Then, we fed this graph into the node2vec model and get back a vector for every node in the graph. Even though we used those vectors in classification, we could use them in any other machine learning task such as regression, clustering etc. So, We saw that we could also use node embeddings in place of the onehot vectors or we could make a pipeline that uses these two methods together for further work.\n\nThese were all I wanted to say. If you have any questions feel free to ask.\n\n### **Thanks for reading**\n","f57e3ac8":"# **Second Part - Building the Networkx Graph on HR dataset**\n\n(If you haven't heard the terms nodes, edges, graphs before, the internet will help you the most.)\n\nFirst we will observe the profiling report from pandas_profiling. What it does is that it profiles the data(clearly explained, you can google it by the way if you don't believe me). This report includes visualizations for the distribution of data for each column as well as statistical measures. For example correlation is just one of them.\n\nI took the notes of those columns which were highly correlated, also the columns that had mostly constant or null values. You could also run the profiler to get the report which was commented out.\n\nBased on the above, I selected 6 columns, 5 as the features and 1 as the target, to build the graph. (Possible improvement point. feature selection can be done instead of blindly dropping the columns.)\n\nThere is a graph builder class that has two methods, namely, build_graph and draw_graph. Build_graph takes the dataframe in addition to node and edge lists. It creates an instance of networkx graph which can be visualized for later use. Draw graph displays a matplotlib figure containing the graph object created in the previous method. Nodes and edges can be configured in many ways. (Possible improvement point. Different node, edge combinations can be tried.)\n\nThere are two different graph objects. One is for visualization of the graph with a small number of data, and one is for the node embedding model to be fitted on.\n"}}