{"cell_type":{"c7a2205b":"code","396c4261":"code","f5ac256b":"code","2a9e7201":"code","e5195bbb":"code","1f3b5a13":"code","d05e82de":"code","44db17f8":"code","e3358fc5":"code","13b4d558":"code","02a5e38a":"code","c9f72095":"code","27779133":"code","c898c298":"code","d00e7c2b":"code","b070f046":"code","429bb749":"code","9a488bf0":"code","fcb04728":"code","1c0cf982":"code","75d9a1aa":"code","91e39b01":"code","8ec04010":"code","a25dcb80":"code","d7c4df3e":"code","386495e6":"code","2c2e87d0":"code","ee9a75c8":"code","14ff6256":"code","d4fec56b":"code","0363e51d":"code","91985515":"code","2058b548":"code","05586988":"code","54a495c7":"code","1b3500b0":"code","7c252fc6":"code","c78095f5":"markdown","8e07b5bf":"markdown","188c1794":"markdown"},"source":{"c7a2205b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","396c4261":"transcriptions = {filename: f\"{dirname}{filename}\" for filename in filenames for dirname, _, filenames in os.walk(\"\/kaggle\/input\/explorationspeechresources\/\")}","f5ac256b":"tedxCorpus=pd.read_csv(transcriptions[\"TEDx_Spanish.transcription\"],names=['sentence','path'],sep=\"TEDX_\")","2a9e7201":"tedxCorpus.loc[:,'path']=tedxCorpus.path.apply(lambda p:f\"TEDX_{p}.wav\")\ntedxCorpus['gender']=tedxCorpus.path.apply(lambda x: 'male' if '_M_' in x else 'female')\ntedxCorpus['accent']='mexicano'\ntranscriptions[\"TEDx_Spanish.transcription\"]=tedxCorpus","e5195bbb":"transcriptions[\"validated.tsv\"]=pd.read_table(transcriptions[\"validated.tsv\"], header = 0)","1f3b5a13":"def process_crowfund(path,gender,accent):\n    df=pd.read_table(path, header = None,names=['path','sentence'])\n    df['gender']=gender\n    df['accent']=accent\n    df.loc[:,'path']=df.path.apply(lambda p:p+'.wav')\n    return df","d05e82de":"transcriptions['es_co_male.tsv']=process_crowfund(transcriptions['es_co_male.tsv'],'male','andino')\ntranscriptions['es_co_female.tsv']=process_crowfund(transcriptions['es_co_female.tsv'],'female','andino')\ntranscriptions['es_pe_male.tsv']=process_crowfund(transcriptions['es_pe_male.tsv'],'male','andino')\ntranscriptions['es_pe_female.tsv']=process_crowfund(transcriptions['es_pe_female.tsv'],'female','andino')\ntranscriptions['es_portoric_female.tsv']=process_crowfund(transcriptions['es_portoric_female.tsv'],'female','caribe')","44db17f8":"tmp=pd.read_json(transcriptions['female_mex.json'],orient='index')\n","e3358fc5":"transcriptions['female_mex.json']=pd.DataFrame()\ntranscriptions['female_mex.json']['path']=tmp.index\ntranscriptions['female_mex.json']['sentence']=tmp.clean.values\ntranscriptions['female_mex.json']['gender']='female'\ntranscriptions['female_mex.json']['accent']='mexicano'\ntmp=None","13b4d558":"def mergeDataframes(**dataframes):\n    return pd.concat(list(dataframes.values()),axis=0).reset_index(drop=True)","02a5e38a":"mergedTranscriptions=mergeDataframes(**transcriptions)","c9f72095":"def getFrequencyDistribution(df,column_name):\n    return df[pd.notnull(df[column_name])].groupby(df[column_name]).size()","27779133":"getFrequencyDistribution(mergedTranscriptions,'accent').plot.bar()","c898c298":"getFrequencyDistribution(mergedTranscriptions,'age').plot.bar()","d00e7c2b":"getFrequencyDistribution(mergedTranscriptions,'gender').plot.bar()","b070f046":"len(mergedTranscriptions.path.unique())!=len(mergedTranscriptions)","429bb749":"len(mergedTranscriptions[mergedTranscriptions.sentence.isnull()]) +  len(mergedTranscriptions[mergedTranscriptions.path.isnull()])","9a488bf0":"from collections import defaultdict\nphonetic_groups = defaultdict(lambda:'other',{\n    **dict.fromkeys(['mexicano', 'andino', 'americacentral'], 'mexican_alike'), \n    **dict.fromkeys(['canario', 'caribe','rioplatense'], 'southAmerican'),\n    **dict.fromkeys(['centrosurpeninsular', 'nortepeninsular','surpeninsular'], 'spaniards'),\n    'chileno':'chileno'})","fcb04728":"mergedTranscriptions.loc[:,'accent']=mergedTranscriptions.accent.apply(lambda a:phonetic_groups[a])","1c0cf982":"getFrequencyDistribution(mergedTranscriptions,'accent').plot.bar()","75d9a1aa":"import numpy as np\ndef apply_w2l_format(dataframe):\n    dataframe=dataframe.reset_index()\n    dataframe.drop('index', axis=1, inplace=True)\n    dataframe['unique_id']=dataframe.index\n    dataframe['duration']=np.zeros(len(dataframe))\n    dataframe=dataframe[['unique_id','path','duration','sentence']]\n    return dataframe","91e39b01":"mergedTranscriptions=apply_w2l_format(mergedTranscriptions)","8ec04010":"mergedTranscriptions.groupby(mergedTranscriptions.sentence.apply(lambda s:len(s.split()))).size().plot.bar()","a25dcb80":"mergedTranscriptions.to_csv(\"raw_dataset.lst\", sep='\\t', index=False, header=None)","d7c4df3e":"import re\nimport string\nimport ftfy\nco_SentenceLevel = {\n    #Separate simbols from words\n    '?':' ? ',\n    '\u00bf':' \u00bf ',\n    ',':' , ',\n    '\\'':' \\' ',\n    '\\.{2,}':' ',\n    '.':' . ',\n    ':':' : ',\n    ftfy.fix_encoding('\u00e1'):ftfy.fix_encoding('A'),\n    ftfy.fix_encoding('\u00e9'):ftfy.fix_encoding('E'),\n    ftfy.fix_encoding('\u00ed'):ftfy.fix_encoding('I'),\n    ftfy.fix_encoding('\u00f3'):ftfy.fix_encoding('O'),\n    ftfy.fix_encoding('\u00fa'):ftfy.fix_encoding('U'),\n    #delete some useless simbols\n    '-':' ',\n    '(':' ',\n    ')':' ',\n    #delete double space, and sequences of \"-,*,^,.\"\n    '\\?{2,}|\\!{2,}':' '\n}\n\n\ndef escapePattern(pattern):\n    \"\"\"Helper function to build our regex\"\"\"\n    if len(pattern)==1:\n        pattern=re.escape(pattern)\n    return pattern\n\ndef compileCleanerRegex(cleaningOptions):\n    \"\"\"Given a dictionary of rules this contruct the regular expresion to detect the patterns \"\"\"\n    return re.compile(\"(%s)\" % \"|\".join(map(escapePattern,cleaningOptions.keys())))","386495e6":"delete=ftfy.fix_encoding('\\\"!\u00a1#$%&()*+-\/:<=>@[\\\\]^_`{|}\\'~')\nreplaceVocal=ftfy.fix_encoding('\u00e4\u00eb\u00ef\u00f6\u00fc')\n\nclean_regex=compileCleanerRegex(co_SentenceLevel)\nrmPunc =str.maketrans('','',delete)\nrPVocal =str.maketrans(replaceVocal,'aeiou')\nnorm_spaces=re.compile(\"\\s{1,}\")","2c2e87d0":"def clean_text(text,cleaningOptions,cleaningRegex,removePunct,replaceVocab,norm_spaces):\n    \"\"\"Cleaning function for text\n       Given a text this function applies the cleaning rules defined\n       in a dictionary using a regex to detect the patterns.\n   Args:\n       text (str): The text we want to clean.\n       cleaningRegex(regex): Regular expression to detect\n                                    the patterns defined in the cleaning options\n                                    compiled using the compileCleanerRegex(cleaningOptions) function.\n\n    Returns:\n        The cleaned text applying the cleaning options.\n    \"\"\"\n    text=ftfy.fix_encoding(text).lower()\n    text=cleaningRegex.sub(lambda mo:cleaningOptions.get(mo.group(1),), text)\n    text=text.translate(removePunct)\n    text=text.translate(replaceVocab)\n    return ' '.join(norm_spaces.split(text.strip()))","ee9a75c8":"from functools import partial\nclean=partial(clean_text,cleaningOptions=co_SentenceLevel,cleaningRegex=clean_regex,removePunct=rmPunc,replaceVocab=rPVocal,norm_spaces=norm_spaces)","14ff6256":"ph=\"\"\"\\\"Tal programa, \"\"Rog-O-Matic\"\",el ping\u00fcino fue desarrollado para jugar.... y ganar el juego.\\\"  \u00e1ngel ,  diego g\u00f3mez ,  carlos o'connor reina ,  ma . \"\"\"\nclean(ph)","d4fec56b":"from multiprocessing import Pool\nfrom tqdm.notebook import tqdm\nwith Pool(8) as p:\n    mergedTranscriptions.loc[:,'sentence']=tqdm(p.imap(clean,mergedTranscriptions.sentence.values),\n                                                total=len(mergedTranscriptions))","0363e51d":"mergedTranscriptions['sentence'].sample(10).values","91985515":"mergedTranscriptions.to_csv(\"punc_dataset.lst\", sep='\\t', index=False, header=None)","2058b548":"punclst=string.punctuation+'\u00bf'\nrmPunc =str.maketrans('','',punclst)\ndef remPunct(text,rmPunc=rmPunc,norm_spaces=norm_spaces):\n    text=text.translate(rmPunc)\n    return ' '.join(norm_spaces.split(text.strip())) ","05586988":"with Pool(8) as p:\n    mergedTranscriptions.loc[:,'sentence']=tqdm(p.imap(remPunct,mergedTranscriptions.sentence.values),\n                                                total=len(mergedTranscriptions))","54a495c7":"mergedTranscriptions['sentence'].sample(10).values","1b3500b0":"mergedTranscriptions.to_csv(\"np_accents_dataset.lst\", sep='\\t', index=False, header=None)","7c252fc6":"mergedTranscriptions.loc[:,'sentence']=mergedTranscriptions.sentence.apply(lambda s:s.lower())\nmergedTranscriptions.to_csv(\"np_dataset.lst\", sep='\\t', index=False, header=None)\nmergedTranscriptions['sentence'].sample(10).values","c78095f5":"Grouping a-like accents","8e07b5bf":"Empty values?","188c1794":"Repeated Values?"}}