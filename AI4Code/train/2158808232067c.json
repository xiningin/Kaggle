{"cell_type":{"b4cf7d31":"code","de78d462":"code","5ac4263a":"code","b8d59cd4":"code","882a03aa":"code","03cfec0b":"markdown","6f4552a0":"markdown","f83bb521":"markdown"},"source":{"b4cf7d31":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\ninput_dir = '\/kaggle\/input'\nworking_dir = '\/kaggle\/working\/'\ntemp_dir = '\/kaggle\/temp\/'","de78d462":"train_df = pd.read_csv('\/kaggle\/input\/tensorflow-great-barrier-reef\/train.csv')\nprint(train_df.shape)\nprint(train_df.isna().sum())\ntrain_df.head(5)","5ac4263a":"def get_sequence_stats(dataframe):\n    num_seq_dataframe = len(dataframe.sequence.unique())\n    print(f'Number of sequences : {num_seq_dataframe}')\n    print('{Sequence ID}   {Num of imgs in Sequence (or Sequence length)}')\n    print(dataframe.sequence.value_counts(sort=False).sort_index())\n    fig, ax = plt.subplots()\n    dataframe.sequence.plot(ax=ax)\n    plt.show()\n\ndef get_video_frame_stats(dataframe):\n    print(f'Number of video_frames : {len(dataframe.video_frame.unique())}')\n    fig, ax = plt.subplots()\n    dataframe.video_frame.plot(ax=ax)\n    plt.show()\n    \ndef get_annotation_stats(dataframe):\n    dataframe['bbox_count'] = dataframe.annotations.apply(lambda x: x.count('{'))\n    print('{BBox Count}   {Num of images with this many BBoxes}')\n    print(dataframe['bbox_count'].value_counts(sort=False).sort_index())\n    print(f'Total Number of bboxes : {dataframe.bbox_count.sum()}')\n    num_img_with_no_bbox = (dataframe.bbox_count == 0).sum()\n    num_img_with_bbox = (dataframe.bbox_count != 0).sum()\n    print(f'Total Number of images (or video_frames) : {dataframe.shape[0]}')\n    print(f'Total Number of images having non-empty annotation (i.e no bbox) : {num_img_with_no_bbox}')\n    print(f'Total Number of images having non-empty annotation : {num_img_with_bbox}')\n    dataframe_with_bbox = get_parsed_annotation(dataframe[dataframe.bbox_count != 0].copy())\n    print(f'BBoxes Stats (for img having bboxes): ')\n    bbox_stats(dataframe_with_bbox.copy())\n    \ndef bbox_stats(dataframe):\n    bbox_area = []\n    for height_list, width_list in zip(dataframe.height, dataframe.width):\n        for height, width in zip(height_list, width_list):\n            bbox_area.append(height*width)\n    bbox_area = pd.Series(bbox_area)\n    print(f'Mean of bbox_area : {bbox_area.mean()}')\n    print(f'Median of bbox_area : {bbox_area.median()}')\n    fig, ax = plt.subplots()\n    bbox_area.plot(ax=ax)\n    plt.show()\n    fig, ax = plt.subplots()\n    bbox_area.hist(ax=ax)\n    plt.show()\n    \ndef get_parsed_annotation(dataframe):\n    dataframe['parsed_annotation'] = dataframe.annotations.apply(lambda x: list(eval(x)))\n    dataframe['width'] = dataframe.parsed_annotation.apply(lambda x: [i['width'] for i in x])\n    dataframe['height'] = dataframe.parsed_annotation.apply(lambda x: [i['height'] for i in x])\n    #dataframe['bbox_area'] = dataframe.apply(lambda x: [width*height for height, width in zip(x.width, x.height)], axis=1)\n    return dataframe\n    \ndef get_metadata_stats(dataframe):\n    print(f'Total number of videos : {len(dataframe.video_id.unique())}')\n    print()\n    print(f'Cummulative sequence stats : ')\n    get_sequence_stats(dataframe.copy())\n    print()\n    print(f'Cummulative annotation stats : ')\n    get_annotation_stats(dataframe.copy())\n    print()\n    print('- - - - - - - - - - - - - - - - - - - -')\n    \n    # get stats for each video\n    for video_id in dataframe.video_id.unique():\n        local_dataframe = dataframe[dataframe.video_id == video_id]\n        print()\n        print(f'Video ID : {video_id}')\n        print()\n        print(f'Cummulative sequence stats : ')\n        get_sequence_stats(local_dataframe.copy())\n        print()\n        print(f'Cummulative video_frame stats : ')\n        get_video_frame_stats(local_dataframe.copy())\n        print()\n        print(f'Cummulative annotation stats : ')\n        get_annotation_stats(local_dataframe.copy())\n        print()\n        print('# # # # # # # # # # # # # # # # # # # # # #')\n        ","b8d59cd4":"get_metadata_stats(train_df.copy())","882a03aa":"from PIL import Image\n\nimg_dir = '\/kaggle\/input\/tensorflow-great-barrier-reef\/train_images'\n\ntrain_img_dim = {}\nfor video_dir in os.listdir(img_dir):\n    images = os.listdir(os.path.join(img_dir, video_dir))\n    for img in images:\n        image_path = os.path.join(img_dir, video_dir, img)\n        img_pil = Image.open(image_path)\n        size = img_pil.size\n        if size in train_img_dim:\n            train_img_dim[size] += 1\n        else:\n            train_img_dim[size] = 1\nprint(train_img_dim)\n        ","03cfec0b":"## (A) 1- Let's see some metadata stats for a single video_id","6f4552a0":"### (A) 2 - Checking Images","f83bb521":"## (A) Train CSV"}}