{"cell_type":{"736fe0db":"code","4d450652":"code","4031b28c":"code","6b85c4ee":"code","5b6ba837":"code","ab2783f2":"code","0889037f":"code","90cdb1b1":"code","569bc016":"code","a8eb22f0":"code","948ca494":"code","a7a00757":"code","de0c86b8":"code","74436c13":"code","15b4659a":"code","e19bff46":"code","7cc74fb7":"code","f092d9cf":"code","80839b28":"code","53d49dfb":"code","e459bcb6":"code","a3e6c7d7":"code","0220c1cc":"code","2cae0cc7":"code","8808eefd":"code","7f7f4a04":"code","ecf7e596":"code","7b188515":"code","ef059c6d":"code","e0c544c8":"code","029e46ab":"code","7f46616c":"code","12ee926c":"code","e5c62875":"code","bb4d400c":"code","277c932c":"code","8a6d03d6":"code","177a7c61":"code","6f1ceab0":"code","66df2c4d":"code","8df40045":"code","7373a362":"code","6d337a97":"code","7048427b":"code","e201458c":"code","c6e4dd7b":"code","38c465d6":"code","7796b189":"code","001858f8":"code","0bc0f9db":"code","676349e9":"code","55969bc5":"code","891a63aa":"code","195c1742":"code","9e117f99":"code","8fa6bab4":"code","0eb5285f":"code","f9ce5333":"code","304e050c":"code","424f8601":"code","c11d5702":"code","f6272318":"code","96af7977":"code","33a8926b":"code","3b36c54e":"code","2f096d02":"code","ba575a51":"code","0edbc8fa":"code","d17e8b66":"code","4b5255e7":"code","6b8a6c49":"code","4d12b623":"code","116dbaa6":"code","3b392cc8":"code","7540f552":"code","0d35cefa":"code","fa28e7db":"code","e0804c19":"markdown","e4136753":"markdown","398e7efc":"markdown","766284fc":"markdown","2aefedac":"markdown","4ef87f0e":"markdown","499cab95":"markdown","8dbb2298":"markdown","b4a07950":"markdown","697f0946":"markdown","82c84707":"markdown","1af526ae":"markdown","176c569f":"markdown","1f5ea10c":"markdown","0e01bcfc":"markdown","9fe0abe7":"markdown","de4ea811":"markdown","c68e6aa2":"markdown","90b676a2":"markdown","a719f11e":"markdown","b1010f57":"markdown","513a4cdf":"markdown","188850c0":"markdown","6989c5c4":"markdown","b15c8eb5":"markdown","0b37046f":"markdown","ab616224":"markdown","32772718":"markdown","4b30cf48":"markdown","1aaaf027":"markdown","c0e07adf":"markdown","b0457947":"markdown","5e02aff5":"markdown","69ebf4f8":"markdown","fdbe4674":"markdown","fac08859":"markdown","7d624eb6":"markdown","19d1e61c":"markdown","adf1b607":"markdown","9722301f":"markdown","9801a98e":"markdown","923ab352":"markdown","52ecb57a":"markdown","88be8e2a":"markdown","a315ca27":"markdown","0c961375":"markdown","c0c7f670":"markdown","440974f7":"markdown","89aa1ccf":"markdown","c4915cb8":"markdown","06736b52":"markdown","d4bf6103":"markdown","57bb8a93":"markdown","b744f45f":"markdown","356dc540":"markdown","5dac7cf0":"markdown","7f8ce31e":"markdown","e009705e":"markdown","18612a63":"markdown","01b78c32":"markdown","d178be1b":"markdown","7e0d27a8":"markdown","5e992bda":"markdown","94b29c0b":"markdown","ba423e84":"markdown","ab9eb429":"markdown","592c89be":"markdown","68cfd0fa":"markdown","38280900":"markdown","2755fe0f":"markdown","fd781689":"markdown","76d4b72e":"markdown","70d1d15b":"markdown","f0c737ef":"markdown","4f169c86":"markdown","903bc6f1":"markdown","6dc004fb":"markdown","ad343b7c":"markdown","e1ae791b":"markdown","3590f7fb":"markdown","f704c102":"markdown","9aaa5fa3":"markdown","4bf181fb":"markdown"},"source":{"736fe0db":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom matplotlib.gridspec import GridSpec\nfrom scipy.special import boxcox1p\nimport warnings\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\nwarnings.filterwarnings(\"ignore\") # ignoring annoying warnings","4d450652":"warnings.filterwarnings(\"ignore\")","4031b28c":"gender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest[\"Survived\"] = np.nan # we don't have target values for the test","6b85c4ee":"dataset = pd.concat([train,test],axis=0).reset_index(drop=True)\ndataset = dataset.fillna(np.nan)","5b6ba837":"dataset.head(10)","ab2783f2":"dataset.dtypes","0889037f":"dataset.isnull().sum(axis = 0)","90cdb1b1":"dataset.describe()","569bc016":"sns.factorplot(x='SibSp', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nSibSp')\nplt.ylabel('Survival Probability\\n')\nplt.show()","a8eb22f0":"sns.factorplot(x='Parch', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nParch')\nplt.ylabel('Survival Probability\\n')\nplt.show()","948ca494":"dataset[\"Family\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ntrain[\"Family\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"Family\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","a7a00757":"sns.factorplot(x='Family', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived', \n               palette = \"dark\")\nplt.xlabel('\\nFamily')\nplt.ylabel('Survival Probability\\n')\nplt.show()","de0c86b8":"dataset = dataset.drop(columns=[\"SibSp\",\"Parch\"])\ntrain = train.drop(columns=[\"SibSp\",\"Parch\"])\ntest = test.drop(columns=[\"SibSp\",\"Parch\"])","74436c13":"plt.figure(figsize=(15,8))\nsns.countplot(data=train,\n              x='Family',\n              palette = \"dark\")\nplt.xlabel('\\nFamily')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","15b4659a":"dataset.Family = list(map(lambda x: 'Big' if x > 4 else('Single' if x == 1 else 'Medium'), dataset.Family))\ntrain.Family = list(map(lambda x: 'Big' if x > 4 else('Single' if x == 1 else 'Medium'), train.Family))\ntest.Family = list(map(lambda x: 'Big' if x > 4 else('Single' if x == 1 else 'Medium'), test.Family))","e19bff46":"plt.figure(figsize=(15,8))\nsns.countplot(data=train,\n              x='Family',\n              palette = \"dark\")\nplt.xlabel('\\nFamily')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","7cc74fb7":"sns.factorplot(x='Family', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nFamily')\nplt.ylabel('Survival Probability\\n')\nplt.show()","f092d9cf":"sns.factorplot(x='Sex', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nSex')\nplt.ylabel('Survival Probability\\n')\nplt.show()","80839b28":"dataset.Sex = dataset.Sex.map({'male': 0, 'female': 1})\ntrain.Sex = train.Sex.map({'male': 0, 'female': 1})\ntest.Sex = test.Sex.map({'male': 0, 'female': 1})","53d49dfb":"sns.factorplot(x='Pclass', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               kind='bar',\n               palette = \"dark\")\nplt.xlabel('\\nPclass')\nplt.ylabel('Survival Probability\\n')\nplt.show()","e459bcb6":"dataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())\ntrain[\"Fare\"] = train[\"Fare\"].fillna(dataset[\"Fare\"].median())\ntest[\"Fare\"] = test[\"Fare\"].fillna(dataset[\"Fare\"].median())","a3e6c7d7":"plt.figure(figsize=(20,8))\nsns.distplot(train['Fare'], color = \"steelblue\", hist_kws={\"rwidth\":0.80, 'alpha':1.0})\nplt.xticks(np.arange(0,600,10),rotation=45)\nplt.xlabel('\\nFare')\nplt.ylabel('Distribution\\n')\nplt.show()","0220c1cc":"plt.figure(figsize=(15,8))\nsns.violinplot(y='Fare',\n            data=dataset,\n            x='Survived',\n            palette = \"dark\")\nplt.xlabel('\\nSurvived')\nplt.ylabel('Fare\\n')\nplt.show()","2cae0cc7":"dataset[dataset.Fare.between(0,10)].shape","8808eefd":"dataset[dataset.Fare.between(11,25)].shape","7f7f4a04":"dataset[dataset.Fare.between(26,50)].shape","ecf7e596":"dataset[dataset.Fare > 51].shape","7b188515":"dataset.Fare = list(map(lambda x: 'Very Low' if x <= 10 \n         else('Low' if (x > 10 and x < 26) \n              else('Medium' if (x >= 26 and x <= 50) else 'High')), dataset.Fare))\n\ntrain.Fare = list(map(lambda x: 'Very Low' if x <= 10 \n         else('Low' if (x > 10 and x < 26) \n              else('Medium' if (x >= 26 and x <= 50) else 'High')), train.Fare))\n\ntest.Fare = list(map(lambda x: 'Very Low' if x <= 10 \n         else('Low' if (x > 10 and x < 26) \n              else('Medium' if (x >= 26 and x <= 50) else 'High')), test.Fare))","ef059c6d":"sns.factorplot(x='Fare', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nFare')\nplt.ylabel('Survival Probability\\n')\nplt.show()","e0c544c8":"plt.figure(figsize=(15,8))\nsns.countplot(x='Embarked', \n               data=train, \n               palette = \"dark\")\nplt.xlabel('\\nEmbarked')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","029e46ab":"sns.factorplot(x='Embarked', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nEmbarked')\nplt.ylabel('Survival Probability\\n')\nplt.show()","7f46616c":"dataset.Embarked = dataset.Embarked.fillna('S')\ntrain.Embarked = train.Embarked.fillna('S')\ntest.Embarked = test.Embarked.fillna('S')","12ee926c":"title = []\nfor i in dataset.Name.str.split(', '):\n    title.append(i[1].split('. ')[0])\ndataset[\"Title\"] = title\n\ntitle = []\nfor i in train.Name.str.split(', '):\n    title.append(i[1].split('. ')[0])\ntrain[\"Title\"] = title\n\ntitle = []\nfor i in test.Name.str.split(', '):\n    title.append(i[1].split('. ')[0])\ntest[\"Title\"] = title","e5c62875":"dataset = dataset.drop(columns=[\"Name\"])\ntrain = train.drop(columns=[\"Name\"])\ntest = test.drop(columns=[\"Name\"])","bb4d400c":"plt.figure(figsize=(20,8))\nsns.countplot(dataset.Title, palette = \"dark\")\nplt.xticks(rotation=45)\nplt.xlabel('\\nTitle')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","277c932c":"dataset.Title = list(map(lambda x: x if (x == 'Mr' or x == 'Mrs' or x == 'Miss')\n         else('Other'), dataset.Title))\n\ntrain.Title = list(map(lambda x: x if (x == 'Mr' or x == 'Mrs' or x == 'Miss')\n         else('Other'), train.Title))\n\ntest.Title = list(map(lambda x: x if (x == 'Mr' or x == 'Mrs' or x == 'Miss')\n         else 'Other', test.Title))","8a6d03d6":"plt.figure(figsize=(15,8))\nsns.countplot(dataset.Title, palette = \"dark\")\nplt.xlabel('\\nTitle')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","177a7c61":"sns.factorplot(x='Title', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nTitle')\nplt.ylabel('Survival Probability\\n')\nplt.show()","6f1ceab0":"cabin = []\nfor i in dataset.Cabin:\n    if type(i) != float:\n        cabin.append(i[0])\n    else:\n        cabin.append('Z')\ndataset.Cabin = cabin\n\ncabin = []\nfor i in train.Cabin:\n    if type(i) != float:\n        cabin.append(i[0])\n    else:\n        cabin.append('Z')\ntrain.Cabin = cabin\n\ncabin = []\nfor i in test.Cabin:\n    if type(i) != float:\n        cabin.append(i[0])\n    else:\n        cabin.append('Z')\ntest.Cabin = cabin","66df2c4d":"plt.figure(figsize=(15,8))\nsns.countplot(dataset.Cabin, palette = \"dark\")\nplt.xlabel('\\nCabin')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","8df40045":"sns.factorplot(x='Cabin', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nCabin')\nplt.ylabel('Survival Probability\\n')\nplt.show()","7373a362":"dataset.Cabin = dataset.Cabin.map({'B':'BCDE','C':'BCDE','D':'BCDE','E':'BCDE','A':'AFG','F':'AFG','G':'AFG','Z':'Z','T':'Z'})\ntrain.Cabin = train.Cabin.map({'B':'BCDE','C':'BCDE','D':'BCDE','E':'BCDE','A':'AFG','F':'AFG','G':'AFG','Z':'Z','T':'Z'})\ntest.Cabin = test.Cabin.map({'B':'BCDE','C':'BCDE','D':'BCDE','E':'BCDE','A':'AFG','F':'AFG','G':'AFG','Z':'Z','T':'Z'})","6d337a97":"plt.figure(figsize=(15,8))\nsns.countplot(dataset.Cabin, palette = \"dark\")\nplt.xlabel('\\nCabin')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","7048427b":"sns.factorplot(x='Cabin', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nCabin')\nplt.ylabel('Survival Probability\\n')\nplt.show()","e201458c":"tickets = []\nfor i in dataset.Ticket:\n    tickets.append(i.split(' ')[-1][0])\ndataset.Ticket = tickets\n\ntickets = []\nfor i in train.Ticket:\n    tickets.append(i.split(' ')[-1][0])\ntrain.Ticket = tickets\n\ntickets = []\nfor i in test.Ticket:\n    tickets.append(i.split(' ')[-1][0])\ntest.Ticket = tickets","c6e4dd7b":"plt.figure(figsize=(15,8))\nsns.countplot(dataset.Ticket.sort_values(), palette = \"dark\")\nplt.xlabel('\\nTicket')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","38c465d6":"sns.factorplot(x='Ticket', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\",\n               order=train.Ticket.sort_values().unique())\nplt.xlabel('\\nTicket')\nplt.ylabel('Survival Probability\\n')\nplt.show()","7796b189":"dataset.Ticket = list(map(lambda x: 4 if (x == 'L' or int(x) >= 4) else int(x), dataset.Ticket))\ntrain.Ticket = list(map(lambda x: 4 if (x == 'L' or int(x) >= 4) else int(x), train.Ticket))\ntest.Ticket = list(map(lambda x: 4 if (x == 'L' or int(x) >= 4) else int(x), test.Ticket))","001858f8":"plt.figure(figsize=(15,8))\nsns.countplot(dataset.Ticket.sort_values(), palette = \"dark\")\nplt.xlabel('\\nTicket')\nplt.ylabel('Number of Occurrences\\n')\nplt.show()","0bc0f9db":"sns.factorplot(x='Ticket', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\",\n               order=train.Ticket.sort_values().unique())\nplt.xlabel('\\nTicket')\nplt.ylabel('Survival Probability\\n')\nplt.show()","676349e9":"plt.figure(figsize=(15,8))\nsns.boxplot(x='Family', data=dataset,y='Age', palette = \"dark\")\nplt.xlabel('\\nFamily')\nplt.ylabel('Age\\n')\nplt.show()","55969bc5":"plt.figure(figsize=(15,8))\nsns.boxplot(x='Title',data=dataset,y='Age', palette = \"dark\")\nplt.xlabel('\\nTitle')\nplt.ylabel('Age\\n')\nplt.show()","891a63aa":"plt.figure(figsize=(15,8))\nsns.boxplot(x='Ticket',data=dataset,y='Age', palette = \"dark\")\nplt.xlabel('\\nTicket')\nplt.ylabel('Age\\n')\nplt.show()","195c1742":"plt.figure(figsize=(15,8))\nsns.boxplot(x='Sex',data=dataset,y='Age', palette = \"dark\")\nplt.xlabel('\\nSex')\nplt.ylabel('Age\\n')\nplt.show()","9e117f99":"plt.figure(figsize=(15,8))\nsns.boxplot(x='Fare',data=dataset,y='Age', palette = \"dark\")\nplt.xlabel('\\nFare')\nplt.ylabel('Age\\n')\nplt.show()","8fa6bab4":"plt.figure(figsize=(15,8))\nsns.boxplot(x='Embarked',data=dataset,y='Age', palette = \"dark\")\nplt.xlabel('\\nEmbarked')\nplt.ylabel('Age\\n')\nplt.show()","0eb5285f":"plt.figure(figsize=(15,8))\nsns.boxplot(x='Pclass',data=dataset,y='Age', palette = \"dark\")\nplt.xlabel('\\nPclass')\nplt.ylabel('Age\\n')\nplt.show()","f9ce5333":"plt.figure(figsize=(15,8))\nsns.boxplot(x='Cabin',data=dataset,y='Age', palette = \"dark\")\nplt.xlabel('\\nCabin')\nplt.ylabel('Age\\n')\nplt.show()","304e050c":"medians = pd.DataFrame(dataset.groupby(['Pclass', 'Title'])['Age'].median())\nmedians","424f8601":"ages = []\nfor i in dataset[dataset.Age.isnull() == True][[\"Pclass\",\"Title\"]].values:\n    ages.append(medians.ix[(i[0],  i[1])].Age)\n    \ndataset.Age[dataset.Age.isnull() == True] = ages","c11d5702":"index = dataset[dataset.Age.isnull() == True].index\ntrain_idx = index[index <= 890]\ntest_idx = index[index > 890]\n\ntrain['Age'][train.index.isin(train_idx)] = dataset['Age'][dataset.index.isin(train_idx)].values\ntest['Age'][test.index.isin(test_idx - 891)] = dataset['Age'][dataset.index.isin(test_idx)].values","f6272318":"ages = []\nfor i in dataset.Age:\n    if i < 18:\n        ages.append('less_18')\n    elif i >= 18 and i < 50:\n        ages.append('18_50')\n    else:\n        ages.append('greater_50')\n\ndataset.Age = ages\n\nages = []\nfor i in train.Age:\n    if i < 18:\n        ages.append('less_18')\n    elif i >= 18 and i < 50:\n        ages.append('18_50')\n    else:\n        ages.append('greater_50')\n\ntrain.Age = ages\n\nages = []\nfor i in test.Age:\n    if i < 18:\n        ages.append('less_18')\n    elif i >= 18 and i < 50:\n        ages.append('18_50')\n    else:\n        ages.append('greater_50')\n\ntest.Age = ages","96af7977":"sns.factorplot(x='Age', \n               size= 7, \n               aspect= 2,\n               data=train, \n               y ='Survived',\n               palette = \"dark\")\nplt.xlabel('\\nAge')\nplt.ylabel('Survival Probability\\n')\nplt.show()","33a8926b":"# PassengerId is not relevant and Sex (we don't want this variable to get dummied - see next cell)\nx_train = train.loc[:, ~train.columns.isin(['PassengerId', 'Survived', 'Sex'])]\ny_train = train.Survived\nx_test = test.loc[:, ~test.columns.isin(['PassengerId', 'Survived', 'Sex'])]","3b36c54e":"x_train = pd.get_dummies(x_train)\nx_train[\"Sex\"] = train.Sex # adding sex\nx_test = pd.get_dummies(x_test)\nx_test[\"Sex\"] = test.Sex # adding sex","2f096d02":"rf = RandomForestClassifier() \nrf.fit(x_train, y_train)","ba575a51":"feature_importances = pd.DataFrame(rf.feature_importances_,\n                                   index = x_train.columns,\n                                   columns=['importance']).sort_values('importance',ascending=False)\n\nplt.figure(figsize=(20,8))\nplt.xticks(rotation=45)\nplt.plot(feature_importances)\nplt.scatter(y=feature_importances.importance,x=feature_importances.index)\nplt.ylabel('Importance\\n')\nplt.grid()\nplt.show()","0edbc8fa":"ABC = AdaBoostClassifier(DecisionTreeClassifier())\n\nABC_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n                  \"base_estimator__splitter\" :   [\"best\", \"random\"],\n                  \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n                  \"n_estimators\" :[5,6,7,8,9,10,20],\n                  \"learning_rate\":  [0.001, 0.01, 0.1, 0.3]}\n\ngsABC = GridSearchCV(ABC, param_grid = ABC_param_grid, cv = 10, scoring = \"accuracy\", n_jobs = 6, verbose = 1)\n\ngsABC.fit(x_train,y_train)\n\nada_best = gsABC.best_estimator_\n\ngsABC.best_score_","d17e8b66":"ExtC = ExtraTreesClassifier()\n\nex_param_grid = {\"max_depth\": [3, 4, 5],\n                 \"max_features\": [3, 10, 15],\n                 \"min_samples_split\": [2, 3, 4],\n                 \"min_samples_leaf\": [1, 2],\n                 \"bootstrap\": [False,True],\n                 \"n_estimators\" :[100,200,300],\n                 \"criterion\": [\"gini\",\"entropy\"]}\n\ngsExtC = GridSearchCV(ExtC, param_grid = ex_param_grid, cv = 10, scoring = \"accuracy\", n_jobs = 6, verbose = 1)\n\ngsExtC.fit(x_train,y_train)\n\next_best = gsExtC.best_estimator_\n\ngsExtC.best_score_","4b5255e7":"rf_test = {\"max_depth\": [24,26],\n           \"max_features\": [6,8,10],\n           \"min_samples_split\": [3,4],\n           \"min_samples_leaf\": [3,4],\n           \"bootstrap\": [True],\n           \"n_estimators\" :[50,80],\n           \"criterion\": [\"gini\",\"entropy\"],\n           \"max_leaf_nodes\":[26,28],\n           \"min_impurity_decrease\":[0.0],\n           \"min_weight_fraction_leaf\":[0.0]}\n\ntuning = GridSearchCV(estimator = RandomForestClassifier(), param_grid = rf_test, scoring = 'accuracy', n_jobs = 6, cv = 10)\n\ntuning.fit(x_train,np.ravel(y_train))\n\nrf_best = tuning.best_estimator_\n\ntuning.best_score_","6b8a6c49":"GBM = GradientBoostingClassifier()\n\ngb_param_grid = {'loss' : [\"deviance\"],\n                 'n_estimators' : [450,460,500],\n                 'learning_rate': [0.1,0.11],\n                 'max_depth': [7,8],\n                 'min_samples_leaf': [30,40],\n                 'max_features': [0.1,0.4,0.6]}\n\ngsGBC = GridSearchCV(GBM, param_grid = gb_param_grid, cv = 10, scoring = \"accuracy\", n_jobs = 6, verbose = 1)\n\ngsGBC.fit(x_train,y_train)\n\ngbm_best = gsGBC.best_estimator_\n\ngsGBC.best_score_","4d12b623":"SVMC = SVC(probability=True)\n\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [0.027,0.029,0.03,0.031],\n                  'C': [45,55,76,77,78,85,95,100],\n                  'tol':[0.001,0.0008,0.0009,0.0011]}\n\ngsSVMC = GridSearchCV(SVMC, param_grid = svc_param_grid, cv = 10, scoring = \"accuracy\", n_jobs = 6, verbose = 1)\n\ngsSVMC.fit(x_train,y_train)\n\nsvm_best = gsSVMC.best_estimator_\n\ngsSVMC.best_score_","116dbaa6":"XGB = XGBClassifier()\n\nxgb_param_grid = {'learning_rate': [0.1,0.04,0.01], \n                  'max_depth': [5,6,7],\n                  'n_estimators': [350,400,450,2000], \n                  'gamma': [0,1,5,8],\n                  'subsample': [0.8,0.95,1.0]}\n\ngsXBC = GridSearchCV(XGB, param_grid = xgb_param_grid, cv = 10, scoring = \"accuracy\", n_jobs = 6, verbose = 1)\n\ngsXBC.fit(x_train,y_train)\n\nxgb_best = gsXBC.best_estimator_\n\ngsXBC.best_score_","3b392cc8":"corr = pd.concat([pd.Series(rf_best.predict(x_test), name=\"RF\"),\n                              pd.Series(ext_best.predict(x_test), name=\"EXT\"),\n                              pd.Series(svm_best.predict(x_test), name=\"SVC\"), \n                              pd.Series(gbm_best.predict(x_test), name=\"GBM\"),\n                              pd.Series(xgb_best.predict(x_test), name=\"XGB\"),\n                              pd.Series(ada_best.predict(x_test), name=\"ADA\")],axis=1)\n\nplt.figure(figsize=(18,18))\nsns.heatmap(corr.corr(),annot=True)\nplt.show()","7540f552":"voting = VotingClassifier(estimators=[('rfc', rf_best), \n                                      ('extc', ext_best),\n                                      ('svc', svm_best),\n                                      ('gbc',gbm_best),\n                                      ('xgbc',xgb_best),\n                                      ('ada',ada_best)])\n\nv_param_grid = {'voting':['soft',\n                          'hard']} # tuning voting parameter\n\ngsV = GridSearchCV(voting, \n                   param_grid = \n                   v_param_grid, \n                   cv = 10, \n                   scoring = \"accuracy\",\n                   n_jobs = 6, \n                   verbose = 1)\n\ngsV.fit(x_train,y_train)\n\nv_best = gsV.best_estimator_\n\ngsV.best_score_","0d35cefa":"pred = v_best.predict(x_test)\n\nsubmission = pd.DataFrame(test.PassengerId)\nsubmission[\"Survived\"] = pd.Series(pred)","fa28e7db":"submission.to_csv(\"submission.csv\",index=False)","e0804c19":"### Pclass","e4136753":"### Sex","398e7efc":"## Models Correlations","766284fc":"> With the boxplots results we can say that Pclass and Title are important to calculate the age.","2aefedac":"> Doing the same for Train and Test.","4ef87f0e":"> New countplot.","499cab95":"> Let's divide *Fare* in categories, first we need to create balanced category shapes.","8dbb2298":"> The more frequent numbers are 1, 2 and 3.","b4a07950":"### If you made this so far, let me know if you have questions, suggestions or critiques to improve the model.","697f0946":"# 3-Train Model","82c84707":"> It seems that the curve has a positive skewness (to the left).","1af526ae":"> Ignoring warnings that are not relevant for this project.","176c569f":"# 4-Voting Classifier","1f5ea10c":"## Project Phases:\n> \n* **0) Libraries and Data Loading**\n* **1) Exploratory Analysis and Data Cleaning**\n* **2) Feature Importance**\n* **3) Train Model**\n* **4) Voting**\n* **5) Submission**","0e01bcfc":"### Splitting variables into train and test sets","9fe0abe7":"### Age","de4ea811":"> Dropping **Name** column that we don't need anymore.","c68e6aa2":"> Another variable that shows a difference in survival probability.","90b676a2":"> By creating list of medians based on variables values it's possible to replace nan's safely.","a719f11e":"> The countplot shows that the more families grow, the fewer occurrences happen.","b1010f57":"### Adaboost","513a4cdf":"> It seems that people without cabines have less chance to survive, but standard deviations are large for some letters. We can group letters with similar behaviors.","188850c0":"> Let's separate the dataset indexes that have **Age** nan values.","6989c5c4":"> Many models need to receive numbers, not text. So, let's change **sex** from string to integer type.\n","b15c8eb5":"### XGBoost","0b37046f":"> Loading data.","ab616224":"> And now we have 4 categories, with different probabilities.","32772718":"> This clearly shows that a woman has higher probability to survive.","4b30cf48":"# 0-Libraries and Data Loading","1aaaf027":"### GBM","c0e07adf":"> It seems that '**Sex**' and '**Mr**' are the most important variables.","b0457947":"> We will need to see which features have more correlation with age, so we can safely replace nan values.","5e02aff5":"# 1-Exploratory Analysis and Data Cleaning","69ebf4f8":"> Lets see the most important features with the Random Forest Classifier.","fdbe4674":"> Small numbers of Parch have higher probability to survive.","fac08859":"# 2-Features Importance","7d624eb6":"> Titles frequency: we can see that the majority of the people has titles like 'Mr', 'Mrs' and 'Miss'. We can group the others into one category.","19d1e61c":"> Transforming each category of each column into another column with 1 or 0 value (get_dummies).","adf1b607":"> Since we have not so many nan values for this feature, then we can use the dataset median to fill them.","9722301f":"> we don't need these features anymore, since we created another one.","9801a98e":"### Name","923ab352":"> Repeating the factorplot for the Family.","52ecb57a":"> Here we can see that high fare people have higher probability to survive, and very low fare people have not.","88be8e2a":"### Ticket","a315ca27":"> New factorplot.","0c961375":"> Here we are going to try some models.","c0c7f670":"> **Age**, **Cabin**, **Fare** and **Embarked** have nan values. \nWe will need to analyze each feature individually to get better results.\n**Survived** has nan values just because of test data.","440974f7":"> This variable doesn't seem to have a lot of value except the first letter. \nSo let's extract it, if nan then let the letter be 'Z'.","89aa1ccf":"> Probably the people who payed more have higher probability to suvive, but there aren't many.","c4915cb8":"## Author: Caio Avelino\n* [LinkedIn](https:\/\/www.linkedin.com\/in\/caioavelino\/)\n* [Kaggle](https:\/\/www.kaggle.com\/avelinocaio)","06736b52":"### Embarked","d4bf6103":"### Cabin","57bb8a93":"> Small numbers of SibSp have higher probability to survive.","b744f45f":"> Finally, it's time to test the model in the test set and make the submission.","356dc540":"> We can use a Voting Classifier to ensemble all the models and to build a powerfull one.","5dac7cf0":"> This results shows that probably **Fare**, for example, has outliers, since its maximum value is so much higher than 75% of the data. Also the mean is very different from median (50%).","7f8ce31e":"> We are going to fill the two nan values with the most frequent category.","e009705e":"> Children and teenagers have more probability to survive.","18612a63":"> Since 1, 2 and 3 have more occurrences and the others have large standard deviations, we can group these into one category.","01b78c32":"### SibSp and Parch","d178be1b":"> Getting the title (Mr, Mrs, Miss and others) which is present in all rows and creating another column.","7e0d27a8":"### Random Forest","5e992bda":"> Since these features have similar behavior, then we can add them with each person being analyzed.","94b29c0b":"### SVC","ba423e84":"> Let's see the number of occurrences for each number.","ab9eb429":"> Counting them again, by group.","592c89be":"> This is a correlation between the models predictions. With the results we can see if its possible to combine them into a Voting Classifier.","68cfd0fa":"### ExtraTress","38280900":"> So we can calculate the median of the age grouped by these features.","2755fe0f":"> 'S' ir more frequent in the dataset.","fd781689":"### Fare","76d4b72e":"> This shows that first class has higher probability to survive, probably because of influence.","70d1d15b":"> This variable also doesn't seem to have a lot of value except the first number.","f0c737ef":"> Clearly the gentlemen are in danger.","4f169c86":"> Let's now see the probabilities for each category.","903bc6f1":"# 5-Submission","6dc004fb":"> Now we have 3 categories.","ad343b7c":"> Now that we have all ages, it's easy to group them into categories.","e1ae791b":"> Since there are 11 different categories for Family, lets group them in single, medium and big families.","3590f7fb":"> Let's see the dataset types, nan quantity for each column and describe them.","f704c102":"> So, lets divide the feature values into 3 categories, with similiar shape.","9aaa5fa3":"> **Fare** can be considered as continuous variable, so we can plot its distribution.","4bf181fb":"> Here we concat train and test into one, so we can analyze everything and replace nan values later based on all dataset."}}