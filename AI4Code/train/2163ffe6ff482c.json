{"cell_type":{"2da69cc1":"code","b677562a":"code","34bd4fad":"code","f7eba19a":"code","c0e3f975":"code","f49d544e":"code","fb5a1a22":"code","281a337c":"code","1243fa05":"code","3f804281":"code","cdfac20e":"code","50be3321":"code","aa4146fb":"code","b2e395ed":"code","3c0df9b0":"code","d18b56b4":"code","823fd1ec":"code","b3083bf3":"code","82e294e0":"code","e15929b0":"code","ef1b6090":"code","a15d02b0":"code","a88aa037":"code","25b5b5d3":"code","f19ab20c":"code","3af50c8e":"code","266e47b4":"code","c6803f71":"code","d4cb3253":"code","45991229":"code","9ca0809b":"code","cd79c404":"code","2137492b":"code","ab3f2e82":"code","ecdf20f7":"code","e6866cf1":"code","175cfa71":"code","3e11d3e8":"code","a4673739":"code","d254e922":"code","e25a5dc7":"code","f2991e4e":"markdown","f6b3d02b":"markdown","24b42729":"markdown","d065195e":"markdown"},"source":{"2da69cc1":"!nvidia-smi","b677562a":"!git clone https:\/\/github.com\/fizyr\/keras-retinanet.git","34bd4fad":"#!pip install --upgrade keras","f7eba19a":"%cd keras-retinanet\/\n\n!pip install .","c0e3f975":"!python setup.py build_ext --inplace","f49d544e":"!pip install gdown\n#!pip install tensorflow-gpu","fb5a1a22":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom pandas.plotting import register_matplotlib_converters\nfrom sklearn.model_selection import train_test_split\nimport urllib\nimport os\nimport csv\nimport cv2\nimport time\nfrom PIL import Image\n\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nregister_matplotlib_converters()\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nrcParams['figure.figsize'] = 22, 10\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)","281a337c":"#!gdown --id 1mTtB8GTWs74Yeqm0KMExGJZh1eDbzUlT --output indian_number_plates.json","1243fa05":"os.makedirs(\"snapshots\", exist_ok=True)","3f804281":"!gdown --id 1wPgOBoSks6bTIs9RzNvZf6HWROkciS8R --output snapshots\/resnet50_csv_10.h5","cdfac20e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","50be3321":"! ls \/kaggle\/input\/vottexp\/vott-csv-export","aa4146fb":"plates_df = pd.read_csv('\/kaggle\/input\/vottexp\/vott-csv-export\/ANPR-export.csv')","b2e395ed":"os.makedirs(\"vott-csv-export\", exist_ok=True)","3c0df9b0":"plates_df","d18b56b4":"plates_df['newImage'] = '\/kaggle\/input\/vottexp\/vott-csv-export\/'+plates_df.image\nplates_df['xmin']=plates_df['xmin'].apply(round)\nplates_df['ymin']=plates_df['ymin'].apply(round)\nplates_df['xmax']=plates_df['xmax'].apply(round)\nplates_df['ymax']=plates_df['ymax'].apply(round)\nplates_df.head()","823fd1ec":"'''\ndataset = dict()\ndataset[\"image_name\"] = list()\ndataset[\"x_min\"] = list()\ndataset[\"y_min\"] = list()\ndataset[\"x_max\"] = list()\ndataset[\"y_max\"] = list()\ndataset[\"class_name\"] = list()\n\ncounter = 0\nfor index, row in plates_df.iterrows():\n    img = urllib.request.urlopen(row[\"content\"])\n    img = Image.open(img)\n    img = img.convert('RGB')\n    img.save(f'number_plates\/licensed_car_{counter}.jpeg', \"JPEG\")\n    \n    dataset[\"image_name\"].append(f'number_plates\/licensed_car_{counter}.jpeg')\n    \n    data = row[\"annotation\"]\n  \n    width = data[0][\"imageWidth\"]\n    height = data[0][\"imageHeight\"]\n\n    dataset[\"x_min\"].append(int(round(data[0][\"points\"][0][\"x\"] * width)))\n    dataset[\"y_min\"].append(int(round(data[0][\"points\"][0][\"y\"] * height)))\n    dataset[\"x_max\"].append(int(round(data[0][\"points\"][1][\"x\"] * width)))\n    dataset[\"y_max\"].append(int(round(data[0][\"points\"][1][\"y\"] * height)))\n    dataset[\"class_name\"].append(\"license_plate\")\n    \n    counter += 1\nprint(\"Downloaded {} car images.\".format(counter))\n'''","b3083bf3":"df = plates_df.drop('image',axis=1)\ndf = df.iloc[:,[5,0,1,2,3,4]]\ndf.head()","82e294e0":"def show_image_objects(image_row):\n\n  img_path = image_row.newImage\n  box = [\n    image_row.xmin, image_row.ymin, image_row.xmax, image_row.ymax\n  ]\n\n  image = read_image_bgr(img_path)\n\n  draw = image.copy()\n  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n  draw_box(draw, box, color=(255, 255, 0))\n\n  plt.axis('off')\n  plt.imshow(draw)\n  plt.show()","e15929b0":"! pwd","ef1b6090":"show_image_objects(df.iloc[0])","a15d02b0":"show_image_objects(df.iloc[5])","a88aa037":"df","25b5b5d3":"train_df, test_df = train_test_split(\n  df, \n  test_size=0.2, \n  random_state=RANDOM_SEED\n)","f19ab20c":"ANNOTATIONS_FILE = 'annotations.csv'\nCLASSES_FILE = 'classes.csv'","3af50c8e":"train_df.to_csv(ANNOTATIONS_FILE, index=False, header=None)","266e47b4":"classes = set(['Lplate'])\n\nwith open(CLASSES_FILE, 'w') as f:\n  for i, line in enumerate(sorted(classes)):\n    f.write('{},{}\\n'.format(line,i))","c6803f71":"!head classes.csv","d4cb3253":"!head annotations.csv","45991229":"PRETRAINED_MODEL = '.\/snapshots\/_pretrained_model.h5'\n\nURL_MODEL = 'https:\/\/github.com\/fizyr\/keras-retinanet\/releases\/download\/0.5.1\/resnet50_coco_best_v2.1.0.h5'\nurllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n\nprint('Downloaded pretrained model to ' + PRETRAINED_MODEL)","9ca0809b":"!keras_retinanet\/bin\/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 4 --steps 10 --epochs 10 csv annotations.csv classes.csv","cd79c404":"!ls snapshots","2137492b":"model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\nprint(model_path)\n\nmodel = models.load_model(model_path, backbone_name='resnet50')\nmodel = models.convert_model(model)\n\nlabels_to_names = pd.read_csv(CLASSES_FILE, header=None).T.loc[0].to_dict()","ab3f2e82":"def predict(image):\n  image = preprocess_image(image.copy())\n  image, scale = resize_image(image)\n\n  boxes, scores, labels = model.predict_on_batch(\n    np.expand_dims(image, axis=0)\n  )\n\n  boxes \/= scale\n\n  return boxes, scores, labels","ecdf20f7":"THRES_SCORE = 0.1\n\ndef draw_detections(image, boxes, scores, labels):\n  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n    if score < THRES_SCORE:\n        break\n\n    color = label_color(label)\n\n    b = box.astype(int)\n    draw_box(image, b, color=color)\n\n    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n    draw_caption(image, b, caption)\n","e6866cf1":"def show_detected_objects(image_row):\n  img_path = image_row.newImage\n  \n  image = read_image_bgr(img_path)\n\n  boxes, scores, labels = predict(image)\n\n  draw = image.copy()\n  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n  true_box = [\n    image_row.xmin, image_row.ymin, image_row.xmax, image_row.ymax\n  ]\n  draw_box(draw, true_box, color=(255, 255, 0))\n\n  draw_detections(draw, boxes, scores, labels)\n\n  plt.axis('off')\n  plt.imshow(draw)\n  plt.show()","175cfa71":"test_df.head(n=10)","3e11d3e8":"show_detected_objects(test_df.iloc[0])","a4673739":"show_detected_objects(test_df.iloc[1])","d254e922":"show_detected_objects(test_df.iloc[2])","e25a5dc7":"test_df","f2991e4e":"# Predictions","f6b3d02b":"# Training","24b42729":"# Preprocessing","d065195e":"# Loading the trained model"}}