{"cell_type":{"27b6155e":"code","e7d1dc0d":"code","5ba63c56":"code","3a86cb4d":"code","4f5c66a9":"code","b121c049":"code","ed5a769e":"code","eecc8288":"code","25fa456b":"code","7e9db616":"code","5c24a11d":"code","09e8e7cc":"code","828225ec":"code","c0dbeefd":"code","2b4bfc11":"code","175b0cec":"code","3fd6da5e":"code","d11c6809":"code","3357e3d2":"code","a56b289a":"markdown","f1d4f730":"markdown","ba406a08":"markdown","4586453b":"markdown","7b10d7ad":"markdown","465d0eab":"markdown","99580b5b":"markdown","a8414ae5":"markdown","a3ac2987":"markdown","0065c79d":"markdown","2c0592be":"markdown","66ae1463":"markdown","d7b29a42":"markdown","d1cae4d9":"markdown","bf831682":"markdown","f4946a5b":"markdown","9bfdd70d":"markdown","ed6882bd":"markdown"},"source":{"27b6155e":"# import libraries\nimport numpy as np # linear algebra, matrix multiplications\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","e7d1dc0d":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","5ba63c56":"print(train.shape)\nntrain = train.shape[0]\n\nprint(test.shape)\nntest = test.shape[0]\n\ntrain.head(10)","3a86cb4d":"# check data type\nprint(train.dtypes[:5]) # all int64, otherwise do train = train.astype('int64')\nprint(train.dtypes[:5]) # all int64, otherwise do test = test.astype('int64')","4f5c66a9":"# array containing labels of each image\nytrain = train[\"label\"]\nprint(\"Shape of ytrain: \", ytrain.shape)\n\n# dataframe containing all pixels (the label column is dropped)\nxtrain = train.drop(\"label\", axis=1)\n\n# the images are in square form, so dim*dim = 784\nfrom math import sqrt\ndim = int(sqrt(xtrain.shape[1]))\nprint(\"The images are {}x{} squares.\".format(dim, dim))\n\nprint(\"Shape of xtrain: \", xtrain.shape)","b121c049":"ytrain.head(5)","ed5a769e":"import seaborn as sns\nsns.set(style='white', context='notebook', palette='deep')\n\n# plot how many images there are in each class\nsns.countplot(ytrain)\n\nprint(ytrain.shape)\nprint(type(ytrain))\n\n# array with each class and its number of images\nvals_class = ytrain.value_counts()\nprint(vals_class)\n\n# mean and std\ncls_mean = np.mean(vals_class)\ncls_std = np.std(vals_class,ddof=1)\n\nprint(\"The mean amount of elements per class is\", cls_mean)\nprint(\"The standard deviation in the element per class distribution is\", cls_std)\n\n# 68% - 95% - 99% rule, the 68% of the data should be cls_std away from the mean and so on\n# https:\/\/en.wikipedia.org\/wiki\/68%E2%80%9395%E2%80%9399.7_rule\nif cls_std > cls_mean * (0.6827 \/ 2):\n    print(\"The standard deviation is high\")\n    \n# if the data is skewed then we won't be able to use accurace as its results will be misleading and we may use F-beta score instead.","eecc8288":"def check_nan(df):\n    print(df.isnull().any().describe())\n    print(\"There are missing values\" if df.isnull().any().any() else \"There are no missing values\")\n\n    if df.isnull().any().any():\n        print(df.isnull().sum(axis=0))\n        \n    print()\n        \ncheck_nan(xtrain)\ncheck_nan(test)","25fa456b":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\n# convert train dataset to (num_images, img_rows, img_cols) format in order to plot it\nxtrain_vis = xtrain.values.reshape(ntrain, dim, dim)\n\n# subplot(2,3,3) = subplot(233)\n# a grid of 3x3 is created, then plots are inserted in some of these slots\nfor i in range(0,9): # how many imgs will show from the 3x3 grid\n    plt.subplot(330 + (i+1)) # open next subplot\n    plt.imshow(xtrain_vis[i], cmap=plt.get_cmap('gray'))\n    plt.title(ytrain[i]);","7e9db616":"# Normalize the data\nxtrain = xtrain \/ 255.0\ntest = test \/ 255.0","5c24a11d":"# reshape of image data to (nimg, img_rows, img_cols, 1)\ndef df_reshape(df):\n    print(\"Previous shape, pixels are in 1D vector:\", df.shape)\n    df = df.values.reshape(-1, dim, dim, 1) \n    # -1 means the dimension doesn't change, so 42000 in the case of xtrain and 28000 in the case of test\n    print(\"After reshape, pixels are a 28x28x1 3D matrix:\", df.shape)\n    return df\n\nxtrain = df_reshape(xtrain) # numpy.ndarray type\ntest = df_reshape(test) # numpy.ndarray type","09e8e7cc":"from keras.utils.np_utils import to_categorical\n\nprint(type(ytrain))\n# number of classes, in this case 10\nnclasses = ytrain.max() - ytrain.min() + 1\n\nprint(\"Shape of ytrain before: \", ytrain.shape) # (42000,)\n\nytrain = to_categorical(ytrain, num_classes = nclasses)\n\nprint(\"Shape of ytrain after: \", ytrain.shape) # (42000, 10), also numpy.ndarray type\nprint(type(ytrain))","828225ec":"from sklearn.model_selection import train_test_split\n\n# fix random seed for reproducibility\nseed = 2\nnp.random.seed(seed)\n\n# percentage of xtrain which will be xval\nsplit_pct = 0.1\n\n# Split the train and the validation set\nxtrain, xval, ytrain, yval = train_test_split(xtrain,\n                                              ytrain, \n                                              test_size=split_pct,\n                                              random_state=seed,\n                                              shuffle=True,\n                                              stratify=ytrain\n                                             )\n\nprint(xtrain.shape, ytrain.shape, xval.shape, yval.shape)","c0dbeefd":"from keras import backend as K\n\n# for the architecture\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPool2D, AvgPool2D\n\n# optimizer, data generator and learning rate reductor\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import LearningRateScheduler","2b4bfc11":"nets = 5\nmodel = [0] *nets\nfor i in range(nets):\n\n    model[i] = Sequential()\n\n    model[i].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(32, kernel_size = 3, activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Dropout(0.4))\n\n    model[i].add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Dropout(0.4))\n\n    model[i].add(Conv2D(128, kernel_size = 4, activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Flatten())\n    model[i].add(Dropout(0.4))\n    model[i].add(Dense(10, activation='softmax'))\n    model[i].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","175b0cec":"datagen = ImageDataGenerator(\n          featurewise_center=False,            # set input mean to 0 over the dataset\n          samplewise_center=False,             # set each sample mean to 0\n          featurewise_std_normalization=False, # divide inputs by std of the dataset\n          samplewise_std_normalization=False,  # divide each input by its std\n          zca_whitening=False,                 # apply ZCA whitening\n          rotation_range=10,                   # randomly rotate images in the range (degrees, 0 to 180)\n          zoom_range = 0.1,                    # Randomly zoom image \n          width_shift_range=0.1,               # randomly shift images horizontally (fraction of total width)\n          height_shift_range=0.1,              # randomly shift images vertically (fraction of total height)\n          horizontal_flip=False,               # randomly flip images\n          vertical_flip=False)                 # randomly flip images\n\ndatagen.fit(xtrain)","3fd6da5e":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n# train the network\nhistory = [0] * nets\nepochs = 45\nfor j in range(nets):\n    print(\"CNN \",j+1)\n    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(xtrain, ytrain, test_size = 0.1)\n    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n        epochs = epochs, steps_per_epoch = X_train2.shape[0]\/\/64,  \n        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=1)\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n        j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))","d11c6809":"fig, ax = plt.subplots(2,1)\nax[0].plot(history[4].history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history[4].history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\nax[0].grid(color='black', linestyle='-', linewidth=0.25)\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history[4].history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history[4].history['val_acc'], color='r',label=\"Validation accuracy\")\nax[1].grid(color='black', linestyle='-', linewidth=0.25)\nlegend = ax[1].legend(loc='best', shadow=True)","3357e3d2":"results = np.zeros( (test.shape[0],10) ) \nfor j in range(nets):\n    results = results + model[j].predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"predictions.csv\",index=False)","a56b289a":"## Fit the model","f1d4f730":"## **Ensemble Predictions and submit**","ba406a08":"## One hot encoding of label","4586453b":"## Split training and validation sets","7b10d7ad":"## Visualization","465d0eab":"## 2.6. Check null and missing values","99580b5b":"## CNN","a8414ae5":"## Credits\nThe code here was inspired by the following outstanding Kaggle kernels\n* [Chris Deotte - 25 Million Images! [0.99757] MNIST](https:\/\/www.kaggle.com\/cdeotte\/25-million-images-0-99757-mnist\/notebook)\n* [Ane - MNIST with CNN in Keras - Detailed explanation](https:\/\/www.kaggle.com\/anebzt\/mnist-with-cnn-in-keras-detailed-explanation)","a3ac2987":"# MNIST classification using ensemble of 5 CNNs","0065c79d":"## Reshape","2c0592be":"## Data Augmentation","66ae1463":"## Check shape, data type","d7b29a42":"## Plot loss and accuracy\n\nLoss and accuracy graph of one of the 5 CNN models","d1cae4d9":"## Normalization","bf831682":"## Load data","f4946a5b":"## Mean and std of the classes","9bfdd70d":"## Extract xtrain, ytrain","ed6882bd":"## Score 0.99742!!\n![image.png](attachment:image.png)"}}