{"cell_type":{"1933723f":"code","f63c1b08":"code","8b9d7e64":"code","26c97eae":"code","14131f85":"code","720b57f8":"code","7b8fa511":"code","3d5e74bc":"code","137a1bdd":"code","ca03bad7":"code","3aca00f0":"code","3e87ea65":"code","ff83effe":"code","0f3a3ce8":"code","0cce0cf8":"code","d8c467da":"code","5d7d4048":"code","b4b3098a":"code","8352625f":"code","cf070a17":"code","faa972f6":"code","a9989405":"code","86160555":"code","82f19d04":"code","d6d58723":"code","6bd8f4fd":"code","2052656f":"code","836289fe":"code","38e5df8b":"code","07e99432":"markdown","688772e8":"markdown","17f29048":"markdown","6ec832b7":"markdown","ed19d2fa":"markdown","00153341":"markdown","730dc4cb":"markdown","10cb3c5d":"markdown","7e413c98":"markdown","d21f3e93":"markdown","c001bc5c":"markdown","d0dcdcb9":"markdown"},"source":{"1933723f":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_palette('husl')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn import metrics\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('..\/input\/Iris.csv')","f63c1b08":" np.where(data.applymap(lambda x: x == ''))","8b9d7e64":"data.isnull().sum()\n","26c97eae":"data.head()","14131f85":"data.info()","720b57f8":"data.describe()","7b8fa511":"data['Species'].value_counts()","3d5e74bc":"tmp = data.drop('Id', axis=1)\ng = sns.pairplot(tmp, hue='Species', markers='+')\nplt.show()","137a1bdd":"g = sns.violinplot(y='Species', x='SepalLengthCm', data=data, inner='quartile')\nplt.show()\ng = sns.violinplot(y='Species', x='SepalWidthCm', data=data, inner='quartile')\nplt.show()\ng = sns.violinplot(y='Species', x='PetalLengthCm', data=data, inner='quartile')\nplt.show()\ng = sns.violinplot(y='Species', x='PetalWidthCm', data=data, inner='quartile')\nplt.show()","ca03bad7":"from sklearn.preprocessing import StandardScaler\n\n#data['SepalLengthCm'] = StandardScaler().fit_transform(data['SepalLengthCm'].values.reshape(-1, 1))\n#data['SepalWidthCm'] = StandardScaler().fit_transform(data['SepalLengthCm'].values.reshape(-1, 1))\n#data['PetalLengthCm'] = StandardScaler().fit_transform(data['SepalLengthCm'].values.reshape(-1, 1))\n#data['PetalWidthCm'] = StandardScaler().fit_transform(data['SepalLengthCm'].values.reshape(-1, 1))\n\nX = data.drop(['Id', 'Species'], axis=1)\n\nY = data['Species']\nprint(X.shape)\nprint(Y.shape)","3aca00f0":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=7)\n","3e87ea65":"# experimenting with different n values\nk_range = list(range(1,26))\nscores = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train, y_train)\n    y_pred = knn.predict(x_test)\n    scores.append(metrics.accuracy_score(y_test, y_pred))\n    \nplt.plot(k_range, scores)\nplt.xlabel('Value of k for KNN')\nplt.ylabel('Accuracy Score')\nplt.title('Accuracy Scores for Values of k of k-Nearest-Neighbors')\nplt.show()","ff83effe":"#from sklearn import svm\nfrom sklearn.ensemble import AdaBoostClassifier\n#from sklearn.linear_model import RANSACRegressor\nlogreg =AdaBoostClassifier(n_estimators=20, random_state=0)#svm.SVC() -0.87 , xgboost -0.87,LogisticRegression-0.9,AdaBoostClassifier-0.95\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nprint(metrics.accuracy_score(y_test, y_pred))","0f3a3ce8":"import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom keras.utils import to_categorical\nimport torch.nn.functional as F\n\n\nfeatures, labels = load_iris(return_X_y=True)\n","0cce0cf8":"class Model(nn.Module):\n    def __init__(self, input_dim):\n        super(Model, self).__init__()\n        self.layer1 = nn.Linear(input_dim,50)\n        self.layer2 = nn.Linear(50, 25)\n        self.layer3 = nn.Linear(25, 10)\n        self.layer4 = nn.Linear(10, 3)\n \n\n    def forward(self, x):\n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        x = F.relu(self.layer3(x))\n        x = F.softmax(self.layer4(x)) # To check with the loss function\n        return x\n    ","d8c467da":"model = Model(features.shape[1])\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nloss_fn = nn.CrossEntropyLoss()\nepochs = 100\n\ndef print_(loss):\n    print (\"The loss calculated: \", loss)","5d7d4048":"features_train,features_test, labels_train, labels_test = train_test_split(features, labels, random_state=42, shuffle=True)\n# Not using dataloader\nx_train, y_train = Variable(torch.from_numpy(features_train)).float(), Variable(torch.from_numpy(labels_train)).long()\nfor epoch in range(1, epochs+1):\n    print (\"Epoch #\",epoch)\n    y_pred = model(x_train)\n    loss = loss_fn(y_pred, y_train)\n    print_(loss.item())\n    \n    # Zero gradients\n    optimizer.zero_grad()\n    loss.backward() # Gradients\n    optimizer.step() # Update","b4b3098a":"x_test = Variable(torch.from_numpy(features_test)).float()\npred = model(x_test)\npred = pred.detach().numpy()\n","8352625f":"print (\"The accuracy is\", accuracy_score(labels_test, np.argmax(pred, axis=1)))\n","cf070a17":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation , Dropout\nfrom tensorflow.keras import regularizers\n\nmodel = Sequential()\nmodel.add(Dense(input_dim=features.shape[1], output_dim=30, activation='relu',activity_regularizer=regularizers.l2(10e-5)))\n#model.add(Dropout(0.2))\nmodel.add(Dense(input_dim=30, output_dim=10, activation='relu'))\nmodel.add(Dense(input_dim=10, output_dim=3,activation='softmax'))\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) #sgd,adam\n#model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\nmodel.summary()","faa972f6":"import keras\n\n#labels_onehot=to_categorical(labels, num_classes = 3)\n\n\nX_train,X_test, y_train,y_test = train_test_split(features,labels,test_size=0.1,random_state=0)\ny_train_onehot= pd.get_dummies(y_train).values\ny_test_onehot=pd.get_dummies(y_test).values\nhistory = model.fit(X_train, y_train_onehot, epochs=100,batch_size=15) # validation_split = 0.25#batch_size=4)\ny_pred = model.predict(X_test)\n\n","a9989405":"from matplotlib import pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","86160555":"from sklearn.metrics import classification_report, confusion_matrix\n\n\ny_test_class = np.argmax(y_test_onehot,axis=1) # convert encoded labels into classes: say [0, 0, 1] -->  [2] i.e Iris-virginica\ny_pred_class = np.argmax(y_pred,axis=1) # convert predicted labels into classes: say [0.00023, 0.923, 0.031] -->  [1] i.e. Iris-versicolor\n\n#Accuracy of the predicted values\nprint(classification_report(y_test_class, y_pred_class)) # Precision , Recall, F1-Score & Support\n\n","82f19d04":"from fastai import *\nfrom fastai.tabular import *\nfrom fastai.metrics import *","d6d58723":"df=data\ndf = df.sample(frac=1).reset_index(drop=True)\n\n\ndep_var = \"Species\"\ncont_names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\nprocs = [Normalize]\n\ndata = (TabularList.from_df(df,cont_names=cont_names,procs=procs)\n       .split_subsets(train_size=0.85,valid_size=0.15,seed=42)\n       .label_from_df(cols=dep_var)\n       .databunch())\n\nlearn = tabular_learner(data,layers=[100,50],metrics=accuracy)\n","6bd8f4fd":"learn.fit_one_cycle(50,1e-03)","2052656f":"learn.unfreeze()","836289fe":"learn.recorder.plot()","38e5df8b":"learn.recorder.plot_losses()","07e99432":"# Use sklearn","688772e8":"# Split train & test data (75%-25%)","17f29048":"# Pytorch","6ec832b7":"# KERAS","ed19d2fa":"![iris-species.png](attachment:iris-species.png)","00153341":"In this work I\u2019ll use iris dataset to compare FastAI , PyTorch & Keras Classification abilities .\nIris dataset contains 150 observations(50 observations of each species (setosa, versicolor, virginica)) with 4 features each (sepal length, sepal width, petal length, petal width)\nNo empty or NA values in dataset.\n","730dc4cb":"# Data Visualization\n- After graphing the features in a pair plot, it is clear that the relationship between pairs of features of a iris-setosa (in pink) is distinctly different from those of the other two species.\n- There is some overlap in the pairwise relationships of the other two species, iris-versicolor (brown) and iris-virginica (green).\n","10cb3c5d":"![1_83KNb93eWuSEt5MxqDow6Q.png](attachment:1_83KNb93eWuSEt5MxqDow6Q.png)","7e413c98":"# imports","d21f3e93":"# preprocessing data :\n\n1.Drop id column \n2.Tried to normalize features but it didn\u2019t improve accuracy results -note that all 4 features are at the same range {~0-10} \n","c001bc5c":"# FAST AI","d0dcdcb9":"# Get information on dataset"}}