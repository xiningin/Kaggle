{"cell_type":{"6e914d47":"code","3f283882":"code","a2e35aa5":"code","5b9668e5":"code","d61ec5c5":"code","5b4c5622":"code","b1cd2562":"code","9071fa3d":"code","4f41d7eb":"code","df75337b":"code","e31e66d2":"code","d31881fa":"code","34a7ac61":"code","ed9aeb7d":"code","8b1312f2":"code","6ab6f870":"code","5bde92a6":"code","556dc8b9":"code","40f09535":"code","342d5acd":"code","b3f8eb36":"code","df9525c3":"code","54da164c":"code","4ef1e07b":"markdown","9a2dff77":"markdown","5eb47d99":"markdown","c26f190c":"markdown","23987de9":"markdown","509214fe":"markdown","19312144":"markdown","f5aee643":"markdown","0d609573":"markdown","7b3845d9":"markdown"},"source":{"6e914d47":"%%capture\n# install tensorflow 2.0 alpha\n!pip install -q tensorflow-gpu==2.0.0-alpha0\n\n#install GapCV\n!pip install -q gapcv","3f283882":"import os\nimport time\nimport cv2\nimport gc\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import callbacks\n\nimport gapcv\nfrom gapcv.vision import Images\n\nfrom sklearn.utils import class_weight\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nprint('tensorflow version: ', tf.__version__)\nprint('keras version: ', tf.keras.__version__)\nprint('gapcv version: ', gapcv.__version__)\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nos.makedirs('model', exist_ok=True)\nprint(os.listdir('..\/input'))\nprint(os.listdir('.\/'))","a2e35aa5":"def elapsed(start):\n    \"\"\"\n    Returns elapsed time in hh:mm:ss format from start time in unix format\n    \"\"\"\n    elapsed = time.time()-start\n    return time.strftime(\"%H:%M:%S\", time.gmtime(elapsed))","5b9668e5":"def plot_sample(imgs_set, labels_set, img_size=(12,12), columns=4, rows=4, random=False):\n    \"\"\"\n    Plot a sample of images\n    \"\"\"\n    \n    fig=plt.figure(figsize=img_size)\n    \n    for i in range(1, columns*rows + 1):\n        \n        if random:\n            img_x = np.random.randint(0, len(imgs_set))\n        else:\n            img_x = i-1\n        \n        img = imgs_set[img_x]\n        ax = fig.add_subplot(rows, columns, i)\n        ax.set_title(str(labels_set[img_x]))\n        plt.axis('off')\n        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.show()","d61ec5c5":"data_set = 'wildlife'\ndata_set_folder = 'oregon_wildlife\/oregon_wildlife'\nminibatch_size = 32\n\nif not os.path.isfile('..\/input\/{}.h5'.format(data_set)):\n    images = Images(data_set, data_set_folder, config=['resize=(128,128)', 'store', 'stream'])\n\n# stream from h5 file\nimages = Images(config=['stream'], augment=['flip=horizontal', 'edge', 'zoom=0.3', 'denoise'])\nimages.load(data_set, '..\/input')\n\n# generator\nimages.split = 0.2\nX_test, Y_test = images.test\nimages.minibatch = minibatch_size\ngap_generator = images.minibatch\n\nY_int = [y.argmax() for y in Y_test]\nclass_weights = class_weight.compute_class_weight(\n    'balanced',\n    np.unique(Y_int),\n    Y_int\n)\n\ntotal_train_images = images.count - len(X_test)\nn_classes = len(images.classes)","5b4c5622":"print('content:', os.listdir(\".\/\"))\nprint('time to load data set:', images.elapsed)\nprint('number of images in data set:', images.count)\nprint('classes:', images.classes)\nprint('data type:', images.dtype)","b1cd2562":"!free -m","9071fa3d":"model = Sequential([\n    layers.Conv2D(filters=128, kernel_size=(4, 4), activation='tanh', input_shape=(128, 128, 3)),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Dropout(0.22018745727040784),\n    layers.Conv2D(filters=64, kernel_size=(4, 4), activation='relu'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Dropout(0.02990527559235584),\n    layers.Conv2D(filters=32, kernel_size=(4, 4), activation='tanh'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Dropout(0.0015225556862044631),\n    layers.Conv2D(filters=32, kernel_size=(4, 4), activation='tanh'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Dropout(0.1207251417283281),\n    layers.Flatten(),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.4724418446300173),\n    layers.Dense(5, activation='softmax')\n])","4f41d7eb":"model.summary()","df75337b":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","e31e66d2":"model_file = '.\/model\/model.h5'\n\n# # Clear any logs from previous runs\n# !rm -rf .\/logs\/fit\/*\n# !rm -rf .\/model\/*\n\n# log_dir=\".\/logs\/fit\/{}\".format(time.strftime(\"%Y%m%d-%H%M%S\", time.gmtime()))\n\n# get_ipython().system_raw(\n#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n#     .format(log_dir)\n# )","d31881fa":"## commented out if you want to check the localhost\n# !curl http:\/\/localhost:6006","34a7ac61":"# !wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip > \/dev\/null 2>&1\n# !unzip ngrok-stable-linux-amd64.zip > \/dev\/null 2>&1\n    \n# get_ipython().system_raw('.\/ngrok http 6006 &')","ed9aeb7d":"# !curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","8b1312f2":"# tensorboard = callbacks.TensorBoard(\n#     log_dir=log_dir,\n#     histogram_freq=1\n# )\n\nearlystopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5\n)\n\nmodel_checkpoint = callbacks.ModelCheckpoint(\n    model_file,\n    monitor='val_accuracy',\n    save_best_only=True,\n    save_weights_only=False,\n    mode='max'\n)","6ab6f870":"start = time.time()\n\nmodel.fit_generator(\n    generator=gap_generator,\n    validation_data=(X_test, Y_test),\n    epochs=50,\n    steps_per_epoch=int(total_train_images \/ minibatch_size),\n    initial_epoch=0,\n    verbose=1,\n    class_weight=class_weights,\n    callbacks=[\n        # tensorboard,\n        model_checkpoint\n    ]\n)\n\nprint('\\nElapsed time: {}'.format(elapsed(start)))","5bde92a6":"del model\nmodel = load_model(model_file)","556dc8b9":"scores = model.evaluate(X_test, Y_test, batch_size=32)\n\nfor score, metric_name in zip(scores, model.metrics_names):\n    print(\"{} : {}\".format(metric_name, score))","40f09535":"!curl https:\/\/d36tnp772eyphs.cloudfront.net\/blogs\/1\/2016\/11\/17268317326_2c1525b418_k.jpg > test_image.jpg","342d5acd":"labels = {val:key for key, val in images.classes.items()}\nlabels","b3f8eb36":"%pwd\n%ls","df9525c3":"image2 = Images('foo', ['test_image.jpg'], [0], config=['resize=(128,128)'])\nimg = image2._data[0]","54da164c":"prediction = model.predict_classes(img)\nprediction = labels[prediction[0]]\n\nplot_sample(img, ['predicted image: {}'.format(prediction)], img_size=(8, 8), columns=1, rows=1)","4ef1e07b":"## training","9a2dff77":"## get a random image and get a prediction!","5eb47d99":"## import libraries","c26f190c":"## Keras model definition","23987de9":"## callbacks","509214fe":"# OREGON WILDLIFE - TENSORFLOW 2.0 + KERAS + GAPCV","19312144":"## utils functions","f5aee643":"## install tensorboard and gapcv","0d609573":"## Tensorboard + Callbacks\n\nTo run tensorboard un-comment lines","7b3845d9":"## GapCV image preprocessing"}}