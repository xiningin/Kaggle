{"cell_type":{"35a99cdd":"code","a33ca702":"code","d92ccdee":"code","c88416a0":"code","ac87c8b3":"code","273d9dc4":"code","952e61d7":"code","d6d3c8ed":"code","2e7ec473":"code","cfb517e3":"code","5e856b9e":"code","3bc9cdc5":"code","249ed65f":"code","af9abaf6":"code","9a7aab67":"code","ea464990":"code","d2134e83":"code","1979928f":"code","52a2a58a":"code","3f81f521":"code","f0469127":"code","8be6de75":"code","cb9ea433":"code","34fcd494":"code","897852c8":"code","d4a075b7":"code","7676bd23":"code","9ac533a5":"code","0edbe325":"code","47ce82de":"code","7dce9e69":"code","1e06f4e3":"code","a9974513":"code","e516a7f1":"code","7867b108":"code","0447cb86":"code","cb96f054":"code","f71c8114":"code","94645ae3":"code","fb2bcd0e":"code","05160d33":"code","0966807f":"code","a7acb221":"code","89fc45ac":"code","56191051":"code","bd4f6a27":"code","4e08636e":"code","b1562982":"code","9e228fbc":"code","d4446d7c":"code","dd552119":"code","cef8c09b":"code","142826de":"code","da76859f":"code","37d291c6":"code","bf5b2934":"code","81b725c1":"code","4e8d42ce":"code","10d33b32":"code","9032f2d1":"code","d08a1698":"code","90ff1596":"code","ace05c0c":"code","37d7e4f5":"code","b3fdd19c":"code","9230f195":"code","96bf44b2":"code","9b5fa722":"code","cb457f42":"code","c71810d4":"code","059018d4":"code","2b6e9498":"code","1d93c6ee":"code","c1df0031":"code","ddf4a424":"code","fed0b85a":"code","bb0eddc3":"markdown","5def9313":"markdown","e0cef6cb":"markdown","84841cad":"markdown","7513d7dd":"markdown","d33fab62":"markdown","ea63cee3":"markdown","24e27ab3":"markdown","eb142fcc":"markdown","c10b49d5":"markdown","5e78348c":"markdown","14d66417":"markdown","23f8b372":"markdown","d5eef567":"markdown","edc63968":"markdown","afe9e0f2":"markdown","38ab7fd3":"markdown","792837bd":"markdown","4f16415e":"markdown","8502b98f":"markdown","59977833":"markdown","1a538d4c":"markdown","8bd0b12f":"markdown","a796ccae":"markdown","76097157":"markdown","5e602491":"markdown","0ff08989":"markdown","ba333696":"markdown","56a64448":"markdown","944e96ad":"markdown","3faef4b3":"markdown","b6e52403":"markdown","1d95d8f6":"markdown","67e54db6":"markdown","25da4c83":"markdown","14e59496":"markdown","da90f92b":"markdown","9eeed413":"markdown","e4660e1e":"markdown","fc36ddb2":"markdown","c76f9006":"markdown","7c4e7b3e":"markdown","e2d8d9d9":"markdown","65e06ee0":"markdown","500f8f52":"markdown","c08505c0":"markdown","b16bd1bd":"markdown","5d0278c4":"markdown","e8dd1f8c":"markdown"},"source":{"35a99cdd":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a33ca702":"#Load data\nfile_path = '\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx'\ndata = pd.read_excel(file_path)\ndata.head()","d92ccdee":"#Compute number of entries per patient\ndata.groupby(by = 'PATIENT_VISIT_IDENTIFIER').count()['ICU'].sort_values(ascending = False)","c88416a0":"#Define function to compilate the ICU admission data\ndef ICU_admission(data):\n    admission_data = data.groupby(\n        by = 'PATIENT_VISIT_IDENTIFIER', \n        as_index = False).max()[['PATIENT_VISIT_IDENTIFIER', 'ICU']]\n    \n    admission_time_data = data.groupby(by = ['PATIENT_VISIT_IDENTIFIER', 'ICU'],\n                                       as_index = False).first()[['PATIENT_VISIT_IDENTIFIER', 'ICU', 'WINDOW']]\n    \n    admission_data = admission_data.join(\n        other = admission_time_data[admission_time_data['ICU'] == 1].set_index('PATIENT_VISIT_IDENTIFIER'),\n        on = 'PATIENT_VISIT_IDENTIFIER',\n        how = 'left',\n        rsuffix = '_R')\n    \n    return admission_data.drop(columns = 'ICU_R')","ac87c8b3":"#Get admission compiled data\nadmission_data = ICU_admission(data)\nprint(admission_data)","273d9dc4":"#Define function to rearrange the data\nadmission_window_order = {\n    '0-2': 1,\n    '2-4': 2,''\n    '4-6': 3,\n    '6-12': 4,\n    'ABOVE_12': 5}\n\ndef to_timeseries_format(data, position_dict):\n    \n    #Order dictionary\n    position_dict = sorted(position_dict.items())\n    \n    #Split data\n    df_list = []\n    for position in position_dict:\n        value, pos = position\n        suffix = '_' + str(pos)\n        df_list.append(data[data['WINDOW'] == value].add_suffix(suffix).reset_index(drop = True))\n        \n    #Reassemble data\n    output_data = pd.concat(df_list, axis = 1)\n    return output_data\n","952e61d7":"#Rearrange data into time series format\ndata = to_timeseries_format(data, admission_window_order)\ndata = data.drop(columns = ['PATIENT_VISIT_IDENTIFIER_2', 'PATIENT_VISIT_IDENTIFIER_3',\n                            'PATIENT_VISIT_IDENTIFIER_4', 'PATIENT_VISIT_IDENTIFIER_5'])\ndata.head()","d6d3c8ed":"#Define function to remove redudant columns\ndef remove_redudant_cols(data, cols, range_begin, range_end):\n    for n in range(range_begin, range_end+1):\n        rm_cols = [x + '_'  + str(n) for x in cols]\n        data = data.drop(columns = rm_cols)\n        \n    return data","2e7ec473":"#Remove redudant columns\nredudant_cols = ['AGE_ABOVE65', 'AGE_PERCENTIL', 'GENDER', 'HTN', 'WINDOW']\ndata = remove_redudant_cols(data, redudant_cols, 2, 5).drop(columns = 'WINDOW_1')","cfb517e3":"#Identify features with missing values as a percentage of the total number of records\nnull_values = data.isnull().sum()\nnull_values = 100 * null_values[null_values > 0] \/ len(data)\n\nnull_values.sort_values(ascending = False)","5e856b9e":"over_50pct_nulls = null_values[null_values > 50]\nprint(over_50pct_nulls.sort_index())","3bc9cdc5":"#Identifying which feature groups are mostly composed of missing values\nover_50pct_nulls = over_50pct_nulls.reset_index(level = 0).rename(columns = {'index': 'Feature', 0: 'Null_Pct'})\nover_50pct_nulls['Feature_Group'] = [x[:-2] for x in over_50pct_nulls['Feature']]\n\nnull_aggregate = over_50pct_nulls.groupby(by = 'Feature_Group').agg({'Null_Pct': ['count', 'min', 'max']})\nprint(null_aggregate)","249ed65f":"null_aggregate.columns = ['_'.join(col).strip() for col in null_aggregate.columns.values]\nnull_aggregate.query('Null_Pct_count == 4 & Null_Pct_min > 50')","af9abaf6":"#Remove columns with overrepresentation of null values\nover_50pct_nulls = null_aggregate.query('Null_Pct_count == 4 & Null_Pct_min > 50').index\n\nfor n in range(1,6):\n    remove_cols = [x + '_' + str(n) for x in over_50pct_nulls]\n    data = data.drop(columns = remove_cols)\n    \ndata.head()","9a7aab67":"null_values = data.isnull().sum()\nnull_values = 100 * null_values[null_values > 0] \/ len(data)\n\nnull_values.sort_index()","ea464990":"#Split columns into time variant or patient constant\ncol_groups = np.unique([x[:-2] for x in data.columns.values], return_counts = True)\ntime_cols = [col_groups[0][x] for x in range(len(col_groups[0])) if col_groups[1][x] > 1]\nconstant_cols = [x + '_1' for x in col_groups[0] if x not in time_cols]","d2134e83":"#Define function to fill the missing values on the time variant features\ndef fill_missing_values(data, time_group, const_group):\n    \n    group_df = [data[const_group]]\n    for group in time_group:\n        col_names = [group + '_' + str(x) for x in range(1, 6)]\n        group_df.append(data[col_names].fillna(method = 'backfill', axis = 1).reset_index(drop = True))\n    \n    return pd.concat(group_df, axis = 1)","1979928f":"#Fill missing values\ndata = fill_missing_values(data, time_cols, constant_cols)\n\nnull_values = data.isnull().sum()\nnull_values[null_values > 0].sort_values(ascending = False)","52a2a58a":"#Check which rows still have missing values\nnull_values = data.isnull().sum(axis = 1)\nnull_rows = null_values[null_values > 0].index.values\n\nprint(null_rows)","3f81f521":"#Remove remaining missing values\ndata = data.drop(index = null_rows)","f0469127":"data.head()","8be6de75":"#Define function to remove data measured after ICU admission\ndef remove_ICU_data(data):\n    \n    df_list = []\n    for n in range(1, 6):\n        cols = [x for x in data.columns.values if int(x[-1]) == n]\n        ICU_col = 'ICU_' + str(n)\n        df_list.append(data[data[ICU_col] == 0][cols].drop(columns = ICU_col))\n        \n    return pd.concat(df_list, axis = 1)","cb9ea433":"#Remove data after ICU admission\ndata = remove_ICU_data(data)","34fcd494":"data","897852c8":"#Join data together\ndata = data.join(other = admission_data.set_index('PATIENT_VISIT_IDENTIFIER').drop(columns = 'WINDOW'),\n                 on = 'PATIENT_VISIT_IDENTIFIER_1',\n                 how = 'inner')\n\ndata.head()","d4a075b7":"#Identify patient-constant features\ncol_groups = [x[:-2] for x in data.drop(columns = ['PATIENT_VISIT_IDENTIFIER_1', 'ICU']).columns.values]\ncol_groups = np.unique(col_groups , return_counts = True)\n\npatient_constant_cols = [col_groups[0][x] for x in range(len(col_groups[0])) if col_groups[1][x] == 1]\npatient_constant_cols","7676bd23":"#AGE_ABOVE65 and AGE_PERCENTIL\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 4))\nsns.countplot(data['AGE_ABOVE65_1'], ax = axis[0])\nsns.countplot(data['AGE_PERCENTIL_1'], ax = axis[1])\nplt.show(fig)","9ac533a5":"#GENDER and HTN\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 4))\nsns.countplot(data['GENDER_1'], ax = axis[0])\nsns.countplot(data['HTN_1'], ax = axis[1])\nplt.show(fig)","0edbe325":"#Define function for a normalized staked bars plot\ndef normalized_stacked_bars(data, col, target):\n\n    bottom = [0 for x in data[col].unique()]\n    for cls in data[target].unique():\n        x_vals, y_vals = np.unique(data[data[target] == cls][col], return_counts = True)\n        x_vals = [str(x) for x in x_vals] \n        y_vals = [x \/ y for x, y in zip(y_vals, np.unique(data[col], return_counts = True)[1])]\n        \n        plt.bar(x_vals, y_vals, bottom = bottom, color = np.random.rand(1,3))\n        bottom = [x + y for x, y in zip(bottom, y_vals)]\n    \n    plt.legend(np.unique(data[target]), title = target)\n    plt.title(col)\n    \n    return plt.show()","47ce82de":"#AGE_ABOVE65\nnormalized_stacked_bars(data, 'AGE_ABOVE65_1', 'ICU')","7dce9e69":"#AGE_PERCENTIL\nnormalized_stacked_bars(data, 'AGE_PERCENTIL_1', 'ICU')","1e06f4e3":"#GENDER\nnormalized_stacked_bars(data, 'GENDER_1', 'ICU')","a9974513":"#HTN\nnormalized_stacked_bars(data, 'HTN_1', 'ICU')","e516a7f1":"#Identifying time variant features and groups of features\npatient_constant_cols = [x + '_1' for x in patient_constant_cols]\n\ntime_variant_cols = [x for x in data.columns.values if x not in patient_constant_cols]\ntime_variant_cols.remove('PATIENT_VISIT_IDENTIFIER_1')\ntime_variant_cols.remove('ICU')\n\ntime_variant_groups = np.unique([x[:-2] for x in time_variant_cols])\nprint(time_variant_groups)","7867b108":"#Identify the largers clusters\nnot_cluster_friendly = ['DISEASE GROUPING 1', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3', \n                        'DISEASE GROUPING 4', 'DISEASE GROUPING 5', 'DISEASE GROUPING 6', \n                        'IMMUNOCOMPROMISED', 'OTHER']\n\nclusters = np.unique([x.split('_')[-1] for x in time_variant_groups if x not in not_cluster_friendly])\nprint(clusters)","0447cb86":"#Define function to compile all values from a feature group\ndef extract_values_from_group(data, group_name):\n    group_cols = [x for x in data.columns.values if x[:-2] == group_name]\n    return data[group_cols].values.reshape(-1)","cb96f054":"#Define function to plot all feature groups from a cluster\ndef plot_by_cluster(data, col_groups, cluster_name):\n    #Identify groups to be ploted\n    groups = [x for x in col_groups if x[-len(cluster_name):] == cluster_name]\n    \n    #Compute dimensions for subplots\n    ncols = 2\n    nrows = int(len(groups) \/ 2) if len(groups) % 2 == 0 else np.floor(len(groups) \/ 2) + 1\n\n    #Plot groups\n    fig, axis = plt.subplots(nrows = nrows, ncols = ncols, figsize = (15, 3*nrows))\n    for i, group in enumerate(groups):\n        row = int(i \/ 2)\n        col = 0 if i%2 == 0 else 1\n        if data[group + '_1'].dtype == np.int64:\n            sns.countplot(extract_values_from_group(data, group), ax = axis[row, col]).set_title(group)\n        else:\n            sns.distplot(extract_values_from_group(data, group), ax = axis[row, col]).set_title(group)\n    \n    fig.tight_layout()\n    return plt.show() ","f71c8114":"#DIFF\nplot_by_cluster(data, time_variant_groups, 'DIFF')","94645ae3":"#REL\nplot_by_cluster(data, time_variant_groups, 'DIFF_REL')","fb2bcd0e":"#Identify remaining groups for plotting\nreduced_time_variant_groups = \\\n[x for x in time_variant_groups if ('DIFF' not in x and x not in not_cluster_friendly)]\n\nnew_clusters = np.unique(['_'.join(x.split('_')[:-1]) for x in reduced_time_variant_groups])\nnew_clusters","05160d33":"#Redefine function to plot all feature groups from a cluster\ndef plot_by_cluster(data, col_groups, cluster_name):\n    #Identify groups to be ploted\n    groups = [x for x in col_groups if x[:len(cluster_name)] == cluster_name]\n    \n    #Compute dimensions for subplots\n    ncols = 2\n    nrows = int(len(groups) \/ 2) if len(groups) % 2 == 0 else np.floor(len(groups) \/ 2) + 1\n\n    #Plot groups\n    fig, axis = plt.subplots(nrows = nrows, ncols = ncols, figsize = (15, 3*nrows))\n    for i, group in enumerate(groups):\n        row = int(i \/ 2)\n        col = 0 if i%2 == 0 else 1\n        if data[group + '_1'].dtype == np.int64:\n            sns.countplot(extract_values_from_group(data, group), ax = axis[row, col]).set_title(group)\n        else:\n            sns.distplot(extract_values_from_group(data, group), ax = axis[row, col]).set_title(group)\n    \n    fig.tight_layout()\n    return plt.show()","0966807f":"#BLOODPRESSURE_DIASTOLIC'\nplot_by_cluster(data, reduced_time_variant_groups, 'BLOODPRESSURE_DIASTOLIC')","a7acb221":"#BLOODPRESSURE_SISTOLIC\nplot_by_cluster(data, reduced_time_variant_groups, 'BLOODPRESSURE_SISTOLIC')","89fc45ac":"#OXYGEN_SATURATION\nplot_by_cluster(data, reduced_time_variant_groups, 'OXYGEN_SATURATION')","56191051":"#HEART_RATE\nplot_by_cluster(data, reduced_time_variant_groups, 'HEART_RATE')","bd4f6a27":"#RESPIRATORY_RATE\nplot_by_cluster(data, reduced_time_variant_groups, 'RESPIRATORY_RATE')","4e08636e":"#TEMPERATURE\nplot_by_cluster(data, reduced_time_variant_groups, 'TEMPERATURE')","b1562982":"#Define function to plot feature group as series of boxplots\ndef plot_time_series(data, group, axs):\n    \n    x_vals = []\n    y_vals = []\n    for n in range(1,6):\n        x_vals.extend([n for x in range(len(data))])\n        y_vals.extend(data[group + '_' + str(n)])\n        \n    return sns.boxplot(x = x_vals, y = y_vals, ax = axs)","9e228fbc":"time_variant_groups","d4446d7c":"#Define function to plot the time series in clusters of feature groups\ndef plot_time_series_cluster(data, cluster_name):\n    groups = [x for x in time_variant_groups if x[:len(cluster_name)] == cluster_name]\n    \n    ncols = 2\n    nrows = int(len(groups) \/ 2) if len(groups) % 2 == 0 else np.floor(len(groups) \/ 2) + 1\n\n    #Plot groups\n    fig, axis = plt.subplots(nrows = nrows, ncols = ncols, figsize = (15, 3*nrows))\n    for i, group in enumerate(groups):\n        row = int(i \/ 2)\n        col = 0 if i%2 == 0 else 1\n        plot_time_series(data, group, axis[row, col]).set_title(group)\n    \n    fig.tight_layout()\n    return plt.show()","dd552119":"#BLOODPRESSURE_DIASTOLIC\nplot_time_series_cluster(data, 'BLOODPRESSURE_DIASTOLIC')","cef8c09b":"#BLOODPRESSURE_SISTOLIC\nplot_time_series_cluster(data, 'BLOODPRESSURE_SISTOLIC')","142826de":"#HEART_RATE\nplot_time_series_cluster(data, 'HEART_RATE')","da76859f":"#OXYGEN_SATURATION\nplot_time_series_cluster(data, 'OXYGEN_SATURATION')","37d291c6":"#RESPIRATORY_RATE\nplot_time_series_cluster(data, 'RESPIRATORY_RATE')","bf5b2934":"#TEMPERATURE\nplot_time_series_cluster(data, 'TEMPERATURE')","81b725c1":"not_cluster_friendly","4e8d42ce":"#Redefine the plot_time_series function to use violinplots instead of boxplots\ndef violinplot_time_series(data, group, axs):\n    \n    x_vals = []\n    y_vals = []\n    for n in range(1,6):\n        x_vals.extend([n for x in range(len(data))])\n        y_vals.extend(data[group + '_' + str(n)])\n        \n    return sns.violinplot(x = x_vals, y = y_vals, ax = axs)","10d33b32":"#IMMUNOCOMPROMISED\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (12,4))\nsns.countplot(extract_values_from_group(data, 'IMMUNOCOMPROMISED'), ax = axis[0])\nviolinplot_time_series(data, 'IMMUNOCOMPROMISED', axs = axis[1])","9032f2d1":"#OTHER\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (12,4))\nsns.countplot(extract_values_from_group(data, 'OTHER'), ax = axis[0])\nviolinplot_time_series(data, 'OTHER', axs = axis[1])","d08a1698":"#DISEASE GROUPING 1\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (12,4))\nsns.countplot(extract_values_from_group(data, 'DISEASE GROUPING 1'), ax = axis[0])\nviolinplot_time_series(data, 'DISEASE GROUPING 1', axs = axis[1])","90ff1596":"#DISEASE GROUPING 2\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (12,4))\nsns.countplot(extract_values_from_group(data, 'DISEASE GROUPING 2'), ax = axis[0])\nviolinplot_time_series(data, 'DISEASE GROUPING 2', axs = axis[1])","ace05c0c":"#DISEASE GROUPING 3\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (12,4))\nsns.countplot(extract_values_from_group(data, 'DISEASE GROUPING 3'), ax = axis[0])\nviolinplot_time_series(data, 'DISEASE GROUPING 3', axs = axis[1])","37d7e4f5":"#DISEASE GROUPING 4\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (12,4))\nsns.countplot(extract_values_from_group(data, 'DISEASE GROUPING 4'), ax = axis[0])\nviolinplot_time_series(data, 'DISEASE GROUPING 1', axs = axis[1])","b3fdd19c":"#DISEASE GROUPING 5\nfig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (12,4))\nsns.countplot(extract_values_from_group(data, 'DISEASE GROUPING 1'), ax = axis[0])\nviolinplot_time_series(data, 'DISEASE GROUPING 1', axs = axis[1])","9230f195":"#Define function to compute the percentage of records in which the feature value changes over time\ndef find_feature_value_change(data, group):\n    group_cols = [x for x in data.columns if x[:len(group)] == group]\n    summarized_data = data.groupby(by = 'PATIENT_VISIT_IDENTIFIER_1').max()[group_cols]\n    data_change = summarized_data.max(axis = 1) - summarized_data.min(axis = 1)\n    \n    return len(data_change[data_change != 0]) \/ len(data)","96bf44b2":"#Compute feature time variance\ntime_change_df = pd.DataFrame(data = [100* find_feature_value_change(data, x) for x in not_cluster_friendly],\n                              index = not_cluster_friendly,\n                              columns = ['% of records with value change'])\n\ntime_change_df.sort_values(by = '% of records with value change', ascending = False)","9b5fa722":"#Define function to show grafically the correlation between ICU admission and feature change over time\ndef feature_target_plot(data, group, target):\n    group_cols = [x for x in data.columns if x[:len(group)] == group]\n    summarized_data = data.groupby(by = 'PATIENT_VISIT_IDENTIFIER_1').max()[group_cols]\n    data_change = summarized_data.max(axis = 1) - summarized_data.min(axis = 1)\n    \n    change_rows = data_change[data_change != 0].index\n    no_change_rows = data_change[data_change == 0].index\n    \n    bot = [0, 0]\n    for value in data[target].unique():\n        y_vals = [len(data[data[target] == value].filter(change_rows, axis = 'index')) \/ len(change_rows),\n                  len(data[data[target] == value].filter(no_change_rows, axis = 'index')) \/ len(no_change_rows)]\n        x_vals = ['Change', 'No Change']\n        \n        plt.bar(x_vals, y_vals, bottom = bot, color = np.random.rand(1,3))\n        bot = [x + y for x, y in zip(bot, y_vals)]\n    \n    plt.legend(data[target].unique(), title = target)\n    \n    return plt.show()","cb457f42":"#OTHER\nfeature_target_plot(data, 'OTHER', 'ICU')","c71810d4":"#IMMUNOCOMPROMISED\nfeature_target_plot(data, 'IMMUNOCOMPROMISED', 'ICU')","059018d4":"#DISEASE GROUPING 1\nfeature_target_plot(data, 'DISEASE GROUPING 1', 'ICU')","2b6e9498":"#DISEASE GROUPING 2\nfeature_target_plot(data, 'DISEASE GROUPING 2', 'ICU')","1d93c6ee":"#DISEASE GROUPING 3\nfeature_target_plot(data, 'DISEASE GROUPING 3', 'ICU')","c1df0031":"#DISEASE GROUPING 4\nfeature_target_plot(data, 'DISEASE GROUPING 4', 'ICU')","ddf4a424":"#DISEASE GROUPING 5\nfeature_target_plot(data, 'DISEASE GROUPING 5', 'ICU')","fed0b85a":"#Save processed dataset\ndata.to_csv('first_step_output_data.csv')","bb0eddc3":"Let's now have another look at our data.","5def9313":"# 4. Data Exploration","e0cef6cb":"Now, we are going to rearrange the patient information into a more time series like format.","84841cad":"The *BLOODPRESSURE_SISTOLIC* features present a similar beahavior to their *BLOODPRESSURE_DIASTOLIC* counterparts. The one notable difference is the *BLOODPRESSURE_SISTOLIC_MIN*, which present a gentle but clear trend downward beggining on window 3.","7513d7dd":"# 3. Data Cleaning and Processing","d33fab62":"Now let's take a look at the features that change over time. For that, we are going to take two approaches. First, we are going to investigate each measurement regardless of when it was taken. Following, we are going to look at theses features as in a time series.","ea63cee3":"We want to explore the dataset, but before, there's a small matter we need to resolve. As we trying to create a model to predict whether or not a patient will require ICU care. Therefore, as instructed by the dataset providers, the data gathered after the ICU admission should not be taken into consideration. Since we are not going to use this data to model ICU admission, it does not make sense to explore this data. Let's them proceed to removing this data.","24e27ab3":"## 3.2. Remove Data Where *ICU = 1*","eb142fcc":"## 3.1. Missing Values","c10b49d5":"Lets have a look at our data set again, to see how it looks like after all this preprocessing.","5e78348c":"These results show a total of 180 feature groups have more nulls than actual values. Our first approach will simply be to remove the related features.","14d66417":"This data is set up in a very specific way.  For each patient, as defined in the PATIENT_VISIT_IDENTIFIER feature, the entries represent different stages of the patient since its admission into the hospital. Lets take a look at how many entries are there for each patient.","23f8b372":"A very interesting pattern seems to arise from the missing value percentage computed data. It appears there are missing values on the early stages of admission to the hospital which gradually reduce to nearly zero at the last measurement window. This probably due to the fact that, not all measurements are taken early in the admission.\n\nThis leads us to the first approach we are going to take on filling the missing values. Basically, the assumption is measurements start to be taken when the patient has just started to present some change on his or hers clinical condition. Therefore, we assume the previous null values could be filled with the first non null value for a given patient.","d5eef567":"For the *DIFF* cluster, we can see the feature groups behave in a very similar way. All of the present most values close to *-1*. This is not good indication in terms of whether the related features can provide meaningfull information to our predictive model. But we are not going to draw conclusions right now.","edc63968":"Our hypothesis is turned out to be true, for the most part. Aside from *OTHER*, all the other features present nearly no change over the time windows. Still, these occurrences, however rare, could be strongly correlated to the target. Before we make any decision, it is important to test this possibility.","afe9e0f2":"We now have some very differents plots from the previous feature groups. When it comes to *OXYGEN_SATURATION*, the data distribution is much more narrow. Additionally, even though the *window 1* measures present a large amount of outliers, it does not seem to exist a window related pattern.","38ab7fd3":"### 4.2.3. The Remainig Features","792837bd":"After applying our approach for the missing values, there are still a single null for most of the features. This is likely a single record with nearly no information. Let's confirm that.","4f16415e":"All theses features have some thing in common. For instance, they are all binary and very poorly distributed. Additionally, their time window distribution does not seem to change very much, specially if we assume most changes in windows 4 and 5 are due to the increasing number of missing values.\n\nThis all leads us to believe these are not actually time variant attributes. If that is the case, we have to remove the redudant features, so they don't get in the way of what we are trying to accomplish. Let's find out if this suspision is true.","8502b98f":"## 3.3. Consolidate Data","59977833":"Here, we are are going to try and simplify our analysis. There are a lot of features, and even if we adopt the group approach, there is still a large number of groups for us to look at then individually. One way out of this comes from the realization the groups can be further categorized.\n\nThere are a couple of ways we can cluster the feature groups together. Our choice we'll be the type of measurement. For instance, feature groups like *BLOODPRESSURE_DIASTOLIC_MAX* and *HEART_RATE_MAX* are part of the same *MAX* cluster.\n\nNotice, some of the features can not be categorized like this. We are going to look at them in a more approppriate form.","1a538d4c":"In this section, we are basically going to do two things:\n\n1. Handle missing values;\n2. Reduce our ","8bd0b12f":"For *AGE_ABOVE65*, *GENDER* and *HTN* we see there is clearly some relationship between the features and the target. For *AGE_PERCENTIL*, we can see an indication of strong correlation.","a796ccae":"# 1. Import Libraries","76097157":"The observation of the *DIFF_REL* cluster reveals all similar behavior to the previous cluster. This is not surprising, since, as the name suggests, they are just a relative version of the previously shown feature groups.\n\nFor the next features, we are goinf to cluster them in a different form, by the health aspect being measured. This is being done because, unlike for the *DIFF* features, we do not expect different measurements to behave very much alike. ","5e602491":"# 2. Data Loading and Preliminary Processing","0ff08989":"For the *BLOODPRESSURE_DIASTOLIC*, we have the *DIFF* feature groups present the most variation over time. As for the other features, they mostly behave the same from windows 1 through 4, present some relevant change on the last time step. Another interesting aspect are the outliers. For the last four features, they are more frequent in the first two windows.","ba333696":"Now, after all this work, we are going to, yet again, look at our dataset. But, this time, we are going to plot some graphs and try to see how these features behave isolated and with each other.","56a64448":"For these features, all but *HTN* are fairly well distributed. Let's not take a look at how they relate directly to the target.","944e96ad":"## 4.2. Time-Variant Features","3faef4b3":"As we can see, while some features present almost no missing values, some are nearly entirely made up of *nulls*. However, we should not be quick to discard this data, since there is a time element to these attributes.","b6e52403":"Our dataset was reduced from the previous 1131 to 251 columns. There surely a lot of information we are discarding in this process. However, we should not worry. We can always come back at look at this features again.\n\nFocusing on the remaining attributes, let's take a look at how to handle their missing values.","1d95d8f6":"Some very interesting facts arise from these simple plots. The two most revealing are:\n\n* For the *DESEASE GROUPING* 1 through 4 features, whenever the value changes over time, the patient does not go to the ICU.\n* The *OTHER* attribute, the one with the most change over time, presents a relevant change in ICU admission likelyhood.\n\nThe main conclusion here is we should not discard the time aspect for these features. Additionally we found out the the change over time for these attributes could be use as new attribute for our model. ","67e54db6":"# 5. Conclusion","25da4c83":"We have completed the first step in our task to create a predictive model for the ICU admission. As this notebook is already too long, we are going to stop right here and start a new one in which our focus will be feature engineering and selection, as well as actually creating the classification model. Both notebooks will be linked, so anyone trying to have the whole picture won't be lost. \n\nWell, this is it for now. Please comment and let me know how can I improve this notebook.","14e59496":"There are couple of features we have investigated yet. We are going to analyze from the two previous perspectives at the same time. But first, let's remember who they are.","da90f92b":"As we suspected, this new way of clustering the feature groups makes a lot more sense. We can clearly see the measurements for each cluster behave in a very similar way, at least when we are not looking at the time component. This leads us to believe something we could have guessed before: the measurements for a single feature cluster are likely correlated, possibly in a strong fashion. We now have a much better sense of how our data behaves. It is then time to look at how the time component affects our analysis.","9eeed413":"This confirms our suspicion. Since we are talking about a single records, let's just discard it.","e4660e1e":"### 4.2.1. First Approach: Investigate Entire Feature Groups","fc36ddb2":"## 4.1. Patient-Constant Features","c76f9006":"At the beggining of this notebook, one of the thing we did was compile the admission data to indetify whether each patient eventually required ICU treatment. Since our data is already on the format we intend to use, now it's a good time to put it all together.","7c4e7b3e":"We are on step closer to finishing the data preprocessing. In order to reduce our dataset, we are now going to remove the redudant variables. We are talking about features that will not change for a given patient, such as *AGE_PERCENTIL* and *GENDER*.","e2d8d9d9":"### 4.2.2. Second Approach: Chronological","65e06ee0":"As we can see, all patients in this dataset have the same amount of entries. However, as instructed, the data in which the patients have already been moved to the ICU are not to be used. But we are not discarding this data yet. What we are going to do first is to extract two very important information from the the data as it is:\n\n* Which patients are admitted to the UCI;\n* At which point these patients are admitted to the UCI.","500f8f52":"The first thing we do load our data and take a first peek at it.","c08505c0":"For the *RESPIRATORY_RATE* attributes, the distributions are once again very narrow. As for the outliers, they are mostly on the windows 1, 2 e 3 features.","b16bd1bd":"Finally, the *TEMPERATURE* features present seem to behave like the the *BLOODPRESSURE* features, preseting a similar behavior until window 3. After that, it is possible to note some relevant change in the data distribution.\n\nWrapping up this sub-section, we should highlight this exploration will not always gives us mindblowing insights. This is ok. The important thing here is the time we ate spending getting to know the dataset. And, of course, there's plenty more exploratory analysis we can perform.","5d0278c4":"Two interesting things happened here. The first, the reduction on the number of columns, is very easy to explain. In our function, the *ICU* attributes are removed, result in precisely 5 fewer columns. The reduced amount of records on the other hand, indicates some patients were directly addmited to the ICU. Their data is of no use for the task we are trying to acomplish, so it was removed.","e8dd1f8c":"The *HEART_RATE* features, once again behaves in similar way to the previos feature groups. As this pattern seems to common for our data, it is interesting to dig further and understand what it means.\n\nFrom the point of view of the problem at hand, the best case scenario happens if we could predict whether or not a patient will have to be admitted to the ICU using only its *window 1* measurements. This would mean the medical team would be better prepared and hospital resources usage could become optimal. We then would really like if the *window 1* features behaved very well and presented the smallest amount of outliers. However, this is not the case.\n\nAnother important observation is not to take the data from the last windows \"too seriously\". I am not insinuating the data is wrong. The real issue here is simply the amount of information we have. Remember we are discarding all data obtained after the ICU admission. In the last window, for instance, only around 25% of the data is not missing. This does not necessarily means we are discarding the features, but we have to be carefull when drawing conclusions from datasets this small."}}