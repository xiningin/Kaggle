{"cell_type":{"aabf8898":"code","de8b75d2":"code","9024335e":"code","791acd81":"code","0db1fb96":"code","8a23c7c1":"code","db9afc7b":"code","2fd821cb":"code","a8fdaacb":"code","0011a72d":"code","61e7bbf4":"code","890e79a1":"code","d8d664bf":"code","f22853f0":"code","e2a428db":"code","38dbfde3":"code","6d350a90":"code","ad115cf0":"code","379c175f":"code","898b1405":"code","65a6e36e":"code","56e8bdd5":"code","c8e4ebb5":"code","48a80e79":"code","5106ce74":"code","87ae6c65":"code","694b64be":"code","33aeb6a2":"code","eeb1264e":"markdown","24b3680f":"markdown","9a20498a":"markdown","6be1f045":"markdown","4d402861":"markdown","2e1e4e06":"markdown","c26bff75":"markdown","3260a6c3":"markdown","8dffa360":"markdown","a3e33b11":"markdown","7d423774":"markdown","c0dda777":"markdown","fb01d909":"markdown","fdf0c04e":"markdown","a0e0c5b1":"markdown"},"source":{"aabf8898":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sklearn\nimport os\nprint(os.listdir(\"..\/input\"))","de8b75d2":"train = pd.read_csv('..\/input\/train.csv')","9024335e":"train.head()","791acd81":"train.shape","0db1fb96":"X_train = (train.iloc[:,1:].values)\ny_train = (train.iloc[:,0].values)","8a23c7c1":"X_train = X_train.reshape(X_train.shape[0], 28, 28)","db9afc7b":"for i in range(0, 9):\n    plt.subplot(330+(i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.axis('off')\n    plt.title(y_train[i]);","2fd821cb":"X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_train.shape","a8fdaacb":"def Normalize(X): \n    X=X \/ 255.0\n    mean_px = X.mean()\n    std_px = X.std()\n    return (X-mean_px)\/std_px.astype(np.float32)","0011a72d":"X_train = Normalize(X_train)","61e7bbf4":"# from keras.utils.np_utils import to_categorical\n# y_train= to_categorical(y_train)\n# num_classes = y_train.shape[1]\n# num_classes","890e79a1":"def history_plot(history):\n    plt.figure(figsize=[15,7])\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    \n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","d8d664bf":"import tensorflow as tf","f22853f0":"annmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\nannmodel.compile(optimizer='adam',\n              #loss='categorical_crossentropy',#you need to convert to one-hot label\n              loss='sparse_categorical_crossentropy', # no need of one-hot label\n              metrics=['accuracy'])\n\nhistory = annmodel.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2)\nhistory_plot(history)","e2a428db":"cnnmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\ncnnmodel.summary()","38dbfde3":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('acc')>0.995):\n          print(\"\\nReached 99.5% accuracy so cancelling training!\")\n          self.model.stop_training = True\n\ncallbacks = myCallback()","6d350a90":"cnnmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory =cnnmodel.fit(X_train, y_train, batch_size=32, epochs=10,validation_split=0.2,callbacks=[callbacks])\nhistory_plot(history)","ad115cf0":"from tensorflow.keras import models\n\ndef convLayerPlot(model,layer_number,CONV_number,image_source,image_numbers):\n    f, axarr = plt.subplots(len(image_numbers),layer_number)\n    layer_outputs = [layer.output for layer in model.layers]\n    activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n\n    for x in range(0,layer_number):\n        for i,n in enumerate(image_numbers):\n            f1 = activation_model.predict(image_source[n].reshape(1, 28, 28, 1))[x]\n            axarr[i,x].imshow(f1[0, : , :, CONV_number], cmap='inferno')\n            axarr[i,x].grid(False)","379c175f":"convLayerPlot(cnnmodel,2,0,X_train,[1,2,8])","898b1405":"testpic=np.array(X_train[7])\nplt.imshow(testpic.reshape(28, 28), cmap=plt.get_cmap('gray'))","65a6e36e":"testpic[0:4,0:6,0]=2\nplt.imshow(testpic.reshape(28, 28), cmap=plt.get_cmap('gray'))","56e8bdd5":"cnnmodel.predict(testpic.reshape(1,28,28,1))[0][3]","c8e4ebb5":"testpic=np.array(X_train[7])\ntestpic[10:15,5:10,0]=2\nplt.imshow(testpic.reshape(28, 28), cmap=plt.get_cmap('gray'))","48a80e79":"cnnmodel.predict(testpic.reshape(1,28,28,1))[0][3]","5106ce74":"import random","87ae6c65":"def affectingarea(testpic,maxsize,model,alpha=0.3):\n    r,c=len(testpic),len(testpic[0])\n    pred=model.predict(testpic.reshape(1,r,c,1))\n    predclass=np.argmax(pred)\n    origpred=pred[0][predclass]\n    minv,maxv = np.amin(testpic),np.amax(testpic)\n    #print(minv,maxv)\n    importance=np.zeros((r,c))\n    for size in range(1,maxsize):\n        for i in range(0,r+1-size):\n            for j in range(0,r+1-size):\n                #area=[i+x,j+y for x in range(size) for y in range(size)]\n                temppic=np.array(testpic)\n                temppic[i:i+size,j:j+size,0] = random.uniform(minv,maxv)\n                predict=model.predict(temppic.reshape(1,r,c,1))[0][predclass]\n                importance[i:i+size,j:j+size]+=(1-predict)\/(size**2)  #normalized by num of pixels \n    plt.imshow(importance,cmap=plt.get_cmap('Reds'))\n    plt.imshow(testpic.reshape(r,c), cmap=plt.get_cmap('gray'),alpha=alpha)\n    return importance","694b64be":"numberlist=[1,2,16,7,3,8,21,18,10,11]\nplt.figure(figsize=(12,6))\nfor i,n in enumerate(numberlist):\n    plt.subplot(2,5,i+1)\n    imp=affectingarea(X_train[n],10,cnnmodel)\n    #plt.imshow(X_train[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n    plt.axis('off')\n    plt.title(y_train[n]);","33aeb6a2":"plt.figure(figsize=(12,6))\nfor i,n in enumerate(numberlist):\n    plt.subplot(2,5,i+1)\n    imp=affectingarea(X_train[n],10,annmodel)\n    #plt.imshow(X_train[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n    plt.axis('off')\n    plt.title(y_train[n]);","eeb1264e":"### it seems more area will impact the prediction, which means the model may not be as robust as cnn model","24b3680f":"### try on ANN as well ","9a20498a":"# USE TensorFlow","6be1f045":"# ANN","4d402861":"### if some of the pixels are changed, how the prediction will be impacted?","2e1e4e06":"### As in the image, the red area will imapct the classification most.\n### some of them makes sense to me, such as for 3 and 8, they will be confused to each other if the red area is not clear.\n### 4 and 5  can be confused into 9 if the red area isn't clear\n\n## In some sense it shows the model works well as the place that confuse the model will also confuse human","c26bff75":"# normalize ","3260a6c3":"### the prediction dropped as expected\n\n### let's check which of the pixels will impact the prediction most.\n### a k*k box will iterate over the hole picture, the pixels inside the box will be feed into the model\n### and make prediction.  The reduce of the prediction confidence will be added to a blank picture.\n\n### the final result will be the overlay of imapct area picture and the original image.","8dffa360":"# Visualize data\n\n### each row is 28*28=784 pixels + 1 label in the begining","a3e33b11":"# one-hot y","7d423774":"# CNN","c0dda777":"## visualize each conv layer","fb01d909":"## try on 0-9s","fdf0c04e":"# check pixel importance","a0e0c5b1":"## the prediction is still very good"}}