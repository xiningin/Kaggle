{"cell_type":{"5866b226":"code","b5b02425":"code","ee49258b":"code","b49adad4":"code","ed71a95b":"code","da35c1ca":"code","608b8795":"code","25485430":"code","41212e1a":"code","574c0853":"code","dcf348b2":"code","05348611":"code","1d96348a":"code","4f41035b":"code","63ca5187":"code","aabedc8b":"code","0345ba95":"code","11454d2c":"code","5bd13e4f":"code","f5e25ea3":"code","3edfc374":"code","0fb2f3a1":"code","5e12d05a":"code","030926a5":"code","548c9406":"code","169f2ce1":"code","61820d17":"code","8db14301":"code","4ac1ad6e":"code","4df37100":"code","e28e876b":"code","4e83b03e":"code","7eaf0b1e":"code","1b654f00":"code","a6c17ce5":"code","4d71ea84":"code","50fd0243":"code","be5ab1a0":"code","6d9c1875":"markdown","132fe049":"markdown","f9658234":"markdown","15d650c3":"markdown","37de003c":"markdown","35a9a27a":"markdown","eff43cfd":"markdown","9e90d3cb":"markdown","6356cd23":"markdown","6da298a5":"markdown","ccb72276":"markdown","18a334f0":"markdown","9d83e386":"markdown","2e6fd50e":"markdown","d05a2823":"markdown","5eb290bf":"markdown","96488b81":"markdown","8c82cfe3":"markdown","198df292":"markdown","350b5556":"markdown"},"source":{"5866b226":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style = 'whitegrid')\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","b5b02425":"data_train = pd.read_csv('..\/input\/av-healthcare-analytics-ii\/healthcare\/train_data.csv')\ndata_test = pd.read_csv('..\/input\/av-healthcare-analytics-ii\/healthcare\/test_data.csv')\ndata_train_dict = pd.read_csv('..\/input\/av-healthcare-analytics-ii\/healthcare\/train_data_dictionary.csv')","ee49258b":"data_train_dict","b49adad4":"train = data_train.copy()\ntrain.head()","ed71a95b":"test = data_test.copy()\ntest.head()","da35c1ca":"print(data_train.info())\nprint('\\n')\nprint(data_test.info())","608b8795":"from collections import Counter\nCounter(train['Stay'].tolist())","25485430":"# Get lower and upper bound value on column \"Age\"\ntrain['Lower_Bound_Age'] = train['Age'].str.split('-', expand = True)[0].astype(int)\ntrain['Upper_Bound_Age'] = train['Age'].str.split('-', expand = True)[1].astype(int)\n\ntest['Lower_Bound_Age'] = test['Age'].str.split('-', expand = True)[0].astype(int)\ntest['Upper_Bound_Age'] = test['Age'].str.split('-', expand = True)[1].astype(int)\n","41212e1a":"# split data (data train) into numerical dan categorical data\nnum_data = train[['Available Extra Rooms in Hospital', 'Bed Grade', 'Visitors with Patient'\n             , 'Admission_Deposit', 'Lower_Bound_Age', 'Upper_Bound_Age']]\n\ncat_data = train[['Hospital_code', 'Hospital_type_code', 'City_Code_Hospital', 'Hospital_region_code'\n             , 'Department', 'Ward_Type', 'Ward_Facility_Code', 'City_Code_Patient', 'Type of Admission'\n             , 'Severity of Illness', 'Stay']]\n\nprint(num_data.info())\nprint('\\n')\nprint(cat_data.info())","574c0853":"fig, ax =plt.subplots(3,2, figsize=(14,10))\nfig.tight_layout(pad=5.0)\n\nfor ax, n in zip(ax.flatten(), num_data.columns.tolist()):\n    sns.distplot(ax=ax, a=num_data[n].dropna(), label=\"Skewness : %.2f\"%(num_data[n].skew()))\n    ax.set_title(n, fontsize = 14)\n    ax.legend(loc = 'best')","dcf348b2":"# Heatmap data numeric\nheatmapdata = train[['Stay', 'Available Extra Rooms in Hospital', 'Bed Grade', 'Visitors with Patient'\n             , 'Admission_Deposit', 'Lower_Bound_Age', 'Upper_Bound_Age', 'City_Code_Patient']]\n\ncormat = heatmapdata.corr()\nfig, ax = plt.subplots(figsize = (8,4))\nsns.heatmap(data = cormat)\nplt.show()","05348611":"fig, ax = plt.subplots(cat_data.shape[1],1, figsize = (14, 32))\nfig.tight_layout(pad = 5.0)\n\nfor ax, n in zip(ax.flatten(), cat_data.columns.tolist()):\n    x_axis = cat_data[n].fillna('NaN').value_counts().index\n    y_axis = cat_data[n].fillna('NaN').value_counts()\n    sns.barplot(ax = ax, x = x_axis, y = y_axis, order =  x_axis)\n    ax.set_title(n, fontsize = 14)\n    \nplt.show()","1d96348a":"# Manipulate columns position to easly do preprocessing data\n\n# Move columns 'Stay' to first position\ntrain = train[['Stay'] + [col for col in train.columns.tolist() if col != 'Stay']]\n# Create columns 'Stay' so that same shape with data train\ntest.insert(0, 'Stay', 'NaN')","4f41035b":"print('Total null value on data train (%) :\\n', np.round(train.isnull().sum() * 100 \/ len(train), 4))\nprint('\\n')\nprint('Total null value on data test (%) :\\n', np.round(test.isnull().sum() * 100 \/ len(test), 4))","63ca5187":"# drop missing value on columns 'Bed Grade' and 'City_Code_Patient'\ntrain.dropna(subset = ['Bed Grade', 'City_Code_Patient'], inplace = True)\n\ntest['Bed Grade'].fillna(train['Bed Grade'].mode()[0], inplace = True)\ntest['City_Code_Patient'].fillna(train['City_Code_Patient'].mode()[0], inplace = True)","aabedc8b":"print('Total null value on data train (%) :\\n', np.round(train.isnull().sum() * 100 \/ len(train), 4))\nprint('\\n')\nprint('Total null value on data test (%) :\\n', np.round(test.isnull().sum() * 100 \/ len(test), 4))","0345ba95":"fig, ax = plt.subplots(2,2, figsize = (16,8))\nsns.boxplot(ax = ax[0, 0], x = train['Available Extra Rooms in Hospital'])\nsns.boxplot(ax = ax[0, 1], x = train['Visitors with Patient'])\nsns.boxplot(ax = ax[1, 0], x = train['Admission_Deposit'])\nfig.delaxes(ax[1,1])\n\nplt.show()\n","11454d2c":"# Remove outliers from data train\n# https:\/\/towardsdatascience.com\/ways-to-detect-and-remove-the-outliers-404d16608dba\n\nq1 = train['Available Extra Rooms in Hospital'].quantile(0.25)\nq3 = train['Available Extra Rooms in Hospital'].quantile(0.75)\niqr = q3-q1\ntrain = train[~((train['Available Extra Rooms in Hospital'] < (q1 - 1.5 * iqr)) | (train['Available Extra Rooms in Hospital'] > (q3+1.5*iqr)))]\n\nq1=train['Visitors with Patient'].quantile(0.25)\nq3 = train['Visitors with Patient'].quantile(0.75)\niqr = q3-q1\ntrain = train[~ ((train['Visitors with Patient'] < q1 - 1.5 * iqr) | (train['Visitors with Patient'] > (q3 + 1.5 * iqr)))]\n\nq1=train['Admission_Deposit'].quantile(0.25)\nq3 = train['Admission_Deposit'].quantile(0.75)\niqr = q3-q1\ntrain = train[~ ((train['Admission_Deposit'] < q1 - 1.5 * iqr) | (train['Admission_Deposit'] > (q3 + 1.5 * iqr)))]","5bd13e4f":"# Do log transform on data train\ntrain['Available Extra Rooms in Hospital'] = np.log(train['Available Extra Rooms in Hospital'] + 1)\ntrain['Visitors with Patient'] = np.log(train['Visitors with Patient'] + 1)\n# Remove outliers after log transform on data train\ntrain = train[train['Available Extra Rooms in Hospital'] > 0]\ntrain = train[train['Visitors with Patient'] > 0]\n\n# Do the same log transform on data test ( for make the same scale value with data train) \ntest['Available Extra Rooms in Hospital'] = np.log(test['Available Extra Rooms in Hospital'] + 1)\ntest['Visitors with Patient'] = np.log(test['Visitors with Patient'] + 1)","f5e25ea3":"fig, ax = plt.subplots(2,2, figsize = (16,8))\nsns.boxplot(ax = ax[0, 0], x = train['Available Extra Rooms in Hospital'])\nsns.boxplot(ax = ax[0, 1], x = train['Visitors with Patient'])\nsns.boxplot(ax = ax[1, 0], x = train['Admission_Deposit'])\nfig.delaxes(ax[1,1])\nplt.show()\n","3edfc374":"fig, ax =plt.subplots(2,2, figsize=(16,8))\nfig.tight_layout(pad=5.0)\n\nsns.distplot(ax=ax[0, 0], a=train['Available Extra Rooms in Hospital']\n             , label=\"Skewness : %.2f\"%(train['Available Extra Rooms in Hospital'].skew()))\nax[0, 0].set_title('Available Extra Rooms in Hospital', fontsize = 14)\nax[0, 0].legend(loc = 'best')\n\nsns.distplot(ax=ax[0, 1], a=train['Visitors with Patient']\n             , label=\"Skewness : %.2f\"%(train['Visitors with Patient'].skew()))\nax[0, 1].set_title('Visitors with Patient', fontsize = 14)\nax[0, 1].legend(loc = 'best')\n\nsns.distplot(ax=ax[1, 0], a=train['Admission_Deposit']\n             , label=\"Skewness : %.2f\"%(train['Admission_Deposit'].skew()))\nax[1, 0].set_title('Admission_Deposit', fontsize = 14)\nax[1, 0].legend(loc = 'best')\n\nfig.delaxes(ax[1,1])\n\nplt.show()","0fb2f3a1":"admission_encode = {'Trauma' : 1, 'Urgent' : 2, 'Emergency' : 3}\ntrain['Type of Admission'] = train['Type of Admission'].map(admission_encode)\ntest['Type of Admission'] = test['Type of Admission'].map(admission_encode)\n\n\nseverity_encode = {'Minor' : 1, 'Moderate' : 2, 'Extreme' : 3}\ntrain['Severity of Illness'] = train['Severity of Illness'].map(severity_encode)\ntest['Severity of Illness'] = test['Severity of Illness'].map(severity_encode)\n\nstay_encode = {'0-10' : 1, '11-20' : 2, '21-30' : 3, '31-40' : 4, '41-50' : 5, '51-60' : 6, '61-70' : 7\n            ,'71-80' : 8, '81-90' : 9, '91-100' : 10, 'More than 100 Days' : 11}\ntrain['Stay'] = train['Stay'].map(stay_encode)\n","5e12d05a":"from sklearn.preprocessing import OneHotEncoder\n# By dropping one of the one-hot encoded columns from each categorical feature, we ensure there are no \"reference\" columns\u2014the remaining columns become linearly independent.\n# https:\/\/kiwidamien.github.io\/are-you-getting-burned-by-one-hot-encoding.html\n# https:\/\/www.youtube.com\/watch?v=g9aLvY8BfRM\nnominal_data = ['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code']\ntestja = pd.DataFrame()\nfor n in nominal_data:\n    ohe = OneHotEncoder(sparse = False, drop = 'first', categories = 'auto')\n    ohe.fit(train[nominal_data])\n    ohecategory_train = ohe.transform(train[nominal_data])\n    ohecategory_test = ohe.transform(test[nominal_data])\n\n    for i in range(ohecategory_train.shape[1]):\n        train['dummy_variable_' + n + '_' + str(i)] = ohecategory_train[:,i]\n        \n    for i in range(ohecategory_test.shape[1]):\n        test['dummy_variable_' + n + '_' + str(i)] = ohecategory_test[:,i]\n\n\nprint('Train shape :', train.shape)\nprint('Test shape :', test.shape)","030926a5":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nnum_col = ['Available Extra Rooms in Hospital', 'Bed Grade', 'Visitors with Patient'\n             , 'Admission_Deposit', 'Lower_Bound_Age', 'Upper_Bound_Age']\nsc.fit(train[num_col])\ntrain[num_col] = sc.transform(train[num_col])\ntest[num_col] = sc.transform(test[num_col])","548c9406":"train[num_col].head()","169f2ce1":"test[num_col].head()","61820d17":"# See if train and test data have same shape and column position\nprint('Train columns :\\n',train.columns)\nprint('Train shape : ', train.shape)\nprint('\\n')\nprint('Test columns :\\n',test.columns)\nprint('Test shape : ', test.shape)","8db14301":"train.head()","4ac1ad6e":"train.drop(['case_id', 'Hospital_code', 'patientid', 'Age', 'City_Code_Hospital', 'City_Code_Patient'\n            , 'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code']\n           , axis = 1, inplace = True)\n\ntest.drop(['case_id', 'Hospital_code', 'patientid', 'Age', 'City_Code_Hospital', 'City_Code_Patient'\n            , 'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code']\n           , axis = 1, inplace = True)\n","4df37100":"# See if train and test data have same shape and column position\nprint('Train columns :\\n',train.columns)\nprint('Train shape : ', train.shape)\nprint('\\n')\nprint('Test columns :\\n',test.columns)\nprint('Test shape : ', test.shape)","e28e876b":"X_train = train.iloc[:, 1:].values\ny_train = train.iloc[:, 0].values\nX_test = test.iloc[:, 1:].values\ny_test = test.iloc[:, 0].values\n\n#print('X_train :\\n', X_train[0:5])\n#print('y_train :\\n', y_train[0:5])","4e83b03e":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nx_train_split, x_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size = 0.3, random_state = 0)\nclf = RandomForestClassifier(n_estimators=300, max_depth = 20, min_samples_leaf= 10, max_features=0.5)\nclf.fit(x_train_split, y_train_split)\ny_pred = clf.predict(x_val_split)\naccuracy = accuracy_score(y_pred, y_val_split)\nprint('Accuracy :',accuracy)","7eaf0b1e":"feature_importances = pd.DataFrame( data = {'Features' : train.iloc[:, 1:].columns\n                                    ,'Features Importances' : clf.feature_importances_.tolist()})\nfeature_importances","1b654f00":"features = []\nfi = []\n# 'nominal_data' from one hot encoder cell (cell no.27)\nfor n in nominal_data:\n    features.append(n)\n    fi.append(feature_importances.loc[feature_importances['Features'].str.contains(n), 'Features Importances'].sum())\n    \n    feature_importances =  feature_importances[~feature_importances['Features'].str.contains(n)]\n\nfi_nominal_data = pd.DataFrame(list(zip(features, fi)), columns = ['Features', 'Features Importances'])\nfeature_importances = feature_importances.append(fi_nominal_data).sort_values('Features Importances'\n                                                                              , ascending = False).reset_index(drop = True)\n\nfeature_importances","a6c17ce5":"fig, ax = plt.subplots(figsize=(16,8))\nax = sns.barplot(ax = ax, data = feature_importances.nlargest(20,'Features Importances')\n                 ,x='Features Importances',y='Features')\nplt.show()","4d71ea84":"# Fit the model into the whole data train\nclf.fit(X_train, y_train)","50fd0243":"y_pred = clf.predict(X_test)\n\n\nsubmission = pd.DataFrame()\nsubmission['case_id'] = data_test['case_id']\nsubmission['Stay'] = y_pred\n\nstay_decode = { 1 : '0-10', 2 : '11-20', 3 : '21-30', 4 : '31-40', 5 : '41-50', 6 : '51-60', 7 : '61-70'\n            ,8 : '71-80', 9 : '81-90', 10 : '91-100', 11 : 'More than 100 Days'}\n\nsubmission['Stay'] = submission['Stay'].map(stay_decode)\nsubmission","be5ab1a0":"submission.to_csv(r'Submission.csv', index = False, header = True)","6d9c1875":"## Encode Categorical Data","132fe049":"### Analysis Numeric Data","f9658234":"Because there are lots of nominal data columns, so I choose who columns that usefull or important for prediction model based on my analysis.\n","15d650c3":"### Feature Importances","37de003c":"## Cleaning Data on Columns 'Available Extra Rooms', 'Visitors with Patient' & 'Admission Deposit'","35a9a27a":"### Analysis Categorical Data","eff43cfd":"# Model Prediction","9e90d3cb":"### Do One Hot Encoder on Nominal Data","6356cd23":"## Random Forest Classifier","6da298a5":"# Exploratory Data Analysis","ccb72276":"## Standardization Numerical Data","18a334f0":"# Preprocessing Data (handle missing data, cleaning data, feature engineering, etc.) on Each Columns","9d83e386":"# Feature Selection","2e6fd50e":"### Train and Evaluate a Model Prediction","d05a2823":"Based on histogram and skewness value, we can know who columns is nearly normally distributed or not. You can see on extra rooms, visitors with patient and admission deposite columns they have right skewed distributions (based on histograms above ), and based on the skewness value they are in moderately skewed\/highly skewed (see the detail on below). So,  we should cleaning thats columns into more nearly normally distributed.\n\n\n-------------------------------------------------------------------------------------------------------------------------------\nThe skewness value can be positive or negative, or even undefined. If skewness is 0, the data are perfectly symmetrical, although it is quite unlikely for real-world data. As a general rule of thumb:\n\nIf skewness is less than -1 or greater than 1, the distribution is highly skewed.\n\nIf skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.\n\nIf skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n\n\nsource :\nhttps:\/\/help.gooddata.com\/doc\/en\/reporting-and-dashboards\/maql-analytical-query-language\/maql-expression-reference\/aggregation-functions\/statistical-functions\/predictive-statistical-use-cases\/normality-testing-skewness-and-kurtosis\n","5eb290bf":"### Explanation :\nDrop unused features, because :\n\n'case_id', 'Hospital_code', 'patientid' -> I dont need this, its just id columns\n\n'Age' -> because I haved create lower and upper bound age, so this column is not used anymore\n\n'City_Code_Hospital' -> I use hospital_region_code instead of this column, because they have same explanation\n\n'City_Code_Patient' -> I think there are no relations between where patient live and how long they have stayed on hospital and there are to much categories on this column, so i drop it to reduce the dimension of the data\n\n'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code' -> because i haved one hot encode them, so I used dummy variable of them","96488b81":"### Do Encoding on Ordinal Data","8c82cfe3":"### Predict Data Test","198df292":"## Handle Missing Data","350b5556":"### The Result of This Model in \"Janatahack: Healthcare Analytics II\" Leaderboard :\n### Public Score : 40.8613\n### Private Score : 40.5301"}}