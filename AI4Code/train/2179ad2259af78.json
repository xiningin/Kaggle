{"cell_type":{"3fc366f3":"code","950bde2f":"code","9e31df09":"code","cb57436a":"code","54407b28":"code","5a2cc64b":"code","886b9585":"code","ce2647b0":"code","4bd21a93":"code","6d4df893":"code","b4ac1d9b":"code","915e15d1":"code","2fd451a3":"code","93c20ddb":"code","d50b7704":"code","bbe3c48a":"code","5ae71fb4":"code","813496de":"code","8e64d353":"code","f3b31123":"code","981e4da4":"code","ad852647":"code","5e6de885":"code","41adc1b6":"code","db56e812":"code","d4ea9900":"markdown","1c45ee10":"markdown","d56a5b16":"markdown","c878c2f5":"markdown","30d54a00":"markdown"},"source":{"3fc366f3":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, SimpleRNN, LSTM\nfrom tensorflow.keras.callbacks import EarlyStopping","950bde2f":"#creating a sine wave\nx = np.linspace(0,50, 501)\ny = np.sin(x)\nprint('length of x : ',len(x))\nprint('length of y : ',len(y))\nprint(x[:10])\nprint(y[:10])","9e31df09":"#plot the sine wave\nplt.figure(figsize=(15,6))\nplt.plot(x,y)\nplt.show()","cb57436a":"#create a dataframe with these values\ndf = pd.DataFrame(data=y, index=x, columns=['sine'])\ndisplay(df.head())","54407b28":"#the train df will be used for training the model and the test df will be used for comparing with the output\nall_points = len(df)\ntest_ratio = 0.1\ntrain_end_point = int(all_points*(1-test_ratio))\ntest_begin_point = train_end_point+1\n\nprint(train_end_point)\nprint(test_begin_point)","5a2cc64b":"#define train and test dataframe\ntrain = df.iloc[:train_end_point+1]\ntest = df.iloc[test_begin_point:]\n\n#view the dataframes\ndisplay(train.head())\ndisplay(train.tail())\n\ndisplay(test.head())\ndisplay(test.tail())","886b9585":"scaler = MinMaxScaler()\n#scale the values(which are between -1 and 1) to between 0 and 1\nscaler.fit(train)\n\nscaled_train = scaler.transform(train)\nscaled_test = scaler.transform(test)\nprint(scaled_train.max(), scaled_train.min())\nprint(scaled_test.max(), scaled_test.min())","ce2647b0":"#TimeseriesGenerator(inputs, targets, length, batch_size)\n\n#input => our train series of values\n\n#target => our train series of values\n#beacuse we are not predicting an output for each input\n#the output will also be a part of the series based on previous inputs\n\n#length => The total number of points we will use to predict the next point(s) in each run of generator\n#batch_size => the total number of points we will predict in each run of  generator\n\nlen_input_series = 50 #use 50 points to predict next point(s)\nbatch_size = 1 #predict next 1 point based on input point(s)\nn_features = 1 #we have only 1 feature (sine of x)\n\ngenerator_train = TimeseriesGenerator(scaled_train, \n                                scaled_train, \n                                length=len_input_series, \n                                batch_size=batch_size)","4bd21a93":"#create the function for rnn model\ndef rnnmodel():\n    model = Sequential()\n    \n    model.add(SimpleRNN(units = len_input_series, input_shape = (len_input_series, n_features)))\n    #Still doubtful what units is, but is often kept equal to len of input series\n    model.add(Dense(1))\n    \n    model.compile(optimizer='adam', loss='mse')\n    \n    return model","6d4df893":"#view model summary\nmodelrnn = rnnmodel()\nmodelrnn.summary()","b4ac1d9b":"#fit the generator to model\nmodelrnn.fit_generator(generator_train,epochs=5)","915e15d1":"#get the losses and plot them for each epoch\nlosses = pd.DataFrame(modelrnn.history.history)\nlosses.plot()","2fd451a3":"#predict the output for the entire range of test values (50 points)\ntest_predictions = []\nfirst_eval_batch = scaled_train[-len_input_series:]\ncurrent_batch = first_eval_batch.reshape((1, len_input_series, n_features))\n\nfor i in range(len(test)):\n    current_pred = modelrnn.predict(current_batch)[0]\n    test_predictions.append(current_pred)\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]], axis=1)","93c20ddb":"#transform the output back to its original range of values (i.e between -1 and 1)\ntrue_predictions = scaler.inverse_transform(test_predictions)\n\n#add predictions to test dataframe\ntest['Predictions'] = true_predictions\n\n#display predictions and plot\ndisplay(test.head())\ntest.plot()","d50b7704":"#scale the data of entire df\nfull_scaler = MinMaxScaler()\nscaled_full_data = full_scaler.fit_transform(df)","bbe3c48a":"#create a generator for entire df, taking 50 values to predict next 1 value\ngenerator_all = TimeseriesGenerator(scaled_full_data, \n                                scaled_full_data, \n                                length=len_input_series, \n                                batch_size=batch_size)","5ae71fb4":"#define function for entire model\ndef finalmodel():\n    model = Sequential()\n    \n    model.add(SimpleRNN(units=len_input_series, input_shape=(len_input_series, n_features)))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    \n    return model","813496de":"#initialize model and fit generator\nmodelfinal = finalmodel()\nmodelfinal.fit_generator(generator_all, epochs=10)","8e64d353":"#predict the next 501 points\nforecast = []\n\nfirst_eval_batch = scaled_full_data[-len_input_series:]\ncurrent_batch = first_eval_batch.reshape((1, len_input_series, n_features))\n\nfor i in range(len(df)):\n    current_pred = modelfinal.predict(current_batch)[0]\n    forecast.append(current_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","f3b31123":"#rescale the predicted values bw -1 and 1\nforecast = scaler.inverse_transform(forecast)\n\n#index for predicted values\nforecast_index = np.arange(50.1,100.2,step=0.1)\n\n#plot the praph\nplt.plot(df.index,df['sine'])\nplt.plot(forecast_index,forecast)\nplt.show()","981e4da4":"#stop training if validation loss increases for continuously 3 times\nearly_stop = EarlyStopping(monitor='val_loss',patience=3)\n\n#define generator and validation generator\ngenerator_lstm = TimeseriesGenerator(scaled_train,scaled_train,\n                               length=len_input_series-1,batch_size=1)\n\nvalidation_generator = TimeseriesGenerator(scaled_test,scaled_test,\n                                          length=len_input_series-1,batch_size=1)","ad852647":"#define the lstm model function\ndef lstmmodel():\n    model = Sequential()\n    \n    model.add(LSTM(units=len_input_series, input_shape=(len_input_series, n_features)))\n    model.add(Dense(1))\n    \n    model.compile(optimizer='adam', loss='mse')\n    \n    return model","5e6de885":"#create the lstm model\nmodellstm = lstmmodel()\n\n#fit the generator to the model\nmodellstm.fit_generator(generator,\n                    epochs=15,\n                    validation_data = validation_generator,\n                    callbacks = [early_stop])","41adc1b6":"#make prediction over the x values in test df\n#note : we r not actually using the values in test df\ntest_predictions = []\n\nfirst_eval_batch = scaled_train[-len_input_series:]\ncurrent_batch = first_eval_batch.reshape((1, len_input_series, n_features))\n\nfor i in range(len(test)):\n    current_pred = modellstm.predict(current_batch)[0]\n    test_predictions.append(current_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","db56e812":"#make predictions and add to test df and plot the graph\ntrue_predictions = scaler.inverse_transform(test_predictions)\ntest['LSTM Predictions'] = true_predictions\ntest.plot(figsize=(12,8))","d4ea9900":"<h1>Forecasting<\/h1>\n<h3>Training over the entire dataset<\/h3>","1c45ee10":"<h4>Experimening with RNN and LSTM on a sine wave.<\/h4>\nIt's quite possible the LSTM section has a logical error with validation generator","d56a5b16":"<h4>It is quite evident from the graph that the error gets magnified after each prediction (because we are predicting using predictions).<\/h4>","c878c2f5":"<h1> LSTM Model with early stopping<\/h1>","30d54a00":"<h3>Train-Test Split<\/h3>"}}