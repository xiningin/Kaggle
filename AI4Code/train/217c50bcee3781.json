{"cell_type":{"c5ac28ea":"code","d3faa38d":"markdown","0fb44ab7":"markdown","6d3607c3":"markdown","95ec6ab7":"markdown"},"source":{"c5ac28ea":"experiment_name = \"bengali_MAIN\"\nhivemind_version = \"bengali-main-run\"\ncollaborative_training_version = \"main\" \n%env HF_EXPERIMENT_ID 15\n\n!echo \"Installing dependencies...\"\n!pip install git+https:\/\/github.com\/learning-at-home\/hivemind.git@{hivemind_version} >> install.log 2>&1\n!git clone https:\/\/github.com\/mryab\/collaborative-training -b {collaborative_training_version} >> install.log 2>&1\n%cd .\/collaborative-training\n!pip install -r requirements.txt >> install.log 2>&1\n!pip install transformers -U\nfrom shlex import quote\nimport torch\nfrom huggingface_auth import authorize_with_huggingface\nfrom runner import run_with_logging\n\nassert torch.cuda.is_available(), \"GPU device not found. If running in colab, please retry in a few minutes.\"\ndevice_name = torch.cuda.get_device_name(0)\nmicrobatch_size = 4 if 'T4' in device_name or 'P100' in device_name else 1\nprint(f\"Running with device {device_name}, local batch size = {microbatch_size}\")\n\nauthorizer = authorize_with_huggingface()\n\ncommand = f\"\"\"ulimit -n 4096 && HIVEMIND_THREADS=256 \\\n HF_USERNAME={quote(authorizer.username)} HF_PASSWORD={quote(authorizer.password)} python .\/run_trainer.py --client_mode \\\n --initial_peers 3.141.202.115:31337 18.219.141.99:31337 {authorizer.coordinator_ip}:{authorizer.coordinator_port} \\\n --averaging_expiration 10 --statistics_expiration 120 \\\n --batch_size_lead 400 --per_device_train_batch_size {microbatch_size} --gradient_accumulation_steps 1 \\\n --logging_first_step --logging_steps 100 --run_name {quote(authorizer.username)} \\\n --output_dir .\/outputs --overwrite_output_dir --logging_dir .\/logs \\\n --experiment_prefix {quote(experiment_name)} --seed 42\"\"\"\nrun_with_logging(command, authorizer.coordinator_ip, wandb_login=True)","d3faa38d":"### How it works\n\nSince peers can join and leave at any time, we can't use global [Ring All-Reduce](https:\/\/towardsdatascience.com\/visual-intuition-on-ring-allreduce-for-distributed-deep-learning-d1f34b4911da) for averaging: a single missing peer can break the entire protocol. Instead, peers dynamically assemble into small groups and run all-reduce within each group. Consider an example with 9 GPUs:\n\n<center>\n<img src=\"https:\/\/i.imgur.com\/QcD1mfG.png\" width=360px><br>\nThe All-Reduce protocol within group can be Ring-AllReduce, but we use a simpler all-to-all algorithm known as butterfly-like all-reduce.<br>\n<img src=\"https:\/\/i.imgur.com\/ewq3vS6.png\" width=380px><br>\nAfter each successful round, participants shuffle around and find new groups:<br>\n<img src=\"https:\/\/i.imgur.com\/dexNCL3.png\" width=350px>\n\nIf one of the peers fails to do his part, it will only affect his local group, and only for a single round.\n\n\n<img src=\"https:\/\/i.imgur.com\/RBmElUi.png\" width=340px>\n\nAfterwards, peers from the failed group will find new groupmates according to the [moshpit algorithm](https:\/\/arxiv.org\/abs\/2103.03239).\n\n<\/center>\n\n\nIf you want to learn more and even host your own collaborative experiments, take a look at the [hivemind library](https:\/\/github.com\/learning-at-home\/hivemind\/) or the [Moshpit-SGD paper](https:\/\/arxiv.org\/pdf\/2103.03239.pdf).\n\n\n","0fb44ab7":"<center><img src=\"https:\/\/i.imgur.com\/FHMoW3N.png\" width=360px><br><b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Collaborative training <sup>v0.9 alpha<\/sup><\/b><\/center>\n\n\nThis notebook will use local or colab GPU to help train ALBERT-large collaboratively. Your instance will compute gradients and exchange them with a bunch of volunteers around the world. We explain how it works at the bottom. But for now, please run all cells :)\n\nTo start training, you will need to login to your huggingface account, please fill in the prompts as in the example below (replace `robot-bengali` with your username):\n\n![img](https:\/\/i.imgur.com\/txuWbJi.png)\n\nPlease do not run kaggle notebooks from multiple accounts: google doesn't like this.\n\n# **BEFORE YOU RUN: please ensure that both GPU and internet access are enabled in a menu on the right:**\n![](https:\/\/i.imgur.com\/d179Ihb.png)","6d3607c3":"<a href=\"https:\/\/colab.research.google.com\/gist\/yhn112\/44a2a1e675bf7290a04f12d0706ead33\/colab_starter.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","95ec6ab7":"### What's up next?\n* Check the training progress on public learning curves: https:\/\/wandb.ai\/learning-at-home\/Main_metrics\n* View model checkpoints: https:\/\/huggingface.co\/Upload\/bengali-albert \n* See [this tutorial](https:\/\/github.com\/learning-at-home\/hivemind\/tree\/master\/examples\/albert) on how to start your own collaborative runs!\n\n\n_Co-created by [yhn112](https:\/\/github.com\/yhn112), [leshanbog](https:\/\/github.com\/leshanbog), [foksly](https:\/\/github.com\/foksly) and [borzunov](https:\/\/github.com\/borzunov) from [hivemind](https:\/\/github.com\/learning-at-home\/hivemind) (YSDA), [lhoestq](https:\/\/github.com\/lhoestq), [SaulLu](https:\/\/github.com\/SaulLu) and [stas00](https:\/\/github.com\/stas00) from [huggingface](http:\/\/huggingface.co)_.\n"}}