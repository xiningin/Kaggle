{"cell_type":{"370c58c3":"code","d49a8b38":"code","4ce3c8e0":"code","8cb711ef":"code","a9b53035":"code","6452b7cb":"code","308c210a":"code","a627ee00":"code","1c159748":"code","e587407e":"markdown","dab11efb":"markdown","fd30e47c":"markdown","ec94652c":"markdown","a70b36f2":"markdown","3974ac61":"markdown"},"source":{"370c58c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom skimage.data import imread\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d49a8b38":"# ref: https:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction","4ce3c8e0":"train = pd.read_csv('..\/input\/train_ship_segmentations.csv')\ntrain.head()","8cb711ef":"sample = train[~train.EncodedPixels.isna()].sample(25)\n\nfig, ax = plt.subplots(5, 5, sharex='col', sharey='row')\nfig.set_size_inches(20, 20)\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i \/\/ 5\n    \n    path = Path('..\/input\/train') \/ '{}'.format(imgid)\n    img = imread(path)\n    \n    ax[row, col].imshow(img)","a9b53035":"sample = train[train.EncodedPixels.isna()].sample(25)\n\nfig, ax = plt.subplots(5, 5, sharex='col', sharey='row')\nfig.set_size_inches(20, 20)\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i \/\/ 5\n    \n    path = Path('..\/input\/train') \/ '{}'.format(imgid)\n    img = imread(path)\n    \n    ax[row, col].imshow(img)","6452b7cb":"ships = train[~train.EncodedPixels.isna()].ImageId.unique()\nnoships = train[train.EncodedPixels.isna()].ImageId.unique()\n\nplt.bar(['Ships', 'No Ships'], [len(ships), len(noships)]);\nplt.ylabel('Number of Images');","308c210a":"def get_img(imgid):\n    '''Return image array, given ID.'''\n    path = Path('..\/input\/train\/') \/ '{}'.format(imgid)\n    return imread(path)","a627ee00":"fig, ax = plt.subplots(1, 2, sharex='col', sharey='row')\nfig.set_size_inches(20, 6)\n\nmask = train.EncodedPixels.isna()\nfor i, (msk, label) in enumerate(zip([mask, ~mask], ['No Ships', 'Ships'])):\n    _ids = train[msk].ImageId.sample(250)\n    imgs = np.array([get_img(_id) for _id in _ids])\n    \n    red = imgs[:, :, :, 0]\n    green = imgs[:, :, :, 1]\n    blue = imgs[:, :, :, 2]\n    \n    ax[i].plot(np.bincount(red.ravel()), color='orangered', label='red', lw=2)\n    ax[i].plot(np.bincount(green.ravel()), color='yellowgreen', label='green', lw=2)\n    ax[i].plot(np.bincount(blue.ravel()), color='skyblue', label='blue', lw=2)\n    ax[i].legend()\n    ax[i].title.set_text(label)","1c159748":"def apply_masks_to_img(img, _id, df):\n    '''Apply masks to image given img, its id and the dataframe.'''\n    masks = df[df.ImageId == _id].EncodedPixels.apply(lambda x: rle_decode(x)).tolist()\n    masks = sum(masks)\n    return img * masks.reshape(img.shape[0], img.shape[1], 1)\n\n\nfig, ax = plt.subplots(1, 2, sharex='col')#, sharey='row')\nfig.set_size_inches(20, 6)\n\nmask = train.EncodedPixels.isna()\nfor i, (msk, label) in enumerate(zip([mask, ~mask], ['No Ships', 'Ships'])):\n    _ids = train[msk].ImageId.sample(250)\n    imgs = [get_img(_id) for _id in _ids]\n    \n    # if we have an encoding to decode\n    if i == 1:\n        imgs = [apply_masks_to_img(i, _id, train) for (i, _id) in zip(imgs, _ids)]\n\n    imgs = np.array(imgs)\n    red = imgs[:, :, :, 0]\n    green = imgs[:, :, :, 1]\n    blue = imgs[:, :, :, 2]\n    \n    # skip bincount index 0 to avoid the masked pixels to overpower the others.\n    ax[i].plot(np.bincount(red.ravel())[1:], color='orangered', label='red', lw=2)\n    ax[i].plot(np.bincount(green.ravel())[1:], color='yellowgreen', label='green', lw=2)\n    ax[i].plot(np.bincount(blue.ravel())[1:], color='skyblue', label='blue', lw=2)\n    ax[i].legend()\n    ax[i].title.set_text(label)","e587407e":"## Look at colour distributions of areas with no ships and ships themselves.","dab11efb":"## Look at 25 images with ships...","fd30e47c":"## ...and 25 without ships.","ec94652c":"## Look at a sample of the training images.","a70b36f2":"## Look at colour distributions between images with ships and those without.\n\nLets look at 250 of each, sampled at random.","3974ac61":"## Look at class balance"}}