{"cell_type":{"567b1e45":"code","34c9b90b":"code","9d36f25b":"code","d131fe1a":"code","86f17c4b":"code","6148e503":"code","234fe923":"code","c6b553d8":"code","b06323ae":"code","117f4fc1":"code","c672e8b4":"code","f827a1e4":"code","d99818ce":"code","4431c069":"code","92404792":"code","3e1bef5a":"code","d6397175":"code","e0573006":"code","35625853":"code","5a98592f":"code","b2ea4edb":"code","a33f5bb0":"code","b1dce7f4":"code","1dba83ed":"code","c38927ff":"code","8137a79a":"code","8675c691":"code","b7c8381b":"code","0802bb5a":"code","dd137bd3":"code","b85c00d5":"code","b7d7c892":"code","acd984f9":"code","0cf74fa2":"code","fecacae9":"code","060ea412":"markdown","d0431fd5":"markdown","89eb75e2":"markdown","f612e431":"markdown","cb93c09f":"markdown","9ecf2d37":"markdown","488fb6de":"markdown","c1058b6a":"markdown","3960c312":"markdown","0bb59993":"markdown","a6d6b562":"markdown","a773cf79":"markdown","3cff1b30":"markdown","69e19161":"markdown","ec2f1463":"markdown","f5018654":"markdown","8002ba84":"markdown"},"source":{"567b1e45":"import os \nimport tensorflow as tf\nimport numpy as np\nimport cv2\ntf.device('\/gpu:0') #for kaggle\n#tf.device('\/device:GPU:0') # for colab\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.applications import DenseNet121\nimport random\nimport zipfile\nimport gc\nfrom IPython.display import FileLink\nimport shutil\nfrom pathlib import Path\nfrom tensorflow.keras.models import load_model\nimport seaborn as sns\nfrom sklearn.metrics import precision_score,recall_score","34c9b90b":"! conda install -y gdown #for kaggle\nmy_file = Path(\"kaggle.json\")\nif not my_file.is_file():\n    !gdown --id 1aF2wQEtAftTSvKD0ibsVLA4h-9fQs0q6\nelse:\n    print('doesn\\'t exist')\n\n# for colab\n# ! pip install kaggle\n# ! pip install --upgrade --force-reinstall --no-deps kaggle\n# ! mkdir ~\/.kaggle\n# ! cp \/content\/kaggle.json ~\/.kaggle\/  \n# ! chmod 600 ~\/.kaggle\/kaggle.json\n# ! kaggle competitions download -c tpu-getting-started\n# ! unzip \/content\/tpu-getting-started.zip -d \/content\/data \n\n# for kaggle\n! mkdir ~\/.kaggle\n! cp .\/kaggle.json ~\/.kaggle\/ \n! chmod 600 ~\/.kaggle\/kaggle.json \n! kaggle competitions download -c tpu-getting-started\nwith zipfile.ZipFile('.\/tpu-getting-started.zip', 'r') as zip_ref:\n   zip_ref.extractall('.\/data')","9d36f25b":"'''\nInput:\n  files: The TFRecord files\n  test:  Flag to check wheather the input files is from the test directory\n\nOutput:\n  ids:    Array of image ids\n  cl:     Array of labels to the corresponding image\n  images: Array of images in ByteIO format\n\n'''\ndef parse_tfrec_data(files, test=False):\n    if not test: \n        feature_description = {\n            'class': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n            'image': tf.io.FixedLenFeature([], tf.string),\n        }\n    else:\n        feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n    }\n    parse_image_f = lambda x: tf.io.parse_single_example(x, feature_description)\n\n    images = []\n    if not test:\n        cl = []\n\n    for i in files:\n        print(i)\n        image_dataset = tf.data.TFRecordDataset(i)\n        image_dataset = image_dataset.map(parse_image_f)\n\n\n        images_ = [np.array(image_features['image']) for image_features in image_dataset]\n        images = images + images_\n\n        if not test:\n                cl_ = [np.array(int(class_features['class'])) for class_features in image_dataset]\n                cl = cl + cl_\n    if test:\n        return images\n    else:\n        return cl, images","d131fe1a":"def read_Files():\n  filenames = []\n  #test data\n  for filedir in os.listdir('.\/data'):\n      if os.path.isdir('.\/data\/'+filedir) : \n        for filedir_2 in os.listdir('.\/data\/'+filedir):\n          for filename in os.listdir('.\/data\/'+filedir+'\/' +filedir_2):\n#            print('\/content\/data\/'+filedir+'\/' +filedir_2 +'\/' +filedir_3 )\n            filenames.append('.\/data\/'+filedir+'\/' +filedir_2 +'\/' +filename )\n  random.shuffle(filenames)\n  return filenames\nfilenames = read_Files()\ncl, images = parse_tfrec_data(filenames)\nshuffle_idx = np.random.permutation(len(images))\ncl = np.array(cl)[shuffle_idx] \nimages = np.array(images)[shuffle_idx]\ncl = tf.keras.utils.to_categorical(cl,num_classes=104)","86f17c4b":"def process_path(image,label):\n    img = tf.image.decode_jpeg(image, channels=3)\n    img = tf.image.resize(img, (192, 192))\n    return img, label\ndef to_cat(image,label): \n    l = tf.keras.utils.to_categorical(label,num_classes=104)\n    return image,l\ndef preprocess(image, label):\n    img = tf.cast(image, tf.float32) \/ 255.0\n    return img, label\ndef dense_preprocess (image, label) : \n    return tf.keras.applications.densenet.preprocess_input(image),label","6148e503":"dataset = tf.data.Dataset.from_tensor_slices((images.tolist(),cl))\nimages = []\ngc.collect()\nimage_ds = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\nprocessed_ds =  image_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE) \nval_size = int(len(cl)*.1)\nprint(val_size)\ntrain_ds = processed_ds.skip(val_size)\nval_ds = processed_ds.take(val_size)\ninput_shape = (192,192,3)","234fe923":"class F1_Score(tf.keras.metrics.Metric):\n\n    def __init__(self, name='f1_score', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.f1 = self.add_weight(name='f1', initializer='zeros')\n        self.precision_fn = tf.keras.metrics.Precision(thresholds=0.5)\n        self.recall_fn = tf.keras.metrics.Recall(thresholds=0.5)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        p = self.precision_fn(y_true, y_pred)\n        r = self.recall_fn(y_true, y_pred)\n        # since f1 is a variable, we use assign\n        self.f1.assign(2 * ((p * r) \/ (p + r + 1e-6)))\n\n    def result(self):\n        return self.f1\n\n    def reset_state(self):\n        # we also need to reset the state of the precision and recall objects\n        self.precision_fn.reset_state()\n        self.recall_fn.reset_state()\n        self.f1.assign(0)","c6b553d8":"def create_simple_model() :\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = input_shape))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n    #model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.3))\n\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.3))\n\n    model.add(Flatten())\n    model.add(Dense(units = 256, input_dim = 4096, activation = 'relu'))\n    model.add(Dense(units = 256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(104, activation = \"softmax\"))\n    model.compile(optimizer='adam',\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy',F1_Score()])\n    model.summary()\n    return model\nmy_model = create_simple_model()","b06323ae":"train_ds = processed_ds.skip(val_size).batch(128)\nval_ds = processed_ds.take(val_size).batch(128)\nmy_model.fit(train_ds, epochs=10, validation_data=val_ds)\ngc.collect()","117f4fc1":"def create_vgg16_model() : \n    VGG16_sof_model =  tf.keras.Sequential([tf.keras.applications.vgg16.VGG16(input_shape=input_shape,include_top=False,weights='imagenet'),\n                                            Flatten(),\n                                            Dense(units = 256, activation = 'relu'),\n                                            Dense(units = 256, activation = 'relu'),\n                                            tf.keras.layers.Dense(104,activation='softmax')])\n    VGG16_sof_model.compile(optimizer='sgd',\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy',F1_Score()])\n    for layer in VGG16_sof_model.layers[0].layers[1:11]:\n        print(layer)\n        layer.trainable = False\n    VGG16_sof_model.summary()\n    return VGG16_sof_model\nVGG16_sof_model = create_vgg16_model()","c672e8b4":"train_ds = processed_ds.skip(val_size).batch(128)\nval_ds = processed_ds.take(val_size).batch(128)\nVGG16_sof_model.fit(train_ds, epochs=4, validation_data=val_ds)\ngc.collect()","f827a1e4":"def create_res_model():\n    res_model =  tf.keras.Sequential([tf.keras.applications.resnet.ResNet152(input_shape=input_shape,include_top=False,weights='imagenet'),\n                                            Flatten(),\n                                            Dense(units = 256, activation = 'relu'),\n                                            Dense(units = 256, activation = 'relu'),\n                                            tf.keras.layers.Dense(104,activation='softmax')])\n    res_model.compile(optimizer=tf.keras.optimizers.Adam(),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy',F1_Score()])\n    res_model.summary()\n    return res_model\nres_model = create_res_model()","d99818ce":"train_ds = processed_ds.skip(val_size).batch(64)\nval_ds = processed_ds.take(val_size).batch(64)\nres_model.fit(train_ds, epochs=5, validation_data=val_ds)\ngc.collect()","4431c069":"def create_eff_model():\n    eff_model = tf.keras.Sequential([tf.keras.applications.efficientnet.EfficientNetB0(input_shape=input_shape,weights='imagenet',include_top=False),\n                                Flatten(),\n                                Dense(units = 256, activation = 'relu'),\n                                Dense(units = 256, activation = 'relu'),\n                                tf.keras.layers.Dense(104,activation='softmax')])\n    eff_model.compile(optimizer=tf.keras.optimizers.Adam(),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy',F1_Score()])\n    eff_model.summary()\n    return eff_model\neff_model = create_eff_model()","92404792":"image_ds = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n#cat_ds = image_ds.map(to_cat, num_parallel_calls=tf.data.AUTOTUNE)\nval_size = int(len(cl)*.1)\ntrain_ds = image_ds.skip(val_size).batch(128)\nval_ds = image_ds.take(val_size).batch(128)\neff_model.fit(train_ds, epochs=5, validation_data=val_ds)\ngc.collect()","3e1bef5a":"def create_dense_model(): \n    dense_model = tf.keras.Sequential([tf.keras.applications.DenseNet121(input_shape=input_shape,weights='imagenet',include_top=False),\n                                    Flatten(),\n                                    Dense(units = 256, activation = 'relu'),\n                                    Dense(units = 256, activation = 'relu'),\n                                    tf.keras.layers.Dense(104,activation='softmax')])\n    dense_model.compile(optimizer=tf.keras.optimizers.Adam(5e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy',F1_Score()])\n    dense_model.summary()\n    return dense_model\ndense_model = create_dense_model()","d6397175":"dense_preprocess_ds = image_ds.map(dense_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_ds = dense_preprocess_ds.skip(val_size).batch(64)\nval_ds = dense_preprocess_ds.take(val_size).batch(64)\ndense_model.fit(train_ds, epochs=5, validation_data=val_ds)\ngc.collect()","e0573006":"#model.save_weights('.\/weights_2\/my_model')\n#VGG16_sof_model.save_weights('.\/weights_2\/vgg16')\n#Res_model.save_weights('.\/weights_2\/res_net')\neff_model.save_weights('.\/eff_weight\/eff_net')\n#dense_model.save_weights('.\/weights_2\/dense')\nshutil.make_archive('.\/eff_weights', 'zip', '.\/eff_weight')\nFileLink('.\/eff_weights.zip')","35625853":"my_file = Path(\"weights.zip\")\nif not my_file.is_file():\n    !gdown --id 1qEoWp3wWFyEEbtZxKOaTm_raGIYTGNvC\nelse:\n    print('doesn\\'t exist')\n! unzip .\/weights.zip -d .\/weights","5a98592f":"train_ds = processed_ds.skip(val_size)\nval_ds = processed_ds.take(val_size)\ntest_labels = np.argmax(np.array([y for x, y in val_ds]),axis =1)\nprint(test_labels.shape)\ngc.collect()","b2ea4edb":"simple_model = create_simple_model()\nsimple_model.load_weights('.\/weights\/my_model')","a33f5bb0":"train_ds = processed_ds.skip(val_size).batch(128)\nval_ds = processed_ds.take(val_size).batch(128)\nsimple_pred = simple_model.predict(val_ds)\nsimple_pred = np.argmax(simple_pred, axis=1)\nprint('Confusing matrix of my_simple model (yea I know it\\'s confusing not confusion)')\ncm = confusion_matrix(test_labels, simple_pred)\nf = sns.heatmap(cm, annot=True)","b1dce7f4":"simple_precision = precision_score(test_labels, simple_pred,average = None)\nsimple_recall = recall_score(test_labels, simple_pred,average = None)\nsimple_f1 = 2 * ((simple_precision * simple_recall) \/ (simple_precision + simple_recall + 1e-6))\nprint('class\\tprecision\\trecall\\t\\tf1_score')\nfor i in range(len(simple_precision)): \n    print(i+1,'\\t',\"%.2f\" % simple_precision[i],'\\t\\t',\"%.2f\" % simple_recall[i],'\\t\\t',\"%.2f\" % simple_f1[i])","1dba83ed":"VGG16_model = create_vgg16_model()\nVGG16_model.load_weights('.\/weights\/vgg16')","c38927ff":"train_ds = train_ds.batch(128)\nval_ds = val_ds.batch(128)\nvgg16_pred = VGG16_model.predict(val_ds)\nvgg16_pred = np.argmax(vgg16_pred, axis=1)\ngc.collect()","8137a79a":"vgg16_precision = precision_score(test_labels, vgg16_pred,average = None)\nvgg16_recall = recall_score(test_labels,vgg16_pred,average = None)\nvgg16_f1 = 2 * ((vgg16_precision * vgg16_recall) \/ (vgg16_precision + vgg16_recall + 1e-6))\nprint('class\\tprecision\\trecall\\t\\tf1_score')\nfor i in range(len(vgg16_precision)): \n    print(i+1,'\\t',\"%.2f\" % vgg16_precision[i],'\\t\\t',\"%.2f\" % vgg16_recall[i],'\\t\\t',\"%.2f\" % vgg16_f1[i])","8675c691":"Res_model = create_res_model()\nRes_model.load_weights('.\/weights\/res_net')","b7c8381b":"train_ds = train_ds.batch(64)\nval_ds = val_ds.batch(64)\nres_pred = Res_model.predict(val_ds)\nres_pred = np.argmax(res_pred, axis=1)\ngc.collect()","0802bb5a":"res_precision = precision_score(test_labels, res_pred,average = None)\nres_recall = recall_score(test_labels,res_pred,average = None)\nres_f1 = 2 * ((res_precision * res_recall) \/ (res_precision + res_recall + 1e-6))\nprint('class\\tprecision\\trecall\\t\\tf1_score')\nfor i in range(len(res_precision)): \n    print(i+1,'\\t',\"%.2f\" % res_precision[i],'\\t\\t',\"%.2f\" % res_recall[i],'\\t\\t',\"%.2f\" % res_f1[i])","dd137bd3":"eff2_model = create_eff_model()\neff2_model.load_weights('.\/weights\/eff_net')","b85c00d5":"image_ds = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n#cat_ds = image_ds.map(to_cat, num_parallel_calls=tf.data.AUTOTUNE)\nval_size = int(len(cl)*.1)\ntrain_ds = image_ds.skip(val_size).batch(128)\nval_ds = image_ds.take(val_size).batch(128)\neff_pred = eff_model.predict(val_ds)\neff_pred = np.argmax(eff_pred, axis=1)","b7d7c892":"eff_precision = precision_score(test_labels, eff_pred,average = None)\neff_recall = recall_score(test_labels,eff_pred,average = None)\neff_f1 = 2 * ((eff_precision * eff_recall) \/ (eff_precision + eff_recall + 1e-6))\nprint('class\\tprecision\\trecall\\t\\tf1_score')\nfor i in range(len(eff_precision)): \n    print(i+1,'\\t',\"%.2f\" % eff_precision[i],'\\t\\t',\"%.2f\" % eff_recall[i],'\\t\\t',\"%.2f\" % eff_f1[i])","acd984f9":"dense_model = create_dense_model()\ndense_model.load_weights('.\/weights\/dense')","0cf74fa2":"dense_preprocess_ds = image_ds.map(dense_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_ds = dense_preprocess_ds.skip(val_size).batch(64)\nval_ds = dense_preprocess_ds.take(val_size).batch(64)\ndense_pred = dense_model.predict(val_ds)\ndense_pred = np.argmax(dense_pred, axis=1)","fecacae9":"dense_precision = precision_score(test_labels, dense_pred,average = None)\ndense_recall = recall_score(test_labels,dense_pred,average = None)\ndense_f1 = 2 * ((dense_precision * dense_recall) \/ (dense_precision + dense_recall + 1e-6))\nprint('class\\tprecision\\trecall\\t\\tf1_score')\nfor i in range(len(dense_precision)): \n    print(i+1,'\\t',\"%.2f\" % dense_precision[i],'\\t\\t',\"%.2f\" % dense_recall[i],'\\t\\t',\"%.2f\" % dense_f1[i])","060ea412":"# Storing weights of models to avoid training them again","d0431fd5":"## 3. Res50-net model","89eb75e2":"## 1. my simple model","f612e431":"# Downloading Data","cb93c09f":"## 2. VGG16 model","9ecf2d37":"## 2. VGG16 model","488fb6de":"## 4. Effecient-net model","c1058b6a":"# Importing used libraries","3960c312":"## 5. Dense-net model","0bb59993":"## 4. Effecient-net model","a6d6b562":"## 5. Dense-net model","a773cf79":"* efficient-net expect their input to be un-pre-processed input, so I'm using input from the begining","3cff1b30":"## 3. Res50-net model","69e19161":"* ### retrieving labels of test set","ec2f1463":"# Loading weights of models to avoid training them again","f5018654":"## 1. my simple model","8002ba84":"# Plotting confusion matrix for previous models"}}