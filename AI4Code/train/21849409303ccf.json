{"cell_type":{"a7e2c513":"code","50d3940e":"code","bb8ad405":"code","1b5ca138":"code","32eaf583":"code","8b78f50d":"code","2ad7aa07":"code","27abb203":"code","1f9d2736":"code","008686e9":"code","d24b5796":"code","c4102c05":"code","0f18bdc6":"code","c125f965":"code","027cf7a0":"code","62fd6d0a":"code","f0628281":"markdown","855286b0":"markdown","fb717735":"markdown","05ef0b57":"markdown"},"source":{"a7e2c513":"%matplotlib inline\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport os\nimport ast\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\nimport seaborn as sns\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nstart = dt.datetime.now()","50d3940e":"DP_DIR = '..\/input\/shuffle-animal-csvs\/'\nINPUT_DIR = '..\/input\/quickdraw-doodle-recognition\/'\nBASE_SIZE = 256\nNCSVS = 100\nnp.random.seed(seed=1987)\ntf.set_random_seed(seed=1987)\n\ndef f2cat(filename: str) -> str:\n    return filename.split('.')[0]\n\ndef list_all_categories():\n    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n    return sorted([f2cat(f) for f in files], key=str.lower)","bb8ad405":"animals = ['ant', 'bat', 'bear', 'bee', 'bird', 'butterfly', 'camel', 'cat', 'cow',\n           'crab', 'crocodile', 'dog', 'dolphin', 'dragon', 'duck', 'elephant', 'fish',\n           'flamingo', 'frog', 'giraffe', 'hedgehog', 'horse', 'kangaroo', 'lion',\n           'lobster', 'monkey', 'mosquito', 'mouse', 'octopus', 'owl', 'panda',\n           'parrot', 'penguin', 'pig', 'rabbit', 'raccoon', 'rhinoceros', 'scorpion',\n           'sea turtle', 'shark', 'sheep', 'snail', 'snake', 'spider', 'squirrel',\n           'swan', 'teddy-bear', 'tiger', 'whale', 'zebra']\nNCATS = len(animals)\nprint('We have {} animals'.format(NCATS))","1b5ca138":"def apk(actual, predicted, k=3):\n    \"\"\"\n    Source: https:\/\/github.com\/benhamner\/Metrics\/blob\/master\/Python\/ml_metrics\/average_precision.py\n    \"\"\"\n    if len(predicted) > k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits \/ (i + 1.0)\n\n    if not actual:\n        return 0.0\n\n    return score \/ min(len(actual), k)\n\ndef mapk(actual, predicted, k=3):\n    \"\"\"\n    Source: https:\/\/github.com\/benhamner\/Metrics\/blob\/master\/Python\/ml_metrics\/average_precision.py\n    \"\"\"\n    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n\n\ndef preds2catids(predictions):\n    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])","32eaf583":"def top_3_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)","8b78f50d":"size = 32\nbatchsize = 512","2ad7aa07":"model = Sequential()\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu',\n                 input_shape=(size, size, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(NCATS, activation='softmax'))\nmodel.compile(optimizer=Adam(lr=0.002), loss='categorical_crossentropy',\n              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\nprint(model.summary())","27abb203":"def draw_cv2(raw_strokes, size=256, lw=6):\n    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n    for stroke in raw_strokes:\n        for i in range(len(stroke[0]) - 1):\n            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 255, lw)\n    if size != BASE_SIZE:\n        return cv2.resize(img, (size, size))\n    else:\n        return img\n\ndef image_generator(size, batchsize, ks, lw=6):\n    while True:\n        for k in np.random.permutation(ks):\n            filename = os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(k))\n            for df in pd.read_csv(filename, chunksize=batchsize):\n                df['drawing'] = df['drawing'].apply(ast.literal_eval)\n                x = np.zeros((len(df), size, size))\n                for i, raw_strokes in enumerate(df.drawing.values):\n                    x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n                x = x \/ 255.\n                x = x.reshape((len(df), size, size, 1)).astype(np.float32)\n                y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n                yield x, y\n\ndef df_to_image_array(df, size, lw=6):\n    df['drawing'] = df['drawing'].apply(ast.literal_eval)\n    x = np.zeros((len(df), size, size))\n    for i, raw_strokes in enumerate(df.drawing.values):\n        x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n    x = x \/ 255.\n    x = x.reshape((len(df), size, size, 1)).astype(np.float32)\n    return x","1f9d2736":"valid_df = pd.read_csv(os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(NCSVS - 1)), nrows=10**5)\nx_valid = df_to_image_array(valid_df, size)\ny_valid = keras.utils.to_categorical(valid_df.y, num_classes=NCATS)\nprint(x_valid.shape, y_valid.shape)\nprint('Validation array memory {:.2f} GB'.format(x_valid.nbytes \/ 1024.**3 ))","008686e9":"train_datagen = image_generator(size=size, batchsize=batchsize, ks=range(NCSVS - 1))","d24b5796":"x, y = next(train_datagen)\nn = 8\nfig, axs = plt.subplots(nrows=n, ncols=n, sharex=True, sharey=True, figsize=(12, 12))\nfor i in range(n**2):\n    ax = axs[i \/\/ n, i % n]\n    ax.imshow(x[i, :, :, 0], cmap=plt.cm.gray)\n    ax.axis('off')\nplt.tight_layout()\nfig.savefig('bw.png', dpi=300)\nplt.show();","c4102c05":"%%timeit\nnext(train_datagen)","0f18bdc6":"callbacks = [\n    EarlyStopping(monitor='val_categorical_accuracy', patience=7, min_delta=0.0001, mode='max'),\n    ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, min_delta=0.005,\n                      mode='max', cooldown=3),\n    ModelCheckpoint('bw_animal_cnn.h5', monitor='val_top_3_accuracy', mode='max',\n                    save_best_only=True, save_weights_only=True),\n]\nhist = model.fit_generator(\n    train_datagen, steps_per_epoch=500, epochs=100, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)","c125f965":"hist_df = pd.DataFrame(hist.history)\nhist_df.to_csv('bw_cnn_history.csv', index=False)\nfig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\naxs[0].plot(hist_df.val_categorical_accuracy, lw=5, label='Validation Accuracy')\naxs[0].plot(hist_df.categorical_accuracy, lw=5, label='Training Accuracy')\naxs[0].set_ylabel('Accuracy')\naxs[0].set_xlabel('Epoch')\naxs[0].grid()\naxs[0].legend(loc=0)\naxs[1].plot(hist_df.val_categorical_crossentropy, lw=5, label='Validation MLogLoss')\naxs[1].plot(hist_df.categorical_crossentropy, lw=5, label='Training MLogLoss')\naxs[1].set_ylabel('MLogLoss')\naxs[1].set_xlabel('Epoch')\naxs[1].grid()\naxs[1].legend(loc=0)\nfig.savefig('hist.png', dpi=300)\nplt.show();","027cf7a0":"valid_predictions = model.predict(x_valid, batch_size=128, verbose=1)\nmap3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions).values)\nprint('Map3: {:.3f}'.format(map3))","62fd6d0a":"end = dt.datetime.now()\nprint('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))","f0628281":"## Training with Image Generator","855286b0":"## Setup\nImport the necessary libraries and a few helper functions.","fb717735":"## Simple ConvNet","05ef0b57":"# Keras Simple CNN Benchmark\n\nI assume you are already familiar with the competition dataset. \n\nThis kernel has two main components:\n\n* Simple Convolutional Network\n* Fast and memory efficient Image Generator\n\nSimplified versions could be trained without GPU."}}