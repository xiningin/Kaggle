{"cell_type":{"e91ab154":"code","d5a12bff":"code","82f6f21e":"code","fd0f4884":"code","e60aacb0":"code","895f121f":"code","7376a97b":"code","0bad8ee0":"code","859f1f98":"code","b307b458":"code","12426043":"code","9ef2eee3":"code","0f08a213":"code","0bfb04ab":"code","2327accd":"code","dac6c372":"code","2d4f8940":"code","0cad140b":"code","1d777faa":"code","19aabe92":"code","098f522b":"code","98319e5d":"code","323e9f94":"code","0795f70a":"markdown","3b83bc99":"markdown","59c0acd8":"markdown","61bd5004":"markdown","02ed5763":"markdown","4939b0af":"markdown","c146f851":"markdown","05e9f0d3":"markdown","896d6a66":"markdown","0025ebad":"markdown","a0b6ed25":"markdown","5530c60b":"markdown","eb42f705":"markdown","2100a3ae":"markdown"},"source":{"e91ab154":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/iris-introduction\/IRIS_Introduction.PNG\")","d5a12bff":"## Import Libraries\nimport pandas as pd\nimport numpy as np","82f6f21e":"## Read IRIS dataset\niris_data = pd.read_csv('..\/input\/train-iris\/train_iris.csv')\niris_data.head(3)","fd0f4884":"iris_data.info()","e60aacb0":"iris_data.shape","895f121f":"iris_data.isnull().sum()","7376a97b":"iris_data.describe()","0bad8ee0":"iris_data.groupby('variety').size()","859f1f98":"iris_data.groupby('variety').mean()","b307b458":"from sklearn import model_selection\n\niris_train, iris_test = model_selection.train_test_split(iris_data,test_size = 0.2,random_state=123)\nprint(\"Original IRIS DataSet Size\",iris_data.shape)\nprint(\"Training IRIS DataSet Size\",iris_train.shape)\nprint(\"Test IRIS DataSet Size\",iris_test.shape)","12426043":"# Reset Index after train_test split data\niris_train = iris_train.reset_index(drop=True)\niris_test = iris_test.reset_index(drop=True)","9ef2eee3":"print(iris_data.shape)\niris_features = iris_data.drop('variety',axis=1)\nprint(iris_features.shape)","0f08a213":"from sklearn.feature_selection import VarianceThreshold\niris_var = VarianceThreshold()\n\n#Perform Variance Threshold\niris_var.fit_transform(iris_features)\n\n# Analyze variance of each feature\nfor feature in zip(iris_features.columns,iris_var.variances_):\n    print(feature)","0bfb04ab":"# Feature Visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure(figsize=(4,4))\nplt.bar(x = iris_features.columns, height=iris_var.variances_, color='yellow')\nplt.xticks(rotation = 'vertical')\nplt.ylabel('Variance')\nplt.title('Variance Comparision')\n\nplt.show()","2327accd":"# create VarianceThreshold object to perform variance thresholding\nselector = VarianceThreshold(threshold=0.2)\n\n#Transform the new features dataset based on variance threshold\niris_features_new = selector.fit_transform(iris_features)\n\nprint('Number of features before varaince threshold:{}'.format(iris_features.shape[1]))\nprint('Number of features before varaince threshold:{}'.format(iris_features_new.shape[1]))","dac6c372":"iris_features_new.shape","2d4f8940":"## Split Data into Features and Labels for Train and Test.\niris_features = ['sepal.length','petal.length','petal.width']\niris_labels = ['variety']\n\n## Train Data\niris_train_features = iris_train[iris_features]\niris_train_label = iris_train[iris_labels]\n\n## Test Data\niris_test_features = iris_test[iris_features]\niris_test_label = iris_test[iris_labels]","0cad140b":"from sklearn.tree import DecisionTreeClassifier\n\n#Create DecisionTree Model Object\ndt = DecisionTreeClassifier(max_depth=3)\n\n# Fit DecisionTree Model on Train Data\ndt.fit(iris_train_features,iris_train_label)","1d777faa":"# Prediction on Test Data\npredictions_dt = dt.predict(iris_test_features)\n\niris_pred_label = pd.DataFrame(predictions_dt.reshape(len(predictions_dt),1))\niris_pred_label.rename(columns={0:'dt_predictions'},inplace=True)\niris_pred_label.head(5)","19aabe92":"## Verify IRIS_test_labels with IRIS_predicted_labels\niris_test_pred = pd.concat([iris_test_label,iris_pred_label],axis =1 )\niris_test_pred.head()","098f522b":"## Accuracy Score\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy Score:', accuracy_score(iris_test_label,iris_pred_label)*100.0, '%')\n","98319e5d":"from sklearn import metrics\nimport seaborn as sns\n\n## Creates a Confusion Matrix\ncm = metrics.confusion_matrix(iris_test_label,iris_pred_label) \n\n## Transform it to DF\ncm_df = pd.DataFrame(cm, index = ['setosa','versicolor','virginica'], columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm_df,annot=True)\nplt.title('Decision Tree \\nAccuracy:{0:.3f}'.format(accuracy_score(iris_test_label,iris_pred_label)))\nplt.ylabel('True Label')\nplt.xlabel('Predicated Label')\nplt.show()","323e9f94":"## Decision Tree IRIS Dataset Visualization\nfrom sklearn import tree\nimport graphviz\n\n#DOT data\ndot_data = tree.export_graphviz(dt,out_file=None,feature_names=iris_features,class_names=['setosa','versicolor','virginica'],filled=True)\n\n#Draw graph\ngraph = graphviz.Source(dot_data,format='png')\ngraph","0795f70a":"* [Table of Contents](#Tableofcontents)\n<a id=\"Confusion Matrix\"><\/a>\n\n## Confusion Matrix","3b83bc99":"* [Table of Contents](#Tableofcontents)\n<a id=\"DecisionTreeVisualization\"><\/a>\n\n## Decision Tree Visualization","59c0acd8":"* [Table of Contents](#Tableofcontents)\n<a id=\"FeatureSelection\"><\/a>\n## Feature Selection\n","61bd5004":"* [Table of Contents](#Tableofcontents)\n<a id=\"SplitDataintoTrainandTest\"><\/a>\n## Split data into Train and Test","02ed5763":"* [Table of Contents](#Tableofcontents)\n<a id=\"ModelEvaluation\"><\/a>\n\n## Model Evaluation","4939b0af":"##### Based on the feature selection, we are dropping the sepal.width feature whose variance is 0.188 here.","c146f851":"* [Table of Contents](#Tableofcontents)\n<a id=\"References\"><\/a>\n    \n## References","05e9f0d3":"* [Table of Contents](#Tableofcontents)\n<a id=\"EDA\"><\/a>\n\n\n## EDA","896d6a66":"<a id=\"Tableofcontents\"><\/a>\n# Table of Contents\n\n* [Introduction](#Introduction)\n* [Exploratory Data Analysis](#ExploratoryDataAnalysis)\n* [Feature Engineering](#FeatureEngineering)\n* [Finding Clusters with Elbow Method](#FindingClusterswithElbowMethod)\n* [Building KMeans Model](#BuildingKMeansModel)\n* [Conclusion](#Conclusion)\n* [References](#References)","0025ebad":"* [Table of Contents](#Tableofcontents)\n<a id=\"ModelBuilding\"><\/a>\n\n## Model Building","a0b6ed25":"## Dphi ML Video by Farhan","5530c60b":"* [Table of Contents](#Tableofcontents)\n<a id=\"DecisionTreeClassifier\"><\/a>\n\n## Decision Tree Classifier","eb42f705":"#### By default, VarianceThreshold removes only zero-variance features. i.e., feature has the same value in all instances. In this problem statement, we will remove variance score below 0.2 value by specifying threshold parameter.","2100a3ae":"## Main intension of developing this project is to understand the Feature Selection handling during Classification problem. ~ Easy understanding for Intermediate DS\n\n### Happy Learning!!!"}}