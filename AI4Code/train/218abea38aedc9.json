{"cell_type":{"27e6b45d":"code","7bb73f18":"code","753d3e18":"code","609075ba":"code","08fdd778":"code","c5e37fca":"code","f0c75bf2":"code","30fe8f95":"code","304b711b":"code","bdd17371":"code","1d65d2da":"code","cf93a2a2":"code","a26a9f07":"code","27ae6f78":"code","b84e9b77":"code","7ce278d2":"code","5e14b094":"code","f28b326f":"markdown","9709ad30":"markdown","c49fc6b4":"markdown","3f127220":"markdown","2cb3aca9":"markdown"},"source":{"27e6b45d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport random\nimport os\nimport cv2\nimport sys\nfrom pylab import rcParams\nfrom PIL import Image\nfrom tqdm import tqdm\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7bb73f18":"#Seed everything for reproducible results\nimport random\nfrom numpy.random import seed\nfrom tensorflow.random import set_seed\n\nseed_value = 42\nrandom.seed(seed_value)\nseed(seed_value)\nset_seed(seed_value)","753d3e18":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\nfrom sklearn.model_selection import StratifiedKFold","609075ba":"policy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy) #shortens training time by 2x","08fdd778":"gps = pd.read_csv(\"..\/input\/offroad-terrain-dataset-for-autonomous-vehicles\/SensorData\/2020-10-02-10-17-05\/gps.csv\")\ngps.head()","c5e37fca":"df_train = pd.read_csv(\"..\/input\/offroad-terrain-dataset-for-autonomous-vehicles\/ImageLabels\/tsm_1_labels.csv\")\ndf_train.head()","f0c75bf2":"df2_train = pd.read_csv(\"..\/input\/offroad-terrain-dataset-for-autonomous-vehicles\/ImageLabels\/tsm_2_labels.csv\")\ndf2_train.head()","30fe8f95":"#df_train[\"tsm1_original\"] = df_train[\"tsm1_original\"].astype(str) #convert to str as we want to use cross entropy loss later\ndf_train.info()","304b711b":"batch_size=32\nimage_size=300\n\ninput_shape = (image_size, image_size, 3)\ntarget_size = (image_size, image_size)\nimg_augmentation = tf.keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomCrop(image_size, image_size),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.25),\n        tf.keras.layers.experimental.preprocessing.RandomContrast(0.2)\n    ])","bdd17371":"path = \"..\/input\/offroad-terrain-dataset-for-autonomous-vehicles\/Images\/Images\/2020-09-24\/\"\nfiles = df_train[\"image\"].tolist()\nfile = random.choice(files)\nimage = Image.open(\"..\/input\/offroad-terrain-dataset-for-autonomous-vehicles\/Images\/Images\/2020-09-24\/969904752s168ms.jpg\")\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()","1d65d2da":"image = tf.expand_dims(np.array(image), 0)\n\nplt.figure(figsize=(14, 14))\nfor i in range(9):\n    augmented_image = img_augmentation(image)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_image[0])\n    plt.axis(\"off\")","cf93a2a2":"#df_train[\"tsm1_original\"] = df_train[\"tsm1_original\"].astype(str) #convert to str as we want to use cross entropy loss later","a26a9f07":"def DataGenerator(train_set, val_set):\n    \n    train_datagen = ImageDataGenerator().flow_from_dataframe(\n                  dataframe = train_set,\n                  directory='..\/input\/offroad-terrain-dataset-for-autonomous-vehicles\/Images\/Images\/',\n                  x_col='image',\n                  y_col='tsm1_original',\n                  target_size=target_size,\n                  batch_size=batch_size,\n                  shuffle=True,\n                  class_mode='sparse',\n                  seed=seed_value)\n\n    val_datagen = ImageDataGenerator().flow_from_dataframe(\n                dataframe = val_set,\n                directory='..\/input\/offroad-terrain-dataset-for-autonomous-vehicles\/Images\/Images\/',\n                x_col='image',\n                y_col='tsm1_original',\n                target_size=target_size,\n                batch_size=batch_size,\n                shuffle=False,\n                class_mode='sparse',\n                seed=seed_value)\n    \n    return train_datagen, val_datagen","27ae6f78":"epochs = 3\ntotal_steps = (int(len(df_train)*0.8\/batch_size)+1)*epochs\n\nlr = tf.keras.experimental.CosineDecay(initial_learning_rate=1e-3, decay_steps=total_steps)","b84e9b77":"def build_model():\n    base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n\n    # Rebuild top\n    inputs = Input(shape=input_shape)\n    base = base_model(inputs)\n    pooling = GlobalAveragePooling2D()(base)\n    outputs = Dense(5, activation=\"softmax\", dtype='float32')(pooling) #necessary for mixed-precision training to work properly\n\n    # Compile\n    model = Model(inputs=inputs, outputs=outputs)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n    return model","7ce278d2":"fold_number = 1\nn_splits = 5\noof_accuracy = []\n\ntf.keras.backend.clear_session()\nskf = StratifiedKFold(n_splits=n_splits, random_state=None)\nfor train_index, val_index in skf.split(df_train[\"image\"], df_train[\"tsm1_original\"]):\n    train_set = df_train.loc[train_index]\n    val_set = df_train.loc[val_index]\n    train_datagen, val_datagen = DataGenerator(train_set, val_set)\n    model = build_model()\n    print(\"Training fold no.: \" + str(fold_number+1))\n\n    model_name = \"effnetb0 \"\n    fold_name = \"fold.h5\"\n    filepath = model_name + str(fold_number+1) + fold_name\n    callbacks = [ModelCheckpoint(filepath=filepath, monitor='val_accuracy', save_best_only=True)]\n\n    history = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n    oof_accuracy.append(max(history.history[\"val_accuracy\"]))\n    fold_number += 1\n    if fold_number == n_splits:\n        print(\"Training finished!\")","5e14b094":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, @mpwolke Was here' )","f28b326f":"#Image Augmentation","9709ad30":"#Codes by Junyi Ng https:\/\/www.kaggle.com\/junyingsg\/step-by-step-guide-to-denoising-your-labels","c49fc6b4":"#ValueError: Asked to retrieve element 0, but the Sequence has length 0","3f127220":"#Augmentation helps the model generalize better. What images can look like after augmentation.","2cb3aca9":"![](https:\/\/www.gminsights.com\/assets\/img\/all-terrain-vehicle-atv-market-pressrelease.png)gminsights.com"}}