{"cell_type":{"01a5acbd":"code","e08a4f38":"code","d51e09de":"code","5a0a923b":"code","75d5435e":"code","174ac7c0":"code","e00ebb35":"code","a4d22af3":"code","8d1d8984":"code","3ab22817":"code","7db4309a":"code","048b032b":"code","58e8b800":"code","98d6f4db":"code","2d7a1b6c":"code","b5a60650":"code","b73b6946":"code","d487eb08":"code","30158a28":"code","95357baf":"code","bacb7e7b":"code","5b78bf6a":"code","5cdffa7e":"code","7bb7c4f4":"code","01642f7c":"code","ff37d802":"code","6c487b88":"code","aaeadb7c":"code","90e9d395":"code","5bbd5e8e":"code","6e4777f1":"code","033579bb":"code","68540a93":"code","98448d1e":"code","a9af4b2e":"code","653480e1":"code","d3a8ad07":"code","aadca49e":"code","2b07e19c":"code","1505ddc9":"code","d06e0979":"code","6a89336d":"code","99388393":"code","397120b1":"code","dd61e00c":"code","76051df8":"code","3b99be1e":"code","b9275ba2":"code","eb2351b6":"code","79b35381":"code","b2c0c432":"code","26636a18":"code","c7fce0dc":"code","9e17a453":"code","5307f304":"markdown","2b3bfd26":"markdown","7be023f6":"markdown","0da38c79":"markdown","bc14687a":"markdown","193f3bc9":"markdown","370e9032":"markdown","087a212c":"markdown","bb46e873":"markdown","df5d41af":"markdown","a81920e7":"markdown","28698d7f":"markdown","422c13a1":"markdown","6ab236ec":"markdown","b188b036":"markdown","a83c62c2":"markdown","05a6d72d":"markdown","bf7f0195":"markdown"},"source":{"01a5acbd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nfrom matplotlib import pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e08a4f38":"!apt-get install p7zip\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/train.tsv.7z\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/test.tsv.7z\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/sample_submission.csv.7z","d51e09de":"!unzip \/kaggle\/input\/mercari-price-suggestion-challenge\/sample_submission_stg2.csv.zip\n!unzip \/kaggle\/input\/mercari-price-suggestion-challenge\/test_stg2.tsv.zip","5a0a923b":"train = pd.read_csv('train.tsv', sep = '\\t')\ntest = pd.read_csv('test_stg2.tsv', sep='\\t')","75d5435e":"print (\"Train data shape:\", train.shape)\nprint (\"Test data shape:\", test.shape)","174ac7c0":"train.head()","e00ebb35":"train.info()","a4d22af3":"train.describe()","8d1d8984":"full_data = pd.concat([train, test], sort=False)","3ab22817":"full_data.isnull().sum()","7db4309a":"print(pd.isnull(train).sum())\nprint(\"------------\")\nprint(pd.isnull(test).sum())","048b032b":"train.brand_name.fillna(value = \"NoBrand\", inplace = True)\ntest.brand_name.fillna(value = \"NoBrand\", inplace = True)\n\ntrain.category_name.fillna(value = \"Other\/Other\/Other\", inplace = True)\ntest.category_name.fillna(value = \"Other\/Other\/Other\", inplace = True)\n\ntrain.item_description.fillna(value = \"No description yet\", inplace = True)\ntest.item_description.fillna(value = \"No description yet\", inplace = True)","58e8b800":"print(train.isnull().any())\nprint(\"------------\")\nprint(test.isnull().any())","98d6f4db":"def split(txt):\n    try :\n        return txt.split(\"\/\")\n    except :\n        return (\"Other\", \"Other\", \"Other\")\n","2d7a1b6c":"train['general_category']='' \ntrain['subcategory_1'] = '' \ntrain['subcategory_2'] = ''\n\ntest['general_category']='' \ntest['subcategory_1'] = '' \ntest['subcategory_2'] = ''\n","b5a60650":"train['general_category'],train['subcategory_1'],train['subcategory_2'] = \\\nzip(*train['category_name'].apply(lambda x: split(x)))\n\ntest['general_category'],test['subcategory_1'],test['subcategory_2'] = \\\nzip(*test['category_name'].apply(lambda x: split(x)))\n","b73b6946":"train","d487eb08":"train.head()","30158a28":"train.price.plot.hist(bins=50, figsize=(8,4), edgecolor='white',range=[0,300])\n\nplt.title('Price Distribution')","95357baf":"%matplotlib inline\nimport matplotlib.pyplot as plt\ntrain.hist(bins=50, figsize=(20,15))\nplt.show()","bacb7e7b":"train['item_description'].value_counts()","5b78bf6a":"train['item_condition_id'].value_counts().plot(kind='bar')","5cdffa7e":"train['brand_name'].value_counts()","7bb7c4f4":"train['general_category'].value_counts().plot(kind='bar')","01642f7c":"train['subcategory_1'].value_counts().plot(kind='bar')\ntrain['subcategory_1'].value_counts()","ff37d802":"train['subcategory_2'].value_counts().plot(kind='bar')\ntrain['subcategory_2'].value_counts()","6c487b88":"log_prices = np.log1p(train.price)\nlog_prices.hist()","aaeadb7c":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_item_condition_id = scaler.fit_transform(train['item_condition_id'].values.reshape(-1,1))","90e9d395":"from sklearn.preprocessing import LabelBinarizer\n\nlb_brand_name = LabelBinarizer(sparse_output=True)\nX_train_brand = lb_brand_name.fit_transform(train['brand_name'])\n\nlb_shipping = LabelBinarizer(sparse_output=True)\nX_train_shipping = lb_shipping.fit_transform(train['shipping'])\n\nlb_cat_0 = LabelBinarizer(sparse_output=True)\nX_train_general_category = lb_cat_0.fit_transform(train['general_category'])\n\nlb_cat_1 = LabelBinarizer(sparse_output=True)\nX_train_subcategory_1 = lb_cat_1.fit_transform(train['subcategory_1'])\n\nlb_cat_2 = LabelBinarizer(sparse_output=True)\nX_train_subcategory_2 = lb_cat_2.fit_transform(train['subcategory_2'])\n","5bbd5e8e":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\ntfidf_desc = TfidfVectorizer(max_features=50000, ngram_range=(1, 1), stop_words='english', norm='l2',lowercase=True)\nname_vectorizer = CountVectorizer(stop_words='english')\n\nX_train_descp = tfidf_desc.fit_transform(train['item_description'])\nX_train_name = name_vectorizer.fit_transform(train['name'])\n","6e4777f1":"from scipy.sparse import hstack\n\nX_train = hstack((X_train_name, X_train_descp, X_train_brand, X_train_item_condition_id, X_train_shipping, X_train_general_category, X_train_subcategory_1, X_train_subcategory_2)).tocsr()\n","033579bb":"X_train","68540a93":"corr_matrix = train.corr()\ncorr_matrix","98448d1e":"from scipy.sparse import hstack\nX_train = hstack((X_train_name, X_train_descp, X_train_brand, X_train_item_condition_id, \nX_train_shipping, X_train_general_category, X_train_subcategory_1, X_train_subcategory_2)).tocsr()","a9af4b2e":"import seaborn as sns\n\nsns.heatmap(corr_matrix, \n            xticklabels=corr_matrix.columns.values,\n            yticklabels=corr_matrix.columns.values)","653480e1":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\nfor train_index, test_index in split.split(train, train['general_category']):\n    train_idx = train_index\n    test_idx = test_index","d3a8ad07":"test_data = X_train[test_idx]\nlog_test_prices = log_prices.iloc[test_idx]\ntrain_data = X_train[train_idx]\nlog_train_prices = log_prices.iloc[train_idx]","aadca49e":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\ndef performance(ytrue, ypredicted):\n    print(\"MSE: \",np.sqrt(mean_squared_error(ytrue, ypredicted))) \n    print(\"MAE: \", np.sqrt(mean_absolute_error(ytrue, ypredicted)))","2b07e19c":"#from sklearn.linear_model import LinearRegression \n#regressor = LinearRegression() \n#regressor.fit(train_data, log_train_prices)","1505ddc9":"#y_pred = regressor.predict(test_data)","d06e0979":"#from sklearn.metrics import mean_absolute_error\n#from sklearn.metrics import mean_squared_error\n    \n#performance(log_test_prices, y_pred)","6a89336d":"from sklearn.linear_model import SGDRegressor\n\n# SkLearn SGD classifier\nclf_ = SGDRegressor()\nclf_.fit(train_data, log_train_prices)\nperformance(log_test_prices, clf_.predict(test_data))","99388393":"from sklearn.linear_model import LinearRegression, Ridge, \\\n                                 RidgeCV, Lasso, LassoCV, \\\n                                 ElasticNet, ElasticNetCV","397120b1":"#lasso = Lasso(max_iter = 100000, normalize = True)\n\n#lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n#lassocv.fit(train_data, log_train_prices)\n\n#lasso.set_params(alpha=lassocv.alpha_)\n#lasso.fit(train_data, log_train_prices)\n\n#print('The Lasso I:')\n#print(\"Alpha =\", lassocv.alpha_)\n#performance(log_test_prices, lasso.predict(test_data))\n","dd61e00c":"ridge_lin_reg = Ridge(alpha=4, max_iter= 500)\nridge_lin_reg.fit(train_data, log_train_prices)\n\nperformance(log_test_prices,ridge_lin_reg.predict(test_data))","76051df8":"from sklearn.svm import SVR\n\nkernel_SVR = SVR(kernel='rbf', verbose=True, max_iter= 1000)\nkernel_SVR.fit(train_data, log_train_prices)\n\nperformance(log_test_prices,kernel_SVR.predict(test_data))","3b99be1e":"MSE:  0.6012809577308371\nMAE:  0.6765551529927671","b9275ba2":"\n#from sklearn.ensemble import RandomForestRegressor\n\n#forest_reg = RandomForestRegressor(verbose=True, max_depth=15, n_estimators=30)\n#forest_reg.fit(train_data, log_train_prices)\n\n#performance(log_test_prices, forest_reg.predict(test_data))","eb2351b6":"MSE:  0.59995163968476\nMAE:  0.6796141406429075","79b35381":"#from lightgbm import LGBMRegressor","b2c0c432":"\n#lgbm_model = LGBMRegressor(verbose=0, max_depth=15, n_estimators=30)\n#lgbm_model.fit(train_data, log_train_prices, verbose=0)\n\n#performance(log_test_prices,lgbm_model.predict(test_data))","26636a18":"from sklearn.model_selection import PredefinedSplit\n","c7fce0dc":"split_index = [-1 if x in train_idx else 0 for x in range(X_train.shape[0])]\n","9e17a453":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\nparam_distribs = {\n        'n_estimators': randint(low=5, high=200),\n        'max_depth': randint(low=10, high=100),\n    }\n\nlgbm_srch = LGBMRegressor()\npds = PredefinedSplit(test_fold = split_index)\n\nrnd_search = RandomizedSearchCV(lgbm_srch, param_distributions=param_distribs,\n                                n_iter=20, cv=pds, scoring='neg_mean_squared_error')\n\nrnd_search.fit(X_train, log_prices)\nperformance(log_test_prices,rnd_search.best_estimator_.predict(test_data))","5307f304":"> **5) Random forest**","2b3bfd26":" **While LGBM has the least of error, SO need to fine-tune it**","7be023f6":"# 3- Stratified sampling\n","0da38c79":"**The correlation with price**","bc14687a":"> **3) Ridge & Lasso**","193f3bc9":"**I took MSE From Colab Note book because it took too much time to run Same also in LGBM regressor**","370e9032":"> **6) LGBM Regressor**","087a212c":"> ****Linear Regression, Lasso, Random forest, and LGBM Regressor took too much time to run ****","bb46e873":"> **4) SVR**","df5d41af":"# 5- Fine-tune model","a81920e7":"# 4- Obtain selected models","28698d7f":"> # 1) Missing data","422c13a1":"> # 2) Subclasses","6ab236ec":"# 2- Data Preprocessing","b188b036":"# 1- Get Data","a83c62c2":"> # 3) EDA","05a6d72d":"> **1) Linear Regression**","bf7f0195":"> **2) SGD Regressor**"}}