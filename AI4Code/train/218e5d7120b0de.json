{"cell_type":{"37be4a15":"code","7d3186a8":"code","5beb3308":"code","ab88a836":"code","7c0162ef":"code","52007e47":"code","4f289ded":"code","ba66deda":"code","0b4148a7":"code","36df0a02":"code","8c8bab0c":"code","2385cb08":"code","a81c17d2":"code","3d9b009f":"code","efa98acf":"code","fe64b66c":"code","ebd7f03d":"code","f26be4f1":"code","3ea2b717":"code","e0128af6":"markdown","7952a1c8":"markdown","5b1c2ca1":"markdown","22297264":"markdown","a5a61382":"markdown","9fecd296":"markdown","e66f022b":"markdown","e37bae42":"markdown","0d768f89":"markdown","64068d00":"markdown","da42350e":"markdown","5fe0c841":"markdown","bee012ac":"markdown","949e0bc3":"markdown","69044138":"markdown","2e14ef3f":"markdown","8fba22b9":"markdown","6c45e571":"markdown"},"source":{"37be4a15":"# Ignore harmless warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","7d3186a8":"# Load a seasonal dataset\ndf1 = pd.read_csv('..\/input\/time-series-test\/airline_passengers.csv',index_col='Month',parse_dates=True)\ndf1.index.freq = 'MS'\n\n# Load a nonseasonal dataset\ndf2 = pd.read_csv('..\/input\/time-series-test\/DailyTotalFemaleBirths.csv',index_col='Date',parse_dates=True)\ndf2.index.freq = 'D'","5beb3308":"df1.head()","ab88a836":"df2.head()","7c0162ef":"from statsmodels.tsa.stattools import ccovf,ccf,periodogram\nfrom statsmodels.tsa.stattools import adfuller,kpss,coint,bds,q_stat,grangercausalitytests,levinson_durbin\nfrom statsmodels.tools.eval_measures import mse, rmse, meanabs\n\n# Alternative:\n# from sklearn.metrics import mean_squared_error","52007e47":"df1['12-month-SMA'] = df1['Thousands of Passengers'].rolling(window=12).mean()\ndf1['12-month-Std'] = df1['Thousands of Passengers'].rolling(window=12).std()\n\nfig = plt.figure(dpi = 120)\nax = plt.axes()\nax.set(xlabel = 'Month',ylabel = 'Passengers',title = 'Moving Avg. and STD')\ndf1[['Thousands of Passengers','12-month-SMA','12-month-Std']].plot(figsize = (8,4),lw = 2,ax=ax,color = ['blue','red','green']);","4f289ded":"dftest = adfuller(df1['Thousands of Passengers'],autolag='AIC')\n\nprint('Augmented Dickey-Fuller Test on Airline Data\\n')\n\ndfout = pd.Series(dftest[0:4],index=['ADF test statistic','p-value','# lags used','# observations'])\n\nfor key,val in dftest[4].items():\n    dfout[f'critical value ({key})']=val\nprint(dfout)","ba66deda":"df2['30-Day-SMA'] = df2['Births'].rolling(window=30).mean()\ndf2['30-Day-Std'] = df2['Births'].rolling(window=30).std()\n\nfig = plt.figure(dpi = 120)\nax = plt.axes()\nax.set(xlabel = 'Date',ylabel = 'Birth',title = 'Moving Avg. and STD')\ndf2[['Births','30-Day-SMA','30-Day-Std']].plot(figsize = (8,4),lw = 2,ax=ax,color = ['blue','red','green']);","0b4148a7":"print('Augmented Dickey-Fuller Test on Daily Female Births\\n')\ndftest = adfuller(df2['Births'],autolag='AIC')\n\ndfout = pd.Series(dftest[0:4],index=['ADF test statistic','p-value','# lags used','# observations'])\n\nfor key,val in dftest[4].items():\n    dfout[f'critical value ({key})']=val\nprint(dfout)","36df0a02":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(series,title=''):\n    \"\"\"\n    Pass in a time series and an optional title, returns an ADF report\n    \"\"\"\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n    \n    labels = ['ADF test statistic','p-value','# lags used','# observations']\n    out = pd.Series(result[0:4],index=labels)\n\n    for key,val in result[4].items():\n        out[f'critical value ({key})']=val\n        \n    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n    \n    if result[1] <= 0.05:\n        print(\"\\nStrong evidence against the null hypothesis\")\n        print(\"Reject the null hypothesis\")\n        print(\"Data has no unit root and is stationary\")\n    else:\n        print(\"\\nWeak evidence against the null hypothesis\")\n        print(\"Fail to reject the null hypothesis\")\n        print(\"Data has a unit root and is non-stationary\")","8c8bab0c":"adf_test(df1['Thousands of Passengers'])","2385cb08":"df3 = pd.read_csv('..\/input\/time-series-test\/samples.csv',index_col=0,parse_dates=True)\ndf3.index.freq = 'MS'\n\nfig = plt.figure(dpi = 120)\nax = plt.axes()\ndf3[['a','d']].plot(figsize = (8,4),lw = 2,ax=ax,color = ['blue','red']);","a81c17d2":"df3['dShift'] = df3['d'].shift(2)\n\nfig = plt.figure(dpi = 120)\nax = plt.axes()\ndf3[['a','dShift']].plot(figsize = (8,4),lw = 2,ax=ax,color = ['blue','red']);","3d9b009f":"# Add a semicolon at the end to avoid duplicate output\ngrangercausalitytests(df3[['a','d']],maxlag=2);","efa98acf":"# Add a semicolon at the end to avoid duplicate output\ngrangercausalitytests(df3[['b','d']],maxlag=2);","fe64b66c":"np.random.seed(42)\ndf = pd.DataFrame(np.random.randint(20,30,(50,2)),columns=['test','predictions'])\n\nfig = plt.figure(dpi = 120)\nax = plt.axes()\ndf.plot(figsize = (8,4),lw = 2,ax=ax,color = ['blue','red']);","ebd7f03d":"from statsmodels.tools.eval_measures import mse, rmse, meanabs\n\n\nMSE = mse(df['test'],df['predictions'])\nRMSE = rmse(df['test'],df['predictions'])\nMAE = meanabs(df['test'],df['predictions'])\n\nprint(f'Model  MSE: {MSE:.3f}')\nprint(f'Model RMSE: {RMSE:.3f}')\nprint(f'Model  MAE: {MAE:.3f}')","f26be4f1":"from statsmodels.graphics.tsaplots import month_plot,quarter_plot\n\nfig = plt.figure(dpi = 120)\nax = plt.axes()\nax.set(xlabel = 'Months',ylabel='Qunatity',title = 'Month Plot')\nmonth_plot(df1['Thousands of Passengers'],ax = ax);","3ea2b717":"dfq = df1['Thousands of Passengers'].resample(rule='Q').mean()\n\nfig = plt.figure(dpi = 120)\nax = plt.axes()\nax.set(xlabel = 'Quarters',ylabel='Qunatity',title = 'Quarter Plot')\n\n\nquarter_plot(dfq,ax = ax);","e0128af6":"##### We can see there are more people travelling during the summer and vacation june july","7952a1c8":"Here we have a very high p-value at 0.99, which provides weak evidence against the null hypothesis, and so we <em>fail to reject<\/em> the null hypothesis, and decide that our dataset is not stationary.<br>\nNote: in statistics we don't \"accept\" a null hypothesis - nothing is ever truly proven - we just fail to reject it.\n<br><br>\nNow let's apply the ADF test to stationary data with the Daily Total Female Births dataset.","5b1c2ca1":"That's it! P value is not less than 0.05 !!","22297264":"Essentially we're looking for extremely low p-values, which we see at lag 2.<br>\n\nBy comparison, let's compare two datasets that are not at all similar, 'b' and 'd'.","a5a61382":"> Not only is this dataset seasonal with a clear upward trend, the standard deviation increases over time as well.","9fecd296":"### Run the test\nThe function takes in a 2D array [y,x] and a maximum number of lags to test on x. Here our y is column 'a' and x is column 'd'. We'll set maxlags to 3.","e66f022b":"# Evaluation\n\nTwo calculations related to linear regression are <a href='https:\/\/en.wikipedia.org\/wiki\/Mean_squared_error'><strong>mean squared error<\/strong><\/a> (MSE) and <a href='https:\/\/en.wikipedia.org\/wiki\/Root-mean-square_deviation'><strong>root mean squared error<\/strong><\/a> (RMSE)\n\nThe formula for the mean squared error is<br><br>\n&nbsp;&nbsp;&nbsp;&nbsp;$MSE = {\\frac 1 L} \\sum\\limits_{l=1}^L (y_{T+l} - \\hat y_{T+l})^2$<br><br>\nwhere $T$ is the last observation period and $l$ is the lag point up to $L$ number of test observations.\n\nThe formula for the root mean squared error is<br><br>\n&nbsp;&nbsp;&nbsp;&nbsp;$RMSE = \\sqrt{MSE} = \\sqrt{{\\frac 1 L} \\sum\\limits_{l=1}^L (y_{T+l} - \\hat y_{T+l})^2}$<br><br>\n\nThe advantage of the RMSE is that it is expressed in the same units as the data.<br><br>\n\nA method similar to the RMSE is the <a href='https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_error'><strong>mean absolute error<\/strong><\/a> (MAE) which is the mean of the magnitudes of the error, given as<br><br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;$MAE = {\\frac 1 L} \\sum\\limits_{l=1}^L \\mid{y_{T+l}} - \\hat y_{T+l}\\mid$<br><br>\n\nA forecast method that minimizes the MAE will lead to forecasts of the median, while minimizing the RMSE will lead to forecasts of the mean.","e37bae42":"It's hard to tell from this overlay but <tt>df['d']<\/tt> almost perfectly predicts the behavior of <tt>df['a']<\/tt>.<br>\nTo see this more clearly (spoiler alert!), we will shift <tt>df['d']<\/tt> two periods forward.","0d768f89":"In this case our p-value is very low at 0.000052, and we do reject the null hypothesis. This dataset appears to have no unit root, and is stationary.","64068d00":"## Function for running the augmented Dickey-Fuller test\n\nSince we'll use it frequently, let's define a function we can copy into future notebooks for running the augmented Dickey-Fuller test. Remember that we'll still have to import <tt>adfuller<\/tt> at the top of our notebook.","da42350e":"# Introduction\n\n![](https:\/\/cdn.app.compendium.com\/uploads\/user\/a7c086f7-9adb-4d2c-90fa-e26177af8317\/7531d8dc-7cb5-440d-9cd9-92d90120c751\/File\/220ff0c46068005baef585b112ea9040\/time_series_forecasting_banner.jpg)\n\nThere are different forecasting models like ARMA, ARIMA, Seasonal ARIMA and others. Each model addresses a different type of time series. For this reason, in order to select an appropriate model we need to know something about the data.\n\nIn this section we'll learn how to determine if a time series is <em>stationary<\/em>, if it's <em>independent<\/em>, and if two series demonstrate <em>correlation<\/em> and\/or <em>causality<\/em>.","5fe0c841":"### Great job! I hope you liked it :) Please feel free to suggest anything and give me a feedback. Please up vote my work if you like it !!","bee012ac":"# Granger Causality Tests\nThe <a href='https:\/\/en.wikipedia.org\/wiki\/Granger_causality'>Granger causality test<\/a> is a a hypothesis test to determine if one time series is useful in forecasting another. While it is fairly easy to measure correlations between series - when one goes up the other goes up, and vice versa - it's another thing to observe changes in one series correlated to changes in another after a consistent amount of time. This <em>may<\/em> indicate the presence of causality, that changes in the first series influenced the behavior of the second. However, it may also be that both series are affected by some third factor, just at different rates. Still, it can be useful if changes in one series can predict upcoming changes in another, whether there is causality or not. In this case we say that one series \"Granger-causes\" another.\n\nIn the case of two series, $y$ and $x$, the null hypothesis is that lagged values of $x$ do <em>not<\/em> explain variations in $y$.<br>\nIn other words, it assumes that $x_t$ doesn\u2019t Granger-cause $y_t$.\n\nThe stattools <tt><strong>grangercausalitytests<\/strong><\/tt> function offers four tests for granger non-causality of 2 timeseries\n\nFor this example we'll use the samples.csv file, where columns 'a' and 'd' are stationary datasets.","949e0bc3":"> We can see that after shifting by 2, D is perfectly explaining time series a, Let us test !!","69044138":"# AIC \/ BIC\n\nMore sophisticated tests include the <a href='https:\/\/en.wikipedia.org\/wiki\/Akaike_information_criterion'><strong>Akaike information criterion<\/strong><\/a> (AIC) and the <a href='https:\/\/en.wikipedia.org\/wiki\/Bayesian_information_criterion'><strong>Bayesian information criterion<\/strong><\/a> (BIC).\n\nThe AIC evaluates a collection of models and estimates the quality of each model relative to the others. Penalties are provided for the number of parameters used in an effort to thwart overfitting. The lower the AIC and BIC, the better the model should be at forecasting.\n\nThese functions are available as\n\n&nbsp;&nbsp;&nbsp;&nbsp;<tt>from from statsmodels.tools.eval_measures import aic, bic<\/tt>\n\nbut we seldom compute them alone as they are built into many of the statsmodels tools we use.","2e14ef3f":"# Stationarity Test\n\nA time series is <em>stationary<\/em> if the mean and variance are fixed between any two equidistant points. That is, no matter where you take your observations, the results should be the same. A times series that shows seasonality is <em>not<\/em> stationary.\n\nA test for stationarity usually involves a <a href='https:\/\/en.wikipedia.org\/wiki\/Unit_root_test'>unit root<\/a> hypothesis test, where the null hypothesis $H_0$ is that the series is <em>nonstationary<\/em>, and contains a unit root. The alternate hypothesis $H_1$ supports stationarity. The <a href='https:\/\/en.wikipedia.org\/wiki\/Augmented_Dickey-Fuller_test'>augmented Dickey-Fuller<\/a> and <a href='https:\/\/en.wikipedia.org\/wiki\/KPSS_test'>Kwiatkowski-Phillips-Schmidt-Shin<\/a> tests are stationarity tests. ","8fba22b9":"## Augmented Dickey-Fuller Test\n\nTo determine whether a series is stationary we can use the <a href='https:\/\/en.wikipedia.org\/wiki\/Augmented_Dickey-Fuller_test'>augmented Dickey-Fuller Test<\/a>. In this test the null hypothesis states that $\\phi = 1$ (this is also called a unit test). The test returns several statistics we'll see in a moment. Our focus is on the p-value. A small p-value ($p<0.05$) indicates strong evidence against the null hypothesis.\n\nTo demonstrate, we'll use a dataset we know is <em>not<\/em> stationary, the airline_passenger dataset. First, let's plot the data along with a 12-month rolling mean and standard deviation:","6c45e571":"# Month and Quarter Plots\nStatsmodels has two plotting functions that group data by month and by quarter. Note that if the data appears as months, you should employ <em>resampling<\/em> with an aggregate function before running a quarter plot. These plots return a <tt>matplotlib.Figure<\/tt> object."}}