{"cell_type":{"4e953afe":"code","31a8e1b1":"code","390f93a8":"code","d9f91c37":"code","516dfe36":"code","fc0be26b":"code","f95755ae":"code","cee15390":"code","2902d4f8":"code","80eb99f4":"code","ab04984b":"code","716eff88":"code","aa961659":"code","ba2d93dd":"code","ef12f5c9":"code","07d1763f":"code","e8111546":"code","ede8985c":"code","29775a75":"code","6f2033f9":"code","ebada9ef":"markdown","ebc7aef6":"markdown","807cd570":"markdown","7745a0d9":"markdown","ff333cca":"markdown","498ec1a3":"markdown","15af7bfa":"markdown","2094455e":"markdown","4c8a7fbf":"markdown","abbf70fb":"markdown","035ae2f2":"markdown","946a3144":"markdown","f551ef2c":"markdown","e9bcd98d":"markdown","e8489118":"markdown","3860bf3b":"markdown","65977315":"markdown","fb5a2502":"markdown","ee04de37":"markdown","7929523a":"markdown"},"source":{"4e953afe":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","31a8e1b1":"!python -m pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'","390f93a8":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport pandas as pd \n\nfrom tqdm import tqdm\nfrom tqdm import tqdm_notebook as tqdm # progress bar\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\nfrom datetime import datetime\nimport time\nimport matplotlib.pyplot as plt\n\nimport os, json, cv2, random\nimport skimage.io as io\nimport copy\nfrom pathlib import Path\nfrom typing import Optional\nimport json\nimport matplotlib.pyplot as plt\n\nimport ast\n\n\nfrom tqdm import tqdm\nimport itertools\n\nimport torch\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom glob import glob\nimport numba\nfrom numba import jit\n\nfrom pycocotools.coco import COCO\n# detectron2\nfrom detectron2.structures import BoxMode\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer, launch\nfrom detectron2.evaluation import COCOEvaluator\nfrom detectron2.structures import BoxMode\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.utils.visualizer import Visualizer\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\n\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\nimport detectron2.data.transforms as T\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n\n\n\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nimport pycocotools.mask as mask_util\nfrom detectron2.engine import BestCheckpointer\nfrom detectron2.checkpoint import DetectionCheckpointer\n\nsetup_logger()\n","d9f91c37":"df_train = pd.read_csv('..\/input\/car-object-detection\/data\/train_solution_bounding_boxes (1).csv')","516dfe36":"x_min = df_train['xmin']\ny_min = df_train['ymin']\nx_max = df_train['xmax']\ny_max = df_train['ymax']\nbboxes = list()\nfor i in range(len(x_min)):\n    bboxes.append([[x_min[i],y_min[i],x_max[i],y_max[i]]])\ndf_train['bboxes'] = bboxes","fc0be26b":"df_train[\"Width\"]=676\ndf_train[\"Height\"]=380\ndf_train.sample(2)","f95755ae":"train_path = '..\/input\/car-object-detection\/data\/training_images\/'\npath = list()\nfor i in df_train['image']:\n    path.append(train_path + i )","cee15390":"df_train['image_path'] = path\ndf_train.sample(2)","2902d4f8":"id = list()\nfor i in df_train['image']:\n    id.append(i[:-4])","80eb99f4":"df_train['image_id'] = id\ndf_train.sample(2)","ab04984b":"n_spl=3\nSelected_Fold=2 #0..2\n\nfrom sklearn.model_selection import GroupKFold\ngkf  = GroupKFold(n_splits = n_spl) # num_folds=3 as there are total 3 videos\ndf_train = df_train.reset_index(drop=True)\ndf_train['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(df_train, groups = df_train.image_id.tolist())):\n    df_train.loc[val_idx, 'fold'] = fold\ndisplay(df_train.fold.value_counts())","716eff88":"def get_data_dicts(\n    _train_df: pd.DataFrame,\n    debug: bool = False,\n    data_type:str=\"train\"\n   \n):\n\n    if debug:\n        _train_df = _train_df.iloc[:10]  # For debug...\n    dataset_dicts = []\n    if data_type==\"train\":\n        _train_df=_train_df[_train_df.fold != Selected_Fold]\n    else: # val\n        _train_df=_train_df[_train_df.fold == Selected_Fold] \n        \n    for index, row in tqdm(_train_df.iterrows(), total=len(_train_df)):\n        record = {}\n        filename  = row.image_path #filename = str(f'{imgdir}\/{image_id}.png')\n        image_id = row.image_id\n        image_height= row.Height\n        image_width = row.Width\n        bboxes_coco = row.bboxes\n        #bboxes_coco  = np.array(row.bboxes).astype(np.float32).copy()\n        record[\"file_name\"] = filename\n        record[\"image_id\"] = image_id\n        record[\"width\"] = image_width\n        record[\"height\"] = image_height\n        objs = []\n        class_id = 0\n        for bbox_idx in range(len(bboxes_coco)):\n            bbox=bboxes_coco[bbox_idx]\n            obj = {\n                    \"bbox\": bbox,\n                    \"bbox_mode\": BoxMode.XYXY_ABS,\n                    \"category_id\": class_id,\n                }\n            objs.append(obj)\n            record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts","aa961659":"thing_classes=['car']\ndebug=False\n\nData_Resister_training=\"BR_data_train2\";\nData_Resister_valid=\"BR_data_valid2\";\n\n\nDatasetCatalog.register(\n    Data_Resister_training,\n    lambda: get_data_dicts(\n        df_train,\n        debug=debug,\n        data_type=\"train\"\n    ),\n)\nMetadataCatalog.get(Data_Resister_training).set(thing_classes=thing_classes)\n    \n\nDatasetCatalog.register(\n    Data_Resister_valid,\n    lambda: get_data_dicts(\n        df_train,\n        debug=debug,\n        data_type=\"val\"\n        ),\n    )\nMetadataCatalog.get(Data_Resister_valid).set(thing_classes=thing_classes)\n    \n\ndataset_dicts_train = DatasetCatalog.get(Data_Resister_training)\nmetadata_dicts_train = MetadataCatalog.get(Data_Resister_training)\n\ndataset_dicts_valid = DatasetCatalog.get(Data_Resister_valid)\nmetadata_dicts_valid = MetadataCatalog.get(Data_Resister_valid)","ba2d93dd":"fig, ax = plt.subplots(2, 1, figsize =(35,20))\ni=-1\nfor d in random.sample(dataset_dicts_train, 2):\n    i=i+1    \n    img = cv2.imread(d[\"file_name\"])\n    v = Visualizer(img[:, :, :],\n                   metadata=metadata_dicts_train, \n                   scale=0.5,\n                   instance_mode=ColorMode.IMAGE_BW # remove the colors of unsegmented pixels. This option is only available for segmentation models\n    )\n    out = v.draw_dataset_dict(d)\n    ax[i].grid(False)\n    ax[i].axis('off')\n    ax[i].imshow(out.get_image()[:, :, ::-1])","ef12f5c9":"import logging\nimport numpy as np\nfrom detectron2.engine.hooks import HookBase\nfrom detectron2.evaluation import inference_context\nfrom detectron2.utils.logger import log_every_n_seconds\nfrom detectron2.data import DatasetMapper, build_detection_test_loader\nimport detectron2.utils.comm as comm\nimport torch\nimport time\nimport datetime\n\nclass LossEvalHook(HookBase):\n    def __init__(self, cfg, model, data_loader):\n        self._model = model\n        self._period = cfg.TEST.EVAL_PERIOD\n        self._root = cfg.OUTPUT_DIR\n        self._data_loader = data_loader\n        self._min_mean_loss = 0.0\n        self._bfirst = True\n    \n    def _do_loss_eval(self):\n        # Copying inference_on_dataset from evaluator.py\n        total = len(self._data_loader)\n        num_warmup = min(5, total - 1)\n            \n        start_time = time.perf_counter()\n        total_compute_time = 0\n        losses = []\n        for idx, inputs in enumerate(self._data_loader):            \n            if idx == num_warmup:\n                start_time = time.perf_counter()\n                total_compute_time = 0\n            start_compute_time = time.perf_counter()\n            if torch.cuda.is_available():\n                torch.cuda.synchronize()\n            total_compute_time += time.perf_counter() - start_compute_time\n            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n            seconds_per_img = total_compute_time \/ iters_after_start\n            if idx >= num_warmup * 2 or seconds_per_img > 5:\n                total_seconds_per_img = (time.perf_counter() - start_time) \/ iters_after_start\n                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n                log_every_n_seconds(\n                    logging.INFO,\n                    \"Loss on Validation  done {}\/{}. {:.4f} s \/ img. ETA={}\".format(\n                        idx + 1, total, seconds_per_img, str(eta)\n                    ),\n                    n=5,\n                )\n            loss_batch = self._get_loss(inputs)\n            losses.append(loss_batch)\n        mean_loss = np.mean(losses)\n        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n        comm.synchronize()\n        return mean_loss\n            \n    def _get_loss(self, data):\n        # How loss is calculated on train_loop \n        metrics_dict = self._model(data)\n        metrics_dict = {\n            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n            for k, v in metrics_dict.items()\n        }\n        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n        return total_losses_reduced\n                \n    def after_step(self):\n        next_iter = self.trainer.iter + 1\n        is_final = next_iter == self.trainer.max_iter\n        if is_final or (self._period > 0 and next_iter % self._period == 0):\n            mean_loss = self._do_loss_eval()\n            if self._bfirst:\n                self._min_mean_loss = mean_loss\n                self._bfirst = False\n            #-------- save best model according to metrics --------\n            if mean_loss < self._min_mean_loss:\n                self._min_mean_loss = mean_loss\n                self.trainer.checkpointer.save('model_best')\n                with open('bestiter.txt', 'a+') as f:\n                    f.write('min val loss: ' + str(mean_loss) + ' at iter: ' + str(self.trainer.iter) + '\\n')","07d1763f":"class Trainer(DefaultTrainer):\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n        return COCOEvaluator(dataset_name,(\"bbox\",), True, output_folder)\n        #return COCOEvaluator(dataset_name, cfg, True, output_folder)\n    \n        #return MAPIOUEvaluator(dataset_name)\n    \n    def build_hooks(self):\n        hooks = super().build_hooks()\n        hooks.insert(-1,LossEvalHook(\n            self.cfg,\n            self.model,\n            build_detection_test_loader(\n                self.cfg,\n                self.cfg.DATASETS.TEST[0],\n                DatasetMapper(self.cfg,True)\n            )\n        ))\n        return hooks","e8111546":"cfg = get_cfg()\nconfig_name = \"COCO-Detection\/faster_rcnn_R_50_FPN_3x.yaml\"  \n\ncfg.merge_from_file(model_zoo.get_config_file(config_name))\ncfg.DATASETS.TRAIN = (Data_Resister_training,)\ncfg.DATASETS.TEST = (Data_Resister_valid,)\n\ncfg.MODEL.WEIGHTS =\"..\/input\/brdetectron2l\/output\/model_best.pth\" \n\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\n\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # 64 is slower but more accurate (128 faster but less accurate)\n\n\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class  + 1\ncfg.MODEL.RETINANET.NUM_CLASSES = 2 # only has one class  + 1\n\ncfg.SOLVER.IMS_PER_BATCH = 2 #(2 is per defaults)\ncfg.SOLVER.BASE_LR = 0.0005 #(quite high base learning rate but should drop)\ncfg.SOLVER.GAMMA = 0.1\n\n    \ncfg.SOLVER.WARMUP_ITERS = 10 #How many iterations to go from 0 to reach base LR\ncfg.SOLVER.MAX_ITER = 800 #Maximum of iterations 1\ncfg.SOLVER.STEPS = (200,400,750) #At which point to change the LR 0.25,0.5\n\ncfg.TEST.EVAL_PERIOD = 60\n#cfg.SOLVER.CHECKPOINT_PERIOD=100\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n#trainer = AugTrainer(cfg) # with  data augmentation  \ntrainer = Trainer(cfg)  # without data augmentation\ntrainer.resume_or_load(resume=False)\ntrainer.train()\n","ede8985c":"print('test model final:')\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # set a custom testing threshold\npredictor = DefaultPredictor(cfg)\nevaluator = COCOEvaluator(Data_Resister_valid,  False, output_dir=\".\/output_final\/\")\nval_loader = build_detection_test_loader(cfg, Data_Resister_valid)\nprint(inference_on_dataset(trainer.model, val_loader, evaluator))\n\n\nprint('test model best:')\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_best.pth\") \n#cfg.MODEL.WEIGHTS=\".\/output\/model_best.pth\"\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)\nevaluator = COCOEvaluator(Data_Resister_valid, False, output_dir=\".\/output_best\/\") #bbox\nval_loader = build_detection_test_loader(cfg, Data_Resister_valid)\nprint(inference_on_dataset(trainer.model, val_loader, evaluator))","29775a75":"def load_json_arr(json_path):\n    lines = []\n    with open(json_path, 'r') as f:\n        for line in f:\n            lines.append(json.loads(line))\n    return lines\nexperiment_metrics = load_json_arr('.\/output\/metrics.json')\n\niters_total_loss = [x['iteration'] for x in experiment_metrics if 'total_loss' in x]\ntotal_loss = [x['total_loss'] for x in experiment_metrics if 'total_loss' in x]\n\n\niters_validation_loss = [x['iteration'] for x in experiment_metrics if 'validation_loss' in x]\nvalidation_loss = [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x]\n\niters_AP = [x['iteration'] for x in experiment_metrics if 'bbox\/AP' in x]\nAP = [x['bbox\/AP'] for x in experiment_metrics if 'bbox\/AP' in x]\n\nfig, ax = plt.subplots(2,1,figsize=(10,8))\nax[0].plot(iters_total_loss, total_loss)\nax[0].plot(iters_validation_loss, validation_loss)\nax[0].set_xlabel('iteration')\nax[0].set_ylabel('loss')\nax[0].legend(['total_loss', 'validation_loss'], loc='best')\n\niter = validation_loss.index(min(validation_loss))\nax[0].vlines(iters_validation_loss[iter], 0, float(max(validation_loss)),color=\"red\",linestyles =\"dashed\")\nax[0].annotate('min validation_loss: %f at iter: %d'%(float(min(validation_loss)),int(iters_validation_loss[iter])),xy=(iters_validation_loss[iter],min(validation_loss)),xytext=(+10,-10),textcoords='offset points',fontsize=12) #arrowprops=dict(arrowstyle='->',connectionstyle='arc3,rad=.2')\n\niter = total_loss.index(min(total_loss))\nax[0].vlines(iters_total_loss[iter], 0, float(max(total_loss)),color=\"blue\",linestyles =\"dashed\")\nax[0].annotate('min total_loss: %f at iter: %d'%(float(min(total_loss)),int(iters_total_loss[iter])),xy=(iters_total_loss[iter],min(total_loss)),xytext=(+10,-10),textcoords='offset points',fontsize=12) #arrowprops=dict(arrowstyle='->',connectionstyle='arc3,rad=.2')\n\nax[0].set_xlim([0,max(max(iters_total_loss),max(iters_validation_loss))])\nax[0].set_ylim([0,max(1.5*max(total_loss),1.5*max(validation_loss))])\n#ax[0].legend(bbox_to_anchor=(1.0, 1.0))\n\nax[1].plot(iters_AP, AP)\nax[1].set_xlabel('iteration')\nax[1].set_ylabel('bbox\/AP')\niter = AP.index(max(AP))\nax[1].vlines(iters_AP[iter], 0, 5+float(max(AP)),color=\"blue\",linestyles =\"dashed\")\nax[1].annotate('max bbox\/AP: %f at iter: %d'%(float(max(AP)),int(iters_AP[iter])),xy=(iters_AP[iter],max(AP)),xytext=(+10,+10),textcoords='offset points',fontsize=12) #arrowprops=dict(arrowstyle='->',connectionstyle='arc3,rad=.2')\nax[1].set_xlim([0,max(iters_AP)])\nax[1].set_ylim([0,max(AP)*1.3])\n\nfig.tight_layout()  \nplt.show()","6f2033f9":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_best.pth\") \ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold for this model\ncfg.DATASETS.TEST = (Data_Resister_valid, )\npredictor = DefaultPredictor(cfg)\n\nfig, ax = plt.subplots(4, 1, figsize =(20,50))\nindices=[ax[0],ax[1],ax[2],ax[3] ]\ni=-1\nfor d in random.sample(dataset_dicts_valid, 4):\n    i=i+1    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, :],\n                   metadata=metadata_dicts_valid, \n                   scale=1 # remove the colors of unsegmented pixels. This option is only available for segmentation models\n    )\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    indices[i].grid(False)\n    indices[i].imshow(out.get_image()[:, :, ::-1])","ebada9ef":"# Install Detectron ","ebc7aef6":"# Visulaise the Bounding Boxes","807cd570":"1. https:\/\/www.kaggle.com\/ammarnassanalhajali\/barrier-reef-detectron2-training\/notebook\n2. https:\/\/github.com\/aakarsh7599\/Text-Detection-using-Detectron2","7745a0d9":"# References","ff333cca":"# Evaluate the model","498ec1a3":"# Importing Libraries","15af7bfa":"# Split the Data","2094455e":"Here is where we begin to create the COCO dataset for our model","4c8a7fbf":"> **Annotations**","abbf70fb":"# Load the Data ","035ae2f2":"# LossEvalHook","946a3144":"> **Image height and width**","f551ef2c":"COCOEvaluator calculates AP with IoU from 0.50 to 0.95","e9bcd98d":"> **Image path**","e8489118":"# Creating a COCO dataset","3860bf3b":"> **Image Id**","65977315":"# Train the model","fb5a2502":"# Plot the performance of the model","ee04de37":"# Predictions of the model","7929523a":"Now we convert all our data into the format that is required to make a COCO dataset to be used by our model"}}