{"cell_type":{"57a908d7":"code","74f7b170":"code","1084d8e3":"code","22bccc22":"code","fa4d2839":"code","2c1dbc6a":"code","4bbfd5e3":"code","5cf18eb2":"code","95e8dac6":"code","edbccfc9":"code","aa579232":"code","057aa90d":"code","2b9ecd7c":"code","8852f38d":"code","d3bc8847":"code","2e7c9bef":"code","a5622880":"code","0bbfeb6a":"code","cf44039d":"code","1ebc996b":"code","8b5c2a8e":"code","551ebe93":"code","edc3e92b":"code","fa494b8e":"code","f1944552":"code","74f0ff5e":"code","3731d0da":"code","657e6d11":"markdown","cd89227b":"markdown","768a7084":"markdown"},"source":{"57a908d7":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n#grafs\nimport pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import Dependencies\n%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","74f7b170":"train=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntrain.info()","1084d8e3":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX = train\nX_test_full = test\n\n# Remove rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['Survived'], inplace=True)\ny = X.Survived              \nX.drop(['Survived'], axis=1, inplace=True)\nX.drop(['Name'], axis=1, inplace=True)\nX.drop(['Ticket'], axis=1, inplace=True)\n#X.drop(['Fare'], axis=1, inplace=True)\n\n\n#complete missing age with median\ntrain['Fare'].fillna(train['Fare'].median(), inplace = True)\nX_test_full['Fare'].fillna(X_test_full['Fare'].median(), inplace = True)\n\n\nX.drop(['Cabin'], axis=1, inplace=True)\n#X.drop(['Embarked'], axis=1, inplace=True)\n#X.drop(['Age'], axis=1, inplace=True)\n   \n    \n    #complete missing age with median\ntrain['Age'].fillna(train['Age'].median(), inplace = True)\nX_test_full['Age'].fillna(X_test_full['Age'].median(), inplace = True)\n   \n    \n    \n    \n    \n    # Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\nlow_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n                        X_train_full[cname].dtype == \"object\"]\n\n# Low cardinality means that the column contains a lot of \u201crepeats\u201d in its data range.\n# Examples of categorical variables are race, sex, age group, and educational level. \n# While the latter two variables may also be considered in a numerical manner by using exact values for age \n# and highest grade completed\n# nunique() function to find the number of unique values over the column axis. So when it finds over 10 uniqe \n# values and the cname is a \n# dtype 'object' which means Data type objects are useful for creating structured arrays. \n# A structured array is the one which contains different types of data.\n\n### one line meaning of above####\n## for cname in a dataframes column shall return a value to 'low_cardinality_cols' if there are more then 10 uniqe values\n## and the dtype shall be a object which is a structured array that can have different types of data (lik; int, float string ect.)\n\n\n\n# Select numeric columns\nnumeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n### for cname (every value, one at the time) in dataframe for columns return a value to 'numeric_cols' if the \n### dtype= int64 or float64. \n\n# Keep selected columns only\nmy_cols = low_cardinality_cols + numeric_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\n\n# One-hot encode the data (to shorten the code, we use pandas)\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\nX_train, X_valid = X_train.align(X_valid, join='left', axis=1)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)","22bccc22":"train.isnull().sum()","fa4d2839":"print(train.head())\nprint('-' * 100)\nprint(test.head())","2c1dbc6a":"y.head()","4bbfd5e3":"train['Sex'] = np.where(train['Sex'] == 'female', 1, 0) # change sex to 0 for male and 1 for female\ntest['Sex'] = np.where(test['Sex'] == 'female', 1, 0) # change sex to 0 for male and 1 for female","5cf18eb2":"train.Sex.head()","95e8dac6":"train.Sex.isnull().sum()","edbccfc9":"sns.scatterplot(x=train['Sex'],y=train['Age'])","aa579232":"train.head()","057aa90d":"\n# Color-coded scatter plot w\/ regression lines\nsns.lmplot(x='Fare',y='Parch', hue='Sex', data=train)","2b9ecd7c":"train.describe()","8852f38d":"#train.Age.isnull().sum()","d3bc8847":"#train.Age.isnull().sum()","2e7c9bef":"#train.Survived.head()","a5622880":"print(len(train))\ntrain = train.dropna(subset=['Embarked'])\ntest = test.dropna(subset=['Embarked'])\nprint(len(train))","0bbfeb6a":"X.head()","cf44039d":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n#from xgboost import XGBRegressor\n\n\nmodel2 = RandomForestClassifier(n_estimators=150, max_depth=4, random_state=1)\nmodel = GradientBoostingClassifier(random_state=1)\n#model = DecisionTreeClassifier(random_state=1)\n#model=SGDClassifier(random_state=1)\n#model=ExtraTreesClassifier(random_state=1)\n#model = XGBRegressor()\n\n\n\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\n\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","1ebc996b":"\nprint('model accuracy score',model.score(X_valid, y_valid))","8b5c2a8e":"model2.fit(X_train, y_train)\ny_predictions = model2.predict(X_test)\nprint('model1 accuracy score',model2.score(X_valid, y_valid))","551ebe93":"if len(output) == len(test):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(output)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")","edc3e92b":"X_train.head()","fa494b8e":"X_valid.head()","f1944552":"ss=X_valid","74f0ff5e":"ss.set_index('Pclass')","3731d0da":"# Heatmap showing average game score by platform and genre\nplt.figure(figsize=(20,20))\n# Add title\nplt.title(\"Average score\")\n\nsns.heatmap(data=X_valid,annot=True)\n","657e6d11":"SEX","cd89227b":"Age","768a7084":"Model\/submission"}}