{"cell_type":{"32d15335":"code","3a623e3f":"code","7a256dac":"code","a3dc64df":"code","8938e48b":"code","cda58f3f":"code","c1fdddc0":"code","e4989534":"code","fe22900a":"code","4f850abe":"code","9bde519d":"code","41a721d9":"code","106e5365":"code","419ddd12":"code","f8897867":"code","c0409af4":"code","cfaddc49":"code","528bc875":"code","f1272727":"code","ce60f79d":"code","86aa766c":"code","d8560c4f":"code","474448f8":"code","b9dfd3ac":"code","3262524a":"code","71c38f6f":"code","d1781823":"code","e3e51cc5":"code","425e0fe2":"markdown","cc7fb2d7":"markdown","8e6bcafb":"markdown","e14299fb":"markdown"},"source":{"32d15335":"#Libraries to import\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nimport pycountry\nimport plotly_express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nsns.set_style('darkgrid')\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn import metrics\n#import xgboost as xgb\n#from xgboost import XGBRegressor\n#from xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import AdaBoostRegressor\nimport itertools\nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nfrom math import sqrt","3a623e3f":"df_train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv') \ndf_test = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv')","7a256dac":"display(df_train.head())\ndisplay(df_train.describe())\ndisplay(df_train.info())","a3dc64df":"df_train['Date'] = pd.to_datetime(df_train['Date'], format = '%Y-%m-%d')\ndf_test['Date'] = pd.to_datetime(df_test['Date'], format = '%Y-%m-%d')","8938e48b":"print('Minimum date from training set: {}'.format(df_train['Date'].min()))\nprint('Maximum date from training set: {}'.format(df_train['Date'].max()))","cda58f3f":"print('Minimum date from test set: {}'.format(df_test['Date'].min()))\nprint('Maximum date from test set: {}'.format(df_test['Date'].max()))","c1fdddc0":"def add_daily_measures(df):\n    df.loc[0,'Daily Cases'] = df.loc[0,'ConfirmedCases']\n    df.loc[0,'Daily Deaths'] = df.loc[0,'Fatalities']\n    for i in range(1,len(df_world)):\n        df.loc[i,'Daily Cases'] = df.loc[i,'ConfirmedCases'] - df.loc[i-1,'ConfirmedCases']\n        df.loc[i,'Daily Deaths'] = df.loc[i,'Fatalities'] - df.loc[i-1,'Fatalities']\n    #Make the first row as 0 because we don't know the previous value\n    df.loc[0,'Daily Cases'] = 0\n    df.loc[0,'Daily Deaths'] = 0\n    return df","e4989534":"df_world = df_train.copy()\ndf_world = df_world.groupby('Date',as_index=False)['ConfirmedCases','Fatalities'].sum()\ndf_world = add_daily_measures(df_world)","fe22900a":"df_world.head()","4f850abe":"df_train.Province_State.fillna('NaN', inplace=True)\ndf_plot = df_train.groupby(['Date','Country_Region','Province_State'], as_index=False)['ConfirmedCases','Fatalities'].sum()","9bde519d":"df = df_plot.query(\"Country_Region=='India'\")\ndf.head()","41a721d9":"srcConf = pd.Series(df['ConfirmedCases'].values,\n                   index=pd.date_range('2020-01-22',periods=len(df),freq= 'D'))\nsrcConf.head()","106e5365":"plt.figure(figsize=(12,8))\nplt.title('Confirmed cases in India')\nplt.xlabel('Days')\nplt.ylabel('No. of confirmed cases')\nplt.plot(srcConf)\nplt.legend(['Confirmed cases'])","419ddd12":"# Stationarity test\ndef stationarity_test(tsObj):\n    \"\"\"Augmented Dickey-Fuller Test for stationarity\"\"\"\n    from statsmodels.tsa.stattools import adfuller\n    print(\"Results of Dickey-Fuller Test\")\n    df_test = adfuller(tsObj,autolag='AIC')\n    df_out = pd.Series(df_test[0:4],\n                      index=['Test Statistic','p-Value','No. of lags used','No. of observations used'])\n    print(df_out)","f8897867":"stationarity_test(srcConf)\nlen(df_train.Country_Region.unique())","c0409af4":"p = d = q = range(0, 5)\npdq = list(itertools.product(p, d, q))\nprint('Examples of parameter combinations for Seasonal ARIMA...')\ncount=0\nfor param in pdq:\n        count= count+1\n\nprint(count)","cfaddc49":"def find_pqd(srcConf):\n    tmp_dic={}\n    tmp_rmse=1000000\n    tmp_list = []\n    breakloop = False\n    for param in pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(srcConf,\n                                            order=param,\n                                            #seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False,\n                                            measurement_error=True)\n            results = mod.fit()\n            rmse = sqrt(mean_squared_error(srcConf.values, results.fittedvalues))\n            if(rmse<tmp_rmse):\n                tmp_rmse=rmse\n                tmp_dic.update({rmse:param})\n#                print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic)) \n        except:\n            continue\n    return tmp_dic.get(tmp_rmse)","528bc875":"tmp_df = df_train[df_train.Country_Region=='India']\nts = pd.Series(tmp_df['ConfirmedCases'].values,\n                           index=pd.date_range(tmp_df.Date.min(),\n                            periods=len(tmp_df),\n                            freq= 'D'))\nbest_pdq_conf = find_pqd(ts)\nbest_pdq_conf","f1272727":"tp = sm.tsa.statespace.SARIMAX(srcConf,\n                                            order=(4, 0, 3),\n                                            #seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False,\n                                            measurement_error=True).fit(disp=False)\nsqrt(mean_squared_error(srcConf.values, tp.fittedvalues))","ce60f79d":"plt.figure(figsize=(12,8))\nplt.title('Confirmed cases in India')\nplt.xlabel('Days')\nplt.ylabel('No. of confirmed cases')\nplt.plot(srcConf)\nplt.plot(tp.fittedvalues)\nplt.legend(['Confirmed cases','Fitted'])","86aa766c":"df_train.head()","d8560c4f":"df_train.Province_State.fillna('NaN', inplace=True)\ndf_test.Province_State.fillna('NaN', inplace=True)","474448f8":"submission = []\n#Loop through all the unique countries\nfor country in df_train.Country_Region.unique():\n    #Filter on the basis of country\n    df_train1 = df_train[df_train[\"Country_Region\"]==country]\n    #Loop through all the States of the selected country\n    for state in df_train1.Province_State.unique():\n        #Filter on the basis of state\n        df_train2 = df_train1[df_train1[\"Province_State\"]==state]\n        #Timeseries dataframe\n        df_train3_conf = pd.Series(df_train2['ConfirmedCases'].values,\n                           index=pd.date_range(df_train2.Date.min(),\n                            periods=len(df_train2),\n                            freq= 'D'))\n        df_train3_fat = pd.Series(df_train2['Fatalities'].values,\n                           index=pd.date_range(df_train2.Date.min(),\n                            periods=len(df_train2),\n                            freq= 'D'))\n        best_pdq_conf = find_pqd(df_train3_conf)\n        best_pdq_fat = find_pqd(df_train3_fat)\n        #model for predicting Confirmed cases\n        model1 = sm.tsa.statespace.SARIMAX(df_train3_conf,\n                                order=best_pdq_conf,\n                                #seasonal_order=best_pdq_conf[1],\n                                enforce_stationarity=False,\n                                enforce_invertibility=False,\n                                measurement_error=True)\n        conf = model1.fit(disp=False)\n        #model2 for predicting Fatalities\n        model2 = sm.tsa.statespace.SARIMAX(df_train3_fat,\n                                order=best_pdq_fat,\n                                #seasonal_order=best_pdq_fat[1],\n                                enforce_stationarity=False,\n                                enforce_invertibility=False,\n                                measurement_error=True)\n        fat = model2.fit(disp=False)\n        #Get the test data for that particular country and state\n        df_test1 = df_test[(df_test[\"Country_Region\"]==country) & (df_test[\"Province_State\"] == state)]\n        #Store the ForecastId separately\n        ForecastId = df_test1.ForecastId.values\n        conf_pred = conf.get_prediction(start= df_test1.Date.min(), end= df_test1.Date.max(),dynamic=False).predicted_mean\n        conf_pred = [round(p) if p>0 else 0 for p in conf_pred]\n        fat_pred = fat.get_prediction(start= df_test1.Date.min(), end= df_test1.Date.max(),dynamic=False).predicted_mean\n        fat_pred = [round(p) if p>0 else 0 for p in fat_pred]\n        #Append the predicted values to submission list\n        for i in range(len(conf_pred)):\n            d = {'ForecastId':ForecastId[i], 'ConfirmedCases':conf_pred[i], 'Fatalities':fat_pred[i]}\n            submission.append(d)","b9dfd3ac":"submission","3262524a":"df_submit = pd.DataFrame(submission)","71c38f6f":"df_submit.head()","d1781823":"len(df_test)","e3e51cc5":"df_submit.to_csv('submission.csv', index=False)","425e0fe2":"## Data Preprocessing","cc7fb2d7":"Select all the columns that are needed for training the model.","8e6bcafb":"Convert the submission list to DataFrame and save it as csv for submission","e14299fb":"Currenty, the date is coming as a string. Lets convert it into datetime format so that EDA on the data becomes easier."}}