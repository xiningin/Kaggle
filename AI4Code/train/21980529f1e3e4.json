{"cell_type":{"c85d58b5":"code","0596583a":"code","797391d0":"code","8474009c":"code","75e92a83":"code","d40a7b7d":"code","697d8fcf":"code","f9b0d2c2":"code","1f2d756b":"code","06388eae":"code","d60b0996":"code","f66ef2de":"code","42154b2a":"code","394bbf2b":"code","19bd3cd5":"code","77650c1c":"code","ecf058db":"code","4f7774d4":"code","109cb546":"code","35165233":"code","5e95b2fd":"code","453e2bea":"code","891c9393":"code","cd40cb34":"code","f19e4ac2":"code","174f7857":"code","4a41759f":"code","2c5727b8":"markdown","9373daae":"markdown","ccc86bdb":"markdown","10399c90":"markdown","ed0589bf":"markdown","9936383e":"markdown","1df99b07":"markdown","df102d10":"markdown","f7144aa6":"markdown","dc4f7b48":"markdown","d47f6b67":"markdown","dec446ef":"markdown","cb1bbdf8":"markdown","f816efaf":"markdown","52ba5b76":"markdown"},"source":{"c85d58b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0596583a":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline\n\n# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import datasets","797391d0":"from keras.models import Sequential, load_model\n\nfrom keras.layers import Dense, Dropout, Flatten\n\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\n\nfrom keras.utils.np_utils import to_categorical","8474009c":"import cv2\nimport os\nimport glob\nimport gc\n\ndef lire_images(img_dir, xdim, ydim, nmax=5000) :\n    \"\"\" \n    Lit les images dans les sous r\u00e9pertoires de img_dir\n    nmax images lues dans chaque r\u00e9pertoire au maximum\n    Renvoie :\n    X : liste des images lues, matrices xdim*ydim\n    y : liste des labels num\u00e9riques\n    label : nombre de labels\n    label_names : liste des noms des r\u00e9pertoires lus\n    \"\"\"\n    label = 0\n    label_names = []\n    X = []\n    y=[]\n    for dirname in os.listdir(img_dir):\n        print(dirname)\n        label_names.append(dirname)\n        data_path = os.path.join(img_dir + \"\/\" + dirname,'*g')\n        files = glob.glob(data_path)\n        n=0\n        for f1 in files:\n            if n>nmax : break\n            img = cv2.imread(f1)\n            img = cv2.resize(img, (xdim,ydim))\n            X.append(np.array(img))\n            y.append(label)\n            n=n+1\n        print(n,' images lues')\n        label = label+1\n    X = np.array(X)\n    y = np.array(y)\n    gc.collect() # R\u00e9cup\u00e9ration de m\u00e9moire\n    return X,y, label, label_names","75e92a83":"X,y,nlabels,names = lire_images(\"..\/input\/chest-xray-pneumonia\/chest_xray\/test\", 224, 224, 2000)","d40a7b7d":"names","697d8fcf":"import random\nplt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    j = random.randint(0,len(X))\n    plt.axis('off')\n    plt.imshow(X[j])\n    plt.title(names[y[j]])","f9b0d2c2":"y = to_categorical(y)","1f2d756b":"X.shape","06388eae":"# Normalisation entre 0 et 1\nX = X \/ 255\nprint(X[0][0])","d60b0996":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","f66ef2de":"del X,y","42154b2a":"# R\u00e9seau convolutionnel simple\nmodel = Sequential()\nmodel.add(Conv2D(32, (5, 5), input_shape=(224, 224, 3), activation='relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\n#model.add(Dense(128, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","394bbf2b":"model.summary()","19bd3cd5":"# Apprentissage\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=1)","77650c1c":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","ecf058db":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","4f7774d4":"plot_scores(train)","109cb546":"# Prediction\ny_cnn = model.predict_classes(X_test)","35165233":"plt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        plt.title('%s \/ %s' % (names[y_cnn[j]], names[y_test[j].argmax(axis=-1)]))\n        i+=1","5e95b2fd":"# Mod\u00e8le CNN plus profond\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","453e2bea":"model.summary()","891c9393":"# Apprentissage\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200, verbose=1)\n\n# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","cd40cb34":"plot_scores(train)","f19e4ac2":"model.save('mnist_cnn2.h5')","174f7857":"new_model = load_model('mnist_cnn2.h5')\nnew_model.summary()","4a41759f":"scores = new_model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","2c5727b8":"On affiche les images o\u00f9 l'algorithme s'est tromp\u00e9 :","9373daae":"On d\u00e9finit une fonction pour afficher un graphique des scores :","ccc86bdb":"On teste un mod\u00e8le avec deux couches convolutionnelles","10399c90":"On va utiliser utiliser une couche convolutionnelle pour l'extraction des caract\u00e9ristiques, et une couche dense pour la classification :","ed0589bf":"On d\u00e9compose en ensemble d'apprentissage et de validation :","9936383e":"Mod\u00e8le CNN plus profond","1df99b07":"On peut ensuite utiliser le mod\u00e8le sans recommencer l'entra\u00eenement","df102d10":"Lecture des images","f7144aa6":"Initialisations ","dc4f7b48":"On affiche des images al\u00e9atoirement :","d47f6b67":"Le mod\u00e8le est plut\u00f4t efficace","dec446ef":"Une couche convolutionnelle","cb1bbdf8":"On \"binarise\" la cible :","f816efaf":"R\u00e9seaux convolutionnels : CNN","52ba5b76":"Le mod\u00e8le entrain\u00e9 peut \u00eatre sauvegard\u00e9"}}