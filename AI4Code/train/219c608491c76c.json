{"cell_type":{"4274ab0f":"code","4d4558e5":"code","48afddbf":"code","2926a808":"code","e49ab293":"code","b181b710":"code","dc7be446":"code","952a4849":"code","c8e234ff":"code","512febbc":"code","9a8100cf":"code","a819513c":"code","4355b885":"code","d7b25406":"code","30f78fc2":"code","d0943903":"code","b05d1aff":"code","858e8a21":"code","1121caac":"code","2410d115":"code","7aa89418":"code","2743b4ac":"code","29ab6e42":"code","865e093d":"code","18b4279a":"code","55a3ea25":"code","304d26da":"code","f67403f3":"code","24b45b03":"code","7e97f008":"code","86a51e6b":"code","a63769fa":"code","68ac4a7c":"code","54031050":"code","aa10d235":"code","baa70b7b":"code","5c9d460d":"markdown","3ac805b1":"markdown","e502ea6d":"markdown","9549bca9":"markdown","0ec4aabe":"markdown","b784ed15":"markdown","95948dfc":"markdown","06f15880":"markdown","b0a6d47c":"markdown","e3c3663b":"markdown","d0c9e93c":"markdown","6d287400":"markdown","b6560460":"markdown","2d9ba255":"markdown","18271529":"markdown","047194b1":"markdown","683c9325":"markdown","1aed6d4e":"markdown","78b25c40":"markdown","517e8de1":"markdown","365bb3e2":"markdown","354fa278":"markdown"},"source":{"4274ab0f":"import numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport time\nimport seaborn as sns\nimport keras_tuner as kt\nfrom tensorflow import keras","4d4558e5":"def evaluate(y_val, y_pred, name):\n    accuracy_score = sklearn.metrics.accuracy_score(y_val, y_pred)\n    cm = sklearn.metrics.confusion_matrix(y_val, y_pred)\n    cls_report = sklearn.metrics.classification_report(y_val, y_pred)\n    f1_score = sklearn.metrics.f1_score(y_val, y_pred)\n    print(\"Accuracy score: \", accuracy_score)\n    print(\"Confusion matrix: \\n\", cm)\n    print(\"F1 score: \", f1_score)\n    print(\"Classification report: \\n\", cls_report)\n    return {\n        \"algorithm\": name,\n        \"accuracy_score\": accuracy_score,\n        \"confusion_matrix\":cm,\n        \"classifcation_report\": cls_report,\n        \"f1_score\": f1_score\n    }","48afddbf":"loan_data = pd.read_csv(\"\/kaggle\/input\/loan-data\/loan_data.csv\")\nloan_data.head()","2926a808":"purposes = pd.get_dummies(loan_data[\"purpose\"])\npurposes.columns = [\"purpose_\" + column for column in purposes.columns]\nloan_data[purposes.columns] = purposes\nloan_data.head()","e49ab293":"sns.countplot(y=\"not.fully.paid\", data=loan_data)","b181b710":"loan_data.describe()","dc7be446":"correlation_scores = loan_data.corr()\nplt.figure(figsize=(15, 15))\nsns.heatmap(correlation_scores, annot=True)","952a4849":"correlation_scores[\"not.fully.paid\"].sort_values(key = lambda x: abs(x), ascending=False)","c8e234ff":"loan_data.groupby(\"purpose\")[\"not.fully.paid\"].mean()","512febbc":"sns.countplot(y=\"not.fully.paid\", hue=\"purpose\", data=loan_data)","9a8100cf":"loan_data.groupby(\"credit.policy\")[\"not.fully.paid\"].mean()","a819513c":"sns.countplot(y=\"not.fully.paid\", hue=\"credit.policy\", data=loan_data)","4355b885":"loan_data[loan_data[\"not.fully.paid\"]==0][\"int.rate\"].hist()","d7b25406":"loan_data[loan_data[\"credit.policy\"]==0][\"int.rate\"].mean()","30f78fc2":"loan_data[loan_data[\"not.fully.paid\"]==1][\"int.rate\"].hist()","d0943903":"loan_data[loan_data[\"credit.policy\"]==1][\"int.rate\"].mean()","b05d1aff":"train_features, val_features =train_test_split(loan_data, test_size = 0.2)\nprint(train_features.shape, val_features.shape)","858e8a21":"train_features.head()","1121caac":"train_targets = train_features.pop(\"not.fully.paid\")\nval_targets = val_features.pop(\"not.fully.paid\")","2410d115":"_ = train_features.pop(\"purpose\")\n_ = val_features.pop(\"purpose\")","7aa89418":"should_normalize = True\nif should_normalize:\n    train_features = (train_features - train_features.mean()) \/ train_features.std()\n    val_features = (val_features - train_features.mean()) \/ train_features.std()","2743b4ac":"leader_board = pd.DataFrame()\ny_preds = []","29ab6e42":"class BinaryCrossEntropy(tf.keras.losses.Loss):\n\n    def __init__(self, class_weight):\n        super().__init__()\n        self.negative_weights = class_weight[0]\n        self.positive_weights = class_weight[1]\n        \n    def call(self, y_true, y_pred):\n        y_true = tf.cast(y_true, y_pred.dtype)\n        pos = self.positive_weights * y_true * tf.math.log(y_pred + tf.keras.backend.epsilon())\n        neg = self.negative_weights * (1.0 - y_true) * tf.math.log(1.0 - y_pred + tf.keras.backend.epsilon())\n        return -(pos + neg)","865e093d":"def epsilon(func=float):\n    machine_epsilon = func(1)\n    while func(1)+func(machine_epsilon) != func(1):\n        machine_epsilon_last = machine_epsilon\n        machine_epsilon = func(machine_epsilon) \/ func(2)\n    return machine_epsilon_last\n    \nclass F1Score(tf.keras.losses.Loss):\n\n    def __init__(self):\n        super().__init__()\n        self.precision = keras.metrics.Precision(name=\"precision\")\n        self.recall = keras.metrics.Recall(name=\"recall\")\n        self.eps = tf.Variable(epsilon())\n        \n    def call(self, y_true, y_pred):\n        precision = self.precision(y_true, y_pred)\n        recall = self.recall(y_true, y_pred)\n        return 2 * (precision * recall) \/ (precision + recall + self.eps)","18b4279a":"class_weights = 1 \/ (train_targets.value_counts() \/ train_targets.shape[0])\nprint(class_weights)\nprint(class_weights.sum())\nclass_weight = dict(1 \/ class_weights.sum() * class_weights)\nprint(class_weight)","55a3ea25":"def build_model(hp):\n    inputs = tf.keras.layers.Input((train_features.shape[-1]))\n    width = hp.Choice('width', [16, 32, 64, 128])\n    depth = hp.Choice('depth', [3, 4, 5, 6, 7, 8, 9, 10])\n    x = keras.layers.Dense(\n            width, \n            activation='relu'\n        )(inputs)\n    for i in range(depth - 1):\n        x = keras.layers.Dense(\n            width, \n            activation=\"relu\"\n        )(x)\n        x = keras.layers.Dropout(\n            hp.Choice('dropout', [0.1, 0.2, 0.3, 0.4, 0.5])\n        )(x)\n    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n    model = keras.Model(inputs=inputs, outputs=output)\n    loss = BinaryCrossEntropy(class_weight)\n    adam = keras.optimizers.Adam(learning_rate=hp.Float(\"learing_rate\", 1e-5, 5e-3))\n    train_features.std()\n    f1 = F1Score()\n    f1.name= \"f1\"\n    metrics = [\n        \"accuracy\", \n        f1\n    ]\n    loss = BinaryCrossEntropy(class_weight)\n    model.compile(loss=loss, optimizer=adam, metrics=metrics)\n    return model\ntuner = kt.RandomSearch(\n    build_model,\n    objective=kt.Objective(\"val_f1\", direction=\"max\"),\n    directory=\"loan\",\n    max_trials=30)\ntuner.search(x=train_features, y=train_targets, epochs=10, validation_data=(val_features, val_targets))\nbest_model = tuner.get_best_models()[0]\nkeras.utils.plot_model(best_model, show_shapes=True)","304d26da":"early_stop = tf.keras.callbacks.EarlyStopping(patience=20, monitor=\"val_f1\")\ncheckpoint_path = \"model.h5\"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor=\"val_f1\", save_best_only=True)\nbegin_time = time.time()\nbest_model.fit(train_features, train_targets, epochs=100, validation_data=(val_features, val_targets), callbacks=[early_stop, checkpoint])\nend_time = time.time() - begin_time\nbest_model.load_weights(checkpoint_path)","f67403f3":"val_targets.describe()","24b45b03":"y_pred = best_model.predict(val_features) > 0.5\ny_preds.append(best_model.predict(val_features).reshape(-1))\nprint(pd.DataFrame(y_pred).describe())\nleader_board = leader_board.append(evaluate(val_targets, y_pred, \"dnn\"), ignore_index=True)","7e97f008":"from sklearn.neighbors import KNeighborsClassifier\nbest_algorithm = \"\"\nbest_knn_score = 0\nbest_knn = None\nbest_n = 2\nfor n in range(2, 10):\n    knn = KNeighborsClassifier(n, algorithm='ball_tree')\n    knn.fit(train_features, train_targets)\n    score = knn.score(val_features, val_targets) \n    if score > best_knn_score:\n        best_n = n\n        best_knn_score = score\n        best_knn = knn\nprint(\"Best KNN Score: \", best_knn_score, \"Model:\", best_knn, \"Best N:\", best_n)","86a51e6b":"y_pred = best_knn.predict(val_features)\ny_preds.append(best_knn.predict_proba(val_features)[:, :1].reshape(-1))\nleader_board = leader_board.append(evaluate(val_targets, y_pred, name=\"knn\"), ignore_index=True)","a63769fa":"from sklearn.tree import DecisionTreeClassifier\nbest_tree_score = 0\nbest_tree = None\nfor max_depth in range(2, 10):\n    tree = DecisionTreeClassifier(max_depth=max_depth)\n    tree.fit(train_features, train_targets)\n    score = tree.score(val_features, val_targets) \n    if score > best_tree_score:\n        best_tree_score = score\n        best_tree = tree","68ac4a7c":"y_pred = best_tree.predict(val_features)\ny_preds.append(best_tree.predict_proba(val_features)[:, :1].reshape(-1))\nleader_board = leader_board.append(evaluate(val_targets, y_pred, name=\"decision_tree\"), ignore_index=True)","54031050":"leader_board = leader_board.append(evaluate(val_targets, np.array(np.mean(y_preds, axis=0) > 0.5, dtype=int), name=\"ensembling\"), ignore_index=True)","aa10d235":"leader_board.sort_values(by=\"accuracy_score\", ascending=False)","baa70b7b":"leader_board.sort_values(by=\"f1_score\", ascending=False)","5c9d460d":"### What's the impact of policy that makes people not fully paid?\nIf someone meet the policy, about 1 \/ 8 of them can't fully paid; If some don't meet the policy, about 1 \/ 3 of them can't fully paid.","3ac805b1":"### What kind of purpose makes people more likely not fully pay the loan?\n","e502ea6d":"### Normalization","9549bca9":"### Ensembling","0ec4aabe":"## Import Dependencies","b784ed15":"### Performance by F1 score","95948dfc":"### Using DNN","06f15880":"### Binary Cross Entropy \nKerasTuner doesn't accept class_weight parameter, so I define a costom loss here.","b0a6d47c":"As we can see there is a label imbalance problem.","e3c3663b":"## Result","d0c9e93c":"## F1 Score\nThe formula of F1 Score are following: \n\n$F1=2 * \\frac{Precision * Recall} {Precision + Recall}$\n\nYou can find more details [here](https:\/\/deepai.org\/machine-learning-glossary-and-terms\/f-score).","6d287400":"## EDA & Data Preprocessing","b6560460":"### Basic statistic infos","2d9ba255":"## Using Decision Tree","18271529":"### Using KNN","047194b1":"## Import Datasets","683c9325":"## Model Development","1aed6d4e":"### Performance by accuracy score","78b25c40":"### What's the impact of interest rate that makes people not fully paid?\nThe average interest rate of people who can't fully paid were about 13.8%; while average interest rate of people who fully paid were about 11.8%, a litte bit lower than people who can't fully paid.","517e8de1":"## Common Functions","365bb3e2":"### Handle categorical features","354fa278":"### Train validation split"}}