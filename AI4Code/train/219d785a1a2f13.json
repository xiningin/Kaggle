{"cell_type":{"d287dc1f":"code","cc939bbb":"code","3f7474f7":"code","1f14fde9":"code","85aae6d7":"code","3c915c5d":"code","7d66c354":"code","942295ef":"code","33753ff0":"code","55b0106d":"code","36921d9a":"code","69095d51":"code","c07fa4d1":"code","35833baf":"code","46407d99":"code","802b9d9a":"code","31cede44":"code","7c365502":"code","ca4c4563":"code","79648098":"code","49af8be6":"code","07ada597":"code","758d1be3":"code","b74e31fe":"code","7c642eef":"code","94754c15":"markdown","69c734df":"markdown"},"source":{"d287dc1f":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport missingno as msno\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ntrain=pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest=pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')","cc939bbb":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import KFold\nimport tensorflow as tf","3f7474f7":"train[\"file_path\"] = train[\"Id\"].apply(lambda x: \"..\/input\/petfinder-pawpularity-score\/train\/\" + x + \".jpg\")\ntest[\"file_path\"] = test[\"Id\"].apply(lambda x: \"..\/input\/petfinder-pawpularity-score\/test\/\" + x + \".jpg\")","1f14fde9":"image_size = 128\ndef preprocess(image_url):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    return image\nx_train=[]\nfor i in train['file_path']:\n    x1=preprocess(i)\n    x_train.append(x1)","85aae6d7":"test2=[]\nfor i in test['file_path']:\n    x1=preprocess(i)\n    test2.append(x1)\ntest2=np.array(test2)","3c915c5d":"x_train=np.array(x_train)\ny_train=train['Pawpularity']\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2)","7d66c354":"inputs=keras.Input(shape=(128,128,3))\nx=inputs\nx=keras.layers.Conv2D(filters=8,kernel_size=3,strides=2,padding='same',activation='relu')(x)\n# x=keras.layers.BatchNormalization()(x)\n# x=keras.layers.Dropout(0.2)(x)\n# x=keras.layers.MaxPool2D(pool_size=2)(x)\n# x=keras.layers.BatchNormalization()(x)\n# x=keras.layers.Dropout(0.2)(x)\nx=keras.layers.Conv2D(filters=16,kernel_size=3,strides=2,padding='same',activation='relu')(x)\n# x=keras.layers.BatchNormalization()(x)\n# x=keras.layers.MaxPool2D(pool_size=2)(x)\n# x=keras.layers.BatchNormalization()(x)\nx=keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding='same',activation='relu')(x)\nx=keras.layers.Flatten()(x)\nx=keras.layers.Dense(128, activation = \"relu\")(x)\nx=keras.layers.Dropout(0.5)(x)\noutput = tf.keras.layers.Dense(1)(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=output)","942295ef":"early_stop = tf.keras.callbacks.EarlyStopping(\n    patience=5\n    )\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    factor=0.1,\n    patience=2, \n    min_lr=1e-9\n    )\ncallbacks = [early_stop,reduce_lr]","33753ff0":"model.compile(loss='mse', optimizer='Adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])","55b0106d":"history = model.fit(x_train,y_train, epochs=25,batch_size=64,validation_data = (x_test,y_test),callbacks=callbacks)","36921d9a":"cnn_pred=model.predict(test2)","69095d51":"cnn=pd.DataFrame()\ncnn['Id']=test['Id']\ncnn['Pawpularity']=cnn_pred","c07fa4d1":"cols=['Id','Pawpularity','file_path']\nx_train=train.drop(cols,axis=1)","35833baf":"y_train=train['Pawpularity']","46407d99":"x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2)","802b9d9a":"import lightgbm as lgb","31cede44":"lgbr=lgb.LGBMRegressor(max_depth=10,learning_rate=0.005,n_estimators=200,reg_alpha=1,reg_lambda=0.1)\nlgbr.fit(x_train,y_train)\ny_pred=lgbr.predict(x_test)","7c365502":"from sklearn.metrics import mean_squared_error,r2_score\ndef rmse(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\nprint(rmse(y_test,y_pred))\nprint(mean_squared_error(y_test,y_pred))\nprint(r2_score(y_test,y_pred))","ca4c4563":"test1=test.drop('Id',axis=1)\ntest2=test1.iloc[:,:-1]\nPred=lgbr.predict(test2)","79648098":"sub=pd.DataFrame()\nsub['Id']=test['Id']\nsub['Pawpularity']=Pred","49af8be6":"sub.head()","07ada597":"cnn.head()","758d1be3":"merge=pd.DataFrame()\nmerge['Pawpularity']=cnn['Pawpularity']\/2+sub['Pawpularity']\/2","b74e31fe":"merge['Id']=sub['Id']","7c642eef":"merge.to_csv('submission.csv',index=False)","94754c15":"# **LightGBM**","69c734df":"# Inference\nI got 20.47 rmse\n\nIt's better than single model\n\nwow...I will it them and look for a better score\n\n**Could you give me some advices...?**"}}