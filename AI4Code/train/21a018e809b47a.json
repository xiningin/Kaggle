{"cell_type":{"cb7ea60c":"code","d5960ad9":"code","d3d7c478":"code","97ab32bd":"code","3ff000e8":"code","0cc1955a":"code","8fd9ad43":"code","44ed84d2":"code","c23977fb":"code","0c7f5bb6":"code","7e487616":"code","84097e43":"code","92ef3390":"code","5d2ecaa9":"code","621d24c2":"code","a201c63a":"code","caa25ebc":"code","cbeeda85":"code","f4bb55a4":"code","8b42fc51":"code","22995808":"code","d101ce09":"code","69106402":"code","01ce5df4":"code","a1291a1a":"code","24f72640":"code","76dd7d73":"code","5df124df":"code","6d50525b":"code","be8f9f9c":"markdown","18d4f0d3":"markdown","6633c73c":"markdown","199966f2":"markdown","3e5af563":"markdown","3fd08595":"markdown","b329ea93":"markdown","c15ceb21":"markdown","9d029389":"markdown","05dfbcc0":"markdown","b9a09b75":"markdown","f86f3bc2":"markdown","3852c0d1":"markdown","4d3ac029":"markdown","f551b8f5":"markdown","064db708":"markdown","c4a0a8f3":"markdown","a4ecf4b1":"markdown","100451ce":"markdown","525dd41f":"markdown","1781f969":"markdown","995255f3":"markdown","bb5f854b":"markdown","253c6352":"markdown","30b6f2c3":"markdown","18c942e0":"markdown","4001b65d":"markdown","a199fb87":"markdown","e4ec0610":"markdown","1a2a81d9":"markdown","7c323119":"markdown","ddeae4bb":"markdown","b759021b":"markdown","6bbe9990":"markdown","2e9a71c1":"markdown","e7eff470":"markdown","95ee45a4":"markdown","d7ce3e8d":"markdown","d8fa2601":"markdown"},"source":{"cb7ea60c":"import pandas as pd\nimport numpy as np\nimport random as rnd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import recall_score","d5960ad9":"# Read in the dataset\nfifa = pd.read_csv(\"..\/input\/data.csv\")\nfifa.head()","d3d7c478":"fifa.info()","97ab32bd":"fifa.describe()","3ff000e8":"df2 = fifa.loc[:, 'Crossing':'Release Clause']\ndf1 = fifa[['ID', 'Name', 'Age', 'Nationality', 'Overall', 'Club', 'Value', 'Wage', 'Preferred Foot', 'Skill Moves', 'Position', 'Height', 'Weight']]\ndf3 = pd.concat([df1, df2], axis=1)\ndf = df3.drop(['GKDiving', 'GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes'], axis=1)\ndf = df.loc[df['Position'] != 'GK', :]","0cc1955a":"df = df.dropna()","8fd9ad43":"def value_to_int(df_value):\n    try:\n        value = float(df_value[1:-1])\n        suffix = df_value[-1:]\n\n        if suffix == 'M':\n            value = value * 1000000\n        elif suffix == 'K':\n            value = value * 1000\n    except ValueError:\n        value = 0\n    return value\n  \ndf['Value_float'] = df['Value'].apply(value_to_int)\ndf['Wage_float'] = df['Wage'].apply(value_to_int)\ndf['Release_Clause_float'] = df['Release Clause'].apply(lambda m: value_to_int(m))","44ed84d2":"def weight_to_int(df_weight):\n    value = df_weight[:-3]\n    return value\n  \ndf['Weight_int'] = df['Weight'].apply(weight_to_int)\ndf['Weight_int'] = df['Weight_int'].apply(lambda x: int(x))","c23977fb":"def height_to_int(df_height):\n    try:\n        feet = int(df_height[0])\n        dlm = df_height[-2]\n\n        if dlm == \"'\":\n            height = round((feet * 12 + int(df_height[-1])) * 2.54, 0)\n        elif dlm != \"'\":\n            height = round((feet * 12 + int(df_height[-2:])) * 2.54, 0)\n    except ValueError:\n        height = 0\n    return height\n\ndf['Height_int'] = df['Height'].apply(height_to_int)","0c7f5bb6":"df.loc[df['Preferred Foot'] == 'Left', 'Preferred_Foot'] = 1\ndf.loc[df['Preferred Foot'] == 'Right', 'Preferred_Foot'] = 0","7e487616":"for i in ['ST', 'CF', 'LF', 'LS', 'LW', 'RF', 'RS', 'RW']:\n  df.loc[df.Position == i , 'Pos'] = 'Strikers' \n\nfor i in ['CAM', 'CDM', 'LCM', 'CM', 'LAM', 'LDM', 'LM', 'RAM', 'RCM', 'RDM', 'RM']:\n  df.loc[df.Position == i , 'Pos'] = 'Midfielder' \n\nfor i in ['CB', 'LB', 'LCB', 'LWB', 'RB', 'RCB', 'RWB']:\n  df.loc[df.Position == i , 'Pos'] = 'Defender' \n\n#df.loc[df['Pos'] == 'Strikers', 'Pos_int'] = 1\n#df.loc[df['Pos'] == 'Midfielder', 'Pos_int'] = 2\n#df.loc[df['Pos'] == 'Defender', 'Pos_int'] = 3","84097e43":"df = df.drop(['Value', 'Wage', 'Release Clause', 'Weight', 'Height'], axis=1)","92ef3390":"df = df[df['Overall'] >=70]\ndf.head()","5d2ecaa9":"plt.figure(figsize=(12, 8))\nsns.countplot(x = 'Pos', data =df)","621d24c2":"plt.figure(figsize=(12, 8))\n\n# Set up the matplotlib figure\nf, axes = plt.subplots(2, 2, figsize=(15, 15), sharex=False)\nsns.despine(left=True)\n\nsns.boxplot('Pos', 'Overall', data = df, ax=axes[0, 0])\nsns.boxplot('Pos', 'Age', data = df, ax=axes[0, 1])\n\nsns.boxplot('Pos', 'Height_int', data = df, ax=axes[1, 1])\nsns.boxplot('Pos', 'Weight_int', data = df, ax=axes[1, 0])\n","a201c63a":"f, axes = plt.subplots(ncols= 3, figsize=(30, 10), sharex=False)\nsns.despine(left=True)\n\nsns.boxplot('Pos', 'Value_float', data = df, showfliers=False, ax=axes[0])\nsns.boxplot('Pos', 'Wage_float', data = df, showfliers=False, ax=axes[1])\nsns.boxplot('Pos', 'Release_Clause_float', data = df, showfliers=False, ax=axes[2])","caa25ebc":"plt.figure(figsize=(15,10))\n\na = df[df['Pos'] == 'Strikers']\nb = df[df['Pos'] == 'Defender']\nc = df[df['Pos'] == 'Midfielder']\n\nsns.distplot(a['Skill Moves'], color='blue', label = 'Strikers', kde=False)\nsns.distplot(b['Skill Moves'], color='red', label = 'Defender',  kde=False)\nsns.distplot(c['Skill Moves'], color='green', label = 'Midfielder',  kde=False)\n\nplt.legend(fontsize = 'xx-large')\n","cbeeda85":"plt.figure(figsize=(15,10))\nsns.countplot(x='Preferred Foot', data=df, hue='Pos')","f4bb55a4":"cols = ['Age', 'Skill Moves', 'Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys',\n       'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing', 'BallControl',\n       'Acceleration', 'SprintSpeed', 'Agility', 'Reactions', 'Balance',\n       'ShotPower', 'Jumping', 'Stamina', 'Strength', 'LongShots',\n       'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties',\n       'Composure', 'Marking', 'StandingTackle', 'SlidingTackle',\n       'Value_float', 'Wage_float', 'Release_Clause_float',\n       'Weight_int', 'Height_int', 'Preferred_Foot']\n\n\ny = ['Pos']\nx = cols\nx_train, x_test, y_train, y_test = train_test_split(df[x],df[y], test_size=0.2)","8b42fc51":"#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n#Common Model Evaluations\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')","22995808":"MLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.SGDClassifier(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    #xgboost: \n    XGBClassifier()    \n    ]\n\n#split dataset in cross-validation with this splitter class\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60\/30 split intentionally leaving out 10%\n\n#create table to compare MLA metrics\nMLA_columns = ['MLA Name','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n#create table to compare MLA predictions\nMLA_predict = y_train[y]\n\n#index through MLA and save performance to table\nrow_index = 1\nfor alg in MLA:\n\n    #set name and parameters\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    \n    #score model with cross validation\n    cv_results = model_selection.cross_validate(alg,x_train[x],  y_train[y], cv  = cv_split)\n\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    #if this is a non-bias random sample, then +\/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n    \n\n    #save MLA predictions \n    alg.fit(x_train[x],  y_train[y])\n    MLA_predict[MLA_name] = alg.predict(x_train[x])\n    \n    row_index+=1\n\n#print and sort table\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\nMLA_compare","d101ce09":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom xgboost import XGBClassifier\nfrom datetime import datetime","69106402":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))","01ce5df4":"# A parameter grid for XGBoost\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }","a1291a1a":"xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n                    silent=True, nthread=1)","24f72640":"folds = 3\nparam_comb = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, n_jobs=4, cv=skf.split(x_train,y_train), verbose=3, random_state=1001 )\n\nstart_time = timer(None) # timing starts from this point for \"start_time\" variable\nrandom_search.fit(x_train,y_train)\ntimer(start_time) # timing ends here for \"start_time\" variable","76dd7d73":"print('\\n All results:')\nprint(random_search.cv_results_)\nprint('\\n Best estimator:')\nprint(random_search.best_estimator_)\nprint('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\nprint(random_search.best_score_ * 2 - 1)\nprint('\\n Best hyperparameters:')\nprint(random_search.best_params_)\nresults = pd.DataFrame(random_search.cv_results_)","5df124df":"xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n       n_estimators=600, n_jobs=1, nthread=1, objective='multi:softprob',\n       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n       seed=None, silent=True, subsample=0.6)\n\nxgb.fit(df[x],df[y])\n\ny_pred = xgb.predict(x_test)\n\nprint('Accuracy of XGBClassifier on test set: {:.2f}'.format(xgb.score(x_test, y_test)))","6d50525b":"from yellowbrick.classifier import ROCAUC\n\nclasses=[0,1,2]\n\n# Instantiate the visualizer with the classification model\nvisualizer = ROCAUC(xgb, classes=classes)\n\nvisualizer.fit(x_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(x_test, y_test)  # Evaluate the model on the test data\ng = visualizer.poof()             # Draw\/show\/poof the data","be8f9f9c":"# **Modeling**","18d4f0d3":"# **Model evaluation**","6633c73c":"### **Overview the Data**","199966f2":"# **Conclusion**","3e5af563":"### **Machine Learning Algorithm (MLA) Selection and Initialization**","3fd08595":"Try different models to see which one provides the best accuracy.","b329ea93":"### **Choose players with more than 70 overall rating**","c15ceb21":"### **Distribution of each position**","9d029389":"### **Import packages**","05dfbcc0":"Dropping all the Goal Keepers because they have totally different attributes compared to players in other positions.","b9a09b75":"# **Ingest**","f86f3bc2":"### **Grid search for XGBClassifier**","3852c0d1":"![alt text](https:\/\/i.ytimg.com\/vi\/qTz8ZhNrEDA\/maxresdefault.jpg)","4d3ac029":"### **Drop null value**","f551b8f5":"In order to do EDA, string values need to be changed into numerical values.","064db708":"### **ROCAUC**","c4a0a8f3":"# **FIFA19**","a4ecf4b1":"The reason of only filtering out 70+ rating players is to see how good players define their position and to find out how to become good player by choosing the right position based on player's attributes.","100451ce":"### **Keep the preprocessed data**","525dd41f":"### **Accuracy with new parameters**","1781f969":"Defender has a much lower skill move score compared to Strikers and Midfielder, which could be one of the reasons why Defender values less than the other two positions. Since Defender cannot perform eye-catching moves due to their low skills move scores, they cannot show their value in a straight forward way.","995255f3":"### **Print out the best combination of parameters**","bb5f854b":"### **Test different combinations**","253c6352":"# **EDA**","30b6f2c3":"### **Set timer to record the time**","18c942e0":"# **Data Preprocessing**","4001b65d":"### **Select the columns we want**","a199fb87":"* **This can be useful to train our own players in the game and help them find their best position on the field.**\n* **Next step can be specifying the precise position**\n\n","e4ec0610":"### **Model comparing and selecting**","1a2a81d9":"### **Train test data split**","7c323119":"* There is no significant difference in Overall Rating among all three positions, excluded from the prediction model \n* Defender has a smaller deviation in Age.\n* Midfielder tends to be shorter and lighter since they need to be more flexible in passing and dribbling.","ddeae4bb":"Compared to Strikers and Midfielder, Defender is more balanced on their foot, even though all three positions are heavily right feet used.","b759021b":"* Strikers tend to have higher value, wage, and Release Clause compared to other positions and Defender is the lowest.\n* It aligns to a fact that, normally, people care more about attacking but ignore the true value of defending.","6bbe9990":"### **Set a range of values for different parameters **","2e9a71c1":"### **Convert string data to numerical data**","e7eff470":"The total count of Midfielder is larger than that of Strikers because there are more specified positions for Midfielder.","95ee45a4":"Only focus on three groups on the upper level, which are \"Strikers\", \"Midfielder\", and \"Defender\".\nFor example: \"CAM\" Central Attacking Midfielder and \"RDM\" Right Defending Midfielder are all categorized to be \"Midfielder\".","d7ce3e8d":"### **Redefine Position**","d8fa2601":"## **Goal: Try to utilize players' attributes to classify their position on the field**"}}