{"cell_type":{"eedd012c":"code","e63d364c":"code","03e09e6f":"code","2ed373f9":"code","ce16bf6e":"code","931224ff":"code","a2c5339d":"code","a6c94144":"code","5d5ec89d":"code","1460a035":"code","271c96bf":"code","76af8a74":"code","0b7c2183":"code","0f586aef":"code","6909395e":"code","9a94bdea":"code","6f05b713":"code","fd7d397d":"code","cd208926":"code","187ea70c":"code","e8dcd60f":"code","1d3ed3f6":"code","8dd104b7":"code","fa01d60b":"code","faba0989":"code","c6225994":"code","77f1c99d":"code","5116f401":"code","7efd9e97":"code","fe8b1a64":"code","780276ea":"code","45406554":"code","2aba5dcc":"code","a0a34a05":"code","5c0c087b":"code","98ade0c8":"code","74107a21":"code","de4344e4":"code","13a4002f":"markdown","6c107865":"markdown","6eb4724a":"markdown","7f789a14":"markdown","6ff56fb4":"markdown","dbc06ddf":"markdown","7aede3f8":"markdown","16ecea20":"markdown","36515dc9":"markdown","2e3e0834":"markdown","fac0eb99":"markdown","955529bc":"markdown","c7ca60aa":"markdown","f81c01e2":"markdown","0d3516ed":"markdown","9b8070ff":"markdown","fda953a0":"markdown","a823097f":"markdown","719eae9e":"markdown","36fc28d6":"markdown","b85eec2e":"markdown","1c06cc56":"markdown","f519ace7":"markdown","9b3eb5c8":"markdown","eac4e161":"markdown","c2e1f476":"markdown","81f64277":"markdown","11322edd":"markdown","1fbccecd":"markdown","d42220d7":"markdown","bdecd061":"markdown","4ac8123e":"markdown","521f16fa":"markdown","41dd2d18":"markdown"},"source":{"eedd012c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e63d364c":"import cv2 as cv\nimport matplotlib.pyplot as plt\nfrom skimage.feature import greycomatrix, greycoprops","03e09e6f":"def show_image(img, cmap='gray'):\n    fig = plt.figure(figsize=(20,20))\n    axes = fig.add_subplot(111)\n    axes.imshow(img, cmap=cmap)","2ed373f9":"test_img = cv.imread('..\/input\/cataractdataset\/dataset\/1_normal\/NL_001.png')\ntest_img = cv.cvtColor(test_img, cv.COLOR_BGR2RGB)\nshow_image(test_img)","ce16bf6e":"width, height, dimension = test_img.shape\nprint(f'Width RGB = {width}')\nprint(f'Height RGB = {height}')\nprint(f'Dimension RGB = {dimension}')","931224ff":"test_img_gray = cv.cvtColor(test_img, cv.COLOR_RGB2GRAY)\nshow_image(test_img_gray)","a2c5339d":"width, height = test_img_gray.shape\nprint(f'Width Grayscale = {width}')\nprint(f'Height Grayscale = {height}')\nprint(f'Image Shape Grayscale {test_img_gray.shape}')","a6c94144":"test_img_thresh = cv.adaptiveThreshold(test_img_gray,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV,11,3)\nshow_image(test_img_thresh)","5d5ec89d":"cnts = cv.findContours(test_img_thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\ncnts = sorted(cnts, key=cv.contourArea, reverse=True)\nfor c in cnts:\n    x,y,w,h = cv.boundingRect(c)\n    test_img_ROI = test_img[y:y+h, x:x+w]\n    break\nshow_image(test_img_ROI)","1460a035":"width, height, dimension = test_img_ROI.shape\nprint(f'Width = {width}')\nprint(f'Height = {height}')\nprint(f'Dimension = {dimension}')","271c96bf":"test_img_ROI_resize = cv.resize(test_img_ROI, (int(width\/4), int(height\/4)))\nshow_image(test_img_ROI_resize)","76af8a74":"width, height, dimension = test_img_ROI_resize.shape\nprint(f'Width = {width}')\nprint(f'Height = {height}')\nprint(f'Dimension = {dimension}')","0b7c2183":"test_img_ROI_resize_gray = cv.cvtColor(test_img_ROI_resize, cv.COLOR_RGB2GRAY)\nshow_image(test_img_ROI_resize_gray)","0f586aef":"def glcm_feature(matrix_coocurrence, featureName):\n    feature = greycoprops(matrix_coocurrence, featureName)\n    result = np.average(feature)\n    return result\ndistance = 10\nteta = 90\n\ncontrast_test = []\nhomogeneity_test = []\nenergy_test = []\ncorrelation_test = []\n\n\nglcm = greycomatrix(test_img_ROI_resize_gray, [distance], [teta], levels=256, symmetric=True, normed=True)\ncontrast_test.append(glcm_feature(glcm, 'contrast'))\nhomogeneity_test.append(glcm_feature(glcm, 'homogeneity'))\nenergy_test.append(glcm_feature(glcm, 'energy'))\ncorrelation_test.append(glcm_feature(glcm, 'correlation'))\n\nprint(f'Homogenity : {homogeneity_test[0]}')\nprint(f'Correlation : {correlation_test[0]}')\nprint(f'Energy : {energy_test[0]}')\nprint(f'Contrast : {contrast_test[0]}')","6909395e":"def preprocessingImage(image):\n    test_img = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n    test_img_gray = cv.cvtColor(test_img, cv.COLOR_RGB2GRAY)\n    test_img_thresh = cv.adaptiveThreshold(test_img_gray,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV,11,3)\n    cnts = cv.findContours(test_img_thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n    cnts = sorted(cnts, key=cv.contourArea, reverse=True)\n    for c in cnts:\n        x,y,w,h = cv.boundingRect(c)\n        test_img_ROI = test_img[y:y+h, x:x+w]\n        break\n    test_img_ROI_resize = cv.resize(test_img_ROI, (width, height))\n    test_img_ROI_resize_gray = cv.cvtColor(test_img_ROI_resize, cv.COLOR_RGB2GRAY)\n    \n    return test_img_ROI_resize_gray","9a94bdea":"file_normal = 301\nfile_cataract = 101\nfile_glaucoma = 102\nfile_retina = 101\nwidth, height = 400, 400\ndistance = 10\nteta = 90\ndata_eye = np.zeros((5, 601))\ncount = 0\nindextable = ['contrast', 'homogenity', 'energy', 'correlation', 'Label']\n\nnormal_dataset_path = '..\/input\/cataractdataset\/dataset\/1_normal\/'\ncataract_dataset_path = '..\/input\/cataractdataset\/dataset\/2_cataract\/'\nglaucoma_dataset_path = '..\/input\/cataractdataset\/dataset\/2_glaucoma\/'\nretina_dataset_path = '..\/input\/cataractdataset\/dataset\/3_retina_disease\/'","6f05b713":"for file in range(1, file_normal):\n    contrast = []\n    homogeneity = []\n    energy = []\n    correlation = []\n    label = 0\n    image = cv.imread(f'{normal_dataset_path}\/NL_{str(file).zfill(3)}.png')\n    img = preprocessingImage(image)\n    \n    glcm = greycomatrix(img, [distance], [teta], levels=256, symmetric=True, normed=True)\n    contrast.append(glcm_feature(glcm, 'contrast'))\n    homogeneity.append(glcm_feature(glcm, 'homogeneity'))\n    energy.append(glcm_feature(glcm, 'energy'))\n    correlation.append(glcm_feature(glcm, 'correlation'))\n    \n    data_eye[0, count] = contrast[0]\n    data_eye[1, count] = homogeneity[0]\n    data_eye[2, count] = energy[0]\n    data_eye[3, count] = correlation[0]\n    data_eye[4, count] = label\n    \n    count += 1","fd7d397d":"data_eye","cd208926":"for file in range(1, file_cataract):\n    contrast = []\n    homogeneity = []\n    energy = []\n    correlation = []\n    label = 1\n    image = cv.imread(f'{cataract_dataset_path}\/cataract_{str(file).zfill(3)}.png')\n    img = preprocessingImage(image)\n    \n    glcm = greycomatrix(img, [distance], [teta], levels=256, symmetric=True, normed=True)\n    contrast.append(glcm_feature(glcm, 'contrast'))\n    homogeneity.append(glcm_feature(glcm, 'homogeneity'))\n    energy.append(glcm_feature(glcm, 'energy'))\n    correlation.append(glcm_feature(glcm, 'correlation'))\n    \n    data_eye[0, count] = contrast[0]\n    data_eye[1, count] = homogeneity[0]\n    data_eye[2, count] = energy[0]\n    data_eye[3, count] = correlation[0]\n    data_eye[4, count] = label\n    \n    count += 1","187ea70c":"for file in range(1, file_glaucoma):\n    contrast = []\n    homogeneity = []\n    energy = []\n    correlation = []\n    label = 2\n    image = cv.imread(f'{glaucoma_dataset_path}\/Glaucoma_{str(file).zfill(3)}.png')\n    img = preprocessingImage(image)\n    \n    glcm = greycomatrix(img, [distance], [teta], levels=256, symmetric=True, normed=True)\n    contrast.append(glcm_feature(glcm, 'contrast'))\n    homogeneity.append(glcm_feature(glcm, 'homogeneity'))\n    energy.append(glcm_feature(glcm, 'energy'))\n    correlation.append(glcm_feature(glcm, 'correlation'))\n    \n    data_eye[0, count] = contrast[0]\n    data_eye[1, count] = homogeneity[0]\n    data_eye[2, count] = energy[0]\n    data_eye[3, count] = correlation[0]\n    data_eye[4, count] = label\n    \n    count += 1","e8dcd60f":"for file in range(1, file_retina):\n    contrast = []\n    homogeneity = []\n    energy = []\n    correlation = []\n    label = 3\n    image = cv.imread(f'{retina_dataset_path}\/Retina_{str(file).zfill(3)}.png')\n    img = preprocessingImage(image)\n    \n    glcm = greycomatrix(img, [distance], [teta], levels=256, symmetric=True, normed=True)\n    contrast.append(glcm_feature(glcm, 'contrast'))\n    homogeneity.append(glcm_feature(glcm, 'homogeneity'))\n    energy.append(glcm_feature(glcm, 'energy'))\n    correlation.append(glcm_feature(glcm, 'correlation'))\n    \n    data_eye[0, count] = contrast[0]\n    data_eye[1, count] = homogeneity[0]\n    data_eye[2, count] = energy[0]\n    data_eye[3, count] = correlation[0]\n    data_eye[4, count] = label\n    \n    count += 1","1d3ed3f6":"df= pd.DataFrame(np.transpose(data_eye), columns = indextable)","8dd104b7":"df","fa01d60b":"df.describe()","faba0989":"from sklearn.preprocessing import MinMaxScaler\nfeatures = df.drop(['Label'], axis='columns')\nfeatures_scaler = MinMaxScaler()\nfeatures = features_scaler.fit_transform(features)\nfeatures","c6225994":"data_normalization = df.copy()\ndata_normalization[['contrast', 'homogenity', 'energy', 'correlation']] = features\ndata_normalization","77f1c99d":"data_normalization.describe()","5116f401":"x = data_normalization.drop(['Label'], axis='columns')\ny = data_normalization.Label","7efd9e97":"from sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_params = {\n    'svm': {\n        'model': svm.SVC(gamma='auto'),\n        'params' : {\n            'C': [1,10,20,30],\n            'kernel': ['rbf','linear','poly']\n        }  \n    },\n    'random_forest': {\n        'model': RandomForestClassifier(),\n        'params' : {\n            'n_estimators': [1,5,10,50,100]\n        }\n    },\n    'logistic_regression' : {\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params': {\n            'C': [1,5,10,50,100]\n        }\n    },\n    'KNN' : {\n        'model': KNeighborsClassifier(),\n        'params': {\n            'n_neighbors': [3,7,11,13]\n        }\n    }\n    \n}","fe8b1a64":"from sklearn.model_selection import GridSearchCV\nscores = []\n\nfor model_name, mp in model_params.items():\n    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n    clf.fit(x, y)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })\n    \ndf_score = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf_score","780276ea":"df_score['best_score'].max()","45406554":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25)","2aba5dcc":"model = svm.SVC(gamma='auto', C=20, kernel='poly')\nmodel.fit(x_train,y_train)","a0a34a05":"model.score(x_test,y_test)","5c0c087b":"from sklearn.metrics import confusion_matrix\nimport seaborn as sb\ny_predicted = model.predict(x_test)\ncm = confusion_matrix(y_test,y_predicted)\nplt.figure(figsize = (10,7))\nsb.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","98ade0c8":"import tensorflow as tf\nfrom tensorflow import keras\nmodel_nn = keras.Sequential([\n    keras.layers.Flatten(input_shape=(4,)),\n    keras.layers.Dense(100, activation='relu'),\n    keras.layers.Dense(4, activation='sigmoid')\n])\n\nmodel_nn.compile(optimizer='adam',\n             loss='sparse_categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel_nn.fit(x_train, y_train, epochs=50)","74107a21":"model_nn.evaluate(x_test, y_test)","de4344e4":"y_predicted = model_nn.predict(x_test)\ny_predicted_labels = [np.argmax(i) for i in y_predicted]\ncm = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted_labels)\nplt.figure(figsize = (10,7))\nsb.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","13a4002f":"Create method to show image, these created to easily show image using matplotlib","6c107865":"## Eye disease Classification Using Grey Level Co-occurrence Matrix","6eb4724a":"Convert image from RGB to Grayscale, in these stage we convert 3 dimension from RGB to 1 dimensian in Grayscale","7f789a14":"## These Classification Goals is to create model that can classify eye disease","6ff56fb4":"Concatenate the normalization data and the label data into new dataframe","dbc06ddf":"# 5. Classification using Machine Learning Alghoritm","7aede3f8":"Read image using cv and convert image color from BGR(Blue, Green, Red) to RGB(Red, Green, Blue) because cv automatically make image color to BGR, and matplotlib make wierd image color when showing BGR image. So we convert BGR to RGB","16ecea20":"In these Exploring Image Data i want to make image data ready for feature extraction using GLCM, So i try some image preprocessing to make image is ready for feature extraction\n\nin this explore image data i want to make some changes to image like\n1. Crop image, so unusefull black image can dissapear from image\n2. Resize image, because image data have a big dimension and i large data make a long time when processing so i resize to small image","36515dc9":"Because i crop image from original RGB color so these ROI image have 3 dimensions","2e3e0834":"## Step for classification\n### 1. Explore Data Image\n### 2. Preprocessing Data\n### 3. Extraction Feature Using Grey level co-occurrence matrix (GLCM)\n### 4. Normalize Data\n### 5. Classification using Machine Learning Alghoritm","fac0eb99":"SVM have the best score with 58%","955529bc":"### Thresholding Image (Binary Image) from grayscale that have a color range from 0-255 to Threshold Image that have color 0 or 1","c7ca60aa":"SVM model can only predict normal and cataract dataset","f81c01e2":"Split data to create confusion matrix of these svm Model","0d3516ed":"Convert resizing image to grayscale because when extraction feature with GLCM image should have 1 dimensions like grayscale","9b8070ff":"Check the reized image that have been resized","fda953a0":"in these feature extraction i split these processiong based on label and i used 10 distance and 90 teta for GLCM feature extraction","a823097f":"In these stage i try to using some machine learning alghoritm with some paramater to create a better model","719eae9e":"Create some variable that used for feature extraction","36fc28d6":"Try using neural network to create a model","b85eec2e":"After i explore some image to be image test, and have some preprocessing image like cropping and resize. i make method to gather all preprocessing step to make image ready to feature extraction","1c06cc56":"Export value of image feature extraction into csv file to make easier to see","f519ace7":"Testing if the feature extraction is succesful","9b3eb5c8":"Resizing image becase 1600x1600 is to large when processing, i resize to 400x400 by divided by 4","eac4e161":"These are some packages to show image","c2e1f476":"Neural Network Model have same similiar result like SVM model","81f64277":"Cropping Image so unusefull black color dissapeaer from image and i can get the Region of Interest (ROI) of this Image","11322edd":"# 4. Normalize Data","1fbccecd":"Grayscale image doseant have dimensiaon becasue grayscale image has 1 color that have range from 0 - 255","d42220d7":"Data have different value so i normalize using min max scaler","bdecd061":"# 1. Explore Image Data","4ac8123e":"# 3. Feature Extraction","521f16fa":"Test image to feture extraction with GLCM","41dd2d18":"# 2. Preprocessing Image"}}