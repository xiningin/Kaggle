{"cell_type":{"b6fc9552":"code","2f103a6d":"code","c061a84c":"code","762ef647":"code","6773864e":"code","644e78f4":"code","6afc8ca8":"code","d6e4651e":"code","a0aa3b93":"code","3e1caac0":"code","8af27072":"code","574d5a27":"code","107cfa6c":"code","fadc883b":"code","d8f0fcf1":"code","18a4e2af":"code","ae81d0c8":"code","dc6c0b37":"code","b0f79cfb":"code","45f081a2":"code","d744edf7":"code","b96150a7":"code","31eaaf2f":"code","b680b4d5":"code","08fbad67":"code","e0bd6f80":"code","b181aa05":"code","ba0fa2fa":"code","a7a59cd6":"code","d27a5315":"code","529ee758":"code","7b552efb":"code","fd97e551":"code","75d68110":"code","2fb2c2f2":"code","86e55964":"code","98d81840":"code","0437d595":"code","a8c3d0de":"code","dd7556ad":"code","1d4e33d0":"code","da5a1fd8":"code","1282f2b0":"code","5d59dcdf":"code","4d829107":"code","1e09abed":"code","5da06f63":"code","d504ae8f":"markdown","5a7a7dae":"markdown","e0ba6d7f":"markdown","ca8f266a":"markdown","c592470c":"markdown","e916379b":"markdown","9d23b66c":"markdown","0c351a28":"markdown","ff2bb39d":"markdown","b71bfa60":"markdown","6b4c99ae":"markdown","44af9a86":"markdown","15a67bed":"markdown","6bb25735":"markdown","e7d15113":"markdown","f666d1de":"markdown","a37b38c3":"markdown","e17ae8c7":"markdown","14d151d7":"markdown","7c8f385f":"markdown","8ded6464":"markdown","4a05361d":"markdown","ad85b8de":"markdown","fbc6598b":"markdown","768ee308":"markdown"},"source":{"b6fc9552":"import pandas as pd\nimport numpy as np\nimport os\nimport joblib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom tqdm.notebook import tqdm\nimport tensorflow as tf","2f103a6d":"import sys, matplotlib, sklearn, lightgbm, xgboost, imblearn\nimport tqdm as tqdm_v\n\nprint(\"Python version :\", sys.version)\ndic_ver = {\n    \"Pandas\": pd.__version__,\n    \"NumPy\": np.__version__,\n    \"Joblib\": joblib.__version__,\n    \"Matplotlib\": matplotlib.__version__,\n    \"Seaborn\": sns.__version__,\n    \"tqdm\": tqdm_v.__version__,\n    \"Scikit-Learn\": sklearn.__version__,\n    \"Imbalanced Learn\": imblearn.__version__, \n    \"LightGBM\": lightgbm.__version__,\n    'XGBoost': xgboost.__version__,\n    'TensorFlow': tf.__version__,\n}\ndel sys, matplotlib, sklearn, lightgbm, tqdm_v, xgboost, imblearn\npd.DataFrame(dic_ver.values(), index=dic_ver.keys(), columns=[\"Version\"])","c061a84c":"from sklearn.metrics import mean_squared_error, make_scorer\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\nrmse_scorer = make_scorer(rmse)","762ef647":"input_path = os.path.join('..', 'input', '1056lab-student-performance-prediction')\n\ntarget_col = 'G3'\ndf_train = pd.read_csv(os.path.join(input_path, 'train.csv'), index_col='id')\ndf_test = pd.read_csv(os.path.join(input_path, 'test.csv'), index_col='id')","6773864e":"df_train.head()","644e78f4":"df_test.head()","6afc8ca8":"df_train.info()","d6e4651e":"df_train.describe()","a0aa3b93":"sns.distplot(df_train[target_col])\n# plt.savefig('target.pdf')\nplt.show()","3e1caac0":"sns.countplot(df_train[target_col])\nplt.show()","8af27072":"obj_cols = [col for t, col in zip(df_test.dtypes, df_test.columns) if t == 'object']\nobj_cols","574d5a27":"flag = True\nfor col in obj_cols:\n    if len(set(df_train[col].unique()) - set(df_test[col].unique())) > 0:\n        print(col, '\u306e\u5024\u306e\u6570\u304c\u4e00\u81f4\u3057\u307e\u305b\u3093')\n        flag = False\n\nif flag:\n    print('\u5024\u306e\u6570\u304c\u4e00\u81f4\u3057\u306a\u3044\u5217\u306f\u5b58\u5728\u3057\u307e\u305b\u3093\u3067\u3057\u305f')","107cfa6c":"for col in obj_cols:\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n    tmp_train_vc = df_train[col].value_counts()\n    ax1.pie(tmp_train_vc, labels=tmp_train_vc.index, autopct='%1.1f%%')\n\n    tmp_test_vc = df_test[col].value_counts()\n    ax2.pie(tmp_test_vc, labels=tmp_test_vc.index, autopct='%1.1f%%')\n    \n    ax1.title.set_text('{} Percentage.'.format(col))\n    ax2.title.set_text('{} Percentage.'.format(col))","fadc883b":"for col in obj_cols:\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n    \n    order_col = df_train[col].value_counts().index\n    sns.countplot(df_train[col], order=order_col, ax=ax1)\n    sns.countplot(df_test[col], order=order_col, ax=ax2)","d8f0fcf1":"num_cols = [col for t, col in zip(df_test.dtypes, df_test.columns) if t == 'float' or t == 'int'] \nnum_cols","18a4e2af":"for col in num_cols:\n#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n    fig = plt.figure(figsize=(10, 5))\n    \n    sns.distplot(df_train[col], label='Train')\n    sns.distplot(df_test[col], label='Test')\n    plt.legend()\n    plt.show()","ae81d0c8":"for col in num_cols:\n#     plt.figure()\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n    ax1.hist(df_train[col], label=\"Train\", density=True)\n    ax2.hist(df_test[col], label=\"Test\", density=True)\n    plt.title(col)\n    plt.show()","dc6c0b37":"plt.hist(df_train['failures'], density=True, label='Train', alpha=0.3)\nplt.hist(df_test['failures'], density=True, label='Test', alpha=0.3)","b0f79cfb":"bool_cols = [col for t, col in zip(df_test.dtypes, df_test.columns) if t == 'bool'] \nbool_cols","45f081a2":"for col in bool_cols:\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n    \n    sns.countplot(df_train[col], label='Train', ax=ax1)\n    sns.countplot(df_test[col], label='Test', ax=ax2)\n    plt.show()","d744edf7":"for col in bool_cols:\n    if len(df_train[df_train[target_col] > 14][col].value_counts()) <= 1:\n        print(col)","b96150a7":"df_train.corr()[target_col].sort_values()","31eaaf2f":"cat_cols = obj_cols + bool_cols","b680b4d5":"df_train_, df_test_ = df_train.copy(), df_test.copy()","08fbad67":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nobj_cols = [col for t, col in zip(df_test.dtypes, df_test.columns) if t == 'object']\nfor col in obj_cols:\n    df_train_[col] = le.fit_transform(df_train_[col])\n    df_test_[col] = le.transform(df_test_[col])","e0bd6f80":"df_train_.head()","b181aa05":"corr_train = df_train_.corr()[target_col].abs().sort_values(ascending=False)\nsns.barplot(corr_train[1: 20].values, corr_train[1: 20].index)\nplt.title(\"correlation\")","ba0fa2fa":"df_train_['All_Sup'] = df_train_['famsup'] & df_train_['schoolsup']\ndf_test_['All_Sup'] = df_test_['famsup'] & df_test_['schoolsup']","a7a59cd6":"df_train_['PairEdu'] = df_train_[['Fedu', 'Medu']].mean(axis=1)\ndf_test_['PairEdu'] = df_test_[['Fedu', 'Medu']].mean(axis=1)","d27a5315":"df_train_['more_high'] = df_train['higher'] & (df_train['schoolsup'] | df_train['paid'])\ndf_test_['more_high'] = df_test['higher'] & (df_test['schoolsup'] | df_test['paid'])","529ee758":"df_train_['All_alc'] = df_train_['Walc'] + df_train_['Dalc']\ndf_test_['All_alc'] = df_test_['Walc'] + df_test_['Dalc']\n\ndf_train_['Dalc_per_week'] = df_train_['Dalc'] \/ df_train_['All_alc']\ndf_test_['Dalc_per_week'] = df_test_['Dalc'] \/ df_test_['All_alc']\n\n# \u30b9\u30b3\u30a2\u304c\u4e0b\u304c\u3063\u305f\u306e\u3067\u5b9f\u884c\u3057\u306a\u3044\n# df_train_['Walc_per_week'] = df_train_['Walc'] \/ df_train_['All_alc']\n# df_test_['Walc_per_week'] = df_test_['Walc'] \/ df_test_['All_alc']\n\ndf_train_.drop(['Dalc'], axis=1, inplace=True)\ndf_test_.drop(['Dalc'], axis=1, inplace=True)","7b552efb":"df_train_['studytime_ratio'] = df_train_['studytime'] \/ (df_train_[['studytime', 'traveltime', 'freetime']].sum(axis=1))\ndf_test_['studytime_ratio'] = df_test_['studytime'] \/ (df_test_[['studytime', 'traveltime', 'freetime']].sum(axis=1))\n\ndf_train_.drop([\"studytime\"], axis=1, inplace=True)\ndf_test_.drop([\"studytime\"], axis=1, inplace=True)","fd97e551":"# df_train_.drop(obj_cols, axis=1, inplace=True)\n# df_test_.drop(obj_cols, axis=1, inplace=True)","75d68110":"# X.replace({True:1, False:0}, inplace=True)","2fb2c2f2":"target_0_indx = df_train[df_train[target_col] == 0].index","86e55964":"from sklearn.model_selection import KFold\nfrom tqdm.notebook import tqdm\nimport re\nfrom functools import partial\n\ndef cross_validation(reg, X, y, cv=5, scoring=None, random_state=42, verbose=True, cat_cols=[], reg_name=\"\",\n                    preprocess=None):\n    if scoring is None: \n        print(\"Pass scoring as evaluation function as an argument.\")\n        return None\n    oof = []\n    np.random.seed(random_state)\n    \n    seeds = np.random.randint(0, 100000, size=cv)\n    \n    for i in range(cv):\n        k_fold = KFold(n_splits=cv, shuffle=True, random_state=seeds[i])\n        temp = np.zeros(len(X))\n\n        for fold, ids in enumerate(tqdm(k_fold.split(X, y), disable=not verbose)):\n            if verbose: print(\"{} Fold.\".format(fold+1))\n            X_train, y_train = X[ids[0]], y[ids[0]]\n            X_valid, y_valid = X[ids[1]], y[ids[1]]\n\n    #         print(help(preprocess))\n            if preprocess is not None:\n#                 X_train, X_valid = partial(preprocess, train=X_train, test=X_valid)\n                X_train, X_valid = preprocess(train=X_train, test=X_valid)\n\n            if verbose: print(\"\\tFitting...\")\n            if reg_name == \"LightGBM\":\n                reg.fit(X_train, y_train, categorical_feature=cat_cols)\n            elif reg_name == \"CatBoost\":\n                reg.fit(X_train, y_train, cat_features=cat_cols)\n            else:\n                reg.fit(X_train, y_train)\n            if verbose: print(\"\\tPredicting...\")\n            p = reg.predict(X_valid)\n            if verbose: print(\"\\tEvaluating...\")\n            \n            temp[ids[1]] += p\n        oof = np.append(oof, scoring(y, temp))\n        \n    return np.mean(oof)","98d81840":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\ndef preprocess(train, test, target_col=\"G3\", standardize=True, impute=True):\n    work = None\n    \n    if not isinstance(train, np.ndarray):\n        if target_col in train.columns:\n            work = train[target_col]\n            train = train.drop(target_col, axis=1)\n    \n    if impute:\n        imputer = SimpleImputer(strategy=\"median\")\n        train = imputer.fit_transform(train)\n        test = imputer.transform(test)\n        \n    if standardize:\n        sc = StandardScaler()\n        train = sc.fit_transform(train)\n        test = sc.transform(test)\n    \n#     if work is not None:\n#         train[target_col] = work.values\n    return train, test","0437d595":"# from sklearn.model_selection import cross_validate\n# from lightgbm import LGBMRegressor\n# from catboost import CatBoostRegressor\n# from xgboost import XGBRegressor, XGBRFRegressor\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.svm import SVR\n# from sklearn.linear_model import ElasticNet, SGDRegressor\n# from sklearn.ensemble import BaggingRegressor\n# from sklearn.tree import DecisionTreeRegressor\n\n# X = df_train_.drop([target_col], axis=1)\n# y = df_train_[target_col]\n\n# X_other = X.drop(target_0_indx, axis=0).values\n# y_other = y.drop(target_0_indx, axis=0).values\n\n\n# d_regs = {\n#     \"LightGBM\": LGBMRegressor(),\n#     \"CatBoost\": CatBoostRegressor(verbose=False),\n#     \"XGBoost\": XGBRegressor(objective=\"reg:squarederror\"),\n#     \"XGRFBoost\": XGBRFRegressor(objective=\"reg:squarederror\"),\n#     \"RandomForest\": RandomForestRegressor(n_estimators=100, n_jobs=-1),\n#     \"DecisionTree\": DecisionTreeRegressor(),\n#     \"Support Vector Machine\": SVR(gamma=\"auto\"),\n#     \"ElasticNet\": ElasticNet(),\n#     \"SGD\": SGDRegressor(),\n# #     \"BaggingReg\": BaggingRegressor(DecisionTreeRegressor(), n_estimators=100, n_jobs=-1),  # \u9577\u3044\u306e\u3067\u4e00\u65e6\u9664\u5916\n# }\n\n# d_scores = {}\n# for reg_name, reg in d_regs.items():\n#     print(\"{} : \".format(reg_name), end=\"\")\n    \n# #     cross_validate(reg, X_other, y_other, cv=5, scoring=rmse_scorer)['test_score'].mean()\n#     d_scores[reg_name] = cross_validation(reg, X_other, y_other, cv=5, scoring=rmse, verbose=False, cat_cols=cat_cols, preprocess=preprocess,\n#                                          random_state=100)\n#     print(d_scores[reg_name])","a8c3d0de":"# plt.figure(figsize=(20, 10))\n# sort_scores = dict(sorted(d_scores.items(), key=lambda x: x[1]))\n# sns.barplot(list(sort_scores.keys()), list(sort_scores.values()))\n# plt.ylim(2.0)\n# plt.title(\"Crossvalidation Score\")\n# plt.show()","dd7556ad":"# vis_model = CatBoostRegressor(verbose=False)\nvis_model = LGBMRegressor()\n\ndf_normal = df_train_[df_train_[target_col] != 0]\nX_normal = df_normal.drop(target_col, axis=1)\ny_normal = df_normal[target_col]","1d4e33d0":"vis_model.fit(X_normal, y_normal)\ndf_imp = pd.DataFrame([vis_model.feature_importances_, \n                      df_normal.drop(target_col, axis=1).columns],\n                     index=['Importance', 'Feature']).T\ndf_imp = df_imp.sort_values('Importance', ascending=False)\n\nplt.figure(figsize=(12, 24))\nsns.barplot(x='Importance', y='Feature', data=df_imp)","da5a1fd8":"X = df_train_.drop([target_col], axis=1)\ny = df_train_[target_col]","1282f2b0":"y_unique = df_train_[target_col].sort_values().unique()","5d59dcdf":"from imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom lightgbm import LGBMClassifier\n\npredict = []\n\nX_test = df_test_.values\n\nfor i in tqdm(y_unique):\n    df_temp = df_train_.copy()\n    \n    df_temp.loc[df_temp[target_col] != i, target_col] = 30\n    \n    X = df_temp.drop(target_col, axis=1)\n    y = df_temp[target_col]\n    \n    if y.value_counts().sort_values()[i] < 6:\n        if y.value_counts().sort_values()[i] < 2:\n            continue\n        n_neighbor = y.value_counts().sort_values()[i] - 1\n    else:\n        n_neighbor = 5\n\n    smote = SMOTE(k_neighbors=n_neighbor)\n    \n    X_, y_ = smote.fit_sample(X, y)\n    \n    clf = LGBMClassifier()\n    \n    clf.fit(X_, y_)\n    predict.append(clf.predict(X_test))","4d829107":"predict = np.array(predict).T","1e09abed":"y_mean = df_train_[df_train[target_col] != 0].mean()[target_col]\npredict_ = pd.DataFrame(predict).replace({30: np.nan}).mean(axis=1).fillna(y_mean)","5da06f63":"df_submit = pd.read_csv(os.path.join(input_path, 'sampleSubmission.csv'))\ndf_submit[target_col] = predict_\ndf_submit.to_csv('submit.csv', index=False)","d504ae8f":"Check DataFrame","5a7a7dae":"## Pie chart.  \n\u81ea\u5206\u7684\u306b\u306f\u4e0b\u306e\u68d2\u30b0\u30e9\u30d5\u306e\u65b9\u304c\u7406\u89e3\u3057\u6613\u3044\u3068\u601d\u3046.","e0ba6d7f":"## Load Library.","ca8f266a":"# Crossvalidation.","c592470c":"## Support multi","e916379b":"## Target Column","9d23b66c":"## Label Encoder","0c351a28":"## Describe\n- Mean \n- Standard Deviation\n- Min \n- Max\n- Quantile","ff2bb39d":"# Visualization Feature Importances.","b71bfa60":"## Numerical Columns.","6b4c99ae":"# EDA(Exploratory Data Analysis)","44af9a86":"## Data type, memory usage.","15a67bed":"## LightGBM","6bb25735":"# Fit and Predict","e7d15113":"## Object Columns","f666d1de":"## Alcohol","a37b38c3":"## Study Time","e17ae8c7":"# Preprocessing.","14d151d7":"## Catigorical Columns","7c8f385f":"# Load Library, Datasets.","8ded6464":"## Boolian Columns.","4a05361d":"## Pairents Education Level.","ad85b8de":"## Load Datasets.","fbc6598b":"## Bar plot","768ee308":"## Drop Object Columns."}}