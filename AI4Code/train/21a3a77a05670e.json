{"cell_type":{"6d69e011":"code","93b0ec99":"code","ec373875":"code","79c6ec1a":"code","2bf37abc":"code","e2ad5d6f":"code","d8dcde2f":"code","4b8272f0":"code","31196678":"code","ad10ee4c":"code","19ee6627":"code","f615ac51":"code","1f3a289e":"code","7bd1fc20":"code","1ec9fda3":"code","9a711190":"code","5af3056d":"code","14c5ab3a":"markdown","cd99f207":"markdown","d89167bf":"markdown","3ba98810":"markdown","35051650":"markdown"},"source":{"6d69e011":"# Load libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n%matplotlib inline\nsns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","93b0ec99":"train_df = pd.read_csv('..\/input\/train_V2.csv')\ntest_df  = pd.read_csv('..\/input\/test_V2.csv')\n\nsubmission_df = pd.DataFrame()\nsubmission_df['Id'] = test_df[\"Id\"].copy()","ec373875":"train_df.info()","79c6ec1a":"def null_percentage(column):\n    df_name = column.name\n    nans = np.count_nonzero(column.isnull().values)\n    total = column.size\n    frac = nans \/ total\n    perc = int(frac * 100)\n    print('%d%% or %d missing values from [ %s ] column.' % (perc, nans, df_name))\n\ndef check_nan(df):\n    columns = df.columns\n    for col in columns: null_percentage(df[col])","2bf37abc":"check_nan(train_df)","e2ad5d6f":"# Just one missing value exists, DROP it.\ntrain_df = train_df.dropna()\ntrain_df.reset_index(drop=True)\ntrain_df.describe().T","d8dcde2f":"# Drop columns\ntrain_df2 = train_df.drop(columns=['Id', 'groupId', 'matchId'])\ntest_df2 = test_df.drop(columns=['Id', 'groupId', 'matchId'])","4b8272f0":"from sklearn.preprocessing import LabelEncoder as LE\n\nle = LE()\ntrain_df2['matchType'] = le.fit_transform(train_df2['matchType'].astype(str))\ntest_df2['matchType'] = le.fit_transform(test_df2['matchType'].astype(str))","31196678":"# Split training dataset into train\/validation set (ratio = 7:3)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler as SS\n\nX = train_df2.iloc[:, 0:-1]; y = train_df2.iloc[:, -1]\n\nscaler_train, scaler_test = SS(), SS()\nscaler_train.fit_transform(X)\nscaler_test.fit_transform(test_df2)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=1040941203)","ad10ee4c":"X_tr = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1).astype('float32')\nX_vd = np.array(X_val).reshape(X_val.shape[0], X_val.shape[1], 1).astype('float32')\n\ny_tr = np.array(y_train)\ny_vd = np.array(y_val)","19ee6627":"X_test = np.array(test_df2)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1).astype('float32')","f615ac51":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv1D\nfrom keras.initializers import random_uniform\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.callbacks import EarlyStopping","1f3a289e":"#hyperparameters\nSEED = 1040941203\nhidden_initializer = random_uniform(seed=SEED)\ndropout_rate = 0.2\n\n# create model\nmodel = Sequential()\nmodel.add(Conv1D(20, 5, input_shape = X_tr.shape[1:3]))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv1D(10, 1))\nmodel.add(Flatten())\nmodel.add(Dense(128, input_dim=25, kernel_initializer=hidden_initializer))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Dense(32))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Dense(1, activation='linear'))\n\nmodel.summary()","7bd1fc20":"model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n\nearly_stopping = EarlyStopping(patience = 3)\nhist = model.fit(X_tr, y_tr, epochs=50, batch_size=5000, validation_data=(X_vd, y_vd), callbacks=[early_stopping])","1ec9fda3":"fig, loss_ax = plt.subplots(figsize=(15,15))\n\nmae_ax = loss_ax.twinx()\n\nloss_ax.plot(hist.history['loss'], 'y', label='train loss', linewidth=5)\nloss_ax.plot(hist.history['val_loss'], 'r', label='val loss', linewidth=9)\n\nmae_ax.plot(hist.history['mean_absolute_error'], 'b', label='train mae')\nmae_ax.plot(hist.history['val_mean_absolute_error'], 'g', label='val mae')\n\nloss_ax.set_xlabel('epoch')\nloss_ax.set_ylabel('loss')\nmae_ax.set_ylabel('MAE')\n\nloss_ax.legend(loc='upper left')\nmae_ax.legend(loc='upper right')\n\nplt.show()","9a711190":"y_pred = model.predict(X_test, batch_size=1000, verbose=True)","5af3056d":"submission_df['winPlacePerc'] = y_pred\nsubmission_df.to_csv('submission_convnet.csv', index=False)","14c5ab3a":"### * Imputing Data","cd99f207":"# Preprocessing Data","d89167bf":"### * Encoding Data","3ba98810":"# Importing Data","35051650":"### * Constructing Models"}}