{"cell_type":{"2d9f98cb":"code","95bfab08":"code","445cc598":"code","5414a68b":"code","7626f366":"code","a6011997":"code","06f0e870":"code","1df3c8af":"code","cf04aae6":"code","5db8750a":"code","815d357c":"code","5fc3394b":"code","d76b02eb":"code","bacfa1d9":"code","dd0989be":"code","51e5b810":"code","a844fb96":"code","1529904c":"code","37a23a93":"code","c00b6964":"code","5bf512b0":"code","d830d096":"code","498612f3":"code","a2e564d7":"code","336c8e8a":"code","48bd792c":"code","8be404f9":"code","90695174":"code","f6ed23f2":"code","6cdd80f0":"code","d005aca6":"code","8e452c13":"code","372bc6e0":"code","90118c4c":"code","f9b9c538":"code","8924ef7c":"code","10a3ceff":"code","7f98bf9f":"code","e264c9dd":"code","bc6f2f92":"code","40088f9d":"code","92f94850":"code","58a408ad":"code","ed17f395":"code","4abe7fb8":"code","df2c9130":"code","ca2572a0":"code","e42428da":"code","a42be0a1":"code","3988bd06":"code","d990c812":"markdown","4d24d15f":"markdown","1fd4f02c":"markdown","18219509":"markdown","7f929724":"markdown","d3ffa3c0":"markdown","4749bd63":"markdown","8a3472c8":"markdown","c36a49dd":"markdown","c75337d3":"markdown","306da56b":"markdown","573eefbf":"markdown","41ac77fc":"markdown","aaf6663c":"markdown"},"source":{"2d9f98cb":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","95bfab08":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","445cc598":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5414a68b":"bike = pd.DataFrame(pd.read_csv(\"\/kaggle\/input\/bike-sharing\/day.csv\"))","7626f366":"# Check the head of the dataset\nbike.head()","a6011997":"# Check the descriptive information\nbike.info()","06f0e870":"bike.describe()","1df3c8af":"# Check the shape of df\n\nprint(bike.shape)","cf04aae6":"# percentage of missing values in each column\nround(100*(bike.isnull().sum()\/len(bike)), 2).sort_values(ascending=False)","5db8750a":"# row-wise null count percentage\nround((bike.isnull().sum(axis=1)\/len(bike))*100,2).sort_values(ascending=False)","815d357c":"bike_dup = bike.copy()\n\n# Checking for duplicates and dropping the entire duplicate row if any\nbike_dup.drop_duplicates(subset=None, inplace=True)","5fc3394b":"bike_dup.shape","d76b02eb":"bike.shape","bacfa1d9":"#Create a copy of the  dataframe, without the 'instant' column, \n\n#as this will have unique values, and donot make sense to do a value count on it.\n\nbike_dummy=bike.iloc[:,1:16]","dd0989be":"for col in bike_dummy:\n    print(bike_dummy[col].value_counts(ascending=False), '\\n\\n\\n')","51e5b810":"bike.columns","a844fb96":"bike_new=bike[['season', 'yr', 'mnth', 'holiday', 'weekday',\n       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n       'cnt']]\n","1529904c":"bike_new.info()","37a23a93":"# Check the datatypes before convertion\nbike_new.info()","c00b6964":"# Convert to 'category' data type\n\nbike_new['season']=bike_new['season'].astype('category')\nbike_new['weathersit']=bike_new['weathersit'].astype('category')\nbike_new['mnth']=bike_new['mnth'].astype('category')\nbike_new['weekday']=bike_new['weekday'].astype('category')\n","5bf512b0":"bike_new.info()","d830d096":"bike_new.head()","498612f3":"!pip install pandas-profiling","a2e564d7":"#Install the below libaries before importing\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\n#EDA using pandas-profiling\nprofile = ProfileReport(bike_new)\n","336c8e8a":"profile","48bd792c":"bike_new.drop(['atemp'], axis = 1,inplace=True) ","8be404f9":"profile_new = ProfileReport(bike_new)","90695174":"profile_new","f6ed23f2":"!pip install pycaret","6cdd80f0":"data = bike_new.sample(frac=0.9, random_state=42)\ndata_unseen = bike_new.drop(data.index)\ndata.reset_index(drop=True, inplace=True)\ndata_unseen.reset_index(drop=True, inplace=True)\nprint('Data for Modeling: ' + str(data.shape))","d005aca6":"print('Unseen Data For Predictions: ' + str(data_unseen.shape))","8e452c13":"from pycaret.regression import *\nexp_reg101 = setup(data = data, target = 'cnt', session_id=1)","372bc6e0":"best = compare_models()","90118c4c":"catboost = create_model('catboost')","f9b9c538":"print(catboost)","8924ef7c":"tuned_catboost = tune_model(catboost)","10a3ceff":"plot_model(tuned_catboost)","7f98bf9f":"plot_model(tuned_catboost, plot = 'error')","e264c9dd":"plot_model(tuned_catboost, plot='feature')","bc6f2f92":"evaluate_model(tuned_catboost)","40088f9d":"predict_model(tuned_catboost)","92f94850":"final_catboost = finalize_model(tuned_catboost)\nfinal_catboost","58a408ad":"predict_model(final_catboost)","ed17f395":"unseen_predictions = predict_model(final_catboost, data=data_unseen)\nunseen_predictions.head()","4abe7fb8":"from pycaret.utils import check_metric\ncheck_metric(unseen_predictions.cnt, unseen_predictions.Label, 'R2')","df2c9130":"save_model(final_catboost,'.\/model')","ca2572a0":"saved_final_catboost = load_model('.\/model')","e42428da":"new_prediction = predict_model(saved_final_catboost, data=data_unseen)","a42be0a1":"new_prediction.head()","3988bd06":"from pycaret.utils import check_metric\ncheck_metric(new_prediction.cnt, new_prediction.Label, 'R2')","d990c812":"### Insights \nThere seems to be no Junk\/Unknown values in the entire dataset.","4d24d15f":"### Insights \n\nThe shape after running the drop duplicate command is same as the original dataframe. \n\nHence we can conclude that there were zero duplicate values in the dataset. ","1fd4f02c":"##  Reading and Understanding the Data\n","18219509":"# Removing redundant & unwanted columns","7f929724":"# Creating Dummy Variables","d3ffa3c0":"## Duplicate Check","4749bd63":"## Check for NULL\/MISSING values","8a3472c8":"# DATA QUALITY CHECK","c36a49dd":"## Finding : \nDataset has 730 rows and 16 columns.\n\nExcept one column, all other are either float or integer type. \n\nOne column is date type.\n\nLooking at the data, there seems to be some fields that are categorical in nature, but in integer\/float type.\n\nWe will analyse and finalize whether to convert them to categorical or treat as integer.","c75337d3":"## Data Cleaning\n\nChecking value_counts() for entire dataframe. \n\nThis will help to identify any Unknow\/Junk values present in the dataset.","306da56b":"# Multiple Linear Regression\n## Bike Sharing Assignment\n\n#### Problem Statement:\n\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\n\nA US bike-sharing provider BikeIndia has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state. \n\n\nIn such an attempt, **BikeIndia** aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\nWhich variables are significant in predicting the demand for shared bikes.\nHow well those variables describe the bike demands\nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors. \n\n#### Business Goal:\n\nWe are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. ","573eefbf":"Based on the high level look at the data and the data dictionary, the following variables can be removed from further analysis:\n\n1. **instant** : Its only an index value\n\n2. **dteday** : This has the date, Since we already have seperate columns for 'year' & 'month',hence, we could live without this column. \n\n3.  **casual & registered** : Both these columns contains the count of bike booked by different categories of customers.\nSince our objective is to find the total count of bikes and not by specific category, we will ignore these two columns.\nMore over, we have created a new variable to have the ratio of these customer types.\n\n4.  We will save the new dataframe as bike_new, so that the original dataset is preserved for any future analysis\/validation","41ac77fc":"We will create DUMMY variables for 4 categorical variables 'mnth', 'weekday', 'season' & 'weathersit'. \n- Before creating dummy variables, we will have to convert them into 'category' data types.","aaf6663c":"## Finding\nThere are no missing \/ Null values either in columns or rows"}}