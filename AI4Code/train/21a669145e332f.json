{"cell_type":{"4419402a":"code","13ba1446":"code","deba3961":"code","2ec8a638":"code","d58ee4ab":"code","14dececc":"code","cd5d656b":"code","7032e478":"code","773f7957":"code","8b1155c4":"code","84afc808":"code","859d3b78":"code","619f29d2":"code","8b5b3324":"code","3789fcb0":"markdown","844ace75":"markdown","98aac7e0":"markdown","93b274c8":"markdown","02c6782e":"markdown","38f6d238":"markdown","3bbe1b60":"markdown","8b4d710a":"markdown","7828f8e0":"markdown","55bdab4c":"markdown","760ebeda":"markdown","55866bb7":"markdown","ec6295b4":"markdown"},"source":{"4419402a":"import pandas as pd\nimport numpy as np\nimport matplotlib as plt","13ba1446":"df = pd.read_csv(\"\/kaggle\/input\/car-price-prediction\/CarPrice_Assignment.csv\", index_col=\"car_ID\")","deba3961":"data = df[['curbweight', 'enginesize', 'highwaympg', 'horsepower', 'citympg', 'peakrpm', 'price']]","2ec8a638":"from pandas.plotting import scatter_matrix\n","d58ee4ab":"from sklearn.model_selection import train_test_split\nX = data[['curbweight', 'enginesize', 'highwaympg', 'horsepower', 'citympg', 'peakrpm']]\ny = data.price\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)","14dececc":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nimport numpy\n","cd5d656b":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nimport numpy\n\npoly_reg = Pipeline([\n    (\"poly_features\", ...), # Ersetze `...` mit dem richtigen Code.\n    (\"lin_reg\", ...)\n])","7032e478":"from sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(poly_reg, {\"poly_features__degree\": [1, 2, 3]})\ngrid_search.fit(X_train, y_train)","773f7957":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\n","8b1155c4":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDRegressor\n\nelastic_net = Pipeline([\n    (\"poly_features\", PolynomialFeatures(degree=4)),\n    (\"std_scaler\", StandardScaler()),\n    (\"elastic_net\", SGDRegressor(...))  # Ersetze `...` mit dem richtigen Code.\n])\ngrid_search = GridSearchCV(elastic_net, {...}, cv=10)  # Ersetze `...` mit dem richtigen Code.\n\n\ngrid_search.fit(X_train, y_train)\nprint(f\"best parameter {grid_search.best_params_}\")\n\n","84afc808":"pd.DataFrame(grid_search.cv_results_).sort_values(\"rank_test_score\").head()","859d3b78":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.exceptions import ConvergenceWarning\n\nsgd = Pipeline([\n    (\"poly_features\", PolynomialFeatures(degree=4)),\n    (\"std_scaler\", StandardScaler()),\n    (\"sgd\", ...)  # Ersetze `...` mit dem richtigen Code.\n])\n","619f29d2":"make_mapping = {\n    \"maxda\": \"mazda\",\n    \"Nissan\": \"nissan\",\n    \"porcshce\": \"porsche\",\n    \"toyouta\": \"toyota\",\n    \"vokswagen\": \"vw\",\n    \"volkswagen\": \"vw\",\n}\n\ndef get_make(car_name: str):\n    make = car_name.split(' ')[0]\n    return make_mapping.get(make, make)\n\nfeatures = ['curbweight', 'enginesize', 'highwaympg', 'horsepower', 'citympg', 'peakrpm']\nX = data.loc[:, features]  # Erstellt eine Kopie\ny = data.price.copy()\n\nX[\"CarMake\"] = df.CarName.map(get_make)","8b5b3324":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.model_selection import GridSearchCV\n","3789fcb0":"- Benutze `sklearn.compose.ColumnTransformer(..., remainder='passthrough'`) und `sklearn.preprocessing.OneHotEncoder` um das kategorische Feature `CarName` in mehrere numerische Features zu verwandeln.\n- Benutze `PolynomialFeatures` und anschlie\u00dfend `StandardScaler` und trainiere ein lineares Regressionsmodell deiner Wahl.","844ace75":"## 2a. Lineare Regression\n- Benutze `X_train, y_train` und `sklearn.linear_model.LinearRegression` um eine lineare Regression zu trainieren.\n- Validiere das Modell mit `sklearn.model_selection.cross_val_score`. Solltest du das Trainingsset oder das Testset verwenden?\n- Benutze `numpy.mean` um den durchschnittlichen Score zu berechnen.","98aac7e0":"## 2b. Polynomregression\nKreiere eine `Pipeline` und benutze `PolynomialFeatures` um ein Polynomregressions-Modell zu erstellen.\nBerechne den durchschnittlichen Cross Validation Score.","93b274c8":"## 2c. Ridge Regression\n- Erstelle eine `Pipeline` und benutze `PolynomialFeatures` um ein Polynomregressions-Modell zu erstellen. Benutze diesmal eine `Ridge` Regression. \n- Benutze `GridSearchCV` um den Hyperparameter $\\alpha$ zu bestimmen.\n- Berechne den durchschnittlichen Cross Validation Score mit dem besten $\\alpha$-Wert. \n- Regularisierte Modelle funktionieren oft besser, wenn man die Daten zus\u00e4tzlich skaliert. Benutze `StandardScaler` und vergleiche den Cross Validation Score. ","02c6782e":"Zuletzt wollen wir unser Datenset in ein *Feature*-Datenset und ein *Target* Datenset teilen, um anschlie\u00dfend ein Trainings- und ein Testset zu erstellen. Diese k\u00f6nnen wir diese beiden Sets verwenden um einige Regressionsmodelle zu testen: ","38f6d238":"## 2d. Elastic Net\nBenutze `PolynomialFeatures` mit einem h\u00f6heren Grad ($\\gt 2$) und erstelle ein Elastic Net Modell. \n- Benutze daf\u00fcr `SGDRegressor` mit `penalty='elasticnet'`. Benutze weiters `GridSearchCV` um die Hyperparameter `alpha` und `l1_ratio` zu w\u00e4hlen. \n- Was sind die besten Hyperparameter. ","3bbe1b60":"- Benutze `pandas.plotting.scatter_matrix` um einen tieferen Einblick in die Daten zu bekommen. Gibt es Features, welche n\u00fctzlicher sind als andere?\n- Berechne eine Korrelationsmatrix. Benutze daf\u00fcr `DataFrame.corr()`.","8b4d710a":"## 2f*. Feature Engineering (Zusatzaufgabe)\nWir wollen ein Feature `CarMake` hinzuf\u00fcgen. Der urspr\u00fcngliche Datensatz hat ein Feature `CarName`. Aus diesem Feature wollen wir die Automarke extrahieren. Allerdings sind die Daten fehlerhaft und k\u00f6nnen Rechtschreibfehler beinhalten.\n- Wie viele Automarken gibt es im Datenset?","7828f8e0":"## 2e. Early Stopping\nErstelle ein regularisiertes Modell, benutze aber diesmal [SGDRegressor](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDRegressor.html?highlight=sgdregressor#sklearn-linear-model-sgdregressor) mit der Einstellung `early_stopping=True` f\u00fcr die Implementierung. \n- Benutze `GridSearchCV` um die Lernrate `eta0` zu bestimmen. \n- Erstelle wie zuvor einen `DataFrame` der Ergebnisse. \n- Im Falle eines schlechten *Scores*, versuche den Parameter `n_iter_no_change` zu erh\u00f6hen. Was macht dieser Parameter?","55bdab4c":"## 2. Vorbereitung der Daten\nIm ersten Teil besch\u00e4ftigen wir uns mit der Vorbereitung der Daten. Das Datenset hat viele Features, in dieser \u00dcbung benutzen wir allerdings nur ein paar davon.\n\nZuerst erstellen wir einen neuen `DataFrame` mit den Features `curbweight, enginesize, highwaympg, horsepower, citympg, peakrpm` und `price`.","760ebeda":"# Lineare Regressionsmodelle\nIn dieser \u00dcbung versuchen wir den Verkaufspreis von Autos mittles verschiedener Regressionsmodelle vorherzusagen. ","55866bb7":"Wir k\u00f6nnen eine Cross Validation mittles `GridSearchCV` machen. Um die inneren Parameter der `Pipeline` zu variieren k\u00f6nnen wir einen doppelten Unterstrich verwenden: `poly_features__degree`.","ec6295b4":"Wir k\u00f6nnen die Ergebnisse der Cross Validation in einem `DataFrame` zusammenfassen:"}}