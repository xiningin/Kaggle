{"cell_type":{"e5100ac8":"code","6141a426":"code","2bdb022c":"code","9799a5f5":"code","c2aa8043":"code","66f4d8a8":"code","425eed02":"code","8636e62f":"code","a4320221":"code","9ef87f54":"code","40999195":"code","cfbc4c0b":"code","34902860":"code","b1fec243":"code","a02d0b72":"code","a5a88fb0":"code","d8749001":"code","34ab8d96":"code","725240b3":"code","8d266a25":"code","a0fd6044":"code","96d8178f":"code","3ec448af":"code","3d723fa2":"code","9e8df45d":"code","ef61236a":"code","e1895bee":"code","945de585":"code","445e2feb":"markdown","7b82790f":"markdown","f9ce816b":"markdown","6cff82b9":"markdown","cfac2e57":"markdown","fd7d6c16":"markdown","1155a4c2":"markdown","ce3aa4f6":"markdown","451c16fb":"markdown","eb7001e7":"markdown"},"source":{"e5100ac8":"import numpy as np \nimport pandas as pd \nimport sklearn\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline\n\n\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")","6141a426":"!ls ..\/input\/","2bdb022c":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ntrain.shape, test.shape","9799a5f5":"train.info()","c2aa8043":"train.head()","66f4d8a8":"train = train.drop(\"Id\", axis=1)","425eed02":"plt.figure(figsize=(9,8))\nsns.distplot(train['SalePrice'], color='g', bins=100);","8636e62f":"list(set(train.dtypes.tolist()))","a4320221":"train_num = train.select_dtypes(include = ['float64', 'int64'])\ntrain_cat = train.select_dtypes(include = ['O'])","9ef87f54":"#univariate distributions\nnum_dist = train_num.describe(percentiles=[0.01,0.05,0.10,0.25,0.50,0.75,0.90,0.95,0.99]).T\nnum_dist = num_dist.rename(columns={\"count\": \"non-missing count\"})\n\n#missing values\nmissing_ = train_num.isnull().sum().to_frame(name = \"missing count\")\nmissing_[\"missing pct\"] = missing_[\"missing count\"] \/ len(train)\n\n#correlations\ncorr_matrix = train_num.corr()\ncorr_matrix[\"abs SalePrice Corr\"] = abs(corr_matrix[\"SalePrice\"])\ncorr_ = corr_matrix[[\"SalePrice\",\"abs SalePrice Corr\"]]\ncorr_ = corr_.rename(columns={\"SalePrice\": \"SalePrice Corr\"})\n\n#Concatenate\nnum_dist = pd.concat([corr_, missing_, num_dist], \n                     axis=1).sort_values(by='abs SalePrice Corr', ascending=False)\n\nnum_dist.style.format({'missing pct':\"{:.2%}\",\n                       'mean':\"{:.1f}\",\n                       'std':\"{:.1f}\",\n                       '5%':\"{:.1f}\",\n                       '10%':\"{:.1f}\",\n                       '25%':\"{:.1f}\",\n                       '50%':\"{:.1f}\",\n                       '75%':\"{:.1f}\",\n                       '90%':\"{:.1f}\",\n                       '95%':\"{:.1f}\",\n                       '99%':\"{:.1f}\",\n                       'min':\"{:.1f}\",\n                       'max':\"{:.1f}\",\n                       'SalePrice Corr':\"{:.2f}\",\n                       'abs SalePrice Corr':\"{:.2f}\",\n                       'missing count':\"{:.0f}\",\n                       'non-missing count':\"{:.0f}\"\n                      })\n","40999195":"missing_[missing_[\"missing pct\"] > 0].sort_values(by=\"missing pct\",ascending=False)","cfbc4c0b":"num_dist[num_dist[\"abs SalePrice Corr\"] > 0.5]","34902860":"highCorr = num_dist[num_dist[\"abs SalePrice Corr\"] > 0.5].T\ncols = list(highCorr.columns)\n\nsns.pairplot(train_num[cols], height = 3, corner=True)\nplt.show();","b1fec243":"for i in range(0, len(train_num.columns),5):\n    sns.pairplot(data=train_num,\n                x_vars=train_num.columns[i:i+5],\n                y_vars=['SalePrice']\n                )","a02d0b72":"cat = list(train.select_dtypes(include = ['O']).columns)\n\ndef bp(x, y, **kwargs):\n    sns.boxplot(x=x, y=y)\n    x=plt.xticks(rotation=90)\n    \nf = pd.melt(train, id_vars=['SalePrice'], value_vars=cat)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False, size=5)\ng = g.map(bp, \"value\", \"SalePrice\")\n","a5a88fb0":"train_cat = train.select_dtypes(include = ['O'])\n\nmissing_cat = train_cat.isna().sum().to_frame(name = \"missing count\")\nmissing_cat[\"missing pct\"] = missing_cat[\"missing count\"] \/ len(train)\n\nmissing_cat[missing_cat[\"missing pct\"] > 0].sort_values(by=\"missing pct\",ascending=False)","d8749001":"train[\"PoolQC\"] = train[\"PoolQC\"].fillna(\"None\")\ntrain[\"MiscFeature\"] = train[\"MiscFeature\"].fillna(\"None\")\ntrain[\"Alley\"] = train[\"Alley\"].fillna(\"None\")\ntrain[\"Fence\"] = train[\"Fence\"].fillna(\"None\")\ntrain[\"FireplaceQu\"] = train[\"FireplaceQu\"].fillna(\"None\")\n\ntrain[\"LotFrontage\"] = train.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    train[col] = train[col].fillna('None')\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    train[col] = train[col].fillna(0)\n\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    train[col] = train[col].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    train[col] = train[col].fillna('None')\n      \ntrain[\"MasVnrType\"] = train[\"MasVnrType\"].fillna(\"None\")\ntrain[\"MasVnrArea\"] = train[\"MasVnrArea\"].fillna(0)\n\ntrain['MSZoning'] = train['MSZoning'].fillna(train['MSZoning'].mode()[0])\n\ntrain[\"Functional\"] = train[\"Functional\"].fillna(\"Typ\")\ntrain['Electrical'] = train['Electrical'].fillna(train['Electrical'].mode()[0])\ntrain['KitchenQual'] = train['KitchenQual'].fillna(train['KitchenQual'].mode()[0])\ntrain['Exterior1st'] = train['Exterior1st'].fillna(train['Exterior1st'].mode()[0])\ntrain['Exterior2nd'] = train['Exterior2nd'].fillna(train['Exterior2nd'].mode()[0])\ntrain['SaleType'] = train['SaleType'].fillna(train['SaleType'].mode()[0])\ntrain['MSSubClass'] = train['MSSubClass'].fillna(\"None\")\n","34ab8d96":"cat_col = list(train.select_dtypes(include = ['O']).columns)\ntrain = pd.get_dummies(train, columns = cat_col)","725240b3":"train_X = train.drop(\"SalePrice\", axis=1) # drop labels for training set\ntrain_Y = train[\"SalePrice\"].copy()","8d266a25":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(train_X, train_Y)\n\nfrom sklearn.metrics import mean_squared_error\n\nhomevalue_predictions = lin_reg.predict(train_X)\nlin_mse = mean_squared_error(train_Y, homevalue_predictions)\nlin_rmse = np.sqrt(lin_mse)\n\nfrom sklearn.metrics import mean_absolute_error\nlin_mae = mean_absolute_error(train_Y, homevalue_predictions)\n\nlin_rmse, lin_mae","a0fd6044":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(lin_reg, train_X, train_Y, scoring=\"neg_mean_squared_error\", cv=10)\npd.Series(np.sqrt(-scores)).describe()","96d8178f":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\nforest_reg.fit(train_X, train_Y)\n\nhomevalue_predictions = forest_reg.predict(train_X)\nforest_mse = mean_squared_error(train_Y, homevalue_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","3ec448af":"from sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, train_X, train_Y,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","3d723fa2":"from sklearn.svm import SVR\n\nsvm_reg = SVR(kernel=\"linear\")\nsvm_reg.fit(train_X, train_Y)\nhomevalue_predictions = svm_reg.predict(train_X)\nsvm_mse = mean_squared_error(train_Y, homevalue_predictions)\nsvm_rmse = np.sqrt(svm_mse)\nsvm_rmse","9e8df45d":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # try 12 (3\u00d74) combinations of hyperparameters\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    # then try 6 (2\u00d73) combinations with bootstrap set as False\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error',\n                           return_train_score=True)\ngrid_search.fit(train_X, train_Y)","ef61236a":"grid_search.best_params_","e1895bee":"grid_search.best_estimator_","945de585":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","445e2feb":"# Support Vector Regression","7b82790f":"# Fine Tune Model - Grid Search","f9ce816b":"# Get the Data","6cff82b9":"# To be Continued...","cfac2e57":"# **Numerics Features - Univariate Distribution, Missing Values, and Correlations**","fd7d6c16":"# Regression","1155a4c2":"# Data Cleansing","ce3aa4f6":"# Random Forest","451c16fb":"# Categorical Features - Univariate Analysis & Data Quality","eb7001e7":"# Tranform Categorical Variables into dummy variables "}}