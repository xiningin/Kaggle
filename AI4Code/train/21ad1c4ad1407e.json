{"cell_type":{"a6d2a4d6":"code","ac0e89fe":"code","9d662de3":"code","34e49198":"code","93212613":"code","7b0847d4":"code","69da673d":"markdown"},"source":{"a6d2a4d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ac0e89fe":"from functools import partial\nimport gc\nimport json\nimport os.path\nimport time\n\nimport datatable as dt\nfrom joblib import delayed, parallel","9d662de3":"INPUT_DIR = '\/kaggle\/input\/mlb-player-digital-engagement-forecasting\/'","34e49198":"%%time\ntrain = dt.fread(os.path.join(INPUT_DIR, 'train_updated.csv')).to_pandas()\ntrain","93212613":"def unpack_json(row: pd.Series, json_col: str) -> pd.DataFrame:\n    try:\n        json_dict = json.loads(row[json_col])\n    except json.JSONDecodeError:\n        return pd.DataFrame()\n    json_df = pd.DataFrame(json_dict)\n    json_df['date__'] = row.date\n    return json_df","7b0847d4":"%%time\nsince = time.time()\njson_columns = train.drop(columns='date').columns.tolist()\nfor c in json_columns:\n    unpack_func = partial(unpack_json, json_col=c)\n    json_df = pd.concat((train[['date', c]].dropna().apply(unpack_func, axis=1)).tolist())\n    print(f'Extract {json_df.shape[0]} rows from {c} ({time.time() - since:.5f} seconds passed)')\n    json_df.to_csv(f'{c}.csv', index=False)\n    print(f'Write \"{c}.csv\" ({time.time() - since:.5f} seconds passed)')\n    del json_df\n    gc.collect()","69da673d":"# train.csv"}}