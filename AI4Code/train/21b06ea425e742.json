{"cell_type":{"43778505":"code","5f1c7627":"code","df08b3b3":"code","b2723ac2":"code","cc18a026":"code","b0e9bb3f":"code","c5c7c747":"code","0c225efa":"code","5372c1ba":"code","0a46495b":"code","19ec812f":"code","60c3d18b":"code","74b498aa":"code","0d3af362":"code","6afd3566":"code","1c484bf9":"code","42561050":"code","26aab1b8":"code","6aaab5ea":"code","4748feae":"code","31c09576":"code","2fb13286":"code","a3311064":"code","1df9ca14":"code","9e91f3b4":"code","9876132e":"code","0e9f459a":"code","27a0aa4c":"code","019fddba":"code","066c5daa":"code","9e3c362b":"code","1b8c7845":"code","6f4b7a4d":"code","d07e7f73":"code","add3c4a5":"code","a7f90d93":"code","6ac9ab8f":"code","0e6b65c1":"code","42483f1c":"code","e874d6c5":"code","7a5e6f55":"code","d7f9610d":"code","7445fdde":"code","3dd23223":"code","30a41f8b":"code","7829ccac":"code","ae8679be":"code","d264a042":"code","8073849f":"code","0fc82238":"code","9b72dc47":"code","63827a00":"code","904bc310":"code","e0a1f79b":"code","28c4dab4":"code","480ce7ca":"code","446280a2":"code","395e68c2":"code","c8c7edb3":"code","bf577685":"code","420b7395":"code","03c61623":"code","1e064dda":"markdown","a264c0e4":"markdown","0d58632b":"markdown","7f1ee75b":"markdown","70dd8f6e":"markdown","b16cc3aa":"markdown","eea38a82":"markdown","21f7cb3d":"markdown","7a36a6c7":"markdown","45c976c2":"markdown","ef5d2974":"markdown","96be292e":"markdown","8e2f4b4b":"markdown","1b176dad":"markdown","19f97f3c":"markdown","77fe35a6":"markdown","e1565c43":"markdown","85bc499d":"markdown","547f5da1":"markdown","5b3d2163":"markdown","c6c314b8":"markdown","011015c7":"markdown","a23db863":"markdown","39102840":"markdown","29bbbbf7":"markdown","f55cf653":"markdown","d629aa2a":"markdown","22b5555a":"markdown","09bfc69b":"markdown","6b95a0cf":"markdown","152eb6bc":"markdown","f46d6607":"markdown"},"source":{"43778505":"#Import all the required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error","5f1c7627":"#Reading the dataset\ndf = pd.read_csv('..\/input\/bike-sharing\/day.csv')\ndf.head()","df08b3b3":"# Check the shape of the dataset\ndf.shape","b2723ac2":"# Check if instant column has unique entries, if yes, then convert it to index\ndf['instant'].nunique()","cc18a026":"# Set the instant column as index to number of columns\ndf.set_index('instant', inplace=True)\ndf.head()","b0e9bb3f":"#Drop the redundant columns i.e. casual and registered\ndf.drop(['casual', 'registered'], inplace=True, axis = 1)\ndf.head()","c5c7c747":"# Check columns of the data types\ndf.info()","0c225efa":"# Convert the dteday to Date Time\ndf['dteday'] = pd.to_datetime(df['dteday'])\ndf['dteday'].dtypes","5372c1ba":"# Change the month number to month abbr for getting better view\nimport calendar\ndf['mnth'] = df['mnth'].apply(lambda x: calendar.month_abbr[x])\ndf['mnth'].unique()","0a46495b":"# Since season, weekday and weathesit are basically categorical values, convert them to string type\ndf[['season','weekday','weathersit']] = df[['season','weekday','weathersit']].astype(str)","19ec812f":"df.info()","60c3d18b":"# Check the percentage of null values in each column\nround(df.isnull().sum()\/len(df.index)*100,2)","74b498aa":"# Check the range of values, for temp, atemp, hum, windspeed\ndf[['temp', 'atemp', 'hum', 'windspeed']].describe()","0d3af362":"# Convert the weathersit variable into more understanable text\ndf['weathersit'].replace(['1','2','3','4'],['Good', 'Average', 'Bad', 'Very Bad'], inplace=True)","6afd3566":"# Convert the seasons into specific season names for better understanding\ndf['season'].replace(['1','2','3','4'],['spring', 'summer', 'fall', 'winter'], inplace=True)","1c484bf9":"# Checking linear relationship between the cnt variable and other numeric variables\nx =sns.pairplot(df, x_vars=['temp', 'atemp', 'hum', 'windspeed'], y_vars=['cnt'] , hue='yr' )\nx._legend.remove()\nplt.legend(labels=['2018', '2019'])\nplt.show()","42561050":"# Check the distribution of rentals across different categorical variables\nplt.figure(figsize = (20,10))\nplt.subplot(2,3,1)\nsns.violinplot(x = 'season', y='cnt', data = df)\nplt.subplot(2,3,2)\nsns.violinplot(x = 'yr', y = 'cnt', data = df)\nplt.subplot(2,3,3)\nsns.violinplot(x = 'mnth', y = 'cnt', data = df)\nplt.subplot(2,3,4)\nsns.violinplot(x = 'holiday', y = 'cnt', data = df)\nplt.subplot(2,3,5)\nsns.violinplot(x = 'weekday', y = 'cnt', data = df)\nplt.subplot(2,3,6)\nsns.violinplot(x = 'workingday', y = 'cnt', data = df)\n\nplt.show()","26aab1b8":"sns.violinplot(x = 'weathersit', y = 'cnt', data = df)\nplt.xlabel('Weather')\nplt.show()","6aaab5ea":"# Check business on Holidays\nholiday_df = df.groupby(['holiday'])['cnt'].mean().reset_index()\nsns.barplot(x = 'holiday', y = 'cnt', data = holiday_df)\nplt.xticks(np.arange(2),('No','Yes'))\nplt.xlabel('Holiday')\nplt.ylabel('Average Number of Rentals')\nplt.show()","4748feae":"# Total rentals on different days of the week.\nweekday_df = df.groupby(['weekday'])['cnt'].mean().reset_index()\nsns.barplot(x = 'weekday', y = 'cnt', data = weekday_df)\nplt.xticks(np.arange(7),('Mon','Tue','Wed','Thu', 'Fri', 'Sat', 'Sun'))\nplt.xlabel('Days of the Week')\nplt.ylabel('Average Number of Rentals')\nplt.show()","31c09576":"# Check business on Workingdays\nworkingday_df = df.groupby(['workingday'])['cnt'].mean().reset_index()\nsns.barplot(x = 'workingday', y = 'cnt', data = workingday_df)\nplt.xticks(np.arange(2),('No','Yes'))\nplt.xlabel('Working Day')\nplt.ylabel('Average Number of Rentals')\nplt.show()","2fb13286":"#Get the dummies\ndummy = pd.get_dummies(df[['season','mnth','weekday','weathersit']], drop_first=True)\ndummy.head()","a3311064":"df = pd.concat([df,dummy], axis = 1)\ndf = df.drop(['season','mnth','weekday','weathersit'], axis = 1)\ndf.head()","1df9ca14":"print('Shape of the new dataframe is:' , df.shape)","9e91f3b4":"#Since we have the month and the year in two separate columns, we no longer need the date column to drop it.\ndf.drop('dteday', inplace = True, axis = 1)","9876132e":"# Move the cnt to the end for easier identification\nfirst_col = df.pop('cnt')\ndf['cnt'] = first_col","0e9f459a":"df_train, df_test = train_test_split(df, train_size = 0.7, random_state = 100)","27a0aa4c":"print('Shape of the Train dataset is:' , df_train.shape)\nprint('Shape of the Test dataset is:' , df_test.shape)","019fddba":"# Check the Train Data\npd.set_option('display.max_columns', None)\ndf_train.head()","066c5daa":"# We will do a MinMax scaling\n#Instantiating the object\nscaler = MinMaxScaler()\ncols = df_train.columns\ndf_train[cols] = scaler.fit_transform(df_train[cols])","9e3c362b":"# Check the Heatmap\nplt.figure(figsize=(25,15))\nsns.heatmap(df_train.corr(),annot=True, cmap='YlGnBu')\nplt.show()","1b8c7845":"y_train = df_train.pop('cnt')\nX_train = df_train\nX_train_sm = sm.add_constant(X_train)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model1 = lr.fit()\nlr_model1.summary()","6f4b7a4d":"# Check VIF (Variance Inflation Factor - MultiColinearity)\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","d07e7f73":"# Removing 'mnth_Mar' due to high P-Value\nX = X_train.drop('mnth_Mar',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model2 = lr.fit()\nlr_model2.summary()","add3c4a5":"# Removing 'weekday_4' due to high P-Value\nX = X.drop('weekday_4',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model3 = lr.fit()\nlr_model3.summary()","a7f90d93":"# Removing 'mnth_Oct' due to high P-Value\nX = X.drop('mnth_Oct',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model4 = lr.fit()\nlr_model4.summary()","6ac9ab8f":"# Removing 'mnth_Jun' due to high P-Value\nX = X.drop('mnth_Jun',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model5 = lr.fit()\nlr_model5.summary()","0e6b65c1":"# Removing 'weekday_3' due to high P-Value\nX = X.drop('weekday_3',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model6 = lr.fit()\nlr_model6.summary()","42483f1c":"# Removing 'atemp' due to high P-Value\nX = X.drop('atemp',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model7 = lr.fit()\nlr_model7.summary()","e874d6c5":"# Removing 'weekday_5' due to high P-Value\nX = X.drop('weekday_5',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model8 = lr.fit()\nlr_model8.summary()","7a5e6f55":"# Removing 'mnth_Aug' due to high P-Value\nX = X.drop('mnth_Aug',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model9 = lr.fit()\nlr_model9.summary()","d7f9610d":"# Removing 'weekday_2' due to high P-Value\nX = X.drop('weekday_2',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model10 = lr.fit()\nlr_model10.summary()","7445fdde":"# Removing 'weekday_1' due to high P-Value\nX = X.drop('weekday_1',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model11 = lr.fit()\nlr_model11.summary()","3dd23223":"# Removing 'mnth_May' due to high P-Value\nX = X.drop('mnth_May',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model12 = lr.fit()\nlr_model12.summary()","30a41f8b":"# Removing 'mnth_Feb' due to high P-Value\nX = X.drop('mnth_Feb',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model13 = lr.fit()\nlr_model13.summary()","7829ccac":"# Checking VIF (Variance Inflation Factor - MultiColinearity)\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","ae8679be":"# Remove 'hum' due to high VIF\nX = X.drop('hum',axis=1)\nX_train_sm = sm.add_constant(X)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model14 = lr.fit()\nlr_model14.summary()","d264a042":"#Checking the VIF Again\nvif = pd.DataFrame()\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","8073849f":"# Check the co-efficients of the final model lr_model14\nprint(lr_model14.summary())","0fc82238":"# Validate Linear Relationship\nsm.graphics.plot_ccpr(lr_model14, 'temp')\nplt.show()","9b72dc47":"# Validate Homoscedasticity : The residuals have constant variance with respect to the dependent variable\ny_train_pred = lr_model14.predict(X_train_sm)\nsns.scatterplot(y_train,(y_train - y_train_pred))\nplt.plot(y_train,(y_train - y_train), '-r')\nplt.xlabel('Count')\nplt.ylabel('Residual')\nplt.show()","63827a00":"# Validate Multi Colinearity\nplt.figure(figsize=(15,8))\nsns.heatmap(X.corr(),annot=True, cmap='YlGnBu')\nplt.show()","904bc310":"print(vif)","e0a1f79b":"# Independence of residuals (absence of auto-correlation)\n# Autocorrelation refers to the fact that observations\u2019 errors are correlated\n# To verify that the observations are not auto-correlated, we can use the Durbin-Watson test. \n# The test will give output values between 0 and 4. The closer it is to 2, the less auto-correlation there is between the various variables\n# (0\u20132: positive auto-correlation, 2\u20134: negative auto-correlation)\n\nprint('The Durbin-Watson value for Model No.14 is',round(sm.stats.stattools.durbin_watson((y_train - y_train_pred)),4))","28c4dab4":"# Normality of Errors\ny_train_pred = lr_model14.predict(X_train_sm)\n\n# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_pred))\nfig.suptitle('Error Terms')                  \nplt.xlabel('Errors')     \nplt.show()","480ce7ca":"sm.qqplot((y_train - y_train_pred), fit = True, line = '45')\nplt.show()","446280a2":"# Scale the Test Dataset with the Scaler of the Training dataset\ncols = df_test.columns\ndf_test[cols] = scaler.transform(df_test[cols])","395e68c2":"# Dividing into X_test and y_test\ny_test = df_test.pop('cnt')\nX_test = df_test","c8c7edb3":"# Adding the constant column\nX_test_m14 = sm.add_constant(X_test)\n# Removing all the columns which has been removed from Model 14\nX_test_m14 = X_test_m14.drop(['hum','mnth_Feb','mnth_Mar','mnth_May',\n                              'mnth_Jun','mnth_Aug','mnth_Oct','atemp',\n                              'weekday_1','weekday_2','weekday_3','weekday_4','weekday_5' ], axis=1)","bf577685":"# Making prediction using Model 14\ny_test_pred = lr_model14.predict(X_test_m14)","420b7395":"print('The R-Squared score of the model for the predicted values is',round(r2_score(y_test, y_test_pred),2))\nprint('The Root Mean Squared Error of the model for the predicted values is',round(np.sqrt(mean_squared_error(y_test, y_test_pred)),4))\nprint('The Mean Absolute Error of the model for the predicted values is',mean_absolute_error(y_test, y_test_pred))","03c61623":"# As asked in problem statement we get the R squared by\nfrom sklearn.metrics import r2_score\nr2_score(y_test, y_test_pred)","1e064dda":"### Splitting the data into Train and Test Dataset","a264c0e4":"### Making prediction using the final model","0d58632b":"### Building the Model\nSince the number of columns is 29, which is manageable, we first build a model with all columns, and then keep removing columns based on statistical significance and co-linearity.\nWe will stop when we notice that there is no further improvement in the R2 value or that all variables are statistically significant with a low VIF value.","7f1ee75b":"Non Holidays have slightly higher average rentals.","70dd8f6e":"The R-square is a significant 85%, but there are insignificant variables and variables with a strong multicollinearity. We need to get rid of them, in the cells below, we're going to follow the same process in itrative fashion until we build a robust model. First, we remove all columns with High P Values, and then when P Values are acceptable to all columns, we check their VIF and remove them.","b16cc3aa":"#### We can see that the equation of our best fitted line developed by Model 14 is:\n\ncnt = 0.1219 + ( 0.2346 * yr - 0.0498 * holiday + 0.0474 * workingday + 0.4370 * temp - 0.1602 * windspeed - 0.0698 * season_spring + 0.0356 * season_summer + 0.0901 * season_winter - 0.0458 * December - 0.0517 * January - 0.0475 * July -0.04078 * November + 0.0674 * September + 0.0596 * weekday_6 - 0.2155 * Bad Weather + 0.0821 * Good Weather )\n","eea38a82":"Rentals are uniform throughout the week, but there's a small uptrend on the weekend.","21f7cb3d":"### Feature Scaling","7a36a6c7":"# **Problem Statement**\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state. \n\n\nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\nWhich variables are significant in predicting the demand for shared bikes.\nHow well those variables describe the bike demands\nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors. \n\n\nBusiness Goal:\nYou are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. ","45c976c2":"As we can see from the above plot, homoscedasticity is well respected as the variance of the residues is almost constant.","ef5d2974":"All variables have a correlation of less than 0,56 with each other. Checking the VIF right now.","96be292e":"Now we see that all variables have a P value < = 0.05, which means that these variables are statistically significant. Let's check if there is any Multi-Colinearity between these variables.","8e2f4b4b":"### Visualizing the data","1b176dad":"The partial residual plot represents the relationship between the predictor and the dependent variable while taking all other variables into account. As we can see from the above graph, linearity is well respected.","19f97f3c":"### Load the Dataset and check it's contents and then check the quality of the data","77fe35a6":"There is almost no auto-correlation","e1565c43":"Taking 10 as the maximum VIF allowed for this model, we decide to retain these limits on the basis of business assumptions.","85bc499d":"### Model Evaluation","547f5da1":"From above figure we can see that the error terms are normally distributed.","5b3d2163":"From above there are no Null values.","c6c314b8":"Since the Model is to be built for the Cnt Column, both casual and registered are redundant. It should not be used to build a model, thus dropping those two columns before further processing.","011015c7":"It looks like an acceptable model. We keep the temp variable because we've seen from our EDA that temperature has a direct colinearity with the booking count. On colder days, the bookings are lower, while on hotter, summer time, the bookings are significantly higher. Thus, as per business understanding, we are finalizing this model as the final model.","a23db863":"The humidity and temperature of the VIF is high , which means that they have multicolinarity and one of them must be removed and checked again.","39102840":"It seems that during the summer months, the registration number will pick up.","29bbbbf7":"We can see that there is a certain correlation between Feeling Temperature and sales. Interestingly, the count in 2019 is much higher than the count in 2018 under all circumstances.","f55cf653":"### Creating Dummy Variables for Categorical Data\n#### We need to create dummy variables for the following columns:\n1. season\n2. mnth\n3. weekday\n4. weathersit","d629aa2a":"# Reading and Understanding the Data","22b5555a":"### Validating the assumptions of Linear Regression\n1. Linear Relationship.\n2. Homoscedasticity.\n3. Absence of Multicollinearity.\n4. Independence of residuals (absence of auto-correlation).\n5. Normality of Errors.","09bfc69b":"cnt has a strong colinearity with yr, temp, atemp. But temp and atemp have almost perfect colinearity, so they can't both be part of the model. We keep this in mind while building a model in the cells below.","6b95a0cf":"All other categorical values have been encoded, other than numeric fields. We can now go ahead and scale the data.","152eb6bc":"#### Final Words:\nAs bookings increase on hot weather days , the company must increase the availability of its bikes and promotions during the summer months in order to further increase the number of bookings.\n\nThe R-Squared value of 0.82 on the test data means that the model is a very good predictor and 82% of the variance is captured by the model.","f46d6607":"Count picks up on Good Weather Days."}}