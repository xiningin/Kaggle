{"cell_type":{"5eb25c1e":"code","fccd323c":"code","709e68b8":"code","bbe06a81":"code","7d100afa":"code","be56d4f3":"code","31fd9669":"code","7546913f":"code","869cf5b3":"code","ab361d07":"code","b82ff4d4":"code","174e5b36":"code","b3b9f079":"code","c3ea1caf":"code","378299e0":"code","96fe67e4":"code","2094312f":"code","321f7c3f":"code","8b0f3f36":"code","bf7d0e5f":"code","5400fd5e":"code","99f924b2":"code","daebb112":"code","7706a082":"code","128cc0b2":"code","dfc5b3fb":"code","64785b73":"code","b6b1c163":"code","da512c23":"code","047a3f9a":"code","b8c7ecc6":"code","857fbfec":"code","3f8e1021":"code","a7f5be2b":"code","74c1df3a":"code","3af8e027":"code","fc0f0665":"code","a99eea46":"code","ac58bbe7":"code","7ec9b3ab":"code","a9ff3b74":"code","9dc3b3c8":"code","753304a7":"code","4789e1b7":"code","6c36b8be":"code","2c430736":"code","2a6c06f8":"code","5a446744":"code","c949cf92":"code","24155bdb":"code","94825a91":"code","e0ee57c5":"code","ae50aab7":"code","6e1be83b":"code","c1410637":"code","924a60df":"code","e6dd51cc":"code","6b9100b9":"code","fb5821a4":"markdown","c2ce6208":"markdown","fc4cb3d6":"markdown","415e5762":"markdown","76aeab87":"markdown","0b5c4408":"markdown","a16fcc50":"markdown","675cd5ce":"markdown","25a5b395":"markdown"},"source":{"5eb25c1e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fccd323c":"BASE_FOLD = '\/kaggle\/input\/ventilator-pressure-prediction\/'\nDEBUG = False","709e68b8":"train = pd.read_csv(BASE_FOLD + 'train.csv', index_col='id')\ntest = pd.read_csv(BASE_FOLD + 'test.csv', index_col='id')\ntrain.shape,test.shape","bbe06a81":"if DEBUG:\n    train = train[:80*1000]","7d100afa":"train.breath_id.nunique(), train.breath_id.nunique()*80","be56d4f3":"test.breath_id.nunique(), test.breath_id.nunique()*80","31fd9669":"train.describe()","7546913f":"test.describe()","869cf5b3":"#plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (10,10)\n\n#sklearn\nfrom sklearn.preprocessing import minmax_scale","ab361d07":"df_full = train[['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']]\ndf_full = pd.DataFrame(minmax_scale(df_full), columns=['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure'])\ndf = df_full.iloc[:80,:]\ndf.describe()","b82ff4d4":"for col in df.columns:\n    print(col)\n    df[col].hist()\n    plt.show()\n","174e5b36":"pd.plotting.scatter_matrix(df, alpha=0.2)","b3b9f079":"plt.rcParams[\"figure.figsize\"] = (10,10)\ncorr_df = df.corr()\nmask = np.zeros_like(corr_df)\nmask[np.triu_indices_from(mask)] = True\n#generate plot\nsns.heatmap(corr_df, cmap='RdYlGn', vmax=1.0, vmin=-1.0 , mask = mask, linewidths=2.5)\nplt.yticks(rotation=0) \nplt.xticks(rotation=90) \nplt.show()","c3ea1caf":"df.mean().plot(style='.')","378299e0":"# Set the width and height of the figure\nplt.figure(figsize=(16,6))\n\n# Line chart showing\nsns.lineplot(data=df)","96fe67e4":"df['R'].nunique(),df['C'].nunique(),df['u_out'].diff().abs().sum()","2094312f":"#breath_id is not continuous\ntrain['breath_id'].unique()[:81]","321f7c3f":"test['breath_id'].unique()[:81]","8b0f3f36":"def count_changes(series):\n    return series.diff().abs().sum()","bf7d0e5f":"agg = train.groupby('breath_id').agg({'u_out': count_changes}).reset_index(drop=False)","5400fd5e":"agg.describe()","99f924b2":"agg = train.groupby('breath_id').agg({'R': [np.mean, np.std], 'C':[np.mean, np.std]}).reset_index(drop=False)\nagg.describe()","daebb112":"agg = test.groupby('breath_id').agg({'u_out': count_changes, 'R': [np.mean, np.std], 'C':[np.mean, np.std]}).reset_index(drop=False)\nagg.describe()","7706a082":"agg = train.groupby('breath_id').agg({'pressure': ['first', 'last', np.mean, np.std]}).reset_index(drop=False)\nagg.head()","128cc0b2":"def flatten_name(prefix, src_names):\n    ret = []\n    for c in src_names:\n        ret.append('.'.join([prefix] + list(c)))\n    return ret","dfc5b3fb":"agg.columns = flatten_name('pressure', agg.columns)","64785b73":"agg['last_first_diff'] = (agg['pressure.pressure.first']*0.5-agg['pressure.pressure.last']*0.5).abs()","b6b1c163":"agg.head()","da512c23":"agg.describe()","047a3f9a":"neg_pressure = agg[agg['pressure.pressure.first'] <= 0]\nneg_pressure.shape","b8c7ecc6":"data=agg[['pressure.pressure.first', 'pressure.pressure.last', 'pressure.pressure.mean', \n          'last_first_diff']].plot()","857fbfec":"#found when u_out is changed\ndef change_index(serial):\n    return np.sum(np.abs(serial - serial.iloc[-1]))","3f8e1021":"%%script echo skipping\n#add time serial id\ndf_train = train.copy()\ndf_train[\"time_id\"] = train.groupby(\"breath_id\")[\"time_step\"].rank(method=\"first\", ascending=True)\n\n\n# make pressure not negtive\ndf_train['pressure.log'] = df_train['pressure']+2\n\n\ndf_train['pressure.log'] = np.log(df_train['pressure.log'])\n# df_train.describe()\n\ndf_train[\"pressure.logdiff\"] = df_train.groupby(\"breath_id\")[\"pressure.log\"].diff()\n\ndf_train[\"u_in.log1p\"] = np.log1p(df_train['u_in'])\n# df_train.describe()\n\ndf_train[\"u_in.log1pdiff\"] = df_train.groupby(\"breath_id\")[\"u_in.log1p\"].diff()\n# df_train.head(81)\n\npv_train = pd.pivot_table(df_train,index=['breath_id'], columns=df_train.groupby(['breath_id']).cumcount().add(1), \n               values=['u_in', 'u_in.log1p', 'u_in.log1pdiff', 'pressure'])\npv_train.columns=pv_train.columns.map('{0[0]}{0[1]}'.format)\n\nagg = train.groupby('breath_id').agg({'u_out': ['first', 'last', change_index], 'R': np.mean, 'C': np.mean}).reset_index(drop=False)\nagg.columns = flatten_name('const', agg.columns)\n# agg.head(81)\n\nagg.rename(columns={'const.breath_id.':'breath_id'}, inplace=True)\n# agg.head()\n\npv_train = pd.merge(pv_train, agg, on='breath_id', how='left')\npv_train.head(81)","a7f5be2b":"#Feature engineering\ndef add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n#     df['R'] = df['R'].astype(str)\n#     df['C'] = df['C'].astype(str)\n#     df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df","74c1df3a":"train = add_features(train)\ntest = add_features(test)","3af8e027":"train.shape, test.shape","fc0f0665":"def get_feature(train, target=False):\n    df_train = train.copy()\n#     df_train[\"u_in.log1p\"] = np.log1p(df_train['u_in'])\n#     df_train[\"u_in.log1pdiff\"] = df_train.groupby(\"breath_id\")[\"u_in.log1p\"].diff()\n    # remove constant features\n    value_cols = [col for col in df_train.columns if col not in ['breath_id', 'R', 'C', 'time_step', 'u_out']]\n\n    pv_train = pd.pivot_table(df_train,index=['breath_id'], columns=df_train.groupby(['breath_id']).cumcount().add(1), \n                   values=value_cols)\n#     pv_train.columns=pv_train.columns.map('{0[0]}{0[1]}'.format)\n    print(pv_train.shape)\n    features = {'u_out': ['first', 'last', change_index], 'R': np.mean, 'C': np.mean}\n    agg = train.groupby('breath_id').agg(features).reset_index(drop=False)\n    agg.columns = flatten_name('const', agg.columns)\n    agg.rename(columns={'const.breath_id.':'breath_id'}, inplace=True)\n    pv_train = pd.merge(pv_train, agg, on='breath_id', how='left')\n    del df_train\n    \n    return pv_train","a99eea46":"%%time\npv_train = get_feature(train, True)\n#pv_train.to_csv('pv_train.csv', index=False)\npv_train.head()","ac58bbe7":"import collections\na = pv_train.columns.to_list()\n[x for x, y in collections.Counter(a).items() if y > 1]","7ec9b3ab":"[col for col in pv_train.columns if 'pressure' in col]","a9ff3b74":"pv_test = get_feature(test)\npv_test.head(81)","9dc3b3c8":"#pv_test.to_csv('pv_test.csv', index=False)","753304a7":"y_features = [col for col in pv_train.columns if 'pressure' in col]\ny_target = pv_train[y_features]\ny_target.head()","4789e1b7":"import gc","6c36b8be":"# del train,test\n_= gc.collect()","2c430736":"from numpy.random import seed\nimport tensorflow as tf\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n  tf.config.experimental.set_memory_growth(gpu, True)\n\ntf.random.set_seed(42)\nfrom tensorflow import keras\nimport numpy as nptensorflow\nfrom tensorflow.keras import backend as K","2a6c06f8":"#reset Keras Session\ndef reset_keras():\n    sess = tf.compat.v1.keras.backend.get_session()\n    tf.compat.v1.keras.backend.clear_session()\n    sess.close()\n    sess = tf.compat.v1.keras.backend.get_session()\n\n    # use the same config as you used to create the session\n    config = tf.compat.v1.ConfigProto()\n    config.gpu_options.per_process_gpu_memory_fraction = 1\n    config.gpu_options.visible_device_list = \"0\"\n    tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n    gc.collect()","5a446744":"def base_model(feature_num, out_num, hidden_units, dropout_rates):\n    print('base_model', feature_num, out_num, hidden_units, dropout_rates)\n    \n    num_input = keras.Input(shape=(feature_num,), name='num_data')\n    input_dense_num = feature_num\n    if hidden_units[0] != -1:\n        input_dense_num = hidden_units[0]\n    \n    input_features = keras.layers.Dense(input_dense_num)(num_input)\n    \n    input_features = keras.layers.BatchNormalization()(input_features)\n    input_features = keras.layers.Activation('swish')(input_features)\n    if dropout_rates[0] < 1:\n        input_features = keras.layers.Dropout(dropout_rates[0])(input_features)\n\n    out = input_features\n    \n#     # Add one or more hidden layers\n    for i in range(1, len(hidden_units)):\n        out = keras.layers.Dense(hidden_units[i])(out)\n        out = keras.layers.BatchNormalization()(out)\n        out = keras.layers.Activation('swish')(out)\n        if dropout_rates[i] < 1:\n            out = keras.layers.Dropout(dropout_rates[i])(out)\n\n    # A single output: our predicted rating\n    out = keras.layers.Dense(out_num, activation='linear', name='prediction')(out)\n    \n    model = keras.Model(\n    inputs = [num_input],\n    outputs = out\n    )\n    \n    model.summary()\n    \n    return model\n","c949cf92":"from sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\n\ndef train_and_evaluate_nn_base(train, test, params):\n    \n    features = [col for col in train.columns if 'pressure' not in col and 'breath_id' not in col ]\n    y_features = [col for col in train.columns if 'pressure' in col]\n    print(train.shape, test.shape, len(features), len(y_features))\n    y = train[y_features]\n    \n    y_train = np.zeros(y.shape)\n    y_test = np.zeros((test.shape[0],y.shape[1]))\n    \n    print('Check null in train', train[features].isnull().any())\n    print('Check null in test', test[features].isnull().any())\n    train[features] = train[features].fillna(train[features].mean())\n    test[features] = test[features].fillna(train[features].mean())\n    print('Check null in test again', test[features].isnull().any())\n    \n    kf = KFold(n_splits=NFOLD, shuffle=True, random_state=1)\n    for fold, (train_idx, valid_idx) in enumerate(kf.split(train)):\n        print('Fold:', fold)\n        x_train, x_val = train.iloc[train_idx], train.iloc[valid_idx]\n        y_tra, y_val = y.iloc[train_idx], y.iloc[valid_idx]\n\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        num_data = x_train[features].values\n        num_data = scaler.fit_transform(num_data)\n\n        num_data_val = x_val[features].values\n        num_data_val = scaler.transform(num_data_val)\n        \n        model = base_model(len(features), len(y_features), params['hidden_units'], params['dropout_rates'])\n\n        model.compile(\n            keras.optimizers.Adam(learning_rate=params['learning_rate']),\n            loss=keras.losses.MeanAbsoluteError()\n        )\n        \n\n        es = tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss', patience=20, verbose=0,\n            mode='min',restore_best_weights=True)\n\n        plateau = tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss', factor=0.2, patience=7, verbose=0,\n            mode='min')\n\n        model.fit([num_data], \n                  y_tra,               \n                  batch_size=params['batch_size'],\n                  epochs=params['epochs'],\n                  validation_data=([num_data_val], y_val),\n                  callbacks=[es, \n                            plateau\n                            ],\n                  validation_batch_size=len(y_val),\n                  shuffle=True,\n                 verbose = 1)\n\n        pred_val = model.predict([num_data_val]).reshape(1,-1, len(y_features))[0]\n        y_train[valid_idx] = pred_val\n        test_nn = test[features].values\n        test_nn = scaler.transform(test_nn)\n        y_test += model.predict([test_nn]).reshape(1,-1, len(y_features))[0]\n        \n        print(y_train[valid_idx][:3], y_test[:3])\n        print('NN base MSE Fold:', mean_absolute_error(y_target.iloc[valid_idx], y_train[valid_idx]))\n        \n        #Delete model and release GPU memory\n        del model, num_data, num_data_val, scaler, test_nn\n        gc.collect()\n        reset_keras()\n    y_test\/=NFOLD\n    \n    return y_train, y_test","24155bdb":"import time\n\nnn_base_time = time.time()\nNFOLD = 5\n\n\nparams = {\n    'batch_size': 4096,\n    'epochs': 1000,\n    'learning_rate': 0.006,\n#     'hidden_units': [128, 128, 64, 32], 1.180226882297499\n    'hidden_units': [-1, 2048, 1024, 512],\n    'dropout_rates': [0.03527936123679956, 0.32024444956111164,\n                     0.2716856145683449,\n                     0.4379233941604448] # 1 means no dropout\n}\n\ny_nn_train1, y_nn_test1 = train_and_evaluate_nn_base(pv_train, pv_test, params)\n_= gc.collect()\n\nprint('Check zero in prediction:', (y_nn_train1 == 0).sum())\nnp.savetxt('pred_nn.csv', y_nn_train1, delimiter=',')\n\nprint( 'NN base MSE CV:', mean_absolute_error(y_target, y_nn_train1), 'time: ', int(time.time() - nn_base_time), 's', y_nn_test1[:3])","94825a91":"y_pressure = y_nn_test1.reshape((-1))","e0ee57c5":"sample_submission = pd.read_csv(BASE_FOLD + 'sample_submission.csv')","ae50aab7":"sample_submission.pressure = y_pressure","6e1be83b":"sample_submission.head()","c1410637":"sample_submission.to_csv('submission.csv', index=False)","924a60df":"train['pressure.pred'] = y_nn_train1.reshape((-1))","e6dd51cc":"train.head(81)","6b9100b9":"# Set the width and height of the figure\nplt.figure(figsize=(16,6))\n\n# Line chart showing\nsns.lineplot(data=train.iloc[:80,:][['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure', 'pressure.pred']])","fb5821a4":"# Train data has similar mean\/std","c2ce6208":"# Check each batch","fc4cb3d6":"## Baseline","415e5762":"## Split train to batch, change pressure to log change","76aeab87":"# From above, we can see R and C are constant, u_out only changes once. Let's confirm it in all train\/test data","0b5c4408":"As we can see, the last value of pressure is similar to the first one, the average is higher than the first\/last value.","a16fcc50":"# Train\/Test data is batched by 80","675cd5ce":"## Get feature for test","25a5b395":"# Model"}}