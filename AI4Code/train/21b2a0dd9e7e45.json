{"cell_type":{"02b014c0":"code","c761dea2":"code","a9c8094e":"code","83287c3b":"code","a4963c9e":"code","bc2ffd8d":"code","2a6de4f7":"code","b55b1b6c":"code","712e9dfa":"code","e3ba793a":"code","ffa4640c":"code","8fd53f0d":"code","2a613db7":"code","ab8acb0e":"code","dd4ca16e":"code","618dec3c":"code","a8f30c67":"code","0a324f3e":"code","52973578":"code","e6b6cdc0":"code","5a959d22":"code","336a66a7":"code","5e1e9a3b":"code","85f985f8":"code","575efe30":"code","b6b2425e":"code","46c85414":"code","8723a316":"code","c62130f4":"markdown","6e670f7d":"markdown","069d7f48":"markdown","4430222c":"markdown","87a3b456":"markdown","643b98d3":"markdown","2a5c501a":"markdown","1a83abaf":"markdown","fe7c1f32":"markdown","c0718d30":"markdown","0557d9c9":"markdown","8a9c81df":"markdown","ae24a998":"markdown"},"source":{"02b014c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.preprocessing import image\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense,Flatten,Input\nfrom keras.optimizers import SGD,RMSprop,Adagrad,Adadelta,Adam,Adamax,Nadam\nfrom keras.losses import mean_squared_error\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras.applications.imagenet_utils import preprocess_input\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nfrom keras.models import load_model\nimport pickle\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom PIL import Image\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n%matplotlib inline\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\nimport tensorflow as tf\n","c761dea2":"def add_snow(img,factor):                      #Function to add snow\n    image_HLS=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n    image_HLS=np.array(image_HLS,dtype=np.float64)\n    brightness_coef=2.5\n    snow_point=factor\n    image_HLS[:,:,1][image_HLS[:,:,1]<snow_point]= image_HLS[:,:,1][image_HLS[:,:,1]<snow_point]*brightness_coef\n    image_HLS[:,:,1][image_HLS[:,:,1]>255]  = 255\n    image_HLS=np.array(image_HLS,dtype=np.uint8)\n    image_RGB=cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n    return image_RGB\n\ndef add_brightness(img,factor):               #Function to change brightness\n    image_HLS=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n    image_HLS=np.array(image_HLS,dtype=np.float64)\n    image_HLS[:,:,1]=image_HLS[:,:,1]*factor\n    image_HLS[:,:,1][image_HLS[:,:,1]>255]  = 255\n    image_HLS=np.array(image_HLS,dtype=np.uint8)\n    image_RGB=cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n    return image_RGB\n\ndef add_saturation(img,factor):           #Function to change saturation\n    image_HLS=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n    image_HLS=np.array(image_HLS,dtype=np.float64)\n    image_HLS[:,:,2]=image_HLS[:,:,2]*factor\n    image_HLS[:,:,2][image_HLS[:,:,2]>255]  = 255\n    image_HLS=np.array(image_HLS,dtype=np.uint8)\n    image_RGB=cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n    return image_RGB\n\ndef add_hue(img,factor):                 #Function to change hue\n    image_HLS=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n    image_HLS=np.array(image_HLS,dtype=np.float64)\n    image_HLS[:,:,0]=image_HLS[:,:,0]*factor\n    image_HLS[:,:,0][image_HLS[:,:,0]>255]  = 255\n    image_HLS=np.array(image_HLS,dtype=np.uint8)\n    image_RGB=cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n    return image_RGB\n\ndef generate_random_lines(imshape,slant,drop_length):\n    drops=[]\n    for i in range(1500): ## If You want heavy rain, try increasing this\n        if slant<0:\n            x= np.random.randint(slant,imshape[1])\n        else:\n            x= np.random.randint(0,imshape[1]-slant)\n        y= np.random.randint(0,imshape[0]-drop_length)\n        drops.append((x,y))\n    return drops\n        \n    \ndef add_rain(image):\n    \n    imshape = image.shape\n    slant_extreme=10\n    slant= np.random.randint(-slant_extreme,slant_extreme) \n    drop_length=20\n    drop_width=2\n    drop_color=(200,200,200) ## a shade of gray\n    rain_drops= generate_random_lines(imshape,slant,drop_length)\n    \n    for rain_drop in rain_drops:\n        cv2.line(image,(rain_drop[0],rain_drop[1]),(rain_drop[0]+slant,rain_drop[1]+drop_length),drop_color,drop_width)\n    image= cv2.blur(image,(7,7)) ## rainy view are blurry\n    \n    brightness_coefficient = 0.7 ## rainy days are usually shady \n    image_HLS = cv2.cvtColor(image,cv2.COLOR_RGB2HLS) ## Conversion to HLS\n    image_HLS[:,:,1] = image_HLS[:,:,1]*brightness_coefficient ## scale pixel values down for channel 1(Lightness)\n    image_RGB = cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB) ## Conversion to RGB\n    return image_RGB\n\ndef flip(img):                #Function to return mirror image\n    return np.fliplr(img)\n\ndef resize(image):                        #Function to resize the image\n    image=image.resize((img_height,img_width),Image.ANTIALIAS)\n    return image","a9c8094e":"def prepareImages(data, m, dataset):\n    print(\"Preparing images\")\n    X_train = np.zeros((m, 100, 100, 3))\n    count = 0\n    \n    for fig in data['Image']:\n        #load images into images of size 100x100x3\n        img = image.load_img(\"..\/input\/humpback-whale-identification\/\"+dataset+\"\/\"+fig, target_size=(100, 100, 3))\n        x = image.img_to_array(img)\n        x = preprocess_input(x)\n\n        X_train[count] = x\n        if (count%500 == 0):\n            print(\"Processing image: \", count+1, \", \", fig)\n        count += 1\n    \n    return X_train\n\n","83287c3b":"train_data_dir='..\/input\/humpback-whale-identification\/train'\ntest_data_dir='..\/input\/humpback-whale-identification\/test'\nimg_height,img_width=100,100\n","a4963c9e":"train=pd.read_csv(train_data_dir+'.csv')\ntrain_md=pd.get_dummies(train,columns=['Id'])\ntrain_md.describe()","bc2ffd8d":"\ntrain_md=train_md[train_md.Id_new_whale!=1]\ntrain_md.describe()","2a6de4f7":"train_md.dropna()\ntrain_md.drop(['Id_new_whale'],axis=1,inplace=True)\ntrain_md.info()","b55b1b6c":"\ny=train_md.drop(train_md.columns[0],axis=1)\nnames=list(y.columns.values)\ny=np.array(y)\nX=prepareImages(train_md,train_md.shape[0],\"train\")\nX\/=255\nX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.1,random_state=2)\nX_train=X\ny_train=y","712e9dfa":"print(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)","e3ba793a":"model=applications.vgg16.VGG16(include_top=False,weights='imagenet',input_shape=(100,100,3),pooling='avg')\nfor layer in model.layers[:-5]:\n    layer.trainable=False\nprint(model.output.shape)    ","ffa4640c":"x=model.output\nx=Dense(5004,activation='softmax')(x)\nmodel_final=Model(inputs=model.input,outputs=x)\ndel X\ndel y\ngc.collect()\nprint(model_final.output.shape)\n","8fd53f0d":"model_final.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(),metrics=['acc'])\nmodel_final.summary()","2a613db7":"history=model_final.fit(X_train,y_train,epochs=20,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ngc.collect()","ab8acb0e":"del X_train\ngc.collect()","dd4ca16e":"X_list=np.array(train['Image'])\nprint(X_list)","618dec3c":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_snow(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),50))\n    \n  \nX=np.array(X)\nX=X\/255  \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()\n","a8f30c67":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_snow(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),100))\n    \nX=X\/255   \nX=np.array(X)\nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","0a324f3e":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_snow(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),150))\n    \nX=X\/255    \nX=np.array(X)\nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","52973578":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_brightness(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),0.5))\n    \n\nX=np.array(X)\nX=X\/255   \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","e6b6cdc0":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_brightness(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),1.25))\n    \n\nX=np.array(X)\nX=X\/255  \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","5a959d22":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_brightness(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),1.75))\n    \n \nX=np.array(X)\nX=X\/255   \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","336a66a7":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_saturation(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),0.5))\n    \n\nX=np.array(X)\nX=X\/255  \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","5e1e9a3b":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_saturation(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),1.5))\n    \n\nX=np.array(X)\nX=X\/255  \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","85f985f8":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_hue(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),0.5))\n    \n \nX=np.array(X)\nX=X\/255   \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","575efe30":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_hue(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width)),1.5))\n    \n\nX=np.array(X)\nX=X\/255    \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","b6b2425e":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_rain(cv2.resize(cv2.imread(train_data_dir+\"\/\"+X_list[i]),(img_height,img_width))))\n    \n   \nX=np.array(X)\nX=X\/255 \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","46c85414":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(resize(flip(cv2.imread(train_data_dir+\"\/\"+X_list[i]))))\n    \n\nX=np.array(X)\nX=X\/255    \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","8723a316":"model_final.save_weights('model1weights.h5')\nmodel_final.save('model1.h5')","c62130f4":"#plt.imshow(X[0])","6e670f7d":"def read_and_process_image(image_dir):          #Read Images from directory and processes them\n    X=[]\n    for image in image_dir:\n        X.append(cv2.resize(cv2.imread(train_data_dir+'\/'+image,cv2.IMREAD_COLOR),(img_height,img_width),interpolation=cv2.INTER_AREA))\n        #print(image)\n    return X    ","069d7f48":"val_generator=val_datagen.flow(X_val,y_val)","4430222c":"X_test=X_train[:10,:,:,:]\nmodel_final=load_model('model1.h5')\nmodel_final.load_weights('model1weights.h5')","87a3b456":"print(np.max(arr[0]))","643b98d3":"print(names[np.argmax(arr[2])])\nprint(np.max(arr[2]))","2a5c501a":"print(X.shape)","1a83abaf":"arr=model_final.predict(X_train)","fe7c1f32":"for j in tqdm(range(64)):\n    for i in range(15):\n        train_generator=train_datagen.flow(X_train[i*1000:(i+1)*1000],y_train[i*1000:(i+1)*1000])\n        history=model_final.fit_generator(train_generator,steps_per_epoch=1000\/\/32,epochs=1,validation_data=val_generator,validation_steps=1000\/\/32)\n        del train_generator\n        gc.collect()\n\n    train_generator=train_datagen.flow(X_train[15000:15697],y_train[15000:15697])\n    history=model_final.fit_generator(train_generator,steps_per_epoch=100\/\/32,epochs=1,validation_data=val_generator,validation_steps=1000\/\/32)\n    del train_generator\n    gc.collect()","c0718d30":"print(X_train.shape)\nprint(y_train.shape)","0557d9c9":"\nprint(names[np.argmax(arr[0])])","8a9c81df":"X_train=read_and_process_image(X_train)\nX_train=np.array(X_train)\nX_val=read_and_process_image(X_val)\nX_val=np.array(X_val)","ae24a998":"train_tt=pd.get_dummies(train,columns=['Id'])\nX=train_tt['Image']\nX=np.array(X)"}}