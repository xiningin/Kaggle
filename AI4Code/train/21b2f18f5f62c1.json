{"cell_type":{"96e49ca3":"code","4a6ee93d":"code","7b292598":"code","4676b04d":"code","7bc2146a":"code","e117506a":"code","6bca5cc6":"code","26578278":"code","58b47989":"code","4a305323":"code","39ef4a94":"code","987d355f":"code","bf326d7e":"code","f7a8f33a":"code","e0e2f219":"code","694d70b2":"code","ec82bec5":"code","c04be9d7":"code","6ada0d46":"code","3eb667fe":"code","0562ce50":"code","d3c217a7":"code","4710dbd4":"code","a144822d":"code","78e0ff4d":"code","919d4ad7":"code","01c00913":"code","f705a550":"code","3d4a31ad":"code","452e5b59":"code","9b2c73ee":"code","d0b0d3c6":"code","63bd1b20":"code","795c6a96":"code","e8593777":"code","53430d88":"code","a89bb117":"code","9eebacf6":"code","69ba8584":"code","3a97330f":"code","30eb426a":"code","6f8f404b":"code","c5aed596":"code","0fbf7974":"code","1b26811c":"code","6ce9c47f":"code","b28646d4":"code","e595dbf2":"code","f6616a07":"code","4e5046c6":"code","062bed42":"code","9dad7b7e":"code","236ce708":"code","90c0a300":"code","cc1ceeff":"code","de56b90b":"code","d1fb35b4":"code","936a9678":"code","eba76702":"code","d51bb085":"markdown","c8469f8b":"markdown","5b87e080":"markdown","d1d4647f":"markdown","66740c9f":"markdown","21e42da6":"markdown"},"source":{"96e49ca3":"!pip install tensorflow-gpu==2.0.0-beta1","4a6ee93d":"import tensorflow as tf","7b292598":"print(tf.__version__)","4676b04d":"\n# small data 2000\nimport os\nimport zipfile\nimport random\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile","7bc2146a":"import urllib.request\nurllib.request.urlretrieve(\"https:\/\/storage.googleapis.com\/mledu-datasets\/cats_and_dogs_filtered.zip\",\"cats_and_dogs_filtered.zip\")","e117506a":"local_zip = 'cats_and_dogs_filtered.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('..\/output\/')","6bca5cc6":"cwd = os.getcwd()\nprint(cwd)","26578278":"!ls","58b47989":"import os\nos.listdir('..\/output\/cats_and_dogs_filtered')","4a305323":"import os\nos.listdir(\"..\/output\/cats_and_dogs_filtered\/train\")","39ef4a94":"base_dir = \"..\/output\/cats_and_dogs_filtered\"\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation')\n\n# Directory with our training cat\/dog pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\n# Directory with our validation cat\/dog pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')","987d355f":"train_cat_fnames = os.listdir( train_cats_dir )\ntrain_dog_fnames = os.listdir( train_dogs_dir )\n\nprint(train_cat_fnames[:10])\nprint(train_dog_fnames[:10])","bf326d7e":"\nprint('total training cat images :', len(os.listdir(      train_cats_dir ) ))\nprint('total training dog images :', len(os.listdir(      train_dogs_dir ) ))\n\nprint('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\nprint('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))","f7a8f33a":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 2\nncols = 2\n\npic_index = 0 # Index for iterating over images\n# Set up matplotlib fig, and size it to fit 2x2 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*2, nrows*2)\n\npic_index+=4\n\n","e0e2f219":"next_cat_pix = [os.path.join(train_cats_dir, fname) \n                for fname in train_cat_fnames[ pic_index-4:pic_index] \n               ]\n\n\nfor i, img_path in enumerate(next_cat_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","694d70b2":"\n\nnext_dog_pix = [os.path.join(train_dogs_dir, fname) \n                for fname in train_dog_fnames[ pic_index-4:pic_index]\n               ]\n\nfor i, img_path in enumerate(next_dog_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","ec82bec5":"# clean data\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator( rescale = 1.0\/255. )\ntest_datagen  = ImageDataGenerator( rescale = 1.0\/255. )\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory('..\/output\/cats_and_dogs_filtered\/train',\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory('..\/output\/cats_and_dogs_filtered\/validation',\n                                                         batch_size=20,\n                                                         class_mode  = 'binary',\n                                                         target_size = (150, 150))\n","c04be9d7":"\n# define model\nimport tensorflow as tf\n\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    #tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(128, activation='relu'), \n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])","6ada0d46":"# model summary    \nmodel.summary()","3eb667fe":"\n# compile model    \nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n              metrics = ['acc'])","0562ce50":"# train model\n# Note that this may take some time.\n# use model.fit_generator not model.fit  because the data is generator data\nhistory = model.fit_generator(train_generator,\n                              validation_data=validation_generator,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_steps=50,\n                              verbose=1)","d3c217a7":"\n# model result\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\nacc      = history.history[     'acc' ]\nval_acc  = history.history[ 'val_acc' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )\n\n","4710dbd4":"# evaluate model\n\nmodel.evaluate(validation_generator)","a144822d":"\n# small data 2000\nimport os\nimport zipfile\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\n","78e0ff4d":"\n# clean data with Augmentation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory('..\/output\/cats_and_dogs_filtered\/train',\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory('..\/output\/cats_and_dogs_filtered\/validation',\n                                                         batch_size=20,\n                                                         class_mode  = 'binary',\n                                                         target_size = (150, 150))","919d4ad7":"\n\n# define model\nimport tensorflow as tf\n\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(256, activation='relu'), \n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])\n# model summary    \nmodel.summary()\n        ","01c00913":"\n# compile model    \nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n              metrics = ['acc'])","f705a550":"# train model\n# Note that this may take some time.\n# use model.fit_generator not model.fit  because the data is generator data\nhistory = model.fit_generator(train_generator,\n                              validation_data=validation_generator,\n                              steps_per_epoch=100,\n                              epochs=15,\n                              validation_steps=50,\n                              verbose=1)\n","3d4a31ad":"\n# model result\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\nacc      = history.history[     'acc' ]\nval_acc  = history.history[ 'val_acc' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )\n","452e5b59":"\n# evaluate model\n\nmodel.evaluate(validation_generator)\n","9b2c73ee":"\nimport os\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\n\n\n\n# small data 2000\nimport os\nimport zipfile\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n","d0b0d3c6":"\n# clean data with Augmentation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory('..\/output\/cats_and_dogs_filtered\/train',\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory('..\/output\/cats_and_dogs_filtered\/validation',\n                                                         batch_size=20,\n                                                         class_mode  = 'binary',\n                                                         target_size = (150, 150))","63bd1b20":"# download model weight\nimport urllib.request\nurllib.request.urlretrieve(\"https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\",'..\/output\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n#!wget --no-check-certificate \\\n#    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 ","795c6a96":"!ls","e8593777":"local_weights_file = '..\/output\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'","53430d88":"pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n  \n","a89bb117":"pre_trained_model.summary()","9eebacf6":"for i, layer in enumerate(pre_trained_model.layers): \n    print(i, layer.name)","69ba8584":"\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","3a97330f":"from tensorflow.keras.optimizers import RMSprop\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc'])","30eb426a":"model.summary()","6f8f404b":"history = model.fit_generator(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 10,\n            validation_steps = 50,\n            verbose = 1)","c5aed596":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","0fbf7974":"# download data\nimport urllib.request\nurllib.request.urlretrieve(\"https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/rps.zip\",\"..\/output\/rps.zip\")\nurllib.request.urlretrieve(\"https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/rps-test-set.zip\",\"..\/output\/rps-test-set.zip\")\n","1b26811c":"import os\ncwd = os.getcwd()\nprint(cwd)","6ce9c47f":"!ls","b28646d4":"import os\nimport zipfile\ndata_location='..\/output'\n\n\nlocal_zip = data_location+'\/rps.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall(data_location)\nzip_ref.close()\n\nlocal_zip = data_location+'\/rps-test-set.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall(data_location)\nzip_ref.close()\n\n\nrock_dir = data_location+'\/rps\/rock'\npaper_dir = data_location+'\/rps\/paper'\nscissors_dir = data_location+'\/rps\/scissors'\n\n","e595dbf2":"print('total training rock images:', len(os.listdir(rock_dir)))\nprint('total training paper images:', len(os.listdir(paper_dir)))\nprint('total training scissors images:', len(os.listdir(scissors_dir)))\n","f6616a07":"rock_files = os.listdir(rock_dir)\nprint(rock_files[:10])\n\npaper_files = os.listdir(paper_dir)\nprint(paper_files[:10])\n\nscissors_files = os.listdir(scissors_dir)\nprint(scissors_files[:10])","4e5046c6":"\n\n# show picture\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\npic_index = 2\n\nnext_rock = [os.path.join(rock_dir, fname) \n                for fname in rock_files[pic_index-2:pic_index]]\nnext_paper = [os.path.join(paper_dir, fname) \n                for fname in paper_files[pic_index-2:pic_index]]\nnext_scissors = [os.path.join(scissors_dir, fname) \n                for fname in scissors_files[pic_index-2:pic_index]]\n\nfor i, img_path in enumerate(next_rock+next_paper+next_scissors):\n  #print(img_path)\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n  plt.axis('Off')\n  plt.show()\n","062bed42":"# input data\n  \nimport tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\nTRAINING_DIR = data_location+\"\/rps\"\ntraining_datagen = ImageDataGenerator(\n      rescale = 1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\nVALIDATION_DIR = data_location+\"\/rps-test-set\"\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = training_datagen.flow_from_directory(\n    TRAINING_DIR,\n    target_size=(150,150),\n    class_mode='categorical'\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    VALIDATION_DIR,\n    target_size=(150,150),\n    class_mode='categorical'\n)","9dad7b7e":"\n# define model\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(3, activation='softmax')\n])\n","236ce708":"# model summary\nmodel.summary()","90c0a300":"\n# compile model\nmodel.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","cc1ceeff":"\n# train model\nhistory = model.fit_generator(train_generator, epochs=5, validation_data = validation_generator, verbose = 1)\n","de56b90b":"# save model\nmodel.save(\"rps.h5\")","d1fb35b4":"\n# resutl summary \nimport matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()\n","936a9678":"# predicting images\nimport numpy as np\npath = data_location+'\/rps-test-set\/paper\/testpaper01-00.png'\nimg = image.load_img(path, target_size=(150, 150))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = model.predict(images, batch_size=10)\nprint(path)\nprint(classes)","eba76702":"img = mpimg.imread(path)\nplt.imshow(img)\nplt.axis('Off')\nplt.show()\n","d51bb085":"#  Class 2  Augmentation: A technique to avoid overfitting","c8469f8b":"#  Class 3  Transfer Learning","5b87e080":"#  Class 4 Multiclass Classifications","d1d4647f":"#  Class 1  Exploring a Larger Dataset","66740c9f":"# Course 2 Convolutional Neural Networks in TensorFlow(Python version)\nClass 1  Exploring a Larger Dataset<br>\nClass 2  Augmentation: A technique to avoid overfitting<br>\nClass 3  Transfer Learning<br>\nClass 4 Multiclass Classifications","21e42da6":"# TensorFlow in Practice Specialization\n\ncoursera: https:\/\/www.coursera.org\/specializations\/tensorflow-in-practice<br>\n\nSpecialization CERTIFICATE:https:\/\/www.coursera.org\/account\/accomplishments\/specialization\/certificate\/7HWVLBEQS62E<br>\n\ncourse CERTIFICATE: https:\/\/www.coursera.org\/account\/accomplishments\/records\/69UE9HYBFQ96<br>\n\nCourse 1 : Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning<br>\ncoursera: https:\/\/www.coursera.org\/learn\/introduction-tensorflow\n\nCourse 2 : Convolutional Neural Networks in TensorFlow<br>\ncoursera: https:\/\/www.coursera.org\/learn\/convolutional-neural-networks-tensorflow\n\nCourse 3 : Natural Language Processing in TensorFlow<br>\ncoursera: https:\/\/www.coursera.org\/learn\/natural-language-processing-tensorflow\n\nCourse 4 : Sequences, Time Series and Prediction<br>\ncoursera: https:\/\/www.coursera.org\/learn\/tensorflow-sequences-time-series-and-prediction"}}