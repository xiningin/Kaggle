{"cell_type":{"c68abac7":"code","8d9a05a3":"code","c78ba8b8":"code","bae83f1d":"code","1b6cffef":"code","70d0a900":"code","b0bca7be":"code","ba5b34f0":"code","6d242cc4":"code","6a66d25c":"code","9a54b8e0":"code","28164d7a":"code","ffd642ae":"code","64e189e0":"code","da6914b7":"code","2f33c8b8":"code","b172d944":"code","d988c590":"code","d2547b2e":"code","f7e2e45a":"code","4fd30faf":"code","887102ac":"code","6bc78f79":"code","77a51429":"code","79cd7886":"code","e2b230e4":"code","1a241ca2":"code","dbc7a586":"code","6dba42f1":"code","cb5367bb":"code","e2a1e16f":"markdown","650bca28":"markdown","c2c9247c":"markdown","ba2da1dc":"markdown"},"source":{"c68abac7":"import os\nimport numpy as np\nfrom nibabel.testing import data_path\nimport nibabel as nib\nfrom pathlib import Path\n\npath = str(Path().resolve())\nprint(path)\npath = path + \"\\\\ADNI_PROCESSED\"\n\n# For kaggle:\npath = \"..\/input\/adni-data\/ADNI_PROCESSED\"\n\ndef apply_mask(img_n_mmni, img_mask):\n    \"\"\"\n        Taking a n_mmni and apply the correspondant mask\n        param:\n            img_n_mmi   : image n_mmi\n            img_mask    : mask\n    \"\"\"\n    mmni_m = img_n_mmni.get_fdata()\n    mask_m = img_mask.get_fdata().astype(bool)\n    mask_bg = np.logical_not(mask_m)\n    mmni_m[mask_bg] = 0\n    return mmni_m\n\ndef process_irm_data():\n    \"\"\"\n        Create a new directory and process all images from tha ADNI1 directory\n    \"\"\"\n    path = str(Path().resolve())\n    path_res = path + \"\\\\ADNI_PROCESSED\"\n    Path(path_res).mkdir(parents=True, exist_ok=True) # Create a directory for data processed\n    path = path + \"\\\\ADNI1\"\n    for filename in os.listdir(path):\n        if filename.startswith(\"n_mmni\"):\n            n_mmni_filename = os.path.join(path, filename)\n            mask_filename = os.path.join(path, \"mask_\" + filename)\n            img_n_mmni = nib.load(n_mmni_filename)\n            img_mask = nib.load(mask_filename)\n            n_mmni_mask = apply_mask(img_n_mmni, img_mask)\n            img = nib.Nifti1Image(n_mmni_mask, np.eye(4))\n            nib.save(img, os.path.join(path_res, filename))","8d9a05a3":"def cut_2D_i(img_n_mmni, axe, idx):\n    \"\"\"\n        Function that returns a 2D cut from the \"img\" in the index \"idx\", along the axe given in parameter\n    \"\"\"\n    axe_dim = {\"x\": img_n_mmni.shape[0], \"y\": img_n_mmni.shape[1], \"z\":img_n_mmni.shape[2]}\n    if axe_dim[axe] <= idx or idx < 0:\n        print(\"Invalid value for index must be between 0 and \" , axe_dim[axe])\n        return\n    if axe == \"x\":\n        cropped_img = img_n_mmni.slicer[idx:idx+1, 90:130, 40:80]\n        img_data = cropped_img.get_fdata()\n        img_data = np.transpose(img_data, (2, 1, 0)) \/ 255.0\n        img_data = np.transpose(img_data, (1, 0, 2))\n    elif axe == \"y\":\n        cropped_img = img_n_mmni.slicer[100:140, idx:idx+1,40:80]\n        img_data = cropped_img.get_fdata()\n        img_data = np.transpose(img_data, (0, 2, 1)) \/ 255.0\n    elif axe == \"z\":\n        cropped_img = img_n_mmni.slicer[100:140, 90:130, idx:idx+1]\n        img_data = cropped_img.get_fdata()\n    else:\n        print(\"Choose a valid value for axe: x, y or z\")\n\n    return img_data\n\ndef custom_patch_3D(img_n_mmni, x_tup, y_tup, z_tup):\n    axe_dim = {\"x\": img_n_mmni.shape[0], \"y\": img_n_mmni.shape[1], \"z\":img_n_mmni.shape[2]}\n    if axe_dim[\"x\"] <= x_tup[1] or x_tup[0] < 0 or axe_dim[\"y\"] <= y_tup[1] or y_tup[0] < 0 or axe_dim[\"z\"] <= z_tup[1] or z_tup[0] < 0 :\n        print(\"Invalid values\")\n        return \n    else:\n        cropped_img = img_n_mmni.slicer[x_tup[0]:x_tup[1], y_tup[0]:y_tup[1], z_tup[0]:z_tup[1]]\n        img_data = cropped_img.get_fdata() \/ 255\n        return img_data","c78ba8b8":"import os\nimport re\nfrom pathlib import Path\nimport pandas as pd\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\ndef load_data(path):\n    data = pd.read_csv(path, names= ['Subject ID', 'Rooster ID', 'Age', 'Sexe', 'Group', 'Conversion', 'MMSE', 'RAVLT', 'FAQ', 'CDR-SB', 'ADAS11'], usecols = ['Subject ID', 'Rooster ID', 'Group'])\n    data.index = data['Subject ID']\n    data = data.drop(['Subject ID'], axis=1)\n    data = data[(data.Group == 'CN') | (data.Group == 'AD')]\n    return data\n\npath = str(Path().resolve())\npath = \"..\/input\/adni-data\/list_standardized_tongtong_2017.csv\"\ny_data = load_data(path)\ny_data.head(7)","bae83f1d":"from tensorflow.keras.utils import to_categorical\n\nusecols = ['Subject ID', 'Rooster ID', 'Group']\n# ['CN', 'AD']\ndef prepare_X_of_Y(Y):\n    X_data = []\n    Y_data = []\n    X_test_index = []\n    X_data_index = []\n    X_hypo = [] # 0 for left, 1 for right\n    Y_test = []\n    path = \"..\/input\/adni-data\/ADNI_PROCESSED\"\n    n_test_AD = 0\n    n_test_CN = 0\n    for index, row in Y.iterrows():\n        file = path + '\/n_mmni_fADNI_' + index + '_1.5T_t1w.nii'\n        if os.path.isfile(file):\n            img_n_mmni = nib.load(file)\n            # Taking 4 images for test purpose\n            if (Y['Group'][index] == 'AD' and n_test_AD < 2) or (Y['Group'][index] == 'CN' and n_test_CN < 2):\n                n_test_AD += 1 if Y['Group'][index] == 'AD' else n_test_AD\n                n_test_CN += 1 if Y['Group'][index] == 'CN' else n_test_CN\n                X_test_index.append(index)\n            else:\n                img_on_three_axes = []\n                \n                img_data = custom_patch_3D(img_n_mmni, x_tup=(59,62), y_tup=(90,130), z_tup=(40,80))\n                img_data = np.transpose(img_data, (1, 2, 0))\n                img_on_three_axes.append(img_data)\n                \n                img_data = custom_patch_3D(img_n_mmni, x_tup=(40,80), y_tup=(109,112), z_tup=(40,80))\n                img_data = np.transpose(img_data, (0, 2, 1))\n                img_on_three_axes.append(img_data)\n                \n                img_data = custom_patch_3D(img_n_mmni, x_tup=(40,80), y_tup=(90,130), z_tup=(59,62))\n                img_on_three_axes.append(img_data)\n                \n                img_on_three_axes = np.array(img_on_three_axes)\n                X_data.append(img_on_three_axes)\n                X_data_index.append(index)\n                X_hypo.append(1)\n                \n                img_on_three_axes = []\n                \n                img_data = custom_patch_3D(img_n_mmni, x_tup=(119,122), y_tup=(90,130), z_tup=(40,80))\n                img_data = img_data[::-1,:,:]\n                img_data = np.transpose(img_data, (1, 2, 0))\n                img_on_three_axes.append(img_data)\n                \n                img_data = custom_patch_3D(img_n_mmni, x_tup=(100,140), y_tup=(109,112), z_tup=(40,80))\n                img_data = np.transpose(img_data, (0, 2, 1))\n                img_data = img_data[::-1,:,:]\n                img_on_three_axes.append(img_data)\n                \n                img_data = custom_patch_3D(img_n_mmni, x_tup=(100,140), y_tup=(90,130), z_tup=(59,62))\n                img_data = img_data[::-1,:,:]\n                img_on_three_axes.append(img_data)\n                \n                img_on_three_axes = np.array(img_on_three_axes)\n                X_data.append(img_on_three_axes)\n                X_data_index.append(index)\n                X_hypo.append(0)\n                \n                if Y['Group'][index] == 'AD':\n                    Y_data.append(1)\n                    Y_data.append(1)\n                elif Y['Group'][index] == 'CN':\n                    Y_data.append(0)\n                    Y_data.append(0)\n        else:\n            Y.drop(index, inplace=True)\n    return np.array(X_data), Y_data, X_test_index, X_data_index, X_hypo\n\n#if os.path.isfile('X_data.npy') and os.path.isfile('Y_data.npy') and os.path.isfile('X_test_index.npy'):\n#    X_data = np.load('X_data.npy')\n#    Y_data = np.load('Y_data.npy')\n#    X_test_index = np.load('X_test_index.npy')\n#else:\nX_data, Y_data_list, X_test_index, X_data_index, X_hypo = prepare_X_of_Y(y_data)\nY_data = to_categorical(Y_data_list, num_classes=2)\n#np.save('X_data', X_data)\n#np.save('Y_data', Y_data)\n#np.save('X_test_index', X_test_index)\n\nprint(len(X_data) == len(Y_data))\nprint(len(X_data))","1b6cffef":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test, X_train_index, X_test_index, X_hypo_train, X_hypo_test = train_test_split(X_data, Y_data, X_data_index, X_hypo, random_state=42, test_size=0.2)\n#X_train, X_val, Y_train, Y_val, X_train_index, X_val_index = train_test_split(X_train, Y_train, X_train_index, random_state=42, test_size=0.2)\n\nprint(\"Data splited\")\nprint(len(X_train))","70d0a900":"map_characters = {0: 'CN', 1: 'AD'}\ndict_characters=map_characters\nimport seaborn as sns\ndf = pd.DataFrame()\ndf[\"labels\"] = Y_train[:,1]\nlab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)","b0bca7be":"def data_augmentation(X_train, Y_train, X_train_index, X_hypo):\n    new_X = []\n    new_Y = []\n    path = \"..\/input\/adni-data\/ADNI_PROCESSED\"\n    for j in range(len(X_train_index)):\n        file = path + '\/n_mmni_fADNI_' + X_train_index[j] + '_1.5T_t1w.nii'\n        new_X.append(X_train[j])\n        new_Y.append(Y_train[j])\n        if os.path.isfile(file):\n            img_n_mmni = nib.load(file)\n            if X_hypo[j]:\n                x = (100,140); x_slice = (119,122)\n            else:\n                x = (40,80); x_slice = (59,62)\n            for i in range(-3, 4):\n                if i != 0:\n                    img_on_three_axes = []\n                    \n                    img_data = custom_patch_3D(img_n_mmni, x_tup=(x_slice[0]+i,x_slice[1]+i), y_tup=(90+i,130+i), z_tup=(40+i,80+i))\n                    img_data = img_data[::-1,:,:]\n                    img_data = np.transpose(img_data, (1, 2, 0))\n                    img_on_three_axes.append(img_data)\n\n                    img_data = custom_patch_3D(img_n_mmni, x_tup=(x[0]+i, x[1]+i), y_tup=(109+i,112+i), z_tup=(40+i,80+i))\n                    img_data = np.transpose(img_data, (0, 2, 1))\n                    img_data = img_data[::-1,:,:]\n                    img_on_three_axes.append(img_data)\n\n                    img_data = custom_patch_3D(img_n_mmni, x_tup=(x[0]+i, x[1]+i), y_tup=(90+i,130+i), z_tup=(59+i,62+i))\n                    img_on_three_axes.append(img_data)\n                    img_data = img_data[::-1,:,:]\n                    img_on_three_axes = np.array(img_on_three_axes)\n                        \n                    new_X.append(img_on_three_axes)\n                    new_Y.append(Y_train[j])\n                        \n    return np.array(new_X), np.array(new_Y)\nX_train, Y_train = data_augmentation(X_train, Y_train, X_train_index, X_hypo_train)","ba5b34f0":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, random_state=42, test_size=0.2)\n\nprint(\"Data splited\")\nprint(len(X_train))","6d242cc4":"map_characters = {0: 'CN', 1: 'AD'}\ndict_characters=map_characters\nimport seaborn as sns\ndf = pd.DataFrame()\ndf[\"labels\"] = Y_test[:,1]\nlab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)","6a66d25c":"from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, UpSampling2D, Cropping2D, Conv3D, MaxPooling3D, UpSampling3D, Cropping3D, Input, Concatenate, Flatten, Dense, Dropout, BatchNormalization, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalAveragePooling3D, add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.regularizers import l2\n\ndef intermediate_network(inputs, i, depth, padding='same'):\n    x = inputs[:,i,:,:]\n    \n    num_filters = 32\n    for i in range(depth):\n        x = SeparableConv2D(filters=num_filters, kernel_size=(3,3), padding=padding)(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        \n        x = SeparableConv2D(filters=num_filters, kernel_size=(3,3), padding=padding)(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        if i != depth - 1:\n            x = MaxPooling2D(pool_size=(2,2), strides=2)(x)\n            num_filters *= 2\n    \n    x = Dropout(0.2)(x)\n    x = Flatten()(x)\n    return x\n\ndef create_model_2D_epsilon(input_size, padding='same', nb_class=2):\n    inputs = Input(shape=input_size)\n    nb_slices = inputs.shape[1]\n    out_list = []\n    for i in range(nb_slices):\n        out_list.append(intermediate_network(inputs=inputs, i=i, depth=4, padding='same'))\n\n    x = Concatenate(name = \"Concat1\")(out_list)\n    x = Flatten(name = \"Flatten1\")(x)\n    \n    x = Dense(512, activation='relu', name = \"Dense1\")(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.7)(x)\n    \n    \n    x = Dense(128, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(64, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    \n    outputs = Dense(nb_class, activation='softmax')(x)\n    \n    return Model(inputs, outputs)","9a54b8e0":"from tensorflow.keras.optimizers import Adam\n\nmodel_2 = create_model_2D_epsilon(X_train[0].shape)\nmodel_2.summary()\nmodel_2.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])","28164d7a":"history = model_2.fit(X_train, Y_train, epochs=80, validation_data=(X_val, Y_val))","ffd642ae":"import matplotlib.pyplot as plt\n\n# Plot the validation and training data separately\ndef plot_loss_curves(history):\n      \"\"\"\n      Returns separate loss curves for training and validation metrics.\n      \"\"\" \n      loss = history.history['loss']\n      val_loss = history.history['val_loss']\n\n      accuracy = history.history['accuracy']\n      val_accuracy = history.history['val_accuracy']\n\n      epochs = range(len(history.history['loss']))\n\n      # Plot loss\n      plt.plot(epochs, loss, label='training_loss')\n      plt.plot(epochs, val_loss, label='val_loss')\n      plt.title('Loss')\n      plt.xlabel('Epochs')\n      plt.legend()\n\n      # Plot accuracy\n      plt.figure()\n      plt.plot(epochs, accuracy, label='training_accuracy')\n      plt.plot(epochs, val_accuracy, label='val_accuracy')\n      plt.title('Accuracy')\n      plt.xlabel('Epochs')\n      plt.legend()\n      plt.savefig('accuracy.png')","64e189e0":"#Evaluating the model on testing data\n\ntest_scores = model_2.evaluate(X_test, Y_test)\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","da6914b7":"plot_loss_curves(history)","2f33c8b8":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nprediction_unet = model_2.predict(X_test)\nprediction_unet = np.argmax(prediction_unet, axis=-1)\nY_labels = np.argmax(Y_test, axis=-1)\nprint(Y_labels)\ncm = confusion_matrix(Y_labels, prediction_unet)\nprint(cm)\nsns.heatmap(cm, annot=True)","b172d944":"from tensorflow.keras.utils import to_categorical\n\ndef prepare_data_viz():\n    path = \"..\/input\/adni-data\/list_standardized_tongtong_2017.csv\"\n    data = pd.read_csv(path, names= ['Subject ID', 'Rooster ID', 'Age', 'Sexe', 'Group', 'Conversion', 'MMSE', 'RAVLT', 'FAQ', 'CDR-SB', 'ADAS11'], usecols = ['Subject ID', 'Rooster ID', 'Group', 'Conversion'])\n    data.index = data['Subject ID']\n    Y = data.drop(['Subject ID'], axis=1)\n    X_data = []\n    Y_data = []\n    path_img = \"..\/input\/adni-data\/ADNI_PROCESSED\"\n    for index, row in Y.iterrows():\n        file = path_img + '\/n_mmni_fADNI_' + index + '_1.5T_t1w.nii'\n        if os.path.isfile(file):\n            img_n_mmni = nib.load(file)\n            img_on_three_axes = []\n\n            img_data = custom_patch_3D(img_n_mmni, x_tup=(59,62), y_tup=(90,130), z_tup=(40,80))\n            img_data = np.transpose(img_data, (1, 2, 0))\n            img_on_three_axes.append(img_data)\n\n            img_data = custom_patch_3D(img_n_mmni, x_tup=(40,80), y_tup=(109,112), z_tup=(40,80))\n            img_data = np.transpose(img_data, (0, 2, 1))\n            img_on_three_axes.append(img_data)\n\n            img_data = custom_patch_3D(img_n_mmni, x_tup=(40,80), y_tup=(90,130), z_tup=(59,62))\n            img_on_three_axes.append(img_data)\n\n            img_on_three_axes = np.array(img_on_three_axes)\n            X_data.append(img_on_three_axes)\n\n            if Y['Group'][index] == \"AD\":\n                Y_data.append(3)\n            elif Y['Group'][index] == \"CN\":\n                Y_data.append(0)\n            elif Y['Group'][index] == \"MCI\":\n                if Y['Conversion'][index] == 4:\n                    Y_data.append(1)\n                else:\n                    Y_data.append(2)\n    return np.array(X_data), Y_data\n\nX_viz, Y_viz = prepare_data_viz()","d988c590":"features_flatten = Model(\n    inputs=model_2.inputs,\n    outputs=model_2.get_layer(name=\"Dense1\").output,\n)\n\nX_layer_pred = features_flatten.predict(X_viz)\nprint(X_layer_pred.shape)","d2547b2e":"from sklearn import decomposition\npca = decomposition.PCA()\npca.n_components = 2\npca_data = pca.fit_transform(X_layer_pred)\nprint(\"shape of pca_reduced.shape\", pca_data.shape)","f7e2e45a":"import seaborn as sn\npca_data = np.vstack((pca_data.T, Y_viz)).T\npca_df = pd.DataFrame(data=pca_data, columns=(\"pca-one\", \"pca-two\", \"Group\"))\npca_df_AD_CN = pca_df[(pca_df.Group == 0) | (pca_df.Group == 3)]","4fd30faf":"sn.FacetGrid(pca_df_AD_CN, hue=\"Group\", size=6, palette=[\"blue\", \"yellow\"]).map(plt.scatter, \"pca-one\", \"pca-two\").add_legend()\nplt.show","887102ac":"colors = [\"blue\", \"purple\", \"orange\", \"yellow\"]\nsn.FacetGrid(pca_df, hue=\"Group\", size=6, palette=colors).map(plt.scatter, \"pca-one\", \"pca-two\").add_legend()\nplt.show","6bc78f79":"from sklearn.decomposition import PCA\nimport plotly.express as px\n\npca = PCA(n_components=2)\npca.fit(X_layer_pred)\npca_data = pca.transform(X_layer_pred)\n\npca_data = np.vstack((pca_data.T, Y_viz)).T\npca_df = pd.DataFrame(data=pca_data, columns=(\"pca-one\", \"pca-two\", \"Group\"))\npca_df_AD_CN = pca_df[(pca_df.Group == 0) | (pca_df.Group == 3)]","77a51429":"fig = px.scatter_matrix(\n    pd.DataFrame(data=pca_df_AD_CN, columns=(\"pca-one\", \"pca-two\")).to_numpy(),\n    dimensions=range(2),\n    color=pca_df_AD_CN[\"Group\"].to_numpy(),\n)\nfig.update_traces(diagonal_visible=False)\nfig.show()","79cd7886":"fig = px.scatter_matrix(\n    pd.DataFrame(data=pca_df, columns=(\"pca-one\", \"pca-two\")).to_numpy(),\n    dimensions=range(2),\n    color=pca_df[\"Group\"].to_numpy(),\n)\nfig.update_traces(diagonal_visible=False)\nfig.show()","e2b230e4":"from sklearn.manifold import TSNE\nimport plotly.express as px\n\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=800)\ntsne_results = tsne.fit_transform(X_layer_pred)\ntsne_data = np.vstack((tsne_results.T, Y_viz)).T\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"tsne-2d-one\", \"tsne-2d-two\", \"Group\"))\ntsne_df_AD_CN = tsne_df[(tsne_df.Group == 0) | (tsne_df.Group == 3)]","1a241ca2":"plt.figure(figsize=(16,10))\n\nsn.FacetGrid(tsne_df_AD_CN, hue=\"Group\", size=6, palette=[\"blue\", \"yellow\"]).map(plt.scatter, \"tsne-2d-one\", \"tsne-2d-two\").add_legend()","dbc7a586":"plt.figure(figsize=(16,10))\n\nsn.FacetGrid(tsne_df, hue=\"Group\", size=6, palette=colors).map(plt.scatter, \"tsne-2d-one\", \"tsne-2d-two\").add_legend()","6dba42f1":"fig = px.scatter_matrix(\n    pd.DataFrame(data=tsne_df_AD_CN, columns=(\"tsne-2d-one\", \"tsne-2d-two\")).to_numpy(),\n    dimensions=range(2),\n    color=tsne_df_AD_CN[\"Group\"].to_numpy()\n)\nfig.update_traces(diagonal_visible=False)\nfig.show()","cb5367bb":"fig = px.scatter_matrix(\n    pd.DataFrame(data=tsne_df, columns=(\"tsne-2d-one\", \"tsne-2d-two\")).to_numpy(),\n    dimensions=range(2),\n    color=tsne_df[\"Group\"].to_numpy()\n)\nfig.update_traces(diagonal_visible=False)\nfig.show()","e2a1e16f":"## Loss visualization function\nThis function is used to visualize the variations of loss, val_loss, accuracy and val_accuracy over epochs. It is used for 3D and 2D models. ","650bca28":"# PCA","c2c9247c":"# Prediction and vizualisation on MCI","ba2da1dc":"# TSNE"}}