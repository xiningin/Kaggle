{"cell_type":{"999e6eb8":"code","a48cf1b9":"code","9de27d08":"code","42162e7a":"code","ec4a4a19":"code","ea992a2d":"code","c1f3b893":"code","2cc52c9a":"code","f0261602":"code","0b015607":"markdown","7f1f0b05":"markdown","3d5bf6a9":"markdown"},"source":{"999e6eb8":"import pandas as pd\nimport numpy as np\nimport os\nimport re","a48cf1b9":"df_train_x = pd.read_csv(\"\/kaggle\/input\/ccf2019news-so\/Train_DataSet.csv\")\ndf_train_y = pd.read_csv(\"\/kaggle\/input\/ccf2019news-so\/Train_DataSet_Label.csv\")\ndf_test_x = pd.read_csv(\"\/kaggle\/input\/ccf2019news-so\/Test_DataSet.csv\")\n# train_x: id, title, content\n# train_y: id, label\nprint(df_train_x.isnull().sum())\ndf_train_x.dropna(axis = 0, subset=['title'], inplace=True)\ndf_train_x.fillna(method='ffill', axis=1, inplace=True)\ndf_test_x.fillna(method='ffill', axis=1, inplace=True)\n\n# dataframe: id, title, content, label, documnet\ndf_train = pd.merge(df_train_x, df_train_y, on = 'id')\ndf_train['document'] = df_train['title'] + df_train['content']\ndf_test_x['document'] = df_test_x['title'] + df_test_x['content']\nprint('train shape:', df_train.shape)\nprint('test shape:', df_test_x.shape)","9de27d08":"# \u7a7a\u683c\nre1 = re.compile(r'\\s')\n# \u4ee3\u7801\nre2 = re.compile(r'[a-zA-Z0-9\\'=\\\\\/:\\\/?;()<>\"\\._-]{5,}')\n# \u6570\u5b57\u5927\u4e8e4\u4e2a\nre3 = re.compile(r'[\\b]{5,}')\n# \u805a\u5408\u6807\u70b9\nre4 = re.compile(r'[\\'=\\\\\/:\\\/?;()<>\"\\._-]{2,}')\n\ndef re_process(text):\n    res1 = re1.sub('', text)\n    res2 = re2.sub('', res1)\n    res3 = re3.sub('', res2)\n    res4 = re4.sub('', res3)\n    return res4\n    \n# \u6b63\u5219\u8868\u8fbe\u5f0f \u6e05\u6d17\ndf_train['document'] = df_train['document'].apply(re_process)\ndf_test_x['document'] = df_test_x['document'].apply(re_process)\n\nfrom keras.utils import to_categorical\ndf_train['label'] = df_train['label'].apply(lambda x:to_categorical(x, 3))\nprint(df_train.loc[0]['label'])","42162e7a":"\n#! -*- coding:utf-8 -*-\nimport re, os, json, codecs, gc\nimport numpy as np\nimport pandas as pd\nfrom random import choice\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\n! pip install keras-bert\nfrom keras_bert import load_trained_model_from_checkpoint, Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras.models import Model\nimport keras.backend as K\nfrom keras.optimizers import Adam","ec4a4a19":"maxlen = 256\nconfig_path = '\/kaggle\/input\/bertch-l12-h768-a12\/chinese_L-12_H-768_A-12\/bert_config.json'\ncheckpoint_path = '\/kaggle\/input\/bertch-l12-h768-a12\/chinese_L-12_H-768_A-12\/bert_model.ckpt'\ndict_path = '\/kaggle\/input\/bertch-l12-h768-a12\/chinese_L-12_H-768_A-12\/vocab.txt'\n\ntoken_dict = {}\nwith codecs.open(dict_path, 'r', 'utf8') as reader:\n    for line in reader:\n        token = line.strip()\n        token_dict[token] = len(token_dict)\n\ntokenizer = Tokenizer(token_dict)\n\nfrom keras.metrics import top_k_categorical_accuracy\ndef acc_top2(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n                    \ndef build_bert(nclass):\n    bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)\n\n    for l in bert_model.layers:\n        l.trainable = True\n\n    x1_in = Input(shape=(None,))\n    x2_in = Input(shape=(None,))\n\n    x = bert_model([x1_in, x2_in])\n    x = Lambda(lambda x: x[:, 0])(x)\n    p = Dense(nclass, activation='softmax')(x)\n\n    model = Model([x1_in, x2_in], p)\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=Adam(1e-5),\n                  metrics=['accuracy', acc_top2])\n    return model","ea992a2d":"#%%\n# data generator\nmax_length = 256\nencode = lambda x: tokenizer.encode(x)[0]\ndf_train[['title','content','document']] = df_train[['title','content','document']].applymap(encode)\ndf_test_x[['title','content','document']] = df_test_x[['title','content','document']].applymap(encode)\n\ndef padding(df, max_length, sl=0):\n    \n    def padding_0(row):\n        x = row.document\n        if len(x)<max_length:\n            x = x+[0]*(max_length-len(x))\n            row.document = x\n        return row\n        \n    def padding_repeat_itself(row):\n        x = row.document\n        if len(x)<max_length:\n            sub_length = max_length - len(x)\n            fold = sub_length \/\/ len(x) \n            x += x*fold\n            x += x[:max_length-len(x)]\n            row.document = x\n        return row\n        \n    def padding_repeat_title(row):\n        x = row.document\n        if len(x)<max_length:\n            sub_length = max_length - len(x)\n            fold = sub_length \/\/ len(x) \n            x += row.title * fold\n            x += row.title[:max_length-len(x)]\n            row.document = x\n            return row\n        \n        \n    df['document'] = df['document'].apply(lambda x: x[:max_length])\n    if sl == 0:\n        df.apply(padding_0, axis=1)\n        #map(padding_0, df)\n    if sl == 1:\n        df.apply(padding_repeat_itself, axis=1)\n    if sl == 2:\n        df.apply(padding_repeat_title, axis=1)\n    return df\n        \ndf_train = padding(df_train,max_length, sl=0)\ndf_test_x = padding(df_test_x,max_length, sl=0)","c1f3b893":"! mkdir bert_dump\ndef run_cv(nfold, data, data_test):\n    kf = KFold(n_splits=nfold, shuffle=True, random_state=520).split(data)\n    train_model_pred = np.zeros((len(data), 3))\n    test_model_pred = np.zeros((len(data_test), 3))\n    data['set'] = np.ones(len(data))\n    X_test = data_test\n    X_test['set'] = np.ones(len(data_test))\n    X_test.loc[:]['set'] = np.zeros([len(X_test), max_length])\n    test_x = [np.array(X_test['document'].tolist()), np.array(X_test['set'].tolist())]\n    \n    for i, (train_fold, test_fold) in enumerate(kf):\n        X_train, X_valid = data.iloc[train_fold], data.iloc[test_fold]\n    \n        model = build_bert(3)\n        if i==0:\n            print(model.summary())\n        early_stopping = EarlyStopping(monitor='val_acc', patience=3)\n        plateau = ReduceLROnPlateau(monitor=\"val_acc\", verbose=1, mode='max', factor=0.5, patience=2)\n        checkpoint = ModelCheckpoint('bert_dump\/' + str(i) + '.hdf5', monitor='val_acc', \n                                         verbose=2, save_best_only=True, mode='max',save_weights_only=True)\n        \"\"\"\n        train_D = data_generator(X_train, shuffle=True)\n        valid_D = data_generator(X_valid, shuffle=True)\n        test_D = data_generator(data_test, shuffle=False)\n        model.fit_generator(\n            train_D.__iter__(),\n            steps_per_epoch=len(train_D),\n            epochs=5,\n            validation_data=valid_D.__iter__(),\n            validation_steps=len(valid_D),\n            callbacks=[early_stopping, plateau, checkpoint])\n        # return model\n        train_model_pred[test_fold, :] =  model.predict_generator(valid_D.__iter__(), steps=len(valid_D),verbose=1)\n        test_model_pred += model.predict_generator(test_D.__iter__(), steps=len(test_D),verbose=1)\n        \"\"\"\n        X_train.iloc[:]['set'] = np.zeros([len(X_train), max_length])\n        X_valid.iloc[:]['set'] = np.zeros([len(X_valid), max_length])\n        \n        train_y = np.array(X_train['label'].tolist())\n        train_x = [np.array(X_train['document'].tolist()), np.array(X_train['set'].tolist())]\n        valid_y = np.array(X_valid['label'].tolist())\n        valid_x = [np.array(X_valid['document'].tolist()), np.array(X_valid['set'].tolist())]\n        model.fit(train_x, train_y, validation_data=(valid_x, valid_y), epochs=5, batch_size=8, callbacks=[early_stopping, plateau, checkpoint],verbose=2)\n        \n        test_model_pred += model.predict(test_x)\n        del model; gc.collect()\n        K.clear_session()\n    return test_model_pred","2cc52c9a":"Y_pre = run_cv(10, df_train, df_test_x)","f0261602":"test_pred = [np.argmax(x) for x in Y_pre]\ndf_test_x['label'] = test_pred\ndf_test_x[['id', 'label']].to_csv('baseline.csv', index=None)","0b015607":"## \u586b\u5145","7f1f0b05":"## BERT","3d5bf6a9":"## \u6570\u636e\u6e05\u6d17"}}