{"cell_type":{"7c74f298":"code","42ff9ce0":"code","d6517488":"code","8457045b":"code","467c7b4b":"code","90a971cc":"code","27ec9807":"code","235ee659":"code","a2e95b97":"code","e793821e":"code","874d4944":"code","f095c653":"code","db956301":"code","8247bc73":"markdown","d9e952e0":"markdown","a4d5e446":"markdown","37c58dfa":"markdown"},"source":{"7c74f298":"import warnings\nwarnings.filterwarnings('ignore')","42ff9ce0":"import os\nimport json\nimport numpy as np\nfrom pathlib import Path\nimport random\nfrom collections import Counter\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\ndata_path = Path('..\/input\/abstraction-and-reasoning-challenge')\ntrain_path = data_path \/ 'training'\nvalid_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'\n\ndef set_seeds(seed):\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    torch.cuda.manual_seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED']=str(seed)\n    \nset_seeds(0)\n\npaths = {'train': train_path, 'eval': valid_path, 'test': test_path}\n\ndef get_tasks(dataset='train'):\n    path = paths[dataset]\n    fns = sorted(os.listdir(path))\n    tasks = {}\n    for idx, fn in enumerate(fns):\n        fp = path \/ fn\n        with open(fp, 'r') as f:\n            task = json.load(f)\n            tasks[fn.split('.')[0]] = task\n    return tasks\n\n\ntest_tasks = get_tasks('test')\ntrain_tasks = get_tasks('train')\nvalid_tasks = get_tasks('eval')","d6517488":"from tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom matplotlib import animation, rc\nfrom IPython.display import HTML\n\ncmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n    \ndef plot_pictures(pictures, labels):\n    fig, axs = plt.subplots(1, len(pictures), figsize=(2*len(pictures),32))\n    for i, (pict, label) in enumerate(zip(pictures, labels)):\n        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n        axs[i].set_title(label)\n    plt.show()\n    \ndef plot_sample(sample, predict=None):\n    if predict is None:\n        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n    else:\n        plot_pictures([sample['input'], sample['output'], predict], ['Input', 'Output', 'Predict'])\n\nnorm = colors.Normalize(vmin=0, vmax=9)\n# 0:black, 1:blue, 2:red, 3:greed, 4:yellow,\n# 5:gray, 6:magenta, 7:orange, 8:sky, 9:brown\nplt.figure(figsize=(3, 1), dpi=200)\nplt.imshow([list(range(10))], cmap=cmap, norm=norm)\nplt.xticks(list(range(10)))\nplt.yticks([])\nplt.show()\n\ntask = train_tasks[\"db3e9e38\"]\nfor sample in task['train']:\n    plot_sample(sample)","8457045b":"from skimage.transform import hough_line\n\ndef is_rotation(img):\n    tested_angles = np.array([0, np.pi \/ 2])\n    image = np.array(img)\n    h, theta, d = hough_line(image, theta=tested_angles)\n    \n    rot = h[:,0].max() > h[:,1].max()\n    return rot\n\n    \ndef get_color_counter(a, binary=False):\n    if binary:\n        unique, counts = np.unique( (a>0).astype(int), return_counts=True)\n    else:\n        unique, counts = np.unique( a, return_counts=True)\n    return dict(zip(unique, counts))\n\ndef similarity(da, db):\n    total = 0\n    for k, v in da.items():\n        if k in db:\n            total += min(v, db.get(k))\n    return total\n    \ndef is_parts_aligned(da1, da2, db1, db2):    \n    def get_most_color(dab):\n        c = 0\n        max_c = 0\n        for k, v in dab.items():\n            if k > 0:\n                if max_c < v:\n                    max_c = v\n                    c = k\n        return c\n    \n    if True:\n        c1 = get_most_color(da1)\n        if (da1.get(c1, 0) >= da2.get(c1, 0)) and (db1.get(c1, 0) < db2.get(c1, 0)):\n            return False\n        if (da1.get(c1, 0) <= da2.get(c1, 0)) and (db1.get(c1, 0) > db2.get(c1, 0)):\n            return False\n    return True\n\n    \ndef is_2images_aligned_updown(img0, img1):\n    a = np.array(img0)\n    a1 = a[0:a.shape[0]\/\/2, :]\n    a2 = a[a.shape[0]\/\/2:, :]\n    \n    b = np.array(img1)\n    b1 = b[0:b.shape[0]\/\/2, :]\n    b2 = b[b.shape[0]\/\/2:, :]\n    \n    da1 = get_color_counter(a1)\n    da2 = get_color_counter(a2)\n    db1 = get_color_counter(b1)\n    db2 = get_color_counter(b2)\n    \n    return is_parts_aligned(da1, da2, db1, db2)\n\ndef is_2images_aligned_leftright(img0, img1):\n    a = np.array(img0)\n    a1 = a[:, 0:a.shape[1]\/\/2] # a[0:a.shape[0]\/\/2, :]\n    a2 = a[:, a.shape[1]\/\/2:]\n    \n    b = np.array(img1)\n    b1 = b[:, 0:b.shape[1]\/\/2] # b[0:b.shape[0]\/\/2, :]\n    b2 = b[:, b.shape[1]\/\/2:]\n    \n    da1 = get_color_counter(a1)\n    da2 = get_color_counter(a2)\n    db1 = get_color_counter(b1)\n    db2 = get_color_counter(b2)\n    \n    return is_parts_aligned(da1, da2, db1, db2)\n    ","467c7b4b":"def align_task(task):\n    task_aligned = task.copy()\n    \n    sample_trains = task['train']\n    sample_tests = task['test']\n    \n    # Train\n    sample_trains_aligned = []\n    for sample in sample_trains:\n        img_input = sample['input']\n        img_ouput = sample['output']\n        \n        sample_aligned = sample.copy()\n        if is_rotation(img_input):\n            sample_aligned['input'] = np.rot90(np.array(img_input), k=1).tolist()\n            sample_aligned['output'] = np.rot90(np.array(img_ouput), k=1).tolist()\n            \n        sample_trains_aligned.append(sample_aligned)\n        \n    sample_trains_aligned_2 = sample_trains_aligned[:1] # first element\n    img0_aligned = sample_trains_aligned_2[0]['input']\n    \n    for sample in sample_trains_aligned[1:]:\n        sample_aligned = sample.copy()\n        \n        if not is_2images_aligned_updown(img0_aligned, sample_aligned['input']):\n            sample_aligned['input'] = np.flipud(np.array(sample_aligned['input'])).tolist()\n            sample_aligned['output'] = np.flipud(np.array(sample_aligned['output'])).tolist()\n            \n        if not is_2images_aligned_leftright(img0_aligned, sample_aligned['input']):\n            sample_aligned['input'] = np.fliplr(np.array(sample_aligned['input'])).tolist()\n            sample_aligned['output'] = np.fliplr(np.array(sample_aligned['output'])).tolist()\n            \n        sample_trains_aligned_2.append(sample_aligned)\n        \n    task_aligned['train'] = sample_trains_aligned_2\n    \n    # Test\n    sample_test_aligned = []\n    \n    for sample in sample_tests:\n        img_input = sample['input']\n        is_output_available = 'output' in sample\n        \n        sample_aligned = sample.copy()\n        sample_aligned['rot90'] = False\n        if is_rotation(img_input):\n            sample_aligned['input'] = np.rot90(np.array(img_input), k=1).tolist()\n            if is_output_available:\n                sample_aligned['output'] = np.rot90(np.array(sample_aligned['output']), k=1).tolist()\n            sample_aligned['rot90'] = True\n            \n        sample_test_aligned.append(sample_aligned)\n        \n    sample_test_aligned_v2 = []\n    for sample in sample_test_aligned:\n        \n        sample_aligned = sample.copy()\n        \n        sample_aligned['flipud'] = False\n        if not is_2images_aligned_updown(img0_aligned, sample_aligned['input']):\n            sample_aligned['input'] = np.flipud(np.array(sample_aligned['input'])).tolist()\n            if is_output_available:\n                sample_aligned['output'] = np.flipud(np.array(sample_aligned['output'])).tolist()\n            sample_aligned['flipud'] = True\n            \n        sample_aligned['fliplr'] = False\n        if not is_2images_aligned_leftright(img0_aligned, sample_aligned['input']):\n            sample_aligned['input'] = np.fliplr(np.array(sample_aligned['input'])).tolist()\n            if is_output_available:\n                sample_aligned['output'] = np.fliplr(np.array(sample_aligned['output'])).tolist()\n            sample_aligned['fliplr'] = True\n            \n        sample_test_aligned_v2.append(sample_aligned)\n        \n    task_aligned['test'] = sample_test_aligned_v2\n        \n    return task_aligned\n        \nsingle_task = train_tasks[\"db3e9e38\"] \nsingle_task = valid_tasks[\"103eff5b\"] \n# single_task = valid_tasks[\"05a7bcf2\"]\ntask_aligned = align_task(single_task)\nfor sample in task_aligned['train']:\n#     print(sample['flipud'], sample['rot90'])\n    plot_sample(sample)\nfor sample in task_aligned['test']:\n    print(sample['fliplr'], sample['flipud'], sample['rot90'])\n    plot_sample(sample)","90a971cc":"!mkdir -p test_aligned\n\ntest_aligned_path = Path(\"test_aligned\")\ntest_tasks = get_tasks('test')\n\nfor task_id, task in tqdm(test_tasks.items()):\n    task_aligned = align_task(task)\n    task_filename = '{}.json'.format(task_id)\n    \n    with open(test_aligned_path \/ task_filename, 'w') as outfile:\n        json.dump(task_aligned, outfile)","27ec9807":"paths['test_aligned'] = test_aligned_path\ntest_aligned_tasks = get_tasks(\"test_aligned\")\nprint(len(test_aligned_tasks))","235ee659":"\"\"\" This file was auto_generated by kernel_generator.py \"\"\"\n\nfrom typing import Set\nfrom deap.tools import selNSGA2\nfrom lightgbm import LGBMClassifier\nfrom joblib import delayed\nfrom scipy.ndimage import binary_erosion\nfrom enum import auto\nfrom collections import defaultdict\nfrom scipy.ndimage import maximum_filter\nfrom itertools import groupby\nfrom skimage.measure import label\nfrom sklearn.neural_network import MLPClassifier\nfrom scipy.ndimage import binary_fill_holes\nimport json\nimport shutil\nfrom typing import List\nfrom enum import IntEnum\nfrom pandas import DataFrame\nfrom enum import unique\nimport cv2\nimport pandas as pd\nfrom copy import deepcopy\nfrom typing import Tuple\nfrom itertools import product\nfrom skimage.filters import try_all_threshold\nfrom pathlib import Path\nfrom heapq import heapify\nfrom scipy.ndimage import generate_binary_structure\nfrom sklearn.linear_model import LogisticRegression\nfrom functools import partial\nimport copy\nfrom typing import Any\nfrom typing import Optional\nfrom heapq import heappush\nfrom category_encoders import OrdinalEncoder\nimport numpy as np\nfrom typing import Dict\nfrom tqdm import tqdm\nfrom matplotlib import colors\nimport time\nimport random\nfrom heapq import heappushpop\nfrom typing import Iterable\nfrom enum import Enum\nimport pickle\nfrom matplotlib import pyplot as plt\nfrom joblib import Parallel\nfrom heapq import heappop\nfrom itertools import chain\nfrom dataclasses import asdict\nfrom skimage.filters import threshold_minimum\nfrom sklearn.linear_model import RidgeClassifier\nfrom scipy.ndimage import binary_dilation\nimport optuna\nfrom dataclasses import dataclass\nfrom typing import Union\nfrom typing import TypeVar\nfrom optuna import Trial\nimport category_encoders\nfrom sklearn.model_selection import KFold\nfrom operator import itemgetter\n# from ruamel import yaml\nfrom collections import Counter\n\n\n@dataclass\nclass OperationInconsistencyException(Exception):\n    message: str = ''\n\n\nclass Timer:\n    def __init__(self):\n        pass\n\n    def __enter__(self):\n        self.start_sec = time.perf_counter()\n        return self\n\n    def second(self):\n        return time.perf_counter() - self.start_sec\n\n    def __exit__(self, *exc):\n        return\n\n\nclass StrNameEnum(Enum):\n    def __str__(self):\n        return self.name\n\n    def __repr__(self):\n        return str(f'{self.__class__.__name__}.{self.name}')\n\n\nclass StrNameIntEnum(IntEnum):\n    def __str__(self):\n        return self.name\n\n    def __repr__(self):\n        return str(f'{self.__class__.__name__}.{self.name}')\n\n\n@unique\nclass RunMode(Enum):\n    LOCAL_RUN_ALL = auto()\n    LOCAL_RUN = auto()\n    TREE_BASE_SEARCH_OPTIMIZATION = auto()\n    NODE_BASE_SEARCH_OPTIMIZATION = auto()\n    LOCAL_DATA_GENERATION = auto()\n    LOCAL_ML_TRAIN = auto()\n    TRAIN_OPERATION_ELEMENT_INCLUSION_PREDICTION = auto()\n    KERNEL = auto()\n    KERNEL_EMULATION = auto()\n\n\n@unique\nclass TaskRange(Enum):\n    ALL = auto()\n    CAN_ANSWER_ONLY = auto()\n    EXCLUDE_GIVE_UPS = auto()\n\n\n@unique\nclass FlipMode(StrNameEnum):\n    UD = auto()\n    LR = auto()\n    UL_DR = auto()\n    UR_DL = auto()\n\n\n@unique\nclass EngineSchedulePattern(Enum):\n    DRY_RUN = auto()\n    HAND_MADE = auto()\n    ML = auto()\n\n\n@unique\nclass EngineType(Enum):\n    NODE_BASED_SEARCH_ENGINE = auto()\n    TREE_BASED_SEARCH_ENGINE = auto()\n\n\nclass RunConfig:\n    RUN_MODE = RunMode.KERNEL  # Usually, use \"LOCAL_RUN\" or \"KERNEL\"\n    TASK_RANGE = TaskRange.ALL  # Limit the range to save time.\n    ENGINE_TYPE = EngineType.NODE_BASED_SEARCH_ENGINE\n    ENGINE_SCHEDULE_PATTERN = EngineSchedulePattern.HAND_MADE\n    USE_ML_GUIDE = False  # DeepCoder-like strategy. Calculate the probability of inclusion of each DSL elements.\n    RUN_ONLY_PRIVATE_LB = False  # Skip public kernel run to save time.\n\n    _KERNEL_N_JOB = 4\n    _LOCAL_N_JOB = 5\n    N_JOB = _KERNEL_N_JOB if RUN_MODE == RunMode.KERNEL else _LOCAL_N_JOB\n\n\n@unique\nclass DepthSearchPattern(Enum):\n    BREADTH_FIRST = auto()\n    NORMAL = auto()\n    DEPTH_FIRST = auto()\n\n\n@unique\nclass TrueOrFalse(StrNameEnum):\n    TRUE = auto()\n    FALSE = auto()\n\n\n@unique\nclass Color(StrNameIntEnum):\n    BLACK = 0\n    BLUE = 1\n    RED = 2\n    GREEN = 3\n    YELLOW = 4\n    GRAY = 5\n    MAGENTA = 6\n    ORANGE = 7\n    SKY = 8\n    BROWN = 9\n    MASK_TAG = 10  # very special color. TODO unused?\n\n    @classmethod\n    def prepare(cls):\n        cls.mapping = {c.value: c for c in Color}\n\n    @classmethod\n    def of(cls, value: int) -> 'Color':\n        try:\n            return cls.mapping[value]\n        except AttributeError:\n            cls.mapping = {c.value: c for c in Color}\n            return cls.mapping[value]\n\n\n@unique\nclass Direction(StrNameEnum):\n    TOP = auto()\n    BOTTOM = auto()\n    RIGHT = auto()\n    LEFT = auto()\n\n\n@unique\nclass PaddingMode(StrNameEnum):\n    REPEAT = auto()\n    MIRROR_1 = auto()  # line-symmetric at the edge\n    MIRROR_2 = auto()  # line-symmetric at the edge-pixel-line\n    EDGE = auto()\n\n\n@unique\nclass Axis(StrNameEnum):\n    VERTICAL = auto()\n    HORIZONTAL = auto()\n    BOTH = auto()\n\n\n@unique\nclass MultiColorSelectionMode(StrNameEnum):\n    # ANY_WITHOUT_FIXED_COLOR = auto()  # TODO should define?\n    ANY_WITHOUT_MOST_COMMON = auto()  # TODO ANY_WITHOUT_TOP2_MOST_COMMON\n    ANY_WITHOUT_LEAST_COMMON = auto()\n\n\n@unique\nclass MaxOrMin(StrNameEnum):\n    MAX = max\n    MIN = min\n\n    @property\n    def func(self):\n        return self.value\n\n\n@unique\nclass FillType(StrNameEnum):\n    NotOverride = auto()\n    Override = auto()\n\n\n@unique\nclass LineEdgeType(StrNameEnum):\n    EdgeExclude = auto()\n    EdgeInclude = auto()\n\n\n@unique\nclass ImageEdgeType(StrNameEnum):\n    EDGE_EXCLUDE = auto()\n    EDGE_INCLUDE = auto()\n\n\n@unique\nclass ObjectFeature(StrNameEnum):\n    AREA = auto()\n    # PERIMETER_LEN = auto() # TODO difficult to implement?\n    HORIZONTAL_LEN = auto()\n    VERTICAL_LEN = auto()\n\n\n@unique\nclass PixelConnectivity(StrNameEnum):\n    FOUR_DIRECTION = 1\n    EIGHT_DIRECTION = 2\n\n    @property\n    def value_for_skimage(self) -> int:\n        return self.value\n\n    @property\n    def structure_for_skimage(self) -> np.ndarray:\n        if self == PixelConnectivity.EIGHT_DIRECTION:\n            return generate_binary_structure(2, 2)\n        if self == PixelConnectivity.FOUR_DIRECTION:\n            return generate_binary_structure(2, 1)\n\n        raise NotImplementedError()\n\n\n@unique\nclass HoleInclude(StrNameEnum):\n    INCLUDE = auto()\n    EXCLUDE = auto()\n\n\n@unique\nclass SingleColorSelectionMode(StrNameEnum):\n    MOST_COMMON = auto()\n    SECOND_MOST_COMMON = auto()\n    LEAST_COMMON = auto()\n\n\n@dataclass(frozen=True)\nclass ColorSelection:\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass MaskConversion:\n    def __call__(self, mask: np.ndarray) -> np.ndarray:\n        raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass NoMaskConversion(MaskConversion):\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        return color_mask\n\n\n@dataclass(frozen=True)\nclass MaskOperation:\n    def __call__(self, arr: np.ndarray, mask: np.ndarray) -> np.ndarray:\n        raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass ColorChannelSelection:\n    def __call__(self, arr: np.ndarray) -> List[Tuple[Color, np.ndarray]]:\n        raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass ChannelMergeOperation:\n    def __call__(self, arr: np.ndarray, original_color_mask_pairs: List[Tuple[Color, np.ndarray]], color_mask_pairs: List[Tuple[Color, np.ndarray]]) -> np.ndarray:\n        raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass ColorOperation:\n    color_selection: ColorSelection\n    mask_conversions: MaskConversion\n    mask_operation: MaskOperation\n\n\n@dataclass(frozen=True)\nclass MultiColorChannelOperation:\n    channel_selection: ColorChannelSelection\n    mask_conversions: MaskConversion\n    channel_merge_operation: ChannelMergeOperation\n\n\n@dataclass(frozen=True)\nclass PartitionedArraySelection:\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]]) -> List[List[bool]]:\n        raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass PartitionOperation:\n    partition_selection: 'PartitionSelection'\n    # partition_uniform_operation: PartitionUniformOperation # TODO implement\n    partition_merge_operation: 'PartitionMergeOperation'\n\n\n@dataclass(frozen=True)\nclass PartitionSelection:\n    # array -> (2d_partitioned_array, 2d_original_location_mask)\n    def __call__(self, arr: np.ndarray) -> Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]:\n        raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass PartitionMergeOperation:\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        raise NotImplementedError()\n\n\n@dataclass\nclass DistanceEvaluatorParameter:\n    same_h_w_dim_between_input_output: float = 1500\n    all_dim_h_w_integer_multiple: float = 650\n    mean_lack_color_num: float = 30\n    mean_excess_color_num: float = 50\n    mean_hit_and_miss_histogram_diff: float = 50\n    mean_h_v_diff_input_arr_line_num: float = 40\n    mean_h_v_diff_output_arr_line_num: float = 60\n    mean_h_v_edge_sum_diff: float = 2\n    mean_h_v_edge_sum_diff_ratio: float = 0.5\n    mean_diff_color_cell_ratio: int = 1  # \u57fa\u6e96\n    mean_diff_cell_where_no_need_to_change_count_ratio: float = 100\n    mean_wrong_change_cell_where_need_to_change_count_ratio: float = 100\n\n\n@dataclass\nclass NodeBaseSearchEngineParameter:\n    breadth_first_cost: float = 3500\n    normal_first_cost: float = 400\n    depth_first_cost: float = 1.2\n    breadth_first_exp_cost: float = 0\n    normal_exp_cost: float = 0\n    depth_first_exp_cost: float = 0\n    element_inclusion_prob_factor: float = 0\n    pq_pop_mins_or_as_least_n: int = 20\n\n\n@dataclass\nclass TreeBaseSearchEngineParameter:\n    population_num: int = 26\n    max_depth: int = 8\n    operation_mutation_prob: float = 0.19\n    operation_component_mutation_prob: float = 0.1\n    operation_param_mutation_prob: float = 0.0048\n    extend_mutation_prob: float = 0.044\n    shrink_mutation_prob: float = 0.0012\n\n\n@dataclass\nclass AllParameter:\n    distance_evaluator_param: DistanceEvaluatorParameter = DistanceEvaluatorParameter()\n    node_base_engine_param: Optional[NodeBaseSearchEngineParameter] = NodeBaseSearchEngineParameter()\n    tree_base_engine_param: Optional[TreeBaseSearchEngineParameter] = TreeBaseSearchEngineParameter()\n\n\n@dataclass()\nclass InputOutput:\n    input_arr: np.ndarray\n    output_arr: Optional[np.ndarray]\n\n    @staticmethod\n    def of(json_dict: dict) -> 'InputOutput':\n        return InputOutput(np.array(json_dict['input'], dtype=np.uint8),\n                           np.array(json_dict['output'], dtype=np.uint8) if 'output' in json_dict else None)\n\n    def get_all_arr(self) -> List[np.ndarray]:\n        if self.output_arr is None:\n            return [self.input_arr]\n        else:\n            return [self.input_arr, self.output_arr]\n\n    def candidate_color_mapping(self) -> List[Tuple[Color, Color]]:\n        input_colors = list(np.unique(self.input_arr)) + [Color.ANY_WITHOUT_MOST, Color.MOST, Color.SECOND_MOST, Color.LEAST]\n        output_colors = np.unique(self.output_arr)\n        return [(Color.of(i), Color.of(o)) for i, o in product(input_colors, output_colors) if i != o]\n\n\n@dataclass(frozen=True)\nclass UniformOperation:\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass OperationSet:\n    operations: List[Union[UniformOperation, ColorOperation, MultiColorChannelOperation, PartitionOperation]]\n\n    def __str__(self):\n        return repr(self)\n\n    def types(self):\n        results = []\n        for o in self.operations:\n            if isinstance(o, UniformOperation):\n                results.append(UniformOperation)\n            elif isinstance(o, ColorOperation):\n                results.append(ColorOperation)\n            elif isinstance(o, MultiColorChannelOperation):\n                results.append(MultiColorChannelOperation)\n            elif isinstance(o, PartitionOperation):\n                results.append(PartitionOperation)\n            else:\n                raise NotImplementedError()\n        return results\n\n    def elements(self) -> List[Union[UniformOperation, ColorSelection, MaskConversion, MaskOperation, PartitionOperation]]:\n        res = []\n        for o in self.operations:\n            if isinstance(o, UniformOperation):\n                res.append(o)\n            elif isinstance(o, ColorOperation):\n                res.append(o.color_selection)\n                res.append(o.mask_conversions)\n                res.append(o.mask_operation)\n            elif isinstance(o, MultiColorChannelOperation):\n                res.append(o.channel_selection)\n                res.append(o.mask_conversions)\n                res.append(o.channel_merge_operation)\n            elif isinstance(o, PartitionOperation):\n                res.append(o.partition_selection)\n                res.append(o.partition_merge_operation)\n            else:\n                raise NotImplementedError()\n        return res\n\n\n@dataclass(frozen=True)\nclass Task:\n    name: str\n    train: Tuple[InputOutput]\n    test: Tuple[InputOutput]\n\n    @staticmethod\n    def of(name: str, json_dict: dict) -> 'Task':\n        return Task(name,\n                    tuple(InputOutput.of(io) for io in json_dict['train']),\n                    tuple(InputOutput.of(io) for io in json_dict['test']))\n\n    def get_all_arr(self) -> List[np.ndarray]:\n        return self.get_train_all_arr() + self.get_test_all_arr()\n\n    def get_train_all_arr(self) -> List[np.ndarray]:\n        return list(chain.from_iterable(map(lambda io: io.get_all_arr(), self.train)))\n\n    def get_test_all_arr(self) -> List[np.ndarray]:\n        return list(chain.from_iterable(map(lambda io: io.get_all_arr(), self.test)))\n\n    def get_input_all_arr(self) -> List[np.ndarray]:\n        return list(map(lambda io: io.input_arr, self.train + self.test))\n\n    def get_output_all_arr(self) -> List[np.ndarray]:\n        return list(filter(lambda arr: arr is not None, map(lambda io: io.output_arr, self.train + self.test)))\n\n    def test_arr_hash(self) -> int:\n        return hash(self.__class__.__name__ +\n                    '_'.join(map(lambda io: str(io.input_arr), self.test)))\n\n\n@dataclass(frozen=True)\nclass ColorSelectedTask(Task):\n    train_masks: List[np.ndarray]\n    test_masks: List[np.ndarray]\n\n\n@dataclass(frozen=True)\nclass MaskConvertedTask(Task):\n    train_masks: List[np.ndarray]\n    test_masks: List[np.ndarray]\n\n\n@dataclass(frozen=True)\nclass ColorChannelSelectedTask(Task):\n    train_color_mask_pairs: List[List[Tuple[Color, np.ndarray]]]\n    test_color_mask_pairs: List[List[Tuple[Color, np.ndarray]]]\n\n\n@dataclass(frozen=True)\nclass ColorChannelMaskConvertedTask(Task):\n    train_original_color_mask_pairs: List[List[Tuple[Color, np.ndarray]]]\n    train_color_mask_pairs: List[List[Tuple[Color, np.ndarray]]]\n    test_original_color_mask_pairs: List[List[Tuple[Color, np.ndarray]]]\n    test_color_mask_pairs: List[List[Tuple[Color, np.ndarray]]]\n\n\n@dataclass(frozen=True)\nclass PartitionSelectionTask(Task):\n    train_partitioned_arrays_original_location_masks: List[Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]]\n    test_partitioned_arrays_original_location_masks: List[Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]]\n\n\n@dataclass\nclass ImageFeature:\n    height: int\n    width: int\n    colors: List[Color]\n    hit_and_miss_histogram: List[int]\n    # most_common_color: Color\n    vertical_edge_num: int\n    horizontal_edge_num: int\n\n\n@dataclass\nclass ImageDiffFeature:\n    input_image_feature: ImageFeature  # TODO should not define here?\n    output_image_feature: ImageFeature  # TODO should not define here?\n    dim_height_increase: int\n    dim_width_increase: int\n    dim_height_integer_multiple: bool\n    dim_width_integer_multiple: bool\n    dim_height_diff: int\n    dim_width_diff: int\n    dim_height_equal: bool\n    dim_width_equal: bool\n    lack_color_num: int\n    excess_color_num: int\n    hit_and_miss_histogram_diff: int\n    # vertical_diff_input_arr_line_num: Optional[int]\n    # horizontal_diff_input_arr_line_num: Optional[int]\n    # vertical_diff_output_arr_line_num: Optional[int]\n    # horizontal_diff_output_arr_line_num: Optional[int]\n    vertical_edge_sum_diff: int\n    horizontal_edge_sum_diff: int\n    vertical_edge_sum_diff_ratio: float\n    horizontal_edge_sum_diff_ratio: float\n    diff_color_cell_ratio: Optional[float]  # None if different image size.\n    diff_cell_where_no_need_to_change_count_ratio: Optional[float]  # None if different image size.\n    wrong_change_cell_where_need_to_change_count_ratio: Optional[float]  # None if different image size.\n\n    # TODO cell_diff_num_except_formost_common_color\n\n    def same_dim(self) -> bool:\n        return self.dim_height_equal and self.dim_width_equal\n\n\n@dataclass\nclass TaskFeature:\n    # image_diff_features: List[ImageDiffFeature]\n    same_dim_between_input_output: bool\n    same_height_dim_between_input_output: bool\n    same_width_dim_between_input_output: bool\n    all_dim_height_increased: bool\n    all_dim_height_decreased: bool\n    all_dim_width_increased: bool\n    all_dim_width_decreased: bool\n    all_dim_height_integer_multiple: bool\n    all_dim_width_integer_multiple: bool\n    mean_lack_color_num: float\n    mean_excess_color_num: float\n    mean_hit_and_miss_histogram_diff: float\n    # mean_vertical_diff_input_arr_line_num: Optional[float]\n    # mean_horizontal_diff_input_arr_line_num: Optional[float]\n    # mean_vertical_diff_output_arr_line_num: Optional[float]\n    # mean_horizontal_diff_output_arr_line_num: Optional[float]\n    mean_vertical_edge_sum_diff: float\n    mean_horizontal_edge_sum_diff: float\n    mean_vertical_edge_sum_diff_ratio: float\n    mean_horizontal_edge_sum_diff_ratio: float\n    mean_diff_color_cell_ratio: Optional[float]  # None if different image size.\n    mean_diff_cell_where_no_need_to_change_count_ratio: Optional[float]  # None if different image size.\n    mean_wrong_change_cell_where_need_to_change_count_ratio: Optional[float]\n\n\n@dataclass\nclass ColorSelectedTaskFeature:\n    task_feature: TaskFeature\n\n\n@dataclass\nclass MaskConvertedTaskFeature:\n    task_feature: TaskFeature\n    possible_improve_ratios: List[Optional[float]]\n\n\n@dataclass\nclass DistanceEvaluator:\n    dist_eval_param: DistanceEvaluatorParameter\n\n    def evaluate_task_feature(self, task_feature: TaskFeature) -> float:\n        return 0 \\\n               + self.dist_eval_param.same_h_w_dim_between_input_output * (0 if task_feature.same_height_dim_between_input_output else 1) \\\n               + self.dist_eval_param.same_h_w_dim_between_input_output * (0 if task_feature.same_width_dim_between_input_output else 1) \\\n               + self.dist_eval_param.all_dim_h_w_integer_multiple * (0 if task_feature.all_dim_height_integer_multiple else 1) \\\n               + self.dist_eval_param.all_dim_h_w_integer_multiple * (0 if task_feature.all_dim_width_integer_multiple else 1) \\\n               + self.dist_eval_param.mean_lack_color_num * task_feature.mean_lack_color_num \\\n               + self.dist_eval_param.mean_excess_color_num * task_feature.mean_excess_color_num \\\n               + self.dist_eval_param.mean_hit_and_miss_histogram_diff * task_feature.mean_hit_and_miss_histogram_diff \\\n               + self.dist_eval_param.mean_h_v_edge_sum_diff * (task_feature.mean_vertical_edge_sum_diff) \\\n               + self.dist_eval_param.mean_h_v_edge_sum_diff * (task_feature.mean_horizontal_edge_sum_diff) \\\n               + self.dist_eval_param.mean_h_v_edge_sum_diff_ratio * (task_feature.mean_vertical_edge_sum_diff_ratio) \\\n               + self.dist_eval_param.mean_h_v_edge_sum_diff_ratio * (task_feature.mean_horizontal_edge_sum_diff_ratio) \\\n               + self.dist_eval_param.mean_diff_color_cell_ratio * (task_feature.mean_diff_color_cell_ratio or 0) \\\n               + self.dist_eval_param.mean_diff_cell_where_no_need_to_change_count_ratio * (task_feature.mean_diff_cell_where_no_need_to_change_count_ratio or 0) \\\n               + self.dist_eval_param.mean_wrong_change_cell_where_need_to_change_count_ratio * (task_feature.mean_wrong_change_cell_where_need_to_change_count_ratio or 0)\n\n    # + self.dist_eval_param.mean_h_v_diff_input_arr_line_num * (task_feature.mean_horizontal_diff_input_arr_line_num or 0) \\\n    # + self.dist_eval_param.mean_h_v_diff_input_arr_line_num * (task_feature.mean_vertical_diff_input_arr_line_num or 0) \\\n    # + self.dist_eval_param.mean_h_v_diff_output_arr_line_num * (task_feature.mean_horizontal_diff_output_arr_line_num or 0) \\\n    # + self.dist_eval_param.mean_h_v_diff_output_arr_line_num * (task_feature.mean_vertical_diff_output_arr_line_num or 0) \\\n\n    def evaluate_task_feature_element(self, task_feature: TaskFeature) -> List[float]:\n        return [(0 if task_feature.same_height_dim_between_input_output else 1),\n                (0 if task_feature.same_width_dim_between_input_output else 1),\n                (0 if task_feature.all_dim_height_integer_multiple else 1),\n                (0 if task_feature.all_dim_width_integer_multiple else 1),\n                task_feature.mean_lack_color_num,\n                task_feature.mean_excess_color_num,\n                task_feature.mean_hit_and_miss_histogram_diff,\n                (task_feature.mean_vertical_edge_sum_diff),\n                (task_feature.mean_horizontal_edge_sum_diff),\n                (task_feature.mean_vertical_edge_sum_diff_ratio),\n                (task_feature.mean_horizontal_edge_sum_diff_ratio),\n                (task_feature.mean_diff_color_cell_ratio or 0)]\n\n\nclass Node:\n\n    def __repr__(self):\n        return str(self)\n\n\n@dataclass\nclass WaitingNode(Node):\n    # This node will be added to priority queue.\n\n    parent_completed_node: 'CompletedNode'\n    cache_pred_distance = None\n\n    def evaluation_features(self) -> Dict[str, Any]:\n        raise NotImplementedError()\n\n    def depth(self) -> int:\n        raise NotImplementedError()\n\n    def __le__(self, other: 'WaitingNode') -> bool:\n        return self.cache_pred_distance <= other.cache_pred_distance\n\n    def __lt__(self, other: 'WaitingNode') -> bool:\n        return self.cache_pred_distance < other.cache_pred_distance\n\n\n@dataclass\nclass UniformOperationWaitingNode(WaitingNode):\n    original_task: Task\n    task: Task\n    task_feature: TaskFeature\n    base_operation_set: OperationSet\n    next_operation: UniformOperation\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, next_ope: {self.next_operation}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n    def evaluation_features(self) -> Dict[str, Any]:\n        return {\n            'node_class': self.__class__.__name__,\n            'depth': len(self.base_operation_set.operations),\n            **asdict(self.task_feature),\n            'next_operation': self.next_operation.__class__.__name__,\n            **asdict(self.next_operation)\n        }\n\n\n@dataclass\nclass ColorSelectionWaitingNode(WaitingNode):\n    original_task: Task\n    task: Task\n    task_feature: TaskFeature\n    base_operation_set: OperationSet\n    next_selection: ColorSelection\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, next_selection: {self.next_selection}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n    def evaluation_features(self) -> Dict[str, Any]:\n        return {\n            'node_class': self.__class__.__name__,\n            'depth': len(self.base_operation_set.operations),\n            **asdict(self.task_feature),\n            'next_selection': self.next_selection.__class__.__name__,\n            **asdict(self.next_selection)\n        }\n\n\n@dataclass\nclass MaskConversionWaitingNode(WaitingNode):\n    original_task: Task\n    color_selected_task: ColorSelectedTask\n    color_selected_task_feature: ColorSelectedTaskFeature\n    base_operation_set: OperationSet\n    color_selection: ColorSelection\n    next_mask_conversion: MaskConversion\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, color_selection: {self.color_selection}, next_add_selection: {self.next_mask_conversion}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n    def evaluation_features(self) -> Dict[str, Any]:\n        return {\n            'node_class': self.__class__.__name__,\n            'depth': len(self.base_operation_set.operations),\n            **asdict(self.color_selected_task_feature.task_feature),\n            'next_mask_conversion': self.next_mask_conversion.__class__.__name__,\n            **asdict(self.next_mask_conversion)\n        }\n\n\n@dataclass\nclass MaskOperationSelectionWaitingNode(WaitingNode):\n    original_task: Task\n    mask_converted_task: MaskConvertedTask\n    mask_converted_task_feature: MaskConvertedTaskFeature\n    base_operation_set: OperationSet\n    color_selection: ColorSelection\n    mask_conversion: MaskConversion\n    next_mask_operation: MaskOperation\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, color_selection: {self.color_selection}, add_selection: {self.mask_conversion}, next_mask_ope: {self.next_mask_operation}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n    def evaluation_features(self) -> Dict[str, Any]:\n        return {\n            'node_class': self.__class__.__name__,\n            'depth': len(self.base_operation_set.operations),\n            **asdict(self.mask_converted_task_feature.task_feature),\n            'next_mask_operation': self.next_mask_operation.__class__.__name__,\n            **asdict(self.next_mask_operation)\n        }\n\n\n@dataclass\nclass ColorChannelSelectionOperationWaitingNode(WaitingNode):\n    original_task: Task\n    task: Task\n    task_feature: TaskFeature\n    base_operation_set: OperationSet\n    next_color_channel_selection: ColorChannelSelection\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, next_color_channeling: {self.next_color_channel_selection}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n    def evaluation_features(self) -> Dict[str, Any]:\n        return {\n            'node_class': self.__class__.__name__,\n            'depth': len(self.base_operation_set.operations),\n            **asdict(self.task_feature),\n            'next_operation': self.next_color_channel_selection.__class__.__name__,\n            **asdict(self.next_color_channel_selection)\n        }\n\n\n@dataclass\nclass ColorChannelMaskConversionWaitingNode(WaitingNode):\n    original_task: Task\n    task: ColorChannelSelectedTask\n    task_feature: TaskFeature\n    base_operation_set: OperationSet\n    color_channel_selection: ColorChannelSelection\n    next_mask_conversion: MaskConversion\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, color_channel_selection: {self.color_channel_selection}, next_mask_conversion: {self.next_mask_conversion}, next_mask_ope: {self.next_mask_conversion}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n\n@dataclass\nclass ColorChannelMergeWaitingNode(WaitingNode):\n    original_task: Task\n    task: ColorChannelMaskConvertedTask\n    task_feature: TaskFeature\n    base_operation_set: OperationSet\n    color_channel_selection: ColorChannelSelection\n    mask_conversion: MaskConversion\n    next_merge_operation: ChannelMergeOperation\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, color_channel_selection: {self.color_channel_selection}, mask_conversion: {self.mask_conversion}, next_merge_operation: {self.next_merge_operation}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n\n@dataclass\nclass PartitionSelectionWaitingNode(WaitingNode):\n    original_task: Task\n    task: Task\n    task_feature: TaskFeature\n    base_operation_set: OperationSet\n    next_partition_selection: PartitionSelection\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, next_partition_sel: {self.next_partition_selection}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n\n@dataclass\nclass PartitionMergeWaitingNode(WaitingNode):\n    original_task: Task\n    task: PartitionSelectionTask\n    task_feature: TaskFeature\n    base_operation_set: OperationSet\n    partition_selection: PartitionSelection\n    next_partition_merge_operation: PartitionMergeOperation\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}+1, class: {self.__class__.__name__}, ' \\\n               f'ope_set: {self.base_operation_set}, partition_sel: {self.partition_selection}, partition_merge: {self.next_partition_merge_operation}'\n\n    def depth(self) -> int:\n        return len(self.base_operation_set.operations)\n\n\n@dataclass()\nclass CompletedNode(Node):\n    # This node won't be added to priority queue. This is processed immediately and converted to next List[WaitingNode].\n\n    parent_waiting_node: 'WaitingNode'\n\n    def train_arr_hash(self) -> int:\n        raise NotImplementedError()\n\n    def all_arr_hash(self) -> int:\n        raise NotImplementedError()\n\n\n@dataclass\nclass UniformOperationCompletedNode(CompletedNode):\n    original_task: Task\n    task: Task\n    task_feature: TaskFeature\n    base_operation_set: OperationSet\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}, class: {self.__class__.__name__}, ope_set: {self.base_operation_set}'\n\n    def train_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(map(lambda io: np_to_str(io.input_arr), self.task.train)))\n\n    def all_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(map(lambda io: np_to_str(io.input_arr), self.task.train + self.task.test)))\n\n\n@dataclass\nclass ColorSelectionCompletedNode(CompletedNode):\n    original_task: Task\n    color_selected_task: ColorSelectedTask\n    color_selected_task_feature: ColorSelectedTaskFeature\n    base_operation_set: OperationSet\n    color_selection: ColorSelection\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}, class: {self.__class__.__name__}, ' \\\n               f'base_ope: {self.base_operation_set}, color_sele: {self.color_selection}'\n\n    def train_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.color_selected_task.train),\n                        map(lambda t: np_to_str(t), self.color_selected_task.train_masks)\n                    )))\n\n    def all_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.color_selected_task.train + self.color_selected_task.test),\n                        map(lambda t: np_to_str(t), self.color_selected_task.train_masks + self.color_selected_task.test_masks)\n                    )))\n\n\n@dataclass\nclass MaskConversionCompletedNode(CompletedNode):\n    original_task: Task\n    mask_converted_task: MaskConvertedTask\n    mask_converted_task_feature: MaskConvertedTaskFeature\n    base_operation_set: OperationSet\n    color_selection: ColorSelection\n    mask_conversion: MaskConversion\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}, class: {self.__class__.__name__}, ' \\\n               f'base_ope: {self.base_operation_set}, color_sele: {self.color_selection}, add_sele: {self.mask_conversion}'\n\n    def train_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.mask_converted_task.train),\n                        map(lambda t: np_to_str(t), self.mask_converted_task.train_masks)\n                    )))\n\n    def all_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.mask_converted_task.train + self.mask_converted_task.test),\n                        map(lambda t: np_to_str(t), self.mask_converted_task.train_masks + self.mask_converted_task.test_masks)\n                    )))\n\n\n@dataclass\nclass ColorChannelSelectionCompletedNode(CompletedNode):\n    original_task: Task\n    task: ColorChannelSelectedTask\n    feature: TaskFeature\n    base_operation_set: OperationSet\n    color_channel_selection: ColorChannelSelection\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}, class: {self.__class__.__name__}, ' \\\n               f'base_ope: {self.base_operation_set}, color_sele: {self.color_channel_selection}'\n\n    def train_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.task.train),\n                        chain.from_iterable([(to_bytes(c), np_to_str(m)) for p_l in self.task.train_color_mask_pairs for c, m in p_l]),\n                    )))\n\n    def all_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.task.test),\n                        chain.from_iterable([(to_bytes(c), np_to_str(m)) for p_l in self.task.train_color_mask_pairs + self.task.test_color_mask_pairs for c, m in p_l]),\n                    )))\n\n\n@dataclass\nclass ColorChannelMaskConversionCompletedNode(CompletedNode):\n    original_task: Task\n    task: ColorChannelMaskConvertedTask\n    feature: TaskFeature\n    base_operation_set: OperationSet\n    color_selection: ColorChannelSelection\n    mask_conversion: MaskConversion\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}, class: {self.__class__.__name__}, ' \\\n               f'base_ope: {self.base_operation_set}, mask_conversion: {self.mask_conversion}'\n\n    def train_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.task.train),\n                        chain.from_iterable([(to_bytes(c), np_to_str(m)) for p_l in self.task.train_original_color_mask_pairs for c, m in p_l]),\n                        chain.from_iterable([(to_bytes(c), np_to_str(m)) for p_l in self.task.train_color_mask_pairs for c, m in p_l]),\n                    )))\n\n    def all_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.task.test),\n                        chain.from_iterable([(to_bytes(c), np_to_str(m)) for p_l in self.task.train_original_color_mask_pairs + self.task.test_original_color_mask_pairs for c, m in p_l]),\n                        chain.from_iterable([(to_bytes(c), np_to_str(m)) for p_l in self.task.train_color_mask_pairs + self.task.test_color_mask_pairs for c, m in p_l]),\n                    )))\n\n\n@dataclass\nclass PartitionSelectionCompletedNode(CompletedNode):\n    original_task: Task\n    task: PartitionSelectionTask\n    feature: TaskFeature\n    base_operation_set: OperationSet\n    partition_selection: PartitionSelection\n\n    def __str__(self):\n        return f'depth: {len(self.base_operation_set.operations)}, class: {self.__class__.__name__}, ' \\\n               f'base_ope: {self.base_operation_set}, partition_selection: {self.partition_selection}'\n\n    def train_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.task.train),\n                        [to_bytes(v) for v in self.task.train_partitioned_arrays_original_location_masks]),\n                    ))\n\n    def all_arr_hash(self) -> int:\n        return hash(bytes(self.__class__.__name__, encoding='utf-8') +\n                    b'_'.join(chain(\n                        map(lambda io: np_to_str(io.input_arr), self.task.test),\n                        [to_bytes(v) for v in self.task.train_partitioned_arrays_original_location_masks + self.task.test_partitioned_arrays_original_location_masks]),\n                    ))\n\n\n@dataclass(frozen=True)\nclass NodeTree:\n    completed_nodes: List[CompletedNode]\n\n    def __str__(self):\n        return '\\n'.join(map(str, self.completed_nodes))\n\n    @classmethod\n    def of(cls, completed_node: CompletedNode) -> 'NodeTree':\n        completed_nodes = []\n\n        current_node = completed_node\n        while True:\n            if isinstance(current_node, CompletedNode):\n                completed_nodes.append(current_node)\n                current_node = current_node.parent_waiting_node\n            elif isinstance(current_node, WaitingNode):\n                current_node = current_node.parent_completed_node\n            elif current_node is None:\n                # TODO root node\n                break\n            else:\n                raise NotImplementedError()\n        return cls(list(reversed(completed_nodes)))\n\n    @classmethod\n    def replaced_new_node_tree(cls, node_tree: 'NodeTree', node_depth: int, node: CompletedNode) -> 'NodeTree':\n        copied_list = copy.copy(node_tree.completed_nodes)\n        copied_list[node_depth] = node\n        return cls(copied_list)\n\n    def to_operation_set(self) -> OperationSet:\n        # TODO found a bug related to MultiColorChannelOperation.\n        try:\n            operations = []\n            temp_color_selection = None\n            temp_mask_conversion = None\n            temp_color_channel_selection = None\n            temp_partition_selection = None\n\n            # TODO too dirty.\n\n            assert len(self.completed_nodes[0].base_operation_set.operations) == 0, self.completed_nodes[0]\n            for n in self.completed_nodes[1:]:  # first element is root.\n                if isinstance(n, UniformOperationCompletedNode):\n                    if isinstance(n.base_operation_set.operations[-1], UniformOperation):\n                        operations.append(n.base_operation_set.operations[-1])\n                    else:\n                        if temp_color_selection is not None:\n                            operations.append(ColorOperation(temp_color_selection, temp_mask_conversion, n.base_operation_set.operations[-1].mask_operation))\n                            temp_color_selection = None\n                            temp_mask_conversion = None\n                            temp_color_channel_selection = None\n                            temp_partition_selection = None\n                        elif temp_color_channel_selection is not None:\n                            operations.append(MultiColorChannelOperation(temp_color_channel_selection, temp_mask_conversion, n.base_operation_set.operations[-1].channel_merge_operation))\n                            temp_color_selection = None\n                            temp_mask_conversion = None\n                            temp_color_channel_selection = None\n                            temp_partition_selection = None\n                        elif temp_partition_selection is not None:\n                            operations.append(PartitionOperation(temp_partition_selection, n.base_operation_set.operations[-1].partition_merge_operation))\n                            temp_color_selection = None\n                            temp_mask_conversion = None\n                            temp_color_channel_selection = None\n                            temp_partition_selection = None\n                        else:\n                            raise NotImplementedError()\n                elif isinstance(n, ColorSelectionCompletedNode):\n                    temp_color_selection = n.color_selection\n                elif isinstance(n, MaskConversionCompletedNode):\n                    temp_mask_conversion = n.mask_conversion\n                elif isinstance(n, ColorChannelMaskConversionCompletedNode):\n                    temp_mask_conversion = n.mask_conversion\n                elif isinstance(n, ColorChannelSelectionCompletedNode):\n                    temp_color_channel_selection = n.color_channel_selection\n                elif isinstance(n, PartitionSelectionCompletedNode):\n                    temp_partition_selection = n.partition_selection\n                else:\n                    raise ValueError()\n\n            return OperationSet(operations)\n        except Exception as e:\n            print(f'error: {e}')\n        return OperationSet([])\n\n    def waiting_nodes(self) -> List[WaitingNode]:\n        return list(filter(lambda n: n is not None, map(lambda n: n.parent_waiting_node, self.completed_nodes)))\n\n\nclass NodeEvaluator:\n\n    def evaluate(self, node: WaitingNode):\n        raise NotImplementedError()\n\n    def evaluate_nodes(self, nodes: List[WaitingNode]):\n        raise NotImplementedError()\n\n\nclass RandomNodeEvaluator(NodeEvaluator):\n\n    def evaluate(self, node: WaitingNode):\n        node.cache_pred_distance = random.uniform(0, 1) * node.depth()\n\n    def evaluate_nodes(self, nodes: List[WaitingNode]):\n        for n in nodes:\n            self.evaluate(n)\n\n\n@dataclass\nclass AnswerStorageElement:\n    task_name: str\n    correct: bool\n    depth: int\n    operation_set: OperationSet\n\n    def __post_init__(self):\n        self.depth = len(self.operation_set.operations)\n\n    def validate(self):\n        task = TaskLoader().get_task(self.task_name)\n        try:\n            a = AnswerMatcher.is_train_test_all_match_if_operated(task, self.operation_set)\n            if a != self.correct:\n                print(f'{self.task_name} correct inconsistency. {self.correct}_{a}')\n                return False\n        except OperationInconsistencyException as e:\n            print(f'{self.task_name} OperationInconsistencyException')\n            return False\n\n        return True\n\n    def __hash__(self):\n        return hash(repr(self))\n\n\n@dataclass\nclass AnsweredSearchResult:\n    operation_set: OperationSet\n    test_output_arr: Tuple[np.ndarray] = None\n    test_correct: Optional[bool] = None\n\n\n@dataclass\nclass AnsweredSearchResults:\n    task: Task\n    results: List[AnsweredSearchResult]\n    zero_depth_search_time: float\n    spent_time: float\n    searched_total_node: int\n\n    def summary(self):\n        summary_elements = [f'{self.task.name}_{i}, '\n                            f'correct: {str(r.test_correct):>5}, '\n                            f'node: {self.searched_total_node:>6}, ' \\\n                            f'zero_depth_sec: {int(self.zero_depth_search_time):>5}, sec: {int(self.spent_time):>5}, '\n                            f'depth: {len(r.operation_set.operations)}, operation_set: {r.operation_set}'\n                            for i, r in enumerate(self.results)]\n\n        return '\\n'.join(summary_elements)\n\n    def final_test_correct(self):\n        return any(map(lambda r: r.test_correct, self.results))\n\n    def to_answer_storage_elements(self) -> List[AnswerStorageElement]:\n        return [AnswerStorageElement(self.task.name, r.test_correct, len(r.operation_set.operations), r.operation_set) for r in self.results]\n\n\n@dataclass\nclass NotAnsweredSearchResult:\n    task: Task\n    exception: Exception\n    spent_time: float\n    searched_total_node: int\n\n    def final_test_correct(self):\n        return None\n\n    def summary(self):\n        return f'{self.task.name}__, ' \\\n               f'correct:  None, ' \\\n               f'node: {self.searched_total_node:>6}, sec: {int(self.spent_time):>5}, ' \\\n               f'exception: {self.exception.__class__.__name__}'\n\n\n@dataclass\nclass AnswerStorage:\n    elements: Set[AnswerStorageElement]\n\n    def validate(self):\n        self.elements = set(filter(lambda e: e.validate(), self.elements))\n\n    def add(self, element: AnswerStorageElement):\n        self.elements.add(element)\n\n    def get_text(self) -> str:\n        return '\\n'.join(repr(e) for e in sorted(self.elements, key=lambda e: (e.task_name, not e.correct, e.depth)))\n\n    def get_only_correct_answer_storage(self) -> 'AnswerStorage':\n        return AnswerStorage({e for e in self.elements if e.correct})\n\n    def get_task_grouped_elements(self) -> List[Tuple[str, List[AnswerStorageElement]]]:\n        elements = list(self.elements)\n        elements = sorted(elements, key=lambda e: e.task_name)\n        return [(k, list(g)) for k, g in groupby(elements, key=lambda e: e.task_name)]\n\n\ndef load_answer_storage() -> AnswerStorage:\n    if not PathConfig.OPERATION_ANSWER_STORAGE.exists():\n        return AnswerStorage(set())\n\n    elements: List[AnswerStorageElement] = []\n    with open(str(PathConfig.OPERATION_ANSWER_STORAGE), mode='r', encoding='utf-8') as f:\n        for l in f.readlines():\n            try:\n                elements.append(str_to_AnswerStorageElement(l))\n            except:\n                pass\n    storage = AnswerStorage(set(elements))\n    storage.validate()\n    return storage\n\n\ndef save_answer_storage(storage: AnswerStorage):\n    PathConfig.OPERATION_ANSWER_STORAGE.unlink()\n    with open(str(PathConfig.OPERATION_ANSWER_STORAGE), mode='w', encoding='utf-8') as f:\n        f.write(storage.get_text())\n\n\ndef update_answer_storage(elements: List[AnswerStorageElement], verbose: bool = False):\n    if verbose:\n        print('load_answer storage')\n    storage = load_answer_storage()\n    if verbose:\n        print(storage.get_text())\n\n        print('add answer storage')\n    for e in elements:\n        e.validate()\n        storage.add(e)\n    if verbose:\n        print('save answer storage')\n        print(storage.get_text())\n    save_answer_storage(storage)\n\n\n@dataclass\nclass AnswerFoundException(Exception):\n    operation_set: OperationSet\n\n\nclass NoImprovementException(Exception):\n    MESSAGE = 'No improve'\n\n\nclass MaxDepthExceededException(Exception):\n    MESSAGE = 'Max depth'\n\n\nclass MaxNodeExceededException(Exception):\n    MESSAGE = 'Max node'\n\n\nclass TimeoutException(Exception):\n    MESSAGE = 'Timeout'\n\n\ndef get_all_operation_classes():\n    return [UniformOperation, ColorOperation, MultiColorChannelOperation, PartitionOperation]\n\n\ndef get_all_operation_element_classes():\n    classes = [UniformOperation, ColorSelection, MaskConversion, MaskOperation, ColorChannelSelection, ChannelMergeOperation, PartitionSelection, PartitionMergeOperation]\n    return chain.from_iterable([c.__subclasses__() for c in classes])\n\n\n@unique\nclass BackGroundColorSelectionMode(StrNameEnum):\n    BLACK = auto()\n    MOST_COMMON = auto()\n\n\n@unique\nclass AxisV2(StrNameEnum):\n    VERTICAL = auto()\n    HORIZONTAL = auto()\n    VERTICAL_HORIZONTAL = auto()\n    MAIN_DIAGONAL = auto()\n    ANTI_DIAGONAL = auto()\n    BOTH_DIAGONAL = auto()\n\n\n@unique\nclass Corner(StrNameEnum):\n    TOP_LEFT = auto()\n    TOP_RIGHT = auto()\n    BOTTOM_RIGHT = auto()\n    BOTTOM_LEFT = auto()\n\n\n@unique\nclass SpiralDirection(StrNameEnum):\n    CLOCKWISE = auto()\n    ANTICLOCKWISE = auto()\n\n\nclass DebugConfig:\n    OPERATION_DEBUG_TASK_NAME = ''  # dae9d2b5\n    OPERATION_DEBUG_OPERATION_SET = ''\n    # solve debug\n    SOLVE_DEBUG_TASK_NAME = ''  # dae9d2b5\n\n    # train_data_generator debug\n    TRAIN_DATA_GENERATION_DEBUG_TASK_NAME = ''\n\n\nclass PathConfig:\n    ROOT: Path = Path('') if RunConfig.RUN_MODE == RunMode.KERNEL else Path(__file__).parent\n\n    # input\n    INPUT_ROOT: Path = ROOT \/ 'input'\n    TRAIN_ROOT: Path = INPUT_ROOT \/ 'training'  # training_and_evaluation\n    EVALUATION_ROOT: Path = INPUT_ROOT \/ 'evaluation'\n    TEST_ROOT: Path = INPUT_ROOT \/ 'test'\n    SAMPLE_SUBMISSION: Path = INPUT_ROOT \/ 'sample_submission.csv'\n\n    # output\n    OUTPUT_SUBMISSION: Path = ROOT \/ 'output' \/ 'submission.csv'\n\n    # answer_memo\n    OPERATION_ANSWER_MEMO_ROOT: Path = ROOT \/ 'answer_memo'\n    OPERATION_ANSWER_TAXONOMY_YAML: Path = OPERATION_ANSWER_MEMO_ROOT \/ 'answer_taxonomy.yaml'\n    OPERATION_ANSWER_TAXONOMY_IMAGE_ROOT: Path = OPERATION_ANSWER_MEMO_ROOT \/ 'answer_taxonomy'\n    OPERATION_ANSWER_STORAGE: Path = OPERATION_ANSWER_MEMO_ROOT \/ 'answer_storage.txt'\n    WRONG_ANSWERS_ROOT: Path = OPERATION_ANSWER_MEMO_ROOT \/ 'wrong_answers'\n\n    # kernel\n    KERNEL_SCRIPT_PATH: Path = ROOT \/ 'kernel' \/ 'kernel_script.py'\n\n    # run\n    LOG_ROOT: Path = ROOT \/ 'log'\n\n    # ml_model\n    SAVED_MODEL: Path = ROOT \/ 'saved_model'\n    NODE_EVALUATOR_FEATURES = SAVED_MODEL \/ 'features.pkl'\n    NODE_EVALUATOR_CATEGORICAL_FEATURES = SAVED_MODEL \/ 'categorical_features.pkl'\n    NODE_EVALUATOR_MODEL = SAVED_MODEL \/ 'model.pkl'\n    NODE_EVALUATOR_ORDINAL_ENCODER = SAVED_MODEL \/ 'ordinal_encoder.pkl'\n    NODE_EVALUATOR_SAMPLE_DF = SAVED_MODEL \/ 'sample_df.pkl'\n\n    OPERATION_ELEMENT_INCLUSION_MODEL_ROOT = SAVED_MODEL \/ 'operation_element_inclusion'\n    OPERATION_ELEMENT_INCLUSION_MODEL = OPERATION_ELEMENT_INCLUSION_MODEL_ROOT \/ 'model.pkl'\n    OPERATION_ELEMENT_INCLUSION_MODEL_TARGET_COLUMNS = OPERATION_ELEMENT_INCLUSION_MODEL_ROOT \/ 'target_columns.pkl'\n    OPERATION_ELEMENT_INCLUSION_MODEL_FEATURE_COLUMNS = OPERATION_ELEMENT_INCLUSION_MODEL_ROOT \/ 'feature_columns.pkl'\n\n    # ml_training_data\n    LABELED_TRAINING_DATA_ROOT = ROOT \/ 'training'\n\n\nclass KernelPathConfig:\n    INPUT_ROOT = Path('\/kaggle\/input\/abstraction-and-reasoning-challenge\/')\n    TRAIN_ROOT: Path = INPUT_ROOT \/ 'training'\n    EVALUATION_ROOT: Path = INPUT_ROOT \/ 'evaluation'\n#     TEST_ROOT: Path = INPUT_ROOT \/ 'test'\n    TEST_ROOT: Path = Path('test_aligned')\n    SAMPLE_SUBMISSION: Path = INPUT_ROOT \/ 'sample_submission.csv'\n    SUBMISSION = 'submission_yuki_alignment.csv'\n\n\ndef create_submission(engine_results: List[Union[AnsweredSearchResults, NotAnsweredSearchResult]]):\n    submission_df = DataFrame(columns=['output_id', 'output'])\n\n    for result in engine_results:\n        test_arr_num = len(result.task.test)\n        for i in range(test_arr_num):\n            if isinstance(result, AnsweredSearchResults):\n                answers = [r.test_output_arr[i] for r in result.results]\n                answers += [None for _ in range(3 - len(answers))]\n            elif isinstance(result, NotAnsweredSearchResult):\n                answers = [None] * 3\n            else:\n                raise NotImplementedError()\n            output_str = ' '.join(map(lambda a: parse_str(a), answers)) + ' '\n            d = {\n                'output_id': f'{result.task.name}_{i}',\n                'output': output_str\n            }\n            submission_df = submission_df.append([d])\n    return submission_df\n\n\ndef parse_str(arr: np.ndarray) -> str:\n    if arr is None:\n        return '|0|'\n\n    return '|' + '|'.join(map(lambda row: ''.join(str(v) for v in row), arr)) + '|'\n\n\ndef save_submission_df(submission_df: DataFrame):\n    if RunConfig.RUN_MODE == RunMode.KERNEL:\n        submission_df.to_csv(KernelPathConfig.SUBMISSION, index=False)\n    else:\n        PathConfig.OUTPUT_SUBMISSION.parent.mkdir(parents=True, exist_ok=True)\n        submission_df.to_csv(PathConfig.OUTPUT_SUBMISSION, index=False)\n\n\ndef plot_one(ax, arr: np.ndarray, i, train_or_test, input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n\n    ax.imshow(arr, cmap=cmap, norm=norm)\n    ax.grid(True, which='both', color='lightgrey', linewidth=0.5)\n    ax.set_yticks([x - 0.5 for x in range(1 + len(arr))])\n    ax.set_xticks([x - 0.5 for x in range(1 + len(arr[0]))])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' ' + input_or_output)\n\n\ndef plot_task(task: Task, show: bool, save_path: Optional[Path]):\n    input_output_num = len(task.train + task.test)\n    total_row = 2\n    fig, axs = plt.subplots(total_row, input_output_num, figsize=(2 * input_output_num, 2 * total_row))\n    for i, (input_output, tag) in enumerate(zip(task.train + task.test, ['train'] * len(task.train) + ['test'] * len(task.test))):\n        plot_one(axs[0, i], input_output.input_arr, i, tag, 'input')\n        plot_one(axs[1, i], input_output.output_arr, i, tag, 'output')\n    plt.tight_layout()\n\n    if save_path:\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        plt.savefig(save_path)\n    if show:\n        plt.show()\n    plt.close()\n\n\ndef plot_task_with_operation_set(task: Task, operation_set: OperationSet, show: bool, save_path: Optional[Path]):\n    input_output_num = len(task.train + task.test)\n    total_row = 3\n\n    applied_task = TaskOperationSetExecutor().execute(task, operation_set)\n    fig, axs = plt.subplots(total_row, input_output_num, figsize=(3 * input_output_num, 3 * total_row))\n    for i, (raw_io, applied_io) in enumerate(zip(task.train + task.test, applied_task.train + applied_task.test)):\n        plot_one(axs[0, i], raw_io.input_arr, i, 'train?', 'input')\n        plot_one(axs[1, i], raw_io.output_arr, i, 'train?', 'output')\n        plot_one(axs[2, i], applied_io.input_arr, i, 'train?', 'operated')\n    plt.tight_layout()\n\n    if save_path:\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        plt.savefig(save_path)\n    if show:\n        plt.show()\n    plt.close()\n\n\ndef plot_task_with_result_set(task: Task, search_results: AnsweredSearchResults, show: bool, save_path: Optional[Path]):\n    input_output_num = len(task.train + task.test)\n    total_row = 2 + len(search_results.results)\n\n    applied_tasks = [TaskOperationSetExecutor().execute(task, r.operation_set) for r in search_results.results]\n    fig, axs = plt.subplots(total_row, input_output_num, figsize=(3 * input_output_num, 3 * total_row))\n    for i, input_output in enumerate(task.train + task.test):\n        plot_one(axs[0, i], input_output.input_arr, i, 'train?', 'input')\n        plot_one(axs[1, i], input_output.output_arr, i, 'train?', 'output')\n    for i, t in enumerate(applied_tasks):\n        for j, input_output in enumerate(t.train + t.test):\n            plot_one(axs[i + 2, j], input_output.input_arr, i, 'train?', 'input')\n    plt.tight_layout()\n\n    if save_path:\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        plt.savefig(save_path)\n    if show:\n        plt.show()\n    plt.close()\n\n\n@dataclass(frozen=True)\nclass Padding(UniformOperation):\n    padding_mode: PaddingMode\n    direction: Direction\n    k: int\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        if self.padding_mode == PaddingMode.REPEAT:\n            np_pad_mode = 'wrap'\n        elif self.padding_mode == PaddingMode.MIRROR_1:\n            np_pad_mode = 'symmetric'\n        elif self.padding_mode == PaddingMode.MIRROR_2:\n            np_pad_mode = 'reflect'\n        elif self.padding_mode == PaddingMode.EDGE:\n            np_pad_mode = 'edge'\n        else:\n            raise ValueError(self.padding_mode)\n\n        h, w = arr.shape\n        if self.padding_mode == PaddingMode.MIRROR_2:\n            h, w = h - 1, w - 1\n\n        if self.direction == Direction.TOP:\n            pad_width = ((self.k * h, 0), (0, 0))\n        elif self.direction == Direction.BOTTOM:\n            pad_width = ((0, self.k * h), (0, 0))\n        elif self.direction == Direction.LEFT:\n            pad_width = ((0, 0), (self.k * w, 0))\n        elif self.direction == Direction.RIGHT:\n            pad_width = ((0, 0), (0, self.k * w))\n        else:\n            raise ValueError(self.direction)\n\n        return np.pad(arr, pad_width, mode=np_pad_mode)\n\n\n@dataclass(frozen=True)\nclass Resize(UniformOperation):\n    axis: Axis\n    ratio: int  # TODO int? How to resize 3\/2?\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        if self.axis == Axis.VERTICAL:\n            return np.repeat(arr, self.ratio, axis=0)\n        elif self.axis == Axis.HORIZONTAL:\n            return np.repeat(arr, self.ratio, axis=1)\n        elif self.axis == Axis.BOTH:\n            temp = np.repeat(arr, self.ratio, axis=0)\n            return np.repeat(temp, self.ratio, axis=1)\n        else:\n            raise ValueError(self.axis)\n\n\n@dataclass(frozen=True)\nclass Flip(UniformOperation):\n    flip_mode: FlipMode\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        if self.flip_mode == FlipMode.UD:\n            return np.flipud(arr)\n        elif self.flip_mode == FlipMode.LR:\n            return np.fliplr(arr)\n        elif self.flip_mode == FlipMode.UL_DR:\n            return arr.T\n        elif self.flip_mode == FlipMode.UR_DL:\n            return np.flipud(np.flipud(arr.T))\n        else:\n            raise ValueError(self.flip_mode)\n\n\n@dataclass(frozen=True)\nclass Rotate(UniformOperation):\n    angle: int\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        if self.angle not in [90, 180, 270]:\n            raise ValueError(self.angle)\n\n        return np.rot90(arr, self.angle \/\/ 90)\n\n\n@dataclass(frozen=True)\nclass LineDeletion(UniformOperation):\n    line_color: Color\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        if arr.size == 1:\n            raise OperationInconsistencyException('size == 1')\n\n        if 1 in arr.shape:\n            raise OperationInconsistencyException('can not separate')\n\n        color_hit: np.ndarray = arr == self.line_color\n        line_v_indices = np.where(color_hit.all(axis=1))[0]\n        line_h_indices = np.where(color_hit.all(axis=0))[0]\n\n        if len(line_v_indices) == len(line_h_indices) == 0:\n            raise OperationInconsistencyException('not line found')\n\n        arr = np.delete(arr, line_h_indices, axis=1)\n        arr = np.delete(arr, line_v_indices, axis=0)\n\n        if 0 in arr.shape:\n            raise OperationInconsistencyException('0 size')\n\n        return arr\n\n\n@dataclass(frozen=True)\nclass FFTCompletion(UniformOperation):\n\n    # TODO GIVE UP implement.\n    #  This is just a poc for \"SYMMETRY\" or \"REPEAT\" pattern tasks.\n    #  If you're interested in this function, let me know. I'll translate it.\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        revs = []\n        for color in Color:\n\n            print(color)\n            color_hit = arr == color\n\n            if color == Color.BLACK or not color_hit.any():\n                revs.append(np.full_like(color_hit, fill_value=False))\n                continue\n\n            rev_arr_int = self.complete_symmetric(color_hit)\n            rev_arr_int = self.complete_symmetric(rev_arr_int)\n            rev_arr_int = self.complete_symmetric(rev_arr_int)\n            revs.append(rev_arr_int)\n\n        for color, rev in zip(Color, revs):\n            arr[rev] = color\n        return arr\n\n    def complete_symmetric(self, hit_arr, verbose=False):\n        h, w = hit_arr.shape\n\n        if verbose:\n            print(hit_arr)\n        f = np.fft.fftshift(np.fft.fft2(hit_arr))\n        if verbose:\n            print(f)\n        amp = np.abs(f)\n        if verbose:\n            print(amp)\n        amp = amp \/ h \/ w * 2\n        if verbose:\n            print(amp)\n            print(f'sum {amp.sum()}')\n            print(f'mean {amp.mean()}')\n            print(f'max {amp.max()}')\n        # TODO detect peak\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u8abf\u6574\n        flags = np.array(self.detect_not_peaks_mask(amp))\n        if verbose:\n            print(flags)\n        f[flags] = 0\n        filtered_amp = amp.copy()\n        filtered_amp[f == 0] = 0\n        # F3_abs = np.abs(f)  # \u8907\u7d20\u6570\u3092\u7d76\u5bfe\u5024\u306b\u5909\u63db\n        # F3_abs_amp = F3_abs \/ h \/ w * 2  # \u4ea4\u6d41\u6210\u5206\u306f\u30c7\u30fc\u30bf\u6570\u3067\u5272\u3063\u30662\u500d\n        # F3_abs_amp[0] = F3_abs_amp[0] \/ 2  # \u76f4\u6d41\u6210\u5206\uff08\u4eca\u56de\u306f\u6271\u308f\u306a\u3044\u3051\u3069\uff09\u306f2\u500d\u4e0d\u8981\n        F3_ifft = np.fft.ifft2(np.fft.ifftshift(f))  # IFFT\n        F3_ifft_real = F3_ifft.real  # \u5b9f\u6570\u90e8\u306e\u53d6\u5f97\n        # TODO 2\u5024\u5316\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u691c\u8a0e\n        rev_arr_int = F3_ifft_real > threshold_minimum(F3_ifft_real)\n        if verbose:\n            fig, ax = try_all_threshold(F3_ifft_real, figsize=(10, 8), verbose=False)\n            plt.show()\n\n            # visualize\n            plt.subplot(171)\n            plt.imshow(hit_arr, cmap='gray')\n            plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n            plt.subplot(172)\n            plt.hist(amp.ravel(), bins=100)\n            plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n            plt.subplot(173)\n            plt.imshow(amp, cmap='gray')\n            plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n            plt.subplot(174)\n            plt.imshow(filtered_amp, cmap='gray')\n            plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n            plt.subplot(175)\n            plt.hist(F3_ifft_real.ravel(), bins=100)\n            plt.subplot(176)\n            plt.imshow(rev_arr_int, cmap='gray')\n            plt.title('rev'), plt.xticks([]), plt.yticks([])\n            plt.subplot(177)\n            plt.imshow(rev_arr_int | hit_arr, cmap='gray')\n            plt.title('and'), plt.xticks([]), plt.yticks([])\n            plt.show()\n        return rev_arr_int\n\n    def detect_not_peaks_mask(self, image, filter_size=3, order=0.05):\n        local_max = maximum_filter(image, footprint=np.ones((filter_size, filter_size)), mode='constant')\n        detected_peaks = np.ma.array(image, mask=~(image == local_max))\n\n        # \u5c0f\u3055\u3044\u30d4\u30fc\u30af\u5024\u3092\u6392\u9664\uff08\u6700\u5927\u30d4\u30fc\u30af\u5024\u306eorder\u500d\u306e\u30d4\u30fc\u30af\u306f\u6392\u9664\uff09\n        temp = np.ma.array(detected_peaks, mask=~(detected_peaks >= detected_peaks.max() * order))\n        return temp.mask\n\n\n@dataclass(frozen=True)\nclass FixedColorMaskFill(MaskOperation):\n    color: Color\n\n    def __call__(self, arr: np.ndarray, mask: np.ndarray) -> np.ndarray:\n        arr[mask] = self.color\n        return arr\n\n\n@dataclass(frozen=True)\nclass SingleColorMaskFill(MaskOperation):\n    single_color_selection_mode: SingleColorSelectionMode\n\n    def __call__(self, arr: np.ndarray, mask: np.ndarray) -> np.ndarray:\n        color = ColorSelectionUtil().select_single_color(arr, self.single_color_selection_mode)\n        arr[mask] = color\n        return arr\n\n\n@dataclass(frozen=True)\nclass MaskCoordsCrop(MaskOperation):\n\n    def __call__(self, arr: np.ndarray, mask: np.ndarray) -> np.ndarray:\n        # TODO raise OperationInconsistencyException?\n        if not mask.any():\n            return arr\n\n        coords = np.argwhere(mask)\n\n        x_min, y_min = coords.min(axis=0)\n        x_max, y_max = coords.max(axis=0)\n\n        return arr[x_min:x_max + 1, y_min:y_max + 1]\n\n\n@dataclass(frozen=True)\nclass FixedSingleColorSelection(ColorSelection):\n    color: Color\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        return arr == self.color\n\n\n@dataclass(frozen=True)\nclass SingleColorSelection(ColorSelection):\n    single_color_selection_mode: SingleColorSelectionMode\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        color = ColorSelectionUtil().select_single_color(arr, self.single_color_selection_mode)\n        return arr == color\n\n\n@dataclass(frozen=True)\nclass MultiColorSelection(ColorSelection):\n    multi_color_selection_mode: MultiColorSelectionMode\n\n    def __call__(self, arr: np.ndarray) -> np.ndarray:\n        if self.multi_color_selection_mode == MultiColorSelectionMode.ANY_WITHOUT_MOST_COMMON:\n            most_common_color = ColorSelectionUtil().select_single_color(arr, SingleColorSelectionMode.MOST_COMMON)\n            return arr != most_common_color\n        elif self.multi_color_selection_mode == MultiColorSelectionMode.ANY_WITHOUT_LEAST_COMMON:\n            least_common_color = ColorSelectionUtil().select_single_color(arr, SingleColorSelectionMode.LEAST_COMMON)\n            return arr != least_common_color\n        else:\n            raise NotImplementedError()\n\n\nclass TaskLoader:\n\n    def get_task(self, name: str) -> Task:\n        try:\n            return self._get_task(PathConfig.TRAIN_ROOT \/ f'{name}.json')\n        except FileNotFoundError:\n            return self._get_task(PathConfig.EVALUATION_ROOT \/ f'{name}.json')\n\n    def get_training_tasks(self):\n        if RunConfig.RUN_MODE == RunMode.KERNEL:\n            return self._get_tasks(KernelPathConfig.TRAIN_ROOT)\n        else:\n            return self._get_tasks(PathConfig.TRAIN_ROOT)\n\n    def get_evaluation_tasks(self):\n        if RunConfig.RUN_MODE == RunMode.KERNEL:\n            return self._get_tasks(KernelPathConfig.EVALUATION_ROOT)\n        else:\n            return self._get_tasks(PathConfig.EVALUATION_ROOT)\n\n    def get_test_tasks(self):\n        if RunConfig.RUN_MODE == RunMode.KERNEL:\n            return self._get_tasks(KernelPathConfig.TEST_ROOT)\n        else:\n            return self._get_tasks(PathConfig.TEST_ROOT)\n\n    def _get_tasks(self, root_path: Path) -> List[Task]:\n        return [self._get_task(json_path) for json_path in root_path.iterdir()]\n\n    def _get_task(self, path: Path) -> Task:\n        with open(str(path), 'r') as f:\n            return Task.of(path.stem, json.load(f))\n\n    def is_private_lb_run(self) -> bool:\n        eval_tasks = self._get_tasks(KernelPathConfig.EVALUATION_ROOT)\n        test_tasks = self._get_tasks(KernelPathConfig.TEST_ROOT)\n\n        eval_names = [t.name for t in eval_tasks]\n        if any(filter(lambda t: t.name in eval_names, test_tasks)):\n            return False\n        else:\n            return True\n\n\ndef create_image_feature(arr: np.ndarray) -> ImageFeature:\n    return ImageFeature(\n        height=arr.shape[0],\n        width=arr.shape[1],\n        colors=[Color.of(v) for v in ColorSelectionUtil().get_colors(arr)],\n        hit_and_miss_histogram=calculate_hit_and_miss_histogram(arr),\n        # most_common_color=ColorSelectionUtil().select_single_color(arr, SingleColorSelectionMode.MOST_COMMON),\n        vertical_edge_num=np.count_nonzero(arr[1:] - arr[:-1]),  # faster than np.diff(arr, axis=0)\n        horizontal_edge_num=np.count_nonzero(arr[:, 1:] - arr[:, :-1]),  # faster than np.diff(arr, axis=1)\n    )\n\n\ndef create_image_diff_feature(original_input_arr: np.ndarray, input_arr: np.ndarray, output_arr: np.ndarray) -> ImageDiffFeature:\n    util = FeatureUtil()\n    in_feature = create_image_feature(input_arr)\n    out_feature = create_image_feature(output_arr)\n    return ImageDiffFeature(\n        input_image_feature=in_feature,\n        output_image_feature=out_feature,\n        dim_height_increase=out_feature.height - in_feature.height,\n        dim_width_increase=out_feature.width - in_feature.width,\n        dim_height_integer_multiple=(out_feature.height \/ in_feature.height).is_integer() or (in_feature.height \/ out_feature.height).is_integer(),\n        dim_width_integer_multiple=(out_feature.width \/ in_feature.width).is_integer() or (in_feature.width \/ out_feature.width).is_integer(),\n        dim_height_diff=abs(out_feature.height - in_feature.height),\n        dim_width_diff=abs(out_feature.width - in_feature.width),\n        dim_height_equal=out_feature.height == in_feature.height,\n        dim_width_equal=out_feature.width == in_feature.width,\n        lack_color_num=len(set(out_feature.colors) - set(in_feature.colors)),\n        excess_color_num=len(set(in_feature.colors) - set(out_feature.colors)),\n        hit_and_miss_histogram_diff=sum(abs(i_c - o_c) for i_c, o_c in zip(in_feature.hit_and_miss_histogram, out_feature.hit_and_miss_histogram)),\n        # vertical_diff_input_arr_line_num=util._vertical_diff_input_arr_line_num(input_arr, output_arr),\n        # horizontal_diff_input_arr_line_num=util._horizontal_diff_input_arr_line_num(input_arr, output_arr),\n        # vertical_diff_output_arr_line_num=util._vertical_diff_output_arr_line_num(input_arr, output_arr),\n        # horizontal_diff_output_arr_line_num=util._horizontal_diff_output_arr_line_num(input_arr, output_arr),\n        vertical_edge_sum_diff=abs(out_feature.vertical_edge_num - in_feature.vertical_edge_num),\n        horizontal_edge_sum_diff=abs(out_feature.horizontal_edge_num - in_feature.horizontal_edge_num),\n        vertical_edge_sum_diff_ratio=abs(out_feature.vertical_edge_num - in_feature.vertical_edge_num) \/ in_feature.width,\n        horizontal_edge_sum_diff_ratio=abs(out_feature.horizontal_edge_num - in_feature.horizontal_edge_num) \/ in_feature.height,\n        diff_color_cell_ratio=util._diff_cell_count_ratio(input_arr, output_arr),\n        diff_cell_where_no_need_to_change_count_ratio=util._diff_cell_where_no_need_to_change_count_ratio(original_input_arr, input_arr, output_arr),\n        wrong_change_cell_where_need_to_change_count_ratio=util._wrong_change_cell_where_need_to_change_count_ratio(original_input_arr, input_arr, output_arr)\n    )\n\n\ndef create_task_feature(original_task: Task, task: Task) -> TaskFeature:\n    diff_features = [create_image_diff_feature(o_io.input_arr, io.input_arr, io.output_arr) for o_io, io in zip(original_task.train, task.train)]\n    return TaskFeature(\n        # image_diff_features=image_diff_features,\n        same_dim_between_input_output=all(f.same_dim() for f in diff_features),\n        same_height_dim_between_input_output=all(f.dim_height_equal for f in diff_features),\n        same_width_dim_between_input_output=all(f.dim_width_equal for f in diff_features),\n        all_dim_height_increased=all(f.dim_height_increase > 0 for f in diff_features),\n        all_dim_height_decreased=all(f.dim_height_increase < 0 for f in diff_features),\n        all_dim_width_increased=all(f.dim_width_increase > 0 for f in diff_features),\n        all_dim_width_decreased=all(f.dim_width_increase < 0 for f in diff_features),\n        all_dim_height_integer_multiple=all(f.dim_height_integer_multiple for f in diff_features),\n        all_dim_width_integer_multiple=all(f.dim_width_integer_multiple for f in diff_features),\n        mean_lack_color_num=mean([f.lack_color_num for f in diff_features]),\n        mean_excess_color_num=mean([f.excess_color_num for f in diff_features]),\n        mean_hit_and_miss_histogram_diff=mean([f.hit_and_miss_histogram_diff for f in diff_features]),\n        # mean_vertical_diff_input_arr_line_num=nan_mean(f.vertical_diff_input_arr_line_num for f in diff_features),\n        # mean_horizontal_diff_input_arr_line_num=nan_mean(f.horizontal_diff_input_arr_line_num for f in diff_features),\n        # mean_vertical_diff_output_arr_line_num=nan_mean(f.vertical_diff_output_arr_line_num for f in diff_features),\n        # mean_horizontal_diff_output_arr_line_num=nan_mean(f.horizontal_diff_output_arr_line_num for f in diff_features),\n        mean_vertical_edge_sum_diff=mean([f.vertical_edge_sum_diff for f in diff_features]),\n        mean_horizontal_edge_sum_diff=mean([f.horizontal_edge_sum_diff for f in diff_features]),\n        mean_vertical_edge_sum_diff_ratio=mean([f.vertical_edge_sum_diff_ratio for f in diff_features]),\n        mean_horizontal_edge_sum_diff_ratio=mean([f.horizontal_edge_sum_diff_ratio for f in diff_features]),\n        mean_diff_color_cell_ratio=nan_mean(f.diff_color_cell_ratio for f in diff_features),\n        mean_diff_cell_where_no_need_to_change_count_ratio=nan_mean(f.diff_cell_where_no_need_to_change_count_ratio for f in diff_features),\n        mean_wrong_change_cell_where_need_to_change_count_ratio=nan_mean(f.wrong_change_cell_where_need_to_change_count_ratio for f in diff_features),\n    )\n\n\ndef create_color_selected_task_feature(original_task: Task, color_selected_task: ColorSelectedTask, task_feature: TaskFeature = None) -> ColorSelectedTaskFeature:\n    if task_feature is None:\n        task_feature = create_task_feature(original_task, color_selected_task)\n    return ColorSelectedTaskFeature(task_feature)\n\n\ndef create_mask_conversion_task_feature(original_task: Task, mask_converted_task: MaskConvertedTask, task_feature: TaskFeature = None) -> MaskConvertedTaskFeature:\n    if task_feature is None:\n        task_feature = create_task_feature(original_task, mask_converted_task)\n    possible_improve_ratios = [_calculate_possible_improve_ratio(io.input_arr, io.output_arr, m) for io, m in zip(mask_converted_task.train, mask_converted_task.train_masks)]\n    return MaskConvertedTaskFeature(\n        task_feature=task_feature,\n        possible_improve_ratios=possible_improve_ratios,\n    )\n\n\ndef _calculate_possible_improve_ratio(input_arr: np.ndarray, output_arr: np.ndarray, mask: np.ndarray) -> Optional[float]:\n    if input_arr.shape != output_arr.shape:\n        return None\n    diff_arr = np.not_equal(input_arr, output_arr)\n    if not diff_arr.all():\n        return 1.0\n    else:\n        selected_diff_arr = np.logical_and(diff_arr, mask)\n        return 1 - selected_diff_arr.sum() \/ diff_arr.sum()\n\n\nclass FeatureUtil:\n    def _horizontal_diff_input_arr_line_num(self, input_arr: np.ndarray, output_arr: np.ndarray) -> Optional[float]:\n        if input_arr.shape[1] != output_arr.shape[1]:\n            return None\n        return abs(input_arr.shape[0] - np.array([(output_arr == h_l).all(axis=1) for h_l in input_arr]).any(axis=1).sum())\n\n    def _horizontal_diff_output_arr_line_num(self, input_arr: np.ndarray, output_arr: np.ndarray) -> Optional[float]:\n        if input_arr.shape[1] != output_arr.shape[1]:\n            return None\n        return abs(output_arr.shape[0] - np.array([(output_arr == h_l).all(axis=1) for h_l in input_arr]).any(axis=0).sum())\n\n    def _vertical_diff_input_arr_line_num(self, input_arr: np.ndarray, output_arr: np.ndarray) -> Optional[float]:\n        if input_arr.shape[0] != output_arr.shape[0]:\n            return None\n        return self._horizontal_diff_input_arr_line_num(input_arr.T, output_arr.T)\n\n    def _vertical_diff_output_arr_line_num(self, input_arr: np.ndarray, output_arr: np.ndarray) -> Optional[float]:\n        if input_arr.shape[0] != output_arr.shape[0]:\n            return None\n        return self._horizontal_diff_output_arr_line_num(input_arr.T, output_arr.T)\n\n    def _diff_cell_count_ratio(self, input_arr: np.ndarray, output_arr: np.ndarray) -> Optional[float]:\n        if input_arr.shape != output_arr.shape:\n            return None\n        diff_arr = np.not_equal(input_arr, output_arr)\n        return diff_arr.sum() \/ diff_arr.size\n\n    def _diff_cell_where_no_need_to_change_count_ratio(self, original_input_arr: np.ndarray, input_arr: np.ndarray, output_arr: np.ndarray) -> Optional[float]:\n        if not original_input_arr.shape == input_arr.shape == output_arr.shape:\n            return None\n        no_need_to_change_mask = np.equal(original_input_arr, output_arr)\n        diff_cell = np.not_equal(input_arr, output_arr)\n        diff_cell_where_no_need_to_change = diff_cell[no_need_to_change_mask]\n        return diff_cell_where_no_need_to_change.sum() \/ original_input_arr.size\n\n    def _wrong_change_cell_where_need_to_change_count_ratio(self, original_input_arr: np.ndarray, input_arr: np.ndarray, output_arr: np.ndarray) -> Optional[float]:\n        if not original_input_arr.shape == input_arr.shape == output_arr.shape:\n            return None\n        need_to_change_mask = np.not_equal(original_input_arr, output_arr)\n        change_mask = np.not_equal(original_input_arr, input_arr)\n        wrong_mask = np.not_equal(input_arr, output_arr)\n\n        wrong_change_cell_where_need_to_change_mask = need_to_change_mask & change_mask & wrong_mask\n\n        return wrong_change_cell_where_need_to_change_mask.sum() \/ original_input_arr.size\n\n\ndef get_hit_and_miss_kernels():\n    return [\n        # right top\n        np.array([\n            [0, -1, -1],\n            [1, 1, -1],\n            [0, 1, 0],\n        ], dtype=np.int8),\n        # right bottom\n        np.array([\n            [0, 1, 0],\n            [1, 1, -1],\n            [0, -1, -1],\n        ], dtype=np.int8),\n        # left bottom\n        np.array([\n            [0, 1, 0],\n            [-1, 1, 1],\n            [-1, -1, 0],\n        ], dtype=np.int8),\n        # left top\n        np.array([\n            [-1, -1, 0],\n            [-1, 1, 1],\n            [0, 1, 0],\n        ], dtype=np.int8),\n\n        # right protrusion\n        np.array([\n            [0, -1, -1],\n            [0, 1, -1],\n            [0, -1, -1],\n        ], dtype=np.int8),\n        # bottom protrusion\n        np.array([\n            [0, 0, 0],\n            [-1, 1, -1],\n            [-1, -1, -1],\n        ], dtype=np.int8),\n        # left protrusion\n        np.array([\n            [-1, -1, 0],\n            [-1, 1, 0],\n            [-1, -1, 0],\n        ], dtype=np.int8),\n        # top protrusion\n        np.array([\n            [-1, -1, -1],\n            [-1, 1, -1],\n            [0, 0, 0],\n        ], dtype=np.int8),\n        # TODO implement others?\n    ]\n\n\ndef calculate_hit_and_miss_histogram(arr: np.ndarray):\n    kernels = get_hit_and_miss_kernels()\n\n    exist_colors = np.unique(arr)\n\n    counts = []\n    for color in range(10):\n        if color not in exist_colors:\n            for k in kernels:\n                counts.append(0)\n        else:\n            for k in kernels:\n                color_hit = (arr == color).astype(np.uint8)\n                hit_and_miss_result = cv2.morphologyEx(color_hit, cv2.MORPH_HITMISS, k)\n                counts.append(int(hit_and_miss_result.sum()))\n\n    # counts = []\n    # for k in kernels:\n    #     for color in range(10):\n    #         if color not in exist_colors:\n    #             counts.append(0)\n    #         else:\n    #             color_hit = (arr == color).astype(np.uint8)\n    #             hit_and_miss_result = cv2.morphologyEx(color_hit, cv2.MORPH_HITMISS, k)\n    #             counts.append(int(hit_and_miss_result.sum()))\n\n    return counts\n\n\ndef summary_engine_results(results: List[Union[AnsweredSearchResults, NotAnsweredSearchResult]]):\n    if len(results) == 0:\n        return '0 result'\n    counts = Counter(r.final_test_correct() for r in results)\n    total_spent_time = np.sum([r.spent_time for r in results]) \/ 60\n    mean_spent_time = np.sum([r.spent_time for r in results])\n    max_spent_time = np.max([r.spent_time for r in results])\n\n    result_message = f'--- stats --- \\n' \\\n                     f'correct_count: {counts} \\n' \\\n                     f'total_spent_time: {total_spent_time} min \\n' \\\n                     f'mean_spent_time: {mean_spent_time} sec \\n' \\\n                     f'max_spent_time: {max_spent_time} sec \\n\\n'\n\n    result_message += '--- answered --- \\n'\n    result_message += '\\n'.join(r.summary() for r in results if isinstance(r, AnsweredSearchResults))\n    result_message += '\\n--- all --- \\n'\n    result_message += '\\n'.join(r.summary() for r in results)\n\n    return result_message\n\n\nclass ColorSelectionUtil:\n\n    def select_single_color(self, arr: np.ndarray, mode: SingleColorSelectionMode) -> Color:\n        if mode == SingleColorSelectionMode.MOST_COMMON:\n            color_counts = self.get_color_counts(arr)\n            if len(color_counts) <= 0:\n                raise OperationInconsistencyException('color <= 0')\n            try:\n                if color_counts[-1][1] == color_counts[-2][1]:  # Two maximums.\n                    raise OperationInconsistencyException('duplicated max color')\n            except IndexError:\n                pass\n            return Color.of(color_counts[-1][0])\n\n        elif mode == SingleColorSelectionMode.SECOND_MOST_COMMON:\n            color_counts = self.get_color_counts(arr)\n            if len(color_counts) <= 1:\n                raise OperationInconsistencyException('color <= 1')\n            if color_counts[-1][1] == color_counts[-2][1]:  # Two maximums.\n                raise OperationInconsistencyException('duplicated max color')\n            try:\n                if color_counts[-2][1] == color_counts[-3][1]:  # Two 2nd maximums.\n                    raise OperationInconsistencyException('duplicated 2nd max color')\n            except IndexError:\n                pass\n            return Color.of(color_counts[-2][0])\n        elif mode == SingleColorSelectionMode.LEAST_COMMON:\n            color_counts = self.get_color_counts(arr)\n            if len(color_counts) <= 1:\n                raise OperationInconsistencyException('color <= 1')\n            if color_counts[0][1] == color_counts[1][1]:  # Two minimum.\n                raise OperationInconsistencyException('duplicated 2nd max color')\n\n            return Color.of(color_counts[0][0])\n        else:\n            raise NotImplementedError()\n\n    def get_background_color(self, arr: np.ndarray, mode: BackGroundColorSelectionMode) -> Color:\n        if mode == BackGroundColorSelectionMode.BLACK:\n            return Color.BLACK\n        elif mode == BackGroundColorSelectionMode.MOST_COMMON:\n            return self.select_single_color(arr, SingleColorSelectionMode.MOST_COMMON)\n        else:\n            raise NotImplementedError()\n\n    def get_color_counts(self, arr: np.ndarray) -> List[Tuple[int, int]]:\n        color_counts = [(color, count) for color, count in enumerate(np.bincount(arr.ravel(), minlength=10)) if count != 0]\n        return sorted(color_counts, key=itemgetter(1))\n\n    def get_colors(self, arr: np.ndarray) -> List[Color]:\n        return sorted(set(arr.ravel().tolist()))\n\n    def select_multi_color(self):\n        # TODO imple\n        raise\n\n\n@dataclass(frozen=True)\nclass SplitLineSelection(MaskConversion):\n    axis: Axis\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        result_mask = np.full_like(color_mask, fill_value=False)\n        if self.axis in [Axis.VERTICAL, Axis.BOTH]:\n            vertical_line_hits = color_mask.all(axis=0)\n            result_mask[:, vertical_line_hits] = True\n\n        if self.axis in [Axis.HORIZONTAL, Axis.BOTH]:\n            horizontal_line_hits = color_mask.all(axis=1)\n            result_mask[horizontal_line_hits] = True\n\n        return result_mask\n\n\n@dataclass(frozen=True)\nclass DotExistLineSelection(MaskConversion):\n    axis: Axis\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        result_mask = np.full_like(color_mask, fill_value=False)\n        if self.axis in [Axis.VERTICAL, Axis.BOTH]:\n            vertical_line_hits = color_mask.any(axis=0)\n            result_mask[:, vertical_line_hits] = True\n\n        if self.axis in [Axis.HORIZONTAL, Axis.BOTH]:\n            horizontal_line_hits = color_mask.any(axis=1)\n            result_mask[horizontal_line_hits] = True\n\n        return result_mask\n\n\n@dataclass(frozen=True)\nclass ObjectsTouchingEdgeSelection(MaskConversion):\n    # TODO Direction or Axis property?\n    true_or_false: TrueOrFalse\n    connectivity: PixelConnectivity\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        label_array, max_label_index = label(color_mask, connectivity=self.connectivity.value_for_skimage,\n                                             background=False, return_num=True)\n\n        if max_label_index == 0:\n            return np.full_like(color_mask, order='C', fill_value=False)\n\n        target_indices = [i for i in range(1, max_label_index + 1) if self._is_target(label_array == i)]\n\n        return np.isin(label_array, target_indices)\n\n    def _is_target(self, arr: np.ndarray) -> bool:\n        top_line = arr[0]\n        bottom_line = arr[-1]\n        left_line = arr[:, 0]\n        right_line = arr[:, -1]\n\n        if self.true_or_false == TrueOrFalse.TRUE:\n            return any([top_line.any(), bottom_line.any(), left_line.any(), right_line.any()])\n        else:\n            return not any([top_line.any(), bottom_line.any(), left_line.any(), right_line.any()])\n\n\n@dataclass(frozen=True)\nclass ObjectsMaxMinSelection(MaskConversion):\n    \"\"\" Create a mask with max\/min feature objects \"\"\"\n    true_or_false: TrueOrFalse\n    max_or_min: MaxOrMin\n    object_feature: ObjectFeature\n    connectivity: PixelConnectivity\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        label_array, max_label_index = label(color_mask, connectivity=self.connectivity.value_for_skimage,\n                                             background=False, return_num=True)\n\n        if max_label_index == 0:\n            return np.full_like(color_mask, order='C', fill_value=False)\n\n        label_indices = list(range(1, max_label_index + 1))\n        label_index_feature_value_pairs = list(map(lambda l: (l, self._calculate_object_feature(label_array, l)), label_indices))\n\n        target_feature_value = self.max_or_min.func(label_index_feature_value_pairs, key=itemgetter(1))[1]\n        if self.true_or_false == TrueOrFalse.TRUE:\n            target_indices = [l_i for l_i, f in label_index_feature_value_pairs if f == target_feature_value]\n        else:\n            target_indices = [l_i for l_i, f in label_index_feature_value_pairs if f != target_feature_value]\n\n        return np.isin(label_array, target_indices)\n\n    def _calculate_object_feature(self, label_array: np.ndarray, label_index: int) -> int:\n        if self.object_feature == ObjectFeature.AREA:\n            return self._label_array_to_area(label_array, label_index)\n        if self.object_feature == ObjectFeature.HORIZONTAL_LEN:\n            return self._label_array_to_horizontal_len(label_array, label_index)\n        if self.object_feature == ObjectFeature.VERTICAL_LEN:\n            return self._label_array_to_vertical_len(label_array, label_index)\n        else:\n            raise NotImplementedError()\n\n    def _label_array_to_area(self, label_array: np.ndarray, label_index: int) -> int:\n        label_hit = label_array == label_index\n        return label_hit.sum()\n\n    def _label_array_to_horizontal_len(self, label_array: np.ndarray, label_index: int) -> int:\n        label_hit = label_array == label_index\n        horizontal_label_hit = label_hit.any(axis=0)\n        coords = np.where(horizontal_label_hit)[0]\n        return max(coords) - min(coords)\n\n    def _label_array_to_vertical_len(self, label_array: np.ndarray, label_index: int) -> int:\n        label_hit = label_array == label_index\n        vertical_label_hit = label_hit.any(axis=1)\n        coords = np.where(vertical_label_hit)[0]\n        return max(coords) - min(coords)\n\n\n@dataclass(frozen=True)\nclass OldObjectsMaxMinSelection(MaskConversion):\n    # similar to ObjectsMaxMinSelection\n    # TODO Without this function, LB will be 0.97 -> 0.98\n    # TODO why???\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        # TODO should variate hierarchy?\n        contours, hierarchy = cv2.findContours(np.ascontiguousarray(color_mask).astype(np.uint8),\n                                               cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        if len(contours) == 0:\n            return np.full_like(color_mask, order='C', fill_value=False)\n\n        max_area_contour = max(contours, key=lambda c: cv2.contourArea(c))\n\n        mask = np.full_like(color_mask, order='C', fill_value=False)\n\n        mask = cv2.drawContours(mask.astype(np.uint8), max_area_contour, contourIdx=-1, color=1)\n        if isinstance(mask, cv2.UMat):  # mask sometimes becomes cv2.UMat class... I don't know why.\n            mask = mask.get()\n\n        return mask.astype(bool)\n\n\n@dataclass(frozen=True)\nclass SquareObjectsSelection(MaskConversion):\n    \"\"\" Create a mask with only square objects \"\"\"\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        color_mask = color_mask.astype(np.uint8)\n        max_square_len = min(color_mask.shape)\n        # TODO\n        # if max_square_len == 1:\n        #     return arr\n\n        square_hit = np.full_like(color_mask, fill_value=False, dtype=bool)\n        for l in range(1, max_square_len):\n            hit_and_miss_kernel = self._square_hit_and_miss_kenel(l)\n            filter_kernel = self._filter_kenel(l)\n            temp_square_hit = cv2.morphologyEx(color_mask, cv2.MORPH_HITMISS, hit_and_miss_kernel, anchor=(1, 1))\n            temp_square_hit = cv2.filter2D(temp_square_hit, -1, filter_kernel, anchor=(l - 1, l - 1), borderType=cv2.BORDER_CONSTANT)\n\n            square_hit = np.logical_or(square_hit, temp_square_hit.astype(bool))\n\n        return square_hit\n\n    def _square_hit_and_miss_kenel(self, l: int) -> np.ndarray:\n        kernel = np.full((l + 2, l + 2), fill_value=1, dtype=np.int8)\n        kernel[0, :] = -1\n        kernel[-1, :] = -1\n        kernel[:, 0] = -1\n        kernel[:, -1] = -1\n        return kernel\n\n    def _filter_kenel(self, l: int) -> np.ndarray:\n        return np.full((l, l), fill_value=1, dtype=np.int8)\n\n\n@dataclass(frozen=True)\nclass HolesSelection(MaskConversion):\n    \"\"\" Select only the empty hole inside. \"\"\"\n\n    connectivity: PixelConnectivity\n\n    # TODO Lack of consideration of the edges of the image?\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        filled = binary_fill_holes(color_mask, structure=self.connectivity.structure_for_skimage)\n        return filled ^ color_mask\n\n\n@dataclass(frozen=True)\nclass ObjectInnerSelection(MaskConversion):\n    connectivity: PixelConnectivity\n    image_edge_type: ImageEdgeType\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        if self.image_edge_type == ImageEdgeType.EDGE_EXCLUDE:\n            border_value = 0\n        elif self.image_edge_type == ImageEdgeType.EDGE_INCLUDE:\n            border_value = 1\n        else:\n            raise NotImplementedError()\n\n        return binary_erosion(color_mask, structure=self.connectivity.structure_for_skimage, border_value=border_value)\n\n\n@dataclass(frozen=True)\nclass ContourSelection(MaskConversion):\n    \"\"\" Create a contour mask \"\"\"\n\n    connectivity: PixelConnectivity\n    image_edge_type: ImageEdgeType\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        inner_mask = ObjectInnerSelection(self.connectivity, self.image_edge_type)(color_mask)\n        return np.logical_xor(inner_mask, color_mask)\n\n\n@dataclass(frozen=True)\nclass ContourOuterSelection(MaskConversion):\n    \"\"\" Create a mask one pixel outside the contour \"\"\"\n\n    connectivity: PixelConnectivity\n    hole_include: HoleInclude\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        if self.hole_include == HoleInclude.INCLUDE:\n            dilated = binary_dilation(color_mask, structure=self.connectivity.structure_for_skimage, border_value=0)\n            return np.logical_xor(dilated, color_mask)\n        elif self.hole_include == HoleInclude.EXCLUDE:\n            dilated = binary_dilation(color_mask, structure=self.connectivity.structure_for_skimage, border_value=0)\n            holes = HolesSelection(self.connectivity)(color_mask)\n            return np.logical_and(np.logical_xor(dilated, color_mask), ~holes)\n        else:\n            raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass ConnectDotSelection(MaskConversion):\n    # TODO This function spends much time.\n    axis: Axis\n    edge_type: LineEdgeType\n    fill_type: FillType\n\n    def __call__(self, color_mask: np.ndarray) -> np.ndarray:\n        result_mask = np.full_like(color_mask, fill_value=False)\n        coords = np.argwhere(color_mask)\n        if self.axis in [Axis.HORIZONTAL, Axis.BOTH]:\n\n            # Calculate the min and max coordinates of the horizontal\n            horizontal_group = {k: itemgetter(0, -1)(tuple(map(itemgetter(1), g))) for k, g in groupby(coords, key=itemgetter(0))}\n\n            # filter\n            horizontal_group = {k: (v[0], v[1]) for k, v in horizontal_group.items() if (v[1] - v[0]) >= 2}\n\n            # mask\u3092\u8a08\u7b97\n            for y, (x_min, x_max) in horizontal_group.items():\n                if self.edge_type == LineEdgeType.EdgeInclude:\n                    pass\n                elif self.edge_type == LineEdgeType.EdgeExclude:\n                    x_min += 1\n                    x_max -= 1\n                else:\n                    raise NotImplementedError()\n\n                result_mask[y, x_min:x_max + 1] = True\n\n        if self.axis in [Axis.VERTICAL, Axis.BOTH]:\n\n            # Calculate the min and max coordinates of the vertical\n            vertical_group = {k: itemgetter(0, -1)(tuple(map(itemgetter(0), g))) for k, g in groupby(sorted(coords, key=itemgetter(1)), key=itemgetter(1))}\n\n            # calculate mask\n            vertical_group = {k: (v[0], v[1]) for k, v in vertical_group.items() if (v[1] - v[0]) >= 2}\n\n            # generate mask\n            for x, (y_min, y_max) in vertical_group.items():\n                if self.edge_type == LineEdgeType.EdgeInclude:\n                    pass\n                elif self.edge_type == LineEdgeType.EdgeExclude:\n                    y_min += 1\n                    y_max -= 1\n                else:\n                    raise NotImplementedError()\n\n                result_mask[y_min:y_max + 1, x] = True\n\n        if self.fill_type == FillType.NotOverride:\n            result_mask = np.logical_xor(result_mask, color_mask)\n        return result_mask\n\n\nclass TaskOperationSetExecutor:\n\n    def execute(self, task: Task, operation_set: OperationSet) -> Task:\n        arrays = OperationSetExecutor.apply_operation_set([io.input_arr for io in task.train + task.test], operation_set)\n\n        return Task(task.name,\n                    tuple([InputOutput(a, io.output_arr) for a, io in zip(arrays[:len(task.train)], task.train)]),\n                    tuple([InputOutput(a, io.output_arr) for a, io in zip(arrays[len(task.train):], task.test)]))\n\n\nclass ColorSelectionExecutor:\n\n    @staticmethod\n    def execute(task: Task, color_selection: ColorSelection) -> ColorSelectedTask:\n        masks = OperationSetExecutor.apply_color_selection([io.input_arr for io in task.train + task.test], color_selection)\n\n        return ColorSelectedTask(task.name, task.train, task.test, masks[:len(task.train)], masks[len(task.train):])\n\n\nclass MaskConversionExecutor:\n\n    @staticmethod\n    def execute(task: ColorSelectedTask, mask_conversion: MaskConversion) -> MaskConvertedTask:\n        masks = OperationSetExecutor.apply_mask_conversion(task.train_masks + task.test_masks, mask_conversion)\n\n        return MaskConvertedTask(task.name, task.train, task.test, masks[:len(task.train_masks)], masks[len(task.train_masks):])\n\n\nclass MaskOperationExecutor:\n\n    @staticmethod\n    def execute(task: MaskConvertedTask, mask_operation: MaskOperation) -> Task:\n        new_arrays = OperationSetExecutor.apply_mask_operation(\n            [io.input_arr for io in task.train + task.test], task.train_masks + task.test_masks, mask_operation)\n        train_io = tuple([InputOutput(n, io.output_arr) for n, io, in zip(new_arrays[:len(task.train)], task.train)])\n        test_io = tuple([InputOutput(n, io.output_arr) for n, io, in zip(new_arrays[len(task.train):], task.train)])\n\n        return Task(task.name, train_io, test_io)\n\n\nclass ColorChannelSelectionExecutor:\n\n    @staticmethod\n    def execute(task: Task, color_channel_selection: ColorChannelSelection) -> ColorChannelSelectedTask:\n        color_mask_pairs_list = OperationSetExecutor.apply_channel_selection([io.input_arr for io in task.train + task.test], color_channel_selection)\n\n        return ColorChannelSelectedTask(task.name, task.train, task.test,\n                                        color_mask_pairs_list[:len(task.train)],\n                                        color_mask_pairs_list[len(task.train):])\n\n\nclass ColorChannelMaskConversionSelectionExecutor:\n\n    @staticmethod\n    def execute(task: ColorChannelSelectedTask, mask_conversion: MaskConversion) -> ColorChannelMaskConvertedTask:\n        color_mask_pairs_list = OperationSetExecutor.apply_color_channel_mask_conversion(\n            task.train_color_mask_pairs + task.test_color_mask_pairs, mask_conversion)\n\n        return ColorChannelMaskConvertedTask(task.name, task.train, task.test,\n                                             task.train_color_mask_pairs,\n                                             color_mask_pairs_list[:len(task.train_color_mask_pairs)],\n                                             task.test_color_mask_pairs,\n                                             color_mask_pairs_list[len(task.train_color_mask_pairs):])\n\n\nclass ColorChannelMergeExecutor:\n\n    @staticmethod\n    def execute(task: ColorChannelMaskConvertedTask, merge_operation: ChannelMergeOperation) -> Task:\n        new_arrays = OperationSetExecutor.apply_channel_merge([io.input_arr for io in task.train + task.test],\n                                                              task.train_original_color_mask_pairs + task.test_original_color_mask_pairs,\n                                                              task.train_color_mask_pairs + task.test_color_mask_pairs,\n                                                              merge_operation)\n\n        train_io = tuple([InputOutput(n, io.output_arr) for n, io, in zip(new_arrays[:len(task.train)], task.train)])\n        test_io = tuple([InputOutput(n, io.output_arr) for n, io, in zip(new_arrays[len(task.train):], task.train)])\n\n        return Task(task.name, train_io, test_io)\n\n\nclass PartitionSelectionExecutor:\n\n    @staticmethod\n    def execute(task: Task, partition_selection: PartitionSelection) -> PartitionSelectionTask:\n        array_mask_list = OperationSetExecutor.apply_partition_selection([io.input_arr for io in task.train + task.test], partition_selection)\n\n        return PartitionSelectionTask(task.name, task.train, task.test, array_mask_list[:len(task.train)], array_mask_list[len(task.train):])\n\n\nclass PartitionMergeExecutor:\n\n    @staticmethod\n    def execute(task: PartitionSelectionTask, partition_merge_operation: PartitionMergeOperation) -> Task:\n        new_arrays = OperationSetExecutor.apply_partition_merge_operation([io.input_arr for io in task.train + task.test],\n                                                                          task.train_partitioned_arrays_original_location_masks + task.test_partitioned_arrays_original_location_masks,\n                                                                          partition_merge_operation)\n\n        train_io = tuple([InputOutput(n, io.output_arr) for n, io, in zip(new_arrays[:len(task.train)], task.train)])\n        test_io = tuple([InputOutput(n, io.output_arr) for n, io, in zip(new_arrays[len(task.train):], task.train)])\n\n        return Task(task.name, train_io, test_io)\n\n\nclass CompletedNodeProcessor:\n\n    @staticmethod\n    def process(node: CompletedNode) -> List[WaitingNode]:\n        mapping = {\n            UniformOperationCompletedNode: OperationCompletedNodeProcessor,\n            ColorSelectionCompletedNode: ColorSelectionCompletedNodeProcessor,\n            MaskConversionCompletedNode: MaskConversionCompletedNodeProcessor,\n            ColorChannelSelectionCompletedNode: ColorChannelSelectionCompletedNodeProcessor,\n            ColorChannelMaskConversionCompletedNode: ColorChannelMaskConversionCompletedNodeProcessor,\n            PartitionSelectionCompletedNode: PartitionSelectionCompletedNodeProcessor,\n        }\n\n        processor = mapping[node.__class__]\n        return processor.process(node)\n\n\nclass OperationCompletedNodeProcessor:\n\n    @classmethod\n    def process(cls, node: UniformOperationCompletedNode) -> List[Union[UniformOperationWaitingNode, ColorSelectionWaitingNode, ColorChannelSelectionOperationWaitingNode]]:\n        res = [\n            *[UniformOperationWaitingNode(node, node.original_task, node.task, node.task_feature, node.base_operation_set, new_operation)\n              for new_operation in cls._candidate_operations(node.task, node.task_feature)],\n            *[ColorSelectionWaitingNode(node, node.original_task, node.task, node.task_feature, node.base_operation_set, color_selection)\n              for color_selection in cls._candidate_color_selections(node.task)],\n            *[ColorChannelSelectionOperationWaitingNode(node, node.original_task, node.task, node.task_feature, node.base_operation_set, color_channel_selection)\n              for color_channel_selection in cls._candidate_color_channel_selection(node.task)],\n        ]\n\n        # first operation only\n        if len(node.base_operation_set.operations) == 0:\n            res.extend([PartitionSelectionWaitingNode(node, node.original_task, node.task, node.task_feature, node.base_operation_set, partition_selection)\n                        for partition_selection in cls._candidate_partition_selection(node.task)])\n\n        return res\n\n    @staticmethod\n    def _candidate_operations(task: Task, task_feature: TaskFeature):\n        input_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(task.get_input_all_arr())))))\n\n        candidates = []\n\n        if task_feature.all_dim_height_increased:\n            candidates += [Resize(Axis.VERTICAL, r) for r in range(2, 5)]\n            candidates += [Padding(m, d, k) for m, d, k in product(PaddingMode, [Direction.TOP, Direction.BOTTOM], range(1, 4))]\n\n        if task_feature.all_dim_width_increased:\n            candidates += [Resize(Axis.HORIZONTAL, r) for r in range(2, 5)]\n            candidates += [Padding(m, d, k) for m, d, k in product(PaddingMode, [Direction.LEFT, Direction.RIGHT], range(1, 4))]\n\n        if task_feature.all_dim_height_decreased or task_feature.all_dim_width_decreased:\n            candidates += [LineDeletion(c) for c in input_colors]\n\n        candidates += [\n            *[Flip(m) for m in FlipMode],\n            *[Rotate(a) for a in [90, 180, 270]],\n        ]\n\n        return candidates\n\n    @staticmethod\n    def _candidate_color_selections(task: Task) -> List[ColorSelection]:\n        input_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(task.get_input_all_arr())))))\n        return [\n            *[FixedSingleColorSelection(c) for c in input_colors],\n            *[SingleColorSelection(m) for m in SingleColorSelectionMode],\n            *[MultiColorSelection(m) for m in MultiColorSelectionMode],\n        ]\n\n    @staticmethod\n    def _candidate_color_channel_selection(task: Task) -> List[ColorChannelSelection]:\n        return [\n            *[WithOutMostCommonColorChannelSelection(m) for m in BackGroundColorSelectionMode]\n        ]\n\n    @staticmethod\n    def _candidate_partition_selection(task: Task) -> List[PartitionSelection]:\n        input_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(task.get_input_all_arr())))))\n\n        return [\n            *[ColorNumIntegerDivisionPartition(axis=a) for a in Axis],\n            *[IntegerDivisionPartition(axis=a, n_split=n) for a, n in product(Axis, range(2, 5))],\n            *[GeneralizedLinePartition(m) for m in BackGroundColorSelectionMode],\n            *[LinePartition(line_color=c) for c in input_colors],\n        ]\n\n\nclass ColorSelectionCompletedNodeProcessor:\n\n    @classmethod\n    def process(cls, node: ColorSelectionCompletedNode) -> List[MaskConversionWaitingNode]:\n        return [MaskConversionWaitingNode(node, node.original_task, node.color_selected_task, node.color_selected_task_feature,\n                                          node.base_operation_set, node.color_selection, mask_conversion)\n                for mask_conversion in cls._candidate_mask_conversions()]\n\n    @staticmethod\n    def _candidate_mask_conversions() -> List[MaskConversion]:\n        return [\n            NoMaskConversion(),\n            SquareObjectsSelection(),\n            *[ObjectsTouchingEdgeSelection(tf, c) for tf, c in product(TrueOrFalse, PixelConnectivity)],\n            *[ObjectsMaxMinSelection(tf, m, t, c) for tf, m, t, c in product(TrueOrFalse, MaxOrMin, ObjectFeature, PixelConnectivity)],\n            OldObjectsMaxMinSelection(),\n            *[SplitLineSelection(a) for a in Axis],\n            *[DotExistLineSelection(a) for a in Axis],\n            *[HolesSelection(c) for c in PixelConnectivity],\n            *[ObjectInnerSelection(c, e) for c, e in product(PixelConnectivity, ImageEdgeType)],\n            *[ContourSelection(c, e) for c, e in product(PixelConnectivity, ImageEdgeType)],\n            *[ContourOuterSelection(c, h) for c, h in product(PixelConnectivity, HoleInclude)],\n            *[ConnectDotSelection(a, e, f) for a, e, f in product(Axis, LineEdgeType, FillType)],\n        ]\n\n\nclass MaskConversionCompletedNodeProcessor:\n\n    @classmethod\n    def process(cls, node: MaskConversionCompletedNode) -> List[MaskOperationSelectionWaitingNode]:\n        return [MaskOperationSelectionWaitingNode(node, node.original_task, node.mask_converted_task, node.mask_converted_task_feature,\n                                                  node.base_operation_set, node.color_selection, node.mask_conversion, mask_operation)\n                for mask_operation in cls._candidate(node)]\n\n    @staticmethod\n    def _candidate(node: MaskConversionCompletedNode) -> List[MaskOperation]:\n        # TODO use\n        # color_mappings = set(chain.from_iterable(t.candidate_color_mapping() for t in task.train))\n\n        output_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(node.mask_converted_task.get_output_all_arr())))))\n\n        candidates = []\n\n        if not node.mask_converted_task_feature.task_feature.same_dim_between_input_output:\n            candidates += [MaskCoordsCrop()]\n\n        candidates += [\n            *[FixedColorMaskFill(c) for c in output_colors],\n            *[SingleColorMaskFill(m) for m in SingleColorSelectionMode],\n        ]\n\n        return candidates\n\n\nclass ColorChannelSelectionCompletedNodeProcessor:\n\n    @classmethod\n    def process(cls, node: ColorChannelSelectionCompletedNode) -> List[ColorChannelMaskConversionWaitingNode]:\n        return [ColorChannelMaskConversionWaitingNode(node, node.original_task, node.task, node.feature,\n                                                      node.base_operation_set, node.color_channel_selection, mask_conversion)\n                for mask_conversion in cls._candidate_mask_conversions()]\n\n    @staticmethod\n    def _candidate_mask_conversions() -> List[MaskConversion]:\n        return [\n            NoMaskConversion(),\n            SquareObjectsSelection(),\n            *[ObjectsTouchingEdgeSelection(tf, c) for tf, c in product(TrueOrFalse, PixelConnectivity)],\n            *[ObjectsMaxMinSelection(tf, m, t, c) for tf, m, t, c in product(TrueOrFalse, MaxOrMin, ObjectFeature, PixelConnectivity)],\n            OldObjectsMaxMinSelection(),\n            *[SplitLineSelection(a) for a in Axis],\n            *[DotExistLineSelection(a) for a in Axis],\n            *[HolesSelection(c) for c in PixelConnectivity],\n            *[ObjectInnerSelection(c, e) for c, e in product(PixelConnectivity, ImageEdgeType)],\n            *[ContourSelection(c, e) for c, e in product(PixelConnectivity, ImageEdgeType)],\n            *[ContourOuterSelection(c, h) for c, h in product(PixelConnectivity, HoleInclude)],\n            *[ConnectDotSelection(a, e, f) for a, e, f in product(Axis, LineEdgeType, FillType)],\n        ]\n\n\nclass ColorChannelMaskConversionCompletedNodeProcessor:\n\n    @classmethod\n    def process(cls, node: ColorChannelMaskConversionCompletedNode) -> List[ColorChannelMergeWaitingNode]:\n        return [ColorChannelMergeWaitingNode(node, node.original_task, node.task, node.feature,\n                                             node.base_operation_set, node.color_selection, node.mask_conversion, merge_operation)\n                for merge_operation in cls._candidate()]\n\n    @staticmethod\n    def _candidate() -> List[ChannelMergeOperation]:\n        return [ColorChannelOverrideOperation()]\n\n\nclass PartitionSelectionCompletedNodeProcessor:\n\n    @classmethod\n    def process(cls, node: PartitionSelectionCompletedNode) -> List[PartitionMergeWaitingNode]:\n        return [PartitionMergeWaitingNode(node, node.original_task, node.task, node.feature,\n                                          node.base_operation_set, node.partition_selection, c) for c in cls._candidate(node)]\n\n    @staticmethod\n    def _candidate(node: PartitionSelectionCompletedNode) -> List[PartitionMergeOperation]:\n        output_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(node.task.get_output_all_arr())))))\n\n        selections = [\n            *[UniqueColorNumberSelection(m) for m in MaxOrMin],\n            *[ColoredCellNumberSelection(m, bg) for m, bg in product(MaxOrMin, BackGroundColorSelectionMode)],\n            *[SameShapeNumSelection(m) for m in MaxOrMin],\n            *[SymmetrySelection(a, tf) for a, tf in product(AxisV2, TrueOrFalse)],\n        ]\n\n        return [\n            *[AnySelectionMerge(m, c) for m, c in product(BackGroundColorSelectionMode, output_colors)],\n            *[NotSelectionMerge(m, c) for m, c in product(BackGroundColorSelectionMode, output_colors)],\n            *[AllSelectionMerge(m, c) for m, c in product(BackGroundColorSelectionMode, output_colors)],\n            *[ModifiedXorSelectionMerge(m, c) for m, c in product(BackGroundColorSelectionMode, output_colors)],\n            *[NaturalArrayOrderedOverrideMerge(m, c, a) for m, c, a in product(BackGroundColorSelectionMode, Corner, [Axis.VERTICAL, Axis.HORIZONTAL])],\n            *[DiagonalArrayOrderedOverrideMerge(m, c, a) for m, c, a in product(BackGroundColorSelectionMode, Corner, [Axis.VERTICAL, Axis.HORIZONTAL])],\n            *[SpiralArrayOrderedOverrideMerge(m, c, d) for m, c, d in product(BackGroundColorSelectionMode, Corner, SpiralDirection)],\n            *[UniquelySelectedArrayExtraction(s) for s in selections],\n            *[RestoreOnlySelectedArray(m, s) for m, s in product(BackGroundColorSelectionMode, selections)],\n            ExtractOneValueFromPartitionedArray(),\n        ]\n\n\nclass AnswerMatcher:\n\n    @staticmethod\n    def is_match_arr(arr1: np.ndarray, arr2: np.ndarray) -> bool:\n        return np.array_equal(arr1, arr2)\n\n    @classmethod\n    def is_train_all_match_if_operated(cls, task: Task, operation_set: OperationSet) -> bool:\n        try:\n            applied_task = TaskOperationSetExecutor().execute(task, operation_set)\n            return all(cls.is_match_arr(io.input_arr, io.output_arr) for io in applied_task.train)\n        except OperationInconsistencyException:\n            return False\n\n    @classmethod\n    def is_train_test_all_match_if_operated(cls, task: Task, operation_set: OperationSet) -> bool:\n        try:\n            applied_task = TaskOperationSetExecutor().execute(task, operation_set)\n            return all(cls.is_match_arr(io.input_arr, io.output_arr) for io in applied_task.train + applied_task.test)\n        except OperationInconsistencyException:\n            return False\n\n    # TODO \uff1f\n    @classmethod\n    def is_train_all_match(cls, task: Task) -> bool:\n        return all(map(lambda io: cls.is_match_arr(io.input_arr, io.output_arr), task.train))\n\n\ndef setup_df_display_options():\n    np.set_printoptions(threshold=10000)\n    np.set_printoptions(linewidth=10000)\n    pd.set_option('display.max_columns', 1000)\n    pd.set_option('display.max_rows', 1000)\n    pd.set_option('display.width', 800)\n    pd.set_option('display.max_colwidth', 300)\n\n\ndef mean(values: List[float]) -> float:\n    return sum(values) \/ len(values)\n\n\ndef nan_mean(val_iter: Iterable[Union[int, float]]) -> Optional[float]:\n    nan_filtered = [v for v in val_iter if v is not None]\n    if not nan_filtered:\n        return None\n    return mean(nan_filtered)\n\n\ndef initialize_path():\n    if RunConfig.RUN_MODE in [RunMode.LOCAL_RUN_ALL, RunMode.LOCAL_RUN]:\n        shutil.rmtree(PathConfig.WRONG_ANSWERS_ROOT, ignore_errors=True)\n        PathConfig.OUTPUT_SUBMISSION.unlink() if PathConfig.OUTPUT_SUBMISSION.exists() else None\n\n\n@dataclass\nclass HandMadeNodeEvaluator(NodeEvaluator):\n    pattern: DepthSearchPattern\n    operation_element_prob_dict: Dict[str, float]\n    node_search_engine_param: NodeBaseSearchEngineParameter\n    dist_eval_param: DistanceEvaluatorParameter\n\n    def __post_init__(self):\n        self.class_mapping = {\n            UniformOperationWaitingNode: OperationWaitingNodeEvaluator(self.operation_element_prob_dict),\n            ColorSelectionWaitingNode: ColorSelectionWaitingNodeEvaluator(self.operation_element_prob_dict),\n            MaskConversionWaitingNode: MaskConversionWaitingNodeEvaluator(self.operation_element_prob_dict),\n            MaskOperationSelectionWaitingNode: MaskOperationSelectionWaitingNodeEvaluator(self.operation_element_prob_dict),\n            ColorChannelSelectionOperationWaitingNode: ColorChannelSelectionOperationWaitingNodeEvaluator(self.operation_element_prob_dict),\n            ColorChannelMaskConversionWaitingNode: ColorChannelMaskConversionWaitingNodeEvaluator(self.operation_element_prob_dict),\n            ColorChannelMergeWaitingNode: ColorChannelMergeWaitingNodeEvaluator(self.operation_element_prob_dict),\n            PartitionSelectionWaitingNode: PartitionSelectionWaitingNodeEvaluator(self.operation_element_prob_dict),\n            PartitionMergeWaitingNode: PartitionMergeWaitingNodeEvaluator(self.operation_element_prob_dict),\n        }\n\n        self.dist_evaluator = DistanceEvaluator(self.dist_eval_param)\n\n    def evaluate_nodes(self, nodes: List[WaitingNode]):\n        for n in nodes:\n            self.evaluate(n)\n\n    def evaluate(self, node: WaitingNode):\n        evaluator = self.class_mapping[node.__class__]\n        task_feature = evaluator.get_task_feature(node)\n        base_distance = self.dist_evaluator.evaluate_task_feature(task_feature)\n        element_including_prob = evaluator.get_element_inclusion_prob(node)\n        node.cache_pred_distance = self.calculate_final_distance(base_distance, element_including_prob, node.depth())\n\n    def evaluate_base_distance_for_completed_node(self, node: CompletedNode):\n        return self.dist_evaluator.evaluate_task_feature(node.task_feature)\n\n    def calculate_final_distance(self, base_distance: float, element_inclusion_prob: float, depth: int) -> float:\n        prob_cost = self.node_search_engine_param.element_inclusion_prob_factor * (1 - element_inclusion_prob)\n        if self.pattern == DepthSearchPattern.BREADTH_FIRST:\n            return base_distance ** (1 + depth * self.node_search_engine_param.breadth_first_exp_cost) + prob_cost + self.node_search_engine_param.breadth_first_cost * depth\n        elif self.pattern == DepthSearchPattern.NORMAL:\n            return base_distance ** (1 + depth * self.node_search_engine_param.normal_exp_cost) + prob_cost + self.node_search_engine_param.normal_first_cost * depth\n        elif self.pattern == DepthSearchPattern.DEPTH_FIRST:\n            return base_distance ** (1 + depth * self.node_search_engine_param.depth_first_exp_cost) + prob_cost + self.node_search_engine_param.depth_first_cost * depth\n        else:\n            raise NotImplementedError()\n\n\n@dataclass\nclass HandmadeNodeEvaluatorBase:\n    operation_element_prob_dict: Dict[str, float]\n\n    def get_task_feature(self, node) -> TaskFeature:\n        raise NotImplementedError()\n\n    def get_element_inclusion_prob(self, node) -> float:\n        raise NotImplementedError()\n\n    def calculate_dist_factor(self, node) -> float:\n        raise NotImplementedError()\n\n\nclass OperationWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, operation_waiting_node: UniformOperationWaitingNode) -> TaskFeature:\n        return operation_waiting_node.task_feature\n\n    def get_element_inclusion_prob(self, operation_waiting_node: UniformOperationWaitingNode) -> float:\n        return self.operation_element_prob_dict[operation_waiting_node.next_operation.__class__.__name__]\n\n    def calculate_dist_factor(self, operation_waiting_node: UniformOperationWaitingNode) -> float:\n        # TODO use height_integer_multiple?\n        operation = operation_waiting_node.next_operation\n        if isinstance(operation, (Flip, Rotate)):\n            if operation_waiting_node.task_feature.same_dim_between_input_output:\n                dist_factor = 0.8\n            else:\n                dist_factor = 1.2\n        elif isinstance(operation, (Resize, Padding)):\n            if operation_waiting_node.task_feature.same_dim_between_input_output:\n                dist_factor = 1.2\n            else:\n                dist_factor = 0.8\n        else:\n            raise NotImplementedError(operation)\n        return dist_factor\n\n\nclass ColorSelectionWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, color_selection_waiting_node: ColorSelectionWaitingNode) -> TaskFeature:\n        return color_selection_waiting_node.task_feature\n\n    def get_element_inclusion_prob(self, color_selection_waiting_node: ColorSelectionWaitingNode) -> float:\n        return self.operation_element_prob_dict[color_selection_waiting_node.next_selection.__class__.__name__]\n\n    def calculate_dist_factor(self, color_selection_waiting_node: ColorSelectionWaitingNode) -> float:\n        return 1.0\n\n\nclass MaskConversionWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, mask_conversion_waiting_node: MaskConversionWaitingNode) -> TaskFeature:\n        return mask_conversion_waiting_node.color_selected_task_feature.task_feature\n\n    def get_element_inclusion_prob(self, mask_conversion_waiting_node: MaskConversionWaitingNode) -> float:\n        return self.operation_element_prob_dict[mask_conversion_waiting_node.next_mask_conversion.__class__.__name__]\n\n    def calculate_dist_factor(self, mask_conversion_waiting_node: MaskConversionWaitingNode) -> float:\n        return 1.0\n\n\nclass MaskOperationSelectionWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, mask_operation_waiting_node: MaskOperationSelectionWaitingNode) -> TaskFeature:\n        return mask_operation_waiting_node.mask_converted_task_feature.task_feature\n\n    def get_element_inclusion_prob(self, mask_operation_waiting_node: MaskOperationSelectionWaitingNode) -> float:\n        return self.operation_element_prob_dict[mask_operation_waiting_node.next_mask_operation.__class__.__name__]\n\n    def calculate_dist_factor(self, mask_operation_waiting_node: MaskOperationSelectionWaitingNode) -> float:\n        return 1.0\n\n\nclass ColorChannelSelectionOperationWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, node: ColorChannelSelectionOperationWaitingNode) -> TaskFeature:\n        return node.task_feature\n\n    def get_element_inclusion_prob(self, node: ColorChannelSelectionOperationWaitingNode) -> float:\n        return self.operation_element_prob_dict[node.next_color_channel_selection.__class__.__name__]\n\n\nclass ColorChannelMaskConversionWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, node: ColorChannelMaskConversionWaitingNode) -> TaskFeature:\n        return node.task_feature\n\n    def get_element_inclusion_prob(self, node: ColorChannelMaskConversionWaitingNode) -> float:\n        return self.operation_element_prob_dict[node.next_mask_conversion.__class__.__name__]\n\n\nclass ColorChannelMergeWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, node: ColorChannelMergeWaitingNode) -> TaskFeature:\n        return node.task_feature\n\n    def get_element_inclusion_prob(self, node: ColorChannelMergeWaitingNode) -> float:\n        return self.operation_element_prob_dict[node.next_merge_operation.__class__.__name__]\n\n\nclass PartitionSelectionWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, node: PartitionSelectionWaitingNode) -> TaskFeature:\n        return node.task_feature\n\n    def get_element_inclusion_prob(self, node: PartitionSelectionWaitingNode) -> float:\n        return self.operation_element_prob_dict[node.next_partition_selection.__class__.__name__]\n\n\nclass PartitionMergeWaitingNodeEvaluator(HandmadeNodeEvaluatorBase):\n\n    def get_task_feature(self, node: PartitionMergeWaitingNode) -> TaskFeature:\n        return node.task_feature\n\n    def get_element_inclusion_prob(self, node: PartitionMergeWaitingNode) -> float:\n        return self.operation_element_prob_dict[node.next_partition_merge_operation.__class__.__name__]\n\n\ndef np_to_str(arr: np.ndarray) -> bytes:\n    return arr.tostring()\n\n\ndef to_bytes(obj):\n    return bytes(str(obj), encoding='utf-8')\n\n\ndef train_operation_element_inclusion_prediction():\n    storage = load_answer_storage()\n    save_answer_storage(storage)\n    storage = storage.get_only_correct_answer_storage()\n    print(storage.get_text())\n\n    type_classes = [c.__name__ for c in get_all_operation_classes()]\n    subclasses = [c.__name__ for c in get_all_operation_element_classes()]\n    record_dicts = []\n\n    for task_name, elements in storage.get_task_grouped_elements():\n        pseudo_operation_set = OperationSet(list(chain.from_iterable([e.operation_set.operations for e in elements])))\n\n        task = TaskLoader().get_task(task_name)\n        task_feature = create_task_feature(task)\n\n        operation_type_classes = [o_s_t.__name__ for o_s_t in pseudo_operation_set.types()]\n        type_answer_dict = {c: c in operation_type_classes for c in type_classes}\n\n        operation_element_classes = [o_s_e.__class__.__name__ for o_s_e in pseudo_operation_set.elements()]\n        element_answer_dict = {c: c in operation_element_classes for c in subclasses}\n\n        record_dicts.append({**asdict(task_feature), **type_answer_dict, **element_answer_dict})\n\n    df = DataFrame(record_dicts)\n    df = df.fillna(10)  # TODO do not use magic number\n\n    target_columns = type_classes + subclasses\n    feature_columns = list(set(df.columns) - set(target_columns))\n\n    x = df[feature_columns]\n    y = df[target_columns]\n\n    print(x)\n    print(y)\n\n    model = MLPClassifier(\n        # early_stopping=True, validation_fraction=0.3, n_iter_no_change=50,\n        hidden_layer_sizes=(50,), solver='sgd', learning_rate_init=0.003, max_iter=40,\n        verbose=True,\n    )\n    model.fit(x, y)\n\n    shutil.rmtree(PathConfig.OPERATION_ELEMENT_INCLUSION_MODEL_ROOT, ignore_errors=True)\n    PathConfig.OPERATION_ELEMENT_INCLUSION_MODEL_ROOT.mkdir(parents=True, exist_ok=True)\n    pickle.dump(model, PathConfig.OPERATION_ELEMENT_INCLUSION_MODEL.open(mode='wb'))\n    pickle.dump(feature_columns, PathConfig.OPERATION_ELEMENT_INCLUSION_MODEL_FEATURE_COLUMNS.open(mode='wb'))\n    pickle.dump(target_columns, PathConfig.OPERATION_ELEMENT_INCLUSION_MODEL_TARGET_COLUMNS.open(mode='wb'))\n\n    temp_dicts = []\n    for e in sorted(storage.elements, key=lambda e: e.task_name):\n        task = TaskLoader().get_task(e.task_name)\n        task_feature = create_task_feature(task)\n        pred_dict = predict_operation_element_inclusion(task_feature)\n\n        operation_type_classes = [o_s_t.__name__ for o_s_t in e.operation_set.types()]\n        operation_element_classes = [o_s_e.__class__.__name__ for o_s_e in e.operation_set.elements()]\n        element_answer_dict = {c: c in operation_type_classes + operation_element_classes for c in type_classes + subclasses}\n        temp_dicts.append(element_answer_dict)\n        temp_dicts.append(pred_dict)\n\n    temp_df = DataFrame(temp_dicts)\n    print(temp_df)\n\n\ndef predict_operation_element_inclusion(task_feature: TaskFeature) -> Dict[str, float]:\n    model: MLPClassifier = pickle.load(PathConfig.OPERATION_ELEMENT_INCLUSION_MODEL.open(mode='rb'))\n    feature_columns = pickle.load(PathConfig.OPERATION_ELEMENT_INCLUSION_MODEL_FEATURE_COLUMNS.open(mode='rb'))\n    target_columns = pickle.load(PathConfig.OPERATION_ELEMENT_INCLUSION_MODEL_TARGET_COLUMNS.open(mode='rb'))\n\n    df = DataFrame([asdict(task_feature)])\n    df = df.fillna(10)\n\n    x = df[feature_columns]\n    y = model.predict_proba(x)[0]\n\n    return {c: p for c, p in zip(target_columns, y)}\n\n\n@dataclass\nclass NodeBaseSearchEngine:\n    MAX_NODE = 100000000\n    answer_limit_num: int = 3\n\n    def search(self, task: Task, params: AllParameter, verbose: bool = False) -> Union[AnsweredSearchResults, NotAnsweredSearchResult]:\n        task_feature = create_task_feature(task, task)\n        if RunConfig.USE_ML_GUIDE:\n            operation_element_prob_dict = predict_operation_element_inclusion(task_feature)\n        else:\n            operation_element_prob_dict = defaultdict(lambda: 1)\n\n        schedules: NodeEvaluatorSchedules = get_schedule(operation_element_prob_dict, params.node_base_engine_param, params.distance_evaluator_param)\n        node_evaluator = schedules.pop_evaluator()\n\n        root_node = UniformOperationCompletedNode(None, task, task, task_feature, OperationSet([]))\n        first_waiting_nodes = CompletedNodeProcessor.process(root_node)\n        node_evaluator.evaluate_nodes(first_waiting_nodes)\n        zero_depth_pq = PriorityQueue([*first_waiting_nodes])\n        pq = PriorityQueue([])\n        zero_depth_completed_nodes = []\n        zero_depth_completed_node_eval_map = {}\n        visited_node_hashes = defaultdict(dict)  # If same array is found, cache to save time.\n\n        if verbose:\n            print('search zero depth nodes')\n        with Timer() as timer:\n            for node_i in range(self.MAX_NODE):\n                if len(zero_depth_pq) == 0:\n                    break\n\n                waiting_new_nodes = []\n                for same_cost_node_i, waiting_node in enumerate(zero_depth_pq.pop_mins_or_as_least_n(params.node_base_engine_param.pq_pop_mins_or_as_least_n)):\n                    completed_node = WaitingNodeProcessor().process(waiting_node)\n\n                    if isinstance(completed_node, Exception):\n                        if verbose:\n                            print(f'skipped: {completed_node}')\n                        continue\n\n                    if isinstance(completed_node, UniformOperationCompletedNode):\n                        zero_depth_completed_nodes.append(completed_node)\n                        zero_depth_completed_node_eval_map[completed_node.base_operation_set.operations[0]] = node_evaluator.evaluate_base_distance_for_completed_node(completed_node)\n                        continue\n\n                    temp_waiting_new_nodes = CompletedNodeProcessor.process(completed_node)\n                    node_evaluator.evaluate_nodes(temp_waiting_new_nodes)\n\n                    waiting_new_nodes += temp_waiting_new_nodes\n\n                for n in waiting_new_nodes:\n                    zero_depth_pq.push(n)\n\n            one_depth_answer_nodes = [k for k, v in zero_depth_completed_node_eval_map.items() if v == 0]\n            if one_depth_answer_nodes:\n                answers = []\n                result_applied_tasks = []\n                for o in one_depth_answer_nodes:\n                    try:\n                        applied_task = TaskOperationSetExecutor().execute(task, OperationSet([o]))\n                    except OperationInconsistencyException:\n                        continue\n                    if any(applied_task.test_arr_hash() == t.test_arr_hash() for t in result_applied_tasks):\n                        continue\n                    result_applied_tasks.append(applied_task)\n                    answers.append(AnsweredSearchResult(OperationSet([o])))\n                answers = answers[:3]\n                return AnsweredSearchResults(task, answers, timer.second(), 0, node_i)\n            zero_depth_search_time = timer.second()\n\n        for completed_node in zero_depth_completed_nodes:\n            train_node_hash = completed_node.train_arr_hash()\n            all_node_hash = completed_node.all_arr_hash()\n            if train_node_hash in visited_node_hashes:\n                if verbose:\n                    print(f'hash skipped. same node: {\"_\".join(map(str, (f\"{k}:{v}\" for k, v in visited_node_hashes[train_node_hash].items())))}')\n                visited_node_hashes[train_node_hash][all_node_hash] = completed_node\n                continue\n            visited_node_hashes[train_node_hash][all_node_hash] = completed_node\n\n            temp_waiting_new_nodes = CompletedNodeProcessor.process(completed_node)\n            node_evaluator.evaluate_nodes(temp_waiting_new_nodes)\n            for n in temp_waiting_new_nodes:\n                pq.push(n)\n\n        # TODO 1 depth\u3082\u306e\u3092\u4f7f\u3063\u3066\u8a55\u4fa1\u95a2\u6570\u3092\u3044\u3044\u611f\u3058\u306b\n        # TODO \u540c\u3058operation\u3092\u542b\u3080\u3068\u30de\u30a4\u30ca\u30b9\u306a\u88dc\u6b63\u3092\u304b\u3051\u306a\u3044\u3068\u3001\u307e\u305a\u3044\u304b\u3082\uff1f\n\n        if verbose:\n            print('search none-zero depth nodes')\n        searched_total_node = 0\n        with Timer() as timer:\n            for node_i in range(self.MAX_NODE):\n                if len(pq) == 0:\n                    return NotAnsweredSearchResult(task, NoImprovementException(), timer.second(), searched_total_node)\n\n                waiting_new_nodes = []\n                for same_cost_node_i, waiting_node in enumerate(pq.pop_mins_or_as_least_n(params.node_base_engine_param.pq_pop_mins_or_as_least_n)):\n                    if verbose:\n                        print(f'total_node: {searched_total_node}, node: {node_i}_{same_cost_node_i}, pq_len: {len(pq)}, cost: {waiting_node.cache_pred_distance}, {waiting_node}')\n\n                    searched_total_node += 1\n                    completed_node = WaitingNodeProcessor().process(waiting_node)\n\n                    if isinstance(completed_node, Exception):\n                        if verbose:\n                            print(f'skipped: {completed_node}')\n                        continue\n\n                    if isinstance(completed_node, UniformOperationCompletedNode):\n                        if AnswerMatcher.is_train_all_match(completed_node.task):\n                            answers = []\n                            for t in get_alternative_operation_sets(task, completed_node, visited_node_hashes, verbose):\n                                answers.append(AnsweredSearchResult(t.to_operation_set()))\n                                if len(answers) == 3:\n                                    break\n                            return AnsweredSearchResults(task, answers, zero_depth_search_time, timer.second(), searched_total_node)\n\n                    train_node_hash = completed_node.train_arr_hash()\n                    all_node_hash = completed_node.all_arr_hash()\n                    if train_node_hash in visited_node_hashes:\n                        if verbose:\n                            print(f'hash skipped. same node: {\"_\".join(map(str, (f\"{k}:{v}\" for k, v in visited_node_hashes[train_node_hash].items())))}')\n                        visited_node_hashes[train_node_hash][all_node_hash] = completed_node\n                        continue\n                    visited_node_hashes[train_node_hash][all_node_hash] = completed_node\n\n                    temp_waiting_new_nodes = CompletedNodeProcessor.process(completed_node)\n                    node_evaluator.evaluate_nodes(temp_waiting_new_nodes)\n\n                    waiting_new_nodes += temp_waiting_new_nodes\n\n                    if timer.second() > schedules.timeout_sec():\n                        return NotAnsweredSearchResult(task, TimeoutException(), timer.second(), searched_total_node)\n\n                for n in waiting_new_nodes:\n                    pq.push(n)\n\n                if timer.second() > schedules.next_timing():\n                    if verbose:\n                        print('=========================== evaluator switch!!! ===========================')\n                    node_evaluator = schedules.pop_evaluator()\n                    if node_evaluator is None:\n                        return NotAnsweredSearchResult(task, TimeoutException(), timer.second(), searched_total_node)\n                    node_evaluator.evaluate_nodes(pq.heap)\n                    pq.refresh()\n\n        return NotAnsweredSearchResult(task, MaxNodeExceededException(), timer.second(), searched_total_node)\n\n\nclass WaitingNodeProcessor:\n\n    def process(self, node: WaitingNode) -> Union[CompletedNode, OperationInconsistencyException]:\n        mapping = {\n            UniformOperationWaitingNode: UniformOperationWaitingNodeProcessor(),\n            ColorSelectionWaitingNode: ColorSelectionWaitingNodeProcessor(),\n            MaskConversionWaitingNode: MaskConversionWaitingNodeProcessor(),\n            MaskOperationSelectionWaitingNode: MaskOperationSelectionWaitingNodeProcessor(),\n            ColorChannelSelectionOperationWaitingNode: ColorChannelSelectionOperationWaitingNodeProcessor(),\n            ColorChannelMaskConversionWaitingNode: ColorChannelMaskConversionWaitingNodeProcessor(),\n            ColorChannelMergeWaitingNode: ColorChannelMergeWaitingNodeProcessor(),\n            PartitionSelectionWaitingNode: PartitionSelectionWaitingNodeProcessor(),\n            PartitionMergeWaitingNode: PartitionMergeWaitingNodeProcessor(),\n        }\n\n        try:\n            processor = mapping[node.__class__]\n            return processor.process(node)\n        except OperationInconsistencyException as e:\n            return e\n\n\nclass UniformOperationWaitingNodeProcessor:\n\n    def process(self, node: UniformOperationWaitingNode) -> UniformOperationCompletedNode:\n        new_task = TaskOperationSetExecutor().execute(node.task, OperationSet([node.next_operation]))\n        if self.can_skip(node.task, new_task):\n            raise OperationInconsistencyException(f'can skip')\n        new_task_feature = create_task_feature(node.original_task, new_task)\n        new_base_operation_set = OperationSet(node.base_operation_set.operations + [node.next_operation])\n\n        return UniformOperationCompletedNode(node, node.original_task, new_task, new_task_feature, new_base_operation_set)\n\n    def can_skip(self, prev_task: Task, next_task: Task) -> bool:\n        # TODO use OperationInconsistencyException?\n        if all(AnswerMatcher.is_match_arr(prev_io.input_arr, next_io.input_arr) for prev_io, next_io in zip(prev_task.train, next_task.train)):\n            # no effect\n            return True\n        else:\n            return False\n\n\nclass ColorSelectionWaitingNodeProcessor:\n\n    def process(self, node: ColorSelectionWaitingNode) -> ColorSelectionCompletedNode:\n        color_selected_task = ColorSelectionExecutor.execute(node.task, node.next_selection)\n        if self.can_skip(color_selected_task):\n            raise OperationInconsistencyException(f'can skip')\n        color_selected_task_feature = create_color_selected_task_feature(node.original_task, color_selected_task, node.task_feature)\n        return ColorSelectionCompletedNode(node, node.original_task, color_selected_task,\n                                           color_selected_task_feature, node.base_operation_set, node.next_selection)\n\n    def can_skip(self, color_selected_task: ColorSelectedTask) -> bool:\n        # TODO use OperationInconsistencyException?\n        if not any(m.any() for m in color_selected_task.train_masks):\n            # if no mask was generated, skip.\n            return True\n        elif all(m.all() for m in color_selected_task.train_masks):\n            # if mask covers all region, skip.\n            return True\n        else:\n            return False\n\n\nclass MaskConversionWaitingNodeProcessor:\n\n    def process(self, node: MaskConversionWaitingNode) -> MaskConversionCompletedNode:\n        mask_converted_task = MaskConversionExecutor.execute(node.color_selected_task, node.next_mask_conversion)\n        if self.can_skip(mask_converted_task):\n            raise OperationInconsistencyException(f'can skip')\n        mask_converted_task_feature = create_mask_conversion_task_feature(node.original_task, mask_converted_task, node.color_selected_task_feature.task_feature)\n\n        return MaskConversionCompletedNode(node, node.original_task, mask_converted_task, mask_converted_task_feature,\n                                           node.base_operation_set, node.color_selection, node.next_mask_conversion)\n\n    def can_skip(self, mask_converted_task: MaskConvertedTask) -> bool:\n        if not any(m.any() for m in mask_converted_task.train_masks):\n            # if no mask was generated, skip.\n            return True\n        elif all(m.all() for m in mask_converted_task.train_masks):\n            # if mask covers all region, skip.\n            return True\n        else:\n            return False\n\n\nclass MaskOperationSelectionWaitingNodeProcessor:\n\n    def process(self, node: MaskOperationSelectionWaitingNode) -> UniformOperationCompletedNode:\n        new_task = MaskOperationExecutor.execute(node.mask_converted_task, node.next_mask_operation)\n        if self.can_skip(node.mask_converted_task, new_task):\n            raise OperationInconsistencyException(f'can skip')\n        new_task_feature = create_task_feature(node.original_task, new_task)\n        new_base_operation_set = OperationSet(node.base_operation_set.operations +\n                                              [ColorOperation(node.color_selection, node.mask_conversion, node.next_mask_operation)])\n\n        return UniformOperationCompletedNode(node, node.original_task, new_task, new_task_feature, new_base_operation_set)\n\n    def can_skip(self, prev_task: Task, next_task: Task) -> bool:\n        if all(AnswerMatcher.is_match_arr(prev_io.input_arr, next_io.input_arr) for prev_io, next_io in zip(prev_task.train, next_task.train)):\n            # no effect\n            return True\n        else:\n            return False\n\n\nclass ColorChannelSelectionOperationWaitingNodeProcessor:\n\n    def process(self, node: ColorChannelSelectionOperationWaitingNode) -> ColorChannelSelectionCompletedNode:\n        new_task = ColorChannelSelectionExecutor().execute(node.task, node.next_color_channel_selection)\n        if self.can_skip(node.task, new_task):\n            raise OperationInconsistencyException(f'can skip')\n\n        # reuse old feature.\n        return ColorChannelSelectionCompletedNode(node, node.original_task, new_task, node.task_feature, node.base_operation_set, node.next_color_channel_selection)\n\n    def can_skip(self, prev_task: Task, next_task: Task) -> bool:\n        # TODO imple\n        return False\n\n\nclass ColorChannelMaskConversionWaitingNodeProcessor:\n\n    def process(self, node: ColorChannelMaskConversionWaitingNode) -> ColorChannelMaskConversionCompletedNode:\n        new_task = ColorChannelMaskConversionSelectionExecutor().execute(node.task, node.next_mask_conversion)\n        if self.can_skip(node.task, new_task):\n            raise OperationInconsistencyException(f'can skip')\n\n        # reuse old feature.\n        return ColorChannelMaskConversionCompletedNode(node, node.original_task, new_task, node.task_feature, node.base_operation_set, node.color_channel_selection, node.next_mask_conversion)\n\n    def can_skip(self, prev_task: Task, next_task: Task) -> bool:\n        # TODO imple\n        return False\n\n\nclass ColorChannelMergeWaitingNodeProcessor:\n\n    def process(self, node: ColorChannelMergeWaitingNode) -> UniformOperationCompletedNode:\n        new_task = ColorChannelMergeExecutor.execute(node.task, node.next_merge_operation)\n        if self.can_skip(node.task, new_task):\n            raise OperationInconsistencyException(f'can skip')\n\n        new_task_feature = create_task_feature(node.original_task, new_task)\n        new_base_operation_set = OperationSet(node.base_operation_set.operations +\n                                              [MultiColorChannelOperation(node.color_channel_selection, node.mask_conversion, node.next_merge_operation)])\n\n        return UniformOperationCompletedNode(node, node.original_task, new_task, new_task_feature, new_base_operation_set)\n\n    def can_skip(self, prev_task: Task, next_task: Task) -> bool:\n        # TODO imple\n        return False\n\n\nclass PartitionSelectionWaitingNodeProcessor:\n\n    def process(self, node: PartitionSelectionWaitingNode) -> PartitionSelectionCompletedNode:\n        new_task = PartitionSelectionExecutor().execute(node.task, node.next_partition_selection)\n        if self.can_skip(node.task, new_task):\n            raise OperationInconsistencyException(f'can skip')\n\n        # reuse old feature.\n        return PartitionSelectionCompletedNode(node, node.original_task, new_task, node.task_feature, node.base_operation_set, node.next_partition_selection)\n\n    def can_skip(self, prev_task: Task, next_task: Task) -> bool:\n        # TODO imple\n        return False\n\n\nclass PartitionMergeWaitingNodeProcessor:\n    def process(self, node: PartitionMergeWaitingNode) -> UniformOperationCompletedNode:\n        new_task = PartitionMergeExecutor().execute(node.task, node.next_partition_merge_operation)\n\n        if self.can_skip(node.task, new_task):\n            raise OperationInconsistencyException(f'can skip')\n\n        new_task_feature = create_task_feature(node.original_task, new_task)\n        new_base_operation_set = OperationSet(node.base_operation_set.operations + [PartitionOperation(node.partition_selection, node.next_partition_merge_operation)])\n\n        return UniformOperationCompletedNode(node, node.original_task, new_task, new_task_feature, new_base_operation_set)\n\n    def can_skip(self, prev_task: Task, next_task: Task) -> bool:\n        # TODO imple\n        return False\n\n\n@dataclass(frozen=True)\nclass WithOutMostCommonColorChannelSelection(ColorChannelSelection):\n    bg_selection_mode: BackGroundColorSelectionMode\n\n    def __call__(self, arr: np.ndarray) -> List[Tuple[Color, np.ndarray]]:\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        colors = ColorSelectionUtil().get_colors(arr)\n\n        results = [(c, arr == c) for c in colors if c != bg]\n\n        if len(results) <= 1:\n            raise OperationInconsistencyException('can not devide')\n\n        return results\n\n\n@dataclass\nclass OperationSetExecutionResultHolder:\n    raw_task: Task\n    cache: Dict[str, Tuple[Task, TaskFeature]]\n\n    def get_result(self, operation_set: OperationSet) -> Tuple[Task, TaskFeature]:\n        if str(operation_set) in self.cache:\n            return self.cache[str(operation_set)]\n\n        for i in reversed(range(1, len(operation_set.operations))):\n            prev_o_s = OperationSet(operation_set.operations[:i])\n            post_o_s = OperationSet(operation_set.operations[i:])\n            assert len(prev_o_s.operations) + len(post_o_s.operations) == len(operation_set.operations)\n\n            if str(prev_o_s) in self.cache:\n                prev_task, _ = self.cache[str(prev_o_s)]\n                post_o_s_applied_task = TaskOperationSetExecutor().execute(prev_task, post_o_s)\n                post_o_s_applied_task_feature = create_task_feature(post_o_s_applied_task)\n                self.cache[str(operation_set)] = (post_o_s_applied_task, post_o_s_applied_task_feature)\n                return post_o_s_applied_task, post_o_s_applied_task_feature\n\n        applied_task = TaskOperationSetExecutor().execute(self.raw_task, operation_set)\n        applied_task_feature = create_task_feature(applied_task)\n        self.cache[str(operation_set)] = (applied_task, applied_task_feature)\n        return applied_task, applied_task_feature\n\n\n@dataclass\nclass OperationSetMutator:\n    # TODO uniform(0, 1) is redundant. There must be easier way to do it.\n    # TODO I'd like to define procedure of probability. like albumentation.\n    # TODO should increase max_depth dynamically?\n\n    holder: OperationSetExecutionResultHolder\n    operation_element_prob_dict: Dict[str, float]\n\n    def mutate(self, operation_set: OperationSet):\n        new_operations = []\n        for o in operation_set.operations:\n            task, task_feature = self.holder.get_result(OperationSet(new_operations))\n            if random.uniform(0, 1) < TreeBaseSearchEngineParameter.operation_mutation_prob:\n                new_operations.append(self.get_random_one_operation(task, task_feature))\n            elif random.uniform(0, 1) < TreeBaseSearchEngineParameter.operation_component_mutation_prob:\n                if isinstance(o, UniformOperation):\n                    new_operations.append(self._uniform_operation_candidates(task_feature))\n                elif isinstance(o, ColorOperation):\n                    color_sel, add_sels, mask_ope = o.color_selection, o.mask_conversions, o.mask_operation\n                    if random.uniform(0, 1) < 1 \/ 3:\n                        color_sel = self._color_selection_candidates(task)\n                    if random.uniform(0, 1) < 1 \/ 3:\n                        add_sels = [self._mask_conversions()]\n                    if random.uniform(0, 1) < 1 \/ 3:\n                        mask_ope = self._mask_operation_candidates(task)\n                    new_operations.append(ColorOperation(color_sel, add_sels, mask_ope))\n                else:\n                    raise NotImplementedError()\n            elif random.uniform(0, 1) < TreeBaseSearchEngineParameter.operation_param_mutation_prob:\n                if isinstance(o, UniformOperation):\n                    new_operations.append(self._mutate_parameter(o, task))\n                elif isinstance(o, ColorOperation):\n                    color_sel, add_sels, mask_ope = o.color_selection, o.mask_conversions, o.mask_operation\n                    if random.uniform(0, 1) < 1 \/ 3:\n                        color_sel = self._mutate_parameter(color_sel, task)\n                    if random.uniform(0, 1) < 1 \/ 3:\n                        add_sels = [self._mutate_parameter(add_sels[0], task)]\n                    if random.uniform(0, 1) < 1 \/ 3:\n                        mask_ope = self._mutate_parameter(mask_ope, task)\n                    new_operations.append(ColorOperation(color_sel, add_sels, mask_ope))\n                else:\n                    raise NotImplementedError()\n            elif random.uniform(0, 1) < TreeBaseSearchEngineParameter.shrink_mutation_prob:\n                continue\n            else:\n                new_operations.append(o)\n\n        if len(new_operations) < TreeBaseSearchEngineParameter.max_depth:\n            if random.uniform(0, 1) < TreeBaseSearchEngineParameter.extend_mutation_prob:\n                temp_new_set = OperationSet(new_operations)\n                task, task_feature = self.holder.get_result(temp_new_set)\n                new_operations.append(self.get_random_one_operation(task, task_feature))\n\n        return OperationSet(new_operations)\n\n    def get_random_one_operation(self, task: Task, task_feature: TaskFeature):\n        classes = [UniformOperation, ColorOperation]\n\n        class_probs = [self.operation_element_prob_dict[c.__name__] for c in classes]\n        total_prob = sum(class_probs)\n        class_probs = [p \/ total_prob for p in class_probs]\n\n        chosen_class = np.random.choice(classes, p=class_probs)\n\n        if chosen_class == UniformOperation:\n            operation = self._uniform_operation_candidates(task_feature)\n        elif chosen_class == ColorOperation:\n            color_sel = self._color_selection_candidates(task)\n            add_sels = self._mask_conversions()\n            mask_ope = self._mask_operation_candidates(task)\n            operation = ColorOperation(color_sel, add_sels, mask_ope)\n        else:\n            raise NotImplementedError()\n\n        return operation\n\n    def _uniform_operation_candidates(self, task_feature: TaskFeature):\n        classes = [Resize, Padding, Flip, Rotate]\n\n        class_probs = [self.operation_element_prob_dict[c.__name__] for c in classes]\n        total_prob = sum(class_probs)\n        class_probs = [p \/ total_prob for p in class_probs]\n\n        chosen_class = np.random.choice(classes, p=class_probs)\n\n        if chosen_class == Resize:\n            return random.choice([Resize(a, r) for a, r in product(Axis, range(2, 5))])\n        elif chosen_class == Padding:\n            return random.choice([Padding(m, d, k) for m, d, k in product(PaddingMode, Direction, range(1, 4))])\n        elif chosen_class == Flip:\n            return random.choice([Flip(m) for m in FlipMode])\n        elif chosen_class == Rotate:\n            return random.choice([Rotate(a) for a in [90, 180, 270]])\n        else:\n            raise NotImplementedError()\n\n    def _color_selection_candidates(self, task: Task):\n        classes = [FixedSingleColorSelection, SingleColorSelection, MultiColorSelection]\n\n        class_probs = [self.operation_element_prob_dict[c.__name__] for c in classes]\n        total_prob = sum(class_probs)\n        class_probs = [p \/ total_prob for p in class_probs]\n\n        chosen_class = np.random.choice(classes, p=class_probs)\n\n        if chosen_class == FixedSingleColorSelection:\n            input_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(task.get_input_all_arr())))))\n            return random.choice([FixedSingleColorSelection(c) for c in input_colors])\n        elif chosen_class == SingleColorSelection:\n            return random.choice([SingleColorSelection(m) for m in SingleColorSelectionMode])\n        elif chosen_class == MultiColorSelection:\n            return random.choice([MultiColorSelection(m) for m in MultiColorSelectionMode])\n        else:\n            raise NotImplementedError()\n\n    def _mask_conversions(self):\n        classes = [NoMaskConversion, SquareObjectsSelection, ObjectsMaxMinSelection, SplitLineSelection, DotExistLineSelection,\n                   HolesSelection, ObjectInnerSelection, ContourSelection, ContourOuterSelection, ConnectDotSelection]\n\n        class_probs = [self.operation_element_prob_dict[c.__name__] for c in classes]\n        total_prob = sum(class_probs)\n        class_probs = [p \/ total_prob for p in class_probs]\n\n        chosen_class = np.random.choice(classes, p=class_probs)\n\n        if chosen_class == NoMaskConversion:\n            return NoMaskConversion()\n        elif chosen_class == SquareObjectsSelection:\n            return SquareObjectsSelection()\n        elif chosen_class == ObjectsMaxMinSelection:\n            return random.choice([ObjectsMaxMinSelection(m, t, c) for m, t, c in product(MaxOrMin, ObjectFeature, PixelConnectivity)])\n        elif chosen_class == SplitLineSelection:\n            return random.choice([SplitLineSelection(a) for a in Axis])\n        elif chosen_class == DotExistLineSelection:\n            return random.choice([DotExistLineSelection(a) for a in Axis])\n        elif chosen_class == HolesSelection:\n            return random.choice([HolesSelection(c) for c in PixelConnectivity])\n        elif chosen_class == ObjectInnerSelection:\n            return random.choice([ObjectInnerSelection(c, e) for c, e in product(PixelConnectivity, ImageEdgeType)])\n        elif chosen_class == ContourSelection:\n            return random.choice([ContourSelection(c, e) for c, e in product(PixelConnectivity, ImageEdgeType)])\n        elif chosen_class == ContourOuterSelection:\n            return random.choice([ContourOuterSelection(c, h) for c, h in product(PixelConnectivity, HoleInclude)])\n        elif chosen_class == ConnectDotSelection:\n            return random.choice([ConnectDotSelection(a, e, f) for a, e, f in product(Axis, LineEdgeType, FillType)])\n        else:\n            raise NotImplementedError()\n\n    def _mask_operation_candidates(self, task: Task):\n        classes = [MaskCoordsCrop, FixedColorMaskFill, SingleColorMaskFill]\n\n        class_probs = [self.operation_element_prob_dict[c.__name__] for c in classes]\n        total_prob = sum(class_probs)\n        class_probs = [p \/ total_prob for p in class_probs]\n\n        chosen_class = np.random.choice(classes, p=class_probs)\n\n        if chosen_class == MaskCoordsCrop:\n            return MaskCoordsCrop()\n        elif chosen_class == FixedColorMaskFill:\n            output_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(task.get_output_all_arr())))))\n            return random.choice([FixedColorMaskFill(c) for c in output_colors])\n        elif chosen_class == SingleColorMaskFill:\n            return random.choice([SingleColorMaskFill(m) for m in SingleColorSelectionMode])\n        else:\n            raise NotImplementedError()\n\n    def _mutate_parameter(self, operation_element, task: Task):\n        # TODO Should mutate one property of operation_element.\n        if isinstance(operation_element, Resize):\n            return random.choice([Resize(Axis.VERTICAL, r) for r in range(2, 5)])\n        elif isinstance(operation_element, Padding):\n            return random.choice([Padding(m, d, k) for m, d, k in product(PaddingMode, [Direction.TOP, Direction.BOTTOM], range(1, 4))])\n        elif isinstance(operation_element, Flip):\n            return random.choice([Flip(m) for m in FlipMode])\n        elif isinstance(operation_element, Rotate):\n            return random.choice([Rotate(a) for a in [90, 180, 270]])\n        elif isinstance(operation_element, FixedSingleColorSelection):\n            input_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(task.get_input_all_arr())))))\n            return random.choice([FixedSingleColorSelection(c) for c in input_colors])\n        elif isinstance(operation_element, SingleColorSelection):\n            return random.choice([SingleColorSelection(m) for m in SingleColorSelectionMode])\n        elif isinstance(operation_element, MultiColorSelection):\n            return random.choice([MultiColorSelection(m) for m in MultiColorSelectionMode])\n        elif isinstance(operation_element, NoMaskConversion):\n            return random.choice([NoMaskConversion()])\n        elif isinstance(operation_element, SquareObjectsSelection):\n            return random.choice([SquareObjectsSelection()])\n        elif isinstance(operation_element, ObjectsMaxMinSelection):\n            return random.choice([ObjectsMaxMinSelection(m, t, c) for m, t, c in product(MaxOrMin, ObjectFeature, PixelConnectivity)])\n        elif isinstance(operation_element, SplitLineSelection):\n            return random.choice([SplitLineSelection(a) for a in Axis])\n        elif isinstance(operation_element, DotExistLineSelection):\n            return random.choice([DotExistLineSelection(a) for a in Axis])\n        elif isinstance(operation_element, HolesSelection):\n            return random.choice([HolesSelection(c) for c in PixelConnectivity])\n        elif isinstance(operation_element, ObjectInnerSelection):\n            return random.choice([ObjectInnerSelection(c, e) for c, e in product(PixelConnectivity, ImageEdgeType)])\n        elif isinstance(operation_element, ContourSelection):\n            return random.choice([ContourSelection(c, e) for c, e in product(PixelConnectivity, ImageEdgeType)])\n        elif isinstance(operation_element, ContourOuterSelection):\n            return random.choice([ContourOuterSelection(c, h) for c, h in product(PixelConnectivity, HoleInclude)])\n        elif isinstance(operation_element, ConnectDotSelection):\n            return random.choice([ConnectDotSelection(a, e, f) for a, e, f in product(Axis, LineEdgeType, FillType)])\n        elif isinstance(operation_element, MaskCoordsCrop):\n            return random.choice([MaskCoordsCrop()])\n        elif isinstance(operation_element, FixedColorMaskFill):\n            output_colors = list(map(lambda v: Color.of(v), set(chain.from_iterable(chain.from_iterable(task.get_output_all_arr())))))\n            return random.choice([FixedColorMaskFill(c) for c in output_colors])\n        elif isinstance(operation_element, SingleColorMaskFill):\n            return random.choice([SingleColorMaskFill(m) for m in SingleColorSelectionMode])\n        else:\n            raise NotImplementedError(operation_element)\n\n\n@dataclass\nclass Individual:\n    operation_set: OperationSet\n    distance: float\n    task_feature: TaskFeature\n\n    def __str__(self):\n        return f'depth: {len(self.operation_set.operations)}, dist: {self.distance:.5f}, ope: {self.operation_set}'\n\n\n@dataclass\nclass Population:\n    strategy: str\n    individuals: List[Individual]\n\n    def show(self):\n        self.sort()\n        for i in self.individuals:\n            print(i)\n\n    def sort(self):\n        random.shuffle(self.individuals)\n        self.individuals = sorted(self.individuals, key=lambda i: i.distance)\n\n    def get_elite(self):\n        # TODO Lack of consideration when there were multiple elites.\n        self.sort()\n        return self.individuals[0]\n\n    def get_dist0_if_exists(self) -> Optional[OperationSet]:\n        elite = min(self.individuals, key=lambda i: i.distance)\n        if elite.distance == 0:\n            return elite.operation_set\n        else:\n            return None\n\n    def mutate(self, mutator, holder, evaluator):\n        # \u5909\u7570\n        self.sort()\n        mutated_individuals = [self.get_elite()]\n        for i in self.individuals[1:]:\n            for _ in range(1000000000000):\n                try:\n                    mutated_operation_set = mutator.mutate(i.operation_set)\n                    # \u30c1\u30a7\u30c3\u30af\u3059\u308b\u3002\n                    task, task_feature = holder.get_result(mutated_operation_set)\n                    break\n                except OperationInconsistencyException:\n                    continue\n\n            applied_task, applied_task_feature = holder.get_result(mutated_operation_set)\n            mutation_distance = evaluator.evaluate_task_feature(applied_task_feature)\n            mutated_individuals.append(Individual(mutated_operation_set, mutation_distance, applied_task_feature))\n\n        self.individuals = mutated_individuals\n\n    def select(self):\n        if self.strategy == 'simple':\n            self.individuals = self.select_simple()\n        elif self.strategy == 'nsga2':\n            self.individuals = self.select_nsga2()\n        else:\n            raise NotImplementedError()\n\n    def select_nsga2(self):\n        raw_len = len(self.individuals)\n        selected = selNSGA2(self.individuals, raw_len)\n\n        simple_selection = self.select_simple(include_elite=True)\n\n        return selected + simple_selection[:raw_len - len(selected)]\n\n    def select_simple(self, include_elite: bool = True):\n        # \u9078\u629e\n        self.sort()\n        if include_elite:\n            next_individuals = [self.get_elite()]\n        else:\n            next_individuals = []\n        # score = 1 \/ distance # TODO Handle 0 division\n        score_sum = sum(map(lambda i: 1 \/ i.distance, self.individuals))\n        score_ratios = [1 \/ i.distance \/ score_sum for i in self.individuals]\n        score_roulette = np.cumsum(score_ratios)\n\n        for _ in range(len(self.individuals) - 1):\n            roulette_prob_hit = random.uniform(0, 1)\n            for i, roulette_prob in enumerate(score_roulette):\n                if roulette_prob_hit < roulette_prob:\n                    next_individuals.append(self.individuals[i])\n                    break\n\n        return next_individuals\n\n\n@dataclass\nclass TreeBaseSearchEngine:\n    time_out: int = 60  # TODO\n\n    def get_first_individual(self, evaluator, mutator, holder, task, root_task_feature):\n        try:\n            operation = mutator.get_random_one_operation(task, root_task_feature)\n            operation_set = OperationSet([operation])\n            _, task_feature = holder.get_result(operation_set)\n            distance = evaluator.evaluate_task_feature(task_feature)\n            return Individual(operation_set, distance, task_feature)\n        except OperationInconsistencyException:\n            return self.get_first_individual(evaluator, mutator, holder, task, root_task_feature)\n\n    def search(self, task: Task, params: AllParameter, verbose: bool = False) -> Union[AnsweredSearchResults, NotAnsweredSearchResult]:\n        evaluator = DistanceEvaluator(params.distance_evaluator_param)\n        holder = OperationSetExecutionResultHolder(task, {})\n        root_operation_set = OperationSet([])\n        _, root_task_feature = holder.get_result(root_operation_set)\n\n        if RunConfig.USE_ML_GUIDE:\n            operation_element_prob_dict = predict_operation_element_inclusion()\n        else:\n            operation_element_prob_dict = defaultdict(lambda: 1)\n\n        if verbose:\n            print(operation_element_prob_dict)\n\n        mutator: OperationSetMutator = OperationSetMutator(holder, operation_element_prob_dict)\n\n        individuals = [self.get_first_individual(evaluator, mutator, holder, task, root_task_feature) for _ in range(TreeBaseSearchEngineParameter.population_num)]\n\n        population = Population('simple', individuals)\n        with Timer() as timer:\n\n            for i in range(10000000):\n\n                if verbose:\n                    print(f'============== generation: {i} population')\n                    population.show()\n\n                population.mutate(mutator, holder, evaluator)\n\n                if verbose:\n                    print(f'============== generation: {i}, mutation population')\n                    population.show()\n\n                answer_operation_set = population.get_dist0_if_exists()\n                if answer_operation_set is not None:\n                    if AnswerMatcher.is_train_all_match_if_operated(task, answer_operation_set):\n                        return AnsweredSearchResults(task, [AnsweredSearchResult(answer_operation_set)], timer.second(), i)\n                    else:\n                        raise NotImplementedError()\n\n                population.select()\n\n                if timer.second() > self.time_out:\n                    return NotAnsweredSearchResult(task, TimeoutException(), timer.second(), i)\n\n            return NotAnsweredSearchResult(task, MaxNodeExceededException(), timer.second(), i)\n\n\nT = TypeVar('T')\n\n\nclass PriorityQueue:\n    def __init__(self, heap: List[T]):\n        self.heap = heap\n        heapify(self.heap)\n\n    def refresh(self):\n        heapify(self.heap)\n\n    def push(self, item: T):\n        heappush(self.heap, item)\n\n    def pop_min(self) -> T:\n        return heappop(self.heap)\n\n    def pop_mins(self) -> List[T]:\n        min_item = self.pop_min()\n        results = [min_item]\n        for _ in range(len(self.heap)):\n            item = self.pop_min()\n            if item <= min_item:\n                results.append(item)\n            else:\n                self.push(item)\n                return results\n\n        return results\n\n    def pop_mins_or_as_least_n(self, n: int) -> List[T]:\n        results = []\n\n        while len(results) < n:\n            if len(self) == 0:\n                break\n            results += self.pop_mins()\n\n        return results\n\n    def push_pop(self, item: T) -> T:\n        return heappushpop(self.heap, item)\n\n    def __len__(self) -> int:\n        return len(self.heap)\n\n    def sorted_list(self) -> List[T]:\n        return sorted(self.heap)\n\n\ndef str_to_operation_set(s: str) -> OperationSet:\n    # DSL string -> DSL object\n    return eval(s)\n\n\ndef str_to_AnswerStorageElement(s: str):\n    # noinspection PyUnresolvedReferences\n    # from abstraction_and_reasoning_challenge.src.answer_storage.answer_storage import AnswerStorageElement\n    return eval(s)\n\n\n@dataclass(frozen=True)\nclass UniqueColorNumberSelection(PartitionedArraySelection):\n    max_or_min: MaxOrMin\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]]) -> List[List[bool]]:\n        color_nums = _apply(self._color_num, partitioned_arrays)\n\n        if self.max_or_min == MaxOrMin.MAX:\n            target_color_num = max(map(max, color_nums))\n        elif self.max_or_min == MaxOrMin.MIN:\n            target_color_num = min(map(min, color_nums))\n        else:\n            raise NotImplementedError()\n\n        return _apply(lambda n: n == target_color_num, color_nums)\n\n    def _color_num(self, array: np.ndarray):\n        return len(np.unique(array))\n\n\n@dataclass(frozen=True)\nclass ColoredCellNumberSelection(PartitionedArraySelection):\n    max_or_min: MaxOrMin\n    bg_selection_mode: BackGroundColorSelectionMode\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]]) -> List[List[bool]]:\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        colored_cell_nums = _apply(partial(self._colored_cell_nums, bg=bg), partitioned_arrays)\n\n        if self.max_or_min == MaxOrMin.MAX:\n            target_color_num = max(map(max, colored_cell_nums))\n        elif self.max_or_min == MaxOrMin.MIN:\n            target_color_num = min(map(min, colored_cell_nums))\n        else:\n            raise NotImplementedError()\n\n        return _apply(lambda n: n == target_color_num, colored_cell_nums)\n\n    def _colored_cell_nums(self, array: np.ndarray, bg: Color):\n        return (array != bg).sum()\n\n\n@dataclass(frozen=True)\nclass SameShapeNumSelection(PartitionedArraySelection):\n    max_or_min: MaxOrMin\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]]) -> List[List[bool]]:\n        np_strings = _apply(lambda n: n.tostring(), partitioned_arrays)\n\n        c = Counter(_flatten(np_strings))\n\n        most_commons = c.most_common()\n        if len(most_commons) < 2:\n            raise OperationInconsistencyException('can not select')\n\n        if self.max_or_min == MaxOrMin.MAX:\n            if most_commons[0][1] == most_commons[1][1]:\n                raise OperationInconsistencyException('duplicated max')\n            target = most_commons[0][0]\n        elif self.max_or_min == MaxOrMin.MIN:\n            if most_commons[-1][1] == most_commons[-2][1]:\n                raise OperationInconsistencyException('duplicated min')\n            target = most_commons[-1][0]\n        else:\n            raise NotImplementedError()\n\n        return _apply(lambda n: n == target, np_strings)\n\n\n@dataclass(frozen=True)\nclass SymmetrySelection(PartitionedArraySelection):\n    axis: AxisV2\n    true_or_false: TrueOrFalse\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]]) -> List[List[bool]]:\n        return _apply(partial(self._is_symmetry, axis=self.axis, true_or_false=self.true_or_false), partitioned_arrays)\n\n    def _is_symmetry(self, array: np.ndarray, axis: AxisV2, true_or_false: TrueOrFalse) -> bool:\n        if axis == AxisV2.VERTICAL:\n            res = np.array_equal(array, Flip(FlipMode.UD)(array))\n        elif axis == AxisV2.HORIZONTAL:\n            res = np.array_equal(array, Flip(FlipMode.LR)(array))\n        elif axis == AxisV2.VERTICAL_HORIZONTAL:\n            res = self._is_symmetry(array, AxisV2.VERTICAL, TrueOrFalse.TRUE) and self._is_symmetry(array, AxisV2.HORIZONTAL, TrueOrFalse.TRUE)\n        elif axis == AxisV2.MAIN_DIAGONAL:\n            res = np.array_equal(array, Flip(FlipMode.UL_DR)(array))\n        elif axis == AxisV2.ANTI_DIAGONAL:\n            res = np.array_equal(array, Flip(FlipMode.UR_DL)(array))\n        elif axis == AxisV2.BOTH_DIAGONAL:\n            res = self._is_symmetry(array, AxisV2.MAIN_DIAGONAL, TrueOrFalse.TRUE) and self._is_symmetry(array, AxisV2.ANTI_DIAGONAL, TrueOrFalse.TRUE)\n        else:\n            raise NotImplementedError()\n\n        if true_or_false == TrueOrFalse.TRUE:\n            return res\n        else:\n            return not res\n\n\ndef _apply(func, partitioned_arrays: List[List[np.ndarray]]) -> List[List[Any]]:\n    results = []\n    for h_arrays in partitioned_arrays:\n        temp_masks = []\n        for array in h_arrays:\n            temp_masks.append(func(array))\n        results.append(temp_masks)\n    return results\n\n\ndef _flatten(partitioned: List[List[Any]]) -> List[Any]:\n    return list(chain.from_iterable(partitioned))\n\n\nclass OperationSetEvaluator:\n    # Evaluation function to choose three answers by ranking the OperationSet.\n    # Smaller is better.\n\n    def evaluate(self, operation_set: OperationSet) -> float:\n        score_map = {\n            FixedSingleColorSelection: 0.5,\n        }\n\n        return sum(score_map.get(e.__class__, 1) for e in operation_set.elements())\n\n\ndef get_alternative_operation_sets(raw_task: Task, last_completed_node: UniformOperationCompletedNode, visited_node_hashes: Dict[int, Dict[int, Any]], verbose: bool) -> Iterable[NodeTree]:\n    if verbose:\n        print('original_answer')\n        print(NodeTree.of(last_completed_node).to_operation_set())\n        print('===search other answers===')\n\n    node_tree = NodeTree.of(last_completed_node)\n\n    depth_alternative_nodes_pairs: List[Tuple[int, List[CompletedNode]]] = []\n    for i, node in enumerate(node_tree.completed_nodes):\n        if i == 0:\n            # no alternative for root node\n            continue\n        if node.train_arr_hash() in visited_node_hashes:\n            same_hash_node_dicts = visited_node_hashes[node.train_arr_hash()]\n            alternative_nodes = [n for all_hash, n in same_hash_node_dicts.items() if all_hash != node.all_arr_hash()]\n            depth_alternative_nodes_pairs.append((i, alternative_nodes))\n\n    if verbose:\n        print(f'alternative_nodes:')\n        for i, alternative_nodes in depth_alternative_nodes_pairs:\n            for n in alternative_nodes:\n                print(f'node_depth: {i}, {n}')\n\n    candidate_node_trees = [node_tree]\n    for i, alternative_nodes in depth_alternative_nodes_pairs:\n        if len(candidate_node_trees) > 1000:\n            break  # TODO Too many candidate_node_trees causes Memory Error.\n        for n in alternative_nodes:\n            candidate_node_trees += [NodeTree.replaced_new_node_tree(t, i, n) for t in candidate_node_trees]\n\n    if verbose:\n        print('node_tree:')\n        print(node_tree)\n        print('candidate_node_trees:')\n        for c in candidate_node_trees:\n            print('===')\n            print(c)\n\n    # TODO unnecessary filter?\n    candidate_node_trees = [t for t in candidate_node_trees if AnswerMatcher.is_train_all_match_if_operated(raw_task, t.to_operation_set())]\n    candidate_node_trees = sorted(candidate_node_trees, key=lambda t: OperationSetEvaluator().evaluate(t.to_operation_set()))\n\n    result_applied_tasks = []\n    for t in candidate_node_trees:\n        try:\n            applied_task = TaskOperationSetExecutor().execute(raw_task, t.to_operation_set())\n        except OperationInconsistencyException:\n            continue\n\n        if any(applied_task.test_arr_hash() == t.test_arr_hash() for t in result_applied_tasks):\n            continue\n\n        result_applied_tasks.append(applied_task)\n        yield t\n\n\nclass ColorChannelOverrideOperation(ChannelMergeOperation):\n\n    def __call__(self, arr: np.ndarray, original_color_mask_paris: List[Tuple[Color, np.ndarray]], color_mask_pairs: List[Tuple[Color, np.ndarray]]) -> np.ndarray:\n        diff_mask_paris = [(c1, np.logical_and(np.logical_xor(o_m, c_m), c_m))\n                           for (c1, o_m), (c2, c_m) in zip(sorted(original_color_mask_paris, key=itemgetter(0)),\n                                                           sorted(color_mask_pairs, key=itemgetter(0)))]  # TODO should groupby color?\n\n        check_mask = np.full_like(diff_mask_paris[0][1], fill_value=False)\n\n        # If duplicated, InconsistencyException\n        for _, m in diff_mask_paris:\n            if check_mask[m].any():\n                raise OperationInconsistencyException('failed channel merge')\n            check_mask[m] = True\n\n        for c, m in diff_mask_paris:\n            arr[m] = c\n\n        return arr\n\n\n@dataclass\nclass NodeEvaluatorSchedule:\n    start_sec: int\n    evaluator: Optional[NodeEvaluator]\n\n\n@dataclass\nclass NodeEvaluatorSchedules:\n    schedules: List[NodeEvaluatorSchedule]\n\n    def pop_evaluator(self) -> Optional[NodeEvaluator]:\n        evaluator = self.schedules[0].evaluator\n        self.schedules = self.schedules[1:]\n        return evaluator\n\n    def next_timing(self):\n        return self.schedules[0].start_sec\n\n    def timeout_sec(self):\n        return self.schedules[-1].start_sec\n\n\ndef get_schedule(operation_element_prob_dict: Dict[str, float], node_search_engine_param, dist_eval_param) -> NodeEvaluatorSchedules:\n    if RunConfig.RUN_MODE == RunMode.KERNEL:\n        if RunConfig.ENGINE_SCHEDULE_PATTERN == EngineSchedulePattern.HAND_MADE:\n            return NodeEvaluatorSchedules([\n                NodeEvaluatorSchedule(0, HandMadeNodeEvaluator(DepthSearchPattern.BREADTH_FIRST, operation_element_prob_dict, node_search_engine_param, dist_eval_param)),\n                NodeEvaluatorSchedule(60 * 1, HandMadeNodeEvaluator(DepthSearchPattern.NORMAL, operation_element_prob_dict, node_search_engine_param, dist_eval_param)),\n                NodeEvaluatorSchedule(60 * 2, HandMadeNodeEvaluator(DepthSearchPattern.DEPTH_FIRST, operation_element_prob_dict, node_search_engine_param, dist_eval_param)),\n                NodeEvaluatorSchedule(60 * 3, None),\n            ])\n        if RunConfig.ENGINE_SCHEDULE_PATTERN == EngineSchedulePattern.DRY_RUN:\n            return NodeEvaluatorSchedules([\n                NodeEvaluatorSchedule(0, HandMadeNodeEvaluator(DepthSearchPattern.BREADTH_FIRST, operation_element_prob_dict, node_search_engine_param, dist_eval_param)),\n                NodeEvaluatorSchedule(3, None),\n            ])\n    else:\n        if RunConfig.ENGINE_SCHEDULE_PATTERN == EngineSchedulePattern.HAND_MADE:\n            return NodeEvaluatorSchedules([\n                NodeEvaluatorSchedule(0, HandMadeNodeEvaluator(DepthSearchPattern.BREADTH_FIRST, operation_element_prob_dict, node_search_engine_param, dist_eval_param)),\n                NodeEvaluatorSchedule(20, HandMadeNodeEvaluator(DepthSearchPattern.NORMAL, operation_element_prob_dict, node_search_engine_param, dist_eval_param)),\n                NodeEvaluatorSchedule(40, HandMadeNodeEvaluator(DepthSearchPattern.DEPTH_FIRST, operation_element_prob_dict, node_search_engine_param, dist_eval_param)),\n                NodeEvaluatorSchedule(60, None),\n            ])\n        if RunConfig.ENGINE_SCHEDULE_PATTERN == EngineSchedulePattern.ML:\n            return NodeEvaluatorSchedules([\n                NodeEvaluatorSchedule(0, MLNodeEvaluator(DepthSearchPattern.BREADTH_FIRST)),\n                NodeEvaluatorSchedule(20, MLNodeEvaluator(DepthSearchPattern.NORMAL)),\n                NodeEvaluatorSchedule(40, MLNodeEvaluator(DepthSearchPattern.DEPTH_FIRST)),\n                NodeEvaluatorSchedule(60, None),\n            ])\n        if RunConfig.ENGINE_SCHEDULE_PATTERN == EngineSchedulePattern.DRY_RUN:\n            return NodeEvaluatorSchedules([\n                NodeEvaluatorSchedule(0, HandMadeNodeEvaluator(DepthSearchPattern.BREADTH_FIRST, operation_element_prob_dict, node_search_engine_param, dist_eval_param)),\n                NodeEvaluatorSchedule(3, None),\n            ])\n    raise NotImplementedError()\n\n\ndef optimize_node_base_search(tasks: List[Task]):\n    assert RunConfig.ENGINE_TYPE == EngineType.NODE_BASED_SEARCH_ENGINE\n\n    def objective(trial: Trial):\n        param = AllParameter(\n            # distance_evaluator_param=DistanceEvaluatorParameter(\n            #     same_h_w_dim_between_input_output=trial.suggest_loguniform('same_h_w_dim_between_input_output', 100, 10000),\n            #     all_dim_h_w_integer_multiple=trial.suggest_loguniform('all_dim_h_w_integer_multiple', 10, 1000),\n            #     mean_lack_color_num=trial.suggest_loguniform('mean_lack_color_num', 1, 100),\n            #     mean_excess_color_num=trial.suggest_loguniform('mean_excess_color_num', 1, 100),\n            #     mean_hit_and_miss_histogram_diff=trial.suggest_loguniform('mean_hit_and_miss_histogram_diff', 1, 100),\n            #     mean_h_v_diff_input_arr_line_num=trial.suggest_loguniform('mean_h_v_diff_input_arr_line_num', 1, 100),\n            #     mean_h_v_diff_output_arr_line_num=trial.suggest_loguniform('mean_h_v_diff_output_arr_line_num', 1, 100),\n            #     mean_h_v_edge_sum_diff=trial.suggest_discrete_uniform('mean_h_v_edge_sum_diff', 0, 2, 0.5),\n            #     mean_h_v_edge_sum_diff_ratio=trial.suggest_discrete_uniform('mean_h_v_edge_sum_diff_ratio', 0, 2, 0.5),\n            # mean_diff_cell_where_no_need_to_change_count_ratio=trial.suggest_loguniform('mean_diff_cell_where_no_need_to_change_count_ratio', 1, 100000),\n            # ),\n\n            node_base_engine_param=NodeBaseSearchEngineParameter(\n                # breadth_first_cost=trial.suggest_loguniform('breadth_first_cost', 1000, 100000),\n                normal_first_cost=trial.suggest_loguniform('normal_first_cost', 10, 1000),\n                depth_first_cost=trial.suggest_loguniform('depth_first_cost', 0.1, 10),\n                # breadth_first_exp_cost=trial.suggest_loguniform('exp_cost', 0.001, 3),\n                # normal_exp_cost=trial.params['exp_cost'],\n                # depth_first_exp_cost=trial.params['exp_cost'],\n                pq_pop_mins_or_as_least_n=trial.suggest_int('pq_pop_mins_or_as_least_n', 1, 10),\n                #     element_inclusion_prob_factor=trial.suggest_loguniform('element_inclusion_prob_factor', 0.001, 10000000),\n            )\n        )\n\n        print(trial.params)\n\n        engine_results = solve_tasks(tasks, param, add_answer_storage=True)\n        answered_results = [r for r in engine_results if isinstance(r, AnsweredSearchResults)]\n        true_results = [r for r in engine_results if r.final_test_correct()]\n\n        all_len = len(engine_results)\n        true_len = len(true_results)\n        false_len = len(answered_results) - len(true_results)\n        none_len = len(engine_results) - len(answered_results)\n\n        print(trial.params)\n        print(f'true: {true_len}, false: {false_len}, none: {none_len}, all: {all_len}')\n        return all_len - true_len - false_len \/ 2\n\n    study = optuna.create_study()\n    study.optimize(objective, n_trials=1000)\n\n    print(study.best_params)\n\n\ndef optimize_tree_base_search(tasks: List[Task]):\n    assert RunConfig.ENGINE_TYPE == EngineType.TREE_BASED_SEARCH_ENGINE\n\n    def objective(trial: Trial):\n        all_parameter = AllParameter(\n            tree_base_engine_param=TreeBaseSearchEngineParameter(\n                population_num=trial.suggest_int('population_num', 20, 80),\n                max_depth=trial.suggest_int('max_depth', 6, 10),\n                operation_mutation_prob=trial.suggest_loguniform('operation_mutation_prob', 0.01, 0.5),\n                operation_component_mutation_prob=trial.suggest_loguniform('operation_component_mutation_prob', 0.005, 0.5),\n                operation_param_mutation_prob=trial.suggest_loguniform('operation_param_mutation_prob', 0.001, 0.5),\n                extend_mutation_prob=trial.suggest_loguniform('extend_mutation_prob', 0.01, 1),\n                shrink_mutation_prob=trial.suggest_loguniform('shrink_mutation_prob', 0.001, 0.1),\n            ))\n        print(trial.params)\n\n        engine_results = solve_tasks(tasks, all_parameter, add_answer_storage=True)\n        answered_results = [r for r in engine_results if isinstance(r, AnsweredSearchResults)]\n        true_results = [r for r in engine_results if r.final_test_correct()]\n\n        all_len = len(engine_results)\n        true_len = len(true_results)\n        false_len = len(answered_results) - len(true_results)\n        none_len = len(engine_results) - len(answered_results)\n\n        print(f'true: {true_len}, false: {false_len}, none: {none_len}, all: {all_len}')\n        return all_len - true_len - false_len \/ 2\n\n    study = optuna.create_study()\n    study.optimize(objective, n_trials=1000)\n\n    print(study.best_params)\n\n\ndef solve_tasks(tasks: List[Task],\n                params: AllParameter,\n                output_summary_path: Optional[Path] = None,\n                save_submission: bool = False,\n                copy_wrong_answers_root_tag: Optional[str] = None,\n                add_answer_storage: bool = False,\n                verbose: bool = False) \\\n        -> List[Union[AnsweredSearchResults, NotAnsweredSearchResult]]:\n    print('===== start parallel solve tasks =====\\n\\n')\n    if RunConfig.N_JOB == 1 or len(tasks) == 1:\n        engine_results = [solve_task(task, params, verbose) for task in tqdm(tasks, miniters=0, mininterval=None, maxinterval=None)]\n    else:\n        # with Pool(processes=RunConfig.N_JOB) as pool:\n        #     args = ((task, verbose) for task in tqdm(tasks, miniters=0, mininterval=None, maxinterval=None))\n        #     engine_results = pool.starmap(solve_task, args)\n\n        # 'multiprocessing' or 'threading'\n        engine_results = Parallel(n_jobs=RunConfig.N_JOB, backend='multiprocessing') \\\n            (delayed(solve_task)(task, params, verbose) for task in tqdm(tasks, miniters=0, mininterval=None, maxinterval=None))\n\n    print('===== end parallel solve tasks =====\\n\\n')\n\n    summary = summary_engine_results(engine_results)\n    print(summary)\n\n    if output_summary_path:\n        output_summary_path.write_text(summary)\n\n    if save_submission:\n        print('start save submission')\n        submission_df = create_submission(engine_results)\n        save_submission_df(submission_df)\n\n    if add_answer_storage:\n        storage_elements = list(chain.from_iterable([r.to_answer_storage_elements() for r in engine_results if isinstance(r, AnsweredSearchResults)]))\n        update_answer_storage(storage_elements)\n\n    if copy_wrong_answers_root_tag:\n        print('start copy wrong answers')\n        for r in engine_results:\n            if not r.final_test_correct():\n                plot_task(r.task, show=False, save_path=PathConfig.WRONG_ANSWERS_ROOT \/ copy_wrong_answers_root_tag \/ f'{r.task.name}.png')\n\n    return engine_results\n\n\ndef solve_task(task: Task, params: AllParameter, verbose: bool = False) -> Union[AnsweredSearchResults, NotAnsweredSearchResult]:\n    try:\n        engine = get_engine(RunConfig.ENGINE_TYPE)\n        engine_result = engine.search(task, params, verbose)\n    except Exception as e:\n        print(f'unknown error {task.name}')\n        raise e\n\n    if isinstance(engine_result, NotAnsweredSearchResult):\n        return engine_result\n    elif isinstance(engine_result, AnsweredSearchResults):\n        # calculate operation_set-executed task.\n        for result in engine_result.results:\n            applied_task = TaskOperationSetExecutor().execute(task, result.operation_set)\n            result.test_output_arr = [io.input_arr for io in applied_task.test]\n            result.test_correct = AnswerMatcher.is_train_test_all_match_if_operated(task, result.operation_set)\n\n        engine_result.results = sorted(engine_result.results, key=lambda r: r.test_correct, reverse=True)\n        print(engine_result.summary())\n        return engine_result\n    else:\n        raise NotImplementedError()\n\n\nclass OperationSetExecutor:\n\n    @classmethod\n    def apply_operation_set(cls, arrays: List[np.ndarray], operation_set: OperationSet) -> List[np.ndarray]:\n        for o in operation_set.operations:\n            arrays = cls.apply_operation(arrays, o)\n\n        return arrays\n\n    @classmethod\n    def apply_operation(cls, arrays: List[np.ndarray], operation: Union[UniformOperation, ColorOperation, MultiColorChannelOperation]) -> List[np.ndarray]:\n        if isinstance(operation, UniformOperation):\n            return cls.apply_uniform_operation(arrays, operation)\n        elif isinstance(operation, ColorOperation):\n            masks = cls.apply_color_selection(arrays, operation.color_selection)\n            masks = cls.apply_mask_conversion(masks, operation.mask_conversions)\n            return cls.apply_mask_operation(arrays, masks, operation.mask_operation)\n        elif isinstance(operation, MultiColorChannelOperation):\n            original_color_mask_pairs_list = cls.apply_channel_selection(arrays, operation.channel_selection)\n            color_mask_pairs_list = deepcopy(original_color_mask_pairs_list)\n            color_mask_pairs_list = cls.apply_color_channel_mask_conversion(color_mask_pairs_list, operation.mask_conversions)\n            return cls.apply_channel_merge(arrays, original_color_mask_pairs_list, color_mask_pairs_list, operation.channel_merge_operation)\n        elif isinstance(operation, PartitionOperation):\n            partitioned_arrays_original_location_masks = cls.apply_partition_selection(arrays, operation.partition_selection)\n            return cls.apply_partition_merge_operation(arrays, partitioned_arrays_original_location_masks, operation.partition_merge_operation)\n        else:\n            raise NotImplementedError()\n\n    @classmethod\n    def apply_uniform_operation(cls, arrays: List[np.ndarray], operation: UniformOperation) -> List[np.ndarray]:\n        new_arrays = [cls._apply_uniform_operation(a, operation) for a in arrays]\n\n        if all(np.array_equal(n, r) for n, r in zip(new_arrays, arrays)):\n            raise OperationInconsistencyException(f'no effect. {operation}')\n        return new_arrays\n\n    @classmethod\n    def _apply_uniform_operation(cls, arr: np.ndarray, operation: UniformOperation) -> np.ndarray:\n        cls._check_arr(arr, operation)\n\n        temp_arr = deepcopy(arr)\n        new_arr = operation(temp_arr)\n        cls._check_arr(new_arr, operation)\n        return new_arr\n\n    @classmethod\n    def apply_color_selection(cls, arrays: List[np.ndarray], selection: ColorSelection) -> List[np.ndarray]:\n        return [cls._apply_color_selection(a, selection) for a in arrays]\n\n    @classmethod\n    def _apply_color_selection(cls, arr: np.ndarray, selection: ColorSelection) -> np.ndarray:\n        cls._check_arr(arr, None)\n\n        temp_arr = deepcopy(arr)\n        mask = selection(temp_arr)\n        cls._check_mask(mask, selection)\n        return mask\n\n    @classmethod\n    def apply_channel_selection(cls, arrays: List[np.ndarray], channel_selection: ColorChannelSelection) -> List[List[Tuple[Color, np.ndarray]]]:\n        return [cls._apply_channel_selection(a, channel_selection) for a in arrays]\n\n    @classmethod\n    def _apply_channel_selection(cls, arr: np.ndarray, channel_selection: ColorChannelSelection) -> List[Tuple[Color, np.ndarray]]:\n        cls._check_arr(arr, None)\n\n        temp_arr = deepcopy(arr)\n        color_mask_pairs = channel_selection(temp_arr)\n\n        for c, m in color_mask_pairs:\n            cls._check_mask(m, channel_selection)\n        return color_mask_pairs\n\n    @classmethod\n    def apply_color_channel_mask_conversion(cls, color_mask_pairs_list: List[List[Tuple[Color, np.ndarray]]], mask_conversion: MaskConversion) -> List[List[Tuple[Color, np.ndarray]]]:\n        new_color_mask_pairs_list = [cls._apply_color_channel_mask_conversion(p, mask_conversion) for p in color_mask_pairs_list]\n        # TODO imple\n        # if not isinstance(mask_conversion, NoMaskConversion):\n        #     if all(np.array_equal(n, r) for n, r in zip(new_color_mask_pairs_list, color_mask_pairs_list)):\n        #         raise OperationInconsistencyException(mask_conversion)\n        return new_color_mask_pairs_list\n\n    @classmethod\n    def _apply_color_channel_mask_conversion(cls, color_mask_pairs: List[Tuple[Color, np.ndarray]], mask_conversion: MaskConversion) -> List[Tuple[Color, np.ndarray]]:\n        for c, m in color_mask_pairs:\n            cls._check_mask(m, None)\n\n        temp_color_mask_pairs = deepcopy(color_mask_pairs)\n        temp_color_mask_pairs = [(c, mask_conversion(m)) for c, m in temp_color_mask_pairs]\n\n        for c, m in temp_color_mask_pairs:\n            cls._check_mask(m, mask_conversion)\n\n        return temp_color_mask_pairs\n\n    @classmethod\n    def apply_channel_merge(cls, arrays: List[np.ndarray], original_color_mask_pairs_list: List[List[Tuple[Color, np.ndarray]]], color_mask_pairs_list: List[List[Tuple[Color, np.ndarray]]], merge_operation: ChannelMergeOperation) -> List[np.ndarray]:\n        new_arrays = [cls._apply_channel_merge(arr, o_p, p, merge_operation) for arr, o_p, p in zip(arrays, original_color_mask_pairs_list, color_mask_pairs_list)]\n\n        if all(np.array_equal(n, r) for n, r in zip(new_arrays, arrays)):\n            raise OperationInconsistencyException(f'no effect. {merge_operation}')\n        return new_arrays\n\n    @classmethod\n    def _apply_channel_merge(cls, arr: np.ndarray, original_color_mask_pairs: List[Tuple[Color, np.ndarray]], color_mask_pairs: List[Tuple[Color, np.ndarray]], merge_operation: ChannelMergeOperation) -> np.ndarray:\n        cls._check_arr(arr, None)\n        for c, m in color_mask_pairs:\n            cls._check_mask(m, None)\n\n        temp_arr = deepcopy(arr)\n        temp_original_color_mask_pairs = deepcopy(original_color_mask_pairs)\n        temp_color_mask_pairs = deepcopy(color_mask_pairs)\n\n        new_arr = merge_operation(temp_arr, temp_original_color_mask_pairs, temp_color_mask_pairs)\n        cls._check_arr(new_arr, merge_operation)\n        return new_arr\n\n    @classmethod\n    def apply_mask_conversion(cls, masks: List[np.ndarray], mask_conversion: MaskConversion) -> List[np.ndarray]:\n        new_masks = [cls._mask_conversion(m, mask_conversion) for m in masks]\n        if not isinstance(mask_conversion, NoMaskConversion):\n            if all(np.array_equal(n, r) for n, r in zip(new_masks, masks)):\n                raise OperationInconsistencyException(f'no effect. {mask_conversion}')\n        return new_masks\n\n    @classmethod\n    def _mask_conversion(cls, mask: np.ndarray, mask_conversion: MaskConversion) -> np.ndarray:\n        cls._check_mask(mask, None)\n\n        temp_mask = deepcopy(mask)\n        applied_mask = mask_conversion(temp_mask)\n        cls._check_mask(applied_mask, mask_conversion)\n        return applied_mask\n\n    @classmethod\n    def apply_mask_operation(cls, arrays: List[np.ndarray], masks: List[np.ndarray], mask_operation: MaskOperation) -> List[np.ndarray]:\n        new_arrays = [cls._apply_mask_operation(a, m, mask_operation) for a, m in zip(arrays, masks)]\n        if all(np.array_equal(n, r) for n, r in zip(new_arrays, arrays)):\n            raise OperationInconsistencyException(f'no effect. {mask_operation}')\n        return new_arrays\n\n    @classmethod\n    def _apply_mask_operation(cls, arr: np.ndarray, mask: np.ndarray, mask_operation: MaskOperation) -> np.ndarray:\n        cls._check_arr(arr, None)\n        cls._check_mask(mask, None)\n\n        temp_arr, temp_mask = deepcopy(arr), deepcopy(mask)\n        applied_arr = mask_operation(temp_arr, temp_mask)\n        cls._check_arr(applied_arr, mask_operation)\n        return applied_arr\n\n    @staticmethod\n    def _check_arr(arr: np.ndarray, operation: Optional[UniformOperation]):\n        # TODO Just for assertion and debug. This function spends some time. Should remove this function at the end of competition?\n        assert isinstance(arr, np.ndarray), f'operation: {operation}, type: {type(arr)}'\n        assert arr.dtype == np.uint8, f'operation: {operation}, dtype: {arr.dtype}'\n        assert arr.size != 0, f'operation: {operation}, operation_result: \\n{arr}'\n        assert 0 <= np.min(arr) <= np.max(arr) <= 10, f'operation: {operation}, operation_result: \\n{arr}'\n        assert len(arr.shape) == 2, f'operation: {operation}, operation_result: \\n{arr}'\n\n    @staticmethod\n    def _check_mask(mask: np.ndarray, operation: Union[ColorSelection, MaskConversion, None]):\n        # TODO Just for assertion and debug. This function spends some time. Should remove this function at the end of competition?\n        assert isinstance(mask, np.ndarray), f'selection: {operation}, type: {type(mask)}'\n        assert mask.dtype == bool, f'selection: {operation}, dtype: {mask.dtype}'\n        assert len(mask.shape) == 2, f'selection: {operation}, result: \\n{mask}'\n\n    @classmethod\n    def apply_partition_selection(cls, arrays: List[np.ndarray], partition_selection: PartitionSelection) -> List[Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]]:\n        return [cls._apply_partition_selection(a, partition_selection) for a in arrays]\n\n    @classmethod\n    def _apply_partition_selection(cls, arr: np.ndarray, partition_selection: PartitionSelection) -> Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]:\n        cls._check_arr(arr, None)\n        temp_arr = deepcopy(arr)\n        return partition_selection(temp_arr)\n\n    @classmethod\n    def apply_partition_merge_operation(cls, arrays: List[np.ndarray], partitioned_arrays_original_location_masks: List[Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]], partition_merge_operation: PartitionMergeOperation):\n        return [cls._apply_partition_merge_operation(a, p, partition_merge_operation) for a, p in zip(arrays, partitioned_arrays_original_location_masks)]\n\n    @classmethod\n    def _apply_partition_merge_operation(cls, arr: np.ndarray, partitioned_arrays_original_location_masks: Tuple[List[List[np.ndarray]], List[List[np.ndarray]]], partition_merge_operation: PartitionMergeOperation):\n        partitioned_arrays, original_location_masks = partitioned_arrays_original_location_masks\n\n        cls._check_arr(arr, None)\n        temp_arr = deepcopy(arr)\n        temp_partitioned_arrays = deepcopy(partitioned_arrays)\n        temp_original_location_masks = deepcopy(original_location_masks)\n\n        res_arr = partition_merge_operation(temp_arr, temp_partitioned_arrays, temp_original_location_masks)\n        cls._check_arr(res_arr, partition_merge_operation)\n\n        return res_arr\n\n\nclass MLNodeEvaluator(NodeEvaluator):\n\n    def __init__(self, pattern: DepthSearchPattern):\n        self.pattern = pattern\n        self.features = pickle.load(PathConfig.NODE_EVALUATOR_FEATURES.open(mode='rb'))\n        self.categorical_features = pickle.load(PathConfig.NODE_EVALUATOR_CATEGORICAL_FEATURES.open(mode='rb'))\n        self.sample_df = pickle.load(PathConfig.NODE_EVALUATOR_SAMPLE_DF.open(mode='rb'))\n        self.model: LGBMClassifier = pickle.load(PathConfig.NODE_EVALUATOR_MODEL.open(mode='rb'))\n        self.model.n_jobs = 1\n        self.oe: OrdinalEncoder = pickle.load(PathConfig.NODE_EVALUATOR_ORDINAL_ENCODER.open(mode='rb'))\n\n    def evaluate(self, node: WaitingNode) -> float:\n        raise NotImplementedError()\n\n    def evaluate_nodes(self, nodes: List[WaitingNode]):\n        if len(nodes) == 0:\n            return\n\n        feature_dicts = [n.evaluation_features() for n in nodes]\n\n        feature_dicts = [{\n            **{k: v for k, v in d.items() if k in self.features},\n            **{f: None for f in self.features if f not in d}\n        } for d in feature_dicts]\n\n        for d in feature_dicts:\n            for c_f in self.categorical_features:\n                d[c_f] = str(d[c_f])\n\n        df = DataFrame(columns=self.features)\n        df = df.append(feature_dicts)\n\n        df[self.categorical_features] = self.oe.transform(df[self.categorical_features])\n        df = df.fillna(-1)\n\n        x = df[self.features]\n        probs = self.model.predict_proba(x)[:, 0]\n\n        for n, p in zip(nodes, probs):\n            n.cache_pred_distance = self._add_cost(p, n.depth())\n\n    def _add_cost(self, prob: float, depth: int) -> float:\n        # Impose penalty. A* like algorithm.\n        if self.pattern == DepthSearchPattern.BREADTH_FIRST:\n            return prob ** (1 \/ (1 + (depth \/ 1))) + 0.3 * depth\n        elif self.pattern == DepthSearchPattern.NORMAL:\n            return prob ** (1 \/ (1 + (depth \/ 2))) + 0.1 * depth\n        elif self.pattern == DepthSearchPattern.DEPTH_FIRST:\n            return prob\n        else:\n            raise NotImplementedError()\n\n\n@dataclass(frozen=True)\nclass LinePartition(PartitionSelection):\n    line_color: Color\n\n    def __call__(self, arr: np.ndarray) -> Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]:\n        if arr.size == 1:\n            raise OperationInconsistencyException('size == 1')\n\n        if 1 in arr.shape and len(np.unique(arr)) == 1:\n            raise OperationInconsistencyException('can not separate')\n\n        color_hit: np.ndarray = arr == self.line_color\n        line_v_indices = np.where(color_hit.all(axis=1))[0]\n        line_h_indices = np.where(color_hit.all(axis=0))[0]\n\n        if len(line_v_indices) == len(line_h_indices) == 0:\n            raise OperationInconsistencyException('not line found')\n\n        if 1 in np.diff(line_v_indices) or 1 in np.diff(line_h_indices):\n            raise OperationInconsistencyException('line duplicated')\n\n        partitioned_arrays = []\n        partitioned_masks = []\n        for start_v_i, end_v_i in zip([0] + list(line_v_indices + 1), list(line_v_indices) + [arr.shape[0]]):\n            if start_v_i == end_v_i:\n                continue\n            partitioned_temp_arrays = []\n            partitioned_temp_masks = []\n            for start_h_i, end_h_i in zip([0] + list(line_h_indices + 1), list(line_h_indices) + [arr.shape[1]]):\n                if start_h_i == end_h_i:\n                    continue\n                partitioned_temp_arrays.append(arr[start_v_i:end_v_i, start_h_i:end_h_i])\n\n                mask = np.full_like(arr, fill_value=False, dtype=bool)\n                mask[start_v_i:end_v_i, start_h_i:end_h_i] = True\n                partitioned_temp_masks.append(mask)\n\n            partitioned_arrays.append(partitioned_temp_arrays)\n            partitioned_masks.append(partitioned_temp_masks)\n\n        return partitioned_arrays, partitioned_masks\n\n\n@dataclass(frozen=True)\nclass GeneralizedLinePartition(PartitionSelection):\n    bg_selection_mode: BackGroundColorSelectionMode\n\n    def __call__(self, arr: np.ndarray) -> Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]:\n        if arr.size == 1:\n            raise OperationInconsistencyException('size == 1')\n\n        if 1 in arr.shape and len(np.unique(arr)) == 1:\n            raise OperationInconsistencyException('can not separate')\n\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        colors = [Color.of(c) for c in np.unique(arr)]\n\n        color_lines = []\n        for c in colors:\n            if c == bg:\n                continue\n            color_hit: np.ndarray = arr == c\n            line_v_indices = np.where(color_hit.all(axis=1))[0]\n            line_h_indices = np.where(color_hit.all(axis=0))[0]\n            color_lines.append((c, len(line_v_indices) + len(line_h_indices)))\n\n        if len(color_lines) == 0:\n            raise OperationInconsistencyException('not colored')\n\n        target_color = max(color_lines, key=itemgetter(1))[0]\n\n        return LinePartition(target_color)(arr)\n\n\n@dataclass(frozen=True)\nclass IntegerDivisionPartition(PartitionSelection):\n    axis: Axis\n    n_split: int\n\n    def __call__(self, arr: np.ndarray) -> Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]:\n        if self.axis == Axis.HORIZONTAL:\n            if arr.shape[1] % self.n_split != 0:\n                raise OperationInconsistencyException('can not divide')\n\n            masks = []\n            partition_len = arr.shape[1] \/\/ self.n_split\n            for i in range(self.n_split):\n                mask = np.full_like(arr, fill_value=False, dtype=bool)\n                start_i, end_i = i * partition_len, (i + 1) * partition_len\n                mask[:, start_i:end_i] = True\n                masks.append(mask)\n            masks = [masks]\n\n            partitioned_arrays = np.split(arr, self.n_split, axis=1)\n            partitioned_arrays = [partitioned_arrays]\n\n        elif self.axis == Axis.VERTICAL:\n            if arr.shape[0] % self.n_split != 0:\n                raise OperationInconsistencyException('can not divide')\n\n            masks = []\n            partition_len = arr.shape[0] \/\/ self.n_split\n            for i in range(self.n_split):\n                mask = np.full_like(arr, fill_value=False, dtype=bool)\n                start_i, end_i = i * partition_len, (i + 1) * partition_len\n                mask[start_i:end_i, :] = True\n                masks.append(mask)\n            masks = [[m] for m in masks]\n\n            partitioned_arrays = np.split(arr, self.n_split, axis=0)\n            partitioned_arrays = [[a] for a in partitioned_arrays]\n        elif self.axis == Axis.BOTH:\n            if arr.shape[0] % self.n_split != 0 or arr.shape[1] % self.n_split != 0:\n                raise OperationInconsistencyException('can not divide')\n\n            masks = []\n            v_partition_len = arr.shape[0] \/\/ self.n_split\n            h_partition_len = arr.shape[1] \/\/ self.n_split\n            for i in range(self.n_split):\n                temp_masks = []\n                v_start_i, v_end_i = i * v_partition_len, (i + 1) * v_partition_len\n                for j in range(self.n_split):\n                    mask = np.full_like(arr, fill_value=False, dtype=bool)\n                    h_start_i, h_end_i = j * h_partition_len, (j + 1) * h_partition_len\n                    mask[v_start_i:v_end_i, h_start_i:h_end_i] = True\n                    temp_masks.append(mask)\n                masks.append(temp_masks)\n\n            partitioned_arrays = np.split(arr, self.n_split, axis=0)\n            partitioned_arrays = [np.split(a, self.n_split, axis=1) for a in partitioned_arrays]\n\n        else:\n            raise NotImplementedError()\n\n        return partitioned_arrays, masks\n\n\n@dataclass(frozen=True)\nclass ColorNumIntegerDivisionPartition(PartitionSelection):\n    axis: Axis\n\n    def __call__(self, arr: np.ndarray) -> Tuple[List[List[np.ndarray]], List[List[np.ndarray]]]:\n        color_num = len(np.unique(arr))\n        color_num = color_num - 1  # bg\n\n        if color_num == 0:\n            raise OperationInconsistencyException('not colored')\n\n        return IntegerDivisionPartition(self.axis, color_num)(arr)\n\n\n@dataclass\nclass RandomNodeTreeCreateEngine:\n    MAX_NODE = 30000\n    timeout_sec: int = 30\n    node_evaluator = RandomNodeEvaluator()\n\n    def search(self, task: Task, verbose: bool = False) -> List[NodeTree]:\n        task_feature = TaskFeature.of(task)\n        root_node = UniformOperationCompletedNode(None, task, task_feature, OperationSet([]))\n        first_waiting_nodes = CompletedNodeProcessor.process(root_node)\n        self.node_evaluator.evaluate_nodes(first_waiting_nodes)\n        pq = PriorityQueue([*first_waiting_nodes])\n\n        if verbose:\n            print('first pq nodes')\n            for n in pq.sorted_list():\n                print(f'cost: {n.cache_pred_distance}, {n}')\n\n        with Timer() as timer:\n            for node_i in range(self.MAX_NODE):\n                if len(pq) == 0:\n                    # TODO What's the right thing to do?\n                    raise NotImplementedError()\n\n                waiting_node = pq.pop_min()\n\n                completed_node = WaitingNodeProcessor().process(waiting_node)\n\n                if completed_node is None:\n                    if verbose:\n                        print('skipped')\n                    continue\n\n                waiting_new_nodes = CompletedNodeProcessor.process(completed_node)\n                self.node_evaluator.evaluate_nodes(waiting_new_nodes)\n\n                for n in waiting_new_nodes:\n                    pq.push(n)\n\n                if timer.second() > self.timeout_sec:\n                    break\n\n        return [NodeTree.of(waiting_node.parent_completed_node) for waiting_node in pq.heap]\n\n\n@dataclass(frozen=True)\nclass AnySelectionMerge(PartitionMergeOperation):\n    bg_selection_mode: BackGroundColorSelectionMode\n    fill_color: Color\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        shape = partitioned_arrays[0][0].shape\n        if not all(a.shape == shape for h_a in partitioned_arrays for a in h_a):\n            raise OperationInconsistencyException('not same shape')\n\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        result_mask = np.full_like(partitioned_arrays[0][0], fill_value=False, dtype=bool)\n        for horizontal_arrays in partitioned_arrays:\n            for a in horizontal_arrays:\n                result_mask[a != bg] = True\n\n        result_arr = np.full_like(partitioned_arrays[0][0], fill_value=bg)\n        result_arr[result_mask] = self.fill_color\n\n        return result_arr\n\n\n@dataclass(frozen=True)\nclass NotSelectionMerge(PartitionMergeOperation):\n    bg_selection_mode: BackGroundColorSelectionMode\n    fill_color: Color\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        shape = partitioned_arrays[0][0].shape\n        if not all(a.shape == shape for h_a in partitioned_arrays for a in h_a):\n            raise OperationInconsistencyException('not same shape')\n\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        result_mask = np.full_like(partitioned_arrays[0][0], fill_value=True, dtype=bool)\n        for horizontal_arrays in partitioned_arrays:\n            for a in horizontal_arrays:\n                result_mask[a != bg] = False\n\n        result_arr = np.full_like(partitioned_arrays[0][0], fill_value=bg)\n        result_arr[result_mask] = self.fill_color\n\n        return result_arr\n\n\n@dataclass(frozen=True)\nclass AllSelectionMerge(PartitionMergeOperation):\n    bg_selection_mode: BackGroundColorSelectionMode\n    fill_color: Color\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        shape = partitioned_arrays[0][0].shape\n        if not all(a.shape == shape for h_a in partitioned_arrays for a in h_a):\n            raise OperationInconsistencyException('not same shape')\n\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        result_mask = np.full_like(partitioned_arrays[0][0], fill_value=True, dtype=bool)\n        for horizontal_arrays in partitioned_arrays:\n            for a in horizontal_arrays:\n                result_mask[a == bg] = False\n\n        result_arr = np.full_like(partitioned_arrays[0][0], fill_value=bg)\n        result_arr[result_mask] = self.fill_color\n\n        return result_arr\n\n\n@dataclass(frozen=True)\nclass ModifiedXorSelectionMerge(PartitionMergeOperation):\n    bg_selection_mode: BackGroundColorSelectionMode\n    fill_color: Color\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        shape = partitioned_arrays[0][0].shape\n        if not all(a.shape == shape for h_a in partitioned_arrays for a in h_a):\n            raise OperationInconsistencyException('not same shape')\n\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        any_result_mask = np.full_like(partitioned_arrays[0][0], fill_value=False, dtype=bool)\n        for horizontal_arrays in partitioned_arrays:\n            for a in horizontal_arrays:\n                any_result_mask[a != bg] = True\n\n        all_result_mask = np.full_like(partitioned_arrays[0][0], fill_value=True, dtype=bool)\n        for horizontal_arrays in partitioned_arrays:\n            for a in horizontal_arrays:\n                all_result_mask[a == bg] = False\n\n        # modified xor\n        result_mask = any_result_mask\n        result_mask[all_result_mask] = False\n\n        result_arr = np.full_like(partitioned_arrays[0][0], fill_value=bg)\n        result_arr[result_mask] = self.fill_color\n\n        return result_arr\n\n\n@dataclass(frozen=True)\nclass NaturalArrayOrderedOverrideMerge(PartitionMergeOperation):\n    bg_selection_mode: BackGroundColorSelectionMode\n    start_corner: Corner\n    first_axis: Axis\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        shape = partitioned_arrays[0][0].shape\n        if not all(a.shape == shape for h_a in partitioned_arrays for a in h_a):\n            raise OperationInconsistencyException('not same shape')\n\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        result_arr = np.full_like(partitioned_arrays[0][0], fill_value=bg)\n\n        h, w = len(partitioned_arrays), len(partitioned_arrays[0])\n        for i, j in self.natural_array(h, w, self.start_corner, self.first_axis):\n            array = partitioned_arrays[i][j]\n            result_arr[array != bg] = array[array != bg]\n\n        return result_arr\n\n    def natural_array(self, h: int, w: int, start_corner: Corner, first_axis: Axis) -> List[Tuple[int, int]]:\n        start_ind = get_index(start_corner, h, w)\n\n        vertical_start_ind, horizontal_start_ind = start_ind\n        vertical_end_ind = h - 1 if vertical_start_ind == 0 else 0\n        horizontal_end_ind = w - 1 if horizontal_start_ind == 0 else 0\n        vertical_step = +1 if vertical_start_ind == 0 else -1\n        horizontal_step = +1 if horizontal_start_ind == 0 else -1\n\n        index_orders = []\n        if first_axis == Axis.HORIZONTAL:\n            for i in range_closed(vertical_start_ind, vertical_end_ind, vertical_step):\n                for j in range_closed(horizontal_start_ind, horizontal_end_ind, horizontal_step):\n                    index_orders.append((i, j))\n        elif first_axis == Axis.VERTICAL:\n            for j in range_closed(horizontal_start_ind, horizontal_end_ind, horizontal_step):\n                for i in range_closed(vertical_start_ind, vertical_end_ind, vertical_step):\n                    index_orders.append((i, j))\n        else:\n            raise NotImplementedError()\n\n        assert len(set(index_orders)) == len(index_orders) == h * w, index_orders\n        return index_orders\n\n\n@dataclass(frozen=True)\nclass DiagonalArrayOrderedOverrideMerge(PartitionMergeOperation):\n    bg_selection_mode: BackGroundColorSelectionMode\n    start_corner: Corner\n    first_axis: Axis\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        shape = partitioned_arrays[0][0].shape\n        if not all(a.shape == shape for h_a in partitioned_arrays for a in h_a):\n            raise OperationInconsistencyException('not same shape')\n\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        result_arr = np.full_like(partitioned_arrays[0][0], fill_value=bg)\n\n        h, w = len(partitioned_arrays), len(partitioned_arrays[0])\n        for i, j in self.diagonal_array(h, w, self.start_corner, self.first_axis):\n            array = partitioned_arrays[i][j]\n            result_arr[array != bg] = array[array != bg]\n\n        return result_arr\n\n    def diagonal_array(self, h: int, w: int, start_corner: Corner, first_axis: Axis) -> List[Tuple[int, int]]:\n        start_ind = get_index(start_corner, h, w)\n\n        vertical_start_ind, horizontal_start_ind = start_ind\n        vertical_end_ind = h - 1 if vertical_start_ind == 0 else 0\n        horizontal_end_ind = w - 1 if horizontal_start_ind == 0 else 0\n        vertical_step = +1 if vertical_start_ind == 0 else -1\n        horizontal_step = +1 if horizontal_start_ind == 0 else -1\n\n        index_orders = []\n        if first_axis == Axis.HORIZONTAL:\n            for i in range_closed(vertical_start_ind, vertical_end_ind, vertical_step):\n                for h_num, j in enumerate(range_closed(horizontal_start_ind, horizontal_end_ind, horizontal_step)):\n                    index_orders.append(((i + h_num) % h, j))\n        elif first_axis == Axis.VERTICAL:\n            for j in range_closed(horizontal_start_ind, horizontal_end_ind, horizontal_step):\n                for v_num, i in enumerate(range_closed(vertical_start_ind, vertical_end_ind, vertical_step)):\n                    index_orders.append((i, (j + v_num) % w))\n        else:\n            raise NotImplementedError()\n        assert len(set(index_orders)) == len(index_orders) == h * w, index_orders\n        return index_orders\n\n\n@dataclass(frozen=True)\nclass SpiralArrayOrderedOverrideMerge(PartitionMergeOperation):\n    bg_selection_mode: BackGroundColorSelectionMode\n    start_corner: Corner\n    spiral_direction: SpiralDirection\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        shape = partitioned_arrays[0][0].shape\n        if not all(a.shape == shape for h_a in partitioned_arrays for a in h_a):\n            raise OperationInconsistencyException('not same shape')\n\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        result_arr = np.full_like(partitioned_arrays[0][0], fill_value=bg)\n\n        h, w = len(partitioned_arrays), len(partitioned_arrays[0])\n        for i, j in self.spiral(h, w, self.start_corner, self.spiral_direction):\n            array = partitioned_arrays[i][j]\n            result_arr[array != bg] = array[array != bg]\n\n        return result_arr\n\n    def spiral(self, h: int, w: int, start_corner: Corner, spiral_direction: SpiralDirection) -> List[Tuple[int, int]]:\n        start_ind = get_index(start_corner, h, w)\n\n        index_orders = [start_ind]\n\n        current_ind = start_ind\n        while True:\n            if (start_corner in [Corner.TOP_LEFT, Corner.TOP_RIGHT, Corner.BOTTOM_RIGHT] and spiral_direction == SpiralDirection.CLOCKWISE) \\\n                    or (start_corner == Corner.BOTTOM_LEFT and spiral_direction == SpiralDirection.ANTICLOCKWISE):\n                if valid_index((current_ind[0], current_ind[1] + 1), h, w, index_orders):\n                    direction = Direction.RIGHT\n                elif valid_index((current_ind[0] + 1, current_ind[1]), h, w, index_orders):\n                    direction = Direction.BOTTOM\n                elif valid_index((current_ind[0], current_ind[1] - 1), h, w, index_orders):\n                    direction = Direction.LEFT\n                elif valid_index((current_ind[0] - 1, current_ind[1]), h, w, index_orders):\n                    direction = Direction.TOP\n                else:\n                    break\n            else:\n                if valid_index((current_ind[0] - 1, current_ind[1]), h, w, index_orders):\n                    direction = Direction.TOP\n                elif valid_index((current_ind[0], current_ind[1] - 1), h, w, index_orders):\n                    direction = Direction.LEFT\n                elif valid_index((current_ind[0] + 1, current_ind[1]), h, w, index_orders):\n                    direction = Direction.BOTTOM\n                elif valid_index((current_ind[0], current_ind[1] + 1), h, w, index_orders):\n                    direction = Direction.RIGHT\n                else:\n                    break\n\n            while True:\n                if direction == Direction.RIGHT:\n                    next_ind = (current_ind[0], current_ind[1] + 1)\n                elif direction == Direction.BOTTOM:\n                    next_ind = (current_ind[0] + 1, current_ind[1])\n                elif direction == Direction.LEFT:\n                    next_ind = (current_ind[0], current_ind[1] - 1)\n                elif direction == Direction.TOP:\n                    next_ind = (current_ind[0] - 1, current_ind[1])\n                else:\n                    raise NotImplementedError()\n\n                if valid_index(next_ind, h, w, index_orders):\n                    index_orders.append(next_ind)\n                    current_ind = next_ind\n                else:\n                    break\n\n        assert len(set(index_orders)) == len(index_orders) == h * w, index_orders\n        return index_orders\n\n\n@dataclass(frozen=True)\nclass UniquelySelectedArrayExtraction(PartitionMergeOperation):\n    array_selection: PartitionedArraySelection\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        selections = self.array_selection(arr, partitioned_arrays)\n\n        results = []\n        for h_arrays, h_flags in zip(partitioned_arrays, selections):\n            for array, flag in zip(h_arrays, h_flags):\n                if flag:\n                    results.append(array)\n\n        if len(set(map(lambda a: a.tostring(), results))) == 1:\n            return results[0]\n        else:\n            raise OperationInconsistencyException('not unique')\n\n\n@dataclass(frozen=True)\nclass RestoreOnlySelectedArray(PartitionMergeOperation):\n    bg_selection_mode: BackGroundColorSelectionMode\n    array_selection: PartitionedArraySelection\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        bg = ColorSelectionUtil().get_background_color(arr, self.bg_selection_mode)\n\n        selections = self.array_selection(arr, partitioned_arrays)\n\n        for h_arrays, h_flags, h_locations in zip(partitioned_arrays, selections, original_location_masks):\n            for array, flag, location in zip(h_arrays, h_flags, h_locations):\n                if flag:\n                    arr[location] = array.ravel()\n                else:\n                    arr[location] = bg\n\n        return arr\n\n\n@dataclass(frozen=True)\nclass ExtractOneValueFromPartitionedArray(PartitionMergeOperation):\n\n    def __call__(self, arr: np.ndarray, partitioned_arrays: List[List[np.ndarray]], original_location_masks: List[List[np.ndarray]]) -> np.ndarray:\n        h, w = len(partitioned_arrays), len(partitioned_arrays[0])\n        result_arr = np.zeros_like(partitioned_arrays[0][0], shape=(h, w))\n\n        for i, j in product(range(h), range(w)):\n            array = partitioned_arrays[i][j]\n            extracted_value = ColorSelectionUtil().select_single_color(array, SingleColorSelectionMode.MOST_COMMON)\n            result_arr[i][j] = extracted_value\n\n        return result_arr\n\n\ndef range_closed(start, stop, step):\n    direction = 1 if (step > 0) else -1\n    return range(start, stop + direction, step)\n\n\ndef get_index(corner: Corner, h: int, w: int) -> Tuple[int, int]:\n    if corner == Corner.TOP_LEFT:\n        return 0, 0\n    elif corner == Corner.TOP_RIGHT:\n        return 0, w - 1\n    elif corner == Corner.BOTTOM_RIGHT:\n        return h - 1, w - 1\n    elif corner == Corner.BOTTOM_LEFT:\n        return h - 1, 0\n    else:\n        raise NotImplementedError()\n\n\ndef valid_index(ind2d: Tuple[int, int], h: int, w: int, black_list: List[Tuple[int, int]]) -> bool:\n    if ind2d in black_list:\n        return False\n    if ind2d[0] < 0 or h <= ind2d[0]:\n        return False\n    if ind2d[1] < 0 or w <= ind2d[1]:\n        return False\n    return True\n\n\ndef save_ml_training_data(task: Task, verbose: bool = False):\n    # \u6b63\u89e3\u30c7\u30fc\u30bf\n    correct_node_trees, exception, _ = NodeBaseSearchEngine(answer_limit_num=60).search(task, verbose)\n\n    print('search engine end')\n    if exception is not None:\n        print('answer not found')\n        return\n\n    correct_node_trees = [t for t in correct_node_trees if AnswerMatcher.is_train_test_all_match_if_operated(task, t.to_operation_set())]\n\n    if len(correct_node_trees) == 0:\n        print('answer not found')\n        return\n\n    correct_waiting_nodes = list(chain.from_iterable([t.waiting_nodes() for t in correct_node_trees]))\n    correct_feature_dicts = [n.evaluation_features() for n in correct_waiting_nodes]\n    correct_feature_dict_tuples = set(tuple(sorted(d.items())) for d in correct_feature_dicts)\n    correct_df = DataFrame(dict(t) for t in correct_feature_dict_tuples)\n\n    # \u4e0d\u6b63\u89e3\u30c7\u30fc\u30bf\n    trees = RandomNodeTreeCreateEngine(timeout_sec=120).search(task, verbose)\n    print('random tree generated')\n    waiting_nodes = list(chain.from_iterable([t.waiting_nodes() for t in trees]))\n    feature_dicts = [n.evaluation_features() for n in waiting_nodes]\n\n    feature_dict_tuples = set(tuple(sorted(d.items())) for d in feature_dicts)\n    feature_dict_tuples = feature_dict_tuples - correct_feature_dict_tuples\n    wrong_df = DataFrame(dict(t) for t in feature_dict_tuples)\n\n    # \u30e9\u30d9\u30eb\u4ed8\u3051\n    correct_df['label'] = 1\n    wrong_df['label'] = 0\n    all_df = correct_df.append(wrong_df, sort=False)\n\n    PathConfig.LABELED_TRAINING_DATA_ROOT.mkdir(parents=True, exist_ok=True)\n    pickle.dump(all_df, (PathConfig.LABELED_TRAINING_DATA_ROOT \/ f'{task.name}.pkl').open(mode='wb'))\n    print('save')\n\n\ndef train_ml():\n    x, y, feature_columns, categorical_features = prepare_train_data()\n    train_lgbm(x, y, feature_columns, categorical_features)\n\n\ndef prepare_train_data():\n    dfs = []\n    for pickle_path in PathConfig.LABELED_TRAINING_DATA_ROOT.iterdir():\n        print(pickle_path)\n        dfs.append(pickle.load((pickle_path.open(mode='rb'))))\n    all_df = pd.concat(dfs, ignore_index=True, sort=False)\n\n    print(f'label1: {len(all_df[all_df[\"label\"] == 1])}_label0: {len(all_df[all_df[\"label\"] == 0])}')\n\n    # TODO Should we not use dsl properties(too detailed) features?\n    not_used_feature_columns = {\n        'label', 'depth', 'color', 'angle', 'direction',\n        'multi_color_selection_mode', 'single_color_selection_mode',\n        'edge_type', 'fill_type', 'flip_mode', 'k', 'ratio', 'padding_mode'\n    }\n    feature_columns = sorted(set(all_df.columns) - not_used_feature_columns)\n    all_df = all_df[feature_columns + ['label']]\n\n    # process categorical\n    categorical_features = list(filter(lambda s: s in feature_columns, map(str, all_df.select_dtypes(include='object').columns)))\n\n    for c_f in categorical_features:\n        all_df[c_f] = all_df[c_f].fillna('None')\n        all_df[c_f] = all_df[c_f].apply(str)\n        # all_df[c_f] = all_df[c_f].astype(str)\n        # all_df[c_f] = all_df[c_f].apply(lambda v: str(v))\n        # all_df[c_f] = all_df[c_f].astype('category')\n\n    oe = category_encoders.OrdinalEncoder()\n    all_df[categorical_features] = oe.fit_transform(all_df[categorical_features])\n\n    # oe = category_encoders.OneHotEncoder(cols=[categorical_features])\n    # all_df = oe.fit_transform(all_df)\n\n    # all_df = all_df.fillna(-1)\n\n    # Relabel 0-labeled data in the neighborhood of 1 to 1\n    print('relabelling')\n    small_is_better_features = [\n        'mean_diff_color_cell_ratio',\n        'mean_excess_color_num',\n        'mean_lack_color_num',\n        'mean_horizontal_diff_input_arr_line_num',\n        'mean_horizontal_diff_output_arr_line_num',\n        'mean_horizontal_edge_sum_diff',\n        'mean_horizontal_edge_sum_diff_ratio',\n        'mean_vertical_diff_input_arr_line_num',\n        'mean_vertical_diff_output_arr_line_num',\n        'mean_vertical_edge_sum_diff',\n        'mean_vertical_edge_sum_diff_ratio',\n    ]\n\n    for index, r in tqdm(all_df[all_df['label'] == 1].iterrows()):\n        temp_feature = sorted(set(feature_columns) - set(small_is_better_features))\n\n        near_rows = all_df[(all_df[temp_feature] == r[temp_feature]).all(axis=1)]\n        can_label_1 = near_rows[(near_rows[small_is_better_features] <= r[small_is_better_features]).all(axis=1)]\n\n        all_df.loc[can_label_1.index.values, 'label'] = 1\n\n    print(f'label1: {len(all_df[all_df[\"label\"] == 1])}_label0: {len(all_df[all_df[\"label\"] == 0])}')\n\n    print(f'feature_columns:')\n    for f in feature_columns:\n        print(f)\n\n    x = all_df[feature_columns]\n    y = all_df['label']\n    print(f'len(x): {len(x)}, 1_labelled_len: {len(y[y == 1])}')\n    # x, y = RandomUnderSampler(sampling_strategy=0.01).fit_resample(x, y)\n    # x, y = EditedNearestNeighbours(sampling_strategy=0.01, n_jobs=RunConfig.N_JOB).fit_resample(x, y)\n    print(f'len(x): {len(x)}, 1_labelled_len: {len(y[y == 1])}')\n\n    # visualize\n    # scaled_x = StandardScaler().fit_transform(x)\n    # x_reduced = PCA(n_components=2).fit_transform(scaled_x)\n    # plt.scatter(x_reduced[y == 1, 0], x_reduced[y == 1, 1], alpha=0.1)\n    # plt.scatter(x_reduced[:, 0], x_reduced[:, 1], c=y, alpha=0.1)\n    # plt.show()\n    # plt.close()\n\n    pickle.dump(all_df, PathConfig.NODE_EVALUATOR_SAMPLE_DF.open(mode='wb'))\n    pickle.dump(oe, PathConfig.NODE_EVALUATOR_ORDINAL_ENCODER.open(mode='wb'))\n    pickle.dump(feature_columns, PathConfig.NODE_EVALUATOR_FEATURES.open(mode='wb'))\n    pickle.dump(categorical_features, PathConfig.NODE_EVALUATOR_CATEGORICAL_FEATURES.open(mode='wb'))\n\n    return x, y, feature_columns, categorical_features\n\n\ndef train_lg(feature_columns, x, y):\n    model = LogisticRegression(class_weight='balanced', n_jobs=RunConfig.N_JOB)\n    model.fit(x, y)\n\n    pred_y = model.predict_proba(x)\n    print(pred_y)\n    # cb = CatBoostClassifier(loss_function='Logloss', class_weights=[0.1, 1], cat_features=categorical_features)\n    # cb.fit(x, y)\n    # pred_y = cb.predict_proba(x)\n\n    PathConfig.SAVED_MODEL.mkdir(parents=True, exist_ok=True)\n    pickle.dump(model, PathConfig.NODE_EVALUATOR_MODEL.open(mode='wb'))\n\n    del model\n\n    print(x)\n    print(y)\n    print(pred_y)\n\n    # cb = CatBoostClassifier()\n    # cb.load_model(str(PathConfig.NODE_EVALUATOR_MODEL), format=\"cbm\")\n    model = pickle.load(PathConfig.NODE_EVALUATOR_MODEL.open(mode='rb'))\n    pred_y = model.predict_proba(x)\n\n    print(pred_y)\n\n    coefs = np.abs(model.coef_[0])\n\n    for c, f in zip(coefs, feature_columns):\n        print(f'{f}_{c}')\n\n\ndef train_lgbm(x, y, feature_columns, categorical_features):\n    lgbm_params = {\n        'silent': False, 'n_jobs': RunConfig.N_JOB,\n        'class_weight': 'balanced', 'max_depth': 3, 'learning_rate': 0.2,\n    }\n\n    best_iterations = []\n    folds = KFold(shuffle=False, n_splits=3)\n    for n_fold, (train_index, valid_index) in enumerate(folds.split(x, y)):\n        train_x, train_y = x.iloc[train_index], y.iloc[train_index]\n        valid_x, valid_y = x.iloc[valid_index], y.iloc[valid_index]\n\n        model = LGBMClassifier(n_estimators=1000, **lgbm_params)\n        model.fit(train_x, train_y, eval_set=[(valid_x, valid_y), (train_x, train_y)],\n                  early_stopping_rounds=10, categorical_feature=categorical_features,\n                  verbose=True)\n        best_iterations.append(model.best_iteration_)\n\n    print(best_iterations)\n\n    model = LGBMClassifier(n_estimators=min(best_iterations), **lgbm_params)\n    model.fit(x, y, verbose=True, categorical_feature=categorical_features)\n\n    pred_y = model.predict_proba(x)\n    print(pred_y)\n\n    PathConfig.SAVED_MODEL.mkdir(parents=True, exist_ok=True)\n    pickle.dump(model, PathConfig.NODE_EVALUATOR_MODEL.open(mode='wb'))\n\n    del model\n\n    print(x)\n    print(y)\n    print(pred_y)\n\n    model = pickle.load(PathConfig.NODE_EVALUATOR_MODEL.open(mode='rb'))\n    pred_y = model.predict_proba(x)\n\n    print(pred_y)\n\n    importance = pd.DataFrame(model.feature_importances_, index=feature_columns, columns=['importance'])\n\n    print(importance)\n\n\ndef train_test_model(feature_columns, x, y):\n    try_cv = False\n\n    if try_cv:\n        folds = KFold(shuffle=True)\n        for n_fold, (train_index, valid_index) in enumerate(folds.split(x, y)):\n            train_x, train_y = x.iloc[train_index], y.iloc[train_index]\n            valid_x, valid_y = x.iloc[valid_index], y.iloc[valid_index]\n\n            model = LGBMClassifier(class_weight='balanced', learning_rate=0.2, n_jobs=RunConfig.N_JOB, n_estimators=1000,\n                                   silent=False)\n            model.fit(train_x, train_y, eval_set=[(valid_x, valid_y), (train_x, train_y)],\n                      early_stopping_rounds=10,\n                      verbose=True)\n\n    # model = MLPClassifier(hidden_layer_sizes=(20, 20, 10))\n    model = RidgeClassifier(class_weight='balanced')\n    # model = LinearSVC(class_weight='balanced')\n    # model = LGBMClassifier(class_weight='balanced', learning_rate=0.2, n_estimators=50,\n    #                        silent=False)\n    model.fit(x, y)\n\n    pred_y = model.predict(x)\n    print(pred_y)\n\n    PathConfig.SAVED_MODEL.mkdir(parents=True, exist_ok=True)\n    pickle.dump(model, PathConfig.NODE_EVALUATOR_MODEL.open(mode='wb'))\n\n    del model\n\n    print(x)\n    print(y)\n    print(pred_y)\n\n    model = pickle.load(PathConfig.NODE_EVALUATOR_MODEL.open(mode='rb'))\n    pred_y = model.predict_proba(x)\n\n    print(pred_y)\n\n    importance = pd.DataFrame(model.feature_importances_, index=feature_columns, columns=['importance'])\n\n    print(importance)\n\n\nCATEGORIES = [\n    'PARTITION',\n    'SYMMETRY',\n    'REPEAT',\n    'DENOISE',\n    'SIMPLIFICATION',\n    'NUMBER',\n    'RANKING',\n    'SHAPE',\n    'FIND_FIT',\n    'LINE',\n    'OBJECT_TRANSFORM',\n    'OBJECT_MOVE',\n    'JIGSAW_PUZZLE',\n    'COLOR',\n    'PASTE',\n    'GUIDE',\n    'META',\n    'OTHERS',\n    'ONCE_ANSWERED',\n]\n\n\nGIVE_UPS = [\n    'SYMMETRY',\n    'REPEAT',\n    'DENOISE',\n    'SIMPLIFICATION',\n    'NUMBER',\n    'RANKING',\n    'SHAPE',\n    'FIND_FIT',\n    'OBJECT_MOVE',\n    'JIGSAW_PUZZLE',\n    'COLOR',\n    'PASTE',\n    'GUIDE',\n    'META',\n]\n\n\nclass TaskTaxonomy:\n\n    def __init__(self):\n        with open(str(PathConfig.OPERATION_ANSWER_TAXONOMY_YAML), 'r') as f:\n            yaml_dict = yaml.load(f, Loader=yaml.Loader)\n        self.trains: Dict[str, List[str]] = yaml_dict['1_train']\n        self.evals: Dict[str, List[str]] = yaml_dict['2_eval']\n        self.check()\n\n    def check(self):\n        assert len(self.trains) == len(self.evals) == 400\n\n        for task_name, categories in {**self.trains, **self.evals}.items():\n            assert len(categories) == len(set(categories))\n            for category in categories:\n                assert category in CATEGORIES, category\n\n        json_task_names = {path.stem for path in chain.from_iterable([PathConfig.TRAIN_ROOT.iterdir(), PathConfig.EVALUATION_ROOT.iterdir()])}\n        df_task_names = set(list(self.trains.keys()) + list(self.evals.keys()))\n        assert json_task_names - df_task_names == set(), json_task_names - df_task_names\n        assert df_task_names - json_task_names == set(), df_task_names - json_task_names\n\n    def show_stats(self):\n        print('=== train stats ====')\n        for c in CATEGORIES:\n            num = len(list(filter(lambda v: c in v, self.trains.values())))\n            print(f'{c}: {num}')\n\n        print('\\n=== eval stats ====')\n        for c in CATEGORIES:\n            num = len(list(filter(lambda v: c in v, self.evals.values())))\n            print(f'{c}: {num}')\n\n    def save_yaml(self):\n        self.check()\n\n        with open(str(PathConfig.OPERATION_ANSWER_TAXONOMY_YAML), 'w') as f:\n            yaml.dump({'1_train': self.trains,\n                       '2_eval': self.evals}, f)\n\n    def save_categorized_fig(self):\n        # from abstraction_and_reasoning_challenge.src.loader.task_loader import TaskLoader  # TODO fix local import\uff1f\n        shutil.rmtree(PathConfig.OPERATION_ANSWER_TAXONOMY_IMAGE_ROOT)\n\n        for (task_name, categories), tag in tqdm(list(zip(list(self.trains.items()) + list(self.evals.items()), ['train'] * len(self.trains) + ['evals'] * len(self.evals)))):\n            if categories == []:\n                task = TaskLoader().get_task(task_name)\n                plot_task(task, show=False, save_path=PathConfig.OPERATION_ANSWER_TAXONOMY_IMAGE_ROOT \/ tag \/ 'not_categorized' \/ f'{task_name}.png')\n            for c in categories:\n                task = TaskLoader().get_task(task_name)\n                plot_task(task, show=False, save_path=PathConfig.OPERATION_ANSWER_TAXONOMY_IMAGE_ROOT \/ tag \/ c \/ f'{task_name}.png')\n\n    def get_give_up_task_names(self) -> List[str]:\n        can_answers = self.get_can_answer_task_names()\n        give_up_task_names = []\n        for task_name, categories in {**self.trains, **self.evals}.items():\n            if task_name in can_answers:\n                continue\n            for c in categories:\n                if c in GIVE_UPS:\n                    give_up_task_names.append(task_name)\n                    break\n\n        return give_up_task_names\n\n    def get_can_answer_task_names(self) -> List[str]:\n        return [task_name for task_name, categories in {**self.trains, **self.evals}.items() if 'ONCE_ANSWERED' in categories]\n\n    def filter_tasks(self, tasks: List[Task]) -> List[Task]:\n        if RunConfig.TASK_RANGE == TaskRange.ALL:\n            return tasks\n        elif RunConfig.TASK_RANGE == TaskRange.EXCLUDE_GIVE_UPS:\n            return list(filter(lambda t: t.name not in self.get_give_up_task_names(), tasks))\n        elif RunConfig.TASK_RANGE == TaskRange.CAN_ANSWER_ONLY:\n            return list(filter(lambda t: t.name in self.get_can_answer_task_names(), tasks))\n        else:\n            raise NotImplementedError()\n\n\n\n\ndef get_engine(engine_type: EngineType):\n    if engine_type == EngineType.NODE_BASED_SEARCH_ENGINE:\n        return NodeBaseSearchEngine()\n    elif engine_type == EngineType.TREE_BASED_SEARCH_ENGINE:\n        return TreeBaseSearchEngine()\n    else:\n        raise NotImplementedError()\n\n\ndef run():\n    if debug_run():\n        return\n\n    initialize_path()\n\n    if RunConfig.RUN_MODE == RunMode.LOCAL_RUN:\n        load_answer_storage()  # debug validate\n        tt = TaskTaxonomy()\n        solve_tasks(tt.filter_tasks(TaskLoader().get_training_tasks()), AllParameter(), output_summary_path=PathConfig.OPERATION_ANSWER_MEMO_ROOT \/ 'answer_summary_train.txt', copy_wrong_answers_root_tag='train', add_answer_storage=True, save_submission=True)\n        solve_tasks(tt.filter_tasks(TaskLoader().get_evaluation_tasks()), AllParameter(), output_summary_path=PathConfig.OPERATION_ANSWER_MEMO_ROOT \/ 'answer_summary_eval.txt', copy_wrong_answers_root_tag='eval', add_answer_storage=False, save_submission=False)\n    elif RunConfig.RUN_MODE == RunMode.LOCAL_RUN_ALL:\n        solve_tasks(TaskLoader().get_training_tasks(), AllParameter(), output_summary_path=PathConfig.OPERATION_ANSWER_MEMO_ROOT \/ 'answer_summary_train.txt', copy_wrong_answers_root_tag='train', add_answer_storage=True, save_submission=True)\n        solve_tasks(TaskLoader().get_evaluation_tasks(), AllParameter(), output_summary_path=PathConfig.OPERATION_ANSWER_MEMO_ROOT \/ 'answer_summary_eval.txt', copy_wrong_answers_root_tag='eval', add_answer_storage=False, save_submission=False)\n        solve_tasks(TaskLoader().get_test_tasks(), AllParameter(), save_submission=True)\n    elif RunConfig.RUN_MODE == RunMode.KERNEL_EMULATION:\n        solve_tasks(TaskLoader().get_test_tasks(), AllParameter(), save_submission=True)\n    elif RunConfig.RUN_MODE == RunMode.NODE_BASE_SEARCH_OPTIMIZATION:\n        optimize_node_base_search(TaskLoader().get_training_tasks())\n    elif RunConfig.RUN_MODE == RunMode.TREE_BASE_SEARCH_OPTIMIZATION:\n        optimize_tree_base_search(TaskLoader().get_training_tasks())\n    elif RunConfig.RUN_MODE == RunMode.LOCAL_DATA_GENERATION:\n        for t in TaskLoader().get_training_tasks():\n            print(t.name)\n            save_ml_training_data(t)\n    elif RunConfig.RUN_MODE == RunMode.LOCAL_ML_TRAIN:\n        train_ml()\n    elif RunConfig.RUN_MODE == RunMode.TRAIN_OPERATION_ELEMENT_INCLUSION_PREDICTION:\n        train_operation_element_inclusion_prediction()\n    elif RunConfig.RUN_MODE == RunMode.KERNEL:\n        if RunConfig.RUN_ONLY_PRIVATE_LB and not TaskLoader().is_private_lb_run():\n            print('This is kernel public run. Skipped.')\n            shutil.copy(str(KernelPathConfig.SAMPLE_SUBMISSION), KernelPathConfig.SUBMISSION)\n            return\n        else:\n            print('This is private private run. Not skipped.')\n            solve_tasks(TaskLoader().get_test_tasks(), AllParameter(), save_submission=True)\n    else:\n        raise ValueError(RunConfig.RUN_MODE)\n    print('end')\n\n\ndef debug_run():\n    print('start')\n    if DebugConfig.OPERATION_DEBUG_TASK_NAME:\n        operation_set = str_to_operation_set(DebugConfig.OPERATION_DEBUG_OPERATION_SET)\n        print(operation_set)\n        task = TaskLoader().get_task(DebugConfig.OPERATION_DEBUG_TASK_NAME)\n        applied_task = TaskOperationSetExecutor().execute(task, operation_set)\n\n        original_task_feature = create_task_feature(task, task)\n        applied_task_feature = create_task_feature(task, applied_task)\n\n        original_df = DataFrame(asdict(original_task_feature), index=['index']).T\n        applied_df = DataFrame(asdict(applied_task_feature), index=['index']).T\n        merged_feature_df = pd.merge(original_df, applied_df, left_index=True, right_index=True,\n                                     suffixes=['original_', 'appplied_'])\n\n        original_waiting_node = ColorSelectionWaitingNode(None, task, task, original_task_feature, OperationSet([]), MultiColorSelection(MultiColorSelectionMode.ANY_WITHOUT_MOST_COMMON))\n        # original_waiting_node2 = MaskConversionWaitingNode(None, None, task, original_task_feature, OperationSet([]), SingleColorSelection(SingleColorSelectionMode.LEAST_COMMON))\n        applied_waiting_node = ColorSelectionWaitingNode(None, task, applied_task, applied_task_feature, operation_set, MultiColorSelection(MultiColorSelectionMode.ANY_WITHOUT_MOST_COMMON))\n        print(merged_feature_df)\n\n        print('distance')\n        print(DistanceEvaluator(DistanceEvaluatorParameter()).evaluate_task_feature(original_task_feature))\n        print(DistanceEvaluator(DistanceEvaluatorParameter()).evaluate_task_feature(applied_task_feature))\n\n        print('breadth cost')\n        HandMadeNodeEvaluator(DepthSearchPattern.BREADTH_FIRST, defaultdict(lambda: 1), NodeBaseSearchEngineParameter(), DistanceEvaluatorParameter()).evaluate_nodes([original_waiting_node, original_waiting_node])\n        HandMadeNodeEvaluator(DepthSearchPattern.BREADTH_FIRST, defaultdict(lambda: 1), NodeBaseSearchEngineParameter(), DistanceEvaluatorParameter()).evaluate_nodes([original_waiting_node, applied_waiting_node])\n        print(original_waiting_node.cache_pred_distance)\n        print(applied_waiting_node.cache_pred_distance)\n\n        print('normal cost')\n        HandMadeNodeEvaluator(DepthSearchPattern.NORMAL, defaultdict(lambda: 1), NodeBaseSearchEngineParameter(), DistanceEvaluatorParameter()).evaluate_nodes([original_waiting_node, original_waiting_node])\n        HandMadeNodeEvaluator(DepthSearchPattern.NORMAL, defaultdict(lambda: 1), NodeBaseSearchEngineParameter(), DistanceEvaluatorParameter()).evaluate_nodes([original_waiting_node, applied_waiting_node])\n        print(original_waiting_node.cache_pred_distance)\n        print(applied_waiting_node.cache_pred_distance)\n\n        print('depth cost')\n        HandMadeNodeEvaluator(DepthSearchPattern.DEPTH_FIRST, defaultdict(lambda: 1), NodeBaseSearchEngineParameter(), DistanceEvaluatorParameter()).evaluate_nodes([original_waiting_node, original_waiting_node])\n        HandMadeNodeEvaluator(DepthSearchPattern.DEPTH_FIRST, defaultdict(lambda: 1), NodeBaseSearchEngineParameter(), DistanceEvaluatorParameter()).evaluate_nodes([original_waiting_node, applied_waiting_node])\n        print(original_waiting_node.cache_pred_distance)\n        print(applied_waiting_node.cache_pred_distance)\n\n        plot_task_with_operation_set(task, operation_set, show=True, save_path=None)\n        return True\n\n    if DebugConfig.SOLVE_DEBUG_TASK_NAME:\n        task = TaskLoader().get_task(DebugConfig.SOLVE_DEBUG_TASK_NAME)\n        engine_result = solve_tasks([task], AllParameter(), add_answer_storage=True, verbose=True)[0]\n\n        if isinstance(engine_result, AnsweredSearchResults):\n            plot_task_with_result_set(task, engine_result, show=True, save_path=None)\n        return True\n\n    if DebugConfig.TRAIN_DATA_GENERATION_DEBUG_TASK_NAME:\n        task = TaskLoader().get_task(DebugConfig.TRAIN_DATA_GENERATION_DEBUG_TASK_NAME)\n        save_ml_training_data(task)\n        train_ml(task)\n        return True\n\n    return False\n\n\ndef performance_run():\n    # from line_profiler import LineProfiler\n    # from python_utils.src.library.print_line_profiler import print_stats\n    # from abstraction_and_reasoning_challenge import run as run_module\n    # from abstraction_and_reasoning_challenge.src.domain import task_solver\n    # from abstraction_and_reasoning_challenge.src.domain.search_engine.evaluation_functions import handmade_evaluator\n    # from abstraction_and_reasoning_challenge.src.domain.search_engine.node import waiting_node\n    # from abstraction_and_reasoning_challenge.src.domain.search_engine.node_processor import waiting_node_processor\n    # from abstraction_and_reasoning_challenge.src.domain.feature import task_feature\n    # from abstraction_and_reasoning_challenge.src.domain.search_engine.engine import node_base_search_engine\n    # from abstraction_and_reasoning_challenge.src.domain.search_engine.engine import tree_base_search_engine\n    #\n    # profiler = LineProfiler()\n    # profiler.add_module(run_module)\n    # profiler.add_module(task_solver)\n    # profiler.add_module(handmade_evaluator)\n    # profiler.add_module(waiting_node)\n    # profiler.add_module(waiting_node_processor)\n    # profiler.add_module(task_feature)\n    # profiler.add_module(node_base_search_engine)\n    # profiler.add_module(tree_base_search_engine)\n    #\n    # profiler.runcall(run)\n    # # profiler.print_stats()\n    # stats = profiler.get_stats()\n    # print_stats(stats, strip_seconds_limit=0., cost_sort=True)\n    pass\n\n\nperformance_profiling_mode = False\n\n\nif __name__ == '__main__':\n    run()\n","a2e95b97":"sub = pd.read_csv(\".\/submission_yuki_alignment.csv\")\nprint(sub.shape)\nsub.head(3)","e793821e":"def get_string(pred):\n    str_pred = str([list(row) for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n    \ndef get_string_list(preds):\n    return \" \".join([get_string(pred) for pred in preds])\n\ndef rollback_row(r, test_aligned_tasks = test_aligned_tasks, debug=False):\n    output_id = r[\"output_id\"]\n    output_aligned = str(r[\"output_aligned\"])\n    \n    # |080000|808000|008088|000008| |0| |0| \n    if len(output_aligned) < 10:\n        return \"|00|00| |00|00| |00|00|\"\n    \n    task_id = output_id.split(\"_\")[0]\n    order_id = int(output_id.split(\"_\")[1])\n    \n    task_aligned = test_aligned_tasks[task_id]\n    sample_aligned = task_aligned['test'][order_id]\n    \n    predictions_aligned = output_aligned.split(\" \")\n    def str2list(s):\n        return [int(d) for d in s]\n    predictions_aligned = [[str2list(s) for s in pred.split(\"|\")[1:-1]] \\\n                               for pred in predictions_aligned if len(pred) > 5]\n    \n    predictions = []\n    modified = False\n    for pred_aligned in predictions_aligned:\n        pred = np.array(pred_aligned)\n        if sample_aligned['fliplr']:\n            pred = np.fliplr(pred)\n            modified = True\n        if sample_aligned['flipud']:\n            pred = np.flipud(pred)\n            modified = True\n        if sample_aligned['rot90']:\n            pred = np.rot90(pred, k=3)\n            modified = True\n        predictions.append(pred.tolist())\n\n    output_final = get_string_list(predictions)\n    if debug and modified:\n        print(task_id, order_id)\n    return output_final\n    \ndef rollback_sub(sub):\n    sub2 = sub.copy()\n    sub2[\"output_aligned\"] = sub2[\"output\"]\n    sub2[\"output\"] = sub2.apply(lambda r: rollback_row(r), axis=1) \n    sub2[\"is_modified\"] = sub2.apply(lambda r: 1 if r[\"output_aligned\"] != r[\"output\"] else 0, axis=1) \n    return sub2\n    \nsub2 = rollback_sub(sub)\nprint(sub2[\"is_modified\"].sum())\nsub2.head(3)","874d4944":"sub2[[\"output_id\", \"output\"]].to_csv(\".\/submission_yuki_rollback.csv\", index=None)","f095c653":"sub2 = sub2[[\"output_id\", \"output\"]]\nsub2.set_index('output_id', inplace=True)","db956301":"sample_submission = pd.read_csv('\/kaggle\/input\/abstraction-and-reasoning-challenge\/sample_submission.csv', index_col='output_id')\n\nfor idx, row in sample_submission.iterrows():\n    if idx in sub2.index:\n        sample_submission.loc[idx, 'output'] = sub2.loc[idx, 'output']\n\nsample_submission.to_csv('submission.csv')","8247bc73":"<a id=\"toc\"><\/a>\n# Table of Contents\n1. [Align tasks](#align_tasks)\n1. [Run @yukikubo123's DSL](#run_yuki_dsl)\n1. [Rollback the predictions](#rollback_the_predictions)","d9e952e0":"<a id=\"align_tasks\"><\/a>\n# Align tasks\n[Back to Table of Contents](#toc)","a4d5e446":"<a id=\"rollback_the_predictions\"><\/a>\n# Rollback the predictions\n[Back to Table of Content](#toc)","37c58dfa":"<a id=\"run_yuki_dsl\"><\/a>\n# Run @yukikubo123's DSL\n[Back to Table of Content](#toc)"}}