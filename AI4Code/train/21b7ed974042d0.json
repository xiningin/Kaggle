{"cell_type":{"b29daa72":"code","3ef72a56":"code","7c2cbdb5":"code","ae178a8e":"code","6e38d16e":"code","90628043":"code","c42dfff3":"code","a337c9b1":"code","74b59f22":"code","8d2cc3eb":"code","ba2824f6":"code","63ac6afd":"code","363dce1d":"code","1de96e16":"code","13e03709":"code","5a90d45b":"code","7a9fa4cb":"code","e3989805":"code","98006f35":"code","271c943f":"code","abaaf425":"code","857cceb7":"code","0ad4b810":"code","4c957c59":"code","9fcc73d7":"code","73e9165f":"code","0464ab2d":"code","1dac2bf2":"code","f909d6b1":"code","27c531da":"code","7cc56145":"markdown","8e734267":"markdown","5f799467":"markdown","f2a74483":"markdown","57ca21d2":"markdown","52840aca":"markdown","5054b3c0":"markdown","1812c992":"markdown","9c1bbd1c":"markdown","d4ee9b24":"markdown","51a340b0":"markdown","f8044f9f":"markdown","16c3517b":"markdown","baa2b5cf":"markdown","1c5a7bab":"markdown","39540a8a":"markdown","2e7b84b6":"markdown"},"source":{"b29daa72":"from collections import Counter\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix,matthews_corrcoef\nimport imblearn\nfrom sklearn.model_selection import cross_val_score","3ef72a56":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","7c2cbdb5":"df.describe()","ae178a8e":"df.head()","6e38d16e":"df['Class'].value_counts()","90628043":"corr = df.corr()\n\n# Generate a mask for the upper triangle \nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Add the mask to the heatmap\nplt.figure(figsize=(20,10))\nsns.heatmap(corr, mask=mask, cmap='rocket', center=0, linewidths=1, annot=True, fmt=\".2f\")\n\nplt.show()","c42dfff3":"df.head()","a337c9b1":"X = df.drop(labels=['Class', 'Time'], axis=1)\ny=df['Class']","74b59f22":"X.head()","8d2cc3eb":"X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.33, stratify=y)","ba2824f6":"columns = df.drop(labels=['Time', 'Class'], axis=1).columns\n# print(columns)\n# df_scaled = pd.DataFrame(df[columns])\n# df_scaled.head()","63ac6afd":"X_test","363dce1d":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n","1de96e16":"X_test_scaled","13e03709":"counter_train = Counter(y_train)\nprint(counter_train)\ncounter_test = Counter(y_test)\nprint(counter_test)","5a90d45b":"from imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline","7a9fa4cb":"over = SMOTE(sampling_strategy=0.1)\nunder = RandomUnderSampler(sampling_strategy=0.5)\nsteps = [('o', over), ('u', under)]\npipeline = Pipeline(steps=steps)\nX_sample, y_sample = pipeline.fit_resample(X_train_scaled, y_train)\ncounter = Counter(y_sample)\nprint(counter)","e3989805":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_sample, y_sample)\ny_pred_rf = rf.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_rf))\nprint(confusion_matrix(y_test, y_pred_rf))\nprint(matthews_corrcoef(y_test, y_pred_rf))","98006f35":"from sklearn.tree import DecisionTreeClassifier\ndt = RandomForestClassifier()\ndt.fit(X_sample, y_sample)\ny_pred_dt = rf.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_dt))\nprint(confusion_matrix(y_test, y_pred_dt))\nprint(matthews_corrcoef(y_test, y_pred_dt))","271c943f":"from sklearn.naive_bayes import ComplementNB \ncnb = ComplementNB()\ncnb.fit(X_sample, y_sample)\ny_pred_cnb = cnb.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_cnb))\nprint(confusion_matrix(y_test, y_pred_cnb))\nprint(matthews_corrcoef(y_test, y_pred_cnb))","abaaf425":"from sklearn.naive_bayes import GaussianNB \ngnb = GaussianNB()\ngnb.fit(X_sample, y_sample)\ny_pred_gnb = gnb.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_gnb))\nprint(confusion_matrix(y_test, y_pred_gnb))\nprint(matthews_corrcoef(y_test, y_pred_gnb))","857cceb7":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_sample, y_sample)\ny_pred_svm = svc.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_svm))\nprint(confusion_matrix(y_test, y_pred_svm))\nprint(matthews_corrcoef(y_test, y_pred_svm))","0ad4b810":"from sklearn.svm import LinearSVC\nlsvc = LinearSVC()\nlsvc.fit(X_sample, y_sample)\ny_pred_lsvc = svc.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_lsvc))\nprint(confusion_matrix(y_test, y_pred_lsvc))\nprint(matthews_corrcoef(y_test, y_pred_lsvc))","4c957c59":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(X_sample, y_sample)\ny_pred_logreg = logreg.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_logreg))\nprint(confusion_matrix(y_test, y_pred_logreg))\nprint(matthews_corrcoef(y_test, y_pred_logreg))","9fcc73d7":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_sample, y_sample)\ny_pred_knn = logreg.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_knn))\nprint(confusion_matrix(y_test, y_pred_knn))\nprint(matthews_corrcoef(y_test, y_pred_knn))","73e9165f":"y_test.values","0464ab2d":"import xgboost as xgb\n\nparam_dist = {'objective':'binary:logistic', 'n_estimators':2}\nxgb_model = xgb.XGBClassifier(**param_dist)\nxgb_model.fit(X_train_scaled,y_train)\ny_pred_xgb = model.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_xgb))\nprint(confusion_matrix(y_test, y_pred_xgb))\nprint(matthews_corrcoef(y_test, y_pred_xgb))","1dac2bf2":"\nfrom sklearn.ensemble import VotingClassifier\nsvc_vote = SVC()\nknn_vote = KNeighborsClassifier(n_neighbors=2)\nparam_dist = {'objective':'binary:logistic', 'n_estimators':2}\nxgb_model_vote = xgb.XGBClassifier(**param_dist)\nrf_vote = RandomForestClassifier()\n\nestimators = [('knn', knn_vote), ('svc', svc_vote) ,('xgb', xgb_model_vote), ('rf', rf_vote)]\nvc = VotingClassifier( estimators=estimators,  voting='soft')\n\nvc.fit(X_train_scaled,y_train)\ny_pred_vc = model.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_vc))\nprint(confusion_matrix(y_test, y_pred_vc))\nprint(matthews_corrcoef(y_test, y_pred_vc))","f909d6b1":"# from sklearn.ensemble import AdaBoostClassifier\n# adb = AdaBoostClassifier()\n# adb.fit(X_sample, y_sample)\n# y_pred_adb = logreg.predict(X_test_scaled)\n# print(classification_report(y_test, y_pred_adb))\n# print(confusion_matrix(y_test, y_pred_adb))\n# print(matthews_corrcoef(y_test, y_pred_adb))","27c531da":"# from sklearn.ensemble import GradientBoostingClassifier\n# gbc = AdaBoostClassifier()\n# gbc.fit(X_sample, y_sample)\n# y_pred_gbc = logreg.predict(X_test_scaled)\n# print(classification_report(y_test, y_pred_gbc))\n# print(confusion_matrix(y_test, y_pred_gbc))","7cc56145":"# Train test split","8e734267":"### Complement NB","5f799467":"## KNNClassifier","f2a74483":"## Gradient Boost","57ca21d2":"# Scaling","52840aca":"## XGBoost","5054b3c0":"## Logistic Regression","1812c992":"## Ada Boost","9c1bbd1c":"# Feature selection","d4ee9b24":"## Oversampling and Undresampling for balancing data\n1. https:\/\/machinelearningmastery.com\/smote-oversampling-for-imbalanced-classification\/\n1. https:\/\/towardsdatascience.com\/5-smote-techniques-for-oversampling-your-imbalance-data-b8155bdbe2b5","51a340b0":"## SVC","f8044f9f":"### GaussianNB","16c3517b":"# Modelling","baa2b5cf":"## Random Forest","1c5a7bab":"# Linear SVC","39540a8a":"## Naive Bayes ","2e7b84b6":"## DecisionTree\""}}