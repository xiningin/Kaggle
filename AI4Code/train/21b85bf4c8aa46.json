{"cell_type":{"336ef580":"code","fc68bf53":"code","116556a7":"code","16772b24":"code","2099bf05":"code","110b9c35":"code","9a9c6989":"code","fe06b358":"code","c54fb19e":"code","5b5e9969":"code","b5071378":"code","613b4a0b":"code","ed99da3e":"code","fac8373f":"code","d3fe5e80":"code","f8a02d85":"code","61536c89":"code","ebb96320":"code","ff09b7cc":"code","c6f90efa":"code","5eca63ad":"code","ed6561c0":"code","d4d659a1":"code","8e38bfc6":"code","a8c42085":"code","77100c1d":"code","3f91df09":"code","805482c4":"code","442bd179":"code","e34424d7":"code","fadda6ff":"code","a771cd82":"code","970f1f34":"code","6820fd0b":"code","34f02aea":"code","ddfbb921":"code","9563f864":"code","17ae8005":"code","dd55b296":"code","879954e7":"code","6dfc21ce":"code","2527a7a5":"markdown","739417ed":"markdown","25bcbf3a":"markdown","fcfb76c1":"markdown","e52c4934":"markdown","abd0540b":"markdown","68cfdb65":"markdown","3ee31b83":"markdown","7ccb114e":"markdown","2b712e0a":"markdown","43ef7128":"markdown","516877ff":"markdown","194377e4":"markdown","3b6a8169":"markdown"},"source":{"336ef580":"import numpy as np\nimport pandas as pd \n!pip install openpyxl \nfrom pandas_profiling import ProfileReport as PR\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nimport seaborn as sns\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nimport tensorflow.keras as ks\nfrom tensorflow.keras import optimizers\nimport tensorflow as tf\n\nfrom functools import partial\nfrom scipy.special import erfinv\n\nimport datetime\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","fc68bf53":"train = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/train.csv\")\ntargetCols=[i for i in train.columns if \"target\" in i]\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/test.csv\")\npslb = pd.read_csv(\"..\/input\/bestsubtps202106\/lightautoml_with_pseudolabelling_kernel_version_15.csv\")\npslbLEAK = pd.read_excel('..\/input\/air-quality-time-series-data-uci\/AirQualityUCI.xlsx', sheet_name=0); pslbLEAK=pslbLEAK.iloc[7110:].reset_index(drop = True)\npslbLEAK.rename({'CO(GT)': 'target_carbon_monoxide', 'C6H6(GT)': 'target_benzene', 'NOx(GT)': 'target_nitrogen_oxides'}, axis = 1, inplace = True)\nsamSub = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv\")","116556a7":"for t in targetCols:\n    pslb[t] = np.where(pslbLEAK[t] >= 0, pslbLEAK[t], pslb[t])","16772b24":"train[\"date_time\"] = train.date_time.astype(\"datetime64\")\ntest[\"date_time\"] = test.date_time.astype(\"datetime64\")\npslb[\"date_time\"] = pslb.date_time.astype(\"datetime64\")","2099bf05":"profile = PR(train, title=\"TPS Train Dataset Report\", dark_mode=True, progress_bar=False)","110b9c35":"profile.to_widgets()","9a9c6989":"parCo = go.Figure(data=\n    go.Parcoords(\n        line = dict(color = train.sample(frac=0.2,random_state=1)['target_carbon_monoxide'],\n                    colorscale = 'Tealrose',\n                    showscale = True,\n                    reversescale = True),\n        dimensions = list([\n            dict(label = \"deg C\", \n                 values = train.sample(frac=0.2,random_state=1)['deg_C']),\n            dict(label = 'rel. humidity', \n                 values = train.sample(frac=0.2,random_state=1)['relative_humidity']),\n            dict(label = 'abs. humidity', \n                 values = train.sample(frac=0.2,random_state=1)['absolute_humidity']),\n            dict(label = 'sensor 1', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_1']),\n            dict(label = 'sensor 2', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_2']),\n            dict(label = 'sensor 3', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_3']),\n            dict(label = 'sensor 4.', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_4'])\n        ])\n    )\n)\n\nparCo.update_layout(\n    title=\"Colored by target carbon monoxide\"\n)\n\nparCo.show()","fe06b358":"parCo = go.Figure(data=\n    go.Parcoords(\n        line = dict(color = train.sample(frac=0.2,random_state=1)['target_benzene'],\n                    colorscale = 'Tealrose',\n                    showscale = True,\n                    \n                    \n                    reversescale = True),\n        dimensions = list([\n            dict(label = \"deg C\", \n                 values = train.sample(frac=0.2,random_state=1)['deg_C']),\n            dict(label = 'rel. humidity', \n                 values = train.sample(frac=0.2,random_state=1)['relative_humidity']),\n            dict(label = 'abs. humidity', \n                 values = train.sample(frac=0.2,random_state=1)['absolute_humidity']),\n            dict(label = 'sensor 1', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_1']),\n            dict(label = 'sensor 2', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_2']),\n            dict(label = 'sensor 3', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_3']),\n            dict(label = 'sensor 4.', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_4'])\n        ])\n    )\n)\n\nparCo.update_layout(\n    title=\"Colored by target benzene\"\n)\n\nparCo.show()","c54fb19e":"parCo = go.Figure(data=\n    go.Parcoords(\n        line = dict(color = train.sample(frac=0.2,random_state=1)['target_nitrogen_oxides'],\n                    colorscale = 'Tealrose',\n                    showscale = True,\n                    \n                    \n                    reversescale = True),\n        dimensions = list([\n            dict(label = \"deg C\", \n                 values = train.sample(frac=0.2,random_state=1)['deg_C']),\n            dict(label = 'rel. humidity', \n                 values = train.sample(frac=0.2,random_state=1)['relative_humidity']),\n            dict(label = 'abs. humidity', \n                 values = train.sample(frac=0.2,random_state=1)['absolute_humidity']),\n            dict(label = 'sensor 1', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_1']),\n            dict(label = 'sensor 2', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_2']),\n            dict(label = 'sensor 3', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_3']),\n            dict(label = 'sensor 4.', \n                 values = train.sample(frac=0.2,random_state=1)['sensor_4'])\n        ])\n    )\n)\n\nparCo.update_layout(\n    title=\"Colored by target nitrogen oxides\"\n)\n\nparCo.show()","5b5e9969":"sns.set_theme(style=\"ticks\")\n\nsns.pairplot(\n    train.sample(frac=0.2).iloc[:,1:], \n    corner=True, \n    kind=\"hist\", \n    diag_kind=\"kde\",\n    aspect=1,\n    height=2.5\n    )","b5071378":"def timeViz(DF, DFName : str, target : str, perc=0.2):\n\n    r = np.random.uniform(size=DF.shape[0])\n    vizDf = DF.loc[r < perc]\n    features = DF.columns[1:9]\n\n    fig = make_subplots(rows=4, cols=2, subplot_titles=(features))\n\n    r=1\n    c=1\n\n    for f in features:\n        fig.add_trace(\n            go.Scatter(\n                x=vizDf.date_time, \n                y=vizDf[f\"{f}\"], \n                mode='markers',\n                showlegend=False,\n                hovertemplate =\n                '<br>%{x}'+\n                '<br>%{y}'+\n                '<br><b>target<\/b>:%{text}',\n                text = ['{}'.format(i) for i in vizDf[f\"{target}\"]],\n                name='Time Seties',\n                 marker=dict(\n                    size=6,\n                    color=vizDf[f\"{target}\"], \n                    colorscale='Tealrose', \n                    showscale=True\n                    )\n                ),\n            row=r, col=c\n        )\n\n        if c == 2:\n            c = 0\n            r+=1\n        c+=1\n\n\n    fig.update_layout(height=800, width=800, title_text= DFName + \"-Features Colored by \" + target, template=\"simple_white\")\n    fig.show()","613b4a0b":"timeViz(train, \"train\", \"target_carbon_monoxide\")","ed99da3e":"timeViz(train, \"train\", \"target_benzene\")","fac8373f":"timeViz(train, \"train\", \"target_nitrogen_oxides\")","d3fe5e80":"def SaisonalComponents(DF1, DF2, periods):\n    DF12 = pd.concat([DF1.iloc[:,:9], DF2.iloc[:,:9]])\n    DF = DF12.copy()\n    for i in DF12.columns[1:]:\n        result = seasonal_decompose(DF12[f\"{i}\"], model='additive', period=periods)\n        DF12[f\"Season_{i}\"] = result.seasonal\n        DF12[f\"Season_{i}\"] = DF12[f\"Season_{i}\"].fillna(DF12[f\"Season_{i}\"].mean())\n        #result.plot()\n    return DF, DF12","f8a02d85":"gap=24\nOrig, SeasAdj = SaisonalComponents(train, test, gap)","61536c89":"def timeVizSeason(DF, DFName : str, addText : str, perc=0.2):\n\n    r = np.random.uniform(size=DF.shape[0])\n    vizDf = DF.loc[r < perc]\n    features = DF.columns[1:9]\n\n    fig = make_subplots(rows=4, cols=2, subplot_titles=(features))\n\n    r=1\n    c=1\n\n    for f in features:\n        fig.add_trace(\n            go.Scatter(\n                x=vizDf.date_time, \n                y=vizDf[f\"{f}\"], \n                showlegend=False,\n                mode=\"lines\",\n                hovertemplate =\n                '<br>%{x}'+\n                '<br>%{y}',\n                name='Time Series',\n                line_color=\"black\"\n                ),\n            row=r, col=c\n        )\n        fig.add_vline(x=\"2011-01-01 00:00:00\", line_width=3, line_dash=\"dash\", line_color=\"red\")\n\n        if c == 2:\n            c = 0\n            r+=1\n        c+=1\n\n\n    fig.update_layout(height=800, width=800, title_text= DFName + \"-Features \" + addText, template=\"simple_white\")\n    fig.show()","ebb96320":"timeVizSeason(Orig, \"train+test\", \"Season + Trend + Residual\")","ff09b7cc":"cols = [i for i in range(9,17)]\ncols.insert(0, 0)\n\ntimeVizSeason(SeasAdj.iloc[:,cols], \"train+test\", \"Seasonal Component\")","c6f90efa":"def FeatEng(DF, Vars, lags=[6]):\n    \n    DF=DF.copy()\n    \n    DF[\"weekday\"] = np.sin(DF.date_time.dt.weekday \/ 7 * np.pi\/2)\n    DF[\"hour\"] = np.sin(DF.date_time.dt.hour \/ 24 * np.pi)\n    DF[\"working_hours\"] =  DF.date_time.dt.hour.isin(list(range(7, 22, 1))).astype(\"int\")\n    DF[\"SMC\"] = np.log1p(DF[\"absolute_humidity\"] * 100) - np.log1p(DF[\"relative_humidity\"])\n    DF[\"Elapsed\"] = np.sin(DF.date_time.dt.day_of_year \/ 365 * np.pi)\n\n    for l in lags:\n        for v in Vars:\n            \n            m=DF[f\"{v}\"].mean()\n            s=DF[f\"{v}\"].std()\n            mx=DF[f\"{v}\"].mean()+DF[f\"{v}\"].std()\n            mi=DF[f\"{v}\"].mean()-DF[f\"{v}\"].std()\n\n            DF[\"mean{0}L{1}\".format(v,l)] = DF[f\"{v}\"].rolling(window=l, center=True).mean().fillna(m)\n            DF[\"max{0}L{1}\".format(v,l)] = DF[f\"{v}\"].rolling(window=l, center=True).max().fillna(mx)\n            DF[\"min{0}L{1}\".format(v,l)] = DF[f\"{v}\"].rolling(window=l, center=True).min().fillna(mi)\n\n    DF.dropna(inplace=True)\n\n    return DF","5eca63ad":"%%time\ntrainTest = FeatEng(Orig, test.columns[4:])","ed6561c0":"ys=train[targetCols]\n\nlength=train.shape[0]\n\ntrain = pd.concat([trainTest.iloc[:length,:], SeasAdj.iloc[:length,12:]], axis=1)\ntrain = pd.concat([train, ys], axis=1)\ntest = pd.concat([trainTest.iloc[length:,:], SeasAdj.iloc[length:,12:]], axis=1)\ntest = test.merge(right=pslb, on = \"date_time\")","d4d659a1":"p=0.8\ncorrelations = train.corr().abs()\nfor i in range(correlations.shape[0]):\n    correlations.iloc[i,i:correlations.shape[0]] = None\n\ncor = px.imshow(\n    correlations,\n    color_continuous_scale='Tealrose'\n)\ncor.add_trace(\n    go.Contour(\n    z=correlations, \n    showscale=False,\n    contours=dict(\n        start=p, \n        end=1, \n        size=100, \n        coloring='lines',\n        operation=\"=\"\n        ),\n    line_width=2,\n    visible=False\n    )\n)\n\ncor.update_layout(\n    updatemenus=[\n        dict(\n            type = \"buttons\",\n            direction = \"left\",\n            buttons=list([\n                dict(\n                    args=[{\"visible\": [True, False]}],\n                    label=\"Clean\",\n                    method=\"update\"\n                ),\n                dict(\n                    args=[{\"visible\": [True, True]}],\n                    label=\"Mark >= 0.8\",\n                    method=\"update\"\n                )\n            ])\n        )\n    ],\n    height=900, width=900,\n    title=\"Absolute Correlations\",\n    template=\"simple_white\"\n)\n\n\ncor.show()","8e38bfc6":"def Normalization(DF1, DF2, cols):\n    DF1=DF1.copy()\n    DF2=DF2.copy()\n    \n    DF12 = pd.concat([DF1[cols], DF2[cols]])\n    \n    for c in cols:\n        DF1[f\"{c}\"] = ((DF1[\"{}\".format(c)]-DF12[\"{0}\".format(c)].mean()) \/ DF12[\"{}\".format(c)].std())\n        \n    return DF1","a8c42085":"def rg(DF1, DF2, e, Vars):\n    \n    DF1=DF1.copy()\n    length = DF1.shape[0]\n    DF2=DF2.copy()\n    \n    DF12 = pd.concat([DF1[Vars], DF2[Vars]])\n    \n    for i in Vars:\n        r = DF12[i].rank()\n        Range = (r\/r.max()-0.5)*2\n        Range = np.clip(Range, a_max = 1-e, a_min = -1+e)\n        rg = erfinv(Range)\n        rg = rg * 2**0.5\n        DF1[i] = rg[:length]\n        DF2[i] = rg[length:]\n        \n    return DF1, DF2","77100c1d":"train, test = rg(train, test, 0.000001, [i for i in train.columns if \"target\" not in i][1:])","3f91df09":"train = pd.concat([train, test]).reset_index(drop=True)","805482c4":"#train = Normalization(train, test, [i for i in train.columns if \"target\" not in i][1:])\n#test = Normalization(test, train, [i for i in test.columns if \"target\" not in i][1:])","442bd179":"tr = train.loc[train.date_time < \"2010-12-31 12:00:00\"]\nval = train.loc[train.date_time > datetime.datetime(2010,12,31,12,0,0) + datetime.timedelta(hours=gap)]#+gap\n\nprint(\"tr shape: \" + str(tr.shape))\nprint(\"val shape: \" + str(val.shape))","e34424d7":"train = train.iloc[8:,:]\ntargetCols=[i for i in train.columns if \"target\" in i]\n\ny = train[targetCols].values\ny = y.reshape((-1, 10, y.shape[1]))# samples, timesteps, features\n\ntargetCols.append(\"date_time\")\ntrain = train.drop(columns=targetCols).to_numpy()\ntrain = train.reshape((-1, 10, train.shape[1]))# samples, timesteps, features\ntrain.shape","fadda6ff":"apDat = {\"date_time\": [pd.Timestamp('2011-04-04 15:00:00'), pd.Timestamp('2011-04-04 16:00:00'), pd.Timestamp('2011-04-04 17:00:00')]}\napDat.update({c: [0,0,0] for c in test.columns[1:]})\n\nappend = pd.DataFrame(apDat)\ntest = pd.concat([test, append])\ntest = test.drop(columns=targetCols).reset_index(drop=True).to_numpy()\ntest = test.reshape((-1, 10, test.shape[1]))# samples, timesteps, features\ntest.shape","a771cd82":"tr=tr.iloc[8:,:]\ny_tr = tr[targetCols[:-1]].values\ny_tr = y_tr.reshape((-1, 10, y_tr.shape[1]))# samples, timesteps, features\n\ntr = tr.drop(columns=targetCols).to_numpy()\ntr = tr.reshape((-1, 10, tr.shape[1]))# samples, timesteps, features\ntr.shape","970f1f34":"val=val.iloc[4:,:]\ny_val = val[targetCols[:-1]].values\ny_val = y_val.reshape((-1, 10, y_val.shape[1]))# samples, timesteps, features\n\nval = val.drop(columns=targetCols).reset_index(drop=True).to_numpy()\nval = val.reshape((-1, 10, val.shape[1]))# samples, timesteps, features\nval.shape","6820fd0b":"def LSTM_Model(seeds=123):\n    \n    np.random.seed(seeds)\n    tf.random.set_seed(seeds)\n\n    INPUT = ks.layers.Input(batch_input_shape=(1, train.shape[1], train.shape[2]), name=\"input\")\n    \n    L = ks.layers.LSTM(\n        128, \n        kernel_initializer='LecunUniform',\n        activation = \"tanh\", \n        return_sequences = True,\n        stateful=True,\n        name=\"L1\")(INPUT)\n\n    L = ks.layers.LSTM(\n        32, \n        kernel_initializer='LecunUniform',\n        activation = \"sigmoid\", \n        return_sequences = True, \n        stateful=True,\n        #dropout=0.1,\n        name=\"L2\")(L)\n\n    L = ks.layers.Dense(\n        3, \n        activation = ks.layers.PReLU(),\n        kernel_initializer='LecunUniform',\n        name=\"L_out\")(L)\n\n    m = ks.Model(inputs=INPUT, outputs=L)\n    m.summary()\n    return m","34f02aea":"lrReducer = ks.callbacks.ReduceLROnPlateau(    \n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=3,\n    verbose=1,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=0,\n    min_lr=0.000001,\n    )","ddfbb921":"def rmsle(y_pred, y_true):\n    y_pred = tf.cast(y_pred, dtype=\"float32\")\n    y_true = tf.cast(y_true, dtype=\"float32\")\n    r = tf.sqrt(tf.keras.backend.mean(tf.square(tf.math.log(y_pred+1) - tf.math.log(y_true+1))))\n    #r = tf.sqrt(tf.keras.backend.mean(tf.square(y_pred - y_true)))\n    return r","9563f864":"def lr_schaker(epoch, lr):\n    if epoch == 10:\n        lr = lr*1.1\n    elif epoch == 40:\n        lr = lr*1.1\n    elif epoch == 80:\n        lr = lr*1.1\n    elif epoch == 160:\n        lr = lr*1.1\n    elif epoch == 250:\n        lr = lr*1.1\n    return lr","17ae8005":"model = LSTM_Model()","dd55b296":"leRa=0.25\ndec=0.000#0\neps=444\nprint(\"Learningrate ok: \" + str(leRa - dec * eps >= 0))\nbs=1\nclip=100\n\noptimizer = ks.optimizers.SGD(\n    lr=leRa, \n    decay=dec, \n    clipvalue=clip,\n    momentum=0.85,\n    nesterov=True\n    )\n\nmodel.compile(\n    optimizer = optimizer, \n    loss = rmsle, \n    metrics=\"mae\"\n    )\n\nhistory = ks.callbacks.History()\n\nhistory = model.fit(\n    x=train, \n    y=y,\n    validation_data=(val, y_val),\n    epochs = eps, \n    batch_size = bs, \n    shuffle = False,\n    callbacks=[lrReducer, ks.callbacks.LearningRateScheduler(lr_schaker, verbose=0)],\n    verbose=1\n    )\n\nValPredictions = model.predict(\n   x=test, \n   batch_size = bs\n)\n\nValPredictions = pd.DataFrame(np.reshape(ValPredictions, (2250, 3)))\nValPredictions = ValPredictions.iloc[:-3,:]","879954e7":"samSub[targetCols[:-1]] = ValPredictions.values\nfor t in targetCols[:-1]:\n    samSub[t] = np.where(pslbLEAK[t] < 0, samSub[t], pslbLEAK[t])\n    \nsamSub[targetCols[:-1]] = samSub[targetCols[:-1]] * 0.5 + pslb[targetCols[:-1]] * 0.5","6dfc21ce":"samSub.to_csv(\"Submission.csv\",index=False)\nsamSub.describe()","2527a7a5":"# Training and Testing","739417ed":"Now, we use the predictions for interpolation.","25bcbf3a":"# Visual Inspection\n\nThe individual features of the parcoords can be moved to left or right by holding the topic. If you hold the left mouse button, you can mark areas on the vertical lines.","fcfb76c1":"# Seasonal Components","e52c4934":"### Normalize","abd0540b":"### Correlations","68cfdb65":"reading the data","3ee31b83":"### Paitplot","7ccb114e":"# **L**ong **S**hort **T**erm **M**emory\n\nIn this notebook, following an exploratory data analysis, I show how to fit an LSTM.\n\n<img height=\"700\" width=\"700\" src=\"https:\/\/www.researchgate.net\/profile\/Juan_Victores\/publication\/334360853\/figure\/fig1\/AS:778955447599106@1562728859405\/The-LSTM-cell-internals.png\">\n\n<p style=\"font-size : 12px\"><em>Image from: <a href=\"https:\/\/www.researchgate.net\/profile\/Juan_Victores\/publication\/334360853\/figure\/fig1\/AS:778955447599106@1562728859405\/The-LSTM-cell-internals.png\">here<\/a><\/em><\/p>","2b712e0a":"# Profiling","43ef7128":"We start by looking at the data set:","516877ff":"# Training and Validation","194377e4":"Credits to [Alexander Ryzhkov](https:\/\/www.kaggle.com\/alexryzhkov) for his [great lightAutoMl notebook](https:\/\/www.kaggle.com\/alexryzhkov\/tps-lightautoml-baseline-with-pseudolabels)!","3b6a8169":"### Time Series Visualization"}}