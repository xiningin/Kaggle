{"cell_type":{"c8c8416f":"code","a448d0e7":"code","a7ea35ad":"code","21addc87":"code","1524e605":"code","bff556e0":"code","edb66721":"code","03da1b70":"code","99ce1460":"code","4344dd38":"code","dcce8ae7":"code","c8ca72ce":"code","155d7a37":"code","7b0eb70c":"code","36aaa08a":"code","e89953e3":"code","148e5c57":"code","4a2d5608":"code","37cca048":"code","2137f09e":"code","ff7b4c18":"code","6e7374e9":"code","622f1c23":"code","050168aa":"code","b44161be":"code","997e95f6":"code","720bfa07":"code","07228773":"code","f91d4b96":"code","05dcbd1c":"markdown","b27d461a":"markdown","2f1bcea6":"markdown","e4b3c4ec":"markdown","12c3bab8":"markdown","d7155acb":"markdown","09746a9c":"markdown","2024f8ca":"markdown","9da644a8":"markdown","88034ced":"markdown","4061f658":"markdown","9d8f90fa":"markdown"},"source":{"c8c8416f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom fastai import * # import the FastAI v3 lib which includes pytorch\nfrom fastai.vision import  * # import all of the computer vision related libs from vision \n\n# lets import our necessary magic libs\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","a448d0e7":"BATCH_SIZE = 64 \nIMG_SIZE = 224\nWORKERS = 0 \nDATA_PATH_STR = '..\/input\/parkinsons-drawings\/'\nDATA_PATH_OBJ = Path(DATA_PATH_STR)","a7ea35ad":"tfms = get_transforms() # standard data augmentation ()\n\ndata = (ImageList.from_folder(DATA_PATH_OBJ)        # get data from path object\n        .split_by_rand_pct()                        # separate 20% of data for validation set\n        .label_from_folder()                          # label based on directory\n        .transform(tfms, size=IMG_SIZE)                   # added image data augmentation\n        .databunch(bs=BATCH_SIZE, num_workers=WORKERS)    # create ImageDataBunch\n        .normalize(imagenet_stats))                   # normalize RGB vals using imagenet stats","21addc87":"# lets check to see if the seperations were done correctls\n('training DS size:', len(data.train_ds), 'validation DS size:' ,len(data.valid_ds))","1524e605":"# lets check our labels\/classes\ndata.classes","bff556e0":"data.show_batch(rows=4, figsize=(10,8))","edb66721":"learn = cnn_learner(data, models.resnet34, metrics=accuracy, model_dir='\/tmp\/models')","03da1b70":"# lets start training via one cycle \nlearn.fit_one_cycle(1)\n# should happen quickly since the dataset is relatively small","99ce1460":"interp = ClassificationInterpretation.from_learner(learn)","4344dd38":"# show me what the model was most confident in yet, was incorrect.\nlosses,idxs = interp.top_losses()\ninterp.plot_top_losses(9, figsize=(15,11))","dcce8ae7":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","c8ca72ce":"# lets unfreeze the remainder of the model to see if our model can do better \nlearn.unfreeze()","155d7a37":"learn.fit_one_cycle(3)","7b0eb70c":"learn.save('stage-1-74')","36aaa08a":"# lets try to find the learning rate to improve the model accuracy\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","e89953e3":"# instead of the default max_lr\n# lets pass our cycle the lowest learning rates suggested\nlearn.fit_one_cycle(10, max_lr=slice(1e-4,1e-6))","148e5c57":"learn.save('stage-2-86')","4a2d5608":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.top_losses()\ninterp.plot_top_losses(9, figsize=(15,11))","37cca048":"interp.most_confused()","2137f09e":"learn5 = cnn_learner(data, models.resnet50, metrics=accuracy, model_dir='\/tmp\/models')","ff7b4c18":"# lets fit only our top layers to see how well she does \nlearn5.fit_one_cycle(1)","6e7374e9":"# Lets optimize\nlearn5.lr_find()\nlearn5.recorder.plot(suggestion=True)","622f1c23":"learn5.fit_one_cycle(2, max_lr=slice(1e-2,1e-4))","050168aa":"# lets now unfreeze the rest to see if we can improve\nlearn5.unfreeze()","b44161be":"# Lets optimize\nlearn5.lr_find()\nlearn5.recorder.plot(suggestion=True)","997e95f6":"# now lets fitting with a suggested lr instead of default\nlearn5.fit_one_cycle(20, max_lr=slice(1e-3,1e-6))","720bfa07":"interp50 = ClassificationInterpretation.from_learner(learn5)","07228773":"interp50.most_confused()","f91d4b96":"learn5.save('stage-1-93')","05dcbd1c":"Looks like when we unfroze the remaining layers and retrained the entire model, **the loss decreased (the model got more confident) and the accuracy jumped as well. **\n\nBut can we further optimize the model by calculating the ideal learning rate? \ud83e\udd14","b27d461a":"# Conclusion & Closing Remarks #\n\nAll in all, our resnet 34 model was able to reach close to **98% accuracy while our larger, more expensive resnet50 model was able to reach 93% accuracy**. In the production enviornment, I would opt for our smaller resnet 34 model as it was able to get consistent diagnosis with a lot less overhead and cost. \n\nIt is a bit astonishing to me how accurate these models can be right out of box. The models both surpassed the 85% benchmark with very little finetuning and adjustments needed. But I am a bit skeptical at the ease, are we overfitting? \ud83e\udd14\n\nIn the future, it would be nice to add features such as speed and pen pressure (CISP) or at least try to determine them from the thickness and intensities of the lines on the drawings.\n\nAgain, please feel free to reply with feedback and constructive criticism. \n\n","2f1bcea6":"## Constants ##","e4b3c4ec":"Looks like our model without any finetuning is already realitively accurate with an accuracy of ~60%. ","12c3bab8":"# Importing & Getting Started #","d7155acb":"## Results ##\nLets try to interpret some of these results from the first stage of training by creating a Classification Interpretation object. ","09746a9c":"Keep in mind the figure above shows the **MOST TOP LOSSES** meaning not only the incorrect labelings but also **classes that the model was correct but was highly inconfident\/unsure that it was correct, leading to a high loss.**","2024f8ca":"## Creating our Data Block ##\nLets create a DataBunch object to feed our model with the appropriate training and testing data for our spiral and waves.","9da644a8":"## Training Resnet50 ##\nSeems like our current model is quite accurate already but can we improve it by increasing the number of layers and overall size. We will now scale our resnet34 model into a full blown resnet50.\n\nThis model is obviously larger with more layers and thus more expensive in terms of computing.","88034ced":"# Hello & Introduction #\n\nHowdy, I am still getting the hang of this, so please feel free to suggest improvements or ideas. \n\nToday, we will be implementing a Convolutional Nueral Network (CNN) from FastAI to acurrately predict patients with Parkinson's Syndrom. The aim of this work is to establish a supplemental yet reliable, computer method of diagnosis. The model aims at underminding a diagnosis bottleneck where experts are needed to interpret these sketches, especially in the early stages of the disease. With the availability of technology exponentially increasing, this model can be deployed and used to supplement the diagnosis of real individuals.\n\nThe data was taken directly from Kevin Mader's [Parkinsons Drawing](https:\/\/www.kaggle.com\/kmader\/parkinsons-drawings). Attached is the [medical article](https:\/\/www.frontiersin.org\/articles\/10.3389\/fneur.2017.00435\/full) documenting how the data was recorded, how the subjects were chosen, and other features they recorded such as pen pressure, speed, etc.\n\n\nAs of today, all of the models using this dataset have reached ~80% accuracy. **This one will _hopefully_ be a bit more accurate.**","4061f658":"<img src=\"https:\/\/i.ibb.co\/6PYWPTQ\/V02PE02.png\" alt=\"V02PE02\" align=\"center\"\/>","9d8f90fa":"## Resnet34 Model Creation & Training ##\nWe will first implement a Convolutional Nueral Network (CNN) with a fully connected head and a single hidden layer as a classifier. I still don't have too much of a clue what that means but i'm rollin' with it. "}}