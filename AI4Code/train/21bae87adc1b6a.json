{"cell_type":{"90ffed9b":"code","e4668d75":"code","0437c41e":"code","25f59a36":"code","98275084":"code","f0cf36f3":"code","9a2c352f":"code","718ce220":"code","02aee828":"code","37cd4030":"code","337f6064":"code","93fcb036":"code","c03ad333":"code","0a0ab58c":"code","77173fd4":"code","d45eaa41":"code","05e78b4f":"code","e94af93d":"code","7ecbb58a":"code","43d46d88":"code","5aa48dab":"code","887c9b97":"code","56474eff":"code","b5946277":"code","d6950539":"code","ed69a081":"code","f0995dd4":"code","d8cc2bea":"code","c73ff554":"code","06dc8822":"code","4ee0d8f1":"code","2fc09508":"code","7138d882":"code","f17c7f36":"code","8b816b8c":"code","e4a20a50":"code","c6db377a":"code","9cd99aa7":"code","8479c1d9":"code","8452c99f":"code","ce55d29e":"markdown","5bcd2378":"markdown","a08590c9":"markdown","6ef15664":"markdown","bfa939d6":"markdown","5b1f4be6":"markdown","9f06348d":"markdown","043057d8":"markdown","a6d11084":"markdown","86861129":"markdown","531af4d9":"markdown","88597c00":"markdown","a2465aad":"markdown","52900a68":"markdown","172d2134":"markdown","5aea46dd":"markdown","d8defc90":"markdown","7fd24a34":"markdown","1b069d06":"markdown"},"source":{"90ffed9b":"!pip install lyrics_extractor","e4668d75":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom lyrics_extractor import Song_Lyrics\nimport nltk\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\nfrom collections import Counter","0437c41e":"import cufflinks as cf\nimport chart_studio.plotly\n\nfrom plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\n\ninit_notebook_mode(connected=True)\ncf.go_offline()","25f59a36":"sns.set_style('darkgrid')\nsns.set_color_codes(\"pastel\")","98275084":"spotify = pd.read_csv(\"..\/input\/spotify-top-50-w-lyrics\/spotify_w_lyrics.csv\",  encoding = \"ISO-8859-1\" , index_col= 0)","f0cf36f3":"spotify.head(10)","9a2c352f":"spotify.columns = [cols.replace('.', '') for cols in spotify.columns]\nspotify = spotify.sort_values(by = 'Popularity', ascending =False).reset_index(drop = True)","718ce220":"spotify.describe()","02aee828":"spotify.info()","37cd4030":"# target variable: popularity \nsns.distplot(spotify['Popularity'], kde = False, bins = 10)","337f6064":"# distribution of other features\n\nx_cols = ['BeatsPerMinute', 'Energy','Danceability', 'LoudnessdB', 'Liveness', 'Valence', 'Length','Acousticness', \n          'Speechiness']\n\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize = (15,15))\nfor i, x_col in enumerate(x_cols):\n    sns.distplot( spotify[x_col], ax=axes[i\/\/3,i%3], kde = False, bins = 10)\n    axes[i\/\/3,i%3].set_xlabel(x_col) ","93fcb036":"# How does features relate to popularity\n\nx_cols = ['BeatsPerMinute', 'Energy','Danceability', 'LoudnessdB', 'Liveness', 'Valence', 'Length','Acousticness', \n          'Speechiness']\n\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize = (15,15))\nfor i, x_col in enumerate(x_cols):\n    sns.regplot( x = x_col,  y = 'Popularity', ax=axes[i\/\/3,i%3], data = spotify)\n    axes[i\/\/3,i%3].set_xlabel(x_col) ","c03ad333":"# correlation heatmap between X features and popularity\n\nfig = plt.figure(figsize = (10,8))\n\nmask = np.zeros_like(spotify.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(spotify.corr(), annot = True,linewidths = 0.3, mask = mask)","0a0ab58c":"# Artist Popularity:\nfig = plt.figure(figsize = (15,8))\nsns.set_style('whitegrid')\nartist = spotify.groupby('ArtistName').size().reset_index(name = 'count')\nartist = artist.sort_values(by = 'count', ascending =False)\nsns.barplot(y = 'ArtistName',x=\"count\", data=artist,  color=\"b\")\nsns.despine(left=True, bottom=True)","77173fd4":"# Genre Popularity:\n\nspotify['Genre'].unique()","d45eaa41":"def parent_genre(genre):\n    music_genre = {'electronic' : ['electropop','trap music','pop house', 'big room', 'brostep' ,'edm'],\n                   'hip hop\/rap': ['canadian hip hop','atl hip hop','reggaeton','reggaeton flow','dfw rap',\n                                   'country rap'],\n                   'pop': ['pop','panamanian pop', 'canadian pop', 'australian pop', 'dance pop', 'boy band'],\n                   'others': ['escape room', 'latin','r&b en espanol']}\n    \n    for parent, sub in music_genre.items():\n        if genre in sub:\n            return parent","05e78b4f":"spotify['parent_genre'] = spotify['Genre'].apply(parent_genre)","e94af93d":"# Genre Popularity:\nimport plotly.graph_objects as go\n\nartist = spotify.groupby('parent_genre').size().reset_index(name = 'count')\nartist = artist.sort_values(by = 'count', ascending =False)\n\nvalues = artist['count'].tolist()\nlabels = artist['parent_genre'].tolist()\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values)])\nfig.update_traces(textposition='inside', textinfo='value+label', title_text = 'Parent Genre Segmentation')\nfig.show()","7ecbb58a":"parent_genre = pd.get_dummies(spotify['parent_genre'],drop_first=True)","43d46d88":"spotify = pd.concat([spotify, parent_genre],axis=1)","5aa48dab":"spotify.head()","887c9b97":"# Original function that scrap for song lyrics\n# def get_lyrics(track):\n#     extract_lyrics = Song_Lyrics('GCS_API_KEY', 'GCS_ENGINE_ID')\n#     song_title, song_lyrics = extract_lyrics.get_lyrics(track)\n#     return song_lyrics","56474eff":"# spotify['lyrics'] = spotify['TrackName'].apply(lambda row: (get_lyrics(row)))\n# spotify = spotify.replace('', 'None')","b5946277":"def pre_processing(lyrics):\n    lyrics = lyrics.replace('\\n', ' ',).lower()\n    lyrics = re.sub(r'\\[.*?\\]', '', lyrics)\n    lyrics = re.sub(r'\\(.*?\\)', '', lyrics)\n    lyrics = re.sub(r'\\{.*?\\}', '', lyrics)\n    \n    lyrics = re.sub(r'[^a-zA-Z0-9 ]', '', lyrics)\n    lyrics = ' '.join(lyrics.split())\n    return lyrics\n\ndef count_unique(df):\n    text = df['Lyrics']\n    stop_words = stopwords.words('english')\n    newStopWords = ['youre','im', 'ill','ive', 'm', 'oh' , 'yeh', 'yeah', 'dont', 'got', 'gonna', 'wanna']\n    stop_words.extend(newStopWords)\n    stopwords_dict = Counter(stop_words)\n    \n    initial_len = len(text.split())\n    clean_lyrics = ' '.join([word for word in text.split() if word not in stopwords_dict])\n    text = set([word for word in text.split() if word not in stopwords_dict])\n    unique_length = (len(text)\/initial_len)*100\n    return clean_lyrics, unique_length","d6950539":"spotify['Lyrics'] = spotify['lyrics'].apply(lambda lyrics:pre_processing(lyrics))\nspotify['text_length'] = spotify['Lyrics'].apply(lambda lyrics: len(lyrics.split()))\nspotify[['clean_lyrics','unique_length']] = spotify.apply(count_unique, result_type='expand', axis = 1)","ed69a081":"spotify.head()","f0995dd4":"def sentiment_analysis(lyrics):\n#   TextBlob has a function that allows for translation of text to eng, \n#   its still possible to run sentiment analysis even without translating the lyrics.\n    blob = TextBlob(lyrics)\n    language = blob.detect_language()\n    if language != 'en':\n        blob = blob.translate(to=\"en\")\n\n    for sentence in blob.sentences:\n        sentiment = sentence.sentiment.polarity\n    return sentiment","d8cc2bea":"spotify['sentiment'] = spotify['clean_lyrics'].apply(sentiment_analysis)","c73ff554":"lexicalrichness = spotify[spotify['text_length'] > 1]","06dc8822":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize = (18,5))\nsns.set_style('darkgrid')\ncols = ['text_length', 'unique_length', 'sentiment']\n \nfor i, x_col in enumerate(cols):\n    sns.distplot(lexicalrichness[x_col], ax=axes[i], kde = False, bins = 15)\n    axes[i].set_xlabel(x_col) ","4ee0d8f1":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize = (18,5))\nsns.set_style('darkgrid')\ncols = ['text_length', 'unique_length', 'sentiment']\n \nfor i, x_col in enumerate(cols):\n    sns.scatterplot(x = x_col, y = 'Popularity' , data = lexicalrichness, ax=axes[i])\n    axes[i].set_xlabel(x_col) ","2fc09508":"# wordcloud for most popular words \n# Here's a word cloud for those curious on popular words.\nfrom wordcloud import WordCloud\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        max_words=200,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(12, 12))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n\nshow_wordcloud(spotify['clean_lyrics'])","7138d882":"from sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nimport statsmodels.api as sm\nimport matplotlib.lines as mlines\nimport matplotlib.transforms as mtransforms","f17c7f36":"spotify.columns","8b816b8c":"# we shall skip observation withtext length = 1 as it may skew our results. \ndf = spotify[spotify['text_length'] > 1]","e4a20a50":"\"\"\"\nTo avoid the problems associated with co-linearity, only BeatsPerMinute is used \nas the dependent variable between the two. \n\"\"\"\n\ny = df['Popularity']\nX = df[['BeatsPerMinute','Valence','unique_length', 'hip hop\/rap', 'others', 'pop']]","c6db377a":"lm = LinearRegression()\nlm.fit(X,y)\npredictions = lm.predict(X)","9cd99aa7":"X2 = sm.add_constant(X)\nest = sm.OLS(y, X2)\nest2 = est.fit()\nprint(est2.summary())","8479c1d9":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\nsns.scatterplot(x = y,y = predictions, ax = ax1)\nline = mlines.Line2D([0, 1], [0, 1], color='red')\ntransform = ax1.transAxes\nline.set_transform(transform)\nax1.add_line(line)\nax1.set_xlim([70,100])\nax1.set_ylim([70,100])\n\nsns.distplot((y-predictions),bins=10, ax= ax2);","8452c99f":"MAE = metrics.mean_absolute_error(y, predictions)\nMSE = metrics.mean_squared_error(y, predictions)\nRMSE = np.sqrt(metrics.mean_squared_error(y, predictions))\n\nerror_df = pd.DataFrame(data = [MAE, MSE, RMSE], index = ['MAE', 'MSE', \"RMSE\"], columns=['Error'])\nerror_df","ce55d29e":"### 3b. Categorical Analysis","5bcd2378":"# 4. Linear Regression for Song Popularity","a08590c9":"# 2. Data Cleaning","6ef15664":"- Ed Sheeren is one of the most popular artist in 2019! Unforuntely, categorisation by artist names cant tell us much sinec most artist only has one popular songs of 2019. ","bfa939d6":"### 4b. Predictions vs Actual","5b1f4be6":"# Top Hits of 2019 (Spotify)\n***\n### Table Column Info:\n\n1. Track.Name: Name of the Track\n2. Artist.Name:Name of the Artist\n3. Genre: the genre of the track\n4. Beats.Per.Minute: The tempo of the song.\n5. Energy: The energy of a song - the higher the value, the more energtic song\n6. Danceability: The higher the value, the easier it is to dance to this song.\n7. Loudness..dB..: The higher the value, the louder the song.\n8. Liveness: The higher the value, the more likely the song is a live recording.\n9. Valence. : The higher the value, the more positive mood for the song.\n10. Length. : The duration of the song.\n11. Acousticness.. : The higher the value the more acoustic the song is.\n12. Speechiness. : The higher the value the more spoken word the song contains.\n13. Popularity :The higher the value the more popular the song is.\n14. Lyrics: Original Lyrics of the Song if available. \n\nThis dataset orignated from https:\/\/www.kaggle.com\/leonardopena\/top50spotify2019 with lyrics was added to the original dataset. Unhash the codes below and run top50.csv to generate lyrics.  \n\n\n### Question:\n- What are the features that contribute to song popularity?\n- Predict song popularity?\n---","9f06348d":"---\n# 3. EDA\n### 3a. Numerical Data Analysis","043057d8":"- Most songs have text length of **~400**\n- Most songs have unique length (also known as lexical richness, measure of normalised unique words) of **20 & 30%.**\n- Sentiment and popularity doesnt seem to be corelated, most songs have no polarity (0). Contrary to the previous findings, songs with higher sentiment (positivity) tends to be more popular here.\n\n$$ unique \\ length = \\frac {num\\ of \\ unique \\ words}{length \\ of \\ words \\ excluding \\ nltk \\ stopwords}$$","a6d11084":"- top 50 songs have popularity score of around 87.5 - 92.5.","86861129":"- pop songs seems to be popular amongst listeners with dance pop being the most popular followed by hip\/hop. Dummy variables are then created to differnetiate between the parent genres.\n- The improportionate ratios across categories could be attributed to the number of sub genres within each category which then skews the parent genre.","531af4d9":"- Popular songs tend to have higher `BeatsPerMinute`, `speechiness` and **lower** `valence`.","88597c00":"- `BeatsPerMinute` co-related to `Speechiness`, this may introduce problems of colinearity in regression later. \n- `Energy` co-related to `LoudnessB`, `Valence` (happiness!).","a2465aad":"---\n## Concluding Remarks:\n- Receipe for popular songs? Try creating a pop song that more unique words and is mildly more melancholic! \n- While some important features were identified, the data set is rather small and the results should be taken with a pinch of salt. Feel free to leave any comments\/ suggestions below , hope you enjoyed the kernel! ","52900a68":"# 1. Import Modules ","172d2134":"- Similar to the categorisation of artistname there are too many sub genres that makes the classification a little meaningless. The next section groups these genres into parent genres and sub genres from other langs are classified under others. Categorisation can be a little subjective since there is no clear distinction for some `Genres`.","5aea46dd":"### 3c. Feature Engineering: Lyrical Analysis\nLyrics from lyrics-extractor library; following the instructions in pypi page to generate GCS_API_KEY, GCS_ENGINE_ID tokens. Unfortuntely unable to run lyrics_extractor py on Kaggle and have attached the data set with lyrics in this kernel. The original code is attached below for reference.\n\nFor more info, visit https:\/\/pypi.org\/project\/lyrics-extractor\/","d8defc90":"- Linear regression model definitely unable to perform well given poor data set and for this data set, we assume that all test = train data since there are too little datapoints to sufficiently create meaningful train\/test set. Thus, the linear regression model will definitely be overfitted with current data. \n- Song popularity is also predicted to be slightly greater than the actual value.","7fd24a34":"**Statiscal Analysis**\n- R2 = 0.480, dependent variables does not explain the y variable well. \n- Discrete variables like `pop`, `Valence`, `unique_length` are statisically signficant (<0.05) and that a non-zero corelation exists. ","1b069d06":"### 4a. Modelling"}}