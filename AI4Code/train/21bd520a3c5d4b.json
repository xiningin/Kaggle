{"cell_type":{"cb70e739":"code","ee355605":"code","736b2cfb":"code","fc632d18":"code","956d731a":"code","40b76616":"code","8ba46ec5":"code","a041706c":"code","23aada2c":"markdown","729a4141":"markdown","22e529c2":"markdown","4b25eaa8":"markdown","b2dcee59":"markdown","c8b15d33":"markdown","e18162c6":"markdown","ff56319f":"markdown","a057589c":"markdown"},"source":{"cb70e739":"#-------Import Dependencies-------#\n%matplotlib inline\nimport pandas as pd\nimport os,shutil,math,scipy,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random as rn\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix,roc_curve,auc\n\nfrom PIL import Image\nfrom PIL import Image as pil_image\nfrom PIL import ImageDraw\n\nfrom time import time\nfrom glob import glob\nfrom tqdm import tqdm\nfrom skimage.io import imread\nfrom IPython.display import SVG\n\nfrom scipy import misc,ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\n\n\nfrom keras import backend as K\nfrom keras.utils.np_utils import to_categorical\nfrom keras import layers\nfrom keras.preprocessing.image import save_img\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.applications.xception import Xception\nfrom keras.applications.nasnet import NASNetMobile\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\nfrom keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler","ee355605":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('acc')\n    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","736b2cfb":"augs_gen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True)  \n\ntrain_gen = augs_gen.flow_from_directory(\n    '..\/input\/training_set\/training_set',\n    target_size = (32,32),\n    batch_size=32,\n    shuffle=True,\n    class_mode = 'binary'\n)\n\ntest_gen = augs_gen.flow_from_directory(\n    '..\/input\/validation_set\/validation_set\/',\n    target_size=(32,32),\n    batch_size=32,\n    shuffle=False,\n    class_mode = 'binary'\n)","fc632d18":"model = Sequential()\nmodel.add(Conv2D(6, kernel_size=(5,5),activation='relu',input_shape=(32,32,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2,strides=2))\nmodel.add(Conv2D(16,kernel_size=5,strides=1,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2,strides=2))\nmodel.add(Flatten())\nmodel.add(Dense(120,activation='relu'))\nmodel.add(Dense(84,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.summary()\n\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","956d731a":"#-------Callbacks-------------#\nbest_model_weights = '.\/base.model'\ncheckpoint = ModelCheckpoint(\n    best_model_weights,\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=10,\n    verbose=1,\n    mode='auto'\n)\ntensorboard = TensorBoard(\n    log_dir = '.\/logs',\n    histogram_freq=0,\n    batch_size=16,\n    write_graph=True,\n    write_grads=True,\n    write_images=False,\n)\n\ncsvlogger = CSVLogger(\n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\n\n#lrsched = LearningRateScheduler(step_decay,verbose=1)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5,\n    verbose=1, \n    mode='auto',\n    cooldown=1 \n)\n\ncallbacks = [checkpoint,tensorboard,csvlogger,reduce]","40b76616":"opt = SGD(lr=2e-4,momentum=0.99)\nopt1 = Adam(lr=1e-2)\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n    \nhistory = model.fit_generator(\n    train_gen, \n    validation_data = test_gen,\n    validation_steps = 100,\n    steps_per_epoch  = 100, \n    epochs = 150,\n    verbose = 1,\n    callbacks=callbacks\n)","8ba46ec5":"show_final_history(history)\nmodel.load_weights(best_model_weights)\nmodel_eval = model.evaluate_generator(test_gen,steps=100)\nprint(\"Model Test Loss:\",model_eval[0])\nprint(\"Model Test Accuracy:\",model_eval[1])\n\nmodel_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save(\"model.h5\")\nprint(\"Weights Saved\")","a041706c":"!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = '.\/logs' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('.\/ngrok http 8080 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","23aada2c":"# Train The Model\n### Here we train the model with our generators","729a4141":"# Callbacks\n### Here we use Keras callbacks to monitor how the training is going and adjust the training accordingly","22e529c2":"# Evaluation\n### Here we visualize the training, load the the best weights from the model, evaluate the model, and save the weights","4b25eaa8":"# TensorBoard\n### Here is a script that will give you a url to view your model's training results.","b2dcee59":"# Import Dependencies\n### Load in the libraries that you will need","c8b15d33":"# Image Preprocessing\n### Thank to Keras ImageDataGenerator for image preprocessing and data augmentation","e18162c6":"# Model\n### This is the LE-Net5 model from the research paper for this dataset","ff56319f":"# Custom Function\n### function for visualizing training results","a057589c":"# Project Paper\n### Here is the link to the research paper for this dataset\n### https:\/\/jivasquez.files.wordpress.com\/2019\/03\/rp_cactus_recognition_elsa-1.pdf"}}