{"cell_type":{"954df497":"code","f5369d18":"code","a94fb5e8":"code","b59aa7c8":"code","c6049661":"code","603126b2":"code","7647424d":"code","f554c8a0":"code","93dd08ac":"code","f4359929":"code","7a60b9d3":"code","063edd13":"code","ebeaf9e5":"code","fc394450":"code","2ebc0294":"code","726719b6":"code","254d4232":"code","ee1e5cee":"code","b7134f4f":"code","d0cfc11a":"code","e2be7284":"code","b4fda2e5":"code","04e5c754":"code","f0784df8":"code","125aa258":"code","d8889654":"code","af47b8fe":"code","41662afd":"code","c6bf57e3":"code","21ff86de":"code","877d360e":"code","dfe0f990":"code","de714952":"code","fbb982ef":"code","db251467":"code","9652999e":"code","fc1d917c":"code","c3e4986b":"code","01583b18":"code","cb0968ba":"code","081c5bbd":"code","92f18fd4":"code","0fc855a5":"code","d9d64c71":"code","77b86c08":"code","dc2424fc":"code","c0af2d98":"code","80e6412e":"code","ab6040c6":"code","763f23b0":"code","9abc4b4d":"code","a12498ef":"code","308d4b8b":"code","4fce5e83":"code","115df613":"code","8b537e1b":"code","e72e2cb2":"code","f43dc024":"code","80291e0b":"code","9ecdf3f6":"code","5599c7ef":"code","f79b0e31":"code","87285408":"code","8ca9a572":"code","a294c70d":"code","7816ce7e":"code","42732396":"code","06ede714":"code","8e85793a":"markdown","03414157":"markdown","e59a4c17":"markdown","ccf0f308":"markdown","e7d4d947":"markdown","5ad07eef":"markdown","76cf3ab3":"markdown","06532c9a":"markdown","bc65638b":"markdown","7eb64267":"markdown","b247fe77":"markdown","50b6289e":"markdown","bda7a87d":"markdown","34030676":"markdown","27576399":"markdown","c7ec0973":"markdown","dd190b98":"markdown"},"source":{"954df497":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.pipeline import Pipeline","f5369d18":"import warnings\nwarnings.filterwarnings('ignore')","a94fb5e8":"df = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","b59aa7c8":"df.head()","c6049661":"df.info()","603126b2":"df.describe()","7647424d":"#Pair Plot\nsns.pairplot(df.drop('id',axis=1),hue=\"stroke\",plot_kws={'alpha':0.3},diag_kind='hist',diag_kws={'multiple':'dodge','bins':5})","f554c8a0":"#Label hisogram \nsns.histplot(df['stroke'])","93dd08ac":"#Skewed Data !!!","f4359929":"#Histogram\ng = sns.histplot(x= 'age',hue='stroke',data=df,bins=5,multiple='dodge')","7a60b9d3":"#It is obvious that older people are more exposed to the risk of stroke, let's split age column and compute the proportion of positive labels per segment","063edd13":"#Splitting function\ndef age_split(col):\n    age = col\n    if age<=18 :\n        return '1'\n    elif 18<age<=30 :\n        return '2'\n    elif 30<age<=40 :\n        return '3'    \n    elif 40<age<=50 :\n        return '4'\n    elif 50<age<=60 :\n        return '5'\n    elif 60<age<=85:\n        return '6'","ebeaf9e5":"df['Age_Category'] = df['age'].apply(age_split)\nage_2 = pd.DataFrame(df.groupby('Age_Category')['stroke'].value_counts())\nage_2['proportion'] = round(age_2['stroke']\/df.groupby('Age_Category')['id'].count(),4)\nage_2","fc394450":"#Plot proportions\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.plot(['3','4','5','6'],age_2[(age_2.index.get_level_values(1)==1)&(age_2.index.get_level_values(0)!='1')]['proportion'],\n        marker='x')\nplt.xlabel('Age category')\nplt.ylabel('Proportion of strokes')\nplt.title('Proportion of strokes per age category')","2ebc0294":"#According to the Data, out of 100 person older than 60 years, approximately 14 had a stroke","726719b6":"#Barplot\nsns.histplot(x='smoking_status',data=df,hue='stroke',multiple='dodge')","254d4232":"#No conclusions can be drawn from the previous plot, lets use the same approach as for Age. \n","ee1e5cee":"##Computing the proportion of positive labels per smoking status\nsmoke_ =  pd.DataFrame(df.groupby('smoking_status')['stroke'].value_counts())\nsmoke_['proportion'] = smoke_['stroke']\/df.groupby('smoking_status')['id'].count()\nsmoke_","b7134f4f":"#Redoing Barplot using proportions\nsns.barplot(smoke_.index.get_level_values(0).unique(),\n            smoke_[smoke_.index.get_level_values(1)==1]['proportion'],order=['formerly smoked','smokes','never smoked','Unknown'])","d0cfc11a":"#From that plot we can say that smoking status might be related to stroke proportion . \n#Still, one might think that old people had more time to smoke, enjoy smoking then quit smoking HAHA. Let's look at the relation between Age and Smoking Status","e2be7284":"#Box Plot\nsns.boxplot(x='smoking_status',y='age',data=df,order=['formerly smoked','smokes','never smoked','Unknown'])","b4fda2e5":"#As expected, Formerly_smoked category has a higher age average... Let's look deeper using proportions by Age_Category & Smoking_status","04e5c754":"age_smoke = pd.DataFrame(df.groupby(['Age_Category','smoking_status'])['stroke'].value_counts())\nage_smoke['proportion'] = np.round(age_smoke['stroke']\/df.groupby(['Age_Category','smoking_status'])['id'].count(),4)\nage_smoke","f0784df8":"#Plotting proportions per Age_Category & smoking_status, the blue line represents propotions computed without using the smoking_status information \nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.plot(['3','4','5','6'],age_2[(age_2.index.get_level_values(1)==1)&(age_2.index.get_level_values(0)!='1')]['proportion'],\n        label ='All smoking status',marker='x')\nax.plot(['3','4','5','6'],age_smoke[(age_smoke.index.get_level_values(1)=='formerly smoked')&(age_smoke.index.get_level_values(2)==1)]['proportion'],\n        label ='formerly smoked',marker='x')\nax.plot(['3','4','5','6'],age_smoke[(age_smoke.index.get_level_values(1)=='smokes')&(age_smoke.index.get_level_values(2)==1)]['proportion'],\n        label ='smokes',marker='x')\nax.plot(['3','4','5','6'],age_smoke[(age_smoke.index.get_level_values(1)=='never smoked')&(age_smoke.index.get_level_values(2)==1)]['proportion'],\n        label ='never smoked',marker='x')\nplt.legend()\nplt.xlabel('Age category')\nplt.ylabel('Proportion of strokes')\nplt.title('Proportion of strokes per age category & smoking status')","125aa258":"#For Formerly_smoked status the proportion of stroke is higher for all age categories. For other smoking status, the effect tends to vary among age categories.","d8889654":"#Countplot\nsns.countplot(x='gender',hue='stroke',data=df)","af47b8fe":"#Proportion of stroke per Gender\ngender_ = pd.DataFrame(df.groupby(['gender','stroke'])['id'].count())\ngender_['proportion'] = round(gender_['id']\/df.groupby('gender')['id'].count(),4)\ngender_","41662afd":"#Slight difference between Male and Female in term of stoke proportion. \n#Keep in mind we are dealing with skewed Data, proportions of stroke is approximately 4%...","c6bf57e3":"#Boxplot (gender vs Age)\nsns.boxplot(x='gender',y='age',data=df)","21ff86de":"#Slight difference between Male and Female in term of Age average","877d360e":"#Count plot\nsns.countplot('ever_married',hue='stroke',data=df)","dfe0f990":"#Proportions of stroke per ever_married status\nmarried_ = pd.DataFrame(df.groupby(['ever_married','stroke'])['id'].count())\nmarried_['proportion'] = married_['id']\/df.groupby('ever_married')['id'].count()\nmarried_","de714952":"sns.barplot(married_.index.get_level_values(0).unique(),\n            married_[married_.index.get_level_values(1)==1]['proportion'])","fbb982ef":"#WOW, rethinking marriage is a must LOL!! ","db251467":"#Boxplot (ever_married vs age)\nsns.boxplot(x='ever_married',y='age',data=df)","9652999e":"#fortunately, it's the age effect...","fc1d917c":"#box plot showing average age of people having Heart disease\/hypertension, both or none \nsns.boxplot(x=df['hypertension']+df['heart_disease'],y=df['age'])","c3e4986b":"#Let's focus on people older than 50 (Age_Category = 5 & 6).","01583b18":"#Proportion of stroke per Age_Category,heart_disease & Hypertension\nage_disease = pd.DataFrame(df.groupby(['Age_Category','heart_disease','hypertension','stroke'])['id'].count())\nage_disease['proportion'] = age_disease['id']\/df.groupby(['Age_Category','heart_disease','hypertension'])['id'].count()\n","cb0968ba":"age_disease['age']=age_disease.index.get_level_values(0)\nage_disease['heart_disease']=age_disease.index.get_level_values(1)\nage_disease['hypertension']=age_disease.index.get_level_values(2)\nage_disease['stroke']=age_disease.index.get_level_values(3)","081c5bbd":"#Ploting propotions for people older than 50 (Age_Category =5,6)\nf = sns.FacetGrid(data=age_disease,col='heart_disease',row='hypertension',hue='stroke')\nf.map(sns.barplot,'age','proportion')","92f18fd4":"#The orange color represents the proportion of stroke. It's clear that heart disease and hypertension increase the probability of experiencing strokes","0fc855a5":"#JoinPlot\nsns.jointplot(x='bmi',y='avg_glucose_level',data=df,hue='stroke',alpha=0.2)","d9d64c71":"#Heatmap\nplt.figure(figsize=(10,6))\nsns.heatmap(df.corr(),annot=True)","77b86c08":"#heatmap\nsns.heatmap(df.isnull())","dc2424fc":"#Some bmi values are missing","c0af2d98":"#Correlation matrix shows that bmi is correlated with age (corr = 0.33), hypertension (corr = 0.17) and average glucose level (corr = 0.18).\n#We can create a linear model using these three parameters to predict missing BMI or just use mean per Age_Category.","80e6412e":"#Mean BMI per Age_Category & Hypertension & Stroke\ndg = df.groupby(['Age_Category','stroke','hypertension'])['bmi'].mean().reset_index()\ndg.head()","ab6040c6":"#Let's use this table to fill the missing values,\ndef fill_bmi(cols) :\n    global g\n    t = cols[3]\n    b = cols[0]\n    s = cols[1]\n    a = cols[2]\n    if np.isnan(b)==False :\n        return b\n    else : \n        return round(float(dg[(dg['stroke']==s) & (dg['Age_Category']==a) & (dg['hypertension']==t)]['bmi']),1)","763f23b0":"df['filled_bmi'] = df[['bmi','stroke','Age_Category','hypertension']].apply(fill_bmi,axis=1)","9abc4b4d":"dum1 = pd.get_dummies(df['gender'],drop_first=True)\ndum2 = pd.get_dummies(df['ever_married'],drop_first=True)\ndum3 = pd.get_dummies(df['work_type'],drop_first=True)\ndum4 = pd.get_dummies(df['Residence_type'],drop_first=True)\ndum5 = pd.get_dummies(df['smoking_status'],drop_first=True)","a12498ef":"df = pd.concat([df,dum1,dum2,dum3,dum4,dum5],axis=1)","308d4b8b":"#New correlation matrix \nplt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True)","4fce5e83":"X = df.drop(['id','gender','ever_married','work_type','Residence_type','smoking_status','Age_Category','stroke','bmi'],axis=1)\ny = df['stroke']","115df613":"#Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","8b537e1b":"#SMOTE on training Set\nsmote = SMOTE(sampling_strategy=0.7)\nX_trainS , y_trainS = smote.fit_resample(X_train,y_train)","e72e2cb2":"#Choosing K value by cross validation \n#Result Dataframe\nreport = pd.DataFrame(index = ['avg accuracy','avg sensitivity','avg precision','avg specifity','avg negative-precision','f-score'])\n#Kvalues\nK = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n\nfor i in K :\n    #Pipeline for scaling Data and fitting Knn model\n    pipe = Pipeline([('Scaler',StandardScaler()),('Classifier',KNeighborsClassifier(n_neighbors=i))])\n    arr = np.zeros(6)\n\n    #Using 5 folds for cross validation\n    for j in range(5) :\n        \n        X_fit, X_cv, y_fit, y_cv = train_test_split(X_trainS, y_trainS, test_size=0.16)\n        pipe.fit(X_fit,y_fit)\n        predictions = pipe.predict(X_cv)\n        acc = np.mean(predictions==y_cv) \n        #Computing metrics\n        TP = np.sum(np.array(predictions ==1)*np.array(predictions==y_cv))\n        TN = np.sum(np.array(predictions ==0)*np.array(predictions==y_cv))\n        FP = np.sum(np.array(predictions ==1)*np.array(predictions!=y_cv))\n        FN = np.sum(np.array(predictions ==0)*np.array(predictions!=y_cv))\n        if TP==0 and FP==0:\n            prec = 0\n        else : \n            prec = TP\/(TP+FP)\n        arr = arr + np.array([acc,TP\/(TP+FN),prec,TN\/(TN+FP),TN\/(TN+FN),2*(prec*TP\/(TP+FN))\/(prec+(TP\/(TP+FN)))])\n        \n    arr = arr\/5\n    #Adding result to Dataframe\n    report[str(f'{i}')] = arr","f43dc024":"#Report average accuracy, precision, specifity and Predictive value of negative class\nreport.head()","80291e0b":"\n#Maximum values are :\nsummary_max = pd.DataFrame([report.max(axis=1),report.idxmax(axis=1)],index=['Value','K value'])\nsummary_max","9ecdf3f6":"#K=1\npipe_c = Pipeline([('Scaler',StandardScaler()),('Classifier',KNeighborsClassifier(n_neighbors=1))])\npipe_c.fit(X_trainS,y_trainS)\npredictions_test = pipe_c.predict(X_test)\nprint(confusion_matrix(y_test,predictions_test))\nprint('\\n')\nprint(classification_report(y_test,predictions_test))","5599c7ef":"#K=2\npipe_c = Pipeline([('Scaler',StandardScaler()),('Classifier',KNeighborsClassifier(n_neighbors=2))])\npipe_c.fit(X_trainS,y_trainS)\npredictions_test = pipe_c.predict(X_test)\nprint(confusion_matrix(y_test,predictions_test))\nprint('\\n')\nprint(classification_report(y_test,predictions_test))","f79b0e31":"#If we try KNN using k=1 and without SMOTE ...\n#K=1\npipe_c = Pipeline([('Scaler',StandardScaler()),('Classifier',KNeighborsClassifier(n_neighbors=1))])\npipe_c.fit(X_train,y_train)\npredictions_test = pipe_c.predict(X_test)\nprint(confusion_matrix(y_test,predictions_test))\nprint('\\n')\nprint(classification_report(y_test,predictions_test))","87285408":"#SMOTE did help in improving f1 score of positive class wich is the minority in our Data...","8ca9a572":"#For this part, SMOTE wont be used","a294c70d":"report2 = pd.DataFrame(index = ['avg accuracy','avg sensitivity','avg precision','avg specifity','avg negative precision','f-score'])\n#K values\nK = range(1,50)\n#Treshhold values\nTreshhold = [0.1,0.2,0.3,0.4,0.5]\nfor i in K :\n    for t in Treshhold : \n        #pipeline for scaling and fitting model\n        pipe = Pipeline([('Scaler',StandardScaler()),('Classifier',KNeighborsClassifier(n_neighbors=i))])\n        arr = np.zeros(6)\n\n        #Cross Validation using 5folds\n        for j in range(5) :\n        \n            X_fit, X_cv, y_fit, y_cv = train_test_split(X_train, y_train, test_size=0.16)\n            pipe.fit(X_fit,y_fit)\n            #Computing probabilities\n            probabilities = pipe.predict_proba((X_cv))\n            #Selecting treshhold and predicting labels\n            predictions = (probabilities>=t)[:,1].astype(int)\n            #Computing Metrics\n            acc = np.mean(predictions==y_cv) \n            TP = np.sum(np.array(predictions ==1)*np.array(predictions==y_cv))\n            TN = np.sum(np.array(predictions ==0)*np.array(predictions==y_cv))\n            FP = np.sum(np.array(predictions ==1)*np.array(predictions!=y_cv))\n            FN = np.sum(np.array(predictions ==0)*np.array(predictions!=y_cv))\n            if TP==0 and FP==0:\n                prec = 0\n            else : \n                prec = TP\/(TP+FP)\n            arr = arr + np.array([acc,TP\/(TP+FN),prec,TN\/(TN+FP),TN\/(TN+FN),2*(prec*TP\/(TP+FN))\/(prec+(TP\/(TP+FN)))])\n        \n        arr = arr\/5\n        report2[str(f'({i},{t})')] = arr","7816ce7e":"#Maximum values are :\nsummary_max2 = pd.DataFrame([report2.max(axis=1),report2.idxmax(axis=1)],index=['Value','(K value,threshhold)'])\nsummary_max2","42732396":"#K=49 & Treshhold = 0.1\npipe_2 = Pipeline([('Scaler',StandardScaler()),('Classifier',KNeighborsClassifier(n_neighbors=49))])\npipe_2.fit(X_train,y_train)\nprobabilities_test = pipe_2.predict_proba(X_test)\npredictions_test = np.array([(probabilities_test >0.1)[:,1].astype(int)]).reshape(1533,)\nprint(confusion_matrix(y_test,predictions_test))\nprint('\\n')\nprint(classification_report(y_test,predictions_test))","06ede714":"#Better F1-score for positive class with a loss of accuracy ...","8e85793a":"### Age & Smoking_Status","03414157":"### Correlation ","e59a4c17":"### Get dummy variables for categorical data","ccf0f308":"### Fill BMI Column","e7d4d947":"### Missing Data","5ad07eef":"### Knn with modified majority rule (probability treshhold)","76cf3ab3":"### Gender","06532c9a":"# **Importing Libraries and Data**","bc65638b":"### Ever_married","7eb64267":"### Smoking status","b247fe77":"### Age","50b6289e":"# Data exploration","bda7a87d":"# k-nearest neighbors model","34030676":"### BMI & avg_glucose_level","27576399":"### Heart Disease & Hypertension","c7ec0973":"### KNN using SMOTE ","dd190b98":"# Data Preprocessing"}}