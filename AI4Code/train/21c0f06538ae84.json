{"cell_type":{"5998c52d":"code","378c060f":"code","33564dd3":"code","8153af51":"code","110e632c":"code","01c66257":"code","f65854b8":"code","ce7612ae":"code","a9a37534":"code","8ec44a5a":"code","f298542f":"code","85e465c8":"code","2fc68bc3":"code","066d5ad7":"code","1da58027":"code","1cc46c07":"code","eacd0ea3":"code","4692550a":"code","9dd8fbd4":"markdown","1b580bc7":"markdown"},"source":{"5998c52d":"# Imports\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","378c060f":"# Reading in train data\n\ntrain = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\")","33564dd3":"# Viewing the first 5 observations\n\ntrain.head()","8153af51":"# Function that reduces memory\n\ndef reduction_mem(df):\n    float_cols = [c for c in df if df[c].dtype == 'float64']\n    int_cols = [c for c in df if df[c].dtype in ['int64', 'int32']]\n    df[float_cols] = df[ float_cols].astype(np.float16)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df","110e632c":"# Reducing memory of the data \n\ntrain = reduction_mem(train)","01c66257":"# Getting the columns that has column names\n\nday_columns = [col for col in train.columns if 'd_' in col]","f65854b8":"# Getting only sales data\n\ntrain = train[day_columns]","ce7612ae":"# Transposing the data\n\ntrain = train.T\ntrain.shape","a9a37534":"# Scaling the features using min-max scaler in range 0-1\n\n## Importing MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n## Calling it\nsc = MinMaxScaler(feature_range = (0, 1))\n\n## Fitting on the train data and tranforming it\ntrain_scaled = sc.fit_transform(train)","8ec44a5a":"def process_data_by_timesteps(train_data, timesteps):\n    \n    print(f\"Forming batches of data every {timesteps} days\")\n    \n    X_train = []\n    y_train = []\n\n    ## Looping through the data\n    for i in range(timesteps, 1913-timesteps):\n\n        ### Getting a batch of timesteps\n        X_train.append(train_data[i-timesteps:i])\n\n        ### Setting the label as the next value in time after the timestamps\n        y_train.append(train_data[i][0:30490]) \n    \n    ## Viewing the shape of the first observation of the training data\n    print(f\"X_train shape: {X_train[0].shape}\")\n    print(f\"y_train shape: {y_train[0].shape}\")\n    \n    ## Viewing the shape after conversion\n    print(\"Converting to arrays...\")\n    \n    X_train = np.array(X_train, dtype = 'float16')\n    y_train = np.array(y_train, dtype = 'float16')\n    \n    print(f\"X_train array shape: {X_train.shape}\")\n    print(f\"y_train array shape: {y_train.shape}\")\n    \n    print(\"COMPLETE!!!\")\n    \n    return X_train, y_train","f298542f":"timesteps=28","85e465c8":"# Getting the processed train data\n\nX_train_f, y_train_f = process_data_by_timesteps(train_data=train_scaled, timesteps=14)","2fc68bc3":"# Creating the model\n\n## Tensorflow imports\nimport tensorflow as tf\n\n## Setting the input shape\ninput_shape = (np.array(X_train_f).shape[1], np.array(X_train_f).shape[2])\n\n## Creating a sequential model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.LSTM(64, return_sequences=True),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dense(30490),\n])\n\n## Viewing the summary of the model\nmodel.summary()\n\n## Compiling the model\nmodel.compile(optimizer='adam', metrics=['mse'], loss='mean_squared_error')","066d5ad7":"# Creating a callback\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=3, min_delta=0.001)","1da58027":"## Training\/ Fitting the model\n\nmodel.fit(X_train_f, y_train_f, epochs = 20, batch_size = 10, callbacks=[callback])","1cc46c07":"def process_test_data_and_get_predictions(train_data, timesteps):\n    \n    # Extracting the first observation of test set by taking the last \"timestamps\" of the training data\n    inputs = train_data[-timesteps:]\n    \n    # Transforming the same way as train data (NOT FITTING!)\n    inputs = sc.transform(inputs)\n    \n    # Creating the test set\n    X_test = []\n    X_test.append(inputs[0:timesteps])\n    X_test = np.array(X_test)\n    \n    # Using the trained model to predict \n\n    predictions = []\n\n    ## Need to predict 28 days\n    for j in range(timesteps,timesteps + 28):\n\n        print(f\"Observation Num: {j}\")\n\n        ### Predicting the next day\n        forecast = model.predict(X_test[0,j - timesteps:j].reshape(1, timesteps, 30490))\n        print(f\"Forecast shape: {forecast.shape}\")\n\n        # Adding the combined data as the next batch\n        X_test = np.append(X_test, forecast).reshape(1,j+1,30490)\n        print(f\"X_test shape: {X_test.shape}\")\n\n        # Inverse the scaling\n        forecast = sc.inverse_transform(forecast)[:,0:30490]\n        print(f\"Forecast shape: {forecast.shape}\")\n\n        # Append the forecast into the predictions\n        predictions.append(forecast)\n    \n    return predictions","eacd0ea3":"# Getting predictions\n\npredictions = process_test_data_and_get_predictions(train, timesteps)","4692550a":"import time\n\ndataPath = '..\/input\/m5-forecasting-accuracy\/'\n\nsubmission = pd.DataFrame(data=np.array(predictions).reshape(28,30490))\n\nsubmission = submission.T\n    \nsubmission = pd.concat((submission, submission), ignore_index=True)\n\nsample_submission = pd.read_csv(dataPath + \"\/sample_submission.csv\")\n    \nidColumn = sample_submission[[\"id\"]]\n    \nsubmission[[\"id\"]] = idColumn  \n\ncols = list(submission.columns)\ncols = cols[-1:] + cols[:-1]\nsubmission = submission[cols]\n\ncolsdeneme = [\"id\"] + [f\"F{i}\" for i in range (1,29)]\n\nsubmission.columns = colsdeneme\n\ncurrentDateTime = time.strftime(\"%d%m%Y_%H%M%S\")\n\nsubmission.to_csv(\"submission.csv\", index=False)","9dd8fbd4":"Learning how to set up a RNN model using this notebook:\nhttps:\/\/www.kaggle.com\/prakash711\/m5-forecasting-with-tensorflow-bilstm\n\nWhat I contributed:\n* Created a function that prepares the train data for a RNN model\n* Created a function that prepares and predicts on a test data\n* Added a callback function to the model\n* Documented code cell by cell to understand what is happening","1b580bc7":"### Processing the test set"}}