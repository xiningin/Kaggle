{"cell_type":{"d1667911":"code","2697f98e":"code","29fb037f":"code","e3faf27a":"code","1e20fc5b":"code","659a3652":"code","2a23eb5f":"code","985b729a":"code","acddc20d":"code","90b885a0":"code","2b02c150":"code","594c3b78":"code","5b98a37b":"code","c0794510":"markdown","3ba488dd":"markdown","8de0402f":"markdown","ca5cf88a":"markdown","8f1bd7fa":"markdown","95ee0d3d":"markdown","0f6ec7f1":"markdown","7764177b":"markdown","78f5c3b7":"markdown","c520fbd2":"markdown","c3abbd30":"markdown","cdaefcf5":"markdown"},"source":{"d1667911":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2697f98e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score,roc_auc_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import StratifiedKFold\n\nlog_r = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l1',\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)\n\ndf = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\nprint(df.shape)\ndf.head()","29fb037f":"\nrscale = RobustScaler()\namount = df['Amount'].values.reshape(-1,1)\ntime = df['Time'].values.reshape(-1, 1)\ndf['scaled_amount'] = rscale.fit_transform(amount)\ndf['scaled_time'] = rscale.fit_transform(time)\n\ndf = df.drop(['Amount', 'Time'], axis = 1)\n\nundersample_X = df.drop(['Class'], axis = 1)\nundersample_y = df['Class']\n\nundersample_X.shape","e3faf27a":"accuracy_skf = []\nprecision_score_skf = []\nrecall_score_skf = []\nroc_auc_score_skf = []\nf1_score_skf = []\n\nskf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\nfor train_index, test_index in skf.split(undersample_X, undersample_y):\n#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    undersample_X_train, undersample_X_test = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n    undersample_y_train, undersample_y_test = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n    \n    undersample_y_train = undersample_y_train.values.reshape(-1,1)\n    undersample_y_test = undersample_y_test.values.reshape(-1, 1)\n#     print('X - Train Shape', undersample_X_train.shape)\n    log_r.fit(undersample_X_train, undersample_y_train)\n    \n#     print('X - Test Shape',undersample_X_test.shape)\n#     prediction = log_r.predict(undersample_X_test)\n    \n    score_skf = accuracy_score(undersample_y_test, log_r.predict(undersample_X_test))\n    accuracy_skf.append(score_skf)\n    print('Accuracy SKF',score_skf)\n    \n    precision_skf = precision_score(undersample_y_test, log_r.predict(undersample_X_test))\n    print('Precision Score SKF', precision_skf)\n    precision_score_skf.append(precision_skf)\n    \n    recall_skf = recall_score(undersample_y_test, log_r.predict(undersample_X_test))\n    print('Recall Score - SKF', recall_skf)\n    recall_score_skf.append(recall_skf)\n    \n    f1_skf = f1_score(undersample_y_test, log_r.predict(undersample_X_test))\n    print('F1 Score SKF',f1_skf)\n    f1_score_skf.append(f1_skf)\n    roc_auc_skf = roc_auc_score(undersample_y_test, log_r.predict(undersample_X_test))\n    print('ROC Score SKF',roc_auc_skf)\n    roc_auc_score_skf.append(roc_auc_skf)\n    print(confusion_matrix(undersample_y_test, log_r.predict(undersample_X_test)))\n    \n","1e20fc5b":"import numpy as np\nprint('Accuracy - SKF',np.mean(accuracy_skf))\nprint('Precision Score - SKF',np.mean(precision_score_skf))\nprint('Recall Score - SKF',np.mean(recall_score_skf))\nprint('ROC-AUC - SKF',np.mean(roc_auc_score_skf))\nprint('F1 Score - SKF',np.mean(f1_score_skf))","659a3652":"from imblearn.under_sampling import NearMiss\n\nnm = NearMiss()\nX_nearmiss,y_nearmiss = NearMiss().fit_sample(undersample_X, undersample_y)\n\nfrom sklearn.model_selection import train_test_split\nX_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(X_nearmiss, y_nearmiss)\n\nlog_r.fit(X_train_nm,y_train_nm)\nprediction = log_r.predict(X_test_nm)\nscore_nm = accuracy_score(y_test_nm, prediction)\nprint('Accuracy NearMiss',score_nm)\nprecision_score_nm = precision_score(y_test_nm, prediction)\nprint('Precision Score NearMiss', precision_score_nm)\nrecall_score_nm = recall_score(y_test_nm, prediction)\nprint('Recall Score - NearMiss', recall_score_nm)\nf1_score_nm = f1_score(y_test_nm, prediction)\nprint('F1 Score NearMiss',f1_score_nm)\nroc_auc_score_nm = roc_auc_score(y_test_nm, prediction)\nprint('ROC Score NearMiss',roc_auc_score_nm)","2a23eb5f":"from sklearn.model_selection import learning_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import style\nstyle.use('fivethirtyeight')\ndef plot_learning_curve(model, X, y):\n    train_size, train_scores, test_scores = learning_curve(model, X, y, train_sizes=np.linspace(0.01, 1, 50), cv=10,\n                                                       scoring='accuracy', n_jobs=3, verbose=1, random_state=42,\n                                                      shuffle=True)\n    train_scores_mean = np.mean(train_scores, axis = 1)\n    train_scores_std = np.std(train_scores, axis = 1)\n    test_scores_mean = np.mean(test_scores, axis = 1)\n    test_scores_std = np.std(test_scores, axis = 1)\n    plt.figure(figsize = (8, 4))\n    plt.plot(train_size, train_scores_mean, color = 'red', label = 'Training Score')\n    plt.fill_between(train_size, train_scores_mean - train_scores_std, train_scores_mean+train_scores_std, color = '#DDDDDD')\n    plt.fill_between(train_size, test_scores_mean - test_scores_std, test_scores_mean+test_scores_std, color = '#DDDDDD')\n    plt.plot(train_size, test_scores_mean, color = 'green', label = 'CV Score')\n    plt.title('Learning Curve ')\n    plt.xlabel('CV Train Size')\n    plt.ylabel('Accuracy')\n    plt.legend(loc = 'best')\n    plt.show()\n    \n   ","985b729a":" plot_learning_curve(log_r, X_nearmiss,y_nearmiss)","acddc20d":"# from imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTETomek\n\nsm = SMOTETomek(random_state=42)\nX_sm, y_sm = sm.fit_resample(undersample_X, undersample_y)\n\nX_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm)\n\nlog_r.fit(X_train_sm,y_train_sm)\nprediction_sm = log_r.predict(X_test_sm)\nscore_sm = accuracy_score(y_test_sm, prediction_sm)\nprint('Accuracy SMOTE',score_sm)\nprecision_score_sm = precision_score(y_test_sm, prediction_sm)\nprint('Precision Score SMOTE', precision_score_sm)\nrecall_score_sm = recall_score(y_test_sm, prediction_sm)\nprint('Recall Score - SMOTE', recall_score_sm)\nf1_score_sm = f1_score(y_test_sm, prediction_sm)\nprint('F1 Score SMOTE',f1_score_sm)\nroc_auc_score_sm = roc_auc_score(y_test_sm, prediction_sm)\nprint('ROC Score SMOTE',roc_auc_score_sm)\n\n","90b885a0":"# it takes 67 mins to run this code.. So your Choice :)\n# plot_learning_curve(log_r, X_sm,y_sm)","2b02c150":"from sklearn.metrics import classification_report\n# print('Classification Report for SMTOE',classification_report(y_test_sm, prediction_sm)) \n# print('Confusion Matrix for SMTOE-LogR',confusion_matrix(y_test_sm, prediction_sm))","594c3b78":"print('Classification Report - NearMiss',classification_report(y_test_nm, prediction)) \nprint('Confusion Matrix - NearMiss',confusion_matrix(y_test_nm, prediction))","5b98a37b":"from sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nmodels = []\nmodels.append(('lreg', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l1',\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)))\nmodels.append(('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=7, p=2, weights='uniform')))\nmodels.append(('svc', SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n                         decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear',\n                         max_iter=-1, probability=False, random_state=None, shrinking=True,\n                         tol=0.001, verbose=False)))\nmodels.append(('dtc', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best')))\n\nfor name, model in models:\n    model.fit(X_train_nm,y_train_nm)\n    prediction = model.predict(X_test_nm)\n    score = accuracy_score(y_test_nm, prediction)\n    print('{} Accuracy NearMiss{}'.format(name,score_nm))\n    precision_score_nm = precision_score(y_test_nm, prediction)\n    print('{} Precision Score NearMiss{}'.format(name, precision_score_nm))\n    recall_score_nm = recall_score(y_test_nm, prediction)\n    print('{} Recall Score - NearMiss{}'.format(name,recall_score_nm))\n    f1_score_nm = f1_score(y_test_nm, prediction)\n    print('{} F1 Score NearMiss{}'.format(name, f1_score_nm))\n    roc_auc_score_nm = roc_auc_score(y_test_nm, prediction)\n    print('{} ROC Score NearMiss{}'.format(name, roc_auc_score_nm))\n    fpr,tpr,threshold = roc_curve(y_test_nm, log_r.predict_proba(X_test_nm)[:,1])\n    plt.figure(figsize = (8, 8))\n    plt.plot(fpr, tpr, label = 'Model (area = %.2f)' % roc_auc_score_nm, color = 'r')\n    plt.plot([0,1], [0,1], 'r--')\n    plt.title('ROC Curve -- {}'.format(name))\n    plt.xlabel('False Positive rate')\n    plt.ylabel('True Positive rate')\n    plt.legend(loc = 'best')\n    plt.show()\n    \n    plot_learning_curve(model, X_nearmiss,y_nearmiss)","c0794510":"Yes, the accuracy has gone down a bit, but look at the Recall score go UP!! This model is better that the previous one for sure!\nLets check if the SMOTE provides any better results.","3ba488dd":"I just averaged out the scores from the 5 runs above. Interesting numbers are Accuracy, who would not want a model that is 99.9 % accurate. But is the model really good?\nLook the the Recall Score its too low, which means the fraud records that were ideally supposed to be predicted as Fraud are not done in a accurate way. \nSooo.. K stratified Cross Validation does not work for me.","8de0402f":"If you look at the Learning curve for Logestic Regression above.. the train and CV curve run in (almost) parallel around 90% accuracy. Which means, providing more training data would not be of any help in improving the performance of the model.","ca5cf88a":"Lets run the SMOTE cross validation.\nNOTE - It takes ~ 10 mins for the code to run.","8f1bd7fa":"Using Robust Scaler over Standard scaler to Normalize the Amount and Time column, deleted the orignal columns in next step.","95ee0d3d":"Lets take a look at the Classification report and the Confusion Matrix for NearMiss and SMTOE cross validations","0f6ec7f1":"I will be trying the Near Miss and the SMOTE Cross Validation functions\nNear Miss - in my terms, this function will reduce the number of majority class to the number of minority class, it uses vector distance method to do so. It picks up records that are closest to the minority class data.\nSMOTE - This method adds minority class records. ","7764177b":"IN the code below i used Stratified K fold validation method to find the accuracy and the Recall score. ","78f5c3b7":"Hmm the Recall score for Decision tree Classifier is gone Up.. good news.. I'll take it. But wait, did you observe the DTC learining curve dipping down as the CV test size increases..\nSo, what do you'll say, which model is a good model??\nComments?","c520fbd2":"Importing all the necessary lib and the best estimated logestic Regression Model that was derived in Part 1.","c3abbd30":"I would like to see if the Logistic regression is really the best model when we use NearMiss CV.. Lets find out..","cdaefcf5":"This is Part 2 - \nIn this part I'll show how the Near Miss and SMOTE CV improves the Recall Accuracy of the models as compared to the Stratified Kfold.\n\nPlease note that few steps like reading the file and normalizing\/standardizing the Amount and Time columns will be repeated."}}