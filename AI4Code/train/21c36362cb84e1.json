{"cell_type":{"ff8f6851":"code","a2de2a8d":"code","a33055b2":"code","1ee35e7e":"code","89cd0416":"code","34846eef":"code","6b263c24":"code","55fc992e":"code","a13e473d":"code","84d47bd5":"code","e2d5b06c":"code","6dc9ace6":"code","ef68615e":"code","74a066b6":"code","02b4fba4":"code","d17dc6e3":"code","110372da":"code","ce8aa30e":"code","01a2d042":"code","d58e0ac5":"code","f8b16697":"code","6e3ad3c4":"code","985bcd29":"code","2558ccd9":"code","0e0c3d13":"code","05685941":"code","cc9def8d":"code","2cf4d2a2":"code","f098fbc5":"code","6c523946":"code","c7d4b320":"code","89468a01":"markdown","018518d1":"markdown","bd83d84f":"markdown","870746f0":"markdown","c32abcc2":"markdown"},"source":{"ff8f6851":"\nimport numpy as np\nimport pandas as pd \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","a2de2a8d":"df=pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","a33055b2":"df.head()","1ee35e7e":"print(\"Minimum Temperature   \"+str(df['MinTemp'].min()))\ndf.groupby('Location',sort = False)['MinTemp'].min().nsmallest()","89cd0416":"print(\"Maximum Temperature   \"+str(df['MaxTemp'].max()))\ndf.groupby('Location',sort = False)['MaxTemp'].max().nlargest()","34846eef":"print(\"Highest Rainfall      \"+str(df['Rainfall'].max()))\ndf.groupby('Location',sort = False)['Rainfall'].max().nlargest()","6b263c24":"# Let's see % of missing values\n\ndf.isnull().mean()","55fc992e":"# Missing values % in the features Evaporation=43%, Sunshine 48%, Cloud9am=38%, Cloud3pm=40% \n# This are to much missing value, I'm dropping this features.\n\ndf=df.drop(['Evaporation','Sunshine','Cloud9am','Cloud3pm'], axis = 1)","a13e473d":"# Let seperate Categories and numerical features\n\ndf_cat=df[['WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow','Date','Location']]\n\ndf_num=df.drop(['WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow','Date','Location'], axis = 1)","84d47bd5":"# Every location has different windspeed, direction, Temperature and Pressure  \n# Replacing Categories features with most frequent value based on location \n\nfor col in df_cat.columns.values:\n    if df[col].isnull().sum() == 0:\n        continue\n    df_cat[col] = df.groupby(['Location'])[col].apply(lambda x: x.fillna(x.mode().max()))","e2d5b06c":"# Still we have missing value for WindGustDir because for few locations we have no values \n\ndf_cat.isnull().mean()","6dc9ace6":"# We replace this values with the mode of complete dataset\n\ndf_cat['WindGustDir']=df['WindGustDir'].fillna(df['WindGustDir'].mode().max())","ef68615e":"# Replacing Numerical features with mean value based on location same as Categories\n\nfor col in df_num.columns.values:\n    if df[col].isnull().sum() == 0:\n        continue\n    df_num[col] = df.groupby(['Location'])[col].apply(lambda x: x.fillna(x.mean()))","74a066b6":"# This has same problem as df_cat, We will replace is mean value of dataset\n\ndf_num['WindGustSpeed']=df_num['WindGustSpeed'].fillna(df['WindGustSpeed'].mean())\ndf_num['Pressure9am']=df_num['Pressure9am'].fillna(df['Pressure9am'].mean())\ndf_num['Pressure3pm']=df_num['Pressure3pm'].fillna(df['Pressure3pm'].mean())\n","02b4fba4":"d={'Yes':1,'No':0}\ndf_cat['RainTomorrow']=df_cat['RainTomorrow'].map(d)\ndf_cat['RainToday']=df_cat['RainToday'].map(d)","d17dc6e3":"df_cat2=df_cat[['WindGustDir','WindDir9am','WindDir3pm','Location']]\n\n#Replacing Categories value with value counts\n\ndf_cat2['Location']=df_cat2['Location'].map(df_cat2['Location'].value_counts())\ndf_cat2['WindGustDir']=df_cat2['WindGustDir'].map(df_cat2['WindGustDir'].value_counts())\ndf_cat2['WindDir9am']=df_cat2['WindDir9am'].map(df_cat2['WindDir9am'].value_counts())\ndf_cat2['WindDir3pm']=df_cat2['WindDir3pm'].map(df_cat2['WindDir3pm'].value_counts())","110372da":"df_n=pd.merge(df_num, df_cat2, left_index=True, right_index=True)","ce8aa30e":"# Using Standar Scaler to scaled\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df_n)\ndf_scaled = pd.DataFrame(scaler.fit_transform(df_n),columns = df_n.columns)","01a2d042":"df_x=pd.merge(df_scaled, df_cat['RainToday'],left_index=True, right_index=True)","d58e0ac5":"df_x.hist(bins=50, figsize=(20, 10))\nplt.show()","f8b16697":"# Let see the correlation\n\nplt.figure(figsize=(20,10))\nheatmap = sns.heatmap(df_x.corr(), vmin=-1, vmax=1, annot=True)","6e3ad3c4":"# Teamp9am(89%) and Temp3pm(98%) has high correlation with MaxTemp\n\ndf_x.drop('Temp9am',axis=1,inplace=True)\ndf_x.drop('Temp3pm',axis=1,inplace=True)","985bcd29":"\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(df_x, df_cat['RainTomorrow'], test_size=0.2, random_state=50)","2558ccd9":"#As we can see we are dealing with big imbalance dataset, We need to perform oversampling\n\ndf_cat['RainTomorrow'].value_counts().plot(kind='barh')","0e0c3d13":"# Oversampled\n\nfrom imblearn.over_sampling import SMOTE \nsm = SMOTE(random_state = 37) \nX_train_res, y_train_res = sm.fit_resample(X_train, y_train)\nfrom collections import Counter\n\nprint(\"Before {}\".format(Counter(y_train)))\nprint(\"After {}\".format(Counter(y_train_res)))","05685941":"# XGBoost\n\nfrom sklearn import datasets, linear_model, metrics \nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score\nfrom xgboost import XGBClassifier\n\nmodel = XGBClassifier(max_depth=10,random_state = 37)\nmodel.fit(X_train_res, y_train_res)\nmodel.score(X_train_res, y_train_res)\n\ny_pred = model.predict(X_test)","cc9def8d":"print('Confusion matrix \\n {}'.format(confusion_matrix(y_test,y_pred)))\nprint('Accuracy score {:.2f}'.format(accuracy_score(y_test,y_pred)*100))\nprint(classification_report(y_test,y_pred))","2cf4d2a2":"from fbprophet import Prophet\n\nm = Prophet()\n\ndf_for=df[['Date','Rainfall']]\ndf_for['Date']=pd.to_datetime(df_for['Date'])\ndf_for.rename(columns = {'Date':'ds'}, inplace = True)\ndf_for.rename(columns = {'Rainfall':'y'}, inplace = True)\nm.fit(df_for)","f098fbc5":"future = m.make_future_dataframe(periods=1285)\nfuture.tail()","6c523946":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","c7d4b320":"from fbprophet.plot import add_changepoints_to_plot\nfig = m.plot(forecast)\na = add_changepoints_to_plot(fig.gca(), m, forecast)","89468a01":"# Data Cleaning","018518d1":"# Task : Most max temp","bd83d84f":"# Task : Update data up to 2020","870746f0":"# Task : The most min temp","c32abcc2":"# Task : Largest amount of rainfall"}}