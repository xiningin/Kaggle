{"cell_type":{"d57b8c21":"code","9ae17866":"code","ca950224":"code","79935b78":"code","832049cc":"code","89d6ee94":"code","90cf0b8b":"code","3f5f3d7e":"markdown"},"source":{"d57b8c21":"import nltk\nimport platform\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport gc\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\n\nimport torch\nimport transformers\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.simplefilter('ignore')","9ae17866":"class Config:\n    MAX_LEN = 284\n    TRAIN_BS = 12\n    STATE_DIR = \"..\/input\/training-kfolds-vanilla-pytorch-bert-starter\"\n    BERT_MODEL = 'bert-base-uncased'\n    FILE_NAME = '..\/input\/commonlitreadabilityprize\/test.csv'\n    TOKENIZER = transformers.BertTokenizer.from_pretrained('..\/input\/bert-base-uncased', do_lower_case=True)\n    scaler = GradScaler()","ca950224":"class BERTDataset(Dataset):\n    def __init__(self, review, target=None, is_test=False):\n        self.review = review\n        self.target = target\n        self.is_test = is_test\n        self.tokenizer = Config.TOKENIZER\n        self.max_len = Config.MAX_LEN\n    \n    def __len__(self):\n        return len(self.review)\n    \n    def __getitem__(self, idx):\n        review = str(self.review[idx])\n        review = ' '.join(review.split())\n        \n        inputs = self.tokenizer.encode_plus(\n            review,\n            None,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True\n        )\n        \n        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n        \n        if self.is_test:\n            return {\n                'ids': ids,\n                'mask': mask,\n                'token_type_ids': token_type_ids,\n            }\n        else:    \n            targets = torch.tensor(self.target[idx], dtype=torch.float)\n            return {\n                'ids': ids,\n                'mask': mask,\n                'token_type_ids': token_type_ids,\n                'targets': targets\n            }","79935b78":"# Model\nclass BERT_BASE_UNCASED(nn.Module):\n    def __init__(self):\n        super(BERT_BASE_UNCASED, self).__init__()\n        self.bert = transformers.BertModel.from_pretrained('..\/input\/bert-base-uncased')\n        self.drop = nn.Dropout(0.3)\n        self.fc = nn.Linear(768, 128)\n        self.out = nn.Linear(128, 1)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n        output = self.drop(output)\n        output = self.fc(output)\n        output = self.out(output)\n        return output\n    \nclass BERT_BASE_CASED(nn.Module):\n    def __init__(self):\n        super(BERT_BASE_CASED, self).__init__()\n        self.bert = transformers.BertModel.from_pretrained('..\/input\/bert-base-cased')\n        self.drop = nn.Dropout(0.3)\n        self.out = nn.Linear(768, 1)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n        output = self.drop(output)\n        output = self.out(output)\n        return output","832049cc":"@torch.no_grad()\ndef inference(model, states_list, test_dataloader, device=torch.device('cuda:0')):\n    \"\"\"\n    Do inference for different model folds\n    \"\"\"\n    model.eval()\n    all_preds = []\n    for state in states_list:\n        print(f\"State: {state}\")\n        state_dict = torch.load(state)\n        model.load_state_dict(state_dict)\n        model = model.to(device)\n        \n        # Clean\n        del state_dict\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        preds = []\n        prog = tqdm(test_dataloader, total=len(test_dataloader))\n        for data in prog:\n            ids = data['ids'].to(DEVICE, dtype=torch.long)\n            mask = data['mask'].to(DEVICE, dtype=torch.long)\n            ttis = data['token_type_ids'].to(DEVICE, dtype=torch.long)\n\n            outputs = model(ids=ids, mask=mask, token_type_ids=ttis)\n            preds.append(outputs.squeeze(-1).cpu().detach().numpy())\n            \n        all_preds.append(np.concatenate(preds))\n        \n        # Clean\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n    return all_preds","89d6ee94":"# Inference Code\nif __name__ == '__main__':\n    if torch.cuda.is_available():\n        print(\"\\n[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n        DEVICE = torch.device('cuda:0')\n    else:\n        print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n        DEVICE = torch.device('cpu')\n    \n    test_file = pd.read_csv(Config.FILE_NAME)\n    \n    test_data = BERTDataset(test_file['excerpt'].values, is_test=True)\n    test_data = DataLoader(\n        test_data,\n        batch_size=Config.TRAIN_BS,\n        shuffle=False\n    )\n    \n    state_list = [os.path.join(Config.STATE_DIR, x) for x in os.listdir(Config.STATE_DIR) if x.endswith(\".pt\")]\n    model = BERT_BASE_UNCASED()\n    \n    print(\"Doing Predictions for all folds\")\n    predictions = inference(model, state_list, test_data, device=DEVICE)\n    \n    final_predictions = pd.DataFrame(predictions).T.mean(axis=1).tolist()","90cf0b8b":"# Form the sample submission\nsub = pd.DataFrame()\nsub['id'] = test_file['id']\nsub['target'] = final_predictions\n\nsub.to_csv(\"submission.csv\", index=None)\nsub.head()","3f5f3d7e":"# Vanilla PyTorch BERT Starter - INFERENCE\n\n\ud83d\udccc Here's the training notebook: https:\/\/www.kaggle.com\/heyytanay\/training-vanilla-pytorch-bert-starter\n\n**If you liked this notebook, you can leave an upvote :)**"}}