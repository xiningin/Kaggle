{"cell_type":{"5aed5452":"code","6efa0098":"code","fb5076cd":"code","15c55059":"code","fbc60759":"code","9b5c386e":"code","b81bbd7d":"code","9f15c4fd":"code","24f4ea60":"markdown"},"source":{"5aed5452":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6efa0098":"import pydicom\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport sys\nimport glob\nfrom scipy.ndimage import zoom\nfrom tqdm import tqdm\nimport gc\n\ndir_path = '\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train\/'","fb5076cd":"from pydicom.pixel_data_handlers.util import apply_modality_lut\n# from pydicom.pixel_data_handlers.util import apply_color_lut\nfor fname in glob.glob('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00355637202295106567614' + '\/*dcm', recursive=False):\n    print(fname)\n    ttt = pydicom.dcmread(fname)\n    print(ttt)\n    print('ppp', ttt.pixel_array.max(), ttt.pixel_array.min())\n    hu = apply_modality_lut(ttt.pixel_array, ttt)\n    print(hu.max(), hu.min())\n    break","15c55059":"def dicom2d_to_3d(path):\n    # load the DICOM files\n    files = []\n    for fname in glob.glob(path + '\/*dcm', recursive=False):\n        files.append(pydicom.dcmread(fname))\n\n    # skip files with no SliceLocation (eg scout views)\n    slices = []\n    skipcount = 0\n    for f in files:\n        slices.append(f)\n\n    # ensure they are in the correct order\n    # slices = sorted(slices, key=lambda s: s.SliceLocation)\n    slices = sorted(slices, key=lambda s: s[0x00200013].value\/len(files))\n\n\n    # pixel aspects, assuming all slices are the same\n    ps = slices[0].PixelSpacing\n    ss = len(files)\/len(files)#slices[0].SliceThickness\n    ax_aspect = ps[1]\/ps[0]\n    sag_aspect = ps[1]\/ss\n    cor_aspect = ss\/ps[0]\n\n    # create 3D array\n    img_shape = list(slices[0].pixel_array.shape)\n    img_shape.append(len(slices))\n    img3d = np.zeros(img_shape)\n\n    # fill 3D array with the images from the files\n    for i, s in enumerate(slices):\n        img2d = s.pixel_array\n        img3d[:, :, i] = img2d\n\n    \n    resize_img3d = zoom(img3d, (64\/files[0].Rows, 64\/files[0].Columns, 64\/len(files)))\n    # normalization\n    #resize_img3d = resize_img3d.clip(0, resize_img3d.max()) \/ resize_img3d.max() * 255\n    resize_img3d = ((resize_img3d - resize_img3d.min()) \/ (resize_img3d.max() - resize_img3d.min())) * 255\n    resize_img3d = resize_img3d.astype('int8')\n    \n    del files\n    del img3d\n\n    return resize_img3d.astype('uint8')","fbc60759":"train_data = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/sample_submission.csv')","9b5c386e":"dir_path = '\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train\/'\npatient_name = 'ID00111637202210956877205'\ntrain_image_dict = {}\nexcept_patient_name = []\nfor patient_name in tqdm(train_data.Patient.unique()):\n    try:\n        train_image_dict[patient_name] = dicom2d_to_3d(dir_path + patient_name)\n        np.save('\/kaggle\/working\/' + patient_name + '.npy', train_image_dict[patient_name])\n    except:\n        except_patient_name.append(patient_name)    ","b81bbd7d":"test = np.load('ID00111637202210956877205.npy')","9f15c4fd":"plt.imshow(test[:, :, 34])","24f4ea60":"merge dicom image slice, and interpolation image\n64 * 64 * 64 resize\n\n\\['ID00011637202177653955184', 'ID00052637202186188008618'\\] has byte size erro"}}