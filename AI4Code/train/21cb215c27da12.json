{"cell_type":{"fcd4b2fb":"code","bd69cfba":"code","2687a67c":"code","b2799246":"code","b8bbadae":"code","081f19c6":"code","679a559c":"code","a71d1394":"code","8d28eae1":"code","0f52554d":"code","e2f364ed":"code","9b2f5d97":"code","3668442f":"code","b4f68d60":"code","0944307c":"code","d1761bb3":"code","46a56c8d":"code","58108107":"code","2831aaf0":"markdown","ff9955f4":"markdown","01d5463b":"markdown","d93bbe6a":"markdown","fa43b809":"markdown","71f68fc1":"markdown","5c14b6dc":"markdown","f16da84c":"markdown","f5bdb8c3":"markdown","99867fe7":"markdown","af36f4ee":"markdown","ad902062":"markdown","36b251e9":"markdown","fd38374e":"markdown"},"source":{"fcd4b2fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd69cfba":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet ,LinearRegression\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nwarnings.simplefilter(\"ignore\")","2687a67c":"df = pd.read_csv(\"..\/input\/clothessizeprediction\/final_test.csv\")\ndf.head()","b2799246":"df['age'] = df ['age'].fillna(df['age'].median())\ndf['height'] = df ['height'].fillna(df['height'].median())\ndf['BMI'] = df['weight'] \/ (df['height']\/100)**2\n","b8bbadae":"scaler = MinMaxScaler(feature_range=(0, 1))\ndf_final = pd.DataFrame(scaler.fit_transform(pd.DataFrame(df.loc[:,['age','height','weight','BMI']])))\ndf_final.columns = ['age','height','weight','BMI']\ndf_final['size'] = df['size']\ndf_final","081f19c6":"df_final['size'] = df_final['size'].map({'XXS': 1, 'S': 2, \"M\" : 3, \"L\" : 4, \"XL\" : 5, \"XXL\" : 6, \"XXXL\" : 7})\ndf_final","679a559c":"df['size'].value_counts()","a71d1394":"X_train, X_test, y_train, y_test = train_test_split(df_final.drop(columns=['size']), df_final['size'], test_size=0.33, random_state=42)","8d28eae1":"model = lgb.LGBMRegressor(objective='regression', num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin=55, bagging_fraction=0.8,\n                              bagging_freq=5, feature_fraction=0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf=6, min_sum_hessian_in_leaf=11)\n\nmodel.fit(X_train, y_train)\n\nyaht = model.predict(X_test)\npred = pd.DataFrame(yaht)\npred.columns = ['lgbmPred']\n#pred['lgbmPred'] = pred['lgbmPred'].apply(lambda x: round(x))\npred['real'] = y_test.reset_index(drop=True)\npred","0f52554d":"reg = LinearRegression().fit(X_train, y_train)\npred['LinearPred'] = reg.predict(X_test)\n#pred['LinearPred'] = pred['LinearPred'].apply(lambda x: round(x))\npred","e2f364ed":"regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\npred['MLPPred']  = regr.predict(X_test)\n#pred['MLPPred'] = pred['MLPPred'].apply(lambda x: round(x))\npred","9b2f5d97":"neigh = KNeighborsRegressor(n_neighbors=2)\nneigh.fit(X_train, y_train)\npred['KNNPred']  = neigh.predict(X_test)\n#pred['KNNPred'] = pred['KNNPred'].apply(lambda x: round(x))\npred","3668442f":"for size_ in range(1,7):\n    print('--------------------------------')\n    print('Accuracy for size:' + str(size_))\n    test = pred.loc[pred.real==size_,:]\n    for i in ['lgbmPred','LinearPred', 'MLPPred', 'KNNPred']:\n        print(i  + ' model accuracy')\n        print(accuracy_score(test['real'], test[i].apply(lambda x: round(x))))","b4f68d60":"pred['pred'] = pred.loc[:,['lgbmPred','LinearPred', 'MLPPred', 'KNNPred']].mean(axis=1)\npred['pred'] = pred['pred'].apply(lambda x: round(x))\npred.loc[:,['lgbmPred','LinearPred', 'MLPPred', 'KNNPred','pred','real']].head(20)","0944307c":"pred.loc[pred['pred']<1,'pred']=1\npred.loc[pred['pred']>7,'pred']=7","d1761bb3":"print('Average Model accuracy')\nprint(accuracy_score(pred['real'], pred['pred']))","46a56c8d":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(pred['real'], pred['pred'])\ncm","58108107":"import matplotlib.pyplot as plt\nimport seaborn as sn\nplt.figure(figsize = (10,7))\ndf_cm = pd.DataFrame(cm, index = [i for i in ['XXS','S',\"M\",\"L\", \"XL\",\"XXL\",\"XXXL\"]],\n                  columns = [i for i in ['XXS','S',\"M\",\"L\", \"XL\",\"XXL\",\"XXXL\"]])\nsn.heatmap(df_cm, annot=True)","2831aaf0":"number of sample by size","ff9955f4":"Train KNNregressor","01d5463b":"Train MLP regression ","d93bbe6a":"load the dataset","fa43b809":"Import packages","71f68fc1":"Calculate the ACC by colth size","5c14b6dc":"Split the data into a train\/test","f16da84c":"Train a LightGBM model","f5bdb8c3":"Scale the data","99867fe7":"Clean the data and fill the missing values ","af36f4ee":"The average accuracy","ad902062":"Encode the SIZE attribute","36b251e9":"Train Linear regression model","fd38374e":"Lets calculate the average size predicion"}}