{"cell_type":{"d2982e48":"code","56f05eb0":"code","6834fb56":"code","14e02214":"code","c760eae2":"code","73264193":"code","b474775a":"code","47c73331":"code","f03b03c6":"code","a5634cf5":"code","4a722c86":"code","2b4e69fa":"code","de413bc9":"code","b574fd02":"code","35e425a6":"code","fb716b2d":"code","e3514ca5":"code","2e6848e8":"code","bc1eaddc":"code","e6af3347":"code","f6e9d8e5":"code","82a6db31":"code","d2891616":"code","ea39e948":"code","0ecea8a8":"code","331d006b":"code","480754ba":"code","30068dc2":"code","7be37c85":"code","5ea7332f":"code","e48395ef":"code","59ed0b6f":"code","8a99984b":"code","859e974e":"code","986f9850":"code","3c9d685b":"code","a04c1dd1":"code","03191c20":"code","c2cd7723":"markdown","07ae9722":"markdown","5a528e03":"markdown","bbf488d8":"markdown","be57f852":"markdown","8b62b26d":"markdown","9eb2db3c":"markdown","28efc95d":"markdown","3e466cdb":"markdown","0be090fe":"markdown","d78a1b53":"markdown","a2c794ce":"markdown"},"source":{"d2982e48":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","56f05eb0":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D\nfrom tensorflow.keras.layers import Input, Dense\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.applications.vgg16 import VGG16","6834fb56":"PATH = os.getcwd()\nprint(PATH)\nPATH = '..\/input\/10_categories-1551435405057\/10_categories'\nprint(os.listdir(PATH))\ndata_dir_list = os.listdir(PATH)\nprint(data_dir_list)","14e02214":"img_rows=224\nimg_cols=224\nnum_channel=3\n\nnum_epoch = 5\nbatch_size = 32\n\nimg_data_list=[]\nclasses_names_list=[]\ntarget_column=[]","c760eae2":"for dataset in data_dir_list:\n    classes_names_list.append(dataset)\n    print(\"Getting images from {} folder\\n\".format(dataset))\n    img_list = os.listdir(PATH+'\/'+ dataset)\n    for img in img_list:\n        input_img = cv2.imread(PATH + '\/' + dataset + '\/' + img)\n        input_img_resize=cv2.resize(input_img,(img_rows,img_cols))\n        img_data_list.append(input_img_resize)\n        target_column.append(dataset)","73264193":"# Checking the number of classed present \nnum_classes = len(classes_names_list)\nprint(num_classes)","b474775a":"img_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data \/= 255\nprint(img_data.shape)","47c73331":"num_of_samples = img_data.shape[0]\ninput_shape = img_data[0].shape","f03b03c6":"Labelencoder = LabelEncoder()\ntarget_column = Labelencoder.fit_transform(target_column)\nnp.unique(target_column)","a5634cf5":"# Shuffle the images and do a test train split \ntarget_column_hotcoded = to_categorical(target_column,num_classes)\nX,Y = shuffle(img_data,target_column_hotcoded,random_state=2)\nX_train,X_temp,y_train,y_temp = train_test_split(X,Y,test_size=0.3,random_state=2)\nX_test,X_val,y_test,y_val = train_test_split(X_temp,y_temp,test_size=0.3,random_state=2)","4a722c86":"first_Mod = Sequential()\n\nfirst_Mod.add(Conv2D(64,(3,3),activation='relu',input_shape=input_shape))\nfirst_Mod.add(Conv2D(64,(3,3),activation='relu'))\nfirst_Mod.add(MaxPool2D(pool_size=(2,2)))\nfirst_Mod.add(Dropout(0.5))\n\nfirst_Mod.add(Conv2D(128,(3,3),activation='relu'))\nfirst_Mod.add(Conv2D(128,(3,3),activation='relu'))\nfirst_Mod.add(MaxPool2D(pool_size=(2,2)))\nfirst_Mod.add(Dropout(0.5))\n\nfirst_Mod.add(Flatten())\nfirst_Mod.add(Dense(128,activation='relu'))\nfirst_Mod.add(Dropout(0.5))\nfirst_Mod.add(Dense(num_classes,activation='softmax'))","2b4e69fa":"#Compile the model\nfirst_Mod.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nfirst_Mod.summary()","de413bc9":"hist = first_Mod.fit(X_train,y_train,batch_size=batch_size,epochs=num_epoch,verbose=1,validation_data=(X_test,y_test))\nscore = first_Mod.evaluate(X_test,y_test,batch_size=batch_size)\nprint('Test Loss',score[0])\nprint(\"Test Accuracy\",score[1])","b574fd02":"test_image = X_test[0:1]\nplt.imshow(X_test[5])","35e425a6":"#Summarize hist for accuracy\nplt.plot(hist.history['acc'])\nplt.plot(hist.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','test'],loc = 'upper left')\nplt.show()\n\n#summarize hist for loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','test'],loc = 'upper left')\nplt.show()","fb716b2d":"data_gen = ImageDataGenerator(\n    rotation_range=20,\n    shear_range=0.5, \n    zoom_range=0.4, \n    rescale=1.\/255,\n    vertical_flip=True, \n    validation_split=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\nTRN_AUGMENTED = os.path.join(PATH , 'Trn_Augmented_Images')\nTST_AUGMENTED = os.path.join(PATH , 'Tst_Augmented_Images')","e3514ca5":"ftrain_generator = data_gen.flow(X_train,y_train,batch_size=batch_size,shuffle=True,subset='training')\nftest_generator = data_gen.flow(X_test,y_test,batch_size=batch_size,shuffle=True,subset='validation')","2e6848e8":"first_Mod.fit_generator(ftrain_generator,epochs=num_epoch,validation_data=ftest_generator,workers=6)","bc1eaddc":"first_Mod.evaluate_generator(ftest_generator,verbose=1)","e6af3347":"#Predict on agumented dataset","f6e9d8e5":"train_fdata_predict = first_Mod.predict_generator(ftest_generator,verbose=1)\ntrain_fdata_predict.argmax(axis=1)","82a6db31":"print(\"Loss: \", fd_model_evaluate[0], \"Accuracy: \", fd_model_evaluate[1])","d2891616":"Y_pred = first_Mod.predict(X_test)\nprint(Y_pred[10])\nplt.imshow(X_test[10])\n\ny_pred=np.argmax(Y_pred,axis=1)\nprint(y_pred[10])","ea39e948":"#Data Augmentation Using flow_from_directory","0ecea8a8":"train_generator = data_gen.flow_from_directory(\n        PATH,\n        target_size=(img_rows, img_cols), \n        batch_size=batch_size,\n        class_mode='categorical',\n        color_mode='rgb', \n        shuffle=True,  \n        #save_to_dir=TRN_AUGMENTED, \n        #save_prefix='TrainAugmented', \n        #save_format='png', \n        subset=\"training\")","331d006b":"train_generator.class_indices","480754ba":"test_generator = data_gen.flow_from_directory(\n        PATH,\n        target_size=(img_rows, img_cols),\n        batch_size=32,\n        class_mode='categorical',\n        color_mode='rgb', \n        shuffle=True, \n        seed=None, \n        #save_to_dir=TST_AUGMENTED, \n        #save_prefix='TestAugmented', \n        #save_format='png',\n        subset=\"validation\")","30068dc2":"first_Mod.fit_generator(train_generator,epochs=num_epoch,validation_data=test_generator)\nfd_model_evaluate = first_Mod.evaluate_generator(test_generator,verbose=1)\nprint(\"Loss: \", fd_model_evaluate[0], \"Accuracy: \", fd_model_evaluate[1])","7be37c85":"fd_model_predict = first_Mod.predict_generator(test_generator,verbose=1)\nfd_model_predict.argmax(axis=1)","5ea7332f":"image_input = Input(shape=(img_rows,img_cols,num_channel))\nvgg_mod = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\nvgg_mod.summary()","e48395ef":"last_layer = vgg_mod.get_layer('fc2').output\nout = Dense(num_classes,activation='softmax',name='output')(last_layer)","59ed0b6f":"cust_vgg_model = Model(image_input,out)\ncust_vgg_model.summary()","8a99984b":"for layer in cust_vgg_model.layers[:-1]:\n    layer.trainable = False\ncust_vgg_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=[\"accuracy\"])","859e974e":"hist_1=cust_vgg_model.fit(X_train,y_train,batch_size=batch_size,epochs=5,verbose=1,validation_data=(X_test, y_test))","986f9850":"Y_test_pred = cust_vgg_model.predict(X_test)\ny_test_pred = np.argmax(Y_test_pred,axis=1)","3c9d685b":"#Summarize hist for accuracy\nplt.plot(hist_1.history['acc'])\nplt.plot(hist_1.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','test'],loc = 'upper left')\nplt.show()\n\n#summarize hist for loss\nplt.plot(hist_1.history['loss'])\nplt.plot(hist_1.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','test'],loc = 'upper left')\nplt.show()","a04c1dd1":"test_generator.class_indices","03191c20":"\nfor i in range(1,30):\n    plt.imshow(X_test[i])\n    #plt.imshow(np.fliplr(X_test[i]))\n    print(y_test_pred[i])\n    plt.show(block=False)\n    \n","c2cd7723":"### Manual Verification of how the classification of Images are performed on the test data ","07ae9722":"#### Image Augmenta","5a528e03":"#### Image Augumentation using Image Data Generator","bbf488d8":"#### Label encoder to label the images with the numeric values ","be57f852":"#### Plotting the Learning Curve ","8b62b26d":"#### Image Pre-Processing","9eb2db3c":"#### Required variables to define the image sizes and number of epochs to run for each model ","28efc95d":"### Importing the Necessary Libararies ","3e466cdb":"### Building a Convolution Layer on the basic images ","0be090fe":"#### Transfer Learning VGG NET","d78a1b53":"#### Plotting the Learning Curve ","a2c794ce":"##### Loading all the images from the given folder and labeling to the each image with the directory name"}}