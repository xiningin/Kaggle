{"cell_type":{"f66ca121":"code","48df9637":"code","e00f25a3":"code","5c953ac8":"code","30fd0c85":"code","b07fa9fe":"code","e9000859":"code","b31c49ac":"code","c7d4aaf2":"code","d28c637b":"markdown","1fd33e38":"markdown","596ea799":"markdown"},"source":{"f66ca121":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy import linalg\nimport sys\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\nimport cv2","48df9637":"def svd(A, tol=1e-5):\n    #singular values and right singular vectors coming from eigenvalues and eigenvectors of A' x A\n    eigs, V = linalg.eig(A.T.dot(A))\n\n    #singular values are the square root of the eigenvalues\n    sing_vals = np.sqrt(eigs)\n\n    #sort both sigular values and right singular vector\n    idx = np.argsort(sing_vals)\n\n    sing_vals = sing_vals[idx[::-1]]\n    V = V[:, idx[::-1]]\n\n    #remove zero singular values below tol\n    sing_vals_trunc = sing_vals[sing_vals>tol]\n    V = V[:, sing_vals>tol]\n\n    #is not necessary to store the entire sigma matrix, so only the diagonal is returned\n    sigma = sing_vals_trunc\n\n    #evaluate U matrix\n    U = A @ V \/sing_vals_trunc\n    \n    return U.real, sigma.real, V.T.real","e00f25a3":"def truncate(U, S, V, k):\n    U_trunc = U[:, :k]\n    S_trunc = S[:k]\n    V_trunc = V[:k, :]\n    return U_trunc, S_trunc, V_trunc","5c953ac8":"from sklearn.datasets import load_iris\nimport seaborn as sns\nimport pandas as pd\n\niris = load_iris()\niris.keys()","30fd0c85":"data = pd.DataFrame(iris.data)\nfeature_names = iris[\"feature_names\"]\ndata.columns = feature_names\ndata[\"labels\"] = iris.target","b07fa9fe":"def custom_pairplot(data, feature_names, labels):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(left = 0, right=1.5, bottom=0, top=1.5)\n    n_features = len(feature_names)\n    \n    for i in range(len(feature_names)):\n        for j in range(len(feature_names)):\n            plt.subplot(n_features, n_features, i*n_features+j+1)\n            if i==j:\n                sns.violinplot(data=data, x=labels, y=feature_names[i])\n            else:\n                plt.scatter(data[feature_names[i]], data[feature_names[j]], c=data[labels])\n                plt.xlabel(feature_names[i])\n                plt.ylabel(feature_names[j])","e9000859":"custom_pairplot(data, feature_names=feature_names, labels=\"labels\")","b31c49ac":"k = 2\n\nA = data[feature_names].values\n\nU, S, Vt = svd(A)\nU_trunc, S_trunc, Vt_trunc = truncate(U, S, Vt, k)\n\ntrunc_A = U_trunc @ np.diag(S_trunc)\nreduced_data = pd.DataFrame(trunc_A)\nplt.figure(figsize=(5, 5))\nplt.barh(feature_names[::-1], S[::-1])\nplt.title(f\"Singular values, (first {k} are kept)\")\nplt.gca().xaxis.grid(True)","c7d4aaf2":"plt.figure(figsize=(5, 5))\nplt.scatter(reduced_data[0], reduced_data[1], c = iris.target)\nplt.xlabel(\"First feature\")\nplt.ylabel(\"Second feature\");","d28c637b":"# **SVD for dimensionality reduction**\n\nKita dapat melihat bagaimana dekomposisi svd berlaku untuk dimensionality reduction, dalam contoh ini, menggunakan set data Iris yang tersedia langsung dari library sklearn","1fd33e38":"#  **SVD decomposition and applications\u00b6**\n\nSVD adalah faktorisasi yang digunakan untuk menyelesaikan persamaan linear, pengurangan dimensi, kompresi data dan sebagainya.\nIni didasarkan pada dekomposisi berikut:\n\n                                                                      A=U\u03a3V\u2217\n \nDiamana matriks A (m x n) dapat difaktorkan menjadi 3 matriks:\nU (m x m) Matriks Kesatuan\n\u03a3 (m x n) Matriks Diagonal Persegi\nV (n x n) Matriks Kesatuan\n\nKolom V adalah vektor eigen dari A*A yang disebut vektor singular\nKolom U adalah vektor eigen dari AA* yang disebut vektor singular\nElemen pada diagonal \u03a3 adalah nilai eigen tidak nol terurut dari A*A and AA* yang disebut nilai singular","596ea799":"# nama  : Dinda Tsania\n# NIM   : 20190040009\n# kelas : TI 19B\n# tugas : 2 (machine learning)\n"}}