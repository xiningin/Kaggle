{"cell_type":{"efce2015":"code","6752bdff":"code","013b2c43":"code","1cd677e2":"code","6d6f6bac":"code","2e7795be":"code","14b6d687":"code","3f095a15":"code","b35d1cbd":"code","ea67b755":"code","07b1559d":"code","93dfb1ef":"code","7e43eb44":"code","e7570f73":"code","12699012":"code","6a674688":"code","67b05f19":"code","e0a86f85":"code","418253d9":"code","d278a2dc":"code","39433bfc":"code","f15a6d8e":"code","f7444fc4":"code","c494d79c":"code","0cec3a6c":"code","b3ba47ae":"code","da552407":"code","de9b1498":"code","0db944b8":"markdown","38ccbb04":"markdown","8cfce634":"markdown","2b2be3c0":"markdown"},"source":{"efce2015":"from fastai.tabular.all import *\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc, mean_absolute_error, mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBClassifier, XGBRFRegressor\nimport lightgbm as lgb\nimport seaborn as sns\nimport optuna\nfrom sklearn.preprocessing import RobustScaler\n","6752bdff":"df_train = pd.read_csv('..\/input\/predict-full-csv\/train_full.csv')\ndf_test = pd.read_csv('..\/input\/predict-full-csv\/test_full.csv')","013b2c43":"idx = list(range(len(df_train)))","1cd677e2":"dep_var = 'song_popularity'\nfeatures = list(df_train.drop(dep_var, axis=1).columns)","6d6f6bac":"features","2e7795be":"x = df_train[features]\ny = df_train[dep_var]","14b6d687":"cat_indices = [\"key\", \"audio_mode\", \"time_signature\"]","3f095a15":"x.columns","b35d1cbd":"# def run(trial, data=x, target=y):\n#     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)\n    \n#     params = {\n#         'max_depth': trial.suggest_int('max_depth', 6, 15),\n#         'n_estimators': trial.suggest_int('n_estimators', 100, 20000, 500),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n#         'subsample': trial.suggest_discrete_uniform('subsample', 0.2, 0.9, 0.1),\n#         'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.2, 0.9, 0.1),\n#         'colsample_bylevel': trial.suggest_discrete_uniform('colsample_bylevel', 0.2, 0.9, 0.1),\n#         'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-4, 1e4),\n#         'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 1e4),\n#         'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 1e4),\n#         'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n#         'objective': 'binary:logistic',\n#          }\n    \n#     model = XGBClassifier(**params, booster= 'gbtree',\n#                             eval_metric = 'auc',\n#                             tree_method= 'gpu_hist',\n#                             predictor=\"gpu_predictor\",\n#                             random_state=9, \n#                             gpu_id = 0,\n#                             use_label_encoder=False)\n#     model.fit(x_train,y_train,eval_set=[(x_test,y_test)], early_stopping_rounds=300, verbose=False)\n    \n#     preds = model.predict_proba(x_test)[:,1]\n#     fpr, tpr, _ = roc_curve(y_test, preds)\n#     score = auc(fpr, tpr)\n    \n#     return score","ea67b755":"study = optuna.create_study(direction='maximize')\nstudy.optimize(run,n_trials=100)","07b1559d":"# study.best_params","93dfb1ef":"xgb_params = {'max_depth': 12,\n 'n_estimators': 5600,\n 'learning_rate': 0.07074059946646541,\n 'subsample': 0.8,\n 'colsample_bytree': 0.6000000000000001,\n 'colsample_bylevel': 0.5,\n 'min_child_weight': 0.00390933891195369,\n 'reg_lambda': 2176.9882633091584,\n 'reg_alpha': 0.00027465681042320085,\n 'gamma': 0.45590270702576924}\n","7e43eb44":"preds_fold = []\nroc_fold = []\npseule_lbl_idx_0 = []\npseule_lbl_idx_1 = []\n\nfor i in range(50):\n    random.shuffle(idx)\n    train_idx = idx[:int(len(df_train)*0.8)]\n    valid_idx = idx[int(len(df_train)*0.8):]\n    x_train = x.iloc[train_idx]\n    y_train = y.iloc[train_idx]\n    x_valid = x.iloc[valid_idx]\n    y_valid = y.iloc[valid_idx]\n    \n    model = XGBClassifier(**xgb_params, booster= 'gbtree',\n                        eval_metric = 'auc',\n                        tree_method= 'gpu_hist',\n                        predictor=\"gpu_predictor\",\n                        random_state=i, \n                        use_label_encoder=False)\n                         \n    model.fit(x_train,y_train,early_stopping_rounds=100,eval_set=[(x_valid,y_valid)],verbose=False)\n    preds_valid = model.predict_proba(x_valid)\n    roc = roc_auc_score(y_valid,preds_valid[:,1])\n    roc_fold.append(roc)\n    print(F'fold {i}: ROC AUC {roc}')\n    preds_test = model.predict_proba(df_test)[:,1]\n    idx_confidence_low = list(np.where(preds_test < 0.25)[0])\n#     idx_confidence_high = list(np.where(preds_test > 0.7)[0])\n    pseule_lbl_idx_0.extend(idx_confidence_low)\n#     pseule_lbl_idx_1.extend(idx_confidence_high)","e7570f73":"new_idx = list(set(pseule_lbl_idx_0))","12699012":"df_pseudo = df_test.iloc[new_idx]","6a674688":"df_pseudo.assign(song_populariy=0)\n","67b05f19":"df_pseudo.shape","e0a86f85":"df_train = df_train.append(df_pseudo)","418253d9":"df_train.shape","d278a2dc":"x = df_train[features]\ny = df_train[dep_var]","39433bfc":"preds_fold = []\nroc_fold = []\nfor i in range(100):\n    random.shuffle(idx)\n    train_idx = idx[:int(len(df_train)*0.8)]\n    valid_idx = idx[int(len(df_train)*0.8):]\n    x_train = x.iloc[train_idx]\n    y_train = y.iloc[train_idx]\n    x_valid = x.iloc[valid_idx]\n    y_valid = y.iloc[valid_idx]\n    \n    model = XGBClassifier(**xgb_params, booster= 'gbtree',\n                          scale_pos_weight = 0.5,\n                        eval_metric = 'auc',\n                        tree_method= 'gpu_hist',\n                        predictor=\"gpu_predictor\",\n                        random_state=i, \n                        use_label_encoder=False)\n                         \n    model.fit(x_train,y_train,early_stopping_rounds=100,eval_set=[(x_valid,y_valid)],verbose=False)\n    preds_valid = model.predict_proba(x_valid)\n    roc = roc_auc_score(y_valid,preds_valid[:,1])\n    roc_fold.append(roc)\n    print(F'fold {i}: ROC AUC {roc}')\n    preds_test = model.predict_proba(df_test)[:,1]\n    preds_fold.append(preds_test)","f15a6d8e":"roc_fold = np.array(roc_fold)","f7444fc4":"np.mean(roc_fold), np.std(roc_fold)\n","c494d79c":"preds_fold = np.array(preds_fold)","0cec3a6c":"final_preds = np.mean(preds_fold, axis=0)\n","b3ba47ae":"submission = pd.read_csv('\/kaggle\/input\/song-popularity-prediction\/sample_submission.csv')\n","da552407":"submission['song_popularity'] = final_preds\n","de9b1498":"submission.to_csv('submission.csv', index=False)","0db944b8":"## Predictions","38ccbb04":"Version 30: experiments with pseudo labeling\nThe .csv with all missing values filled you can find here: https:\/\/www.kaggle.com\/dienhoa\/csv-fiiling-missing-values-song-popularity","8cfce634":"## Tuning params\u00b6\n","2b2be3c0":"## Pseudo label"}}