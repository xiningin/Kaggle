{"cell_type":{"265034ce":"code","72cbfc69":"code","f193a116":"code","5aa0f338":"code","1be32418":"code","2f0ba9c0":"code","bf0fe3d7":"code","36988bfc":"code","149b92aa":"code","838c9e87":"code","75481cab":"code","2c31e81d":"code","87816fdf":"code","bd9b6104":"code","d5c70c92":"code","079e1ade":"code","8d5a67a5":"code","16d12707":"markdown","f731d508":"markdown","64a02330":"markdown","60053f63":"markdown","b7986a8b":"markdown","ffe8eada":"markdown","62e5c827":"markdown"},"source":{"265034ce":"# install prophet\n!pip install pystan==2.19.1.1\n!pip install prophet","72cbfc69":"# import libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nprint(\"plotly version: {}\". format(plotly.__version__))\n\nfrom prophet import Prophet\n#print('Prophet Version: %s' % prophet.__version__)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","f193a116":"# read input files\ndf_train = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv\")","5aa0f338":"# store target columns\ny_cm = df_train[\"target_carbon_monoxide\"]\ny_b = df_train[\"target_benzene\"]\ny_no = df_train[\"target_nitrogen_oxides\"]\ntarget_cols = [\"target_carbon_monoxide\",\"target_benzene\",\"target_nitrogen_oxides\"]\n# store known target values\nknown_target = df_train.iloc[7110][target_cols]","1be32418":"df_train['date_time'] = pd.to_datetime(df_train['date_time'])\ndf_train.head()","2f0ba9c0":"# get the training data in the format needed by Prophet\ndf = df_train[['date_time','target_carbon_monoxide']].copy()\ndf.columns = [\"ds\",\"y\"] # Prophet requires special column names\ndisplay(df.head())\n\nparam_grid = { # only used to note down my hyperparameter tuning experiments\n    'changepoint_prior_scale' : [0.001], # a higher value here makes the predictions follow the yearly trend more closely\n    'seasonality_prior_scale' : [0.01 , 10], # with visual inspection I could not see the effect of this parameter, so let's keep the default (10)\n    'changepoint_range' : [0.7, 0.8, 0.9] # setting it to 0.9 will make predictions go down at the end, keep default 0.8\n}\n\n# fit model\nmodel = Prophet(changepoint_prior_scale = 0.1 )\nmodel.fit(df)","bf0fe3d7":"# prepare test set, Prophet requires a dataframe with one column named \"ds\" containing timestamps\n# by default, make_future_dataframe includes historic dates as well to be able to see the fit\ntimerange = model.make_future_dataframe(periods=2246, freq='H')","36988bfc":"# make predictions for training data + test data to assess how good Prophet got the trends\npredictions = model.predict(timerange)\n# if there are negative predictions, set them to 0\npredictions.yhat = np.clip(predictions.yhat,0,None)\n# calculate training rmsle, use yhat\ntrain_pred = predictions.iloc[:df_train.shape[0]]\ntrain_rmsle = (((np.log(train_pred.yhat + 1) - np.log(df.y + 1))**2).sum() \/ train_pred.shape[0] )**0.5\nprint(\"Training rmsle: \", train_rmsle)\n# store predictions for test set\ntest_pred_y_cm = predictions.iloc[df_train.shape[0]-1:]","149b92aa":"predictions.head(2)\n# the prediction from Prophet gives a lot of values, including confidence intervals for the predictions \n# the actual prediction (yhat) is at the end","838c9e87":"# plot\nfig = go.Figure()\n\nfig.add_trace(\n      go.Scatter(x=timerange.ds, \n                 y=y_cm, \n                 mode = 'lines', \n                 line = {'color':'darkgoldenrod', 'width' : 1},\n                 #opacity=0.1,\n                 name=\"Carbon Monoxide Ground Truth\")\n)\nfig.add_trace(\n      go.Scatter(x=timerange.ds, \n                 y=predictions.yhat, \n                 mode = 'lines', \n                 line = {'color':'black', 'width' : 1},\n                 #opacity=0.1,\n                 name=\"Carbon Monoxide Predicted\")\n)\n\nfig.update_layout(\n    title=\"Carbon Monoxide Predicted vs Ground Truth (train data)\"\n)\nfig.show()","75481cab":"# get the training data in the format needed by Prophet\ndf = df_train[['date_time','target_benzene']].copy()\ndf.columns = [\"ds\",\"y\"]\n#df.head()\n\nparam_grid = { # only to note down my hyperparameter tuning experiments\n    'changepoint_prior_scale' : [0.001, 1], # 1 makes test predictions go down steadily\n    'seasonality_prior_scale' : [0.01 , 10], # with visual inspection I could not see the effect of this parameter, so let's keep the default (10)\n    'changepoint_range' : [0.7, 0.8, 0.9] # setting it to 0.9 will make predictions go down at the end, keep default 0.8\n}\n\n# fit model\nmodel = Prophet(changepoint_prior_scale = 0.001, changepoint_range = 0.9 )\nmodel.fit(df)\n\n# make predictions for training data + test data to assess how good Prophet got the trends\npredictions = model.predict(timerange)\n# if there are negative predictions, set them to 0\npredictions.yhat = np.clip(predictions.yhat,0,None)\n# calculate training rmsle, use yhat\ntrain_pred = predictions.iloc[:df_train.shape[0]]\ntrain_rmsle = (((np.log(train_pred.yhat + 1) - np.log(df.y + 1))**2).sum() \/ train_pred.shape[0] )**0.5\nprint(\"Training rmsle: \", train_rmsle)\n# store predictions for test set\ntest_pred_y_b = predictions.iloc[df_train.shape[0]-1:]","2c31e81d":"# plot\nfig = go.Figure()\n\nfig.add_trace(\n      go.Scatter(x=timerange.ds, \n                 y=y_b, \n                 mode = 'lines', \n                 line = {'color':'darkgoldenrod', 'width' : 1},\n                 #opacity=0.1,\n                 name=\"Benzene Ground Truth\")\n)\nfig.add_trace(\n      go.Scatter(x=timerange.ds, \n                 y=predictions.yhat, \n                 mode = 'lines', \n                 line = {'color':'black', 'width' : 1},\n                 #opacity=0.1,\n                 name=\"Benzene Predicted\")\n)\n\nfig.update_layout(\n    title=\"Benzene Predicted vs Ground Truth (train data)\"\n)\nfig.show()","87816fdf":"# get the training data in the format needed by Prophet\ndf = df_train[['date_time','target_nitrogen_oxides']].copy()\ndf.columns = [\"ds\",\"y\"]\n#df.head()\n\nparam_grid = { # only to note down my hyperparameter tuning experiments\n    'changepoint_prior_scale' : [0.01, 1, 10], # 0.01 makes test predictions go up steadily, 1\/10 make them go down slightly\n    'seasonality_prior_scale' : [0.01 , 10], # with visual inspection I could not see the effect of this parameter, so let's keep the default (10)\n    'changepoint_range' : [0.7, 0.8, 0.9] # setting it to 0.9 will make predictions go down at the end, keep default 0.8\n}\n\n# fit model\nmodel = Prophet(changepoint_prior_scale = 1)\nmodel.fit(df)\n\n# make predictions for training data + test data to assess how good Prophet got the trends\npredictions = model.predict(timerange)\n# if there are negative predictions, set them to 0\npredictions.yhat = np.clip(predictions.yhat,0,None)\n# calculate training rmsle, use yhat\ntrain_pred = predictions.iloc[:df_train.shape[0]]\ntrain_rmsle = (((np.log(train_pred.yhat + 1) - np.log(df.y + 1))**2).sum() \/ train_pred.shape[0] )**0.5\nprint(\"Training rmsle: \", train_rmsle)\n# store predictions for test set\ntest_pred_y_no = predictions.iloc[df_train.shape[0]-1:]","bd9b6104":"# plot\nfig = go.Figure()\n\nfig.add_trace(\n      go.Scatter(x=timerange.ds, \n                 y=y_no, \n                 mode = 'lines', \n                 line = {'color':'darkgoldenrod', 'width' : 1},\n                 #opacity=0.1,\n                 name=\"Nitrogen Oxides Ground Truth\")\n)\nfig.add_trace(\n      go.Scatter(x=timerange.ds, \n                 y=predictions.yhat, \n                 mode = 'lines', \n                 line = {'color':'black', 'width' : 1},\n                 #opacity=0.1,\n                 name=\"Nitrogen Oxides Predicted\")\n)\n\nfig.update_layout(\n    title=\"Nitrogen Oxides Predicted vs Ground Truth (train data)\"\n)\nfig.show()","d5c70c92":"# prophet build in plotting, shows the confidence intervals, but overall gives me less insight than the plotly graphic\nfig = model.plot(predictions)","079e1ade":"# prophet build in plotting, shows compontents of the prediction\nfig = model.plot_components(predictions)","8d5a67a5":"# generate submission file \nsubmission_prophet = pd.DataFrame(data={\"date_time\" : sample_submission.date_time,\n                               \"target_carbon_monoxide\" : test_pred_y_cm.yhat.values,\n                               \"target_benzene\" : test_pred_y_b.yhat.values,\n                               \"target_nitrogen_oxides\" : test_pred_y_no.yhat.values})\nsubmission_prophet.loc[0,target_cols] = known_target # replace the first row with the known values as timestamp is identical\nsubmission_prophet.to_csv('submission_prophet.csv', index=False)\nsubmission_prophet.head()","16d12707":"## Nitrogen Oxides: Train, predict and assess performance","f731d508":"# Submission\n","64a02330":"It can be seen how Prophet detects seasonal components in the training data and builds it's predictions based on them. Don't forget to zoom in!","60053f63":"## Target Benzene: Train, predict and assess performance","b7986a8b":"### Examining Prophet's build in plotting possibilities\n\nI use Nitrogen Oxides here as an example. It can be seen how the confidence of the model in it's predictions decreases with a rising time horizon. In other words, the farther a prediction is away from the training data, the more unsure the model is.","ffe8eada":"## Target Carbon Monoxide: Train, predict and assess performance","62e5c827":"# Tabular Playground Series 7 - Predict Air Pollution\n\nThe dataset deals with predicting air pollution in a city via various input sensor values. The task is to predict, based on the sensor, values **three** target variables: target_carbon_monoxide,target_benzene and target_nitrogen_oxides. Submissions are evaluated using the [mean column-wise root mean squared logarithmic error](http:\/\/www.kaggle.com\/c\/tabular-playground-series-jul-2021\/overview\/evaluation).\n\nIn this notebook I experimented with a pure time series algorithm: **Prophet**, developed by Facebook. [Prophed is described as](http:\/\/facebook.github.io\/prophet\/):\n<div class=\"alert alert-success\">\nProphet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.\n<\/div>\n\nI use Prophet to predict the three target variables seperately and assess the performance on the training data. Using visual checks it can be seen how Prophet works and that **it is not able to learn the training data as well as XGBoost** that I used in [my other notebook](https:\/\/www.kaggle.com\/melanie7744\/tps7-tuned-xgb-graphic-validation\/notebook?scriptVersionId=69040682&select=submission_xgb_minfactor.csv).\nThis is not very surprising given the fact that Prophet only uses the timestamp and the target variable for it's predictions whereas XGBoost can make use of all features.\n\n\nFeedback is highly appreciated!\n\n\n### Note: I decided not to use the leak!\n"}}