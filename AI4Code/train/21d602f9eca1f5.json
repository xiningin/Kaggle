{"cell_type":{"cf422f75":"code","374f1e4d":"code","7f3cd476":"code","b62fe288":"code","c393e402":"code","702a27e9":"code","b157fd3f":"code","7dbe6163":"code","5e618a87":"code","e493dd11":"code","593ffa95":"code","bb5c4a85":"code","ae7d9bd0":"code","4c405e68":"code","832c2557":"code","9344a870":"code","c0fa2e81":"code","dbfe00ab":"code","5d3a3be8":"code","42203211":"code","de89619e":"code","a2b134ff":"code","943800d7":"code","e3a386c9":"code","7a2ca365":"code","5f7ce82d":"code","1d8f63bf":"code","deb54b96":"code","a31bcb06":"code","f050110f":"markdown","ed27c7b7":"markdown","505255a0":"markdown","3bad3ed2":"markdown","f4e60820":"markdown","1fc540b6":"markdown","cc704bef":"markdown","20d89f4b":"markdown","f6d58d90":"markdown","b81d81e6":"markdown","fd6d3bdc":"markdown","4eab9b4c":"markdown","a595808e":"markdown","3c57d154":"markdown","6f3c1fb9":"markdown","25de5abd":"markdown"},"source":{"cf422f75":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","374f1e4d":"# Read the train.csv file (training \/ validation data) and test.csv (testing \/ prediction data)\nX = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\nX_test = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')","7f3cd476":"# Check up nulls (training set)\nX.isnull().sum()[X.isnull().any()]","b62fe288":"# Check up nulls (testing set)\nX_test.isnull().sum()[X_test.isnull().any()]","c393e402":"cols_to_drop = ['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu']\nX.drop(cols_to_drop, axis=1, inplace=True)\nX_test.drop(cols_to_drop, axis=1, inplace=True)","702a27e9":"# Separate target variable from predicting variables\ny = X.SalePrice\nX.drop(['SalePrice'], axis=1, inplace=True)","b157fd3f":"# Display stats for categorical columns: training set\nX.describe(include=['object'], exclude=['int64', 'float64'])","7dbe6163":"# Display stats for categorical columns: testing set\nX_test.describe(include=['object'], exclude=['int64', 'float64'])","5e618a87":"# Object-type columns with null values: training set\nX_obj_cols_with_nulls = [[col, X[col].isnull().sum()] for col in X.columns if X[col].dtype == \"object\" and X[col].isnull().sum()>0]\nprint(len(X_obj_cols_with_nulls))\nX_obj_cols_with_nulls","e493dd11":"# Object-type columns with null values: testing set\nX_test_obj_cols_with_nulls = [[col, X_test[col].isnull().sum()] for col in X_test.columns if X_test[col].dtype == \"object\" and X_test[col].isnull().sum()>0]\nprint(len(X_test_obj_cols_with_nulls))\nX_test_obj_cols_with_nulls","593ffa95":"X_cols_with_nulls = [col for col in X.columns if X[col].dtype == \"object\" and X[col].isnull().sum()>0]\nfor col in X_cols_with_nulls:\n    X[col].fillna(value='Unknown', inplace=True)","bb5c4a85":"X_test_cols_with_nulls = [col for col in X_test.columns if X_test[col].dtype == \"object\" and X_test[col].isnull().sum()>0]\nfor col in X_test_cols_with_nulls:\n    X_test[col].fillna(value='Unknown', inplace=True)","ae7d9bd0":"from sklearn.preprocessing import LabelEncoder\nobject_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n# Apply label encoder to categorical columns\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    val1 = X[col].unique()\n    val2 = X_test[col].unique()\n    values = list(set().union(val1, val2))\n    label_encoder.fit(values)\n    X[col] = label_encoder.transform(X[col])\n    X_test[col] = label_encoder.transform(X_test[col])  ","4c405e68":"# Number of missing values in each column of training data\nmissing_val_count_by_column_1 = (X.isnull().sum())\nprint(missing_val_count_by_column_1[missing_val_count_by_column_1 > 0])","832c2557":"# Number of missing values in each column of test data\nmissing_val_count_by_column_2 = (X_test.isnull().sum())\nprint(missing_val_count_by_column_2[missing_val_count_by_column_2 > 0])","9344a870":"# Numerical columns missing in training set\nnum_cols_with_nulls = ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n\nX[num_cols_with_nulls].describe()","c0fa2e81":"# Fill nulls independently\nX['LotFrontage'].fillna(value=X['LotFrontage'].quantile(0.75), inplace=True)\nX_test['LotFrontage'].fillna(value=X_test['LotFrontage'].quantile(0.75), inplace=True)\nX['MasVnrArea'].fillna(value=X['MasVnrArea'].mean(), inplace=True)\nX_test['MasVnrArea'].fillna(value=X_test['MasVnrArea'].mean(), inplace=True)\nX['GarageYrBlt'].fillna(value=X['YearBuilt'], inplace=True)\nX_test['GarageYrBlt'].fillna(value=X_test['YearBuilt'], inplace=True)","dbfe00ab":"# Numerical columns missing in testing set\ncols_with_missing_2 = [col for col in X_test.columns if X_test[col].isnull().any()]\n\nX_test[cols_with_missing_2].describe()","5d3a3be8":"# Fill nulls with column mean\nfor col in cols_with_missing_2:\n    X_test[col].fillna(value=X_test[col].mean(), inplace=True)","42203211":"from sklearn.model_selection import train_test_split\n\n# Split data into train and validation sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","de89619e":"%%time\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Define and fit model\nmodel_1 = RandomForestRegressor(n_estimators=4000, random_state=0, n_jobs=4)\nmodel_1.fit(X_train, y_train)\n\n# Get validation predictions and MAE\npreds_valid_1 = model_1.predict(X_valid)\nprint(\"MAE_1 (Random Forest Regressor): \" + str(mean_absolute_error(y_valid, preds_valid_1)))","a2b134ff":"# Define and fit model with full train data\n# X_train = X.copy()\n# y_train = y.copy()\n# model_1 = RandomForestRegressor(n_estimators=500, random_state=0)\n# model_1.fit(X_train, y_train)\n\n# # Make test predictions\n# preds_test_1 = model_1.predict(X_test)","943800d7":"%%time\nfrom xgboost import XGBRegressor\n\n# Define and fit the model\nmodel_2 = XGBRegressor(n_estimators=4000, learning_rate=0.015, n_jobs=4)\nmodel_2.fit(X_train, y_train)\n\n# Get validation predictions and MAE\npreds_valid_2 = model_2.predict(X_valid)\nprint(\"MAE_2 (XG Boost Regressor): \" + str(mean_absolute_error(y_valid, preds_valid_2)))","e3a386c9":"# # Define and fit model with full train data\n# X_train = X.copy()\n# y_train = y.copy()\n# model_2 = XGBRegressor(n_estimators=5000, learning_rate=0.025)\n# model_2.fit(X_train, y_train)\n\n# # Make test predictions\n# preds_test_2 = model_2.predict(X_test)","7a2ca365":"%%time\nfrom sklearn.ensemble import AdaBoostRegressor\n\n# Define and fit the model\nmodel_3 = AdaBoostRegressor(n_estimators=3000, learning_rate=0.01)\nmodel_3.fit(X_train, y_train)\n\n# Get validation predictions and MAE\npreds_valid_3 = model_3.predict(X_valid)\nprint(\"MAE_3 (AdaBoost Regressor): \" + str(mean_absolute_error(y_valid, preds_valid_3)))","5f7ce82d":"# %%time\n# Define and fit model with full train data\n# X_train = X.copy()\n# y_train = y.copy()\n# model_3 = AdaBoostRegressor(n_estimators=5000, learning_rate=0.02)\n# model_3.fit(X_train, y_train)\n\n# # Make test predictions\n# preds_test_3 = model_3.predict(X_test)","1d8f63bf":"%%time\nfrom catboost import CatBoostRegressor\n\n# Define and fit the model\nmodel_4 = CatBoostRegressor(n_estimators=2602, learning_rate=0.022, verbose=0)\nmodel_4.fit(X_train, y_train)\n\n# Get validation predictions and MAE\npreds_valid_4 = model_4.predict(X_valid)\nprint(\"MAE_4 (CatBoost Regressor): \" + str(mean_absolute_error(y_valid, preds_valid_4)))","deb54b96":"# %%time\n# # Define and fit model with full train data\n# X_train = X.copy()\n# y_train = y.copy()\n# model_4 = CatBoostRegressor(n_estimators=2602, learning_rate=0.022, verbose=0)\n# model_4.fit(X_train, y_train)\n\n# # Make test predictions\n# preds_test_4 = model_4.predict(X_test)","a31bcb06":"# # Save test predictions to file\n# output = pd.DataFrame({'Id': X_test.index,\n#                        'SalePrice': preds_test_4})\n# output.to_csv('submission.csv', index=False)","f050110f":"Now that there are no nulls in the categorical features, I can proceed to label-encode them, so they become numerical features that will allow me to put them through the regression algorithms.","ed27c7b7":"## Investigate numerical columns","505255a0":"## Predictive model 1: Random Forest Regressor","3bad3ed2":"Now and after a few hours of trial - error I have chosen what appears to be the optimum way to handle nulls in the numerical columns.\n\nBelow is the process.","f4e60820":"Given the fact that they hold relativel small number of nulls, I will just set them to 'Unknown'.","1fc540b6":"This notebook compares the performance of four regression algorithms on the House Prices Competition:\n- Random Forest Regressor\n- Extreme Gradient Boost (XGBoost) Regressor\n- Adaptive Boost (AdaBoost) Regressor\n- Category Boost (CatBoost) Regressor\n\nI have achieved a top 2% score with the predictions from the CatBoost algorithm. ","cc704bef":"Best predictor is #4 the CatBoost Regressor, both in terms of accuracy and speed.","20d89f4b":"Features with high number of missing values can be removed as they provide little information (I will drop columns Alley, FireplaceQu, PoolQc, Fence and MiscFeature).","f6d58d90":"## Predictive model 3: AdaBoost Regressor","b81d81e6":"## Predictive model 2: XG Boost Regressor","fd6d3bdc":"## Data loading and pre-process","4eab9b4c":"## Save predictions to file for submission","a595808e":"## Split training data into train and validation sets","3c57d154":"I have to get rid of the nulls in the categorical variables before I can encode them , so let's have a closer look and see what the best way of doing so might be.","6f3c1fb9":"## Investigate categorical columns and label encode them","25de5abd":"## Predictive model 4: CatBoost Regressor"}}