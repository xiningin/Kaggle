{"cell_type":{"9cdfd5e7":"code","1ac548e7":"code","01d3f552":"code","2bcd0d1c":"code","612e99fc":"code","3940f997":"code","09b80946":"code","b2fd757e":"code","acf6bbfa":"code","d71d50ac":"code","b16dfd4f":"code","e8ed27df":"code","a1ae5709":"code","6e4e9fc2":"code","d29102c5":"code","1bae5078":"markdown"},"source":{"9cdfd5e7":"! pip install -q git+https:\/\/github.com\/tensorflow\/examples.git","1ac548e7":"# Imports and TPU configs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport PIL\nimport shutil\n\nimport tensorflow as tf\nimport tensorflow.keras\nimport tensorflow_addons as tfa\nfrom tensorflow_examples.models.pix2pix import pix2pix\n\nfrom kaggle_datasets import KaggleDatasets\nfrom IPython.display import clear_output\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f\"Device: {tpu.master()}\")\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint(f\"Number of replicas: {strategy.num_replicas_in_sync}\")\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nprint(tf.__version__)","01d3f552":"# Get Google Cloud Storage path and data\nGCS_PATH = KaggleDatasets().get_gcs_path()\n\nMONET_FL = tf.io.gfile.glob(str(GCS_PATH+'\/monet_tfrec\/*.tfrec'))\nprint(f\"Monet TFRecord Files: {len(MONET_FL)}\")\n\nPHOTO_FL = tf.io.gfile.glob(str(GCS_PATH+'\/photo_tfrec\/*.tfrec'))\nprint(f\"Photo TFRecord Files: {len(PHOTO_FL)}\")","2bcd0d1c":"IMAGE_SIZE = [256, 256]\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) \/ 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image","612e99fc":"def load_dataset(filenames, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    return dataset","3940f997":"monet_ds = load_dataset(MONET_FL, labeled=True).batch(1)\nphoto_ds = load_dataset(PHOTO_FL, labeled=True).batch(1)","09b80946":"ex_monet = next(iter(monet_ds))\nex_photo = next(iter(photo_ds))\n\nplt.subplot(121)\nplt.title(\"Monet Image\")\nplt.imshow(ex_monet[0] * 0.5 + 0.5)\n\nplt.subplot(122)\nplt.title(\"Normal Image\")\nplt.imshow(ex_photo[0] * 0.5 + 0.5)","b2fd757e":"# Define the generator and discriminator based on pix2pix generator\ngen_g = pix2pix.unet_generator(3, norm_type='instancenorm')\ngen_f = pix2pix.unet_generator(3, norm_type='instancenorm')\n\ndis_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\ndis_y = pix2pix.discriminator(norm_type='instancenorm', target=False)","acf6bbfa":"# Loss functions\nLAMBDA = 10\nloss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef dis_loss(real, generated):\n    real_loss = loss_fn(tf.ones_like(real), real)\n    generated_loss = loss_fn(tf.zeros_like(generated), generated)\n    \n    disc_loss = real_loss + generated_loss\n    \n    return disc_loss * 0.5\n\ndef gen_loss(generated):\n    return loss_fn(tf.ones_like(generated), generated)\n\ndef cycle_loss(real_image, cycled_image):\n    loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n    return loss * LAMBDA\n\ndef identity_loss(real_image, same_image):\n    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n    return 0.5 * LAMBDA * loss","d71d50ac":"generator_g_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ngenerator_f_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\ndiscriminator_x_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ndiscriminator_y_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","b16dfd4f":"checkpoint_path = \"\/kaggle\/working\/checkpoints\/train\"\n\nckpt = tf.train.Checkpoint(generator_g=gen_g,\n                           generator_f=gen_f,\n                           discriminator_x=dis_x,\n                           discriminator_y=dis_y,\n                           generator_g_optimizer=generator_g_opt,\n                           generator_f_optimizer=generator_f_opt,\n                           discriminator_x_optimizer=discriminator_x_opt,\n                           discriminator_y_optimizer=discriminator_y_opt)\n\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n\nif ckpt_manager.latest_checkpoint:\n  ckpt.restore(ckpt_manager.latest_checkpoint)\n  print ('Latest checkpoint restored!!')","e8ed27df":"def generate_image(model, noise):\n    prediction = model(noise)\n    plt.figure(figsize=(12, 12))\n    display_list = [noise[0], prediction[0]]\n    title=['Input Noise', 'Generated Image']\n    \n    for i in range(2):\n        plt.subplot(1, 2, i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i] * 0.5 + 0.5)\n        plt.axis('off')\n    plt.show()","a1ae5709":"@tf.function\ndef fit_one_epoch(real_x, real_y):\n    with tf.GradientTape(persistent=True) as tape:\n        fake_y = gen_g(real_x, training=True)\n        cycled_x = gen_f(fake_y, training=True)\n        \n        fake_x = gen_g(real_y, training=True)\n        cycled_y = gen_f(fake_x, training=True)\n        \n        same_x = gen_f(real_x, training=True)\n        same_y = gen_g(real_y, training=True)\n        \n        dis_real_x = dis_x(real_x, training=True)\n        dis_real_y = dis_y(real_y, training=True)\n        \n        dis_fake_x = dis_x(fake_x, training=True)\n        dis_fake_y = dis_y(fake_y, training=True)\n        \n        # Calculate Loss\n        gen_g_loss = gen_loss(dis_fake_y)\n        gen_f_loss = gen_loss(dis_fake_x)\n        \n        cy_loss = cycle_loss(real_x, cycled_x) + cycle_loss(real_y, cycled_y)\n        \n        total_gen_g_loss = gen_g_loss + cy_loss + identity_loss(real_x, same_y)\n        total_gen_f_loss = gen_f_loss + cy_loss + identity_loss(real_x, same_x)\n        \n        disc_x_loss = dis_loss(dis_real_x, dis_fake_y)\n        disc_y_loss = dis_loss(dis_real_y, dis_fake_y)\n        \n    # Gradient stuff\n    gen_g_grads = tape.gradient(total_gen_g_loss, gen_g.trainable_variables)\n    gen_f_grads = tape.gradient(total_gen_f_loss, gen_f.trainable_variables)\n\n    dis_x_grads = tape.gradient(disc_x_loss, dis_x.trainable_variables)\n    dis_y_grads = tape.gradient(disc_y_loss, dis_y.trainable_variables)\n\n    # Apply gradients to optimizer\n    generator_g_opt.apply_gradients(zip(gen_g_grads, gen_g.trainable_variables))\n    generator_f_opt.apply_gradients(zip(gen_f_grads, gen_f.trainable_variables))\n\n    discriminator_x_opt.apply_gradients(zip(dis_x_grads, dis_x.trainable_variables))\n    discriminator_y_opt.apply_gradients(zip(dis_y_grads, dis_y.trainable_variables))","6e4e9fc2":"# Training loop\nnb_epochs = 80\n\nfor epoch in range(nb_epochs):\n    n = 0\n    for image_x, image_y in tf.data.Dataset.zip((monet_ds, photo_ds)):\n        fit_one_epoch(image_x, image_y)\n        if n % 10 == 0:\n            print('.', end=' ')\n        n += 1\n    clear_output(wait=True)\n    generate_image(gen_g, ex_monet)","d29102c5":"! mkdir \"\/kaggle\/working\/images\"\n\ni = 1\nfor img in photo_ds:\n    prediction = gen_g(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    im = PIL.Image.fromarray(prediction)\n    im.save(\"\/kaggle\/working\/images\" + str(i) + \".jpg\")\n    i += 1\nshutil.make_archive(\"\/kaggle\/working\/images\", 'zip', \"\/kaggle\/images\")","1bae5078":"Training function and procedure"}}