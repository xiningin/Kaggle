{"cell_type":{"77974256":"code","c8256dbc":"code","a7571dd9":"code","575bb39e":"code","f2b4741d":"code","7870aa3c":"code","721568d9":"code","6c7ecd20":"code","daa68ecb":"code","64e5809e":"code","f8591c94":"code","b9a0b23b":"code","f3902249":"code","9c69ea17":"code","9a0710b0":"code","99d15d11":"code","5208c07a":"code","713d5db6":"code","fbb0452e":"code","03e467d9":"code","3cf2fa18":"code","0bedc341":"code","ead4ce96":"code","a34c6f17":"code","9d79609c":"code","559dad8a":"code","eb8de856":"code","ffbb5f93":"markdown","173115ed":"markdown","74cf1bc1":"markdown","8e82967a":"markdown","5a790051":"markdown","bb4b133f":"markdown","a4da0543":"markdown","0597e8f6":"markdown"},"source":{"77974256":"import pandas as pd\nimport numpy as np\nimport missingno as msno\nimport seaborn as sns\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error as mse\nfrom scipy.stats import randint as sp_randint","c8256dbc":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","a7571dd9":"for df in [train, test]:\n    \n    # \uc804\uccb4\ubd80\uc9c0 - \uc8fc\uac70\uacf5\uac04\n    df['without_living'] = df['sqft_lot'] - df['sqft_living']\n    \n    # \uc8fc\uac70\uacf5\uac04 \/ \uc804\uccb4\ubd80\uc9c0\n    df['living_lot_ratio'] = df['sqft_living'] \/ df['sqft_lot']\n    \n    # \uc8fc\uac70\uacf5\uac04 \/ \uce35\uc218\n    df['living_per_floor'] = df['sqft_living'] \/ df['floors']\n    \n    # (\uc8fc\uac70\uacf5\uac04 \/ \uce35\uc218)\uc758 \uacf5\uac04 \ube44\uc728\n    df['living_ratio'] = df['living_per_floor'] \/ df['sqft_lot']\n    \n    # \uc9c0\ud558\uacf5\uac04 \uc720\ubb34\n    df['has_basement'] = np.where(df['sqft_basement'] > 0, 1, 0)\n    \n    # zipcode \ubcc4 sqft\ub2f9 \ud3c9\uade0\uac00\uaca9\n    df['price_per_sqft-ZIP'] = df['zipcode'].replace(train.groupby('zipcode').mean().price.to_dict())\n    \n    # \ud654\uc7a5\uc2e4 \/ \uce68\uc2e4\n    df['bath_per_bed'] = df['bathrooms'] \/ (df['bedrooms'] + 0.01)\n    \n    # is_renovated\n    df['is_renovated'] = np.where(df['yr_renovated'] > 0, 1, 0)\n    \n    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n    \n    qcut_count = 10\n    df['qcut_long'] = pd.qcut(df['long'], qcut_count, labels=range(qcut_count))\n    df['qcut_lat'] = pd.qcut(df['lat'], qcut_count, labels=range(qcut_count))\n    df['qcut_long'] = df['qcut_long'].astype(int)\n    df['qcut_lat'] = df['qcut_lat'].astype(int)\n    \n    df['grade_condition'] = df['grade'] * df['condition']\n    df['sqft_total'] = df['sqft_living'] + df['sqft_lot']\n    df['sqft_total_size'] = df['sqft_living'] + df['sqft_lot'] + df['sqft_above'] + df['sqft_basement']","575bb39e":"for df in [train, test]:\n    \n    df['year'] = df['date'].str[:4].astype(int)\n    \n    df['month'] = df['date'].str[4:6].astype(int)\n    \n    df.drop(['date'], axis=1, inplace=True)\n    \n    df['yr_latest'] = df[['yr_built','yr_renovated']].apply(lambda x: x.max(), axis=1)\n    \n    df['yr_renovated'] = df['yr_renovated'].apply(lambda x: sp.nan if x == 0 else x)\n    df['yr_renovated'] = df['yr_renovated'].fillna(df['yr_built'])\n    \n    del df['yr_built']\n    del df['yr_renovated']\n","f2b4741d":"train = train[train['living_ratio'] > 0.01]\ntrain = train.loc[train['bedrooms']<10]","7870aa3c":"train['price'] = np.log1p(train['price'].values)","721568d9":"skew_columns = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n\nfor c in skew_columns:\n    train[c] = np.log1p(train[c].values)\n    test[c] = np.log1p(test[c].values)","6c7ecd20":"train.fillna(0, inplace=True)","daa68ecb":"from sklearn.ensemble import RandomForestRegressor\n\ntest_id = test['id']\nY_test = test.drop(['id'], axis = 1, inplace = False)","64e5809e":"y_target = train['price']\nx_data = train.drop(['price', 'id'], axis = 1, inplace = False)\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_target, test_size = 0.2, random_state = 42)","f8591c94":"forest_reg = RandomForestRegressor()","b9a0b23b":"def report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")","f3902249":"param_dist = {\"max_depth\": [7, 11, 15, 18, 21],\n              \"max_features\": sp_randint(1, len(x_train.columns)),\n              \"min_samples_split\": sp_randint(2, 21),\n              \"min_samples_leaf\": sp_randint(1, 21),\n              \"bootstrap\": [True, False],\n              \"random_state\": [42]\n             }\n\nn_iter_search = 20\nrandom_search = RandomizedSearchCV(forest_reg, param_distributions=param_dist,\n                                   n_iter=n_iter_search)","9c69ea17":"random_search.fit(x_train, y_train)","9a0710b0":"report(random_search.cv_results_)","99d15d11":"pred = sp.special.expm1(random_search.predict(x_test))\ny_test = sp.expm1(y_test)\nrf_score = (mse(y_test, pred)) ** float(0.5)\nprint('RMSE : {0:.3F}'.format(rf_score))","5208c07a":"rf_pred = sp.special.expm1(random_search.predict(Y_test))","713d5db6":"import lightgbm as lgb","fbb0452e":"y_target = train['price']\nX_data = train.drop(['price', 'id'], axis = 1, inplace = False)\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size = 0.2, random_state = 42)\n\nmodel_lgb=lgb.LGBMRegressor(\n                           learning_rate=0.001,\n                           n_estimators=100000,\n                           subsample=0.6,\n                           colsample_bytree=0.6,\n                           reg_alpha=0.2,\n                           reg_lambda=10,\n                           num_leaves=35,\n                           silent=True,\n                           min_child_samples=10,\n                            \n                           )\n\nmodel_lgb.fit(X_train,y_train,eval_set=(X_test,y_test),verbose=0,early_stopping_rounds=1000,\n              eval_metric='rmse')\n\nlgbm_score=mse(sp.special.expm1(model_lgb.predict(X_test)),sp.special.expm1(y_test))**0.5\nlgbm_pred = sp.special.expm1(model_lgb.predict(Y_test))\nprint(\"RMSE unseen : {}\".format(lgbm_score))","03e467d9":"fig, ax = plt.subplots(figsize=(10,10))\nlgb.plot_importance(model_lgb, ax=ax)\nplt.show()","3cf2fa18":"import xgboost as xgb\n\ntest_id = test['id']\nY_test = test.drop(['id'], axis = 1, inplace = False)\ny_target = train['price']\nX_data = train.drop(['price', 'id'], axis = 1, inplace = False)\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size = 0.2, random_state = 42)\nwatchlist=[(X_train,y_train),(X_test,y_test)]","0bedc341":"Y_test = Y_test[X_test.columns]","ead4ce96":"model_xgb= xgb.XGBRegressor(tree_method='gpu_hist',\n                        n_estimators=100000,\n                        num_round_boost=500,\n                        show_stdv=False,\n                        feature_selector='greedy',\n                        verbosity=0,\n                        reg_lambda=10,\n                        reg_alpha=0.01,\n                        learning_rate=0.001,\n                        seed=42,\n                        colsample_bytree=0.8,\n                        colsample_bylevel=0.8,\n                        subsample=0.8,\n                        n_jobs=-1,\n                        gamma=0.005,\n                        base_score=np.mean(y_target)\n                        )","a34c6f17":"model_xgb.fit(X_train,y_train, verbose=False, eval_set=watchlist,\n              eval_metric='rmse',\n              early_stopping_rounds=1000)","9d79609c":"xgb_score=mse(np.exp(model_xgb.predict(X_test)),np.exp(y_test))**0.5\nxgb_pred=np.exp(model_xgb.predict(Y_test))\n\nprint(\"RMSE unseen : {}\".format(xgb_score))","559dad8a":"fig, ax = plt.subplots(figsize=(10,10))\nxgb.plot_importance(model_xgb, ax=ax)\nplt.show()","eb8de856":"score=lgbm_score+rf_score+xgb_score\nlgbm_ratio=lgbm_score\/score\nrf_ratio=rf_score\/score\nxgb_ratio=xgb_score\/score\npredict=lgbm_pred*(lgbm_ratio)+rf_pred*(rf_ratio)+xgb_pred*(xgb_ratio)\nprint('rf_ratio={}, lgbm_ratio={}, xgb_ratio={}'.format(rf_ratio,lgbm_ratio, xgb_ratio))\nsubmission=pd.read_csv('..\/input\/sample_submission.csv')\nsubmission.loc[:,'price']=predict\nsubmission.to_csv('submission.csv',index=False)","ffbb5f93":"### LGBM","173115ed":"### \uc804\ucc98\ub9ac","74cf1bc1":"### Ansemble","8e82967a":"### Random Forest","5a790051":"### \uc815\uaddc\ud654\n\ub2e4\uc74c \ub9c1\ud06c\ub97c \ud65c\uc6a9\ud588\uc2b5\ub2c8\ub2e4.  \nhttps:\/\/www.kaggle.com\/kcs93023\/2019-ml-month-2nd-baseline","bb4b133f":"### \ud30c\uc0dd\ubcc0\uc218 \uc0dd\uc131","a4da0543":"\ubaa8\ub378\ub9c1\uc740 \ucc98\uc74c\uc774\ub77c \ub2e4\uc74c \ub9c1\ud06c\ub97c \ud65c\uc6a9\ud588\uc2b5\ub2c8\ub2e4.  \nhttps:\/\/www.kaggle.com\/jsdae1\/house-price-prediction-challenge","0597e8f6":"### XGB"}}