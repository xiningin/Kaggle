{"cell_type":{"d9ee9d3e":"code","f354385b":"code","c780ad47":"code","3eb3a1ac":"code","b168d4ee":"code","b866cbcb":"code","342394dc":"code","4c2470cd":"code","78c63c70":"code","a8c23df3":"code","eea4c7cd":"code","c57105c2":"code","a889d41e":"code","44d58457":"code","ac5cf6d3":"code","89623879":"code","b6540b08":"markdown","2040bfa2":"markdown","db7ecee9":"markdown","3c63d038":"markdown","a8db736e":"markdown","15448335":"markdown","4ba64691":"markdown","ce51f25c":"markdown","233fed28":"markdown"},"source":{"d9ee9d3e":"%%capture\n!pip install \/kaggle\/input\/facenet-pytorch-vggface2\/facenet_pytorch-2.2.7-py3-none-any.whl\n!pip install \/kaggle\/input\/dlibpkg\/dlib-19.19.0\n!pip install \/kaggle\/input\/mtcnn-package\/mtcnn-0.1.0-py3-none-any.whl","f354385b":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport torch\nfrom tqdm.notebook import tqdm\nimport time\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'","c780ad47":"sample = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/aagfhgtpmv.mp4'\n\nreader = cv2.VideoCapture(sample)\nimages_1080_1920 = []\nimages_720_1280 = []\nimages_540_960 = []\nfor i in tqdm(range(int(reader.get(cv2.CAP_PROP_FRAME_COUNT)))):\n    _, image = reader.read()\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    images_1080_1920.append(image)\n    images_720_1280.append(cv2.resize(image, (1280, 720)))\n    images_540_960.append(cv2.resize(image, (960, 540)))\nreader.release()\n\nimages_1080_1920 = np.stack(images_1080_1920)\nimages_720_1280 = np.stack(images_720_1280)\nimages_540_960 = np.stack(images_540_960)\n\nprint('Shapes:')\nprint(images_1080_1920.shape)\nprint(images_720_1280.shape)\nprint(images_540_960.shape)","3eb3a1ac":"def plot_faces(images, figsize=(10.8\/2, 19.2\/2)):\n    shape = images[0].shape\n    images = images[np.linspace(0, len(images)-1, 16).astype(int)]\n    im_plot = []\n    for i in range(0, 16, 4):\n        im_plot.append(np.concatenate(images[i:i+4], axis=0))\n    im_plot = np.concatenate(im_plot, axis=1)\n    \n    fig, ax = plt.subplots(1, 1, figsize=figsize)\n    ax.imshow(im_plot)\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n\n    ax.grid(False)\n    fig.tight_layout()\n\ndef timer(detector, detect_fn, images, *args):\n    start = time.time()\n    faces = detect_fn(detector, images, *args)\n    elapsed = time.time() - start\n    print(f', {elapsed:.3f} seconds')\n    return faces, elapsed","b168d4ee":"plot_faces(images_540_960, figsize=(10.8, 19.2))","b866cbcb":"from facenet_pytorch import MTCNN\ndetector = MTCNN(device=device, post_process=False)\n\ndef detect_facenet_pytorch(detector, images, batch_size):\n    faces = []\n    for lb in np.arange(0, len(images), batch_size):\n        imgs = [img for img in images[lb:lb+batch_size]]\n        faces.extend(detector(imgs))\n    return faces\n\ntimes_facenet_pytorch = []    # batched\ntimes_facenet_pytorch_nb = [] # non-batched","342394dc":"print('Detecting faces in 540x960 frames', end='')\n_, elapsed = timer(detector, detect_facenet_pytorch, images_540_960, 60)\ntimes_facenet_pytorch.append(elapsed)\n\nprint('Detecting faces in 720x1280 frames', end='')\n_, elapsed = timer(detector, detect_facenet_pytorch, images_720_1280, 40)\ntimes_facenet_pytorch.append(elapsed)\n\nprint('Detecting faces in 1080x1920 frames', end='')\nfaces, elapsed = timer(detector, detect_facenet_pytorch, images_1080_1920, 20)\ntimes_facenet_pytorch.append(elapsed)\n\nplot_faces(torch.stack(faces).permute(0, 2, 3, 1).int().numpy())","4c2470cd":"print('Detecting faces in 540x960 frames', end='')\n_, elapsed = timer(detector, detect_facenet_pytorch, images_540_960, 1)\ntimes_facenet_pytorch_nb.append(elapsed)\n\nprint('Detecting faces in 720x1280 frames', end='')\n_, elapsed = timer(detector, detect_facenet_pytorch, images_720_1280, 1)\ntimes_facenet_pytorch_nb.append(elapsed)\n\nprint('Detecting faces in 1080x1920 frames', end='')\nfaces, elapsed = timer(detector, detect_facenet_pytorch, images_1080_1920, 1)\ntimes_facenet_pytorch_nb.append(elapsed)","78c63c70":"del detector\ntorch.cuda.empty_cache()","a8c23df3":"from dlib import get_frontal_face_detector\ndetector = get_frontal_face_detector()\n\ndef detect_dlib(detector, images):\n    faces = []\n    for image in images:\n        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        boxes = detector(image_gray)\n        box = boxes[0]\n        face = image[box.top():box.bottom(), box.left():box.right()]\n        faces.append(face)\n    return faces\n\ntimes_dlib = []","eea4c7cd":"print('Detecting faces in 540x960 frames', end='')\n_, elapsed = timer(detector, detect_dlib, images_540_960)\ntimes_dlib.append(elapsed)\n\nprint('Detecting faces in 720x1280 frames', end='')\n_, elapsed = timer(detector, detect_dlib, images_720_1280)\ntimes_dlib.append(elapsed)\n\nprint('Detecting faces in 1080x1920 frames', end='')\nfaces, elapsed = timer(detector, detect_dlib, images_1080_1920)\ntimes_dlib.append(elapsed)\n\nplot_faces(np.stack([cv2.resize(f, (160, 160)) for f in faces]))","c57105c2":"del detector\ntorch.cuda.empty_cache()","a889d41e":"from mtcnn import MTCNN\ndetector = MTCNN()\n\ndef detect_mtcnn(detector, images):\n    faces = []\n    for image in images:\n        boxes = detector.detect_faces(image)\n        box = boxes[0]['box']\n        face = image[box[1]:box[3]+box[1], box[0]:box[2]+box[0]]\n        faces.append(face)\n    return faces\n\ntimes_mtcnn = []","44d58457":"print('Detecting faces in 540x960 frames', end='')\n_, elapsed = timer(detector, detect_mtcnn, images_540_960)\ntimes_mtcnn.append(elapsed)\n\nprint('Detecting faces in 720x1280 frames', end='')\n_, elapsed = timer(detector, detect_mtcnn, images_720_1280)\ntimes_mtcnn.append(elapsed)\n\nprint('Detecting faces in 1080x1920 frames', end='')\nfaces, elapsed = timer(detector, detect_mtcnn, images_1080_1920)\ntimes_mtcnn.append(elapsed)\n\nplot_faces(np.stack([cv2.resize(face, (160, 160)) for face in faces]))","ac5cf6d3":"del detector\ntorch.cuda.empty_cache()","89623879":"fig, ax = plt.subplots(figsize=(10,6))\n\npos = np.arange(3)\nplt.bar(pos, times_facenet_pytorch, 0.2, label='facenet-pytorch')\nplt.bar(pos + 0.2, times_facenet_pytorch_nb, 0.2, label='facenet-pytorch (non-batched)')\nplt.bar(pos + 0.4, times_dlib, 0.2, label='dlib')\nplt.bar(pos + 0.6, times_mtcnn, 0.2, label='mtcnn')\n\nax.set_ylabel('Elapsed time (seconds)')\nax.set_xticks(pos + 0.25)\nax.set_xticklabels(['540x960', '720x1280', '1080x1920'])\nplt.legend();","b6540b08":"## The mtcnn package","2040bfa2":"## Install packages\n\nNormally, each package can be installed with `pip install <package>`, but this notebook is offline to demonstrate their use in this competition.","db7ecee9":"## Performance comparison","3c63d038":"# Comparison of face detection packages","a8db736e":"## The facenet-pytorch package","15448335":"Read in the frames of a video using cv2's `VideoCapture`.","4ba64691":"This notebook demonstrates the use of three face detection packages:\n\n1. facenet-pytorch: https:\/\/pypi.org\/project\/facenet-pytorch\/\n1. mtcnn: https:\/\/pypi.org\/project\/mtcnn\/\n1. dlib: https:\/\/pypi.org\/project\/dlib\/\n\nThanks to Carlos Souza and \"Need to think of a good name\" for creating the datasets used to install the packages offline.\n\nEach package is tested for its speed in detecting the faces in a set of 300 images (all frames from one video), with GPU support enabled. Detection is performed at 3 different resolutions. Any one-off initialization steps, such as model instantiation, are performed prior to performance testing.\n\nPlease let me know if you know of better\/faster ways to use these packages.\n\n*****\n**UPDATE (2020-01-05)**: facenet-pytorch version 2.0.0 has been released, offering some additional performance gains, particularly for batched processing.\n*****\n\n## Summary of results\n\n|Package|FPS (1080x1920)|FPS (720x1280)|FPS (540x960)|\n|-|-|-|\n|***facenet-pytorch***|12.97|20.32|25.50|\n|***facenet-pytorch (non-batched)***|9.75|14.81|19.68|\n|***dlib***|3.80|8.39|14.53|\n|***mtcnn***|3.04|5.70|8.23|\n\n## Other resources\n\nSee the following kernel for a guide to using the MTCNN functionality of facenet-pytorch: https:\/\/www.kaggle.com\/timesler\/guide-to-mtcnn-in-facenet-pytorch","ce51f25c":"## The facenet-pytorch package (non-batched)","233fed28":"## The dlib package"}}