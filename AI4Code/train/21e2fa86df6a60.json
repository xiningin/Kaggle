{"cell_type":{"7cbb2a01":"code","63c28b29":"code","c95fbdc3":"code","3a6c7042":"code","acd0655e":"code","e783559f":"code","550c4110":"code","e5a763b9":"code","eb2e90c7":"code","c8dddfd9":"code","0420e157":"code","f11e91c4":"code","58ddddcc":"code","cf2d0077":"code","104dbce3":"code","01181939":"markdown","3c94ddfe":"markdown","fe80c823":"markdown","b2557918":"markdown","2f7ad43b":"markdown","acc567db":"markdown","cab899dd":"markdown","e1a444ff":"markdown"},"source":{"7cbb2a01":"# -*- coding: utf-8 -*-\n\n# I don't like warnings, especially user warnings at all!\nimport warnings\nwarnings.filterwarnings('ignore')","63c28b29":"# Import some packages that we require\nimport os\nimport glob\nimport umap\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom keras.models import Sequential, Model\nfrom keras.applications import vgg16\nfrom keras.applications import resnet50\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\nfrom keras import backend as K\nimport tensorflow as tf\nfrom collections import defaultdict, Counter\nprint(os.listdir(\"..\/input\"))","c95fbdc3":"# For plotting within the notebook\n%matplotlib inline\n\n# Graphics in SVG format are more sharp and legible\n%config InlineBackend.figure_format = 'svg'\n\n# seaborn color palette \ncolor = sns.color_palette()\n\n# For REPRODUCIBILITY\nseed = 111\nnp.random.seed(seed)\ntf.set_random_seed(seed)","3a6c7042":"# Let us define some paths first\ninput_path = Path(\"..\/input\")\n\n# Path to training images and corresponding labels provided as numpy arrays\nkmnist_train_images_path = input_path\/\"kmnist-train-imgs.npz\"\nkmnist_train_labels_path = input_path\/\"kmnist-train-labels.npz\"\n\n# Path to the test images and corresponding labels\nkmnist_test_images_path = input_path\/\"kmnist-test-imgs.npz\"\nkmnist_test_labels_path = input_path\/\"kmnist-test-labels.npz\"","acd0655e":"# Load the training data from the corresponding npz files\nkmnist_train_images = np.load(kmnist_train_images_path)['arr_0']\nkmnist_train_labels = np.load(kmnist_train_labels_path)['arr_0']\n\n# Load the test data from the corresponding npz files\nkmnist_test_images = np.load(kmnist_test_images_path)['arr_0']\nkmnist_test_labels = np.load(kmnist_test_labels_path)['arr_0']\n\nprint(f\"Number of training samples: {len(kmnist_train_images)} where each sample is of size: {kmnist_train_images.shape[1:]}\")\nprint(f\"Number of test samples: {len(kmnist_test_images)} where each sample is of size: {kmnist_test_images.shape[1:]}\")","e783559f":"# Get the unique labels\nlabels = np.unique(kmnist_train_labels)\n\n# Get the frequency count for each label\nfrequency_count = np.bincount(kmnist_train_labels)\n\n# Visualize \nplt.figure(figsize=(10,5))\nsns.barplot(x=labels, y=frequency_count);\nplt.title(\"Distribution of labels in KMNIST training data\", fontsize=16)\nplt.xlabel(\"Labels\", fontsize=14)\nplt.ylabel(\"Count\", fontsize=14)\nplt.show()","550c4110":"# Let's see how the images for different labels look like\nrandom_samples = []\nfor i in range(10):\n    samples = kmnist_train_images[np.where(kmnist_train_labels==i)][:3]\n    random_samples.append(samples)\n\n# Converting list into a numpy array\nrandom_samples = np.array(random_samples)\n\n# Visualize the samples\nf, ax = plt.subplots(10,3, figsize=(10,20))\nfor i, j in enumerate(random_samples):\n    ax[i, 0].imshow(random_samples[i][0,:,:], cmap='gray')\n    ax[i, 1].imshow(random_samples[i][1,:,:], cmap='gray')\n    ax[i, 2].imshow(random_samples[i][2,:,:], cmap='gray')\n    \n    ax[i,0].set_title(str(i))\n    ax[i,0].axis('off')\n    ax[i,0].set_aspect('equal')\n    \n    ax[i,1].set_title(str(i))\n    ax[i,1].axis('off')\n    ax[i,1].set_aspect('equal')\n    \n    ax[i,2].set_title(str(i))\n    ax[i,2].axis('off')\n    ax[i,2].set_aspect('equal')\nplt.show()","e5a763b9":"# Labels mapping\nlabels_dict = dict([(0, u\"\\u304A\"), (1, u\"\\u304D\"), (2, u\"\\u3059\"), (3, u\"\\u3064\"),\n                    (4, u\"\\u306A\"), (5, u\"\\u306F\"), (6, u\"\\u307E\"), (7, u\"\\u3084\"),\n                    (8, u\"\\u308C\"), (9, u\"\\u3093\")])\n\nprint(labels_dict)","eb2e90c7":"# A handy-dandy function to get randomly sampled data \ndef get_random_samples(nb_indices):\n    # Choose indices randomly \n    random_indices = np.random.choice(nb_indices, size=nb_indices, replace=False)\n\n    # Get the data corresponding to these indices\n    random_train_images = kmnist_train_images[random_indices].astype(np.float32)\n    random_train_images \/=255.\n    random_train_images = random_train_images.reshape(nb_indices, 28*28)\n    random_train_labels = kmnist_train_labels[random_indices]\n    labels = np.unique(random_train_labels)\n    return random_indices, random_train_images, random_train_labels, labels","c8dddfd9":"#Get randomly sampled data\nnb_indices = 5000\nrandom_indices, random_train_images, random_train_labels, labels = get_random_samples(nb_indices)\n\n# Get the actual labels from the labels dictionary\nlabels_name = [labels_dict[x] for x in labels]\n\n# Get a t-SNE instance\ntsne = TSNE(n_components=2, random_state=seed, perplexity=30)\n\n# Fit tsne to the data\nrandom_train_2D = tsne.fit_transform(random_train_images)\n\n\nfig = plt.figure(figsize=(10, 8))\n\nfor i, label in zip(labels, labels_name):\n    sns.scatterplot(random_train_2D[random_train_labels == i, 0], \n                random_train_2D[random_train_labels == i, 1], \n                label=i, s=18)\n\nplt.title(\"Visualizating KMNIST embeddings using tSNE\", fontsize=16)\nplt.legend()\nplt.show()","0420e157":"# Let's try UMAP now.\nnb_indices = 10000\nrandom_indices, random_train_images, random_train_labels, labels = get_random_samples(nb_indices)\n\nembedding = umap.UMAP(n_components=2, metric='correlation', min_dist=0.8)\nrandom_train_2D = embedding.fit_transform(random_train_images)\n\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111) #projection='3d')\n\nfor i, label in zip(labels, labels):\n    sns.scatterplot(random_train_2D[random_train_labels == i, 0], \n                random_train_2D[random_train_labels == i, 1], \n                label=label, s=15)\nplt.title(\"Visualiza KMNIST embeddings using UMAP \", fontsize=16)\nplt.legend()\nplt.show()","f11e91c4":"# A bunch of variables. The variable have the same value as given in the keras example\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# input shape\ninput_shape = (img_rows, img_cols, 1)","58ddddcc":"# Process the train and test data in the exact same manner as done for MNIST\nx_train = kmnist_train_images.astype('float32')\nx_test = kmnist_test_images.astype('float32')\nx_train \/= 255\nx_test \/= 255\n\nx_train = x_train.reshape(x_train.shape[0], *input_shape)\nx_test = x_test.reshape(x_test.shape[0], *input_shape)\n\n# convert class vectors to binary class matrices\ny_train = to_categorical(kmnist_train_labels, num_classes)\ny_test = to_categorical(kmnist_test_labels, num_classes)","cf2d0077":"# Build and train the model. \nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))","104dbce3":"# Check the test loss and test accuracy \nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1]*100)","01181939":"If you look at the embeddings, you can actually see why this problem is much harder than solving simple MNIST. If you haven't seen t-SNE  and UMAP embeddings for MNIST, I will show you right here.\n\nMNIST embeddings using t-SNE\n![tsne](https:\/\/in.mathworks.com\/help\/examples\/stats\/win64\/VisualizeHighDimensionalDataUsingTSNEExample_01.png)\n![umap](https:\/\/raw.githubusercontent.com\/lmcinnes\/umap\/master\/images\/umap_example_mnist1.png)\n\nBoth the algoritms can perfectly separate labels into different clusters but in KMNIST the clusters aren't that clear. Why do you think is the case with KMNIST? Just think about it ","3c94ddfe":"### Reproducing the results provided in the paper.\nIn the paper, it has been mentioned that a simple CNN used in Keras examples for MNIST achieves a score of 99.06%, in terms of accuracy,  while on KMNIST, the same network is able to achieve only ~95% of accuracy, Let's validate the results. \nWe will copy the [code](https:\/\/github.com\/keras-team\/keras\/blob\/master\/examples\/mnist_cnn.py) given in the keras repo for MNIST. We will train the network on KMNIST and check the final accuracy on the test set. Let's do that","fe80c823":"Hello everyone! Today, we are here with another very cool dataset **KMNIST**, short for **Kuzushiji-MNIST**.  This dataset was showcased at NeurIPS 2018 along with a [paper](https:\/\/arxiv.org\/pdf\/1812.01718.pdf).  The dataset is actually divided into three categories:<br>\n* **Kuzushiji-MNIST** is a drop-in replacement for the MNIST dataset (28x28 grayscale, 70,000 images), provided in the original MNIST format as well as a NumPy format. Since MNIST restricts us to 10 classes, we chose one character to represent each of the 10 rows of Hiragana when creating Kuzushiji-MNIST.\n\n* **Kuzushiji-49**, as the name suggests, has 49 classes (28x28 grayscale, 270,912 images), is a much larger, but imbalanced dataset containing 48 Hiragana characters and one Hiragana iteration mark.\n\n* **Kuzushiji-Kanji** is an imbalanced dataset of total 3832 Kanji characters (64x64 grayscale, 140,426 images), ranging from 1,766 examples to only a single example per class.\n\nIn this kernel, we will focus on the **Kuzushiji-MNIST**  dataset. For many years, researchers have been using MNIST as one of the standard datasets for benchmarking their algorithms. No doubt that MNIST is a very good dataset but given the advancements that we have achieved in deep learning in the last 5 years, it is high time to replace MNIST with a more challenging dataset.  The above point is fair but why KMNIST? What makes it unique? Why is it important?\n\nActually,  cursive Kuzushiji (\u304f\u305a\u3057\u5b57) was an integral part of Japanese culture in the pre-modernisation era. It has been used for more than 1000 years but with the reforms done by Japanese leaders in the Japanese education system in 1868 and the following years, Kuzushiji was no longer seen as an important part and as a result, it is no longer taught in the official school curriculum.  Now you may ask: \"So what? Japanese lost the script but with modernisation, such things are expected. Why do you think it is important at all?\"\n\nFair question! As a result of the changes that were made in the education system, most Japanese cannot read books over 150 years old, written in cursive Kuzushiji style. Also, According to the General Catalog of National Books, there have been over 1.7 million books written or published in Japan prior to 1867 along with a billion of unregistered books. **Almost every book, no matter what, always provides some sort of knowledge**.  So, in short, we have a lot of knowledge lying around in those books but we don't have many people who are experts in reading and extracting information from them. Because of lack of domain experts, the process of digitizing that knowledge is slow. \n\nThis dataset can help non-experts to develop systems that can be implemented to extract the information from those millions and billions of books. Deep learning can certainly be very useful in this task. If you want more info about the topic, I suggest reading that paper I mentioned above. Let's dive into the dataset now and see how different is it from MNIST.  \n \n![fun](https:\/\/pbs.twimg.com\/media\/DuKOQlXWoAAndWt.jpg:large)","b2557918":"### Load the dataset<br>\nThe focus of this kernel is going to be kmnisr, drop-in replacement for MNIST. So, we will be loading only that dataset. Also, KMNIST is provided in two formats: \n* Raw images and labels\n* Images and labels as numpy arrays stored in `npz` file format\n\nWe will be using the `npz` files to load and process the data because it is much faster as well as the recommended way.","2f7ad43b":"### t-SNE and UMAP\nVisulaizing high-dimensional data is always fun. Plus it can give you some basic insights about local and global relationships within the data, though it totally depends on your problem statement. Currently, there are two widely used algoritms that are used for visualuzing high dimesional data.\n* **[t-SNE](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.manifold.TSNE.html)**\n* **[UMAP](https:\/\/github.com\/lmcinnes\/umap)**\n\nWe will be using both to visualize KMNIST here. t-SNE is very expensive to compute. Also, the sklearn implementation of t-SNE is very very slow. It runs on single core and takes too much of memory. That's why I will be limiting the number of samples to at max 5K for t-SNE. For UMAP, we will be using a bigger sample size, somwhere 30K to 50K.","acc567db":"### Quick sneak peek\nBefore moving further, we will get some random samples for each label in the training data. We will look at how the images for each character(label) looks like and how much is the variation between samples of the same class. Given these samples without any prior, would you be able to group them correctly?   \ud83d\ude1b ","cab899dd":"Awesome. As reported in the paper, the results are fully reproducible. There is a huge gap  between the accuracy on MNIST and KMNIST. The same algorithm which scores `99.06%` on MNIST is able to score only `~95%` on KMNIST. This again proves the point that KMNIST is the perfect replacement for research and SOTA purposes as well. \n\nThat's it folks. Hope you enjoyed the kernel!","e1a444ff":"### Labels and their distribution<br>\nAs the dataset is a drop-in replacement for MNIST, it is expected that it will have 10 labels but for the sanity check, let's look into it and check how many samples for each label are there in  the training data "}}