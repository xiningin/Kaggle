{"cell_type":{"1a36b114":"code","870a3a33":"code","34ccdcf9":"code","66a2d7b0":"code","78799a77":"code","1c55f811":"code","8b18839b":"code","c67778ea":"code","7383e9e0":"code","97ba9089":"code","82e50222":"code","0e3e697b":"code","53a17270":"code","6d240659":"code","4718362c":"code","6fee91c4":"code","bb1fe896":"code","464a5e47":"code","44552cdf":"code","ab94b7f3":"code","3c187b65":"code","a4ec19ea":"code","07c2f728":"code","0a922762":"code","e1e3c428":"code","260967fa":"code","843d3993":"markdown","c0d4c226":"markdown","f3697b8e":"markdown","0966d10d":"markdown","e71fdf41":"markdown","92f363f4":"markdown","f2bc39b4":"markdown","0f3cf050":"markdown","46b1f43d":"markdown","1f575ec3":"markdown","96e77845":"markdown","1ba93c99":"markdown","25727fb6":"markdown","d94a6530":"markdown","1c5756c6":"markdown","8f994439":"markdown","276cb803":"markdown"},"source":{"1a36b114":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport PIL\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet import preprocess_input","870a3a33":"tf.__version__","34ccdcf9":"path = \"..\/input\/chest-ctscan-images\/Data\/train\"\nfor files in os.listdir(path):\n    print(os.path.join(path,files))","66a2d7b0":"train_path = \"..\/input\/chest-ctscan-images\/Data\/train\"\ntest_path = \"..\/input\/chest-ctscan-images\/Data\/test\"","78799a77":"# Helper-function for joining a directory and list of filenames.\ndef path_join(dirname, filenames):\n    return [os.path.join(dirname, filename) for filename in filenames]","1c55f811":"# Helper-function for plotting images\ndef plot_images(images, cls_true, cls_pred=None, smooth=True):\n\n    assert len(images) == len(cls_true)\n\n    # Create figure with sub-plots.\n    fig, axes = plt.subplots(3, 3, figsize=(15,15))\n\n    # Adjust vertical spacing.\n    if cls_pred is None:\n        hspace = 0.3\n    else:\n        hspace = 0.6\n    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n\n    # Interpolation type.\n    if smooth:\n        interpolation = 'spline16'\n    else:\n        interpolation = 'nearest'\n\n    for i, ax in enumerate(axes.flat):\n        # There may be less than 9 images, ensure it doesn't crash.\n        if i < len(images):\n            # Plot image.\n            ax.imshow(images[i],\n                      interpolation=interpolation)\n\n            # Name of the true class.\n            cls_true_name = class_names[cls_true[i]]\n\n            # Show true and predicted classes.\n            if cls_pred is None:\n                xlabel = \"True: {0}\".format(cls_true_name)\n            else:\n                # Name of the predicted class.\n                cls_pred_name = class_names[cls_pred[i]]\n\n                xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n\n            # Show the classes as the label on the x-axis.\n            ax.set_xlabel(xlabel)\n        \n        # Remove ticks from the plot.\n        ax.set_xticks([])\n        ax.set_yticks([])\n    \n    # Ensure the plot is shown correctly with multiple plots\n    # in a single Notebook cell.\n    plt.show()","8b18839b":"# Helper-function for printing confusion matrix\n\n# Import a function from sklearn to calculate the confusion-matrix.\nfrom sklearn.metrics import confusion_matrix\n\ndef print_confusion_matrix(cls_pred):\n    # cls_pred is an array of the predicted class-number for\n    # all images in the test-set.\n\n    # Get the confusion matrix using sklearn.\n    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n                          y_pred=cls_pred)  # Predicted class.\n\n    print(\"Confusion matrix:\")\n    \n    # Print the confusion matrix as text.\n    print(cm)\n    \n    # Print the class-names for easy reference.\n    for i, class_name in enumerate(class_names):\n        print(\"({0}) {1}\".format(i, class_name))","c67778ea":"# Helper-function for plotting example errors\ndef plot_example_errors(cls_pred):\n    # cls_pred is an array of the predicted class-number for\n    # all images in the test-set.\n\n    # Boolean array whether the predicted class is incorrect.\n    incorrect = (cls_pred != cls_test)\n\n    # Get the file-paths for images that were incorrectly classified.\n    image_paths = np.array(image_paths_test)[incorrect]\n\n    # Load the first 9 images.\n    images = load_images(image_paths=image_paths[0:9])\n    \n    # Get the predicted classes for those images.\n    cls_pred = cls_pred[incorrect]\n\n    # Get the true classes for those images.\n    cls_true = cls_test[incorrect]\n    \n    # Plot the 9 images we have loaded and their corresponding classes.\n    # We have only loaded 9 images so there is no need to slice those again.\n    plot_images(images=images,\n                cls_true=cls_true[0:9],\n                cls_pred=cls_pred[0:9])","7383e9e0":"# Function for calculating the predicted classes of the entire test-set and calling \n# the above function to plot a few examples of mis-classified images.\ndef example_errors():\n    # The Keras data-generator for the test-set must be reset\n    # before processing. This is because the generator will loop\n    # infinitely and keep an internal index into the dataset.\n    # So it might start in the middle of the test-set if we do\n    # not reset it first. This makes it impossible to match the\n    # predicted classes with the input images.\n    # If we reset the generator, then it always starts at the\n    # beginning so we know exactly which input-images were used.\n    test_generator.reset()\n    \n    # Predict the classes for all images in the test-set.\n    y_pred = model.predict(test_generator, steps=STEPS_TEST)\n\n    # Convert the predicted classes from arrays to integers.\n    cls_pred = np.argmax(y_pred,axis=1)\n\n    # Plot examples of mis-classified images.\n    plot_example_errors(cls_pred)\n    \n    # Print the confusion matrix.\n    print_confusion_matrix(cls_pred)","97ba9089":"# Helper-function for loading images\ndef load_images(image_paths):\n    # Load the images from disk.\n    images = [plt.imread(path) for path in image_paths]\n\n    # Convert to a numpy array and return it.\n    return np.asarray(images)","82e50222":"# Set some important constants here\nIMAGE_SIZE = 350\nN_CLASSES = 4\nBATCH_SIZE = 5","0e3e697b":"# ImageDataGenerator is needed because the dataset has no many data.\n# The data augmentation can be useful to generate many augmented images from a single image\n\n# train_datagen = ImageDataGenerator(\n#       rescale=1.\/255,\n#       rotation_range=0.4,\n#       width_shift_range=0.2,\n#       height_shift_range=0.2,\n#       shear_range=0.2,\n#       zoom_range=0.2,\n#       horizontal_flip=True,\n#       vertical_flip=True,\n#       fill_mode='nearest')\ntrain_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=preprocess_input)\ntrain_generator = train_datagen.flow_from_directory(train_path,\n                                                   batch_size = BATCH_SIZE,\n                                                   target_size = (IMAGE_SIZE, IMAGE_SIZE),\n                                                   class_mode = 'categorical')\n\n# test_datagen = ImageDataGenerator(rescale = 1.0\/255.0)\ntest_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=preprocess_input)\ntest_generator = test_datagen.flow_from_directory(test_path,\n                                                   batch_size = BATCH_SIZE,\n                                                   target_size = (IMAGE_SIZE, IMAGE_SIZE),\n                                                   class_mode = 'categorical')","53a17270":"# save some values to be used later\n\ncls_train = train_generator.classes\ncls_test = test_generator.classes\nclass_names = list(train_generator.class_indices.keys())\nprint(class_names)\nnum_classes = train_generator.num_classes\nprint(\"num classes:\",num_classes)","6d240659":"image_paths_train = path_join(train_path, train_generator.filenames)\nimage_paths_test = path_join(test_path, test_generator.filenames)","4718362c":"STEPS_TEST = test_generator.n \/ BATCH_SIZE\nSTEPS_TEST","6fee91c4":"res_model = ResNet50(include_top=False, pooling='avg', weights='imagenet', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))","bb1fe896":"for layer in res_model.layers:\n    if 'conv5' not in layer.name:\n        layer.trainable = False","464a5e47":"# Check if all layers except conv5 layers are not trainable\nfor i, layer in enumerate(res_model.layers):\n    print(i, layer.name, \"-\", layer.trainable)","44552cdf":"model = Sequential()\nmodel.add(res_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(N_CLASSES, activation='softmax'))","ab94b7f3":"model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['acc'])","3c187b65":"model.summary()","a4ec19ea":"checkpoint = ModelCheckpoint(filepath='.\/chest_CT_SCAN-ResNet50.h5',\n                            monitor='val_loss',\n                            mode='auto',\n                            save_best_only=True)\nearly_stopping = EarlyStopping(verbose=1, patience=3)","07c2f728":"history = model.fit(train_generator,\n                    steps_per_epoch = 100,\n                    epochs = 20,\n                    verbose = 1,\n                    validation_data = test_generator,\n                    validation_steps = 50,\n                    callbacks = [checkpoint, early_stopping])","0a922762":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","e1e3c428":"result = model.evaluate(test_generator, steps=STEPS_TEST)","260967fa":"example_errors()","843d3993":"---","c0d4c226":"# Helper Functions\ntaken from: https:\/\/github.com\/Hvass-Labs\/TensorFlow-Tutorials\/blob\/master\/10_Fine-Tuning.ipynb <br>\nThese helper functions will be useful for later computation.","f3697b8e":"Make sure to set all layers to be not trainable except the last convolution layer. We need the last convolution layer to be trained so it can adapt our data during learning process. We do this to make the computation more efficient since the layers is trained before in the base model.","0966d10d":"We can see from the confusion matrix that our model are often predicts an image wrong but can still achieve the accuracy about 70%. Perhaps we need to do another approach to fine-tune the model so it can perform better.","e71fdf41":"After that, we create new model to connect it later with pre-trained model. Since we excluded the top layers, we need to make the new layers to fit the classification task on this data. In this case, we only have 4 classes, so make a dense layer that can output 4 classes only using softmax activation function.","92f363f4":"We import the pre-Trained ResNet50 from tensorflow, and we exclude the top layer because we will use Transfer Learning. We use Average Pooling layer and use weights from ImageNet dataset.","f2bc39b4":"The model seems pretty good for now because it can reach 70% accuracy. Still, the model can be improved in other way. Last step, let's see what are the examples that can make the model fail to predict the images.","0f3cf050":"References:\n* https:\/\/medium.com\/@kenneth.ca95\/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b\n* https:\/\/www.kaggle.com\/vincentsiow\/chest-ct-scan-using-resnet101v2\n* https:\/\/stackoverflow.com\/a\/61656540\/10275039","46b1f43d":"We set some callbacks method for evaluation purpose","1f575ec3":"Now we plot the line graph to see how the model performs on this data","96e77845":"Begin to create data generator to arrange the dataset to be used later. This can makes the work easier.","1ba93c99":"Then we set the path for this data.","25727fb6":"First we need to import all important modules.","d94a6530":"**LOG**\n<br>\n05\/02\/2022\n* Add classification evaluation accuracy\n* Add helper functions for plotting\n* Add descriptions and comments\n\n04\/02\/2022\n* Add Average Pooling layer into the network.\n* Use `tf.keras.applications.resnet.preprocess_input` instead of manual augmentation.\n* Simplify transfer learning model.\n* Change image size input from 224 to 350.\n* Change `monitor` in `ModelCheckpoint` from `val_acc` to `val_loss` and set the `mode` to `auto`.\n* Change `patience` in `EarlyStopping` from 5 to 3.\n\n03\/02\/2022\n* Initial code.","1c5756c6":"*This notebook is for my learning purpose so the model might be not optimal nor efficient.*","8f994439":"Compile the model then the model is ready to train","276cb803":"# Working on ResNet50"}}