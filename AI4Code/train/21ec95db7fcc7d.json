{"cell_type":{"3186d45b":"code","d5ee5036":"code","84030c1a":"code","c2a7be46":"code","1d855ea0":"code","ff6e81de":"code","e35a0c29":"code","c9ce9a93":"code","b66993f2":"code","1ff4d0a2":"code","d0de1e9e":"code","40a54335":"markdown","e8aa3f86":"markdown","5d0789c8":"markdown","f422b08f":"markdown","5a57bc87":"markdown","d4e5769f":"markdown","890942b9":"markdown","71062f9c":"markdown","ae767efd":"markdown","41a45523":"markdown","f187b867":"markdown","c0c9e136":"markdown","ac9e93fe":"markdown","01cc2bbb":"markdown","20b0af50":"markdown","7f39bf46":"markdown"},"source":{"3186d45b":"# for basic operations\nimport numpy as np\nimport pandas as pd\n\n# for visualizations\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud\nimport networkx as nx\n\n# for analysis\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nfrom mlxtend.preprocessing import TransactionEncoder","d5ee5036":"# importing the two datasets and merging them based on the same column\ndf1 = pd.read_csv(r\"..\/input\/market2\/transactions.csv\")\ndf2 = pd.read_csv(r\"..\/input\/market1\/segments-description.csv\")\ndf = df1.merge(df2, on=\"COD_MKT_ID\")","84030c1a":"# checking the head of the data\ndf.head()","c2a7be46":"# checking the tail of the data\ndf.tail()","1d855ea0":"# for simplicity we prefer to work on 10000 transactions rather than nearly 1 million which fails the computer RAM\ndf=df.iloc[0:10000]\ndf","ff6e81de":"# making each transaction-id unique and create a new dataset that contains lists of items that are bought together\nlst=[]\nfor item in df['SCONTRINO_ID'].unique():\n    lst2=list(set(df[df['SCONTRINO_ID']==item]['SEGMENTO']))\n    if len(lst2)>0:\n        lst.append(lst2)\nprint(lst[0:3])\nprint(len(lst))","e35a0c29":"# a good tool for data visualization to see the most popular items in SEGMENTO column\nplt.rcParams['figure.figsize'] = (15, 15)\nwordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 10000).generate(str(lst))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Most Popular Items',fontsize = 20)\nplt.show()","c9ce9a93":"# for Apriori algorithm, the dataset has to be one-hot encoded\nte = TransactionEncoder()\nte_lst = te.fit(lst).transform(lst)\ndata = pd.DataFrame(te_lst,columns=te.columns_)\ndata","b66993f2":"# Apriori Algorithm finds the frequent itemsets\nfrequent_items= apriori(data, use_colnames=True, min_support=0.03)\nfrequent_items.head()","1ff4d0a2":"# Association rules function is used which can take any metric such as 'lift' and also the minimum threshold set to 1\nrules = association_rules(frequent_items, metric=\"lift\", min_threshold=1)\nrules.antecedents = rules.antecedents.apply(lambda x: next(iter(x)))\nrules.consequents = rules.consequents.apply(lambda x: next(iter(x)))\nrules","d0de1e9e":"# a network graph to check association between antecedents and consequents\nfig, ax=plt.subplots(figsize=(10,4))\nGA=nx.from_pandas_edgelist(rules,source='antecedents',target='consequents')\nnx.draw(GA,with_labels=True)\nplt.show()","40a54335":"We will see some vidualizations in output using the following codes.","e8aa3f86":"Now let's import some packages which we are going to use them in the next parts.","5d0789c8":"The idea here is that for every customer we have a unique transaction, but as you can see these transactions are repeated many times in rows of the table which determine each purchases at a time. At end we want to consider one basket for each customer for a trip to the supermarket.\nTo do so, we will make each transaction(SCONTRINO_ID) unique.","f422b08f":"<font size=\"4\">Introduction<\/font>","5a57bc87":"<font size=\"4\">Begining of the codes<\/font>","d4e5769f":"The major problem in the project is that we have two datasets and we want to work with column \"SCONTRINO_ID\" which is the transaction code of customers and the column \"SEGMENTO\" which is the segment we are going to analize. The thing is that we have these two information in two different files. The idea is to merge these two table in one table based on the common column named \"COD_MKT_ID\", which is the product number. For example Apple could be equal to 24 and etc.\nWe merge them by using Pandas.","890942b9":"In this project I am using two CSV datasets(Italian products) which are described below.\nFirst of all we need to consider the customers' transactions and be informed of what products they buy in the supermarket.\n\nTo do so, we are given a huge dataset named \"transactions\" which contains the customers' transaction code with the number of product she\/he bought.\n\nThe second dataset contains number of columns which are information we are not very interested to most of them. But we need two important ones. First, the product number which we had in \"transaction\" file and also segment column.\n\nto make it clear I am going to explain what we are going to do with these project. We want to analyze the customer's purchased stuffs and analyze what kind of products they bought and see which of them are more frequent and which item they are tending to buy afterwards.\n\nThe difference here is that we want to analyze the segments and not the products. The column \"Segmento\" in the \"segments-description\" is our focus.\n\nTo sum up, we have two CSV files named \"transactions\" and \"segments-description\".","71062f9c":"<font size=\"6\">Market Basket Analysis<\/font>\n\n<font size=\"3\">Pouya Hosseinzadeh<\/font>","ae767efd":"One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.","41a45523":"In this project I am going to analyze Market-Basket datasets to find the frequent itemsets and also generate some rules which is a key factor for Market-Basket analysis.\n\nTo have an overall overview, first take a quick look at what Market-Basket analysis is and how it is used in real life applications.\n\nSuppose you are in a supermarket and you are thinking of your little baby and buy a diaper. Afterwards, you see beers next to the diapers and pick them up!\n\nStatistics show that(this project is one of them) fathers who buy a diaper, they tend to buy beers afterwards. So, if we put the shelves belonging to beers next to the diaper ones, we push them to buy beers subconsciously.\n\nNow, let's talk about these statistics and analyses to see which products come after each other and learn how to analyze any dataset with a simple lines of code.\n","f187b867":"Then we generate rules to see which product should come after a given product.","c0c9e136":"Here we have a visualization and see the most important products bigger in the output. They are repeated more.","ac9e93fe":"Another visualization for the generated rules.","01cc2bbb":"![Market-photo.jpg](attachment:Market-photo.jpg)","20b0af50":"Since we have millions of transactions in the supermarket and we have all of them in our datasets, we will face a disaster after running the code. The 8 GB RAM of my laptop is not able to handle the processing part and the computer freezes.\nTo avoid facing this problem, I consider only a portion of dataset(eg, 10000 transactions) and work with it.","7f39bf46":"Now running A-priori algorithm"}}