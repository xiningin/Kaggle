{"cell_type":{"ad07e21b":"code","17ad8448":"code","426568b1":"code","3181d1a7":"code","491ca07a":"code","e3795c3c":"code","cdde38bb":"code","402cfa2a":"code","78b79a16":"code","aa86e9f2":"code","40b1c10e":"code","48941089":"code","4c6db119":"code","d1ba3fe3":"code","36ffed2c":"code","779293f7":"code","bb0ec950":"code","db2f1d1d":"code","80cae86d":"code","2d5331c4":"code","cd35c1d2":"code","16f9d19d":"markdown","394f6f4c":"markdown","8eb40cc1":"markdown","f6589a3a":"markdown","d8b432b6":"markdown","c0ff61e9":"markdown","c9e30e14":"markdown","acf0d3b0":"markdown","3671fce6":"markdown"},"source":{"ad07e21b":"import cv2\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\n%matplotlib inline","17ad8448":"IMAGE = '..\/input\/lena.bmp'\nIMAGE_GRAY = '..\/input\/lena.gray.bmp'","426568b1":"#OpenCV will import all images (grayscale or color) as having 3 channels\ncolor_img_as_grayscale = cv2.imread(IMAGE, 0) #0 for read as grayscale(single channel), -1 for read as it is, default 1 for read as color\nprint(\"Shape of lena.bmp after converting to\/read as single channel (grayscale) i.e., color_img_as_grayscale : {}\".format(color_img_as_grayscale.shape))","3181d1a7":"#Without cmap='gray argument, matplotlib will try to plot the gray image as a RGB image. This is wrong way of plotting image\nplt.imshow(color_img_as_grayscale)\nplt.title(\"Wrong\")","491ca07a":"#The correct way of plotting a grayscale image using matplotlib goes like this\nplt.imshow(color_img_as_grayscale, cmap='gray')\nplt.title(\"Right\")","e3795c3c":"color_img_bgr = cv2.imread(IMAGE) #default 1 for read as color\nprint(\"Shape of lena.bmp as it is (color), i.e., color_img : {}\".format(color_img_bgr.shape))","cdde38bb":"# Example of how matplotlib displays color images from OpenCV incorrectly\nplt.imshow(color_img_bgr)\nplt.title(\"Wrong : How OpenCV images (BGR) display in Matplotlib (RGB)\")","402cfa2a":"#images are stored as numpy arrays\ntype(color_img_bgr)","78b79a16":"#Right way of doing it\ncolor_img_rgb = color_img_bgr[:,:,::-1] #slicing only the channel component to reverse its order: BGR reversed is RGB!\nplt.imshow(color_img_rgb)\nplt.title(\"Right\")","aa86e9f2":"img = cv2.imread(IMAGE_GRAY)\nprint(\"Shape of lena.gray.bmp i.e., img : {}\".format(img.shape))","40b1c10e":"plt.imshow(img)\nplt.title(\"lena.gray.bmp\")","48941089":"#Didn't do numpy array slicing above since each pixel has the same value in all 3 channels.\nimg","4c6db119":"def reduce_intensity(img, factor):\n    \"\"\"Quantize by the specified factor\"\"\"\n    return np.multiply(np.floor(np.divide(img, factor)).astype(int), factor)","d1ba3fe3":"reduced_intensity_image = reduce_intensity(color_img_rgb, 128)\nplt.imshow(reduced_intensity_image)","36ffed2c":"from scipy import ndimage\ndef neighborhood_averaging(img, filter_size):\n    \"\"\"If filter_size is 3, then average of 3x3 is calculated. Centre pixel is not ignored\"\"\"\n    #return ndimage.generic_filter(input=img, function=np.nanmean, size=filter_size, mode='constant', cval=np.NaN)\n    return cv2.blur(img, (filter_size, filter_size))","779293f7":"fig = plt.figure(figsize=(25, 25))\n\nimg1 = fig.add_subplot(1,4,1) #1 rows, 4 coulmns, image fills the 1st column\nimg1.imshow(color_img_rgb)\nplt.title(\"Original image\")\n\nimg2 = fig.add_subplot(1,4,2) #1 rows, 4 coulmns, image fills the 2nd column\nimg2.imshow(neighborhood_averaging(color_img_rgb, 3))\nplt.title(\"3x3 neighbourhood averaged image\")\n\nimg3 = fig.add_subplot(1,4,3) #1 rows, 4 coulmns, image fills the 3rd column\nimg3.imshow(neighborhood_averaging(color_img_rgb, 10))\nplt.title(\"10x10 neighbourhood averaged image\")\n\nimg4 = fig.add_subplot(1,4,4) #1 rows, 4 coulmns, image fills the 4th column\nimg4.imshow(neighborhood_averaging(color_img_rgb, 20))\nplt.title(\"20x20 neighbourhood averaged image\")","bb0ec950":"fig = plt.figure(figsize=(25, 25))\n\nimg1 = fig.add_subplot(1,4,1) #1 rows, 4 coulmns, image fills the 1st column\nimg1.imshow(color_img_as_grayscale, cmap='gray')\nplt.title(\"Original image\")\n\nimg2 = fig.add_subplot(1,4,2) #1 rows, 4 coulmns, image fills the 2nd column\nimg2.imshow(neighborhood_averaging(color_img_as_grayscale, 3), cmap='gray')\nplt.title(\"3x3 neighbourhood averaged image\")\n\nimg3 = fig.add_subplot(1,4,3) #1 rows, 4 coulmns, image fills the 3rd column\nimg3.imshow(neighborhood_averaging(color_img_as_grayscale, 10), cmap='gray')\nplt.title(\"10x10 neighbourhood averaged image\")\n\nimg4 = fig.add_subplot(1,4,4) #1 rows, 4 coulmns, image fills the 4th column\nimg4.imshow(neighborhood_averaging(color_img_as_grayscale, 20), cmap='gray')\nplt.title(\"20x20 neighbourhood averaged image\")","db2f1d1d":"def image_rotate(img, angle):\n    \"\"\"Rotates the image by angle degrees\"\"\"\n    rows, cols, _ = img.shape\n    rotation = cv2.getRotationMatrix2D(center=(cols\/2,rows\/2), angle=angle, scale=1)\n    rotated = cv2.warpAffine(src=img, M=rotation, dsize=(cols, rows))\n    return rotated","80cae86d":"fig = plt.figure(figsize=(20, 20))\n\nimg1 = fig.add_subplot(1,3,1)\nimg1.imshow(color_img_rgb)\nplt.title(\"Original image\")\n\nimg2 = fig.add_subplot(1,3,2)\nimg2.imshow(image_rotate(color_img_rgb, 45))\nplt.title(\"45 degree rotated image\")\n\nimg3 = fig.add_subplot(1,3,3)\nimg3.imshow(image_rotate(color_img_rgb, 90))\nplt.title(\"90 degree rotated image\")","2d5331c4":"def shrink_resolution(img, factor):\n    \"\"\"Reduces resolution of an image by reducing and re enlarging it using the average of the neighbouring pixels\"\"\"\n    shrunk = cv2.resize(img, (0,0), None, fx=1.0\/factor, fy=1.0\/factor, interpolation=cv2.INTER_AREA)\n    print(\"Shape of reduced\/shrunk image = {}\".format(shrunk.shape))\n    re_enlarged= cv2.resize(shrunk, (0,0), None, fx=factor, fy=factor, interpolation=cv2.INTER_AREA)\n    print(\"Shape of re-enlarged image = {}\".format(re_enlarged.shape))\n    return (shrunk, re_enlarged)","cd35c1d2":"fig = plt.figure(figsize=(20, 20))\n\n#shrinking and re-enlarging by a factor of 10 using 10x10 blocks\n(shrunk, re_enlarged) = shrink_resolution(color_img_rgb, 10)\n\nimg1 = fig.add_subplot(1,3,1)\nimg1.imshow(color_img_rgb)\nplt.title(\"Original image\")\n\nimg2 = fig.add_subplot(1,3,2)\nimg2.imshow(shrunk)\nplt.title(\"Shrunk image\")\n\nimg3 = fig.add_subplot(1,3,3)\nimg3.imshow(re_enlarged)\nplt.title(\"Re-enlarged image\")","16f9d19d":"# **Plotting lena.bmp after reading it as a grayscale image**","394f6f4c":"# **Plotting lena.gray.bmp**\n\nWe must understand that lena.gray.bmp is not a grayscale image since it has 3 channels. Apparently, each pixel has the same value in all 3 channels. Hence, it looks like a grayscale image.","8eb40cc1":"# **3**\n\nRotate the image by 45 and 90 degrees","f6589a3a":"# **Plotting lena.bmp as it is i.e., using all 3 channel values**","d8b432b6":"# **2**\n\nUsing any programming language you feel comfortable with (it is though recommended to use the provided free Matlab), load an image and then perform a simple spatial 3x3 average of image pixels. In other words, replace the value of every pixel by the average of the values in its 3x3 neighborhood. If the pixel is located at (0,0), this means averaging the values of the pixels at the positions (-1,1), (0,1), (1,1), (-1,0), (0,0), (1,0), (-1,-1), (0,-1), and (1,-1). Be careful with pixels at the image boundaries. Repeat the process for a 10x10 neighborhood and again for a 20x20 neighborhood. Observe what happens to the image (we will discuss this in more details in the very near future, about week 3).","c0ff61e9":"For every 3\u00d73 block of the image (without overlapping), replace all corresponding 9 pixels by their average. This operation simulates reducing the image spatial resolution. Repeat this for 5\u00d75 blocks, 7\u00d77 blocks and 10x10 blocks.","c9e30e14":"# **4**","acf0d3b0":"# **Exercises**","3671fce6":"# **1**\n\nWrite a computer program capable of reducing the number of intensity levels in an image from 256 to 2, in integer powers of 2. The desired number of intensity levels needs to be a variable input to your program."}}