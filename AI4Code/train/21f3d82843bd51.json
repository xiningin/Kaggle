{"cell_type":{"43082296":"code","f80fd449":"code","5439c7f9":"code","fa1fb8c2":"code","67668283":"code","54301b41":"code","3d1cea71":"code","b45a97f2":"code","e0f1756e":"code","c85f77c9":"code","e51212a3":"code","dd96495c":"code","413a888e":"code","c2010c00":"code","dcb7a53e":"code","9c0f7809":"code","ef83f896":"code","299af853":"code","285e0612":"code","f525f8d5":"code","5da80225":"code","ac561255":"markdown"},"source":{"43082296":"# Libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns","f80fd449":"# store the data into a variable\ndf = pd.read_csv(\"..\/input\/cardiovascular-disease-dataset\/cardio_train.csv\", sep = ';')\n\n# Print the head of data\ndf.head()","5439c7f9":"# check for any null or missing values\ndf.isnull().values.any()","fa1fb8c2":"# View some basic statistics\ndf.describe().T","67668283":"# Get a count of the num of patients with a cardiovascular disease and without\n\ndf['cardio'].value_counts()","54301b41":"# Visualize the count\nsns.countplot(df['cardio'])","3d1cea71":"# create a years column\ndf['years'] = (df['age']\/365).round(0)\ndf['years'] = pd.to_numeric( df['years'], downcast = 'integer')\n\n# Visualize the data\nsns.countplot(x='years', hue = 'cardio', data = df, palette = 'colorblind', edgecolor = sns.color_palette('dark', n_colors = 1));","b45a97f2":"# orrelation table\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize =(7,7))\nsns.heatmap(df.corr(), annot=True, fmt = '.0%');\n# with that heatmap we can see easily correlations","e0f1756e":"# drop the years column\ndf = df.drop('years', axis = 1) # axis = 1 means column\n# drop the id column\ndf = df.drop('id', axis = 1)","c85f77c9":"# split the data into deature data and target data\nX = df.iloc[:, :-1].values\nY = df.iloc[:, -1].values","e51212a3":"# Split the data into 67% training - 33% testing\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)","dd96495c":"# Feature Scaling\n# Scale the values in the data to be values btw 0 and 1 inclusive\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\n\n# Use Random farest classifier\nfrom sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\nforest.fit(X_train, y_train)","413a888e":"# Test our model's accuracy on the training data set\n\nmodel = forest\nmodel.score(X_train, y_train)\n#0.98 is a not bad score but I tried tune the model, in next step\n","c2010c00":"# Test the model's accuracy on the test data set \n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, model.predict(X_test))\n\nTN = cm[0][0]\nTP = cm[1][1]\nFN = cm[1][0]\nFP = cm[0][1]\n\n# print the confusion matrix\nprint(cm)\n\n# Print the models accuracy on the test data\nprint('Model Test Accuracy = {}'.format((TP+TN)\/ (TP+TN+FN+FP)))","dcb7a53e":"# Tune our model\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\nrf_params = {\"max_depth\": [2,5,8,10],\n             \"max_features\": [2,5,8],\n             \"n_estimators\": [10,500,1000],\n             \"min_samples_split\": [2,5,10]}","9c0f7809":"rf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params,\n                           cv = 10,\n                           n_jobs = -1,\n                           verbose = 2)","ef83f896":"rf_cv_model.fit(X_train, y_train)","299af853":"print(\"Best rf parameters: \" + str(rf_cv_model.best_params_))","285e0612":"rf_model = RandomForestClassifier(max_depth = 8,\n                                  max_features = 5 ,\n                                  min_samples_split = 10 ,\n                                  n_estimators = 500)\n                                \nrf_model.fit(X_train, y_train)","f525f8d5":"# Test our model's accuracy on the training data set\n\ntuned_model = rf_model\ntuned_model.score(X_train, y_train)","5da80225":"# Test the model's accuracy on the test data set \n\ncm_tuned = confusion_matrix(y_test, tuned_model.predict(X_test))\n\nTN = cm_tuned[0][0]\nTP = cm_tuned[1][1]\nFN = cm_tuned[1][0]\nFP = cm_tuned[0][1]\n\n# print the confusion matrix\nprint(cm_tuned)\n\n# Print the models accuracy on the test data\nprint('Tuned Model Test Accuracy = {}'.format((TP+TN)\/ (TP+TN+FN+FP))) ","ac561255":"#### Our result has an acceptable success, but I wanted to tune our model with gridsearch.\n---\n"}}