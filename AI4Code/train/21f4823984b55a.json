{"cell_type":{"600eaec8":"code","66f181ee":"code","e2703e4a":"code","288b1249":"code","5a8149c0":"code","c4037d79":"code","3499d736":"code","e5db0757":"code","24ed93f2":"code","9a71fc5b":"code","79f56186":"code","48328e52":"code","1cf2ca5f":"code","2e91a02a":"code","b5f17e52":"code","a25ce8d9":"code","1a060afc":"code","5de6009f":"code","3fb96bd7":"code","d3e84d43":"code","9b011e88":"code","b00c01f8":"code","b59552d7":"code","fad8d663":"code","f5011ba8":"code","c5708333":"markdown","85511f99":"markdown","d6bd5418":"markdown","e04ed31a":"markdown","3a8887a3":"markdown","fab8a74f":"markdown","eeeeb091":"markdown","d8ef74bd":"markdown","6ce3150e":"markdown","6c238cb8":"markdown"},"source":{"600eaec8":"import pandas as pd\nimport numpy as np\n\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import accuracy_score\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nFEATURES = [\n    'total_acc_x_',\n    'total_acc_y_',\n    'total_acc_z_',\n\n    'body_acc_x_',\n    'body_acc_y_',\n    'body_acc_z_',\n\n    'body_gyro_x_',\n    'body_gyro_y_',\n    'body_gyro_z_'\n]\n\nTARGETS = [\n    'WALKING',\n    'WALKING_UPSTAIRS',\n    'WALKING_DOWNSTAIRS',\n    'SITTING',\n    'STANDING',\n    'LAYING'\n]","66f181ee":"train_x = np.fromfile('..\/input\/con_train_x.bin').reshape((7352, 128, 9))\ntrain_y = to_categorical(pd.read_csv('..\/input\/con_train_y.csv')[['label']])\ntest_x = np.fromfile('..\/input\/con_test_x.bin').reshape((2947, 128, 9))","e2703e4a":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(train_x, train_y, test_size=0.3, random_state=42)","288b1249":"pd.Series(dict(zip(TARGETS, train_y.sum(axis=0))))","5a8149c0":"X_train.shape # (sample, timestamp, feature_index)","c4037d79":"test_x.shape","3499d736":"sample = X_train[0]\n\nf, ax = plt.subplots(nrows=sample.shape[1], figsize=(16,15))\n\nfor i in range(sample.shape[1]):\n    ax[i].set_title(FEATURES[i])\n    ax[i].plot(sample[:, i])","e5db0757":"from xgboost import XGBClassifier\n\n\nxgb_train_x = X_train.reshape(len(X_train), -1)\nxgb_val_x = X_val.reshape(len(X_val), -1)\n\nxgb_train_y = np.argmax(y_train, axis=1)\nxgb_val_y = np.argmax(y_val, axis=1)","24ed93f2":"xgbc = XGBClassifier(n_estimators=100, random_state=0, n_jobs=-1)","9a71fc5b":"xgbc.fit(xgb_train_x, xgb_train_y)","79f56186":"preds = xgbc.predict(xgb_val_x)","48328e52":"accuracy_score(np.argmax(y_val, axis=1), preds)","1cf2ca5f":"xgb_train_x = train_x.reshape(len(train_x), -1)\nxgb_test_x = test_x.reshape(len(test_x), -1)\n\nxgb_train_y = np.argmax(train_y, axis=1)","2e91a02a":"xgbc.fit(xgb_train_x, xgb_train_y)","b5f17e52":"xgbc.predict(xgb_test_x)","a25ce8d9":"from keras.models import Model\nfrom keras.layers import Input, Dense, Add, Activation, Conv1D, GlobalAveragePooling1D\nfrom keras.utils import np_utils\nimport numpy as np\nimport keras \nfrom keras.callbacks import ReduceLROnPlateau\n\n \ndef build_resnet(input_shape, n_feature_maps, nb_classes):    \n    x = Input(shape=(input_shape))\n    conv_x = keras.layers.normalization.BatchNormalization()(x)\n    conv_x = keras.layers.Conv1D(n_feature_maps, 8, padding='same')(conv_x)\n    conv_x = keras.layers.normalization.BatchNormalization()(conv_x)\n    conv_x = Activation('relu')(conv_x) \n\n    conv_y = keras.layers.Conv1D(n_feature_maps, 5, padding='same')(conv_x)\n    conv_y = keras.layers.normalization.BatchNormalization()(conv_y)\n    conv_y = Activation('relu')(conv_y)\n\n    conv_z = keras.layers.Conv1D(n_feature_maps, 3, padding='same')(conv_y)\n    conv_z = keras.layers.normalization.BatchNormalization()(conv_z)\n\n    is_expand_channels = not (input_shape[-1] == n_feature_maps)\n    if is_expand_channels:\n        shortcut_y = keras.layers.Conv1D(n_feature_maps, 1, padding='same')(x)\n        shortcut_y = keras.layers.normalization.BatchNormalization()(shortcut_y)\n    else:\n        shortcut_y = keras.layers.normalization.BatchNormalization()(x)\n\n    y = Add()([shortcut_y, conv_z])\n    y = Activation('relu')(y)\n\n    x1 = y\n    conv_x = keras.layers.Conv1D(n_feature_maps*2, 8, padding='same')(x1)\n    conv_x = keras.layers.normalization.BatchNormalization()(conv_x)\n    conv_x = Activation('relu')(conv_x)\n\n\n    conv_y = keras.layers.Conv1D(n_feature_maps*2, 5, padding='same')(conv_x)\n    conv_y = keras.layers.normalization.BatchNormalization()(conv_y)\n    conv_y = Activation('relu')(conv_y)\n\n\n    conv_z = keras.layers.Conv1D(n_feature_maps*2, 3, padding='same')(conv_y)\n    conv_z = keras.layers.normalization.BatchNormalization()(conv_z)\n\n    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n    if is_expand_channels:\n        shortcut_y = keras.layers.Conv1D(n_feature_maps*2, 1, padding='same')(x1)\n        shortcut_y = keras.layers.normalization.BatchNormalization()(shortcut_y)\n    else:\n        shortcut_y = keras.layers.normalization.BatchNormalization()(x1)\n\n    y = Add()([shortcut_y, conv_z])\n    y = Activation('relu')(y)\n\n    x1 = y\n    conv_x = keras.layers.Conv1D(n_feature_maps*2, 8, padding='same')(x1)\n    conv_x = keras.layers.normalization.BatchNormalization()(conv_x)\n    conv_x = Activation('relu')(conv_x)\n\n    conv_y = keras.layers.Conv1D(n_feature_maps*2, 5, padding='same')(conv_x)\n    conv_y = keras.layers.normalization.BatchNormalization()(conv_y)\n    conv_y = Activation('relu')(conv_y)\n\n    conv_z = keras.layers.Conv1D(n_feature_maps*2, 3, padding='same')(conv_y)\n    conv_z = keras.layers.normalization.BatchNormalization()(conv_z)\n\n    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n    if is_expand_channels:\n        shortcut_y = keras.layers.Conv1D(n_feature_maps*2, 1, padding='same')(x1)\n        shortcut_y = keras.layers.normalization.BatchNormalization()(shortcut_y)\n    else:\n        shortcut_y = keras.layers.normalization.BatchNormalization()(x1)\n\n    y = Add()([shortcut_y, conv_z])\n    y = Activation('relu')(y)\n\n    full = keras.layers.pooling.GlobalAveragePooling1D()(y)   \n    out = Dense(nb_classes, activation='softmax')(full)\n\n    return x, out","1a060afc":"inputs, outputs = build_resnet(train_x.shape[1:], n_feature_maps=64, nb_classes=y_train.shape[1])","5de6009f":"model = Model(inputs, outputs)\noptimizer = keras.optimizers.Adam(lr=0.0001)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])","3fb96bd7":"chck = keras.callbacks.ModelCheckpoint(\"har_nn_bw.hdf\", save_best_only=True)","d3e84d43":"history = model.fit(\n    X_train, y_train, \n    validation_data=(X_val, y_val), epochs=10, batch_size=32, shuffle=True,\n    callbacks=[chck]\n)","9b011e88":"pd.DataFrame({\n    'loss': history.history['loss'],\n    'val_loss': history.history['val_loss']\n}).plot()","b00c01f8":"model.load_weights(\"har_nn_bw.hdf\")","b59552d7":"preds = model.predict(X_val)","fad8d663":"accuracy_score(np.argmax(y_val, axis=1), np.argmax(preds, axis=1))","f5011ba8":"test_y = pd.read_csv('..\/input\/con_sample.csv')\ntest_y['label'] = np.argmax(model.predict(test_x), axis=1)\n\ntest_y.to_csv('submission.csv', index=False)","c5708333":"**Human Activity Recognition Using Smartphones Dataset**\n\nThe experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n\nThe sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings\/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. \n","85511f99":"---","d6bd5418":"---","e04ed31a":"Predict","3a8887a3":"Classes is balanced","fab8a74f":"## GB model","eeeeb091":"----","d8ef74bd":"Score","6ce3150e":"  Predicting test data","6c238cb8":"## NN Model (ResNet)"}}