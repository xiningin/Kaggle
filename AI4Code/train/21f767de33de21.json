{"cell_type":{"426e462d":"code","49278476":"code","1f6dbae5":"code","22ffaa65":"code","ac62654f":"code","ef802a35":"code","07c17b28":"code","a3ce27dd":"code","3cb25de3":"code","7a172c3d":"code","fdb4c17c":"code","50e932ec":"code","5ee34023":"code","27aaf29e":"code","e4d62d95":"markdown","22b5d330":"markdown","f68502c8":"markdown","072753c4":"markdown","12a72a29":"markdown","8ad4feae":"markdown","b75b1bd7":"markdown","f77124d5":"markdown","2a1f523b":"markdown"},"source":{"426e462d":"# Importing all Libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport math\nimport statistics as stat\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier","49278476":"# Loading all datasets and defining directories\nfor dirname, _, filenames in os.walk('..\/input\/titanic'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain_data = pd.read_csv('..\/input\/c\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/c\/titanic\/test.csv')\n\n# Add missing column to properly join both datasets, also include parameter for Scikit-Learn models\ntest_data['Survived'] = np.NaN\ntrain_data['train_test'] = 1\ntest_data['train_test'] = 0\ntest_train_data = pd.concat([train_data, test_data])\n\n# The dataset's intrinsic features\ntrain_data.columns","1f6dbae5":"# Exploring Gender and death rate\nmen_death=train_data.loc[train_data.Sex=='male'][\"Survived\"]\nmen_death_rate=1 - sum(men_death)\/len(men_death)\nwomen_death=train_data.loc[train_data.Sex=='female'][\"Survived\"]\nwomen_death_rate=1 - sum(women_death)\/len(women_death)\n\nX = ['Man', 'Woman']\nY = [men_death_rate,women_death_rate]\nfig = plt.figure()\nax = fig.add_axes([0,0,1.1,1])\nax.bar(X,Y)\nplt.ylabel('Death rate')\nplt.xlabel('Gender')\n\nprint(\"Men death rate (%):\", men_death_rate)\nprint(\"Women death rate (%):\", women_death_rate)\nplt.show()","22ffaa65":"# Socioeconomic status and death rate\n# Their socioeconomic status should imply their priority on the ship (higher class people are usually taken care of)\n# Looking at percentage death by class [1,2,3] (1st class being the highest class)\nXarr = []\nYarr = []\n\nfor x in range(1,4):\n    classdeath = train_data.loc[train_data.Pclass==x][\"Survived\"]\n    classdeath_rate=1 - sum(classdeath)\/len(classdeath)\n    Xarr.append(x)\n    Yarr.append(classdeath_rate)\n    print(f'class {x} (%): {classdeath_rate}')\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nXarr = [int(x) for x in Xarr]\nax.bar(Xarr,Yarr)\nplt.ylabel('Death rate')\nplt.xlabel('Class (Decsending)')\nplt.show()","ac62654f":"# Good practice to split data labels into qualititative and quantitative varibles before processing distributions\ndf_quant = train_data[['Age','SibSp','Parch','Fare']]\ndf_qual = train_data[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]\n\n# Distributions for quantitative labels \nfor x in df_quant.columns:\n    plt.hist(df_quant[x])\n    plt.title(x)\n    plt.show()","ef802a35":"# Investigating null values and empty cells\ntrain_data.info()","07c17b28":"train_data.Age = train_data.Age.fillna(train_data.Age.median())\ntrain_data.dropna(subset=['Embarked'],inplace = True)\ntrain_data.dropna(subset=['Cabin'],inplace = True)","a3ce27dd":"# This feature is taken from (Author: Ken Jee, Source: Kaggle)[https:\/\/www.kaggle.com\/kenjee\/titanic-project-example]\ntrain_data['cabin_multiple'] = train_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\ntrain_data['cabin_multiple'].value_counts()","3cb25de3":"pd.pivot_table(train_data, index = 'Survived', columns = 'cabin_multiple', values = 'Ticket' ,aggfunc ='count')","7a172c3d":"train_data['name_title'] = train_data.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntrain_data['name_title'].value_counts()","fdb4c17c":"# Normalizing the test and training data to feed to the models\n# Applied log normal distribution to Fare because it follows a skewed normal distribution\ntest_train_data['name_title'] = test_train_data.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntest_train_data['cabin_multiple'] = test_train_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\ntest_train_data['norm_fare'] = np.log(test_train_data.Fare+1)\n\ntest_train_data.info()","50e932ec":"test_train_data.Pclass = test_train_data.Pclass.astype(str)\n\n#created dummy variables from categories (also can use OneHotEncoder)\nall_dummies = pd.get_dummies(test_train_data[['Pclass','Sex','Age','SibSp','Parch','norm_fare','Embarked','cabin_multiple','name_title','train_test']])\n\n#Split to train test again\nX_train = all_dummies[all_dummies.train_test == 1].drop(['train_test'], axis =1)\nX_train.Age = X_train.Age.fillna(X_train.Age.median())\nX_test = all_dummies[all_dummies.train_test == 0].drop(['train_test'], axis =1)\nX_test.norm_fare = X_test.norm_fare.fillna(X_test.norm_fare.median())\nX_test.Age = X_test.Age.fillna(X_test.Age.median())\n\ny_train =test_train_data[test_train_data.train_test==1].Survived\n\n\nX_test.info()","5ee34023":"print(\"Accuracy Score:\")\n\ngnb = GaussianNB()\ncv = cross_val_score(gnb,X_train,y_train,cv=6)\nprint(\"Naive Bayes:\", cv.mean())\n\nsvc = SVC(probability = True)\ncv = cross_val_score(svc,X_train,y_train,cv=6)\nprint(\"SVC:\", cv.mean())\n\nxgb = XGBClassifier(random_state =1,use_label_encoder=False,eval_metric='logloss')\ncv = cross_val_score(xgb,X_train,y_train,cv=5)\nprint(\"XGBC:\", cv.mean())\n\n\nknn = KNeighborsClassifier()\ncv = cross_val_score(knn,X_train,y_train,cv=5)\nprint(\"KNN:\", cv.mean())\n\nvoting_clf = VotingClassifier(estimators = [('knn',knn),('gnb',gnb),('svc',svc),('xgb',xgb)], voting = 'soft') \ncv = cross_val_score(voting_clf,X_train,y_train,cv=5)\nprint(\"Voting Classifier:\", cv.mean())","27aaf29e":"voting_clf.fit(X_train,y_train)\nvclf_fit = voting_clf.predict(X_test).astype(int)\nbasic_submission = {'PassengerId': test_data.PassengerId, 'Survived': vclf_fit}\nbase_submission = pd.DataFrame(data=basic_submission)\nbase_submission.to_csv('base_submission.csv', index=False)","e4d62d95":"## **Classifier Models**\n* Naive Bayes\n* Support Vector Classifier\n* XGBClassifier\n* K-Nearest Neighbors\n* Voting Classifier","22b5d330":"## **Data Wrangling**\n\nCleaning the data and organizing it for Preprocessing","f68502c8":"# Titanic Classification Project\n## Latest Submission Score: Top 24% (14218\/57176)\n### The full project code and resources can be found on [GitHub](https:\/\/github.com\/hassangaber\/KaggleTitanic).","072753c4":"## **Contents**\n\n1. [x] Understanding The Problem & Provided Datasets\n2. [x] Exploratory & Statistical Data Analysis: Histograms, Logistic Regression\n3. [x] Data Wrangling: Handling Null values, Feature Engineering, Building feature matrix (test_train_data)\n4. [x] Classifier Models\n5. [x] Voting Classifier\n6. [ ] Optimization","12a72a29":"Null values in Age and Embarked have been fixed, but due to the excess of null values in Cabin, some feature engineering can be done to further make use of the sparse data.\n\n### Feature Engineering\n\n* Cabin Multiple: How many cabins one person rented\n* Title: The prefix to their name (Mr., Mrs., ...)","8ad4feae":"## **The Problem and Provided Data\/Features**\n\nUsing datasets of passenger information on the Titanic (name, age, price of ticket, etc), predict who will die and who will survive the Titanic tragedy. This is a classification machine learning problem: outputs True if the passenger survives, False if the passenger dies.\n\nThe provided data includes three datasets: `test.csv`, `train.csv`, and `gender_submission.csv`. These can all be found in `~\/KaggleTitanic\/data`.\n\n#### `gender_submission.csv`\n\nContains two features, PassengerID and the Survived boolean. This is an example dataset showing how to structure the prediction of the model. This particular example output dataset shows all females survived while all males died.\n\n* `PassengerID` from `test.csv` indicating the Identity of a passenger\n* `Survived` is a boolean indicating `1` for survived and `0` for died\n\n#### `train.csv`\n\nThis is the dataset to used to train the model. It includes 11 different features (The dictionary is provided below). There are 891 out of 1309 passengers in this dataset. \n\n#### `test.csv`\n\nThis is the dataset to test our predictions based on our model trained using `train.csv`. It will show us the accuracy of our model. It includes the exact same features as `train.csv`.\n\nThe development of this project will be staged in a Jupyter notebook and move to python files in the final stages.\n\n","b75b1bd7":"## **Exploratory Data Analysis**","f77124d5":"### Features with Null Values\n* 105 values in `Age`\n* 687 values in `Cabin`\n* 2 values in `Embarked`","2a1f523b":"## **Output**"}}