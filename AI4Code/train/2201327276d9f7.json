{"cell_type":{"137c6d0d":"code","1a634879":"code","213aacd0":"code","a91d4300":"code","c69543c5":"code","1920c879":"code","3c925b6f":"markdown","1c5e827c":"markdown","aeb5c0c3":"markdown","b3ea9030":"markdown","d2adda5f":"markdown","416102c5":"markdown","952e63a9":"markdown","60a6a3c8":"markdown","5ab5bf15":"markdown"},"source":{"137c6d0d":"!pip install qiskit","1a634879":"import numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nimport qiskit\nfrom qiskit import BasicAer, Aer\nfrom qiskit.aqua import QuantumInstance\nfrom qiskit.aqua.algorithms import QSVM\nfrom qiskit.aqua.components.multiclass_extensions import one_against_rest, all_pairs\nfrom qiskit.aqua.components.feature_maps import SecondOrderExpansion\nfrom qiskit.aqua.input import ClassificationInput\nfrom qiskit.aqua import run_algorithm\n\nbackend = Aer.get_backend('qasm_simulator')\niris = load_iris()","213aacd0":"X, Y = iris.data, iris.target\nprint(X.shape)\nprint(len(set(Y)))\ntrain_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2)\nnum_features = 4\ntraining_size = 120\ntest_size = 30\nfeature_map = SecondOrderExpansion(feature_dimension=num_features, depth=3)\n# With feature_map, we have defined the function we will use the quantum property space we mentioned above.","a91d4300":"params = {\n            'problem': {'name': 'classification', 'random_seed': 794},\n            'algorithm': {\n                'name': 'QSVM',\n            },\n            'backend': {'shots': 1},\n            'multiclass_extension': {'name': 'OneAgainstRest'},\n            'feature_map': {'name': 'SecondOrderExpansion', 'depth': 3, 'entangler_map': [[1, 0]]}\n            #'feature_map': {'name': 'SecondOrderExpansion', 'depth': 3}\n        }\ntraining_dataset={'A':train_x[train_y==0],\n                'B':train_x[train_y==1],\n                'C':train_x[train_y==2]}\n\ntest_dataset={'A':test_x[test_y==0],\n                        'B':test_x[test_y==1],\n                        'C':test_x[test_y==2]}\n\ntotal_arr = np.concatenate((test_dataset['A'],test_dataset['B'],test_dataset['C']))\nalg_input = ClassificationInput(training_dataset, test_dataset, total_arr)","c69543c5":"result = run_algorithm(params, algo_input=alg_input, backend=backend)","1920c879":"result","3c925b6f":"We defined feature map above, but we did not need to define it here since we will give it as a parameter below. For the sake of example, both remain for now.","1c5e827c":"Since it takes too long to run the algorithm on IBM-Q, I run it on qasm_simulator. But nevertheless it will take time.","aeb5c0c3":"Our results are not very good. The fact that we haven't run a full QSVM technically in these results also has an impact. But you can see that it is possible to obtain more precise results by examining the article we gave above.\n\nWith the development of technology and hardware obstacles disappearing one by one in the next 10 years, we will be able to run more advanced algorithms in quantum computers with more precise results.","b3ea9030":"# Why did they need Q-SVM? Why are there such studies?\n\nWhy are quantum computers and algorithms used when there are classical machine learning algorithms? There are two answers to this question: the first is to make use of the quantum physics features such as quantum entanglement, the second is to use the computational power of quantum computers.\n\u00a0\nIn SVM algorithm, it is used to classify data by creating support points from close points of data. There are photographs of the feature spaces above and it can be understood that sometimes it may not be possible to classify the data using two or three dimensions. For this, it may be necessary to increase the size towards an n-dimensional space and to separate our data with the points representing this space. But as we work in multi-dimensional spaces, our computing power starts to be insufficient in classical computers.","d2adda5f":"### Let's print the results and see how we got the output","416102c5":"#### If the qiskit library is not installed, we need to install it with the command below.","952e63a9":"# Q-SVM (Quantum Support Vector Machine Algorithm)\n\nAlthough quantum computers and quantum programming are a very new field, they both arouse curiosity and stage experimental studies to understand what can be done. One of these experimental areas of study is the study of machine learning and testing of deep learning algorithms, even artificial intelligence, on quantum computers. However, even deep learning methods and artificial intelligence studies are at the beginning, while their application in quantum computers continues to be academic and theoretical studies rather than practical uses.\n\n\nAs far as I research, implementing the QSVM algorithm can be accomplished in 2 different ways. The first of these methods is to run the kernel function only on a quantum computer and to get the data from a conventional computer and conventional feature space by reducing it with conventional methods. The second is to do both the reduction of data in the property space and the labels of the data and the kernel function on quantum computers.\n\nTo understand the difference between these two methods, we first need to know how the classic version of SVM classifies the data. Assuming we know this, let's remember with an image that shows how data is separated from each other in the property space by increasing size: \n\n![alt text](https:\/\/www.researchgate.net\/profile\/Katarzyna_Matek\/publication\/235892711\/figure\/fig1\/AS:299920994127876@1448518145475\/Illustration-of-the-operation-of-the-SVM-algorithm-The-input-data-on-the-left-side.png)\n\nThe difference between the two methods mentioned above is that in the first one, our feature space is also calculated in quantum circuits. The quantum property space can also be shown in the figure below.\n\n\n![alt text](https:\/\/raw.githubusercontent.com\/RegaipKURT\/QuantumProgramming\/master\/qc.png)\n\n\nThe common point in both methods is that kernel function is obtained by quantum calculations rather than the traditional way. However, in order to increase the success rate, the labels of the data must be provided in the superposition state. In order to do this, the data must be read from a quantum circuit, but we do not have the opportunity to apply this method of data provision here. However, the results obtained in experimental studies show that 100% predictive success can be achieved with this method. (Of course, this was done by using a regular data that can achieve 100% success.)\n\nAlthough we are unable to provide the data from the quantum computer, a function is provided inside the qiskit library that allows the data to be separated from each other using the quantum property space. We will use this library named feature_map below.\n\nYou can examine the academic study from the link of the article about the work I mentioned here and you can also find other sources from the excerpts of the article. Other studies have been done on the subject. The article I linked below is also referenced in qiskit.aqua.\n\n---\n\nArticle of the Quantum-SVM algorithm:  https:\/\/arxiv.org\/pdf\/1804.11326.pdf","60a6a3c8":"## Import the Library\n\nFirst, we will use the qsvm algorithm in qiskit.aqua. But there is other libraries which have alternative to qsvm algorithms. The dataset we will use is iris dataset, which is one of the most frequently used datasets in machine learning studies.","5ab5bf15":"## Install the Dataset\n\nIris, which is the dataset we will use, consists of 3 separate classes as the target variable and 4 feature columns."}}