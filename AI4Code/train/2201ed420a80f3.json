{"cell_type":{"08961c3f":"code","a6e97603":"code","00acfb76":"code","776e7e9c":"code","4ed196ed":"code","33dfe113":"code","7132c291":"code","53c3a6d7":"code","0c70e193":"code","5043b3c2":"code","265880e8":"code","5cd0d091":"code","aa338c3a":"code","4293ae6c":"code","8f173001":"code","2347c777":"code","d8ea8804":"code","0e917571":"code","436d4099":"code","839ef31b":"code","15006418":"code","56c717ea":"code","911759aa":"code","8ced0f58":"code","6e6fc3f0":"code","d827761d":"code","a5776121":"code","ecd196c5":"code","7e3eb4ad":"code","7c7e4ec0":"code","c2364578":"code","55abc150":"code","91bc14c0":"code","83260b0b":"code","104add8a":"code","7c5874c7":"code","10223c5e":"code","3cf07983":"code","301d32ec":"code","6a19ed22":"code","1aad055b":"code","c53edd55":"code","2c75b1de":"code","225a462a":"code","08aabf0c":"code","bcd7282a":"markdown"},"source":{"08961c3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6e97603":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nimport folium\nimport geopandas as gpd\nplt.style.use(\"dark_background\")\n","00acfb76":"df = pd.read_csv(\"\/kaggle\/input\/indian-food-101\/indian_food.csv\")\ndf.head()","776e7e9c":"df.isnull().sum()","4ed196ed":"df.info()","33dfe113":"df = df.dropna()","7132c291":"df.describe()","53c3a6d7":"df['course'].unique()","0c70e193":"def plotmapfor(item):\n    itemdata = df[df['course']==item]\n    itemdf =itemdata.state.value_counts().reset_index()\n    itemdf.columns = ['state','count']\n\n    fp = \"..\/input\/india-states\/Igismap\/Indian_States.shp\"\n    map_df = gpd.read_file(fp)\n\n    merged = map_df.set_index('st_nm').join(itemdf.set_index('state'))\n\n    fig, ax = plt.subplots(1, figsize=(20, 12))\n    ax.axis('off')\n    ax.set_title(f'State Wise Distribution of indian {item}', fontdict={'fontsize': '16', 'fontweight' : '3'})\n    merged.plot(column='count', cmap='viridis', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)\n","5043b3c2":"plotmapfor(\"snack\")","265880e8":"plotmapfor(\"main course\")","5cd0d091":"plotmapfor(\"starter\")","aa338c3a":"plotmapfor(\"dessert\")","4293ae6c":"df['flavor_profile'].value_counts()","8f173001":"def plotmapfor(item):\n    itemdata = df[df['flavor_profile']==item]\n    itemdf =itemdata.state.value_counts().reset_index()\n    itemdf.columns = ['state','count']\n\n    fp = \"..\/input\/india-states\/Igismap\/Indian_States.shp\"\n    map_df = gpd.read_file(fp)\n\n    merged = map_df.set_index('st_nm').join(itemdf.set_index('state'))\n\n    fig, ax = plt.subplots(1, figsize=(20, 12))\n    ax.axis('off')\n    ax.set_title(f'State Wise Distribution of flavour profile = {item}', fontdict={'fontsize': '16', 'fontweight' : '3'})\n    merged.plot(column='count', cmap='viridis', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)","2347c777":"plotmapfor(\"spicy\")","d8ea8804":"plotmapfor(\"sweet\")","0e917571":"df.head()","436d4099":"df['diet'].unique()","839ef31b":"ax = df['diet'].value_counts().plot(kind='bar',\n                                      figsize=(10, 6),\n                                     color=[\"skyblue\", \"pink\"])\n\nax.set_xticklabels(['vegetarian', 'non vegetarian'],rotation=0,fontsize=12)\nax.set_ylabel('count', fontsize = 12)\nax.set_title(\"Distribution of data based on diet\",fontsize=18)\nplt.show()","15006418":"ax = df['course'].value_counts().plot(kind='bar',\n                                      figsize=(10, 6),\n                                     color=[\"royalblue\",\"orange\",\"seagreen\",\"maroon\"])\n\nax.set_xticklabels(['dessert', 'main course', 'starter', 'snack'],rotation=0,fontsize=12)\nax.set_ylabel('count', fontsize = 12)\nax.set_title(\"Distribution of data based on diet\",fontsize=18)\nplt.show()","56c717ea":"df['flavor_profile'].unique()","911759aa":"ax = df['flavor_profile'].value_counts().plot(kind='bar',\n                                      figsize=(10, 6),\n                                     color=[\"royalblue\",\"orange\",\"seagreen\",\"maroon\",\"pink\"])\n\nax.set_xticklabels(['sweet', 'spicy', 'bitter', 'NA', 'sour'],rotation=0,fontsize=12)\nax.set_ylabel('count', fontsize = 12)\nax.set_title(\"Distribution of data based on flavour profile\",fontsize=18)\nplt.show()","8ced0f58":"plt.figure(figsize=(14,8))\nsns.distplot(df['prep_time'],color='red')\nplt.title(\"Histogram for prep time\",fontsize=24)\nplt.show()","6e6fc3f0":"plt.figure(figsize=(14,8))\nsns.boxplot(df['prep_time'],color='red',orient='v')\nplt.title(\"boxplot for prep time\",fontsize=24)\nplt.show()","d827761d":"plt.figure(figsize=(14,8))\nsns.distplot(df['cook_time'],color='seagreen')\nplt.title(\"Histogram for cook time\",fontsize=24)\nplt.show()","a5776121":"plt.figure(figsize=(14,8))\nsns.boxplot(df['cook_time'],color='seagreen',orient='v')\nplt.title(\"boxplot for cook time\",fontsize=24)\nplt.show()","ecd196c5":"df['prep_time'].describe()","7e3eb4ad":"# as our data is skewed so we will compute the Interquantile range to calculate the boundaries \nIQR=df['cook_time'].quantile(0.75)-df['cook_time'].quantile(0.25)\nlower_bridge=df['cook_time'].quantile(0.25)-(IQR*1.5)\nupper_bridge=df['cook_time'].quantile(0.75)+(IQR*1.5)\nprint(lower_bridge), print(upper_bridge)","7c7e4ec0":"#### Extreme outliers\nlower_bridge=df['cook_time'].quantile(0.25)-(IQR*3)\nupper_bridge=df['cook_time'].quantile(0.75)+(IQR*3)\nprint(lower_bridge), print(upper_bridge)","c2364578":"data = df.copy()\ndata.loc[data['cook_time']>=100,'cook_time']=100","55abc150":"plt.figure(figsize=(14,8))\nsns.distplot(data['cook_time'],color='red')\nplt.title(\"Histogram for cook time after handling outliers\",fontsize=24)\nplt.show()","91bc14c0":"# Handling outliers for prep_time \n\n# as our data is skewed so we will compute the Interquantile range to calculate the boundaries \nIQR=df['prep_time'].quantile(0.75)-df['prep_time'].quantile(0.25)\nlower_bridge=df['prep_time'].quantile(0.25)-(IQR*1.5)\nupper_bridge=df['prep_time'].quantile(0.75)+(IQR*1.5)\nprint(lower_bridge), print(upper_bridge)\n\n#### Extreme outliers\nlower_bridge=df['prep_time'].quantile(0.25)-(IQR*3)\nupper_bridge=df['prep_time'].quantile(0.75)+(IQR*3)\nprint(lower_bridge), print(upper_bridge)\n\n","83260b0b":"data.loc[data['prep_time']>=50,'prep_time']=50","104add8a":"plt.figure(figsize=(14,8))\nsns.distplot(data['prep_time'],color='seagreen')\nplt.title(\"Histogram for prep time after handling outliers\",fontsize=24)\nplt.show()","7c5874c7":"data['totaltime'] = data['prep_time']+data['cook_time']\ndata.head()","10223c5e":"from wordcloud import WordCloud, STOPWORDS\n\ncomment_words = '' \nstopwords = set(STOPWORDS)\nfor val in data.name: \n    val = str(val) \n    tokens = val.split() \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower()       \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n                        \nplt.figure(figsize = (10,10), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title(\"Wordcloud for Dishes\",fontsize=24)  \nplt.show()","3cf07983":"from wordcloud import WordCloud, STOPWORDS\n\ncomment_words = '' \nstopwords = set(STOPWORDS)\nfor val in data.ingredients: \n    val = str(val) \n    tokens = val.split() \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower()       \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n                        \nplt.figure(figsize = (10,10), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title(\"Wordcloud for Ingredients\",fontsize=24) \nplt.show()","301d32ec":"data.head()","6a19ed22":"group = data.groupby(['course'])[['prep_time']].mean().reset_index()\nfig = px.pie(group,values='prep_time',names='course',title=\"average preparation time taken for items belonging to each course\")\nfig.update_traces(rotation=90, pull=0.02, textinfo=\"percent+label\")\nfig.show()","1aad055b":"group = data.groupby(['course'])[['cook_time']].mean().reset_index()\nfig = px.pie(group,values='cook_time',names='course',title=\"average cooking time taken for items belonging to each course\")\nfig.update_traces(rotation=90, pull=0.02, textinfo=\"percent+label\")\nfig.show()","c53edd55":"df = px.data.tips()\nfig = px.sunburst(data, path=['region','course','flavor_profile'], values='totaltime',color='region')\nfig.show()","2c75b1de":"df = px.data.tips()\nfig = px.sunburst(data, path=['region','course','diet'], values='totaltime',color='region')\nfig.show()","225a462a":"def groupbyplot(feature):\n    group = data.groupby(\"name\")[feature].mean().sort_values(ascending=False).reset_index().head(10)\n    fig = plt.figure(figsize=(16,8))\n    fig = px.bar(group, x='name',y=feature,color=feature,title=f\"Top 10 dishes based on {feature} taken\")\n    fig.show()","08aabf0c":"groupbyplot(\"totaltime\")","bcd7282a":"# we can see some outliers in cook time and prep time columns let's see those"}}