{"cell_type":{"7ddc37a9":"code","0ed8a45b":"code","1e5e0656":"code","9a78e3fe":"code","670e2b79":"code","9f9bb52b":"code","043823d3":"code","fded8275":"code","5ecd5fdd":"code","6c456ec7":"code","f5e18647":"code","6ba959e4":"code","e54f236c":"code","b6e1ea93":"code","07736c19":"code","7677d189":"code","720160c4":"code","75ce2d43":"code","69ad8441":"code","b6bd7bd1":"code","0425352d":"code","a1af5d83":"code","cb556c7e":"code","8cd3ab33":"code","52418895":"code","555fe03b":"code","90578575":"code","497d445d":"code","32f3d116":"code","12511ef7":"code","cec95172":"code","e151c9e8":"code","56246c07":"code","39c7ee39":"code","5e350236":"code","ec6577c7":"code","edb7fa46":"code","d4fdc364":"code","c4cffdc4":"code","75267a0d":"code","cd234d7d":"code","1d41abb4":"code","9b9df190":"code","0a1a2cab":"code","ce4866c6":"code","0b611712":"code","2221aaf1":"code","524d1576":"code","002a6653":"code","b861a7d9":"code","3cb4d412":"code","5140fef0":"code","ba97cece":"code","81ab2d36":"code","0793345c":"code","62b76ada":"code","3d824c5b":"code","3e1baeac":"code","f37a67c3":"code","12d96140":"code","053fc7fb":"code","00f06263":"code","2bc6e185":"code","6db0088c":"code","40ddaba5":"code","b1a60a4b":"code","d2b45d06":"code","e63c3c97":"code","68524f50":"code","1330955a":"code","33595a2c":"code","ba26141c":"code","803f29a3":"code","0b1bdfbe":"code","3215a1c9":"code","fb4de644":"code","91d81f78":"code","8ba280e0":"code","6f6267bb":"code","22623c20":"code","5385496d":"code","961ee749":"code","6c55c5d5":"code","b2cb308f":"code","3f93ddec":"code","6fd3e3db":"code","0101d447":"code","559d4c9a":"code","618a5230":"code","23be3ccf":"code","98cb53dc":"code","3efa6bdf":"code","7d5517d1":"code","ba7c1995":"code","11765a5a":"code","dc62d3db":"code","e02cf6cc":"code","a37480c3":"markdown","8c1814a0":"markdown","22342855":"markdown","18e3530c":"markdown","fdabf77b":"markdown","c2fb4495":"markdown","603841f1":"markdown","b94c7dd3":"markdown","452c55f2":"markdown","02a1a62e":"markdown","2923aa71":"markdown","75c54d2a":"markdown","16441a18":"markdown","be742dc4":"markdown","423b183b":"markdown","571d65ce":"markdown","dc557745":"markdown","5e9dc736":"markdown","e5e98aa7":"markdown","163bbbc7":"markdown","8822de02":"markdown","d395c3ba":"markdown","f70b2626":"markdown","689b48af":"markdown","1bb9f326":"markdown","4d4ae20d":"markdown","2c8381fb":"markdown","cd0ef5ac":"markdown","5ce193dc":"markdown","588f117f":"markdown","50485048":"markdown","a13818e5":"markdown","a4c89e22":"markdown","acfa0f36":"markdown","3dda4a1b":"markdown","0af445a2":"markdown","429bb0b7":"markdown","32a10808":"markdown"},"source":{"7ddc37a9":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport math, time, datetime\n# from math import sqrt\nimport numpy as np \nimport pandas as pd\nfrom scipy import stats\n\nfrom matplotlib import pyplot as plt\nimport missingno as msno\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate, cross_val_predict\nfrom sklearn.metrics import (confusion_matrix, mean_squared_error, r2_score, classification_report,\n            roc_auc_score, roc_curve, precision_recall_curve, auc, log_loss, accuracy_score, f1_score)\nfrom sklearn.feature_selection import (mutual_info_classif, SelectKBest, chi2, RFE, RFECV)\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier","0ed8a45b":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ngender_submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\n\ny = train['Survived']\ntrain = train.drop('Survived', axis=1)\ntrain.tail()","1e5e0656":"test.head()","9a78e3fe":"fig, ax = plt.subplots(figsize = (12, 2))\nax.barh(y.unique(), y.value_counts(), align='center', color=['red', 'green'])\nax.text(530, 0, y.value_counts()[0], ha='center', va='center', color='w', size=20)\nax.text(320, 1, y.value_counts()[1], ha='center', va='center', color='w', size=20)\nax.set_yticks(y.unique())\nax.set_yticklabels(y.unique())\nax.invert_yaxis()\nax.set_ylabel('Survived')\nax.set_title('How many people survived?')\n\nplt.show()","670e2b79":"# Combine train and test set for easy preprocessing\n# REFERENCE: https:\/\/www.kaggle.com\/abderrahimalakouche\/first-kernel-on-kaggle-top-17\ndf = pd.concat([train, test]).reset_index(drop=True)\ndf.shape","9f9bb52b":"## plot graphic of missing values\nmsno.matrix(df, figsize=(12, 6))","043823d3":"# drop unnecessary columns, which won't be used in analysis and prediction\ndf = df.drop(['Ticket', 'Cabin'], axis=1)","fded8275":"for col in df[df.notnull()]:\n    unique_vals = df[col].value_counts()\n    nr_values = len(unique_vals)\n    if nr_values < 10:\n        print(f'The number of values for feature {col} :{nr_values} -- {df[col].unique()}')\n    else:\n        print(f'The number of values for feature {col} :{nr_values}')","5ecd5fdd":"df.isnull().sum()","6c456ec7":"import re\ntitle = []\nfor i in df['Name']:\n#     print(re.search('([A-Z][a-z]+)\\.',i))\n    title.append(re.search('([A-Z][a-z]+)\\.',i)[1])\ndf[\"Title\"] = title\ndf.head()","f5e18647":"title_list = df['Title'].value_counts()\n\nmale_list = []\nfemale_list = []\nfemale_male_list = []\nfor ind in title_list.index:\n    if not ind in ['Mr', 'Miss', 'Mrs']:\n        title_uni = df[df['Title'] == ind]['Sex'].unique()\n        if len(title_uni) == 1:\n            if title_uni[0] == 'male':\n                male_list.append(ind)\n            else:\n                female_list.append(ind)\n        else:\n            female_male_list.append(ind)\nprint(male_list)\nprint(female_list)\nprint(female_male_list)\ntitle_list","6ba959e4":"for male in male_list:\n    df['Title']=df['Title'].replace([male],'Mr')","e54f236c":"df['Title'].value_counts()","b6e1ea93":"filt = ((df['Title'] == 'Ms') | (df['Title'] == 'Mlle') | (df['Title'] == 'Lady') | \n        (df['Title'] == 'Dona') | (df['Title'] == 'Mme') | (df['Title'] == 'Countess'))\n\ndf[filt][['Title', 'Age']]","07736c19":"df['Title']=df['Title'].replace(['Mme', 'Ms', 'Mlle'],'Miss')\ndf['Title']=df['Title'].replace(['Lady', 'Countess', 'Dona'],'Mrs')\n\ndf['Title'].value_counts()","7677d189":"filt = (df['Title'] == 'Dr')\ndf[filt][['Title', 'Sex', 'Age']]","720160c4":"df.loc[796, 'Title'] = 'Mrs'\ndf['Title']=df['Title'].replace(['Dr'],'Mr')","75ce2d43":"fig, ax = plt.subplots(figsize = (12, 2))\nax.barh(df['Title'].value_counts().index, df['Title'].value_counts().values, align='center')\nax.set_ylabel('Title')\nplt.show()","69ad8441":"Title_col_names = []\none_hot_encoded_Title = pd.get_dummies(df['Title'])\nfor i in one_hot_encoded_Title.columns:\n    Title_col_names.append(f'Title_{i}')\none_hot_encoded_Title.columns = Title_col_names\none_hot_encoded_Title.head()","b6bd7bd1":"fig, ax = plt.subplots(figsize = (12, 2))\nax.barh(df['Pclass'].value_counts().index, df['Pclass'].value_counts().values, align='center')\nax.set_ylabel('Pclass')\nplt.show()","0425352d":"Pclass_col_names = []\none_hot_encoded_Pclass = pd.get_dummies(df['Pclass'])\nfor i in one_hot_encoded_Pclass.columns:\n    Pclass_col_names.append(f'Pclass_{i}')\none_hot_encoded_Pclass.columns = Pclass_col_names\none_hot_encoded_Pclass.head()","a1af5d83":"fig, ax = plt.subplots(figsize = (12, 2))\nax.barh(df['Sex'].value_counts().index, df['Sex'].value_counts().values, align='center')\nax.set_ylabel('Sex')\nplt.show()","cb556c7e":"Sex_col_names = []\none_hot_encoded_Sex = pd.get_dummies(df['Sex'])\nfor i in one_hot_encoded_Sex.columns:\n    Sex_col_names.append(f'Sex_{i}')\none_hot_encoded_Sex.columns = Sex_col_names\none_hot_encoded_Sex.head()","8cd3ab33":"df = pd.concat([df, one_hot_encoded_Title, one_hot_encoded_Pclass, one_hot_encoded_Sex], axis = 1)\ndf.drop(['Title', 'Pclass', 'Sex', 'Name'], axis=1, inplace=True)\ndf.head()","52418895":"# the Pclass of the Fare missing value is Pclass_3\ndf[df['Fare'].isnull()]","555fe03b":"# the mean of Fare for the Pclass 3\ndf_Pclass_mean = df[df['Pclass_3'] == 1]['Fare'].mean()\n\n# fill NaN value in Fare column with mean\ndf.loc[1043, 'Fare'] = df_Pclass_mean\n\ndf.isnull().sum()","90578575":"df[\"Age\"].fillna(df[\"Age\"].mean(),inplace=True)","497d445d":"df.isnull().sum()","32f3d116":"# getting the Pclass of the Embarked missing value\nPclass_embarked_mis = df[df['Embarked'].isnull()]['Pclass_1'].values\nprint(Pclass_embarked_mis)\nprint(\"----------------------------\")\n# distribution in Embarked by their Pclass\nprint(df[df['Pclass_1'] == 1]['Embarked'].value_counts())\n\n# for Pclass = 1, the most occurring values are S and C. \n# Therefore, one is filled as 'S', and the other as 'C'. \ndf.loc[61, 'Embarked'] = 'S'\ndf.loc[829, 'Embarked'] = 'C'\n\ndf.isnull().sum()","12511ef7":"Embarked_col_names = []\none_hot_encoded_Embarked = pd.get_dummies(df['Embarked'])\nfor i in one_hot_encoded_Embarked.columns:\n    Embarked_col_names.append(f'Embarked_{i}')\none_hot_encoded_Embarked.columns = Embarked_col_names\none_hot_encoded_Embarked.head()","cec95172":"df = pd.concat([df, one_hot_encoded_Embarked], axis = 1)\ndf.drop(['Embarked'], axis=1, inplace=True)\ndf.head()","e151c9e8":"def create_heatmap(hm, figsize=(10, 6)):\n    fig, ax = plt.subplots(figsize=figsize)\n\n    im = ax.imshow(hm, \n    #                vmin=0, vmax=10, \n                   cmap='viridis', aspect='auto')\n\n    # Create colorbar\n    cbar = ax.figure.colorbar(im, ax=ax)\n\n    # We want to show all ticks...\n    ax.set_xticks(np.arange(len(hm.columns)))\n    ax.set_yticks(np.arange(len(hm.columns)))\n    # ... and label them with the respective list entries\n    ax.set_xticklabels(hm.columns)\n    ax.set_yticklabels(hm.columns)\n\n    # Turn spines off and create white grid.\n    ax.spines[:].set_visible(False)\n    ax.set_xticks(np.arange(hm.shape[1]+1)-.5, minor=True)\n    ax.set_yticks(np.arange(hm.shape[0]+1)-.5, minor=True)\n    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n    ax.tick_params(which=\"minor\", bottom=False, left=False)\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    for i in range(len(hm.columns)):\n        for j in range(len(hm.columns)):\n            hm_val = round(hm.values[i, j], 2)\n            if hm_val > 0.85:\n                text = ax.text(j, i, hm_val,\n                               ha=\"center\", va=\"center\", color=\"black\", size=16)\n            else:\n                text = ax.text(j, i, hm_val,\n                               ha=\"center\", va=\"center\", color=\"w\", size=16)\n\n    fig.tight_layout()\n    plt.show()","56246c07":"hm_X_train = df.corr()\ncreate_heatmap(hm_X_train, figsize=(12, 8))","39c7ee39":"#  to select highly correlated features\ndef correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold:\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr","5e350236":"corr_features = correlation(df, 0.85)\ncorr_features","ec6577c7":"df = df.drop(corr_features, axis=1)","edb7fa46":"df.head()","d4fdc364":"df = df.sort_values(by='PassengerId')\nX = df[df['PassengerId'] < 892]\nX = X.drop('PassengerId', axis=1)\n\nX_kaggle = df[df['PassengerId'] >= 892]\nX_kaggle = X_kaggle.drop('PassengerId', axis=1)\n\nprint(X.shape)\nprint(X_kaggle.shape)","c4cffdc4":"def box_plot(df, label):\n    fig, ax = plt.subplots(figsize = (10, 1))\n    # rectangular box plot\n    bplot = ax.boxplot(df,\n                           vert=False,  # vertical box alignment\n                           notch=True,  # notch shape\n                           patch_artist=True,  # fill with color\n                           labels=[label]  # will be used to label x-ticks\n                          )\n    # fill with colors\n    colors = ['pink', 'lightblue', 'lightgreen']\n    for box in (bplot):\n        for patch, color in zip(bplot['boxes'], colors):\n            patch.set_facecolor(color)\n\n\n    whiskers_1 = bplot['whiskers'][0].get_xdata()[1]\n    whiskers_2 = bplot['whiskers'][0].get_xdata()[0]\n    median = bplot['medians'][0].get_xdata()[0]\n    whiskers_3 = bplot['whiskers'][1].get_xdata()[0]\n    whiskers_4 = bplot['whiskers'][1].get_xdata()[1]\n    \n    ax.text(whiskers_1, 1.15, f\"{whiskers_1}\", ha='center', va='center', color='b', size=13)\n    ax.text(whiskers_2, 1.25, f\"{whiskers_2}\", ha='center', va='center', color='b', size=13)\n    ax.text(median, 0.7, f\"{median}\", ha='center', va='center', color='b', size=13)\n    ax.text(whiskers_3, 1.25, f\"{whiskers_3}\", ha='center', va='center', color='b', size=13)\n    ax.text(whiskers_4, 1.15, f\"{whiskers_4}\", ha='center', va='center', color='b', size=13)\n\n\n    ax.xaxis.grid(True)\n    plt.show()\n\n    outliers = bplot['fliers'][0].get_xdata()\n#     print(sorted(outliers))","75267a0d":"box_plot(X['Age'], 'Age')","cd234d7d":"outliers_index_age = X[X['Age'] > 71].index\nprint(outliers_index_age)\nX1 = X.drop(outliers_index_age, axis=0)","1d41abb4":"box_plot(X1['Fare'], 'Fare')","9b9df190":"outliers_index_fare = X1[X1['Fare'] > 500].index\nprint(outliers_index_fare)\nX2 = X1.drop(outliers_index_fare, axis=0)","0a1a2cab":"box_plot(X2['SibSp'], 'SibSp')","ce4866c6":"outliers_index_sibSp = X2[X2['SibSp'] > 5].index\nprint(outliers_index_sibSp)\nX3 = X2.drop(outliers_index_sibSp, axis=0)","0b611712":"box_plot(X3['Parch'], 'Parch')","2221aaf1":"outliers_index_parch = X3[X3['Parch'] > 5].index\nprint(outliers_index_parch)\nX4 = X3.drop(outliers_index_parch, axis=0)","524d1576":"outlier_list = (list(outliers_index_age) + list(outliers_index_fare) + \n                list(outliers_index_sibSp) + list(outliers_index_parch))\noutlier_list","002a6653":"import itertools\nfrom sklearn.linear_model import LogisticRegression\nindex_dropped = []\ntrain_scores = []\ntest_scores = []\nfor L in range(0, len(outlier_list)+1):\n    for subset in itertools.combinations(outlier_list, L):\n        ind = list(subset)\n        if len(ind) > 6:\n            df1=df.drop(ind)\n            y1=y.drop(ind)\n            df1[\"Age\"]=np.log(df1[\"Age\"])\n            X = df1[df1['PassengerId'] < 892]\n            X = X.drop('PassengerId', axis=1)\n            X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.25, random_state=0)\n            lr=LogisticRegression(random_state=40)\n            lr.fit(X_train, y_train)\n            train_scores.append(lr.score(X_train,y_train))\n            test_scores.append(lr.score(X_test,y_test))\n            index_dropped.append(ind)","b861a7d9":"df_ind_acc = pd.DataFrame({'index':index_dropped, 'train_scores':train_scores, 'test_scores':test_scores})\ndf_ind_acc = df_ind_acc.sort_values(by=['train_scores', 'test_scores'], ascending=False).reset_index(drop=True)\ndf_ind_acc.head()","3cb4d412":"df_ind_acc[(df_ind_acc['train_scores'] > 0.83) & (df_ind_acc['test_scores'] > 0.819)]","5140fef0":"#now we gpoing to remove outliers\nind_dropped = [851, 679, 737, 159, 324, 792, 846, 863]\ndf1=df.drop(ind_dropped)\ny1=y.drop(ind_dropped)","ba97cece":"X = df1[df1['PassengerId'] < 892]\nX = X.drop('PassengerId', axis=1)\n\nX_kaggle = df1[df1['PassengerId'] >= 892]\nX_kaggle = X_kaggle.drop('PassengerId', axis=1)\n\nprint(X.shape)\nprint(y1.shape)","81ab2d36":"X[\"Age\"]=np.log(X[\"Age\"])","0793345c":"from sklearn.linear_model import LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.25, random_state=0)","62b76ada":"#hyperparameter tuning of logistic regression\nfrom sklearn.model_selection import GridSearchCV\nparam = {\n         'penalty':['l1','l2'],\n         'C':[0.001, 0.01, 0.1, 1, 10, 20,100, 1000]\n}\ncv=GridSearchCV(LogisticRegression(),param,cv=5,n_jobs=-1)\ncv.fit(X_train,y_train)\n\nprint(cv.score(X_train,y_train))\nprint(cv.score(X_test,y_test))\n\n# cv.predict(x_test)","3d824c5b":"# best_parameters\nprint(\"Best CV params\", cv.best_params_)  ","3e1baeac":"# best_score\nprint(\"Best CV score\", cv.best_score_)","f37a67c3":"# best_estimators\nbest_lr = cv.best_estimator_\nbest_lr","12d96140":"### It will zero variance features\nfrom sklearn.feature_selection import VarianceThreshold\nvar_thres=VarianceThreshold(threshold=0)\nvar_thres.fit(df)\ndf.columns[var_thres.get_support()]","053fc7fb":"constant_columns = [column for column in df.columns\n                    if column not in df.columns[var_thres.get_support()]]\n\nprint(len(constant_columns))","00f06263":"# determine the mutual information\nmutual_info = mutual_info_classif(X_train, y_train)\nmutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info.sort_values(ascending=False)","2bc6e185":"# select the  top k important features\nKBest_mutual = SelectKBest(mutual_info_classif, k=8)\nKBest_mutual.fit(X_train, y_train)\nKBest_cols = X_train.columns[KBest_mutual.get_support()]\nprint(KBest_cols)\n\nKBest_df = pd.DataFrame({'Feature':list(X_train.columns),\n                                     'Scores':KBest_mutual.scores_})\nKBest_df.sort_values(by='Scores', ascending=False).reset_index(drop=True)","6db0088c":"# KBest_chi2 = SelectKBest(chi2, k=8).fit(X_train, y_train)\n# KBest_chi2_cols = X_train.columns[KBest_chi2.get_support()]\n# print(KBest_chi2_cols)\n\n# KBest_chi2_df = pd.DataFrame({'Feature':list(X_train.columns), 'Scores':KBest_chi2.scores_})\n# KBest_chi2_df = KBest_chi2_df.sort_values(by='Scores', ascending=False).reset_index(drop=True)\n# KBest_chi2_df","40ddaba5":"# GBC_reg = GradientBoostingClassifier()\nrf = RandomForestClassifier(n_estimators=100, random_state=0, criterion = 'entropy')\n\nrfe = RFE(estimator=RandomForestClassifier(), step=1, n_features_to_select=10)\nrfe = rfe.fit(X_train, y_train)\nrfe_cols = X_train.columns[rfe.get_support()]\nprint(rfe_cols)\n\nrfe_df = pd.DataFrame({'Feature':list(X_train.columns), 'Scores':rfe.ranking_})\nrfe_df = rfe_df.sort_values(by='Scores', ascending=True).reset_index(drop=True)\nrfe_df","b1a60a4b":"rfecv = RFECV(estimator=LogisticRegression(C=20), step=1, cv=10, scoring='accuracy')\nrfecv = rfecv.fit(X_train.values, y_train)\nrfecv_cols = X_train.columns[rfecv.get_support()]\nprint(rfecv_cols)\n\nprint(\"Optimal number of features: %d\" % rfecv.n_features_)\nprint('Selected features: %s' % list(X_train.columns[rfecv.support_]))\n\n# Plot number of features VS. cross-validation scores\nplt.figure(figsize=(10,6))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","d2b45d06":"new_cols = ['Age', 'SibSp', 'Parch', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Pclass_1', 'Pclass_3', \n            'Embarked_Q', 'Embarked_S']","e63c3c97":"import itertools\n\ndef feature_selection(model, cols):\n    best_cols = []\n    best_acc = []\n    best_mse = []\n    best_r2 = []\n    \n    stuff = cols\n    for L in range(0, len(cols)+1):\n        for subset in itertools.combinations(stuff, L):\n            cols = list(subset)\n            if len(cols) > 10:\n                # Cross Validation \n                y_pred_test = cross_val_predict(model, X_test[cols], y_test, cv=5, n_jobs = -1)\n                # Cross-validation accuracy metric\n                acc_cv = round(accuracy_score(y_test, y_pred_test) * 100, 2)\n                best_acc.append(acc_cv)\n                best_cols.append(cols)\n\n    best_zip = zip(best_cols, best_acc)\n    df_best_acc = pd.DataFrame(best_zip, columns=['columns', 'accuracy'])\n    df_best_acc = df_best_acc.sort_values('accuracy', ascending = False).reset_index(drop=True)\n    pd.set_option('max_colwidth', -1)\n\n    return df_best_acc","68524f50":"from sklearn.linear_model import LogisticRegression\n\n#hyperparameter tuning of logistic regression\nfrom sklearn.model_selection import GridSearchCV\nparam = {\n         'penalty':['l1','l2'],\n         'C':[0.001, 0.01, 0.1, 1, 10, 20,100, 1000]\n}\ncv_lg=GridSearchCV(LogisticRegression(),param,cv=5,n_jobs=-1)\ncv_lg.fit(X_train,y_train)\n\nlg_train_score = cv_lg.score(X_train, y_train)\nlg_test_score = cv_lg.score(X_test, y_test)\nprint(\"Test accuracy of best grid search hypers:\", lg_train_score)\nprint(\"Test accuracy of best grid search hypers:\", lg_test_score)","1330955a":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(max_depth=10,min_samples_split=9)\nrf.fit(X_train,y_train)\n\nrf_train_score = rf.score(X_train, y_train)\nrf_test_score = rf.score(X_test, y_test)\nprint(\"Test accuracy of best grid search hypers:\", rf_train_score)\nprint(\"Test accuracy of best grid search hypers:\", rf_test_score)","33595a2c":"from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB","ba26141c":"bNB = BernoulliNB()\nbNB.fit(X_train, y_train)\n\nbNB_train_score = bNB.score(X_train, y_train)\nbNB_test_score = bNB.score(X_test, y_test)\nprint(\"Test accuracy of best grid search hypers:\", bNB_train_score)\nprint(\"Test accuracy of best grid search hypers:\", bNB_test_score)","803f29a3":"# mNB = MultinomialNB()\n# # df_bNB = feature_selection(bNB, X_train.columns)\n# # df_bNB.head()\n\n# mNB.fit(X_train, y_train)\n# print(\"Test accuracy of best grid search hypers:\", mNB.score(X_train, y_train))\n# print(\"Test accuracy of best grid search hypers:\", mNB.score(X_test, y_test))","0b1bdfbe":"gNB = GaussianNB()\ngNB.fit(X_train, y_train)\n\ngNB_train_score = gNB.score(X_train, y_train)\ngNB_test_score = gNB.score(X_test, y_test)\nprint(\"Test accuracy of best grid search hypers:\", gNB_train_score)\nprint(\"Test accuracy of best grid search hypers:\", gNB_test_score)","3215a1c9":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='rbf',C=0.5, gamma=0.1, random_state=42, probability=True)\nsvm.fit(X_train, y_train)\n\nsvm_train_score = svm.score(X_train, y_train)\nsvm_test_score = svm.score(X_test, y_test)\nprint(\"Test accuracy of best grid search hypers:\", svm_train_score)\nprint(\"Test accuracy of best grid search hypers:\", svm_test_score)","fb4de644":"from sklearn.neighbors import KNeighborsClassifier\n\nacc_list = []\nfor k in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn_mean = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy').mean()\n    acc_list.append(knn_mean)\n    \nplt.figure(figsize=(8,4))\nplt.plot(range(1,40),acc_list,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Accuracy vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Accuracy')\nplt.show()","91d81f78":"k_max_list = [i for i in acc_list if i >= 0.76]\nk_max_list","8ba280e0":"k_max = acc_list.index(0.7688828584350973)\nprint(k_max)","6f6267bb":"knn = KNeighborsClassifier(n_neighbors=k_max)\nknn.fit(X_train, y_train)\n\nknn_train_score = knn.score(X_train, y_train)\nknn_test_score = knn.score(X_test, y_test)\nprint(\"Test accuracy of best grid search hypers:\", knn_train_score)\nprint(\"Test accuracy of best grid search hypers:\", knn_test_score)","22623c20":"from sklearn.linear_model import SGDClassifier\nsgdc = SGDClassifier()\n\n# df_sgdc = feature_selection(sgdc, X_train.columns)\n# df_sgdc.head()\n\nparameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n             'loss':['hinge','log'], 'penalty':['l1','l2']}\ncv_sgdc = GridSearchCV(sgdc, parameters, cv=10)\ncv_sgdc.fit(X_train, y_train)\n\nsgdc_train_score = cv_sgdc.score(X_train, y_train)\nsgdc_test_score = cv_sgdc.score(X_test, y_test)\nprint(\"Test accuracy of best grid search hypers:\", sgdc_train_score)\nprint(\"Test accuracy of best grid search hypers:\", sgdc_test_score)","5385496d":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\n\ngbc_train_score = gbc.score(X_train, y_train)\ngbc_test_score = gbc.score(X_test, y_test)\nprint(\"Test accuracy of best grid search hypers:\", gbc_train_score)\nprint(\"Test accuracy of best grid search hypers:\", gbc_test_score)","961ee749":"df_models_acc = pd.DataFrame({\n    'Model': ['lg', 'rf', 'gNB', 'svm', 'knn', 'sgdc', 'gbc'],\n    'Accuracy_Train': [lg_train_score, rf_train_score, gNB_train_score, svm_train_score, \n                       knn_train_score, sgdc_train_score, gbc_train_score],\n    'Accuracy_Test': [lg_test_score, rf_test_score, gNB_test_score, svm_test_score, \n                      knn_test_score, sgdc_test_score, gbc_test_score],\n})\ndf_models_acc.sort_values(by='Accuracy_Test', ascending=False)","6c55c5d5":"df_lg = feature_selection(cv_lg, X_train.columns)\ndf_lg.head()","b2cb308f":"cols_final = ['Age', 'SibSp', 'Parch', 'Fare', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n       'Pclass_1', 'Pclass_3', 'Embarked_S', 'Embarked_C']\n\n# cols_final = X_train.columns\nX_train_final = X_train[cols_final]\nX_test_final = X_test[cols_final]\nX_kaggle_final = X_kaggle[cols_final]\nmodel = GridSearchCV(LogisticRegression(),param,cv=5,n_jobs=-1)\n\nmodel.fit(X_train_final, y_train)\ny_pred_train = model.predict(X_train_final)\ny_pred_test = model.predict(X_test_final)\n\npred_proba_train = model.predict_proba(X_train_final)\npred_proba_test = model.predict_proba(X_test_final)\n\nprint('='*7)\nprint('TRAIN')\nprint('='*7)\nprint('')\n\ncm = confusion_matrix(y_train, y_pred_train).T\nTP, FP, FN, TN = cm.ravel()\n# Sensitivity, hit rate, recall, or true positive rate\nTPR = TP \/ (TP + FN)\nprint('The True Positive Rate is: {:.2%}'.format(TPR))\n# Specificity, selectivity or true negative rate (TNR)\nTNR = TN \/ (TN + FP)\nprint('The True Negative Rate is: {:.2%}'.format(TNR))\nprint('='*10)\n\nprint('='*7)\nprint('TEST')\nprint('='*7)\nprint('')\ncm = confusion_matrix(y_test, y_pred_test).T\nTP, FP, FN, TN = cm.ravel()\n# Sensitivity, hit rate, recall, or true positive rate\nTPR = TP \/ (TP + FN)\nprint('The True Positive Rate is: {:.2%}'.format(TPR))\n# Specificity, selectivity or true negative rate (TNR)\nTNR = TN \/ (TN + FP)\nprint('The True Negative Rate is: {:.2%}'.format(TNR))\nprint('='*10)","3f93ddec":"def confusion_matrix_func(cm, cm_title):\n    fig, ax = plt.subplots(figsize=(4, 4))\n\n    # Plot the heatmap\n    im = ax.imshow(cm, interpolation='nearest', cmap='Reds', aspect='auto')\n\n    # We want to show all ticks...\n    ax.set_xticks(np.arange(len(cm.tolist())))\n    ax.set_yticks(np.arange(len(cm.tolist())))\n\n\n    thresh = cm.max() \/ 1.5\n    # Loop over data dimensions and create text annotations.\n    for i in range(len(cm.tolist())):\n        for j in range(len(cm.tolist())):\n            text = ax.text(j, i, cm.tolist()[i][j],\n                           ha=\"center\", va=\"center\", size=16,\n                           color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    # Let the horizontal axes labeling appear on top.\n    ax.xaxis.set_ticks_position('top')\n    ax.xaxis.set_label_position('top')\n\n    plt.xlabel('Actual value', size=16)\n    plt.ylabel('Predicted value', size=16)\n    plt.title(cm_title, size=20, x=0.2, y=1.2)\n    plt.show()","6fd3e3db":"def Confusion_matrix_metrics(TP, FP, FN, TN):\n    # Sensitivity, hit rate, recall, or true positive rate\n    TPR = TP \/ (TP + FN)\n    print('The True Positive Rate is: {:.2%}'.format(TPR))\n    # Specificity, selectivity or true negative rate (TNR)\n    TNR = TN \/ (TN + FP)\n    print('The True Negative Rate is: {:.2%}'.format(TNR))\n    print('='*10)\n\n    # accuracy (ACC)\n    ACC = (TP + TN) \/ (TP + TN + FP + FN)\n    print('The Accuracy is: {:.2%}'.format(ACC))\n    # balanced accuracy (BA)\n    BA = (TPR + TNR) \/ 2\n    print('The Balanced Accuracy is: {:.2%}'.format(BA))\n    print('='*10)\n\n    # Precision or positive predictive value\n    PPV = TP \/ (TP + FP)\n    print('The Precision is: {:.2%}'.format(PPV))\n    # negative predictive value (NPV)\n    NPV = TN \/ (TN + FN)\n    print('The Negative Predictive Value is: {:.2%}'.format(NPV))\n    # false discovery rate (FDR)\n    FDR = 1 - PPV\n    print('The False Discovery Rate is: {:.2%}'.format(FDR))\n    # false omission rate (FOR)\n    FOR = 1 - NPV\n    print('The False Omission Rate is: {:.2%}'.format(FOR))\n    print('='*10)\n\n    # prevalence threshold (PT)\n    PT = (math.sqrt(TPR*(1 - TNR)) + TNR - 1)\/(TPR + TNR - 1)\n    print('The Prevalence Threshold is: {:.2}'.format(PT))\n    # F1 score\n    F1 = 2*TP \/ (2*TP + FP + FN)\n    print('The F1 Score is: {:.2}'.format(F1))\n    # Matthews correlation coefficient (MCC) or phi coefficient\n    MCC = ((TP*TN) - (FP*FN)) \/ math.sqrt((TP + FP)*(TP + FN)*(TN + FP)*(TN + FN))\n    print('The Matthews Correlation Coefficient is: {:.2}'.format(MCC))\n    print('='*10)\n\n    # False positive rate or False alarm rate\n    FPR = FP \/ (FP + TN)\n    print('The False positive rate is: {:.2}'.format(FPR))\n    # False negative rate or Miss Rate\n    FNR = FN \/ (FN + TP)\n    print('The False Negative Rate is: {:.2%}'.format(FNR))","0101d447":"cm = confusion_matrix(y_train, y_pred_train).T\nconfusion_matrix_func(cm, cm_title=\"Confusion Matrix_Train\")","559d4c9a":"# Calculating False Positives (FP), False Negatives (FN), True Positives (TP) & True Negatives (TN)\nTP, FP, FN, TN = cm.ravel()\nConfusion_matrix_metrics(TP, FP, FN, TN)","618a5230":"cm_test = confusion_matrix(y_test, y_pred_test).T\nconfusion_matrix_func(cm_test, cm_title=\"Confusion Matrix_Test\")","23be3ccf":"# Calculating False Positives (FP), False Negatives (FN), True Positives (TP) & True Negatives (TN)\nTP, FP, FN, TN = cm_test.ravel()\nConfusion_matrix_metrics(TP, FP, FN, TN)","98cb53dc":"# TRAIN\n# calculate scores\nlr_auc = roc_auc_score(y_train, pred_proba_train[:, 1])\n# summarize scores\n# print('Logistic: ROC AUC=%.3f' % (lr_auc))\n# calculate roc curves\nlr_fpr, lr_tpr, thresholds = roc_curve(y_train, pred_proba_train[:, 1])\n\n# Evaluating model performance at various thresholds\ndf_roc = pd.DataFrame({\n    'False Positive Rate': lr_fpr,\n    'True Positive Rate': lr_tpr\n}, index=thresholds)\ndf_roc.index.name = \"Thresholds\"\ndf_roc.columns.name = \"Rate\"\n\n\n# TEST\n# calculate scores\nlr_auc_test = roc_auc_score(y_test, pred_proba_test[:, 1])\n# summarize scores\n# print('Logistic: ROC AUC=%.3f' % (lr_auc_test))\n# calculate roc curves\nlr_fpr_test, lr_tpr_test, thresholds_test = roc_curve(y_test, pred_proba_test[:, 1])\n\n# Evaluating model performance at various thresholds\ndf_roc_test = pd.DataFrame({\n    'False Positive Rate': lr_fpr_test,\n    'True Positive Rate': lr_tpr_test\n}, index=thresholds_test)\ndf_roc_test.index.name = \"Thresholds\"\ndf_roc_test.columns.name = \"Rate\"\n\n\n# GRAPH\n# Set up the matplotlib figure\nfig, axes = plt.subplots(2, 2, figsize=(14, 8))\n\n# row=0, col=0\naxes[0, 0].plot(df_roc.iloc[:,0], df_roc.iloc[:,1], color='red', linewidth=2, \n                label=f'AUC={lr_auc:.2f}')\naxes[0, 0].fill_between(df_roc.iloc[:,0], df_roc.iloc[:,1], 0, color='red', alpha=0.3)\naxes[0, 0].plot(df_roc_test.iloc[:,0], df_roc_test.iloc[:,1], color='black', linewidth=2, \n                label=f'AUC_test={lr_auc_test:.2f}')\naxes[0, 0].plot([0, 1], [0, 1], color='green', linestyle='--', linewidth=1,\n                label='No Skill')\n\n# index of the first threshold for which the sensibility > 0.90\nidx = np.min(np.where(lr_tpr > 0.90))\naxes[0, 0].plot([0,lr_fpr[idx]], [lr_tpr[idx],lr_tpr[idx]], 'k--', color='blue')\naxes[0, 0].plot([lr_fpr[idx],lr_fpr[idx]], [0,lr_tpr[idx]], 'k--', color='blue')\n# Annotation\naxes[0, 0].annotate('(%.2f, %.2f)'%(lr_fpr[idx], lr_tpr[idx]),\n            (lr_fpr[idx], lr_tpr[idx]), \n            xytext =(-2 * 50, -30),\n            textcoords ='offset points',\n            bbox = dict(boxstyle =\"round\", fc =\"0.8\"), \n            arrowprops = dict(arrowstyle = \"->\"))\n\naxes[0, 0].set_xlabel('False Positive Rate', size=12)\naxes[0, 0].set_ylabel('True Positive Rate (recall)', size=12)\naxes[0, 0].legend(title='kNN')\naxes[0, 0].set_title('ROC curve', color='red', size=14)\n\n# row=0, col=1\naxes[0, 1].plot(df_roc.index[1:], df_roc[\"True Positive Rate\"][1:], color='blue', linewidth=2, \n                label='TPR')\naxes[0, 1].plot(df_roc_test.index[1:], df_roc_test[\"True Positive Rate\"][1:], color='black', linewidth=2, \n                label='TPR_test')\naxes[0, 1].plot(df_roc.index[1:], df_roc[\"False Positive Rate\"][1:], color='orange', linewidth=2, \n                label='FPR')\naxes[0, 1].plot(df_roc_test.index[1:], df_roc_test[\"False Positive Rate\"][1:], color='black', linewidth=2, \n                label='FPR_test')\n\naxes[0, 1].set_xlabel('Threshold', size=12)\naxes[0, 1].legend()\naxes[0, 1].set_title('TPR and FPR at every threshold', color='red', size=14)\n\n# row=1, col=0\nprecision, recall, thresholds = precision_recall_curve(y_test, pred_proba_test[:, 1])\n\naxes[1, 0].plot(recall, precision, color='green', linewidth=2, \n                label=f'PR_Curve (AUC={auc(lr_fpr, lr_tpr):.2f})')\naxes[1, 0].fill_between(recall, precision, 0, color='green', alpha=0.3)\n\naxes[1, 0].set_xlabel('Recall', size=12)\naxes[1, 0].set_ylabel('Precision', size=12)\naxes[1, 0].legend()\naxes[1, 0].set_title('Precision-Recall Curve', color='red', size=14)\n\nfig.tight_layout()\nfig.show()","3efa6bdf":"# Running Log loss on training\nprint('The Log Loss on Training is: {:.2}'.format(log_loss(y_train, pred_proba_train[:, 1])))\n\n# Running Log loss on testing\nprint('The Log Loss on Testing Dataset is: {:.2}'.format(log_loss(y_test, pred_proba_test[:, 1])))","7d5517d1":"X_kaggle_final[\"Age\"]=np.log(X_kaggle_final[\"Age\"])\nsubmission = gender_submission.drop('Survived', axis=1)\ny_pred_kaggle = model.predict(X_kaggle_final)\nsubmission['Survived'] = y_pred_kaggle\nsubmission.head()","ba7c1995":"df_gender_sub.head()","11765a5a":"# Are our test and submission dataframes the same length?\nif len(submission) == len(gender_submission):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submission)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")","dc62d3db":"# Convert submisison dataframe to csv for submission to csv for Kaggle submisison\nsubmission.to_csv('titanic_submission.csv', index=False)\nprint('Submission CSV is ready!')","e02cf6cc":"# Check the submission csv to make sure it's in the right format\nsubmissions_check = pd.read_csv(\"titanic_submission.csv\")\nsubmissions_check.head()","a37480c3":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.6.3 Logarithmic loss\n    <\/h4>\n<\/div>","8c1814a0":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.5.9 Model_Selection - Final\n    <\/h4>\n<\/div>","22342855":"# The goal","18e3530c":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.5.7 Gradient Boosting Trees\n    <\/h4>\n<\/div>","fdabf77b":"#### 3.1.2.1 Missing values in train data","c2fb4495":"<a id='44'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.4 Feature Selection\n   <\/h3>\n<\/div>","603841f1":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.5.1 Logistic\n    <\/h4>\n<\/div>","b94c7dd3":"<a id='1'><\/a>\n<div class=\"alert alert-block alert-danger\">\n<h2>1 Importing packages<\/h2>\n<\/div>","452c55f2":"<a id='45'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.5 Running Machine Learning Models\n   <\/h3>\n<\/div>","02a1a62e":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.5.2 Random Forest\n    <\/h4>\n<\/div>","2923aa71":"<a id='5'><\/a>\n<div class=\"alert alert-block alert-danger\">\n    <h2>\n        5. Submission\n    <\/h2>\n<\/div>","75c54d2a":"<a id='32'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        3.2 Drop Features Using Pearson Correlation\n   <\/h3>\n<\/div>","16441a18":"pclass: A proxy for socio-economic status (SES)<br>\n1st = Upper<br>\n2nd = Middle<br>\n3rd = Lower<br>\n<br>\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br>\nsibsp: The dataset defines family relations in this way...<br>\nSibling = brother, sister, stepbrother, stepsister<br>\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)<br>\nparch: The dataset defines family relations in this way...<br>\nParent = mother, father<br>\nChild = daughter, son, stepdaughter, stepson<br>\nSome children travelled only with a nanny, therefore parch=0 for them.","be742dc4":"<a id='3'><\/a>\n## 3.Data Preprocessing","423b183b":"<a id='42'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.2 Check categorical columns\n   <\/h3>\n<\/div>","571d65ce":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.4.3 RFE\n    <\/h4>\n<\/div>","dc557745":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.3 Embarked\n    <\/h4>\n<\/div>","5e9dc736":"<a id='42'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.2 Separate the dataset into train and test\n   <\/h3>\n<\/div>","e5e98aa7":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.6.2 roc curve and auc\n    <\/h4>\n<\/div>","163bbbc7":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.6.1 Confusion matrix\n    <\/h4>\n<\/div>","8822de02":"<a id='31'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        3.1 Missing Values\n   <\/h3>\n<\/div>","d395c3ba":"<a id='2'><\/a>\n<div class=\"alert alert-block alert-danger\">\n   <h2>\n    2 Read CSV train\/test files into DataFrame\n    <\/h2>\n<\/div>","f70b2626":"The goal is to predict the target variable(Survived) using logistic regression.","689b48af":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.5.4 SVM\n    <\/h4>\n<\/div>","1bb9f326":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.5.3 Naive Bayes\n    <\/h4>\n<\/div>","4d4ae20d":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.4.2 SelectKBest_chi2\n    <\/h4>\n<\/div>","2c8381fb":"## Index\n\n[1 Importing packages](#1)<br>\n[2 Read CSV train\/test files into DataFrame](#2)<br>\n[3 Data Preprocessing](#3)<br>\n    <ul>\n        <li>[3.1 Missing Values](#31)<\/li>\n        <li>[3.2 Drop Features Using Pearson Correlation](#32)<\/li>\n    <\/ul>\n[4 Regressions and Results](#4)<br>\n    <ul>\n        <li>[4.1 Separate the dataset into train and test](#41)<\/li>\n        <li>[4.2 Check categorical columns](#42)<\/li>\n        <li>[4.3 Check zero variance features](#43)<\/li>\n        <li>[4.4 Feature Selection](#44)<\/li>\n        <li>[4.5 Running Machine Learning Models](#45)<\/li>\n        <li>[4.6 Evaluating the Model ](#46)<\/li>\n    <\/ul>\n[5. Submission](#5)<br>","cd0ef5ac":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.2 Age\n    <\/h4>\n<\/div>","5ce193dc":"![titanic_data_dict.png](attachment:ed5ffef9-1b68-4b9b-bc51-d27d8f77cbf3.png)","588f117f":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.4.4 RFECV\n    <\/h4>\n<\/div>","50485048":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.5.6 Stochastic Gradient Descent\n    <\/h4>\n<\/div>","a13818e5":"<a id='4'><\/a>\n<div class=\"alert alert-block alert-danger\">\n   <h2>\n    4. Regressions and Results\n    <\/h2>\n<\/div>","a4c89e22":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.5.5 k-Nearest Neighbours\n    <\/h4>\n<\/div>","acfa0f36":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.4.1 SelectKBest_mutual_info_classif\n    <\/h4>\n<\/div>","3dda4a1b":"<a id='46'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.6 Evaluating the Model\n   <\/h3>\n<\/div>","0af445a2":"<a id='41'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.1 Drop Outliers\n   <\/h3>\n<\/div>","429bb0b7":"#### 3.1.1.1 Missing values in test data","32a10808":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.1 Fare\n    <\/h4>\n<\/div>"}}