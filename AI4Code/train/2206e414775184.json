{"cell_type":{"ad005f7e":"code","06443c60":"code","d36e9625":"code","d2104b8b":"code","3016b106":"code","0940703e":"code","a54ff8ee":"code","19dfff61":"code","ffe3b9eb":"code","4c34d6ff":"code","c5cfb409":"code","a1fecc8e":"code","4bd55556":"code","78f9ed00":"code","890cde4b":"code","af0c5d11":"code","5d8967f2":"code","2e122439":"code","1bdb35ca":"code","d5d43446":"code","d0f65511":"code","4db9d084":"code","a2278ae6":"code","47ce56da":"code","fa4d09e2":"code","782b3b81":"code","0bd1a187":"code","6fd7622d":"code","330be003":"code","056d890b":"code","8a27b5a7":"code","0e6afa45":"code","546ea6f7":"code","f17fd40d":"code","8be292ef":"code","ad6982b0":"code","c9b00364":"code","d98112f0":"code","2a9e60c1":"code","5a83001a":"code","7832a88d":"code","307910bd":"code","70b460ea":"markdown","d5ae3e53":"markdown","8821dce0":"markdown","8e401941":"markdown","7701f2e6":"markdown","094b05bc":"markdown","50ed379b":"markdown","bab1d054":"markdown","0cb4c77b":"markdown","e7f042c4":"markdown","15dde5e8":"markdown","7ef32025":"markdown","f10ee082":"markdown","55285739":"markdown","186a60cf":"markdown","b38ced10":"markdown","812e37d7":"markdown","19425887":"markdown","c353b6ba":"markdown","9cf0a9bc":"markdown","c0ab0d91":"markdown","8b08d055":"markdown","cbd30cb9":"markdown","45aec8e5":"markdown","58adf405":"markdown","170c5aee":"markdown","c80c8a4b":"markdown","4baa6c91":"markdown","2a3de84f":"markdown"},"source":{"ad005f7e":"!pip install iterative-stratification","06443c60":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.metrics import log_loss\n\nfrom sklearn.preprocessing import LabelEncoder, QuantileTransformer\n\nsns.set_style('whitegrid')","d36e9625":"DATA_PATH = '..\/input\/lish-moa\/'\n\nTRAIN_FEATURES = DATA_PATH + 'train_features.csv'\nTEST_FEATURES = DATA_PATH + 'test_features.csv'\nTRAIN_TARGETS_NON_SCORED = DATA_PATH + 'train_targets_nonscored.csv'\nTRAIN_TARGETS_SCORED = DATA_PATH + 'train_targets_scored.csv'","d2104b8b":"train_features_df = pd.read_csv(TRAIN_FEATURES)\ntrain_targets_df = pd.read_csv(TRAIN_TARGETS_SCORED)","3016b106":"test_features_df = pd.read_csv(TEST_FEATURES)","0940703e":"train_features_df.head()","a54ff8ee":"print(f'There are {len(train_features_df)} samples.')\nprint(f'There are {len(train_features_df[\"sig_id\"].unique())} unique samples.')\nprint(f'There are {len(train_features_df.columns)-1} predictive features.')\nprint(f'There are {(train_features_df.dtypes == \"float64\").sum()} continuous features.')\nprint(f'There are {len(train_targets_df.columns)-1} classes.')\nprint(f'{train_features_df.isna().sum().sum()} missing value')\n\nprint(f'TEST: There are {len(test_features_df)} samples to predict.')","19dfff61":"fig, ax = plt.subplots(2, 3, figsize=(20, 10))\nsns.set_palette(sns.color_palette(\"icefire\"))\n\nsns.countplot(train_features_df['cp_type'], ax=ax[0][0])\nax[0][0].set_title('Train - cp_type distribution', fontsize=14, fontweight='bold')\n\nsns.countplot(train_features_df['cp_time'], ax=ax[0][1])\nax[0][1].set_title('Train - cp_time distribution', fontsize=14, fontweight='bold')\n\nsns.countplot(train_features_df['cp_dose'], ax=ax[0][2])\nax[0][2].set_title('Train - cp_dose distribution', fontsize=14, fontweight='bold')\n\nsns.countplot(test_features_df['cp_type'], ax=ax[1][0])\nax[1][0].set_title('Test - cp_type distribution', fontsize=14, fontweight='bold')\n\nsns.countplot(test_features_df['cp_time'], ax=ax[1][1])\nax[1][1].set_title('Test - cp_time distribution', fontsize=14, fontweight='bold')\n\nsns.countplot(test_features_df['cp_dose'], ax=ax[1][2])\nax[1][2].set_title('Test - cp_dose distribution', fontsize=14, fontweight='bold')\n\nfig.suptitle('Distributions of type, time and dose', fontsize=20, fontweight='bold')\n\nfig.tight_layout(rect=[0, 0.03, 1, 0.90]);","ffe3b9eb":"gene_features = list([x for x in list(train_features_df.columns) if \"g-\" in x])\n\nprint(f'There are {len(gene_features)} gene features.')","4c34d6ff":"fig, ax = plt.subplots(5, 5, figsize=(25, 20))\nrand_feats = np.random.choice(gene_features, 25, replace=False)\n\nfig.suptitle('Kernel density estimator of some gene features', fontsize=20, fontweight=\"bold\")\n\nfor x in range(25):\n    i = x \/\/ 5\n    j = x % 5\n    \n    sns.kdeplot(train_features_df[rand_feats[x]], shade=True, label=\"Train\", ax=ax[i][j])\n    sns.kdeplot(test_features_df[rand_feats[x]], shade=True, label=\"Test\", ax=ax[i][j])\n    ax[i][j].set_title(rand_feats[x])","c5cfb409":"fig, ax = plt.subplots(5, 5, figsize=(22, 16))\n\nfig.suptitle('Boxplot of some gene features', fontsize=20, fontweight=\"bold\")\n\ntrain_features_df[rand_feats].plot(\n    kind='box', \n    subplots=True, \n    ax=ax,\n);","a1fecc8e":"fig, ax = plt.subplots(1, 4, figsize=(20, 6))\nfig.suptitle('Distributions of meta-statistics', fontsize=20, fontweight=\"bold\")\n\nsns.kdeplot(train_features_df[gene_features].mean(), shade=True, label=\"Train\", ax=ax[0])\nsns.kdeplot(test_features_df[gene_features].mean(), shade=True, label=\"Test\", ax=ax[0])\nax[0].set_title(\"Mean\", fontsize=14, fontweight=\"bold\")\n\nsns.kdeplot(train_features_df[gene_features].std(), shade=True, label=\"Train\", ax=ax[1])\nsns.kdeplot(test_features_df[gene_features].std(), shade=True, label=\"Test\", ax=ax[1])\nax[1].set_title(\"Standard deviation\", fontsize=14, fontweight=\"bold\")\n\nsns.kdeplot(train_features_df[gene_features].skew(), shade=True, label=\"Train\", ax=ax[2])\nsns.kdeplot(test_features_df[gene_features].skew(), shade=True, label=\"Test\", ax=ax[2])\nax[2].set_title(\"Skew\", fontsize=14, fontweight=\"bold\")\n\nsns.kdeplot(train_features_df[gene_features].kurt(), shade=True, label=\"Train\", ax=ax[3])\nsns.kdeplot(test_features_df[gene_features].kurt(), shade=True, label=\"Test\", ax=ax[3])\nax[3].set_title(\"Kurtosis\", fontsize=14, fontweight=\"bold\")\n\nfig.tight_layout(rect=[0, 0.03, 1, 0.90]);","4bd55556":"cell_features = list([x for x in list(train_features_df.columns) if \"c-\" in x])\n\nprint(f'There are {len(cell_features)} gene features.')","78f9ed00":"fig, ax = plt.subplots(5, 5, figsize=(25, 20))\nrand_feats = np.random.choice(cell_features, 25, replace=False)\n\nfig.suptitle('Kernel density estimator of some cell features', fontsize=20, fontweight=\"bold\")\n\nfor x in range(25):\n    i = x \/\/ 5\n    j = x % 5\n    \n    sns.kdeplot(train_features_df[rand_feats[x]], shade=True, label=\"Train\", ax=ax[i][j])\n    sns.kdeplot(test_features_df[rand_feats[x]], shade=True, label=\"Test\", ax=ax[i][j])\n    ax[i][j].set_title(rand_feats[x])","890cde4b":"fig, ax = plt.subplots(5, 5, figsize=(22, 16))\n\nfig.suptitle('Boxplot of some gene features', fontsize=20, fontweight=\"bold\")\n\ntrain_features_df[rand_feats].plot(\n    kind='box', \n    subplots=True, \n    ax=ax,\n);","af0c5d11":"fig, ax = plt.subplots(1, 4, figsize=(20, 6))\nfig.suptitle('Distributions of meta-statistics', fontsize=20, fontweight=\"bold\")\n\nsns.kdeplot(train_features_df[cell_features].mean(), shade=True, label=\"Train\", ax=ax[0])\nsns.kdeplot(test_features_df[cell_features].mean(), shade=True, label=\"Test\", ax=ax[0])\nax[0].set_title(\"Mean\", fontsize=14, fontweight=\"bold\")\n\nsns.kdeplot(train_features_df[cell_features].std(), shade=True, label=\"Train\", ax=ax[1])\nsns.kdeplot(test_features_df[cell_features].std(), shade=True, label=\"Test\", ax=ax[1])\nax[1].set_title(\"Standard deviation\", fontsize=14, fontweight=\"bold\")\n\nsns.kdeplot(train_features_df[cell_features].skew(), shade=True, label=\"Train\", ax=ax[2])\nsns.kdeplot(test_features_df[cell_features].skew(), shade=True, label=\"Test\", ax=ax[2])\nax[2].set_title(\"Skew\", fontsize=14, fontweight=\"bold\")\n\nsns.kdeplot(train_features_df[cell_features].kurt(), shade=True, label=\"Train\", ax=ax[3])\nsns.kdeplot(test_features_df[cell_features].kurt(), shade=True, label=\"Test\", ax=ax[3])\nax[3].set_title(\"Kurtosis\", fontsize=14, fontweight=\"bold\")\n\nfig.tight_layout(rect=[0, 0.03, 1, 0.90]);","5d8967f2":"for col in gene_features + cell_features:\n    transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n    \n    vec_len = len(train_features_df[col])\n    vec_len_test = len(test_features_df[col])\n    \n    raw_vec = train_features_df[col].values.reshape(vec_len, 1)\n    transformer.fit(raw_vec)\n\n    train_features_df[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    test_features_df[col] = transformer.transform(test_features_df[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]","2e122439":"fig, ax = plt.subplots(5, 5, figsize=(25, 20))\nrand_feats = np.random.choice(gene_features, 25, replace=False)\n\nfig.suptitle('Kernel density estimator of some gene features', fontsize=20, fontweight=\"bold\")\n\nfor x in range(25):\n    i = x \/\/ 5\n    j = x % 5\n    \n    sns.kdeplot(train_features_df[rand_feats[x]], shade=True, label=\"Train\", ax=ax[i][j])\n    sns.kdeplot(test_features_df[rand_feats[x]], shade=True, label=\"Test\", ax=ax[i][j])\n    ax[i][j].set_title(rand_feats[x])","1bdb35ca":"fig, ax = plt.subplots(5, 5, figsize=(25, 20))\nrand_feats = np.random.choice(cell_features, 25, replace=False)\n\nfig.suptitle('Kernel density estimator of some cell features', fontsize=20, fontweight=\"bold\")\n\nfor x in range(25):\n    i = x \/\/ 5\n    j = x % 5\n    \n    sns.kdeplot(train_features_df[rand_feats[x]], shade=True, label=\"Train\", ax=ax[i][j])\n    sns.kdeplot(test_features_df[rand_feats[x]], shade=True, label=\"Test\", ax=ax[i][j])\n    ax[i][j].set_title(rand_feats[x])","d5d43446":"fig = plt.figure(figsize=(12, 7))\nax = sns.countplot(x=\"cp_time\", hue=\"cp_dose\", data=train_features_df)\n\nfor p in ax.patches:\n    '''\n    https:\/\/www.kaggle.com\/rohitsingh9990\/panda-eda-better-visualization-simple-baseline\n    '''\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2,\n                height +3,\n                '{:1.2f}%'.format(100*height\/len(train_features_df)),\n                ha=\"center\")\n\nax.set_title('Distribution of cp_time with respect to dose', fontsize=20, fontweight=\"bold\");","d0f65511":"fig = plt.figure(figsize=(12,7))\nax = sns.countplot(x=\"cp_type\", hue=\"cp_dose\", data=train_features_df)\n\nfor p in ax.patches:\n    '''\n    https:\/\/www.kaggle.com\/rohitsingh9990\/panda-eda-better-visualization-simple-baseline\n    '''\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2,\n                height +3,\n                '{:1.2f}%'.format(100*height\/len(train_features_df)),\n                ha=\"center\")\n\nax.set_title('Distribution of cp_type with respect to dose', fontsize=20, fontweight=\"bold\");","4db9d084":"fig = plt.figure(figsize=(12,7))\nax = sns.countplot(x=\"cp_time\", hue=\"cp_type\", data=train_features_df)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width() \/ 2, height +3,\n            '{:1.2f}%'.format(100*height\/len(train_features_df)),\n            ha=\"center\")\n\nax.set_title('Distribution of cp_time with respect to dose', fontsize=20, fontweight=\"bold\");","a2278ae6":"rand_cell_feats = np.random.choice(cell_features, 25, replace=False)\nrand_gene_feats = np.random.choice(gene_features, 25, replace=False)","47ce56da":"plt.figure(figsize=(30, 12))\nsns.heatmap(train_features_df[rand_cell_feats].corr(), \n            annot=True,\n            fmt='.3f',\n            cmap='cool',\n            linewidths=0.01,\n            cbar=True)\n\nplt.title('Correlation matrix for cell features', fontsize=20, fontweight=\"bold\");","fa4d09e2":"plt.figure(figsize=(30, 12))\nsns.heatmap(train_features_df[rand_gene_feats].corr(), \n            annot=True,\n            fmt='.3f',\n            cmap='cool',\n            linewidths=0.01,\n            cbar=True)\n\nplt.title('Correlation matrix for gene features', fontsize=20, fontweight=\"bold\");","782b3b81":"random_selected_features = list(rand_gene_feats) + list(rand_cell_feats)\n\nplt.figure(figsize=(30, 12))\nsns.heatmap(train_features_df[random_selected_features].corr(),\n            annot=True,\n            fmt='.1f',\n            cmap='cool',\n            linewidths=0.01,\n            cbar=True)\n\nplt.title('Correlation matrix for cell and gene features', fontsize=20, fontweight=\"bold\");","0bd1a187":"correlations = train_features_df.iloc[:,1:].corr().abs().unstack().sort_values(kind=\"quicksort\",ascending=False).reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']]\n\ncorr_max = correlations.level_0.head(25).tolist()\ncorr_max = list(set(corr_max)) \n\ncorr_min = correlations.level_0.tail(25).tolist()\ncorr_min = list(set(corr_min)) ","6fd7622d":"plt.figure(figsize=(30, 12))\n\nsns.heatmap(train_features_df[corr_max].corr(), \n            annot=True,\n            fmt='.3f',\n            cmap='cool',\n            linewidths=0.01,\n            cbar=True);\n\nplt.title('Most correlated features', fontsize=20, fontweight=\"bold\");","330be003":"plt.figure(figsize=(30, 12))\n\nsns.heatmap(train_features_df[corr_min].corr(), \n            annot=True,\n            fmt='.3f',\n            cmap='cool',\n            linewidths=0.01,\n            cbar=True)\n\nplt.title('Least correlated features', fontsize=20, fontweight=\"bold\");","056d890b":"train_targets_df.head()","8a27b5a7":"# Plot of multiple labels for one id\n\nsns.set_palette(sns.color_palette(\"icefire\"))\n\ntarget_cols = list(train_targets_df.columns)\ntarget_cols.remove('sig_id')\n\nmultiple_labels = train_targets_df[target_cols].sum(axis=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\nsns.countplot(multiple_labels, ax=ax)\nax.set_xlabel('Number of labels', fontsize=14)\nax.set_ylabel('Frequency', fontsize=14)\nax.set_title('Distribution of number of labels', fontsize=20, fontweight=\"bold\");","0e6afa45":"multiple_labels = train_targets_df[target_cols].sum(axis=0).sort_values(ascending=False)[:10] \/ len(train_targets_df) * 100\nmultiple_labels.sort_values(ascending=True, inplace=True)\n\nplt.figure(figsize=(7,7)) \nplt.scatter(multiple_labels.values, multiple_labels.index, color=sns.color_palette('Reds',len(multiple_labels)))\nplt.title('Targets with higher presence in train samples', weight='bold', fontsize=20)\nplt.xlabel('Percentage', fontsize=13)\nplt.show()","546ea6f7":"le = LabelEncoder()\n\ntrain_features_df['cp_type'] = le.fit_transform(train_features_df['cp_type'])\ntrain_features_df['cp_time'] = le.fit_transform(train_features_df['cp_time'])\ntrain_features_df['cp_dose'] = le.fit_transform(train_features_df['cp_dose'])","f17fd40d":"cat_features = ['cp_type', 'cp_time', 'cp_dose']\nfeatures = cell_features +  gene_features + cat_features\n\nX = train_features_df[features].values\ny_1 = train_targets_df[target_cols].sum(axis=1).values\ny_2 = train_targets_df['nfkb_inhibitor'].values\ny_3 = train_targets_df['proteasome_inhibitor'].values\ny_4 = train_targets_df['cyclooxygenase_inhibitor'].values\n\nindices = random.choices(range(len(X)), k=2000)\n\nX = X[indices,]\ny_1 = y_1[indices,]\ny_2 = y_2[indices,]\ny_3 = y_3[indices,]\ny_4 = y_4[indices,]\n\nprint('X shape:', X.shape)\nprint('y shape:', y_1.shape)","8be292ef":"# First we reduce the number of features using PCA\npca = PCA(n_components=50)\nX_reduced = pca.fit_transform(X)\n\n# Then we can apply TSNE for low-dimensional visualization of the data points\nt_sne_results_2d = TSNE(n_components=2).fit_transform(X_reduced)","ad6982b0":"fig, ax = plt.subplots(1, 1, figsize=(16,10))\n\nsns.scatterplot(t_sne_results_2d[:, 0], t_sne_results_2d[:, 1], hue=y_1,\n                palette=sns.color_palette(\"hls\", len(np.unique(y_1))), legend=\"full\",\n                alpha=0.3, ax=ax)\n\nax.set_title('2D visualization of T-SNE components  - Number of triggered mechanisms', fontsize=20, fontweight=\"bold\");","c9b00364":"fig, ax = plt.subplots(1, 1, figsize=(16,10))\n\nsns.scatterplot(t_sne_results_2d[:, 0], t_sne_results_2d[:, 1], hue=y_2,\n                palette=sns.color_palette(\"hls\", 2), legend=\"full\",\n                alpha=0.3, ax=ax)\n\nax.set_title('2D visualization of T-SNE components - nfkb_inhibitor triggered ', fontsize=20, fontweight=\"bold\");","d98112f0":"fig, ax = plt.subplots(1, 1, figsize=(16,10))\nsns.scatterplot(\n    x=t_sne_results_2d[:, 0], \n    y=t_sne_results_2d[:, 1],\n    hue=y_3,\n    palette=sns.color_palette(\"hls\", 2),\n    legend=\"full\",\n    alpha=0.3,\n    ax=ax\n)\n\nax.set_title('2D visualization of T-SNE components - proteasome_inhibitor triggered', fontsize=20, fontweight=\"bold\");","2a9e60c1":"fig, ax = plt.subplots(1, 1, figsize=(16,10))\nsns.scatterplot(\n    x=t_sne_results_2d[:, 0], \n    y=t_sne_results_2d[:, 1],\n    hue=y_4,\n    palette=sns.color_palette(\"hls\", 2),\n    legend=\"full\",\n    alpha=0.3,\n    ax=ax\n)\n\nax.set_title('2D visualization of T-SNE components - cyclooxygenase_inhibitor', fontsize=20, fontweight=\"bold\");","5a83001a":"kfold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n\nX = train_features_df[features]\ny = train_targets_df[target_cols]\n\nfull_df = train_features_df.merge(train_targets_df, on=\"sig_id\", how='left')\n\nfor i, (trn_, val_) in enumerate(kfold.split(X, y)):\n    full_df.loc[val_, 'fold'] = i","7832a88d":"print('Shape:', full_df.shape)","307910bd":"full_df.to_csv('df.csv', index=False)","70b460ea":"### Correlation matrices\n\nSince plotting a 700x700 matrix is virtually infeasible, we will only plot a correlation matrix for gene features and cell features. Eventually, we will plot a correlation matrix for gene and cell features combined.","d5ae3e53":"# Mechanism of action \n\n## Definition\nIn pharmacology, the term mechanism of action (MOA) refers to the specific biochemical interaction through which a drug substance produces its pharmacological effect. A mechanism of action usually includes mention of the specific molecular targets to which the drug binds, such as an enzyme or receptor. Receptor sites have specific affinities for drugs based on the chemical structure of the drug, as well as the specific action that occurs there.\n\nFind here below an example of how beta-blockers work.\n\n![image.png](attachment:image.png)\n\n## How Mechanism of Action Is Determined\nWhen scientists are researching antibiotic treatments in the lab, they can see how effective different medications are at fighting specific bacteria. They study the cells closely and watch how they interact. Their observations reveal how the drug attacks and kills the bacteria.\n\nWhen they discuss the exact way that a drug works on its target, they refer to it as the medication's mechanism of action.\n\nDrugs bind to receptors that are located on the surface of cells or within the cytoplasm (a jelly-like substance inside a cell). After the receptors bind to a cell, the drug will take on one of two roles: agonist or antagonist.\n\n## Agonists vs. Antagonists\nDrugs that are agonists activate the receptors they bind to. This bond will either increase or decrease the activity within the cell. Antagonist drugs do the opposite; they will block the receptors and prevent the natural agonists within the body from binding.\n\nMost drugs bind to a specific type of receptor (which is known as receptor selectivity). The ability of a drug to bind to a certain receptor is determined by its unique chemical structure.\n\n## Why mechanism of action is important\n\nElucidating the mechanism of action of novel drugs and medications is important for several reasons:\n\n- In the case of anti-infective drug development, the information permits anticipation of problems relating to clinical safety. Drugs disrupting the cytoplasmic membrane or electron transport chain, for example, are more likely to cause toxicity problems than those targeting components of the cell wall (peptidoglycan or \u03b2-glucans) or 70S ribosome, structures which are absent in human cells.\n\n- By knowing the interaction between a certain site of a drug and a receptor, other drugs can be formulated in a way that replicates this interaction, thus producing the same therapeutic effects. Indeed, this method is used to create new drugs.\n\n- It can help identify which patients are most likely to respond to treatment. Because the breast cancer medication trastuzumab is known to target protein HER2, for example, tumors can be screened for the presence of this molecule to determine whether or not the patient will benefit from trastuzumab therapy.\n\n- It can enable better dosing because the drug's effects on the target pathway can be monitored in the patient. Statin dosage, for example, is usually determined by measuring the patient's blood cholesterol levels.\n\n- It allows drugs to be combined in such a way that the likelihood of drug resistance emerging is reduced. By knowing what cellular structure an anti-infective or anticancer drug acts upon, it is possible to administer a cocktail that inhibits multiple targets simultaneously, thereby reducing the risk that a single mutation in microbial or tumor DNA will lead to drug resistance and treatment failure.\n\n- It may allow other indications for the drug to be identified. Discovery that sildenafil inhibits phosphodiesterase-5 (PDE-5) proteins, for example, enabled this drug to be repurposed for pulmonary arterial hypertension treatment, since PDE-5 is expressed in pulmonary hypertensive lungs","8821dce0":"The meta-statistics look quite different from the gene ones.\n\n- Almost no distribution is zero-centered.\n- All variables are right-skewed (we have previously witnessed that when plotting the feature distributions), this is due to the spike at around -10.\n- They are fat-tailed variables with for most a kurtosis exceeding 10.\n- There is a slight mean distribution shift between the training and the test sets. ","8e401941":"# 1  - Predictive features","7701f2e6":"#### Meta-statistics\n\nSince we can't plot all the distributions of the features, let's first try to see how the meta-statistics (mean, std, kurtosis...) are distributed.","094b05bc":"As inferred with the distribution plot, we are indeed faced with distributions with a lot of outliers. The whiskers around the box are set at 1.5IQR where IQR is the interquartile range. That is usually a standard used to measure outliers.","50ed379b":"Some notes when using t-SNE from sklearn documentation: \n> Since t-SNE scales quadratically in the number of objects N, its applicability is limited to data sets with only a few thousand input objects; beyond that, learning becomes too slow to be practical (and the memory requirements become too large).\n\n> It is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data) to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high. This will suppress some noise and speed up the computation of pairwise distances between samples.","bab1d054":"Indeed, our distributions look Gaussian now, with the exception of this peak for cell features at around -5 (remember it was the peak around -10 before normalization).","0cb4c77b":"With more than 700 features, it will be difficult to plot every distribution of features. Instead we want to gather meta-statistics of each feature, plot the distribution and check if there are a significant portion of the features who have a skewed distribution of a high kurtosis.\n\n**As meta-statistics, we will be interested in**:\n- Mean\n- Standard deviation \n- Skew\n- Kurtosis","e7f042c4":"Finally let's generate our folds for future experimentations.","15dde5e8":"# 3 - High-dimensional visualization with t-SNE","7ef32025":"### 1.3.2 - Quantile transform\n\nFrom this analysis, we can conclude that the feature distributions are close from being Gaussian. Hence we can safely using a quantile transform to transform the features distribution into a Gaussian distribution. This is all the more critical so that it has been reported that neural networks perform best in this competition. Neural networks need to have normalized features to perform best.","f10ee082":"- Most feature distributions are centered in 0.\n- Most distributions are symmetric with the exception of an equivalent number of left-skewed and right-skewed distributions.\n- There are quite a large number of fat-tailed distributions with a kurtosis largely exceeding 3 (for some models, a transformation might be needed).","55285739":"## 1.1. - Type, time and dose","186a60cf":"Now let's try to investigate which features are the most and the least correlated. This will be very important for applying dimensionality reduction techniques.","b38ced10":"Same for the **proteatosome_inhibitor**. It seems like both the **nfkb_inhibitor** and the **proteatosome_inhibitor** react together.","812e37d7":"The distributions look like Gaussian variables with a low variance for the most part, which is not unusual for that kind of biological data. At least we don't notice a lot of outliers. I'd like to have more details by having a look at the boxplot of the distributions. This might give us additional information about the outliers.","19425887":"## 1.2. - Gene features","c353b6ba":"## 1.3. - Cell features","9cf0a9bc":"## 1.4. - Bivariate analysis","c0ab0d91":"First let's remember that the correlation matrix only captures **linear correlation**. \n\n**We notice**:\n- Cell features are quite linearly correlated.\n- Gene features are way less linearly correlated, at least for the sample we have extracted. \n- Using the large correlation matrix, we can clearly see from the vertical bands on the bottom left corner of the image that gene features seem to have the same level of correlation for all the cell features. Either a gene feature is highly correlated to all cell features or it is not.","8b08d055":"The number of triggered mechanisms is evenly distributed except from one which has mostly 2 mechanisms triggered (on the bottom-right of the image).","cbd30cb9":"# 2  - Targets","45aec8e5":"# 4 - Folds","58adf405":"Let's now check the resulting distributions...","170c5aee":"Let's first plot the distribution of the 3 categorical features.","c80c8a4b":"We will now try to plot a low-dimensional representation of our data. I won't take the full dataset, but rather 2000 random samples.","4baa6c91":"Now, this gets more interesting since we are plotting the data points where the **nfkb_inhibitor** is triggered. We see that the same cluster turns blue, meaning that those drugs have an action on the **nfkb_inhibitor**.","2a3de84f":"Here, the distributions look a bit suspicious due to a recurrent spike in the negative values at -10. Notice also that those outliers are present in the boxplots as well. There are even more outliers in the cell features."}}