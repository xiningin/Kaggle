{"cell_type":{"72d19ad2":"code","b88b7d59":"code","8607122a":"code","50f5013b":"code","8946b644":"code","1ffdd9c9":"code","04043bcd":"code","05275630":"code","374f81bf":"code","6bfba7fb":"code","4dda3c1e":"code","9c489865":"code","488a84e2":"code","5f6660a9":"code","7f9c502b":"code","46f29b48":"code","85c3814d":"code","4d60208e":"code","8a97a1d7":"code","5d0e1f3d":"code","e657aa74":"code","5f420fb5":"code","ee38ddf7":"code","b9048607":"code","1c3479f3":"code","42444fcd":"code","65776ea2":"code","91222a16":"code","1d990403":"code","02ada099":"code","b8c14fd7":"code","38b41412":"code","67614a03":"code","ecb31496":"code","48cb00e2":"code","dc53377d":"code","2d93f02c":"code","9d81f4a6":"code","ca86cf25":"code","dcb6e19a":"code","050620ed":"markdown","1254d89d":"markdown","73b5470b":"markdown","c87bacc6":"markdown","8855377e":"markdown","da3dd97c":"markdown","a1f63f59":"markdown","237c788e":"markdown","32d5d81e":"markdown","d7b6f616":"markdown","0c6e4c7a":"markdown","cea1d0b5":"markdown","4cfb5128":"markdown","9df17845":"markdown","3e6560b8":"markdown","2a03fe8a":"markdown","ca18c879":"markdown","558961b3":"markdown","90443ef4":"markdown","bedb49a9":"markdown","3d328d5e":"markdown","342d9c28":"markdown","59dcf30b":"markdown","51479414":"markdown","b099d310":"markdown","f41fd2bb":"markdown","6fbf3772":"markdown","74f2ab4a":"markdown","077412b0":"markdown","b5766005":"markdown","cde9f8c0":"markdown","c6bd695f":"markdown","96c1a2fc":"markdown","0582a87f":"markdown","72f0376a":"markdown"},"source":{"72d19ad2":"# linear algebra\nimport numpy as np \n\n# data processing\nimport pandas as pd\n\n# data visualization(for EDA)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nsns.set(color_codes=True)\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nimport datetime\n\n\n# Importing sklearn methods\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import svm\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\n# import labelencoder\nfrom sklearn.preprocessing import LabelEncoder\n\n# the spearman's correlation between two variables\nfrom scipy.stats import spearmanr\n\n","b88b7d59":"df=pd.read_csv('..\/input\/marketing-data\/marketing_data.csv')\ndf.shape","8607122a":"df.rename({' Income ':'Income'}, axis=1, inplace=True)\ndf['Income'] = df['Income'].str.replace('$','').str.replace(',','').astype(float)\n","50f5013b":"df.head(3)","8946b644":"#null values\nsns.heatmap(df.isnull(),yticklabels=False,cmap='YlOrRd');","1ffdd9c9":"#We can see that Income has 24 null values so we drop them \ndf = df[df['Income'].notna()]\ndf.columns[df.isnull().any()].tolist()  ","04043bcd":"import matplotlib.pyplot as plt\nlist(set(df.dtypes.tolist()))\ndf_num = df.drop(columns=['ID', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'Complain']).select_dtypes(include = ['float64', 'int64'])\n\ndf_num.plot(subplots=True, layout=(4,4), kind='box', figsize=(16,18), patch_artist=True,color=\"Green\" )\nplt.subplots_adjust(wspace=0.5);","05275630":"df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8,color=\"Red\");\n","374f81bf":"from scipy import stats\nimport seaborn as sns\nstats.probplot(df['Income'], plot=sns.mpl.pyplot);","6bfba7fb":"stats.probplot(df['Year_Birth'],plot=sns.mpl.pyplot);","4dda3c1e":"df.Marital_Status.value_counts()","9c489865":"df = df[~df['Marital_Status'].isin(['Absurd', 'Alone', 'YOLO'])]","488a84e2":"df = df[df['Year_Birth'] > 1910].reset_index(drop=True)\ndf = df[df['Income'] < 600000].reset_index(drop=True)","5f6660a9":"#Total kids\ndf['Totalkids'] = df['Kidhome'] + df['Teenhome']\n\n#\ndf['YearCustomer'] = pd.DatetimeIndex(df['Dt_Customer']).year\n\n\n# total amount spent\nmnt_cols = [col for col in df.columns if 'Mnt' in col]\ndf['TotalMnt'] = df[mnt_cols].sum(axis=1)\n\n# Total Purchases\npurchases_cols = [col for col in df.columns if 'Purchases' in col]\ndf['TotalPurchases'] = df[purchases_cols].sum(axis=1)\n\n# Total Campaigns Accepted\ncampaigns_cols = [col for col in df.columns if 'Cmp' in col] + ['Response'] \ndf['TotalCampaignsAcc'] = df[campaigns_cols].sum(axis=1)\n\n#age\nyear=datetime.datetime.today().year\ndf['Age']=year-df['Year_Birth']\n\n#Age_groupe\nbins= [18,39,59,90]\nlabels = ['Adult','Middle Age Adult','Senior Adult']\ndf['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\ndf['AgeGroup'] = df['AgeGroup'].astype('object')","7f9c502b":"\nf,ax=plt.subplots(2,2,figsize=(20,15))\n\n\ndf['Education'].value_counts().plot.pie(autopct='%1.1f%%',ax=ax[0][0],shadow=True,legend=True)\nax[0][0].set_title('Level of Education',fontweight =\"bold\") \nax[0][0].set_ylabel('')\ndf['Marital_Status'].value_counts().plot.pie(autopct='%1.1f%%',ax=ax[0][1],shadow=True,legend=True)\nax[0][1].set_title('Marital status',fontweight =\"bold\") \nax[0][1].set_ylabel('')\ndf['Country'].value_counts().plot.pie(autopct='%1.1f%%',ax=ax[1][0],shadow=True,legend=True)\nax[1][0].set_title('Countries',fontweight =\"bold\") \nax[1][0].set_ylabel('')\ndf['AgeGroup'].value_counts().plot.pie(autopct='%1.1f%%',ax=ax[1][1],shadow=True,legend=True)\nax[1][1].set_title('Age Group',fontweight =\"bold\") \nax[1][1].set_ylabel('');\n\n","46f29b48":"f,ax=plt.subplots(2,2,figsize=(16,8))\nsns.barplot(x='Education', y='TotalMnt', data=df,ax=ax[0][0]);\nax[0][0].set_title(' Education vs Total spending',fontweight =\"bold\") \nax[0][0].set_xlabel('')\nsns.barplot(x='Marital_Status', y='TotalMnt', data=df,ax=ax[0][1]);\nax[0][1].set_title('Marital status vs Total spending',fontweight =\"bold\") \nax[0][1].set_xlabel('')\nsns.barplot(x='Totalkids', y='TotalMnt', data=df,ax=ax[1][0]);\nax[1][0].set_title('Countries vs Total spending',fontweight =\"bold\") \nax[1][0].set_xlabel('')\nsns.barplot(x='Country', y='TotalMnt', data=df,ax=ax[1][1]);\nax[1][1].set_title('Age Group vs Total spending',fontweight =\"bold\") ;\nax[1][1].set_xlabel('');","85c3814d":"channels = ['NumWebPurchases', 'NumCatalogPurchases',  'NumStorePurchases']\ndata = df[channels].sum()\nplt.figure(figsize=(10,5))\nplt.title('The number of purchases through the Each channels')\nx=sns.barplot(x=channels,y=data.values,palette='Set2')\nx.set_xticklabels(channels, size=12)\nplt.tight_layout();\n","4d60208e":"col_products = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n\ndata = df[col_products].sum()\nplt.figure(figsize=(15,5))\nplt.title('The Total Amount of each product spent',fontweight =\"bold\")\nx=sns.barplot(x=col_products,y=data.values,palette='Set2')\nx.set_xticklabels(col_products, size=15)\nplt.tight_layout()\n\n","8a97a1d7":"plt.figure(figsize=(8,5))\nplt.title('Income Age Group wise',fontweight =\"bold\")\nx=sns.barplot(data=df,x='AgeGroup',y='Income',palette='Set2')\nplt.tight_layout()\n","5d0e1f3d":"\n\nPurchases = ['NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases']\ndataset = df.groupby('AgeGroup')[Purchases].mean()\n\nscore_label = np.arange(0, 10, 1)\nAdult_mean  = list(dataset.T['Adult'])\nMiddleage_mean  = list(dataset.T['Middle Age Adult'])\nSeniorAdult_mean  = list(dataset.T['Senior Adult'])\n\n# set width of bar\nbarWidth = 0.35\n\nfig, ax = plt.subplots(figsize=(19,8))\n\n# Set position of bar on X axis\nr1 = np.arange(0,len(Purchases)*2,2)\nr2 = [x + barWidth for x in r1]\nr3 = [x + barWidth for x in r2]\n\n\n# Make the plot\n\nAdult = ax.bar(r1, Adult_mean, width=barWidth, label='Adult')\nMiddleage = ax.bar(r2,Middleage_mean, width=barWidth, label='Middelage')\nSeniorAdult= ax.bar(r3, SeniorAdult_mean,width=barWidth, label='Senior Adult')\n\n\n# inserting x axis label\nplt.xticks([r + barWidth for r in range(0,len(Purchases)*2,2)], dataset)\nax.set_xticklabels(Purchases)\n\n# inserting y axis label\nax.set_yticks(score_label)\nax.set_yticklabels(score_label)\n\n# inserting legend\nax.legend()\n\nplt.title('purchases  vs age group')\n\n\nplt.show()","e657aa74":"Products = ['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']\ndataset = df.groupby('AgeGroup')[Products].mean()\n\nscore_label = np.arange(0, 500, 50)\nAdult_mean  = list(dataset.T['Adult'])\nMiddleage_mean  = list(dataset.T['Middle Age Adult'])\nSeniorAdult_mean  = list(dataset.T['Senior Adult'])\n# set width of bar\nbarWidth = 0.35\n\nfig, ax = plt.subplots(figsize=(19,8))\n\n# Set position of bar on X axis\nr1 = np.arange(0,len(Products)*2,2)\nr2 = [x + barWidth for x in r1]\nr3 = [x + barWidth for x in r2]\n\n\n# Make the plot\n\nAdult = ax.bar(r1, Adult_mean, width=barWidth, label='Adult')\nMiddleage = ax.bar(r2,Middleage_mean, width=barWidth, label='Middelage')\nSeniorAdult= ax.bar(r3, SeniorAdult_mean,width=barWidth, label='Senior Adult')\n\n\n# inserting x axis label\nplt.xticks([r + barWidth for r in range(0,len(Products)*2,2)], dataset)\nax.set_xticklabels(Products)\n\n# inserting y axis label\nax.set_yticks(score_label)\nax.set_yticklabels(score_label)\n\n# inserting legend\nax.legend()\n\nplt.title('products amount vs age group')\nplt.show()","5f420fb5":"fig, ax = plt.subplots(figsize=(18,8))\nsns.scatterplot(data=df,x='Income', y='TotalPurchases',ax=ax,hue='AgeGroup',style=\"AgeGroup\",palette='dark')","ee38ddf7":"f,ax=plt.subplots(3,2,figsize=(18,17))\n\nsns.scatterplot(data=df, x='Income', y='MntWines', hue='AgeGroup',markers=[\"o\", \"s\", \"D\"],ax=ax[0][0])\nsns.scatterplot(data=df, x='Income', y='MntWines', hue='AgeGroup',style=\"AgeGroup\",ax=ax[0][0],palette=\"dark\")\nax[0][0].set_title('Income vs Amount of wines purchase')\nsns.scatterplot(data=df, x='Income', y='MntFruits', hue='AgeGroup',style=\"AgeGroup\",ax=ax[0][1],palette=\"bright\")\nax[0][1].set_title('Income vs Amount of Fruits purchase')\nsns.scatterplot(data=df, x='Income', y='MntMeatProducts', hue='AgeGroup',style=\"AgeGroup\",ax=ax[1][0],palette=\"bright\")\nax[1][0].set_title('Income vs Amount of Meat purchase')\nsns.scatterplot(data=df, x='Income', y='MntSweetProducts', hue='AgeGroup',style=\"AgeGroup\",ax=ax[1][1],palette=\"bright\")\nax[1][1].set_title('Income vs Amount of Sweet purchase')\nsns.scatterplot(data=df, x='Income', y='MntGoldProds', hue='AgeGroup',style=\"AgeGroup\",ax=ax[2][0], palette=\"bright\")\nax[2][0].set_title('Income vs Amount of Gold purchase')\nsns.scatterplot(data=df, x='Income', y='MntFishProducts', hue='AgeGroup',style=\"AgeGroup\",ax=ax[2][1], palette=\"bright\")\nax[2][1].set_title('Income vs Amount of Fish purchase')\n","b9048607":"df_num = df.drop(columns=['ID']).select_dtypes(include = ['float64', 'int64'])\n\n\nplt.figure(figsize=(25,14))\n\n\nmask = np.triu(np.ones_like(df_num.corr(), dtype=np.bool))\nheatmap = sns.heatmap(df_num.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=16);\n","1c3479f3":"corr_with_SalePrice = df_num.corr()\nplot_data = corr_with_SalePrice[\"NumStorePurchases\"].sort_values(ascending=True)\nplt.figure(figsize=(12,6))\nplot_data.plot.bar()\nplt.title(\"Correlations with the  NumStorePurchases\")\nplt.show()","42444fcd":"\nData=df.drop(columns=['Response', 'Complain','Recency','Teenhome'])\n#Droping uninformative features\nData=df.drop(columns=['ID','Dt_Customer'])","65776ea2":"few_cat_variables = ['Education','Marital_Status','Country' ,'AgeGroup']\n\nfor i in range(len(few_cat_variables)):\n    sns.boxplot(x=few_cat_variables[i], y='NumStorePurchases', data=df)\n    plt.show()","91222a16":"# Categorical boolean mask\ncategorical_feature_mask = Data.dtypes==object \n# filter categorical columns using mask and turn it into a list\ncategorical_cols =Data.columns[categorical_feature_mask].tolist()\n\n\n# instantiate labelencoder object\nle = LabelEncoder()\n# apply le on categorical feature columns\nData[categorical_cols] =Data[categorical_cols].apply(lambda col: le.fit_transform(col))","1d990403":"plt.figure(figsize = (7, 5))\nsns.distplot(df['NumStorePurchases'], color = 'k')\nplt.title('NumStorePurchases distribution');","02ada099":"# Separating 'NumStorePurchases' column\n\nX = Data.drop(columns='NumStorePurchases')\ny = Data['NumStorePurchases']\n\n#Train, test split\nx_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n\n# print Test and Validation data lenght\nprint(\"Train data points: \", len(x_train))\nprint(\"test data points: \", X_test.shape[0])","b8c14fd7":"class Models(object):\n    \n\n    \n    # Initialization \n    def __init__(self, x_train, X_test, y_train, y_test):\n        # changing input as dataframe to list\n        self.x_train = [x_train.iloc[i].tolist() for i in range(len(x_train))]\n        self.X_test = [X_test.iloc[i].tolist() for i in range(len(X_test))]\n        self.y_train = y_train.tolist()\n        self.y_test = y_test.tolist()\n    \n    \n    @staticmethod\n    def print_info(mse):\n        print(\"Mean Squared Error: \", mse)\n        \n        \n    # Linear Regression \n    def linear_regression(self, x_train, X_test,  y_train, y_test):\n        reg = linear_model.LinearRegression()\n        reg.fit(self.x_train, self.y_train)\n        y_pred_list = reg.predict(self.X_test)\n        mse = mean_squared_error(self.y_test, y_pred_list)\n        print(\"\\nLinear Regression Model\")\n        self.print_info(mse)\n        return  mse\n        \n\n    def random_forest(self, x_train, X_test,  y_train, y_test):\n        rfr = RandomForestRegressor(n_estimators=8, max_depth=8, random_state=0, verbose=0)\n     \n        rfr.fit(self.x_train, self.y_train)\n        y_pred_list = rfr.predict(self.X_test)\n        mse = mean_squared_error(self.y_test, y_pred_list)\n        print(\"\\nRandom Forest Regressor\")\n        self.print_info(mse)\n        return  mse\n            \n    # Lasso method \n    def lasso(self, x_train, X_test,  y_train, y_test):\n        reg = linear_model.Lasso(alpha = 0.1)\n        reg.fit(self.x_train, self.y_train)\n        y_pred_list = reg.predict(self.X_test)\n        mse = mean_squared_error(self.y_test, y_pred_list)\n\n        print(\"\\nLasso Regression Model\")\n        self.print_info(mse)\n        return  mse\n    \n    # Gradient Boosing Regressor\n    def GBR(self, x_train, X_test,  y_train, y_test):\n        gbr = GradientBoostingRegressor(n_estimators=175, learning_rate=0.08, max_depth=3, random_state=0, loss='ls')\n        gbr.fit(self.x_train, self.y_train)\n        mse = mean_squared_error(self.y_test, gbr.predict(self.X_test))\n        print('\\nGradient Boosting Regressor')\n        self.print_info(mse)\n        return  mse\n","38b41412":"from types import FunctionType\n\n\nmethods = [x for x, y in Models.__dict__.items() if type(y) == FunctionType]\nmethods.remove('__init__')\n# Now calling the all regression methods\nmse_list = []\nfor model in methods:\n    reg = Models(x_train, X_test, y_train, y_test)\n    mse = getattr(reg, model)(x_train, X_test, y_train, y_test)\n\n    mse_list.append(mse)\n","67614a03":"# # Plot Mean Squared Error\n\nplt.plot(mse_list, c='b')\nplt.title('Comparision of Algorithms')\nplt.ylabel('Mean Squared Error')\nx = np.array([0,1,2,3])\nplt.scatter(x, mse_list, c='r', marker=\"s\")\nplt.xticks(x, methods)\nplt.show()","ecb31496":"import eli5\nfrom eli5.sklearn import PermutationImportance\nreg = linear_model.LinearRegression().fit(x_train, y_train)\nperm = PermutationImportance(reg, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist(), top=5)","48cb00e2":"plt.figure(figsize=(12,6))\nexplode = (0, 0.1, 0.2, 0.3, 0.4, 0, 0.5, 0.6)\ndf.groupby('Country')['TotalPurchases'].sum().sort_values(ascending=False).plot(kind='pie',autopct = '%1.1f%%',explode = explode)\nplt.title('Total purchases in each country');","dc53377d":"df=df.assign(\n    gold_amount = lambda df: df['MntGoldProds'].map(lambda MntGoldProds:'Aboveavg' if MntGoldProds >=df['MntGoldProds'].mean() else 'Belowavg') \n)","2d93f02c":"sns.boxplot(x='gold_amount',y='TotalPurchases',data=df);","9d81f4a6":"plt.figure(figsize=(12,6))\ndf.groupby([\"Education\",'Marital_Status'])['MntFishProducts'].sum().sort_values(ascending=False).plot(kind='bar')\nplt.title('Amount of fish purchase by people');","ca86cf25":"corr_with_SalePrice = Data.corr()\nplot_data = corr_with_SalePrice[\"MntFishProducts\"].sort_values(ascending=True)\nplt.figure(figsize=(12,6))\nplot_data.plot.bar()\nplt.title(\"Correlations with the MntFishProducts\")\nplt.show()","dcb6e19a":"a=['AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1','AcceptedCmp2']\n\nfor i in a:\n    data1 = Data[i]\n    data2 = df['Country']\n    \n   \n    coef, p = spearmanr(data1, data2)\n    print('Correlation coefficient: %.3f' % coef)\n    # interpret the significance\n    alpha = 0.05\n    if p > alpha:\n        print('{0} and {1} are uncorrelated (fail to reject H0) p={2}\\n' .format(i,'Country',p))\n       \n    else:\n        print('Samples are correlated (reject H0) p=%.3f' % p)","050620ed":"<a id=\"5\"><\/a> <br>\n### **Does US fare significantly better than the Rest of the World in terms of total purchases?**\n* From the graph, we can clearly see that the US is on second last ranked in terms of total purchases.","1254d89d":"<a id=\"3\"><\/a> <br>\n# Do you notice any patterns or anomalies in the data? Can you plot them?","73b5470b":"### The Total Amount of each product spent","c87bacc6":"<a id=\"1\"><\/a> <br>\n\n### **1. Are there any null values or outliers? How will you wrangle\/handle them?**","8855377e":"# Regression Models Analysis & Prediction \nNow, we take the cleaned data  and carry out prediction analysis with different regression methods from sklearn-library. We will compare the accuracy of different regression methods with  mean squared error.","da3dd97c":"Total purchases vs Income","a1f63f59":"We can see that the martial_status has outliers (alone, absurd, Yolo) as there are only seven records. Therefore, we will simply exclude these outliers from our data.","237c788e":"Finding :\nThe Year_Birth column contains three anomalies, so we'll simply drop these records","32d5d81e":"## significant features","d7b6f616":"From the above qqplot we see that one person has an income of over 600,000  which is an anomaly.Since it's a single record, I'll simply delete it.","0c6e4c7a":"From boxplot we can see that  people who spent an below average amount on gold have less in store purchases.So it means that the given statement is correct.+4\n","cea1d0b5":"### Outliers & Anomalies\nFrom the graphs , it is clear that multiple features contain outliers but income and births may indicate data entry error","4cfb5128":"# Section 02: Statistical Analysis\nPlease run statistical tests in the form of regressions to answer these questions & propose data-driven action recommendations to your CMO. Make sure to interpret your results with non-statistical jargon so your CMO can understand your findings.\n\n1. [What factors are significantly related to the number of store purchases?](#4)\n2. [Does US fare significantly better than the Rest of the World in terms of total purchases?](#5)\n3. [Your supervisor insists that people who buy gold are more conservative. Therefore, people who spent an above average amount on gold in the last 2 years would have more in store purchases. Justify or refute this statement using an appropriate statistical test](#6)\n4. [Fish has Omega 3 fatty acids which are good for the brain. Accordingly, do \"Married PhD candidates\" have a significant relation with amount spent on fish? What other factors are significantly related to amount spent on fish? (Hint: use your knowledge of interaction variables\/effects)](#7)\n5. [Is there a significant relationship between geographical regional and success of a campaign?](#8)","9df17845":"### purchases  vs age group","3e6560b8":"<a id=\"8\"><\/a> <br>\n### **Is there a significant relationship between geographical regional and success of a campaign?**\n\nFrom the analysis we can see that the success of a campaign has no relation to country.","2a03fe8a":"### Numeric Data Distribution","ca18c879":"We can see the correlation of numerical columns\/decorations on 'NumStorePurchases'. The columns that have clear correlation (high positive or high negative) are important for the prediction model, but few of those with small (about zero) correlation will not have much effect on the 'SalePrice', therefore, we can still drop few of them.","558961b3":"<a id=\"4\"><\/a> <br>\n# Section 02: Statistical Analysis\n### What factors are significantly related to the number of store purchases?\nLet us plot heatplot diagrams to see the correlation of the numeric variables on the store purchases","90443ef4":"<a id=\"2\"><\/a> <br>\n### **Are there any useful variables that you can engineer with the given data?**","bedb49a9":"<a id=\"6\"><\/a> <br>\n### **Your supervisor insists that people who buy gold are more conservative. Therefore, people who spent an above average amount on gold in the last 2 years would have more in store purchases. Justify or refute this statement using an appropriate statistical test**","3d328d5e":"<a id=\"7\"><\/a> <br>\n### **Fish has Omega 3 fatty acids which are good for the brain. Accordingly, do \"Married PhD candidates\" have a significant relation with amount spent on fish? What other factors are significantly related to amount spent on fish? (Hint: use your knowledge of interaction variables\/effects)**\n* From the graph we can see that Married PhD customers does not have a significant relationship with the amount spent on fish.","342d9c28":"### **products amount vs age group**","59dcf30b":"## Feature Engineering\nWith the help of given features we can drive some important variables like:\n\n1. The total number of kid in the home can be calculated from the sum of \u201cKidhome\u201d and \u201cTeenhome\u201d.\n1. The total amount spent can be calculated from the sum of all features that containing the Mnt keyword.\n1. The total number of purchases can be calculated from the sum of all features containing the keyword \"Purchases\".\n1. The total number of campains accepted can be calculated from the sum of all features containing the keyword \"Cmp\".\n1. From Dt_Customer we can find The year of becoming a customer\n1. From Year_Birth we can derive Age","51479414":"Now we will change the categorical variables to numerical ones by using LabelEncoder for the regression models","b099d310":"### **The number of purchases through the Each channels**\nPlot represent that most customer buy product from store.","f41fd2bb":"**Cleaning Data**\n1. Income column change to numeric\n1. Dt_Customer has string data type, we have to change it type to date\n","6fbf3772":"Based on the graph, the factors that are significantly related to the amount spent on fish are:'TotalMNt', 'MntSweetProducts', 'MntFruits', 'MntMeatProducts', 'NumCatalogPurchases', 'MntGoldProds' and 'Country_ME'.","74f2ab4a":"### Income versus the quantity of products purchased\n","077412b0":"# Section 01: Exploratory Data Analysis\n1. [ Are there any null values or outliers? How will you wrangle\/handle them?](#1)\n1.  Are there any variables that warrant transformations?\n1. [ Are there any useful variables that you can engineer with the given data?](#2)\n1. [ Do you notice any patterns or anomalies in the data? Can you plot them?](#3)\n","b5766005":"Findings\n1. Almost 50% of clients' education level is graduate, and few customers have an primary level of education.\n1. The number of married clients is more than widow and divorce.\n1. There is a remarkably high percentage of customers in Spain while the percentage of clients in the United States and Montenegro is very small.\n1. There is a very high percentage of clients between 39 to 59 years old compared to other age groups","cde9f8c0":"# Total spending\nFindings\n* People with PhDs used to spend more than other group of people\n* Total spending of divorced, single, and married group members is roughly equal while widows spending is slightly higher than these individuals. \n* People who have no children spend more money than people who have children\n* Montenegro spends significantly more than other countries.","c6bd695f":"Let us now look at the 'NumStorePurchases' variation on different categories of categorical variables\/columns.","96c1a2fc":"## Handling Outliers","0582a87f":"As we can see that from the above plot, we have null values in Income column","72f0376a":"### Correlation with NumStorePurchases\nLet us check the correlation of numerical variables with NumStorePurchases."}}