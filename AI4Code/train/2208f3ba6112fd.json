{"cell_type":{"f14eddc9":"code","e4b6c001":"code","d074382d":"code","eed6fa4d":"code","56f38fe0":"code","4e9a70f0":"code","fc3d4085":"code","d6c99752":"code","33105ddc":"code","7b590f90":"code","730d725a":"code","8a22c8b4":"code","db73c2f9":"code","5d4c1583":"code","e2f16495":"code","b6236794":"code","a4497284":"code","4d5fad93":"code","0e2828df":"code","32494c17":"code","23fd1780":"code","14a7d5ba":"code","64ce478c":"code","cafbd1ab":"code","54abb2dd":"code","6505188f":"code","2772cc07":"code","fc50eee0":"code","d50225b3":"code","e173f60b":"code","56d38bff":"code","40474b19":"code","dee473fa":"code","e2777082":"code","42eb4cf5":"code","6ed39b9c":"code","cef866e0":"code","86dbfcaa":"code","bd80099f":"code","155b0ec3":"code","dd94a195":"code","a19b5ad3":"code","23e8cf41":"code","59c857cc":"code","1e66002b":"code","bfcd0c1f":"code","ad2a4c3d":"code","64214083":"code","60f73432":"code","90ec3459":"code","b1adf6ff":"code","8eaa4af1":"code","28a911c2":"code","bfbc7d19":"code","8a064885":"code","99c87c7f":"code","38ca443a":"code","0021d149":"code","95a11275":"code","4b107d39":"code","77a2da53":"code","5808f37d":"code","ed4f8ca4":"code","bca61e78":"code","14c2789a":"code","01e27d3f":"code","a7598ed2":"code","131a8f9d":"code","2c057f47":"code","f6281d45":"code","996ec795":"code","e170d8c0":"code","4af35d94":"code","e2c6fb89":"markdown","f7b7df3e":"markdown","ea475296":"markdown","736f9a23":"markdown","00353375":"markdown","e87a311c":"markdown","077a2737":"markdown","e06f6881":"markdown","425da487":"markdown","87e52606":"markdown","199aede9":"markdown","3cc83eb3":"markdown","c54b3d0b":"markdown","2375ab1a":"markdown","01faf967":"markdown","523b205a":"markdown","9530ab87":"markdown","0b42a743":"markdown","1d3f9a14":"markdown","229dd9a3":"markdown","1cf3652f":"markdown","768b91d0":"markdown","6bfea74b":"markdown","ce053dce":"markdown","15416898":"markdown","51d5b24c":"markdown","51c23418":"markdown","866461ef":"markdown","b2505a0f":"markdown","74fbc9f1":"markdown","a6246db0":"markdown","8ef36beb":"markdown","e3ebfe45":"markdown","d530f034":"markdown","f8cf33b7":"markdown","608a59d6":"markdown","47eb2ff1":"markdown","d6d97570":"markdown","b2cb2b2d":"markdown","d60b6eea":"markdown","d5a6b835":"markdown","0f1d1f35":"markdown","f0a5ade5":"markdown","b0677cf0":"markdown","085a70cc":"markdown","bcd60849":"markdown","69ee9189":"markdown","a80171bf":"markdown","81d3f308":"markdown","9b651e9b":"markdown","8ead71dc":"markdown","99ef48ea":"markdown","588b0afe":"markdown","32a65c8e":"markdown","ecab7683":"markdown","e288e8f2":"markdown","69c49803":"markdown","c40a33e9":"markdown","a6777bb8":"markdown","22d4230f":"markdown","97aef1c9":"markdown","5034c70e":"markdown","a7977ff0":"markdown","a4e5c951":"markdown","7a518ffa":"markdown","00c2600b":"markdown","d167bc8c":"markdown","6ff2a521":"markdown","0f9db26f":"markdown","58468d4b":"markdown"},"source":{"f14eddc9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings \nwarnings.filterwarnings('ignore')\n%matplotlib inline","e4b6c001":"csv_filename = \"\/kaggle\/input\/mental-health-in-tech-survey\/survey.csv\"\ndf = pd.read_csv(csv_filename)\ndf.head()","d074382d":"df.info() # basic information, data type","eed6fa4d":"raw_data = df.copy() # checkpoint\n\n# missing values\nnull_count = df.isnull().sum().sort_values(ascending=False)\nnull_percent = null_count\/len(df.index)*100\nnull_summary = pd.concat([null_count, null_percent], axis = 1, keys = [\"Count\", \"Percentage\"])\nprint(\"Missing value count and percentage: \")\nprint(null_summary)","56f38fe0":"# drop comments column\ndf = df.drop(\"comments\",axis = 1)","4e9a70f0":"# explore Country variable\ncountry_count = df.Country.value_counts()\ncountry_percent = country_count\/len(df.index)*100\ncountry_summary = pd.concat([country_count, country_percent], axis = 1, keys = [\"Count\", \"Percentage\"])\nprint(\"Country value count and percentage: \")\nprint(country_summary)","fc3d4085":"df.state.unique() # explore state variables","d6c99752":"# drop Country and state\ndf.drop([\"Country\", \"state\"],axis = 1, inplace = True)","33105ddc":"df[\"work_interfere\"].value_counts(normalize = True)","7b590f90":"df[\"work_interfere\"] = df[\"work_interfere\"].fillna(\"Don't know\")\ndf[\"work_interfere\"].value_counts(normalize = True)","730d725a":"def plot_percentage_group(data, feature, target, order = None, figsize = (10,5), palette = \"Blues\"): # plot percentage, count answers to \"treatment\" in each group\n    feature_percentage = data[feature].value_counts(normalize = True).rename_axis(feature).reset_index(name = \"Percentage\")\n    plt.figure(figsize = figsize)\n    plt.subplot(1,2,1)\n    sns.barplot(x=feature, y=\"Percentage\", data = feature_percentage, palette = palette)\n    plt.subplot(1,2,2)\n    plt.title(feature + \" by \" + target)\n    sns.countplot(data[feature], hue = df[target], order =order,palette = palette)","8a22c8b4":"plot_percentage_group(df, \"work_interfere\", \"treatment\", order =[\"Don't know\",\"Never\",\"Rarely\",\"Sometimes\",\"Often\"]) ","db73c2f9":"df[\"self_employed\"].value_counts(normalize = True)","5d4c1583":"df[\"self_employed\"] = df[\"self_employed\"].fillna(\"No\")\ndf[\"self_employed\"].value_counts(normalize = True)","e2f16495":"null_count = df.isnull().sum().sort_values(ascending=False)\nnull_percent = null_count\/len(df.index)*100\nnull_summary = pd.concat([null_count, null_percent], axis = 1, keys = [\"Count\", \"Percentage\"])\nprint(\"Missing value count and percentage: \")\nprint(null_summary)","b6236794":"for col in df.columns:\n    print(col, end= ': ')\n    print(df[col].unique())","a4497284":"print(df[\"Age\"][df[\"Age\"]<14].count())\nprint(df[\"Age\"][df[\"Age\"]>100].count())","4d5fad93":"df.drop(df[df[\"Age\"]<14].index, inplace = True)\ndf.drop(df[df[\"Age\"]>100].index, inplace = True)\ndf[\"Age\"].unique()","0e2828df":"df[\"Gender\"].value_counts()","32494c17":"df[\"Gender\"].unique()","23fd1780":"male_group = ['M', 'Male', 'male', 'm', 'Male-ish', 'maile','Cis Male', \n              'Mal', 'Male (CIS)',  'Make', 'Male ', 'Man', 'msle', \n              'Mail', 'cis male', 'Malr', 'Cis Man']\nfemale_group = ['Female', 'Female ','female','Cis Female', 'F', 'Woman', 'f','woman', \n                'Femake', 'cis-female\/femme', 'Female (cis)', 'femail']\nother_group = ['Trans-female','non-binary', 'Nah', 'Enby', 'fluid', 'Genderqueer', \n               'Androgyne', 'Agender', 'Guy (-ish) ^_^', 'Neuter',\n               'queer', 'queer\/she\/they','Trans woman',\n               'Female (trans)','male leaning androgynous', \n               'ostensibly male, unsure what that really means',\n               'something kinda male?']\ntotal_words = len(male_group) + len(female_group) + len(other_group)\nassert(total_words == len(df[\"Gender\"].unique())) # to make sure all words are categorized\n\ndf[\"Gender\"].replace(male_group,\"Male\",inplace=True)\ndf[\"Gender\"].replace(female_group,\"Female\",inplace=True)\ndf[\"Gender\"].replace(other_group,\"Others\",inplace=True)\ndf[\"Gender\"].value_counts()","14a7d5ba":"df.drop(\"Timestamp\", axis = 1, inplace = True)\ndf.columns","64ce478c":"df= df.reset_index(drop=True)\nfor col in df.columns:\n    print(col, end= ': ')\n    print(df[col].unique())\ndata_cleaned = df.copy() # checkpoint","cafbd1ab":"treatment_percentage = df[\"treatment\"].value_counts(normalize = True).rename_axis(\"treatment\").reset_index(name = \"Percentage\")\nplt.figure(figsize = (5,5))\nplt.title(\"Have you sought treatment for a mental health condition?\")\nsns.barplot(x = \"treatment\", y = \"Percentage\", data = treatment_percentage)","54abb2dd":"plt.figure(figsize = (10,5))\nplt.subplot(1,2,1)\nsns.histplot(x=\"Age\", data = df, kde = True)\nplt.subplot(1,2,2)\nplt.title(\"Age distribution by treatment\")\nsns.boxplot(x= df[\"Age\"], y = df[\"treatment\"])\nprint(df[\"Age\"].describe())\nprint(\"Skewness = %.2f\"%(df[\"Age\"].skew()))\ndf.groupby(\"treatment\")[\"Age\"].mean()","6505188f":"for feature in [\"Gender\",\"family_history\"]:\n    plot_percentage_group(df, feature, \"treatment\")","2772cc07":"plot_percentage_group(df, \"work_interfere\", \"treatment\", order =[\"Don't know\",\"Never\",\"Rarely\",\"Sometimes\",\"Often\"])","fc50eee0":"for feature in [\"self_employed\",\"remote_work\",\"tech_company\"]:\n    plot_percentage_group(df, feature, \"treatment\", figsize=(10,3))","d50225b3":"plot_percentage_group(df, \"no_employees\", \"treatment\", order = ['1-5', '6-25', '26-100', '100-500', '500-1000','More than 1000'],figsize=(15,5))","e173f60b":"for feature in [\"benefits\", \"care_options\", \"wellness_program\", \"seek_help\", \"anonymity\"]:\n    plot_percentage_group(df, feature, \"treatment\", figsize=(10,3))","56d38bff":"plot_percentage_group(df, \"leave\", \"treatment\", order =[\"Don't know\",'Very easy','Somewhat easy', 'Somewhat difficult', 'Very difficult'],figsize=(20,3))","40474b19":"for feature in [\"mental_health_consequence\", \"phys_health_consequence\", \"coworkers\", \n                \"supervisor\", \"mental_health_interview\",'phys_health_interview','mental_vs_physical','obs_consequence']:\n    plot_percentage_group(df, feature, \"treatment\", figsize=(10,3))","dee473fa":"yes_no_features = ['self_employed', 'family_history', 'treatment',\n                   'remote_work', 'tech_company','obs_consequence'] # these answers only contain \"Yes\" or \"No\", can be easily mapped to [0,1]\nyes_no_unknown_features = ['benefits','wellness_program','seek_help','anonymity','mental_vs_physical'] \nyes_no_maybe_features = ['mental_health_consequence','phys_health_consequence','mental_health_interview','phys_health_interview']\nyes_no_someofthem_features = ['coworkers','supervisor'] # these answers have intermediate level between \"yes\" and \"No\"\nonehot_features=['Gender', 'leave','work_interfere'] # these answers containe non-ordinal answers, use one-hot encoding\n\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n\n#df=data_cleaned.copy()\n\nordinal_encoder = OrdinalEncoder(categories=[['No', 'Yes']])\nfor feature in yes_no_features:\n    df[feature] = pd.Series(ordinal_encoder.fit_transform(df.loc[:,[feature]]).squeeze())\n\nordinal_encoder = OrdinalEncoder(categories=[['No', \"Don't know\", 'Yes']])\nfor feature in yes_no_unknown_features:\n    df[feature] = pd.Series(ordinal_encoder.fit_transform(df.loc[:,[feature]]).squeeze())\n    \nordinal_encoder = OrdinalEncoder(categories=[['No', 'Maybe', 'Yes']]) \nfor feature in yes_no_maybe_features:\n    df[feature] = pd.Series(ordinal_encoder.fit_transform(df.loc[:,[feature]]).squeeze())\n\nordinal_encoder = OrdinalEncoder(categories=[['No', 'Some of them', 'Yes']])\nfor feature in yes_no_someofthem_features:\n    df[feature] = pd.Series(ordinal_encoder.fit_transform(df.loc[:,[feature]]).squeeze())\n\nordinal_encoder = OrdinalEncoder(categories=[['No', \"Not sure\", 'Yes']])\ndf[\"care_options\"] = pd.Series(ordinal_encoder.fit_transform(df.loc[:,[\"care_options\"]]).squeeze())\n\nordinal_encoder = OrdinalEncoder(categories=[['1-5', '6-25', '26-100', '100-500', '500-1000','More than 1000']]) # ordered\ndf[\"no_employees\"] = pd.Series(ordinal_encoder.fit_transform(df.loc[:,[\"no_employees\"]]).squeeze())\n\nonehot_encoder = OneHotEncoder()#drop='first')\nonehot_encoded = onehot_encoder.fit_transform(df.loc[:,onehot_features]).toarray()\nnewfeature = onehot_encoder.get_feature_names(onehot_features)\ndf[newfeature] = pd.DataFrame(onehot_encoded)","e2777082":"df_all_variable = df.copy() # checkpoint\ndf.drop(columns= onehot_features,inplace=True) # drop original feature after one-hot encoding\ndf","42eb4cf5":"# all numeric data\nfor col in df.columns:\n    print(col, end=\": \")\n    print(df[col].unique())","6ed39b9c":"corr_mat = df.corr() # pairwise correlation\nmask = np.zeros_like(corr_mat, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True # mask upper triangle of the matrix\nplt.figure(figsize = (12,12))\nsns.heatmap(corr_mat, mask = mask, vmin = -.3, vmax=.3, square=True)","cef866e0":"# correlation with \"treatment\"\ncorr_treatment = corr_mat['treatment'].sort_values(ascending=False).to_frame().T\nplt.subplots(figsize=(25,1))\nsns.heatmap(corr_treatment, vmin = -.3, vmax=.3, annot=True)\n#plt.plot(corr_treatment.columns,corr_treatment.to_numpy().squeeze())","86dbfcaa":"k = 10 #top k correlations (including treatment), actually k-1\ncols = corr_mat.nlargest(k, 'treatment')['treatment'].index\ntreatment_corr = df[cols].corr()\nmask = np.zeros_like(treatment_corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nplt.figure(figsize = (8,8))\nsns.heatmap(treatment_corr,mask = mask, vmin = -.3, vmax=.3, square=True, annot=True, annot_kws={'size': 10})\n\nfeature_names = df.drop(\"treatment\", axis = 1).columns\ncols = cols[1:]\ncorr_features = pd.DataFrame(np.zeros((1,len(df.columns)-1)), columns = feature_names, index = [\"corr\"])\ncorr_features[cols]=1","bd80099f":"X = df.drop(columns = [\"treatment\"])\ny = df[\"treatment\"]","155b0ec3":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","dd94a195":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, stratify = y, random_state=10) # stratified","a19b5ad3":"# minimize the objective over the space\nfrom hyperopt import hp\nfrom hyperopt import fmin, tpe, space_eval, Trials\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix,roc_curve, roc_auc_score, accuracy_score, f1_score","23e8cf41":"def objective(params): # loss function for hyperparameter optimization\n    model = params.pop(\"model\")\n    clf = model(**params)\n    clf.fit(X_train, y_train)\n    return -np.mean(cross_val_score(clf, X_train, y_train, cv=5)) # cross validation\n\ndef evaluate_model(space, best): # evaluate model: prediction scores: accuracy, f1 score, confusion matrix, auc score etc.\n    opt_para = space_eval(space, best)\n    model = opt_para.pop(\"model\")\n    clf = model(**opt_para)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    f1_score_ = f1_score(y_test,y_pred)\n    report = classification_report(y_test, y_pred, target_names = ('No','Yes'))\n    conf_mat = confusion_matrix(y_test,y_pred, labels = [0,1])\n    fpr, tpr, threshold = roc_curve(y_test, y_pred)\n    #auc_score = auc(fpr, tpr)\n    auc_score = roc_auc_score(y_test, y_pred)\n    model_dict={}\n    model_dict[\"model\"]=clf\n    model_dict[\"para\"]=opt_para\n    model_dict[\"y_pred\"]=y_pred\n    model_dict[\"accuracy\"]=accuracy\n    model_dict[\"f1_score\"]=f1_score_\n    model_dict[\"report\"]=report\n    model_dict[\"conf_mat\"]=conf_mat\n    model_dict[\"fpr\"]=fpr\n    model_dict[\"tpr\"]=tpr\n    model_dict[\"threshold\"]=threshold\n    model_dict[\"auc_score\"]=auc_score\n    return model_dict   \n\ndef trial_ana(trials, para_keys): # read scores and parameters for each iterative trials\n    scores = []\n    params = {}\n    for k in para_keys:\n        params[k]=[]\n    for t in trials:\n        scores.append(-t[\"result\"][\"loss\"])\n        for k in para_keys:\n            params[k].append(t[\"misc\"][\"vals\"][k][0])\n    return scores, params","59c857cc":"score_name = [\"cv_score\",\"pred_score\",\"auc_score\",\"f1_score\"]\n\n# hyperparameter space\nfrom sklearn.linear_model import LogisticRegression\nlr_space = {\"model\":LogisticRegression,\n         \"C\": hp.uniform(\"C\",0.1,1),\n         \"l1_ratio\":hp.uniform(\"l1_ratio\",0.1,1),\n         \"solver\": \"saga\",\n         \"penalty\" : \"elasticnet\",\n         \"random_state\" : 10\n        }\ntrials = Trials() # record each trial\nbest = fmin(objective, lr_space, algo=tpe.suggest, max_evals=200, trials = trials) # find best hyperparameters\nbest_para = space_eval(lr_space, best) # best parameters\nlr_cv_score= -objective(best_para) # cross validation score with best parameters\nprint(best_para)","1e66002b":"lr_para_keys = [\"C\",\"l1_ratio\"]    # hyperparameters tuning\nscores, params = trial_ana(trials, lr_para_keys) # cross-validation score and hyperparameters for each trial\n\n# visualize score trial by trial, score map in hyperprameter space\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.plot(scores)\nplt.xlabel(\"Trials\")\nplt.ylabel(\"Cross-validation-score\")\nplt.title(\"Cross-val-score by trials\")\n\nplt.subplot(1,2,2)\nplt.scatter(x=params[\"C\"],y=params[\"l1_ratio\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"C\")\nplt.ylabel(\"l1 ratio\")\nplt.title(\"Cross-val-score vs. Hyperparameters\")","bfcd0c1f":"lr_clf_dict  = evaluate_model(lr_space, best)\nfor metrics, value in lr_clf_dict.items():\n    if metrics ==\"y_pred\":\n        continue\n    print(metrics, end = \":\\n\")\n    print(value)\nplt.plot(lr_clf_dict[\"fpr\"], lr_clf_dict[\"tpr\"])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nlr_model_scores= pd.DataFrame([[lr_cv_score,lr_clf_dict[\"accuracy\"],lr_clf_dict[\"auc_score\"],\n                                   lr_clf_dict[\"f1_score\"]]],index =[\"LogisticRegression\"], columns =score_name )\nlr_model_scores","ad2a4c3d":"# coeficient for each feature\nsortind_coef = np.argsort(abs(lr_clf_dict[\"model\"].coef_[0]))[::-1]\nsorted_coef = np.expand_dims(lr_clf_dict[\"model\"].coef_[0][sortind_coef],axis=0)\ncoef_df = pd.DataFrame(data = sorted_coef,columns = feature_names[sortind_coef])\nplt.subplots(figsize=(25, 1))\nsns.heatmap(coef_df, vmin = -.3, vmax=.3, annot=True)\n\n# select top 9 features if >0\nlr_features = pd.DataFrame(np.zeros((1,len(df.columns)-1)), columns = feature_names, index = [\"LogisticRegression\"])\nbool_feature= abs(sorted_coef)>0\ntmp = sortind_coef[bool_feature.squeeze()]\nsel_len = min(9, len(tmp))\nlr_features[feature_names[sortind_coef[:sel_len]]]=1","64214083":"from sklearn.neighbors import KNeighborsClassifier\nknn_space = {\"model\":KNeighborsClassifier,\n         \"n_neighbors\": hp.choice(\"n_neighbors\",list(range(3,40))),\n         'weights':hp.choice(\"weights\",[\"uniform\",\"distance\"]),\n        }\ntrials = Trials()\nbest = fmin(objective, knn_space, algo=tpe.suggest, max_evals=200, trials = trials)\nbest_para = space_eval(knn_space, best)\nknn_cv_score = -objective(best_para)\nprint(best_para)","60f73432":"para_keys = [\"n_neighbors\",\"weights\"]   \nscores, params = trial_ana(trials, para_keys)\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.plot(scores)\nplt.xlabel(\"Trials\")\nplt.ylabel(\"Cross-validation-score\")\nplt.title(\"Cross-val-score by trials\")\nplt.subplot(1,2,2)\nparams[\"weights\"][params[\"weights\"]==\"distance\"]=1\nparams[\"weights\"][params[\"weights\"]==\"uniform\"]=0\nplt.scatter(x=params[\"n_neighbors\"],y=params[\"weights\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"n_neighbors\")\nplt.ylabel(\"weights\")\nplt.title(\"cv-score vs. Hyperparameters\")","90ec3459":"knn_clf_dict  = evaluate_model(knn_space, best)\nfor metrics, value in knn_clf_dict.items():\n    if metrics ==\"y_pred\":\n        continue\n    print(metrics, end = \":\\n\")\n    print(value)\nplt.plot(knn_clf_dict[\"fpr\"], knn_clf_dict[\"tpr\"])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nknn_model_scores=pd.DataFrame([[knn_cv_score,knn_clf_dict[\"accuracy\"],knn_clf_dict[\"auc_score\"],\n                                   knn_clf_dict[\"f1_score\"]]],index =[\"KNeighborsClassifier\"], columns =score_name )\nknn_model_scores","b1adf6ff":"from sklearn.tree import DecisionTreeClassifier\ndt_space = {\"model\":DecisionTreeClassifier,\n         \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n         \"splitter\":hp.choice(\"splitter\", [\"best\", \"random\"]),\n         \"max_depth\": hp.quniform(\"max_depth\",3, 12,1),\n         \"min_samples_split\":hp.choice('min_samples_split',list(range(2,10))),\n         \"min_samples_leaf\":hp.choice('min_samples_leaf',list(range(1,10))),\n         \"random_state\": 10\n        }\ntrials = Trials()\nbest = fmin(objective, dt_space, algo=tpe.suggest, max_evals=200, trials = trials)\nbest_para = space_eval(dt_space, best)\ndt_cv_score = -objective(best_para)\nprint(best_para)","8eaa4af1":"para_keys = [\"max_depth\",\"criterion\",\"splitter\",\"min_samples_split\",\"min_samples_leaf\"]   \nscores, params = trial_ana(trials, para_keys)\nparams[\"criterion\"][params[\"criterion\"]==\"gini\"]=1\nparams[\"criterion\"][params[\"criterion\"]==\"entropy\"]=0\nparams[\"splitter\"][params[\"splitter\"]==\"best\"]=1\nparams[\"splitter\"][params[\"splitter\"]==\"random\"]=0\n\nplt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nplt.plot(scores)\nplt.xlabel(\"Trials\")\nplt.ylabel(\"Cross-validation-score\")\nplt.title(\"Score by trials\")\n\nplt.subplot(2,2,2)\nplt.scatter(x=params[\"max_depth\"],y=params[\"criterion\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"criterion\")\nplt.title(\"Score vs. Hyperparameters\")\n\nplt.subplot(2,2,3)\nplt.scatter(x=params[\"max_depth\"],y=params[\"splitter\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"splitter\")\nplt.title(\"Score vs. Hyperparameters\")\n\nplt.subplot(2,2,4)\nplt.scatter(x=params[\"min_samples_split\"],y=params[\"min_samples_leaf\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"min_samples_split\")\nplt.ylabel(\"min_samples_leaf\")\nplt.title(\"Score vs. Hyperparameters\")","28a911c2":"dt_clf_dict  = evaluate_model(dt_space, best)\nfor metrics, value in dt_clf_dict.items():\n    if metrics ==\"y_pred\":\n        continue\n    print(metrics, end = \":\\n\")\n    print(value)\nplt.plot(dt_clf_dict[\"fpr\"], dt_clf_dict[\"tpr\"])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\n\ndt_model_scores=pd.DataFrame([[dt_cv_score,dt_clf_dict[\"accuracy\"],dt_clf_dict[\"auc_score\"],dt_clf_dict[\"f1_score\"]]],\n                           index =[\"DecisionTreeClassifier\"], columns =score_name )\ndt_model_scores","bfbc7d19":"sortind_dt_feat_imp = np.argsort(dt_clf_dict[\"model\"].feature_importances_)[::-1]\nsorted_dt_feat_imp = np.expand_dims(dt_clf_dict[\"model\"].feature_importances_[sortind_dt_feat_imp],axis=0)\ndt_feat_imp_df = pd.DataFrame(data = sorted_dt_feat_imp,columns = feature_names[sortind_dt_feat_imp])\nplt.subplots(figsize=(25, 1))\nsns.heatmap(dt_feat_imp_df, vmin = 0, vmax=.3, annot=True)\n\n# select top 9 features if >0\ndt_features = pd.DataFrame(np.zeros((1,len(df.columns)-1)), columns = feature_names, index = [\"DecisionTreeClassifier\"])\nbool_feature= abs(sorted_dt_feat_imp)>0\ntmp = sortind_dt_feat_imp[bool_feature.squeeze()]\nsel_len = min(9, len(tmp))\ndt_features[feature_names[sortind_dt_feat_imp[:sel_len]]]=1","8a064885":"from sklearn.ensemble import RandomForestClassifier\nrf_space = {\"model\":RandomForestClassifier,\n         \"n_estimators\":hp.choice('n_estimators',np.arange(20,200,10)),\n         \"max_depth\": hp.quniform(\"max_depth\",2, 20,1),\n         \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n         \"min_samples_split\":hp.choice('min_samples_split',list(range(2,10))),\n         \"min_samples_leaf\":hp.choice('min_samples_leaf',list(range(1,10))),\n         \"oob_score\": True,\n         \"random_state\": 10\n        }\ntrials = Trials()\nbest = fmin(objective, rf_space, algo=tpe.suggest, max_evals=200, trials = trials)\nbest_para = space_eval(rf_space, best)\nrf_cv_score= -objective(best_para)\nprint(best_para)","99c87c7f":"para_keys = [\"n_estimators\",\"max_depth\",\"criterion\",\"min_samples_split\",\"min_samples_leaf\"]   \nscores, params = trial_ana(trials, para_keys)\nparams[\"criterion\"][params[\"criterion\"]==\"gini\"]=1\nparams[\"criterion\"][params[\"criterion\"]==\"entropy\"]=0\nn_estimator_range = np.arange(20,200,10)\n\n# visualize scores across trials and hyperparameter space\nplt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nplt.plot(scores)\nplt.xlabel(\"Trials\")\nplt.ylabel(\"Cross-validation-score\")\nplt.title(\"Cross-val-score by trials\")\n\nplt.subplot(2,2,2)\nplt.scatter(x=n_estimator_range[params[\"n_estimators\"]],y=params[\"max_depth\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"max_depth\")\nplt.title(\"Cross-val-score vs. Hyperparameters\")\n\nplt.subplot(2,2,3)\nplt.scatter(x=params[\"min_samples_split\"],y=params[\"min_samples_leaf\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"min_samples_split\")\nplt.ylabel(\"min_samples_leaf\")\nplt.title(\"Cross-val-score vs. Hyperparameters\")\n\nplt.subplot(2,2,4)\nplt.scatter(x=n_estimator_range[params[\"n_estimators\"]],y=params[\"criterion\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"criterion\")\nplt.title(\"Cross-val-score vs. Hyperparameters\")","38ca443a":"rf_clf_dict  = evaluate_model(rf_space, best)\nfor metrics, value in rf_clf_dict.items():\n    if metrics ==\"y_pred\":\n        continue\n    print(metrics, end = \":\\n\")\n    print(value)\nplt.plot(rf_clf_dict[\"fpr\"], rf_clf_dict[\"tpr\"])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nrf_model_scores=pd.DataFrame([[rf_cv_score,rf_clf_dict[\"accuracy\"],rf_clf_dict[\"auc_score\"],\n                             rf_clf_dict[\"f1_score\"]]],index =[\"RandomForestClassifier\"], columns =score_name )\nrf_model_scores","0021d149":"sortind_rf_feat_imp = np.argsort(rf_clf_dict[\"model\"].feature_importances_)[::-1]\nsorted_rf_feat_imp = np.expand_dims(rf_clf_dict[\"model\"].feature_importances_[sortind_rf_feat_imp],axis=0)\nfeat_rf_imp_df = pd.DataFrame(data = sorted_rf_feat_imp,columns = feature_names[sortind_rf_feat_imp])\nplt.subplots(figsize=(25, 1))\nsns.heatmap(feat_rf_imp_df, vmin = 0, vmax=.3, annot=True)\n\n# select top 9 features if >0\nrf_features = pd.DataFrame(np.zeros((1,len(df.columns)-1)), columns = feature_names, index = [\"RandomForestClassifier\"])\nbool_feature= abs(sorted_rf_feat_imp)>0\ntmp = sortind_rf_feat_imp[bool_feature.squeeze()]\nsel_len = min(9, len(tmp))\nrf_features[feature_names[sortind_rf_feat_imp[:sel_len]]]=1","95a11275":"from sklearn.ensemble import AdaBoostClassifier\nab_space = {\"model\":AdaBoostClassifier,\n         \"n_estimators\":hp.choice('n_estimators',np.arange(10,200,10)),\n         \"learning_rate\": hp.uniform(\"learning_rate\",0.1, 1),\n         \"random_state\": 10\n        }\ntrials = Trials()\nbest = fmin(objective, ab_space, algo=tpe.suggest, max_evals=200, trials = trials)\nbest_para = space_eval(ab_space, best)\nab_cv_score = -objective(best_para)\nprint(best_para)","4b107d39":"para_keys = [\"n_estimators\",\"learning_rate\"]   \nscores, params = trial_ana(trials, para_keys)\nn_estimator_range = np.arange(10,200,10)\nplt.figure(figsize=(10,2))\nplt.subplot(1,2,1)\nplt.plot(scores)\nplt.xlabel(\"Trials\")\nplt.ylabel(\"Cross-validation-score\")\nplt.title(\"Cross-val-score by trials\")\n\nplt.subplot(1,2,2)\nplt.scatter(x=n_estimator_range[params[\"n_estimators\"]],y=params[\"learning_rate\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"learning_rate\")\nplt.title(\"Cross-val-score vs. Hyperparameters\")","77a2da53":"ab_clf_dict  = evaluate_model(ab_space, best)\nfor metrics, value in ab_clf_dict.items():\n    if metrics ==\"y_pred\":\n        continue\n    print(metrics, end = \":\\n\")\n    print(value)\nplt.plot(ab_clf_dict[\"fpr\"], ab_clf_dict[\"tpr\"])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nab_model_scores=pd.DataFrame([[ab_cv_score,ab_clf_dict[\"accuracy\"],ab_clf_dict[\"auc_score\"],\n                                   ab_clf_dict[\"f1_score\"]]],index =[\"AdaBoostClassifier\"], columns =score_name )\nab_model_scores","5808f37d":"sortind_ab_feat_imp = np.argsort(ab_clf_dict[\"model\"].feature_importances_)[::-1]\nsorted_ab_feat_imp = np.expand_dims(ab_clf_dict[\"model\"].feature_importances_[sortind_ab_feat_imp],axis=0)\nab_feat_imp_df = pd.DataFrame(data = sorted_ab_feat_imp,columns = feature_names[sortind_ab_feat_imp])\nplt.subplots(figsize=(25, 1))\nsns.heatmap(ab_feat_imp_df, vmin = 0, vmax=.2, annot=True)\n\n# select top 9 features if >0\nab_features = pd.DataFrame(np.zeros((1,len(df.columns)-1)), columns = feature_names, index = [\"AdaBoostClassifier\"])\nbool_feature= abs(sorted_ab_feat_imp)>0\ntmp = sortind_ab_feat_imp[bool_feature.squeeze()]\nsel_len = min(9, len(tmp))\nab_features[feature_names[sortind_ab_feat_imp[:sel_len]]]=1","ed4f8ca4":"from sklearn.ensemble import GradientBoostingClassifier\ngb_space = {\"model\":GradientBoostingClassifier,\n         \"n_estimators\":hp.choice('n_estimators',np.arange(50,500,50)),\n         \"max_depth\":hp.choice('max_depth',list(range(2,10))),\n         \"learning_rate\": hp.loguniform(\"learning_rate\",np.log(1e-3), np.log(1e-1)),\n         \"subsample\": hp.uniform(\"subsample\",0.7,1),\n         \"min_samples_split\":hp.choice('min_samples_split',list(range(2,10))),\n         \"min_samples_leaf\":hp.choice('min_samples_leaf',list(range(1,10))),\n         \"random_state\": 10\n        }\ntrials = Trials()\nbest = fmin(objective, gb_space, algo=tpe.suggest, max_evals=200, trials = trials)\nbest_para = space_eval(gb_space, best)\ngb_cv_score = -objective(best_para)\nprint(best_para)","bca61e78":"para_keys = [\"n_estimators\",\"max_depth\",\"learning_rate\",\"subsample\",\"min_samples_split\",\"min_samples_leaf\"]   \nscores, params = trial_ana(trials, para_keys)\nn_estimator_range = np.arange(50,500,50)\n\nplt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.plot(scores)\nplt.xlabel(\"Trials\")\nplt.ylabel(\"Cross-validation-score\")\nplt.title(\"Score by trials\")\n\nplt.subplot(2,2,2)\nplt.scatter(x=n_estimator_range[params[\"n_estimators\"]],y=params[\"max_depth\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"max_depth\")\nplt.title(\"Score vs. Hyperparameters\")\n\nplt.subplot(2,2,3)\nax = plt.gca()\nax.scatter(x=params[\"learning_rate\"],y=params[\"subsample\"], c=scores)\nax.set_xscale('log')\nplt.colorbar()\nplt.xlabel(\"learning_rate\")\nplt.ylabel(\"subsample\")\nplt.title(\"Score vs. Hyperparameters\")\n\nplt.subplot(2,2,4)\nplt.scatter(x=params[\"min_samples_split\"],y=params[\"min_samples_leaf\"], c=scores)\nplt.colorbar()\nplt.xlabel(\"min_samples_split\")\nplt.ylabel(\"min_samples_leaf\")\nplt.title(\"Score vs. Hyperparameters\")","14c2789a":"gb_clf_dict  = evaluate_model(gb_space, best)\nfor metrics, value in gb_clf_dict.items():\n    if metrics ==\"y_pred\":\n        continue\n    print(metrics, end = \":\\n\")\n    print(value)\nplt.plot(gb_clf_dict[\"fpr\"], gb_clf_dict[\"tpr\"])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\ngb_model_scores=pd.DataFrame([[gb_cv_score,gb_clf_dict[\"accuracy\"],gb_clf_dict[\"auc_score\"],\n                                   gb_clf_dict[\"f1_score\"]]],index =[\"GradientBoostingClassifier\"], columns =score_name )\ngb_model_scores","01e27d3f":"sortind_gb_feat_imp = np.argsort(gb_clf_dict[\"model\"].feature_importances_)[::-1]\nsorted_gb_feat_imp = np.expand_dims(gb_clf_dict[\"model\"].feature_importances_[sortind_gb_feat_imp],axis=0)\ngb_feat_imp_df = pd.DataFrame(data = sorted_gb_feat_imp,columns = feature_names[sortind_gb_feat_imp])\nplt.subplots(figsize=(25, 1))\nsns.heatmap(gb_feat_imp_df, vmin = 0, vmax=.2, annot=True)\n\n# select top 9 features if >0\ngb_features = pd.DataFrame(np.zeros((1,len(df.columns)-1)), columns = feature_names, index = [\"GradientBoostingClassifier\"])\nbool_feature= abs(sorted_gb_feat_imp)>0\ntmp = sortind_gb_feat_imp[bool_feature.squeeze()]\nsel_len = min(9, len(tmp))\ngb_features[feature_names[sortind_gb_feat_imp[:sel_len]]]=1","a7598ed2":"model_scores = pd.concat([lr_model_scores, knn_model_scores, dt_model_scores, rf_model_scores, ab_model_scores, gb_model_scores])\nplt.subplots(figsize=(8, 5))\nsns.heatmap(model_scores, annot=True)","131a8f9d":"feature_counts = pd.concat([corr_features,lr_features, dt_features, rf_features, ab_features, gb_features])\nfeature_counts","2c057f47":"feature_counts.sum().sort_values(ascending=False)","f6281d45":"# top 12 highly voted features (vote>1)\nn_sel=12\nfeature_sel = feature_counts.sum().nlargest(n_sel).index\nfeature_sel","996ec795":"# dataset preparation\nX_feature_sel = df[feature_sel]\nfeature_names_sel = X_feature_sel.columns\n\nX_feature_sel = scaler.fit_transform(X_feature_sel) # Normalization\nX_train, X_test, y_train, y_test = train_test_split(X_feature_sel, y, test_size =0.2, stratify = y, random_state=10) # training, testing set split, stratified","e170d8c0":"# model tuning with feature selection\n\n# Logistic Regression\nbest = fmin(objective, lr_space, algo=tpe.suggest, max_evals=200, trials = Trials())\nbest_para = space_eval(lr_space, best)\nlr_cv_score_feature_sel= -objective(best_para) \nlr_clf_dict_feature_sel  = evaluate_model(lr_space, best)\nlr_model_scores_feature_sel = pd.DataFrame([[lr_cv_score_feature_sel,lr_clf_dict_feature_sel[\"accuracy\"],lr_clf_dict_feature_sel[\"auc_score\"],\n                                               lr_clf_dict_feature_sel[\"f1_score\"]]],index =[\"LogisticRegression\"], columns =score_name )\n\n# KNN\nbest = fmin(objective, knn_space, algo=tpe.suggest, max_evals=200, trials = Trials())\nbest_para = space_eval(knn_space, best)\nknn_cv_score_feature_sel= -objective(best_para) \nknn_clf_dict_feature_sel  = evaluate_model(knn_space, best)\nknn_model_scores_feature_sel= pd.DataFrame([[knn_cv_score_feature_sel,knn_clf_dict_feature_sel[\"accuracy\"],knn_clf_dict_feature_sel[\"auc_score\"],\n                                               knn_clf_dict_feature_sel[\"f1_score\"]]],index =[\"KNeighborsClassifier\"], columns =score_name )\n\n# Decision Tree\nbest = fmin(objective, dt_space, algo=tpe.suggest, max_evals=200, trials = Trials())\nbest_para = space_eval(dt_space, best)\ndt_cv_score_feature_sel= -objective(best_para) \ndt_clf_dict_feature_sel  = evaluate_model(dt_space, best)\ndt_model_scores_feature_sel=pd.DataFrame([[dt_cv_score_feature_sel,dt_clf_dict_feature_sel[\"accuracy\"],dt_clf_dict_feature_sel[\"auc_score\"],\n                                               dt_clf_dict_feature_sel[\"f1_score\"]]],index =[\"DecisionTreeClassifier\"], columns =score_name )\n\n# Random Forest\nbest = fmin(objective, rf_space, algo=tpe.suggest, max_evals=200, trials = Trials())\nbest_para = space_eval(rf_space, best)\nrf_cv_score_feature_sel= -objective(best_para) \nrf_clf_dict_feature_sel  = evaluate_model(rf_space, best)\nrf_model_scores_feature_sel = pd.DataFrame([[rf_cv_score_feature_sel,rf_clf_dict_feature_sel[\"accuracy\"],rf_clf_dict_feature_sel[\"auc_score\"],\n                                               rf_clf_dict_feature_sel[\"f1_score\"]]],index =[\"RandomForestClassifier\"], columns =score_name )\n\n# Adaboosting\nbest = fmin(objective, ab_space, algo=tpe.suggest, max_evals=200, trials = Trials())\nbest_para = space_eval(ab_space, best)\nab_cv_score_feature_sel= -objective(best_para) \nab_clf_dict_feature_sel  = evaluate_model(ab_space, best)\nab_model_scores_feature_sel = pd.DataFrame([[ab_cv_score_feature_sel,ab_clf_dict_feature_sel[\"accuracy\"],ab_clf_dict_feature_sel[\"auc_score\"],\n                                               ab_clf_dict_feature_sel[\"f1_score\"]]],index =[\"AdaBoostClassifier\"], columns =score_name )\n\n# Gradient Boosting\nbest = fmin(objective, gb_space, algo=tpe.suggest, max_evals=200, trials = Trials())\nbest_para = space_eval(gb_space, best)\ngb_cv_score_feature_sel= -objective(best_para) \ngb_clf_dict_feature_sel  = evaluate_model(gb_space, best)\ngb_model_scores_feature_sel = pd.DataFrame([[gb_cv_score_feature_sel,gb_clf_dict_feature_sel[\"accuracy\"],gb_clf_dict_feature_sel[\"auc_score\"],\n                                               gb_clf_dict_feature_sel[\"f1_score\"]]],index =[\"GradientBoostingClassifier\"], columns =score_name )\n\nmodel_scores_feature_sel = pd.concat([lr_model_scores_feature_sel,knn_model_scores_feature_sel, dt_model_scores_feature_sel, \n                                      rf_model_scores_feature_sel, ab_model_scores_feature_sel, gb_model_scores_feature_sel])","4af35d94":"plt.subplots(figsize=(8,5))\nsns.heatmap(model_scores_feature_sel, vmin=0.81, vmax=0.85, annot=True)\nplt.title(\"With Feature selction\")\n\nplt.subplots(figsize=(8,5))\nsns.heatmap(model_scores, vmin=0.81, vmax=0.85, annot=True)\nplt.title(\"Without Feature selction\")","e2c6fb89":"<a id=\"model\"><\/a>\n# Prediction Model\nI will try these base models and ensemble models to predict whether or not a responder has sought for treatment in a mental health condition from these features. I will first use all the features to fit the model and check which features will be selected (highly weighted). The hyperparameters will be tuned via cross-validation.\n\nBase model:\n* Logistic Regression\n* K-Nearest Neighbor\n* Decision Tree\n\nEnsemble model:\n* Random Forest\n* Adaboosting\n* Gradient Boosting\n\n## Construct Features and Target","f7b7df3e":"The cross validation accuracy in training set is 0.844, and accuracy in test set is 0.825. ","ea475296":"Let's check **work interfere** variable. We already know that ~21% of data in \"work_interfere\" columns is *NaN*. \n\nWhat about the distribution of other values?","736f9a23":"Distinct patterns can be found between Male and Female groups, and can also be found between groups with and withou family hisotry. \n\n1. **Larger proportion of female responders have sought treatments than male responders.**\n2. **Those with family history of mental health conditions have higher probability to seek treatment than the other groups.**\n\n### How are the **work interfere**, **working style (self-employed, remote work, tech company)** and **scale of workplace (number of employee)** related with the attitude towards treatment?\n\nWe have already seen that **people tend to seek treatment when they think their work will be interfered by a mental condition** (the graph previously shown and the graph below), so \"work_interfere\" would be important factor that affect the responder's attitude. ","00353375":"validatiaon accuracy in training set: 0.824, while accuracy in test set: 0.809, weaker than logistic regression.","e87a311c":"Getting rid of missing values and outliers, the dataset is ready for **Explorary Data Analysis (EDA)**.","077a2737":"<a id=\"ab\"><\/a>\n## AdaBoost Classifier","e06f6881":"<a id=\"summary\"><\/a>\n# Summary\nHere I explored the questions about how different factors may affect a person's attitude towards mental health in tech workspace.\n1. The most predictive factors include: **family history of mental illness, the options for mental health care the employer provides, benefits provided by employers, whether or not a mental health condition interferes with work, Age , Anonymity protected, Gender (larger proportion of female group seek treatment for mental health condition)**\n2. Several predictive models can predict whether a person has sought for treatment for mental health condition with accuracy ~0.83.\n3. We can see that with better supports from employers, the employee has higher probability to have positive attitute towards mental health conditions. Therefore, we can improve the situation by providing better supports and facilities for mental health.\n\nLi Shen 9\/1\/2021","425da487":"We can see:\n1. Almost 60% of data come from United States, ~15% come from United Kindom, data points come from other countries only account for a small portion.\n2. State information is only valid for data points from United States.\n\nSince a lot of missing values and biased distribution of data points in United States. These columns will not add much information realted to our question. I will drop them.\n","87e52606":"Now, let's move to **self_employed** column. Let's check its distribution.","199aede9":"We can see some positive correlations between the variables: \n\n* **work interfere** vs. **treatment** and **family history**: Having family history, or seeking treatment, may indicate that the responder has high probability to get work interfered by mental condition.\n* **number of employees** vs. **benefits**, **wellness program** and **seek help**. Larger company can afford better mental health facilities.\n* **benefit**, **care options**, **wellness program**, **seek help**, **anonymity**: These 5 variables are pair-wised correlated. They are all indicators about the supports from employers.\n* **coworkers** vs. **supervisors** vs. **mental health interview**: People are willing to discuss the mental condition with coworkers usually also are willing to discuss it with supervisors, and during interview.\n* **supervisor** vs. **mental with physical**: When the employer takes mental health as seriously as physical health, the employees are more willing to discuss it with supervisors.\n* **physical health consequence** vs. **mental health consequence**: These two consequences are highly correlated.\n* **physical health interview** vs. **mental health interview**: People are willing to discuss physical health issues during interview also are willing to discuss mental health issues during interview.\n\nNegative correlations:\n* **mental health consequences** vs. **mental-physical**, **mental health interview**, **supervisors** and **coworkers**: When employees perceive more negative consequences about mental condition, they also tend to think that the employers do not take mental health as seriously as physical health, and are not willing to talk about mental health during interview or to supervisor or to coworks.\n* **physical health consequences** show similar correlation with the above variables.\n* **observed sequence** vs. **mental vs physical**: If the employer takes mental health as seriously as physical health, the employee tends to not observed or heard of negative consequences about mental conditions.\n\nNext, let's focus on correlations with \"**treatment**\" variables.\n","3cc83eb3":"<a id=\"EDA\"><\/a>\n# Exploratory Data Analysis","c54b3d0b":"## Model with selected features\nI summarize highly voted features by correlation matrix, and the above models. ","2375ab1a":"Since there are irrelvant features and correlated features. Using fewer features may speed up the training and prevent overfitting. Now, I will try to use these selected features to train the models. ","01faf967":"Since missing value constitute a non-ignorable proportion (~21%). I first fill the missing value as \"Don't know\".","523b205a":"Mental health includes our emotional, psychological, and social well-being. It can affect our interactions with the world, work performance and our physical health. Nowadays, mental health topic attracts more and more attentions. A positive attitude towards seeking for treatment is important for people with mental health conditions. There are many factors that may affect this attitude. This dataset includes information about attitude about mental health in the tech workplace, individual's geographic and demographic information, and supports from workplace. We can get insights about which factors would affect the attitude and how we can do to improve the situation. \n* [Read the dataset](#read_dataset)\n* [Data Cleaning](#data_cleaning)\n* [Exploratory Data Analysis](#EDA)\n* [Encoding Data](#encoding_data)\n* [Correlation Analysis](#corr)\n* [Predictive Model](#model)\n* [Summary](#summary)","9530ab87":"Now, let's check again the missing value.","0b42a743":"We can also see in the **Gender** column, many phrases for \"gender\" appeared.","1d3f9a14":"When the max_depth < 8, it will generate better result.","229dd9a3":"Better hyperparameters located in the combination of fewer estimators and lower learning rate. We can further fine tuning in this are.","1cf3652f":"## Cross-validation and Hyperparameter Search\nTo more efficiently search for optimal hyperparameters, I apply **Bayesian Hyperparameter Optimization** method, to iteratively maximize the **Expectation Improvement (EI)**. Here, I use **Tree-structure Parzen Estimator (TPE)**, with *hyperopt* package for hyperparameter optimization.\n### First, import relevant packges.","768b91d0":"Since only ~1.4% of data are missing and \"No\" constitutes majority of the answers. It may be the default answer for the responders who ignored this question), I will fill the missing value as \"**No**\".","6bfea74b":"The cross validation accuracy in training set is 0.842 and accuracy in test set is 0.829.","ce053dce":"Training set cross validation accuracy ~ 0.839, while test set accuracy ~ 0.829. The generalization performance is generally good.","15416898":"<a id=\"lr\"><\/a>\n## Logistic Regression","51d5b24c":"<a id=\"rf\"><\/a>\n## Random Forest","51c23418":"<a id=\"gb\"><\/a>\n## Gradient Boosting Classfier","866461ef":"I cannot see signficant correlations between these variables. \n\nHence, the **working style (self-employed, remote work, tech company)** and **scale of workplace (number of employee)** do not significantly contribute to the attitude. \n\nBut **how frequently a mental condition inteferes work** is correlated with the attitude.\n\n### Next, let's explore the **mental health supporting** from the employer (**benefits, care_options, wellness_program, seek_help, anonymity, leave**).","b2505a0f":"The most important feature is still: **work interfere. Ohters include: age, care options, family history, number of employees, supervisor, phys_health_consequence, mental_health_consequence** etc.\n\nAfter hyperparameter tuning, these models generate similar results, except that **KNN** performance seems weaker in this case. Here is a summary for models' performance.","74fbc9f1":"The \"**Age**\" feature shows a *right-skewed* distribution, which means the data samples tend to come from younger ones, which are 20-40 years old. This may relate to the fact that responder were from tech workspace. From the boxplot of ages in two groups defined by \"treatment\" (one group have sought treatment for mental health condition, the other one not), we cannot see significant differences between the ages of the two groups here. \n### Gender and family history","a6246db0":"<a id=\"corr\"><\/a>\n## Pairwise correlation matrix: How each features correlated with others and the target?","8ef36beb":"## Feature Normalization","e3ebfe45":"We can see the majority of responders are male. That reflects a trend that more men than women working in technology workspace.\n\nWhat about other variables? \n\nThe **timestamp** column records the time when the survey was submitted, hence is irrelevant with our question. I will drop this column.","d530f034":"Let's group these words into three categories: \"**Female**\", \"**Male**\" and \"**Others**\".","f8cf33b7":"The top 9 highly correlated with treatment is:\n**work_interfere, family history, care options, Gender, obs consequence, benefits, leave, mental health consequence, anonymity**\n\nFor **Gender** variable, we can see female gender is positively correlated with treatment, while male gender is the opposite: negatively correlated the \"treatment\" target. That is consistent with our observation in preliminary analysis that female responders tend to seek treatment more often.\n\nThe top 9 variables are also consistent with our preliminary analysis.\n\nCheck the correlations between the 9 variables.","608a59d6":"Generally, larger **n_estimater** and **max_depth**, **min_sample_leaf** generate better results.","47eb2ff1":"<a id=\"read_dataset\"><\/a>\n# Read the dataset","d6d97570":"Since \"**comments**\" are usually optional for responders and almost 87% data were missing, this column will not add additional information for us. So we can simply drop this column.","b2cb2b2d":"From above results, we can see selection of \"**learning rate**\" is critical in this case (lower). **max_depth** and **n_estimator** in lower range will generate better results.","d60b6eea":"It seems when it is more difficult to take medical leave for a mental health condition, the responder tend to seek treatment. But the proportion of \"somewhat difficult\" or \"very difficult\" is relatively small. So we cannot get a conclusion right now.\n\n### Other factors include **being afraid of \"negative consequences\" after revealing mental illness to public**, especially to supervisors or coworkers. Now let's explore how these variables may affect the attitudes toward mental health conditions.","d5a6b835":"We can each of \"Yes\" and \"No\" answers accounts for about half of the responses. So the target data is **balanced** in these two categories.","0f1d1f35":"From above graphs, **when there are good supports (\"benefits\", \"care_options\", \"wellness_program\", \"seek_help\", \"anonymity\") from employer, higher proportion of the responders will seek for mental illness treatment.**","f0a5ade5":"We can also see the **state** column also contains many missing values. Now, let's look at the **state** column along with the **Country** column.","b0677cf0":"<a id=\"knn\"><\/a>\n## K-Nearest Neighbors","085a70cc":"Now, let's look at \"**Gender**\" and \"**family_history**\", which are personal related features. How these two variables are related with the \"**treatment**\" variable.","bcd60849":"First, let's explore the **target** variable.","69ee9189":"The highest coefficients are: **work interfere, family history, care options, anonymity, Gender, coworkers, Age, leave, benefits**. Most of them has also been found high correlation with \"**treatment**\" accoriding to correlation matrix.","a80171bf":"The most important features still include: **work interfere, family history, care options, gender, age, benefit**.","81d3f308":"## Decision Tree","9b651e9b":"Let's also check distributions of \"**self_employed, remote_work, tech_company, number of employees**\" in two groups (by \"treatment\").","8ead71dc":"The cross validationa accuracy is 0.836, and the accuracy in test set is 0.829.","99ef48ea":"The cross validation accuracy is 0.841, while the accuracy in test set is 0.825, with performance similar with logistic regression.","588b0afe":"The important features include: **age, work interfere, gender, family history, benefits, care options, seek_help, anonymity, coworkers, phys_health_interview, leave.**\n","32a65c8e":"* **care options** is correlated with **benefits** and **anonymity**: They are all supports from employers.\n* **mental health consequences** is **negatively** correlated with **anonymity**: higher level of anonymity, weaker negative consequences perceived.","ecab7683":"### How would geographic and demographic information correlated with the attitude of mental illness treatment?\nLet's first look at the \"**Age**\" feature.","e288e8f2":"The score was rapidly increased in the first 30 trials. From the parameter space, we can see better parameters locate locally in **C<0.5, l1_ratio>0.5**.","69c49803":"We can see some unreasonable values appears in ***Age*** column, such as negative values, or values below 14 (unreasonable age for a employee), or values exceed 100. Let's check how many values outsize the range [14,100].","c40a33e9":"<a id=\"data_cleaning\"><\/a>\n# Data Cleaning: Missing values, Outliers","a6777bb8":"The feature \"**work interfere**\" still has highest importance. Other important features include **family history, care options, age** etc.","22d4230f":"The outliers just constitute a very small proportion, so we can savely drop these unreasonable points. ","97aef1c9":"<a id=\"encoding_data\"><\/a>\n# Encoding data","5034c70e":"**k** in the range of [10,30] generate better results. We can refine parameter space further.","a7977ff0":"We can see the most voted answer to this question is \"Sometimes\". Let's check the whether attitude towards mental health in the group of \"Don't know\" is the same as the majority group \"Sometimes\"? If yes, we can consider to assign these missing values to this \"majority\" group.","a4e5c951":"It seems the \"**Don't know**\" group shows much more \"**No**\" responses to \"treatment\", and is more close to \"**Never**\" option. We may infer that these responders who have not\/would not sought for treatment, also tend to ignore the questions about \"work interfere\". ","7a518ffa":"### Define Objective function\nHere I use **cross-validation score (accuracy)** as objective function for hyperparameter tuning (multiply '-1' to make it loss function)","00c2600b":"## Training \/ Testing set split","d167bc8c":"Next, let's take a glance at all the columns to see whether they contain outliers. ","6ff2a521":"There are **26** columns in the datset.\nThe survey covers information mainly in 5 aspects: \n1. **Geographic** and **Demographic** information of responders: e.g. **Age**, **Gender**, **Country**, **state**, **family history** of mental illness\n2.  Basic information about **workspace**: e.g. **self-employed** or not, **number of employees**, **remote work** or not, **tech company** or not, **work interfere** when have mental health condition\n3.  **Supporting** for mental health from Workspaces: \n* **benefits**: Does your employer provide mental health benefits?\n* **care_options**: Do you know the options for mental health care your employer provides?\n* **wellness_program**: Has your employer ever discussed mental health as part of an employee wellness program?\n* **seek_help**: Does your employer provide resources to learn more about mental health issues and how to seek help?\n* **anonymity**: Is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources?\n* **leave**: How easy is it for you to take medical leave for a mental health condition?\n4. **Possible negative consequence**:\n* **mental_health_consequence**: Do you think that discussing a mental health issue with your employer would have negative consequences?\n* **phys_health_consequence**: Do you think that discussing a physical health issue with your employer would have negative consequences?\n* **coworkers**: Would you be willing to discuss a mental health issue with your coworkers?\n* **supervisor**: Would you be willing to discuss a mental health issue with your direct supervisor(s)?\n* **mental_health_interview**: Would you bring up a mental health issue with a potential employer in an interview?\n* **phys_health_interview**: Would you bring up a physical health issue with a potential employer in an interview?\n* **mental_vs_physical**: Do you feel that your employer takes mental health as seriously as physical health?\n* **obs_consequence**: Have you heard of or observed negative consequences for coworkers with mental health conditions in your workplace?\n5. Whether or not seek mental disorder treatment: **treatment**\n\nUsually, the factors from the individual, and from the workplace will affect one's attitude towards mental health. Based on these information, I would like to explore: \n1. How these factors contribute to the responder's attitude towards mental health conditions and treatments;\n2. Can we predict a personal's possibility to seek treatment for mental illness based on these information?\n3. How can we promote positive attitude towards mental health?\n\nTo addressing these questions, whether or not to seek treatment for mental illness (\"treatment\") become our target variable, others would be features.\n\nLet's first clean the data.","0f9db26f":"We can see that model with only some relevant features get similar or even better performance than the models with all features, and with faster training speed.","58468d4b":"We can see that when the responders think **discussing a mental health issue with employer would have negative consequences**, have **willing to discuss it with coworkers**, and have **heard of or observed negative consequences for coworkers** with mental health conditions, they tend to seek treatment. \n\nNext, I will perform **correlation analysis** to quantify their relationships.\n\nBefore that, we need to **encode** categorical data into numeric data."}}