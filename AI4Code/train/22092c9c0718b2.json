{"cell_type":{"912e743a":"code","6c334dc7":"code","229eb02d":"code","1431a9e3":"code","b1566903":"code","04e514be":"code","214a1a55":"code","103183c3":"code","04699ea2":"code","4d174755":"code","d830483d":"code","4c2ac58f":"code","6e2ec92a":"code","313b27ca":"code","51a7e99e":"code","a384fafe":"code","dc1826f9":"code","d1bdf289":"code","2bede9f9":"code","7fa738b5":"code","d54aa3b5":"code","38de145b":"code","2cb52e12":"code","272d31f6":"code","6a883a84":"code","493d3bca":"code","65406416":"code","86f0d528":"code","4d916c44":"code","f9436a17":"code","7f24c1d3":"code","e8d04113":"code","43aeeede":"code","968bcbed":"code","cd389656":"code","da53fe4a":"code","2f6c5277":"code","d011c43d":"markdown","c69631f8":"markdown","475b08ba":"markdown","3934ad58":"markdown","e5c18913":"markdown","29ede588":"markdown","ccd0f426":"markdown","b1332a99":"markdown","9178aefd":"markdown","eee98e67":"markdown","65520cf5":"markdown","5852ab8a":"markdown","fc52f69f":"markdown","e1a81aaf":"markdown","3fad8a3d":"markdown","022d27ea":"markdown","079af7f5":"markdown","6a8a20cc":"markdown","2084af73":"markdown"},"source":{"912e743a":"#import python packages \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn import cross_validation, preprocessing\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import accuracy_score \n%matplotlib inline","6c334dc7":"#import dataset from draft environment\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","229eb02d":"train.head()","1431a9e3":"train.columns, test.columns","b1566903":"#Descriptive statistic of Titanic data\ntrain.describe()","04e514be":"#Check data type\ntrain.dtypes","214a1a55":"#titanic info\ntrain.info()","103183c3":"#check missing value\ntrain.isnull().sum()","04699ea2":"sum(pd.isnull(train['Age']))","4d174755":"# proportion of \"Age\" missing\nround(177\/(len(train[\"PassengerId\"])),4)","d830483d":"# proportion of \"cabin\" missing\nround(687\/len(train[\"PassengerId\"]),4)","4c2ac58f":"# proportion of \"Embarked\" missing\nround(2\/len(train[\"PassengerId\"]),4)","6e2ec92a":"# median age is 28 (as compared to mean which is ~30)\ntrain[\"Age\"].median(skipna=True)","313b27ca":"#final adjustment\ntrain_data = train\ntrain_data[\"Age\"].fillna(28, inplace=True)\ntrain_data[\"Embarked\"].fillna(\"S\", inplace=True)\ntrain_data.drop('Cabin', axis=1, inplace=True)","51a7e99e":"## Create categorical variable for traveling alone\ntrain_data['TravelBuds']=train_data[\"SibSp\"]+train_data[\"Parch\"]\ntrain_data['TravelAlone']=np.where(train_data['TravelBuds']>0, 0, 1)","a384fafe":"train_data.drop('SibSp', axis=1, inplace=True)\ntrain_data.drop('Parch', axis=1, inplace=True)\ntrain_data.drop('TravelBuds', axis=1, inplace=True)","dc1826f9":"#create categorical variable for Pclass\n\ntrain2 = pd.get_dummies(train_data, columns=[\"Pclass\"])","d1bdf289":"train3 = pd.get_dummies(train2, columns=[\"Embarked\"])","2bede9f9":"train4=pd.get_dummies(train3, columns=[\"Sex\"])\ntrain4.drop('PassengerId', axis=1, inplace=True)\ntrain4.drop('Name', axis=1, inplace=True)\ntrain4.drop('Ticket', axis=1, inplace=True)\ntrain4.head(5)\nfinal_train = train4\n\nfinal_train.head()","7fa738b5":"#final adjustment\ntest_data = test\ntest_data[\"Age\"].fillna(28, inplace=True)\ntest_data[\"Embarked\"].fillna(\"S\", inplace=True)\ntest_data.drop('Cabin', axis=1, inplace=True)\n\n## Create categorical variable for traveling alone\n\ntest_data['TravelBuds']=test_data[\"SibSp\"]+test_data[\"Parch\"]\ntest_data['TravelAlone']=np.where(test_data['TravelBuds']>0, 0, 1)\n\ntest_data.drop('SibSp', axis=1, inplace=True)\ntest_data.drop('Parch', axis=1, inplace=True)\ntest_data.drop('TravelBuds', axis=1, inplace=True)\n\n#create categorical variable for Pclass\n\ntest2 = pd.get_dummies(test_data, columns=[\"Pclass\"])\n\ntest3 = pd.get_dummies(test2, columns=[\"Embarked\"])\n\ntest4=pd.get_dummies(test3, columns=[\"Sex\"])\n\ntest4.drop('PassengerId', axis=1, inplace=True)\ntest4.drop('Name', axis=1, inplace=True)\ntest4.drop('Ticket', axis=1, inplace=True)\ntest4.head(5)\n\nfinal_test=test4\nfinal_test.head()","d54aa3b5":"ax = train[\"Age\"].hist(bins=15, color='green', alpha=0.8)\nax.set(xlabel='Age', ylabel='Count')\nplt.show()","38de145b":"#Explor Age Variable\nplt.figure(figsize=(10,5))\ntrain['Age'].plot.hist(bins=35)","2cb52e12":"plt.figure(figsize=(10,5))\ntrain[train['Survived']==0]['Age'].hist(bins=35,color='blue',\n                                       label='Survived = 0', \n                                        alpha=0.6)\ntrain[train['Survived']==1]['Age'].hist(bins=35,color='red',\n                                       label='Survived = 1',\n                                       alpha=0.6)\nplt.legend()\nplt.xlabel(\"The Number of Age\")","272d31f6":"sns.countplot(x='Embarked',data=train,palette='Set2')\nplt.show()","6a883a84":"#Import Packages for Machine Learning models \n## the packages is Scikit-Learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.cross_validation import train_test_split","493d3bca":"x = final_train.drop('Survived', axis=1)\ny = final_train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(x , y, test_size = 0.20)\n\nLogmodel = LogisticRegression()\nLogmodel.fit(X_train,y_train)","65406416":"pred_LR = Logmodel.predict(X_test)","86f0d528":"print(confusion_matrix(y_test,pred_LR))\nprint('\\n')\nprint(classification_report(y_test,pred_LR))","4d916c44":"Accuracy_LR = print ('1. Accuracy_L.Regression_Classifier :', \n                     accuracy_score(y_test,pred_LR)*100)","f9436a17":"x = final_train.drop('Survived', axis=1)\ny = final_train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(x , y, test_size = 0.20)\n\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)","7f24c1d3":"pred_tree = dtree.predict(X_test)","e8d04113":"print(confusion_matrix(y_test,pred_tree))\nprint('\\n')\nprint(classification_report(y_test,pred_tree))","43aeeede":"Accuracy_DT = print ('2. Accuracy_D.Tree_Classifier :', \n                     accuracy_score(y_test,pred_tree)*100)","968bcbed":"x = final_train.drop('Survived', axis=1)\ny = final_train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(x , y, test_size = 0.20)\n\nRfc = RandomForestClassifier(n_estimators = 300 )\nRfc.fit(X_train,y_train)","cd389656":"Pred_Rfc =Rfc.predict(X_test)","da53fe4a":"print(confusion_matrix(y_test,Pred_Rfc))\nprint ('\\n')\nprint(classification_report(y_test,Pred_Rfc))","2f6c5277":"Accuracy_RF = print ('3. Accuracy_R.Forest_Classifier :', \n                     accuracy_score(y_test,Pred_Rfc)*100)","d011c43d":"### 3.2. Preprocessing Data Test ","c69631f8":"# Conculsion :\n\nFrom the Analisys we can see that there are several of acc model from \neach machine learning that have been made. Choose the highest value of accuracy models.  \n\nnoted : (those models are not consistant) ","475b08ba":"\n# 3. Data Preprocessing","3934ad58":"If we see from the chceking missing value, there are 3 variables that have NA value, that is Age, Cabin, and Embarked variables. how to fix it ?\n\nin this analysis, we will be filling several of  columns that have NA value with existing value, foe example :\n1. in order to fillin the empty columns on the Age variable can be filled with the median value of the Age variable. what is the median value of Age ?","e5c18913":"# Introduction\n\nHello everyone !\n\nThis is my first project in kaggle. i would like to sharing about implementation of the machine learning to predict titanic classification, especially using Logistic Regression, Decision Tree, and Random Forest  algorithm. Lets Check it out.","29ede588":"# 2.  Check missing value","ccd0f426":"## 2.2. Cabin Missing Value","b1332a99":"the median value is 28. so that, we'll filling each empty column with that value. \n\n2. In order to fillin the empty columns on the Embarked variable can be filled with S (Southampton). Since the average of passengers boards a ship in that city. \n\n3. We will remove several of a variable which not used, that is Cabin since that variable has much missing value. so that, we will not use that variable. \n\n4. Remove SibSp and Parch, then combine those variables to be one group. We will give the name of variables are **TravelBuds**.\n\n5. The last, remove  variables that are not used. (PassengerId, Name, and Ticket)","9178aefd":"## 5.2. Decision Tree Classifier ","eee98e67":"### 3.1. Preprocessing Data Train","65520cf5":"# 1. Import python packages and dataset is needed\n","5852ab8a":"**Information of variables :**\n* **PassengerId** = ID number of each Passenger \n* **Survived**       = Whether the passenger survived or not ( 0 = no, 1 =yes) \n* **Pclass**           = Passanger class indicates the class of that person aboard the ship. (1 (1st)= Upper,  2(2nd) = Middle, 3(3rd) = lower)\n* **Name**            = The name of Passenger\n* **Sex**                = sex\n* **Age**                = Age in years\n* **SibSp**            = The number of Sibling\/Spouces they had.\n* **Parch**             = Parch indicates Parents with children.\n* **Ticket**            = Ticket name\/Number.\n* **Fare**               = How much the passenger should be paid\n* **Cabin**             = Cabin name of that Passenger.\n* **Embarked**      = Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton) ","fc52f69f":"In order to see the descriptive statistics of Titanic data, you just write the code is following ","e1a81aaf":"## 5.1. Logistic Regression","3fad8a3d":"## 2.1. Age missing value","022d27ea":"## 5.3. Random Forest Classifier","079af7f5":"# 5. Machine Learning Models","6a8a20cc":"## 2.3. Embarked Missing Value","2084af73":"# 4. Exploratory Data"}}