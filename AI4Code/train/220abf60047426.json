{"cell_type":{"13c11ab9":"code","2a100d67":"code","597d7000":"code","67ae02a2":"code","d889ab8e":"code","aece5b00":"code","9bfa29fa":"code","54b34042":"code","bcbaf579":"code","010af8ce":"code","7dd659c9":"code","1e947106":"code","909c48a0":"code","6cfb7b6f":"code","4838175c":"code","32f9f054":"code","baaaef19":"code","b431bfd5":"code","b9cc1837":"markdown","f9ee0b80":"markdown","96886be5":"markdown","ddc5dda9":"markdown","bf086a0f":"markdown","f20a8ce7":"markdown","25a5fb77":"markdown","9aed96dc":"markdown","88f03486":"markdown","d52799f4":"markdown","18a5597c":"markdown"},"source":{"13c11ab9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport keras\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport cv2\nfrom keras import applications\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\nfrom keras.models import Model\nfrom keras.optimizers import Adam","2a100d67":"df = pd.read_csv('\/kaggle\/input\/human-protein-atlas-image-classification\/train.csv')","597d7000":"INPUT_SHAPE = (512, 512, 3)\nBATCH_SIZE = 16\npath_to_train = '\/kaggle\/input\/human-protein-atlas-image-classification\/train\/'","67ae02a2":"df[\"complete_path\"] = path_to_train + df[\"Id\"]","d889ab8e":"df.head()","aece5b00":"import random\nfig, axes = plt.subplots(3, 4, figsize=(11, 11))\nfor i in range(3):\n    for j in range(4):\n        idx = random.randint(0, df.shape[0])\n        row = df.iloc[idx,:]\n        path = row.complete_path\n        red = np.array(Image.open(path + '_red.png'))\n        green = np.array(Image.open(path + '_green.png'))\n        blue = np.array(Image.open(path + '_blue.png'))\n        im = np.stack((\n                red,\n                green,\n                blue),-1)\n        axes[i][j].imshow(im)\n        axes[i][j].set_title(row.Target)\n        axes[i][j].set_xticks([])\n        axes[i][j].set_yticks([])\nfig.tight_layout()\nfig.show();","9bfa29fa":"train, val = train_test_split(df, test_size=0.2, random_state=42)","54b34042":"print(f'Shape of train: {train.shape}')\nprint(f'Shape of val: {val.shape}')","bcbaf579":"def get_clean_data(df):\n    targets = []\n    paths = []\n    for _, row in df.iterrows():\n        target_np = np.zeros((28))\n        t = [int(t) for t in row.Target.split()]\n        target_np[t] = 1\n        targets.append(target_np)\n        paths.append(row.complete_path)\n    return np.array(paths), np.array(targets)","010af8ce":"train_path, train_target = get_clean_data(train)\nval_path, val_target = get_clean_data(val)","7dd659c9":"print(f'Train path shape: {train_path.shape}')\nprint(f'Train target shape: {train_target.shape}')\nprint(f'Val path shape: {val_path.shape}')\nprint(f'Val target shape: {val_target.shape}')","1e947106":"train_data = tf.data.Dataset.from_tensor_slices((train_path, train_target))\nval_data = tf.data.Dataset.from_tensor_slices((val_path, val_target))","909c48a0":"def load_data(path, target):\n    red = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_red.png'), channels=1), [2])\n    blue = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_blue.png'), channels=1), [2])\n    green = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_green.png'), channels=1), [2])\n    img = tf.stack((\n                red,\n                green,\n                blue), axis=2)\n    return img, target\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_data = train_data.map(load_data, num_parallel_calls=AUTOTUNE)\nval_data = val_data.map(load_data, num_parallel_calls=AUTOTUNE)","6cfb7b6f":"def image_augment(img, target):\n    img = tf.image.random_contrast(img, lower=0.3, upper=2.0)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_brightness(img, max_delta=0.1)\n    return img, target\n    \ntrain_data = train_data.map(image_augment, num_parallel_calls=AUTOTUNE)","4838175c":"train_data_batches = train_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\nval_data_batches = val_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","32f9f054":"resnet_model = applications.ResNet50(include_top=False, weights='imagenet')\n\nresnet_model.trainable = True\n\ninput_layer = Input(shape=INPUT_SHAPE)\nx = resnet_model(input_layer)\nx = Flatten()(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(28, activation='sigmoid')(x)\nmodel = Model(input_layer, output)\n\nmodel.summary()","baaaef19":"model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['binary_accuracy'])","b431bfd5":"history = model.fit(train_data_batches, steps_per_epoch = 150, validation_data = val_data_batches, epochs=3)","b9cc1837":"To get more information about tf.data you can refer to it's [official docs](http:\/\/www.tensorflow.org\/guide\/data)","f9ee0b80":"Loading pretrained ResNet50 model, adding final layers and training it:","96886be5":"**If you like my notebook, please upvote it :)**","ddc5dda9":"If you want you can also resize the images using **tf.image.resize_images** function. I would like to keep the original dimensions :)","bf086a0f":"It may happen that row.Target.split() won't work. In that case, you can try row.Target.str.split() instead.","f20a8ce7":"# <span style=\"font-family:candara; background:#99ffff; font-size: 25px; test-align: center;\">TRAINING<\/span>","25a5fb77":"# <span style=\"font-family:candara; background:#99ffff; font-size: 25px; test-align: center;\">IMAGE AUGMENTATION<\/span>\nNow, I augment the training set images below by appling random contrast, brightness and flip. There are multiple other augmentations that you can apply.","9aed96dc":"# <span style=\"font-family:candara; background:#99ffff; font-size: 25px; test-align: center;\">READING IMAGES FROM FILES<\/span>","88f03486":"# <span style=\"font-family:candara; background:#99ffff; font-size: 25px; test-align: center;\">CREATING DATASET FROM FILE AND TARGETS<\/span>","d52799f4":"# <span style=\"font-family:candara; background:#99ffff; font-size: 25px; test-align: center;\">PLOTTING RANDOM CELL IMAGES<\/span>","18a5597c":"# <span style=\"font-family:candara; background:#99ffff; font-size: 30px; test-align: center;\">HUMAN PROTEIN ATLAS<\/span>\n\nThe word *Protein* comes from Greek word *Proteios* meaning primary or in the lead. Proteins are of immense importance in our body. From catalysing reactions and passing signals at cellular level to growth and maintainance of tissues, many of the major life functions are carried out by proteins.\n\nBut why did I choose this topic??\n* Instead of one RGB image, four channels images i.e. red, green, blue, yellow images are provided separately.\n* Multilabel classification.\n\nMoreover, I would like to use **tf.data** API which enables us to build asynchronous and highly efficient input pipeline.\n\nSo, let's get started."}}