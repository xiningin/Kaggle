{"cell_type":{"2f816edc":"code","6ed95374":"code","6b7e29d7":"code","8ef0946e":"code","44fa0a26":"code","8a39f464":"code","4d352937":"code","f61a4bc6":"code","91806fac":"code","c75de81c":"code","bacd07fe":"code","507ffbe8":"code","95fa4abc":"code","3cf7cf0f":"markdown","9dfdf5e3":"markdown","773f33bf":"markdown","56823d27":"markdown","80b819c2":"markdown","ae80b68a":"markdown","37275d91":"markdown","f5222adc":"markdown","717a6985":"markdown","2d6ccb24":"markdown","3f67654f":"markdown","fced3bbd":"markdown","b7c4164e":"markdown","06a758a2":"markdown","c91ad500":"markdown"},"source":{"2f816edc":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import classification_report, mean_squared_error, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6ed95374":"df = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\ndf.head()","6b7e29d7":"plt.figure(figsize=(15,15))\nsns.heatmap(df.corr(), annot=True, linewidths=1, cmap = 'coolwarm')\nplt.title('Correlation Heatmap')\nplt.xlabel('Column')\nplt.ylabel('Column')","8ef0946e":"fig, axs = plt.subplots(1,2,figsize=(14,4))\n\ntable=pd.crosstab(df.cp,df.output)\ntable.div(table.sum(1).astype(float), axis=0).plot(ax=axs[0],kind='bar', stacked=True)\npd.crosstab(df.cp,df.output).plot(ax=axs[1],kind='bar')\n\nfor ax in axs.flat:\n    ax.set(xlabel='Cp', ylabel='number of patients')\n    ax.title.set_text('Number of Patients for different Cp types')","44fa0a26":"table=pd.crosstab(df.caa,df.output)\ntable.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\nplt.title('Proportion of number of patients for different number of major veseels')\nplt.xlabel('number of major vessels')\nplt.ylabel('Number of Patients')","8a39f464":"output = df.output.unique()\nplt.hist([df.loc[df.output == x, 'thalachh'] for x in output], label=output)\nplt.legend()","4d352937":"pd.crosstab(df.exng,df.output).plot(kind='bar')\nplt.title('Patients with exercise induced angina & Possibility of heart attack')\nplt.xlabel('exng')\nplt.ylabel('Number of Patients')","f61a4bc6":"pd.crosstab(df.thall,df.output).plot(kind='bar')\nplt.title('Patients with different type of thall')\nplt.xlabel('thall')\nplt.ylabel('Number of Patients')","91806fac":"pd.crosstab(df.fbs,df.output).plot(kind='bar')\nplt.title('Patients with fasting blood sugar > 120')\nplt.xlabel('fbs')\nplt.ylabel('Number of Patients')","c75de81c":"x = df.drop(columns=['output'])\ny = df['output']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(x_train, y_train)\n\ny_test_pred = logreg.predict(x_test)\nprint(classification_report(y_test, y_test_pred))","bacd07fe":"x = df.drop(columns=['output','slp','chol','fbs','trtbps', 'restecg','age'])\ny = df['output']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(x_train, y_train)\n\ny_test_pred = logreg.predict(x_test)\nprint(classification_report(y_test, y_test_pred))","507ffbe8":"logreg = LogisticRegression(solver=\"liblinear\")\ngnb = GaussianNB()\nknn = KNeighborsClassifier()\ndec_tree = DecisionTreeClassifier(random_state=42)\nrf = RandomForestClassifier(random_state=42,verbose=False)\ngb = GradientBoostingClassifier(verbose=False)\n\nmodels = [logreg,gnb,knn,dec_tree,rf,gb]","95fa4abc":"for model in models:\n    model.fit(x_train,y_train)\n    name = model.__class__.__name__\n    y_pred = model.predict(x_test)\n    print(\"Model    -\", name)\n    print(\"Accuracy -\",accuracy_score(y_test,y_pred))\n    print(\"Loss     -\", mean_squared_error(y_test,y_pred))\n    print()","3cf7cf0f":"### Correlation Coefficient magnitute with target variable (output)\n1. Greater than 0.35 - cp, thalachh, exng, oldpeak, slp, caa\n2. Greater than 0.25 - thall, sex\n3. Less than 0.25 and greater than 0.1 - age, trtbps, restecg\n4. Almost equal to 0 - chol, fbs  \n\n**Note**: We can see that slp and oldpeak have negative correlation of 0.58 which is significant. So, only one of them is included in x_train. As the correaltion of oldpeak with output is greater than that of slp, we are dropping slp from x","9dfdf5e3":"We can see that accuracy increased from 0.87 to 0.89 when the columns are dropped. This shows us the importance of feature engineering. It's always importat to make sure that the features are independant of each other and have maximum correlation with target variable only.","773f33bf":"## Maximum Accuracy is for Logistic Regression - 0.885","56823d27":"As expected, the patients with exercise induced angina are less likely to be suffered from heart attack","80b819c2":"When thall type is 2, the chances of getting heart attack are much higher.","ae80b68a":"As we can see, the number of patients getting heart attack is almost same as number of patients who are less likely to get heart attack regardless of their blood sugar level. So this feature will less likely to be helpful in classification model","37275d91":"As from above figures, we can say that for type 1 and type 2 cp, the proability of y being 1 is high","f5222adc":"Similarly, for number of vessels 0 and 4, probability of y being 1 is high. Hence the correlation of caa with output is high","717a6985":"## Importance of Feature Engineering  \nLet's see the accuracy of the logistic regression model without doing any feature engineering","2d6ccb24":"We can observe that when value of thalachh (maximum heart rate achieved) is around 160, the value of y is 1","3f67654f":"Now let's try the same thing with dropping the features with correlation less than 0.25","fced3bbd":"## Correlation Heatmap","b7c4164e":"## Feature Engineering","06a758a2":"## Classification Models","c91ad500":"## Data Visualization"}}