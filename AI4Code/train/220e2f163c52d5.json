{"cell_type":{"587e72f7":"code","69637426":"code","7ffb1d8c":"code","cebff59b":"code","3440588a":"code","975b52f3":"code","98d69786":"code","c2c26736":"code","7ba180f4":"code","4e626554":"code","6d7b5b8b":"code","af21e081":"markdown","4cc2c1fc":"markdown","e60b7715":"markdown","9dc83db3":"markdown","228225af":"markdown","88ae5ce8":"markdown","1280a5a7":"markdown","42867d37":"markdown","1d2128ce":"markdown","91b84211":"markdown","1e739d0a":"markdown","bc4d5304":"markdown","8da36bfc":"markdown"},"source":{"587e72f7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statistics as stat\nimport category_encoders as ce\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import metrics","69637426":"players_df = pd.read_csv('..\/input\/unsupervised-ml\/nba_2013.csv')\nprint('Dataset Shape: ',players_df.shape)","7ffb1d8c":"# Check for missing values\nplayers_df['player'].duplicated().value_counts()","cebff59b":"print(players_df.dtypes)\nprint(players_df.head(5))","3440588a":"print(players_df.season.value_counts())\nprint(players_df.season_end.value_counts())","975b52f3":"drop_cols = ['player','pos','bref_team_id','fg.','x3p.','x2p.','efg.', 'ft.','trb','season','season_end']\nplayers_df.drop(drop_cols, axis=1, inplace=True, errors='ignore')\nplayers_df.columns","98d69786":"# Sum of null values in each column\nplayers_df.isnull().sum()","c2c26736":"# The columns that we will be making predictions with.\nx = players_df[['age', 'g', 'gs', 'mp', 'fg', 'fga', 'x3p', 'x3pa', 'x2p', 'x2pa', \n                'ft', 'fta', 'orb', 'drb', 'ast', 'stl', 'blk', 'tov', 'pf']]\n\n# The column that we want to predict.\ny = players_df['pts']\n\n# Split 80% training data and 20% testing data\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)","7ba180f4":"# Train for k=1 to 10, and calculate R-square for prediction\nreg_score = []\nfor k in range(10):\n    k_value = k + 1\n    knn = KNeighborsRegressor(n_neighbors = k_value)\n    knn.fit(x_train, y_train) \n    y_pred = knn.predict(x_test)\n    r_square = format(metrics.r2_score(y_test, y_pred),'.4f')\n    print ('Regression score is:', r_square, 'for k_value:', k_value)\n    reg_score.append(r_square)\nprint()\nmax_k_value = reg_score.index(max(reg_score))+1\nprint('Max Regression Score is:', max(reg_score), 'for k_value:', max_k_value)","4e626554":"# Prepare cross validation\nkfold = KFold(n_splits=10,random_state=5, shuffle=True)\nknn = KNeighborsRegressor(n_neighbors = max_k_value)\n\n# Train on each splits\nk_reg_scores = []\nfor train_index, test_index in kfold.split(x):\n    X_train, X_test, Y_train, Y_test = x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n    knn.fit(X_train, Y_train) \n    Y_pred = knn.predict(X_test)\n    acc = format(metrics.r2_score(Y_test, Y_pred),'.4f')\n    k_reg_scores.append(float(acc))\n\n# Print mean R-square of folds\nprint('K-Fold Cross Validation with k=10:-')\nprint('Mean Regression Score is:',stat.mean(k_reg_scores),'for k_value =', max_k_value)","6d7b5b8b":"print('10 values of y_test:')\nprint(np.asarray(y_test.head(10)))\nprint()\nprint()\nprint('Corresponding values of y_pred:')\nprint(np.array(y_pred.tolist()[0:10]))","af21e081":"The dataset has 481 rows and 31 columns, with no duplicate entries.","4cc2c1fc":"Here,\n* `player`, `pos`, `bref_team_id` irrelevant categorical features\n* `fg.`, `x3p.`, `x2p.`, `efg.`, `ft.`, `trb` are dependent on other features, and hence void\n* `season`, `season_end` have the same value throughout (irrelevant)\n\nHence, we drop the above columns from the dataframe.","e60b7715":"# Predicting Player Points Using K Nearest Neighbours in Python (NBA 2013 Players Dataset)\n\nStatistics in basketball are collected and analyzed to evaluate and predict a team's or individual players' performance. The dataset we have gives the various performance statistics of the NBA 2013 players. Here we are attempting predict the points scored by the players, and we will be using the K Nearest Neighbours Regression Algorithm to do this.","9dc83db3":"There are no missing values","228225af":"Let us first import the necessary libraries and load our dataset.","88ae5ce8":"### K-Fold Cross Validation","1280a5a7":"## The Data","42867d37":"### Model Training and Calculating Regression Score","1d2128ce":"### Missing Values","91b84211":"### Splitting Train and Test Data","1e739d0a":"Explanation of the columns:\n* `player` - Name of the player\n* `pos` - Position of the player (Center(C), Point Forward(PF), Shooting Guard(SG), etc.)\n* `age` - Age of the player\n* `bref_team_id` - Player team\n* `g`, `gs` - No.of Games, No.of Games Started by the player\n* `mp` - Minutes Played\n* `fg`, `fga`, `fg.` - Field Goals, Field Goal Attempts, Field Goal Percetage(FG%=FG\/FGA)\n* `x3p`, `x3pa`, `x3p.` - 3-Point Field Goals, 3-Point Field Goal Attempts, 3-Point Field Goal Percentage(3P%=3P\/3PA)\n* `x2p`, `x2pa`, `x2p.` - 2-Point Field Goals, 2-Point Field Goal Attempts, 2-Point Field Goal Percentage(2P%=2P\/2PA)\n* `efg.` - Effective Field Goal Percentage; eFG% = (FG + 0.5 * 3P) \/ FGA\n* `ft`, `fta`, `ft.` - Free Throws, Free Throw Attempts, Free Throw Percentage(FT%=FT\/FTA)\n* `orb`, `drb`, `trb` - Offensive Rebounds, Defensive Rebounds, Total Rebounds(TRB=ORB+DRB)\n* `ast`, `stl`, `blk` - Assists, Steals, Blocks\n* `tov`, `pf` - Turnovers, Personal Fouls\n* `pts` - Points\n* `season`, `season_end` - Season(2013-14), Season end year(2013)","bc4d5304":"### Dropping Irrelevant Columns","8da36bfc":"### View the Predictions"}}