{"cell_type":{"5e1c4502":"code","bf0e5435":"code","b578224f":"code","6e5c5b3d":"code","14317423":"code","d22ea82b":"code","fb73e9c5":"code","141af15e":"code","85b15fc7":"code","45b4fcaf":"code","68acc798":"code","8d85fccc":"markdown","2626d444":"markdown","39b8910f":"markdown","d9933c45":"markdown","030388fc":"markdown","ffc53c0f":"markdown","4cddba89":"markdown","80e811df":"markdown"},"source":{"5e1c4502":"import numpy as np\nimport pandas as pd\nfrom time import time\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","bf0e5435":"data = pd.read_csv(\"..\/input\/compresive_strength_concrete.csv\")\ndisplay(data)","b578224f":"#Renomeando as colunas\ndata.columns = ['cimento', 'escoria', 'cinzas', 'agua', 'superplastificante', 'ag_grosso', 'ag_fino', 'idade', 'resistencia']\ndisplay(data)","6e5c5b3d":"data.isnull().any()","14317423":"data.info()","d22ea82b":"sns.distplot(data[\"resistencia\"])","fb73e9c5":"data.describe()","141af15e":"sns.set(font_scale=1.5)\nsns.pairplot(data)","85b15fc7":"corr = data.corr()\nplt.figure(figsize=(14, 14)) #deixando a imagem maior\nsns.heatmap(corr,annot = True, xticklabels=corr.columns.values, yticklabels=corr.columns.values,cmap = \"coolwarm\")","45b4fcaf":"#Colocando os dados em ordem aleat\u00f3ria \nrandomdata = (data.sample(n=1030, replace=False))\n\n#Treino e teste\nX = data.drop('resistencia', axis = 1)\ny = data['resistencia']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n\n#Padronizando dados\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","68acc798":"###Decision Tree\nDTR = DecisionTreeRegressor()\nDTR = DTR.fit(X_train, y_train)\npred_dtr = DTR.predict(X_test)\n\nprint('Arvores de Decis\u00e3o:')\nprint('Erro Quadr\u00e1tico M\u00e9dio:', mean_squared_error(y_test, pred_dtr))\nprint('Raiz do Erro Quadr\u00e1tico M\u00e9dio:', np.sqrt(mean_squared_error(y_test, pred_dtr)))\n\nerrors = abs(pred_dtr - y_test)\naux = 100 * (errors \/ y_test)\ndtr_eval = round(100 - np.mean(aux), 2)\nprint (\"Acur\u00e1cia:\", dtr_eval, \"%\")\n\n#Valida\u00e7\u00e3o cruzada\ndtr_cv = cross_val_score(estimator = DTR, X = X_train, y = y_train, cv = 10)\ndtr_cv = round((dtr_cv.mean()*100), 2)\nprint(\"Acur\u00e1cia usando valida\u00e7\u00e3o cruzada:\",dtr_cv, \"%\\n\")\n\n\n###Random Forest\nRFR = RandomForestRegressor(n_estimators=200)\nRFR = RFR.fit(X_train, y_train)\npred_rfr = RFR.predict(X_test)\n\nprint('Florestas aleat\u00f3rias de decis\u00e3o:')\nprint('Erro Quadr\u00e1tico M\u00e9dio:', mean_squared_error(y_test, pred_rfr))\nprint('Raiz do Erro Quadr\u00e1tico M\u00e9dio:', np.sqrt(mean_squared_error(y_test, pred_rfr)))\n\nerrors = abs(pred_rfr - y_test)\naux = 100 * (errors \/ y_test)\nrfr_eval = round(100 - np.mean(aux), 2)\nprint(\"Acur\u00e1cia:\", rfr_eval, \"%\")\n\n#Valida\u00e7\u00e3o cruzada\nrfr_cv = cross_val_score(estimator = RFR, X = X_train, y = y_train, cv = 10)\nrfr_cv = round((rfr_cv.mean()*100), 2)\nprint(\"Acur\u00e1cia usando valida\u00e7\u00e3o cruzada:\",rfr_cv, \"%\\n\")\n\n\n###Regressao Linear\nLIR = LinearRegression()\nLIR = LIR.fit(X_train, y_train)\npred_lir = LIR.predict(X_test)\n\nprint('Regress\u00e3o Linear:')\nprint('Erro Quadr\u00e1tico M\u00e9dio:', mean_squared_error(y_test, pred_lir))\nprint('Raiz do Erro Quadr\u00e1tico M\u00e9dio:', np.sqrt(mean_squared_error(y_test, pred_lir)))\n\nerrors = abs(pred_lir - y_test)\naux = 100 * (errors \/ y_test)\nlir_eval = round(100 - np.mean(aux), 2)\nprint(\"Acur\u00e1cia:\", lir_eval, \"%\")\n\n#Valida\u00e7\u00e3o cruzada\nlir_cv = cross_val_score(estimator = LIR, X = X_train, y = y_train, cv = 10)\nlir_cv = round((lir_cv.mean()*100), 2)\nprint(\"Acur\u00e1cia usando valida\u00e7\u00e3o cruzada:\",lir_cv, \"%\\n\")\n\n\n###KNN\nKNN = KNeighborsRegressor(n_neighbors=3)\nKNN = KNN.fit(X_train, y_train)\npred_knn = KNN.predict(X_test)\n\nprint('K vizinhos mais pr\u00f3ximos:')\nprint('Erro Quadr\u00e1tico M\u00e9dio:', mean_squared_error(y_test, pred_knn))\nprint('Raiz do Erro Quadr\u00e1tico M\u00e9dio:', np.sqrt(mean_squared_error(y_test, pred_knn)))\n\nerrors = abs(pred_knn - y_test)\naux = 100 * (errors \/ y_test)\nknn_eval = round(100 - np.mean(aux),2)\nprint(\"Acur\u00e1cia:\", knn_eval, \"%\")\n\n#Valida\u00e7\u00e3o cruzada\nknn_cv = cross_val_score(estimator = KNN, X = X_train, y = y_train, cv = 10)\nknn_cv = round((knn_cv.mean()*100), 2)\nprint(\"Acur\u00e1cia usando valida\u00e7\u00e3o cruzada:\",knn_cv, \"%\\n\")\n\nconc0 = {\n    'Holdout':[dtr_eval,rfr_eval,lir_eval,knn_eval] ,\n    'CrossValidation':[dtr_cv,rfr_cv,lir_cv,knn_cv]\n}\nconcl0 = pd.DataFrame(conc0, columns=['Holdout', 'CrossValidation'], index=['DT', 'RF', 'LR', 'KNN'])","8d85fccc":"# Renomeandos os atributos para facilitar entendimento","2626d444":"# Projeto de Aprendizado de Maquina\n\nO dataset do Kaggle utilizado, apresenta informa\u00e7\u00f5es referentes \u00e0 dados em rela\u00e7\u00e3o a concreto e a for\u00e7a compressiva, que \u00e9 a capacidade de um material ou estrutura de resistir uma determinado carga sem alterar de tamanho.\n\nO projeto foi desenvolvido em 5 etapas: <br>\n1\u00ba Pr\u00e9 processamento e an\u00e1lise dos dados <br>\n2\u00ba Aplica\u00e7\u00e3o da \u00c1rvores de Decis\u00f5es <br>\n3\u00ba Aplica\u00e7\u00e3o do Random Forest <br>\n4\u00ba Aplica\u00e7\u00e3o da Regress\u00e3o Linear <br> \n5\u00ba Aplica\u00e7\u00e3o do KNN <br>\n","39b8910f":"# Verificando se existe dados faltos e seus respectivos tipos","d9933c45":"Pelos gr\u00e1ficos acima,n\u00e3o \u00e9 justific\u00e1vel uma redu\u00e7\u00e3o de atributos","030388fc":"# Leitura dos dados","ffc53c0f":"# Distribui\u00e7\u00e3o das resist\u00eancias e an\u00e1lise das v\u00e1riaveis","4cddba89":"# Aplicando os algoritmos de aprendizado","80e811df":"# An\u00e1lise do PairPlot e de um Heatmap de correla\u00e7\u00f5es para verificar a possibilidade de redu\u00e7\u00e3o de v\u00e1riaveis"}}