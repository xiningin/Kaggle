{"cell_type":{"810ed707":"code","d2534d4e":"code","50b4fba1":"code","28d4211b":"code","3921abd5":"code","63b24770":"code","3673cf7f":"code","97241410":"code","a1380240":"code","699326ce":"code","079d494a":"code","ae530181":"code","f5723a70":"code","8b936d1c":"code","5561504e":"code","8149615f":"code","e0c751ad":"code","d0f9f863":"code","95f5bbee":"code","0d0f03dd":"code","adee8515":"code","04a43c6e":"code","caf62863":"code","7c69b20f":"code","9629881b":"code","2102b97e":"code","59f9c28a":"code","4b4b0847":"markdown"},"source":{"810ed707":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport sklearn as sk\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nimport keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nimport plotly.graph_objs as go\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer,auc\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d2534d4e":"df = pd.read_csv(\"..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf = pd.DataFrame(df)\ndf.head()","50b4fba1":"sns.pairplot(df[['tenure','MonthlyCharges','TotalCharges','Churn','Contract','SeniorCitizen']], hue='Churn')","28d4211b":"### checking counts of types in each columns\nprint(df.InternetService.value_counts())\nprint(df.Contract.value_counts())\nprint(df.PaymentMethod.value_counts())\n\n### empty data replace with np.nan\ndf['TotalCharges'] = df['TotalCharges'].replace(\" \",np.nan)\n\n### drop rows including nan\ndf = df[df['TotalCharges'].notnull()]\n\n### change str type into float\ndf['TotalCharges'] = df['TotalCharges'].astype('float')","3921abd5":"### checking distribution of MonthlyCharges and TotalCharges\ndf.MonthlyCharges.plot(kind='hist',color='c')\nplt.xlabel('dollar')\nplt.title('MonthlyCharges')\nplt.show()\n\ndf.TotalCharges.plot(kind='hist',color='coral')\nplt.xlabel('dollar')\nplt.title('TotalCharges')\nplt.show()\n#df[['MonthlyCharges','TotalCharges']].plot(kind='hist', subplots=True)\n","63b24770":"### making dummy variables except customerID column\ndf_dum = pd.get_dummies(df.iloc[:,1:])","3673cf7f":"df_dum.head()","97241410":"plt.hist(data=df_dum, x='SeniorCitizen')\nplt.title('SeniorCitizen or Not?')\nplt.xlim(-1,2)\nplt.xticks([0,1])\nplt.show()","a1380240":"### chekcing columns\ndf_dum.columns","699326ce":"dum_cols = df.nunique()[df.nunique()<5].keys().tolist()\ndum_cols = dum_cols[:-1]\nnum_cols = df.nunique()[df.nunique()>=5].keys().tolist()\nnum_cols = num_cols[1:]\n\nprint(\"Total number of dum_cols: \"+ str(len(dum_cols)) + \"\\n\" + str(dum_cols)+\"\\n\")\nprint(\"Total number of num_cols: \"+ str(len(num_cols)) + \"\\n\" + str(num_cols))","079d494a":"def pie_plot(Column):    \n    ct1 = pd.crosstab(df[Column],df['Churn'])\n    trace1 = go.Pie(labels = ct1.index,\n                    values = ct1.iloc[:,0],\n                    hole=0.3,\n                    domain=dict(x=[0,.45]))\n    trace2 = go.Pie(labels = ct1.index,\n                    values = ct1.iloc[:,1],\n                    domain=dict(x=[.55,1]),\n                    hole=0.3)\n\n    layout = go.Layout(dict(title = Column + \" distribution in customer attrition \",\n                                plot_bgcolor  = \"rgb(243,243,243)\",\n                                paper_bgcolor = \"rgb(243,243,243)\",\n                                annotations = [dict(text = \"churn customers\",\n                                                    font = dict(size = 13),\n                                                    showarrow = False,\n                                                    x = .15, y = 1),\n                                               dict(text = \"Non churn customers\",\n                                                    font = dict(size = 13),\n                                                    showarrow = False,\n                                                    x = .88,y = 1)\n\n                                              ]\n                               )\n                          )\n\n    fig = go.Figure(data=[trace1,trace2],layout=layout)\n    py.iplot(fig)","ae530181":"for i in dum_cols:\n    pie_plot(i)","f5723a70":"### shorter the contract period, higher probability of churn? lets check crosstab\n\nct  = pd.crosstab(df.Contract, df.Churn)\nct.plot(kind='bar')\nplt.title('Churn by Contract')\nplt.ylabel(\"# of chrun\")\nplt.show()","8b936d1c":"### spliting into train and test set. fitting into linear regression model\nX_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(df_dum.iloc[:,:-2],df_dum.iloc[:,-1],test_size=0.2,random_state=5)\nln = LinearRegression()\nln_fit = ln.fit(X_train, Y_train)\n\n\n###  showing relationship between monthly charges, TotalCharges between churn\nplt.scatter(df['MonthlyCharges'], ln.predict(df_dum.iloc[:,:-2]), c='lawngreen', alpha=0.05)\nplt.title('Monthly Charges vs Churn')\nplt.show()\n\nplt.scatter(df['TotalCharges'], ln.predict(df_dum.iloc[:,:-2]), c='c',alpha=0.05)\nplt.title('Total Charges vs Churn')\nplt.show()","5561504e":"df","8149615f":"df.head()","e0c751ad":"### correlation heatmap\n\nplt.figure(figsize=(10,10))\ncorr = df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n","d0f9f863":"### correlation matrix checking\n\nrs = np.random.RandomState(0)\ndf = pd.DataFrame(rs.rand(10, 10))\ncorr = df_dum.corr()\ncorr.style.background_gradient()","95f5bbee":"### model fitting using logistic regression\n\nlm = LogisticRegression(max_iter=10000)\nfitted = lm.fit(X_train, Y_train)\npred = lm.predict(X_test)\nscores = lm.score(X_test,Y_test)\nprint(\"Logistic Regression score is.:\" + str(lm.score(X_test,Y_test)))\n","0d0f03dd":"fpr, tpr, thres = roc_curve(Y_test, pred)\nroc_auc = auc(fpr,tpr)","adee8515":"fpr, tpr, thres = roc_curve(Y_test, pred)\nroc_auc = auc(fpr,tpr)\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","04a43c6e":"cf_matrix = confusion_matrix(Y_test,pred)\nroc = roc_auc_score(Y_test,pred)\nprint(cf_matrix)\nprint(roc)","caf62863":"sns.heatmap(cf_matrix, annot=True, linewidths=1.0)","7c69b20f":"### model fitting with SVC\n\nsvc = SVC(max_iter=10000, gamma='auto')\nsvc_fitted = svc.fit(X_train, Y_train)\nsvc_pred = svc.predict(X_test)\nsvc_scores = svc.score(X_test,Y_test)\nprint(\"SVC Regression scores is..:\" + str(svc.score(X_test,Y_test)))","9629881b":"### model fitting using SVM svc\n\nsvm = LinearSVC(max_iter=100000)\nsvm_fitted = svm.fit(X_train, Y_train)\nsvm_pred = svm.predict(X_test)\nsvm_scores = svm.score(X_test,Y_test)\nprint(\"SVM Regression scores is..:\" + str(svm.score(X_test,Y_test)))","2102b97e":"fpr, tpr, thres = roc_curve(Y_test, svm_pred)\nroc_auc = auc(fpr,tpr)\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","59f9c28a":"### model fitting using deep learning\nfrom keras.callbacks import EarlyStopping\nearly_stopping_monitor = EarlyStopping(patience=10)\n\npredictors = np.array(df_dum.iloc[:,:-2])\ntarget = np.array(df_dum.iloc[:,-1])\n# Specify the model\nn_cols = predictors.shape[1]\nmodel_1 = Sequential()\nmodel_1.add(Dense(10, activation='relu', input_shape = (n_cols,)))\nmodel_1.add(Dense(10, activation='relu'))\nmodel_1.add(Dense(2, activation='softmax'))\nmodel_1.add(Dense(1))\n\nmodel_2 = Sequential()\nmodel_2.add(Dense(45, activation='relu', input_shape = (n_cols,)))\nmodel_2.add(Dense(100, activation='relu'))\nmodel_2.add(Dense(100, activation='relu'))\nmodel_2.add(Dense(2, activation='softmax'))\nmodel_2.add(Dense(1))\n\n# Compile the model\nmodel_1.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\nmodel_2.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n\n# Fit the model\nmodel_1_training = model_1.fit(predictors, target, batch_size=100, epochs=100, validation_split=0.2,callbacks=[early_stopping_monitor],verbose=False)\nmodel_2_training = model_2.fit(predictors, target, batch_size=100, epochs=100, validation_split=0.2,callbacks=[early_stopping_monitor],verbose=False)\npredictions = model_1.predict(X_test)\nprint(predictions)\nmodel_1.summary()\nmodel_1.evaluate(X_test,Y_test)\n\n### compare model1 and model2\nplt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\nplt.xlabel('Epochs')\nplt.ylabel('Validation score')\nplt.show()\n","4b4b0847":"It seems quite interesting. In the plot of monthly charges, lower charges users are seems to have lower Churn rates.\nHowever, in the ploty of total charges, lower charge users are seems to have hihger Chrun rate.. why?"}}