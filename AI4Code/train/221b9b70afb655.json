{"cell_type":{"8939b9bf":"code","d949b59c":"code","1dedcae3":"code","94fc8e44":"code","997aa409":"code","e31dcb2c":"code","4b40a662":"code","264c6e2e":"code","59c58954":"code","66bbaa7f":"code","2273915e":"code","7d7dc823":"code","0bc7a726":"markdown","feaa68d7":"markdown","568e8751":"markdown","db538dc6":"markdown","58228943":"markdown","fb3ca490":"markdown","85699d9c":"markdown","78bd3c99":"markdown","480df26d":"markdown","e65ffaeb":"markdown","d6894978":"markdown","d22ee88d":"markdown","b75888c3":"markdown","7493331b":"markdown","a7c9a649":"markdown","be404426":"markdown","bf2519ae":"markdown","95e7c98f":"markdown"},"source":{"8939b9bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d949b59c":"print(\"loading data takes about 1 minute....\")\n\ntrain_transaction = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv', index_col='TransactionID')\n#test_transaction = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv', index_col='TransactionID')\n\n#train_identity = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv', index_col='TransactionID')\n#test_identity = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv', index_col='TransactionID')\n\n#sample_submission = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/sample_submission.csv', index_col='TransactionID')\n\nprint(\"loading successful!\")","1dedcae3":"print(\"shape of train_transaction: \", train_transaction.shape, \"\\n\")\n\nprint(\"info of train_transaction: \\n\")\n\nprint(train_transaction.info())","94fc8e44":"# lets generate some useful lists of columns,\n# we want a list of numerical features\n# and a list of categorical features\n\nc = (train_transaction.dtypes == 'object')\nn = (train_transaction.dtypes != 'object')\ncat_cols = list(c[c].index)\nnum_cols = list(n[n].index) \n\nprint(cat_cols, \"\\n\")\nprint(\"number categorical features: \", len(cat_cols), \"\\n\\n\")\nprint(num_cols, \"\\n\")\nprint(\"number numerical features: \", len(num_cols))","997aa409":"# the int\/float datatypes have the following ranges:\n\n#   int8:  -128 to 127, range = 255  \n\n#  int16:  -32,768 to 32,767, range = 65,535\n\n#  int32:  -2,147,483,648 to 2,147,483,647, range = 4,294,967,295\n\n#  int64:  -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807,\n#           range = 18,446,744,073,709,551,615\n\n\n#  These ranges are the same for all float datatypes.\n#  By default all numerical columns in pandas are in int64 or float64.\n#  This means that when we find a numerical integer column whose \n#  values do not exceed one of the ranges shown above, we can then\n#  convert this datatype down to a smaller one. ","e31dcb2c":"print(\"train_transaction.info(): \\n\")\n\nprint(train_transaction.info())","4b40a662":"#  this function detects all the numerical columns,\n#  that can be converted to a smaller datatype.\n\ndef detect_num_cols_to_shrink(list_of_num_cols, dataframe):\n \n    convert_to_int8 = []\n    convert_to_int16 = []\n    convert_to_int32 = []\n    \n    #  sadly the datatype float8 does not exist\n    convert_to_float16 = []\n    convert_to_float32 = []\n    \n    for col in list_of_num_cols:\n        \n        if dataframe[col].dtype in ['int', 'int8', 'int32', 'int64']:\n            describe_object = dataframe[col].describe()\n            minimum = describe_object[3]\n            maximum = describe_object[7]\n            diff = abs(maximum - minimum)\n\n            if diff < 255:\n                convert_to_int8.append(col)\n            elif diff < 65535:\n                convert_to_int16.append(col)\n            elif diff < 4294967295:\n                convert_to_int32.append(col)   \n                \n        elif dataframe[col].dtype in ['float', 'float16', 'float32', 'float64']:\n            describe_object = dataframe[col].describe()\n            minimum = describe_object[3]\n            maximum = describe_object[7]\n            diff = abs(maximum - minimum)\n\n            if diff < 65535:\n                convert_to_float16.append(col)\n            elif diff < 4294967295:\n                convert_to_float32.append(col) \n        \n    list_of_lists = []\n    list_of_lists.append(convert_to_int8)\n    list_of_lists.append(convert_to_int16)\n    list_of_lists.append(convert_to_int32)\n    list_of_lists.append(convert_to_float16)\n    list_of_lists.append(convert_to_float32)\n    \n    return list_of_lists","264c6e2e":"num_cols_to_shrink_trans = detect_num_cols_to_shrink(num_cols, train_transaction)\n\nconvert_to_int8 = num_cols_to_shrink_trans[0]\nconvert_to_int16 = num_cols_to_shrink_trans[1]\nconvert_to_int32 = num_cols_to_shrink_trans[2]\n\nconvert_to_float16 = num_cols_to_shrink_trans[3]\nconvert_to_float32 = num_cols_to_shrink_trans[4]\n\nprint(\"convert_to_int8 :\", convert_to_int8, \"\\n\")\nprint(\"convert_to_int16 :\", convert_to_int16, \"\\n\")\nprint(\"convert_to_int32 :\", convert_to_int32, \"\\n\")\n\nprint(\"convert_to_float16 :\", convert_to_float16, \"\\n\")\nprint(\"convert_to_float32 :\", convert_to_float32, \"\\n\")","59c58954":"print(\"starting with converting process....\")\n\n# convert the datatypes with .astype() \n\nfor col in convert_to_int16:\n    train_transaction[col] = train_transaction[col].astype('int16')  \n    \nfor col in convert_to_int32:\n    train_transaction[col] = train_transaction[col].astype('int32') \n\nfor col in convert_to_float16:\n    train_transaction[col] = train_transaction[col].astype('float16')\n    \nfor col in convert_to_float32:\n    train_transaction[col] = train_transaction[col].astype('float32')\n    \nprint(\"successfully converted!\")","66bbaa7f":"print(\"train_transaction.info(): \\n\")   # now uses 548 MB\n\nprint(train_transaction.info(), \"\\n\")","2273915e":"for i in cat_cols:\n    \n    train_transaction[i] = train_transaction[i].astype('category')\n    \nprint(\"successfully converted all categorical features!\")","7d7dc823":"print(\"train_transaction.info(): \\n\")\n\nprint(train_transaction.info(), \"\\n\")","0bc7a726":"**As we can see this dataframe has 590540 rows and 393 columns.**\n\n**The .info() function of pandas is quite helpful, it shows us what datatypes the 393 columns have: float64(376), int64(3), object(14).**\n\n**And in the last line we can see that our dataframe uses about 1.7 GB of memory\/RAM, let's see if we can reduce it :)**\n\n**Before we can reduce the memory usage of our dataframe, we have to detect the numerical and the categorical features first:**","feaa68d7":"**Now we can check if the memory usage went down again:**","568e8751":"# 4. Summary\n\n\n**Converting the 379 numerical features saved about 1.1 GB, while converting the 14 categorical columns only saved about 55 MB.**\n\n**Considering the few lines of code and the low effort this whole procedure takes, it can really be worth it, since you can save Gigabytes of RAM.**","db538dc6":"**Wow, the memory usage went down from 1.7 GB to 548 MB, so converting the numerical datatypes can really be worth it.**\n\n**In the next and final chapter we will transform the categorical columns from 'object' datatype to 'category'.**","58228943":"**We have already created our list 'cat_cols' containing all categorical features.**\n\n**We can simply convert all of the 14 categorical features from 'object' datatype to 'category', we do not have to check for any conditions.**","fb3ca490":"**Well ok, converting the 14 categorical features from 'object' to 'category' only saved us about 55 MB, but there were only 14 categorical features.**","85699d9c":"**As we can see a lot of features can be converted,  most of them to float16, some more of them to float32.** ","78bd3c99":"# Thank you for reading this tutorial :)","480df26d":"# Hello and welcome to my memory usage reduction tutorial!\n\n\n**In this very short and simple tutorial I will show some insanely easy methods to reduce the memory\/RAM usage of pandas dataframes.**\n\n**I will not do any stuff like imputing, encoding, handling missing values, feature selection,  NONE of that stuff, ONLY memory usage reduction.**\n\n**For this tutorial I will use the data of the IEEE fraud detection competition:**  https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/submissions\n\n**If you are interested in a complete and detailed tutorial for this competition, feel free to have a look at this:** https:\/\/www.kaggle.com\/jonas0\/ieee-fraud-detection","e65ffaeb":"# 1. Load the data\n\n**For this short and simple tutorial we will only load the train_transaction data.**","d6894978":"# 3. Convert categorical features to 'category' datatype","d22ee88d":"# Overview\n \n## '1'. Load the data\n\n## '2'. Convert numerical datatypes to smaller ones\n\n## '3'. Convert categorical features to 'category' datatype\n\n## '4'. Summary","b75888c3":"**The dataframes uses 1.7 GB and has 376 columns in float64, 3 columns in int64 and 14 columns in object.**\n\n**Let's write some code that checks if we can convert a numerical feature to a smaller datatype:**","7493331b":"**Dataframes can contain two types of numerical values: integers and floats. These integers and floats have a certain datatype called int8\/int16\/int32\/int64  or float16\/float32\/float64. (float8 does not exist)**\n\n**As you maybe already know, the higher the number in the datatype, the more memory it consumes. Down below is a chart listing all numerical datatypes together with their minimum and maximum value displayable and the maximum range which this datatype can cover.**\n\n**When you load a dataframe with pandas all numerical features are given by int64\/float64 by default.**\n\n**If all values of a numerical feature do not exceed this range or the minimum or maximum value, you can convert this int64\/float64  number down to a smaller datatype. No information is lost, but we can save a lot of memory.** ","a7c9a649":"**Let's call the function and print all the numerical features we can convert:**","be404426":"**Let's have a look at our data:**","bf2519ae":"# 2. Convert numerical datatypes to smaller ones","95e7c98f":"**Let's look at our dataframe again before we start reducing the memory usage:**"}}