{"cell_type":{"9d464517":"code","8ccf9eb1":"code","49e67679":"code","82ff8afb":"code","3723b5a8":"code","4fda6ff4":"code","36db1604":"code","255e1f16":"code","076ae13b":"code","a828df91":"code","2f281651":"code","584f0dbe":"code","fe6949a2":"code","ccb9b0cf":"code","60bdb9f0":"code","1b3eead4":"code","02bec85c":"code","9073ce10":"code","c6a179e7":"code","2388fef5":"code","558173dd":"code","7031f909":"code","5ab151e7":"code","048f8d3e":"code","68b19f8d":"code","9306621f":"code","2cff69fb":"code","f7745f23":"code","dc963eae":"code","20265292":"code","57a62ab8":"code","11f545e4":"code","48190831":"code","6f8ea054":"code","5fe775bd":"code","300d17a0":"code","4be39195":"code","a8f85d78":"markdown","226fbf4d":"markdown","a80dea45":"markdown","69185075":"markdown","571eeaa2":"markdown","329b9eac":"markdown","c6b73ebc":"markdown","86fb56d9":"markdown","7c51c56f":"markdown","6e30fe6f":"markdown","81238052":"markdown","77b56e31":"markdown","87e9afd0":"markdown","8db4e207":"markdown","c5754eed":"markdown","d9eb1bbf":"markdown","70553650":"markdown","a5e6fd26":"markdown","50780417":"markdown","0bdbc055":"markdown","354129f6":"markdown","960f5673":"markdown","ad9c48fc":"markdown","0f0cb459":"markdown","5d6dbb07":"markdown","9db2da39":"markdown","47a88074":"markdown","f41621af":"markdown","48e7600a":"markdown","47f4b6b4":"markdown","fcf49e64":"markdown","2c2713cd":"markdown","9a09eeda":"markdown","69cf9d65":"markdown","c3d4ffeb":"markdown","d8c5e4b1":"markdown","9f07fa73":"markdown","4031249f":"markdown","933ded74":"markdown","55c0d876":"markdown","1f01a10f":"markdown"},"source":{"9d464517":"# Default\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly \nimport plotly.graph_objects as go\nimport seaborn as sns\n\n# Data prepocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# Tuning parameter\nfrom sklearn.model_selection import GridSearchCV\n\n# Model\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom keras.optimizers import SGD\nfrom keras.optimizers import Adam\nfrom sklearn.neural_network import MLPClassifier\n\n# result\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\n\n\n#retina\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')","8ccf9eb1":"df = pd.read_csv(\"..\/input\/obesity-levels\/ObesityDataSet_raw_and_data_sinthetic.csv\")\n# rename the lebel columns from 'NObeyesdad' to 'result'\ndf = df.rename(columns={'NObeyesdad': 'result'})\ndf.head()","49e67679":"print('Dataset consisting of ',df.shape[0],' observations')\nprint('Dataset consisting of ',df.shape[1],' columns')","82ff8afb":"df.info()","3723b5a8":"df.isnull().sum()","4fda6ff4":"df.describe()","36db1604":"name = df['result'].value_counts().index\nnum = df['result'].value_counts().values\n\nfig = px.pie(data_frame=df,names=name,values=num\n             ,title='Pies chard show the over all result',width=800,height=600)\nfig.update_traces(textposition='inside',textinfo='label+percent')\nfig.show()\n\nplt.figure(figsize=(12,7))\nsns.countplot(x='result',data=df,order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Results of each weight',fontsize=15)\nplt.show()","255e1f16":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='Gender',order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.ylabel('Count',fontsize=12)\nplt.xlabel(None)\nplt.title('The result of weight Vs Gender',fontsize=15)\nplt.show()","076ae13b":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='Age',data=df,order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.title('Result Vs Age',fontsize=15)\nplt.ylabel('Age (Year old)',fontsize=12)\nplt.xlabel(None)\nplt.show()","a828df91":"plt.figure(figsize=(13,8))\nsns.barplot(x='result',y='Weight',data=df,\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Weight (kg)',fontsize=12)\nplt.title('Result Vs Weight',fontsize=15)\nplt.show()","2f281651":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='family_history_with_overweight',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs overweight family',fontsize=15)\nplt.show()\n","584f0dbe":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='FAVC',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Eat high caloric food',fontsize=15)\nplt.show()","fe6949a2":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='FCVC',data=df,\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Amount of event',fontsize=12)\nplt.title('Result Vs Vegatable in meals',fontsize=15)\nplt.show()","ccb9b0cf":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='NCP',data=df,hue_order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Amount of meals',fontsize=12)\nplt.title('Result Vs Main means do you have daily',fontsize=15)\nplt.show()","60bdb9f0":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='CAEC',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Any food between meals',fontsize=15)\nplt.show()","1b3eead4":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='SMOKE',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Smoking',fontsize=15)\nplt.show()","02bec85c":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='CH2O',data=df,hue_order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Water (L)',fontsize=12)\nplt.title('Result Vs drink water (L)',fontsize=15)\nplt.show()","9073ce10":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='SCC',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Monitor the calories',fontsize=15)\nplt.show()","c6a179e7":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='FAF',data=df,hue_order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.ylabel('Amount of days',fontsize=12)\nplt.xlabel(None)\nplt.title('Result Vs Weekly working out \\n 0-5 day',fontsize=15)\nplt.show()\n","2388fef5":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='TUE',data=df,hue_order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Hours',fontsize=12)\nplt.title('Result Vs Hour',fontsize=15)\nplt.show()\n\n","558173dd":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='CALC',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs How often drink alcohol',fontsize=15)\nplt.show()","7031f909":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='MTRANS',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Transportation',fontsize=15)\nplt.show()","5ab151e7":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(),annot=True,square=True,center=0,vmin=-1,vmax=1,\n            cmap='BrBG',linewidths=5)","048f8d3e":"data = df.copy()\n\nfeature = data.drop('result',axis=1)\nanswer = data['result'].values.reshape(-1)","68b19f8d":"le = LabelEncoder()\nfor column_name in feature.columns:\n  if feature[column_name].dtype == object:\n    feature[column_name] = le.fit_transform(feature[column_name])\n  else:\n    pass\n\nanswer = le.fit_transform(answer)","9306621f":"feature.head()","2cff69fb":"xtrain,xtest,ytrain,ytest = train_test_split(feature,answer,test_size=0.3,random_state=42)\n\nparam_grid = {'criterion':['gini', 'entropy'],\n              'splitter':['best','random'],\n              'max_depth':list(range(1,50)),\n              }\n\ngrid = GridSearchCV(DecisionTreeClassifier(random_state=42),param_grid,cv=5)\ngrid.fit(xtrain,ytrain)\nprint(grid.best_params_)","f7745f23":"clf = DecisionTreeClassifier(criterion='entropy',max_depth=9,splitter='best')\nclf.fit(xtrain,ytrain)\ny_pred = clf.predict(xtest)\ny_prob = clf.predict_proba(xtest)\n\nmapping = dict(zip(le.classes_, range(0, len(le.classes_)+1)))\n\ncm = confusion_matrix(ytest,y_pred)\ncm_df = pd.DataFrame(cm,index=mapping)\n\nplt.figure(figsize=(8,6))                  \nsns.heatmap(cm_df, annot=True)\nplt.title('The accuracy Decision Tree (Best param): {0:.3f}'.format(accuracy_score(ytest,y_pred)),fontsize=13)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label',)\nplt.show()\n\nprint('Accuracy score: ', accuracy_score(ytest,y_pred))\nprint('Precision score: ',precision_score(ytest,y_pred,average='macro'))\nprint('Recall: ', recall_score(ytest,y_pred,average='macro'))\nprint('F1 score: ',f1_score(ytest,y_pred,average='macro'))\nprint('ROC-AUC score',roc_auc_score(ytest, y_prob, multi_class=\"ovo\",\n                                  average=\"macro\"))\n\n","dc963eae":"xtrain,xtest,ytrain,ytest = train_test_split(feature,answer,test_size=0.3,random_state=42)\n\nparam_grid = {'n_estimators':list(range(8,30)),\n              'criterion':['gini','entropy'],\n              'max_depth':list(range(1,50))\n              }\n\ngrid = GridSearchCV(RandomForestClassifier(random_state=42),param_grid,cv=5)\ngrid.fit(xtrain,ytrain)\nprint(grid.best_params_)","20265292":"clf = RandomForestClassifier(criterion='entropy',max_depth=10,n_estimators=29)\nclf.fit(xtrain,ytrain)\ny_pred = clf.predict(xtest)\ny_prob = clf.predict_proba(xtest)\n\nmapping = dict(zip(le.classes_, range(0, len(le.classes_)+1)))\nprint(mapping)\n\n\ncm = confusion_matrix(ytest,y_pred)\ncm_df = pd.DataFrame(cm,index=mapping)\n\nplt.figure(figsize=(8,6))                  \nsns.heatmap(cm_df, annot=True)\nplt.title('The accuracy of Random Forest (Best param): {0:.3f}'.format(accuracy_score(ytest,y_pred)),fontsize=13)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label',)\nplt.show()\n\nprint('Accuracy score: ', accuracy_score(ytest,y_pred))\nprint('Precision score: ',precision_score(ytest,y_pred,average='macro'))\nprint('Recall: ', recall_score(ytest,y_pred,average='macro'))\nprint('F1 score: ',f1_score(ytest,y_pred,average='macro'))\nprint('ROC-AUC score',roc_auc_score(ytest, y_prob, multi_class=\"ovo\",\n                                  average=\"macro\"))\n\n","57a62ab8":"xtrain,xtest,ytrain,ytest = train_test_split(feature,answer,test_size=0.3,random_state=42)\n\nscaler = StandardScaler()\nxtrain = scaler.fit_transform(xtrain)\nxtest = scaler.fit_transform(xtest)\n\nparam_grid = {'hidden_layer_sizes': [(16,),(32,),(48,)],\n    'activation': ['logistic', 'relu',  'tanh'],\n    'solver': ['sgd', 'adam'],\n    'learning_rate': ['constant','adaptive'],\n    'learning_rate_init':[0.001,0.1,0.2]\n}\n\ngrid = GridSearchCV(MLPClassifier(random_state=42),param_grid=param_grid,cv=5)\ngrid.fit(xtrain,ytrain)\nprint(grid.best_params_)","11f545e4":"clf = MLPClassifier(random_state=42, activation='tanh',hidden_layer_sizes=(16,),learning_rate='constant',learning_rate_init=0.2,solver='sgd')\nclf.fit(xtrain,ytrain)\ny_pred = clf.predict(xtest)\ny_prob = clf.predict_proba(xtest)\n\nmapping = dict(zip(le.classes_, range(0, len(le.classes_)+1)))\n\n\ncm = confusion_matrix(ytest,y_pred)\ncm_df = pd.DataFrame(cm,index=mapping)\n\nplt.figure(figsize=(8,6))                  \nsns.heatmap(cm_df, annot=True)\nplt.title('The accuracy of Neural network (MLP) (Best param): {0:.3f}'.format(accuracy_score(ytest,y_pred)),fontsize=13)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label',)\nplt.show()\n\nprint('Accuracy score: ', accuracy_score(ytest,y_pred))\nprint('Precision score: ',precision_score(ytest,y_pred,average='macro'))\nprint('Recall: ', recall_score(ytest,y_pred,average='macro'))\nprint('F1 score: ',f1_score(ytest,y_pred,average='macro'))\nprint('ROC-AUC score',roc_auc_score(ytest, y_prob, multi_class=\"ovo\",\n                                  average=\"macro\"))","48190831":"xtrain,xtest,ytrain,ytest = train_test_split(feature,answer,test_size=0.3,random_state=42)\n\nscaler = StandardScaler()\nxtrain = scaler.fit_transform(xtrain)\nxtest = scaler.fit_transform(xtest)","6f8ea054":"\ndef create_model(optimizer='adam',init_mode='uniform',activation='relu',learn_rate=0.01):\n    model = Sequential()\n    model.add(Dense(32, input_dim=16,kernel_initializer=init_mode, activation=activation))\n    model.add(Dense(7,kernel_initializer=init_mode, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model\n\nmodel = KerasClassifier(build_fn=create_model,epochs=200,batch_size=10, verbose=0)\n\noptimizer = ['SGD', 'Adam']\nlearn_rate = [0.001, 0.01, 0.1, 0.2]\ninit_mode = ['uniform', 'normal', 'zero']\nactivation = ['relu', 'tanh', 'sigmoid']\n\nparam_grid = dict(optimizer=optimizer,learn_rate=learn_rate,init_mode=init_mode,activation=activation)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(xtrain, ytrain)\n\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","5fe775bd":"from keras.utils import to_categorical\nytrain = to_categorical(ytrain)\n\n\ndef create_model(learn_rate=0.1):\n    model = Sequential()\n    model.add(Dense(32, input_dim=16,kernel_initializer='uniform', activation='tanh'))\n    model.add(Dense(7, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n# create model\nmodel = KerasClassifier(build_fn=create_model, verbose=0,epochs=200,batch_size=10)\n# define the grid search parameters\nmodel.fit(xtrain,ytrain)\n\ny_pred = model.predict(xtest)\ny_prob = model.predict_proba(xtest)","300d17a0":"cm = confusion_matrix(ytest,y_pred)\n# Transform to df for easier plotting\ncm_df = pd.DataFrame(cm,index=mapping)\n\nplt.figure(figsize=(8,6))                  \nsns.heatmap(cm_df, annot=True)\nplt.title('The accuracy of Neural Network (Keras) (Best param): {0:.3f}'.format(accuracy_score(ytest,y_pred)),fontsize=13)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label',)\nplt.show()\n\nprint('Accuracy score: ', accuracy_score(ytest,y_pred))\nprint('Precision score: ',precision_score(ytest,y_pred,average='macro'))\nprint('Recall: ', recall_score(ytest,y_pred,average='macro'))\nprint('F1 score: ',f1_score(ytest,y_pred,average='macro'))\nprint('ROC-AUC score',roc_auc_score(ytest, y_prob, multi_class=\"ovo\",\n                                  average=\"macro\"))","4be39195":"Accuracy = [0.9495268138801262,0.9290220820189274,0.9495268138801262,0.9542586750788643]\nPrecision = [0.9496370646467616,0.9289982846109511,0.9479671732410866,0.9527158255497573]\nRecall =[0.949554506796094,0.9282477859822877,0.9490035908012435,0.9539127392113407]\nF1Score = [0.9484366746957662,0.9282682517367851,0.9482428382213861,0.9529216047587254]\nRoc = [0.974036944270467,0.994470045662756,0.9975705078538368,0.9976146480444302]\n\nresult = pd.DataFrame(index=['DecisionTree','RandomForest','MLP','Keras'])\nresult['Accuracy'] = Accuracy\nresult['Precision'] = Precision\nresult['Recall'] = Recall\nresult['F1-Score'] = F1Score\nresult['ROC-AUC score'] = Roc\n\nprint(result)","a8f85d78":"As i said, I am still a beginner in this field so if you guys please suggest the wrong part or what to do, That would be a great help to me. Appreciate that, Thank you.","226fbf4d":"Result and weight","a80dea45":"How many main meals do you have daily?","69185075":"## Obesity Dataset","571eeaa2":"* The label of this dataset contain of 7 weight type which are Insufficient weight, Normal weight, Overweight level I, Overweight level II, Obesity type II, and Obesity type II. Each type of Obesty quite normal distribution and closely same value (12%-16%) and it slightly imbalance","329b9eac":"This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.","c6b73ebc":"* Data includes of both numerical data and catagorical data\n","86fb56d9":"How much time do you have physical activity?","7c51c56f":"Do you monitor the calories you eat daily?","6e30fe6f":"Overall of result","81238052":"## 3. EDA","77b56e31":"Results and Age","87e9afd0":"* None of missing value","8db4e207":"Do you eat any food between meals?","c5754eed":"Heatmap(Correlation)","d9eb1bbf":"Do you eat high caloric food frequenlty? ","70553650":"* Insufficient weight  are in the young age (19-21)\n* The obesity level increasing follow by age except Obesity type III","a5e6fd26":"Results and Gender","50780417":"Which transportation do you usually use?","0bdbc055":"Do you smoke? ","354129f6":"How often do you have physical activity?","960f5673":"## 5. Modeling and tuning hyperparameter","ad9c48fc":"Do you usually eat vagatables in your meals? ","0f0cb459":"## 1. Importing Library","5d6dbb07":"**Decision Tree**","9db2da39":"Attributes consisting of \n\n* What is your gender? (Gender) = Female, Male\n* what is your age? (Age) = Numeric value\n* What is your height? (Height) = Numeric value in meters\n* What is your weight? (Weight) = Numeric value in Kilograms\n* Has a family member suffered or suffers from overweight? = Yes, No\n* Do you eat high caloric food frequenlty? (FAVC) = Yes, No\n* Do you usually eat vegatables in your meals? (FCVC) = 1-3 follow by usually meal\n* How many main means do you have daily? (NCP) = Between 1 y 2, 3, more than 4\n* Do you eat any food between mean? (CAEC) = No, Sometimes, Frequently, Always\n* Do you smoke? (Smoke) = Yes, No\n* How much water do you drink daily? (CH20) = less than a liter, between 1 and 2L, more than 2 L\n* Do you monitor the calories you eat daily? (SCC) = Yes, No\n* How often do you have physical activity? (FAF) = I do not have, 1 or 2 days, 2 or 4 days, 4 or 5 day\n* How much time do you use technological devices? (TUE) = 0-2 hours, 3-5 hours, more than 5 hours\n* How often do you drink alcohol? (CALC) =I don't drink, Sometimes, Frequently, Always\n* Which transportation do you usually use? (MTRANS) = Automobile, Motorbike, Bike Public Transportation, Walking \n\n* Associated task: regression, classification, clustering\n      ","47a88074":"* When classified the obisity levels by gender found that some of levels are super-imbalance (Obisity type II and Obisity type III)","f41621af":"How often do you drink alcohol?","48e7600a":"* Obesity in family effected to sample","47f4b6b4":"How much water do you drink daily?","fcf49e64":"   The dataset contaning of both numerical data and categorical data then I splited data to feature as attribute and answer as label and encoder the object types column","2c2713cd":"## 6. Summary","9a09eeda":"* Make sense","69cf9d65":"## 4. Data Preprocessing","c3d4ffeb":"Has family member suffer or suffers from overweight?","d8c5e4b1":"## 2. Importing dataset","9f07fa73":"**Neural network: Multilayer perceptron**","4031249f":"**Neural network: Keras**","933ded74":"* Make Sense","55c0d876":"This experiment perform on various model:\n    * DecisionTree\n    * RandomForest\n    * Neural network using Multilayer perceptron\n    * Neural network using Keras\nand using GridSearch for tuning hyper parameter\n ","1f01a10f":"**Random Forest**"}}