{"cell_type":{"42d5f1a2":"code","f03b487f":"code","855fe4c3":"code","41bb98f7":"code","e7df957f":"code","e0201633":"code","f1248d9e":"code","6783b149":"code","40cd983a":"code","b2299d37":"code","2d0cf41e":"code","53ebe651":"code","1ba11a65":"code","7ab8796a":"code","e5155150":"code","8461866a":"code","36068267":"code","6753c021":"code","6a364086":"code","fbf42e1e":"code","445b21f7":"code","bb8c1025":"code","2494a889":"code","9b9ff8ec":"code","46b068f9":"code","0f003f5e":"code","c2e0e462":"code","7d5af1b8":"code","81620306":"code","2be60c86":"code","81ecdfce":"code","58209b46":"code","eff9dc11":"code","ec55aa3a":"code","deea82b8":"code","c3c1bfa3":"code","7a0da48b":"code","a691bb36":"code","de939a57":"code","6252b648":"code","c4e25b59":"code","c0680722":"code","260727b3":"code","b52acae8":"code","8c14e800":"code","cc5f6896":"markdown"},"source":{"42d5f1a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f03b487f":"%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = { \n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)","855fe4c3":"data = pd.read_csv('..\/input\/titanic\/train.csv')\nprint(data.shape)","41bb98f7":"data.head()","e7df957f":"data.describe()","e0201633":"data['Age'] = data['Age'].fillna(data['Age'].median())","f1248d9e":"data['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),stacked=True,);","6783b149":"data.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7), stacked=True);","40cd983a":"fig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',hue='Survived', data=data, split=True,palette={0: \"r\", 1: \"g\"});","b2299d37":"figure = plt.figure(figsize=(25, 7))\nplt.hist([data[data['Survived'] == 1]['Fare'], data[data['Survived'] == 0]['Fare']], \n         stacked=True, color = ['g','r'],\n         bins = 50, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend();","2d0cf41e":"plt.figure(figsize=(25, 7))\nax = plt.subplot()\n\nax.scatter(data[data['Survived'] == 1]['Age'], data[data['Survived'] == 1]['Fare'], \n           c='green', s=data[data['Survived'] == 1]['Fare'])\nax.scatter(data[data['Survived'] == 0]['Age'], data[data['Survived'] == 0]['Fare'], \n           c='red', s=data[data['Survived'] == 0]['Fare']);","53ebe651":"ax = plt.subplot()\nax.set_ylabel('Average fare')\ndata.groupby('Pclass').mean()['Fare'].plot(kind='bar', figsize=(25, 7), ax = ax);","1ba11a65":"fig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Embarked', y='Fare', hue='Survived', data=data, split=True, palette={0: \"r\", 1: \"g\"});","7ab8796a":"def status(feature):\n    print('Processing', feature, ': ok')","e5155150":"def get_combined_data():\n    # reading train data\n    train = pd.read_csv('..\/input\/titanic\/train.csv')\n    \n    # reading test data\n    test = pd.read_csv('..\/input\/titanic\/test.csv')\n\n    # extracting and then removing the targets from the training data \n    targets = train.Survived\n    train.drop(['Survived'], 1, inplace=True)\n    \n\n    # merging train data and test data for future feature engineering\n    # we'll also remove the PassengerID since this is not an informative feature\n    combined = train.append(test)\n    combined.reset_index(inplace=True)\n    combined.drop(['index', 'PassengerId'], inplace=True, axis=1)\n    \n    return combined\n\ncombined = get_combined_data()","8461866a":"print(combined.shape)","36068267":"combined.head()","6753c021":"titles = set()\nfor name in data['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\n    \nprint(titles)    ","6a364086":"Title_Dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\"\n}\n\ndef get_titles():\n    # we extract the title from each name\n    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    \n    # a map of more aggregated title\n    # we map each title\n    combined['Title'] = combined.Title.map(Title_Dictionary)\n    status('Title')\n    return combined","fbf42e1e":"combined = get_titles()\ncombined.head()","445b21f7":"combined[combined['Title'].isnull()]","bb8c1025":"print(combined.iloc[:891].Age.isnull().sum())","2494a889":"grouped_train = combined.iloc[:891].groupby(['Sex','Pclass','Title'])\ngrouped_median_train = grouped_train.median()\ngrouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n\ngrouped_median_train.head()","9b9ff8ec":"def fill_age(row):\n    condition = (\n        (grouped_median_train['Sex'] == row['Sex']) & \n        (grouped_median_train['Title'] == row['Title']) & \n        (grouped_median_train['Pclass'] == row['Pclass'])\n    ) \n    return grouped_median_train[condition]['Age'].values[0]\n\n\ndef process_age():\n    global combined\n    # a function that fills the missing values of the Age variable\n    combined['Age'] = combined.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n    status('age')\n    return combined\n\ncombined = process_age()","46b068f9":"def process_names():\n    global combined\n    # we clean the Name variable\n    combined.drop('Name', axis=1, inplace=True)\n    \n    # encoding in dummy variable\n    titles_dummies = pd.get_dummies(combined['Title'], prefix='Title')\n    combined = pd.concat([combined, titles_dummies], axis=1)\n    \n    # removing the title variable\n    combined.drop('Title', axis=1, inplace=True)\n    \n    status('names')\n    return combined","0f003f5e":"combined = process_names()\n\ncombined.head()","c2e0e462":"def process_fares():\n    global combined\n    # there's one missing fare value - replacing it with the mean.\n    combined.Fare.fillna(combined.iloc[:891].Fare.mean(), inplace=True)\n    status('fare')\n    return combined","7d5af1b8":"combined = process_fares()","81620306":"def process_embarked():\n    global combined\n    # two missing embarked values - filling them with the most frequent one in the train  set(S)\n    combined.Embarked.fillna('S', inplace=True)\n    # dummy encoding \n    embarked_dummies = pd.get_dummies(combined['Embarked'], prefix='Embarked')\n    combined = pd.concat([combined, embarked_dummies], axis=1)\n    combined.drop('Embarked', axis=1, inplace=True)\n    status('embarked')\n    return combined\ncombined = process_embarked()\n\ncombined.head()\n","2be60c86":"train_cabin, test_cabin = set(), set()\n\nfor c in combined.iloc[:891]['Cabin']:\n    try:\n        train_cabin.add(c[0])\n    except:\n        train_cabin.add('U')\n        \nfor c in combined.iloc[891:]['Cabin']:\n    try:\n        test_cabin.add(c[0])\n    except:\n        test_cabin.add('U')\n\nprint(train_cabin)","81ecdfce":"print(test_cabin)","58209b46":"def process_cabin():\n    global combined    \n    # replacing missing cabins with U (for Uknown)\n    combined.Cabin.fillna('U', inplace=True)\n    \n    # mapping each Cabin value with the cabin letter\n    combined['Cabin'] = combined['Cabin'].map(lambda c: c[0])\n    \n    # dummy encoding ...\n    cabin_dummies = pd.get_dummies(combined['Cabin'], prefix='Cabin')    \n    combined = pd.concat([combined, cabin_dummies], axis=1)\n\n    combined.drop('Cabin', axis=1, inplace=True)\n    status('cabin')\n    return combined\n\ncombined = process_cabin()","eff9dc11":"def process_sex():\n    global combined\n    # mapping string values to numerical one \n    combined['Sex'] = combined['Sex'].map({'male':1, 'female':0})\n    status('Sex')\n    return combined\n\ncombined = process_sex()","ec55aa3a":"def process_pclass():\n    \n    global combined\n    # encoding into 3 categories:\n    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix=\"Pclass\")\n    \n    # adding dummy variable\n    combined = pd.concat([combined, pclass_dummies],axis=1)\n    \n    # removing \"Pclass\"\n    combined.drop('Pclass',axis=1,inplace=True)\n    \n    status('Pclass')\n    return combined\n\ncombined = process_pclass()","deea82b8":"def cleanTicket(ticket):\n    ticket = ticket.replace('.', '')\n    ticket = ticket.replace('\/', '')\n    ticket = ticket.split()\n    ticket = map(lambda t : t.strip(), ticket)\n    ticket = list(filter(lambda t : not t.isdigit(), ticket))\n    if len(ticket) > 0:\n        return ticket[0]\n    else: \n        return 'XXX'\n\ntickets = set()\nfor t in combined['Ticket']:\n    tickets.add(cleanTicket(t))\n\nprint(len(tickets))\n#37\n\n\ndef process_ticket():\n    \n    global combined\n    \n    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n    def cleanTicket(ticket):\n        ticket = ticket.replace('.','')\n        ticket = ticket.replace('\/','')\n        ticket = ticket.split()\n        ticket = map(lambda t : t.strip(), ticket)\n        ticket = list(filter(lambda t : not t.isdigit(), ticket))\n        if len(ticket) > 0:\n            return ticket[0]\n        else: \n            return 'XXX'\n    \n\n    # Extracting dummy variables from tickets:\n\n    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n    tickets_dummies = pd.get_dummies(combined['Ticket'], prefix='Ticket')\n    combined = pd.concat([combined, tickets_dummies], axis=1)\n    combined.drop('Ticket', inplace=True, axis=1)\n\n    status('Ticket')\n    return combined\n\ncombined = process_ticket()","c3c1bfa3":"def process_family():\n    \n    global combined\n    # introducing a new feature : the size of families (including the passenger)\n    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n    \n    # introducing other features based on the family size\n    combined['Singleton'] = combined['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    combined['SmallFamily'] = combined['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n    combined['LargeFamily'] = combined['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n    \n    status('family')\n    return combined\ncombined = process_family()\n\nprint(combined.shape)","7a0da48b":"from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV","a691bb36":"def compute_score(clf, X, y, scoring='accuracy'):\n    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n    return np.mean(xval)","de939a57":"def recover_train_test_target():\n    global combined\n    \n    targets = pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Survived'])['Survived'].values\n    train = combined.iloc[:891]\n    test = combined.iloc[891:]\n    \n    return train, test, targets\n\ntrain, test, targets = recover_train_test_target()","6252b648":"clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\nclf = clf.fit(train, targets)","c4e25b59":"features = pd.DataFrame()\nfeatures['feature'] = train.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(25, 25))","c0680722":"model = SelectFromModel(clf, prefit=True)\ntrain_reduced = model.transform(train)\nprint(train_reduced.shape)\n\ntest_reduced = model.transform(test)\nprint(test_reduced.shape)","260727b3":"logreg = LogisticRegression()\nlogreg_cv = LogisticRegressionCV()\nrf = RandomForestClassifier()\ngboost = GradientBoostingClassifier()\n\nmodels = [logreg, logreg_cv, rf, gboost]\n\nfor model in models:\n    print('Cross-validation of : {0}'.format(model.__class__))\n    score = compute_score(clf=model, X=train_reduced, y=targets, scoring='accuracy')\n    print('CV score = {0}'.format(score))\n    print('****')\n","b52acae8":"run_gs = False\n\nif run_gs:\n    parameter_grid = {\n                 'max_depth' : [4, 6, 8],\n                 'n_estimators': [50, 10],\n                 'max_features': ['sqrt', 'auto', 'log2'],\n                 'min_samples_split': [2, 3, 10],\n                 'min_samples_leaf': [1, 3, 10],\n                 'bootstrap': [True, False],\n                 }\n    forest = RandomForestClassifier()\n    cross_validation = StratifiedKFold(n_splits=5)\n\n    grid_search = GridSearchCV(forest,\n                               scoring='accuracy',\n                               param_grid=parameter_grid,\n                               cv=cross_validation,\n                               verbose=1\n                              )\n\n    grid_search.fit(train, targets)\n    model = grid_search\n    parameters = grid_search.best_params_\n\n    print('Best score: {}'.format(grid_search.best_score_))\n    print('Best parameters: {}'.format(grid_search.best_params_))\n    \nelse: \n    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n    \n    model = RandomForestClassifier(**parameters)\n    model.fit(train, targets)","8c14e800":"output = model.predict(test).astype(int)\ndf_output = pd.DataFrame()\naux = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_output['PassengerId'] = aux['PassengerId']\ndf_output['Survived'] = output\ndf_output[['PassengerId','Survived']].to_csv('titanic_outcome.csv', index=False)","cc5f6896":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n*     text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\");"}}