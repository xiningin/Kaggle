{"cell_type":{"00e195d3":"code","520e227c":"code","b8e60c06":"code","bef791a6":"code","711fcac3":"code","03f7f73a":"code","a6970fbf":"code","be1da327":"code","8e01a0b2":"code","8fc833ee":"code","1f440378":"code","f3325624":"code","f0d536bd":"markdown","f571a92d":"markdown","2e820ed9":"markdown","9d8491c9":"markdown","7fb51d02":"markdown","0b576d51":"markdown","d25c47b6":"markdown","65dfd0e1":"markdown","65814757":"markdown","3bdc7e1f":"markdown","8deb031c":"markdown","ce30cbf3":"markdown","fa4dc6f6":"markdown","286e5f38":"markdown","7458f499":"markdown","298667b8":"markdown"},"source":{"00e195d3":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt","520e227c":"#List to save contexts\ncontexts = []","b8e60c06":"'''\nimport json\nimport spacy\n\nprint('It\\'s running!\\n')\n\nnlp = spacy.load('en')\nvocab = ['transmission', 'transmitted', 'transmitting', 'incubation', 'incubate', 'incubated', 'environmental', 'stability', 'health status', 'asymptomatic', 'physical science', 'distribution', 'hydrophilic', 'phobic', 'environment', 'decontamination', 'nasal', 'fecal', 'model', 'phenotypic', 'phenotype', 'immunity', 'protective', 'protection']\n\npaths = open('\/kaggle\/input\/file-paths\/file_paths.txt', 'r')\ncount = 0\nfor p in paths:\n    \n    if count >=-1:\n        \n        text = \"\"\n        try:\n            data = open(p[:-1]).read()\n        except:\n            continue\n        \n        data_dic = json.loads(data)\n        try:\n            title = data_dic['metadata']['title']\n        except:\n            title = \"\"\n        try:\n            abstract = data_dic['abstract'][0]['text']\n        except:\n            abstract = \"\"\n        \n        body_structure = data_dic['body_text']\n        body = \"\"\n        for i in range(0,len(body_structure)):\n            body+= body_structure[i]['text'] + \" \"\n        \n        text += title + \". \" + abstract + \" \" + body + \"\\n\"\n\n        try:\n            doc = nlp(text)\n        except:\n            print('Article skipped due to the number of tokens, more than 1 million!')\n            continue\n\n        for token in doc:\n            if str(token) in vocab:\n                contexts.append(str(token.sent)) #Contexts, that is full sentences containing keywords,\n                                                 #extracted here.\n    count+=1\n    if count == 29335:\n        break\npaths.close()\nprint('Finished!')\n'''","bef791a6":"import re\n\nif len(contexts)==0:\n    ctx = open('\/kaggle\/input\/all-contexts\/Contexts_Kaggle_Covid-19_2.txt', 'r')\nelse:\n    ctx = contexts\n\ncontx = []\nfor c in ctx:\n    c = re.sub('Context: ','',c)\n    c = c[:-1]\n    #Do not take into account contexs which contains the pronoun \"we\"...\n    pron = c.lower().split()\n    if \"we\" in pron:\n        continue\n    elif \"COVID-19\".lower() in c.lower() or \"SARS-COV-2\".lower() in c.lower(): # make sure the contexts talk about COVID-19 and not about other viruses. \n        contx.append(c.lower())\n\nprint(\"Number of contexts: \", len(contx))","711fcac3":"import sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer as BoW\nfrom sklearn.feature_extraction.text import TfidfVectorizer as TF_IDF\n\nbow = BoW(ngram_range=(1,1)).fit(contx)\nbw = bow.transform(contx)\nX = bw.toarray()\nprint(\"Dimension of the matrix of Data: \", X.shape)","03f7f73a":"from sklearn.decomposition import LatentDirichletAllocation\n\nlda = LatentDirichletAllocation(n_components=5) #Number of clusters (5)\nlda.fit(bw)\n\n#get clusters for some given samples:\nclusters_ids = []\nfor i in range(bw.shape[0]):\n    prob = lda.transform(bw[i])\n    clusters_ids.append((i,np.argmax(prob)))","a6970fbf":"samplesXcluster = [0,0,0,0,0]    # 5 clusters\ny = []\nfor c in clusters_ids:\n    y.append(c[1])\n    samplesXcluster[c[1]]+=1\ny = np.asarray(y)","be1da327":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nclt = ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5']\nsamples = [samplesXcluster[0],samplesXcluster[1],samplesXcluster[2],samplesXcluster[3],samplesXcluster[4]]\nax.bar(clt,samples)\nplt.show()","8e01a0b2":"from sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.model_selection import KFold\nfrom sklearn.svm import SVC\n\nkf = KFold(n_splits=50, shuffle=True)\nscores = []\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    #Logistic regression classifier\n    clf = LR(C=1, max_iter=200, solver='liblinear').fit(X_train, y_train)\n    \n    scores.append(clf.score(X_test, y_test))\nprint('Score = ', np.round(np.mean(np.asarray(scores)),2))","8fc833ee":"## Test classification using some of the Task's keywords and phrases.\n\n## Comment or uncomment according to the query to be used.\n\n#query = [\"incubation period in days\"]\n#query = [\"how long individuals are contagious.\"]\n#query = [\"how long individuals are contagious after recovery.\"]\nquery = [\"Prevalence of asymptomatic shedding\"]\n#query = [\"Prevalence of asymptomatic transmission in children\"]\n#query = [\"transmission in children\"]\n#query = [\"seasonality of transmission\"]\n#query = [\"physical science of the coronavirus\"]\n#query = [\"Smoking, pre-existing lung disease\"]\n#query = [\"Role of the environment in transmission\"]\n#quetion = [\"Effectiveness of personal protective equipment\"]\n#query = [\"control strategies\"]\n#query = [\"how long individuals are contagious, even after recovery\"]\n#query = [\"Physical science\"]\n#query = [\"Persistence and stability\"]\n#query = [\"Persistence of virus on surfaces\"]\n#query = [\"history of the virus\"]\n#query = [\"diagnostic\"]\n#query = [\"phenotypic change\"]\n\n\nqf = bow.transform(query)\nind = clf.predict(qf)\nout = []\nfor c in clusters_ids:\n    if c[1] == ind:\n        out.append(contx[c[0]][1:])","1f440378":"from scipy.spatial.distance import cosine as dist\nimport operator\n\nanswer = bow.transform(out).toarray()\nqq = qf.toarray()\ndistances = np.zeros(answer.shape[0])\nans_dist = dict()\ni = 0\nfor a in answer:\n    d = dist(a,qq)\n    distances[i] = d \n    ans_dist.update({i:d})\n    i+=1\n    \ndist_sort = sorted(ans_dist.items(), key=operator.itemgetter(1), reverse=False)\n\nanswer_words = \"\"\nresults2show = 10\nfor k in range(results2show):\n    try:\n        ans = out[dist_sort[k][0]]\n        print(\"- \", ans + \"\\n\")\n        answer_words += ans + ' ' \n    except:\n        continue","f3325624":"from wordcloud import WordCloud, STOPWORDS\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(width = 600, height = 600,\n                background_color ='black',\n                stopwords = stopwords,\n                min_font_size = 10).generate(answer_words)\n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n  \nplt.show()","f0d536bd":"## 2. Extraction of contexts containing keywords from dataset","f571a92d":"   - Wordcloud visualization of results","2e820ed9":"The code chunk below takes time to process due to its computational cost. However, it is not neccessary to run it as we have created and uploaded the two files that it is intended to create. That is one containing all the paths to relevant articles, and another one cotaining all the contexts relevant to the defined keywords. <b>Therefore this step may be skipped and proceed to 2.1<\/b>. If you want to run it, please uncomment the code below.","9d8491c9":"# COVID-19 - Information Extraction Combining Unsupervised and Supervised Learning\n\n## What is known about transmission, incubation, and environmental stability?","7fb51d02":"## 7. Query-based retrieval of relevant contexts using logistic regression","0b576d51":"## 6. Training classifiers using Bag of Words","d25c47b6":"### Findings\n\n1. Efficiency of context classification with $5$ clusters is $0.78$.\n2. A lower number of clusters seems to improve efficiency, but it may affect relevance of returned results. Relevance has been evaluated qualitatively only.\n3. We have observed that the answer to a specific query using the Task's keywords is often found explicitely (or implied) in the results. See below a couple of examples:\n\n   - Query: Range of incubation periods for the disease in humans\n     - Answer: the symptoms of covid-19 infection appear after an incubation period of approximately 5.2 days.\n   - Query: how long individuals are contagious?\n     - Answer: sars-cov-2 is contagious even in the incubation (sars was not).","65dfd0e1":"## 1. Keyword selection from Task's questions\n\nTransmission, transmitted, transmitting, incubate, incubation, incubated, environmental, stability, asymptomatic, hysical science,\tprotection, health status, distribution, hydrophilic, phobic, environment, decontamination, nasal, fecal, model, phenotypic, phenotype, immunity, protective.","65814757":"## 8. Ranking and returning contexts using cosine distance between query and retrieved contexts\n","3bdc7e1f":"## 2.1 Filtering out irrelevant contexts","8deb031c":"# Content\n\n## A. Methodology\n\n1. Keyword selection from Task's questions\n2. Extraction of contexts containing keywords \n3. Representation of contexts in a vector space\n4. Clustering of contexts using LDA (Latent Dirichlet Allocation)\n5. Building a database for supervised learning\n   - Input: contexts (see 2 above)\n   - Output: groups of contexts (see 4 above)\n6. Training classifiers using Bag of Words\n7. Query-based retrieval of relevant contexts using logistic regression\n8. Ranking and returning contexts using cosine distance between query and retrieved contexts\n   - Wordcloud visualization of results\n\n## B. Findings\n\n## C. Pros and Cons","ce30cbf3":"## 3. Representation of contexts in a vector space. Bag-of-Words representation.","fa4dc6f6":"## Exploring the clusters","286e5f38":"## 4. Clustering of contexts using LDA (Latent Dirichlet Allocation)","7458f499":"## 5. Building a database for supervised learning\n    Database format:\n   - Input: contexts (see 2 above)\n   - Output: groups of contexts (see 4 above)\n\n### Building the output variables for a supervised dataset from the clustering process","298667b8":"## Pros and Cons\n\n### Pros\n1. Simple and completly automatic approach combining unsupervised and supervised techniques.\n2. The system returns detailed information (not complete articles) about a topic or keyword. \n3. The system allows queries using natural language.\n4. Low computation cost\n5. No feature engineering\n6. Highly interpretable features\n7. Can be easily adapted to the other tasks in this challenge with different questions.\n8. The system does not require external resources besides the dataset.\n9. The number of results to show can be define as desired.\n\n### Cons\n1. No query reformulation implemented.\n2. No metadata included in the results (i.e., source of the information, year, etc.).\n3. The number of clusters has to be defined manually.\n4. Relevant information may have been left out during filtering of contexts.\n5. No keyword stemming or lemmatization\n6. No NER or relation extraction"}}