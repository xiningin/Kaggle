{"cell_type":{"7c927022":"code","12c42330":"code","aaca6b51":"code","969eb4a3":"code","c80bbc6e":"code","a089412c":"code","c4fc0f7e":"code","a173e82f":"code","ee3ce12f":"code","7614e243":"code","c6b7ab8b":"code","4a63a061":"code","eac9634e":"code","831307eb":"code","fa0fce29":"code","936bec7d":"code","417ca172":"markdown","e67ae4d0":"markdown","d2d7f12f":"markdown","74c60d2e":"markdown","39a5624e":"markdown","de5b5508":"markdown","71d915b5":"markdown","86ccdc6f":"markdown","8baa6641":"markdown","9c860cd0":"markdown","e6914072":"markdown","76dceeec":"markdown","d5dcdc48":"markdown","5a5c0615":"markdown","1cf394da":"markdown","4f2e5a84":"markdown","54829386":"markdown"},"source":{"7c927022":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","12c42330":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport re\nfrom itertools import product\n\n# matplotlib style\nplt.style.use('fivethirtyeight')\n\n# random state\nRSTATE=1984","aaca6b51":"# color hunt palettes\nch_div_palette_1 = [\"#288fb4\", \"#1d556f\", \"#efddb2\", \"#fa360a\"]\nch_div_palette_2 = [\"#ff5335\", \"#dfe0d4\", \"#3e92a3\", \"#353940\"]\nch_div_palette_3 = [\"#daebee\", \"#b6d7de\", \"#fcedda\", \"#ff5126\"]\n# matplotlib \"fivethirtyeight\" style colors\nch_div_palette_4 = ['#008fd5', '#fc4f30', '#e5ae38', '#6d904f', '#8b8b8b', '#810f7c']","969eb4a3":"# https:\/\/www.kaggle.com\/c\/human-protein-atlas-image-classification\/data\nlabel_names = [\n    \"Nucleoplasm\",\n    \"Nuclear membrane\",\n    \"Nucleoli\",\n    \"Nucleoli fibrillar center\",\n    \"Nuclear speckles\",\n    \"Nuclear bodies\",\n    \"Endoplasmic reticulum\",\n    \"Golgi apparatus\",\n    \"Peroxisomes\",\n    \"Endosomes\",\n    \"Lysosomes\",\n    \"Intermediate filaments\",\n    \"Actin filaments\",\n    \"Focal adhesion sites\",\n    \"Microtubules\",\n    \"Microtubule ends\",\n    \"Cytokinetic bridge\",\n    \"Mitotic spindle\",\n    \"Microtubule organizing center\",\n    \"Centrosome\",\n    \"Lipid droplets\",\n    \"Plasma membrane\",\n    \"Cell junctions\",\n    \"Mitochondria\",\n    \"Aggresome\",\n    \"Cytosol\",\n    \"Cytoplasmic bodies\",\n    \"Rods & rings\",    \n]\n    \ndef get_num_labels_for_instance(label_string):\n    labels = re.split(r'\\s+', label_string)\n    return len(labels)\n\ndef get_label_presence_func(label):\n    def is_label_present(label_string):\n        labels = set(re.split(r'\\s+', label_string))\n        return int(str(label) in labels)\n    return is_label_present\n\ndef is_single_label(label_string):\n    label_ids = re.split(r'\\s+', label_string)\n    if len(label_ids) > 1:\n        return False\n    return True\n \ndef get_label_name_for_label_id_string(label_ids_str):\n    label_ids = re.split(r'\\s+', label_ids_str)\n    label_ids = [int(id) for id in label_ids]\n    label = \"+\".join([label_names[id] for id in label_ids])\n    return label\n\n# Returns different bar color for single and multi-labels\ndef get_bar_color_1(is_single_label):\n    if is_single_label:\n        return ch_div_palette_1[0]\n    return ch_div_palette_1[2]\n\n# Returns different bar color for single and multi-labels\ndef get_bar_color_2(is_single_label):\n    if is_single_label:\n        return ch_div_palette_2[0]\n    return ch_div_palette_2[2]\n\n# Returns different bar color for single and multi-labels\ndef get_bar_color_3(is_single_label):\n    if is_single_label:\n        return ch_div_palette_3[2]\n    return ch_div_palette_3[3]\n\n# Returns different bar color for single and multi-labels\ndef get_bar_color_4(is_single_label):\n    if is_single_label:\n        return ch_div_palette_4[0]\n    return ch_div_palette_4[1]","c80bbc6e":"labels_df = pd.read_csv(\"..\/input\/train.csv\")\nprint(\"Shape of the training labels frame (train.csv): \", labels_df.shape)\nlabels_df.head()","a089412c":"labels_df[\"num_labels\"] = labels_df[\"Target\"].apply(get_num_labels_for_instance)\nlabels_count_dist = labels_df.groupby(\"num_labels\")[\"num_labels\"].count()\nfig, ax = plt.subplots(num=1)\nax.bar(labels_count_dist.index.values, labels_count_dist.values)\nax.set_xlabel(\"Number of labels per instance\")\nax.set_ylabel(\"Number of instances\")\nax.set_title(\"Labels count distribution\")\nplt.show()","c4fc0f7e":"multi_labels_dist = pd.DataFrame()\ntmp = labels_df.groupby(\"Target\")[\"Target\"].count().sort_values(ascending=False)\nmulti_labels_dist[\"Target\"] = tmp.index.values\nmulti_labels_dist[\"Count\"] = tmp.values\nmulti_labels_dist[\"is_single_label\"] = multi_labels_dist[\"Target\"].apply(is_single_label)\nmulti_labels_dist[\"Target_str\"] = multi_labels_dist[\"Target\"].apply(get_label_name_for_label_id_string)\nmulti_labels_dist = multi_labels_dist[[\"Target\", \"Target_str\", \"Count\", \"is_single_label\"]]\nprint(\"Number of unique labels (single\/multi): {}\".format(multi_labels_dist.shape[0]))\nmulti_labels_dist.head()","a173e82f":"topn = 50\nfig, ax = plt.subplots(num=2)\nfig.set_figwidth(15)\nfig.set_figheight(10)\nbar_colors = multi_labels_dist[\"is_single_label\"].apply(get_bar_color_4).head(topn)\nax.bar(multi_labels_dist[\"Target_str\"].head(topn), multi_labels_dist[\"Count\"].head(topn), color=bar_colors)\nax.set_xticks(range(topn))\nax.set_xticklabels(multi_labels_dist[\"Target_str\"].head(topn), rotation = 45, ha=\"right\")\nax.set_title(\"Distribution of top-{} training labels (single\/multi)\".format(topn))\nplt.show()","ee3ce12f":"label_columns_df = pd.DataFrame()\nfor i in range(len(label_names)):\n    label_chk_fn = get_label_presence_func(i)\n    label_columns_df[label_names[i]] = labels_df[\"Target\"].apply(label_chk_fn)\nlabels_dist = label_columns_df.sum().sort_values(ascending=False)","7614e243":"fig, ax = plt.subplots(num=2)\nfig.set_figwidth(15)\nfig.set_figheight(10)\nax.bar(labels_dist.index.values, labels_dist.values)\nax.set_xticks(range(len(labels_dist.values)))\nax.set_xticklabels(labels_dist.index.values, rotation = 45, ha=\"right\")\nax.set_title(\"Distribution of single labels\")\nplt.show()","c6b7ab8b":"fig, ax = plt.subplots(num=1, nrows=3, ncols=3)\nfig.set_figheight(15)\nfig.set_figwidth(15)\nfor idx, (x, y) in enumerate(product(range(3), range(3))):\n    img_blue = cv2.imread(\"..\/input\/train\/\" + labels_df.loc[idx, \"Id\"] + \"_blue.png\", cv2.IMREAD_GRAYSCALE)\n    img_green = cv2.imread(\"..\/input\/train\/\" + labels_df.loc[idx, \"Id\"] + \"_green.png\", cv2.IMREAD_GRAYSCALE)\n    img_red = cv2.imread(\"..\/input\/train\/\" + labels_df.loc[idx, \"Id\"] + \"_red.png\", cv2.IMREAD_GRAYSCALE)\n    img_bgr = cv2.merge((img_blue, img_green, img_red))\n    image_label = get_label_name_for_label_id_string(labels_df.loc[idx, \"Target\"])\n    ax[x,y].imshow(img_bgr)\n    ax[x,y].set_xticks([])\n    ax[x,y].set_yticks([])\n    ax[x,y].set_title(image_label, fontdict={\"fontsize\": 12})\nplt.show()","4a63a061":"# top-5\ntopn = 5\ntopn_labels = multi_labels_dist.head(topn)[\"Target\"]\nmulti_labels_dist.head(5)","eac9634e":"images_per_label = 5\nfig, ax = plt.subplots(num=1, nrows=topn, ncols=images_per_label)\nfig.set_figheight(21)\nfig.set_figwidth(21)\nfor idx, t in enumerate(topn_labels):\n    sample_ids_for_label = labels_df[labels_df[\"Target\"] == t].sample(n=images_per_label, random_state=RSTATE)[\"Id\"].tolist()\n    ax[idx, 0].set_ylabel(get_label_name_for_label_id_string(t))\n    for idy in range(images_per_label):\n        img_blue = cv2.imread(\"..\/input\/train\/\" + sample_ids_for_label[idy] + \"_blue.png\", cv2.IMREAD_GRAYSCALE)\n        img_green = cv2.imread(\"..\/input\/train\/\" + sample_ids_for_label[idy] + \"_green.png\", cv2.IMREAD_GRAYSCALE)\n        img_red = cv2.imread(\"..\/input\/train\/\" + sample_ids_for_label[idy] + \"_red.png\", cv2.IMREAD_GRAYSCALE)\n        img_bgr = cv2.merge((img_blue, img_green, img_red))\n        ax[idx,idy].imshow(img_bgr)\n        ax[idx,idy].set_xticks([])\n        ax[idx,idy].set_yticks([])\n        ax[idx,idy].set_title(sample_ids_for_label[idy], fontdict={\"fontsize\":10})\nplt.show()","831307eb":"n_images = 25\nncols = 5\nnrows = n_images \/\/ ncols\nimage_ids = labels_df[labels_df[\"Target\"] == \"0\"].sample(n=n_images, random_state=RSTATE)[\"Id\"].tolist()\nfig, ax = plt.subplots(num=1, nrows=nrows, ncols=ncols)\nfig.set_figheight(21)\nfig.set_figwidth(21)\nfor idx, (x, y) in enumerate(product(range(nrows), range(ncols))):\n    img_blue = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_blue.png\", cv2.IMREAD_GRAYSCALE)\n    img_green = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_green.png\", cv2.IMREAD_GRAYSCALE)\n    img_red = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_red.png\", cv2.IMREAD_GRAYSCALE)\n    img_bgr = cv2.merge((img_blue, img_green, img_red))\n    ax[x,y].imshow(img_bgr)\n    ax[x,y].set_xticks([])\n    ax[x,y].set_yticks([])\n    ax[x,y].set_title(image_ids[idx], fontdict={\"fontsize\": 12})\nplt.show()","fa0fce29":"n_images = 25\nncols = 5\nnrows = n_images \/\/ ncols\nimage_ids = labels_df[labels_df[\"Target\"] == \"23\"].sample(n=n_images, random_state=RSTATE)[\"Id\"].tolist()\nfig, ax = plt.subplots(num=1, nrows=nrows, ncols=ncols)\nfig.set_figheight(21)\nfig.set_figwidth(21)\nfor idx, (x, y) in enumerate(product(range(nrows), range(ncols))):\n    img_blue = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_blue.png\", cv2.IMREAD_GRAYSCALE)\n    img_green = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_green.png\", cv2.IMREAD_GRAYSCALE)\n    img_red = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_red.png\", cv2.IMREAD_GRAYSCALE)\n    img_bgr = cv2.merge((img_blue, img_green, img_red))\n    ax[x,y].imshow(img_bgr)\n    ax[x,y].set_xticks([])\n    ax[x,y].set_yticks([])\n    ax[x,y].set_title(image_ids[idx], fontdict={\"fontsize\": 12})\nplt.show()","936bec7d":"n_images = 25\nncols = 5\nnrows = n_images \/\/ ncols\nimage_ids = labels_df[labels_df[\"Target\"] == \"25\"].sample(n=n_images, random_state=RSTATE)[\"Id\"].tolist()\nfig, ax = plt.subplots(num=1, nrows=nrows, ncols=ncols)\nfig.set_figheight(21)\nfig.set_figwidth(21)\nfor idx, (x, y) in enumerate(product(range(nrows), range(ncols))):\n    img_blue = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_blue.png\", cv2.IMREAD_GRAYSCALE)\n    img_green = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_green.png\", cv2.IMREAD_GRAYSCALE)\n    img_red = cv2.imread(\"..\/input\/train\/\" + image_ids[idx] + \"_red.png\", cv2.IMREAD_GRAYSCALE)\n    img_bgr = cv2.merge((img_blue, img_green, img_red))\n    ax[x,y].imshow(img_bgr)\n    ax[x,y].set_xticks([])\n    ax[x,y].set_yticks([])\n    ax[x,y].set_title(image_ids[idx], fontdict={\"fontsize\": 12})\nplt.show()","417ca172":"## Distribution of top-50 training labels (single\/multi)","e67ae4d0":"> Each file represents a different filter on the subcellular protein patterns represented by the sample. The format should be [filename]_[filter color].png for the PNG files, and [filename]_[filter color].tif for the TIFF files.\n\n> All image samples are represented by four filters (stored as individual files), the protein of interest (green) plus three cellular landmarks: nucleus (blue), microtubules (red), endoplasmic reticulum (yellow). The green filter should hence be used to predict the label, and the other filters are used as references.\n\nWe may want to look at some images to understand how they are labeled. ","d2d7f12f":"## Breakdown of multi-labels distribution","74c60d2e":"# Helper functions","39a5624e":"# Imports","de5b5508":"# Definitions","71d915b5":"Most of the training images have 1 or 2 labels. The number labels per image vary from 1 to 5. ","86ccdc6f":"# Look at sample training images","8baa6641":"# Training labels","9c860cd0":"## Sample images for top frequency labels\nWe have not yet looked at how the images within the same label category (single\/multi) look like and how similar or dissimilar they are. We can try looking into few images per label for the top frequency labels. ","e6914072":"I have never worked with image data before, so my goals are limited to basic data set exploration.\n\n**Credits:**\n*  When I was wondering how to work with images and which image packges (scikit-image, Pillow, Matplotlib, OpenCV) to use: \n    -  Checked out few kernels from past image competitions and the current competition, this kernel -  https:\/\/www.kaggle.com\/jschnab\/exploring-the-human-protein-atlas-images came to the rescue. I decided to go with OpenCV and learn along the way.","76dceeec":"## Sample images for label: \"Mitochondria\" (23)","d5dcdc48":"Many top frequency labels are multi-label categories. ","5a5c0615":"## Sample images for label: \"Nucleoplasm\" (0)\nWe previously looked at few sample images for top-n frequency labels and looked at them together. Let's look into more images for a particular category, for example: \"Nucleoplasm\". ","1cf394da":"## Sample images for label: \"Cytosol\" (25)","4f2e5a84":"The target is a multi-labels separated by a space. Our task is to predict those labels using multi-label classification methods.","54829386":"## Distribution of single training labels"}}