{"cell_type":{"831497bb":"code","1d15c9c4":"code","8f16797c":"code","74b60e27":"code","3e2532d6":"code","45448c9b":"code","e2abceca":"code","04725458":"code","51736276":"code","6bdd5953":"code","a6a6eed5":"code","28df6b2f":"code","2414270a":"code","90194b9c":"code","810bbd94":"code","4b65c6ee":"code","6e03d415":"code","708e4949":"code","7dd95096":"code","cfa707e5":"code","0fb47150":"code","9a0da1be":"code","00d06a5c":"code","39e402b1":"code","5af691c6":"code","64f1ee8a":"code","0c4bad28":"code","9235302e":"code","87e21de5":"code","31a2080c":"code","7b6bd5ff":"code","ac0c1019":"code","0020f1c2":"code","0c94fc89":"code","4bd4965f":"code","ec0ce1cc":"code","d83d66f0":"code","0497a668":"markdown","152d2c0b":"markdown","387a9fc1":"markdown","21b7626d":"markdown","c318b9e8":"markdown","dcfa1c8a":"markdown","e69c2a8b":"markdown","3b3bf572":"markdown","bc22d9c2":"markdown","0362b320":"markdown","a402739d":"markdown","cc59b069":"markdown","14b137b8":"markdown","5c34095a":"markdown"},"source":{"831497bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport shutil\nimport os\nimport imageio\nimport sys\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image, ImageOps\nimport scipy.ndimage as ndi\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1d15c9c4":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.python import keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\nimport matplotlib.pyplot as plt","8f16797c":"import os\nprint(os.listdir(\"..\/input\/coronahack-chest-xraydataset\/\"))\nprint(os.listdir(\"..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/\"))","74b60e27":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","3e2532d6":"os.mkdir(\"\/kaggle\/corona_check\")\nos.mkdir(\"\/kaggle\/corona_check\/train\")\nos.mkdir(\"\/kaggle\/corona_check\/test\")\nos.mkdir(\"\/kaggle\/corona_check\/train\/Normal\/\")\nos.mkdir(\"\/kaggle\/corona_check\/train\/COVID19\/\")\nos.mkdir(\"\/kaggle\/corona_check\/test\/Normal\/\")\nos.mkdir(\"\/kaggle\/corona_check\/test\/COVID19\/\")\n","45448c9b":"print(os.listdir(\"\/kaggle\/corona_check\/train\/Normal\"))\nprint(os.listdir(\"\/kaggle\/corona_check\/test\/Normal\"))","e2abceca":"!cd \/kaggle\/corona_check\/train\/\n!rm \/kaggle\/corona_check\/train\/*.jpeg\n\n!cd \/kaggle\/corona_check\/test\/\n!rm \/kaggle\/corona_check\/test\/*.jpeg","04725458":"def copy_img(src_path,dst_path):\n    try:\n        shutil.copy(src_path, dst_path)\n        stmt ='File Copied'\n    except IOError as e:\n        print('Unable to copy file {} to {}'\n              .format(src_path, dst_path))\n        stmt ='Copy Failed - IO Error'\n    except:\n        print('When try copy file {} to {}, unexpected error: {}'\n              .format(src_path, dst_path, sys.exc_info()))\n        stmt ='Copy Failed - other Error'+ sys.exc_info()\n        \n    return stmt ","51736276":"data_dir=\"..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/\"\nmetadata_path=\"..\/input\/coronahack-chest-xraydataset\/\"","6bdd5953":"train_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')","a6a6eed5":"meta_data = pd.read_csv(metadata_path+'Chest_xray_Corona_Metadata.csv')\nmeta_data.head()","28df6b2f":"meta_data['File_path']=''\nmeta_data.loc[meta_data['Dataset_type']=='TRAIN','File_path']=train_dir+'\/'\nmeta_data.loc[meta_data['Dataset_type']=='TEST','File_path']=test_dir+'\/'","2414270a":"meta_data['X_ray_img_nm_path']=meta_data['File_path']+meta_data['X_ray_image_name']","90194b9c":"meta_data.head()","810bbd94":"meta_COVID_19_train = meta_data[(meta_data['Dataset_type']=='TRAIN') & \n                        ((meta_data['Label']=='Normal')|(meta_data['Label']=='Pnemonia') & (meta_data['Label_2_Virus_category']=='COVID-19'))]\n\n\nmeta_COVID_19_test = meta_data[(meta_data['Dataset_type']=='TEST') & \n                        ((meta_data['Label']=='Normal')|(meta_data['Label']=='Pnemonia') & (meta_data['Label_2_Virus_category']=='COVID-19'))]\n\n\n## Moving the 10 Corona Infected dataset to Test\n\nmeta_data_covid_test = meta_data[meta_data['Label_2_Virus_category']=='COVID-19'].sample(12)\nmeta_COVID_19_train = meta_COVID_19_train[~meta_COVID_19_train['X_ray_image_name'].isin(meta_data_covid_test['X_ray_image_name'])]\nmeta_COVID_19_test_fnl = pd.concat([meta_data_covid_test,meta_COVID_19_test],ignore_index=False)","4b65c6ee":"meta_COVID_19_train.loc[meta_COVID_19_train['Label'] =='Pnemonia','Label']='COVID19'\nmeta_COVID_19_test_fnl.loc[meta_COVID_19_test_fnl['Label'] =='Pnemonia','Label']='COVID19'","6e03d415":"print(\"===============Train Set==========================\\n\")\nprint(meta_COVID_19_train.groupby(['Label']).agg({'Dataset_type':'count'}))\n\nprint(\"\\n===============Test Set==========================\\n\")\nprint(meta_COVID_19_test_fnl.groupby(['Label']).agg({'Dataset_type':'count'}))","708e4949":"meta_COVID_19_train['Img_tgt_path']=\"\/kaggle\/corona_check\/train\/\"\nmeta_COVID_19_test_fnl['Img_tgt_path']=\"\/kaggle\/corona_check\/test\/\"","7dd95096":"meta_COVID_19_train.loc[meta_COVID_19_train['Label']=='Normal','Img_tgt_path']=meta_COVID_19_train['Img_tgt_path']+'Normal\/'\nmeta_COVID_19_train.loc[meta_COVID_19_train['Label']=='COVID19','Img_tgt_path']=meta_COVID_19_train['Img_tgt_path']+'COVID19\/'\n\nmeta_COVID_19_test_fnl.loc[meta_COVID_19_test_fnl['Label']=='Normal','Img_tgt_path']=meta_COVID_19_test_fnl['Img_tgt_path']+'Normal\/'\nmeta_COVID_19_test_fnl.loc[meta_COVID_19_test_fnl['Label']=='COVID19','Img_tgt_path']=meta_COVID_19_test_fnl['Img_tgt_path']+'COVID19\/'","cfa707e5":"meta_COVID_19_train['Move_status'] = np.vectorize(copy_img)(meta_COVID_19_train['X_ray_img_nm_path'],meta_COVID_19_train['Img_tgt_path'])\nmeta_COVID_19_test_fnl['Move_status'] = np.vectorize(copy_img)(meta_COVID_19_test_fnl['X_ray_img_nm_path'],meta_COVID_19_test_fnl['Img_tgt_path'])","0fb47150":"dirname = '\/kaggle\/corona_check\/'\ntrain_path = os.path.join(dirname, 'train\/')\ntrain_nrml_pth = os.path.join(train_path, 'Normal\/')\ntrain_covid19_pth = os.path.join(train_path, 'COVID19\/')\n\ntest_path = os.path.join(dirname, 'test\/')\ntest_nrml_pth = os.path.join(train_path, 'Normal\/')\ntest_covid19_pth = os.path.join(train_path, 'COVID19\/')","9a0da1be":"def plot_imgs(item_dir, num_imgs=25):\n    all_item_dirs = os.listdir(item_dir)\n    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_imgs]\n\n    plt.figure(figsize=(10, 10))\n    for idx, img_path in enumerate(item_files):\n        plt.subplot(5, 5, idx+1)\n\n        img = plt.imread(img_path)\n        plt.imshow(img)\n\n    plt.tight_layout()","00d06a5c":"plot_imgs(train_nrml_pth)","39e402b1":"plot_imgs(train_covid19_pth)","5af691c6":"def plot_img_hist(item_dir, num_img=6):\n  all_item_dirs = os.listdir(item_dir)\n  item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_img]\n  \n  #plt.figure(figsize=(10, 10))\n  for idx, img_path in enumerate(item_files):\n    fig1 = plt.figure(idx,figsize=(10, 10))\n    fig1.add_subplot(2, 2, 1)\n    img = mpimg.imread(img_path, )\n    plt.imshow(img)\n    fig1.add_subplot(2, 2, 2)\n    plt.hist(img.ravel(),bins=256, fc='k', ec='k')\n  \n  plt.tight_layout()","64f1ee8a":"plot_img_hist(train_nrml_pth,3)","0c4bad28":"plot_img_hist(train_covid19_pth,3)","9235302e":"def plot_img_hist_ndi(item_dir, num_img=6):\n  all_item_dirs = os.listdir(item_dir)\n  item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_img]\n  \n  #plt.figure(figsize=(10, 10))\n  for idx, img_path in enumerate(item_files):\n    im = imageio.imread(img_path)\n    hist = ndi.histogram(im, min=0, max=255, bins=256)\n    cdf = hist.cumsum() \/ hist.sum()\n    \n    fig1 = plt.figure(idx,figsize=(10, 10))\n    fig1.add_subplot(2, 3, 1)\n    img = mpimg.imread(img_path, )\n    plt.title(\"No. {}\".format(idx))\n    plt.imshow(img)\n    fig1.add_subplot(2, 3, 2)\n    plt.title(\"Histogram\")\n    plt.plot(hist)\n    fig1.add_subplot(2, 3, 3)\n    plt.title(\"CDF\")\n    plt.plot(cdf)\n\n  plt.tight_layout()","87e21de5":"plot_img_hist_ndi(train_nrml_pth,2)","31a2080c":"plot_img_hist_ndi(train_covid19_pth,2)","7b6bd5ff":"\ntrain_dir = r'\/kaggle\/corona_check\/train\/'\ntest_dir = r'\/kaggle\/corona_check\/test\/'\n\n## Model Params\n\nimage_size = 150\nbatch_size = 50\nnb_classes = 2\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,     # Convert all pixels to 0-1\n                              width_shift_range = 0.1,   # The magnitude of the horizontal shift of the picture when the data is improved\n                              height_shift_range = 0.1,  # The magnitude of the vertical shift of the picture when the data is boosted\n                              shear_range = 0.2,         # Set the shear strength\n                              horizontal_flip = True,    # Randomly select half of the picture to flip horizontally\n                              fill_mode ='nearest')      #The points that exceed the boundary will be processed according to the method given by this parameter.Generally, there are some  \n                                                         # \u2018constant\u2019\uff0c\u2018nearest\u2019\uff0c\u2018reflect\u2019\u6216\u2018wrap\u3002\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","ac0c1019":"print(test_dir)","0020f1c2":"print(\"traning set: \")\n\n# Generate batches of tensor image data through real-time data augmentation. Data will be continuously cycled (by batch)\n\ntrain_datagen = train_datagen.flow_from_directory(train_dir,              # The path to the target directory. Each class should contain a subdirectory. Any PNG, JPG, BMP, PPM or TIF images in the subdirectory tree will be included in the raw\n                                               (image_size, image_size),  # Integer tuple (height, width), default: (256, 256). All images will be resized \n                                               batch_size=batch_size,     # The size of the batch of data (default 32)\n                                               class_mode='categorical')  # class_mode is one of categorical \",\" binary \",\" sparse \"or None, which determines the array form of the returned tags. categorical returns 2D one-hot encoded tags.\nprint(\"testing set: \")\n\ntest_datagen = test_datagen.flow_from_directory(test_dir,\n                                             (image_size,image_size),\n                                              batch_size=batch_size,\n                                              class_mode='categorical')\n\n\n#Define step count\n\ntrain_steps = train_datagen.samples\/\/batch_size # \"\/\/\" means integer division\ntest_steps = test_datagen.samples\/\/batch_size\n","0c94fc89":"if K.image_data_format()=='channels_first':  # (\u2018channels_last\u2019,\u2018channels_first\u2019\uff09\n   input_shape =(3,image_size,image_size)\nelse:\n   input_shape =(image_size,image_size,3)   \n   \n# The input feature is a tensor of 150x150x3, where 150x150 is used for image pixels and 3 is used for three color channels\nimg_input = layers.Input(shape=input_shape)\n\n#\n# The first convolution layer extracts the features of 3x3x32 (size of 2D convolution window: 3x3, output 32 dimensions),\n#uses a linear rectification function (Rectified Linear Unit, ReLU), and then the largest pooling layer with a size of 2x2\n\nx = layers.Conv2D(32,3,activation='relu')(img_input)\nx = layers.MaxPooling2D(2)(x)\n\nx = layers.Conv2D(64,3,activation='relu')(x)\nx = layers.MaxPooling2D(2)(x)\n\nx = layers.Conv2D(64,3,activation='relu')(x)\nx = layers.MaxPooling2D(2)(x)\n\n\n# Flatten the feature map into a one-dimensional data (`1-dim`) tensor to add a fully connected layer (dense)\n\nx = layers.Flatten()(x)\n\n\n# Use `sigmoid` activation function and 128 neurons to create a fully connected layer\n\nx = layers.Dense(128,activation='sigmoid')(x)\n\n# Randomly disconnect the input neural cloud with a certain probability to prevent overfitting\nx = layers.Dropout(0.5)(x)                       \n\n\n# Create output layer with 2 neurons and `softmax` activation function\n\noutput = layers.Dense(2,activation='softmax')(x)\n\nmodel= Model(img_input,output)\n\nmodel.summary()                  ","4bd4965f":"# Define corresponding parameters for the model\nmodel.compile(loss='categorical_crossentropy', # Multi-class logarithmic loss. Note that when using this objective function, labels need to be converted into binary sequences of the form (nb_samples, nb_classes).\n              optimizer =Adam(lr=0.0001),\n              metrics = ['acc'] )              # Metrics list metrics: For classification problems, we generally set the list to metrics = ['accuracy']\n\n\n# Set the corresponding number of training iterations\n\nepochs = 20\n\n\n# Training model\nhistory = model.fit_generator(train_datagen,\n                             steps_per_epoch=train_steps,\n                             epochs=epochs,\n                             validation_data=test_datagen,\n                             validation_steps=test_steps )   ","ec0ce1cc":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, epochs + 1)\n\nplt.figure(figsize=(8,4))\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Test Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.title('Model Accuracy')\nplt.show()\n\nplt.figure(figsize=(8,4))\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Test Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.title('Model Loss')\nplt.show()","d83d66f0":"# Evaluate the model to get the corresponding Accuracy, Precision, and Recall\n\nY_pred = model.predict_generator(test_datagen,test_steps+1)\ny_pred = np.argmax(Y_pred,axis=1)\n\nCM =confusion_matrix(test_datagen.classes,y_pred)\nprint(\"Confusion Matrix :\")\nprint(CM)\n\npneumonia_precision= CM[1][1] \/ (CM[1][0]+CM[1][1])\nprint(\"pnuemonia_precision:\", pneumonia_precision)\n\npnuemonia_recall = CM[1][1] \/ (CM[1][1]+CM[0][1])\nprint('pnuemonia_recall   :', pnuemonia_recall)\n\naccuracy = (CM[0][0]+CM[1][1])\/(CM[0][0]+CM[0][1]+CM[1][0]+CM[1][1])\nprint('Accuracy           :', accuracy)\n\ntarget_names = ['Normal', 'COVID19'] \nprint(classification_report(test_datagen.classes, y_pred, target_names=target_names))","0497a668":"#           CoronaHack - Simple Data Exploration & Baseline Model 97% Accuracy ","152d2c0b":"## Assess Metrics and Accuracy ","387a9fc1":"## Histogram with Mathplotlib","21b7626d":"## Neural Architecture","c318b9e8":"### Configure TPU to train the Neural Model","dcfa1c8a":"## Configuring Metrics and Model training params for Neural Networks","e69c2a8b":"## Importing necessary libraries","3b3bf572":"## Preparing the dataset ","bc22d9c2":"### Dataset contains variety of latest for ease of classification first we will catagorise Normal \/ Healthy & COVID ","0362b320":"About this Notebook:\n\nFrom CoronaHack dataset , Covers the simple data exploration of Chest X Ray image dataset & image classification model to classify Normal and COVID19 infected cases\n\n","a402739d":"# Exploratory Data Analysis","cc59b069":"**Import Metadata information**","14b137b8":"## Moving the file to seperate path for COVID19 Classification ","5c34095a":"# Data Preperation"}}