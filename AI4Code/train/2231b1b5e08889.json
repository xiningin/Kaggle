{"cell_type":{"a8485974":"code","1a5f0731":"code","8796dfd0":"code","dd825900":"code","bb707b25":"code","9a0fedfa":"code","ce152726":"code","5edb614c":"code","4b0cb035":"code","8ecfbb17":"code","42fcf19b":"code","c9af2da6":"code","6ec251e3":"code","da016857":"code","46bb4cbd":"code","53196fcf":"code","2a406eb4":"code","5e7c7484":"code","b3f9c65d":"code","2191147a":"code","ce6b3567":"code","a94c2623":"code","6288f569":"code","86fcb469":"code","cbe91c8c":"code","1682c0a0":"markdown","7540436a":"markdown","6adaada4":"markdown"},"source":{"a8485974":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a5f0731":"fake = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/Fake.csv\")\nreal = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/True.csv\")","8796dfd0":"print(fake.head(2))\nprint(real.head(2))","dd825900":"#cehcking shape for both files\nprint(fake.shape)\nprint(real.shape)","bb707b25":"print('FAKE',fake.isnull().sum())\nprint('REAL',real.isnull().sum())","9a0fedfa":"print(list(fake.columns))\nprint(list(real.columns))","ce152726":"#adiing label to fake\nfake['label'] = 'fake'\nfake.head(5)","5edb614c":"#adiing label to Real\nreal['label'] = 'real'\nreal.head(5)","4b0cb035":"# let's concatenate the dataframes\nframes = [fake, real]\nnews_dataset = pd.concat(frames)\nnews_dataset","8ecfbb17":"news_dataset.describe()","42fcf19b":"news_dataset.info()","c9af2da6":"final_data = news_dataset.dropna()","6ec251e3":"final_data.isnull().sum()","da016857":"import seaborn as sns\nfinal_data['length'] = final_data['title'].apply(len)\nsns.countplot(final_data['length'], hue='label', data=final_data)","46bb4cbd":"final_data.hist(column='length', by='label', figsize=(20,5), bins=50)","53196fcf":"import copy\nfrom nltk.corpus import stopwords","2a406eb4":"## removing punctuations from title\nimport string\n\ndef text_process(title):\n    \n    nop = [char for char in title if char not in string.punctuation]\n    \n    nop = ''.join(nop)\n    \n    return [word for word in nop.split() if word in word.lower() not in stopwords.words('english')]","5e7c7484":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","b3f9c65d":"\n#Naive model with hyper parameters\npiplineTitle = Pipeline([\n    ('bow', CountVectorizer(analyzer=text_process)),\n    ('tfidf', TfidfTransformer()),\n    ('classifier', MultinomialNB()),\n])","2191147a":"X_train, X_test, y_train, y_test = train_test_split(final_data['title'], final_data['label'], test_size=0.2, random_state=123)","ce6b3567":"print(piplineTitle.fit(X_train, y_train))","a94c2623":"y_pred = piplineTitle.fit(X_train, y_train).predict(X_test)\ny_pred","6288f569":"clf_report = classification_report(y_test, y_pred)\nprint('Classification_Report',clf_report)","86fcb469":"cnf_matrix = confusion_matrix(y_test, y_pred)\nprint('Cnfusion Matrix',cnf_matrix)","cbe91c8c":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (10,7))\nsns.heatmap(cnf_matrix, annot=True)\nplt.xlabel('predicted')\nplt.ylabel('truth')","1682c0a0":"Simple Approach for the Problem:\n\n1. Data Collection:\n\n (fakes news and real news datasets)\n explain rationale\n2. Data Preprocessing:\n\n filter and manipulate columns, adding labels (fake or real), and merge on selected columns, data       visualization\n\n3. Preprocessing the text: \n NLP Approach\n\n4. Text to features conversion:\n  data cleaning\n  removing stopwords\n  removing punctuation\n   \n6. Model Implementation\n  Naive Bayes\n7. Check on Model Performance\n  Classification Report \n  ","7540436a":" **In all times of human existence real news has to be separated from fake news or rumour mongering. The need for such classification has never been more acute than in the recent times. Data Science models can be favourably used to do this task.**","6adaada4":"The purpose of this TASK is to segregate fake news from real news by using a suitable data science model such as Na\u00efve Bayes.\n\nWe use both fake news and real news as training inputs to our TFIDF (Term Frequency and Inverse Document Frequency) features for creating a classifier. Then a regular test set is given as input and the classifier to detect if it is fake news or real news\n"}}