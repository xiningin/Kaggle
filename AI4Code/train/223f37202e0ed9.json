{"cell_type":{"b8e0e998":"code","cf591ad5":"code","562174e0":"code","e62708da":"code","4caa9472":"code","4ff8becb":"code","4053363d":"code","0b7c4829":"code","5c0afba1":"code","8cef7d25":"code","668a4554":"code","a9d7725a":"code","ad6c5b9c":"code","3a65d8b7":"code","b26d7304":"code","865a43c4":"markdown"},"source":{"b8e0e998":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split as TTS\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport nltk\n# nltk.download('stopwords')\nfrom nltk.corpus import stopwords","cf591ad5":"train_df = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")\nsample_df = pd.read_csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")","562174e0":"train_df.head()","e62708da":"X_train = train_df[\"text\"].values\nX_val = test_df[\"text\"].values\ny_train = train_df[\"target\"].values\n# y_val = test_df[\"target\"].values","4caa9472":"import re\n\nREPLACE_BY_SPACE_RE = re.compile('[\/(){}\\[\\]\\[@,;]]')\nBAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\nSTOPWORDS = set(stopwords.words(\"english\"))\n\ndef process(text):\n    \n    text = text.lower()\n    text = REPLACE_BY_SPACE_RE.sub('',text)\n    text = BAD_SYMBOLS_RE.sub('',text)\n    \n    text = ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n    return text","4ff8becb":"X_train = [process(x) for x in X_train]","4053363d":"X_train = np.array(X_train)","0b7c4829":"vocab_size = 1000\ntrunc='post'\nmax_length = 150\ntokenizer = Tokenizer(num_words=vocab_size,oov_token='<OOV>')\ntokenizer.fit_on_texts(X_train)\n\nword_index = tokenizer.word_index\n\nsequences = tokenizer.texts_to_sequences(X_train)\npadded = pad_sequences(sequences,maxlen=max_length,truncating=trunc,padding='post')\n\nval_sequences = tokenizer.texts_to_sequences(X_val)\nval_padded = pad_sequences(val_sequences,maxlen=max_length,truncating=trunc,padding='post')","5c0afba1":"from keras.models import Sequential\nfrom keras.layers import Embedding, Dense, GlobalAveragePooling1D, Bidirectional, LSTM, Conv1D, Dropout, Activation","8cef7d25":"model = Sequential()\n\nmodel.add(Embedding(vocab_size,20,input_length=max_length))\nmodel.add(Bidirectional(LSTM(64)))\n\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","668a4554":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nhistory = model.fit(padded,y_train,epochs=20,verbose=1)","a9d7725a":"def show_history(history):\n    fig,ax = plt.subplots(1,2,figsize=(15,5))\n    \n    ax[0].plot(history.history['loss'])\n    ax[1].plot(history.history['accuracy'])\n    \n    ax[0].set_title(\"Loss\")\n    ax[0].set_title(\"Accuracy\")\n    pass","ad6c5b9c":"show_history(history)","3a65d8b7":"def predict_and_save(test,model,name):\n    \n    test = [process(x) for x in test]\n    test = np.array(test)\n    test_sequences = tokenizer.texts_to_sequences(test)\n    test_padded = pad_sequences(test_sequences,maxlen=max_length,truncating=trunc,padding='post')\n    \n    pred = model.predict(test_padded)\n    pred = np.argmax(pred,axis=1)\n    pred = np.array(pred)\n    sample_df.target = pred\n    sample_df.to_csv(name,index=False)\n    pass","b26d7304":"predict_and_save(X_val,model,\"model_lstm.csv\")","865a43c4":"**1 is disaster, while 0 is not**"}}