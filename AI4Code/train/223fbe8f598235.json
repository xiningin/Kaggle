{"cell_type":{"7cc85308":"code","5f874205":"code","2a632daf":"code","2cbf0313":"code","37c7c922":"code","e2aa93af":"code","856c63dd":"code","bc7cece1":"code","ed24159e":"code","f479e939":"code","c800baec":"code","29d63701":"code","5fe578e9":"code","cc52e0cf":"code","f21f2c0d":"code","d9561701":"markdown","bbe58ae9":"markdown","72cb5419":"markdown","5f6fbab0":"markdown","3703ed07":"markdown","2c01ec3a":"markdown","5e722e04":"markdown","c914c5b8":"markdown","5cd44ec5":"markdown","2e87af86":"markdown","f229f710":"markdown","be0e3f8a":"markdown","b82a0c32":"markdown"},"source":{"7cc85308":"import sys\nimport os\nimport PIL\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.preprocessing import LabelEncoder\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nfrom skimage.feature import hog\nfrom skimage import exposure\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\n\nwarnings.simplefilter('ignore')","5f874205":"path = '\/kaggle\/input\/caltech101\/101_ObjectCategories\/'\n\n\ninput_path = []\nlabels = []\nfor dirname, _, filenames in os.walk(path):\n    labels.append(_)\n    for file in filenames:\n        input_path.append(os.path.join(dirname, file))\nlabels = labels[0]","2a632daf":"img = Image.open(input_path[0])\nimg","2cbf0313":"resized_image = img.resize((64, 64))\nresized_image","37c7c922":"fd, hog_image = hog(resized_image, orientations=9,\n                    pixels_per_cell=(8, 8),\n                    cells_per_block=(2, 2),\n                    visualize=True,\n                    multichannel=True)","e2aa93af":"fd.shape","856c63dd":"fig, (ax1, ax2) = plt.subplots(1, 2,\n                               figsize=(10, 3),\n                               sharex=True,\n                               sharey=True)\n\nax1.imshow(resized_image, cmap=plt.cm.gray)\nax1.set_title('Input image')\n\nhog_ = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n\nax2.imshow(hog_, cmap=plt.cm.gray)\n\nplt.show()","bc7cece1":"def feature_extraction(img_i):\n    resized = img_i.resize((64, 64))\n    fd, hog_image = hog(resized, orientations=9,\n                    pixels_per_cell=(8, 8),\n                    cells_per_block=(2, 2),\n                    visualize=True,\n                    multichannel=False)\n    return fd","ed24159e":"features = []\nfor i, j in enumerate(input_path[:1000]):\n    pic = ImageOps.grayscale(Image.open(input_path[i]))\n    features.append(feature_extraction(pic))\nfeatures = np.array(features)","f479e939":"lb = []\nfor i, j in enumerate(input_path):\n    for k, m in enumerate(labels):\n        if labels[k] in input_path[i]:\n            lb.append(m)\nlb = np.array(lb)","c800baec":"X = features\ny = lb[:1000]\nscale = LabelEncoder()\ny = scale.fit_transform(y)","29d63701":"df = pd.DataFrame(X)\ndf['label'] = y\ndf.head().T","5fe578e9":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","cc52e0cf":"def lgb_(x_train, y_train, x_test, y_test):\n    params = {\n        \"objective\": \"multiclass\",\n        \"metric\": \"multi_logloss\",\n        \"num_leaves\": 30,\n        \"learning_rate\": 0.1,\n        \"verbosity\": -1,\n        \"num_class\": len(np.unique(y_train))\n    }\n\n    train = lgb.Dataset(x_train, label=y_train)\n    val = lgb.Dataset(x_test, label=y_test)\n    result = {}\n    model = lgb.train(params, train, 20,\n                      valid_sets=[train, val],\n                      verbose_eval=100,\n                      evals_result=result)\n\n    predict = np.expm1(model.predict(\n        x_test, num_iteration=model.best_iteration))\n    return result","f21f2c0d":"lgb_(x_train, y_train, x_test, y_test)","d9561701":"# Data Entry","bbe58ae9":"# Import libraries","72cb5419":"# Extract features for 1000 instances\n#### I used the same HOG as I explained before, with this difference that I used grayscale image to skip the multichannel","5f6fbab0":"# Resizing the image","3703ed07":"## feature matrix","2c01ec3a":"# Modeling","5e722e04":"<h5>If you are interested in this problem and detailed analysis, you can copy this Notebook as follows<\/h5>\n\n<img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F1101107%2F8187a9b84c9dde4921900f794c6c6ff9%2FScreenshot%202020-06-28%20at%201.51.53%20AM.png?generation=1593289404499991&alt=media\" alt=\"Copyandedit\" width=\"300\" height=\"300\" class=\"center\">","c914c5b8":"## Defining the target labels","5cd44ec5":"# Define related methods and inputs of the ML models","2e87af86":"## Preparing the dataframe","f229f710":"* I defined nine buckets to create (9 x 1 Matrix).\n* The size of the normalized block is 2x2.\n* And the histogram is 8 x 8.","be0e3f8a":"# About this notebook\n#### As for all of my codes, the Author is Seyedsaman Emami\n\nHey, everyone.\nHope you are doing well.\n\n\nIn the following notebook, I extracted the 101 category images and labeled them. To build the ML model, I had to know more about the dataset, so I printed the images, and I moved to feature extraction. \nI used HOG (implement the Histogram orientation and gradient or HOG method for Image feature engineering and extract the highlights), resized the images to 64 * 64 sizes, and then convert their channel and finally defined my data frame to move the modeling.\nFor the modeling, I considered lightGBM model.","b82a0c32":"# Calculating Gradients, orientations, for the image\ncompute the gradient for each pixel in the picture"}}