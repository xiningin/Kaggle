{"cell_type":{"cb5a1fed":"code","8aa24050":"code","1bc8c1da":"code","fe73fb26":"code","1ee8b3d6":"code","e88d8a25":"code","c5f651d2":"code","587dbb60":"code","dc2a00e6":"code","c8430929":"code","a8d3ddca":"code","31b5687e":"code","0a7f5359":"code","42bfe128":"code","ffceb008":"code","4932bb44":"code","ffb58e1f":"code","15b6ebb5":"code","889114fe":"code","dd9b41a2":"code","25eeaa4a":"code","528331f7":"code","4e29d5b5":"code","a1191124":"code","ff7910b5":"code","904a0791":"code","4ee3d50b":"code","ee2cfc9d":"code","7f27e6ee":"code","f07ed786":"code","195b7d56":"code","07468a65":"code","166e0856":"code","cc2b0864":"code","57bad8e8":"code","03f37717":"code","c378bf42":"code","67f00748":"code","4d3a3ed9":"markdown","e4f3e535":"markdown","18636bc5":"markdown","70cc13fd":"markdown","bf3f322a":"markdown","738ba2e9":"markdown","75660dc6":"markdown","3ee0813d":"markdown","87388d53":"markdown","14de5c39":"markdown","e341a8e4":"markdown","47e8c7bb":"markdown","f8774344":"markdown","7149b399":"markdown","971045aa":"markdown","5c85270e":"markdown","1a4f31b5":"markdown","25e2d4ba":"markdown"},"source":{"cb5a1fed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\") # ignore the warnings about file size\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n%matplotlib inline\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8aa24050":"# import des donn\u00e9es\ndrop_data_nan = (pd.read_csv('..\/input\/openfoodfacts\/clean_p2.csv',sep='\\t', error_bad_lines=False, low_memory=False))","1bc8c1da":"# define the quantitative and categorical variables that are relevant sorted in a new dataframe\n\ndataset = pd.DataFrame()\ndataset['Product Name'] = drop_data_nan['product_name']\ndataset['Countries'] = drop_data_nan['countries']\ndataset['States'] = drop_data_nan['states']\ndataset['Energy Kcal per 100g'] = drop_data_nan['energy-kcal_100g']\ndataset['Energy per 100g'] = drop_data_nan['energy_100g']\ndataset['Fat per 100g'] = drop_data_nan['fat_100g']\ndataset['Saturated fat per 100g'] = drop_data_nan['saturated-fat_100g']\ndataset['Carbohydrates per 100g'] = drop_data_nan['carbohydrates_100g']\ndataset['Sugars per 100g'] = drop_data_nan['sugars_100g']\ndataset['Proteins per 100g'] = drop_data_nan['proteins_100g']\n\ndataset.head(10)","fe73fb26":"# Univariate Analysis of Energy Kcal per 100g\n\n#Distribution using boxplot\n\nsns.boxplot(dataset['Energy Kcal per 100g'],color=\"blue\")\nplt.xlabel(\"Fat per 100g\", size=16)\nplt.title(\"Distribution of Energy Kcal per 100g\", size=18, y=1.03)\nplt.xlim([-20, 1000])\nplt.show()","1ee8b3d6":"# Univariate Analysis of Energy per 100g\n\n#Distribution using boxplot\n\nsns.boxplot(dataset['Energy per 100g'],color=\"green\")\nplt.xlabel(\"Energy per 100g\", size=16)\nplt.title(\"Distribution of the Energy per 100g\", size=18, y=1.03)\nplt.xlim([-100, 4000])\nplt.show()","e88d8a25":"# Univariate Analysis of Fat per 100g\n\n#Distribution using boxplot\n\nsns.boxplot(dataset['Fat per 100g'],color=\"red\")\nplt.xlabel(\"Fat per 100g\", size=16)\nplt.title(\"Distribution of the Fat per 100g\", size=18, y=1.03)\nplt.xlim([-1, 100])\nplt.show()","c5f651d2":"# Univariate Analysis of Saturated fat per 100g\n\n#Distribution using boxplot\n\nsns.boxplot(dataset['Saturated fat per 100g'],color=\"yellow\")\nplt.xlabel(\"Saturated fat per 100g\", size=16)\nplt.title(\"Distribution of the Saturated fat per 100g\", size=18, y=1.03)\nplt.xlim([-1, 50])\nplt.show()","587dbb60":"# Univariate Analysis of Carbohydrates per 100g\n\n#Distribution using boxplot\n\nsns.boxplot(dataset['Carbohydrates per 100g'],color=\"purple\")\nplt.xlabel(\"Carbohydrates per 100g\", size=16)\nplt.title(\"Distribution of the Carbohydrates per 100g\", size=18, y=1.03)\nplt.xlim([-10, 150])\nplt.show()\n\n","dc2a00e6":"# Univariate Analysis of Sugars per 100g\n\n#Distribution using boxplot\n\nsns.boxplot(dataset['Sugars per 100g'],color=\"brown\")\nplt.xlabel(\"Sugars per 100g\", size=16)\nplt.title(\"Distribution of the Sugars per 100g\", size=18, y=1.03)\nplt.xlim([-2, 50])\nplt.show()","c8430929":"# Univariate Analysis of Proteins per 100g\n\n#Distribution using boxplot\n\nsns.boxplot(dataset['Proteins per 100g'],color=\"gray\")\nplt.xlabel(\"Proteins per 100g\", size=16)\nplt.title(\"Distribution of the Proteins per 100g\", size=18, y=1.03)\nplt.xlim([-2, 50])\nplt.show()\n","a8d3ddca":"count_countries = pd.DataFrame(dataset['Countries'].value_counts().rename_axis(axis=0, index='Countries')).set_axis([\"Count\"], axis='columns')\ncount_countries.describe()","31b5687e":"new_cc = count_countries.query(\"Count >= 200\")\nnew_cc.head()","0a7f5359":"to_plot = new_cc.sort_values(by=['Count'])\nfig, ax = plt.subplots(figsize=(18, 9))\nax.set_facecolor(\"#2E2E2E\")\nplt.title('Number of products per country', fontsize=20, y=1.03)\nplt.xlabel('Countries', fontsize=18)\nplt.ylabel('Count', fontsize=18)\nplt.grid(True, color=\"#93a1a1\", alpha=0.05)\nplt.xticks(rotation=90) # this line allow us to rotate the x_labels so they can be readable\nplt.plot(to_plot.index.values,to_plot['Count'],color=\"#E8FF41\"); \n","42bfe128":"# We do a barplot displaying the distribution of the number of products per country\nfig, ax = plt.subplots(figsize=(10, 10))\nsns.set_style('darkgrid')\nsns.barplot(x=new_cc.index.values, y=new_cc[\"Count\"], palette=\"Blues_d\")\nplt.xticks(rotation=90)","ffceb008":"# IQR detection and method\nQ1=dataset.quantile(0.25)\nQ3=dataset.quantile(0.75)\nIQR=Q3-Q1\nlower_bound = Q1-1.5*IQR\nupper_bound = Q3+1.5*IQR\nprint('Lower bound for each quantitative variable:')\nprint(lower_bound) \nprint('Upper bound for each quantitative variable:')\nprint(upper_bound) \n# we eliminate all the values above it for each column using IQR, we can notice them with the max() function\ndataset_out =dataset[~((dataset<(Q1-1.5*IQR)) | (dataset>(Q3+1.5*IQR)))]\ndataset_out.describe()","4932bb44":"dataset_out['Fat per 100g'].fillna(dataset_out['Fat per 100g'].median(), inplace=True)\ndataset_out['Proteins per 100g'].fillna(dataset_out['Proteins per 100g'].median(), inplace=True)\ndataset_out['Carbohydrates per 100g'].fillna(dataset_out['Carbohydrates per 100g'].median(), inplace=True)\ndataset_out.describe()","ffb58e1f":"# Univariate Analysis of Energy Kcal per 100g (without outliers)\n\n#Distribution using boxplot\n\nsns.boxplot(dataset_out['Energy Kcal per 100g'],color=\"blue\")\nplt.xlabel(\"Fat per 100g\", size=16)\nplt.title(\"Distribution of the Energy Kcal per 100g\", size=18, y=1.03)\nplt.xlim([-20,900])\nplt.show()\n\n#Distribution using displot\n\nsns.displot(dataset_out['Energy Kcal per 100g'].sort_values(ascending=True), kde=True, color=\"blue\")\nplt.title(\"Distribution of the Energy Kcal per 100g\", size=18, y=1.03)\nplt.ylabel(\"Density of the distribution (Count)\", size=16)\nplt.xlabel(\"Energy Kcal per 100g\", size=16)\nplt.show()","15b6ebb5":"# Univariate Analysis of Energy per 100g (without outliers)\n\n#Distribution using boxplot\n\nsns.boxplot(dataset_out['Energy per 100g'],color=\"green\")\nplt.xlabel(\"Energy per 100g\", size=16)\nplt.title(\"Distribution of the Energy per 100g\", size=18, y=1.03)\nplt.xlim([-20, 4000])\nplt.show()\n\n#Distribution using displot\n\nsns.displot(dataset_out['Energy per 100g'].sort_values(ascending=True), kde=True, color=\"green\")\nplt.title(\"Distribution of the Energy per 100g\", size=18, y=1.03)\nplt.ylabel(\"Density of the distribution (Count)\", size=16)\nplt.xlabel(\"Energy per 100g\", size=16)\nplt.show()","889114fe":"# Univariate Analysis of Fat per 100g (without outliers)\n\n#Distribution using boxplot\n\nsns.boxplot(dataset_out['Fat per 100g'],color=\"red\")\nplt.xlabel(\"Fat per 100g\", size=16)\nplt.title(\"Distribution of the Fat per 100g\", size=18, y=1.03)\nplt.xlim([-5, max(dataset_out['Fat per 100g'])])\nplt.show()\n\n#Distribution using displot\n\nsns.displot(dataset_out['Fat per 100g'].sort_values(ascending=True), kde=True, color=\"red\")\nplt.title(\"Distribution of the Fat per 100g\", size=18, y=1.03)\nplt.ylabel(\"Density of the distribution (Count)\", size=16)\nplt.xlabel(\"Fat per 100g\", size=16)\nplt.show()","dd9b41a2":"# Univariate Analysis of Saturated fat per 100g (without outliers)\n\n#Distribution using boxplot\n\nsns.boxplot(dataset_out['Saturated fat per 100g'],color=\"yellow\")\nplt.xlabel(\"Saturated fat per 100g\", size=16)\nplt.title(\"Distribution of the Saturated fat per 100g\", size=18, y=1.03)\nplt.xlim([-2, 15])\nplt.show()\n\n#Distribution using displot\n\nsns.displot(dataset_out['Saturated fat per 100g'].sort_values(ascending=True), kde=True, color=\"yellow\")\nplt.title(\"Distribution of the Saturated fat per 100g\", size=18, y=1.03)\nplt.ylabel(\"Density of the distribution (Count)\", size=16)\nplt.xlabel(\"Saturated fat per 100g\", size=16)\nplt.show()","25eeaa4a":"# Univariate Analysis of Carbohydrates per 100g (without outliers)\n\n#Distribution using boxplot\n\nsns.boxplot(dataset_out['Carbohydrates per 100g'],color=\"purple\")\nplt.xlabel(\"Carbohydrates per 100g\", size=16)\nplt.title(\"Distribution of the Carbohydrates per 100g\", size=18, y=1.03)\nplt.xlim([-10, max(dataset_out['Carbohydrates per 100g'])])\nplt.show()\n\n#Distribution using displot\n\nsns.displot(dataset_out['Carbohydrates per 100g'].sort_values(ascending=True), kde=True, color=\"purple\")\nplt.title(\"Distribution of the Carbohydrates per 100g\", size=18, y=1.03)\nplt.ylabel(\"Density of the distribution (Count)\", size=16)\nplt.xlabel(\"Carbohydrates per 100g\", size=16)\nplt.show()","528331f7":"# Univariate Analysis of Sugars per 100g (without outliers)\n\n#Distribution using boxplot\n\nsns.boxplot(dataset_out['Sugars per 100g'],color=\"brown\")\nplt.xlabel(\"Sugars per 100g\", size=16)\nplt.title(\"Distribution of the Sugars per 100g\", size=18, y=1.03)\nplt.xlim([-5, 30])\nplt.show()\n\n#Distribution using displot\n\nsns.displot(dataset_out['Sugars per 100g'].sort_values(ascending=True), kde=True, color=\"brown\")\nplt.title(\"Distribution of the Sugars per 100g\", size=18, y=1.03)\nplt.ylabel(\"Density of the distribution (Count)\", size=16)\nplt.xlabel(\"Sugars per 100g\", size=16)\nplt.show()","4e29d5b5":"# Univariate Analysis of Proteins per 100g (without outliers)\n\n#Distribution using boxplot\n\nsns.boxplot(dataset_out['Proteins per 100g'],color=\"gray\")\nplt.xlabel(\"Proteins per 100g\", size=16)\nplt.title(\"Distribution of the Proteins per 100g\", size=18, y=1.03)\nplt.xlim([-10, max(dataset_out['Proteins per 100g'])])\nplt.show()\n\n#Distribution using displot\n\nsns.displot(dataset_out['Proteins per 100g'].sort_values(ascending=True), kde=True, color=\"gray\")\nplt.title(\"Distribution of the Proteins per 100g\", size=18, y=1.03)\nplt.ylabel(\"Density of the distribution (Count)\", size=16)\nplt.xlabel(\"Proteins per 100g\", size=16)\nplt.show()","a1191124":"# we reduce the number of variable of our dataset_clean to fit our application needs\n# we use .dropna() function of our library to have practical data for our application\ndataset_app = dataset_out[['Product Name','Countries','Fat per 100g','Proteins per 100g','Carbohydrates per 100g']].dropna()\nsns.pairplot(dataset_app.sample(1000),size=4)","ff7910b5":"dataset_app.head(10)","904a0791":"corr_df = dataset_app.corr(method ='pearson')\nplt.figure(figsize=(9, 9))\nplt.title('Correlation Matrix using Pearson Method',fontsize=20)\nsns.heatmap(corr_df, annot=True)\nplt.show()","4ee3d50b":"from sklearn.preprocessing import StandardScaler\n\nx = dataset_app.loc[:, ['Fat per 100g','Proteins per 100g','Carbohydrates per 100g']]\nx = StandardScaler().fit_transform(x)","ee2cfc9d":"np.mean(x),np.std(x)","7f27e6ee":"normalized_dataset_app = pd.DataFrame(x,columns={'Fat per 100g': '0','Proteins per 100g': '1','Carbohydrates per 100g': '2'})\nnormalized_dataset_app.head()","f07ed786":"from sklearn.decomposition import PCA\npca_dataset_app = PCA(n_components=2)\nprincipalComponents_dataset = pca_dataset_app.fit_transform(normalized_dataset_app)\nprincipal_components_Df = pd.DataFrame(data = principalComponents_dataset, columns = ['Principal Component 1', 'Principal Component 2'])\nprincipal_components_Df.head()","195b7d56":"print('Explained variation per principal component: {}'.format(pca_dataset_app.explained_variance_ratio_))","07468a65":"X = \"Countries\" # categorical\nY = \"Fat per 100g\" # quantitative\n\nsample_anova = dataset_app[dataset_app[\"Fat per 100g\"] < 100] # we make sure we do our analysis based on filtered data\n\ndef eta_squared(x,y):\n    mean_y = y.mean()\n    classes = []\n    for classe in x.unique():\n        yi_classe = y[x==classe]\n        classes.append({'ni': len(yi_classe),\n                        'mean_classe': yi_classe.mean()})\n    SCT = sum([(yj-mean_y)**2 for yj in y])\n    SCE = sum([c['ni']*(c['mean_classe']-mean_y)**2 for c in classes])\n    return SCE\/SCT\n    \neta_squared(sample_anova[X],sample_anova[Y])","166e0856":"# all\u00e9ger la m\u00e9moire\ndataset_chi2 = dataset_app.sample(n=1000)","cc2b0864":"X = \"Product Name\"\nY = \"Countries\"\n\ncont = dataset_chi2[[X,Y]].pivot_table(index=X,columns=Y,aggfunc=len)\ntx = dataset_chi2[X].value_counts()\nty = dataset_chi2[Y].value_counts()\ntx = pd.DataFrame(tx)\nty = pd.DataFrame(ty)\ntx.columns = [\"Product Name\"]\nty.columns = [\"Countries\"]\nn = len(dataset_chi2)\nindep = np.outer(tx,ty.T) \/ n\nc = cont.fillna(0) # We replace NaN values by 0\nmeasure = (c-indep)**2\/indep\nxi_n = measure.sum().sum()\ntable = measure\/xi_n\ntable.head(5)","57bad8e8":"# function 1\n\ndef ketodapp1(x):\n    f = dataset_app.loc[dataset_app['Product Name'] == x]['Fat per 100g'].values[0]\n    p = dataset_app.loc[dataset_app['Product Name'] == x]['Proteins per 100g'].values[0]\n    c = dataset_app.loc[dataset_app['Product Name'] == x]['Carbohydrates per 100g'].values[0]\n    print(x,'contains:',f,'g of Fat per 100g,',p,'g of Proteins per 100g,',c,'g of Carbohydrates per 100g.')\n   \n    \n#example\nketodapp1('Jus de grenade bio artisanal')\n    ","03f37717":"# function 2\n\ndef ketodapp2(x):\n    \n    cc = dataset_app.loc[dataset_app.index == x]['Countries'].values[0]\n    f = dataset_app.loc[dataset_app.index == x]['Fat per 100g'].values[0]\n    p = dataset_app.loc[dataset_app.index == x]['Proteins per 100g'].values[0]\n    c = dataset_app.loc[dataset_app.index == x]['Carbohydrates per 100g'].values[0]\n    print(dataset_app.loc[dataset_app.index == x]['Product Name'].values[0],'imported from',cc,'contains:',\n          f,'g of Fat per 100g,',p,'g of Proteins per 100g,',c,'g of Carbohydrates per 100g.')\n   \n    \n#example\nketodapp2(108)","c378bf42":"import os\nos.chdir(r'.\/')\ndataset_app.to_csv('ketodapp.csv',sep = '\\t',index = True)","67f00748":"from IPython.display import FileLink\nFileLink(r'ketodapp.csv')","4d3a3ed9":"The **.explained_variance_ratio_** parameter returns a vector of the variance explained by each dimension.\nFrom the below output, we can observe that the principal component 1 holds **46.4%** of the information while the principal component 2 holds **34.2%** of the information. Also, the other point to note is that while projecting three-dimensional data (**Fat, Proteins, Carbohydrates**) to a two-dimensional data, **19.4%** information was lost.\nSo, our principal components explain a cumulative **80.6%** of the variable which is acceptable to avoid overfitting \n\n","e4f3e535":"# Univariate Analysis for Quantitative Values\n\nWe're doing some univariate analysis on the quantitative variables contained in our *dataset* dataframe.\nOur analysis will include a graph using matplot and seaborn libraries for each variable.\n\nFor convenience, we applied some adjustments.\n\nIn the boxplot distribution, we have limited the **x axis** depending on the concentration of the values to have a readable graph for each variable.\nThis distribution allows us to notice the outliers over Q4 for each variable which will be useful for out next step.","18636bc5":"# Function 2\n\nThe following function take as input, the iD of the product represented by the index of the dataframe and returns the product name, fat per 100g, carbohydrates per 100g and proteins per 100g. \nUsing this function, we avoid the trap of having a product name that exist in duplicates as we saw with function 1. \nThinking ahead, we can imagine that the iD of each product can be scanned as QR code in a supermarket. ","70cc13fd":"# Univariate Analysis for Categorical Values\n\nWe create a dataframe called *count_countries* that return the countries as the index and the count of products as a column.\nIn order to clarify our graph for our analysis on the countries, we  decide to drop all the countries variable using a boolean condition below 200 count values. It allows us to keep enough countries to make our observations while having a readable graph (45 countries).\nWe use **matplotlib** to display the results. \n\nThen, we create a **countplot()** to observe the count of products per country. ","bf3f322a":"# Imputation for Variables Using Median\n\nWe decide to replace the NaN values of our quantitative values that we're going to keep for our application using median() method.  \n\nWe specifically use it after removing the outliers so we can better normalize our data - the median() will be more \"true\" than before removing the outliers. \n\nThe mean() is usually less exact than median() and 0 imputation might create an issue of overfitting once we train a predictive model.\n\nThe quantitative variables we're going to keep for later are: **Fat**, **Carbohydrates** and **Proteins**\n\nWe notice using .describe() that the statistical values changed from our *dataset_out*.","738ba2e9":"# New Data Visualization\n\nOnce we used the interquartile range, we're using our *dataset_out* dataframe (without outliers) to display our data in two different ways:\n* Boxplot distribution using **.boxplot()**\n* Displot distribution using **.displot()**\n\nNote that for the displot distribution, we used **KDE** parameters which stands for Kernel Density Estimate and shows us the estimate density curve based on KDE equation. \n\n","75660dc6":"We use are going to check is our StandardScaler has been used properly on our dataset and normalized our data.\nThe mean needs to be zero and the standard deviation needs to be one.\n\nWe notice that the mean is almost equals to zero that we'll consider correct for our PCA. Standard deviation is equals to on","3ee0813d":"# Prepare for Modeling\n\nOur cleaning and exploration steps are done, we export our dataset as a csv to work on our predictions and modeling\n","87388d53":"# Multivariate Analysis (PCA)\n\nWe use PCA to make a multivariate analysis of our quantitative variables.\n\nThe prerequisite for a PCA is to have a normalized set of data - this is why we apply .StandardScaler().\nAnother prerequisite is to have approximately the mean equals to 0 and the standard deviation equals to 1. \n","14de5c39":"# Function 1\n\nThis function take in input the product name the user wants to enter in the app and returns the values of fat, proteins and carbohydrates contained in that particular product.\nWe notice that this function has some limits because some products have the same name but their quantitative values are different.","e341a8e4":"# Bivariate Analysis \n\nOur bivariate analysis will help us to focus on the important data for our application.\nThe goal is to provide insights and product recommendations for people doing a ketogenic diet based on their locations (per country).\n\nThe ketogenic or \u201cketo\u201d diet is a low-carbohydrate, fat-rich eating plan that has been used for centuries to treat specific medical conditions. In the 19th century, the ketogenic diet was commonly used to help control diabetes.\n\nFor 2000 calories consumed per day, a ketogenic diet is generally made of:\n- Carbohydrates: 20 to 50 grams per day\n- Fat: 150 to 170 grams per day\n- Proteins: 60 to 80 grams per day\n\nSource: https:\/\/www.hsph.harvard.edu\/nutritionsource\/healthy-weight\/diet-reviews\/ketogenic-diet\/\n\n\nWe're going to study the following pairs of variables by doing a **pairplot()** and by doing a multivariate analysis with the variables (Fat, Proteins, Carbohydrates):\n- Carbohydrates\/Fat\n- Carbohydrates\/Proteins\n- Proteins\/Fat\n\nAfter that we'll cross the results with the countries where we can find our product recommendations so people can use it in any countries!\n\n","47e8c7bb":"# Filtered Variables Observations\n\nNow, we have a better dataset to make our first explorations.\nWe're going to start by working on the quantitative columns that make the most sense in order to draw conclusions for our application, as well as adding the categorical columns that make the most sense to describe our dataset.\nHere are the columns we're going to work on:\n\n*Categorical values*\n\n* **product_name**\n* **countries**\n* **states**\n\n*Quantitative values*\n\n* **energy-kcal_100g**\n* **energy_100g**  \n* **fat_100g** \n* **saturated-fat_100g** \n* **carbohydrates_100g**   \n* **sugars_100g**  \n* **proteins_100g**   ","f8774344":"# Multivariate Analysis (Chi-2)\n\nThe Chi-2 analysis allow us to analyze two categorical variables.\n\nWe obtain a table that contains a value between 0 and 1 for each columns (Countries).\n\nIn our case, all the values are very closed to 0, which means that there is no dependance between the two categorical variables: **Product Name** and **Countries**.","7149b399":"# Multivariate Analysis (ANOVA)\n\nANOVA allows us to make a multivariate analysis between quantitative variables and a categorical variable.\n\nThe overall equation to apply ANOVA is the following:\n\n**Y = alpha(i) + mu + epsilon**\n\nwith alpha(i) the adjustment \nmu the reference of the categorical variable\nepsilon the error\n\nTo do so, we gotta calculate:\n\n- SCT: Total Sum of Squares\n- SCE: Sum of Squares of the Model\n- SCR: Sum of Squares of the Error\n\n\nIt allows us to calculate:\n\neta^2 = V(interclass)\/V(total)\n\nIf eta^2 = 0, then there is no relationship between the variables.\nIf eta^2 = 1, then the means of the classes are different from one another but within a class, the values are very closed from the mean of the class (meaning there is a great relation between the two variables).\n\nNow, we're going to use this method between our categorical variable: *Countries* and our quantitative variable: *Fat per 100g*.\n\nWe notice a result of **0.02%** which means that there is almost no relation between those two variables","971045aa":"Now that our dataset has been normalized for PCA, we can use it using sklearn library with n=2 components","5c85270e":"# Correlation Matrix\n\nWe use seaborn library with **heatmap()** to define our correlation matrix using Pearson method. \n\nThe Pearson method gives us indications about the linearity between two variables.\n\n - A positive correlation value between two variables indicates a linear relation between the two variables and the fact that they describe the same characteristics\n \n - A negative correlation value between two variables indicates an anticorrelation bewteewn the two variables which means that they describe different characteristics or are not clearly defined\n","1a4f31b5":"# Removing the Outliers on Quantitative Variables\n\nAs explaines previously, the boxplot graphs allowed us to visually determine the outliers - they are the ones that we can see after the Q4 bar on the diagrams.\nNow, we're going to remove these extreme values called outliers to purify our data using the interquartile range method. \n\n**Some notes about the IQR method:**\n\nThis method allows us to detect outliers in our distribution on quantitative variables. IQR method is based on the Gaussian distribution (normal distribution). A normal distribution descibes the repartition of the data around the mean value and tells us that the whole data is found below three times the standard deviation of the mean value which means that the part of the data above it is considered as outliers: outliers>3xsigma of mu with sigma the standard deviation and mu the mean. \n\nIn the IQR method, the choice of defining a scale equal to 1.5 is used because it gives us a range between -2.7xsigma and +2.7xsigma (which is pretty closed to the scale of 3 in the Gaussian distribution) while keeping a certain symmetry in the outliers detection.\n\nHence, we're using these two following delimiters to detect our outliers:\nLower Bound: (Q1 - 1.5 * IQR)\nUpper Bound: (Q3 + 1.5 * IQR)\n\nBy using *dataset_out.describe()*, we clearly notice the difference in the **max** values with *dataset.describe()*. \n\n","25e2d4ba":"# Application\n\nOur application called **Ketodapp** allows the users to add their groceries on a list in the app which show them the addition of fat, proteins and carbohydrates in their grocery list so they know if they exceed their weekly consumption in their keto diet. \nThey will use Ketodapp to plan their daily, weekly, monthly groceries. We can even think about adding QR code for each product so they can use it while doing their groceries to see if they exceed the authorized fat, proteins and carbs or if they still have space left to buy more products. \n\nWhen creating an account on the application, we can have the users setting the parameters they want for their keto diet and input the correct amount of fat, proteins and carbs per day, week and month that they desire to respect."}}