{"cell_type":{"9bf2d5c4":"code","0b57815b":"code","06aae02d":"code","5051041a":"code","206a6f1a":"code","f36e4b07":"code","16cdb8aa":"code","97949bc5":"code","6cc0dda3":"code","d6e50c11":"code","7f3c7024":"code","16ddcb6b":"code","448a56a1":"code","edc0282e":"code","e3c38fac":"code","a7c85eb2":"code","e0962267":"code","78707bfc":"markdown","f8a583e5":"markdown","2a5dd616":"markdown","9322bab9":"markdown","0d6671cc":"markdown","4064d391":"markdown","e0fef1cf":"markdown"},"source":{"9bf2d5c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0b57815b":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/output'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","06aae02d":"import nltk\nimport random\nfrom nltk.classify.scikitlearn import SklearnClassifier\nimport pickle\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import SVC\nfrom nltk.classify import ClassifierI\nfrom statistics import mode\nfrom nltk.tokenize import word_tokenize\nimport re","5051041a":"files_pos = os.listdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclImdb\/train\/pos\/')\nfiles_pos = [open('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclImdb\/train\/pos\/'+f, 'r').read() for f in files_pos]\nfiles_neg = os.listdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclImdb\/train\/neg\/')\nfiles_neg = [open('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclImdb\/train\/neg\/'+f, 'r').read() for f in files_neg]","206a6f1a":"len(files_neg)","f36e4b07":"all_words = []\ndocuments = []\n\nfrom nltk.corpus import stopwords\nimport re\n\nstop_words = list(set(stopwords.words('english')))\n\n#  j is adject, r is adverb, and v is verb\n#allowed_word_types = [\"J\",\"R\",\"V\"]\nallowed_word_types = [\"J\"]\n\nfor p in  files_pos:\n    \n    # create a list of tuples where the first element of each tuple is a review\n    # the second element is the label\n    documents.append( (p, \"pos\") )\n    \n    # remove punctuations\n    cleaned = re.sub(r'[^(a-zA-Z)\\s]','', p)\n    \n    # tokenize \n    tokenized = word_tokenize(cleaned)\n    \n    # remove stopwords \n    stopped = [w for w in tokenized if not w in stop_words]\n    \n    # parts of speech tagging for each word \n    pos = nltk.pos_tag(stopped)\n    \n    # make a list of  all adjectives identified by the allowed word types list above\n    for w in pos:\n        if w[1][0] in allowed_word_types:\n            all_words.append(w[0].lower())\n\n    \nfor p in files_neg:\n    # create a list of tuples where the first element of each tuple is a review\n    # the second element is the label\n    documents.append( (p, \"neg\") )\n    \n    # remove punctuations\n    cleaned = re.sub(r'[^(a-zA-Z)\\s]','', p)\n    \n    # tokenize \n    tokenized = word_tokenize(cleaned)\n    \n    # remove stopwords \n    stopped = [w for w in tokenized if not w in stop_words]\n    \n    # parts of speech tagging for each word \n    neg = nltk.pos_tag(stopped)\n    \n    # make a list of  all adjectives identified by the allowed word types list above\n    for w in neg:\n        if w[1][0] in allowed_word_types:\n            all_words.append(w[0].lower())","16cdb8aa":"len(all_words)","97949bc5":"pos_A = []\nfor w in pos:\n    if w[1][0] in allowed_word_types:\n        pos_A.append(w[0].lower())\npos_N = []\nfor w in neg:\n    if w[1][0] in allowed_word_types:\n        pos_N.append(w[0].lower())","6cc0dda3":"len(pos_N)","d6e50c11":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\ntext = ' '.join(pos_A)\nwordcloud = WordCloud().generate(text)\n\nplt.figure(figsize = (15, 9))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation= \"bilinear\")\nplt.axis(\"off\")\nplt.show()","7f3c7024":"len(pos)","16ddcb6b":"# pickling the list documents to save future recalculations \n#save_documents = 'documents.pickle'\n#save_documents = open(\"..\/output\/kaggle\/working\/documents.pickle\",\"w\")\n#pickle.dump(documents, save_documents)\n#save_documents.close()","448a56a1":"# creating a frequency distribution of each adjectives. \nBOW = nltk.FreqDist(all_words)\n","edc0282e":"# listing the 5000 most frequent words\nword_features = list(BOW.keys())[:5000]\nword_features[0], word_features[-1]","e3c38fac":"# function to create a dictionary of features for each review in the list document.\n# The keys are the words in word_features \n# The values of each key are either true or false for wether that feature appears in the review or not\ndef find_features(document):\n    words = word_tokenize(document)\n    features = {}\n    for w in word_features:\n        features[w] = (w in words)\n\n    return features\n\n# Creating features for each review\nfeaturesets = [(find_features(rev), category) for (rev, category) in documents]\n\n# Shuffling the documents \nrandom.shuffle(featuresets)\nprint(len(featuresets))","a7c85eb2":"training_set = featuresets[:20000]\ntesting_set = featuresets[20000:]\nprint( 'training_set :', len(training_set), '\\ntesting_set :', len(testing_set))","e0962267":"classifier = nltk.NaiveBayesClassifier.train(training_set)\n\nprint(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n\nclassifier.show_most_informative_features(15)","78707bfc":"# Sentiment Classification Using Bayes Approach","f8a583e5":"# Word Cloud","2a5dd616":"# Feature Extraction for Reviews","9322bab9":"# BOW","0d6671cc":"# Imports","4064d391":"# Save Documents","e0fef1cf":"# Preprocessing"}}