{"cell_type":{"4a8a0079":"code","302ffa17":"code","2b18785b":"code","3c42b407":"code","440fa672":"code","e59fe369":"code","36ae6ab7":"code","c017e973":"code","576e8e1b":"code","b688a4f4":"code","8baee17c":"code","f3040e22":"code","b42e2091":"code","ddf1b054":"code","45e26c48":"code","5db7a7f3":"code","8021da2a":"code","d8d254f1":"code","ab41480d":"code","bc2ea7cc":"code","3c984736":"code","ca66b001":"code","7197e333":"code","a1dda7d3":"code","4e90c70a":"code","85fa98b9":"code","5ede1e7e":"code","85ba0622":"markdown","9fe79500":"markdown","8f885b23":"markdown","4e784b9c":"markdown","0494b64e":"markdown","f47b8635":"markdown","aa8f6881":"markdown","51ba4efc":"markdown","abd6a3c2":"markdown"},"source":{"4a8a0079":"# Install packages","302ffa17":"# Import packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport re\nfrom tqdm import tqdm","2b18785b":"train_data = pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')\nsubmission_data = pd.read_csv('..\/input\/feedback-prize-2021\/sample_submission.csv')","3c42b407":"print(train_data.shape)\ntrain_data.head()","440fa672":"print('Discourse types in train:\\n', len(train_data['discourse_type'].unique().tolist()), 'types -', train_data['discourse_type'].unique().tolist())","e59fe369":"print('# Splits for first passage:', train_data[train_data['id']==train_data['id'].iloc[0]]['discourse_id'].nunique())\ntrain_data[train_data['id']==train_data['id'].iloc[0]]","36ae6ab7":"print(submission_data.shape)\nsubmission_data.head()","c017e973":"''.join(train_data[train_data['id']==train_data['id'].unique()[2]]['predictionstring'].tolist())","576e8e1b":"len(' '.join(train_data[train_data['id']==train_data['id'].unique()[2]]['discourse_text'].apply(lambda x: re.sub('\\n+',' ',x)).str.strip().tolist()).split(' ')), len(' '.join(train_data[train_data['id']==train_data['id'].unique()[2]]['predictionstring'].tolist()).split(' '))","b688a4f4":"filepath = '..\/input\/feedback-prize-2021\/'\nrecord_id = 'A97DE0D49AEA'\n# record_id = '1CEDD5563788'\nwith open(filepath + 'train\/' + record_id+'.txt','r') as f:\n    data = f.read()","8baee17c":"train_data[train_data['id']==record_id]","f3040e22":"re.sub('\\n+',' ', data).strip().replace(\"\\xa0\",\" \").replace('\"','')","b42e2091":"re.sub('\\n+',' ',train_data[train_data['id']==record_id]['discourse_text'].iloc[0].strip().replace(\"\\xa0\",\" \").replace('\"',''))","ddf1b054":"print('Prediction string in train data should start at:', len(re.sub('\\n+',' ', data).strip().replace(\"\\xa0\",\" \").replace('\"','')[0:re.sub('\\n+',' ', data).strip().replace(\"\\xa0\",\" \").replace('\"','').find(' '.join(re.sub('\\n+',' ',train_data[train_data['id']==record_id]['discourse_text'].iloc[0].strip().replace(\"\\xa0\",\" \").replace('\"','')).split(' ')[0:4]))].strip().split(' ')))","45e26c48":"len(re.sub('\\n+',' ',train_data[train_data['id']==record_id]['discourse_text'].iloc[0]).strip().replace(\"\\xa0\",\" \").replace('\"','').split(' ')), re.sub('\\n+',' ',train_data[train_data['id']==record_id]['discourse_text'].iloc[0]).strip().replace(\"\\xa0\",\" \").replace('\"','').split(' ')","5db7a7f3":"len(train_data[train_data['id']==record_id]['predictionstring'].iloc[0].split(' ')), train_data[train_data['id']==record_id]['predictionstring'].iloc[0].split(' ')","8021da2a":"train_data['cleaned_discourse_text'] = train_data['discourse_text'].apply(lambda x: re.sub('\\n+',' ',x).strip().replace(\"\\xa0\",\" \").replace('\"',''))\ntrain_data['Flag - pred len and text len'] = np.where(len(train_data['cleaned_discourse_text'].str.split(' '))==len(train_data['predictionstring'].str.split(' ')), 1, 0)\n\nmismatches_pred_string = []\nrecords_with_name_mask = []\nrecord_id_list = []\n\nfor i in tqdm(range(0, train_data.shape[0])):\n    record_id = train_data['id'].iloc[i]\n    if record_id not in record_id_list:\n        with open(filepath + 'train\/' + record_id+'.txt','r') as f:\n            data = f.read()\n\n        data = re.sub('\\n+',' ', data).strip().replace(\"\\xa0\",\" \").replace('\"','')\n        str_index = data.find(train_data[train_data['id']==record_id]['cleaned_discourse_text'].iloc[0])\n        words_before_pred_string_start = data[:str_index].strip().split(' ')\n\n        if str_index != -1:\n            if (len(words_before_pred_string_start) != int(train_data['predictionstring'].iloc[i].strip().split(' ')[0])) and (words_before_pred_string_start[0] != ''):\n                mismatches_pred_string.append(record_id)\n                if ('PROPER_NAME' in data) or ('GENERIC_NAME' in data):\n                    records_with_name_mask.append(record_id)\n        else:   \n            # At least first 4 words are correct\n            if (len(data[:data.find(' '.join(train_data[train_data['id']==record_id]['cleaned_discourse_text'].iloc[0].split(' ')[0:4]))].strip().split(' ')) != int(train_data['predictionstring'].iloc[i].strip().split(' ')[0])) and (data[:data.find(' '.join(train_data[train_data['id']==record_id]['cleaned_discourse_text'].iloc[0].split(' ')[0:4]))].strip().split(' ')[0] != ''):\n                mismatches_pred_string.append(record_id)\n                if ('PROPER_NAME' in data) or ('GENERIC_NAME' in data):\n                    records_with_name_mask.append(record_id)\n        record_id_list.append(record_id)","d8d254f1":"print('# Records with number of words in discourse text not equal to number of indices in prediction string:', train_data[train_data['Flag - pred len and text len'] == 0].shape[0])","ab41480d":"print('# Misatches:', len(mismatches_pred_string), 'out of', train_data['id'].nunique(), 'ids in train data', '(' + str(len(mismatches_pred_string)\/train_data['id'].nunique() * 100) + '%)')","bc2ea7cc":"mismatches_pred_string","3c984736":"len([x for x in mismatches_pred_string if x not in records_with_name_mask]), [x for x in mismatches_pred_string if x not in records_with_name_mask]","ca66b001":"# # Check if ending of predictionstring matches with beginning of next predictionstring\n# start_not_matching_end_discourse_ids = []\n# for i in tqdm(range(0, train_data.shape[0])):\n#     temp = train_data[(train_data['id']==train_data['id'].iloc[i])].reset_index(drop = True)\n#     temp_index = temp[temp['discourse_id']==train_data['discourse_id'].iloc[i]].index[0]\n#     if temp_index > 0:\n#         if (temp['discourse_id'].iloc[temp_index-1] != train_data['discourse_id'].iloc[i]):\n#             previous_pred = temp['predictionstring'].iloc[temp_index-1].strip().split(' ')[-1]\n#             start_pred = train_data['predictionstring'].iloc[i].strip().split(' ')[0]\n#             if int(start_pred) != int(previous_pred) + 1:\n#                 start_not_matching_end_discourse_ids.append(train_data['discourse_id'].iloc[i])","7197e333":"record_id = 'E05C7F5C1156'\n\nwith open(filepath + 'train\/' + record_id+'.txt','r') as f:\n    data = f.read()","a1dda7d3":"train_data[train_data['id']==record_id]","4e90c70a":"re.sub('\\n+',' ', data).strip().replace(\"\\xa0\",\" \").replace('\"','')","85fa98b9":"re.sub('\\n+',' ',train_data[train_data['id']==record_id]['discourse_text'].iloc[4].strip().replace(\"\\xa0\",\" \").replace('\"',''))","5ede1e7e":"re.sub('\\n+',' ',train_data[train_data['id']==record_id]['discourse_text'].iloc[5].strip().replace(\"\\xa0\",\" \").replace('\"',''))","85ba0622":"# Import packages","9fe79500":"The sentence \"Therefore, driving can cause many accidents that can be fatal to the driver and passengers if there is any and cell phones should only be used when not operating a vehicle.\" does not have any tagged class","8f885b23":"# Load data","4e784b9c":"https:\/\/drive.google.com\/file\/d\/1r9vxKn5Az3ZBoZ7PgkmIh2ov87axyN8B\/view","0494b64e":"# EDA","f47b8635":"Combined words create an issue e.g: \"DrivingHundreds\" in the above passage\n\nAlso references are not to be tagged under the 7 classes","aa8f6881":"# Feedback Prize - Evaluating Student Writing\n#### Analyze argumentative writing elements from students grade 6-12\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/31779\/logos\/header.png?t=2021-11-12-22-52-17&quot)","51ba4efc":"## Check prediction string","abd6a3c2":"# WIP"}}