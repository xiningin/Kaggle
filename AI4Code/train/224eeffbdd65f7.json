{"cell_type":{"1639a8ff":"code","3d4de318":"code","714292d4":"code","715619a4":"code","e97a35c0":"code","5c5264c9":"code","040b49d0":"code","8daac139":"code","5a6ae5d4":"code","21e8e0ed":"code","131f4add":"code","190d5dee":"code","c9868ef0":"code","6fb096ae":"code","7a1e287e":"code","4567c320":"code","a9f0d996":"code","3374ce0a":"code","dde18318":"code","5b358fe9":"code","db6e6fd5":"code","b3193dd0":"code","f2b80931":"code","6746f75c":"code","bbec681a":"code","9a7c95fa":"code","5b421b91":"code","c86aa54a":"code","9ace53d0":"code","d86e231b":"code","d737387e":"code","b6a3eeaf":"code","b5133095":"code","b0be25a2":"code","f5404fe6":"code","0a5a1e3e":"code","bf5d0031":"code","a8d3614a":"code","a911d34c":"code","1b036514":"code","ecd516d2":"code","63d25a36":"code","1b4f66c8":"code","dd1ef181":"code","a9a366ad":"code","8d62fff1":"code","77d5bc1b":"markdown","5cf173c5":"markdown","198dfba3":"markdown","dcc1b55e":"markdown","16696fcd":"markdown","11e26cae":"markdown","5854ee53":"markdown","377817fe":"markdown"},"source":{"1639a8ff":"# Load Grassroots DICOM (GDCM) for xray DICOM files\n!pip install python-gdcm -q\n\n# Load glob2\n!pip install glob2\n\n# Load tqdm\n!pip install tqdm","3d4de318":"# Loading necessary packages\nimport os\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport glob2\nfrom tqdm.notebook import tqdm\nimport cv2\nimport gdcm\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nfrom torchvision.utils import save_image","714292d4":"SOURCE = '\/kaggle\/input\/siim-covid19-detection'\nos.listdir(SOURCE)","715619a4":"train_image_level = pd.read_csv(f'{SOURCE}\/train_image_level.csv')\ntrain_study_level = pd.read_csv(f'{SOURCE}\/train_study_level.csv')\nsample_submission = pd.read_csv(f'{SOURCE}\/sample_submission.csv')","e97a35c0":"train_image_level.head()","5c5264c9":"train_study_level.head()","040b49d0":"sample_submission.head()","8daac139":"# XRAY Files\ndef get_dcm_files(path, recurse=True, folders=None):\n    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n    return get_files(path, extensions=['.dcm'], recurse=recurse, folders=folders)\n\n# Read DICOM files\nTRAIN_DIR = f'{SOURCE}\/train\/'\nTEST_DIR =  f'{SOURCE}\/test\/'\ntrain_dcm = get_dcm_files(TRAIN_DIR)\ntest_dcm = get_dcm_files(TEST_DIR)\n\n# Looking on a sample XRAY\nxray_sample = train_dcm[1].dcmread()\nxray_sample","5a6ae5d4":"xray_sample.show()","21e8e0ed":"# Merging study_level and image_level\n# rename id column in study_level to StudyInstanceUID\ntrain_study_level.rename(columns = {'id':'StudyInstanceUID'}, inplace = True)\n\n# remove _study from StudyInstanceUID\ntrain_study_level['StudyInstanceUID'] = train_study_level['StudyInstanceUID'].str.replace('_study', '')\n\n# merge\ndf_train = pd.merge(train_image_level, train_study_level, on='StudyInstanceUID')\n\n# remove _image from id column\ndf_train['id'] = df_train['id'].str.replace('_image', '')\n\n# rename id column as imageID\ndf_train.rename(columns = {'id':'imageID'}, inplace = True)\n\n# renaming target columns\ndf_train.rename(columns = {'Negative for Pneumonia':'negative'}, inplace = True)\ndf_train.rename(columns = {'Typical Appearance':'typical'}, inplace = True)\ndf_train.rename(columns = {'Indeterminate Appearance':'indeterminate'}, inplace = True)\ndf_train.rename(columns = {'Atypical Appearance':'atypical'}, inplace = True)\n\n# Create a new target column\ncategories = ['negative','typical','indeterminate','atypical']\ndf = df_train[categories]\ndf_train[\"target\"] = pd.Series(df.columns[np.where(df!=0)[1]])\ndf_train.head()","131f4add":"# Creating path column for each image\nTRAIN_DIR = f'{SOURCE}\/train\/'\npaths = []\n\nfor instance_id in tqdm(df_train['StudyInstanceUID']):\n    paths.append(glob.glob(os.path.join(TRAIN_DIR, instance_id +\"\/*\/*\"))[0])\n\ndf_train['path'] = paths\ndf_train[:5]","190d5dee":"# Calculate number of bounding boxes\n# Source: https:\/\/www.kaggle.com\/avirdee\/siim-covid-19-initial-pipeline-fastai\nnum_of_boxes = []\nfor i in df_train.index:\n    val_len = len(df_train['label'][i].split(' '))\n    val = df_train['label'][i].split(' ')\n    label = df_train['target'][i]\n    box_count = val_len\/\/6\n    num_of_boxes.append(box_count)\n    \ndf_train['num_of_boxes'] = num_of_boxes\ndf_train.head()","c9868ef0":"df_train['num_of_boxes'].value_counts()","6fb096ae":"# Parse label column\nbboxes = []\nfor i in df_train.index:\n    num_of_boxes = df_train['num_of_boxes'][i]\n    val = df_train['label'][i].split(' ')\n    if num_of_boxes == 1: boxes = val[2:6]\n    if num_of_boxes == 2: boxes = val[2:6] + val[8:12]\n    if num_of_boxes == 3: boxes = val[2:6] + val[8:12] + val[14:18]\n    if num_of_boxes == 4: boxes = val[2:6] + val[8:12] + val[14:18] + val[20:24]\n    bboxes.append(boxes)\n    \ndf_train['parsed_label'] = bboxes\ndf_train.head()","7a1e287e":"# Subsetting df_train on columns required for datablock\ndf_datablock = df_train[['imageID', 'target', 'parsed_label', 'path']].copy()\ndf_datablock.head()","4567c320":"# Defining get_items() as Path() object to file\nim_df = df_datablock['path'].unique()\nfns = [Path(str(f'{fn}')) for fn in im_df]\n#fns[:5]\n\ndef get_items(noop): return fns","a9f0d996":"# Convert data frame to numpy array for faster processing\ndf_np = df_datablock.to_numpy()\ndf_np[0]","3374ce0a":"def get_tmp_bbox(fn):\n    rows = np.where(df_np[:,0] == fn.name[:-4])\n    bboxs = df_np[rows][:,-2][0]\n    return np.array([np.fromstring(b, sep=',') for b in bboxs])\n\ndef get_tmp_lbl(fn):\n    rows = np.where((df_np[:, 0] == fn.name[:-4]))\n    bboxs = len(df_np[rows][:,-2][0])\n    if bboxs > 12:\n        return np.concatenate(([df_np[rows][:,1]]*4))\n    if bboxs > 8:\n        return np.concatenate(([df_np[rows][:,1]]*3))\n    if bboxs > 4:\n        return np.concatenate(([df_np[rows][:,1]]*2))\n    else:\n        return df_np[rows][:,1]","dde18318":"get_tmp_bbox(get_items(SOURCE)[2])","5b358fe9":"get_tmp_lbl(get_items(SOURCE)[2])","db6e6fd5":"bboxs = get_tmp_bbox(fns[0])\nlbls = get_tmp_lbl(fns[0])\narr = np.array([fns[0].name[:-4], bboxs, lbls], dtype=object)\narr","b3193dd0":"# Whole dataset\nfor path in fns[1:]:\n    bbox = get_tmp_bbox(path)\n    lbl = get_tmp_lbl(path)\n    arr2 = np.array([path.name[:-4], bbox, lbl], dtype='object')\n    arr = np.vstack((arr, arr2))","f2b80931":"def get_bbox(fn):\n    idx = np.where((arr[:,0] == fn.name[:-4]))\n    return arr[idx][0][1]\n\ndef get_lbl(fn):\n    idx = np.where((arr[:,0] == fn.name[:-4]))\n    return arr[idx][0][-1]","6746f75c":"get_bbox(get_items(SOURCE)[2])","bbec681a":"get_lbl(get_items(SOURCE)[2])","9a7c95fa":"# Source: https:\/\/www.kaggle.com\/avirdee\/siim-covid-19-initial-pipeline-fastai\nclass HistView(PILDicom):\n    \"View histogram scaled version of the pixel array\"\n    @classmethod\n    def create(cls, fn:(Path, str, bytes))->None:\n        if isinstance(fn, bytes): im = pydicom.dcmread(pydicom.filebase.DicomBytesIO(fn))\n        if isinstance(fn, (Path, str)): im = pydicom.dcmread(fn)\n        scaled = np.array(im.hist_scaled())\n        scaled = scaled - np.min(scaled)\n        scaled = scaled \/ np.max(scaled)\n        scaled = (scaled * 255).astype(np.uint8)\n        pill_im = Image.fromarray(scaled)\n        return cls(pill_im)","5b421b91":"set_seed(7)\ndatablock = DataBlock(blocks=(ImageBlock(cls=HistView), BBoxBlock, BBoxLblBlock),\n                 get_items=get_items,\n                 splitter=RandomSplitter(),\n                 get_y=[get_bbox, get_lbl],\n                 item_tfms=[Resize(128, method='pad'),],\n                 batch_tfms=[Rotate(), Flip(), Dihedral(), Normalize.from_stats(*imagenet_stats)],\n                 n_inp=1)\n\ndls = datablock.dataloaders(TRAIN_DIR, bs=128)\ndls.show_batch(max_n=20, ncols=5)","c86aa54a":"# Checking shape of a batch\nbatch = dls.one_batch()\nbatch[0].shape","9ace53d0":"batch[1].shape","d86e231b":"batch[1][0]","d737387e":"batch[2].shape","b6a3eeaf":"batch[2][0]","b5133095":"# Source: https:\/\/github.com\/muellerzr\/Practical-Deep-Learning-for-Coders-2.0\/blob\/master\/Computer%20Vision\/06_Object_Detection.ipynb\n!git clone https:\/\/github.com\/muellerzr\/Practical-Deep-Learning-for-Coders-2.0.git\n%cd \"Practical-Deep-Learning-for-Coders-2.0\/Computer Vision\"","b0be25a2":"from imports import *","f5404fe6":"encoder = create_body(resnet34, pretrained=True)","0a5a1e3e":"arch = RetinaNet(encoder, get_c(dls), final_bias=-4)","bf5d0031":"# Loss function\nratios = [1\/2,1,2]\nscales = [1,2**(-1\/3), 2**(-2\/3)]","a8d3614a":"crit = RetinaNetFocalLoss(scales=scales, ratios=ratios)","a911d34c":"def _retinanet_split(m): \n    return L(m.encoder,nn.Sequential(m.c5top6, m.p6top7, m.merges, m.smoothers, m.classifier, m.box_regressor)).map(params)","1b036514":"learn = Learner(dls, arch, loss_func=crit, splitter=_retinanet_split)","ecd516d2":"learn.freeze()","63d25a36":"learn.fit_one_cycle(2, slice(1e-5, 1e-4))","1b4f66c8":"# Saving weights of the trained model\nTRAINED_MODELS_DIR = '\/kaggle\/working\/trained_models_dir\/'\nos.mkdir(TRAINED_MODELS_DIR)\n\ntimestamp = datetime.now().strftime(\"_%Y%m%d_%H%M%S_\")\nfile_name = TRAINED_MODELS_DIR + \"trainedModelWeights\" + timestamp\nlearn.save(file = file_name)","dd1ef181":"# Exporting the trained model\ntimestamp = datetime.now().strftime(\"_%Y%m%d_%H%M%S_\")\nfile_name = TRAINED_MODELS_DIR + \"trainedModelExport\" + timestamp + \".pkl\"\nlearn.export(fname = file_name)\nos.listdir(TRAINED_MODELS_DIR)","a9a366ad":"sample_img_path = TEST_DIR + '\/2fb11712bc93\/b056067b8455\/a29c5a68b07b.dcm'\nsample_img_path","8d62fff1":"learn.predict(sample_img_path)","77d5bc1b":"# 3. Preparing DataBlock","5cf173c5":"# 4. Training","198dfba3":"# 5. Predictions","dcc1b55e":"The objective of this notebook is to provide a minimum viable pipeline using [fastai](https:\/\/docs.fast.ai\/) for classification and detection of opacity in xray images. Anyone who is new to this competition can start from this notebook and learn the followings:\n\n* Basic understanding of the nature of medical imaging data\n* Introduction to fastai library for [medical imaging](https:\/\/docs.fast.ai\/medical.imaging)\n* Submission of predictions\n\nThe progress is as following:\n\n    1. Data Overview           (Done)\n    2. Data Preprocessing      (Done)\n    3. Preparing Datablock     (Done)\n    4. Training                (Done)\n    5. Predictions             (In Progress)\n    6. Subsmission             (tdb)\n\nI am using following 2 notebooks as reference:\n* https:\/\/www.kaggle.com\/avirdee\/siim-covid-19-initial-pipeline-fastai\n* https:\/\/github.com\/muellerzr\/Practical-Deep-Learning-for-Coders-2.0\/blob\/master\/Computer%20Vision\/06_Object_Detection.ipynb\n\n    ","16696fcd":"# 2. Data Preprocessing","11e26cae":"# 6. Submission","5854ee53":"# 1. Data Overview","377817fe":"# 0. Objective"}}