{"cell_type":{"01c7525f":"code","c78c15d7":"code","36b7cce2":"code","54673a55":"code","5dd065ee":"code","0e11141b":"code","d8e91bb2":"code","17debcbc":"code","94ce7877":"code","9a318dcf":"code","aefd3bbc":"code","db8e3dfa":"code","c494301c":"code","b5dfce07":"code","60a86ae2":"code","3cb102c6":"code","b7b4f80b":"code","9106387a":"code","904e691e":"code","d133b991":"code","887c95af":"code","89566120":"code","2dc81c06":"code","c4efa5f9":"code","56df6017":"code","3b2c795e":"code","993babec":"code","cacebc56":"code","e762a875":"code","0fb91bfc":"code","4d0bec27":"code","f1ec02e4":"code","bfb900b3":"markdown","76e374ae":"markdown","054cb1d3":"markdown","80bbc6e7":"markdown","1bb38bbf":"markdown","2c694be0":"markdown"},"source":{"01c7525f":"from IPython.display import Image\nimport os\n!ls ..\/input\/image1\n","c78c15d7":"Image(\"..\/input\/image1\/COVID_TWITTER1200X600.jpg\")","36b7cce2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nfrom wordcloud import WordCloud, STOPWORDS\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","54673a55":"data = pd.read_csv(\"\/kaggle\/input\/covid19-tweets\/covid19_tweets.csv\")","5dd065ee":"data.info()","0e11141b":"data_shape =  data.shape\nprint(f\"Shape of the dataset {data_shape}\")","d8e91bb2":"data.head(10).style.highlight_max(color ='red').highlight_min(color='green')","17debcbc":"data.tail(5).style.highlight_max(color='blue').highlight_min(color='lightgreen')","94ce7877":"data.describe().style.highlight_max(color=\"green\").highlight_min(color=\"lightgreen\")","9a318dcf":"data.columns","aefd3bbc":"missing_graph = sns.heatmap(data.isnull(),cbar=False,yticklabels=False,cmap='viridis')\nprint(f\"Graphically Representation of Missing values : \\n {missing_graph}\")","db8e3dfa":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals \/ total * 100, 3)\n    return(np.transpose(tt))\n\nmost_frequent_values(data)","c494301c":"def plot_features_distribution(features, title, df, isLog=False):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    for feature in features:\n        if(isLog):\n            sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature)\n        else:\n            sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature)\n    plt.xlabel('')\n    plt.legend()\n    plt.show()\n","b5dfce07":"data['hashtags'] = data['hashtags'].replace(np.nan, \"['None']\", regex=True)\ndata['hashtags'] = data['hashtags'].apply(lambda x: x.replace('\\\\N',''))\ndata['hashtags_count'] = data['hashtags'].apply(lambda x: len(x.split(',')))\nplot_features_distribution(['hashtags_count'], 'Hashtags per tweet (all data)', data)","60a86ae2":"data['hashtags_individual'] = data['hashtags'].apply(lambda x: x.split(','))\nfrom itertools import chain\nall_hashtags = set(chain.from_iterable(list(data['hashtags_individual'])))\nprint(f\"There are totally: {len(all_hashtags)}\")","3cb102c6":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(10,10))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","b7b4f80b":"show_wordcloud(data['text'], title = 'Prevalent words in tweets')","9106387a":"india_df = data.loc[data.user_location==\"India\"]\nshow_wordcloud(india_df['text'], title = 'Prevalent words in tweets from India')","904e691e":"new_df = data.loc[data.user_location==\"New Delhi\"]\nshow_wordcloud(new_df['text'], title = 'Prevalent words in tweets from New Delhi')","d133b991":"mumbai_df = data.loc[data.user_location==\"Mumbai\"]\nshow_wordcloud(mumbai_df['text'], title = 'Prevalent words in tweets from Mumbai')","887c95af":"pune_df = data.loc[data.user_location==\"Pune\"]\nshow_wordcloud(pune_df['text'], title = 'Prevalent words in tweets from Pune')","89566120":"hyderabad_df = data.loc[data.user_location==\"Hyderabad\"]\nshow_wordcloud(hyderabad_df['text'], title = 'Prevalent words in tweets from Hyderabad')","2dc81c06":"delhi_df = data.loc[data.user_location==\"Delhi\"]\nshow_wordcloud(delhi_df['text'], title = 'Prevalent words in tweets from Delhi')","c4efa5f9":"punjab_df = data.loc[data.user_location==\"Punjab\"]\nshow_wordcloud(punjab_df['text'], title = 'Prevalent words in tweets from Punjab')","56df6017":"USA_df = data.loc[data.user_location==\"USA\"]\nshow_wordcloud(USA_df['text'], title = 'Prevalent words in tweets from USA')","3b2c795e":"london_df = data.loc[data.user_location==\"London\"]\nshow_wordcloud(london_df['text'], title = 'Prevalent words in tweets from London')","993babec":"world_df = data.loc[data.user_location==\"WORLDWIDE\"]\nshow_wordcloud(world_df['text'], title = 'Prevalent words in tweets from WORLDWIDE')","cacebc56":"global_df = data.loc[data.user_location==\"Global\"]\nshow_wordcloud(global_df['text'], title = 'Prevalent words in tweets from Global')","e762a875":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()    ","0fb91bfc":"plot_count(\"user_location\", \"User location\", data,4)","4d0bec27":"plot_count(\"user_name\", \"User name\", data,4)","f1ec02e4":"plot_count(\"source\", \"Source\", data,4)","bfb900b3":"# COVID -19 INDIA TWEETS !\n    PLEASE UPVOTE !","76e374ae":"# Sources from where they are Collected!\n","054cb1d3":"# Hashtags analysis","80bbc6e7":"# Word Cloud on Tweet dataset.","1bb38bbf":"# Most frequent tweets values","2c694be0":"# Check the Missing values in the Dataset."}}