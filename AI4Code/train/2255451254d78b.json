{"cell_type":{"851bfc9d":"code","412ecd85":"code","1d9480d8":"code","ef63d9e8":"code","d1fe882c":"code","7e19d218":"code","aa079b43":"code","44e86e3d":"code","d68fa78e":"code","b7137f0e":"code","cd60b608":"code","23052a9c":"code","f225bf7f":"code","a36e9a0e":"code","aa7dec8a":"code","66394c27":"code","65ab5991":"code","aa968345":"code","459d3bcf":"code","a7ad0fa9":"code","42b9fc00":"code","ef1a1fb3":"code","924a0df2":"markdown","fabe462c":"markdown","5afeb841":"markdown","a8f5d560":"markdown","373be538":"markdown","49b4268d":"markdown","0abc54ab":"markdown","933cb73d":"markdown","2053b785":"markdown","aff43ea9":"markdown","87284c46":"markdown","01bc82a0":"markdown","213ab609":"markdown","b7c61927":"markdown"},"source":{"851bfc9d":"# data processing\nimport pandas as pd\nimport numpy as np\n# plotting\nfrom pandas.plotting import parallel_coordinates\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n# models\nimport sklearn.linear_model\nfrom sklearn.svm import SVC\nimport sklearn.model_selection\nfrom sklearn import metrics, tree, ensemble, neighbors","412ecd85":"ratings_train = pd.read_csv(\"..\/input\/homework-2\/train.csv\", index_col = 'id')\nratings_eval = pd.read_csv(\"..\/input\/homework-2\/eval.csv\", index_col = 'id')\nprint(ratings_train.shape)\nratings_train.head(1)","1d9480d8":"# note eval already has title column dropped\nratings_eval.head()","ef63d9e8":"ratings_train.mean()","d1fe882c":"# all columns have no missing values, every field is one hot encoded except target value and console\n# ratings.isna().sum()\nratings_train.info()\nrating_PC_totals = np.array([])\nrating_console_totals = np.array([])\n# count up instances of game ratings by console and rating type\nfor rating in ratings_train['esrb_rating'].unique():\n    rating_PC_totals = np.append(rating_PC_totals, ratings_train[(ratings_train['esrb_rating']==rating) & \n                                                                     (ratings_train['console']==1)].shape[0])\n    rating_console_totals = np.append(rating_console_totals, ratings_train[(ratings_train['esrb_rating']==rating) & \n                                                                     (ratings_train['console']==0)].shape[0])\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(ratings_train['esrb_rating'].unique(), rating_PC_totals, color='r')\nax.bar(ratings_train['esrb_rating'].unique(), rating_console_totals, bottom = rating_PC_totals, color='b')\nax.set_title('PC vs Console Total Ratings')\nax.set_xlabel('rating')\nax.set_ylabel('counts')\nax.legend(labels=['PC', 'Console'])","7e19d218":"#totals for each binary feature\nfeature_labels = ratings_train[:][0:32].columns\n# drop title and rating\nfeature_PC_totals = np.array([])\nfeature_console_totals = np.array([])\nfeature_labels = feature_labels[2:-1]\nfor label in feature_labels:\n    feature_PC_totals = np.append(feature_PC_totals, ratings_train[(ratings_train['console']==0)][label].sum())\n    feature_console_totals = np.append(feature_console_totals, ratings_train[(ratings_train['console']==1)][label].sum())\n# print(feature_console_totals, feature_PC_totals)\nfig = plt.figure(figsize=(14,6))\nax = fig.add_axes([0,0,1,1])\nax.bar(feature_labels, feature_PC_totals, color='r')\nax.bar(feature_labels, feature_console_totals, bottom = feature_PC_totals, color='b')\nax.set_title('PC vs Console Total Feature Totals')\nax.set_xlabel('Feature')\nax.set_ylabel('counts')\nax.legend(labels=['PC', 'Console'])\nplt.xticks(rotation=90)\nprint('Mean features per sample:', (feature_PC_totals.sum()+feature_console_totals.sum())\/(1422))","aa079b43":"feature_labels","44e86e3d":"alcohol_labels=np.array([])\nblood_labels=np.array([])\nviolence_labels=np.array([])\nsexual_labels=np.array([])\ndrug_labels=np.array([])\nbad_language_labels=np.array([])\nfor label in feature_labels:\n    if 'alcohol' in label:\n        alcohol_labels = np.append(alcohol_labels, label)\n    if 'blood' in label:\n        blood_labels = np.append(alcohol_labels, label)\n    if 'violen' in label:\n        violence_labels = np.append(alcohol_labels, label)\n    if ('sex' or 'suggest' or 'nudity') in label:\n        sexual_labels = np.append(alcohol_labels, label)\n    if 'drug' in label:\n        drug_labels = np.append(alcohol_labels, label)\n    if 'language' in label:\n        bad_language_labels = np.append(alcohol_labels, label)\n# these lines are unfinioshed \nbad_language_labels = np.append(alcohol_labels, ['crude_humor', 'mature_humor', 'mild_lyrics'])\nsexual_labels = np.append(alcohol_labels, 'crude_humor')\nbad_language_labels","d68fa78e":"#totals for each binary feature\nfeature_labels = ratings_train[:][0:32].columns\n# drop title and rating\nfeature_PC_totals = np.array([])\nfeature_console_totals = np.array([])\nfeature_labels = feature_labels[2:-1]\nfor label in feature_labels:\n    feature_PC_totals = np.append(feature_PC_totals, ratings_train[(ratings_train['console']==0) &  \n                                                                   (ratings_train['no_descriptors']==1)][label].sum())\n    feature_console_totals = np.append(feature_console_totals, ratings_train[(ratings_train['console']==1) &  \n                                                                   (ratings_train['no_descriptors']==1)][label].sum())\n# print(feature_console_totals, feature_PC_totals)\nfig = plt.figure(figsize=(14,6))\nax = fig.add_axes([0,0,1,1])\nax.bar(feature_labels, feature_PC_totals, color='r')\nax.bar(feature_labels, feature_console_totals, bottom = feature_PC_totals, color='b')\nax.set_title('PC vs Console Total Feature Totals, with \\'no_descriptors\\'==1' )\nax.set_xlabel('Feature')\nax.set_ylabel('counts')\nplt.xticks(rotation=90)\nax.legend(labels=['PC', 'Console'])","b7137f0e":"# correlation matrix\ncorr_matrix = ratings_train.corr()\ncorr_matrix.violence.sort_values(ascending=False)","cd60b608":"# correlation matrix\nfig, ax = plt.subplots(figsize=(13, 9))\ncorr_matrix = ratings_train.corr()\nheatmap = sns.heatmap(round(corr_matrix,2), annot=True, ax=ax, cmap=\"coolwarm\",fmt='.1f', linewidths=.01, cbar=False)","23052a9c":"# only include proper descriptors for X\nX = ratings_train.drop(columns=['esrb_rating', 'title'], axis=1).to_numpy()\ny = ratings_train['esrb_rating'].to_numpy()","f225bf7f":"train_X, test_X, train_Y, test_Y = sklearn.model_selection.train_test_split(X, y, test_size=.33)\n# logistic\nlogistic = sklearn.linear_model.LogisticRegression(penalty='l2', solver='lbfgs', multi_class='multinomial')\n# support vector machine\nSV_classifier = SVC()\n# decision tree\ntree_classifier = tree.DecisionTreeClassifier()\n# random forest classifier\nforest_classifier = ensemble.RandomForestClassifier()\n# KNN\nKNN_classifier = neighbors.KNeighborsClassifier()\nclassifiers = [logistic, SV_classifier, tree_classifier, forest_classifier, KNN_classifier]\nclassifier_labels = ['logistic', 'SV_classifier', 'tree_classifier', 'forest_classifier', 'KNN_classifier']\nlabel_iter = iter(classifier_labels)","a36e9a0e":"strat_Kfold = sklearn.model_selection.StratifiedKFold(shuffle=True, n_splits=20)\nscores = pd.Series(dtype='object')\nfor classifier in classifiers:\n    del scores\n    scores = pd.Series(dtype='object')\n    for num  in range(20):\n        scores = pd.concat([pd.Series(sklearn.model_selection.cross_val_score(classifier, train_X, train_Y, \n                                                                        scoring='accuracy', cv = strat_Kfold)), scores])\n    plt.hist(scores)\n    plt.title((classifier))\n    plt.xlabel('score')\n    plt.ylabel('count')\n    plt.show()\n    print(scores.describe())","aa7dec8a":"train_X, test_X, train_Y, test_Y = sklearn.model_selection.train_test_split(X, y, test_size=.20,shuffle=True)\nSV_tryhard = sklearn.svm.SVC()\nSV_tryhard.fit(train_X, train_Y)\ntrain_predicted = SV_tryhard.predict(train_X)\ntest_predicted = SV_tryhard.predict(test_X)\nprint('train predict:' ,sklearn.metrics.accuracy_score(train_Y, train_predicted), 'test predict:' ,sklearn.metrics.accuracy_score(test_Y, test_predicted))","66394c27":"# for i in range(4):\n#     # Separate data into test and training sets\n#     X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.20)# Train a SVC model using different kernal\n#     svclassifier = getClassifier(i) \n#     svclassifier.fit(X_train, y_train)# Make prediction\n#     y_pred = svclassifier.predict(X_test)# Evaluate our model\n#     print(\"Evaluation:\", kernals[i], \"kernel\")\n#     print(classification_report(y_test,y_pred))\n","65ab5991":"#  params reduced for runtime to save notebook\nparams = {'degree':[2],'C':np.logspace(start=-2, stop=2, base=10, num=5), 'gamma':np.logspace(start=-1, stop=2, base=5, num=5),\n'kernel':['rbf'], 'decision_function_shape' : ['ovo'], 'tol': np.logspace(start=-4, stop=-1, base=10, num=5)}\n# params = {}\ngridSearch = sklearn.model_selection.GridSearchCV(SV_classifier, param_grid=params, scoring='accuracy', cv=20)\ngridSearch.fit(train_X, train_Y)","aa968345":"gridSearch.best_params_","459d3bcf":"# used to determine gridsearch model improvements\nbest_model = gridSearch.best_estimator_\ny_pred = best_model.predict(test_X)\nprint(sklearn.metrics.accuracy_score(test_Y, y_pred))\nSV_classifier.fit(train_X, train_Y)\ny1_pred = SV_classifier.predict(test_X)\nprint(sklearn.metrics.accuracy_score(test_Y, y1_pred))","a7ad0fa9":"# print(gridSearch.best_params_)\n# y_pred = gridSearch.predict(test_X)\nfor classifier in classifiers:\n    classifier.fit(train_X, train_Y)\n    y_pred = classifier.predict(test_X)\n    print(classifier,': ')\n    print(sklearn.metrics.classification_report(test_Y, y_pred, target_names=ratings_train['esrb_rating'].unique()))\nsklearn.metrics.accuracy_score(test_Y, y_pred)","42b9fc00":"Logi_scores = sklearn.model_selection.cross_val_score(logistic, X, y, cv=20 , scoring='accuracy')\nprint('mean:', Logi_scores.mean(), 'max:',Logi_scores.max(),'min:', Logi_scores.min(), 'std:', Logi_scores.std())\nsvc_scores = sklearn.model_selection.cross_val_score(SV_classifier, X, y, cv=50, scoring='accuracy',)\nprint('mean:', svc_scores.mean(), 'max:',svc_scores.max(),'min:', svc_scores.min(), 'std:', svc_scores.std())\n# for num in range(10,250, 10):\n    \n# confusion_matrix() https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html","ef1a1fb3":"# SV_classifier.fit(ratings_train.drop(columns=['esrb_rating', 'title'], axis=1), ratings_train['esrb_rating'])\n# y_pred = gridSearch.predict(ratings_eval)\ny_pred = best_model.predict(ratings_eval)\noutput = pd.read_csv('..\/input\/homework-2\/sample_submission.csv', index_col = 0)\noutput['esrb_rating'] = y_pred\noutput.to_csv('\/kaggle\/working\/SV_try_hard_4_89.csv')\n# note best values were made with initial submission, with default parameters on the sklearn.svm.SVC() model, fitted to training datasets, and are well within the SVC() model distribution (.87)\nprint(output[:][:])","924a0df2":"## Data Pre-processing\n   - dropping title: name provides no information on rating that isnt given by content descriptor\n   - converting esrb_rating into one hot encoding, each one will be taken as a separate class\n   - dont forgeet a confusion matrix","fabe462c":"# PROJECT 2: VIDEO GAME RATINGS\n### Import Statements","5afeb841":"notebook developed in JUNO for ios. copied to kaggle","a8f5d560":"### Gridsearch here\nseparate search for poly\/sigmoid b\/c of coef0?\n## SVC() Is the algorithm im most familiar with and performed as well as the random forest algorithm.   selecting this to perform gridsearch and make submission","373be538":"## Cross validation Scores distributions here","49b4268d":"# Test data processing here","0abc54ab":"### Importing Data","933cb73d":"## ESRB website has 8 major categories, containing all these sub-categories\nhttps:\/\/www.esrb.org\/ratings-guide\/\nthese may be useful for reducing colinear features","2053b785":"## Model Building\n- logistic regression: use either lbgfs or liblinear, maybe newton?\n- lbfgs may perform the best, but if convergence issue maybe try newton\n    - works with softmax\n    - only uses l2 regularization\n- liblinear works well with high dimensionality \n    - can get stuck, only works with one vs rest logistic regression \n- verbosity param enables printing debug statements, much slower\n\nmany routes to explore with dimensionality reduction in classification and visualization, but first get basic pipelines runing ","aff43ea9":"### What does feature 'no_descriptors' mean? \ncould imply null value indicator, however training examples which have this field as '1' also have other features sometimes as well.","87284c46":"## bar graphs show no outliers, some descriptors appear more often than others. data values can only be zero or 1...","01bc82a0":"# TO DO: MAKE CORRELATIONS, POSSIBLE FEATURE ENGINEERING\n   ### **GET THE PIPELINE DONE AND GET YPREDICT OUTPUT TOMORROW, 10\/19**","213ab609":"# PROJECT 2: VIDEO GAME RATINGS\n### Import Statements","b7c61927":"### Data exploration\nCounting up totals of each feature, and comparing console vs pc "}}