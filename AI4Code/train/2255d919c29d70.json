{"cell_type":{"7b676190":"code","7cec07d5":"code","89c5c931":"code","37a7dc13":"code","e7fec90b":"code","6e8ed7c2":"code","16e85d6a":"code","25294919":"markdown","a1838bca":"markdown","9acb22bd":"markdown","c130e8b2":"markdown","dfed5a3f":"markdown","be117f93":"markdown"},"source":{"7b676190":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import RandomizedSearchCV\nimport lightgbm\nimport matplotlib.pyplot as plt","7cec07d5":"train = pd.read_csv(\"..\/input\/learn-together\/train.csv\")\ntest = pd.read_csv(\"..\/input\/learn-together\/test.csv\")\n\ntrain = train.drop([\"Id\"], axis = 1)\n\ntest_ids = test[\"Id\"]\ntest = test.drop([\"Id\"], axis = 1)","89c5c931":"from sklearn.ensemble import RandomForestClassifier\n\ndef random_RF(X,y,n_iter):\n    # Number of trees in random forest\n    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n    # Number of features to consider at every split\n    max_features = ['auto', 'sqrt']\n    # Maximum number of levels in tree\n    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n    max_depth.append(None)\n    # Minimum number of samples required to split a node\n    min_samples_split = [2, 5, 10]\n    # Minimum number of samples required at each leaf node\n    min_samples_leaf = [1, 2, 4]\n    # Method of selecting samples for training each tree\n    bootstrap = [True, False]\n    # Create the random grid\n    random_grid = {'n_estimators': n_estimators,\n                   'max_features': max_features,\n                   'max_depth': max_depth,\n                   'min_samples_split': min_samples_split,\n                   'min_samples_leaf': min_samples_leaf,\n                   'bootstrap': bootstrap}\n\n    rfc = RandomForestClassifier(n_jobs=-1)\n    rf_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = n_iter, cv = 5, verbose=1, random_state=111, n_jobs = -1, scoring = {'NLL':'neg_log_loss', 'Accuracy':'accuracy'}, refit='NLL')\n\n    # Fit the random search model\n    rf_random.fit(X, y)\n    return rf_random.best_estimator_, rf_random.cv_results_, rf_random.best_params_","37a7dc13":"n_iter=10 #iters for random search\nX,y=train.drop(['Cover_Type'], axis=1), train['Cover_Type']\nm,s = X.mean(0), X.std(0)\ns[s==0]=1\nX = (X-m)\/s\ntrained_model, results, params=random_RF(X,y,n_iter=n_iter)\nimport pickle\nwith open('params.pickle', 'wb') as handle:\n    pickle.dump(params, handle)","e7fec90b":"plt.figure(figsize=(13, 13))\nplt.title(\"RandomSearchCV evaluating using multiple scorers simultaneously\",\n          fontsize=16)\n\nplt.xlabel(\"iters\")\nplt.ylabel(\"Score\")\n\nax = plt.gca()\n#ax.set_xlim(0, 402)\nax.set_ylim(0.5, 0.85)\n\n# Get the regular numpy array from the MaskedArray\nX_axis = np.arange(0,n_iter)\n\nscoring={'NLL':'neg_log_loss', 'Accuracy':'accuracy'}\nfor scorer, color in zip(sorted(scoring, reverse=True), ['g', 'k']):\n    sample = 'test'\n    if scorer == 'NLL':\n        sample_score_mean = -1 * results['mean_%s_%s' % (sample, scorer)]\n    else:\n        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n    sample_score_std = results['std_%s_%s' % (sample, scorer)]\n    ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n                    sample_score_mean + sample_score_std,\n                    alpha=0.1 if sample == 'test' else 0, color=color)\n    ax.plot(X_axis, sample_score_mean,  color=color,\n            alpha=0.4,\n            label=\"%s (%s)\" % (scorer, sample))\n    \n    if scorer=='NLL':\n        best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n        best_score = -1*results['mean_test_%s' % scorer][best_index]\n    if scorer=='Accuracy':\n        best_score = results['mean_test_%s' % scorer][best_index]\n        \n        \n\n    # Plot a dotted vertical line at the best score for that scorer marked by x\n    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n\n    # Annotate the best score for that scorer\n    if scorer==\"NLL\":\n        ax.annotate(\"%0.2f\" % best_score,\n                   (X_axis[best_index]+0.05, best_score + 0.005))\n    else:\n        ax.annotate(\"%0.2f\" % best_score,\n                    (X_axis[best_index]+0.05, best_score - 0.01))\n\nplt.legend(loc=\"best\")\nplt.grid(False)\nplt.show()","6e8ed7c2":"test = (test - m)\/s\ntest_pred = trained_model.predict(test)","16e85d6a":"# Save test predictions to file\noutput = pd.DataFrame({'Id': test_ids,\n                       'Cover_Type': test_pred})\noutput.to_csv('rf_submission.csv', index=False)","25294919":"# Load data","a1838bca":"# Results of Cross-Validation","9acb22bd":"This a notebook where Random Forest is used as it is getting best results in this competition. This time instead of looking for its parameter in a Grid we will define a bigger space where randomly we will trying different parameters (with only 10 tries we will find optimal values, thanks probability theory!). We obtain a neg log loss of 0.54 and a accuracy of 0.8. In leader I placed in a good position with 0.77198 of accuracy. \n\nPlease look at the notebook for further information, vote up if it was of help for you and if you have any question please ask me.","c130e8b2":"# Predictions and submission","dfed5a3f":"We choose the NLL metric because it returns how sure is the estimator about predictions. It is a loss function so the less the better. We choose the minimal value and see which is the accuracy associated. Of course, this accuracy is the best in the CV.","be117f93":"# Random Forest"}}