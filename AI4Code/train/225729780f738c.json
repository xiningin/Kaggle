{"cell_type":{"c0116283":"code","2a2f6de7":"code","e7c1b2d7":"code","f897acd1":"code","635b252f":"code","069eff21":"code","ef5d6d96":"code","99183b78":"code","c6747ad2":"code","508b6472":"code","2070edae":"code","c44801d9":"code","6b062433":"code","d97f140f":"code","11f65669":"code","0b42698b":"code","98ed567d":"code","0f04c395":"code","6d6e1387":"code","4796649f":"code","afb127e9":"code","375e142d":"code","a0e14f82":"code","8ebb59fa":"code","05633683":"code","2c141696":"code","3286636b":"code","e170966b":"code","80b6b998":"code","dbfb0a45":"code","1e9e23e1":"code","724e6953":"code","db4b340a":"code","f87ad90a":"code","1c77715b":"code","6459ccc7":"code","41b0b953":"code","3f3ba149":"code","fadd30f2":"markdown","490b3911":"markdown","cf6c9e6d":"markdown","834fc245":"markdown","36af3b7f":"markdown","4d4a7c1d":"markdown","9bad88d6":"markdown","6f48a183":"markdown","0674b143":"markdown","e0fea30e":"markdown","c96bbbf5":"markdown","e49331f8":"markdown","7c6c3734":"markdown","c6e7abcb":"markdown","7e5b75bd":"markdown","1082a114":"markdown","1fa4909c":"markdown","317d40e9":"markdown","d6156aca":"markdown","db07b577":"markdown","90dab146":"markdown","8aa78074":"markdown","be13191e":"markdown","062657f8":"markdown","f6d35499":"markdown","adf2aa4e":"markdown","e54847f4":"markdown","a37af7f7":"markdown","68c2eed0":"markdown","7b7feb42":"markdown","4046388b":"markdown","7678b861":"markdown","24147917":"markdown","445fec78":"markdown"},"source":{"c0116283":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n","2a2f6de7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings","e7c1b2d7":"df=pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","f897acd1":"df.head()","635b252f":"df.describe().T","069eff21":"df.isnull().sum()\/len(df)","ef5d6d96":"corr=df.corr()\nsns.heatmap(corr)","99183b78":"df[\"Class\"].head()","c6747ad2":"df[\"Class\"].value_counts()","508b6472":"sns.countplot(df.Class)","2070edae":"fraud=df.loc[df[\"Class\"]==1]\n\nfraud","c44801d9":"i=0\nfraud=df.iloc[0:1,:]\n\nwhile i<284807:\n    \n    if df.Class[i]==1:\n        fraud=pd.concat([fraud,df.iloc[i:i+1,:]],axis=0)\n        \n    i+=1\n    \nfraud=fraud.iloc[1:,:]\n","6b062433":"not_fraud=df.loc[df[\"Class\"]==0]\nnot_fraud","d97f140f":"fraud[\"Amount\"].value_counts(1)","11f65669":"not_fraud[\"Amount\"].value_counts(1)","0b42698b":"sns.distplot(fraud.Time)","98ed567d":"sns.distplot(not_fraud.Time)","0f04c395":"fraud.describe()","6d6e1387":"not_fraud.describe()","4796649f":"yeni_not_fraud=not_fraud.iloc[0:1,:]\nyeni_not_fraud","afb127e9":"import random","375e142d":"while len(yeni_not_fraud)<492:\n    \n    i=random.randrange(0,284315)\n    yeni_not_fraud=pd.concat([not_fraud.iloc[i:i+1,:],yeni_not_fraud],axis=0)\n    ","a0e14f82":"yeni_not_fraud","8ebb59fa":"yeni_df=pd.concat([fraud,yeni_not_fraud],axis=0)\nyeni_df","05633683":"corr_yeni=yeni_df.corr()\nsns.heatmap(corr_yeni)","2c141696":"sns.heatmap(corr)","3286636b":"from sklearn.preprocessing import StandardScaler, RobustScaler\n\nstd_scaler = StandardScaler()\nrob_scaler = RobustScaler()\n\nyeni_df['scaled_amount'] = rob_scaler.fit_transform(yeni_df['Amount'].values.reshape(-1,1))\nyeni_df['scaled_time'] = rob_scaler.fit_transform(yeni_df['Time'].values.reshape(-1,1))\n\nyeni_df.drop(['Time','Amount'], axis=1, inplace=True)\n\n\n\nscaled_amount = yeni_df['scaled_amount']\nscaled_time = yeni_df['scaled_time']\n\nyeni_df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\nyeni_df.insert(0, 'scaled_amount', scaled_amount)\nyeni_df.insert(1, 'scaled_time', scaled_time)\n","e170966b":"yeni_df","80b6b998":"x=yeni_df.iloc[:,0:30]\ny=yeni_df.iloc[:,30:31]","dbfb0a45":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=42)","1e9e23e1":"from sklearn.ensemble import RandomForestClassifier\n\nrf=RandomForestClassifier()\nrf.fit(x_train,y_train)\nrf_tahmin=rf.predict(x_test)","724e6953":"from xgboost import XGBClassifier\n\nxgb=XGBClassifier()\nxgb.fit(x_train,y_train)\nxgb_tahmin=xgb.predict(x_test)\n","db4b340a":"from lightgbm import LGBMClassifier\n\nlgb=LGBMClassifier()\nlgb.fit(x_train,y_train)\nlgb_tahmin=lgb.predict(x_test)","f87ad90a":"from sklearn.metrics import accuracy_score, confusion_matrix\n\nprint(accuracy_score(y_test,rf_tahmin),accuracy_score(y_test,xgb_tahmin),accuracy_score(y_test,lgb_tahmin))","1c77715b":"X=df.iloc[:,0:30]\nY=df.iloc[:,30:31]","6459ccc7":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.33,random_state=34)","41b0b953":"rf2=RandomForestClassifier()\nrf2.fit(X_train,Y_train)\nrf2_tahmin=rf2.predict(X_test)\naccuracy_score(Y_test,rf2_tahmin)","3f3ba149":"print(\"Te\u015fekk\u00fcrler !\")","fadd30f2":"\u015eimi hem eski hemde yeni datam\u0131zdaki kolerasyonlara bakal\u0131m.","490b3911":"\u015eimdi Time(Zaman) de\u011fi\u015fkenine bakal\u0131m acaba iki data aras\u0131nda zaman olarak farkl\u0131l\u0131k \u00e7\u0131kacak m\u0131?","cf6c9e6d":"Bir \u00e7ok de\u011fi\u015fken aras\u0131ndaki kolerasyon neredeyse 0 gibi g\u00f6z\u00fck\u00fcyor.","834fc245":"Yeni datam\u0131zda bulunan Time ve Amount de\u011fi\u015fkenlerini standartla\u015ft\u0131r\u0131p data haz\u0131rl\u0131\u011f\u0131n\u0131 bitirelim.","36af3b7f":"Art\u0131k 492 tane fraud olmayan dataya sahibiz \u015fimdi fraud ve fraud olmayan datalar\u0131 birle\u015ftirelim.","4d4a7c1d":"Gelen sonu\u00e7larda;\n\nRandom Forest --> %94\nXGB --> %93\nLGB --> %92 \n\n\u00dc\u00e7\u00fcn\u00fcn ortalamas\u0131 --> %93\n\nTahminlerini verdi.\n\n\nE\u011fer t\u00fcm data ile \u00e7al\u0131rsak ne olacakt\u0131?","9bad88d6":"Eyl\u00fcl 2013 y\u0131l\u0131nda avrupa da credi kart\u0131 ile yap\u0131lan al\u0131\u015fveri\u015flerden olu\u015fan bir data setidir. Burada ki amac\u0131m\u0131z yap\u0131lan al\u0131\u015fveri\u015flerden fraud (sahtekarl\u0131k) olanlar\u0131 tespit etmek fakat data da bulunan fraud say\u0131s\u0131 olduk\u00e7a dengesiz bir bi\u00e7imdedir, datan\u0131n sadece %0.17'sini olu\u015fturmaktad\u0131r. Bunun d\u0131\u015f\u0131nda data da verilen de\u011fi\u015fkenlerin isimleri gizililik nedeniyle sans\u00fcrlenmi\u015f V1, V2 vs gibi ve Time ile Amount harici t\u00fcm de\u011ferler pca olarak verilmi\u015ftir. ","6f48a183":"Bu problemi ortadan kald\u0131rmak i\u00e7in \u015f\u00f6yle bir yol izlemeyi d\u00fc\u015f\u00fcn\u00fcyorum. Bana verilen data 284807 sat\u0131rl\u0131k bir data ve benim fraud olan data say\u0131m 492 o zaman ben datam\u0131n b\u00fcy\u00fck bir k\u0131sm\u0131n\u0131 silerek ikiye ay\u0131rabilirm. 492 tane fraud datas\u0131 ve 492 tane fraud olmayan data. Toplamda 984 sat\u0131l\u0131k data! Art\u0131k kendimiz gelen her \u00f6rne\u011fe 0 desek sadece %50 do\u011frulu\u011fa ula\u015fabiliriz yani overfit durumundan biraz kurtulduk demektir ve art\u0131k Time, Amount gibi de\u011fi\u015fkenlerden data daha \u00e7ok anlam \u00e7\u0131karacak ayn\u0131 zamanda fraud olan datan\u0131n istatistiki de\u011ferlerinin fraud olmayan dataya g\u00f6re daha y\u00fcksek \u00e7\u0131kma sonucundan da daha fazla anlam \u00e7\u0131karabilecek.","0674b143":"**Yeni Data**","e0fea30e":"Art\u0131k verimizi ba\u011f\u0131ml\u0131 ve ba\u011f\u0131ms\u0131z de\u011fi\u015fken diye b\u00f6l\u00fcp modellemeye ge\u00e7ebiliriz.","c96bbbf5":"Data daki en b\u00fcy\u00fck problem hedef de\u011fi\u015fkenimiz olan Class'\u0131n de\u011ferlerinin d\u00fczensiz bir \u015fekilde da\u011f\u0131lmas\u0131. En ba\u015fta dedi\u011fimiz gibi fraud'a konu olanlar\u0131n t\u00fcm\u00fc %0.17'lik bir orana sahip. E\u011fer biz elimizdeki t\u00fcm datay\u0131 kullanarak bir model olu\u015ftursak ve bu modeli herhangi bir algoritma ile kursak bile \u00e7ok y\u00fcksek bir do\u011fruluk oran\u0131na sahip olaca\u011f\u0131z fakat bu do\u011fru \u00e7al\u0131\u015fan bir modeli mi bize g\u00f6sterecek? Asl\u0131nda hay\u0131r bu bir overfit problemine yol a\u00e7acak \u00e7\u00fcnk\u00fc ister random forest ister Xgboost ister Lojistik Regresyon modeli kural\u0131m herbir model ger\u00e7ek 1 de\u011ferlerini asl\u0131nda g\u00f6remeyecek. Daha basit bir ifadeyle \u015f\u00f6yle d\u00fc\u015f\u00fcnelim, zaten datam\u0131z\u0131n %99'u 0 o zaman bu modellerin hi\u00e7birini kullanmasak sadece kendimiz cevaplasak nas\u0131l bir yol izleriz? En basit yolu \u00f6n\u00fcm\u00fcze gelen her \u00f6rne\u011fe 0 demek olur ve bu sayede %99 ba\u015far\u0131ya ula\u015f\u0131r\u0131z ama asla ger\u00e7ek bir fraud'u yani as\u0131l konumuzu do\u011fru bilemeyiz. Fraud datalar\u0131 overfit i\u00e7in \u00e7ok g\u00fczel \u00f6rnekler.","e49331f8":"Hedef de\u011fi\u015fkenimiz olan Class 0 ve 1'lerden olu\u015fuyor. 0 fraud olmad\u0131\u011f\u0131n\u0131 1 ise fraud oldu\u011fu g\u00f6steriyor. Fraud olan \u00f6rnekler veri de olduk\u00e7a da\u011f\u0131n\u0131k durumda bulunuyor ve \u00e7ok az bir k\u0131sm\u0131n\u0131 olu\u015fturuyor.\n\nBunun i\u00e7in \u00f6nce veride ne kadar fraud i\u015flemi oldu\u011funu ard\u0131ndan da bu fraud olan sat\u0131rlardan ayr\u0131 bir data frame olu\u015fturarak sadece fraud olan datalar\u0131 incelemeye \u00e7al\u0131\u015fal\u0131m.","7c6c3734":"\u0130lk farkl\u0131l\u0131k fraud olan data da 1 de\u011feri daha s\u0131k kar\u015f\u0131m\u0131za \u00e7\u0131k\u0131yor bunun yan\u0131nda 0 ve 99.99 de\u011ferleri de fraud olan data da daha s\u0131k.","c6e7abcb":"Merhaba, bu \u00e7al\u0131\u015fma sayfas\u0131nda CredictCard datas\u0131 ile ilgili yeni bir \u00e7\u00f6z\u00fcm \u00f6rne\u011fini payla\u015f\u0131yorum.\nKonu hakk\u0131ndaki yorumlar\u0131n\u0131z benim i\u00e7in \u00f6nemlidir.\n\nBaz\u0131 k\u0131s\u0131mlar da g\u00f6r\u00fc\u015f eksikli\u011fi veya dolayl\u0131 yoldan gidilmi\u015f olabilir yeni olan t\u00fcm \u00f6nerilere a\u00e7\u0131\u011f\u0131m umar\u0131m bu \u00f6rnek \u00e7al\u0131\u015fma sizin i\u00e7in faydal\u0131 olur.","7e5b75bd":"Art\u0131k fraud 1 olanlar fraud ad\u0131nda yeni bir data frame de topland\u0131 ayn\u0131 i\u015flem a\u015fa\u011f\u0131daki y\u00f6ntem ile de yap\u0131labilir ama daha zahmetli oldu\u011fu kesindir.","1082a114":"**Credict Card Fraud \u00c7al\u0131\u015fma \u00d6rne\u011fi**","1fa4909c":"**Veriye \u0130lk Bak\u0131\u015f ve Giri\u015f K\u00fct\u00fcphanelerinin Y\u00fcklenmesi**","317d40e9":"Umar\u0131m bu \u00e7al\u0131\u015fma sizin i\u00e7in faydal\u0131 olmu\u015ftur.\n\nTekrar g\u00f6r\u00fc\u015fmek \u00fczere.\n\nAlper Temel.","d6156aca":"\u0130lk bak\u0131\u015fta sanki fraud olan datan\u0131\u0131n de\u011ferleri daha y\u00fcksek gibi g\u00f6z\u00fck\u00fcyor. \u015eimdi bu iki datay\u0131 birle\u015ftirerek tek bir data olu\u015ftural\u0131m ve analize b\u00f6yle devam edelim. Birle\u015ftirmenin bu data \u00f6rne\u011finde \u00e7\u00f6z\u00fcm i\u00e7in as\u0131l konu oldu\u011funu d\u00fc\u015f\u00fcn\u00fcyorum.","db07b577":"G\u00f6r\u00fcld\u00fc\u011f\u00fc gibi 1'ler neredeyse yok gibi. Class'\u0131n bir oldu\u011fu sat\u0131larlar\u0131 alal\u0131m.","90dab146":"\u015eimdi fraud 0 olanlara bakal\u0131m. Burada \u015fimdilik fraud 0 olan t\u00fcm de\u011ferleri almak istiyorum. T\u00fcm fraud 1'ler t\u00fcm fraud 0'lar aras\u0131nda benzerlik ve \u00f6zellikle farkl\u0131l\u0131klar neler g\u00f6rmek i\u015fimize yarayabilir.\n\nBunun i\u00e7in \u00f6nce t\u00fcm fraud 0 olanlar\u0131 da alal\u0131m.","8aa78074":"Fraud olmayan datalar\u0131 \u00f6nceden ay\u0131rm\u0131\u015ft\u0131k \u015fimdi bunlar\u0131n aras\u0131ndan rastgele 492 tane se\u00e7elim.","be13191e":"Overfit durumunda do\u011fru tahmin %999 \u00e7\u0131k\u0131yor.","062657f8":"**Sonu\u00e7lar**","f6d35499":"Veride bo\u015f bilgilerin olup olmad\u0131\u011f\u0131n\u0131 sorgulama","adf2aa4e":"Asl\u0131dan iki data birbirinden baz\u0131 farkl\u0131l\u0131klar\u0131 var bunu birde istatistik de\u011ferleri \u00fczerinden bakal\u0131m.","e54847f4":"Zaman olarak da aralar\u0131nda fark oldu\u011fu g\u00f6z\u00fck\u00fcyor.","a37af7f7":"**Modelleme**","68c2eed0":"Train ve Test setlerimizide olu\u015fturduk bu data i\u00e7in Random Forest, XGBoost ve LightGBoost algoritmalar\u0131n\u0131 kullanaca\u011f\u0131m.","7b7feb42":"**Nas\u0131l Birle\u015ftirmeli**","4046388b":"De\u011fi\u015fkenler aras\u0131ndaki kolerasyonlar\u0131 g\u00f6rmek","7678b861":"Veride ki hedef de\u011fi\u015fkene bakma","24147917":"**Data Hakk\u0131nda Genel Bilgi**","445fec78":"Fraud olan ve fraud olmayan data i\u00e7inde Amount de\u011ferlerinin neler oldu\u011funu bu de\u011ferlerin ka\u00e7 defa tekrar etti\u011fine bakal\u0131m"}}