{"cell_type":{"61e38185":"code","9db0afe8":"code","f5909b75":"code","96d2bdfa":"code","2fdec0dd":"code","159e8589":"code","fb862f79":"code","d94cc037":"code","a2062277":"code","53b317ed":"code","40b8b196":"code","d543da21":"code","d7d53a71":"code","a1fddfac":"code","44041f3c":"code","dd983ee9":"code","e73fd3b8":"code","72f19e38":"code","68b3547e":"code","f51fe30a":"code","b581d635":"code","5b69e669":"code","b93f1d75":"code","43ef7e86":"code","f8d88ec4":"code","7e71ec48":"code","3ee77d6a":"code","45d71857":"code","35d57da7":"code","0c407906":"code","93c429e8":"code","f463247e":"code","897f956a":"code","9e25cdb6":"code","f34f7c75":"code","803e9704":"code","4ad9f7dd":"code","7b079e1d":"code","9968c7d7":"code","d337d63c":"code","ec0f919f":"code","e89da5f6":"code","aa8636c5":"code","c18356ad":"code","e4f50526":"code","41d344f5":"code","348dd738":"code","7cb70ba8":"code","f800ed37":"code","b3d04310":"code","f68c75e0":"code","13bba406":"code","38887a71":"code","f8e0ebd3":"code","c330a6be":"code","96694738":"code","e192825e":"code","fb9df31a":"code","5f9b311e":"code","901a6af5":"markdown"},"source":{"61e38185":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9db0afe8":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","f5909b75":"train.describe()\n\ntest.shape\ntrain.shape","96d2bdfa":"a = train.isnull().sum()\/train.shape[0]*100","2fdec0dd":"columns_in_sum = a.index","159e8589":"columns_to_remove = []\nfor i in columns_in_sum:\n    if a[i]>15:\n        columns_to_remove.append(i)","fb862f79":"columns_to_remove","d94cc037":"b = test.isnull().sum()\/train.shape[0]*100\ntest_column_to_remove = []\nfor i in b.index:\n    if b[i] > 15:\n        test_column_to_remove.append(i)\ntest_column_to_remove","a2062277":"train_test_data = [train,test]","53b317ed":"train_after_drop = train.copy()\ntest_after_drop = test.copy()","40b8b196":"train_after_drop = train_after_drop.drop(columns_to_remove,axis=1)\ntest_after_drop = test_after_drop.drop(test_column_to_remove,axis=1)","d543da21":"train_after_drop.info()","d7d53a71":"train_after_drop.shape","a1fddfac":"test_after_drop.shape","44041f3c":"train_after_drop.describe().columns","dd983ee9":"train_after_drop.describe(include='all').columns","e73fd3b8":"train_after_drop.describe(include='all').columns","72f19e38":"all_columns = train_after_drop.describe(include='all').columns","68b3547e":"numeric_columns = train_after_drop.describe().columns\nnumeric_columns","f51fe30a":"cat_columns = []\nfor i in all_columns:\n    if i not in numeric_columns:\n        cat_columns.append(i)\ncat_columns","b581d635":"for i in cat_columns:\n    print(i,'::', train[i].unique())","5b69e669":"train_after_drop[cat_columns].isnull().sum()","b93f1d75":"test_after_drop[cat_columns].isnull().sum()","43ef7e86":"## filling missing data for categorical variables:","f8d88ec4":"for i in cat_columns:\n    train_after_drop[i] = train_after_drop[i].fillna(train_after_drop[i].mode()[0])","7e71ec48":"train_after_drop[cat_columns].isnull().sum()","3ee77d6a":"for i in cat_columns:\n    test_after_drop[i] = test_after_drop[i].fillna(test_after_drop[i].mode()[0])","45d71857":"test_after_drop[cat_columns].isnull().sum()","35d57da7":"numeric_columns","0c407906":"train_after_drop[numeric_columns].isnull().sum()","93c429e8":"for i in numeric_columns:\n    train_after_drop[i] = train_after_drop[i].fillna(train_after_drop[i].mean())\ntrain_after_drop[numeric_columns].isnull().sum()","f463247e":"for i in numeric_columns[:-1]:\n    test_after_drop[i] = test_after_drop[i].fillna(test_after_drop[i].mean())\ntest_after_drop[numeric_columns[:-1]].isnull().sum()","897f956a":"test_after_drop.info()","9e25cdb6":"train_after_drop.info()","f34f7c75":"train_filledna = train_after_drop.copy()\ntest_filledna = test_after_drop.copy()","803e9704":"train_filledna['train'] = 1\ntest_filledna['train'] = 0","4ad9f7dd":"final_df = pd.concat([train_filledna,test_filledna],axis=0)\nfinal_df.head()\nfinal_df","7b079e1d":"## functions by krish naik,\ndef category_onehot_multcols(multcolumns):\n    df_final=final_df\n    i=0\n    for fields in multcolumns:\n        \n        print(fields)\n        df1=pd.get_dummies(final_df[fields],drop_first=True)\n        \n        final_df.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:\n            \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n       \n        \n    df_final=pd.concat([final_df,df_final],axis=1)\n        \n    return df_final","9968c7d7":"final_df = category_onehot_multcols(cat_columns)","d337d63c":"final_df.shape","ec0f919f":"final_df.head()","e89da5f6":"final_df.drop(['Id'],axis=1,inplace=True)\nfinal_df.head()","aa8636c5":"final_df =final_df.loc[:,~final_df.columns.duplicated()]\nfinal_df.shape","c18356ad":"df_train = final_df[final_df['train'] == 1]\ndf_train","e4f50526":"df_test = final_df[final_df['train'] == 0]\ndf_test","41d344f5":"df_train.drop(['train'],axis=1,inplace=True)\ndf_test.drop(['train'],axis=1,inplace=True)\ndf_train.shape","348dd738":"df_test.drop(['SalePrice'],axis=1,inplace=True)\ndf_test.shape","7cb70ba8":"y_train=df_train['SalePrice']\nX_train=df_train.drop(['SalePrice'],axis=1)","f800ed37":"import xgboost\nclassifier=xgboost.XGBRegressor()\n\nclassifier.fit(X_train,y_train)","b3d04310":"train_prediction =classifier.predict(X_train)\ntrain_prediction","f68c75e0":"import matplotlib.pyplot as plt\nplt.scatter(train_prediction, y_train)\nplt.show()","13bba406":"from sklearn.metrics import accuracy_score","38887a71":"y_train","f8e0ebd3":"predictions = [round(value) for value in train_prediction]\npredictions","c330a6be":"test_prediction =classifier.predict(df_test)\ntest_prediction","96694738":"submission = pd.DataFrame({\n        \"Id\": test[\"Id\"],\n        \"SalePrice\": test_prediction\n    })","e192825e":"submission","fb9df31a":"submission.to_csv('submission.csv', index=False)","5f9b311e":"submission = pd.read_csv('submission.csv')\nsubmission.head()","901a6af5":"# Training models and checking accuracy"}}