{"cell_type":{"7eee6ce5":"code","440a55a5":"code","229e4260":"code","c727d3e3":"code","597a5347":"code","ca42870f":"code","ef4d2cb5":"code","b80d6410":"code","3725fb4d":"code","a32c46bc":"code","a5664d03":"code","855f7b01":"code","f122e0e6":"code","d6c3e8eb":"code","71368b03":"code","d3882536":"code","07fc62fb":"code","29253f8c":"markdown","950a94b4":"markdown","740c348b":"markdown","7b9ac688":"markdown","6779f1c1":"markdown","a72d1e4e":"markdown","c1df490a":"markdown","340f6399":"markdown","a6e7a8cc":"markdown","4cb70cdc":"markdown","1a87023b":"markdown","1dbc9d2c":"markdown","10cc1744":"markdown","71d6204c":"markdown","3df9a0fe":"markdown","44d09655":"markdown","b0d0cbc3":"markdown","69293d6c":"markdown","a60c1286":"markdown","d43215bd":"markdown","c3cdfec9":"markdown","3c021671":"markdown","b3f262a3":"markdown","29fcb475":"markdown","f13c0a2b":"markdown","d6c95efa":"markdown","460e7b34":"markdown","cee7b1e1":"markdown","6acf13e4":"markdown","90c0a324":"markdown","564cfe69":"markdown","61099ead":"markdown","0c01831f":"markdown","0fc760c3":"markdown"},"source":{"7eee6ce5":"import os\nimport numpy as np \nimport pandas as pd \nimport plotly.express as px\nimport seaborn as sns\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nimport plotly.offline as pyo\npyo.init_notebook_mode()\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","440a55a5":"import plotly.express as px\nfig = px.choropleth(locations=[\"BGD\"], locationmode = \"ISO-3\", color_continuous_scale=\"Plasma\")\nfig.show()","229e4260":"#reading data in pandas dataframe\ndf_survey_20 = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\", low_memory=False)\ndf_survey_19 = pd.read_csv(\"..\/input\/kagglesurvey2019\/kaggle-survey-2019\/multiple_choice_responses.csv\", low_memory=False)\ndf_survey_18 = pd.read_csv(\"..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv\", low_memory=False)\ndf_survey_17 = pd.read_csv(\"..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv\", low_memory=False, encoding='ISO-8859-1')","c727d3e3":"df_survey_17.Country.unique()","597a5347":"count_df_list = []\ndf_bd_20 = df_survey_20.loc[df_survey_20[\"Q3\"] == \"Bangladesh\"]\ndf_bd_20_row, col = df_bd_20.shape\ncount_df_list.append(df_bd_20_row)\ndf_bd_19 = df_survey_19.loc[df_survey_19[\"Q3\"] == \"Bangladesh\"]\ndf_bd_19_row, col = df_bd_19.shape\ncount_df_list.append(df_bd_19_row)\ndf_bd_18 = df_survey_18.loc[df_survey_18[\"Q3\"] == \"Bangladesh\"]\ndf_bd_18_row, col = df_bd_18.shape\ncount_df_list.append(df_bd_18_row)\nyears_ = [\"2020\", \"2019\", \"2018\"]\n\ndata = [go.Bar(\n   x = years_,\n   y = count_df_list\n)]\nfig = go.Figure(data=data)\nfig.update_layout(title_text='Survey Participant over the year', width=500, title_x=0.5)","ca42870f":"#age distribution\ndf_age_20 = df_bd_20.groupby(\"Q1\").count().Q2\ndf_age_19 = df_bd_19.groupby(\"Q1\").count().Q2\ndf_age_18 = df_bd_18.groupby(\"Q2\").count().Q1\n\nfig = make_subplots(rows = 1, cols = 3,\n                   specs = [[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n                   subplot_titles=('2020', '2019', '2018'))\n\nfig.add_trace(go.Bar(x=df_age_20.index, y=df_age_20.values,name='2020'),row=1, col=1)\nfig.add_trace(go.Bar(x=df_age_19.index, y=df_age_19.values,name='2019'),row=1, col=2)\nfig.add_trace(go.Bar(x=df_age_18.index, y=df_age_18.values,name='2018'),row=1, col=3)\n\nfig.update_layout(title_text='Age Group Distribution', title_x=0.5)","ef4d2cb5":"#gender distribution\ngen_dist_20 = df_bd_20.Q2.iloc[1:].value_counts()\ngen_dist_19 = df_bd_19.Q2.iloc[1:].value_counts()\ngen_dist_18 = df_bd_18.Q1.iloc[1:].value_counts()\n#pic slice name filtering\nas_list = gen_dist_20.index.tolist()\nidx_man = as_list.index('Man')\nidx_woman = as_list.index('Woman')\nas_list[idx_man] = 'Male'\nas_list[idx_woman] = 'Female'\ngen_dist_20.index = as_list\n\nfig=make_subplots(rows=1,cols=3,\n                  specs=[[{\"type\": \"pie\"},{\"type\": \"pie\"},{\"type\": \"pie\"}]]\n                 ,subplot_titles=('2020','2019','2018'))\nfig.add_trace(go.Pie(labels=gen_dist_20.index[:2], values=gen_dist_20.values[:2], hole=0.2, name='2020', pull=[0,0.3]), row=1, col=1)\nfig.add_trace(go.Pie(labels=gen_dist_19.index[:2], values=gen_dist_19.values[:2], hole=0.2, name='2019', pull=[0,0.3]), row=1, col=2)\nfig.add_trace(go.Pie(labels=gen_dist_18.index[:2], values=gen_dist_18.values[:2], hole=0.2, name='2018', pull=[0,0.3]), row=1, col=3)\n\nfig.update_layout(title_text='Gender Distribution', title_x=0.5)","b80d6410":"# educational background\ndeg_dist_20=df_bd_20.Q4.iloc[1:].value_counts()\ndeg_dist_19=df_bd_19.Q4.iloc[1:].value_counts()\ndeg_dist_18=df_bd_18.Q4.iloc[1:].value_counts()\n\nas_list_20 = deg_dist_20.index.tolist()\nas_list_19 = deg_dist_19.index.tolist()\nas_list_18 = deg_dist_18.index.tolist()\nidx_20 = as_list_20.index(\"Some college\/university study without earning a bachelor\u2019s degree\")\nidx_19 = as_list_19.index(\"Some college\/university study without earning a bachelor\u2019s degree\")\nidx_18 = as_list_18.index(\"Some college\/university study without earning a bachelor\u2019s degree\")\nas_list_20[idx_20] = 'no bechelore degree'\nas_list_19[idx_19] = 'no bechelore degree'\nas_list_18[idx_18] = 'no bechelore degree'\ndeg_dist_20.index = as_list_20\ndeg_dist_19.index = as_list_19\ndeg_dist_18.index = as_list_18\n\nfig=make_subplots(rows=1,cols=3,\n                  specs=[[{\"type\": \"pie\"},{\"type\": \"pie\"},{\"type\": \"pie\"}]]\n                 ,subplot_titles=('2020','2019','2018'))\nfig.add_trace(go.Pie(labels=deg_dist_20.index[:4], values=deg_dist_20.values[:4], hole=0.2,name='2020', pull=[0,0.1]), row=1, col=1)\nfig.add_trace(go.Pie(labels=deg_dist_19.index[:4], values=deg_dist_19.values[:4], hole=0.2,name='2019', pull=[0,0.1]), row=1, col=2)\nfig.add_trace(go.Pie(labels=deg_dist_18.index[:4], values=deg_dist_18.values[:4], hole=0.2, name='2018', pull=[0,0.1]), row=1, col=3)\n\nfig.update_layout(title_text='Educational Background', title_x=0.5)","3725fb4d":"#most used language in day to day life\nval_count_20 ={\n    \"Python\": (df_bd_20[\"Q7_Part_1\"].value_counts().values[0]),\n    \"R\": (df_bd_20[\"Q7_Part_2\"].value_counts().values[0]),\n    \"SQL\": (df_bd_20[\"Q7_Part_3\"].value_counts().values[0]),\n    \"C\/C++\": (df_bd_20[\"Q7_Part_4\"].value_counts().values[0] + df_bd_20[\"Q7_Part_5\"].value_counts().values[0]),\n    \"Java\": (df_bd_20[\"Q7_Part_6\"].value_counts().values[0]),\n    \"JavaScript\": (df_bd_20[\"Q7_Part_7\"].value_counts().values[0]),\n    \"Bash\": (df_bd_20[\"Q7_Part_10\"].value_counts().values[0]),\n    \"Matlab\": (df_bd_20[\"Q7_Part_11\"].value_counts().values[0]),\n}\n\nval_count_19 ={\n    \"Python\": (df_bd_19[\"Q18_Part_1\"].value_counts().values[0]),\n    \"R\": (df_bd_19[\"Q18_Part_2\"].value_counts().values[0]),\n    \"SQL\": (df_bd_19[\"Q18_Part_3\"].value_counts().values[0]),\n    \"C\/C++\": (df_bd_19[\"Q18_Part_4\"].value_counts().values[0] + df_bd_20[\"Q18_Part_5\"].value_counts().values[0]),\n    \"Java\": (df_bd_19[\"Q18_Part_6\"].value_counts().values[0]),\n    \"JavaScript\": (df_bd_19[\"Q18_Part_7\"].value_counts().values[0]),\n    \"Bash\": (df_bd_19[\"Q18_Part_9\"].value_counts().values[0]),\n    \"Matlab\": (df_bd_19[\"Q18_Part_10\"].value_counts().values[0]),\n}\n\nval_count_18 ={\n    \"Python\": (df_bd_18[\"Q16_Part_1\"].value_counts().values[0]),\n    \"R\": (df_bd_18[\"Q16_Part_2\"].value_counts().values[0]),\n    \"SQL\": (df_bd_18[\"Q16_Part_3\"].value_counts().values[0]),\n    \"C\/C++\": (df_bd_18[\"Q16_Part_8\"].value_counts().values[0]),\n    \"Java\": (df_bd_18[\"Q16_Part_5\"].value_counts().values[0]),\n    \"JavaScript\": (df_bd_18[\"Q16_Part_6\"].value_counts().values[0]),\n    \"Bash\": (df_bd_18[\"Q16_Part_4\"].value_counts().values[0]),\n    \"Matlab\": (df_bd_18[\"Q16_Part_9\"].value_counts().values[0]),\n}\n\nlst_2018 = []\nlst_2019 = []\nlst_2020 = []\nlabel_keys = list(val_count_20.keys())\nfor i in range(len(label_keys)):\n    lst_2018.append(val_count_18[label_keys[i]])\n    lst_2019.append(val_count_19[label_keys[i]])\n    lst_2020.append(val_count_20[label_keys[i]])\ndata = {\n    \"dt_18\":lst_2018,\n    \"dt_19\": lst_2019,\n    \"dt_20\": lst_2020,\n    \"labels\": label_keys\n}\n\nfig = go.Figure(\n    data=[\n        go.Bar(\n            name=\"2020\",\n            x=data[\"labels\"],\n            y=data[\"dt_20\"],\n            offsetgroup=0,\n        ),\n        go.Bar(\n            name=\"2019\",\n            x=data[\"labels\"],\n            y=data[\"dt_19\"],\n            offsetgroup=1,\n        ),\n        \n        go.Bar(\n            name=\"2018\",\n            x=data[\"labels\"],\n            y=data[\"dt_18\"],\n            offsetgroup=2,\n        )\n    ],\n    layout=go.Layout(\n        title=\"Most used programming language in day to day life\",\n        yaxis_title=\"Number of Kaggler\",\n        title_x=0.5\n    )\n)\n\nfig.show()","a32c46bc":"#studying ML\nstudy_ml_20=df_bd_20.Q15.iloc[1:].value_counts()\nstudy_ml_19=df_bd_19.Q23.iloc[1:].value_counts()\nstudy_ml_18=df_bd_18.Q25.iloc[1:].value_counts()\n\nas_list_20 = study_ml_20.index.tolist()\nas_list_19 = study_ml_19.index.tolist()\nas_list_18 = study_ml_18.index.tolist()\nidx_20 = as_list_20.index('Under 1 year')\nidx_19 = as_list_19.index('< 1 years')\nidx_18 = as_list_18.index('I have never studied machine learning but plan to learn in the future')\nas_list_20[idx_20] = '< 1 year'\nas_list_19[idx_19] = '< 1 year'\nas_list_18[idx_18] = 'never studied ML'\nstudy_ml_20.index = as_list_20\nstudy_ml_19.index = as_list_19\nstudy_ml_18.index = as_list_18\n\nfig=make_subplots(rows=1,cols=3,\n                  specs=[[{\"type\": \"pie\"},{\"type\": \"pie\"},{\"type\": \"pie\"}]]\n                 ,subplot_titles=('2020','2019','2018'))\nfig.add_trace(go.Pie(labels=study_ml_20.index[:6], values=study_ml_20.values[:6], hole=0.1, name='2020', pull=[0,0.1]), row=1, col=1)\nfig.add_trace(go.Pie(labels=study_ml_19.index[:6], values=study_ml_19.values[:6], hole=0.1, name='2019', pull=[0,0.1]), row=1, col=2)\nfig.add_trace(go.Pie(labels=study_ml_18.index[:6], values=study_ml_18.values[:6], hole=0.1, name='2018', pull=[0,0.1]), row=1, col=3)\n\nfig.update_layout(title_text='How much time is invested to study ML', title_x=0.5)","a5664d03":"#importance of online courses\nval_count_20 ={\n    \"Coursera\": (df_bd_20[\"Q37_Part_1\"].value_counts().values[0]),\n    \"Edx\": (df_bd_20[\"Q37_Part_2\"].value_counts().values[0]),\n    \"Kaggle_Leam\": (df_bd_20[\"Q37_Part_3\"].value_counts().values[0]),\n    \"DataCamp\": (df_bd_20[\"Q37_Part_4\"].value_counts().values[0]),\n    \"Fastai\": (df_bd_20[\"Q37_Part_5\"].value_counts().values[0]),\n    \"Udacity\": (df_bd_20[\"Q37_Part_6\"].value_counts().values[0]),\n    \"Udemy\": (df_bd_20[\"Q37_Part_7\"].value_counts().values[0]),\n    \"Linkedin_learning\": (df_bd_20[\"Q37_Part_8\"].value_counts().values[0]),\n    \"From_university\": (df_bd_20[\"Q37_Part_10\"].value_counts().values[0])\n}\nval_count_19 ={\n    \"Coursera\": (df_bd_19[\"Q13_Part_2\"].value_counts().values[0]),\n    \"Edx\": (df_bd_19[\"Q13_Part_3\"].value_counts().values[0]),\n    \"Kaggle_Leam\": (df_bd_19[\"Q13_Part_6\"].value_counts().values[0]),\n    \"DataCamp\": (df_bd_19[\"Q13_Part_4\"].value_counts().values[0]),\n    \"Fastai\": (df_bd_19[\"Q13_Part_7\"].value_counts().values[0]),\n    \"Udacity\": (df_bd_19[\"Q13_Part_1\"].value_counts().values[0]),\n    \"Udemy\": (df_bd_19[\"Q13_Part_8\"].value_counts().values[0]),\n    \"Linkedin_learning\": (df_bd_19[\"Q13_Part_9\"].value_counts().values[0]),\n    \"From_university\": (df_bd_19[\"Q13_Part_10\"].value_counts().values[0]),\n}\nval_count_18 ={\n    \"Coursera\": (df_bd_18[\"Q36_Part_2\"].value_counts().values[0]),\n    \"Edx\": (df_bd_18[\"Q36_Part_3\"].value_counts().values[0]),\n    \"Kaggle_Leam\": (df_bd_18[\"Q36_Part_6\"].value_counts().values[0]),\n    \"DataCamp\": (df_bd_18[\"Q36_Part_4\"].value_counts().values[0]),\n    \"Fastai\": (df_bd_18[\"Q36_Part_7\"].value_counts().values[0]),\n    \"Udacity\": (df_bd_18[\"Q36_Part_1\"].value_counts().values[0]),\n    \"Udemy\": (df_bd_18[\"Q36_Part_9\"].value_counts().values[0]),\n    #No data given for Linkedin_learning\n    \"Linkedin_learning\": 0,\n    \"From_university\": (df_bd_18[\"Q36_Part_11\"].value_counts().values[0]),\n}\nlst_2018 = []\nlst_2019 = []\nlst_2020 = []\nlabel_keys = list(val_count_20.keys())\nfor i in range(len(label_keys)):\n    lst_2018.append(val_count_18[label_keys[i]])\n    lst_2019.append(val_count_19[label_keys[i]])\n    lst_2020.append(val_count_20[label_keys[i]])\ndata = {\n    \"dt_18\":lst_2018,\n    \"dt_19\": lst_2019,\n    \"dt_20\": lst_2020,\n    \"labels\": label_keys\n}\n\nfig = go.Figure(\n    data=[\n        go.Bar(\n            name=\"2020\",\n            x=data[\"labels\"],\n            y=data[\"dt_20\"],\n            offsetgroup=0,\n        ),\n        go.Bar(\n            name=\"2019\",\n            x=data[\"labels\"],\n            y=data[\"dt_19\"],\n            offsetgroup=1,\n        ),\n        go.Bar(\n            name=\"2018\",\n            x=data[\"labels\"],\n            y=data[\"dt_18\"],\n            offsetgroup=2,\n        )\n        \n    ],\n    layout=go.Layout(\n        title=\"Importance of online courses\",\n        yaxis_title=\"Number of Kaggler\",\n        title_x=0.5\n    )\n)\n\nfig.show()","855f7b01":"#which IDE is used mostly\nval_count_20 ={\n    \"Jupyter\": (df_bd_20[\"Q9_Part_1\"].value_counts().values[0]),\n    \"RStudio\": (df_bd_20[\"Q9_Part_2\"].value_counts().values[0]),\n    \"Pycharm\": (df_bd_20[\"Q9_Part_5\"].value_counts().values[0]),\n    \"MATLAB\": (df_bd_20[\"Q9_Part_10\"].value_counts().values[0]),\n    \"VS_Std+Code\": (df_bd_20[\"Q9_Part_3\"].value_counts().values[0]) +\n                    (df_bd_20[\"Q9_Part_4\"].value_counts().values[0]),\n    \"Spyder\": (df_bd_20[\"Q9_Part_6\"].value_counts().values[0]),\n    \"VIM\": (df_bd_20[\"Q9_Part_9\"].value_counts().values[0]),\n    \"Sublime\": (df_bd_20[\"Q9_Part_8\"].value_counts().values[0]),\n    \"Notepad++\": (df_bd_20[\"Q9_Part_7\"].value_counts().values[0]),\n}                   \nval_count_19 ={\n    \"Jupyter\": (df_bd_19[\"Q16_Part_1\"].value_counts().values[0]),\n    \"RStudio\": (df_bd_19[\"Q16_Part_2\"].value_counts().values[0]),\n    \"Pycharm\": (df_bd_19[\"Q16_Part_3\"].value_counts().values[0]),\n    \"MATLAB\": (df_bd_19[\"Q16_Part_5\"].value_counts().values[0]),\n    \"VS_Std+Code\": (df_bd_19[\"Q16_Part_6\"].value_counts().values[0]),\n    \"Spyder\": (df_bd_19[\"Q16_Part_7\"].value_counts().values[0]),\n    \"VIM\": (df_bd_19[\"Q16_Part_8\"].value_counts().values[0]),\n    \"Sublime\": (df_bd_19[\"Q16_Part_10\"].value_counts().values[0]),\n    \"Notepad++\": (df_bd_19[\"Q16_Part_9\"].value_counts().values[0]),\n}\nval_count_18 ={\n    \"Jupyter\": (df_bd_18[\"Q13_Part_1\"].value_counts().values[0]),\n    \"RStudio\": (df_bd_18[\"Q13_Part_2\"].value_counts().values[0]),\n    \"Pycharm\": (df_bd_18[\"Q13_Part_3\"].value_counts().values[0]),\n    \"MATLAB\": (df_bd_18[\"Q13_Part_7\"].value_counts().values[0]),\n    \"VS_Std+Code\": (df_bd_18[\"Q13_Part_4\"].value_counts().values[0]) + \n                (df_bd_18[\"Q13_Part_8\"].value_counts().values[0]),\n    \"Spyder\": (df_bd_18[\"Q13_Part_12\"].value_counts().values[0]),\n    \"VIM\": (df_bd_18[\"Q13_Part_11\"].value_counts().values[0]),\n    \"Sublime\": (df_bd_18[\"Q13_Part_10\"].value_counts().values[0]),\n    \"Notepad++\": (df_bd_18[\"Q13_Part_9\"].value_counts().values[0]),\n}\n\nlst_2018 = []\nlst_2019 = []\nlst_2020 = []\nlabel_keys = list(val_count_20.keys())\nfor i in range(len(label_keys)):\n    lst_2018.append(val_count_18[label_keys[i]])\n    lst_2019.append(val_count_19[label_keys[i]])\n    lst_2020.append(val_count_20[label_keys[i]])\ndata = {\n    \"dt_18\":lst_2018,\n    \"dt_19\": lst_2019,\n    \"dt_20\": lst_2020,\n    \"labels\": label_keys\n}\n\nfig = go.Figure(\n    data=[\n        go.Bar(\n            name=\"2020\",\n            x=data[\"labels\"],\n            y=data[\"dt_20\"],\n            offsetgroup=0,\n        ),\n        go.Bar(\n            name=\"2019\",\n            x=data[\"labels\"],\n            y=data[\"dt_19\"],\n            offsetgroup=1,\n        ),\n        go.Bar(\n            name=\"2018\",\n            x=data[\"labels\"],\n            y=data[\"dt_18\"],\n            offsetgroup=2,\n        )\n        \n    ],\n    layout=go.Layout(\n        title=\"Which IDE is most liked\",\n        yaxis_title=\"Number of Kaggler\",\n        title_x=0.5\n    )\n)\n\nfig.show()","f122e0e6":"#0 denotes the product was not listed in 2018 \nval_count_20 ={\n    \"Kaggle_NBook\": (df_bd_20[\"Q10_Part_1\"].value_counts().values[0]),\n    \"Colab_NBook\": (df_bd_20[\"Q10_Part_2\"].value_counts().values[0]),\n    \"Azure_NBook\": (df_bd_20[\"Q10_Part_3\"].value_counts().values[0]),\n    \"Paperspace\/Gradient\": (df_bd_20[\"Q10_Part_4\"].value_counts().values[0]),\n    \"Binder\/JupyterHub\": (df_bd_20[\"Q10_Part_5\"].value_counts().values[0]),\n    \"IBM_WNBook\": (df_bd_20[\"Q10_Part_7\"].value_counts().values[0]),\n    \"Amazon_EMR\/SM\": (df_bd_20[\"Q10_Part_8\"].value_counts().values[0]) + (df_bd_20[\"Q10_Part_9\"].value_counts().values[0]),\n    \"Google_AI\/Datalab\": (df_bd_20[\"Q10_Part_10\"].value_counts().values[0]) + (df_bd_20[\"Q10_Part_11\"].value_counts().values[0]),\n}\n\nval_count_19 ={\n    \"Kaggle_NBook\": (df_bd_19[\"Q17_Part_1\"].value_counts().values[0]),\n    \"Colab_NBook\": (df_bd_19[\"Q17_Part_2\"].value_counts().values[0]),\n    \"Azure_NBook\": (df_bd_19[\"Q17_Part_3\"].value_counts().values[0]),\n    \"Paperspace\/Gradient\": 0,\n    \"Binder\/JupyterHub\": (df_bd_19[\"Q17_Part_7\"].value_counts().values[0]),\n    \"IBM_WNBook\": (df_bd_19[\"Q17_Part_8\"].value_counts().values[0]),\n    \"Amazon_EMR\/SM\": (df_bd_19[\"Q17_Part_10\"].value_counts().values[0]),\n    \"Google_AI\/Datalab\": (df_bd_19[\"Q17_Part_4\"].value_counts().values[0]),\n}\n\nval_count_18 ={\n    \"Kaggle_NBook\": (df_bd_18[\"Q14_Part_1\"].value_counts().values[0]),\n    \"Colab_NBook\": (df_bd_18[\"Q14_Part_2\"].value_counts().values[0]),\n    \"Azure_NBook\": (df_bd_18[\"Q14_Part_3\"].value_counts().values[0]),\n    \"Paperspace\/Gradient\": (df_bd_18[\"Q14_Part_6\"].value_counts().values[0]),\n    \"Binder\/JupyterHub\": (df_bd_18[\"Q14_Part_9\"].value_counts().values[0]),\n    \"IBM_WNBook\": 0,\n    \"Amazon_EMR\/SM\": 0,\n    \"Google_AI\/Datalab\": (df_bd_18[\"Q14_Part_5\"].value_counts().values[0]),\n}\n\nlst_2018 = []\nlst_2019 = []\nlst_2020 = []\nlabel_keys = list(val_count_20.keys())\nfor i in range(len(label_keys)):\n    lst_2018.append(val_count_18[label_keys[i]])\n    lst_2019.append(val_count_19[label_keys[i]])\n    lst_2020.append(val_count_20[label_keys[i]])\ndata = {\n    \"dt_18\":lst_2018,\n    \"dt_19\": lst_2019,\n    \"dt_20\": lst_2020,\n    \"labels\": label_keys\n}\n\nfig = go.Figure(\n    data=[\n        go.Bar(\n            name=\"2020\",\n            x=data[\"labels\"],\n            y=data[\"dt_20\"],\n            offsetgroup=0,\n        ),\n        go.Bar(\n            name=\"2019\",\n            x=data[\"labels\"],\n            y=data[\"dt_19\"],\n            offsetgroup=1,\n        ),\n        go.Bar(\n            name=\"2018\",\n            x=data[\"labels\"],\n            y=data[\"dt_18\"],\n            offsetgroup=2,\n        ),\n        \n    ],\n    layout=go.Layout(\n        title=\"Used Hosted Notebook\",\n        yaxis_title=\"Number of Kaggler\",\n        title_x=0.5\n    )\n)\n\nfig.show()","d6c3e8eb":"#employment status\nemp_stat_20=df_bd_20.Q5.iloc[1:].value_counts()\nemp_stat_19=df_bd_19.Q5.iloc[1:].value_counts()\nemp_stat_18=df_bd_18.Q6.iloc[1:].value_counts()\n\n#pic slice name filtering\nas_list = emp_stat_20.index.tolist()\nidx_not = as_list.index('Currently not employed')\nas_list[idx_not] = 'Not employed'\nemp_stat_20.index = as_list\n\nfig=make_subplots(rows=1,cols=3,\n                  specs=[[{\"type\": \"pie\"},{\"type\": \"pie\"},{\"type\": \"pie\"}]]\n                 ,subplot_titles=('2020','2019','2018'))\nfig.add_trace(go.Pie(labels=emp_stat_20.index[:6], values=emp_stat_20.values[:6], hole=0.1, name='2020', pull=[0,0.2]), row=1, col=1)\nfig.add_trace(go.Pie(labels=emp_stat_19.index[:6], values=emp_stat_19.values[:6], hole=0.1, name='2019', pull=[0,0.2]), row=1, col=2)\nfig.add_trace(go.Pie(labels=emp_stat_18.index[:6], values=emp_stat_18.values[:6], hole=0.1, name='2018', pull=[0,0.2]), row=1, col=3)\n\nfig.update_layout(title_text='Employment Status', title_x=0.5)","71368b03":"#most used Framework\nval_count_20 ={\n    \"Scikit-Learn\": (df_bd_20[\"Q16_Part_1\"].value_counts().values[0]),\n    \"TensorFlow\": (df_bd_20[\"Q16_Part_2\"].value_counts().values[0]),\n    \"Keras\": (df_bd_20[\"Q16_Part_3\"].value_counts().values[0]),\n    \"PyTorch\": (df_bd_20[\"Q16_Part_4\"].value_counts().values[0]),\n    \"Fastai\": (df_bd_20[\"Q16_Part_5\"].value_counts().values[0]),\n    \"Boosting\": (df_bd_20[\"Q16_Part_7\"].value_counts().values[0]) + \n                (df_bd_20[\"Q16_Part_8\"].value_counts().values[0]) + \n                (df_bd_20[\"Q16_Part_9\"].value_counts().values[0]),\n    \"Caret\": (df_bd_20[\"Q16_Part_12\"].value_counts().values[0]),\n    \"Mxnet+H20+Prophet\": 0 + (df_bd_20[\"Q16_Part_11\"].value_counts().values[0]) +\n                        (df_bd_20[\"Q16_Part_10\"].value_counts().values[0]),\n}\nval_count_19 ={\n    \"Scikit-Learn\": (df_bd_19[\"Q28_Part_1\"].value_counts().values[0]),\n    \"TensorFlow\": (df_bd_19[\"Q28_Part_2\"].value_counts().values[0]),\n    \"Keras\": (df_bd_19[\"Q28_Part_3\"].value_counts().values[0]),\n    \"PyTorch\": (df_bd_19[\"Q28_Part_6\"].value_counts().values[0]),\n    \"Fastai\": (df_bd_19[\"Q28_Part_10\"].value_counts().values[0]),\n    \"Boosting\": (df_bd_19[\"Q28_Part_5\"].value_counts().values[0]) + (df_bd_19[\"Q28_Part_8\"].value_counts().values[0]),\n    \"Caret\": (df_bd_19[\"Q28_Part_7\"].value_counts().values[0]),\n    #no data is given for Mxnet+H20+Prophet\n    \"Mxnet+H20+Prophet\": 0+0+0,\n}\nval_count_18 ={\n    \"Scikit-Learn\": (df_bd_20[\"Q19_Part_1\"].value_counts().values[0]),\n    \"TensorFlow\": (df_bd_20[\"Q19_Part_2\"].value_counts().values[0]),\n    \"Keras\": (df_bd_20[\"Q19_Part_3\"].value_counts().values[0]),\n    \"PyTorch\": (df_bd_20[\"Q19_Part_4\"].value_counts().values[0]),\n    \"Fastai\": (df_bd_18[\"Q19_Part_7\"].value_counts().values[0]),\n    \"Boosting\": (df_bd_18[\"Q19_Part_10\"].value_counts().values[0]) +\n                (df_bd_18[\"Q19_Part_13\"].value_counts().values[0]) +\n                (df_bd_18[\"Q19_Part_14\"].value_counts().values[0]),\n    \"Caret\": (df_bd_18[\"Q19_Part_9\"].value_counts().values[0]),\n    \"Mxnet+H20+Prophet\": (df_bd_18[\"Q19_Part_8\"].value_counts().values[0]) +\n                        (df_bd_18[\"Q19_Part_6\"].value_counts().values[0]) +\n                        (df_bd_18[\"Q19_Part_12\"].value_counts().values[0]),\n}\nlst_2018 = []\nlst_2019 = []\nlst_2020 = []\nlabel_keys = list(val_count_20.keys())\nfor i in range(len(label_keys)):\n    lst_2018.append(val_count_18[label_keys[i]])\n    lst_2019.append(val_count_19[label_keys[i]])\n    lst_2020.append(val_count_20[label_keys[i]])\ndata = {\n    \"dt_18\":lst_2018,\n    \"dt_19\": lst_2019,\n    \"dt_20\": lst_2020,\n    \"labels\": label_keys\n}\n\nfig = go.Figure(\n    data=[\n        go.Bar(\n            name=\"2020\",\n            x=data[\"labels\"],\n            y=data[\"dt_20\"],\n            offsetgroup=2,\n        ),\n        go.Bar(\n            name=\"2019\",\n            x=data[\"labels\"],\n            y=data[\"dt_19\"],\n            offsetgroup=1,\n        ),\n        go.Bar(\n            name=\"2018\",\n            x=data[\"labels\"],\n            y=data[\"dt_18\"],\n            offsetgroup=0,\n        )\n        \n    ],\n    layout=go.Layout(\n        title=\"Most used machine learning or deep learning framework\",\n        yaxis_title=\"Number of Kaggler\",\n        title_x=0.5\n    )\n)\n\nfig.show()","d3882536":"#Earning\ndf_sal_20 = df_bd_20.groupby(\"Q24\").count().Q1\ndf_sal_19 = df_bd_19.groupby(\"Q10\").count().Q1\ndf_sal_18 = df_bd_18.groupby(\"Q9\").count()\n\nas_list = df_sal_18.index.tolist()\nidx = as_list.index('I do not wish to disclose my approximate yearly compensation')\nas_list[idx] = 'concealed'\ndf_sal_18.index = as_list\ndf_sal_18 = df_sal_18.Q1\n\nfig = make_subplots(rows = 1, cols = 3,\n                   specs = [[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n                   subplot_titles=('2020', '2019', '2018'))\n\nfig.add_trace(go.Bar(x=df_sal_20.index.sort_values(), y=df_sal_20.values, name='2020'), row=1, col=1)\nfig.add_trace(go.Bar(x=df_sal_19.index, y=df_sal_19.values, name='2019'), row=1, col=2)\nfig.add_trace(go.Bar(x=df_sal_18.index, y=df_sal_18.values, name='2018'), row=1, col=3)\n\nfig.update_layout(title_text='Earnings', title_x=0.5)","07fc62fb":"#mostly used cloud service providers\nval_count_20 ={\n    \"AWS\": (df_bd_20[\"Q26_A_Part_1\"].value_counts().values[0]),\n    \"Microsoft_Azure\": (df_bd_20[\"Q26_A_Part_2\"].value_counts().values[0]),\n    \"GCP\": (df_bd_20[\"Q26_A_Part_3\"].value_counts().values[0]),\n    \"IBM_Cloud\": (df_bd_20[\"Q26_A_Part_4\"].value_counts().values[0]),\n    \"Alibaba_cloud\": (df_bd_20[\"Q26_A_Part_8\"].value_counts().values[0]),\n    \"Oracle+Salesforce+VMware_cloud\": (df_bd_20[\"Q26_A_Part_5\"].value_counts().values[0]) + \n                                    #total VMware_cloud count = 0\n                                    (df_bd_20[\"Q26_A_Part_6\"].value_counts().values[0]) + 0\n}\nval_count_19 ={\n    \"AWS\": (df_bd_19[\"Q29_Part_2\"].value_counts().values[0]),\n    \"Microsoft_Azure\": (df_bd_19[\"Q29_Part_3\"].value_counts().values[0]),\n    \"GCP\": (df_bd_19[\"Q29_Part_1\"].value_counts().values[0]),\n    #Added RED Hat cloud values with this\n    \"IBM_Cloud\": (df_bd_19[\"Q29_Part_4\"].value_counts().values[0]) +\n                (df_bd_19[\"Q29_Part_9\"].value_counts().values[0]),\n    \"Alibaba_cloud\": (df_bd_19[\"Q29_Part_5\"].value_counts().values[0]),\n    \"Oracle+Salesforce+VMware_cloud\": (df_bd_19[\"Q29_Part_7\"].value_counts().values[0]) + \n                                    #total VMware_cloud count = 0\n                                    (df_bd_19[\"Q29_Part_6\"].value_counts().values[0]) + 0\n}\nval_count_18 ={\n    \"AWS\": (df_bd_18[\"Q15_Part_2\"].value_counts().values[0]),\n    \"Microsoft_Azure\": (df_bd_18[\"Q15_Part_3\"].value_counts().values[0]),\n    \"GCP\": (df_bd_18[\"Q15_Part_1\"].value_counts().values[0]),\n    \"IBM_Cloud\": (df_bd_18[\"Q15_Part_4\"].value_counts().values[0]),\n     #total Alibaba_cloud count = 0\n    \"Alibaba_cloud\": 0,\n    \"Oracle+Salesforce+VMware_cloud\": 0 + 0 + 0\n}\nlst_2018 = []\nlst_2019 = []\nlst_2020 = []\nlabel_keys = list(val_count_20.keys())\nfor i in range(len(label_keys)):\n    lst_2018.append(val_count_18[label_keys[i]])\n    lst_2019.append(val_count_19[label_keys[i]])\n    lst_2020.append(val_count_20[label_keys[i]])\ndata = {\n    \"dt_18\":lst_2018,\n    \"dt_19\": lst_2019,\n    \"dt_20\": lst_2020,\n    \"labels\": label_keys\n}\n\nfig = go.Figure(\n    data=[\n        go.Bar(\n            name=\"2020\",\n            x=data[\"labels\"],\n            y=data[\"dt_20\"],\n            offsetgroup=2,\n        ),\n        go.Bar(\n            name=\"2019\",\n            x=data[\"labels\"],\n            y=data[\"dt_19\"],\n            offsetgroup=1,\n        ),\n        go.Bar(\n            name=\"2018\",\n            x=data[\"labels\"],\n            y=data[\"dt_18\"],\n            offsetgroup=0,\n        )\n    ],\n    layout=go.Layout(\n        title=\"Mostly used Cloud Searvice Providers\",\n        yaxis_title=\"Number of Kaggler\",\n        title_x=0.5\n    )\n)\n\nfig.show()","29253f8c":"# We are not in kaggle-survey-2017 data!","950a94b4":"# Where are we?","740c348b":"Depending on the pi chart, it can be said that the response from female kagglers has significantly increased in 2020. It could be inferred that, all over they are engaging themselves in data science more and more in upcoming years.","7b9ac688":"# Usages of Hosted Notebooks..","6779f1c1":"The survey response from our country increased over time. It has gone from 107 to 137 in 2018 to 2019 and total response data we got this year is 143.","a72d1e4e":"**Let's have a glimpse where we are in the global map(marked in blue)..**","c1df490a":"# Summary of total survey response from Bangladesh:","340f6399":"Kagglers with Bachelor's Degrees are dominating in kaggle. It is also true in reality. From the chart above, it can be found that over the percentage of Master\u2019s degree holders are not increasing like bachelor\u2019s degree holders. There is also a slight increase in Doctoral degree holders in Bangladesh.","a6e7a8cc":"**Welcome here..**   \nHere I have presented an analysis on what the survey data contains about different aspects of Bangladeshi Kaggalers in the Kaggle community. It's an ongoing work, so any kinds of suggestions or recommendations are welcomed. If you find this useful please consider upvoting it after your time.","4cb70cdc":"# Age Distribution..","1a87023b":"It can be seen from the chart that, most of the Kaggle participants are fresh graduates or they experience between 1-2 years.","1dbc9d2c":"# Earnings..","10cc1744":"As a data science enthusiast, it is obvious that python will take place at the top as the most used programming language among Kagglers over times. Along with  Python other languages like SQL, C\/C++, Java, JavaScript, and R are getting priorities.","71d6204c":"Let's have a summary of the data first. How many response from Bangladesh we got over time.","3df9a0fe":"I will start with the most common and frequest questions asked over times(2018-2020). I have already [shared a notebook](https:\/\/www.kaggle.com\/sharif485\/what-kaggle-is-asking-over-the-time-2018-2020)(If you found it useful don't forget to upvote) on that which contains different types of questions Kaggle asked over the time. I found that there is 15 question that was available all the time. Let's focus on that first...\n","44d09655":"# Most used Programming Language..","b0d0cbc3":"It is not surprising seeing that, for gaining knowledge we are mostly dependent on different kinds of online learning platforms which offers varieties of free and paid courses. In addition to this, it can be found from the chart that students are almost fully dependent on online courses comparing to the courses thought at university. From those platforms, Coursera got undivided attention all the time for its well-designed courses. ","69293d6c":"# Employment Status..","a60c1286":"A question analysis from the year between 2018 to 2020 can be found [here](https:\/\/www.kaggle.com\/sharif485\/what-kaggle-is-asking-over-the-time-2018-2020). I have analyzed all the question to find out the range of questions Kaggle were asking over time. That notebook helped a lot to create this notebook. Feel free to check that out.","d43215bd":"Most of the participants in Kaggle from our country are students and in 2020 it's even increased significantly. A noticeable state from the figure is that the unemployment rates have increased dramatically compared to other years. World pandemic hit can be the root cause for that. Another noticeable thing is in 2020 the employment for machine learning engineer positions has increased vastly.","c3cdfec9":"Lets start with **kaggle-survey-2017** data.","3c021671":"# Most used Machine Learning or Deep Learning Frameworks..","b3f262a3":"# Time invested to study ML..","29fcb475":"# Most preferred IDE's..","f13c0a2b":"It seems that Bangladesh is not in the list of countries!!! As per the rules by [kaggle-survey-2017](https:\/\/www.kaggle.com\/kaggle\/kaggle-survey-2017), if total survey_response count for a country exceeds 50 only then the country name will be appeared in country list otherwise it will be included in \"Other\". Unfortunately this happened in 2017 for our country. For this reason, I have to skip 2017 survey data. All the comments were made depending on the data. Let's explore other year's data...","d6c95efa":"# Let's have a look in other questions...","460e7b34":"From the figures above we can clearly say that, person with age between 22 to 29 is mostly interested in data science sector in Bangladesh.","cee7b1e1":"When it comes to talking about the most favourite deep learning framework Tensorflow and Keras are still popular in the community. The users for PyTorch is also growing gradually but not like Tensorflow or Keras. For machine learning, Scikit-Learn is always getting top priority for its enriched modules. Usages of different kinds of boosting algorithms are also in the rise.","6acf13e4":"It seems that Amazon, Microsoft, and Google all of them are getting popular after a fall from 2018. Other cloud services are still in the market.","90c0a324":"# Gender Distribution..","564cfe69":"# Mostly used Cloud Searvice Providers..","61099ead":"# Still working on it..  \n\nIf you have any suggestions or comments feel free to post a comment.","0c01831f":"# Educational Background..","0fc760c3":"# Impact of Online Mediums.."}}