{"cell_type":{"56f3ac65":"code","a6ebe268":"code","c342c5c1":"code","419cfefe":"code","550b75b5":"code","d32c13bb":"code","cf6e372d":"code","557c8efd":"code","ec79cef9":"code","0bb5e1f6":"code","548aa026":"code","0363e13e":"code","3abc8581":"code","a9bfe96d":"markdown","575bb93b":"markdown","be4adac1":"markdown","6ee2cd28":"markdown","bb631a37":"markdown","c82985e4":"markdown","ffa80f24":"markdown","b4fb6fe0":"markdown","5e42099d":"markdown","4fa5f3d0":"markdown","d0f18d0c":"markdown","8a54cd71":"markdown","bc4488b6":"markdown","d75d9fcb":"markdown","279206eb":"markdown"},"source":{"56f3ac65":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_theme(style=\"darkgrid\", palette=\"rainbow\")\n%matplotlib inline","a6ebe268":"df_normal = pd.read_csv(\"..\/input\/water-potability\/water_potability.csv\", usecols=[\"Sulfate\"])\ndf_skew = pd.read_csv(\"..\/input\/titanic\/train.csv\", usecols=[\"Fare\"])","c342c5c1":"plt.figure(figsize=(15,7))\nplt.subplot(1,2,1)\nplt.title(\"Almost Normal Distribution\", fontsize=15)\nsns.kdeplot(data = df_normal[\"Sulfate\"])\nplt.subplot(1,2,2)\nplt.title(\"Skewed Distribution\", fontsize=15)\nsns.boxplot(data = df_skew[\"Fare\"], palette=\"Dark2\")\nplt.show()","419cfefe":"#defining lower and upper limit\nnorm_upper_limit = df_normal[\"Sulfate\"].mean() + 3 * df_normal[\"Sulfate\"].std()\nnorm_lower_limit = df_normal[\"Sulfate\"].mean() - 3 * df_normal[\"Sulfate\"].std()","550b75b5":"#trimming the outliers away and we only have the distribution in 3 standard deviation\ndf_normal_new = df_normal[(df_normal[\"Sulfate\"] > norm_lower_limit) & (df_normal[\"Sulfate\"] < norm_upper_limit)]","d32c13bb":"plt.figure(figsize=(8,5))\nplt.suptitle(\"Distribution before Trimming\", fontsize=18)\nplt.subplot(1,2,1)\nsns.kdeplot(data = df_normal)\nplt.subplot(1,2,2)\nsns.boxplot(data = df_normal, palette=\"magma\")\nplt.tight_layout()\nplt.show()","cf6e372d":"plt.figure(figsize=(8,5))\nplt.suptitle(\"Distribution after Trimming\",fontsize=18)\nplt.subplot(1,2,1)\nsns.kdeplot(data = df_normal_new)\nplt.subplot(1,2,2)\nsns.boxplot(data = df_normal_new, palette=\"magma\")\nplt.tight_layout()\nplt.show()","557c8efd":"#finding the Q1(25 percentile) and Q3(75 percentile)\nq1 = df_skew[\"Fare\"].quantile(0.25)\nq2 = df_skew[\"Fare\"].quantile(0.75)","ec79cef9":"#finding out the value of Inter Quartile Range\nIQR = q2 - q1","0bb5e1f6":"#defining max and min limits\nmax_limit = q2 + (1.5 * IQR)\nmin_limit = q1 - (1.5 * IQR) ","548aa026":"#capping\ndf_skew_new = pd.DataFrame(np.where(df_skew[\"Fare\"] > max_limit, max_limit, \n         (np.where(df_skew[\"Fare\"] < min_limit, min_limit, df_skew[\"Fare\"]))), columns=[\"Fare\"])","0363e13e":"plt.figure(figsize=(8,5))\nplt.suptitle(\"Distribution before Capping\", fontsize=18)\nplt.subplot(1,2,1)\nsns.kdeplot(data = df_skew, palette=\"cool\")\nplt.subplot(1,2,2)\nsns.boxplot(data = df_skew, palette=\"Dark2\")\nplt.tight_layout()\nplt.show()","3abc8581":"plt.figure(figsize=(8,5))\nplt.suptitle(\"Distribution after Capping\",fontsize=18)\nplt.subplot(1,2,1)\nsns.kdeplot(data = df_skew_new, palette=\"cool\")\nplt.subplot(1,2,2)\nsns.boxplot(data = df_skew_new, palette=\"Dark2\")\nplt.tight_layout()\nplt.show()","a9bfe96d":"<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:nexa\">\n    <b>1. Trimming<\/b> is the method of cutting off or getting rid of the outliers at the end of the dataset. This is easier than all the other methods. <br>\n    <b>2. Capping<\/b> is setting a limit for the feature and set the value of all the outliers exceeding the limit to the value of the limit. So in the student example, we will set a limit of score and change the score of the 2% student to that. For example, 75 is the max score limit that we set. The score of 2% outlier students will be set to 75. <br>\n    <b>3. Percentile<\/b> method is equal percentile on both the sides to detect outliers. Once you detect these outliers you can use either trimming or capping to get rid of them.\n<\/div>","575bb93b":"<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:nexa\">\n    See how the distribution did not get effected in this method. Also, we got rid of the outliers. One bad thing about this method is loss of information. We got rid of corresponding feature information which might have been useful in some way for the model. However, just like dropping nun values, this method might result to loss of information.\n<\/div>","be4adac1":"***","6ee2cd28":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5CCBD0;\n           font-size:20px;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:black;\">\n            <b>How to Handle Outliers?<\/b>\n        <\/p>\n<\/div>","bb631a37":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#FD7056;\n           font-size:20px;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:white;\">\n            <b>3. Percentile Method<\/b>\n        <\/p>\n<\/div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:nexa\">\n    In percentile method, you decide a specific threshold in percentile. So, use the same function that I have used for q1 and q2 in finding out IQR. Use that to decide a certain threshold, say for example, aynthing above 98 percentile and below 2 percentile will be considered as an outlier. Then you can go ahead and use trimming or capping to handle them. I have showed both the ways in the above examples. <br>\n    Percentile method is arbitrary and you will have to find out a value manually and here domain knowledge will help you a lot. Domain knowledge is the strongest pillar in feature engineering. If you do not know about the data, start googling and learning more about it. Learn more about the features and you will develop a basic intuition and you might find a custom way to handle outliers. Experiment, do trial and error and have fun with ML. Keep kaggling! \n<\/div>","c82985e4":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#FF718F;\n           font-size:20px;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:black;\">\n            <b>How to Find Outliers?<\/b>\n        <\/p>\n<\/div>","ffa80f24":"<img src=\"https:\/\/www.writerscentre.com.au\/wp-content\/uploads\/2020\/05\/diff.jpg\" alt=\"min max formula\" width=\"500\" height=\"600\">","b4fb6fe0":"<img src=https:\/\/cdn.discordapp.com\/attachments\/517815672613503006\/874179036371386378\/unknown.png>","5e42099d":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#7C5099;\n           font-size:20px;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:white;\">\n            <b>1. Trimming & Standard Deviation<\/b>\n        <\/p>\n<\/div>","4fa5f3d0":"<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:nexa\">\n    Notice how we got rid of the outliers. Also, as the outlier values were replaced by the max and min limit, notice, how in the PDF or KDEplot, there is a buldge or more values near 60-80. \n<\/div>","d0f18d0c":"<img src=https:\/\/cdn.discordapp.com\/attachments\/517815672613503006\/874185466637877318\/unknown.png>","8a54cd71":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#FFDD00;\n           font-size:20px;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:black;\">\n            <b>Guide on handling Outliers<\/b>\n        <\/p>\n<\/div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:nexa;\">\n    Outliers are the different ones. In a distribution, if few of the datapoints have distinguishable characters compared to its counterparts, then it is termed as an outlier. Suppose in a dataset of students' performance, 98% of the students scored below 60 but only 2% scored above 85. In this example, these 2% students are outliers. \n<\/div>","bc4488b6":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#FF0861;\n           font-size:20px;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:white;\">\n            <b>If you have found the notebook useful, please upvote it so that more people finds it! :)<\/b>\n        <\/p>\n<\/div>","d75d9fcb":"<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:nexa\">\n    In a machine learning problem, outliers create a loss of mess. Your accuracy might dip significantly if there are unhandled outliers in the dataset. So it is always recommended to find out the outliers and do something about them before you proceed on to model building. \n<\/div>","279206eb":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#2AB28C;\n           font-size:20px;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:white;\">\n            <b>2. Capping & Inter-Quartile Range (IQR)<\/b>\n        <\/p>\n<\/div>"}}