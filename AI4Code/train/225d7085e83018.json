{"cell_type":{"6fd3774a":"code","a58851ae":"code","196d7ddd":"code","5be98b3a":"code","9c07f3b3":"code","7545d4c1":"code","f5a2eecc":"code","25b77370":"code","2340442d":"code","9ec8d3ac":"code","e43875f6":"code","cfb5474c":"code","abb769b4":"code","457a4712":"markdown","e61c63f5":"markdown","d8f90e1d":"markdown","1e1ac92a":"markdown","b624e597":"markdown","9fca3fdd":"markdown","b91e2a7b":"markdown","6f71fee4":"markdown"},"source":{"6fd3774a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a58851ae":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","196d7ddd":"df = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\ndf.head()","5be98b3a":"original_columns = df.columns.values\n\ncolumns =['ID']\n\nfor i in range(110):\n    columns.append('V{}'.format(i))\n\ndf.columns = columns\n\ndf = df[columns[1:]]\n\ndf.head()","9c07f3b3":"df['V1'] = [0 if a == 'negative' else 1 for a in df['V1'].values]","7545d4c1":"sns.violinplot(x=\"V0\", y='V1', data=df, vert=False)","f5a2eecc":"sns.distplot(df['V1'])","25b77370":"corrmat = df.corr()\nf, ax = plt.subplots(figsize=(24, 18))\nsns.heatmap(corrmat, vmax=.8, square=True);","2340442d":"corrmat_v1 = corrmat.nlargest(10, 'V1')\n\nfeatures = corrmat_v1.index.values.tolist()\n\nsns.heatmap(df[features].corr(), yticklabels=features, xticklabels=features, square=True);\n\n#sns.heatmap(corrmat_best)","9ec8d3ac":"from sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\n\nX = df[features[1:]]\nY = df[features[0]]\n\nimp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.0)\nimp = imp.fit(X)\n\nX = pd.DataFrame(imp.transform(X), columns=features[1:])\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3)\n\nmodel_tree = tree.DecisionTreeClassifier()\nmodel_tree = model_tree.fit(X_train, y_train)\n\ny_pred = model_tree.predict(X_test)\n\npredictions = [round(value) for value in y_pred]\n\naccuracy = accuracy_score(y_test, predictions)\n\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","e43875f6":"fig, ax = plt.subplots(figsize=(15,15))\ntm = tree.plot_tree(model_tree, ax=ax)\nplt.show()","cfb5474c":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\n\nX = df[features[1:]]\nY = df[features[0]]\n\nimp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.0)\nimp = imp.fit(X)\n\nX = pd.DataFrame(imp.transform(X), columns=features[1:])\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3)\n\nmodel_rf = RandomForestClassifier(max_depth=2, random_state=0)\nmodel_rf = model_rf.fit(X_train, y_train)\n\ny_pred = model_rf.predict(X_test)\n\npredictions = [round(value) for value in y_pred]\n\naccuracy = accuracy_score(y_test, predictions)\n\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","abb769b4":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\n\nX = df[features[1:]]\nY = df[features[0]]\n\n\nimp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.0)\nimp = imp.fit(X)\n\nX = pd.DataFrame(imp.transform(X), columns=features[1:])\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3)\n\nmodel_xgb = XGBClassifier()\n\nmodel_xgb.fit(X_train, y_train)\n\ny_pred = model_xgb.predict(X_test)\n\npredictions = [round(value) for value in y_pred]\n\naccuracy = accuracy_score(y_test, predictions)\n\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","457a4712":"### Random Forests","e61c63f5":"## Predicting Infection","d8f90e1d":"## Data Loading and Preprocessing","1e1ac92a":"### Simple Feature Selection","b624e597":"### XGBoost","9fca3fdd":"## Visualizations","b91e2a7b":"### Correlogram","6f71fee4":"### Decision Trees"}}