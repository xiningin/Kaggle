{"cell_type":{"4073dbd4":"code","91bd7748":"code","6034c781":"code","b32ff000":"code","11262873":"code","1eed00f6":"code","426502f9":"markdown"},"source":{"4073dbd4":"# use \"python read url file data\" search\"\n# get \"https:\/\/stackoverflow.com\/questions\/1393324\/given-a-url-to-a-text-file-what-is-the-simplest-way-to-read-the-contents-of-the\"\n# since we use python 3 therefore try to use the following script to get cp1a list\nimport urllib.request  # the lib that handles the url stuff\ntarget_url = \"https:\/\/nfulist.herokuapp.com\/?semester=1091&courseno=0762\"\ncp1a = []\nfor line in urllib.request.urlopen(target_url):\n    cp1a.append(line.decode('utf-8'))\n    #print(line.decode('utf-8'), end = \"\") #utf-8 or iso8859-1 or whatever the page encoding scheme is\nprint(cp1a)\n# need to chop \\n for each line","91bd7748":"# use \"python chop new line\" search \n# get \"https:\/\/stackoverflow.com\/questions\/275018\/how-can-i-remove-a-trailing-newline\"\n# found .rstrip() maybe work\nimport urllib.request  # the lib that handles the url stuff\ntarget_url = \"https:\/\/nfulist.herokuapp.com\/?semester=1091&courseno=0762\"\ncp1a = []\nfor line in urllib.request.urlopen(target_url):\n    cp1a.append(line.decode('utf-8').rstrip())\n    #print(line.decode('utf-8'), end = \"\") #utf-8 or iso8859-1 or whatever the page encoding scheme is\nprint(cp1a)\n# yes, we got the needed list.","6034c781":"# now we can get the cp1b by using the same method\n# https:\/\/nfulist.herokuapp.com\/?semester=1091&courseno=0776\nimport urllib.request  # the lib that handles the url stuff\ntarget_url = \"https:\/\/nfulist.herokuapp.com\/?semester=1091&courseno=0776\"\ncp1a = []\nfor line in urllib.request.urlopen(target_url):\n    # we can use int() to convert string into integer\n    cp1a.append(int(line.decode('utf-8').rstrip()))\n    #print(line.decode('utf-8'), end = \"\") #utf-8 or iso8859-1 or whatever the page encoding scheme is\nprint(cp1a)","b32ff000":"''' now can we read [[40823148, 40923203, 40923208, 40923209, 40923210, 40923223, 40923225, 40923230, 40923238, 40923239, 40923244, 40923249], [40523148, 40923201, 40923202, 40923218, 40923219, 40923228, 40923231, 40923232, 40923240, 40923247, 40923248, 40923250], [40823152, 40923205, 40923212, 40923214, 40923217, 40923226, 40923236, 40923241, 40923242, 40923246, 40923251], [40723217, 40728238, 40923206, 40923216, 40923220, 40923227, 40923233, 40923237, 40923243, 40923252, 40923253], [40523138, 40923204, 40923207, 40923211, 40923213, 40923221, 40923224, 40923229, 40923234, 40923235, 40923245]] \ninto one dimensional list\n'''\ncp1bGroup = [[40823148, 40923203, 40923208, 40923209, 40923210, 40923223, 40923225, 40923230, 40923238, 40923239, 40923244, 40923249], [40523148, 40923201, 40923202, 40923218, 40923219, 40923228, 40923231, 40923232, 40923240, 40923247, 40923248, 40923250], [40823152, 40923205, 40923212, 40923214, 40923217, 40923226, 40923236, 40923241, 40923242, 40923246, 40923251], [40723217, 40728238, 40923206, 40923216, 40923220, 40923227, 40923233, 40923237, 40923243, 40923252, 40923253], [40523138, 40923204, 40923207, 40923211, 40923213, 40923221, 40923224, 40923229, 40923234, 40923235, 40923245]] \n# len() can be used to get the length of a list\n#print(len(cp1bGroup))\n# so we can use the for loop to read group member out\ngroupNum = len(cp1bGroup)\ncp1b = []\nfor i in range(groupNum):\n    # use len() to get student number for each group\n    studNum = len(cp1bGroup[i])\n    #print(cp1bGroup[i])\n    for j in range(studNum):\n        cp1b.append(cp1bGroup[i][j])\nprint(cp1b)\n# yes, we transfer two dimensional list into one diimension\n# for the next step we may need to compare two lists to find the discrepancy","11262873":"# since we don't have cp1a grouping list, we need to get it from http:\/\/mde.tw\/cp2020\/content\/W3.html\nimport requests\nfrom bs4 import BeautifulSoup\n\nurl = \"http:\/\/mde.tw\/cp2020\/content\/W3.html\"\nresponse = requests.get(url) # request object from url\nhtml_doc = response.text # get html from request object\n# can we use split to seperate file content\n#print(html_doc.split(\"==============================\"))\n# use \"1b\" to cut the page\ncut1a = html_doc.split(\"1b\")\n# get first part of cut1a\n# use \"==============================\" to cut the 1a html content\ncutPage = cut1a[0].split(\"==============================\")\n#print(len(cutPage))\n#soup = BeautifulSoup(response.text, \"lxml\") # use lxml to parse html\n# we only test the first element of the html page\ncp1a = []\nfor group in range(len(cutPage)):\n    soup = BeautifulSoup(cutPage[group], \"lxml\")\n\n    '''\n    print(soup.title) # get title\n    print(\"---\")\n    print(soup.title.name) # get title name\n    print(\"---\")\n    print(soup.title.string) # get title string\n    print(\"---\")\n    print(soup.title.parent.name) # get title parent name\n    print(\"---\")\n    print(soup.a) # get first anchor tag\n    print(\"---\")\n    '''\n\n    # get all tags\n    #print(soup.find_all('a'))\n    allA = soup.find_all('a')\n    # search with \"bs4 get all tag with certain text\" and get \"https:\/\/stackoverflow.com\/questions\/866000\/using-beautifulsoup-to-find-a-html-tag-that-contains-certain-text\"\n    index = 0\n    cp1aElement = []\n    for i in allA:\n        #print(i)\n        if \"github\" in str(i):\n            #print(i)\n            #print(allA[index].contents[0])\n            stud = allA[index].contents[0]\n            if stud not in cp1aElement:\n                cp1aElement.append(stud)\n        index = index + 1\n    #print(\"1a group \" + str(group + 1) + \":\")\n    #print(cp1aElement)\n    cp1a.append(cp1aElement)\nprint(cp1a)\nfor i in range(len(cp1a)):\n    print(\"group \" + str(i+1) + \":\", cp1a[i])\n    \n","1eed00f6":"# 1b student_no and github_account can be retrieved from \"http:\/\/mde.tw\/cp2020\/downloads\/hw2\/cpb_github_account.txt\"\nimport urllib.request  # the lib that handles the url stuff\ntarget_url = \"http:\/\/mde.tw\/cp2020\/downloads\/hw2\/cpb_github_account.txt\"\ncp1b = []\nfor line in urllib.request.urlopen(target_url):\n    cp1bTemp = line.decode('utf-8').rstrip()\n    #print(line.decode('utf-8'), end = \"\") #utf-8 or iso8859-1 or whatever the page encoding scheme is\n    cp1b.append(cp1bTemp.split('\\t'))\n#print(cp1b)\n# drop the first element of cp1b and convert into dictionary\ncp1bAccount = dict(cp1b[1:])\n# check into the cp1bAccount dict for \"40923208\"\nprint(cp1bAccount[\"40923208\"])","426502f9":"http:\/\/mde.tw\/cp2020\/content\/HW2.html \u6240\u9762\u81e8\u7684\u554f\u984c\u662f\u5404\u73ed\u63a1\u7528\u4e82\u6578\u5206\u7d44\u5f8c, \u90e8\u5206\u5b78\u54e1\u7121\u6cd5\u5229\u7528\u5b78\u865f\u767b\u8a18 Github \u5e33\u865f, \u5c0e\u81f4\u7576\u6642\u76f4\u63a5\u5229\u7528\u5b78\u865f\u4f5c\u70ba Github \u5e33\u865f\u6240\u7522\u751f\u7684 http:\/\/mde.tw\/cp2020\/content\/W3.html \u90e8\u5206\u5167\u5bb9\u932f\u8aa4, \u5728\u6b64\u5e0c\u671b\u63a1\u7528\u7a0b\u5f0f\u6d41\u7a0b\u4f86\u7522\u751f\u6b63\u78ba\u7684 W3 \u5206\u7d44\u9023\u7d50\u5167\u5bb9.\n\u4f46\u56e0\u70ba\u5206\u7d44\u5f8c\u90e8\u5206\u5b78\u54e1\u52a0\u9000\u9078, \u56e0\u6b64\u4e5f\u5e0c\u671b\u900f\u904e\u7a0b\u5f0f\u65b9\u6cd5\u627e\u51fa\u5404\u73ed\u52a0\u9078\u6216\u9000\u9078\u7684\u5b78\u54e1\u540d\u55ae, \u4e26\u5c07\u5c1a\u672a\u7d0d\u7d44\u7684\u7d44\u54e1\u52a0\u5165\u7279\u5b9a\u7d44\u5225.\n\u53e6\u5916, \u7576\u6642\u7532\u73ed\u5206\u7d44\u5f8c\u4e26\u6c92\u6709\u50cf\u4e59\u73ed\u5c07\u5206\u7d44\u7d50\u5408\u4ee5\u6578\u5217\u5132\u5b58, \u56e0\u6b64\u5fc5\u9808\u5f9e W3 \u7684\u7db2\u7ad9\u5167\u5bb9\u4e2d\u8a2d\u6cd5\u64f7\u53d6\u51fa\u7532\u73ed\u7684\u5206\u7d44\u6578\u5217, \u4ee5\u5229\u5f8c\u7e8c\u9032\u884c\u6bd4\u5c0d\u6216\u5faa\u74b0\u5efa\u7acb\u7d44\u54e1\u9023\u7d50\u8cc7\u6599\u4e4b\u7528.\n\u7e3d\u7d50\u4e0a\u8ff0, HW2 \u8a08\u6709\u4e09\u9805\u4e3b\u984c:\n1. \u5f9e W3 \u7db2\u9801\u4e2d\u64f7\u53d6\u51fa\u7532\u73ed\u7684\u5206\u7d44\u6578\u5217\n2. \u6bd4\u5c0d\u5148\u524d\u5206\u7d44\u8cc7\u6599\u8207\u6700\u7d42\u6559\u52d9\u8655\u9078\u8ab2\u540d\u55ae,\u5217\u51fa\u4e8b\u5f8c\u52a0\u9078\u6216\u9000\u9078\u4eba\u54e1\u540d\u55ae\n3. \u6839\u64da\u7d44\u54e1\u7684 Github \u5e33\u865f\u5217\u51fa\u6b63\u78ba\u7684 W3 \u5009\u5132\u8207\u7db2\u7ad9\u9023\u7d50"}}