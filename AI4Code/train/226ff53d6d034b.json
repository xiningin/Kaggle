{"cell_type":{"89f6edba":"code","192b8e60":"code","a8252778":"code","a5382921":"code","510efd3f":"code","bed1f091":"code","10577d95":"code","0b56c266":"code","1aa72507":"code","b9eef7ee":"code","11caab58":"code","d3d83e81":"code","de7f68c6":"code","525402f1":"code","b96e421c":"code","9104b5ec":"code","e9e6d32f":"code","77c7456a":"code","95c3fad1":"code","cca4f8a8":"code","6ddc8438":"code","570bae53":"code","4d80c80c":"code","23192728":"code","4293b3fa":"code","90393509":"code","1d336285":"code","92364e74":"code","c853d05f":"markdown","0dd8f739":"markdown","3bd244fd":"markdown","010cc0b1":"markdown","e9d19f82":"markdown"},"source":{"89f6edba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","192b8e60":"data = pd.read_csv(\"\/kaggle\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 5.csv\")\nmydata = data\nmydata.info()","a8252778":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# FOR FUZZY MATCH\nimport fuzzywuzzy\nfrom fuzzywuzzy import process, fuzz\n\n# FOR TRANSLATE URDU-ENGLISH\nfrom textblob import TextBlob","a5382921":"mydata = mydata.rename({\"Order Number\": \"OrdNumber\", \n                        \"Order Status\": \"OrdStatus\", \n                        \"Book Name\" : \"BookName\", \n                        \"Order Date & Time\": \"OrdDate\", \n                        \"City\": \"city\", \n                        \"Payment Method\": \"PayMethod\", \n                        \"Total items\": \"TotItems\", \n                        \"Total weight (grams)\": \"weight\"}, \n                       axis = 1 )\nmydata.city =mydata.city.astype('str')\nmydata.city = mydata.city.str.lower()\nmydata.city = mydata.city.str.strip()\nshort_names = mydata.city.str.len()<=4","510efd3f":"short_to_full = {\n    \"fsd\": \"faisalabad\",\n    \"rwp\": \"rawalpindi\",\n    \"lhr\": \"lahore\",\n    \"isb\": \"islamabad\",\n    \"ryk\": \"rahim yar khan\",    \n    \"khi\": \"karachi\",\n    \"hyd\": \"hydrabad\",\n    \"aj&k\": \"azad jammu & kashmir\",\n    \"lahr\": \"lahore\",\n    \"lah\": \"lahore\",\n    \"d i khan\": \"dera ismail khan\",\n    \"g g khan\": \"dera ghazi khan\",\n    \"dgk\": \"dera ghazi khan\",\n    \"vehari\": \"vihari\",\n    \"mailsi, district vehari\": \"vihari\"\n}\nmydata.city = mydata.city.replace(short_to_full)","bed1f091":"alpha_num_name = mydata.city.str.contains(\"[a-zA-Z0-9]\")\nbeore_urduNames = mydata[~alpha_num_name].city.unique()\nconvert_to_eng = {}\nfor x in beore_urduNames:\n    try:\n        tr = TextBlob(x).translate().string\n        convert_to_eng[x] = tr\n    except:\n        pass\nmydata.city = mydata.city.replace(convert_to_eng)","10577d95":"alpha_num_name = mydata.city.str.contains(\"[a-zA-Z0-9]\")\nafter_urduNames = mydata[~alpha_num_name].city.unique()\nafter_urduNames.shape, after_urduNames","0b56c266":"remaing_translate_to_eng = {\n    \"\u062e\u0627\u0646\u06cc\u0648\u0627\u0644\": \"khanewal\",\n    \"\u06c1\u06cc\u0644\u0627\u06ba\": \"heelan\",\n    \"\u0627\u0648\u06a9\u0627\u0691\u06c1\": \"okara\",\n    \"\u067e\u06be\u0627\u0644\u06cc\u06c1\": \"phalia\",\n    \"\u067e\u06cc\u0631\u0645\u062d\u0644\": \"pir mahal\",\n    \"\u0644\u06cc\u06c1\": \"layyah\",\n    \"\u0633\u0646\u0627\u0646\u0648\u0627\u06ba\": \"sananwan\",\n    \"\u062c\u0639\u0641\u0631\u0627\u0628\u0627\u062f\": \"jaffarabad\",\n    \"\u06a9\u0648\u06c1\u06cc\u0679\u0627\": \"kohita\",\n    \"\u0631\u0648\u06c1\u06cc\u0644\u0627\u0646\u0648\u0627\u0644\u06cc\": \"rohilanwali\",\n    \"\u06c1\u0631\u0646\u0627\u0626\u06cc\": \"harnai\",\n    \"\u06c1\u0646\u06af\u0648\": \"hangu\",\n    \"\u0645\u062d\u0644\u06c1 \u06af\u0648\u0691\u06be\u0627\": \"mohalla godha\",\n    \"\u0679\u0645\u0646\": \"timon\",\n    \"\u06c1\u0631\u0646\u0648\u0644\u06cc\": \"harnoli\",\n    \"\u0633\u06a9\u06c1\u0631\": \"sukkur\",\n    \"\u062c\u0627\u0645 \u067e\u0648\u0631\": \"jampur\",\n    \"\u0645\u064a\u0631\u067e\u0648\u0631\u062e\u0627\u0635\": \"mirpurkhas\",\n    \"\u0644\u0627\u0644\u06cc\u0627\u06ba\": \"lalian\",\n    \"\u0628\u06be\u06a9\u0631\": \"bhakkar\",\n    \"\u067e\u0644\u0646\u062f\u0631\u06cc\": \"pallandri\",\n    \"\u06a9\u0646\u0688\u06cc\u0627\u0631\u0648\": \"kandiaro\",\n    \"\u062f\u06be\u0648\u06a9 \u0645\u0635\u0627\u062d\u0628\": \"dhok musahib\",\n    \"\u0635\u0627\u0644\u062d \u067e\u0679\": \"saleh Pat\",\n    \"\u0644\u0648\u062f\u06be\u0631\u0627\u06ba\": \"lodhran\",\n    \"\u067e\u062a\u0648\u06a9\u06cc\": \"patoki\",\n    \"\u0686\u0648\u06a9 \u0622\u0639\u0638\u0645\": \"chowk azam\"\n}\nmydata.city = mydata.city.replace(remaing_translate_to_eng)\nalpha_num_name = mydata.city.str.contains(\"[a-zA-Z0-9]\")\nafter_replace_urduNames = mydata[~alpha_num_name].city.unique()\nafter_replace_urduNames.shape","1aa72507":"externalData = pd.read_csv(\"..\/input\/pakistan-cities\/pk.csv\")\nexternalData.city = externalData.city.str.lower()\nexternalData.city = externalData.city.str.strip()\nexternalData[externalData.city.str.contains('city')]","b9eef7ee":"externalData.city = externalData.city.replace('sialkot city', 'sialkot')\nexternalData.city = externalData.city.replace('jhang city', 'jhang')\nexternalData.city = externalData.city.replace('hyderabad city', 'hyderabad')\nexternalData.city = externalData.city.replace('attock city', 'attock')","11caab58":"testExt = {}\nmydata.new_city = None\nmydata.lat = None\nmydata.lng = None\nmydata.ratio = None\n\nfor x, xRows in externalData.iterrows():\n    for y, yRows in mydata.iterrows():\n        if (xRows.city not in yRows.city):\n            if xRows.city not in testExt:\n                testExt[xRows.city] = {\"count\":1}\n            else:\n                testExt[xRows.city][\"count\"] = testExt[xRows.city][\"count\"] + 1\n        else:\n            getRatio = fuzz.ratio(yRows.city, xRows.city)\n            mydata.at[y, 'ratio'] = getRatio\n            mydata.at[y, 'new_city'] = xRows.city\n            mydata.at[y, 'lat'] = xRows.lat\n            mydata.at[y, 'lng'] = xRows.lng\nmydata.info()\nmydata","d3d83e81":"print (\"\\nTotal Number of Rows: \", len(mydata))\nprint (\"\\n\\n----------------- BEFORE PROCESSING --------------------\\n\")\nprint (\"Unique Cities: \", len(mydata['city'].unique()))\nprint (f\"Total Unique Cities: {mydata['city'].nunique()} \" )\nprint (\"\\n\\n------------------ AFTER PROCESSING --------------------\\n\")\nprint (\"Unique Cities: \", len(mydata['new_city'].unique()))\nprint (f\"Total Unique Cities: {mydata['new_city'].nunique()} \" )\nprint (\"\\n\\n---------- UNPROCCESSED\/INVALID CITIES --------------\\n\")\nprint (\"Number of Invalid \/ UnProccessed Cities: \", mydata['new_city'].isnull().sum())","de7f68c6":"mydata_map = mydata\nmydata_map.head()\nmydata_map","525402f1":"cities_per_order = pd.DataFrame(columns=['city', 'orders', 'Longitude', 'Latitude'])\ncities = list(mydata_map['new_city'].str.strip())\nprint (\"Total Cities in dataFrame: \", len(cities))","b96e421c":"for city in cities:\n    orderNos = 0\n    iter_data = mydata_map[mydata_map['new_city'] == city]\n    geolocations = iter_data.drop_duplicates(subset = [\"lat\",\"lng\"])\n    orderNos = len(iter_data)\n    lat = geolocations['lat']\n    lng = geolocations['lng']\n    df = { \"city\": city, \"orders\": orderNos, \"Longitude\": lng, \"Latitude\": lat}\n    cities_per_order = cities_per_order.append(pd.DataFrame(df))","9104b5ec":"cities_per_order\nprint (\"Total Cities in dataFrame: \", len(cities_per_order))\n# Calculating Total Number of Orders\ntotal_orders = len(mydata_map)\nprint (\"Total Number of Orders: \", total_orders)","e9e6d32f":"#pip install folium\nimport folium as fo","77c7456a":"# with folium-map library\npakistan_map = fo.Map(location = [30.37,69.34],\n                          zoom_start=5.5,\n                          tiles='OpenStreetMap' )\n\nfor city, orders, lng, lat in zip(list(cities_per_order['city']), \n                                 list(cities_per_order['orders']), \n                                 list(cities_per_order['Longitude']), \n                                 list(cities_per_order['Latitude'])):\n    fo.CircleMarker(location=[lat, lng], \n                        radius=(float(orders)\/total_orders)*100, \n                        color=\"green\", \n                        fill=True, opacity=0.8, \n                        fill_color=\"green\").add_to(pakistan_map )\n    \npakistan_map","95c3fad1":"cities_per_ordStatus = pd.DataFrame(columns=['city', 'ordComplete', 'ordCancel', 'ordReturn', 'Longitude', 'Latitude'])\nmydata_map['OrdStatus'].unique()","cca4f8a8":"for city in cities:\n    Ordcomplete = 0\n    ordCancel = 0\n    ordReturn = 0\n    iter_data = mydata_map[mydata_map['new_city'] == city]\n    Ordcomplete = len(iter_data[iter_data['OrdStatus'] == \"Completed\" ])\n    ordCancel = len(iter_data[iter_data['OrdStatus'] == \"Cancelled\" ])\n    ordReturn = len(iter_data[iter_data['OrdStatus'] == \"Returned\" ])\n    geolocations = iter_data.drop_duplicates(subset = [\"lat\",\"lng\"])\n    lat = geolocations['lat']\n    lng = geolocations['lng']\n    df = { \"city\": city, \"ordComplete\": Ordcomplete, \"ordCancel\": ordCancel, \"ordReturn\": ordReturn, \"Longitude\": lng, \"Latitude\": lat}\n    cities_per_ordStatus = cities_per_ordStatus.append(pd.DataFrame(df))","6ddc8438":"cities_per_ordStatus","570bae53":"orderStat_map = fo.Map(location = [30.37,69.34],\n                          zoom_start=5.5,\n                          tiles='OpenStreetMap' )\n\nfor city, ordComplete, ordCancel, ordReturn, lng, lat in zip(list(cities_per_ordStatus['city']), \n                                                             list(cities_per_ordStatus['ordComplete']), \n                                                             list(cities_per_ordStatus['ordCancel']), \n                                                             list(cities_per_ordStatus['ordReturn']), \n                                                             list(cities_per_ordStatus['Longitude']), \n                                                             list(cities_per_ordStatus['Latitude'])):\n    fo.CircleMarker(location=[lat, lng], radius=(float(ordComplete)\/total_orders)*100, \n                        color=\"green\", fill=True, opacity=0.8, fill_color=\"green\", \n                   tooltip='{}: {}'.format(city, ordComplete) ).add_to(orderStat_map )\n    fo.CircleMarker(location=[lat, lng], radius=(float(ordCancel)\/total_orders)*100, \n                        color=\"red\", fill=True, opacity=0.8, fill_color=\"red\", \n                   tooltip='{}: {}'.format(city, ordCancel) ).add_to(orderStat_map )\n    fo.CircleMarker(location=[lat, lng], radius=(float(ordReturn)\/total_orders)*100, \n                        color=\"purple\", fill=True, opacity=0.8, fill_color=\"purple\", \n                   tooltip='{}: {}'.format(city, ordReturn) ).add_to(orderStat_map )\n    \norderStat_map","4d80c80c":"print(\"Unique Payment Methods: \", mydata_map['PayMethod'].unique())\nprint(\"NULL Payment Methods: \", mydata_map['PayMethod'].isna().sum())\nmydata_map['PayMethod'].value_counts()","23192728":"mydata_map['PayMethod'] = mydata_map['PayMethod'].replace('Cash on Delivery (COD)', 'Cash on delivery')\nmydata_map.head()","4293b3fa":"cities_paymethod = pd.DataFrame(columns=['city', 'COD', 'EasyPaisa', 'JazzCash', 'BankTransfer', 'Longitude', 'Latitude'])\n\nmydata_pay = mydata_map[mydata_map['PayMethod'].notna()]\nprint(\"Unique Payment Methods: \", mydata_pay['PayMethod'].unique())\nprint(\"NULL Payment Methods: \", mydata_pay['PayMethod'].isna().sum())\n\ntotal_paymethods = len(mydata_pay)\nprint(\"Total Pay Methods: \", total_paymethods)\n\nmydata_pay['PayMethod'].value_counts()","90393509":"for city in cities:\n    cod = 0\n    epaisa = 0\n    jcash = 0\n    bTransfer = 0\n    iter_data = mydata_map[mydata_map['new_city'] == city]\n    cod = len(iter_data[iter_data['PayMethod'] == \"Cash on delivery\" ])\n    epaisa = len(iter_data[iter_data['PayMethod'] == \"EasyPaisa\" ])\n    jcash = len(iter_data[iter_data['PayMethod'] == \"JazzCash\" ])\n    bTransfer = len(iter_data[iter_data['PayMethod'] == \"BankTransfer\" ])\n    geolocations = iter_data.drop_duplicates(subset = [\"lat\",\"lng\"])\n    lat = geolocations['lat']\n    lng = geolocations['lng']\n    df = { \"city\": city, \"COD\": cod, \"EasyPaisa\": epaisa, \"JazzCash\": jcash, \"BankTransfer\": bTransfer, \"Longitude\": lng, \"Latitude\": lat}\n    cities_paymethod = cities_paymethod.append(pd.DataFrame(df))","1d336285":"cities_paymethod","92364e74":"payMethod_map = fo.Map(location = [30.37,69.34],\n                          zoom_start=5.5,\n                          tiles='OpenStreetMap' )\n\nfor city, cod, epaisa, jcash, bTransfer, lng, lat in zip(list(cities_paymethod['city']), \n                                                         list(cities_paymethod['COD']), \n                                                         list(cities_paymethod['EasyPaisa']), \n                                                         list(cities_paymethod['JazzCash']), \n                                                         list(cities_paymethod['BankTransfer']), \n                                                         list(cities_paymethod['Longitude']), \n                                                         list(cities_paymethod['Latitude'])):\n    fo.CircleMarker(location=[lat, lng], radius=(float(cod)\/total_paymethods)*100, \n                        color=\"green\", fill=True, opacity=0.8, fill_color=\"green\", \n                       tooltip='{}: {}'.format(city, cod) ).add_to(payMethod_map )\n    fo.CircleMarker(location=[lat, lng], radius=(float(epaisa)\/total_paymethods)*100, \n                        color=\"red\", fill=True, opacity=0.8, fill_color=\"red\", \n                   tooltip='{}: {}'.format(city, epaisa) ).add_to(payMethod_map )\n    fo.CircleMarker(location=[lat, lng], radius=(float(jcash)\/total_paymethods)*100, \n                        color=\"purple\", fill=True, opacity=0.8, fill_color=\"purple\", \n                   tooltip='{}: {}'.format(city, jcash) ).add_to(payMethod_map )\n    fo.CircleMarker(location=[lat, lng], radius=(float(bTransfer)\/total_paymethods)*100, \n                        color=\"yellow\", fill=True, opacity=0.8, fill_color=\"yellow\", \n                   tooltip='{}: {}'.format(city, bTransfer) ).add_to(payMethod_map )\n    \npayMethod_map","c853d05f":"Hope attempt is appriciated **with lots of love**, looking for your guidance **like, UPVOTES for motivation**\nPreviously Notebook comments and like\/Upvores highly appriciated and motivated\nHeartly Thanks with lots of **LOVE**","0dd8f739":"Use External Data for Cities Normalization","3bd244fd":"# Visualiztion of Orders per Cities","010cc0b1":"# Number of Orders Status Per Cities","e9d19f82":"# Total Number of Orders Per Cities"}}