{"cell_type":{"1ac54937":"code","617b7362":"code","0e6b6503":"code","391e4cb1":"code","19668f8b":"code","2c9cb2dc":"code","f8baad1f":"code","b1c4ed16":"code","63c539cc":"code","f3b9e6a3":"code","6841608a":"code","be1f8564":"code","b3b16e8a":"markdown","4d19a118":"markdown","31957946":"markdown","da53e26f":"markdown","1418dfc9":"markdown","4e283506":"markdown","7eaf8b04":"markdown","e3369af0":"markdown","77eccdf4":"markdown","216b9d32":"markdown"},"source":{"1ac54937":"!pip install nb_black -q \n%load_ext nb_black","617b7362":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport plotly.figure_factory as ff\nimport keras\n\ndata = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","0e6b6503":"data.info()","391e4cb1":"table = data.corr()\nwith sns.axes_style(\"white\"):\n    mask = np.zeros_like(table)\n    mask[np.triu_indices_from(mask)] = True\n    plt.figure(figsize=(20, 20))\n    sns.heatmap(\n        round(table, 2),\n        cmap=\"Reds\",\n        mask=mask,\n        vmax=0.5,\n        vmin=table.min().min(),\n        linewidths=0.5,\n        annot=True,\n        annot_kws={\"size\": 12},\n    ).set_title(\"Dataset's Correlation Matrix\")","19668f8b":"class_corr = (\n    pd.DataFrame(table[\"Class\"].drop(\"Class\"))\n    .reset_index()\n    .sort_values(\"Class\", ascending=False)\n    .round(3)\n)\n\nfig = px.bar(class_corr, x=\"index\", y=\"Class\", color=\"Class\", text=\"Class\")\nfig.update_layout(\n    title_text=\"Correlation between Target and Features\",\n    yaxis_title=\"Correlation\",\n    xaxis_title=\"Features\",\n)\nfig.update_traces(textposition=\"outside\")\nfig.show()","2c9cb2dc":"fig = ff.create_table(data.describe().round(3).drop(\"count\").T, index=True)\nfig.show()","f8baad1f":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndata.Amount = scaler.fit_transform(data.Amount.values.reshape(-1, 1))","b1c4ed16":"from sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\n\nX_train, X_test, y_train, y_test = train_test_split(\n    data.drop([\"Time\", \"Class\"], axis=1),\n    data.Class.values,\n    test_size=0.20,\n    random_state=42,\n)\n\nsmote = SMOTE()\nX, y = smote.fit_sample(data.drop([\"Time\", \"Class\"], axis=1), data.Class.values.ravel())\nX_train_os, X_test_os, y_train_os, y_test_os = train_test_split(\n    X, y, test_size=0.20, random_state=42\n)\n\nX_train_os.shape","63c539cc":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nmodel = Sequential(\n    [\n        Dense(units=16, input_dim=29, activation=\"relu\"),\n        Dense(24, activation=\"relu\"),\n        Dropout(0.5),\n        Dense(20, activation=\"relu\"),\n        Dense(24, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ]\n)\n\nmodel.summary()","f3b9e6a3":"model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.fit(X_train_os, y_train_os, batch_size=15, epochs=5)\nmodel.evaluate(X_test_os, y_test_os)","6841608a":"from plotly import figure_factory as ff, graph_objects as go\nfrom sklearn.metrics import (\n    log_loss,\n    accuracy_score,\n    confusion_matrix,\n    f1_score,\n    precision_score,\n    recall_score,\n)\n\n\ndef metrics(y_true, y_pred, y_pred_class):\n    ac = accuracy_score(y_true, y_pred)\n    ll = log_loss(y_true, y_pred_class)\n    f1 = f1_score(y_true, y_pred, zero_division=1)\n    ps = precision_score(y_true, y_pred)\n    mc = confusion_matrix(y_true, y_pred)\n    rc = recall_score(y_true, y_pred)\n\n    header = [\"Metric\", \"Accuracy\", \"Loss(log)\", \"F1\", \"Precision\", \"Recall\"]\n    score = [\n        \"Score\",\n        round(ac, 3),\n        round(ll, 3),\n        round(f1, 3),\n        round(ps, 3),\n        round(rc, 3),\n    ]\n\n    x = [\"Real 0\", \"Real 1\"]\n    y = [\"Predict 0\", \"Predict 1\"]\n\n    fig = ff.create_table([header, score], height_constant=20)\n    fig.show()\n\n    fig = ff.create_annotated_heatmap(z=mc, x=x, y=y, colorscale=\"Blues\")\n    fig.show()","be1f8564":"y_pred = model.predict(X_test).round()\ny_pred_class = model.predict_proba(X_test)\nmetrics(y_test, y_pred, y_pred_class)","b3b16e8a":"## Metrics","4d19a118":"### Which correlations exist beteween the features?\nAs we can see on the graph the variables are ony relationed to Time, Amount and Class(Target). ","31957946":"There's no null value in the whole dataset.","da53e26f":"## Handling with unbalanced data","1418dfc9":"Amount columns must me normalize to be used in a machine learning model.","4e283506":"## Correlation to the target","7eaf8b04":"# Deep Neural Network","e3369af0":"# Imports\n\n#### This kernel is an approach to predict fraud in a credit card transaction but will analyse a data already preprocessed and imbalanced. The most columns are renamed and formated as V1~V29, and we have time and amount. Anyway, we can try to figure out a pattern or relationship between any one of those columns.","77eccdf4":"# The dataset","216b9d32":"### The PCA's features descriptions"}}