{"cell_type":{"79880601":"code","8178c5e5":"code","7f35bfd5":"code","007c1356":"code","52af4bab":"code","69da116e":"code","b3300920":"code","b9487c52":"code","61d76061":"code","3d96db41":"code","faaddfcb":"code","1b53a0a6":"code","2d0fd85f":"code","b3092b33":"code","260478ff":"code","3c3ea626":"code","ba061dd0":"code","cdf5a5ec":"code","7c3f58e5":"code","750fef10":"code","3ea0cd63":"code","64681960":"code","82fe1514":"code","5a14ffda":"code","e4823b5f":"code","79a84d87":"code","0b4111db":"code","cb42887e":"code","a66f1241":"code","e3eedf0e":"code","680da238":"code","16ee14d5":"code","457495a1":"code","b7265b1c":"code","e354eb13":"code","efe34cce":"code","b84e377a":"code","31d6c9ea":"code","8a84a43d":"code","ee4d14e4":"markdown","09bd38d1":"markdown","71b6b2ab":"markdown","3179e6d9":"markdown","ca3db4c8":"markdown","c4a7299a":"markdown","0ed29952":"markdown","aeb5b20e":"markdown","6bbba543":"markdown","c092f5d4":"markdown","e361fe8e":"markdown","6f1a069c":"markdown","daaded9f":"markdown","fe473393":"markdown","9c55ea09":"markdown","c475d395":"markdown","aa9bb8fd":"markdown","d1af0f0f":"markdown","5a73a28e":"markdown","0626682a":"markdown","5aeb0c64":"markdown","516d9dba":"markdown","a8c81e67":"markdown","98e5d41a":"markdown","bfed17c8":"markdown","5538cb54":"markdown","1cad901b":"markdown"},"source":{"79880601":"!pip install kats\n!pip install pmdarima\n!pip install tbats\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pmdarima as pm\nfrom kats.consts import TimeSeriesData\nfrom scipy import stats\nsns.set()\n\nfrom sklearn.metrics import mean_squared_error\nfrom pmdarima.arima import ndiffs\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8178c5e5":"dfbeer  = pd.read_csv('\/kaggle\/input\/monthly-beer-production\/datasets_56102_107707_monthly-beer-production-in-austr.csv')\ndfbeer['Month'] = pd.to_datetime(dfbeer['Month'])\ndfbeer.index = dfbeer['Month'] \ndfbeer.tail()","7f35bfd5":"dfbeer['Monthly beer production'].plot();","007c1356":"dfbeer['Monthly beer production'].plot();\ndfbeer['Monthly beer production'].rolling(12).mean().plot();","52af4bab":"fig, axes = plt.subplots(1, 2, figsize=(12,4))\n\nsns_graph = dfbeer.copy()\nsns_graph['year'] = sns_graph.index.year\nsns_graph['month'] = sns_graph.index.month\n\nsns.boxplot(x=\"year\", y=\"Monthly beer production\", data=sns_graph, ax = axes[0]);\nsns.boxplot(x=\"month\", y=\"Monthly beer production\", data=sns_graph, ax = axes[1]);","69da116e":"def plot_transformations_histograms(series, box_cox_lambda):\n    fig, axes = plt.subplots(1, 3, figsize=(12,3))\n\n    sns.histplot(series, ax = axes[0]);\n    axes[0].set_title('Histogram level')\n\n    sns.histplot(np.log(series), ax = axes[1]);\n    axes[1].set_title('Histogram log');\n\n    sns.histplot(stats.boxcox(series, lmbda = box_cox_lambda), ax = axes[2]);\n    axes[2].set_title('Histogram Box-Cox');\n    \nplot_transformations_histograms(dfbeer[\"Monthly beer production\"], 0.65)","b3300920":"np.log(dfbeer['Monthly beer production']).plot();","b9487c52":"keeptrain = len(dfbeer)-12\ntrain = np.log(dfbeer['Monthly beer production']).iloc[:keeptrain]\ntest = np.log(dfbeer['Monthly beer production']).iloc[keeptrain:]\ntrain.plot();","61d76061":"from statsmodels.tsa.seasonal import STL\nstl = STL(train, period=12, robust=True)\nres_STL = stl.fit()\nfig = res_STL.plot()","3d96db41":"ts1 = train - res_STL.seasonal\nts1.plot();","faaddfcb":"ts1_postbreak = ts1[ts1.index>'1974-01-01']\nts1_postbreak.plot();","1b53a0a6":"from statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import kpss\n\ndef test_stationarity(series, crit='BIC'):\n    print_tests = 'Stationarity tests \\n \\\n    P-values for: ADF with drift: {0:0.3f}, ADF drift and trend: {1:0.3f}, ADF no drift or trend: {2:0.3f} \\n \\\n    KPSS p-value: {3:0.3f}'\n    adftest_c = adfuller(series, autolag=crit, regression = 'c')\n    adftest_ct = adfuller(series, autolag=crit, regression = 'ct')\n    adftest_nc = adfuller(series, autolag=crit, regression = 'nc')\n    kpsstest = kpss(series)\n\n    return print(print_tests.format(adftest_c[1], adftest_ct[1], adftest_nc[1], kpsstest[1]))\n\ntest_stationarity(ts1, 't-stat')","2d0fd85f":"test_stationarity(ts1_postbreak, 't-stat')","b3092b33":"test_stationarity(ts1.diff().dropna(), 't-stat')\ntest_stationarity(ts1_postbreak.diff().dropna(), 't-stat')","260478ff":"def plot_acf_pacf(series, nlags):\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n    \n    sm.graphics.tsa.plot_acf(series, lags=nlags, ax = axes[0])\n    axes[0].set_title('Sample ACF')\n\n    sm.graphics.tsa.plot_pacf(series, lags=nlags, ax = axes[1])\n    axes[1].set_title('Sample PACF')\n    \n    return fig\n\nplot_acf_pacf(ts1.diff().dropna(), 36)","3c3ea626":"#initialize dicts to keep model results\nmse_models = {}\nforecast_models = {}","ba061dd0":"#we already know the data is not stationary, but can use the ndiffs function from pmdarima to confirm that it's I(1)\n\nadf_diffs = ndiffs(ts1, alpha=0.05, test='adf', max_d=12)\nadf_diffs","cdf5a5ec":"model = pm.auto_arima(train, start_p = 0, start_q = 0, \n                      max_p = 4, d = 1, max_q = 4, information_criterion='aic',\n                      test = 'adf', max_P=3, max_D=1, max_Q=3, m=12, trace=True,\n                      maxiter = 50, stepwise = True, seasonal=True)","7c3f58e5":"print(model.summary())","750fef10":"plot_acf_pacf(model.resid(), 36)","3ea0cd63":"forecast_mean_ci = model.predict(n_periods = len(test), return_conf_int=True) \nforecast = pd.DataFrame(forecast_mean_ci[0], index = test.index)\nforecast.columns = ['Forecast']\nforecast[['upper_ci','lower_ci']] = forecast_mean_ci[1]","64681960":"#graph\nplt.figure(figsize=(12, 8))\nplt.plot(forecast['Forecast'], color='r');\nplt.plot(train.iloc[-40:], color='black')\nplt.plot(test, color='b')\nplt.fill_between(forecast.index, forecast['upper_ci'], forecast['Forecast'], alpha = 0.1, color='darkslategrey')\nplt.fill_between(forecast.index, forecast['lower_ci'], forecast['Forecast'], alpha = 0.1, color='darkslategrey')\nplt.legend(['Forecast', 'Train', 'Test']);","82fe1514":"mean_squared_error(test, forecast['Forecast'])\nmse_models['SARIMA'] = mean_squared_error(test, forecast['Forecast'])\nforecast_models['SARIMA'] = forecast['Forecast']","5a14ffda":"from statsmodels.tsa.api import STLForecast\nfrom statsmodels.tsa.arima.model import ARIMA\n\nstlf = STLForecast(train, ARIMA, model_kwargs={\"order\": (2, 1, 3)}, robust=True)\nres_stl = stlf.fit()\nforecasts = res_stl.forecast(12)\nforecasts.plot()\ntest.plot();","e4823b5f":"print(mean_squared_error(test, forecasts))\nmse_models['STL_arima'] = mean_squared_error(test, forecasts)\nforecast_models['STL_arima'] = forecasts","79a84d87":"#pass the data to kats structure\nbeerts = TimeSeriesData(time=train.index, value=train)","0b4111db":"# import the param and model classes for Prophet model\nfrom kats.models.prophet import ProphetModel, ProphetParams\n\n# create a model param instance\nparams = ProphetParams(seasonality_mode='additive') \n\n# create a prophet model instance\nm = ProphetModel(beerts, params)\nm.fit()\nfcst = m.predict(steps=len(test), freq=\"MS\")","cb42887e":"m.plot()","a66f1241":"print(mean_squared_error(test, fcst['fcst']))\n\nmse_models['Fbprophet'] = mean_squared_error(test, fcst['fcst'])\nforecast_models['Fbprophet'] = fcst['fcst']","e3eedf0e":"from tbats import BATS\nestimator = BATS(seasonal_periods=[12])\nmodel_tbats = estimator.fit(train)\n\nprint(model_tbats.summary())","680da238":"forecast_tbats = pd.DataFrame(model_tbats.forecast(steps=len(test), confidence_level=0.95)[1], index = test.index)\nplt.plot(forecast_tbats['mean'], label='BATS')\nplt.plot(test, label = 'Test');\nplt.plot((pd.DataFrame(model_tbats.y_hat, index = train.index).iloc[-100:]))\nplt.plot((train.iloc[-100:]))\nplt.fill_between(test.index, forecast_tbats['lower_bound'], forecast_tbats['mean'], alpha = 0.1, color='darkslategrey')\nplt.fill_between(test.index, forecast_tbats['upper_bound'], forecast_tbats['mean'], alpha = 0.1, color='darkslategrey');","16ee14d5":"print(mean_squared_error(test, forecast_tbats['mean']))\n\nmse_models['BATS'] = mean_squared_error(test, forecast_tbats['mean'])\nforecast_models['BATS'] = forecast_tbats['mean']","457495a1":"plot_acf_pacf(model_tbats.resid, 36)","b7265b1c":"from statsmodels.tsa.holtwinters import ExponentialSmoothing\nfit = ExponentialSmoothing(train,  seasonal_periods=12,\n                           seasonal='mul', initialization_method=\"estimated\").fit()\nsimulations = fit.simulate(12, anchor='1994-09-01', repetitions=500,  random_errors='bootstrap')\n\nax = train.iloc[-100:].plot(figsize=(10,6), marker='o', color='black',\n               title=\"Forecasts and simulations from Holt-Winters' method\" )\nax.set_ylabel(\"Electricity Load Bulgaria\")\nax.set_xlabel(\"Year\")\nfit.fittedvalues.iloc[-100:].plot(ax=ax, style='--', color='green')\nsimulations.plot(ax=ax, style='-', alpha=0.05, color='grey', legend=False)\ntest.rename('Test data').plot(ax=ax, style='-',  color='red')\nfit.forecast(12).rename('Holt-Winters)').plot(ax=ax, style='--', marker='o', color='green', legend=True)\nplt.show()","e354eb13":"print(mean_squared_error(test, fit.forecast(12)))\n\nmse_models['Exponential_smoothing'] = mean_squared_error(test, fit.forecast(12))\nforecast_models['Exponential_smoothing'] = fit.forecast(12)","efe34cce":"mse_models","b84e377a":"forecast_models['STL_arima']","31d6c9ea":"np.exp(res_stl.forecast(28)[-12:])","8a84a43d":"np.exp(res_stl.forecast(28)).plot();","ee4d14e4":"We can visualize both the trend and seasonal components as boxplots as well. The months with the lowest beer production are May, June and July, which also correspomd to the Australian winter.","09bd38d1":"We can use an exponential smoothing model, in particular if we want to dampen the trend for the forecast. The exponential smoothing model, however, doesn't converge once a trend component is added, which is likely due to the structural break we observe in the trend.","71b6b2ab":"#### Model Diagnostics\nThe chosen model is SARIMAX(2, 1, 3)x(1, 0, 1). The Ljung-Box test shows that we cannot reject $H_0$ that the data is independently distributed, and this is further confirmed by the correlogram of the residuals.","3179e6d9":"The ACF and PACF plots can be used to study the autocorrelation structure of the residuals. If the PACF is decaying gradually, for example, while the ACF is showing only q-lags significant, this indicates an MA (q) process. From the plots below it seems like the process might be MA(1), but we need to investigate further.","ca3db4c8":"We can use auto arima for the grid-search of the optimal parameters for the SARMA model. We know that the series is I(1), and therefore set d=1. We use AIC as an information criterion, as the primary goal of the model is forecasting, rather than studying the in-sample properties of the data.","c4a7299a":"## Exploratory Data Analysis\n\nBy plotting the data, we can immediately spot two things: \n - repeating patterns at seemingly regular frequency - seasonal component\n - upward linear trend until around 1975, and a structural change afterwards. For the rest of the period, there seems to be no trend component.","0ed29952":"We can see some autocorrelation is left in the residuals, since the model did not pick up on the ARMA strucure.","aeb5b20e":"# Forecasting Models\nI explore different forecasting models, and will select the final one based on the MSE on the test data.\nThe models used here are:\n - SARIMA\n - STL model with ARMA structure (based on the auto SARIMA output)\n - Fbprophet\n - TBATS\n - Exponential Smoothing","6bbba543":"The data is monthly, so it is safe to assume that the seasonality is with a period of one year (12 months). A quick plot of the 12-month moving average confirms this assumption, and visualizes the trend component of the series. We can also see that the seasonal peaks increase with time, which is indicative of **multiplicative seasonality**.","c092f5d4":"# Overall Results\nWe can see that the model with the lowest MSE is the STL-ARIMA combination and this is the one we use for the forecast.","e361fe8e":"# 1996 Final Forecast","6f1a069c":"# Introduction\nThe notebook explores the data on beer production in Australia and provides forecasts from various models.\nAs a first step, I perform a short EDA on the data. The first step is to plot the time series and observe for any typical characteristics. \nOne way to respresent a time series is by assuming that the stochastic process $y_t$ can be represented as a combination of a trend, seasonal, cyclical and innovations components. We first try to break down the series into those components, in order to choose which model would perform better in terms of forecasting it (for example, if we find an ARMA structure in the innovations\/residuals term, Fbprophet might not be the best choice.)","daaded9f":"Time series data is often skewed and needs to undergo some distributional transformations. Both the log and Box-Cox transforms can be used for this. In this case, I choose the log-transform for two main reasons:\n - it seems like there is multiplicative seasonality in the series, which, after transformed into logs, becomes additive \n - the log-transform decreases the volatility of the series","fe473393":"I also keep the data only post- the structural break, so we can study if any changes have occured in the ARMA or stationarity characteristics of the data.","9c55ea09":"### Stationarity Tests\nFor most statistical time series models, we assume weak stationarity of the data. This implies that the mean and the autocovariance are constant over time, and together with the ergodicity assumptions, allows us the generalize the model findings.\nWe test both the series, after removing the seasonalc component, and the only the part of the series after the structural break. For the former we can use the ADF with a drift and trend, and for the latter the ADF with drift. Both tests show that the series is I(1), and therefore we need to model its first difference, rathr than the series itself. This allows us to use the entire series for modelling, rather than only the post-structural break part.","c475d395":"We can remove the seasonal component, in order to better study the trend and residuals.","aa9bb8fd":"## Additional Models","d1af0f0f":"We can also explore the Fbprophet, exponential smoothing, and TBATS models. FBprophet does a good job capturing seasonal effects, but is perhaps more useful for higher-frequency data, and further is unable to uncover the ARMA structure of the residuals. TBATS can be used for capturing multiple seasonalities (both daily and quarterly, for example) due to its trigonometric regressors, which we do not observe in our data. In this case therefore, we will use the BATS model. \nOverall, our data exhibits strong monthly seasonality, structural break in the trend, there seems to be no cylical component, but there is a well defined ARMA structure of the residuals. All of the above hint that the SARIMA model or the STL-ARMA combination will outperform the other models.","5a73a28e":"### FB Prophet Model","0626682a":"### Exponential Smoothing","5aeb0c64":"### BATS model","516d9dba":"## STL model with ARMA structure\nWe can take advantage of the ARMA structure uncovered in the auto-SARIMA grid search, and use it to forecast with the STL model for the seasonal decomposition.","a8c81e67":"We can use the statsmodels STL decomposition to further explore the break-down of the series into its respective components.","98e5d41a":"#### Model Forecast\nWe can plot the forecast with the confidence intervals.","bfed17c8":"### Auto SARIMA model","5538cb54":"### Arma structure of the residuals","1cad901b":"I split the data into train and test. In order to preserve the temporal relationship in the series, the split is done in the time dimension. I keep only the last one year as tast data, since the structural break has happened rather recently in history so I prefer to keep more of the post-structural break data for the model training. Further, the model would not be used for longer-term forecasts (more than one year), and therefore we are less interested in how it generalizes long-term than in the short-run."}}