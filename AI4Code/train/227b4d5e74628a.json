{"cell_type":{"25c2f8ac":"code","cf8d6323":"code","c8210676":"code","88c934fc":"code","b2624910":"code","5b4bc7b3":"code","ea3f39a0":"code","e7ff8f4f":"code","caaf591a":"code","71f79a82":"code","f14aa249":"code","fe6c9219":"code","31295552":"code","e45b951d":"code","369c7a3a":"code","67c85357":"code","9b3eebd6":"code","8e6ab7d7":"code","d3613f86":"code","32ba1c3e":"code","279563e9":"code","18915383":"code","88d8d5ec":"code","814432b7":"code","d9d6e799":"code","c1d26331":"code","899da826":"code","d2a89f29":"code","fc23fefb":"code","47ec4a71":"code","0c6e6526":"code","9b76c31a":"code","481c1403":"code","cd670494":"code","6c6b5610":"code","c71e8369":"code","563661fd":"code","f74d6ef3":"code","eb67f42a":"code","d5f123bd":"markdown","6f7a50d9":"markdown","f8de3f82":"markdown","6cbbba89":"markdown","a70a60ae":"markdown","0e9ce9dd":"markdown","d647c635":"markdown","5fe11574":"markdown","cd90e66c":"markdown","4fa9ea99":"markdown","84eb5725":"markdown"},"source":{"25c2f8ac":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn import datasets","cf8d6323":"from keras.datasets import mnist\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.utils.np_utils import to_categorical","c8210676":"import cv2\nimport os\nimport glob\nimport gc\n\n# Lire_image permettra de lire les images dans les sous-r\u00e9pertoires\n\ndef lire_images(img_dir, xdim, ydim, nmax=5000) :\n    label = 0\n    label_names = []\n    X = []\n    y=[]\n    for dirname in os.listdir(img_dir):\n        print(dirname)\n        label_names.append(dirname)\n        data_path = os.path.join(img_dir + \"\/\" + dirname,'*g')\n        files = glob.glob(data_path)\n        n=0\n        for f1 in files:\n            if n>nmax : break\n            img = cv2.imread(f1)\n            img = cv2.resize(img, (xdim,ydim))\n            X.append(np.array(img))\n            y.append(label)\n            n=n+1\n        print(n,' images lues')\n        label = label+1\n    X = np.array(X)\n    y = np.array(y)\n    gc.collect()\n    return X,y, label, label_names","88c934fc":"X,y,nlabels,names = lire_images('..\/input\/chest-xray-pneumonia\/chest_xray\/test', 224, 224, 2000)","b2624910":"names","5b4bc7b3":"import random\nplt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    j = random.randint(0,len(X))\n    plt.axis('off')\n    plt.imshow(X[j])\n    plt.title(names[y[j]])","ea3f39a0":"y = to_categorical(y)","e7ff8f4f":"X.shape","caaf591a":"X = X \/ 255\nprint(X[0][0])","71f79a82":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","f14aa249":"del X,y","fe6c9219":"# R\u00e9seau convolutionnel simple\nmodel = Sequential()\nmodel.add(Conv2D(32, (5, 5), input_shape=(224, 224, 3), activation='relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\n#model.add(Dense(128, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","31295552":"model.summary()","e45b951d":"# Apprentissage\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=1)","369c7a3a":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(scores)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","67c85357":"# Fonction pour afficher graphiquement les scores\ndef plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","9b3eebd6":"plot_scores(train)","8e6ab7d7":"# Prediction\ny_cnn = model.predict_classes(X_test)","d3613f86":"plt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        plt.title('%s \/ %s' % (names[y_cnn[j]], names[y_test[j].argmax(axis=-1)]))\n        i+=1","32ba1c3e":"# Mod\u00e8le CNN plus profond\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","279563e9":"model.summary()","18915383":"# Apprentissage\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200, verbose=1)\n\n# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","88d8d5ec":"#sauvegarde du modele entrain\u00e9\nmodel.save('mnist_cnn2.h5')","814432b7":"new_model = load_model('mnist_cnn2.h5')\nnew_model.summary()","d9d6e799":"scores = new_model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","c1d26331":"from keras.applications import VGG16","899da826":"vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\nvgg16.trainable = False","d2a89f29":"vgg16.summary()","fc23fefb":"model = Sequential()\nmodel.add(vgg16)\nmodel.add(Flatten())\nmodel.add(Dense(49, activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","47ec4a71":"model.summary()","0c6e6526":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=1)","9b76c31a":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","481c1403":"for i in range (len(vgg16.layers)):\n    print (i,vgg16.layers[i])","cd670494":"for layer in vgg16.layers[15:]:\n    layer.trainable=True\nfor layer in vgg16.layers[0:15]:\n    layer.trainable=False","6c6b5610":"model = Sequential()\nmodel.add(vgg16)\nmodel.add(Flatten())\nmodel.add(Dense(49, activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","c71e8369":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=1)","563661fd":"plot_scores(train)","f74d6ef3":"y_cnn = model.predict_classes(X_test)","eb67f42a":"plt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        plt.title('%s \/ %s' % (names[y_cnn[j]], names[y_test[j].argmax(axis=-1)]))\n        i+=1","d5f123bd":"Affichage des fausse predictions, o\u00f9 notre modele s'est tromp\u00e9","6f7a50d9":"### Modele CNN plus profond","f8de3f82":"### Modele CNN avec une seul couche convolutionnelle","6cbbba89":"### Transfert learning : Modele VGG16 (Modele pr\u00e9d\u00e9fini)","a70a60ae":"## Lecture des images","0e9ce9dd":"Parfait on s'est tromp\u00e9 une seul fois c'est tres bien.","d647c635":"## Pr\u00e9paration de la data","5fe11574":"## Importation des biblio","cd90e66c":"Affichage de la structure du modele","4fa9ea99":"Affichage al\u00e9atoire des images","84eb5725":"## Construction du modele"}}