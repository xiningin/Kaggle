{"cell_type":{"ca877499":"code","1f408f56":"code","fec137c9":"code","018aa8a5":"code","833ca6a5":"code","6f1639d7":"code","33db995e":"code","76801401":"code","c72b71f8":"code","813c158c":"code","67c98f10":"code","8e09ca4a":"code","69e17546":"code","d844a129":"code","a23ef8a3":"code","fd8596c6":"code","ce9e1633":"code","dd2bf0f3":"code","06395da8":"code","32c22de5":"code","0bc821dd":"code","7caac26d":"markdown","219ef683":"markdown","ad3da418":"markdown","67cdaf38":"markdown","8d6a2b84":"markdown","aebb908d":"markdown","f94242cd":"markdown","ab1f39d0":"markdown","3bccb2ba":"markdown","8ce385ca":"markdown","6cfe2917":"markdown","fa4b365b":"markdown","4f30eea0":"markdown","1211fa81":"markdown","d8eb8999":"markdown","38482eee":"markdown","5b9121aa":"markdown","f2636db7":"markdown"},"source":{"ca877499":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport skimage.io\nimport skimage.transform\nimport keras\nfrom keras.layers import Conv2D,Dropout,Flatten,Dense,MaxPool2D\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.utils import plot_model\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom keras.applications.vgg16 import VGG16","1f408f56":"trn_path = \"..\/input\/dataset\/dataset_updated\/training_set\/\"\ntest_path = \"..\/input\/dataset\/dataset_updated\/validation_set\/\"\n\ncats = ['drawings', 'engraving', 'iconography', 'painting', 'sculpture']\nn_cats = len(cats)\ncategory_embeddings = {\n    'drawings': 0,\n    'engraving': 1,\n    'iconography': 2,\n    'painting': 3,\n    'sculpture': 4\n}\n\nwidth,height,channels = 128,128,3\nbatchsize = 16","fec137c9":"# training dataset metadata\nn_imgs = []\nfor cat in cats:\n    files = os.listdir(os.path.join(trn_path, cat))\n    n_imgs += [len(files)]\n    \nplt.bar([_ for _ in range(n_cats)], n_imgs, tick_label=cats)\nplt.show()","018aa8a5":"#lets visualize some of the images\nfig,axes = plt.subplots(nrows=1,ncols=n_cats,figsize=(15,3))\n\ncat_cpt=0\nfor cat in cats:\n    category_path = os.path.join(trn_path,cat)\n    img_name=os.listdir(category_path)[0]\n    img = skimage.io.imread(os.path.join(category_path,img_name))\n    img = skimage.transform.resize(img,(width,height,channels),mode='reflect')\n    axes[cat_cpt].imshow(img,resample=True)\n    axes[cat_cpt].set_title(cat,fontsize=8)\n    cat_cpt += 1\n\nplt.show()","833ca6a5":"#create the training dataset which will be tuples\n#will be used to read images batch by batch\ntrn_data = []\nfor cat in cats:\n    files = os.listdir(os.path.join(trn_path,cat))\n    for file in files:\n        trn_data += [(os.path.join(cat,file),cat)]\n        \n        \ntest_data = []\nfor cat in cats:\n    files = os.listdir(os.path.join(test_path,cat))\n    for file in files:\n        test_data += [(os.path.join(cat,file),cat)]","6f1639d7":"def load_dataset(tuples_list, dataset_path):\n    indexes = np.arange(len(tuples_list))\n    np.random.shuffle(indexes)\n    \n    X = []\n    y = []\n    n_samples = len(indexes)\n    cpt = 0\n    for i in range(n_samples):\n        t = tuples_list[indexes[i]]\n        try:\n            img = skimage.io.imread(os.path.join(dataset_path, t[0]))\n            img = skimage.transform.resize(img, (width, height,channels), mode='reflect')\n            X += [img]\n            y_tmp = [0 for _ in range(n_cats)]\n            y_tmp[category_embeddings[t[1]]] = 1\n            y += [y_tmp]\n        except OSError:\n            pass\n        \n        cpt += 1\n        \n        if cpt % 1000 == 0:\n            print(\"Processed {} images\".format(cpt))\n    return X, y","33db995e":"x_train, y_train = load_dataset(trn_data, trn_path)\nx_val, y_val = load_dataset(test_data, test_path)","76801401":"print(len(x_train))\nprint(len(y_train))\nprint(len(x_val))\nprint(len(y_val))","c72b71f8":"x_train = np.array(x_train)\ny_train = np.array(y_train)","813c158c":"x_val=np.array(x_val)\ny_val=np.array(y_val)","67c98f10":"x_train.shape","8e09ca4a":"y_train.shape","69e17546":"x_val.shape","d844a129":"y_val.shape","a23ef8a3":"#data augmentation\ntrn_augs = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\ntrn_augs.fit(x_train)","fd8596c6":"tmodel = Sequential()\ntmodel.add(Conv2D(32, kernel_size=5, input_shape=(width, height,channels), activation='relu'))\ntmodel.add(MaxPool2D(pool_size=(2, 2)))\ntmodel.add(Conv2D(48, kernel_size=3, activation='relu'))\ntmodel.add(MaxPool2D(pool_size=(2, 2)))\ntmodel.add(Dropout(0.35))\ntmodel.add(Flatten())\ntmodel.add(Dense(512, activation='relu'))\ntmodel.add(Dropout(0.25))\ntmodel.add(Dense(256,activation='relu'))\ntmodel.add(Dropout(0.10))\ntmodel.add(Dense(n_cats, activation='softmax'))\n\ntmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\ntmodel.summary()","ce9e1633":"trn_gen = trn_augs.flow(x_train,y_train,batch_size=batchsize)\n\nhistory = tmodel.fit_generator(trn_gen,\n                              validation_data=(x_val,y_val),\n                              epochs=30,\n                              verbose=1,\n                              steps_per_epoch=200)","dd2bf0f3":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 3))\n\naxes[0].plot(history.history['loss'], label=\"Loss\")\naxes[0].plot(history.history['val_loss'], label=\"Validation loss\")\naxes[0].set_title('Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].legend()\n\n\naxes[1].plot(history.history['acc'], label=\"Accuracy\")\naxes[1].plot(history.history['val_acc'], label=\"Validation accuracy\")\naxes[1].set_title('Accuracy')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy')\naxes[1].legend()\nplt.tight_layout()\n\nplt.show()\n\n","06395da8":"X_test = []\ny_test = []\nfor t in test_data:\n    try:\n        img = skimage.io.imread(os.path.join(test_path, t[0]))\n        img = skimage.transform.resize(img, (width, height, channels), mode='reflect')\n        X_test += [img]\n        y_test += [category_embeddings[t[1]]]\n    except OSError:\n        pass\n\nX_test = np.array(X_test)\ny_test = np.array(y_test)","32c22de5":"pred = tmodel.predict(X_test, verbose=1)\n\ny_pred = np.argmax(pred, axis=1)\nprint(classification_report(y_test, y_pred))\n\ncmatrix = confusion_matrix(y_test, y_pred)\nplt.imshow(cmatrix, cmap=plt.cm.Blues)\nplt.title(\"Confusion matrix\")\nplt.colorbar()\nplt.show()\nprint(cmatrix)","0bc821dd":"plot_model(tmodel,to_file='model.png')","7caac26d":"### 9.\u8fd9\u4f7f\u7528\u6570\u636e\u589e\u5f3a\u521b\u5efa\u4e00\u4e2a\u751f\u6210\u5668\u3002\u63a5\u4e0b\u6765\u8c03\u7528\u201cfit_generator()\u201d\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u6dfb\u52a0\u201chistory\u201d\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u53ef\u89c6\u5316\u4e4b\u540e\u7684\u8bad\u7ec3","219ef683":"### 10.\u4f7f\u7528\u5728\u201cfit_generator()\u201d\u4e4b\u524d\u8c03\u7528\u7684\u201chistory\u201d\u6765\u67e5\u770b\u5404\u4e2a\u65f6\u4ee3\u7684\u635f\u5931\u548c\u51c6\u786e\u6027","ad3da418":"\u4f60\u5c06\u5b66\u5230\u4ec0\u4e48:<br\/>\n1.\u4f7f\u7528Keras\u5e93\u8fdb\u884c\u5206\u7c7b\u4efb\u52a1<br\/>\n2.\u4f7f\u7528keras\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60<br\/>\n3.\u6570\u636e\u589e\u5f3a<br\/>","67cdaf38":"# \u6709\u5173\u827a\u672f\u753b\u4f5c\u5206\u7c7b\u7684 Kaggle \u6bd4\u8d5b\u7ecf\u9a8c\u5206\u4eab","8d6a2b84":"### 13.\u4f7f\u7528\u201cplot_model()\u201d\u6765\u83b7\u5f97\u6a21\u578b\u67b6\u6784\u7684\u56fe\u50cf\uff0c\u6211\u5c06\u5728\u4e0b\u9762\u663e\u793a","aebb908d":"### 3.\u6309\u7c7b\u522b\u5c06\u8bad\u7ec3\u56fe\u50cf\u8fdb\u884c\u53ef\u89c6\u5316","f94242cd":"\u6982\u8ff0:<br\/>\n\u5728\u8fd9\u4e2a\u9879\u76ee\u4e2d\uff0c\u6211\u5c06\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6Keras\u5bf9kaggle\u6570\u636e\u96c6\u4e2d\u7684\u4e0d\u540c\u827a\u672f\u4f5c\u54c1\u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u3002","ab1f39d0":"### 4.\u5c06\u6765\u81ea\u4e0d\u540c\u7c7b\u7684\u4e00\u4e9b\u56fe\u50cf\u8fdb\u884c\u53ef\u89c6\u5316","3bccb2ba":"\u6e90\u4ee3\u7801:<br\/>\nhttps:\/\/github.com\/Terrance-Whitehurst\/Keras-Art-Images-Classification\/blob\/master\/Keras%20Artwork%20Classification.ipynb ","8ce385ca":"### 11.\u521b\u5efa\u4e00\u4e2a\u6d4b\u8bd5\u96c6\u6765\u83b7\u5f97\u9884\u6d4b","6cfe2917":"### 8.\u8fd9\u662f\u6700\u7ec8\u6a21\u578b\u3002\u5b83\u662f\u4e00\u4e2a\u4e24\u5c42\u7f51\u7edc\uff0c\u6709\u4e24\u4e2a\u5bc6\u96c6\u7684\u5c42\u548c\u4e00\u4e2a\u8f93\u51fa\u5c42\u3002\u5728\u6211\u4eec\u5b8c\u6210\u6a21\u578b\u67b6\u6784\u4e4b\u540e\uff0c\u6211\u4eec\u8fd8\u5fc5\u987b\u5728\u57f9\u8bad\u4e4b\u524d\u7f16\u8bd1\u6a21\u578b","fa4b365b":"## \u5f00\u59cb ","4f30eea0":"### 5.\u4f7f\u7528for\u5faa\u73af\u521b\u5efa\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e","1211fa81":"### 7.\u4f7f\u7528keras\u7684\u201cImageDataGenerator()\u201d\u6765\u589e\u5f3a\u6570\u636e\u3002\u7136\u540e\u5c06\u8bad\u7ec3\u6570\u636e\u4e0e\u6269\u5145\u76f8\u5339\u914d","d8eb8999":"### 6.\u5b9a\u4e49\u51fd\u6570\u6765\u52a0\u8f7d\u6570\u636e\u96c6","38482eee":"### 12.\u8c03\u7528\u201cpredict()\u201d\u6765\u83b7\u5f97\u9884\u6d4b\uff0c\u7136\u540e\u521b\u5efa\u4e00\u4e2a\u5206\u7c7b\u62a5\u544a\u548c\u6df7\u6dc6\u77e9\u9635\uff0c\u4ee5\u67e5\u770b\u6a21\u578b\u505a\u5f97\u6709\u591a\u597d!","5b9121aa":"### 2.\u52a0\u8f7d\u4e86\u8bad\u7ec3\u548c\u9a8c\u8bc1\u96c6\u4ee5\u53ca\u827a\u672f\u56fe\u50cf\u7684\u7c7b\u522b\u3002\u8fd8\u8bbe\u7f6e\u4e86\u4e00\u4e9bhyper\u53c2\u6570\uff0c\u4ee5\u4fbf\u5728\u57f9\u8bad\u548c\u52a0\u8f7d\u6a21\u578b\u65f6\u4f7f\u7528","f2636db7":"### 1.\u9996\u5148\u5bfc\u5165\u6240\u6709\u7684\u4f9d\u8d56\u9879"}}