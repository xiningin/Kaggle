{"cell_type":{"da230624":"code","797d9cef":"code","041f79bd":"code","9cbd9667":"code","433ee409":"code","bd7eee73":"markdown","9fd1825f":"markdown","099a37f6":"markdown","7ee240d6":"markdown","d9539991":"markdown","d905c3a0":"markdown","6d98f87e":"markdown","a7595c3e":"markdown","1f40f209":"markdown","28c5776b":"markdown","a46103dc":"markdown","737ca43d":"markdown","edbd1424":"markdown"},"source":{"da230624":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","797d9cef":"dataset = pd.read_csv('..\/input\/position-salaries\/Position_Salaries.csv')\nX = dataset.iloc[:, 1:-1].values\ny = dataset.iloc[:, -1].values","041f79bd":"from sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\nregressor.fit(X, y)","9cbd9667":"regressor.predict([[6.5]])","433ee409":"X_grid = np.arange(min(X), max(X), 0.01)\nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.scatter(X, y, color = 'red')\nplt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\nplt.title('Truth or Bluff (Random Forest Regression)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","bd7eee73":"For better understanding of current notebook for beginners go through the links:\n\n [1.1 Data Preprocessing](http:\/\/www.kaggle.com\/saikrishna20\/data-preprocessing-tools)\n\n\n[1.2 Simple linear Regression](https:\/\/www.kaggle.com\/saikrishna20\/1-2-simple-linear-regression) \n\n\n[1.3 Multiple linear Regression with Backward Elimination](http:\/\/www.kaggle.com\/saikrishna20\/1-3-multiple-linear-regression-backward-eliminat)\n\n[1.4 Polynomial Linear Regression](https:\/\/www.kaggle.com\/saikrishna20\/1-4-polynomial-linear-regression)\n\n[1.5 Support Vector Regression (SVR)](https:\/\/www.kaggle.com\/saikrishna20\/1-5-support-vector-regression-svr\/edit\/run\/37240657)\n\n[1.6 Decision Tree Regressor](https:\/\/www.kaggle.com\/saikrishna20\/1-6-decision-tree-regression)\nDefinetely go through the decision tree link\n\nIt basically tells u about the preprocessing & Linear Regression which will help u in understanding this notebook better","9fd1825f":"# 1.7 Random Forest Regression","099a37f6":"## Training the Random Forest Regression model on the whole dataset","7ee240d6":"## Importing the dataset","d9539991":"## Importing the libraries","d905c3a0":"we can say that random forset is a whole large group of decision trees built from the subset of the dataset and their target is predicted by taking the majority of decision tree target in case of clasiificaion and average of decision tree target incase of regression.","6d98f87e":"For a better understanding of Random Forest if u don't have any idea whatsoever, visit the links:\n[Random Forest Intuition](https:\/\/www.youtube.com\/watch?v=LIPtRVDmj1M)","a7595c3e":"## Predicting a new result","1f40f209":"n_estimators (int) default=100\nThe number of trees(Decision Trees) in the forest.","28c5776b":"# Like this notebook then upvote it.\n\n\n# Need to improve it then comment below.\n\n\n# Enjoy Machine Learning","a46103dc":"Here we will predict each value i.e. 1.01 , 1.02, 1.03,1.04 and so.... on untill 10.00 and plot these outcomes for a wider understanding.","737ca43d":"As the Position level is increasing there are more steps in the model.\n\n1.5 to 2.5 salary is same\n\n2.5 to 3.0 \n\n3.0 to 3.5\n\n3.5 to 4.0\n\n4.0 to 4.5\n\n4.5 to 5.0 \n\n5.0 to 5.5 \n\nu can clearly see the change in 7 to 7.5 and 7.5 to 8.0 there is a hike in salary.\n\nIn the decision tree the range is constant and is higher.\n\nIn the random forest the range is constant and is lower for a certain values whose salary is same, that's what the model is pedicting by using a 10 decision trees. By combining multiple trees we get forest.","edbd1424":"## Visualising the Random Forest Regression results (higher resolution)"}}