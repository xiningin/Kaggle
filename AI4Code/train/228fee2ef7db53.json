{"cell_type":{"31b769c5":"code","4d71bc8e":"code","eb449f01":"code","f932e32d":"code","2d272872":"code","981603fa":"code","51d22e7a":"code","2ba35e7f":"code","0ff1219d":"code","77b8ac69":"code","d6f56f01":"code","59b6c98e":"code","afce6c40":"code","eaee8aea":"code","d85a282a":"code","1897e78c":"code","ceae55f5":"code","ce35b361":"code","9444ce27":"code","02d2642f":"code","1bffbf74":"code","88aa5d5d":"code","298c01c2":"code","820cab97":"code","aaa88ec3":"code","700b843d":"code","6a5a42b7":"markdown","9a2fd215":"markdown","5a60ee63":"markdown","ea85e38f":"markdown","450384e7":"markdown","87d0217b":"markdown","a86cc772":"markdown","fbee62f6":"markdown","a2fab716":"markdown","e3fe0614":"markdown","03d4abab":"markdown","bdc47cb7":"markdown","d634e100":"markdown","1db0f4b8":"markdown","08a647ae":"markdown","8a13cff3":"markdown","45ed427b":"markdown","c9f3d6d2":"markdown","5fbda284":"markdown","25d63f62":"markdown","3f2a95e9":"markdown","f99d6310":"markdown","aadeba24":"markdown","b119a3d6":"markdown","c962be20":"markdown","48d43bf4":"markdown","ba04cba3":"markdown","866d63e3":"markdown","460ead6b":"markdown","bf82b2de":"markdown","8d2043aa":"markdown","cf441a27":"markdown","431e9780":"markdown","64a977a1":"markdown"},"source":{"31b769c5":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb\n\ntrain_df = pd.read_csv(\"..\/input\/learn-together\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/learn-together\/test.csv\")","4d71bc8e":"train_df.head()","eb449f01":"print('Train set size: ', train_df.shape)\nprint('Test set size: ' , test_df.shape)","f932e32d":"print(\"Missing values in train set: \", train_df.isna().any().any())\nprint(\"Missing values in test set: \", test_df.isna().any().any())","2d272872":"train_df.describe()","981603fa":"cat_cols_filter = train_df.columns.str.startswith(('Soil', 'Wild'))\ncat_col_names = train_df.loc[:, cat_cols_filter].columns.values\n\n# Iterate through categorcial columns in both train and tests sets to find differences in unique values\n# It is also good to know how many unique values are there to help decide what to do in case mismatch is found\nfor col in cat_col_names:\n    if set(train_df[col].unique()) != set(test_df[col].unique()):\n        print(f'Col [{col}] value \/ count:')\n        print('-------------- train -----------')\n        print(f'{train_df[col].value_counts().to_string()}')\n        print('-------------- test ------------')\n        print(f'{test_df[col].value_counts().to_string()}\\n')\n","51d22e7a":"train_df['Cover_Type'].value_counts().plot.bar();","2ba35e7f":"num_col_names = [cname for cname in train_df.columns.values if (cname not in cat_col_names) and (cname != 'Cover_Type')]\ncorr_matrix_df = train_df[num_col_names].corr()\n\n# Since Pandas do not have a built-in heatmap plot, I'm using pyplot and seaborn here instead\nfig, ax = plt.subplots(figsize=(10,10)) \nsns.heatmap(corr_matrix_df, annot=True, ax=ax);","0ff1219d":"train_prep_df = train_df.copy()\ntest_prep_df = test_df.copy()\n\ntrain_prep_df.drop([\"Id\"], axis = 1, inplace=True)\ntest_ids = test_df[\"Id\"]\ntest_prep_df.drop([\"Id\"], axis = 1, inplace=True)\n\ntrain_prep_df.drop([\"Soil_Type7\", \"Soil_Type15\"], axis = 1, inplace=True)\ntest_prep_df.drop([\"Soil_Type7\", \"Soil_Type15\"], axis = 1, inplace=True)\n\nfeature_names = [f for f in train_prep_df.columns.values if f != 'Cover_Type']\ntarget_name = 'Cover_Type'\n\n#to make sure I got it right\nprint(len(feature_names)) #should be 56-3-1 = 52","77b8ac69":"X_train, X_val, y_train, y_val = train_test_split(train_prep_df[feature_names], train_prep_df[target_name], test_size=0.2, random_state=0)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","d6f56f01":"rf_model = RandomForestClassifier(n_jobs=4, random_state=0)\nrf_model.fit(X_train, y_train)","59b6c98e":"xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=7, n_jobs=4, seed=0)\nxgb_model.fit(X_train, y_train)","afce6c40":"rf_train_score = rf_model.score(X_train, y_train)\nrf_val_score = rf_model.score(X_val, y_val)\nprint('RF train score: ', rf_train_score)\nprint('RF val score: ', rf_val_score)\n\nxgb_train_score = xgb_model.score(X_train, y_train)\nxgb_val_score = xgb_model.score(X_val, y_val)\nprint('XGB train score: ', xgb_train_score)\nprint('XGB val score: ', xgb_val_score)","eaee8aea":"test_preds_rf = rf_model.predict(test_prep_df)\ntest_preds_xgb = xgb_model.predict(test_prep_df)\n\noutput = pd.DataFrame({'Id': test_ids, 'Cover_Type': test_preds_rf})\noutput.to_csv('initial_rf.csv', index=False);\n\noutput = pd.DataFrame({'Id': test_ids, 'Cover_Type': test_preds_xgb})\noutput.to_csv('initial_xgb.csv', index=False);\n\nprint('Done!')","d85a282a":"# First I will create a new dataframe to hold the feature importance values, so that it is easier to plot them \nfeature_df = pd.DataFrame({'feature': feature_names, 'importance': rf_model.feature_importances_})\nax = feature_df.sort_values('importance', ascending=False).plot.bar(x='feature', figsize=(15, 6), fontsize=12)","1897e78c":"# What value is the cut-off border? \nprint(feature_df[feature_df['feature']=='Soil_Type20'])\n\n#store this value\ncutoff = feature_df[feature_df['feature']=='Soil_Type20']['importance'].values[0]\nprint('\\nCut-off val: ', cutoff)","ceae55f5":"cols_to_keep = feature_df[feature_df['importance']>cutoff]['feature']\n\n# Prepare new set of training \/ validation data\nX_train_new, X_val_new, y_train_new, y_val_new = train_test_split(train_prep_df[cols_to_keep], train_prep_df[target_name], test_size=0.2, random_state=1)\nprint('New train \/ val data shape: ', X_train_new.shape, X_val_new.shape, y_train_new.shape, y_val_new.shape)\n\n# Also modify test data set accordingly\ntest_new_df = test_prep_df[cols_to_keep]\nprint('New test data shape: ', test_new_df.shape)","ce35b361":"rf_model_new = RandomForestClassifier(n_jobs=4, random_state=0);\nrf_model_new.fit(X_train_new, y_train_new);\n\nrf_train_score_new = rf_model_new.score(X_train_new, y_train_new)\nrf_val_score_new = rf_model_new.score(X_val_new, y_val_new)\nprint('RF new train score: ', rf_train_score_new)\nprint('RF new val score: ', rf_val_score_new)\nprint('RF old val score: ', rf_val_score)\n\nxgb_model_new = xgb.XGBClassifier(objective='multi:softmax', num_class=7, n_jobs=4, seed=0)\nxgb_model_new.fit(X_train_new, y_train_new);\n\nxgb_train_score_new = xgb_model_new.score(X_train_new, y_train_new)\nxgb_val_score_new = xgb_model_new.score(X_val_new, y_val_new)\nprint('\\nXGB new train score: ', xgb_train_score_new)\nprint('XGB new val score: ', xgb_val_score_new)\nprint('XGB old val score: ', xgb_val_score)","9444ce27":"# check out scikit and xgb docs for more info on which params are best suited for tuning\n\n# RF initial random search through params \n#random_params = {\n#    'n_estimators': [100,200,400,800],\n#    'max_features': [\"sqrt\", None, \"log2\"],\n#    'max_depth': [None, 50, 100, 200, 400, 800, 1600],\n#    'min_samples_split': [2, 5],\n#    'bootstrap': [True, False],\n#}\n#\n# RandomizedSearchCV and GridSearchCV already include cross-validation functionality, and return a model that will be ready for training accordingly\n#rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(random_state=0), param_distributions=random_params, scoring='accuracy', n_iter=200, cv=5, n_jobs=4, verbose=10, random_state=0)\n#rf_random.fit(X_train_new, y_train_new)\n#\n# Grid search through reduced list of params\n#tune_params = {\n#    'n_estimators': [200,400,800],\n#    'max_features': [\"sqrt\", None],\n#    'max_depth': [None, 100, 400],\n#    'min_samples_split': [2],\n#    'bootstrap': [False],\n#}\n#\n#rf_tuned = GridSearchCV(RandomForestClassifier(random_state=0), tune_params, scoring='accuracy', cv=5, scoring='accuracy', n_jobs=4, verbose=10)\n#rf_tuned.fit(X_train_new, y_train_new)\n","02d2642f":"# XGBoost grid search\n#xgb_clf = xgb.XGBClassifier(objective='multi:softmax', num_class=7, n_jobs=4, seed=0)\n#\n# Grid search through reduced list of params\n#random_params = {\n#        'n_estimators': [100,200, 400, 800],\n#        'min_child_weight': [1, 5, 10],\n#        'gamma': [0.5, 1, 1.5, 2, 5],\n#        'subsample': [0.6, 0.8, 1.0],\n#        'colsample_bytree': [0.6, 0.8, 1.0],\n#        'learning_rate': [0.1,0.05,0.001],\n#        'max_depth': [3, 4, 5, 10]\n#}\n#\n#xgb_random = RandomizedSearchCV(estimator = xgb_clf, param_distributions=random_params, scoring='accuracy',n_iter=500, cv=5, n_jobs=4, verbose=10, random_state=0)\n#xgb_random.fit(X_train_new, y_train_new)","1bffbf74":"#RF results\n#rf_random_val_score = rf_random.score(X_val_new, y_val_new)\n#rf_tuned_val_score = rf_random.score(X_val_new, y_val_new)\n#\n#print(\"Best parameter set found in random search:\")\n#print()\n#print(rf_random.best_params_)\n#print()\n#print('RF random val score: ', rf_random_val_score)\n#print('RF random val score improvement vs previous: ', rf_random_val_score - rf_val_score_new)\n#\n#print(\"\\nBest parameter set found in grid search:\")\n#print()\n#print(rf_tuned.best_params_)\n#print()\n#print('RF tunded val score: ', rf_tuned.score(X_val_new, y_val_new))\n#print('RF tuned val score improvement vs previous: ', rf_tuned_val_score - rf_val_score_new)\n\n#XGB results\n#xgb_random_val_score = xgb_random.score(X_val_new, y_val_new)\n#xgb_tuned_val_score = xgb_random.score(X_val_new, y_val_new)\n#\n#print(\"Best parameter set found in random search:\")\n#print()\n#print(xgb_random.best_params_)\n#print()\n#print('XGB random val score: ', xgb_random_val_score)\n#print('XGB random val score improvement vs previous: ', xgb_random_val_score - xgb_val_score_new)\n#\n#print(\"\\nBest parameter set found in grid search:\")\n#print()\n#print(rf_tuned.best_params_)\n#print()\n#print('XGB tunded val score: ', xgb_tuned.score(X_val_new, y_val_new))\n#print('XGB tuned val score improvement vs previous: ', xgb_tuned_val_score - xgb_val_score_new)","88aa5d5d":"rf_tuned = RandomForestClassifier(bootstrap=False, max_depth=45, max_features='sqrt', min_samples_split=2, min_samples_leaf=1, n_estimators=950, random_state=0, n_jobs=4);\nrf_tuned.fit(X_train_new, y_train_new);\n\nrf_tuned_train_score = rf_tuned.score(X_train_new, y_train_new)\nrf_tuned_val_score = rf_tuned.score(X_val_new, y_val_new)\nprint('RF tuned train score: ', rf_tuned_train_score)\nprint('RF tuned val score: ', rf_tuned_val_score)\nprint('RF old val score: ', rf_val_score)\n\nxgb_tuned = xgb.XGBClassifier(objective='multi:softmax', num_class=7, n_estimators=500, max_depth=45, subsample=1.0, learning_rate=0.035, min_child_weight=1, gamma=0.5, colsample_bytree=0.8, n_jobs=4, seed=0)\nxgb_tuned.fit(X_train_new, y_train_new);\n\nxgb_tuned_train_score = xgb_tuned.score(X_train_new, y_train_new)\nxgb_tuned_val_score = xgb_tuned.score(X_val_new, y_val_new)\nprint('\\nXGB tuned train score: ', xgb_tuned_train_score)\nprint('XGB tuned val score: ', xgb_tuned_val_score)\nprint('XGB old val score: ', xgb_val_score)","298c01c2":"test_preds_rf_tuned = rf_tuned.predict(test_new_df)\ntest_preds_xgb_tuned = xgb_tuned.predict(test_new_df)\n\noutput = pd.DataFrame({'Id': test_ids, 'Cover_Type': test_preds_rf_tuned})\noutput.to_csv('tuned_rf.csv', index=False);\n\noutput = pd.DataFrame({'Id': test_ids, 'Cover_Type': test_preds_xgb_tuned})\noutput.to_csv('tuned_xgb.csv', index=False);\n\nprint('Done!')","820cab97":"# I scale the whole dataset, and then split into training \/ validation data again specificaly for SVC training\n# Target colkumn is niot scaled\nscaler = StandardScaler()\ntrain_scaled_data = scaler.fit_transform(train_prep_df[cols_to_keep])\ntest_scaled_data = scaler.fit_transform(test_prep_df[cols_to_keep])\n\ntrain_scaled_df = pd.DataFrame(data=train_scaled_data, columns=cols_to_keep)\ntest_scaled_df = pd.DataFrame(data=test_scaled_data, columns=cols_to_keep)\n\ntrain_scaled_df[target_name] = train_prep_df[target_name]\n\n# Prepare new set of training \/ validation data\nX_train_scaled, X_val_scaled, y_train_scaled, y_val_scaled = train_test_split(train_scaled_df[cols_to_keep], train_scaled_df[target_name], test_size=0.2, random_state=1)\nprint('Original train \/ val data shape: ', X_train_new.shape, X_val_new.shape, y_train_new.shape, y_val_new.shape)\nprint('New scaled train \/ val data shape: ', X_train_scaled.shape, X_val_scaled.shape, y_train_scaled.shape, y_val_scaled.shape)\n\nprint('\\nOriginal test data shape: ', test_new_df.shape)\nprint('New scaled test data shape: ', test_scaled_df.shape)","aaa88ec3":"# Training with the best found params\nsvc_tuned = SVC(C=130, gamma=0.045, kernel='rbf', decision_function_shape='ovo', random_state=0);\nsvc_tuned.fit(X_train_scaled, y_train_scaled);\n\nsvc_tuned_train_score = svc_tuned.score(X_train_scaled, y_train_scaled)\nsvc_tuned_val_score = svc_tuned.score(X_val_scaled, y_val_scaled)\nprint('SVC tuned train score: ', svc_tuned_train_score)\nprint('SVC tuned val score: ', svc_tuned_val_score)","700b843d":"test_preds_svc_tuned = svc_tuned.predict(test_scaled_df)\n\noutput = pd.DataFrame({'Id': test_ids, 'Cover_Type': test_preds_svc_tuned})\noutput.to_csv('tuned_svc.csv', index=False);\n\nprint('Done!')","6a5a42b7":"Out of curiosity, I do a quick model training with the reduced data to see if it had any impact on performance.","9a2fd215":"## Contents\n1. [Intro](#1)\n1. [Setup](#2)\n1. [Exploring The Data](#3)\n    1. [The Basics](#31)\n    1. [Target Distribution](#32)\n    1. [Correlation](#33)    \n1. [Data Prep](#4)\n    1. [Drop Unused Features](#41)\n1. [Model Building](#5)\n    1. [Random Forest](#51)\n    1. [XGBoost](#52)\n    1. [Initial Scores](#53)\n    1. [First Submission](#54)\n    1. [Initial Results](#55)\n1. [Model Tuning](#6)\n    1. [Feature Reduction](#61)\n    1. [Hyperparameter Tuning](#62)\n    1. [Second Submission](#63)\n    1. [SVC](#64)\n    1. [Third Submission](#65)\n1. [Conclusion](#7)    \n","5a60ee63":"<a id='63'><\/a>\n### Second Submission\n\nAnd now to see how these new tuned models did in the leaderboard:","ea85e38f":"![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/d\/dd\/Ouzellake.jpg)","450384e7":"<a id='53'><\/a>\n### Initial Scores\n\nTo see how the models did:","87d0217b":"<a id='7'><\/a>\n## Conclusion\n\nIn this notebook I went from exploring the data to creating and fine-tuning 3 separate classification models. Except SVC, they achieved decent score, but are not on a level of best competition submissions. In the next notebook I intend to play around with the models a bit more, perhaps try even combining them to increase the accuracy of predictions. Ideas \/ suggestions on improving the models welcome.","a86cc772":"RF model seems to fare better, however the training accuracy of close to 100% is an indication of over-fitting. I will submit predictions of both models to see how they compare as of now.","fbee62f6":"<a id='1'><\/a>\n## Intro\nI this notebook I combined some good ideas I have seen in other notebooks as well as external sources like official documentation and blogs. It goes through some initial EDA, first model training, further iterative model tuning and competition score submissions. Models are based on RF, XGB and SVC.","a2fab716":"<a id='5'><\/a>\n## Model Building\n\nThe most straight-forward way to proceed is to train a tree-based model. They do not require data normalization, so without any further prep work I can easily proceed to model training. I will train Random Forest model and an XGBoost model.","e3fe0614":"This time the tuned RF model got a score of **0.75903**, while tuned XGB got **0.74485**. This is a significant improvement, but still not on a level of top performers using same algorithms. What can be done to improve RF and XGB even further, without going so far as to start reading scientific papers?","03d4abab":"<a id='4'><\/a>\n## Data Prep\n<a id='41'><\/a>\n### Drop Unused Features\nOk, so up till now the following has been decided, based on observations:\n1. Drop \"ID\" column from training data (but preserve the ID's, as they will need to be part of results submission)\n2. Drop \"Soil_Type7\" and \"Soil_Type15\" from training and test data\n3. Leave the remaining columns as is for now, will look at their importance later.","bdc47cb7":"<a id='33'><\/a>\n### Correlation\n\nI've seen some kernels showing correlation heat-maps to try to see which feature impacts target variable most. I'm gonna argue here that since target variable is categorical, with numbers (1 through 7) only indicating their class, and have no ordinal meaning, the standard correlation analysis would be wrong (as typically correlation measures how increase or decrease in a particular ordinal numerical feature increases or decreases another numerical ordinal feature).\n\nInstead, I will look at which non-categorical features correlate with each other, to perhaps find some that are highly correlated and thus interchangeable:","d634e100":"<a id='32'><\/a>\n### Target Distribution\n\nLooking at value distribution info, I am interested to see if the target (\"Cover_Type\") categories are equally represented in training set, so that model can learn to be equally effective at predicting all classes:","1db0f4b8":"<a id='51'><\/a>\n### Random Forest","08a647ae":"<a id='3'><\/a>\n## Exploring The Data\n<a id='31'><\/a>\n### The Basics\nTo get a feel of the data available:","8a13cff3":"<a id='52'><\/a>\n### XGBoost","45ed427b":"I got a score of **0.51918**, which was both a surprise and a big dissapointment, I did not expect such a difference in validation and test scores.","c9f3d6d2":"<a id='6'><\/a>\n## Model Tuning\n<a id='61'><\/a>\n### Feature Reduction\nI am curious to see if before any further model tuning I can identify features that contribute little to nothing towards target prediction. Luckily, the trained RF model has built-in property \"feature_importances_\" that illustrates that.\n","5fbda284":"From the looks of it, anything east of Soil_Type20 is just noise, so I'll take it out of both training and test data:","25d63f62":"<a id='55'><\/a>\n### Initial Results\n\nAfter submission the RF model got a score of **0.70173**, while the XGB model got a disappointing score of **0.58439**. Overall these results are somewhere in the bottom half of all submissions, which is to be expected, given that most participants created almost identical models.\nTime to think how to squeeze some additional juice out of my models to improve performance.","3f2a95e9":"The correlation coefficient has values between -1 to 1:\n* A value closer to 0 implies weaker correlation (exact 0 implying no correlation)\n* A value closer to 1 implies stronger positive correlation\n* A value closer to -1 implies stronger negative correlation\n\nFrom what I can see there are some rather strong negative correlations regarding hillshade, which is logical, but other than that I cannot conclude that some features are excludable.","f99d6310":"Two columns contain more categories in test than in train sets- the values of \"ones\" are in test and not in train. It is probably safe to drop both of these columns from future model, as their impact is relativey small - in case of \"Soil_Type15\" there are only 3 values of \"1\" in test set and 105 values of \"1\" in test set for \"Soil_Type7\" (out of 565k).","aadeba24":"<a id='65'><\/a>\n### Third Submission\n\nLet's compare SVC against other entries in the leaderboard.","b119a3d6":"One of the noticeable things is that the \"ID\" column matches the index, and will not provide any useful information to train the model. Another observation is that test set is much larger than training set. Finally, \"Soil_Type\" is already one-hot-encoded. There are no missing values, so the dataset seems to be already pre-processed and prepared for analysis and modeling.","c962be20":"<a id='2'><\/a>\n## Setup\n\nThe usual imports and data loading:","48d43bf4":"<a id='62'><\/a>\n### Hyper-parameter Tuning\n\nFor subsequent model training I will do parameter tuning with random and grid search to let the model find it's own best hyper-parameters. This will also utilize cross-validation.\n\nMy approach will be to at first use random search function to try a limited number of combinations to find some potentially good parameter values, and then do a grid search through a reduced list of narrowed-down combinations. This is due to brute-force approach (grid-searching at once all possible combos) would likely result in model training for unfeasibly long time.\n\nI have performed parameter searching in Google colab notebook while I worked on this kernel and already obtained the results.\nAfter several experimental runs through random search and grid search, these are the best param values I found:\n* RF: {'bootstrap': False, 'max_depth': 45, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 950}\n* XGB: {'colsample_bytree': 0.8, 'gamma': 0.5, 'learning_rate': 0.035, 'max_depth': 45, 'min_child_weight': 1, 'n_estimators': 500, 'subsample': 1.0}\n\nIn this notebook I will just train a new RF and XGB model with the above best parameters that my grid search found and proceed from there, but the code for grid search is provided below for reference.","ba04cba3":"Since I already have a set of optimized parameter values, I will train new RF and XGB models so that I can proceed with this notebook.","866d63e3":"<a id='64'><\/a>\n### SVC\n\nI wanted to try another classification model- SVC. Similarly as with RF and XGB, I did extensive grid searching for best param values in Google colab, so here I will just proceed to train the model with those param values.\n\nJust to note - models like SVMs need data to be pre-scaled, so there is one extra step before grid search.","460ead6b":"It appears the performance has even increased a bit!","bf82b2de":"Tuning the models helped with validation score improvement, though they appear to still be over-fitting training data.","8d2043aa":"It appears Kaggle has thought about it already and provided a training set with perfectly distributed target values.","cf441a27":"The dataset has many categorical columns: \n\n- Wilderness_Area (4 binary columns, 0 = absence or 1 = presence) - \n    Wilderness area designation\n- Soil_Type (40 binary columns, 0 = absence or 1 = presence) - \n    Soil Type designation\n- Cover_Type (7 types, integers 1 to 7) - \n    Forest Cover Type designation\n\nI'm interested to know if unique values (the categories) in these columns in training set match those in the test set (excluding the target col - \"Cover_Type\", which is missing in test set). This is important, as the model will not be able to effectively interpret values (categories) from test dataset if it did not encounter them before in the training set.","431e9780":"Looking at stats, nothing suspicious as far as I can tell. Without specific domain knowledge it is difficult to judge if these values are reasonable.","64a977a1":"<a id='54'><\/a>\n### First Submission\n\nSave the predictions of initial RF and XGBoost models:"}}