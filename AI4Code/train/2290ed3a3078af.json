{"cell_type":{"22119e9b":"code","7331d1f5":"code","07757c7f":"code","34523dfc":"code","4b7a0723":"code","0ea7cf5e":"code","f3c7d71a":"code","3df59305":"code","465df38d":"code","4edf1d6b":"code","8774be22":"code","04889203":"code","3ca79223":"code","7cf1aee7":"code","71e16c19":"code","92c776ed":"code","040c2e6c":"code","3d56d79a":"code","19394312":"code","1340a065":"code","80823cb0":"code","f73b73cf":"code","41419932":"code","49b56767":"code","bbbb55c8":"markdown","4e08af50":"markdown","1b6dff30":"markdown","a14955c4":"markdown","c68bdc5c":"markdown","934e0b3d":"markdown","1cc0526f":"markdown","b0880d38":"markdown","68da69f6":"markdown","1866303a":"markdown","7bb1e07f":"markdown","10a9662c":"markdown","edb76355":"markdown","d0135468":"markdown","8daf3a95":"markdown","3d465d35":"markdown","b937fead":"markdown","5c3a947b":"markdown","e7a5eb1a":"markdown","31d6693b":"markdown","84413e64":"markdown","5c7e09c4":"markdown","7962bcb6":"markdown","67a7ecec":"markdown","bafd78a7":"markdown"},"source":{"22119e9b":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as D\nfrom torch.optim.lr_scheduler import ExponentialLR\n\nfrom torchvision import models, transforms as T\n\nfrom tqdm import tqdm_notebook\n\nfrom glob import glob\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style = \"darkgrid\")\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\nfrom ignite.metrics import Loss, Accuracy\nfrom ignite.contrib.handlers.tqdm_logger import ProgressBar\nfrom ignite.handlers import  EarlyStopping, ModelCheckpoint","7331d1f5":"# Set Seed\n\ndef set_seed(seed = 1234):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n#     random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed) # gpu vars\n    if torch.backends.cudnn.is_available:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(42)","07757c7f":"BASE_PATH = \"\/kaggle\/input\/intel-image-classification\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 32","34523dfc":"def get_data(repo):\n    image_path_dict = {os.path.basename(x).split(\".\")[0] : x for x in glob(os.path.join(BASE_PATH, repo, repo, \"*\", \"*.jpg\"))}\n    df = pd.DataFrame()\n    image_id = [os.path.basename(x).split(\".\")[0] for x in glob(os.path.join(BASE_PATH, repo, repo, \"*\", \"*.jpg\"))] \n    df[\"image_id\"] = image_id\n    df[\"path\"] = df[\"image_id\"].map(image_path_dict.get)\n    df[\"target\"] = df.path.apply(lambda x: x.split(\"\/\")[-2])\n    return df","4b7a0723":"def label_encode():\n    df = pd.concat([df_train, df_test])\n    le = LabelEncoder()\n    le.fit(df[\"target\"])\n    df_train[\"label\"] = le.transform(df_train[\"target\"])\n    df_test[\"label\"] = le.transform(df_test[\"target\"])\n    print(le.classes_)\n    print(\"Encoding Successful\")\n    return le.classes_","0ea7cf5e":"class ImagesDS(D.Dataset):\n    def __init__(self, df, img_dir, mode = 'seg_train'):\n        self.records = df.to_records(index = False)\n        self.mode = mode\n        self.img_dir = img_dir\n        self.len = df.shape[0]\n        \n    @staticmethod\n    def _load_img_as_tensor(file_name):\n        with Image.open(file_name) as img:\n            return T.Compose([T.RandomResizedCrop(size = 150, scale = (0.7, 1.0)),\n                              T.RandomHorizontalFlip(),\n                              T.ToTensor(), \n                              T.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])(img)\n\n    def _get_img_path(self, index):\n        image_id, target = self.records[index].image_id, self.records[index].target\n        return '\/'.join([self.img_dir,self.mode, self.mode, target, f\"{image_id}.jpg\"])\n        \n    def __getitem__(self, index):\n        path = self._get_img_path(index)\n        img = self._load_img_as_tensor(path)\n        if self.mode == 'seg_train':\n            return img, int(self.records[index].label)\n        else:\n            return img, self.records[index].image_id\n\n    def __len__(self):\n        return self.len","f3c7d71a":"df_train = get_data(\"seg_train\")\ndf_test = get_data(\"seg_test\")","3df59305":"encodings = label_encode()","465df38d":"plt.rcParams[\"figure.figsize\"] = [10, 8]\ndf_train.target.value_counts().plot(kind = \"bar\", color = [\"B\", \"G\", \"R\", \"Y\", \"Orange\", \"Violet\"])","4edf1d6b":"temp = df_train.sample(9)\n\nfig=plt.figure(figsize=(10, 10))\ncolumns = 3\nrows = 3\nfor i in range(1, columns*rows +1):\n    img = plt.imread(temp.path.iloc[i-1])\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.xticks([])\n    plt.yticks([])\n    label = temp.target.iloc[i-1]\n    plt.xlabel(f\"Label: {label}\")\nplt.tight_layout()\nplt.show()","8774be22":"classes = 6\nmodel = models.resnet50(pretrained = True)\nmodel.fc = nn.Linear(2048, 1000)\nmodel._fc = nn.Linear(1000, classes)","04889203":"train_data, val_data = train_test_split(df_train, random_state = 42, test_size = 0.2, stratify = df_train[\"label\"])","3ca79223":"ds = ImagesDS(train_data, BASE_PATH, mode = \"seg_train\")\nds_val = ImagesDS(val_data, BASE_PATH, mode = \"seg_train\")\nds_test = ImagesDS(df_test, BASE_PATH, mode = \"seg_test\")","7cf1aee7":"loader = D.DataLoader(ds, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\nval_loader = D.DataLoader(ds_val, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\ntest_loader = D.DataLoader(ds_test, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4)","71e16c19":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 3e-4, weight_decay = 0.0001)","92c776ed":"metrics = { \"loss\" : Loss(criterion), \"accuracy\" : Accuracy()}\n\ntrainer = create_supervised_trainer(model, optimizer, criterion, device = device)\nval_eval = create_supervised_evaluator(model, metrics = metrics, device = device)","040c2e6c":"@trainer.on(Events.EPOCH_COMPLETED)\ndef compute_and_display(engine):\n    epoch = engine.state.epoch\n    metrics = val_eval.run(val_loader).metrics\n    print(\"Validation Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} \"\n          .format(engine.state.epoch, \n                      metrics['loss'], \n                      metrics['accuracy']))","3d56d79a":"handler = EarlyStopping(patience = 4, score_function = lambda engine : engine.state.metrics['accuracy'], trainer = trainer)\nval_eval.add_event_handler(Events.COMPLETED, handler)","19394312":"checkpoints = ModelCheckpoint(\"models\", \"Model\", n_saved = 3, create_dir = True)\ntrainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoints, {\"Resnet50\" : model})","1340a065":"pbar = ProgressBar(bar_format = '')\npbar.attach(trainer, output_transform = lambda x : {\"loss\" : x})","80823cb0":"trainer.run(loader, max_epochs = 30)","f73b73cf":"model.eval()\nwith torch.no_grad():\n    preds = np.empty(0)\n    for x, _ in tqdm_notebook(test_loader): \n        x = x.to(device)\n        output = model(x)\n        idx = output.max(dim=-1)[1].cpu().numpy()\n        preds = np.append(preds, idx, axis=0)\n\npreds = pd.Series(preds).astype(np.int)","41419932":"random_index = df_test.sample(9).index\nfig=plt.figure(figsize=(10, 10))\ncolumns = 3\nrows = 3\nfor i in range(1, columns*rows +1):\n    img = plt.imread(df_test.path[random_index[i-1]])\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.xticks([])\n    plt.yticks([])\n    prediction = encodings[preds[random_index[i-1]]]\n    original = df_test.target[random_index[i-1]]\n    plt.xlabel(f\"Prediction: {prediction} \\n Original: {original}\")\nplt.tight_layout()\nplt.show()","49b56767":"count = 0\nfor i in range(len(preds)):\n    if df_test.label[i] == preds[i]:\n        count += 1\n        \nprint(\"Test accuracy: {}%\".format((count\/len(preds))*100))","bbbb55c8":"![](https:\/\/cdn-images-1.medium.com\/max\/2000\/1*YRINRZFr0E1FRJ4JpizEMw.jpeg)","4e08af50":"Let's define our Image preparing pipeline which will take jpg image as input and after preprocessing and doing some augmentations on it, will provide us with augmented PIL image.","1b6dff30":"Let's see the distribution of data over all the 6 classes we have!","a14955c4":"Let's define our model!\n\nWe will be using Resnet50 for prediction with weights from imagenet!","c68bdc5c":"## Getting and Preprocessing data","934e0b3d":"Evaluation mode, here, we will predict the labels for the test data we had put aside in the starting!","1cc0526f":"## Training","b0880d38":"## Importing Essential Libraries","68da69f6":"Defining Loss, optimizer and metrics!\n\nWe have set learning rate to be 0.0003 with a weight decay of 0.0001.","1866303a":"Okay, seems like the data is almost balanced.\n\nNow, let's take a sneak peek into some of the images from the the data with their labels.","7bb1e07f":"Encoding the target classes.","10a9662c":"## Setting parameters","edb76355":"Let's now see the %age accuracy of our model on all of the test data!","d0135468":"## Inference","8daf3a95":"Let's get the training and test data.","3d465d35":"Yayyy, Training time! :)","b937fead":"Early stopping in case our model stops learning and we want to stop it midway, in order to prevent overfitting!","5c3a947b":"I hope you found reading this notebook worthwhile! \n\nThanks for reading!\n\nUntil next time! :)","e7a5eb1a":"Defining necessary functions","31d6693b":"I will be trying to make this notebook very beginner friendly, if you find anything that should be changed or added, please leave a comment!\n\nNow, Let's make this fun!","84413e64":"Here comes the part we are all waiting for, in the next few cells, we will pass our data through image preparing pipeline we defined earlier and then creating batches of the data using Dataloader class from Pytorch! ","5c7e09c4":"Let's now split our data into two parts, i.e. training and validation, which will help us in comparing our model's accuracy. We will using 80% of data in training while 20% of data will be used for test.","7962bcb6":"This is now time to see some of the images with their predicted labels and original ones side by side!","67a7ecec":"## Post Prediction Analysis","bafd78a7":"Below cells use some of the very powerful inbuilt functions from Ignite!"}}