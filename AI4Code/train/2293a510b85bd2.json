{"cell_type":{"d00a44db":"code","5919d6a6":"code","47a95c27":"code","9220440f":"code","94840b2c":"code","583b7188":"code","d063c29a":"code","60eafa2d":"code","e27aa834":"code","ce2e492d":"code","0054af23":"code","81641a49":"markdown","46107034":"markdown","89a52981":"markdown","8f450aa0":"markdown","924ba204":"markdown","f7a61244":"markdown","cee5ea61":"markdown","0f1a3fc1":"markdown","187fb0ad":"markdown"},"source":{"d00a44db":"from keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport os\nfrom PIL import Image","5919d6a6":"img_rows = 28\nimg_cols = 28\nchannels = 1\nimg_shape = (img_rows, img_cols, channels)\nlatent_dim = 100","47a95c27":"def build_generator():\n    model = Sequential()\n    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n    model.add(Reshape((7, 7, 128)))\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(UpSampling2D())\n    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n    model.summary()\n    noise = Input(shape=(latent_dim,))\n    img = model(noise)\n    return Model(noise, img)","9220440f":"def build_discriminator():\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    model.summary()\n    img = Input(shape=img_shape)\n    validity = model(img)\n    return Model(img, validity)","94840b2c":"optimizer = Adam(0.0002, 0.5)\n\n# build discriminator\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy',\n                      optimizer=optimizer,\n                      metrics=['accuracy'])\n\n# build generator\ngenerator = build_generator()\nz = Input(shape=(100,))\nimg = generator(z)\n\n# For the combined model we will only train the generator\ndiscriminator.trainable = False\n\n# The discriminator takes generated images as input and determines validity\nvalid = discriminator(img)\n\n# The combined model  (stacked generator and discriminator)\n# Trains the generator to fool the discriminator\ncombined = Model(z, valid)\ncombined.compile(loss='binary_crossentropy', optimizer=optimizer)","583b7188":"def train(epochs, batch_size=128, save_interval=50):\n    os.makedirs('images', exist_ok=True)\n    \n    # Load the dataset\n    (X_train, _), (_, _) = mnist.load_data()\n\n    # Rescale -1 to 1\n    X_train = X_train \/ 127.5 - 1.\n    X_train = np.expand_dims(X_train, axis=3)\n\n    # Adversarial ground truths\n    valid = np.ones((batch_size, 1))\n    fake = np.zeros((batch_size, 1))\n\n    for epoch in range(epochs):\n        # Select a random real images\n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        real_imgs = X_train[idx]\n\n        # Sample noise and generate a batch of fake images\n        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n        fake_imgs = generator.predict(noise)\n\n        # Train the discriminator\n        D_loss_real = discriminator.train_on_batch(real_imgs, valid)\n        D_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n        D_loss = 0.5 * np.add(D_loss_real, D_loss_fake)\n\n        # Train the generator\n        g_loss = combined.train_on_batch(noise, valid)\n\n        # If at save interval\n        if epoch % save_interval == 0:\n            # Print the progress\n            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, D_loss[0], 100 * D_loss[1], g_loss))\n            # Save generated image samples\n            save_imgs(epoch)","d063c29a":"def save_imgs(epoch):\n    r, c = 5, 5\n    noise = np.random.normal(0, 1, (r * c, latent_dim))\n    gen_imgs = generator.predict(noise)\n\n    # Rescale images 0 - 1\n    gen_imgs = 0.5 * gen_imgs + 0.5\n\n    fig, axs = plt.subplots(r, c)\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n            axs[i, j].axis('off')\n            cnt += 1\n    fig.savefig(\"images\/mnist_%d.png\" % epoch)\n    plt.close()","60eafa2d":"start = time.time()\n\ntrain(epochs=10000, batch_size=32, save_interval=1000)\n\nend = time.time()\nelapsed_train_time = 'elapsed training time: {} min, {} sec '.format(int((end - start) \/ 60),\n                                                                     int((end - start) % 60))\nprint(elapsed_train_time)","e27aa834":"os.makedirs('saved_model_weights', exist_ok=True)\ngenerator.save_weights('saved_model_weights\/generator_weights.h5')\ndiscriminator.save_weights('saved_model_weights\/discriminator_weights.h5')\ncombined.save_weights('saved_model_weights\/combined_weights.h5')","ce2e492d":"Image.open('images\/mnist_1000.png')","0054af23":"Image.open('images\/mnist_9000.png')","81641a49":"This kernel use DCGAN(Deep Convolutional Generative Adversarial Network) to generate different MNIST images.","46107034":"## Train GAN","89a52981":"## Reference\n[Keras - DCGAN](https:\/\/github.com\/eriklindernoren\/Keras-GAN#dcgan)","8f450aa0":"## Build GAN","924ba204":"## Define a function to build a discriminator","f7a61244":"## Define a function to train GAN","cee5ea61":"## Define a function to build a generator","0f1a3fc1":"## Show generated MNIST images","187fb0ad":"## Set up network parameters\n "}}