{"cell_type":{"abd71953":"code","b7840960":"code","536de55e":"code","b0ab6125":"code","4c8e5785":"code","30b16948":"code","63f7733a":"code","8516f72e":"code","e671062a":"code","1f9d0431":"code","9607de74":"code","acfcbcbd":"code","c499d093":"code","ef1d26da":"code","1f63b16d":"code","4fc8510d":"code","1e796807":"markdown","3022adfd":"markdown","ee1d351f":"markdown","480d01eb":"markdown","931024ea":"markdown","eee83228":"markdown","815328ed":"markdown","26088ed4":"markdown","5fb99110":"markdown","b0c68e5f":"markdown","feb49af1":"markdown","5eec50ac":"markdown","96f4d321":"markdown","d3a6c324":"markdown","e7dd15bd":"markdown","1f6c2b90":"markdown","0aaee11f":"markdown"},"source":{"abd71953":"import numpy as np\n\nimport pandas as pd\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\n\nfrom sklearn.preprocessing import Imputer\n\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier","b7840960":"def show_kde_and_bins(df, col):\n    global fig_num\n    plt.figure(fig_num)\n    sns.kdeplot(df.loc[df['TARGET'] == 0, col], label = 'target == 0')\n    sns.kdeplot(df.loc[df['TARGET'] == 1, col], label = 'target == 1')\n    plt.xlabel(col)\n    plt.ylabel('Density')\n    \n    plt.figure(fig_num + 1)\n    axes = plt.gca()\n    axes.set_xlim([df[col].min(), df[col].max()])\n    staging = df[[col,'TARGET']]\n    staging['COL_BINNED'] = pd.cut(staging[col], bins = 10)\n    final = staging.groupby('COL_BINNED').mean()\n    plt.bar(final[col], final['TARGET'])\n    plt.xlabel(col)\n    plt.ylabel('AVG TARGET')\n    \n    fig_num += 2","536de55e":"train = pd.read_csv('..\/input\/application_train.csv')\ntest = pd.read_csv('..\/input\/application_test.csv')\n\nprint(train.shape)\n\n# columns with outliers:\n# DAYS_EMPLOYED\n\noutlier = train[train['DAYS_EMPLOYED'] > 30000]\nnon_outlier = train[train['DAYS_EMPLOYED'] < 30000]\n\n# new column for outlier\ntrain['DAYS_EMPLOYED_OUTLIER'] = 0\ntrain.loc[train['DAYS_EMPLOYED'] > 30000, 'DAYS_EMPLOYED_OUTLIER'] = 1\n\n# fill in outliers with mean\ntrain.loc[train['DAYS_EMPLOYED'] > 30000, 'DAYS_EMPLOYED'] = non_outlier['DAYS_EMPLOYED'].mean()\n\n# clean up DAYS_BIRTH and DAYS_EMPLOYED to be easy to understand\ntrain['YEARS_BIRTH'] = train['DAYS_BIRTH'] \/ -365\ntrain['YEARS_EMPLOYED'] = train['DAYS_EMPLOYED'] \/ -365\n\ntrain = pd.get_dummies(train)\n\n# columns with outliers:\n# DAYS_EMPLOYED\n\noutlier_te = test[test['DAYS_EMPLOYED'] > 30000]\nnon_outlier_te = test[test['DAYS_EMPLOYED'] < 30000]\n\n# new column for outlier\ntest['DAYS_EMPLOYED_OUTLIER'] = 0\ntest.loc[test['DAYS_EMPLOYED'] > 30000, 'DAYS_EMPLOYED_OUTLIER'] = 1\n\n# fill in outliers with mean\ntest.loc[test['DAYS_EMPLOYED'] > 30000, 'DAYS_EMPLOYED'] = non_outlier_te['DAYS_EMPLOYED'].mean()\n\n# clean up DAYS_BIRTH and DAYS_EMPLOYED to be easy to understand\ntest['YEARS_BIRTH'] = test['DAYS_BIRTH'] \/ -365\ntest['YEARS_EMPLOYED'] = test['DAYS_EMPLOYED'] \/ -365\n\ntest = pd.get_dummies(test)\n\ntarget = train['TARGET']\n\ntrain, test = train.align(test, join = 'inner', axis = 1)\n\ntrain['TARGET'] = target\n\n#corr = train.corr()\n#print(corr['TARGET'].sort_values(ascending = False))\n\n# strong positive corr -> DAYS_BIRTH, DAYS_EMPLOYED,REGION_RATING_CLIENT_W_CITY \n# strong negative corr -> EXT_SOURCE 1,2,3\n# Let's explore!\n\n# KDE \/ pd.cut()\n\nfig_num = 1\n\n    \nshow_kde_and_bins(train, 'EXT_SOURCE_1')\nshow_kde_and_bins(train, 'EXT_SOURCE_2')\nshow_kde_and_bins(train, 'EXT_SOURCE_3')\nshow_kde_and_bins(train, 'REGION_RATING_CLIENT_W_CITY')\nshow_kde_and_bins(train, 'YEARS_BIRTH')\nshow_kde_and_bins(train, 'YEARS_EMPLOYED')","b0ab6125":"bureau = pd.read_csv('..\/input\/bureau.csv')\nbureau = pd.get_dummies(bureau)\n\n# odd columns\n# amt_credit_max_overdue\n# AMT_CREDIT_SUM_LIMIT\n# AMT_CREDIT_SUM_OVERDUE\n\ndef outliers(df, col):\n    mean = df[col].mean()\n    std_dev = df[col].std()\n    df['Z_SCORE'] = (df[col] - mean) \/ std_dev\n    print(df[col].describe())\n    print('mean: ', mean,'. std dev: ', std_dev)\n    print(df.loc[df['Z_SCORE'] > 5, [col, 'Z_SCORE']])\n\n#outliers(bureau, 'AMT_CREDIT_MAX_OVERDUE')\n#outliers(bureau, 'AMT_CREDIT_SUM_LIMIT')\n#outliers(bureau, 'AMT_CREDIT_SUM_OVERDUE')\n# .. definitely outliers but leaving there since it seems legit (not one value or anything mysterious)\n\n# metrics on bureau\nbureau_staging = bureau \\\n    .drop(columns = ['SK_ID_BUREAU']) \\\n    .groupby('SK_ID_CURR') \\\n    .agg(['count','mean','min','max', 'sum']) \\\n    .reset_index()\n\ncolumns = ['SK_ID_CURR']\n\n# Convert multi-level index from .agg() into clean columns\n# borrowing from: https:\/\/www.kaggle.com\/willkoehrsen\/introduction-to-manual-feature-engineering\nfor var in bureau_staging.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in bureau_staging.columns.levels[1][:-1]:\n            columns.append('bureau_%s_%s' % (var, stat))\n\nbureau_staging.columns = columns\n\ntrain = pd.merge(\n    train,\n    bureau_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\ntest = pd.merge(\n    test,\n    bureau_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\n# columns.append('TARGET')\n\n# bureau_corr = tr[columns]\n#tr = imputer.fit_transform(tr)\n#print(tr)\n\n# corr = bureau_corr.corr()\n# print(corr['TARGET'].sort_values(ascending = False))\n\n# strong-ish corrs:\n# bureau_DAYS_CREDIT_mean  \n# bureau_CREDIT_ACTIVE_Active_mean\n# bureau_DAYS_CREDIT_min\n\nshow_kde_and_bins(train, 'bureau_DAYS_CREDIT_mean')\nshow_kde_and_bins(train, 'bureau_CREDIT_ACTIVE_Active_mean')\nshow_kde_and_bins(train, 'bureau_DAYS_CREDIT_min')","4c8e5785":"previous_application = pd.read_csv('..\/input\/previous_application.csv')\n\nprevious_application = previous_application[\n    [\n        'SK_ID_CURR',\n        'CODE_REJECT_REASON',                       \n        'NAME_CONTRACT_STATUS',                      \n        'NAME_PRODUCT_TYPE'\n    ]\n]\nprevious_application = pd.get_dummies(previous_application)\n\nprevious_application_staging = previous_application \\\n    .groupby('SK_ID_CURR') \\\n    .agg(['count','mean','min','max', 'sum']) \\\n    .reset_index()\n\ncolumns = ['SK_ID_CURR']\n\n# Convert multi-level index from .agg() into clean columns\n# borrowing from: https:\/\/www.kaggle.com\/willkoehrsen\/introduction-to-manual-feature-engineering\nfor var in previous_application_staging.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in previous_application_staging.columns.levels[1][:-1]:\n            columns.append('previous_application_%s_%s' % (var, stat))\n\nprevious_application_staging.columns = columns\n\nprevious_application = previous_application_staging[\n    [\n        'SK_ID_CURR',\n        'previous_application_CODE_REJECT_REASON_XAP_mean',                       \n        'previous_application_NAME_CONTRACT_STATUS_Approved_mean',                 \n        'previous_application_NAME_CONTRACT_STATUS_Refused_mean',                      \n        'previous_application_NAME_CONTRACT_STATUS_Refused_sum',                     \n        'previous_application_CODE_REJECT_REASON_SCOFR_max',                        \n        'previous_application_NAME_PRODUCT_TYPE_walk-in_sum'\n    ]\n]\n\ntrain = pd.merge(\n    train,\n    previous_application_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\ntest = pd.merge(\n    test,\n    previous_application_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)","30b16948":"POS_CASH_balance = pd.read_csv('..\/input\/POS_CASH_balance.csv')\nPOS_CASH_balance = POS_CASH_balance[['SK_ID_CURR', 'MONTHS_BALANCE']]\n\nPOS_CASH_balance_staging = POS_CASH_balance \\\n    .groupby('SK_ID_CURR') \\\n    .agg(['count','mean','min','max', 'sum']) \\\n    .reset_index()\n\ncolumns = ['SK_ID_CURR']\n\n# Convert multi-level index from .agg() into clean columns\n# borrowing from: https:\/\/www.kaggle.com\/willkoehrsen\/introduction-to-manual-feature-engineering\nfor var in POS_CASH_balance_staging.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in POS_CASH_balance_staging.columns.levels[1][:-1]:\n            columns.append('POS_CASH_balance_%s_%s' % (var, stat))\n\nPOS_CASH_balance_staging.columns = columns\n\ntrain = pd.merge(\n    train,\n    POS_CASH_balance_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\ntest = pd.merge(\n    test,\n    POS_CASH_balance_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)","63f7733a":"credit_card_balance = pd.read_csv('..\/input\/credit_card_balance.csv')\n\ncredit_card_balance_staging = credit_card_balance \\\n    .groupby('SK_ID_CURR') \\\n    .agg(['count','mean','min','max', 'sum']) \\\n    .reset_index()\n\ncolumns = ['SK_ID_CURR']\n\n# Convert multi-level index from .agg() into clean columns\n# borrowing from: https:\/\/www.kaggle.com\/willkoehrsen\/introduction-to-manual-feature-engineering\nfor var in credit_card_balance_staging.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in credit_card_balance_staging.columns.levels[1][:-1]:\n            columns.append('credit_card_balance_%s_%s' % (var, stat))\n\ncredit_card_balance_staging.columns = columns\n\ntrain = pd.merge(\n    train,\n    credit_card_balance_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\ntest = pd.merge(\n    test,\n    credit_card_balance_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)","8516f72e":"y = train['TARGET']\nimputer = Imputer(strategy = 'mean')","e671062a":"x_cols_app = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED'\n]\n\nx_app = train[x_cols_app]\nx_app = imputer.fit_transform(x_app)\n\nx_app_train, x_app_test, y_app_train, y_app_test = train_test_split(x_app, y, test_size = 0.33, random_state = 0)\n\nmodel_app = RandomForestClassifier()\nmodel_app.fit(x_app_train, y_app_train)\npredictions_app = model_app.predict_proba(x_app_test)\n\nauc_app = roc_auc_score(y_app_test, predictions_app[:,1])\nprint('AUC: app only:', auc_app)","1f9d0431":"x_cols_app_bureau = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED',\n    'bureau_DAYS_CREDIT_mean',\n    'bureau_CREDIT_ACTIVE_Active_mean',\n    'bureau_DAYS_CREDIT_min'\n]\n\nx_app_bureau = train[x_cols_app_bureau]\nx_app_bureau = imputer.fit_transform(x_app_bureau)\n\nx_app_bureau_train, x_app_bureau_test, y_app_bureau_train, y_app_bureau_test = train_test_split(x_app_bureau, y, test_size = 0.33, random_state = 0)\n\nmodel_app_bureau = RandomForestClassifier()\nmodel_app_bureau.fit(x_app_bureau_train, y_app_bureau_train)\npredictions_app_bureau = model_app_bureau.predict_proba(x_app_bureau_test)\n\nauc_app_bureau = roc_auc_score(y_app_bureau_test, predictions_app_bureau[:,1])\nprint('AUC: app + bureau:', auc_app_bureau)","9607de74":"x_cols_app_bureau_prev = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED',\n    'bureau_DAYS_CREDIT_mean',\n    'bureau_CREDIT_ACTIVE_Active_mean',\n    'bureau_DAYS_CREDIT_min',\n    'previous_application_CODE_REJECT_REASON_XAP_mean',                       \n    'previous_application_NAME_CONTRACT_STATUS_Approved_mean',                 \n    'previous_application_NAME_CONTRACT_STATUS_Refused_mean',                      \n    'previous_application_NAME_CONTRACT_STATUS_Refused_sum',                     \n    'previous_application_CODE_REJECT_REASON_SCOFR_max',                        \n    'previous_application_NAME_PRODUCT_TYPE_walk-in_sum' \n]\n\nx_app_bureau_prev = train[x_cols_app_bureau_prev]\nx_app_bureau_prev = imputer.fit_transform(x_app_bureau_prev)\n\nx_app_bureau_prev_train, x_app_bureau_prev_test, y_app_bureau_prev_train, y_app_bureau_prev_test = train_test_split(x_app_bureau_prev, y, test_size = 0.33, random_state = 0)\n\nmodel_app_bureau_prev = RandomForestClassifier()\nmodel_app_bureau_prev.fit(x_app_bureau_prev_train, y_app_bureau_prev_train)\npredictions_app_bureau_prev = model_app_bureau_prev.predict_proba(x_app_bureau_prev_test)\n\nauc_app_bureau_prev = roc_auc_score(y_app_bureau_prev_test, predictions_app_bureau_prev[:,1])\nprint('AUC: application_train.csv + bureau.csv + previous_application.csv:', auc_app_bureau_prev)\n#previous_application_CODE_REJECT_REASON_XAP_mean                           -0.073930\n#previous_application_NAME_CONTRACT_STATUS_Approved_mean                    -0.063521\n#previous_application_NAME_CONTRACT_STATUS_Refused_mean                      0.077671\n#previous_application_NAME_CONTRACT_STATUS_Refused_sum                       0.064469\n#previous_application_CODE_REJECT_REASON_SCOFR_max                           0.063657\n#previous_application_NAME_PRODUCT_TYPE_walk-in_sum                          0.062628","acfcbcbd":"x_cols_app_bureau_prev_pos = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED',\n    'bureau_DAYS_CREDIT_mean',\n    'bureau_CREDIT_ACTIVE_Active_mean',\n    'bureau_DAYS_CREDIT_min',\n    'previous_application_CODE_REJECT_REASON_XAP_mean',                       \n    'previous_application_NAME_CONTRACT_STATUS_Approved_mean',                 \n    'previous_application_NAME_CONTRACT_STATUS_Refused_mean',                      \n    'previous_application_NAME_CONTRACT_STATUS_Refused_sum',                     \n    'previous_application_CODE_REJECT_REASON_SCOFR_max',                        \n    'previous_application_NAME_PRODUCT_TYPE_walk-in_sum',\n    'POS_CASH_balance_MONTHS_BALANCE_min'\n]\n\nx_app_bureau_prev_pos = train[x_cols_app_bureau_prev_pos]\nx_app_bureau_prev_pos = imputer.fit_transform(x_app_bureau_prev_pos)\n\nx_app_bureau_prev_pos_train, x_app_bureau_prev_pos_test, y_app_bureau_prev_pos_train, y_app_bureau_prev_pos_test = train_test_split(x_app_bureau_prev_pos, y, test_size = 0.33, random_state = 0)\n\nmodel_app_bureau_prev_pos = RandomForestClassifier()\nmodel_app_bureau_prev_pos.fit(x_app_bureau_prev_pos_train, y_app_bureau_prev_pos_train)\npredictions_app_bureau_prev_pos = model_app_bureau_prev_pos.predict_proba(x_app_bureau_prev_pos_test)\n\nauc_app_bureau_prev_pos = roc_auc_score(y_app_bureau_prev_pos_test, predictions_app_bureau_prev_pos[:,1])\nprint('AUC: application_train.csv + bureau.csv + previous_application.csv + POS_CASH_balance.csv:', auc_app_bureau_prev_pos)\n#previous_application_CODE_REJECT_REASON_XAP_mean                           -0.073930\n#previous_application_NAME_CONTRACT_STATUS_Approved_mean                    -0.063521\n#previous_application_NAME_CONTRACT_STATUS_Refused_mean                      0.077671\n#previous_application_NAME_CONTRACT_STATUS_Refused_sum                       0.064469\n#previous_application_CODE_REJECT_REASON_SCOFR_max                           0.063657\n#previous_application_NAME_PRODUCT_TYPE_walk-in_sum                          0.062628","c499d093":"x_cols_app_bureau_prev_pos_credit = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED',\n    'bureau_DAYS_CREDIT_mean',\n    'bureau_CREDIT_ACTIVE_Active_mean',\n    'bureau_DAYS_CREDIT_min',\n    'previous_application_CODE_REJECT_REASON_XAP_mean',                       \n    'previous_application_NAME_CONTRACT_STATUS_Approved_mean',                 \n    'previous_application_NAME_CONTRACT_STATUS_Refused_mean',                      \n    'previous_application_NAME_CONTRACT_STATUS_Refused_sum',                     \n    'previous_application_CODE_REJECT_REASON_SCOFR_max',                        \n    'previous_application_NAME_PRODUCT_TYPE_walk-in_sum',\n    'POS_CASH_balance_MONTHS_BALANCE_min',\n    'credit_card_balance_CNT_DRAWINGS_ATM_CURRENT_mean',\n    'credit_card_balance_CNT_DRAWINGS_CURRENT_max',\n    'credit_card_balance_AMT_BALANCE_mean',\n    'credit_card_balance_AMT_TOTAL_RECEIVABLE_mean'\n]\n\nx_app_bureau_prev_pos_credit = train[x_cols_app_bureau_prev_pos_credit]\nx_app_bureau_prev_pos_credit = imputer.fit_transform(x_app_bureau_prev_pos_credit)\n\nx_app_bureau_prev_pos_credit_train, x_app_bureau_prev_pos_credit_test, y_app_bureau_prev_pos_credit_train, y_app_bureau_prev_pos_credit_test = train_test_split(x_app_bureau_prev_pos_credit, y, test_size = 0.33, random_state = 0)\n\nmodel_app_bureau_prev_pos_credit = RandomForestClassifier()\nmodel_app_bureau_prev_pos_credit.fit(x_app_bureau_prev_pos_credit_train, y_app_bureau_prev_pos_credit_train)\npredictions_app_bureau_prev_pos_credit = model_app_bureau_prev_pos_credit.predict_proba(x_app_bureau_prev_pos_credit_test)\n\nauc_app_bureau_prev_pos_credit = roc_auc_score(y_app_bureau_prev_pos_credit_test, predictions_app_bureau_prev_pos_credit[:,1])\nprint('AUC: application_train.csv + bureau.csv + previous_application.csv + POS_CASH_balance.csv + credit_card_balance.csv:', auc_app_bureau_prev_pos_credit)","ef1d26da":"import lightgbm as lgb\n\nx_app_bureau_prev_pos_credit_train, x_app_bureau_prev_pos_credit_test, y_app_bureau_prev_pos_credit_train, y_app_bureau_prev_pos_credit_test = train_test_split(x_app_bureau_prev_pos_credit, y, test_size = 0.33, random_state = 0)\n\nmodel = lgb.LGBMClassifier(\n    n_estimators=10000, \n    objective = 'binary', \n    class_weight = 'balanced', \n    learning_rate = 0.05, \n    reg_alpha = 0.1, \n    reg_lambda = 0.1, \n    subsample = 0.8, \n    n_jobs = -1, \n    random_state = 50\n)\n\nmodel.fit(\n    x_app_bureau_prev_pos_credit_train,\n    y_app_bureau_prev_pos_credit_train,\n    eval_metric = 'auc'\n)\n\np = model.predict_proba(x_app_bureau_prev_pos_credit_test)\n\nlightGBM_guinea = roc_auc_score(y_app_bureau_prev_pos_credit_test, p[:,1])\nprint('LGBM:', lightGBM_guinea)","1f63b16d":"test_submit = test[x_cols_app_bureau_prev_pos_credit]\ntest_submit = imputer.fit_transform(test_submit)\n\npredictions_final = model.predict_proba(test_submit)","4fc8510d":"submit = pd.DataFrame({\n    \"SK_ID_CURR\": test['SK_ID_CURR'],\n    \"TARGET\": predictions_final[:,1]\n})\n\nsubmit.to_csv('submit.csv', index = False)","1e796807":"# application_train.csv + bureau.csv = ~.635\n# Very minimal improvement, but improvement nonetheless...\n# Now let's layer on previous_application.csv\n","3022adfd":"# Returns ~.646 -> Only a slight increase\n\n# Let's try out the lightGBM library because that is all the rage..\n\n","ee1d351f":"# EDA: credit_card_balance.csv\n# Full EDA here: https:\/\/www.kaggle.com\/jacksmengel\/home-away-eda-credit-card-balance-csv\n# These features had .10 on .corr():\n## - credit_card_balance_CNT_DRAWINGS_ATM_CURRENT_mean\n## - credit_card_balance_CNT_DRAWINGS_CURRENT_max","480d01eb":"# ~.636 .. slightly better!\n\n# Now, add on POS_CASH_balance.csv:","931024ea":"# Inviting our helping friendly libraries.","eee83228":"# ~.63 score using just application_train.csv...\n# Now, let's try adding on the bureau.csv columns...","815328ed":"# EDA: bureau_balance.csv\n# Removing -> did not produce any helpful features :)","26088ed4":"# EDA: application_train.csv\n\n## Found columns which have \"low\" correlation to TARGET.  Nevertheless, built function to do EDA on columns.  \n\n## Findings:\n\n* Age and how long you've been employed are strongest positive correlations.\n* EXT_SOURCE_* columns are strongest negative correlations.","5fb99110":"# Function to do EDA on a Feature\n# Takes in dataframe and column, spits out:\n## - KDE plot on this column relative to TARGET (=0 and =1)\n## - Binned histogram of TARGET being 1 (on average) for that bin\n\n# This function is used throughout EDA process","b0c68e5f":"# Fire away! -> results in .642 score\n# Model is therefore somewhat overfit to train data.\n\n# Next: layer on any interesting features from bureau_balance.csv .. stay tuned!","feb49af1":"# ~.642!  Getting better.\n\n# Add on credit_card_balance.csv (score of .1 on .corr()!).. high hopes.","5eec50ac":"# EDA: previous_application.csv\n# See full EDA here: https:\/\/www.kaggle.com\/jacksmengel\/home-away-eda-previous-application-csv","96f4d321":"# Now I see why .. score improved to .685!  Let's use this in submission","d3a6c324":"# EDA: POS_CASH_balance.csv\n# Only found MONTHS_BALANCE feature to be useful","e7dd15bd":"# It's time to see what these features can do\n\n# First, create imputer and our y dataframe:","1f6c2b90":"# Next, train model using just application_train.csv columns","0aaee11f":"# EDA: bureau.csv\n\n## Built function to find rows with outliers to see if there's an easy fix-up.. there is not.  Lots of outliers.  So I let them be.\n\n## Found columns with very little correlation to TARGET.  Still, they added some predictive value.  \n\n## Running .corr() over every column took a long time.  Minimized .corr() to just run on new columns from bureau.csv.\n\n## Features discovered with some predictive value:\n* bureau_DAYS_CREDIT_mean -> mean value for given applicant on DAYS_CREDIT column (how long credit is issued for)\n* bureau_CREDIT_ACTIVE_Active_mean -> average number of loans that are currently active \/ outstanding\n* bureau_DAYS_CREDIT_min -> Lowest number of days of credit given"}}