{"cell_type":{"200e2a58":"code","86d1f767":"code","d8686c40":"code","b2da0c4d":"code","e31bdfcd":"code","52047515":"code","ca091aee":"code","2aa80bea":"code","4475acfc":"code","42c9b673":"code","58aae19d":"code","c73c2396":"code","08f59661":"code","5accf7b3":"code","42aaf4f6":"code","c7fb27bf":"code","7d88986d":"code","5c77e9e3":"code","db039a11":"code","ddd36241":"code","79ae9237":"markdown","595b56a7":"markdown","de87fc3d":"markdown","cde44a6e":"markdown","54dc4768":"markdown"},"source":{"200e2a58":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86d1f767":"data = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","d8686c40":"data.head()","b2da0c4d":"data['quality'].unique()","e31bdfcd":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n%matplotlib inline","52047515":"data.info()","ca091aee":"data.isnull().sum()","2aa80bea":"import seaborn as sns\nsns.set(rc={'figure.figsize':(12,9)})\nsns.heatmap(data.corr(),annot=True)","4475acfc":"sns.barplot('quality','volatile acidity',data=data)","42c9b673":"sns.boxplot('quality','fixed acidity',data=data)","58aae19d":"sns.barplot('quality','citric acid',data=data)","c73c2396":"sns.barplot('quality','residual sugar',data=data)","08f59661":"bins = (2, 6.5, 8)\ngroup_names = ['bad', 'good']\ndata['quality'] = pd.cut(data['quality'], bins = bins, labels = group_names)","5accf7b3":"data.head()","42aaf4f6":"le = LabelEncoder()\ndata['quality'] = le.fit_transform(data['quality'])","c7fb27bf":"print(data['quality'].unique())\nX = data.drop('quality',axis=1)\nY = data['quality']\n","7d88986d":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state = 42,shuffle=True)","5c77e9e3":"std = StandardScaler()\nX_train = std.fit_transform(X_train)\nX_test = std.transform(X_test)","db039a11":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,confusion_matrix\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\nprediction = model.predict(X_test)\nprint(classification_report(y_test,prediction))","ddd36241":"rfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)\nprint(classification_report(y_test, pred_rfc))","79ae9237":"Thanks for viewing the notebook.","595b56a7":"Accurcacy about 90%","de87fc3d":"**From Logistic our accuracy is around 84%**\n\nLets see the accuracy through other model","cde44a6e":"# Logistic Regression","54dc4768":"# Random Forest Classifier"}}