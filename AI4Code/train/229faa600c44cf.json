{"cell_type":{"ba27fd0b":"code","d2c4d62c":"code","ce89fe48":"markdown","6515a7cd":"markdown","4f39991f":"markdown"},"source":{"ba27fd0b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d2c4d62c":"import tensorflow as tf # Importing tensorflow library \n\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])  # This line defines the type of model(here, it is Sequential) \n                                                                                #  and the first and only layer(look at the keyword Dense) in this neural network\n                                                                                #  units define the no. of neurons in this network(here, it is a single neuron)\n                                                                                #  input_shape defines the no. of input we want to give(here, it is one because we are inputting X only)\n\nmodel.compile(optimizer='sgd', loss='mean_squared_error')  # There are two functions in compile statement:\n                                                           # Optimizer and loss\n                                                           # First, optimizer will make a random prediction of relation,e.g; Y = 5X + 5,\n                                                           # and at the time of training, it will guess how good or how bad the model is \n                                                           # based on the loss function and then the optimizer will generate a new relation\n                                                           # and with the combination of these two, we will get our relation.\n\nX = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\nY = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n\nmodel.fit(X, Y, epochs=500) # Fitting the float data into a loop of 500 times\n                            # Firstly, the optimizer will make a guess and then training the data into the first loop and correcting itself based on the loss function.\n                            # This cycle will repeat for 500 times. The model will make guesses and then correcting itself making more guesses.\n\nprint(model.predict([20.0])) # Printing the prediction","ce89fe48":"**Have you ever played a game of rock, paper and scissor? I bet you have. So, how do you differentiate between rock, paper and scissor? You must be saying that if this pattern forms, then it is a rock and if that pattern then paper. So you have a pattern in mind with which you decide whether it is a rock, paper or scissor. But, how would you teach a computer to recognise patterns as we human beings do. Note: There are people who have different skin tones and people who like to have their fingers stay close to each other and some like to stay as wide as possible. In short, you have to feed information for each and every possible combination of skin tone and these patterns in the computer which would require thousands and thousands lines of code. Is there any possible way out?**\n\n**Machine Learning makes this easy for us. It gives the computer some information and from that information the computer tries to recoginse some patterns by itself. This is the most basic explanation of Machine Learning.**\n\n**Let's work on an example:**\n\n**X = -1, 0, 1, 2, 3, 4**\n\n**Y = -3, -1, 1, 3, 5, 7**\n\n**Can you tell me what's the relation between X and Y ?**\n**Correct, Y = 2X - 1. How did you recognise this relation. Some of you have tried different relations and some of you did some math like Y is this much higher than X so it must be this and then you tried other points to fit inside this realtion and it worked. That's how machine learning principle works. Now the implementation part for which people would have opened this notebook.**","6515a7cd":"*Does this answer matches to the value calculated by the theoritical value? It is close to the answer but not answer, why?*\n\n*It seems to be a straight line for the the 6 points we have given the input but not for other points it has calculated based on the optimizer and loss function. There is a very high chance that it is a straight line for the other points too, but it isn't. This is the very reason you would get a value close to the theoritical value but not that value.*","4f39991f":"**If you learned something, please hit the upvote button. It will encourage me to make more of these notebooks. THANK YOU!!**"}}