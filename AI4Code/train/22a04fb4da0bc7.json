{"cell_type":{"1dd03f98":"code","a745a075":"code","92f01efd":"code","b51e5a7e":"code","8f0eaece":"code","6b6c1439":"code","34d87eab":"code","267100f2":"code","a893fc94":"code","87001122":"markdown","10692b65":"markdown","392f5e63":"markdown","5d85e014":"markdown","e268eed5":"markdown","db51ead3":"markdown","46b06f23":"markdown"},"source":{"1dd03f98":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #matplotlib for vizualization\nimport seaborn as sbs\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a745a075":"data = pd.read_csv(\"\/kaggle\/input\/social-network-adds\/Social_Network_Ads.csv\")\nx=data.iloc[::-1].values\ny=data.iloc[:,-1].values\ndata.head(5)","92f01efd":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 0,test_size = 0.25)","b51e5a7e":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","8f0eaece":"from sklearn.linear_model import LogisticRegression\nlogReg = LogisticRegression(C=50,solver='newton-cg')\nlogReg.fit(x_train,y_train)","6b6c1439":"y_pred=logReg.predict(x_test)\ny_pred","34d87eab":"print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))","267100f2":"from sklearn.metrics import confusion_matrix, accuracy_score\ncf=confusion_matrix(y_test,y_pred)\nprint(accuracy_score(y_test,y_pred))\ncf","a893fc94":"class_names=[\"Not Buy\",\"Buy\"] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsbs.heatmap(pd.DataFrame(cf), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","87001122":"**Feature Scaling**","10692b65":"**Predicting the test result**","392f5e63":"**Making the confusion matrix**","5d85e014":"**Splitting the Dataset into training set and test set**","e268eed5":"Compare the actual result with the predicted result","db51ead3":"**Visualising The Confusion Matrix**","46b06f23":"**Logistic Regression Model**"}}