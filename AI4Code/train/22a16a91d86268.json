{"cell_type":{"0fa6de8b":"code","1d02b770":"code","94377d5e":"code","bece9b8d":"code","f317d4ab":"code","4a11a374":"code","6bed8902":"code","a926ad60":"code","64ff9cfa":"code","4c6e85e2":"code","48731f22":"code","885e1f0a":"code","b5dd7cef":"code","fcbd3b8c":"code","f819dcc4":"code","95763017":"markdown","9c4c58e1":"markdown","79ab970b":"markdown","53e8c835":"markdown","31d9eea2":"markdown","852d483d":"markdown","5193b8e7":"markdown","bee9dc88":"markdown","76a7f799":"markdown","14cf7695":"markdown","cf4f18a6":"markdown","da232b93":"markdown","17609f3a":"markdown","4fea69df":"markdown"},"source":{"0fa6de8b":"! pip install imutils","1d02b770":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nimport pickle\nimport random\nimport time\nimport cv2\nimport os\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom imutils import paths","94377d5e":"# get hold of the train images directory\ndata_path_train = '..\/input\/seg_train\/seg_train'\n# get hold of the test images directory\ndata_path_test = '..\/input\/seg_test\/seg_test'\n\ndef get_images_and_labels(data_path):\n    images = []\n    image_labels = []\n\n    # get the image paths \n    image_paths = sorted(list(paths.list_images(data_path)))\n    random.seed(42)\n    # shuffle the images\n    random.shuffle(image_paths)\n    \n    for image_path in image_paths:\n        # load and resize the images\n        image = cv2.imread(image_path)\n        image = cv2.resize(image, (128, 128))\n        images.append(image)\n\n        # get the train labels\n        image_label = image_path.split(os.path.sep)[-2]\n        image_labels.append(image_label)\n\n    # rescale the image pixels\n    images = np.array(images, dtype='float') \/ 255.0\n    # make the `image_labels` as array\n    image_labels = np.array(image_labels)\n    \n    return images, image_labels","bece9b8d":"train_X, train_y = get_images_and_labels(data_path_train)\ntest_X, test_y = get_images_and_labels(data_path_test)","f317d4ab":"print(len(train_X))\nprint(len(test_X))","4a11a374":"# one-hot encode the labels\nlb = LabelBinarizer()\ntrain_y = lb.fit_transform(train_y)\ntest_y = lb.fit_transform(test_y)","6bed8902":"# generator for image augmentation\nimage_aug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=30, \n                                                            shear_range=0.2, \n                                                            zoom_range=0.2, \n                                                            height_shift_range=0.2, \n                                                            width_shift_range=0.2, \n                                                            horizontal_flip=True, \n                                                            vertical_flip=True,\n                                                            fill_mode='nearest')","a926ad60":"# build the model\nmodel = tf.keras.models.Sequential()\ninput_shape = (128, 128, 3)\n\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', \n            activation='relu', input_shape=input_shape))\nmodel.add(tf.keras.layers.BatchNormalization(axis=-1))      \nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.2))\n        \nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', \n                                 activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization(axis=-1))\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', \n                                 activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization(axis=-1))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.2))\n\nmodel.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', \n                                 activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization(axis=-1))\nmodel.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', \n                                 activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization(axis=-1))\nmodel.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', \n                                 activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization(axis=-1))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.2))\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.2))\n\nmodel.add(tf.keras.layers.Dense(len(lb.classes_), activation='softmax'))","64ff9cfa":"optimizer = tf.keras.optimizers.Adam(lr=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, \n              metrics=['accuracy'])\n\nhistory = model.fit_generator(image_aug.flow(train_X, train_y, \n                                             batch_size=64), \n                                             validation_data=(test_X, test_y), \n                                             steps_per_epoch=len(train_X)\/\/64, \n                                             epochs=30)","4c6e85e2":"model.save('scene_classification.model')\nf = open('scene_classification_lb.pickle', 'wb')\nf.write(pickle.dumps(lb))\nf.close()","48731f22":"num_epochs = np.arange(0, 30)\nplt.figure(dpi=300)\nplt.plot(num_epochs, history.history['loss'], label='train_loss', c='red')\nplt.plot(num_epochs, history.history['val_loss'], \n    label='val_loss', c='orange')\nplt.plot(num_epochs, history.history['acc'], label='train_acc', c='green')\nplt.plot(num_epochs, history.history['val_acc'], \n    label='val_acc', c='blue')\nplt.title('Training Loss and Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Loss\/Accuracy')\nplt.legend()\nplt.savefig('plot.png')","885e1f0a":"# load the test image\nimage = cv2.imread('..\/input\/seg_pred\/seg_pred\/350.jpg')\noutput = image.copy()\nimage = cv2.resize(image, (128, 128))\n\n# scale the pixels\nimage = image.astype('float') \/ 255.0\n\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))","b5dd7cef":"model = tf.keras.models.load_model('scene_classification.model')\nlb = pickle.loads(open('scene_classification_lb.pickle', 'rb').read())","fcbd3b8c":"# predict\npreds = model.predict(image)\n\n# get the class label\nmax_label = preds.argmax(axis=1)[0]\nprint('PREDICTIONS: \\n', preds)\nprint('PREDICTION ARGMAX: ', max_label)\nlabel = lb.classes_[max_label]\nprint(label)","f819dcc4":"# class label along with the probability\ntext = '{}: {:.2f}%'.format(label, preds[0][max_label] * 100)\nplt.figure(figsize=(3, 3))\nplt.text(0, -3, text, fontsize=12)\nplt.imshow(output[:, :, :])","95763017":"## Load and Preprocess the Images","9c4c58e1":"## Import Packages","79ab970b":"## Visualization","53e8c835":"**Be sure to install `imutils` package first when runnung on kaggle kernel**.","31d9eea2":"Let's save the model weights and labels so that when running locally, we can do inference without training each time.","852d483d":"## Saving the Model","5193b8e7":"That's it for this kernel. If you think it helped you, then do consider upvoting it. Also check my website [**DebuggerCafe**](https:\/\/debuggercafe.com\/) for more machine learning posts and tutorials.","bee9dc88":"If you find this kernel helpful, then do consider upvoting it. Also check my website [**DebuggerCafe**](https:\/\/debuggercafe.com\/) for more machine learning posts and tutorials.","76a7f799":"When running locally on your machine, you can run this part independently after you have trained your model once.","14cf7695":"## Data and Directory Structure\n**This part is mainly useful when running locally. If you can running this notebook on Kaggle kernel, then ignore it**.\n\nThe data is taken from Kaggle => [**Intel Image Classification**](https:\/\/www.kaggle.com\/puneet6060\/intel-image-classification).\n\n***The following is the project directory structure:***  \n```\n\u251c\u2500\u2500\u2500.ipynb_checkpoints\n\u2514\u2500\u2500\u2500intel-image-classification\n    \u251c\u2500\u2500\u2500seg_pred\n    \u2502   \u2514\u2500\u2500\u2500seg_pred\n    \u251c\u2500\u2500\u2500seg_test\n    \u2502   \u2514\u2500\u2500\u2500seg_test\n    \u2502       \u251c\u2500\u2500\u2500buildings\n    \u2502       \u251c\u2500\u2500\u2500forest\n    \u2502       \u251c\u2500\u2500\u2500glacier\n    \u2502       \u251c\u2500\u2500\u2500mountain\n    \u2502       \u251c\u2500\u2500\u2500sea\n    \u2502       \u2514\u2500\u2500\u2500street\n    \u2514\u2500\u2500\u2500seg_train\n        \u2514\u2500\u2500\u2500seg_train\n            \u251c\u2500\u2500\u2500buildings\n            \u251c\u2500\u2500\u2500forest\n            \u251c\u2500\u2500\u2500glacier\n            \u251c\u2500\u2500\u2500mountain\n            \u251c\u2500\u2500\u2500sea\n            \u2514\u2500\u2500\u2500street\n```  \nSo, we have the `intel-image-classification` directory. Inside that we have three sub-directories namely. `seg_pred` contains the prediction images which we will use for inference after our model has been trained. `seg_train` contains images for training which we will use for training obviously. Then, finally we will use the images in `seg_test` for validation using training. The above described directories again contain sub-directories, which have the specific images separated by their own directory names. Feel free to explore the folders on your own a bit before proceeding further.","cf4f18a6":"## Introduction\nIn this project we will try to classify images using deep neural networks.\n\nThe Data contains around **25k** images of size **150x150** distributed under 6 categories. **{'buildings' -> 0, 'forest' -> 1, 'glacier' -> 2, 'mountain' -> 3, 'sea' -> 4, 'street' -> 5 }**","da232b93":"## Building the Model","17609f3a":"## Compile and Run the Model","4fea69df":"## Prediction"}}