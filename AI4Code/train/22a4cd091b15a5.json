{"cell_type":{"018eebb3":"code","4c463a05":"code","ff18d069":"code","be0960cd":"code","50232bf4":"code","2ac63c8a":"code","635c0d9c":"code","99391103":"code","f833ddb2":"code","f8e287e1":"code","d79aa02d":"code","91894d90":"code","c77bd9ea":"code","c40f72ec":"code","e71ca686":"markdown","f0ce5846":"markdown","ae0eb1c5":"markdown","a0b917ef":"markdown","5f4b670d":"markdown","b25a0b3d":"markdown","71debbce":"markdown","dfcc46b8":"markdown","7936331c":"markdown","96ff319d":"markdown","adb38a0f":"markdown","28c69b5e":"markdown","96f3fa60":"markdown","722280e0":"markdown","e9f0a5f4":"markdown","48a9053e":"markdown"},"source":{"018eebb3":"# Make sure we have the latest kaggle-environments installed\n!pip install kaggle-environments --upgrade","4c463a05":"from kaggle_environments import make\nfrom kaggle_environments.envs.halite.helpers import *\n\n# Create a test environment for use later\nboard_size = 5\nenvironment = make(\"halite\", configuration={\"size\": board_size, \"startingHalite\": 1000})\nagent_count = 2\nenvironment.reset(agent_count)\nstate = environment.state[0]","ff18d069":"board = Board(state.observation, environment.configuration)\nprint(board)","be0960cd":"print(f\"Player Ids: {[player.id for player in board.players.values()]}\")\nprint(f\"Ship Ids: {[ship.id for ship in board.ships.values()]}\")\n# Note there are currently no shipyards because our Board just initialized\nprint(f\"Shiyard Ids: {[shipyard.id for shipyard in board.shipyards.values()]}\")\nassert len(board.cells) == board_size * board_size","50232bf4":"point = Point(3, -4)\n\n# Points are tuples\nassert isinstance(point, tuple)\n# Points have x and y getters (no setters)\nassert point.x == 3\nassert point.y == -4\n# Points implement several common operators\nassert point == Point(3, -4)\nassert abs(point) == Point(3, 4)\nassert -point == Point(-3, 4)\nassert point + point == (6, -8)\nassert point - point == Point(0, 0)\nassert point * 3 == Point(9, -12)\n# Point supports floordiv but not div since x and y are ints not floats\nassert point \/\/ 2 == Point(1, -2)\nassert point % 3 == Point(0, 2)\n# Prints like a tuple\nprint(point)\nprint(board[point])","2ac63c8a":"print([action.name for action in ShipAction])\nprint([action.name for action in ShipyardAction])\n\n# Grab a ship to test with\nship = next(iter(board.ships.values()))\nprint(f\"Initial action: {ship.next_action}\")\nship.next_action = ShipAction.NORTH\nprint(f\"New action: {ship.next_action}\")","635c0d9c":"print(board)\nboard = board.next()\nprint(board)\n\n# Let's make sure we moved north!\nnext_ship = board.ships[ship.id]\nassert next_ship.position - ship.position == ShipAction.NORTH.to_point()\n# We'll use this in the next cell\nship = next_ship\n\n# What happens if we call board.next()?\nprint(board.next())","99391103":"ship.next_action = ShipAction.CONVERT\nboard = board.next()\nprint(board)","f833ddb2":"shipyard = board[ship.position].shipyard\nshipyard.next_action = ShipyardAction.SPAWN\nboard = board.next()\nprint(board)","f8e287e1":"for ship in board.ships.values():\n    ship.next_action = ShipAction.SOUTH\nboard = board.next()\nprint(board)","d79aa02d":"current_player = board.current_player\nfor ship in current_player.ships:\n    ship.next_action = ShipAction.SOUTH\nprint(current_player.next_actions)","91894d90":"def move_ships_north_agent(observation, configuration):\n    board = Board(observation, configuration)\n    current_player = board.current_player\n    for ship in current_player.ships:\n        ship.next_action = ShipAction.NORTH\n    return current_player.next_actions\n\nenvironment.reset(agent_count)\nenvironment.run([move_ships_north_agent, \"random\"])\nenvironment.render(mode=\"ipython\", width=500, height=450)","c77bd9ea":"@board_agent\ndef move_ships_north_agent(board):\n    for ship in board.current_player.ships:\n        ship.next_action = ShipAction.NORTH\n\nenvironment.reset(agent_count)\nenvironment.run([move_ships_north_agent, \"random\"])\nenvironment.render(mode=\"ipython\", width=500, height=450)","c40f72ec":"first_player_actions = {'0-1': 'CONVERT'}\nsecond_player_actions = {'0-2': 'NORTH'}\n\nactions = [first_player_actions, second_player_actions]\nboard = Board(state.observation, environment.configuration, actions)\nprint(board)\nprint(board.next())","e71ca686":"**Board.\\_\\_str__ Legend:**  \n* Capital letters are shipyards  \n* Lower case letters are ships  \n* Digits are cell halite and scale from 0-9 where 9 is `Board.configuration.max_cell_halite`  \n* Player 1 is letter a\/A  \n* Player 2 is letter b\/B  \n* Player n is letter x\/X","f0ce5846":"# Creating an Agent\nNow we're able to plan and simulate changes to the Halite simulation state. The last step is turning this knowledge into a working agent.\nAs a reminder the signature for a Halite agent is \n```\nagent(observation: Dict[str, Any], configuration: Dict[str, Any]) -> Dict[str, str]\n```\nThe observation and configuration agent parameters can be passed directly to the `Board` constructor to create a board representing the current simulation state.\n\nLastly, we need to generate our return value. The return value of an agent is a dict where the keys are ship or shipyard ids and the values are ship or shipyard actions for the corresponding id to execute.After queueing all actions for our ships and shipyards, we can call `board.current_player.next_actions` to retrieve those actions as an agent response. As noted in the previous section, the return type of `Player.next_actions` is `Dict[str, str]` -- this is to match the return type for agents.","ae0eb1c5":"# Simulating Actions (Lookahead)\nAbove we have set the `next_action` for our ship to NORTH. The `Board.next()` method applies all currently set `next_actions` and steps time forward in the Halite simulation. This method returns a completely new board that will not be affected by subsequent changes to the previous board. Because we've already set `ship.next_action = ShipAction.NORTH` then when we call `board.next()` we should see that our ship has moved north in the next board.","a0b917ef":"If you're new to Halite, check out Alexis' [Getting Started With Halite Notebook](https:\/\/www.kaggle.com\/alexisbcook\/getting-started-with-halite)","5f4b670d":"# Point\nPoints are used to represent positions on the halite board as well as offsets when a ship moves from one position to another. Note that in `Board` the point `(0, 0)` is the lower left corner and the point `(board.configuration.size - 1, board.configuration.size - 1)` is the upper right corner. This differs from the raw Halite observation where the index `0` is the upper left corner and the index `(board.configuration.size * board.configuration.size) - 1` is the lower right corner.","b25a0b3d":"This technique utilizes the `Board` class just for its lookahead ability and not for its action forming or state browsing constructs.","71debbce":"Cool, we've got a shipyard, now let's make a new ship!","dfcc46b8":"# Board\nBoard is the top-level entity when working with the Halite SDK and is the main type we'll construct when building a Halite agent. A board represents the Halite simulation state at a particular turn. Boards are constructed with an observation and configuration as defined in [the halite schema](https:\/\/github.com\/Kaggle\/kaggle-environments\/blob\/master\/kaggle_environments\/envs\/halite\/halite.json).\n\nBoards track all entities in the Halite simulation state including cells, players, ships, and shipyards.","7936331c":"Notice that the second board looks just like the third board. This is because the call to `board.next()` clears all `next_actions` from ships and shipyards in the new board to prevent actions from automatically repeating from step to step.\n\nWhat if we want to make a shipyard?","96ff319d":"We have a complete agent, but wait, there's (slightly) more! This library also vends a `@board_agent` decorator for converting a regular agent into an agent that accepts a `Board` and assigns all `next_actions`. The signature of a `@board_agent` is `agent(board: Board) -> None`, note that there is no return value, we just have to modify the board that's passed to us. Let's convert our `move_ships_north_agent` to a `@board_agent`.","adb38a0f":"# Schema Cheat Sheet\n```\nBoard: {\n    __init__(observation: Dict[str, Any], configuration: Dict[str, Any], next_actions: Optional[List[Dict[str, str]]] = None) -> None\n    cells -> Dict[Point, Cell]\n    ships -> Dict[ShipId, Ship]\n    shipyards -> Dict[ShipyardId, Shipyard]\n    players -> Dict[PlayerId, Player]\n    \n    current_player_id -> PlayerId\n    current_player -> Player\n    opponents -> List[Player]\n    \n    configuration -> Configuration\n    observation -> Dict[str, Any]\n    step -> int\n    \n    next() -> Board\n    \n    __deepcopy__(_) -> Board\n    __getitem__(point: Union[Tuple[int, int], Point]) -> Cell\n    __str__() -> str\n}\n\nCell: {\n    position -> Point\n    halite -> float\n    \n    ship_id -> Optional[ShipId]\n    ship -> Optional[Ship]\n    \n    shipyard_id -> Optional[ShipyardId]\n    shipyard -> Optional[Shipyard]\n\n    north -> Cell\n    south -> Cell\n    east -> Cell\n    west -> Cell\n    \n    neighbor(offset: Point) -> Cell\n}\n\nShip: {\n    id -> ShipId\n    halite -> int\n    \n    position -> Point\n    cell -> Cell\n    \n    player_id -> PlayerId\n    player -> Player\n    \n    next_action -> Optional[ShipAction]\n}\n\nShipyard: {\n    id -> ShipyardId\n    \n    position -> Point\n    cell -> Cell\n    \n    player_id -> PlayerId\n    player -> Player\n    \n    next_action -> Optional[ShipyardAct\n}\n\nPlayer: {\n    id -> PlayerId\n    is_current_player -> bool\n    halite -> int\n    next_actions -> Dict[str, str]\n    \n    ship_ids -> List[ShipId]\n    shipys -> List[Ship]\n    \n    shipyard_ids -> List[ShipyardId]\n    shipyards -> List[Shipyard]\n}\n\nPoint: {\n    x -> int\n    y -> int\n    \n    translate(offset: Point, size: int) -> Point\n    to_index(size: int) -> int\n    \n    @staticmethod\n    from_index(index: int, size: int) -> Point\n    \n    __abs__() -> Point\n    __add__(other: Point) -> Point\n    __eq__(other: Point) -> bool\n    __floordiv__(denominator: int) -> Point\n    __hash__() -> int\n    __mod__(mod: int) -> Point\n    __mul__(factor: int) -> Point\n    __neg__() -> Point\n    __str__() -> str\n    __sub__(other: Point) -> Point\n}\n```","28c69b5e":"# Actions\nActions are how our agent issues commands to our ships and shipyards. The `Ship` and `Shipyard` types each have a settable `next_action` property that enqueues an action to be executed for that ship or shipyard at the end of the current turn. `ShipAction` and `ShipyardAction` types contain enum values for each action.","96f3fa60":"# Board (Advanced)\nUntil now we've always constructed our boards with just an observation and configuration but `Board` also accepts an optional third parameter:\n```\nBoard.__init__(observation: Dict[str, Any], configuration: Dict[str, Any], next_actions: Optional[List[Dict[str, str]]] = None) -> None\n```\nThis parameter can be used to populate next_actions for the board from an external source like an agent.","722280e0":"# Final Thoughts\nThat about covers things! Please let me know if you have any questions, comments, or suggestions for the Halite SDK (or this tutorial) in the discussion for this notebook or [on GitHub](https:\/\/github.com\/Kaggle\/kaggle-environments\/).","e9f0a5f4":"As we set `Ship.next_action` and `Shipyard.next_action` for each entity in our board, the board tracks all of those actions for each player in the `Player.next_actions` property. `Board.current_player` refers to the player that our agent represents, so we can retrieve all of the queued actions for our ships and shipyards with `Board.current_player.next_actions`. Note that the return type of `Player.next_actions` is `Dict[str, str]` **not** `Dict[Union[ShipId, ShipyardId], Union[ShipAction, ShipyardAction]]`. We'll find out why in the next section.","48a9053e":"We can simulate actions for any player in the simulation, not just the current player. Of course our agent won't be able to control opponents during the actual episode evaluation but this technique can be useful for planning our own actions based on the actions we expect our opponents to take.\n\nLet's try moving all ships south."}}