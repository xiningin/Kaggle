{"cell_type":{"f5f5bfb3":"code","73648383":"code","36a31b14":"code","ecca7a3d":"code","22a745b2":"code","f60b0511":"code","24b7ff91":"code","82004d6f":"code","82a2bd58":"code","874ce7b6":"code","1f38cd79":"code","29a675d6":"code","bafeb614":"code","5fb232b0":"code","1f436a25":"code","4573caa1":"code","e5b65e50":"code","ba82e5d8":"code","b53ba7cb":"code","7068c17b":"code","15a06aa7":"code","75e7d756":"code","ea77a651":"code","f6e3a952":"code","606d7e50":"code","dd43e3e8":"code","f19cc21d":"code","2fa9cb64":"code","708fff77":"code","f62f3fa2":"code","a0610b93":"code","efd81d0c":"code","58608b0d":"code","6c507eb7":"code","3a02e5f8":"code","36ddafcf":"code","59f9dba2":"code","84aa6b4f":"code","2b055bbe":"code","e98423f6":"code","454c62c8":"markdown","2d3914dd":"markdown","a9e3258d":"markdown","1c5d1132":"markdown","018b3abd":"markdown","fe93187a":"markdown","2e5f92fc":"markdown","20fed360":"markdown","fcd502bc":"markdown","ce93ca96":"markdown","6a0f879a":"markdown","7da77d41":"markdown","a2a93ba9":"markdown","837c0f35":"markdown","61d463e2":"markdown","78d3caf5":"markdown","64f6fcca":"markdown","443e5af0":"markdown","9f8a07fc":"markdown","24272e48":"markdown","71e7c116":"markdown","90f3bc36":"markdown","0aaef2bd":"markdown","69fa48a3":"markdown","3ec9d2ae":"markdown","1fef7d8e":"markdown","ea72231b":"markdown","1e85da27":"markdown","483d15a1":"markdown","632efe70":"markdown","17af2f2e":"markdown","1a7dfa33":"markdown","5b04d066":"markdown","e0c0d204":"markdown","082457ef":"markdown","b2ef5eb7":"markdown","418234e9":"markdown","e9a24866":"markdown","fc03bf7c":"markdown"},"source":{"f5f5bfb3":"# module imports\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport random\n\n# model imports\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# processing imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nprint('Welcome!')","73648383":"# fetch the training file\nfile_path_20_percent = '..\/input\/nslkdd\/KDDTrain+_20Percent.txt'\nfile_path_full_training_set = '..\/input\/nslkdd\/KDDTrain+.txt'\nfile_path_test = '..\/input\/nslkdd\/KDDTest+.txt' \n\n#df = pd.read_csv(file_path_20_percent)\ndf = pd.read_csv(file_path_full_training_set)\ntest_df = pd.read_csv(file_path_test)","36a31b14":"# add the column labels\ncolumns = (['duration'\n,'protocol_type'\n,'service'\n,'flag'\n,'src_bytes'\n,'dst_bytes'\n,'land'\n,'wrong_fragment'\n,'urgent'\n,'hot'\n,'num_failed_logins'\n,'logged_in'\n,'num_compromised'\n,'root_shell'\n,'su_attempted'\n,'num_root'\n,'num_file_creations'\n,'num_shells'\n,'num_access_files'\n,'num_outbound_cmds'\n,'is_host_login'\n,'is_guest_login'\n,'count'\n,'srv_count'\n,'serror_rate'\n,'srv_serror_rate'\n,'rerror_rate'\n,'srv_rerror_rate'\n,'same_srv_rate'\n,'diff_srv_rate'\n,'srv_diff_host_rate'\n,'dst_host_count'\n,'dst_host_srv_count'\n,'dst_host_same_srv_rate'\n,'dst_host_diff_srv_rate'\n,'dst_host_same_src_port_rate'\n,'dst_host_srv_diff_host_rate'\n,'dst_host_serror_rate'\n,'dst_host_srv_serror_rate'\n,'dst_host_rerror_rate'\n,'dst_host_srv_rerror_rate'\n,'attack'\n,'level'])\n\ndf.columns = columns\ntest_df.columns = columns\n\n# sanity check\ndf.head()","ecca7a3d":"# map normal to 0, all attacks to 1\nis_attack = df.attack.map(lambda a: 0 if a == 'normal' else 1)\ntest_attack = test_df.attack.map(lambda a: 0 if a == 'normal' else 1)\n\n#data_with_attack = df.join(is_attack, rsuffix='_flag')\ndf['attack_flag'] = is_attack\ntest_df['attack_flag'] = test_attack\n\n# view the result\ndf.head()","22a745b2":"# lists to hold our attack classifications\ndos_attacks = ['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm','worm']\nprobe_attacks = ['ipsweep','mscan','nmap','portsweep','saint','satan']\nprivilege_attacks = ['buffer_overflow','loadmdoule','perl','ps','rootkit','sqlattack','xterm']\naccess_attacks = ['ftp_write','guess_passwd','http_tunnel','imap','multihop','named','phf','sendmail','snmpgetattack','snmpguess','spy','warezclient','warezmaster','xclock','xsnoop']\n\n# we will use these for plotting below\nattack_labels = ['Normal','DoS','Probe','Privilege','Access']\n\n# helper function to pass to data frame mapping\ndef map_attack(attack):\n    if attack in dos_attacks:\n        # dos_attacks map to 1\n        attack_type = 1\n    elif attack in probe_attacks:\n        # probe_attacks mapt to 2\n        attack_type = 2\n    elif attack in privilege_attacks:\n        # privilege escalation attacks map to 3\n        attack_type = 3\n    elif attack in access_attacks:\n        # remote access attacks map to 4\n        attack_type = 4\n    else:\n        # normal maps to 0\n        attack_type = 0\n        \n    return attack_type\n\n# map the data and join to the data set\nattack_map = df.attack.apply(map_attack)\ndf['attack_map'] = attack_map\n\ntest_attack_map = test_df.attack.apply(map_attack)\ntest_df['attack_map'] = test_attack_map\n\n# view the result\ndf.head()","f60b0511":"# use a crosstab to get attack vs protocol\nattack_vs_protocol = pd.crosstab(df.attack, df.protocol_type)\nattack_vs_protocol","24b7ff91":"# helper function for drawing mulitple charts.\ndef bake_pies(data_list,labels):\n    list_length = len(data_list)\n    \n    # setup for mapping colors\n    color_list = sns.color_palette()\n    color_cycle = itertools.cycle(color_list)\n    cdict = {}\n    \n    # build the subplots\n    fig, axs = plt.subplots(1, list_length,figsize=(18,10), tight_layout=False)\n    plt.subplots_adjust(wspace=1\/list_length)\n    \n    # loop through the data sets and build the charts\n    for count, data_set in enumerate(data_list): \n        \n        # update our color mapt with new values\n        for num, value in enumerate(np.unique(data_set.index)):\n            if value not in cdict:\n                cdict[value] = next(color_cycle)\n       \n        # build the wedges\n        wedges,texts = axs[count].pie(data_set,\n                           colors=[cdict[v] for v in data_set.index])\n\n        # build the legend\n        axs[count].legend(wedges, data_set.index,\n                           title=\"Flags\",\n                           loc=\"center left\",\n                           bbox_to_anchor=(1, 0, 0.5, 1))\n        # set the title\n        axs[count].set_title(labels[count])\n        \n    return axs   \n\n","82004d6f":"# get the series for each protocol\nicmp_attacks = attack_vs_protocol.icmp\ntcp_attacks = attack_vs_protocol.tcp\nudp_attacks = attack_vs_protocol.udp\n\n# create the charts\nbake_pies([icmp_attacks, tcp_attacks, udp_attacks],['icmp','tcp','udp'])\nplt.show()","82a2bd58":"# get a series with the count of each flag for attack and normal traffic\nnormal_flags = df.loc[df.attack_flag == 0].flag.value_counts()\nattack_flags = df.loc[df.attack_flag == 1].flag.value_counts()\n\n# create the charts\nflag_axs = bake_pies([normal_flags, attack_flags], ['normal','attack'])        \nplt.show()","874ce7b6":"# get a series with the count of each service for attack and normal traffic\nnormal_services = df.loc[df.attack_flag == 0].service.value_counts()\nattack_services = df.loc[df.attack_flag == 1].service.value_counts()\n\n# create the charts\nservice_axs = bake_pies([normal_services, attack_services], ['normal','attack'])        \nplt.show()\n","1f38cd79":"# get the intial set of encoded features and encode them\nfeatures_to_encode = ['protocol_type', 'service', 'flag']\nencoded = pd.get_dummies(df[features_to_encode])\ntest_encoded_base = pd.get_dummies(test_df[features_to_encode])\n\n# not all of the features are in the test set, so we need to account for diffs\ntest_index = np.arange(len(test_df.index))\ncolumn_diffs = list(set(encoded.columns.values)-set(test_encoded_base.columns.values))\n\ndiff_df = pd.DataFrame(0, index=test_index, columns=column_diffs)\n\n# we'll also need to reorder the columns to match, so let's get those\ncolumn_order = encoded.columns.to_list()\n\n# append the new columns\ntest_encoded_temp = test_encoded_base.join(diff_df)\n\n# reorder the columns\ntest_final = test_encoded_temp[column_order].fillna(0)\n\n# get numeric features, we won't worry about encoding these at this point\nnumeric_features = ['duration', 'src_bytes', 'dst_bytes']\n\n# model to fit\/test\nto_fit = encoded.join(df[numeric_features])\ntest_set = test_final.join(test_df[numeric_features])","29a675d6":"# create our target classifications\nbinary_y = df['attack_flag']\nmulti_y = df['attack_map']\n\ntest_binary_y = test_df['attack_flag']\ntest_multi_y = test_df['attack_map']\n\n# build the training sets\nbinary_train_X, binary_val_X, binary_train_y, binary_val_y = train_test_split(to_fit, binary_y, test_size=0.6)\nmulti_train_X, multi_val_X, multi_train_y, multi_val_y = train_test_split(to_fit, multi_y, test_size = 0.6)","bafeb614":"# model for the binary classification\nbinary_model = RandomForestClassifier()\nbinary_model.fit(binary_train_X, binary_train_y)\nbinary_predictions = binary_model.predict(binary_val_X)\n\n# calculate and display our base accuracty\nbase_rf_score = accuracy_score(binary_predictions,binary_val_y)\nbase_rf_score","5fb232b0":"# define the list of models that we want to test\nmodels = [\n    RandomForestClassifier(),\n    LogisticRegression(max_iter=250),\n    KNeighborsClassifier(),\n]\n\n# an empty list to capture the performance of each model\nmodel_comps = []\n\n# walk through the models and populate our list\nfor model in models:\n    model_name = model.__class__.__name__\n    accuracies = cross_val_score(model, binary_train_X, binary_train_y, scoring='accuracy')\n    for count, accuracy in enumerate(accuracies):\n        model_comps.append((model_name, count, accuracy))","1f436a25":"# a box plot will do well to show us overall performance and the variation in the models.\nresult_df = pd.DataFrame(model_comps, columns=['model_name', 'count', 'accuracy'])\nresult_df.pivot(index='count',columns='model_name',values='accuracy').boxplot(rot=45)","4573caa1":"# a helper function for getting some analytical data about our predictions\ndef add_predictions(data_set,predictions,y):\n    prediction_series = pd.Series(predictions, index=y.index)\n\n    # we need to add the predicted and actual outcomes to the data\n    predicted_vs_actual = data_set.assign(predicted=prediction_series)\n    original_data = predicted_vs_actual.assign(actual=y).dropna()\n    conf_matrix = confusion_matrix(original_data['actual'], \n                                   original_data['predicted'])\n    \n    # capture rows with failed predictions\n    base_errors = original_data[original_data['actual'] != original_data['predicted']]\n    \n    # drop columns with no value\n    non_zeros = base_errors.loc[:,(base_errors != 0).any(axis=0)]\n\n    # idetify the type of error\n    false_positives = non_zeros.loc[non_zeros.actual==0]\n    false_negatives = non_zeros.loc[non_zeros.actual==1]\n\n    # put everything into an object\n    prediction_data = {'data': original_data,\n                       'confusion_matrix': conf_matrix,\n                       'errors': base_errors,\n                       'non_zeros': non_zeros,\n                       'false_positives': false_positives,\n                       'false_negatives': false_negatives}\n    \n    return prediction_data\n","e5b65e50":"# capture our prediction data\nbinary_prediction_data = add_predictions(df,\n                                         binary_predictions,\n                                         binary_val_y)\n\n# create a heatmap of the confusion matrix\nsns.heatmap(data=binary_prediction_data['confusion_matrix'],\n            xticklabels = ['Predicted Normal','Predicted Attack'],\n            yticklabels = ['Actual Normal','Actual Attack'],\n            cmap=\"YlGnBu\",\n            fmt='d',\n            annot=True)","ba82e5d8":"# dataframe to store incorrect classification\nbinary_prediction_data['errors'].describe()","b53ba7cb":"# data minus the rows with no variance\nbinary_prediction_data['non_zeros'].describe()","7068c17b":"# see the standard deviation of the false positives\nbinary_prediction_data['false_positives'].std()","15a06aa7":"# see the standard deviation of the false negatives\nbinary_prediction_data['false_negatives'].std()","75e7d756":"# distribution of false negatives--what attacks did we miss?\nbinary_prediction_data['false_negatives'].attack.value_counts().plot.bar()","ea77a651":"# we'll need to pull these from the data set\noutcomes = ['attack_flag','attack_map', 'actual']\n\n# get the new features we're interested in and drop the outcomes\nnew_features = (binary_prediction_data['false_positives']==0).all(axis=0)\nfeature_cols = binary_prediction_data['false_positives'].loc[:,new_features]\nfeature_cols = feature_cols.drop(outcomes,axis=1)\n\n# Let's get these in a list and take a look\nnew_feature_columns = list(feature_cols.columns)\nnew_feature_columns","f6e3a952":"# add the new freatures\nto_fit_new_features = to_fit.join(df[new_feature_columns])\n\n# build the training sets\nnew_feature_train_X, new_feature_val_X, new_feature_train_y, new_feature_val_y = train_test_split(to_fit_new_features, binary_y)","606d7e50":"# model for the binary classification\nnew_feature_model = RandomForestClassifier()\nnew_feature_model.fit(new_feature_train_X, new_feature_train_y)\nnew_feature_predictions = new_feature_model.predict(new_feature_val_X)\n\n# get the score for the model\nnew_feature_score = accuracy_score(new_feature_predictions,new_feature_val_y)\n\nnew_feature_score","dd43e3e8":"# capture the prediction data\nnew_prediction_data = add_predictions(df,\n                                      new_feature_predictions,\n                                      new_feature_val_y)\n\n# create a heatmap of the confusion matrix\nsns.heatmap(data=new_prediction_data['confusion_matrix'],\n            xticklabels = ['Predicted Normal','Predicted Attack'],\n            yticklabels = ['Actual Normal','Actual Attack'],\n            cmap=\"YlGnBu\",\n            fmt='d',\n            annot=True)","f19cc21d":"# distribuition of the false negatives--what attacks did we miss?\nnew_prediction_data['false_negatives'].attack.value_counts().plot.bar()","2fa9cb64":"# model for the binary classification\nfull_model = RandomForestClassifier(random_state=1)\nfull_model.fit(to_fit, binary_y)\nfull_predictions = full_model.predict(test_set)\n\n# get the score\nfull_score = accuracy_score(full_predictions,test_binary_y)\nfull_score","708fff77":"# capture the prediction data\nfull_prediction_data = add_predictions(test_df, full_predictions, test_binary_y)\n\n# create a heatmap of the confusion matrix\nsns.heatmap(data=full_prediction_data['confusion_matrix'],\n            xticklabels = ['Predicted Normal','Predicted Attack'],\n            yticklabels = ['Actual Normal','Actual Attack'],\n            cmap=\"YlGnBu\",\n            fmt='d',\n            annot=True)","f62f3fa2":"# create our label encoder\nlabel_encoder = LabelEncoder()\n\n# get the intial set of encoded features and encode them\nfeatures_to_encode = ['protocol_type', 'flag']\ndummy_encoded = pd.get_dummies(df[features_to_encode])\ntest_dummy_encoded = pd.get_dummies(test_df[features_to_encode])\n\n# now we'll label encode the service column\nlabel_encoder.fit(df.service)\ndummy_encoded['service'] = label_encoder.transform(df.service)\ntest_dummy_encoded['service'] = label_encoder.transform(test_df.service)\n\n# get numeric features, we won't worry about encoding these at this point\nnumeric_features = ['duration', 'src_bytes', 'dst_bytes']\n\n# model to fit\/test\nto_fit = dummy_encoded.join(df[numeric_features])\ntest_set = test_dummy_encoded.join(test_df[numeric_features])\n\n# make sure our columns match\nprint(to_fit.columns)\nprint(test_set.columns)","a0610b93":"# model for the binary classification\nfull_model = RandomForestClassifier(random_state=1)\nfull_model.fit(to_fit, binary_y)\nfull_predictions = full_model.predict(test_set)\n\n# get the score\nfull_score = accuracy_score(full_predictions,test_binary_y)\nfull_score","efd81d0c":"# add new features\nto_fit_new_features = to_fit.join(df[new_feature_columns])\ntest_set_new_features = test_set.join(test_df[new_feature_columns])","58608b0d":"# run the model\nfull_model.fit(to_fit_new_features,binary_y)\nfull_predictions = full_model.predict(test_set_new_features)\n\n# get the score\nfull_score = accuracy_score(full_predictions,test_binary_y)\nfull_score","6c507eb7":"# model for the mulit classification\nmulti_model = RandomForestClassifier()\nmulti_model.fit(multi_train_X, multi_train_y)\nmulti_predictions = multi_model.predict(multi_val_X)\n\n# get the score\naccuracy_score(multi_predictions,multi_val_y)","3a02e5f8":"# build the training sets\nmulti_feature_train_X, multi_feature_val_X, multi_feature_train_y, multi_feature_val_y = train_test_split(to_fit_new_features, multi_y)","36ddafcf":"# model for the mulit classification\nmulti_model = RandomForestClassifier()\nmulti_model.fit(multi_feature_train_X, multi_feature_train_y)\nmulti_predictions = multi_model.predict(multi_feature_val_X)\n\n# get the score\naccuracy_score(multi_predictions,multi_feature_val_y)","59f9dba2":"# capture the prediction data\nmulti_prediction_data = add_predictions(df, multi_predictions, multi_feature_val_y)\n\n# create a heatmap of the confusion matrix\nsns.heatmap(data=multi_prediction_data['confusion_matrix'],\n            xticklabels = ['Predicted ' + x for x in attack_labels],\n            yticklabels = ['Actual ' + x for x in attack_labels],\n            cmap=\"YlGnBu\",\n            fmt='d',\n            annot=True)","84aa6b4f":"# fit on the full data set\nmulti_model.fit(to_fit_new_features, multi_y)\nfull_multi_predictions = multi_model.predict(test_set_new_features)\n\n# get the score\naccuracy_score(full_multi_predictions,test_multi_y)","2b055bbe":"# run the model on the smaller column set\nmulti_model.fit(to_fit, multi_y)\nfull_multi_predictions = multi_model.predict(test_set)\n\n# get the score\naccuracy_score(full_multi_predictions,test_multi_y)","e98423f6":"# build our prediction data\nmulti_prediction_data = add_predictions(df, full_multi_predictions, test_multi_y)\n\n# create a heatmap of the confusion matrix\nsns.heatmap(data=multi_prediction_data['confusion_matrix'],\n            xticklabels = ['Predicted ' + x for x in attack_labels],\n            yticklabels = ['Actual ' + x for x in attack_labels],\n            cmap=\"YlGnBu\",\n            fmt='d',\n            annot=True)","454c62c8":"The thing to notice here is the difference in each protocol type. Our initial impression is that protocol may be useful in being able to identify the type of traffic we are observing. Let's see if flag behaves the same way. ","2d3914dd":"# Model fitting\nBased on the nature of the data we saw above, decision trees are a good starting point for building out predictive models. In this case we'll use a random forest to build and combine multiple trees. We'll start by simply taking the defaults.","a9e3258d":"Now let's go ahead and set our classification targets. We'l do both training sets to start: binrary and multi classifications.","1c5d1132":"Again--strong ability to identify the attack types based on the data coming through. A quick dive into some specifics of the performance.","018b3abd":"Looks like we have a lot of room for some future exploration! We'll use a future notebook to drill into things a bit more and see if we can improve the scores as well as incorporate some more of the delivered sci-kit features to make our work more efficient.","fe93187a":"Neptune and Satan are the biggest misses. Let's see if we can correct that.\n\nThe last data set we were working with was to_fit. So we'll work with that. Since the rest of the values are numeric features, we can add them easily.","2e5f92fc":"That helps us see that most attacks are going to target a specific protocol. There are several (satan, nmap, ipsweep) that are cross-prototcol attacks. Think about why that may be--what is the purpose of those attacks and why would they be cross-protocol?\n\nAlso notice how icmp data is less frequently found in normal traffic.","20fed360":"99% accuracy on our first try! Not bad, right? Let's see how it plays out. \n\nIt might be interesting to see how differnt models compare against a data set like this. That is easy enought to do with `cross_val_score`. ","fcd502bc":"Let's take a look at some charts to see how things are distributed.","ce93ca96":"Now, let's see how we performed.","6a0f879a":"# Exploring NSL-KDD dataset\n\nThe purpose of this notebook is a basic exploration of the NSL-KDD dataset. Here are the goals of this exploration:\n* Gain a basic understanding of the data set\n* Look at how the data set might be used to predict network anomalies or attacks\n* Walk through some fundemental concepts of building machine learning models\n\nThroughout we'll do some work by hand that could be done in more effective ways using delivered functionality within sci-kit. The intent here is to be more deliberate about the process of understanding what we're doing and why. We will look at how to approach some of these problems using the built-in toools in a later notebook.","7da77d41":"# Feature engineering","a2a93ba9":"That's looking better! Still a few that we missed. How about specific attacks?","837c0f35":"# Data transformations\nThe first transformations that we'll want to do are around the attack field. We'll start by adding a column that encodes 'normal' values as 0 and any other value as 1. We will use this as our classifier for a simple binary model that idenfities any attack. ","61d463e2":"It doesn't seem like there's going to be a quick way to get past that. We're going to have to spend some time drilling into the data a little deeper to build a more robust model. There's obviously some overfitting going on and we're going to need to do some work to build a model that does a better job of generalizing the fit. At this point, we're going to let that be an exercise for a future notebook and turn our attention to our multi-classification scenario. Here we are going to see if we can identify the type of attack from the data. Remember, we have four attack types:\n* DOS\n* Probe\n* Privilege escalation\n* Remote access\n\nLet's go ahead and check our base model to start with.\n","78d3caf5":"Overall, things are looking better. We're just missing a few isolated instances of most specific attacks. Neptune is still the hardest to find.","64f6fcca":"Wait, what!? Weren't we running 99%+ with our model? What happened? Let's look at our confusion matrix.","443e5af0":"Notice in the false positives all of columns with no variance? In the false negatives, though, all the columns have some degree of variance. That suggests to us that there may be some good information in those columns because there is a difference bewteen the observations in one classification vs the other.\n\nLet's also take a look at the false-negatives and see what types of attacks we missed.","9f8a07fc":"# Data profiling\nSome intital investigations of what we have in the set. First is a simple table of attack by protocol. In network traffic analysis protocol is a simple tool to create some initial buckets to categorize our data. 'normal' is left in the set at this point as a benchmark.","24272e48":"What about the full data set are we going to see the same overfitting?","71e7c116":"Next, we'll classify each of the attacks according to attack type for a more granular prediction model. \n* Denial of Service attacks:\n  * apache2\n  * back\n  * land\n  * neptune\n  * mailbomb\n  * pod\n  * processtable\n  * smurf\n  * teardrop\n  * udpstorm\n  * worm\n* Probe attacks:\n  * ipsweep\n  * mscan\n  * nmap\n  * portsweep\n  * saint\n  * satan\n* Privilege escalation attacks\n  * buffer_overflow\n  * loadmdoule\n  * perl\n  * ps\n  * rootkit\n  * sqlattack\n  * xterm\n* Remote access attacks\n  * ftp_write\n  * guess_passwd\n  * http_tunnel\n  * imap\n  * multihop\n  * named\n  * phf\n  * sendmail\n  * snmpgetattack\n  * snmpguess\n  * spy\n  * warezclient\n  * warezmaster\n  * xclock\n  * xsnoop","90f3bc36":"Now we can take a closer look at our results. The first thing that we can do is look at a confusion matrix, which in this case will map the predicted classification to the actual classification.","0aaef2bd":"# Data extraction\nWe'll start by fetching our data set. There's a few options for data sets here, so we'll build a couple paths and use comments to pick and choose the ones we want.","69fa48a3":"What we find is some inconsistency across the models. The random forest and K-nearest neighbors are tight groupings with solid performance. Our logistic regression didn't perform as well. That may be in  part because we didn't do sufficient preprocessing on our data to shape it into a form optimized for that model. That too is an exercise for another day.","3ec9d2ae":"Ugh! Again, looks like some significant over fitting. What if we use our smaller `to_fit` object with less features?","1fef7d8e":"Notice there are several columns with a standard deviation of 0. That tells us that there is no additional information to glean from those columns. So we can start by dropping those. ","ea72231b":"We see a lot of false positives (normal traffic that got flagged as an attack) and false negatives (attack traffic that got flagged as normal) there.  \n\nSo let's explore the prediction errors a bit and see if there is more information to extract.","1e85da27":"Let's try it with the additional features.","483d15a1":"Now let's add the new features.","632efe70":"Now it's time to for the real thing. Let's run our model against some unseen data. We can think of this as new network traffic.\n\nWe will fit our model on full dataset and then run it against the test set to see how we did. ","17af2f2e":"So let's dive into some feature building. It seems like that items above would make a good place to start: protocol_type, service and flag. There's enough variation between these that we should be able to get some base level of identification. We're also going to throw in some basic numeric data: duration, src_bytes, dst_bytes. All of these are going to be readily available from modern network equipment and should tell us a lot about what is happening on our network.","1a7dfa33":"The data set doesn't include column names, so let's add them.","5b04d066":"Wow! Look at how many services are in the attack set! Whereas a huge amount of normal traffic is http, our attack traffic is all over the place. That is interesting as it means that attacks are searching for many different paths into systems--some well traveled and some not. \n\nIf we think about this from the eyes of a network adminstrator, the combination of protocol, flag and service seem like they should tell us a lot about the nature of our traffic. Coupling them with the duration of a connection and the amount of data in that connection seems like a good starting point for us.","e0c0d204":"We'll run another confustion matrix to see our missed predictions...","082457ef":"Now we should see some variance across our features. Here, though, we're going to look into our false positives and false negatives separately and see what we notice.","b2ef5eb7":"And service?","418234e9":"# Analyzing our predictions\nLet's take a look at how our predictions fared. We are going to create a helper function to pull some relevant metrics from our results. ","e9a24866":"Yikes! That's a lot of bad predictions! Because we are not setting the random_state, the specifics will vary for each run. Generally, though, we are seeing a lot of false negatives--missed attacks.\n\nThis sure looks a lot like over fitting our data. Since the RandomForestClassifier tends to have good default settings, one likely scenario is that we have too many features. Remember how we had all those services and one-hot encoded them? That creates a lot of columns (features). Let's start by walking back a bit and shifting how we encode that. We'll use label encoding instead to generate a single feature with a unique numeric value for each string value in the original data set.","fc03bf7c":"It's worth drawing attention to a few things here. First, `pd.get_dummies` is a method that allows us to do a quick one hot encoding on our columns. This takes every value it finds in a single column and makes an individual column for each value, with a `0` or `1` indicating whether that column is 'hot'.\n\nOne thing we find is that note every value is in the test data. So that creates different shapes of our data frame. That's why we added some columns, filled them in and reorded them. We know they are all zeros because they aren't in the data."}}