{"cell_type":{"9439f811":"code","21054b9b":"code","8f57ccfa":"code","61fd45df":"code","d14237f5":"code","f037b28b":"code","52f5a0ca":"code","905e3b54":"code","4d3b1f98":"code","5eb5e2d3":"code","d6317a19":"code","e40b9295":"code","9fe2ed51":"code","573c38fb":"code","ea9f527e":"code","bdb6b96a":"code","663d4c3e":"code","28057ed1":"code","27179150":"code","0b883acd":"code","70eed1a1":"code","97a5ebb2":"code","9128ca43":"code","690ea0c8":"code","0c9b78a3":"code","c7b98dbf":"code","92046b00":"code","5fec3986":"code","ce220141":"code","578024b3":"code","a74a1e2e":"code","ceb98759":"code","fafb24ff":"code","1d384c17":"code","8d20677c":"code","82ee7d5d":"code","514979c1":"code","221669ce":"code","a76a71a7":"code","20a73a40":"code","d539556f":"code","484a7cca":"code","0afb4195":"code","55686703":"code","f3d53f26":"code","b7b669c5":"code","dfdb128b":"code","f79e1a79":"code","0a2e8c93":"code","333dbac7":"code","e234e89d":"markdown","c287cf3c":"markdown","e28a6807":"markdown","c3460bdf":"markdown","b508b31f":"markdown","8f7d78d0":"markdown","236609fc":"markdown","71e1ff6d":"markdown","6f1c633e":"markdown","0d303bc0":"markdown","5b36d0a7":"markdown","e6f926ac":"markdown","0ba1e336":"markdown","0e9994f3":"markdown","7be590bb":"markdown","64dc4858":"markdown","f1e70f40":"markdown","4351dcb6":"markdown","a1a9ea7a":"markdown","2d14cf47":"markdown","49f8950e":"markdown","ef09010e":"markdown","01b0fe53":"markdown","616d0762":"markdown"},"source":{"9439f811":"#Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_absolute_error\nimport gc\n\n#Figures Inline and Visualization style\n%matplotlib inline\nsb.set()","21054b9b":"train = pd.read_csv('..\/input\/train_V2.csv')\ntest = pd.read_csv('..\/input\/test_V2.csv')\ntrain.dropna(inplace=True)","8f57ccfa":"train['matchType'].value_counts()","61fd45df":"train['teamPlayers']=train.groupId.map(train.groupId.value_counts())\ntest['teamPlayers']=test.groupId.map(test.groupId.value_counts())\ntrain['gamePlayers']=train.matchId.map(train.matchId.value_counts())\ntest['gamePlayers']=test.matchId.map(test.matchId.value_counts())","d14237f5":"train['enemyPlayers']=train['gamePlayers']-train['teamPlayers']\ntest['enemyPlayers']=test['gamePlayers']-test['teamPlayers']","f037b28b":"train['totalDistance']=train['rideDistance']+train['swimDistance']+train['walkDistance']\ntest['totalDistance']=test['rideDistance']+test['swimDistance']+test['walkDistance']","52f5a0ca":"train['enemyDamage']=train['assists']+train['kills']\ntest['enemyDamage']=test['assists']+test['kills']","905e3b54":"totalKills = train.groupby(['matchId','groupId']).agg({'kills': lambda x: x.sum()})\ntotalKills.rename(columns={\"kills\": \"squadKills\"}, inplace=True)\ntrain = train.join(other=totalKills, on=['matchId', 'groupId'])\ntotalKills = test.groupby(['matchId','groupId']).agg({'kills': lambda x: x.sum()})\ntotalKills.rename(columns={\"kills\": \"squadKills\"}, inplace=True)\ntest = test.join(other=totalKills, on=['matchId', 'groupId'])","4d3b1f98":"train['medicKits']=train['heals']+train['boosts']\ntest['medicKits']=test['heals']+test['boosts']","5eb5e2d3":"train['medicPerKill'] = train['medicKits']\/train['enemyDamage']\ntest['medicPerKill'] = test['medicKits']\/test['enemyDamage']","d6317a19":"train['distancePerHeals'] = train['totalDistance']\/train['heals']\ntest['distancePerHeals'] = test['totalDistance']\/test['heals']","e40b9295":"train['headShotKillRatio']=train['headshotKills']\/train['kills']\ntest['headShotKillRatio']=test['headshotKills']\/test['kills']","9fe2ed51":"train['headshotKillRate'] = train['headshotKills'] \/ train['kills']\ntest['headshotKillRate'] = test['headshotKills'] \/ test['kills']","573c38fb":"train['killPlaceOverMaxPlace'] = train['killPlace'] \/ train['maxPlace']\ntest['killPlaceOverMaxPlace'] = test['killPlace'] \/ test['maxPlace']","ea9f527e":"train['kills\/distance']=train['kills']\/train['totalDistance']\ntest['kills\/distance']=test['kills']\/test['totalDistance']","bdb6b96a":"train['kills\/walkDistance']=train['kills']\/train['walkDistance']\ntest['kills\/walkDistance']=test['kills']\/test['walkDistance']","663d4c3e":"train['avgKills'] = train['squadKills']\/train['teamPlayers']\ntest['avgKills'] = test['squadKills']\/test['teamPlayers']","28057ed1":"train['damageRatio'] = train['damageDealt']\/train['enemyDamage']\ntest['damageRatio'] = test['damageDealt']\/test['enemyDamage']","27179150":"train['distTravelledPerGame'] = train['totalDistance']\/train['matchDuration']\ntest['distTravelledPerGame'] = test['totalDistance']\/test['matchDuration']","0b883acd":"train['killPlacePerc'] = train['killPlace']\/train['gamePlayers']\ntest['killPlacePerc'] = test['killPlace']\/test['gamePlayers']","70eed1a1":"train[\"playerSkill\"] = train[\"headshotKills\"]+ train[\"roadKills\"]+train[\"assists\"]-(5*train['teamKills']) \ntest[\"playerSkill\"] = test[\"headshotKills\"]+ test[\"roadKills\"]+test[\"assists\"]-(5*test['teamKills'])","97a5ebb2":"train['gamePlacePerc'] = train['killPlace']\/train['maxPlace']\ntest['gamePlacePerc'] = test['killPlace']\/test['maxPlace']","9128ca43":"train.fillna(0,inplace=True)\ntrain.replace(np.inf, 0, inplace=True)\ntest.fillna(0,inplace=True)\ntest.replace(np.inf, 0, inplace=True)","690ea0c8":"train.count()","0c9b78a3":"train.drop(columns=['killPoints','rankPoints','winPoints','maxPlace'],inplace=True)\ntest.drop(columns=['killPoints','rankPoints','winPoints','maxPlace'],inplace=True)","c7b98dbf":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage, took from Kaggle.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n                    \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    return df","92046b00":"def feature(df):\n    features = list(df.columns)\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    features.remove(\"matchType\")\n    condition='False'\n    \n    if 'winPlacePerc' in df.columns:\n        y = np.array(df.groupby(['matchId','groupId'])['winPlacePerc'].agg('mean'), dtype=np.float64)\n        features.remove(\"winPlacePerc\")\n        condition='True'\n        \n    print(\"get group mean feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = agg.reset_index()[['matchId','groupId']]\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n        \n    print(\"get group max feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get match mean feature\")\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    df_id=df_out[[\"matchId\", \"groupId\"]].copy()\n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n    \n    del df, agg, agg_rank\n    gc.collect()\n    if condition=='True':\n        return df_out,pd.DataFrame(y),df_id\n    else:\n        return df_out,df_id","5fec3986":"x,y,id_train=feature(reduce_mem_usage(train))","ce220141":"x_test,id_test=feature(reduce_mem_usage(test))","578024b3":"del train,test\ngc.collect()","a74a1e2e":"x['matchId']=id_train['matchId']\nx['groupId']=id_train['groupId']\n# Train test split\nx_train,x_val,y_train,y_val=train_test_split(reduce_mem_usage(x),y,test_size=.1)\nx_test=reduce_mem_usage(x_test)\nid_val=x_val[['matchId','groupId']]\nx_val.drop(['matchId','groupId'],axis=1,inplace=True)\nx_train.drop(['matchId','groupId'],axis=1,inplace=True)\nx.drop(['matchId','groupId'],axis=1,inplace=True)\ndel y\ngc.collect()","ceb98759":"params = {\n        \"objective\" : \"regression\", \n        \"metric\" : \"mae\", \n        \"num_leaves\" : 149, \n        \"learning_rate\" : 0.03, \n        \"bagging_fraction\" : 0.9,\n        \"bagging_seed\" : 0, \n        \"num_threads\" : 4,\n        \"colsample_bytree\" : 0.5,\n        'min_data_in_leaf':1900, \n        'min_split_gain':0.00011,\n        'lambda_l2':9\n}","fafb24ff":"# create dataset for lightgbm\nlgb_train = lgb.Dataset(x_train, y_train,\n                       free_raw_data=False)\nlgb_eval = lgb.Dataset(x_val, y_val, reference=lgb_train,\n                      free_raw_data=False)","1d384c17":"model = lgb.train(params,\n                lgb_train,\n                num_boost_round=22000,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=10,\n                verbose_eval=1000)","8d20677c":"y_pred_val = model.predict(x, num_iteration=model.best_iteration)\nid_train['win_pred']=y_pred_val\nid_train.set_index(['matchId','groupId'])\ntrain = reduce_mem_usage(pd.read_csv(\"..\/input\/train_V2.csv\"))\n\ndf=pd.merge(train,id_train,on=['matchId','groupId'],how='right')\ndf","82ee7d5d":"print('The mae score is {}'.format(mean_absolute_error(df['winPlacePerc'],df['win_pred'])))\ndf = df[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\",'winPlacePerc', 'win_pred']]","514979c1":"df_grouped = df.groupby([\"matchId\", \"groupId\"]).first().reset_index()\ndf_grouped[\"team_place\"] = df_grouped.groupby([\"matchId\"])[\"win_pred\"].rank()\ndf_grouped","221669ce":"df_grouped[\"win_perc\"] = (df_grouped[\"team_place\"] - 1) \/ (df_grouped[\"numGroups\"]-1)\ndf = df.merge(df_grouped[[\"win_perc\",\"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")","a76a71a7":"df.loc[df['maxPlace'] == 0, \"win_perc\"] = 0\ndf.loc[df['maxPlace'] == 1, \"win_perc\"] = 1\ndf.loc[(df['maxPlace'] > 1) & (df['numGroups'] == 1), \"win_perc\"] = 0\ndf.loc[df['win_perc'] < 0,\"win_perc\"] = 0\ndf.loc[df['win_perc'] > 1,\"win_perc\"] = 1\ndf['win_perc'].fillna(df['win_pred'],inplace=True)","20a73a40":"df_grouped[df_grouped['maxPlace']>1][['winPlacePerc','win_perc','maxPlace','numGroups','team_place']]","d539556f":"subset = df.loc[df['maxPlace'] > 1]\ngap = 1 \/ (subset['maxPlace'].values-1)\nnew_perc = np.around(subset['win_perc'].values \/ gap) * gap\ndf.loc[df.maxPlace > 1, \"win_perc\"] = new_perc","484a7cca":"print('The new mae score is {}'.format(mean_absolute_error(df['winPlacePerc'],df['win_perc'])))","0afb4195":"del x,train,df\ngc.collect()","55686703":"y_pred = model.predict(x_test, num_iteration=model.best_iteration)\nid_test['win_pred']=y_pred\nid_test.set_index(['matchId','groupId'])\ndel x_train,x_val,y_train,y_val,x_test\ngc.collect()\n\ntest = reduce_mem_usage(pd.read_csv(\"..\/input\/test_V2.csv\"))\ndf=pd.merge(test,id_test,on=['matchId','groupId'],how='right')\ndel id_test,test\ngc.collect()\ndf","f3d53f26":"df = df[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\",'win_pred']]","b7b669c5":"df_grouped = df.groupby([\"matchId\", \"groupId\"]).first().reset_index()\ndf_grouped[\"team_place\"] = df_grouped.groupby([\"matchId\"])[\"win_pred\"].rank()\ndf_grouped","dfdb128b":"df_grouped[\"win_perc\"] = (df_grouped[\"team_place\"] - 1) \/ (df_grouped[\"numGroups\"]-1)\ndf = df.merge(df_grouped[[\"win_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")","f79e1a79":"df.loc[df.maxPlace == 0, \"win_perc\"] = 0\ndf.loc[df.maxPlace == 1, \"win_perc\"] = 1\ndf.loc[(df.maxPlace > 1) & (df.numGroups == 1), \"win_perc\"] = 0\ndf.loc[df['win_perc'] < 0,\"win_perc\"] = 0\ndf.loc[df['win_perc'] > 1,\"win_perc\"] = 1\ndf['win_perc'].fillna(df['win_pred'],inplace=True)","0a2e8c93":"subset = df.loc[df['maxPlace'] > 1]\ngap = 1 \/ (subset['maxPlace'].values-1)\nnew_perc = np.around(subset['win_perc'].values \/ gap) * gap\ndf.loc[df.maxPlace > 1, \"win_perc\"] = new_perc\ndf['winPlacePerc']=df['win_perc']","333dbac7":"df=df[['Id','winPlacePerc']]\ndf.to_csv(\"submission_final.csv\", index=False)","e234e89d":"'groupId' and 'matchId' are available in the data.  From these, no. of players in the team and total players entered in the match can be extracted.","c287cf3c":"New column containing total kills by the team. For this, rows are grouped based on 'matchId', 'groupId' and the sum of matching row 'kills' are taken.","e28a6807":"Lets create  new columns and find if any of them helps improve model prediction.","c3460bdf":"Let's take only one row from each groupby matchId and groupId since the winPlacePerc is almost same for each player in a team. Now sort and rank each group in a match. Rank is directly proportional to predicted winPerc.","b508b31f":"Split the data into train and validation set.","8f7d78d0":"New column which is the sum of assists and kills.","236609fc":"# Woahh!!! The Score has improved a lot. ","71e1ff6d":"Let's create a new column with total enemy players . The players remaining other than the player's squad. ","6f1c633e":"Let's take only one row from each groupby matchId and groupId since the winPlacePerc is almost same for each player in a team. Now sort and rank each group in a match. Rank is directly proportional to winPlacePerc.","0d303bc0":"Let's post process the new win_perc similar. winPlacePerc shoul not exceed 1 and should not drop below 0. It should be between 1 and 0. Also maxPlace=0 is impossible in a game and maxPlace=0 means their is no team. So winPerc=0. Similarly maxPlace=0 means only one team. ","5b36d0a7":"Now that we have trained the model, let' have a look if we can make some tweaks in the predicted data so that the predicted value can be improved. First let's merge the predicted value with appropriate gamer Id in the train data.","e6f926ac":"# **3. FEATURE ENGINEERING**","0ba1e336":"# This idea I got while referring similar kernels published publicly during the competion time and the credit goes for <a href='https:\/\/www.kaggle.com\/anycode\/simple-nn-baseline-3'>Kernel Here<\/a>. This helps to change the predicted win by few decimal points and improve the mae score. ","0e9994f3":"# 6.Post Processing","7be590bb":"Let's Inspect the categorical colmn match type. ","64dc4858":"From the heat map, killPoints, rankPoints, winPoints, maxPlace are found to be not having any significance in determining winPlacePerc. So let's remove these features from the data set. ","f1e70f40":"It has been found out that rank of team\/team_place is proportional to winPlacePerc. So team_place can be used as the most important factor judging winplacePerc. Let's try to explain winPlacePerc as the ratio of team_place to numGroups. team_place will never be equal to zero. However winPlacePerc can also be zero. So let's subtract 1 from team_place as that will return zero in cases where team_place=1.","4351dcb6":"# If you liked the kernel, DO upvote! ","a1a9ea7a":"The newly created features contains missing values and Infinity values in it. Let's replace these with 0.","2d14cf47":"# This is the second part of my Kernel containing only the Feature Engineering and LightGBM algorithm. The Kernel is divided into two sections due to memory and time constraints of kaggle kernel. For Exploratory Data Analysis and Base Model of my kernel, Visit the first part of the model <a href='https:\/\/www.kaggle.com\/iamarjunchandra\/part-1-pubg-eda-base-model'>Here!<\/a>","49f8950e":"Let's create a new column representing the total distance(ride+swim+walk) covered by the player in the game. ","ef09010e":"# **4. GRADIENT BOOSTING MODEL**","01b0fe53":"In Pubg, if a player wins, his team mates are also winners. So instead on finding winPlacePerc for individual payers, let's find the winPlacePerc for each group in a match.  Let's write a function that will create new columns that are the match wise and group wise mean, max, min of all the current features and also rank them.","616d0762":"# SUBMISSION"}}