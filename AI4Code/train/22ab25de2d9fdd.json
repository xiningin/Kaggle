{"cell_type":{"fee91ef9":"code","1869d0e7":"code","3dc20981":"code","0c149578":"code","68b1c328":"code","30a631cc":"code","f8d99d94":"code","733aa269":"code","56ce3a8a":"code","bcc3603d":"code","e2f8eef8":"code","dbe27007":"code","32c9b27c":"code","765d4cad":"code","a29f5c9b":"code","734271b1":"code","8c4893b4":"code","cc660a19":"code","a76e75d5":"code","7aa4a472":"code","3d493ab5":"code","45f27d8c":"markdown","88a7a7df":"markdown","74255bc4":"markdown","1850f9a3":"markdown","c23990ba":"markdown","60614c19":"markdown","ba9ceb26":"markdown","de49bca0":"markdown","d110a79c":"markdown"},"source":{"fee91ef9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1869d0e7":"from collections import Counter\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer, MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss","3dc20981":"df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv')\ndf.info()","0c149578":"# We can see that all the features follow different scales\ndf.describe()","68b1c328":"target = df['target']\ndf = df.drop(columns=['id', 'target'])\nprint(df.shape, len(target), type(target))","30a631cc":"target.value_counts()","f8d99d94":"pip install -U imbalanced-learn","733aa269":"from imblearn.over_sampling import SMOTE\nX_sam, y_sam = SMOTE().fit_resample(df, target)\nprint(X_sam.shape, y_sam.shape)\ny_sam.value_counts()","56ce3a8a":"X_train, X_test, y_train, y_test = train_test_split(X_sam, y_sam, random_state=42, test_size=0.05)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","bcc3603d":"sc = StandardScaler()\nsc.fit_transform(X_train)\nsc.transform(X_test)","e2f8eef8":"pca = PCA(n_components=0.99, svd_solver='full')\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nprint(pca.n_components_)\nprint(X_train.shape, X_test.shape)","dbe27007":"clf = RandomForestClassifier()\nclf.fit(X_train, y_train)\ny_pred_prob = clf.predict_proba(X_test)\ny_pred = clf.predict(X_test)","32c9b27c":"print(y_pred_prob[5], y_pred)","765d4cad":"log_loss(y_test, y_pred_prob)","a29f5c9b":"test_df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv')\nids = test_df['id']\ntest_df = test_df.drop(columns=['id'])\nsc.transform(test_df)\ntest_df = pca.transform(test_df)\nprint(test_df.shape)","734271b1":"y_sub = clf.predict_proba(test_df)\ny_sub.shape","8c4893b4":"col_names = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', \n             'Class_7', 'Class_8', 'Class_9']\ndf_sub = pd.DataFrame(data=y_sub, columns=col_names)\ndf_sub.shape","cc660a19":"df_sub.head()","a76e75d5":"df_ids = pd.DataFrame(data=ids, columns=['id'])\nprint(df_ids.shape)\ndf_ids.head()","7aa4a472":"df_final = pd.concat([df_ids, df_sub], axis=1)\ndf_final.head()","3d493ab5":"df_final.to_csv('submission.csv', index=False)","45f27d8c":"## Importing the required libraries and modules","88a7a7df":"# Tabular Playground Series (June 2021)\n- This notebook covers my code for the Tabular Playground Series - June challenge, based on Random Forest classifier\n- As the dataset is severely imbalanced, I have used an over-sampling technique in order to balance the dataset, particularly SMOTE (Synthetic Minority Oversampling Technique).\n- In order to increase the accuracy of the predictions, I have used PCA in order to reduce the dimensions, such that the data continues to contain 99% of it's variance.\n- Also, I have standardized the data, in order to remove the effect of the scales on the data.\n- If you have any queries, feel free to post them in the comments section.","74255bc4":"## SMOTE ","1850f9a3":"## Modelling the Data","c23990ba":"## Feature Importance","60614c19":"## Describing the data","ba9ceb26":"## Pre-processing the data","de49bca0":"## Submission","d110a79c":"### Conclusions:\n- As can be seen from the above values, the dataset is highly imbalanced towards Classes 6 and 8.\n- In order to balance this dataset, we will be using **SMOTE (Synthetic Minority Oversampling TEchnique)**"}}