{"cell_type":{"f8faa3c8":"code","d9e590d7":"code","578c99c7":"code","a3c749fc":"code","2a0b0aab":"code","ecbed5ef":"code","7a859dd7":"code","6cde36ba":"code","3bc5c1bd":"code","f6250f8c":"code","b0dd69e7":"code","7ff3f66d":"code","4b3418bb":"code","fd61225d":"code","01b769e4":"code","771ff45c":"code","50281600":"code","1dc86983":"code","955a78af":"code","0495fa38":"code","c8657dd9":"code","b9642f2f":"code","ad52a72a":"code","2e73bbc6":"code","23d501a0":"code","e65e57c8":"code","3804e00a":"code","ea36c767":"code","ddcb1312":"code","e73f7d7d":"code","f0e139ff":"code","e8d1a01f":"code","cf6bee40":"code","42b1ea11":"code","77e212fe":"code","279a7617":"code","36ee4d5c":"markdown","38459655":"markdown","344877b5":"markdown","53af7b7d":"markdown","296b289d":"markdown","52d0417b":"markdown","d6437cda":"markdown","b735b1aa":"markdown"},"source":{"f8faa3c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d9e590d7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","578c99c7":"df=pd.read_csv('\/kaggle\/input\/beginner-dataset-v2\/beginner_level_dataset_2\/census_income.csv', sep=';')","a3c749fc":"df.head(5)","2a0b0aab":"#Information about the dataset\ndf.info()","ecbed5ef":"#Replace question marks with nan value\ndf[df == '?'] = np.nan","7a859dd7":"df.info()","6cde36ba":"# There are missing values in some columns\ndf.isnull().sum()","3bc5c1bd":"#Column names in the dataset\ndf.columns","f6250f8c":"#Strip spaces in the dataset\ndf.rename(columns=lambda x: x.strip(),inplace=True)","b0dd69e7":"#Impute missing values with mode\nfor col in ['sex', 'capital-gain', 'capital-loss','hours-per-week','native-country','income' ]:\n    df[col].fillna(df[col].mode()[0], inplace=True)","7ff3f66d":"df.isnull().sum()","4b3418bb":"categorical = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\ndf[categorical] = df[categorical].astype(str)","fd61225d":"class MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)","01b769e4":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\ndf=MultiColumnLabelEncoder(columns = categorical).fit_transform(df)","771ff45c":"X = df.drop(['income'], axis=1)\ny = df['income']","50281600":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","1dc86983":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n\nX_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)","955a78af":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\n\nprint('Logistic Regression accuracy score with all the features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","0495fa38":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)\n\nprint('Random Forest accuracy score with all the features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","c8657dd9":"from sklearn.ensemble import RandomForestClassifier\nfrom boruta import BorutaPy\nfrom datetime import datetime\nimport pandas as pd","b9642f2f":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))","ad52a72a":"X = df.drop(['income'], axis=1).values\ny = df['income'].values","2e73bbc6":"rfc = RandomForestClassifier(n_estimators=200, n_jobs=4, class_weight='balanced', max_depth=6)\nboruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2)\nstart_time = timer(None)\nboruta_selector.fit(X, y)\ntimer(start_time)","23d501a0":"# number of selected features\nprint ('\\n Number of selected features:')\nprint (boruta_selector.n_features_)","e65e57c8":"feature_df = pd.DataFrame(df.drop(['income'], axis=1).columns.tolist(), columns=['features'])\nfeature_df['rank']=boruta_selector.ranking_\nfeature_df = feature_df.sort_values('rank', ascending=True).reset_index(drop=True)\nprint ('\\n Top %d features:' % boruta_selector.n_features_)\nfeature_df2=feature_df.head(boruta_selector.n_features_)\nfeature_df2.shape","3804e00a":"feature_list=feature_df2['features'].to_list()\nfeature_list","ea36c767":"feature_list.append('income')","ddcb1312":"df_boruta=df[feature_list]","e73f7d7d":"df_boruta.info()","f0e139ff":"df_boruta.head()","e8d1a01f":"X = df_boruta.drop(['income'], axis=1)\ny = df_boruta['income']","cf6bee40":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","42b1ea11":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n\nX_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)","77e212fe":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\n\nprint('Logistic Regression accuracy score with Boruta features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","279a7617":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)\n\nprint('Random Forest accuracy score with Boruta features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","36ee4d5c":"# *4. Apply Models*","38459655":"# *3. Label Encoding*\n\nLabel Encoding refers to converting the labels into numeric form so as to convert it into the machine-readable form. Machine learning algorithms can then decide in a better way on how those labels must be operated. It is an important pre-processing step for the structured dataset in supervised learning.","344877b5":"# *5. Apply Boruta for feature selection*","53af7b7d":"# *1.Import libraries and Read the data*","296b289d":"# *6. Apply Models for Boruta Features*","52d0417b":"# *2. Preprocess the data*","d6437cda":"# *8. Some last words*\n\nCheck out this link for more details on Boruta and Label Encoding: \n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html\n\nhttps:\/\/github.com\/scikit-learn-contrib\/boruta_py\n\nIf you have any ideas to feedback please let me know in comments, and if you liked my work please don't forget to vote, thank you!","b735b1aa":"# ***Getting Started with Boruta***\n\nThis notebook was created for getting beginner level simple prediction and also, usage example of Boruta.\n\nBoruta is a pretty smart algorithm dating back to 2010 designed to automatically perform feature selection on a dataset. It was born as a package for R (this is the article that first described it). A version of Boruta for Python \u2014 called BorutaPy \u2014.\n\nBoruta is an all relevant feature selection method, while most other are minimal optimal; this means it tries to find all features carrying information usable for prediction, rather than finding a possibly compact subset of features on which some classifier has a minimal error."}}