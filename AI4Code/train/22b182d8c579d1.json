{"cell_type":{"6847cd9d":"code","ef0e3f26":"code","791d6ef7":"code","37192f7d":"code","6c3d56db":"code","f7ae6008":"code","d9c1882e":"code","ae4bb585":"code","c0c0352d":"markdown","c4073bfa":"markdown","5c0132d0":"markdown","6ec620ca":"markdown","c06e5aec":"markdown","710aa27f":"markdown","cf593aad":"markdown","445fee7c":"markdown","02f46ab3":"markdown"},"source":{"6847cd9d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\nfrom datetime import time,date\nimport nltk\nimport spacy\nimport re","ef0e3f26":"data = [[[5,164,192],[133,206,218],[210,167,216]],[[166,123,197],[187,28,139],[220,38,110]],]\nfig = plt.figure(figsize=(5, 5))\nfig.patch.set_visible(False) \nimg = plt.imshow(data,interpolation='nearest')\nimg.set_cmap('hot')\nplt.axis('off')","791d6ef7":"data = pd.read_csv('..\/input\/coronavirus-2019ncov\/covid-19-all.csv')\ndata.rename(columns={\"Country\":\"Country\/Region\",\"State\":\"State\/Province\"},inplace=True)\ntweets = pd.read_csv('..\/input\/covid19-tweets\/covid19_tweets.csv')\n#Inspect Data\ndata.head(5)","37192f7d":"#Inspect Tweet\ntweets.head(2)","6c3d56db":"data[['Confirmed','Recovered','Deaths']] = data[['Confirmed','Recovered','Deaths']].fillna(0)\ndata_new = pd.melt(data[['Date','Confirmed','Recovered','Deaths']],id_vars=['Date'],value_vars=['Confirmed','Recovered','Deaths'],var_name='group_var',value_name='Cases')\ndata_new['Date'] = pd.to_datetime(data_new['Date'])\ndata['Date'] = pd.to_datetime(data['Date'])\ndates = data['Date'].unique()\nnew_df = pd.DataFrame(index = pd.date_range(dates.min(), dates.max()),columns=['Confirmed','Recovered','Deaths'])\nnew_df[['Confirmed','Recovered','Deaths']] = new_df.apply(lambda x:data.loc[(data['Date'] == x.name),['Confirmed','Recovered','Deaths']].sum(),axis=1)\nnew_df = new_df.rename_axis('Date').reset_index()\ndata_new = pd.melt(new_df,id_vars=['Date'],value_vars=['Confirmed','Deaths','Recovered'],var_name='group_var',value_name='Cases')\ndata_new = data_new.sort_values(by=['Date','group_var']).reset_index(drop=True)\ndata_new['label'] = data_new['group_var']\nnew_data = data_new.pivot_table(index=['Date'], columns='group_var')\nnew_data.columns = new_data.columns.droplevel().rename(None)\nfig,ax = plt.subplots(1,figsize=(16,8))\nnew_data[['Confirmed','Recovered','Deaths']].plot(ax=ax,fontsize=15)\nplt.title(label='Reported Cases In Time',loc='Left',fontsize='20')\nax.set_ylabel('frequency',fontsize=20)\nax.set_ylim([0,30000000])\nax.set_xlabel('')\nplt.grid()\nplt.tight_layout()","f7ae6008":"data_new = pd.melt(data[['Date','Country\/Region','Confirmed','Recovered','Deaths']],id_vars=['Date','Country\/Region'],value_vars=['Confirmed','Recovered','Deaths'],var_name='group_var',value_name='Cases')\ndata_new['Date'] = pd.to_datetime(data_new['Date'])\nnew_df = data[['Country\/Region','Confirmed','Recovered','Deaths']].groupby(['Country\/Region']).sum().reset_index()\ndata_new = pd.melt(new_df,id_vars=['Country\/Region'],value_vars=['Confirmed','Deaths','Recovered'],var_name='group_var',value_name='Cases')\ndata_new = data_new.sort_values(by=['Country\/Region','group_var']).reset_index(drop=True)\nnew_data = data_new.pivot_table(index=['Country\/Region'], columns='group_var')\nnew_data.columns = new_data.columns.droplevel().rename(None)\nfig,ax = plt.subplots(3,figsize=(16,24))\ngroup_labels = ['Confirmed','Deaths','Recovered']\nnew_data.nlargest(5, ['Confirmed']).plot(y='Confirmed',ax=ax[0],kind='bar')\nnew_data.nlargest(5, ['Deaths']).plot(y='Deaths',ax=ax[1],kind='bar')\nnew_data.nlargest(5, ['Recovered']).plot(y='Recovered',ax=ax[2],kind='bar')","d9c1882e":"data['Province\/State'] = data['Province\/State'].fillna('Unknown')\ndata_new = pd.melt(data[['Date','Province\/State','Confirmed','Recovered','Deaths']],id_vars=['Date','Province\/State'],value_vars=['Confirmed','Recovered','Deaths'],var_name='group_var',value_name='Cases')\ndata_new['Date'] = pd.to_datetime(data_new['Date'])\nnew_df = data[['Province\/State','Confirmed','Recovered','Deaths']].groupby(['Province\/State']).sum().reset_index()\ndata_new = pd.melt(new_df,id_vars=['Province\/State'],value_vars=['Confirmed','Deaths','Recovered'],var_name='group_var',value_name='Cases')\ndata_new = data_new.sort_values(by=['Province\/State','group_var']).reset_index(drop=True)\nnew_data = data_new.pivot_table(index=['Province\/State'], columns='group_var')\nnew_data.columns = new_data.columns.droplevel().rename(None)\nfig,ax = plt.subplots(3,figsize=(16,24))\ngroup_labels = ['Confirmed','Deaths','Recovered']\nnew_data.nlargest(5, ['Confirmed']).plot(y='Confirmed',ax=ax[0],kind='bar')\nnew_data.nlargest(5, ['Deaths']).plot(y='Deaths',ax=ax[1],kind='bar')\nnew_data.nlargest(5, ['Recovered']).plot(y='Recovered',ax=ax[2],kind='bar')","ae4bb585":"def clean_corpus(text):\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = text.strip()\n    text= text.lower()\n    stop_words = set(nltk.corpus.stopwords.words('english'))\n    word_tokens = nltk.tokenize.word_tokenize(text) \n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    filtered_sentence = [] \n    for w in word_tokens: \n        if w not in stop_words: \n            filtered_sentence.append(w)\n    text = ' '.join(filtered_sentence)\n    text = \"\".join(filter(lambda x: not x.isdigit(), text))\n    text = text.strip()\n    return text","c0c0352d":"## Top Countries per Case Type\n\n> **\ud83d\udcccNote**: US has the lead in all cases. *China* is on 18th place in this ranking. Also, it's interesting to see that top 5 countries are from ~different continents; US from North America, Brazil from South America, India from Asia, Russia from Europe and Asia and Spain from Europe.","c4073bfa":"**### Data\ud83d\udcc2\n\nFirst let's inspect the data to see what we're working with. I'm gonna keep it simple, as we'll make it more complicated soon \ud83d\ude01","5c0132d0":"<img src=\"https:\/\/i.imgur.com\/FNi8CFE.png\">\n<center><h1>COVID-19: EDA and Text Analysis<\/h1><\/center>\n\n# 1. Introduction\n\n# 2. Imports\n\n### Libraries\ud83d\udcda","6ec620ca":"# Work in Progress... \u23f3\n<div class=\"alert alert-block alert-info\">\nGrams, Sentiment Analysis, Graphs, {sentimentr}, wordclouds and many more to come ^^\n<\/div>","c06e5aec":"# 4. Sentiment Analysis \ud83d\udc25\ud83d\udc23\n\n## 4.1 Text Mining \ud83d\udd28\ud83d\udd26\n\n### #1. Clean Corpus Function\n\nThis predefined function is going to clean the text from:\n* the punctuation - `removePunctuation`\n* extra white space - `stripWhitespace`\n* transforms to lower case - `tolower`\n* stopwords (common words that should be ignored) - `stopwords`\n* numbers - `removeNumbers`","710aa27f":"## Top States per Case Type\n\n> **\ud83d\udcccNote**: in *Recovered* category, \"Recovered\" state is from US. I will figure the state later in the analysis. There is also an \"Unknown\" state.","cf593aad":"# 3. What's the situation worldwide? \ud83c\udf0d\ud83c\udf0e\ud83c\udf0f\n\n## Reported Cases in Time \ud83d\udcc5\n> **\ud83d\udcccNote**: Cases are stable in the first quarter of the year. However, starting April they begin to rise first linearly, then almost exponentialy starting July.","445fee7c":"Thanks to @andradaolteanu for her good sentiment analysis report on covid-19 using R(https:\/\/www.kaggle.com\/andradaolteanu\/covid-19-sentiment-analysis\/notebook). This I have done the same thing using Python. Hope you find it useful.","02f46ab3":"Color Palette and Custom Theme\ud83c\udfa8"}}