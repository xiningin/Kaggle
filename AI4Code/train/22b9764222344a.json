{"cell_type":{"212a201e":"code","af8291d4":"code","3a9e1926":"code","45886327":"code","c3853fb7":"code","77a47360":"code","35f0260f":"code","851c1a1c":"code","d5bd58f8":"code","b45279cb":"code","94b66288":"code","a016d0bb":"code","4e41ed40":"code","632a5906":"code","ff66210f":"code","02f79052":"code","feb08aca":"code","ba0364ab":"code","5f3403e7":"markdown","88110835":"markdown","7b0e3d25":"markdown","cd52f73a":"markdown","e5562c3b":"markdown"},"source":{"212a201e":"!pip -q install ..\/input\/pytorchtabnet\/pytorch_tabnet-3.1.1-py3-none-any.whl","af8291d4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy.matlib\n\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\n\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom joblib import Parallel, delayed\n\nimport shutil\nimport glob\n\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import KFold, GroupKFold\n\nfrom pytorch_tabnet.metrics import Metric\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\nimport torch\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n\nfrom tsfresh.feature_extraction import feature_calculators as fcs\n\n# setting some globl config\n\nplt.style.use('ggplot')\norange_black = [\n    '#fdc029', '#df861d', '#FF6347', '#aa3d01', '#a30e15', '#800000', '#171820'\n]\nplt.rcParams['figure.figsize'] = (16,9)\nplt.rcParams[\"figure.facecolor\"] = '#FFFACD'\nplt.rcParams[\"axes.facecolor\"] = '#FFFFE0'\nplt.rcParams[\"axes.grid\"] = True\nplt.rcParams[\"grid.color\"] = orange_black[3]\nplt.rcParams[\"grid.alpha\"] = 0.5\nplt.rcParams[\"grid.linestyle\"] = '--'\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport psutil\npsutil.cpu_count()","3a9e1926":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nprint(gpu_info)","45886327":"# config\n\n\nclass CFG:\n    lag_range = [1,2,-1,-2]\n    use_folds = [0,1,2,3,4]\n    nof_epochs = 15\n    nfolds = 5\n    data_dir = '..\/input\/ventilator-pressure-prediction\/'\n    verbose = 1\n","c3853fb7":"def reduce_memory_usage(df):\n    \n    start_memory = np.round(df.memory_usage().sum() \/ 1024**2,2)\n    print(f\"Memory usage of dataframe is {start_memory} MB\")\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != 'object':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    pass\n        else:\n            df[col] = df[col].astype('category')\n    \n    end_memory = np.round(df.memory_usage().sum() \/ 1024**2,2)\n    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n    print(f\"Reduced by { np.round(100 * (start_memory - end_memory) \/ start_memory,2) } % \")\n    return df","77a47360":"# Pytorch metric setup\ndef mae(y_true, y_pred):\n    # Function to calculate the root mean squared percentage error\n    return np.mean(np.abs(y_true - y_pred))\n\nclass MAE(Metric):\n    def __init__(self):\n        self._name = \"mae\"\n        self._maximize = False\n\n    def __call__(self, y_true, y_score):\n        \n        return np.mean(np.abs(y_true - y_score))\n\ndef MAELoss(y_pred, y_true):\n    return torch.mean(torch.abs(y_true - y_pred )).clone()","35f0260f":"def add_features(df):\n    \n    \n    xtr_gr_in = df.groupby('breath_id')['u_in']\n    df['last_value_u_in'] = np.round(xtr_gr_in.transform('last'),2)\n    del xtr_gr_in\n\n    # variations around u_in\n    xgr = df.groupby('breath_id')['u_in']\n    for lag in CFG.lag_range:\n        df['u_in_lag' + str(lag)] = np.round(xgr.shift(lag),2)\n    df['u_in_median'] = xgr.transform('median')\n\n    # slope of the curve - v1\n    df['u_in_slope'] =\\\n    xgr.transform(lambda s: fcs.linear_trend(s, [{'attr': 'slope'}])[0][1] )\n\n    # kurtosis\n    df['u_in_kurt'] = np.round(xgr.transform(fcs.kurtosis),2)\n    \n    # varia\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = np.round(df.groupby('breath_id')['area'].cumsum(),2)\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n  \n    # categoricals\n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['RxC'] = df['C'] + '_' + df['R']\n   \n    df.fillna(0, inplace = True)\n    return df","851c1a1c":"xtrain = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\nxtest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')","d5bd58f8":"%time\nxtrain = add_features(xtrain)\nxtest = add_features(xtest)","b45279cb":"%time\nxtrain = reduce_memory_usage(xtrain)\nxtest = reduce_memory_usage(xtest)","94b66288":"breath_train = xtrain['breath_id'].copy()\nid_train = xtrain['id'].copy()\nytrain = xtrain['pressure']\nbreath_test = xtest['breath_id'].copy()\nid_test = xtest['id'].copy()\n\nxtrain.drop(['breath_id', 'id', 'pressure'], axis = 1, inplace = True)\nxtest.drop(['breath_id', 'id'], axis = 1, inplace = True)\n\n\ncategorical_columns = ['R', 'C', 'RxC']\nnumerical_columns = [f for f in xtrain.columns if f not in categorical_columns ]\n","a016d0bb":"categorical_dims =  {}\n\nfor col in categorical_columns:\n    l_enc = LabelEncoder()\n    xtrain[col] = l_enc.fit_transform(xtrain[col].values)\n    xtest[col] = l_enc.transform(xtest[col].values)\n    categorical_dims[col] = len(l_enc.classes_)\n    \nfor col in numerical_columns:\n    scaler = RS = RobustScaler()\n    xtrain[col] = scaler.fit_transform(xtrain[col].values.reshape(-1, 1))\n    xtest[col] = scaler.transform(xtest[col].values.reshape(-1, 1))\n        \n    ","4e41ed40":"cat_idxs = [ i for i, f in enumerate(xtrain.columns.tolist()) if f in categorical_columns]\n\ncat_dims = [ categorical_dims[f] for i, f in enumerate(xtrain.columns.tolist()) if f in categorical_columns]","632a5906":"tabnet_params = dict(\n    cat_idxs=cat_idxs,\n    cat_dims=cat_dims,\n    cat_emb_dim=1,\n    n_d = 16,\n    n_a = 16,\n    n_steps = 2,\n    gamma = 2,\n    n_independent = 2,\n    n_shared = 2,\n    lambda_sparse = 0,\n    optimizer_fn = Adam,\n    optimizer_params = dict(lr = (2e-2)),\n    mask_type = \"entmax\",\n    scheduler_params = dict(T_0=200, T_mult=1, eta_min=1e-4, last_epoch=-1, verbose=False),\n    scheduler_fn = CosineAnnealingWarmRestarts,\n    seed = 42,\n    verbose = CFG.verbose\n    \n)","ff66210f":"# Create out of folds array\noof_predictions = np.zeros((xtrain.shape[0], 1))\ntest_predictions = np.zeros(xtest.shape[0])\nfeature_importances = pd.DataFrame()\nfeature_importances[\"feature\"] = xtrain.columns.tolist()\nstats = pd.DataFrame()\nexplain_matrices = []\nmasks_ =[]\n\n\n\nk_fold = GroupKFold(n_splits = CFG.nfolds)\nfor fold, (id0, id1) in enumerate(k_fold.split(xtrain, ytrain, breath_train)):\n    print(f'Training fold {fold}')\n    X_train, X_val = xtrain.iloc[id0].values, xtrain.iloc[id1].values\n    y_train, y_val = ytrain.iloc[id0].values.reshape(-1,1), ytrain.iloc[id1].values.reshape(-1,1)\n\n\n    clf =  TabNetRegressor(**tabnet_params)\n    clf.fit(\n      X_train, y_train,\n      eval_set=[(X_val, y_val)],\n      max_epochs = CFG.nof_epochs,\n      patience = 50,\n      batch_size = 1024*20, \n      virtual_batch_size = 128*20,\n      num_workers = 4,\n      drop_last = False,\n      eval_metric = [MAE],\n      loss_fn = MAELoss\n      )\n    \n    saving_path_name = f\".\/tabnet_f{fold}\"\n    saved_filepath = clf.save_model(saving_path_name)\n    \n    explain_matrix, masks = clf.explain(X_val)\n    explain_matrices.append(explain_matrix)\n    masks_.append(masks[0])\n    masks_.append(masks[1])\n      \n    oof_predictions[id1] = clf.predict(X_val)\n    test_predictions += clf.predict(xtest.values).flatten()\/5\n    feature_importances[f\"importance_fold{fold}+1\"] = clf.feature_importances_\n    \n    stats[f'fold{fold}_train_mae']=clf.history['loss']\n    stats[f'fold{fold}_val_mae']=clf.history['val_0_mae']\n    \nprint(f'OOF score across folds: {mae(y, oof_predictions.flatten())}')","02f79052":"prval = pd.DataFrame(id_train)\nprval['pressure'] = oof_predictions\nprval.to_csv('prval_tabnet.csv', index = False)\n\n\nprfull = pd.DataFrame(id_test)\nprfull['pressure'] = test_predictions\nprfull.to_csv('prfull_tabnet.csv', index = False)","feb08aca":"# feature importances\nfeature_importances['mean_importance']=feature_importances[['importance_fold0+1','importance_fold1+1']].mean(axis=1)\nfeature_importances.sort_values(by='mean_importance', ascending=False, inplace=True)\nsns.barplot(y=feature_importances['feature'][:25],x=feature_importances['mean_importance'][:25], palette='inferno')\nplt.title('Mean Feature Importance by Folds')\nplt.show()","ba0364ab":"test['target'] = test_predictions\ntest[['row_id', 'target']].to_csv('submission.csv',index = False)","5f3403e7":"# Model","88110835":"# Submission","7b0e3d25":"Original https:\/\/www.kaggle.com\/datafan07\/optiver-volatility-predictions-using-tabnet\/notebook","cd52f73a":"# Functions","e5562c3b":"# Data"}}