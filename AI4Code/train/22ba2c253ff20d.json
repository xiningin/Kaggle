{"cell_type":{"aed611ef":"code","58fad814":"code","0c5fc703":"code","7e74860d":"code","3c3e9ec1":"code","526ea55a":"code","cb7b1bd7":"code","9dc7e99b":"code","79638b7c":"code","88b9e8f3":"code","1dd3d62d":"code","63bd27be":"code","513cf622":"code","3fdea2fc":"code","60e72cef":"code","7d332873":"code","75ed580c":"code","d279d314":"code","43dafd6b":"code","6b29ac48":"code","4bc12497":"code","207580a6":"code","f60b2f60":"code","db19fbaa":"code","c60b8311":"code","d21d66ac":"code","07537fdd":"code","f42488b2":"code","414849a7":"code","72667c68":"code","2a539f7b":"code","46dec37e":"markdown","bc4f4dba":"markdown","ae4fa9bd":"markdown","ae9ca1ad":"markdown","dadef7e6":"markdown","52572b45":"markdown","2432357e":"markdown","aab98a08":"markdown","ed939b6b":"markdown","55d5135b":"markdown","ae3f0589":"markdown","4092e491":"markdown","ab17e778":"markdown","6137a132":"markdown","9063e608":"markdown","8a53327e":"markdown","6fd74fdd":"markdown","2fa918e3":"markdown","3a964e40":"markdown","80e69a84":"markdown"},"source":{"aed611ef":"!pip install pycaret","58fad814":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0c5fc703":"\n\ntelcom = pd.read_csv(r'\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ntelcom.head()","7e74860d":"print (\"Rows     : \" ,telcom.shape[0])\nprint (\"Columns  : \" ,telcom.shape[1])\nprint (\"\\nMissing values :  \", telcom.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",telcom.nunique())","3c3e9ec1":"telcom.info()","526ea55a":"#Data Manipulation\n\n#Replacing spaces with null values in total charges column\ntelcom['TotalCharges'] = telcom[\"TotalCharges\"].replace(\" \",np.nan)\n\n#Dropping null values from total charges column which contain .15% missing data \ntelcom = telcom[telcom[\"TotalCharges\"].notnull()]\ntelcom = telcom.reset_index()[telcom.columns]\n\n#convert to float type\ntelcom[\"TotalCharges\"] = telcom[\"TotalCharges\"].astype(float)\n\n#replace 'No internet service' to No for the following columns\nreplace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                'TechSupport','StreamingTV', 'StreamingMovies']\nfor i in replace_cols : \n    telcom[i]  = telcom[i].replace({'No internet service' : 'No'})\n    \n#replace values\ntelcom[\"SeniorCitizen\"] = telcom[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n\n#Tenure to categorical column\ndef tenure_lab(telcom) :\n    \n    if telcom[\"tenure\"] <= 12 :\n        return \"Tenure_0-12\"\n    elif (telcom[\"tenure\"] > 12) & (telcom[\"tenure\"] <= 24 ):\n        return \"Tenure_12-24\"\n    elif (telcom[\"tenure\"] > 24) & (telcom[\"tenure\"] <= 48) :\n        return \"Tenure_24-48\"\n    elif (telcom[\"tenure\"] > 48) & (telcom[\"tenure\"] <= 60) :\n        return \"Tenure_48-60\"\n    elif telcom[\"tenure\"] > 60 :\n        return \"Tenure_gt_60\"\ntelcom[\"tenure_group\"] = telcom.apply(lambda telcom:tenure_lab(telcom),\n                                      axis = 1)\n\n#Separating churn and non churn customers\nchurn     = telcom[telcom[\"Churn\"] == \"Yes\"]\nnot_churn = telcom[telcom[\"Churn\"] == \"No\"]\n\n#Separating catagorical and numerical columns\nId_col     = ['customerID']\ntarget_col = [\"Churn\"]\ncat_cols   = telcom.nunique()[telcom.nunique() < 6].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\nnum_cols   = [x for x in telcom.columns if x not in cat_cols + target_col + Id_col]","cb7b1bd7":"import seaborn as sns\nimport matplotlib.pyplot  as plt\nval_counts = telcom[\"Churn\"].value_counts()\n\n#labels\nlab = val_counts.keys().tolist()\n#values\nval = val_counts.values.tolist()\n\nfig1, ax1 = plt.subplots()\nax1.pie(val, labels=lab, autopct='%1.1f%%', shadow=True)\nax1.axis('equal')","9dc7e99b":"def plotpie(col):\n  val_counts_churn = churn[col].value_counts()\n  #labels\n  lab_churn = val_counts_churn.keys().tolist()\n  #values\n  val_churn = val_counts_churn.values.tolist()\n\n  val_counts_notchurn = not_churn[col].value_counts()\n  #labels\n  lab_notchurn = val_counts_churn.keys().tolist()\n  #values\n  val_notchurn = val_counts_churn.values.tolist()\n\n  fig1, (ax1,ax2) = plt.subplots(1,2)\n  fig1.suptitle(col)\n  ax1.pie(val_churn, labels=lab_churn, autopct='%1.1f%%', shadow=True)\n  ax1.axis('equal')\n  ax2.pie(val_notchurn, labels=lab_notchurn, autopct='%1.1f%%', shadow=True)\n  ax2.axis('equal')\n\n\nfor col in cat_cols:\n  plotpie(col)","79638b7c":"def plothist(col):\n  plt.figure()\n  ax = sns.boxplot(x=\"Churn\", y=col, data=telcom)\n\n\nfor col in num_cols:\n  plothist(col)","88b9e8f3":"sns.pairplot(telcom[num_cols + ['Churn']], hue=\"Churn\")","1dd3d62d":"tenures = sorted(telcom[\"tenure_group\"].unique())\n\nax = sns.countplot(x=\"tenure_group\", hue=\"Churn\", data=telcom,order=tenures)\nplt.xticks(rotation=90)\n\nplt.figure()\n\n\nax = sns.barplot(x=\"tenure_group\", y=\"MonthlyCharges\", hue='Churn', data=telcom, estimator=np.mean,order=tenures)\nplt.xticks(rotation=90)\n\nplt.figure()\nax = sns.barplot(x=\"tenure_group\", y=\"TotalCharges\", hue='Churn', data=telcom, estimator=np.mean,order=tenures)\nplt.xticks(rotation=90)\n#\n#tmp_df = pd.DataFrame(telcom.groupby(['Churn'])['TotalCharges'].mean()).reset_index()\n#tmp_df.columns = ['Churn','Avg Total Charges']\n#ax = sns.countplot(x=\"Avg Total Charges\", hue=\"Churn\", data=tmp_df)\n#plt.xticks(rotation=90)\n#","63bd27be":"sns.relplot(x=\"MonthlyCharges\", y=\"TotalCharges\", hue=\"tenure_group\", alpha=.5, palette=\"muted\",\n            height=6, data=telcom)\nplt.figure()\nsns.relplot(x=\"MonthlyCharges\", y=\"TotalCharges\", hue=\"Churn\", alpha=.5, palette=\"muted\",\n            height=6, data=telcom)","513cf622":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n#customer id col\nId_col     = ['customerID']\n#Target columns\ntarget_col = [\"Churn\"]\n#categorical columns\ncat_cols   = telcom.nunique()[telcom.nunique() < 6].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\n#numerical columns\nnum_cols   = [x for x in telcom.columns if x not in cat_cols + target_col + Id_col]\n#Binary columns with 2 values\nbin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols :\n    telcom[i] = le.fit_transform(telcom[i])\n    \n#Duplicating columns for multi value columns\ntelcom = pd.get_dummies(data = telcom,columns = multi_cols )\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(telcom[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf_telcom_og = telcom.copy()\ntelcom = telcom.drop(columns = num_cols,axis = 1)\ntelcom = telcom.merge(scaled,left_index=True,right_index=True,how = \"left\")","3fdea2fc":"\ntelcom.info()","60e72cef":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 2)\n\nX = telcom[[i for i in telcom.columns if i not in Id_col + target_col]]\nY = telcom[target_col + Id_col]\n\nprincipal_components = pca.fit_transform(X)\npca_data = pd.DataFrame(principal_components,columns = [\"PC1\",\"PC2\"])\npca_data = pca_data.merge(Y,left_index=True,right_index=True,how=\"left\")\npca_data[\"Churn\"] = pca_data[\"Churn\"].replace({1:\"Churn\",0:\"Not Churn\"})\n\nsns.relplot(x=\"PC1\", y=\"PC2\", hue=\"Churn\", alpha=.5, palette=\"muted\",\n            height=6, data=pca_data)","7d332873":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\n#splitting train and test data \ntelcom = telcom.drop(columns = Id_col,axis = 1)\ntrain,test = train_test_split(telcom,test_size = .25 ,random_state = 111)\n    \n##seperating dependent and independent variables\n#cols    = [i for i in telcom.columns if i not in Id_col + target_col]\n#train_X = train[cols]\n#train_Y = train[target_col]\n#test_X  = test[cols]\n#test_Y  = test[target_col]","75ed580c":"train.info()","d279d314":"from pycaret.utils import enable_colab\nenable_colab()","43dafd6b":"features = train.columns.tolist()\nfeatures.remove('Churn')","6b29ac48":"from pycaret.classification import *\nexp_clf101 = setup(data = train, target = 'Churn',numeric_features=features, session_id=123) ","4bc12497":"compare_models()","207580a6":"xboost = create_model('xgboost')","f60b2f60":"tuned_xgboost= tune_model(xboost)","db19fbaa":"plot_model(tuned_xgboost, plot = 'auc')","c60b8311":"plot_model(tuned_xgboost, plot = 'pr')","d21d66ac":"plot_model(tuned_xgboost, plot='feature')","07537fdd":"plot_model(tuned_xgboost, plot = 'confusion_matrix')","f42488b2":"predict_model(tuned_xgboost);","414849a7":"final_xgboost = finalize_model(tuned_xgboost)\nprint(final_xgboost)","72667c68":"unseen_predictions = predict_model(final_xgboost, data=test)\nunseen_predictions.head()","2a539f7b":"save_model(final_xgboost,'Final xgboost Model 13_08_2020')\nsaved_final_xgboost = load_model('Final xgboost Model 13_08_2020')\nnew_prediction = predict_model(saved_final_xgboost, data=test)\nnew_prediction.head()","46dec37e":"**6.5 Tune A Model**","bc4f4dba":"# **2. Data Manipulation**","ae4fa9bd":"**3.3 Churn vs Not Churn - Numerical Features**","ae9ca1ad":"# **1. Data Overview**","dadef7e6":"**6.8 Finalize The Model**","52572b45":"# **3. Data Exploratory Analysis**","2432357e":"**3.2 Churn vs Not Churn - Categorical Features**","aab98a08":"6.6 Visualize The Tuned Model","ed939b6b":"**6.1 Train-Test Split**","55d5135b":"# **4. Data Processing**","ae3f0589":"**6.7 Prediction On Hold-out Set**","4092e491":"**3.4 Churn vs Not Churn - Tenure Groups**","ab17e778":"# **0. Load Data**","6137a132":"# **6. Predictive Modelling**","9063e608":"This notebook is based on https:\/\/www.kaggle.com\/pavanraj159\/telecom-customer-churn-prediction\n\nChanges:\n\nUse seaborn instead of plotly\nUse PyCarat for predictive modelling\nLink to dataset: https:\/\/www.kaggle.com\/blastchar\/telco-customer-churn\n\nTo install PyCarat: !pip install pycaret","8a53327e":"**6.2 PyCaret Setup**","6fd74fdd":"**6.4 Create A Model**","2fa918e3":"**6.3 Compare Models**","3a964e40":"# **5. Dimension Reduction**","80e69a84":"**6.8 Save & Load**"}}