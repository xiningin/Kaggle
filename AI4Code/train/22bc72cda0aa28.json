{"cell_type":{"1bda5f57":"code","7c87d938":"code","eb0d4b70":"code","94aa0690":"code","9b71654b":"code","566ead73":"code","af656dc2":"code","bd0c8ef7":"code","46320d05":"code","a8dfea08":"code","3f3da249":"code","a99dafaa":"code","1ad9b3c8":"code","1b5b8efc":"code","65a541cb":"code","e478f1be":"code","b1b63381":"markdown","b550822a":"markdown","72498ce9":"markdown","d77c3e99":"markdown","5b8efc94":"markdown","b856551b":"markdown","072599e0":"markdown","c8d5a76e":"markdown","b82b726a":"markdown","94c5aed2":"markdown","8f560a38":"markdown","905d8af7":"markdown"},"source":{"1bda5f57":"!pip install tensorflow==2.5","7c87d938":"!git clone https:\/\/github.com\/ipmach\/CVPR.git","eb0d4b70":"%cd CVPR\nfrom ComputerVision.Geometric_Transformations.geometric_matrix import GeometricTransformations\nfrom ComputerVision.Geometric_Transformations.mappings import inverse_mapping, forward_mapping\n%cd ..\n\nimport tensorflow_probability as tfp\nimport tensorflow as tf\n\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\n\nfrom sklearn.cluster import KMeans\nfrom tqdm.notebook import tqdm \nfrom scipy.spatial import distance\nimport numpy as np\nimport time\nimport cv2","94aa0690":"class sea_segmentation:\n\n    def __init__(self, sample):\n        \"\"\"\n        Apply segmentation using the likelihood of the sample distribution\n        GPU optimize\n        :param sample: sample using to create the distribution\n        \"\"\"\n        tfd = tfp.distributions\n        x = sample.astype(float).reshape((-1, 3))\n        # Creating normal distribution\n        mean_ = tf.math.reduce_mean(x, axis=0)\n        std = tfp.stats.stddev(x)\n        self.dist = tfd.Normal(loc=mean_, scale=std)\n        \n\n    def __call__(self, img, threshold=0.0001):\n        \"\"\"\n        Apply distribution\n        :param img: frame we want to segment\n        :param threshold: threshold to filter segmentation\n        \"\"\"\n        # Apply the likelihood\n        aux_f = np.array(tf.math.reduce_mean(\n                         self.dist.prob(img.reshape((-1,3))), axis=1))\n        # Filter segmentation\n        filter_ = np.vectorize(lambda x: 0 if x > threshold else 1)\n        aux_f = filter_(aux_f).reshape(img.shape[:2])\n        # Getting final image\n        indx = np.nonzero(aux_f)\n        img2 = np.zeros(img.shape)\n        img2[indx] = img[indx]\n        # Convert in binary\n        idx_b = np.nonzero(np.sum(img2, axis=2))\n        img_b = np.zeros(img.shape[:2])\n        img_b[idx_b] = 1\n        return img_b\n\nclass morphologicalOperations:\n    \n    def __init__(self, kernel1_shape=(5,5), kernel2_shape=(20,20)):\n        \"\"\"\n        Apply morphological operations for preprocessing image\n        :param kernel1_shape: kernel1 initial shape, default = (5,5)\n        :param kernel2_shape: kernel2 initial shape, default = (20,20)\n        \"\"\"\n        kernel1_shape = kernel1_shape\n        kernel2_shape = kernel2_shape\n        self.kernel = np.ones(kernel1_shape, np.uint8)\n        self.kernel2 = np.ones(kernel2_shape, np.uint8)\n    \n    def __call__(self, img):\n        \"\"\"\n        Preprocess image\n        :param img: image to preprocess\n        :return: new image\n        \"\"\"\n        img_erode = cv2.erode(img, self.kernel)\n        img_erode = cv2.dilate(img_erode, self.kernel2)\n        img_erode = cv2.erode(img_erode, self.kernel2)\n        img_erode = cv2.dilate(img_erode, self.kernel)\n        return img_erode   \n\nclass get_structures():\n    \n    @staticmethod\n    def get_neighbours(i, j, shape_):\n        \"\"\"\n        Get neighbours pixel\n        :param i: coordinate x\n        :param j: coordinate y\n        :param shape_: shape image\n        :return: neighbours\n        \"\"\"\n        list_indexes = [(i, j)]\n        if i - 1 >= 0:\n            if j - 1 >= 0:\n                list_indexes.append((i - 1, j - 1))\n            if j >= 0:\n                list_indexes.append((i - 1, j))\n            if j + 1 < shape_[1]:\n                list_indexes.append((i - 1, j + 1))\n        if j - 1 >= 0:\n            list_indexes.append((i, j - 1))\n        if j + 1 < shape_[1]:\n            list_indexes.append((i, j + 1))\n        if i + 1 < shape_[0]:\n            if j - 1 >= 0:\n                list_indexes.append((i + 1, j - 1))\n            if j >= 0:\n                list_indexes.append((i + 1, j))\n            if j + 1 < shape_[1]:\n                list_indexes.append((i + 1, j + 1))\n        return list_indexes\n    \n    @staticmethod\n    def grow(x, y, img, new_img, value, _shape):\n        \"\"\"\n        Apply grow in a image pixel by pixel recursively\n        :param x: coordinate x\n        :param y: coordinate y\n        :param img: original image\n        :param new_img: new image\n        :param value: actual label value\n        :param _shape: shape img and new image\n        :return: new_img, img\n        \"\"\"\n        neigh = get_structures.get_neighbours(x, y, _shape)\n        if len(neigh) > 0:\n            for (i,j) in neigh:\n                if new_img[i, j] == 0 and img[i, j] > 0:\n                    new_img[i, j] = value\n                    img[i, j] = 0\n                    new_img, img = get_structures.grow(i, j, img, new_img, value,\n                                                       _shape)\n        return new_img, img\n\n    def do_grow_region(self, img, value):\n        \"\"\"\n        Do multilabel grow region\n        :param img: original image\n        :param value: value label\n        :return: new_image, value\n        \"\"\"\n        img2 = img.copy()\n        idx = np.nonzero(img2)\n        new_img = np.zeros(img.shape)\n        while True:\n            if len(idx[0]) == 0:\n                break\n            new_img, img2 = get_structures.grow(idx[0][0], idx[1][0], img2, new_img, \n                                                value, img.shape)\n            idx = np.nonzero(img2)\n            value += 1\n            \n        return new_img, value\n    \n    def postprocessing_inside_loop(self, aux0, aux1, test_img, jump, i, j):\n        \"\"\"\n        Inside loop of postprocessing\n        :param aux0: image block 0\n        :param aux1: image block 1\n        :param test_img: image\n        :param jump: jump between blocks\n        :param i: coordinate block\n        :param j: coordinate block\n        :return: test_img\n        \"\"\"\n        idx_0 = np.nonzero(aux0)\n        idx_1 = np.nonzero(aux1)\n        for z in idx_0[0]:\n            if z in idx_1[0]:\n                value = aux0[z]\n                value2 = aux1[z]\n                if value != value2:\n                    test_img[i * jump: (i + 1) * jump, \n                            j * jump: (1+ j) * jump] = np.vectorize(lambda x: value if x == value2 else x)(\n                                                                      test_img[i * jump: (i + 1) * jump, \n                                                                               j * jump: (1+ j) * jump])\n        return test_img\n                    \n    def __call__(self, img, jump=50, debug=False):\n        \"\"\"\n        Apply multilabel region grow\n        :param img: image to apply grow\n        :param jump: size blocks image\n        :param debug: return middle results\n        :return: image\n        \"\"\"\n        new_img = np.zeros(img.shape)\n        value = 1    \n        print(\"Region Grow\")\n        for i in tqdm(range(int(img.shape[0] \/ jump))):\n            for j in range(int(img.shape[1] \/ jump)):\n                new_img[i * jump: (i + 1) * jump, j * jump:(j + 1) * jump], value = \\\n                        self.do_grow_region(img[i * jump: (i + 1) * jump, j * jump:(j + 1) * jump], value) \n        \n        print(\"Postprocess\")\n        # Left -> Right\n        test_img2 = new_img.copy()\n        for i in tqdm(range(1, int(test_img2.shape[0] \/ jump))):\n            for j in range(int(test_img2.shape[1] \/ jump)):\n                aux0 = test_img2[(i - 1) * jump: i * jump, j* jump: (1 + j) * jump][-1, :]\n                aux1 = test_img2[i * jump: (i + 1) * jump, j * jump: (1 + j) * jump][0, :]\n                test_img2 = self.postprocessing_inside_loop(aux0, aux1, test_img2, jump, i, j)\n        # Up -> Bottom\n        test_img3 = test_img2.copy()\n        for i in tqdm(range(int(test_img3.shape[0] \/ jump))):\n            for j in range(1, int(test_img3.shape[1] \/ jump)):\n                aux0 = test_img3[i * jump: (i + 1) * jump, (j - 1) * jump: j * jump][:, -1]\n                aux1 = test_img3[i * jump: (i + 1) * jump, j * jump: (1 + j) * jump][:, 0]\n                test_img3 = self.postprocessing_inside_loop(aux0, aux1, test_img3, jump, i, j)\n        # Right -> Left\n        test_img4 = test_img3.copy()\n        for i in tqdm(range(1, int(test_img4.shape[0] \/ jump))):\n            for j in reversed(range(int(test_img4.shape[1] \/ jump))):\n                aux0 = test_img4[(i - 1) * jump: i * jump, j* jump: (1 + j) * jump][0, :]\n                aux1 = test_img4[i * jump: (i + 1) * jump, j * jump: (1 + j) * jump][-1, :]\n                test_img4 = self.postprocessing_inside_loop(aux0, aux1, test_img4, jump, i, j)\n        # Bottom -> Up\n        test_img4a = test_img4.copy()\n        for i in tqdm(list(reversed(range(int(test_img4a.shape[0] \/ jump))))):\n            for j in range(1, int(test_img4a.shape[1] \/ jump)):\n                aux0 = test_img4a[i * jump: (i + 1) * jump, (j - 1) * jump: j * jump][:, 0]\n                aux1 = test_img4a[i * jump: (i + 1) * jump, j * jump: (1 + j) * jump][:, -1]\n                test_img4a = self.postprocessing_inside_loop(aux0, aux1, test_img4a, jump, i, j)\n    \n        test_img5 = test_img4.copy()\n        j = 1\n        print(\"Reasigning labels\")\n        for v in tqdm(np.unique(test_img4)):\n            if v != 0:\n                idx = np.where(test_img4 == v)\n                if 200 < len(idx[0]) < 7000:\n                    test_img5[idx] = j\n                    j += 1\n                else:\n                    test_img5[idx] = 0\n                    \n        if debug:\n            return test_img5, [test_img2, test_img3, test_img4, test_img4a]\n        else:\n            return test_img5\n        \nclass boat_analysis:\n    \n    def __init__(self, func_analyze):\n        \"\"\"\n        Analyze result of the grow region\n        :param func_analyze: function use to analyze if a candidate is a boat\n        \"\"\"\n        self.func_analyze = func_analyze\n    \n    def get_axis(self, aux, return_all=False):\n        \"\"\"\n        Obtain axis of a binary object (lines functions)\n        :param aux: img\n        :param return_all: return m and b instead of the line function\n        :return: line functions of  the axis\n        \"\"\"\n        idx = np.nonzero(aux)\n        X = np.stack((idx[1], idx[0]), axis=0)\n        x_m, y_m = round(np.mean(idx[1])), round(np.mean(idx[0]))\n        cov = np.cov(X)\n        w, v = np.linalg.eig(cov)\n        idx_eign = np.argmax(w)\n        m = v[idx_eign][0] \/ v[idx_eign][1]   \n        if return_all:\n            return m, y_m - m * x_m, - (1\/m),  y_m + (1\/m) * x_m\n        line = np.vectorize(lambda x: y_m + m * (x - x_m))\n        orto_line = np.vectorize(lambda x: y_m - (1 \/ m) * (x - x_m))\n        return line, orto_line\n    \n    def image_detection(self, test_img, img, plot=False):\n        \"\"\"\n        Check the data obtain from region grow\n        :param img: original image\n        :param test_img: img cluster by grow detection\n        :param plot: True if you want to plot\n        :return: img_sections, img_sections_clusters, pos_img\n        \"\"\"\n        margin = 20\n        if plot:\n            fig, ax = plt.subplots(figsize=(15, 15))\n            plt.title(\"Grow detection\")\n            ax.imshow(img)\n        img_sections = []\n        img_sections_clusters = []\n        pos_img = []\n        for i in tqdm(range(1, int(np.max(test_img)) + 1)):\n            idx = np.where(test_img == i)\n            pos = [np.min(idx[1]), np.min(idx[0])]\n            if np.min(idx[1]) - margin >= 0:\n                pos[0] = np.min(idx[1]) - margin\n            if np.min(idx[0]) - margin >= 0:\n                pos[1] = np.min(idx[0]) - margin\n            witdh = abs(np.min(idx[0]) - np.max(idx[0])) + margin\n            height = abs(np.min(idx[1]) - np.max(idx[1])) + margin\n            img_sections.append(img[pos[1]:pos[1] + witdh, pos[0]:pos[0] + height])\n            img_sections_clusters.append(test_img[pos[1]:pos[1] + witdh, pos[0]:pos[0] + height])\n            pos_img.append([pos, height, witdh])\n            if plot:\n                rect = patches.Rectangle(pos, height, witdh, linewidth=1, edgecolor='r', facecolor='none')\n                ax.add_patch(rect)\n        if plot:\n            plt.show()\n        return img_sections, img_sections_clusters, pos_img\n\n    def boat_analyze(self, img_sections, img_sections_clusters, img_idx, plot=False):\n        \"\"\"\n        Analyze the different possible boats\n        :param img_sections: samples cut from the original image\n        :param img_sections_clusters: clusters cut from the grow image\n        :param img_idx: index of boat to analyze\n        :param plot: True if you want to plot\n        :return: TODO\n        \"\"\"\n        # Boat segmentation\n        img_boat = img_sections_clusters[img_idx]\n        idx = np.nonzero(img_boat)\n        # Cut boat\n        img_b = np.zeros(img_sections[img_idx].shape)\n        img_b[idx] = img_sections[img_idx][idx]\n        # Center translation\n        x_m, y_m = round(np.mean(idx[1])), round(np.mean(idx[0]))\n        x_c, y_c = int(img_boat.shape[1]\/2), int(img_boat.shape[0]\/2)\n        A = GeometricTransformations.translation_k(x_c - x_m, y_c - y_m)\n        img2 = forward_mapping(img_boat, A, scale=(1, 1), default_value=0)\n        # Get boat axis\n        m1, b1, m2, b2 = self.get_axis(img2, return_all=True)\n        y1 = np.vectorize(lambda x: m2 * x + b2)(np.arange(img2.shape[0]))\n        y2 = np.vectorize(lambda x: m1 * x + b1)(np.arange(img2.shape[0]))\n        # Do rotation\n        x = (b2 - b1) \/ (m1 - m2)\n        y = m1 * x + b1\n        x_1 = (-b2 \/ m2)\n        h = distance.euclidean([x_1, 0], [x, y])\n        c1 = distance.euclidean([x, 0], [x, y])\n        alpha = np.arccos(c1\/h)\n        if x_1 < x:\n            A = GeometricTransformations.rotation_k(-alpha)\n        else:\n            A = GeometricTransformations.rotation_k(alpha)\n        img3 = inverse_mapping(img2, A, scale=(1, 1), default_value=0, apply_in_zero=True)\n        # Plot\n        if plot:\n            plt.figure(figsize=(10, 5))\n            plt.subplot(1,3, 1)\n            plt.title(\"Original\")\n            plt.imshow(img2)\n            plt.subplot(1,3, 2)\n            plt.title(\"PCA\")\n            plt.imshow(img2)\n            plt.axis([0,  img2.shape[1], img2.shape[0], 0])\n            plt.plot(y1, label='Axis 1')\n            plt.plot(y2, label='Axis 2')\n            straight_line = np.vectorize(lambda z: x)(np.arange(img2.shape[0]))\n            plt.plot(straight_line, np.arange(img2.shape[0]), label='Perpendicular line')\n            #plt.legend()\n            plt.subplot(1, 3, 3)\n            plt.title(\"Standarize, angle: \" + str(alpha))\n            plt.imshow(img3)\n            straight_line = np.vectorize(lambda z: img2.shape[1]\/2)(np.arange(img2.shape[0]))\n            plt.plot(straight_line, np.arange(img2.shape[0]), '-r')\n            straight_line2 = np.vectorize(lambda z: img2.shape[0]\/2)(np.arange(img2.shape[1]))\n            plt.plot(straight_line2, '-r')\n            plt.show()\n        is_boat, analyze_boat = self.func_analyze(img3, plot=plot)\n        return img3, alpha, len(analyze_boat),  np.mean(analyze_boat), is_boat, img_b.astype(int)\n    \n    def __call__(self, test_img, img, plot=False):\n        print(\"Get images sections\")\n        img_sections, img_sections_clusters, pos_img = self.image_detection(test_img, img, plot=plot)\n        print(\"Filtering and processing images\")\n        selected_images = []\n        index = []\n        for j, i in enumerate(tqdm(range(len(img_sections)))):\n            try:\n                new_boat, angle, len_boat, witdh, is_boat, img_b =self.boat_analyze(img_sections, \n                                                                                    img_sections_clusters, \n                                                                                    i, plot=plot)\n                print(is_boat, len(selected_images))\n                if is_boat:\n                    selected_images.append({\"ProcessImage\": new_boat, \"CutImage\": img_b, \"Angle\": angle, \n                                            \"Len\": len_boat, \"Witdh\": witdh})\n                    index.append(j)\n            except ValueError:\n                print(\"Warning {} didnt work\".format(j))\n        #self.show_final_detection(pos_img, img, index)\n        return selected_images, np.array(pos_img)[index]\n\n    \ndef show_final_detection(img, pos_img):\n    margin = 20\n    fig, ax = plt.subplots(figsize=(15, 15))\n    plt.title(\"Boat detection\")\n    ax.imshow(img)\n    for i in tqdm(pos_img):\n        [pos, height, witdh] = i\n        rect = patches.Rectangle(pos, height, witdh, linewidth=1, edgecolor='r', facecolor='none')\n        ax.add_patch(rect)\n    plt.show()\n","9b71654b":"img = cv2.imread('\/kaggle\/input\/ships-in-satellite-imagery\/scenes\/scenes\/sfbay_1.png')\nplt.figure(figsize=(15, 15))\nplt.imshow(img)","566ead73":"#train_data = img[1200:1400,2000:2500]\ntrain_data = img[1500:1700 ,1500:2000]\nplt.imshow(train_data)","af656dc2":"print(\"Start segmentation\")\nstart = time.time()\nsegmentation = sea_segmentation(train_data)\nimg_seg = segmentation(img)\ntime_segmentation = time.time() - start\nprint(\"End segmentation, time {}\".format(time_segmentation))\n\n\nplt.figure(figsize=(15, 15))\nplt.title(\"Segmentation image\")\nplt.imshow(img_seg, cmap='gray')\n","bd0c8ef7":"print(\"Start morphological operations\")\nstart = time.time()\nmo = morphologicalOperations()\nimg_erode = mo(img_seg)\ntime_morphological = time.time() - start\nprint(\"End morphological operations, time {}\".format(time_morphological))\n\nplt.figure(figsize=(15, 15))\nplt.title(\"Morphological image\")\nplt.imshow(img_erode, cmap='gray')","46320d05":"print(\"Start region grow\")\nstart = time.time()\nregion_grow = get_structures()\ntest_img, debug_img  = region_grow(img_erode, debug=True)\ntime_grow = time.time() - start\nprint(\"End region grow, time {}\".format(time_grow))\n\nplt.figure(figsize=(15, 15))\nplt.title(\"Multi region grow image\")\nplt.imshow(test_img)\nplt.colorbar()","a8dfea08":"def analyze_func(img3, plot=False):\n    analyze_boat = []\n    for i in range(img3.shape[0]):\n        aux = np.nonzero(img3[i])[0]\n        if len(aux) > 0:\n            analyze_boat.append(np.max(aux) - np.min(aux))\n    is_boat = False\n    if 6 < np.mean(analyze_boat) < 18 and 1.5 < np.std(analyze_boat) < 5 and len(analyze_boat) > 50:\n        is_boat = True\n    if plot:\n        print(\"is_boat: {} len: {}, mean witdh {} std witdh {}\".format(is_boat, len(analyze_boat),\n                                                                       np.mean(analyze_boat), \n                                                                       np.std(analyze_boat)))\n    return is_boat, analyze_boat","3f3da249":"print(\"Start processing boats\")\nstart = time.time()\nresults, result_pos = boat_analysis(analyze_func)(test_img, img, plot=True)\nshow_final_detection(img, result_pos)\ntime_processing = time.time() - start\nprint(\"End region grow, time {}\".format(time_processing))","a99dafaa":"plt.figure(figsize=(10,10))\nfor i in range(len(results)):\n    try:\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(results[i]['CutImage'], cmap=plt.cm.binary)\n    except IndexError:\n        break\nplt.show()","1ad9b3c8":"print(\"Total time {}\".format(time_segmentation + time_morphological + time_grow + time_processing))","1b5b8efc":"path = '\/kaggle\/input\/ships-in-satellite-imagery\/scenes\/scenes\/'\nimages = ['sfbay_1.png', 'sfbay_2.png', 'sfbay_3.png', 'sfbay_4.png', 'lb_1.png', 'lb_2.png', 'lb_3.png', 'lb_4.png']\nsamples = [[1500,1700 ,1500,2000], [1500,1700 ,1500,2000], [1500,1700 ,1500,2000], [800,1000 ,500,1000],\n          [1200,1400 ,1500,2000], [1200,1400 ,1500,2000], [1200,1400 ,1500,2000], [1200,1400 ,500,1000]]","65a541cb":"for img_name, s in tqdm(zip(images, samples)):\n    img = cv2.imread(path + img_name)\n    train_data = img[s[0]:s[1] ,s[2]:s[3]]\n    \n    plt.imshow(img)\n    plt.show()\n    plt.imshow(train_data)\n    plt.show()","e478f1be":"for img_name, s in tqdm(zip(images, samples)):\n    img = cv2.imread(path + img_name)\n    train_data = img[s[0]:s[1] ,s[2]:s[3]]\n    segmentation = sea_segmentation(train_data)\n    img_seg = segmentation(img)\n    img_erode = mo(img_seg)\n    test_img  = region_grow(img_erode, debug=False)\n    results, result_pos = boat_analysis(analyze_func)(test_img, img, plot=False)\n    show_final_detection(img, result_pos)\n","b1b63381":"### Region grow","b550822a":"# Satallite image boat detection with multilabel-region-grow","72498ce9":"## Load methods need it\n\nMethods used to do boat detection","d77c3e99":"## Process image","5b8efc94":"## Load image ","b856551b":"# All","072599e0":"### Morphological operations","c8d5a76e":"### Processing boats","b82b726a":"### Segmentation","94c5aed2":"### Total time","8f560a38":"## Load dependencies\n\nWe need tensorflow 2.5 to use some functions in tensorflow_probability.","905d8af7":"### Boat selection"}}