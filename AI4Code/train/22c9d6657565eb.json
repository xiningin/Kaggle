{"cell_type":{"bcafd1ff":"code","a9611348":"code","808e5741":"code","e99d0acd":"code","25944f38":"code","c0a02415":"code","e914787d":"markdown","b3063fc5":"markdown","c1a90c45":"markdown","4b47e533":"markdown","eae1548d":"markdown","4239ce4c":"markdown","7e16cba0":"markdown"},"source":{"bcafd1ff":"import numpy as np\nimport pandas as pd\nimport time\nimport json\nimport glob\nfrom tqdm import tqdm\nimport multiprocessing as mp\nimport cv2\nimport os\nimport mxnet as mx\nimport pydicom\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom gluoncv.utils import viz","a9611348":"class GenerateMxNetRecordIOFile(object):\n    \"\"\"\n    This class generates a binary file following RecordIO format from a list of images.\n    Some code of this class is copied from https:\/\/raw.githubusercontent.com\/apache\/incubator-mxnet\/master\/tools\/im2rec.py.\n    \"\"\"\n\n    def __init__(self, n_cores = -1):\n        \"\"\"\n        This is the class' constructor.\n\n        Parameters\n        ----------\n        n_cores : integer (default = -1)\n                Number of CPU cores to use to extract the data. \n                If n_cores == 1, then multiprocessing module is not used.\n                If n_cores == -1, then all CPU cores are used.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        self.n_cores = n_cores\n\n        if n_cores == -1:\n            self.n_cores = mp.cpu_count()\n\n    def _extract_dcm_info(self, dcm_file_path_str):\n        \"\"\"\n        This method extracts the content of a DCM file (image and metadata).\n\n        Parameters\n        ----------\n        dcm_file_path_str: string\n                Path where the DCM file is stored.\n                \n        Returns\n        -------\n        img: numpy array\n                Extracted image from the DCM file.\n\n        metadata_df: Pandas DataFrame\n                DataFrame containing the extracted metadata.\n        \"\"\"\n\n        # Read the DCM file\n        dcm_data = pydicom.dcmread(dcm_file_path_str)\n\n        # Extract the metadata\n        metadata_dict = {\"file_path\": dcm_file_path_str}\n        metadata_dict[\"storage_type\"] = dcm_data.SOPClassUID\n        metadata_dict[\"patient_name\"] = dcm_data.PatientName.family_name + \" \" + dcm_data.PatientName.given_name\n        metadata_dict[\"patient_id\"] = dcm_data.PatientID\n        metadata_dict[\"patient_age\"] = dcm_data.PatientAge\n        metadata_dict[\"patient_sex\"] = dcm_data.PatientSex\n        metadata_dict[\"modality\"] = dcm_data.Modality\n        metadata_dict[\"body_part_examined\"] = dcm_data.BodyPartExamined\n        metadata_dict[\"view_position\"] = dcm_data.ViewPosition\n\n        if \"PixelData\" in dcm_data:\n            rows = int(dcm_data.Rows)\n            cols = int(dcm_data.Columns)\n            metadata_dict[\"image_height\"] = rows\n            metadata_dict[\"image_width\"] = cols\n            metadata_dict[\"image_size\"] = len(dcm_data.PixelData)\n        else:\n            metadata_dict[\"image_height\"] = np.nan\n            metadata_dict[\"image_width\"] = np.nan\n            metadata_dict[\"image_size\"] = np.nan\n\n        if \"PixelSpacing\" in dcm_data:\n            metadata_dict[\"pixel_spacing_x\"] = dcm_data.PixelSpacing[0]\n            metadata_dict[\"pixel_spacing_y\"] = dcm_data.PixelSpacing[1]\n        else:\n            metadata_dict[\"pixel_spacing_x\"] = np.nan\n            metadata_dict[\"pixel_spacing_y\"] = np.nan\n\n        metadata_df = pd.DataFrame.from_records([metadata_dict])\n\n        # Extract the image (in OpenCV BGR format)\n        img = cv2.cvtColor(dcm_data.pixel_array, cv2.COLOR_GRAY2BGR)\n\n        return img, metadata_df\n\n    def _generate_lst_file(self, patients_id_lst, input_dir_path_str, output_file_path_str):\n        \"\"\"\n        This method generates the RecordIO .lst file.\n        File format is described here: https:\/\/mxnet.incubator.apache.org\/versions\/master\/faq\/recordio.html?highlight=rec%20file.\n\n        Parameters\n        ----------\n        patients_id_lst : list\n                List containing the IDs of the pets we want to extract data for.\n\n        input_dir_path_str: string\n                Path of the directory containing images to use.\n\n        output_file_path_str: string\n                Path where the .lst file will be written.\n\n        Returns\n        -------\n        lst_file_content_lst: list of lists\n                List of lists in the following format: [integer_image_index, path_to_image, label_index]\n        \"\"\"\n\n        # Get images list\n        images_lst = [os.path.basename(f) for f in glob.glob(input_dir_path_str + \"*.*\") if os.path.isfile(f)]\n\n        # Create the file content\n        lst_file_content_df = pd.DataFrame({\"integer_image_index\": list(range(len(images_lst))), \"label_index\": [0.000000 for _ in range(len(images_lst))], \"path_to_image\": images_lst})\n        lst_file_content_df[\"ImageId\"] = lst_file_content_df[\"path_to_image\"].apply(lambda x: x.replace(\".dcm\", \"\"))\n        lst_file_content_df = lst_file_content_df.loc[lst_file_content_df[\"ImageId\"].isin(patients_id_lst)]\n        lst_file_content_df.drop(\"ImageId\", axis = 1, inplace = True)\n        \n        # Ensure the DataFrame has the correct column order\n        lst_file_content_df = lst_file_content_df[[\"integer_image_index\", \"label_index\", \"path_to_image\"]]\n\n        # Save the .lst file\n        lst_file_content_df.to_csv(output_file_path_str, sep = \"\\t\", header = False, index = False)\n\n        # Reshape the DataFrame\n        lst_file_content_df = lst_file_content_df[[\"integer_image_index\", \"path_to_image\", \"label_index\"]]\n\n        # Convert the DataFrame to list\n        lst_file_content_lst = lst_file_content_df.values.tolist()\n\n        return lst_file_content_lst\n    \n    def _read_worker(self, input_dir_path_str, q_in, q_recordio_out, q_metadata_out):\n        \"\"\"\n        This method gets an image, preprocess it and put in the output queue.\n\n        Parameters\n        ----------\n        input_dir_path_str: string\n                Path of the directory containing images to use.\n\n        q_in: Multiprocessing Queue\n                Input queue containing images names.\n\n        q_recordio_out: Multiprocessing Queue\n                Output queue containing extracted images in RecordIO format.\n\n        q_metadata_out: Multiprocessing Queue\n                Output queue containing extracted metadata.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        while True:\n            deq = q_in.get()\n            \n            if deq is None:\n                break\n\n            i, item = deq\n\n            # Compute the DCM file full path\n            dcm_path_str = os.path.join(input_dir_path_str, item[1])\n\n            # Extract data from DCM file\n            img, metadata_df = self._extract_dcm_info(dcm_path_str)\n                        \n            # Create one RecordIO item\n            header = mx.recordio.IRHeader(0, item[2], item[0], 0)\n\n            if img is None:\n                print(\"Image was None for file: %s\" % img_path_str)\n                q_recordio_out.put((i, None, item))\n            else:\n                try:\n                    s = mx.recordio.pack_img(header, img, quality = 95, img_fmt = \".jpg\")\n                    q_recordio_out.put((i, s, item))\n                    q_metadata_out.put(metadata_df)\n                except Exception as e:\n                    print(\"pack_img error on file: %s\" % img_path_str, e)\n                    q_recordio_out.put((i, None, item))\n\n    def _write_worker(self, q_out, output_file_prefix_str):\n        \"\"\"\n        This method fetches a processed image from the output queue and write it to the .rec file.\n\n        Parameters\n        ----------\n        q_out: Multiprocessing Queue\n                Output queue containing result of processing.\n\n        output_file_prefix_str: string\n                Prefix indicating where both .rec and .idx files will be written.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        pre_time = time.time()\n        count = 0\n        record = mx.recordio.MXIndexedRecordIO(output_file_prefix_str + \".idx\", output_file_prefix_str + \".rec\", \"w\")\n        buf = {}\n        more = True\n        while more:\n            deq = q_out.get()\n            if deq is not None:\n                i, s, item = deq\n                buf[i] = (s, item)\n            else:\n                more = False\n            while count in buf:\n                s, item = buf[count]\n                del buf[count]\n                if s is not None:\n                    record.write_idx(item[0], s)\n\n                if count % 1000 == 0:\n                    cur_time = time.time()\n                    print(\"        \", count, \"items saved in the RecordIO in\", cur_time - pre_time, \"secs\")\n                    pre_time = cur_time\n                count += 1\n\n    def _metadata_worker(self, q_out, output_file_prefix_str):\n        \"\"\"\n        This method fetches a processed image from the output queue and write it to a csv file.\n\n        Parameters\n        ----------\n        q_out: Multiprocessing Queue\n                Output queue containing result of processing.\n\n        output_file_prefix_str: string\n                Prefix indicating where both .rec and .idx files will be written.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        metadata_lst = []\n\n        while True:\n            deq = q_out.get()\n\n            if deq is not None:\n                metadata_lst.append(deq)\n            else:\n                # Merge all rows into one DataFrame\n                metadata_df = pd.concat(metadata_lst, axis = 0)\n\n                # Reorder columns\n                metadata_df = metadata_df[[\"file_path\", \"storage_type\", \"patient_name\", \"patient_id\", \"patient_age\", \"patient_sex\", \"modality\", \"body_part_examined\", \"view_position\", \"image_height\", \"image_width\", \"image_size\", \"pixel_spacing_x\", \"pixel_spacing_y\"]]\n\n                # Generate index\n                metadata_df[\"ImageId\"] = metadata_df[\"file_path\"].apply(lambda x: os.path.basename(x).replace(\".dcm\", \"\"))\n                metadata_df.set_index(\"ImageId\", inplace = True)\n\n                # Save DataFrame to csv\n                metadata_df.to_csv(output_file_prefix_str + \".csv\")\n\n                break\n\n    def _generate_rec_file(self, input_dir_path_str, lst_file_content_lst, output_file_prefix_str):\n        \"\"\"\n        This method generates the RecordIO .rec file.\n\n        Parameters\n        ----------\n        input_dir_path_str: string\n                Path of the directory containing images to use.\n\n        lst_file_content_lst: list of lists\n                List of lists in the following format: [integer_image_index, path_to_image, label_index]\n\n        output_file_prefix_str: string\n                Prefix indicating where both .rec and .idx files will be written.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        # Create queues for Producer-Consumer paradigm\n        q_in = [mp.Queue(1024) for i in range(self.n_cores - 1)]\n        q_recordio_out = mp.Queue(1024)\n        q_metadata_out = mp.Queue(1024)\n        \n        # Define the processes\n        read_processes = [mp.Process(target = self._read_worker, args = (input_dir_path_str, q_in[i], q_recordio_out, q_metadata_out)) for i in range(self.n_cores - 1)]\n        \n        # Process images with n_cores - 1 process\n        for p in read_processes:\n            p.start()\n            \n        # Only use one process to write .rec to avoid race-condtion\n        write_process = mp.Process(target = self._write_worker, args = (q_recordio_out, output_file_prefix_str))\n        write_process.start()\n\n        # Only use one process to write metadata to avoid race-condtion\n        metadata_process = mp.Process(target = self._metadata_worker, args = (q_metadata_out, output_file_prefix_str))\n        metadata_process.start()\n        \n        # Put the image list into input queue\n        for i, item in enumerate(lst_file_content_lst):\n            q_in[i % len(q_in)].put((i, item))\n        \n        for q in q_in:\n            q.put(None)\n            \n        for p in read_processes:\n            p.join()\n\n        q_recordio_out.put(None)\n        q_metadata_out.put(None)\n        write_process.join()\n        metadata_process.join()\n\n    def generate_record_io_file(self, patients_id_lst, output_file_prefix, input_images_dir):\n        \"\"\"\n        This method generates the .rec RecordIO file and its .lst associated file.\n        It also apply a transformation on each image.\n\n        Parameters\n        ----------\n        patients_id_lst : list\n                List containing the IDs of the pets we want to extract data for.\n\n        output_file_prefix: string\n                Prefix indicating where both .rec and .idx files will be written.\n\n        input_images_dir: string\n                Path of the directory containing images to use.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        st = time.time()\n        print(\"Generating RecordIO file from images found in \", input_images_dir, \"...\") \n\n        # Generate the .lst file\n        print(\"    Generating the .lst file as\", output_file_prefix + \".lst\", \"...\")\n        lst_file_content_lst = self._generate_lst_file(patients_id_lst, input_images_dir, output_file_prefix + \".lst\")\n\n        # Generate the .rec file\n        print(\"    Generating the .rec file as\", output_file_prefix + \".rec\", \"...\")\n        self._generate_rec_file(input_images_dir, lst_file_content_lst, output_file_prefix)\n        \n        print(\"Generating RecordIO file from images... done in\", round(time.time() - st, 3), \"secs\")","808e5741":"# Get number of available CPUs\ncpu_count = mp.cpu_count()\nprint(\"Found\", cpu_count, \"CPUs\")\n\n# Get the list of patient IDs in sample\npatients_ids_lst = [os.path.basename(f).replace(\".dcm\", \"\") for f in glob.glob(\"..\/input\/sample images\/*.dcm\")]\n\n# Start the timer\nstart_time = time.time()\n\n# Load the data\ngmrf = GenerateMxNetRecordIOFile(n_cores = cpu_count)\ngmrf.generate_record_io_file(patients_ids_lst, \"sample_recordio\", \"..\/input\/sample images\/\")\n\n# Stop the timer and print the exectution time\nprint(\"*** Test finished: Executed in:\", time.time() - start_time, \"seconds ***\")","e99d0acd":"glob.glob(\".\/*.*\")","25944f38":"sample_data = mx.io.ImageRecordIter(\n    path_imgrec = \"sample_recordio.rec\",\n    path_imgidx = \"sample_recordio.idx\",\n    data_shape  = (3, 1024, 1024),\n    batch_size  = 2,\n    shuffle     = True\n)\n\ni = 0\nfor batch in sample_data:\n    for img in batch.data[0]:\n        img = np.transpose(img.asnumpy(), (1, 2, 0))\n        cv2.imwrite(\"sample_image_\" + str(i) + \".png\", img)\n        i += 1","c0a02415":"img = cv2.imread(\"sample_image_0.png\")\nnew_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(new_img)","e914787d":"## 1. Create a class that contains the data loader\n\nThe following class defines the data loading system.","b3063fc5":"## 2. Actually load the data\n\nHere is the code that uses the class defined above to load the data.","c1a90c45":"# Fastest way to load data from Dicom files\n### Author: Thomas SELECK\n### Date: 25\/06\/2019\n\nThe purpose of this notebook is to load the data the fastest possible way before using it in neural nets using MXNet\/Gluon Deep Learning framework.","4b47e533":"## 4. Iterate over the RecordIO\n\nHere, you have multiple options to use the RecordIO.\n\n - Use MxNet API: see [mx.io.ImageRecordIter()](https:\/\/mxnet.incubator.apache.org\/versions\/master\/architecture\/note_data_loading.html) which is a fast iterator, written in C++.\n - Iterate manually over it:","eae1548d":"We can see that 4 files were generated. The description of the files are the following:\n\n - .\/sample_recordio.idx, .\/sample_recordio.lst and .\/sample_recordio.rec: Those files are the generated files in MxNet RecordIO format. For more info, please look [here](https:\/\/mxnet.incubator.apache.org\/versions\/master\/faq\/recordio.html)\n - .\/sample_recordio.csv: This file contains the metadata extracted from the Dicom files, in csv format.\n \n**NOTE: Here the processing of the 10 files in the sample only took 648 ms. For the whole training set (10,712 samples) it only takes 33.8 seconds to generate the RecordIO files (on a 16-cores CPU: AMD Threadripper 1950X).**","4239ce4c":"## 3. See if the data is actually processed","7e16cba0":"## 5. Going further\n\nThe RecordIO file can be used to train a Deep Learning model that can be found in the [GluonCV library](https:\/\/gluon-cv.mxnet.io\/)."}}