{"cell_type":{"bad69e9e":"code","1ad39951":"code","6ac8d4ec":"code","5ce16ee2":"code","16e92ff9":"code","1eca65c1":"code","8bee207c":"code","3052d827":"code","2a3a99fc":"code","21ac7154":"code","9dbd467d":"code","356684f1":"code","4d4fd07a":"code","a04692ba":"code","db34f601":"code","4f413e0b":"code","1557189a":"code","5760dd64":"code","4531354a":"code","0bbb920f":"code","3fa3c902":"code","5146c15b":"code","59498439":"code","46488f21":"code","2763d36e":"code","4ab9cb13":"code","37bb8f55":"code","9e78abca":"code","cdfa4772":"code","2f5be9e1":"code","35f517f7":"code","a6a8dea5":"code","ad066d09":"code","1e8c2e38":"code","9348f420":"code","484eed7c":"code","a85e5332":"code","f3bbd079":"code","8e317023":"code","8ae2e1f4":"code","3ab1b3fb":"code","d6eae596":"code","c8086305":"code","052c5ec6":"code","018dc30a":"code","2609e7cf":"code","a012984a":"code","3dd5ba6a":"code","7d7281c0":"code","6e87bec9":"code","217ca0c0":"code","5250d073":"code","3efcd0d4":"code","c1e7b231":"code","a428bf45":"code","3e462794":"code","f3137e85":"code","19d85997":"code","0dd3c551":"code","b7535eb5":"code","6ac5de2e":"code","1a377511":"code","ee382823":"code","3e330f96":"code","f5ba1b33":"code","5d2056bb":"code","a31183f3":"code","82798a65":"code","27999f92":"code","dbe39091":"code","6513668c":"code","5d99cfdc":"code","1af611d3":"code","d843cff7":"code","3e336976":"code","e048600e":"code","0f22b89c":"code","8b5638c4":"markdown","87c4a087":"markdown","7c6ec6f4":"markdown","85a8268f":"markdown","f1a197a2":"markdown","ea981235":"markdown","a2c0cb1d":"markdown","c581bbc3":"markdown","f3db2490":"markdown","5b5e4abb":"markdown","408bbfef":"markdown","1fbdcdde":"markdown","facfce26":"markdown","ea70fb8d":"markdown","a4500706":"markdown","d74e9f10":"markdown","7aec08cd":"markdown","efe5b292":"markdown","0acaa727":"markdown","36e8d1d1":"markdown","1a627a37":"markdown","ee805d4c":"markdown","1588ade7":"markdown","17435c7e":"markdown","fa148106":"markdown","2a130f24":"markdown","53682e6a":"markdown","16abb8ba":"markdown","8b2542c6":"markdown","93d5266f":"markdown","6f9d0225":"markdown","fa0eeb86":"markdown","e02e3b06":"markdown","f8c28679":"markdown","1b02b817":"markdown","b5169261":"markdown","bef3af12":"markdown","d0fdc9ab":"markdown","daa7a8b6":"markdown","0a1bd090":"markdown","185b8696":"markdown","3a6d31ea":"markdown","38cb060e":"markdown","0f44d170":"markdown","01c21598":"markdown","e42f2e22":"markdown","d7744070":"markdown","efa9eca9":"markdown","b5c6214f":"markdown","cb9ab258":"markdown","7faece8b":"markdown","ea74dc2b":"markdown","be464d71":"markdown","bcece474":"markdown","65f84986":"markdown","68c32750":"markdown","8081eef7":"markdown","8e43ab26":"markdown","6e6c6173":"markdown","9eaa43e3":"markdown","7c6d6d19":"markdown","2d7b7671":"markdown","d9158227":"markdown","e8ada16e":"markdown","afa53a89":"markdown","57a2f981":"markdown","4f84328b":"markdown","f00dff5b":"markdown","c0d203e0":"markdown"},"source":{"bad69e9e":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport squarify\nimport matplotlib.pyplot as plt\nimport plotly.plotly as py\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\nimport plotly.figure_factory as ff\n#Always run this the command before at the start of notebook\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport cufflinks as cf\ncf.set_config_file(offline=True, world_readable=True, theme='ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set_style(\"darkgrid\")","1ad39951":"def question_info(index):\n    survey_headers = pd.read_csv(\"..\/input\/multipleChoiceResponses.csv\", nrows=1)\n    survey_headers.head()\n    print(survey_headers.columns[index], ' : ',survey_headers[survey_headers.columns[index]][0])\n    \ndef question_info2(index):\n    survey_headers = pd.read_csv(\"..\/input\/multipleChoiceResponses.csv\", nrows=1)\n    survey_headers.head()\n    return survey_headers[survey_headers.columns[index]][0]\n    \ndef get_data():\n    survey = pd.read_csv(\"..\/input\/multipleChoiceResponses.csv\", skiprows=2,header=None)\n    data = survey.loc[(survey[7] == 'Data Scientist') | (survey[7] == 'Data Analyst')]\n    return data\n\ndef get_ds_data():\n    survey = pd.read_csv(\"..\/input\/multipleChoiceResponses.csv\", skiprows=2,header=None)\n    ds_data = survey[survey[7] == 'Data Scientist']\n    return ds_data\n\ndef get_da_data():\n    survey = pd.read_csv(\"..\/input\/multipleChoiceResponses.csv\", skiprows=2,header=None)\n    da_data = survey[survey[7] == 'Data Analyst']\n    return da_data\n\nds_data = get_ds_data()\nda_data = get_da_data()","6ac8d4ec":"question_info(5)","5ce16ee2":"ds_education = ds_data[5].value_counts()\nds_education = pd.DataFrame(ds_education).reset_index().rename(columns={'index':'Education_lvl', 5:\"Count\"})\nds_education = ds_education.replace('Some college\/university study without earning a bachelor\u2019s degree', 'Partial college\/university study')\nds_education['Proportion'] = ds_education['Count'] \/ ds_education['Count'].sum()\nds_education['Job'] = 'Data Scientist'\n\nda_education = da_data[5].value_counts()\nda_education = pd.DataFrame(da_education).reset_index().rename(columns={'index':'Education_lvl', 5:\"Count\"})\nda_education = da_education.replace('Some college\/university study without earning a bachelor\u2019s degree', 'Partial college\/university study')\nda_education['Proportion'] = da_education['Count'] \/ da_education['Count'].sum()\nda_education['Job'] = 'Data Analyst'\n\neducation = ds_education.append(da_education)\n\nfig,axes = plt.subplots(1,1,figsize=(10, 10))\npal = sns.light_palette((315, 49, 49),n_colors=2, input='husl', reverse=True)\nsns.set_palette(pal)\nax = sns.barplot(x='Proportion', y='Education_lvl', data=education, hue='Job')\nax.set_ylabel('Education Level',fontsize=15)\nax.set_xlabel('Percentage of Respondentss',fontsize=15)\nax.set_title('Education Levels' ,fontsize=15)\nax.tick_params(labelsize=12.5)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n\nplt.show()","16e92ff9":"question_info(6)","1eca65c1":"ds_education = ds_data[6].value_counts()\nds_education = pd.DataFrame(ds_education).reset_index().rename(columns={'index':'degree', 6:\"Count\"})\nds_education['Percentage'] = ds_education['Count'] \/ ds_education['Count'].sum()\nds_education['Job'] = 'Data Scientist'\n\nda_education = da_data[6].value_counts()\nda_education = pd.DataFrame(da_education).reset_index().rename(columns={'index':'degree', 6:\"Count\"})\nda_education['Percentage'] = da_education['Count'] \/ da_education['Count'].sum()\nda_education['Job'] = 'Data Analyst'\n\nundergrad = ds_education.append(da_education)\nfig,axes = plt.subplots(1,1,figsize=(10, 10))\npal = sns.light_palette((115, 49, 49),n_colors=2, input='husl', reverse=True)\nsns.set_palette(pal)\nax = sns.barplot(x='Percentage', y='degree', data=undergrad, hue='Job')\nax.set_ylabel('Undergraduate Degree',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title('Percentage of Undergraduate Degrees per Job' ,fontsize=15)\nax.tick_params(labelsize=12.5)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n\nplt.show()","8bee207c":"ds_location = ds_data[4].value_counts()\nds_location = pd.DataFrame(ds_location).reset_index().rename(columns={'index':'Loc', 4:\"Count\"})\nds_location = ds_location.sort_values(['Count'], ascending=False)\nds_location['Proportion'] = ds_location['Count'] \/ ds_location['Count'].sum()\nds_location = ds_location[:20]\n\nmy_colours = [[0,\"rgb(5, 10, 172)\"],[0.35,\"rgb(40, 60, 190)\"],[0.5,\"rgb(70, 100, 245)\"],\\\n            [0.6,\"rgb(90, 120, 245)\"],[0.7,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"]]\ndata = [ dict(\n        type = 'choropleth',\n        colorscale = my_colours,\n        locations=ds_location['Loc'],\n        locationmode = 'country names', #matches locations to country names\n        z = ds_location['Proportion'],\n        text = ds_location['Count'], #hover info\n        hoverinfo = 'text',\n        autocolorscale = False,\n        reversescale = True,\n        marker = dict(\n            line = dict (\n                color = 'rgb(180,180,180)',\n                width = 0.5\n            ) ),\n        colorbar=dict(\n            tickprefix='',\n            title='Respondent Proportion')\n) ]\n\nlayout = dict(\n    title = 'Top 20 Locations for Data Scientists',\n    geo = dict(\n        showframe = False,\n        showcoastlines = True,\n        projection = dict(\n            type = 'equirectangular'\n        )\n    )\n)\n\nfig = dict( data=data, layout=layout )\niplot(fig)","3052d827":"da_location = da_data[4].value_counts()\nda_location = pd.DataFrame(da_location).reset_index().rename(columns={'index':'Loc', 4:\"Count\"})\nda_location = da_location.sort_values(['Count'], ascending=False)\nda_location['Proportion'] = da_location['Count'] \/ da_location['Count'].sum()\nda_location = da_location[:20]\n\ndata = [ dict(\n        type = 'choropleth',\n        colorscale = my_colours,\n        locations=da_location['Loc'],\n        locationmode = 'country names', #matches locations to country names\n        z = da_location['Proportion'],\n        text = da_location['Count'], #hover info\n        hoverinfo = 'text',\n        autocolorscale = False,\n        reversescale = True,\n        marker = dict(\n            line = dict (\n                color = 'rgb(180,180,180)',\n                width = 0.5\n            ) ),\n        colorbar=dict(\n            tickprefix='',\n            title='Respondent Proportion')\n) ]\n\nlayout = dict(\n    title = 'Top 20 Locations for Data Analysts',\n    geo = dict(\n        showframe = False,\n        showcoastlines = True,\n        projection = dict(\n            type = 'equirectangular'\n        )\n    )\n)\n\nfig = dict( data=data, layout=layout )\niplot(fig)","2a3a99fc":"question_info(9)","21ac7154":"ds_emp = ds_data[9].value_counts()\nds_emp = pd.DataFrame(ds_emp).reset_index().rename(columns={'index':'industry', 9:\"Count\"})\nds_emp['Proportion'] = ds_emp['Count'] \/ ds_emp['Count'].sum()\nds_emp['Job'] = 'Data Scientist'\n\nda_emp = da_data[9].value_counts()\nda_emp = pd.DataFrame(da_emp).reset_index().rename(columns={'index':'industry', 9:\"Count\"})\nda_emp['Proportion'] = da_emp['Count'] \/ da_emp['Count'].sum()\nda_emp['Job'] = 'Data Analyst'\n\nemployment = ds_emp.append(da_emp)\n\nfig,axes = plt.subplots(1,1,figsize=(10, 10))\npal = sns.light_palette((325, 49, 49),n_colors=2, input='husl', reverse=True)\nsns.set_palette(pal)\nax = sns.barplot(x='Proportion', y='industry', data=employment, hue='Job')\nax.set_ylabel('Top Employment Industries',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title('Most Popular Industries per Job Title' ,fontsize=15)\nax.tick_params(labelsize=12.5)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n\nplt.show()","9dbd467d":"question_info(11)","356684f1":"ds_exp = ds_data[11].value_counts()\nds_exp = pd.DataFrame(ds_exp).reset_index().rename(columns={'index':'exp', 11:\"Count\"})\nds_exp['Proportion'] = ds_exp['Count'] \/ ds_exp['Count'].sum()\nds_exp['Job'] = 'Data Scientist'\n\nda_exp = da_data[11].value_counts()\nda_exp = pd.DataFrame(da_exp).reset_index().rename(columns={'index':'exp', 11:\"Count\"})\nda_exp['Proportion'] = da_exp['Count'] \/ da_exp['Count'].sum()\nda_exp['Job'] = 'Data Analyst'\n\nexp = ds_exp.append(da_exp)\n\nfig,axes = plt.subplots(1,1,figsize=(10, 10))\npal = sns.light_palette((5, 76, 49),n_colors=1, input='husl', reverse=True)\nsns.set_palette(pal)\nax = sns.barplot(x='Proportion', y='exp', data=exp, hue='Job')\nax.set_ylabel('Years Experience',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title('Level of Work Experience' ,fontsize=15)\nax.tick_params(labelsize=12.5)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n\nplt.show()","4d4fd07a":"question_info(12)","a04692ba":"ds_pay = ds_data[12].value_counts()\nds_pay = pd.DataFrame(ds_pay).reset_index().rename(columns={'index':'Wages', 12:\"Count\"})\nds_pay = ds_pay.replace('I do not wish to disclose my approximate yearly compensation', 'Not Disclosing')\nds_pay['Proportion'] = ds_pay['Count'] \/ ds_pay['Count'].sum()\nds_pay['Job'] = 'Data Scientist'\n\nda_pay = da_data[12].value_counts()\nda_pay = pd.DataFrame(da_pay).reset_index().rename(columns={'index':'Wages', 12:\"Count\"})\nda_pay = da_pay.replace('I do not wish to disclose my approximate yearly compensation', 'Not Disclosing')\nda_pay['Proportion'] = da_pay['Count'] \/ da_pay['Count'].sum()\nda_pay['Job'] = 'Data Analyst'\n\npay = ds_pay.append(da_pay)\n\nfig,axes = plt.subplots(1,1,figsize=(15, 15))\npal = sns.diverging_palette(250, 151, s=94, l=85,n=2)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Proportion\", y=\"Wages\", hue=\"Job\", data=pay)\nax.set_ylabel('Wage Range',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Comparison of Compensation\" ,fontsize=15)\nax.tick_params(labelsize=10)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n\nplt.show()","db34f601":"pay_v_edu = ds_data.iloc[:,[11,12]].rename(columns={11:'Exp', 12:'Pay'})\ntemp = pay_v_edu.groupby(by=['Exp','Pay'], as_index=False).size().reset_index()\npay_v_edu = pd.DataFrame(temp).rename(columns={'Exp':'Exp', 'Pay':'Pay', 0:'Count'})\npay_v_edu['Proportion'] = pay_v_edu['Count'] \/ pay_v_edu['Count'].sum()\npay_v_edu = pay_v_edu.replace('I do not wish to disclose my approximate yearly compensation', 'Not Disclosing')\n\nax = sns.FacetGrid(pay_v_edu, col='Exp', height=6, aspect=.75,col_wrap=4, hue='Exp', palette=\"viridis\")\n                                                                \nax.map(sns.barplot, 'Proportion', 'Pay')","4f413e0b":"pay_v_edu = da_data.iloc[:,[11,12]].rename(columns={11:'Exp', 12:'Pay'})\n\ntemp = pay_v_edu.groupby(by=['Exp','Pay'], as_index=False).size().reset_index()\npay_v_edu = pd.DataFrame(temp).rename(columns={'Exp':'Exp', 'Pay':'Pay', 0:'Count'})\npay_v_edu['Proportion'] = pay_v_edu['Count'] \/ pay_v_edu['Count'].sum() * 100\npay_v_edu = pay_v_edu.replace('I do not wish to disclose my approximate yearly compensation', 'Not Disclosing')\n\nax1 = sns.FacetGrid(pay_v_edu, col='Exp', height=6, aspect=.75,col_wrap=4, hue='Exp', palette = sns.diverging_palette(4, 239, s=74, l=50,\n                                                                n=len(pd.unique(da_exp['exp'])), center='dark'))\nax1.map(sns.barplot, 'Proportion', 'Pay')\ndel(ax1)","1557189a":"question_info(13)","5760dd64":"ml_data = get_data()\nml_data = ml_data.replace('We are exploring ML methods (and may one day put a model into production)', 'Exploring ML methods')\nml_data = ml_data.replace('We recently started using ML methods (i.e., models in production for less than 2 years)', 'Recently started using ML')\nml_data = ml_data.replace('We have well established ML methods (i.e., models in production for more than 2 years)', 'Established ML Methods')\nml_data = ml_data.replace('We use ML methods for generating insights (but do not put working models into production)', 'Used for Insights')\nml_data = ml_data.replace('No (we do not use ML methods)', 'No')\n\n#ml_data = ml_data.iloc[:,[7,13]].rename(columns={7:'Job', 13:'Ml'})\n#ml_data = ml_data.groupby(by='Ml',as_index=False)['Job'].count()\n\nml_data = ml_data.iloc[:,[7,13]].rename(columns={7:'Job',13:'Ml'})\nml_DsData = ml_data[ml_data['Job']=='Data Scientist']\nml_DaData = ml_data[ml_data['Job']=='Data Analyst']\n\nml_DsData = ml_DsData['Ml'].value_counts()\nml_DsData = pd.DataFrame(ml_DsData).reset_index().rename(columns={'index':'Ml', 'Ml':\"Count\"})\nml_DsData.iplot(kind='pie',labels='Ml',values='Count',pull=.2,hole=.2,\n          colorscale='greens',textposition='outside',textinfo='value+percent', title='Data Scientist ML Usage')\n\nml_DaData = ml_DaData['Ml'].value_counts()\nml_DaData = pd.DataFrame(ml_DaData).reset_index().rename(columns={'index':'Ml', 'Ml':\"Count\"})\nml_DaData.iplot(kind='pie',labels='Ml',values='Count',pull=.2,hole=.2,\n          colorscale='blues',textposition='outside',textinfo='value+percent', title='Data Analyst ML Usage')","4531354a":"question_info(14)","0bbb920f":"data = get_ds_data()\njob_activity = data[14].value_counts()\njob_activity = pd.DataFrame(job_activity).reset_index().rename(columns={'index':'Activity', 14:\"Count\"})\nfor item in range(15,21):\n    temp = data[item].value_counts()\n    temp = pd.DataFrame(temp).reset_index().rename(columns={'index':'Activity', item:\"Count\"})\n    job_activity = job_activity.append(temp)\n\njob_activity['Job'] = 'Data Scientist'\njob_activity['Percentage'] = job_activity['Count'] \/ job_activity['Count'].sum() * 100\njob_activity['Category'] = ['Category 0','Category 1','Category 2','Category 3','Category 4','Category 5','Category 6']\n\ntrace = go.Table(\n    header=dict(values=['Category', 'Activity'],\n                fill = dict(color='#C2D4FF'),\n                align = ['left'] * 5),\n    cells=dict(values=[job_activity.Category, job_activity.Activity],\n               fill = dict(color='#F5F8FF'),\n               align = ['left'] * 5))\n\ndata = [trace] \niplot(data, filename = 'pandas_table')\n\njob_activity.iplot(kind='bubble', categories='Category', x='Percentage', y='Category', size='Percentage', text='Activity', colorscale='YlGn', \n            xTitle='Percentage of Respondents', title='ML Usage for Data Scientists')\n\ndata = get_da_data()\ntemp_activity = data[14].value_counts()\ntemp_activity = pd.DataFrame(temp_activity).reset_index().rename(columns={'index':'Activity', 14:\"Count\"})\nfor item in range(15,21):\n    temp = data[item].value_counts()\n    temp = pd.DataFrame(temp).reset_index().rename(columns={'index':'Activity', item:\"Count\"})\n    temp_activity = temp_activity.append(temp)\n\ntemp_activity['Job'] = 'Data Analyst'\ntemp_activity['Percentage'] = temp_activity['Count'] \/ temp_activity['Count'].sum() * 100\ntemp_activity['Category'] = ['Category 0','Category 1','Category 2','Category 3','Category 4','Category 5','Category 6']\n\n\njob_activity = job_activity.append(temp_activity)\ntemp_activity.iplot(kind='bubble',categories='Category', x='Percentage', y='Category', size='Percentage', text='Activity', colorscale='YlOrRd' ,\n            xTitle='Percentage of Data Analyst Respondents', title='ML Usage for Data Analysts' )\n\n","3fa3c902":"question_info(22)","5146c15b":"def change_string(item):\n    if len(item.split('(')) > 1:\n        item  = item.split('(')[1].strip(')')\n        return item\n    else:\n        item = item\n        return item","59498439":"data = get_ds_data()\nds_tools = data[22].value_counts()\nds_tools = pd.DataFrame(ds_tools).reset_index().rename(columns={'index':'Tool', 22:\"Count\"})    \nds_tools['Job'] = 'Data Scientist'\nds_tools['Percentage'] = ds_tools['Count'] \/ ds_tools['Count'].sum() * 100\n\ndata = get_da_data()\nda_tools = data[22].value_counts()\nda_tools = pd.DataFrame(da_tools).reset_index().rename(columns={'index':'Tool', 22:\"Count\"})\nda_tools['Job'] = 'Data Analyst'\nda_tools['Percentage'] = da_tools['Count'] \/ da_tools['Count'].sum() * 100\n\ntools = ds_tools.append(da_tools)\n\ntools['Tool'] = tools['Tool'].apply(change_string)\n\nig,axes = plt.subplots(1,1,figsize=(10, 10))\npal = sns.light_palette((95, 96, 49),n_colors=2, input='husl', reverse=True)\nsns.set_palette(pal)\nax = sns.barplot(x='Percentage', y='Tool', data=tools, hue='Job')\nax.set_ylabel('Primary Analysis Tool',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title('Most Popular Data Analysis Tools Used in Last 5 Years' ,fontsize=15)\nax.tick_params(labelsize=12.5)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n\nplt.show()\n\n","46488f21":"question_info(29)","2763d36e":"def agg_data(data,index, end, column,job):\n    ds_data = data[index].value_counts().reset_index().rename(columns={'index':column,index:'Count'})\n    \n    for item in range(index +1, end + 1):\n        ds_data = ds_data.append(data[item].value_counts().reset_index().rename(columns={'index':column,item:'Count'}))\n        \n    ds_data['Job'] = job\n    ds_data['Percentage'] = ds_data['Count'] \/ ds_data['Count'].sum() * 100\n    return ds_data","4ab9cb13":"ds_ide = agg_data(ds_data,29, 43, 'IDE','Data Scientist')\nda_ide = agg_data(da_data,29, 43, 'IDE','Data Analyst')\n\nide = ds_ide.append(da_ide)\n\nfig,axes = plt.subplots(1,1,figsize=(15, 15))\npal = sns.diverging_palette(118, 309, s=74, l=50,n=2)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Percentage\", y=\"IDE\", hue=\"Job\", data=ide)\nax.set_ylabel('IDE',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular IDE'S\" ,fontsize=15)\nax.tick_params(labelsize=10)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title","37bb8f55":"question_info(55)","9e78abca":"ds_note = agg_data(ds_data,45, 55, 'Notebook','Data Scientist')\nda_note = agg_data(da_data,45, 55, 'Notebook','Data Analyst')\n\nnotebooks = ds_note.append(da_note)\nfig,axes = plt.subplots(1,1,figsize=(15, 15))\nsns.set_palette(\"viridis\")\nax = sns.barplot(x=\"Percentage\", y=\"Notebook\", hue=\"Job\", data=notebooks)\nax.set_ylabel('Hosted Notebook',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular Hosted Notebook\" ,fontsize=15)\nax.tick_params(labelsize=10)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title","cdfa4772":"question_info(57)","2f5be9e1":"ds_ccs = agg_data(ds_data,57, 63, 'Cloud','Data Scientist')\nda_ccs = agg_data(da_data,57, 63, 'Cloud','Data Analyst')\n\nccs = ds_ccs.append(da_ccs)\n\nfig,axes = plt.subplots(1,1,figsize=(10, 10))\npal = sns.light_palette((164, 99, 51),n_colors=len(pd.unique(ccs['Job'])), input='husl', reverse=True)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Percentage\", y=\"Cloud\", hue=\"Job\", data=ccs)\nax.set_ylabel('Cloud Computing Provider',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular Cloud Computing Provider\" ,fontsize=15)\nax.tick_params(labelsize=12.5)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title","35f517f7":"question_info(65)","a6a8dea5":"ds_prog = agg_data(ds_data,65, 82, 'Prog','Data Scientist')\nda_prog = agg_data(da_data,65, 82, 'Prog','Data Analyst')\n\nprog = ds_prog.append(da_prog)\n\nfig,axes = plt.subplots(1,1,figsize=(15, 15))\npal = sns.diverging_palette(220, 10, s=74, l=50,n=2)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Percentage\", y=\"Prog\", hue=\"Job\", data=prog)\nax.set_ylabel('Programming Language',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular Programming Languages\" ,fontsize=15)\nax.tick_params(labelsize=10)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title","ad066d09":"question_info(84)","1e8c2e38":"ds_prog = agg_data(ds_data,84, 84, 'Prog','Data Scientist')\nda_prog = agg_data(da_data,84, 84, 'Prog','Data Analyst')\n\nprog = ds_prog.append(da_prog)\n\nfig,axes = plt.subplots(1,1,figsize=(20, 10))\npal = sns.diverging_palette(150, 10, s=74, l=50, n=6)\nsns.set_palette(pal)\nax = squarify.plot(sizes=ds_prog['Percentage'], label=ds_prog['Prog'], alpha=.4,color=pal )\nax.set_title('Most Popular Programming Language for Data Scientists' ,fontsize=20)\nplt.axis('off')\nplt.show()\n\nfig,axes = plt.subplots(1,1,figsize=(20, 10))\npal = sns.diverging_palette(294, 244, s=74, l=50, n=6)\nsns.set_palette(pal)\nax = squarify.plot(sizes=da_prog['Percentage'], label=da_prog['Prog'], alpha=.4, color=pal )\nax.set_title('Most Popular Programming Language for Data Analysts' ,fontsize=20)\nplt.axis('off')\nplt.show()\n","9348f420":"question_info(88)","484eed7c":"ds_ml = agg_data(ds_data,88, 106, 'Ml_framework','Data Scientist')\nda_ml = agg_data(da_data,88, 106, 'Ml_framework','Data Analyst')\n\nframeworks = ds_ml.append(da_ml)\nds_ml.sort_values('Percentage', inplace=True)\nda_ml.sort_values('Percentage', inplace=True)\nfig,ax = plt.subplots(1,1,figsize=(10, 10))\n\nplt.scatter(ds_ml['Percentage'], ds_ml['Ml_framework'], color='blue', alpha=1, label='Data Scientist')\nplt.scatter(da_ml['Percentage'], da_ml['Ml_framework'], color='green', alpha=1, label='Data Analyst' )\nax.set_ylabel('ML Framework',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular Machine Learning Frameworks (Last 5 Years)\" ,fontsize=15)\nax.tick_params(labelsize=10)\nplt.legend()\nplt.show()\n","a85e5332":"question_info(108)","f3bbd079":"ds_ml = agg_data(ds_data,108, 108, 'Ml_framework','Data Scientist')\nda_ml = agg_data(da_data,108, 108, 'Ml_framework','Data Analyst')\n\nframeworks = ds_ml.append(da_ml)\n\nds_ml.iplot(kind='bubble', colorscale='PRGn', categories='Ml_framework', x='Percentage', y='Ml_framework', size='Percentage',\n            xTitle='Percentage of Data Scientist Respondents', title='Most Popular ML Framework for Data Scientists')\n\nda_ml.iplot(kind='bubble', categories='Ml_framework', x='Percentage', y='Ml_framework', size='Percentage', colorscale='RdYlBu',\n            xTitle='Percentage of Data Analyst Respondents', title='Most Popular ML Framework for Data Analysts')\n","8e317023":"question_info(110)","8ae2e1f4":"ds_viz = agg_data(ds_data,110, 122, 'Viz','Data Scientist')\nda_viz = agg_data(da_data,110, 122, 'Viz','Data Analyst')\n\nviz = ds_viz.append(da_viz)\nviz.sort_values('Percentage', inplace=True)\n\nfig,axes = plt.subplots(1,1,figsize=(15, 15))\npal = sns.diverging_palette(120, 10, s=74, l=50,n=2)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Percentage\", y=\"Viz\", hue=\"Job\", data=viz)\nax.set_ylabel('Visualization Libraries',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular Visualization Libraries\" ,fontsize=15)\nax.tick_params(labelsize=15)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title","3ab1b3fb":"question_info(124)","d6eae596":"ds_viz = agg_data(ds_data,124, 124, 'Viz','Data Scientist')\nda_viz = agg_data(da_data,124, 124, 'Viz','Data Analyst')\n\nds_viz.sort_values('Percentage', ascending=False, inplace=True)\nda_viz.sort_values('Percentage', ascending=False, inplace=True)\n\nds_viz[:8].iplot(kind='pie',labels='Viz',values='Count',pull=.1,hole=.1, \n          colorscale='Greens',textposition='outside',textinfo='value+percent', title='Most Popular Visualization Library used by Data Scientists (Top 8)')\n\n\nda_viz[:8].iplot(kind='pie',labels='Viz',values='Count',pull=.1,hole=.1, \n          colorscale='Reds',textposition='outside',textinfo='value+percent', title='Most Popular Visualization Library used by Data Analysts (Top 8)')\n\n","c8086305":"question_info(126)","052c5ec6":"ds_code = agg_data(ds_data,126, 126, 'Coding','Data Scientist')\nda_code = agg_data(da_data,126, 126, 'Coding','Data Analyst')\n\nfig,axes = plt.subplots(1,1,figsize=(20, 10))\npal = sns.diverging_palette(350, 10, s=74, l=50, n=6)\nsns.set_palette(pal)\nax = squarify.plot(sizes=ds_code['Percentage'], label=ds_code['Coding'], alpha=.4,color=pal )\nax.set_title('Time Spent Coding for Data Scientists' ,fontsize=20)\nplt.axis('off')\nplt.show()\n\nfig,axes = plt.subplots(1,1,figsize=(20, 10))\npal = sns.diverging_palette(394, 114, s=74, l=50, n=6)\nsns.set_palette(pal)\nax = squarify.plot(sizes=da_code['Percentage'], label=da_code['Coding'], alpha=.4, color=pal )\nax.set_title('Time Spent Coding for Data Analysts' ,fontsize=20)\nplt.axis('off')\nplt.show()","018dc30a":"question_info(127)","2609e7cf":"question_info(128)","a012984a":"ds_analyse = agg_data(ds_data,127, 127, 'Analyse','Data Scientist')\nda_analyse = agg_data(da_data,127, 127, 'Analyse','Data Scientist')\n\nds_ml = agg_data(ds_data,128, 128, 'Ml','Data Scientist')\nda_ml = agg_data(da_data,128, 128, 'Ml','Data Scientist')\n\nds_analyse = ds_analyse.replace('I have never written code but I want to learn', 'Never wrote code. Want to Learn')\nds_analyse = ds_analyse.replace('I have never written code and I do not want to learn', 'Never wrote code. Dont want to Learn')\n\nagg = ds_ml.append(da_ml)\n\nvalues = da_analyse['Percentage'] * -1\nvalues = values.append(ds_analyse['Percentage'])\nvalues = values.sort_values(ascending=True)\n\nmin_v = int(values.min())\nmax_v = int(values.max())\nvalues = [int(i) for i in values]\n\nlabels = da_analyse['Percentage'] * -1\nlabels = labels.append(ds_analyse['Percentage'])\nlabels = labels.sort_values(ascending=True)\nlabels = [int(i) for i in labels]\n\nnew_labels =[]\nfor item in labels:\n    if item < 0:\n        item = item * -1\n        new_labels.append(item)\n    else:\n        new_labels.append(item)\n\nda_analyse['Percentage'] = da_analyse['Percentage'] * -1\n\n\nlayout = go.Layout(title='Experience in Analysing Data',\n                   yaxis=go.layout.YAxis(tickangle=-15),\n                   xaxis=go.layout.XAxis(\n                       tickangle=-55,\n                       range=[min_v, max_v],\n                       tickvals= [int(i) for i in values],\n                       ticktext= new_labels,\n                       title='Percentage of Respondents'),\n                   barmode='overlay',\n                   bargap=0.5,\n                   height=500,\n                  width=900, \n                  margin=go.layout.Margin(l=225, r=0))\n\ndata = [go.Bar(y=ds_analyse['Analyse'],\n               x=ds_analyse['Percentage'],\n               orientation='h',\n               name='Data Scientists',\n               marker=dict(color='powderblue')\n               ),\n        go.Bar(y=ds_analyse['Analyse'],\n               x=da_analyse['Percentage'],\n               orientation='h',\n               name='Data Analysts',\n               marker=dict(color='seagreen')\n               )]\n\niplot(dict(data=data, layout=layout), filename='EXAMPLES\/bar_pyramid') \n\nds_ml = ds_ml.replace('I have never studied machine learning and I do not plan to', 'Never used ML')\nds_ml = ds_ml.replace('I have never studied machine learning but plan to learn in the future', 'Never used ML but want to')\n\nvalues = da_ml['Percentage'] * -1\nvalues = values.append(ds_ml['Percentage'])\nvalues = values.sort_values(ascending=True)\n\nmin_v = int(values.min())\nmax_v = int(values.max())\nvalues = [int(i) for i in values]\n\nlabels = da_ml['Percentage'] * -1\nlabels = labels.append(ds_ml['Percentage'])\nlabels = labels.sort_values(ascending=True)\nlabels = [int(i) for i in labels]\n\nnew_labels =[]\nfor item in labels:\n    if item < 0:\n        item = item * -1\n        new_labels.append(item)\n    else:\n        new_labels.append(item)\n\nda_ml['Percentage'] = da_ml['Percentage'] * -1\n\n\nlayout = go.Layout(title='Experience in ML Modelling',\n            yaxis=go.layout.YAxis(tickangle=-15),\n                   xaxis=go.layout.XAxis(\n                       tickangle=-55,\n                       range=[min_v, max_v],\n                       tickvals= [int(i) for i in values],\n                       ticktext= new_labels,\n                       title='Percentage of Respondents'),\n                   barmode='overlay',\n                   bargap=0.5,\n                   height=500,\n                  width=900, \n                  margin=go.layout.Margin(l=160, r=0))\n\ndata = [go.Bar(y=ds_ml['Ml'],\n               x=ds_ml['Percentage'],\n               orientation='h',\n               name='Data Scientists',\n               marker=dict(color='powderblue')\n               ),\n        go.Bar(y=ds_ml['Ml'],\n               x=da_ml['Percentage'],\n               orientation='h',\n               name='Data Analysts',\n               marker=dict(color='seagreen')\n               )]\n\niplot(dict(data=data, layout=layout), filename='EXAMPLES\/bar_pyramid') ","3dd5ba6a":"question_info(130)","7d7281c0":"ds_ccs = agg_data(ds_data,130, 149, 'CCS','Data Scientist')\nda_ccs = agg_data(da_data,130, 149, 'CCS','Data Analyst')\n\ns1 = ds_ccs['Percentage'] * 40\ns2 = da_ccs['Percentage'] * 40\n\nfig,ax = plt.subplots(1,1,figsize=(10, 10))\n\nplt.scatter(ds_ccs['Percentage'], ds_ccs['CCS'], color='red', alpha=1, label='Data Scientist', s=s1)\nplt.scatter(da_ccs['Percentage'], da_ccs['CCS'], color='green', alpha=1, label='Data Analyst', s=s2 )\nax.set_ylabel('Cloud Computing Service',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular Cloud Computing Services in the last 5 years\" ,fontsize=15)\nax.tick_params(labelsize=15)\nplt.legend(loc=0, markerscale=.5)\nplt.show()\n","6e87bec9":"question_info(151)","217ca0c0":"ds_ccs = agg_data(ds_data,151, 193, 'ML','Data Scientist')\nda_ccs = agg_data(da_data,151, 193, 'ML','Data Analyst')\n\nds_ccs = ds_ccs[:20]\nda_ccs = da_ccs[:20]\n\nfig,axes = plt.subplots(1,1,figsize=(25, 20))\npal = sns.diverging_palette(350, 10, s=74, l=50, n=20)\nsns.set_palette(pal)\nax = squarify.plot(sizes=ds_ccs['Percentage'], label=ds_ccs['ML'], alpha=.4,color=pal )\nax.set_title('Most Popular Machine Learning Products (Last 5 Years) for Data Scientists' ,fontsize=20)\nplt.axis('off')\nplt.show()\n\nfig,axes = plt.subplots(1,1,figsize=(25, 20))\npal = sns.diverging_palette(250, 44, s=74, l=50, n=20)\nsns.set_palette(pal)\nax = squarify.plot(sizes=da_ccs['Percentage'], label=da_ccs['ML'], alpha=.4,color=pal )\nax.set_title('Most Popular Machine Learning Products (Last 5 Years) for Data Analysts' ,fontsize=20)\nplt.axis('off')\nplt.show()","5250d073":"question_info(195)","3efcd0d4":"ds_db = agg_data(ds_data,195, 222, 'DB','Data Scientist')\nda_db = agg_data(da_data,195, 222, 'DB','Data Analyst')\n\ndb = ds_db.append(da_db)\nfig,axes = plt.subplots(1,1,figsize=(15, 15))\npal = sns.diverging_palette(280, 10, s=44, l=50,n=2)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Percentage\", y=\"DB\", hue=\"Job\", data=db)\nax.set_ylabel('Relational Database Products',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular Relational Database Products (Last 5 Years)\" ,fontsize=15)\nax.tick_params(labelsize=15)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n","c1e7b231":"question_info(224)","a428bf45":"ds_bigData = agg_data(ds_data,224, 248, 'bigData','Data Scientist')\nda_bigData = agg_data(da_data,224, 248, 'bigData','Data Analyst')\n\nds_bigData.sort_values('Percentage', ascending=False, inplace=True)\nda_bigData.sort_values('Percentage', ascending=False, inplace=True)\n\n\nds_bigData[:15].iplot(kind='pie',labels='bigData',values='Count',pull=.1,hole=.1, \n          colorscale='Paired',textposition='outside',textinfo='value+percent', title='Most Popular Big Data Products for Data Scientists (Top 15)')\n\nda_bigData[:15].iplot(kind='pie',labels='bigData',values='Count',pull=.1,hole=.1, \n          colorscale='Set3',textposition='outside',textinfo='value+percent', title='Most Popular Big Data Products for Data Analysts (Top 15)')\n","3e462794":"question_info(250)","f3137e85":"ds_dtype = agg_data(ds_data,250, 261, 'Data','Data Scientist')\nda_dtype = agg_data(da_data,250, 261, 'Data','Data Analyst')\n\nagg = ds_dtype.append(da_dtype)\n\nvalues = da_dtype['Percentage'] * -1\nvalues = values.append(ds_dtype['Percentage'])\nvalues = values.sort_values(ascending=True)\n\nmin_v = int(values.min())\nmax_v = int(values.max())\nvalues = [int(i) for i in values]\n\nlabels = da_dtype['Percentage'] * -1\nlabels = labels.append(ds_dtype['Percentage'])\nlabels = labels.sort_values(ascending=True)\nlabels = [int(i) for i in labels]\n\nnew_labels =[]\nfor item in labels:\n    if item < 0:\n        item = item * -1\n        new_labels.append(item)\n    else:\n        new_labels.append(item)\n\nda_dtype['Percentage'] = da_dtype['Percentage'] * -1\n\n\nlayout = go.Layout(title='Most Popular types of data worked on in the PAST',\n                   yaxis=go.layout.YAxis(tickangle=-15),\n                   xaxis=go.layout.XAxis(\n                       tickangle=-55,\n                       range=[min_v, max_v],\n                       tickvals= [int(i) for i in values],\n                       ticktext= new_labels,\n                       title='Percentage of Respondents'),\n                   barmode='overlay',\n                   bargap=0.5,\n                   height=500,\n                  width=900, \n                  margin=go.layout.Margin(l=225, r=0))\n\ndata = [go.Bar(y=ds_dtype['Data'],\n               x=ds_dtype['Percentage'],\n               orientation='h',\n               name='Data Scientists',\n               marker=dict(color='powderblue')\n               ),\n        go.Bar(y=ds_dtype['Data'],\n               x=da_dtype['Percentage'],\n               orientation='h',\n               name='Data Analysts',\n               marker=dict(color='seagreen')\n               )]\n\niplot(dict(data=data, layout=layout), filename='EXAMPLES\/bar_pyramid') ","19d85997":"ds_dtype = agg_data(ds_data,263, 263, 'Data','Data Scientist')\nda_dtype = agg_data(da_data,263, 263, 'Data','Data Analyst')\n\nagg = ds_dtype.append(da_dtype)\n\nvalues = da_dtype['Percentage'] * -1\nvalues = values.append(ds_dtype['Percentage'])\nvalues = values.sort_values(ascending=True)\n\nmin_v = int(values.min())\nmax_v = int(values.max())\nvalues = [int(i) for i in values]\n\nlabels = da_dtype['Percentage'] * -1\nlabels = labels.append(ds_dtype['Percentage'])\nlabels = labels.sort_values(ascending=True)\nlabels = [int(i) for i in labels]\n\nnew_labels =[]\nfor item in labels:\n    if item < 0:\n        item = item * -1\n        new_labels.append(item)\n    else:\n        new_labels.append(item)\n\nda_dtype['Percentage'] = da_dtype['Percentage'] * -1\n\n\nlayout = go.Layout(title='Most Popular types of data CURRENTLY worked on',\n                   yaxis=go.layout.YAxis(tickangle=-15),\n                   xaxis=go.layout.XAxis(\n                       tickangle=-55,\n                       range=[min_v, max_v],\n                       tickvals= [int(i) for i in values],\n                       ticktext= new_labels,\n                       title='Percentage of Respondents'),\n                   barmode='overlay',\n                   bargap=0.5,\n                   height=500,\n                  width=900, \n                  margin=go.layout.Margin(l=225, r=0))\n\ndata = [go.Bar(y=ds_dtype['Data'],\n               x=ds_dtype['Percentage'],\n               orientation='h',\n               name='Data Scientists',\n               marker=dict(color='red')\n               ),\n        go.Bar(y=ds_dtype['Data'],\n               x=da_dtype['Percentage'],\n               orientation='h',\n               name='Data Analysts',\n               marker=dict(color='purple')\n               )]\n\niplot(dict(data=data, layout=layout), filename='EXAMPLES\/bar_pyramid') ","0dd3c551":"question_info(265)","b7535eb5":"ds_dtype = agg_data(ds_data,265, 275, 'Data','Data Scientist')\nda_dtype = agg_data(da_data,265, 275, 'Data','Data Analyst')\n\nds_dtype = ds_dtype.replace('None\/I do not work with public data', 'None')\nds_dtype = ds_dtype.replace('Dataset aggregator\/platform (Socrata, Kaggle Public Datasets Platform, etc.)', 'Kaggle, Socrata, etc.')\nds_dtype = ds_dtype.replace('I collect my own data (web-scraping, etc.)', 'I collect my own data')\n\nda_dtype = ds_dtype.replace('None\/I do not work with public data', 'None')\nda_dtype = ds_dtype.replace('Dataset aggregator\/platform (Socrata, Kaggle Public Datasets Platform, etc.)', 'Kaggle, Socrata, etc.')\nda_dtype = ds_dtype.replace('I collect my own data (web-scraping, etc.)', 'I collect my own data')\n\n\nagg = ds_dtype.append(da_dtype)\n\nds_dtype.iplot(kind='pie',labels='Data',values='Count',pull=.1,hole=.1, \n          colorscale='RdYlGn',textposition='outside',textinfo='value+percent', \n        title='Most Popular Public Dataset Source for Data Scientists')\n\nds_dtype.iplot(kind='pie',labels='Data',values='Count',pull=.1,hole=.1, \n          colorscale='RdYlBu',textposition='outside',textinfo='value+percent', \n         title='Most Popular Public Dataset Source for Data Analysts')\n","6ac5de2e":"question_info(278)","1a377511":"def agg_data_work(data,index, end, column,job, label_5):\n    \n    labels=[]\n    for i in range(index,end+1):\n        temp_str = str(question_info2(i))\n        s = temp_str.split(\"-\")[1]\n        labels.append(s)\n    \n    if len(label_5) > 1:\n        labels[5] = 'Finding and Communicating Insights'\n    \n    ds_data = data[index].value_counts().reset_index().rename(columns={'index':column,index:'Count'})\n    ds_data['Activity'] = labels[0]\n\n    for ind,item in enumerate(range(index +1, end + 1)):\n        temp = data[item].value_counts().reset_index().rename(columns={'index':column,item:'Count'})\n        temp['Activity'] = labels[ind+1]\n        ds_data = ds_data.append(temp)\n        #ds_data = ds_data.append(data[item].value_counts().reset_index().rename(columns={'index':column,item:'Count'}))\n    \n        \n    ds_data['Job'] = job\n    ds_data['Percentage_of_Respondents'] = ds_data['Count'] \/ ds_data['Count'].sum() * 100\n    return ds_data","ee382823":"def widths(data, w):\n    widths = []\n    for item in range(0, len(data)):\n        widths.append(w)\n    \n    return widths","3e330f96":"def colors(data, c):\n    colors = []\n    for item in range(0, len(data)):\n        colors.append(c)\n    \n    return colors","f5ba1b33":"def gen_plot(ds_work, Job):\n    gathering_data = ds_work[ds_work['Activity'] == ' Gathering data']\n    trace_gather = go.Scatter(x=list(gathering_data['Percentage_of_Respondents']),\n                            y=list(gathering_data['Percentage_of_Time']),\n                            name='Gathering data',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(gathering_data, '#33CFA5') ))\n    \n    cleaning_data = ds_work[ds_work['Activity'] == ' Cleaning data']\n    trace_clean = go.Scatter(x=list(cleaning_data['Percentage_of_Respondents']),\n                            y=list(cleaning_data['Percentage_of_Time']),\n                            name='Cleaning data',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(cleaning_data, '#4286f4') ))\n\n    viz_data = ds_work[ds_work['Activity'] == ' Visualizing data']\n    trace_viz = go.Scatter(x=list(viz_data['Percentage_of_Respondents']),\n                            y=list(viz_data['Percentage_of_Time']),\n                            name='Visualizing data',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(viz_data, '#f2435d') ))\n\n    model_data = ds_work[ds_work['Activity'] == ' Model building\/model selection']\n    trace_model = go.Scatter(x=list(model_data['Percentage_of_Respondents']),\n                            y=list(model_data['Percentage_of_Time']),\n                            name='Model building',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(model_data, '#de75ff') ))\n\n    prod_data = ds_work[ds_work['Activity'] == ' Putting the model into production']\n    trace_prod = go.Scatter(x=list(prod_data['Percentage_of_Respondents']),\n                            y=list(prod_data['Percentage_of_Time']),\n                            name='Putting the model into production',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(prod_data, '#8dfcc4') ))\n\n    insight_data = ds_work[ds_work['Activity'] == 'Finding and Communicating Insights']\n    trace_insight = go.Scatter(x=list(insight_data['Percentage_of_Respondents']),\n                            y=list(insight_data['Percentage_of_Time']),\n                            name='Finding and Communicating Insights',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(insight_data, '#f7cb79') ))   \n\n    other_data = ds_work[ds_work['Activity'] == ' Other']\n    trace_other = go.Scatter(x=list(other_data['Percentage_of_Respondents']),\n                            y=list(other_data['Percentage_of_Time']),\n                            name='Other',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(other_data, '#8dfcf5') ))\n\n    data = [trace_gather, trace_clean, trace_viz, trace_model, trace_prod, trace_insight, trace_other]\n    \n    gather=[dict(x=gathering_data['Percentage_of_Respondents'].mean(),\n                       y=gathering_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. Time at Activity: ' + str(round(gathering_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    clean=[dict(x=cleaning_data['Percentage_of_Respondents'].mean(),\n                       y=cleaning_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. Time at Activity: ' + str(round(cleaning_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    viz=[dict(x=viz_data['Percentage_of_Respondents'].mean(),\n                       y=viz_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. Time at Activity: ' + str(round(viz_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    model=[dict(x=model_data['Percentage_of_Respondents'].mean(),\n                       y=model_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. Time at Activity: ' + str(round(model_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    prod=[dict(x=prod_data['Percentage_of_Respondents'].mean(),\n                       y=prod_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. Time at Activity: ' + str(round(prod_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    insights=[dict(x=insight_data['Percentage_of_Respondents'].mean(),\n                       y=insight_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. Time at Activity: ' + str(round(insight_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    other=[dict(x=other_data['Percentage_of_Respondents'].mean(),\n                       y=other_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. Time at Activity: ' + str(round(other_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n\n\n    updatemenus = list([\n        dict(active=0,\n             buttons=list([  \n                dict(label = 'All Activities',\n                     method = 'update',\n                     args = [{'visible': [True, True, True, True,True, True, True]},\n                             {'title': Job + 'Work Activity: All Activities'}]),\n                dict(label = 'Gathering data',\n                     method = 'update',\n                     args = [{'visible': [True, False, False, False,False, False, False]},\n                             {'title': Job + 'Work Activity: Gathering data',\n                             'annotations': gather}]),\n                dict(label = 'Cleaning data',\n                     method = 'update',\n                     args = [{'visible': [False, True, False, False,False, False, False]},\n                             {'title': Job + 'Work Activity: Cleaning data',\n                             'annotations': clean}]),\n                dict(label = 'Visualizing data',\n                     method = 'update',\n                     args = [{'visible': [False, False, True, False,False, False, False]},\n                             {'title': Job + 'Work Activity: Visualizing data',\n                             'annotations': viz}]),\n\n                dict(label = 'Model building',\n                     method = 'update',\n                     args = [{'visible': [False, False, False, True,False, False, False]},\n                             {'title': Job + 'Work Activity: Model building',\n                             'annotations': model}]),\n                dict(label = 'Putting the model into production',\n                     method = 'update',\n                     args = [{'visible': [False, False, False, False,True, False, False]},\n                             {'title': Job + 'Work Activity: Putting the model into production',\n                             'annotations': prod}]),\n                dict(label = 'Finding and Communicating Insights',\n                     method = 'update',\n                     args = [{'visible': [False, False, False, False,False, True, False]},\n                             {'title': Job + 'Work Activity: Finding and Communicating Insights',\n                             'annotations': insights}]), \n                 dict(label = 'Other',\n                     method = 'update',\n                     args = [{'visible': [False, False, False, False,False, False, True]},\n                             {'title': Job + 'Work Activity: Other',\n                             'annotations': other}]), \n\n                dict(label = 'Reset',\n                     method = 'update',\n                     args = [{'visible': [True, True, True, True,True, True, True]},\n                             {'title':  Job + 'Work Activity: All Activities'}])\n            ]),\n        )\n    ])\n\n    Job2 = '% of ' + Job.strip() + 's '\n    layout = dict(title=Job + 'Work Activities', showlegend=False,\n                  updatemenus=updatemenus, \n                  xaxis=dict(\n                    title=Job2 + 'That Perform Selected Activity',\n                  ),\n                  yaxis=dict(\n                    title='% of Time Spent at Selected Activity',\n                  ))\n\n    fig = dict(data=data, layout=layout)\n    filename='update_dropdown'\n    return [fig, filename]   ","5d2056bb":"labels_5 = 'Finding and Communicating Insights'\n\nds_work = agg_data_work(ds_data,277, 283, 'Percentage_of_Time','Data Scientist', labels_5)\nda_work = agg_data_work(da_data,277, 283, 'Percentage_of_Time','Data Analyst', labels_5)\n\nJob = 'Data Scientist '\nplot = gen_plot(ds_work, Job)\niplot(plot[0], plot[1])\n\nJob = 'Data Analyst '\nplot = gen_plot(da_work, Job)\niplot(plot[0], plot[1])","a31183f3":"question_info(284)","82798a65":"def gen_plot_ml(ds_work, Job):\n    self_data = ds_work[ds_work['Activity'] == ' Self']\n    trace_self = go.Scatter(x=list(self_data['Percentage_of_Respondents']),\n                            y=list(self_data['Percentage_of_Time']),\n                            name='Self Taught',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(self_data, '#33CFA5') ))\n    \n    online_data = ds_work[ds_work['Activity'] == ' Online courses (Coursera, Udemy, edX, etc.)']\n    trace_online = go.Scatter(x=list(online_data['Percentage_of_Respondents']),\n                            y=list(online_data['Percentage_of_Time']),\n                            name='Online courses',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(online_data, '#4286f4') ))\n\n    work_data = ds_work[ds_work['Activity'] == ' Work']\n    trace_work = go.Scatter(x=list(work_data['Percentage_of_Respondents']),\n                            y=list(work_data['Percentage_of_Time']),\n                            name='Learned Through Work',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(work_data, '#f2435d') ))\n\n    uni_data = ds_work[ds_work['Activity'] == ' University']\n    trace_uni = go.Scatter(x=list(uni_data['Percentage_of_Respondents']),\n                            y=list(uni_data['Percentage_of_Time']),\n                            name='Learned at University',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(uni_data, '#de75ff') ))\n\n    comp_data = ds_work[ds_work['Activity'] == ' Kaggle competitions']\n    trace_kaggle = go.Scatter(x=list(comp_data['Percentage_of_Respondents']),\n                            y=list(comp_data['Percentage_of_Time']),\n                            name='Learned by doing Kaggle competitions',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(comp_data, '#8dfcc4') ))  \n\n    other_data = ds_work[ds_work['Activity'] == ' Other']\n    trace_other = go.Scatter(x=list(other_data['Percentage_of_Respondents']),\n                            y=list(other_data['Percentage_of_Time']),\n                            name='Other',\n                            mode = 'markers',\n                            marker=dict(size = 10,color= colors(other_data, '#8dfcf5') ))\n\n    data = [trace_self, trace_online, trace_work, trace_uni, trace_kaggle, trace_other]\n    \n    self=[dict(x=self_data['Percentage_of_Respondents'].mean(),\n                       y=self_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. amount of ML knowledge gained at selected activity: ' + str(round(self_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    online=[dict(x=online_data['Percentage_of_Respondents'].mean(),\n                       y=online_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. amount of ML knowledge gained at selected activity: ' + str(round(online_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    work=[dict(x=work_data['Percentage_of_Respondents'].mean(),\n                       y=work_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. amount of ML knowledge gained at selected activity: ' + str(round(work_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    uni=[dict(x=uni_data['Percentage_of_Respondents'].mean(),\n                       y=uni_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. amount of ML knowledge gained at selected activity: ' + str(round(uni_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n    \n    kaggle=[dict(x=comp_data['Percentage_of_Respondents'].mean(),\n                       y=comp_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. amount of ML knowledge gained at selected activity: ' + str(round(comp_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n\n    \n    other=[dict(x=other_data['Percentage_of_Respondents'].mean(),\n                       y=other_data['Percentage_of_Time'].mean(),\n                       xref='x', yref='y',\n                       text='Avg. amount of ML knowledge gained at selected activity: ' + str(round(other_data['Percentage_of_Time'].mean(),2)),\n                           ax=200, ay=-50)]\n\n\n    updatemenus = list([\n        dict(active=0,\n             buttons=list([  \n                dict(label = 'All ML Learning Sources',\n                     method = 'update',\n                     args = [{'visible': [True, True, True, True,True, True]},\n                             {'title': Job + 'ML knowledge: All Sources'}]),\n                dict(label = 'Self Taught',\n                     method = 'update',\n                     args = [{'visible': [True, False, False, False,False, False]},\n                             {'title': Job + 'ML knowledge got by: Self Teaching',\n                             'annotations': self}]),\n                dict(label = 'Online Courses',\n                     method = 'update',\n                     args = [{'visible': [False, True, False, False,False, False]},\n                             {'title': Job + 'ML knowledge got by: Online Courses',\n                             'annotations': online}]),\n                dict(label = 'Learning Through Work',\n                     method = 'update',\n                     args = [{'visible': [False, False, True, False,False, False]},\n                             {'title': Job + 'ML knowledge got by: Learning Through Work',\n                             'annotations': work}]),\n\n                dict(label = 'University Course',\n                     method = 'update',\n                     args = [{'visible': [False, False, False, True,False, False]},\n                             {'title': Job + 'ML knowledge got by: University Course',\n                             'annotations': uni}]),\n                dict(label = 'Partaking in Kaggle Competitions',\n                     method = 'update',\n                     args = [{'visible': [False, False, False, False,True, False]},\n                             {'title': Job + 'ML knowledge got by: Partaking in Kaggle Competitions',\n                             'annotations': kaggle}]),\n                 dict(label = 'Other',\n                     method = 'update',\n                     args = [{'visible': [False, False, False, False,False, True]},\n                             {'title': Job + 'ML knowledge got by: Other Sources',\n                             'annotations': other}]), \n\n                dict(label = 'Reset',\n                     method = 'update',\n                     args = [{'visible': [True, True, True, True,True, True]},\n                             {'title':  Job + 'ML knowledge: All Sources'}])\n            ]),\n        )\n    ])\n\n    Job2 = '% of ' + Job.strip() + 's '\n    layout = dict(title=Job + 'ML Learning Sources', showlegend=False,\n                  updatemenus=updatemenus, \n                  xaxis=dict(\n                    title=Job2 + 'Responses',\n                  ),\n                  yaxis=dict(\n                    title='% of ML knowledge gained',\n                  ))\n\n    fig = dict(data=data, layout=layout)\n    filename='update_dropdown'\n    return [fig, filename] ","27999f92":"label_5 = ''\nds_ml = agg_data_work(ds_data,284, 289, 'Percentage_of_Time','Data Scientist', label_5)\nda_ml = agg_data_work(da_data,284, 289, 'Percentage_of_Time','Data Analyst', label_5)\n\nJob = 'Data Scientist '\nplot = gen_plot_ml(ds_ml, Job)\niplot(plot[0], plot[1])\n\nJob = 'Data Analyst '\nplot = gen_plot_ml(da_ml, Job)\niplot(plot[0], plot[1])\n","dbe39091":"question_info(291)","6513668c":"ds_dtype = agg_data(ds_data,291, 303, 'Course','Data Scientist')\nda_dtype = agg_data(da_data,291, 303, 'Course','Data Analyst')\n\nagg = ds_dtype.append(da_dtype)\n\nvalues = da_dtype['Percentage'] * -1\nvalues = values.append(ds_dtype['Percentage'])\nvalues = values.sort_values(ascending=True)\n\nmin_v = int(values.min())\nmax_v = int(values.max())\nvalues = [int(i) for i in values]\n\nlabels = da_dtype['Percentage'] * -1\nlabels = labels.append(ds_dtype['Percentage'])\nlabels = labels.sort_values(ascending=True)\nlabels = [int(i) for i in labels]\n\nnew_labels =[]\nfor item in labels:\n    if item < 0:\n        item = item * -1\n        new_labels.append(item)\n    else:\n        new_labels.append(item)\n\nda_dtype['Percentage'] = da_dtype['Percentage'] * -1\n\n\nlayout = go.Layout(title='Most Popular online courses for data science',\n                   yaxis=go.layout.YAxis(tickangle=-15),\n                   xaxis=go.layout.XAxis(\n                       tickangle=-55,\n                       range=[min_v, max_v],\n                       tickvals= [int(i) for i in values],\n                       ticktext= new_labels,\n                       title='Percentage of Respondents'),\n                   barmode='overlay',\n                   bargap=0.5,\n                   height=500,\n                  width=900, \n                  margin=go.layout.Margin(l=225, r=0))\n\ndata = [go.Bar(y=ds_dtype['Course'],\n               x=ds_dtype['Percentage'],\n               orientation='h',\n               name='Data Scientists',\n               marker=dict(color='green')\n               ),\n        go.Bar(y=ds_dtype['Course'],\n               x=da_dtype['Percentage'],\n               orientation='h',\n               name='Data Analysts',\n               marker=dict(color='orange')\n               )]\n\niplot(dict(data=data, layout=layout), filename='EXAMPLES\/bar_pyramid')","5d99cfdc":"question_info(330)","1af611d3":"ds_qual= agg_data(ds_data,330, 330, 'Quality','Data Scientist')\nds_qual2= agg_data(ds_data,331, 331, 'Quality','Data Scientist')\n\nds_qual = ds_qual.append(ds_qual)\n\nda_qual = agg_data(da_data,330, 330, 'Quality','Data Analyst')\nda_qual2 = agg_data(da_data,331, 331, 'Quality','Data Analyst')\n\nagg = ds_qual.append(da_qual)\nagg1 = ds_qual2.append(da_qual2)\n\nfig,axes = plt.subplots(1,1,figsize=(10, 10))\npal = sns.light_palette((105, 70, 84),n_colors=2, input='husl', reverse=True)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Percentage\", y=\"Quality\", hue=\"Job\", data=agg)\nax.set_ylabel('Media Sources',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Opinion: Online Courses VS. Traditional Learning Methods\" ,fontsize=15)\nax.tick_params(labelsize=15)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n\n\nfig,axes = plt.subplots(1,1,figsize=(10, 10))\npal = sns.light_palette((145, 50, 84),n_colors=2, input='husl', reverse=True)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Percentage\", y=\"Quality\", hue=\"Job\", data=agg1)\nax.set_ylabel('Media Sources',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Opinion: Bootcamps VS. Traditional Learning Methods\" ,fontsize=15)\nax.tick_params(labelsize=15)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title","d843cff7":"question_info(307)","3e336976":"ds_media= agg_data(ds_data,307, 328, 'Media','Data Scientist')\nda_media = agg_data(da_data,307, 328, 'Media','Data Analyst')\n\nagg = ds_media.append(da_media)\n\nfig,axes = plt.subplots(1,1,figsize=(15, 15))\npal = sns.diverging_palette(120, 10, s=74, l=50,n=2)\nsns.set_palette(pal)\nax = sns.barplot(x=\"Percentage\", y=\"Media\", hue=\"Job\", data=agg)\nax.set_ylabel('Media Sources',fontsize=15)\nax.set_xlabel('Percentage of Respondents',fontsize=15)\nax.set_title(\"Most Popular Media Sources for Data Science\" ,fontsize=15)\nax.tick_params(labelsize=15)\nplt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\nplt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title","e048600e":"question_info(332)","0f22b89c":"ds_expertise = agg_data(ds_data,332, 332, 'Exp','Data Scientist')\nda_expertise = agg_data(da_data,332, 332, 'Exp','Data Analyst')\n\nds_expertise = ds_expertise.replace('Independent projects are slightly more important than academic achievements', 'Independent projects are slightly more important')\nds_expertise = ds_expertise.replace('Independent projects are much more important than academic achievements', 'Independent projects are much more important')\nds_expertise = ds_expertise.replace('Independent projects are equally important as academic achievements', 'Independent projects are equally important')\nds_expertise = ds_expertise.replace('Independent projects are slightly less important than academic achievements', 'Independent projects are slightly less important')\nds_expertise = ds_expertise.replace('Independent projects are much less important than academic achievements', 'Independent projects are much less important')\n\nda_expertise = ds_expertise.replace('Independent projects are slightly more important than academic achievements', 'Independent projects are slightly more important')\nda_expertise = ds_expertise.replace('Independent projects are much more important than academic achievements', 'Independent projects are much more important')\nda_expertise = ds_expertise.replace('Independent projects are equally important as academic achievements', 'Independent projects are equally important')\nda_expertise = ds_expertise.replace('Independent projects are slightly less important than academic achievements', 'Independent projects are slightly less important')\nda_expertise = ds_expertise.replace('Independent projects are much less important than academic achievements', 'Independent projects are much less important')\n\nds_expertise.iplot(kind='pie',labels='Exp',values='Count',pull=.1,hole=.1, \n          colorscale='Greens',textposition='outside',textinfo='value+percent', \n        title='Academic achievement or independent projects?. Data Scientist Responses')\n\nda_expertise.iplot(kind='pie',labels='Exp',values='Count',pull=.1,hole=.1, \n          colorscale='Reds',textposition='outside',textinfo='value+percent', \n         title='Academic achievement or independent projects?. Data Analyst Responses')\n","8b5638c4":"### **Most Popular Big Data Products (Last 5 Years)**\n**Timmy:** *Google and AWS are surely going to be popular here*\n\n**Jimmy:** *Yeah but I think the term big data is more to do with data engineers rather than data analysts and data scientists. Theres a lot of options for this question so I think we should look at the top 10 only.*","87c4a087":"### **Formal Education**\n\n**Timmy:** *Jimmy I think people choosing to be in either of our disciplines are going to need some form of degree either in computing or mathematics\/statistics given the nature of our jobs. I remember looking at job descriptions for both titles and I think data science requires a higher qualification like masters degree at minimum.*\n\n**Jimmy:** *I dont agree with that last statement, I think analysts also require masters degrees as standard. We shall see.*","7c6ec6f4":"**Timmy:** *So Numerical data, categorical data and time series data are primarily used by both occupations. If theres one thing we know about now its categorical data Jimmy!*\n\n**Jimmy:** *Absolutely Timmy! The time series data is interesting though, remember at the start we found that the financial services sector was a big employer, the second biggest if I remember correctly. Well, the financial services sector tend to work extensively on time series data e.g. predicting stock prices.*\n\n**Timmy:** *Yeah your right Jimmy. Data scientists seem to be more using more sensor data and image data. I think this shows that they are embracing new fields like IoT and Image Recognition\/segmentation problems more than data analysts. I have said it before and I will say it again, I think data scientists are a little more progressive when it comes to tackling new technologies and problems.* \n\n**Jimmy:** *I don't mean to be picky Timmy but don't forget that this represents ALL types of data the respondents may have used. We should look at what they are actually using most often NOW. *\n","85a8268f":"**Timmy:** *Yep as we thought computers or mathematics\/statistics are the most popular undergraduates for both. Thats to be expected really.*\n\n**Jimmy:** *Yeah true, but I notice that more data analysts contain undergraduate backgrounds that are not related to computers or maths\/statistics which gives more diversity in the workplace. I think we're even stevens after that!*\n\n**Timmy:** *Remember that article [1] I was talking about earlier, it contains loads of information that overlaps with our debate. Basically though it says analysts need programming a.k.a computer science and good math\/statistics backgrounds which again reinforces what the graph we have just created is saying. Just thought I'd let you know!*\n\n1 - 1 draw game:)","f1a197a2":"**Timmy:** *As I expected RStudio and JupyterLab are some of the most used tools by data analysts and data scientists to analyse data, but even more so for data scientists it seems*\n\n**Jimmy:** *The main point I see is that RStudio and JupyterLab which are free are the most widely used. Unfortunately for us data analysts, we normally need to make numerous fancy visualisations to present our findings to business users which is why we tend to use other products such as Tableau, Google Sheets etc. that make the job of producing them slightly easier. I personally prefer the to create the visualisations myself using RStudio and JupyterLab so I'm will to concede to data scientists here given their larger uptake.*\n\n**Timmy:** *Good news Jimmy I had a look around and found that KDnuggets [6] had run a poll to see what the top analytics, data science and machine learning tools were. They found Python, RapidMiner and R to be the top 3 tools. Here's their results.*\n\n![Tools](https:\/\/www.kdnuggets.com\/images\/top-analytics-data-science-machine-learning-software-2018-3yrs-539.jpg)\n\n**Jimmy:** *Yeah thats cool, its a good comparison at the very least. Your research skills know no bounds Timmy!*\n\n5 - 2 to data scientists, the data analysts need to pull some back!","ea981235":"**Timmy:** *I know we separated the graph by job title but I don't think it means one occupation is better than the other in this scenario.*\n\n**Jimmy:** *Agreed.*","a2c0cb1d":"### **Most Used Visualization Libraries (Last 5 Years)**\n**Timmy:** *Well we have been using matplotlib, plotly and seaborn to try and solve our debate haven't we Jimmy?*\n\n**Jimmy:** *Yep and I'm fairly sure the will be quite popular as well.*","c581bbc3":"**Jimmy:** *So the general consensus for both occupations (excluding the no opinion responses) is that Online Courses and Bootcamps are as good as traditional learning methods if not better. A very small proportion of responses from both occupations do not conform to this statement.*\n\n**Timmy:** *You hit the nail on the head there Jimmy:)*","f3db2490":"**Timmy:** *Your on a roll Jimmy, I think your right when you said Big Data is more relevant to data engineers. A significant proportion of both occupations are not using any big data tools.*","5b5e4abb":"### **Where are data scientists and data analysts being employed (Top 20 Countries)?**\n**Timmy:** *Touch\u00e9, well played Jimmy. Lets look at the where the most employment oppourtunities are for both jobs. We should limit it to the top 20 countries for each I think.*\n\n**Jimmy:** *Yep suits me.*","408bbfef":"**Timmy:** *From what I can see the USA, India and Russia are the top locations for data scientists and data analysts. But, data analysts seem to be more popular in asian countries whereas data scientists are more popular in european countries. What are you thinking Jimmy?*\n\n**Jimmy:** *I agree with you I don't think we can pick one as better or worse here its slightly irrelevant in this case. Also I had a look at another article [2] regarding the requirements to become a data scientist. Long story short, the data scientists studied as part of that article came from the USA (40 percent), UK (15 percent), India (15 percent) and the rest were listed as \"other\". It partially resembles the information displayed above for data scientist which as you said reinforces our points.*\n\nWe stay at 1 - 1 folks, how exciting.","1fbdcdde":"**Timmy:** *Jimmy my previous statement about data scientists using cloud computing service more is proven correct given that almost 34 percent of data analysts have not used anly cloud providers which I find hard to believe.*\n\n**Jimmy:** *Yes I'm quite surprised by that myself. Data scientists clearly use more cloud computing services. Technically speaking data science is more progressive than data analysis in that respect.*\n\n7 - 2 to data scientists, can data analysts get back in the contest?","facfce26":"**Timmy:** *I think I was right. As you go up the wage ranges the proportions of data scientists recieving these wages is larger than the proportion of data scientists.*\n\n**Jimmy:** *No arguments here. Yet!.*\n\n**Timmy:** *According to [3] the median salary for data scientists is 110,000 USD whereas the median salary for data analysts is 60,000 USD.*\n\nAnd we're all square at 2 - 2\n\n**Jimmy:** *Wait, I will argue. Looking at wages alone is not ideal, how do the wages relate years of experience? *","ea70fb8d":"### **Machine Learning Frameworks Used In Last 5 Years**\n**Timmy:** *I use Tensorflow and Keras myself what about you Jimmy?*\n\n**Jimmy:** *I use the very same and SciKit-learn. To be honest the only other ones I know of are Theano, Caffe, Torch and PyTorch.*","a4500706":"**Timmy:** *You were right again Jimmy. Kaggle and other data platforms featured highly for both occupations. Government authorities are also quite popular.*\n\n**Jimmy:** *Yup, theres very little to say here, it is what it is if you get me.*","d74e9f10":"**Timmy:** *Jimmy, you were so right. In comparison I was so wrong!*\n\n**Jimmy:** *Sure we can't be right all the time Timmy! In all seriousness though, MySQL and Microsoft SQL Server etc. are technologies that have been around for a long time. They're well understood, well documented user friendly storage technologies so their popularity is well earned.*\n\n**Timmy:** *Data analysts seem to use these top storage technologies more that data scientists. You've already outlined their benefits so I think thats a win for data analysts.*\n\n**Jimmy:** *Just to reinforce our findings here, [11] used the 2018 stackoverflow developer survey and found MySQL and SQL Server to be the most extensively used relational databases.*\n\n10 - 3 to data scientists! Are the data analysts mounting a comeback?","7aec08cd":"This is a story of a data scientist (Timmy) and data analyst (Jimmy) debating which occupation has better attributes and is a better choice for people choosing analytic based disciplines. They will now try settle their debate of data scientists vs. data analysts using the kaggle ML & DS survey dataset. Therefore only respondents who are listed as data scientists or data analysts are examined.\n\nBefore starting I think it is worth giving a brief description of each occupation that gives a rough idea of how they differ. Fortunately for me an article on towards data science [10] gives a really accurate and concise description of both:\n\n**\"A Data Analyst** collects, processes and applies statistical algorithms to structured data in order to yield benefits and improve decision making.\"\n\n**\"A Data Scientist** has similar goals but also has robust skills for dealing with large quantities of unstructured data, potentially processing in near real time. They discover important information and are able to clean, process and run advanced algorithms on the data, which may orginate from a variety of sources. They have strong story telling and visualisation skills.\"\n\nFor the most part I agree with the above statements but we'll let Timmy and Jimmy clarify! :) \n\n**Leave a comment and let me know what you think or what could be improved:)**","efe5b292":"### **Time Spent Analysing Data vs Using Machine Learning Methods**\n**Timmy:** *I wonder if both occupations experience in analysing data will be greater given that ML methods are relatively new?*\n\n**Jimmy** *I would expect that to be the case, even more so for data analysts as they don't use ML methods as often.*","0acaa727":"**Timmy:** *Ok Jimmy I've gone through both Plots and this is what I've found*\n\n        1. Data Analysts spend marginally more time gathering data than data scientists do.\n        2. Data Scientists spend marginally more time at cleaning data in comparison to data analysts. \n        3. Data Analysts spend more time generating visualisations.\n        4. Data Scientists spend slightly more time at modelling data than data analysts.\n        5. Data Scientists spend significantly more time putting the models they created into production than data analysts do.\n        6. Data Scientists spend more time finding and communicating insights than data analysts.\n        7. Finally Data Scientists spend a far more of their time performing other activities in comparison to their data analyst co-workers.\n        \n**Jimmy:** *It's kinda funny how data analysts spend more time creating visualisations which are usually used to communicate something yet data scientists spend more time finding and communicating insights. I would assume they spend more time at the finding part than the communicating part if you know what I mean.*\n\n13 - 3  to data scientists! Surely their too far ahead!","36e8d1d1":"### **Most Popular Relational Database Products (Last 5 Years)**\n**Timmy:** *I'm going to go out on a limb her and say that AWS products like S3 will be popular given that the previous 2 topics contained quite a lot of AWS products.*\n\n**Jimmy:** *Yes thats true but don't forget that a significant proportion of respondents from both occupations didn't use any form of cloud computing services. Those respondents probably use local data bases. Surely MySQL is the most used*","1a627a37":"### **Data Analyst: Pay vs Experience**","ee805d4c":"### **Primary Software Packages**\n**Timmy:** *I don't know about you Jimmy but I reckon jupyter notebook or Rstudio are going to be runaway leaders here.*\n\n**Jimmy:** *Yep probably but their will definitely be more because jupyter notebook for example is not really an enviroment for creating production ready code in my opionion*\n","1588ade7":"**Timmy:** *As we though Jimmy the majority of both data analysts and data scientists have only been working with machine learning for 1 or 2 years.*\n\n**Jimmy:** *Yeah and as experience increases, Data scientists tend to make up a larger proportion. In comparison data analysts have far more experience of analysing data. So if you were trying to choose between a career in either, its sort or a choice between which do you find more interesting or which do you want to spend more time working at, ML or data analysis.*\n\n**Timmy:** *Yeah I agree but you will probably get to do both even if one is only on a smale scale.*","17435c7e":"### **Most Popular Programming Languages (Last 5 Years)**\n**Timmy:** *I'm really looking forward to the comparison of programming languages, this could be really interesting.*\n\n**Jimmy:** *Yes this is one of the topics I have been looking forward to.*","fa148106":"### **Best Online Platforms For Data Science Courses?**\n**Timmy:** *Right, so we're just after seeing that data analysts gain more machine learning knowledge from online courses but where do both occupations gain their data science knowledge. Now theres some overlap between both occupations which is why data analysts would use online data science courses also, and also to upskill I presume.*\n\n**Jimmy:** *Yeah that sounds about right.*","2a130f24":"**Timmy:** *Ok cool, SciKit-Learn appears to be most popular with both data analysts and data scientists. Now I have two theories why this may be the case. Firstly I think the relatively straightforward API and ample documentation is a key factor. Secondly given that a large proportion of respondents are new to data science, and presumably new to machine learning, SciKit-Learn is probably the best starting point.*\n\n**Jimmy:** *Yeah I totally agree with that. I started my machine learning journey on SciKit-Learn and still use it to this day. I notice though, as the frameworks become more powerful they become more popular with data scientists given that its a large part of their job. For more exposure to these libraries, data science is probably the way to go.*\n\n8 - 2 to data scientists, a large marin has opened here folks!","53682e6a":"### **Machine Learning**\n**Timmy:** *And we're on to the hot topic of machine learning. I'll get straight to the point, I think this is more relevant to data scientists. Most articles that compare the two jobs put a greater emphasis on machine learning when talking about data scientists. An article Northeastern University confirms this by saying \"Data scientists also use a variety of techniques to comb through data, including data mining and machine learning\u2014key differentiators between the two roles\" [4] *\n\n**Jimmy:** *I expect that may be the case alright*","16abb8ba":"**Timmy:** *For the most part, it seems that data analysts use R, SQL, SAS and VB more than data scientists but for the rest data scientists seem to use them more. Noticebly data scientists dominate mainstream programming languages that can be used for more than just analysis work. *\n\n**Jimmy:** *Yes but this data represents what programming languages the respondents use on a regular basis but I would like to know which particular language they use most often?*","8b2542c6":"**Timmy:** *Wow SAS is really popular with both! I knew it was widely used but I wasn't expecting it to be that popular.*\n\n**Jimmy:** *I see the machine learning emphasis for data scientists with Amazon Sagemaker and Google Cloud Machine learning engine being quite popular with them. I'm not overly surprised by SAS being so popular, I have used it myself, theres very little it can't do*\n\n**Timmy:** *NLP and computer vision software are also popular among both occupations, which isn't surprising given the popularity of the topics at the moment.*","93d5266f":"**Timmy:** *A quarter of data analysts don't use any cloud computing service and similarly over an eight of data scientists don't use them either. Maybe they work for smaller organisations that can't justify the cost.*\n\n**Jimmy:** *AWS EC2 is very popular with both occupations, but more so with data analysts. I think this is due to extensive data pipelines analysts would be running. I think its less popular with data scientists because AWS offer specific applications for working with machine learning which we already discovered data scientists spend more time at.*\n\n**Timmy:** *But on a wider scale, data scientists seem to use cloud computing services more. I think they put a bigger emphasis on automation which is a good thing.*\n\n10 - 2 to data scientists, what a lead!","6f9d0225":"**Timmy:** *Now, I've never actually used online courses myself but I know of most of them.*\n\n**Jimmy:** *Same, I would have guessed that Coursera was the most popular though, so that doesnt surprise me. An article on learndatasci [12] lists Coursera, edX, DataCamp, Udemy, Udacity and DataQuest as some of the top online data science course providers which is also the case in the above figure. They are all great resources but I just prefer working from books myself. Personal preference I suppose.*\n\n**Timmy:** *Luckily for us, we can actually see how the respondents feel using online courses or bootcamps compare to traditional learning methods. Lets have a look*\n","fa0eeb86":"**Timmy:** *Again it's close. *\n\n**Jimmy:** *The proportions are really similar for both, it's hard to pick a winner here. The article on Towards Data Sciene[2] has some info on this as well. They claim that the median amount of experience data scientists have is 2 years which they also think is caused by it being a relatively new job title.*\n\n**Timmy:** *Yeah they also stated that 64 percent of data scientists came from a different occupation. I had a brief look to see if there was an article that talked about how much experience data analysts have, but to avail unfortunately. What I will say is data analysts as a job title has been around longer which you can see in the graph when the experience increases the number of analysts becomes greater than the number of data scientists. *\n\nThe score remains at 2 - 1 to data analysts","e02e3b06":"**Timmy:** *As we suspected Jimmy Jupyter\/Ipython and RStudio are the most popular by a significant margin for both occupations. It's interesting to see how popular notepad++ is with data analysts, why do think that is Jimmy?*\n\n**Jimmy:** *I'm not really sure to be quite honest I suppose it's generally a popular choice for scripting especially with programmers. It's hard to pick a \"winner\" or \"loser\" between both jobs here, I'm calling it even.*\n\n**Timmy:** *Funnily enough Jimmy, I'm just after reading an article on data camp [7] that showed the results of the stackoverflow survey in relation to the top IDE's and editors, and notepad++ came out on top.*\n\n**Jimmy:** *I'm not surprised given that it's stackoverflow which is aimed at pure programmers. As I said pure programmers tend to like simpler\/retro user interfaces which notepad++ has. Will you show me their visualisation please?*\n\n**Timmy:** *Sure here it is*\n\n![Tools](https:\/\/s3.amazonaws.com\/assets.datacamp.com\/blog_assets\/Python+IDEs\/content_so-poll.jpg)","f8c28679":"### **Most Popular Cloud Computing Products (Last 5 Years)**\n**Timmy:** *So we have meandered around this topic earlier where we found AWS, Google Cloud Platform and Microsoft Azure to be the most popular cloud computing services for both occupations.*\n\n**Jimmy** *Yeah thats true but we may get a little more information on what they are using exactly this time.*","1b02b817":"**Timmy:** *Again its very similar here especially in the top 5 industries for each with there only being one difference for each title (ignoring rank). Computing and finance industries are the big areas for both.*\n\n**Jimmy:** *Yeah this is quite interesting because data analysts appear to be more popular in more industries overall. I looks like data analysts may be more employable in that sense.*\n\n**Timmy:** *Yep that looks to be the case in fairness. Jimmy that article [2] you were talking about earlier had a really interesting visualisation which basically said the data scientists generally work in the industrial sector, which is a bit vague, but India is the exception where most data scientists work in IT. Here's the image if your interested.*\n\n![Industry of Employment](https:\/\/cdn-images-1.medium.com\/max\/2000\/1*fZAdsrW6FTO06SBOgAhfyw.png)\n\n2 - 1 to data analysts!","b5169261":"### **What Industries do data scientists and analysts work in?** \n**Timmy:** *I don't really know why but I associated data analysts with general business whereas I tend to associate data scientists with finance and stuff but I dont know why.*\n\n**Jimmy:** *Well, data analysts are often the source of business decisions so I can see why you associate us with general business but I would have thought that is the case for data scientists also*","bef3af12":"### **Perception of expertise in Data Science?**\n**Timmy:** *So Jimmy, which do you think demonstrates more expertise in data science\/data analysis, academic achievements or independent projects?*\n\n**Jimmy:** *I would say a combination of both, we established earlier that you pretty much need advanced degrees to get these occupations which covers the academic achievement side of things. If you also have independent projects it shows that your proactive in the subject area, you have, and maintain an interest and finally it shows you have a really strong work ethic.*","d0fdc9ab":"### **Data Scientists: Pay vs Experience**","daa7a8b6":"**Jimmy:** *Yeah this really presents us with the same information as the previous but no harm in being thorough. Both jobs use the same technologies though and answering which is best is really a matter of personal preference.*\n\nIt stays at 8 - 2 to data scientists folks.","0a1bd090":"**Timmy:** *You were dead right Jimmy it is much closer than I thought but data scientists do marginally spend more time coding. For me and a lot of my co-workers the coding is the fun part so thats quite an important factor.*\n\n**Jimmy:** *Yeah I agree it is a big factor when choosing between the jobs alright.*\n\n**Timmy:** *The article on SimpleLearn [1] does say that the ability to code is a significant requirement for both jobs.*\n\n9 - 2 to data scientists, the \"sexiest job of the 21st Centuary\" is running away with it now.","185b8696":"**Timmy:** *Wow I wasn't expecting it to be that close.*\n\n**Jimmy:** *Yeah that is quite close isn't it.*\n\n**Timmy:** *In saying that, I notice that almost 20 percent of data scientists have a doctoral degree compared to roughly 5 percent of data analysts so I think data scientists edge the argument of who is superior here given that I think that indicates more research has been done in this subject area.*\n\n**Jimmy:** *I think I will have to reluctantly concede this one!.*\n\n**Timmy:** *Jimmy, I actually found an article [1] that stated 88 percent of data scientists had a masters degree and a further 46 percent had doctoral degrees. Although the figures differ the importance of this level of education to be a data scientist is still reflected*\n\n1 - 0 to data scientists!\n\n### **Undergraduate Major**\n**Timmy:** *As I already said I think to be proficient in either discipline you need a background in computers or mathematics\/statistics.*\n\n**Jimmy:** *Yeah I agree with that, lets have a look.*","3a6d31ea":"### **Most Popular Machine Learning Products (Last 5 Years)**\n**Timmy:** *Although I have used machine learning techniques before, I personally have never used any machine learning services yet.*\n\n**Jimmy:** *Same, but I do know there are a lot of them out there, maybe we should look at the top 20 only.*","38cb060e":"**Timmy:** *Wow, over 85 percent or responses from both occupations consider independent projects to be equally or more important than academic achievements in relation to expertise in data science.*\n\n**Jimmy:** *I suppose in hindsight independent projects are more important for the reasons I stated above. It was interesting to see what the general consensus was for this section. Its very cool to see that both data scientists and data analysts are on the same page if you catch my drift.*\n\n**Timmy:** *So we've pretty much found out all we need to know Jimmy, and if I'm not mistaken the score is 13 - 5 to data scientists?*\n\n**Jimmy:** *Yeah yeah yeah data scientists are brilliant. I'm still proud to be a data analyst regardless of the result!*\n\n**Timmy:** *Ah I'm only messing with you Jimmy. They are two very good careers. Theres some similarities between them obviously but it comes down to personal preference really i.e. what does a student trying to decide between the two careers like most; if they like machine learning they should go for data science, if the prefer gathering data and generating visualisations then data analysis is a more suited role.*\n\n**Jimmy:** *I completely agree, each to their own as the saying goes. I've thoroughly enjoyed our debate Timmy, I'm devastated I \"lost\" but I can't win everything I suppose.*  ","0f44d170":"**Timmy:** *It's a good thing we looked at this actually because there seems to be data scientists and analysts with less than 3 years experience with wages of 500,000 USD. I need to get a significant pay rise!*\n\n**Jimmy:** *Yeah I think I need to get a rise too! But the general the trend for both is larger wages are associated with more years experience. As far as I can see its just a small few individuals who are bucking this trend significantly*","01c21598":"### **Cloud Computing Services**\n**Timmy:** *As data scientists are more actively involved in machine learning, and given the processing power machine learning requires, I reckon data scientists will be using cloud computing services more than data analysts.*\n\n**Jimmy:** *Yeah you could be right there Timmy.*","e42f2e22":"### **Favourite media sources reporting on data science?**\n**Timmy:** *Well we've probably mentioned one or two in our discussion so far e.g. toward data science, medium, etc.*\n\n**Jimmy:** *Yeah, and I'm sure theres many more to go with them*","d7744070":"**Timmy:** *Ok cool, almost 35 percent of analysts do not use any hosted notebook service. Almost 25 percent of data scientists and data analysts are using kaggle kernels. I wonder if people use kaggle kernals in some sort of a working capacity or only for personal use?.*\n\n**Jimmy:** *I'm not sure but I doubt they use them in a working capacity but you never know. It's quite clear that data scientists are more actively using hosted notebooks so you could argue they are more proactive with emerging technologies. I also believe this is the case as data scientists do more programming than data analysts in general.*\n\n**Timmy:** *Yeah I think you could be on to something there*\n\n6 - 2 to data scientists, its a big lead!","efa9eca9":"### **Integrated Development Environments**\n**Timmy:** *I think there will be a repeat of the previous with RStudio and JupyterLab being most popular but maybe a few surprises will occur.*\n\n**Jimmy:** *Yeah lets have a look anyway*","b5c6214f":"### References\n[1]\t\u2018Data Science vs. Big Data vs. Data Analytics\u2019, Simplilearn.com, 05-Apr-2016. [Online]. Available: https:\/\/www.simplilearn.com\/data-science-vs-big-data-vs-data-analytics-article. [Accessed: 29-Nov-2018].\n\n[2]\tI. Valchanov, \u2018What are the Skills Needed to Become a Data Scientist in 2018?\u2019, Towards Data Science, 17-Apr-2018. [Online]. Available: https:\/\/towardsdatascience.com\/what-are-the-skills-needed-to-become-a-data-scientist-in-2018-d037012f1db2. [Accessed: 29-Nov-2018].\n\n[3]\tC. P. School Flatiron, \u2018Data Analyst vs. Data Scientist: What\u2019s the Difference?\u2019, Switch. [Online]. Available: https:\/\/www.switchup.org\/blog\/data-analyst-vs-data-scientist. [Accessed: 29-Nov-2018].\n\n[4]\t\u2018Data Scientist vs. Data Analyst: What\u2019s the Difference?\u2019, Northeastern University Graduate Programs, 17-Aug-2017. .\n\n[5]\tT. Ray, \u2018MBA vs MS Business Analytics vs MS Data Science - Tips for Choosing the Right Program\u2019, 09-Jan-2018. .\n\n[6]\t\u2018Python eats away at R: Top Software for Analytics, Data Science, Machine Learning in 2018: Trends and Analysis\u2019. .\n\n[7]\t\u2018Top 5 Python IDEs For Data Science\u2019, DataCamp Community, 22-Jun-2017. [Online]. Available: https:\/\/www.datacamp.com\/community\/tutorials\/data-science-python-ide. [Accessed: 29-Nov-2018].\n\n[8]\tM. Techlabs, \u20188 Best Deep Learning Frameworks for Data Science enthusiasts\u2019, Medium, 05-Apr-2018. .\n\n[9]\tQ. Smith, \u2018The Best Python Data Visualization Libraries\u2019, FusionBrew - The FusionCharts Blog, 17-May-2018. [Online]. Available: https:\/\/www.fusioncharts.com\/blog\/best-python-data-visualization-libraries\/. [Accessed: 29-Nov-2018].\n\n[10]\tB. Stanbury, \u2018From Data Analyst to Data Scientist\u2019, Towards Data Science, 21-Jul-2018. [Online]. Available: https:\/\/towardsdatascience.com\/from-data-analyst-to-data-scientist-f67a724ea265. [Accessed: 29-Nov-2018].\n\n[11]\t\u2018Most popular databases in 2018 according to StackOverflow survey\u2019, EverSQL, 13-Mar-2018. .\n\n[12]\t\u2018Top Data Science Online Courses in 2018\u2019. [Online]. Available: http:\/\/learndatasci.com\/best-data-science-online-courses\/. [Accessed: 01-Dec-2018].\n","cb9ab258":"**Jimmy** *Yup, you were right Timmy. Python and R dominate. SQL is a big player too, I suppose the data needs to be extracted from the database somehow:)*\n\n**Timmy** *This correlates with the a visualisation from the article on towards data science relating to the most popular programming languages for data scientists [2]. Heres what they found.*\n\n![Programming Language](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*sb5cDVL1F7uplIZyQAn-vw.png)\n\n**Jimmy** *I suppose the results aren't identicle but the main thing is it confirms that Python, R and SQL are definite if you want to be a data scientist or data analyst.*\n\n**Timmy** *Yep I agree.*","7faece8b":"**Timmy:** *Well this is interesting. Over 40 percent of analysts analyze data to influence business decisions which you stated earlier Jimmy. It shows the importance of an analyst to a business. In this case though data science appear to be the more diverse job as the percentage of respondents per category is more spread out.*\n\n**Jimmy:** *I have to aggree with you, I also like how how data scientists spend a quarter of their time building prototypes to explore applying ML to other areas. Thats a massive perk of the job for me and something data analysis clearly lacks. Data scientists lead in category 4 which also speaks volumes of the what the job entails. An article by Tanmoy Ray[5] gives a brief description of the job roles which roughly mimics the information contained in the two figures, its worth a look Timmy.*\n\n![Job Role](https:\/\/www.stoodnt.com\/blog\/wp-content\/uploads\/2018\/01\/Data-Science-vs-Business-Analytics-1.png)\n\n**Timmy** *I'll have a look now!*\n\n4 - 2 to data scientists, its double scores here folks, data scientists are starting to pull away!","ea74dc2b":"**Timmy:** *Wow we were way off Jimmy!*\n\n**Jimmy:** *Yep not our finest moment! But given that a large proportion of respondents had small amounts of experience in their respective roles, I'm not surprised to see SciKit-Learn flourish. I didn't think it would be used in a production environment though.*\n\n**Timmy:** *An article on Medium [8] states that Tensorflow Caffe and CNTK are the top 3 ML frameworks. I think this is more realistic as these frameworks are designed to produce ML models for production environments with most supporting GPU utilisation. The results are so similar its hard to pick a winner here either.*\n\nWe stay at 8 - 2 for the next round.","be464d71":"### **Compensation**\n**Timmy:** *I reckon data scientists are bringing in the big bucks because machine learning experience is almost a requirement in all job specifications and thats a booming subject area.*\n\n**Jimmy:** *Possibly, I'm not sure though given that data analysts are so crucial to business decisions.*","bcece474":"**Thanks for viewing my kernel, leave a comment and let me know what you think, or what I should improve upon:)**","65f84986":"### **Most Used Machine Learning Frameworks**\n**Timmy:** *Again I reckon Tensorflow and Keras myself what about you Jimmy?*\n\n**Jimmy:** *Yeah given how powerful they are and Keras is often used as a high level API with a tensorflow backend, theres a good chance they will be quite popular.*","68c32750":"**Timmy:** *As we expected the featured quite highly, 3 of the top 4 to be exact. I notice that ggplot2 is much more popular with data analysts. Having looked back at the treemaps to determine the most popular programming languages its clear R is more popular with data analysts which is why ggplot2 is more popular with them as well, or at least I think thats why.*\n\n**Jimmy:** *Yeah I reckon your right. I also notice altair is quite low even though its a decent library. I personally have tried to use it in Kaggle kernels but it generally causes a lot of difficulty. I have read a couple of threads on Kaggle about it and most seem to think its something to do with Kaggle's technology stack but I'm not sure. It's a pity though because its a nice library.*\n\n**Timmy:** *My personal favourite is seaborn. It makes generating visualisations so easy. Plotly graphs tend to look a little slicker though.*\n\n**Jimmy:** *An article on FusionBrew [9] states that Matplotlib, seaborn, ggplot, bokeh and plotly are some of the top visualisation libraries so we're not the only ones loving them!*","8081eef7":"### **Work Activities**\n**Timmy:** *Oh this one could be really really interesting.*\n\n**Jimmy:** *This is a 2 pointer, definitely a 2 pointer!*","8e43ab26":"### **Sourcing Public Datasets**\n**Timmy:** *I'm not sure about you Jimmy, but I doubt many data analysts or data scientists use public data that often within their jobs, maybe in their own time though.*\n\n**Jimmy:** *Yeah I think your right with that. Most local authorities have data made freely available now though, and obviously Kaggle is another good source, theres nearly 13,000 datasets available now!*","6e6c6173":"### **Where Are Skills Gained?**\n**Timmy:** *We have another two pointer here! As I'm relatively new to the title of data scientist, most of my skills were gained outside of university. More specifically I must give serious credit to Kaggle Competitions for most of what I know about machine learning in conjuction with a few books:)*\n\n**Jimmy:** *Yeah I picked up most of my knowledge of machine learning from kaggle competitions as well. I think the fact that there is a very small possibility that an individual\/team could win a prize is a great driving factor, well for me at least it is.*","9eaa43e3":"### **Most Popular Visualization Libraries Overall**\n**Timmy:** *Just to thorough lets see which library is most popular overall.*","7c6d6d19":"### **Coding Time**\n**Timmy:** *I think data scientists will spend more time coding given that generating prototypes is a larger part of their role as we found out earlier Jimmy.*\n\n**Jimmy** *I don't agree fully with that. It depends if the analyst is using tools with extensive user interfaces which means they spend less time coding because its more point and click. We saw Python and R were quite popular with data analysts as well so I reckon it will be closer than you think.*","2d7b7671":"**Jimmy:** *Right so I'll summarise this one Timmy if thats ok.*\n\n    1. Data analysts gain more ML knowledge via self learning than data scientists do.\n    2. Data analysts gain significantly more of their machine learning knowledge from online courses compared to data scientists.\n    3. Again, Data analysts gain more of their machine learning knowledge through their jobs than data scientists do.\n    4. Data analysts gain more of their knowledge of machine learning through their university courses in comparison to data scientists.\n    5. Data analysts gain more of their machine learning knownledge from partaking in kaggle competitions than data scientists do.\n    6. Finally, data scientists gain more of their machine learning knowledge from other sources in comparison to data analysts.\n    \n**Timmy:** *Basically speaking, data analysts seem to gain more of their machine learning knowledge from a wider range of sources.*   \n\n13 - 5  to data scientists! Start of the comeback for data analysts?","d9158227":"### **How many years of experience have respondents in these roles?**\n**Timmy:** *This could be interesting because both titles have only become popular in the last 10 years really.*\n\n**Jimmy:** *Yeah the experience levels could be relatively low.*","e8ada16e":"### **Responsibilities**\n**Timmy** *Ok so this could be a big help in determining the job thats most interesting and effective.*\n\n**Note: Hover over the bubbles in the below graphs to get info on what they represent!**","afa53a89":"### **Hosted Notebooks**\n**Timmy:** *Where are data scientists and data analysts hosting their code? Lets find out.*\n\n**Jimmy:** *Sure thing.*","57a2f981":"**Timmy:** *It's quite clear data scientists have a greater association with data science as shown by the two smallest categories being no and I don't know. In comparison ~31 percent of you data analysts are not using it which I don't understand given its such a cool and powerful topic.*\n\n**Jimmy:** *I use it myself and I have to agree it is a cool and powerful topic. That is an obvious benefit of being a data scientist alright, your almost guaranteed to be using machine learning  *\n\n3 - 2 to data scientists, this is proving to be a real tug of war for the coveted title of best occupation!","4f84328b":"### **Most Popular Programming Languages (Last 5 Years)**\n**Timmy:** *I could see python and R dominating here..*","f00dff5b":"**Jimmy:** *Now before you say it Timmy, yes data scientists are currently more active in up and coming fields but we do see here that data analysts are actually working more on image data than data scientists. The previous graph would have been misleading had we not looked at the CURRENT data types that are analysed most often.*\n\n11 - 3  to data scientists despite Jimmys best efforts! Hard to see the data analysts coming back in to this one!","c0d203e0":"### **What data are they working on**\n**Timmy:** *Ok so not a lot of insights in the last section but this one should be really cool. Given that we found  machine learning products for NLP and image recognition were popular, text and image data will probably be popular.*\n\n**Jimmy:** *Yeah thats true. Tabular data will be a big one as well because MySQL was so popular too.*"}}