{"cell_type":{"212e1aef":"code","39f4515b":"code","15c9458b":"code","3b7b8498":"code","8af68c97":"code","f7a8abb6":"code","0dd7071c":"code","0599c6e0":"code","f9964c89":"code","4bb0eb8f":"code","ed8987c1":"code","51bc9b6a":"code","1bc5abe7":"code","14ba599e":"code","177b6bed":"code","5f9c9066":"code","94ef2c87":"code","68ab967d":"code","418fa86d":"code","2f1c80ad":"code","749e132a":"code","b5218eee":"code","6e1ebb45":"code","e12dcd8f":"code","cc618750":"code","df164131":"code","75aee08f":"code","45cd2422":"code","be1a730b":"code","b064f825":"code","17edb4a4":"code","39a6149e":"code","fd99a9f5":"code","fbdcf935":"code","02f619da":"code","b7d7f6ca":"code","d7cedfb9":"code","5740efc0":"code","c6eb92ee":"code","2bf4b76c":"code","957782a2":"markdown","9c5a0c87":"markdown","6c5ff615":"markdown","5369de12":"markdown","21dad050":"markdown","4a1f6134":"markdown","4bf11733":"markdown","9d9f7b98":"markdown","d29c6426":"markdown","ce564b0f":"markdown","5b95feca":"markdown","49031d4a":"markdown","f97c67c9":"markdown","52eaf9e0":"markdown","6979c3ca":"markdown","1710407b":"markdown"},"source":{"212e1aef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","39f4515b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px","15c9458b":"df_tr = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_tr.head()","3b7b8498":"df_te = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_te.head()","8af68c97":"df_tr.info()","f7a8abb6":"survived = df_tr['Survived'].value_counts().reset_index()\nfig = px.bar(survived,x=survived.index,y=survived.Survived)\nfig.show()","0dd7071c":"df_tr['Survived'].value_counts(normalize=True)","0599c6e0":"sex_sur = df_tr['Sex'].value_counts().reset_index().rename(columns={\"index\":\"sex\",\"Sex\":\"counts\"})\nfig2 = px.bar(sex_sur,x=sex_sur.sex,y=sex_sur.counts)\nfig2.show()","f9964c89":"df_ss = df_tr.loc[:,[\"Sex\",\"Survived\",\"PassengerId\"]]\ndf_ss","4bb0eb8f":"dg = df_ss.groupby([\"Sex\",\"Survived\"]).count().reset_index()\ndg","ed8987c1":"fig3 = px.bar(dg,x=dg.Survived,y=dg.PassengerId,color=dg.Sex,barmode=\"group\")\nfig3.show()","51bc9b6a":"df_tr[\"Age\"].isna().sum()","1bc5abe7":"#fill age_null\ndf_tr[\"Age\"] = df_tr[\"Age\"].interpolate()\ndf_tr[\"Age\"].isna().sum()","14ba599e":"df_tr.loc[:,[\"Survived\",\"Age\"]].groupby(\"Survived\").agg({\"Age\":[\"mean\",\"max\",\"min\"]})","177b6bed":"ds = df_tr.loc[:,[\"Survived\",\"Pclass\",\"PassengerId\"]].groupby([\"Survived\",\"Pclass\"]).count().reset_index().rename(columns={\"PassengerId\":\"survived_counts\"})\nds[\"Survived\"] = ds[\"Survived\"].replace({0:\"surv_no\",1:\"surv_yes\"})\nds","5f9c9066":"fig4 = px.bar(ds,x=ds.Pclass,y=ds.survived_counts,color=ds.Survived)\nfig4.show()","94ef2c87":"df_tr['SibSp'].unique()","68ab967d":"db = df_tr.loc[:,[\"SibSp\",\"Survived\",\"PassengerId\"]].groupby([\"Survived\",\"SibSp\"]).count().reset_index()\ndb","418fa86d":"plt.figure(figsize=(10,7))\nsns.barplot(x=db.SibSp,y=db.PassengerId,hue=db.Survived)\nplt.ylabel(\"survived_counts\")\nplt.title(\"survived_counts for Slibsp\")","2f1c80ad":"ds_ = df_tr.loc[:,[\"SibSp\",\"PassengerId\"]].groupby(\"SibSp\").count().reset_index().rename(columns={\"PassengerId\":\"Counts\"})\nsns.barplot(x=ds_[\"SibSp\"],y=ds_[\"Counts\"])","749e132a":"df_tr['Parch'].unique()","b5218eee":"dp = df_tr.loc[:,[\"Parch\",\"Survived\",\"PassengerId\"]].groupby([\"Survived\",\"Parch\"]).count().reset_index()\nplt.figure(figsize=(10,7))\nsns.barplot(x=dp.Parch,y=db.PassengerId,hue=db.Survived)\nplt.ylabel(\"survived_counts\")\nplt.title(\"survived_counts for Parch\")","6e1ebb45":"ds_ = df_tr.loc[:,[\"Parch\",\"PassengerId\"]].groupby(\"Parch\").count().reset_index().rename(columns={\"PassengerId\":\"Counts\"})\nsns.barplot(x=ds_[\"Parch\"],y=ds_[\"Counts\"])","e12dcd8f":"de_ = df_tr.loc[:,[\"Embarked\",\"Survived\",\"PassengerId\"]].groupby([\"Embarked\",\"Survived\"]).count().reset_index().rename(columns={\"PassengerId\":\"Counts\"})\nde_","cc618750":"plt.figure(figsize=(10,7))\nsns.barplot(x=de_[\"Embarked\"],y=de_[\"Counts\"],hue=de_[\"Survived\"])","df164131":"dee_ = df_tr.loc[:,[\"Embarked\",\"Fare\"]].groupby([\"Embarked\"]).agg({\"Fare\":\"mean\"})\ndee_","75aee08f":"dp_ = df_tr.loc[:,[\"Pclass\",\"Embarked\",\"PassengerId\"]].groupby([\"Embarked\",\"Pclass\"]).count().reset_index().rename(columns={\"PassengerId\":\"counts\"})\ndp_","45cd2422":"plt.figure(figsize=(10,7))\nsns.barplot(x=dp_[\"Embarked\"],y=dp_[\"counts\"],hue=dp_[\"Pclass\"])","be1a730b":"df_tr.head()","b064f825":"print(df_tr[\"Cabin\"].isnull().sum(),df_tr.shape[0])","17edb4a4":"df_tr.drop(columns=[\"PassengerId\",\"Name\",\"Cabin\",\"Ticket\"],inplace=True)   #train data\ndf_te.drop(columns=[\"Name\",\"Cabin\",\"Ticket\"],inplace=True)  #test data   ","39a6149e":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import recall_score,f1_score,roc_curve,roc_auc_score","fd99a9f5":"#1------train data    cater\n\n\"\"\"step one-----\"\"\"\n#Pclass    1>2>3\ndf_tr[\"Pclass\"] = df_tr[\"Pclass\"].replace({1:\"Pclass_1\",2:\"Pclass_2\",3:\"Pclass_3\"})\np = pd.get_dummies(df_tr[\"Pclass\"])\ndf_tr.drop(columns=[\"Pclass\"],inplace=True)\ndf_tr = pd.concat([df_tr,p],axis=1)\n\n# male = female\nx = pd.get_dummies(df_tr[\"Sex\"])\ndf_tr.drop(columns=[\"Sex\"],inplace=True)\ndf_tr = pd.concat([df_tr,x],axis=1)\n\ne = pd.get_dummies(df_tr[\"Embarked\"])\ndf_tr.drop(columns=[\"Embarked\"],inplace=True)\ndf_tr = pd.concat([df_tr,e],axis=1)\n\n\"\"\"step two-----\"\"\"\n#StandardScaler > age  sibsp parch fare\n#I think these numbers can be large and small, and the size will also make sense. It can be temporarily retained and used as a numeric type to handle features.\n\ndef std(lis_col,data):\n    dataset = data\n    st = StandardScaler()\n    for col in lis_col:\n        dataset[col+\"_std\"] = st.fit_transform(dataset[col].values.reshape(-1,1))\n        dataset = dataset.drop(columns=[col])\n    \n    return dataset \n\ndf_tr = std([\"Age\",\"SibSp\",\"Parch\",\"Fare\"],df_tr)\ndf_tr.head()","fbdcf935":"#2------test data    cater\n\n\"\"\"step one-----\"\"\"\n#Pclass    1>2>3\ndf_te[\"Pclass\"] = df_te[\"Pclass\"].replace({1:\"Pclass_1\",2:\"Pclass_2\",3:\"Pclass_3\"})\npe = pd.get_dummies(df_te[\"Pclass\"])\ndf_te.drop(columns=[\"Pclass\"],inplace=True)\ndf_te = pd.concat([df_te,pe],axis=1)\n\n# male = female\nxe = pd.get_dummies(df_te[\"Sex\"])\ndf_te.drop(columns=[\"Sex\"],inplace=True)\ndf_te = pd.concat([df_te,xe],axis=1)\n\nee = pd.get_dummies(df_te[\"Embarked\"])\ndf_te.drop(columns=[\"Embarked\"],inplace=True)\ndf_te = pd.concat([df_te,ee],axis=1)\n\n\"\"\"step two-----\"\"\"\n#StandardScaler > age  sibsp parch fare\n#I think these numbers can be large and small, and the size will also make sense. It can be temporarily retained and used as a numeric type to handle features.\n\n#fill age _null !!!!!!\n\ndf_te[\"Age\"] = df_te[\"Age\"].interpolate()\ndf_te[\"Fare\"] = df_te[\"Fare\"].interpolate()\n\ndef std(lis_col,data):\n    dataset = data\n    st = StandardScaler()\n    for col in lis_col:\n        dataset[col+\"_std\"] = st.fit_transform(dataset[col].values.reshape(-1,1))\n        dataset = dataset.drop(columns=[col])\n    \n    return dataset \n\ndf_te = std([\"Age\",\"SibSp\",\"Parch\",\"Fare\"],df_te)\ndf_te.head()","02f619da":"from sklearn.model_selection import train_test_split\nx = df_tr.iloc[:,1:].values\ny = df_tr[\"Survived\"].values\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.25,random_state=123)\nlogis = LogisticRegression()\nlogis.fit(xtrain,ytrain)","b7d7f6ca":"print(\"score\",round(logis.score(xtest,ytest),2))\nprint(\"recall_score\",round(recall_score(logis.predict(xtest),ytest),2))","d7cedfb9":"svc = SVC()\nsvc.fit(xtrain,ytrain)\nprint(svc.score(xtest,ytest))\nprint(recall_score(svc.predict(xtest),ytest))","5740efc0":"from sklearn.ensemble import GradientBoostingClassifier\ngbdt = GradientBoostingClassifier()\ngbdt.fit(xtrain,ytrain)\nprint(gbdt.score(xtest,ytest))\nprint(recall_score(gbdt.predict(xtest),ytest))","c6eb92ee":"passdata = df_te.iloc[:,0].to_frame()\nx_test = df_te.iloc[:,1:].values\npre_data = svc.predict(x_test)\npassdata[\"Survived\"] = pre_data\npassdata","2bf4b76c":"passdata.to_csv('submission.csv',index=None)\n","957782a2":"# **Data preprocessing**","9c5a0c87":"1. **People with high status have a high survival rate**\n2. **People with low status have very low survival rates**","6c5ff615":"**I consider combining the values of the above two features in the final data processing**","5369de12":"1. **Processing training data and test data**\n2. **The following columns will not be processed temporarily**","21dad050":"**Select svm**","4a1f6134":"1. **The average age of surviving is about the same**\n2. **The baby survived?**","4bf11733":"# EDA","9d9f7b98":"**survived sex male**","d29c6426":"1. ****drop Passengerld\/Name\/Ticket\/Cabin****\n2. **cabin--- The eigenvalue is indeed too much, so it is not considered**","ce564b0f":"1. **The surviving sex is mainly male**\n2. **The sex of death was mainly female**","5b95feca":"1. **C has the highest survival rate**\n2. **S has the highest mortality rate**","49031d4a":"1. **survived 0 count for 62%**\n2. **survived 1 count for 38%**","f97c67c9":"**Seems the same as the above graphic**","52eaf9e0":"**Is it easier for someone to be in bed?**","6979c3ca":"1. **Most people choose S, but S has the lowest survival rate**\n2. **People who choose Q are almost all people with lower social status**","1710407b":"# **Machine learning model**"}}