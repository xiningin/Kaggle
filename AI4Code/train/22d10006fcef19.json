{"cell_type":{"7cfa5b5f":"code","96dcf9e8":"code","3c993564":"code","7b3f9031":"code","34e21320":"code","59894c60":"code","90e9cda8":"code","a91f520d":"code","54834e61":"code","cf37a704":"code","591b16d0":"code","7ab0d22c":"code","61fe946e":"code","8dd92595":"code","35ef9d2d":"code","d910296a":"code","8d766ce0":"code","67424927":"code","f1583a34":"code","0da1daa8":"code","d6279de3":"code","50a96fe0":"code","364ef4bb":"code","6e4f7cf2":"code","c679c924":"code","610a6bd6":"code","b4610816":"code","ae8161ae":"code","dda78958":"code","951f75b9":"code","721f2ddc":"code","69eb51fa":"code","13da6422":"code","3b60f06a":"code","97276a63":"code","c6cc9f1c":"code","1fe92de9":"markdown","72c8975e":"markdown","088b659b":"markdown","54e71764":"markdown","2a3e3f13":"markdown","0f94b320":"markdown","c62b59b1":"markdown","cced6ffd":"markdown","e2ccd662":"markdown","1c8c0fc5":"markdown","43c3573f":"markdown","4911ada3":"markdown","38ee7ff5":"markdown","ad8f0d5e":"markdown","14831b72":"markdown","e3c47a93":"markdown","e97155ee":"markdown"},"source":{"7cfa5b5f":"import pandas as pd\nimport numpy as np\n\nfrom random import uniform\n\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.feature_selection import VarianceThreshold\nfrom mlxtend.feature_selection import ExhaustiveFeatureSelector\nfrom mlxtend.feature_selection import SequentialFeatureSelector\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import RFECV\nfrom boruta import BorutaPy\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.model_selection import train_test_split\nimport optuna.integration.lightgbm as lgb","96dcf9e8":"train=pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest=pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\nsub=pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')","3c993564":"conditions = [\n    (train.target == \"Class_1\"), (train.target == \"Class_2\"), (train.target == \"Class_3\"),\n    (train.target == \"Class_4\"), (train.target == \"Class_5\"), (train.target == \"Class_6\"),\n    (train.target == \"Class_7\"), (train.target == \"Class_8\"), (train.target == \"Class_9\")\n]\nchoices = [0, 1, 2, 3, 4, 5, 6, 7, 8]\ntrain[\"target\"] = np.select(conditions, choices)\n\nX_test = test.drop(['id'], axis=1)\nX = train.drop(['id', 'target'], axis=1)\ny = train.target","7b3f9031":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)","34e21320":"X_sample = X.sample(frac=0.3, random_state=314) # dev","59894c60":"final_params = {'objective': 'multiclass',\n 'num_class': 9,\n 'metric': 'multi_logloss',\n 'verbosity': -1,\n 'boosting_type': 'gbdt',\n 'learning_rate': 0.03,\n 'random_state': 314,\n 'feature_pre_filter': False,\n 'lambda_l1': 5.620817633003194,\n 'lambda_l2': 1.4316945406619173e-08,\n 'num_leaves': 19,\n 'feature_fraction': 0.4,\n 'bagging_fraction': 1.0,\n 'bagging_freq': 0,\n 'min_child_samples': 5,\n 'num_iterations': 1000,\n 'early_stopping_round': 100}\n\nfinal_lgb = LGBMClassifier(**final_params)","90e9cda8":"%%time\n\nlgb_cv = cross_val_score(final_lgb, X_train, y_train,\n                         fit_params={\n                             'eval_set':(X_val, y_val),\n                             'early_stopping_rounds':final_params['early_stopping_round'],\n                             'verbose':0,\n                             'eval_metric':\"multi_logloss\" \n                         },\n                         error_score='raise',\n                         cv=5, scoring='neg_log_loss', n_jobs=-1)\n\nprint('lgb with all features Mean:', -lgb_cv.mean())\nprint('lgb with all features Std:', lgb_cv.std())","a91f520d":"%%time\n\nfinal_lgb.fit(X, y,\n             eval_set=(X_val, y_val),\n              early_stopping_rounds=final_params['early_stopping_round'],\n              verbose=0,\n              eval_metric=\"multi_logloss\" );","54834e61":"res_var_imp = pd.DataFrame({\n    \"feature\": final_lgb.feature_name_,\n    \"var_imp\": final_lgb.feature_importances_\n})\n\nres_var_imp.sort_values('var_imp', ascending=False)","cf37a704":"%%time\n\nmutual_info = mutual_info_classif(X, y)","591b16d0":"res_mutual_info = pd.DataFrame({\n    \"feature\": X.columns,\n    \"mutual_info\": mutual_info\n})\n\nres_mutual_info.sort_values('mutual_info', ascending=False)","7ab0d22c":"res_pzeros = pd.DataFrame({\n    \"feature\": X.columns,\n    \"pzeros\": (X.shape[0] - X.astype(bool).sum(axis=0)) \/ X.shape[0] * 100\n})\n\nres_pzeros.sort_values('pzeros', ascending=False)","61fe946e":"# CalculeMAD\nmean_abs_diff = np.sum(np.abs(X-np.mean(X, axis=0)), axis=0)\/X.shape[0]","8dd92595":"res_mad = pd.DataFrame({\n    \"feature\": X.columns,\n    \"mad\": mean_abs_diff\n})\nres_mad.sort_values('mad', ascending=False)","35ef9d2d":"#%%time\n#lasso_newton = LogisticRegression(C=1, penalty=\"l2\", solver='sag', tol = 0.1, random_state=314)\n#bfs=SequentialFeatureSelector(lasso_newton,\n#                              k_features='best',\n#                              forward=False,\n#                              floating=False, \n#                              scoring='neg_log_loss',\n#                              cv=0,\n#                              verbose=2,\n#                              n_jobs=1)\n#bfs.fit(X, y);","d910296a":"#res_bfs = pd.DataFrame({\n#    \"feature\": X.columns,\n#    \"bfs\": np.where(X.columns.isin(bfs.k_feature_names_), \"to_keep\", \"to_remove\")\n#})\n#res_bfs.sort_values('bfs', ascending=True)","8d766ce0":"# %%time\n# \n# efs = ExhaustiveFeatureSelector(LGBMClassifier(),\n#                                 min_features=10,\n#                                 max_features=75,\n#                                 scoring='neg_log_loss',\n#                                 print_progress=True,\n#                                 cv=5)\n# \n# efs.fit(X, y);","67424927":"# res_efs = pd.DataFrame({\n#     \"feature\": X.columns,\n#     \"efs\": np.where(X.columns.isin(efs.k_feature_names_), \"to_keep\", \"to_remove\")\n# })\n# res_efs.sort_values('efs', ascending=True)","f1583a34":"%%time\n\nlasso = LogisticRegression(C=1, penalty=\"l1\", solver=\"liblinear\", random_state=314).fit(X, y)\nlasso_selector = SelectFromModel(lasso, prefit=True, threshold=\"median\")","0da1daa8":"res_lasso = pd.DataFrame({\n    \"feature\": X.columns,\n    \"lasso\": np.where(lasso_selector.get_support(), \"to_keep\", \"to_remove\")\n})\nres_lasso.sort_values('lasso', ascending=True)","d6279de3":"%%time\n\nrf = RandomForestClassifier(n_jobs=-1, max_depth=4)\nrfe_selector = RFECV(rf, min_features_to_select=20, step=1, n_jobs=1, verbose=1)\n#rfe_selector.fit(X_sample.values, y[X_sample.index]) #dev\nrfe_selector.fit(X.values, y)","50a96fe0":"res_rfe = pd.DataFrame({\n    \"feature\": X.columns,\n    \"rfe\": np.where(rfe_selector.support_, \"to_keep\", \"to_remove\")\n})\nres_rfe.sort_values('rfe', ascending=True)","364ef4bb":"%%time\n\nrf = RandomForestClassifier(n_jobs=-1, max_depth=4)\nboruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=314)\nboruta_selector.fit(X.values, y)\n#boruta_selector.fit(X_sample.values, y[X_sample.index]) #dev","6e4f7cf2":"res_boruta = pd.DataFrame({\n    \"feature\": X.columns,\n    \"boruta\": np.where(boruta_selector.support_, \"to_keep\", \"to_remove\")\n})\nres_boruta.sort_values('boruta', ascending=True)","c679c924":"X_random = pd.concat([X, pd.DataFrame({'random':[uniform(0.0, 100.0) for i in range(X.shape[0])]})], axis=1)","610a6bd6":"%%time\nrf = RandomForestClassifier(n_jobs=-1, max_depth=3)\nrf.fit(X_random, y);","b4610816":"varip_random = np.float(rf.feature_importances_[X_random.columns==\"random\"])\nprint(\"Random VarImp:\", varip_random)\n\nres_rand_var_imp = pd.DataFrame({\n    \"feature\": X_random.columns,\n    \"rand_var_imp\": rf.feature_importances_,\n    \"rand_var\": np.where(rf.feature_importances_ > varip_random, \"to_keep\", \"to_remove\")\n})\nres_rand_var_imp.sort_values('rand_var_imp', ascending=False)","ae8161ae":"feature_selection = res_var_imp.\\\n                    merge(res_mutual_info).\\\n                    merge(res_pzeros).\\\n                    merge(res_mad).\\\n                    merge(res_lasso).\\\n                    merge(res_boruta).\\\n                    merge(res_rfe).\\\n                    merge(res_rand_var_imp.drop('rand_var_imp', axis=1))\n\nfeature_selection.to_csv('feature_selection.csv', index=False)","dda78958":"feature_selection.style.\\\n    bar(subset=['var_imp'],color='#205ff2').\\\n    bar(subset=['mutual_info'],color='#205ff2').\\\n    bar(subset=['mad'],color='#205ff2').\\\n    background_gradient(subset=['pzeros'],cmap='coolwarm').\\\n    apply(lambda x: [\"background: red\" if v == \"to_remove\" else \"\" for v in x], axis = 1)","951f75b9":"to_drop = [6, 27, 36, 47, 73, 74]\n\nfs = X.drop(['feature_'+str(j) for j in to_drop], axis=1).columns","721f2ddc":"%%time\n\ndtrain = lgb.Dataset(X_train[fs], label=y_train)\ndval = lgb.Dataset(X_val[fs], label=y_val)\n\nparams = {\n    \"objective\": \"multiclass\",\n    \"num_class\": 9,\n    \"metric\": \"multi_logloss\",\n    \"verbosity\": -1,\n    \"boosting_type\": \"gbdt\",\n    'learning_rate': 0.03,\n    'random_state': 314\n    }\n\nbooster = lgb.train(params, \n                    dtrain, valid_sets=dval,\n                    verbose_eval=0,\n                    early_stopping_rounds=100\n                   )","69eb51fa":"booster.params","13da6422":"#1.7487904400322265\nfinal_lgb = LGBMClassifier(**booster.params)","3b60f06a":"booster.best_score","97276a63":"lgb_pred = booster.predict(test[fs])","c6cc9f1c":"sub.iloc[:, 1:] = lgb_pred\nsub.to_csv(\"sub_lgb_feature_selection.csv\", index=False)","1fe92de9":"# Variable Importance","72c8975e":"# Boruta","088b659b":"# Exhaustive Feature  Selection","54e71764":"# Load dependencies","2a3e3f13":"# Lasso Regularization (L1)","0f94b320":"# Sub","c62b59b1":"# Information Gain","cced6ffd":"# RFE","e2ccd662":" # Ref\n\n- https:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/feature-selection-techniques-in-machine-learning\/\n- https:\/\/www.machinelearningplus.com\/machine-learning\/feature-selection\/","1c8c0fc5":"# Random Column","43c3573f":"# Combine Results","4911ada3":"# Methods used:\n\n- Variable Importance\n- Information Gain\n- Zero Proportion\n- Mean Absolute Difference (MAD)\n- Backward Feature Elimination <span style=\"color: red;\">(off)<\/span>\n- Exhaustive Feature  Selection <span style=\"color: red;\">(off)<\/span>\n- Lasso Regularization (L1)\n- Recursive Feature Elimination (RFE) \n- Boruta \n- Random Feature","38ee7ff5":"# Final LightGBM \n\nsee: https:\/\/www.kaggle.com\/gomes555\/tps-jun2021-lightgbmtunercv?scriptVersionId=64532708","ad8f0d5e":"# Mean Absolute Difference (MAD)","14831b72":"# Backward Feature Elimination","e3c47a93":"# Zero proportion","e97155ee":"# Tuner LightGBM with feature selection"}}