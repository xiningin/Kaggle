{"cell_type":{"285a90a7":"code","6f02f3c1":"code","f249d566":"code","a71d6f36":"code","9027a65b":"code","f844b8d8":"code","c1c0d3b8":"code","ada15cea":"code","f926e64d":"code","3f003742":"code","620ad4cb":"code","a1937bed":"code","bc9ea0ad":"code","46509f80":"code","272167cf":"markdown","ff7d9fd3":"markdown","5fe67879":"markdown","ceee687e":"markdown"},"source":{"285a90a7":"import os\nimport random\nimport cv2\nimport glob2\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm_notebook as tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport matplotlib.image as immg\nfrom pathlib import Path\nimport os\nimport gc\nimport cv2\nfrom tqdm.notebook import tqdm\nimport zipfile\nimport io\nfrom sklearn.decomposition import PCA\nimport pandas as pd","6f02f3c1":"import warnings\nwarnings.filterwarnings(\"ignore\")","f249d566":"tr_img_dir = Path('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train')\nts_img_dir = Path('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/test')","a71d6f36":"df = pd.read_csv('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/sample_submission.csv')","9027a65b":"df.head()","f844b8d8":"df.shape","c1c0d3b8":"files = [str(x)+'.dicom' for x in df.image_id.tolist()]","ada15cea":"def get_szs(x):\n    fl = pydicom.read_file(x)\n    return fl.Rows,fl.Columns","f926e64d":"#szs = Parallel(n_jobs=-1,verbose=1)(delayed(get_szs)(str(ts_img_dir)+'\/'+i) for i in random.sample(files,50))","3f003742":"IMAGE_SIZE = (512,512)","620ad4cb":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    img = cv2.resize(data, IMAGE_SIZE)\n    \n    return img","a1937bed":"x_tot,x2_tot = [],[]\nbatch = 50\ndim0 = []\ndim1 = []\nfor idx in tqdm(range(0,len(files),batch)):\n    names = [str(ts_img_dir)+'\/'+x for x in files[idx:idx+batch]]\n    out = Parallel(n_jobs=-1)(delayed(get_szs)(i) for i in names)\n    for s in range(len(out)):\n        d0,d1 = out[s][0],out[s][1]\n        dim0.append(d0)\n        dim1.append(d1)","bc9ea0ad":"df['dim0'] = dim0\ndf['dim1'] = dim1","46509f80":"df.to_csv('vinbigdata_test_meta.csv',index=False)","272167cf":"## Since Dataset Is quite large:\n### We will convert images from dicom to png and resize them.\n**We will be using joblib parallel and delayed functions to speed up the process**","ff7d9fd3":"## SAMPLE Image","5fe67879":"## We will use joblib **parallel & delayed** to read and process dicom images in batches of 50. ","ceee687e":"### Thanks to https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n\nFor Explaining and giving function for correct method for conversion."}}