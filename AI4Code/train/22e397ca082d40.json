{"cell_type":{"cfaba891":"code","907e8181":"code","d2f1ddca":"code","371b50ac":"code","eb7ec9ef":"code","e6ac0378":"code","148fdd54":"code","bb4ef7c3":"code","f45d2168":"code","93c04631":"code","d0d319d3":"code","ea311fa1":"code","d92d979c":"code","72e60207":"code","06b7576e":"code","646c4eb9":"code","524392a7":"code","62aabe36":"code","aa180379":"code","7bc7d17c":"code","4396f7e0":"code","28f1adcc":"code","a9070952":"code","08ef6283":"code","74daebef":"code","c0cbd3f1":"code","69e204e1":"code","b619d828":"code","2a98107f":"code","28eb01c0":"code","f93f63b6":"code","e8ec2dac":"code","3fca1006":"code","54ae65ef":"code","1c15cc84":"code","493bfbd8":"code","b97197be":"code","468fd2d1":"code","9d9f9891":"code","c1c0e4a0":"code","4b3da095":"code","950bc8cb":"code","a8f925bd":"code","ddf398a2":"code","d98923b6":"code","62e2c597":"code","e0c30b49":"code","27036183":"code","9bdb950a":"code","502386d9":"code","0b408b5c":"code","cdc95b99":"markdown","30420f16":"markdown","d0284711":"markdown","6b55da60":"markdown","f04a3d23":"markdown","ab84bf67":"markdown","879390ab":"markdown","1f38be50":"markdown","63055e3d":"markdown","c97b350e":"markdown","675bff6e":"markdown","7a957836":"markdown","a2c56766":"markdown","6a7454e9":"markdown","b6987be0":"markdown"},"source":{"cfaba891":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","907e8181":"pd.set_option('display.max_column',None)","d2f1ddca":"train = pd.read_csv('..\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv')\ntest = pd.read_csv('..\/input\/loan-prediction-problem-dataset\/test_Y3wMUE5_7gLdaTN.csv')","371b50ac":"train","eb7ec9ef":"train.info()","e6ac0378":"train.isna().sum()","148fdd54":"Lone_1 = train[train.Loan_Status == 'Y']['LoanAmount'].mean()\nLone_0 = train[train.Loan_Status == 'N']['LoanAmount'].mean()\nprint(Lone_1,Lone_0)","bb4ef7c3":"train.loc[train.Loan_Status == 'Y','LoanAmount'] = train[train.Loan_Status == 'Y']['LoanAmount'].fillna(Lone_1)\ntrain.loc[train.Loan_Status == 'N','LoanAmount'] = train[train.Loan_Status == 'N']['LoanAmount'].fillna(Lone_0)","f45d2168":"Loan_Term_1 = train[train.Loan_Status == 'Y']['Loan_Amount_Term'].mean()\nLoan_Term_0 = train[train.Loan_Status == 'N']['Loan_Amount_Term'].mean()\nprint(Loan_Term_1,Loan_Term_0)","93c04631":"train.loc[train.Loan_Status == 'Y','Loan_Amount_Term'] = train[train.Loan_Status == 'Y']['Loan_Amount_Term'].fillna(Loan_Term_1)\ntrain.loc[train.Loan_Status == 'N','Loan_Amount_Term'] = train[train.Loan_Status == 'N']['Loan_Amount_Term'].fillna(Loan_Term_0)","d0d319d3":"credit_history_1 = train[train.Loan_Status == 'Y']['Credit_History'].mean()\ncredit_history_0 = train[train.Loan_Status == 'N']['Credit_History'].mean()\nprint(credit_history_1,credit_history_0)\n# \ub300\ucd9c\uc0c1\ud0dc\uac00 Yes\uc778 \uc0ac\ub78c\ub4e4\uc740 credit history \uac00 \uc788\ub294 \uc0ac\ub78c\ub4e4\uc740 0.98\ub85c \uac70\uc758 1\uc774\ub2e4.\n# \ubc18\uba74 \ub300\ucd9c\uc0c1\ud0dc\uac00 No \uc778 \uc0ac\ub78c\ub4e4\uc740 credi history \uc758 \ud3c9\uade0\uc774 0.54\uc774\ub2e4.\n# \uadf8\ub7ec\ubbc0\ub85c Loan_Status == Y ,fillna(credit hisory = 1) Loan_Status == N ,fillna(credit_history=0)","ea311fa1":"train.loc[train.Loan_Status == 'Y','Credit_History'] = train[train.Loan_Status == 'Y']['Credit_History'].fillna(1)\ntrain.loc[train.Loan_Status == 'N','Credit_History'] = train[train.Loan_Status == 'N']['Credit_History'].fillna(0)","d92d979c":"train.Self_Employed.value_counts().plot(kind='bar')\nprint(train.Self_Employed.value_counts())","72e60207":"train.drop('Self_Employed',axis=1,inplace=True)","06b7576e":"dependents = []\nfor i in train.Dependents:\n    if i == '3+':\n        i = 3\n        dependents.append(i)\n    else:\n        dependents.append(i)\ntrain.Dependents = dependents\n    ","646c4eb9":"train.dropna(inplace=True)","524392a7":"train.isna().sum()","62aabe36":"train\n# train set 28 data drop ","aa180379":"train.describe()","7bc7d17c":"f,ax = plt.subplots(figsize=(15,10))\nax.boxplot([train.ApplicantIncome,train.CoapplicantIncome])\nplt.xticks([1,2],['ApplicantIncome','CoapplicantIncome'])\nplt.show()","4396f7e0":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\nfrom sklearn.pipeline import Pipeline","28f1adcc":"encoder = LabelEncoder()\nscaler = MinMaxScaler(feature_range=(0,1))","a9070952":"class data_process(BaseEstimator,TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(x,y):\n        return self\n    def transform(self,x):\n        x['Gender'] = encoder.fit_transform(x.Gender)\n        x['Married'] = encoder.fit_transform(x.Married)\n        x['Education'] = encoder.fit_transform(x.Education)\n        x['Property_Area'] = encoder.fit_transform(x.Property_Area)\n        x['Loan_Status'] = encoder.fit_transform(x.Loan_Status)\n        x['ApplicantIncome'] = scaler.fit_transform(np.array(x.ApplicantIncome).reshape(-1,1))\n        x['CoapplicantIncome'] = scaler.fit_transform(np.array(x.CoapplicantIncome).reshape(-1,1))\n        return x\n        ","08ef6283":"data_pipeline = Pipeline([\n    ('Data_preprocessing',data_process())\n])\ndf = data_pipeline.transform(train)","74daebef":"df","c0cbd3f1":"corr_data = df[df.keys()]\ncolormap = plt.cm.PuBu\ncols = corr_data.corr().nlargest(len(df.keys()),'Loan_Status')['Loan_Status'].index\ncm = np.corrcoef(df[cols].values.T)\nplt.subplots(figsize=(15,10))\nheatmap = sns.heatmap(cm,square=True,annot=True,cmap=colormap,xticklabels=cols.values,yticklabels=cols.values)","69e204e1":"low_corr = ['Education','CoapplicantIncome','LoanAmount','ApplicantIncome','Loan_Amount_Term']","b619d828":"df.Loan_Status.value_counts().plot(kind='bar')\nprint(df.Loan_Status.value_counts())","2a98107f":"df","28eb01c0":"from imblearn.over_sampling import SMOTE","f93f63b6":"train_ = round(len(df)*0.8)\ntest_ = round(len(df)*0.2)\nprint(train_,test_)","e8ec2dac":"train, test = df[:train_] , df[-test_:]\nprint(train.shape,test.shape)","3fca1006":"x_train = train.drop(['Loan_Status','Loan_ID'],axis=1)\ny_train = train.Loan_Status\nprint(x_train.shape,y_train.shape)","54ae65ef":"x_test = test.drop(['Loan_Status','Loan_ID'],axis=1)\ny_test = test.Loan_Status\nprint(x_test.shape,y_test.shape)","1c15cc84":"smote = SMOTE()\nx_train_over, y_train_over = smote.fit_resample(x_train,y_train)\nprint(x_train_over.shape,y_train_over.shape)","493bfbd8":"y_train_over.value_counts().plot(kind='bar')\nprint(y_train_over.value_counts())","b97197be":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold,KFold,train_test_split\nfrom sklearn.metrics import accuracy_score,f1_score,roc_auc_score,precision_score,recall_score","468fd2d1":"skf = StratifiedKFold(n_splits=5,shuffle=True)\nkf = KFold(n_splits=5,shuffle=True)","9d9f9891":"fold = 1\nKFold_models = []\nfor train_idx,valid_idx in kf.split(x_train_over,y_train_over):\n    train_x, valid_x = x_train_over.values[train_idx], x_train_over.values[valid_idx]\n    train_y, valid_y = y_train_over.values[train_idx], y_train_over.values[valid_idx]\n    \n    model = RandomForestClassifier(n_estimators=300,max_depth=100,n_jobs=8,random_state=0)\n    model = model.fit(train_x,train_y)\n    pred = model.predict(valid_x)\n    KFold_models.append(model)\n    score = accuracy_score(pred,valid_y)\n    F1_score = f1_score(pred,valid_y)\n    roc_score = roc_auc_score(pred,valid_y)\n    precision = precision_score(pred,valid_y)\n    recall = recall_score(pred,valid_y)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))\n    fold += 1","c1c0e4a0":"RF_models = []\nfold = 1\nfor train_idx,valid_idx in skf.split(x_train_over,y_train_over):\n    train_x, valid_x = x_train_over.values[train_idx], x_train_over.values[valid_idx]\n    train_y, valid_y = y_train_over.values[train_idx], y_train_over.values[valid_idx]\n    \n    model = RandomForestClassifier(n_estimators=300,max_depth=100,n_jobs=8,random_state=0)\n    model = model.fit(train_x,train_y)\n    pred = model.predict(valid_x)\n    RF_models.append(model)\n    score = accuracy_score(pred,valid_y)\n    F1_score = f1_score(pred,valid_y)\n    roc_score = roc_auc_score(pred,valid_y)\n    precision = precision_score(pred,valid_y)\n    recall = recall_score(pred,valid_y)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))\n    fold += 1","4b3da095":"for model in KFold_models:\n    pred = model.predict(x_test)\n    score = accuracy_score(pred,y_test)\n    F1_score = f1_score(pred,y_test)\n    roc_score = roc_auc_score(pred,y_test)\n    precision = precision_score(pred,y_test)\n    recall = recall_score(pred,y_test)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))","950bc8cb":"for model in RF_models:\n    pred = model.predict(x_test)\n    score = accuracy_score(pred,y_test)\n    F1_score = f1_score(pred,y_test)\n    roc_score = roc_auc_score(pred,y_test)\n    precision = precision_score(pred,y_test)\n    recall = recall_score(pred,y_test)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))","a8f925bd":"drop_train = x_train_over.drop(low_corr,axis=1)","ddf398a2":"drop_test = x_test.drop(low_corr,axis=1)","d98923b6":"fold = 1\nDrop_model = []\nfor train_idx,valid_idx in skf.split(drop_train,y_train_over):\n    train_x, valid_x = drop_train.values[train_idx], drop_train.values[valid_idx]\n    train_y, valid_y = y_train_over.values[train_idx], y_train_over.values[valid_idx]\n    \n    model = RandomForestClassifier(n_estimators=300,max_depth=100,n_jobs=8,random_state=0)\n    model = model.fit(train_x,train_y)\n    pred = model.predict(valid_x)\n    score = accuracy_score(pred,valid_y)\n    Drop_model.append(model)\n    F1_score = f1_score(pred,valid_y)\n    roc_score = roc_auc_score(pred,valid_y)\n    precision = precision_score(pred,valid_y)\n    recall = recall_score(pred,valid_y)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))\n    fold += 1","62e2c597":"for model in Drop_model:\n    pred = model.predict(drop_test.values)\n    score = accuracy_score(pred,y_test)\n    F1_score = f1_score(pred,y_test)\n    roc_score = roc_auc_score(pred,y_test)\n    precision = precision_score(pred,y_test)\n    recall = recall_score(pred,y_test)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))","e0c30b49":"from lightgbm import LGBMClassifier\nimport warnings\nwarnings.filterwarnings(action='ignore')","27036183":"LGB_models = []\nfold = 1\nfor train_idx,valid_idx in skf.split(x_train_over,y_train_over):\n    train_x, valid_x = x_train_over.values[train_idx], x_train_over.values[valid_idx]\n    train_y, valid_y = y_train_over.values[train_idx], y_train_over.values[valid_idx]\n    print(f'Fold:{fold}')\n    model = LGBMClassifier(n_estimators=5000,max_depth=100,\n                           n_jobs=8,learning_rate=3e-3,random_state=0)\n    model = model.fit(train_x,train_y,\n                      eval_set=[(valid_x,valid_y)],\n                      eval_metric=['accuracy'],\n                     early_stopping_rounds=200,verbose=200\n    pred = model.predict(valid_x)\n    LGB_models.append(model)\n    score = accuracy_score(pred,valid_y)\n    F1_score = f1_score(pred,valid_y)\n    roc_score = roc_auc_score(pred,valid_y)\n    precision = precision_score(pred,valid_y)\n    recall = recall_score(pred,valid_y)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))\n    fold += 1","9bdb950a":"for model in LGB_models:\n    pred = model.predict(x_test.values)\n    score = accuracy_score(pred,y_test)\n    F1_score = f1_score(pred,y_test)\n    roc_score = roc_auc_score(pred,y_test)\n    precision = precision_score(pred,y_test)\n    recall = recall_score(pred,y_test)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))","502386d9":"LGB_models = []\nfold = 1\nfor train_idx,valid_idx in skf.split(drop_train,y_train_over):\n    train_x, valid_x = drop_train.values[train_idx], drop_train.values[valid_idx]\n    train_y, valid_y = y_train_over.values[train_idx], y_train_over.values[valid_idx]\n    print(f'Fold:{fold}')\n    model = LGBMClassifier(n_estimators=5000,max_depth=100,\n                           n_jobs=8,learning_rate=3e-3,random_state=0)\n    model = model.fit(train_x,train_y,\n                      eval_set=[(valid_x,valid_y)],\n                      eval_metric=['accuracy'],\n                     early_stopping_rounds=200,verbose=200)\n    pred = model.predict(valid_x)\n    LGB_models.append(model)\n    score = accuracy_score(pred,valid_y)\n    F1_score = f1_score(pred,valid_y)\n    roc_score = roc_auc_score(pred,valid_y)\n    precision = precision_score(pred,valid_y)\n    recall = recall_score(pred,valid_y)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))\n    fold += 1","0b408b5c":"for model in LGB_models:\n    pred = model.predict(drop_test.values)\n    score = accuracy_score(pred,y_test)\n    F1_score = f1_score(pred,y_test)\n    roc_score = roc_auc_score(pred,y_test)\n    precision = precision_score(pred,y_test)\n    recall = recall_score(pred,y_test)\n    print('Accuracy:{:3f} F1_score:{:.3f} ROC_AUC_score:{:.3f} Precision_score:{:.3f} Recall_score:{:.3f}'.format(\n        score,F1_score,roc_score,precision,recall))","cdc95b99":"### Apply SMOTE(oversampling)","30420f16":"# Credit Hisotry(\uc2e0\uc6a9 \uae30\ub85d(Bad))","d0284711":"#### NaN \ubd80\ubd84\uc744 \ud3c9\uade0\uc744 \ub0b4\uc5b4\uc11c \uc804\ucc98\ub9ac","6b55da60":"##### \ub370\uc774\ud130\uac00 \ubd88\uade0\ud615\ud574\uc11c \ud3c9\uade0\uc744 \ub0b4\uc5b4\uc11c NaN\uc5d0 \uc0bd\uc785\ud558\uae30\uc5d0 \uc560\ub9e4\ud55c \ubd80\ubd84\uc774 \uc788\uc5b4\uc11c feature drop","f04a3d23":"##### Scalering(\uc9c4\ud589 \uc5ec\ubd80 o) ","ab84bf67":"# Dependents","879390ab":"# LGB model","1f38be50":"# ML","63055e3d":"# Loan Amount(\ub300\ucd9c \uae08\uc561)","c97b350e":"# After Drop Low correlation feature","675bff6e":"### Target imblance check","7a957836":"# After Drop low Corr feature","a2c56766":"# self Employed(\uc790\ucde8 \uc5ec\ubd80)","6a7454e9":"# Loan_Amount_Term(\ub300\ucd9c \uae30\uac04)","b6987be0":"#### \uc0c1\uad00\uad00\uacc4 \ubd84\uc11d\uc744 \uc704\ud55c \uc804\ucc98\ub9ac(data preprocessing for corrleationship)\n##### Scalering = ApplicatnIncome, CoapplicantIncom\n##### LabelEnoder = Gender,Married ,Education, property_Area"}}