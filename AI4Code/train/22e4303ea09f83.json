{"cell_type":{"9bce4678":"code","2fd9a01e":"code","2607ef24":"code","8af4ff6f":"code","68e1cde1":"code","f810ff98":"code","7469bbff":"code","9178c2a1":"code","602db112":"code","6b7325ca":"code","d5512aed":"code","6725434e":"code","23f0489d":"code","d879f5cd":"code","9987c469":"code","fae863a4":"code","85a7fa3f":"code","44511806":"code","ec817059":"code","c701e1e5":"code","657133b2":"code","90541884":"code","d6ef0e94":"code","b105e089":"code","9fe7d91a":"code","44f76c52":"code","df2099ca":"code","455f9f0c":"code","32b85943":"code","d851b7fd":"code","23baa626":"code","83a1a5d2":"code","66bf41d5":"code","df8210cc":"code","a320e800":"code","2b608968":"code","a48817fb":"code","0ce4006a":"code","e8fa373a":"code","8d837be4":"code","9560b53a":"code","4c7f5dcd":"code","98334ca7":"code","3e54c52e":"code","23905a11":"code","4d5866ed":"code","06d879be":"code","2c99c2c5":"code","7336c9de":"markdown","5b32fe68":"markdown","77b658fb":"markdown","28f1ac38":"markdown","46dab004":"markdown","f6497e58":"markdown","10789c45":"markdown","8ab96e97":"markdown","13c50638":"markdown","4d476745":"markdown","05fea1e6":"markdown","17100e23":"markdown","104846e5":"markdown","9be2f862":"markdown","cdb80b18":"markdown","3c839823":"markdown","f38213d7":"markdown","47a303b4":"markdown","15cc5d7d":"markdown","0f8972f9":"markdown","c9cde634":"markdown","d1475d43":"markdown","7675e43b":"markdown"},"source":{"9bce4678":"import json\nimport pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport re, string\nfrom nltk.corpus import stopwords\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau \n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","2fd9a01e":"df_News = pd.read_json('..\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset_v2.json', lines=True)\ndf_News.head()","2607ef24":"df_News.info()","8af4ff6f":"# looking at some sarcastic news\ndf_News[df_News.is_sarcastic == 1].head(5)","68e1cde1":"# looking at some legitimate news\ndf_News[df_News.is_sarcastic == 0].head(5)","f810ff98":"df_News.is_sarcastic.value_counts()","7469bbff":"sns.countplot(df_News.is_sarcastic)","9178c2a1":"wordcloud = WordCloud(background_color='black',\n                    stopwords = STOPWORDS,\n                    max_words = 100,\n                    random_state = 101, \n                    width=1800, \n                    height=1000)\nwordcloud.generate(str(df_News['headline']))\nplt.imshow(wordcloud)","602db112":"df_News['headline_len'] = df_News.headline.apply(lambda x: len(x.split()))","6b7325ca":"sarcastic = df_News[df_News.is_sarcastic == 1]\nlegit = df_News[df_News.is_sarcastic == 0]","d5512aed":"plt.figure(figsize=(8,5))\nsns.distplot(sarcastic.headline_len, hist= True, label= 'Sarcastic')\nsns.distplot(legit.headline_len, hist= True, label= 'legitimate')\nplt.legend()\nplt.title('News Headline Length Distribution by Class', fontsize = 10)\nplt.show()","6725434e":"df_News = df_News.drop(columns=['article_link'])","23f0489d":"lem = WordNetLemmatizer()\nstop_words = set(stopwords.words(\"english\"))\npunctuations = string.punctuation","d879f5cd":"def clean_text(news):\n    \"\"\"\n    This function receives headlines sentence and returns clean sentence\n    \"\"\"\n    news = news.lower()\n    news = re.sub(\"\\\\n\", \"\", news)\n    #news = re.sub(\"\\W+\", \" \", news)\n    \n    #Split the sentences into words\n    words = list(news.split())\n    \n    words = [lem.lemmatize(word, \"v\") for word in words]\n    words = [w for w in words if w not in punctuations]\n    #words = [w for w in words if w not in stop_words]\n    #words = [''.join(x for x in w if x.isalpha()) for w in words]\n\n    clean_sen = \" \".join(words)\n    \n    return clean_sen","9987c469":"df_News['news_headline'] = df_News.headline.apply(lambda news: clean_text(news)) \ndf_News.head()","fae863a4":"df_News.groupby(['is_sarcastic']).headline_len.mean()","85a7fa3f":"df_News.groupby(['is_sarcastic']).headline_len.max()","44511806":"headlines = df_News['news_headline']\nlabels = df_News['is_sarcastic'] ","ec817059":"train_sentences, test_sentences, train_labels, test_labels = train_test_split(headlines, labels, test_size=0.2, stratify=labels, random_state=42)","c701e1e5":"train_labels.value_counts()","657133b2":"#Defining Hyperparameters to be used\n\nmax_words = 20000     # how many unique words to use (i.e num rows in embedding vector)\nmax_len = 60       # max number of words in a headline to use\noov_token = '<00V>'    # for the words which are not in training samples\npadding_type = 'post'   # padding type\ntrunc_type = 'post'    # truncation for headlines longer than max length\nembed_size = 64    # how big is each word vector","90541884":"tokenizer = Tokenizer(num_words=max_words, oov_token=oov_token)\ntokenizer.fit_on_texts(train_sentences)\n\nword_index = tokenizer.word_index","d6ef0e94":"train_sequences = tokenizer.texts_to_sequences(train_sentences)\ntrain_sequences = pad_sequences(train_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n\ntest_sequences = tokenizer.texts_to_sequences(test_sentences)\ntest_sequences = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)","b105e089":"train_sequences","9fe7d91a":"from tensorflow.keras.callbacks import ReduceLROnPlateau \n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_words, embed_size, input_length=max_len),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","44f76c52":"history = model.fit(train_sequences, train_labels, batch_size=32, epochs=5, \n                    validation_data=(test_sequences, test_labels), \n                    callbacks=[rlrp] ,verbose=1)","df2099ca":"score = model.evaluate(test_sequences, test_labels)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy', score[1])\n\n\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","455f9f0c":"model_rnn = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_words, embed_size, input_length=max_len),\n    tf.keras.layers.SpatialDropout1D(0.2),\n    tf.keras.layers.SimpleRNN(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\nmodel_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_rnn.summary()","32b85943":"history_rnn = model_rnn.fit(train_sequences, train_labels, batch_size=32, epochs=5, \n                    validation_data=(test_sequences, test_labels), \n                    callbacks=[rlrp] ,verbose=1)","d851b7fd":"score = model_rnn.evaluate(test_sequences, test_labels)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy', score[1])\n\n\n# list all data in history\nprint(history_rnn.history.keys())\n# summarize history for accuracy\nplt.plot(history_rnn.history['accuracy'])\nplt.plot(history_rnn.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_rnn.history['loss'])\nplt.plot(history_rnn.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","23baa626":"from tensorflow.keras.callbacks import ReduceLROnPlateau \n\nmodel_lstm = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_words, embed_size, input_length=max_len),\n    tf.keras.layers.SpatialDropout1D(0.2),\n    tf.keras.layers.LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\nmodel_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_lstm.summary()","83a1a5d2":"history_lstm = model_lstm.fit(train_sequences, train_labels, batch_size=32, epochs=5, \n                    validation_data=(test_sequences, test_labels), \n                    callbacks=[rlrp] ,verbose=1)","66bf41d5":"score = model_lstm.evaluate(test_sequences, test_labels)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy', score[1])\n\n\n# list all data in history\nprint(history_lstm.history.keys())\n# summarize history for accuracy\nplt.plot(history_lstm.history['accuracy'])\nplt.plot(history_lstm.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_lstm.history['loss'])\nplt.plot(history_lstm.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","df8210cc":"from tensorflow.keras.callbacks import ReduceLROnPlateau \n\nmodel_lstm_avg = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_words, embed_size, input_length=max_len),\n    tf.keras.layers.SpatialDropout1D(0.2),\n    tf.keras.layers.LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\nmodel_lstm_avg.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_lstm_avg.summary()","a320e800":"history_lstm_avg = model_lstm_avg.fit(train_sequences, train_labels, batch_size=32, epochs=5, \n                    validation_data=(test_sequences, test_labels), \n                    callbacks=[rlrp] ,verbose=1)","2b608968":"score = model_lstm_avg.evaluate(test_sequences, test_labels)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy', score[1])\n\n\n# list all data in history\nprint(history_lstm_avg.history.keys())\n# summarize history for accuracy\nplt.plot(history_lstm_avg.history['accuracy'])\nplt.plot(history_lstm_avg.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_lstm_avg.history['loss'])\nplt.plot(history_lstm_avg.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","a48817fb":"from tensorflow.keras.callbacks import ReduceLROnPlateau \n\nmodel_lstm1 = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_words, embed_size, input_length=max_len),\n    tf.keras.layers.SpatialDropout1D(0.2),\n    tf.keras.layers.LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\nmodel_lstm1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_lstm1.summary()","0ce4006a":"history_lstm1 = model_lstm1.fit(train_sequences, train_labels, batch_size=32, epochs=5, \n                    validation_data=(test_sequences, test_labels), \n                    callbacks=[rlrp] ,verbose=1)","e8fa373a":"score = model_lstm1.evaluate(test_sequences, test_labels)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy', score[1])\n\n\n# list all data in history\nprint(history_lstm1.history.keys())\n# summarize history for accuracy\nplt.plot(history_lstm1.history['accuracy'])\nplt.plot(history_lstm1.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_lstm1.history['loss'])\nplt.plot(history_lstm1.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","8d837be4":"from tensorflow.keras.callbacks import ReduceLROnPlateau \n\nmodel_st_lstm = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_words, embed_size, input_length=max_len),\n    tf.keras.layers.SpatialDropout1D(0.2),\n    tf.keras.layers.LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n    tf.keras.layers.LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\nmodel_st_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_st_lstm.summary()","9560b53a":"history_st_lstm = model_st_lstm.fit(train_sequences, train_labels, batch_size=32, epochs=5, \n                    validation_data=(test_sequences, test_labels), \n                    callbacks=[rlrp] ,verbose=1)","4c7f5dcd":"score = model_st_lstm.evaluate(test_sequences, test_labels)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy', score[1])\n\n\n# list all data in history\nprint(history_st_lstm.history.keys())\n# summarize history for accuracy\nplt.plot(history_st_lstm.history['accuracy'])\nplt.plot(history_st_lstm.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_st_lstm.history['loss'])\nplt.plot(history_st_lstm.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","98334ca7":"model_gru = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_words, embed_size, input_length=max_len),\n    tf.keras.layers.GRU(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\nmodel_gru.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_gru.summary()","3e54c52e":"history_gru = model_gru.fit(train_sequences, train_labels, batch_size=32, epochs=5, \n                    validation_data=(test_sequences, test_labels), \n                    callbacks=[rlrp] ,verbose=1)","23905a11":"score = model_gru.evaluate(test_sequences, test_labels)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy', score[1])\n\n\n# list all data in history\nprint(history_gru.history.keys())\n# summarize history for accuracy\nplt.plot(history_gru.history['accuracy'])\nplt.plot(history_gru.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_gru.history['loss'])\nplt.plot(history_gru.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","4d5866ed":"from tensorflow.keras.callbacks import ReduceLROnPlateau \n\nmodel_bidir = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_words, embed_size, input_length=max_len),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n    tf.keras.layers.GlobalMaxPool1D(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\nmodel_bidir.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_bidir.summary()","06d879be":"history_bidir = model_bidir.fit(train_sequences, train_labels, batch_size=32, epochs=5, \n                    validation_data=(test_sequences, test_labels), \n                    callbacks=[rlrp] ,verbose=1)","2c99c2c5":"score = model_bidir.evaluate(test_sequences, test_labels)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy', score[1])\n\n\n# list all data in history\nprint(history_bidir.history.keys())\n# summarize history for accuracy\nplt.plot(history_bidir.history['accuracy'])\nplt.plot(history_bidir.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_bidir.history['loss'])\nplt.plot(history_bidir.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","7336c9de":"### Import the libraries","5b32fe68":"### Data Cleaning & Pre-processing","77b658fb":"### Converting News Headlines into Sequences of tokens","28f1ac38":"### Stratified Split \n\nI am using Stratified split to sample approx equal number of instances for training for both the categories of our Target.","46dab004":"The dataset appears to be balanced for Sarcastic and legitimate news","f6497e58":"### Target Column Distribution","10789c45":"### 1. Neural Network with Embedding","8ab96e97":"I will be doing just some basic Pre-processing, as these are News Headlines which are written by Professionals in a formal way, so to not remove anything which can help with context, I will only remove punctuations and apply lemmatization","13c50638":"### Please Upvote the Kernel if you liked it. ","4d476745":"### Loading the Dataset","05fea1e6":"### Bidirectional LSTM","17100e23":"### Predictive Modeling\nOur aim is to build a binary Classification model which given a sequence of text, can classify it as Sarcastic or not, or Fake news or real news.\n\n### A. I will try below different models and see which works best.\n1. Neural Network with Embedding\n2. RNN(Recurrent Neural Network)\n3. LSTM(Long-short term Memory) with GlobalAveragePooling\n4. LSTM with GlobalMaxPooling\n5. Stacked LSTM\n6. Bidirectional LSTM\n7. GRU(Gated Recurrent Unit)\n8. Stacked Bidirectional LSTM\n9. Best Model from above with pre-trained Embeddings","104846e5":"### Exploratory Data Analysis","9be2f862":"On an Average most of the headlines have same length, in some cases, Sarcastic headlines are longer. ","cdb80b18":"## Abstract\n\n### Can you identify Sarcastic sentences?\n### Can you distinguish between Fake news and Legitimate news?\n\nSince news headlines are written by professionals in a formal manner, there are no spelling mistakes and informal usage. This reduces the sparsity and also increases the chance of finding pre-trained embeddings.\n\nFurthermore, since the sole purpose of TheOnion is to publish sarcastic news, we get high-quality labels with much less noise as compared to Twitter datasets.\n\n### Dataset\n\nEach record consists of three attributes:\n\nis_sarcastic: 1 if the record is sarcastic otherwise 0\n\nheadline: the headline of the news article\n\narticle_link: link to the original news article. Useful in collecting supplementary data\n\n### Deep Learning Framework\nI will be using Tensorflow to implement the Deep Learning Models for this Project.","3c839823":"### Conclusion\n\nThe best model is using LSTM and Bidirectional along with GlobalMaxPooling and Spatial Dropout. \n\nBest test Accuracy - 85.55 %\n","f38213d7":"### 2. RNN (Recurrent Neural Network)","47a303b4":"### 3. LSTM (Long Short Term Memory) with GlobalMaxPooling & SpatialDropout","15cc5d7d":"### Stacked LSTM","0f8972f9":"### 7. GRU (Gated Recurrent Unit","c9cde634":"### 4. LSTM with GlobalAveragePool","d1475d43":"### 5. LSTM with only one FC Dense Layer","7675e43b":"### News Headline length Distribution"}}