{"cell_type":{"10d91e40":"code","69a8960e":"code","7f643605":"code","b5edf79f":"code","51b6d47b":"code","67df5081":"code","840a1225":"code","a2d81885":"code","7ec76861":"code","40894893":"code","385ceee2":"code","d5411baa":"code","9679664c":"code","49dfa05b":"code","cf470c69":"code","f36985d6":"code","fd5d440c":"code","a455a7eb":"markdown"},"source":{"10d91e40":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","69a8960e":"# loading the dataset\ndf=pd.read_csv('\/kaggle\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv')","7f643605":"df.head()","b5edf79f":"df.shape","51b6d47b":"df.isnull().sum()","67df5081":"df.dtypes","840a1225":"# lets rename the last column which is our target column\ndf['target']= df['default.payment.next.month']","a2d81885":"# selecting dependent and independent variable\nX=df.drop(['ID','default.payment.next.month'],axis=1)\ny=df['default.payment.next.month']","7ec76861":"X[0:5]","40894893":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=1)","385ceee2":"from sklearn.ensemble import RandomForestClassifier\nrfc_model=RandomForestClassifier()\nrfc_model.fit(X_train,y_train)\ny_pred_rfc=rfc_model.predict(X_test)","d5411baa":"from sklearn.metrics import accuracy_score,confusion_matrix\nrfc_score=accuracy_score(y_test,y_pred_rfc)\nrfc_score","9679664c":"from sklearn.tree import DecisionTreeClassifier\ndt_model=DecisionTreeClassifier()\ndt_model.fit(X_train,y_train)\ny_pred_dt=dt_model.predict(X_test)\ndt_score=accuracy_score(y_test,y_pred_dt)\ndt_score","49dfa05b":"from sklearn.svm import SVC\nsvm_model=SVC()\nsvm_model.fit(X_train,y_train)\ny_pred_svm=svm_model.predict(X_test)\nsvm_score=accuracy_score(y_test,y_pred_svm)\nsvm_score","cf470c69":"models=['Random Forest','Decision Tree','SVM']\nscores=[rfc_score,dt_score,svm_score]","f36985d6":"# making a dictionary of all models and scores\nmodel_scores= {'models':models,'scores':scores}\nmodel_scores","fd5d440c":"# converting the dictionary into a dataframe\nscore_df=pd.DataFrame(model_scores)\nscore_df","a455a7eb":"All the columns are integers type, so we don't need to do any label encoding "}}