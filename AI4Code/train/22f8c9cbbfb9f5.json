{"cell_type":{"cf8eaaf0":"code","e59b28e5":"code","e5e6fd4e":"code","361fbaf8":"code","b325cc2d":"code","0c900164":"code","a59937aa":"code","eda62b61":"code","099dab5f":"code","1e90bccb":"code","974052dd":"code","c6db23db":"code","15b50283":"code","d1de732d":"code","718e67f0":"code","99e22478":"code","9d6a367a":"code","c6bd7872":"code","796a9ffe":"code","cee3f6b1":"code","af440475":"code","a2d86692":"code","3885d4fc":"markdown","a393f40f":"markdown","d3935f28":"markdown","2952a21b":"markdown","da650f6f":"markdown"},"source":{"cf8eaaf0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# importing all packages\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n! pip install imutils\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nimport cv2\nfrom keras.optimizers import SGD\n\n","e59b28e5":"# derive the paths to the training, validation, and testing\n# directories\n\ntrainPath = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\"\ntestPath = \"\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\"\nvalPath = \"\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred\"\n\n\n# determine the total number of image paths in training, validation,\n# and testing directories\ntotalTrain = len(list(paths.list_images(trainPath)))\ntotalTest = len(list(paths.list_images(testPath)))\ntotalVal = len(list(paths.list_images(valPath)))\n\n\n# determine the name of classes\nclass_name = os.listdir(trainPath)\n\nprint(f\"Total Training images:{totalTrain}\")\nprint(f\"Total Testing images:{totalTest}\")\nprint(f\"Total validation images:{totalVal}\")\nprint(f\"Name of classes:{class_name}\")\nprint(f\"Number of classes:{len(class_name)}\")\n\n\n","e5e6fd4e":"# Generator for our training data \ntrain_image_generator = ImageDataGenerator(rotation_range=30,fill_mode='nearest') \n\n# Generator for our Testing data\ntest_image_generator = ImageDataGenerator()\n","361fbaf8":"# Loading training data\n# class_mode='categorical' because we are having categories more than 2\n\ntrain_data_gen = train_image_generator.flow_from_directory(batch_size=32,\n                                                           directory=trainPath,\n                                                           shuffle=True,\n                                                           target_size=(150,150),\n                                                           class_mode='categorical')","b325cc2d":"# Loading testing data\ntest_data_gen = test_image_generator.flow_from_directory(batch_size=32,\n                                                              directory=testPath,\n                                                              shuffle=True,\n                                                              target_size=(150,150),\n                                                              class_mode='categorical')        \n","0c900164":"# Display sample images per category\n\n# dict_imgs: key with category and values with paths to the images\ndict_imgs = dict()\ndict_labels = dict()\nnum_cat = len(os.listdir(trainPath))\nnum_col = int(num_cat\/3)\nnum_row = int(np.ceil(num_cat\/num_col))\ni = 0\nplt.subplots(num_col,num_row)\n\nfor category in os.listdir(trainPath):\n    train_imgs = glob('{}\/{}\/*jpg'.format(trainPath, category))\n    dict_imgs[category] = train_imgs    \n    # sample image\n    plt.subplot(num_col,num_row,i+1)\n    img = cv2.imread(train_imgs[0])\n    plt.imshow(img)\n    plt.xlabel('{}:{}'.format(i, category))\n    dict_labels[i] = category\n    i += 1\nplt.tight_layout()\nplt.show() ","a59937aa":"# build the basic model from scracth\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(len(class_name), activation='softmax')\n])","eda62b61":"# compile the model\n# by using SGD as optimizer \nopt = SGD(lr=1e-4, momentum=0.9)\nmodel.compile(optimizer=opt,\n              loss=\"categorical_crossentropy\",\n              metrics=['accuracy'])","099dab5f":"# fitting the model\nEPOCHS =50\nhistory = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=int(np.ceil(totalTrain \/ float(100))),\n    epochs=EPOCHS,\n    validation_data=test_data_gen,\n    validation_steps=int(np.ceil(totalTest \/ float(100)))\n)","1e90bccb":"# determine the loss and accuracy\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","974052dd":"# plotting the graph of accuracy and training\nepochs_range = range(EPOCHS)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","c6db23db":"# With the help of transfer learning\nfrom keras.layers import Input, Lambda, Dense, Flatten,Dropout\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import SGD","15b50283":"# add preprocessing layer to the front of VGG\nbaseModel = VGG16(input_shape=(150,150,3), weights='imagenet', include_top=False)\n\n\n","d1de732d":"# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(512, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(len(class_name), activation=\"softmax\")(headModel)\n\n# create a model object\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# don't train existing weights\nfor layer in baseModel.layers:\n  layer.trainable = False\n  \n# view the structure of the model\nmodel.summary()\n\n","718e67f0":"# compile our model (this needs to be done after our setting our\n# layers to being non-trainable\nprint(\"[INFO] compiling model...\")\nopt = SGD(lr=1e-4, momentum=0.9)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])\n\nprint(\"[INFO] training head...\")\nH = model.fit_generator(\n\ttrain_data_gen,\n\tsteps_per_epoch=100,\n\tvalidation_data=test_data_gen,\n\tvalidation_steps=100,\n\tepochs=50)\n\n","99e22478":"# loss\nplt.plot(H.history['loss'], label='train loss')\nplt.plot(H.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n\n# accuracies\nplt.plot(H.history['accuracy'], label='train acc')\nplt.plot(H.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\n","9d6a367a":"# saving model in local directory\nmodel.save('.\/transfer_learning.h5')\n","c6bd7872":"# add preprocessing layer to the front of VGG\nbaseModel1 = VGG16(input_shape=(150,150,3), weights='imagenet', include_top=False)\n\n# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(baseModel1.layers))\n\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in baseModel1.layers[:15]:\n  layer.trainable = False\n\nfor layer in baseModel1.layers:\n    print(\"{}: {}\".format(layer, layer.trainable))","796a9ffe":"# create a model object\nheadModel = baseModel1.output\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(512, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(len(class_name), activation=\"softmax\")(headModel)\n\nmodel = Model(inputs=baseModel1.input, outputs=headModel)\n\n# view the structure of the model\nmodel.summary()","cee3f6b1":"# recompile our model (this needs to be done after our setting our\n# layers to being non-trainable\nprint(\"[INFO] compiling model...\")\nopt = SGD(lr=1e-4, momentum=0.9)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n\nprint(\"[INFO] training head...\")\nH = model.fit_generator(\n\ttrain_data_gen,\n\tsteps_per_epoch=100,\n\tvalidation_data=test_data_gen,\n\tvalidation_steps=100,\n\tepochs=50)","af440475":"# saving model in local directory\nmodel.save('.\/fine_tuning.h5')\n# loss\nplt.plot(H.history['loss'], label='train loss')\nplt.plot(H.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n\n# accuracies\nplt.plot(H.history['accuracy'], label='train acc')\nplt.plot(H.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\n","a2d86692":"\n# loading model and inferening on single image\nfrom keras.models import load_model\nimport numpy as np\nimport argparse\nimport imutils\nimport cv2\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n# load the trained model from disk\nprint(\"[INFO] loading model...\")\nmodel = load_model(\".\/transfer_learning.h5\")\n\n# pass the image through the network to obtain our predictions\n\nimage = cv2.imread(\"\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred\/10048.jpg\")\noutput = image.copy()\noutput = imutils.resize(output, width=400)\n\n\n# our model was trained on RGB ordered images but OpenCV represents\n# images in BGR order, so swap the channels, and then resize to\n# 150x150 (the input dimensions for VGG16)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage = cv2.resize(image, (150, 150))\n\n# plot the image\nplt.imshow(image)\n\n# convert the image to a floating point data type and perform mean\n# image = image.astype(\"float32\")\n\nCLASSES = ['buildings', 'forest', 'glacier' , 'mountain', 'sea', 'street' ]\n\npreds = model.predict(np.expand_dims(image, axis=0))[0]\n# print(preds)\ni = np.argmax(preds)\nlabel = CLASSES[i]\n# draw the prediction on the output image\ntext = \"{}: {:.2f}%\".format(label, preds[i] * 100)\nprint(text)\n\n","3885d4fc":"<h4>Observation:<\/h4>\n1.The validation loss is not diverge properly<br>\n2.Accuracy is quiet low\n\n# 2. Transfer-learning :\nHere using VGG16 as a base model and imagenet weights upon that going to train new model for 6 categories<br>\nThe base model layers will be same.\n","a393f40f":"# 1. From Scratch Training","d3935f28":"<h4>Observation:<\/h4>\n1.Accuracy improve than the scratch training.<br>\nAccuracy:88%\n\n\n# 3. Fine Tuning\nUsing same base model as VGG16 <br>\nOur base model have total 19 layers, so will retrain from the 15th layer onwards","2952a21b":"# Conclusion\n1. we are getting highest accuracy by fine tuning the base model.<br>\nAccuracy: 91%","da650f6f":"# Loading  the saved model and infernce on the images"}}