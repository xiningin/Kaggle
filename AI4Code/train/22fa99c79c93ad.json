{"cell_type":{"f1b50e8f":"code","d54c88d5":"code","11cdd832":"code","3ccd6791":"code","9f03da25":"code","00c8f8c6":"code","475c4d81":"code","62d33bae":"code","e1f371ec":"code","e1181186":"code","f2317c24":"code","e46978b8":"code","b2faf1b0":"code","dc3c59a0":"code","d7d2e82f":"code","010dfa0d":"code","57bf64b1":"code","118d9bdd":"code","bd312469":"code","3c6ef437":"code","50682254":"code","74e171d3":"code","fc0b1342":"code","d151c6a3":"code","8eb1a3dc":"code","e2ef21e0":"code","89a7fefb":"code","6e7d1b2f":"code","377d8571":"code","07dbdc8e":"code","1d3fbf93":"code","c8d791a5":"code","0d731070":"code","7aa2d6e5":"code","b3269b51":"code","4641c0b2":"code","d460082a":"code","03784785":"code","6a6bb442":"code","2077fcac":"code","ea7239b3":"code","8bb3a7e6":"code","ac827bbe":"code","e49ca319":"code","54d8ab07":"code","826b700e":"code","ffa9c1aa":"code","5767e2e6":"code","417561a9":"code","c3a42847":"code","742d59bd":"code","1f2f721c":"code","9a641c6a":"code","a9678140":"code","59a7ff6f":"code","3ea556eb":"code","5aa1e8d4":"code","c487fb75":"code","8343dbf4":"code","3e0dd98c":"code","168255c7":"code","36161f7a":"code","9d62a169":"code","c033d391":"code","35a1feb1":"code","67558fe9":"code","e30dbd89":"code","4024bb21":"code","1269c336":"code","a76e852d":"code","3ae7b2a4":"code","84083406":"code","98e24b20":"code","aeb929df":"code","2ad044ab":"code","4b5111f3":"code","3e583d0e":"code","c6db181a":"code","33520fce":"code","d7e5645a":"code","041f599b":"code","d20aa50c":"code","939eca7d":"code","5cefbc3d":"code","17bee666":"code","7cf8f748":"code","efb5b259":"code","68ff8490":"code","d943d399":"code","29ef36d2":"code","e39c7e60":"code","39e2d8ff":"code","c2a70891":"markdown","ed3a3fa1":"markdown","db621839":"markdown","57174d98":"markdown","23827da7":"markdown","016a0c04":"markdown","22242e5a":"markdown","fe4204ca":"markdown","0e3e5257":"markdown","6a9f53a1":"markdown","add919c1":"markdown","f4052849":"markdown","6e25c2a3":"markdown","06b5f61d":"markdown","9fa9296e":"markdown","32e62920":"markdown","c60bec61":"markdown","9a7b1542":"markdown","817e84d8":"markdown","d920c9de":"markdown","61996a35":"markdown","13308da9":"markdown","45e8811a":"markdown","2b9eb7fe":"markdown","71e68fe6":"markdown","9fcf8335":"markdown","ef3f3b28":"markdown","ff659193":"markdown","d0f02309":"markdown","0b3c9d08":"markdown","0ad112ea":"markdown","fee35ae5":"markdown","a4204d26":"markdown","51277f6f":"markdown","b8b33878":"markdown","5f34551d":"markdown","bd89b28b":"markdown","23ef0b7c":"markdown","95865081":"markdown","af086272":"markdown","eec09339":"markdown","bf4d7258":"markdown","7733ad16":"markdown","31fc6c47":"markdown","bfd33e03":"markdown","82e5e1a6":"markdown","0f2f3b6d":"markdown","ee5edb05":"markdown","5b91a22a":"markdown","ae0e0e58":"markdown","06b2651c":"markdown","9855bc1a":"markdown","e637fe1a":"markdown","c4fb3b37":"markdown","c3045386":"markdown","f2289e8b":"markdown","999ef226":"markdown","3502602a":"markdown","7352163b":"markdown","63b8b246":"markdown","b8704f07":"markdown","6dd7d206":"markdown","8ba54cd6":"markdown","b6f3e4e9":"markdown","fa1076b3":"markdown","532ab555":"markdown","c16bd36c":"markdown","59423551":"markdown","b8ef5cde":"markdown","b09d3036":"markdown"},"source":{"f1b50e8f":"import pandas as pd","d54c88d5":"import numpy as np","11cdd832":"import seaborn as sns","3ccd6791":"import matplotlib.pyplot as plt","9f03da25":"import torch","00c8f8c6":"import torchvision","475c4d81":"from torch.autograd import Variable","62d33bae":"from torch.utils.data import Dataset","e1f371ec":"from torchvision.transforms import ToTensor","e1181186":"from torchvision import datasets","f2317c24":"from torch.utils.data import DataLoader","e46978b8":"import os","b2faf1b0":"from torch import optim","dc3c59a0":"array = [[4,7,9],[11,2,3]]","d7d2e82f":"type(array)","010dfa0d":"a = np.array(array)","57bf64b1":"a","118d9bdd":"a.shape","bd312469":"type(a)","3c6ef437":"l = [[11, 32, 43], [44, 51, 96]]","50682254":"tns = torch.tensor(l)","74e171d3":"tns","fc0b1342":"type(tns)","d151c6a3":"tns.shape","8eb1a3dc":"tns.size()","e2ef21e0":"# We can also initialize with scalars\ntorch.tensor(6)","89a7fefb":"torch.ones(2, 3)","6e7d1b2f":"torch.ones(5)","377d8571":"torch.zeros(2, 3)","07dbdc8e":"torch.zeros(6)","1d3fbf93":"torch.rand(2,3)","c8d791a5":"torch.rand(7)","0d731070":"a = np.array([6,7,9])","7aa2d6e5":"t = torch.from_numpy(a)","b3269b51":"t","4641c0b2":"type(t)","d460082a":"a = torch.ones(12)","03784785":"b = a.numpy()","6a6bb442":"b","2077fcac":"type(b)","ea7239b3":"x = torch.tensor([1, 2, 3])\ny = torch.tensor([4, 5, 6])","8bb3a7e6":"print(x)\nprint(y)","ac827bbe":"print(\"Addition:\", x+y)\nprint(\"Subtraction:\", x-y)\nprint(\"Multipication:\", x*y)\nprint(\"Division:\", x\/y)","e49ca319":"print(\"Addition:\",torch.add(x,y))\nprint(\"Subtraction:\", torch.sub(x,y))\nprint(\"Multipication:\", torch.mul(x,y))\nprint(\"Division:\", torch.div(x,y))","54d8ab07":"tns = torch.tensor([[2,5,7,9],[91,21,34,56]])","826b700e":"tns","ffa9c1aa":"tns.t()","5767e2e6":"tns = torch.Tensor([91,21,34,56])","417561a9":"tns","c3a42847":"tns.mean()","742d59bd":"tns.median()","1f2f721c":"tns.mode()","9a641c6a":"tns.std()","a9678140":"t = torch.rand(8, 4)","59a7ff6f":"t","3ea556eb":"t.view(2,16)","5aa1e8d4":"x = torch.randn(2, 3)\ny = torch.randn(2, 3)","c487fb75":"x","8343dbf4":"y","3e0dd98c":"torch.cat((x,y))","168255c7":"torch.cat((x,y),dim=1)","36161f7a":"x = torch.ones(3,1,3,1,3)","9d62a169":"x","c033d391":"x.shape","35a1feb1":"y = torch.squeeze(x)","67558fe9":"y","e30dbd89":"y.shape","4024bb21":"x= Variable(torch.ones(5), requires_grad = True)\nx","1269c336":"type(x)","a76e852d":"x = Variable(torch.Tensor([6,12]), requires_grad = True)","3ae7b2a4":"x","84083406":"x[0]**3","98e24b20":"x[1]**3","aeb929df":"y = x**3\n\no = (1\/2)*sum(y)","2ad044ab":"o","4b5111f3":"o.backward() # calculates gradients\n\nprint(\"gradients: \",x.grad)","3e583d0e":"training_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor()\n)","c6db181a":"test_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor())","33520fce":"training_data","d7e5645a":"test_data","041f599b":"labels_map = {\n    0: \"T-Shirt\",\n    1: \"Trouser\",\n    2: \"Pullover\",\n    3: \"Dress\",\n    4: \"Coat\",\n    5: \"Sandal\",\n    6: \"Shirt\",\n    7: \"Sneaker\",\n    8: \"Bag\",\n    9: \"Ankle Boot\",\n}","d20aa50c":"figure = plt.figure(figsize=(10, 10))\ncols, rows = 4, 4\n\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n    img, label = training_data[sample_idx]\n    figure.add_subplot(rows, cols, i)\n    plt.title(labels_map[label])\n    plt.axis(\"off\")\n    plt.imshow(img.squeeze(), cmap=\"gray\")\nplt.show()","939eca7d":"class CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label","5cefbc3d":"train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)","17bee666":"train_features, train_labels = next(iter(train_dataloader))\nprint(f\"Feature batch shape: {train_features.size()}\")\nprint(f\"Labels batch shape: {train_labels.size()}\")","7cf8f748":"img = train_features[0].squeeze()\nlabel = train_labels[0]\nplt.imshow(img, cmap=\"gray\")\nplt.show()\nprint(f\"Label: {label}\")","efb5b259":"batch_size, input_dimension, hidden_dimension, output_dimension = 128, 1500, 150, 20","68ff8490":"# Create random Tensors to hold inputs and outputs\nx = torch.randn(batch_size, input_dimension)\ny = torch.randn(batch_size, output_dimension)","d943d399":"# Use the nn package to define our model and loss function.\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(input_dimension, hidden_dimension),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(hidden_dimension, output_dimension),\n)","29ef36d2":"loss_fn = torch.nn.MSELoss(reduction='sum')","e39c7e60":"# Use the optim package to define an Optimizer that will update the weights of the model for us. \n# Here we will use SGD. The first argument to the SGD constructor tells the optimizer which Tensors it should update.\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4)","39e2d8ff":"for t in range(500):\n    # Forward pass: compute predicted y by passing x to the model.\n    y_pred = model(x)\n\n    # Compute and print loss.\n    loss = loss_fn(y_pred, y)\n    if t % 100 == 99:\n        print(t, loss.item())\n\n    # Before the backward pass, use the optimizer object to zero all of the gradients for the variables \n    # it will update (which are the learnable weights of the model). This is because by default, gradients are\n    # accumulated in buffers( i.e, not overwritten) whenever .backward() is called. \n    optimizer.zero_grad()\n\n    # Backward pass: compute gradient of the loss with respect to model parameters\n    loss.backward()\n\n    # Calling the step function on an Optimizer makes an update to its parameters\n    optimizer.step()","c2a70891":"We can index Datasets manually like a list: *training_data[index]*. We use matplotlib to visualize some samples in our training data.","ed3a3fa1":"optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)","db621839":"If we want to concat vertically, we need to use additional brackets.","57174d98":"NN Module defines a set of functions, similar to the layers of a neural network, which takes the input from the previous state and produces an output.","23827da7":"In order to get a tensor filled with random numbers from a uniform distribution on the interval [0, 1), we can use **torch.rand()**.","016a0c04":"**Creating a Custom Dataset** \n \n A custom Dataset class must implement three functions: __init__, __len__, and __getitem__. Take a look at this implementation; the FashionMNIST images are stored in a directory img_dir, and their labels are stored separately in a CSV file annotations_file.","22242e5a":"After calculation, we find that y = [216,1728] (y = x^3.).","fe4204ca":"In order to get mean of a tensor, we can use **mean()**.","0e3e5257":"**SGD Optimizer**","6a9f53a1":" Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.**torch.cat()** can be used to cancatinate different tensors.","add919c1":"Let's make an example with Optim.","f4052849":"![image.png](attachment:image.png)\n\n                                            This image is taken by Dev Community.","6e25c2a3":"We can concatenate the tensors horizontally as well by setting the *dim* parameter to 1.","06b5f61d":"We can get transpoze of a matrix with **t()**.","9fa9296e":"Difference between variables and tensors is variable accumulates gradients. In order to make back prob, we need variables.\n\nWe can make math operations with variables too.","32e62920":"**Preparing Our data for training with DataLoaders**\n\nThe Dataset retrieves our dataset\u2019s features and labels one sample at a time. While training a model, we typically want to pass samples in \u201cminibatches\u201d, reshuffle the data at every epoch to reduce model overfitting, and use Python\u2019s multiprocessing to speed up data retrieval.\n\nDataLoader is an iterable that abstracts this complexity for us in an easy API.","c60bec61":"PyTorch allows a tensor to be a **View** of an existing tensor. View tensor shares the same underlying data with its base tensor. Supporting View avoids explicit data copy, thus allows us to do fast and memory efficient reshaping, slicing and element-wise operations.**view()** can be used for that.","9a7b1542":"![image.png](attachment:image.png)","817e84d8":"## What is Pytorch?","d920c9de":"In order to get standart deviation of a tensor, we can use **std()**.","61996a35":"The Optim module in PyTorch has pre-written codes for most of the optimizers that are used while building a neural network. We just have to import them and then they can be used to build models.","13308da9":" We have loaded that dataset into the Dataloader and can iterate through the dataset as needed. Each iteration below returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively). Because we specified shuffle=True, after we iterate over all batches the data is shuffled.","45e8811a":"In Pytorch, matrices(arrays) are called as **Tensors**. Tensors are multidimensional arrays. These tensors can be used on a GPU as well (this is not the case with NumPy arrays). This is a major advantage of using tensors.\n\nPyTorch supports multiple types of tensors, including:\n\n- FloatTensor: 32-bit float\n \n- DoubleTensor: 64-bit float\n \n- HalfTensor: 16-bit float\n \n- IntTensor: 32-bit int\n \n- LongTensor: 64-bit int","2b9eb7fe":"Let's make an example. \n\nAssume we have an equation y = x^3 and we define x = [6,12] variable.","71e68fe6":"### NN(Neural Network) Module","9fcf8335":"We can also use their own functions.","ef3f3b28":"### Optim Module","ff659193":"## Extra - Useful Resources","d0f02309":"- __init__(): The __init__ function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms\n\n- __len__(): The __len__ function returns the number of samples in our dataset.\n\n- __getitem__(): The __getitem__ function loads and returns a sample from the dataset at the given index idx. Based on the index, it identifies the image\u2019s location on disk, converts that to a tensor using read_image, retrieves the corresponding label from the csv data in self.img_labels, calls the transform functions on them (if applicable), and returns the tensor image and corresponding label in a tuple.","0b3c9d08":" Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives: **torch.utils.data.DataLoader** and **torch.utils.data.Dataset** that allow us to use pre-loaded datasets as well as our own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.","0ad112ea":"## Math Operations","fee35ae5":"In order to get tensor filled with the scalar value 0, we can use **torch.zeros()**.","a4204d26":" *Numpy* provides an n-dimensional array object, and many functions for manipulating these arrays. Numpy is a generic framework for scientific computing; it does not know anything about computation graphs, or deep learning, or gradients. Let's look at the classical numpy array:","51277f6f":"Addition, subtraction, multiplication and division are common operations that we do while working with tensors. They are so similar to numpy and intuitive.","b8b33878":"**Concatinating**","5f34551d":"## Common Modules: Optim - nn","bd89b28b":"**Loading a Dataset**\n\nHere is an example of how to load the Fashion-MNIST dataset from TorchVision. Fashion-MNIST is a dataset of Zalando\u2019s article images consisting of of 60,000 training examples and 10,000 test examples. Each example comprises a 28\u00d728 grayscale image and an associated label from one of 10 classes.\n\nWe load the FashionMNIST Dataset with the following parameters:\n\n- root is the path where the train\/test data is stored,\n\n- train specifies training or test dataset,\n\n- download=True downloads the data from the internet if it\u2019s not available at root.\n\n- transform and target_transform specify the feature and label transformations","23ef0b7c":"**Resources**\n\n- [Pytorch Wikipedia](https:\/\/en.wikipedia.org\/wiki\/PyTorch)\n- [Pytorch Official Tutorial Page](https:\/\/pytorch.org\/tutorials\/beginner\/basics\/intro.html)\n- [A Beginner-Friendly Guide to PyTorch and How it Works from Scratch by Analytics Vidhya](https:\/\/www.analyticsvidhya.com\/blog\/2019\/09\/introduction-to-pytorch-from-scratch\/)\n- [PyTorch Tutorial: How to Develop Deep Learning Models with Python by Machine Learning Mastery](https:\/\/machinelearningmastery.com\/pytorch-tutorial-develop-deep-learning-models\/)\n- [PyTorch - Variables, functionals and Autograd](https:\/\/jhui.github.io\/2018\/02\/09\/PyTorch-Variables-functionals-and-Autograd\/)\n- [A Gentle Introduction To Torch.Autograd](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/autograd_tutorial.html)","95865081":" PyTorch domain libraries provide a number of pre-loaded datasets (such as MNIST) that subclass torch.utils.data.Dataset and implement functions specific to the particular data. They can be used to prototype and benchmark our model. We can find them here: [Image Datasets](https:\/\/pytorch.org\/vision\/stable\/datasets.html), [Text Datasets](https:\/\/pytorch.org\/text\/stable\/datasets.html) and [Audio Datasets](https:\/\/pytorch.org\/tutorials\/beginner\/basics\/data_tutorial.html)","af086272":"We can define a variable with **variable()**.","eec09339":"## Common Funtions","bf4d7258":"## Importing Libraries","7733ad16":"## Content\n\n- What is Pytorch?\n- Importing Libraries\n- Basics of Pytorch\n- Tensors\n- Math Operations\n- Common Funtions\n- Variables - Autograd\n- Datasets & DataLoaders\n- Common Modules: Optim - nn\n- Extra - Useful Resources\n\n**Soon**\n\n- Linear Regression with Pytorch\n- Logistic Regression with Pytorch\n- Artificial Neural Networks(ANN) with Pytorch\n- Recurrent Neural Networks(RNN) with Pytorch\n- Long Short Term Memory(LSTM) with Pytorch","31fc6c47":"Converting a torch Tensor to a numpy array and vice versa is a breeze. We can use **numpy()** for that.","bfd33e03":"Pytorch is an open source machine learning framework that accelerates the path from research prototyping to production deployment.\n\nIt is used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR).It is free and open-source software released under the Modified BSD license. Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.\n\nA number of pieces of deep learning software are built on top of PyTorch, including Tesla Autopilot, Uber's Pyro, HuggingFace's Transformers, PyTorch Lightning,and Catalyst.\n\n**PyTorch provides two high-level features**:\n\n- Tensor computing (like NumPy) with strong acceleration via graphics processing units (GPU)\n\n- Deep neural networks built on a type-based automatic differentiation system\n\nOfficial Website: https:\/\/pytorch.org\/","82e5e1a6":"**Reshaping**","0f2f3b6d":"Specifying requires_grad as True will make sure that the gradients are stored for this particular tensor whenever we perform some operation on it. ","ee5edb05":"When training neural networks, the most frequently used algorithm is back propagation. In this algorithm, parameters (model weights) are adjusted according to the gradient of the loss function with respect to the given parameter. **torch.autograd** is PyTorch\u2019s automatic differentiation engine that powers neural network training. ","5b91a22a":"## Variables - Autograd","ae0e0e58":"In order to get mode of a tensor, we can use **mode()**.","06b2651c":"Let's create a tensor.","9855bc1a":"In order to create a Tensor from a numpy.ndarray we can use **torch.from_numpy**.","e637fe1a":"It returns a tensor with all the dimensions of input of size 1 removed.\n\nFor example, if input is of shape: (A x 1 x B x C x 1 x D) then the out tensor will be of shape: (A x B x C x D)\n\nWhen dim is given, a squeeze operation is done only in the given dimension. If input is of shape: (A\u00d71\u00d7B) , squeeze(input, 0) leaves the tensor unchanged, but squeeze(input, 1) will squeeze the tensor to the shape (A\u00d7B) .\n\n**Note:** The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contents of the other.\n\nIn order to do that, we will use **squeeze()**.","c4fb3b37":"Recap o equation is that o = (1\/2)sum(y) = (1\/2)sum(x^3) and deriavative of o = 3x2.","c3045386":"- [Scalars, Vectors, Matrices and Tensors with Tensorflow 2.0](https:\/\/dev.to\/mmithrakumar\/scalars-vectors-matrices-and-tensors-with-tensorflow-2-0-1f66)\n\n- [Introduction to PyTorch for Deep Learning](https:\/\/www.kdnuggets.com\/2018\/11\/introduction-pytorch-deep-learning.html)\n\n- [Common Torch Functions](https:\/\/pytorch.org\/docs\/stable\/torch.html)\n\n- [Introduction to Pytorch (a very gentle start)](https:\/\/www.kaggle.com\/frtgnn\/introduction-to-pytorch-a-very-gentle-start)\n\n- [Neural Networks from Statquest](https:\/\/www.youtube.com\/watch?v=CqOfi41LfDw&ab_channel=StatQuestwithJoshStarmerStatQuestwithJoshStarmerDo%C4%9Fruland%C4%B1)\n\n- [Fast AI Pytorch Tutorial](https:\/\/docs.fast.ai\/)\n\n- [Intro to Deep Learning with Pytorch by Udacity](https:\/\/www.udacity.com\/course\/deep-learning-pytorch--ud188?cjevent=becd1b75759d11ea83f301a10a24060d)","f2289e8b":"So gradients are [54,216].","999ef226":"**Squeezing**","3502602a":"**Created by Berkay Alan**\n\n**Deep Learning with Pytorch - A complete Tutorial**\n\n**2 June 2021**\n\n**For more Tutorial:** https:\/\/github.com\/berkayalan","7352163b":"optimizer = optim.Adam([var1, var2], lr=0.0001)","63b8b246":"## Datasets & DataLoaders","b8704f07":"**Background**\n\nNeural networks (NNs) are a collection of nested functions that are executed on some input data. These functions are defined by parameters (consisting of weights and biases), which in PyTorch are stored in tensors.\n\nTraining a NN happens in two steps:\n\n*Forward Propagation*: In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.\n\n*Backward Propagation*: In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (gradients), and optimizing the parameters using gradient descent. \n\nFor a more detailed walkthrough of backprop, check out [this video](https:\/\/www.youtube.com\/watch?v=IN2XmBhILt4&ab_channel=StatQuestwithJoshStarmer) from Statquest.","6dd7d206":"In order to get median of a tensor, we can use **median()**.","8ba54cd6":"In order to get a tensor filled with the scalar value 1, we can use **torch.ones()**.","b6f3e4e9":"## Tensors","fa1076b3":"Above are the examples to get the ADAM and SGD optimizers. Most of the commonly used optimizers are supported in PyTorch and hence we do not have to write them from scratch. Some of them are:\n\n- SGD\n\n- Adam\n\n- Adadelta\n\n- Adagrad\n\n- AdamW\n\n- SparseAdam\n\n- Adamax\n\n- ASGD (Averaged Stochastic Gradient Descent)\n\n- RMSprop\n\n- Rprop (resilient backpropagation)","532ab555":"**Adam Optimizer**","c16bd36c":"We can also get statistical information from tensors.","59423551":"![image.png](attachment:image.png)\n\n                                            This image is taken by KDNuggets.","b8ef5cde":"To construct an Optimizer we have to give it an iterable containing the parameters (all should be Variable s) to optimize. Then, we can specify optimizer-specific options such as the learning rate, weight decay, etc.","b09d3036":"Tensors can be created from Python lists with the **torch.tensor()** function."}}