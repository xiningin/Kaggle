{"cell_type":{"a072a8b2":"code","db91ada7":"code","17d01182":"code","f98a7f0b":"code","c70dac1f":"code","36557c6a":"code","01b72233":"code","a331d4b1":"code","adf5da85":"code","51462672":"code","56da5a43":"code","7d30856c":"code","7b87f114":"code","7f50fed2":"code","b912e61a":"code","d407a119":"code","39ebd20f":"code","760fd210":"code","3e60c91c":"code","ae84af2c":"code","ff5fa56a":"code","89a5ddcb":"code","ee41a07e":"code","73ad7844":"code","2e01a28c":"code","86771d49":"code","4dcd7b94":"code","7a576e9d":"code","6a1a8584":"code","c4858adf":"markdown","f775bdcc":"markdown","83cee936":"markdown","767e5dc4":"markdown","49e435bc":"markdown","5ffc61f1":"markdown","67dec102":"markdown","7f996c84":"markdown","6020a13c":"markdown","476c589f":"markdown","477088a3":"markdown","5713133f":"markdown","b58d4c4c":"markdown","e0affef2":"markdown","f642727a":"markdown","263c7421":"markdown","5f412732":"markdown"},"source":{"a072a8b2":"# Importing the main libraries\nimport numpy as np\nimport pandas as pd\n\n# Notebook settings\n%matplotlib inline\n\n# Importing data visualization libraries\nimport plotly.express as px\nimport seaborn as sns\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport folium\nfrom folium.plugins import HeatMap\n\n# Data visualization settings\nsns.set_style(\"darkgrid\")\n\n# Disabling warnings\nimport warnings; warnings.simplefilter('ignore')","db91ada7":"# Loading the dataset\ndf = pd.read_csv('\/kaggle\/input\/montcoalert\/911.csv')","17d01182":"# Checking the dataset variables\ndf.info()","f98a7f0b":"# Viewing a sample of the dataset\ndf.head()","c70dac1f":"# Showing min and max dates\nprint(df['timeStamp'].min())\nprint(df['timeStamp'].max())","36557c6a":"# The reason for the call is represented by the title column, composed by a category and a subcategory\n# Therefore, we will begin by splitting this column into two new columns\ndf['Category'] = df['title'].apply(lambda x: x.split(': ')[0])\ndf['Subcategory'] = df['title'].apply(lambda x: x.split(': ')[1])","01b72233":"# Checking the new columns in the dataset\ndf.head()","a331d4b1":"# Now, we can investigate the most common reasons for a call\n# First, we will see how the calls are distributed by category\ndf['Category'].value_counts()","adf5da85":"# In order to better visualize, we can plot the above information\nplt.figure(figsize=(14,7))\n\nsns.countplot(x=\"Category\", data=df, palette='viridis', order=df['Category'].value_counts().index)\n\nplt.title('911 Calls by Category')\nplt.xlabel('Category')\nplt.ylabel('Number of Calls')","51462672":"# The same can be done to see the subcategories with most calls\n# In order not to lose the category information, we will use the title column\n\nplt.figure(figsize=(14,7))\n\nsns.countplot(x=\"title\", data=df, palette='Accent', order=df['title'].value_counts().head().index)\n\nplt.title('911 Calls by Subcategory')\nplt.xlabel('Subcategory')\nplt.ylabel('Number of Calls')\nplt.xticks(rotation=45)","56da5a43":"# Now, for example, let's explore the most representative subcategories in the EMS category\nplt.figure(figsize=(12,6))\n\nsns.barplot(x=df[df['Category'] == 'EMS']['Subcategory'].value_counts().head(), \n            y=df[df['Category'] == 'EMS']['Subcategory'].value_counts().head().index,\n            data=df[df['Category'] == 'EMS'], palette='Spectral', orient='h')\n\nplt.title('EMS - 911 Calls by Subcategory')\nplt.xlabel('Number of Calls')\nplt.ylabel('Subcategory')","7d30856c":"# To explore the calls in the studied period, we will use the timeStamp column\n# First, we have to convert the timeStamp column from string to datetime\ndf['timeStamp'] = pd.to_datetime(df['timeStamp'])","7b87f114":"# Now we can create three new columns to better explore the data\ndf['Date'] = df['timeStamp'].apply(lambda x: x.date())\ndf['Day of Week'] = df['timeStamp'].apply(lambda x: x.strftime(\"%a\"))\ndf['Hour'] = df['timeStamp'].apply(lambda x: x.strftime(\"%H\"))","7f50fed2":"# Let's see how the dataframe is now\ndf.head()","b912e61a":"# Initially, we can plot a heatmap to see which hours of the day and days of the week the number of calls are higher\n# Data for the plot\nbyDayHour = df.groupby(['Day of Week','Hour']).size().reset_index().rename(columns={0:'Number of Calls'})\nbyDayHour_df = pd.pivot_table(data=byDayHour,values='Number of Calls',index='Day of Week',columns='Hour',aggfunc='sum')\nbyDayHour_df.index = pd.CategoricalIndex(byDayHour_df.index, categories=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"][::-1])\nbyDayHour_df.sort_index(level=0, inplace=True)\n\n# Plot\nplt.figure(figsize=(15,8))\nsns.heatmap(data = byDayHour_df, cmap='magma', linecolor='grey', linewidth=0.2)\nplt.title('911 Calls by Day of Week and Hour')","d407a119":"# In another analysis, we will plot a line plot containing the calls in the period, segregated by the category of the call\nbyDateCategory = df.groupby(['Date','Category']).size().reset_index().rename(columns={0:'Number of Calls'})\n\nplt.figure(figsize=(15,7))\n\nsns.lineplot(x='Date',y='Number of Calls',data=byDateCategory, hue='Category', palette='Set2')\nplt.xticks(rotation=45)\nplt.title('911 Calls - Evolution')","39ebd20f":"# Analyzing the plot above, we can clearly see several spikes in traffic related calls\n# Let's see now the dates with higher occurrences and the exact number of calls\ndf[df['Category'] == 'Traffic'].groupby('Date').size().reset_index() \\\n                               .rename(columns={0:'Number of Calls'}) \\\n                               .sort_values('Number of Calls', ascending = False) \\\n                               .head(10)","760fd210":"# Let's isolate the traffic category for better visualization and make the plot interactive using Plotly library\nfig = px.line(byDateCategory[byDateCategory['Category'] == 'Traffic'], x=\"Date\", y=\"Number of Calls\",\n              template='seaborn', title='Traffic Calls - Evolution')\n\nfig.add_shape( # add a horizontal line, representing mean\n    type=\"line\", line_color=\"orange\", line_width=3, opacity=1, line_dash=\"dot\",\n    x0=0, x1=1, xref=\"paper\", y0=byDateCategory['Number of Calls'].mean(),\n    y1=byDateCategory['Number of Calls'].mean(), yref=\"y\"\n)\n\nfig.add_annotation( # add a text for the nor'easter\n    text=\"March 1-3, 2018 nor'easter\", x='2018-03-02', y=1350, arrowhead=1, showarrow=True, arrowcolor='red' \n)","3e60c91c":"# March 1-3, 2018 Nor'easter","ae84af2c":"# Now let's see the 911 call subcategories in traffic in that day\ndf[(df['Category'] == 'Traffic') & (df['Date'].astype(str) == '2018-03-02')] \\\n  .groupby('Subcategory') \\\n  .size() \\\n  .reset_index() \\\n  .rename(columns={0:'Number of Calls'}) \\\n  .sort_values('Number of Calls', ascending = False) ","ff5fa56a":"# Loading the geojson file containing the township boundaries with the geopandas library\nmontgomery_map = gpd.read_file('https:\/\/opendata.arcgis.com\/datasets\/74f1d8fde3204995916dc377e8db0dbc_0.geojson')","89a5ddcb":"# Verifying the type of the object\ntype(montgomery_map)","ee41a07e":"# Viewing a sample of the dataset\nmontgomery_map.head()","73ad7844":"# Verifying the difference between the townships in both datasets\nset(montgomery_map['Name'].str.lower()) - set(df['twp'].str.lower())","2e01a28c":"# Tranforming the Name column in the map dataframe to be equal the twp column in the df dataframe\n# Aplying the title function (making the first letter in each word upper case)\ndf['twp'] = df['twp'].str.title()\n# Correcting the difference in the writing of the Hatfield Township\nmontgomery_map['Name'].replace('Hatfield Twp','Hatfield Township',inplace=True)","86771d49":"# Creating a dataframe containing the 911 calls by township\ncalls_df = df['twp'].value_counts().reset_index().rename(columns={'index':'Township','twp':'Number of Calls'})\ncalls_df.head()","4dcd7b94":"# Merging the calls_df dataframe with the montgomery_map dataframe\nmerged_df = pd.merge(montgomery_map, calls_df, how='left', left_on='Name', right_on='Township')\nmerged_df.head()","7a576e9d":"# Now, we can use the folium library to plot an interactive choropleth map\n# Setting the coordinates for the map\nfolium_map = folium.Map(location=[40.2, -75.4], zoom_start=10)\n\n# Creating the choropleth layer\nchoropleth = folium.Choropleth(merged_df, data=merged_df,\n                  key_on='feature.properties.Township',\n                  columns=['Township', 'Number of Calls'], \n                  fill_color='Reds', fill_opacity = 0.7,\n                  line_opacity=0.3, highlight=True,\n                  name='Montgomery County', legend_name='Number of Calls',).add_to(folium_map)\n\n# Adding the layer to the map\nfolium.LayerControl().add_to(folium_map)\n\n# Adding the tooltip to the map\nchoropleth.geojson.add_child(\n    folium.features.GeoJsonTooltip(['Township','Number of Calls'])\n)\n\n# Displaying the map\nfolium_map","6a1a8584":"# Creating a basemap centered in the Lower Merion Township region\nbasemap = folium.Map(location=[40.0250, -75.2850], zoom_start=12)\n\n# Creating lists with lat and lng data points\nlat = df[df['twp'] == 'Lower Merion'].lat.tolist()\nlng = df[df['twp'] == 'Lower Merion'].lng.tolist()\n\n# Adding the heatmap layer\nHeatMap(list(zip(lat, lng)),radius=10,).add_to(basemap)\n\n# Plotting the map\nbasemap","c4858adf":"![marchnoreaster.png](attachment:marchnoreaster.png)","f775bdcc":"The dataset has 633701 rows, each one representing a call, from December 2015 to May 2020.\nIt contains the following fields:\n\n* lat : String variable, Latitude\n* lng: String variable, Longitude\n* desc: String variable, Description of the Emergency Call\n* zip: String variable, Zipcode\n* title: String variable, Title\n* timeStamp: String variable, YYYY-MM-DD HH:MM:SS\n* twp: String variable, Township\n* addr: String variable, Address\n* e: String variable, Dummy variable (always 1)\n\nFrom this initial analysis, the dataset information can be resumed in three aspects:\n\n- Call reason\n- Call time\n- Call location\n\nFrom this aspects, we can formulate some questions that we will investigate further:\n\n1. What are the most common reasons for a 911 call?\n2. How are the calls distributed in time?\n3. How are the calls distributed geographically? \n","83cee936":"From the information above, we can draw some conclusions:\n\n- EMS (Emergency Medical Services) accounts for almost half the total of 911 calls in the period\n- Vehicle accident is by far the most common 911 call reason\n- Although fall victim ranks first in EMS call reasons, it only represents around 5% of total calls\n- Fire alarm represents almost 40% of fire related 911 calls","767e5dc4":"Now we have to verify if the townships available on this file are the ones we have on the 911 calls dataset.","49e435bc":"## Setup","5ffc61f1":"As stated above, the purpose of this project was to provide a brief data analysis of the dataset in order to answer some basic questions. The answers for the questions are summarized below:\n\n- EMS (Emergency Medical Services) accounted for almost half the total of 911 calls in the period\n- Vehicle accident was by far the most common 911 call reason\n- Although fall victim ranked first in EMS call reasons, it only represented around 5% of total calls\n- Fire alarm represented almost 40% of fire related 911 calls\n- 911 calls occured mostly from 8:00 to 18:00, decreasing into the night\n- In all categories, the number of calls over time didn't vary substantially, mantaining a certain pattern. Nevertheless, the occurence of events such as climate ones, affected the number of traffic calls in several moments.\n- Lower Merion, Abington and Norristown townships represented one out of five calls made.","67dec102":"From the map above, we can see that the townships with most calls are **Lower Merion (53240)**, **Abington (38208)** and **Norristown (35678)**. Now, let's dig deeper into the Lower Merion township by plotting a heatmap with the lat and lng info we have, in order to see how the calls were distributed geographically.","7f996c84":"We can see that almost half of calls that day had **road obstruction** as a reason. This makes sense since in a severe cyclone, down trees and power lines are usual.","6020a13c":"Now we will explore the locations of the 911 calls represented in the dataset. For this task, we need a dataset\/layer that represents the townships' boundaries. Luckily, we've found what we need in the [Mountgomery County website][1].\n\n[1]: https:\/\/data-montcopa.opendata.arcgis.com\/datasets\/montgomery-county-municipal-boundaries","476c589f":"![montgomery_county.jpeg](attachment:montgomery_county.jpeg)\n\n- The purpose of this project is to provide a brief data analysis of a 911 calls dataset.\n- The dataset contains emergency calls data from Montgomery County, Pennsylvania. ","477088a3":"The plot above shows that the 911 calls occurs mostly from **8:00 to 18:00**, and decreases gradually as the night advances.","5713133f":"Our purpose now is to enrich the map dataframe with the calls info from the 911 dataset. With the conclusion of the previous steps, we can use the columns that represent the township in both datasets as a key to join them.","b58d4c4c":"# 911 Calls - Data Analysis","e0affef2":"## Conclusions","f642727a":"## Exploratory Data Analysis","263c7421":"After a search on Google, we see that the cause for a high number of calls in **March 2nd, 2018** was a powerful **nor'easter (cyclone)** that impacted the region.","5f412732":"## Dataset Overview"}}