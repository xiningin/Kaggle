{"cell_type":{"71f4a606":"code","ef20e3e8":"code","9e12b0c8":"code","10e31a62":"code","2aeb915c":"code","703a4421":"code","91c0e897":"code","cf54e06a":"code","f4164ed8":"markdown","e3db08c4":"markdown"},"source":{"71f4a606":"from PIL import Image, ImageDraw, ImageFont\nfrom os import listdir\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","ef20e3e8":"df_train = pd.read_csv('..\/input\/train.csv')\nunicode_map = {codepoint: char for codepoint, char in pd.read_csv('..\/input\/unicode_translation.csv').values}","9e12b0c8":"fontsize = 50\n# From https:\/\/www.google.com\/get\/noto\/\n!wget -q --show-progress https:\/\/noto-website-2.storage.googleapis.com\/pkgs\/NotoSansCJKjp-hinted.zip\n!unzip -p NotoSansCJKjp-hinted.zip NotoSansCJKjp-Regular.otf > NotoSansCJKjp-Regular.otf\n!rm NotoSansCJKjp-hinted.zip\n\nfont = ImageFont.truetype('.\/NotoSansCJKjp-Regular.otf', fontsize, encoding='utf-8')","10e31a62":"df_train.head()\n\"\"\"\nImage_id\n\u4e00\u822c\u7684\u306aID\u5217\n\nlabels\n[\u30e6\u30cb\u30b3\u30fc\u30c9\u3001\u3000x, y, weight, high]\nx\u3068y\u306f\u59cb\u70b9\nweight\u3068high\u306f\u67a0\u306e\u5927\u304d\u3055\u3092\u8868\u3057\u3066\u3044\u308b\n\u3064\u307e\u308a\u6587\u5b57\u3092\u62bd\u51fa\u3057\u305f\u304b\u3063\u305f\u3089\n[x, y, x+weight, y+high]\n\u306e\u9577\u65b9\u5f62\u3092\u629c\u304d\u53d6\u308c\u3070\u826f\u3044\n\"\"\"\n\n\"\"\"\n\u63d0\u51fa\u3059\u308b\u3082\u306e\ncsv\u5f62\u5f0f\nid\u5217\u3068labels\u5217\nid\u5217\u306f\u753b\u50cf\u306eID\u3092\u5165\u308c\u308c\u3070OK\n\nlabels\u5217\n[\u30e6\u30cb\u30b3\u30fc\u30c9\u3001\uff58\u5ea7\u6a19\u3001\uff59\u5ea7\u6a19]\n\u3053\u3053\u306e\u5ea7\u6a19\u306f\u771f\u3093\u4e2d\u3067\u826f\u3044\u305d\u3046\n\"\"\"\n\n\"\"\"\n\u3068\u306a\u308b\u3068\u3001\n\n\u524d\u51e6\u7406\n1.\u6587\u5b57\u3068\u5ea7\u6a19\u3092\u629c\u304d\u53d6\u3063\u3066\u5358\u7d14\u306a\u753b\u50cf\u5206\u985e\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u3088\u3046\u306a\u3082\u306e\u3092\u4f5c\u6210\u3059\u308b\n\n\u30e2\u30c7\u30eb\u4f5c\u6210\n2.\uff11\u3067\u4f5c\u6210\u3057\u305f\u30c7\u30fc\u30bf\u3092\u5b66\u7fd2\u3055\u305b\u308b\n3.OCR\u307f\u305f\u3044\u306a\u3082\u306e\u3067\u753b\u50cf\u304b\u3089\u6587\u5b57\u3092\u691c\u51fa\u3059\u308b\u30e2\u30c7\u30eb\u3082\u4f5c\u6210\uff08\u53e4\u4ee3\u306e\u304b\u306a\u3060\u304b\u3089\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u304c\u3042\u308b\u304b\u306f\u308f\u304b\u3089\u306a\u3044\uff09\n\n\u4e88\u6e2c\n4.\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u304b\u3089\u6587\u5b57\u3092\u53d6\u308a\u51fa\u3059\n5.2\u3067\u4f5c\u3063\u305f\u753b\u50cf\u5206\u985e\u30e2\u30c7\u30eb\u306b4\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u5b66\u7fd2\u3055\u305b\u308b\n\nsubmit\n6.\u30c7\u30fc\u30bf\u306e\u6574\u5f62\uff06submit\n\n\u3068\u3044\u3046\u6d41\u308c\u304c\u3067\u304d\u308b\u306e\u304b\u306a\uff08\u9593\u9055\u3063\u3066\u3044\u305f\u3089\u6559\u3048\u3066\u304f\u3060\u3055\u3044\uff09\n\n\u3068\u306f\u3044\u30484781\u3082\u30e9\u30d9\u30eb\u304c\u3042\u308b\u30c7\u30fc\u30bf\u3068\u306a\u308b\u3068\u591a\u5c11\u306e\u5de5\u592b\u306f\u5fc5\u8981\u305d\u3046\n\u305d\u308c\u306b\u5b9f\u884c\u6642\u9593\u3082\u76f8\u5f53\u9577\u304f\u306a\u308a\u305d\u3046\u3060......\n32x32\u306e\u753b\u50cf\u3092\uff11\uff10\u4e07\u679a\u5b66\u7fd2\u3055\u305b\u305f\u3068\u3057\u3066\u3001\u3069\u308c\u304f\u3089\u3044\u306e\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u3060\u308d\u3046\u304b\uff08\u3084\u3063\u3066\u307f\u306a\u304f\u3061\u3083\u308f\u304b\u3089\u306a\u3044\uff09\n\"\"\"","2aeb915c":"len(unicode_map)","703a4421":"# This function takes in a filename of an image, and the labels in the string format given in train.csv, and returns an image containing the bounding boxes and characters annotated\n\n\"\"\"\n\u30a2\u30ec\u30f3\u30b8\u3057\u307e\u3057\u305f\n\"\"\"\ndef visualize_training_data(image_fn, labels):\n    # Convert annotation string to array\n\n    labels = np.array(str(labels).split(' ')).reshape(-1, 5)\n    # print(\"labels\u3067\u3059\", labels)\n    # print(\"label.shape \u3067\u3059\", labels.shape, len(labels))\n    # Read image\n    imsource = Image.open(image_fn).convert('RGBA')\n\n    memo2 = np.array(labels)[:, 0]  # \u30e9\u30d9\u30eb\u304c\u5165\u308b\n    memo3 = np.zeros((len(labels), 32, 32, 4)).astype(\"int32\")  # Image\u30c7\u30fc\u30bf\u304c\u5165\u308b\n    # print(memo3.shape)\n    \"\"\"\n    weight, high\u3092\u898b\u3066\u3044\u308b\u306864\u304f\u3089\u3044\u3067\u3061\u3087\u3046\u3069\u3044\u3044\uff1f\u611f\u3058\u304c\u3059\u308b\u306e\u306764\u306b\u3057\u307e\u3057\u305f\u3002\n    \"\"\"\n    # print(memo3)\n    # print(labels.shape)\n\n    for i, (codepoint, x, y, w, h) in enumerate(labels):\n        # print(i)\n        x, y, w, h = int(x), int(y), int(w), int(h)\n        \"\"\"\n        \u3053\u3053\u304b\u3089\u753b\u50cf\u306e\u5207\u308a\u629c\u304d\u3092\u884c\u3046\n        \"\"\"\n        # print(np.asarray(img_crop).shape)\n        \n        # \u753b\u50cf\u304b\u3089\u6587\u5b57\u306e\u90e8\u5206\u3092\u629c\u304d\u53d6\u308b\n        img_crop = imsource.crop((x, y, x+w, y+h))\n        \n        img_crop = np.asarray(img_crop.resize((32, 32)))\n        \n        # print(np.array(img_crop).shape)\n        \"\"\"\n        print(np.array(img_crop).shape)\n        \n        # (64, 64, 4)\n        \"\"\"\n        # array\u306b\u5165\u308c\u308b\n        memo3[i, :, :, :] = np.asarray(img_crop).astype(\"int32\")\n    \n    # \u30e9\u30d9\u30eb\u3068\u53d6\u308a\u51fa\u3057\u305f\u6587\u5b57\u306e\u30c7\u30fc\u30bf\u3082return\n    return memo2, memo3","91c0e897":"from glob import glob\nfrom tqdm import tqdm\nimport gc\nimport matplotlib.font_manager as fm\n\nprop = fm.FontProperties(fname=\".\/NotoSansCJKjp-Regular.otf\")\n\"\"\"\n\u9069\u5f53\u306b\u30b3\u30e1\u30f3\u30c8\u4ed8\u3051\u307e\u3059\n\"\"\"\ntotal = 800\ni = 0\nfor x in glob(\"..\/input\/train_images\/*.jpg\"):\n    # print(x)\n    # print(df_train.head())\n    # path = x.split(\"\/\")[3]\n    # local\n    path = x.split(\"\/\")[3]\n    path = path.split(\".\")[0]\n\n    memo1 = df_train.values[df_train[\"image_id\"] == path].flatten()\n    # print(memo1)\n    # print(memo1[1])\n\n    try:\n        \"\"\"\n        1\u30da\u30fc\u30b8\u5168\u3066\u30a4\u30e9\u30b9\u30c8\u3060\u3063\u305f\u5834\u5408\u306f\u98db\u3070\u3059\u3002\uff08nan\u306b\u306a\u308b\u305f\u3081ValueError)\n        \"\"\"\n        labels = memo1[1]\n        # print(labels)\n        \n        memo2, memo3 = visualize_training_data(x, labels)\n\n        # print(memo3.shape)\n        \n        # save\n        # np.save(\"npyy\/\" + str(i) + \"image.npy\", memo3)\n        # np.save(\"npyy\/\" + str(i) + \"labels.npy\", memo2)\n\n        if i == 0:\n            image_data = memo3.copy()\n            labels_data = memo2.copy()\n        elif i % 400 == 0:\n            \"\"\"\n            400\u679a\u3054\u3068\u306b1\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n            \"\"\"\n            np.save(\"image_data_\" + str(i) + \".npy\", image_data)\n            np.save(\"labels_data_\" + str(i) + \".npy\", labels_data)\n            del image_data, labels_data\n            gc.collect()\n            image_data = memo3.copy()\n            labels_data = memo2.copy()\n        else:\n            image_data = np.append(image_data, memo3, axis=0)\n            labels_data = np.append(labels_data, memo2, axis=0)\n        # \u30a4\u30e9\u30b9\u30c8\u30da\u30fc\u30b8\u3067\u30ab\u30a6\u30f3\u30c8\u3057\u306a\u3044\u3088\u3046\u306b\n        i += 1\n        # i.update(10)\n    except ValueError:\n        print(\"\u30a4\u30e9\u30b9\u30c8\u30da\u30fc\u30b8\u3067\u3059\uff01\uff01\")\n    \n    if i % 50 == 0:\n        \"\"\"\n        \u53d6\u308a\u51fa\u3057\u305f\u753b\u50cf\u3092\u8868\u793a\u3057\u307e\u3059\n        \"\"\"\n        plt.rcParams[\"font.size\"] = 15\n\n        char = memo2[10]\n        plt.title(unicode_map[char], fontproperties=prop, fontsize=50)\n        plt.imshow(memo3[10, :, :, :])\n        plt.show()\n        \n    if i == total:\n        np.save(\"image_data_\" + str(i) +\".npy\", image_data)\n        np.save(\"labels_data_\" + str(i) + \".npy\", labels_data)\n        break","cf54e06a":"\"\"\"\n\u30ab\u30fc\u30cd\u30eb\u306eDisk\u306e\u5236\u9650\u30673800\u679a\u5168\u3066\u306e\u753b\u50cf\u306e\u4fdd\u5b58\u306f\u51fa\u6765\u307e\u305b\u3093\u3067\u3057\u305f\u3002\uff08\u30e1\u30e2\u30ea\u30a8\u30e9\u30fc\u304b\u3082\u3057\u308c\u306a\u3044?\uff09\n\n\u89e3\u6c7a\u7b56\u3082\u4f55\u304b\u3042\u308c\u3070\u30b3\u30e1\u30f3\u30c8\u304f\u3060\u3055\u3044\u3002\n\n\u50d5\u306f\u3042\u3068\u3067\u30ed\u30fc\u30ab\u30eb\u74b0\u5883\u3067\u5b9f\u884c\u3057\u3066\u307f\u3088\u3046\u3068\u601d\u3063\u3066\u3044\u307e\u3059\u3002\n\"\"\"","f4164ed8":"# Read first\n\nSorry, I use Japanese here.\n\nBecause, I can't speak English.\n\n\u65e5\u672c\u8a9e\u3067\u66f8\u304d\u307e\u3059\u3002  \n\u3053\u306e\u30ab\u30fc\u30cd\u30eb\u306f\u4e0d\u5341\u5206\u306a\u7b87\u6240\u304c\u3042\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u306e\u3067\u3001\u4f55\u304b\u6307\u6458\u304c\u3042\u308c\u3070\u30b3\u30e1\u30f3\u30c8\u304f\u3060\u3055\u3044\u3002\n\n\n[https:\/\/www.kaggle.com\/anokas\/kuzushiji-visualisation\/output](https:\/\/www.kaggle.com\/anokas\/kuzushiji-visualisation\/output)\n\u3053\u3053\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f","e3db08c4":"\u3053\u3053\u3067\u306ftrain\u30c7\u30fc\u30bf\u304b\u3089\u6587\u5b57\u3092\u62bd\u51fa\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002\n\n\u3053\u3053\u3067\u4fdd\u5b58\u3057\u305f\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u6587\u5b57\u306e\u8b58\u5225\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u306f\u305a\uff08\uff1f\uff09\u3067\u3059\u3002"}}