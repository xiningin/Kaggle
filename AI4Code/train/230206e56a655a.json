{"cell_type":{"8d39eae4":"code","1e73409d":"code","e2a360dd":"code","921a477d":"code","e11afba5":"code","456c6cde":"code","f252daa6":"code","e73cd0f6":"code","71da70e9":"code","4ed6e50a":"code","1222f90a":"code","72e03ce7":"code","0e2ae1c9":"code","dfeb04c9":"code","821b8ee7":"code","cba36d0f":"code","f6121b66":"code","413378dc":"code","f7763eaf":"code","00d0ac27":"code","c04f5520":"code","74324174":"code","8ef9d480":"code","4f8b4712":"code","7886eb88":"code","861f6ddc":"code","1011b0f0":"code","a9dd677e":"code","cab65764":"code","a8e16cac":"code","c1d68c56":"code","d057939c":"code","6d81f11f":"code","c329c364":"code","52042bbd":"code","134720ac":"code","8a625e04":"code","6d55cf4b":"code","11a8c73d":"code","569b4605":"code","bb4bf619":"code","be1bd762":"code","f81830f5":"code","85562478":"code","8e6e92eb":"code","f77cdb13":"code","b21dd721":"code","408eee26":"code","72c93638":"code","8a043ce6":"code","50848345":"code","36678ceb":"code","bbfaf30d":"code","9f8412da":"code","464375b3":"code","35b533b5":"code","1fddac1d":"code","d8f45859":"code","43d1ef09":"code","c9cba9a0":"code","664b9e64":"code","52dbc9a4":"code","a8a996a5":"code","418e0df5":"code","e793b0b3":"code","02134852":"code","6a28364f":"code","8cadf398":"code","8649cbf8":"markdown","adecfc44":"markdown","61d6f53b":"markdown","a0c75819":"markdown","62c97262":"markdown","1e4a63de":"markdown","c2d15a83":"markdown","9525c7c0":"markdown","608c9223":"markdown"},"source":{"8d39eae4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n## Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","1e73409d":"df = pd.read_csv('..\/input\/job-interview-assignments-test\/Task 1 PM Assignments - Raw Data.csv')\ndf","e2a360dd":"df.info()","921a477d":"### dataset Have non missing values but there are duplicate entries lets check for it\ndf.duplicated().sum()","e11afba5":"## There are 40,096 duplicate entries. which was my first observation when I skimmed theough the dataset\ndf.drop_duplicates(inplace= True)","456c6cde":"### Change Date to Date Time from Object DataType\ndf['Order Date & Time']= pd.to_datetime(df['Order Date & Time'], infer_datetime_format=True)\n## Display min and max for date time\ndf['Order Date & Time'].min(),df['Order Date & Time'].max()","f252daa6":"### Sort DF w.r.t df['Order Date & Time']\ndf.sort_values('Order Date & Time', inplace=True)","e73cd0f6":"df.sort_values('Date', inplace=True)","71da70e9":"plt.figure(figsize=(15,6))\nsns.countplot(x='Date', data = df)\nplt.xticks(rotation=90);","4ed6e50a":"##### Why min =2018-01-06 07:53:00 and max= 2018-12-06 21:57:00. whereas graph shows dates beyond 12 June\ndf[df['Date']=='22-Jun']","1222f90a":"df.hist(figsize=(14,10), edgecolor='Black', linewidth=1.2);","72e03ce7":"df.isnull().mean()","0e2ae1c9":"df.describe()","dfeb04c9":"df.describe(include='object')","821b8ee7":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nx=df['Primary Order Category'].value_counts()\nlabels=['SEEDS','CROP NUTRITION', 'CROP PROTECTION']\nplt.title(\"Primary Order Category\", fontsize=14);\nplt.pie(x,explode=[0.0,0.1, 0.15],autopct='%1.1f%%', labels=labels);\n\nplt.subplot(1,2,2)\nx=df['Order Status'].value_counts()\nlabels=['CANCELLED','COMPLETE']\nplt.title(\"Order Status\", fontsize=14);\nplt.pie(x,explode=[0.0,0.1],autopct='%1.1f%%', labels=labels)\nplt.tight_layout();","cba36d0f":"df.groupby('Order Status').sum()","f6121b66":"df.groupby('Primary Order Category').mean().drop(columns={'Customer ID', 'Shipping Pincode', 'Order ID'})","413378dc":"df.groupby('Primary Order Category').sum().drop(columns={'Customer ID', 'Shipping Pincode', 'Order ID'})","f7763eaf":"plt.subplot(3,1,1)\nsns.countplot(y='Shipping State', data=df)\nplt.title(\"Shipping State wise\")\nplt.subplot(3,1,2)\ndf['Shipping City'].value_counts().plot(kind=\"bar\" )\nplt.xticks(fontsize=13)\nplt.title('Shipping Citywise')\nplt.subplot(3,1,3)\ndf['Corrected City'].value_counts().plot(kind=\"bar\", figsize=(22,18), color = 'Black' )\nplt.xticks(fontsize=13)\nplt.title('Shipping After Correction Citywise')\nplt.tight_layout();","00d0ac27":"df.groupby('Shipping Pincode').sum()","c04f5520":"df.groupby('Shipping Pincode').sum().sort_values('Count', ascending=False)","74324174":"df_pin_cum = df.groupby('Shipping Pincode').sum().sort_values('Count', ascending=False)\ndf_pin_cum.drop(columns={'Customer ID','Order ID'}, inplace=True)\ndf_pin_cum['avg_order_value']= df_pin_cum['Order Value']\/df_pin_cum['Count']\ndf_pin_cum","8ef9d480":"df_pin_cum.columns","4f8b4712":"!pip install geopy","7886eb88":"import geopy\nfrom geopy.geocoders import Nominatim\nfrom geopy.extra.rate_limiter import RateLimiter\nfrom geopy import distance","861f6ddc":"### Try our code\ncity_name = 'Ahmedabad'\ncorrect_city = Nominatim(user_agent='tutorial').geocode(city_name)\ncorrect_city","1011b0f0":"df.head()","a9dd677e":"### Try our code on pincode\nPinCode = '382250'\nlocation = Nominatim(user_agent='tutorial').geocode(PinCode)\nlocation","cab65764":"Nominatim(user_agent='tutorial').geocode(PinCode).latitude,Nominatim(user_agent='tutorial').geocode(PinCode).longitude","a8e16cac":"'''\ndf['Latitude']=0.0\ndf['Longitude']=0.0\n'''","c1d68c56":"### This block of code was expected to take 47257 sec or 13hr to execute thus lets try folium\n\n##~~~~~~~ Note ~~~~~~~##\n## geopy is very power full library but due to constrain of time I am Switching to Folium\n### Geopy also support Bing API etc\n\n'''\n%%time\n### Now lets sctore location longitute and latitute in our dataframe\n\n# Nominatim geocoder for OpenStreetMap data with RateLimiter\ngeocoder = RateLimiter(Nominatim(user_agent='tutorial').geocode, min_delay_seconds=1)\ndf['Location'] = df['Shipping Pincode'].apply(geocoder)\n\n# add latitude and longitude to dataframe\ndf['Latitude'] = df['Location'].apply(lambda loc: loc.latitude if loc else None)\ndf['Longitude'] = df['Location'].apply(lambda loc: loc.longitude if loc else None)\n\ndf\n'''","d057939c":"### Lets try using map as above method will take very long time\ndf['Shipping Pincode'].nunique()","6d81f11f":"len(df['Shipping Pincode'].unique())\nlocations=pd.DataFrame({\"Pin Code\":df['Shipping Pincode'].unique()})\nlocations.head(3)","c329c364":"%%time\n\n# We have found out latitude and longitude of each location listed in the dataset using geopy.\n\nlat_lon=[] # list that will store the lat and lon\ngeolocator=Nominatim(user_agent=\"app\") # to establish connection \nfor location in locations['Pin Code']:\n    location = geolocator.geocode(location)\n    if location is None:\n        lat_lon.append(np.nan) # if no location is there\n    else:    \n        geo=(location.latitude,location.longitude)\n        lat_lon.append(geo)","52042bbd":"locations['geo_loc']=lat_lon\nlocations.to_csv('GPS_locations.csv',index=False)","134720ac":"locations.head(3)","8a625e04":"# Creating a dataframe with total value count for each pin code\nRest_locations=pd.DataFrame(df['Shipping Pincode'].value_counts().reset_index())\nRest_locations.columns=['Pin Code','count']\nRest_locations.head(3)","6d55cf4b":"# now combine both the dataframes\nlocations_details = Rest_locations.merge(locations,on='Pin Code',how=\"left\").dropna()\nlocations_details.head(3)","11a8c73d":"### Creating a new feature for lat and lon\n\nlat,lon=zip(*np.array(locations_details['geo_loc']))\n\n\nlocations_details['lat']=lat\nlocations_details['lon']=lon\n\nlocations_details.head(3)","569b4605":"sns.scatterplot(x='lat', y='lon', data=locations_details)\nplt.title(\"just to get the Idea about lat and lon\", fontsize=12);","bb4bf619":"def generateBaseMap(default_location=[23.0225, 72.5714], default_zoom_start=12):\n    base_map = folium.Map(location=default_location, zoom_start=default_zoom_start)\n    return base_map","be1bd762":"!pip install folium","f81830f5":"import folium\nfrom folium.plugins import HeatMap\nbasemap=generateBaseMap()","85562478":"### This map will pin to Ahemdabad as I set its location while creating it\n#map = folium.Map(location=[23.0225, 72.5714], default_zoom_start=4, width=800, height=500, control_scale=True)\n# map","8e6e92eb":"HeatMap(locations_details[['lat','lon','count']].values.tolist(),zoom_start=1,radius=15).add_to(basemap)","f77cdb13":"basemap","b21dd721":"import plotly.express as px\n","408eee26":"df_complete= df[df['Order Status']=='COMPLETE']\ndf_Cancel= df[df['Order Status']=='CANCELLED']","72c93638":"df_summary= df_complete['Corrected City'].value_counts()\ndf_summary = df_summary.to_frame()\ndf_summary.head(2)","8a043ce6":"fig = px.treemap(df_summary, path=[df_summary.index], values=\"Corrected City\", height = 750,\n                 title=\"<b>No of Complete Shipping to Corrected City<\/b>\",\n                 color_discrete_sequence = px.colors.qualitative.Set3)\n\nfig.update_traces(textinfo = \"label+text+value\")\nfig.show()","50848345":"df_summary= df_complete['Shipping City'].value_counts()\ndf_summary = df_summary.to_frame()","36678ceb":"fig = px.treemap(df_summary, path=[df_summary.index], values=\"Shipping City\", height = 750,\n                 title=\"<b>No of Complete Shipping to Shipping City<\/b>\",\n                 color_discrete_sequence = px.colors.qualitative.Set3)\n\nfig.update_traces(textinfo = \"label+text+value\")\nfig.show()","bbfaf30d":"df_summary= df_Cancel['Corrected City'].value_counts()\ndf_summary = df_summary.to_frame()\ndf_summary.head(2)","9f8412da":"fig = px.treemap(df_summary, path=[df_summary.index], values=\"Corrected City\", height = 750,\n                 title=\"<b>No of CANCELLED Shipping to Corrected City<\/b>\",\n                 color_discrete_sequence = px.colors.qualitative.Set3)\n\nfig.update_traces(textinfo = \"label+text+value\")\nfig.show()","464375b3":"a=df_Cancel['Corrected City'].value_counts().to_frame()\na.reset_index(level=0, inplace=True)\na.rename(columns={'index': 'City', 'Corrected City': 'Cancelled'}, inplace=True)\n\nb= df_complete['Corrected City'].value_counts().to_frame()\nb.reset_index(level=0, inplace=True)\nb.rename(columns={'index': 'City', 'Corrected City': 'Completed'}, inplace=True)\nc= b.merge(a)\nc['Cancel Rate'] = (c['Cancelled']\/(c['Completed']+ c['Cancelled']))*100\nc","35b533b5":"fig = px.treemap(c, path=['City'], values=\"Cancel Rate\", height = 750,\n                 title=\"<b>Cancellation Rate<\/b>\",\n                 color_discrete_sequence = px.colors.qualitative.Set3)\n\nfig.update_traces(textinfo = \"label+text+value\")\nfig.show()","1fddac1d":"group_city_order = df.groupby(['Shipping City','Order Status']).sum().drop(columns={'Customer ID','Shipping Pincode','Order ID'})\ngroup_city_order","d8f45859":"rough= df_complete.groupby('Shipping Pincode').sum().drop(columns={'Customer ID','Order ID'})\nrough.sort_values(\"Order Value\", ascending=False, inplace=True)\nrough.head(20)","43d1ef09":"rough.reset_index(inplace=True)\nrough.head(2)","c9cba9a0":"PinCode = '431113'\nlocation = Nominatim(user_agent='app').geocode(PinCode)\nlocation","664b9e64":"PinCode = '431204'\nlocation = Nominatim(user_agent='app').geocode(PinCode)\nlocation","52dbc9a4":"%%time\n### Now lets sctore location longitute and latitute in our dataframe\n\n# Nominatim geocoder for OpenStreetMap data with RateLimiter\ngeocoder = RateLimiter(Nominatim(user_agent='tutorial').geocode)\nrough['Location'] = rough['Shipping Pincode'].apply(geocoder)\nrough.head(3)","a8a996a5":"temp=rough","418e0df5":"# add latitude and longitude to dataframe\nrough['Latitude'] = rough['Location'].apply(lambda loc: loc.latitude if loc else None)\nrough['Longitude'] = rough['Location'].apply(lambda loc: loc.longitude if loc else None)\nrough","e793b0b3":"rough.to_csv('location_rough.csv', index=False)","02134852":"locations_details.to_csv('locations_details.csv', index=False)","6a28364f":"df.to_csv('Assignment.csv',index=False)","8cadf398":"df_pin_cum.to_csv('Assignment Pin Cum.csv', index=False)","8649cbf8":"# Conclusion\n### What are the key factors you would use to determine the location? Why?\n* Mode of Transportation Available and connectivity to **PAN India**\n* Location which have high demand for our products\n##### Cancelation rate\n* Place with high cancelation rate mean `There is a market for product but there may be some logistic problem`\n* Place have Low cancelation rate :: **`Assumption`** cancelation occur to places due to logistic problem or end user may cancel the order but since we are trading with crop related products farmers have very limited places to buy product and once they brought it there is very low chance they will cancel their order. As in my experience Customers switch to online mode ***When either similar quality product is not available in local market or when online item is cheap compared to local market***. To support my assumption Farmers won't cancel product during **`Kharif`** as there time scarcity for sowing\n\n### What taluka (across three states) would you look open in? Why?","adecfc44":"#### Observations from data to move forward\nShipping Pincode is better way to pin address on map than city name. As this data set has different pin code for same city meaning pin code contains local data","61d6f53b":"# Now Plot these coordinates on map\n![FedStats_Lat_long.svg.png](attachment:ab78aea4-5bf1-45da-bd38-da96242cd3a1.png)\n\n![download.jpg](attachment:f30d4b44-e01c-4fe3-8f36-c4fc34b04b17.jpg)","a0c75819":"# geopy 2.20 \npip install geopy  \n[More on Geopy](https:\/\/pypi.org\/project\/geopy\/)","62c97262":"Map zoom in to Ahmedabad scroll out to get the complete pic of heatmap","1e4a63de":"# Task:\n\nSince its inception, AgroStar has been leveraging an assisted marketplace model. Given that the market potential is huge and that the target customer appreciates a physical store nearby, we have taken a call to explore the offline retail model to drive growth. The primary objective is to get a larger wallet share for AgroStar among existing customers.\n\nAssume you are back in time, in August 2018 and you have been **asked to determine the location (taluka) of the first AgroStar offline retail store**.\n\n1. What are the key factors you would use to determine the location? Why?\n2. What taluka (across three states) would you look open in? Why?","c2d15a83":"# Geopolitical analysis","9525c7c0":"# Saving processed data on disk","608c9223":"This dataset contains data for month for June 2018"}}