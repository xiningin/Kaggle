{"cell_type":{"6e7bc97f":"code","603f4a61":"code","4465c6cb":"code","0c5dd0b4":"code","f8b926f0":"code","c1d58735":"code","39be953f":"code","190c83ea":"code","32d70f24":"code","6c15421f":"code","cd188f89":"code","0e04796c":"code","be03d7db":"code","ddf7a5d6":"code","1ef64d4e":"code","1ec76c55":"code","42f60f9b":"code","cbdf19d0":"code","49d92db4":"code","27082c99":"code","814001fd":"code","a23bcea4":"code","4b9c01b3":"markdown","e203866c":"markdown"},"source":{"6e7bc97f":"\nimport pandas as pd\nimport joblib\nimport glob\nfrom tqdm import tqdm\n","603f4a61":"import pandas as pd\nimport albumentations\nimport joblib\nimport numpy as np\nimport torch\n\nfrom PIL import Image\n","4465c6cb":"import torch.nn as nn\nfrom torch.nn import functional as F","0c5dd0b4":"%%writefile train.py\n\nimport os\nimport ast\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport sklearn.metrics\n","f8b926f0":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","c1d58735":"import sys\nfrom torchvision import models","39be953f":"import glob\nimport torch\nimport albumentations\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\nfrom PIL import Image\nimport joblib\nimport torch.nn as nn\nfrom torch.nn import functional as F","190c83ea":"model_dir =  \"..\/input\/bengalifold6\/fold6.pth\"","32d70f24":"class BengaliModel(nn.Module):\n    def __init__(self, pretrained=False):\n        super(BengaliModel, self).__init__()\n        self.basemodel = models.resnext50_32x4d(pretrained=pretrained)\n        \n        self.Linr = nn.Linear(2048, 168)\n        self.Linv = nn.Linear(2048, 11)\n        self.Linc = nn.Linear(2048, 7)\n\n    def forward(self, x):\n        bs, _, _ , _ = x.shape\n\n        x = self.basemodel.conv1(x)\n        x = self.basemodel.bn1(x)\n        x = self.basemodel.relu(x)\n        x = self.basemodel.maxpool(x)\n        x = self.basemodel.layer1(x)\n        x = self.basemodel.layer2(x)\n        x = self.basemodel.layer3(x)\n        x = self.basemodel.layer4(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n\n        roots = self.Linr(x)\n        vowels = self.Linv(x)\n        consonents = self.Linc(x)\n\n\n        return roots, vowels, consonents\n\n","6c15421f":"\nMODEL_MEAN = (0.485, 0.456, 0.406)\nMODEL_STD = (0.229, 0.224, 0.225)\nIMG_HEIGHT = 137\nIMG_WIDTH = 236\nDEVICE=\"cuda\"","cd188f89":"class BengaliDatasetTest:\n    def __init__(self, df, img_height, img_width, mean, std):\n        \n        self.image_ids = df.image_id.values\n        self.img_arr = df.iloc[:, 1:].values\n\n        self.aug = albumentations.Compose([\n            albumentations.Resize(img_height, img_width, always_apply=True),\n            albumentations.Normalize(mean, std, always_apply=True)\n        ])\n\n\n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self, item):\n        image = self.img_arr[item, :]\n        img_id = self.image_ids[item]\n        \n        image = image.reshape(137, 236).astype(float)\n        image = Image.fromarray(image).convert(\"RGB\")\n        image = self.aug(image=np.array(image))[\"image\"]\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n\n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"image_id\": img_id\n        }","0e04796c":"def model_predict():\n    g_pred, v_pred, c_pred = [], [], []\n    img_ids_list = [] \n    \n    for file_idx in range(4):\n        print('loading Parquet'+str(file_idx))\n        df = pd.read_parquet(f\"..\/input\/bengaliai-cv19\/test_image_data_{file_idx}.parquet\")\n\n        dataset = BengaliDatasetTest(df=df,\n                                    img_height=IMG_HEIGHT,\n                                    img_width=IMG_WIDTH,\n                                    mean=MODEL_MEAN,\n                                    std=MODEL_STD)\n\n        data_loader = torch.utils.data.DataLoader(\n            dataset=dataset,\n            batch_size= TEST_BATCH_SIZE,\n            shuffle=False,\n            num_workers=4\n        )\n\n        for bi, d in enumerate(data_loader):\n            image = d[\"image\"]\n            img_id = d[\"image_id\"]\n            image = image.to(DEVICE, dtype=torch.float)\n\n            g, v, c = model(image)\n            #g = np.argmax(g.cpu().detach().numpy(), axis=1)\n            #v = np.argmax(v.cpu().detach().numpy(), axis=1)\n            #c = np.argmax(c.cpu().detach().numpy(), axis=1)\n\n            for ii, imid in enumerate(img_id):\n                g_pred.append(g[ii].cpu().detach().numpy())\n                v_pred.append(v[ii].cpu().detach().numpy())\n                c_pred.append(c[ii].cpu().detach().numpy())\n                img_ids_list.append(imid)\n        \n    return g_pred, v_pred, c_pred, img_ids_list","be03d7db":"model = BengaliModel(pretrained=False)\nmodel.load_state_dict(torch.load(model_dir))\n\nTEST_BATCH_SIZE = 32\n\nfinal_g_pred = []\nfinal_v_pred = []\nfinal_c_pred = []\nfinal_img_ids = []\n\nmodel.to(DEVICE)\nmodel.eval()\ng_pred, v_pred, c_pred, img_ids_list = model_predict()\n\nfinal_g_pred.append(g_pred)\nfinal_v_pred.append(v_pred)\nfinal_c_pred.append(c_pred)\nfinal_img_ids.extend(img_ids_list)","ddf7a5d6":"img_ids_list","1ef64d4e":"torch.argmax(torch.softmax(torch.tensor(final_g_pred[0]), 0), 1).shape","1ec76c55":"final_g = np.argmax(np.array(final_g_pred[0]), axis=1)\nfinal_v = np.argmax(np.array(final_v_pred[0]), axis=1)\nfinal_c = np.argmax(np.array(final_c_pred[0]), axis=1)","42f60f9b":"final_img_ids","cbdf19d0":"final_g.shape","49d92db4":"predictions = []\nfor ii, imid in enumerate(final_img_ids):\n    predictions.append((f\"{imid}_consonant_diacritic\", final_c[ii]))\n    predictions.append((f\"{imid}_grapheme_root\", final_g[ii]))\n    predictions.append((f\"{imid}_vowel_diacritic\", final_v[ii]))\n    ","27082c99":"sub = pd.DataFrame(predictions, columns=[\"row_id\", \"target\"])","814001fd":"sub","a23bcea4":"sub.to_csv(\"submission.csv\", index=False)","4b9c01b3":"# Inference","e203866c":"## This kernel is from [@Abhishek Thakur](https:\/\/www.kaggle.com\/abhishek) youtube channel\n\n### [Bengali.AI: Handwritten Grapheme Classification Using PyTorch (Part-1)](https:\/\/www.youtube.com\/watch?v=8J5Q4mEzRtY) \n\n### [Bengali.AI: Handwritten Grapheme Classification Using PyTorch (Part-2)](https:\/\/www.youtube.com\/watch?v=uZalt-weQMM&t=3478s)"}}