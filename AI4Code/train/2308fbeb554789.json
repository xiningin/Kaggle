{"cell_type":{"0423e0e3":"code","dbfaadc3":"code","0db0330b":"code","73af14e3":"code","3cb989dc":"code","edc61d01":"code","5a5a0dbc":"code","195241aa":"code","527cc872":"code","a07b936e":"code","c6477b44":"code","bfa9f643":"code","e34e64a4":"code","d0259266":"code","b62863b8":"code","c63d9b14":"code","c0e616f4":"code","b0363cc5":"code","ba5f34cf":"code","a86ebedd":"code","d8fba81b":"code","e12a8250":"code","fbb053ed":"code","81415fa0":"code","48c8dafa":"code","c8d19ce7":"code","959a112b":"code","d41ae4e3":"code","c30b710e":"code","eab73497":"markdown","39f7d0c3":"markdown","5c27599e":"markdown","cdc17564":"markdown","69c6ce8d":"markdown","38ecd489":"markdown","e80d3c67":"markdown","99212594":"markdown","8d66b510":"markdown","0ee371d0":"markdown","fcaaa4aa":"markdown","44ac4694":"markdown","6a48c5f5":"markdown","d89affaa":"markdown","3fb63a9c":"markdown","e0af8659":"markdown","6b8882d6":"markdown"},"source":{"0423e0e3":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Bidirectional, CuDNNGRU, Reshape, GlobalMaxPooling1D, GlobalAveragePooling1D, Input, concatenate, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score","dbfaadc3":"df_train = pd.read_json('..\/input\/train.json')\ndf_test = pd.read_json('..\/input\/test.json')","0db0330b":"print(\"Number of train sample : \", df_train.shape[0])\nprint(\"Number of test sample : \", df_test.shape[0])","73af14e3":"df_train.head()","3cb989dc":"plt.figure(figsize=(12,8))\nsns.countplot(df_train['is_turkey'])\nplt.show()","edc61d01":"df_train.info()","5a5a0dbc":"df_test.info()","195241aa":"df_train[\"length\"] = df_train['audio_embedding'].apply(len)","527cc872":"plt.figure(figsize=(12,8))\nplt.yscale('log')\nsns.countplot(\"length\", hue=\"is_turkey\", data=df_train)\nplt.show()","a07b936e":"max_len = 10\nfeature_size = 128","c6477b44":"from keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split","bfa9f643":"X = pad_sequences(df_train['audio_embedding'], maxlen=10, padding='post')\nX_test = pad_sequences(df_test['audio_embedding'], maxlen=10, padding='post')","e34e64a4":"y = df_train['is_turkey'].values","d0259266":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n\nprint(f\"Training on {X_train.shape[0]} texts\")","b62863b8":"def build_model():\n    inp = Input(shape=(max_len, feature_size))\n    x = BatchNormalization()(inp)\n    x = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n    x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n    avg_pool = GlobalAveragePooling1D()(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    concat = concatenate([avg_pool, max_pool])\n    concat = Dense(64, activation=\"relu\")(concat)\n    concat = Dropout(0.5)(concat)\n    output = Dense(1, activation=\"sigmoid\")(concat)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n    return model","c63d9b14":"model = build_model()","c0e616f4":"model.summary()","b0363cc5":"reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, min_lr=1e-8)","ba5f34cf":"epochs = 30","a86ebedd":"history = model.fit(X_train, y_train, batch_size=256, epochs=epochs, validation_data=[X_val, y_val], callbacks=[reduce_lr], verbose=2)","d8fba81b":"plt.figure(figsize=(12,8))\nsns.lineplot(range(1, epochs+1), history.history['acc'], label='Train Accuracy')\nsns.lineplot(range(1, epochs+1), history.history['val_acc'], label='Test Accuracy')\nplt.show()","e12a8250":"val = model.evaluate(X_val, y_val, verbose=1)\nprint(\"Accuracy on validation data : \", val[1])","fbb053ed":"model_final = build_model()","81415fa0":"history_final = model_final.fit(X, y, epochs=30, batch_size=256, verbose=2)","48c8dafa":"plt.figure(figsize=(10,6))\nsns.lineplot(range(1, 31), history_final.history['acc'], label='Train Accuracy')\nplt.show()","c8d19ce7":"y_test = model_final.predict(X_test, verbose=1)","959a112b":"submission = pd.DataFrame({'vid_id': df_test['vid_id'].values, 'is_turkey': list(y_test.flatten())})","d41ae4e3":"submission.head()","c30b710e":"submission.to_csv(\"submission.csv\", index=False)","eab73497":"We will pad our videos to 10.","39f7d0c3":"We can see that the model converges quite fast, 10 epochs is enough.","5c27599e":"### Callbacks\n* When the network is not improving its performances, it reduces its learning rate.","cdc17564":"Not a lot of samples, this is going to be fast to train","69c6ce8d":"Nothing is missing !","38ecd489":"## Model","e80d3c67":"## Loading Data","99212594":"Data is approximately balanced.","8d66b510":"# Winner Winner Turkey Dinner ! \n### A First Approach to Turkey Sounds Detection\n\nCurrent Leaderboard score : 0.990\n\n*Feel free to fork, but please upvote if you do !*","0ee371d0":"#### The model is the following:\n* BatchNormalization : Normalizes the Data\n* Two Bidirectionnal CuDNNGRU : They are recurrent layers optimized for GPU. The idea is that they can interprete the temporal aspect of our data.\n* Pooling Layers : Select the Average or Maximum value in the temporal axis. I use both and concatenate the outputs.\n* Dense + ReLu : To get some extra info\n* Dense + sigmoid : The output layer, to get the score between 0 and 1 ","fcaaa4aa":"### Predictions","44ac4694":"### Thanks for reading !","6a48c5f5":"## Video Lengths\nThis will be used for padding","d89affaa":"## Data for the network\nWe apply padding, for inputs to have the same length, and then split to evaluate our model.","3fb63a9c":"### Fitting","e0af8659":"### Learning Curves","6b8882d6":"## Submission\nLet us now train a model on the entire train set. We will gain a bit with that."}}