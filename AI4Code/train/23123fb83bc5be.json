{"cell_type":{"b2fbe319":"code","e8763d2d":"code","216182ea":"code","51ff867e":"code","c6f7dd41":"code","a004231b":"code","3e0b6e81":"code","3ef5dad1":"code","61cd5987":"code","d9b93068":"code","265556d2":"code","dd71615c":"code","08be5eb3":"code","92b45660":"code","80544551":"code","fcef5b40":"code","f503cc9c":"code","1a4cdc35":"code","a1bd557a":"code","057a011b":"code","5b2da4e9":"code","d973748f":"code","523893fa":"code","f3fbc15b":"code","f1a0afaf":"code","2ffdf954":"code","20224148":"code","90ace00b":"code","8e1b6273":"code","c668c5a5":"code","1f4ed61b":"code","f3997d02":"code","580e6424":"code","1fef9a4b":"code","a5fd1803":"code","791b0e5a":"code","93760845":"code","cb37abcb":"code","99a56701":"code","2f2250ad":"markdown","6d5cba05":"markdown","20af1847":"markdown","4d7a5a21":"markdown","2fc332ab":"markdown","1d8aab87":"markdown","dcdbb93b":"markdown","1dfe8b57":"markdown","29988414":"markdown","de2b431c":"markdown","157a218e":"markdown","3dee6736":"markdown","d50b1f1a":"markdown","3a364cc1":"markdown","17c099f5":"markdown","c6e227fe":"markdown","5c30dadc":"markdown","8261f70b":"markdown","b5eb82d2":"markdown","48eca2b9":"markdown","8e70b22f":"markdown","e03f68ec":"markdown","408d881d":"markdown","65d6d364":"markdown","d1b8ffdc":"markdown"},"source":{"b2fbe319":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport numpy.random as rnd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","e8763d2d":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nprint(train.shape)\ntrain.head()","216182ea":"print(test.shape)\ntest.head()","51ff867e":"len_train = len(train)","c6f7dd41":"dataset = pd.concat([train, test], ignore_index=True)\nprint(dataset.shape)\ndataset.head()","a004231b":"dataset.describe()","3e0b6e81":"sns.barplot(x='Sex', y='Survived', data=train)","3ef5dad1":"sns.barplot(x= 'Pclass', y='Survived', data=train)","61cd5987":"sns.barplot(x='Embarked', y='Survived', data=train)","d9b93068":"sns.violinplot(x='Survived', y= 'Age', data=train)","265556d2":"dataset.isnull().sum()","dd71615c":"age_mean = dataset['Age'].mean()\nage_std = dataset['Age'].std()\nnan_count = dataset['Age'].isnull().sum()\ndataset['Age'][np.isnan(dataset['Age'])] = rnd.randint(age_mean - age_std, age_mean + age_std, size= nan_count)","08be5eb3":"dataset = dataset.drop(['Cabin', 'Ticket'], axis =1)","92b45660":"dataset['Fare'][np.isnan(dataset['Fare'])] = dataset['Fare'].mean()","80544551":"top = dataset['Embarked'].describe().top\ndataset['Embarked'] = dataset['Embarked'].fillna(top)","fcef5b40":"dataset['Sex'] = dataset['Sex'].map({'male':0, 'female':1})","f503cc9c":"dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q':2})","1a4cdc35":"print(dataset.isnull().sum())\ndataset.head()","a1bd557a":"title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\ndataset['Title'] = pd.Series(title)\ndataset['Title'].head()","057a011b":"dataset['Title'].describe()","5b2da4e9":"sns.countplot(x=\"Title\",data=dataset)","d973748f":"g = sns.countplot(x=\"Title\",data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45) ","523893fa":"dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don',\n                                             'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1,\n                                         \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndataset[\"Title\"] = dataset[\"Title\"].astype(int)","f3fbc15b":"g = sns.countplot(dataset[\"Title\"])\ng = g.set_xticklabels([\"Master\",\"Miss\/Ms\/Mme\/Mlle\/Mrs\",\"Mr\",\"Rare\"])","f1a0afaf":"g = sns.factorplot(x=\"Title\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","2ffdf954":"dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)\n","20224148":"dataset.head()","90ace00b":"train = dataset[:len_train]\ntest = dataset[len_train:]\ntest.drop(['Survived'], axis=1, inplace=True)","8e1b6273":"Y_train = train['Survived'].astype(int)\nX_train = train.drop(['Survived'], axis=1)\nX_train.drop(labels=[\"PassengerId\"], axis=1, inplace=True)","c668c5a5":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n","1f4ed61b":"X_train.head()","f3997d02":"clf_log = LogisticRegression()\nclf_log.fit(X_train, Y_train)\nacc_log = round(clf_log.score(X_train, Y_train)*100, 2)\nacc_log","580e6424":"clf_rnd = RandomForestClassifier()\nclf_rnd.fit(X_train, Y_train)\nacc_rnd = round(clf_rnd.score(X_train, Y_train)*100, 2)\nacc_rnd","1fef9a4b":"clf_svc = LinearSVC()\nclf_svc.fit(X_train, Y_train)\nacc_svc = round(clf_svc.score(X_train, Y_train)*100, 2)\nacc_svc","a5fd1803":"clf_knc = KNeighborsClassifier()\nclf_knc.fit(X_train, Y_train)\nacc_knc = round(clf_knc.score(X_train, Y_train)*100, 2)\nacc_knc","791b0e5a":"clf_gc = GaussianNB();\nclf_gc.fit(X_train, Y_train)\nacc_gc = round(clf_gc.score(X_train, Y_train)*100, 2)\nacc_gc","93760845":"y_rnd = clf_rnd.predict(test)\n","cb37abcb":"\nsubmission = pd.DataFrame({\n    \"PassengerId\": test['PassengerId'],\n    \"Survived\": y_rnd\n})\n","99a56701":"submission.to_csv('submission.csv', sep=',', encoding='utf-8', index=False)","2f2250ad":"#### Lets Import some Libraries !!","6d5cba05":"##### Extracting titles from name","20af1847":"### Visualisation\nLets plot some graph to get better Insights.","4d7a5a21":"Age has 267 Null values.\nSurvived - Since we have concatenated test and train data, the 418 null values are from test set which need not be filled.\nEmbarked - Since there are only 2 null values, we will fill it with the most Embarked one.\nSince cabin has too many empty values, lets drop that column.\nSince Ticket has not much Corelation with Survival, we will drop that too.\n","2fc332ab":"#### About the Problem :-\n\nThis is a Binary classification problem where we have to predict only Yes(1, true) or No(0, false). \nSo these are the following steps which we will follow - \n1. Data Analysis - \n a. Check the type and  number of Features (Inputs) and trying to remove any unwanted features which             may not help in prediction.\n b. Join train and test dataset and try to fill Null values \n                   \n2. Visualisation - \na. Plot Graphs.\nb. Try to find Co-relation between different features and Survival.\n                   \n3. Feature Engineering - \na. Adding additional features which may help in Survival prediction.\n\n4. Modelling - \na.Try to predict output using various Models.","1d8aab87":"#### converting Categorical data to Numerical ","dcdbb93b":"As we see, females have got a better chance of Survival ","1dfe8b57":"#### Concatenate both Train and Test datasets for data cleaning","29988414":"#### Filling Null values","de2b431c":"#### Lets predict the test data output using random forest classifier","157a218e":"#### Sex vs Survival","3dee6736":"#### Hope this Notebook has helped you in getting started with kaggle. Please upvote if you have liked it.","d50b1f1a":"Filling Age null Values with random numbers generated between its mean and standard deviation.","3a364cc1":"Add the result y_rnd to submission dataframe and submit the created file on Kaggle.","17c099f5":"### Modelling","c6e227fe":"After checking accuracies of various Algorithms, we see that RandomForestClassifier has highest accuracy (Infact i think it has overfit the data, we should decrease the variance by  adding more features and  normalize the data) . Will do that soon.","5c30dadc":"Those who embarked at port C had better Survival chances","8261f70b":"#### PClass vs Survival","b5eb82d2":"#### Loading Train and Test Data","48eca2b9":"As we see from the Violin plot, younger children and old people had more Survival rate. ","8e70b22f":"### Feature Engineering","e03f68ec":"#### Age vs Survival","408d881d":"Seperating the train and test data from the concatenated dataframe.","65d6d364":"#### Embarked vs Survival","d1b8ffdc":"# Titanic Survival Prediction"}}