{"cell_type":{"c3e3d6f6":"code","aa592217":"code","feb5349c":"code","7d2fd587":"code","a2939f52":"code","911aa865":"code","737aca80":"code","94ded760":"code","d9364ea9":"code","cb2b44e6":"markdown","5da6285e":"markdown","5b78de09":"markdown"},"source":{"c3e3d6f6":"# Desired output size.\nRESIZED_WIDTH, RESIZED_HEIGHT = 224, 224\nOUTPUT_FORMAT = \"png\"\n\nOUTPUT_DIR = \"output\"","aa592217":"import glob\n\nimport joblib\n\nimport numpy as np\n\nimport PIL\n\nimport pydicom\n\nimport tqdm","feb5349c":"data_dir = \"..\/input\/rsna-intracranial-hemorrhage-detection\/rsna-intracranial-hemorrhage-detection\"\n!ls {data_dir}","7d2fd587":"train_dir = \"stage_2_train\"\ntrain_paths = glob.glob(f\"{data_dir}\/{train_dir}\/*.dcm\")\nprint(len(train_paths))","a2939f52":"def get_patient_id(img_path):\n    img_dicom = pydicom.read_file(img_path)\n    return img_dicom.PatientID","911aa865":"get_patient_id(train_paths[0])","737aca80":"from collections import defaultdict \nfrom tqdm import tqdm\nimport random\ndict_id = defaultdict(list)\nrandom.shuffle(train_paths)\n#print(train_paths)\nfor img_path in tqdm(train_paths):\n    patient_id = get_patient_id(img_path)\n    path = img_path[101:114] + 'png'\n    dict_id[patient_id].append(path)\nlen(dict_id)\n","94ded760":"!apt-get install zip","d9364ea9":"import numpy as np\n\n!mkdir -p {OUTPUT_DIR}\/{train_dir}\n\nnp.save('.\/output\/stage_2_train\/my_file.npy', dict_id) \n!zip resized.zip .\/output\/stage_2_train -r\n!rm .\/output\/stage_2_train -r ","cb2b44e6":"# Get images paths","5da6285e":"Dataset URL: https:\/\/www.kaggle.com\/guiferviz\/rsna_stage1_png_128\n\n# Preparing dataset\n\nThe DICOM format is so cool, but I prefer normal images :)\n\nWith 156GB (compressed) it is very difficult to work with the resources of the vast majority of the mortals.\nThis notebook shows you how to scale down all the images and create a new dataset easier to deal with.\nEven with the best computing resources, I don't think it's necessary to use the original size to get good accuracy.\n\nIMPORTANT: In this notebook runs in a subset of the data, so don't use the generated output. That is because the Kaggle notebook runs out of space if you use all the examples. If you want to run this by yourself you should run it in a different machine or opening the next notebook https:\/\/colab.research.google.com\/gist\/guiferviz\/50912a681776d5afe012b1a9259bd637\/resize-dataset.ipynb in Google Colab. If you try to unzip the data in Google Colab you will also run out of space, so I've used the amazing tool *fuse-zip* to mount the zip and work with the files in it without extracting any of those.\n\nSome code taken from:\n* https:\/\/www.kaggle.com\/omission\/eda-view-dicom-images-with-correct-windowing\n* https:\/\/www.kaggle.com\/c\/rsna-intracranial-hemorrhage-detection\/discussion\/109649#latest-631701\n\n# Constants","5b78de09":"# Imports"}}