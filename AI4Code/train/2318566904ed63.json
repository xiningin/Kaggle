{"cell_type":{"f72e234b":"code","afbac07b":"code","5f05f472":"code","0a91c288":"code","36faed8a":"code","e283a94f":"code","c5e5a0e3":"code","6b0aa9f0":"code","d6ac86b7":"code","1d6184f7":"code","7140b173":"code","5fac7a6f":"code","74c21fbf":"code","16bfcdc1":"code","f459ba83":"code","f5ea25f7":"code","6f479b9b":"code","b0b6b05b":"code","db11ca59":"code","ec58d782":"code","3f91d3e9":"code","abb1f0fe":"code","d382f155":"code","609ec60a":"code","908ce894":"code","de4dabd0":"code","8481c3ff":"code","b7001310":"code","66d53edc":"code","f2d213f7":"code","c8e892bc":"code","7cce59b2":"code","a1ee7d9d":"code","9536f921":"code","7a9e6ab4":"code","04f5b944":"code","6e54bb8a":"code","3550031a":"code","51f8c3ff":"code","832993c5":"code","2fd5592f":"code","5da4116f":"code","41e49e46":"code","85019c53":"code","141ae997":"code","4b37cd04":"code","1fb70467":"code","0b17ef2d":"code","af4faca2":"code","3c7b58f5":"code","ef1aa250":"code","6a1cd9ad":"code","706d0f56":"code","2645aa44":"code","84f90e65":"code","db67b239":"markdown","ce12f097":"markdown","264442cc":"markdown","420fd8a3":"markdown","fad177b3":"markdown","3b40d7db":"markdown","4194afec":"markdown","bdd926db":"markdown","90fc310d":"markdown","3e5afc70":"markdown","85fbf2a4":"markdown","36dd72a8":"markdown","b5ff9d9e":"markdown","052939f4":"markdown","f9efb322":"markdown","ec5174ed":"markdown","aaa32870":"markdown","c9a96853":"markdown","40eb5276":"markdown","aa8e78b7":"markdown","c24d0f12":"markdown","16ae25f9":"markdown"},"source":{"f72e234b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n%matplotlib inline","afbac07b":"business=pd.read_csv(\"..\/input\/yelp_business.csv\")","5f05f472":"business.head()","0a91c288":"x = business['stars'].value_counts().index\ny = business['stars'].value_counts().values","36faed8a":"plt.figure(figsize=(9,6))\nax= sns.barplot(x, y,data= business ,alpha=0.8 )\nplt.title(\"Ratings Distribution\")\nplt.xlabel('Ratings ', fontsize=12)","e283a94f":"plt.figure(figsize=(9,6))\nax= sns.barplot(x = 'stars', y='review_count',data= business ,alpha=0.8 )\nplt.title(\"Ratings Distribution\")\nplt.xlabel('Ratings ', fontsize=12)","c5e5a0e3":"business['categories'].head()","6b0aa9f0":"business_cat=' '.join(business['categories'])","d6ac86b7":"categry=pd.DataFrame(business_cat.split(';'),columns=['category'])","1d6184f7":"x = categry.category.value_counts()","7140b173":"x=x.sort_values(ascending=False)\nx=x.iloc[0:20]","5fac7a6f":"plt.figure(figsize=(16,4))\nax = sns.barplot(x.index, x.values, alpha=0.8)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","74c21fbf":"x = business['city'].value_counts().sort_values(ascending = False)\nx=x.iloc[0:25]","16bfcdc1":"plt.figure(figsize=(16,4))\nax = sns.barplot(x.index, x.values, alpha=0.8)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","f459ba83":"x = business['name'].value_counts().sort_values(ascending = False)\n\nx=x.iloc[0:25]","f5ea25f7":"plt.figure(figsize=(16,4))\nax = sns.barplot(x.index, x.values, alpha=0.8)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","6f479b9b":"busi_attr = pd.read_csv('..\/input\/yelp_review.csv') ","b0b6b05b":"busi_attr = busi_attr[:100000]","db11ca59":"from collections import Counter\nfrom nltk.tokenize import RegexpTokenizer\nfrom stop_words import get_stop_words\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk import sent_tokenize, word_tokenize","ec58d782":"nltk.download('punkt')","3f91d3e9":"a = busi_attr['text'].str.lower().str.cat(sep=' ')","abb1f0fe":"import re","d382f155":"b = re.sub('[^A-Za-z]+', ' ', a)","609ec60a":"b[:1000]","908ce894":"stop_words = list(get_stop_words('en'))         \nnltk_words = list(stopwords.words('english'))   \nstop_words.extend(nltk_words)","de4dabd0":"word_tokens = word_tokenize(b)","8481c3ff":"len(word_tokens)","b7001310":"filtered_sentence = []\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)","66d53edc":"len(filtered_sentence)","f2d213f7":"# Remove characters which have length less than 2  \nwithout_single_chr = [word for word in filtered_sentence if len(word) > 2]\n\n# Remove numbers\ncleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]   ","c8e892bc":"top_N = 100\nword_dist = nltk.FreqDist(cleaned_data_title)\nrslt = pd.DataFrame(word_dist.most_common(top_N),\n                    columns=['Word', 'Frequency'])\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt.head(7))","7cce59b2":"from wordcloud import WordCloud, STOPWORDS","a1ee7d9d":"def wc(data,bgcolor,title):\n    plt.figure(figsize = (100,100))\n    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50)\n    wc.generate(' '.join(data))\n    plt.imshow(wc)\n    plt.axis('off')","9536f921":"wc(cleaned_data_title,'black','Most Used Words')","7a9e6ab4":"from textblob import TextBlob\n\nbloblist_desc = list()\n\ndf_review_str=busi_attr['text'].astype(str)","04f5b944":"for row in df_review_str:\n    blob = TextBlob(row)\n    bloblist_desc.append((row,blob.sentiment.polarity, blob.sentiment.subjectivity))\n    df_polarity_desc = pd.DataFrame(bloblist_desc, columns = ['Review','sentiment','polarity'])","6e54bb8a":"df_polarity_desc.head()","3550031a":"def f(df_polarity_desc):\n    if df_polarity_desc['sentiment'] > 0:\n        val = \"Positive Review\"\n    elif df_polarity_desc['sentiment'] == 0:\n        val = \"Neutral Review\"\n    else:\n        val = \"Negative Review\"\n    return val","51f8c3ff":"df_polarity_desc['Sentiment_Type'] = df_polarity_desc.apply(f, axis=1)\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.countplot(x=\"Sentiment_Type\", data=df_polarity_desc)","832993c5":"positive_reviews=df_polarity_desc[df_polarity_desc['Sentiment_Type']=='Positive Review']\nnegative_reviews=df_polarity_desc[df_polarity_desc['Sentiment_Type']=='Negative Review']","2fd5592f":"negative_reviews.head()","5da4116f":"wc(positive_reviews['Review'],'black','Most Used Words')","41e49e46":"wc(negative_reviews['Review'],'black','Most Used Words')","85019c53":"busi_attr=busi_attr.dropna(axis=0,how='any')\nrating_class = busi_attr[(busi_attr['stars'] == 1) | (busi_attr['stars'] == 5)]\nX_review=rating_class['text']\ny=rating_class['stars']","141ae997":"import string\ndef text_process(review):\n    nopunc=[word for word in review if word not in string.punctuation]\n    nopunc=''.join(nopunc)\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","4b37cd04":"from sklearn.feature_extraction.text import CountVectorizer\nbow_transformer=CountVectorizer(analyzer=text_process).fit(X_review)","1fb70467":"X_review = bow_transformer.transform(X_review)","0b17ef2d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)","af4faca2":"X_train","3c7b58f5":"from sklearn.svm import SVC\nsv_model = SVC()\nsv_model.fit(X_train, y_train)\nY_pred = sv_model.predict(X_test)","ef1aa250":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nprint(confusion_matrix(y_test, Y_pred))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, Y_pred))\nprint(classification_report(y_test, Y_pred))","6a1cd9ad":"from sklearn.linear_model import LogisticRegression\nlg_model = LogisticRegression()\nlg_model.fit(X_train, y_train)\nY_pred = lg_model.predict(X_test)","706d0f56":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nprint(confusion_matrix(y_test, Y_pred))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, Y_pred))\nprint(classification_report(y_test, Y_pred))","2645aa44":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(X_train, y_train)\npredict=nb.predict(X_test)","84f90e65":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nprint(confusion_matrix(y_test, predict))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, predict))\nprint(classification_report(y_test, predict))","db67b239":"Using Naive Bayes","ce12f097":"Cities with most business ","264442cc":"Let us create a wordcloud ","420fd8a3":"Using Logistic Regression","fad177b3":"Based on my analysis, I have selected these values however you could use based on your insights","3b40d7db":"Let us look at the wordcloud of the most used words in a negative review","4194afec":"Let us create a bag of words consisting of all the reviews!","bdd926db":"We can see we have the best accuracy with Logistic regression. \n\n\nIn SVM the given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes the new examples.\n\nNaive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naive) independence assumptions between the features.\n\nNa\u00efve Bayes is probabilistic in nature, while the SVM one is geometric.\n\nThe features point of view is that Naive Bayes treats them as independent, whereas SVM looks at the interactions.\n\n\n\n\nNaive Bayes classifier (nBc) makes two bold assumptions:\n1)The probability of occurrence of any word given the class label, is independent of the probability of occurrence of any other word, given that label.\n2)The probability of occurrence of a word in a document, is independent of the location of that word within the document(!).\n\nLogistic regression measures the relationship between a output variable Y (categorical) and one or more independent variables, which are usually (but not necessarily) continuous, by using probability scores as the predicted values of the dependent variable.\n\nIn short Naive Bayes has a higher bias but lower variance compared to logistic regression. If the data set follows the bias then Naive Bayes will be a better classifier. \n\n","90fc310d":"Let us find the most frequently used words in the reviews!","3e5afc70":"Let us now train a model We are taking only review with ratings 1 and 5 to perform the analysis to make the analysis more simple.","85fbf2a4":"Using SVM","36dd72a8":"Let us check the review count based on the rating","b5ff9d9e":"Types of Business","052939f4":"Let us try to perform analysis on the entire review rather than all the words. For this we make use of the TextBlob","f9efb322":"Let us look at the wordcloud of the most used words in a positive review","ec5174ed":"After removing the stop words, we can see reduction of size by 50 percent","aaa32870":"### EDA on the reviews","c9a96853":"### Using machine learning to predict whether a review has 1 star rating or 5 star rating","40eb5276":"Most reviwed business","aa8e78b7":"As the data is huge it is not possible for my system to perform analysis on the entire dataset, but if it is possible with your system try using more reviews. <br> I have selected data from 100,000 reviews.","c24d0f12":"Let us check the rating distribution","16ae25f9":"### EDA"}}