{"cell_type":{"8df6829b":"code","a082e176":"code","6025acda":"code","cff3fa1f":"code","5a3d7d2e":"code","d9253dfc":"code","0ef2dc7f":"code","4d947a41":"code","7d82d932":"code","804080ca":"code","ec18b28e":"code","fdf6c94c":"code","b627eabd":"code","90371f1f":"code","e6e375ef":"markdown","2fc2f3ab":"markdown","e64993ea":"markdown","f32afaf2":"markdown","711c6a68":"markdown","85099b7a":"markdown","fe3b3139":"markdown","153e44cd":"markdown","1e614f55":"markdown","af089a66":"markdown","7f3fb5d3":"markdown","361ca6de":"markdown","f0a2beeb":"markdown","ad4ecc6c":"markdown"},"source":{"8df6829b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","a082e176":"ii=1\nwith open('\/kaggle\/input\/coronavirusgenometxt\/Complete sequences.txt','r') as readfile:\n    with open('hasilSekuensComplete.txt','w') as writefile:\n        for line in readfile:\n            if (line[0]!='>'):\n                writefile.write(line[0:len(line)-1])\n            else:\n                writefile.write('\\n')\n                ii=ii+1","6025acda":"baris=0\nkolom=0\nwith open('\/kaggle\/input\/coronavirusgenometxt\/hasilSekuensComplete.txt','r') as readfile:\n    for line in readfile:\n        baris=baris+1\n        if (len(line)>kolom):\n            kolom=len(line)\nprint('Input matrix dimension= ',baris,' x ',kolom)\nInputData=np.zeros((baris, kolom))\n\nnp.save('InputData.npy', InputData)","cff3fa1f":"\nInputData = np.load('InputData.npy')\nwith open('\/kaggle\/input\/coronavirusgenometxt\/hasilSekuensComplete.txt','r') as readfile:\n    ii=0;\n    for line in readfile:\n        for jj in range (0,len(line)-1):\n            if line[jj]=='T':\n                InputData[ii,jj]=1\n            elif line[jj]=='C':\n                InputData[ii,jj]=2\n            elif line[jj]=='A':\n                InputData[ii,jj]=3\n            elif line[jj]=='G':\n                InputData[ii,jj]=4\n            else:\n                InputData[ii,jj]=0\n        ii=ii+1\nprint('Mapping result:')\nprint(InputData)\nnp.save('InputDataInteger.npy', InputData)\n","5a3d7d2e":"import keras\nfrom matplotlib import pyplot as plt\nimport numpy as np\n#import gzip\n%matplotlib inline\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom tensorflow.keras.utils import plot_model\n#from keras.optimizers import RMSprop","d9253dfc":"InputData = np.load('\/kaggle\/input\/coronavirusgenometxt\/InputDataInteger.npy')","0ef2dc7f":"# Model AutoEncoder 1 (500, 250, 100, 50, 10)\nInputDim = InputData.shape[1]\n# Encoder\ninput_encoder = Input(shape=(InputDim,))\nencoded1 = Dense(500, activation='relu')(input_encoder)\nencoded2 = Dense(250, activation='relu')(encoded1)\nencoded3 = Dense(100, activation='relu')(encoded2)\nencoded4 = Dense(50, activation='relu')(encoded3)\noutput_encoder = Dense(10, activation='relu')(encoded4)\nencoder = Model(input_encoder, output_encoder, name='encoder')\nencoder.summary()\n\n# Decoder\ninput_decoder = Input(shape=(10,))\ndecoded1 = Dense(50, activation='relu')(input_decoder)\ndecoded2 = Dense(100, activation='relu')(decoded1)\ndecoded3 = Dense(250, activation='relu')(decoded2)\ndecoded4 = Dense(500, activation='relu')(decoded3)\noutput_decoder = Dense(InputDim, activation='relu')(decoded4)\ndecoder = Model(input_decoder, output_decoder, name='decoder')\ndecoder.summary()\n\n# Autoencoder\nautoencoder = Model(input_encoder,\n                    decoder(encoder(input_encoder)),\n                    name='autoencoder')\nautoencoder.compile(loss='mse', optimizer='adam')\nautoencoder.summary()","4d947a41":"# Model AutoEncoder 2 (500, 250, 100, 50)\nInputDim = InputData.shape[1]\n# Encoder\ninput_encoder = Input(shape=(InputDim,))\nencoded1 = Dense(500, activation='relu')(input_encoder)\nencoded2 = Dense(250, activation='relu')(encoded1)\nencoded3 = Dense(100, activation='relu')(encoded2)\noutput_encoder = Dense(50, activation='relu')(encoded3)\nencoder = Model(input_encoder, output_encoder, name='encoder')\nencoder.summary()\n\n# Decoder\ninput_decoder = Input(shape=(50,))\ndecoded1 = Dense(100, activation='relu')(input_decoder)\ndecoded2 = Dense(250, activation='relu')(decoded1)\ndecoded3 = Dense(500, activation='relu')(decoded2)\noutput_decoder = Dense(InputDim, activation='relu')(decoded3)\ndecoder = Model(input_decoder, output_decoder, name='decoder')\ndecoder.summary()\n\n# Autoencoder\nautoencoder = Model(input_encoder,\n                    decoder(encoder(input_encoder)),\n                    name='autoencoder')\nautoencoder.compile(loss='mse', optimizer='adam')\nautoencoder.summary()","7d82d932":"# Model AutoEncoder 3 (500, 250, 100)\nInputDim = InputData.shape[1]\n# Encoder\ninput_encoder = Input(shape=(InputDim,))\nencoded1 = Dense(500, activation='relu')(input_encoder)\nencoded2 = Dense(250, activation='relu')(encoded1)\noutput_encoder = Dense(100, activation='relu')(encoded2)\nencoder = Model(input_encoder, output_encoder, name='encoder')\nencoder.summary()\n\n# Decoder\ninput_decoder = Input(shape=(100,))\ndecoded1 = Dense(250, activation='relu')(input_decoder)\ndecoded2 = Dense(500, activation='relu')(decoded1)\noutput_decoder = Dense(InputDim, activation='relu')(decoded2)\ndecoder = Model(input_decoder, output_decoder, name='decoder')\ndecoder.summary()\n\n# Autoencoder\nautoencoder = Model(input_encoder,\n                    decoder(encoder(input_encoder)),\n                    name='autoencoder')\nautoencoder.compile(loss='mse', optimizer='adam')\nautoencoder.summary()","804080ca":"from sklearn.model_selection import KFold\nfrom numpy import savetxt\n \nn_split=5\nii=1\nkf=KFold(n_split)\n#autoencoder.load_weights('ae_weights.npy')\n\nfor train_index, val_index in kf.split(InputData):\n    x_train,x_test=InputData[train_index],InputData[val_index]\n    y_train,y_test=InputData[train_index],InputData[val_index]\n    autoencoder.fit(x_train, y_train,epochs=10)\n    evalModel =  autoencoder.evaluate(x_test,y_test)\n    print('Model evaluation ',evalModel)\nautoencoder.save_weights('ae_weights.npy')","ec18b28e":"autoencoder.load_weights('ae_weights.npy')\nsekuens_reduced = encoder.predict(InputData)\nprint('size before reduction:', InputData.shape)\nprint('size after reduction :', sekuens_reduced.shape)\nprint(sekuens_reduced)\nnp.save('sekuens_reduced.npy',sekuens_reduced)","fdf6c94c":"from sklearn.cluster import KMeans\nimport numpy as np\nfrom sklearn.metrics import silhouette_samples, silhouette_score","b627eabd":"sse = {}\nlabel_sekuens={}\nsilAvg=-1\nnClustOpt=2\nfor nCluster in range(2, 51):\n    # Train K-means\n    kmeans = KMeans(n_clusters=nCluster, max_iter=100).fit(sekuens_reduced)\n    cluster_labels = kmeans.fit_predict(sekuens_reduced)\n    print(\"Number of iteration: \", kmeans.n_iter_)\n    #print(cluster_labels)\n    \n    # Evaluation using Elbow Method:\n    sse[nCluster] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n    \n    # Evaluation using Silhouette Analysis\n    silhouette_avg = silhouette_score(sekuens_reduced, cluster_labels)\n    print(\"For n_clusters =\", nCluster,\n          \"The average silhouette_score is :\", silhouette_avg)\n    if (silhouette_avg>=silAvg):\n        nClustOpt=nCluster\n\nprint(\"Number of cluster optimum =\", nClustOpt)\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","90371f1f":"kmeans = KMeans(n_clusters=nClustOpt, max_iter=100).fit(sekuens_reduced)\ncluster_labels = kmeans.fit_predict(sekuens_reduced)\n\nimport numpy as np\nnp.savetxt('ClusterLabel.csv', cluster_labels, delimiter=',')","e6e375ef":"Load data:","2fc2f3ab":"Parsing data sekuens genome from file text from Genbank (Fasta files are converted to text files):\nNote: To speed up computing and reuse parsed files, the file is saved again in a txt file, and uploaded to the Kaggle database.","e64993ea":"Save the cluster label result from k-means algorithm:","f32afaf2":"# **SARS-CoV-2 NUCLEOTIDE SEQUENCES CLUSTERING**","711c6a68":"Create Model AutoEncoder (choose one model):\n* Model AutoEncoder 1 (500, 250, 100, 50, 10)\n* Model AutoEncoder 2 (500, 250, 100, 50)\n* Model AutoEncoder 3 (500, 250, 100)","85099b7a":"**Clustering data using K-means**","fe3b3139":"**METHODOLOGY**\n![Figure%206.JPG](attachment:Figure%206.JPG)\nFigure 6. SARS-CoV-2 Sequence Clustering System Diagram.\n\nFigure 6 shows a diagram process of the COVID-19 sequence clustering system. Genome sequence data of patients infected with COVID-19 were obtained from Genbank, The National Center for Biotechnology Information \/ NCBI (https:\/\/www.ncbi.nlm.nih.gov\/genbank\/sars-cov-2-seqs\/) which amounted to 2434 data. The data is stored in .fasta format so that it requires a parsing process for the acquisition of sequence data only, without other information. Mapping DNA sequences is needed to convert DNA sequences into numerical sequences so that they can be processed at a later stage. The mapping technique used in this task is integer representation, where nucleotides T = 1, C = 2, A = 3, and G = 4. Then the padding process is carried out with the number 0 so that the length of the sequence becomes the same and produces a sequence length of 29,946.\n\nTo extract important features in sequence data, feature extraction is performed using the Deep Autoencoder method. The Deep AutoEncoder model that is built consists of Encoder and Decoder, where the Encoder functions to extract features from the data used and also to reduce the dimensions of the data, while the Decoder is used to reconstruct the reduced data into initial data. The model is trained with Adam's optimization algorithm and the Mean Square Error (MSE) loss function, and k-fold Cross Validation, for 100 epochs. To cluster DNA sequence data, the clustering algorithm used is the K-means algorithm, where the evaluation is measured using the Elbow and Silhouette analysis methods.","153e44cd":"Create input matrix and calculate the maximum dimension of sequence data:\nNote: sequences whose length is less than the maximum dimensions, padding will be carried out with a value of 0.","1e614f55":"In this task a system was built to cluster genome data from patients indicated COVID-19 to determine coronavirus variations. The method used is a deep autoencoder for feature extraction and dimensional reduction, K-means for data clustering, and Python programming language.","af089a66":"DNA sequens mapping using integer representation.","7f3fb5d3":"**Deep AutoEncoder for Feature Extraction**","361ca6de":"Dimension reduction using encoder model:","f0a2beeb":"Train and evaluation model using k-fold cross validation:","ad4ecc6c":"**Results and Discussions**\n\nTo test the system performance that has been built, testing is done by comparing experiments with the AutoEncoder 1 model (output feature 10), 2 (output feature 50), and 3 (output feature 100) based on MSE and Time Processing of training and validation process and sequence clustering results with the K-means algorithm. Details of the AutoEncoder model and evaluation used are presented in the Methodology section. Here are some of the results and analysis of the experiments that have been carried out:\n* Comparison of AutoEncoder 1, 2 and 3 models based on MSE calculations and time processing of training and validation process. Based on the results presented in Table 1, the average MSE training and validation in the AutoEncoder models 2 and 3 are better than the AutoEncoder 1 model. This shows that the AutoEncoder 2 and 3 models converge faster than the AutoEncoder 1 model. And the AutoEncoder 2 and 3 models has a faster processing time than the AutoEncoder 1 model.\n![Table%201.JPG](attachment:Table%201.JPG)\n* Comparison of Elbow graph from COVID-19 sequences clustering. Based on the Elbow graph in Figure 2 and Figure 3 (Models 2 and 3) the exact number of clusters cannot be determined for cluster COVID-19 sequence data because there is no point forming the Elbow and then the SSE value is stable. This can be due to the dimension of the data from feature extraction is still too large for the K-means algorithm, so a larger dimension reduction is needed. Whereas in Figure 1 (Model 1), the Elbow graph has converged and formed the Elbow at cluster 12.\n![Figure%201-4.JPG](attachment:Figure%201-4.JPG)\n* Comparison of Silhouette scores for each cluster from COVID-19 sequences clustering. Based on Figure 4, the Silhouette score of Model 1 is higher (close to 1) than Models 2 and 3. This can be due to the smaller number of features and better feature produced by Model 1 than Model 2 and 3 so the K-means algorithm can produce better cluster from these features. Silhouette score close to 1 indicate that the cluster produced is correct and the distance of data in different clusters are far apart.\n* Figure 5 and Table 2 show the distribution of the amount of data based on Geo-Location in each Cluster.\n![Figure%205.png](attachment:Figure%205.png)\nFigure 5. Distribution of the amount of data based on Geo-Location in each Cluster.\n\nTable 2. Distribution of the amount of data based on Geo-Location in each Cluster.\n![Table%202.png](attachment:Table%202.png)\n\n**Cons:**\nThe AutoEncoder training process is carried out in 100 epochs and 5 folds due to the long training time, so the AutoEncoder 1 model has not yet reached the convergence point.\nThe optimal number of clusters produced is 50 with a Silhouette score of 0.8764, which is already very good. However, if viewed from the distribution of the amount of data based on Geo Location in each cluster, there are several data in the same Geo Location that are still very spread to different clusters. Therefore, a re-analysis is needed to cluster the data.\n"}}