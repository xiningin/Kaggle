{"cell_type":{"6b82e2a1":"code","8ce70706":"code","a664756e":"code","278f6727":"code","beefb231":"code","76cd1997":"code","08525130":"code","7d593c94":"code","a73b9f20":"code","33a7cc8e":"code","2cbf5acb":"code","a4f5f1b2":"code","15c7195f":"code","f76a23ed":"code","492b53da":"code","39cddf9f":"code","dcdc496e":"code","8df7e7ee":"code","c78ebb7d":"code","694e6395":"code","0ba057ef":"code","68915ecb":"code","b17f4e36":"code","061b8ff2":"code","9d63cebf":"code","ac6ff82e":"code","1603401c":"code","27b8844d":"code","f4c629f1":"code","0f09c1d3":"code","3ea1bd90":"code","fc1da71b":"code","6b9cc26d":"code","daf03740":"code","a1c42e52":"code","f51ae6c7":"code","4421afd4":"code","9b0a4590":"code","ce6e504b":"code","6bad1111":"code","d1881b8c":"code","6265e684":"code","4836eb61":"code","e2ab5099":"code","e8973dd8":"code","5a322d37":"code","3162b121":"code","a26866e6":"markdown","89abe5f9":"markdown","843a5cef":"markdown","c9a2b6d1":"markdown"},"source":{"6b82e2a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8ce70706":"df=pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","a664756e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom scipy import stats\nfrom scipy.stats import norm\nwarnings.filterwarnings('ignore')","278f6727":"df.head(10)","beefb231":"df.shape","76cd1997":"df.describe().T","08525130":"df.info()","7d593c94":"df.isnull().sum()","a73b9f20":"## checking the balance of the data by plotting the count of outcomes by their value\ncolor_wheel = {1: \"#0392cf\",2: \"#7bc043\"}\ncolors = df[\"age\"].map(lambda x: color_wheel.get(x + 1))\nprint(df.age.value_counts())\np=df['age'].value_counts().plot(kind=\"bar\")","33a7cc8e":"df.duplicated().sum()","2cbf5acb":"df.drop_duplicates(inplace=True)","a4f5f1b2":"df.duplicated().sum() # now i dont has a duplicate ","15c7195f":"df.columns","f76a23ed":"#This is to look at what all unique values have . Just trying to use python\nlist_col=['sex','chol','trtbps','cp','thall','exng']\n\nfor col in list_col: \n    print('{} :{} ' . format(col.upper(),df[col].unique()))","492b53da":"print(f'Number of people having sex as 0 are {df.sex.value_counts()[0]} and Number of people having sex as 1 are {df.sex.value_counts()[1]}')\np = sns.countplot(data=df, x=\"sex\", palette='pastel')\nplt.show()","39cddf9f":"sns.countplot(data=df, x=\"cp\", palette='pastel')","dcdc496e":"sns.countplot(data=df, x=\"thall\", palette='pastel')","8df7e7ee":"sns.countplot(data=df, x=\"exng\", palette='pastel')","c78ebb7d":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(df.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap","694e6395":"df.head(10)","0ba057ef":"#dividing data\nX = df.drop(\"output\",axis = 1)\ny = df.output","68915ecb":"df.reset_index(drop=True, inplace=True)","b17f4e36":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","061b8ff2":"#scalling all data to be with the same scale \nscaler = StandardScaler()","9d63cebf":"columns_to_scale=df.iloc[:,[0,3,4,7,9,]]","ac6ff82e":"columns_to_scale","1603401c":"scaled_values=scaler.fit_transform(columns_to_scale)","27b8844d":"scaled_values","f4c629f1":"# to tranfer scaled_value to dataframe\nscaled_values = pd.DataFrame(scaled_values, columns=columns_to_scale.columns)\nscaled_values","0f09c1d3":"# coneccted all value to gether(scaled and not scaled)\nscaled_df = pd.concat([scaled_values,df.iloc[:,[1,2,5,6,8,10,11,12,13]]],axis=1)\nscaled_df","3ea1bd90":"#importing train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42,shuffle=True, stratify=y)","fc1da71b":"print('X_train shape : ', X_train.shape )\nprint('y_train shape : ', y_train.shape )\nprint('X_test shape : ', X_test.shape )\nprint('y_test shape : ', y_test.shape )","6b9cc26d":"X = scaled_df.drop('output', axis = 1)\ny = scaled_df['output']","daf03740":"#for model building\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport xgboost as xgb","a1c42e52":"key = ['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier','GradientBoostingClassifier','AdaBoostClassifier','XGBClassifier']\nvalue = [LogisticRegression(random_state=9), KNeighborsClassifier(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(), AdaBoostClassifier(), xgb.XGBClassifier()]\nmodels = dict(zip(key,value))","f51ae6c7":"predicted =[]","4421afd4":"X = scaled_df.drop('output', axis = 1)\ny = scaled_df['output']\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","9b0a4590":"for name,algo in models.items():\n    model=algo\n    model.fit(X_train,y_train)\n    predict = model.predict(X_test)\n    acc = accuracy_score(y_test, predict)\n    predicted.append(acc)\n    print(name,acc)","ce6e504b":"plt.figure(figsize = (10,5))\nsns.barplot(x = predicted, y = key, palette='pastel')","6bad1111":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nRFclfModel=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nRFclfModel.fit(X_train,y_train)\n\ny_pred_RFclfModel=RFclfModel.predict(X_test)","d1881b8c":"from sklearn import metrics\nacc_Rf=metrics.accuracy_score(y_test, y_pred_RFclfModel)\nprint(\"Accuracy_RF= :\",acc_Rf)","6265e684":"from sklearn.tree import DecisionTreeClassifier\n#Create a Gaussian Classifier\nDecisionTreeClassifier = DecisionTreeClassifier()\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nDecisionTreeClassifier.fit(X_train,y_train)\n\ny_pred_DecisionTreeClassifier=DecisionTreeClassifier.predict(X_test)","4836eb61":"from sklearn import metrics\nacc_dt=metrics.accuracy_score(y_test, y_pred_DecisionTreeClassifier)\nprint(\"Accuracy_dt = :\",acc_dt)","e2ab5099":"from sklearn.ensemble import AdaBoostClassifier\n#Create a Gaussian Classifier\nAda = AdaBoostClassifier()\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nAda.fit(X_train,y_train)\n\ny_pred_Ada=Ada.predict(X_test)","e8973dd8":"from sklearn import metrics\nacc_Ada=metrics.accuracy_score(y_test, y_pred_Ada)\nprint(\"Accuracy_Ada = :\",acc_Ada)","5a322d37":"data= {'Algo': ['RFclfModel',  'DecisionTreeClassifier',  'Ada'],\n       'Accuricy': [0.75,  0.73,  0.76]}\n\ndf1 = pd.DataFrame(data,columns=['Algo',  'Accuricy'])       ","3162b121":"df1\n","a26866e6":"check if we have a duplicat","89abe5f9":"# Observation:\n\n### There are two sex : 0 and 1\n### The highest cholestrol level is 564 and the lowest is 126.\n### Resting Blood Pressure of individuals vary between 94 to 200.\n### There are 4 types of chest pain.\nexercise induced angina has 2 types (1 = yes; 0 = no)","843a5cef":"since i have 1 duplicat,i should delet it ","c9a2b6d1":"different way for biginer"}}