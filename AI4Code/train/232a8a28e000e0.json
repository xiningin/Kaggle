{"cell_type":{"6aa480ec":"code","14fc8fa8":"code","42b2ba18":"code","6a6aa6e2":"code","5e04dcce":"markdown","a8e0d01d":"markdown","4358ee41":"markdown","d0bae294":"markdown","ba5fe8fe":"markdown"},"source":{"6aa480ec":"import os, math, re\n\nfrom datetime import datetime as dt\nfrom itertools import product\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom tqdm import tqdm\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\npd.set_option('display.max_colwidth', -1)","14fc8fa8":"P_PATH = '..\/input\/house-prices-preprocessed-feature-selected\/'\nB_PATH = '..\/input\/house-prices-advanced-regression-techniques\/'\ndef reload(df, processed=True, index=False):\n    path = P_PATH if processed else B_PATH\n    return pd.read_csv(path + df)\ntrain = reload('train_preprocessed.csv')\nX_test = reload('test_preprocessed.csv')\nX_train = train[[c for c in train.columns if c!='SalePrice']]\ny_train = train.SalePrice.copy()\ny_trans = np.log1p(y_train)\nbase_model = GradientBoostingRegressor(\n    loss='lad'\n    , learning_rate=0.1\n    , n_estimators=5000\n    , subsample=1\n    , min_samples_split=10\n    , min_samples_leaf=1\n    , max_depth=2\n    , max_features=0.4\n    , n_iter_no_change=None\n    , random_state=713\n)\n\ndef RMSE(y_true, y_pred):\n    return -math.sqrt(mean_squared_error(y_true, y_pred))\nrmse_scorer = make_scorer(RMSE)\ndef timer(t):\n    t = dt.now() - t\n    return t.seconds + t.microseconds\/1e6\ndef grid(params\n         , model=base_model\n         , X=X_train, y=y_trans, scorer=rmse_scorer\n        ):\n    complexity = np.product([len(params[l]) for l in params])\n    print(f'Grid search complexity: {complexity}')\n    grid = GridSearchCV(model, params, scoring=scorer\n                        , n_jobs=-1, cv=3, return_train_score=True)\n    t = dt.now()\n    grid.fit(X, y)\n    print(f'Search time: {timer(t)} secs')\n    out = pd.DataFrame(grid.cv_results_)\n    out = out.sort_values(by='rank_test_score').reset_index(drop=True)\n    out['mean_test_scr_delt_pct'] = out.mean_test_score.pct_change(-1)*100\n    return out","42b2ba18":"params = dict(\n    learning_rate = [0.075, 0.08, 0.085, 0.095, 0.1]\n    , n_estimators = np.logspace(3.4,3.9,6).astype(int) #array([2511, 3162, 3981, 5011, 6309, 7943])\n    , max_features = [0.37, 0.39, 0.4, 0.41]\n    , min_samples_split = [8, 9, 10]\n    , max_depth = [2, 3]\n    , min_samples_leaf = [1, 2]\n)\ntest_param = params.keys()\ntest_params = {}\nfor p in test_param:\n    test_params[p] = params[p]\n\noutput = grid(test_params)\nattrbts = ['params', 'mean_fit_time', 'mean_train_score', 'mean_test_score', 'mean_test_scr_delt_pct']\noutput[attrbts].iloc[:20,:].round(4)","6a6aa6e2":"output.drop(columns=[\n    'std_fit_time', 'std_score_time', 'split0_test_score'\n    , 'split1_test_score', 'split2_test_score', 'std_test_score'\n    , 'split0_train_score', 'split1_train_score', 'split2_train_score'\n    , 'std_train_score'\n], inplace=True)\noutput.to_csv('gridsearch_result.csv', index=False)","5e04dcce":"**Version 10 run**\n<br>learning_rate = [0.085, 0.09, 0.095, 0.1, 0.11]\n<br>n_estimators = np.logspace(3.35,3.7,5).astype(int) #array([2238, 2738, 3349, 4097, 5011])\n<br>max_features = [0.35, 0.37, 0.4, 0.43]\n<br>min_samples_split = [8, 9, 10]\n<br>max_depth = [1, 2, 3]\n<br>min_samples_leaf = [1, 2]\n- 1800 models, 18500 secs ~ 5hrs, best score -0.11793\n- `learning_rate` fluctuates between 0.085 and 0.1 but 0.11 is not on top results-> test [0.075, 0.085, 0.095, 0.1]\n- `n_estimators` is best at higher ends -> test np.logspace(3.4,3.9,6).astype(int)\n- `max_features` wanders in the middle -> test [0.37, 0.39, 0.4, 0.41]\n- `min_samples_split` doesn't have a clearly best one -> keeping [8, 9, 10]\n- `max_depth` is at 2 and 3 -> remove 1 [2, 3]\n- `min_samples_leaf` best at 1 but fluctuates to 2 sometimes -> keep [1,2]","a8e0d01d":"## Testing log:\n**Version 6 run**\n<br>loss = ['ls', 'lad']\n<br>learning_rate = [0.07, 0.09, 0.11, 0.13]\n<br>n_estimators = np.logspace(2,3.3,4).astype(int)\n<br>max_features = [0.6, 0.7, 0.8]\n<br>min_samples_split = [3, 5, 9]\n<br>max_depth = [3, 5, 7]\n<br>validation_fraction = [0.1, 0.2]\n<br>n_iter_no_change = [None, 10, 20, 30]\n<br>tol = [1e-4, 1e-3, 1e-2]\n- best `loss` is `lad`\n- best `learning_rate` fluctuating around 0.07 and 0.09 (sometimes upto 0.11) -> change to [0.07, 0.08, 0.09, 0.1, 0.12]\n- best `n_estimators` is between 735 and 1995 -> change to `np.logspace(3,3.4,4).astype(int)`\n- no clear sign on `max_features` -> expand to [0.5, 0.6, 0.7, 0.8, 0.9]\n- no clear sign on `min_samples_split` -> expand to [3, 7, 12, 20]\n- best `max_depth` is primarily 3 -> change to [2, 3, 4]\n- best `n_iter_no_change` is None -> remove all early stopping-related hyperparams.","4358ee41":"**Version 7 run**\n<br>learning_rate = [0.07, 0.08, 0.09, 0.1, 0.12]\n<br>n_estimators = np.logspace(3,3.4,4).astype(int)\n<br>max_features = [0.5, 0.6, 0.7, 0.8, 0.9]\n<br>min_samples_split = [3, 7, 12, 20]\n<br>max_depth = [2, 3, 4]\n- 1200 models, 24k seconds ~ 6.5 hours\n- best `learning_rate` fluctuated between 0.1, 0.0.7 and 0.08 -> test [0.065, 0.075, 0.085, 0.1, 0.15]\n- best `n_estimators` a bit toward 2000 -> test np.logspace(3.2,3.5,4).astype(int)\n- best `max_features` is around 0.5 and 0.6 -> test [0.45, 0.5, 0.6, 0.75]\n- best `min_samples_split` seems better around 7 and 12 -> test [7, 8, 10, 12]\n- `max_depth` should be between 2 and 3 -> [2, 3]\n- test `min_samples_leaf` [1, 3]","d0bae294":"**Version 9 run**\n<br>learning_rate = [0.075, 0.085, 0.095, 0.1]\n<br>n_estimators = np.logspace(3.2,3.6,4).astype(int) #array([1584, 2154, 2928, 3981])\n<br>max_features = [0.35, 0.4, 0.45, 0.55, 0.6]\n<br>min_samples_split = [7, 8, 9, 10]\n<br>max_depth = [2, 3]\n<br>min_samples_leaf = [1, 2]\n- 1280 models, 12000s ~ 3.5hrs, best score -0.11804737\n- `learning_rate` is either 0.1 or 0.085 - seems there are two local optimals here -> test [0.085, 0.09, 0.095, 0.1, 0.11]\n- best `n_estimators` is still at higher end (3981) -> test `np.logspace(3.35,3.7,5).astype(int)`\n- `max_depth` is 2 or higher `learning_rate` and 3 for small `learning_rate`. Let's test `max_depth` in [1, 2, 3]\n- `max_features` is between 0.4 and 0.35 -> test [0.35, 0.37, 0.4, 0.43]\n- `min_samples_split` is more towards 10 -> test [8, 9, 10]\n- `min_samples_leaf` performs like `max_depth` - varying with `learning_rate` -> keep testing [1,2]","ba5fe8fe":"**Version 8 run**\n<br>learning_rate = [0.065, 0.075, 0.085, 0.1, 0.15]\n<br>n_estimators = np.logspace(3.2,3.5,4).astype(int)\n<br>max_features = [0.45, 0.5, 0.6, 0.75]\n<br>min_samples_split = [7, 8, 10, 12]\n<br>max_depth = [2, 3]\n<br>min_samples_leaf = [1, 3]\n- 1280 models, 13500s ~ 4hrs. Best score -0.118616853\n- `learning_rate` seems the best between 0.1 and 0.075 -> test [0.075, 0.085, 0.095, 0.1]\n- `n_estimators` is more towards higher end of np.logspace(3.2,3.5,4).astype(int) -> test np.logspace(3.2,3.6,4).astype(int)\n- `max_features` tends toward lower end -> test [0.35, 0.4, 0.45, 0.55, 0.6]\n- `min_samples_split` should be around 8 -> test [7, 8, 9, 10]\n- `max_depth` still between 2 and 3, with higher `learning_rates` associated with smaller `max_depth` -> keep testing [2, 3]\n- `min_samples_leaf` is strictly 1 -> test [1,2]"}}