{"cell_type":{"44376bd3":"code","5d9cef83":"code","df333d49":"code","42bf73f0":"code","79e7df0c":"code","83041d6a":"code","8fa92abb":"code","c233aa56":"code","dd87386b":"code","b97df027":"code","2572b204":"code","38e71174":"code","2ea50fa1":"code","ed6b123d":"code","9d2c4afd":"code","87f54142":"code","b3816de9":"code","dbb51b90":"code","19cc105f":"code","71c4d578":"code","4c6a0d3a":"code","411cdf9a":"code","0c7dbabe":"code","429ea167":"code","c8b4be28":"code","81eda876":"code","f741dc5b":"markdown","b09e01f3":"markdown","3e1c780d":"markdown","b4ddf0b8":"markdown","bd726659":"markdown","1ef05223":"markdown","ce87d250":"markdown","50d377fe":"markdown","838194d4":"markdown","37546ec1":"markdown","16e63a63":"markdown","5685e779":"markdown","4df8421d":"markdown","1cead3d8":"markdown","c9e07b83":"markdown","d995ad7a":"markdown","b124301f":"markdown","2c814649":"markdown","d686274a":"markdown","0778c0a7":"markdown","475e2031":"markdown","5b911698":"markdown"},"source":{"44376bd3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import plot_confusion_matrix, classification_report, f1_score\nfrom sklearn.model_selection import train_test_split ,GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\n\n#Classification Models:\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\nfrom xgboost import XGBClassifier\n\n#Supress Warnings:\nimport warnings\nwarnings.filterwarnings('ignore')","5d9cef83":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain_df = train_df.set_index(\"PassengerId\")\ntrain_df.head()","df333d49":"#General Info:\ntrain_df.info()","42bf73f0":"#Statistical Summary for Numerical Features:\ntrain_df.describe().T","79e7df0c":"#Check for duplicate rows:\ntrain_df.duplicated(subset=\"Name\",keep=False).sum()","83041d6a":"train_df[train_df.duplicated(subset=\"Ticket\",keep=False)].sort_values(\"Ticket\").head(20)","8fa92abb":"#Check for missing values:\ntrain_df.isnull().sum()\/len(train_df)","c233aa56":"test_df.isnull().sum()\/len(test_df)","dd87386b":"fig, ax = plt.subplots(1, 2, figsize=(12,5))\ntrain_df[\"Sex\"].value_counts().plot(kind='bar',\n                                    title= \"Gender count in the training data\",\n                                    xlabel= 'Sex',\n                                    ylabel= 'Count',\n                                    ax=ax[0])\n\nax[1].set_title(\"Number of survivors per gender\")\nsns.countplot(data=train_df, \n              x=\"Sex\",\n              hue=\"Survived\",\n              ax=ax[1])\n\nplt.show()","b97df027":"sns.displot(data=train_df,\n            x=\"Age\",\n            col=\"Sex\",\n            hue=\"Survived\");","2572b204":"fig, ax = plt.subplots(1, 2, figsize=(12,5))\ntrain_df[\"Pclass\"].value_counts().plot(kind='bar',\n                                    title= \"Pclass count in the training data\",\n                                    xlabel= 'Pclass',\n                                    ylabel= 'Count',\n                                    ax=ax[0])\n\nax[1].set_title(\"Number of survivors per Pclass\")\nsns.countplot(data=train_df, \n              x=\"Pclass\",\n              hue=\"Survived\",\n              ax=ax[1])\n\nplt.show()","38e71174":"ax = sns.catplot(kind=\"point\",\n                 data=train_df,\n                 x=\"Pclass\", \n                 y=\"Fare\",\n                 hue=\"Survived\")\nax.fig.suptitle('Fare per Pclass')\nplt.show()","2ea50fa1":"fig, ax = plt.subplots(1, 3, figsize=(18,5))\ntrain_df[\"Embarked\"].value_counts().plot(kind='bar',\n                                         title= \"Embarked count in the training data\",\n                                         xlabel= 'Embarked',\n                                         ylabel= 'Count',\n                                         ax=ax[0])\n\nax[1].set_title(\"Number of male survivors per Embarked\")\nsns.countplot(data=train_df[train_df[\"Sex\"]==\"male\"], \n              x=\"Embarked\",\n              hue=\"Survived\",\n              ax=ax[1])\n\nax[2].set_title(\"Number of female survivors per Embarked\")\nsns.countplot(data=train_df[train_df[\"Sex\"]==\"female\"], \n              x=\"Embarked\",\n              hue=\"Survived\",\n              ax=ax[2])\n\nplt.show()","ed6b123d":"sns.heatmap(train_df.corr(),annot = True, cmap = 'viridis_r', fmt = '.2f');","9d2c4afd":"train_df.dropna(subset=[\"Embarked\"], inplace=True)\ntrain_df.info()","87f54142":"for df in [train_df, test_df]:\n    df[\"Sex\"] = df[\"Sex\"].map({\"male\":1, \"female\":0, 1:1, 0:0})\n    \n    # Use onehotencoder method on \"Embarked\":\n    df[['Embarked_Q', 'Embarked_S']] = pd.get_dummies(df[\"Embarked\"], drop_first=True)\n    \ntrain_df.head()","b3816de9":"for df in [train_df, test_df]:\n    df['relatives'] = df['SibSp'] + df['Parch'] # Total number of relatives.\n    \n    df.loc[df['relatives'] > 0, 'travelled_alone'] = 0\n    df.loc[df['relatives'] == 0, 'travelled_alone'] = 1\n    \ntrain_df.head()","dbb51b90":"selected_features=[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\",\"Fare\", \"Embarked_Q\", \"Embarked_S\", \"travelled_alone\"]\n\nX_train, X_val, y_train, y_val = train_test_split(train_df[selected_features],\n                                                  train_df[\"Survived\"],\n                                                  test_size = 0.1,\n                                                  stratify = train_df[\"Survived\"],\n                                                  random_state=0)\n\nX_test = test_df[selected_features]\n\nX_train.head()","19cc105f":"for df in [X_train, X_val, X_test]:\n    df.fillna(X_train.mean(), inplace=True)\n    \nX_train.info()","71c4d578":"sc = StandardScaler()\nscaled_features = [\"Age\", \"Fare\"]\n\nsc.fit(X_train[scaled_features])\n\nfor df in [X_train, X_val, X_test]:\n    df[scaled_features] = sc.transform(df[scaled_features])\n    \nX_train.describe()","4c6a0d3a":"#Estimate model performance:\ndef estimate_model(model, X_train, y_train, X_val, y_val):\n    y_pred_train = model.predict(X_train)\n    y_pred_val = model.predict(X_val)\n    \n    print(f\"  Training set Accuracy   = {model.score(X_train, y_train):.4%}\\n  Validation set Accuracy = {model.score(X_val, y_val):.4%}\\n\")\n    print(\"  Validation set Classification Report:\")\n    print(classification_report(y_val, y_pred_val, digits=4))\n    \n    fig, ax = plt.subplots(1, 2, figsize = (15, 5))\n    ax[0].set_title(\"Training Set Confusion Matrix\")\n    plot_confusion_matrix(model, X_train, y_train, ax=ax[0], \n                          cmap=\"cividis\", xticks_rotation=\"vertical\")\n    \n    ax[1].set_title(\"Validation Set Confusion Matrix\")\n    plot_confusion_matrix(model, X_val, y_val, ax=ax[1],\n                          cmap=\"cividis\", xticks_rotation=\"vertical\")\n    \n    \n#View the most predictive features from any tree-based model:\ndef feature_importance(model):\n    importance = pd.DataFrame(model.feature_importances_, index= X_train.columns).sort_values(0)\n    importance.plot(kind='barh', title=\"Feature Importance\"), plt.show()\n    \n    \ndef coss_val(model,X,y,cv=10):\n    scores=cross_val_score(model, X, y, cv=cv)\n    print(\"Cross Validation:\\n  %0.5f accuracy with a standard deviation of %0.5f \\n\" % (scores.mean(), scores.std()))","411cdf9a":"print(\"\\033[1mSupport Vector Classifier:\\033[0m\")\nmodel = SVC(C=11,\n            kernel=\"rbf\",\n            gamma=\"scale\",\n            break_ties=True,\n            random_state=0)\n\n\nmodel.fit(X_train, y_train)\nestimate_model(model, X_train, y_train, X_val, y_val)","0c7dbabe":"print(\"\\033[1mK-Nearest Neighbour Classifier:\\033[0m\")\nmodel = KNeighborsClassifier(n_neighbors=5,\n                             p=3,\n                             weights=\"uniform\",\n                             metric=\"minkowski\",\n                             n_jobs=-1)\n\nmodel.fit(X_train, y_train)\nestimate_model(model, X_train, y_train, X_val, y_val)","429ea167":"print(\"\\033[1mRandom Forest Classifier:\\033[0m\")\nmodel = RandomForestClassifier(n_estimators=100,\n                               criterion=\"entropy\",\n                               max_depth=6,\n                               min_samples_split=4,\n                               bootstrap=True,\n                               max_samples=0.8,\n                               oob_score=True,\n                               n_jobs=-1,\n                               random_state=0)\n\nmodel.fit(X_train, y_train)\ncoss_val(model,X_train, y_train, cv=5)\nestimate_model(model, X_train, y_train, X_val, y_val)\nfeature_importance(model)","c8b4be28":"test_df[\"Survived\"] = model.predict(X_test)\nsubmission = test_df[[\"PassengerId\", \"Survived\"]]\nsubmission","81eda876":"submission.to_csv('submission.csv', index=False)","f741dc5b":"#### Drop null values in \"Embarked\"","b09e01f3":"- There are no duplicate names. Let's check for duplicates in Tickets:","3e1c780d":"## **Load training and test sets**","b4ddf0b8":"## **Exploratory Data Analysis**","bd726659":"## **Preprocessing**","1ef05223":"## **Model Testing**","ce87d250":"- most males embarked in Queenstown didnot survive.\n- passengers embarking in Cherbourg had higher survival rate than Queenstown and Southampton.","50d377fe":"#### Evaluation Functions","838194d4":"#### Split training data into training and validation sets","37546ec1":"- There's more males than females in the dataset.\n- Females survived more than males despite having a lower total count.\n- around 75% of females survived vs. only around 19% of males.","16e63a63":"#### Normalize \"Age\" and \"Fare\" features","5685e779":"#### Fill null values in every feature with its mean","4df8421d":"- Passengers in the 1st class seem to have a better chance of survival than 2nd and 3rd classes","1cead3d8":"#### Add \"travelled_alone\" feature that determines whether a passenger is travelling alone or with family","c9e07b83":"- There are many duplicate ticket numbers, but each entry represents a different passenger, so we will keep them.","d995ad7a":"- Is seems like younger passengers (<10) had a higher chance of survival than older passengers.","b124301f":"## **Test Data predictions**","2c814649":"- Random Forest Seems to perform better than SVM and KNN, so we'll use it to predict the survivor in the test set.","d686274a":"#### Encode \"Sex\" and \"Embarked\" features","0778c0a7":"- Some entries are missing in the test dataset as well, so we have to find a way to deal with missing values if we decide to keep these features.","475e2031":"## **Importing Libraries**","5b911698":"- **19.86%** of the entries in the **\"Age\"** column are missing. We may try to impute them or drop the missing rows from the data\n- **77.10%** of the entries in the **\"Cabin\"** column are missing. We may drop this column from the data as it doesn't provide reliable information.\n- **0.224%** of the entries in the **\"Embarked\"** column are missing. Removing them from the data won't cause an issue."}}