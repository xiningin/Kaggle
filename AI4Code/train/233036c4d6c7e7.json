{"cell_type":{"b6ea20bb":"code","eed88bf4":"code","a9a7ccf3":"code","d1601aae":"code","3c9021d1":"code","3e11a8bc":"code","7e44ad36":"code","42320694":"code","77347cda":"code","beb13d59":"code","a0f67c66":"code","86f88612":"code","19fdf04d":"code","9bcf663a":"code","ee32195d":"code","046ce0a9":"code","dee78e41":"markdown","b06c0440":"markdown","efc1a8fa":"markdown","1aae89d6":"markdown","efd3df2a":"markdown","d67e8539":"markdown","63053258":"markdown","7d533ea6":"markdown","67c379b0":"markdown"},"source":{"b6ea20bb":"#import basic libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')","eed88bf4":"raw_data = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\n# Check the data\nraw_data.info()","a9a7ccf3":"raw_data.head()","d1601aae":"sns.countplot(raw_data.quality);","3c9021d1":"data.corr()['quality'].sort_values()[:-1]","3e11a8bc":"data = raw_data.copy()\nplt.figure(figsize=(12,12))\nsns.heatmap(data.corr(),annot=True);","7e44ad36":"def quality_trans(x):\n    if x<6:\n        return 0\n    else:\n        return 1\ndata.quality = data.quality.map(quality_trans)\nsns.countplot(data.quality);","42320694":"data.quality.value_counts()","77347cda":"from sklearn.utils import resample,shuffle\ndf_majority = data[data['quality']==1]\ndf_minority = data[data['quality']==0]\ndf_minority_upsampled = resample(df_minority,replace=True,n_samples=855,random_state = 123)\nbalanced_df = pd.concat([df_minority_upsampled,df_majority])\nbalanced_df = shuffle(balanced_df)\nbalanced_df.quality.value_counts()","beb13d59":"balanced_df.describe()","a0f67c66":"sns.boxplot(balanced_df['residual sugar']);","86f88612":"len(balanced_df[balanced_df['residual sugar']>4])","19fdf04d":"sns.boxplot(balanced_df['volatile acidity']);","9bcf663a":"# standardization\nfrom sklearn.preprocessing import StandardScaler\nX = balanced_df.drop('quality',axis=1)\ny = balanced_df.quality\nscaled_X = pd.DataFrame(StandardScaler().fit_transform(X),columns=X.columns)\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(scaled_X,y,test_size=0.3,shuffle=True,random_state=42)\nx_train.shape,x_test.shape","ee32195d":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import f1_score,accuracy_score\n\nclassifiers = {\n    'Logistic Regression' : LogisticRegression(),\n    'Decision Tree' : DecisionTreeClassifier(),\n    'Random Forest' : RandomForestClassifier(),\n    'Support Vector Machines' : SVC(),\n    'K-nearest Neighbors' : KNeighborsClassifier(),\n    'XGBoost' : XGBClassifier()\n}\nresults=pd.DataFrame(columns=['Accuracy in %','F1-score'])\nfor method,func in classifiers.items():\n    func.fit(x_train,y_train)\n    pred = func.predict(x_test)\n    results.loc[method]= [100*np.round(accuracy_score(y_test,pred),decimals=4),\n                         round(f1_score(y_test,pred),2)]\nresults","046ce0a9":"#Now lets try to do some evaluation for random forest model using cross validation.\nfrom sklearn.model_selection import cross_val_score\nrfc_eval = cross_val_score(estimator = RandomForestClassifier(), X = x_train, y = y_train, cv = 10)\nrfc_eval.mean()","dee78e41":"Random forest model seems promising. :)\n\n***Please upvote!!!***","b06c0440":"As for now I am not dealing with outliers in features because data is not much big.","efc1a8fa":"We can observe quality is highly correlated with volatile acidity and alcohol features.\n","1aae89d6":"Comparing mean values of all the features we can see there is difference in their magnitude. So, we will standardize our data to get all the features on same scale.","efd3df2a":"To make this data balanced let's upsample the minority class using sklearn library resample.","d67e8539":"**About the dataset:**\nInput variables (based on physicochemical tests):\n* 1 - fixed acidity\n* 2 - volatile acidity\n* 3 - citric acid\n* 4 - residual sugar\n* 5 - chlorides\n* 6 - free sulfur dioxide\n* 7 - total sulfur dioxide\n* 8 - density\n* 9 - pH\n* 10 - sulphates\n* 11 - alcohol\n\nOutput variable (based on sensory data):\n* 12 - quality (score between 0 and 10)","63053258":"There are 1599 observations in the dataset. Luckily, no missing values!\nLet's have a look at the data.","7d533ea6":"*Though feature quality can take values from 0 to 10, here we have only 6 possible values,i.e.,(3,4,5,6,7,8). Let us partition it into 'good' and 'bad' range. Values less than and equal to 5 will corespond to bad quality wine and vice versa.*","67c379b0":"Also, mean and max value of feature residual sugar have a huge gap implying resence of outliers."}}