{"cell_type":{"6252f557":"code","3c38bde3":"code","713aa42c":"code","f526ec0c":"code","fef91568":"code","96236705":"code","5a9a518f":"code","1436cee8":"code","1f67b805":"code","e8e3944b":"markdown","8a521268":"markdown","f21b9148":"markdown","f8539d2c":"markdown","cecf8c23":"markdown","fa9d4b76":"markdown"},"source":{"6252f557":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3c38bde3":"import cv2 as cv\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, MaxPool2D\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.layers import Activation, Convolution2D, Dropout, Conv2D,AveragePooling2D, BatchNormalization,Flatten,GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.utils import shuffle  \nimport pandas as pd\n\nimages = []\nlabels  = []\nTRAIN_DIR = '..\/input\/food41\/images'\nIMG_SIZE = (224,224) # Image resolution\nBATCH_SIZE = 32","713aa42c":"\n# # Looping through the train file to get the classes and lable \n# img_path = []\n# for filename in os.listdir(TRAIN_DIR):\n#     IMG_DIR = os.path.join(TRAIN_DIR, filename)\n#     for image_file in os.listdir(IMG_DIR):\n#         img_path.append(os.path.join(IMG_DIR, image_file))\n#         labels.append(filename)\n\n\n\n# num_classes = np.unique(labels)\n# lb = LabelEncoder()\n# labels = pd.DataFrame(labels)\n# labels = lb.fit_transform(labels[0])\n\n# img_path = np.array(img_path)\n# labels = np.array(labels, dtype = 'int32')\n\n# print(img_path.shape, len(images))\n# print(labels.shape, len(labels))\n# print(num_classes)","f526ec0c":"# generator = tf.keras.preprocessing.image.ImageDataGenerator(\n#         rescale=1.\/255,\n#         rotation_range=30,\n#         shear_range=0.3,\n#         horizontal_flip=True,\n#         width_shift_range=0.1,\n#         height_shift_range=0.1,\n#         zoom_range=0.25,\n#         validation_split=0.3\n# )\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(\n    TRAIN_DIR,\n    validation_split=0.2,\n    image_size=(224, 224),\n    batch_size= BATCH_SIZE,\n    shuffle = True,\n    subset='training',\n    seed = 123,\n    label_mode = 'categorical',\n)\n\nvalid_data = tf.keras.preprocessing.image_dataset_from_directory(\n    TRAIN_DIR,\n    validation_split=0.2,\n    image_size=(224, 224),\n    batch_size= BATCH_SIZE,\n    shuffle = False,\n    subset='validation',\n    seed = 123,\n    label_mode = 'categorical',\n)\n\nprint(len(train_data))\nprint(len(valid_data))","fef91568":"resize_and_rescale = tf.keras.Sequential([\n  layers.experimental.preprocessing.Resizing(224, 224),\n  layers.experimental.preprocessing.Rescaling(1 \/255)\n])\n\n# Data augmentation to reduce overtraining\ndata_augmentation = tf.keras.Sequential([\n     layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n                                                 input_shape=(224, \n                                                              224,\n                                                              3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n])\n\nmodel = tf.keras.Sequential([\n        #resize_and_rescale,\n        data_augmentation,\n        tf.keras.applications.EfficientNetB0(\n            input_shape=(224, 224, 3),\n            weights='imagenet',\n            include_top=False,\n            drop_connect_rate=0.5\n        ),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(101, activation='softmax') # Sigmoid is not used for many lables, uses softmax instead and the 101 number represented for the numbers of classes in the dataset\n])","96236705":"# x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.33, random_state=25)\n\n# y_train = keras.utils.to_categorical(y_train, len(num_classes))\n# y_test = keras.utils.to_categorical(y_test, len(num_classes))","5a9a518f":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy']) \n\nhistory = model.fit(\n    train_data, \n    validation_data=valid_data,\n    epochs= 20,\n)","1436cee8":"scores = model.evaluate(valid_data)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","1f67b805":"# Plotting Results\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'g', label='Validation acc')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\nplt.title('Training and validation accuracy')\nplt.legend()\nfig = plt.figure()\nfig.savefig('acc.png')\n\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'g', label='Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and validation loss')\n\nplt.legend()\nplt.show()","e8e3944b":"# Visualize the model's accurency and loss","8a521268":"In the last Dense model, the 101 number represented for the number of classes in the data set","f21b9148":"From the dataset directory, we split it into train_data (80%) and valid_data (20%)","f8539d2c":"# **DATA PROCESSING**","cecf8c23":"# Reference\n1. https:\/\/www.tensorflow.org\/tutorials\/images\/classification\n2. https:\/\/www.tensorflow.org\/tutorials\/keras\/overfit_and_underfit\n3. https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image_dataset_from_directory\n4. https:\/\/machinelearningmastery.com\/display-deep-learning-model-training-history-in-keras\/\n5. https:\/\/www.kaggle.com\/arjunrao2000\/beginners-guide-efficientnet-with-keras\n6. https:\/\/keras.io\/examples\/vision\/image_classification_efficientnet_fine_tuning\/","fa9d4b76":"# ****Creating Model****"}}