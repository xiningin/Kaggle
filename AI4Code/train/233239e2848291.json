{"cell_type":{"2258be4d":"code","1c61c37f":"code","29fa974b":"code","2fabe717":"code","e25fa6db":"code","a971decd":"code","8cbd95a3":"code","bd5ce6e4":"code","3f54a1b9":"code","860314be":"code","0190032a":"code","be71bad4":"code","c9af141a":"code","cfd3c1ce":"code","027fb8b3":"code","b73c75ba":"code","587fb216":"code","8934c278":"code","93bbe294":"code","e74f3838":"code","9c31b99f":"code","027bdb50":"code","d51ad066":"code","cc96f1bf":"code","090ffc68":"code","0d6eba0d":"code","a6ba5aa9":"code","5b6c5b92":"markdown","df2ba63b":"markdown","2d9b394e":"markdown","57acd985":"markdown","8ffca922":"markdown","261a2dd7":"markdown","934a7427":"markdown","679bd5a6":"markdown","f4d2cb5d":"markdown","11294140":"markdown","280689b5":"markdown","e5dd6324":"markdown","5685bab9":"markdown","92761f83":"markdown","0ca01b7c":"markdown","2ee5d6a0":"markdown","9cf86272":"markdown"},"source":{"2258be4d":"import numpy as np                # linear algebra\nimport pandas as pd               # data frames\nimport seaborn as sns             # visualizations\nimport matplotlib.pyplot as plt   # visualizations\nimport scipy.stats                # statistics\nfrom sklearn.preprocessing import power_transform\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom scipy.stats import randint as sp_randint\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n%matplotlib inline\nimport matplotlib.pyplot as plt","1c61c37f":"df = pd.read_csv(\"..\/input\/data.csv\")\nprint(df.head())\nprint(df.info())\nprint(df.shape)","29fa974b":"df.head()","2fabe717":"df=df.drop([\"id\",\"Unnamed: 32\"],axis=1)\ndf.head()","e25fa6db":"df.shape","a971decd":"#probando si hay valores nulos\npd.isnull(df).sum()","8cbd95a3":"def mapping(df,feature):\n    featureMap=dict()\n    count=0\n    for i in sorted(df[feature].unique(),reverse=True):\n        featureMap[i]=count\n        count=count+1\n    df[feature]=df[feature].map(featureMap)\n    return df","bd5ce6e4":"df=mapping(df,feature=\"diagnosis\")","3f54a1b9":"df.sample(5)","860314be":"plt.figure(figsize=(12,8))\nsns.heatmap(df.describe()[1:].transpose(),\n            annot=True,linecolor=\"w\",\n            linewidth=2,cmap=sns.color_palette(\"Blues\"))\nplt.title(\"Data summary\")\nplt.show()","0190032a":"# Histograma de sus datos\nf, axes = plt.subplots(2,4, figsize=(20, 12))\nsns.distplot( df[\"radius_mean\"], ax=axes[0,0])\nsns.distplot( df[\"texture_mean\"], ax=axes[0,1])\nsns.distplot( df[\"perimeter_mean\"], ax=axes[0,2])\nsns.distplot( df[\"area_mean\"], ax=axes[1,0])\nsns.distplot( df[\"smoothness_mean\"], ax=axes[1,1])\nsns.distplot( df[\"compactness_mean\"], ax=axes[1,2])\nsns.distplot( df[\"concavity_mean\"], ax=axes[2,0])\nsns.distplot( df[\"concave points_mean\"], ax=axes[2,1])\nsns.distplot( df[\"symmetry_mean\"], ax=axes[2,2])\n","be71bad4":"corr=df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(11, 9))\ncmap = sns.color_palette(\"Blues\")\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","c9af141a":"sns.set(style=\"white\")\ndf = df.loc[:,['radius_worst','perimeter_worst','area_worst']]\ng = sns.PairGrid(df, diag_sharey=False)\ng.map_lower(sns.kdeplot, cmap=\"Blues_d\")\ng.map_upper(plt.scatter)\ng.map_diag(sns.kdeplot, lw=3)","cfd3c1ce":"X = observables\ny = df['diagnosis']","027fb8b3":"gnb = GaussianNB()\ngnb_scores = cross_val_score(gnb, X, y, cv=10, scoring='accuracy')\nprint(gnb_scores.mean())","b73c75ba":"knn = KNeighborsClassifier()\n\nk_range = list(range(1, 30))\nleaf_size = list(range(1,30))\nweight_options = ['uniform', 'distance']\nalgorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\nparam_grid = {'n_neighbors': k_range, 'leaf_size': leaf_size, 'weights': weight_options, 'algorithm': algorithm}","587fb216":"rand_knn = RandomizedSearchCV(knn, param_grid, cv=10, scoring=\"accuracy\", n_iter=100, random_state=42)\nrand_knn.fit(X,y)","8934c278":"print(rand_knn.best_score_)\nprint(rand_knn.best_params_)\nprint(rand_knn.best_estimator_)","93bbe294":"dt_clf = DecisionTreeClassifier(random_state=42)\n\nparam_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n              'min_samples_split': sp_randint(2, 11), \n              'min_samples_leaf': sp_randint(1, 11)}","e74f3838":"rand_dt = RandomizedSearchCV(dt_clf, param_grid, cv=10, scoring=\"accuracy\", n_iter=100, random_state=42)\nrand_dt.fit(X,y)\n","9c31b99f":"print(rand_dt.best_score_)\nprint(rand_dt.best_params_)\nprint(rand_dt.best_estimator_)","027bdb50":"sv_clf = SVC(random_state=42)\n\nparam_grid = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},{'C': [1, 10, 100, 1000], \n               'gamma': [0.001, 0.0001], 'kernel': ['rbf']},]","d51ad066":"grid_sv = GridSearchCV(sv_clf, param_grid, cv=10, scoring=\"accuracy\")\ngrid_sv.fit(X,y)","cc96f1bf":"print(grid_sv.best_score_)\nprint(grid_sv.best_params_)\nprint(grid_sv.best_estimator_)","090ffc68":"# Tratando de evitar el sobreajuste\nstump_clf =  DecisionTreeClassifier(random_state=42, max_depth=1)\n\nparam_grid = {\"base_estimator__max_features\": ['auto', 'sqrt', 'log2'],\n              \"n_estimators\": list(range(1,500)),\n              \"learning_rate\": np.linspace(0.01, 1, num=20),}","0d6eba0d":"ada_clf = AdaBoostClassifier(base_estimator = stump_clf)\n\nrand_ada = RandomizedSearchCV(ada_clf, param_grid, scoring = 'accuracy', n_iter=100, random_state=42)\nrand_ada.fit(X,y)","a6ba5aa9":"print(rand_ada.best_score_)\nprint(rand_ada.best_params_)\nprint(rand_ada.best_estimator_)","5b6c5b92":"**AdaBoost Classifier**","df2ba63b":"**Modelo**","2d9b394e":"Conclusi\u00f3n\nEl mejor modelo utilizado para diagnosticar el c\u00e1ncer de mama a partir de mi an\u00e1lisis comparativo es AdaBoost utilizando un Toc\u00f3n de decisi\u00f3n como su estimador base. Adaboost tuvo una precisi\u00f3n de predicci\u00f3n de 0.97 con Support Vector Machine (0.96) y Random Forest (0.95) en segundo y tercer lugar.\n\n","57acd985":"**Objetivo**\n Primero, se debe realizar un an\u00e1lisis exploratorio de los datos, luego limpiar un poco la transformaci\u00f3n de una caracter\u00edstica, luego elegir un modelo entre varias opciones y realizar una optimizaci\u00f3n de optimizaci\u00f3n m\u00e1xima para que al final tengamos el modelo m\u00e1s preciso.","8ffca922":"El conjunto de datos tiene algunas variables muy sesgadas. Esos son susceptibles de hacer una transformaci\u00f3n para modelar.","261a2dd7":"Hallazgos de KNN\nLa utilizaci\u00f3n de la b\u00fasqueda de par\u00e1metros hiperactivos aleatorios junto con la validaci\u00f3n cruzada result\u00f3 en un modelo KNN con una puntuaci\u00f3n de precisi\u00f3n de 0,93. El modelo que fue elegido por RandomizedSearchCV es el siguiente: {'weightes': 'uniform', 'n_neighbors': 14, 'leaf_size': 22, 'algorithm': 'ball_tree'}.\n\nNo creo que KNN sea \u00f3ptimo para este problema, por lo que se realizar\u00e1 una comparaci\u00f3n de resultados m\u00e1s complicada despu\u00e9s de varias pruebas m\u00e1s","934a7427":"La idea es realizar diferentes algoritmos de clasificaci\u00f3n est\u00e1ndar para elegir cu\u00e1l es mejor para el conjunto de datos. M\u00e1s tarde, sobre el modelo m\u00e1s prometedor, realice algunos ajustes para encontrar el mejor modelo posible.","679bd5a6":"El modelo nos muestra un modelo de clasificaci\u00f3n de \u00e1rbol de decisiones con una puntuaci\u00f3n de precisi\u00f3n de 0,95. ","f4d2cb5d":"Se hace necesario para tener un analisis proxy una transformaci\u00f3n inicial al ser datos que son analisados apartir de un grafica de las masas mamarias\n\n**Transformaci\u00f3n**","11294140":"Resultados Gausianos","280689b5":" AdaBoost funcion\u00f3 bastante bien. Tiene una precisi\u00f3n de 0,97. ","e5dd6324":"**MODELO FINAL**","5685bab9":"**ANALISIS EXPLORATORIO DE LOS DATOS**\n\nAn\u00e1lisis de datos exploratorios b\u00e1sicos para identificar si existe una relaci\u00f3n entre las variables dependientes  y todas las variables independientes.","92761f83":"La precisi\u00f3n de la clasificaci\u00f3n es de 0,95, lo que resuma muy interesante","0ca01b7c":"**KNN**\nEl algoritmo K-vecinos m\u00e1s cercanos (KNN) es un tipo de algoritmos supervisados de aprendizaje autom\u00e1tico. KNN es extremadamente f\u00e1cil de implementar en su forma m\u00e1s b\u00e1sica y, sin embargo, realiza tareas de clasificaci\u00f3n bastante complejas. Es un algoritmo de aprendizaje perezoso ya que no tiene una fase de capacitaci\u00f3n especializada. M\u00e1s bien, utiliza todos los datos para el entrenamiento mientras clasifica un nuevo punto de datos o instancia. KNN es un algoritmo de aprendizaje no param\u00e9trico, lo que significa que no asume nada sobre los datos subyacentes. Esta es una caracter\u00edstica extremadamente \u00fatil, ya que la mayor\u00eda de los datos del mundo real no siguen realmente ninguna suposici\u00f3n te\u00f3rica, por ejemplo, separabilidad lineal, distribuci\u00f3n uniforme, etc.","2ee5d6a0":"Los datos usados para este estudio se calculan a partir de una imagen digitalizada de un aspirado con aguja fina (FNA) de una masa mamaria. \n1) N\u00famero de identificaci\u00f3n \n2) Diagn\u00f3stico (M = maligno, B = benigno)\n\nSe calculan diez caracter\u00edsticas de valor real para cada n\u00facleo celular:\n\na) Radio (media de las distancias desde el centro a los puntos en el per\u00edmetro) \nb) Textura (desviaci\u00f3n est\u00e1ndar de los valores de escala de grises) \nc) Per\u00edmetro \nd) \u00e1rea \ne) suavidad (variaci\u00f3n local en longitudes de radio) \nf) compacidad (per\u00edmetro ^ 2) \/ \u00e1rea - 1.0) \ng) concavidad (severidad de las porciones c\u00f3ncavas del contorno) \nh) puntos c\u00f3ncavos (n\u00famero de porciones c\u00f3ncavas del contorno)\ni) simetr\u00eda\nj) dimensi\u00f3n fractal (\"aproximaci\u00f3n de la l\u00ednea de costa\" - 1)\n","9cf86272":"El conjunto de datos tiene 569 candidatos con 33 variables. "}}