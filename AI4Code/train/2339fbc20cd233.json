{"cell_type":{"4db4094f":"code","8610883f":"code","ace8c4d1":"code","3aa2b623":"code","bb6e50bd":"code","e2a15950":"code","a9a9f3f8":"code","965179ee":"markdown","4a76725d":"markdown","e571320e":"markdown"},"source":{"4db4094f":"import numpy as np\nimport pandas as pd\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","8610883f":"WEIGHTS_FILE = \"..\/input\/cots-torch-fasterrcnn-weights\/fasterrcnn_resnet50_fpn-e10.bin\"","ace8c4d1":"def get_model():\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n    num_classes = 2  # 1 class (starfish) + background\n\n    # get number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    # Load the trained weights\n    model.load_state_dict(torch.load(WEIGHTS_FILE))\n    model.eval()\n\n    model = model.to(device)\n    return model\n\nmodel = get_model()","3aa2b623":"detection_threshold = 0.5","bb6e50bd":"def format_prediction_string(boxes, scores):\n    # Format as specified in the evaluation page\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.2f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)\n\n\ndef predict(model, pixel_array):\n    # Predictions for a single image\n    \n    # Apply all the transformations that are required\n    pixel_array = pixel_array.astype(np.float32) \/ 255.\n    tensor_img = ToTensorV2(p=1.0)(image=pixel_array)['image'].unsqueeze(0)\n    \n    # Get predictions\n    with torch.no_grad():\n        outputs = model(tensor_img.to(device))[0]\n    \n    # Move predictions to cpu and numpy\n    boxes = outputs['boxes'].data.cpu().numpy()\n    scores = outputs['scores'].data.cpu().numpy()\n    \n    # Filter predictions with low score\n    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n    scores = scores[scores >= detection_threshold]\n    \n    # Go back from x_min, y_min, x_max, y_max to x_min, y_min, w, h\n    boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n    boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n  \n    # Format results as requested in the Evaluation tab\n    return format_prediction_string(boxes, scores)","e2a15950":"import greatbarrierreef\nenv = greatbarrierreef.make_env()\niter_test = env.iter_test() \n\nfor (pixel_array, df_pred) in iter_test:  # iterate through all test set images\n    df_pred['annotations'] = predict(model, pixel_array)\n    env.predict(df_pred)\n","a9a9f3f8":"pd.read_csv('submission.csv')","965179ee":"## Predict","4a76725d":"## Reference Notebook - https:\/\/www.kaggle.com\/julian3833\/reef-starter-torch-fasterrcnn-infer-lb-0-416\/notebook","e571320e":"## Load Model"}}