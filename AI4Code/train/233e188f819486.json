{"cell_type":{"acebda90":"code","3fe93498":"code","a05596a4":"code","fd04384e":"code","0840cf23":"code","7ba52b5b":"code","0f789094":"code","da6c1bad":"code","4b6a9550":"code","0870420d":"code","4cd8b3ac":"code","43bc0b65":"markdown","2b028e0a":"markdown","3fd9a73f":"markdown","3da55d55":"markdown","3cf3c385":"markdown","961d510f":"markdown","33c5ebdd":"markdown"},"source":{"acebda90":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport category_encoders as ce\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom eli5.sklearn.explain_prediction import explain_prediction_linear_regressor\nfrom eli5.sklearn.explain_prediction import explain_prediction_tree_regressor\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3fe93498":"# Path of the file to read\niowa_file_path = '\/kaggle\/input\/housing\/AmesHousing.csv'\nhome_data = pd.read_csv(iowa_file_path)\nhome_data_copy = home_data.copy()\n\n# Create target object and call it y\ny = home_data.SalePrice\n# Create X\nX = home_data[home_data.columns[:-1]]\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nval_X.head()","a05596a4":"train_df = train_X.copy()\ntrain_df['SalePrice'] = train_y\nval_df = val_X.copy()\ntrain_df.to_csv('train.csv', index=False)\nval_df.to_csv('test.csv', index=False)\n\ntarget = pd.DataFrame({'Order': val_df.Order, 'SalePrice': val_y})\ntarget.to_csv('target.csv', index=False)","fd04384e":"plt.scatter(val_X[\"Year Built\"], val_y, color = \"darkblue\", alpha=.8)\nplt.title(\"Sale Price vs Year Built (Validation set)\")\nplt.xlabel(\"Year Built\")\nplt.ylabel(\"Sale Price\")\nplt.show()","0840cf23":"# Turn categorical features into numeric using count encoding\ncat_features = home_data.select_dtypes(exclude=['int64','float64']).columns\nnon_cat_features = home_data.select_dtypes(include=['int64','float64']).columns[:-1]\ncount_enc = ce.CountEncoder(cols=cat_features)\n\n# Learn encoding from the training set\ncount_enc.fit(train_X[cat_features])\n\n# Apply encoding to the train and validation sets\ntrain_X = train_X[non_cat_features].join(count_enc.transform(train_X[cat_features]).add_suffix('_count'))\nval_X = val_X[non_cat_features].join(count_enc.transform(val_X[cat_features]).add_suffix('_count'))","7ba52b5b":"to_plot = val_X.copy()\nto_plot['cost_over_150000'] = val_y >= 150000\nsns.pairplot(to_plot, vars=['Year Built', 'Overall Qual', 'Overall Cond'], hue='cost_over_150000')","0f789094":"# Deal with missing values\ntrain_X = train_X.fillna(method='bfill')\nval_X = val_X.fillna(method='bfill')","da6c1bad":"# Define the model\nl_model = LinearRegression()\n# fit the model\nl_model.fit(train_X, train_y)\n\npreds = l_model.predict(val_X)\n\n# Calculate the mean absolute error of the Random Forest model on the validation data\nl_val_mae = mean_absolute_error(val_y, preds)\nl_val_rmse = np.sqrt(mean_squared_error(val_y, preds))\nprint(\"Validation MAE for Linear Model: {}\".format(l_val_mae))\nprint(\"Validation RMSE for Linear Model: {}\".format(l_val_rmse))","4b6a9550":"# Define the model\nrf_model = RandomForestRegressor(random_state=1)\n# fit the model\nrf_model.fit(train_X, train_y)\n\npreds = rf_model.predict(val_X)\n\n# Calculate the mean absolute error of the Random Forest model on the validation data\nrf_val_mae = mean_absolute_error(val_y, preds)\nrf_val_rmse = np.sqrt(mean_squared_error(val_y, preds))\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\nprint(\"Validation RMSE for Random Forest Model: {}\".format(rf_val_rmse))","0870420d":"import xgboost as xgb\n\nxg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 100)\nxg_reg.fit(train_X, train_y)\n\npreds = xg_reg.predict(val_X)\n\nxgb_val_mae = mean_absolute_error(val_y, preds)\nxgb_val_rmse = np.sqrt(mean_squared_error(val_y, preds))\nprint(\"Validation MAE for XGBoost model: {}\".format(xgb_val_mae))\nprint(\"Validation RMSE for XGBoost model: {}\".format(xgb_val_rmse))","4cd8b3ac":"my_predictions = pd.DataFrame({'Order': val_df.Order, 'SalePrice': preds})\nmy_predictions.to_csv('submission.csv', index=False)","43bc0b65":"## Turning Categorical Features into Numerical","2b028e0a":"## XGBoost Regression","3fd9a73f":"## Linear Regression","3da55d55":"## Random Forest Regression","3cf3c385":"## Loading the Data","961d510f":"# Simple Regression Example\n## Importing Necessary Packages","33c5ebdd":"## Filling in the Missing Values"}}