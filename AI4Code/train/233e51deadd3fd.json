{"cell_type":{"7081d90a":"code","9e3340f2":"code","07466eb6":"code","fb50bbd3":"code","13aa3f9e":"code","3ab16584":"code","d7ad8b20":"code","d3b681b5":"code","491f20f0":"code","01ab69e6":"code","2d318b13":"code","50155795":"code","660eac87":"code","552613c1":"code","7f682e1c":"code","556d3461":"code","fdf721f0":"code","f85e9f2e":"code","e2fce71b":"code","39fcc04f":"code","f1cfd331":"code","323bb813":"code","1b327c96":"markdown","56a8df11":"markdown","299fb2f0":"markdown","dc67fbbf":"markdown","d59a1009":"markdown","c7ac6202":"markdown","3cf667f1":"markdown","6ae0df7f":"markdown","9aea2b9d":"markdown","ed27dfa1":"markdown","0a97ed5b":"markdown","4108cc83":"markdown","e67e3760":"markdown","8b65a373":"markdown"},"source":{"7081d90a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/natural-images\/data\/natural_images\"))\n\n# Any results you write to the current directory are saved as output.\n","9e3340f2":"######## Gpu Check ###########\nimport tensorflow as tf \ndevice_name = tf.test.gpu_device_name() \nif device_name != '\/device:GPU:0':  \n    raise SystemError('GPU device not found') \nprint('Found GPU at: {}'.format(device_name)) ","07466eb6":"# from google.colab import drive\n# drive.mount('\/content\/drive\/')","fb50bbd3":"# import zipfile\n# zip_ref = zipfile.ZipFile('..\/input\/data\/natural_images', 'r')\n# zip_ref.extractall()\n# zip_ref.close()","13aa3f9e":"from os import listdir\nimg_dir = '..\/input\/natural-images\/data\/natural_images'\ndata_list = listdir(img_dir)\ndata_list","3ab16584":"from tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model ,load_model\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport tensorflow as tf\n\n\nDATASET_PATH  = img_dir\nIMAGE_SIZE    = (299, 299)\nNUM_CLASSES   = len(data_list)\nBATCH_SIZE    = 25  \nFREEZE_LAYERS = 16  \nNUM_EPOCHS    = 1\nLEARNING_RATE = 5e-5\nDROP_OUT = .5\nchkpoint_model_loc = '5'\n\n\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                   rotation_range=50,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.25,\n                                   zoom_range=0.1,\n                                   channel_shift_range = 20,\n                                   horizontal_flip = True ,\n                                   vertical_flip = True ,\n                                   validation_split = 0.2,\n                                   fill_mode='constant')\n\n# test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n#                                    fill_mode='constant')\n\ntrain_batches = train_datagen.flow_from_directory(DATASET_PATH,\n                                                  target_size=IMAGE_SIZE,\n                                                  shuffle=True,\n                                                  batch_size=BATCH_SIZE,\n                                                  subset = \"training\"\n                                                  )\n\nvalid_batches = train_datagen.flow_from_directory(DATASET_PATH,\n                                                  target_size=IMAGE_SIZE,\n                                                  shuffle=True,\n                                                  batch_size=BATCH_SIZE,\n                                                  subset = \"validation\"\n                                                  )\nclass_dictionary = train_batches.class_indices\nclass_dictionary\n","d7ad8b20":"len(chkpoint_model_loc)","d3b681b5":"# build our classifier model based on pre-trained InceptionResNetV2:\n# 1. we don't include the top (fully connected) layers of InceptionResNetV2\n# 2. we add a DropOut layer followed by a Dense (fully connected)\n#    layer which generates softmax class score for each class\n# 3. we compile the final model using an Adam optimizer, with a\n#    low learning rate (since we are 'fine-tuning')\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nif len(chkpoint_model_loc) < 5:\n#############main portion for InceptionResnetV2 only##############\n  net = InceptionResNetV2(include_top=False,\n                          weights='imagenet',\n                          input_tensor=None,\n                          input_shape=(299,299,3))\n\n  ############## Run this block if include top = False ######\n  x = net.output\n  x = GlobalAveragePooling2D()(x)\n#   x = Flatten()(x)\n#   x = Dropout(DROP_OUT)(x)\n###############   End of block ##################\n\n############## Run this block if include top = True ######\n#   '''\n#   This block keeps avg_pool (GlobalAveragePooling2) layer and removes only prediction layer.\n#   Then replace inceptionResnetv2's predictionlayer with a drpout layer and and a softmax layer. \n#   To change the class class size of 1000 to 8 we need to replace their pediction layer with our softmax layer.\n#   '''\n#   avg_pool = net.layers[-2]\n#   prediction = net.layers[-1]\n\n#   #create drpout layer\n#   drp1 = Dropout(DROP_OUT)\n#   x = drp1(avg_pool.output)\n###############   End of block ##################\n\n\n\n  output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n  net_final = Model(inputs=net.input, outputs=output_layer)\n\n  for layer in net_final.layers[:FREEZE_LAYERS]:\n      layer.trainable = False\n\n  for layer in net_final.layers[FREEZE_LAYERS:]:\n      layer.trainable = True\n\n  net_final.compile(optimizer=Adam(lr=LEARNING_RATE),\n                    loss='categorical_crossentropy', metrics=['accuracy'])\n\n#   print(net_final.summary())","491f20f0":"print(net_final.summary())","01ab69e6":"#CHECKPOINT\n# filepath = \"..\/weights-improvement-EPOCH_{epoch:02d}-ACC_{acc:.2f}-VALIDATION_{val_acc:.2f}.hdf5\"\n# checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n# callbacks_list = [checkpoint]","2d318b13":"######## if running pre trained model is running #######\n# if len(chkpoint_model_loc) > 5:\n#   net_final = load_model(chkpoint_model_loc)\n#   net_final.evaluate_generator(valid_batches,\n#                                steps = np.ceil(len(valid_batches) \/ BATCH_SIZE),\n#                                verbose = 1\n#                                )\n","50155795":"if len(chkpoint_model_loc) > 5:\n  net_final.evaluate_generator(valid_batches,\n                               steps = np.ceil(len(valid_batches) \/ BATCH_SIZE),\n                               verbose = 1\n                               )\n","660eac87":"#Adding Dropout layer to a pre trained model\ndrpout_needed = False\n\nif drpout_needed :\n  flt = net_final.layers[-2]\n  prediction = net_final.layers[-1]\n\n  #create drpout layer\n  drp1 = Dropout(DROP_OUT)\n  x = drp1(flt.output)\n\n  predictors = prediction(x)\n  net_final = Model(inputs=net_final.input, outputs=predictors)","552613c1":"print(net_final.summary())","7f682e1c":"# !pip install tensorflow-gpu==2.0.0-alpha0\n# import tensorflow as tf\n# print(tf.__version__)","556d3461":"\n#FIT MODEL\nnet_final.fit_generator(train_batches,\n                        steps_per_epoch = np.ceil(len(train_batches) \/ BATCH_SIZE),\n                        validation_data = valid_batches,\n                        validation_steps = np.ceil(len(valid_batches) \/ BATCH_SIZE),\n                        epochs = NUM_EPOCHS,\n#                         callbacks = callbacks_list \n                       )\n","fdf721f0":"# # save trained weights\n# # net_final.save(WEIGHTS_FINAL)\n# x = net_final.evaluate_generator(valid_batches,\n#                            steps = np.ceil(len(valid_batches) \/ BATCH_SIZE),\n#                            use_multiprocessing = True,\n#                            verbose = 1\n#                            )","f85e9f2e":"# incorrects = np.nonzero(net_final.predict(valid_batches).reshape((-1,)) != valid_batches)","e2fce71b":"# from PIL import Image\nimport pandas as pd\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\n\nIMAGE_SIZE    = (299, 299)\n# print(data_list)\nprint(\"Class name to class id map\\n\",class_dictionary)\n\ntest_image = image.load_img((img_dir + \"\/motorbike\/motorbike_0011.jpg\"),target_size =IMAGE_SIZE )\ntest_image = image.load_img(\"..\/input\/natural-images\/data\/natural_images\/cat\/cat_0005.jpg\",target_size =IMAGE_SIZE )\ntest_image = image.img_to_array(test_image)\n\nplt.imshow(test_image\/255.)\n\n# test_image = np.expand_dims(test_image , axis = 0)\ntest_image = test_image.reshape((1, test_image.shape[0], test_image.shape[1], test_image.shape[2]))\ntest_image = preprocess_input(test_image)\n\nprediction = net_final.predict(test_image)\ndf = pd.DataFrame({'pred':prediction[0]})\n# print(prediction[0])\ndf = df.sort_values(by='pred', ascending=False, na_position='first')\nprint(df)\n\nfor x in data_list:\n  if class_dictionary[x] == (df[df == df.iloc[0]].index[0]):\n    print(\"Class prediction = \", x)\n    break","39fcc04f":"os.listdir('..\/input\/natural-images\/data\/natural_images')","f1cfd331":"\n# import sys\n# import numpy as np\n# import cv2\n# import utils\n# import matplotlib.pyplot as plt\n\n\n# pred = net_final.predict(test_image)\n\n# bboxes = utils.get_boxes(pred[0], cutoff=0.1)\n# bboxes = utils.nonmax_suppression(bboxes, iou_cutoff = 0.05)\n# draw = utils.draw_boxes(img, bboxes, color=(0, 0, 255), thick=3, draw_dot=True, radius=3)\n# draw = draw.astype(np.uint8)\n\n# plt.imshow(draw[...,::-1])\n# plt.show()","323bb813":"# # from PIL import Image\n# import pandas as pd\n# from tensorflow.keras.preprocessing import image\n# import matplotlib.pyplot as plt\n\n# IMAGE_SIZE    = (299, 299)\n\n# test_image = image.load_img(\"..\/input\/data\/natural_images\/motorbike\/motorbike_0000.jpg\",target_size =IMAGE_SIZE )\n# test_image = image.img_to_array(test_image)\n# plt.imshow(test_image\/255.)\n# test_image = np.expand_dims(test_image , axis = 0)\n\n# prediction = net_final.predict(test_image)\n# df = pd.DataFrame({'pred':prediction[0]})\n# print(prediction[0])\n# df.sort_values(by='pred', ascending=False, na_position='first')","1b327c96":"** pascale voc dataset\n**","56a8df11":"# Resnet","299fb2f0":"## Evaluation of loaded model","dc67fbbf":"# load pretrained model","d59a1009":"## Checkpoint declare","c7ac6202":"## Layer modification","3cf667f1":"https:\/\/github.com\/makatx\/YOLO_ResNet\/blob\/master\/Vehicle%20Detection.ipynb\nhttps:\/\/github.com\/makatx\/YOLO_ResNet\/blob\/master\/Dataset%20Exploration.ipynb\n\n\nhttps:\/\/www.kaggle.com\/zaraks\/pascal-voc-2007\/kernels\nhttps:\/\/www.kaggle.com\/huanghanchina\/pascal-voc-2012\/kernels","6ae0df7f":"# Run Training","9aea2b9d":"# Get data from google drive","ed27dfa1":"# Predict","0a97ed5b":"# Get data from zip file","4108cc83":"## Image process and variable declare","e67e3760":"# DropOut add","8b65a373":"# Summary"}}