{"cell_type":{"2d0c0906":"code","9a4ef7f3":"code","e5faacad":"code","a463721f":"code","4443f861":"code","92256197":"code","f7226751":"code","8317d78c":"code","eca058bf":"code","92c1a36f":"code","46b502ad":"code","8b9e010e":"code","5c04c112":"markdown","e4aeeee0":"markdown","b27596b6":"markdown","e3a99e5d":"markdown","216b72d5":"markdown","49ca8733":"markdown","3ad3788b":"markdown","d083bb55":"markdown","69276745":"markdown"},"source":{"2d0c0906":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #ploting\nimport seaborn as sns\n\npd.set_option('display.max_columns', 500)\n\npd.set_option('display.max_rows', 500)\n","9a4ef7f3":"# Path of the file to read\ncovid_data_path = \"\/kaggle\/input\/covid19\/dataset.xlsx\"\n\n# Read the file into a variable covid_data\ncovid_data = pd.read_excel(covid_data_path)\n\n# Print the first 5 rows of the data\ncovid_data.head()\n\n# Print the percentage of missing values\n\npercent_of_missing_values = sum(covid_data.isnull().sum())\/sum(covid_data.isnull().count())\n\nprint('There are {:.1%} of missing values in the dataset.'.format(percent_of_missing_values))\n","e5faacad":"# Drop Id Column\n\nids = covid_data[[\"Patient ID\"]]\ncovid_data = covid_data.drop(\"Patient ID\",axis=1)\n\n\nfor col in covid_data.columns :\n    \n    if covid_data[col].dtypes == \"object\" and col != \"Patient ID\":\n        \n        covid_data.loc[covid_data[col] == \"positive\", col] = 1\n        covid_data.loc[covid_data[col] == \"negative\", col] = 0\n        covid_data.loc[covid_data[col] == \"detected\", col] = 1\n        covid_data.loc[covid_data[col] == \"not_detected\", col] = 0\n        covid_data.loc[covid_data[col] == \"present\", col] = 1\n        covid_data.loc[covid_data[col] == \"absent\", col] = 0       \n        covid_data.loc[covid_data[col] == \"N\u00e3o Realizado\", col] = float(\"Nan\")\n        covid_data.loc[covid_data[col] == \"not_done\", col] = float(\"Nan\")\n        covid_data.loc[covid_data[col] == \"<1000\", col] = 999\n        \n        \n        # print(covid_data.groupby(covid_data[col].astype(str))[['Patient ID']].count())\n        \ncovid_data[[\"Urine - Leukocytes\"]] = covid_data[[\"Urine - Leukocytes\"]].astype(float)\ncovid_data[[\"Urine - pH\"]] = covid_data[[\"Urine - pH\"]].astype(float)\ncovid_data[[\"SARS-Cov-2 exam result\"]] = covid_data[[\"SARS-Cov-2 exam result\"]].astype(int)","a463721f":"col_num = [col for col in covid_data.columns if covid_data[col].dtype in ('float64', 'int64') \n           and len(covid_data[col].unique())>3\n           and (covid_data[col].isnull().sum() \/ covid_data[col].isnull().count()) <= 0.9 # at least 10% os values are filled\n          ]\n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\n\nsns.heatmap(covid_data[col_num].astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","4443f861":"df_1 = pd.DataFrame(columns = ['variable', 'value'])\n\nfor col in covid_data.columns:\n    if len(covid_data[col].unique()) <= 5 :\n        x1 = pd.DataFrame({'variable' : col,\n                           'value' :covid_data[col].unique()\n                          })\n        df_1 = df_1.append(x1)\n\ndf_1[\"count_of_positive\"] = 0\ndf_1[\"count_of_negative\"] = 0\n\nfor row in range(len(df_1)):\n    variable = df_1.iloc[row][\"variable\"]\n    value = df_1.iloc[row][\"value\"]\n    \n    if pd.isna(value):\n        pos = len(covid_data.loc[ (pd.isna(covid_data[variable])) & (covid_data['SARS-Cov-2 exam result'] == 1) ])\n        neg = len(covid_data.loc[ (pd.isna(covid_data[variable])) & (covid_data['SARS-Cov-2 exam result'] == 0) ])\n        \n        df_1[\"count_of_positive\"].loc[ (df_1['variable'] == variable) & (pd.isna(df_1['value'])) ] = pos\n        df_1[\"count_of_negative\"].loc[ (df_1['variable'] == variable) & (pd.isna(df_1['value'])) ] = neg\n        \n        # print(neg)\n    else:\n        pos = len(covid_data.loc[ (covid_data[variable] == value) & (covid_data['SARS-Cov-2 exam result'] == 1) ])\n        neg = len(covid_data.loc[ (covid_data[variable] == value) & (covid_data['SARS-Cov-2 exam result'] == 0) ])\n\n        df_1[\"count_of_positive\"].loc[ (df_1['variable'] == variable) & (df_1['value'] == value) ] = pos\n        df_1[\"count_of_negative\"].loc[ (df_1['variable'] == variable) & (df_1['value'] == value) ] = neg","92256197":"df_1[\"percentage_of_positive\"] = df_1[\"count_of_positive\"] \/  (df_1[\"count_of_positive\"] + df_1[\"count_of_negative\"] )\n\ndf_1.sort_values(by = \"percentage_of_positive\", ascending = False)","f7226751":"from sklearn.model_selection import train_test_split\nfrom sklearn import ensemble\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nfeatures = [col for col in covid_data.columns if covid_data[col].dtype in ('float64', 'int64') and\n                                                 (covid_data[col].isnull().sum() \/ covid_data[col].isnull().count()) == 0]\n\ncovid_data2 = covid_data[features]\n\n# Splitting data\ntarget = covid_data2['SARS-Cov-2 exam result']\nX_train, X_test, y_train, y_test = train_test_split(covid_data2.drop('SARS-Cov-2 exam result',axis=1), \n                                                    target, test_size=0.20, \n                                                    random_state=0)\n\n\n# Define model. Specify a number for random_state to ensure same results each run\ncovid_model = ensemble.RandomForestClassifier(random_state=1)\n\n# Fit model\ncovid_model.fit(X_train, y_train)\n\n# Make predictions\ncovid_predictions = covid_model.predict(X_test)\n\n# Accuracy\n\nprint('Accuracy of: %.1f%%' % (accuracy_score(y_test, covid_predictions)*100))\n\n\n# Confusion matrix\ntn, fp, fn, tp = confusion_matrix(y_test, covid_predictions).ravel()\n\n(tn, fp, fn, tp)","8317d78c":"from imblearn.over_sampling import SMOTE\n\n\nfeatures = [col for col in covid_data.columns if covid_data[col].dtype in ('float64', 'int64') and\n                                                 (covid_data[col].isnull().sum() \/ covid_data[col].isnull().count()) == 0]\n\ntarget = covid_data2['SARS-Cov-2 exam result']\n\n# Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(covid_data2.drop('SARS-Cov-2 exam result',axis=1), \n                                                    target, test_size=0.20, \n                                                    random_state=0)\n\n# OverSample\noversample = SMOTE()\nX_train, y_train = oversample.fit_resample(X_train, y_train)\n\n\n# Define model. Specify a number for random_state to ensure same results each run\ncovid_model = ensemble.RandomForestClassifier(random_state=1)\n\n# Fit model\ncovid_model.fit(X_train, y_train)\n\n# Make predictions\ncovid_predictions = covid_model.predict(X_test)\n\n# Accuracy\n\nprint('Accuracy of: %.1f%%' % (accuracy_score(y_test, covid_predictions)*100))\n\n\n# Confusion matrix\ntn, fp, fn, tp = confusion_matrix(y_test, covid_predictions).ravel()\n\n(tn, fp, fn, tp)\n","eca058bf":"features_cat = [col for col in covid_data.columns if  ( (covid_data[col].dtype == 'object') and\n                                                    (covid_data[col].isnull().sum() \/ covid_data[col].isnull().count()) >= 0 and\n                                                    (covid_data[col].isnull().sum() \/ covid_data[col].isnull().count()) <= 0.9\n                                                  )]\n\nfeatures_num = [col for col in covid_data.columns if  ( (covid_data[col].dtype != 'object') and\n                                                    (covid_data[col].isnull().sum() \/ covid_data[col].isnull().count()) >= 0 and\n                                                    (covid_data[col].isnull().sum() \/ covid_data[col].isnull().count()) <= 0.9\n                                                  )]\n\nfeatures  = features_cat + features_num\ncovid_data2 = covid_data[features].fillna(-1)\n\n","92c1a36f":"# label encoding the data \nfrom sklearn.preprocessing import LabelEncoder \n  \nle = LabelEncoder() \n           \nfor ele in features_cat:\n\n    covid_data2[ele]= le.fit_transform(covid_data2[ele]) \n","46b502ad":"from imblearn.over_sampling import SMOTE\n\ntarget = covid_data2['SARS-Cov-2 exam result']\n\n# Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(covid_data2.drop('SARS-Cov-2 exam result',axis=1), \n                                                    target, test_size=0.20, \n                                                    random_state=0)\n\n# OverSample\noversample = SMOTE()\nX_train, y_train = oversample.fit_resample(X_train, y_train)\n\n\n# Define model. Specify a number for random_state to ensure same results each run\ncovid_model = ensemble.RandomForestClassifier(random_state=1)\n\n# Fit model\ncovid_model.fit(X_train, y_train)\n\n# Make predictions\ncovid_predictions = covid_model.predict(X_test)\n\n# Accuracy\n\nprint('Accuracy of: %.1f%%' % (accuracy_score(y_test, covid_predictions)*100))\n\n\n# Confusion matrix\ntn, fp, fn, tp = confusion_matrix(y_test, covid_predictions).ravel()\n\n(tn, fp, fn, tp)\n\n","8b9e010e":"features = [col for col in covid_data.columns if covid_data[col].dtype in ('float64', 'int64') \n           and len(covid_data[col].unique())<30\n            and len(covid_data[col].unique())>=2\n          ]\n\nfor ele in features:\n    \n    graph = covid_data.groupby([ele,'SARS-Cov-2 exam result'])['SARS-Cov-2 exam result'].count().unstack()\n    graph.plot(kind='bar', stacked=True)\n\n","5c04c112":"# Data Exploration\n\n**Let's take a look at the dataset**","e4aeeee0":"# Data cleaning\n\nWe have the target column **SARS-Cov-2 exam result**, which representes if a patient is positive or negative. Let's first transform all string columns into numerical.","b27596b6":"# Modeling 1 Imbalanced data#\n1. Numerical variables only\n2. NOT Oversampling data\n3. Variables that not contain \"na\" values","e3a99e5d":"# Modeling 2 Oversampling data#\n1. Numerical variables only\n2. Oversampling data\n3. Variables that not contain \"na\" values","216b72d5":"# Pearson Correlation of Features","49ca8733":"# Frequency table\n\nNow we will group all variables by the target values","3ad3788b":"# Modeling 3 Oversampling data One Hot Encode#\n1. All variables with at least 10% of records filled\n2. Oversampling data\n3. One hot encode","d083bb55":"# Set up the notebook\n**First, we need to import some libraries**","69276745":"# Plotting some graphs"}}