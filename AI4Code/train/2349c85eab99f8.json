{"cell_type":{"33a18ff6":"code","fbabfef1":"code","49f44610":"code","635b1424":"code","1dd101ce":"code","8e4ec8c3":"markdown"},"source":{"33a18ff6":"! pip install imutils\n\nimport os\nimport math\nimport cv2\nimport dlib\nimport numpy as np\nfrom imutils import face_utils\nimport matplotlib.pyplot as plt","fbabfef1":"# Define mathematics functions\n\ndef slope(point1, point2, absolute=False):\n    x1,y1 = point1\n    x2,y2 = point2\n    deltaX = x2-x1\n    deltaY = y2-y1\n    if deltaX == 0:\n        return \"inf\"\n    slope = deltaY \/ deltaX\n    if absolute:\n        slope = abs(slope)\n    return round(slope,3)","49f44610":"# Define helper functions\n\ndef load_images_from_folder(folder):\n    images = []\n    filenames = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        if img is not None:\n            images.append(img)\n            filenames.append(filename)\n    return images, filenames\n","635b1424":"# Build 'computer vision' functions\n\npredictor68 = dlib.shape_predictor('..\/input\/shape-predictor-68-face-landmarks\/shape_predictor_68_face_landmarks.dat')\npredictor81 = dlib.shape_predictor('..\/input\/shape-predictor81\/shape_predictor_81_face_landmarks.dat')\n\n# Function to determine the color range allowed to move landmarks points through image\ndef getAllowedColorRange(avgSkinColor):\n    # Dark skin\n    if (avgSkinColor < 100):\n        colorRange = (avgSkinColor-35, avgSkinColor+50)\n    # Somehow dark skin\n    elif(avgSkinColor <= 130): \n        colorRange = (avgSkinColor-30, avgSkinColor+30)\n    # Normal skin color (tends to dark)\n    elif(avgSkinColor <= 160):\n        colorRange = (avgSkinColor-40, avgSkinColor+40) \n    # Normal skin color \n    elif(avgSkinColor < 180):\n        colorRange = (avgSkinColor-50, avgSkinColor+50)\n    # Normal skin color (tends to white)\n    elif(avgSkinColor < 210):\n        colorRange = (avgSkinColor-50, avgSkinColor+30) \n    # white skin color\n    elif (avgSkinColor < 230):\n        colorRange = (avgSkinColor-40, avgSkinColor+20)\n    # Abnormal white skin color\n    else:\n        colorRange = (avgSkinColor-30, avgSkinColor+15)\n    return colorRange\n\n# Function to move landmarks points, based on skincolor\ndef moveUp(grayscale_image, point, avgSkinColor, foreheadHeight):\n    # Get color range & current color where the point is located in image\n    steps = 5\n    portionOfOriginalPointY = 0.275\n    originalPoint = np.copy(point)\n    colorRange = getAllowedColorRange(avgSkinColor)\n    currentPixelColor = grayscale_image.item(point[1],point[0])\n    \n    # move the landmark point up until a strong change of color happen (outside color range)\n    while currentPixelColor > colorRange[0] and currentPixelColor < colorRange[1]:\n        \n        # If point is going out of image boundary\n        if point[1] < 0:\n            # Get back to original point location, with a little bit higher\n            point[1] = originalPoint[1] - (originalPoint[1] * portionOfOriginalPointY)\n            break\n            \n        # move up (N steps) pixels & get the color\n        point[1] = point[1] - steps\n        \n        currentPixelColor = grayscale_image.item(point[1],point[0])\n        \n    # if the pixel is moved too high than expected (3\/4 forehead height): keep close to original\n    if abs( originalPoint[1] - point[1] ) > ( foreheadHeight * 0.75 ):\n        point[1] = originalPoint[1] - (originalPoint[1] * portionOfOriginalPointY)\n    return point\n\n# Function to detect if the forehead is clear or covered with hair (it corrupts the enhancement of landmarks points)\ndef clearForehead(forehead, avgSkinColor):\n    clarityThreshold = 85\n    colorRange = getAllowedColorRange(avgSkinColor)\n    \n    # Check if most of the forehead is the same as skin color\n    regionOK = np.logical_and(forehead > colorRange[0] , forehead < colorRange[1])\n    try:\n        percentage = (np.count_nonzero(regionOK) \/ forehead.size) * 100\n    except:\n        return False\n    isClear = True if percentage >= clarityThreshold else False\n    return isClear\n\n\n# Function to perform facial landmark detection on the whole face\ndef facial_landmarks(image, eyeOnlyMode=False, allowEnhancement=False):\n    # ARGUMENTS:\n    # - eyeOnlyMode: detect & return eye landmarks, used to align face\n    # - allowEnhancement: allow improvement (landmarks repositioning)\n    \n    # Return:\n    # - NumPy array of coordinates of landmarks\n    \n    # Use dlib 68 & 81 to predict landmarks points coordinates\n    detector = dlib.get_frontal_face_detector()\n    global predictor68\n    global predictor81\n    \n    # Grayscale image\n    try:\n        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    except:\n        grayscale_image = image\n    \n    # array of rectangles surrounding faces detected\n    rectangles = detector(grayscale_image, 1)\n\n    # If at least one face is detected   \n    if len(rectangles) > 0:\n        # Get 68 landmark points\n        faceLandmarks = predictor68(grayscale_image, rectangles[0])\n        faceLandmarks = face_utils.shape_to_np(faceLandmarks)\n        \n        if eyeOnlyMode:\n            # Return eye points to perform a calculated rotation\n            return np.array([faceLandmarks[39], faceLandmarks[42]])\n        \n        # Get 81 landmark points\n        foreheadLandmarks = predictor81(grayscale_image, rectangles[0])\n        foreheadLandmarks = face_utils.shape_to_np(foreheadLandmarks)\n        \n        # Get 68 point from -68- predictor (higher accuracy) + forehead from -81- predictor\n        fullFacePoints = np.concatenate((faceLandmarks, foreheadLandmarks[68:]))\n        \n        # Get forehead region & height to perform simple improvement\n        x,y,x2,y2 = (fullFacePoints[69,0]-10, fullFacePoints[68,1], fullFacePoints[80,0]+10, fullFacePoints[23, 1])\n        foreheadRegion = grayscale_image[y:y2,x:x2]\n        foreheadHeight = foreheadRegion.shape[0]\n        \n        if allowEnhancement:\n            # Perform progressive quality improvement\n            # Get nose region to get average skin color\n            x,y,x2,y2 = (fullFacePoints[28,0]-5, fullFacePoints[28,1], fullFacePoints[28,0]+5, fullFacePoints[30,1])\n            noseRegion = grayscale_image[y:y2, x:x2]\n            avgSkinColor = np.average(noseRegion[:,:])\n            \n            # Check if forehead is clear -> perform heuristic based enhancement\n            forehead_is_clear = clearForehead(foreheadRegion, avgSkinColor)\n            originalPoints = fullFacePoints[[69,70,71,73,80]]\n            \n            if forehead_is_clear:\n                avgSkinColor = np.average(foreheadRegion)\n                \n                # Modify some points for more accuracy\n                # Point[68] will be center between lower-lip & chin\n                distance = int((fullFacePoints[8,1]-fullFacePoints[57,1]) \/ 2)\n                fullFacePoints[68] = np.array([fullFacePoints[8,0], fullFacePoints[8,1]-distance])\n                \n                # Enhance points locations\n                enhancedPoints = np.array([moveUp(grayscale_image, orgPoint, avgSkinColor, foreheadHeight) for orgPoint in originalPoints])\n\n                # Assign original points to enhanced points (some maybe the same)\n                fullFacePoints[[69,70,71,73,80]] = enhancedPoints  \n                \n                # Adjust points to fix any corruptions\n                fullFacePoints[[69,70,71,73,80]] = adjustPoints(enhancedPoints, fullFacePoints[76], fullFacePoints[79])\n\n                #Prepare point[72] for center of forehead\n                distance = (fullFacePoints[22,0] - fullFacePoints[21,0]) \/ 2\n                distanceY = (fullFacePoints[21,1] - fullFacePoints[71,1]) \/ 2\n                fullFacePoints[72] = np.array([fullFacePoints[21,0] + distance, fullFacePoints[21,1]-distanceY])\n                \n                # Point[74] sometimes have a fixed corruption, this line helps :)\n                fullFacePoints[74,0] -= foreheadHeight * 0.1 # Arbitery heurestic\n                \n            else:\n                # If forehead isn't clear -> fix points with very simple heuristics\n                fullFacePoints[70,1] -= foreheadHeight * 0.2\n                fullFacePoints[71,1] -= foreheadHeight * 0.3\n                fullFacePoints[80,1] -= foreheadHeight * 0.2\n    \n        else:\n            # If Enhancement is False -> do the simple enhancement, better quality + low performance :)\n#             fullFacePoints[70,1] -= foreheadHeight * 0.2\n#             fullFacePoints[71,1] -= foreheadHeight * 0.3\n#             fullFacePoints[80,1] -= foreheadHeight * 0.2\n            pass\n        \n        return fullFacePoints\n    # No faces found\n    else:\n        return None\n\n# Function to adjust landmarks points of the forehead \n# and fix corruptions of improvement (such as the bald man case)\ndef adjustPoints(points, leftSidePoint, rightSidePoint):    \n    # Use shape_predictor_81 as a reference for points indexes to fix:\n    # points = [69,70,71,73,80]\n    # LeftSidePoint = 76  |  rightSidePoint = 79\n    \n    slopes = []\n    slopeThreshold = 0.4 # slope > 0.4 = corruption -> fix\n    totalSlopeThreshold = 1 # sum of slopes > 1 = corruption -> fix\n    leftPoint = points[0]\n    rightPoint = points[3]\n    criticalLeftPoint = points[1]\n    criticalRightPoint = points[4]\n    \n    # if any point is higher than a (accurate located point) -> fix\n    if leftPoint[1] < criticalLeftPoint[1] :\n        points[0,1] = np.average([criticalLeftPoint[1], leftSidePoint[1]])\n    if rightPoint[1] < criticalRightPoint[1]:\n        points[3,1] = np.average([criticalRightPoint[1], rightSidePoint[1]])\n    \n    # Collect some slopes of the usually corrupted points\n    slopes.append(slope(points[1], points[2], True))\n    slopes.append(slope(points[2], points[4], True))\n    \n    # Calculate slope differences & sum\n    difference = abs(np.diff(slopes))\n    _sum = np.sum(slopes)\n    \n    # If calculation results (either) too high = corruption -> fix\n    if difference > slopeThreshold:\n        issueIndex = np.argmax(slopes)\n        if issueIndex == 0:\n            points[1,1] = max(points[4,1], points[2,1])\n        else:\n            points[4,1] = max(points[1,1], points[2,1])\n            \n    if _sum > totalSlopeThreshold:\n        points[1,1] = np.average(points[[4,2], 1])\n        points[4,1] = np.average(points[[1,2], 1])\n        points[2,1] = np.average(points[[4,1], 1])  \n        \n    return points\n\n# Function to rotate image to align the face\ndef align_face(image, eyePoints):\n    # Get left eye & right eye coordinates\n    leftEyeX,leftEyeY = eyePoints[0]\n    rightEyeX, rightEyeY = eyePoints[1]\n\n    # Calculate angle of rotation & origin point\n    angle = math.atan( (leftEyeY - rightEyeY) \/ (leftEyeX - rightEyeX) ) * (180\/math.pi)\n    origin_point = tuple(np.array(image.shape[1::-1]) \/ 2)\n\n    # Rotate using rotation matrix\n    rot_mat = cv2.getRotationMatrix2D(origin_point, angle, 1.0)\n    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n    return result\n\n\n# Function to draw points on facial features\ndef drawPoints(image, points, pointColor=(255,255,255), lineColor=(255,255,255), pointThickness=None, lineThickness=1):\n    if pointThickness is None:\n        pointThickness = round((7\/1200) * image.shape[1])\n    imgcopy = image.copy()\n    for i in points:\n        x,y = i\n        imgcopy = cv2.circle(imgcopy, (x,y), radius=0, color=pointColor, thickness=pointThickness)\n    return imgcopy\n\n\ndef main():\n    # Capture all images in current folder & their names\n    images, filesnames = load_images_from_folder('..\/input\/facessamples2')\n    \n    # Detect & Visualize each image\n    for originalImage in images:\n        originalImage = cv2.cvtColor(originalImage,cv2.COLOR_BGR2RGB)\n        \n        eyes_landmarks = facial_landmarks(originalImage, eyeOnlyMode=True)\n        \n        if eyes_landmarks is not None:\n            # Align face\n            face_aligned = align_face(originalImage, eyes_landmarks)\n            \n            # Detect landmarks (NO improve)\n            landmarks_no_improve = facial_landmarks(face_aligned,\n                                                    allowEnhancement=False)\n            \n            # Draw landmarks (not improved)\n            image_no_improve = drawPoints(face_aligned, landmarks_no_improve)\n            \n            \n            # Improve landmarks after the face is aligned\n            landmarks_improved = facial_landmarks(face_aligned,\n                                                  allowEnhancement=True\n                                                 )\n            \n            # Draw landmarks (not improved)\n            image_improved = drawPoints(face_aligned, landmarks_improved)\n            \n\n            f, axarr = plt.subplots(1,2, figsize=(16,16))\n            axarr[0].imshow(image_no_improve)\n            axarr[0].set_axis_off()\n            axarr[0].set_title(\"Before Improve\")\n            \n            axarr[1].imshow(image_improved)\n            axarr[1].set_axis_off()\n            axarr[1].set_title(\"After Improve\")\n            \n            plt.show()\n            print()\n            print()","1dd101ce":"main()","8e4ec8c3":"# Full Face Landmarks Detection (Highly Improved)\n> \u201cWhat this algorithm does to the landmarks, is the same thing that a dentist\/orthodontist does to his patient's teeth\u201d\n\n<br>\n<img src=\"https:\/\/user-images.githubusercontent.com\/50156227\/140418778-f6c5dba1-abc6-475a-97ae-e49cb7686912.gif\" height=\"480\">\n<br>\n\n<h3>What was the problem?<\/h3>\n<ol>\n    <li>\n        <b>NOT Enough Landmarks:<\/b><br>\n        The shape_predictor_68_landmarks has a good (actually high) quality detecting landmarks, but it does NOT include the whole face\n    <\/li>\n    <li>\n        <b>Low Quality<\/b><br>\n        The shape_predictor_81_landmarks has enough landmarks for all facial features, BUT low quality detection.\n    <\/li>\n<\/ol>\n\n<h2>Solution:<\/h2>\n<ol>\n    <li>\n        <b>Use the best of both worlds<\/b>:<br>\nSelect the 68 high quality points from the 68 landmarks shape predictor, and the last 13 points (<b>forehead landmarks<\/b>) from the 81 landmarks shape predictor<br>\n    <\/li>\n    <li>\n        <b>Improve the quality of the forehead landmarks<\/b>:<br>\nReposition the forehead landmarks by heuristically clustering skin colors and giving a range for each cluster, then move every point individually upward by a specified step size (in pixels), until the color underneath the point is out of the skin color range (which means we reached the edge between the forehead and hair), there, is the best position for a landmark on the forehead<br>\n    <\/li>\n<\/ol>\n\n<h3>Questions outside the box:<\/h3>\n<ol>\n        <li>\n        <b>How to determine the range of the skin color?<\/b>: <br>\ntake a slice from the nose (the most part that's not affected by shadows\/lights issues), then calculate the average of pixels colors, then discover which cluster is this skin color, finally set range based on that cluster. <br>\n    <\/li>\n    <li>\n        <h3>What if the forehead is too clear (bald man)?:<\/h3>\n       <img src=\"https:\/\/user-images.githubusercontent.com\/50156227\/140418814-a4609dce-9a43-4a30-9518-74242663d93e.gif\"><br>\n    <\/li>\n    <li>\n        <h3>What if the forehead isn't clear, (hair covers it)?:<\/h3>\n   <img src=\"https:\/\/user-images.githubusercontent.com\/50156227\/140418889-f76ac8d2-4389-4f30-9f67-cc41d8defd6e.gif\">\n    <\/li>\n<\/ol>\n\n"}}