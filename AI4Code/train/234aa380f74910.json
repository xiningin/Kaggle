{"cell_type":{"14124b6e":"code","cfbc4dae":"code","428eb0c2":"code","75fac196":"code","0a30eb21":"code","ca8e3a91":"code","900598c3":"code","60bc85a2":"code","65153628":"code","e71c732f":"code","bf508df7":"code","57f04474":"code","a45d9b99":"code","289d0c8c":"code","4c477f70":"code","352fe6c9":"code","a92d9779":"code","a4f30e12":"code","cfe8b51a":"code","7cedb477":"code","a9e2b4ca":"code","00a58d4c":"code","d9d4f0d9":"code","a305944e":"code","1e585398":"code","0eff509f":"code","c7dd04a9":"code","cdb746d8":"code","78c390d7":"code","8733f9b2":"code","b2995e68":"code","dd1f09ef":"code","9e1745d2":"code","42b26c3e":"code","a115d587":"code","cfadd5fa":"code","eb742c48":"code","953b1585":"code","7e2b4e02":"code","2f57c942":"code","e52d77dd":"code","cdac03de":"code","84254284":"code","bd52c9e6":"code","6750e00e":"code","8038bd27":"code","2ce88510":"code","428ea4fc":"code","5e9c1767":"code","32f80f58":"code","4f36500e":"code","9d2797f0":"code","b870a08b":"markdown","c2c790e5":"markdown","7622e1ae":"markdown","33cd188f":"markdown","d9c3afae":"markdown","359ffb5f":"markdown","6607c5f5":"markdown","3cafb9be":"markdown","ec4cea4f":"markdown","838e5565":"markdown","0e177242":"markdown","986309c4":"markdown","6d56be8e":"markdown","0e52dff6":"markdown","0eb56e27":"markdown","91eb43d2":"markdown","5095f7ea":"markdown","c2686f9d":"markdown"},"source":{"14124b6e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cfbc4dae":"!pip install jovian --upgrade\nimport jovian\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\n\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","428eb0c2":"project_name='02-insurance-linear-regression' ","75fac196":"DATASET_URL = \"https:\/\/hub.jovian.ml\/wp-content\/uploads\/2020\/05\/insurance.csv\"\nDATA_FILENAME = \"insurance.csv\"\ndownload_url(DATASET_URL, '.')","0a30eb21":"dataframe_raw = pd.read_csv(DATA_FILENAME)\ndataframe_raw.head()","ca8e3a91":"len(dataframe_raw)\n","900598c3":"dataframe_raw.dropna()","60bc85a2":"dataframe_raw.describe()","65153628":"your_name = 'Preeti'","e71c732f":"def customize_dataset(dataframe_raw, rand_str):\n    dataframe = dataframe_raw.copy(deep=True)\n    # drop some rows\n    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n    # scale input\n    dataframe.bmi = dataframe.bmi * ord(rand_str[1])\/100.\n    # scale target\n    dataframe.charges = dataframe.charges * ord(rand_str[2])\/100.\n    # drop column\n    if ord(rand_str[3]) % 2 == 1:\n        dataframe = dataframe.drop(['region'], axis=1)\n    return dataframe","bf508df7":"dataframe = customize_dataset(dataframe_raw, your_name)\ndataframe.head()","57f04474":"num_rows = dataframe.shape[0]\nnum_rows","a45d9b99":"num_cols = dataframe.shape[1]\nnum_cols","289d0c8c":"input_cols = [\"age\",\"sex\",\"bmi\",\"children\",\"smoker\",\"charges\"]\ninput_cols","4c477f70":"categorical_cols = ['sex', 'smoker']\ndataframe.head()[categorical_cols]","352fe6c9":"output_cols = ['charges']\nprint(dataframe[output_cols])","a92d9779":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a4f30e12":"t = dataframe[output_cols]   #avg\navg = t\/len(dataframe)\nsns.distplot(avg)\n","cfe8b51a":"e = t.max()\nsns.barplot(e )","7cedb477":"f = t.min()\nsns.barplot(f)","a9e2b4ca":"jovian.commit(project=project_name, environment=None)","00a58d4c":"dataframe[output_cols].mean()","d9d4f0d9":"dataframe[output_cols].min()\n","a305944e":"dataframe[output_cols].max()","1e585398":"plt.title('Distribution')\nsns.distplot(dataframe[output_cols], kde=False)","0eff509f":"plt.title('Distribution')\nsns.scatterplot(dataframe['charges'],dataframe_raw['bmi'])","c7dd04a9":"sns.barplot(dataframe['age'],dataframe_raw['bmi'])","cdb746d8":"avg_smokers_charges = dataframe[dataframe.smoker == 'yes'][output_cols].mean()\navg_non_smokers_charges = dataframe[dataframe.smoker == 'no'][output_cols].mean()\nprint('Average smokers', avg_smokers_charges)\nprint('Average non smokers', avg_non_smokers_charges)\nplt.show()","78c390d7":"avg_smokers_charges\/avg_non_smokers_charges","8733f9b2":"sns.catplot(x=\"sex\", y=\"charges\", hue=\"smoker\",\n            kind=\"violin\", data=dataframe, palette = 'magma')","b2995e68":"sns.boxplot(y=\"smoker\", x=\"charges\",data = dataframe[(dataframe.age == 18)],palette='pink')","dd1f09ef":"plt.figure(figsize=(12,5))\nplt.title(\"Distribution of bmi\")\nax = sns.distplot(dataframe[\"bmi\"], color = 'm')","9e1745d2":"def dataframe_to_arrays(dataframe):\n    # Make a copy of the original dataframe\n    dataframe1 = dataframe.copy(deep=True)\n    # Convert non-numeric categorical columns to numbers\n    for col in categorical_cols:\n        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n    # Extract input & outupts as numpy arrays\n    inputs_array = dataframe1[input_cols].to_numpy()\n    targets_array = dataframe1[output_cols].to_numpy()\n    return inputs_array, targets_array","42b26c3e":"inputs_array, targets_array = dataframe_to_arrays(dataframe)\ninputs_array.shape, inputs_array, targets_array","a115d587":"inputs = torch.from_numpy(inputs_array).type(torch.float32)\ntargets = torch.from_numpy(targets_array).type(torch.float32)","cfadd5fa":"inputs.dtype, targets.dtype","eb742c48":"dataset = TensorDataset(inputs, targets)","953b1585":"from sklearn.model_selection import train_test_split\n\nval_percent = 0.1 # between 0.1 and 0.2\nval_size = int(num_rows * val_percent)\ntrain_size = num_rows - val_size\n\n\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\n#refrence from https:\/\/jovian.ml\/kir-prz\/02-insurance-linear-regression","7e2b4e02":"batch_size = 32","2f57c942":"train_loader = DataLoader(train_ds,  \n                          batch_size,\n                         shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)\n","e52d77dd":"for xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break","cdac03de":"jovian.commit(project=project_name, environment=None)","84254284":"input_size = len(input_cols)\noutput_size = len(output_cols)","bd52c9e6":"class InsuranceModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, output_size)               # fill this (hint: use input_size & output_size defined above)\n        \n    def forward(self, xb):\n        out = self.linear(xb)                        # fill this\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out,targets)                       # fill this\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out,targets)               # fill this    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","6750e00e":"model = InsuranceModel()","8038bd27":"list(model.parameters())\n","2ce88510":"jovian.commit(project=project_name, environment=None)","428ea4fc":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","5e9c1767":"\nresult = evaluate(model, val_loader)\nprint(result)","32f80f58":"epochs = 5000\nlr = 1.5e-1\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","4f36500e":"loss = []\nfor values in history2:\n    loss.append(values['val_loss'])\nplt.plot(loss)","9d2797f0":"jovian.commit(project=project_name, environment=None)","b870a08b":"Step 4: Train the model to fit the data\nTo train our model, we'll use the same fit function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem.","c2c790e5":"Finally, we can create data loaders for training & validation.\n\nQ: Pick a batch size for the data loader.\n\n","7622e1ae":"**Q: Which of the input columns are non-numeric or categorial variables ?**\n","33cd188f":"> Q: How many columns doe the dataset have**","d9c3afae":"****Q: What are the column titles of output\/target variable(s)?****","359ffb5f":"**Let us answer some basic questions about the dataset.\n\nQ: How many rows does the dataset have?**","6607c5f5":"Let us create a model using the InsuranceModel class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes nan or infinity.","3cafb9be":"In non-smokers, the cost of treatment increases with age. That makes sense. So take care of your health, friends! In smoking people, we do not see such dependence. I think that it is not only in smoking but also in the peculiarities of the dataset. Such a strong effect of Smoking on the cost of treatment would be more logical to judge having a set of data with a large number of records and signs. But we work with what we have! Let's pay attention to bmi. I am surprised that this figure but affects the cost of treatment in patients. Or are we on a diet for nothing?","ec4cea4f":"The customize_dataset function will customize the dataset slightly using your name as a source of random numbers.","838e5565":"Lets check out the weight and bias of model using model.parameters() .","0e177242":"Step 2: Prepare the dataset for training\nWe need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out input_cols, categorial_cols and output_cols correctly, this following function will perform the conversion to numpy arrays.","986309c4":"**Q: (Optional) What is the minimum, maximum and average value of the charges column? Can you show the distribution of values in a graph? Use this data visualization cheatsheet for referece: https:\/\/jovian.ml\/aakashns\/dataviz-cheatsheet**","6d56be8e":"Use the evaluate function to calculate the loss on the validation set before training.","0e52dff6":"Q: What are the column titles of the input variables?****","0eb56e27":"Q: Convert the numpy arrays inputs_array and targets_array into PyTorch tensors. Make sure that the data type is torch.float32.\n\n","91eb43d2":": Pick a number between 0.1 and 0.2 to determine the fraction of data that will be used for creating the validation set. Then use random_split to create training & validation datasets.","5095f7ea":"Q: Complete the class definition below by filling out the constructor (__init__), forward, training_step and validation_step methods.\n\nHint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See","c2686f9d":"*Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a TensorDataset.*"}}