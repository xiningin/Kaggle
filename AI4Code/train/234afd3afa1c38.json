{"cell_type":{"1228a0ca":"code","385ed48c":"code","ac281a7e":"code","7580f275":"code","2488ba68":"code","bad83d7a":"code","54ffe0ba":"code","942e2e07":"code","3d625c8a":"code","fda551a8":"code","4636322f":"code","885b29c7":"code","7b780a03":"code","b08ed224":"code","2966b2f1":"code","95af42a3":"code","7cbd34a6":"code","67b359a1":"code","090ff150":"markdown","26e31e64":"markdown","9fd5a524":"markdown","3e2d3785":"markdown","5ebff6df":"markdown","743b2da7":"markdown","70c20665":"markdown","990fada6":"markdown","ba27f38a":"markdown","74758687":"markdown","b30b4b51":"markdown","45338032":"markdown","2919d7ee":"markdown","e9a6ccf4":"markdown","d530788f":"markdown","86554ae1":"markdown","f52a3c57":"markdown","f61dd31f":"markdown","78860388":"markdown","66f971d4":"markdown","ae23eedb":"markdown","7805fd04":"markdown","fb4354b8":"markdown","ccc58b5f":"markdown","1e8c6e47":"markdown","465ab77f":"markdown","97ecf9d6":"markdown","bb39f081":"markdown","aae25fb5":"markdown","e5c53af6":"markdown","24aa9162":"markdown","d3ef65e2":"markdown","60eaa502":"markdown","5047c25e":"markdown","81b6c7e4":"markdown","49e8c989":"markdown","7d8fb65d":"markdown"},"source":{"1228a0ca":"import pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \nimport matplotlib.pyplot as plt","385ed48c":"#Click here and press Shift+Enter\n!wget -O cell_samples.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/cell_samples.csv","ac281a7e":"cell_df = pd.read_csv(\"cell_samples.csv\")\ncell_df.head()","7580f275":"#refer the DataSlicing and Mathplotlib Notebooks for details about ploting and slicing the data\nax = cell_df[cell_df['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='malignant');\ncell_df[cell_df['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benign', ax=ax);\nplt.show()","2488ba68":"cell_df.dtypes","bad83d7a":"cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]\ncell_df['BareNuc'] = cell_df['BareNuc'].astype('int')\ncell_df.dtypes","54ffe0ba":"feature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\nX = np.asarray(feature_df)\nX[0:5]","942e2e07":"cell_df['Class'] = cell_df['Class'].astype('int')\ny = np.asarray(cell_df['Class'])\ny [0:5]","3d625c8a":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","fda551a8":"from sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train) ","4636322f":"yhat = clf.predict(X_test)\nyhat [0:5]","885b29c7":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools","7b780a03":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","b08ed224":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[2,4])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat))\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Benign(2)','Malignant(4)'],normalize= False,  title='Confusion matrix')","2966b2f1":"from sklearn.metrics import f1_score\nf1_score(y_test, yhat, average='weighted') ","95af42a3":"clf1 = svm.SVC(kernel='linear')\nclf1.fit(X_train, y_train) \nyhat1 = clf1.predict(X_test)\nyhat1 [0:5]","7cbd34a6":"cnf_matrix1 = confusion_matrix(y_test, yhat1, labels=[2,4])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat1))\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix1, classes=['Benign(2)','Malignant(4)'],normalize= False,  title='Confusion matrix')","67b359a1":"from sklearn.metrics import f1_score\nf1_score(y_test, yhat1, average='weighted') ","090ff150":"<h2 id=\"load_dataset\">Load the Cancer data<\/h2>\nThe example is based on a dataset that is publicly available from the UCI Machine Learning Repository (Asuncion and Newman, 2007)[http:\/\/mlearn.ics.uci.edu\/MLRepository.html]. The dataset consists of several hundred human cell sample records, each of which contains the values of a set of cell characteristics. The fields in each record are:\n\n|Field name|Description|\n|--- |--- |\n|ID|Clump ID|\n|Clump|Clump thickness|\n|UnifSize|Uniformity of cell size|\n|UnifShape|Uniformity of cell shape|\n|MargAdh|Marginal adhesion|\n|SingEpiSize|Single epithelial cell size|\n|BareNuc|Bare nuclei|\n|BlandChrom|Bland chromatin|\n|NormNucl|Normal nucleoli|\n|Mit|Mitoses|\n|Class|Benign or malignant|\n\n<br>\n<br>\n\nFor the purposes of this example, we're using a dataset that has a relatively small number of predictors in each record. To download the data, we will use `!wget` (We studied it in last Lab) to download it from IBM Object Storage.  \n","26e31e64":"It looks like the __BareNuc__ column includes some values that are not numerical. We can drop those rows: ","9fd5a524":"We then split the data into 4 types, input test , input train, output test and output train. We then have a look at their shapes which tells us about their rows and columns. The shape attribute gives us results in the form of (rows,columns).","3e2d3785":"We want the model to predict the value of Class (that is, benign (=2) or malignant (=4)). As this field can have one of only two possible values, we need to change its measurement level to reflect this.","5ebff6df":"<h2 id=\"practice\">Practice<\/h2>\nCan you rebuild the model, but this time with a __linear__ kernel? You can use __kernel='linear'__ option, when you define the svm. How the accuracy changes with the new kernel function?","743b2da7":"<h2>Thanks for completing this lesson!<\/h2>\n<h4>Author:  Santosh Bothe <\/a><\/h4>\n<hr>\n\n<p>Copyright &copy; 2020 ML Class IEDC Shirur.","70c20665":"Now we select the input we want to give to the model. We select the required features and transform them into a array using .asarray attribute. Then we slice the rows and get the values of the first 5 rows using [0:5].","990fada6":"### Load Data From CSV File  ","ba27f38a":"We import the algorithm and then apply it to build the model. We use the default RBF(Radial Basis Function for computations).Then we fit the training data into the model to see how well the model works.","74758687":"Here, according to the values we have plotted the classes to which malignant and benign belong to. We have used Matplotlib and data slicing here. Data slicing here means [0:50] so we have taken 50 rows ( from 0 to 49) and uses the values of all their columns.","b30b4b51":"The ID field contains the patient identifiers. The characteristics of the cell samples from each patient are contained in fields Clump to Mit. The values are graded from 1 to 10, with 1 being the closest to benign.\n\nThe Class field contains the diagnosis, as confirmed by separate medical procedures, as to whether the samples are benign (value = 2) or malignant (value = 4).\n\nLets look at the distribution of the classes based on Clump thickness and Uniformity of cell size:","45338032":"You can also easily use the __f1_score__ from sklearn library:","2919d7ee":"Here, we directly import the f1-score from sklearn library and have a look at the results.","e9a6ccf4":"Lets first look at columns data types:","d530788f":"Here, we convert the Barenuc column which is of the type object to int so that it is easier for computations.","86554ae1":"<h2 id=\"evaluation\">Evaluation<\/h2>","f52a3c57":"<h1>Table of contents<\/h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a href=\"#load_dataset\">Load the Cancer data<\/a><\/li>\n        <li><a href=\"#modeling\">Modeling<\/a><\/li>\n        <li><a href=\"#evaluation\">Evaluation<\/a><\/li>\n        <li><a href=\"#practice\">Practice<\/a><\/li>\n    <\/ol>\n<\/div>\n<br>\n<hr>","f61dd31f":"> Double-click __here__ for the solution.\n\n<!-- Your answer is below:\n    \nclf2 = svm.SVC(kernel='linear')\nclf2.fit(X_train, y_train) \nyhat2 = clf2.predict(X_test)\nprint(\"Avg F1-score: %.4f\" % f1_score(y_test, yhat2, average='weighted'))\nprint(\"Jaccard score: %.4f\" % jaccard_similarity_score(y_test, yhat2))\n\n-->","78860388":"We import classification report and confusion matrix from the sklearn library to check the accuracy of our model.","66f971d4":"Here we have plotted the confusion matrix.Here True Positives are 85, False Negatives are 5, False Positive is 0 and True Positives are 47. This means that 132 values were predicted correctly and 5 values were predicted wrongly by the model. In the classification reports we can see different accuracy scores like f1- score,accuracy, etc. which tell us more about how well the model is predicting. We have a got a f1-score of 96%.","ae23eedb":"<h2 id=\"modeling\">Modeling (SVM with Scikit-learn)<\/h2>","7805fd04":"Here we imported libraries that are required for building the SVM model. We import Pandas, Pylab, Numpy, a package of scipy library that is optimize, from sklearn we import a part which is preprocessing and train_test_split. We also import Matplotlib. Pandas is used to import data and numpy is used for calculations. Scipy library is used for gernally and scientific computing. Sklearn is a libary used for the machine learning algorithms and we imported preprocessing from it to extract features from the dataset and train_test_split is used to import the data into test and training data. Matplotlib is used for visualizing the results or any required data.","fb4354b8":"Okay, we split our dataset into train and test set:","ccc58b5f":"## Train\/Test dataset","1e8c6e47":"We use wget which is a GNU computer program that retrieves content from web servers. We use -O because we are using the datset as input. After -O we give the file name and the link from where it has to access.","465ab77f":"## Data pre-processing and selection","97ecf9d6":"Details:-\n1. Name:-Kalvakota Rohith\n2. Roll no:- A223\n3. Class:- B.Tech IT 3rd Year\n4. SAP ID:- 70011118031","bb39f081":"dataframe.dtypes is used here. .dtypes is used to get the datatype of all the columns present in the data. We can see that all data here is of the type 'int' except 'Barenuc' which is of the type 'object'.","aae25fb5":"After being fitted, the model can then be used to predict new values:","e5c53af6":"This is the prediction done by the model. 2 refers to benign class and 4 refers to malignant class, we fetch the results of the first 5 rows using slicing.","24aa9162":"You can refer <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.to_numeric.html\">Pandas Documentation <\/a> of to_numeric for more details.  \n\n* pandas.to_numeric(arg, errors='raise', downcast=None)\n\n* Convert argument to a numeric type.\n\nThe default return dtype is float64 or int64 depending on the data supplied. Use the downcast parameter to obtain other dtypes.\n\n   Parameters\n\n1. args : Scalar, list, tuple, 1-d array, or Series\n2. errors : {\u2018ignore\u2019, \u2018raise\u2019, \u2018coerce\u2019}, default \u2018raise\u2019\n            If \u2018raise\u2019, then invalid parsing will raise an exception.\n            If \u2018coerce\u2019, then invalid parsing will be set as NaN.\n            If \u2018ignore\u2019, then invalid parsing will return the input.\n        downcast{\u2018integer\u2019, \u2018signed\u2019, \u2018unsigned\u2019, \u2018float\u2019}, default None\n\nIf not None, and if the data has been successfully cast to a numerical dtype (or if the data was numeric to begin with), downcast that resulting data to the smallest numerical dtype possible according to the following rules:\n\n  \u2018integer\u2019 or \u2018signed\u2019: smallest signed int dtype (min.: np.int8)\n\n  \u2018unsigned\u2019: smallest unsigned int dtype (min.: np.uint8)\n\n  \u2018float\u2019: smallest float dtype (min.: np.float32)\n","d3ef65e2":"The SVM algorithm offers a choice of kernel functions for performing its processing. Basically, mapping data into a higher dimensional space is called kernelling. The mathematical function used for the transformation is known as the\u00a0kernel\u00a0function, and can be of different types, such as:\n\n    1.Linear\n    2.Polynomial\n    3.Radial basis function (RBF)\n    4.Sigmoid\nEach of these functions has its characteristics, its pros and cons, and its equation, but as there's no easy way of knowing which function performs best with any given dataset, we usually choose different functions in turn and compare the results. Let's just use the default, RBF (Radial Basis Function) for this lab.","60eaa502":"Here, we use pandas library to import the dataset and create it into a dataframe. Then using the head attribute we see the first 5 rows of the dataframe to see how it looks.","5047c25e":"\n<h1 align=center><font size=\"5\"> Machine Learning (IT):  Sem V <\/font><\/h1>\n<h1 align=center><font size=\"5\"> SVM (Support Vector Machines)<\/font><\/h1>\n","81b6c7e4":"We select the output we want to give which is the \"Class\" feature and then convert into a array. Then we slice and get the results of the first 5 rows.","49e8c989":"In this notebook, you will use SVM (Support Vector Machines) to build and train a model using human cell records, and classify cells to whether the samples are benign or malignant.\n\nAs we discussed in the class SVM is to map data to a high-dimensional feature space so that data points can be categorized, even when the data are not otherwise linearly separable. A separator between the categories is found, then the data is transformed in such a way that the separator could be drawn as a hyperplane. Following this, characteristics of new data can be used to predict the group to which a new record should belong.","7d8fb65d":"We have designed the code for the confusion matrix and what it has to show."}}