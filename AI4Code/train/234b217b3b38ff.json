{"cell_type":{"24c1be6c":"code","4212e80d":"code","80b6bef4":"code","a2dcdcbd":"code","e221f0ba":"code","7eaa1975":"code","cb6d4f8b":"code","be7d25c2":"code","f1e7fb7d":"code","3ff38765":"code","86978e15":"markdown","6e7db9f0":"markdown","fd7ef82e":"markdown","bfb46ba5":"markdown","3d8630c2":"markdown","018b748d":"markdown","1c620df4":"markdown","95a466cc":"markdown","f6868a8a":"markdown"},"source":{"24c1be6c":"import sys, cv2, glob, os, time\nimport pandas as pd \nimport numpy as np\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten,Activation\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nprint(os.listdir(\"..\/input\"))\n%matplotlib inline","4212e80d":"train_dir = \"..\/input\/train\/train\/\"\ntest_dir = \"..\/input\/test\/test\/\"\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntrain_df.tail()","80b6bef4":"img_rows = 32\nimg_cols = 32\nchannels = 3\nimg_shape = (img_rows, img_cols, channels)\nz_dim = 100","a2dcdcbd":"def generator(img_shape, z_dim):\n    model = Sequential()\n    model.add(Dense(128, input_dim=z_dim))\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Dense(img_rows*img_cols*channels, activation='tanh'))\n    model.add(Reshape(img_shape))\n    z = Input(shape=(z_dim,))\n    img = model(z)\n    return Model(z, img)\n\ndef discriminator(img_shape):\n    model = Sequential()\n    model.add(Flatten(input_shape=img_shape))\n    model.add(Dense(128))\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Dense(1, activation='sigmoid'))\n    img = Input(shape=img_shape)\n    prediction = model(img)\n    return Model(img, prediction)\n\ndiscriminator = discriminator(img_shape)\ndiscriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\ngenerator = generator(img_shape, z_dim)\nz = Input(shape=(100,))\nimg = generator(z)\ndiscriminator.trainable = False\nprediction = discriminator(img)\ncombined = Model(z, prediction)\ncombined.compile(loss='binary_crossentropy', optimizer=Adam())","e221f0ba":"img_ = cv2.imread(\"..\/input\/train\/train\/00b4dfbb267109b5f0d0dde365fa6161.jpg\",1)\n#img_ = cv2.cvtColor(img_,cv2.COLOR_BGR2GRAY)\nplt.imshow(img_)","7eaa1975":"def prepareTrainSet(train_df):\n    train_1 = train_df[train_df.has_cactus == 1]\n    train_0 = train_df[train_df.has_cactus == 0]\n    ids_1 = train_1.id.tolist()\n    ids_0 = train_0.id.tolist()\n\n    path = glob.glob(\"..\/input\/train\/train\/*.jpg\")\n    imgs_0,imgs_1 = [],[]\n    for img in path:\n        im = cv2.imread(img)\n#     uncomment next line while using single channel image\n        #im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n#     uncomment next line if your want to scale image\n        #im = cv2.resize(im,(80,65))\n        if img.split(\"\/\")[-1] in ids_1:\n            imgs_1.append(im)\n        elif img.split(\"\/\")[-1] in ids_0:\n            imgs_0.append(im)\n            \n    X_train_0 = np.asarray(imgs_0)\n    X_train_1 = np.asarray(imgs_1)\n\n    X_train_0 = X_train_0 \/ 127.5 - 1.\n    X_train_1 = X_train_1 \/ 127.5 - 1.\n    \n#     uncomment next two line while using single channel image\n\n#     X_train_0 = np.expand_dims(X_train_0, axis=3)\n#     X_train_1 = np.expand_dims(X_train_1, axis=3)\n\n    print(X_train_0.shape)\n    print(X_train_1.shape)\n    \n    return X_train_0,X_train_1\n\nlosses = []\naccuracies = []\ndef train(iterations, batch_size, sample_interval):\n    gen_images = []\n    X_train_0,X_train_1 = prepareTrainSet(train_df)\n    \n    # Assign X_train to X_train_0 for augment non-cactus images\n    # Assign X_train to X_train_1 for augment cactus images\n\n    X_train = X_train_0\n    real = np.ones((batch_size, 1))\n    fake = np.zeros((batch_size, 1))\n\n    for iteration in range(iterations):\n       \n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        imgs = X_train[idx]\n\n        z = np.random.normal(0, 1, (batch_size, 100))\n        gen_imgs = generator.predict(z)\n\n        d_loss_real = discriminator.train_on_batch(imgs, real)\n        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n        z = np.random.normal(0, 1, (batch_size, 100))\n        gen_imgs = generator.predict(z)\n        g_loss = combined.train_on_batch(z, real)\n\n        if iteration % sample_interval == 0:\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100*d_loss[1], g_loss))\n            losses.append((d_loss[0], g_loss))\n            accuracies.append(100*d_loss[1])\n            gen_images.append(sample_images(iteration))\n    return gen_images","cb6d4f8b":"def sample_images(iteration, image_grid_rows=4, image_grid_columns=4):\n\n    z = np.random.normal(0, 1, \n              (image_grid_rows * image_grid_columns, z_dim))\n\n    gen_imgs = generator.predict(z)\n    gen_imgs = 0.5 * gen_imgs + 0.5\n    \n    fig, axs = plt.subplots(image_grid_rows, image_grid_columns,  figsize=(10,10), sharey=True, sharex=True)\n    \n    cnt = 0\n    for i in range(image_grid_rows):\n        for j in range(image_grid_columns):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,0],)\n            axs[i,j].axis('off')\n            cnt += 1\n            \n    return gen_imgs","be7d25c2":"import warnings; warnings.simplefilter('ignore')","f1e7fb7d":"# Set iterations at least 10000 for good results\niterations = 1000\nbatch_size = 128\nsample_interval = 1000\n\ngen_imgs = train(iterations, batch_size, sample_interval)","3ff38765":"#row -1 for lastly generated samples\nrow = -1\n\n#columns -1 for last element of lastly generated samples\ncol = -1\n\nplt.imshow(gen_imgs[row][col])","86978e15":"# Show Sample Images","6e7db9f0":"# GAN","fd7ef82e":"# Set Directories","bfb46ba5":"# Create Dataset and Train","3d8630c2":"# Don't forget to enable GPU on Setting","018b748d":"## Import Packages","1c620df4":"# Set Image Size\n- Width: 32, Height:32, 3 Channels for colored image. Set channels 0 for greyscale image","95a466cc":"# Start Training\n- Generated images can be found in gen_imgs list","f6868a8a":"# Single image for test"}}