{"cell_type":{"556fc24f":"code","9c279497":"code","8488ef39":"code","6744247a":"code","2f3066b7":"code","c5e07196":"code","db62b6f0":"code","de11a806":"code","8de15c20":"code","abac69be":"code","42ac8b3f":"code","f1c8b3b2":"code","4a405af4":"code","53943f23":"markdown","7bf78ce2":"markdown","9983c605":"markdown","496c41a6":"markdown","c8abe08f":"markdown","3ed6eb39":"markdown"},"source":{"556fc24f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9c279497":"import matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\n\nfrom sklearn.linear_model import Ridge, Lasso, LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport sys\n\nimport warnings\n\nwarnings.simplefilter('ignore')","8488ef39":"#import data\ndf = pd.read_csv('..\/input\/dummy-advertising-and-sales-data\/Dummy Data HSS.csv')\ndf.head()","6744247a":"df.describe()","2f3066b7":"df.isnull().sum()","c5e07196":"df['TV'].fillna(df['TV'].mean(),inplace=True)\ndf['Radio'].fillna(df['Radio'].mean(),inplace=True)\ndf['Social Media'].fillna(df['Social Media'].mean(),inplace=True)\ndf['Sales'].fillna(df['Sales'].mean(),inplace=True)","db62b6f0":"plt.pie(df['Influencer'].value_counts(),\n   labels=df['Influencer'].unique(), counterclock=False, startangle=90,\n   autopct='%1.1f%%', pctdistance=0.7)","de11a806":"categorical_columns = ['TV', 'Radio', 'Social Media']\n\nRP=plt.figure(figsize=(10,3))\nfor i, feature in enumerate(categorical_columns):\n    r=RP.add_subplot(1,3,i+1)\n    #plt.hist(np.log(df[feature]))\n    plt.hist(df[feature])\n    r.set_title(feature+\" Histogram Plot\",color='DarkRed')\nRP.tight_layout()  ","8de15c20":"fig,axes = plt.subplots(1,3,figsize=(15,5))\nfor idx,cat_col in enumerate(categorical_columns):\n    r=fig.add_subplot(1,3,idx+1)\n    grid = sns.scatterplot(data=df, x=cat_col, y='Sales', hue=\"Influencer\")\n    grid.set_xticklabels('') \n    grid.set_yticklabels('') \n    \n    r.set_title(cat_col,color='DarkRed')\nfig.tight_layout(rect=[0,0,1,0.96])  ","abac69be":"plt.figure()\ndf.groupby([\"Influencer\"])['Sales'].mean().sort_values(ascending=False).plot(kind=\"bar\",figsize=(10, 6))\n\nplt.xticks(rotation=90)\nplt.grid(True)\nplt.show()","42ac8b3f":"df_enc=pd.get_dummies(df,drop_first=True)\n\nX=df_enc.drop(['Sales'],axis=1)\ny = df_enc['Sales']\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)","f1c8b3b2":"from sklearn.linear_model import LogisticRegression,LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV,RepeatedStratifiedKFold\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\n\nmodels=[('LR',LinearRegression()),('DT',DecisionTreeRegressor()),('RF',RandomForestRegressor()),('XGB',XGBRegressor())\n        ,('SVR',SVR())]\nscores=[]\n\nfor name,model in models:\n    model.fit(X_train,y_train)\n    preds=model.predict(X_test)\n    score=explained_variance_score(preds,y_test)\n    mae = mean_absolute_error(y_test, preds)\n    r2 = r2_score(y_test, preds)\n    scores.append([name,model,mae,r2,score])","4a405af4":"scores_df=pd.DataFrame(scores,columns=['Name','Model','MAE','R2','Score'])\nscores_df.sort_values('Score',ascending=False)\n\nscores_df.set_index('Name', drop=True,inplace=True)\nscores_df","53943f23":"According to pie chart , propotions of influencer are equivalent propotion.","7bf78ce2":"This is my first analysis in the kaggle , also it's own first attainment that opened in public as analyst . \nSo I am nothing but layman as analyst , besides my method may wrong or sort of not right way to analyze .\nthat's why if someone sees this one , I wish that guys write a comment so that I improve .","9983c605":"# **Data exploration**","496c41a6":"**Train - Test Split**","c8abe08f":"I fill null data with each mean value .","3ed6eb39":"**Model Creation**\nI used following models at the same time by for loop to compare these accuracy .\n\n* LinearRegression\n* DecisionTreeRegressor\n* RandomForestRegressor\n* XGBRegressor\n* Support Vector Regression"}}