{"cell_type":{"37bc7f08":"code","0a9eac4f":"code","c1e69934":"code","a7e47fde":"code","d9ead4f2":"code","57ba5380":"code","cf996f3a":"code","9096b53a":"code","7ba0b200":"code","81185b8f":"code","4633bdd3":"code","c1049f7f":"code","b6243e1c":"code","d245ce76":"code","b61f9ac4":"code","4b62229b":"code","f8970696":"code","cde25779":"code","ec3e5863":"code","8717a050":"code","16af882f":"code","6ac7a30c":"code","391e0d3f":"code","8caa5463":"code","b1ed744b":"code","ec09fb4c":"code","67bad151":"code","aa17d225":"code","9ecbe455":"code","8fcd0482":"code","3dbb8453":"code","d09f2afe":"code","4ffa9006":"code","c720f3cc":"code","eb8b07f3":"code","f0688eb6":"code","e34e478f":"code","10950241":"code","300f5460":"code","275d9b2d":"code","a2994bc4":"code","3ed27b72":"code","7a0fff0b":"code","29165e3d":"code","98f081b5":"code","deca3f43":"markdown","a5bbf518":"markdown","54907f04":"markdown","a043101e":"markdown","726ee6a9":"markdown","53569f0e":"markdown","64e57c2b":"markdown","484f36eb":"markdown","bafa3c55":"markdown","ccf116c7":"markdown","6496b42d":"markdown","e3376e81":"markdown","28831227":"markdown","4ee34264":"markdown","05958a3b":"markdown","f2f1a676":"markdown","2f96d331":"markdown","20d18b0c":"markdown","e082650f":"markdown","44f4556e":"markdown","c04c8433":"markdown"},"source":{"37bc7f08":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","0a9eac4f":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","c1e69934":"df.head()","a7e47fde":"df.describe().T","d9ead4f2":"df.isnull().sum()","57ba5380":"X = df.drop('Class', axis=1)\ny = df['Class']","cf996f3a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","9096b53a":"train = pd.concat([X_train, y_train], axis=1)","7ba0b200":"sns.boxenplot(data=train, x='Class', y='Amount')","81185b8f":"sns.countplot(train['Class'])","4633bdd3":"class1_pct = np.round(len(train[train['Class']==1])\/len(train)*100, 2)\nprint(f'The clas 0 and class 1 distributions are  {class1_pct}% and {100-class1_pct}% respectively')","c1049f7f":"def plot_hist(train,n_pics=6, offset=0):\n    cols = train.columns[:-1]\n    ncols = 2\n    row = 0\n    n_pics = 6\n    fig,ax = plt.subplots(nrows=n_pics, ncols=ncols, figsize=(10,12))\n    plt.title(f'Plot of class 0 and class 1')\n\n    for col in cols[n_pics*offset:n_pics*(offset+1)]:\n        sns.histplot(data=train[train['Class']==0], x=col, ax=ax[row,0])\n        sns.histplot(data=train[train['Class']==1], x=col, ax=ax[row,1])\n        row+=1\n    plt.tight_layout()","b6243e1c":"plot_hist(train)\n","d245ce76":"plot_hist(train, offset=1)","b61f9ac4":"plot_hist(train, offset=2)","4b62229b":"plot_hist(train, offset=3)","f8970696":"class1 = train[train['Class']==1].describe().T\nclass1 = class1.drop('Class')\nglobal_d = train.describe().T\nclass1['global_max']=global_d['max']\nclass1['global_min']=global_d['min']\norig_len = len(train)\n\nfor index, row in class1.iterrows():\n    \n    if row['global_max'] > row['max']:      \n        train = train[train[index]<=row['max']]\n    elif row['global_min'] < row['min']:\n        train = train[train[index]>=row['min']]\n        \nprint(f'removed records {orig_len - len(train)}')","cde25779":"y='Class'\nX = train.columns[1:-2]\nncols = 4\nnrows = int(np.ceil(len(X)\/ncols))\nfix, ax = plt.subplots(nrows=nrows, ncols=ncols,figsize=(15,15))\n\nfor i in range(len(X)):\n    row = i\/\/ncols\n    col = i%ncols\n    sns.scatterplot(data=train, x=X[i], y=y, ax=ax[row, col])\n    ax[row, col].title.set_text(f'{X[i]} vs Class')\n    \nplt.tight_layout()  ","ec3e5863":"corr_df = train.corr()\nfor col in corr_df.columns:\n    corr_df[col] = corr_df[col].apply(lambda x :np.round(x, decimals=2) )\n\nplt.figure(figsize=(17,17))\nsns.heatmap(corr_df, cmap='viridis', annot=True)","8717a050":"\ncorr_df = train[train['Class']==1].corr()\nfor col in corr_df.columns:\n    corr_df[col] = corr_df[col].apply(lambda x :np.round(x, decimals=2) )\nplt.figure(figsize=(15,12))\n\nsns.heatmap(corr_df, cmap='viridis', annot=True)","16af882f":"y='Amount'\nX = train.columns[1:-2]\nhue = 'Class'\nncols = 4\nnrows = int(np.ceil(len(X)\/ncols))\nfix, ax = plt.subplots(nrows=nrows, ncols=ncols,figsize=(15,15))\n\nfor i in range(len(X)):    \n    row = i\/\/ncols\n    col = i%ncols\n    sns.scatterplot(data=train, x=X[i], y=y, hue=hue, ax=ax[row, col], alpha=0.7)\n    ax[row, col].title.set_text(f'{X[i]} vs Amount')        \nplt.tight_layout()  ","6ac7a30c":"y='Time'\nX = train.columns[1:-2]\nhue = 'Class'\n\nncols = 4\nnrows = int(np.ceil(len(X)\/ncols))\n\nfix, ax = plt.subplots(nrows=nrows, ncols=ncols,figsize=(15,15))\n\nfor i in range(len(X)):\n    \n    row = i\/\/ncols\n    col = i%ncols\n    sns.scatterplot(data=train, x=X[i], y=y, hue=hue, ax=ax[row, col], alpha=0.7)\n    ax[row, col].title.set_text(f'{X[i]} vs Amount')\n    \nplt.tight_layout()  \n    ","391e0d3f":"cols_to_delete = ['V13', 'V15', 'V19','V20','V21','V22','V23','V24','V25','V26','V27','V28']\nX_train = X_train.drop(cols_to_delete, axis=1)\nX_test = X_test.drop(cols_to_delete, axis=1)\n\ntrain = pd.concat([X_train, y_train], axis=1)","8caa5463":"\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTEENN, SMOTETomek\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.svm import LinearSVC\nfrom imblearn.under_sampling import ClusterCentroids\n\n\n\nsamplers = [SMOTE(random_state=0), SMOTEENN(0.62,random_state=0), SMOTETomek(random_state=0)]\ncc = ClusterCentroids(random_state=0)\nX_train_res, y_train_res = cc.fit_resample(X_train, y_train)\n","b1ed744b":"from sklearn.preprocessing import StandardScaler","ec09fb4c":"scaller = StandardScaler()\nscalled_X_train_res = scaller.fit_transform(X_train_res)\nscalled_X_test = scaller.transform(X_test)\n","67bad151":"from sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.linear_model import LogisticRegression","aa17d225":"# fit a model\nmodel = LogisticRegression(solver='lbfgs')\nmodel.fit(scalled_X_train_res, y_train_res)\n# predict probabilities\n","9ecbe455":"lr_probs = model.predict_proba(scalled_X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]","8fcd0482":"lr_auc = roc_auc_score(y_test, lr_probs)\n\nfpr, tpr, thresholds = roc_curve(y_test, lr_probs)\n# plot the roc curve for the model\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n\ngmeans = np.sqrt(tpr * (1-fpr))\n# locate the index of the largest g-mean\nix = np.argmax(gmeans)\nprint('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n# plot the roc curve for the model\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\nplt.plot(fpr, tpr, marker='.', label='Logistic')\nplt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\n# show the plot\nplt.show()\n\nbest_th = thresholds[ix]\n\npred = [(x>=best_th).astype('int') for x in lr_probs]\n\n\nprint(f'For class 1 by ROC Curve Predicted {np.round(np.sum(pred)*100\/len(pred),2)}% Actual {np.round(np.sum(y_test)*100\/len(y_test),2)}%')\n","3dbb8453":"\nfrom sklearn.metrics import precision_recall_curve\n\nprecision, recall, thresholds = precision_recall_curve(y_test, lr_probs)\n# convert to f score\nfscore = (2 * precision * recall) \/ (precision + recall)\n# locate the index of the largest f score\nix = np.argmax(fscore)\nprint('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n# plot the roc curve for the model\nno_skill = len(y_test[y_test==1]) \/ len(y_test)\nplt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\nplt.plot(recall, precision, marker='.', label='Logistic')\nplt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n# axis labels\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\n# show the plot\nplt.show()\n\nbest_th = thresholds[ix]\n\npred = [(x>=best_th).astype('int') for x in lr_probs]\n\n\nprint(f'For class 1 by Precision\/Recall Curve Predicted {np.round(np.sum(pred)*100\/len(pred),2)}% Actual {np.round(np.sum(y_test)*100\/len(y_test),2)}%')\n","d09f2afe":"from sklearn.metrics import confusion_matrix, classification_report","4ffa9006":"print(classification_report(pred, y_test))","c720f3cc":"print(confusion_matrix(pred, y_test))","eb8b07f3":"from numpy import arange\nfrom numpy import argmax\n\nfrom sklearn.metrics import f1_score\n \n# apply threshold to positive probabilities to create labels\ndef to_labels(pos_probs, threshold):\n\treturn (pos_probs >= threshold).astype('int')\n \n# generate dataset\n# define thresholds\nthresholds = arange(0, 1.01, 0.001)\n# evaluate each threshold\nscores = [f1_score(y_test, to_labels(lr_probs, t)) for t in thresholds]\n# get best threshold\nix = np.argmax(scores)\nprint('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))","f0688eb6":"best_th = thresholds[ix]\n\npred = [(x>=best_th).astype('int') for x in lr_probs]\n\nprint(f'For class 1 by Precision\/Recall Curve Predicted {np.round(np.sum(pred)*100\/len(pred),2)}% Actual {np.round(np.sum(y_test)*100\/len(y_test),2)}%')\n","e34e478f":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(scalled_X_train_res, y_train_res)\nlr_probs = rf.predict_proba(scalled_X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]","10950241":"precision, recall, thresholds = precision_recall_curve(y_test, lr_probs)\n# convert to f score\nfscore = (2 * precision * recall) \/ (precision + recall)\n# locate the index of the largest f score\nix = np.argmax(fscore)\nprint('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n# plot the roc curve for the model\nno_skill = len(y_test[y_test==1]) \/ len(y_test)\nplt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\nplt.plot(recall, precision, marker='.', label='Logistic')\nplt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n# axis labels\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\n# show the plot\nplt.show()\n\nbest_th = thresholds[ix]\n\npred = [(x>=best_th).astype('int') for x in lr_probs]\n\n\nprint(f'For class 1 by Precision\/Recall Curve Predicted {np.round(np.sum(pred)*100\/len(pred),2)}% Actual {np.round(np.sum(y_test)*100\/len(y_test),2)}%')\n","300f5460":"print('Classification Report\\n')\nprint(classification_report(pred, y_test))\nprint('\\nConfusion Matrix\\n')\nprint(confusion_matrix(pred, y_test))","275d9b2d":"from xgboost import XGBClassifier","a2994bc4":"xgb = XGBClassifier()\nxgb.fit(scalled_X_train_res, y_train_res)\nlr_probs = xgb.predict_proba(scalled_X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]","3ed27b72":"precision, recall, thresholds = precision_recall_curve(y_test, lr_probs)\n# convert to f score\nfscore = (2 * precision * recall) \/ (precision + recall)\n# locate the index of the largest f score\nix = np.argmax(fscore)\nprint('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n# plot the roc curve for the model\nno_skill = len(y_test[y_test==1]) \/ len(y_test)\nplt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\nplt.plot(recall, precision, marker='.', label='Logistic')\nplt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n# axis labels\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\n# show the plot\nplt.show()\n\nbest_th = thresholds[ix]\n\npred = [(x>=best_th).astype('int') for x in lr_probs]\n\n\nprint(f'For class 1 by Precision\/Recall Curve Predicted {np.round(np.sum(pred)*100\/len(pred),2)}% Actual {np.round(np.sum(y_test)*100\/len(y_test),2)}%')\n","7a0fff0b":"print('Classification Report\\n')\nprint(classification_report(pred, y_test))\nprint('\\nConfusion Matrix\\n')\nprint(confusion_matrix(pred, y_test))","29165e3d":"from sklearn.metrics import accuracy_score, precision_score, recall_score","98f081b5":"print('Accuracy :{0:0.5f}'.format(accuracy_score( y_test, pred))) \nprint('AUC : {0:0.5f}'.format(roc_auc_score(y_test, pred)))\nprint('Precision : {0:0.5f}'.format(precision_score(y_test, pred)))\nprint('Recall : {0:0.5f}'.format(recall_score(y_test, pred)))\nprint('F1 : {0:0.5f}'.format(f1_score(y_test, pred)))","deca3f43":"- Based on the diagram above it appears the feachers form V19 to V28 does not produce clear distinctions , similarly v13 and v15. Hnece they can be deleted.","a5bbf518":"## 1. Data Exploration","54907f04":"We can See that only 0.18% of the data belongs to Class1\n\n## Feature Engineering\n\n- As we can see there are many more data for class0 than 1 . Ideally machine learning models expect the class distributions to have a more or less equal for diffrent classes. \nit should be ok for us to delete some of the data from Class 0 so that the distribution difference improves slightly. \nWe are not going to delete the records randomly, we will take the decision based on the histogram of Various feature Data.\n\n- Let's Plot the histogram for different featurs btween class0 and 1\n","a043101e":"#### XGB Classifier","726ee6a9":"\n- Let's try to figure out which features are important and which are not. We will start with heatmap of correlation of features.","53569f0e":"- We clearly see form all of these diagrams that range of Class 0 is Higher that Class1, \nsinec are interested that to find data having class 1, we can safely assume that \ndata outside of the range of class1 will  always belong to class 0.\n\n\n","64e57c2b":"#### It appears the XGB gives us the best resuts so far.","484f36eb":"- From the results above , we can see the precision_recall_curve provided the best results , hence we are going to select it.\n\n#### Choosing best Alogorithm \n\n- Now we have selected the best thresholding approach , let\u2019s try with some different algorithms to select the best one. Will wil trying with Random forecast and Extreme Gradient Boosting XGB ","bafa3c55":"Good, No missing data found\n### Train test Split\nSince we don't have separate Train and Test data set here, lets split our dataset as train and test\/validation \nso that we can check how our system is performing.","ccf116c7":"#### Optimum Threshold \n\n- Usually any kind of classification algorithm determines the probability of having a class and the use threshold as 0.5 if the probability > 05 it classifies it as 1 otherwise 0.  However in our case since there are many 0 and only a few 1 , we would take a slightly different approach here.  We would calculate the optimum threshold and use that threshold instead of 0.5 to determine the class. \n\n- Again there are multiple approaches to find the optimal threshold. We would take slime logistic regression model try 3 different approach for thresholding \n1. ROC_AUC  curve\n2. Precision Recall curve and \n3. Simply try   a range of thresholds and select the best.\n\nThen select the best method from the above list. \n- Then we would try different algorithms to even improve the results.\n\n","6496b42d":"- We can see some string Correlation between few features like V16 and V18 when they all belong to Class1 \nbut that does not exist when we consider all data.\n\n- Let's try to plot the data making with amount against all features V1 to V28, This should give information which features are important.\n","e3376e81":"##### Random forest ","28831227":"- Here is Diagram for Precision Recall Curve","4ee34264":"### Lets look for missing data","05958a3b":"## Modelling\n\n- As the distributions of class0 and class1 are extremely unbalanced we would still need to balance them before proceeding. One of the popular techniques is oversampling of the class having less data , class1 here our case and under sampling of the calls having more records - class0 here. \n- We can easily achieve this by using the imblean python library. \n- Here I choose the undersample method.\nRemember we have done some undersampling in the previous section by removing about 34k records. \n","f2f1a676":"#### Let's See the Distribusion of Class 0 and Class1 , ie. the Regular and the fraud transtions","2f96d331":"- From this diagram, we can see again that Feature 19 to 28 does not give us enough \ninformation to split the data for class 0 and 1, which we can find in the correlation heatmap above. Hence are going to delete these features.\n\n- Let's plot them again against the Time Column this time.","20d18b0c":"# Credit card fraud detection","e082650f":"- Based on this Correlation Heatmap Above it appears that Feature V19 to V28 is Not Very Importent in oter to defermine class1\n- Let's try to see if features shows any specific pattern when all class are 1 ie, fraud","44f4556e":"- Ok, we have deleted about 34k records of class 0 without losing much information.\n- Let's see how the distrution looks like after deletion with the help of another diagram ","c04c8433":"- Let's Scale the data using StandardScaler"}}