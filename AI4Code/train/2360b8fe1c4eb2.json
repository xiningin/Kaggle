{"cell_type":{"922a7b96":"code","6cfbcfa6":"code","4a0549c1":"code","651e49c8":"code","df146542":"code","61463e6f":"code","251ffc22":"code","e44d66ea":"code","3d18357a":"code","4115c431":"code","48eb8765":"code","f988b894":"code","0cfcede1":"code","27141922":"code","c38015d2":"code","08b6cf5e":"code","edfc3219":"code","bac3290d":"code","8d82c34f":"code","d8cf2576":"code","514e05fd":"markdown","06b883c9":"markdown","25a3202e":"markdown","21b9a924":"markdown","7904cdf9":"markdown"},"source":{"922a7b96":"import cudf\nimport cuml\nimport cupy as cp\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport os\nfrom scipy.interpolate import interp1d\nimport gc\nfrom cuml.linear_model import Ridge\nfrom cuml.neighbors import KNeighborsRegressor\nfrom cuml.svm import SVR\nfrom cuml.ensemble import RandomForestRegressor\nfrom cuml.preprocessing.TargetEncoder import TargetEncoder\nfrom sklearn.model_selection import GroupKFold, KFold\nfrom cuml.metrics import mean_squared_error\n\nimport soundfile as sf\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import roc_auc_score, label_ranking_average_precision_score","6cfbcfa6":"train = cudf.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ntest = cudf.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv\")\nsample_submission = cudf.read_csv('..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv')","4a0549c1":"target = train['target'].values\ncolumns = test.columns[1:]\ncat_features = columns[:10]\ncat_features","651e49c8":"train.head()","df146542":"test.head()","61463e6f":"rr_train_oof = cp.zeros((300000,))\nrr_test_preds = 0\nrr_train_oof.shape","251ffc22":"NUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        test_df = test.copy()\n        \n        for cat_col in cat_features:\n            te = TargetEncoder()\n            train_df[cat_col] = te.fit_transform(train_df[cat_col], train_target)\n    \n            val_df[cat_col] = te.transform(val_df[cat_col])\n            test_df[cat_col] = te.transform(test_df[cat_col])\n            \n        model = Ridge(alpha=0.1)\n        model.fit(train_df, train_target)\n        temp_oof = model.predict(val_df)\n        temp_test = model.predict(test_df[columns])\n\n        rr_train_oof[val_ind] = temp_oof\n        rr_test_preds += temp_test\/NUM_FOLDS\n        \n        print(mean_squared_error(temp_oof, val_target, squared=False))","e44d66ea":"mean_squared_error(rr_train_oof, target, squared=False)","3d18357a":"val_df.head()","4115c431":"cp.save('rr_train_oof', rr_train_oof)\ncp.save('rr_test_preds', rr_test_preds)","48eb8765":"knn_train_oof = cp.zeros((300000,))\nknn_test_preds = 0\nknn_train_oof.shape","f988b894":"NUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        test_df = test.copy()\n        \n        for cat_col in cat_features:\n            te = TargetEncoder()\n            train_df[cat_col] = te.fit_transform(train_df[cat_col], train_target)\n    \n            val_df[cat_col] = te.transform(val_df[cat_col])\n            test_df[cat_col] = te.transform(test_df[cat_col])\n            \n        model = KNeighborsRegressor(n_neighbors=200)\n        model.fit(train_df, train_target)\n        temp_oof = model.predict(val_df)\n        temp_test = model.predict(test_df[columns])\n\n        knn_train_oof[val_ind] = temp_oof\n        knn_test_preds += temp_test\/NUM_FOLDS\n        \n        print(mean_squared_error(temp_oof, val_target, squared=False))","0cfcede1":"cp.save('knn_train_oof', knn_train_oof)\ncp.save('knn_test_preds', knn_test_preds)","27141922":"mean_squared_error(knn_train_oof, target, squared=False)","c38015d2":"svr_train_oof = cp.zeros((300000,))\nsvr_test_preds = 0\nsvr_train_oof.shape","08b6cf5e":"NUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        test_df = test.copy()\n        \n        for cat_col in cat_features:\n            te = TargetEncoder()\n            train_df[cat_col] = te.fit_transform(train_df[cat_col], train_target)\n    \n            val_df[cat_col] = te.transform(val_df[cat_col])\n            test_df[cat_col] = te.transform(test_df[cat_col])\n            \n        model = SVR(C=1)\n        model.fit(train_df, train_target)\n        temp_oof = model.predict(val_df)\n        temp_test = model.predict(test_df[columns])\n\n        svr_train_oof[val_ind] = temp_oof\n        svr_test_preds += temp_test\/NUM_FOLDS\n        \n        print(mean_squared_error(temp_oof, val_target, squared=False))","edfc3219":"mean_squared_error(svr_train_oof, target, squared=False)","bac3290d":"cp.save('svr_train_oof', svr_train_oof)\ncp.save('svr_test_preds', svr_test_preds)","8d82c34f":"mean_squared_error(0.8*rr_train_oof + 0.1*knn_train_oof+ 0.1*svr_train_oof, target, squared=False)","d8cf2576":"sample_submission['target'] = 0.8*rr_test_preds + 0.1* knn_test_preds + 0.1* svr_test_preds\nsample_submission.to_csv('submission.csv', index=False)","514e05fd":"Next, we'll take a look at the K Nearest Neighbors algorithm\n\n","06b883c9":"<img src=\"https:\/\/developer.nvidia.com\/sites\/default\/files\/pictures\/2018\/rapids\/rapids-logo.png\"\/>","25a3202e":"And now Support Vector Regressor","21b9a924":"[Rapids](https:\/\/rapids.ai) is an open-source GPU accelerated Data Sceince and Machine Learning library, developed and mainatained by [Nvidia](https:\/\/www.nvidia.com). It is designed to be compatible with many existing CPU tools, such as Pandas, scikit-learn, numpy, etc. It enables **massive** acceleration of many data-science and machine learning tasks, oftentimes by a factor fo 100X, or even more. If you are interested in installing and running Rapids locally on your own machine, then you should [refer to the followong instructions](https:\/\/rapids.ai\/start.html).","7904cdf9":"In this notebook we'll deal with categorical features using Target Encoding. For the ake of consistency, target encoding needs to be applied withing the cross-validation loop; otherwise, we'll be easily leakign targt information to the out-of-fold rows, which can lead to serious overfitting.\n\nWe'll also start with a simple Ridge regression. This is the simplest ML algo, and in general can give us a good idea of what the baseline score would be for our problem."}}