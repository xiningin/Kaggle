{"cell_type":{"704ce790":"code","9180e9a0":"code","73ae84d6":"code","5bd50a00":"code","eff2166e":"code","3bbf37ef":"code","c9f97165":"code","514e9bc1":"code","bcc2f0ac":"markdown","d7cf956e":"markdown"},"source":{"704ce790":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9180e9a0":"#import packages from sklearn \n#polynomial graghing package\nfrom sklearn.preprocessing import PolynomialFeatures\n#linear fitting package\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\n\n#actual function\ndef PolynomialRegression(degree=2, **kwargs):\n\treturn make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))","73ae84d6":"import numpy as np\n\ndef make_data(N, err=1.0, rseed=1):\n\t#randomly get data (if the data is rigged we will get perfect accuracy and then we wont learn anything\n\trng = np.random.RandomState(rseed)\n\tX = rng.rand(N,1) ** 2\n\ty = 10 - 1. \/ (X.ravel() + 0.1)\n\tif err > 0:\n\t\ty += err * rng.randn(N)\n\treturn X, y\n\n#this part of the code actually makes the data\nX, y = make_data(40)","5bd50a00":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn; seaborn.set() #plot formatting\n\nX_test = np.linspace(-0.1, 1.1, 500)[:, None]\n\n#plot the points as black dots\nplt.scatter(X.ravel(), y, color='black')\naxis = plt.axis\n#plot the lines\n\nfor degree in [1,3,5]:\n    y_test = PolynomialRegression(degree).fit(X,y).predict(X_test)\n    plt.plot(X_test.ravel(), y_test, label = 'degree={0}'.format(degree))\nplt.xlim(-1.0, 1.0)\nplt.ylim(-2,12)\nplt.legend(loc='best');","eff2166e":"#!pip install learning_curve\nfrom sklearn.model_selection import learning_curve \nfrom sklearn.model_selection import validation_curve \n\n\ndegree=np.arange(0,21)\ntrain_score, val_score = validation_curve(PolynomialRegression(), X, y, \n                                          'polynomialfeatures__degree', \n                                          degree, cv=7)\n\nplt.plot(degree, np.median(train_score, 1), color='blue', label='training_score')\nplt.plot(degree, np.median(val_score, 1), color='red', label = 'validation_score')\nplt.legend(loc='best')\nplt.ylim(0,1)\nplt.xlabel('degree')\nplt.ylabel('score');","3bbf37ef":"plt.scatter(X.ravel(), y)\nlim = plt.axis()\ny_test = PolynomialRegression(3).fit(X,y).predict(X_test)\nplt.plot(X_test.ravel(), y_test);\nplt.axis(lim);","c9f97165":"X2, y2 = make_data(200)\nplt.scatter(X2.ravel(), y2);\n#make another dataset to test on ","514e9bc1":"degree = np.arange(21)\ntrain_score2, val_score2 = validation_curve(PolynomialRegression(), X2, y2, 'polynomialfeatures__degree', degree, cv=7)\n\nplt.plot(degree, np.median(train_score2,1), color='blue',label='training_score')\nplt.plot(degree, np.median(val_score2,1), color='red', label = 'validation_score')\nplt.plot(degree, np.median(train_score, 1), color='blue',alpha=0.3, linestyle='dashed')\nplt.plot(degree, np.median(val_score, 1), color='red',alpha=0.3, linestyle='dashed')\nplt.legend(loc='lower center')\nplt.ylim(0,1)\nplt.xlabel('degree') #label the x axis\nplt.ylabel('score'); #label the y axis","bcc2f0ac":"Welcome!! \n\nThis notbook will teach you how to fit a model with polynomial regresssion, basically we will be using a curved line to connect dots. \n\nConnect with the community: https:\/\/discord.gg\/2M3q7GkCCC\n\nPlease upvote! Please","d7cf956e":"This notebook uses code from the Python Data Science Handbook, thank you to Jake VanderPlas"}}