{"cell_type":{"007b632c":"code","8d7d9dd8":"code","a9d0cff7":"code","3a01cde4":"code","2c0dd02f":"code","b7b173d9":"code","a88d33e5":"code","e9296fde":"code","da0b29a0":"code","dc825703":"code","f6ecf791":"code","10e7673e":"code","d2889adc":"code","56683344":"code","b648e6c4":"code","48e77a83":"code","13b0462a":"code","d2f4612b":"code","a8a0d47e":"code","91fdb17b":"code","25bdedad":"code","6911602f":"code","d3ae41e5":"code","108be20a":"code","833a9f55":"code","75ca6084":"code","8c57636b":"code","9698deed":"code","f6be0764":"code","b27e4fe7":"code","36a5bb70":"code","c4047252":"code","15e5e50e":"code","e83eaf18":"code","ad64ecc8":"code","0c62cfe4":"markdown","2861750d":"markdown","e45bdc5e":"markdown"},"source":{"007b632c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d7d9dd8":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport pandas_profiling as pp \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,accuracy_score,f1_score,precision_score,recall_score,roc_curve,roc_auc_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","a9d0cff7":"df_diabetes = pd.read_csv('\/kaggle\/input\/diabetes-dataset\/diabetes2.csv')","3a01cde4":"df=df_diabetes.copy()","2c0dd02f":"df.head()","b7b173d9":"df.info()","a88d33e5":"df.shape","e9296fde":"df[\"Outcome\"].value_counts()","da0b29a0":"#The number of patients who has diabetes are lower than the others.\nsns.catplot(x=\"Outcome\",kind=\"count\",data=df, palette=\"Set2\")","dc825703":"df[\"Pregnancies\"].value_counts()","f6ecf791":"#Mean of pregnancy amount of patients who has diabetes is 4.87\ndf.loc[(df[\"Outcome\"]==1)][\"Pregnancies\"].mean()","10e7673e":"\nsns.catplot(x=\"Pregnancies\", kind=\"count\",hue=\"Outcome\",data=df, palette=\"pastel\", legend=False)\nplt.legend(loc='upper right', labels= [\"Non diabetic\", \"Diabetic\"])","d2889adc":"df[\"Pregnancies\"].value_counts()","56683344":"plt.figure(figsize=(10,8))\nsns.kdeplot(df.Age,shade=True, palette=\"pastel\").set_title(\"Age Distribution\")","b648e6c4":"#Average age of patients who has diabetes is 37\ndf.loc[(df[\"Outcome\"]==1)][\"Age\"].mean()\n","48e77a83":"df.loc[(df[\"Outcome\"]==0)][\"Age\"].mean()","13b0462a":"#Older ages are more tend to have diabetes than youngers\nsns.catplot(x=\"Age\", kind=\"count\",hue=\"Outcome\",data=df, palette=\"pastel\", legend=False)\nplt.legend(loc='upper right', labels= [\"Non diabetic\", \"Diabetic\"])","d2f4612b":"custom_palette = ['#39A7D0', '#36ADA4']\nsns.set_palette(custom_palette)\nsns.scatterplot(x=\"Age\", y=\"Outcome\", data=df).set_title(\"Age vs Being Diabetic\")","a8a0d47e":"sns.pairplot(df, hue=\"Outcome\", palette=\"Set2\")","91fdb17b":"plt.figure(figsize=(20,7))\nsns.boxplot(x=\"Outcome\", y=\"Age\", data=df)","25bdedad":"df.isnull().sum()","6911602f":"#Highest correlated factor for being diabetic is glucose\ncorr=df.corr()\nplt.figure(figsize=(8, 8))\nsns.heatmap(corr, vmax=.8, linewidths=0.05,square=True,annot=True,linecolor=\"pink\")","d3ae41e5":"from sklearn.model_selection import train_test_split\n\ny=df[\"Outcome\"] #dependent variable\nX=df.drop([\"Outcome\"],axis=1) #independent variables\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","108be20a":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","833a9f55":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import confusion_matrix as cm\n\nlr = LogisticRegression(solver='liblinear') #solve=liblinear kaggle i\u00e7in gerekli\nlr.fit(X_train, y_train)","75ca6084":"x_pred=lr.predict(X_train)","8c57636b":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nconfusion_matrix(y_train, x_pred)","9698deed":"#train score\nscore = accuracy_score(y_train, x_pred)\nscore","f6be0764":"y_pred = lr.predict(X_test)","b27e4fe7":"confusion_matrix(y_pred,y_test)","36a5bb70":"#test score \nscore = accuracy_score(y_pred, y_test)\nscore","c4047252":"cm1 = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm1, annot=True, fmt=\".0f\")\nplt.xlabel('Predicted Values')\nplt.ylabel('Actual Values')\nplt.title('Accuracy Score: {0}'.format(score), size = 15)\nplt.show()","15e5e50e":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","e83eaf18":"#Overall accuracy score is %75\n#Non-diabetics prediction success is higher (%83)","ad64ecc8":"#e\u011fer data setim k\u00fc\u00e7\u00fckse 80'e 20 gibi b\u00f6lmektende 70'e 30 gibi b\u00f6lmek daha do\u011fru olur","0c62cfe4":"# Visualisation ","2861750d":"# Regression Model","e45bdc5e":"# Comments About The Analysis"}}