{"cell_type":{"1be50b3c":"code","33606bec":"code","2bc7a00d":"code","796b2be6":"code","f870c921":"code","a8ca9df5":"code","7638941d":"code","43d788c6":"code","47386be9":"code","be8b0258":"code","ce478cf3":"code","fd6fb798":"code","7638d7df":"code","ccb9443a":"code","a2789381":"code","ed205796":"code","5c1c55e0":"code","4fa6ebf8":"code","22d942b8":"code","44f425e4":"code","abcd4af3":"code","15c59b5b":"code","ee3d72d3":"code","7bda0a6f":"code","0e92308d":"code","18c8e8cf":"code","3c2b23fd":"code","44f7def5":"code","d54f240d":"code","2e0590c6":"code","3380ff1b":"code","0e9ed6b5":"code","1f87200c":"code","cfb90c51":"code","a5f1e6b4":"code","a7750a2a":"code","67cd69fb":"code","9695fcac":"code","888f4985":"code","e3b4f6b2":"code","95ecdad8":"code","07023354":"code","4dc45f65":"code","45e405cf":"code","492f449e":"code","5a248dc2":"code","b494dadd":"code","db0943f0":"code","11d5c4e4":"code","f3ce8922":"code","ed2895dd":"markdown","539c0e5f":"markdown","fae38f77":"markdown","0e2abae7":"markdown","e89c8ccd":"markdown","ea9be79f":"markdown","2bcf5038":"markdown","f11fe4af":"markdown","7b84e437":"markdown","7adf7c7e":"markdown","d42b33f1":"markdown","9b0dc6f1":"markdown","c8ac4760":"markdown","ce24e131":"markdown","80ebeb2a":"markdown","197729d6":"markdown","cdbd3446":"markdown","725fae12":"markdown","f280ec65":"markdown","082886b3":"markdown","468166fe":"markdown","7a255538":"markdown","7915e15a":"markdown","182f4d90":"markdown","52193485":"markdown","40dfa692":"markdown","38b4d6e6":"markdown","4283c2b0":"markdown","426f2baf":"markdown","02e4db5c":"markdown","66b84bf0":"markdown","b92e7b1e":"markdown","285a2cc2":"markdown","08558561":"markdown","24ad870a":"markdown","d2085aea":"markdown","5d6d93e4":"markdown","19c4eed7":"markdown","bb775f84":"markdown","a6d60fbf":"markdown","621546b0":"markdown","e318e267":"markdown","0290ba84":"markdown","b318d677":"markdown","ab87ef0c":"markdown","6e40a19a":"markdown","7809c947":"markdown","6f7474fe":"markdown","017c1b3e":"markdown","55681972":"markdown","30e280fe":"markdown","ad44a133":"markdown","e06a0421":"markdown","42fab5a6":"markdown","40551bf5":"markdown","8c6c616d":"markdown","47bc1e69":"markdown","38b6a1fb":"markdown","fbd18a6d":"markdown","db035955":"markdown","9841b979":"markdown","eeb674c3":"markdown","f248b692":"markdown","7cb8730c":"markdown","10be3ea8":"markdown","0bc3146a":"markdown","b0885f02":"markdown","81cb5f00":"markdown","82f44ba9":"markdown","7a983985":"markdown","310d8d97":"markdown","8a3f165a":"markdown","486d426b":"markdown","9553155d":"markdown","ea15c7b3":"markdown","b9c71840":"markdown","75359e94":"markdown","905e64fd":"markdown","d3d411fc":"markdown","7512dc9a":"markdown","90b3f0d0":"markdown","3ca77382":"markdown","1bc96586":"markdown","72814871":"markdown","0fc0c8d2":"markdown","905c7c94":"markdown","628348b2":"markdown","6b89a15a":"markdown","eb78a5ab":"markdown","7b093986":"markdown","8e5501aa":"markdown","73335de2":"markdown","6fe35af1":"markdown","64b64029":"markdown","1c3eb27d":"markdown","49baaa1b":"markdown","58117ea0":"markdown","7b9683a3":"markdown","5cfee35c":"markdown","0a2d19e5":"markdown","3256ec83":"markdown","2a95bb1e":"markdown","25edab75":"markdown","65a49f5b":"markdown","df24b2ed":"markdown","75193a9c":"markdown","8d5bfad9":"markdown","5045064d":"markdown","9dd89eb1":"markdown","22573682":"markdown","90a042f1":"markdown","144f8afe":"markdown","9704aac3":"markdown","e976f0b6":"markdown","c172067f":"markdown","f36444f5":"markdown","c6c60c82":"markdown","f31acaeb":"markdown","d147cd70":"markdown","66d8e7d0":"markdown","e994f439":"markdown","c003c592":"markdown","99885f87":"markdown","94807061":"markdown","0ed8dbf6":"markdown","d1bfe873":"markdown","dd0faf6c":"markdown","63ac76aa":"markdown","4544bbe7":"markdown","7722f136":"markdown","2b4ba6c9":"markdown","2bbd46d8":"markdown","67b9743e":"markdown","2fd93653":"markdown","229a4bed":"markdown","159f9bbf":"markdown","39541d6e":"markdown"},"source":{"1be50b3c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nfrom sklearn.model_selection import cross_val_score,cross_val_predict, train_test_split\nfrom sklearn.preprocessing import OneHotEncoder,StandardScaler,PowerTransformer,LabelEncoder\n\nfrom sklearn.metrics import accuracy_score,classification_report, recall_score,confusion_matrix, roc_auc_score, precision_score, f1_score, roc_curve, auc, plot_confusion_matrix,plot_roc_curve\n\n\nimport optuna\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier\n#from lightgbm import LGBMClassifier, plot_importance\nfrom catboost import CatBoostClassifier\n\n\n\n\n#importing plotly and cufflinks in offline mode\nimport cufflinks as cf\nimport plotly.offline\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n\n\nimport plotly \nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\nimport shap \n\nimport missingno as msno\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","33606bec":"pd.set_option('max_columns',100)\npd.set_option('max_rows',900)\n\npd.set_option('max_colwidth',200)\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf.head()","2bc7a00d":"y = df['Churn']\nprint(f'Percentage of Churn:  {round(y.value_counts(normalize=True)[1]*100,2)} %  --> ({y.value_counts()[1]} customer)\\nPercentage of customer did not churn: {round(y.value_counts(normalize=True)[0]*100,2)}  %  --> ({y.value_counts()[0]} customer)')\n","796b2be6":"y.iplot(kind='hist', title= 'Churn')","f870c921":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['tenure']= df1['tenure'].astype(float)\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\ncategorical_features_indices = np.where(X.dtypes != np.float)[0]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\ncatboost_5 = CatBoostClassifier(verbose=False,random_state=0,scale_pos_weight=5)\n\ncatboost_5.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_test, y_test))\ny_pred = catboost_5.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['Catboost_adjusted_weight_5']\nresult_df3 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df3","a8ca9df5":"fig, ax = plt.subplots(figsize=(8, 8))\nplot_confusion_matrix(catboost_5, X_test, y_test, cmap=plt.cm.Blues, ax=ax);","7638941d":"explainercat = shap.TreeExplainer(catboost_5)\nshap_values_cat_test = explainercat.shap_values(X_test)\nshap_values_cat_train = explainercat.shap_values(X_train)","43d788c6":"shap.summary_plot(shap_values_cat_train, X_train, plot_type=\"bar\",plot_size=(12,12))","47386be9":"fig = plt.subplots(figsize=(6,6),dpi=200)\n\nax = shap.summary_plot(shap_values_cat_train, X_train,plot_type=\"dot\")","be8b0258":"fig, ax= plt.subplots(figsize=(6,6),dpi=100)\nshp_plt = shap.dependence_plot(\"Contract\", shap_values_cat_test, X_test,ax=ax,interaction_index=None)","ce478cf3":"fig, ax= plt.subplots(figsize=(6,6),dpi=100)\n\nshap.dependence_plot(\"InternetService\", shap_values_cat_test, X_test,ax=ax, interaction_index=None)","fd6fb798":"fig, ax1= plt.subplots(figsize=(6,6),dpi=150)\n\nshp_plt = shap.dependence_plot(\"MonthlyCharges\", shap_values_cat_test,X_test,ax=ax1, interaction_index=None)","7638d7df":"fig, ax2 = plt.subplots(figsize=(6,6),dpi=200)\nshap.dependence_plot(\"tenure\", shap_values_cat_test, X_test,interaction_index=None,ax=ax2)","ccb9443a":"fig, ax3 = plt.subplots(figsize=(6,6),dpi=200)\nshp_plt = shap.dependence_plot(\"tenure\", shap_values_cat_test, X_test,ax=ax3, cmap=plt.get_cmap('autumn'))","a2789381":"fig, ax4 = plt.subplots(figsize=(6,6),dpi=200)\nshp_plt = shap.dependence_plot('MonthlyCharges', shap_values_cat_test, X_test,interaction_index='Contract',ax=ax4, cmap=plt.get_cmap('Spectral'))","ed205796":"print(f'Expected Value-Base Value: {explainercat.expected_value}')","5c1c55e0":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_1= shap.decision_plot(explainercat.expected_value, shap_values_cat_test[:50], X_test.iloc[:50],auto_size_plot=False, link= \"logit\")\n","4fa6ebf8":"X_test.iloc[15]","22d942b8":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_2= shap.decision_plot(explainercat.expected_value, shap_values_cat_test[15], X_test.iloc[[15]], link= \"logit\")\n","44f425e4":"print(f'Customer 15: Actual value for the Customer Churn : {y_test.iloc[15]}')\nprint(f\"Customer 15: CatBoost Model's prediction for the Customer Churn : {y_pred[15]}\")","abcd4af3":"X_test.iloc[35]","15c59b5b":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_2= shap.decision_plot(explainercat.expected_value, shap_values_cat_test[35], X_test.iloc[[35]],link= \"logit\")\n","ee3d72d3":"print(f'Customer 35: Actual value for the Customer Churn : {y_test.iloc[35]}')\nprint(f\"Customer 35: CatBoost Model's prediction for the Customer Churn : {y_pred[35]}\")","7bda0a6f":"shap.initjs()\nshap.force_plot(explainercat.expected_value, shap_values_cat_test[:50], X_test.iloc[:50],link= \"logit\")","0e92308d":"shap.initjs()\nshap.force_plot(explainercat.expected_value, shap_values_cat_test[15], X_test.iloc[[15]],link= \"logit\")","18c8e8cf":"shap.initjs()\nshap.force_plot(explainercat.expected_value, shap_values_cat_test[35], X_test.iloc[[35]],link= \"logit\")","3c2b23fd":"fig = plt.subplots(figsize=(6,6),dpi=150)\nax_3= shap.plots._waterfall.waterfall_legacy(explainercat.expected_value, shap_values_cat_test[15], feature_names = X_test.columns,max_display = 20)","44f7def5":"fig = plt.subplots(figsize=(6,6),dpi=150)\nax_3= shap.plots._waterfall.waterfall_legacy(explainercat.expected_value, shap_values_cat_test[35], feature_names = X_test.columns,max_display = 20)","d54f240d":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\nfor col in X.columns:\n    col_type = X[col].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        X[col] = X[col].astype('category')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nlgbmc_5=lgb.LGBMClassifier(random_state=0,scale_pos_weight=5)\n\nlgbmc_5.fit(X_train, y_train,categorical_feature = 'auto',eval_set=(X_test, y_test),feature_name='auto', verbose=0)\n\ny_pred = lgbmc_5.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['LightGBM_adjusted_weight_5']\nresult_df9 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df9","2e0590c6":"fig, ax = plt.subplots(figsize=(8, 8))\nplot_confusion_matrix(lgbmc_5, X_test, y_test, cmap=plt.cm.Blues, ax=ax);","3380ff1b":"explainerlgbmc = shap.TreeExplainer(lgbmc_5)\nshap_values_LightGBM_test = explainerlgbmc.shap_values(X_test)\nshap_values_LightGBM_train = explainerlgbmc.shap_values(X_train)","0e9ed6b5":"shap.summary_plot(shap_values_LightGBM_train[1], X_train, plot_type=\"bar\",plot_size=(12,12))","1f87200c":"fig = plt.subplots(figsize=(6,6),dpi=200)\n\nax = shap.summary_plot(shap_values_LightGBM_train[1], X_train,plot_type=\"dot\")","cfb90c51":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_2= shap.decision_plot(explainerlgbmc.expected_value[1], shap_values_LightGBM_test[1][15], X_test.iloc[[15]],link= \"logit\")\n","a5f1e6b4":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_2= shap.decision_plot(explainerlgbmc.expected_value[1], shap_values_LightGBM_test[1][35], X_test.iloc[[35]],link= \"logit\")\n","a7750a2a":"shap.initjs()\nshap.force_plot(explainerlgbmc.expected_value[1],shap_values_LightGBM_test[1][15], X_test.iloc[[15]],link= \"logit\")","67cd69fb":"shap.initjs()\nshap.force_plot(explainerlgbmc.expected_value[1],shap_values_LightGBM_test[1][35], X_test.iloc[[35]],link= \"logit\")","9695fcac":"fig = plt.subplots(figsize=(6,6),dpi=150)\nax_3= shap.plots._waterfall.waterfall_legacy(explainerlgbmc.expected_value[1],shap_values_LightGBM_test[1][15], feature_names = X_test.columns,max_display = 20)","888f4985":"fig = plt.subplots(figsize=(6,6),dpi=150)\nax_3= shap.plots._waterfall.waterfall_legacy(explainerlgbmc.expected_value[1],shap_values_LightGBM_test[1][35], feature_names = X_test.columns,max_display = 20)","e3b4f6b2":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\ndf1= pd.get_dummies(df1)\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nxgbc_5 = XGBClassifier(random_state=0,scale_pos_weight=5)\n\nxgbc_5.fit(X_train, y_train)\ny_pred = xgbc_5.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['XGBoost_adjusted_weight_5']\nresult_df6 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df6","95ecdad8":"fig, ax = plt.subplots(figsize=(8, 8))\nplot_confusion_matrix(xgbc_5, X_test, y_test, cmap=plt.cm.Blues, ax=ax);","07023354":"explainerxgbc = shap.TreeExplainer(xgbc_5)\nshap_values_XGBoost_test = explainerxgbc.shap_values(X_test)\nshap_values_XGBoost_train = explainerxgbc.shap_values(X_train)","4dc45f65":"shap.summary_plot(shap_values_XGBoost_train, X_train, plot_type=\"bar\",plot_size=(12,12))","45e405cf":"fig = plt.subplots(figsize=(6,6),dpi=200)\n\nax = shap.summary_plot(shap_values_XGBoost_train, X_train,plot_type=\"dot\")","492f449e":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_2= shap.decision_plot(explainerxgbc.expected_value, shap_values_XGBoost_test[15], X_test.iloc[[15]],link= \"logit\")\n","5a248dc2":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_2= shap.decision_plot(explainerxgbc.expected_value, shap_values_XGBoost_test[35], X_test.iloc[[35]],link= \"logit\")","b494dadd":"shap.initjs()\nshap.force_plot(explainerxgbc.expected_value, shap_values_XGBoost_test[15], X_test.iloc[[15]],link= \"logit\")","db0943f0":"shap.initjs()\nshap.force_plot(explainerxgbc.expected_value, shap_values_XGBoost_test[35], X_test.iloc[[35]],link= \"logit\")","11d5c4e4":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_3= shap.plots._waterfall.waterfall_legacy(explainerxgbc.expected_value, shap_values_XGBoost_test[15], feature_names = X_test.columns,max_display = 20)","f3ce8922":"fig = plt.subplots(figsize=(6,6),dpi=200)\nax_3= shap.plots._waterfall.waterfall_legacy(explainerxgbc.expected_value, shap_values_XGBoost_test[35], feature_names = X_test.columns,max_display = 20)","ed2895dd":"#### The baseline is 0.4562. \n## Customer 35 has a very low predicted risk of **0.05 to churn**. \n### **Two year contract** significantly decreases the probability of customer churn.\n### Only **17 months of being with the company** increases the probability of churn.\n### It is very similar to **Decision Plot** we have seen before.","539c0e5f":"### **Tenure & Contract** interaction:\n### As expected customer with longer time with the company and with the two year contract less likely to churn\n### Customer with a month-to-month contract and less than at around 20 months with the company more likely to churn.\n### Customer with one year contract and less than 60 months with the company does not have much interaction with the churn rate.\n### Customer with one year contract and more than 60 months with the company more likely to stay with the company.","fae38f77":"#### The baseline is 0.6693. \n## Customer 35 has a very low predicted risk of **0.0005 to churn**. \n### **Having Two year contract** instead of **month-to-month contract** significantly decreases the probability of customer churn.\n### It is very similar to **Decision Plot** we have seen before.","0e2abae7":"Image Credit: https:\/\/miro.medium.com\/","e89c8ccd":"- Let's see our model prediction on the customer 35:","ea9be79f":"### **Customer 15**","2bcf5038":"## **Decision Plot** , **Force Plot** and **Waterfall Plot** are very useful to understand and explain how the model arrived at its decision.\n","f11fe4af":"![](https:\/\/media.giphy.com\/media\/11gC4odpiRKuha\/giphy.gif)","7b84e437":"### **Customer 15**","7adf7c7e":"> ### You can visualize feature attributions such as Shapley values as \u201cforces\u201d. \n\n> ### Each feature value is a force that either increases or decreases the prediction. \n\n> ### The prediction starts from the baseline. The baseline for Shapley values is the average of all predictions. \n\n> ### In the plot, each Shapley value is an arrow that pushes to increase (positive value) or decrease (negative value) the prediction. These forces balance each other out at the actual prediction of the data instance.\n\nReference: https:\/\/christophm.github.io\/interpretable-ml-book\/shap.html","d42b33f1":"<a id=\"22\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>XGBoost (with adjusted Scale_Pos_Weight = 5) Deals With Imbalanced Data<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","9b0dc6f1":"- SHAP feature importance is easy to explain. Features with larger values are important. \n- As we have seen from the feature importance:\n   - **`contract`**\n   - **`internet service type`**\n   - **`tenure:How long they are with the company`** are the important features based on the Catboost model we have selected.","c8ac4760":"- By using **`scale_pos_weight =5`**, **LightGBM** correctly predicted **83% of the churned customer**.","ce24e131":"<a id=\"14\"><\/a>\n<font color=\"Darkblue\" size=+2.5><b>LightGBM with SHAP<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","80ebeb2a":"Image Credit: https:\/\/avatars.mds.yandex.net","197729d6":"#### The baseline is  0.6693. \n## Customer 15 has a very high predicted risk of **0.96 to churn**. \n### **Month to month contract** significantly increases the probability of customer churn.\n### Only **Payment method: Bank Transfer-Automatic** decreases the probability of churn.\n### It is very similar to **Decision Plot** we have seen before.","cdbd3446":"![](https:\/\/e7.pngegg.com\/pngimages\/301\/649\/png-clipart-snake-scale-measuring-scales-measurement-scale-light-fixture-measuring-scales-thumbnail.png)","725fae12":"<a id=\"8\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Feature Importance<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","f280ec65":"- Let's look at the data.","082886b3":"### **Monthly Charges**:\n### Monthly charges until at around 60 US Dollars, customer most likely not to churn and continue with the company.\n### When monthly charges start to increase from 100 US Dollar and up, customer is most likely to churn.","468166fe":"### **Customer 35**","7a255538":"![](https:\/\/user-images.githubusercontent.com\/38404461\/65588818-7734b500-df88-11e9-907c-a0bc0c0fdfc1.png)","7915e15a":"### **Data Dictionary**\n\n1. **`CustomerID`**: A unique ID that identifies each customer.\n\n2. **`Gender`**: The customer\u2019s gender: Male, Female\n\n3. **`Age`**: The customer\u2019s current age, in years, at the time the fiscal quarter ended.\n\n4. **`Senior Citizen`**: Indicates if the customer is 65 or older: Yes, No\n\n5. **`Married (Partner)`**: Indicates if the customer is married: Yes, No\n\n6. **`Dependents`**: Indicates if the customer lives with any dependents: Yes, No. Dependents could be children, parents, grandparents, etc.\n\n7. **`Number of Dependents`**: Indicates the number of dependents that live with the customer.\n\n8. **`Phone Service`**: Indicates if the customer subscribes to home phone service with the company: Yes, No\n\n9. **`Multiple Lines`**: Indicates if the customer subscribes to multiple telephone lines with the company: Yes, No\n\n10. **`Internet Service`**: Indicates if the customer subscribes to Internet service with the company: No, DSL, Fiber Optic, Cable.\n\n11. **`Online Security`**: Indicates if the customer subscribes to an additional online security service provided by the company: Yes, No\n\n12. **`Online Backup`**: Indicates if the customer subscribes to an additional online backup service provided by the company: Yes, No\n\n13. **`Device Protection Plan`**: Indicates if the customer subscribes to an additional device protection plan for their Internet equipment provided by the company: Yes, No\n\n14. **`Premium Tech Support`**: Indicates if the customer subscribes to an additional technical support plan from the company with reduced wait times: Yes, No\n\n15. **`Streaming TV`**: Indicates if the customer uses their Internet service to stream television programing from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n16. **`Streaming Movies`**: Indicates if the customer uses their Internet service to stream movies from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n17. **`Contract`**: Indicates the customer\u2019s current contract type: Month-to-Month, One Year, Two Year.\n\n18. **`Paperless Billing`**: Indicates if the customer has chosen paperless billing: Yes, No\n\n19. **`Payment Method`**: Indicates how the customer pays their bill: Bank Withdrawal, Credit Card, Mailed Check\n\n20. **`Monthly Charge`**: Indicates the customer\u2019s current total monthly charge for all their services from the company.\n\n21. **`Total Charges`**: Indicates the customer\u2019s total charges, calculated to the end of the quarter specified above.\n\n22. **`Tenure`**: Indicates the total amount of months that the customer has been with the company.\n\n23. **`Churn`**: Yes = the customer left the company this quarter. No = the customer remained with the company. Directly related to Churn Value.\n\nReference:\nhttps:\/\/www.kaggle.com\/blastchar\/telco-customer-churn\n\nhttps:\/\/community.ibm.com\/community\/user\/businessanalytics\/blogs\/steven-macko\/2019\/07\/11\/telco-customer-churn-1113\n\n","182f4d90":"### [As we discussed in the previous notebook](https:\/\/www.kaggle.com\/kaanboke\/xgboost-lightgbm-catboost-imbalanced-data), in this dataset we are dealing with imbalanced data.\n### [To handle imbalanced data](https:\/\/www.kaggle.com\/kaanboke\/xgboost-lightgbm-catboost-imbalanced-data) we use  **scale_pos_weight** and adjust it accordingly.\n###  By adjusting  **scale_pos_weight**  to **5**: Minority class gets 5 times more impact and 5 times more correction than errors made on the majority class. ","52193485":"- With the adjusted **`scale_pos_weight=5`**, **CatBoost** got  almost **.92 Recall and .75 Roc_Auc**","40dfa692":"<a id=\"6\"><\/a>\n<font color=\"Darkblue\" size=+2.5><b>CatBoost with SHAP<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","38b4d6e6":"#### The baseline is  0.4562. \n## Customer 15 has a very high predicted risk of **0.90 to churn**. \n###  **Month to month contract** significantly increases the probability of customer churn.\n### Only **Payment method: Bank Transfer-Automatic** decreases the probability of churn.\n### It is very similar to **Decision Plot** we have seen before.","4283c2b0":"## **Contract**","426f2baf":"<a id=\"13\"><\/a>\n<font color=\"Darkblue\" size=+2><b>SHAP Waterfall Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","02e4db5c":"### As seen very cleary form the dependence plot;\n### Customers with the **Fiber Optic Internet Service** with the company most likely to churn\n### Customers **without any internet service** with the company most likely to continue with the company.","66b84bf0":"- So customer 35:\n   - Not a Senior citizen\n   - Has two year contract\n   - 17 month tenure with the company\n   - Monthly charges is 19.45 $ and Total charges is 369.05 US Dollars.\n   - Does not have any partner or dependent \n   - Doesnot have any internet service with the company.\n   - No device protection, no online security, no tech support\n","b92e7b1e":"### **Customer 15**","285a2cc2":"- It is very similar to **`force plot`** so, it would be good to know it.","08558561":"### **Customer 35**","24ad870a":"- Let' see one more categorical variable.","d2085aea":"- By using **`scale_pos_weight = 5`**, **CatBoost** correctly predict almost **92% of the churned customers**.","5d6d93e4":"### SHAP feature importance is easy to explain. Features with larger values are important. \n### As we have seen from the feature importance:\n### **contract**\n### **tenure:How long they are with the company** \n### **monthly charges**\n### **internet service type** are the important features based on the Catboost model we have selected.","19c4eed7":"# [We have already covered detailed EDA in our previous notebook. For that reason, I won't include detailed EDA in this notebook.](https:\/\/www.kaggle.com\/kaanboke\/xgboost-lightgbm-catboost-imbalanced-data)","bb775f84":"- Let's see customer 15 in detail.","a6d60fbf":"<a id=\"29\"><\/a>\n<font color=\"darkblue\" size=+1.5><b>References & Further Reading<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>\n\n[Machine Learning - Beginner &Intermediate-Friendly BOOKS](https:\/\/www.kaggle.com\/general\/255972)\n\nhttps:\/\/christophm.github.io\/interpretable-ml-book\/\n\nhttps:\/\/shap.readthedocs.io\/\n\nhttps:\/\/shap-lrjball.readthedocs.io\/en\/docs_update\/index.html","621546b0":"### [As we discussed in the previous notebook](https:\/\/www.kaggle.com\/kaanboke\/xgboost-lightgbm-catboost-imbalanced-data), in this dataset we are dealing with imbalanced data.\n### [To handle imbalanced data](https:\/\/www.kaggle.com\/kaanboke\/xgboost-lightgbm-catboost-imbalanced-data) we use  **scale_pos_weight** and adjust it accordingly.\n### By adjusting  **scale_pos_weight**  to **5**: Minority class gets 5 times more impact and 5 times more correction than errors made on the majority class. ","e318e267":"## Before seeing how model make decison on the speficic case, let's see model force plot on the first 50 customers' churn probability.\n## Enjoy the beauty of the interactive SHAP Force plot.","0290ba84":"![](https:\/\/avatars.mds.yandex.net\/get-bunker\/56833\/dba868860690e7fe8b68223bb3b749ed8a36fbce\/orig)","b318d677":"### **Customer 35**","ab87ef0c":"### **Customer 15**","6e40a19a":"![](https:\/\/shap-lrjball.readthedocs.io\/en\/stable\/_images\/shap_header.png)","7809c947":"### **Customer 35**","6f7474fe":"- **XGBoost** correctly predicted almost **74% of the churned customers** by using **scale_pos_weight=5** (Roc_Auc = .75)\n","017c1b3e":"![](https:\/\/repository-images.githubusercontent.com\/64991887\/dc855780-e34b-11ea-9ab8-e08ca33288b0)","55681972":"<a id=\"25\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Decision Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","30e280fe":"### **Customer 35**","ad44a133":"## **Customer 15**","e06a0421":"### **Customer 35**","42fab5a6":"### **Customer 35**","40551bf5":"- With the adjusted **`scale_pos_weight = 5`**, **XGBoost** got **.74 Recall and .75 Roc_Auc**","8c6c616d":"## **Internet Service**","47bc1e69":"![](https:\/\/media.giphy.com\/media\/3orieM85kojJlOEYFy\/giphy.gif)","38b6a1fb":"#### Hi all.  \ud83d\ude4b\n\n#### We continue our **Beginner-Intermediate Friendly Machine Learning series**, which would help anyone who wants to learn or refresh the basics of ML.\n\n#### What we have covered: \n\n#### [Beginner Friendly Detailed Explained EDAs \u2013 For anyone at the beginnings of DS\/ML journey](https:\/\/www.kaggle.com\/general\/253911#1393015) \u2714\ufe0f\n\n#### [BIAS & VARIANCE TRADEOFF](https:\/\/www.kaggle.com\/kaanboke\/ml-basics-bias-variance-tradeoff) \u2714\ufe0f\n\n#### [LINEAR ALGORITHMS](https:\/\/www.kaggle.com\/kaanboke\/ml-basics-linear-algorithms)  \u2714\ufe0f\n\n#### [NONLINEAR ALGORITHMS](https:\/\/www.kaggle.com\/kaanboke\/nonlinear-algorithms)  \u2714\ufe0f\n\n#### [The Most Used Methods to Deal with MISSING VALUES](https:\/\/www.kaggle.com\/kaanboke\/the-most-used-methods-to-deal-with-missing-values)  \u2714\ufe0f\n\n#### [Beginner Friendly End to End ML Project- Classification with Imbalanced Data](https:\/\/www.kaggle.com\/kaanboke\/beginner-friendly-end-to-end-ml-project-enjoy)  \u2714\ufe0f\n\n#### [How to Prevent the Data Leakage ?](https:\/\/www.kaggle.com\/kaanboke\/how-to-prevent-the-data-leakage) \u2714\ufe0f\n\n#### [The Most Common EVALUATION METRICS- A Gentle Intro](https:\/\/www.kaggle.com\/kaanboke\/the-most-common-evaluation-metrics-a-gentle-intro) \u2714\ufe0f\n\n#### [Feature Selection-The Most Common Methods to Know](https:\/\/www.kaggle.com\/kaanboke\/feature-selection-the-most-common-methods-to-know) \u2714\ufe0f\n\n#### [Beginner Friendly End to End ML Project- Car Price Prediction](https:\/\/www.kaggle.com\/kaanboke\/car-price-prediction-beginner-friendly-94-3)  \u2714\ufe0f\n\n#### [Beginner Friendly CATBOOST with OPTUNA](https:\/\/www.kaggle.com\/kaanboke\/beginner-friendly-catboost-with-optuna)  \u2714\ufe0f\n\n#### [A Gentle Intro to PYCARET-Beginner Friendly](https:\/\/www.kaggle.com\/kaanboke\/a-gentle-intro-to-pycaret-beginner-friendly)  \u2714\ufe0f\n\n#### [XGBoost & LightGBM & Catboost - Imbalanced Data](https:\/\/www.kaggle.com\/kaanboke\/xgboost-lightgbm-catboost-imbalanced-data)  \u2714\ufe0f\n\n\n#### In this notebook, we will look in detail at how the famous trio (**XGBoost & LightGBM & Catboost**) are explained by **SHAP**.\n\n\n#### **Enjoy** \ud83e\udd18","fbd18a6d":"### The expected value \u2013 the average predicted probability \u2013 is:  - 0.1755.\n### In the plot, we will use **logit** function and  will change log-odds numbers into probabilities.\n### By using logit number, **base value- expected value** will be **0.4562**","db035955":"Image Credit:https:\/\/user-images.githubusercontent.com\/38404461\/","9841b979":"## **Monthly Charges & Contract - Churn**","eeb674c3":"- It is very similar to **`force plot`** so, it would be good to know.","f248b692":"### Model starts with the **expected value** \u2013 the average predicted probability:  0.4562.\n### Not having **multiple lines** and  **Streaming TV** with the company, have small effects on the increasing the probability of the not churn decision.\n### On the other hand being 17 months **tenure** has small effect on the increasing the probability of the churn decision.\n### **Monthly charges** with 19.45 US Dollars and not having **paperless billing`* have effects on the increasing the probability of the not churn decision.\n### Not having any **internet service** with the company have signigicant level effects on the increasing the probability of the not churn decision.\n### From decision plot, it is seen that having **two year contract** with the company has the most signigicant effect on the probability of the not churn decision in this model for this specific customer.","7cb8730c":"### **Customer 15**","10be3ea8":"#### OK. so far we  have seen general pictures.\n\n#### Since we want to explain model predictions to our (most probably non-technical) customers \/ stakeholders, let's make it more specific.\n\n#### We will focus on two different customers, who are customer 15 and customer 35 in test set.\n\n#### We will see how model decide the process and what features have affect on that decisions of the model.\n\n## Very enjoable, let's dive in.","0bc3146a":"- Let's see customer 35 in detail.","b0885f02":"## In this notebook, we have looked in detail at how famous trio (XGBoost & LightGBM & Catboost)  models are explained by the SHAP.\n\n### First we started with the general explanation of  how model works.\n\n### Then we focused on the two different customer churn predictions to see everything in the action.\n\n### **SHAP (SHapley Additive exPlanations)** is a method to explain individual predictions.\n\n###  **SHAP summary plot** gives in detail info by combining feature importance with its effects.\n\n### **SHAP Decison Plot** gives us a clear picture of how models, in our case how complex models, reach their decisions.\n\n### **SHAP Force Plot**: We can visualize feature attributions such as Shapley values as \u201cforces\u201d. Each feature value is a force that either increases or decreases the prediction.\n\n### **SHAP Waterfall plots** are designed to display explanations for individual predictions, so they expect a single row of an Explanation object as input.\n\n### I have to emphasize that it is important to get deep knowledge on the data and problem on the hand. \n\n### Model interpretability is very important tool for any Data Scientist to have in her\/his toolbox. \n\n## **SHAP** is very useful tool to understand and explain how the model arrived at its decision.\n\n ","81cb5f00":"<a id=\"19\"><\/a>\n<font color=\"Darkblue\" size=+2><b>SHAP Force Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","82f44ba9":"<a id=\"27\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Waterfall Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","7a983985":"<a id=\"17\"><\/a>\n<font color=\"Darkblue\" size=+2><b>SHAP Summary Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","310d8d97":"<a id=\"26\"><\/a>\n<font color=\"Darkblue\" size=+2><b>SHAP Force Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","8a3f165a":"### [As we discussed in the previous notebook](https:\/\/www.kaggle.com\/kaanboke\/xgboost-lightgbm-catboost-imbalanced-data), in this dataset we are dealing with imbalanced data.\n### [To handle imbalanced data](https:\/\/www.kaggle.com\/kaanboke\/xgboost-lightgbm-catboost-imbalanced-data) we use  **scale_pos_weight** and adjust it accordingly.\n### By adjusting  **scale_pos_weight**  to **5**: Minority class gets 5 times more impact and 5 times more correction than errors made on the majority class. ","486d426b":"Image Credit: https:\/\/e7.pngegg.com","9553155d":"### **Monthly Charges & Contract** interaction:\n  \n### Customer with a month-to-month contract and less than at around 60 US Dollars  monthly charges is more likely to stay with the company.\n### When monthly charges get more than 100 US Dollars, probability of the customer churn in all contract types starts to increase.\n### Customer with two year contract or one year contract and with the monthly charges more than at around 110 US Dollars are more likely to churn.","ea15c7b3":"<a id=\"18\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Decision Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","b9c71840":"<a id=\"7\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>CatBoost (with adjusted Scale_Pos_Weight = 5) Deals With Imbalanced Data<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","75359e94":"<a id=\"2\"><\/a>\n<font color=\"Darkblue\" size=+2.5><b>Exploratory Data Analysis<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","905e64fd":"> ### SHAP (SHapley Additive exPlanations) is a method to explain individual predictions. SHAP is based on the game theory.\n\n> ### A prediction can be explained by assuming that each feature value of the instance is a \u201cplayer\u201d in a game where the prediction is the payout. \n\n> ### Shapley values \u2013 a method from coalitional game theory \u2013 tells us how to fairly distribute the \u201cpayout\u201d among the features.\n\n> ### The \u201cgame\u201d is the prediction task for a single instance of the dataset. \n\n> ### The \u201cgain\u201d is the actual prediction for this instance minus the average prediction for all instances. \n\n> ### The \u201cplayers\u201d are the feature values of the instance that collaborate to receive the gain (= predict a certain value). \n\n> ### The Shapley value is the average marginal contribution of a feature value across all possible coalitions.\n\nReference: https:\/\/christophm.github.io\/interpretable-ml-book\/shapley.html","d3d411fc":"<a id=\"toc\"><\/a>\n\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\">Table of Contents<\/h3>\n    \n* [Data](#0)\n* [What Problem We Have and Which Metric to Use?](#1)\n\n* [Exploratory Data Analysis](#2)\n    * [Target Variable](#3)\n    * [Overall Insights from the EDA](#4)\n      \n      \n* [What is SHAP](#5) \n\n\n* [CATBOOST with SHAP](#6)\n    * [CatBoost (with adjusted Scale_Pos_Weight = 5) Deals With Imbalanced Data](#7)\n    * [SHAP Feature Importance](#8)\n    * [SHAP Summary Plot](#9)\n    * [SHAP Dependence Plot](#10)\n    * [SHAP Decision Plot](#11)\n    * [SHAP Force Plot](#12)\n    * [SHAP Waterfall Plot](#13)\n    \n* [LightGBM with SHAP](#14)\n    * [LightGBM (with adjusted Scale_Pos_Weight = 5) Deals With Imbalanced Data](#15)\n    * [SHAP Feature Importance](#16)\n    * [SHAP Summary Plot](#17)\n    * [SHAP Decision Plot](#18)\n    * [SHAP Force Plot](#19)\n    * [SHAP Waterfall Plot](#20)  \n\n* [XGBOOST with SHAP](#21)\n    * [XGBoost (with adjusted Scale_Pos_Weight = 5) Deals With Imbalanced Data](#22)\n    * [SHAP Feature Importance](#23)\n    * [SHAP Summary Plot](#24)\n    * [SHAP Decision Plot](#25)\n    * [SHAP Force Plot](#26)\n    * [SHAP Waterfall Plot](#27) \n    \n* [Conclusion](#28)\n\n* [References & Further Reading](#29)","7512dc9a":"<a id=\"9\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Summary Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","90b3f0d0":"<a id=\"1\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>What Problem We Have and Which Metric to Use?<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","3ca77382":"## **Customer 35**","1bc96586":"<a id=\"23\"><\/a>\n<font color=\"Darkblue\" size=+2><b>SHAP Feature Importance<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","72814871":"<a id=\"21\"><\/a>\n<font color=\"Darkblue\" size=+2.5><b>XGBoost with SHAP<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","0fc0c8d2":"### **Customer 15**","905c7c94":"<a id=\"20\"><\/a>\n<font color=\"Darkblue\" size=+2><b>SHAP Waterfall Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","628348b2":"- Let's see different features interaction and how it effects the churn.","6b89a15a":"<a id=\"10\"><\/a>\n<font color=\"Darkblue\" size=+2><b>SHAP Dependence Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","eb78a5ab":"- Let's see our model prediction on the customer 15:","7b093986":"<a id=\"11\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Decision Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","8e5501aa":"## **Decision Plot** , **Force Plot** and **Waterfall Plot** are very useful to understand and explain how the model arrived at its decision.\n","73335de2":"> ### Waterfall plots are designed to display explanations for individual predictions, so they expect a single row of an Explanation object as input. \n\n> ### The bottom of a waterfall plot starts as the expected value of the model output, and then each row shows how the positive (red) or negative (blue) contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction.\n\nReference: https:\/\/shap.readthedocs.io\/\n","6fe35af1":"\n# **It is beautiful**","64b64029":"<a id=\"28\"><\/a>\n<font color=\"Darkblue\" size=+2.5><b>Conclusion<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","1c3eb27d":"<a id=\"3\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>Target Variable<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","49baaa1b":"### SHAP summary plot gives in detail info by combining feature importance with its effects.\n### Color of the dots represents the value of the feature (Blue: low value, red: Higher value)\n### Features are ordered based on their importance\n### As we have seen in the tenure higher values of the tenure, lower the probability of the customer churn.\n### Higher monthly charges increase risk of the customer churn.\n### As you have seen that **contract** has kind of dark gray color, what does it mean?\n### Both CatBoost and LightGBM handles with the categorical variables internaly for that reason, categorical features are not included into SHAP model as numerical encoded versions.\n### We will see their importance in detail with **SHAP Dependence Plot**\n","58117ea0":"#### The baseline is 0.3025. \n## Customer 35 has a very low predicted risk of **0.01 to churn**. \n### **Two year contract** significantly decreases the probability of customer churn.\n### Only **17 months of being with the company** slightly increases the probability of churn.\n### It is very similar to **Decision Plot** we have seen before.","7b9683a3":"### As seen very cleary form the dependence plot;\n### Customers with the **Month to month contract** most likely to churn\n### Customers with the **Two year contract** most likely to continue with the company","5cfee35c":"Gif Credit: https:\/\/media.giphy.com\/","0a2d19e5":"#### The baseline is  0.3025. \n## Customer 15 has a very high predicted risk of **0.94 to churn**. \n### **Month to month contract** significantly increases the probability of customer churn.\n### Only **Payment method: Bank Transfer-Automatic** decreases the probability of churn.\n### It is very similar to **Decision Plot** we have seen before.","3256ec83":"- Based on the data and data dictionary, We have a classification problem.\n- We wil make classification on the target variable **`Churn`**\n- And we will build a model to get best classification possible on the target variable.\n- For that we will look at the balance of the target variable.\n- As we will see later, our target variable has imblanced data\n- For that reason we are not going to use Accuracy score, \n- Based on the problem on the hand, we will use **`Recall score`**.\n- [For the detailed info about the evaluation metrics](https:\/\/www.kaggle.com\/kaanboke\/the-most-common-evaluation-metrics-a-gentle-intro)","2a95bb1e":"- Let's import the libraries","25edab75":"### **Customer 35**","65a49f5b":"<a id=\"12\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Force Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","df24b2ed":"### **Customer 15**","75193a9c":"### **Customer 15**","8d5bfad9":"# **Customer Specific Cases: Customer 15 and Customer 35**","5045064d":"### Model starts with the **expected value** \u2013 the average predicted probability:  **0.4562**.\n### Being **senior citizen**, doesn't have an **online security services**, having a **multiple lines** with the company, 1K **total charges**, **paperless billing** slightly increase probability of the churn.\n### **Monthly charges** with 95.15 US Dollars and having **Streaming TV** services have medium level effects on the increasing the probability of the churn.\n### On the other hand **payment method as a bank transfer automatic** has effect on the decreasing the probability of the churn decision.\n### Being 11 months **tenure** with the company and having **Fiber internet service** with the company have signigicantly increase the probability of the churn.  \n### From decision plot, it is seen that having **month-to-month contract** with the company has the most signigicant effect on the increasing the probability of the churn decision in this model for this specific customer.","9dd89eb1":"- We have imbalanced data.\n- Almost 27% of the customers didn't continue with the company and churned.\n- 1869 customer churned.\n- Almost 73% of the customers continue with the company and didn't churn.\n- 5174 customer didn't churn.\n","22573682":"Image Credit: https:\/\/shap-lrjball.readthedocs.io\/","90a042f1":"![](https:\/\/miro.medium.com\/max\/1400\/1*1kjLMDQMufaQoS-nNJfg1Q.png)","144f8afe":"### SHAP feature importance is easy to explain. Features with larger values are important. \n### As we have seen from the feature importance:\n### **contract: month-to-month**\n### **tenure:How long they are with the company** \n### **Total charges**\n### **Monthly charges**\n### **Internet service type:: fiber optic** are the important features based on the XGboost model we have selected.\n   ","9704aac3":"- With the adjusted **`scale_pos_weight = 5`**, **LightGBM** got **.84 Recall and  .76 Roc_Auc**","e976f0b6":"- **`Gender`** : There is not much difference between gender on the churn rate. We won't include gender into our model.\n- **`Partner`** :  Customer without any relationship, single customer almost 1.7 times more likely churn than cutomer with a partner.\n- **`Dependents`** : Customer without any dependents, almost 2.03 times more likely churn than cutomer with a dependent.\n- **`Phone Service`**: Churn rate difference between customer has a phone service with the company and customer does not have a home phone service with the company is very small. We won't include phone service into our model.\n- **`Multiple Lines`** : Churn rate difference between customer has a multiple lines phone service with the company and customer does not have a multiple line phone service with the company is very small.\n- **`\u00ecnternet Service`** : Customer with fiber optic internet with the company compare to customer without any internet service with the company 5.66 times more likely to churn.\n- **`Online Security`**: A customer with an online security service with the company almost 2.14 times less likely to leave the company than a customer without any online security service with the company.\n- **`Online Backup`** A customer with an online backup service with the company almost 1.35 times less likely to leave the company than a customer without any online backup service with the company.\n- **`Device Protection`** : A customer with a device protection service with the company almost 1.27 times less likely to leave the company than a customer without any a device protection service with the company.\n- **`Tech Support`** : A customer with a Tech Support service with the company almost 2.06 times less likely to leave the company than a customer without any a Tech Support service with the company.\n- **`Streaming TV Service`** : A customer with a Streaming TV service with the company almost 1.24 times more likely to leave the company than a customer without any a Streaming TV service with the company.\n- **`Streaming Movies Service`** : A customer with a Streaming Movies service with the company almost 1.23 times more likely to leave the company than a customer without any a Streaming movies service with the company.\n- **`Contract Type`** : Great differences based on the contract were seen in the histogram and mean differences.\n    - Customer with the 2 year contract almost 15.1 times less likely to churn compare to customer with a monthly contract.\n    - On the other hand customer with the 1 year contract almost 3.79 times less likely to churn compare to customer with a monthly contract.\n- **`Paperless Billing`** : A customer with a paperless billing with the company almost 2.06 times more likely to leave the company than a customer without a paperless billing with the company.\n- **`Payment Method`** : Almost half of the customers with a payment method as a Electornic Check churn, which is a quite big percentage.\n","c172067f":"- It is very similar to **force plot** so, it would be good to know it.","f36444f5":"### By the way, when you like the topic, you can show it by supporting \ud83d\udc4d\n\n###  **Feel free to leave a comment**. \n\n##  ENJOY YOUR DS \/ ML Learning Journey.\n\n## All the best \ud83e\udd18","c6c60c82":"### Before seeing how model make decison on the speficic case, let's see model decison plot on the **`first 50 customers' churn probability`**.","f31acaeb":"## **Tenure & Contract-Churn**","d147cd70":"<a id=\"16\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Feature Importance<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","66d8e7d0":"Image Credit: https:\/\/repository-images.githubusercontent.com\/64991887\/","e994f439":"![](https:\/\/media.giphy.com\/media\/Qtp1Ps7V6mRZwja223\/giphy.gif)","c003c592":"- And let's see one numerical feature","99885f87":"Gif Credit: https:\/\/media.giphy.com","94807061":"<a id=\"0\"><\/a>\n<font color=\"Darkblue\" size=+2.5><b>Data<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","0ed8dbf6":"## SHAP Decison Plot gives us a clear picture of how models, in our case how complex models, reach their decisions.\n\n","d1bfe873":"<a id=\"4\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>Overall Insights from the EDA<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","dd0faf6c":"# **Telco Customer Churn**","63ac76aa":"## **Monthly Charges**","4544bbe7":"Gif Credit: https:\/\/media.giphy.com\/","7722f136":"## **Tenure**","2b4ba6c9":"### **Tenure** as a numerical feature gives us a quite clear picture.\n### Customer more than at around 25 months with the company less likely to churn. ","2bbd46d8":"## **Decision Plot** , **Force Plot** and **Waterfall Plot** are very useful to understand and explain how the model arrived at its decision.\n","67b9743e":"<a id=\"5\"><\/a>\n<font color=\"Darkblue\" size=+2.5><b>What is SHAP?<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","2fd93653":"<a id=\"15\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>LightGBM (with adjusted Scale_Pos_Weight =5) Deals With Imbalanced Data<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","229a4bed":"<a id=\"24\"><\/a>\n<font color=\"Darkblue\" size=+1.5><b>SHAP Summary Plot<\/b><\/font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents<\/a>","159f9bbf":"> ### The x-axis represents the model\u2019s output. In this case, the units are log odds. \n\n> ### The plot is centered on the x-axis at explainer.expected_value. All SHAP values are relative to the model\u2019s expected value like a linear model\u2019s effects are relative to the intercept. \n\n> ### The y-axis lists the model\u2019s features. By default, the features are ordered by descending importance. The importance is calculated over the observations plotted. This is usually different than the importance ordering for the entire dataset. \n\n> ### In addition to feature importance ordering, the decision plot also supports hierarchical cluster feature ordering and user-defined feature ordering. \n\n> ### Each observation\u2019s prediction is represented by a colored line. At the top of the plot, each line strikes the x-axis at its corresponding observation\u2019s predicted value. This value determines the color of the line on a spectrum. \n\n> ### Moving from the bottom of the plot to the top, SHAP values for each feature are added to the model\u2019s base value. This shows how each feature contributes to the overall prediction.  \n\n> ### At the bottom of the plot, the observations converge at **explainer.expected_value**.\n\nReference: https:\/\/shap.readthedocs.io\/\n","39541d6e":"- So customer 15:\n   - Senior citizen\n   - Has Month to month contract\n   - 11 month tenure with the company\n   - Monthly charges is 95.15 $ and Total charges is around 1K\n   - Does not have any partner or dependent\n   - Internet service is Fiber optic\n   - No device protection, no online security, no tech support\n"}}