{"cell_type":{"c0e0932f":"code","3a8129d5":"code","00c1cad2":"code","83cbde34":"code","26aa497c":"code","c14443bb":"code","bfb4f6f2":"code","7c03b0bd":"code","216052d7":"code","ef0b5630":"code","de90ea67":"code","7fb767ca":"code","cbde4f54":"code","77ba53a5":"code","be4db3d8":"code","ddb7096d":"code","e88bf20d":"code","1cf8cbd7":"code","76c9ecd3":"code","2ce50e7c":"code","ee00c3c9":"code","87463bd9":"code","b6eeae56":"code","fd835e76":"code","e3bba8ee":"code","5931765a":"code","878ba3f2":"code","fd79943c":"code","e4e52142":"code","bdc255a4":"code","edb03b41":"code","30883eef":"code","46599c43":"code","23983df7":"code","7a569e2c":"code","5f9a5bac":"code","2dbd5beb":"code","16fc4eda":"code","b86b9c5a":"code","8f5bf449":"code","af25b0a2":"code","400573f3":"code","6fa6c227":"code","3a4009b5":"code","af2e463c":"code","55c96695":"code","3656bc69":"code","2d446835":"code","53b18f94":"code","f65cb810":"code","c1e49aba":"code","30dab4f0":"code","4cdd3b6d":"code","1c177e0d":"code","745a4eeb":"markdown","3e457ed3":"markdown","fc5191d9":"markdown","1ddf292d":"markdown","0a2a41b7":"markdown","b23efd70":"markdown","aeb02501":"markdown","861f625a":"markdown","75824169":"markdown","8877800b":"markdown","c2992952":"markdown","cac50282":"markdown","a82c22d0":"markdown","9cdc2234":"markdown","a6127ad1":"markdown","95e70060":"markdown","0841fd2d":"markdown","7d1563df":"markdown","08dcbc4d":"markdown","84c6c8d1":"markdown","198b22f7":"markdown","62f6df23":"markdown","986b436c":"markdown","17804ec5":"markdown","cb3c9f19":"markdown","5003948b":"markdown","8dfe8c5b":"markdown","c55f24c3":"markdown","da3c4366":"markdown","c3961de7":"markdown","034ba6be":"markdown","68233d25":"markdown","9ac65561":"markdown","b080b0cc":"markdown"},"source":{"c0e0932f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # l|inear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3a8129d5":"# Imports \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport sklearn\nimport random\nimport tensorflow as tf\nimport os\nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","00c1cad2":"# base_path and labels.\nbase_path = '..\/input\/brain-tumor-classification-mri\/'\nlabels = ['no_tumor', 'pituitary_tumor', 'meningioma_tumor', 'glioma_tumor']","83cbde34":"# Constants\nIMAGE_SIZE = 150\nBATCH_SIZE = 32\nVERBOSE = 1","26aa497c":"# Dataset from the training folder.\nx_train=[]\ny_train=[]\nfor i in labels:\n    folderPath = os.path.join(os.path.join(base_path,'Training'),i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n        x_train.append(img)\n        y_train.append(i)\nprint('Training dataset Loading complete.')\n\n# Dataset from the testing folder..\n\nfor i in labels:\n    folderPath = os.path.join(os.path.join(base_path,'Testing'),i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n        x_train.append(img)\n        y_train.append(i)\nx_train = np.array(x_train)\ny_train = np.array(y_train)\nx_train, y_train = sklearn.utils.shuffle(x_train, y_train, random_state=0)\n\nprint('Testing dataset Loading complete.')\n","c14443bb":"sns.countplot(y_train)\nplt.show()","bfb4f6f2":"j=0\nfor i in labels:\n    j=0\n    while True :\n        if y_train[j]==i:\n            plt.figure(figsize = (5,5))\n            plt.imshow(x_train[j])\n            plt.title(y_train[j])\n            break\n        j+=1","7c03b0bd":"datagen = ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=30,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True, vertical_flip=False\n)\n\ndatagen.fit(x_train)\nx_train.shape","216052d7":"# Splitting of dataset for Testing.\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.10, random_state=0)\n\nprint(\"Shapes X : Train :\",x_train.shape,  \" Test :\",x_test.shape)\nprint(\"Shapes Y : Train :\",y_train.shape,  \" Test :\",y_test.shape)\n","ef0b5630":"y_train_new = []\nfor i in y_train:\n    y_train_new.append(labels.index(i))\ny_train = y_train_new\ny_train = tf.keras.utils.to_categorical(y_train)\n\n\ny_test_new = []\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test = y_test_new\ny_test = tf.keras.utils.to_categorical(y_test)","de90ea67":"# Importing the model and initializing.\nfrom tensorflow.keras.applications import EfficientNetB0\neffnet = EfficientNetB0(weights = 'imagenet',include_top=False,input_shape=(IMAGE_SIZE,IMAGE_SIZE, 3))","7fb767ca":"# Adding Top Layers.\nmodel1 = effnet.output\nmodel1 = tf.keras.layers.GlobalAveragePooling2D()(model1)\nmodel1 = tf.keras.layers.Dropout(0.5)(model1)\nmodel1 = tf.keras.layers.Dense(4, activation = 'softmax')(model1)\nmodel1 = tf.keras.models.Model(inputs = effnet.input, outputs = model1)","cbde4f54":"# Model summary.\nmodel1.summary()","77ba53a5":"# Compiling Model\nmodel1.compile(loss = 'categorical_crossentropy', optimizer ='Adam', metrics=['accuracy'])","be4db3d8":"# Callbacks.\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\ntensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"effnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,mode='auto',verbose=VERBOSE)","ddb7096d":"# Fitting the model\nhistory1 = model1.fit(x_train, y_train, validation_split=0.1, epochs = 12, verbose =VERBOSE, batch_size=BATCH_SIZE, callbacks=[tensorboard,checkpoint,reduce_lr])","e88bf20d":"epochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2)\ntrain_acc = history1.history['accuracy']\ntrain_loss = history1.history['loss']\nval_acc = history1.history['val_accuracy']\nval_loss = history1.history['val_loss']\nfig.set_size_inches(14, 7)\n\nax[0].plot(epochs, train_acc, 'go-', label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, 'ro-', label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nax[1].plot(epochs, train_loss, 'g-o', label ='Training Loss')\nax[1].plot(epochs, val_loss, 'r-o', label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\nplt.show()","1cf8cbd7":"# Evaluating Model.\nresult1=model1.evaluate(x_test, y_test)\nprint(\"Testing Loss :\", result1[0])\nprint(\"Testing Accuracy :\", result1[1]*100, \"%\")","76c9ecd3":"predictions1 = model1.predict(x_test)\npredictions1 = np.argmax(predictions1, axis = 1)\ny_test_edit = np.argmax(y_test , axis = 1)","2ce50e7c":"# Classification report.\ncf_report = sklearn.metrics.classification_report(y_test_edit, predictions1 )\nprint(cf_report)","ee00c3c9":"cf_matrix = sklearn.metrics.confusion_matrix(y_test_edit, predictions1)\nsns.heatmap(cf_matrix, cmap = 'Blues', linewidth = 1, annot = True, xticklabels=labels, yticklabels=labels)","87463bd9":"# Importing the model and initializing.\nfrom tensorflow.keras.applications import Xception\nxception = Xception(weights = 'imagenet',include_top=False,input_shape=(IMAGE_SIZE,IMAGE_SIZE, 3))","b6eeae56":"# Adding Top Layers.\nmodel2 = xception.output\nmodel2 = tf.keras.layers.GlobalAveragePooling2D()(model2)\nmodel2 = tf.keras.layers.Dropout(0.5)(model2)\nmodel2 = tf.keras.layers.Dense(4, activation = 'softmax')(model2)\nmodel2 = tf.keras.models.Model(inputs = xception.input, outputs = model2)","fd835e76":"# Summary of the model.\nmodel2.summary()","e3bba8ee":"# Compiling the model.\nmodel2.compile(loss = 'categorical_crossentropy', optimizer ='Adam', metrics=['accuracy'])","5931765a":"# Callbacks.\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\ntensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"xception.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,mode='auto',verbose=VERBOSE)","878ba3f2":"# Fitting the model\nhistory2 = model2.fit(x_train, y_train, validation_split=0.1,epochs = 12,  verbose = VERBOSE, batch_size=BATCH_SIZE, callbacks=[tensorboard,checkpoint, reduce_lr])","fd79943c":"epochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2)\ntrain_acc = history2.history['accuracy']\ntrain_loss = history2.history['loss']\nval_acc = history2.history['val_accuracy']\nval_loss = history2.history['val_loss']\nfig.set_size_inches(14, 7)\n\nax[0].plot(epochs, train_acc, 'go-', label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, 'ro-', label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nax[1].plot(epochs, train_loss, 'g-o', label ='Training Loss')\nax[1].plot(epochs, val_loss, 'r-o', label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\nplt.show()","e4e52142":"# Evaluating Model.\nresult2=model2.evaluate(x_test, y_test)\nprint(\"Testing Loss :\", result2[0])\nprint(\"Testing Accuracy :\", result2[1]*100, \"%\")","bdc255a4":"predictions2 = model2.predict(x_test)\npredictions2 = np.argmax(predictions2, axis = 1)\ny_test_edit = np.argmax(y_test , axis = 1)","edb03b41":"# Classification report.\ncf_report = sklearn.metrics.classification_report(y_test_edit, predictions2 )\nprint(cf_report)","30883eef":"cf_matrix = sklearn.metrics.confusion_matrix(y_test_edit, predictions2)\nsns.heatmap(cf_matrix, cmap = 'Blues', linewidth = 1, annot = True, xticklabels=labels, yticklabels=labels)","46599c43":"# Importing the model and initializing.\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nmblnt = MobileNet(weights = 'imagenet',include_top=False,input_shape=(IMAGE_SIZE,IMAGE_SIZE, 3))","23983df7":"# Adding Top Layers.\nmodel3 = mblnt.output\nmodel3 = tf.keras.layers.GlobalAveragePooling2D()(model3)\nmodel3 = tf.keras.layers.Dropout(0.5)(model3)\nmodel3 = tf.keras.layers.Dense(4, activation = 'softmax')(model3)\nmodel3 = tf.keras.models.Model(inputs = mblnt.input, outputs = model3)","7a569e2c":"# Summary of the model.\nmodel3.summary()","5f9a5bac":"# Compiling Model\nmodel3.compile(loss = 'categorical_crossentropy', optimizer ='Adam', metrics=['accuracy'])","2dbd5beb":"# Callbacks.\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\ntensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"mblnt.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,mode='auto',verbose=VERBOSE)","16fc4eda":"# Fitting the model\nhistory3 = model3.fit(x_train, y_train, validation_split=0.1, epochs = 12, verbose =VERBOSE, batch_size=BATCH_SIZE, callbacks=[tensorboard,checkpoint, reduce_lr])","b86b9c5a":"epochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2)\ntrain_acc = history3.history['accuracy']\ntrain_loss = history3.history['loss']\nval_acc = history3.history['val_accuracy']\nval_loss = history3.history['val_loss']\nfig.set_size_inches(14, 7)\n\nax[0].plot(epochs, train_acc, 'go-', label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, 'ro-', label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nax[1].plot(epochs, train_loss, 'g-o', label ='Training Loss')\nax[1].plot(epochs, val_loss, 'r-o', label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\nplt.show()","8f5bf449":"# Evaluating Model.\nresult3=model3.evaluate(x_test, y_test)\nprint(\"Testing Loss :\", result3[0])\nprint(\"Testing Accuracy :\", result3[1]*100, \"%\")","af25b0a2":"predictions3 = model3.predict(x_test)\npredictions3 = np.argmax(predictions3, axis = 1)\ny_test_edit = np.argmax(y_test , axis = 1)","400573f3":"# Classification report.\ncf_report = sklearn.metrics.classification_report(y_test_edit, predictions3 )\nprint(cf_report)","6fa6c227":"cf_matrix = sklearn.metrics.confusion_matrix(y_test_edit, predictions3)\nsns.heatmap(cf_matrix, cmap = 'Blues', linewidth = 1, annot = True, xticklabels=labels, yticklabels=labels)","3a4009b5":"# Importing the model and initializing.\nfrom tensorflow.keras.applications.resnet import ResNet50\nrsnet = ResNet50(weights = 'imagenet',include_top=False,input_shape=(IMAGE_SIZE,IMAGE_SIZE, 3))","af2e463c":"# Adding Top Layers.\nmodel4 = rsnet.output\nmodel4 = tf.keras.layers.GlobalAveragePooling2D()(model4)\nmodel4 = tf.keras.layers.Dropout(0.5)(model4)\nmodel4 = tf.keras.layers.Dense(4, activation = 'softmax')(model4)\nmodel4 = tf.keras.models.Model(inputs = rsnet.input, outputs = model4)","55c96695":"# Summary of the model.\nmodel4.summary()","3656bc69":"# Compiling Model\nmodel4.compile(loss = 'categorical_crossentropy', optimizer ='Adam', metrics=['accuracy'])","2d446835":"# Callbacks.\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\ntensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"rsnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,mode='auto',verbose=VERBOSE)","53b18f94":"# Fitting the model\nhistory4 = model4.fit(x_train, y_train,  validation_split=0.1,epochs = 12,  verbose =VERBOSE, batch_size=BATCH_SIZE, callbacks=[tensorboard,checkpoint, reduce_lr])","f65cb810":"epochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2)\ntrain_acc = history4.history['accuracy']\ntrain_loss = history4.history['loss']\nval_acc = history4.history['val_accuracy']\nval_loss = history4.history['val_loss']\nfig.set_size_inches(20, 10)\n\nax[0].plot(epochs, train_acc, 'go-', label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, 'ro-', label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nax[1].plot(epochs, train_loss, 'g-o', label ='Training Loss')\nax[1].plot(epochs, val_loss, 'r-o', label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\nplt.show()","c1e49aba":"# Evaluating Model.\nresult4=model4.evaluate(x_test, y_test)\nprint(\"Testing Loss :\", result4[0])\nprint(\"Testing Accuracy :\", result4[1]*100, \"%\")","30dab4f0":"predictions4 = model4.predict(x_test)\npredictions4 = np.argmax(predictions4, axis = 1)\ny_test_edit = np.argmax(y_test , axis = 1)","4cdd3b6d":"# Classification report.\ncf_report = sklearn.metrics.classification_report(y_test_edit, predictions4 )\nprint(cf_report)","1c177e0d":"cf_matrix = sklearn.metrics.confusion_matrix(y_test_edit, predictions4)\nsns.heatmap(cf_matrix, cmap = 'Blues', linewidth = 1, annot = True, xticklabels=labels, yticklabels=labels)","745a4eeb":"3.6 Confusion Matrix","3e457ed3":"1.6 Confusion Matrix","fc5191d9":"2.2 Training the model.","1ddf292d":"1.3 Training, Loss vs epoch.","0a2a41b7":"4.4 Model Performance","b23efd70":"# Brain Tumor Classification from MRI","aeb02501":"3.2 Training the model.","861f625a":"4.6 Confusion Matrix","75824169":"Importing the necessary libraries and modules.","8877800b":"3.1 Model Summary.","c2992952":"## 2. MODEL:Xception","cac50282":"1.5 Classification Report.","a82c22d0":"2.3 Training, Loss vs epoch.","9cdc2234":"Encoding the y_train and y_test to numbers and one-hot encoding it.","a6127ad1":"3.3 Training, Loss vs epoch.","95e70060":"4.5 Classification Report.","0841fd2d":"Encoding the y_train and y_test to numbers and one-hot encoding it.","7d1563df":"## 4. MODEL:ResNet50","08dcbc4d":"Reading the dataset.","84c6c8d1":"4.1 Model Summary.","198b22f7":"2.5 Classification Report.","62f6df23":"## 3. MODEL:MobileNet","986b436c":"1.4 Model Performance","17804ec5":"4.2 Training the model.","cb3c9f19":"## 1. MODEL:EfficientNetB0","5003948b":"3.5 Classification Report.","8dfe8c5b":"2.6 Confusion Matrix","c55f24c3":"4.3 Training, Loss vs epoch.","da3c4366":"2.4 Model Performance","c3961de7":"Sample images of each class","034ba6be":"1.1 Model Summary.","68233d25":"2.1 Model Summary.","9ac65561":"1.2 Training the model.","b080b0cc":"3.4 Model Performance"}}