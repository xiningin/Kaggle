{"cell_type":{"e30ae486":"code","d4046f57":"code","ad6786b5":"code","fde13d37":"code","8397b4fe":"code","45c03459":"code","27f12199":"code","60c29fe5":"markdown","816b4e65":"markdown","de419a9e":"markdown","d7837cc9":"markdown","31a9ff6a":"markdown","9739f6fc":"markdown","f46c4fed":"markdown"},"source":{"e30ae486":"import pandas as pd\nfrom pathlib import Path\nimport warnings  \nwarnings.filterwarnings('ignore')\n\ndata_dir = Path('..\/input\/tabular-playground-series-dec-2021\/')\n\ndf_train = pd.read_csv(\n    data_dir \/ \"train.csv\",\n    index_col='Id'\n)\n\nFEATURES = df_train.columns[:-1]\nTARGET = df_train.columns[-1]\n\ndf_train.head()","d4046f57":"from xgboost import XGBClassifier\n\nX = df_train.loc[:, FEATURES]\ny = df_train.loc[:, TARGET]\n\nmodel = XGBClassifier(\n    max_depth=3,\n    subsample=0.5,\n    colsample_bytree=0.5,\n    n_jobs=-1,\n    # Uncomment if you want to use GPU. Recommended for whole training set.\n    tree_method='gpu_hist',\n    random_state=0,\n)","ad6786b5":"from sklearn.model_selection import cross_validate\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndef score(X, y, model, cv):\n    scoring = [\"accuracy\"]\n    scores = cross_validate(\n        model, X, y, scoring=scoring, cv=cv, return_train_score=True\n    )\n    scores = pd.DataFrame(scores).T\n    return scores.assign(\n        mean = lambda x: x.mean(axis=1),\n        std = lambda x: x.std(axis=1),\n    )\n\nscores = score(X, y, model, cv=2)\n\ndisplay(scores)","fde13d37":"# Fit on full training set\nmodel.fit(X, y)\n\nX_test = pd.read_csv(data_dir \/ \"test.csv\", index_col='Id')\n\n# Make predictions\ny_pred = pd.Series(\n    model.predict(X_test),\n    index=X_test.index,\n    name=TARGET,\n)\n\n# Create submission file\ny_pred.to_csv(\"submission_xgboost.csv\")","8397b4fe":"from xgboost import XGBClassifier\n\nX = df_train.loc[:, FEATURES]\ny = df_train.loc[:, TARGET]\n\nmodel_gblinear = XGBClassifier(\n    n_jobs=-1,\n    random_state=0,\n    objective ='reg:squarederror', # WARNING -> reg:linear is now deprecated in favor of reg:squarederror\n    booster='gblinear'\n)","45c03459":"scores = score(X, y, model_gblinear, cv=2)\n\ndisplay(scores)","27f12199":"# Fit on full training set\nmodel_gblinear.fit(X, y)\n\nX_test = pd.read_csv(data_dir \/ \"test.csv\", index_col='Id')\n\n# Make predictions\ny_pred = pd.Series(\n    model_gblinear.predict(X_test),\n    index=X_test.index,\n    name=TARGET,\n)\n\n# Create submission file\ny_pred.to_csv(\"submission_gblinear.csv\")","60c29fe5":"# Evaluation: XGBoost\n\nThe evaluation metric is multi-class classification accuracy.","816b4e65":"# Evaluation: XGBoost Linear\n\nThe evaluation metric is multi-class classification accuracy.","de419a9e":"# Submission: XGBoost Linear","d7837cc9":"# Submission: XGBoost","31a9ff6a":"The target attribute 'Cover_Type' contains 7 types of Forest Cover (1, 2, 3, 4, 5, 6, 7).\n\n# Model: XGBoost\n\nLet's try out a simple XGBoost model. This algorithm can handle missing values. We use XGBClassifier (instead of XGBRegressor, for instance), since this is a classification problem.","9739f6fc":"# Problem Statement\n\nIn this competition, we use cartographic variables to classify forest categories.\n\nThe word 'cartographic' is an adjective which means 'relating to the science or practice of drawing maps'. Example usage: \"he started his own cartographic printing company\".\n\nWe are going to cover the following steps:\n1. Import Libraries\n2. Model: XGBoost\n3. Evaluation: XGBoost\n4. Submission: XGBoost\n5. Model: XGBoost Linear using gblinear\n6. Evaluation: XGBoost Linear\n7. Submission: XGBoost Linear\n\nLet's get started.\n\n# Import Libraries","f46c4fed":"# Model: XGBoost Linear using gblinear"}}