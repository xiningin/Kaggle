{"cell_type":{"38fdb715":"code","a428b4b3":"code","7a760177":"code","ee74b4a9":"code","267ac286":"code","78227438":"code","00f992ec":"code","3ad9b3d6":"code","d1cbf710":"code","e0ee2957":"code","6840aac7":"code","0602e40f":"markdown","c9314b9e":"markdown"},"source":{"38fdb715":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a428b4b3":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('..\/input\/cusersmarildownloadsgermancsv\/german.csv', delimiter=';', encoding = \"ISO-8859-2\", nrows = nRowsRead)\ndf.dataframeName = 'german.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","7a760177":"#Code by Tolga Kurtulus https:\/\/www.kaggle.com\/tolgakurtulus\/comparison-of-lightautoml-h2o-ai-flaml\/notebook\n\n!pip install scikit-learn --upgrade\nfrom sklearn.metrics import mean_squared_error","ee74b4a9":"!pip install -U flaml","267ac286":"from flaml import AutoML","78227438":"\n#Code by Tolga Kurtulus https:\/\/www.kaggle.com\/tolgakurtulus\/comparison-of-lightautoml-h2o-ai-flaml\/notebook\n\n\n#X = train_df.drop(['id', 'loss'], axis=1).values\n#y = train_df['loss'].values\nX = df.drop(['Duration_of_Credit_monthly', 'Creditability'], axis=1).values\ny = df['Creditability'].values\nX_test = df.drop(['Duration_of_Credit_monthly'], axis=1).values\n\n#X_test = test_df.drop(['id'], axis=1).values","00f992ec":"%%time\n\n# Initialize an AutoML instance\nautoml = AutoML()\n\n# Specify automl goal and constraint\nautoml_settings = {\n    \"time_budget\": 1200,\n    \"metric\": 'rmse',\n    \"task\": 'regression',\n    \"seed\": 2021,\n    \"log_file_name\": 'tpsaug21log.log', \n}\n\n# Train with labeled input data\nautoml.fit(X_train=X , y_train=y,\n                        **automl_settings)","3ad9b3d6":"#Code by Tolga Kurtulus https:\/\/www.kaggle.com\/tolgakurtulus\/comparison-of-lightautoml-h2o-ai-flaml\/notebook\n\n# Retrieve best config and best learner\nprint('Best ML leaner:', automl.best_estimator)\nprint('Best hyperparmeter config:', automl.best_config)\nprint('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\nprint('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))","d1cbf710":"%%time\nypred = automl.predict(X_test)","e0ee2957":"ypred","6840aac7":"sample_submission['loss'] = ypred\nsample_submission.to_csv('microsoft_flaml_submission.csv', index=False)","0602e40f":"#That snippet below will take a long time.","c9314b9e":"#Code by Tolga Kurtulus https:\/\/www.kaggle.com\/tolgakurtulus\/comparison-of-lightautoml-h2o-ai-flaml\/notebook"}}