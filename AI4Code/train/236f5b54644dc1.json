{"cell_type":{"e20025a8":"code","ea4ced39":"code","4fe179d9":"code","03a8b5ca":"code","ae5c8970":"code","c7241bf9":"code","fde4ebc2":"code","5941a262":"code","654dbe0e":"code","9abe532d":"code","8359e6b5":"code","7f70a8e9":"code","e5810581":"code","a966e083":"code","1eca476e":"code","9bf77fd3":"code","ae27a105":"code","a408c2ea":"code","4b6641c4":"code","4fbdf415":"code","5669c191":"code","4bae2ef2":"code","8e51a935":"code","085e15cd":"code","5a8f96a5":"code","276d180e":"code","920a0006":"code","82f0c4f9":"code","01744c9d":"code","b338d24a":"code","5496e6c2":"code","5114aa3f":"code","4b24a566":"code","6d03f0e8":"code","3d5e4b00":"code","6411b6f7":"code","9fbdc0f7":"code","8cccf4fd":"code","75e2ef9c":"code","5cf49c8c":"code","d251806f":"code","091022db":"code","09bd84b5":"code","d81cd4f7":"code","c12b7a30":"code","ab08423d":"code","22b7d0de":"code","ef2f2dbe":"code","ee2cf6ed":"code","3622cc14":"code","8dc277db":"code","f2d992bd":"code","087243f6":"code","9e2d1d22":"code","d962790a":"code","e2af22a6":"code","bf76c301":"code","ec52219f":"code","05c04174":"code","ea1a315e":"code","87e7d6ab":"code","9d57a503":"markdown","ffb53b5d":"markdown","8d07573e":"markdown","6798eec2":"markdown","fdda5b3e":"markdown","136577a9":"markdown","84d59973":"markdown","e9ab6049":"markdown","5165941b":"markdown","640bbf01":"markdown","ddadc426":"markdown","a8281a14":"markdown","60083a34":"markdown","c8e172db":"markdown","6e458217":"markdown","5c38f066":"markdown","8fff9985":"markdown","ab31c8b6":"markdown","3a492617":"markdown","6f721661":"markdown","09b92bf0":"markdown","323d63ca":"markdown","3d0f241d":"markdown","16c613ef":"markdown","42b5cae2":"markdown","fc1f6a54":"markdown","5ed89680":"markdown","c3c79b0e":"markdown","1d49bae3":"markdown","3a69fa08":"markdown","1f7dc305":"markdown","7b740f68":"markdown","83df9a3f":"markdown","913673b1":"markdown","c4584ac0":"markdown","e9c1ff64":"markdown","24a1ad4a":"markdown","e858a8f1":"markdown","80eaef2c":"markdown","691b567d":"markdown","6883de72":"markdown","e536eaea":"markdown","9b4bf34a":"markdown","ce0b0f2c":"markdown","acff9a3b":"markdown","2203e7b4":"markdown","590db4a9":"markdown","e3e1c311":"markdown","ec69169d":"markdown","8ee666f6":"markdown","4d764047":"markdown","bb108408":"markdown","9d9c3f66":"markdown","e2246b14":"markdown","37862ab9":"markdown","a4b42a74":"markdown","9583d929":"markdown","993a6347":"markdown","78c70185":"markdown","9025cbbf":"markdown","ee374cc0":"markdown","bf78b27f":"markdown","048b96c1":"markdown","75692afd":"markdown","497ce88b":"markdown","e60ba9de":"markdown","ffe98b5d":"markdown","ef87e670":"markdown","b0155baa":"markdown","17203be8":"markdown","7cdc0ac9":"markdown","c646bb15":"markdown","796bd78b":"markdown","08130e33":"markdown","266ffe29":"markdown","7f783f2d":"markdown","98ec7c7e":"markdown","87a3ee61":"markdown","c077b1f3":"markdown","c123a7ee":"markdown","72cc415f":"markdown","bdc938be":"markdown","245dca84":"markdown","9fbaeaea":"markdown","bcf9bbd9":"markdown","5373f2bd":"markdown","bb8ded99":"markdown"},"source":{"e20025a8":"import pandas as pd\nimport numpy as np\nfrom pandas import read_csv\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\n\nlinkname = '..\/input\/bank-full.csv'\ndataset1 = pd.read_csv(linkname, sep = ';')","ea4ced39":"# View the first 5 rows in the dataset\ndataset1.head()","4fe179d9":"# Step 1: Delete the rows which column 'poutcome' contains 'other'\ncondition = dataset1.poutcome == 'other'\ndataset2 = dataset1.drop(dataset1[condition].index, axis = 0, inplace = False)","03a8b5ca":"# Step 2: Replace 'unknown' in job and education with 'other'\ndataset2[['job','education']] = dataset2[['job','education']].replace(['unknown'],'other')","ae5c8970":"from scipy.stats import zscore\n\ndataset2[['balance']].mean()\ndataset2[['balance']].mean()\n\ndataset2['balance_outliers'] = dataset2['balance']\ndataset2['balance_outliers']= zscore(dataset2['balance_outliers'])\n\ncondition1 = (dataset2['balance_outliers']>3) | (dataset2['balance_outliers']<-3 )\ndataset3 = dataset2.drop(dataset2[condition1].index, axis = 0, inplace = False)","c7241bf9":"dataset4 = dataset3.drop('balance_outliers', axis=1)","fde4ebc2":"# Step 1: Change column name: 'y' to 'response'\ndataset4.rename(index=str, columns={'y': 'response'}, inplace = True)\n\ndef convert(dataset4, new_column, old_column):\n    dataset4[new_column] = dataset4[old_column].apply(lambda x: 0 if x == 'no' else 1)\n    return dataset4[new_column].value_counts()\n\nconvert(dataset4, \"response_binary\", \"response\")","5941a262":"# Step 2: Drop column \"contact\" which is useless\ndataset5 = dataset4.drop('contact', axis=1)","654dbe0e":"# Step 3: Change the unit of 'duration' from seconds to minutes\ndataset5['duration'] = dataset5['duration'].apply(lambda n:n\/60).round(2)","9abe532d":"# Step 4: Change 'month' from words to numbers for easier analysis\nlst = [dataset5]\nfor column in lst:\n    column.loc[column[\"month\"] == \"jan\", \"month_int\"] = 1\n    column.loc[column[\"month\"] == \"feb\", \"month_int\"] = 2\n    column.loc[column[\"month\"] == \"mar\", \"month_int\"] = 3\n    column.loc[column[\"month\"] == \"apr\", \"month_int\"] = 4\n    column.loc[column[\"month\"] == \"may\", \"month_int\"] = 5\n    column.loc[column[\"month\"] == \"jun\", \"month_int\"] = 6\n    column.loc[column[\"month\"] == \"jul\", \"month_int\"] = 7\n    column.loc[column[\"month\"] == \"aug\", \"month_int\"] = 8\n    column.loc[column[\"month\"] == \"sep\", \"month_int\"] = 9\n    column.loc[column[\"month\"] == \"oct\", \"month_int\"] = 10\n    column.loc[column[\"month\"] == \"nov\", \"month_int\"] = 11\n    column.loc[column[\"month\"] == \"dec\", \"month_int\"] = 12","8359e6b5":"# Step 1: Drop rows that 'duration' < 5s\ncondition2 = (dataset5['duration']<5\/60)\ndataset6 = dataset5.drop(dataset5[condition2].index, axis = 0, inplace = False)","7f70a8e9":"# Step 2: Drop customer values with 'other' education\ncondition3 = (dataset6['education'] == 'other')\ndataset7 = dataset6.drop(dataset6[condition3].index, axis = 0, inplace = False)","e5810581":"dist_age_balance = plt.figure(figsize = (10,6))\n\nra1 = dist_age_balance.add_subplot(1,2,1) \nra2 = dist_age_balance.add_subplot(1,2,2)\n\nra1.hist(dataset7['age'])\nra1.set_title('The Distribution of Age')\n\nra2.hist(dataset7['balance'], color = 'skyblue')\nra2.set_title('The Distribution of Balance')\n\nplt.tight_layout() \nplt.show()","a966e083":"scatter_age_balance = dataset7.plot.scatter('age','balance',figsize = (7,5))\n\nplt.title('The Relationship between Age and Balance ')\nplt.show()","1eca476e":"dist_dur_cam = dataset7[['duration','campaign']].plot(kind = 'box', \n                                                      figsize = (8,8),\n                                                      subplots = True, layout = (1,2),\n                                                      sharex = False, sharey = False,\n                                                      title='The Distribution of Duration and Campaign')\nplt.show()","9bf77fd3":"import seaborn as sns\ndur_cam = sns.lmplot(x='duration', y='campaign',data = dataset7,\n                     hue = 'response',\n                     fit_reg = False,\n                     scatter_kws={'alpha':0.6}, height =7)\n\nplt.axis([0,65,0,65])\nplt.ylabel('Number of Calls')\nplt.xlabel('Duration of Calls (Minutes)')\nplt.title('The Relationship between the Number and Duration of Calls (with Response Result)')\n\n# Annotation\nplt.axhline(y=5, linewidth=2, color=\"k\", linestyle='--')\nplt.annotate('Higher subscription rate when calls <5',xytext = (35,13),\n             arrowprops=dict(color = 'k', width=1),xy=(30,6))\nplt.show()","ae27a105":"from pandas.plotting import scatter_matrix\nmatrix = scatter_matrix(dataset7[['age','balance','duration','campaign']],figsize=(10,8))\n\nplt.suptitle('The Scatter Matrix of Age, Balance, Duration and Campaign')\nplt.show()","a408c2ea":"corr_data = dataset7[['age','balance','duration','campaign','month_int','previous','response_binary']]\ncorr = corr_data.corr()\n\ncor_plot = sns.heatmap(corr,annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':10})\nfig=plt.gcf()\nfig.set_size_inches(6,5)\nplt.xticks(fontsize=10,rotation=-30)\nplt.yticks(fontsize=10)\nplt.title('Correlation Matrix')\nplt.show()","4b6641c4":"lst = [dataset7]\nfor column in lst:\n    column.loc[column[\"age\"] < 30,  'age_group'] = 20\n    column.loc[(column[\"age\"] >= 30) & (column[\"age\"] <= 39), 'age_group'] = 30\n    column.loc[(column[\"age\"] >= 40) & (column[\"age\"] <= 49), 'age_group'] = 40\n    column.loc[(column[\"age\"] >= 50) & (column[\"age\"] <= 59), 'age_group'] = 50\n    column.loc[column[\"age\"] >= 60, 'age_group'] = 60","4fbdf415":"count_age_response_pct = pd.crosstab(dataset7['response'],dataset7['age_group']).apply(lambda x: x\/x.sum() * 100)\ncount_age_response_pct = count_age_response_pct.transpose() ","5669c191":"age = pd.DataFrame(dataset7['age_group'].value_counts())\nage['% Contacted'] = age['age_group']*100\/age['age_group'].sum()\nage['% Subscription'] = count_age_response_pct['yes']\nage.drop('age_group',axis = 1,inplace = True)\n\nage['age'] = [30,40,50,20,60]\nage = age.sort_values('age',ascending = True)","4bae2ef2":"plot_age = age[['% Subscription','% Contacted']].plot(kind = 'bar',\n                                              figsize=(8,6), color = ('green','red'))\nplt.xlabel('Age Group')\nplt.ylabel('Subscription Rate')\nplt.xticks(np.arange(5), ('<30', '30-39', '40-49', '50-59', '60+'),rotation = 'horizontal')\nplt.title('Subscription vs. Contact Rate by Age')\nplt.show()","8e51a935":"lst = [dataset7]\nfor column in lst:\n    column.loc[column[\"balance\"] <= 0,  'balance_group'] = 'no balance'\n    column.loc[(column[\"balance\"] > 0) & (column[\"balance\"] <= 1000), 'balance_group'] = 'low balance'\n    column.loc[(column[\"balance\"] > 1000) & (column[\"balance\"] <= 5000), 'balance_group'] = 'average balance'\n    column.loc[(column[\"balance\"] > 5000), 'balance_group'] = 'high balance'","085e15cd":"count_balance_response_pct = pd.crosstab(dataset7['response'],dataset7['balance_group']).apply(lambda x: x\/x.sum() * 100)\ncount_balance_response_pct = count_balance_response_pct.transpose()","5a8f96a5":"bal = pd.DataFrame(dataset7['balance_group'].value_counts())\nbal['% Contacted'] = bal['balance_group']*100\/bal['balance_group'].sum()\nbal['% Subscription'] = count_balance_response_pct['yes']\nbal.drop('balance_group',axis = 1,inplace = True)\n\nbal['bal'] = [1,2,0,3]\nbal = bal.sort_values('bal',ascending = True)","276d180e":"plot_balance = bal[['% Subscription','% Contacted']].plot(kind = 'bar',\n                                               color = ('royalblue','skyblue'),\n                                               figsize = (8,6))\n\nplt.title('Subscription vs Contact Rate by Balance Level')\nplt.ylabel('Subscription Rate')\nplt.xlabel('Balance Category')\nplt.xticks(rotation = 'horizontal')\n\n# label the bar\nfor rec, label in zip(plot_balance.patches,\n                      bal['% Subscription'].round(1).astype(str)):\n    plot_balance.text(rec.get_x() + rec.get_width()\/2, \n                      rec.get_height() + 1, \n                      label+'%',  \n                      ha = 'center', \n                      color = 'black')","920a0006":"age_balance1 = pd.DataFrame(dataset7.groupby(['age_group','balance_group'])['response_binary'].sum())\nage_balance2 = pd.DataFrame(dataset7.groupby(['age_group','balance_group'])['response'].count())\n\nage_balance1['response'] = age_balance2['response']\nage_balance1['response_rate'] = age_balance1['response_binary']\/ (age_balance1['response'])\nage_balance1 = age_balance1.drop(['response_binary','response'],axis =1)\n\nage_balance1 = age_balance1.unstack()","82f0c4f9":"age_bal = age_balance1.plot(kind='bar',figsize = (10,6))\n\n# Set x ticks\nplt.xticks(np.arange(5),('<30', '30-39', '40-49', '50-59', '60+'),rotation = 'horizontal')\n\n# Set legend\nplt.legend(['Average Balance','High Balance','Low Balance','No Balance'],loc = 'best',ncol = 1)\n\nplt.ylabel('Subscription Rate')\nplt.xlabel('Age Group')\nplt.title('The Subscription Rate of Different Balance Levels in Each Age Group')\nplt.show()","01744c9d":"count_job_response_pct = pd.crosstab(dataset7['response'],dataset7['job']).apply(lambda x: x\/x.sum() * 100)\ncount_job_response_pct = count_job_response_pct.transpose()","b338d24a":"plot_job = count_job_response_pct['yes'].sort_values(ascending = True).plot(kind ='barh',\n                                                                           figsize = (12,6))\n                                                                               \nplt.title('Subscription Rate by Job')\nplt.xlabel('Subscription Rate')\nplt.ylabel('Job Category')\n\n# Label each bar\nfor rec, label in zip(plot_job.patches,\n                      count_job_response_pct['yes'].sort_values(ascending = True).round(1).astype(str)):\n    plot_job.text(rec.get_width()+0.8, \n                  rec.get_y()+ rec.get_height()-0.5, \n                  label+'%', \n                  ha = 'center', \n                  va='bottom')","5496e6c2":"count_month_response_pct = pd.crosstab(dataset7['response'],dataset7['month_int']).apply(lambda x: x\/x.sum() * 100)\ncount_month_response_pct = count_month_response_pct.transpose()","5114aa3f":"month = pd.DataFrame(dataset7['month_int'].value_counts())\nmonth['% Contacted'] = month['month_int']*100\/month['month_int'].sum()\nmonth['% Subscription'] = count_month_response_pct['yes']\nmonth.drop('month_int',axis = 1,inplace = True)\n\nmonth['Month'] = [5,7,8,6,11,4,2,1,10,9,3,12]\nmonth = month.sort_values('Month',ascending = True)","4b24a566":"plot_month = month[['% Subscription','% Contacted']].plot(kind ='line',\n                                                          figsize = (10,6),\n                                                          marker = 'o')\n\nplt.title('Subscription vs. Contact Rate by Month')\nplt.ylabel('Subscription and Contact Rate')\nplt.xlabel('Month')\n\nticks = np.arange(1,13,1)\nplt.xticks(ticks)\n\n# Annotation: peak of contact\ny = month['% Contacted'].max()\nx = month['% Contacted'].idxmax()\nplt.annotate('May: Peak of contact', xy=(x+0.1, y+0.1), xytext=(x+1,y+4), arrowprops=dict(facecolor='black', headwidth=6, width=1, headlength=4), horizontalalignment='left', verticalalignment='top')\n\n# Annotation: peak of subscription rate\ny = month['% Subscription'].max()\nx = month['% Subscription'].idxmax()\nplt.annotate('March: Peak Subscription rate', xy=(x+0.1, y+0.1), xytext=(x+1,y+1), arrowprops=dict(facecolor='black', headwidth=6, width=1, headlength=4), horizontalalignment='left', verticalalignment='top')\n\nplt.show()","6d03f0e8":"linkname = '..\/input\/bank_cleaned.csv'\ndataset = read_csv(linkname)\ndataset = dataset.drop(['Unnamed: 0'], axis=1)","3d5e4b00":"# View the first 5 rows of cleaned data\ndataset.head()","6411b6f7":"dataset.drop(['marital'],axis=1, inplace=True)\ndataset1 = dataset.iloc[:, 0:7]","9fbdc0f7":"dataset2 = pd.get_dummies(dataset1, columns = ['job'])\ndataset2 = pd.get_dummies(dataset2, columns = ['education'])\ndataset2['housing'] = dataset2['housing'].map({'yes': 1, 'no': 0})\ndataset2['default'] = dataset2['default'].map({'yes': 1, 'no': 0})\ndataset2['loan'] = dataset2['loan'].map({'yes': 1, 'no': 0})\ndataset_response = pd.DataFrame(dataset['response_binary'])\ndataset2 = pd.merge(dataset2, dataset_response, left_index = True, right_index = True)","8cccf4fd":"array = dataset2.values\n\n# Features: first 20 columns\nX = array[:,0:-1]\n\n# Target variable: 'response_binary'\nY = array[:,-1]","75e2ef9c":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score","5cf49c8c":"# 20% of the data will be used for testing\ntest_size= 0.20\nseed = 7\nX_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size=test_size, random_state=seed)","d251806f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB","091022db":"models = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))","09bd84b5":"results_c = []\nnames_c = []\n\nfor name, model in models:\n    # define how to split off validation data ('kfold' how many folds)\n    kfold = KFold(n_splits=10, random_state=seed)    \n    # train the model\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')    \n    results_c.append(cv_results)\n    names_c.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","d81cd4f7":"fig = plt.figure()\nfig.suptitle('Perfomance of Classification Algorithms')\nax = fig.add_subplot(111)\nplt.boxplot(results_c)\nax.set_xticklabels(names_c)\nplt.show()","c12b7a30":"LR = LogisticRegression()\nLR.fit(X_train, Y_train)","ab08423d":"predictions = LR.predict(X_test)","22b7d0de":"# Accuracy Score \nprint(accuracy_score(Y_test, predictions))","ef2f2dbe":"# Confusion Matrix \nfrom sklearn.metrics import confusion_matrix\nimport pylab as pl\n\nprint(confusion_matrix(Y_test, predictions))\n\ncm = confusion_matrix(Y_test, predictions)\npl.matshow(cm)\npl.title('Confusion matrix of the classifier')\npl.colorbar()\npl.show()","ee2cf6ed":"# Classification Report\nfrom sklearn.metrics import classification_report\nprint(classification_report(Y_test, predictions))","3622cc14":"dataset4 = dataset2.drop(['response_binary'],axis = 1)\ndataset4['duration'] = dataset['duration']","8dc277db":"array = dataset4.values\nX = array[:,0:20]\nY = array[:,20]","f2d992bd":"test_size= 0.20\nseed = 10\nX_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size=test_size, random_state=seed)","087243f6":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor","9e2d1d22":"models = []\nmodels.append(('LR', LinearRegression()))\nmodels.append(('LASSO', Lasso()))\nmodels.append(('RIDGE', Ridge()))\nmodels.append(('EN', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))","d962790a":"results_e2 = []\nnames_e2 = []\n\nfor name, model in models:\n    # define how to split off validation data\n    kfold = KFold(n_splits=10, random_state=seed)\n    \n    # train the model\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='neg_mean_squared_error')\n    results_e2.append(cv_results)\n    names_e2.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","e2af22a6":"# Plot results\nfig = plt.figure(figsize=(9,6))\nax = fig.add_subplot(111)\nplt.boxplot(results_e2)\n\nfig.suptitle('Algorithm Comparison')\nax.set_xticklabels(names_e2)\nplt.show()","bf76c301":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\npipelines = []\npipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LinearRegression())])))\npipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\npipelines.append(('ScaledRIDGE', Pipeline([('Scaler', StandardScaler()),('RIDGE', Ridge())])))\npipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\npipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\npipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))","ec52219f":"results_e2_normalized = []\nnames_e2_normalized = []\n\nfor name, model in pipelines:\n    # define how to split off validation data\n    kfold = KFold(n_splits=10, random_state=seed)\n    \n    # train the model\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='neg_mean_squared_error')\n    results_e2_normalized.append(cv_results)\n    names_e2_normalized.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","05c04174":"# Plot results\nfig = plt.figure(figsize=(9,6))\nax = fig.add_subplot(111)\nplt.boxplot(results_e2_normalized)\n\nfig.suptitle('Algorithm Comparison')\nax.set_xticklabels(names_e2_normalized)\nplt.show()","ea1a315e":"ridge = Ridge()\nridge.fit(X_train, Y_train)\npredicted_y = ridge.predict(X_test)","87e7d6ab":"from sklearn.metrics import mean_squared_error\nprint('The MSE is', mean_squared_error(Y_test, predicted_y))","9d57a503":"# Part 3. Exploratory Data Analysis <a id=\"3\"><\/a>","ffb53b5d":"### 2.4 Filtering","8d07573e":"## Compare regression algorithms","6798eec2":"To obtain a better understanding of the dataset, the distribution of key variables and the relationships among them were plotted.","fdda5b3e":"### 6.2 Train\/ test split","136577a9":"## Recommendations\n\n**1. More appropriate timing**\n\nWhen implementing a marketing strategy, external factors, such as the time of calling, should also be carefully considered. The previous analysis points out that March, September, October and December had the highest success rates. Nevertheless, more data should be collected and analyzed to make sure that this seasonal effect is constant over time. If the trend has the potential to continue in the future, the bank should consider initiating its telemarketing campaign in fall and spring. \n\n**2. Smarter marketing design**\n\nBy targeting the right customers, the bank will have more and more positive responses, and the classification algorithms would ultimately eliminate the imbalance in the original dataset. Hence, more accurate information will be presented to the bank for improving the subscriptions. Meanwhile, to increase the likelihood of subscription, the bank should re-evaluate the content and design of its current campaign, making it more appealing to its target customers. \n\n**3. Better services provision**\n\nWith a more granular understanding of its customer base, the bank has the ability to provide better banking services.\nFor example, marital status and occupation reveal a customer's life stage while loan status indicates his\/her overall risk profile. With this information, the bank can estimate when a customer might need to make an investment. In this way, the bank can better satisfy its customer demand by providing banking services for the right customer at the right time.","84d59973":"Accuracy score is the percentage of correct predictions out of all predictions made. The LR algorithm achieves an accuracy of 89.08%, suggesting high level of strength of this model to classify the customer response given all the defined customer features. ","e9ab6049":"**Logistic regression is the best performing model.**\n\nAmong all algorithms, logistic regression achieved an accuracy of about 88%, suggesting a high level of strength of this model to classify the customer response given all the defined customer features. ","5165941b":"With a sound knowledge of the distribution of key variables, further analysis of each customer characteristic can be carried out to investigate its influence on the subscription rate. ","640bbf01":"**Insights: initiate the telemarketing campaign in fall or spring**\n\nBesides customer characteristics, external factors may also have an impact on the subscription rate, such as seasons and the time of calling. So the month of contact is also analyzed here.  \n\nThis line chart displays the bank\u2019s contact rate in each month as well as clients\u2019 response rate in each month. One way to evaluate the effectiveness of the bank's marketing plan is to see whether these two lines have a similar trend over the same time horizon.\n* The bank **contacted most clients between May and August**. The highest contact rate is around 30%, which happened in May, while the contact rate is closer to 0 in March, September, October, and December. \n\n\n* However, the subscription rate showed a different trend. **The highest subscription rate occurred in March**, which is over 50%, and all subscription rates in **September, October, and December** are over 40%. \n\nClearly, **these two lines move in different directions which strongly indicates the inappropriate timing of the bank\u2019s marketing campaign**. To improve the marketing campaign, the bank should consider initiating the telemarketing campaign in fall and spring when the subscription rate tends to be higher.\n\nNevertheless, the bank should be cautious when analyzing external factors. More data from previous marketing campaign should be collected and analyzed to make sure that this seasonal effect is constant over time and applicable to the future. \n","ddadc426":"### 2.1 Deal with missing data","a8281a14":"**The distribution of duration**: As observed from the box plot, the duration of contact has a median of 3 minutes, with an interquartile range of 1.73 minutes to 5.3 minutes. The left-skewed boxplot indicates that most calls are relatively short. Also, there is a large number of outliers ranging from 10 minutes to 40 minutes, which are worth further study.","60083a34":"## Evalute LR Model","c8e172db":"# Part 4. Data Visualization <a id=\"4\"><\/a>","6e458217":"# Table of Contents\n\n1. **[Project Background](#1)**\n2. **[Data Cleaning](#2)**\n3. **[Exploratory Data Analysis](#3)**\n4. **[Data Visualization](#4)**\n5. **[Machine Learning: Classification](#5)**\n6. **[Machine Learning: Regression](#6)**\n7. **[Conclusion & Recommendations](#7)**","5c38f066":"**The distribution of campagin**: About half of the clients have been contacted by the bank for the second time, while 25% was first introduced to the term deposit. Most clients have been reached by the bank for one to three times, which is reasonable. However, some clients have been contacted by as high as 58 times, which is not normal. These clients may have some special needs that require frequent contact. ","8fff9985":"The values of the first 20 columns, which contain customer statistics, are selected as features while the value of the last column, 'campaign outcome', is set as target. ","ab31c8b6":"![ma](http:\/\/algolytics.com\/wp-content\/uploads\/2018\/08\/Classification_model_construction.png)","3a492617":"**Insights: target clients with average or high balance** \n\nTo identify the trend more easily, clients are categorized into four groups based on their levels of balance: \n* No Balance: clients with a negative balance.\n* Low Balance: clients with a balance between 0 and 1000 euros\n* Average Balance: clients with a balance between 1000 and 5000 euros.\n* High Balance: clients with a balance greater than 5000 euros.\n\n\nUnsurprisingly, this bar chart indicates a positive correlation between clients\u2019 balance levels and subscription rate. Clients with negative balances only returned a subscription rate of 6.9% while clients with average or high balances had significantly higher subscription rates, nearly 15%. \n\nHowever, in this campaign, more than 50% of clients contacted only have a low balance level. In the future, the bank should shift its marketing focus to high-balance customers to secure more term deposits. ","6f721661":"**However, the result of accuracy score can possibly yield misleading result if the data set is unbalanced, because the number of observations in different classes largely vary.**\n\nA confusion matrix gives a detailed breakdown of prediction result and error types. Each cell in the matrix represents a combination of instances of the predicted response and the actual response. In the test set, the matrix proves that the algorithm performed well because most test results (7277 True Positive predictions) locate on the diagonal cells which represent correct predictions. 891 tests (False negative) predicted the bank\u2019s client would subscribe to the term deposit but they actually did not. \n\n**A problem revealed by this confusion matrix is that the dataset is highly unbalanced, with nearly all client actually decline to subscribe.** This infers that the accuracy score is biased, and further evaluation should be carried out to determine the accuracy of logistic regression model.","09b92bf0":"![qa](http:\/\/www.zenergylabz.com\/wp-content\/uploads\/2015\/05\/ecommerce-strategy-header-animate.gif)","323d63ca":"### 5.1 Select variables relevant to customers","3d0f241d":"## Compare classification algorithms","16c613ef":"The scatter matrix does not reveal any clear relationship among age, balance, duration and campaign. \n\nTo investigate more about correlation, a correlation matrix was plotted with all qualitative variables. Clearly, \u201ccampaign outcome\u201d has a strong correlation with \u201cduration\u201d, a moderate correlation with \u201cprevious contacts\u201d, and mild correlations between \u201cbalance\u201d, \u201cmonth of contact\u201d and \u201cnumber of campaign\u201d. Their influences on campaign outcome will be investigated further in the machine learning part.","42b5cae2":"### 4.2 Visualize the subscription rate by balance level","fc1f6a54":"Only the most relevant customer information is considered, which includes job title, education, age, balance, default record, housing record and loan record. Other information, such as \u2018the number of contacts performed before this campaign\u2019, is omitted because it is not directly related to customers themselves.","5ed89680":"### 4.3 Visualize the subscription rate by age and balance","c3c79b0e":"Classification report shows the precision, recall, F1 and support scores for the LR classification model. \n* Precision of 0 (the client said no) represents that for all instances predicted as no subscription, the percentage of clients that actually said no is 89%. \n* Recall is the ability of a classifier to find all positive instances. Recall of 0 indicates that for all clients that actually said no, the model predicts 100% correctly that they would decline the offer. \n\nIn general, the report shows that **LR model has great predictive power to identify the customers who would not subscribe to the term deposit**. However, because of the limited number of clients accepting the term deposit, there is a **need for stratified sampling or rebalancing to deal with this structural weakness** before we conclude whether LR algorithm can accurately classify those who are more likely to subscribe.","1d49bae3":"Six different regression algorithms (Linear Regression, Lasso, Ridge, ElasticNet, K Neighbors and Decision Tree) are run on the dataset and the best-performing one will be used to build the estimation model.  ","3a69fa08":"Four different classification algorithms (Logistic Regression, K-Neighbors Classifier, Decision Tree Classifier, and Gaussian NB) are run on the dataset and the best-performing one will be used to build the classification model.  ","1f7dc305":"![qwe](https:\/\/media3.giphy.com\/media\/l378c04F2fjeZ7vH2\/giphy.gif)","7b740f68":"### 4.4 Visualize the subscription rate by job","83df9a3f":"Some changes were made to the column name, units and data types for easier analysis.","913673b1":"## Load the raw data","c4584ac0":"### 5.3 Feature selection","e9c1ff64":"# Part 6. Machine Learning: Regression","24a1ad4a":"**After standardization, ridge regression is still the best-performing model.**","e858a8f1":"### 3.1 Visualize the distribution of 'age' and 'balance'","80eaef2c":"## Stardardize Data","691b567d":"### 3.2 Visualize the relationship between 'age' and 'balance' ","6883de72":"<img src='https:\/\/static.wixstatic.com\/media\/e42cce_756b090fe40548eda9148fd5599980bb~mv2.gif' width='450'>","e536eaea":"**The distribution of age**: In its telemarketing campaigns, clients called by the bank have an extensive age range, from 18 to 95 years old. However, a majority of customers called is in the age of 30s and 40s (33 to 48 years old fall within the 25th to 75th percentiles). The distribution of customer age is fairly normal with a small standard deviation.","9b4bf34a":"In order to capture the general trend in the dataset, outliers in the column \u201cbalance\u201d are dropped. Outliers are defined as the values which are more than three standard deviations away from the mean.\nIn sum, 2556 rows of data were removed.","ce0b0f2c":"There are 41,188 observations in this dataset. Each represents an existing customer that the bank reached via phone calls. \n* For each observation, the dataset records **16 input variables** that stand for both qualitative and quantitative attributes of the customer, such as age, job, housing and personal loan status, account balance, and the number of contacts. \n* There is **a single binary output variable** that denotes \u201cyes\u201d or \u201cno\u201d revealing the outcomes of the phone calls.","acff9a3b":"Based on this scatter plot, there is no clear relationship between client\u2019s age and balance level. \n\nNevertheless, over the age of 60, clients tend to have a significantly lower balance, mostly under 5,000 euros. This is due to the fact that most people retire after 60 and no longer have a reliable income source.","2203e7b4":"### 6.1 Feature selection","590db4a9":"# Part 5. Machine Learning: Classification","e3e1c311":"## Load the cleaned dataset","ec69169d":"<img src='https:\/\/sendiancreations.com\/wp-content\/uploads\/2018\/05\/opening.gif' width='450'>","8ee666f6":"### 3.3 Visualize the distribution of 'duration' & 'campaign'","4d764047":"### 5.4 Train\/ test split","bb108408":"### Main Objective: increase the effectiveness of the bank's telemarketing campaign\nThis project will enable the bank to develop a more granular understanding of its customer base, predict customers' response to its telemarketing campaign and establish a target customer profile for future marketing plans. \n\nBy analyzing customer features, such as demographics and transaction history, the bank will be able to predict customer saving behaviours and identify which type of customers is more likely to make term deposits. The bank can then focus its marketing efforts on those customers. This will not only allow the bank to secure deposits more effectively but also increase customer satisfaction by reducing undesirable advertisements for certain customers. ","9d9c3f66":"Regression analysis is carried out to complement the classification result and help the bank better predict campaign outcome based on customer statistics.\n\nSince the duration of a phone call is positively correlated with the campaign outcome, it can serve as another indicator of the possibility of subscription. In this part, regression algorithms will be used to estimate the duration of a phone call, helping the bank better predict subscription rate.","e2246b14":"Nowadays, marketing spending in the banking industry is massive, meaning that it is essential for banks to optimize marketing strategies and improve effectiveness. Understanding customers\u2019 need leads to more effective marketing plans, smarter product designs and greater customer satisfaction.","37862ab9":"## Prepare Data for Regression","a4b42a74":"**Insights: target older clients with high balance levels**\n\nWhile age represents a person\u2019s life stage and balance represents a person\u2019s financial condition, jointly evaluating the impact of these two factors enables us to investigate if there is a common trend across all ages, and to identify which combination of client features indicates the highest likelihood of subscription. \n\nIn order to investigate the combined effect of age and balance on a client\u2019s decision, we performed a two-layer grouping, segmenting customers according to their balance levels within each age group.\n\n* The graph tells the same story regarding the subscription rate for different age groups: **the willingness to subscribe is exceptionally high for people aged above 60 and younger people aged below 30** also have a distinguishable higher subscription rate than those of other age groups. \n\n\n* Furthermore, **the effect of balance levels on subscription decision is applicable to each individual age group**: every age group shares a common trend that the percentage of subscription increases with balance. \n\nIn sum, the bank should **prioritize its telemarketing to clients who are above 60 years old and have positive balances**, because they have the highest acceptance rate of about 35%. The next group the bank should focus on is **young clients with positive balances**, who showed high subscription rates between 15% and 20%.","9583d929":"## Evaluate RIDGE Model ","993a6347":"In this scatter plot, clients subscribed to term deposits are denoted as \"yes\" while those did not are denoted as \"no\".\n\nAs we can see from the plot, \u201cyes\u201d clients and \u201cno\u201d clients are forming two relatively separate clusters. Compared to \u201cno\u201d clients\u201d, \u201cyes\u201d clients were contacted by fewer times and had longer call duration. More importantly, after five campaign calls, clients are more likely to reject the term deposit unless the duration is high. Most \u201cyes\u201d clients were approached by less than 10 times. \n\nThis suggests that the bank should resist calling a client for more than five times, which can be disturbing and increase dissatisfaction.","78c70185":"### 2.3 Creating and transforming data","9025cbbf":"<img src='https:\/\/www.agencialorean.com.br\/manager\/imagens\/eXsbcBpleqH9XIAytQK1OgOQUSs3Iuo6NruNtVKbZ6Ly6NGtmt_organic.jpg' width='500'>","ee374cc0":"**The main objective of this project is to increase the effectiveness of the bank's telemarketing campaign, which was successfully met through data analysis,  visualization and analytical model building. A target customer profile was  established while classification and regression models were built to predict customers' response to the term deposit campaign.**\n\n## Conclusion:\n\nAccording to previous analysis, a target customer profile can be established. The most responsive customers possess these features:\n* Feature 1: age < 30 or age > 60\n* Feature 2: students or retired people\n* Feature 3: a balance of more than 5000 euros\n\nBy applying logistic and ridge regression algorithms, classification and estimation model were successfully built. With these two models, the bank will be able to predict a customer's response to its telemarketing campaign before calling this customer. In this way, the bank can allocate more marketing efforts to the clients who are classified as highly likely to accept term deposits, and call less to those who are unlikely to make term deposits.\n\nIn addition, predicting duration before calling and adjusting marketing plan benefit both the bank and its clients. On the one hand, it will increase the efficiency of the bank\u2019s telemarketing campaign, saving time and efforts. On the other hand, it prevents some clients from receiving undesirable advertisements, raising customer satisfaction. With the aid of logistic and ridge regression models, the bank can enter a virtuous cycle of effective marketing, more investments and happier customers.","bf78b27f":"**Ridge regression slightly outperforms other models.**","048b96c1":"**Insights: target students and retired clients**\n\nAs noted from the horizontal bar chart, students and retired clients account for more than 50% of subscription, which is consistent with the previous finding of higher subscription rates among the younger and older. ","75692afd":"# Part 2. Data Cleaning <a id=\"2\"><\/a>","497ce88b":"# Part 7. Conclusion & Recommendations","e60ba9de":"Digital images retrieved from:\n\n* https:\/\/www.geeksforgeeks.org\/data-preprocessing-machine-learning-python\/\n* https:\/\/www.jejurtv.com\/blank-6\n* https:\/\/giphy.com\/gifs\/animation-animated-l378c04F2fjeZ7vH2\n* http:\/\/algolytics.com\/tutorial-how-to-determine-the-quality-and-correctness-of-classification-models-part-1-introduction\/\n* https:\/\/www.zenergylabz.com\/whatwecando\/strategize\n* https:\/\/sendiancreations.com\/our-marketing-services\/best-motion-graphics\/opening\/\n* https:\/\/www.agencialorean.com.br\/conteudos\/ineficaz-organico","ffe98b5d":"**Insights: target the youngest and the oldest instead of the middle-aged**\n\nGreen vertical bars indicate that clients with a age of 60+ have the highest subscription rate. About 17% of the subscriptions came from the clients aged between 18 to 29. More than 50% of the subscriptions are contributed by the youngest and the eldest clients. \n\n* It is not surprising to see such a pattern because the main investment objective of older people is saving for retirement while the middle-aged group tend to be more aggressive with a main objective of generating high investment income. Term deposits, as the least risky investment tool, are more preferable to the eldest. \n\n\n* The youngest may not have enough money or professional knowledge to engage in sophisticated investments, such as stocks and mutual funds. Term deposits provide liquidity and generate interest incomes that are higher than the regular saving account, so term deposits are ideal investments for students.\n\nHowever, red vertical bars show that the bank focused its marketing efforts on the middle-aged group, which returned lower subscription rates than the younger and older groups. Thus, to make the marketing campaign more effective, the bank should target younger and older clients in the future. ","ef87e670":"## Test RIDGE model on the test set","b0155baa":"# <center> Portuguese Bank Telemarketing Analytics","17203be8":"### 4.5 Visualize the subscription and contact rate by month","7cdc0ac9":"The main objective of this project is to identify the most responsive customers before the marketing campaign so that the bank will be able to efficiently reach out to them, saving time and marketing resources. To achieve this objective, classification algorithms will be employed. By analyzing customer statistics, a classification model will be built to classify all clients into two groups: \"yes\" to term deposits and \"no\" to term deposits.","c646bb15":"## Prepare Data for Classification","796bd78b":"According to the previous analysis, observations on duration are extremely varied from 0.1 to 81.97 minutes in this dataset. Therefore, a 17.78 MSE testifies that ridge regression is a sound model in predicting the target variable and suggest that the bank can roughly estimate the duration of campaign calls of each client using their customer profiles such as age, job, and loans.","08130e33":"![clean](https:\/\/www.geeksforgeeks.org\/wp-content\/uploads\/ml.png)","266ffe29":"**The distribution of balance**: After dropping outliers in balance, the range of balance is still massive, from a minimum of -6847 to a maximum of 10443 euros, giving a range of 17290 euros. The distribution of balance has a huge standard deviation relative to the mean, suggesting large variabilities in customers' balance levels. ","7f783f2d":"## Test LR model on the test set","98ec7c7e":"### 3.4 Visualize the relationship between 'duration' & 'campaign': with response result ","87a3ee61":"This dataset is about the direct phone call marketing campaigns, which aim to promote term deposits among existing customers, by a Portuguese banking institution from May 2008 to November 2010. It is publicly available in the UCI Machine learning Repository, which can be retrieved from http:\/\/archive.ics.uci.edu\/ml\/datasets\/Bank+Marketing#.","c077b1f3":"The values of the first 19 columns, which contain customer statistics, are selected as features while the value of the last column, 'duration', is set as target. ","c123a7ee":"### 5.2 Tranform categorical data into dummy variables","72cc415f":"# Part 1. Project Background","bdc938be":"Since machine learning algorithms only take numerical values, all five categorical variables (job, education, default, housing and loan) are transformed into dummy variables.\n\nDummy variables were used instead of continuous integers because these categorical variables are not ordinal. They simply represent different types rather than levels, so dummy variables are ideal to distinguish the effect of different categories. ","245dca84":"There is no missing value in this dataset. Nevertheless, there are values like \u201cunknown\u201d, \u201cothers\u201d, which are helpless just like missing values. Thus, these ambiguous values are removed from the dataset. ","9fbaeaea":"### 2.2 Drop outliers in the column 'balance'","bcf9bbd9":"### 4.1 Visualize the subscription and contact rate by age","5373f2bd":"## Clean the dataset","bb8ded99":"### 3.5 Scatter matrix and Correlation matrix"}}