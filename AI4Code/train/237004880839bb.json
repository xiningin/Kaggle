{"cell_type":{"b8248184":"code","6984eb2b":"code","2d366af5":"code","b0292848":"code","ca8cd448":"code","99bbb260":"code","ce51ead3":"code","ece46da0":"code","4fd730ce":"code","46bb1c7b":"code","c0a77d98":"code","4e059d7f":"code","a7dc9128":"code","ff45b96d":"code","86154399":"code","f6517a88":"code","bffbf3a1":"code","2c378b2b":"code","37dd2f54":"code","f4429309":"code","527f5c5b":"code","04836b16":"code","7f4e4539":"code","214f845f":"code","3f01028f":"code","e6fef84a":"code","c926113c":"code","b34d4228":"code","69a54651":"code","110de60e":"code","e811bebd":"code","33afe48e":"code","f72d9380":"code","f4a459f4":"code","4c864d31":"code","a40941b9":"code","e359907c":"code","88efc489":"code","f1f11690":"code","67f6df52":"code","5dedf41a":"code","042d7284":"code","2a5cb63e":"code","8e4f597d":"code","138e9336":"code","30da6130":"code","ecaf7e86":"code","afdd926c":"code","3a36df53":"code","afe1643e":"code","e989e897":"code","f4982ab3":"code","336c2e47":"code","875a7e84":"markdown","6660b412":"markdown","c791cb35":"markdown","fa21ea31":"markdown","b2171d06":"markdown","54f4c7c0":"markdown","29cbcf51":"markdown","235d3e86":"markdown","6aa79721":"markdown","c353a8a5":"markdown","15f88774":"markdown","6bff69c9":"markdown","f2ef6e17":"markdown","e93f078d":"markdown","def63af2":"markdown","dcbb0103":"markdown"},"source":{"b8248184":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\nimport PIL\nfrom IPython import display\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","6984eb2b":"Anime_Face_Dataset = Path(\"..\/input\/animefacedataset\/images\")\nHuman_Face_Dataset = Path(\"..\/input\/extyalebcroppedpng\/CroppedYalePNG\")\nArtWork_Dataset = Path(\"..\/input\/best-artworks-of-all-time\/images\/images\/Pablo_Picasso\")","2d366af5":"Anime_Images = list(Anime_Face_Dataset.glob(r\"*.jpg\"))\nHuman_Images = list(Human_Face_Dataset.glob(r\"*.png\"))\nArtWork_Images = list(ArtWork_Dataset.glob(r\"*.jpg\"))","b0292848":"Reduce_Anime_Images = Anime_Images[0:600]\nReduce_Human_Images = Human_Images[0:50]","ca8cd448":"Mix_Dataset = []\n\nfor images_Anime in Reduce_Anime_Images:\n    Mix_Dataset.append(images_Anime)\n    \nfor images_Human in Reduce_Human_Images:\n    Mix_Dataset.append(images_Human)","99bbb260":"Mix_Series = pd.Series(Mix_Dataset,name=\"JPG\").astype(str)\nAnime_Series = pd.Series(Reduce_Anime_Images,name=\"JPG\").astype(str)\nHuman_Series = pd.Series(Reduce_Human_Images,name=\"JPG\").astype(str)\nArtWork_Images_Series = pd.Series(ArtWork_Images,name=\"JPG\").astype(str)","ce51ead3":"print(Mix_Series.head(-1))","ece46da0":"print(Anime_Series.head(-1))","4fd730ce":"print(Human_Series.head(-1))","46bb1c7b":"print(ArtWork_Images_Series.head(-1))","c0a77d98":"Mix_Series = Mix_Series.sample(frac=1).reset_index(drop=True)","4e059d7f":"print(Mix_Series.head(-1))","a7dc9128":"example_IMG = Mix_Series[44]\nReading_IMG = cv2.imread(example_IMG)\nTransformation_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n\nplt.xlabel(Transformation_IMG.shape)\nplt.ylabel(Transformation_IMG.size)\nplt.imshow(Transformation_IMG)","ff45b96d":"example_IMG = Mix_Series[4]\nReading_IMG = cv2.imread(example_IMG)\nTransformation_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n\nplt.xlabel(Transformation_IMG.shape)\nplt.ylabel(Transformation_IMG.size)\nplt.imshow(Transformation_IMG)","86154399":"example_IMG = Mix_Series[6]\nReading_IMG = cv2.imread(example_IMG)\nTransformation_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n\nplt.xlabel(Transformation_IMG.shape)\nplt.ylabel(Transformation_IMG.size)\nplt.imshow(Transformation_IMG)","f6517a88":"figure,axis = plt.subplots(4,4,figsize=(10,10))\n\nfor indexing,operations in enumerate(axis.flat):\n    Reading_IMG = cv2.imread(Mix_Series[indexing])\n    Reading_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n    \n    operations.set_xlabel(Reading_IMG.shape)\n    operations.imshow(Reading_IMG)\n    \nplt.tight_layout()\nplt.show()","bffbf3a1":"figure,axis = plt.subplots(4,4,figsize=(10,10))\n\nfor indexing,operations in enumerate(axis.flat):\n    Reading_IMG = cv2.imread(ArtWork_Images_Series[indexing])\n    Reading_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n    \n    operations.set_xlabel(Reading_IMG.shape)\n    operations.imshow(Reading_IMG)\n    \nplt.tight_layout()\nplt.show()","2c378b2b":"X_Train = []\n\nfor picking_images in ArtWork_Images_Series:\n    X_img = cv2.imread(picking_images)\n    X_img = cv2.cvtColor(X_img,cv2.COLOR_BGR2RGB)\n    X_img = cv2.resize(X_img,(180,180))\n    X_img = X_img \/ 255.\n    X_Train.append(X_img)\n\nprint(\"IT'S TRANSFORMED\")","37dd2f54":"print(np.shape(np.array(Mix_Series)))","f4429309":"X_Train = np.asarray(X_Train)\nprint(X_Train.shape)","527f5c5b":"iterations = 250\nvector_noise_dim = 180\ncount_example = 20\nbatch_size = 12\ncount_buffer = 60000","04836b16":"Train_Data = tf.data.Dataset.from_tensor_slices(X_Train).shuffle(count_buffer).batch(batch_size)","7f4e4539":"print(Train_Data)","214f845f":"def Generator_Model():\n    \n    \n    Model = Sequential()\n    #\n    Model.add(Dense(90*90*128,use_bias=False,input_shape=(180,)))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Reshape((90,90,128)))\n    #\n    Model.add(Conv2DTranspose(128,(3,3),padding=\"same\",use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    \n    #\n    Model.add(Conv2DTranspose(3,(3,3),padding=\"same\",use_bias=False,activation=\"tanh\"))\n    \n    \n    return Model","3f01028f":"Generator = Generator_Model()","e6fef84a":"print(Generator.summary())","c926113c":"print(Generator.layers)","b34d4228":"def Discriminator_Model():\n    \n    model = Sequential()\n    \n    model.add(Conv2D(64,(3,3),padding=\"same\",input_shape=[180,180,3]))\n    model.add(Dropout(0.3))\n    model.add(LeakyReLU())\n    \n    model.add(Conv2D(128,(3,3),padding=\"same\"))\n    model.add(Dropout(0.3))\n    model.add(LeakyReLU())\n    \n    model.add(Conv2D(256,(3,3),padding=\"same\"))\n    model.add(Dropout(0.3))\n    model.add(LeakyReLU())\n    \n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n    \n    return model","69a54651":"Discriminator = Discriminator_Model()","110de60e":"print(Discriminator.summary())","e811bebd":"print(Generator.layers)","33afe48e":"Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)","f72d9380":"Generator_Optimizer = tf.keras.optimizers.RMSprop(lr=0.0001,clipvalue=1.0,decay=1e-8)\nDiscriminator_Optimizer = tf.keras.optimizers.RMSprop(lr=0.0001,clipvalue=1.0,decay=1e-8)","f4a459f4":"seed = tf.random.normal([count_example,vector_noise_dim])","4c864d31":"def Discriminator_Loss(real_out,fake_out):\n    \n    real_loss_function = Loss_Function(tf.ones_like(real_out),real_out)\n    fake_loss_function = Loss_Function(tf.zeros_like(fake_out),fake_out)\n    total_loss = real_loss_function + fake_loss_function\n    \n    return total_loss","a40941b9":"def Generator_Loss(fake_out):\n    return Loss_Function(tf.ones_like(fake_out),fake_out)","e359907c":"def generate_and_save_images(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(10, 10))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(5, 5, i+1)\n        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n        plt.axis('off')\n\n    plt.savefig('images_epoch_{:04d}.png'.format(epoch))\n    plt.show()","88efc489":"def Train_Step(images):\n    \n    random_noise_vector = tf.random.normal([batch_size,vector_noise_dim])\n    \n    with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n        \n        Generator_Fake_IMG = Generator(random_noise_vector,training=False)\n        \n        real_out = Discriminator(images,training=True)\n        fake_out = Discriminator(Generator_Fake_IMG,training=True)\n        \n        Generator_Loss_Result = Generator_Loss(fake_out)\n        Discriminator_Loss_Result = Discriminator_Loss(real_out,fake_out)\n        \n        Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Result,Generator.trainable_variables)\n        Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Result,Discriminator.trainable_variables)\n        \n        Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n        Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))","f1f11690":"def Train_Function(dataset,iterations):\n    \n    for epoch in range(iterations):\n        \n        start = time.time()\n        \n        for image_batch in dataset:\n            Train_Step(image_batch)\n            \n        display.clear_output(wait=True)\n        generate_and_save_images(Generator,epoch+1,seed)\n        \n    display.clear_output(wait=True)\n    generate_and_save_images(Generator,epoch,seed)","67f6df52":"Train_Function(Train_Data, iterations)","5dedf41a":"Predict_Random_Noise = tf.random.normal(shape=[30,vector_noise_dim])","042d7284":"Generator_Prediction = Generator(Predict_Random_Noise)","2a5cb63e":"figure,axis = plt.subplots(3,3,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    Image_Picking = Generator_Prediction[i]\n    ax.imshow(Image_Picking,cmap=\"gray\")\n    ax.set_xlabel(Image_Picking.shape)\n    \nplt.tight_layout()\nplt.show()","8e4f597d":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[25])\nplt.show()","138e9336":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[2])\nplt.show()","30da6130":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[13])\nplt.show()","ecaf7e86":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[1])\nplt.show()","afdd926c":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[5])\nplt.show()","3a36df53":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[7])\nplt.show()","afe1643e":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[9])\nplt.show()","e989e897":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[11])\nplt.show()","f4982ab3":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[14])\nplt.show()","336c2e47":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction[0])\nplt.show()","875a7e84":"#### TRAIN FUNCTIONS","6660b412":"# TRAIN","c791cb35":"# DATA EXPORT AND TRANSFORMATION","fa21ea31":"#### IMAGES","b2171d06":"#### TO SERIES","54f4c7c0":"#### GENERATING AND DISPLAYING FUNCTION","29cbcf51":"# EXPORTATION AND TRANSFORMATION","235d3e86":"#### PARAMETERS AND MAIN FUNCTIONS","6aa79721":"#### TO SHUFFLE","c353a8a5":"# DATA ENGINEERING BEFORE DC-GAN PROCESS","15f88774":"#### TO MIX","6bff69c9":"# PACKAGES AND LIBRARIES","f2ef6e17":"#### OPTIMIZER AND LOSS FUNCTIONS","e93f078d":"#### VISION","def63af2":"#### MAIN PATH","dcbb0103":"#### EXPORTATION AND TRANSFORMATION"}}