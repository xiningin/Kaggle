{"cell_type":{"db72a653":"code","d8621331":"code","4a83c7c6":"code","1159448a":"code","e3be927b":"code","69365edc":"code","91b10ef4":"code","804940ff":"code","6b75f941":"code","9a4eaa12":"code","031798e6":"code","1a2331e1":"code","fd457830":"code","97bc1ff4":"code","bab51655":"code","83722590":"code","90957db6":"code","e94b63cb":"code","84717cd9":"code","943cdbaf":"code","7201e208":"code","d6f6b0f7":"code","225c90c0":"markdown","e0c1ed5e":"markdown","6dccb3ad":"markdown","d228bf02":"markdown","74b62a06":"markdown","7746a6f6":"markdown","801b348a":"markdown","dd285d71":"markdown","839dc70c":"markdown","0c52b97c":"markdown","6cee3e05":"markdown","a00b885c":"markdown","1476c59d":"markdown","a8483dca":"markdown","0acdd132":"markdown","7959e045":"markdown"},"source":{"db72a653":"!pip install featurewiz -q\n!pip install autogluon -q\n!pip install BorutaShap -q\n!pip install autoviz -q\n!pip install xlrd -q\n!pip install autofeat -q\n!pip install pytorch_tabnet -q","d8621331":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#importing Autoviz class\nfrom autoviz.AutoViz_Class import AutoViz_Class#Instantiate the AutoViz class\n\nfrom featurewiz import featurewiz","4a83c7c6":"AV = AutoViz_Class()\ndf = AV.AutoViz('..\/input\/spectogram-feature\/spectogram_feature.csv')","1159448a":"data = pd.read_csv('..\/input\/spectogram-feature\/spectogram_feature.csv')\n\nnormalized_data=(data-data.min())\/(data.max()-data.min())\nnormalized_data['activity'] = data['activity']\n\nnormalized_data","e3be927b":"data = normalized_data\n\ntarget='activity'\n\nselected_features = featurewiz(data, target=target, corr_limit=0.70, verbose=2)","69365edc":"data_selected=selected_features[1]\ndata_selected","91b10ef4":"# from sklearn.decomposition import PCA\n# pca = PCA(n_components=20)\n\n# principalComponents = pca.fit_transform(X)\n\n# principalDf = pd.DataFrame(data = principalComponents)\n\n# finalDf = pd.concat([principalDf, y], axis = 1)\n\n# finalDf","804940ff":"data = normalized_data\n\nX=data.loc[:, data.columns != 'activity']\ny=data['activity']\n\ndata","6b75f941":"from sklearn.svm import SVC\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\nX_train = X_train.to_numpy()\ny_train = y_train.to_numpy()\nX_test = X_test.to_numpy()\ny_test = y_test.to_numpy()\n\nsvclassifier = SVC(kernel='rbf')\nsvclassifier.fit(X_train, y_train)\n\ny_pred = svclassifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","9a4eaa12":"import lightgbm as lgb\n\nlgbclf = lgb.LGBMClassifier()\nlgbclf.fit(X_train, y_train)\n\ny_pred = lgbclf.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","031798e6":"from catboost import CatBoostClassifier\n\ncatclf = CatBoostClassifier(\n)\n\ncatclf.fit(X_train, y_train,\n        verbose=False\n)\n\ny_pred = catclf.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","1a2331e1":"import pytorch_tabnet\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nimport torch\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n\ntabclf = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n                       optimizer_params=dict(lr=2e-2),\n                       scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n                                         \"gamma\":0.9},\n                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n                       mask_type='entmax' # \"sparsemax\"\n                      )\n\ntabclf.fit(\n    X_train,y_train,\n    eval_set=[(X_train, y_train), (X_val, y_val)],\n    eval_name=['train', 'valid'],\n    eval_metric=['accuracy'],\n    max_epochs=500 , patience=30,\n    batch_size=128, virtual_batch_size=128,\n    num_workers=0,\n    weights=1,\n    drop_last=False\n) ","fd457830":"y_pred = tabclf.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","97bc1ff4":"import pytorch_tabnet\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nimport torch\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\nX_train = X_train.to_numpy()\ny_train = y_train.to_numpy()\nX_test = X_test.to_numpy()\ny_test = y_test.to_numpy()\n\ntabclf = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n                       optimizer_params=dict(lr=1e-2),\n                       scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n                                         \"gamma\":0.9},\n                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n                       mask_type='entmax' # \"sparsemax\"\n                      )\n\ntabclf.fit(\n    X_train,y_train,\n    eval_set=[(X_train, y_train)],\n    eval_name=['train'],\n    eval_metric=['accuracy'],\n    max_epochs=100 , patience=30,\n    batch_size=128, virtual_batch_size=128,\n    num_workers=0,\n    weights=1,\n    drop_last=False\n) ","bab51655":"y_pred = tabclf.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","83722590":"from autogluon.tabular import TabularDataset, TabularPredictor\nfrom autogluon.features.generators import AsTypeFeatureGenerator, DatetimeFeatureGenerator\nfrom autogluon.core.features.types import R_INT","90957db6":"time_limit = 600\nmetric = 'accuracy'  # specify your evaluation metric here\nsave_path = 'agModels-spec-baseline'\nlabel= 'activity'","e94b63cb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\nbaseline_train_data = pd.concat([X_train, y_train], axis=1)","84717cd9":"# predictor = TabularPredictor(label, eval_metric=metric, path=save_path, problem_type='multiclass').fit(baseline_train_data, time_limit=time_limit, presets='best_quality')\n\n# y_pred = predictor.predict(X_test)\n\n# from sklearn.metrics import classification_report, confusion_matrix\n# print(confusion_matrix(y_test,y_pred))\n# print(classification_report(y_test,y_pred))","943cdbaf":"time_limit = 8*3600\nmetric = 'accuracy'  # specify your evaluation metric here\nsave_path = 'agModels-spec'\nlabel= 'activity'","7201e208":"predictor = TabularPredictor(label, eval_metric=metric, path=save_path, problem_type='multiclass').fit(data, time_limit=time_limit, presets='best_quality')\npredictor.fit_summary()","d6f6b0f7":"# from autofeat import FeatureSelector\n# fsel = FeatureSelector(verbose=1)\n\n# X=data.loc[:, data.columns != 'class']\n# y=data['class']\n\n# new_X = fsel.fit_transform(pd.DataFrame(X), pd.DataFrame(y))","225c90c0":"#### Use all training data","e0c1ed5e":"## Feature Selection (did not use)","6dccb3ad":"### LGB baseline","d228bf02":"### Using AutoFeat","74b62a06":"#### Use only X_train(for baseline)(skip)","7746a6f6":"### Cat baseline","801b348a":"### Tabnet baseline (with val)","dd285d71":"## Baseline","839dc70c":"### PCA (did not use)","0c52b97c":"## Visualization (before feature engineering)","6cee3e05":"### Tab baseline (without val, use all X_train data)","a00b885c":"## Modeling Using AutoGluon","1476c59d":"### Using featurewiz","a8483dca":"## min-max Normalization","0acdd132":"## Set Data","7959e045":"### SVM baseline"}}