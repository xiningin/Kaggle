{"cell_type":{"35118fe4":"code","d5de6cda":"code","918d3179":"code","d5151096":"code","16cb9eee":"code","b7b2ccd9":"code","e609e676":"markdown","a55f2b74":"markdown","ab50994c":"markdown"},"source":{"35118fe4":"#  Libraries\nimport pandas as pd \nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d5de6cda":"#Read data\ntrain_transaction = pd.read_csv('..\/input\/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/test_transaction.csv', index_col='TransactionID')\ntrain_identity = pd.read_csv('..\/input\/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('..\/input\/test_identity.csv', index_col='TransactionID')","918d3179":"# Merge\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)","d5151096":"# Pre-process\ntrain = train.fillna(-999)\ntest = test.fillna(-999)\n\nlabel_y = train['isFraud']\ndel train['isFraud']\n\n# Label Encoding\nprint('Label Encoding...')\nfor f in train.columns:\n    if train[f].dtype=='object' or test[f].dtype=='object':\n        lbl = LabelEncoder()\n        lbl.fit(list(train[f].values)+ list(test[f].values))\n        train[f] = lbl.transform(list(train[f].values))\n        test[f] = lbl.transform(list(test[f].values))","16cb9eee":"# Create new y label to detect shift covariance\ntrain['origin'] = 0\ntest['origin'] = 1\n\n# Create a random index to extract random train and test samples\ntraining = train.sample(10000, random_state=12)\ntesting = test.sample(10000, random_state=11)\n\n## Combine random samples\ncombi = training.append(testing)\ny = combi['origin']\ncombi.drop('origin',axis=1,inplace=True)\n\n## Modelling\nmodel = RandomForestClassifier(n_estimators = 50, max_depth = 5,min_samples_leaf = 5)\nall_scores = []\ndrop_list = []\nscore_list =[]\ntemp = -1\nfor i in combi.columns:\n    temp +=1\n    score = cross_val_score(model,pd.DataFrame(combi[i]),y,cv=2,scoring='roc_auc')\n    if (np.mean(score) > 0.8):\n        drop_list.append(i)\n        score_list.append(np.mean(score))\n    all_scores.append(np.mean(score))    \n    print('Checking feature no {} out of {}'.format(temp, train.shape[1]))\n    print(i,np.mean(score))\n","b7b2ccd9":"#Print Top 20 features with possible covariate shift\nscores_df = pd.DataFrame({'feature':combi.columns, \n                          'score': all_scores})\n\nscores_df = scores_df.sort_values(by = 'score', ascending = False)\nscores_df.head(20)","e609e676":"## Covariate shift \nThis data set is closely resembling reality, i.e. the distributions of the various features may vary greatly from one period to the next. This, in turn, can cause great degradation in the model's predictive performance between train and test.\n\nThe purpose of this kernel is to highlight these features in order to remove them or treat them somehow. \n\nIf you find the kernel usefull, an upvote is alwyas welcome! Enjoy!","a55f2b74":"### Conclusion \nSo, not only D15, but other features like id_31 seem to present a covariate shift between train and test. \nI have personally removed both id_31 and D15 original features after including them in some feature engineering and I saw an increase in Public LB. \nTreat at your own discretion though: these features may contain usefull information. \n\nHappy to hear your own thoughts! \n","ab50994c":"### Explanation of next cell (or how to find features with covariate shift)\n- First I assign a new variable (lets say 'origin') to pinpoint each dataset. \n- Then, I take a random sample of both sets for convenience.\n- In the next step I concatenate the two datasets into a single dataframe\n- Afterwards, I build a simple random forest and I try to predict the new variable ('origin') using only 1 feature at a time\n- I calculate the performance of the model using AUC \n- Any given variable should not be able to predict the dummy 'origin' and should thus return an AUC score of around 0.5\n- If any variable succeeds in predicting the 'origin' variable (i.e. it is able to distinguish between train and test sets), it becomes a suspect of covariate shift"}}