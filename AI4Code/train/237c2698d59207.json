{"cell_type":{"8e99a669":"code","06259f7f":"code","9bedd188":"code","9ae254ba":"code","0ce727c1":"code","ca46e30d":"code","40c4eb3f":"code","32e83f7c":"code","2399cc7c":"code","a95814b2":"code","545112bc":"markdown","10a470c7":"markdown","5077b36e":"markdown","b2351dc5":"markdown","652f97d3":"markdown","492dd67f":"markdown","5e59684a":"markdown","c5facde3":"markdown"},"source":{"8e99a669":"# Data Manipulation\nimport numpy as np\nimport pandas as pd\n# Visualisation\nimport matplotlib.pyplot as plt\n# Dataset exploring\nimport os\n# Dataset generation\nfrom keras.preprocessing import image_dataset_from_directory\nfrom keras.preprocessing.image import ImageDataGenerator\n# Transfert learning\nfrom keras.applications import VGG16\n# Optimizer\nfrom keras.optimizers import Adam\n# Keras layers\nfrom keras.layers import Input, Dense, Dropout, Flatten, AveragePooling2D\n# Keras model\nfrom keras.models import Model","06259f7f":"classes = []\nclass_counter = 0\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/fruits-fresh-and-rotten-for-classification\/dataset\/train\/'):\n    if dirname.endswith('\/'):\n        continue\n    else:\n        classes.append({dirname.split('\/')[-1]: 0})\n    file_count = 0\n    for filename in filenames:\n        file_count += 1\n    classes[class_counter][dirname.split('\/')[-1]] = file_count\n    class_counter += 1\n    \nprint('{:<15} {:<15}'.format('Class', 'Number of instances'))\nprint()\nfor d in classes:\n    [(k, v)] = d.items()\n    print('{:<15} {:<15}'.format(k, v))","9bedd188":"counts = []\nlabels = []\nfor d in classes:\n    [(k, v)] = d.items()\n    labels.append(k)\n    counts.append(v)\n\nplt.figure()\nplt.bar(range(len(counts)), counts, color = ['yellow', 'orange', 'orange', 'green', 'green', 'yellow'], alpha = .7)\nplt.xticks(range(len(counts)), labels, rotation = 30)\nplt.title('Count of each label in our training data')\nplt.show()","9ae254ba":"TRAIN_PATH = '\/kaggle\/input\/fruits-fresh-and-rotten-for-classification\/dataset\/train'\nTEST_PATH = '\/kaggle\/input\/fruits-fresh-and-rotten-for-classification\/dataset\/test'","0ce727c1":"datagen = ImageDataGenerator(\n    rotation_range = 30, \n    zoom_range = .3, \n    horizontal_flip = True, \n    vertical_flip = True, \n    validation_split = .3\n)\n\ntrain_ds = datagen.flow_from_directory(\n    directory = TRAIN_PATH,\n    target_size = (256, 256),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    subset = 'training'\n)\n\nvalidation_ds = datagen.flow_from_directory(\n    directory = TRAIN_PATH,\n    target_size = (256, 256),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    subset = 'validation'\n)","ca46e30d":"vgg16 = VGG16(include_top = False, weights = 'imagenet', input_shape = (224, 224, 3))\nvgg16.trainable = False","40c4eb3f":"X_input = Input(shape = (256, 256, 3))\nX = vgg16(X_input)\nX = AveragePooling2D(pool_size = (3, 3), strides = 2, padding = 'valid',name = 'AvgPool2D')(X)\nX = Flatten(name = 'Flatten')(X)\nX = Dense(200, activation = 'relu', name = 'Dense1')(X)\nX = Dropout(.1)(X)\nX = Dense(100, activation = 'relu', name = 'Dense2')(X)\nX = Dropout(.1)(X)\nX = Dense(6, activation = 'softmax', name = 'Dense3')(X)\n\nmodel = Model(inputs = X_input, outputs = X, name = 'Fruit_Classifer')\n\nprint(model.summary())","32e83f7c":"optimizer = Adam(learning_rate = 0.001)\n\nmodel.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\n_ = model.fit(train_ds, validation_data = validation_ds, epochs = 5, batch_size = 32)","2399cc7c":"test_ds = image_dataset_from_directory(\n    TEST_PATH,\n    label_mode = 'categorical',\n    color_mode = 'rgb',\n    image_size = (256, 256)\n)","a95814b2":"results = model.evaluate(test_ds)\n\nprint('{:<20} {:<20}'.format('Test loss', 'Test accuracy'))\nprint('{:<20} {:<20}'.format(np.round(results[0], 2), np.round(results[1], 2)))","545112bc":"## Exploring data","10a470c7":"## Loading data","5077b36e":"## Creating model architecture\nNote : We will be using VGG-16 for transfert learning","b2351dc5":"We may have a slight imbalance in our dataset. Orange images are much less than apples.","652f97d3":"<center>\n    <h1>Rotten vs Fresh Fruit Detection<\/h1>\n<\/center>","492dd67f":"To generate more images we will use Keras' `ImageDataGenerator`.","5e59684a":"## Libraries","c5facde3":"## Model evaluation using test data"}}