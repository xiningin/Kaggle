{"cell_type":{"ad4e2dd8":"code","97a23d1e":"code","e3462efa":"code","5d397336":"code","d9b4d1d7":"code","5f742454":"code","8514a10b":"code","9235a18f":"code","3b0342ab":"code","1c55282f":"code","a2758d11":"code","e1d4dcde":"code","b9e8c6ee":"code","a4fcda56":"code","d72920d5":"code","693cc55f":"code","3d2c4a64":"code","5d74660c":"code","81166206":"code","db1b1a1e":"code","e832b9cd":"code","9a96bf7a":"markdown","fe36dbc3":"markdown","c48931c2":"markdown","f880f1f1":"markdown","c89e6a57":"markdown","9bc13911":"markdown","a3d5ad16":"markdown","b3f34bf2":"markdown","e5406f57":"markdown","8d20a925":"markdown","099c7e49":"markdown","c3673b97":"markdown","975e9028":"markdown","d3cebcad":"markdown","3398fc2b":"markdown","6093ad13":"markdown","da60ed08":"markdown","e6635df2":"markdown","e5076613":"markdown","d4e88ed4":"markdown","149822f8":"markdown","b40a928a":"markdown"},"source":{"ad4e2dd8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv(\"..\/input\/swiss-banknote-conterfeit-detection\/banknotes.csv\")","97a23d1e":"df.head()","e3462efa":"df.describe()","5d397336":"df.info()","d9b4d1d7":"sns.heatmap(df.isnull())\nplt.title(\"Missing values?\", fontsize = 18)\nplt.show()","5f742454":"# Pairwise relationships depending on counterfeit\nsns.pairplot(df, hue = \"conterfeit\")\nplt.show()","8514a10b":"sns.heatmap(df.corr(), annot = True, cmap=\"RdBu\")\nplt.title(\"Pairwise correlation of the columns\", fontsize = 18)\nplt.show()","9235a18f":"# Shuffle the dataset\ndf = df.reindex(np.random.permutation(df.index))\n\nX = df.drop(columns = \"conterfeit\")\ny = df[\"conterfeit\"]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nst = StandardScaler()\nX_train = st.fit_transform(X_train)\n","3b0342ab":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\n\npred = model.predict(st.transform(X_test))\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults = []\nresults.append((\"LogisticRegression\",class_report, conf_matrix, acc))","1c55282f":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\n\nrfc.fit(X_train, y_train)\n\npred = rfc.predict(st.transform(X_test))\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults.append((\"RandomForestClassifier\",class_report, conf_matrix, acc))","a2758d11":"from sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier()\n\ndtc.fit(X_train, y_train)\n\npred = dtc.predict(st.transform(X_test))\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults.append((\"DecisionTreeClassifier\",class_report, conf_matrix, acc))","e1d4dcde":"import tensorflow.keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(6))\nmodel.add(Dense(10))\nmodel.add(Dense(10))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train,y_train.values, epochs = 50, verbose = 0)","b9e8c6ee":"pred = model.predict(st.transform(X_test))\npred = [int(round(t)) for t in pred.reshape(1,-1)[0]]\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults.append((\"Neural Network\",class_report, conf_matrix, acc))","a4fcda56":"from sklearn.svm import SVC\nsvc = SVC()\n\nsvc.fit(X_train, y_train)\n\npred = svc.predict(st.transform(X_test))\n\nclass_report = classification_report(y_test, pred)\nconf_matrix = confusion_matrix(y_test,pred)\nacc = accuracy_score(y_test,pred)\n\nprint(\"Classification report:\\n\\n\", class_report)\nprint(\"Confusion Matrix\\n\",conf_matrix)\nprint(\"\\nAccuracy\\n\",acc)\n\nresults.append((\"SVC\",class_report, conf_matrix, acc))","d72920d5":"from sklearn.decomposition import TruncatedSVD\nsvd = TruncatedSVD(n_components = 2, random_state = 0)\n\ntransf = svd.fit_transform(X)\n\nplt.scatter(x = transf[:,0], y = transf[:,1])\nplt.title(\"Dataset after transformation with SVD\", fontsize = 18)\nplt.show()","693cc55f":"from sklearn.cluster import KMeans\n\nkm = KMeans(n_clusters = 2)\nc = km.fit_predict(transf)\n\nplt.scatter(x = transf[:,0], y = transf[:,1], c = c)\nplt.title(\"Clustering with Kmeans after SVD\", fontsize = 18)\nplt.show()","3d2c4a64":"plt.scatter(x = transf[:,0], y = transf[:,1], c = y)\nplt.title(\"Original labels after SVD\", fontsize = 18)\nplt.show()","5d74660c":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2, random_state = 0)\n\ntransf = pca.fit_transform(X)\n\nplt.scatter(x = transf[:,0], y = transf[:,1])\nplt.title(\"Dataset after transformation with PCA\", fontsize = 18)\nplt.show()","81166206":"km = KMeans(n_clusters = 2)\nc = km.fit_predict(transf)\n\nplt.scatter(x = transf[:,0], y = transf[:,1], c = c)\nplt.title(\"Clustering with Kmeans after PCA\", fontsize = 18)\nplt.show()","db1b1a1e":"plt.scatter(x = transf[:,0], y = transf[:,1], c = y)\nplt.title(\"Original labels after PCA\", fontsize = 18)\nplt.show()","e832b9cd":"labels  = []\nheight = []\nfor i in range(len(results)):\n    labels.append(results[i][0])\n    height.append(results[i][-1])\n    \nplt.figure(figsize = (12,6))    \nax = sns.barplot(labels,height)\nax.set_xticklabels(labels, fontsize = 18, rotation = 90)\nplt.title(\"Comparison of the models\", fontsize = 18)\nplt.ylabel(\"Prediction accuracy\")\nplt.show()","9a96bf7a":"## 2.3. Decision Tree<a class=\"anchor\" id=\"23\"><\/a>","fe36dbc3":"There is no missing value in the dataset.","c48931c2":"In the part, we will first separate the dataset in a training-set and a test-set. With the train-set, we will train the model and later we will the accuracy of the predictions of different models on the test-set.","f880f1f1":"## 2.1. Logistic Regression<a class=\"anchor\" id=\"21\"><\/a>","c89e6a57":"### ==> Goal: Detect counterfeit banknotes based on their size. ","9bc13911":"Now we'll use the unsupervised learning algorithm KMeans to find clusters in the dataset without using the counterfeit column to see if it will be capable to separate well the dataset in two clusters.\n","a3d5ad16":"<strong>==> All of the models give good predictions.<\/strong>","b3f34bf2":"# Table of contents\n\n\n[<h3>1. Content of the dataset<\/h3>](#1)\n[<h3>2. Predictions<\/h3>](#2)\n.... [2.1. Logistic Regression](#21)<br>\n.... [2.2. Random Forrest](#22)<br>\n.... [2.3. Decision Tree](#23)<br>\n.... [2.4. Neural Network](#24)<br>\n.... [2.5. SVC](#25)<br><br>\n[<h3>3. Clustering<\/h3>](#3)\n.... [3.1. KMeans with SVD](#31)<br>\n.... [3.2. KMeans with PCA](#32)<br><br>\n[<h3>4. Comparison of the models<\/h3>](#4)","e5406f57":"## 2.4. Neural Network<a class=\"anchor\" id=\"24\"><\/a>","8d20a925":"<img src=\"https:\/\/i.imgur.com\/vzYAmpP.png\" alt=\"search Conterfeit\">","099c7e49":"# 2. Predictions<a class=\"anchor\" id=\"2\"><\/a>","c3673b97":"<img src=\"https:\/\/i.imgur.com\/5VIHT6R.png\" alt = \"good\">","975e9028":"# 1. Content of the dataset<a class=\"anchor\" id=\"1\"><\/a>\n","d3cebcad":"# 4. Comparison of the models<a class=\"anchor\" id=\"4\"><\/a>","3398fc2b":"The dataset includes information about the shape of the bill, as well as the label. It is made up of 200 banknotes in total, 100 for genuine\/counterfeit each.<br\/>\n\n<strong>Attributes:<\/strong>\n- conterfeit: Whether a banknote is counterfeit (1) or genuine (0)\n- Length: Length of bill (mm)\n- Left: Width of left edge (mm)\n- Right: Width of right edge (mm)\n- Bottom: Bottom margin width (mm)\n- Top: Top margin width (mm)\n- Diagonal: Length of diagonal (mm)","6093ad13":"<strong>Original Data Source:<\/strong> \nFlury, B. and Riedwyl, H. (1988). Multivariate Statistics: A practical approach. London: Chapman & Hall, Tables 1.1 and 1.2, pp. 5-8.   \n","da60ed08":"# 2.5. SVC<a class=\"anchor\" id=\"25\"><\/a>","e6635df2":"# 3. Clustering<a class=\"anchor\" id=\"3\"><\/a>","e5076613":"# Detect counterfeit Banknotes with machine learning","d4e88ed4":"## 3.2. KMeans with PCA<a class=\"anchor\" id=\"32\"><\/a>","149822f8":"## 2.2. Random Forrest<a class=\"anchor\" id=\"22\"><\/a>","b40a928a":"## 3.1. KMeans with SVD<a class=\"anchor\" id=\"31\"><\/a>"}}