{"cell_type":{"82c723bc":"code","778ccec7":"code","99132d7c":"code","bc25048b":"code","3e78b8da":"code","f6d48794":"markdown"},"source":{"82c723bc":"%%bash\nyour_pet=\"https:\/\/pbs.twimg.com\/media\/FJJXtIQVgAEaDoZ?format=jpg&name=large\"\n\ncurl -o img ${your_pet}","778ccec7":"from PIL import ImageFont, ImageDraw, Image\nimg = Image.open('img')\nimg = img.resize((384, int(img.size[1] \/ img.size[0] * 384)))\nimg.save('target.jpg')","99132d7c":"import pandas as pd\n\n#df = pd.DataFrame()\n#df['Id'] = ['abcde']\ndf = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv', nrows=1)\ndf['path'] = ['target.jpg']\ndf.to_csv('target.csv', index=False)","bc25048b":"\nimport sys\nimport gc\nfrom tqdm.auto import tqdm\nsys.path = [\"..\/input\/pytorch-1-10-1\/\"] + sys.path\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nfrom timm import create_model\nsys.path.append('..\/input\/convnext\/ConvNeXt')\nimport models.convnext\nimport models.convnext_isotropic\n\nfrom fastai.vision.all import *\nprint(torch.__version__)\n\nBATCH_SIZE = 16\n\ndataset_path = Path('..\/input\/petfinder-pawpularity-score\/')\n\ntorch.backends.cudnn.benchmark = True\n\ndef petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ntest_df = pd.read_csv('target.csv')\n\n\ndef get_data(img_size):\n    dls = ImageDataLoaders.from_df(test_df, #pass in train DataFrame\n                               #valid_col='is_valid', #\n                               seed=999, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               #label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(img_size), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n    \n    return dls\n\n\n\nmodel_weights = {\n    'exp20_convnext_large': 1,\n    \n #'exp15_vit_base_patch16_224_miil_in21k': 0.08459557519051042,\n #'exp15_vit_large_patch16_224': 0.054602278608471444,\n #'exp20_convnext_large': 0.10757113794966554,\n #'exp4_crossvit_18_dagger_408': 0.07255291221705243,\n #'exp4_xcit_small_24_p16_384_dist': 0.07615822693896708,\n #'exp4_xcit_small_24_p8_384_dist': 0.07345531269210354,\n #'exp7_cait_m36_384': 0.08676476831055598,\n #'exp7_jx_nest_base': 0.05555615759973762,\n #'exp7_swin_base_patch4_window12_384': 0.0573931578726199,\n #'exp7_swin_large_patch4_window12_384_in22k': 0.07210228959069125,\n #'exp7_vit_base_patch16_224_miil_in21k': 0.07195345528468275,\n #'exp7_vit_base_r50_s16_384': 0.058601333331186556,\n #'exp8_vit_base_patch16_224_miil_in21k': 0.05634679166402379,\n #'exp9_cait_m36_384': 0.0769990055041272\n}\n\n\nN_FOLDS = 5\nall_preds = []\n\nfor path, w in tqdm(model_weights.items()):\n    model_name = path.split('_', 1)[-1]\n    try:\n        img_size = int(model_name.split('_')[-1])\n    except:\n        try:\n            img_size = int(model_name.split('_')[-2])\n        except:\n            img_size = 224\n    \n    def proc(pred):\n        return pred\n    num_classes = 1\n    if 'exp4_' in path:\n        model_dir = '..\/input\/model-exp4-0106\/pet'\n        loss = BCEWithLogitsLossFlat()\n    elif 'exp7_' in path:\n        model_dir = '..\/input\/model-exp7-0106\/pet'\n        loss = BCEWithLogitsLossFlat()\n    elif 'exp8_' in path:\n        model_dir = '..\/input\/model-exp8-9-15-0106\/pet'\n        loss = MSELossFlat()\n    elif 'exp9_' in path:\n        model_dir = '..\/input\/model-exp8-9-15-0106\/pet' \n        loss = CrossEntropyLossFlat()\n        num_classes = 100\n        def proc(pred):\n            return (pred.argmax(axis=1) + 1) \/ 100\n    elif 'exp15_' in path:\n        model_dir = '..\/input\/model-exp8-9-15-0106\/pet'\n        loss = MSELossFlat()\n        def proc(pred):\n            return (np.exp(pred) \/ 100).clip(0.01, 1)\n    elif 'exp20_' in path:\n        model_dir = '..\/input\/model-exp20\/pet\/'\n        loss = BCEWithLogitsLossFlat()\n        img_size = 384\n    else:\n        raise\n                 \n    dls = get_data(img_size)\n            \n    for i in range(N_FOLDS):\n        if 'convnext' in path:\n            model = create_model(model_name, pretrained=False)\n            model.head = nn.Linear(in_features=model.head.in_features, out_features=1, bias=True)\n        else:\n            model = create_model(model_name, pretrained=False, num_classes=num_classes)\n\n        model.load_state_dict(torch.load(f'{model_dir}\/{path}\/{model_name}_{i}.pth'))\n\n        learn = Learner(dls, model, \n                        loss_func=loss,\n                        metrics=petfinder_rmse).to_fp16()\n\n        test_dl = dls.test_dl(test_df)\n\n        preds, _ = learn.get_preds(dl=test_dl)\n        #preds, _ = learn.tta(dl=test_dl, n=2, beta=0)\n        \n        preds = proc(preds).flatten()\n        \n        all_preds.append(preds * w \/ N_FOLDS)\n\n        del learn\n        torch.cuda.empty_cache()\n        gc.collect()\n    del dls\n    torch.cuda.empty_cache()\n    gc.collect()\n\npreds = np.sum(np.stack(all_preds), axis=0)\n\npawpularity = round(preds[0] * 100)\n\nprint(f'Pawpularity of your pet is {pawpularity}.')","3e78b8da":"draw = ImageDraw.Draw(img)\nfont = ImageFont.truetype(\"..\/input\/arial-font\/arial.ttf\", 48)\ndraw.text((0,0), f'Pawpularity: {pawpularity}', font=font)\nimg","f6d48794":"# A Notebook to get a Pawpularity of Your Pet\n\nI saw someone say that they want to measure a Pawpularity of their own pet. This is a brief tutorial."}}