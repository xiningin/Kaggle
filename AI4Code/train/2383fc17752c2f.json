{"cell_type":{"63157e95":"code","4f4a6f3b":"code","19041bb2":"code","8fc010ae":"code","e318cc08":"code","67123d69":"code","e2f5d188":"code","4ab6dbb6":"code","48d58067":"code","20ee0dce":"code","83b49bc3":"code","e106561c":"code","bc49e26c":"code","7f4eacb1":"code","910363a0":"code","458a26b2":"code","f7bf8a6e":"code","0e951e35":"code","7eb28ac2":"code","b03c96ae":"code","707317d7":"code","ddee3514":"code","aafff232":"code","d1adfc6c":"code","3c58019a":"code","6dd7d6aa":"code","0ac06af3":"code","1a67ee52":"code","96684c65":"code","de7b2abd":"code","6823c7eb":"code","4dcaf9bd":"code","b59fb3a8":"code","1dfaaad0":"markdown","a28667d6":"markdown","caf40986":"markdown","00cefb4a":"markdown","c582c7a9":"markdown","e77d61cc":"markdown","1aeace8d":"markdown","ddac6e68":"markdown","c11d447f":"markdown","349b2d22":"markdown","d215be88":"markdown","855450d6":"markdown","785e89c2":"markdown","648cb4a9":"markdown","8de9195a":"markdown","3f7a3d05":"markdown","be5f079a":"markdown","fed3a3d7":"markdown","2807ce4b":"markdown","c5a8d8a5":"markdown","7bd0807f":"markdown","a4eb5754":"markdown","dce7e46a":"markdown","26324f6c":"markdown","a4847e17":"markdown","9049692f":"markdown"},"source":{"63157e95":"#Model ID\nModelId='digit_recognizer_FML_v1'\n\n#Setting the model target variable name\nvar_target = 'label'\n\n#process outputs such as MOJO model, images and performance of tested models\nOutputPath='\/kaggle\/temp'\n\n#If you have a huge dataset, I should consider use a small sample for first execution\npct_sample_size = 1","4f4a6f3b":"import glob\nimport functools\nimport datetime as dt\nimport pandas as pd\nimport numpy as np\nimport h2o\nimport matplotlib.pyplot as plt\nimport shap\nfrom pandas_profiling import ProfileReport\nfrom collections import defaultdict\nfrom pandas_profiling.model.base import get_var_type\nimport seaborn as sns\nimport os\nimport random","19041bb2":"#Import bases with features for modeling\n#In this case we will use titanic dataset available below\ndataprep_df_full = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\n#The target variavle must be integer\n\ndataprep_df_full['label'] = dataprep_df_full['label'].astype(int)","8fc010ae":"random.seed(59354518745)\nfor i in range(len(dataprep_df_full)):\n    dataprep_df_full.loc[i, ('random')] = random.random()\ndataprep_df_full['dataset'] = ['train' if x <= 0.85 else 'test' for x in dataprep_df_full['random']]\ndataprep_df_full = dataprep_df_full.drop(labels=['random'], axis=1)","e318cc08":"#Work with a sample data if the pct_sample_size is less than 1\nif pct_sample_size == 1:\n    dataprep_df = dataprep_df_full\nelse:    \n    dataprep_df = dataprep_df_full.sample(frac=pct_sample_size, replace=False, random_state=1)","67123d69":"X_train = dataprep_df.drop(labels=[var_target, 'dataset'], axis=1)\nX_train = X_train.astype('float32')\nX_train = X_train \/ 255\ndataprep_df = pd.concat([dataprep_df.loc[:,(var_target, 'dataset')], X_train], axis=1)","e2f5d188":"#Generate report\n#If the database has many records or columns, the report can take a long time\n#If this is the case, disable the explorative, samples, correlations, missing_diagrams, duplicates and interactions options by commenting out\nprofile = ProfileReport(dataprep_df, title=f\"Pandas Profiling Report{ModelId}\"\n                        ,explorative=True\n                        ,samples=None\n                        ,correlations=None\n                        ,missing_diagrams=None\n                        ,duplicates=None\n                        ,interactions=None\n                       )\n#profile.to_file(\"profile.html\")\n#display(profile)","4ab6dbb6":"# Get all the types pandas_profiling offers\nlist_columns = dataprep_df.columns.drop('dataset').drop(var_target)\nd = {col: get_var_type(dataprep_df[col])['type'].value for col in list_columns}\nfd = defaultdict(list)\nfor k, v in d.items():\n    fd[v].append(k)\n     \ncols_by_base_type = dict(fd)\n# Group the types pandas_profiling offers to match typical needs\ncat_num_cols = defaultdict(list)\nfor k, v in cols_by_base_type.items():\n    # Treat boolean and unique columns as categorical\n    k = 'CAT' if k in ['BOOL', 'UNIQUE'] else k\n    cat_num_cols[k].extend(v)\n#print(dict(cat_num_cols))","48d58067":"#It is necessary to define the types of variables (cageroric and numeric) to ensure that the type of data used in the modeling will be the most suitable.\n#For example, categorical variables need to be defined as a string because this prevents it from being treated as a numeric variable in H20 modeling\n#Another example is that the string variables will have a missing treatment by placing the missing category for all values found as 'null'\nCAT = []\n#float\nNUM = cat_num_cols['NUM'] + cat_num_cols['CAT']\n\nselected_features = CAT + NUM","20ee0dce":"#Numeric features must be float type\nfor col_name in NUM:    \n    dataprep_df[col_name] = dataprep_df[col_name].astype(float)    \n\n#Categorical features must be string type and null values will be filled with \"missing\"\nfor col_name in CAT:        \n    dataprep_df[col_name] = dataprep_df[col_name].astype(str)\n    dataprep_df = dataprep_df.fillna(value={col_name: 'missing'})    ","83b49bc3":"# Number of threads, nthreads = -1, means use all cores on your machine\n# max_mem_size is the maximum memory (in GB) to allocate to H2O\nh2o.init(nthreads = -1, max_mem_size = 8)","e106561c":"#Import TRAINING base to the H20 context\ndata_hdf = h2o.H2OFrame(dataprep_df.query('dataset == \"train\"'))\n\n# Conversion of Target variables and categorical features to factor (enum)\n#no H2O it is necessary that the categorical variables are transformed into a factor\ndata_hdf[var_target] = data_hdf[var_target].asfactor()\nfor col_name in CAT:\n    data_hdf[col_name] = data_hdf[col_name].asfactor()    \n    \n# Partition data into 90%, 10% chunks\n# Setting a seed will guarantee reproducibility\ntrain_hdf, valid_hdf = data_hdf.split_frame(ratios=[0.90], destination_frames=['train_hdf', 'valid_hdf'], seed=1)\n        \n#Notice that `split_frame()` uses approximate splitting not exact splitting (for efficiency), so these are not exactly 90%, 10% of the total rows.\nprint('Training: ' + str(train_hdf.nrow))\nprint('Validation: ' + str(valid_hdf.nrow))","bc49e26c":"#Import TEST base to the H20 context\ntest_hdf = h2o.H2OFrame(dataprep_df.query('dataset == \"test\"'))\n\n# Conversion of Target variables and categorical features to factor (enum)\n#no H2O it is necessary that the categorical variables are transformed into a factor\ntest_hdf[var_target] = test_hdf[var_target].asfactor()\nfor col_name in CAT:\n    test_hdf[col_name] = test_hdf[col_name].asfactor()    \n    \nprint('Test: ' + str(test_hdf.nrow))","7f4eacb1":"vModel = 'GLM_'\n\nstart = dt.datetime.now()\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\n\n#definir par\u00e1metros\nGLM = H2OGeneralizedLinearEstimator(family= 'multinomial',\n                                    seed=1,\n                                    #auc_type=\"MACRO_OVR\",\n                                    model_id='%s%s%s' % (vModel, ModelId, str(dt.datetime.now())[:19].replace('-',\"\").replace(':',\"\").replace(' ',\"_\")))\n\n#Executar Modelo\nGLM.train(x = selected_features,\n          y = var_target,\n          training_frame = train_hdf,\n          validation_frame = valid_hdf)\n\n#Execution time of the model\nstop = dt.datetime.now()\nexecution_time = stop-start\nprint(\"\\n\"+ \"Execution time: \" + str(execution_time) +\"\\n\")\nprint(GLM)","910363a0":"vModel='GBM_'\n\n#Execution time of the model\nstart = dt.datetime.now()\n\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nGBM = H2OGradientBoostingEstimator(model_id='%s%s%s' % (vModel, ModelId, str(dt.datetime.now())[:19].replace('-',\"\").replace(':',\"\").replace(' ',\"_\")),\n                                   ntrees=500,\n                                   score_tree_interval=5,     #used for early stopping\n                                   stopping_rounds=3,         #used for early stopping\n                                   stopping_metric='mean_per_class_error',     #used for early stopping\n                                   stopping_tolerance=0.0005, #used for early stopping\n                                   #auc_type=\"MACRO_OVR\",\n                                   seed=1)\n\n# The use of a validation_frame is recommended with using early stopping\nGBM.train(x=selected_features, y=var_target, training_frame=train_hdf, validation_frame=valid_hdf)\n\n#Execution time of the model\nstop = dt.datetime.now()\nexecution_time = stop-start\nprint(\"\\n\"+ \"Execution time: \" + str(execution_time) + \"\\n\")\nprint(GBM)","458a26b2":"vModel='GBM_cv_'\n\n#Execution time of the model\nstart = dt.datetime.now()\n\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nGBM_cv = H2OGradientBoostingEstimator(model_id='%s%s%s' % (vModel, ModelId, str(dt.datetime.now())[:19].replace('-',\"\").replace(':',\"\").replace(' ',\"_\"))\n                                   ,nfolds=5\n                                   ,seed=1\n                                   #,auc_type=\"MACRO_OVR\"\n                                   )\n\n# The use of a validation_frame is recommended with using early stopping\nGBM_cv.train(x=selected_features, y=var_target, training_frame=train_hdf, validation_frame=valid_hdf)\n\n#Execution time of the model\nstop = dt.datetime.now()\nexecution_time = stop-start\nprint(\"\\n\"+ \"Execution time: \" + str(execution_time) + \"\\n\")\nprint(GBM_cv)","f7bf8a6e":"vModel='DRF_CV_'\n\n#Execution time of the model\nstart = dt.datetime.now()\n\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator\n\nDRF = H2ORandomForestEstimator(seed=1\n                               ,nfolds=5\n                               #,auc_type=\"MACRO_OVR\"\n                               ,model_id='%s%s%s' % (vModel, ModelId, str(dt.datetime.now())[:19].replace('-',\"\").replace(':',\"\").replace(' ',\"_\")))\n\n# The use of a validation_frame is recommended with using early stopping\nDRF.train(x=selected_features, y=var_target, training_frame=train_hdf, validation_frame=valid_hdf)\n\n#Execution time of the model\nstop = dt.datetime.now()\nexecution_time = stop-start\nprint(\"\\n\"+ \"Execution time: \" + str(execution_time) + \"\\n\")\nprint(DRF)","0e951e35":"vModel='AUTOML'\n\n#Execution time of the model\nstart = dt.datetime.now()\n\n#Set the maximum time in seconds for the H20 AutoML\nmax_runtime_secs=60*10\n\n#Define metrics to select the best model in AutoML\nsort_metric = 'mean_per_class_error'\n\nfrom h2o.automl import H2OAutoML\nAUTOML = H2OAutoML(seed=1,                   \n                   include_algos = ['DRF', 'GLM', 'XGBoost', 'GBM', 'DeepLearning', 'StackedEnsemble'],\n                   max_runtime_secs = max_runtime_secs,\n                   stopping_metric = sort_metric,\n                   sort_metric = sort_metric)\nAUTOML.train(x=selected_features, y=var_target, training_frame = train_hdf, validation_frame = valid_hdf, leaderboard_frame=test_hdf)\n\n#View the AutoML Leaderboard\nlb = AUTOML.leaderboard\nprint(lb.head(rows=lb.nrows))\n\n#Execution time of the model\nstop = dt.datetime.now()\nexecution_time = stop-start\nprint(\"\\n\"+ \"Execution time: \" + str(execution_time) + \"\\n\")","7eb28ac2":"#Choose the desired AutoML model\nbest_automl_position=0\nif len(AUTOML.leaderboard) > 0:\n    best_AutoML = h2o.get_model(AUTOML.leaderboard[best_automl_position, 0])\n    print(best_AutoML)","b03c96ae":"#Create empty model list\nlist_models = []\n\n#Define the list of all models that have been executed and should be compared\ntry:\n    list_models.append(GLM)\nexcept NameError:\n    GLM = None\ntry:\n    list_models.append(GBM)\nexcept NameError:\n    GBM = None\ntry:\n    list_models.append(GBM_cv)\nexcept NameError:\n    GBM_cv = None\ntry:\n    list_models.append(DRF)\nexcept NameError:\n    DRF = None\ntry:\n    list_models.append(best_AutoML)\nexcept NameError:\n    best_AutoML = None","707317d7":"#Compare performance on the TEST dataset for all trained models\nplt.rcParams.update({'font.size': 12})\nfig = plt.figure(figsize=(10, 10))\nfor i in list_models:\n    #Save all models in H20 format\n    h2o.save_model(model=i, path='%s\/models\/todos\/' % OutputPath, force=True)    \n    \n    #Ascertain the performance of all models on the test base\n    performance = i.model_performance(test_hdf)\n    \n    #Salve metrics\n    f=open(\"%s\/models\/todos\/performance_%s.csv\" % (OutputPath, i.model_id), 'w')\n    f.write(\n        str(i.model_id) + \";\"\n        + str(performance.mean_per_class_error()) + \";\"\n        + str(performance.auc()) + ';'\n        + str(performance.aucpr()) + ';'\n        + str(performance.logloss()) + ';'\n        + str(performance.mse()) + ';'\n        + str(performance.rmse()))\n    f.write('\\n')\n    f.close()\n    \n    if i.model_id==list_models[0].model_id:\n        df_plot = pd.DataFrame({'Model_id': i.model_id.split(\"_\")[0]+\"_\"+i.model_id.split(\"_\")[1]+\"_\"+i.model_id.split(\"_\")[2],\n                                    'mean_per_class_error': int(performance.mean_per_class_error()*100)\/100,\n                                    'mse': int(performance.mse()*100)\/100,\n                                    'mse': int(performance.rmse()*100)\/100\n                                    }, index=[0])\n    else:\n        df_plot = df_plot.append(pd.DataFrame({'Model_id': i.model_id.split(\"_\")[0]+\"_\"+i.model_id.split(\"_\")[1]+\"_\"+i.model_id.split(\"_\")[2],\n                                    'mean_per_class_error': int(performance.mean_per_class_error()*100)\/100,\n                                    'mse': int(performance.mse()*100)\/100,\n                                    'rmse': int(performance.rmse()*100)\/100\n                                    }, index=[0]))\n\nax = df_plot.plot(kind='bar', x=\"Model_id\", title=\"mean_per_class_error, mse and rmse for Model (Test dataset)\", grid=True, figsize=(10,5), legend=1)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\nplt.legend(loc=3, prop={'size': 10})","ddee3514":"#Consider all models in the history .\/models\/todos\/performance_*.csv. To disregard any old version, set erase_modelos = \"S\":\napagar_modelos = 'N'\nif apagar_modelos == 'S':\n    os.system('rm %s\/models\/todos\/performance_*.csv' % OutputPath)","aafff232":"sort_metric_best_model='mean_per_class_error'\n#importar todos os modelos testados e imprmie na tela os 10 melhores erdedando per AUC\nmodelos_testados = pd.concat(map(functools.partial(pd.read_csv, sep=';', header=None), glob.glob('%s\/models\/todos\/performance_*.csv' % OutputPath)))\nmodelos_testados.columns = ('model_id', 'mean_per_class_error', 'AUC', 'AUCPR', 'logloss', 'mse', 'rmse')\nmodelos_testados = modelos_testados.sort_values(by=sort_metric_best_model, ascending=True)\nmodelos_testados = modelos_testados.drop_duplicates(subset=[\"model_id\"])\nprint('MBest Models. Sorted by : ' + str(sort_metric_best_model))\nmodelos_testados.reset_index(0).head(30)","d1adfc6c":"#If you want to choose a model other than the first one on the list. Choose the position number:\nposicao_melhor_modelo=0\n\nmelhor_modelo = h2o.load_model('%s\/models\/todos\/%s' % (OutputPath, modelos_testados.iloc[posicao_melhor_modelo, 0]))\n(print(\"\\n\"+ \"BEST MODEL: \" + str(modelos_testados.iloc[posicao_melhor_modelo, 0]) + \"\\n\"))\n\nplt.rcParams.update({'font.size': 10})\ntry:\n    melhor_modelo.varimp_plot(50)\nexcept Exception as e:\n    print(\"Warning: This model doesn't have variable importances\")","3c58019a":"#Listar todas as vari\u00e1veis do modelo atual, ordenadas por variable importance\n#Para as variaveis definidas como fator (que possivelmente est\u00e3o como dummys), remover a categoria do nome e deixar apenas o nome orifinal da variavel\n\n#List all variables in the current model, ordered by variable importance\n#For variables defined as a factor (which possibly are like dummys), remove the category from the name and leave only the orifinal name of the variable\ntry:\n    df_features_sorted = melhor_modelo.varimp(True).variable.str.split('.', expand=True).drop_duplicates(subset = 0)[0].reset_index(drop=True)\nexcept Exception as e:\n    #As the model with ensemble in H20 does not show the importance of variables, we will include variables with higher IV first using result_formatado graph of step 5.1\n    df_features_sorted = result_formated_graph.Variable.reset_index(drop=True)","6dd7d6aa":"#Define the number of variables to be increased with each new model. Try to put 10% or 20% of the total, as it can take a long time\nqt_var=10\nqt_total_var = len(df_features_sorted)\n\ndict_model_tmp={}\ndict_performance={}\n\nfor i in range(qt_var, qt_total_var+qt_var, qt_var):    \n    df_features_sorted[0:i].values.tolist()    \n    \n    #If no model chosen is not an ensemble of models. Then use the same model for training with increment of variables\n    melhor_modelo_tmp = melhor_modelo\n    if melhor_modelo_tmp.model_id.lower().find(\"ensemble\") == -1:\n        dict_model_tmp[i] = melhor_modelo_tmp\n        dict_model_tmp[i].train(x = df_features_sorted[0:i].values.tolist(),\n                                y = var_target,\n                                training_frame=train_hdf, \n                                validation_frame=valid_hdf)\n    ##If it is not possible, for the home of an ensemble of models, use GradientBoostingEstimator to make the assessment\n    else:\n        dict_model_tmp[i] = H2OGradientBoostingEstimator(seed=1, model_id=str('model_tmp_%s' % i))\n        dict_model_tmp[i].train(x = df_features_sorted[0:i].values.tolist(),\n                                y = var_target,\n                                training_frame=train_hdf, \n                                validation_frame=valid_hdf)       \n\n\n    perform_oot = dict_model_tmp[i].model_performance(test_hdf)\n    dict_performance_tmp = {}\n    dict_performance_tmp['MSE'] = {'qt_var': i, 'medida': 'MSE', 'Validation_Dataset': dict_model_tmp[i].mse(valid=True), 'Test_Dataset': perform_oot.mse()}\n    dict_performance_tmp['RMSE'] = {'qt_var': i, 'medida': 'RMSE', 'Validation_Dataset': dict_model_tmp[i].rmse(valid=True), 'Test_Dataset': perform_oot.rmse()}\n    dict_performance_tmp['logloss'] = {'qt_var': i, 'medida': 'logloss', 'Validation_Dataset': dict_model_tmp[i].logloss(valid=True), 'Test_Dataset': perform_oot.logloss()}\n    dict_performance[i] = pd.DataFrame(dict_performance_tmp).transpose()","0ac06af3":"##Plot graph comparing the increase in performance with the increase in variables\nfor i in dict_performance.keys():\n    if i == list(dict_performance.keys())[0]:\n        df_performance = dict_performance[i]\n    else:\n        df_performance = df_performance.append(dict_performance[i], ignore_index=True)\n\nlista_metricas_perf = df_performance['medida'].unique()\n\nfor i in range(len(lista_metricas_perf)):   \n    #selects only the metric to be analyzed\n    metrics_df_tmp = df_performance.query('medida == \"%s\"' % lista_metricas_perf[i])\n    metrics_df_tmp = metrics_df_tmp.set_index('qt_var')\n    del metrics_df_tmp['medida']\n    if lista_metricas_perf[i] == 'R2':\n        max_oot = metrics_df_tmp[metrics_df_tmp['Test_Dataset'] == metrics_df_tmp.Test_Dataset.max()].index.values\n    else:\n        max_oot = metrics_df_tmp[metrics_df_tmp['Test_Dataset'] == metrics_df_tmp.Test_Dataset.min()].index.values\n        \n    if lista_metricas_perf[i] == 'logloss':\n        max_oot_filtro = max_oot[0]        \n    \n    ax=metrics_df_tmp.plot(figsize=(15,5), linewidth=2, fontsize=10, marker='D', ms=5,\\\n                            title='Best %s with %s Variables' % (lista_metricas_perf[i].upper(), str(max_oot[0])))\n    plt.xlabel('Variables Number')\n    plt.ylabel('%s' % lista_metricas_perf[i].upper())\n    plt.grid(axis='y')\n    plt.legend(loc=0, prop={'size': 12})\n    #display(ax)","1a67ee52":"print('Consider removing the following variables: '+ str(df_features_sorted[df_features_sorted.index > int(max_oot_filtro)].values.tolist()))","96684c65":"#Save the H2O model in MOJO format and all the variables of the best model\nmelhor_modelo = h2o.load_model('%s\/models\/todos\/%s' % (OutputPath, modelos_testados.iloc[posicao_melhor_modelo, 0]))\ncaminho_modelo_mojo = melhor_modelo.download_mojo('%s\/models\/melhores\/' % OutputPath, get_genmodel_jar=True)\nprint(caminho_modelo_mojo)\ncaminho_modelo_h2o = h2o.save_model(model=melhor_modelo, path='%s\/models\/melhores\/' % OutputPath, force=True)","de7b2abd":"try:\n    features_names= melhor_modelo.varimp(True)\n    features_names.to_csv('%s\/models\/melhores\/features_names_%s.csv' % (OutputPath, melhor_modelo.model_id), sep=';')\nexcept Exception as e:\n    print(\"Warning: This model doesn't have variable importances\")","6823c7eb":"submission_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\nsubmission_df = submission_df.astype('float32')\nsubmission_df = submission_df \/ 255\n\n#Numeric features must be float type\nfor col_name in NUM:    \n    submission_df[col_name] = submission_df[col_name].astype(float)    \n\n#Categorical features must be string type and null values will be filled with \"missing\"\nfor col_name in CAT:        \n    submission_df[col_name] = submission_df[col_name].astype(str)    \n    submission_df = submission_df.fillna(value={col_name: 'missing'}) ","4dcaf9bd":"#Importar MOJO\ntry:\n    test_tmp = h2o.mojo_predict_pandas(submission_df, caminho_modelo_mojo)    \n    predict_df = submission_df.merge(test_tmp, left_index=True, right_index=True)\nexcept:    \n    submission_hdf = h2o.H2OFrame(submission_df)\n    for col_name in CAT:\n        submission_hdf[col_name] = submission_hdf[col_name].asfactor() \n    h2o_predict = melhor_modelo.predict(submission_hdf)\n    predict_df = h2o_predict.cbind(submission_hdf).as_data_frame()\n    \npredict_df.rename(columns={'predict':'Label'}, inplace=True)\npredict_df = predict_df.reset_index(drop=True)\npredict_df = predict_df.reset_index(drop=False)\npredict_df.rename(columns={'index':'ImageId'}, inplace=True)\npredict_df['ImageId'] = predict_df['ImageId']+1\npredict_df.loc[:, ('ImageId', 'Label')]","b59fb3a8":"predict_df.loc[:, ('ImageId', 'Label')].to_csv('\/kaggle\/working\/digit_recognizer_submission.csv', index=False)","1dfaaad0":"## 6.2 Using H2O to performe many ML algorithms","a28667d6":"### It is necessary to create a variable to indicate the records used in training and testing. In this case we will use the random variable, but you can use a date variable for exemple if you have a base with a reference date to fix the training base as an out of time validation.","caf40986":"## END","00cefb4a":"## GBM - Gradient Boosting Machine with Cross-Validation","c582c7a9":"# 8. Save final dataset with predictions","e77d61cc":"## H2OAutoML","1aeace8d":"## 6.1 Creating context and H2O and Importing data into the H2O context","ddac6e68":"# 3. Importing Data for Modeling","c11d447f":"## 5. Classify the types of variables\n#### list all columns to select the ones to be used","349b2d22":"## GBM - Gradient Boosting Machine","d215be88":"# 6. Modeling","855450d6":"##### For more details on the pandas profiling library see https:\/\/github.com\/pandas-profiling\/pandas-profiling\n","785e89c2":"## 6.4 Stepwise for Analysis of the importance of variables","648cb4a9":"# 7. Predict Submision dataset using MOJO or H2O Model","8de9195a":"# This notebook will help you to do:\n* Import training and test data\n* Univariate Analysis\n* Run many ML algorithms using H2O\n* Compare all model performance in test dataset\n* Choosing the best model\n\n## The Digit Recognizer dataset will be used for this demonstration","3f7a3d05":"## 6.5 Exporting the best model to Deploy","be5f079a":"# 1. Parameters","fed3a3d7":"## 4.1 Pandas Profiling","2807ce4b":"## 6.4 Choose the best model among all tested","c5a8d8a5":"## Logistic Regresion (GLM)","7bd0807f":"# 2. Import Libraries","a4eb5754":"## 6.3 Compare performance on the TEST dataset for all trained models","dce7e46a":"# 4. Univariate Analysis","26324f6c":"## Random Forest","a4847e17":"### From the variables listed above you can select which  one will be tested in the model and confirm if the correct type is numeric(NUM) or categorical (CAT). Paste the correct information below:","9049692f":"## 3.1 Feature Engineering"}}