{"cell_type":{"c1b37b84":"code","9f2903ac":"code","a0eab75d":"code","ec126d6c":"code","9128ce98":"code","bc9db325":"code","659ded40":"code","7bcd593d":"code","a75d3071":"code","bd6245ef":"code","74af754c":"code","3739c60e":"code","9be1b328":"code","d2d51091":"code","ea65a742":"code","238be24f":"code","b6937c02":"markdown","e4d43c88":"markdown","5cc4075a":"markdown","a56d8478":"markdown","24368867":"markdown","67be4264":"markdown","3461778d":"markdown","275f326f":"markdown","cd50c907":"markdown","45a1e4fb":"markdown"},"source":{"c1b37b84":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f2903ac":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","a0eab75d":"train = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/train.csv', index_col='id')\ntest = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/test.csv', index_col='id')","ec126d6c":"print(train.shape)\nprint(test.shape)","9128ce98":"train.head()","bc9db325":"test.head()","659ded40":"train.isnull().sum()","7bcd593d":"test.isnull().sum()","a75d3071":"X = train.drop('target', axis=1)\ny = train.target","bd6245ef":"cat_cols = ['cat'+str(i) for i in range(10)]\ncat_cols","74af754c":"cont_cols = ['cont'+str(i) for i in range(14)]\ncont_cols","3739c60e":"# check cardinarity\nfor col in cat_cols:\n    print('{}: {}({})'.format(col,len(X[col].unique()),X[col].unique()))","9be1b328":"# Split cat_cols to law cardinarity and high cardianrity\nlow_cardinarity_cols = list(set(cat_cols) - set(['cat9']))\nhigh_caridnarity_cols = ['cat9']","d2d51091":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\n\n\npreprocessor = ColumnTransformer(transformers=[\n    ('ordinal', OrdinalEncoder(), high_caridnarity_cols),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'), low_cardinarity_cols)\n])\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', XGBRegressor(n_estimators=100, learning_rate=0.05))\n                             ])\n\nscores = -1 * cross_val_score(my_pipeline, X, y,\n                              cv=5,\n                              scoring='neg_mean_squared_error')\n\nprint(scores)","ea65a742":"my_pipeline.fit(X,y)\npred = my_pipeline.predict(test)\npred","238be24f":"pd.DataFrame(pred, index=test.index, columns=['target']).to_csv('submission.csv')","b6937c02":"## Look at the data","e4d43c88":"# Make submission","5cc4075a":"# Reading the data","a56d8478":"# Submit","24368867":"# Import Libraries","67be4264":"## Split to X & y","3461778d":"## Check null values","275f326f":"# Make ML Model & check CV scores","cd50c907":"There are no null value.","45a1e4fb":"# Prepare for data transform"}}