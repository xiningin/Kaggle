{"cell_type":{"07d719bb":"code","f29d1282":"code","02c019b0":"code","501ab9df":"code","24aa87f5":"code","b38b320c":"code","8c586038":"code","b83aaa6f":"code","58460132":"code","4846b3c3":"code","591d4064":"code","2b25ea27":"code","d35e7ef3":"code","02a65208":"code","57276cb8":"markdown","fc3f0295":"markdown","b9cf49e1":"markdown","8be20998":"markdown","40050f30":"markdown","652727b6":"markdown","65191cb2":"markdown","bc80d536":"markdown","be68ebb1":"markdown","bb482727":"markdown","500d7cb8":"markdown","32c102a3":"markdown","310d9dcf":"markdown","8e8bccc3":"markdown","657286ea":"markdown","05687e01":"markdown"},"source":{"07d719bb":"!pip install face_recognition","f29d1282":"# we will import the required libraries\nimport matplotlib.pyplot as plt #for ploting of image\nfrom skimage.feature import hog # for extraction HOG features of image.\nfrom skimage import data, exposure\nimport cv2 # for preprocessing on image\n\n# Now we will read image from the disk\nimage = cv2.imread('..\/input\/pictures\/dhoni.jpeg')\n# When we read image using OpenCV, it reads the image in BGR format\n# So now we will convert the image into RGB format\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n\n# Now we will show the image\nplt.imshow(image)","02c019b0":"# now lets perform the feature extraction.\n# we are going to use the hog function from skimage to extrat the HOG(Histogram of Oriented Gradient) image from input image.\n\nfd, hog_image = hog(image, orientations=8, pixels_per_cell=(16,16),\n                   cells_per_block=(1,1), visualize=True, multichannel=True)\n# fd is feature discriptor which is used for representation of image\n# hog_image is a HOG image extracted from input image\n\n# now let's plot input image and hog image both so it's easy to compare\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 12), sharex = True, sharey = True)\n\nax1.axis('off')\nax1.imshow(image, cmap=plt.cm.gray)\nax1.set_title('Input Image')\n\nhog_rescaled_img = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n\nax2.axis('off')\nax2.imshow(hog_rescaled_img, cmap=plt.cm.gray)\nax2.set_title('HOG Image')\nplt.show()","501ab9df":"# Let us import the important libraries for Face Detection purpose\nimport face_recognition # For Face Detection\nfrom matplotlib.patches import Rectangle # To draw rectangles\nimport numpy as np # for mathematicle operations\n\n# In Face Recognition library there is a function face_locations which detects the all faces in the image and \n# returns there locations\n# let's use the function and detect the faces\nface_locations = face_recognition.face_locations(image)\n\ntotal_faces = len(face_locations)\n# lets print out the number of faces in the image.\nprint('There are {} face(s) in the image'.format(total_faces))\n","24aa87f5":"def detect_the_faces(image_path):\n    image = cv2.imread(image_path) # Read the image\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert BGR to RGB format\n    plt.imshow(image)\n    ax = plt.gca()\n    #Detect the face locations\n    face_locations = face_recognition.face_locations(image)\n    if len(face_locations) == 0:\n        return 'No Faces Detected'\n    \n    # Now we need draw rectangle for each faces found\n    for face_location in face_locations:\n        # Get the co-ordinates from the location\n        y, w, h, x = face_location \n        # here y is for top, w for right width, h for bottom height and x for left\n        \n        # So we got the co-orinates, let's draw the rectangle\n        rect = Rectangle((x,y), w-x, h-y, fill=False, color='red')\n        ax.add_patch(rect)\n    \n    # Let's disply\n    plt.show()\n    ","b38b320c":"# Let us pass our input image to the function that we created above.\ndetect_the_faces('..\/input\/pictures\/dhoni.jpeg')","8c586038":"# We will use python dictionary as Database for known faces encodings\nknown_faces = {}\n\n#Now we create a function to add the faces encoding into the data base.\ndef add_face(image_path, name):\n    image = cv2.imread(image_path) # Read the image\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert BGR to RGB format\n    \n    # We will get a face encoding for the face in the image\n    face_encoding = face_recognition.face_encodings(image)[0] # 0 because if there are more than one facec then it will take first detected face\n    \n    # We add the face encoding in thedatabase with corresponding names \n    known_faces[name] = face_encoding\n    \n\n    \n    ","b83aaa6f":"# Let's add known faces in database, For now we will add 3 known faces\nadd_face('..\/input\/pictures\/dhoni.jpeg', 'Dhoni')\nadd_face('..\/input\/pictures\/hrithik.jpeg', 'Hrithik')\nadd_face('..\/input\/pictures\/Rohit.jpg', 'Rohit')\n\n#Let's check total keys in database\nprint(list(known_faces.keys()))","58460132":"from scipy.spatial import distance # This will be used for calculating the distance between two encodings\n\ndef recognize_face(image_path):\n    # Let's read the image using cv2\n    unknown_image = cv2.imread(image_path)\n    unknown_image = cv2.cvtColor(unknown_image, cv2.COLOR_BGR2RGB) # Convert thr BGR to RGB format\n    \n    # Let's get encodings for the face in the image\n    unknown_face_encodings = face_recognition.face_encodings(unknown_image) # Here we will not add [0] because we want all the faces to be recognized in the image.\n    \n    # Now we will check the euclidean distance between two faces\n    found_faces=[]\n    threshold = 0.6\n    for unknown_face_encoding in unknown_face_encodings:\n        for known_person in known_faces:\n            # Calculate the Euclidean distance\n            d = distance.euclidean(known_faces[known_person], unknown_face_encoding)\n            # We will check that distance should be less than threshold\n            if d <= threshold:\n                found_faces.append(known_person)\n    if len(found_faces) ==  0:\n        found_faces.append('Unknown')\n    \n    return found_faces # We return a list on found images in the image\n    \n        \n    ","4846b3c3":"# Now Let's use above function that we created for recognition of person\n# our function returns a list of found faces in the image\n\n################### TEST NO 1\ntest_image_path = '..\/input\/pictures\/dhoni_test.jpg'\ntest_image = cv2.imread(test_image_path)\ntest_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\nplt.imshow(test_image)\n\nfaces_in_picture = recognize_face(test_image_path)\nfor face in faces_in_picture:\n    print(\"There is {}'s face in image\".format(face))","591d4064":"################### TEST NO 2\ntest_image_path = '..\/input\/pictures\/rohit_test.jpg'\ntest_image = cv2.imread(test_image_path)\ntest_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\nplt.imshow(test_image)\n\nfaces_in_picture = recognize_face(test_image_path)\nfor face in faces_in_picture:\n    print(\"There is {}'s face in image\".format(face))","2b25ea27":"################### TEST NO 3\ntest_image_path = '..\/input\/pictures\/hrithik_test.jpg'\ntest_image = cv2.imread(test_image_path)\ntest_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\nplt.imshow(test_image)\n\nfaces_in_picture = recognize_face(test_image_path)\nfor face in faces_in_picture:\n    print(\"There is {}'s face in image\".format(face))","d35e7ef3":"################### TEST NO 4\ntest_image_path = '..\/input\/pictures\/Aftab.jpg'\ntest_image = cv2.imread(test_image_path)\ntest_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\nplt.imshow(test_image)\n\nfaces_in_picture = recognize_face(test_image_path)\nfor face in faces_in_picture:\n    print(\"There is {}'s face in image\".format(face))","02a65208":"################### TEST NO 5\ntest_image_path = '..\/input\/pictures\/rohit_dhoni_test.jpg'\ntest_image = cv2.imread(test_image_path)\ntest_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\nplt.imshow(test_image)\n\nfaces_in_picture = recognize_face(test_image_path)\nfor face in faces_in_picture:\n    print(\"There is {}'s face in image\".format(face))","57276cb8":"Above, we created a function which can be used to draw the rectangle around the faces in any picture. Just we need to pass the RGB image. \nLet's use use this function on our inputed image.","fc3f0295":"Till now, We created a function for detecting the faces in the image which is passed to the function. \n\nSo from here we are going to work on Face Recognition process. ","b9cf49e1":"## Feature Extraction\nSo from here we are going to start image processing. First of all we need a picture on which we will perform feature extraction. So now lets import a image from our device","8be20998":"Run this line of code if you do not have OpenCV\n\n\n!pip install opencv-python","40050f30":"As we can see HOG image removes all unwanted data from the picture and showcases only the important features.","652727b6":"We created some useful function which can help us to capsulize our code, for better understanding and scalability, such as detect_the_face(image_path), and recognize_face(image_path).","65191cb2":"## Conclusion\nWe started with the extracting the features from the image so that it will be easy to train model. Then we used pre-trained model to detect the faces in the picture. and lastly we encoded the faces in the picture and calculated the euclidean distace between known faces and the test faces. If the calculated distance is less than threshold then it's a match for corrosponding known face. ","bc80d536":"## Requirement Analysis\nAs our whole project is going to be in python so we will need some python packages.\n1. os - We will need the os library to access the device folders. \n2. OpenCV - To do operations on the picture\n3. Face_Recognition - For face detection and Recogition\n4. Matplotlib - To display the pictures\n5. skimage - to do feature extraction related tasks.\n\n\nWe will import these libraries differently for each step, so that we can understand which library we will need for which task.","be68ebb1":"# Face Recognition\nFace recognition is machine learning application, in which machine learns to identify the human face in the image. \nAs we know machine learning model need a lots of data, on which we need to train it. Hence to identify a human face in the image we will need lots of pictures with human faces and pictures without human faces. It requires lot time to train this type of model, hence we will use the already trained model, which is very accurate in detecting the faces. Hence we are going to use Face_Recognition package to identification of faces.","bb482727":"This is our input image, on which we are going to perform the feature extraction","500d7cb8":"So till now, we are able to detect the faces in the image. Now let's create a function, using which we can draw the rectangles over the faces in the picture.","32c102a3":"Now we create a function which can be used to recognize the faces in the image. for that we just need to pass path of test image.","310d9dcf":"## Objectives\nTo create a Face Recognition System we will need to achieve following objectives:\n### 1. Requirement Analysis\nIn this step we need to list out the all required packages and tool for development of the system.\n### 2. Feature Extraction \nA image cantain lot of noisy data, so we need to remove those unnecessary data and need to extract the features which will be useful for detecting the faces.\n### 3. Face Detection\nTo recognise the face in a picture we first need to check that is there any human face in the picture or not. and if the human face is in the picture then we need to locate the face in the picture.\n### 4. Face Recognition\nnow, as we located the face in the picture we need to recognize that face. for that we need a database with persone names and there pictures. we will compare the face in the inputed picture and the face in the picture got from database. ","8e8bccc3":"## Face Recognition\n\nHere in face recognition process, it itself has some steps. \n1. Locate and Extract Faces\n  \nWe completed this step above.\n\n\n2. Represent face as features\n\nNow, to recognize the faces we have to represent the faces with unique features, we will call it as encodigs. Here to save our time we will use already trained encoder which will encode the each faces uniquely. So if two faces are same then the encodings of those faces has minimum euclidean distance. So calculating the distance between two faces we can say those faces are of same persone or not.\n3. Compare with known faces\n\nWe have to first create a database for known faces, so we will compare the test image with our known image. \n4. Compute Euclidean distance and Apply Threshold\n\nWe will calculate the Euclidean distance between every known face and the test face. Then we will apply the threshould on it. If euclidean distance for any known face is less than the threshould then that test face is similar to the perticual known face so we can recognize it.\n","657286ea":"## Face Detection \nAs till now we extracted the important features from the image, We need to detect that is there any faces in the image or not. If yes, then how many faces are there. \nFor this we are going to use, already trained model, so that we can save our time.\nFor this operation we are going to use the Face Recognition library which we installed earlier. It is already trained model so with the use of some function we can detect the faces in the image.","05687e01":"So our database is ready with the persone names and there face encoding.\n\nNow we will need a test image to check the difference between the encodings of the known faces and test face. If it matches then we will try to recognize it."}}