{"cell_type":{"142ed8ac":"code","56a4b304":"code","bf556a5b":"code","2f6f059f":"code","34681b6c":"code","5775ca67":"code","b6bbae6c":"code","56473fd7":"code","8f8657ca":"code","2e963038":"code","fdb26b12":"code","dafc8559":"code","0ce1630c":"code","abb970b4":"code","f0bec3b8":"code","ba3446e7":"code","d8f213bc":"code","df848348":"code","c3d9c97f":"code","944c652b":"code","858ae088":"code","7e2eb4a7":"code","e30bb759":"code","b2383f37":"code","30ff2641":"code","4c7bd065":"code","fb3eadaa":"code","58f455af":"code","070df3ac":"markdown","287e0f7b":"markdown","55779ac6":"markdown","1a2a42c3":"markdown","0e9cc2bc":"markdown"},"source":{"142ed8ac":"import os\nimport random\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","56a4b304":"TRAIN_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/train.csv'\nTEST_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/test.csv'\n\nTRAIN_DIRECTORY = '..\/input\/petfinder-pawpularity-score\/train'\nTEST_DIRECTORY = '..\/input\/petfinder-pawpularity-score\/test'","bf556a5b":"TARGET_NAME = 'Pawpularity'\nVAL_SIZE = 0.15\nSEED = 5","2f6f059f":"#Settings and training parameters\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 224\nBATCH_SIZE = 64\nDROPOUT_RATE = 0.2\nLEARNING_RATE = 1e-3\nDECAY_STEPS = 100\nDECAY_RATE = 0.96\nEPOCHS = 500\nPATIENCE = 5","34681b6c":"# Pretrained image classification model EfficientNetB0\n# From https:\/\/www.kaggle.com\/ekaterinadranitsyna\/keras-applications-models\nIMG_MODEL = '..\/input\/keras-applications-models\/EfficientNetB0.h5'","5775ca67":"def set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n    return tf.keras.applications.efficientnet.preprocess_input(image)\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None) -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['root_mean_squared_error']\n    val_rmse = hist.history['val_root_mean_squared_error']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation')\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation')\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","b6bbae6c":"set_seed(SEED)\nset_display()","56473fd7":"# Train data set\ndata_train = pd.read_csv(TRAIN_DATA_PATH)\nprint(f'Train data shape: {data_train.shape}')\ndata_train.head()","8f8657ca":"# From https:\/\/www.kaggle.com\/valleyzw\/petfinder-duplicate-images\nsims = ['13d215b4c71c3dc603cd13fc3ec80181_373c763f5218610e9b3f82b12ada8ae5',\n       '5ef7ba98fc97917aec56ded5d5c2b099_67e97de8ec7ddcda59a58b027263cdcc',\n       '839087a28fa67bf97cdcaf4c8db458ef_a8f044478dba8040cc410e3ec7514da1',\n       '1feb99c2a4cac3f3c4f8a4510421d6f5_264845a4236bc9b95123dde3fb809a88',\n       '3c50a7050df30197e47865d08762f041_def7b2f2685468751f711cc63611e65b',\n       '37ae1a5164cd9ab4007427b08ea2c5a3_3f0222f5310e4184a60a7030da8dc84b',\n       '5a642ecc14e9c57a05b8e010414011f2_c504568822c53675a4f425c8e5800a36',\n       '2a8409a5f82061e823d06e913dee591c_86a71a412f662212fe8dcd40fdaee8e6',\n       '3c602cbcb19db7a0998e1411082c487d_a8bb509cd1bd09b27ff5343e3f36bf9e',\n       '0422cd506773b78a6f19416c98952407_0b04f9560a1f429b7c48e049bcaffcca',\n       '68e55574e523cf1cdc17b60ce6cc2f60_9b3267c1652691240d78b7b3d072baf3',\n       '1059231cf2948216fcc2ac6afb4f8db8_bca6811ee0a78bdcc41b659624608125',\n       '5da97b511389a1b62ef7a55b0a19a532_8ffde3ae7ab3726cff7ca28697687a42',\n       '78a02b3cb6ed38b2772215c0c0a7f78e_c25384f6d93ca6b802925da84dfa453e',\n       '08440f8c2c040cf2941687de6dc5462f_bf8501acaeeedc2a421bac3d9af58bb7',\n       '0c4d454d8f09c90c655bd0e2af6eb2e5_fe47539e989df047507eaa60a16bc3fd',\n       '5a5c229e1340c0da7798b26edf86d180_dd042410dc7f02e648162d7764b50900',\n       '871bb3cbdf48bd3bfd5a6779e752613e_988b31dd48a1bc867dbc9e14d21b05f6',\n       'dbf25ce0b2a5d3cb43af95b2bd855718_e359704524fa26d6a3dcd8bfeeaedd2e',\n       '43bd09ca68b3bcdc2b0c549fd309d1ba_6ae42b731c00756ddd291fa615c822a1',\n       '43ab682adde9c14adb7c05435e5f2e0e_9a0238499efb15551f06ad583a6fa951',\n       'a9513f7f0c93e179b87c01be847b3e4c_b86589c3e85f784a5278e377b726a4d4',\n       '38426ba3cbf5484555f2b5e9504a6b03_6cb18e0936faa730077732a25c3dfb94',\n       '589286d5bfdc1b26ad0bf7d4b7f74816_cd909abf8f425d7e646eebe4d3bf4769',\n       '9f5a457ce7e22eecd0992f4ea17b6107_b967656eb7e648a524ca4ffbbc172c06',\n       'b148cbea87c3dcc65a05b15f78910715_e09a818b7534422fb4c688f12566e38f',\n       '3877f2981e502fe1812af38d4f511fd2_902786862cbae94e890a090e5700298b',\n       '8f20c67f8b1230d1488138e2adbb0e64_b190f25b33bd52a8aae8fd81bd069888',\n       '221b2b852e65fe407ad5fd2c8e9965ef_94c823294d542af6e660423f0348bf31',\n       '2b737750362ef6b31068c4a4194909ed_41c85c2c974cc15ca77f5ababb652f84',\n       '01430d6ae02e79774b651175edd40842_6dc1ae625a3bfb50571efedc0afc297c',\n       '72b33c9c368d86648b756143ab19baeb_763d66b9cf01069602a968e573feb334',\n       '03d82e64d1b4d99f457259f03ebe604d_dbc47155644aeb3edd1bd39dba9b6953',\n       '851c7427071afd2eaf38af0def360987_b49ad3aac4296376d7520445a27726de',\n       '54563ff51aa70ea8c6a9325c15f55399_b956edfd0677dd6d95de6cb29a85db9c',\n       '87c6a8f85af93b84594a36f8ffd5d6b8_d050e78384bd8b20e7291b3efedf6a5b',\n       '04201c5191c3b980ae307b20113c8853_16d8e12207ede187e65ab45d7def117b']","2e963038":"#Filter the lower score out\nless_score_duplicates = []\n\nfor pair in sims:\n    p1, p2 = pair.split('_')\n    t1 = data_train.query(f'Id == \"{p1}\"')['Pawpularity'].values[0]\n    t2 = data_train.query(f'Id == \"{p2}\"')['Pawpularity'].values[0]\n    if(t1<t2):\n        less_score_duplicates.append(p1)\n    else:\n        less_score_duplicates.append(p2)\n    \nless_score_duplicates","fdb26b12":"data_train.shape","dafc8559":"len(less_score_duplicates)","0ce1630c":"data_train = data_train.loc[~data_train['Id'].isin(less_score_duplicates)]\ndata_train.shape","abb970b4":"# Test data set\ndata_test = pd.read_csv(TEST_DATA_PATH)\nprint(f'Test data shape: {data_test.shape}')\ndata_test.head()","f0bec3b8":"# Paths to train and test images.\ndata_train['path'] = data_train['Id'].apply(\n    lambda x: id_to_path(x, TRAIN_DIRECTORY))\ndata_test['path'] = data_test['Id'].apply(\n    lambda x: id_to_path(x, TEST_DIRECTORY))\n\n# Keep a portion of the labeled data for validation.\ntrain_subset, valid_subset = train_test_split(\n    data_train[['path', TARGET_NAME]],\n    test_size=VAL_SIZE, shuffle=True, random_state=SEED\n)","ba3446e7":"train_subset.shape ","d8f213bc":"valid_subset.shape","df848348":"# Create TensorFlow datasets\ntrain_ds = get_dataset(x=train_subset['path'], y=train_subset[TARGET_NAME])\nvalid_ds = get_dataset(x=valid_subset['path'], y=valid_subset[TARGET_NAME])\ntest_ds = get_dataset(x=data_test['path'])","c3d9c97f":"# Pretrained image classification model\nfeature_model = tf.keras.models.load_model(IMG_MODEL)\n\n# Freeze weights in the original model\nfeature_model.trainable = False","944c652b":"#Do random horizontal flip augmentation, and passed them to pretrained feature extraction model\n#Then, do batch normalization, dropout and activations.\nimage_model = tf.keras.models.Sequential(\n    [\n        tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n        feature_model,\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(DROPOUT_RATE, name='top_dropout'),\n        tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.Dense(1, name='score')\n    ]\n)","858ae088":"#Gradually decrease learning rate \nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=LEARNING_RATE,\n    decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n    staircase=True)","7e2eb4a7":"# Compile the model\nimage_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n                    loss=tf.keras.losses.MeanSquaredError(),\n                    metrics=[tf.keras.metrics.RootMeanSquaredError()])","e30bb759":"image_model.summary()","b2383f37":"#Monitor validation loss and stop the training.\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=PATIENCE, restore_best_weights=True)","30ff2641":"history = image_model.fit(train_ds, validation_data=valid_ds,\n                          epochs=EPOCHS, callbacks=[early_stop],\n                          use_multiprocessing=True, workers=-1)","4c7bd065":"plot_history(history)","fb3eadaa":"#Popularity score prediction\ndata_test[TARGET_NAME] = image_model.predict(\n    test_ds, use_multiprocessing=True, workers=os.cpu_count())","58f455af":"data_test[['Id', TARGET_NAME]].to_csv('submission.csv', index=False)\ndata_test[['Id', TARGET_NAME]].head()","070df3ac":"# Predict Pawpularity using EfficientNet Model","287e0f7b":"## Inference","55779ac6":"## Functions","1a2a42c3":"# Define duplicate images list and remove from train set","0e9cc2bc":"## Data Processing"}}