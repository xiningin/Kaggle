{"cell_type":{"2f2b14f2":"code","c8138c83":"code","868f3f6a":"code","02d5e905":"code","67b245ff":"code","4442c112":"code","45b6af60":"code","9078cea8":"code","2c3b6fdf":"code","410442f9":"code","008528a6":"code","0204902b":"code","610268ee":"code","d9306235":"code","65e629c9":"markdown","3651b08f":"markdown","7e34bac9":"markdown","e3e01203":"markdown","6de7e9c9":"markdown","42d9a086":"markdown","43a72441":"markdown","3021143e":"markdown","7e196b66":"markdown","6fa26853":"markdown"},"source":{"2f2b14f2":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\ntreino = pd.read_csv(\"\/kaggle\/input\/usp-pj01\/train_Iris.csv\")","c8138c83":"treino.head()\n","868f3f6a":"#Estat\u00edsticas do conjunto de dados\ntreino.describe()","02d5e905":"#Avaliando se os dados s\u00e3o desequilibrados\ntreino.groupby('Species').SepalLengthCm.count()","67b245ff":"#Grafico com as densidades das variaveis\ntreino2 = treino.iloc[:,1:]\nsns.pairplot(treino2, hue=\"Species\",corner=True)\n","4442c112":"#Mapa de calor em rela\u00e7\u00e3o as correla\u00e7\u00f5es\nsns.heatmap(treino2.corr(),annot=True)","45b6af60":"\nX=treino.iloc[:,1:-1]            #Variavel so com as variaveis (sem as classe)\ny=treino.iloc[:,-1]              #Varavels so com as classes\n","9078cea8":"grid_params = {\n    'n_neighbors':[3,5,9,11,19,29],               \n    'metric':['euclidean','manhattan'],\n}                                             #n\u00famero de vizinhos que quermos que ele teste\nModel = GridSearchCV(                         #medidas de distancia que queremos que ele teste\n    KNeighborsClassifier(),\n    grid_params\n)\n\nfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=23)\nscore = []\nhiperparametros = []\n\nfor train_index, test_index in folds.split(X, y):\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    model = Model\n    model.fit(X_train, y_train)\n    score.append(model.best_score_)\n    hiperparametros.append(model.best_estimator_)\nprint(np.mean(score))\nprint(score)\nprint(hiperparametros)\n","2c3b6fdf":"folds = StratifiedKFold(n_splits=20, shuffle=True, random_state=23)\nscore = []\n\n\nfor train_index, test_index in folds.split(X, y):\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    model = KNeighborsClassifier(metric='euclidean', n_neighbors=11)\n    model.fit(X_train, y_train)\n    score.append(accuracy_score(model.predict(X_val),y_val))\nprint(np.mean(score))\nprint(score)","410442f9":"grid_params = {\n    'gamma': [0.05, 0.1,'scale', 'auto', 0.5],           #valores que queremos que ele teste\n    'C' : [0.5, 1, 2, 5, 7, 10]\n}\nModel = GridSearchCV(\n    svm.SVC(),\n    grid_params\n)\nfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=23)\n\n\nfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=23)\nscore = []\nhiperparametros = []\n\nfor train_index, test_index in folds.split(X, y):\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    model = Model\n    model.fit(X_train, y_train)\n    score.append(model.best_score_)\n    hiperparametros.append(model.best_estimator_)\nprint(np.mean(score))\nprint(score)\nprint(hiperparametros)\n","008528a6":"\nModel = svm.SVC(C=5, gamma=0.1)\nModel2 = svm.SVC(C=2, gamma=0.1)\n\n\nfolds = StratifiedKFold(n_splits=30, shuffle=True, random_state=17)\nscore = []\nscore2 = []\n\nfor train_index, test_index in folds.split(X, y):\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    model = Model\n    model2 = Model2\n    model.fit(X_train, y_train)\n    model2.fit(X_train, y_train)\n    score.append(accuracy_score(model.predict(X_val),y_val))\n    score2.append(accuracy_score(model2.predict(X_val),y_val))\nprint(np.mean(score))\nprint(np.mean(score2))\nprint(score)\nprint(score2)","0204902b":"#Separa o Id das plantas do teste para futuro envio no Kaggle.\nteste = pd.read_csv(\"..\/input\/usp-pj01\/test_Iris.csv\")\ntest_id = teste.Id\nteste.drop(\"Id\", axis = 1, inplace = True)","610268ee":"#Identifica-se o melhor modelo, com a melhor combina\u00e7\u00e3o de hiperpar\u00e2metros\n#  aplicados no conjunto de treino para, agora, aplicar no conjunto de teste.\nmodel = svm.SVC(C=5, gamma=0.1)\n\nmodel.fit(X, y)\ny_pred = model.predict(teste)","d9306235":"#Gera um csv com as predi\u00e7\u00f5es feitas pelo modelo para o conjunto de teste\ntest_id = pd.DataFrame(data = {\"Id\": test_id, \"Category\": y_pred})\ntest_id.to_csv(\"resposta1.csv\", index = False)","65e629c9":"# **Importes e coleta de Dados**","3651b08f":"## Ajustando os hiperpar\u00e2metros da M\u00e1quina de Vetor de Suporte","7e34bac9":"## Ajustando os hiperpar\u00e2metros do modelo. Vamos utilizar o GridSearch dentro de um K-fold.","e3e01203":"## Vamo utilizar a moda encontrada no K-fold como modelo e testar a sua consist\u00eancia com um novo k-fold.\n## KNeighborsClassifier(metric='euclidean', n_neighbors=11)","6de7e9c9":"# **K-Vizinhos (KNN)**","42d9a086":"## Vamos comparar a consit\u00eancia do (C=5, gamma=0.1) com a do SVC(C=2, gamma=0.1)","43a72441":"# **SVM**","3021143e":"# **Preparando os dados para modelagem**","7e196b66":"## Ambos hiperpar\u00e2metros t\u00eam acur\u00e1cia muito parecida, mas vamos optar pelo 'svm.SVC(C=5, gamma=0.1)'","6fa26853":"# **An\u00e1lise explorat\u00f3ria**"}}