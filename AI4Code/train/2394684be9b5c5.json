{"cell_type":{"2b5690c4":"code","16a1db7b":"code","b14f0c74":"code","9c55c519":"code","cfbe3ff8":"code","93e41e90":"code","68c06575":"code","35014803":"code","6dcd338e":"code","e093e648":"code","8d10fa60":"code","300ccbee":"code","81a36a8b":"code","a9054ff2":"code","231f09b9":"code","39beb970":"code","9e9fd8d8":"code","b20d0f77":"code","fdd4acea":"markdown","8b40175f":"markdown","35673254":"markdown","8aeb50e3":"markdown","bba6cb96":"markdown","c28eee7c":"markdown"},"source":{"2b5690c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","16a1db7b":"#Creating Data Frame from my csv file\ndf=pd.read_csv('\/kaggle\/input\/car-prices-poland\/Car_Prices_Poland_Kaggle.csv')\nprint(df)","b14f0c74":"print(df.describe(percentiles=[.8,.2,.5,0.9,0.1]).round()) #The pareto principle is our everything","9c55c519":"#Simple filtr\ndf=df[df['year']>=2008]\ndf=df[df['price']>=13000]\ndf=df[df['price']<=160000]\ndf=df[df['mileage']<=255000]\nprint(df)\n","cfbe3ff8":"print(df['city'].value_counts())\nprint(df['city'].value_counts().describe(percentiles=[0.2,.5,.8]))","93e41e90":"#Finding top locations\ntop_cities=df['city'].value_counts()[:300].index.tolist()\nprint(top_cities[:20])","68c06575":"#Now we needto create new column with new location\ndf['location']=[list(i)[0] if list(i)[0] in top_cities else list(i)[1] for i in df[['city','province']].values]\nprint(df['location'].value_counts()[-20:])","35014803":"#Removing wrong places\ndropping=df['location'].value_counts().index[-5:].tolist()\nfor i in dropping:\n    df=df[df['location']!=i]","6dcd338e":"#Round vol_engine\ndf['vol_engine']=df['vol_engine'].round(-2)\nprint(df)","e093e648":"#Replacing n\/a data\ndf['generation_name'].fillna('No_gen',inplace=True)\n#Create new name\ndf['name']=df['mark']+\" \"+df['model']+\" \"+df['generation_name']\nprint(len(df['name'].unique()))","8d10fa60":"#Creating \"new\" column\ndf['new']=[1 if i[0]<999 and i[1]>2020 else 0 for i in df[['mileage','year']].values.tolist()]\nprint(df['new'].value_counts())\n\n#Save DF for \ndf.to_csv('ready_df')","300ccbee":"#Some my functions for normalization \n\n#Create dict={item:noraml_item}\ndef get_dict_items(items):\n    dict_model_arr={}\n    items=list(set(items))\n    number_items=len(items)\n    for i in items:\n        base_arr = [(lambda x: 0)(x) for x in range(number_items)]\n        model_arr=base_arr\n        model_arr[items.index(i)]=1\n        dict_model_arr.update({i:model_arr})    \n    return dict_model_arr\n\n#List of normal items from dcit\ndef get_norm_items(dict_items,items):\n    norm_items=[]\n    for i in items:\n        norm_items.append(dict_items[i])\n    return norm_items\n\n#Numbers normalization\ndef get_norm_numbers(numbers):\n    min_n=min(numbers)\n    max_n=max(numbers)\n    range_=max_n-min_n\n    norm_numbers=[]\n    for n in numbers:\n        norm_n=(n-min_n)\/range_\n        norm_numbers.append([norm_n])\n    return norm_numbers\n\n#Some lists to one\ndef tog_lists(lists):\n    data=[]\n    for l in lists:\n        data+=l\n    return np.array(data)\n","81a36a8b":"#Creating input, output and test data for model\n\n#Shuffle data\ndf=df.sample(frac=1)\n# df=df[:1000]\n\n\n#DF normalization\n#Numeric data are without vol_engine because it doesn't matter for electric engine \nnumeric_data=['year','mileage','price'] \nitem_data=['vol_engine','fuel','location','name','new']\n\n#Creating new DF for normalized data\nnorm_df=pd.DataFrame()\n\n#Create normalized columns with numeric data \nfor column in numeric_data:\n    norm_df[column]=get_norm_numbers(df[column].values.tolist())\n\n#Create normalized columns with list data \nnormalization_dict={} #I'll save this dict for outside normalization\nfor column in item_data:\n    items=df[column].values.tolist()\n    dict_items=get_dict_items(items)\n    normalization_dict.update({column:dict_items})\n    norm_df[column]=get_norm_items(dict_items,items)\n\n#Save dict for normalization in telegram bot\nimport json\nwith open('normalization_dict.json', 'w') as f:\n    json.dump(normalization_dict, f)\n\n\n#Create output data for keras \noutput_data=np.array(norm_df['price'].values.tolist())\n\n#Create input data for keras \n#Remove output column\ncolumns=norm_df.columns.tolist()\ncolumns.remove('price')\ninput_data=np.array([tog_lists(list(i)) for i in norm_df[columns].values])\n\n#Few tests\nprint(input_data[:2])\nprint(len(input_data))\nprint(len(output_data))\nprint(type(input_data))\nprint(len(input_data[0]))","a9054ff2":"#6,2\n# Create keras model\nimport keras as k\nmodel=k.Sequential()\nmodel.add(k.layers.Dense(units=1024*4,activation=\"relu\"))\nmodel.add(k.layers.Dense(units=1024*4,activation=\"relu\"))\nmodel.add(k.layers.Dense(units=1024*4,activation=\"relu\"))\nmodel.add(k.layers.Dense(units=1,activation=\"sigmoid\"))\nmodel.compile(loss='mean_absolute_percentage_error',optimizer='adamax',metrics=['accuracy'])\nfit_results=model.fit(x=input_data[:],y=output_data[:],epochs=120,\n                      validation_split=0.05,\n                      batch_size=10\n                    )\nmodel.summary()\n\n# # Create keras model\n# import keras as k\n# model=k.Sequential()\n# model.add(k.layers.Dense(units=1024*2,activation=\"relu\"))\n# model.add(k.layers.Dense(units=1024*2,activation=\"relu\"))\n# model.add(k.layers.Dense(units=1024*2,activation=\"relu\"))\n# model.add(k.layers.Dense(units=1,activation=\"sigmoid\"))\n# model.compile(loss='mean_absolute_percentage_error',optimizer='adamax',metrics=['accuracy'])\n# fit_results=model.fit(x=input_data[:],y=output_data[:],epochs=80,\n#                       validation_split=0.1,\n#                       batch_size=16\n#                     )\n# model.summary()\n\n\n","231f09b9":"#Save and zip model\nmodel.save('Car_prices_test_model')\n!zip -r model_car_prices.zip .\/Car_prices_test_model","39beb970":"#Check model\nfrom matplotlib import pyplot as plt\nplt.title ('Accuracy train\/validation')\nplt.plot(fit_results.history['accuracy'],label=\"Train\")\nplt.plot(fit_results.history['val_accuracy'],label=\"Validation\")\nplt.legend()\nplt.show()","9e9fd8d8":"#Check model\nplt.title ('Losses train\/validation')\nplt.plot(fit_results.history['loss'][10:],label=\"Train\")\nplt.plot(fit_results.history['val_loss'][10:],label=\"Validation\")\nplt.legend()\nplt.show()","b20d0f77":"#Test model\nimport random\n#Test model\ntest_sample=1000\nrandom_indexes=[random.randint(0,len(input_data)) for x in range(test_sample)]\ntest_data = [input_data[x] for x in random_indexes]\noutput=[output_data[x] for x in random_indexes] \npredicted_test=model.predict(np.array(test_data)).tolist()\n\nn=0\nfor i in range(1,test_sample):\n    error=(output[i][0]\/predicted_test[i][0])*100-100\n    if error>5:\n        n+=1\n        print(f\"reality:{output[i][0]}; forecast:{predicted_test[i][0]};error:{error}%\")\nprint(f'{n} errors more than 5% in {test_sample} samples')","fdd4acea":"So it works! But some not-polish places here. Remove it!","8b40175f":"Now I'd like to add column NEW. if car has 2021-2022 year and millage below 1.000 km it will be mark as new \n","35673254":"So I will not use vol_engine as numeric data because we have hybrids and electric cars and theay have other rules, also demand is determined by people and people see vol_engine like 1.2, 1.9, 3.0 not like 1221cm3 1897cm3 or 2980cm3. So I round this data ","8aeb50e3":"I know that some models don't have generations but it is important option because same models can have few generations at same time. And this difference can determine the price. So I combine this data","bba6cb96":"Here we can see that 80% cities has less than 12 listings.here is 3323 So I'd like to use about 10% cites it is first 300.\n\nWe will have city if it is in top of Poland cities or We will have only one province as location factor","c28eee7c":"We can see that 90% cars have price below ~160k PLN and 90% above ~13k PLN\n\nAlso 80% are newer than 2008 year \n\nAnd just 10% have milage more than 255.000 KM\n\nSo for my model I will use this confine. It willhelps minmax normalazing"}}