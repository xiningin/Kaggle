{"cell_type":{"a3205d92":"code","cb76f58a":"code","c7c29939":"code","56808d65":"code","88f5fd38":"code","67d698a9":"code","98b9a2ae":"code","1c694f22":"code","67aae427":"code","cbc35bf4":"code","6a51a1a7":"code","3f5bf726":"code","c51210bc":"code","cb35f19a":"code","02c04811":"code","e0333285":"code","5a5ec238":"code","67a306ea":"code","acdd2de7":"code","d916bf36":"code","a4683574":"code","f3f647e3":"code","cc06d119":"code","81457b12":"code","dfbdfdab":"code","3950b4e1":"code","040dfdd9":"code","aabe9e03":"code","5e94d946":"code","8742ca16":"code","a28c7aaf":"code","a1f595b2":"code","b2da3c92":"code","faa2ab62":"code","1a64c8db":"code","568f51a8":"code","c039e907":"code","361b9e15":"code","03204dd6":"code","db5cd762":"markdown","54c6115b":"markdown","a167efde":"markdown","e2cff984":"markdown","a0825747":"markdown","4da8e157":"markdown","34a0a0c5":"markdown","5567bd85":"markdown","97c84990":"markdown","3abd9e38":"markdown","60d29353":"markdown","a52f7503":"markdown","b5be03be":"markdown","03cf471a":"markdown","fd0bcf73":"markdown","05524f0f":"markdown"},"source":{"a3205d92":"import numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport random\n\n#plotly packages\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tools","cb76f58a":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","c7c29939":"print('There are ',train.shape[0],'rows and ',train.shape[1],'columns in the train dataset')\nprint('There are ',test.shape[0],'rows and ',test.shape[1],'columns in the test dataset')","56808d65":"train.head(5)","88f5fd38":"print(list(train.columns))","67d698a9":"data = go.Histogram(x=train.SalePrice)\nfig = [data]\npy.iplot(fig)","98b9a2ae":"data = go.Histogram(x=np.log(train.SalePrice))\nfig = [data]\npy.iplot(fig)","1c694f22":"#Saving the log_price variables\nSalesPrice_log = np.log(train.SalePrice)\nSalePrice = train.SalePrice\nId = train.Id","67aae427":"#Removing the ID and SalePrice Variable\ntrain = train.drop(['Id','SalePrice'], 1)\ntest = test.drop(['Id'], 1)\nprint(train.shape)\nprint(test.shape)","cbc35bf4":"#Combining the train and testing dataset\ntrain_test = pd.concat([train,test], axis=0, sort=False)\ntrain_test.shape","6a51a1a7":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ntrain_num = train.select_dtypes(include=numerics)","3f5bf726":"columns_to_rem =  train_num.columns.tolist()\ntrain_cat = train[train.columns.difference(columns_to_rem)]","c51210bc":"def missing_values(df):\n    percent_missing = df.isnull().sum() * 100 \/ len(df)\n    missing_value_df = pd.DataFrame({'column_name': df.columns,\n                                     'percent_missing': percent_missing})\n    return missing_value_df\n\nmissing_values(train_num).sort_values(by=['percent_missing'], ascending = False).head()","cb35f19a":"#Filling the missing values with mean\ntrain_num = train_num.fillna(train_num.mean())","02c04811":"from scipy.stats import zscore\n\nz = train_num.apply(zscore)\nthreshold = 3\nnp.where(z > 10)","e0333285":"Q1 = train_num.quantile(0.25)\nQ3 = train_num.quantile(0.75)\nIQR = Q3 - Q1","5a5ec238":"#Identifying rows to remove using the z-score and the interquartile range\nprint(train_num.shape)\ntrain_num = train_num[(z < 10).all(axis=1)]\nprint(train_num.shape)","67a306ea":"#Identifying rows to remove using the interquartile range\n#ts = 20\n#train_num = train_num[~((train_num < (Q1 - ts * IQR)) |(train_num > (Q3 + ts * IQR))).any(axis=1)]\n#train_num.shape","acdd2de7":"train_test_num = pd.concat([train_num,test[list(train_num.columns)]])\ntrain_test_num.head()","d916bf36":"#Filling the missing values with mean\ntrain_test_num = train_test_num.fillna(train_test_num.mean())","a4683574":"profile = pp.ProfileReport(train_test_num)","f3f647e3":"profile","cc06d119":"from scipy.stats import skew\n\nskew_features = train_test_num.apply(lambda x: skew(x)).sort_values(ascending=False)\nskews = pd.DataFrame({'skew':skew_features})\nskews.head()","81457b12":"from scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n#Setting threshold for skew\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\n#creating a new df for skew\ntrain_test_num_skew = pd.DataFrame()\n\nfor i in skew_index:\n    train_test_num_skew[i]= boxcox1p(train_test_num[i], boxcox_normmax(train_test_num[i]+1))\n\n#Changing col names of new df\nskew_cols = [s + '_skew' for s in list(train_test_num_skew.columns)]\n\ntrain_test_num_skew.columns = skew_cols\ntrain_test_num_skew.head()","dfbdfdab":"print(train_test_num[skew_index].shape) \nprint(train_test_num_skew.shape)\n\ntrain_test_skew_compare = pd.concat([train_test_num[skew_index],train_test_num_skew], axis = 1)\ntrain_test_skew_compare = train_test_skew_compare.reindex(sorted(train_test_skew_compare.columns), axis=1)\ntrain_test_skew_compare.head()","3950b4e1":"def pick_color():\n    colors = [\"blue\",\"black\",\"brown\",\"red\",\"yellow\",\"green\",\"orange\",\"beige\",\"turquoise\",\"pink\"]\n    random.shuffle(colors)\n    return colors[0]\n\ndef Hist_plot(data,i):\n    trace0 = go.Histogram(\n        x= data.iloc[:,i],\n        name = str(data.columns[i]),\n        nbinsx = 100,\n        marker= dict(\n            color=pick_color(),\n            line = dict(\n                color = 'black',\n                width = 0.5\n              ),\n        ),\n        opacity = 0.70,\n  )\n    fig_list = [trace0]\n    title = str(data.columns[i])\n    return fig_list, title\n    \ndef Plot_grid(data, ii, ncols=2):\n    plot_list = list()\n    title_list = list()\n    \n    #Saving all the plots in a list\n    for i in range(ii):\n        p = Hist_plot(data,i)\n        plot_list.append(p[0])\n        title_list.append(p[1])\n    \n    #Creating the grid\n    nrows = max(1,ii\/\/ncols)\n    i = 0\n    fig = tools.make_subplots(rows=nrows, cols=ncols, subplot_titles = title_list)\n    for rows in range(1,nrows+1):\n        for cols in range(1,ncols+1):\n            fig.append_trace(plot_list[i][0], rows, cols)\n            i += 1\n    fig['layout'].update(height=400*nrows, width=1000)\n    return py.iplot(fig)\n","040dfdd9":"Plot_grid(train_test_skew_compare,len(train_test_skew_compare.columns),2)","aabe9e03":"#Combinig the skewed data with the original train test dataset\ntrain_test_num = pd.concat([train_test_num, train_test_num_skew], axis = 1)\ntrain_test_num.shape","5e94d946":"#Lets check how the data looks like when BsmtFinSF1 is zero for columns that contain Bsmt\nbsmt_cols = [col for col in train_test if 'Bsmt' in col]\ntrain_bsmt = train[bsmt_cols][train['BsmtFinSF1']== 0]\ntrain_bsmt.head(10)\n","8742ca16":"def compare_df(data1, data2, column_name):\n    data1 = data1.filter(regex = column_name).iloc[:,0]\n    df1 = pd.DataFrame(data1.value_counts(normalize=True) * 100)\n    \n    data2 = data2.filter(regex = column_name).iloc[:,0]\n    df2 = pd.DataFrame(data2.value_counts(normalize=True) * 100)\n    \n    df3 = pd.merge(df1,df2, how='outer', left_index=True, right_index=True)\n    \n    return df3\n\ntrain_bsmt_cat = train_bsmt.select_dtypes(exclude=[\"number\",\"bool_\"])\n\nfor col in train_bsmt_cat.columns:\n    print(compare_df(train_bsmt,train,col))","a28c7aaf":"train_test_num['BsmtFinSF1'] = np.where(train_test_num['BsmtFinSF1'] <= 0, -1,train_test_num['BsmtFinSF1'])","a1f595b2":"train_bsmt = train[bsmt_cols][train['BsmtFinSF2']== 0]\nfor col in train_bsmt_cat.columns:\n    print(compare_df(train_bsmt,train,col))","b2da3c92":"train_test_num['BsmtFinSF2'] = np.where(train_test_num['BsmtFinSF2'] <= 0, -1,train_test_num['BsmtFinSF2'])","faa2ab62":"missing_values(train_test_num).sort_values(by=['percent_missing'], ascending = False).head()","1a64c8db":"train_test_cat = pd.concat([train_cat,test[list(train_cat.columns)]])\ntrain_test_cat.head()","568f51a8":"missing_values(train_test_cat).sort_values(by=['percent_missing'], ascending = False)","c039e907":"profile = pp.ProfileReport(train_test_cat)","361b9e15":"profile","03204dd6":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","db5cd762":"Removing missing values manually will be done in a later version","54c6115b":"Lets try the log of the target varirable","a167efde":"## Model Development","e2cff984":"> **EDA and Basic Model**\n\n- For EDA I would be using the pandas profiling package (since that does a lot of the EDA for me) and will make changes to individual variable from there. If you have not looked at pandas profiling package then you should because it is a very powerful EDA package\n- The next step would be to create a simple GLM model and a RF model\n- I will then use the H2O package to run the model\n- Compare the results of manual tweaking vs H2O model","a0825747":"## Looking at the Target Variable","4da8e157":"## Skew Features","34a0a0c5":"Before normalizing, I would need to combine the test and train numeric dataset.","5567bd85":"**Variable**: BsmtFinSF1  \n**Comments**: ~32.0% are zeros and there are also some extreme values (>2000)  \n**Findings**: Looks like there are zeros whererever the BsmtFinType1 and BsmtFinType2 is Unf (Unfinished). These basement sqft is not actually zero. I would have to convert it to -1.\nI will also remove rows greater than 2000 (4 rows)","97c84990":"# Normalizing values based on Box-Cox Transformation","3abd9e38":"#### Removing outliers from numerical data using z-score and IQR (Interquartile Range) ","60d29353":"## Categorical Variables EDA","a52f7503":"# Removing Extreme Values from Train Dataset and Identifying Columns to Remove","b5be03be":"**Variable**: BsmtFinSF2  \n**Comments**: ~88.0% are zeros  \n**Findings**: This tells us that BsmtFinSF2 is zero when the Basement2 is unfinished. I will change it to -1","03cf471a":"## Numerical data EDA","fd0bcf73":"## Splitting the data into numerical and categorical","05524f0f":"Lets look at the transformations"}}