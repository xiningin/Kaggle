{"cell_type":{"2fda04de":"code","4a702ac9":"code","2acd4394":"code","1db5c91f":"code","209833e9":"code","20aa4a6f":"code","6ab31a93":"code","541da91d":"code","44da13f2":"code","7aea7a80":"code","b7fad57f":"code","b9797b2b":"code","5af190b0":"markdown","3c251346":"markdown","4baad7ef":"markdown","8b14ac78":"markdown","34e7effd":"markdown"},"source":{"2fda04de":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\nfrom PIL import Image","4a702ac9":"class PokemonDataset(Dataset):\n    def __init__(self, data_dir='..\/input\/pokemon-mugshots-from-super-mystery-dungeon\/smd\/smd', transforms=None):\n        self.files = [os.path.join(data_dir, file) for file in os.listdir(data_dir)]\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.files)\n    \n    def __getitem__(self, index):\n        img = Image.open(self.files[index])\n        if self.transforms is not None:\n            img = self.transforms(img)\n        return img","2acd4394":"img_size = (64, 64)\nimage_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize(img_size),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\nbatch_size = 128\ntrainloader = DataLoader(\n    PokemonDataset(transforms=image_transforms),\n    batch_size = batch_size,\n    shuffle = True,\n    num_workers = 2,\n)","1db5c91f":"class PixelNorm(nn.Module):\n    def __init__(self, eps=1e-8):\n        super(PixelNorm, self).__init__()\n        self.eps = eps\n        \n    def forward(self, x):\n        return x \/ torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.eps)\n    \nclass Generator(nn.Module):\n    def __init__(self, z_channels, out_channels=3):\n        super(Generator, self).__init__()\n        \n        convs = []\n        channels = [z_channels, 1024, 512, 256, 128, 64]\n        for i in range(1, len(channels)):\n            convs.append(nn.ConvTranspose2d(channels[i-1], channels[i], 2, stride=2, bias=False))\n            convs.append(PixelNorm())\n            convs.append(nn.LeakyReLU(0.2, inplace=True))\n        convs.append(nn.ConvTranspose2d(channels[-1], out_channels, 2, stride=2, bias=False))\n        convs.append(nn.LeakyReLU(0.2, inplace=True))\n        \n        self.convs = nn.Sequential(*convs)\n        \n    def forward(self, x):\n        return self.convs(x)\n    \nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        channels = [3, 64, 128, 256, 512, 1024] # size: 64->32->16->8->4\n        convs = []\n        for i in range(1, len(channels)):\n            convs.append(nn.Conv2d(channels[i-1], channels[i], 3, padding=1, stride=2, bias=False))\n            convs.append(PixelNorm())\n            convs.append(nn.LeakyReLU(0.2, inplace=True))\n        \n        convs.append(nn.Conv2d(channels[-1], 1, 2, bias=False))\n        \n        self.convs = nn.Sequential(*convs)\n    \n    def forward(self, x):\n        x = self.convs(x)\n        return x.view(-1)","209833e9":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","20aa4a6f":"z_channels = 512\nG = Generator(z_channels, 3)\nG.apply(weights_init)\nD = Discriminator()\nD.apply(weights_init)\n\ncuda = torch.cuda.is_available()\nif cuda:\n    print('Use GPU')\n    G = G.cuda()\n    D = D.cuda()\nelse:\n    print('No GPU')","6ab31a93":"lr = 1e-3\noptimizer_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.0, 0.99))\noptimizer_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.0, 0.99))","541da91d":"def gradient_penalty(netD, real_img, fake_img, LAMDA=10, cuda=True):\n    batch_size = real_img.size(0)\n    alpha = torch.rand(batch_size, 1)\n    alpha= alpha.expand(batch_size, real_img.nelement()\/\/batch_size).reshape(real_img.shape)\n    if cuda:\n        alpha = alpha.cuda()\n    x = (alpha * real_img + (1-alpha) * fake_img).requires_grad_(True)\n    if cuda:\n        x = x.cuda()\n    out = netD(x)\n    \n    grad_outputs = torch.ones(out.shape)\n    if cuda:\n        grad_outputs = grad_outputs.cuda()\n        \n    gradients = torch.autograd.grad(outputs=out, inputs=x, grad_outputs=grad_outputs, create_graph=True, only_inputs=True)[0]\n    gradients = gradients.reshape(batch_size, -1)\n    \n    return LAMDA * ((gradients.norm(2, dim=1)-1)**2).mean()","44da13f2":"noise_mean = 0\nnoise_std = 1\nepoches = 500\nG_loss_list = []\nD_loss_list = []\nfixed_z = torch.normal(noise_mean, noise_std, size=(64, z_channels, 1, 1))\nif cuda:\n    fixed_z = fixed_z.cuda()\nout_imgs = []\n    \nfor epoch in range(epoches):\n    for i, img in enumerate(trainloader):\n        z = torch.normal(noise_mean, noise_std, size=(img.size(0), z_channels, 1, 1))\n        if cuda:\n            img, z = img.cuda(), z.cuda()\n        \n        # train D\n        D.zero_grad()\n        loss_real = -D(img).mean()\n        fake_img = G(z).detach()\n        loss_fake = D(fake_img).mean()\n        gp = gradient_penalty(D, img.detach(), fake_img, LAMDA=10, cuda=cuda)\n        loss_D = loss_real + loss_fake + gp\n        loss_D.backward()\n        optimizer_D.step()\n        \n        \n        # train G\n        z = torch.normal(0, 1, size=(img.size(0), z_channels, 1, 1))\n        if cuda:\n            z = z.cuda()\n        G.zero_grad()\n        loss_G = -D(G(z)).mean()\n        loss_G.backward()\n        optimizer_G.step()\n\n        D_loss_list.append(loss_D.item())\n        G_loss_list.append(loss_G.item())\n            \n    print(f'[Epoch {epoch+1}\/{epoches}] [G loss: {loss_G.item()}] [D loss: {loss_D.item()} | loss_real: {loss_real.item()} loss_fake: {loss_fake.item()}]')\n    \n    if (epoch+1) % 10 == 0:\n        with torch.no_grad():\n            out_img = make_grid(G(fixed_z), padding=2, normalize=True).cpu().permute(1,2,0).numpy()\n            out_imgs.append(out_img)","7aea7a80":"plt.plot(G_loss_list, label='G')\nplt.plot(D_loss_list, label='D')\nplt.legend()\nplt.show()","b7fad57f":"from matplotlib import animation, rc\nfrom IPython.display import HTML\nimport numpy as np\n\nrc('animation', html='jshtml')\nrc('animation', embed_limit=100.0)\n\ndef create_animation(ims):\n    fig = plt.figure(figsize=(10, 10))\n    plt.axis('off')\n    im = plt.imshow(ims[0])\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 500)\n\nout_imgs = np.stack(out_imgs)\n\ncreate_animation(out_imgs)","b9797b2b":"plt.figure(figsize=(10, 10))\nplt.imshow(out_imgs[-1, :, :])\nplt.show()","5af190b0":"# Dataset","3c251346":"# DCGAN with pixel norm","4baad7ef":"# optimizers and WGAN loss","8b14ac78":"# Train","34e7effd":"# Results"}}