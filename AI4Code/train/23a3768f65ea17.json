{"cell_type":{"53572847":"code","9a1443de":"code","5c636eb9":"code","bdaf6318":"code","8da7d031":"code","c327dfb2":"code","3cdf6740":"code","fad8649b":"code","71c711ee":"code","30a71e74":"code","dd246471":"code","b00181be":"code","005e1b05":"code","e6e5224c":"code","4060a42e":"code","dc06b105":"code","b49c929c":"code","45c80d6f":"code","00c2f047":"code","e4e0c329":"code","4c740831":"code","96c1433e":"code","e3a8baf2":"code","8c0965b4":"code","02b39a49":"code","701a6050":"code","1ca06939":"code","422d6e4d":"code","32cc19b7":"code","1e48d59a":"code","be91d6f7":"code","2fe479b6":"code","fb25ed5b":"code","dd847897":"code","3a25ed1d":"code","0e74e1e6":"code","46a7d31c":"code","850a6afc":"code","12a725f4":"code","aef1edca":"code","fbd80975":"code","1352f201":"code","828231a7":"code","f7ef7ee3":"code","17d705ef":"code","e0b3bd12":"code","0b2c804a":"code","3edb6ed0":"code","caf43d5a":"code","da8ee212":"code","03dab279":"code","ab3d7b2a":"code","b94987de":"code","77306288":"code","ca6ccd48":"code","80543dbc":"code","3c00648a":"code","67f27134":"code","c22ec5b7":"code","55e2052e":"code","aa8b537d":"code","a8968453":"code","faf218b7":"code","569bb526":"code","e8018dd1":"code","a07bc4f4":"code","fe89f1b2":"code","dc68eb9b":"code","732b572f":"code","c0642a4c":"code","8c08e1c5":"markdown","683413ec":"markdown","41e1cd34":"markdown","da0933c2":"markdown","80af26eb":"markdown","416519a7":"markdown","120791f3":"markdown","2d35ab80":"markdown","e93f5924":"markdown","12011454":"markdown","4b568a41":"markdown","f009d67c":"markdown","b5995354":"markdown","9d2223a1":"markdown","d85baa83":"markdown","ad6674f3":"markdown","db95e31f":"markdown","635074bd":"markdown","a804a17c":"markdown","a65702d4":"markdown","8e087206":"markdown","c7723f4f":"markdown","31f8500d":"markdown","259e10ad":"markdown","e95f8bfa":"markdown","f2c523ae":"markdown","b9d29235":"markdown","8129a75d":"markdown","833ffc7f":"markdown","a5c671e5":"markdown","f20a8e7c":"markdown","f9b20f2e":"markdown","9a840c79":"markdown","716b5e5d":"markdown","01a04d19":"markdown","5edeb785":"markdown","c150510f":"markdown","9e651516":"markdown","b241d11d":"markdown","0fbf8ed5":"markdown","28424267":"markdown","b9e450ed":"markdown","e5ba089f":"markdown","b60988b1":"markdown","90eddb1c":"markdown","9057fd69":"markdown","70979232":"markdown","9451226b":"markdown","091e6661":"markdown","38472e31":"markdown","d5c9d32c":"markdown","7b4dadf7":"markdown","4a53f171":"markdown","1b161ac6":"markdown","c1bbe5d2":"markdown","7f542261":"markdown","a0994517":"markdown","4db8c963":"markdown","8226a081":"markdown","09923993":"markdown","3833093e":"markdown","18f45b4d":"markdown","17133cf3":"markdown","1b231b46":"markdown","24a6330c":"markdown","fd13f06b":"markdown","ea0c72c4":"markdown","d8d66c37":"markdown","d1d99606":"markdown"},"source":{"53572847":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","9a1443de":"data = pd.read_csv('..\/input\/gtd\/globalterrorismdb_0718dist.csv' ,encoding= 'ISO-8859-1')  \nprint(f'Data Shape is {data.shape}')\ndata.head()","5c636eb9":"def drop(feature) :\n    global data\n    data.drop([feature],axis=1, inplace=True)\n    data.head()\n\ndef unique(feature) : \n    global data\n    print(f'Number of unique vaure are {len(list(data[feature].unique()))} which are : \\n {list(data[feature].unique())}')\n\ndef unique_all(show_value = True) : \n    global data\n    for col in data.columns : \n        print(f'Length of unique data for   {col}   is    {len(data[col].unique())} ')\n        if show_value == True  : \n            print(f'unique values ae {data[col].unique()}' )\n            print('-----------------------------')\n\ndef drop_nulls(percentage = 0.3) : \n    global data\n    for col in data.columns : \n        ratio =  data[col].isna().sum()\/data.shape[0]\n        if ratio >= percentage : \n            data.drop([col],axis=1, inplace=True)\n            print(f'Column {col} has been dropped since nulls percentage is {round(ratio *100)} %')\n\ndef count_nulls() : \n    global data\n    for col in data.columns : \n        if not data[col].isna().sum() == 0 : \n            print(f'Column {col} has been number of nulls {data[col].isna().sum()}')\n\n\ndef fillna(feature , val = 'none') : \n    global data\n    data[feature].fillna(val, inplace=True)\n\ndef cplot(feature) : \n    global data\n    sns.countplot(x=feature, data=data,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))\n\ndef spie(series) : \n    global data\n    plt.pie(series.values,labels=list(series.index),autopct ='%1.2f%%',labeldistance = 1.1,explode = [0.05 for i in range(len(series.values))])\n    plt.show()\n\ndef pie(feature) : \n    global data\n    plt.pie(data[feature].value_counts(),labels=list(data[feature].value_counts().index),\n        autopct ='%1.2f%%' , labeldistance = 1.1,explode = [0.05 for i in range(len(data[feature].value_counts()))] )\n    plt.show()\n\ndef make_xy(feature) : \n    global data\n    X = data.drop([feature], axis=1, inplace=False)\n    y = data[feature]\n    return X , y\n   \ndef encoder(feature , new_feature, drop = True) : \n    global data\n    enc  = LabelEncoder()\n    enc.fit(data[feature])\n    data[new_feature] = enc.transform(data[feature])\n    if drop == True : \n        data.drop([feature],axis=1, inplace=True)\n    \ndef max_counts(feature, number, return_rest = False) : \n    global data\n    counts = data[feature].value_counts()\n    values_list = list(counts[:number].values)\n    rest_value =  sum(counts.values) - sum (values_list)\n    index_list = list(counts[:number].index)\n\n    if return_rest : \n        values_list.append(rest_value )\n        index_list.append('rest items')\n\n    result = pd.Series(values_list, index=index_list)\n\n    if len(data[feature]) <= number : \n        result = None\n    return result\n\ndef remove_zero(feature , val = 0) :\n    global data\n    data = data[data[feature] != val]\n    \ndef show_details() : \n    global data\n    for col in data.columns : \n        print(f'for feature : {col}')\n        print(f'Number of Nulls is   {data[col].isna().sum()}')\n        print(f'Number of Unique values is   {len(data[col].unique())}')\n        print(f'random Value {data[col][0]}')\n        print(f'random Value {data[col][10]}')\n        print(f'random Value {data[col][20]}')\n        print('--------------------------')\n","bdaf6318":"data.shape","8da7d031":"drop_nulls()","c327dfb2":"data.shape","3cdf6740":"drop('eventid')\ndrop('country')\ndrop('region')\ndrop('attacktype1')\ndrop('targtype1')\ndrop('targsubtype1')\ndrop('natlty1')\ndrop('weaptype1')\ndrop('weapsubtype1')","fad8649b":"data.head()","71c711ee":"unique_all(False)","30a71e74":"count_nulls()","dd246471":"show_details()","b00181be":"unique('iyear')","005e1b05":"cplot('iyear')","e6e5224c":"unique('imonth')","4060a42e":"data.shape[0]","dc06b105":"remove_zero('imonth')","b49c929c":"data.shape[0]","45c80d6f":"unique('imonth')","00c2f047":"cplot('imonth')","e4e0c329":"unique('iday')","4c740831":"remove_zero('iday')","96c1433e":"unique('iday')","e3a8baf2":"data.shape[0]","8c0965b4":"unique('extended')","02b39a49":"data['latitude'].isna().sum()","701a6050":"fillna('latitude',0)\nremove_zero('latitude')","1ca06939":"data['latitude'].isna().sum()","422d6e4d":"data.shape[0]","32cc19b7":"fillna('longitude',0)\nremove_zero('longitude')\ndata['longitude'].isna().sum()","1e48d59a":"data.shape[0]","be91d6f7":"data['specificity'].isna().sum()","2fe479b6":"data['vicinity'].isna().sum()","fb25ed5b":"data['doubtterr'].isna().sum()","dd847897":"unique('doubtterr')","3a25ed1d":"fillna('doubtterr',33)\nremove_zero('doubtterr',33)\ndata['doubtterr'].isna().sum()","0e74e1e6":"data['multiple'].isna().sum()","46a7d31c":"unique('multiple')","850a6afc":"fillna('multiple',33)\nremove_zero('multiple',33)\ndata['multiple'].isna().sum()","12a725f4":"data['guncertain1'].isna().sum()","aef1edca":"unique('guncertain1')","fbd80975":"fillna('guncertain1',33)\nremove_zero('guncertain1',33)\ndata['guncertain1'].isna().sum()","1352f201":"pie('guncertain1')","828231a7":"unique('nkill')","f7ef7ee3":"fillna('nkill',999999)\nremove_zero('nkill',999999)\ndata['nkill'].isna().sum()","17d705ef":"victims = max_counts('nkill',10, True)\nvictims","e0b3bd12":"spie(victims)","0b2c804a":"data['nwound'].isna().sum()","3edb6ed0":"unique('nwound')","caf43d5a":"fillna('nwound',999999)\nremove_zero('nwound',999999)\ndata['nwound'].isna().sum()","da8ee212":"wounded = max_counts('nwound',10, True)\nwounded","03dab279":"spie(wounded)","ab3d7b2a":"data['ishostkid'].isna().sum()","b94987de":"unique('ishostkid')","77306288":"fillna('ishostkid',33)\nremove_zero('ishostkid',33)\ndata['ishostkid'].isna().sum()","ca6ccd48":"data.shape","80543dbc":"count_nulls()","3c00648a":"fillna('provstate','other')\nfillna('city','other')\nfillna('targsubtype1_txt','other')\nfillna('corp1','other')\nfillna('target1','other')\nfillna('natlty1_txt','other')\nfillna('weapsubtype1_txt','other')","67f27134":"count_nulls()","c22ec5b7":"encoder('provstate','provstate_code',True)\nencoder('city','city_code',True)\nencoder('targsubtype1_txt','targsubtype_code',True)\nencoder('corp1','corp_code',True)\nencoder('target1','target_code',True)\nencoder('natlty1_txt','natlty_code',True)\nencoder('weapsubtype1_txt','weapsubtype_code',True)\n\nencoder('country_txt','country_code',True)    \nencoder('region_txt','region_code',True)    \nencoder('attacktype1_txt','attacktype_code',True)    \nencoder('targtype1_txt','targtype_code',True)    \nencoder('gname','gname_code',True)    \nencoder('weaptype1_txt','weaptype_code',True)    \nencoder('dbsource','dbsource_code',True)    ","55e2052e":"show_details()","aa8b537d":"data.head()","a8968453":"data.info()","faf218b7":"X , y = make_xy('success')","569bb526":"X.shape","e8018dd1":"y.shape","a07bc4f4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=44, shuffle =True)\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","fe89f1b2":"cplot('success')","dc68eb9b":"from sklearn.ensemble import GradientBoostingClassifier\n\nGBCModel = GradientBoostingClassifier(n_estimators=100,max_depth=3,random_state=33) \nGBCModel.fit(X_train, y_train)","732b572f":"print('GBCModel Train Score is : ' , GBCModel.score(X_train, y_train))\nprint('GBCModel Test Score is : ' , GBCModel.score(X_test, y_test))","c0642a4c":"y_pred = GBCModel.predict(X_test)\ny_pred_prob = GBCModel.predict_proba(X_test)\nprint('Predicted Value for GBCModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for GBCModel is : ' , y_pred_prob[:10])","8c08e1c5":"again we have to drop all values of 0 ","683413ec":"unique values ? ","41e1cd34":"what are values at it ? ","da0933c2":"& how many nulls are there  ? ","80af26eb":"now check number of rows ","416519a7":"almost half of operations with no victims & fifth with only 1 victim , now how about the wounds","120791f3":"since value of 0 is not accepted in month , we have to drop all rows contain 0 in month value , how many are rows right now ? \n","2d35ab80":"now how it looks ","e93f5924":"now how the scores looks like","12011454":"what are the values ? ","4b568a41":"so much nulls , so let's fill nulls with 0 then drop all rows with zero value ","f009d67c":"____\n\nnow it's time to define needed functions\n","b5995354":"so since it got an original values for 0 , so we'll fill nulls with another number 33 to drop it","9d2223a1":"great ,  94% accuracy ,  lets predict the X_test","d85baa83":"let's have a look to number of wounded people statistics","ad6674f3":"great now we can label encode all categorical features , & drop original features ","db95e31f":"also we can draw a pie chart for it","635074bd":"_____\n\nnow what is the shape  ? ","a804a17c":"great , let's repeat it with longitude","a65702d4":"ok looks fine , let's draw a graphical representaion for year distribution ","8e087206":"how about unique values ? ","c7723f4f":"now how it looks ","31f8500d":"almost 10% of operations failed & 90% succeeded\n\n______\n\n# Building the Model\n\nlet's use the Gradient Boosting Classifier , with 100 classifier & max_depth 3","259e10ad":"almost equally distributed \n\nnow how about the days ? ","e95f8bfa":"so let's use 33 value","f2c523ae":"_____\n\nnow let's have a look to unique values for each feature ","b9d29235":"now it should got no nulls","8129a75d":"about 20 rows dropped , let's be sure that 0 value is vanished","833ffc7f":"nothing wrong with it , how about latitude , how many nulls at it  ?","a5c671e5":"also we can have a look to their ratios","f20a8e7c":"almost 1 thousand rows dropped\n\n______\n\nok , let's moce to extended","f9b20f2e":"now it should show 0 nulls in all features  ","9a840c79":"great , how many rows dropped ? ","716b5e5d":"______\n\nlet's move to specificity ","01a04d19":"how it looks","5edeb785":"so we can have a look to umber of victims distribution ","c150510f":"also we need to have a detailed look so all data ","9e651516":"again we'll fill nulls with 33 to drop it","b241d11d":"now how data looks like","0fbf8ed5":"almost 100 feature are dropped . \n\nnow we'll drop ventid feature since it is not helpful , & also several numerical features which got exact values as text like country & region \n\n","28424267":"ok , 135 features ,  but since several features got so much nulls , so it will mislead us in the training . \n\nso let's drop all features with null value covers more than 30% of all rows ","b9e450ed":"____\n\nnow the number of victims","e5ba089f":"____\n\n# Data Cleaning\n\nnow let's know the data shape","b60988b1":"what are unique values for it ? ","90eddb1c":"now let's drop 0 value at month","9057fd69":"again we'll use 999999to drop null rows","70979232":"then we'll read the data","9451226b":"looks that the rate increased so much in the last fea years , how about the month","091e6661":"is there specific month which got more terroristic operation rate ? ","38472e31":"ok , now to the last numerical feature ","d5c9d32c":"then split it ","7b4dadf7":"snce we have hundreds of nulls in these 7 features , let's fill them with 'other' to make them ready for label encoder","4a53f171":"and it should show no nulls","1b161ac6":"we'll repeat the 33 value again ","c1bbe5d2":"great , now we read to move to categorical features \n\n______\n\n# Categorical Features\n\nhow the data looks now ? ","7f542261":"cool , how about vicinity","a0994517":"____\n\nnow data is ready to split & build the model \n\n# Data Splitting\n\n\n","4db8c963":"again it contain several numbers & we cannot use 0 since it's exist indeed , let's pick 999999","8226a081":"_____\n\nnow let's move to gun certain","09923993":"# Global Terrorism Classification\nby : Hesham Asem\n\n________________\n\nhere we have a dataset for ens of thousands of successful & failed terroristic operations worldwide , & we need to build a classifier , which can expect whether the operation will succeeded or failed \n\nDatabase : \nhttps:\/\/www.kaggle.com\/START-UMD\/gtd\/\n\nso let's import needed libraries","3833093e":"now hw many rows left","18f45b4d":"_____\n\nso we'll need to handle Numerical features & categorical features , step by step\n\n_____\n\n# Numerical Features\n","17133cf3":"we have 14 numerical features to handle here which are : iyear , imonth , iday , extended , latitude , longitude , specificity , vicinity , doubtterr , multiple , guncertain1, nkill , nwound & ishostkid\n\nlet's be sure that it got no nulls & all values are suitable\n\nlet's start with iyear","1b231b46":"and we can see the count plot of the output","24a6330c":"and doubtterr","fd13f06b":"great , now how multiple looks  ? ","ea0c72c4":"how many nulls ? ","d8d66c37":"& how many rows left","d1d99606":"how about the shape"}}