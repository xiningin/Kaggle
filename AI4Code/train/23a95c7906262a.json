{"cell_type":{"ea00e339":"code","e370a8b1":"code","3135ff78":"code","4a4a63c4":"code","4f61d501":"markdown","ef75f8c3":"markdown","a6a09b92":"markdown","05224587":"markdown","82db7197":"markdown","ff47bc1e":"markdown","fd8b3e04":"markdown","960f50e6":"markdown"},"source":{"ea00e339":"\"\"\"Generate a raw data preview report\"\"\"\nimport pandas as pd\npd.set_option('display.max_columns',None)  #show all columns\npd.set_option('display.width',None)\npd.set_option('display.unicode.ambiguous_as_wide', True)\npd.set_option('display.unicode.east_asian_width', True)\n\ndef read_file(file_path):\n    \"\"\"read_file according to file format\"\"\"\n    if file_path.endswith(\"csv\"):\n        data = pd.read_csv(file_path)\n    elif file_path.endswith(\"xls\"):\n        data = pd.read_excel(file_path)\n    elif file_path.endswith(\"xlsx\"):\n        data = pd.read_excel(file_path)\n    return data\n\ndef preview(file_path,class_name): #transfer into file_path and the data's class\/label name (in this case, class name is ACTIVITY)\n    data = read_file(file_path)  \n\n    \"\"\"1.show data shape\"\"\"\n    data_shape = data.shape\n    print(\"1..data shape:\", data_shape)\n    print(\"*******\"*20)\n    #\n    \"\"\"2.show first 10 rows and last 10 rows of data\"\"\"\n    head_10 = data.head(10)\n    print(\"2.First 10 rows:\")\n    print(head_10)\n    print(\"*******\"*20)\n    print(\"3.Last 10 rows:\")\n    tail_10 = data.tail(10)\n    print(tail_10)\n    print(\"*******\"*20)\n\n    \"\"\"3.show basic information of the raw data\"\"\"\n    print(\"4.Basic information of the raw data:\")\n    data_info = data.info()\n    print(data_info)\n    print(\"*******\"*20)\n\n    \"\"\"4.Show more detailed information of the data...\"\"\"\n    data_describe = data.describe(include = \"all\")\n    print(\"5.Detailed information of the raw data:\")\n    print(data_describe)\n    print(\"*******\"*20)\n\n    \"\"\"5.Examine null\"\"\"\n    print(\"6.Situation of null value of raw data:\")\n    data_null = data.isnull().sum()\n    print(data_null)\n    print(\"*******\" * 20)\n\n    \"\"\"6.Gain feature name(column name) list\"\"\"\n    print(\"7.feature_name_list\uff1a\")\n    features_list = data.columns.values.tolist()\n    print(features_list)\n    print(\"*******\" * 20)\n\n    \"\"\"7.Gain the distribution of class value\"\"\"\n    print(\"8.Distribution of class_value {}:\".format(repr(class_name)))\n    class_values_distribution = data[class_name].value_counts()\n    print(class_values_distribution)\n\n#use function 'preview'\npreview(r'..\/input\/falldeteciton.csv','ACTIVITY')","e370a8b1":"import pandas as pd\n\ndata = pd.read_csv(r\"..\/input\/falldeteciton.csv\")\n\n#1.change the order of features to make \"ACTIVITY\" to be the last column\ndata = data[['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION','ACTIVITY' ]]\n\n#2. change the class value from numeric to nominal\ndict_ = {0:\"Standing\",1:\"Walking\",2:'Sitting',3:\"Falling\",4:\"Cramps\",5:\"Running\"}\ndata[\"ACTIVITY\"] = data[\"ACTIVITY\"].map(dict_)\n\n\"\"\"3.min-max normalization\"\"\"\n# from sklearn.preprocessing import MinMaxScaler\n# minmax = MinMaxScaler()\n# data[['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']] = minmax.fit_transform(data[['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']])\n\n# data.to_csv(\"prepcessed_minmax.csv\")\n\n\"\"\"4.z-score normalization\"\"\"\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(data[['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']]) \ndata[['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']] = scaler.fit_transform(data[['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']])\n# data.to_csv(\"preprocessed_zscore.csv\")","3135ff78":"import pandas as pd\nimport numpy as np\n\n# file_path_zscore = r\"xxxxxxxxxxxxx\\preprocessed_zscore.csv\"  #read preprocessed file\n# data = pd.read_csv(file_path_zscore,engine='python')\n\n\nfeatures = ['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']                       #get features list\nlabel = ['ACTIVITY']                                                                 #get lable name\nclass_value = [\"Standing\",\"Walking\",\"Sitting\",\"Falling\",\"Cramps\",\"Running\"]     #get class values list\nfeatures_data = data[features]                                                         #get features' Dataframe\nlabel_data = data[label]                                                              #get class data\n\n#split the data into training data and test data\nfrom sklearn.model_selection import train_test_split  #\u5bfc\u5165split\u5305\ntrain_features, test_features,train_label, test_label = train_test_split(features_data, label_data, test_size=0.33, random_state=33)\n\n#feature selection part\nfrom sklearn.feature_selection import RFE\nfrom sklearn.tree import DecisionTreeClassifier\n#import an external estimator\nclf = DecisionTreeClassifier(criterion=\"entropy\")\n#\u2193 n_features_to_select:4\nselector = RFE(estimator=clf,n_features_to_select=4,step=1)\nselector.fit(features_data,np.ravel(label_data))\nselected_features = [features[i] for i in list(selector.get_support(indices=True))]\nprint(selected_features)  # show selected features\n\n########################################################################\n#L1-based feature selection\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import LinearSVC\nlsvc = LinearSVC(C=0.005, penalty=\"l1\", dual=False).fit(features_data, np.ravel(label_data))\nselector = SelectFromModel(lsvc,prefit=True)\nselected_features = [features[i] for i in list(selector.get_support(indices=True))]\nprint(selected_features)\n","4a4a63c4":"import pandas as pd\nimport numpy as np\n\n# file_path_zscore = r\"xxxxxxxxxxxxx\\preprocessed_zscore.csv\"  #read preprocessed file\n# data = pd.read_csv(file_path_zscore,engine='python')\n\n\nfeatures = ['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']                       #get features list\nlabel = ['ACTIVITY']                                                                 #get lable name\nclass_value = [\"Standing\",\"Walking\",\"Sitting\",\"Falling\",\"Cramps\",\"Running\"]     #get class values list\nfeatures_data = data[features]                                                         #get features' Dataframe\nlabel_data = data[label]                                                              #get class data\n\n#split the data into training data and test data\nfrom sklearn.model_selection import train_test_split  #\u5bfc\u5165split\u5305\ntrain_features, test_features,train_label, test_label = train_test_split(features_data, label_data, test_size=0.33, random_state=33)\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import GridSearchCV\n# parameters = {'n_estimators':np.arange(110,150,3)}\n# clf = GridSearchCV(estimator=ExtraTreesClassifier(),n_jobs=-1,cv=5,param_grid=parameters)      #get the best n_estimators is 125\n# clf.fit(features_data,np.ravel(label_data))\n# print(clf.best_params_)\n# print(clf.best_score_)\nclf = ExtraTreesClassifier(n_estimators=125,n_jobs=-1)\n\n# fit the data\nclf.fit(train_features,train_label)\npredict_label = clf.predict(test_features)\n\n#####################################################################################################################\n# I create a evaluation pack, following is a simplified edition\nimport pandas as pd\ndef evaluate(predict_label,test_label,class_value):\n    print(\"***********The evaluation of split test data.*************\")\n    from sklearn.metrics import accuracy_score\n    print(\"Accuracy-Test data:\", accuracy_score(y_pred=predict_label, y_true=test_label))\n    print('****'*30)\n    \n    from sklearn.metrics import cohen_kappa_score\n    kappa = cohen_kappa_score(test_label, predict_label)\n    print(\"Kappa:\", kappa)\n    print('****' * 30)\n\n    from sklearn.metrics import confusion_matrix\n    confustion = confusion_matrix(y_pred=predict_label, y_true=test_label, labels=class_value)\n    confustion_matrix_df = pd.DataFrame(confustion, columns=class_value, index=class_value)\n    print(confustion_matrix_df)\n    print('****'*30)\n\n    from sklearn.metrics import classification_report\n    report_dict = classification_report(y_true=test_label, y_pred=predict_label, output_dict=False)\n    print(report_dict)\n##################################################################################################\nevaluate(predict_label,test_label,class_value)","4f61d501":"**2. Preprocess**\n1. I change the order of features to make \"ACTIVITY\" to be the last column\n2. change the class value from numeric to nominal  {0:\"Standing\",1:\"Walking\",2:'Sitting',3:\"Falling\",4:\"Cramps\",5:\"Running\"}\n3. do the min-max and z-score normalization","ef75f8c3":"The best model I can get is using the ExtraTrees Classifier. \nWhen using 33% test data, 67% training data. the score: accuracy:78.23%, Kappa:0.725, \n* Precision\t  Recall\t  F1_Score  AUC\t Class\n* 0.683887916\t0.666951324\t0.675313446\t\\\tCramps\n* 0.689627229\t0.731728289\t0.710054234\t\\\tFalling\n* 0.723628692\t0.596521739\t0.653956149\t\\\tRunning\n* 0.746621622\t0.787410926\t0.766473988\t\\\tSitting\n* 0.97146649\t0.975349767\t0.973404255\t\\\tStanding\n* 0.790123457\t0.825806452\t0.807570978\t\\\tWalking\n* 0.781995831\t0.782319216\t0.781252874\t\\\tWeighted\n\nWhen using 10-cross-validation, the score: accuracy:78.68%, Kappa:0.73,\n* Precision\t      Recall\t F1_Score  AUC\tClass\n* 0.690030507\t0.675767806\t0.682660462\t\\\tCramps\n* 0.689454251\t0.734983383\t0.711247066\t\\\tFalling\n* 0.726174254\t0.613828146\t0.664433211\t\\\tRunning\n* 0.745496538\t0.772011056\t0.758044005\t\\\tSitting\n* 0.979348841\t0.977453487\t0.978388534\t\\\tStanding\n* 0.802069494\t0.82736695\t0.814005032\t\\\tWalking\n* 0.787291569\t0.786474338\t0.785927192\t\\\tWeighted\n\n\n","a6a09b92":"After preview the raw data. I got the following information:\n1. There are about **16000** samples, **7** columns.\n2. The the value range from different features differs a lot. So,the data should be preprocessed with min-max normalization or z-score\n3. There are no null values.\n4. feature name list: ['ACTIVITY', 'TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']\n5. The class value is unbalanced, and I prefer to change the value from numeric to nominal [0- Standing 1- Walking 2- Sitting 3- Falling 4- Cramps 5- Running]","05224587":"I tried some features selection methods, some filter the features and left like ['SL', 'EEG', 'HR', 'CIRCLUATION'], some just keep all the six features.I finnaly keep all the features to train the model. And I also try to use ['SL', 'EEG', 'HR', 'CIRCLUATION'] these 4 features, but the accuracy is less than using all the features.","82db7197":"**3. Feature Selection**","ff47bc1e":"4.Machine Learning\n* I tried basic Decision Tree, Naive Bayes,KNN,SVM,Adaboost,Random forest and ExtraTrees. The best score is about 78.2% which is far behind the 95%. ","fd8b3e04":" **1.Data Preview**\n \n*  I make a preview_data package to generate a description report of the original data","960f50e6":"The processed data will be saved in new csv files."}}