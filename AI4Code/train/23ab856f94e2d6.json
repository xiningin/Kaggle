{"cell_type":{"a7114f58":"code","4d8a3c73":"code","15a5dcb5":"markdown"},"source":{"a7114f58":"from PIL import Image \nImage.open(\"\/kaggle\/input\/data-pipeline\/data_pipeline.PNG\")","4d8a3c73":"\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport missingno as msno\nfrom datetime import date\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n\n#############################################\n# 1. Outliers\n#############################################\n\n# Thresholds for Outliers(IQR Method)\ndef outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n# Checking the Outliers\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n\n# Catching the Outliers\ndef grab_outliers(dataframe, col_name, index=False):\n    low, up = outlier_thresholds(dataframe, col_name)\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index\n\n# Removing the Outliers\ndef remove_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n    return df_without_outliers\n\n# Reassigning the Outliers\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n# Local Outlier Factor\ndef lof(dataframe):\n    clf = LocalOutlierFactor(n_neighbors=20)\n    clf.fit_predict(dataframe)\n    df_scores = clf.negative_outlier_factor_\n    scores = pd.DataFrame(np.sort(df_scores))\n    scores.plot(stacked=True, xlim=[0, 20], style='.-')\n    plt.show()\n    th = np.sort(df_scores)[3]\n    dataframe=dataframe[df_scores < th].drop(axis=0, labels=dataframe[df_scores < th].index)\n\n    return dataframe\n\n\n#############################################\n# 2. Missing Values\n#############################################\n\n# Catching Missing Values\ndef missing_catch(dataframe):\n    print(\"*\"*20+\"  Is there any Missing Value in Data?  \"+\"*\"*20)\n    print(dataframe.isnull().values.any())\n    print(\"*\" * 20 + \"  Number of Missing for Variables  \" + \"*\" * 20)\n    print(dataframe.isnull().sum())\n    print(\"*\" * 20 + \"  Number of Not Null Values for Variables  \" + \"*\" * 20)\n    print(dataframe.notnull().sum())\n    print(\"*\" * 20 + \"  The Variables that have One Missing Least  \" + \"*\" * 20)\n    print(dataframe[dataframe.isnull().any(axis=1)])\n    print(\"*\" * 20 + \"  The Ratio of Missing Values  \" + \"*\" * 20)\n    print((dataframe.isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False))\n    print(\"*\" * 20 + \"  Columns that has Missing Value  \" + \"*\" * 20)\n    print([col for col in dataframe.columns if dataframe[col].isnull().sum() > 0])\n\n\n# Quick Handling Missing Values\ndef missing_handle(dataframe, na_col=None, method=\"drop\"):\n    if method == \"drop\":\n        dataframe = dataframe.dropna()\n    elif method == \"mean\":\n        dataframe[na_col] = dataframe[na_col].fillna(dataframe[na_col].mean())\n    elif method == \"median\":\n        dataframe[na_col] = dataframe[na_col].fillna(dataframe[na_col].median())\n    elif method == \"mode\":\n        dataframe[na_col] = dataframe[na_col].fillna(dataframe[na_col].mode()[0])\n    return dataframe\n\n\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n    if na_name:\n        return na_columns\n\n# Filling Missing Values based on Categorical Variable\ndef cat_group_fill(dataframe,cat_col,num_col,method=\"mean\"):\n    dataframe[num_col].fillna(dataframe.groupby(cat_col)[num_col].transform(method))\n\n# Missing & Target\ndef missing_vs_target(dataframe, target, na_columns):\n    temp_df = dataframe.copy()\n    for col in na_columns:\n        temp_df[col + '_NA_FLAG'] = np.where(temp_df[col].isnull(), 1, 0)\n    na_flags = temp_df.loc[:, temp_df.columns.str.contains(\"_NA_\")].columns\n    for col in na_flags:\n        print(pd.DataFrame({\"TARGET_MEAN\": temp_df.groupby(col)[target].mean(),\n                            \"Count\": temp_df.groupby(col)[target].count()}), end=\"\\n\\n\\n\")\n\n# Filling Numerical variable with Median\ndef num_fill_median(dataframe):\n    dataframe.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0).isnull().sum()\n\n# Filling Categorical variable with Mode\ndef cat_fill_mode(dataframe,th=10):\n    dataframe.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= th) else x, axis=0).isnull().sum()\n\n\n\n#############################################\n# 3. Encoding\n#############################################\n\n# Label Encoding & Binary Encoding\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\n# One-Hot Encoding\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\n# Rare category & Target\ndef rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\n# Rare Encoding\ndef rare_encoder(dataframe, rare_perc, cat_cols):\n    rare_columns = [col for col in cat_cols if (dataframe[col].value_counts() \/ len(dataframe) < 0.01).sum() > 1]\n\n    for col in rare_columns:\n        tmp = dataframe[col].value_counts() \/ len(dataframe)\n        rare_labels = tmp[tmp < rare_perc].index\n        dataframe[col] = np.where(dataframe[col].isin(rare_labels), 'Rare', dataframe[col])\n\n    return dataframe\n\n\n\n#############################################\n# 4. Feature Scaling\n#############################################\n\n# Feature Scaling\ndef feature_scaling(dataframe, col, method=None):\n    if method == \"MinMaxScaler\":\n        dataframe[\"NEW_\"+col + \"_SCALED\"] = MinMaxScaler().fit_transform(dataframe[[col]])\n    elif method == \"StandardScaler\":\n        dataframe[\"NEW_\"+col+\"_SCALED\"] = StandardScaler().fit_transform(dataframe[[col]])\n    elif method == \"RobustScaler\":\n        dataframe[\"NEW_\"+col + \"_SCALED\"] = RobustScaler().fit_transform(dataframe[[col]])\n    elif method == \"Log\":\n        dataframe[\"NEW_\"+col + \"_SCALED\"] = np.log(dataframe[col])\n\n\n\n#############################################\n# 5. Feature Extraction\n#############################################\n# Word Count\ndef word_count(dataframe, text_col, sep=\" \"):\n    dataframe[\"NEW_\"+text_col+\"_WORD_COUNT\"] = dataframe[text_col].apply(lambda x: len(str(x).split(sep)))\n    return dataframe\n\n# Catching Special Words\ndef special_words(dataframe,text_col,spec_word):\n    dataframe[\"NEW_\"+text_col+\"_\"+spec_word] = dataframe[text_col].apply(lambda x: len([x for x in x.split() if x.startswith(spec_word)]))\n    return dataframe\n\n# Generating Date Columns\ndef date_extract(dataframe, col, pref=\"NEW_\", year=True, month=True, year_diff=False, \\\n    month_diff=False, day_nm=False):\n    dataframe[col] = pd.to_datetime(dataframe[col], format=\"%Y-%m-%d\")\n    if year:\n        dataframe[pref+\"YEAR\"] = dataframe[col].dt.year\n    if month:\n        dataframe[pref + \"MONTH\"] = dataframe[col].dt.month\n    if year_diff:\n        dataframe[pref+\"YEAR_DIFF\"] = date.today().year - dataframe[col].dt.year\n    if month_diff:\n        dataframe[pref+\"MONTH_DIFF\"] = (date.today().year - dataframe[col].dt.year) * 12 + date.today().month - dataframe[col].dt.month\n    if day_nm:\n        dataframe[pref+\"DAY_NM\"] = dataframe[col].dt.day_name()\n    return dataframe","15a5dcb5":"# Helping Functions for Data Preparation"}}