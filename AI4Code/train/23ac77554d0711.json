{"cell_type":{"8ca0b900":"code","df816d91":"code","2ce34d73":"code","22a4010d":"code","fa08a7ac":"code","e87a1930":"code","2222a01a":"code","1e14f279":"code","5b2909d9":"code","ad779d96":"code","fe3e542b":"code","34afb5af":"code","ecd393dd":"code","11ed6dfa":"code","65e725e4":"code","021f284f":"code","d7d42a92":"code","e3d8c917":"code","4ca57d07":"code","0ba09181":"code","f30b578d":"code","33e10d18":"code","3b321c4d":"code","76b74f49":"code","a5b014ff":"code","d5fe4be4":"code","029d60f9":"code","b6fc67e1":"code","29133464":"code","ce3ae702":"code","71544a98":"code","7105d5ff":"code","0025c385":"code","dd56ad4a":"code","50882557":"code","4bdac05b":"code","9b4c32dd":"code","ba46face":"code","ba376778":"code","0d107ad4":"code","fa1c3ff5":"code","e94312bf":"code","759ccfa0":"code","0dafb730":"code","419978d5":"code","20087f42":"code","f537439b":"code","ab62b5a7":"code","fcfd74a5":"code","8f84191f":"code","d8ed0130":"code","dea3df62":"code","fcaf9daf":"code","c767f72e":"code","f7d225bc":"code","fa553906":"code","95650a0c":"code","acd0bb82":"code","7bc940d7":"code","b440c6c0":"code","5845189d":"code","fb8a67a7":"code","5d521d95":"code","1f8afccc":"code","ea7aa022":"code","cd16f077":"code","22dbe2ac":"code","09ef1492":"code","847351cb":"code","225ec7cf":"code","6966d27e":"code","5b3d35ef":"code","f2660887":"code","b910582f":"code","e1942ef3":"code","316ac69b":"code","e030ef8f":"code","00695539":"code","9b263687":"code","a590ccc2":"code","1ae4b38e":"code","1d6f978b":"code","48bee2e4":"code","afc854e9":"code","c37bd052":"code","798b9a73":"code","518210d6":"code","1024833d":"code","3ad98d19":"code","b3fba35d":"code","40666582":"code","50984d4c":"code","9371a9c3":"code","b15bf300":"code","b8d65130":"code","4aad0ce9":"code","b0ab19d3":"code","561a371c":"code","86874144":"code","37dba8d3":"code","f7f26bd4":"code","40fbd8d5":"code","7c94755c":"code","2eff6b95":"code","3a4cb67a":"code","e7fd9aa4":"code","c6de9fea":"code","7e8ca961":"code","e2dc1c61":"code","1a2e5729":"code","5d3cbeb2":"code","42967e2c":"code","e9d0cc9f":"code","f1b578e7":"code","8d9a4a21":"code","267dd1d7":"code","f180b089":"code","a2d46c7c":"code","549363f0":"code","20a49513":"code","14fa60e3":"code","b5f19a50":"code","59542c56":"markdown","8c341860":"markdown","973239ab":"markdown","16dd6edc":"markdown","c850ae62":"markdown","92b7bd7e":"markdown","cb42c8e4":"markdown","7944daf5":"markdown","7b1b52f0":"markdown","7032f5e6":"markdown","0a2b6025":"markdown","ef3298b8":"markdown","820cb321":"markdown","5ddaab70":"markdown","1e93803a":"markdown","bb415db3":"markdown","12dc8846":"markdown","472bbbc4":"markdown","fea8b80b":"markdown","7d7aa709":"markdown","0f779e3d":"markdown","d46b2a3d":"markdown","70ebc179":"markdown","c1ebe494":"markdown","e3192830":"markdown","be020ac5":"markdown","37680010":"markdown","15f2e190":"markdown","da1e30d6":"markdown","007aa3aa":"markdown","b485c2ae":"markdown","68d5621a":"markdown","ad18e0e7":"markdown","d510b207":"markdown","fbd42b5d":"markdown","6c9fac4e":"markdown","b130b80b":"markdown","21ebb089":"markdown","345a1f2e":"markdown","8e31e7e1":"markdown","4b6ba4df":"markdown","a4d059dc":"markdown","d436fd94":"markdown","81bc4033":"markdown","2e300be8":"markdown","de454d61":"markdown","fde0edf4":"markdown","481ec486":"markdown","4a4cfcb9":"markdown","011178aa":"markdown","d34c4cc2":"markdown","732cd25f":"markdown","d201a181":"markdown","31465b7a":"markdown","0e1c5243":"markdown","16dc8dea":"markdown","9b44b492":"markdown","7e2631c8":"markdown","8ce3aba6":"markdown"},"source":{"8ca0b900":"DATA_PROCESSED_DIR = \"..\/input\/mini-project\/files\/_data_processed\/\"","df816d91":"CSV_FILES=\"..\/input\/csv-files\"\nCSV_FILES","2ce34d73":"#model making\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow as tf\nimport seaborn as sn\nprint (tf.__version__)","22a4010d":"# Load the TensorBoard notebook extension\n%load_ext tensorboard","fa08a7ac":"IMAGES_DIR = DATA_PROCESSED_DIR\nIMAGES_DIR","e87a1930":"CLASS_NAMES = \"Atelectasis,Cardiomegaly,Effusion,\\\nInfiltration,Mass,Nodule,Pneumonia,Pneumothorax,\\\nConsolidation,Edema,Emphysema,Fibrosis,Pleural_Thickening,Hernia\"\nCLASS_NAMES = CLASS_NAMES.split(',')\nCLASS_NAMES","2222a01a":"from imgaug import augmenters as iaa\n\nAUG = iaa.Sequential(\n    [\n        iaa.Fliplr(0.5),\n    ],\n    random_order=True,\n)","1e14f279":"#data pipeline\nclass DataGenerator(Sequence):\n    \"\"\"\n    This is the Sequece data generator\n    \"\"\"\n\n    def __init__(self, dataset_csv_file, class_names, source_image_dir, batch_size, target_size, verbose, \n                 shuffle_on_epoch_end, counts, augmenter):\n        \"\"\"\n        :param dataset_csv_file: str, path of dataset csv file\n        :param class_names: list of str\n        :param batch_size: int\n        :param target_size: tuple(int, int)\n        :param verbose: int\n        \"\"\"\n        self.dataset_df = pd.read_csv(dataset_csv_file)\n        self.source_image_dir = source_image_dir\n        self.batch_size = batch_size\n        self.target_size = target_size\n        self.verbose = verbose\n        self.augmenter = augmenter\n        self.shuffle = shuffle_on_epoch_end\n        self.random_state = 1\n        self.class_names = class_names\n        self.counts = counts\n        self.steps = int(np.ceil(self.counts \/ float(self.batch_size)))\n        self.prepare_dataset()\n        \n        \n    def __bool__(self):\n        return True\n\n    def __len__(self):\n        return self.steps\n\n    def __getitem__(self, idx):\n        batch_x_path = self.x_path[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_x = np.asarray([self.load_image(x_path) for x_path in batch_x_path])\n        batch_x = self.transform_batch_images(batch_x)\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n        return batch_x, batch_y\n\n    def load_image(self, image_file):\n        image_path = os.path.join(self.source_image_dir, image_file)\n        image = Image.open(image_path)\n        image_array = np.asarray(image.convert(\"RGB\"))\n#         image_array = image_array \/ 255.\n        return image_array\n\n    def transform_batch_images(self, batch_x):\n        if self.augmenter is not None:\n            batch_x = self.augmenter.augment_images(batch_x)\n        return batch_x\n\n    def get_y_true(self):\n        \"\"\"\n        Use this function to get y_true for predict_generator\n        In order to get correct y, you have to set shuffle_on_epoch_end=False.\n        \"\"\"\n        if self.shuffle:\n            raise ValueError(\"\"\"\n            You're trying run get_y_true() when generator option 'shuffle_on_epoch_end' is True.\"\"\")\n    \n    def prepare_dataset(self):\n        df = self.dataset_df.sample(frac=1., random_state=self.random_state)\n        self.x_path, self.y = df[\"Image Index\"].to_numpy(), df[self.class_names].to_numpy()\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            self.random_state += 1\n            self.prepare_dataset()\n            ","5b2909d9":"def get_class_weights(total_counts, class_positive_counts, multiply):\n    \"\"\"\n    Calculate class_weight used in training\n    Arguments:\n    total_counts - int\n    class_positive_counts - dict of int, ex: {\"Effusion\": 300, \"Infiltration\": 500 ...}\n    multiply - int, positve weighting multiply\n    use_class_balancing - boolean \n    Returns:\n    class_weight - dict of dict, ex: {\"Effusion\": { 0: 0.01, 1: 0.99 }, ... }\n    \"\"\"\n    def get_single_class_weight(pos_counts, total_counts):\n        denominator = (total_counts - pos_counts) * multiply + pos_counts\n        return {\n            0: pos_counts \/ denominator,\n            1: (denominator - pos_counts) \/ denominator,\n        }\n\n    class_names = list(class_positive_counts.keys())\n    label_counts = np.array(list(class_positive_counts.values()))\n    class_weights = []\n    for i, class_name in enumerate(class_names):\n        class_weights.append(get_single_class_weight(label_counts[i], total_counts))\n\n    return class_weights","ad779d96":"from sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n\ndef generate_class_weights(class_names):\n    df = pd.read_csv(os.path.join(CSV_FILES, \"train.csv\"))\n    class_series = df[class_names].to_numpy()\n    n_samples = len(class_series)\n    n_classes = len(class_series[0])\n    print(f\"No of Train Images are {n_samples}\")\n    \n    # Count each class frequency\n    class_count = [0] * n_classes\n    for classes in class_series:\n        for index in range(n_classes):\n            if classes[index] != 0:\n                class_count[index] += 1\n    \n    # Compute class weights using balanced method\n    class_weights = [n_samples \/ (n_classes * freq) if freq > 0 else 1 for freq in class_count]\n    class_labels = range(len(class_weights)) \n    return dict(zip(class_labels, class_weights))","fe3e542b":"print (generate_class_weights(CLASS_NAMES))","34afb5af":"def get_sample_weights(total_counts, class_positive_counts, multiply):\n    def get_single_class_weight(pos_counts, total_counts):\n        denominator = (total_counts - pos_counts) * multiply + pos_counts\n        return {\n            0: pos_counts \/ denominator,\n            1: (denominator - pos_counts) \/ denominator,\n        }\n\n    class_names = list(class_positive_counts.keys())\n    label_counts = np.array(list(class_positive_counts.values()))\n    sample_weights = []\n    for i, class_name in enumerate(class_names):\n        sample_weights.append(get_single_class_weight(label_counts[i], total_counts))\n\n    return sample_weights","ecd393dd":"def get_sample_counts(csv_dir, dataset, class_names):\n    \"\"\"\n    Get total and class-wise positive sample count of a dataset\n    \"\"\"\n    df = pd.read_csv(os.path.join(csv_dir, f\"{dataset}.csv\"))\n    total_count = df.shape[0]\n    labels = df[class_names].to_numpy()\n    positive_counts = np.sum(labels, axis=0)\n    class_positive_counts = dict(zip(class_names, positive_counts))\n    return total_count, class_positive_counts","11ed6dfa":"output_dir= \"..\/input\/chexnetkeras\/\"\n","65e725e4":"train_counts, train_pos_counts = get_sample_counts(csv_dir=CSV_FILES ,dataset=\"train\", class_names=CLASS_NAMES)\ndev_counts, _ = get_sample_counts(csv_dir=CSV_FILES, dataset=\"dev\", class_names=CLASS_NAMES)\ntest_counts, _ = get_sample_counts(output_dir, \"test\", CLASS_NAMES)","021f284f":"print(f'No of Train Images = {train_counts} | No of Validation Images = {dev_counts}')\n","d7d42a92":"BATCH_SIZE = 32\nEPOCHS = 10\nINI_LE_RATE = 0.001\n\n# NO of CPU for pipeline\nGENRATOR_WORKERS = 8\n# Image Dimention\nIMAGE_DIM = 256","e3d8c917":"train_sequence = DataGenerator(\n    dataset_csv_file=os.path.join(CSV_FILES, \"train.csv\"),\n    class_names=CLASS_NAMES,\n    source_image_dir=IMAGES_DIR,\n    batch_size=BATCH_SIZE,\n    target_size=(IMAGE_DIM, IMAGE_DIM, 3),\n    verbose=1,\n    shuffle_on_epoch_end=True,\n    counts=train_counts,\n    augmenter=AUG,\n)","4ca57d07":"validation_sequence = DataGenerator(\n    dataset_csv_file=os.path.join(CSV_FILES, \"dev.csv\"),\n    class_names=CLASS_NAMES,\n    source_image_dir=IMAGES_DIR,\n    batch_size=BATCH_SIZE,\n    target_size=(IMAGE_DIM, IMAGE_DIM, 3),\n    verbose=1,\n    shuffle_on_epoch_end=True,\n    counts=dev_counts,\n    augmenter=AUG\n)","0ba09181":"test_sequence = DataGenerator(\n    dataset_csv_file=\"..\/input\/chexnetkeras\/test.csv\",\n    class_names=CLASS_NAMES,\n    source_image_dir=IMAGES_DIR,\n    batch_size=BATCH_SIZE,\n    target_size=(IMAGE_DIM, IMAGE_DIM, 3),\n    verbose=1,\n    shuffle_on_epoch_end=False,\n    counts=test_counts,\n    augmenter=AUG\n)","f30b578d":"from PIL import Image\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.imshow(train_sequence[0][0][0])","33e10d18":"df = pd.read_csv(os.path.join(CSV_FILES, \"train.csv\"))\ntotal_count = df.shape[0]\ncategories = list(CLASS_NAMES)\nsns.set(font_scale = 2)\nplt.figure(figsize=(40,12))\nax= sns.barplot(categories, df[CLASS_NAMES].sum().values)\nplt.title(\" Number of category\", fontsize=30)\nplt.ylabel('Number of Compilcations', fontsize=20)\nplt.xlabel('Type of Complications ', fontsize=20)\n#adding the text labels\nrects = ax.patches\nlabels = df[CLASS_NAMES].sum().values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()\/2, height + 5, label, ha='center', va='bottom', fontsize=20)\nplt.show()","3b321c4d":"rowSums = df[CLASS_NAMES].sum(axis=1)\nmultiLabel_counts = rowSums.value_counts()\nmultiLabel_counts = multiLabel_counts.iloc[1:]\nsns.set(font_scale = 2)\nplt.figure(figsize=(20,8))\nax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\nplt.title(\"Images with multiple labels \")\nplt.ylabel('Number of Complications', fontsize=18)\nplt.xlabel('Number of labels', fontsize=18)#adding the text labels\nrects = ax.patches\nlabels = multiLabel_counts.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()\/2, height + 5, label, ha='center', va='bottom')\nplt.show()","76b74f49":"\n\nimport importlib\nfrom tensorflow.keras.applications import inception_v3,resnet50,mobilenet_v2,densenet\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import ReLU\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import BinaryAccuracy\nfrom tensorflow import concat\nfrom tensorflow.keras.layers import ZeroPadding2D\nfrom tensorflow.math import reduce_logsumexp\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.metrics import AUC, Accuracy, BinaryAccuracy\nfrom sklearn.metrics import multilabel_confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\n","a5b014ff":"init_learning_rate = 1e-4\nEPSILON = 1e-4 # AdamOptimizer epsilon\ndropout_rate = 0.2","d5fe4be4":"nesterov_momentum = 0.9\nweight_decay = 1e-4","029d60f9":"df = pd.read_csv(\"..\/input\/chexnetkeras\/test.csv\")\ntotal_count = df.shape[0]\ny_true = df[CLASS_NAMES].to_numpy()","b6fc67e1":"DEF_MODEL = [[\"DenseNet121\",\"densenet\"],[\"ResNet50\",\"resnet50\"],[\"InceptionV3\",\"inception_v3\"],[\"MobileNetV2\",\"mobilenet_v2\"]]","29133464":"def get_model(class_names, model=DEF_MODEL[0], input_shape=None, input_tensor=None, train=False, weights=None):\n    base_weights = weights\n    base_model_class = getattr(\n        importlib.import_module(\n            f\"tensorflow.keras.applications.{model[1]}\"\n        ),\n        model[0])\n    img_input = input_tensor\n    base_model = base_model_class(\n        include_top=False,\n        input_tensor=input_tensor,\n        input_shape=input_shape,\n        weights=base_weights,\n    )\n    base_model.trainable = train\n    return base_model","ce3ae702":"INPUT_SHAPE = (IMAGE_DIM, IMAGE_DIM, 3)\nIMG_INPUT = tf.keras.Input(INPUT_SHAPE,name='Input')","71544a98":"def lse_pool(x):\n    return reduce_logsumexp(x,axis=[1,2],keepdims=True,name='lse_pool')","7105d5ff":"if not os.path.exists(\"\/kaggle\/working\/logs\"):\n    os.mkdir(\"\/kaggle\/working\/logs\")\nLOGS_PATHS = \"\/kaggle\/working\/logs\"\n\n","0025c385":"if not os.path.exists(\"\/kaggle\/working\/checkpoints\"):\n    os.mkdir(\"\/kaggle\/working\/checkpoints\")\nCHECK_POINT = \"\/kaggle\/working\/checkpoints\"\n\nif not os.path.exists(\"\/kaggle\/working\/weights\"):\n    os.mkdir(\"\/kaggle\/working\/weights\")\nWEIGHTS_PATH = \"\/kaggle\/working\/weights\"","dd56ad4a":"training_stats = {}\ntrain_steps = int(train_counts \/ BATCH_SIZE)\nvalidation_steps = int(dev_counts \/ BATCH_SIZE)\ntest_steps = int(test_counts \/ BATCH_SIZE)\nPOS_WEIGHTS_MUL=1","50882557":"def print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=14):\n\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names,\n    )\n\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    axes.set_ylabel('True label')\n    axes.set_xlabel('Predicted label')\n    axes.set_title(\"Confusion Matrix for the class - \" + class_label)","4bdac05b":"y_true_argmax=np.argmax(y_true, axis=1)","9b4c32dd":"IMAGE_INPUT = tf.keras.applications.densenet.preprocess_input(IMG_INPUT)\nDenseNet = get_model(class_names=CLASS_NAMES,\n                   model=DEF_MODEL[0],\n                   input_shape=INPUT_SHAPE,\n                   input_tensor=IMG_INPUT,\n                   train=True,weights=\"imagenet\")","ba46face":"x = DenseNet.output\nx = GlobalAveragePooling2D()(x)","ba376778":"x.get_shape()","0d107ad4":"x = Dropout(0.2)(x)\nx = Dense(1024,activation='relu')(x) \nx = Dense(512,activation='relu')(x) \nx = Dropout(0.2)(x)\npredictions = Dense(len(CLASS_NAMES), activation=\"sigmoid\", name=\"predictions\")(x)\ndense_model = Model(inputs=IMG_INPUT, outputs=predictions)","fa1c3ff5":"DENSE_CHKP = os.path.join(CHECK_POINT,DEF_MODEL[0][0])\nDENSE_WEIGHTS = os.path.join(WEIGHTS_PATH, DEF_MODEL[0][0])\nDENSE_LOGS = os.path.join(LOGS_PATHS, DEF_MODEL[0][0])","e94312bf":"# DenseNet Chechpoint directory\nos.mkdir(DENSE_CHKP)\n# DenseNet Weights directory\nos.mkdir(DENSE_WEIGHTS)\n# DenseNet Logs directory\nos.mkdir(DENSE_LOGS)","759ccfa0":"classWeights = generate_class_weights(CLASS_NAMES)\nsampleWeights = get_sample_weights(train_counts, train_pos_counts,multiply=1)\nprint(\"** class_weights **\")\nprint(classWeights)","0dafb730":"checkpoint = ModelCheckpoint(\n    filepath=os.path.join(DENSE_CHKP,f\"chkp_best.hdf5\"),\n    save_weights_only=True,\n    save_best_only=True,\n    mode='max',\n    verbose=1,\n    save_freq=\"epoch\",\n)","419978d5":"callbacks = [\n    checkpoint,\n    TensorBoard(log_dir=DENSE_LOGS,histogram_freq=0, write_graph=True, write_images=True,update_freq='epoch'),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1,\n                      verbose=1, mode=\"min\", min_lr=1e-8),\n]","20087f42":"METRICS = [BinaryAccuracy(name='accuracy'),AUC(name='AUC',multi_label=True),'hinge']","f537439b":"import keras.backend as K\n\ndef loss_pred(y_true, y_pred):\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=tf.cast(y_true,tf.float32))\n\n    loss = tf.reduce_mean(tf.reduce_sum(cross_entropy, axis=1))\n    return loss\n","ab62b5a7":"print(\"** compile model with class weights **\")\ninitial_learning_rate=0.001\noptimizer = Adam(lr=initial_learning_rate)\ndense_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\",metrics=METRICS)","fcfd74a5":"# dense_model.summary()","8f84191f":"print(f\"Total number of parameters is {dense_model.count_params()}\")","d8ed0130":"hist1 = dense_model.fit(x=train_sequence,\n                        batch_size=32,\n                        validation_data=validation_sequence,\n                        verbose=1,\n                        epochs=EPOCHS,\n                        workers=4,\n                        class_weight=classWeights,\n                        callbacks=callbacks)","dea3df62":"plt.plot(hist1.history['AUC'])\nplt.plot(hist1.history['val_AUC'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","fcaf9daf":"plt.plot(hist1.history['loss'])\nplt.plot(hist1.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","c767f72e":"dense_model.save_weights(\"dense_net_weights.h5\")","f7d225bc":"y_pred_dense = dense_model.predict(x=test_sequence,\n                                   verbose=1,\n                                   workers=4)\n","fa553906":"# confusion_matrix=multilabel_confusion_matrix(y_true, y_pred_dense)\n# df_cm = pd.DataFrame(confusion_matrix, index = [i for i in \"ABCDEFGHIJKLMO\"],\n#                   columns = [i for i in \"ABCDEFGHIJKLMO\"])\n# plt.figure(figsize = (10,7))\n# sn.heatmap(df_cm, annot=True)\n\ny_pred_dense_argmax = np.argmax(y_pred_dense, axis=1)\nconfusion_matrix=multilabel_confusion_matrix(y_true_argmax, y_pred_dense_argmax)","95650a0c":"# print(\"\\nClassification report : \\n\", classification_report(y_true, y_pred_dense, target_names=CLASS_NAMES))\n\nfig, ax = plt.subplots(7, 2, figsize=(25, 15))\nfor axes, cfs_matrix, label in zip(ax.flatten(), confusion_matrix, CLASS_NAMES):\n    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n    \nfig.tight_layout()\nplt.show()","acd0bb82":"print(\"\\nClassification report : \\n\", classification_report(y_true_argmax, y_pred_dense_argmax, target_names=CLASS_NAMES))","7bc940d7":"IMAGE_INPUT = tf.keras.applications.resnet.preprocess_input(IMG_INPUT)\nResNet = get_model(class_names=CLASS_NAMES,\n                   model=DEF_MODEL[1],\n                   input_shape=INPUT_SHAPE,\n                   input_tensor=IMG_INPUT,\n                   train=True,weights=\"imagenet\")","b440c6c0":"x = ResNet.output\nx = GlobalAveragePooling2D()(x)","5845189d":"x.get_shape()","fb8a67a7":"predictions = Dense(len(CLASS_NAMES), activation=\"sigmoid\", name=\"predictions\")(x)\nres_model = Model(inputs=IMG_INPUT, outputs=predictions)","5d521d95":"RES_CHKP = os.path.join(CHECK_POINT,DEF_MODEL[1][0])\nRES_WEIGHTS = os.path.join(WEIGHTS_PATH, DEF_MODEL[1][0])\nRES_LOGS = os.path.join(LOGS_PATHS, DEF_MODEL[1][0])","1f8afccc":"# DenseNet Chechpoint directory\nos.mkdir(RES_CHKP)\n# DenseNet Weights directory\nos.mkdir(RES_WEIGHTS)\n# DenseNet Logs directory\nos.mkdir(RES_LOGS)","ea7aa022":"checkpoint = ModelCheckpoint(\n    filepath=os.path.join(RES_CHKP,f'chkp_best.hdf5'),\n    save_weights_only=True,\n    save_best_only=False,\n    verbose=1,\n    save_freq='epoch',\n)","cd16f077":"callbacks = [\n    checkpoint,\n    TensorBoard(log_dir=RES_LOGS,histogram_freq=0, write_graph=True, write_images=True,update_freq='epoch'),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1,\n                      verbose=1, mode=\"min\", min_lr=1e-8),\n]","22dbe2ac":"print(\"** compile model with class weights **\")\ninitial_learning_rate=0.001\noptimizer = Adam(lr=initial_learning_rate)\nres_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\",metrics=METRICS)","09ef1492":"# model.summary()","847351cb":"print(f\"Total number of parameters is {res_model.count_params()}\")","225ec7cf":"hist2 = res_model.fit(x=train_sequence,\n                      batch_size=32,\n                      validation_data=validation_sequence,\n                      verbose=1,\n                      epochs=EPOCHS,\n                      workers=4,\n                      class_weight=classWeights,\n                      callbacks=callbacks)","6966d27e":"plt.plot(hist2.history['accuracy'])\nplt.plot(hist2.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","5b3d35ef":"plt.plot(hist2.history['loss'])\nplt.plot(hist2.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","f2660887":"res_model.save_weights(\"res_net_weights.h5\")","b910582f":"y_pred_res = res_model.predict(x=test_sequence,\n                               verbose=1,\n                               workers=4)","e1942ef3":"# confusion_matrix=multilabel_confusion_matrix(y_true, y_pred_res)\n# df_cm = pd.DataFrame(confusion_matrix, index = [i for i in \"ABCDEFGHIJK\"],\n#                   columns = [i for i in \"ABCDEFGHIJK\"])\n# plt.figure(figsize = (10,7))\n# sn.heatmap(df_cm, annot=True)\ny_pred_res_argmax = np.argmax(y_pred_res, axis=1)\nconfusion_matrix=multilabel_confusion_matrix(y_true_argmax, y_pred_res_argmax)\n\nfig, ax = plt.subplots(7, 2, figsize=(25, 15))\nfor axes, cfs_matrix, label in zip(ax.flatten(), confusion_matrix, CLASS_NAMES):\n    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n    \nfig.tight_layout()\nplt.show()\n","316ac69b":"print(\"\\nClassification report : \\n\",classification_report(y_true_argmax, y_pred_res_argmax, target_names=CLASS_NAMES))","e030ef8f":"IMAGE_INPUT = tf.keras.applications.inception_v3.preprocess_input(IMG_INPUT)\nIncNet = get_model(class_names=CLASS_NAMES,\n                   model=DEF_MODEL[2],\n                   input_shape=INPUT_SHAPE,\n                   input_tensor=IMG_INPUT,\n                   train=True,weights=\"imagenet\")","00695539":"x = IncNet.output\nx = GlobalAveragePooling2D()(x)","9b263687":"x.get_shape()","a590ccc2":"predictions = Dense(len(CLASS_NAMES), activation=\"sigmoid\", name=\"predictions\")(x)\ninc_model = Model(inputs=IMG_INPUT, outputs=predictions)","1ae4b38e":"INC_CHKP = os.path.join(CHECK_POINT,DEF_MODEL[2][0])\nINC_WEIGHTS = os.path.join(WEIGHTS_PATH, DEF_MODEL[2][0])\nINC_LOGS = os.path.join(LOGS_PATHS, DEF_MODEL[2][0])","1d6f978b":"# DenseNet Chechpoint directory\nos.mkdir(INC_CHKP)\n# DenseNet Weights directory\nos.mkdir(INC_WEIGHTS)\n# DenseNet Logs directory\nos.mkdir(INC_LOGS)","48bee2e4":"checkpoint = ModelCheckpoint(\n    filepath=os.path.join(INC_CHKP,f'chkp_best.hdf5'),\n    save_weights_only=True,\n    save_best_only=True,\n    verbose=1,\n    save_freq='epoch',\n)","afc854e9":"callbacks = [\n    checkpoint,\n    TensorBoard(log_dir=INC_LOGS,histogram_freq=0, write_graph=True, write_images=True,update_freq='epoch'),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1,\n                      verbose=1, mode=\"min\", min_lr=1e-8),\n]","c37bd052":"print(\"** compile model with class weights **\")\ninitial_learning_rate=0.001\noptimizer = Adam(lr=initial_learning_rate)\ninc_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\",metrics=METRICS)","798b9a73":"print(f\"Total number of parameters is {inc_model.count_params()}\")","518210d6":"hist3 = inc_model.fit(x=train_sequence,batch_size=32,\n                      validation_data=validation_sequence,\n                      verbose=1,\n                      epochs=EPOCHS,\n                      workers=4,\n                      class_weight=classWeights,\n                      callbacks=callbacks)","1024833d":"plt.plot(hist3.history['accuracy'])\nplt.plot(hist3.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","3ad98d19":"plt.plot(hist3.history['loss'])\nplt.plot(hist3.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","b3fba35d":"inc_model.save_weights(\"inc_net_weights.h5\")","40666582":"y_pred_inc = inc_model.predict(x=test_sequence,\n                               verbose=1,\n                               workers=4)","50984d4c":"# confusion_matrix=multilabel_confusion_matrix(y_true, y_pred_inc)\n# df_cm = pd.DataFrame(confusion_matrix, index = [i for i in \"ABCDEFGHIJK\"],\n#                   columns = [i for i in \"ABCDEFGHIJK\"])\n# plt.figure(figsize = (10,7))\n# sn.heatmap(df_cm, annot=True)\n\ny_pred_inc_argmax = np.argmax(y_pred_inc, axis=1)\nconfusion_matrix=multilabel_confusion_matrix(y_true_argmax, y_pred_inc_argmax)\n\nfig, ax = plt.subplots(7, 2, figsize=(25, 15))\nfor axes, cfs_matrix, label in zip(ax.flatten(), confusion_matrix, CLASS_NAMES):\n    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n    \nfig.tight_layout()\nplt.show()","9371a9c3":"print(\"\\nClassification report : \\n\", classification_report(y_true_argmax, y_pred_inc_argmax, target_names=CLASS_NAMES))","b15bf300":"IMAGE_INPUT = tf.keras.applications.mobilenet_v2.preprocess_input(IMG_INPUT)\nMobileNet = get_model(class_names=CLASS_NAMES,\n                   model=DEF_MODEL[3],\n                   input_shape=INPUT_SHAPE,\n                   input_tensor=IMG_INPUT,\n                   train=True, weights=\"imagenet\")","b8d65130":"x = MobileNet.output\nx = GlobalAveragePooling2D()(x)","4aad0ce9":"x.get_shape()","b0ab19d3":"predictions = Dense(len(CLASS_NAMES), activation=\"sigmoid\", name=\"predictions\")(x)\nmobile_model = Model(inputs=IMG_INPUT, outputs=predictions)","561a371c":"MOB_CHKP = os.path.join(CHECK_POINT,DEF_MODEL[3][0])\nMOB_WEIGHTS = os.path.join(WEIGHTS_PATH, DEF_MODEL[3][0])\nMOB_LOGS = os.path.join(LOGS_PATHS, DEF_MODEL[3][0])","86874144":"# DenseNet Chechpoint directory\nos.mkdir(MOB_CHKP)\n# DenseNet Weights directory\nos.mkdir(MOB_WEIGHTS)\n# DenseNet Logs directory\nos.mkdir(MOB_LOGS)","37dba8d3":"checkpoint = ModelCheckpoint(\n    filepath=os.path.join(MOB_CHKP,f'chkp_besT.hdf5'),\n    save_weights_only=True,\n    save_best_only=False,\n    verbose=1,\n    save_freq='epoch',\n)","f7f26bd4":"callbacks = [\n    checkpoint,\n    TensorBoard(log_dir=MOB_LOGS,histogram_freq=0, write_graph=True, write_images=True,update_freq='epoch'),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1,\n                      verbose=1, mode=\"min\", min_lr=1e-8),\n]","40fbd8d5":"print(\"** compile model with class weights **\")\ninitial_learning_rate=0.001\noptimizer = Adam(lr=initial_learning_rate)\nmobile_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\",metrics=METRICS)","7c94755c":"print(f\"Total number of parameters is {mobile_model.count_params()}\")","2eff6b95":"hist4 = mobile_model.fit(x=train_sequence,batch_size=32,\n                         validation_data=validation_sequence,\n                         verbose=1,\n                         epochs=EPOCHS,\n                         workers=4,\n                         class_weight=classWeights,\n                         callbacks=callbacks)","3a4cb67a":"# summarize history for accuracy\nplt.plot(hist4.history['accuracy'])\nplt.plot(hist4.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e7fd9aa4":"# summarize history for loss\nplt.plot(hist4.history['loss'])\nplt.plot(hist4.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c6de9fea":"mobile_model.save_weights(\"mobile_net_weights.h5\")","7e8ca961":"y_pred_mobile = mobile_model.predict(x=test_sequence,\n                                     verbose=1,\n                                     workers=4)","e2dc1c61":"# confusion_matrix=multilabel_confusion_matrix(y_true, y_pred_mobile)\n# df_cm = pd.DataFrame(confusion_matrix, index = [i for i in \"ABCDEFGHIJK\"],\n#                   columns = [i for i in \"ABCDEFGHIJK\"])\n# plt.figure(figsize = (10,7))\n# sn.heatmap(df_cm, annot=True)\ny_pred_mobile_argmax = np.argmax(y_pred_mobile, axis=1)\nconfusion_matrix=multilabel_confusion_matrix(y_true_argmax, y_pred_mobile_argmax)\nfig, ax = plt.subplots(7, 2, figsize=(25, 15))\nfor axes, cfs_matrix, label in zip(ax.flatten(), confusion_matrix, CLASS_NAMES):\n    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n    \nfig.tight_layout()\nplt.show()","1a2e5729":"print(\"\\nClassification report : \\n\", classification_report(y_true_argmax, y_pred_mobile_argmax, target_names=CLASS_NAMES))","5d3cbeb2":"class ModelFactory:\n    \"\"\"\n    Model factory for Keras default models\n    Select one of: VGG16, VGG19, DenseNet121, ResNet50, InceptionV3, InceptionResNetV2,\n    NASNetMobile, NASNetLarge\n    \"\"\"\n\n    def __init__(self):\n        self.models_ = dict(\n            VGG16=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"vgg16\",\n                last_conv_layer=\"block5_conv3\",\n            ),\n            VGG19=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"vgg19\",\n                last_conv_layer=\"block5_conv4\",\n            ),\n            DenseNet121=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"densenet\",\n                last_conv_layer=\"bn\",\n            ),\n            ResNet50=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"resnet50\",\n                last_conv_layer=\"activation_49\",\n            ),\n            InceptionV3=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"inception_v3\",\n                last_conv_layer=\"mixed10\",\n            ),\n            InceptionResNetV2=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"inception_resnet_v2\",\n                last_conv_layer=\"conv_7b_ac\",\n            ),\n            NASNetMobile=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"nasnet\",\n                last_conv_layer=\"activation_188\",\n            ),\n            NASNetLarge=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"nasnet\",\n                last_conv_layer=\"activation_260\",\n            ),\n            MobileNetV2=dict(\n                input_shape=(256, 256, 3),\n                module_name=\"mobilenet_v2\",\n                last_conv_layer=\"block_16_project_BN\"\n            ),\n        )\n\n    def get_model(self, class_names, model_name=\"DenseNet121\",\n                  weights_path=None, input_shape=None, input_tensor=None, train=False):\n        \n        base_weights = \"imagenet\"\n        base_model_class = getattr(\n            importlib.import_module(\n                f\"tensorflow.keras.applications.{self.models_[model_name]['module_name']}\"\n            ),\n            model_name)\n        if input_shape is None:\n            input_shape = self.models_[model_name][\"input_shape\"]\n            \n        img_input = input_tensor\n        base_model = base_model_class(\n            include_top=False,\n            input_tensor=input_tensor,\n            input_shape=input_shape,\n            weights=base_weights,\n        )\n        base_model.trainable = train\n        x = base_model(img_input)\n        if weights_path == \"\":\n            weights_path = None\n\n        if weights_path is not None:\n            print(f\"load model weights_path: {weights_path}\")\n            x.load_weights(weights_path)\n        return x\n    def Concatenation(self,layers) :\n        return tf.concat(layers, axis=3,name='Concatenation')\n    \n    def transition_layer(self, x):\n        x = BatchNormalization()(x)\n        x = ReLU()(x)\n        in_channel = x.shape[-1]\n        x = Conv2D(filters=in_channel*0.5, kernel_size=[1,1])(x)\n        return x\n    \n    def lse_pool(self, cat):\n        return reduce_logsumexp(cat,axis=[1,2],keepdims=True)\n    \n    def build(self, class_names, weights_path=None, inp_shape=None):\n        img_input = Input(shape=inp_shape)\n        mob_input = mobilenet_v2.preprocess_input(img_input)\n        res_input = resnet50.preprocess_input(img_input)\n        dense_input= densenet.preprocess_input(img_input)\n        inc_input = inception_v3.preprocess_input(img_input)\n        input_shape = inp_shape\n        x1 = self.get_model(class_names,\n                            model_name=\"ResNet50\",\n                            weights_path=None,\n                            input_shape=input_shape,\n                            input_tensor=res_input,\n                            train=False)\n        x2 = self.get_model(class_names,\n                            model_name=\"InceptionV3\",\n                            weights_path=None,\n                            input_shape=input_shape,\n                            input_tensor=inc_input,\n                            train=False)\n        x3 = self.get_model(class_names,\n                            model_name=\"DenseNet121\",\n                            weights_path=None,\n                            input_tensor=dense_input,\n                            train=False)\n        x4 = self.get_model(class_names,\n                            model_name=\"MobileNetV2\",\n                            weights_path=None,\n                            input_shape=input_shape,\n                            input_tensor=mob_input,\n                            train=False)\n        \n        x2 = ZeroPadding2D(((1,1),(1,1)))(x2)\n        x = self.Concatenation([x1,x2,x3,x4])\n        print(x.shape[-1])\n        x = self.transition_layer(x)\n        x = self.lse_pool(x)\n        x = Flatten()(x)\n        x= Dropout(0.2)(x)\n        x= Dense(1024,activation='relu')(x) \n        x= Dense(512,activation='relu')(x) \n        x= Dropout(0.2)(x)\n        predictions = Dense(len(class_names), activation=\"sigmoid\", name=\"predictions\")(x)\n        return Model(inputs=img_input, outputs=predictions)","42967e2c":"model_factory = ModelFactory()\nmodel = model_factory.build(\n    CLASS_NAMES,\n    weights_path=None,\n    inp_shape=(IMAGE_DIM, IMAGE_DIM, 3))","e9d0cc9f":"checkpoint = ModelCheckpoint(\n    filepath=os.path.join(WEIGHTS_PATH, \"chkp_best_weights.hdf5\"),\n    save_weights_only=True,\n    save_best_only=False,\n    verbose=1,\n    save_freq='epoch',\n)","f1b578e7":"callbacks = [\n    checkpoint,\n    TensorBoard(log_dir=LOGS_PATHS,histogram_freq=0, write_graph=True, write_images=True,update_freq='epoch'),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1,\n                      verbose=1, mode=\"min\", min_lr=1e-8),\n]","8d9a4a21":"METRICS = [Accuracy(name='accuracy'),AUC(name='AUC'), BinaryAccuracy('BinAcc')]","267dd1d7":"model.compile(optimizer='adam', loss=BinaryCrossentropy(from_logits=True),metrics=METRICS)","f180b089":"hist = model.fit(x=train_sequence,\n                 batch_size=32,\n                 validation_data=validation_sequence,\n                 validation_steps=validation_steps,\n                 verbose=1,\n                 epochs=10,\n                 workers=4)","a2d46c7c":"plt.plot(hist.history['BinAcc'])\nplt.plot(hist.history['val_BinAcc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","549363f0":"plt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","20a49513":"y_pred = model.predict(x=test_sequence,\n                       verbose=1,\n                       workers=4)","14fa60e3":"y_pred_argmax = np.argmax(y_pred, axis=1)\nconfusion_matrix=multilabel_confusion_matrix(y_true_argmax, y_pred_argmax)\nfig, ax = plt.subplots(7, 2, figsize=(25, 15))\nfor axes, cfs_matrix, label in zip(ax.flatten(), confusion_matrix, CLASS_NAMES):\n    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n    \nfig.tight_layout()\nplt.show()","b5f19a50":"print(\"\\nClassification report : \\n\", classification_report(y_true_argmax, y_pred_argmax,target_names=CLASS_NAMES))","59542c56":"#### Multi-label classification report","8c341860":"## Model Factory","973239ab":"Import Required Libraries","16dd6edc":"## MobileNet V2","c850ae62":"#### Model creation end","92b7bd7e":"CONFUSION MATRIX CODE****","cb42c8e4":"### Save Weights","7944daf5":"y_pred_inc = inc_model.predict(x=test_sequence,\n                               verbose=1,\n                               workers=4)#### summarize history for loss\n","7b1b52f0":"#### Now Compiling the model","7032f5e6":"#### Checkpoints ","0a2b6025":"#### Defining callbacks for DenseNet","ef3298b8":"### Predictions","820cb321":"### Predictions","5ddaab70":"### Save Weights","1e93803a":"#### summarize history for loss\n","bb415db3":"#### Multi-label classification report","12dc8846":"### Class weights generartor\n* Due to imbalanced distribution of dataset.","472bbbc4":"#### Making directories for storing weights, logs, checkpoints","fea8b80b":"#### summarize history for loss\n","7d7aa709":"#### Important parameters","0f779e3d":"#### Multi-label classification report","d46b2a3d":"#### summarize history for accuracy\n","70ebc179":"#### Multi-label classification report","c1ebe494":"#### Plot training & validation loss values","e3192830":"## ResNet50 model","be020ac5":"#### Chechkpoint","37680010":"#### Multi-label confusion matrix","15f2e190":"### Load Tensorboard","da1e30d6":"#### Defining the model","007aa3aa":"#### Class weights ","b485c2ae":"### Metrics","68d5621a":"## InceptionNet V3","ad18e0e7":"### Barplot to represent the Multi-labels","d510b207":"## Training the models","fbd42b5d":"## Data Pipeline","6c9fac4e":"### Callback parameters","b130b80b":"#### Multi-label confusion matrix","21ebb089":"### Barplot to represent the Train Datset","345a1f2e":"### Save Weights","8e31e7e1":"#### Multi-label confusion matrix","4b6ba4df":"### Callback","a4d059dc":"#### Multi-label confusion matrix","d436fd94":"#### Multi-label confusion matrix","81bc4033":"#### Multi-label classification report","2e300be8":"#### summarize history for accuracy\n","de454d61":"### Predictions","fde0edf4":"### Compiling the model","481ec486":"#### Plot training & validation accuracy values","4a4cfcb9":"#### Model creation","011178aa":"#### Defining the Input","d34c4cc2":"#### summarize history for accuracy\n","732cd25f":"#### Fitting the model","d201a181":"### Predictions","31465b7a":"#### Metrics","0e1c5243":"### Y Test true labels","16dc8dea":"### Model Summary","9b44b492":"### Predictions","7e2631c8":"#### Callabcks for the model","8ce3aba6":"### DenseNet Model "}}