{"cell_type":{"f053b2e2":"code","7eaf48aa":"code","030a93be":"code","215a0692":"code","01c724da":"code","849af237":"code","2dc67385":"code","1d0a2990":"code","eb3d8202":"code","3d66ee42":"code","0665e221":"code","ff72b7bf":"code","6c3fbdf6":"code","4a5cc0be":"code","60347b66":"code","fc016b4d":"code","fadc2232":"code","c28ea154":"code","1e6cde70":"code","0ab8e575":"code","c540ca87":"code","08c56512":"code","53899e52":"code","bdab46e7":"code","a3a8bb4c":"code","a5c2d024":"code","1227b2b8":"code","4a15df95":"code","5cca153a":"code","9a51f917":"code","19a211e6":"code","667c3568":"code","81b5a5c4":"code","119e8ed3":"code","b000a5f0":"code","d658af79":"code","d0f468c5":"code","6238e5f2":"code","8da5bac9":"code","48e9e206":"code","b3334b53":"code","12453a4d":"code","835ba34b":"code","4aaef320":"code","cbf96478":"code","dfb8207a":"code","7626cdd9":"code","3a1ad344":"code","b07dfc93":"code","26fb06e2":"code","50373389":"code","8eefaa44":"code","bb570ec5":"code","d45b73c8":"code","a1ad728a":"code","7c5547ff":"code","b4f458b9":"code","a94a6036":"code","8db7605f":"code","fa04f8c5":"code","d238bef4":"code","3345d9bd":"code","e16c542d":"code","2fb55cce":"code","2e5e035d":"code","a75ac33e":"code","e966c782":"code","bd188a9e":"code","510318b4":"markdown","6cbf3dc0":"markdown","1dd00ea5":"markdown","98c36719":"markdown","20ecad0d":"markdown","145385be":"markdown","c78e48df":"markdown","4d9da7c7":"markdown","332c343a":"markdown","f9641aac":"markdown","62382e56":"markdown","1f97d9d5":"markdown","25aeea2b":"markdown","2266e1f1":"markdown","42438f2c":"markdown","fc239174":"markdown","77811ba2":"markdown","47de1ed0":"markdown","ca5da291":"markdown","bb8698e0":"markdown","f23e3d9c":"markdown","80862061":"markdown","1fc9df80":"markdown","51d071eb":"markdown"},"source":{"f053b2e2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict","7eaf48aa":"df = pd.read_csv('..\/input\/data-analyst-jobs\/DataAnalyst.csv')\ndf.shape","030a93be":"df.head()","215a0692":"states_df = pd.read_csv('..\/input\/latitude-and-longitude-for-every-country-and-state\/world_country_and_usa_states_latitude_and_longitude_values.csv')","01c724da":"print(df.isnull().any()) # To check whether any column in dataset has null values\n# df = df.drop(columns = [\"Unnamed: 0\",\"Easy Apply\",\"Competitors\"]) # dropping the columns which I will not use for analysis\ndf.shape # Check the shape of the dataset -> Rows and Columns","849af237":"df = df.dropna()","2dc67385":"df = df[~df[\"Salary Estimate\"].str.contains(\"Per Hour\")] # Removing the salary estimates given as per hour basis\ndf.shape # only 4 rows were deleted","1d0a2990":"df[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"(Glassdoor est.)\", \"\",regex=True) # Remove the \"Glassdoor est.\" keyword\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"(Employer est.)\", \"\",regex=True)  # Remove the \"Employer est.\" Keyword\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"K\", \"\",regex=True) # Remove the Letter K\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].apply(lambda x: x.strip('()')) # Remove the \"()\" from the end\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"$\", \"\",regex=True) # Remove the dollar '$' sign\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"-\", \" \",regex=True) # Remove the '-' sign","eb3d8202":"df[\"Salary Estimate\"] = df[\"Salary Estimate\"].apply(lambda x: x.strip(' ')) # Remove the whitespaces\ndf[['Salary Estimate Lower Bound','Salary Estimate Upper Bound']] = df[\"Salary Estimate\"].str.split(\" \",expand=True) # split the Salary Estimate into upper and lower bound\ndf = df.drop(columns = \"Salary Estimate\") # drop the salary estimate column","3d66ee42":"df[\"Salary Estimate Lower Bound\"] = df[\"Salary Estimate Lower Bound\"].replace({'\\$':\"\"},regex=True) # Remove the dollar '$' sign from lower bound\ndf[\"Salary Estimate Upper Bound\"] = df[\"Salary Estimate Upper Bound\"].replace({'\\$':\"\"},regex=True) # Remove the dollar '$' sign from upper bound","0665e221":"df.head(50)","ff72b7bf":"df = df.dropna(axis=0) # drop the null values","6c3fbdf6":"df[\"Salary Estimate Lower Bound\"] = df[\"Salary Estimate Lower Bound\"].astype(str).astype(int) # Convert the column from string to integer\ndf[\"Salary Estimate Upper Bound\"] = df[\"Salary Estimate Upper Bound\"].astype(str).astype(int) # Convert the column from string to integer","4a5cc0be":"df[\"Size\"] = df[\"Size\"].replace(\"employees\", \"\",regex=True)  # Remove the \"employees\" keyword\ndf[\"Size\"] = df[\"Size\"].replace(\"to\", \" \",regex=True) # Remove the \"to\" keyword\ndf[\"Size\"] = df[\"Size\"].replace({'\\+':\" 0\"},regex=True) # Remove the \"+\" sign\n","60347b66":"df[\"Size\"] = df[\"Size\"].apply(lambda x: x.strip(' ')) # Remove the whitespaces\ndf[\"Size\"] = df[\"Size\"].replace(\"   \", \" \",regex=True) # Replace double space with single space so that we can split the column\ndf[['Size Lower Bound','Size Upper Bound']] = df[\"Size\"].str.split(\" \",expand=True) # Split the Size column in upper and lower bound\ndf = df.drop(columns = \"Size\") # drop the Size column","fc016b4d":"df[\"Size Upper Bound\"] = df[\"Size Upper Bound\"].replace(\"0\", \"10001\") \ndf[\"Size Lower Bound\"] = df[\"Size Lower Bound\"].replace(\"10000\", \"0\")","fadc2232":"df['Company Name'] = df[\"Company Name\"].str.partition(\"\\n\")","c28ea154":"df[\"Size Lower Bound\"] = df[\"Size Lower Bound\"].replace(\"-1\", \"Unknown\",regex=True)\ndf[\"Type of ownership\"] = df[\"Type of ownership\"].replace(\"-1\", \"Unknown\",regex=True)\ndf[\"Industry\"] = df[\"Industry\"].replace(\"-1\", \"Unknown\",regex=True)\ndf[\"Sector\"] = df[\"Sector\"].replace(\"-1\", \"Unknown\",regex=True)","1e6cde70":"def filter_revenue(x):\n    revenue=0\n    if(x== 'Unknown \/ Non-Applicable' or type(x)==float):\n        revenue=0                                                                                   # Max Revenue will be 0 if the range is Unknown or non-applicable \n    elif(('million' in x) and ('billion' not in x)):\n        maxRev = x.replace('(USD)','').replace(\"million\",'').replace('$','').strip().split('to')    # Remove the words such as: USD, million, $, to\n        if('Less than' in maxRev[0]):\n            revenue = float(maxRev[0].replace('Less than','').strip())                              # Remove the \"less than\" keyword and also remove the whitespaces\n        else:\n            if(len(maxRev)==2):\n                revenue = float(maxRev[1])\n            elif(len(maxRev)<2): \n                revenue = float(maxRev[0])\n    elif(('billion'in x)):\n        maxRev = x.replace('(USD)','').replace(\"billion\",'').replace('$','').strip().split('to')    # Remove the words such as: USD, billion, $, to\n        if('+' in maxRev[0]):\n            revenue = float(maxRev[0].replace('+','').strip())*1000                                 #  Remove the \"+\" sign and also remove the whitespaces\n        else:\n            if(len(maxRev)==2):\n                revenue = float(maxRev[1])*1000\n            elif(len(maxRev)<2):\n                revenue = float(maxRev[0])*1000\n    return revenue","0ab8e575":"df['Max_revenue']=df['Revenue'].apply(lambda x: filter_revenue(x))","c540ca87":"states_df = states_df.drop(columns = [\"country_code\",\"usa_state\",\"country\",\"latitude\",\"longitude\"])","08c56512":"states_df = states_df.dropna() # drop the null values","53899e52":"df[['City','State','extra']] = df[\"Location\"].str.split(\",\",expand=True) \ndf = df[~df[\"State\"].str.contains(\"United Kingdom\")] # Removing United Kingdom from state!\ndf = df[~df[\"State\"].str.contains(\"Arapahoe\")] # Removing United Kingdom from state!","bdab46e7":"df=df.drop(columns=[\"extra\"])","a3a8bb4c":"df['State'] = df['State'].str.lstrip() # Remove the whitespaces from front\nlatitude = states_df['usa_state_latitude'].to_list() # Make a list of all the states \nlongitude = states_df['usa_state_longitude'].to_list() # Make a list of all the latitudes of a state\nstates = states_df['usa_state_code'].to_list() # Make a list of all the longitudes of a state","a5c2d024":"def find_latitude(x,states,latitude):\n    index = states.index(x)\n    return latitude[index]","1227b2b8":"def find_longitude(x,states,longitude):\n    index = states.index(x)\n    return longitude[index]","4a15df95":"df['latitude']= df['State'].apply(lambda x: find_latitude(x,states,latitude))\ndf['longitude']= df['State'].apply(lambda x: find_longitude(x,states,longitude))","5cca153a":"df","9a51f917":"df1 = df[df[\"Rating\"]>1]\nsns.distplot(df1[\"Rating\"],)\nplt.title('Distribution of Ratings Column')\nplt.show()","19a211e6":"plt.hist(df1['Rating'], density=True, cumulative=True, label='CDF',histtype='step');","667c3568":"sns.distplot(df[\"Salary Estimate Lower Bound\"])\nplt.title('Distribution of Salary Estimate Lower Bound Column')\nplt.show()","81b5a5c4":"sns.distplot(df[\"Salary Estimate Upper Bound\"])\nplt.title('Distribution of Salary Estimate Lower Bound Column')\nplt.show()","119e8ed3":"plt.figure(figsize = (15,5))\n\ndf[\"Company Name\"].value_counts().sort_values(ascending=False).head(20).plot.bar(color = \"orange\",fontsize=12, edgecolor='Red', linewidth = 2)\nplt.title(\"Top 20 Company with Highest number of jobs for Data Analyst posistion\")\nplt.xlabel(\"Company Name\",fontsize=15)\nplt.ylabel(\"Count\")\n\nplt.show()","b000a5f0":"plt.figure(figsize = (15,5))\ndf[\"Job Title\"].value_counts().sort_values(ascending=False).head(20).plot.bar(color= \"Red\", fontsize=12, edgecolor='green',linewidth = 2)\nplt.title(\"Top 20 Data Analyst Job\")\nplt.xlabel(\"Job Title\",fontsize=15)\nplt.ylabel(\"Count\")\nplt.show()","d658af79":"plt.figure(figsize = (10,5))\ndf[\"Location\"].value_counts().sort_values(ascending=False).head(20).plot.bar(color= \"Blue\", fontsize=12)\nplt.title(\"Top 20 locations for Data Analyst Job\")\nplt.xlabel(\"Locations\",fontsize=15)\nplt.ylabel(\"Count\")\nplt.show()","d0f468c5":"plt.figure(figsize = (50,8))\ndf[\"Headquarters\"].value_counts().sort_values(ascending=False).head(15).plot.pie(y=\"Headquarters\",autopct=\"%0.1f%%\")\nplt.title(\"Head Quarters according to Locations\")\nplt.axis(\"off\")\nplt.show()","6238e5f2":"plt.figure(figsize = (10,5))\ndf[\"Type of ownership\"].value_counts().sort_values(ascending=False).plot.bar(color= \"Orange\",fontsize=12)\nplt.title(\"Types of Ownership\")\nplt.xlabel(\"Ownership\",fontsize=15)\nplt.ylabel(\"Count\")\nplt.show()","8da5bac9":"plt.figure(figsize = (10,5))\ndf[\"Sector\"].value_counts().sort_values(ascending=False).plot.bar(color= \"red\",fontsize=12)\nplt.title(\"Different types of Sectors in Data Analyst\")\nplt.xlabel(\"Sectors\",fontsize=15)\nplt.ylabel(\"Count\")\nplt.show()","48e9e206":"plt.figure(figsize = (10,5))\ndf[\"Founded\"].value_counts().sort_values(ascending=False)[1:21].plot.bar(color= \"Green\",fontsize=12)\nplt.title(\"Number of Company, Founded in a Year\",fontsize=20)\nplt.xlabel(\"Foundation Year\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.show()","b3334b53":"ax = sns.boxplot(x=df[\"Rating\"])","12453a4d":"df2 = df.groupby('Sector')[['Max_revenue']].mean().sort_values(['Max_revenue'],ascending=False).head(20)","835ba34b":"df2.head(20)","4aaef320":"df2.reset_index(inplace=True)\nplt.figure(figsize=(10,5))\nchart = sns.barplot(\n    data=df2,\n    x='Sector',\n    y='Max_revenue'\n)\nchart.set_xticklabels(\n    chart.get_xticklabels(), \n    rotation=65, \n    horizontalalignment='right',\n    fontweight='light',\n \n)\nchart.axes.yaxis.label.set_text(\"Revenue(Million dollars)\")","cbf96478":"df3 = df.groupby('Industry')[['Max_revenue']].mean().sort_values(['Max_revenue'],ascending=False).head(20)","dfb8207a":"df3.reset_index(inplace=True)\nplt.figure(figsize=(10,5))\nchart = sns.barplot(\n    data=df3,\n    x='Industry',\n    y='Max_revenue',\n    palette='Set1'\n)\nchart.set_xticklabels(\n    chart.get_xticklabels(), \n    rotation=65, \n    horizontalalignment='right',\n    fontweight='light',\n \n)\nchart.axes.yaxis.label.set_text(\"Revenue(Million dollars)\")\n","7626cdd9":"from wordcloud import WordCloud\njob_title=df['Job Title'][~pd.isnull(df['Job Title'])]\nwordCloud = WordCloud(background_color = 'lightpink',width=2000,height= 2000).generate(' '.join(job_title))\nplt.figure(figsize=(19,9))\nplt.axis('off')\nplt.title(df['Job Title'].name,fontsize=20)\nplt.imshow(wordCloud)\nplt.show()","3a1ad344":"pg_lan = [\"python\",\"c++\",\"java\",\"matlab\",\".net\",\"c#\",\"javascript\",\"html\",\"bash\"]\nbig_data = [\"big data\",\"hadoop\",\"spark\",\"impala\",\"cassandra\",\"kafka\",\"hdfs\",\"hbase\",\"hive\"]\nexp_edu = [\"experience\",\"bs\",\"ms\",\"phd\",\"full-time\",\"intern\",\"remote\",\"master\",\"doctorate\",\"computer science\",\"bachelor\"]\ncloud = [\"aws\",\"gcp\",\"azure\",\"s3\",\"redshift\",\"ec2\",\"lambda\",\"route s3\",\"dynamo db\"]\nds_ml = [\"time series\",\"machine learning\",\"regression\",\"stat\",\"numpy\",\"pandas\",\"data visualization\",\"data analysis\",\"time series\",\"data cleaning\",\"deep learning\"]\nother_skills = [\"sql\",\"mongo db\",\"excel\",\"sas\",\"nosql\",\"communication\"]\njob = df[\"Job Description\"].tolist()","b07dfc93":"job = [x.lower() for x in job]","26fb06e2":"pg_lan_required = defaultdict()\nfor item in pg_lan:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    pg_lan_required[item] = counter\n\npg_lan_df = pd.DataFrame(list(pg_lan_required.items()),columns = ['Programming Langauge','count']) \npg_lan_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","50373389":"plt.figure(figsize = (15,5))\nx = pg_lan_df[\"Programming Langauge\"]\ny = pg_lan_df[\"count\"]\nplt.bar(x,y,color= \"blue\")\nplt.title(\"Top programming languages requrired by the companies\",fontsize=15)\nplt.xlabel(\"Programming Languages\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in pg_lan_required.items():\n    plt.text(k,v+25, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","8eefaa44":"counter = 0\nbig_data_required = defaultdict()\nfor item in big_data:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    big_data_required[item] = counter\n\nbig_data_df = pd.DataFrame(list(big_data_required.items()),columns = ['Big Data Technologies','count']) \nbig_data_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","bb570ec5":"plt.figure(figsize = (15,5))\nx = big_data_df[\"Big Data Technologies\"]\ny = big_data_df[\"count\"]\nplt.bar(x,y,color= \"orange\")\nplt.title(\"Top Big Data Technologies requrired by the companies\",fontsize=15)\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in big_data_required.items():\n    plt.text(k,v+5, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","d45b73c8":"exp_edu_required = defaultdict()\nfor item in exp_edu:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    exp_edu_required[item] = counter\n    \nexp_edu_df = pd.DataFrame(list(exp_edu_required.items()),columns = ['Experience\/Education','count']) \nexp_edu_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","a1ad728a":"plt.figure(figsize = (15,5))\nx = exp_edu_df[\"Experience\/Education\"]\ny = exp_edu_df[\"count\"]\nplt.bar(x,y,color= \"blue\")\nplt.title(\"Experience\/Education requrired by the companies\",fontsize=15)\nplt.xlabel(\"Experience\/Education\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in exp_edu_required.items():\n    plt.text(k,v+25, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","7c5547ff":"counter = 0\ncloud_required = defaultdict()\nfor item in cloud:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    cloud_required[item] = counter\n\n\n\ncloud_df = pd.DataFrame(list(cloud_required.items()),columns = ['cloud ','count']) \ncloud_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","b4f458b9":"plt.figure(figsize = (15,5))\nx = cloud_df[\"cloud \"]\ny = cloud_df[\"count\"]\nplt.bar(x,y,color= \"red\")\nplt.title(\"Top cloud computing skills requrired by the companies\",fontsize=15)\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in cloud_required.items():\n    plt.text(k,v+5, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","a94a6036":"counter = 0\nds_ml_required = defaultdict()\nfor item in ds_ml:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    ds_ml_required[item] = counter\n\nds_ml_df = pd.DataFrame(list(ds_ml_required.items()),columns = ['Data Analyst\/Machine Learning Skills ','count']) \nds_ml_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","8db7605f":"plt.figure(figsize = (15,5))\nx = ds_ml_df[\"Data Analyst\/Machine Learning Skills \"]\ny = ds_ml_df[\"count\"]\nplt.bar(x,y,color= \"orange\")\nplt.title(\"Top data Analyst or machine learning skills requrired by the companies\",fontsize=15)\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in ds_ml_required.items(): \n    plt.text(k,v+25, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","fa04f8c5":"counter = 0\nother_skills_required = defaultdict()\nfor item in other_skills:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    other_skills_required[item] = counter\n\n\nother_skills_df = pd.DataFrame(list(other_skills_required.items()),columns = ['Other Skills ','count']) \nother_skills_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","d238bef4":"plt.figure(figsize = (15,5))\nplt.title(\"other top skills required by companies\", fontsize=18)\nplt.bar(other_skills_df[\"Other Skills \"], other_skills_df[\"count\"],color= \"Green\")\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in other_skills_required.items(): \n    plt.text(k,v+25, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","3345d9bd":"import plotly.express as px\nfig = px.scatter(df, x='Rating', y='Salary Estimate Upper Bound',color=\"Rating\",hover_data=['Headquarters','Location', 'Type of ownership', 'Industry', 'Sector','Company Name'], title = \"Data Analyst jobs\")\nfig.show()","e16c542d":"df_sal = df.groupby('Location')[['Salary Estimate Upper Bound','Salary Estimate Lower Bound']].mean().sort_values(['Salary Estimate Upper Bound','Salary Estimate Lower Bound'],ascending=False)[0:30]\ndf_sal.plot(kind=\"barh\", figsize=(16,17), width=0.8)\nplt.ylabel(\"Location\")\nplt.xlabel(\"Salary\")\nplt.title(\"Min and Max Salary From Different Location\", fontweight=\"bold\")\n\nfor index, value in enumerate(df_sal[\"Salary Estimate Upper Bound\"]):\n    plt.text(value + 0.5, index - 0.4, str(value))\n    \n    \nfor index, value in enumerate(df_sal[\"Salary Estimate Lower Bound\"]):\n    plt.text(value + 0.2, index + 0.1, str(value))","2fb55cce":"df_sal = df.groupby('Job Title')[['Salary Estimate Upper Bound','Salary Estimate Lower Bound']].mean().sort_values(['Salary Estimate Upper Bound','Salary Estimate Lower Bound'],ascending=False)[:30]\ndf_sal.plot(kind=\"barh\", figsize=(16,17), width=0.8)\nplt.ylabel(\"Job Title\")\nplt.xlabel(\"Salary\")\nplt.title(\"Min and Max Salary of different Job Title\", fontweight=\"bold\")\n\nfor index, value in enumerate(df_sal[\"Salary Estimate Upper Bound\"]):\n    plt.text(value + 0.5, index - 0.4, str(value))\n    \n    \nfor index, value in enumerate(df_sal[\"Salary Estimate Lower Bound\"]):\n    plt.text(value + 0.2, index + 0.1, str(value))","2e5e035d":"df[\"State\"].value_counts().sort_values(ascending=False).head(20)","a75ac33e":"import folium\nimport folium.plugins as plugins","e966c782":"data_heat = df[['latitude','longitude','Rating']].values.tolist()","bd188a9e":"import folium.plugins as plugins\n\nm = folium.Map(location=[41, -102],zoom_start=4)\n\nplugins.HeatMap(data_heat).add_to(m)\n\nm","510318b4":"**Let's check how the dataset looks after cleaning**","6cbf3dc0":"**Read the Data Analyst job dataset**","1dd00ea5":"**Split the Location into City and State**","98c36719":"**Let's split Salary Estimate into lower & upper bound**\n\nAnd let's remove the rows having Salary on an hourly basis. We can change it and guess an estimate, but we don't know the no. of working hours","20ecad0d":"**Let's Look at the Cummulative Distributive Function for Ratings!**","145385be":"**So most of the Head Quarters are in New York, & \"-1\" is the no. of undeclared Head Quarters in the Dataset**","c78e48df":"**We don't require the codes of all the countries, since our dataset mostly deals with states in America.**","4d9da7c7":"**Now let's remove the \"\\n & rating\" from company Name**","332c343a":"**Let's do analysis on Job Description!**\n\n**We will check how many jobs require skills such as Hadoop, Python, Machine Learning etc.?**","f9641aac":"![image.png](attachment:image.png)","62382e56":"**Split Salary Estimate into lower & upper bound**","1f97d9d5":"**The 10000+ range was split with a lower bound of 10000 and upper bound as null**\n\n**The lower bound is updated to 0 and the upper bound is updated to 10001.**","25aeea2b":"**The filter_revenue function takes the input as the range of revenue and finds the max. revenue**","2266e1f1":"**This is how the dataset looks**","42438f2c":"**Replace \"-1\" with \"Unknown\"**","fc239174":"# Data Cleaning","77811ba2":"# Data Visualization","47de1ed0":"<center><h1><b>Data Analyst Job Analysis<\/b><\/h1><\/center>\n\n**1. Data Cleaning**\n\n**2. Data Visualization**\n\n\n**You can also check the same analysis on Data Scientist Jobs and Data Engineer Jobs**\n1. [Data Scientist Job Analysis](https:\/\/www.kaggle.com\/rohitsahoo\/data-scientist-jobs-analysis)\n2. [Data Engineer Job Analysis](https:\/\/www.kaggle.com\/rohitsahoo\/data-engineer-job-analysis)","ca5da291":"**For Better analysis, I have taken another dataset which consists of the latitudes and longitudes of the all the Stats in America!**","bb8698e0":"**Similary, Let's split Size of a company into lower & upper bound!**","f23e3d9c":"**There are some unnecessary columns,First drop these Columns**\n1. Index\n2. Unnamed\n3. Easy Apply\n4. Competitors\n\n***Check whether any column has Null Values***","80862061":"**To map the latitudes and longitudes to the states in the dataset we have to write a funtion!**\n\n**Here the find_function finds the latitude of a given state. It takes the input as the Abbreviation of State (Given in Dataset), list of states and latitude.**","1fc9df80":"**Clean up the Salary Estimate!**","51d071eb":"**Let's Make a new column of max revenue of a company**"}}