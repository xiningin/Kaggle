{"cell_type":{"c0e27670":"code","8a79f5ca":"code","5b122071":"code","a6fd02d2":"code","10f15014":"code","4cf7240c":"code","279369b7":"code","f2b0182b":"code","8ed78671":"code","bbdc4cac":"code","e6e4778b":"code","31d5f333":"code","f0e77595":"code","0c959965":"code","42cd9ac4":"code","c6882c55":"code","3ed84dfb":"code","eee8727e":"code","2dc5bdd8":"code","c0d95f28":"code","5cb09053":"code","62618c1a":"code","c116d476":"code","af6563fa":"code","bde49425":"code","4e56283c":"code","cdf66c90":"code","363e62aa":"markdown","055d8b4f":"markdown","d64471f6":"markdown","1cc63b7e":"markdown","b88ff478":"markdown"},"source":{"c0e27670":"# We have one folder for each flower type. We are going to load it into two numpy arrays-\n# X - filenames (training data)\n# y - flower names(target labels)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport keras\n\nfrom sklearn.datasets import load_files\n\ndata_dir = '..\/input\/flowers\/flowers'\n\ndata = load_files(data_dir)\nX = np.array(data['filenames'])\ny = np.array(data['target'])\nlabels = np.array(data['target_names'])\n\n# How the arrays look like?\nprint('Data files - ',X)\nprint('Target labels - ',y) \n# numbers are corresponding to class label. We need to change them to a vector of 5 elements.\n\n# Remove .pyc or .py files\npyc_file_pos = (np.where(file==X) for file in X if file.endswith(('.pyc','.py')))\nfor pos in pyc_file_pos:\n    X = np.delete(X,pos)\n    y = np.delete(y,pos)\n    \nprint('Number of training files : ', X.shape[0])\nprint('Number of training targets : ', y.shape[0]) \n","8a79f5ca":"#We have only the file names in X. Time to load the images from filename and save it to X.  \nfrom keras.preprocessing.image import img_to_array, load_img\n\ndef convert_img_to_arr(file_path_list):\n    arr = []\n    for file_path in file_path_list:\n        img = load_img(file_path, target_size = (224,224))\n        img = img_to_array(img)\n        arr.append(img)\n    return arr\n\nX = np.array(convert_img_to_arr(X))\nprint(X.shape) \nprint('First training item : ',X[0])\n#Note that the shape of training data is (4323, 224, 224, 3)\n# 4323 is the number of training items, (224,224) is the target size provided while loading image\n# 3 refers to the depth for colored images(RGB channels).","5b122071":"#Let's look at first 5 training data.\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize = (16,9))\nfor i in range(5):\n    ax = fig.add_subplot(1,5,i+1,xticks=[],yticks=[])\n    ax.imshow((X[i].astype(np.uint8)))\n# Beautiful flowers! ","a6fd02d2":"# re-scale so that all values in X lie within 0 to 1\nX = X.astype('float32')\/255","10f15014":"# Let's confirm the number of classes ;) \nno_of_classes = len(np.unique(y))\nno_of_classes","4cf7240c":"from keras.utils import np_utils\ny = np.array(np_utils.to_categorical(y,no_of_classes))\ny[0]# Note that only one element has value 1(corresponding to its label) and others are 0.","279369b7":"# Lets divide into training, validation and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\nX_test.shape[0]","f2b0182b":"X_test,X_valid, y_test, y_valid = train_test_split(X_test,y_test, test_size = 0.5)\nX_valid.shape[0]","8ed78671":"# Fine-tuning\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.layers import GlobalAveragePooling2D,Dense,Flatten,Dropout\nfrom keras.models import Sequential\nfrom keras.callbacks import ModelCheckpoint\n\n#load the VGG16 model without the final layers(include_top=False)\nbase_model = applications.VGG16(weights='imagenet', include_top=False)\nprint('Loaded model!')\n\n#Let's freeze the first 15 layers - if you see the VGG model layers below, \n# we are freezing till the last Conv layer.\nfor layer in base_model.layers[:15]:\n    layer.trainable = False\n    \nbase_model.summary()","bbdc4cac":"# In the summary above of our base model, trainable params is 7,079,424\n\n# Now, let's create a top_model to put on top of the base model(we are not freezing any layers of this model) \ntop_model = Sequential()  \ntop_model.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:]))\ntop_model.add(Dense(no_of_classes, activation='softmax')) \ntop_model.summary()","e6e4778b":"# In the summary above of our base model, trainable params is 2,565\n\n# Let's build the final model where we add the top_model on top of base_model.\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(top_model)\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n# When we check the summary below,  and trainable params for model is 7,081,989 = 7,079,424 + 2,565","31d5f333":"# Time to train our model !\nepochs = 100\nbatch_size=32\nbest_model_finetuned_path = 'best_finetuned_model.hdf5'\n\ntrain_datagen = ImageDataGenerator(\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow(\n    X_train,y_train,\n    batch_size=batch_size)\n\nvalidation_generator = test_datagen.flow(\n    X_valid,y_valid,\n    batch_size=batch_size)\n\ncheckpointer = ModelCheckpoint(best_model_finetuned_path,save_best_only = True,verbose = 1)\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=len(X_train) \/\/ batch_size,\n    epochs= epochs ,\n    validation_data=validation_generator,\n    validation_steps=len(X_valid) \/\/ batch_size,\n    callbacks=[checkpointer])","f0e77595":"model.load_weights(best_model_finetuned_path)  \n   \n(eval_loss, eval_accuracy) = model.evaluate(  \n     X_test, y_test, batch_size=batch_size, verbose=1)\n\nprint(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100))  \nprint(\"Loss: {}\".format(eval_loss)) ","0c959965":"# Let's visualize some random test prediction.\ndef visualize_pred(y_pred):\n# plot a random sample of test images, their predicted labels, and ground truth\n    fig = plt.figure(figsize=(16, 9))\n    for i, idx in enumerate(np.random.choice(X_test.shape[0], size=16, replace=False)):\n        ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n        ax.imshow(np.squeeze(X_test[idx]))\n        pred_idx = np.argmax(y_pred[idx])\n        true_idx = np.argmax(y_test[idx])\n        ax.set_title(\"{} ({})\".format(labels[pred_idx], labels[true_idx]),\n                     color=(\"green\" if pred_idx == true_idx else \"red\"))\n\nvisualize_pred(model.predict(X_test))","42cd9ac4":"import matplotlib.pyplot as plt \n# Let's visualize the loss and accuracy wrt epochs\ndef plot(history):\n    plt.figure(1)  \n\n     # summarize history for accuracy  \n\n    plt.subplot(211)  \n    plt.plot(history.history['acc'])  \n    plt.plot(history.history['val_acc'])  \n    plt.title('model accuracy')  \n    plt.ylabel('accuracy')  \n    plt.xlabel('epoch')  \n    plt.legend(['train', 'test'], loc='upper left')  \n\n     # summarize history for loss  \n\n    plt.subplot(212)  \n    plt.plot(history.history['loss'])  \n    plt.plot(history.history['val_loss'])  \n    plt.title('model loss')  \n    plt.ylabel('loss')  \n    plt.xlabel('epoch')  \n    plt.legend(['train', 'test'], loc='upper left')  \n    plt.show()\nplot(history)","c6882c55":"from keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nimport math\n\nepochs = 100\nbatch_size = 32\n\nmodel = applications.VGG16(weights='imagenet', include_top=False)\n\ndatagen = ImageDataGenerator()  \n   \ngenerator = datagen.flow(  \n     X_train,   \n     batch_size=batch_size,    \n     shuffle=False)  \n   \ntrain_data = model.predict_generator(  \n     generator, int(math.ceil(len(X_train) \/ batch_size)) )  \n\nprint(train_data.shape) ","3ed84dfb":"generator = datagen.flow(  \n     X_valid,   \n     batch_size=batch_size,    \n     shuffle=False)  \n   \nvalidation_data = model.predict_generator(  \n     generator, int(math.ceil(len(X_valid) \/ batch_size)) )  \n\nvalidation_data.shape","eee8727e":"generator = datagen.flow(  \n     X_test,   \n     batch_size=batch_size,    \n     shuffle=False)  \n   \ntest_data = model.predict_generator(generator, int(math.ceil(len(X_test) \/ batch_size)))\ntest_data.shape","2dc5bdd8":"from keras.layers import GlobalAveragePooling2D,Dense,Flatten,Dropout\nfrom keras.models import Sequential\nfrom keras.callbacks import ModelCheckpoint\n\nbest_model_bottleneck_path = 'best_bottleneck_model.hdf5'\n\nmodel = Sequential()  \nmodel.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\nmodel.add(Dense(no_of_classes, activation='softmax'))  \n   \nmodel.compile(optimizer='rmsprop',  \n              loss='categorical_crossentropy', metrics=['accuracy'])  \n  \ncheckpointer = ModelCheckpoint(best_model_bottleneck_path,save_best_only = True,verbose = 1)\n\nhistory = model.fit(train_data, y_train,  \n          epochs=epochs,  \n          batch_size=batch_size,  \n          validation_data=(validation_data, y_valid),\n          callbacks =[checkpointer])  ","c0d95f28":"model.load_weights(best_model_bottleneck_path)  \n   \n(test_loss, test_accuracy) = model.evaluate(  \n     test_data, y_test, batch_size=batch_size, verbose=1)\n\nprint(\"Accuracy: {:.2f}%\".format(test_accuracy * 100))  \nprint(\"Loss: {}\".format(test_loss)) ","5cb09053":"# Let's visualize some random test prediction.\nvisualize_pred(model.predict(test_data))","62618c1a":"plot(history)","c116d476":"from keras.models import Model\nfrom keras import optimizers\n\nbase_model = applications.VGG16(weights='imagenet', include_top=False)\n\nbest_model_finetuned_bottleneck = 'best_bottleneck_finetuned_model.hdf5'\n\nfor layer in base_model.layers[:15]:\n    layer.trainable = False\n\ntop_model = Sequential()  \ntop_model.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:]))\ntop_model.add(Dense(no_of_classes, activation='softmax')) \n\n# loading the weights of bottle neck features model\ntop_model.load_weights(best_model_bottleneck_path)\n\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(top_model)\n    \nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","af6563fa":"train_datagen = ImageDataGenerator(\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow(\n    X_train,y_train,\n    batch_size=batch_size)\n\nvalidation_generator = test_datagen.flow(\n    X_valid,y_valid,\n    batch_size=batch_size)\n\ncheckpointer = ModelCheckpoint(best_model_finetuned_bottleneck,save_best_only = True,verbose = 1)\n\n# fine-tune the model\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=len(X_train) \/\/ batch_size,\n    epochs=100,\n    validation_data=validation_generator,\n    validation_steps=len(X_valid) \/\/ batch_size,\n    callbacks=[checkpointer])","bde49425":"model.load_weights(best_model_finetuned_bottleneck)  \n   \n(test_loss, test_accuracy) = model.evaluate(  \n     X_test, y_test, batch_size=batch_size, verbose=1)\n\nprint(\"Accuracy: {:.2f}%\".format(test_accuracy * 100))  \nprint(\"Loss: {}\".format(test_loss)) ","4e56283c":"visualize_pred(model.predict(X_test))","cdf66c90":"plot(history)","363e62aa":"**Introduction**\n\nIn this kernel,  I am going to build three models - \n1. Fine tuning VGG16 pre-trained model to adapt to our dataset.\n2. Using VGG 16 bottleneck features for our dataset.\n3. Fine tuning VGG16 on top of bottleneck features.\n\nIn all cases, we will load the VGG model without the final layers because final layers are specific to the high level classification. We want the model's target labels to be same as our dataset classes(daisy, dandelion, rose, sunflower, tulip).\n\n* When we are *fine-tuning*, we want to freeze the weights of initial layers(may be till the last convolutional layer) of the loaded VGG model and add some fully connected layers which will be specific to our dataset with **random** weights. When we say we are going to freeze the layers, it means that the weight for those layers are not going to be updated while training.Only the weights of the newly added layers will be updated in each epoch. \n* When we trying to use *bottleneck features*, we are going to pass our dataset i.e. training and validation set once through the loaded VGG model(note that we are not going to freeze the weights here) and save the output in two arrays respectively called as the bottleneck features for training data and validation data. On top of these bottleneck features, we are going to train a small model which will have target labels specific to our dataset. \n* When we are going to fine-tune using bottleneck features, the approach is going to be same as fine-tuning except that instead of adding new layers with random weights, we will load the weights of the bottleneck features model into the new layers. \n\nAfter we are set with the model architecture, we are going to train the model until we find the best set of weights for our datset.\nLet's get started ! :) ","055d8b4f":"**Fine-tuning with bottleneck features**","d64471f6":"**Bottleneck features**","1cc63b7e":"**Fine-tuning**","b88ff478":"**Data Pre-processing**"}}