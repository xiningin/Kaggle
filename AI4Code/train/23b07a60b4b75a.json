{"cell_type":{"e0c835a6":"code","55c10e38":"code","b9bc415d":"code","2d3a5752":"code","0b7a9750":"code","a8148c46":"code","11a08b39":"code","4b0622e1":"code","f51cb528":"code","5525fd05":"code","50330f09":"code","55924abc":"code","96c5e64e":"code","060b73ab":"code","6382ec22":"code","62000801":"markdown","6ee1d9c2":"markdown","fd1ebdb8":"markdown","76e5d87b":"markdown","327c799f":"markdown","5c74b8f7":"markdown","f485544c":"markdown","fb562cfa":"markdown","3140d791":"markdown","d48959ca":"markdown","1e1d5ef8":"markdown","66e48bea":"markdown"},"source":{"e0c835a6":"import os\nimport shutil\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom torchvision import transforms, datasets, models\nimport torch\nfrom torch import optim, cuda\nfrom torch.utils.data import DataLoader, sampler, random_split\nimport torch.nn as nn\n\nimport seaborn as sns\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport xml.etree.ElementTree as ET\n\nimport numpy as np\nimport pandas as pd\n\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom PIL import Image\nfrom imgaug import augmenters as iaa\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.utils import *\nfrom keras.callbacks import *\nfrom keras.applications.densenet import DenseNet121, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n\nINPUT_SIZE = 100\nPLOT_FRECUENCY = 10","55c10e38":"#array de carpetas con las imagenes de cada raza\nrazas = os.listdir(\"..\/input\/stanford-dogs-dataset\/images\/Images\/\") \n\n#cantidad de carpetas de razas\ncantidadDeRazas = len(razas) \nprint(\"Hay {} Razas\".format(cantidadDeRazas))\n\n#contador del total de todas las imagenes en la data\nnumeroTotalDeImagenes = 0 \nfor raza in razas:\n    numeroTotalDeImagenes += len(os.listdir(\"..\/input\/stanford-dogs-dataset\/images\/Images\/{}\".format(raza)))\nprint(\"Hay {} imagenes\".format(numeroTotalDeImagenes))\n","b9bc415d":"def mostrarImagenes(raza, numeroDeRazasParaMostrar):\n    plt.figure(figsize=(16,16))\n    directorioDeImagen = \"..\/input\/stanford-dogs-dataset\/images\/Images\/{}\/\".format(raza)\n    imagen = os.listdir(directorioDeImagen)[:numeroDeRazasParaMostrar]\n    for i in range(numeroDeRazasParaMostrar):\n        img = mpimg.imread(directorioDeImagen + imagen[i])\n        plt.subplot(numeroDeRazasParaMostrar\/4+1, 4, i+1)\n        plt.imshow(img)\n        plt.axis('off')\nprint(razas[10])\nmostrarImagenes(razas[10], 20)","2d3a5752":"def cortarImagen(raza, perro, directorioDeData):\n    img = Image.open(directorioDeData + 'images\/Images\/' + raza + '\/' + perro + '.jpg')\n    tree = ET.parse(directorioDeData + 'annotations\/Annotation\/' + raza + '\/' + perro)\n    xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n    xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n    ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n    ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n    img = img.crop((xmin,ymin,xmax,ymax))\n    return img","0b7a9750":"if 'data' not in os.listdir():\n    os.mkdir('data')\nos.mkdir('data\/perrosCortados\/')\nos.mkdir('data\/perrosNoCortados\/')\nprint('Se ha creado {} carpeta para guardad las nuevas imagenes de perros'.format(len(os.listdir('data'))))","a8148c46":"directorioDeData = '..\/input\/stanford-dogs-dataset\/'\nfor raza in razas:\n    print('guardando imagenes de:' + raza)\n    for file in os.listdir(directorioDeData + 'annotations\/Annotation\/' + raza):\n        img = cortarImagen(raza, file, directorioDeData)\n        img = img.convert('RGB')\n        img.save('data\/perrosCortados\/' + file + '.jpg')\n        img2 = Image.open(directorioDeData + 'images\/Images\/' + raza + '\/' + file + '.jpg')\n        img2 = img2.convert('RGB')\n        img2.save('data\/perrosNoCortados\/' + file + '.jpg')\n","11a08b39":"contadorDeImagenes = 0\nfor image in os.listdir('data\/perrosCortados'):\n    contadorDeImagenes += 1\nprint('Numero de imagenes: {}'.format(contadorDeImagenes))\ncontadorDeImagenes = 0\nfor image in os.listdir('data\/perrosNoCortados'):\n    contadorDeImagenes += 1\nprint('Numero de imagenes: {}'.format(contadorDeImagenes))","4b0622e1":"def mostrarImagenesCortadas(numeroDeImagenesCortadas):\n    plt.figure(figsize=(10,10))\n    directorioDeImagen = \"data\/perrosCortados\/\"\n    imagen = os.listdir(directorioDeImagen)[:numeroDeImagenesCortadas]\n    for i in range(numeroDeImagenesCortadas):\n        img = mpimg.imread(directorioDeImagen + imagen[i])\n        plt.subplot(numeroDeImagenesCortadas\/4+1, 4, i+1)\n        plt.imshow(img)\n        plt.axis('off')\nmostrarImagenesCortadas(15)","f51cb528":"def read_image(file, bounds):\n    image = open_image(file, bounds)\n    image = normalize_image(image)\n    return image\n\n\ndef open_image(file, bounds):\n    image = Image.open(file)\n    image = image.crop(bounds)\n    image = image.resize((64, 64))\n    return np.array(image)\n\n\n# Normalization, [-1,1] Range\ndef normalize_image(image):\n    image = np.asarray(image, np.float32)\n    image = image \/ 127.5 - 1\n    return img_to_array(image)\n\n\n# Restore, [0,255] Range\ndef denormalize_image(image):\n    return ((image+1)*127.5).astype(np.uint8)\n\n\ndef load_images():\n    images = []\n\n    for raza in os.listdir('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/'):\n        for perro in os.listdir('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/' + raza):\n            tree = ET.parse('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/' + raza + '\/' + perro)\n            root = tree.getroot()\n            objects = root.findall('object')\n            for o in objects:\n                box = o.find('bndbox')\n                xmin = int(box.find('xmin').text)\n                ymin = int(box.find('ymin').text)\n                xmax = int(box.find('xmax').text)\n                ymax = int(box.find('ymax').text)\n\n            bounds = (xmin, ymin, xmax, ymax)\n            try:\n                image = read_image('data\/perrosNoCortados\/' + perro + '.jpg', bounds)\n                images.append(image)\n            except:\n                print('No image', perro)\n\n    return np.array(images)\n\n\nx_train = load_images()\n","5525fd05":"\n\ndef create_generator():\n    generator = Sequential()\n    generator.add(Dense(units=256*4*4,input_dim=INPUT_SIZE))\n    generator.add(Reshape((4,4,256)))\n\n    generator.add(Conv2DTranspose(1024, 4, strides=1, padding='same'))\n    generator.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    generator.add(ReLU())\n    \n    generator.add(Conv2DTranspose(512, 4, strides=2, padding='same'))\n    generator.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    generator.add(ReLU())\n    \n    generator.add(Conv2DTranspose(256, 4, strides=2, padding='same'))\n    generator.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    generator.add(ReLU())\n\n    generator.add(Conv2DTranspose(128, 4, strides=2, padding='same'))\n    generator.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    generator.add(ReLU())\n    \n    generator.add(Conv2DTranspose(64, 4, strides=2, padding='same'))\n    generator.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    generator.add(ReLU())\n    \n    generator.add(Conv2DTranspose(3, 3, strides=1, activation='tanh', padding='same'))\n    \n    generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0005, beta_1=0.5))\n\n    return generator\n\n\ngenerator = create_generator()\ngenerator.summary()","50330f09":"def create_discriminator():\n    discriminator = Sequential()\n\n    discriminator.add(Conv2D(32, kernel_size=4, strides=2, padding='same', input_shape=(64,64,3)))\n    discriminator.add(LeakyReLU(0.2))\n    \n    discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding='same'))\n    discriminator.add(LeakyReLU(0.2))\n    \n    discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n    discriminator.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    discriminator.add(LeakyReLU(0.2))\n    \n    discriminator.add(Conv2D(256, kernel_size=4, strides=2, padding='same'))\n    discriminator.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    discriminator.add(LeakyReLU(0.2))\n    \n    discriminator.add(Conv2D(1, kernel_size=4, strides=1, padding='same'))\n\n    discriminator.add(Flatten())\n    discriminator.add(Dense(units=1, activation='sigmoid'))\n    \n    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0005, beta_1=0.5))\n    return discriminator\n\n\ndiscriminator = create_discriminator()\ndiscriminator.summary()","55924abc":"def create_gan(generator, discriminator):\n    discriminator.trainable = False\n\n    gan_input = Input(shape=(INPUT_SIZE,))\n    generator_output = generator(gan_input)\n    gan_output = discriminator(generator_output)\n\n    gan = Model(inputs=gan_input, outputs=gan_output)\n    gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0005, beta_1=0.5))\n\n    return gan\n\n\ngan = create_gan(generator, discriminator)\ngan.summary()","96c5e64e":"PLOT_FRECUENCY = 1\ndef plot_images(generator, size=25, dim=(5,5), figsize=(10,10)):\n    noise= generate_noise(size)\n    generated_images = generator.predict(noise)\n\n    plt.figure(figsize=figsize)\n    for i in range(generated_images.shape[0]):\n        plt.subplot(dim[0], dim[1], i+1)\n        plt.imshow(denormalize_image(generated_images[i]), interpolation='nearest')\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n    \n    \ndef plot_loss(epoch, g_losses, d_losses):\n    plt.figure(figsize=(10,5))\n    plt.title(\"Loss, Epochs 0-\" + str(epoch))\n    plt.plot(g_losses,label=\"Generator\")\n    plt.plot(d_losses,label=\"Discriminator\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","060b73ab":"def generate_noise(size):\n    return np.random.normal(0, 1, size=[size, INPUT_SIZE])\n\n\ndef training(epochs=1, batch_size= 128):\n    #Loading Data\n    batches = x_train.shape[0] \/ batch_size\n    \n    # Adversarial Labels\n    y_valid = np.ones(batch_size)*0.9\n    y_fake = np.zeros(batch_size)\n    discriminator_loss, generator_loss = [], []\n\n    for epoch in range(1, epochs+1):\n        g_loss = 0; d_loss = 0\n\n        for _ in range(int(batches)):\n            # Random Noise and Images Set\n            noise = generate_noise(batch_size)\n            image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n\n            # Generate Fake Images\n            generated_images = generator.predict(noise)\n            \n            # Train Discriminator (Fake and Real)\n            discriminator.trainable = True\n            d_valid_loss = discriminator.train_on_batch(image_batch, y_valid)\n            d_fake_loss = discriminator.train_on_batch(generated_images, y_fake)            \n\n            d_loss += (d_fake_loss + d_valid_loss)\/2\n            \n            # Train Generator\n            noise = generate_noise(batch_size)\n            discriminator.trainable = False\n            g_loss += gan.train_on_batch(noise, y_valid)\n            \n        discriminator_loss.append(d_loss\/batches)\n        generator_loss.append(g_loss\/batches)\n            \n        if epoch % PLOT_FRECUENCY == 0:\n            print('Epoch', epoch)\n            plot_images(generator)\n            plot_loss(epoch, generator_loss, discriminator_loss)\n\n    \ntraining(epochs=50)","6382ec22":"def save_images(generator):\n    if not os.path.exists('..\/output'):\n        os.mkdir('..\/output')\n\n    noise = generate_noise(10000)\n    generated_images = generator.predict(noise)\n\n    for i in range(generated_images.shape[0]):\n        image = denormalize_image(generated_images[i])\n        image = array_to_img(image)\n        image.save( '..\/output\/' + str(i) + '.png')\n\n    shutil.make_archive('images', 'zip', '..\/output')\n    \n    \nsave_images(generator)","62000801":"# Entrenamiento","6ee1d9c2":"# Finalizar","fd1ebdb8":"# Guardamos la Data en Carpetas","76e5d87b":"# Generador de Imagenes","327c799f":"# Plotting","5c74b8f7":"# Cortado de Imagenes\nPara mayo exactitud utilizamos un metodo usado en [https:\/\/www.kaggle.com\/gabrielloye\/dogs-inception-pytorch-implementation](http:\/\/) para cortar las imagenes con el fin de que solo se vieran los perros en las imagenes.","f485544c":"# Mostrar x Cantidad de Imagenes de Alguna Raza","fb562cfa":"# Modelo GAN","3140d791":"# Mostramos imagenes cortadas para verificar","d48959ca":"# Procesamos toda la data","1e1d5ef8":"# Contamos la cantidad de imagenes para verificar.","66e48bea":"# Discriminador"}}