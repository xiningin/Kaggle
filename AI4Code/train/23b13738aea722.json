{"cell_type":{"c5f8a48d":"code","0349563b":"code","b0a654d7":"code","5b492075":"code","a0f99577":"code","f8b160d6":"code","a25864b8":"code","a76bceb6":"code","5a20be11":"code","06510a51":"code","0cf8598e":"code","e7e42e6a":"code","9940d3cb":"code","6b9ecd57":"code","94a0162a":"code","ab5d4383":"code","b41de15a":"code","230c50fb":"code","ffeeae29":"code","1f3f94cd":"code","543e1269":"code","354adec2":"code","d26bc127":"code","1690b3de":"code","af96f311":"code","b8f02d43":"code","bd086624":"markdown","9e7bbe3d":"markdown","530b6cbf":"markdown","b70b195a":"markdown","408b19fa":"markdown","8685fb1f":"markdown","3d6e6831":"markdown","ab7fe11e":"markdown","6a462c1f":"markdown","00cf7509":"markdown","fdcf6f45":"markdown"},"source":{"c5f8a48d":"import os\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import (\n    Dense, Conv2D, MaxPool2D, Dropout, Flatten, \n    BatchNormalization, GlobalAveragePooling2D\n)\n\nfrom keras.applications.densenet import DenseNet121\nfrom keras import backend as K\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nos.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\")","0349563b":"len(os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\"))","b0a654d7":"train_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"\ntest_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"\nval_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/val\"\n\nprint(\"Train set:\\n========================================\")\nnum_pneumonia = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))\nnum_normal = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\nprint(f\"PNEUMONIA={num_pneumonia}\")\nprint(f\"NORMAL={num_normal}\")\n\nprint(\"Test set:\\n========================================\")\nprint(f\"PNEUMONIA = {len(os.listdir(os.path.join(test_dir, 'PNEUMONIA')))}\")\nprint(f\"NORMAL = {len(os.listdir(os.path.join(test_dir, 'NORMAL')))}\")\n\nprint(\"Validation set:\\n========================================\")\nprint(f\"PNEUMONIA = {len(os.listdir(os.path.join(val_dir, 'PNEUMONIA')))}\")\nprint(f\"NORMAL = {len(os.listdir(os.path.join(val_dir, 'NORMAL')))}\")\n\npneumonia = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\")\npneumonia_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\"\n\nplt.figure(figsize=(20, 10))\n\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    img = plt.imread(os.path.join(pneumonia_dir, pneumonia[i]))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \nplt.tight_layout()","5b492075":"normal = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\")\nnormal_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\"\n\nplt.figure(figsize=(20, 10))\n\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    img = plt.imread(os.path.join(normal_dir, normal[i]))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \nplt.tight_layout()","a0f99577":"normal_img = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\")[0]\nnormal_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\"\nsample_img = plt.imread(os.path.join(normal_dir, normal_img))\nplt.imshow(sample_img, cmap='gray')\nplt.colorbar()\nplt.title('Raw Chest X Ray Image')\n\nprint(f\"The dimensions of the image are {sample_img.shape[0]} pixels width and {sample_img.shape[1]} pixels height, one single color channel.\")\nprint(f\"The maximum pixel value is {sample_img.max():.4f} and the minimum is {sample_img.min():.4f}\")\nprint(f\"The mean value of the pixels is {sample_img.mean():.4f} and the standard deviation is {sample_img.std():.4f}\")","f8b160d6":"sns.distplot(sample_img.ravel(),\n             label=f\"Pixel Mean {np.mean(sample_img):.4f} & Standard Deviation {np.std(sample_img):.4f}\", \n             kde=False)\nplt.legend(loc='upper right')\nplt.title('Distribution of Pixel Intensities in the Image')\nplt.xlabel('Pixel Intensity')\nplt.ylabel('# Pixels in Image')","a25864b8":"image_generator = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    samplewise_center=True,\n    samplewise_std_normalization=True\n)","a76bceb6":"train = image_generator.flow_from_directory(train_dir, \n                                            batch_size=8, \n                                            shuffle=True, \n                                            class_mode='binary',\n                                            target_size=(320, 320))\n\nvalidation = image_generator.flow_from_directory(val_dir, \n                                                batch_size=1, \n                                                shuffle=False, \n                                                class_mode='binary',\n                                                target_size=(320, 320))\n\ntest = image_generator.flow_from_directory(test_dir, \n                                            batch_size=1, \n                                            shuffle=False, \n                                            class_mode='binary',\n                                            target_size=(320, 320))","5a20be11":"sns.set_style('white')\ngenerated_image, label = train.__getitem__(0)\nplt.imshow(generated_image[0], cmap='gray')\nplt.colorbar()\nplt.title('Raw Chest X Ray Image')\n\nprint(f\"The dimensions of the image are {generated_image.shape[1]} pixels width and {generated_image.shape[2]} pixels height, one single color channel.\")\nprint(f\"The maximum pixel value is {generated_image.max():.4f} and the minimum is {generated_image.min():.4f}\")\nprint(f\"The mean value of the pixels is {generated_image.mean():.4f} and the standard deviation is {generated_image.std():.4f}\")","06510a51":"sns.distplot(generated_image.ravel(),\n             label=f\"Pixel Mean {np.mean(generated_image):.4f} & Standard Deviation {np.std(generated_image):.4f}\", \n             kde=False)\nplt.legend(loc='upper center')\nplt.title('Distribution of Pixel Intensities in the Image')\nplt.xlabel('Pixel Intensity')\nplt.ylabel('# Pixels in Image')","0cf8598e":"# Class weights\n\nweight_for_0 = num_pneumonia \/ (num_normal + num_pneumonia)\nweight_for_1 = num_normal \/ (num_normal + num_pneumonia)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(f\"Weight for class 0: {weight_for_0:.2f}\")\nprint(f\"Weight for class 1: {weight_for_1:.2f}\")","e7e42e6a":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(320, 320, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(320, 320, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy'])","9940d3cb":"model.summary()","6b9ecd57":"r = model.fit(\n    train, \n    epochs=10,\n    validation_data=validation, \n    class_weight=class_weight,\n    steps_per_epoch=100,\n    validation_steps=25,\n)","94a0162a":"plt.figure(figsize=(12, 8))\n\nplt.subplot(2, 2, 1)\nplt.plot(r.history['loss'], label='Loss')\nplt.plot(r.history['val_loss'], label='Val_Loss')\nplt.legend()\nplt.title('Loss Evolution')\n\nplt.subplot(2, 2, 2)\nplt.plot(r.history['accuracy'], label='Accuracy')\nplt.plot(r.history['val_accuracy'], label='Val_Accuracy')\nplt.legend()\nplt.title('Accuracy Evolution')","ab5d4383":"evaluation = model.evaluate(test)\nprint(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n\nevaluation = model.evaluate(train)\nprint(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")","b41de15a":"pred = model.predict(test)\n\nprint(confusion_matrix(test.classes, pred > 0.5))\npd.DataFrame(classification_report(test.classes, pred > 0.5, output_dict=True))","230c50fb":"print(confusion_matrix(test.classes, pred > 0.7))\npd.DataFrame(classification_report(test.classes, pred > 0.7, output_dict=True))","ffeeae29":"base_model = DenseNet121(input_shape=(320, 320, 3), include_top=False, weights='imagenet', pooling='avg')\n\nbase_model.summary()","1f3f94cd":"layers = base_model.layers\nprint(f\"The model has {len(layers)} layers\")\n\nprint(f\"The input shape {base_model.input}\")\nprint(f\"The output shape {base_model.output}\")","543e1269":"# model = Sequential()\nbase_model = DenseNet121(include_top=False, weights='imagenet')\nx = base_model.output\n\nx = GlobalAveragePooling2D()(x)\n\npredictions = Dense(1, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n# model.add(base_model)\n# model.add(GlobalAveragePooling2D())\n# model.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy'])\n\nr = model.fit(\n    train, \n    epochs=10,\n    validation_data=validation,\n    class_weight=class_weight,\n    steps_per_epoch=100,\n    validation_steps=25,\n)","354adec2":"plt.figure(figsize=(12, 8))\n\nplt.subplot(2, 2, 1)\nplt.plot(r.history['loss'], label='Loss')\nplt.plot(r.history['val_loss'], label='Val_Loss')\nplt.legend()\nplt.title('Loss Evolution')\n\nplt.subplot(2, 2, 2)\nplt.plot(r.history['accuracy'], label='Accuracy')\nplt.plot(r.history['val_accuracy'], label='Val_Accuracy')\nplt.legend()\nplt.title('Accuracy Evolution')","d26bc127":"evaluation = model.evaluate(test)\nprint(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n\nevaluation = model.evaluate(train)\nprint(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")","1690b3de":"predicted_vals = model.predict(test, steps=len(test))","af96f311":"print(confusion_matrix(test.classes, predicted_vals > 0.5))\npd.DataFrame(classification_report(test.classes, predicted_vals > 0.5, output_dict=True))","b8f02d43":"print(confusion_matrix(test.classes, predicted_vals > 0.7))\npd.DataFrame(classification_report(test.classes, predicted_vals > 0.7, output_dict=True))","bd086624":"# \ud83e\udd16 Model Building\n\n> One of the challenges with working with medical diagnostic datasets is the large class imbalance present in such datasets.\n\n## \u2714\ufe0f Impact of imbalance data on loss function\n\n> Loss Function:\n$$\\mathcal{L}_{cross-entropy}(x_i) = -(y_i \\log(f(x_i)) + (1-y_i) \\log(1-f(x_i))),$$\n\n> We can rewrite the the overall average cross-entropy loss over the entire training set `D` of size `N` as follows:\n$$\\mathcal{L}_{cross-entropy}(\\mathcal{D}) = - \\frac{1}{N}\\big( \\sum_{\\text{positive examples}} \\log (f(x_i)) + \\sum_{\\text{negative examples}} \\log(1-f(x_i)) \\big).$$\n\n\n\n> When we have an imbalance data, using a normal loss function will result a model that bias toward the dominating class. One solution is to use a weighted loss function. Using weighted loss function will balance the contribution in the loss function.\n\n$$\\mathcal{L}_{cross-entropy}^{w}(x) = - (w_{p} y \\log(f(x)) + w_{n}(1-y) \\log( 1 - f(x) ) ).$$","9e7bbe3d":"# Evaluation","530b6cbf":"# \ud83d\udce5 Import Packages and Functions\n\n> We'll make use of the following packages:\n> - `numpy` and `pandas` is what we'll use to manipulate our data\n> - `matplotlib.pyplot` and `seaborn` will be used to produce plots for visualization\n> - `util` will provide the locally defined utility functions that have been provided for this assignment\n\n> We will also use several modules from the `keras` framework for building deep learning models.\n\n> Run the next cell to import all the necessary packages.","b70b195a":"# \ud83d\udd04 Image Preprocessing\n\n> Before training, you'll first modify your images to be better suited for training a convolutional neural network. For this task you'll use the Keras `ImageDataGenerator` function to perform data preprocessing and data augmentation.\n\n> - This class also provides support for basic data augmentation such as random horizontal flipping of images.\n> - We also use the generator to transform the values in each batch so that their mean is 0 and their standard deviation is 1 (this will faciliate model training by standardizing the input distribution).\n> - The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels (we will want this because the pre-trained model that we'll use requires three-channel inputs).\n\n","408b19fa":"# \ud83d\udd0d Investigate a single image","8685fb1f":"\u2714\ufe0f **Build a separate generator fo valid and test sets**\n\n> Now we need to build a new generator for validation  and t esting data.\n\n\u2714\ufe0f **Why can't use the same generator as for the training data?**\n\n> Look back at the generator we wrote for the training data.\n> - It normalizes each image per batch, meaning thatit uses batch statistics.\n> - We should not do this with the test and validation data, since in a real life scenario we don't process incoming images a batch at a time (we process one image at a time).\n> - Knowing the average per batch of test data would effectively give our model an advantage (The model should not have any information about the test data).\n\n> What we need to do is to normalize incomming test data using the statistics computed from the training set.","3d6e6831":"> The dataset is divided into three sets: \n> 1. Train set \n> 2. Validation set and \n> 3. Test set. ","ab7fe11e":"# \ud83e\ude7a AI for Medicine Course By Deeplearning.ai\n\n> Computer Vision (CV) has a lot of applications in medical diagnosis:\n> - Dermatology\n> - Ophthakmology\n> - Histopathology.\n\n> X-rays images are critical for the detection of lung cancer, pneumenia ... In this notebook you will learn:\n> - Data pre-processing \n> - Preprocess images properly for the train, validation and test sets.\n> - Set-up a pre-trained neural network to make disease predictions on chest X-rays.\n\n> In this notebook you will work with chest X-ray images taken from the public [ChestX-ray8 dataset](https:\/\/arxiv.org\/abs\/1705.02315). ","6a462c1f":"# \ud83d\udd0d Ivestigate pixel value distribution","00cf7509":"# DenseNet\n\n> Densenet is a convolutional network where each layer is connected to all other layers that are deeper in the network:\n> - The first layer is connected to the 2nd, 3rd, 4th etc.\n> - The second layer is conected to the 3rd, 4th, 5th etc.\n\n![densenet.png](attachment:densenet.png)","fdcf6f45":"# \ud83d\udcc9 Data Visualization"}}