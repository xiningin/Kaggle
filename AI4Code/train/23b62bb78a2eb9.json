{"cell_type":{"50d65717":"code","e4922a35":"code","522675bd":"code","1183d452":"code","840f42dd":"code","561b0320":"code","647fd5d7":"code","2042a68b":"code","f2a39eca":"code","936ad7f7":"code","fe1966df":"code","4f719a64":"code","63b57b36":"code","9f6cfb81":"code","34c70427":"code","7fe30199":"code","bd51cd59":"code","6c7e2277":"code","9ac5ad99":"markdown","e736fec9":"markdown","39c4b9b4":"markdown","7a13cc11":"markdown","8aa831ba":"markdown"},"source":{"50d65717":"import cv2\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom tensorflow.keras.callbacks import *","e4922a35":"imagePaths = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/'):\n    for filename in filenames:\n        if (filename[-3:] == 'png'):\n            imagePaths.append(os.path.join(dirname, filename))","522675bd":"imgSize = 224","1183d452":"X = []\nY = []\nhmap = {'Viral Pneumonia': 'Pneumonia', 'NORMAL': 'Normal', 'COVID-19': 'Covid-19'}\nfor imagePath in tqdm(imagePaths):\n    label = imagePath.split(os.path.sep)[-2]\n    \n    if (label == \"Viral Pneumonia\"):\n        continue\n        \n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (imgSize, imgSize))\n\n    X.append(image)\n    Y.append(hmap[label])\n    ","840f42dd":"print('Covid-19:',Y.count('Covid-19'))\nprint('Normal:',Y.count('Normal'))\nprint('Pneumonia: ',Y.count('Pneumonia'))","561b0320":"le = LabelEncoder()\nY = le.fit_transform(Y)\nY = to_categorical(Y)","647fd5d7":"(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size=0.20, stratify=Y, random_state=42)","2042a68b":"del X\ndel Y","f2a39eca":"ntimes = 6\ntrainY = trainY.tolist()\nfor i in tqdm(range(len(trainX))):\n    if (trainY[i][0] == 1):\n        trainX += [trainX[i]]*ntimes\n        trainY += [trainY[i]]*ntimes\n        \ntrainY = np.array(trainY)","936ad7f7":"trainX = np.array(trainX).astype('float16')\/255\n\ntestX = np.array(testX).astype('float16')\/255","fe1966df":"trainAug = ImageDataGenerator(rotation_range=20, horizontal_flip = True,fill_mode=\"nearest\")","4f719a64":"best_val_acc = 0\nbest_train_acc = 0\ndef saveModel(epoch,logs):\n    val_acc = logs['val_accuracy']\n    train_acc = logs['accuracy']\n    global best_val_acc\n    global best_train_acc\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        model.save('model.h5')\n    elif val_acc == best_val_acc:\n        if train_acc > best_train_acc:\n            best_train_acc= train_acc\n            model.save('model.h5')","63b57b36":"baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(imgSize, imgSize, 3)))\nheadModel = baseModel.output\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(64, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\nfor layer in baseModel.layers:\n    layer.trainable = False","9f6cfb81":"INIT_LR = 3e-4\nEPOCHS = 50\nBS = 32\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\nH = model.fit_generator(\n    trainAug.flow(trainX, trainY, batch_size=BS),\n    steps_per_epoch=len(trainX) \/\/ BS,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) \/\/ BS,\n    callbacks= [LambdaCallback(on_epoch_end=saveModel),\n#              EarlyStopping(monitor='val_accuracy', patience=3),\n#              ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,patience=2),\n              ],\n    epochs=EPOCHS)","34c70427":"N = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\")","7fe30199":"model= load_model('model.h5')","bd51cd59":"predIdxs = model.predict(trainX, batch_size=BS)\npredIdxs = np.argmax(predIdxs, axis=1)\nprint(classification_report(trainY.argmax(axis=1), predIdxs, target_names=le.classes_, digits = 5))","6c7e2277":"predIdxs = model.predict(testX, batch_size=BS)\npredIdxs = np.argmax(predIdxs, axis=1)\nprint(classification_report(testY.argmax(axis=1), predIdxs, target_names=le.classes_, digits = 5))","9ac5ad99":"# Result on train","e736fec9":"# Train model","39c4b9b4":"# MODEL","7a13cc11":"# Load best model","8aa831ba":"# Result on test"}}