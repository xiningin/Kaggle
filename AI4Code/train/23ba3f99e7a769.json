{"cell_type":{"d2bd0cb7":"code","4012b23c":"code","d49a8b72":"code","6611d9e6":"code","e5346976":"code","56618e34":"code","cda8f30f":"code","32312913":"code","4198954f":"code","18fe0cb1":"code","419cd375":"code","a96d00a6":"code","1415d5f6":"code","7129130b":"code","8a894b3a":"code","ac611131":"code","61053aca":"code","6d167253":"code","6a8f2988":"code","2f0edc4e":"code","5cd5f9ad":"code","9e29c1c6":"code","a1630763":"code","8749b38f":"code","9ce5548c":"code","7e98ae05":"code","d6aafc4c":"code","7d3d43fd":"code","3001bb30":"code","7f53928b":"code","1afe5895":"code","a9fe00d1":"code","0001db9d":"code","831de3c2":"code","f511d6e6":"code","158ef8dc":"code","963e4057":"code","3b6e9abe":"code","e13b575a":"code","942d64a0":"code","d6ec0b96":"code","839e6362":"code","cb9db655":"code","5489181b":"code","3d5e3e86":"code","cd8a26f2":"code","3e435393":"code","0ed60728":"code","49524806":"markdown","4a2e36a8":"markdown","b71d5d70":"markdown","99b55ac0":"markdown","9c3de1cd":"markdown","49e4c945":"markdown","b416749e":"markdown","48ae5381":"markdown","685f9514":"markdown","c9d7f78b":"markdown","a1316fa8":"markdown","687eb943":"markdown","452e8a34":"markdown","36a9ed76":"markdown","b6d03d3b":"markdown","127e64c2":"markdown","25b1f5cc":"markdown"},"source":{"d2bd0cb7":"from pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV,\\\n                                    cross_val_score, ShuffleSplit\nimport eli5\nfrom IPython.display import display_html\nimport matplotlib\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n#matplotlib.style.use('ggplot')\n\nfrom shapely.geometry import Polygon\n\nPATH_TO_DATA = Path('..\/input')\nSEED = 42","4012b23c":"# reading data\ny_train = pd.read_csv(PATH_TO_DATA \/ 'train_targets.csv', index_col='match_id_hash')['radiant_win']\ny_train = y_train.map({True: 1, False: 0})\ntrain_df = pd.read_csv(PATH_TO_DATA \/ 'train_features.csv', index_col='match_id_hash')\ntest_df = pd.read_csv(PATH_TO_DATA \/ 'test_features.csv', index_col='match_id_hash')","d49a8b72":"# lists of players coordinates for teams\nradiant_coords = [f'r{i}_{j}' for i in range(1, 6) for j in ('x','y')]\ndire_coords = [f'd{i}_{j}' for i in range(1, 6) for j in ('x','y')]","6611d9e6":"# make dataset with coordinates\ncoords_df = train_df.loc[:, radiant_coords + dire_coords]","e5346976":"coords_df.head()","56618e34":"# function to fit logistic regression, with parameters tuning, crossvalidation and visualization of feature weights\ndef evaluate(df, features):\n    train_df_part, valid_df, y_train_part, y_valid = \\\n        train_test_split(df, y_train, test_size=0.25, random_state=SEED)\n    logreg = LogisticRegression(C=1, solver='liblinear', random_state=SEED)\n    c_values = np.logspace(-3, 1.7, 20)\n    shf = ShuffleSplit(n_splits=5, test_size=0.25, random_state=SEED)\n    loggrid = GridSearchCV(estimator=logreg, \n                           param_grid={'C': c_values,\n                           'penalty': ['l1', 'l2'] \n                                      },\n                           scoring='roc_auc', n_jobs=4, cv=shf, verbose=1)\n    loggrid.fit(train_df_part, y_train_part)\n    print(loggrid.best_score_, loggrid.best_params_)\n    final_model = loggrid.best_estimator_\n    final_model.fit(train_df_part, y_train_part)\n    valid_pred = final_model.predict_proba(valid_df)[:, 1]\n    score = roc_auc_score(y_valid, valid_pred)\n    print('Score on validation set:', score)\n    final_model.fit(df, y_train)\n    res = cross_val_score(final_model, df, y_train, scoring='roc_auc', cv=shf, n_jobs=4, verbose=1)\n    print('Scores on folds:', res)\n    print('Standard deviation:',np.std(res))\n    print('Mean score on whole set:',np.mean(res))\n    display_html(eli5.show_weights(estimator=final_model, \n                 feature_names=features, top=50))\n    return final_model","cda8f30f":"classifier = evaluate(coords_df, coords_df.columns.tolist())","32312913":"row = 400\nplt.scatter(coords_df.iloc[row, [i for i in range(0,10, 2)]].values,\n            coords_df.iloc[row, [i for i in range(1,10, 2)]].values)\nplt.scatter(coords_df.iloc[row, [i for i in range(10,20, 2)]].values,\n            coords_df.iloc[row, [i for i in range(11,20, 2)]].values);","4198954f":"# Collect data into fixed-length chunks of tuples\ndef grouper(iterable, n, fillvalue=None):\n    from itertools import zip_longest\n    args = [iter(iterable)] * n\n    return zip_longest(*args, fillvalue=fillvalue)","18fe0cb1":"p1 = coords_df.iloc[row, [i for i in range(0,10)]].tolist()\np2 = coords_df.iloc[row, [i for i in range(10,20)]].tolist()","419cd375":"#Radiant players polygon of unordered points\nPolygon(grouper(p1,2))","a96d00a6":"#Dire players polygon of unordered points\nPolygon(grouper(p2,2))","1415d5f6":"# flag encoding: 1 for area, 0 for perimeter, 2 for Polygon object\ndef geometry(p, flag=1):\n    \n    from functools import reduce\n    import math\n    from shapely.geometry import Polygon\n    \n    # grouping coordinates in list of tuples\n    grouped = list(grouper(p,2))\n    \n    # ordering the coordinates\n    center = reduce(lambda a, b: (a[0] + b[0], a[1] + b[1]), grouped, (0, 0))\n    center = (center[0] \/ len(grouped), (center[1] \/ len(grouped)))\n    grouped.sort(key = (lambda a: math.atan2(a[1] - center[1], a[0] - center[0])))\n    \n    # calculating simple features with shapely\n    if flag == 1:\n        feature = Polygon(grouped).area\n    elif flag == 0:\n        feature = round(Polygon(grouped).length, 3)\n    else:\n        feature = Polygon(grouped) #returns shapely object for more features\n        \n    return feature","7129130b":"#Radiant players polygon of ordered points\ngeometry(p1, flag=2)","8a894b3a":"#Dire players polygon of ordered points\ngeometry(p2, flag=2)","ac611131":"# Hausdorff distance measures how far two subsets of a metric space are from each other.\ngeometry(p1, flag=2).hausdorff_distance(geometry(p2, flag=2))","61053aca":"# representative point, a cheaply computed point that is guaranteed to be within the geometric object.\ngeometry(p2, flag=2).representative_point().x, geometry(p2, flag=2).representative_point().y","6d167253":"# object\u2019s geometric centroid.\ngeometry(p2, flag=2).centroid.x, geometry(p2, flag=2).centroid.y","6a8f2988":"# area of objects intersection.\ngeometry(p1, flag=2).buffer(0).intersection(geometry(p2, flag=2).buffer(0)).area","2f0edc4e":"def plot_polygons(df, row):\n    if row <= df.shape[0]:\n        p1 = df.iloc[row, :10].tolist()\n        p2 = df.iloc[row, 10:20].tolist()\n        plt.plot(*geometry(p1, flag=2).exterior.xy)\n        plt.scatter(geometry(p1, flag=2).centroid.x, geometry(p1, flag=2).centroid.y)\n        plt.plot(*geometry(p2, flag=2).exterior.xy)\n        plt.scatter(geometry(p2, flag=2).centroid.x, geometry(p2, flag=2).centroid.y)\n        plt.scatter(geometry(p1, flag=2).buffer(0).representative_point().x, geometry(p1, flag=2).buffer(0).representative_point().y, marker='*')\n        plt.scatter(geometry(p2, flag=2).buffer(0).representative_point().x, geometry(p2, flag=2).buffer(0).representative_point().y, marker='*')\n        plt.title('Hausdorff distance: {:.2f}. Intersetion area: {:.2f}'.format(geometry(p1, flag=2).hausdorff_distance(geometry(p2, flag=2)),\\\n                                                                                geometry(p1, flag=2).buffer(0).intersection(geometry(p2, flag=2).buffer(0)).area))\n    else:\n        print('Out of data boundaries!')","5cd5f9ad":"plt.figure(figsize=(20, 10))\nfor i in range(0, 6):\n    plt.subplot((231 + i))\n    plot_polygons(coords_df, row + i * 10)","9e29c1c6":"def intersection(a, b):\n    return round(geometry(a, flag=2).buffer(0).intersection(geometry(b, flag=2).buffer(0)).area, 3)","a1630763":"def hausdorff_distance(a, b):\n    return round(geometry(a, flag=2).buffer(0).hausdorff_distance(geometry(b, flag=2).buffer(0)), 3)","8749b38f":"# checking if everything is fine\nintersection(p1, p2), hausdorff_distance(p1, p2)","9ce5548c":"def feature_engineering(df, transform=True):\n    radiant_coords = [f'r{i}_{j}' for i in range(1, 6) for j in ('x','y')]\n    dire_coords = [f'd{i}_{j}' for i in range(1, 6) for j in ('x','y')]\n    coords_df = df.loc[:, radiant_coords + dire_coords]\n\n    coords_df['r_centr_x'] = coords_df.loc[:, radiant_coords].apply(lambda x: geometry(x.tolist(), flag=2).centroid.x, axis=1)\n    coords_df['r_centr_y'] = coords_df.loc[:, radiant_coords].apply(lambda x: geometry(x.tolist(), flag=2).centroid.y, axis=1)\n    coords_df['d_centr_x'] = coords_df.loc[:, dire_coords].apply(lambda x: geometry(x.tolist(), flag=2).centroid.x, axis=1)\n    coords_df['d_centr_y'] = coords_df.loc[:, dire_coords].apply(lambda x: geometry(x.tolist(), flag=2).centroid.y, axis=1)\n    coords_df['r_repr_x'] = coords_df.loc[:, radiant_coords].apply(lambda x: geometry(x.tolist(), flag=2).buffer(1).representative_point().x, axis=1)\n    coords_df['r_repr_y'] = coords_df.loc[:, radiant_coords].apply(lambda x: geometry(x.tolist(), flag=2).buffer(1).representative_point().y, axis=1)\n    coords_df['d_repr_x'] = coords_df.loc[:, dire_coords].apply(lambda x: geometry(x.tolist(), flag=2).buffer(1).representative_point().x, axis=1)\n    coords_df['d_repr_y'] = coords_df.loc[:, dire_coords].apply(lambda x: geometry(x.tolist(), flag=2).buffer(1).representative_point().y, axis=1)\n    coords_df['r_area'] = coords_df.loc[:, radiant_coords].apply(lambda x: geometry(x.tolist(), flag=1), axis=1)\n    coords_df['r_perim'] = coords_df.loc[:, radiant_coords].apply(lambda x: geometry(x.tolist(), flag=0), axis=1)\n    coords_df['d_area'] = coords_df.loc[:, dire_coords].apply(lambda x: geometry(x.tolist(), flag=1), axis=1)\n    coords_df['d_perim'] = coords_df.loc[:, dire_coords].apply(lambda x: geometry(x.tolist(), flag=0), axis=1)\n    coords_df['intersection'] = coords_df.loc[:, radiant_coords + dire_coords].apply(lambda x: intersection(x.iloc[:10].tolist(), x.iloc[10:].tolist()), axis=1)\n    coords_df['hausdorff_distance'] = coords_df.loc[:, radiant_coords + dire_coords].apply(lambda x: hausdorff_distance(x.iloc[:10].tolist(), x.iloc[10:].tolist()), axis=1)\n    coords_df['area_diff'] = coords_df['r_area'] - coords_df['d_area']\n    coords_df['perim_diff'] = coords_df['r_perim'] - coords_df['d_perim']\n    \n    if transform:\n        powertransform = PowerTransformer(method='yeo-johnson', standardize=False)\n        X_power = powertransform.fit_transform(coords_df[['r_area', 'r_perim', 'd_area','d_perim', 'intersection', \\\n                                                          'hausdorff_distance', 'area_diff', 'perim_diff']])\n   \n        X_coords = coords_df.drop(columns=['r_area', 'r_perim', 'd_area', 'd_perim','intersection',\\\n                                           'hausdorff_distance', 'area_diff', 'perim_diff']).values\n        X = np.hstack((X_coords, X_power))\n    \n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        return X_scaled, coords_df.columns.tolist()\n    \n    else:\n        return coords_df","7e98ae05":"%%time\ndata = feature_engineering(train_df, transform=False)","d6aafc4c":"# insert target column\ndata['target'] = y_train","7d3d43fd":"data.head()","3001bb30":"data.loc[data['target']==1,'r_perim'].hist(label='radiant win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==0,'r_perim'].hist(label='radiant loose',figsize=(8, 6), alpha=.5)\nplt.title('Radiant polygon perimeter')\nplt.legend();","7f53928b":"data.loc[data['target']==0,'d_perim'].hist(label='dire win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==1,'d_perim'].hist(label='dire loose',figsize=(8, 6), alpha=.5)\nplt.title('Dire polygon perimeter')\nplt.legend();","1afe5895":"data.loc[data['target']==1,'r_area'].hist(label='radiant win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==0,'r_area'].hist(label='radiant loose',figsize=(8, 6), alpha=.5)\nplt.title('Radiant polygon area')\nplt.legend();","a9fe00d1":"data.loc[data['target']==1,'r_centr_y'].hist(label='radiant win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==0,'r_centr_y'].hist(label='radiant loose',figsize=(8, 6), alpha=.5)\nplt.title('Radiant polygon centroid - coordinate y')\nplt.legend();","0001db9d":"data.loc[data['target']==1,'r_centr_x'].hist(label='radiant win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==0,'r_centr_x'].hist(label='radiant loose',figsize=(8, 6), alpha=.5)\nplt.title('Radiant polygon centroid - coordinate x')\nplt.legend();","831de3c2":"data.loc[:,'r_centr_y'].hist(label='radiant', figsize=(8, 6), alpha=.5)\ndata.loc[:,'d_centr_y'].hist(label='dire',figsize=(8, 6), alpha=.5)\nplt.title('Teams polygons centroids - coordinate y')\nplt.legend();","f511d6e6":"data.loc[:,'r_centr_x'].hist(label='radiant', figsize=(8, 6), alpha=.5)\ndata.loc[:,'d_centr_x'].hist(label='dire',figsize=(8, 6), alpha=.5)\nplt.title('Teams polygons centroids - coordinate x')\nplt.legend();","158ef8dc":"data.loc[data['target']==1,'r_repr_x'].hist(label='radiant win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==0,'r_repr_x'].hist(label='radiant loose',figsize=(8, 6), alpha=.5)\nplt.title('Radiant polygon representative point - coordinate x')\nplt.legend();","963e4057":"data.loc[data['target']==1,'r_repr_y'].hist(label='radiant win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==0,'r_repr_y'].hist(label='radiant loose',figsize=(8, 6), alpha=.5)\nplt.title('Radiant polygon representative point - coordinate y')\nplt.legend();","3b6e9abe":"data.loc[:,'r_repr_x'].hist(label='radiant', figsize=(8, 6), alpha=.5)\ndata.loc[:,'d_repr_x'].hist(label='dire',figsize=(8, 6), alpha=.5)\nplt.title('Teams polygons representative points - coordinate x')\nplt.legend();","e13b575a":"data.loc[:,'r_repr_y'].hist(label='radiant', figsize=(8, 6), alpha=.5)\ndata.loc[:,'d_repr_y'].hist(label='dire',figsize=(8, 6), alpha=.5)\nplt.title('Teams polygons representative points - coordinate y')\nplt.legend();","942d64a0":"data.loc[data['target']==1,'intersection'].hist(label='radiant win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==0,'intersection'].hist(label='radiant loose',figsize=(8, 6), alpha=.5)\nplt.title('Polygons intersection')\nplt.legend();","d6ec0b96":"data.loc[data['target']==1,'hausdorff_distance'].hist(label='radiant win', figsize=(8, 6), alpha=.5)\ndata.loc[data['target']==0,'hausdorff_distance'].hist(label='radiant loose',figsize=(8, 6), alpha=.5)\nplt.title('Polygons Hausdorff distance')\nplt.legend();","839e6362":"fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,6))\nsns.scatterplot(x='r_centr_x', y='r_centr_y', hue='target', data=data, ax=ax[0])\nax[0].set_title(\"Radiant centroids\")\nsns.scatterplot(x='d_centr_x', y='d_centr_y', hue='target', data=data, ax=ax[1])\nax[1].set_title(\"Dire centroids\");","cb9db655":"%%time\nX, features = feature_engineering(train_df, transform=True)","5489181b":"classifier = evaluate(X,features)","3d5e3e86":"import xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier","cd8a26f2":"# Here we can define columns in dataset which we dont want the model to train on\ntarget = 'target'","3e435393":"# function to fit XGBoost classifier, with tuning the number of estimators and plotting feature importancies\ndef modelfit(alg, dtrain, predictors,useTrainCV=True, plot=False, cv_folds=5, early_stopping_rounds=50):\n\n# Crossvalidation\n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n                          metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=10)\n        alg.set_params(n_estimators=cvresult.shape[0])\n\n# Fit the algorithm on the data\n    alg.fit(dtrain[predictors], dtrain['target'],eval_metric='auc')\n\n# Predict training set:\n    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n\n# Print model report:\n    print( \"\\nModel Report\")\n    print( \"AUC Score (Train): {:.4f}\".format(roc_auc_score(dtrain['target'], dtrain_predprob)))\n    print( 'Optimal number of estimators: {}'.format(cvresult.shape[0]))                \n    if plot:\n        feat_imp = pd.Series(alg.feature_importances_, index=predictors, name='Importances').sort_values(ascending=False)\n        plt.figure(figsize=(13,7))\n        feat_imp.iloc[:50].plot(kind='bar', title='XGBoost feature Importances')\n        plt.ylabel('Feature Importance Score')","0ed60728":"%%time\n#Choose all predictors except target (and something else if you want)\npredictors = [x for x in data.columns if x not in [target]]\n\n# max_depth and reg_alpha were tuned manually. You are welcome to improve.\nxgb_clf = XGBClassifier(\n         learning_rate =0.1,\n         n_estimators=1000,\n         max_depth=4,\n         min_child_weight=1,\n         gamma=0,\n         subsample=0.8,\n         colsample_bytree=0.8,\n         reg_alpha=0.08,\n         objective= 'binary:logistic',\n         nthread=4,\n         seed=SEED)\nmodelfit(xgb_clf, data, predictors, plot=True)","49524806":"Baseline model gives 0.73542 ROC-AUC score on crossvalidation and 0.73832 on LB. As we see from *eli5* , feature weights almost evenly distributed. Boring!\n\nLet's look how we can interpret a group of coordinates from view of geometry. For some particular game, location of players on the map shown below:","4a2e36a8":"That's what polygons of unordered points look like:","b71d5d70":"# Dota 2: engineering coordinates features","99b55ac0":"As we hoped we've got some improvement. This model gives us 0.738615 ROC-AUC score on crossvalidation and 0.74217 on LB  (from baseline scores 0.73542\/0.73832). Coordinates of centroids confidently leading. Although, *eli5* shows features of polygons representative points seem excessive, and polygons intersection feature weight is almost meaningless.\n\nWell, it's time to try gradient boosting algorythm. I chose XGBoost. Data is prepaired above already.","9c3de1cd":"Now we can visualize the polygons for some particular games just to make it clear why we are doing all these things.","49e4c945":"As we can see from plots, mutual arrangement, shape and thus geometric parameters of polygons vary a lot from game to game. We can expect that besides pure coordinates these features may have some additional influence on winner prediction ability of a model. Let's get started with the construction of additional features, but before that we\u2019ll code two missing functions (to simplify things for rows of our dataframe).","b416749e":"Coordinates of polygons centroids is strong feature that we discovered! Both algorythms consider polygons intersection feature not so important. As for coordinates of representative points, there is a need for additional investigation.\n\nThank you for attention!","48ae5381":"We cannot make use of polygons in this form. So, we need to write a function in which we order the points and calculate simple  geometric features using *shapely* inbuilt functions (area, perimeter):","685f9514":"First we make baseline model on pure coordinates using logistic regression.","c9d7f78b":"For example, let's take some coordinates of particular game as lists:","a1316fa8":"Ordered points give us needed representation of polygons:","687eb943":"This kernel shows some new ideas on feature engineering using players coordinates. We'll learn new tools to make use of computational geometry.","452e8a34":"Applying the function on train data with no transformation (we want to see distribution plots for new features):","36a9ed76":"Time to get confirmation of our hypothesis and beat baseline model score! :)","b6d03d3b":"Next step is to get more features from geometric objects using inbuilt functions of *shapely*:","127e64c2":"So, this is the main function to make boring data funny :). As we can see later from distribution plots, we need to power transform some new features to  minimize skewness and make data more Gaussian-like. I left a possibility not to power transform and normalize data as tree-based algorythms don't need it.","25b1f5cc":"For teams polygons can be built based on thier coordinates. The main idea of feature engineering is to calculate some values which describe geometry of these poligons alone or in interaction. For this i used [*shapely*](https:\/\/shapely.readthedocs.io\/en\/stable\/manual.html) module which requires specific representation of data. Let's figure out what it means.\nSimplest 2D object is a *Point*, constructed from tuple of coordinates *x* and *y*. Then, *Polygon* is an ordered sequence of *(x, y)* point tuples. To meet this requirement we need to:\n1. create points as tuples of coordinates,\n2. order points.\n\nTo begin with, we define function to  group coordinates in tuples."}}