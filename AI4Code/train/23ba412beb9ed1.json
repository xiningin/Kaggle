{"cell_type":{"dde19a92":"code","22b57e4b":"code","ddceab89":"code","9c0076fe":"code","a05efc12":"code","eeea7345":"markdown","e5af0555":"markdown","45ebb4f6":"markdown","8d094880":"markdown","e5d294d8":"markdown"},"source":{"dde19a92":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils.data.sampler import SubsetRandomSampler","22b57e4b":"class Inception(nn.Module):\n    def __init__(self, in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x, pool_planes):\n        super(Inception, self).__init__()\n\n        self.path1 = nn.Sequential(\n            nn.Conv2d(in_planes, kernel_1_x, 1),\n            nn.ReLU(inplace=True),\n        )\n        self.path2 = nn.Sequential(\n            nn.Conv2d(in_planes, kernel_3_in, 1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(kernel_3_in, kernel_3_x, 3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n        self.path3 = nn.Sequential(\n            nn.Conv2d(in_planes, kernel_5_in, 1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(kernel_5_in, kernel_5_x, 5, padding=2),\n            nn.ReLU(inplace=True),\n        )\n        self.path4 = nn.Sequential(\n            nn.MaxPool2d(3, stride=1, padding=1, ceil_mode=True),\n            nn.Conv2d(in_planes, pool_planes, 1),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        x1 = self.path1(x)\n        x2 = self.path2(x)\n        x3 = self.path3(x)\n        x4 = self.path4(x)\n        return torch.cat([x1, x2, x3, x4], 1)\n\n\nclass GoogLeNet(nn.Module):\n    def __init__(self, input_dim=3):\n        super(GoogLeNet, self).__init__()\n        self.pre_layers = nn.Sequential(\n            nn.Conv2d(input_dim, 192, kernel_size=3, padding=1),\n            nn.BatchNorm2d(192),\n            nn.ReLU(True),\n        )\n        \n        self.layer1 = Inception(192,  64,  96, 128, 16, 32, 32)\n        \n        self.layer2 = Inception(256, 128, 128, 192, 32, 96, 64)\n        \n        self.layer3 = Inception(480, 192,  96, 208, 16,  48,  64)\n        \n        self.max_pool = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.avgpool = nn.AvgPool2d(8, stride=1)\n        self.linear = nn.Linear(512, 10)\n        \n\n    def forward(self, x):\n        x = self.pre_layers(x)\n\n        x = self.layer1(x)\n        x = self.max_pool(x)\n        x = self.layer2(x)\n        x = self.max_pool(x)\n        x = self.layer3(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        return x","ddceab89":"torchvision.transforms.functional.resize\ntransform = transforms.Compose(\n    [\n     transforms.Resize(size=(32, 32)),\n     transforms.ToTensor(),\n     transforms.Normalize((0.5,), (0.5,)),\n])\n     \n\nbatch_size = 64\n\nidx_train = np.arange(50000)\nnp.random.shuffle(idx_train)\nidx_train = idx_train[:1000]\n\ntrainset = torchvision.datasets.CIFAR10(root=\".\/data\", train=True, transform=transform, download=True)\ntrainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=False,num_workers=2,\n                                         sampler=SubsetRandomSampler(idx_train))\n\nidx_test = np.arange(10000)\nnp.random.shuffle(idx_test)\nidx_test = idx_train[:1000]\n\ntestset = torchvision.datasets.CIFAR10(root=\".\/data\", train=False, transform=transform, download=True)\ntestloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=False,num_workers=2)\n\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))","9c0076fe":"criterion = nn.CrossEntropyLoss()\n\ndef accuracy(net, test_loader, cuda=True):\n    net.eval()\n    correct = 0\n    total = 0\n    loss = 0\n    with torch.no_grad():\n        for data in test_loader:\n            images, labels = data\n            if cuda:\n                images = images.type(torch.cuda.FloatTensor)\n                labels = labels.type(torch.cuda.LongTensor)\n            outputs = net(images)\n            # loss+= criterion(outputs, labels).item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            # if total > 100:\n                # break\n    net.train()\n    print('Accuracy of the network on the test images: %d %%' % (\n        100 * correct \/ total))\n    # return (100.0 * correct \/ total, loss\/total)\n    return 100.0 * correct \/ total\n\ndef train(net, optimizer, train_loader, test_loader, loss,  n_epoch = 5,\n          train_acc_period = 100, test_acc_period = 5, cuda=True):\n    loss_train = []\n    loss_test = []\n    total = 0\n    for epoch in range(n_epoch):  # loop over the dataset multiple times\n        running_loss = 0.0\n        running_acc = 0.0\n        for i, data in enumerate(train_loader, 0):\n            # get the inputs\n            inputs, labels = data\n            if cuda:\n                inputs = inputs.type(torch.cuda.FloatTensor)\n                labels = labels.type(torch.cuda.LongTensor)\n            # print(inputs.shape)\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n          \n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total += labels.size(0)\n            # print statistics\n            running_loss = 0.33*loss.item()\/labels.size(0) + 0.66*running_loss\n            _, predicted = torch.max(outputs.data, 1)\n            correct = (predicted == labels).sum().item()\/labels.size(0)\n            running_acc = 0.3*correct + 0.66*running_acc\n            if i % train_acc_period == train_acc_period-1:\n                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss))\n                print('[%d, %5d] acc: %.3f' %(epoch + 1, i + 1, running_acc))\n                running_loss = 0.0\n                total = 0\n                # break\n        if epoch % test_acc_period == test_acc_period-1:\n            cur_acc, cur_loss = accuracy(net, test_loader, cuda=cuda)\n            print('[%d] loss: %.3f' %(epoch + 1, cur_loss))\n            print('[%d] acc: %.3f' %(epoch + 1, cur_acc))\n      \n    print('Finished Training')","a05efc12":"net = GoogLeNet()\n\nuse_cuda = True\nif use_cuda and torch.cuda.is_available():\n    print(\"using cuda\")\n    net.cuda()\nlearning_rate = 1e-3\noptimizer = torch.optim.Adam(net.parameters(),lr=learning_rate)\ntrain(net, optimizer, trainloader, testloader, criterion,  n_epoch = 50,\n      train_acc_period = 10, test_acc_period = 1000)\naccuracy(net, testloader, cuda=use_cuda)","eeea7345":"## Defining GoogleNet","e5af0555":"## Train function for CIFAR10","45ebb4f6":"## Training","8d094880":"From https:\/\/www.enseignement.polytechnique.fr\/informatique\/INF473V\/TD\/6\/INF473V-td_6-1.php\n\nArticle: https:\/\/arxiv.org\/pdf\/1409.4842.pdf","e5d294d8":"## Downloading CIFAR10 dataset"}}