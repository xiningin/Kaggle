{"cell_type":{"f4034546":"code","8279b9b3":"code","3fc6b541":"code","c0df368d":"code","c78c0621":"code","bee2db3f":"code","13d11b1c":"code","38c914ed":"code","0de2e240":"code","32059db0":"code","83cc4c63":"code","857df982":"code","90b8e46e":"code","77d01f7d":"code","ef3a91e6":"code","f67d11ff":"code","b989776c":"code","4c33f439":"code","a29b6232":"code","b78447ea":"code","edba5f50":"code","5aee0f87":"code","a4b57530":"code","146b46e2":"code","10c2bd2e":"code","b3f88122":"code","a8c77930":"code","4c5c18d0":"code","0b3f74df":"code","047aa70f":"code","a4538df4":"code","d98ddc92":"code","aef4dc6f":"code","1f66d5a0":"code","64a7ce24":"code","464975a8":"code","b30519dd":"code","76f45070":"code","16214805":"code","5debbb2f":"code","d25ea914":"code","91d6c98d":"code","38451fa8":"code","81f0603a":"code","16495960":"code","ab95af40":"code","d4fd4c31":"code","8f6868f1":"code","83892298":"code","4ce2cb1f":"code","5c4fd2f1":"code","ffbd6986":"markdown","a6bf0c0b":"markdown","c37a22f1":"markdown","5644cada":"markdown","439e0f8a":"markdown","f28a04bf":"markdown","33bea8f6":"markdown","04ef6ebb":"markdown","83c2fd0b":"markdown","e66e4d15":"markdown","fd7ce3fb":"markdown","eeca3455":"markdown","788f37dc":"markdown","6d5160ef":"markdown","4997e126":"markdown","ec8c5015":"markdown","3e89035a":"markdown","e5be6796":"markdown","86644e33":"markdown","4d89839b":"markdown","99cc0036":"markdown","b8b617f1":"markdown","5b5201fb":"markdown","4406fa32":"markdown","3e7ae068":"markdown","171539c0":"markdown","414e81f7":"markdown","970647f9":"markdown","7b371d03":"markdown","28734ee3":"markdown","3f612cbb":"markdown","ce09cf9e":"markdown","196f9ae4":"markdown","20483e30":"markdown","5e3b66c2":"markdown","cac46aba":"markdown","79bb5dd9":"markdown","67cc1f53":"markdown","4dc2227c":"markdown","22b0fa68":"markdown","c02f1778":"markdown","23225898":"markdown","0ef41199":"markdown","2ee42f91":"markdown","da8b3e5a":"markdown","a0ad7ceb":"markdown","dc8efbbd":"markdown","b85f17e2":"markdown","214f18ad":"markdown","ad36e8e3":"markdown","d42b1088":"markdown","06f05b09":"markdown","a35f2349":"markdown","d67bb98f":"markdown","44fb7902":"markdown","d15d382c":"markdown","39c98c76":"markdown","eeea366f":"markdown","8b54e14d":"markdown","a1403d37":"markdown","07da51af":"markdown","06213181":"markdown","c352bc60":"markdown","1789f88c":"markdown","9fa80a69":"markdown","664c4e69":"markdown","00336ae7":"markdown","391cc4ce":"markdown","3afa8110":"markdown","73974acf":"markdown","b191dbf2":"markdown","34038444":"markdown"},"source":{"f4034546":"# Setting html stuff for the rest of the notebook\nfrom IPython.core.display import display, HTML, Javascript\nhtml_contents =\"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n    <style>\n    font-size: 18px;\n    a:link, a:visited, a:active{\n      color: #003EFF; \n      background-color: transparent; \n      text-decoration: none;\n    }\n\n    a:hover {\n      color: #FF0000;\n      background-color: transparent;\n      text-decoration: underline;\n    }\n    \n    .top_section{\n        background-color: #4F963C;\n        color: black;\n        font-family: Copperplate, Papyrus, fantasy;\n        font-weight: 800;\n        font-size: 30px;\n        padding: 14px 14px;\n        margin-bottom: 6px;\n    }\n    \n    .section_title{\n        background-color: #6AB155;\n        color: black;\n        font-family: Copperplate, Papyrus, fantasy;\n        font-weight: 600;\n        font-size: 30px;\n        padding: 6px 12px;\n        margin-bottom: 5px;\n    }\n    \n    .subsection_title{\n        background: #85CC6F;\n        font-weight: 400;\n        color: black;\n        font-family: Copperplate, Papyrus, fantasy;\n        font-size: 21px;\n        padding: 6px 12px;\n        margin-bottom: 0px;\n    }\n\n    <\/style>\n    <\/head>\n    \n<\/html>\n\"\"\"\n\nHTML(html_contents)","8279b9b3":"# Warning Harry Potter to not come out of the room ! \nimport warnings\nwarnings.filterwarnings('ignore')\n# Basic ingredients\nimport pandas as pd\nimport numpy as np\nimport math,time,copy,json\nfrom tqdm import tqdm\n# Decoration stuff libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\nimport seaborn as sns\n# Setting up decoration params\nplt.style.use('fivethirtyeight')\nlist_gradient = ['#136207','#337B24','#4F963C','#6AB155','#85CC6F','#A0E989',\n                 '#BDFFA4','#D9FFBF','#F7FFDC','#EDEDED','#B5B5B5','#9A9A9A',\n                 '#808080']\nplt.rcParams['figure.figsize'] = (18,16)\nplt.rcParams['figure.dpi'] = 300\nplt.rcParams[\"axes.grid\"] = True\nplt.rcParams[\"grid.color\"] = list_gradient[0]\nplt.rcParams[\"grid.alpha\"] = 0.5\nplt.rcParams[\"grid.linestyle\"] = '--'\nplt.rcParams[\"font.family\"] = \"monospace\"\nplt.rcParams['axes.edgecolor'] = 'black'\nplt.rcParams['figure.frameon'] = True\nplt.rcParams['axes.spines.left'] = True\nplt.rcParams['axes.spines.bottom'] = True\nplt.rcParams['axes.spines.top'] = False\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['axes.linewidth'] = 1.5\nplt.rcParams['figure.facecolor'] = 'white'","3fc6b541":"# Formatting Data\ndata_column_mapping = {\n    \"Time Taken\":[\"Time from Start to Finish (seconds)\"],\n    \"Q1\":[\"Q1\"],\"Q2\":[\"Q2\"],\"Q3\":[\"Q3\"],\"Q4\":[\"Q4\"],\"Q5\":[\"Q5\"],\"Q6\":[\"Q6\"],\n    \"Q7\":[\"Q7_Part_1\",\"Q7_Part_2\",\"Q7_Part_3\",\"Q7_Part_4\",\"Q7_Part_5\",\"Q7_Part_6\",\n          \"Q7_Part_7\",\"Q7_Part_8\",\"Q7_Part_9\",\"Q7_Part_10\",\"Q7_Part_11\",\"Q7_Part_12\",\"Q7_OTHER\"],\n    \"Q8\":[\"Q8\"],\n    \"Q9\":[\"Q9_Part_1\",\"Q9_Part_2\",\"Q9_Part_3\",\"Q9_Part_4\",\"Q9_Part_5\",\"Q9_Part_6\",\n          \"Q9_Part_7\",\"Q9_Part_8\",\"Q9_Part_9\",\"Q9_Part_10\",\"Q9_Part_11\",\"Q9_Part_12\",\"Q9_OTHER\"],\n    \"Q10\":[\"Q10_Part_1\",\"Q10_Part_2\",\"Q10_Part_3\",\"Q10_Part_4\",\"Q10_Part_5\",\"Q10_Part_6\",\"Q10_Part_13\",\"Q10_Part_14\",\n          \"Q10_Part_7\",\"Q10_Part_8\",\"Q10_Part_9\",\"Q10_Part_10\",\"Q10_Part_11\",\"Q10_Part_12\",\"Q10_Part_15\",\"Q10_Part_16\",\"Q10_OTHER\"],\n    \"Q11\":[\"Q11\"],\n    \"Q12\":[\"Q12_Part_1\",\"Q12_Part_2\",\"Q12_Part_3\",\"Q12_Part_4\",\"Q12_Part_5\",\"Q12_OTHER\"],\n    \"Q13\":[\"Q13\"],\n    \"Q14\":[\"Q14_Part_1\",\"Q14_Part_2\",\"Q14_Part_3\",\"Q14_Part_4\",\"Q14_Part_5\",\"Q14_Part_6\",\n          \"Q14_Part_7\",\"Q14_Part_8\",\"Q14_Part_9\",\"Q14_Part_10\",\"Q14_Part_11\",\"Q14_OTHER\"],\n    \"Q15\":[\"Q15\"],\n    \"Q16\":[\"Q16_Part_1\",\"Q16_Part_2\",\"Q16_Part_3\",\"Q16_Part_4\",\"Q16_Part_5\",\"Q16_Part_6\",\"Q16_Part_13\",\"Q16_Part_14\",\"Q16_Part_17\",\n          \"Q16_Part_7\",\"Q16_Part_8\",\"Q16_Part_9\",\"Q16_Part_10\",\"Q16_Part_11\",\"Q16_Part_12\",\"Q16_Part_15\",\"Q16_Part_16\",\"Q16_OTHER\"],\n    \"Q17\":[\"Q17_Part_1\",\"Q17_Part_2\",\"Q17_Part_3\",\"Q17_Part_4\",\"Q17_Part_5\",\"Q17_Part_6\",\n          \"Q17_Part_7\",\"Q17_Part_8\",\"Q17_Part_9\",\"Q17_Part_10\",\"Q17_Part_11\",\"Q17_OTHER\"],\n    \"Q18\":[\"Q18_Part_1\",\"Q18_Part_2\",\"Q18_Part_3\",\"Q18_Part_4\",\"Q18_Part_5\",\"Q18_Part_6\",\"Q18_OTHER\"],\n    \"Q19\":[\"Q19_Part_1\",\"Q19_Part_2\",\"Q19_Part_3\",\"Q19_Part_4\",\"Q19_Part_5\",\"Q19_OTHER\"],\n    \"Q20\":[\"Q20\"],\"Q21\":[\"Q21\"],\"Q22\":[\"Q22\"],\"Q23\":[\"Q23\"],\n    \"Q24\":[\"Q24_Part_1\",\"Q24_Part_2\",\"Q24_Part_3\",\"Q24_Part_4\",\"Q24_Part_5\",\"Q24_Part_6\",\n          \"Q24_Part_7\",\"Q24_OTHER\"],\n    \"Q25\":[\"Q25\"],\"Q26\":[\"Q26\"],\n    \"Q27_A\":[\"Q27_A_Part_1\",\"Q27_A_Part_2\",\"Q27_A_Part_3\",\"Q27_A_Part_4\",\"Q27_A_Part_5\",\"Q27_A_Part_6\",\n          \"Q27_A_Part_7\",\"Q27_A_Part_8\",\"Q27_A_Part_9\",\"Q27_A_Part_10\",\"Q27_A_Part_11\",\"Q27_A_OTHER\"],\n    \"Q27_B\":[\"Q27_B_Part_1\",\"Q27_B_Part_2\",\"Q27_B_Part_3\",\"Q27_B_Part_4\",\"Q27_B_Part_5\",\"Q27_B_Part_6\",\n          \"Q27_B_Part_7\",\"Q27_B_Part_8\",\"Q27_B_Part_9\",\"Q27_B_Part_10\",\"Q27_B_Part_11\",\"Q27_B_OTHER\"],\n    \"Q28\":[\"Q28\"],\n    \"Q29_A\":[\"Q29_A_Part_1\",\"Q29_A_Part_2\",\"Q29_A_Part_3\",\"Q29_A_Part_4\",\"Q29_A_OTHER\"],\n    \"Q29_B\":[\"Q29_B_Part_1\",\"Q29_B_Part_2\",\"Q29_B_Part_3\",\"Q29_B_Part_4\",\"Q29_B_OTHER\"],\n    \"Q30_A\":[\"Q30_A_Part_1\",\"Q30_A_Part_2\",\"Q30_A_Part_3\",\"Q30_A_Part_4\",\"Q30_A_Part_5\",\"Q30_A_Part_6\",\"Q30_A_Part_7\",\"Q30_A_OTHER\"],\n    \"Q30_B\":[\"Q30_B_Part_1\",\"Q30_B_Part_2\",\"Q30_B_Part_3\",\"Q30_B_Part_4\",\"Q30_B_Part_5\",\"Q30_B_Part_6\",\"Q30_B_Part_7\",\"Q30_B_OTHER\"],\n    \"Q31_A\":[\"Q31_A_Part_1\",\"Q31_A_Part_2\",\"Q31_A_Part_3\",\"Q31_A_Part_4\",\"Q31_A_Part_5\",\"Q31_A_Part_6\",\n          \"Q31_A_Part_7\",\"Q31_A_Part_8\",\"Q31_A_Part_9\",\"Q31_A_OTHER\"],\n    \"Q31_B\":[\"Q31_B_Part_1\",\"Q31_B_Part_2\",\"Q31_B_Part_3\",\"Q31_B_Part_4\",\"Q31_B_Part_5\",\"Q31_B_Part_6\",\n          \"Q31_B_Part_7\",\"Q31_B_Part_8\",\"Q31_B_Part_9\",\"Q31_B_OTHER\"],\n    \"Q32_A\":[\"Q32_A_Part_1\",\"Q32_A_Part_2\",\"Q32_A_Part_3\",\"Q32_A_Part_4\",\"Q32_A_Part_5\",\"Q32_A_Part_6\",\"Q32_A_Part_13\",\"Q32_A_Part_14\",\"Q32_A_Part_17\",\"Q32_A_Part_18\",\n          \"Q32_A_Part_7\",\"Q32_A_Part_8\",\"Q32_A_Part_9\",\"Q32_A_Part_10\",\"Q32_A_Part_11\",\"Q32_A_Part_12\",\"Q32_A_Part_15\",\"Q32_A_Part_16\",\"Q32_A_Part_19\",\"Q32_A_Part_20\",\"Q32_A_OTHER\"],\n    \"Q32_B\":[\"Q32_B_Part_1\",\"Q32_B_Part_2\",\"Q32_B_Part_3\",\"Q32_B_Part_4\",\"Q32_B_Part_5\",\"Q32_B_Part_6\",\"Q32_B_Part_13\",\"Q32_B_Part_14\",\"Q32_B_Part_17\",\"Q32_B_Part_18\",\n          \"Q32_B_Part_7\",\"Q32_B_Part_8\",\"Q32_B_Part_9\",\"Q32_B_Part_10\",\"Q32_B_Part_11\",\"Q32_B_Part_12\",\"Q32_B_Part_15\",\"Q32_B_Part_16\",\"Q32_B_Part_19\",\"Q32_B_Part_20\",\"Q32_B_OTHER\"],\n    \"Q33\":[\"Q33\"],\n    \"Q34_A\":[\"Q34_A_Part_1\",\"Q34_A_Part_2\",\"Q34_A_Part_3\",\"Q34_A_Part_4\",\"Q34_A_Part_5\",\"Q34_A_Part_6\",\"Q34_A_Part_13\",\"Q34_A_Part_14\",\"Q34_A_Part_16\",\n          \"Q34_A_Part_7\",\"Q34_A_Part_8\",\"Q34_A_Part_9\",\"Q34_A_Part_10\",\"Q34_A_Part_11\",\"Q34_A_Part_12\",\"Q34_A_Part_15\",\"Q34_A_OTHER\"],\n    \"Q34_B\":[\"Q34_B_Part_1\",\"Q34_B_Part_2\",\"Q34_B_Part_3\",\"Q34_B_Part_4\",\"Q34_B_Part_5\",\"Q34_B_Part_6\",\"Q34_B_Part_13\",\"Q34_B_Part_14\",\"Q34_B_Part_16\",\n          \"Q34_B_Part_7\",\"Q34_B_Part_8\",\"Q34_B_Part_9\",\"Q34_B_Part_10\",\"Q34_B_Part_11\",\"Q34_B_Part_12\",\"Q34_B_Part_15\",\"Q34_B_OTHER\"],\n    \"Q35\":[\"Q35\"],\n    \"Q36_A\":[\"Q36_A_Part_1\",\"Q36_A_Part_2\",\"Q36_A_Part_3\",\"Q36_A_Part_4\",\"Q36_A_Part_5\",\"Q36_A_Part_6\",\n          \"Q36_A_Part_7\",\"Q36_A_OTHER\"],\n    \"Q36_B\":[\"Q36_B_Part_1\",\"Q36_B_Part_2\",\"Q36_B_Part_3\",\"Q36_B_Part_4\",\"Q36_B_Part_5\",\"Q36_B_Part_6\",\n          \"Q36_B_Part_7\",\"Q36_B_OTHER\"],\n    \"Q37_A\":[\"Q37_A_Part_1\",\"Q37_A_Part_2\",\"Q37_A_Part_3\",\"Q37_A_Part_4\",\"Q37_A_Part_5\",\"Q37_A_Part_6\",\n          \"Q37_A_Part_7\",\"Q37_A_OTHER\"],\n    \"Q37_B\":[\"Q37_B_Part_1\",\"Q37_B_Part_2\",\"Q37_B_Part_3\",\"Q37_B_Part_4\",\"Q37_B_Part_5\",\"Q37_B_Part_6\",\n          \"Q37_B_Part_7\",\"Q37_B_OTHER\"],\n    \"Q38_A\":[\"Q38_A_Part_1\",\"Q38_A_Part_2\",\"Q38_A_Part_3\",\"Q38_A_Part_4\",\"Q38_A_Part_5\",\"Q38_A_Part_6\",\n          \"Q38_A_Part_7\",\"Q38_A_Part_8\",\"Q38_A_Part_9\",\"Q38_A_Part_10\",\"Q38_A_Part_11\",\"Q38_A_OTHER\"],\n    \"Q38_B\":[\"Q38_B_Part_1\",\"Q38_B_Part_2\",\"Q38_B_Part_3\",\"Q38_B_Part_4\",\"Q38_B_Part_5\",\"Q38_B_Part_6\",\n          \"Q38_B_Part_7\",\"Q38_B_Part_8\",\"Q38_B_Part_9\",\"Q38_B_Part_10\",\"Q38_B_Part_11\",\"Q38_B_OTHER\"],\n    \"Q39\":[\"Q39_Part_1\",\"Q39_Part_2\",\"Q39_Part_3\",\"Q39_Part_4\",\"Q39_Part_5\",\"Q39_Part_6\",\n          \"Q39_Part_7\",\"Q39_Part_8\",\"Q39_Part_9\",\"Q39_OTHER\"],\n    \"Q40\":[\"Q40_Part_1\",\"Q40_Part_2\",\"Q40_Part_3\",\"Q40_Part_4\",\"Q40_Part_5\",\"Q40_Part_6\",\n          \"Q40_Part_7\",\"Q40_Part_8\",\"Q40_Part_9\",\"Q40_Part_10\",\"Q40_Part_11\",\"Q40_OTHER\"],\n    \"Q41\":[\"Q41\"],\n    \"Q42\":[\"Q42_Part_1\",\"Q42_Part_2\",\"Q42_Part_3\",\"Q42_Part_4\",\"Q42_Part_5\",\"Q42_Part_6\",\n          \"Q42_Part_7\",\"Q42_Part_8\",\"Q42_Part_9\",\"Q42_Part_10\",\"Q42_Part_11\",\"Q42_OTHER\"]\n}\ndef format_input_data(df):\n    list_formatted_data = list()\n    dict_question_mapping = dict()\n    for i, row in tqdm(df.iterrows(),desc=\"Reading the Survey Data\"):\n        #\n        dict_tmp_0 = dict()\n        if i == 0:\n            for q,q_data in data_column_mapping.items():\n                if q in [\"Q5\",\"Q24\"]:\n                    list_tmp_result = list(set([\"{}?\".format(row[p].split(\":\")[0]) for p in q_data]))\n                    #list_headers.append(\"{}|{}\".format(q,list_tmp_result[0]))\n                    dict_question_mapping[q] = list_tmp_result[0]\n                elif q == \"Time Taken\":\n                    pass\n                else:\n                    list_tmp_result = list(set([\"{}?\".format(row[p].split(\"?\")[0]) for p in q_data]))\n                    #list_headers.append(\"{}|{}\".format(q,list_tmp_result[0]))\n                    dict_question_mapping[q] = list_tmp_result[0]\n        else:\n            for q,q_data in data_column_mapping.items():\n                list_tmp_result=list()\n                for p in q_data:\n                    if row[p] is not np.nan:\n                        list_tmp_result.append(str(row[p]).strip())\n                #\n                dict_tmp_0[q]=\"|\".join(list_tmp_result)\n            list_formatted_data.append(dict_tmp_0)\n    #\n    df_output = pd.DataFrame(list_formatted_data)\n    #\n    return df_output, dict_question_mapping\n#\ndf = pd.read_csv(\"..\/input\/kaggle-2021-ds-formatted-file\/formatted_file.csv\")\nwith open('..\/input\/kaggle-2021-ds-formatted-file\/dict_ques_map.json','r') as f:\n    dict_ques_map = json.load(f)\n#df = pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\n#df, dict_ques_map = format_input_data(copy.deepcopy(df))\ndf[\"Time Taken\"] = df[\"Time Taken\"].astype(int)\ndf = df.fillna(\"No Answer Provided\")\ndf = df.replace(\"\",\"No Answer Provided\")","c0df368d":"def prepare_data_for_bar_plot(df,col_name):\n    list_tmp_data = list()\n    df_tmp = pd.DataFrame(get_count_of_data(df[col_name].to_list()).items(),columns=[col_name,\"Count\"])\n    for i, row in df_tmp.iterrows():\n        #print(row[col_name],int(row[\"Count\"]))\n        list_tmp_data.extend([row[col_name]]*int(row[\"Count\"]))\n    df_tmp = pd.DataFrame()\n    df_tmp[col_name] = list_tmp_data\n    return df_tmp\n#\ndef generate_barplot_with_percent(df,colname=None,dict_label=None,label_axis='x',\n                                  gradient=list_gradient,shift=-0.005,x_label=\"\",\n                                  fontsize=12,rotation=45,title=None,y_label=\"\"):\n    \"\"\"Function to display features count including percentage texts.\"\"\"\n    fig, ax = plt.subplots()\n    df_for_plot = np.round(pd.merge(df[colname].value_counts(),\n                                    df[colname].value_counts().div(df[colname].value_counts().sum()\/100),\n                                    left_index=True, right_index=True\n                                   ).rename(columns={'{}_x'.format(colname):\"Count\",\n                                                     '{}_y'.format(colname):\"Percent\"}),\n                           2)\n    #\n    sns.barplot(x=df_for_plot[\"Count\"],y=df_for_plot.index,\n                palette=gradient,edgecolor='black',linewidth=1.5,saturation=1.5)\n    #\n    for counter,(i, row) in enumerate(df_for_plot.iterrows()):\n        ax.text(int(row[\"Count\"]+shift),\n                counter,\n                s='{}%'.format(row[\"Percent\"]),\n                va='center',\n                color='white',\n                fontsize=fontsize,\n                bbox=dict(boxstyle='round',facecolor='black', alpha=0.5))\n    #\n    if dict_label:\n        df_for_plot = pd.merge(df_for_plot,\n                               pd.DataFrame(dict_label.values(),index=dict_label.keys(),columns=[\"col4plot\"]),\n                               left_index=True, right_index=True)\n        if label_axis == 'x':\n            ax.set_xticklabels(df_for_plot[\"col4plot\"].to_list())\n        else:\n            ax.set_yticklabels(df_for_plot[\"col4plot\"].to_list())\n    #\n    plt.title(title, fontname = 'monospace', weight='bold')\n    plt.yticks(fontsize=fontsize,rotation=rotation)\n    plt.xlabel(x_label, fontname = 'monospace', weight='semibold')\n    plt.ylabel(y_label, fontname = 'monospace', weight='semibold')\n    plt.show()\n#\ndef get_count_of_data(list_data):\n    dict_data_count = dict()\n    for i in list_data:\n        for j in i.split(\"|\"):\n            if j not in dict_data_count:\n                dict_data_count[j]=0\n            dict_data_count[j]+=1\n    return dict_data_count\ndef data_for_2_columns(df,outer_loop,column_basis,set_keys):\n    list_i_data = list()\n    for i in df[outer_loop].unique():\n        list_input_data = df[(df[outer_loop]==i)][column_basis].to_list()\n        dict_output = get_count_of_data(list_input_data)\n        for k in (set_keys-dict_output.keys()):\n            dict_output[k]=0\n        dict_output[\"outer_basis\"] = i\n        list_i_data.append(dict_output)\n    return list_i_data\n#\ndef generate_heatmap(df,x_col=None,percent1_y_col=None,palette=list_gradient,show_plot=True,\n                     ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                     x_label=\"\",percent1_y_label=\"\",title=\"\",figsize=(16,12),grouped_col=\"percent1_y_col\",\n                     list_x_format=None,list_percent1_y_format=None,return_df=False):\n    \"\"\"\n    Function to generate heatmap for 2 columns with y column percentage summing up to 1.\n    \"\"\"\n    #\n    if grouped_col == \"percent1_y_col\":\n        df_tmp = pd.DataFrame(data_for_2_columns(df=copy.deepcopy(df),\n                                                  outer_loop=x_col,\n                                                  column_basis=percent1_y_col,\n                                                  set_keys=list(get_count_of_data(df[percent1_y_col].to_list()).keys()))\n                              ).set_index(\"outer_basis\").T\n        df_data = pd.DataFrame(df_tmp.values,columns=list(df_tmp.columns))\n        df_data[\"outer_basis\"] = df_tmp.index\n    elif grouped_col == \"x_col\":\n        df_data = pd.DataFrame(data_for_2_columns(df=copy.deepcopy(df),\n                                                  outer_loop=percent1_y_col,\n                                                  column_basis=x_col,\n                                                  set_keys=list(get_count_of_data(df[x_col].to_list()).keys()))\n                              )\n    #\n    df_data = df_data.rename(columns={\"outer_basis\":\"not_1_percent\"}).set_index(\"not_1_percent\")\n    df_data = (df_data.div(df_data.sum(axis=1),axis=0)).T\n    df_data = df_data[list_percent1_y_format].T[list_x_format].T\n    #\n    if show_plot is True:\n        fig, ax = plt.subplots(figsize=figsize)\n        sns.heatmap(df_data.T,annot=True,cmap=palette[8::-1],edgecolor='black',linewidth=1.5)\n        #\n        plt.title(title, fontname = 'monospace', weight='bold')\n        plt.yticks(fontsize=ticks_fontsize,rotation=y_rotation)\n        plt.xticks(fontsize=ticks_fontsize,rotation=x_rotation)\n        plt.xlabel(x_label, fontname = 'monospace', weight='semibold',fontsize=label_fontsize)\n        plt.ylabel(percent1_y_label, fontname = 'monospace', weight='semibold',fontsize=label_fontsize)\n        plt.show()\n    if return_df==True:\n        return df_data\n#\n#\ndef generate_lineplot(df2plot,x_col=None,y_col=None,hue_col=None,\n                      x_label=\"\",y_label=\"\",title=\"\",figsize=(16,12),\n                      hue_order=None,ticks_fontsize=12,color=None,label_fontsize=12,\n                      rotation_xlabel=90,rotation_ylabel=90,palette=None):\n    \"\"\"\n    Function to generate lineplot\n    \"\"\"\n    #\n    fig, ax = plt.subplots(figsize=figsize)\n    if hue_col is not None:\n        if palette is not None:\n            palette = {i:palette[counter] for counter,i in enumerate(df2plot[hue_col].value_counts().index)}\n        sns.lineplot(x=df2plot[x_col],y=df2plot[y_col],hue=df2plot[hue_col],\n                     hue_order=hue_order,marker=\"o\",\n                     dashes=False,linewidth=1.5,palette=palette)\n    else:\n        sns.lineplot(x=df2plot[x_col],y=df2plot[y_col],marker=\"o\",\n                     dashes=False,linewidth=1.5,color=color)\n    #\n    plt.title(title, fontname = 'monospace', weight='bold')\n    plt.yticks(fontsize=ticks_fontsize,rotation=rotation_ylabel)\n    plt.xticks(fontsize=ticks_fontsize,rotation=rotation_xlabel)\n    plt.xlabel(x_label,fontname='monospace',weight='semibold',fontsize=label_fontsize)\n    plt.ylabel(y_label,fontname='monospace',weight='semibold',fontsize=label_fontsize)\n#\ndef generate_barplot(df2plot,x_col=None,y_col=None,hue_col=None,\n                      x_label=\"\",y_label=\"\",title=\"\",figsize=(16,12),\n                      hue_order=None,ticks_fontsize=12,color=None,label_fontsize=12,\n                      rotation_xlabel=90,rotation_ylabel=90,palette=None):\n    \"\"\"\n    Function to generate lineplot\n    \"\"\"\n    #\n    fig, ax = plt.subplots(figsize=figsize)\n    if hue_col is not None:\n        if palette is not None:\n            palette = {i:palette[counter] for counter,i in enumerate(df2plot[hue_col].value_counts().index)}\n        sns.barplot(x=df2plot[x_col],y=df2plot[y_col],hue=df2plot[hue_col],hue_order=hue_order,palette=palette)\n    else:\n        sns.barplot(x=df2plot[x_col],y=df2plot[y_col],color=color)\n    #\n    plt.title(title, fontname = 'monospace', weight='bold')\n    plt.yticks(fontsize=ticks_fontsize,rotation=rotation_ylabel)\n    plt.xticks(fontsize=ticks_fontsize,rotation=rotation_xlabel)\n    plt.xlabel(x_label,fontname='monospace',weight='semibold',fontsize=label_fontsize)\n    plt.ylabel(y_label,fontname='monospace',weight='semibold',fontsize=label_fontsize)\n###\n###### Specific Plots ######\ndef get_elite_group_distribution(df,x_col=None,x_label=None,y_label=None,title=None,\n                                 plot_hue_col=None,plot_x_col=None,palette=None):\n    #\n    list_be_ml_5 = [\"1-2 years\",\"2-3 years\",\"3-4 years\",\"4-5 years\"]\n    list_ab_ml_5 = [\"5-10 years\",\"10-20 years\",\"20 or more years\"]\n    list_be_c_5 = [\"< 1 years\",\"1-3 years\",\"3-5 years\"]\n    list_ab_c_5 = [\"5-10 years\",\"10-20 years\",\"20+ years\"]\n    #\n    df_lce_mmle_5 = copy.deepcopy(df[(df[\"Q6\"].isin(list_be_c_5)) & (df[\"Q15\"].isin(list_ab_ml_5))])\n    df_mce_lmle_5 = copy.deepcopy(df[(df[\"Q6\"].isin(list_ab_c_5)) & (df[\"Q15\"].isin(list_be_ml_5))])\n    df_mce_mmle_5 = copy.deepcopy(df[(df[\"Q6\"].isin(list_ab_c_5)) & (df[\"Q15\"].isin(list_ab_ml_5))])\n    df_lce_lmle_5 = copy.deepcopy(df[(df[\"Q6\"].isin(list_be_c_5)) & (df[\"Q15\"].isin(list_be_ml_5))])\n    #\n    df_final = pd.merge(df_lce_mmle_5[x_col].value_counts().div(df_lce_mmle_5[x_col].value_counts().sum(),axis=0),\n                        df_mce_lmle_5[x_col].value_counts().div(df_mce_lmle_5[x_col].value_counts().sum(),axis=0),\n                        left_index=True,right_index=True\n                       ).rename(columns={x_col+\"_x\":\"More MLE\",x_col+\"_y\":\"More CE\"})\n    df_final = pd.merge(df_final,\n                        df_mce_mmle_5[x_col].value_counts().div(df_mce_mmle_5[x_col].value_counts().sum(),axis=0),\n                        left_index=True,right_index=True\n                       ).rename(columns={x_col:\"More MLE|CE\"})\n    df_final = pd.merge(df_final,\n                        df_lce_lmle_5[x_col].value_counts().div(df_lce_lmle_5[x_col].value_counts().sum(),axis=0),\n                        left_index=True,right_index=True\n                       ).rename(columns={x_col:\"Low MLE|CE\"})\n    df_final = pd.merge(df_final,\n                        df[x_col].value_counts().div(df[x_col].value_counts().sum(),axis=0),\n                        left_index=True,right_index=True).rename(columns={x_col:\"Overall\"})\n    #\n    df_final[\"More Coding Experience\"] = df_final[\"More CE\"]\/df_final[\"Overall\"]\n    df_final[\"More ML Experience\"] = df_final[\"More MLE\"]\/df_final[\"Overall\"]\n    df_final[\"More ML & Coding Experience\"] = df_final[\"More MLE|CE\"]\/df_final[\"Overall\"]\n    df_final[\"Low ML & Coding Experience\"] = df_final[\"Low MLE|CE\"]\/df_final[\"Overall\"]\n    #\n    if x_col == \"Q5\":\n        df_final = df_final.T.drop(columns=[\"Other\",\"Currently not employed\",\"Student\"])\n    else:\n        df_final = df_final.T\n    df_final = df_final.T[[\"More Coding Experience\",\"More ML Experience\",\n                           \"More ML & Coding Experience\",\n                           \"Low ML & Coding Experience\"]].unstack().reset_index()\n    df_final = df_final.rename(columns={\"level_0\":plot_hue_col,\"level_1\":plot_x_col})\n    #\n    generate_lineplot(df2plot=df_final,x_col=plot_x_col,y_col=0,hue_col=plot_hue_col,\n                      x_label=x_label,y_label=y_label,title=title,figsize=(16,8),\n                      hue_order=None,ticks_fontsize=12,color=None,label_fontsize=12,\n                      rotation_xlabel=90,rotation_ylabel=90,palette=palette)\n#","c78c0621":"generate_barplot_with_percent(df=df, colname='Q1',fontsize=14,rotation=45,\n                              title='Age Distribution of Participants',\n                              x_label=\"# of Participants\",y_label=\"Age Group\",shift=50)","bee2db3f":"ml_exp_format = [\"No Answer Provided\",\"I do not use machine learning methods\",\"Under 1 year\",\n                 \"1-2 years\",\"2-3 years\",\"3-4 years\",\"4-5 years\",\"5-10 years\",\"10-20 years\",\n                 \"20 or more years\"]\ncoding_exp_format = [\"I have never written code\",\"< 1 years\",\"1-3 years\",\"3-5 years\",\n                     \"5-10 years\",\"10-20 years\",\"20+ years\"]\ngenerate_heatmap(df,x_col=\"Q6\",percent1_y_col=\"Q15\",palette=list_gradient,\n                 x_label=\"Coding Experience (in years)\",percent1_y_label=\"ML Experience (in years)\",\n                 title=\"Coding experience within each ML experience (in years)\",\n                 list_x_format=coding_exp_format,list_percent1_y_format=ml_exp_format)","13d11b1c":"generate_heatmap(df,x_col=\"Q6\",percent1_y_col=\"Q1\",palette=list_gradient,\n                       x_label=\"Coding Experience\",percent1_y_label=\"Age Group\",\n                       title=\"Coding experience distribution within each age group\",\n                       list_x_format=coding_exp_format,list_percent1_y_format=df[\"Q1\"].sort_values().unique().tolist())","38c914ed":"generate_heatmap(df,x_col=\"Q15\",percent1_y_col=\"Q1\",palette=list_gradient,\n                       x_label=\"ML Experience\",percent1_y_label=\"Age Group\",\n                       title=\"ML experience distribution within each age group\",\n                       list_x_format=ml_exp_format,list_percent1_y_format=df[\"Q1\"].sort_values().unique().tolist())","0de2e240":"df_intelligent_fellas = df[((df[\"Q1\"]==\"18-21\") & ((df[\"Q6\"]==\"20+ years\") | (df[\"Q15\"]==\"20 or more years\")))]\ndf = df[~((df[\"Q1\"]==\"18-21\") & ((df[\"Q6\"]==\"20+ years\") | (df[\"Q15\"]==\"20 or more years\")))]","32059db0":"df_intelligent_fellas.groupby(by=[\"Q1\",\"Q6\",\"Q15\"])[[\"Q2\"]].count().rename(columns={\"Q2\":\"Count\"}\n                                                                          ).rename_axis(index={\"Q1\":\"Age Group\",\n                                                                                   \"Q6\":\"Coding Experience\",\n                                                                                   \"Q15\":\"ML Experience\"})","83cc4c63":"generate_barplot_with_percent(df=df,colname=\"Q2\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Gender\",\n                              title=\"Gender distribution of Participants\",\n                              fontsize=14,rotation=0)","857df982":"df_age_by_gender = generate_heatmap(df=df,x_col=\"Q1\",percent1_y_col=\"Q2\",show_plot=False,\n                                          list_x_format=df[\"Q1\"].sort_values().unique(),\n                                          list_percent1_y_format=df[\"Q2\"].sort_values().unique(),\n                                          return_df=True)\ndf_age_by_gender = pd.DataFrame(df_age_by_gender.unstack()).reset_index().rename(columns={\"not_1_percent\":\"Gender\",\"level_1\":\"Age Group\",0:\"Count\"})\ngenerate_lineplot(df2plot=df_age_by_gender,x_col=\"Age Group\",y_col=\"Count\",hue_col=\"Gender\",\n                  x_label=\"Age Group\",y_label=\"% of Participants\",figsize=(16,12),\n                  title=\"Age Group distribution by Gender\",\n                  ticks_fontsize=10,label_fontsize=14,\n                  rotation_xlabel=45,rotation_ylabel=0,palette=None)","90b8e46e":"generate_barplot(df2plot=df[\"Q3\"].value_counts().reset_index(),\n                 x_col=\"index\",y_col=\"Q3\",hue_col=None,\n                 x_label=\"Country\",y_label=\"# of Participant\",\n                 title=\"Country distribution of Participants\",figsize=(18,8),\n                 ticks_fontsize=12,color=\"green\",label_fontsize=12,\n                 rotation_xlabel=90,rotation_ylabel=90,palette=None)","77d01f7d":"generate_heatmap(df,x_col=\"Q15\",percent1_y_col=\"Q3\",palette=list_gradient,\n                 x_label=\"ML Experience\",percent1_y_label=\"Country\",\n                 title=\"ML Experience distribution wihtin each Country\",figsize=(16,26),\n                 list_percent1_y_format=df[\"Q3\"].sort_values().unique().tolist(),\n                 list_x_format=ml_exp_format)","ef3a91e6":"generate_barplot_with_percent(df=df,colname=\"Q5\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Role\",\n                              title=\"Role distribution of Participants\",\n                              fontsize=14,rotation=0)","f67d11ff":"get_elite_group_distribution(df=df,x_col=\"Q5\",x_label=\"Roles taken\",plot_x_col=\"Roles\",palette=None,\n                             y_label=\"Ratio of experience to overall experience\",plot_hue_col=\"Experience\",\n                             title=\"Importance of ML & Coding Experience based on Roles\")","b989776c":"list_be_ml_5 = [\"1-2 years\",\"2-3 years\",\"3-4 years\",\"4-5 years\"]\nlist_be_c_5 = [\"< 1 years\",\"1-3 years\",\"3-5 years\"]\ndf_lce_lmle_5 = copy.deepcopy(df[(df[\"Q6\"].isin(list_be_c_5)) & (df[\"Q15\"].isin(list_be_ml_5))])\ngenerate_heatmap(df=df_lce_lmle_5,x_col=\"Q1\",percent1_y_col=\"Q5\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Age Group\",percent1_y_label=\"Roles\",figsize=(16,10),\n                 title=\"Role distribution across Age Group\",\n                 list_percent1_y_format=df[\"Q5\"].value_counts().index,\n                 list_x_format=df[\"Q1\"].sort_values().unique())","4c33f439":"df_role_by_gender = generate_heatmap(df=df,x_col=\"Q5\",percent1_y_col=\"Q2\",palette=list_gradient,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,show_plot=True,\n                 x_label=\"Roles\",percent1_y_label=\"Gender\",figsize=(26,12),\n                 title=\"Role distribution within each Gender\",return_df=True,\n                 list_x_format=df[\"Q5\"].value_counts().index,\n                 list_percent1_y_format=df[\"Q2\"].value_counts().index)","a29b6232":"generate_barplot(df2plot=df[\"Q20\"].value_counts().reset_index(),\n                 x_col=\"index\",y_col=\"Q20\",hue_col=None,\n                 x_label=\"Country\",y_label=\"# of Participant\",\n                 title=\"Industry distribution of Participants\",figsize=(18,8),\n                 ticks_fontsize=12,color=\"green\",label_fontsize=12,\n                 rotation_xlabel=90,rotation_ylabel=90,palette=None)","b78447ea":"generate_heatmap(df=df,x_col=\"Q15\",percent1_y_col=\"Q20\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Age Group\",percent1_y_label=\"ML Experience\",figsize=(16,10),\n                 title=\"ML Experience distribution across Age Group\",\n                 list_x_format=ml_exp_format,\n                 list_percent1_y_format=df[\"Q20\"].value_counts().index)","edba5f50":"generate_heatmap(df=df,x_col=\"Q5\",percent1_y_col=\"Q20\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Industry\",percent1_y_label=\"Roles\",figsize=(16,12),\n                 title=\"Role distribution within Industry\",\n                 list_x_format=df[\"Q5\"].value_counts().index,\n                 list_percent1_y_format=df[\"Q20\"].value_counts().index)","5aee0f87":"get_elite_group_distribution(df=df,x_col=\"Q20\",x_label=\"Industry\",plot_x_col=\"Industry\",palette=None,\n                             y_label=\"Ratio of experience to overall experience\",plot_hue_col=\"Experience\",\n                             title=\"Importance of ML & Coding Experience in a given Industry\")","a4b57530":"generate_heatmap(df=df,x_col=\"Q20\",percent1_y_col=\"Q2\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Industry\",percent1_y_label=\"Gender\",figsize=(26,12),\n                 title=\"Industry distribution within each Gender\",\n                 list_x_format=df[\"Q20\"].value_counts().index,\n                 list_percent1_y_format=df[\"Q2\"].value_counts().index)","146b46e2":"generate_barplot(df2plot=df[\"Q25\"].value_counts().reset_index(),\n                 x_col=\"index\",y_col=\"Q25\",hue_col=None,\n                 x_label=\"Yearly Compensation (in $)\",y_label=\"# of Participant\",\n                 title=\"Yearly Compensation distribution of Participants\",figsize=(18,8),\n                 ticks_fontsize=12,color=\"green\",label_fontsize=12,\n                 rotation_xlabel=90,rotation_ylabel=90,palette=None)","10c2bd2e":"compensation_order = [\"No Answer Provided\",\"$0-999\",\"1,000-1,999\",\"2,000-2,999\",\"3,000-3,999\",\n                      \"4,000-4,999\",\"5,000-7,499\",\"7,500-9,999\",\"10,000-14,999\",\"15,000-19,999\",\n                      \"20,000-24,999\",\"25,000-29,999\",\"30,000-39,999\",\"40,000-49,999\",\"50,000-59,999\",\n                      \"60,000-69,999\",\"70,000-79,999\",\"80,000-89,999\",\"90,000-99,999\",\"100,000-124,999\",\n                      \"125,000-149,999\",\"150,000-199,999\",\"200,000-249,999\",\"250,000-299,999\",\n                      \"300,000-499,999\",\"$500,000-999,999\",\">$1,000,000\"]\nget_elite_group_distribution(df=df,x_col=\"Q25\",x_label=\"Yearly Compensation (in $)\",plot_x_col=\"Compenstaion\",\n                             palette=None,plot_hue_col=\"Experience\",\n                             y_label=\"Ratio of experience to overall experience\",\n                             title=\"Importance of ML & Coding Experience to earn a given compensation\")","b3f88122":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q7\"),\n                              colname=\"Q7\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Language\",\n                              title=\"Language distribution of Participants\",\n                              fontsize=14,rotation=0)","a8c77930":"list_languages_order = list(get_count_of_data(df[\"Q7\"]).keys())\ngenerate_heatmap(df=df,x_col=\"Q5\",percent1_y_col=\"Q7\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Roles\",percent1_y_label=\"Language\",figsize=(18,12),\n                 title=\"Role distribution within each Language\",\n                 list_x_format=df[\"Q5\"].value_counts().index,\n                 list_percent1_y_format=list_languages_order)","4c5c18d0":"generate_heatmap(df,x_col=\"Q15\",percent1_y_col=\"Q7\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"ML Experience\",percent1_y_label=\"Languages\",figsize=(16,12),\n                 title=\"ML Experience distribution within each Language\",grouped_col=\"percent1_y_col\",\n                 list_x_format=ml_exp_format,list_percent1_y_format=list_languages_order,return_df=False)","0b3f74df":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q9\"),\n                              colname=\"Q9\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"IDE\",\n                              title=\"IDE distribution of Participants\",\n                              fontsize=14,rotation=0)","047aa70f":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q10\"),\n                              colname=\"Q10\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Hosted Notebook\",\n                              title=\"Hosted Notebook distribution of Participants\",\n                              fontsize=14,rotation=0)","a4538df4":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q11\"),\n                              colname=\"Q11\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Computing Resource\",\n                              title=\"Computing Resource distribution of Participants\",\n                              fontsize=14,rotation=0)","d98ddc92":"generate_heatmap(df,x_col=\"Q5\",percent1_y_col=\"Q11\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Role\",percent1_y_label=\"Computing Resource\",figsize=(16,12),\n                 title=\"Role distribution within each Computing Resource\",grouped_col=\"percent1_y_col\",\n                 list_x_format=df[\"Q5\"].value_counts().index,list_percent1_y_format=df[\"Q11\"].value_counts().index,\n                 return_df=False)","aef4dc6f":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q14\"),\n                              colname=\"Q14\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Visualization Library\",\n                              title=\"Visualization Library distribution of Participants\",\n                              fontsize=14,rotation=0)","1f66d5a0":"list_vizs_order = list(get_count_of_data(df[\"Q14\"]).keys())\ngenerate_heatmap(df,x_col=\"Q5\",percent1_y_col=\"Q14\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Role\",percent1_y_label=\"Visualization Library\",figsize=(16,12),\n                 title=\"Role distribution within each Visualization Library\",grouped_col=\"percent1_y_col\",\n                 list_x_format=df[\"Q5\"].value_counts().index,list_percent1_y_format=list_vizs_order,\n                 return_df=False)","64a7ce24":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q17\"),\n                              colname=\"Q17\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Algorithms\",\n                              title=\"Algorithms distribution of Participants\",\n                              fontsize=14,rotation=0)","464975a8":"list_algo_order = list(get_count_of_data(df[\"Q17\"]).keys())\ngenerate_heatmap(df,x_col=\"Q15\",percent1_y_col=\"Q17\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"ML Experience\",percent1_y_label=\"Algorithms\",figsize=(16,12),\n                 title=\"ML Experience distribution within each Algorithms\",grouped_col=\"percent1_y_col\",\n                 list_x_format=ml_exp_format,list_percent1_y_format=list_algo_order,return_df=False)","b30519dd":"generate_heatmap(df,x_col=\"Q5\",percent1_y_col=\"Q17\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Role\",percent1_y_label=\"Algorithms\",figsize=(16,12),\n                 title=\"Role distribution within each Algorithms\",grouped_col=\"percent1_y_col\",\n                 list_x_format=df[\"Q5\"].value_counts().index,list_percent1_y_format=list_algo_order,return_df=False)","76f45070":"generate_heatmap(df,x_col=\"Q20\",percent1_y_col=\"Q17\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Industry\",percent1_y_label=\"Algorithms\",figsize=(26,12),\n                 title=\"Industry distribution within each Algorithms\",grouped_col=\"percent1_y_col\",\n                 list_x_format=df[\"Q20\"].value_counts().index,list_percent1_y_format=list_algo_order,return_df=False)","16214805":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q16\"),\n                              colname=\"Q16\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"ML Frameworks\",\n                              title=\"ML Frameworks distribution of Participants\",\n                              fontsize=14,rotation=0)","5debbb2f":"list_framew_order = list(get_count_of_data(df[\"Q16\"]).keys())\ngenerate_heatmap(df,x_col=\"Q5\",percent1_y_col=\"Q16\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Role\",percent1_y_label=\"Framework\",figsize=(16,12),\n                 title=\"Role distribution within each Framework\",grouped_col=\"percent1_y_col\",\n                 list_x_format=df[\"Q5\"].value_counts().index,list_percent1_y_format=list_framew_order,\n                 return_df=False)","d25ea914":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q24\"),\n                              colname=\"Q24\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Activity\",\n                              title=\"Activity distribution of Participants\",\n                              fontsize=14,rotation=0)","91d6c98d":"dict_act_mapping = {\"No Answer Provided\":\"NAP\",\"Other\":\"Other\",\n\"Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\":\"Data infrastructure activity\",\n\"Do research that advances the state of the art of machine learning\":\"Advance ML\",\n\"Analyze and understand data to influence product or business decisions\":\"Decision making\",\n\"Build prototypes to explore applying machine learning to new areas\":\"Explore new avenues\",\n\"None of these activities are an important part of my role at work\":\"None of these\",\n\"Experimentation and iteration to improve existing ML models\":\"Improve existing ML\",\n\"Build and\/or run a machine learning service that operationally improves my product or workflows\":\"ML to improve product\"}\ndef map_activity(str_data):\n    list_output = list()\n    for i in str_data.split(\"|\"):\n        list_output.append(dict_act_mapping[i])\n    return \"|\".join(list_output)\ndf[\"Q24_updated\"] = df.apply(lambda row:map_activity(row[\"Q24\"]),axis=1)\n#","38451fa8":"list_activity_order = list(get_count_of_data(df[\"Q24_updated\"]).keys())\ngenerate_heatmap(df,x_col=\"Q24_updated\",percent1_y_col=\"Q5\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Activity\",percent1_y_label=\"Role\",figsize=(16,12),\n                 title=\"Activity distribution within each Role\",grouped_col=\"x_col\",\n                 list_x_format=list_activity_order,list_percent1_y_format=df[\"Q5\"].value_counts().index,\n                 return_df=False)","81f0603a":"generate_heatmap(df,x_col=\"Q24_updated\",percent1_y_col=\"Q20\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Activity\",percent1_y_label=\"Industry\",figsize=(16,12),\n                 title=\"Activity distribution within each Industry\",grouped_col=\"x_col\",\n                 list_x_format=list_activity_order,list_percent1_y_format=df[\"Q20\"].value_counts().index,\n                 return_df=False)","16495960":"generate_heatmap(df,x_col=\"Q24_updated\",percent1_y_col=\"Q15\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Activity\",percent1_y_label=\"ML Experience\",figsize=(16,12),\n                 title=\"Activity Distribution within each ML Experience\",grouped_col=\"x_col\",\n                 list_x_format=list_activity_order,list_percent1_y_format=ml_exp_format,\n                 return_df=False)","ab95af40":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q4\"),\n                              colname=\"Q4\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Education\",\n                              title=\"Education (completed\/planning) Distribution of Participants\",\n                              fontsize=14,rotation=0)","d4fd4c31":"generate_heatmap(df,x_col=\"Q4\",percent1_y_col=\"Q5\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Education\",percent1_y_label=\"Role\",figsize=(16,12),\n                 title=\"Education (completed\/planning) Distribution within each Role\",grouped_col=\"x_col\",\n                 list_x_format=df[\"Q4\"].value_counts().index,list_percent1_y_format=df[\"Q5\"].value_counts().index,\n                 return_df=False)","8f6868f1":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q39\"),\n                              colname=\"Q39\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Sharing Platform\",\n                              title=\"Sharing Platform Distribution of Participants\",\n                              fontsize=14,rotation=0)","83892298":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q42\"),\n                              colname=\"Q42\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Media Sources\",\n                              title=\"Media Sources Distribution of Participants\",\n                              fontsize=14,rotation=0)","4ce2cb1f":"list_msources_order = list(get_count_of_data(df[\"Q42\"]).keys())\ngenerate_heatmap(df,x_col=\"Q42\",percent1_y_col=\"Q5\",palette=list_gradient,show_plot=True,\n                 ticks_fontsize=12,label_fontsize=14,y_rotation=0,x_rotation=90,\n                 x_label=\"Media Sources\",percent1_y_label=\"Role\",figsize=(16,12),\n                 title=\"Media Sources Distribution within each Role\",grouped_col=\"x_col\",\n                 list_x_format=list_msources_order,list_percent1_y_format=df[\"Q5\"].value_counts().index,\n                 return_df=False)","5c4fd2f1":"generate_barplot_with_percent(df=prepare_data_for_bar_plot(df=df,col_name=\"Q40\"),\n                              colname=\"Q40\",gradient=list_gradient,shift=-0.005,\n                              x_label=\"# of Participants\",y_label=\"Platform for DS Courses\",\n                              title=\"Platform for DS Courses Distribution of Participants\",\n                              fontsize=14,rotation=0)","ffbd6986":"I hope you enjoyed this notebook and found something useful for you. Thank you all for reading :) Do let me know your thoughts on this notebook, it will really help me to improve\n\n<center><b>Keep Evolving<\/b><center>","a6bf0c0b":"# <div class=\"subsection_title\">Mark 3.3 Yearly Compensation<\/div>\n\n- Early Note for young fellas: In starting of the career one should not be focused on money but I think no one would deny that <b>money is important.<\/b> Trust the process and keep learning.\n\n\n- With that being said, we are all set to explore. Buckle up...","c37a22f1":"- Transformers is being used by participants with varying ML Experience. - That's sounds cool.\n- There's one patch in <i>5-10 years<\/i> for <i>Evolutionary Approaches<\/i>, that's wierd. Which industry is using it ?\n\n- Time for Roles by Algorithms...","5644cada":"- Again comparatively, there's just double (~ 1.89, ~ 2.21) the number of Man to Woman participants in <i>Broadcasting and Military<\/i> industries, respectively.\n\n- While <i>Academics\/Education<\/i> industry has comparatively, more Woman participant than Man participants.\n\n- It would be interesting to see how yearly compensation is distributed within experience \ud83e\udd14","439e0f8a":"- Wowvy!! Second assumption on point. <i>Colab<\/i> followed by <i>Kaggle<\/i> notebooks tops the chart\n\n\n- So if participants more than often use <i>Colab<\/i> followed by <i>Kaggle<\/i> then they might be using laptop as their computing resource. One more reason behind this is our # of participants are more from Student background where having your own high-end system is very rare thing !\n\n\n- So why to make speculation when we can visualise it..","f28a04bf":"- As expected most of them updates themself through Kaggle followed by YouTube and then Blogs.\n- The other expected but worth mentioning behaviour - Research Scientist keep themself updated through Journals. -> it's not bad but it's damn hard !\n\n\nIn case you guys are wondering where to learn from before we join college\/university, then here something you might like...","33bea8f6":"- That red spike in <i>Online Service<\/i> followed by <i>Retail\/Sales<\/i>. Participants working here have 5+ years of ML experience but <5 years experience of coding.\n\n- Wait, I think we forgot one very good correlation to uncover - Industry distribution within each Gender.","04ef6ebb":"- Quite interesting. Having either coding, ML or both experience gets you to six figure mark yearly ! So don't rush, trust the process and sail calmly.\n- Seems like industry is paying more to the ones with ML experience than to the coding experience comparatively, except for few cases like in 90,000-99,999 brakcet.","83c2fd0b":"# <div class=\"subsection_title\">Mark 3.4 Summary<\/div>\n\n- You excited to learn how our participants do things they do so that you can also do ? Let's quickly revies before we move ahead :<b><i>\n    - Rule of thumb: Keep learning and evolving in both coding and ML concepts, but if you are about to start your journey in DS Universe do start with coding before going into ML concepts.\n    - Industries are still adapting the AI era so don't think you are too late. It's never too late to start.\n    - Yearly Compensation increase with time so don't rush for the money during your early career, though it's important to earn something!\n    <\/i><\/b>","e66e4d15":"- Quite interesting, even though we have so many Python users but when you dive deep and see within each language the whole story changes:\n    - Among all users of C and C++, Student use it more than often. -> That's a good sign ? decide yourself \ud83d\ude1c\n    - Among all users of R and SQL, it's more common among <i>Data Scientist and Data Analyst<\/i>. -> No debates please ! Remember they are using Python too but that's what data suggests within each language\n    - Statistician seems to prefer more of R and Julia in their day to day job.\n    - Our <i>Data Scientist<\/i> are awesome. Using R, SQL, Bash, Julia, Python. -> How are they not messing up with syntax \ud83d\ude02 and ruining their life.\n    - All thanks to <i>Software Engineers<\/i> and <i>Students<\/i> aiming to become the same, we have Swift and JavaScript in contest.\n    - <i>Research Scientist<\/i> seems to be fan of MATLAB followed by Julia. -> Needs to explore more but that's what I can observe now.\n\n\n- Let's see which language keeps up it's popularity among various ML experience participants.","fd7ce3fb":"# <div class=\"section_title\">Mark 2.0 Know Your Fellow Mates<\/div>\n\n- Data is like ingredients. Don't you think so ? Same data when used differently can give you dishes of very similar & disimilar tastes. Oopsie! I meant stories and insights \ud83e\udd2d\n\n- Besides, it's always good to know something about whom you are going to meet. So without further ado, let's get introduced with our participants.\n\n\n\n- First thing first, basic number game about the Survey.\n    - Total number of questions (including sub-questions) asked - <b>51<\/b>\n    - Total number of participants - <b>25973<\/b>\n","eeca3455":"# <div class=\"subsection_title\">Mark 5.4 Cloud College<\/div>","788f37dc":"# <div class=\"subsection_title\">Mark 5.3 Sources to Update Yourself<\/div>","6d5160ef":"# <div class=\"subsection_title\">Mark 2.1 Deadly combination: Age & Experience<\/div>","4997e126":"- So it's <i>Computers\/Technology & Academics\/Education<\/i> using it. Almost all algos are significantly being used by only these two. Other seems to be still evolving and pacing up. -> Focuse young fellas!\n\n\n- Reinventing the wheel is not good for health. Hence, after looking at algorithms lets look at the frameworks being used to implement those algos","ec8c5015":"- Master's degree tops the chart followed by Bachelor's and then Doctoral -> I was expecting Bachelor's to top the charts because we have too many young fellas. Possible reason:\n    - It list either completed or planning to do and that's where everything changes \ud83d\ude09","3e89035a":"# <div class=\"section_title\">Mark 5.0 Know Where They Learn From<\/div>\n\n- Knowing what you want to learn based on what you want to be is already half job done. Now all you need to do is know from where you have to learn and what things you should follow to get regular updates!\n\n\n- Again following the same line, to know more about DS Universe you have to learn the way they did at the same time keeping yourself updated with latest advancement.\n\nSo why to wait more, let's uncover from where we need to learn and keep ourself updated ...","e5be6796":"- Okay obvious thing first - Matplotlib being more used followed by Seaborn (we have more number of Python participants)\n\n- Interesting stuff - <b>we have participants using <i>Folium, Geoplotlib<\/i> which means few of our participants work on geospatial or geographical related data !!<\/b>","86644e33":"# <div class=\"subsection_title\">Mark 2.4 Summary<\/div>\n\n- Before we get to know what role and industry our DS Universe participants perform and contribute towards, we learned few interesting things about them as an individual:<b><i>\n    - Age is just a number - our participants in 40s and 50s are gearing up just like the ones in 20s and 30s\n    - There are 7 out of Universe participants with age between 18-21 but with 20+ years of coding experience\n    - Though we overall have less woman participants, young females (<30 years) are participating more than male counterparts\n    - There are 3 elite groups that are worth exploring a bit more closely. Don't worry, we should be doing that in Mark 3.1<\/i><\/b>","4d89839b":"# <div class=\"subsection_title\">Mark 3.2 Industry<\/div>\n\n- Before we jump in some good stuff, let's first take an overview of our participants spread across industries.","99cc0036":"- Okay on ligher note let's connect few things we have seen in this Mark 4.3:\n    - Most participants use basic ML algo (Regression,Trees\/Forest,Gradient Boosting) that is implemented very well implemented in Scikit-learn. And since most of our participants also use Python it all connects and makes sense.\n    - For other languages (R, Julia, C++), we already know most of the frameworks works well across languages or other way round is wrapper developed by the language community.\n\n- Hmm, taking all these points into consideration the only correlation worth looking at would be Framework vs Role to see who prefers what ?","b8b617f1":"# <div class=\"section_title\">Mark 6.0 Climax<\/div>\n\nYou cannot make all mistakes by yourself to learn ! You are not Reinforcement Learning agent. So let's learn from our 25K superheroes.","5b5201fb":" - Statistician (most) and Data Analyst (to some extent) are in awe with <i>Shiny<\/i> library. And why not ?\n - As for Data Scientist, <i>Altair, Shiny, Folium and Bokeh<\/i> are some go to library for visualization\n \n \n - With visualizations done it's time to explore more about algorithms being used...","4406fa32":"- Interesting, isn't it ? Comparatively, <i>Data Analyst and Business Analyst<\/i> are more into <i>Decision making<\/i> activities.\n- While it's <i>Research Scientist<\/i> at the helm to advance, optimize and explore new areas for applicaiton of ML.\n- <i>Data and Database Engineer<\/i> tend to work more on Data infrastructure activities.\n- <i>Data Scientist<\/i> are like swiss army knife doing everything by using everything ! I think Data Scientist word needs a bit more explanation or maybe have to categorised otherwise it's becoming an umbrella word \ud83d\ude02 -> Don't you think so ? Please do let me know about this !\n- Lokking at Data Scientist, Machine Learning Engineers thought why we should lag behind -> as as result they are also handling most of the activities in their daily work.\n- How I can forget <i>Statisticians<\/i> working in R and Julia; contributing most in <i>Medical\/Pharmaceutical<\/i> industry - they are among ones who make some critical decision\n\n\nIndustry focus on these activities would shed more light on where they stand. Let's see...","3e7ae068":"# <div class=\"subsection_title\">Mark 2.2 Gender<\/div>\n\n- Having known the age group and experience of our participants let's heads up towards Gender.","171539c0":"# <div class=\"subsection_title\">Mark 4.4 Activity<\/div>\n\n- Time for some observations w.r.t activity. This might tell where our AI era is stands, although we know it's just the beginning...","414e81f7":"# <div class=\"subsection_title\">Mark 4.5 Summary<\/div>\n\n- <b>Except for <i>Academics\/Education<\/i>, more focused on <i>Advancing ML<\/i>, all other industries are optimizing existing ML to either imporve thier product or decision making process.\n- Industries are adapting to the AI era and still in their initial stages to use ML \n- There are works going across all industries to explore new avenues for application of existing ML techniques\n- Both Business Analyst and Data Analyst spend most of their time in decision making process. But the difference is the focus. DAs are more widespread while BAs are focused in Accounting\/Finnace, Marketing\/CRM, and Retail\/Sales\n- Python is most widely used language but with increase in ML Experience participants tend to decrease their Python usage. While Julia and R have the just opposite trend from thier user base\n<\/b>","970647f9":"- Haven't seen last year trend but even without it I can say - not good enough. Let's see it's relation with other features to find some more insights.","7b371d03":"- Regression is making life easier since ages.\n- Good to see that student are exploring all algorithms to some extent. -> Future is good \ud83d\ude09\n- There is path of only very light green on right hand side showing Data Engineer, Statistician and others are not that much into algorithms.\n- Data Scientist, Research Scientist and Machine Learning Engineer are making the most out of these algorithms.\n\n\n- Looking at this I am just imagining what problem statement these guys are solving in their day to day life \ud83e\udd14 we will take this up in <b>Mark 4.4<\/b>. \n\n\nBefore that let's investigate that \"Evolutionary Approach\" point","28734ee3":"# <div class=\"subsection_title\">Mark 6.2 Thinking to recruit from DS Universe<\/div>\n\n- Your organization is looking for decision makers ? -> Hire Data Analyst or Data Scientist\n- Your organization is lookting for decision markers but specifically in Marketing\/CRM\/Accounting\/Finnace ? -> Hire Business Analyst\n- Your organization is looking for someone who can handle data ? -> Hire Data Engineers\n- Your organization is looking to explore new avenues or optimize their ML algos ? -> Hire Data Scientist\n- Your organization is from Medical industry ? -> First choice Statistician followed by Data Scientist\n- Need some specific ML work ? -> Get yourself a Machine Learning Engineer buddy\n- Looking to advance ML ? -> Hire Research Scientist","3f612cbb":"# <div class=\"section_title\">Mark 3.0 Know What They Do<\/div>\n\n- In any team sports, every player is important to win the game but for players it's more easy to contribute when they know their roles. Roles - layout a plan of what they are expected to deliver on any given day.\n- You might have already experienced that on some days we need Iron Man but on other we need Hulk and then there are days when we need Captain America's speech ! Every situtation have different superheroes.\n\n\n- Similarly, in DS Universe having your role defined sets some obvious expectations. Sometimes it also tells you more about what path they would have taken to become who they are now. So why to wait, let's explore ...\n","ce09cf9e":"- Wow, many participants chose not to answer or may be these are Students\/currently unemployed.\n- Most of the work seems to be decision making or a kind of consulting. What fascinates me is <i> \"Build prototypes to explore apply ML to new areas\", \"Do research that advances the state of the art of ML\"<\/i>.\n\n- Managing data infrastructure seems to be experience job. But before we move on, mapping these long activities with short ones:\n    - <b>No Answer Provided :- NAP\n    - Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data :- Data infrastructure activity\n    - Do research that advances the state of the art of machine learning :- Advance ML\n    - Analyze and understand data to influence product or business decisions :- Decision making\n    - Build prototypes to explore applying machine learning to new areas :- Explore new avenues\n    - None of these activities are an important part of my role at work :- None of these\n    - Experimentation and iteration to improve existing ML models :- Improve existing ML\n    - Build and\/or run a machine learning service that operationally improves my product or workflows :- ML to improve product\n    - Other :- Other<\/b>","196f9ae4":"- As data says, <i>No Answer Provided<\/i> comes from total of ~0.91% participants who are either <i>Student<\/i> or <i>Currently not employed<\/i>. --> make sense\n\n- Except for <i>Computer\/Technology<\/i> and <i>Academics\/Education<\/i>, all other fields is dominated by <i>Data Scientist<\/i>. In some industries, <i>Data Analyst<\/i> are also becoming the new normal.\n\n- <b><i>Business Analyst<\/i> are more focused towards <i>Accounting\/Finnace, Marketing\/CRM, and Retail\/Sales<\/i> distinguishing themselves from <i>Data Analyst<\/i> whose role is widesrpead across industries.<\/b>\n\n- With that done, let's see how our 4 elite groups are distributed across industries.","20483e30":"- It's always good to have Master's degree if you are planning to enter DS Universe.\n- In case you are looking to contribute in advancing ML and look cool like Research Scientists then be ready to pursue PhD !\n\nWant to know and learn more from these superheroes, let's see where they post their work...","5e3b66c2":"- <b>What \ud83e\udd2f !! - Students have access to deep learning workstations - I am amazed<\/b> I need a break. Change the topic !!!!\n\n\n- Okay, that's not something to shocked so much. But let's move on to the tools our superheroes are using in their life","cac46aba":"# <div class=\"subsection_title\">Mark 5.1 Formal Education<\/div>","79bb5dd9":"- Based on ML Experience, we can observe three patterns:\n    - Participants with <b>0-3<\/b> years of experience:\n        - Most of them come from either Africa (Uganda, Kenya, Nigeria), South Asia (Sri Lanka, Nepal, India and others) or Veit Nam.\n        - Countries like Canada, USA, and western Europe countries have least young participants.\n    - Participants with <b>3-5<\/b> years of experience:\n        - Most of them reside in western and nothern Europe countries. Just opposite of what we saw in 0-3 years of experience.\n        - Least # of participants with experience b\/w 3-5 years come from African countries.\n    - Participants with <b>5+<\/b> years of experience:\n        - Again most of them resides in European countries or from USA or Australia.\n        - While just the opposite of 0-3 years ML experience, least number of participants in the this experience bracket comes from African or South Asian countries\n        \n\n- The above observation implies two things (my assumption):\n    - It can be the case that European and North American countries adapted the AI era before African and South Asia.\n    - Countries that now have less experienced ML participants are pacing up for AI era.\n    \n    \n- Overall it's good to see that participant from all age group and experience are coming together to build this DS Universe, taking it to the new heights.","67cc1f53":"# <div class=\"subsection_title\">Mark 4.1 Language<\/div>\n\n- Lets's start with languages !!!!","4dc2227c":"- Hmm, that looks pretty amazing ! Though Woman participants are significantly less compared to Man participants, but the amazing stuff is:\n    <center><b>Number of <i>Woman<\/i> participants are more in the age bracket <i>18-30<\/i> than <i>Man<\/i> participants.<\/b><\/center>\n\n\n\n- Expect Woman participants to be more than Man participant for 30-40 age group in coming years. Because, for now Man participants are marginally more than Woman participants in the same bracket.\n\n<b><u>Note:<\/u><\/b> Sum of percentage across Gender is equal to 1.","22b0fa68":"# <div class=\"subsection_title\">Mark 6.3 Getting bored in DS Universe<\/div>\n\n- Learn advance ML algos (GNN, RL, Transformers, Evolutionary Approaches)\n- Start posting your insights using available data on Kaggle, GitHub or even personal blogs.","c02f1778":"- That's nice. If most of our participants are using <i>Laptop, Desktop<\/i> followed by <i>Cloud Computing<\/i> and then working on hosted notebooks then:\n    - I think our young fellas don't need to buy heavy end systems. All they need is a laptop on which they can open web browser and type using keyboard \ud83d\ude1c -> Just kidding\n    \n- Let's see for fun which profession tend to use what computing resource...","23225898":"- Something that everyone can notice or is good to assume beforehand:\n    - A strong correlation between coding experience and ML experience.\n    - The upper right corner showing - one can have 10+ years of coding experience and still be new to ML world.\n    - Following that, as depicted in the plot it's always good to start with coding and then move towards ML concepts. --> Makes life easier \ud83d\ude09 \n\n\n- Wait, did you saw what I saw ? The lower left hand-side corner -- there are individuals with less than 5 years of coding experience but with 5+ year of ML experience (approx ~96 individuals). They must be having strong theoretical skills \ud83e\udd14\n\n\n- In case anyone is curious, here's a summary (later called <b>Elite Group<\/b>*):\n    - Ones with < 5 years of coding and > 5 years of ML experience = 96 --> <b>ML Experience Group<\/b>\n    - Ones with > 5 years of coding and < 5 years of ML experience = 3459 --> <b>Coding Experience Group<\/b>\n    - Ones with > 5 years of coding and > 5 years of ML experience = 1510 --> <b>More ML & Coding Experience Group<\/b>\n    - Ones with < 5 years of coding and < 5 years of ML experience = 5637 --> <b>Low ML & Coding Experience Group<\/b>\n    \n*<font size=2><i>We will take this later in Mark: 3.1<\/i><\/font>\n\n\n\n- Not all would have started coding or ML from their college days (i.e., 21 years). Hence, it would be interesting to see how coding and ML experience is distributed across age groups.","0ef41199":"- Keenly observe <i>Julia, R, SQL and Python<\/i> across ML Experience. As participants gain ML experience and given that participant have already used these four languages in their initial career then:\n    - They are most likely to continue in Julia followed by R, SQL and lastly Python. Confused ?\n        - Look at only <i>Julia<\/i> row. It's usage within the users is almost evenly distributed from <i>Under 1 year<\/i> to <i>10-20 years<\/i>. \n        - Now look at <i>Python<\/i>. The % of users significantly drops when you move beyond 1-2 years of experience. It's user base is more clustered in within 0-2 years of experience.\n\n\n- Moving ahead let's explore which IDE our participants tend to use more.","2ee42f91":"- Wow \ud83d\ude2e. We had so many participants with <2 years of ML experience or even many who are still student and then who are currently unemployed. So this plot goes as expected.\n\n- No further insights from my side, let's see how it correlates with Coding and ML experience using our elite group of 4","da8b3e5a":"- Woah! We are in the right place. Kaggle is where they keep themselves updated. So don't foget to follow your superheroes.\n- Would be interesting to see who follows what ?","a0ad7ceb":"- Since we have lot of young Woman participants (18-30 years; Mark 2.2) and student role being most popular within age bracket 18-24, it's expected that most Student are Woman participants.\n\n- But two more interesting points are:\n    - Comparatively, we have more Woman participant as <i>Data Analyst<\/i> than our Man participants.\n    - <b>Comparatively, there's almost double (~1.7) Man participants as <i>Project Manager or Product Manager<\/i> compared to Woman participants.<\/b>\n\n\n- Having explored our role, let's explore few stuff regarding the <b>industry<\/b> these superheroes are revolutionizing.","dc8efbbd":"- That's an interesting plot using the 4 elite groups we discussed before in <b>Mark 2.1<\/b>\n<center><i>Let the data speak for itself !<\/i><\/center>\n\n\n- <i>Data Scientist, Research Scientist, and Statistician<\/i> tend to have more experience in both Coding and ML. --> Something useful for our young fellas.\n\n\n- We have less participants as <i>Software Engineer<\/i> having ML experience >5 years and coding experience <5 years. Otherway round, we have more Software Engineer participants with >5 years of coding experience and some hands on ML concepts. --> They are evolving !\n\n\n- Anyone finds the <i>Machine Learning Engineer<\/i> column interestingly weird ? Here's something:\n    - There are less ML Engineers with coding experience of <5 years and ML experience >5 years.\n    - Most of ML Engineers have both coding and ML experience >5 years (depicted in Yellow line).\n    - While the Green line shows we have batch of ML Engineers with both coding and ML experience <5 years. They are warming up before they can conquer this Universe.\n    \n  \n<b>Rule of thumb: You need both coding and ML concepts to survive in DS Universe. However, as we have seen before: start with coding and then ML concepts.<\/b>\n\n\n- A quite interesting one to note here is <i>Business Analyst<\/i>:\n    - There are quite a number of participants with 5+ years of ML experience and <5 years of coding experience.\n    - And guess what they have least participants with 5+ years of experience in both coding and ML.\n    - Might be due to (my assumption):\n        - <b><i>Latest trend set by AutoML like techniques<\/i><\/b> - it gets most of the coding part done for you. All you need to have is some ML experience to decide what model to be used and then decipher the results. \n\n\n- Expectation from <i>Data Engineer<\/i> is to prepare the data for analytical use. Ideally, you should have experience in both but having either ML experience or coding experience gives you a reason to survive. --Something well depicted in the plot.\n\n\n- Finally did you notice the <i>green line<\/i> ? They have <5 years experience in both coding and ML. They must be our young fellas. It would be interesting to see their role distribution across age groups.\n\n\n<b><u>Note<\/u><\/b>: That's too much information to get in one go. Apologies audience couldn't resist my inner self...","b85f17e2":"- Really \ud83e\udd2f many of our participant don't share their work. That's a bad news but we have other way round. We can learn from the same source they prefer to learn and follow","214f18ad":"- Wowvy, the obvious choice tops the chart - <i>Jupyter IDE<\/i> followed by <i>VSCode<\/i>.\n\n- Nothing much to say. Let's move ahead to hosted notebook category","ad36e8e3":"- Decision making is important across all industries -> make sense\n- <b>Except for <i>Academics\/Education<\/i>, more focused on <i>Advancing ML<\/i>, all other industries are optimizing existing ML to either imporve thier product or decision making process.\n- AI has not been used by any industry to it's full potential. And that's what figure shows too and it's never too late!<\/b>\n\nWith that being said, would be interesting to see if participants from any experience brakcet can do all stuff or you need some experience before you jump-in ?","d42b1088":"- Well depicted plot, keep it up! The ones with <5 years of experience in both coding and ML are young (18-35) --> <i>That proves the rule of thumb.<\/i>\n\n- Let's head towards seeing how roles are distributed within each gender.","06f05b09":"- We have quite a good amount of students as our participants. This should not come as an unexpected observation, as most (~36%) of our participants are between 18-24.\n\n- Hmm, Software Engineers second to Data Scientist as top roles of our participants. Would be interesting to see ML experience vs Coding experience of our almighty superheroes.","a35f2349":"- Before we go further, let me draw your attention to this:\n    - Approx ~0.15% participants in each industry don't use machine learning methods\n    - Industries are still adapting to the AI era and that's why we see participants with <3 years as most in numbers.","d67bb98f":"- ","44fb7902":"- Participants from all ML experience group are involved in decision making process -> it's seems that vital\n- <i>Advancing ML<\/i> seems to be reserved for the ones with 4+ ML experience -> make sense\n- Exploring new avenues is application of existing ML methods and that's why we see participants from all ML experience background contributing towards it.\n- The same applies for using ML to either imporve itself or the product.\n\n\nNow, I am really getting excited to see where these guys most learn and interact -> how awesome those places would be \ud83e\udd29\n","d15d382c":"- Seems like \"Gen Z\" is coming in numbers (approx ~55% below age 30).\n- But what about the ones with 60+ ? Like how much edge cases they would have dealt with. And what about the experiences and stories they would have to tell. <b>Just imagine fellas !!<\/b>\n- Proving \"<i>age is just a number<\/i>\", let's go further and look at the experience our participants bring to the table.","39c98c76":"- Oh, so many Python lovers ! Glad to see SQL followed by C++ and then R. Was expecting Julia too but it tops from bottom \ud83d\ude1c\n\n- Let's see who uses what ?","eeea366f":"# <div class=\"section_title\">Mark 4.0 Know How They Do<\/div>\n\n- Knowing who you are and what your role is gives you a glimpse of your future self. But it's all planning stuff. It's only your execution that will tell how good your planning was.\n\n- Also, you might find N number of paths to same destination but you always take the path that increases your chances to be the future self you want to be!\n\n\n- Following the same line, learning who your fellow mates are and what they do is just tip of iceberg to understand or to settle in this DS Universe. To know them more you need to interact with them. And the easiest way would be to learn how they do the way they do.\n\nSo why to wait more, let's uncover what needs to be learned ...","8b54e14d":"# <div class=\"subsection_title\">Mark 6.4 Closing Comments<\/div>\n\n- Don't you foget the rule of thumb.\n- It's never too late to start. Industries are still adapting\n- Always start with basic algos (Regression,Trees\/Forest) before jumping onto advance concepts\n    \n","a1403d37":"# <div class=\"subsection_title\">Mark 2.3 Country<\/div>\n\n- After unveiling some awesome trends in Age, Experience and Gender, let's see what Country holds for us...","07da51af":"# <div class=\"subsection_title\">Mark 3.1 Role<\/div>","06213181":"- Did you noticed that ? <b>There are participants who are in age group of 18-21 and have coding experience more than 20 years \ud83e\udd2f<\/b> They must be <i> Abhimanyu <\/i> from Mahabharata (an epic of ancient India).\n\n- All and all, youngester are learning this awesome skill called coding and there's a clear trend of increase in coding experience with that of age except those weird fellas.\n\n- Time for the plot with ML experience.","c352bc60":"- Most of them have chosen not to answer - I totally respect their privacy. But can they the ones who are currently either not employed or student ? A question to be answered in coming viz. Till then stay tuned \ud83d\ude09\n\n- <i>Hospitality\/Entertainment\/Sports<\/i> have least number of participants followed by <i>Military\/Security\/Defense<\/i>. Where are you Netflix and Prime developers ? we are lagging behind \ud83d\ude1c - Just kidding.\n\n- <i>Computer\/Technology<\/i> leading their way followed by <i>Academics\/Education<\/i> and then <i>Accounting\/Finance<\/i>.\n\n- Let's move ahead...","1789f88c":"# <div class=\"subsection_title\">Mark 4.3 Frameworks, Algorithms, & Libraries<\/div>\n\n- Before developing a model we try to understand data with some visualization. Similarly, firstly we will explore visualization tools before seeing the ML frameworks being used by our participants.","9fa80a69":"- By now you might have accepted that <i>Data Scientist<\/i> use everything to get their job done \ud83d\ude1c\n- Given <i>Statistician<\/i> use more R and then more of <i>Shiny<\/i> for visualization it's expected for them to use <i>Tidymodels<\/i>\n\n\n\nGetting bored. TBH, I AM !!\nLet's spice things up with the kind of problem statements our superheroes solve in their daya to day work","664c4e69":"- OKAY OKAY! These exceptionally intelligent Gen Z participants between 18-21 years with either 20+ years of coding experience or ML experience are driving me crazy. I would be looking at them with close lens later on. <i>For now dropping them for downstream analysis.<\/i>\n\n\n- Let me bring something good to your notice: <i> column with \"Under 1 year\" ML Experience on x-axis<\/i>. This column has the highest percent of individuals across age groups showing us:\n<center><b>Irrespective of age more and more people are pacing up their ML skills \ud83d\ude09 <\/b><\/center>","00336ae7":"# <div class=\"subsection_title\">Mark 6.1 Thinking to enter in DS Universe<\/div>\n\n- Follow the rule of thumb: make yourself comfortable in coding and then start your journey in AI\/ML\/DS\n- Python, R and Julia are awesome but try to start from C followed by either Java or C++ and then any language of your choice\n- Get yourself exposure by following some Kaggle profile notebooks or doing it yourself\n- Start following some good YouTube channels, Kaggle profile or blogs.\n- Don't rush behind yearly compensation or title, trust the process and kepp evolving.\n- Learn visualization tools because it's good if you can code or present but if you can do both you will be unstopable\n- Choose your industry wisely. Domain knowledge makes your day easier.\n- There are always resources to learn stuff. Don't be limited by your physical location\n\n\nSpecifics\n- If you are planning to go into Medical industry then do yourself a favour learn R or Julia.\n- If you are looking to contribute towards advancing ML then be ready to pursue PhD\n- If you are Woman, it doesn't matter ! I repeat it never matters","391cc4ce":"- Crux is you can learn without going to any college\/university. All you need is a laptop !\n\nWe have reached the climax! Time for some key takeaways...","3afa8110":"# <div class=\"subsection_title\">Mark 4.2 IDE, Hosted Notebooks, & Computing Platform<\/div>\n\n- Assumption before we dive in:\n    - Since most of our participants use Python obvious choice would go to Jupyter\n    - With Jupyter extension available in VSCode who knows it might to the list because that IDE is most loved by Software Engineers (atleast the ones with whom I interacted)\n    - Colab and Kaggle Notebook should be among the top in hosted notebook category.\n    \n    \n- That's all I had as my assumptions. Let's see how it turns out..","73974acf":"# <div class=\"top_section\">Mark 1.0 Inception<\/div>\n\n- Hello world! In this notebook we are going to analyze Data Science Universe (DSU) in the year 2021 and will try to learn from the paths other have embarked upon. \n\n\n- To start with, I tried to imagine how a reviewer will assess the situation of being introduced to a new Universe, asking some basic but relevant questions to uncover some key aspects:\n    - Who are your fellow mates ?\n    - What your fellow mates do in their life ?\n    - How they accomplish their day to day task - like the tools and steps they take up in their role\n    - Where they learn from, share and keep themselves updated with trending skills ?\n    - Key takeaways from different perspectives !\n\n\n- Hope you enjoy the journey of exploring this awesome DS Universe...\n\n\n<b><u>Note:<\/u><\/b> All analysis done is based on observations collected as a part of <a href=\"https:\/\/www.kaggle.com\/c\/kaggle-survey-2021\/overview\">2021 Kaggle Machine Learning & Data Science Survey<\/a>.","b191dbf2":"# <div class=\"subsection_title\">Mark 5.2 Platform to Share Your Insights<\/div>","34038444":"- Linear or Logistic Regression forms base of modern day neural network. Hence, anyone who is having some ML experience would have surely worked on this algorithm. -> And data proves it\n- Besides, Deision Trees, Random Forest, Gradient Boosting Algos and DNNs are some basic algorithms that we would have expected to pop out !\n- What intrigues me more are the participants using CNN, RNN, Transformers - let's do some deep dive:\n    - Who they are ? - Role and ML Experience\n    - In which industry they are using it ?"}}