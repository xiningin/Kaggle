{"cell_type":{"8e24213a":"code","78290698":"code","9a2bd699":"code","4a98cb72":"code","3f2f2bb0":"code","5bc89cd1":"code","f5ad883f":"code","4224bbcb":"code","95736db8":"code","dae4fe61":"code","45b32a7d":"code","d300e9ba":"code","7046c371":"code","5894da83":"code","9cd2e260":"code","6ba6525a":"code","4026d336":"code","760a0b72":"code","d3474098":"code","01eab3e7":"code","65776696":"code","82dfe851":"code","6913c292":"code","192bfcb9":"code","1b25cfb9":"code","8e293ff1":"code","c34c98e0":"code","4ca4b697":"code","ac0fb778":"code","a5cb4d0f":"code","3e554050":"code","d266bc66":"code","a9f8dd93":"code","ed5722d0":"code","77575b90":"code","cf1c6291":"code","00baf9b9":"code","4e1646cb":"code","87f98800":"code","f81f4d5a":"code","663f9b4d":"code","d40c834f":"code","40898310":"code","92f38efa":"code","497b84ed":"code","ebb43420":"code","6fcb32f1":"code","fd7fabba":"code","2041921a":"code","9298b641":"code","84857770":"code","654c667b":"code","e2d5ae98":"code","b20a03f7":"code","ca488412":"code","279ffe0f":"code","8ae22cad":"markdown","8d096de1":"markdown","dc01e984":"markdown","84ebc46c":"markdown","67150355":"markdown","ad8d9c4d":"markdown","acfd5272":"markdown","9629c0fc":"markdown","68646f98":"markdown","72a4e100":"markdown","7b6d8276":"markdown","8569173b":"markdown","07edac6c":"markdown","1e791eb2":"markdown","f4aa7321":"markdown","ed43593d":"markdown","a616563f":"markdown","9a07a38a":"markdown","e0303b7c":"markdown","c4b516f3":"markdown","3a0c9294":"markdown","3c032956":"markdown","1ec0cb6d":"markdown","266ff8fd":"markdown","79eccefb":"markdown","0f2c4621":"markdown","888b3104":"markdown","59bac4bf":"markdown","bacaba0d":"markdown","6c712845":"markdown","477e444f":"markdown","e4b33bec":"markdown","a2838e54":"markdown","885da368":"markdown","f9eb698f":"markdown","d251f888":"markdown","9d1d82fa":"markdown","3ead479a":"markdown","8ab806b8":"markdown","92ce9c68":"markdown","032aa2c4":"markdown","e0ee16dd":"markdown","71937dc9":"markdown","ac5e660e":"markdown","55ba5131":"markdown","49dc4f0d":"markdown","523a3823":"markdown","8f7042a2":"markdown","a47e7897":"markdown","fdd01a8f":"markdown","e81076e5":"markdown","f20409df":"markdown"},"source":{"8e24213a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nimport xgboost as xgb\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline","78290698":"dados = pd.read_csv('\/kaggle\/input\/data-train-secitec-ifg\/treino.csv')\ndados.info()","9a2bd699":"teste = pd.read_csv('\/kaggle\/input\/data-train-secitec-ifg\/teste.csv')\nteste.info()","4a98cb72":"submissao = pd.read_csv('\/kaggle\/input\/data-train-secitec-ifg\/submission.csv')\nsubmissao.info()","3f2f2bb0":"dados.head()","5bc89cd1":"dados['apgar1'].value_counts(dropna=False).sort_index()","f5ad883f":"dados['apgar5'].value_counts(dropna=False).sort_index()","4224bbcb":"fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n\nfor name, ax in zip(['apgar1', 'apgar5'], axes):\n    ax.hist(dados[name])\n    ax.set_title(f'APGAR ({name[-1]}\u00ba segundo)')\n\nfig.show();","95736db8":"cat_features = ['estadocivilmae', 'catprenatal', 'tipoparto', 'malformacao', 'sexo', 'obito']\n\nfig, axes = plt.subplots(2, 3, figsize=(24, 16), sharey=True, gridspec_kw={'wspace': .05, 'hspace': .18})\n\naxes = axes.ravel()\n\nfor name, ax in zip(cat_features, axes):\n    \n    counts = dados[name].value_counts(dropna=False)\n    ax.bar(counts.index.astype(str), counts)\n    ax.set_title(name, fontname='Times New Roman', fontweight='bold')\n    ax.set_axisbelow(True)\n    \n    for x, y in enumerate(counts):\n        ax.text(x=x, y=y+100, s=str(y), horizontalalignment='center')\n\nfig.show();","dae4fe61":"num_features = ['idademae', 'qtdsemanas', 'peso']\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), sharey=True)\n\nfor name, ax in zip(num_features, axes):\n    ax.hist(dados[name], bins=20)\n    ax.set_title(name, fontname='Times New Roman', fontweight='bold')\n\nfig.show();","45b32a7d":"# temos NaN?\ndados[num_features].isna().sum()","d300e9ba":"pd.DataFrame(dados[num_features].describe()).T","7046c371":"dados.head()","5894da83":"# propor\u00e7\u00e3o de NaN\ndados[['estadocivilmae', 'tipoparto', 'malformacao', 'sexo']].isnull().sum() \/ dados.shape[0]","9cd2e260":"dados['estadocivilmae'].value_counts(dropna=False)","6ba6525a":"# transformando estadocivilmae\ndados = dados.assign(**pd.get_dummies(dados['estadocivilmae'], prefix='estadocivil'))\ndados.head()","4026d336":"# transformando sexo\ndados['binario_sexo'] = dados['sexo'].map({'f': 0, 'm': 1}, na_action='ignore')\ndados.head()","760a0b72":"# transformando tipoparto\ndados['binario_tipoparto'] = dados['tipoparto'].map({'vaginal': 0, 'cesareo': 1}, na_action='ignore')\ndados.head()","d3474098":"# transformando malformacao\ndados['binario_malformacao'] = dados['malformacao'].map({'nao': 0, 'sim': 1}, na_action='ignore')\ndados.head()","01eab3e7":"dados['ord_catprenatal'] = dados['catprenatal'].map({'nenhuma': 0, 'de1a3': 1, 'de4a6': 2, '7mais': 3}, na_action='ignore')\ndados.head()","65776696":"import seaborn as sns\n\nsns.boxplot(data=dados, x='obito', y='idademae');","82dfe851":"sns.boxplot(data=dados, x='obito', y='qtdsemanas');","6913c292":"sns.boxplot(data=dados, x='obito', y='peso');","192bfcb9":"# temos pouqu\u00edssima observa\u00e7\u00f5es de \"vi\u00favas\", ent\u00e3o vou eliminar essa feature\n# separando X e y\nX = dados.drop(['id', 'estadocivilmae', 'catprenatal', 'tipoparto', 'sexo', 'malformacao', 'obito', 'estadocivil_viuva'], axis=1)\ny = dados['obito']\n\nX.head()","1b25cfb9":"# relembrando quantidade de NaN para cada coluna\nX.isnull().sum()","8e293ff1":"from sklearn.model_selection import StratifiedKFold\n\nfor tr, val in StratifiedKFold(n_splits=5, shuffle=True, random_state=0).split(X, y):\n    \n    y_train, y_val = y.iloc[tr], y.iloc[val]\n    \n    print('\u00cdndices treino:', tr, '-> \u00cdndices valida\u00e7\u00e3o:', val)\n    print('Porcentagem obito = 1 (treino):', len(y_train[y_train == 1]) \/ len(y_train), 'Porcentagem obito = 0 (treino):', len(y_train[y_train == 0]) \/ len(y_train))\n    print('Porcentagem obito = 1 (val):', len(y_val[y_val == 1]) \/ len(y_val), 'Porcentagem obito = 0 (val):', len(y_val[y_val == 0]) \/ len(y_val))\n    print()\n    \n    # esta linha verifica se exista alguma intersec\u00e7\u00e3o entre os valores de treino e teste\n    assert len(list(set(tr) & set(val))) == 0","c34c98e0":"from sklearn.model_selection import KFold\n\nfor tr, val in KFold(n_splits=5, shuffle=True, random_state=0).split(X, y):\n    \n    y_train, y_val = y.iloc[tr], y.iloc[val]\n    \n    print('\u00cdndices treino:', tr, '-> \u00cdndices valida\u00e7\u00e3o:', val)\n    print('Porcentagem obito = 1 (treino):', len(y_train[y_train == 1]) \/ len(y_train), 'Porcentagem obito = 0 (treino):', len(y_train[y_train == 0]) \/ len(y_train))\n    print('Porcentagem obito = 1 (val):', len(y_val[y_val == 1]) \/ len(y_val), 'Porcentagem obito = 0 (val):', len(y_val[y_val == 0]) \/ len(y_val))\n    print()\n    \n    # esta linha verifica se exista alguma intersec\u00e7\u00e3o entre os valores de treino e teste\n    assert len(list(set(tr) & set(val))) == 0","4ca4b697":"# propor\u00e7\u00e3o das classes na target\ny.value_counts() \/ len(y)","ac0fb778":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, brier_score_loss, log_loss, confusion_matrix\nfrom sklearn.calibration import calibration_curve\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom lightgbm import LGBMClassifier\n\n\nauc_treino = []\nauc_validacao = []\nacc_treino = []\nacc_validacao = []\nlogloss_treino = []\nlogloss_validacao = []\n\n\nkf = KFold(n_splits=5, shuffle=True, random_state=0)\n\nfor tr, val in kf.split(X, y):\n    \n    # splita em treino\/valida\u00e7\u00e3o\n    X_train, X_val = X.iloc[tr], X.iloc[val]\n    y_train, y_val = y.iloc[tr], y.iloc[val]    \n    \n    \n    # imputando NaN para dados de treino e valida\u00e7\u00e3o usando a m\u00e9dia\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n    \n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_val[col] = X_val[col].fillna(X_val[col].mean())  \n    \n    \n    # treina nos folds de treino\n    clf = xgb.XGBClassifier(random_state=1, missing=np.nan)\n    clf.fit(X_train, y_train)\n    \n    # calcula probabilidades para treino e valida\u00e7\u00e3o\n    # pega segunda coluna: P(Y = 1)\n    prob_tr = clf.predict_proba(X_train)[:, 1]\n    prob_val = clf.predict_proba(X_val)[:, 1]\n    \n    # calcula AUC\n    auc_tr = roc_auc_score(y_train, prob_tr)\n    auc_val = roc_auc_score(y_val, prob_val)\n    \n    # calcula acur\u00e1cia\n    acc_tr = accuracy_score(y_train, (prob_tr > .5).astype(int))\n    acc_val = accuracy_score(y_val, (prob_val > .5).astype(int))\n    \n    # calcula log-loss\n    logloss_tr = log_loss(y_train, prob_tr)\n    logloss_val = log_loss(y_val, prob_val)\n    \n    # guarda resultados\n    auc_treino.append(auc_tr)\n    auc_validacao.append(auc_val)\n    acc_treino.append(acc_tr)\n    acc_validacao.append(acc_val)\n    logloss_treino.append(logloss_tr)\n    logloss_validacao.append(logloss_val)\n    \n    print('AUC (treino):', auc_tr, ' AUC (val):', auc_val)\n    print('Acur\u00e1cia (treino):', acc_tr, ' Acur\u00e1cia (val):', acc_val)\n    print('Log loss (treino):', logloss_tr, 'Log loss (val):', logloss_val)\n    print()\n    \n    \nprint('M\u00e9dia AUC (treino):', np.mean(auc_treino))\nprint('M\u00e9dia AUC (val):', np.mean(auc_validacao))\nprint('M\u00e9dia Acur\u00e1cia (treino):', np.mean(acc_treino))\nprint('M\u00e9dia Acur\u00e1cia (val):', np.mean(acc_validacao))\nprint('M\u00e9dia Log-loss (treino):', np.mean(logloss_treino))\nprint('M\u00e9dia Log-loss (val):', np.mean(logloss_validacao))","a5cb4d0f":"auc_treino = []\nauc_validacao = []\nacc_treino = []\nacc_validacao = []\nlogloss_treino = []\nlogloss_validacao = []\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n\nfor tr, val in skf.split(X, y):\n    \n    # splita em treino\/valida\u00e7\u00e3o\n    X_train, X_val = X.iloc[tr], X.iloc[val]\n    y_train, y_val = y.iloc[tr], y.iloc[val]    \n    \n    \n    # imputando NaN para dados de treino e valida\u00e7\u00e3o usando a m\u00e9dia\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n    \n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_val[col] = X_val[col].fillna(X_val[col].mean()) \n    \n    \n    # treina nos folds de treino\n    clf = xgb.XGBClassifier(random_state=1, missing=np.nan)\n    clf.fit(X_train, y_train)\n    \n    # calcula probabilidades para treino e valida\u00e7\u00e3o\n    # pega segunda coluna: P(Y = 1)\n    prob_tr = clf.predict_proba(X_train)[:, 1]\n    prob_val = clf.predict_proba(X_val)[:, 1]\n    \n    # calcula AUC\n    auc_tr = roc_auc_score(y_train, prob_tr)\n    auc_val = roc_auc_score(y_val, prob_val)\n    \n    # calcula acur\u00e1cia\n    acc_tr = accuracy_score(y_train, (prob_tr > .5).astype(int))\n    acc_val = accuracy_score(y_val, (prob_val > .5).astype(int))\n    \n    # calcula log-loss\n    logloss_tr = log_loss(y_train, prob_tr)\n    logloss_val = log_loss(y_val, prob_val)\n    \n    # guarda resultados\n    auc_treino.append(auc_tr)\n    auc_validacao.append(auc_val)\n    acc_treino.append(acc_tr)\n    acc_validacao.append(acc_val)\n    logloss_treino.append(logloss_tr)\n    logloss_validacao.append(logloss_val)\n    \n    print('AUC (treino):', auc_tr, ' AUC (val):', auc_val)\n    print('Acur\u00e1cia (treino):', acc_tr, ' Acur\u00e1cia (val):', acc_val)\n    print('Log loss (treino):', logloss_tr, 'Log loss (val):', logloss_val)\n    print()\n    \n    \nprint('M\u00e9dia AUC (treino):', np.mean(auc_treino))\nprint('M\u00e9dia AUC (val):', np.mean(auc_validacao))\nprint('M\u00e9dia Acur\u00e1cia (treino):', np.mean(acc_treino))\nprint('M\u00e9dia Acur\u00e1cia (val):', np.mean(acc_validacao))\nprint('M\u00e9dia Log-loss (treino):', np.mean(logloss_treino))\nprint('M\u00e9dia Log-loss (val):', np.mean(logloss_validacao))","3e554050":"teste.isnull().sum()","d266bc66":"# transformando categ\u00f3ricas nos dados de tete  \nteste = teste.assign(**pd.get_dummies(teste['estadocivilmae'], prefix='estadocivil'))\nteste['binario_sexo'] = teste['sexo'].map({'f': 0, 'm': 1}, na_action='ignore')\nteste['binario_tipoparto'] = teste['tipoparto'].map({'vaginal': 0, 'cesareo': 1}, na_action='ignore')\nteste['binario_malformacao'] = teste['malformacao'].map({'nao': 0, 'sim': 1}, na_action='ignore')\nteste['ord_catprenatal'] = teste['catprenatal'].map({'nenhuma': 0, 'de1a3': 1, 'de4a6': 2, '7mais': 3}, na_action='ignore')\n\nteste.head()","a9f8dd93":"teste.isnull().sum()","ed5722d0":"def gera_submissao():\n    \n    # guarda ids\n    sub = teste.copy()\n    ids = sub['id']\n    \n    # dropa colunas n\u00e3o utilizadas pelo modelo\n    sub = sub.drop(['id', 'estadocivilmae', 'catprenatal', 'tipoparto', 'sexo', 'malformacao', 'estadocivil_viuva'], axis=1)\n\n    # imputando NaN\n    # for col in ['idademae', 'qtdsemanas', 'apgar1', 'apgar5']:\n    #    sub[col] = sub[col].fillna(sub[col].mean())\n    \n    \n    # treina nos dados completos\n    X_train = X.copy()\n    y_train = y.copy()\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n    \n    clf = xgb.XGBClassifier(random_state=1, missing=np.nan)\n    clf.fit(X_train, y_train)\n    print('Modelo treinado')\n    \n    # gera probabilidades\n    print('Gerando probabilidades...')\n    probs = clf.predict_proba(sub)\n    print(probs)\n    \n    # gerando submiss\u00e3o\n    print('Gerando submiss\u00e3o...')\n    print('OK')\n    \n    return pd.DataFrame({'id': ids, 'obito': probs[:, 1]})  \n    \n    \nsub1 = gera_submissao()","77575b90":"sub1.to_csv('sub1_xgboost_sem_tunning_missing_np.nan_sem_imputer.csv', index=False)","cf1c6291":"X['qtdsemanas'].value_counts(dropna=False).sort_index()","00baf9b9":"# qual a probabilidade de escolher um obito=1 na amostra?\nprob_obito = len(y[y == 1]) \/ len(y)\nprob_obito","4e1646cb":"from itertools import permutations\n\n\n# fun\u00e7\u00e3o para calcular probabilidades condicionais\ndef gera_probabilidades(dataset):\n    \n    # criando permuta\u00e7\u00f5es:\n    # [0, 0]\n    # [0, 1]\n    # ...\n    # [0, 10]\n    # [1, 0]\n    # [1, 1]\n    # ....\n    # [1, 10]\n    # ...\n\n    primeira_combinacao = [(0, 0)]\n    ultima_combinacao = [(10, 10)]\n    permutacoes = list(permutations(range(0, 11), 2))\n    permutacoes = primeira_combinacao + permutacoes + ultima_combinacao\n    \n    \n    # cria mapa da probabilidades\n    # vamos nos basear nos dados completos, porque em dados de teste n\u00e3o temos a informa\u00e7\u00e3o de obito\n    # ou seja, n\u00e3o \u00e9 poss\u00edvel calcular a probabilidade l\u00e1\n    mapa_probs_obito = dict()\n    for a1, a5 in permutacoes:\n        prob_numerador = ((dados['obito'] == 1) & (dados['apgar1'] == a1) & (dados['apgar5'] == a5)).sum()\n        prob_denominador = ((dados['apgar1'] == a1) & (dados['apgar5'] == a5)).sum()\n        prob = prob_numerador \/ prob_denominador\n\n        mapa_probs_obito[str(a1)+str(a5)] = prob        \n        \n    # mapeia com o dataset  \n    probs_features = np.zeros((len(dataset), 1))\n    for i, (a1, a5) in enumerate(dataset[['apgar1', 'apgar5']].values):\n\n        if pd.isna(a1) or pd.isna(a5):\n            probs_features[i, 0] = 0.5\n        else:\n            probs_features[i, 0] = mapa_probs_obito.get(str(int(a1))+str(int(a5)), 0.5)\n        \n    for i in range(len(probs_features)):\n        if pd.isna(probs_features[i, 0]):\n            probs_features[i, 0] = np.nan            \n            \n    prob_obito = (dados['obito'] == 1).sum() \/ len(dados) \n            \n    return probs_features \/ prob_obito","87f98800":"gera_probabilidades(X)","f81f4d5a":"X.isnull().sum()","663f9b4d":"auc_treino = []\nauc_validacao = []\nacc_treino = []\nacc_validacao = []\nlogloss_treino = []\nlogloss_validacao = []\n\nfor tr, val in kf.split(X, y):\n    \n    # splita em treino\/valida\u00e7\u00e3o    \n    X_train, X_val = X.iloc[tr], X.iloc[val]\n    y_train, y_val = y.iloc[tr], y.iloc[val]\n    \n    X_train['prematuro'] = np.where(X_train['qtdsemanas'] < 37, 1, 0)\n    X_train['pos_termo'] = np.where(X_train['qtdsemanas'] > 42, 1, 0)\n    X_train['probs'] = gera_probabilidades(X_train)\n\n    X_val['prematuro'] = np.where(X_val['qtdsemanas'] < 37, 1, 0)\n    X_val['pos_termo'] = np.where(X_val['qtdsemanas'] > 42, 1, 0)\n    X_val['probs'] = gera_probabilidades(X_val)\n    \n        \n    # imputando NaN para dados de treino e valida\u00e7\u00e3o usando a m\u00e9dia\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n        \n\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_val[col] = X_val[col].fillna(X_val[col].mean())\n       \n    # treina nos folds de treino\n    clf = xgb.XGBClassifier(random_state=1, missing=np.nan)\n    clf.fit(X_train, y_train)\n    \n    # calcula probabilidades para treino e valida\u00e7\u00e3o\n    # pega segunda coluna: P(Y = 1)\n    prob_tr = clf.predict_proba(X_train)[:, 1]\n    prob_val = clf.predict_proba(X_val)[:, 1]\n    \n    # calcula AUC\n    auc_tr = roc_auc_score(y_train, prob_tr)\n    auc_val = roc_auc_score(y_val, prob_val)\n    \n    # calcula acur\u00e1cia\n    acc_tr = accuracy_score(y_train, (prob_tr > .5).astype(int))\n    acc_val = accuracy_score(y_val, (prob_val > .5).astype(int))\n    \n    # calcula log-loss\n    logloss_tr = log_loss(y_train, prob_tr)\n    logloss_val = log_loss(y_val, prob_val)\n    \n    # guarda resultados\n    auc_treino.append(auc_tr)\n    auc_validacao.append(auc_val)\n    acc_treino.append(acc_tr)\n    acc_validacao.append(acc_val)\n    logloss_treino.append(logloss_tr)\n    logloss_validacao.append(logloss_val)\n    \n    print('AUC (treino):', auc_tr, ' AUC (val):', auc_val)\n    print('Acur\u00e1cia (treino):', acc_tr, ' Acur\u00e1cia (val):', acc_val)\n    print('Log loss (treino):', logloss_tr, 'Log loss (val):', logloss_val)\n    print()\n    \nprint('M\u00e9dia AUC (treino):', np.mean(auc_treino))\nprint('M\u00e9dia AUC (val):', np.mean(auc_validacao))\nprint('M\u00e9dia Acur\u00e1cia (treino):', np.mean(acc_treino))\nprint('M\u00e9dia Acur\u00e1cia (val):', np.mean(acc_validacao))\nprint('M\u00e9dia Log-loss (treino):', np.mean(logloss_treino))\nprint('M\u00e9dia Log-loss (val):', np.mean(logloss_validacao))","d40c834f":"print(0.9479901533726919 - 0.9478498979926228)","40898310":"auc_treino = []\nauc_validacao = []\nacc_treino = []\nacc_validacao = []\nlogloss_treino = []\nlogloss_validacao = []\n\nfor tr, val in skf.split(X, y):\n    \n    # splita em treino\/valida\u00e7\u00e3o    \n    X_train, X_val = X.iloc[tr], X.iloc[val]\n    y_train, y_val = y.iloc[tr], y.iloc[val]\n    \n    X_train['prematuro'] = np.where(X_train['qtdsemanas'] < 37, 1, 0)\n    X_train['pos_termo'] = np.where(X_train['qtdsemanas'] > 42, 1, 0)\n    X_train['probs'] = gera_probabilidades(X_train)\n\n    X_val['prematuro'] = np.where(X_val['qtdsemanas'] < 37, 1, 0)\n    X_val['pos_termo'] = np.where(X_val['qtdsemanas'] > 42, 1, 0)\n    X_val['probs'] = gera_probabilidades(X_val)\n    \n    \n    # imputando NaN para dados de treino e valida\u00e7\u00e3o usando a m\u00e9dia\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_val[col] = X_val[col].fillna(X_val[col].mean())\n\n    \n    # treina nos folds de treino\n    clf = xgb.XGBClassifier(random_state=1, missing=np.nan)\n    clf.fit(X_train, y_train)\n    \n    # calcula probabilidades para treino e valida\u00e7\u00e3o\n    # pega segunda coluna: P(Y = 1)\n    prob_tr = clf.predict_proba(X_train)[:, 1]\n    prob_val = clf.predict_proba(X_val)[:, 1]\n    \n    # calcula AUC\n    auc_tr = roc_auc_score(y_train, prob_tr)\n    auc_val = roc_auc_score(y_val, prob_val)\n    \n    # calcula acur\u00e1cia\n    acc_tr = accuracy_score(y_train, (prob_tr > .5).astype(int))\n    acc_val = accuracy_score(y_val, (prob_val > .5).astype(int))\n    \n    # calcula log-loss\n    logloss_tr = log_loss(y_train, prob_tr)\n    logloss_val = log_loss(y_val, prob_val)\n    \n    # guarda resultados\n    auc_treino.append(auc_tr)\n    auc_validacao.append(auc_val)\n    acc_treino.append(acc_tr)\n    acc_validacao.append(acc_val)\n    logloss_treino.append(logloss_tr)\n    logloss_validacao.append(logloss_val)\n    \n    print('AUC (treino):', auc_tr, ' AUC (val):', auc_val)\n    print('Acur\u00e1cia (treino):', acc_tr, ' Acur\u00e1cia (val):', acc_val)\n    print('Log loss (treino):', logloss_tr, 'Log loss (val):', logloss_val)\n    print()\n    \nprint('M\u00e9dia AUC (treino):', np.mean(auc_treino))\nprint('M\u00e9dia AUC (val):', np.mean(auc_validacao))\nprint('M\u00e9dia Acur\u00e1cia (treino):', np.mean(acc_treino))\nprint('M\u00e9dia Acur\u00e1cia (val):', np.mean(acc_validacao))\nprint('M\u00e9dia Log-loss (treino):', np.mean(logloss_treino))\nprint('M\u00e9dia Log-loss (val):', np.mean(logloss_validacao))","92f38efa":"print(0.9483085841994916 - 0.9482892409102384)","497b84ed":"def gera_submissao():\n    \n    # guarda ids\n    sub = teste.copy()\n    ids = sub['id']\n    \n    # dropa colunas n\u00e3o utilizadas pelo modelo\n    sub = sub.drop(['id', 'estadocivilmae', 'catprenatal', 'tipoparto', 'sexo', 'malformacao', 'estadocivil_viuva'], axis=1)\n    \n    # cria novas features\n    sub['prematuro'] = np.where(sub['qtdsemanas'] < 37, 1, 0)\n    sub['pos_termo'] = np.where(sub['qtdsemanas'] > 42, 1, 0)\n    sub['probs'] = gera_probabilidades(sub)\n\n    # imputando NaN\n    # for col in ['idademae', 'qtdsemanas', 'apgar1', 'apgar5']:\n    #    sub[col] = sub[col].fillna(sub[col].mean())\n    \n    \n    # treina nos dados completos\n    X_train = X.copy()\n    y_train = y.copy()    \n    \n    # cria novas features\n    X_train['prematuro'] = np.where(X_train['qtdsemanas'] < 37, 1, 0)\n    X_train['pos_termo'] = np.where(X_train['qtdsemanas'] > 42, 1, 0)\n    X_train['probs'] = gera_probabilidades(X_train)    \n    \n    # imputa NaN\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n    \n    \n    clf = xgb.XGBClassifier(random_state=1, missing=np.nan)\n    clf.fit(X_train, y_train)\n    print('Modelo treinado')\n    \n    # gera probabilidades\n    print('Gerando probabilidades...')\n    probs = clf.predict_proba(sub)\n    print(probs)\n    \n    # gerando submiss\u00e3o\n    print('Gerando submiss\u00e3o...')\n    print('OK')\n    \n    return pd.DataFrame({'id': ids, 'obito': probs[:, 1]})  \n    \n    \nsub2 = gera_submissao()","ebb43420":"sub2.to_csv('sub2_xgboost_semtunning_prematuro_pos_termo_probscondicionais_missingnp.nan_sem_imputer.csv', index=False)","6fcb32f1":"from sklearn.calibration import CalibratedClassifierCV, calibration_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import brier_score_loss\n\n\ndef calibracao():\n\n    # separa em treino e valida\u00e7\u00e3o\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.67, random_state=0)\n\n    # cria novas features\n    X_train['prematuro'] = np.where(X_train['qtdsemanas'] < 37, 1, 0)\n    X_train['pos_termo'] = np.where(X_train['qtdsemanas'] > 42, 1, 0)\n    X_train['probs'] = gera_probabilidades(X_train)      \n    \n    # imputa NaN\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n    \n    # cria novas features\n    X_val['prematuro'] = np.where(X_val['qtdsemanas'] < 37, 1, 0)\n    X_val['pos_termo'] = np.where(X_val['qtdsemanas'] > 42, 1, 0)\n    X_val['probs'] = gera_probabilidades(X_val)      \n    \n    # imputa NaN\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_val[col] = X_val[col].fillna(X_val[col].mean())\n    \n\n    # treina modelo\n    clf = xgb.XGBClassifier(random_state=1, missing=np.nan)\n    clf.fit(X_train, y_train)\n    probs = clf.predict_proba(X_val)[:, 1]\n\n    \n    # treina calibrador com m\u00e9todo isot\u00f4nico (para amostras pequenas ele n\u00e3o \u00e9 adequado)\n    # aqui o argumento cv vai fazer o mesmo que fiz at\u00e9 agora (usar KFold ou StratifiedKFold)\n    clf_isotonic = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n    clf_isotonic.fit(X_train, y_train)\n    prob_pos_isotonic = clf_isotonic.predict_proba(X_val)[:, 1]\n    \n    # cria curva de calibra\u00e7\u00e3o\n    x_, y_ = calibration_curve(y_val, prob_pos_isotonic, n_bins=10, normalize=True) \n    \n    plt.plot([0, 1], [0, 1], linestyle='--', label='Ideal') \n    plt.plot(y_, x_, marker='.', label='XGBoost') \n    plt.legend(loc = 'upper left') \n    plt.xlabel('M\u00e9dia das probabilidades preditas em cada bin') \n    plt.ylabel('Raz\u00e3o de positivos') \n    plt.show(); \n    \n    return clf_isotonic\n\nclf_isotonic = calibracao()","fd7fabba":"auc_treino = []\nauc_validacao = []\nacc_treino = []\nacc_validacao = []\nlogloss_treino = []\nlogloss_validacao = []\n\nfor tr, val in kf.split(X, y):\n    \n    # splita em treino\/valida\u00e7\u00e3o    \n    X_train, X_val = X.iloc[tr], X.iloc[val]\n    y_train, y_val = y.iloc[tr], y.iloc[val]\n    \n    # cria novas features\n    X_train['prematuro'] = np.where(X_train['qtdsemanas'] < 37, 1, 0)\n    X_train['pos_termo'] = np.where(X_train['qtdsemanas'] > 42, 1, 0)\n    X_train['probs'] = gera_probabilidades(X_train)\n\n    # cria novas features\n    X_val['prematuro'] = np.where(X_val['qtdsemanas'] < 37, 1, 0)\n    X_val['pos_termo'] = np.where(X_val['qtdsemanas'] > 42, 1, 0)\n    X_val['probs'] = gera_probabilidades(X_val)\n\n    \n    # imputando NaN para dados de treino e valida\u00e7\u00e3o usando a m\u00e9dia\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n        \n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_val[col] = X_val[col].fillna(X_val[col].mean())\n\n    \n    # calcula probabilidades usando o modelo calibrado\n    prob_tr = clf_isotonic.predict_proba(X_train)[:, 1]\n    prob_val = clf_isotonic.predict_proba(X_val)[:, 1]\n    \n    # calcula AUC\n    auc_tr = roc_auc_score(y_train, prob_tr)\n    auc_val = roc_auc_score(y_val, prob_val)\n    \n    # calcula acur\u00e1cia\n    acc_tr = accuracy_score(y_train, (prob_tr > .5).astype(int))\n    acc_val = accuracy_score(y_val, (prob_val > .5).astype(int))\n    \n    # calcula log-loss\n    logloss_tr = log_loss(y_train, prob_tr)\n    logloss_val = log_loss(y_val, prob_val)\n    \n    # guarda resultados\n    auc_treino.append(auc_tr)\n    auc_validacao.append(auc_val)\n    acc_treino.append(acc_tr)\n    acc_validacao.append(acc_val)\n    logloss_treino.append(logloss_tr)\n    logloss_validacao.append(logloss_val)\n    \n    print('AUC (treino):', auc_tr, ' AUC (val):', auc_val)\n    print('Acur\u00e1cia (treino):', acc_tr, ' Acur\u00e1cia (val):', acc_val)\n    print('Log loss (treino):', logloss_tr, 'Log loss (val):', logloss_val)\n    print()\n    \nprint('M\u00e9dia AUC (treino):', np.mean(auc_treino))\nprint('M\u00e9dia AUC (val):', np.mean(auc_validacao))\nprint('M\u00e9dia Acur\u00e1cia (treino):', np.mean(acc_treino))\nprint('M\u00e9dia Acur\u00e1cia (val):', np.mean(acc_validacao))\nprint('M\u00e9dia Log-loss (treino):', np.mean(logloss_treino))\nprint('M\u00e9dia Log-loss (val):', np.mean(logloss_validacao))","2041921a":"print(0.949606988646474 - 0.9479901533726919)","9298b641":"auc_treino = []\nauc_validacao = []\nacc_treino = []\nacc_validacao = []\nlogloss_treino = []\nlogloss_validacao = []\n\nfor tr, val in skf.split(X, y):\n    \n    # splita em treino\/valida\u00e7\u00e3o    \n    X_train, X_val = X.iloc[tr], X.iloc[val]\n    y_train, y_val = y.iloc[tr], y.iloc[val]\n    \n    # cria novas features\n    X_train['prematuro'] = np.where(X_train['qtdsemanas'] < 37, 1, 0)\n    X_train['pos_termo'] = np.where(X_train['qtdsemanas'] > 42, 1, 0)\n    X_train['probs'] = gera_probabilidades(X_train)\n\n    # cria novas features\n    X_val['prematuro'] = np.where(X_val['qtdsemanas'] < 37, 1, 0)\n    X_val['pos_termo'] = np.where(X_val['qtdsemanas'] > 42, 1, 0)\n    X_val['probs'] = gera_probabilidades(X_val)\n    \n    \n    # imputando NaN para dados de treino e valida\u00e7\u00e3o usando a m\u00e9dia\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_val[col] = X_val[col].fillna(X_val[col].mean())\n\n    \n    # calcula probabilidades com o modelo calibrado\n    prob_tr = clf_isotonic.predict_proba(X_train)[:, 1]\n    prob_val = clf_isotonic.predict_proba(X_val)[:, 1]\n    \n    # calcula AUC\n    auc_tr = roc_auc_score(y_train, prob_tr)\n    auc_val = roc_auc_score(y_val, prob_val)\n    \n    # calcula acur\u00e1cia\n    acc_tr = accuracy_score(y_train, (prob_tr > .5).astype(int))\n    acc_val = accuracy_score(y_val, (prob_val > .5).astype(int))\n    \n    # calcula log-loss\n    logloss_tr = log_loss(y_train, prob_tr)\n    logloss_val = log_loss(y_val, prob_val)\n    \n    # guarda resultados\n    auc_treino.append(auc_tr)\n    auc_validacao.append(auc_val)\n    acc_treino.append(acc_tr)\n    acc_validacao.append(acc_val)\n    logloss_treino.append(logloss_tr)\n    logloss_validacao.append(logloss_val)\n    \n    print('AUC (treino):', auc_tr, ' AUC (val):', auc_val)\n    print('Acur\u00e1cia (treino):', acc_tr, ' Acur\u00e1cia (val):', acc_val)\n    print('Log loss (treino):', logloss_tr, 'Log loss (val):', logloss_val)\n    print()\n    \nprint('M\u00e9dia AUC (treino):', np.mean(auc_treino))\nprint('M\u00e9dia AUC (val):', np.mean(auc_validacao))\nprint('M\u00e9dia Acur\u00e1cia (treino):', np.mean(acc_treino))\nprint('M\u00e9dia Acur\u00e1cia (val):', np.mean(acc_validacao))\nprint('M\u00e9dia Log-loss (treino):', np.mean(logloss_treino))\nprint('M\u00e9dia Log-loss (val):', np.mean(logloss_validacao))","84857770":"print(0.9496030332857954 - 0.9482892409102384)","654c667b":"def gera_submissao():\n    \n    # guarda ids\n    sub = teste.copy()\n    ids = sub['id']\n    \n    # dropa colunas n\u00e3o utilizadas pelo modelo\n    sub = sub.drop(['id', 'estadocivilmae', 'catprenatal', 'tipoparto', 'sexo', 'malformacao', 'estadocivil_viuva'], axis=1)\n    \n    # cria novas features\n    sub['prematuro'] = np.where(sub['qtdsemanas'] < 37, 1, 0)\n    sub['pos_termo'] = np.where(sub['qtdsemanas'] > 42, 1, 0)\n    sub['probs'] = gera_probabilidades(sub) \n\n    # imputando NaN\n    # for col in ['idademae', 'qtdsemanas', 'apgar1', 'apgar5']:\n    #    sub[col] = sub[col].fillna(sub[col].mean())\n\n    \n    # treina nos dados completos\n    # aqui precisamos imputar novamente, porque os dados originais n\u00e3o est\u00e3o imputados\n    X_train = X.copy()\n    y_train = y.copy()    \n    \n    # cria novas features\n    X_train['prematuro'] = np.where(X_train['qtdsemanas'] < 37, 1, 0)\n    X_train['pos_termo'] = np.where(X_train['qtdsemanas'] > 42, 1, 0)\n    X_train['probs'] = gera_probabilidades(X_train)    \n    \n    # imputa NaN\n    # for col in ['qtdsemanas', 'peso', 'apgar1', 'apgar5']:\n    #    X_train[col] = X_train[col].fillna(X_train[col].mean())\n    \n    # gera probabilidades com o modelo calibrado\n    print('Gerando probabilidades...')\n    probs = clf_isotonic.predict_proba(sub)\n    print(probs)\n    \n    # gerando submiss\u00e3o\n    print('Gerando submiss\u00e3o...')\n    print('OK')\n    \n    return pd.DataFrame({'id': ids, 'obito': probs[:, 1]})  \n    \n    \nsub3 = gera_submissao()","e2d5ae98":"sub3.to_csv('sub3_xgboost_calibradocom5folds_test_frac0.67_com_prematuro_pos_termo_probscondicionais_missingnp.nan_sem_imputer.csv', index=False)","b20a03f7":"apgar_obito = pd.DataFrame({'apgar1': X['apgar1'], 'apgar5': X['apgar5'], 'obito': y})\napgar_obito.head(10)","ca488412":"import seaborn as sns\n\nfig, _ = plt.subplots(figsize=(13, 10))\n\npiv = pd.pivot_table(apgar_obito[apgar_obito['obito'] == 1][['apgar1', 'apgar5']].groupby(['apgar1', 'apgar5']).size().reset_index(name='obitos'),\n                     values='obitos', index=['apgar1'], columns=['apgar5'])\nax = sns.heatmap(piv, annot=True)\nplt.title('N\u00famero de \u00f3bitos')\nfig.show();","279ffe0f":"fig, _ = plt.subplots(figsize=(10, 10))\n\nplt.scatter(X['peso'], X['qtdsemanas'], c=y)\nplt.xlabel('peso')\nplt.ylabel('qtdsemanas')\n\nfig.show();","8ae22cad":"## Conclus\u00e3o:  \n     \n- As submiss\u00f5es com o modelo calibrado tamb\u00e9m n\u00e3o melhoraram, apesar de localmente melhorarem muito. O curioso \u00e9 que este\nmodelo calibrado foi o melhor modelo no *private leaderboard*. Talvez calibrar os modelos seja uma boa forma para que seu\nmodelo consiga generalizar para dados novos.   \n        \nNo final das contas eu usei a submiss\u00e3o 2 como principal, e a submiss\u00e3o 1 como secund\u00e1ria. Ambas ficaram bem pr\u00f3ximas no *private leaderboard*.","8d096de1":"Intuitivamente eu pensei que ter\u00edamos mais \u00f3bitos quando as 2 vari\u00e1veis s\u00e3o pequenas (entre 0 e 3), por\u00e9m podemos ver que h\u00e1 muitos casos quando os valores s\u00e3o grandes (entre 6 e 10).","dc01e984":"## An\u00e1lise explorat\u00f3ria de dados","84ebc46c":"## Usando KFold","67150355":"## Calibra\u00e7\u00e3o do modelo\n       \nVou fazer uma fun\u00e7\u00e3o que retorna um objeto do modelo XGBoost, por\u00e9m calibrado. A ideia \u00e9 reduzir o *brier score*:     https:\/\/en.wikipedia.org\/wiki\/Brier_score       \n       \nEsse tipo de m\u00e9todo ajusta um modelo de regress\u00e3o com as probabilidades preditas pelo classificador e tenta \"calibrar\" as probabilidades,\ndiminuindo os momentos que fazemos predi\u00e7\u00f5es subestimados ou superestimadas. O m\u00e9todo usa valida\u00e7\u00e3o cruzada. Quando a resposta \u00e9 bin\u00e1ria \nele utiliza KFold ou StratifiedKfold.   \n          \nEste v\u00eddeo explica bem o que \u00e9 calibra\u00e7\u00e3o de um modelo. \u00c9 um pouco confuso, mas esse v\u00eddeo realmente explica bem o que \u00e9 isso:         \nhttps:\/\/www.youtube.com\/watch?v=RXMu96RJj_s&list=PLYx7XA2nY5GcDQblpQ_M1V3PQPoLWiDAC&index=12 ","ad8d9c4d":"## Lendo dados","acfd5272":"## Gerando submiss\u00e3o\n    \nPara gerar a submiss\u00e3o, precisamos fazer as mesmas transforma\u00e7\u00f5es nos dados de teste.   ","9629c0fc":"A rela\u00e7\u00e3o entre `peso` e `qtdsemanas` tamb\u00e9m \u00e9 interessante.","68646f98":"## Valores at\u00edpicos (*outliers*)\n     \nPode acontecer de existirem valores muitos diferentes da distribui\u00e7\u00e3o original dos dados, que podem afetar nosso modelo.","72a4e100":"E as probabilidades condicionais?      \n    \n$P(Y = 1 | \\ apgar1 = 0, apgar5 = 0)$   \n$P(Y = 1 | \\ apgar1 = 1, apgar5 = 0)$   \n             $\\vdots$  \n$P(Y = 1 | \\ apgar1 = 10, apgar5 = 10)$","7b6d8276":"J\u00e1 para a vari\u00e1vel `qtdsemanas`, temos uma discrimina\u00e7\u00e3o muito maior. Veja que o 3\u00ba quartil da classe 1 \u00e9 praticamente o 1\u00ba quartil da classe 0. As medianas est\u00e3o muito longes. Esse pode ser um ind\u00edcio de que essa vari\u00e1vel pode ser boa para o modelo.    ","8569173b":"Como \u00e9 poss\u00edvel notar, a porcentagem de `obito=1` para cada *fold* de treino e valida\u00e7\u00e3o s\u00e3o aproximadamente iguais.    \nIsso se deve \u00e0 estratifica\u00e7\u00e3o, que foi usada aqui.","07edac6c":"Todas as *features* categ\u00f3ricas possuem `NaN` (apesar de serem poucos valores). \n    \n### Outra coisa importante \u00e9 que nossa *target* est\u00e1 bem desbalanceada (h\u00e1 muito mais sobreviv\u00eancias do que \u00f3bitos).","1e791eb2":"**Dicion\u00e1rio de dados:**\n       \n- idademae: Idade da m\u00e3e em anos    \n- estadocivilmae: Estado Civil da M\u00e3e    \n- catprenatal: Quantidade de Consultas pr\u00e9-natal realizadas pela m\u00e3e    \n- qtdsemanas: Idade gestacional no momento do parto em semanas    \n- tipoparto: Tipo do parto    \n- peso: Peso do rec\u00e9m-nascido no momento do nascimento em gramas    \n- malformacao: Se foi observada alguma mal forma\u00e7\u00e3o no beb\u00ea    \n- sexo: Sexo do rec\u00e9m-nascio (f=feminino, m=masculino)    \n- apgar1: Apgar no 1\u00ba Minuto    \n- apgar5: Apgar no 5\u00ba Minuto    \n- obito: Indica se o rec\u00e9m-nascido veio a \u00f3bito antes de completar 1 ano de vida    ","f4aa7321":"## Resultado:\n  \n- AUC (valida\u00e7\u00e3o KFold): 0.9480558292143977  \n- AUC (valida\u00e7\u00e3o StratifieldKFold): 0.9482892409102384\n            \n- AUC *leaderboard*: 0.94335\n     \nMelhorou um pouco o AUC, tanto localmente quanto na *leaderboard*.    \nO AUC da *leaderboard* ainda est\u00e1 mais perto da valida\u00e7\u00e3o KFold.    \nPode ser que a melhora tenha sido por acaso, por\u00e9m podemos pensar que foi por causa das novas *features* tamb\u00e9m.","ed43593d":"## Baseline usando StratifiedKFold","a616563f":"## 3\u00aa submiss\u00e3o","9a07a38a":"Eu parei por aqui. As pr\u00f3ximas c\u00e9lulas foram experimenta\u00e7\u00f5es que n\u00e3o melhoraram o modelo.","e0303b7c":"Houve uma melhora pequena tanto no $AUC$ (0.9478498979926228 para 0.9479901533726919) quanto no $logloss$.    \nSer\u00e1 mesmo que faz sentido aumentar a complexidade do modelo em troca desta melhora?         \nEu rodei alguns testes com alguns algoritmos (antes de usar a *feature* de probabilidades) de `feature selection` e n\u00e3o obtive melhoras.     \n      \nApesar disso, foi poss\u00edvel perceber que as vari\u00e1veis `peso`, `apgar_1` e `apgar_5` e `prematuro` (nesta ordem), se mostraram as 4 vari\u00e1veis mais importantes para o `xgboost`. A vari\u00e1vel `prematuro` \u00e9 a nova vari\u00e1vel criada aqui.    ","c4b516f3":"## Baseline usando KFold","3a0c9294":"O AUC para valida\u00e7\u00e3o mudou de 0.9482892409102384 para 0.9496030332857954","3c032956":"## Usando StratifiedKFold, com modelo calibrado","1ec0cb6d":"## Transformando vari\u00e1veis categ\u00f3ricas\n   \nAntes de fazer o *split* em treino\/valida\u00e7\u00e3o, podemos transformar as vari\u00e1veis categ\u00f3ricas para os dados completos, porque uma `categoria=0` dos dados de treino\nprecisa ser a mesma categoria nos dados de valida\u00e7\u00e3o, sen\u00e3o estar\u00edamos \"bagun\u00e7ando\" toda a l\u00f3gica dos dados.   \n    \nMas precisamos tomar cuidado: algumas vari\u00e1veis s\u00f3 podem ser transformadas depois do *split*. Por exemplo, se transformarmos a vari\u00e1vel `idademae` para\nos dados completos, estar\u00edamos \"interferindo\" na distribui\u00e7\u00e3o desta vari\u00e1vel nos dados de valida\u00e7\u00e3o. Isso \u00e9 um problema, porque teoricamente os dados de \nvalida\u00e7\u00e3o precisam ser totalmente desconhecidos pelo modelo. Se categorizarmos usando os dados completos, ent\u00e3o informa\u00e7\u00f5es dos dados de valida\u00e7\u00e3o ser\u00e3o usados\npara treinar o modelo, podendo causar uma boa performance em dados de treino e\/ou valida\u00e7\u00e3o, por\u00e9m m\u00e1 performance em dados desconhecidos. Esse \u00e9 um exemplo de *data leakage* (vazamento de dados).    \n        \nSe eu quisesse transformar a vari\u00e1vel `idademae` em classes, o correto seria fazer isso usando somente os dados de treino, e usar estas mesmas categorias criadas para categorizar os dados de valida\u00e7\u00e3o.   \n    \nPara valores faltantes, vamos manter o `NaN`.","266ff8fd":"Neste caso, a propor\u00e7\u00e3o ainda se manteve muito perto (eu pensei que as propor\u00e7\u00f5es iam ser bem distantes rsrs).      \nD\u00e1 para notar que os \u00edndices mudaram: isso deve ser porque agora ele n\u00e3o est\u00e1 preocupado em manter a propor\u00e7\u00e3o exata, e talvez pegue outras observa\u00e7\u00f5es da amostra que n\u00e3o sejam da mesma classe.","79eccefb":"O peso tamb\u00e9m parece discriminar de forma clara as duas classes. Novamente, v\u00e1rias crian\u00e7as que sobreviveram s\u00e3o *outliers* quanto ao `peso`.","0f2c4621":"## Valida\u00e7\u00e3o com StratifiedKFold","888b3104":"## Resultado\n      \n- Baseline notebook (KFold): 0.9478498979926228  \n     \n- Baseline notebook (StratifiedKFold): 0.9482892409102384\n           \n- Baseline public leaderboard: 0.94295\n      \nFiquei contente com esse resultado, pois parece que de fato n\u00e3o houve nenhum vazamento de dados de valida\u00e7\u00e3o para dados de treino, pois o AUC local ficou pr\u00f3ximo do AUC da *leaderboard*.     \n       \nParece que o cen\u00e1rio usando valida\u00e7\u00e3o KFold ficou mais pr\u00f3ximo do AUC da *public leaderboard*.      \nPode ser que eu esteja errado, por\u00e9m pode ser que os dados da *leaderboard* n\u00e3o foram *splitados* por estratifica\u00e7\u00e3o.","59bac4bf":"## Visualizando *features* num\u00e9ricas","bacaba0d":"## Usando StratifiedKFold","6c712845":"Relembrando:  \n    \n`catprenatal`: Quantidade de Consultas pr\u00e9-natal realizadas pela m\u00e3e   \n   \nPortanto essa vari\u00e1vel \u00e9 categ\u00f3rica **ordinal**, ou seja, a ordem aqui importa, pois `nenhuma` < `de1a3` < `de4a6` < `7mais`.    \nPrecisamos levar isso em considera\u00e7\u00e3o na hora de transformar.","477e444f":"## Feature Engineering\n      \nPodemos criar duas *features* relacionadas a quantidade de semanas de gesta\u00e7\u00e3o:\n    \n- prematuro: o beb\u00ea nasceu antes de 37 semanas\n   \n- p\u00f3s-termo: o beb\u00ea nasceu depois de 42 semanas\n    \nEu peguei essa refer\u00eancia de alguns sites de not\u00edcias, pois n\u00e3o consegui achar em fontes oficiais como SIM, por exemplo.\n     \nOutra ideia que eu tive tamb\u00e9m foi tentar usar as probabilidades condicionais (conjuntas) de `apgar1` e `apgar5` como *feature*.","e4b33bec":"## Qual valida\u00e7\u00e3o escolher?    \n       \nEu acho que podem acontecer duas coisas aqui:\n      \n- Os dados que est\u00e3o na *leaderboard* foram *splitados* de forma que a porcentagem das classes da resposta `\u00f3bito` seja respeitada. Isso significa que \nse nos dados completos temos 80% de crian\u00e7as sobreviventes e 20% de \u00f3bitos, ent\u00e3o na *leaderboard* essa propor\u00e7\u00e3o \u00e9 mantida. Isso se faz usando *estratifica\u00e7\u00e3o*.    \n    \n- Os dados que est\u00e3o na *leaderboard* foram *splitados* de forma aleat\u00f3ria. Neste caso, a porcentagem das classes da resposta `\u00f3bito` n\u00e3o \u00e9 mantida, logo nos dados\ncompletos podemos ter uma propor\u00e7\u00e3o 80\/20, por\u00e9m na leaderboard essa propor\u00e7\u00e3o ser de 95\/5, por exemplo.\n      \nPode ser que existam outras formas de tentar simular esse *split*, por\u00e9m eu vou tentar esses dois.\n    \nLink legal para entender melhor os *splits* do *sklearn*:    \nhttps:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py","a2838e54":"Esse ser\u00e1 nosso baseline, que por enquanto n\u00e3o possui nenhum tunning de hiperpar\u00e2metros. ","885da368":"## Visualizando frequ\u00eancias das *features* categ\u00f3ricas","f9eb698f":"## 1\u00aa Submiss\u00e3o","d251f888":"O AUC para valida\u00e7\u00e3o mudou de 0.9479901533726919 para 0.949606988646474.   \nApesar disso, parece que a vari\u00e2ncia entre os *folds* mudou. N\u00e3o sei se este modelo ficar\u00e1 melhor que o atual.","9d1d82fa":"A *feature* `idademae` \u00e9 assim\u00e9trica \u00e0 esquerda, enquanto `qtdsemanas` \u00e9 assim\u00e9trica \u00e0 direta. J\u00e1 `peso` parece ter duas modas.    ","3ead479a":"Para esta vari\u00e1vel, a distribui\u00e7\u00e3o da `idademae` \u00e9 bem parecida para as duas classes, apesar da classe 0 possuir mais *outliers*.","8ab806b8":"## Usando KFold, com modelo calibrado","92ce9c68":"Podemos ver que temos crian\u00e7as com `asfixia grave` (Apgar 0 a 2), por exemplo.   \nTemos alguns valores `NaN` tamb\u00e9m.","032aa2c4":"O AUC para valida\u00e7\u00e3o mudou de 0.9482892409102384 para 0.9483085841994916","e0ee16dd":"H\u00e1 v\u00e1rios casos de beb\u00eas prematuros, assim tamb\u00e9m como casos de p\u00f3s-termo. Talvez essas duas features possam ajudar o modelo.","71937dc9":"Podemos fazer um teste: rodar modelos com os *outliers* e modelos sem os *outliers* posteriormente.    \nObs.: eu fiz isso por\u00e9m n\u00e3o obtive melhoras,ent\u00e3o n\u00e3o prossegui com essa abordagem.","ac5e660e":"## Valida\u00e7\u00e3o com KFold","55ba5131":"## Treinamento","49dc4f0d":"## Resultado\n       \n- AUC (Kfold): 0.949606988646474       \n- AUC (StratifiedKFold): 0.9496030332857954\n    \n- AUC (public *leaderboard*): 0.94115\n     \nO AUC caiu um pouco na *public leaderboard*.","523a3823":"Em ambos valida\u00e7\u00f5es, o aumento foi bem baixo, por\u00e9m vamos submeter.","8f7042a2":"### O que \u00e9 Apgar?   \n       \nA Escala ou \u00cdndice de Apgar \u00e9 um teste desenvolvido pela Dra. Virginia Apgar (1909 \u2013 1974), m\u00e9dica norte-americana, que consiste na avalia\u00e7\u00e3o por um pediatra de 5 sinais objetivos do rec\u00e9m-nascido, atribuindo-se a cada um dos sinais uma pontua\u00e7\u00e3o de 0 a 2. O teste, aplicado duas vezes (no primeiro e no quinto minuto ap\u00f3s o nascimento), \u00e9 utilizado para avaliar o ajuste imediato do rec\u00e9m-nascido \u00e0 vida extrauterina, sendo que os sinais avaliados s\u00e3o: frequ\u00eancia card\u00edaca, respira\u00e7\u00e3o, t\u00f4nus muscular, irritabilidade reflexa e cor da pele. O somat\u00f3rio da pontua\u00e7\u00e3o (no m\u00ednimo 0 e no m\u00e1ximo 10) resultar\u00e1 no \u00cdndice de Apgar e o rec\u00e9m-nascido ser\u00e1 classificado como:\n\n- sem asfixia (Apgar 8 a 10);    \n- com asfixia leve (Apgar 5 a 7);    \n- com asfixia moderada (Apgar 3 a 4) ou    \n- com asfixia grave: Apgar 0 a 2.    \n    \n****\n    \n**APGAR**:    \n- **A**par\u00eancia\n     \n- **P**ulso   \n    \n- **G**esticula\u00e7\u00e3o\n    \n- **A**tividade\n    \n- **R**espira\u00e7\u00e3o\n      \n*Fonte: https:\/\/pt.wikipedia.org\/wiki\/Escala_de_Apgar*","a47e7897":"Temos datasets pequenos (o dataset de treino tem somente 1 MB), comparados com alguns aqui do Kaggle.","fdd01a8f":"## Alguns outros *insights*","e81076e5":"## 2\u00aa submiss\u00e3o","f20409df":"****"}}