{"cell_type":{"03cda899":"code","4ccb2fa2":"code","5bb1763d":"code","7ecc6680":"code","a59a8805":"code","d6979547":"code","3af4b26a":"code","f67bd6ca":"code","60aa99d3":"code","a6a5051b":"code","5d74b27b":"code","b513edaa":"code","f54f7834":"code","125f43b7":"code","f9550f31":"code","c78a2f54":"code","2b7f33a6":"code","d7f0c105":"code","32d0241a":"code","d8a52718":"code","98183856":"code","e12de1c8":"code","0bb49c25":"code","ea6536bf":"code","ffb679b2":"code","01bf6c59":"code","5ee78928":"code","f1694c5d":"code","732c04c8":"code","7a288358":"code","2adf93c4":"code","c6411fc5":"markdown"},"source":{"03cda899":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ccb2fa2":"#import libry\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score, train_test_split\nimport warnings\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n","5bb1763d":"#reading_data\ntrain = pd.read_csv('..\/input\/data-science-london-scikit-learn\/train.csv', header=None)\ntrainLabel = pd.read_csv('..\/input\/data-science-london-scikit-learn\/trainLabels.csv', header=None)\ntest = pd.read_csv('..\/input\/data-science-london-scikit-learn\/test.csv', header=None)","7ecc6680":"train.info()","a59a8805":"train.describe()","d6979547":"train.head()","3af4b26a":"test.info()","f67bd6ca":"test.head()","60aa99d3":"trainLabel\n","a6a5051b":"X, y = train, np.ravel(trainLabel)\n","5d74b27b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","b513edaa":"#modeal_complex \nn_egl=np.arange(4,30)\nkfold=10\ntrain_acyorcy=[]\nval_acyorcy=[]\nbest_score=0\nbest_score2=0\nbest_knn=None\nbest_knn2=None\nfor i,k in  enumerate(n_egl):\n  knn=KNeighborsClassifier(n_neighbors=k)\n  knn.fit(X_train,y_train)\n  train_acyorcy.append(knn.score(X_train,y_train))\n  val_acyorcy.append(np.mean(cross_val_score(knn,X,y,cv=kfold)))\n  if np.mean(cross_val_score(knn,X,y,cv=kfold)) > best_score:\n             best_score=np.mean(cross_val_score(knn,X,y,cv=kfold))\n             best_knn = knn\n  elif knn.score(X_train,y_train)>best_score2:\n     best_score2=knn.score(X_train,y_train)   \n     best_knn2=knn\n\n\n","f54f7834":"# Plot\nplt.figure(figsize=[13,8])\nplt.plot(n_egl, val_acyorcy, label = 'Validation Accuracy')\nplt.plot(n_egl, train_acyorcy, label = 'Training Accuracy')\nplt.legend()\nplt.title('k value VS Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.xticks(n_egl)\nplt.show()\n\nprint('Best Accuracy without feature scaling:',best_score)\nprint('Best Accuracy without feature scaling2:',best_score2)\nprint(best_knn2)\nprint(best_knn)","125f43b7":"#pridact\nbest_knn.predict(X_test)","f9550f31":"best_knn.score(X_test,y_test)","c78a2f54":"best_knn2.predict(X_test)","2b7f33a6":"best_knn2.score(X_test,y_test)","d7f0c105":"my_slosione=pd.DataFrame(best_knn.predict(test))\n","32d0241a":"print(my_slosione)","d8a52718":"my_slosione.to_csv('my_slotion.csv', index=False)","98183856":"from sklearn.preprocessing import StandardScaler,minmax_scale,Normalizer\nstd=StandardScaler()\nx_std=std.fit_transform(X)\nmin_x=minmax_scale(X)\nNor=Normalizer()\nNor_x=Nor.fit_transform(X)","e12de1c8":"#complex_model\nn_gl=np.arange(4,40)\nk_fold=20\nval_acurcy={'x_std':[],'min':[],'Nor_x':[]}\nbest_KNN=None\nbest_scaling=None\nbest_accurcy_ascaling=0\nfor i,k in enumerate(n_gl):\n  KNN=KNeighborsClassifier(n_neighbors=k)\n  S1=np.mean(cross_val_score(KNN,x_std,y,cv=k_fold))\n  val_acurcy['x_std'].append(S1)\n  S2=np.mean(cross_val_score(KNN,min_x,y,cv=kfold))\n  val_acurcy['min'].append(S2)\n  S3=np.mean(cross_val_score(KNN,Nor_x,y,cv=kfold))\n  val_acurcy['Nor_x'].append(S3)\n  if S1>best_accurcy_ascaling :\n    best_KNN=KNN\n    best_accurcy_ascaling=S1\n    best_scaling='x_std'\n  elif S2>best_accurcy_ascaling:\n    best_KNN=KNN\n    best_accurcy_ascaling=S2\n    best_scaling='min_x'\n  elif S3> best_accurcy_ascaling:\n    best_KNN=KNN\n    best_accurcy_ascaling=S3\n    best_scaling='Nor_x'  ","0bb49c25":"#plot\nplt.figure(figsize=[12,7])\nplt.plot(n_gl,val_acurcy['x_std'],label=' Acurcy with StandardScaler')\nplt.plot(n_gl,val_acurcy['min'],label='ACURCY withe minmax_scale ')\nplt.plot(n_gl,val_acurcy['Nor_x'],label='Acurcy withe Normalizer')\nplt.legend()\nplt.xlabel('knn_numper')\nplt.ylabel('Acurcy')\nplt.title('KNN & Accurcy')\nplt.xticks(n_gl)\nplt.show()\nprint('Best Accuracy with feature scaling:', best_KNN)\nprint('Best kNN classifier:', best_scaling)\nprint('Best scaling:', best_accurcy_ascaling)\n","ea6536bf":"#fiting\nbest_KNN.fit(Nor_x,y)\n","ffb679b2":"#prdict\nbest_KNN.predict(X_test)","01bf6c59":"best_KNN.score(X_test,y_test)","5ee78928":"#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, best_KNN.predict(X_test))\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()","f1694c5d":"#Calculating classification Report :  \nclassification_report(y_test,  best_KNN.predict(X_test), labels=None, target_names=None,sample_weight=None, digits=2, output_dict=False)\n\nClassificationReport = classification_report(y_test, best_KNN.predict(X_test))\nprint('Classification Report is : ', ClassificationReport )","732c04c8":"my_slotione2=pd.DataFrame(best_KNN.predict(test))","7a288358":"print(my_slotione2.shape)","2adf93c4":"my_slotione2.to_csv('my_slotione2.csv', index=False)\n","c6411fc5":"ather slution withe data_scaling(StandardScaler&minmax_scale&Normalizer)\n"}}