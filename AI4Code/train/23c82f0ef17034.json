{"cell_type":{"95a091d5":"code","f1def3d9":"code","b745f51f":"code","d74942dd":"code","32c01064":"code","b98d4076":"code","90fac74c":"code","30ddf299":"code","eda5c1b6":"code","aa49fd9a":"code","5633a699":"code","dafa6c4b":"code","3290421c":"code","a2dee0fc":"code","fec3bb39":"code","cc35ba6e":"code","0f17a433":"code","1ce48698":"code","f1288f04":"code","c0964b5c":"code","aaa2a9b0":"code","86e0cbd5":"code","d55b95eb":"code","704a82ab":"code","8aa19661":"code","6b441967":"code","e8e54aa7":"markdown","f617279f":"markdown","0d935498":"markdown","2549ee01":"markdown","51b49b60":"markdown","de445295":"markdown","a8fff8f2":"markdown","a8d62fa3":"markdown","d1ce6944":"markdown","55dd53c0":"markdown","e4546ca8":"markdown","25be5717":"markdown","2e10de51":"markdown","2b90138e":"markdown","fc83e4b4":"markdown"},"source":{"95a091d5":"import pandas as pd\nimport numpy as np\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n%matplotlib inline","f1def3d9":"movies = pd.read_csv(\"..\/input\/the-movies-dataset\/movies_metadata.csv\")\nprint(movies.columns)\nmovies.head()","b745f51f":"movies['genres'][0]","d74942dd":"movies['genres'] = movies['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])","32c01064":"keywords = pd.read_csv('..\/input\/the-movies-dataset\/keywords.csv')\n","b98d4076":"keywords.head()","90fac74c":"def clean_ids(x):\n    try:\n        return int(x)\n    except:\n        return np.nan\n\nmovies['id'] = movies['id'].apply(clean_ids)\nmovies = movies[movies['id'].notnull()]","30ddf299":"movies['id'] = movies['id'].astype('int')\nkeywords['id'] = keywords['id'].astype('int')\n\nmovies = movies.merge(keywords, on='id')\n\nmovies.head()","eda5c1b6":"movies[\"keywords\"][0]","aa49fd9a":"movies[\"keywords\"] = movies[\"keywords\"].apply(literal_eval)","5633a699":"def generate_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n        if len(names) > 10:\n            names = names[:10]\n        return names\n    return []\n\nmovies['keywords'] = movies['keywords'].apply(generate_list)\nmovies['genres'] = movies['genres'].apply(lambda x: x[:10])\n\nmovies[['title', 'keywords', 'genres']].head()","dafa6c4b":"def sanitize(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(' ','')) for i in x]\n    else:\n        if isinstance(x, str):\n            return str.lower(x.replace(' ', ''))\n        else:\n            return ''\n\nfor feature in ['genres', 'keywords']:\n    movies[feature] = movies[feature].apply(sanitize)\n","3290421c":"\ndef movie_soup(x):\n    return  x[\"title\"] + \" \" + \" \".join(x['genres']) + \" \"+x['overview']+\" \"+\" \".join(x['keywords'])\n\nmovies['overview'] = movies['overview'].fillna('')\nmovies['title'] = movies['title'].fillna('')\nmovies['soup'] = movies.apply(movie_soup, axis=1)","a2dee0fc":"movies.loc[movies['title']==\"The Matrix\",'soup'].values","fec3bb39":"books = pd.read_csv(\"..\/input\/top2k-books-with-descriptions\/top2k_book_descriptions.csv\", index_col=0)\nprint(books.columns)\nbooks.head()","cc35ba6e":"books['tag_name'][1]","0f17a433":"books['tag_name'] = books['tag_name'].apply(lambda x: literal_eval(x) if literal_eval(x) else np.nan)\nbooks = books[books['description'].notnull() | books['tag_name'].notnull()]\nbooks = books.fillna('')","1ce48698":"def book_soup(x):\n    soup = x[\"original_title\"]+\" \"+x[\"description\"]+\" \"+\" \".join(x['tag_name'])+\" \"+x[\"authors\"]\n    return soup","f1288f04":"books[\"soup\"] = books.apply(book_soup, axis=1)","c0964b5c":"\nsoups = pd.concat([movies['soup'],books['soup']],ignore_index=True)","aaa2a9b0":"\n\ncount = CountVectorizer(stop_words = \"english\")\ncount.fit(soups)\n\nmovies_matrix = count.transform(movies['soup'])\nbooks_matrix = count.transform(books['soup'])\n\nbooks_matrix.shape, movies_matrix.shape","86e0cbd5":"cosine_sim = cosine_similarity(movies_matrix, books_matrix)","d55b95eb":"movies = movies.reset_index()\nindices = pd.Series(movies.index, index=movies['title'].apply(lambda x: x.lower() if x is not np.nan else \"\")).drop_duplicates()","704a82ab":"def content_recommender(title):\n    idx = indices[title.lower()]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse=True)\n    \n    sim_scores = sim_scores[:10]\n\n    book_indices = [i[0] for i in sim_scores]\n\n    return books.iloc[book_indices]","8aa19661":"\n\n!pip3 install -q ipywidgets\n!jupyter nbextension enable --py --sys-prefix widgetsnbextension\n","6b441967":"import ipywidgets\nfrom IPython.display import HTML\ndef showhtml(recommendations):\n    html = ' '.join([f\"\"\"\n     <div class=\"flip-card\">\n      <div class=\"flip-card-inner\">\n        <div class=\"flip-card-front\">\n          <img src=\"{recommendations.iloc[i]['image_url']}\" alt=\"Avatar\" style=\"width:300px;height:300px;\">\n        <\/div>\n        <div class=\"flip-card-back\">\n          <h4>{recommendations.iloc[i]['title']}<\/h4>\n          <p>by {recommendations.iloc[i]['authors']}<\/p>\n        <\/div>\n      <\/div>\n    <\/div> \"\"\" for i in range(10)])\n    html = \"<div class='grid'>\"+html+\"<\/div>\"\n    html +=\"\"\"<style>\n    .flip-card {\n      background-color: transparent;\n      width: 200px;\n      height: 300px;\n      border: 1px solid #f1f1f1;\n    }\n\n    .flip-card-inner {\n      position: relative;\n      width: 100%;\n      height: 100%;\n      text-align: center;\n      transition: transform 0.8s;\n      transform-style: preserve-3d;\n    }\n\n    .flip-card:hover .flip-card-inner {\n      transform: rotateY(180deg);\n    }\n\n    .flip-card-front, .flip-card-back {\n      position: absolute;\n      width: 100%;\n      height: 100%;\n      -webkit-backface-visibility: hidden; \/* Safari *\/\n      backface-visibility: hidden;\n    }\n\n    .flip-card-front {\n      background-color: #bbb;\n      color: black;\n    }\n\n    .flip-card-back {\n    padding:10px;\n      background-color: dodgerblue;\n      color: white;\n      transform: rotateY(180deg);\n    }\n    .grid {\n        display: grid;\n        grid-template-columns: 30% 30% 30%;\n        grid-template-rows: 25% 25% 25%;\n        grid-gap: 5%;\n    }\n    <\/style>\"\"\"\n    return html\n\n\ndef show_books(movie_name='I, robot'):\n    recommendations = content_recommender(movie_name)\n#     for i in range(10):\n#         disPic(recommendations[\"image_url\"].iloc[i])\n#         print(recommendations[\"original_title\"].iloc[i])\n#         print(recommendations[\"description\"].iloc[i])\n    display(HTML(showhtml(recommendations)))\ndisplay(ipywidgets.interact(show_books))\n\n","e8e54aa7":"to make the search easier, I change the index to the title column, that way I will get the index of the movie I am searching for.","f617279f":"Our soup for movies includes the name of the movie, genres, overview, and the keywords(or sub-genres)","0d935498":"converting tag_name from string to list.<br>\nand we can't have our soup ready without description and tag_names, at least we must have one.","2549ee01":"generate_list function will help you to select as many keywords you need.","51b49b60":"ahh.. finally we have our Content based Recommendation system<br>\nit will select the first 10 books that are most similar to the movie you search for","de445295":"<h2>these are the top book recommendations for the movie <b>I, Robot<\/b><\/h2>","a8fff8f2":"Our soup for books includes the title, description, tag names(or book shelves) and author(s)","a8d62fa3":"Now we have to change them back to string tokens so that we can add them all to our soup.","d1ce6944":"We'll add genres and sub-genres or keywords to our soup. we already have genres, now we need to get the keywords.","55dd53c0":"same as the genres, we need to convert them from string to dictionary.","e4546ca8":"# Pick a movie, and get some book recommendations\n### In this notebook we will work on a content based recommendation system. we use two different datasets, one for movies([the movies dataset](https:\/\/www.kaggle.com\/rounakbanik\/the-movies-dataset)), the other one for books ([top2k book descriptions](https:\/\/www.kaggle.com\/yehyachali\/top2k-books-with-descriptions)).\n### I used Goodreads API to download descriptions for 2000 most rated books.(soon I will update the dataset with 10K descriptions)\n![](https:\/\/media.giphy.com\/media\/cw80NAWi858lO\/giphy.gif)\n\n","25be5717":"as you can see the genres in Movies dataset are in a dictionary format however the type is string. I will use literal_eval function to get the dictionary, then all we need is to select names of the genres.","2e10de51":"The data is ready, we have our soups!<br>\nnow all we have to do is to vectorize the data. And because our soup includes genres and tag names, I think it is better if we use Count vectorizer.<br>\nthis is how it works\n![](https:\/\/www.educative.io\/api\/edpresso\/shot\/5197621598617600\/image\/6596233398321152)","2b90138e":"Now the most important part of this recommendation system is to find the similarities between these vectors.<br> \nI am going to use Cosine_similarity formula.\n![](https:\/\/miro.medium.com\/max\/875\/1*r5ULMbx7ju3_Y4TU1PJIyQ.png)\nBy applying the definition of similarity, this will be in fact equal to 1 if the two vectors are identical, and it will be 0 if the two are orthogonal. In other words, the similarity is a number bounded between 0 and 1 that tells us how much the two vectors are similar.","fc83e4b4":"Joining movies and keywords dataframes"}}