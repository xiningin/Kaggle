{"cell_type":{"2abdc56a":"code","fd5883a8":"code","63285944":"code","6fcf66cc":"code","f0eee216":"code","dba0a96d":"code","19fb6514":"code","0a46b91d":"code","604db909":"code","eff9bb79":"code","6660c602":"code","e15ceaa1":"code","9ae36ac7":"code","06f0c9ae":"code","0cfcf1d2":"code","df75d85d":"code","550bab52":"code","722ea1a8":"code","c29826cc":"code","512899fb":"code","9c33a36f":"code","8a43647e":"code","064f7a26":"code","02effdc5":"code","b07a693c":"code","d32097e8":"code","2e7ba62d":"code","9f9e77fe":"code","ba888410":"code","fa403c6f":"code","12b4cb4c":"code","67ee1204":"code","06471cd1":"code","688fc5c6":"code","e71920d8":"code","71d2ba3a":"code","cd0394c7":"markdown","647b7116":"markdown","f3b4469d":"markdown","894894f8":"markdown","3932aaad":"markdown"},"source":{"2abdc56a":"import pandas as pd\nimport numpy as np\n\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm, skew\nplt.rc(\"font\", size=14)\n\nimport seaborn as sns\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","fd5883a8":"warnings.filterwarnings(\"ignore\")\nempData=pd.read_csv(r\"..\/input\/HR-Employee-Attrition.csv\",header=0)\n#empData.head()\nempData.shape\n","63285944":"print(list(empData.columns))","6fcf66cc":"empData.head()","f0eee216":"#empData.drop(['EmployeeNumber'],axis=1,inplace=True)\n#Dropped Emp Number, which is not required for analysis","dba0a96d":"empData.describe().T","19fb6514":"empData.columns.groupby(empData.dtypes)","0a46b91d":"empData.info()","604db909":"\nisnaa=empData.isna().sum()\nisnaa\n\n\n","eff9bb79":"empData.duplicated().sum()","6660c602":"\"\"\"\n(mu, sigma) = norm.fit(empData.loc[empData['Attrition'] == 'Yes', 'Age'])\nprint(\"Ave age of emp left the organization : \",mu)\n(mu, sigma) = norm.fit(empData.loc[empData['Attrition'] == 'No', 'Age'])\nprint(\"Ave age of emp in the organization : \",mu)\n\"\"\"","e15ceaa1":"empData['EducationField'].unique()\n","9ae36ac7":"ed_field=empData['EducationField'].unique()\ned_field\nfor i in ed_field:\n    ratio = empData.loc[empData['EducationField'] == i,'Attrition'].shape[0]\/empData.loc[empData['Attrition'] == 'Yes'].shape[0]\n    print(\"Attrition Rate for EduField {0}:\\t {1}\".format(i,ratio))","06f0c9ae":"#empData.Gender.value_counts()\ned_field=empData['Gender'].unique()\ned_field\nfor i in ed_field:\n    ratio = (empData.loc[empData['Gender'] == i,'Attrition'].shape[0])\/(empData.loc[empData['Attrition'] == 'Yes'].shape[0])\n    print(\"Attrition Rate for {0}: {1}\".format(i,ratio))\n    \n# Changing the Attrition Rate \nempDataAna = empData.copy()\nempDataAna['Target'] = empDataAna['Attrition'].apply(\n    lambda x: 0 if x == 'No' else 1)    \n\n\n\n","0cfcf1d2":"empData.head()","df75d85d":"empData['JobSatisfaction'].value_counts()\n\n\n\n\n#for i in empData['EnvironmentSatisfaction'].unique():\n    #ratio = df_HR[(df_HR['EnvironmentSatisfaction']==field)&(df_HR['Attrition']==\"Yes\")].shape[0] \/ df_HR[df_HR['EnvironmentSatisfaction']==field].shape[0]\n    #ratio = empData.loc[empData['EnvironmentSatisfaction'] == i ,empData['Attrition'] == 'Yes'].shape(0) \/ empData.loc[empData['EnvironmentSatisfaction'] == i].shape(0)\n    \n #   empData[empData['EnvironmentSatisfaction'] == i ,'Attrition'].shape(0)\n    \n    \n    \n    ","550bab52":"empDataAna.columns","722ea1a8":"# Dropping columns which are not significant\nempDataAna = empDataAna.drop(['Attrition', 'EmployeeCount', 'EmployeeNumber', 'StandardHours','Over18'], axis=1)\nempDataAna.head()\n\n\n","c29826cc":"empDataAna.corr()['Target'].sort_values()","512899fb":"num_cols = empDataAna.select_dtypes(include = np.number)\na = num_cols[num_cols.columns].hist(bins=15, figsize=(15,35), layout=(9,3),color = 'blue',alpha=0.6)","9c33a36f":"cat_cols = empDataAna.select_dtypes(exclude=np.number)","8a43647e":"\"\"\"\nfig, ax = plt.subplots(4, 2, figsize=(20, 20))\nfor variable, subplot in zip(cat_col, ax.flatten()):\n    sns.countplot(empDataAna[variable], ax=subplot,palette = 'Set3')\n    for label in subplot.get_xticklabels():\n        label.set_rotation(360)\nplt.tight_layout()\n\"\"\"","064f7a26":"\"\"\"\ncorr = data.drop(columns=['StandardHours','EmployeeCount']).corr()\ncorr.style.background_gradient(cmap='YlGnBu')\n\"\"\"","02effdc5":"print(\"Cat Columns --- {0} and Count ---- {1} \".format(cat_cols.columns,cat_cols.columns.shape[0]))\n\n","b07a693c":"num_cols = empDataAna.select_dtypes(include = np.number)\nprint(\"Num Columns --- {0} and Count ---- {1} \".format(num_cols.columns,num_cols.columns.shape[0]))","d32097e8":"# ENCODING CAT COLUMNS...\ncat_col_encoded = pd.get_dummies(cat_cols)\ncat_col_encoded.head()","2e7ba62d":"empDatafin = pd.concat([num_cols,cat_col_encoded,],axis=1)\nempDatafin.head()\n\n","9f9e77fe":"x = empDatafin.drop(columns='Target')\ny = empDatafin['Target']","ba888410":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\nmLogReg = LogisticRegression()\nmLogReg.fit(x_train, y_train)","fa403c6f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nx_train, x_test, y_train, y_test = train_test_split(\nx, y, test_size = 0.3, random_state = 100)\ny_train=np.ravel(y_train)\ny_test=np.ravel(y_test)","12b4cb4c":"for i in range(25):\n    K = i+1\n    neigh = KNeighborsClassifier(n_neighbors = K, weights='uniform', algorithm='auto')\n    neigh.fit(x_train, y_train) \n    y_pred = neigh.predict(x_test)\n    print (\"Accuracy : {0}% for K-Value {1}\".format(accuracy_score(y_test,y_pred)*100,K))","67ee1204":"accuracy_dict = {}\naccuracy_list = []\nfor k in range(1,39):\n    model = KNeighborsClassifier(n_neighbors = k,weights='uniform', algorithm='auto').fit(x_train,y_train)\n    Y_predict = model.predict(x_test)\n    accuracy = metrics.accuracy_score(y_test,Y_predict)\n    accuracy_dict.update({k:accuracy})\n    accuracy_list.append(accuracy)\n    print(\"Accuracy ---> k = {} is {}\" .format(k,accuracy))","06471cd1":"\nkey_max = max(accuracy_dict.keys(), key=(lambda k: accuracy_dict[k]))\n\nprint( \"The Accuracy value is \",accuracy_dict[key_max], \"with k= \", key_max)","688fc5c6":"elbow_curve = pd.DataFrame(accuracy_list,columns = ['accuracy'])","e71920d8":"elbow_curve.plot()","71d2ba3a":"\"\"\"\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, mLogReg.predict(x_test))\nfpr, tpr, thresholds = roc_curve(y_test, mLogReg.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()\n\"\"\"","cd0394c7":"**ENCODING**","647b7116":"**ANALYSIS**","f3b4469d":"**Basic Infering with plots**","894894f8":"**ROC CURVE**","3932aaad":"Correlation Between Target and other variables"}}