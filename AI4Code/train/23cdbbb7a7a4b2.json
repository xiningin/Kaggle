{"cell_type":{"93134552":"code","9bfce8df":"code","068c99ac":"code","045b04ad":"code","08cb5031":"code","1ffa44ff":"code","71a045b0":"code","181540e3":"code","db509c5b":"code","a9ddab0f":"code","db1aea01":"code","a5f3c25a":"code","73434593":"code","03c9fc7a":"code","a9e3f55a":"code","04a4ad07":"code","46c7f4d2":"code","fd46f099":"code","e0b31a18":"code","7d348eb2":"code","365dc946":"code","e72699b2":"code","166837e2":"code","dd8a2c41":"code","07a4d1c5":"code","ad895914":"code","e48eda6e":"code","cdffb04e":"code","51505aa7":"code","f6d96785":"code","8c948baf":"code","09cb3b64":"code","92e98f74":"code","cbe504a3":"code","63ae1ade":"code","09857afd":"code","10784685":"code","e31dfc5b":"code","7ca1abc1":"code","6852c66e":"code","a89ecdd4":"code","4d5e93b0":"code","05647089":"code","79fb2bfa":"code","9e0e3a19":"code","4e82cda6":"code","503c3651":"code","42040e5f":"code","6b9ef217":"markdown","e1be2c3d":"markdown","309cb1b4":"markdown","f99b80d8":"markdown","ff62f64b":"markdown","2b27541f":"markdown","22d3a742":"markdown","2b22b8c8":"markdown","d2bb053b":"markdown","d6223b84":"markdown","db075926":"markdown","82056eae":"markdown","de9d1fd9":"markdown","45519adb":"markdown","ea019610":"markdown","6b71f600":"markdown","7c073a01":"markdown","5014915f":"markdown","a8041d5c":"markdown","70b6ab5c":"markdown","e1b81128":"markdown","6383c89f":"markdown","b190cbbb":"markdown"},"source":{"93134552":"# imports for data analysis and plot\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# import models to use from sklearn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\n# import fuctions for model evaluation and tuning \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, recall_score, precision_score, plot_roc_curve","9bfce8df":"data = pd.read_csv('\/kaggle\/input\/cardiovascular-disease-dataset\/cardio_train.csv', sep = ';')\ndata","068c99ac":"data.drop(labels = 'id', axis = 1, inplace = True)\ndata","045b04ad":"# Check how many samples of each class there are and plot it \ndata['cardio'].value_counts().plot(kind = 'bar');","08cb5031":"# check datatypes in our data\ndata.info()","1ffa44ff":"# view information about our data\ndata.describe()","71a045b0":"# use pd.crosstab to check the heart disease frequency acording to the gender and plot it\npd.crosstab(data['cardio'], data['gender']).plot(kind = 'bar')\nplt.xlabel('0 = no heart disease, 1 = heart disease')\nplt.legend(['woman','man'])\nplt.show()","181540e3":"data['age'].T.hist(bins = 40)","db509c5b":"corr_matrix = data.corr()\nfig, ax = plt.subplots(figsize = (15,10))\nax = sns.heatmap(\n    corr_matrix, \n    annot = True, \n    linewidths = 0.5,\n    fmt = '0.2f', \n    cmap = 'GnBu'\n)","a9ddab0f":"pd.crosstab(data['smoke'], data['gender']).plot(kind = 'bar')\nplt.xlabel('0 = no smoke, 1 = smoke')\nplt.legend(['woman','man'])\nplt.show()","db1aea01":"# Split data into X and y\nX = data.drop(labels = 'cardio', axis = 1)\ny = data['cardio']","a5f3c25a":"# split the data into training and test datasets\nnp.random.seed(42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","73434593":"np.random.seed(7)\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)","03c9fc7a":"# evaluate the stock model on test data\nclf.score(X_test, y_test)","a9e3f55a":"# grid of hyperparameters to tune\nrandom_forest_grid = {\n    'n_estimators': np.arange(10,1000, 50),\n    'max_depth': [None, 3, 5, 10],\n    'min_samples_split': np.arange(2,20,2),\n    'min_samples_leaf': np.arange(1,20,2)\n}","04a4ad07":"np.random.seed(7)\n\nrandom_search_rf = RandomizedSearchCV(\n    RandomForestClassifier(),\n    param_distributions = random_forest_grid,\n    cv = 5,\n    n_iter = 25,\n    verbose = True,\n    n_jobs = -1\n)\n\n# Fit random search for random forest classifier\nrandom_search_rf.fit(X_train, y_train)","46c7f4d2":"# check wich are the best params\nrandom_search_rf.best_params_","fd46f099":"# evaluate the model on the test data using the score method\nrandom_search_rf.score(X_test, y_test)","e0b31a18":"# make some predictions to calculate evaluation metrics\ny_preds = random_search_rf.predict(X_test)","7d348eb2":"y_preds","365dc946":"plot_roc_curve(random_search_rf, X_test, y_test);","e72699b2":"# make a fucntion for ploting the confussion matrix for later use\nsns.set(font_scale = 1.5)\ndef conf_matrix(y_true, y_preds):\n    fig, ax = plt.subplots(figsize = (5,5))\n    ax = sns.heatmap(\n        confusion_matrix(y_true,y_preds),\n        annot=True,\n        cbar = False,\n        fmt = 'g'\n    ) \n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')","166837e2":"# plotting the confusion matrix of our randomforestclassifier model\nconf_matrix(y_test,y_preds)","dd8a2c41":"print(classification_report(y_test, y_preds))","07a4d1c5":"# Check the best params for the RandomForestClassifier\nrandom_search_rf.best_params_","ad895914":"# Create a RandomForestClassifier instance with the best params\nrf_clf = RandomForestClassifier(\n    n_estimators = 910,\n    min_samples_split = 4,\n    min_samples_leaf = 15,\n    max_depth = 10\n)","e48eda6e":"# Use cross_validation and the scoring parameter to evaluate the classifier and make a function for later use\ndef cv_classification_report(classifier, X, y):\n    \n    cv_accuracy = cross_val_score(classifier, X, y, scoring = 'accuracy', n_jobs = -1)\n    cv_accuracy = np.mean(cv_accuracy)\n    \n    cv_precision = cross_val_score(classifier, X, y, scoring = 'precision', n_jobs = -1)\n    cv_precision = np.mean(cv_precision)\n    \n    cv_recall = cross_val_score(classifier,X,y,scoring = 'recall', n_jobs = -1)\n    cv_recall = np.mean(cv_recall)\n    \n    cv_f1 = cross_val_score(classifier, X, y, scoring = 'f1', n_jobs = -1)\n    cv_f1 = np.mean(cv_f1)\n    \n    return {\n    'Accuracy': cv_accuracy,\n    'Precision': cv_precision,\n    'Recall': cv_recall,\n    'F1 Score': cv_f1\n    }","cdffb04e":"# use the function\ncv_metrics = cv_classification_report(rf_clf, X, y)","51505aa7":"# view the cross-validated metrics\ncv_metrics","f6d96785":"# save the metrics in a pandas dataframe and plot it in a bar graph\n# the variable name is for 'cross-validated random forest classifier metrics'\ncv_rfc_metrics_df = pd.DataFrame(cv_metrics, index = [0]) \n\nsns.set(font_scale = 1.3)\n\ncv_rfc_metrics_df.T.plot.bar(title = 'Cross-validated random forest classifier metrics', legend = False)\nplt.yticks(np.linspace(0,1,11));","8c948baf":"# create an instance of the scaler\nstd = StandardScaler()\n\n# use StandardScaler to scale X\nX_scaled = std.fit_transform(X)","09cb3b64":"# split into train and test datasets (The s in the varible names is for scaled)\nX_train_s, X_test_s, y_train, y_test = train_test_split(X_scaled, y)","92e98f74":"lr_stock = LogisticRegression()\nlr_stock.fit(X_train_s, y_train)","cbe504a3":"# Evaluate the stock model on the test data using the scoring method\nlr_stock.score(X_test_s, y_test)","63ae1ade":"# grid with hyperparameters to tune\nlogistic_regression_grid = {\n    'C': np.logspace(-4,4,20),\n    'solver': ['liblinear']\n}\n\nrs_logistic_regression = RandomizedSearchCV(\n    LogisticRegression(),\n    param_distributions = logistic_regression_grid,\n    cv = 5,\n    n_iter = 20,\n    verbose = True,\n    n_jobs = -1\n)\n\n# Fit the random hyperparameter search for logistic regression\nrs_logistic_regression.fit(X_train_s, y_train)","09857afd":"# check the best hyperparameters\nrs_logistic_regression.best_params_","10784685":"# evaluate the model on the test data using the score method\nrs_logistic_regression.score(X_test_s, y_test)","e31dfc5b":"# make a logistic regression classifier model with the best params\nlr_clf = LogisticRegression(\n    solver = 'liblinear',\n    C =  29.763514416313132\n)\n\n# Fit the model\nlr_clf.fit(X_train_s, y_train)","7ca1abc1":"# make predictions on test data to evaluate\nlr_y_preds = lr_clf.predict(X_test_s)\nlr_y_preds","6852c66e":"plot_roc_curve(lr_clf, X_test_s, y_test);","a89ecdd4":"conf_matrix(y_test,lr_y_preds)","4d5e93b0":"print(classification_report(y_test,lr_y_preds))","05647089":"cv_lr_metrics = cv_classification_report(lr_clf, X_test_s, y_test)","79fb2bfa":"cv_lr_metrics","9e0e3a19":"# save the metrics in a pandas dataframe and plot it in a bar graph\ncv_lr_metrics_df = pd.DataFrame(cv_lr_metrics, index = [0]) \n\nsns.set(font_scale = 1.3)\n\ncv_lr_metrics_df.T.plot.bar(title = 'Cross-validated logistic regression classifier metrics', legend = False)\nplt.yticks(np.linspace(0,1,11));","4e82cda6":"# evaluation metrics for the random forest classifier\ncv_rfc_metrics_df","503c3651":"# evaluation metrics for the logistic regression classifier\ncv_lr_metrics_df","42040e5f":"rf_clf","6b9ef217":"## Model comparison\nNow that we have 2 classifiers, one random forest classifier and one logistic regression we should compare both of them, and we have the cross validated metrics for each model in 2 variables:","e1be2c3d":"### Evaluating the RandomForestClassifier model","309cb1b4":"### We can se a positive correlation betweeen the gender an if the patient smoke or not, lets see it in a bar graph ","f99b80d8":"#### We can se that it is more common for women to have heart disease in this dataset \n\n### View the distribution of the age using a histogram (remember that the age is in days)","ff62f64b":"### Create and fit a stock random forest classifier","2b27541f":"### ROC curve and Area under the curve","22d3a742":"### Make a correlation matrix and plot it using seaborn ","2b22b8c8":"### ROC curve and Area under the curve\nAUC of 0.8 is acceptable, but not exellent ","d2bb053b":"### Confusion matrix","d6223b84":"### Improving this score tuning the hyperparameters with `RandomizedSearchCV()`","db075926":"### Import the data and view it","82056eae":"### Classification Report ","de9d1fd9":"I accept any type of criticism or comment about the code, it is my first project here in kaggle\n\n\n# Predicting heart disease with Sklearn\n\nThis notebook uses python and many helpful libraries to predict whether or not a patient has heart disease training a machine learning model with the dataset from https:\/\/www.kaggle.com\/sulianova\/cardiovascular-disease-dataset\n\n## Data and features\nData description\nThere are 3 types of input features:\n\nObjective: factual information;\nExamination: results of medical examination;\nSubjective: information given by the patient.\nFeatures:\n\n- Age: Objective Feature | age | int (days)\n- Height: Objective Feature | height | int (cm) |\n- Weight: Objective Feature | weight | float (kg) |\n- Gender: Objective Feature | gender | categorical code | 1 - women, 2 - men\n- Systolic blood pressure: Examination Feature | ap_hi | int |\n- Diastolic blood pressure: Examination Feature | ap_lo | int |\n- Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n- Glucose: Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n- Smoking: Subjective Feature | smoke | binary |\n- Alcohol intake: Subjective Feature | alco | binary |\n- Physical activity: Subjective Feature | active | binary |\n- Presence or absence of cardiovascular disease: Target Variable | cardio | binary | 1 = disease, 0 = no disease","45519adb":"### Evaluating the Logistic regression model","ea019610":"### Drop the `id` column, because is useless","6b71f600":"We can se that both models are so close, but in every metric the RandomForestClassifier wins over the Logistic Regression\n\nThe RandomForestClassifier model is still in a variable:","7c073a01":"### Making a confussion matrix and ploting it using `sns.heatmap`","5014915f":"### Lets improve the model tuning the hyperparameters using RandomizedSearchCV","a8041d5c":"### Evaluation metrics calculated using cross validation","70b6ab5c":"#### In this notebook we are going to build, test and tune 2 sklearn machine learning models\n - `RandomForestClassifier()`\n - `LogisticRegression()`","e1b81128":"### Create and fit a stock LogisticRegression classifier\n\n#### Preprocing the data\nGradientDecent based model requiere data to be scaled","6383c89f":"The confusion matrix shows a high number of false-negative predictions, lets see the precision predicting each category with a classification report:\n\n### Classification report","b190cbbb":"#### In proportion, there are many more male smokers than female smokers \n\n## Creating models"}}