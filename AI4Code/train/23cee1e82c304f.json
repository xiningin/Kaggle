{"cell_type":{"a22ff82f":"code","3de7843a":"code","008173ed":"code","58147643":"code","974635fa":"code","14082c08":"code","e32000e7":"code","de2653a2":"code","d0524cd0":"code","2733b54c":"code","1d86f32b":"code","3a56447c":"code","01039a89":"code","2db7e1f3":"code","1dac7000":"code","b4e1dc34":"code","53151f34":"code","06bb4790":"code","68213054":"code","38f796b5":"code","1a595ee3":"code","03395383":"code","a009ea5e":"code","75e81e89":"code","82d08ccd":"code","998bc65b":"code","03c4449e":"code","a744db39":"code","d997cc5a":"code","78b457a3":"code","5656a190":"markdown","8d71c1ef":"markdown","f5775930":"markdown","d9ad0d8b":"markdown","566bcd5c":"markdown","bb4972e1":"markdown","92423d7e":"markdown","84a578f7":"markdown","bb69df1f":"markdown","3a05b5eb":"markdown","d0f29b1c":"markdown","b08b24da":"markdown","fac440ef":"markdown","0d8770b7":"markdown","700721dc":"markdown","eef1038b":"markdown","2801008b":"markdown","7884c9e6":"markdown"},"source":{"a22ff82f":"import tensorflow as tf \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport os\nimport cv2\ntf.__version__","3de7843a":"img_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n                            #rotation_range=90,\n                            brightness_range=(0.5,1), \n                            #shear_range=0.2, \n                            #zoom_range=0.2,\n                            channel_shift_range=0.2,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            rescale=1.\/255,\n                            validation_split=0.3)","008173ed":"root_dir = '..\/input\/is-that-santa-image-classification\/is that santa\/train'\n\nimg_generator_flow_train = img_generator.flow_from_directory(\n    directory=root_dir,\n    target_size=(224, 224),\n    batch_size=16,\n    shuffle=True,\n    subset=\"training\")\n\nimg_generator_flow_valid = img_generator.flow_from_directory(\n    directory=root_dir,\n    target_size=(224, 224),\n    batch_size=16,\n    shuffle=True,\n    subset=\"validation\")","58147643":"test_dir = '..\/input\/is-that-santa-image-classification\/is that santa\/test'\n\nimg_generator_flow_test = img_generator.flow_from_directory(\n    directory=root_dir,\n    target_size=(224, 224),\n    batch_size=16,\n    shuffle=True,\n    )","974635fa":"data_dir='..\/input\/is-that-santa-image-classification\/is that santa\/train'\nNames0 = os.listdir(data_dir)\nNames=sorted(Names0)\nprint(Names)\nprint(len(Names))","14082c08":"N=list(range(len(Names)))\nnormal_mapping=dict(zip(Names,N))\nreverse_mapping=dict(zip(N,Names))","e32000e7":"imgs, labels = next(iter(img_generator_flow_train))\nfor img, label in zip(imgs, labels):\n    plt.imshow(img)\n    #plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n    value=np.argmax(label)\n    plt.title(reverse_mapping[value])\n    plt.show()","de2653a2":"base_model = tf.keras.applications.InceptionV3(input_shape=(224,224,3),\n                                               include_top=False,\n                                               weights = \"imagenet\"\n                                               )","d0524cd0":"base_model.trainable = False","2733b54c":"model = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(len(Names), activation=\"softmax\")\n])","1d86f32b":"model.summary()","3a56447c":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n              loss = tf.keras.losses.CategoricalCrossentropy(),\n              metrics = [tf.keras.metrics.CategoricalAccuracy()])","01039a89":"model.fit(img_generator_flow_train, \n          validation_data=img_generator_flow_valid, \n          steps_per_epoch=8, epochs=40) #8,64","2db7e1f3":"# Visualise train \/ Valid Accuracy\nplt.plot(model.history.history[\"categorical_accuracy\"], c=\"r\", label=\"train_accuracy\")\nplt.plot(model.history.history[\"val_categorical_accuracy\"], c=\"b\", label=\"test_accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()","1dac7000":"# Visualise train \/ Valid Loss\nplt.plot(model.history.history[\"loss\"], c=\"r\", label=\"train_loss\")\nplt.plot(model.history.history[\"val_loss\"], c=\"b\", label=\"test_loss\")\nplt.legend(loc=\"upper left\")\nplt.show()","b4e1dc34":"imgs, labels = next(iter(img_generator_flow_valid))\ntimgs, tlabels = next(iter(img_generator_flow_test))","53151f34":"for layer in model.layers:\n    print(layer.name)","06bb4790":"base_model = model.layers[0]","68213054":"tf.keras.utils.plot_model(base_model, show_shapes=True, show_layer_names=True)","38f796b5":"for layer in base_model.layers:\n    print(layer.name)","1a595ee3":"last_conv_layer_name = \"mixed10\"\nclassifier_layer_names = [layer.name for layer in model.layers][1:]","03395383":"# We start by setting up the dependencies we will use\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Display\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","a009ea5e":"# The Grad-CAM algorithm\ndef get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(\n    img_array, base_model, model, last_conv_layer_name, classifier_layer_names):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer\n    last_conv_layer = base_model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = keras.Model(base_model.inputs, last_conv_layer.output)\n\n    # Second, we create a model that maps the activations of the last conv\n    # layer to the final class predictions\n    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = keras.Model(classifier_input, x)\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        # Compute activations of the last conv layer and make the tape watch it\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        tape.watch(last_conv_layer_output)\n        # Compute class predictions\n        preds = classifier_model(last_conv_layer_output)\n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n\n    # This is the gradient of the top predicted class with regard to\n    # the output feature map of the last conv layer\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n    # The channel-wise mean of the resulting feature map\n    # is our heatmap of class activation\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap","75e81e89":"# Print what the top predicted class is\npreds = model.predict(imgs)\npred_labels = tf.argmax(preds, axis = -1)\n\nprint(\"Prediction output:\", preds)\nprint(\"Predicted label:\", pred_labels)","82d08ccd":"# Print what the top predicted class is\ntpreds = model.predict(timgs)\ntpred_labels = tf.argmax(tpreds, axis = -1)\n\nprint(\"Prediction output:\", tpreds)\nprint(\"Predicted label:\", tpred_labels)","998bc65b":"# Generate class activation heatmap\nheatmaps = []\n\nfor img in imgs:\n    heatmap = make_gradcam_heatmap(\n    tf.expand_dims(img,axis=0),\n        base_model, model, \n        last_conv_layer_name, \n        classifier_layer_names\n  )\n    heatmaps.append(heatmap)\n\n\n# Display heatmap\nplt.matshow(heatmaps[0])\nplt.show()\n","03c4449e":"from pathlib import Path\n\nfor img, pred_label, true_label, heatmap in zip(imgs, pred_labels, labels, heatmaps): \n    # We rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # We use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # We use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # We create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * 0.003 + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    save_path = \"saved_img.jpg\"\n    superimposed_img.save(save_path)\n\n    # Display Grad CAM\n    pred_file_path = np.argmax(img_generator_flow_valid.labels == pred_label)\n    pred_label_name = Path(img_generator_flow_valid.filepaths[pred_file_path]).parent.name\n\n    true_file_path = np.argmax(img_generator_flow_valid.labels == tf.argmax(true_label))\n    true_label_name = Path(img_generator_flow_valid.filepaths[true_file_path]).parent.name\n\n    print(\"Predicted label:\",pred_label_name)\n    print(\"True label:\", true_label_name)\n\n    display(Image(save_path))","a744db39":"LABEL=[]\nfor item in tlabels:\n    LABEL+=[np.argmax(item)]\nPRED=tpred_labels.numpy().tolist()","d997cc5a":"print(LABEL)\nprint(PRED)","78b457a3":"from sklearn.metrics import classification_report\nprint(classification_report(LABEL,PRED))","5656a190":"### Compile model","8d71c1ef":"# Transfer Learning ","f5775930":"### Train the model","d9ad0d8b":"### Import a pretrained model\nhttps:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications\/InceptionV3","566bcd5c":"# Santa Image Transfer Learning\nhttps:\/\/www.kaggle.com\/stpeteishii\/santa-classification-transfer-learning<br\/>\n<div align=\"left\">\n<img src=\"https:\/\/img.shields.io\/badge\/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle\" alt=\"upvote\">\n<\/div>","bb4972e1":"### Set the weights of the imported model","92423d7e":"### Visualize accuracy and loss","84a578f7":"### make_gradcam_heatmap","bb69df1f":"### Create model","3a05b5eb":"### Create imgs and labels","d0f29b1c":"### Prepare ImageDataGenerator\nhttps:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator","b08b24da":"### Visualize a batch of images","fac440ef":"### Prepare img_generator_flow","0d8770b7":"### Create heatmap","700721dc":"### Predict","eef1038b":"# Interpretation with Grad Cam\n","2801008b":"# Preprocessing with ImageDataGenerator","7884c9e6":"### Predicted label and heatmap"}}