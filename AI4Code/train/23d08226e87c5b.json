{"cell_type":{"4afe0aa6":"code","18cf6a66":"code","4797929a":"code","b87f0753":"code","81f55b99":"code","a6b7e077":"code","4adea841":"code","38c8c78e":"code","9d7f6579":"code","f7bc7837":"code","97b7319a":"code","6b9700fa":"code","97d02fde":"code","8cf528df":"code","e4ff5b5f":"code","150ae65f":"code","f08f0a37":"code","30110144":"code","8dee2e10":"code","29af179d":"code","8627c8dd":"code","f240fb7d":"code","31635d5d":"code","1abb64bd":"markdown","8e7ca6d8":"markdown","00094872":"markdown"},"source":{"4afe0aa6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18cf6a66":"import os\nimport shutil\nimport re\nimport requests\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.applications import DenseNet169, VGG16, Xception, ResNet152V2\nimport tensorflow.image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy","4797929a":"def plot_history(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\n    \n    ax[0].plot(epochs, acc, 'bo', label='\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f')\n    ax[0].plot(epochs, val_acc, 'b', label='\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438')\n    ax[0].set_title('\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c (accuracy)')\n    ax[0].legend()\n    ax[0].grid()\n\n    ax[1].plot(epochs, loss, 'bo', label='\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f')\n    ax[1].plot(epochs, val_loss, 'b', label='\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438')\n    ax[1].set_title('\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c')\n    ax[1].legend()\n    ax[1].grid()","b87f0753":"import zipfile\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\",\"r\") as z:\n    z.extractall(\".\") ","81f55b99":"# Retrieving a list of directories in each folder\n\nDIR_TRAIN = \"\/kaggle\/working\/train\/\"\nDIR_TEST = \"\/kaggle\/working\/test1\"\n\ntrain_imgs = os.listdir(DIR_TRAIN)\ntest_imgs = os.listdir(DIR_TEST)","a6b7e077":"image = load_img(\"\/kaggle\/working\/train\/\"+ \"dog.10008.jpg\")\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()","4adea841":"# Creating a DataFrame for our train set\n\ncategory = [x.split(\".\")[0] for x in train_imgs]\ndf = pd.DataFrame({\"Filename\":train_imgs, \"Category\":category})\ndf.head()","38c8c78e":"df_train, df_test = train_test_split(df, test_size = 7500, \n                                     stratify=df['Category'],\n                                     random_state=42)","9d7f6579":"df_train['Category'].value_counts()","f7bc7837":"df_test['Category'].value_counts()","97b7319a":"train_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n        df_train,\n        directory = DIR_TRAIN,\n        x_col = 'Filename',\n        y_col = 'Category',\n        target_size = (200, 200),\n        class_mode = 'binary',\n        batch_size = 20)\n\ntest_generator = test_datagen.flow_from_dataframe(\n        df_test,\n        directory = DIR_TRAIN,\n        x_col = 'Filename',\n        y_col = 'Category',\n        target_size = (200, 200),\n        class_mode = 'binary',\n        batch_size = 20)\n\n","6b9700fa":"model = Sequential()\nmodel.add(Conv2D(8, (3, 3), padding='SAME', activation='relu',\n                        input_shape=(200, 200, 3)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(16, (3, 3), padding='SAME', activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","97d02fde":"model.summary()","8cf528df":"model.compile(loss='binary_crossentropy',\n              optimizer=Adam(learning_rate=2e-4),\n              metrics=['acc'])","e4ff5b5f":"history_baseline = model.fit(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=30,\n      validation_data=test_generator,\n      validation_steps=50)","150ae65f":"plot_history(history_baseline)","f08f0a37":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n        df_train,\n        directory = DIR_TRAIN,\n        x_col = 'Filename',\n        y_col = 'Category',\n        target_size = (200, 200),\n        class_mode = 'binary',\n        batch_size = 20)\n\ntest_generator = test_datagen.flow_from_dataframe(\n        df_test,\n        directory = DIR_TRAIN,\n        x_col = 'Filename',\n        y_col = 'Category',\n        target_size = (200, 200),\n        class_mode = 'binary',\n        batch_size = 20)","30110144":"for data_batch, labels_batch in train_generator:\n    print('data batch shape:', data_batch.shape)\n    print('labels batch shape:', labels_batch.shape)\n    break","8dee2e10":"model = models.Sequential()\nmodel.add(layers.Conv2D(8, (3, 3), padding='SAME', activation='relu',\n                        input_shape=(200, 200, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(16, (3, 3), padding='SAME', activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","29af179d":"model.summary()","8627c8dd":"model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(learning_rate=2e-4),\n              metrics=['acc'])","f240fb7d":"history_augmentation = model.fit(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=140,\n      validation_data=test_generator,\n      validation_steps=50)","31635d5d":"plot_history(history_augmentation)","1abb64bd":"# \u0414\u043e\u043c\u0430\u0448\u043d\u044f\u044f \u0440\u0430\u0431\u043e\u0442\u0430 \u21164\n\n# \u0412\u044b\u043f\u043e\u043b\u043d\u0438\u043b: \u041b\u043e\u0431\u0430\u043d\u043e\u0432 \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440","8e7ca6d8":"### \u0417\u0430\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435\n\n\u0421\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f accuracy \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 (history_baseline) \u0438 \u043d\u0430 \u043c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 (history_augmentation), \u043c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434, \u0447\u0442\u043e \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0440\u0438 \u043f\u043e\u043c\u043e\u0449\u0438 \u043f\u0440\u0438\u0435\u043c\u0430 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u0430 \u0443\u0441\u043f\u0435\u0448\u043d\u0430. \n\n> \u0417\u043d\u0430\u0447\u0435\u043d\u0438\u044f accuracy \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0443\u043b\u0443\u0447\u0448\u0438\u043b\u043e\u0441\u044c: \n* Accuracy \u043d\u0430 history_baseline: 0.7730\n* Accuracy \u043d\u0430 history_augmentation: 0.8840","00094872":"### \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438"}}