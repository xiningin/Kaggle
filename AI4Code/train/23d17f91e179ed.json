{"cell_type":{"f4d9d809":"code","6651e07d":"code","3173082d":"code","0a4d7354":"code","abeacd0a":"code","68051471":"code","ce31349a":"code","9956ad90":"code","993ec040":"code","97b80228":"code","694448e5":"code","e53cb2ff":"code","8e7cd468":"code","94b14de5":"code","14f7d557":"code","78008adf":"code","0c50c3fd":"code","d2f94d2c":"code","d986ee94":"code","c88bf1c4":"markdown","e32aff62":"markdown"},"source":{"f4d9d809":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams['figure.dpi'] = 300\nfrom IPython.display import Image \nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.externals.six import StringIO  \nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\n\nimport itertools\nimport seaborn as sns\nimport os\nprint(os.listdir('..\/input\/Kannada-MNIST'))","6651e07d":"train_df = pd.read_csv('..\/input\/Kannada-MNIST\/train.csv')\ntest_df = pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')\ndig_df = pd.read_csv('..\/input\/Kannada-MNIST\/Dig-MNIST.csv')","3173082d":"print(train_df.shape)\ntrain_df.head()","0a4d7354":"test_df = test_df.drop(['id'], axis=1)","abeacd0a":"sns.countplot(train_df['label'])\nplt.show()","68051471":"\nx_train = (train_df.iloc[:,1:].values).astype('float32')\ny_train = train_df.iloc[:,0].values.astype('int32')\nx_test = test_df.values.astype('float32')\n","ce31349a":"plt.figure(figsize=(8,8))\n\nx, y = 5, 4\nfor i in range(20):  \n    plt.subplot(y, x, i+1)\n    plt.title(str(y_train[i]))\n    plt.axis('off')\n    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')\nplt.show()","9956ad90":"plt.figure(figsize=(8,8))\n\nx, y = 5, 4\nfor i in range(20):  \n    plt.subplot(y, x, i+1)\n    #plt.title(str(y_train[i]))\n    plt.axis('off')\n    plt.imshow(x_test[i].reshape((28,28)),interpolation='nearest')\nplt.show()","993ec040":"concat_df = pd.concat([train_df, test_df])","97b80228":"features = [col for col in train_df.columns if col.startswith('pixel')]\nX_train, X_val, y_train, y_val = train_test_split(train_df[features], train_df['label'], test_size=0.25, random_state=42)","694448e5":"def acc(y_true, y_pred):\n    return round(accuracy_score(y_true, y_pred) * 100, 2)\n\nclf = DecisionTreeClassifier(max_depth=10, random_state=42)\nclf.fit(X_train, y_train)\n\ntrain_preds_baseline = clf.predict(X_train)\nval_preds_baseline = clf.predict(X_val)\nacc_baseline_train = acc(train_preds_baseline, y_train)\nacc_baseline_val = acc(val_preds_baseline, y_val)\n\nprint(f'Training accuracy for our baseline (using all pixel features): {acc_baseline_train}%')\nprint(f'Validation accuracy for our baseline (using all pixel features): {acc_baseline_val}%')","e53cb2ff":"tsvd = TruncatedSVD(n_components=50).fit_transform(concat_df[features])","8e7cd468":"tsvd_cols = [f'component_{i+1}' for i in range(50)]\ntsvd_train = pd.DataFrame(tsvd[:len(train_df)], columns=[tsvd_cols])\ntsvd_test = pd.DataFrame(tsvd[len(train_df):], columns=[tsvd_cols])","94b14de5":"X_train, X_val, y_train, y_val = train_test_split(tsvd_train, \n                                                  train_df['label'], \n                                                  test_size=0.25, \n                                                  random_state=42)","14f7d557":"# Train model with t-svd features\nclf = DecisionTreeClassifier(max_depth=10, random_state=42)\nclf.fit(X_train, y_train)","78008adf":"train_preds = clf.predict(X_train)\nval_preds = clf.predict(X_val)\nacc_tsvd_train = acc(train_preds, y_train)\nacc_tsvd_val = acc(val_preds, y_val)\nprint(f'Training accuracy with TSVD features (50 components): {acc_tsvd_train}%')\nprint(f'Validation accuracy with TSVD features (50 components): {acc_tsvd_val}%')\n# Check out how it performed compared to the baseline\nacc_diff = round(acc_tsvd_val - acc_baseline_val, 2)\nprint(f'\\nThis is a difference of {acc_diff}% in validation accuracy compared to the baseline.')","0c50c3fd":"%%time\ntsne = TSNE()\ntransformed = tsne.fit_transform(tsvd)  ","d2f94d2c":"tsne_train = pd.DataFrame(transformed[:len(train_df)], columns=['component1', 'component2'])\ntsne_test = pd.DataFrame(transformed[len(train_df):], columns=['component1', 'component2'])","d986ee94":"plt.figure(figsize=(14, 14))\nplt.title(f\"Visualization of t-SNE results on the MNIST Dataset\\n\\\nAmount of datapoints = {len(tsne_train)}\", fontsize=20, weight='bold')\nsns.scatterplot(\"component1\", \"component2\", \n                data=tsne_train, hue=train_df['label'], \n                palette=\"Set1\", legend=\"full\", alpha=0.6)\n\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlabel(\"Component 1\", fontsize=16)\nplt.ylabel(\"Component 2\", fontsize=16)\nplt.legend(fontsize=16)\nplt.show()","c88bf1c4":"- T-SNE code from this kernel https:\/\/www.kaggle.com\/carlolepelaars\/97-on-mnist-with-a-single-decision-tree-t-sne \n\n- If you want to get better score on leaderboard, I would recommend you to study https:\/\/www.kaggle.com\/c\/digit-recognizer this competition first! \n- Same model can get better score on kannada-mnist dataset than digit-recognizer dataset","e32aff62":"## T_SNE"}}