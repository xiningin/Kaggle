{"cell_type":{"8db391ed":"code","50b5aa56":"code","e97f8cfb":"code","d6fd0106":"code","c1dcb9f6":"code","0871ebe8":"code","c8929a5b":"code","4881ecf6":"code","bc920bb4":"code","79fa3455":"code","c06a0b55":"code","1bb2cd85":"code","efdec536":"code","52ff087b":"code","0214b79e":"code","f2180477":"code","7fc58758":"code","5622b20c":"code","ce3c7239":"code","0501670f":"code","9b46a7b8":"code","371602a1":"markdown","0de9cc92":"markdown","884be669":"markdown","7c2d7e01":"markdown","03b9137c":"markdown","2dae9947":"markdown","0b18b6f6":"markdown","d9964460":"markdown","e1ef9e7b":"markdown","ef6cbd94":"markdown","b273c04d":"markdown","a1e03821":"markdown"},"source":{"8db391ed":"# Import numpy, pandas, and matplotlib using the standard aliases.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Import mpimg from matplotlib.image\nimport matplotlib.image as mpimg\n\n# Import train_test_split from sklearn\nfrom sklearn.model_selection import train_test_split\n\n# Import pickle.\nimport pickle\n\n# Import tensorflow and all needed tools from tensorflow.keras. \nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","50b5aa56":"# Load the training data into a DataFrame named 'train'.\ntrain = pd.read_csv('..\/input\/cifar10-mu\/train.csv', dtype=str)\n\n# Print the shape of the resulting DataFrame.\nprint(train.shape)","e97f8cfb":"# Display the head of the train DataFrame.\ntrain.head()","d6fd0106":"# Display a DataFrame showing the proportion of observations with each \n# possible of the target variable (which is label).\ny_train = train.label\n\n(train.label.value_counts() \/ len(train)).to_frame().sort_index(ascending=True)","c1dcb9f6":"# Sample 16 images from the training set and display these along with their labels.\n# The images should be arranged in a 4x4 grid of subplots. \n# Please set the figure size to (6,6)\n\nsample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(6,6))\n\nfor i, row in sample.iterrows():\n    \n    img = mpimg.imread(f'..\/input\/cifar10-mu\/train_images\/{row.filename}')\n    label = row.label\n    \n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n    \n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","0871ebe8":"# Split the dataframe train into two DataFrames named train_df and valid_df. \n# Use 20% of the data for the validation set. \n# Use stratified sampling so that the label proportions are preserved.\n# Set a random seed for the split.\n\ntrain_df, valid_df = train_test_split(train, test_size=0.2, random_state=1, stratify=train.label)\n\nprint(train_df.shape)\nprint(valid_df.shape)","c8929a5b":"# Create image data generators for both the training set and the validation set. \n# Use the data generators to scale the pixel values by a factor of 1\/255.\n\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\nvalid_datagen = ImageDataGenerator(rescale=1\/255)","4881ecf6":"# Complete the code for the data loaders below. \n\nBATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = '..\/input\/cifar10-mu\/train_images',\n    x_col = 'filename',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)\n\nvalid_loader = train_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = '..\/input\/cifar10-mu\/train_images',\n    x_col = 'filename',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)","bc920bb4":"# Run this cell to determine the number of training and validation batches. \n\nTR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","79fa3455":"# Use this cell to construct a convolutional neural network model. \n# Your model should make use of each of the following layer types:\n#    Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense\n# You can start by mimicking the architecture used in the \n# Aerial Cactus competetition, but you should explore different architectures\n# by adding more layers and\/or adding more nodes in individual layers\n\nnp.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    Conv2D(32,(3,3), activation='relu', padding='same', input_shape=(32,32,3)),\n    Conv2D(32,(3,3), activation='relu', padding='same'),\n    Conv2D(32,(3,3), activation='relu', padding='same'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    BatchNormalization(),\n    \n    Conv2D(64,(3,3), activation='relu', padding='same'),\n    Conv2D(64,(3,3), activation='relu', padding='same'),\n    Conv2D(64,(3,3), activation='relu', padding='same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n    \n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.25),\n    BatchNormalization(),\n    Dense(10, activation='softmax')\n])\n\ncnn.summary()","c06a0b55":"# Define an optimizer and select a learning rate. \n# Then compile the model.\n\nopt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","1bb2cd85":"%%time\n# Complete one or more training runs. \n# Display training curves after each run.\n\nh1 = cnn.fit(\n    x = train_loader,\n    steps_per_epoch = TR_STEPS,\n    epochs = 20,\n    validation_data = valid_loader,\n    validation_steps = VA_STEPS,\n    verbose = 1\n)","efdec536":"history = h1.history\nprint(history.keys())","52ff087b":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\n\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.ylim(0.9,1)\nplt.legend()\n\nplt.tight_layout()\nplt.show()","0214b79e":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","f2180477":"%%time\n\nh2 = cnn.fit(\n    x = train_loader,\n    steps_per_epoch = TR_STEPS,\n    epochs = 20,\n    validation_data = valid_loader,\n    validation_steps = VA_STEPS,\n    verbose = 1\n)","7fc58758":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\n\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.ylim(0.9,1)\nplt.legend()\n\nplt.tight_layout()\nplt.show()","5622b20c":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.00001)","ce3c7239":"%%time\n\nh3 = cnn.fit(\n    x = train_loader,\n    steps_per_epoch = TR_STEPS,\n    epochs = 20,\n    validation_data = valid_loader,\n    validation_steps = VA_STEPS,\n    verbose = 1\n)","0501670f":"for k in history.keys():\n    history[k] += h3.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\n\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.ylim(0.9,1)\nplt.legend()\n\nplt.tight_layout()\nplt.show()","9b46a7b8":"# When you are satisfied with the model you have found, \n# save the model and the combined history dictionary to files.\n# Download these filesto your local device and then upload them \n# as a Kaggle dataset.\ncnn.save('cifar10_model_v01.h5')\npickle.dump(history, open(f'cifar10_history_v01.pk1', 'wb'))","371602a1":"# View Sample of Images","0de9cc92":"# Save Model and History","884be669":"# Label Distribution","7c2d7e01":"# Train Network","03b9137c":"# Data Generators","2dae9947":"# CIFAR 10 Image Classification","0b18b6f6":"# Import Packages","d9964460":"# Load Training DataFrame","e1ef9e7b":"### Training Run #1","ef6cbd94":"### Train Run #3","b273c04d":"# Build Network","a1e03821":"### Training Run #2"}}