{"cell_type":{"b9770b01":"code","b9aa5a9c":"code","6c29e3c7":"code","6905d78d":"code","4c22f39d":"code","8f5377a3":"code","b17668f8":"code","c93a4b27":"code","1040911c":"code","afa8d778":"code","ec5877d1":"code","5ae8a54a":"code","6ad33044":"code","748d838b":"code","9844aff0":"code","62a843d6":"markdown","185d593c":"markdown","2a52a300":"markdown","998dcc0d":"markdown","fa4b2e19":"markdown","1a4daaec":"markdown","13ef8249":"markdown","cae932ea":"markdown","fbeccb09":"markdown","e763fb06":"markdown","d8db44ce":"markdown","1a0f3cac":"markdown","a9f29f5f":"markdown","02d813ab":"markdown","3fa9d830":"markdown","6c913cd9":"markdown","a87314c4":"markdown"},"source":{"b9770b01":"# importaci\u00f3n de paquetes\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn\nimport sklearn.datasets\nimport scipy.io\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (7.0, 4.0) # tama\u00f1o de los gr\u00e1ficos\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'","b9aa5a9c":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\/\"]).decode(\"utf8\"))","6c29e3c7":"from shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/scriptstaller7\/testCases.py\", dst = \"..\/working\/testCases.py\")\ncopyfile(src = \"..\/input\/scriptstaller7\/reg_utils.py\", dst = \"..\/working\/reg_utils.py\")\n\n# import all our functions\nfrom reg_utils import sigmoid, relu, plot_decision_boundary, initialize_parameters, predict_dec\nfrom reg_utils import compute_cost, predict, forward_propagation, backward_propagation, update_parameters\nfrom testCases import *","6905d78d":"def load_2D_dataset():\n    data = scipy.io.loadmat('..\/input\/datataller7\/data.mat')\n    train_X = data['X'].T\n    train_Y = data['y'].T\n    test_X = data['Xval'].T\n    test_Y = data['yval'].T\n\n    plt.scatter(train_X[0, :], train_X[1, :], c=train_Y[0,:], s=40, cmap=plt.cm.Spectral);\n    \n    return train_X, train_Y, test_X, test_Y","4c22f39d":"def load_dataset():\n    train_dataset = h5py.File('datasets\/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # entrenamiento\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) \n\n    test_dataset = h5py.File('datasets\/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # prueba\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) \n\n    classes = np.array(test_dataset[\"list_classes\"][:]) # clases\n    \n    train_set_y = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n    \n    train_set_x_orig = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n    test_set_x_orig = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n    \n    train_set_x = train_set_x_orig\/255\n    test_set_x = test_set_x_orig\/255\n\n    return train_set_x, train_set_y, test_set_x, test_set_y, classes\n","8f5377a3":"train_X, train_Y, test_X, test_Y=load_2D_dataset()","b17668f8":"def model(X, Y, learning_rate = 0.3, num_iterations = 30000, print_cost = True, lambd = 0):\n    \"\"\"\n    Implementa la red: LINEAL->RELU->LINEAL->RELU->LINEAL->SIGMOIDE.\n    \n    Input:\n    X: datos de entrada de tama\u00f1o (n_x, n\u00famero de ejemplos)\n    Y: vector de etiquetas (1 para azul y 0 para rojo), observadas de tama\u00f1o (n_y, n\u00famero de ejemplos)\n    learning_rate: tasa de aprendizaje de la regla de actualizaci\u00f3n por G.D. \n    num_iterations: n\u00famero de iteraciones del bucle de optimizaci\u00f3n\n    print_cost: Si es True, muestra el coste cada 10000 iteraciones\n    lambd: (hiper)par\u00e1metro de regularizaci\u00f3n, escalar\n    Output:\n    parameters: par\u00e1metros aprendidos por el modelo, usados para predecir\n    \"\"\"\n        \n    grads = {}\n    costs = []                            # guarda el coste\n    m = X.shape[1]                        # numero de ejemplos\n    layers_dims = [X.shape[0], 20, 3, 1]\n    \n    # Inicializa los par\u00e1metros del diccionario.\n    parameters = initialize_parameters(layers_dims)\n\n    # Bucle (G.D.)\n\n    for i in range(0, num_iterations):\n       \n        #Propagaci\u00f3n hacia delante \n        a3, cache = forward_propagation(X, parameters)\n        \n        # Coste\n        if lambd == 0:\n            cost = compute_cost(a3, Y)\n        else:\n            cost = coste_con_regularizacion(a3, Y, parameters, lambd)\n            \n        # Retro-propagacion\n        if lambd == 0:\n            grads = backward_propagation(X, Y, cache)\n        elif lambd != 0:\n            grads = retropropagacion_con_regularizacion(X, Y, cache, lambd)\n\n        \n        # Actualizaci\u00f3n de par\u00e1metros\n        parameters = update_parameters(parameters, grads, learning_rate)\n        \n        # Imprime la p\u00e9rdida cada 10000 iteraciones\n        if print_cost and i % 10000 == 0:\n            print(\"Coste tras la iteraci\u00f3n {}: {}\".format(i, cost))\n        if print_cost and i % 1000 == 0:\n            costs.append(cost)\n    \n    # grafica el coste\n    plt.plot(costs)\n    plt.ylabel('Coste')\n    plt.xlabel('Iteraciones (x1,000)')\n    plt.title(\"Tasa de aprendizaje =\" + str(learning_rate))\n    plt.show()\n    \n    return parameters","c93a4b27":"parameters = model(train_X, train_Y)\nprint (\"Sobre el entrenamiento:\")\npredictions_train = predict(train_X, train_Y, parameters)\nprint (\"Sobre la prueba:\")\npredictions_test = predict(test_X, test_Y, parameters)","1040911c":"plt.title(\"Modelo sin regularizaci\u00f3n\")\naxes = plt.gca()\naxes.set_xlim([-0.75,0.40])\naxes.set_ylim([-0.75,0.65])\nplot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y.flatten())","afa8d778":"# FUNCI\u00d3N A CALIFICAR: coste_con_regularizacion\n\ndef coste_con_regularizacion(A3, Y, parameters, lambd):\n    \"\"\"\n    Implementa la funci\u00f3n de coste con regularizaci\u00f3n-L2 (ver (2)).\n    Input:\n    A3: post-activaci\u00f3n, salida de la propagaci\u00f3n hacia delante, de dimensiones (tama\u00f1o de salida, n\u00famero de ejemplos)\n    Y: vector de etiquetas, de tama\u00f1o (tama\u00f1o de salida, n\u00famero de ejemplos)\n    parameters: diccionario python con los par\u00e1metros del modelo\n    Salida:\n    cost: valor de la funci\u00f3n de coste regularizada \n    \"\"\"\n    m = Y.shape[1]\n    W1 = parameters[\"W1\"]\n    W2 = parameters[\"W2\"]\n    W3 = parameters[\"W3\"]\n    \n    cross_entropy_cost = compute_cost(A3, Y) # salida de la parte de entrop\u00eda-cruzada del coste\n    \n    ### EMPIEZE EL C\u00d3DIGO AQU\u00cd ### (\u2248 1 l\u00ednea de c\u00f3digo)\n    L2_regularization_cost = \n    ### TERMINE EL C\u00d3DIGO AQU\u00cd ###\n    \n    cost = cross_entropy_cost + L2_regularization_cost\n    \n    return cost","ec5877d1":"A3, Y_assess, parameters = compute_cost_with_regularization_test_case()\n\nprint(\"coste = \" + str(coste_con_regularizacion(A3, Y_assess, parameters, lambd = 0.1)))","5ae8a54a":"# FUNCI\u00d3N A CALIFICAR: retropropagacion_con_regularizacion\n\ndef retropropagacion_con_regularizacion(X, Y, cache, lambd):\n    \"\"\"\n    Implements the backward propagation of our baseline model to which we added an L2 regularization.\n    \n    Arguments:\n    X -- input dataset, of shape (input size, number of examples)\n    Y -- \"true\" labels vector, of shape (output size, number of examples)\n    cache -- cache output from forward_propagation()\n    lambd -- regularization hyperparameter, scalar\n    \n    Returns:\n    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables\n    \"\"\"\n    \n    m = X.shape[1]\n    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache\n    \n    dZ3 = A3 - Y\n    \n    ### EMPIEZE EL C\u00d3DIGO AQU\u00cd ### (\u2248 1 l\u00ednea de c\u00f3digo)\n    dW3 = \n    ### TERMINE EL C\u00d3DIGO AQU\u00cd ###\n    db3 = 1.\/m * np.sum(dZ3, axis=1, keepdims = True)\n    \n    dA2 = np.dot(W3.T, dZ3)\n    dZ2 = np.multiply(dA2, np.int64(A2 > 0))\n    ### EMPIEZE EL C\u00d3DIGO AQU\u00cd ### (\u2248 1 l\u00ednea de c\u00f3digo)\n    dW2 = \n    ### TERMINE EL C\u00d3DIGO AQU\u00cd ###\n    db2 = 1.\/m * np.sum(dZ2, axis=1, keepdims = True)\n    \n    dA1 = np.dot(W2.T, dZ2)\n    dZ1 = np.multiply(dA1, np.int64(A1 > 0))\n    ### EMPIEZE EL C\u00d3DIGO AQU\u00cd ### (\u2248 1 l\u00ednea de c\u00f3digo)\n    dW1 = \n    ### TERMINE EL C\u00d3DIGO AQU\u00cd ###\n    db1 = 1.\/m * np.sum(dZ1, axis=1, keepdims = True)\n    \n    gradients = {\"dZ3\": dZ3, \"dW3\": dW3, \"db3\": db3,\"dA2\": dA2,\n                 \"dZ2\": dZ2, \"dW2\": dW2, \"db2\": db2, \"dA1\": dA1, \n                 \"dZ1\": dZ1, \"dW1\": dW1, \"db1\": db1}\n    \n    return gradients","6ad33044":"X_assess, Y_assess, cache = backward_propagation_with_regularization_test_case()\n\ngrads = retropropagacion_con_regularizacion(X_assess, Y_assess, cache, lambd = 0.7)\nprint (\"dW1 = \"+ str(grads[\"dW1\"]))\nprint (\"dW2 = \"+ str(grads[\"dW2\"]))\nprint (\"dW3 = \"+ str(grads[\"dW3\"]))","748d838b":"parameters = model(train_X, train_Y, lambd = 0.7)\nprint (\"Sobre el conjunto de entrenamiento:\")\npredictions_train = predict(train_X, train_Y, parameters)\nprint (\"Sobre el conjunto de prueba:\")\npredictions_test = predict(test_X, test_Y, parameters)","9844aff0":"plt.title(\"Modelo con regularizaci\u00f3n-L2\")\naxes = plt.gca()\naxes.set_xlim([-0.75,0.40])\naxes.set_ylim([-0.75,0.65])\nplot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y.flatten())","62a843d6":"**Resultados de los dos modelos**: \n\n<table> \n    <tr>\n        <td>\n        **Modelo**\n        <\/td>\n        <td>\n        **Precisi\u00f3n de entrenamiento**\n        <\/td>\n        <td>\n        **Precisi\u00f3n de prueba**\n        <\/td>\n\n    <\/tr>\n        <td>\n        Red de 3 capas sin regularizaci\u00f3n\n        <\/td>\n        <td>\n        95%\n        <\/td>\n        <td>\n        91.5%\n        <\/td>\n    <tr>\n        <td>\n        Red de 3 capas con regularizaci\u00f3n\n        <\/td>\n        <td>\n        94%\n        <\/td>\n        <td>\n        93%\n        <\/td>\n    <\/tr>\n<\/table> ","185d593c":"**Anotaciones**:\n- El valor de $\\lambda$ es un (hiper)par\u00e1metro que se puede optimizar sobre el conjunto de validaci\u00f3n.\n- La regularizaci\u00f3n-L2 vuelve la frontera de decisi\u00f3n m\u00e1s suave. Si $\\lambda$ es muy grande, tambi\u00e9n ser\u00eda posible tener demasiada \"sobre-generalizaci\u00f3n\", lo cual llevar\u00eda a un mayor sesgo del modelo.\n\n<font color='blue'>\n**Para recordar:** \n\nLa regularizaci\u00f3n-L2 se basa en el principio que un modelo sencillo (con pesos peque\u00f1os o casi nulos) que obtenga resultados al menos tan buenos como los de otro modelo m\u00e1s comlejo (pesos m\u00e1s grandes para todos los predictores), es mejor. Por ello, mediante la penalizaci\u00f3n sobre los valores de los pesos al cuadrado en la funci\u00f3n de p\u00e9rdida se consiguen pesos con valores reducidos. As\u00ed se consigue un mayor coste de tener mayores pesos, obteniendo un modelo m\u00e1s suave o general, donde la salida cambia m\u00e1s gradual y lentamente a medida que el input de entrada cambia. \n\nEspero te haya gustado este Notebook. Por favor compartelo para que entre todos aprendamos juntos.\n\nPuedes Seguirme a mi cuenta en Twitter **[@andres_jejen](https:\/\/twitter.com\/andres_jejen)** Constantemente comparto noticias y contenido educativo sibre Machine Learning, Big Data y Data Science.\n","2a52a300":"Felicitaciones, la precisi\u00f3n de prueba se increment\u00f3 en un 93%. \n\nLos datos de entrenamiento ya no est\u00e1n sobre-ajustados. Compru\u00e9belo graficando ls frontera de decisi\u00f3n.","998dcc0d":"## 1 - Modelo no-regularizado\n\nVamos a utilizar el siguiente modelo de red sin regularizaci\u00f3n. \n\nLuego va a implementar:\n- *regularizacion tipo-L2* con las funciones \"`coste_con_regularizacion()`\" y \"`retropropagacion_con_regularizacion()`\"\n\nLea el c\u00f3digo abajo para familiarizarse con el modelo.","fa4b2e19":"**Salida esperada**:\n\n<table> \n    <tr>\n    <td>\n    **dW1**\n    <\/td>\n        <td>\n    [[-0.25604646  0.12298827 -0.28297129]\n [-0.17706303  0.34536094 -0.4410571 ]]\n    <\/td>\n    <\/tr>\n    <tr>\n    <td>\n    **dW2**\n    <\/td>\n        <td>\n    [[ 0.79276486  0.85133918]\n [-0.0957219  -0.01720463]\n [-0.13100772 -0.03750433]]\n    <\/td>\n    <\/tr>\n    <tr>\n    <td>\n    **dW3**\n    <\/td>\n        <td>\n    [[-1.77691347 -0.11832879 -0.09397446]]\n    <\/td>\n    <\/tr>\n<\/table> ","1a4daaec":"Este modelo no-regularizado se est\u00e1 sobre-ajustando al conjunto de entrenamiento. Esto se puede ver ya que se ajusta a los puntos que muestran mayor ruido. \n\nVeamos ahora la t\u00e9cnica de regularizaci\u00f3n para reducir el sobre-ajuste.","13ef8249":"La precisi\u00f3n de entrenamiento es de 94.8% mientras que la precisi\u00f3n de prueba es de 91.5%. Este es el modelo de base (el cual podemos intentar mejorar, por ejemplo mediante regularizaci\u00f3n). \n\nEjecute el siguiente c\u00f3digo para graficar la frontera de decisi\u00f3n del modelo.","cae932ea":"**Salida esperada**:\n\n<table> \n    <tr>\n    <td>\n    **coste**\n    <\/td>\n        <td>\n    1.78648594516\n    <\/td>\n    \n    <\/tr>\n\n<\/table> ","fbeccb09":"Desde luego, como se ha cambiado la funci\u00f3n de p\u00e9rdida, tambi\u00e9n se debe modificar la retro-propagaci\u00f3n. Todos los gradiantes deben ser calculados con respecto al nuevo coste. \n\n**Ejercicio**: Implemente los cambios requeridos en la retro-propagaci\u00f3n tomando en cuenta la regularizaci\u00f3n. Los cambios solo se refieren al c\u00e1lculo de dW1, dW2 y dW3. Para cada uno, debe a\u00f1adir el gradiente del t\u00e9rmino de regularizaci\u00f3n $\\frac{d}{dW} ( \\frac{1}{2}\\frac{\\lambda}{m}  W^2) = \\frac{\\lambda}{m} W$.","e763fb06":"N\u00f3tese que la regularizaci\u00f3n perjudica el desempe\u00f1o sobre el conjunto de entrenamiento. Esto es porque limita la abilidad de la red a sobre-ajustarlo. De todos modos, el sistema se ve beneficiado al tener una mejor precisi\u00f3n en prueba. ","d8db44ce":"Entrenemos el modelo sin ninguna regularizaci\u00f3n, y observe la precisi\u00f3n sobre los conjuntos de entrenamiento y prueba.","1a0f3cac":"## 2 - Regularizaci\u00f3n-L2\n\nEl m\u00e9todo m\u00e1s usual para evitar el sobre-ajuste es la **regularizaci\u00f3n-L2**. Consiste en modificar apropiadamente la funci\u00f3n de coste, tal que:\n$$J = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small  y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)} \\tag{1}$$\npasa a ser formulada como:\n$$J_{regularizada} = \\small \\underbrace{-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)} }_\\text{entrop\u00eda cruzada} + \\underbrace{\\frac{1}{m} \\frac{\\lambda}{2} \\sum\\limits_l\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2} }_\\text{coste de regularizacion-L2} \\tag{2}$$\n\nAhora, modifique el coste y constate el cambio en el ajuste.\n\n**Ejercicio**: Implemente `coste_con_regularizacion()` para computar el coste de acuerdo con la f\u00f3rmula (2). Para calcular $\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2}$  , utilice :\n```python\nnp.sum(np.square(W[l]))\n```\nN\u00f3tese que debe hacer esto para $W^{[1]}$, $W^{[2]}$ y $W^{[3]}$, y luego sumar los tres t\u00e9rminos y multiplicar por $ \\frac{1}{m} \\frac{\\lambda}{2} $.","a9f29f5f":"Cada punto corresponde con la ubicaci\u00f3n de una tienda.\n- Si el punto es azul, la tienda tiene un buen volumen de ventas\n- Si el punto es rojo, quiere decir que el nivel de ventas de esa tienda no es bueno\n\n**Objetivo**: Utilice un modelo de aprendizaje profundo para encontrar las ubicaciones de las tiendas que son m\u00e1s propensas al \u00e9xito en ventas, y donde se debe centrar la pr\u00f3xima campa\u00f1a publicitaria.","02d813ab":"**Problema anal\u00edtico**: Este conjunto de datos, aunque un poco ruidoso, parece que podr\u00eda ser separado de manera adecuada por una diagonal que separa la parte superior izquierda (en azul) de la parte inferior derecha (en rojo). \n\nPrimero intente desarrollar un modelo no-regularizado. Luego aprender\u00e1 a regularizarlo y decidir cu\u00e1l modelo elegir para resolver el problema de la empresa que lo contrat\u00f3. ","3fa9d830":"**Enunciado del problema**: como experto en aprendizaje computacional, se le acaba de encomendar la tarea de recomendar la ubicaci\u00f3n de nuevas tiendas con el fin de maximizar las ventas.  \n\nSe le proporciona el siguiente conjunto de datos sobre el conjunto de tiendas que tiene la empresa en este momento.","6c913cd9":"# Regularizaci\u00f3n\n\nComo hemos venido discutiendo en clase y en los talleres, lo modelos de aprendizaje profundo tienen una alta propensi\u00f3n hacia el **sobre-ajuste**, lo cual es un gran problema si no se controla. Recordemos que estamos buscando una buena generalizaci\u00f3n para predecir sobre con nuevos ejemplos\/datos. \n\nEn este taller vamos a revisar la t\u00e9cnica de regularizaci\u00f3n en los modelos de redes neuronales.\n\nPrimero cargamos los paquetes que vamos a usar.","a87314c4":"Ahora ejecute el modleo con regularizaci\u00f3n L2 $(\\lambda = 0.7)$. La funcion `model()` utiliza: \n- `coste_con_regularizacion` en lugar de `compute_cost`\n- `retropropagacion_con_regularizacion` en lugar de `backward_propagation`"}}