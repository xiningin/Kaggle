{"cell_type":{"20af0dfe":"code","87d50f6d":"code","fa25db94":"code","b40c32de":"code","282a1720":"code","dc93c7bb":"code","f13b0ad1":"code","23fe3ee8":"code","32288cef":"code","6dd174a7":"code","d4b71953":"code","4f8f302a":"code","2f05c0e2":"code","c5d42e62":"code","155bb686":"code","b9305110":"code","dfa58c5e":"code","53b23ba3":"code","1816c9a2":"code","eec794c0":"code","f76a273d":"code","d28e08e0":"markdown","f9f8573c":"markdown","49f7a796":"markdown","e5bf310b":"markdown","af8d6404":"markdown","77d724ea":"markdown","fd7d6c42":"markdown","f0f896c8":"markdown","8f93ecf0":"markdown","4f938b76":"markdown","18e824cb":"markdown","543bbe23":"markdown"},"source":{"20af0dfe":"# Submissions for https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques\n# House Prices: Advanced Regression Techniques\n\n#Standard Toolbox\nimport sys\nimport numpy as np \nimport pandas as pd\nimport os\nimport sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#Evaluation \nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.model_selection import train_test_split\n\n# Stats\nfrom scipy.stats import norm, skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom scipy import stats\n\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.svm import SVC\n\n\n# Preset data display\npd.options.display.max_seq_items = 5000\npd.options.display.max_rows = 5000\npd.set_option('display.max_columns', 500)\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")","87d50f6d":"def displot(c):\n    fig, ax = plt.subplots(figsize=(18,5), ncols=2, nrows=1)\n    ax1 = sns.distplot(c, fit=norm, kde=False, ax=ax[0])\n    ax2 = stats.probplot(c, plot=ax[1])\n    mu, sigma = norm.fit(c)\n    ax1.legend(['Dist. ($\\mu=$ {:.0f}, $\\sigma=$ {:.0f} , skw= {:.3f} , kurt= {:.3f} )'.format(mu, sigma, c.skew(), c.kurt())],\n            loc='best')","fa25db94":"def OHE(df, cols):\n    return pd.get_dummies(df, columns=cols)\n\ndef Encoding_BE(df, col, th):\n    #c = col+'_Code'\n    c = col\n    vc = df[col].value_counts().to_frame()\n    include = vc[vc[col] > th]\n    df[c] = df[col]\n    for v in df[c].unique():\n        i = np.where(df[c]==v)[0]\n        if v in include.index:\n            m= len(list(include.index)) - list(include.index).index(v)\n            df.loc[i,c]= m\n        else:\n            df.loc[i,c]= 0\n    i = np.where(df[c].isnull())[0]\n    df.loc[i,c]= 0\n    return df\n\ndef Encoding_BE_Rank(df, col, rank):\n    #c = col+'_Code'\n    c = col\n    df[c] = df[col]\n    for v in df[c].unique():\n        i = np.where(df[c]==v)[0]\n        if v in rank:\n            m = rank.index(v)\n            df.loc[i,c]= m +1\n    return df\ndef Normalize01(df, col):\n    #df[col] = (df[col] - df[col].min())\/(df[col].max() - df[col].min())\n    #df[col] = df[col]\n    rscaler = MinMaxScaler()\n    df_col = rscaler.fit_transform(np.array(df[col]).reshape(-1,1))\n    df[col] = df_col\n    return df\n\n\ndef Impute_Missing(c,t,m=False,r=True):\n    total_rec = c.shape[0]\n    null_count = c.isna().sum()\n    p_null = null_count\/total_rec * 100\n    t = pd.get_dummies(t)\n    m_index = c[(c.isna() | c.isnull())].index\n    Y = c.drop(m_index)\n    X = t.drop(m_index)\n    X_m = np.array(t.iloc[m_index])\n    if r:\n        if m:\n            m_regressor = RidgeCV(alphas=[1e-3, 1e-2],cv=5).fit(X, Y)\n            c[m_index] = m_regressor.predict(X_m).astype(str(c.dtypes)).reshape(len(m_index),)\n    else:\n        if m:\n            m_classifier = SVC(kernel='rbf',gamma=1, C=0.5).fit(X, Y)\n            c[m_index] = m_classifier.predict(X_m).reshape(len(m_index),)\n    return c\n\ndef outliers(c, t, top=5):\n    lof = LocalOutlierFactor(n_neighbors=40, contamination=0.05)\n    x_=np.array(c).reshape(-1,1)\n    preds = lof.fit_predict(x_)\n    lof_scr = lof.negative_outlier_factor_\n    out_idx = pd.Series(lof_scr).sort_values()[:top].index\n    return out_idx\n\ndef reduceSkew(c):\n    #displot(c)\n    #c_trn = c[0:trn_i]\n    #c_tst = c[trn_i:]\n    #sk_c_trn = boxcox1p(c_trn, boxcox_normmax(c_trn+1))\n    #sk_c_tst = boxcox1p(c_tst, boxcox_normmax(c_tst+1))\n    #nc = pd.concat([sk_c_trn, sk_c_tst], ignore_index=True)\n    if skew(c)>0.75:\n        print('Column: ' + c.name +' skew:' +  str(skew(c)))\n        return boxcox1p(c, boxcox_normmax(c+1))\n    else:\n        return c","b40c32de":"testdata = pd.read_csv(os.path.join(\"..\/input\",\"test.csv\"))\ntraindata = pd.read_csv(os.path.join(\"..\/input\",\"train.csv\"))\n\ntrn_i = traindata.shape[0]\ntrain_target = traindata.SalePrice\nlog_trn_target = np.log(train_target)\ntrainID = traindata.Id\ntestID = testdata.Id\ntestdata['SalePrice'] = 0\ntraindata = traindata.drop(['Id','SalePrice'], axis=1)\ntestdata = testdata.drop(['Id','SalePrice'], axis=1)\n\n\n\nouts = outliers(traindata['LotArea'], train_target, top=40)\ntraindata = traindata.drop(outs)\ntrain_target = train_target.drop(outs)\nlog_trn_target =log_trn_target.drop(outs)\ntrn_i = traindata.shape[0]\ndfull = pd.concat([traindata,testdata], ignore_index=True) # merge for dataframe for EDA\nprint(traindata.shape, testdata.shape, dfull.shape)","282a1720":"plt.scatter(dfull['LotArea'],dfull['GrLivArea'])","dc93c7bb":"plt.boxplot(dfull[\"LotArea\"])","f13b0ad1":"displot(dfull['LotArea'])","23fe3ee8":"dfull['LotArea'].sort_values()","32288cef":"columns_to_drop=[]\nOHE_Cols=[]\n\n#Process Columns\n# 1) ID\n#columns_to_drop.append('Id')\n# 2) MSSubClass - Convert to Category; append to OHE list\ndfull['MSSubClass']= dfull['MSSubClass'].astype('category') \nOHE_Cols.append('MSSubClass')\n#dfull['MSSubClass'] = reduceSkew(dfull['MSSubClass'])\n# 3) MSZoning -  Append to OHE List\nOHE_Cols.append('MSZoning')\n# 4) LotFrontage + LotArea\n#dfull['LotFrontage'].fillna(dfull['LotFrontage'].mean(), inplace=True)\ndfull['LotFrontage'] = Impute_Missing(c=dfull['LotFrontage'],t=dfull.loc[:,['LotArea','Neighborhood', 'GrLivArea']], r=True, m=True)\n#dfull['LotFrontRatio'] = dfull['LotFrontage']\/dfull['LotArea']\n#dfull['LotFrontRatio'] = reduceSkew(dfull['LotFrontRatio'])\ndfull= Normalize01(dfull, 'LotFrontage')\ndfull= Normalize01(dfull, 'LotArea')\ndfull['LotArea'] = reduceSkew(dfull['LotArea'])\ndfull['LotFrontage'] = reduceSkew(dfull['LotFrontage'])\n#columns_to_drop.append('LotFrontage')\n#columns_to_drop.append('LotArea') # double check\n# 6) Street\nOHE_Cols.append('Street')\n# 7) Alley\n    #dfull['Alley'].fillna('None', inplace=True)\ndfull['Alley'] = dfull['Alley'].apply(lambda x: 0 if pd.isnull(x) else 1)\ncolumns_to_drop.append('Alley')\n# 8) LotShape\nOHE_Cols.append('LotShape')\n# 9) LandContour\nOHE_Cols.append('LandContour')\n# 10) Utilities\ncolumns_to_drop.append('Utilities')\n# 11) LotConfig\nOHE_Cols.append('LotConfig')\n# 12) LandSlope\nOHE_Cols.append('LandSlope')\n# 13) 'Neighborhood'\nOHE_Cols.append('Neighborhood')\n# 14) Condition1\n#dfull = Encoding_BE(dfull,'Condition1', 20)\n#dfull = Normalize01(dfull, 'Condition1')\nOHE_Cols.append('Condition1')\n# 14) Condition2\n    #New Column to track houses with two different prime conditions for location\ndfull['If2Conditions'] = ((dfull['Condition1'] != 'Norm') & (dfull['Condition2'] != 'Norm') & (dfull['Condition2'] != dfull['Condition2'])).astype('int16')\ncolumns_to_drop.append('Condition2')\n# 15) BldgType\nOHE_Cols.append('BldgType')\n# 16) HouseStyle\nOHE_Cols.append('HouseStyle')\n# 17) & 18) OverallQual * OverallCond\ndfull['OverallQuCo']= (dfull['OverallQual'] * dfull['OverallCond'])\ndfull = Normalize01(dfull, 'OverallQuCo')\ndfull['OverallQuCo'] = reduceSkew(dfull['OverallQuCo'])\ncolumns_to_drop.append('OverallQual')\ncolumns_to_drop.append('OverallCond')\n# 19 - 20) YearBuilt & YearRemodAdd- > deducted New column 'Rennovate'\ndfull['Rennovate'] = ((dfull['YearRemodAdd'].astype('int16') - dfull['YearBuilt'].astype('int16'))>1).astype('int16')\ndfull= Normalize01(dfull, 'Rennovate')\ndfull['Rennovate'] = reduceSkew(dfull['Rennovate'])\ndfull['YearOld'] = dfull['YearBuilt'].max() - dfull['YearBuilt'].astype('int16')\ndfull= Normalize01(dfull, 'YearOld')\ndfull['YearOld'] = reduceSkew(dfull['YearOld'])\ncolumns_to_drop.append('YearBuilt')\ncolumns_to_drop.append('YearRemodAdd')\n# 21) RoofStyle\nOHE_Cols.append('RoofStyle')\n# 22) RoofMatl\nOHE_Cols.append('RoofMatl')\n# 23) & Exterior1st\nOHE_Cols.append('Exterior1st')\n# 24) Exterior2nd\ndfull['Exterior'] = ((dfull['Exterior1st'] != dfull['Exterior2nd'])).astype('int32')\ncolumns_to_drop.append('Exterior2nd')\n# 25) MasVnrType\ndfull['MasVnrType'].loc[dfull['MasVnrType'].isna()==True] = 'None'\n#dfull['MasVnrType']= Impute_Missing(c = dfull['MasVnrType'], t = dfull.loc[:,['Exterior1st','Exterior2nd']], m = True, r = False)\nOHE_Cols.append('MasVnrType')\n# 26) MasVnrArea\ndfull['MasVnrArea'].loc[dfull['MasVnrType'].isna()==True] = 0\n#dfull['MasVnrArea'].fillna((dfull['MasVnrArea'].loc[dfull['MasVnrArea']>0]).mean(), inplace=True)\ndfull= Normalize01(dfull, 'MasVnrArea')\ndfull['MasVnrArea'] = reduceSkew(dfull['MasVnrArea'])\n# 27) & 28) ExterQaCo =  ExterQual * ExterCond\ndfull = Encoding_BE_Rank(dfull,'ExterQual', ['None','Po','Fa','TA','Gd','Ex'])\ndfull = Encoding_BE_Rank(dfull,'ExterCond', ['None','Po','Fa','TA','Gd','Ex'])\ndfull['ExterQaCo'] = (dfull['ExterQual'] * dfull['ExterCond'])\ndfull= Normalize01(dfull, 'ExterQaCo')\ndfull['ExterQaCo'] = reduceSkew(dfull['ExterQaCo'])\ncolumns_to_drop.append('ExterQual')\ncolumns_to_drop.append('ExterCond')\n# 29) Foundation \nOHE_Cols.append('Foundation')\n# 30) BsmtQual 30) BsmtQual  32) BsmtExposure \ndfull['BsmtQual'].fillna('None', inplace=True)\ndfull['BsmtCond'].fillna('None', inplace=True)\ndfull['BsmtExposure'].fillna('None', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'BsmtExposure', ['None','No','Mn','Av','Gd'])\ndfull['BsmtExposure'] = reduceSkew(dfull['BsmtExposure'])\ndfull= Normalize01(dfull, 'BsmtExposure')\ndfull = Encoding_BE_Rank(dfull,'BsmtCond', ['None','Po','Fa','TA','Gd','Ex'])\ndfull = Encoding_BE_Rank(dfull,'BsmtQual', ['None','Po','Fa','TA','Gd','Ex'])\ndfull['BsmtQC'] = (dfull['BsmtQual'] * dfull['BsmtCond'])**(0.5)\ndfull['BsmtQC'] = reduceSkew(dfull['BsmtQC'])\ndfull= Normalize01(dfull, 'BsmtQC')\ncolumns_to_drop.append('BsmtQual')\ncolumns_to_drop.append('BsmtCond')\n# 33) & 35) BsmtFinType1 & BsmtFinType2\ndfull['BsmtFinType1'].fillna('None', inplace=True)\ndfull['BsmtFinType2'].fillna('None', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'BsmtFinType2', ['None','Unf','LwQ','Rec','BLQ','ALQ','GLQ'])\ndfull = Encoding_BE_Rank(dfull,'BsmtFinType1', ['None','Unf','LwQ','Rec','BLQ','ALQ','GLQ'])\n#dfull['BsmtFin'] = dfull['BsmtFinType1'] + dfull['BsmtFinType2']\n#dfull['BsmtFin'] = reduceSkew(dfull['BsmtFin'])\n#dfull= Normalize01(dfull, 'BsmtFin')\ncolumns_to_drop.append('BsmtFinType1')\ncolumns_to_drop.append('BsmtFinType2')\n# 34) BsmtFinSF1\ncolumns_to_drop.append('BsmtFinSF1')\n# 36) BsmtFinSF2\ncolumns_to_drop.append('BsmtFinSF2')\n# 37) BsmtUnfSF\ndfull['BsmtUnfSF'].fillna(0.0, inplace=True) # this is for house at index 2120\ncolumns_to_drop.append('BsmtUnfSF')\n# 38) TotalBsmtSF\ndfull['TotalBsmtSF'].fillna(0, inplace=True) # this is for house at index 2120\ndfull['BsmtFinRatio'] = dfull.loc[:,['TotalBsmtSF','BsmtUnfSF']].apply(lambda x: x['BsmtUnfSF']\/x['TotalBsmtSF'] if x['TotalBsmtSF']!=0 else 0, axis=1) # new column\ndfull['BsmtFinRatio'] = reduceSkew(dfull['BsmtFinRatio'])\ndfull= Normalize01(dfull, 'BsmtFinRatio')\ncolumns_to_drop.append('TotalBsmtSF')\n# 39) Heating\nOHE_Cols.append('Heating')\n# 40) HeatingQC\ndfull = Encoding_BE_Rank(dfull,'HeatingQC', ['None','Po','Fa','TA','Gd','Ex'])\ndfull['HeatingQC'] = reduceSkew(dfull['HeatingQC'])\ndfull= Normalize01(dfull, 'HeatingQC')\n# 41) CentralAir\ndfull['CentralAir'] = dfull['CentralAir'].apply(lambda x: 1 if x=='Y' else 0)\ndfull['CentralAir'] = reduceSkew(dfull['CentralAir'])\ndfull= Normalize01(dfull, 'CentralAir')\n# 42)Electrical\ndfull['Electrical'].fillna('SBrkr', inplace=True) #applying Majority class for #1379\ndfull = Encoding_BE_Rank(dfull,'Electrical', ['None','Mix','FuseP','FuseF','FuseA','SBrkr'])\ndfull['Electrical'] = reduceSkew(dfull['Electrical'])\ndfull= Normalize01(dfull, 'Electrical')\n# 43) 1stFlrSF\ncolumns_to_drop.append('1stFlrSF')\n#dfull= Normalize01(dfull, '1stFlrSF')\n# 44) 2ndFlrSF\ndfull['2ndFlrSF']= dfull['2ndFlrSF'].apply(lambda x: 1 if x > 10 else 0) # check if 2nd floor exist\n# 45) LowQualFinSF\ndfull['LowQualFinSF']= dfull['LowQualFinSF'].apply(lambda x: 1 if x > 10 else 0) # check if LowQualFinSF exist for the house\n# 46) GrLivArea\ndfull['GrLivArea'] = reduceSkew(dfull['GrLivArea'])\ndfull= Normalize01(dfull, 'GrLivArea')\n# 47) BsmtFullBath 48) BsmtHalfBath\ndfull['BsmtFullBath'].fillna(0.0, inplace=True)\ndfull['BsmtHalfBath'].fillna(0.0, inplace=True)\ndfull['BsmtTotBath'] = dfull['BsmtFullBath'] + 0.5*dfull['BsmtHalfBath']\ndfull['BsmtTotBath'] = reduceSkew(dfull['BsmtTotBath'])\ndfull= Normalize01(dfull, 'BsmtTotBath')\ncolumns_to_drop.append('BsmtFullBath')\ncolumns_to_drop.append('BsmtHalfBath')\n# 49) FullBath 50) HalfBath\ndfull['FullBath'].fillna(0.0, inplace=True)\ndfull['HalfBath'].fillna(0.0, inplace=True)\ndfull['TotBath'] = dfull['FullBath'] + 0.5* dfull['HalfBath']\ndfull['TotBath'] = reduceSkew(dfull['TotBath'])\ndfull= Normalize01(dfull, 'TotBath')\ncolumns_to_drop.append('FullBath')\ncolumns_to_drop.append('HalfBath')\n# 51) BedroomAbvGr\ndfull['BedroomAbvGr'] = reduceSkew(dfull['BedroomAbvGr'])\ndfull= Normalize01(dfull, 'BedroomAbvGr')\n# 52) KitchenAbvGr\ndfull['KitchenAbvGr'] = reduceSkew(dfull['KitchenAbvGr'])\ndfull= Normalize01(dfull, 'KitchenAbvGr')\n# 53) KitchenQual\ndfull['KitchenQual'].fillna('None', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'KitchenQual', ['None','Po','Fa','TA','Gd','Ex'])\ndfull= Normalize01(dfull, 'KitchenQual')\n# 54) TotRmsAbvGrd\ndfull['TotRmsAbvGrd'] = reduceSkew(dfull['TotRmsAbvGrd'])\ndfull= Normalize01(dfull, 'TotRmsAbvGrd')\ncolumns_to_drop.append('TotRmsAbvGrd')\n# 55) Functional\n#dfull['Functional']=dfull['Functional'].apply(lambda x: 1 if x == 'Typ' else 0)\ndfull['Functional'].fillna('Typ', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'Functional', ['None','Typ','Min1','Min2','Mod','Maj1','Maj2','Sev','Sal'])\ndfull= Normalize01(dfull, 'Functional')\n# 56) Fireplaces 57) FireplaceQu\ndfull['FireplaceQu'].fillna('None', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'FireplaceQu', ['None','Po','Fa','TA','Gd','Ex'])\ndfull['FireplaceInfo'] = (dfull['FireplaceQu'] * dfull['Fireplaces'])\ncolumns_to_drop.append('Fireplaces')\ncolumns_to_drop.append('FireplaceQu')\n# 58) GarageType\ndfull['GarageType'].fillna('None', inplace=True)\nOHE_Cols.append('GarageType')\n# 59) GarageYrBlt - deducted New column 'Rennovate'\ndfull['GarageYrBlt'].fillna(0, inplace=True)\ndfull['GarageSmYr'] = dfull['GarageYrBlt'].astype('int16')- dfull['YearBuilt'].astype('int16')\ndfull['GarageSmYr'] = dfull['GarageSmYr'].apply(lambda x: 0 if x <= 0 else 1) ## Need to check again \n#OHE_Cols.append('GarageSmYr')\n#dfull['GarageSmYr'] = reduceSkew(dfull['GarageSmYr'])\n#dfull= Normalize01(dfull, 'GarageSmYr')\ncolumns_to_drop.append('GarageYrBlt')\n#columns_to_drop.append('GarageSmYr')\n# 60) GarageFinish\ndfull['GarageFinish'].fillna('None', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'GarageFinish', ['None','Unf','RFn','Fin'])\ndfull= Normalize01(dfull, 'GarageFinish')\n# 61) GarageCars & 62) GarageArea\ndfull['GarageCars'].fillna(0, inplace=True)\ndfull['GarageArea'].fillna(0, inplace=True)\ndfull['GarageAreaCar'] = dfull.loc[:,['GarageCars','GarageArea']].apply(lambda x: x['GarageArea']\/x['GarageCars'] if x['GarageCars']!=0 else 0, axis=1)\ndfull['GarageAreaCar'] = reduceSkew(dfull['GarageAreaCar'])\ncolumns_to_drop.append('GarageCars')\ncolumns_to_drop.append('GarageArea')\ndfull= Normalize01(dfull, 'GarageAreaCar')\n# 63) GarageQual 64) GarageCond\ndfull['GarageQual'].fillna('None', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'GarageQual', ['None','Po','Fa','TA','Gd','Ex'])\ndfull['GarageCond'].fillna('None', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'GarageCond', ['None','Po','Fa','TA','Gd','Ex'])\ndfull['GarageQuCo']= (dfull['GarageQual'] * dfull['GarageCond'])\ndfull['GarageQuCo'] = reduceSkew(dfull['GarageQuCo'])\ncolumns_to_drop.append('GarageQual')\ncolumns_to_drop.append('GarageCond')\ndfull = Normalize01(dfull, 'GarageQuCo')\n# 65) PavedDrive\ndfull = Encoding_BE_Rank(dfull,'PavedDrive', ['N','P','Y'])\ndfull['PavedDrive'] = reduceSkew(dfull['PavedDrive'])\ndfull = Normalize01(dfull, 'PavedDrive')\n# 66) WoodDeckSF\ndfull['WoodDeckSF'] = dfull['WoodDeckSF'].apply(lambda x: 1 if x> 1 else 0)\ndfull['WoodDeckSF'] = reduceSkew(dfull['WoodDeckSF'])\n# 67) OpenPorchSF\ndfull['OpenPorchSF'] = dfull['OpenPorchSF'].apply(lambda x: 1 if x> 1 else 0)\ndfull['OpenPorchSF'] = reduceSkew(dfull['OpenPorchSF'])\n# 68) EnclosedPorch\ndfull['EnclosedPorch'] = dfull['EnclosedPorch'].apply(lambda x: 1 if x> 1 else 0)\n#dfull['EnclosedPorch'] = reduceSkew(dfull['EnclosedPorch'])\n# 69) 3SsnPorch\ndfull['3SsnPorch'] = dfull['3SsnPorch'].apply(lambda x: 1 if x> 1 else 0)\n#dfull['3SsnPorch'] = reduceSkew(dfull['3SsnPorch'])\n# 70) ScreenPorch\ndfull['ScreenPorch'] = dfull['ScreenPorch'].apply(lambda x: 1 if x>1 else 0)\n#dfull['ScreenPorch'] = reduceSkew(dfull['ScreenPorch'])\n# 71) PoolArea 72) PoolQC\ndfull['PoolArea']=dfull['PoolArea'].apply(lambda x: 1 if x>0 else 0)\ndfull['PoolQC'].fillna('None', inplace=True)\ndfull = Encoding_BE_Rank(dfull,'PoolQC', ['None','Fa','TA','Gd','Ex'])\ndfull['PoolInfo'] = (dfull['PoolArea'] * dfull['PoolQC'])\n#dfull['PoolInfo'] = reduceSkew(dfull['PoolInfo'])\ndfull = Normalize01(dfull, 'PoolInfo')\ncolumns_to_drop.append('PoolQC')\ncolumns_to_drop.append('PoolArea')\n# 73) Fence\ndict_fence = {0:\"NA\", 1:\"MnWw\", 2:\"GdWo\", 3:\"MnPrv\", 4:\"GdPrv\"}\ndfull['Fence']=dfull['Fence'].apply(lambda x: 0 if pd.isnull(x) else 1)\n# 74) MiscFeature\ndfull['MiscFeature']=dfull['MiscFeature'].apply(lambda x: 0 if pd.isnull(x) else 1)\n# 75) MiscVal\ncolumns_to_drop.append('MiscVal')\n# 76) MoSold\n#dfull['MoSold']=dfull['MoSold'].apply(lambda x: 'Q1' if x in [1,2,3] else ('Q2' if x in [4,5,6] else ( 'Q3' if x in [7,8,9] else 'Q4')) )\ndfull['MoSold']=dfull['MoSold'].apply(lambda x: 'H1' if x in [1,2,3,4,5,6] else 'H2')\nOHE_Cols.append('MoSold')\n# 77) YrSold\nOHE_Cols.append('YrSold')\n# 78) SaleType\n#dfull['SaleType'] = dfull['SaleType'].apply(lambda x: 1 if x in ['WD','New','CWD'] else 0)\nOHE_Cols.append('SaleType')\n# 79) SaleCondition\nOHE_Cols.append('SaleCondition')\n# 80) SalePrice\n#dfull['SalePrice'] = dfull['SalePrice'].astype('float')\n\n#for One Hot Encoding (OHE)\ndfull = OHE(dfull,OHE_Cols)\n#Drop unused columns\ndfull =dfull.drop(columns_to_drop, axis=1)","6dd174a7":"print(\"Columns to be dropped for training and predictions\")\nprint(columns_to_drop)\nprint(\"Columns for One Hot Encoding\")\nprint(OHE_Cols)","d4b71953":"print(dfull.shape)\n#print(dfull.head())","4f8f302a":"corrmat = dfull.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.75,vmin =.5)","2f05c0e2":"# Select upper triangle of correlation matrix\nupper = corrmat.where(np.triu(np.ones(corrmat.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.80)]\n\ndfull =dfull.drop(to_drop, axis=1)","c5d42e62":"dfull.head()","155bb686":"testdata = dfull.loc[trn_i:,:]\ntraindata = dfull.loc[0:(trn_i-1), :]\ntestdata = testdata.reset_index(drop=True)\ntraindata= traindata.reset_index(drop=True)\nprint(traindata.shape)\nprint(testdata.shape)","b9305110":"traindata_y = log_trn_target\ntraindata_x = traindata\n#testdata_y = testdata.pop(\"SalePrice\")\ntestdata_x = testdata\ntraindata_x.head(3)","dfa58c5e":"#train_x, val_x, train_y,val_y = train_test_split(traindata_x,traindata_y, train_size=0.7,test_size=0.3, random_state = 123456)","53b23ba3":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\ndef get_predictions(model, params, x, y, xtest):\n    gs = GridSearchCV(model, params, scoring='neg_mean_squared_error', cv=10, verbose=False)\n    gs.fit(x,y)\n    print(gs.best_params_)\n    print(gs.best_score_)\n    bestmodel = gs.best_estimator_\n    bestmodel.fit(x,y)\n    prediction = bestmodel.predict(xtest)\n    return prediction\n\nsubmissions = pd.read_csv(\"..\/input\/sample_submission.csv\")\n","1816c9a2":"rfm = RandomForestRegressor( random_state=123)\nparams = {'n_estimators':[1000]}\n#rfm_pred = np.exp(get_predictions(rfm, params, traindata_x, traindata_y,testdata_x))\n#submissions[\"SalePrice\"] = np.exp(get_predictions(lgbmr, params, traindata_x, traindata_y,testdata_x))","eec794c0":"from lightgbm import LGBMRegressor\nlgbmr = LGBMRegressor(random_state=123)\nparams = {\n    'num_leaves': [25],\n    'max_depth': [7], \n    'bagging_fraction': [0.63],\n    'feature_fraction': [0.55],\n    'min_data_in_leaf': [23],\n    'learning_rate': [0.01],\n    'n_estimators':[1500]}\n\nsubmissions[\"SalePrice\"] = np.exp(get_predictions(lgbmr, params, traindata_x, traindata_y,testdata_x))\n","f76a273d":"#submissions[\"SalePrice\"] = (rfm_pred + pred_lgbm)\/2\nsubmissions.to_csv(\"submission.csv\", index=False)","d28e08e0":"*Plots et, al**","f9f8573c":"* Import and merge the data for common pre-processing","49f7a796":"**Column Wise Preprocessing of Data**","e5bf310b":"**Split data again for Training and Prediction**","af8d6404":"**Model Building**\n\nDefining common model function","77d724ea":"2) get the predictions from LightGBM (tuning)","fd7d6c42":"Version Footnote: <br\/>\n- Checked variance\n- disable skew check for porch related columns","f0f896c8":"* Sanity Checks for Null\/NA","8f93ecf0":"**Data Exploration on the Clean dataset**","4f938b76":"* Defining few helper Functions","18e824cb":"*  Necessary imports and inclusions","543bbe23":"1) Lasso Regression to get most important predictors."}}