{"cell_type":{"66fdb032":"code","065e4a4b":"code","87f78f0d":"code","b40cef6e":"code","9956a60b":"code","f4e8e6bf":"code","99b6c283":"code","697a9979":"code","6e4b0f4d":"markdown","d04dd261":"markdown","5d19c5f4":"markdown","6514ddd3":"markdown","4bc59d08":"markdown","6a50cf65":"markdown"},"source":{"66fdb032":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","065e4a4b":"df = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-1\/train.csv', sep=',')\ndf['Date'] = pd.to_datetime(df['Date'])\ntrain_last_date = df.Date.unique()[-1]","87f78f0d":"print(f\"Dataset has training data untill : {train_last_date}\")","b40cef6e":"\nwpop = pd.read_csv('\/kaggle\/input\/worldpopulationbyage\/WPP2019_PopulationByAgeSex_Medium.csv')\n\ncountry_mapper = {\n'Iran (Islamic Republic of)' : \"Iran\",\n'Bolivia (Plurinational State of)' : 'Bolivia',\n'Brunei Darussalam' : 'Brunei',\n'Congo' : 'Congo (Kinshasa)',\n'Democratic Republic of the Congo' : \"Congo (Brazzaville)\",\n\"C\u00f4te d'Ivoire\": \"Cote d'Ivoire\",\n\"Gambia\" : \"Gambia, The\",\n\"Republic of Korea\": \"Korea, South\",\n\"Republic of Moldova\": \"Moldova\",\n'R\u00e9union' : \"Reunion\",\n'Russian Federation' : \"Russia\",\n'China, Taiwan Province of China' : \"Taiwan*\",\n\"United Republic of Tanzania\": \"Tanzania\",\n\"Bahamas\": \"The Bahamas\",\n\"Gambia\": \"The Gambia\",\n\"United States of America (and dependencies)\" : \"US\",\n\"Venezuela (Bolivarian Republic of)\" : \"Venezuela\",\n'Viet Nam' : \"Vietnam\"}\n\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\nwpop = wpop[wpop['Time']==2020].reset_index(drop=True)\nwpop['Location'] = wpop.Location.apply(lambda x : rename_countries(x, country_mapper))\nclean_wpop = wpop[wpop['Location'].isin(df['Country\/Region'].unique())].reset_index()\n\npopulation_distribution = []\nfor country, gpdf in clean_wpop.groupby(\"Location\"):\n    aux = {f\"age_{age_grp}\": tot for age_grp, tot in zip(gpdf.AgeGrp, gpdf.PopTotal)}\n    aux[\"Country\/Region\"] = country\n    population_distribution.append(aux)\n    \ndf_pop_distrib = pd.DataFrame(population_distribution)\n\n# add missing countries with median values\nno_data = []\nfor country in df['Country\/Region'].unique():\n    if country not in df_pop_distrib['Country\/Region'].unique():\n        aux = df_pop_distrib.drop('Country\/Region', axis=1).median(axis=0).to_dict()\n        aux[\"Country\/Region\"] = country\n        no_data.append(aux)\ndf_no_data = pd.DataFrame(no_data)\n\ndf_pop_distrib = pd.concat([df_pop_distrib, df_no_data], axis=0)\n\n# normalize features\nnorm_pop_distrib = df_pop_distrib.drop(\"Country\/Region\", axis=1).div(df_pop_distrib.drop(\"Country\/Region\", axis=1).sum(axis=1), axis=0)\nnorm_pop_distrib['total_pop'] = df_pop_distrib.drop(\"Country\/Region\", axis=1).sum(axis=1)\nnorm_pop_distrib[\"Country\/Region\"] = df_pop_distrib[\"Country\/Region\"]\n\ndel df_pop_distrib\ndel df_no_data\ndel clean_wpop\ndel wpop\n\ndf = df.merge(norm_pop_distrib, on=\"Country\/Region\", how='left')","9956a60b":"#https:\/\/ourworldindata.org\/smoking#prevalence-of-smoking-across-the-world\nsmokers = pd.read_csv('\/kaggle\/input\/smokingstats\/share-of-adults-who-smoke.csv')\nsmokers = smokers[smokers.Year == 2016].reset_index(drop=True)\n\nsmokers_country_dict = {'North America' : \"US\",\n 'Gambia' : \"The Gambia\",\n 'Bahamas': \"The Bahamas\",\n \"'South Korea'\" : \"Korea, South\",\n'Papua New Guinea' : \"Guinea\",\n \"'Czech Republic'\" : \"Czechia\",\n 'Congo' : \"Congo (Brazzaville)\"}\n\nsmokers['Entity'] = smokers.Entity.apply(lambda x : rename_countries(x, smokers_country_dict))\n\nno_datas_smoker = []\nfor country in df['Country\/Region'].unique():\n    if country not in smokers.Entity.unique():\n        mean_score = smokers[['Smoking prevalence, total (ages 15+) (% of adults)']].mean().to_dict()\n        mean_score['Entity'] = country\n        no_datas_smoker.append(mean_score)\nno_data_smoker_df = pd.DataFrame(no_datas_smoker)   \nclean_smoke_data = pd.concat([smokers, no_data_smoker_df], axis=0)[['Entity','Smoking prevalence, total (ages 15+) (% of adults)']]\nclean_smoke_data.rename(columns={\"Entity\": \"Country\/Region\",\n                                  \"Smoking prevalence, total (ages 15+) (% of adults)\" : \"smokers_perc\"}, inplace=True)\n\ndf = df.merge(clean_smoke_data, on=\"Country\/Region\", how='left')\n","f4e8e6bf":"def concat_country_province(country, province):\n    if not isinstance(province, str):\n        return country\n    else:\n        return country+\"_\"+province\n\n# Concatenate region and province for training\ndf[\"Country\/Region\"] = df[[\"Country\/Region\", \"Province\/State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\n","99b6c283":"# https:\/\/www.kaggle.com\/koryto\/countryinfo\n\ncountry_info = pd.read_csv('\/kaggle\/input\/countryinfo\/covid19countryinfo.csv')\ncountry_info = country_info[~country_info.country.isnull()].reset_index(drop=True)\ncountry_info.drop([ c for c in country_info.columns if c.startswith(\"Unnamed\")], axis=1, inplace=True)\ncountry_info.drop(columns=['pop', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'medianage', \"smokers\", \"sexratio\"],\n                  axis=1,\n                  inplace=True)\n# Columns with dates\ncountry_info[\"quarantine\"] = pd.to_datetime(country_info[\"quarantine\"])\ncountry_info[\"restrictions\"] = pd.to_datetime(country_info[\"restrictions\"])\ncountry_info[\"schools\"] = pd.to_datetime(country_info[\"schools\"])\n\nsame_state = []\nfor country in df[\"Province\/State\"].unique():\n    if country in country_info.country.unique():\n        same_state.append(country)\n    else:\n        pass\n        # This part can help matching different external dataset and find corresponding countries\n        #print(country)\n        #matches = []\n        #scores = []\n        #if str(country)==\"nan\":\n        #    continue\n        #for possible_match in country_info.country.unique():\n        #    matches.append(possible_match)\n        #    scores.append(fuzz.partial_ratio(country, possible_match))\n            \n        #top_5_index = np.argsort(scores)[::-1][:5]\n        #print(np.array(matches)[top_5_index])\n        #print(np.array(scores)[top_5_index])\n        #print(\"-------------------\")\n        \ncountry_to_state_country = {}\nfor state in same_state:\n    #print(state)\n    #print(df[df[\"Province\/State\"]==state][\"Country\/Region\"].unique())\n    #print(\"----\")\n    country_to_state_country[state] = df[df[\"Province\/State\"]==state][\"Country\/Region\"].unique()[0]+\"_\"+state\n\ncountry_info['country'] = country_info.country.apply(lambda x : rename_countries(x, country_to_state_country))\n\ncoutry_merge_info = country_info[[\"country\", \"density\", \"urbanpop\", \"hospibed\", \"lung\", \"femalelung\", \"malelung\"]]\n\ncols_median = [\"density\", \"urbanpop\", \"hospibed\", \"lung\", \"femalelung\", \"malelung\"]\ncoutry_merge_info.loc[:, cols_median] = coutry_merge_info.loc[:, cols_median].apply(lambda x: x.fillna(x.median()),axis=0)\n\n\nmerged = df.merge(coutry_merge_info, left_on=\"Country\/Region\", right_on=\"country\", how=\"left\")\nmerged.loc[:, cols_median] = merged.loc[:, cols_median].apply(lambda x: x.fillna(x.median()),axis=0)\n\ncountry_dates_info = country_info[[\"country\", \"restrictions\", \"quarantine\", \"schools\"]]\n\ndef update_dates(a_df, col_update):\n    \"\"\"\n    This creates a boolean time series with one after the start of confinements (different types : schools, restrictions or quarantine)\n    \"\"\"\n    gpdf = a_df.groupby(\"Country\/Region\")\n    new_col = gpdf.apply(lambda df : df[col_update].notnull().cumsum()).reset_index(drop=True)\n    a_df[col_update] = new_col\n\n\nfor col in [\"restrictions\", \"quarantine\", \"schools\"]:\n    print(merged.shape)\n    merged = merged.merge(country_dates_info[[\"country\", col]],\n                          left_on=[\"Country\/Region\", \"Date\"],\n                          right_on=[\"country\", col],\n                          how=\"left\",\n                          )\n    update_dates(merged, col)\n\ndrop_country_cols = [x for x in merged.columns if x.startswith(\"country_\")]\nmerged.drop(columns=drop_country_cols, axis=1, inplace=True)","697a9979":"merged.to_csv('enriched_covid_19.csv', index=None)","6e4b0f4d":"# About this notebook\n\nThis is a pipeline to merge different data sources with the covid train dataset.\n\nI hope this can help people start with an enriched dataset and do useful modelling.\n\nDon't hesitate to fork from here and add more useful informations.\n\nSome merging are quite brutal and might be improved.\n","d04dd261":"# Add Time Data information from Quarantine, Restrictions and Schools","5d19c5f4":"# Load Covid Data","6514ddd3":"# Add Population Distributions By Country","4bc59d08":"# Add Smokers Percentages By Country","6a50cf65":"## Concatenate Country and Region Province"}}