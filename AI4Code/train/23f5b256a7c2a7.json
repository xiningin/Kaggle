{"cell_type":{"8b89fcbe":"code","c6247588":"code","17e48a45":"code","013917bf":"code","dacc67ac":"code","7242166a":"code","7c7e0891":"code","3b6cd42d":"code","21ebc38a":"code","aebc3468":"code","c9c2cfee":"code","e28bbf6d":"markdown","6d2d40bf":"markdown","4e8ba8e2":"markdown","9a7a146a":"markdown","afbe6392":"markdown","ede82bab":"markdown","bc5d5862":"markdown","2c5f9171":"markdown","5e132bdb":"markdown","fe4c7cec":"markdown","c2886b50":"markdown","d5a46e97":"markdown"},"source":{"8b89fcbe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# For visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c6247588":"data= pd.read_csv('..\/input\/column_2C_weka.csv')","17e48a45":"data.head(10)","013917bf":"f, ax = plt.subplots(figsize=(10,10)) \nsns.heatmap(data.corr(), annot=True, linewidths=0.5,linecolor=\"red\", fmt= '.1f',ax=ax)\nplt.show()","dacc67ac":"data.info()","7242166a":"data[\"class\"] = [1 if(each == \"Abnormal\") else 0 for each in data[\"class\"]]\n\ny= data[\"class\"].values\nx_data= data.drop([\"class\"],axis=1)","7c7e0891":"x= (x_data - np.min(x_data))\/(np.max(x_data) - np.min(x_data))","3b6cd42d":"sns.countplot(x=\"class\", data=data)\ndata.loc[:,'class'].value_counts()","21ebc38a":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.3, random_state=1)","aebc3468":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nx,y = data.loc[:,data.columns != 'class'], data.loc[:,'class']\nknn.fit(x,y)\nprediction = knn.predict(x)\nprint('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test))","c9c2cfee":"score_list = []\nfor each in range(1,20):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,20),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","e28bbf6d":"<a id=\"count\"> <\/a>\n## TOTAL CLASS VALUES COUNT    ","6d2d40bf":"<a id=\"#cor\"> <\/a>\n## CHECKING CORRELATION BETWEEN FEATURES","4e8ba8e2":"<a id=\"#read\"> <\/a>\n## READ DATA","9a7a146a":"As we can see accuracy %70. Its not a good result for this algortihm we can change parameters for reach optimal result.","afbe6392":"If we set \"n_neighbors\" to 19 we will reach best accuarcy.","ede82bab":"## INTRODUCTION\n* [Reading data](#read)\n* [Checking first 10 data for look features](#head)\n* [Checking correlation between features](#cor)\n* [Checking data types](#info)\n* [Converting feature to int](#con)\n* [Normalization](#norm)\n* [Total \"class\" values count](#count)\n* [Splitting data to train and test](#split)\n* [Implementing KNN](#knn)","bc5d5862":"<a id=\"#con\"> <\/a>\n## CONVERTING FEATURE TO INT\nAs we can see \"class\" is \"object\". We can't use \"object\" for classifaciton problems. The Logistic Algortihm is has to be 2 situation. For this dataset our situatins is \"Abnormal\" or \"Normal\" and there outputs has to be 0 or 1, so lets convert to \"int\"","2c5f9171":"<a id=\"#head\"><\/a>\n## CHECKING FIRST 10 DATA FOR LOOK FEATURES","5e132bdb":"<a id=\"norm\"> <\/a>\n## NORMALIZATION","fe4c7cec":"<a id=\"knn\"> <\/a>\n## IMPLEMENTING KNN\nK nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions).","c2886b50":"<a id=\"#info\"> <\/a>\n## CHECKING DATA TYPES","d5a46e97":"<a id=\"#split\"> <\/a>\n## SPLITTING DATA TO TRAIN AND TEST"}}