{"cell_type":{"fd8f6c0f":"code","b9f8fd32":"code","7e1ffa45":"code","db94fe6b":"code","a615e984":"code","22751548":"code","dcd76ce6":"code","9ff6e12b":"code","313baa9d":"code","35a68155":"code","410e2c60":"code","bbb0afad":"code","fc394f4b":"code","0a6f66f4":"code","c7b74b70":"code","30a063ab":"code","b513d4b5":"code","bd2ab5f9":"code","24827b58":"code","2d4b0e0c":"code","c34cdf87":"code","4eb34b35":"code","b9600169":"code","4106e81c":"code","21fb065b":"code","2fbde617":"code","cbc10f88":"code","adc3fa37":"code","2bd6bf25":"code","bf5dd767":"code","00454785":"code","a6ae66ea":"code","8bcdb40b":"code","ee35bdae":"code","7c291781":"code","c582d727":"code","c0c45839":"markdown","c2646b98":"markdown","42865101":"markdown","4cc93e6e":"markdown","8f671cc6":"markdown","89005497":"markdown","ee483704":"markdown","13fd17b3":"markdown","73ef2b02":"markdown","e5cd9de9":"markdown","33f27b56":"markdown","d6f64760":"markdown","5a23df42":"markdown","71fb2201":"markdown","3fe5f617":"markdown","39ea29ca":"markdown","f62198e6":"markdown","348e772b":"markdown"},"source":{"fd8f6c0f":"# import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans,AgglomerativeClustering,DBSCAN,SpectralClustering\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n","b9f8fd32":"# import the dataset\ncreditcard_df=pd.read_csv(\"..\/input\/ccdata\/CC GENERAL.csv\")\ncreditcard_df.head()","7e1ffa45":"creditcard_df.shape","db94fe6b":"# information about the data\ncreditcard_df.info()","a615e984":"# check for null value using heatmap\nsns.heatmap(creditcard_df.isnull(),yticklabels=False,cbar=False,cmap=\"Blues\")","22751548":"creditcard_df.isnull().sum()","dcd76ce6":"# find all columns having missing values\nmissing_var=[var for var in creditcard_df.columns if creditcard_df[var].isnull().sum()>0]\nmissing_var","9ff6e12b":"# see normal distribution of columns having null value\nsns.set()\nfor i,var in enumerate(missing_var):\n  plt.subplot(1,2,i+1)\n  sns.distplot(creditcard_df[var],bins=20,kde_kws={'linewidth':5})","313baa9d":"# check the normal distribution of columns having null values by filling with the mean value\nplt.figure(figsize=(15,5))\nsns.set()\nfor i,var in enumerate(missing_var):\n  plt.subplot(1,2,i+1)\n  sns.distplot(creditcard_df[var],bins=20,kde_kws={'linewidth':3,'color':'red'},label=\"original\")\n  sns.distplot(creditcard_df[var],bins=20,kde_kws={'linewidth':2,'color':'green'},label=\"mean\")","35a68155":"# check the normal distribution of columns having null values by filling with the mean value\nplt.figure(figsize=(15,5))\nsns.set()\nfor i,var in enumerate(missing_var):\n  plt.subplot(1,2,i+1)\n  sns.distplot(creditcard_df[var],bins=20,kde_kws={'linewidth':3,'color':'red'},label=\"original\")\n  sns.distplot(creditcard_df[var],bins=20,kde_kws={'linewidth':2,'color':'green'},label=\"median\")","410e2c60":"# fill mean value in place of missing values\ncreditcard_df[\"MINIMUM_PAYMENTS\"]=creditcard_df[\"MINIMUM_PAYMENTS\"].fillna(creditcard_df[\"MINIMUM_PAYMENTS\"].mean())\ncreditcard_df[\"CREDIT_LIMIT\"]=creditcard_df[\"CREDIT_LIMIT\"].fillna(creditcard_df[\"CREDIT_LIMIT\"].mean())","bbb0afad":"# Again check for null values\ncreditcard_df.isnull().sum()","fc394f4b":"# check duplicate entries in the dataset\ncreditcard_df.duplicated().sum()","0a6f66f4":"# drop unnecessary columns\ncreditcard_df.drop(columns=[\"CUST_ID\"],axis=1,inplace=True)","c7b74b70":"creditcard_df.columns","30a063ab":"# visualise probability density of all columns\nplt.figure(figsize=(10,50))\nfor i in range(len(creditcard_df.columns)):\n  plt.subplot(17,1,i+1)\n  sns.distplot(creditcard_df[creditcard_df.columns[i]],kde_kws={\"color\":\"b\",\"lw\":3,\"label\":\"KDE\"},hist_kws={\"color\":\"g\"})\n  plt.title(creditcard_df.columns[i])\nplt.tight_layout()\n# This is to ignore warning\nimport warnings\nwarnings.filterwarnings('ignore')","b513d4b5":"# find outlier in all columns\nfor i in creditcard_df.select_dtypes(include=['float64','int64']).columns:\n  max_thresold=creditcard_df[i].quantile(0.95)\n  min_thresold=creditcard_df[i].quantile(0.05)\n  creditcard_df_no_outlier=creditcard_df[(creditcard_df[i] < max_thresold) & (creditcard_df[i] > min_thresold)].shape\n  print(\" outlier in \",i,\"is\" ,int(((creditcard_df.shape[0]-creditcard_df_no_outlier[0])\/creditcard_df.shape[0])*100),\"%\")","bd2ab5f9":"# remove outliers from columns having nearly 10% outlier\nmax_thresold_BALANCE=creditcard_df[\"BALANCE\"].quantile(0.95)\nmin_thresold_BALANCE=creditcard_df[\"BALANCE\"].quantile(0.05)\nmax_thresold_CREDIT_LIMIT=creditcard_df[\"CREDIT_LIMIT\"].quantile(0.95)\nmin_thresold_CREDIT_LIMIT=creditcard_df[\"CREDIT_LIMIT\"].quantile(0.05)\nmax_thresold_PAYMENTS=creditcard_df[\"PAYMENTS\"].quantile(0.95)\nmin_thresold_PAYMENTS=creditcard_df[\"PAYMENTS\"].quantile(0.05)\ncreditcard_df_no_outlier=creditcard_df[(creditcard_df[\"CREDIT_LIMIT\"] < max_thresold_CREDIT_LIMIT) & (creditcard_df[\"CREDIT_LIMIT\"] > min_thresold_CREDIT_LIMIT) & (creditcard_df[\"BALANCE\"] < max_thresold_BALANCE) & (creditcard_df[\"BALANCE\"] > min_thresold_BALANCE) &  (creditcard_df[\"PAYMENTS\"] < max_thresold_PAYMENTS) & (creditcard_df[\"PAYMENTS\"] > min_thresold_PAYMENTS)]\n","24827b58":"# DataFrame having no outlier\ncreditcard_df_no_outlier.head()","2d4b0e0c":"# correlation matrix of DataFrame\nplt.figure(figsize=(20,10))\ncorn=creditcard_df_no_outlier.corr()\nsns.heatmap(corn,annot=True,cmap=\"BuPu\",fmt='.2f')","c34cdf87":"# scale the DataFrame\nscalar=StandardScaler()\ncreditcard_scaled_df=scalar.fit_transform(creditcard_df_no_outlier)","4eb34b35":"# convert the DataFrame into 2D DataFrame for visualization\npca= PCA(n_components=2)\nprincipal_comp=pca.fit_transform(creditcard_scaled_df)\npca_df=pd.DataFrame(data=principal_comp,columns=[\"pca1\",\"pca2\"])\npca_df.head()","b9600169":"# find 'k' value by Elbow Method\ninertia=[]\nrange_val=range(1,15)\nfor i in range_val:\n  kmean=KMeans(n_clusters=i)\n  kmean.fit_predict(pd.DataFrame(creditcard_scaled_df))\n  inertia.append(kmean.inertia_)\nplt.plot(range_val,inertia,'bx-')\nplt.xlabel('Values of K') \nplt.ylabel('Inertia') \nplt.title('The Elbow Method using Inertia') \nplt.show()","4106e81c":"# Spectral clustering\ndef train_spectral(k,X):\n  spectral_model = SpectralClustering(n_clusters=k)\n  y_pred = spectral_model.fit_predict(X)\n  print(\"Spectral Clustering : clusters : \",k ,\" silhouette_score : \",silhouette_score(X,y_pred) )\n\n# Agglomerative clustering\ndef train_Agglomerative(linkage,k,X):\n  agglo_model = AgglomerativeClustering(linkage=linkage,n_clusters=k)\n  y_pred = agglo_model.fit_predict(X)\n  print(\"Agglomerative Clustering : clusters : \",k,\" linkage : \",linkage,\" silhouette_score : \",silhouette_score(X,y_pred) )\n\n# GaussianMixture Model based clustering\ndef train_GaussianMixture(k,X):\n  GaussianMixture_model = GaussianMixture(n_components=k)\n  y_pred = GaussianMixture_model.fit_predict(X)\n  print(\"GaussianMixture Model based Clustering : clusters : \",k ,\" silhouette_score : \",silhouette_score(X,y_pred) )\n","21fb065b":"# Spectral clustering\nclusters=[3,4,5,6]\nfor i in clusters:\n  train_spectral(i,creditcard_scaled_df)","2fbde617":"# Agglomerative clustering\nclusters=[3,4,5,6]\nlinkage=['ward', 'complete', 'average', 'single']\nfor lin in linkage:\n  for i in clusters:\n    train_Agglomerative(lin,i,creditcard_scaled_df)","cbc10f88":"# GaussianMixture Model based clustering\nclusters=[3,4,5,6]\nfor i in clusters:\n  train_GaussianMixture(i,creditcard_scaled_df)","adc3fa37":"# apply kmeans algorithm\nkmeans_model=KMeans(4)\nkmeans_model.fit_predict(creditcard_scaled_df)\npca_df_kmeans= pd.concat([pca_df,pd.DataFrame({'cluster':kmeans_model.labels_})],axis=1)\n# visualize the clustered dataframe\nplt.figure(figsize=(8,8))\n#palette=['dodgerblue','red','green','blue','black','pink','gray','purple','coolwarm']\nax=sns.scatterplot(x=\"pca1\",y=\"pca2\",hue=\"cluster\",data=pca_df_kmeans,palette=['red','green','blue','black'])\nplt.title(\"Clustering using K-Means Algorithm\")\nplt.show()","2bd6bf25":"agglo_model = AgglomerativeClustering(linkage=\"ward\",n_clusters=4)\ny_pred = agglo_model.fit_predict(creditcard_scaled_df)\npca_df_aglo= pd.concat([pca_df,pd.DataFrame({'cluster':agglo_model.labels_})],axis=1)\nplt.figure(figsize=(8,8))\nax=sns.scatterplot(x=\"pca1\",y=\"pca2\",hue=\"cluster\",data=pca_df_aglo,palette=['red','green','blue','black'])\nplt.title(\"Clustering using Agglomerative Algorithm\")\nplt.show()","bf5dd767":"spectral_model = SpectralClustering(n_clusters=4)\ny_pred = spectral_model.fit_predict(creditcard_scaled_df)\npca_df_spl= pd.concat([pca_df,pd.DataFrame({'cluster':spectral_model.labels_})],axis=1)\nplt.figure(figsize=(8,8))\nax=sns.scatterplot(x=\"pca1\",y=\"pca2\",hue=\"cluster\",data=pca_df_spl)\nplt.title(\"Clustering using Spectral Algorithm\")\nplt.show()","00454785":"GaussianMixture_model = GaussianMixture(n_components=3)\ny_pred = GaussianMixture_model.fit_predict(creditcard_scaled_df)\npca_df_gmm= pd.concat([pca_df,pd.DataFrame({'cluster':y_pred})],axis=1)\nplt.figure(figsize=(8,8))\nax=sns.scatterplot(x=\"pca1\",y=\"pca2\",hue=\"cluster\",data=pca_df_gmm,palette=['red','green','blue'])\nplt.title(\"Clustering using GaussianMixture Model Based Algorithm\")\nplt.show()","a6ae66ea":"model_dbscan = DBSCAN(eps=1, min_samples=18)\ny_pred = model_dbscan.fit_predict(creditcard_scaled_df)\npca_df_dbscan= pd.concat([pca_df,pd.DataFrame({'cluster':model_dbscan.labels_})],axis=1)\nplt.figure(figsize=(8,8))\nax=sns.scatterplot(x=\"pca1\",y=\"pca2\",hue=\"cluster\",data=pca_df_dbscan,palette=['red','green','blue','purple','pink'])\nplt.title(\"Clustering using DBSCAN Algorithm\")\nplt.show()","8bcdb40b":"#Saving Scikitlearn models\nimport joblib\njoblib.dump(kmeans_model, \"kmeans_model.pkl\")","ee35bdae":"# find all cluster centers\ncluster_centers = pd.DataFrame(data=kmeans_model.cluster_centers_,columns=[creditcard_df.columns])\n# inverse transfor the data\ncluster_centers = scalar.inverse_transform(cluster_centers)\ncluster_centers=pd.DataFrame(data=cluster_centers,columns=[creditcard_df.columns])\ncluster_centers","7c291781":"# create a column as \"cluster\" & store the respective cluster name that they belongs to\ncreditcard_cluster_df=pd.concat([creditcard_df,pd.DataFrame({'cluster':kmeans_model.labels_})],axis=1)\ncreditcard_cluster_df.head()","c582d727":"# save the dataframe in .csv file named as \"Clustered_Costumer_Data\"\ncreditcard_cluster_df.to_csv(\"Clustered_Customer_Data.csv\")","c0c45839":"## **d) GaussianMixture Model based clustering**","c2646b98":"# **6. Dimensionality reduction**","42865101":"# **2. Import Libraries:**","4cc93e6e":"## **e) DBSCAN Clustering**","8f671cc6":"# **7. Hyperparameter tuning**","89005497":"## **a) K-Means Clustering**","ee483704":"## **b) Agglomerative Clustering**","13fd17b3":"# **8. Model Building**","73ef2b02":"Here we saw that all the datapoints are clstered nicely with very less errors by using k-means clustering as compared to other clustering algorithms. So we'll use K-Means model for clustering in this dataset.","e5cd9de9":"## **c) Spectral Clustering**","33f27b56":"# **3. Load Dataset:**","d6f64760":"**Visualization of dataset**","5a23df42":"This case requires to develop a customer segmentation to define marketing strategy. The\nsample Dataset summarizes the usage behavior of about 9000 active credit card holders during the last 6 months. The file is at a customer level with 18 behavioral variables.\n\n\nFollowing is the Data Dictionary for Credit Card dataset :-\n\n**CUSTID :** Identification of Credit Card holder (Categorical)\n\n**BALANCE :** Balance amount left in their account to make purchases\n\n**BALANCEFREQUENCY :** How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n\n**PURCHASES :** Amount of purchases made from account\n\n**ONEOFFPURCHASES :** Maximum purchase amount done in one-go\n\n**INSTALLMENTSPURCHASES :** Amount of purchase done in installment\n\n**CASHADVANCE :** Cash in advance given by the user\n\n**PURCHASESFREQUENCY :** How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n\n**ONEOFFPURCHASESFREQUENCY :** How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\nPURCHASESINSTALLMENTSFREQUENCY : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n\n**CASHADVANCEFREQUENCY :** How frequently the cash in advance being paid\n\n**CASHADVANCETRX :** Number of Transactions made with \"Cash in Advanced\"\n\n**PURCHASESTRX :** Numbe of purchase transactions made\n\n**CREDITLIMIT :** Limit of Credit Card for user\n\n**PAYMENTS :** Amount of Payment done by user\n\n**MINIMUM_PAYMENTS :** Minimum amount of payments made by user\n\n**PRCFULLPAYMENT :** Percent of full payment paid by user\n\n**TENURE :** Tenure of credit card service for user","71fb2201":"# **5. Outlier Detection**","3fe5f617":"# **1. Overview**","39ea29ca":"# **4.Exploratory Data Analysis:**","f62198e6":"Here we saw that there is a little change in normal distribution of data by filling mean value in the columns where filling median affect the distribution more. So it's good to fill mean value in missing values.","348e772b":"# **9. Save The Model**"}}