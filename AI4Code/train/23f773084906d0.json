{"cell_type":{"ad39e800":"code","03c8827b":"code","75332620":"code","3b8cc069":"code","146b762a":"code","672d2d5d":"code","9ac15389":"code","42ed55cf":"code","76eddfc4":"code","cba3d3fd":"code","c7b32c77":"code","8e8d1ae2":"code","9cd67d16":"code","e65a05c8":"code","2c0140f7":"code","a03725ff":"code","b9841f7b":"code","05738b54":"code","c1a8ba47":"code","3e891a39":"code","5f1668af":"code","d9b2eda4":"code","9ee35bf0":"code","19c86cfa":"code","3763ee9c":"code","91e52cb0":"code","4c480381":"code","2e31d5a9":"code","ffe67415":"code","3b8d33e5":"code","22cb440b":"code","aa23a854":"code","fbcbb266":"code","d348d743":"markdown","d6e97ed0":"markdown","91d18976":"markdown","04061f62":"markdown","8ee86b89":"markdown","0202e16c":"markdown","be1b64a1":"markdown","ae74a7b7":"markdown","588d4b1a":"markdown","a376952b":"markdown","a84b099f":"markdown","be003c16":"markdown","8f3eac5b":"markdown","8491a059":"markdown","9bb1b348":"markdown","5c5f3b50":"markdown","49c9053b":"markdown","ce2979f3":"markdown","633d1abf":"markdown"},"source":{"ad39e800":"import pandas as pd\nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom datetime import datetime\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom warnings import filterwarnings\nimport warnings\nfrom pandas import DataFrame\nfrom pandas import concat\n\nwarnings.filterwarnings(\"ignore\")\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import neighbors\nfrom numpy import sqrt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.ensemble import RandomForestRegressor","03c8827b":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndf = pd.read_csv('\/kaggle\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv')\nprint('Esta base de datos consta de (filas,columnas): ', df.shape,'\\n')","75332620":"df.info()","3b8cc069":"df.index = pd.to_datetime(df['Timestamp'],unit='s')\ndf=df.drop(['Timestamp'],axis=1)\ndf=df.resample('D').mean()\ndf=df.dropna()\ndf=df.drop(['Open','High','Low','Close'],axis=1)","146b762a":"def grafico_bloxplot(data):\n    plt.rcParams['figure.figsize']=10,5\n    vs3=sns.boxplot(data=data,orient='v',color=\"Green\",palette=\"Set2\")\n    plt.title(\"'Identificaci\u00f3n de outliers en la base de datos'\")\n    plt.show()\ndef correlacion1(data,metodo):\n    plt.rcParams['figure.figsize']=10,5\n    correlacion=data.corr(method=metodo,min_periods=10)\n    sns.heatmap(correlacion, cmap='YlGnBu', annot=True, fmt='.2f', vmin=0)\n    plt.show() ","672d2d5d":"correlacion1(df,'pearson')","9ac15389":"grafico_bloxplot(df['Volume_(BTC)'])\ngrafico_bloxplot(df['Volume_(Currency)'])\ngrafico_bloxplot(df['Weighted_Price'])","42ed55cf":"for c in df.columns:\n    df[c] = df[c][np.abs(df[c]-df[c].mean())<=(2*df[c].std())]\n\ndf = df.dropna()\ndf.info()","76eddfc4":"grafico_bloxplot(df['Volume_(BTC)'])\ngrafico_bloxplot(df['Volume_(Currency)'])\ngrafico_bloxplot(df['Weighted_Price'])","cba3d3fd":"df_s = MinMaxScaler(feature_range=(0, 1))\ndf_s = df_s.fit_transform(df)","c7b32c77":"df1 = pd.DataFrame(df_s,columns=['Volume_(BTC)', 'Volume_(Currency)', 'Weighted_Price'])\ndf2=df1","8e8d1ae2":"df1=df1.sample(frac=1)\nX=df1.drop(['Weighted_Price'],axis=1)\nY=df1['Weighted_Price']","9cd67d16":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.80,shuffle=False)\nX_train,X_val,Y_train,Y_val=train_test_split(X_train,Y_train,train_size=0.90,shuffle=False)\nprint('La data original contiene:', X.shape[0],'filas y',X.shape[1]+1,'columnas')\nprint('La data para entrenamiento contiene:', X_train.shape[0],'filas y',X_train.shape[1],'columnas')\nprint('La data de validaci\u00f3n contiene:', X_val.shape[0],'filas y',X_val.shape[1],'columnas')\nprint('La data de test contiene:', X_test.shape[0],'filas y',X_test.shape[1],'columnas')","e65a05c8":"model = Sequential()\n\nmodel.add(Dense(300, input_dim=X_train.shape[1], activation='relu')) \nmodel.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dropout(0.05))\nmodel.add(Dense(30, input_dim=X_train.shape[1], activation='relu')) \nmodel.add(Dense(3, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(1)) \n\nmodel.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, epochs=100, batch_size=100, validation_data=(X_val, Y_val), verbose=False)","2c0140f7":"plt.figure(figsize=(10, 4))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","a03725ff":"X2=df2.drop(['Weighted_Price'],axis=1)\nY2=df2['Weighted_Price']\nX_train2,X_test2,Y_train2,Y_test2=train_test_split(X2,Y2,train_size=0.80,shuffle=False)\nX_train2,X_val2,Y_train2,Y_val2=train_test_split(X_train2,Y_train2,train_size=0.90,shuffle=False)\npred = model.predict(X_test2)\nplt.figure(figsize=(20, 10))\nplt.plot(Y_test2.values, marker='.',label='Test')\nplt.plot(pred, marker='.',label='Pred')\nplt.legend()\nplt.show()","b9841f7b":"error = sqrt(mean_squared_error(Y_test2,pred))\nprint('RMSE =',error)\nfrom sklearn.metrics import r2_score\nprint('R2 score =',r2_score(Y_test2, pred))","05738b54":"param={'n_estimators': range(100,1000,20),'max_depth': range(2,10)}\n\nforest = RandomForestRegressor()\nforest = GridSearchCV(forest,param_grid=param,scoring='r2',cv=5,return_train_score=True)\nforest.fit(X_train, Y_train)\n\nrandomforest_score = forest.score(X_val, Y_val)\n\nprint('Forest Score: ', randomforest_score)","c1a8ba47":"results= cross_validate(forest, X,Y,return_train_score=True,cv=5)\nresults","3e891a39":"pred = forest.predict(X_test2)\nplt.figure(figsize=(20, 10))\nplt.plot(Y_test2.values, marker='.')\nplt.plot(pred, marker='.' )\nplt.show()","5f1668af":"model_KNN = neighbors.KNeighborsRegressor()\nmodel_KNN=GridSearchCV(model_KNN,param_grid={'n_neighbors': list(range(2,20))})\nmodel_KNN.fit(X_train, Y_train)\n\npred=model_KNN.predict(X_test)\n\nerror = sqrt(mean_squared_error(Y_test,pred))\nprint('RMSE value' , error)\n\ncoeff = np.corrcoef(Y_test,pred)\nprint('coeff value', coeff)","d9b2eda4":"results= cross_validate(model_KNN, X,Y,return_train_score=True,cv=5)\nresults","9ee35bf0":"pred = model_KNN.predict(X_test2)\nplt.figure(figsize=(20, 10))\nplt.plot(Y_test2.values, marker='.')\nplt.plot(pred, marker='.' )\nplt.show()","19c86cfa":"def df_pasado(data, pasado, presente, dropnan=True):\n    variables = 1 if type(data) is list else data.shape[1]\n    df = DataFrame(data)\n    columnas, nombre = list(), list()\n    for i in range(pasado, 0, -1):\n        columnas.append(df.shift(i))\n        nombre += [('Variable%d(t-%d)' % (j+1, i)) for j in range(variables)]\n    for i in range(0, presente):\n        columnas.append(df.shift(-i))\n        if i == 0:\n            nombre += [('Variable%d(t)' % (j+1)) for j in range(variables)]\n        else:\n            nombre += [('Variable%d(t+%d)' % (j+1, i)) for j in range(variables)]\n    matriz = concat(columnas, axis=1)\n    matriz.columns = nombre\n    if dropnan:\n        matriz.dropna(inplace=True)\n    return matriz","3763ee9c":"df3 = df_pasado(df2, 2, 1)","91e52cb0":"df3=df3.drop(['Variable1(t)', 'Variable2(t)'],axis=1)","4c480381":"df3.columns=['Volume_(BTC)(t-2)', 'Volume_(Currency)(t-2)', 'Weighted_Price(t-2)', 'Volume_(BTC)(t-1)', 'Volume_(Currency)(t-1)',\n       'Weighted_Price(t-1)', 'Weighted_Price(t)']","2e31d5a9":"df4=df3.sample(frac=1)\nX=df4.drop(['Weighted_Price(t)'],axis=1)\nY=df4['Weighted_Price(t)']","ffe67415":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.80,shuffle=False)\nX_train,X_val,Y_train,Y_val=train_test_split(X_train,Y_train,train_size=0.90,shuffle=False)\nprint('La data original contiene:', X.shape[0],'filas y',X.shape[1]+1,'columnas')\nprint('La data para entrenamiento contiene:', X_train.shape[0],'filas y',X_train.shape[1],'columnas')\nprint('La data de validaci\u00f3n contiene:', X_val.shape[0],'filas y',X_val.shape[1],'columnas')\nprint('La data de test contiene:', X_test.shape[0],'filas y',X_test.shape[1],'columnas')","3b8d33e5":"model = Sequential()\n\nmodel.add(Dense(300, input_dim=X_train.shape[1], activation='relu')) \nmodel.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dropout(0.05))\nmodel.add(Dense(30, input_dim=X_train.shape[1], activation='relu')) \nmodel.add(Dense(3, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(1)) \n\nmodel.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, epochs=100, batch_size=100, validation_data=(X_val, Y_val), verbose=False)","22cb440b":"plt.figure(figsize=(10, 4))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","aa23a854":"X2=df3.drop(['Weighted_Price(t)'],axis=1)\nY2=df3['Weighted_Price(t)']\nX_train2,X_test2,Y_train2,Y_test2=train_test_split(X2,Y2,train_size=0.80,shuffle=False)\nX_train2,X_val2,Y_train2,Y_val2=train_test_split(X_train2,Y_train2,train_size=0.90,shuffle=False)\npred = model.predict(X_test2)\nplt.figure(figsize=(20, 10))\nplt.plot(Y_test2.values, marker='.',label='Test')\nplt.plot(pred, marker='.',label='Pred')\nplt.legend()\nplt.show()","fbcbb266":"error = sqrt(mean_squared_error(Y_test2,pred))\nprint('RMSE =',error)\nfrom sklearn.metrics import r2_score\nprint('R2 score =',r2_score(Y_test2, pred))","d348d743":"## <center> Conclusion\n**A traves de los diferentes algoritmos de regresi\u00f3n y considerando un dataset no sucesivo para entrenar tales algoritmos los resultados de la red neuronal y knn fueron sobresalientes. Lo cual hace concluir que se logra una buena estimaci\u00f3n del valor del bitcoin a traves de 2 variables, en este caso Volume(BTC) y Volume(Currency)**\n    \n**Debido a que Cross-validation arrojo una muy buena puntuaci\u00f3n y similar para los datos de entrenamiento y test no se puede considerar un overfitting en el algortimo. Para el caso de la NN las metricas R2 y RMSE son bastantes buenas las cuales indican que el modelo tiene un alto grado de precision y un buen ajuste con respecto a los datos**","d6e97ed0":"## <center> Desarrollo de KNN\n**Se buscan los mejores parametros de \"n_neighbors\" mediante GridSearch, posteriormente se pueden observar las metricas de desempe\u00f1o del algoritmo.**","91d18976":"# Conclusi\u00f3n 2","04061f62":"**Se procede a eliminar valores atipicos.**","8ee86b89":"## <center> Correlacion y Boxplot\n**A continuacion se crearan funciones para realizar la correlacion de las variables y que se grafiquen los boxplots.**","0202e16c":"En la presente secci\u00f3n se realizara la predicci\u00f3n del precio del bitcoin solo con valores pasados de volumen y precio. Lo que podria ser de vital importancia al momento de querer estimar si es rentable una inversi\u00f3n en este tipo de criptomoneda","be1b64a1":"## <center> Cargamos dataset seleccionado","ae74a7b7":"**Se realiza Cross Validation en el algoritmo KNN.**","588d4b1a":"## <center> Cargamos librerias a utilizar","a376952b":"**Se realiza Cross Validation en el algoritmo de Random Forest.**","a84b099f":"## <center> Desarrollo de Neural Network","be003c16":"## Extra","8f3eac5b":"# <center> **Proyecto Final IA**\n**INTEGRANTES:**\n>*    Pedro L\u00f3pez V.\n>*    Ignacio Reyes V.\n    \n    \n**Se procedera a desarrollar una aplicacion donde se aplicara una serie de algoritmos de Machine Learning sobre un dataset que permite predecir el valor de Bitcoin a lo largo de tiempo, con el fin de comparar los distintos metodos en terminos de desempe\u00f1o.**","8491a059":"Debido a que el dataset es simple y las variables utilizadas afectan directamente el precio del bitcoin, los resultados de la predicci\u00f3n son buenos, y esto considerando solamente valores anteriores de las variables. Lo cual puede ser de gran aporte para decidir si invertir o no.","9bb1b348":"## <center> Desarrollo de Random Forest\n**Se buscan los mejores parametros de \"n_estimators\" y \"max_depth\" mediante GridSearch, posteriormente se puede observar la precision del algoritmo.**","5c5f3b50":"## <center> Caracteristicas de cada columna\n* **Timestamp :** Hora de inicio de la ventana de tiempo (ventana de 60 segundos)\n* **Open:** Precio de apertura en la ventana de hora de inicio \n* **High :** Precio alto dentro de la ventana de tiempo\n* **Low :** Precio bajo dentro de la ventana de tiempo\n* **Close :** Precio de cierre al final de la ventana de tiempo\n* **Volume_(BTC) :** Volumen de BTC negociado en esta ventana\n* **Volume_(Currency) :** Volumen de la moneda correspondiente negociada en esta ventana\n* **Weighted_Price :** VWAP- Precio promedio ponderado por volumen","49c9053b":"## <center> Separacion de data\n**A continuaci\u00f3n se procedera a separar la data, para entrenamiento, test y validacion. Posteriormente se probaran los distintos algoritmos de Machine Learning**","ce2979f3":"## <center> Normalizaci\u00f3n\n**A continuaci\u00f3n se procedera a escalar los valores entre 0 y 1**","633d1abf":" **Se puede observar que son casi 5 Millones de datos , esto debido a que la muestra esta tomada cada muy poco tiempo, por lo que acontinuacion se procedera a \nresamplear los datos, haciendo un promedio de los valores dentro de un d\u00eda. Ademas se procede a eliminar las columnas de Open, High, Low y Close debido a que \nsi se saca un promedio total por d\u00eda, estos 4 valores seran los mismos, tambien se procede a limpiar la data de los valores nulos.**"}}