{"cell_type":{"a42777d7":"code","b5910010":"code","65fa956f":"code","5ef7ecf0":"code","93f27d8a":"code","645a55b0":"code","2f8b34a9":"code","1e78c435":"code","3979ab87":"code","c6a7e3d4":"code","149d916f":"code","87ae02e1":"code","c2091d09":"code","c49a2e3e":"code","c727e1ec":"code","6e2db9fe":"code","9e7abb30":"code","ef48fb30":"code","5e905038":"code","66385b85":"code","e55d62db":"code","a43cca7c":"code","da3bd945":"code","1d670f62":"code","4682470b":"code","b38d34bf":"code","9d94087e":"code","300e6200":"code","55696f22":"code","1371ab9c":"code","f2dc282b":"markdown","42577e0b":"markdown","be4606aa":"markdown","95de8ecf":"markdown","e3837c7a":"markdown","da45e314":"markdown","bb3429a0":"markdown","aa28215f":"markdown","024d6e9a":"markdown","f2ba0642":"markdown","c9cf344a":"markdown","2b7c1f60":"markdown","2efdcdf5":"markdown","7e5c43dc":"markdown"},"source":{"a42777d7":"!pip install bs4","b5910010":"import requests\nfrom bs4 import BeautifulSoup\nimport numpy as np\nimport pandas as pd\n\n\n","65fa956f":"!pip install cfscrape","5ef7ecf0":"import cfscrape\nscraper =cfscrape.create_scraper()\n\n","93f27d8a":"links = []\ni = 1;","645a55b0":"while i < 500:\n    url = \"https:\/\/www.imdb.com\/search\/title\/?title_type=tv_series&countries=in&start={}&ref_=adv_nxt\".format(i);\n    req = scraper.get(url)\n    webp = req.text\n    soup = BeautifulSoup(webp, 'html.parser')\n    all_headers = soup.findAll(\"h3\",\"lister-item-header\")\n    for header in all_headers:\n        link = header.a['href']\n        link = 'https:\/\/www.imdb.com' + link\n        links.append(link)\n    i+=50\n    ","2f8b34a9":"links","1e78c435":"len(links)","3979ab87":"# Name\ndef name(soup):\n    return soup.find('h1').text.strip()","c6a7e3d4":"# Duration\ndef duration(soup):\n    try:\n        return soup.find('time').text.strip()\n    except:\n        return np.nan","149d916f":"# Genre\ndef genre(soup):\n    try:\n        tags = soup.find('div','subtext').findAll('a')[:-1]\n        genres = []\n        for t in tags:\n            genres.append(t.text.strip())\n        return genres\n    except:\n        return np.nan","87ae02e1":"# Ratings\ndef ratings(soup):\n    try:\n        return float(soup.find('div','imdbRating').div.strong.text)\n    except:\n        return np.nan","c2091d09":"# No. of Ratings\ndef no_ratings(soup):\n    try:\n        return int(soup.find('div','imdbRating').find('a').text.replace(',',''))\n    except:\n        return np.nan","c49a2e3e":"# No. of Episodes\ndef episodes(soup):\n    try:\n        return int(soup.find('div','button_panel navigation_panel').span.text[:-8].strip())\n    except:\n        return np.nan","c727e1ec":"# Creators \ndef creators(soup):\n    try:\n        creators = []\n        if len(soup.findAll('div','credit_summary_item')) == 1:\n            return np.nan\n        else:\n            for creator in soup.findAll('div','credit_summary_item')[0].findAll('a'):\n                creator = creator.text\n                creators.append(creator)\n        return creators\n    \n    except:\n        return np.nan","6e2db9fe":"# Stars\ndef stars(soup):\n    try:\n        stars = []\n        idx = 1\n        if len(soup.findAll('div','credit_summary_item')) == 1:\n            idx = 0\n        for star in soup.findAll('div','credit_summary_item')[idx].findAll('a'):\n            star = star.text\n            stars.append(star)\n        stars = stars[:-1]\n        return stars\n    except:\n        return np.nan","9e7abb30":"# Reviews (Users)\ndef reviews_users(soup):\n    try:\n        return int(soup.find('span','subText').findAll('a')[0].text[:-4].replace(',','').strip())\n    except:\n        return np.nan","ef48fb30":"# Reviews (Critics)\ndef reviews_critics(soup):\n    try:\n        return int(soup.find('span','subText').findAll('a')[1].text[:-6].replace(',','').strip())\n    except:\n        np.nan","5e905038":"# Seasons \ndef seasons(soup):\n    try:\n        return int(soup.find('div','seasons-and-year-nav').findAll('a')[0].text.strip())\n    except:\n        return np.nan","66385b85":"# Storyline\ndef storyline(soup):\n    try:\n        return soup.find('div','inline canwrap').text.strip()\n    except:\n        return np.nan","e55d62db":"# Language\ndef language(soup):\n    try:\n        return soup.find('h4',text='Language:').parent.a.text\n    except:\n        return np.nan","a43cca7c":"# Release Date \ndef release_data(soup):\n    try:\n        return soup.find('h4',text='Release Date:').parent.text.replace(\"Release Date:\",\"\").replace(\"    \\nSee more\\xa0\u00bb\\n    \\n\",\"\").strip()\n    except:\n        return np.nan","da3bd945":"def row_maker(soup):\n    row = []\n    row.append(name(soup))\n    row.append(duration(soup))\n    row.append(genre(soup))\n    row.append(ratings(soup))\n    row.append(no_ratings(soup))\n    row.append(episodes(soup))\n    row.append(creators(soup))\n    row.append(stars(soup))\n    row.append(reviews_users(soup))\n    row.append(reviews_critics(soup))\n    row.append(seasons(soup))\n    row.append(storyline(soup))\n    row.append(language(soup))\n    row.append(release_data(soup))\n    return row","1d670f62":"def table_maker(links_list):\n    table = []\n    count = 0\n    for i in links_list:\n        req = scraper.get(i)\n        webp = req.text\n        soup = BeautifulSoup(webp, 'html.parser')\n        print(i)\n        print(count)\n        table.append(row_maker(soup))\n        count+=1\n        \n    tab_arr = np.array(table)\n    return tab_arr\n        \n        ","4682470b":"top_500 = table_maker(links)","b38d34bf":"cols = ['Name',\n'Duration',\n'Genre',\n'Rating',\n'No. of Ratings',\n'No. of Episodes',\n'Creators', \n'Stars',\n'Reviews (Users)',\n'Reviews (Critics)',\n'Seasons',\n'Storyline',\n'Language',\n'Release Date']","9d94087e":"top_500","300e6200":"data = pd.DataFrame(top_500, columns = cols)","55696f22":"data","1371ab9c":"data.to_csv(\"IMDd Top Indian TV Shows.csv\")","f2dc282b":"### Creating a list of all the links , which are to be scraped!","42577e0b":"### We are trying to extract the following features of the IMDB webpage\n* Name\n* Duration\n* Genre\n* Rating\n* No. of Ratings\n* No. of Episodes\n* Creators \n* Stars\n* Reviews (Users)\n* Reviews (Critics)\n* Seasons\n* Storyline\n* Language\n* Release Date","be4606aa":"### The following function is used to create the table","95de8ecf":"### Thank You for being here! :)","e3837c7a":"![](https:\/\/static.amazon.jobs\/teams\/53\/images\/IMDb_Header_Page.jpg?1501027252\/)","da45e314":"### Importing the main Libraries","bb3429a0":"### Converting it into a DataFrame","aa28215f":"### Looping through the pages and adding the links to the list. Each page contains 50 links , and thus we are incrementing the pointer by 50 per iteration","024d6e9a":"### Part 2","f2ba0642":"### So now we have the links of the top 500 TV Shows in our list!","c9cf344a":"### This notebooks aims on creating a dataset of the top Indian TV Shows from IMDb. Beginners may use this notebook as reference to learn basic web scraping and work on similar projects!\n\n### Feedbacks and Suggestions are always welcome :)\n","2b7c1f60":"### We will be using the cfscrape module from python for this project - Cfscrafe is used to bypass Cloudflare's anti-bot page","2efdcdf5":"### The following function is used to create a row out of a particular example","7e5c43dc":"### The following snippets present a function for each of the feature mentioned above. Every function takes the soup object as input and returns the particular feature based on the response from the website.\n> There are a few examples which don't have the particular feature available , inorder to handle them i have used the try-except statements , if the example is unable to respond properly to the request and not return the feature we return nan value instead. "}}