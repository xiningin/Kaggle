{"cell_type":{"790dcf96":"code","85024392":"code","9dcbeb2b":"code","de7849fb":"code","2e580d65":"code","b68a3035":"code","d69d3e89":"markdown","b64a6a82":"markdown","0d4ac3be":"markdown","6a18820c":"markdown","6d989f74":"markdown","1cc43dfd":"markdown","4ec96ebe":"markdown","7b9c9715":"markdown","b4a9e9fb":"markdown","aaa2d178":"markdown"},"source":{"790dcf96":"from IPython.utils import io\nimport os\nimport subprocess\nimport tqdm.notebook\n\nTQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}\/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n\ntry:\n  with tqdm.notebook.tqdm(total=100, bar_format=TQDM_BAR_FORMAT) as pbar:\n    with io.capture_output() as captured:\n      # Uninstall default Colab version of TF.\n      !pip uninstall -y tensorflow\n\n      !apt install --quiet --yes hmmer\n      pbar.update(6)\n\n      # Install py3dmol.\n      !pip install py3dmol\n      pbar.update(2)\n\n      # Install OpenMM and pdbfixer.\n      !rm -rf \/opt\/conda\n      !wget -q -P \/tmp \\\n        https:\/\/repo.anaconda.com\/miniconda\/Miniconda3-latest-Linux-x86_64.sh \\\n          && bash \/tmp\/Miniconda3-latest-Linux-x86_64.sh -b -p \/opt\/conda \\\n          && rm \/tmp\/Miniconda3-latest-Linux-x86_64.sh\n      pbar.update(9)\n\n      PATH=%env PATH\n      !env PATH=\/opt\/conda\/bin:{PATH}\n      !conda update -qy conda \\\n          && conda install -qy -c conda-forge \\\n            python=3.7 \\\n            openmm=7.5.1 \\\n            pdbfixer\n      pbar.update(80)\n\n      # Create a ramdisk to store a database chunk to make Jackhmmer run fast.\n      !mkdir -m 777 --parents \/tmp\/ramdisk\n      !mount -t tmpfs -o size=9G ramdisk \/tmp\/ramdisk\n      pbar.update(2)\n\n      !wget -q -P \/content \\\n        https:\/\/git.scicore.unibas.ch\/schwede\/openstructure\/-\/raw\/7102c63615b64735c4941278d92b554ec94415f8\/modules\/mol\/alg\/src\/stereo_chemical_props.txt\n      pbar.update(1)\nexcept subprocess.CalledProcessError:\n  print(captured)\n  raise","85024392":"GIT_REPO = 'https:\/\/github.com\/deepmind\/alphafold'\n\nSOURCE_URL = 'https:\/\/storage.googleapis.com\/alphafold\/alphafold_params_2021-07-14.tar'\nPARAMS_DIR = '.\/alphafold\/data\/params'\nPARAMS_PATH = os.path.join(PARAMS_DIR, os.path.basename(SOURCE_URL))\n\ntry:\n  with tqdm.notebook.tqdm(total=100, bar_format=TQDM_BAR_FORMAT) as pbar:\n    with io.capture_output() as captured:\n      !rm -rf alphafold\n      !git clone {GIT_REPO} alphafold\n      pbar.update(8)\n      # Install the required versions of all dependencies.\n      !pip3 install -r .\/alphafold\/requirements.txt\n      # Run setup.py to install only AlphaFold.\n      !pip3 install --no-dependencies .\/alphafold\n      pbar.update(10)\n\n      # Apply OpenMM patch.\n      !pushd \/opt\/conda\/lib\/python3.7\/site-packages\/ && \\\n          patch -p0 < \/content\/alphafold\/docker\/openmm.patch && \\\n          popd\n          \n      !mkdir -p .\/alphafold\/common\n      !cp -f \/content\/stereo_chemical_props.txt .\/alphafold\/common\n\n      !mkdir --parents \"{PARAMS_DIR}\"\n      !wget -O \"{PARAMS_PATH}\" \"{SOURCE_URL}\"\n      pbar.update(27)\n\n      !tar --extract --verbose --file=\"{PARAMS_PATH}\" \\\n        --directory=\"{PARAMS_DIR}\" --preserve-permissions\n      !rm \"{PARAMS_PATH}\"\n      pbar.update(55)\nexcept subprocess.CalledProcessError:\n  print(captured)\n  raise\n\nimport jax\n#if jax.local_devices()[0].platform == 'tpu':\n#  raise RuntimeError('Colab TPU runtime not supported. Change it to GPU via Runtime -> Change Runtime Type -> Hardware accelerator -> GPU.')\n#elif jax.local_devices()[0].platform == 'cpu':\n#  raise RuntimeError('Colab CPU runtime not supported. Change it to GPU via Runtime -> Change Runtime Type -> Hardware accelerator -> GPU.')  ","9dcbeb2b":"# Enter the amino acid sequence to fold \u2b07\ufe0f\nsequence = 'MAAHKGAEHHHKAAEHHEQAAKHHHAAAEHHEKGEHEQAAHHADTAYAHHKHAEEHAAQAAKHDAEHHAPKPH'  #@param {type:\"string\"}\n\nMIN_SEQUENCE_LENGTH = 16\nMAX_SEQUENCE_LENGTH = 2500\n\n# Remove all whitespaces, tabs and end lines; upper-case\nsequence = sequence.translate(str.maketrans('', '', ' \\n\\t')).upper()\naatypes = set('ACDEFGHIKLMNPQRSTVWY')  # 20 standard aatypes\nif not set(sequence).issubset(aatypes):\n  raise Exception(f'Input sequence contains non-amino acid letters: {set(sequence) - aatypes}. AlphaFold only supports 20 standard amino acids as inputs.')\nif len(sequence) < MIN_SEQUENCE_LENGTH:\n  raise Exception(f'Input sequence is too short: {len(sequence)} amino acids, while the minimum is {MIN_SEQUENCE_LENGTH}')\nif len(sequence) > MAX_SEQUENCE_LENGTH:\n  raise Exception(f'Input sequence is too long: {len(sequence)} amino acids, while the maximum is {MAX_SEQUENCE_LENGTH}. Please use the full AlphaFold system for long sequences.')","de7849fb":"!pip install py3Dmol","2e580d65":"import sys\nimport os\nos.environ['TF_FORCE_UNIFIED_MEMORY'] = '1'\nos.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '2.0'\n\nfrom urllib import request\nfrom concurrent import futures\n\nimport json\nfrom matplotlib import gridspec\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport py3Dmol\n\nfrom alphafold.model import model\nfrom alphafold.model import config\nfrom alphafold.model import data\n\nfrom alphafold.data import parsers\nfrom alphafold.data import pipeline\nfrom alphafold.data.tools import jackhmmer\n\nfrom alphafold.common import protein\n\nfrom alphafold.relax import relax\nfrom alphafold.relax import utils\n\nfrom IPython import display\nfrom ipywidgets import GridspecLayout\nfrom ipywidgets import Output\n\n# Color bands for visualizing plddt\nPLDDT_BANDS = [(0, 50, '#FF7D45'),\n               (50, 70, '#FFDB13'),\n               (70, 90, '#65CBF3'),\n               (90, 100, '#0053D6')]\n\n# --- Find the closest source ---\ntest_url_pattern = 'https:\/\/storage.googleapis.com\/alphafold-colab{:s}\/latest\/uniref90_2021_03.fasta.1'\nex = futures.ThreadPoolExecutor(3)\ndef fetch(source):\n  request.urlretrieve(test_url_pattern.format(source))\n  return source\nfs = [ex.submit(fetch, source) for source in ['', '-europe', '-asia']]\nsource = None\nfor f in futures.as_completed(fs):\n  source = f.result()\n  ex.shutdown()\n  break\n\n# --- Search against genetic databases ---\nwith open('target.fasta', 'wt') as f:\n  f.write(f'>query\\n{sequence}')\n\n# Run the search against chunks of genetic databases (since the genetic\n# databases don't fit in Colab ramdisk).\n\njackhmmer_binary_path = '\/usr\/bin\/jackhmmer'\ndbs = []\n\nnum_jackhmmer_chunks = {'uniref90': 59, 'smallbfd': 17, 'mgnify': 71}\ntotal_jackhmmer_chunks = sum(num_jackhmmer_chunks.values())\nwith tqdm.notebook.tqdm(total=total_jackhmmer_chunks, bar_format=TQDM_BAR_FORMAT) as pbar:\n  def jackhmmer_chunk_callback(i):\n    pbar.update(n=1)\n\n  pbar.set_description('Searching uniref90')\n  jackhmmer_uniref90_runner = jackhmmer.Jackhmmer(\n      binary_path=jackhmmer_binary_path,\n      database_path=f'https:\/\/storage.googleapis.com\/alphafold-colab{source}\/latest\/uniref90_2021_03.fasta',\n      get_tblout=True,\n      num_streamed_chunks=num_jackhmmer_chunks['uniref90'],\n      streaming_callback=jackhmmer_chunk_callback,\n      z_value=135301051)\n  dbs.append(('uniref90', jackhmmer_uniref90_runner.query('target.fasta')))\n\n  pbar.set_description('Searching smallbfd')\n  jackhmmer_smallbfd_runner = jackhmmer.Jackhmmer(\n      binary_path=jackhmmer_binary_path,\n      database_path=f'https:\/\/storage.googleapis.com\/alphafold-colab{source}\/latest\/bfd-first_non_consensus_sequences.fasta',\n      get_tblout=True,\n      num_streamed_chunks=num_jackhmmer_chunks['smallbfd'],\n      streaming_callback=jackhmmer_chunk_callback,\n      z_value=65984053)\n  dbs.append(('smallbfd', jackhmmer_smallbfd_runner.query('target.fasta')))\n\n  pbar.set_description('Searching mgnify')\n  jackhmmer_mgnify_runner = jackhmmer.Jackhmmer(\n      binary_path=jackhmmer_binary_path,\n      database_path=f'https:\/\/storage.googleapis.com\/alphafold-colab{source}\/latest\/mgy_clusters_2019_05.fasta',\n      get_tblout=True,\n      num_streamed_chunks=num_jackhmmer_chunks['mgnify'],\n      streaming_callback=jackhmmer_chunk_callback,\n      z_value=304820129)\n  dbs.append(('mgnify', jackhmmer_mgnify_runner.query('target.fasta')))\n\n\n# --- Extract the MSAs and visualize ---\n# Extract the MSAs from the Stockholm files.\n# NB: deduplication happens later in pipeline.make_msa_features.\n\nmgnify_max_hits = 501\n\nmsas = []\ndeletion_matrices = []\nfull_msa = []\nfor db_name, db_results in dbs:\n  unsorted_results = []\n  for i, result in enumerate(db_results):\n    msa, deletion_matrix, target_names = parsers.parse_stockholm(result['sto'])\n    e_values_dict = parsers.parse_e_values_from_tblout(result['tbl'])\n    e_values = [e_values_dict[t.split('\/')[0]] for t in target_names]\n    zipped_results = zip(msa, deletion_matrix, target_names, e_values)\n    if i != 0:\n      # Only take query from the first chunk\n      zipped_results = [x for x in zipped_results if x[2] != 'query']\n    unsorted_results.extend(zipped_results)\n  sorted_by_evalue = sorted(unsorted_results, key=lambda x: x[3])\n  db_msas, db_deletion_matrices, _, _ = zip(*sorted_by_evalue)\n  if db_msas:\n    if db_name == 'mgnify':\n      db_msas = db_msas[:mgnify_max_hits]\n      db_deletion_matrices = db_deletion_matrices[:mgnify_max_hits]\n    full_msa.extend(db_msas)\n    msas.append(db_msas)\n    deletion_matrices.append(db_deletion_matrices)\n    msa_size = len(set(db_msas))\n    print(f'{msa_size} Sequences Found in {db_name}')\n\ndeduped_full_msa = list(dict.fromkeys(full_msa))\ntotal_msa_size = len(deduped_full_msa)\nprint(f'\\n{total_msa_size} Sequences Found in Total\\n')\n\naa_map = {restype: i for i, restype in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ-')}\nmsa_arr = np.array([[aa_map[aa] for aa in seq] for seq in deduped_full_msa])\nnum_alignments, num_res = msa_arr.shape\n\nfig = plt.figure(figsize=(12, 3))\nplt.title('Per-Residue Count of Non-Gap Amino Acids in the MSA')\nplt.plot(np.sum(msa_arr != aa_map['-'], axis=0), color='black')\nplt.ylabel('Non-Gap Count')\nplt.yticks(range(0, num_alignments + 1, max(1, int(num_alignments \/ 3))))\nplt.show()","b68a3035":"model_names = ['model_1', 'model_2', 'model_3', 'model_4', 'model_5', 'model_2_ptm']\n\ndef _placeholder_template_feats(num_templates_, num_res_):\n  return {\n      'template_aatype': np.zeros([num_templates_, num_res_, 22], np.float32),\n      'template_all_atom_masks': np.zeros([num_templates_, num_res_, 37, 3], np.float32),\n      'template_all_atom_positions': np.zeros([num_templates_, num_res_, 37], np.float32),\n      'template_domain_names': np.zeros([num_templates_], np.float32),\n      'template_sum_probs': np.zeros([num_templates_], np.float32),\n  }\n\noutput_dir = 'prediction'\nos.makedirs(output_dir, exist_ok=True)\n\nplddts = {}\npae_outputs = {}\nunrelaxed_proteins = {}\n\nwith tqdm.notebook.tqdm(total=len(model_names) + 1, bar_format=TQDM_BAR_FORMAT) as pbar:\n  for model_name in model_names:\n    pbar.set_description(f'Running {model_name}')\n    num_templates = 0\n    num_res = len(sequence)\n\n    feature_dict = {}\n    feature_dict.update(pipeline.make_sequence_features(sequence, 'test', num_res))\n    feature_dict.update(pipeline.make_msa_features(msas, deletion_matrices=deletion_matrices))\n    feature_dict.update(_placeholder_template_feats(num_templates, num_res))\n\n    cfg = config.model_config(model_name)\n    params = data.get_model_haiku_params(model_name, '.\/alphafold\/data')\n    model_runner = model.RunModel(cfg, params)\n    processed_feature_dict = model_runner.process_features(feature_dict,\n                                                           random_seed=0)\n    prediction_result = model_runner.predict(processed_feature_dict)\n\n    mean_plddt = prediction_result['plddt'].mean()\n\n    if 'predicted_aligned_error' in prediction_result:\n      pae_outputs[model_name] = (\n          prediction_result['predicted_aligned_error'],\n          prediction_result['max_predicted_aligned_error']\n      )\n    else:\n      # Get the pLDDT confidence metrics. Do not put pTM models here as they\n      # should never get selected.\n      plddts[model_name] = prediction_result['plddt']\n\n    # Set the b-factors to the per-residue plddt.\n    final_atom_mask = prediction_result['structure_module']['final_atom_mask']\n    b_factors = prediction_result['plddt'][:, None] * final_atom_mask\n    unrelaxed_protein = protein.from_prediction(processed_feature_dict,\n                                                prediction_result,\n                                                b_factors=b_factors)\n    unrelaxed_proteins[model_name] = unrelaxed_protein\n\n    # Delete unused outputs to save memory.\n    del model_runner\n    del params\n    del prediction_result\n    pbar.update(n=1)\n\n  # --- AMBER relax the best model ---\n  pbar.set_description(f'AMBER relaxation')\n  amber_relaxer = relax.AmberRelaxation(\n      max_iterations=0,\n      tolerance=2.39,\n      stiffness=10.0,\n      exclude_residues=[],\n      max_outer_iterations=20)\n  # Find the best model according to the mean pLDDT.\n  best_model_name = max(plddts.keys(), key=lambda x: plddts[x].mean())\n  relaxed_pdb, _, _ = amber_relaxer.process(\n      prot=unrelaxed_proteins[best_model_name])\n  pbar.update(n=1)  # Finished AMBER relax.\n\n# Construct multiclass b-factors to indicate confidence bands\n# 0=very low, 1=low, 2=confident, 3=very high\nbanded_b_factors = []\nfor plddt in plddts[best_model_name]:\n  for idx, (min_val, max_val, _) in enumerate(PLDDT_BANDS):\n    if plddt >= min_val and plddt <= max_val:\n      banded_b_factors.append(idx)\n      break\nbanded_b_factors = np.array(banded_b_factors)[:, None] * final_atom_mask\nto_visualize_pdb = utils.overwrite_b_factors(relaxed_pdb, banded_b_factors)\n\n\n# Write out the prediction\npred_output_path = os.path.join(output_dir, 'selected_prediction.pdb')\nwith open(pred_output_path, 'w') as f:\n  f.write(relaxed_pdb)\n\n\n# --- Visualise the prediction & confidence ---\nshow_sidechains = True\ndef plot_plddt_legend():\n  \"\"\"Plots the legend for pLDDT.\"\"\"\n  thresh = [\n            'Very low (pLDDT < 50)',\n            'Low (70 > pLDDT > 50)',\n            'Confident (90 > pLDDT > 70)',\n            'Very high (pLDDT > 90)']\n\n  colors = [x[2] for x in PLDDT_BANDS]\n\n  plt.figure(figsize=(2, 2))\n  for c in colors:\n    plt.bar(0, 0, color=c)\n  plt.legend(thresh, frameon=False, loc='center', fontsize=20)\n  plt.xticks([])\n  plt.yticks([])\n  ax = plt.gca()\n  ax.spines['right'].set_visible(False)\n  ax.spines['top'].set_visible(False)\n  ax.spines['left'].set_visible(False)\n  ax.spines['bottom'].set_visible(False)\n  plt.title('Model Confidence', fontsize=20, pad=20)\n  return plt\n\n# Color the structure by per-residue pLDDT\ncolor_map = {i: bands[2] for i, bands in enumerate(PLDDT_BANDS)}\nview = py3Dmol.view(width=800, height=600)\nview.addModelsAsFrames(to_visualize_pdb)\nstyle = {'cartoon': {\n    'colorscheme': {\n        'prop': 'b',\n        'map': color_map}\n        }}\nif show_sidechains:\n  style['stick'] = {}\nview.setStyle({'model': -1}, style)\nview.zoomTo()\n\ngrid = GridspecLayout(1, 2)\nout = Output()\nwith out:\n  view.show()\ngrid[0, 0] = out\n\nout = Output()\nwith out:\n  plot_plddt_legend().show()\ngrid[0, 1] = out\n\ndisplay.display(grid)\n\n# Display pLDDT and predicted aligned error (if output by the model).\nif pae_outputs:\n  num_plots = 2\nelse:\n  num_plots = 1\n\nplt.figure(figsize=[8 * num_plots, 6])\nplt.subplot(1, num_plots, 1)\nplt.plot(plddts[best_model_name])\nplt.title('Predicted LDDT')\nplt.xlabel('Residue')\nplt.ylabel('pLDDT')\n\nif num_plots == 2:\n  plt.subplot(1, 2, 2)\n  pae, max_pae = list(pae_outputs.values())[0]\n  plt.imshow(pae, vmin=0., vmax=max_pae, cmap='Greens_r')\n  plt.colorbar(fraction=0.046, pad=0.04)\n  plt.title('Predicted Aligned Error')\n  plt.xlabel('Scored residue')\n  plt.ylabel('Aligned residue')\n\n# Save pLDDT and predicted aligned error (if it exists)\npae_output_path = os.path.join(output_dir, 'predicted_aligned_error.json')\nif pae_outputs:\n  # Save predicted aligned error in the same format as the AF EMBL DB\n  rounded_errors = np.round(pae.astype(np.float64), decimals=1)\n  indices = np.indices((len(rounded_errors), len(rounded_errors))) + 1\n  indices_1 = indices[0].flatten().tolist()\n  indices_2 = indices[1].flatten().tolist()\n  pae_data = json.dumps([{\n      'residue1': indices_1,\n      'residue2': indices_2,\n      'distance': rounded_errors.flatten().tolist(),\n      'max_predicted_aligned_error': max_pae.item()\n  }],\n                        indent=None,\n                        separators=(',', ':'))\n  with open(pae_output_path, 'w') as f:\n    f.write(pae_data)\n\n# --- Download the predictions ---\n!zip -q -r {output_dir}.zip {output_dir}\n#from google.colab import files\n#files.download(f'{output_dir}.zip')","d69d3e89":"## Paper: [Highly accurate protein structure prediction with AlphaFold](https:\/\/www.nature.com\/articles\/s41586-021-03819-2)","b64a6a82":"## Interpreting the prediction\nPlease see the [AlphaFold methods paper](https:\/\/www.nature.com\/articles\/s41586-021-03819-2) and the [AlphaFold predictions of the human proteome paper](https:\/\/www.nature.com\/articles\/s41586-021-03828-1), as well as [our FAQ](https:\/\/alphafold.ebi.ac.uk\/faq) on how to interpret AlphaFold predictions.","0d4ac3be":"## Making a prediction","6a18820c":"### Differences to AlphaFold v2.0\nIn comparison to AlphaFold v2.0, this Colab notebook uses no templates (homologous structures) and a selected portion of the [BFD database](https:\/\/bfd.mmseqs.com\/). We have validated these changes on several thousand recent PDB structures. While accuracy will be near-identical to the full AlphaFold system on many targets, a small fraction have a large drop in accuracy due to the smaller MSA and lack of templates. For best reliability, we recommend instead using the [full open source AlphaFold](https:\/\/github.com\/deepmind\/alphafold\/), or the [AlphaFold Protein Structure Database](https:\/\/alphafold.ebi.ac.uk\/).\n\nPlease note that this Colab notebook is provided as an early-access prototype and is not a finished product. It is provided for theoretical modelling only and caution should be exercised in its use.\n\n### Citing this work\n\nAny publication that discloses findings arising from using this notebook should cite the [AlphaFold paper](https:\/\/www.nature.com\/articles\/s41586-021-03819-2).\n\n### Licenses\nThis Colab uses the [AlphaFold model parameters](https:\/\/github.com\/deepmind\/alphafold\/#model-parameters-license) and its outputs are thus for non-commercial use only, under the Creative Commons Attribution-NonCommercial 4.0 International [(CC BY-NC 4.0)](https:\/\/creativecommons.org\/licenses\/by-nc\/4.0\/legalcode) license. The Colab itself is provided under the [Apache 2.0 license](https:\/\/www.apache.org\/licenses\/LICENSE-2.0).","6d989f74":"## Run AlphaFold and download prediction","1cc43dfd":"# [AlphaFold Colab](https:\/\/colab.research.google.com\/github\/deepmind\/alphafold\/blob\/main\/notebooks\/AlphaFold.ipynb)\nThis Colab notebook allows you to easily predict the structure of a protein using a slightly simplified version of AlphaFold v2.0.","4ec96ebe":"## Search against genetic databases","7b9c9715":"## Download AlphaFold","b4a9e9fb":"## Install third-party software","aaa2d178":"## Architecture\n![image.png](attachment:d4067ba8-9f3c-4253-80af-bf148b214a33.png)"}}