{"cell_type":{"2cf80c14":"code","7618b339":"code","f694a85c":"code","cd3a36d2":"code","ec4c72fa":"code","9f67d3f6":"code","a4512db9":"code","434f67f6":"code","b47573aa":"code","3cc15057":"code","ec92a45a":"code","1fd9a696":"code","273330a9":"code","678352f2":"code","dcc830bb":"code","2adf4ebe":"code","e34e0da8":"code","9efa716b":"code","c822ec7f":"code","5e396fee":"code","7b9ebe8f":"code","6e09fef7":"code","d963e628":"code","d90c927c":"code","b88dc54c":"code","8cc5ebad":"code","a1830a37":"code","b68a28d8":"code","4d257d5b":"code","84a2a4fa":"code","cf972287":"code","bab4eada":"code","07f63f93":"code","8eac005b":"markdown","a2f34e1d":"markdown","4e0a7c2d":"markdown","a7f97de0":"markdown","2b1a81e8":"markdown","53cb3cf8":"markdown","18965037":"markdown","dc3a0685":"markdown","d753f733":"markdown","58d641a1":"markdown","4ffc7f74":"markdown","a2ac52aa":"markdown","8889b4e0":"markdown","1f3abdd5":"markdown","8f5862bb":"markdown","11d61aca":"markdown","9c8d1e3d":"markdown","9fa2f110":"markdown"},"source":{"2cf80c14":"%%HTML\n<style type=\"text\/css\">\n\ndiv.h1 {\n    font-size: 32px; \n    margin-bottom:2px;\n    background-color: steelblue; \n    color: white; \n    text-align: center;\n}\ndiv.h2 {\n    background-color: steelblue; \n    color: white; \n    padding: 8px; \n    padding-right: 300px; \n    font-size: 24px; \n    max-width: 1500px; \n    margin-top: 50px;\n    margin-bottom:4px;\n    \n}\ndiv.h3 {\n    color: steelblue; \n    font-size: 20px; \n    margin-top: 4px; \n    margin-bottom:8px;\n}\ndiv.h4 {\n    font-size: 15px; \n    margin-top: 20px; \n    margin-bottom: 8px;\n}\n\n<\/style>","7618b339":"# importing libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n%matplotlib inline \nsns.set(rc={'figure.figsize': [10,10]}, font_scale=1.3)","f694a85c":"# read the dataset\ndf = pd.read_csv('..\/input\/diamonds\/diamonds.csv')\ndf.head()","cd3a36d2":"#droping the first column as the data is already index by row index\ndf.drop('Unnamed: 0', axis=1, inplace = True) \ndf","ec4c72fa":"# cleaning process searching for null values\ndf.info()","9f67d3f6":"#same way to detect the number of null values\ndf.isnull().sum()","a4512db9":"df['cut'].value_counts()","434f67f6":"# coding the categories of 'cut' attribute into numbers by mapping method replacing the string by number\ncut_dict = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}\ndf['cut'] = df['cut'].map(cut_dict)\ndf.info() ","b47573aa":"df.color.unique()","3cc15057":"df.clarity.unique()","ec92a45a":"df.describe()","1fd9a696":"# using loc method and | (or) operator\ndf.loc[(df['x'] == 0) | (df['y'] == 0) | (df['z'] == 0)]\n","273330a9":"len(df[(df['x']==0) | (df['y']==0) | (df['z']==0)])","678352f2":"df = df[(df[['x', 'y', 'z']] !=0).all(axis=1)]","dcc830bb":"len(df[(df['x']==0) | (df['y']==0) | (df['z']==0)])","2adf4ebe":"df['size'] = df['x'] * df['y'] * df['z']\ndf","e34e0da8":"df = df.drop(df[['x', 'y', 'z']], axis=1)\ndf","9efa716b":"df.hist(bins=20, figsize=(20,15))\nplt.show()","c822ec7f":"## checking correlation between different attributes\ncorr = df.corr()\ncorr","5e396fee":"sns.heatmap(data=corr, square=True, annot=True, cmap=\"BuPu\")","7b9ebe8f":"X = df[['carat', 'cut', 'depth','table', 'size']]\ny = df['price']","6e09fef7":"# splitting the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 0)","d963e628":"scaler= StandardScaler()\n\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","d90c927c":"models = {\n    \"LR\": LinearRegression(),\n    \"KNR\" : KNeighborsRegressor(), \n    \"DT\": DecisionTreeRegressor(),\n    \"RF\": RandomForestRegressor(),\n}","b88dc54c":"for name, model in models.items():\n    print(f'Using model: {name}')\n    model.fit(X_train, y_train)\n    print(f'Training Score: {model.score(X_train, y_train)}')\n    print(f'Test Score: {model.score(X_test, y_test)}')  \n    print(f'RMSE: {np.sqrt(mean_squared_error(y_test, model.predict(X_test)))}')\n    print('-'*30)","8cc5ebad":"model = RandomForestRegressor(n_estimators = 6)\nmodel.fit(X_train,y_train)","a1830a37":"import joblib","b68a28d8":"joblib.dump(model, 'model.h5')","4d257d5b":"joblib.dump(scaler, 'scaler.h5')","84a2a4fa":"X.columns","cf972287":"inp = [0.3, 3, 57, 57, 60]","bab4eada":"inp = scaler.transform([inp])","07f63f93":"model.predict(inp)","8eac005b":"## removing these enteries","a2f34e1d":"## Getting the data","4e0a7c2d":"## Dropping first column \"Unnamed\"","a7f97de0":"### features x, y, z contain Zero values, and we should exclude these enteries","2b1a81e8":"## Visualizing distribution of each feature","53cb3cf8":"\n<div class=\"h1\">Predicting diamonds price<\/div>\n\n","18965037":"the best model with lower RMSE is the random forest","dc3a0685":"# Part 1: Exploratory data analysis and data visualization","d753f733":"## Featuring engineering using domain knowledge","58d641a1":"## Exploring the categorical features","4ffc7f74":"# Part 3: Saving the model for deployment","a2ac52aa":"## Importing libaries","8889b4e0":"## Recoding caterogical features","1f3abdd5":"# Part 2: Building a prediction model","8f5862bb":"## checking for null values","11d61aca":"<h2> Diamond is the most precious gemstones in the world. <\/h2>\n<h2>Its price depends on several factors:<\/h2>\n<ol>\n<li> Carat: the weight of diamond peice <\/li>\n<li> Cut: the process of converting the mined rough diamonds into gems, whether the cut is fair, good, very good, premium or ideal <\/li>\n<li> Color: according GIA universalized the D-to-Z Color Grading Scale with D (colorless = best) to Z (light yellow = worst) In our dataset from D to J.<\/li>\n<li> Clarity: the absence of inclusions and flaws. The ascending scale is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best)) <\/li>\n<li> Depth percentage: known by dividing its physical depth measurement by its width<\/li>\n<li> Table: the flat facet on its surface<\/li>\n<li> Additional features: length (x), width (y) and depth (z) all in mm\nz in the depth  \n\n\n\n<p1>For example, the current diamond price per 1.0 carat ranges from ($2,500 \u2013 $18,000) according to Diamond Carat Weight <\/p1>\n<a href='https:\/\/www.diamonds.pro\/education\/diamond-prices\/'> Source <\/a> <p1>(accessed in 28-2-2021 )<p1>\n<p1> In our dataset, it ranges from $326 \u2013 $18,823 <\/p1>\n<center> <img src='https:\/\/yourdiamondguru.com\/wp-content\/uploads\/2018\/09\/GIA-Cut-Scale.png' >  \n<br>\n<a href='https:\/\/yourdiamondguru.com\/grading\/depth-and-table-values'> Source <\/a>\n<br>\n<center> <img src=\"https:\/\/www.millsjewelers.com\/wp-content\/uploads\/2017\/05\/14_4CS_img1.jpg\"><\/center>\n<br>\n<a href='https:\/\/memoryjewellery.com\/diamond-guide\/diamond-carat\/'> Source <\/a>\n<\/body>\n<\/html>","9c8d1e3d":"It is clear from the table and plot the following:\n<ol>\n<li> The price is strongly correlated with the carat and the size<\/li>\n<li> The price is poorly correlated with table<\/li>\n<li> The price is inversly correlated with depth; i.e. the deeper the diamond, the cheaper they will be, as well as the cut <\/li>\n\n<\/ol>","9fa2f110":"## Selecting enteries where x, y or z features are zero"}}