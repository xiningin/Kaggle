{"cell_type":{"153d11b6":"code","afcc3f62":"code","1e9720d9":"code","66d0fa3c":"code","662e3efe":"code","128fd79c":"code","a962f39d":"code","6fd0cbac":"code","f9c7fa2c":"code","a32d4743":"code","216c12d3":"markdown","e5a2e45f":"markdown","acae94dc":"markdown","285676e2":"markdown","b52566cf":"markdown","89ffc0f2":"markdown"},"source":{"153d11b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","afcc3f62":"#read data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)\nsample_submission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")","1e9720d9":"train.columns","66d0fa3c":"#set target\ntarget = train.target\nfeature = train.drop(['target'], axis=1)\nfeature.head()","662e3efe":"# Select categorical columns\nfrom sklearn.preprocessing import OrdinalEncoder\n# List categorical column\ncat_cols = [col for col in feature.columns if 'cat' in col ]\n\n#encode\nX = feature.copy()\nX_test = test.copy()\nenc = OrdinalEncoder()\nX[cat_cols] = enc.fit_transform(feature[cat_cols])\nX_test[cat_cols] = enc.transform(test[cat_cols])","128fd79c":"X.head()","a962f39d":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, target, train_size=0.8, random_state=0)","6fd0cbac":"#define model\nfrom xgboost import XGBRegressor\nmodel1 = XGBRegressor()\nmodel1.fit(X_train, y_train)\npredict1 = model1.predict(X_val)\n\nfrom sklearn.ensemble import RandomForestRegressor\nmodel2 = RandomForestRegressor()\nmodel2.fit(X_train, y_train)\npredict2 = model2.predict(X_val)\n\nfrom sklearn.tree import DecisionTreeRegressor\nmodel3 = DecisionTreeRegressor(random_state=1)\nmodel3.fit(X_train, y_train)\npredict3 = model3.predict(X_val)","f9c7fa2c":"from sklearn.metrics import mean_squared_error\nprint(mean_squared_error(y_val, predict1, squared=False))\nprint(mean_squared_error(y_val, predict2, squared=False))\nprint(mean_squared_error(y_val, predict3, squared=False))","a32d4743":"# Use the model to generate predictions\npredictions = model1.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('day1_submission.csv', index=False)","216c12d3":"# **6. EVALUATE**","e5a2e45f":"# **3. ENCODE THE CATEGORICAL DATA INTO NUMERICAL**","acae94dc":"# **2. SET TARGET AND FEATURE**","285676e2":"# **1. IMPORT DATA**","b52566cf":"# **5. MODELLING AND TRAIN**","89ffc0f2":"# **4. SPLIT TRAIN AND TEST**"}}