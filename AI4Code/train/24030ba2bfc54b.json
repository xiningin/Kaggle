{"cell_type":{"1ac06da8":"code","7bdc9be2":"code","b848cef4":"code","8ae48b25":"code","3fad1dc5":"code","a8c31f76":"code","2b3b1335":"code","ec696d19":"code","a68f119a":"code","268dda30":"code","a71fb707":"code","36dba87d":"code","47a8ba8c":"code","b3e15c25":"code","a6ebef8a":"markdown","510ec141":"markdown","7d3a3d7e":"markdown","568975d5":"markdown","34e9dad9":"markdown","282c279f":"markdown","8f3834f9":"markdown","116a5f37":"markdown"},"source":{"1ac06da8":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","7bdc9be2":"dataset_folder = \"\/kaggle\/input\/hpa-single-cell-image-classification\/\"\ntraining_image_folder = dataset_folder+\"train\/\"\ntrain_df = pd.read_csv(dataset_folder+\"train.csv\")\ntrain_df","b848cef4":"def get_binary_mask(img):\n    '''\n    Turn the RGB image into grayscale before\n    applying an Otsu threshold to obtain a\n    binary segmentation\n    '''\n    \n    blurred_img = cv2.GaussianBlur(img,(25,25),0)\n    gray_img = cv2.cvtColor(blurred_img, cv2.COLOR_RGBA2GRAY)\n    ret, otsu = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    \n    kernel = np.ones((40,40),np.uint8)\n    closed_mask = cv2.morphologyEx(otsu, cv2.MORPH_CLOSE, kernel)\n    return closed_mask","8ae48b25":"def load_RGBY_image(image_id_path):\n    '''\n    Load and stack the channels that are stored separately.\n    '''\n    \n    red_image = cv2.imread(image_id_path+\"_red.png\", cv2.IMREAD_UNCHANGED)\n    green_image = cv2.imread(image_id_path+\"_green.png\", cv2.IMREAD_UNCHANGED)\n    blue_image = cv2.imread(image_id_path+\"_blue.png\", cv2.IMREAD_UNCHANGED)\n    yellow_image = cv2.imread(image_id_path+\"_yellow.png\", cv2.IMREAD_UNCHANGED)\n\n    stacked_images = np.transpose(np.array([red_image, green_image, blue_image, yellow_image]), (1,2,0))\n    return stacked_images","3fad1dc5":"image_id_path = training_image_folder+train_df.iloc[0].ID\nstacked_images = load_RGBY_image(image_id_path)\nbinary_mask = get_binary_mask(stacked_images)","a8c31f76":"plt.imshow(stacked_images[:,:,:3])\nplt.show()","2b3b1335":"plt.imshow(binary_mask)\nplt.show()","ec696d19":"def rle_encoding(x):\n    '''\n    Turns our masks into RLE encoding to easily store them\n    and feed them into models later on\n    https:\/\/en.wikipedia.org\/wiki\/Run-length_encoding\n    '''\n    \n    dots = np.where(x.T.flatten() == 255)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n        \n    return ' '.join([str(x) for x in run_lengths])","a68f119a":"def get_instance_masks(binary_mask):\n    '''\n    Using a binary mask, this function filters out \n    small items and create a separate mask for each \n    blobs\n    '''\n    \n    contours= cv2.findContours(binary_mask,\n                               cv2.RETR_TREE, \n                               cv2.CHAIN_APPROX_SIMPLE)\n    instance_masks = []\n    for contour in contours[0]:\n        if cv2.contourArea(contour)>100:\n            instance_contour = np.zeros(binary_mask.shape)\n            cv2.drawContours(instance_contour,[contour], \n                             0, 255,thickness=cv2.FILLED)\n            \n            encoded_cell_mask = rle_encoding(instance_contour)\n            instance_masks.append(encoded_cell_mask)\n            \n    return instance_masks","268dda30":"process_RLE_for = 20\ntrain_df[\"RLE_encoding\"] = \"\"\n\nwith tqdm(total=process_RLE_for) as pbar:\n    for idx, item in train_df[:process_RLE_for].iterrows():\n        image_id_path = training_image_folder+item.ID\n\n        stacked_images = load_RGBY_image(image_id_path)\n        binary_mask = get_binary_mask(stacked_images)\n        instance_masks = get_instance_masks(binary_mask)\n\n        train_df.at[idx, \"RLE_encoding\"] = str(instance_masks)\n        pbar.update(1)","a71fb707":"train_df","36dba87d":"def plot_color_distribution(isolated_cell_img):\n    color = ('r','g','b','y')\n    for i,col in enumerate(color):\n        histr = cv2.calcHist([isolated_cell_img],[i],None,[256],[1,256])\n        plt.plot(histr,color = col)\n        plt.xlim([1,256])\n    plt.show()\n\ndef analyze_individual_cells(binary_mask, original_image):\n    \n    contours= cv2.findContours(binary_mask,\n                               cv2.RETR_TREE, \n                               cv2.CHAIN_APPROX_SIMPLE)\n    \n    for contour in contours[0]:\n        if cv2.contourArea(contour)>100:\n            x, y, width, height = cv2.boundingRect(contour)\n            \n            instance_contour = np.zeros(binary_mask.shape)\n            cv2.drawContours(instance_contour,[contour], \n                             0, 255, thickness=cv2.FILLED)\n\n            isolated_cell_image = np.zeros(binary_mask.shape)\n            isolated_cell_image = cv2.bitwise_and(original_image,original_image, mask = instance_contour.astype(\"uint8\"))\n    \n            plt.imshow(isolated_cell_image[y:y+height,x:x+width,:3])\n            plt.show()\n            plot_color_distribution(isolated_cell_image[y:y+height,x:x+width])","47a8ba8c":"image_id_path = training_image_folder+train_df.iloc[0].ID\nstacked_images = load_RGBY_image(image_id_path)\nbinary_mask = get_binary_mask(stacked_images)\nanalyze_individual_cells(binary_mask, stacked_images)","b3e15c25":"image_id_path = training_image_folder+train_df.iloc[55].ID\nstacked_images = load_RGBY_image(image_id_path)\nbinary_mask = get_binary_mask(stacked_images)\nanalyze_individual_cells(binary_mask, stacked_images)","a6ebef8a":"## Thanks for reading this notebook! If you found this notebook helpful, please give it an upvote. It is always greatly appreciated!","510ec141":"By creating individual masks for every cells in the training images, I now have the possibility to proceed to image analysis. Below, I display every cell and the color distribution for the RGB channels. A preliminary methods to identify the cells' classes could be to cluster them based on their color distribution signature.","7d3a3d7e":"# Introduction","568975d5":"# Add the RLE encoding to the existing training dataframe","34e9dad9":"# Load the images and apply a binary mask","282c279f":"As seen below, when attempting to isolate individual cells using the functions previously defined, we can observe some issues when cells are too close from each other. Nonetheless, it does appear like a promising technique to generate instance masks.","8f3834f9":"This notebook has for goal to introduce several functions to load the data and create instance masks for every cell present in training images. By generating instance segmentation masks, we will make it possible to analyze cells individually and potentially associate each of them to one or several of the labels given for the entire image.","116a5f37":"# Generate instance masks and convert to RLE encoding"}}