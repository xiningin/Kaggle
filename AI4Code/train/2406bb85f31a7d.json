{"cell_type":{"28bf734e":"code","43191f1d":"code","17de28fa":"code","2984ea16":"code","e9803cab":"code","85bc1feb":"code","2f82f367":"code","33b03192":"code","d5994b8b":"code","f72e3426":"code","135dead7":"code","4ea8c4e7":"code","ecc4b31a":"code","7e523a54":"code","c72c7bf3":"code","69d477db":"code","3fcebab4":"code","6f85d245":"code","2c1f89db":"code","9e3666d2":"code","c890787c":"code","cb7fb1e6":"code","6e62d3b1":"code","f58f9375":"code","da8f9516":"code","0989c4cf":"code","05f16cd3":"markdown","0f7b824a":"markdown","9d2f5dd4":"markdown","b588980f":"markdown","565ebca5":"markdown","4c669e12":"markdown","1076648c":"markdown","e00f69e7":"markdown","862682e8":"markdown","3ac7a9ed":"markdown","6b50bbd7":"markdown","0da8ba73":"markdown","0ab73129":"markdown","c7247b62":"markdown","7c6c3159":"markdown","99a97a55":"markdown","69a611de":"markdown","d9d7ab3b":"markdown","4071f1e8":"markdown","c9360370":"markdown","71bb6b8d":"markdown","20cc6611":"markdown","1ed353f5":"markdown","4658210c":"markdown","cb96fab1":"markdown"},"source":{"28bf734e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv('..\/input\/StudentsPerformance.csv')\ndata.head(6)","43191f1d":"print(data.shape)\nprint(data.describe())","17de28fa":"sns.pairplot(data[['math score', 'reading score', 'writing score']], height = 4)","2984ea16":"def ScoreMark(score):\n    if ( score > 90 ):\n        mark = 'A'\n    elif ( score > 80):\n        mark = 'B'\n    elif ( score > 70):\n        mark = 'C'\n    elif ( score > 60):\n        mark = 'D'\n    elif ( score > 50):\n        mark = 'E'\n    else: \n        mark = 'F'\n    return mark\n\ndata['math mark'] = data['math score'].apply(lambda s: ScoreMark(s))\ndata['reading mark'] = data['reading score'].apply(lambda s: ScoreMark(s))\ndata['writing mark'] = data['writing score'].apply(lambda s: ScoreMark(s))\n","e9803cab":"\nfigure = plt.figure(figsize=(16,4))\nn = 1\nfor i in ['math score', 'reading score', 'writing score']:\n    ax = figure.add_subplot(1, 3, n)\n    ax.set_title(i)\n    data[i].hist()\n    n = n + 1\n","85bc1feb":"figure = plt.figure(figsize=(16,4))\nn = 1\nfor i in ['math mark', 'reading mark', 'writing mark']:\n    ax = figure.add_subplot(1, 3, n)\n    ax.set_title(i)\n    data[i].value_counts().sort_index().plot(kind=\"bar\")\n    n = n + 1","2f82f367":"def boxpl(dt, x_cols, y_cols):\n    n = 1\n    x_cnt = len(x_cols)\n    y_cnt = len(y_cols)\n    figure = plt.figure(figsize=(17, 5 * x_cnt))\n    for x_ax in x_cols:\n        for i in y_cols:\n            ax = figure.add_subplot(x_cnt, y_cnt, n)\n            #ax.set_title(i)\n            g = sns.boxplot(x = dt[x_ax], y = dt[i])\n            g.set_xticklabels(g.get_xticklabels(), rotation=20)\n            n = n + 1","33b03192":"y_cols = ['math score', 'reading score', 'writing score']\nx_cols = ['gender', 'race\/ethnicity']\nboxpl(data, x_cols, y_cols)","d5994b8b":"y_cols = ['math score', 'reading score', 'writing score']\nx_cols = ['test preparation course', 'lunch']\nboxpl(data, x_cols, y_cols)","f72e3426":"y_cols = ['math score', 'reading score', 'writing score']\nx_cols = [ 'parental level of education']\nboxpl(data, x_cols, y_cols)","135dead7":"def getMarkData(dt, marks):\n    subDt = dt[(dt['math mark'].isin(marks)) | (dt['reading mark'].isin(marks)) | (dt['writing mark'].isin(marks))]\n    return subDt\n    \ndef MarkCounts(dt, marks):\n    subDt = getMarkData(dt, marks)\n    print('Math: ' + str(subDt[subDt['math mark'].isin(marks)].shape[0])\n      , '\\n'\n      , 'Writing: ' + str(subDt[subDt['writing mark'].isin(marks)].shape[0])\n      , '\\n'\n      , 'Reading: ' + str(subDt[subDt['reading mark'].isin(marks)].shape[0])\n      , '\\n'\n      , '\\n'\n      , 'Math and Reading: ' + str(subDt[(subDt['math mark'].isin(marks)) & (subDt['reading mark'].isin(marks))].shape[0])\n      , '\\n'\n      , 'Math and Writing: ' + str(subDt[(subDt['math mark'].isin(marks)) & (subDt['writing mark'].isin(marks))].shape[0])\n      , '\\n'\n      ,'Reading and Writing: ' + str(subDt[(subDt['reading mark'].isin(marks)) & (subDt['writing mark'].isin(marks))].shape[0])\n      , '\\n'\n      , '\\n',\n      'All: '+str(subDt[(subDt['math mark'].isin(marks))&(subDt['reading mark'].isin(marks))&(subDt['writing mark'].isin(marks))].shape[0])\n     )\n","4ea8c4e7":"print('F')\nMarkCounts(data, ['F'])\nprint('\\n A')\nMarkCounts(data, ['A'])","ecc4b31a":"# Relative ratios have been added.\n\nfigure = plt.figure(figsize=(18,20))\nn = 1\nfor k in ['gender', 'race\/ethnicity', 'parental level of education', 'lunch', 'test preparation course']:\n    for i in ['math mark', 'reading mark', 'writing mark']:\n        tab = pd.crosstab(data[k], data[i])\n        tab['total'] = (tab['A'] + tab['B'] + tab['C'] + tab['D'] + tab['E'] + tab['F'])        \n        tab['A'] = round(tab['A'] \/ tab['total'], 2)\n        tab['B'] = round(tab['B'] \/ tab['total'], 2)\n        tab['C'] = round(tab['C'] \/ tab['total'], 2)\n        tab['D'] = round(tab['D'] \/ tab['total'], 2)\n        tab['E'] = round(tab['E'] \/ tab['total'], 2)\n        tab['F'] = round(tab['F'] \/ tab['total'], 2)\n        tab = tab.drop(columns=['total'])\n        ax = figure.add_subplot(5, 3, n)\n        #ax.set_title(i)\n        g = sns.heatmap(tab, annot=True, cmap='Purples', fmt='g')\n        g.set_yticklabels(g.get_yticklabels(), rotation=45)\n        n = n + 1","7e523a54":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm.libsvm import predict_proba\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","c72c7bf3":"\ndef hasFailed(dt):\n    if ((dt['math mark'] == 'F') | (dt['reading mark'] == 'F') | (dt['writing mark'] == 'F')):\n        return 1\n    else:\n        return 0\ndata['failed'] = data.apply(hasFailed, axis=1)","69d477db":"classification_data = data[[\n                              'gender'\n                            , 'race\/ethnicity'\n                            , 'parental level of education'\n                            , 'lunch'\n                            , 'test preparation course'\n                            , 'failed'\n                           ]]","3fcebab4":"text_columns = [\n  'gender'\n, 'race\/ethnicity'\n, 'parental level of education'\n, 'lunch'\n, 'test preparation course'] \n\nclassification_data = pd.get_dummies(classification_data, columns=text_columns)\nclassification_data.head(6)","6f85d245":"#Splitting data into main training and validation datasets, 80\/20\nclassification_data.reset_index(level=[0], inplace=True)\ndata_train = classification_data.sample(int(np.floor(classification_data.shape[0] * 0.8)), random_state=999)\ndata_val = classification_data[np.logical_not(classification_data['index'].isin(data_train['index']))]\ndata_train = data_train.drop(columns = ['index'])\ndata_val = data_val.drop(columns = ['index'])\nprint(data_train[data_train['failed'] == 0].shape\n    , data_train[data_train['failed'] == 1].shape\n     , data_val.shape)\n","2c1f89db":"#Oversampling: ge the needed oversample values\n\ndata_train_fail = data_train[data_train['failed'] == 1]\ndata_train_pass = data_train[data_train['failed'] == 0]\n\npass_n = data_train[data_train['failed'] == 0].shape[0]\nfail_n = data_train[data_train['failed'] == 1].shape[0]\ntimes_x = np.floor(pass_n \/ fail_n)\ndiff = int(pass_n - times_x * fail_n)\n\nprint(times_x, diff)","9e3666d2":"#Oversampling: concatenating oversampled data together.\ndata_train_over = pd.concat([data_train_pass, \n                            data_train_fail,\n                            data_train_fail,\n                            data_train_fail,\n                            data_train_fail,\n                            data_train_fail.sample(diff, random_state = 999)])\nprint(data_train_over[data_train_over['failed'] == 0].shape\n    , data_train_over[data_train_over['failed'] == 1].shape\n     , data_train_over.shape)","c890787c":"#test_train_sample\nX_train, X_test, y_train, y_test = train_test_split(\n    data_train_over[data_train_over.columns.difference(['failed'])],\n    data_train_over['failed'], test_size=0.3, random_state=999)","cb7fb1e6":"\nparam_grid = { \n    'n_estimators': [8,9,10,11, 12,13, 14, 15, 16, 17, 18, 19, 20],\n    'max_depth' : [5, 10, 15, 17, 18, 19, 20, 21, 23, 25],\n#    'max_features': ['auto', 'sqrt', 'log2'],\n    'criterion' :['gini', 'entropy']\n}\n\nCV_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=1), param_grid=param_grid, cv= 5)\nCV_rfc.fit(X_train, y_train)\nCV_rfc.best_params_\n","6e62d3b1":"\n# SVM\nsvm = SVC(kernel = \"linear\").fit(X_train, y_train)\nsvm_poly = SVC(kernel = \"poly\", degree = 2, gamma = \"auto\").fit(X_train, y_train)\nsvm_rbf = SVC(kernel = \"rbf\", gamma=\"auto\").fit(X_train, y_train)\n\n#Random Forest\nrf = RandomForestClassifier(n_estimators=19, max_depth = 15, criterion = 'gini', random_state = 999).fit(X_train, y_train)\n\n# Decision Tree\ndt = DecisionTreeClassifier(criterion = \"entropy\", random_state = 999).fit(X_train, y_train)\n\n# knn\nknn1 = KNeighborsClassifier(n_neighbors = 1).fit(X_train, y_train)\nknn3 = KNeighborsClassifier(n_neighbors = 3).fit(X_train, y_train)\nknn5 = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train)\nknn7 = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)\nknn9 = KNeighborsClassifier(n_neighbors = 9).fit(X_train, y_train)\nknn11 = KNeighborsClassifier(n_neighbors = 11).fit(X_train, y_train)\nknn13 = KNeighborsClassifier(n_neighbors = 13).fit(X_train, y_train)\nknn25 = KNeighborsClassifier(n_neighbors = 25).fit(X_train, y_train)","f58f9375":"acc1 = accuracy_score(y_test, svm.predict(X_test))\nacc2 = accuracy_score(y_test, svm_poly.predict(X_test))\nacc3 = accuracy_score(y_test, svm_rbf.predict(X_test))\n\nacc4 = accuracy_score(y_test, rf.predict(X_test))\n\nacc5 = accuracy_score(y_test, dt.predict(X_test))\n\nacc6 = accuracy_score(y_test, knn1.predict(X_test))\nacc7 = accuracy_score(y_test, knn3.predict(X_test))\nacc8 = accuracy_score(y_test, knn5.predict(X_test))\nacc9 = accuracy_score(y_test, knn7.predict(X_test))\nacc10 = accuracy_score(y_test, knn9.predict(X_test))\nacc11 = accuracy_score(y_test, knn11.predict(X_test))\nacc12 = accuracy_score(y_test, knn13.predict(X_test))\nacc13 = accuracy_score(y_test, knn25.predict(X_test))\n\nprint('\\n svm', acc1\n      , '\\n svm poly', acc2\n      , '\\n svm rbf', acc3\n      , '\\n random forest', acc4\n      , '\\n decision tree', acc5\n      , '\\n 1nn', acc6\n      , '\\n 3nn', acc7\n      , '\\n 5nn', acc8\n      , '\\n 7nn', acc9\n      , '\\n 9nn', acc10\n      , '\\n 11nn', acc11\n      , '\\n 13nn', acc12\n      , '\\n 25nn', acc13)","da8f9516":"val_x = data_val[data_val.columns.difference(['failed'])]\nval_y = data_val['failed']\ntrain_x = data_train[data_train.columns.difference(['failed'])]\ntrain_y = data_train['failed']\n\nprint('SVM rbf', accuracy_score(val_y, \n               SVC(kernel = \"rbf\", gamma=\"auto\").fit(train_x, train_y).predict(val_x)))\n\nprint('random forest', accuracy_score(val_y, \n               RandomForestClassifier(n_estimators=12, max_depth = 10, criterion = 'gini', random_state = 999).fit(train_x, train_y).predict(val_x)))\n\n\nprint('decision tree', accuracy_score(val_y, \n               DecisionTreeClassifier(criterion = \"entropy\", random_state = 999).fit(train_x, train_y).predict(val_x)))\n\n\nprint('3nn KNN', accuracy_score(val_y,\n               KNeighborsClassifier(n_neighbors = 3).fit(train_x, train_y).predict(val_x)))\n","0989c4cf":"from sklearn.metrics import confusion_matrix\n\nprint('SVM rbf')\ny_pred = SVC(kernel = \"rbf\", gamma=\"auto\").fit(train_x, train_y).predict(val_x)\nconfusion_matrix_result = confusion_matrix(val_y, y_pred)\nprint(\"Confusion matrix:\\n%s\" % confusion_matrix_result)\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprint('True Negative: ' + str(tn), ', False Positive: ' + str(fp), ', False Negative: ' + str(fn), ', True Positive: ' + str(tp))\n\n\n\nprint(' \\n Random Forest')\ny_pred = RandomForestClassifier(n_estimators=12, max_depth = 10, criterion = 'gini', random_state = 999).fit(train_x, train_y).predict(val_x)\nconfusion_matrix_result = confusion_matrix(val_y, y_pred)\nprint(\"Confusion matrix:\\n%s\" % confusion_matrix_result)\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprint('True Negative: ' + str(tn), ', False Positive: ' + str(fp), ', False Negative: ' + str(fn), ', True Positive: ' + str(tp))\n\n\nprint(' \\n Decision Tree')\ny_pred = DecisionTreeClassifier(criterion = \"entropy\", random_state = 999).fit(train_x, train_y).predict(val_x)\nconfusion_matrix_result = confusion_matrix(val_y, y_pred)\nprint(\"Confusion matrix:\\n%s\" % confusion_matrix_result)\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprint('True Negative: ' + str(tn), ', False Positive: ' + str(fp), ', False Negative: ' + str(fn), ', True Positive: ' + str(tp))\n\n\nprint(' \\n KNN 3 nearest neighbours')\ny_pred = KNeighborsClassifier(n_neighbors = 3).fit(train_x, train_y).predict(val_x)\nconfusion_matrix_result = confusion_matrix(val_y, y_pred)\nprint(\"Confusion matrix:\\n%s\" % confusion_matrix_result)\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprint('True Negative: ' + str(tn), ', False Positive: ' + str(fp), ', False Negative: ' + str(fn), ', True Positive: ' + str(tp))\n","05f16cd3":"<h3> Add one hot encoding: transform textual variables into binaries <\/h3>","0f7b824a":"<h3> Check exam score quartiles allocation for gender and race <\/h3>","9d2f5dd4":"<h3> Run models on validation dataset and see the results of accuracy there. <\/h3>","b588980f":"<h3> modify the label: failed = 1 (if student has failed 1 or more exams) and failed = 0 (if student has not failed any exam) <\/h3>","565ebca5":"<h3> run prediction on fitted model and get accuracy score. <\/h3> ","4c669e12":"<h1> Predicting student exam failures with Classification methods <\/h1>","1076648c":"<h3> perform Gridsearch to find out best fitting parameters for random forest classifier <\/h3>","e00f69e7":"<h3> working dataset is unbalanced, so we need balance it. \nWe will use oversampling method <\/h3>","862682e8":"<h3> Split working dataset into test\/train datasets and y labels <\/h3>","3ac7a9ed":"<h3> add columns for grade marks for each exam:  <\/h3>\n<h5> >90 = A, >80 = B, >70 = C, >60 = D, >50 = E, <=50 = F <\/h5>","6b50bbd7":"<h3> Plot histograms for the exam scores and marks <\/h3>","0da8ba73":"<h3>Check dataset size and describe the numeric variables <\/h3>","0ab73129":"<h3> Define Boxplot function, to plot all three exam scores for different variables, check median and quartiles of the scores. <\/h3>","c7247b62":"<h1> Exam results analysis and classification <\/h1>\n<h3> import basic libraries and load the dataset <\/h3>","7c6c3159":"<h3> Check Score quartiles allocation for parental level of education <\/h3>","99a97a55":"<h4>Seems that the model with the best accuracy score, SVM with rbf, only predicts negatives. Since the validation data is unbalanced, it gets high accuracy. In the other words, the best performing model in our case has same accuracy as the randomly predicting model - the one that only predicts negatives. <\/h4>","69a611de":"<h3> Define function that takes a grade mark and returns the number of students that have the given grade for each exam. <\/h3>","d9d7ab3b":"<h3> Check Confusion matrix for each of those model predictions on validation data <\/h3>","4071f1e8":"<h3>Call a pairplot to get the correlation between the numeric variables - math, reading and writing scores <\/h3> ","c9360370":"<h3> fit the different models: SVM, SVM Poly, SVM rdf, random forest, decision tree, knn with various number of nearest neighbours. <\/h3>","71bb6b8d":"<h3>Import libraries from sklearn<\/h3>","20cc6611":"<h2> Add relative rations per variable <\/h2> <h5>(for example, exam grades for females in total will give 1, and the number on plot will be percentage of females that have got the particular exam mark)<\/h5>\n<h3>\nPlot heatmap with math, reading and writing marks on x axis, and different variables on y axis, and showing the relative percentage of students that got the given score within the y variable value.\n<\/h3>\n<h4>\nPlot shows students of which of the variable values are getting better grades, and which of the variable values are getting less grades or even fail. <\/h4>\n","1ed353f5":"<h3> split dataset into working train\/test and validation datasets (80\/20). models will be trained and tested on main working dataset, but for validation the models results we will use validation dataset <\/h3>","4658210c":"<h3> Check exam score quartiles allocation for test preparation course and lunch variables <\/h3>","cb96fab1":"<h3> Get number of students that have Failed (F), and number of students that have distinction results (A) in the exams. <\/h3>"}}