{"cell_type":{"4fddade5":"code","c178d401":"code","64bbb99d":"code","fd6f4a8a":"code","2c3805b1":"code","f55b36dd":"code","6236af6f":"code","c82942ed":"code","58328410":"code","5478ad1c":"code","fd022784":"code","93a74819":"code","10eebd0c":"code","d22f3b12":"code","b4a76ed5":"code","e8da9c49":"code","1e46d766":"code","892a66a9":"code","a36f6c2e":"code","512d613f":"code","780ab26e":"markdown","06e1908e":"markdown","789c6a81":"markdown","2bb3faf5":"markdown","9ed226a1":"markdown","e74e99fd":"markdown"},"source":{"4fddade5":"# This Python 3 environment comes with many helpful analytics libraries installed\n\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c178d401":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# roc curve and auc curve\nfrom sklearn.datasets import make_classification","64bbb99d":"from sklearn.model_selection import train_test_split\n\nX,y = make_classification(n_samples=2000, n_classes=2,weights=[1,1], random_state=1) ","fd6f4a8a":"X.shape","2c3805b1":"y","f55b36dd":"\nfrom sklearn.model_selection import train_test_split\nX_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)","6236af6f":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","c82942ed":"# Apply RandomForestClasifier\n\nfrom sklearn.ensemble import RandomForestClassifier \nrf_model = RandomForestClassifier()\nrf_model.fit(X_train,y_train)\nytrain_pred = rf_model.predict_proba(X_train)\nprint('RF train roc-auc: {}'. format(roc_auc_score(y_train,ytrain_pred[:,1])))\nytest_pred=rf_model.predict_proba(x_test)\nprint('RF test roc-auc: {}'. format(roc_auc_score(y_test, ytest_pred[:,1])))","58328410":"ytrain_pred","5478ad1c":"\nfrom sklearn.linear_model import LogisticRegression\nlog_classifier=LogisticRegression()\nlog_classifier.fit(X_train, y_train)\nytrain_pred = log_classifier.predict_proba(X_train)\nprint('Logistic train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\nytest_pred = log_classifier.predict_proba(x_test)\nprint('Logistic test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))","fd022784":"from sklearn.ensemble import AdaBoostClassifier\nada_classifier=AdaBoostClassifier()\nada_classifier.fit(X_train, y_train)\nytrain_pred = ada_classifier.predict_proba(X_train)\nprint('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\nytest_pred = ada_classifier.predict_proba(x_test)\nprint('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))\n","93a74819":"from sklearn.neighbors import KNeighborsClassifier\nknn_classifier=KNeighborsClassifier()\nknn_classifier.fit(X_train, y_train)\nytrain_pred = knn_classifier.predict_proba(X_train)\nprint('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\nytest_pred = knn_classifier.predict_proba(x_test)\nprint('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))","10eebd0c":"pred=[]\nfor model in [rf_model,log_classifier,ada_classifier,knn_classifier]:\n    pred.append(pd.Series(model.predict_proba(x_test)[:,1]))\nfinal_prediction=pd.concat(pred,axis=1).mean(axis=1)\nprint('Ensemble test roc-auc: {}'.format(roc_auc_score(y_test,final_prediction)))","d22f3b12":"pd.concat(pred,axis=1)","b4a76ed5":"final_prediction","e8da9c49":"### Calculate the ROC Curve\n\nfpr,tpr,thresholds=roc_curve(y_test,final_prediction)\nthresholds","1e46d766":"from sklearn.metrics import accuracy_score\naccuracy_ls = []\nfor thres in thresholds:\n    y_pred = np.where(final_prediction>thres,1,0)\n    accuracy_ls.append(accuracy_score(y_test, y_pred, normalize=True))\n    \naccuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n                        axis=1)\naccuracy_ls.columns = ['thresholds', 'accuracy']\naccuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\naccuracy_ls.head()","892a66a9":"accuracy_ls","a36f6c2e":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='red', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\n","512d613f":"plot_roc_curve(fpr,tpr)","780ab26e":"### KNN Classifer","06e1908e":"### Now we will focus on selecting the best threshold for maximum accuracy","789c6a81":"### Adaboost Classifier","2bb3faf5":"##  Select the Right Threshold values using ROC Curve","9ed226a1":"### Random Forests","e74e99fd":"### Logistic Regression"}}