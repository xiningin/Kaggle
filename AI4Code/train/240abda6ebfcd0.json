{"cell_type":{"74c40ccf":"code","b559a09e":"code","4f084435":"code","7b347c67":"code","a36abf1b":"code","89194d7c":"code","96772802":"code","6448f2d6":"code","0fefcd62":"code","a385a87d":"code","9eab56a8":"code","e13b4072":"code","e2980732":"code","206b0660":"code","2a27ccfa":"code","21da1037":"code","3b56a7f1":"code","8419f62c":"code","d4ae8900":"code","f803bbd2":"code","dc889569":"code","6e7ff034":"markdown","f5faadfc":"markdown","657e12da":"markdown","dbd7fed8":"markdown"},"source":{"74c40ccf":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\nimport skimage\nfrom skimage.morphology import convex_hull_image, erosion\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D,\\\nZeroPadding2D, Convolution2D, ZeroPadding2D, Conv2DTranspose,ReLU, UpSampling2D, Concatenate, Conv2DTranspose\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nfrom keras import backend\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","b559a09e":"MAIN_IMAGE_PATH = Path(\"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/train_val\/images\")\nMAIN_MASK_PATH = Path(\"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/train_val\/masks\")\n\nOBJECT_PATH = list(MAIN_IMAGE_PATH.glob(r\"*.jpg\"))\nMASK_PATH = list(MAIN_MASK_PATH.glob(r\"*.bmp\"))\n\nOBJECT_PATH = sorted(OBJECT_PATH)\nMASK_PATH = sorted(MASK_PATH)\n\nOBJECT_SERIES = pd.Series(OBJECT_PATH,name=\"OBJECTS\").astype(str)\nMASK_SERIES = pd.Series(MASK_PATH,name=\"MASK\").astype(str)\n\nMAIN_DATA = pd.concat([OBJECT_SERIES,MASK_SERIES],axis=1)\n\nMASK_MAIN_TRANSFORMATION = []\nOBJECT_MAIN_TRANSFORMATION = []\nADD_MAIN_TRANSFORMATION = []\n\nfor x_image,x_mask in zip(MAIN_DATA.OBJECTS,MAIN_DATA.MASK):\n    \n    IMAGE_X = cv2.cvtColor(cv2.imread(x_image),cv2.COLOR_BGR2RGB)\n    MASK_X = cv2.cvtColor(cv2.imread(x_mask),cv2.COLOR_BGR2RGB)\n    \n    RESIZED_X_IMAGE = cv2.resize(IMAGE_X,(256,256))\n    RESIZED_X_MASK = cv2.resize(MASK_X,(256,256))\n    \n    ADD_X = cv2.addWeighted(RESIZED_X_IMAGE,0.6,RESIZED_X_MASK,0.6,0.5)\n    \n    RESIZED_X_ADD = cv2.resize(ADD_X,(256,256))\n    \n    MASK_MAIN_TRANSFORMATION.append(RESIZED_X_MASK)\n    OBJECT_MAIN_TRANSFORMATION.append(RESIZED_X_IMAGE)\n    ADD_MAIN_TRANSFORMATION.append(RESIZED_X_ADD)\n    \nprint(\"WHEN IT IS ARRAY IMAGE SHAPE: \",np.shape(np.array(OBJECT_MAIN_TRANSFORMATION)))\nprint(\"WHEN IT IS ARRAY MASK SHAPE: \",np.shape(np.array(MASK_MAIN_TRANSFORMATION)))\nprint(\"WHEN IT IS ARRAY ADD SHAPE: \",np.shape(np.array(ADD_MAIN_TRANSFORMATION)))\n\nTransformation_Image = np.array(OBJECT_MAIN_TRANSFORMATION,dtype=\"float32\")\nTransformation_Mask = np.array(MASK_MAIN_TRANSFORMATION,dtype=\"float32\")\nTransformation_Add = np.array(ADD_MAIN_TRANSFORMATION,dtype=\"float32\")\n\nprint(\"TRAIN: \",Transformation_Image.shape)\nprint(\"TRANSFORMATION MASK: \",Transformation_Mask.shape)\nprint(\"TRANSFORMATION ADD: \",Transformation_Add.shape)","4f084435":"Transformation_Image = Transformation_Image \/ 255.\nTransformation_Mask = Transformation_Mask \/ 255.\nTransformation_Add = Transformation_Add \/ 255.","7b347c67":"compile_loss = \"binary_crossentropy\"\ncompile_optimizer = Adam(lr=0.00001)\noutput_class = 3","a36abf1b":"Checkpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,\n                                                      filepath=\".\/modelcheck\")","89194d7c":"E_AE = Sequential()\n#\nE_AE.add(Conv2D(32,(2,2),kernel_initializer = 'he_normal',use_bias = True, padding=\"same\"))\nE_AE.add(BatchNormalization())\nE_AE.add(ReLU())\n#\nE_AE.add(Conv2D(64,(2,2),kernel_initializer = 'he_normal',use_bias = True, padding=\"same\"))\nE_AE.add(BatchNormalization())\nE_AE.add(ReLU())\n#\nE_AE.add(Conv2D(128,(5,5),kernel_initializer = 'he_normal',use_bias = True, padding=\"same\"))\nE_AE.add(BatchNormalization())\nE_AE.add(ReLU())\n\n\n\n\nD_AE = Sequential()\n#\nD_AE.add(Conv2DTranspose(64,(2,2), padding=\"same\"))\nD_AE.add(ReLU())\n#\nD_AE.add(Conv2DTranspose(32,(5,5), padding=\"same\"))\nD_AE.add(ReLU())\n#\nD_AE.add(Conv2DTranspose(output_class,(5,5), padding=\"same\"))\nD_AE.add(ReLU())","96772802":"Auto_Encoder = Sequential([E_AE,D_AE])\nAuto_Encoder.compile(loss=compile_loss,optimizer=compile_optimizer,metrics=[\"mse\"])","6448f2d6":"Model_AutoEncoder = Auto_Encoder.fit(Transformation_Image,Transformation_Add,epochs=20,callbacks=[Checkpoint_Model])","0fefcd62":"Prediction_Seen = Auto_Encoder.predict(Transformation_Image[:10])","a385a87d":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 1\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","9eab56a8":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 3\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","e13b4072":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 5\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","e2980732":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 7\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","206b0660":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","2a27ccfa":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/n_l_12_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","21da1037":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/d_r_84_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","3b56a7f1":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/f_r_1220_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","8419f62c":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/f_r_1435_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","d4ae8900":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/n_l_87_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","f803bbd2":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/w_r_84_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","dc889569":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/w_r_199_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","6e7ff034":"# AUTO-ENCODER PROCESS \/ AE","f5faadfc":"# PACKAGES AND LIBRARIES","657e12da":"### MODEL 2","dbd7fed8":"# PATH \/ LABEL \/ DATA TRANSFORMATION PROCESS"}}