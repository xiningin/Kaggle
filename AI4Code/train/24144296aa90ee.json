{"cell_type":{"4730e720":"code","bfa3f836":"code","242c183c":"code","da7a9097":"code","208ef2b0":"code","c686365a":"code","49e7b2c9":"code","e3e8489e":"code","67ef2bea":"code","77d4364c":"code","11ac1d67":"code","59041bf9":"code","424ee7ac":"code","34aec086":"code","aa33e92f":"code","1bf2c4fc":"code","f1be9667":"code","ad8841ae":"code","26193ac5":"code","216987c0":"code","13c581ca":"code","064e9a79":"code","1deb14fd":"code","39bc17bd":"code","d07896e5":"code","bd23afd7":"code","b5d9d838":"code","8724f591":"code","2aa66528":"code","82fb9cf5":"code","509e44d9":"code","6f5a7519":"code","2a2db59a":"code","83e6be4a":"code","e5376e8e":"code","52192ad9":"code","36310ca4":"code","6364985b":"code","e9acad64":"code","26f5b8e2":"code","d425fba4":"code","dddeb898":"code","7001fabc":"code","c2ca7282":"code","5f80dd63":"code","3629b7af":"code","6c7571d2":"code","9d49e08a":"code","3c7a12fb":"code","6abb7743":"code","10736a9e":"code","6dc13024":"code","fd22305e":"code","53cb3010":"code","77714727":"code","50e7604a":"code","492e929f":"code","3b23f8ca":"code","8dca6afc":"code","45594632":"code","2922e5b6":"code","0789f978":"code","ccc1f88c":"code","b8ed475f":"code","ebc14ab0":"code","aa6ccdb9":"code","f1aaee60":"code","2a5919ac":"code","e925843a":"code","932c0e1d":"code","f5804d3c":"code","8de3c938":"code","5a3d24f1":"code","40596810":"code","5bfa54df":"markdown","7533f17a":"markdown","ca59a80b":"markdown","c10d3340":"markdown","90eb8f56":"markdown","17595694":"markdown","c6d471e7":"markdown","95d28e76":"markdown","b88ffdfc":"markdown","8f476f71":"markdown","8b35c590":"markdown","34d27317":"markdown","5a6feedb":"markdown","87e3411a":"markdown","55d92a15":"markdown","3d190d86":"markdown","7e9d1973":"markdown","1fd878e9":"markdown","90dc268e":"markdown","d2887e48":"markdown","90ad6a9f":"markdown","5c34847d":"markdown","9b976220":"markdown","4d5ba597":"markdown","1015e55b":"markdown","74253fae":"markdown","ad09d545":"markdown","51f6e613":"markdown","096a06d4":"markdown","15a41b99":"markdown","7ff140bd":"markdown","0fabd013":"markdown"},"source":{"4730e720":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport scipy.stats as stats","bfa3f836":"train_df = pd.read_csv('..\/input\/predict-the-cost-to-ship-the-sculptures\/dataset\/train.csv')","242c183c":"train_df.head()","da7a9097":"train_df.shape","208ef2b0":"train_df.info()","c686365a":"float_list = ['Artist Reputation', 'Height', 'Width', 'Weight', 'Price Of Sculpture', 'Base Shipping Price']","49e7b2c9":"for col in float_list:\n    \n    plt.figure(figsize=(16, 4))\n\n    # histogram\n    plt.subplot(1, 3, 1)\n    sns.histplot(train_df[col], bins = 30)\n    plt.title('Histogram')\n\n    # Q-Q plot\n    plt.subplot(1, 3, 2)\n    stats.probplot(train_df[col], dist = \"norm\", plot = plt)\n    plt.title('Probability Plot')\n\n    # boxplot\n    plt.subplot(1, 3, 3)\n    sns.boxplot(y = train_df[col])\n    plt.title('Boxplot')\n\n    plt.show()\n    ","e3e8489e":"train_df['Cost'].unique()","67ef2bea":"sns.distplot(train_df['Cost'], kde = False, color ='red')\nplt.show()","77d4364c":"train_df['Cost']=train_df['Cost'].abs()\ntrain_df['Cost']=np.log(train_df['Cost'])","11ac1d67":"# Alternate\n# train_df['Cost'] = np.log(np.abs(df_train['Cost']))","59041bf9":"train_df['Cost'].unique()","424ee7ac":"sns.distplot(train_df['Cost'], kde = False, color ='red') ","34aec086":"train_df.skew(axis = 0, skipna = True)","aa33e92f":"train_df['Price Of Sculpture'] = np.log(train_df['Price Of Sculpture'])\ntrain_df.head()","1bf2c4fc":"sns.distplot(train_df['Price Of Sculpture'], kde = False, color ='red') ","f1be9667":"train_df['Scheduled Date'] = pd.to_datetime(train_df['Scheduled Date'],format='%m\/%d\/%y')","ad8841ae":"train_df['S_Day']=train_df['Scheduled Date'].dt.day\ntrain_df['S_month']=train_df['Scheduled Date'].dt.month\ntrain_df['S_year']=train_df['Scheduled Date'].dt.year","26193ac5":"train_df['Delivery Date'] = pd.to_datetime(train_df['Delivery Date'],format='%m\/%d\/%y')\ntrain_df['D_Day']=train_df['Delivery Date'].dt.day\ntrain_df['D_month']=train_df['Delivery Date'].dt.month\ntrain_df['D_year']=train_df['Delivery Date'].dt.year","216987c0":"# train_df['days_diff'] = (train_df['Delivery Date'] - train_df['Scheduled Date']).days\n# train_df['days_diff'] = np.abs(train_df['days_diff'])","13c581ca":"# Drop them as we dont require now.\ntrain_df.drop(['Scheduled Date','Delivery Date'],1,inplace=True)","064e9a79":"# Not required. But need to retain the Customer ID from test set to for submission.\ntrain_df.drop(['Customer Id', 'Artist Name'], axis = 1, inplace=True)","1deb14fd":"train_df['Transport'].fillna(\"missing_Transport\",inplace=True)\ntrain_df['Material'].fillna(\"missing_Material\",inplace=True)\ntrain_df['Remote Location'].fillna(\"missing_RL\",inplace=True)","39bc17bd":"train_df['Artist Reputation'].fillna(value=train_df['Artist Reputation'].mean(), inplace=True)\ntrain_df['Height'].fillna(value=train_df['Height'].mean(), inplace=True)\ntrain_df['Weight'].fillna(value=train_df['Weight'].mean(), inplace=True)\ntrain_df['Width'].fillna(value=train_df['Width'].mean(), inplace=True)","d07896e5":"# Verify again if any null exists\ntrain_df.isnull().sum()","bd23afd7":"train_df['city'] = train_df['Customer Location'].str.split(',', expand=True)[0]\ntrain_df['city'].head()","b5d9d838":"train_df['State_code'] = train_df['Customer Location'].str.split(',', expand=True)[1].str.slice(0, 3)\ntrain_df[['city', 'State_code']].head","8724f591":"train_df['postal_code'] = train_df['Customer Location'].str.split(',', expand=True)[1].str.split(' ', expand=True)[2]\ntrain_df[['city', 'State_code', 'postal_code']].head","2aa66528":"train_df[['city', 'State_code', 'postal_code']].isnull().sum() ","82fb9cf5":"train_df[train_df['State_code'].isna()][['Customer Location', 'city', 'State_code', 'postal_code']]  ","509e44d9":"city_others = train_df[train_df['State_code'].isna()]['Customer Location'].str.split(' ', expand=True)[0]\ncity_others","6f5a7519":"city_others.index = train_df[train_df['State_code'].isnull()].index","2a2db59a":"city_others","83e6be4a":"State_code_others = train_df[train_df['State_code'].isna()]['Customer Location'].str.split(' ', expand=True)[1]\nState_code_others.index = train_df[train_df['State_code'].isnull()].index","e5376e8e":"postal_code_others = train_df[train_df['postal_code'].isna()]['Customer Location'].str.split(' ', expand=True)[2]\npostal_code_others.index = train_df[train_df['postal_code'].isnull()].index","52192ad9":"train_df.loc[train_df['State_code'].isnull(), 'city'] = city_others\ntrain_df.loc[train_df['State_code'].isnull(), 'State_code'] = State_code_others\ntrain_df.loc[train_df['postal_code'].isnull(), 'postal_code'] = postal_code_others","36310ca4":"train_df[['city', 'State_code', 'postal_code']].isnull().sum() ","6364985b":"train_df.drop(['Customer Location'], axis = 1, inplace=True)\ntrain_df.drop(['city', 'postal_code'], axis = 1, inplace=True) ","e9acad64":"train_df.head()","26f5b8e2":"train_df.tail()","d425fba4":"X = train_df.drop(['Cost'], axis = 1)\ny = train_df['Cost']","dddeb898":"X.shape, y.shape","7001fabc":"list(X.columns)","c2ca7282":"!pip install feature-engine","5f80dd63":"from feature_engine.encoding import OrdinalEncoder\nfrom feature_engine.encoding import OneHotEncoder","3629b7af":"ordinal_enc = OrdinalEncoder(\n    encoding_method='arbitrary',\n    variables=['Material', 'State_code']\n)\nordinal_enc","6c7571d2":"X[['Material', 'State_code']].head()","9d49e08a":"ordinal_enc.fit(X)\nX = ordinal_enc.transform(X)","3c7a12fb":"# X.head()\nX[['Material', 'State_code']].head()","6abb7743":"ordinal_enc.encoder_dict_","10736a9e":"ohe_enc = OneHotEncoder(top_categories=None) \nohe_enc.fit(X)\nX = ohe_enc.transform(X)","6dc13024":"X.head()","fd22305e":"from sklearn.model_selection import train_test_split","53cb3010":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state = 99)","77714727":"X_train.shape, X_valid.shape, y_train.shape, y_valid.shape","50e7604a":"# from sklearn.linear_model import LinearRegression\n# from sklearn.ensemble import RandomForestRegressor \nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom sklearn.metrics import mean_squared_error ","492e929f":"gbr = GradientBoostingRegressor(n_estimators=500, \n                                learning_rate=0.1, \n                                max_depth=8, \n                                random_state=99,\n                                loss='ls', \n                                min_samples_split=5\n                               )","3b23f8ca":"# train the model\ngbr.fit(X_train, y_train)","8dca6afc":"print(gbr.score(X_train, y_train))\nprint(gbr.score(X_valid, y_valid))","45594632":"test_df =  pd.read_csv('..\/input\/predict-the-cost-to-ship-the-sculptures\/dataset\/test.csv')","2922e5b6":"my_submission = test_df[['Customer Id']]","0789f978":"test_df['Price Of Sculpture'] = np.log(test_df['Price Of Sculpture'])","ccc1f88c":"test_df['Scheduled Date'] = pd.to_datetime(test_df['Scheduled Date'],format='%m\/%d\/%y')\ntest_df['S_Day']=test_df['Scheduled Date'].dt.day\ntest_df['S_month']=test_df['Scheduled Date'].dt.month\ntest_df['S_year']=test_df['Scheduled Date'].dt.year\n\ntest_df['Delivery Date'] = pd.to_datetime(test_df['Delivery Date'],format='%m\/%d\/%y')\ntest_df['D_Day']=test_df['Delivery Date'].dt.day\ntest_df['D_month']=test_df['Delivery Date'].dt.month\ntest_df['D_year']=test_df['Delivery Date'].dt.year\n\n# Drop them as we dont require now.\ntest_df.drop(['Scheduled Date','Delivery Date'],1,inplace=True)","b8ed475f":"# Not required. But need to retain the Customer ID from test set to for submission.\ntest_df.drop(['Customer Id', 'Artist Name'], axis = 1, inplace=True)","ebc14ab0":"# Verify again if any null exists\ntest_df.isnull().sum()","aa6ccdb9":"test_df['Transport'].fillna(\"missing_Transport\",inplace=True)\n# test_df['Material'].fillna(\"missing_Material\",inplace=True)\n# test_df['Remote Location'].fillna(\"missing_RL\",inplace=True)\n\ntest_df['Artist Reputation'].fillna(value=test_df['Artist Reputation'].mean(), inplace=True)\ntest_df['Height'].fillna(value=test_df['Height'].mean(), inplace=True)\ntest_df['Weight'].fillna(value=test_df['Weight'].mean(), inplace=True)\ntest_df['Width'].fillna(value=test_df['Width'].mean(), inplace=True)\n","f1aaee60":"test_df['city'] = test_df['Customer Location'].str.split(',', expand=True)[0]\ntest_df['State_code'] = test_df['Customer Location'].str.split(',', expand=True)[1].str.slice(0, 3)\ntest_df['postal_code'] = test_df['Customer Location'].str.split(',', expand=True)[1].str.split(' ', expand=True)[2]\ntest_df[test_df['State_code'].isna()][['Customer Location', 'city', 'State_code', 'postal_code']]  \ncity_others = test_df[test_df['State_code'].isna()]['Customer Location'].str.split(' ', expand=True)[0]\ncity_others.index = test_df[test_df['State_code'].isnull()].index\nState_code_others = test_df[test_df['State_code'].isna()]['Customer Location'].str.split(' ', expand=True)[1]\nState_code_others.index = test_df[test_df['State_code'].isnull()].index\npostal_code_others = test_df[test_df['postal_code'].isna()]['Customer Location'].str.split(' ', expand=True)[2]\npostal_code_others.index = test_df[test_df['postal_code'].isnull()].index\ntest_df.loc[test_df['State_code'].isnull(), 'city'] = city_others\ntest_df.loc[test_df['State_code'].isnull(), 'State_code'] = State_code_others\ntest_df.loc[test_df['postal_code'].isnull(), 'postal_code'] = postal_code_others\n\ntest_df.drop(['Customer Location'], axis = 1, inplace=True)\ntest_df.drop(['city', 'postal_code'], axis = 1, inplace=True) \n","2a5919ac":"test_df.shape","e925843a":"list(test_df.columns)","932c0e1d":"test_df = ordinal_enc.transform(test_df)\ntest_df = ohe_enc.transform(test_df)","f5804d3c":"y_predicted = gbr.predict(test_df)","8de3c938":"y_predicted","5a3d24f1":"my_submission['Cost'] = np.exp(y_predicted)\nmy_submission.to_csv('my_submission.csv', index=False)","40596810":"my_submission","5bfa54df":"Next Step : Predict on the test set.","7533f17a":"Next Step : Visualize the Float fields.","ca59a80b":"Lets see what value is assigned to which Code.","c10d3340":"Next Step : Split the train set into X and y.\nAfter splitting into X and y, will do Feature Engineering.","90eb8f56":"Please do refer https:\/\/www.hackerearth.com\/problem\/machine-learning\/predict-the-cost-to-ship-the-sculptures-12-e7728f5d\/\nfor more details.","17595694":"Next Step : Now we have predicted cost, however this cost is a log value and need to convert back to original, once done will add it into our submission datafrae.","c6d471e7":"Next Step : Target `Cost` field distribution and transform it into log.","95d28e76":"Observation\n* There are 20 columns (including Target) -- Already known\n* There are 6500 records or observations -- Already known\n* 7 fields such as `Artist Reputation`, `Height`, `Width`, `Weight`, `Price Of Sculpture`, `Base Shipping Price`, `Cost` are of float type, and reast are Object.\n* Field `Material` is Categorical and need to transform into numerical format either using one-hot encoding; get_dummies; etc.\n* Some fields such as `Artist Reputation`, `Height`, `Material`, `Transport` etc has NULL or missing values, which need to be taken care.\n","b88ffdfc":"# Model\nNext Step : Train the model with various Algorithm.\n\nAs this is Regression Problem, will try to train the model with various Regression Algorithms.\n\nI did tried with LinearRegression and RandomForestRegression, however GradientBoostingRegressor is resulting the best.. so just have that only in below.","8f476f71":"Cool... so finally Gradient Bossting Regressior has resulted the best score when compared to other regression algorithms.\n\nThere are lot of room to improve the score.\n\nIn the next notebook will try to use NLTK as well, as the Text fields such as `Artist Name` might give some different result. Will try.","8b35c590":"# EDA ","34d27317":"# Result submission guidelines\n* The index is Customer Id and the target is the Cost column. \n* The result file must be submitted in .csv format only.\n* The size of this result file must be 3500 x 2.\n\nNote: Ensure that your submission file contains the following:\n\n* Correct index values as per the test file\n* Correct names of columns as provided in the sample_submission.csv file","5a6feedb":"## Displot\nIt is used basically for univariant set of observations and visualizes it through a histogram i.e. only one observation and hence we choose one particular column of the dataset.","87e3411a":"Next Step : Split the X and y into train and valid dataset","55d92a15":"Now no missing values.","3d190d86":"Next Step : Handing Missing Values.\n\nFor now will populate the missing values with its mean value for numeric and for categorical lets set some string.","7e9d1973":"Same activity for `Delivery Date`","1fd878e9":"# Feature Encoding\nHere will be using the library called `Feature-engine` : A Python library for Feature Engineering for Machine Learning.\n\nFeature-engine is a Python library with multiple transformers to engineer features for use in machine learning models. Feature-engine preserves Scikit-learn functionality with methods fit() and transform() to learn parameters from and then transform the data.\n\n* Feature-engine includes transformers for:\n* Missing data imputation\n* Categorical variable encoding\n* Discretisation\n* Variable transformation\n* Outlier capping or removal\n* Variable creation\n* Variable selection\n\nFeature-engine allows you to select the variables you want to transform within each transformer. This way, different engineering procedures can be easily applied to different feature subsets.\n\nFeature-engine transformers can be assembled within the Scikit-learn pipeline, therefore making it possible to save and deploy one single object (.pkl) with the entire machine learning pipeline. That is, one object with the entire sequence of variable transformations to leave the raw data ready to be consumed by a machine learning algorithm, and the machine learning model at the back.\n\nPlease visit for more details https:\/\/feature-engine.readthedocs.io\/en\/latest\/index.html\n\nFirst we have to install it.","90dc268e":"Next Step : Handling other float \/ numeric fields","d2887e48":"Next Step : Working with `Customer Location`.\n\nThe field `Customer Location` has a combination of City; State Code; and Postal Code.\n\nExample : New Michelle, OH 50777 \n* City : New Michelle\n* State Code : OH\n* Postal Code : 50777\n\nwe will split this data into new features, and later will drop the \"Customer oLocation\".","90ad6a9f":"Seems there are 717 state and postal code which are missing.","5c34847d":"# Evaluation metric\n        score = 100*max(0, 1-metrics.mean_squared_log_error(actual, predicted))","9b976220":"Next Step : We need to retain the Customer ID, and rest which we dropped earlier we can drop and do the same process we did for train set.","4d5ba597":"# Problem\nIt can be difficult to navigate the logistics when it comes to buying art. These include, but are not limited to, the following:\n\n* Effective collection management\n* Shipping the paintings, antiques, sculptures, and other collectibles to their respective destinations after purchase\n\nThough many companies have made shipping consumer goods a relatively quick and painless procedure, the same rules do not always apply while shipping paintings or transporting antiques and collectibles.\n\n# Task\n\nYou work for a company that sells sculptures that are acquired from various artists around the world. Your task is to predict the cost required to ship these sculptures to customers based on the information provided in the dataset.\n\n# Data description\n\nThe dataset folder contains the following files:\n\n* train.csv: 6500 x 20\n* test.csv: 3500 x 19\n* sample_submission.csv: 5 x 2\n\nThe columns provided in the dataset are as follows:\n![image.png](attachment:image.png)","1015e55b":"Seems there are some city which are identified with code instead of name. so lets set them as OTHER, and populate the State and Postal.","74253fae":"Next Step : Handling Dates.\n\nFor field `Scheduled Date` and `Delivery Date`, first will transform into m-d-y format.. and then will extract the Day; Month; and Year, also will create one more field to have difference between Delivery DAte and Scheduled Date (not sure if this is going to help us or not.. but for now will have it)","ad09d545":"# Import Library","51f6e613":"Next Step : Dropping unused fields.","096a06d4":"Next Step : Load Test set","15a41b99":"# Load Data\nFor now will just load the Training set.","7ff140bd":"Cool.... so no null or missing any more.","0fabd013":"Now looking at this we can say that most of the Shipping Cost lies between ~5 and ~7.\n\nAlso the distribution is positive positive skew "}}