{"cell_type":{"85ebe7ba":"code","1a87fd7f":"code","9b457160":"code","391fe8a6":"code","f05510e1":"code","e5e461e1":"code","dd6355cd":"code","259ce0de":"code","c850bb8b":"code","5a978259":"code","9ba92fbc":"code","85e2e5bf":"code","d74936ec":"markdown","57554a9e":"markdown","9706205e":"markdown"},"source":{"85ebe7ba":"!pip install google-cloud-automl","1a87fd7f":"## TODO: relace PATH_TO_JSON_FILE with your service account key json file path\nimport os\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"PATH_TO_JSON_FILE\"","9b457160":"## This is helper function which is used to visualize testing images\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom keras.preprocessing import image\n\nimagepath = glob(\"\/content\/*.jpg\")\n\ncolumns = 20\nrows = 20\nfig = plt.figure(figsize = (8, 8))\ncolumns = 2\nrows = 2\nfor i in range(columns * rows):\n    img = image.load_img(imagepath[i])\n    fig.add_subplot(rows, columns, i+1)\n    plt.imshow(img)\n    plt.title(imagepath[i].split(\"\/\")[2])\nplt.show()","391fe8a6":"#TODO: Replace PROJECT_ID with your project id, MODEL_ID with your model id \nfrom google.cloud import automl\n\n# TODO(developer): Uncomment and set the following variables\nproject_id = \"PROJECT_ID\" \nmodel_id = \"MODEL_ID\" \nimage_path = glob(\"\/content\/*.jpg\")\n\nfor i in range(4):\n  file_path = image_path[i] # your image path\n  print(\"Original Image type is {}\".format(image_path[i].split(\"\/\")[2]))\n  \n  prediction_client = automl.PredictionServiceClient()\n\n  # Get the full path of the model.\n  model_full_id = prediction_client.model_path(\n      project_id, \"us-central1\", model_id\n  )\n\n\n  # Read the file.\n  with open(file_path, \"rb\") as content_file:\n      content = content_file.read()\n\n  image = automl.types.Image(image_bytes=content)\n  payload = automl.types.ExamplePayload(image=image)\n\n  # params is additional domain-specific parameters.\n  # score_threshold is used to filter the result\n  # https:\/\/cloud.google.com\/automl\/docs\/reference\/rpc\/google.cloud.automl.v1#predictrequest\n  params = {\"score_threshold\": \"0.8\"}\n\n  response = prediction_client.predict(model_full_id, payload, params)\n  print(\"Prediction results:\")\n  for result in response.payload:\n      print(\"Predicted class name: {}\".format(result.display_name))\n      print(\"Predicted class score: {}\".format(result.classification.score))\n      print(\"==============================================================\")\n","f05510e1":"#TODO: replace IMAGEPATH with your testing imagepath\n!base64 IMAGEPATH > output.txt","e5e461e1":"#TODO: replace IMAGEPATH with your testing imagepath\n# Import the base64 encoding library.\nimport base64\n\n# Pass the image data to an encoding function.\ndef encode_image(image):\n  with open(image, \"rb\") as content_file:\n    image_content = content_file.read()\n\n  #image_content = image.read()\n  return base64.b64encode(image_content)\n\noutput = encode_image(\"IMAGEPATH\")\nprint(output)","dd6355cd":"!cat output.txt","259ce0de":"#TODO: replace YOUR_BASE64_ENCODED_IMAGE_BYTES with output of above cell and remove 'b' from starting\n{\n  \"payload\": {\n    \"image\": {\n      \"imageBytes\": \"YOUR_BASE64_ENCODED_IMAGE_BYTES\"\n    }\n  }\n}","c850bb8b":"#TODO: assign output of above cell to content variable\ncontent = \"OUTPUT_OF_ABOVE_CELL\"","5a978259":"# copy value of content variable to request.json file\nfile = open(\"request.json\", \"w\")\nfile.writelines(content)\nfile.close()","9ba92fbc":"!cat request.json","85e2e5bf":"## TODO: CHANGE PROJECT_ID, MODEL_ID AND JASON FILE PATH  \n!curl -X POST -H \"Content-Type: application\/json\" \\\n  -H \"Authorization: Bearer $(gcloud auth application-default print-access-token)\" \\\n  https:\/\/automl.googleapis.com\/v1beta1\/projects\/PROJECT_ID\/locations\/us-central1\/models\/MODEL_ID:predict \\\n  -d @JSON_FILE_PATH","d74936ec":"## Linux\n\n    $ base64 input.jpg > output.txt\n\n## Mac os\n\n    $ base64 -i input.jpg -o output.txt\n\n## Windows\n\n    C:> Base64.exe -e input.jpg > output.txt\n\n## PowerShell\n\n    [Convert]::ToBase64String([IO.File]::ReadAllBytes(\".\/input.jpg\")) > output.txt\n\n## Python \n\n    # Import the base64 encoding library.\n    import base64\n\n    # Pass the image data to an encoding function.\n    def encode_image(image):\n      image_content = image.read()\n      return base64.b64encode(image_content)\n\n## Node.js\n\n    \/\/ Read the file into memory.\n    var fs = require('fs');\n    var imageFile = fs.readFileSync('\/path\/to\/file');\n\n    \/\/ Convert the image data to a Buffer and base64 encode it.\n    var encoded = Buffer.from(imageFile).toString('base64');\n\n## Java\n\n    \/\/ Import the Base64 encoding library.\n    import org.apache.commons.codec.binary.Base64;\n\n    \/\/ Encode the image.\n    byte[] imageData = Base64.encodeBase64(imageFile.getBytes());","57554a9e":"# Creating a service account\n\n1. In the Cloud Console, go to the Create service account key page or click [here](https:\/\/console.cloud.google.com\/apis\/credentials\/serviceaccountkey?_ga=2.106839428.647810741.1595677119-773815894.1587384701).\n\n2. From the **Service account list**, select **New service account**.\n3. In the **Service account name** field, enter a name.\n4. From the **Role** list, select **Project > Owner**\n5. Click **Create**. A JSON file that contains your key downloads to your computer.\n\n# Setting the environment variable\n\nIf you plan to use a service account, you need to set an [environment variable](https:\/\/en.wikipedia.org\/wiki\/Environment_variable).\n\nProvide authentication credentials to your application code by setting the environment variable `GOOGLE_APPLICATION_CREDENTIALS`. Replace [PATH] with the file path of the JSON file that contains your service account key. This variable only applies to your current shell session, so if you open a new session, set the variable again.\n\nLinux or Mac OS\n\n    export GOOGLE_APPLICATION_CREDENTIALS=\"[PATH]\"\n\nFor example:\n\n    export GOOGLE_APPLICATION_CREDENTIALS=\"\/home\/user\/Downloads\/my-key.json\"\n\nSetting the environment variable allows you to provide credentials separately from your application, without making changes to application code when you deploy. Alternately, you can explicitly specify the path to the service account key file in your code. For more information, see [Authenticating as a service account](https:\/\/cloud.google.com\/docs\/authentication\/production).","9706205e":"# Mask-NoMask Classification\n\nClassify if given image is of person wearing mask or not\n\n### Dataset\nWe have 440 images with male, female and children wearing masks and without masks. 220 images per category. for example 220 images for person wearing mask and 220 images for person without mask. All of these images are collected froom internet and used to train model only. \n\n### AutoML\nWe have used Google Cloud AutoMl vision API to train the model and deploy. We can use deployed model using python code or rest api. \n\n<br>\n\n#### STEP-1:\nMake a new project in Google Cloud Platform \n\n<img src=\"https:\/\/tr3.cbsistatic.com\/hub\/i\/r\/2019\/11\/14\/e0fb7900-b070-48ac-ac73-8e7ff6c74ddb\/crop\/936x685+5+0\/resize\/1200x\/cb8b8690b161693116b83d68b128f11e\/b-create-project-google-cloud.jpg\">\n\n<br>\n\n#### STEP-2:\nGo to Navigation Menu > APIs & Services > Library and search for AutoMl then enable Cloud AutoML API\n\n<img src=\"https:\/\/support.crowdin.com\/assets\/docs\/cloud-automl-api-enable.png\">\n<br>\n\n#### STEP-3:\nClick on the cloud shell button in top right corner\n<img src=\"https:\/\/cloud.google.com\/shell\/docs\/images\/start-cloud-shell-session.gif\">\n\nNow copy paste these commands in sequence in cloud shell \n        1. export PROJECT_ID=$DEVSHELL_PROJECT_ID\n    2. export USERNAME=YOUR_USENAME # you can find your username in your profile. assign it here\n    3. gcloud projects add-iam-policy-binding $PROJECT_ID \\\n           --member=\"user:$USERNAME\" \\\n           --role=\"roles\/automl.admin\"\n    4. gsutil mb -p ${PROJECT_ID} -c standard -l us-central1 gs:\/\/${PROJECT_ID}-vcm\/\n\n<br>\n\n#### STEP-4:\n\nGo to Navigation Menu > Vision > Datasets and click on create new dataset. Name your dataset Appropriately select Single Label classification and click on create Dataset. \n\nIn select files to import select Upload Images from your computer and upload dataset.zip by clicking on Select Files. Now Browse the bucket named PROJECT_ID-vcm\/ and click on continue.\n\nThis will take few moments for dataset to be uploaded\n\nNow go to train tab and click on start trainig. Name your model appropriately in model name, select cloud hosted and click on continue, select Deploy model to 1 node after training checkbox and then click on START TRAINING. This will take two and half hour to complete training.\n\nAfter training completed we can see Precision and recall of training and Evaluate it. Now go to Test & USE and test your model by uploading images from UPLOAD IMAGES button. We can upload 10 image at most at a time. From there we can use Rest API and Python code to test model via code.\n\nCheck Version 2 for output of notebook"}}