{"cell_type":{"5cfb920e":"code","7c885011":"code","5ebf84ef":"code","96ef4c77":"code","10117b40":"code","e7064f55":"code","a83d2b03":"code","f368b3b1":"code","9880ea96":"code","635a9d9f":"code","ad32f131":"code","10bc970f":"code","fc1283b7":"code","4e6b402f":"code","3f226493":"code","10e7b94c":"code","3250e78a":"code","5bb79b93":"code","7364e9b3":"code","19a696c5":"code","997607fe":"code","8a0de35d":"code","b5b5a5db":"code","1c1f0e3a":"code","b0d49a09":"code","e111c3ac":"code","5f13f12b":"code","05ae6c6e":"code","a84418d3":"code","337cbc4c":"code","d39c3cdc":"code","fc48f695":"code","1c4e0a4e":"code","37153cb7":"code","a59f34cc":"code","8b7e8045":"code","3874ea01":"code","d32cf653":"code","57ebd507":"code","85ad660f":"code","26d6c6ce":"code","e9020de7":"code","53239edc":"code","2b01beae":"code","e075398b":"code","7d08d9d0":"code","6ad6c5fe":"code","d2ef950a":"code","530919f5":"code","8fbd6593":"code","2ec2642f":"code","94606ac1":"code","65e639fd":"code","472a4613":"code","78b8d329":"code","d1aaafbe":"code","ae551187":"code","04e0882a":"code","952362d3":"code","40e0c216":"code","875f3b6f":"code","ebe4673b":"code","7b30aa2d":"code","5b89064b":"code","72512ecb":"code","a5bf2fde":"code","77ffa402":"code","337685d9":"code","29e16662":"code","de5d9d9b":"code","6c827e63":"code","4eb6bccf":"code","3d3c4c0d":"code","ac43243a":"code","8fac1765":"code","92e5f940":"code","67511d28":"code","1ce943ad":"code","93976367":"code","71d1337c":"code","05816cd0":"code","6e231b27":"code","5738a9db":"code","b116ab57":"code","96417c2a":"code","cb8661ab":"code","d8822cce":"code","e37869f0":"markdown","4ac22ca9":"markdown","1fcae1e7":"markdown","2ae514a1":"markdown","f93b0eed":"markdown","b8cb1765":"markdown","23d8b142":"markdown","e3c634f1":"markdown","29e3fe7f":"markdown","bd9f47d6":"markdown","dde92c6e":"markdown","c756b5f2":"markdown","8e15f980":"markdown","c30455b9":"markdown","5eb898d7":"markdown","26d9a61d":"markdown","ad622c16":"markdown","852342d8":"markdown","e07276e2":"markdown","19cbb082":"markdown"},"source":{"5cfb920e":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport string\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nimport nltk\nfrom nltk.corpus import wordnet","7c885011":"customer = pd.read_csv('..\/input\/bank-reviewcomplaint-analysis\/BankReviews.csv', encoding='windows-1252' )\n","5ebf84ef":"customer.head()","96ef4c77":"customer.info()","10117b40":"customer.shape","e7064f55":"customer.isnull().sum()","a83d2b03":"customer['Stars'].value_counts()","f368b3b1":"plt.figure(figsize=(8,6))\nsns.countplot(customer.Stars)\nplt.show()","9880ea96":"X = customer['Reviews']\nY = customer['Stars']","635a9d9f":"X.head()","ad32f131":"# UDF to find sentiment polarity of the reviews\ndef sentiment_review(text):\n    analysis = TextBlob(text)\n    polarity_text = analysis.sentiment.polarity\n    if polarity_text > 0:\n        return 'Positive'\n    elif polarity_text == 0:\n        return 'Neutral'\n    else:\n        return 'Negative'  ","10bc970f":"# creating dictionary which will contain both the review and the sentiment of the review\nfinal_dictionary = []\nfor text in X:\n    dictionary_sentiment = {}\n    dictionary_sentiment['Review'] = text\n    dictionary_sentiment['Sentiment'] = sentiment_review(text)\n    final_dictionary.append(dictionary_sentiment)\nprint(final_dictionary[:5])","fc1283b7":"# Finding positive reviews\npositive_reviews = []\nfor review in final_dictionary:\n    if review['Sentiment'] =='Positive':\n        positive_reviews.append(review)\nprint(positive_reviews[:5])\n    ","4e6b402f":"# Finding neutral reviews\nneutral_reviews = []\nfor review in final_dictionary:\n    if review['Sentiment'] =='Neutral':\n        neutral_reviews.append(review)\nprint(neutral_reviews[:5])","3f226493":"# Finding negative reviews\nnegative_reviews = []\nfor review in final_dictionary:\n    if review['Sentiment'] =='Negative':\n        negative_reviews.append(review)\nprint(negative_reviews[:5])","10e7b94c":"# counting number of positive,neutral and negative reviews\nreviews_count = pd.DataFrame([len(positive_reviews),len(neutral_reviews),len(negative_reviews)],index=['Positive','Neutral','Negative'])","3250e78a":"reviews_count","5bb79b93":"reviews_count.plot(kind='bar')\nplt.ylabel('Reviews Count')   \nplt.show()","7364e9b3":"# printing first five positive reviews\ni=1\nfor review in positive_reviews[:5]:\n        print(i)\n        print(review['Review'])\n        print('******************************************************')\n        i+=1","19a696c5":"# printing first five negative reviews\ni=1\nfor review in negative_reviews[:5]:\n        print(i)\n        print(review['Review'])\n        print('******************************************************')\n        i+=1","997607fe":"# UDF to clean the reviews\ndef clean_text(text):\n    text = text.lower()\n    text = text.strip()\n    text = \"\".join([char for char in text if char not in string.punctuation])\n    return text","8a0de35d":"# X = customer['Reviews']\nX.head()","b5b5a5db":"# applying clean_text function defined above to remove punctuation, strip extra spaces and convert each word to lowercase\nX = X.apply(lambda y: clean_text(y))","1c1f0e3a":"X.head()","b0d49a09":"tokens_vect = CountVectorizer(stop_words='english')","e111c3ac":"token_dtm = tokens_vect.fit_transform(X)","5f13f12b":"tokens_vect.get_feature_names()","05ae6c6e":"token_dtm.toarray()","a84418d3":"token_dtm.toarray().shape","337cbc4c":"len(tokens_vect.get_feature_names())","d39c3cdc":"pd.DataFrame(token_dtm.toarray(),columns = tokens_vect.get_feature_names())","fc48f695":"print(token_dtm)","1c4e0a4e":"# creating a dataframe which shows the count of how many times a word is coming in the corpus\ncount_dtm_dataframe = pd.DataFrame(np.sum(token_dtm.toarray(),axis=0),tokens_vect.get_feature_names()).reset_index()\ncount_dtm_dataframe.columns =['Word','Count']","37153cb7":"count_dtm_dataframe.head()","a59f34cc":"#adding sentiment column which shows sentiment polarity of each word\nsentiment_word = []\nfor word in count_dtm_dataframe['Word']:\n    sentiment_word.append(sentiment_review(word))\ncount_dtm_dataframe['Sentiment'] = sentiment_word","8b7e8045":"count_dtm_dataframe.head()","3874ea01":"# separating positive words\npositive_words_df= count_dtm_dataframe.loc[count_dtm_dataframe['Sentiment']=='Positive',:].sort_values('Count',ascending=False)","d32cf653":"positive_words_df.head(20)","57ebd507":"# plotting word cloud of 10 most frequently used positive words\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(positive_words_df.iloc[0:11,0]))\n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()","85ad660f":"# separating negative words\nnegative_words_df= count_dtm_dataframe.loc[count_dtm_dataframe['Sentiment']=='Negative',:].sort_values('Count',ascending=False)","26d6c6ce":"negative_words_df.head(10)","e9020de7":"# plotting word cloud of 10 most frequently used positive words\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(negative_words_df.iloc[0:11,0]))\n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()","53239edc":"train_X,test_X,train_Y,test_Y = train_test_split(X,Y,random_state = 123, test_size = 0.2)  ","2b01beae":"print('No.of observations in train_X: ',len(train_X), '| No.of observations in test_X: ',len(test_X))\nprint('No.of observations in train_Y: ',len(train_Y), '| No.of observations in test_Y: ',len(test_Y))","e075398b":"vect = CountVectorizer(strip_accents='unicode', stop_words='english', ngram_range=(1,1),min_df=0.001,max_df=0.95)","7d08d9d0":"train_X_fit = vect.fit(train_X)\ntrain_X_dtm = vect.transform(train_X)\ntest_X_dtm = vect.transform(test_X)","6ad6c5fe":"print(train_X_dtm)","d2ef950a":"print(test_X_dtm)","530919f5":"vect.get_feature_names()","8fbd6593":"print('No.of features for are',len(vect.get_feature_names()))","2ec2642f":"train_X_dtm_df = pd.DataFrame(train_X_dtm.toarray(),columns=vect.get_feature_names())","94606ac1":"train_X_dtm_df.head()","65e639fd":"# Finding how many times a tem is used in corpus\ntrain_dtm_freq = np.sum(train_X_dtm_df,axis=0)","472a4613":"train_dtm_freq.head(20)","78b8d329":"vect_tdm = TfidfVectorizer(strip_accents='unicode', stop_words='english', ngram_range=(1,1),min_df=0.001,max_df=0.95)","d1aaafbe":"train_X_tdm = vect_tdm.fit_transform(train_X)\ntest_X_tdm = vect.transform(test_X)","ae551187":"print(train_X_tdm)","04e0882a":"print(test_X_tdm)","952362d3":"vect_tdm.get_feature_names()","40e0c216":"print('No.of features for are',len(vect_tdm.get_feature_names()))","875f3b6f":"# creating dataframe to to see which features are present in the documents\ntrain_X_tdm_df = pd.DataFrame(train_X_tdm.toarray(),columns=vect_tdm.get_feature_names())","ebe4673b":"train_X_tdm_df.head()","7b30aa2d":"test_X_tdm_df = pd.DataFrame(test_X_tdm.toarray(),columns=vect_tdm.get_feature_names())","5b89064b":"test_X_tdm_df.head()","72512ecb":"# Finding how many times a term is used in test corpus\ntest_tdm_freq = np.sum(test_X_tdm_df,axis=0)","a5bf2fde":"test_tdm_freq.head(20)","77ffa402":"# train a LDA Model\nlda_model = LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=50)\nX_topics = lda_model.fit_transform(train_X_tdm)\ntopic_word = lda_model.components_ \nvocab = vect.get_feature_names()","337685d9":"# view the topic models\ntop_words = 10\ntopic_summaries = []\nfor i, topic_dist in enumerate(topic_word):\n    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(top_words+1):-1]\n    topic_summaries.append(' '.join(topic_words))\n    print(topic_words)","29e16662":"# view the topic models\ntop_words = 10\ntopic_summaries = []\nfor i, topic_dist in enumerate(topic_word):\n    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(top_words+1):-1]\n    topic_summaries.append(' '.join(topic_words))\ntopic_summaries","de5d9d9b":"# building naive bayes model on DTM\nnaive_model = MultinomialNB()\nnaive_model.fit(train_X_dtm,train_Y)","6c827e63":"predict_train = naive_model.predict(train_X_dtm)\npredict_test = naive_model.predict(test_X_dtm)","4eb6bccf":"len(predict_test)","3d3c4c0d":"print('Accuracy on train: ',metrics.accuracy_score(train_Y,predict_train))\nprint('Accuracy on test: ',metrics.accuracy_score(test_Y,predict_test))","ac43243a":"# predict probabilities on train and test\npredict_prob_train = naive_model.predict_proba(train_X_dtm)[:,1]\npredict_prob_test = naive_model.predict_proba(test_X_dtm)[:,1]","8fac1765":"print('ROC_AUC score on train: ',metrics.roc_auc_score(train_Y,predict_prob_train))\nprint('ROC_AUC score on test: ',metrics.roc_auc_score(test_Y,predict_prob_test))","92e5f940":"# confusion matrix on test \ncm_test = metrics.confusion_matrix(test_Y,predict_test,[5,1])","67511d28":"cm_test","1ce943ad":"import seaborn as sns\nsns.heatmap(cm_test,annot=True,xticklabels=[5,1],yticklabels=[5,1])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","93976367":"# building naive bayes model on DTM\nnaive_model = MultinomialNB()\nnaive_model.fit(train_X_tdm,train_Y)","71d1337c":"predict_train = naive_model.predict(train_X_tdm)\npredict_test = naive_model.predict(test_X_tdm)","05816cd0":"len(predict_test)","6e231b27":"print('Accuracy on train: ',metrics.accuracy_score(train_Y,predict_train))\nprint('Accuracy on test: ',metrics.accuracy_score(test_Y,predict_test))","5738a9db":"# predict probabilities on train and test\npredict_prob_train = naive_model.predict_proba(train_X_tdm)[:,1]\npredict_prob_test = naive_model.predict_proba(test_X_tdm)[:,1]","b116ab57":"print('ROC_AUC score on train: ',metrics.roc_auc_score(train_Y,predict_prob_train))\nprint('ROC_AUC score on test: ',metrics.roc_auc_score(test_Y,predict_prob_test))","96417c2a":"# confusion matrix on test \ncm_test = metrics.confusion_matrix(test_Y,predict_test,[5,1])","cb8661ab":"cm_test","d8822cce":"import seaborn as sns\nsns.heatmap(cm_test,annot=True,xticklabels=[5,1],yticklabels=[5,1])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","e37869f0":"## Import necesssary libraries","4ac22ca9":"### Feature generation using DTM","1fcae1e7":"## Finding most frequently used Positive\/ Negative words","2ae514a1":"### Coverting reviews to tokens","f93b0eed":"## Topic Modelling","b8cb1765":"\n# Feature Generation using DTM and TDM","23d8b142":"## Data Audit","e3c634f1":"<h3> Model showed better results using DTM values and using unigrams.<\/h3>","29e3fe7f":"# Building Model","bd9f47d6":"### Data Preprocessing","dde92c6e":"### Building Model on DTM","c756b5f2":"### Building Model on TDM","8e15f980":"<h1 align ='center'> Bank Review\/Complaint Analysis <\/h1>","c30455b9":"### Feature generation using TDM","5eb898d7":"<h2>The objetive of the case study is to analyze customer reviews and predict customer satisfaction with the reviews.\n<\/h2>","26d9a61d":"## Sentiment Analysis to find positive and negative reviews","ad622c16":"### Splitting the data into train and test","852342d8":"<h4><i>Central banks collecting information about customer satisfaction with the services provided by different banks. Also collects the information about the complaints.<\/i><\/h4>\n<ul>\n<li><i>Bank users give ratings and write reviews about the services on central bank websites. These reviews and ratings help banks evaluate services provided and take necessary action to improve customer service. While ratings are useful to convey the overall experience, they do not convey the context which led a reviewer to that experience.<\/i><\/li>\n<li><i>If we look at only the rating, it is difficult to guess why the user rated the service as 4 stars. However, after reading the review, it is not difficult to identify that the review talks about good 'service' and 'experience'.<\/i><\/li><\/ul>","e07276e2":"## We were asked that we can ignore intent analysis as that is covered in topic modelling. Hence skipping that part.","19cbb082":"### Import the data set"}}