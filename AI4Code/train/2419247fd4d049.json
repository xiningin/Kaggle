{"cell_type":{"e3233a5b":"code","4094d950":"code","a65b7a75":"code","b5d95e6b":"code","f74d22b2":"code","154d504b":"code","1158a047":"code","906d74c9":"code","9f05d640":"code","e3ba9da7":"code","ec8892aa":"code","82684306":"code","a2458e13":"code","d00cdc6e":"markdown","e0ce3e8b":"markdown","9fcf08e9":"markdown"},"source":{"e3233a5b":"import pandas as pd\nimport numpy as np\nimport gc\nimport os\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom torchvision.utils import draw_bounding_boxes\nfrom torchvision.utils import make_grid\nfrom torchvision.io import read_image\nfrom pathlib import Path\nimport torchvision.transforms.functional as F\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\ndef rmse(y_pred,y_true):\n    loss = np.sqrt(np.mean(np.square(y_true - y_pred), axis=0))\n    return loss\n\n#plt.rcParams[\"savefig.bbox\"] = 'tight'\npd.set_option('mode.chained_assignment',None)\n%matplotlib inline\nimport torch\ndata_dir='\/kaggle\/input\/petfinder-pawpularity-score\/'\ndataset_path=data_dir\ntarget='Pawpularity'","4094d950":"if not os.path.exists('.\/models'):\n    os.makedirs('.\/models')\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'","a65b7a75":"!mkdir -p \/root\/.cache\/torch\/hub\/ultralytics_yolov5_master\n!cp -r ..\/input\/yolo5x-pkl-file-for-pytorch\/yolov5-master\/yolov5-master\/* \/root\/.cache\/torch\/hub\/ultralytics_yolov5_master\n!mkdir -p \/root\/.config\/Ultralytics\n!cp ..\/input\/nfl-arial\/Arial.ttf \/root\/.config\/Ultralytics\/Arial.ttf\n!cp -r ..\/input\/yolo-lung-detector\/yolov5x.pt \/root\/.cache\/torch\/hub\/ultralytics_yolov5_master\/yolov5x.pt","b5d95e6b":"#model_yolo = torch.load('yolov5x.pkl')\n#model_yolo = torch.load('..\/input\/yolo5x-pkl-file-for-pytorch\/yolov5x.pkl')\nmodel_yolo =torch.hub.load('ultralytics\/yolov5', 'yolov5x')\nmodel_yolo.classes = [0,15,16] \n#torch.save(model_yolo,'yolov5x.pkl')\n#model.conf = 0.25  # confidence threshold (0-1)\n#model.iou = 0.45  # NMS IoU threshold (0-1)\n # filter by class, i.e. = [15, 16] for cats and dogs\n    \n#############To save the model for offline use ###########\n\ngc.collect()","f74d22b2":"def process_batch(df_source,img_source_dir,a_rang):\n    gc.collect()\n    torch.cuda.empty_cache()\n    img_list =[Image.open(img_source_dir+df_source['Id'][j]+'.jpg') for j in a_rang]\n    img_area=[float(img.size[0]*img.size[1]) for img in img_list] \n    results = model_yolo(img_list)\n    results_pd=results.pandas().xyxy\n\n    x_len=len(a_rang)\n    for i in a_rang:\n        results_tmp=results_pd[i%x_len]\n        dog_count=results_tmp['name'][results_tmp['name']=='dog'].count()\n        cat_count=results_tmp['name'][results_tmp['name']=='cat'].count()\n        person_count=results_tmp['name'][results_tmp['name']=='person'].count()\n        results_tmp['areas']=(results_tmp['xmax']-results_tmp['xmin'])*(results_tmp['ymax']-results_tmp['ymin'])\/img_area[i%x_len]\n        #print(results_tmp)\n        max_area=results_tmp['areas'][(results_tmp['name']=='dog')|(results_tmp['name']=='cat')].max()\n        min_area=results_tmp['areas'][(results_tmp['name']=='dog')|(results_tmp['name']=='cat')].min()\n        average_area=results_tmp['areas'][(results_tmp['name']=='dog')|(results_tmp['name']=='cat')].mean()\n        #print(max_area,min_area,average_area)\n        #std_area=results_tmp['areas'][(results_tmp['name']=='dog')|(results_tmp['name']=='cat')].std()\n        df_source.at[i,'nbrDogs']=dog_count\n        df_source.at[i,'nbrCats']=cat_count\n        df_source.at[i,'nbrPersons']=person_count\n        df_source.at[i,'max_area']=max_area\n        df_source.at[i,'min_area']=min_area\n        df_source.at[i,'average_area']=average_area\n        #df_source.at[i,'std_area']=std_area\n        #print(df_source.iloc[i])\n\n    return df_source\n\ndef generate_pet_counts(df_source,img_source_dir,bs):\n    gc.collect()\n    df_source['nbrCats']=0\n    df_source['nbrDogs']=0\n    df_source['nbrPersons']=0\n    cat_columns=list(df_source.columns)\n    df_source['max_area']=0.00001\n    df_source['min_area']=0.00001\n    df_source['average_area']=0.00001\n    #df_source['std_area']=0\n    cat_columns.remove('Id')\n    cat_columns.append('nbrCats')\n    cat_columns.append('nbrDogs')\n    cat_columns.append('nbrPersons')\n    df_source[cat_columns].astype('int8')\n    df_source[['max_area','min_area','average_area']].astype('float')\n        \n    x_len=int(df_source.shape[0]\/bs)\n    for i in tqdm(range(x_len)):\n        a_rang=range(i*bs,(i+1)*bs)\n        df_source=process_batch(df_source,img_source_dir,a_rang) #multiples\n    if ((df_source.shape[0]%bs)!=0):\n        a_rang=range(x_len*bs,df_source.shape[0])\n        df_source=process_batch(df_source,img_source_dir,a_rang)#the rest\n    return df_source.fillna(0)\nbatch_size=200","154d504b":"#trainSet = pd.read_csv(data_dir+'train.csv', low_memory=False)\n#trainSet=trainSet.iloc[:100]\n#gc.collect()\n#trainSet=generate_pet_counts(trainSet,data_dir+'train\/',batch_size)\n#trainSet[['Id','nbrCats','nbrDogs']].head(5)\ntrain_fname='..\/input\/trainset-with-pet-count\/train_with_areaFeatures.ftr'\ntrainSet=pd.read_feather(train_fname)\ntrain_df=trainSet.copy()\ntrain_df['norm_score'] = train_df['Pawpularity']\/100\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path+'train\/'+x)+'.jpg')","1158a047":"testSet = pd.read_csv(data_dir+'test.csv', low_memory=False)\ntestSet=generate_pet_counts(testSet,data_dir+'test\/',batch_size)\ntestSet['path'] = testSet['Id'].map(lambda x:dataset_path+'test\/'+str(x)+'.jpg')","906d74c9":"import sys\nimport os\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nfrom timm import create_model\nimport gc\nfrom fastai.vision.all import *\nBATCH_SIZE = 16\nseed=365\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n\ndef clean_mem():\n    torch.cuda.empty_cache()\n    gc.collect()","9f05d640":"def rmse(pred,target):\n  return np.sqrt(np.mean(np.square(target - pred)))\n\ndef petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(torch.sigmoid(input.flatten()), target))\n\ndef z_freeze(model):\n  for name, param in model.named_parameters():\n#    if name.startswith('head')  or name.startswith('classifier'): #or name.startswith('norm')\n    #param.requires_grad = True  \n#      continue\n    param.requires_grad = False\ndef z_unfreeze(model):\n  for name, param in model.named_parameters():\n    param.requires_grad = True\ndef print_param_status(model):\n  for i,x in enumerate(model.named_parameters()):\n    name, param=x\n    print(i,name, param.requires_grad)\n    \ndef tuple_of_tensors_to_tensor(tuple_of_tensors):\n    return  torch.stack(list(tuple_of_tensors), dim=0)\ndef calc_emb_size(x):\n    return min(600, round(1.6 * x**0.56))\n\ndef get_training_score(learn):\n  preds, _ = learn.get_preds(ds_idx=0)\n  preds=np.squeeze(preds.float().numpy()*100)\n  train_score=rmse(preds,learn.dls.train_ds.items['Pawpularity'])\n  return train_score","e3ba9da7":"cat_list=['nbrCats', 'nbrDogs']#,'Eyes', 'Face']#,'Group',\nmax_cat=[15]*2#+[2]*2\n#cat_list=['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory','Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'nbrCats', 'nbrDogs']\n#max_cat=[2]*12+[15]*2\nnb_cat=len(cat_list)\n\nblocks=(ImageBlock(cls=PILImage),*(nb_cat*[CategoryBlock]),RegressionBlock)\ngetters_x=[ColReader('path', pref='', suff='')]\n#,ColReader('Eyes'), ColReader('Face'),ColReader('Group'),ColReader('nbrCats'), ColReader('nbrDogs')]\nfor i in range(nb_cat): getters_x.append(ColReader(cat_list[i]))\ngetters_y=ColReader('norm_score')\ndblock = DataBlock(blocks=blocks, get_x=getters_x,get_y=getters_y,  n_inp=nb_cat+1,# Set the number of inputs\n              item_tfms=Resize(224),\n                   #splitter=...,  #batch_tfms=...\n)\ndls = dblock.dataloaders(train_df, bs=BATCH_SIZE)\n#dls.show_batch()\nclean_mem()","ec8892aa":"# From image_tabular module\nclass CNNTabularModel(Module):\n    def __init__(self, cnn_model, tabular_model, layers, ps, out_sz):\n        super().__init__()\n        self.cnn_model = cnn_model\n        self.tabular_model = tabular_model\n\n        ps = ifnone(ps, [0]*len(layers))\n        ps = [ps for i in range(len(layers))]\n        sizes = layers + [out_sz]\n        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n        layers = []\n        for n_in,n_out,dp,act in zip(sizes[:-1],sizes[1:], ps, actns):\n            layers += LinBnDrop(n_in, n_out, bn=True, p=dp, act=act)\n        self.layers = nn.Sequential(*layers)\n\n\n    def forward(self, *x):\n        x_image = self.cnn_model(x[0])\n        x_tab = self.tabular_model(tuple_of_tensors_to_tensor(x[1:]).transpose(0,1)) \n        #print(type(x_image),type(x_tab))\n        #<class 'fastai.torch_core.TensorImage'> <class 'fastai.torch_core.TensorCategory'>\n        #print(torch.tensor(x_image),torch.tensor(x_tab))\n        # Pytorch doesn't accept mixed Tensor types\n        #.as_subclass(TensorBase)\n        #torch.tensor(x_image),torch.tensor(x_tab) # gives a warning\n        x_image, x_tab= x_image.as_subclass(TensorBase),x_tab.as_subclass(TensorBase)\n        x = torch.cat((x_image, x_tab), 1)\n        x = self.layers(x)\n        return x\n    \nmodel_str=['resnet34','resnet50','efficientnet_b4','swin_large_patch4_window7_224']\ncnn_out_sz_list=[512,2048,1792,1536]\n####BATCH_SIZE = 128,128,128,16\nmodel_num=3\nimage_model = create_model(model_str[model_num], pretrained=True, num_classes=0)\ncnn_out_sz = cnn_out_sz_list[model_num]\nclean_mem()\nfrom fastai.tabular import *\nfrom fastai.tabular.model import TabularModel  \n# get embedding sizes of categorical data\ntab_df=train_df[cat_list]\n\ncont_names=[]\nemb_szs = [(max_cat[i],calc_emb_size(max_cat[i])) for i in range(nb_cat)]\nprint('Embedding sizes: ',emb_szs)\n# output size of the tabular model that will be concatenated with cnn model output\ntotal_emb_size=sum([calc_emb_size(max_cat[i]) for i in range(nb_cat)])\ntab_out_sz = 4#max(10,total_emb_size\/\/2)\n\n# use fastai functions to get a tabular model\ntabular_model = TabularModel(emb_szs, len(cont_names), out_sz=tab_out_sz, layers=[6], ps=0.2) #max(total_emb_size,16)\n#tabular_model\nclean_mem()\n# use gpu by default if available\nintegrated_model = CNNTabularModel(image_model,\n                                  tabular_model,\n                                  layers = [cnn_out_sz + tab_out_sz,512, 32],\n                                  ps=0.4,\n                                  out_sz=1).to(device)\nclean_mem()\n!cp ..\/input\/trainset-with-pet-count\/swin_01.pth models\nlearn = Learner(dls, integrated_model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse)#.to_fp16()\nlearn.load('swin_01',with_opt=False)\nget_training_score(learn)","82684306":"clean_mem()\ntest_dl=dls.test_dl(testSet)\npreds, _ = learn.get_preds(dl=test_dl)\npreds=np.squeeze(preds.float().numpy()*100)","a2458e13":"testSubmission=pd.DataFrame()\ntestSubmission['Id']=testSet['Id']\ntestSubmission[target]=preds\ntestSubmission[['Id', target]].to_csv('submission.csv',index = False)\ntestSubmission.head(5)","d00cdc6e":"# **Inference and Submission**","e0ce3e8b":"# **Load Trained Model**","9fcf08e9":"# **Generating Pet Counts**"}}