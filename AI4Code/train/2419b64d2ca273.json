{"cell_type":{"4beb4264":"code","ffc83363":"code","67dddca9":"code","a64c06c6":"code","7967b50a":"code","2583e1ac":"code","95a68b4e":"code","4f0dad21":"code","20450799":"code","d4f2b574":"code","31d182a5":"code","02c565d2":"code","b85d7f8c":"code","2b3a5d76":"code","1f014297":"code","29adb080":"code","e86a28be":"code","996a6a2b":"code","ff1fcf92":"code","f3cd70c1":"code","cb1665db":"code","2328b302":"code","aa67b152":"code","792566b1":"code","b62acdf5":"code","0b41bb16":"code","6fab9908":"code","98785188":"code","b5812601":"code","6c3fbd00":"code","a16db27d":"code","68c156f3":"code","e1a5df20":"code","f00fb582":"code","8e954124":"code","415f3e97":"code","d6c86c1b":"code","295e301d":"code","2d2e4e2f":"code","a167bde8":"code","6b9a73d2":"code","f19550b6":"code","c507ffc5":"code","58c93684":"code","ef46e7a8":"code","aa93be28":"code","191c100f":"code","7ed9aa75":"code","1e84ba39":"code","b5f3eb37":"code","a19fc4cd":"code","53cc92f5":"code","76da12c3":"code","b7e796b8":"code","9f228883":"code","ae1e47f3":"code","805b2f33":"code","3e31080b":"code","c0b2e5d1":"code","d1a076ab":"code","52f2b413":"code","7551a046":"code","f7b95cd6":"code","d2c5fd38":"code","10a8c43b":"code","d729ddfd":"code","95f669f7":"code","b051c04a":"code","5d632233":"code","1a66381e":"code","93eddbe8":"code","14a54097":"code","48410f4b":"code","cdb9d913":"code","34fb2575":"code","818797fd":"code","a9f78eea":"markdown","e2f35546":"markdown","a33d0cea":"markdown","b360e6d5":"markdown","07c899cd":"markdown","4a238ef2":"markdown","962a5ead":"markdown","56f37111":"markdown","c7b42f8e":"markdown","9d003d2b":"markdown","03a56898":"markdown","caeff50f":"markdown","a218b226":"markdown","c1e1411a":"markdown","5bbeeb87":"markdown"},"source":{"4beb4264":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ffc83363":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","67dddca9":"df_train = pd.read_csv(\"\/kaggle\/input\/spam-sms-classification\/TrainDataset.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/spam-sms-classification\/TestDataset.csv\")","a64c06c6":"train = df_train\ntest = df_test","7967b50a":"df_train.head()","2583e1ac":"df_train = df_train.rename(columns = {'v1':'class_label','v2':'message'})\ndf_test = df_test.rename(columns = {'v2':'message'})","95a68b4e":"df_train.head()","4f0dad21":"df_train.shape","20450799":"df_test.head()","d4f2b574":"df_test.shape","31d182a5":"class_label = df_train['class_label']","02c565d2":"df_train.info()","b85d7f8c":"df_train.groupby('class_label').describe()","2b3a5d76":"df_train['length'] = df_train['message'].apply(len)\ndf_train.head()","1f014297":"df_train.hist(column='length', by='class_label', bins=50,figsize=(11,5))\nplt.show()","29adb080":"df_train.class_label.value_counts()","e86a28be":"df_train.class_label.value_counts(normalize=True)","996a6a2b":"f,ax=plt.subplots(1,2, figsize=(12,4))\ndf_train.class_label.value_counts().plot.pie(explode=[0,0.12],autopct='%1.3f%%',ax=ax[0])\nsns.countplot('class_label',data=df_train)\nplt.show()","ff1fcf92":"df_train.drop('class_label',axis=1,inplace=True)\ndf_train.drop('length',axis=1,inplace=True)","f3cd70c1":"## joined df_train is combination of train and test\ndf_train = df_train.append(df_test)","cb1665db":"# store the SMS message\nsms = df_train.message\nsms.head()","2328b302":"# Replace email address with 'emailaddress'\nfinal_sms = sms.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress')","aa67b152":"# Replace urls with 'webaddress'\nfinal_sms = final_sms.str.replace(r'^http\\:\/\/[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(\/\\S*)?$', 'webaddress')","792566b1":"# Replace money symbol with 'money-symbol'\nfinal_sms = final_sms.str.replace(r'\u00a3|\\$', 'money-symbol')","b62acdf5":"# Replace 10 digit phone number with 'phone-number'\nfinal_sms = final_sms.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phone-number')","0b41bb16":"# Replace normal number with 'number'\nfinal_sms = final_sms.str.replace(r'\\d+(\\.\\d+)?', 'number')","6fab9908":"# remove punctuation\nfinal_sms = final_sms.str.replace(r'[^\\w\\d\\s]', ' ')","98785188":"# remove whitespace between terms with single space\nfinal_sms = final_sms.str.replace(r'\\s+', ' ')","b5812601":"# remove leading and trailing whitespace\nfinal_sms = final_sms.str.replace(r'^\\s+|\\s*?$', ' ')","6c3fbd00":"# change words to lower case\nfinal_sms = final_sms.str.lower()","a16db27d":"final_sms","68c156f3":"import nltk","e1a5df20":"# remove stop words from SMS\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nfinal_sms = final_sms.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))","f00fb582":"# remove word stems using Porter stemmer\nimport nltk\nps = nltk.PorterStemmer()\nfinal_sms = final_sms.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))","8e954124":"final_sms","415f3e97":"from nltk.tokenize import word_tokenize","d6c86c1b":"# creating a bag-of-words\nall_words = []\nfor sms in final_sms:\n    words = word_tokenize(sms)\n    for w in words:\n        all_words.append(w)\n        \nall_words = nltk.FreqDist(all_words)        ","295e301d":"# print total number of words\nprint('Number of words: {}'.format(len(all_words)))","2d2e4e2f":"# print 10 most common words\nprint('10 most common words: {}'.format(all_words.most_common(10)))","a167bde8":"temp = []\nfor (i,j) in all_words.most_common(1200):\n    temp.append(i)","6b9a73d2":"# use the top 1200 most common words as features\ntemp","f19550b6":"from sklearn.feature_extraction.text import TfidfVectorizer","c507ffc5":"tfidf_model=TfidfVectorizer()\ntfidf_vec=tfidf_model.fit_transform(final_sms)\ntfidf_data=pd.DataFrame(tfidf_vec.toarray())\ntfidf_data.head()","58c93684":"train.shape","ef46e7a8":"test.shape","aa93be28":"df_test = tfidf_data.iloc[-1115:]","191c100f":"df_train = tfidf_data.iloc[:4457]","7ed9aa75":"df_train['class_label'] = class_label","1e84ba39":"df_train.shape","b5f3eb37":"df_train","a19fc4cd":"X = df_train.drop('class_label',axis=1)\nY = class_label","53cc92f5":"# splitting training data into train and validation using sklearn\nfrom sklearn import model_selection\nX_train,X_test,y_train,y_test = model_selection.train_test_split(X,Y,test_size=.2, random_state=42)","76da12c3":"print(len(X_train))\nprint(len(X_test))","b7e796b8":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score","9f228883":"from sklearn.ensemble import RandomForestClassifier\nrfc_mod = RandomForestClassifier(n_estimators=50,max_depth=12, random_state=101,\n                             class_weight='balanced',verbose=1,n_jobs=-1)","ae1e47f3":"rfc_mod.fit(X_train,y_train)","805b2f33":"y_pred_rfc = rfc_mod.predict(X_test)","3e31080b":"y_pred_rfc ","c0b2e5d1":"print(\"F1 Score :\",f1_score(y_pred_rfc,y_test,average = \"weighted\"))\nprint('Report:\\n',classification_report(y_test, y_pred_rfc))\nprint('Confusion Matrix: \\n',confusion_matrix(y_test, y_pred_rfc))","d1a076ab":"rfc_predicted = rfc_mod.predict(df_test)","52f2b413":"test_predicted= pd.DataFrame()\ntest_predicted['class_label'] = rfc_predicted\ntest_predicted.to_csv('test_predicted_rfc.csv',index=False)","7551a046":"from sklearn.tree import DecisionTreeClassifier","f7b95cd6":"dectre_mod = DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=5).fit(X_train, y_train)","d2c5fd38":"dectre_mod.fit(X_train,y_train)","10a8c43b":"y_pred_dectre = dectre_mod.predict(X_test)","d729ddfd":"y_pred_dectre","95f669f7":"print(\"F1 Score :\",f1_score(y_pred_dectre,y_test,average = \"weighted\"))\nprint('Report:\\n',classification_report(y_test, y_pred_dectre))\nprint('Confusion Matrix: \\n',confusion_matrix(y_test, y_pred_dectre))","b051c04a":"dectre_predicted = dectre_mod.predict(df_test)","5d632233":"test_predicted= pd.DataFrame()\ntest_predicted['class_label'] = dectre_predicted\ntest_predicted.to_csv('test_predicted_DecisionTree.csv',index=False)","1a66381e":"from sklearn.linear_model import LogisticRegression","93eddbe8":"logreg_mod = LogisticRegression(random_state=42).fit(X_train, y_train)","14a54097":"y_pred_logreg = logreg_mod.predict(X_test)","48410f4b":"y_pred_logreg","cdb9d913":"print(\"F1 Score :\",f1_score(y_pred_logreg,y_test,average = \"weighted\"))\nprint('Report:\\n',classification_report(y_test, y_pred_logreg))\nprint('Confusion Matrix: \\n',confusion_matrix(y_test, y_pred_logreg))","34fb2575":"predicted_test = logreg_mod.predict(df_test)","818797fd":"test_predicted = pd.DataFrame()\ntest_predicted['class_label'] = predicted_test\ntest_predicted.to_csv('test_predicted_logisticRgrsn.csv',index=False)","a9f78eea":"### Import Evaluation metric","e2f35546":"## 3.) Exploratory Data Analysis","a33d0cea":"## 2.) Load the dataset ","b360e6d5":"### Decision Tree","07c899cd":"### RandomForest","4a238ef2":"## 1.) Import packages","962a5ead":"### Seprating Columns","56f37111":"#### NLTK ","c7b42f8e":"## 5.) Model Building","9d003d2b":"### Distribution of Target Variable","03a56898":"### Using *regular expression* to replace email address, urls, phone number, money","caeff50f":"#### TFIDF","a218b226":"#### So, the dataset is imbalanced with respect to target variable.","c1e1411a":"### Logistic Regression","5bbeeb87":"## 4.) Preprocessing the data"}}