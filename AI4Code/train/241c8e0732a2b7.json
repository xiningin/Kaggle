{"cell_type":{"a5aa95ca":"code","2d0c4d91":"code","c124417c":"code","92945c8a":"code","6038916b":"code","1b40c75a":"code","53569733":"code","7d5305ca":"code","b4839e7c":"code","12c1b7b1":"code","b5eeaf59":"code","f529599a":"code","60b26cf9":"code","6d49cf31":"code","e92e94d5":"markdown"},"source":{"a5aa95ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n        print(os.path.join(dirname))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2d0c4d91":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as  np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n","c124417c":"#defining our training and validation data set path\ntrain_data = \"\/kaggle\/input\/rock-paper-scissors-dataset\/rock-paper-scissors\/Rock-Paper-Scissors\/train\"\nvalidation_data = \"\/kaggle\/input\/rock-paper-scissors-dataset\/rock-paper-scissors\/Rock-Paper-Scissors\/test\"","92945c8a":"#printing images\n\ndef read_img(path):\n    img=mpimg.imread(path)\n    imgplot = plt.imshow(img)\n    return plt.show()\n\nread_img(\"\/kaggle\/input\/rock-paper-scissors-dataset\/rock-paper-scissors\/Rock-Paper-Scissors\/train\/rock\/rock01-001.png\")\n\nread_img(\"\/kaggle\/input\/rock-paper-scissors-dataset\/rock-paper-scissors\/Rock-Paper-Scissors\/train\/paper\/paper01-005.png\")\n\nread_img(\"\/kaggle\/input\/rock-paper-scissors-dataset\/rock-paper-scissors\/Rock-Paper-Scissors\/train\/scissors\/scissors01-005.png\")\n    ","6038916b":"#definig a callback to stop our model when it gets 95%\nclass myCallbacks(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('acc')>0.95):\n            print(\"\\nReached 92 accuracy so cancelling training!\")\n            self.model.stop_training = True\n    ","1b40c75a":"#importing dataset \ntrain_genr = ImageDataGenerator(rescale = 1.\/255.)\nvalidation_genr = ImageDataGenerator(rescale = 1.\/255.)\n\ntrain_imgs = train_genr.flow_from_directory(directory = train_data, batch_size = 32,\n                                                  target_size = (300,300), class_mode = 'categorical' )\n\nval_imgs = validation_genr.flow_from_directory(directory = validation_data, batch_size = 32,\n                                                  target_size = (300,300), class_mode = 'categorical' )\n#initiallising call backs\ncallbacks = myCallbacks()","53569733":"model = tf.keras.models.Sequential([\n    #adding convolution layer and maxpooling layers\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (3*3), activation = 'relu', input_shape = (300,300,3)),\n    tf.keras.layers.MaxPooling2D(pool_size = (2*2)),\n    tf.keras.layers.Conv2D(64, kernel_size = (3*3), padding = 'same', activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(pool_size = (2*2)),\n    tf.keras.layers.Conv2D(128, kernel_size = (3*3), padding = 'same', activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(pool_size = (2*2)),\n    \n    #flatting  array because dense layer takes input in 1d\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation = 'relu'),\n    tf.keras.layers.Dense(3, activation = 'softmax')\n\n])\n\n\n\n#compiling the model\nmodel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['acc'])\n\n#summary of model\nmodel.summary()","7d5305ca":"#fitting the model\nhistory = model.fit(train_imgs, validation_data = val_imgs, epochs = 20, steps_per_epoch = 30, verbose = 1, callbacks = [callbacks])","b4839e7c":"import matplotlib.pyplot as plt\nacc= history.history['acc']\nloss = history.history['loss']\n\nval_loss = history.history['val_loss']\nval_acc = history.history['val_acc']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r' ,label = 'Training Accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'validation Accuracy')\nplt.title(\"Training and validation Accuracy\")\nplt.legend()\nplt.figure()\n\n\n\nplt.plot(epochs, loss, 'r',  label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label = 'validation loss')\nplt.title(\"Training and validation loss\")\nplt.legend()\nplt.figure()","12c1b7b1":"model.save('h.h5') #save our model for further use","b5eeaf59":"from tensorflow.keras.models import load_model\nmodel  = load_model('h.h5')\nmodel.summary()","f529599a":"import numpy as np\nfrom keras.preprocessing import image\npath = '\/kaggle\/input\/rock-paper-scissors-dataset\/rock-paper-scissors\/Rock-Paper-Scissors\/validation\/paper5.png'\nread_img(path)\n#reading images\nimg = image.load_img(path, target_size = (300,300))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nimages = np.expand_dims(x, axis = 0)\nimages = np.vstack([x])\n","60b26cf9":"def predict_img(img):\n    pred_clss = model.predict_classes(images)\n    print(\"prediction class is :\", pred_clss)\n    if pred_clss ==array([1]):\n        print('rock')\n    elif pred_clss ==array([0]):\n        print('paper')\n    if pred_clss ==array([1]):\n        print('scissor')\n    \n          ","6d49cf31":"predict_img(path)","e92e94d5":"### Reading image and predicting it"}}