{"cell_type":{"b177da74":"code","b08783d8":"code","9be7aafa":"code","095131f0":"code","200c4713":"code","135f1b44":"code","7c23c600":"code","f0debe36":"code","89151338":"code","0542be94":"code","10365e50":"code","ee1509a7":"code","eaf6714f":"code","66f13c71":"code","1d79668a":"code","36df8d30":"code","33fbad6e":"code","b4ba87df":"code","2f43dff0":"code","dc4d2741":"code","82955b4e":"code","aab119a0":"code","b2c85d5e":"code","e29c4c33":"code","7f6d94d7":"code","b2876c2b":"code","15d16537":"code","7cd10535":"code","514eeedb":"code","cd2150b7":"code","7af5ea41":"code","0b97262e":"code","bd935c3b":"code","f1ca21d7":"code","899e963a":"code","d95158ab":"code","ae32cd46":"code","5676972b":"code","587b640c":"code","d82e29c5":"code","89a48a6c":"code","4dada02c":"code","ce4fe068":"code","7e33e675":"code","54272f74":"code","329c91b6":"code","061a1174":"code","a511de20":"code","fcb2b470":"code","63579253":"code","6316f94d":"code","912f045d":"code","b1f6eb50":"code","ea0ff323":"code","7b79e679":"code","1f47e47c":"code","ba0aa590":"code","5b807fc0":"code","58e4b294":"code","725f4996":"code","a7918b75":"code","ccdc3124":"code","cbe5f856":"markdown","4b14981f":"markdown","f27d63cc":"markdown","8300e73f":"markdown","d54d6ebf":"markdown","5658edd0":"markdown","4e77b628":"markdown","7c148457":"markdown","746d800c":"markdown","897ef737":"markdown","40ef6fee":"markdown","34fee0ca":"markdown","09279220":"markdown","0d80c9dc":"markdown","49ba85a9":"markdown","b6f3d4da":"markdown","43e57a9e":"markdown","dfb4c89e":"markdown","51106a0c":"markdown","5600bcc7":"markdown","c03e8233":"markdown","0c2822fc":"markdown","cef7e304":"markdown","8c0de902":"markdown","59346b03":"markdown"},"source":{"b177da74":"# Explore the state of digital learning in the U.S by 2020\n# Explore impact of different factors on digital learning\n# Suggest recomendation policies \n","b08783d8":"# Study the picture of digital connectivitiy and engagemnt in 2020\n# Study effect of pandemic on online and distance learning for future relation\n# Study student ability to engage in a given type of educationa technology change\n# Study relation of digital learning to geography\n# Study relation of digital learning to demographic context of factors like: race\/ethinicity, ESL, learning disability\n# Study relation of digital learning to socioeconmic status\n# Perform state interventions, practices or policies like: stimulus, reopening, eviction, moratorium\n# Perform state interventions to correlate with the increase or decrease online student engament  ","9be7aafa":"import os\nimport glob\nimport tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport missingno as msno\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport statistics as stat\nimport folium\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)\n","095131f0":"# setiing environment to read data\n\ndf = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\ndf.head() # viewing top records of the data","200c4713":"#we define a couple of scripts that we shall implement\ndef null_values(df):\n    \n    #get the number of null values in the system\n    try:\n        print(\" #### Calculating Missing Values ##### \\n\")\n        for i in tq(range(1),desc=\"Fetching data\"):\n        \n            \n            \n            sumofNull=df.isna().sum()\n            percentage=sumofNull\/len(df)*100\n        print(\" #### Done #### \\n \")\n            \n            \n        \n        print(\"#### Creating data frame #### \\n \")\n        \n        for i in tq(range(1),desc=\"Creating DataFrame\"):\n            valuesdf=pd.DataFrame(data=[sumofNull,percentage])\n            valuesdf=valuesdf.T\n            valuesdf.columns=[\"Total Missing\",\"Percentage Missing\"]\n        print(\" #### Done #### \")\n        \n\n        return valuesdf\n            \n    except Exception as e:\n        \n        print(\" !!! Error File Not Found  !!!!! \\n\")\n        print(\" !!! Program Failed !!!!! \\n\")\n        \n        print(\"Safely exiting the program\")\n        sys.exit(1)\n\ndef dropDuplicates(data):\n        try:\n            \n            for i in tq(range(1),desc=\"Detecting duplicates\"):\n                data=data.drop_duplicates()\n            for i in tq(range(1),desc=\"Report on Duplicates \"):\n                dupCount=len(data)-len(data.drop_duplicates())\n                \n            print (\"There are {} duplicates in the dataset\\n\".format(dupCount))\n            logging.info(\"Number of duplicates in the datset are {} \".format(dupCount))\n\n            \n\n            return data \n        except Exception as e:\n\n            print(\"The following error occured {} \".format(e.__class__))","135f1b44":"df.info()","7c23c600":"import sys\nfrom tqdm.notebook import tqdm_notebook as tq\nnull_values(df)","f0debe36":"#we get the state abbrevations to use in potting graphs\nstate_abb = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndf['state_abb'] = df['state'].map(state_abb)\n","89151338":"def count_plot(data,colr,title):\n    plt.figure(figsize=(10,8))\n    ax=sns.countplot(x=data,palette=colr,order=data.value_counts().index)\n    plt.xticks(rotation=90)\n    plt.title(title)\n    for p in ax.patches:\n        ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n#         ax.text('%{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))","0542be94":"import plotly.graph_objects as go\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Count of districts in the available States\",\n    title_font = dict(\n            family = \"monospace\",\n            size = 25,\n            color = \"black\"\n            ),\n    geo_scope = 'usa'\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations = df['state_abb'].value_counts().to_frame().reset_index()['index'],\n        zmax = 1,\n        z = df['state_abb'].value_counts().to_frame().reset_index()['state_abb'],\n        locationmode = 'USA-states',\n        marker_line_color = 'white',\n        geo = 'geo',\n        colorscale = \"cividis\", \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()","10365e50":"import matplotlib.pyplot as plt\nimport seaborn as sns\ncount_plot(df['state'],'RdYlGn',\"State count display\")","ee1509a7":"df2 = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')\ndf2  # viewing top and  bottom records of the data","eaf6714f":"# Understanding the data types and null counts\ndf.info()\n","66f13c71":"# Identify the shape of data\nprint(f\"There are {df.shape[0]} rows and {df.shape[1]} columns\")","1d79668a":"# there is need to understand the numeric data\ndf.describe()","36df8d30":"#slipting numerical and categorical data \ndf_num = df[['district_id']]\ndf_cat = df[['state','locale', 'pct_black\/hispanic', 'pct_free\/reduced', 'county_connections_ratio', 'pp_total_raw']]","33fbad6e":"# Visualization of data structure\nimport matplotlib.pyplot as plt \n\nfor i in df_num.columns:\n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()","b4ba87df":"df.head()","2f43dff0":"#Outline the datatypes and null counts \ndf2.info()","dc4d2741":"# Identify the shape of data\nprint(f\"There are {df2.shape[0]} rows and {df2.shape[1]} columns\")","82955b4e":"df2.describe()","aab119a0":"#slipting numerical and categorical data \ndf2_num = df2[['LP ID']]\ndf2_cat = df2[['URL','Product Name', 'Provider\/Company Name', 'Sector(s)', 'Primary Essential Function']]","b2c85d5e":"#Visualization of data structure \nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nfor i in df2_num.columns:\n    plt.hist(df2_num[i])\n    plt.title(i)\n    plt.show()\n","e29c4c33":"# Handling columns with missing values \ndf.isna().sum()","7f6d94d7":"df.dtypes","b2876c2b":"# checking for null values if there is any empty column\ncheck_null = df.columns.isnull().any()\ncheck_null","15d16537":"# Identfying the percentage of null values \ndef null_analysis(df):\n    total_values = np.product(df.shape)\n    total_null = (df.isnull().sum()).sum()\n    proportion_null = (total_null \/ total_values)*100\n    \n    print(\"The district info dataset has \", proportion_null,\"% null values.\")\n\nnull_analysis(df)","7cd10535":"# Identifying duplicated rows\ndf = df[df.duplicated()]\nprint(\"Number of duplicate rows: \", df.shape)\n","514eeedb":"# fill missing with ffill method for columns (pct_free\/reduced , pp_total_raw )\n\ndef fix_missing_ffill(df2, col):\n    df2[col] = df2[col].fillna(method='ffill')\n    return df2[col]\n# fill missing with ffill method for columns (pct_free\/reduced , pp_total_raw )\n\ndef fix_missing_ffill(df2, col):\n    df2[col] = df2[col].fillna(method='ffill')\n    return df2[col]","cd2150b7":"msno.bar(df2,color='#924893', sort=\"ascending\", figsize=(10,5), fontsize=12)\nplt.show()","7af5ea41":"#using the foward ffill\ndf2['Sector(s)'] = fix_missing_ffill(df2, 'Sector(s)')\ndf2['Primary Essential Function'] = fix_missing_ffill(df2,'Primary Essential Function')","0b97262e":"df2['primary_function_max'] = df2['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\ndf2['primary_function_min'] = df2['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\ndf2['primary_function_min'] = df2['primary_function_min'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\ndf2.drop(\"Primary Essential Function\", axis=1, inplace=True)","bd935c3b":"df2.dtypes","f1ca21d7":"# Handling columns with missing values \ndf2.isna().sum()","899e963a":"df2=df2.dropna()","d95158ab":"df2.head()","ae32cd46":"def bar_p(df:pd.DataFrame, column:str,title:str):\n    plt.figure(figsize=(18, 9))\n    sns.countplot(y=column, data=df2, order=df[column].value_counts().head(10).index,color = \"#a265b8\")\n    plt.title(title,font=\"Tahoma\", size=20)\n    plt.show()\n    \nbar_p(df2,'Provider\/Company Name','Showing 10 providers')","5676972b":"# removing spaces and other charcters between words for each column\ndf2.columns = df2.columns.str.replace(' ','_')\ndf2.columns = df2.columns.str.replace('\/','_')\n\ndf2.columns.to_list()\n","587b640c":"# We rename the sector(s) column\ndf2.rename(columns={'Sector(s)': 'sector_s'}, inplace=True)","d82e29c5":"# checking for null values if there is any empty column\ncheck_null = df2.columns.isnull().any()\ncheck_null","89a48a6c":"df2.isna().sum()","4dada02c":"# Identifying duplicated rows\ndf2 = df2[df2.duplicated()]\nprint(\"Number of duplicate rows: \", df2.shape)\n","ce4fe068":"import glob\nimport os\nimport pandas as pd\n\npath = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'\nfile_type = 'csv'\nseperator=','\nfiles = glob.glob(path + \"\/*.csv\")# glob function to call diffrent files of csv\nUpdated_Df = []\n\nfor f in files:\n    data = pd.read_csv(f, index_col=None, sep=seperator, header=0) #for f in glob.glob(folder_name + \"\/*.\"+file_type)],ignore_index=True)\n    #generating a column from each csv file\n    district_id = f.split(\"\/\")[4].split(\".\")[0] #print (district_id) \n    data['district_id'] = district_id\n    Updated_Df.append(data)\n\ndata = pd.concat(Updated_Df)\n\ndata = data.reset_index(drop=True)\n\ndata.head()\n    ","7e33e675":"data.isna().sum()","54272f74":"data.dtypes","329c91b6":"msno.bar(data, color='#25c28b', sort=\"ascending\", figsize=(10,5), fontsize=12)\nplt.title(\"Number of non-null entries in engagement dataset\", size=20)\nplt.show()","061a1174":"plt.figure(figsize=(15,5))\n\nsns.histplot(data.groupby('district_id').time.nunique(), bins=30, color = '#b3a42f')\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.xlabel('Number of days', fontsize=20)\nplt.ylabel('Number of district', fontsize=20)\nplt.title('Districts with unique days of engagement ', fontsize = 20)","a511de20":"data.lp_id.head()","fcb2b470":"df.dropna(inplace=True)","63579253":"df = df.copy()\n","6316f94d":"df['pct_black\/hispanic'] = df['pct_black\/hispanic'].apply(lambda x: (x.replace('[', '')).split(','))\ndf['pct_free\/reduced'] = df['pct_free\/reduced'].apply(lambda x: (x.replace('[', '')).split(','))\ndf['pp_total_raw'] = df['pp_total_raw'].apply(lambda x: (x.replace('[', '')).split(','))\ndf.drop(columns=['county_connections_ratio'],inplace=True)\nfor i in ['pct_black\/hispanic','pct_free\/reduced','pp_total_raw']:\n    df[i] = df[i].apply(lambda x: (float(x[0])+float(x[1]))\/2)\ndf","912f045d":"data_clean = data.copy()\n\n# Replacing null values for float data types \ncols = ['lp_id','pct_access','engagement_index']\n\nfor i in cols:\n    data_clean[i]=data_clean[i].fillna(data_clean[i].median())\n    \n(data_clean.isnull().sum()).sum()","b1f6eb50":"data_clean.head()","ea0ff323":"# merging all datsets into one \ndata_clean['district_id'] = data_clean['district_id'].astype(int)\nm = pd.merge(data_clean, df, on=\"district_id\")\nm.head()","7b79e679":"df2 = df2.rename(columns={'LP_ID':'lp_id'})\ndf2['lp_id'] = df2['lp_id'].astype('float')","1f47e47c":"df_data = pd.merge(df2,m, on=\"lp_id\")\ndf_data.head()","ba0aa590":"df_data.describe()","5b807fc0":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import display, HTML, Javascript\nimport IPython.display as py_display\nimport plotly.express as px\n\n# lets set plotting functions \ndef plot_hist(df:pd.DataFrame, column: str, color: str) -> None:\n    plt.figure(figsize=(9,7))\n    sns.displot(data=df,x=column, color=color, kde=True, height=7, aspect=2)\n    plt.title(f'Distribution of {column}', size=20, fontweight='bold')\n    plt.show()\n    \ndef plot_dist(df:pd.DataFrame, column:str) -> None:\n    plt.figure(figsize=(9,7))\n    sns.displot(df).set_title(f'Distribution of {column}')\n    plt.show()\n\ndef plot_count(df:pd.DataFrame, column:str) -> None:\n    plt.figure(figsize=(12,7))\n    sns.counterplot(data=df, x=column)\n    plt.title(f'plot count of {column}', size=20, fontweight='bold')\n    plt.show()\n    \ndef plot_bar(df:pd.DataFrame, x_col:str, y_col:str, title: str, xlabel: str, ylabel: str) -> None:\n    plt.figure(figsize=(9,7))\n    sns.barplot(data=df, x=x_col, y=y_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.show()\n    \ndef plot_heatmap(f:pd.DataFrame, title: str, char=False) -> None:\n    plt.figure(figsize=(12,7))\n    sns.heatmap(title, size=18, fontweight='bold')\n    plt.show()\n    \ndef plot_box(df: pd.DataFrame, x_col: str, y_col: str, title: str) ->None:\n    plt.figure(figsize=(12,7))\n    sns.boxplot(data=df, x=x_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.show()\n    \ndef plot_box_multi(df:pd.DataFrame, x_col: str, y_col: str, title: str) -> None:\n    plt.figure(figsize=(12,7))\n    sns.boxplot(data=df, x=x_col,y=y_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.show()\n    \ndef plot_scatter(df:pd.DataFrame, x_col: str, y_col: str, title: str, hue: str, style: str) -> None:\n    plt.figure(figsize=(10,8))\n    sns.scatterplot(data=df, x=x_col, y=y_col, hue=hue, styles=style)\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.show()\n        \n    \nimport warnings    \n# Environment check\nwarnings.filterwarnings(\"ignore\")\n","58e4b294":"    \n#plot_count(df_data,\"pct_black\/hispanic\")\n","725f4996":"#number states in the diastrict\n#plot_count(df_data,\"state\")","a7918b75":"# Study effect of pandemic on online and distance learning for future relation\n#plot_bar(df_data,\"locale\",\"engagement_index\", ylabel=\"engement_index\", xlabel=\"locale\", title=f'Engagement with state coverage')","ccdc3124":"# Study effect of pandemic on online and distance learning for future relation\n#plot_bar(df_data,\"county_connections_ratio\",\"engagement_index\", ylabel=\"engement_index\", xlabel=\"county_connections_ratio\", title=f'Engagement with data connection ability')","cbe5f856":"The columns with missing values have to be cleaned and renaming column names is also import for easy integration of the records into other tools like MySQL","4b14981f":"Spliting added values fin each cell","f27d63cc":"**Steps to follow**","8300e73f":"According to what we observe data for district id gives a normalised graph thus no need of normaliszing this data","d54d6ebf":"**Sumary plan **","5658edd0":"Understandaing the structure of table2 ","4e77b628":"Education was perceived as most important field to change the world by Nelson mandela, but effectiveness of education policy has been questioned with unmeasurable impacts until the occurance of COVID-19 since education has now been anticipated as a cause of inequity \n\nAccess to online learning platforms with tools like LearnPlatform is a solution identified to reduce this gap. learning Platform uses evidence basis strategy that is adopted to all stakeholders involved to monitor feedback. This is anicipated to improve safety, equity and effeciveness  \n\nTask activities aim at uncovering trends from digital learning by analysing data from LearnPlatform. A number of policies ad activities will be numbered to close the digital gap ","7c148457":"### Description of features","746d800c":"1. Understanding the shape of data and structure (value counts, hitograms, shape, null records)\n2. Perform Data cleaning \n3. Exploration of cleaned data for differen factors that ipact digital learning \n4. Preprocessing \n5. Feature extraction and engineering (scaling, transformation)\n6. Model building and training\n7. Model evaluations\n8. Prediction of results \n","897ef737":"## Data cleaning ","40ef6fee":"Study effect of pandemic on online and distance learning for future relation","34fee0ca":"### Description of features ","09279220":"### Reading data","0d80c9dc":"The district_id is identified as the only numeric data sice others have the object data type","49ba85a9":"### Setting up environment for data nalyis","b6f3d4da":"1. district_id expalins the unique identfier of the school district\n2. state explains the state where the school district is located\n3. locale includes the U.S territory types of areas: City, Town, Subtown,and Rural\n4. pct_black\/hispanic explains the percentage os students in districts of Black or Hispanic\n5. pct_free\/reduced explains percentage of students who are eligigible to acquire free or reduced price lunch\n6. country_connections_ratio explains the residential fixed high speed connection of data over 200kbps\n7. pp_total_raw explains the rate of pupil per total expenditure (sum of local and federal expenditure data)\n    ","43e57a9e":"Filling the missing values can be done using two functions ffill (filing with a value at front) and bfill (filling with a value behind)\n\nThis is done by considering the mode if data is not skewed or using the median if the data is skewed","dfb4c89e":"### Meging data","51106a0c":"## Exploration Data Analysis","5600bcc7":"## Introduction","c03e8233":"It indicates high inovlment with distance learning from the rural areas","0c2822fc":"# **Analyzing digital learning**","cef7e304":"## Challenge Activities ","8c0de902":"## 1. Understanding the shape of data and structure","59346b03":"1. LP ID explains the unique identifier of the product\n2. URL explains the web link to the specific product\n3. Product Name explains the name of a gven product\n4. Provider\/Company Name explains the name of company providing the product\n5. Sector(s) explains the sector of education where the product is being used\n5. Primary Essential Function explains the basic fucnction of the product. The LC is for Learning & Curriculum and CM is for Classroom Management, and SDO is for School & District Operations.Each of these three has other lables identifying the products)\n"}}