{"cell_type":{"ae7a73a2":"code","54ddf1c0":"code","d8187ad6":"code","b3420d41":"code","74b16718":"code","5e58a1a2":"code","d4d7ef92":"code","0ef151af":"code","8c32af83":"code","98e11f00":"code","8022c3e7":"code","1b89beda":"code","40f3e80f":"code","e21155b6":"markdown","e680f788":"markdown"},"source":{"ae7a73a2":"import os\nimport sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\n\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport timm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader,random_split","54ddf1c0":"def dataframe(df, istrain=True):\n    if istrain:\n        mode = 'train'\n    else:\n        mode = 'test'\n    df['filepath'] = df.id.apply(lambda x: '..\/input\/seti-breakthrough-listen\/'+ f'{mode}\/'+str(x[0])+f'\/{x}.npy')\n    return df\ntest_df = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\ntest_df = dataframe(test_df, istrain=False)\ntest_df['target'] = 0\ntrain_df = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntrain_df = dataframe(train_df)\ntrain_df.head(2)","d8187ad6":"class setiDataset(Dataset):\n    def __init__(self, df, transform = None): \n        self.df = df\n        self.transform = transform\n    \n    def fileinfo(self, idx):\n        return self.df.filepath.iloc[idx], self.df.target.iloc[idx]\n    \n    def loadfile(self, filepath):\n        image = np.load(filepath).astype('float32')\n        return image\n    \n    def __getitem__(self, idx):\n        filepath, target = self.fileinfo(idx)\n        image = self.loadfile(filepath)\n        return  torch.tensor(image, dtype=torch.float), torch.tensor(target, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.df)","b3420d41":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding = 1 if kernel_size == 3 else 0, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.vals = nn.Parameter(torch.zeros(out_channels)) \n        nn.init.kaiming_normal_(self.conv.weight, mode='fan_in', nonlinearity='leaky_relu')\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x += self.vals.view(1, self.bn.num_features, 1, 1).expand_as(x)\n        x = x * torch.tanh(F.softplus(x))\n        return x\n    \nclass ResBlock(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int):\n        super().__init__()\n        self.conv1 = ConvBlock(in_channels, out_channels, 3)\n        self.conv2 = ConvBlock(out_channels, out_channels, 3)\n\n    def forward(self, x):\n        initial = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = x + initial\n        x = x * torch.tanh(F.softplus(x))\n        return x","74b16718":"class CustomModel(nn.Module):\n    def __init__(self, in_channels = 6, out_channels = 20, res_level = 2, pretrained=True):\n        super(CustomModel,self).__init__()\n        # residual layer\n        self.conv_input = ConvBlock(in_channels, out_channels, 3)\n        self.res_layer = nn.Sequential(\n            *[ResBlock(out_channels, out_channels) for _ in range(res_level)]\n        )\n        self.conv_output = ConvBlock(out_channels, 2, 1)\n        \n        # prob layer\n        self.prob_fc_1 = nn.Linear(2*273*256, 256)\n        self.prob_fc_2 = nn.Linear(256, 1)\n        \n        self.model = timm.create_model('efficientnet_b0', pretrained=pretrained, in_chans=2, num_classes=1)\n\n    def extract(self, x):\n        x = self.conv_input(x)\n        x = self.res_layer(x)\n        x = self.conv_output(x)\n        return x\n    \n    def forward(self, x):\n        # residual layer\n        x = self.extract(x)\n        \n        # prob layer\n        prob = self.prob_fc_2(self.prob_fc_1(torch.flatten(x, start_dim=1)))\n        prob = torch.sigmoid(prob)\n        \n        x = self.model(x)\n        return prob, x","5e58a1a2":"def train(data_loader, model, optimizer, device):\n    model.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        images, targets = data\n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        def closure():\n            optimizer.zero_grad()\n            prob, output = model(images)\n            loss1 = nn.BCEWithLogitsLoss(reduction='none')(output, targets.view(-1,1))\n            loss2 = nn.BCEWithLogitsLoss(reduction='none')(-output, targets.view(-1,1))\n            loss = (1-prob\/2)*loss1 + (prob\/2)*loss2\n            loss = loss.mean()\n            loss.backward()\n            return loss\n        optimizer.step(closure)","d4d7ef92":"def evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    validate_losses = 0\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            prob, output = model(images)\n            loss = nn.BCEWithLogitsLoss()(output, targets.view(-1, 1))\n            validate_losses += loss.item()\n\n\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n    return final_outputs, final_targets, validate_losses\/len(data_loader)","0ef151af":"def submission(data_loader, model, device):\n    model.eval()\n    \n    final_outputs = []\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            \n            prob, output = model(images)\n\n            output = output.detach().cpu().numpy().tolist()\n            final_outputs.extend(output)\n    return final_outputs","8c32af83":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device('cpu')\n    print(\"GPU not available, CPU used\")","98e11f00":"cmodel = CustomModel()\ncmodel.to(device)","8022c3e7":"Batch_Size = 16\ninit_dataset = setiDataset(train_df)\nlengths = [int(len(init_dataset)*0.8), int(len(init_dataset)*0.2)]\n\ntrain_dataset, valid_dataset = random_split(init_dataset, lengths)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size, shuffle=False)\noptimizer=  torch.optim.Adam(cmodel.parameters(), lr=3e-4, eps=1e-5)\n\nfor epoch in range(10):\n    print(epoch)\n    train(train_loader, cmodel, optimizer, device)\n    valid_pred, target, valid_loss = evaluate(valid_loader, cmodel, device)\n    roc_auc = metrics.roc_auc_score(target, valid_pred)\n    print(f\"Epoch={epoch}, Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")","1b89beda":"valid_pred, target, valid_loss = evaluate(valid_loader, cmodel, device)\nroc_auc = metrics.roc_auc_score(target, valid_pred)\nprint(f\"Epoch={epoch}, Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")","40f3e80f":"def sigmoid(x):\n    return 1\/(1+np.exp(-x))\n\ntest_dataset = setiDataset(test_df)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False)\npred = submission(test_loader, cmodel, device)\nsub = test_df[['id']].copy()\nsub['target'] = sigmoid(np.array(pred).flatten())\nsub.to_csv('submission.csv', index=None)","e21155b6":"I thought it would be nice <br>\nif there was an probability to be sure of their prediction.","e680f788":"too slow...\n\nI just want to make below, but too slow.\n\noriginal loss + prob\/2 * (opposite loss - orignal loss)"}}