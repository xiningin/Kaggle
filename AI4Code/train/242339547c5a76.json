{"cell_type":{"a721db4b":"code","a32b5426":"code","edf17b47":"code","3fc3aa6d":"code","d088177d":"code","374febc4":"code","9285f80a":"code","8072436a":"code","1fe08e0c":"code","a309aba9":"code","12a0ba75":"code","bd13aff5":"code","a01521fd":"code","078b0bb3":"code","7619ec8c":"code","f6d72f2c":"code","c2bbe8b1":"code","f29244ab":"code","b7c4610e":"code","b064d59d":"code","186094c7":"markdown","d881ec16":"markdown","6dfea431":"markdown","03a23df5":"markdown","a71d69eb":"markdown","75a8eefd":"markdown","749634ff":"markdown","c6c84037":"markdown","d8f3fdd5":"markdown","6534e037":"markdown","3aacffac":"markdown","650be056":"markdown"},"source":{"a721db4b":"import numpy as np\nimport pandas as pd\n\nN_FEATURES = 22\n# taken from http:\/\/simaaron.github.io\/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks\/\nTHRESHOLD = 73 ","a32b5426":"train_df = pd.read_csv(\"\/kaggle\/input\/train.zip\")\n# to reduce memory consumption\ntrain_df[train_df.columns[1:]] = train_df[train_df.columns[1:]].astype(np.float32)\ntrain_df.shape","edf17b47":"good_ids = set(train_df.loc[train_df['Ref'].notna(), 'Id'])\ntrain_df = train_df[train_df['Id'].isin(good_ids)]\ntrain_df.shape","3fc3aa6d":"train_df.reset_index(drop=True, inplace=True)\ntrain_df.fillna(0.0, inplace=True)\ntrain_df.head()","d088177d":"train_df.shape","374febc4":"train_df = train_df[train_df['Expected'] < THRESHOLD]\ntrain_df.shape","9285f80a":"train_groups = train_df.groupby(\"Id\")\ntrain_size = len(train_groups)","8072436a":"MAX_SEQ_LEN = train_groups.size().max()\nMAX_SEQ_LEN","1fe08e0c":"X_train = np.zeros((train_size, MAX_SEQ_LEN, N_FEATURES), dtype=np.float32)\ny_train = np.zeros(train_size, dtype=np.float32)\n\ni = 0\nfor _, group in train_groups:\n    X = group.values\n    seq_len = X.shape[0]\n    X_train[i,:seq_len,:] = X[:,1:23]\n    y_train[i] = X[0,23]\n    i += 1\n    del X\n    \ndel train_groups\nX_train.shape, y_train.shape","a309aba9":"test_df = pd.read_csv(\"\/kaggle\/input\/test.zip\")\ntest_df[test_df.columns[1:]] = test_df[test_df.columns[1:]].astype(np.float32)\ntest_ids = test_df['Id'].unique()\n\n# Convert all NaNs to zero\ntest_df = test_df.reset_index(drop=True)\ntest_df = test_df.fillna(0.0)","12a0ba75":"test_groups = test_df.groupby(\"Id\")\ntest_size = len(test_groups)\n\nX_test = np.zeros((test_size, MAX_SEQ_LEN, N_FEATURES), dtype=np.float32)\n\ni = 0\nfor _, group in test_groups:\n    X = group.values\n    seq_len = X.shape[0]\n    X_test[i,:seq_len,:] = X[:,1:23]\n    i += 1\n    del X\n    \ndel test_groups\nX_test.shape","bd13aff5":"from keras.layers import (\n    Input,\n    Dense,\n    LSTM,\n    GlobalAveragePooling1D,\n    AveragePooling1D,\n    TimeDistributed,\n    Flatten,\n    Bidirectional,\n    Dropout,\n    Masking,\n    Layer,\n    BatchNormalization\n)\nfrom keras.models import Model\nfrom keras.optimizers import Adam,Nadam","a01521fd":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_delta=0.01)","078b0bb3":"BATCH_SIZE = 1024\nN_EPOCHS = 30","7619ec8c":"class NonMasking(Layer):   \n    def __init__(self, **kwargs):   \n        self.supports_masking = True  \n        super(NonMasking, self).__init__(**kwargs)   \n    def build(self, input_shape):   \n        input_shape = input_shape   \n    def compute_mask(self, input, input_mask=None):   \n        # do not pass the mask to the next layers   \n        return None   \n    def call(self, x, mask=None):   \n        return x   \n    def get_output_shape_for(self, input_shape):   \n        return input_shape ","f6d72f2c":"def get_model_deep(shape=(MAX_SEQ_LEN, N_FEATURES)):\n    inp = Input(shape)\n    x = Dense(16)(inp)\n    x = BatchNormalization()(x)\n    x = Masking(mask_value=0.)(x)\n    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n    x = BatchNormalization()(x)\n    x = TimeDistributed(Dense(64))(x)\n    x = BatchNormalization()(x)\n    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n    x = BatchNormalization()(x)\n    x = TimeDistributed(Dense(1))(x)\n    x = BatchNormalization()(x)\n    x = NonMasking()(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1)(x)\n\n    model = Model(inp, x)\n    return model","c2bbe8b1":"model = get_model_deep()\nmodel.compile(optimizer=Nadam(lr=0.001), loss='mae')\nmodel.summary()","f29244ab":"history = model.fit(X_train, y_train, \n            batch_size=BATCH_SIZE, epochs=N_EPOCHS, \n            validation_split=0.2, callbacks=[early_stopping, reduce_lr])","b7c4610e":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\ndel history","b064d59d":"y_pred = model.predict(X_test, batch_size=BATCH_SIZE)\nsubmission = pd.DataFrame({'Id': test_ids, 'Expected': y_pred.reshape(-1)})\nsubmission.to_csv('submission.csv', index=False)","186094c7":"Forked from https:\/\/www.kaggle.com\/andkul\/deep-lstm-to-predict-rainfall with some changes to the model, in particular I added the masking of paddded time steps and BatchNormalization between each layer (except the first).\nThe optimizer here is [Nadam](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers\/Nadam) (Adam + Nesterov momentum) rather than Adam.","d881ec16":"## Architecture of the model","6dfea431":"Define and exclude outliers from training set","03a23df5":"## Training set","a71d69eb":"Replace NaN values with zeros","75a8eefd":"### Grouping and padding into sequences","749634ff":"Remove ids with NaNs in `Ref` column for each observation (obeservations, where we have no data from radar)","c6c84037":"# Data preprocessing","d8f3fdd5":"Before creating the model we define a subclass of the class Layer provided by Keras. This because all layers in or model support [Masking](https:\/\/www.tensorflow.org\/guide\/keras\/masking_and_padding) except Flatten. Thus before the Flatten layer we need to remove the mask.","6534e037":"# Masked LSTM to predict rainfall","3aacffac":"# Models","650be056":"## Test set"}}