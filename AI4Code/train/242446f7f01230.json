{"cell_type":{"42391a93":"code","c03a0729":"code","0efb54dc":"code","90e4fa9f":"code","aa60f7dd":"code","bb8bdc86":"code","5fa7d5c5":"code","d8a99986":"code","3786381a":"code","87c2b450":"code","55ff2988":"code","e78ad778":"code","315cb5b5":"code","b19db663":"code","8640f0d8":"markdown","89c87b94":"markdown","1b911cf0":"markdown","5ee026ed":"markdown","d46be123":"markdown","1047a3df":"markdown","565bbf14":"markdown","da4a003e":"markdown","4f8c18a6":"markdown","b3a9273c":"markdown","2ab18955":"markdown","8d48668a":"markdown","04a7e0d6":"markdown","053e06d3":"markdown","764d0581":"markdown","3e463f52":"markdown","0559fd98":"markdown","52a3572c":"markdown"},"source":{"42391a93":"import os, time\nimport numpy as np\nimport torch\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics as mtr\n\nimport torch\nfrom torchvision.transforms import ToTensor\nfrom torchvision.models import resnet18","c03a0729":"class chest_xray_data(object):\n    def __init__(self, root, split, transforms=None):\n        self.root = root\n        self.transforms = transforms\n        self.data_dir = os.path.join(root, split)\n        self.imgs = [(i, 'NORMAL') for i in list(sorted(os.listdir(os.path.join(self.data_dir, 'NORMAL'))))]\n        self.imgs += [(i, 'PNEUMONIA') for i  in list(sorted(os.listdir(os.path.join(self.data_dir, 'PNEUMONIA'))))]\n    \n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.data_dir, self.imgs[idx][1], self.imgs[idx][0])\n        img = Image.open(img_path).convert('RGB').resize((448, 448))\n        img = np.moveaxis(np.array(img)\/255.0, -1, 0)\n        label = 0 if self.imgs[idx][1] == 'NORMAL' else 1\n        if self.transforms is not None:\n            img, label = self.transforms(img, label)\n        return img, label\n","0efb54dc":"root = \"..\/input\/chest-xray-pneumonia\/chest_xray\"\ntrain_data = chest_xray_data(root, 'train')\ntest_data = chest_xray_data(root, 'test')","90e4fa9f":"train_dataloader = torch.utils.data.DataLoader(train_data, 128, True)\ntest_dataloader = torch.utils.data.DataLoader(test_data, 128, True)","aa60f7dd":"fig, ax = plt.subplots(ncols=4, figsize=(16, 4))\nfor i in train_dataloader:\n    for j in range(4):\n        img = i[0][j]\n        label = i[1][j]\n        ax[j].imshow(np.moveaxis(img.numpy(), 0, -1))\n        ax[j].set_title('Normal' if label == 0 else 'Pneumonia')\n    break","bb8bdc86":"def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n    \n        pred = model(X.float())\n        loss = loss_fn(pred, y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % int(size\/10) == 0:\n            loss, current = loss.item(), batch\n            print(f\"loss: {loss:>7f}  [{current:>2d}\/{size:>2d}]\")","5fa7d5c5":"def test(dataloader, model):\n    size = len(dataloader.dataset)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X.float())\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss \/= size\n    correct \/= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss:{test_loss:>8f} \\n\")\n    return test_loss","d8a99986":"model = resnet18(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\nin_features = model.fc.in_features\nmodel.fc = torch.nn.Sequential(\n    torch.nn.Linear(in_features, 128),\n    torch.nn.BatchNorm1d(128),\n    torch.nn.ReLU(),\n    torch.nn.Linear(128, 32),\n    torch.nn.BatchNorm1d(32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32, 2),\n    torch.nn.Sigmoid()\n)","3786381a":"params = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=1e-3, momentum=0.7, weight_decay=0.0005)\nloss_fn = torch.nn.CrossEntropyLoss()\ndevice = 'cuda' if torch.cuda.is_available() else  'cpu'\nnum_epochs = 20\nprint(f\"Model Is Running On {device}\")","87c2b450":"start_time = time.time()\nbest_loss_score = test(test_dataloader, model.to(device))\nend_time = time.time()\nprint(f\"Elapsed TIme :=> {np.round(end_time - start_time,3)} sec\")","55ff2988":"best_model = model.state_dict()\nfor i in range(num_epochs):\n    print(f\"Epoch {i+1}\\n-------------------------------\")\n    start_time = time.time()\n    train(train_dataloader, model.to(device), loss_fn, optimizer)\n    test_loss = test(test_dataloader, model.to(device))\n    if test_loss < best_loss_score:\n        best_loss_score = test_loss\n        best_model = model.state_dict()\n        print(\"Best performing model captured & saved\")\n    end_time = time.time()\n    print(f\"Epoch Execution Time :=> {np.round(end_time - start_time, 3)} sec\")\n    print('---------------------------------------------')","e78ad778":"pred = list()\ntrue = list()\nwith torch.no_grad():\n  model.to(device)\n  for X, y in test_dataloader:\n    true.append(y)\n    y_pred = model(X.float().to(device))\n    pred.append(y_pred)","315cb5b5":"pred = np.argmax(np.array([tuple(j) for i in pred for j in i.to('cpu').numpy()]),axis=1)\ntrue = np.array([j for i in true for j in i.numpy()])","b19db663":"conf = mtr.confusion_matrix(true, pred)\nprint(f'Precision Score : {mtr.precision_score(true, pred)*100:3f}')\nprint(f'Recall Score : {mtr.recall_score(true, pred)*100:3f}')\nfig,ax = plt.subplots(figsize=(6,6))\nfig = sns.heatmap(conf, annot=True, fmt='.4g', xticklabels=['Normal', 'Pneumonia'],\n            yticklabels=['Normal', 'Pneumonia'], ax=ax, cmap='Blues')","8640f0d8":"Under construction, please check again later!","89c87b94":"Now we can use our custom class to define the data, remember that we just defining our dataset,and it will not be loaded into the memory until it has to feed into the model.","1b911cf0":"Now we need to define our loss function and optimizer, the choice is loss function is obvious as we are using binary classes. For optimizer I have chossen to use SGD you can try something else.","5ee026ed":"PyTorch dataloader allows us to batch the data into useful chunks  and allow shuffle the order in which data called, but the data is still not loaded into the memory at this point.","d46be123":"Now unlike Tensorflow-Keras,the PyTorch will not automaticaly use GPU if available we need to explicity define what we want to send into GPU for computation, by default it will use CPU unless we send the data\/model to GPU for execution.\n\nSo everytime you see something like some_tensor.to(device) or model.to(device) it means, we are pushing the model\/tensor into GPU for computation.\n\nYou cannot perform computation with one component in GPU and one in CPU, both must be in same locations.","1047a3df":"We define similar function for testing as well.","565bbf14":"Let Visualize some of our images to get an idea of what  we are dealing with.","da4a003e":"Now here we download the ResNet18 pretrained model from PyTorch model zoo, the model contains  18 layers as per the name, and is trained on ImageNet dataset.\n\nThe code \"param.requires_grad = False\" frezzes the layers and blocks and gradient updates on them.\nWe also need to replace the lasy layer of our model with a new sequence as we only have 2 classes unlike imagenet's 1000.\n\nWe need define a sequence of layers because the 2nd last layer of our model contains around 512 neurons and if directly merge that with  a 2 neuron, we  will bottelneck a lot of useful information, therefore we need to steadly bring down the count from 512 neurons to 2.","4f8c18a6":"<h1>Pneumonia Chest X-Ray Using Pytorch<\/h1>","b3a9273c":"Recall rate is preety good, but precision could have been better, we can try to balance the classes and try again.\n\nWe can also use different backend for our model, for example ResNet54 or VGG etc. to further improve the performance.","2ab18955":"<h1>Using Transfer Learning to fine-tune a pretrained model.<\/h1>","8d48668a":"The idea behind implementing your own custom class for data streaming is to abstract the details of data pipeline seperate to model training loop, we can perform any transformation we need to perform on our data before feeding into the model, and PyTorch will take care batching, shuffling and streaming this data to  our model for training.\nThere are basic functions we must implement in our dataset class for it be consumed by PyTorch.\n1. __init__(): In the constructor function we need to identify the data source and identify data points that need to fetched, this can be done by loading the file names of the images\/audio etc into a list.\n2. __getitem__(): This functions is called with a index value and must return a training and label data for that index.\n3. __len__(): the function must return the length of the dataset.","04a7e0d6":"<h1>Implementing a Custom training loop<\/h1>","053e06d3":"Now the good thing about writing your own training loops is that you have a high degree of control over each step, for example you can experiment with different optimzers over epochs, for example begin with SGD and then swtich to ADA etc.","764d0581":"What you will read in this notebook.\n1. How to write custome class to create PyTroch Datasets and Dataloaders to stream data into the model.\n2. How to use transfer learning using a pretrained model.\n3. Implement a basic training and testing loop.\n4. Run basic metric evaluation to determine business value of the model.","3e463f52":"<h1>Converting Model Inference into Business Logic<\/h1>","0559fd98":"<h1>Custom Dataset To Stream Data<\/h1>","52a3572c":"Here we define our training data loop, which loads all the batch of data in our dataset and trains the model over it each time  its called and performs backprop after each batch."}}