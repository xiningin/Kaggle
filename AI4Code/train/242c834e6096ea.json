{"cell_type":{"ff85adeb":"code","a25dacb0":"code","083b6564":"code","c8cbb9b0":"code","b93dc170":"code","1487dd50":"code","1ddf7364":"code","6cd0a750":"code","338362b1":"code","8d293c37":"code","71118ed7":"code","c1db4703":"code","0318be36":"code","0ea659d2":"code","43b688d6":"code","a6c4db92":"code","d90412ba":"code","2ad47248":"code","fe71bbac":"code","d64a447f":"code","6d98a605":"code","2c263587":"code","fbab559f":"code","b6bd845b":"code","af42ceb0":"code","3df04494":"markdown"},"source":{"ff85adeb":"#Classic libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport collections\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\n\n#Pytorch\nimport torch.nn as nn\nimport torch\nimport torchvision\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, ConcatDataset\nfrom torchvision import transforms\n\n#Augumentation\nimport albumentations\nimport albumentations.pytorch\n\n\n#Extra\nimport cv2\nfrom tqdm import tqdm\nimport os\n\nimport glob\nfrom PIL import Image\nimport random as random","a25dacb0":"official = pd.read_csv(\"..\/input\/polytech-nice-data-science-course-2021\/polytech\/class_names.csv\")\nofficial","083b6564":"convert = transforms.Compose([transforms.Resize((256,256)), \n                              transforms.CenterCrop(224),\n                              transforms.ToTensor()])\n\ndataset = ImageFolder('..\/input\/polytech-nice-data-science-course-2021\/polytech\/train', transform = convert)\n\n################################ Creation Validation set and Training set\nindex_train, index_val = train_test_split(np.arange(len(dataset)), train_size=0.85, random_state=42, shuffle=True)\n\ntrain_subset = torch.utils.data.Subset(dataset,index_train)\nval_subset = torch.utils.data.Subset(dataset,index_val)\n#############################################################\nprint(\"Number of observations for the train set: \", len(train_subset))\nprint(\"Number of observations for the validation set: \", len(val_subset))\nprint(\"Number of total observations: \", len(dataset))","c8cbb9b0":"def visualize_batch(batch, classes):\n    \n    # initialize a figure\n    figure(figsize=(10, 8), dpi=80)\n    \n    # loop over the batch size\n    for i in range(0, 8):\n        \n        # create a subplot\n        ax = plt.subplot(2, 4, i + 1)\n        \n        # grab the image\n        image = batch[0][i]\n        image = image.permute(1, 2, 0)\n        \n        # grab the label \n        idx = batch[1][i].item()\n        label = int(classes[idx])\n        #print(idx,label)\n        \n        # show the image along with the label\n        name = official.loc[official['id_species'] == label].iloc[0][1]\n        plt.imshow(image)\n        plt.title(name)\n        plt.axis(\"off\")\n        \n    # show the plot\n    plt.tight_layout()\n    plt.show()\n\n    \n# Visualization\ntrainDataLoader = DataLoader(train_subset, batch_size=8, shuffle=True, num_workers=2)\n\ntrainBatch = next(iter(trainDataLoader))\nvisualize_batch(trainBatch, dataset.classes)","b93dc170":"#Visualization\nfigure(figsize=(10, 8), dpi=80)\n\nvalues = dict(Counter(list( dataset.targets[i] for i in index_train )))\nkeys = values.keys()\nvalues = values.values()\n\nplt.title(\"Distributions classes\", fontsize=20, color = 'black')\nplt.bar(keys, values)","1487dd50":"np.random.seed(42)\n################################ Over-Under Sampling\nimport statistics\nmean = 4 * int(statistics.mean(values))\n\ntot = []\nfor k in tqdm(keys):\n    actual_indeces = index_train[list( dataset.targets[i] == k for i in index_train )]\n    dimension = actual_indeces.shape[0]\n\n    if dimension > mean:\n        removing = np.random.choice(np.arange(dimension), dimension - mean, replace=False)\n        new_indeces = np.delete(actual_indeces, removing)       \n        tot.append(new_indeces)\n    else:\n        adding = np.random.choice(actual_indeces, mean - dimension, replace=True)\n        new_indeces = np.concatenate((actual_indeces,adding))\n        tot.append(new_indeces)\n\nnew_index_train = np.hstack(tot)\nnew_train_subset = torch.utils.data.Subset(dataset,new_index_train)","1ddf7364":"figure(figsize=(10, 8), dpi=80)\n\nvalues = dict(Counter(list( dataset.targets[i] for i in new_index_train)))\nkeys = values.keys()\nvalues = values.values()\n\nplt.title(\"Distributions classes\", fontsize=20, color = 'black')\nplt.bar(keys, values)","6cd0a750":"################## Ensemble Learning Methods\n\n################################ Creation Different sets for both models\nfrom sklearn.model_selection import train_test_split\n\n# Creation subsets\nindex_train_1, index_train_2 = train_test_split(new_index_train, train_size=0.5, random_state=42, shuffle=True)\n\ntrain_subset_1 = torch.utils.data.Subset(dataset,index_train_1)\ntrain_subset_2 = torch.utils.data.Subset(dataset,index_train_2)\n#############################################################\nprint(\"Number of observations for the train set for model 1: \", len(train_subset_1))\nprint(\"Number of observations for the train set for model 2: \", len(train_subset_2))\nprint(\"Number of total observations in the train set: \", len(new_index_train))\nprint(\"Number of observations for the validation set: \", len(val_subset))","338362b1":"### Set the batch size\n#BATCH_SIZE = 64\n\n#################Normalization\n\n#def get_mean_and_std(loader):\n    \n    #mean = 0\n    #std = 0\n    #total_images_count = 0\n    \n    #for images,_ in tqdm(loader):\n        #image_count_in_a_batch = images.size(0)\n        #images = images.view(image_count_in_a_batch,images.size(1), -1)\n        \n        #mean += images.mean(2).sum(0)\n        #std += images.std(2).sum(0)\n        #total_images_count += image_count_in_a_batch\n\n    #mean \/= total_images_count\n    #std \/= total_images_count\n    \n    #return mean, std \n\n\n#trainDataLoader = DataLoader(new_train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n#mean, std = get_mean_and_std(trainDataLoader)\n#print(mean, std)\n\n\n\n#convert = transforms.Compose([transforms.Resize((256,256)), \n                              #transforms.CenterCrop(224),\n                              #transforms.ToTensor(),\n                              #transforms.Normalize(mean=mean, std=std)])\n\n# Dataset normalized\n#dataset = ImageFolder('..\/input\/polytech-nice-data-science-course-2021\/polytech\/train',transform = convert)\n\n## Splitting in the same two datasets\n#train_subset = torch.utils.data.Subset(dataset,new_index_train)\n#val_subset = torch.utils.data.Subset(dataset,index_val)\n\n#print(\"Number of observations for the train set: \", len(train_subset))\n#print(\"Number of observations for the validation set: \", len(val_subset))\n#print(\"Number of total observations: \", len(dataset))","8d293c37":"##### Faster with the Normalization already computed (plausible)\nBATCH_SIZE = 128\nconvert = transforms.Compose([transforms.Resize((256,256)), \n                              transforms.CenterCrop(224),\n                              transforms.ToTensor(),\n                              transforms.Normalize(mean=[0.4477, 0.4701, 0.3317], std=[0.2072, 0.1977, 0.1941])]) \n\n# Dataset normalized\ndataset = ImageFolder('..\/input\/polytech-nice-data-science-course-2021\/polytech\/train', transform = convert)\n\n## Splitting \ntrain_subset_1 = torch.utils.data.Subset(dataset,index_train_1)\ntrain_subset_2 = torch.utils.data.Subset(dataset,index_train_2)\nval_subset = torch.utils.data.Subset(dataset,index_val)\n\nprint(\"Number of observations for the training set for model 1: \", len(train_subset_1))\nprint(\"Number of observations for the training set for model 2: \", len(train_subset_2))\nprint(\"Number of total observations in the train set: \", len(new_index_train))\nprint(\"Number of observations for the validation set: \", len(val_subset))","71118ed7":"# Visualization trainining set model 1\ntrainDataLoader = DataLoader(train_subset_1, batch_size=8, shuffle=True, num_workers=2)\n\ntrainBatch = next(iter(trainDataLoader))\nvisualize_batch(trainBatch, dataset.classes)","c1db4703":"# Visualization trainining set model 2\ntrainDataLoader = DataLoader(train_subset_2, batch_size=8, shuffle=True, num_workers=2)\n\ntrainBatch = next(iter(trainDataLoader))\nvisualize_batch(trainBatch, dataset.classes)","0318be36":"############################## AUGMENTATION\nclass AlbumentationsDataset(torch.utils.data.Dataset):\n    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n    def __init__(self, file_paths, transform=None):\n        self.file_paths = file_paths\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        label = self.file_paths[idx][1]\n        file_path = self.file_paths[idx][0]\n        \n        # Image to numpy\n        image = file_path.permute(1, 2, 0).numpy()\n\n        if self.transform:\n            augmented = self.transform(image=image)[\"image\"]     \n            return augmented,label\n    \n# Same transform with torchvision_transform\nalbumentations_transform_1 = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.VerticalFlip(p=0.5),\n    albumentations.RandomBrightnessContrast(p=0.5),\n    albumentations.RandomRotate90(p=0.5),\n    albumentations.pytorch.transforms.ToTensorV2()\n])\n\n\nalbumentations_transform_2 = albumentations.Compose([\n    albumentations.RandomCrop(height= 224, width = 224, p=0.5),\n    albumentations.Flip(p=0.5),\n    albumentations.OneOf([\n                    albumentations.MotionBlur(p=.3),\n                    albumentations.MedianBlur(blur_limit=3, p=0.2),\n                    albumentations.Blur(blur_limit=3, p=0.2)], p=1),\n    albumentations.Transpose(p=0.5), \n    albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.5),\n    albumentations.GaussNoise(var_limit=(0, 1), p=0.5),\n    albumentations.pytorch.transforms.ToTensorV2()\n])\n\n\ndata_plus_augmented_1 = AlbumentationsDataset(train_subset_1,transform=albumentations_transform_1)\ndata_plus_augmented_2 = AlbumentationsDataset(train_subset_2,transform=albumentations_transform_2)\nprint(len(data_plus_augmented_1))\nprint(len(data_plus_augmented_2))","0ea659d2":"#### Check if the augmentations works \nacca = data_plus_augmented_1\n\nplt.figure()\nplt.imshow(next(iter(train_subset_1))[0].permute(1, 2, 0))\n\nplt.figure()\nplt.imshow(acca[0][0].permute(1, 2, 0))","43b688d6":"###### Common memebers\nval_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\ncriterion = nn.CrossEntropyLoss()","a6c4db92":"\"\"\"\n##############################################   MODEL 1 \nnet_1 = torchvision.models.resnet50(pretrained=True)  \n\n## torchvision models are meant to be used on imagenet (1000 classes)\n## we need to modify the last layer\nlast = net_1.fc.in_features\nnet_1.fc = nn.Linear(last,153)\n \n## Move model to the GPU\nnet_1 = net_1.cuda()\n\n\noptimizer = torch.optim.Adam(net_1.parameters(), lr=0.001) #torch.optim.SGD(net_1.parameters(), lr=0.01, momentum=0.9)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)\n\n\ntrain_loader = DataLoader(data_plus_augmented_1, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\"\"\"","d90412ba":"\"\"\"\n## NUMBER OF EPOCHS TO TRAIN\nN_EPOCHS = 8\n\nepoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []\nbest_acc = 0\n\nfor e in range(N_EPOCHS):\n    \n    print(\"EPOCH:\",e)\n  \n    ### TRAINING LOOP\n    running_loss = 0\n    running_accuracy = 0\n  \n    ## Put the network in training mode\n    net_1.train()\n  \n    for i, batch in enumerate(tqdm(train_loader)):\n    \n        # Get a batch from the dataloader\n        x = batch[0]\n        labels = batch[1]\n        \n    \n        # move the batch to GPU\n        x = x.cuda()\n        labels = labels.cuda()\n\n        # Compute the network output\n        y = net_1(x)\n    \n        # Compute the loss\n        loss = criterion(y, labels)\n    \n        # Reset the gradients\n        optimizer.zero_grad()\n    \n        # Compute the gradients\n        loss.backward()\n    \n        # Apply one step of the descent algorithm to update the weights\n        optimizer.step()\n    \n        ## Compute some statistics\n        with torch.no_grad():\n            running_loss += loss.item()            \n            running_accuracy += (y.max(1)[1] == labels).sum().item()\n    \n    print(\"Training accuracy:\", running_accuracy\/float(len(data_plus_augmented_1)),\n          \"Training loss:\", running_loss\/float(len(data_plus_augmented_1)))\n    scheduler.step()\n  \n    epoch_loss.append(running_loss\/len(data_plus_augmented_1))\n    epoch_acc.append(running_accuracy\/len(data_plus_augmented_1))\n  \n    ### VALIDATION LOOP\n    ## Put the network in validation mode\n    net_1.eval()\n  \n    running_val_loss = 0\n    running_val_accuracy = 0\n  \n    for i, batch in enumerate(tqdm(val_loader)):\n    \n        with torch.no_grad():\n            # Get a batch from the dataloader\n            x = batch[0]\n            labels = batch[1]\n\n            # move the batch to GPU\n            x = x.cuda()\n            labels = labels.cuda()\n\n            # Compute the network output\n            y = net_1(x)\n      \n            # Compute the loss\n            loss = criterion(y, labels)\n      \n            running_val_loss += loss.item()\n            running_val_accuracy += (y.max(1)[1] == labels).sum().item()\n    \n    print(\"Validation accuracy:\", running_val_accuracy\/float(len(val_subset)),\n          \"Validation loss:\", running_val_loss\/float(len(val_subset)))\n  \n    epoch_val_loss.append(running_val_loss\/len(val_subset))\n    epoch_val_acc.append(running_val_accuracy\/len(val_subset))\n    \n    if running_val_accuracy\/len(val_subset) > best_acc:\n        best_acc = running_val_accuracy\/len(val_subset)\n        es = 0\n        torch.save(net_1.state_dict(), \"model_\" + str(e) + 'weight.pt')\n    else:\n        es += 1\n        print(\"Counter {} of 2\".format(es))\n\n        if es > 1:\n            print(\"Early stopping with best_acc: \", best_acc)\n            break\n\"\"\"","2ad47248":"\"\"\"\nx = np.arange(N_EPOCHS)\nplt.figure()\nplt.plot(x, epoch_acc, x, epoch_val_acc)\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(('train_acc', 'val_acc'))\n\nplt.figure()\nplt.plot(x, epoch_loss, x, epoch_val_loss)\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(('train_loss', 'val_loss'))\n\"\"\"","fe71bbac":"##############################################   MODEL 2\nnet_2 = torchvision.models.vgg11(pretrained=True)\n\n## torchvision models are meant to be used on imagenet (1000 classes)\n## we need to modify the last layer\nnet_2.classifier[6] = nn.Linear(4096,153)\n \n## Move model to the GPU\nnet_2 = net_2.cuda()\n\n\noptimizer = torch.optim.Adam(net_2.parameters(), lr=0.001) #torch.optim.SGD(net_2.parameters(), lr=0.01, momentum=0.9)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)\n\ntrain_loader = DataLoader(data_plus_augmented_2, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)","d64a447f":"## NUMBER OF EPOCHS TO TRAIN\nN_EPOCHS = 6\n\nepoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []\nbest_acc = 0\n\nfor e in range(N_EPOCHS):\n    \n    print(\"EPOCH:\",e)\n  \n    ### TRAINING LOOP\n    running_loss = 0\n    running_accuracy = 0\n  \n    ## Put the network in training mode\n    net_2.train()\n  \n    for i, batch in enumerate(tqdm(train_loader)):\n    \n        # Get a batch from the dataloader\n        x = batch[0]\n        labels = batch[1]\n        \n    \n        # move the batch to GPU\n        x = x.cuda()\n        labels = labels.cuda()\n\n        # Compute the network output\n        y = net_2(x)\n    \n        # Compute the loss\n        loss = criterion(y, labels)\n    \n        # Reset the gradients\n        optimizer.zero_grad()\n    \n        # Compute the gradients\n        loss.backward()\n    \n        # Apply one step of the descent algorithm to update the weights\n        optimizer.step()\n    \n        ## Compute some statistics\n        with torch.no_grad():\n            running_loss += loss.item()            \n            running_accuracy += (y.max(1)[1] == labels).sum().item()\n    scheduler.step()\n    \n    print(\"Training accuracy:\", running_accuracy\/float(len(data_plus_augmented_2)),\n          \"Training loss:\", running_loss\/float(len(data_plus_augmented_2)))\n  \n    epoch_loss.append(running_loss\/len(data_plus_augmented_2))\n    epoch_acc.append(running_accuracy\/len(data_plus_augmented_2))\n  \n    ### VALIDATION LOOP\n    ## Put the network in validation mode\n    net_2.eval()\n  \n    running_val_loss = 0\n    running_val_accuracy = 0\n  \n    for i, batch in enumerate(tqdm(val_loader)):\n    \n        with torch.no_grad():\n            # Get a batch from the dataloader\n            x = batch[0]\n            labels = batch[1]\n\n            # move the batch to GPU\n            x = x.cuda()\n            labels = labels.cuda()\n\n            # Compute the network output\n            y = net_2(x)\n      \n            # Compute the loss\n            loss = criterion(y, labels)\n      \n            running_val_loss += loss.item()\n            running_val_accuracy += (y.max(1)[1] == labels).sum().item()\n    \n    print(\"Validation accuracy:\", running_val_accuracy\/float(len(val_subset)),\n          \"Validation loss:\", running_val_loss\/float(len(val_subset)))\n    \n    epoch_val_loss.append(running_val_loss\/len(val_subset))\n    epoch_val_acc.append(running_val_accuracy\/len(val_subset))\n    \n    if running_val_accuracy\/len(val_subset) > best_acc:\n        best_acc = running_val_accuracy\/len(val_subset)\n        es = 0\n        torch.save(net_2.state_dict(), \"model_\" + str(e) + 'weight.pt')\n    else:\n        es += 1\n        print(\"Counter {} of 2\".format(es))\n\n        if es > 1:\n            print(\"Early stopping with best_acc: \", best_acc)\n            break","6d98a605":"x = np.arange(N_EPOCHS)\nplt.figure()\nplt.plot(x, epoch_acc, x, epoch_val_acc)\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(('train_acc', 'val_acc'))\n\nplt.figure()\nplt.plot(x, epoch_loss, x, epoch_val_loss)\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(('train_loss', 'val_loss'))","2c263587":"class InferenceDataset(torch.utils.data.Dataset):\n    def __init__(self, images_filepaths, transform=None):\n        self.images_filepaths = images_filepaths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n        return image\n\nconvert = albumentations.Compose([\n    albumentations.Resize(256,256), \n    albumentations.CenterCrop(224,224),\n    albumentations.Normalize(mean=[0.4477, 0.4701, 0.3317], std=[0.2072, 0.1977, 0.1941]),\n    albumentations.pytorch.transforms.ToTensorV2()])\n\n\ntest_dataset = InferenceDataset(images_filepaths= glob.glob(\"..\/input\/polytech-nice-data-science-course-2021\/polytech\/test\/*\"), transform=convert)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\nprint(len(test_dataset), len(test_loader))","fbab559f":"def visualize_batch(batch, classes):\n    \n    # initialize a figure\n    figure(figsize=(10, 8), dpi=80)\n    \n    # loop over the batch size\n    for i in range(0, 8):\n        \n        # create a subplot\n        ax = plt.subplot(2, 4, i + 1)\n        \n        # grab the image\n        image = batch[i]\n        image = image.permute(1, 2, 0)\n        \n        # show the image along with the label\n        plt.imshow(image)\n        plt.axis(\"off\")\n        \n    # show the plot\n    plt.tight_layout()\n    plt.show()\n\n    \n# Visualization\ntrainDataLoader = DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=2)\n\ntrainBatch = next(iter(trainDataLoader))\nvisualize_batch(trainBatch, dataset.classes)","b6bd845b":"####### Load model_1\nnet_1 = torchvision.models.resnet50(pretrained=True)  \n\n## torchvision models are meant to be used on imagenet (1000 classes)\n## we need to modify the last layer\nlast = net_1.fc.in_features\nnet_1.fc = nn.Linear(last,153)\n \n## Move model to the GPU\nnet_1 = net_1.cuda()\n\nnet_1.load_state_dict(torch.load('..\/input\/model-1\/model_1.pt'))","af42ceb0":"model_1 = net_1.eval()\nmodel_2 = net_2.eval()\n\npredicted_labels = []\nwith torch.no_grad():\n    for images in tqdm(test_loader):\n        images = images.to('cuda', non_blocking=True)\n        output = model_1(images) + model_2(images)\n        predicted_labels.append(list(map(lambda x: int(dataset.classes[torch.argmax(x).item()]), output )))\n\nprint(len(predicted_labels))\n\n\n# Flatten the list of lists\nflat_list = [item for sublist in predicted_labels for item in sublist]\nprint(len(flat_list))\n\n\n\nTEST_DIR = '..\/input\/polytech-nice-data-science-course-2021\/polytech\/test\/'\npreds = pd.DataFrame(flat_list, columns = [\"class\"])\n\n\ntots = glob.glob(\"..\/input\/polytech-nice-data-science-course-2021\/polytech\/test\/*\")\nnames = []\nfor i in tqdm(range(len(flat_list))):\n    names.append(tots[i].replace(TEST_DIR,\"\"))\n    names_tests = pd.DataFrame(names, columns = [\"image_name\"])\n    \n\npd.concat([names_tests, preds], axis=1).to_csv('predictions_combo.csv', index=False)","3df04494":"The dataset is unblanced."}}