{"cell_type":{"e5a90160":"code","f0b305c8":"code","c75c9983":"code","ea1ad106":"code","f68957b6":"code","5144ac6a":"code","76830227":"code","4e700e27":"code","0b9f2a74":"code","af324f16":"code","946063a4":"code","f9f8c029":"markdown","5599bf4c":"markdown","5841ff05":"markdown"},"source":{"e5a90160":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","f0b305c8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\n\nDATADIR = r\"\/kaggle\/input\/brain-tumor-classification-mri\/Training\/\"\nCATEGORIES = [\"glioma_tumor\",\"meningioma_tumor\",\"no_tumor\",\"pituitary_tumor\"]\nfor category in CATEGORIES:\n    path = os.path.join(DATADIR,category)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path,img))\n        plt.imshow(img_array)\n        plt.show()\n        plt.axis(\"off\")\n        break\n    break","c75c9983":"IMG_SIZE = 150\nnew_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))    \nplt.imshow(new_array,cmap = \"gray\")\nplt.axis(\"off\")\n","ea1ad106":"training_data = []\n\ndef create_training_data():\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR,category)\n        class_num = CATEGORIES.index(category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n                training_data.append([new_array,class_num])\n            except Exception as e:\n                pass\ncreate_training_data()","f68957b6":"X = []\ny = []\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\nX = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE)\nprint(X.shape)\nX = X\/255.0  \nX = X.reshape(-1,150,150,1)","5144ac6a":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\ny = to_categorical(y, num_classes = 4)","76830227":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","4e700e27":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n#\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (150,150,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n#\nmodel.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n\n#\nmodel.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n\n# \nmodel.add(Flatten())\nmodel.add(Dense(1024, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4, activation = \"softmax\"))\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\nepochs = 50  \nbatch_size = 40\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False, \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=0,\n        zoom_range = 0,\n        width_shift_range=0,  \n        height_shift_range=0,  \n        horizontal_flip=True,  \n        vertical_flip=False)  \n","0b9f2a74":"datagen.fit(X_train)\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              steps_per_epoch = X_train.shape[0] \/\/ batch_size)    ","af324f16":"plt.plot(history.history[\"loss\"],c = \"purple\")\nplt.plot(history.history[\"val_loss\"],c = \"orange\")\nplt.title(\"Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend([\"train\", \"test\"])\nplt.show()","946063a4":"plt.plot(history.history[\"accuracy\"],c = \"purple\")\nplt.plot(history.history[\"val_accuracy\"],c = \"orange\")\nplt.title(\"Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend([\"train\", \"test\"])\nplt.show()","f9f8c029":"### PREDICTION USING CNN","5599bf4c":"<font color ='brown'>\n    \n\n    \n### Load and Check Data ","5841ff05":"### MANIPULATING DATA"}}