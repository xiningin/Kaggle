{"cell_type":{"cd4c1925":"code","a9b7c75b":"code","f6c70654":"code","91d84d73":"code","18f268ca":"code","5a6f7c9c":"code","c71ddd82":"code","1274a9c1":"code","fbaf073a":"code","64eab462":"code","138a87af":"code","997287db":"code","d6c0c17c":"code","64567880":"code","dc89ba22":"code","63f0d992":"code","58771e81":"code","b7377878":"code","51176d0c":"code","0011b4a8":"code","38019bb0":"code","c218c7fb":"code","0a7e0bb4":"code","f0be32f9":"code","bfb7c9ab":"code","474ab366":"code","d908d9e5":"code","ddc78ae2":"code","e38eedc7":"code","a563ba23":"code","c59be3ce":"code","a3dd2d40":"code","8e7c1fc4":"code","94670f38":"code","006227fc":"code","a6647ab7":"code","ebe0b8c6":"code","4d29557e":"code","520f673b":"code","86a834a7":"code","ee85d2ae":"code","3cdc5acb":"code","f1031508":"code","03f961a4":"code","8f3a106e":"code","2e3d7d0b":"code","58a28903":"code","90983040":"code","4f95f857":"code","42cb0bdf":"code","38983a6b":"code","5dce782f":"code","f3a692b1":"code","40625f35":"code","c52b6419":"code","5d9e9fc8":"code","76813e67":"code","d34343fd":"code","99cead0e":"code","6f1033ef":"code","61a4bc2e":"code","768ebafe":"code","75b803c1":"markdown","9ca1ee7d":"markdown","34687157":"markdown","01b5c282":"markdown","c3367765":"markdown","e1969683":"markdown","7d924755":"markdown","bad70121":"markdown","125724bf":"markdown","8b55cbc7":"markdown","c260af24":"markdown","3ec418f1":"markdown","c0008cb5":"markdown","42335f19":"markdown"},"source":{"cd4c1925":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a9b7c75b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport statsmodels.api as sm\nimport warnings\nimport missingno as msno\nfrom datetime import date\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import KNNImputer\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.linear_model import LogisticRegression\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nwarnings.simplefilter(\"ignore\")","f6c70654":"pd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.float_format', lambda x: '%.5f' % x)","91d84d73":"df_ = pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\ndf = df_.copy()\ndf.head()","18f268ca":"def check_df(dataframe, head=5, tail = 5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head ######################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail ######################\")\n    print(dataframe.tail(tail))\n    print(\"##################### NA ########################\")\n    print(dataframe.isnull().sum())\n    print(\"################### Quantiles ###################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)","5a6f7c9c":"check_df(df)","c71ddd82":"df.nunique()","1274a9c1":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n    It gives the names of categorical, numerical and categorical but cardinal variables in the data set.\n    Note: Categorical variables with numerical appearance are also included in categorical variables.\n    Parameters\n    ------\n        dataframe: dataframe\n                The dataframe from which variable names are to be retrieved\n        cat_th: int, optional\n                Class threshold for numeric but categorical variables\n        car_th: int, optinal\n                Class threshold for categorical but cardinal variables\n    Returns\n    ------\n        cat_cols: list\n                Categorical variable list\n        num_cols: list\n                Numeric variable list\n        cat_but_car: list\n                Categorical view cardinal variable list\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = total number of variables\n        num_but_cat is inside cat_cols.\n        The sum of 3 lists with return is equal to the total number of variables: cat_cols + num_cols + cat_but_car = number of variables\n    \"\"\"\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car","fbaf073a":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","64eab462":"def cat_summary(dataframe, col_name, plot=False):\n    import pandas as pd\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()","138a87af":"for col in cat_cols:\n    cat_summary(df, col, plot=True)","997287db":"def num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.show()","d6c0c17c":"num_summary(df, num_cols, True)","64567880":"def target_summary_with_num(dataframe, target, numerical_col):\n    print(dataframe.groupby(target).agg({numerical_col: \"mean\"}), end=\"\\n\\n\\n\")","dc89ba22":"for col in num_cols:\n    target_summary_with_num(df, \"Salary\", col)","63f0d992":"df.corr()","58771e81":"f, ax = plt.subplots(figsize=[18, 13])\nsns.heatmap(df.corr(), annot=True, fmt=\".2f\", ax=ax, cmap=\"magma\")\nax.set_title(\"Correlation Matrix\", fontsize=20)\nplt.show()","b7377878":"correlation_matrix = df.corr().round(2)\nthreshold=0.75\nfiltre=np.abs(correlation_matrix['Salary']) > 0.50\ncorr_features=correlation_matrix.columns[filtre].tolist()\nsns.clustermap(df[corr_features].corr(),annot=True,fmt=\".2f\")\nplt.title('Correlation Between Features')\nplt.show()","51176d0c":"msno.bar(df);\nplt.show()","0011b4a8":"df.isnull().sum()","38019bb0":"def pairplot(dataset, target_column):\n    sns.set(style=\"ticks\")\n    sns.pairplot(dataset, hue=target_column)\n    plt.show()","c218c7fb":"pairplot(df, 'Salary')","0a7e0bb4":"df[\"New_Avg_CAtBat\"] = df[\"CAtBat\"] \/ df[\"Years\"]\ndf[\"New_Avg_CHits\"] = df[\"CHits\"] \/ df[\"Years\"]\ndf[\"New_Avg_CHmRun\"] = df[\"CHmRun\"] \/ df[\"Years\"]\ndf[\"New_Avg_Cruns\"] = df[\"CRuns\"] \/ df[\"Years\"]\ndf[\"New_Avg_CRBI\"] = df[\"CRBI\"] \/ df[\"Years\"]\ndf[\"New_Avg_CWalks\"] = cwalks = df[\"CWalks\"] \/ df[\"Years\"]","f0be32f9":"df[\"New_Hits\/AtBat_Rate\"] = (df[\"Hits\"] \/ df[\"AtBat\"])*100\ndf[\"New_HmRun\/Hits_Rate\"] = (df[\"HmRun\"] \/ df[\"Hits\"])*100\ndf[\"New_Runs\/Hits_Rate\"] = (df[\"Runs\"] \/ df[\"Hits\"])*100\ndf[\"New_RBI\/Hits_Rate\"] = (df[\"RBI\"] \/ df[\"Hits\"])*100\ndf[\"New_Errors\/Walks_Rate\"] = (df[\"Errors\"] \/ df[\"Walks\"])*100\ndf[\"New_CHits\/CAtBat_Rate\"] = (df[\"CHits\"] \/ df[\"CAtBat\"])*100\ndf[\"New_CHmRun\/CHits_Rate\"] = (df[\"CHmRun\"] \/ df[\"CHits\"])*100\ndf[\"New_CRuns\/CHits_Rate\"] = (df[\"CRuns\"] \/ df[\"CHits\"])*100\ndf[\"New_CRBI\/CHits_Rate\"] = (df[\"CRBI\"] \/ df[\"CHits\"])*100","bfb7c9ab":"df[\"New_Hit_Success\"] = df[\"CHits\"]\/df[\"CAtBat\"]","474ab366":"df[\"New_Rating\"] = (24*df[\"HmRun\"] + 21*df[\"Runs\"] + 21*(df[\"Walks\"] - df[\"Errors\"]) + 18*df[\"Assists\"] + 16*df[\"RBI\"])\/100","d908d9e5":"df[\"New_Best\"]=df[\"Hits\"]*df[\"CRBI\"]*df[\"PutOuts\"]","ddc78ae2":"df.head()","e38eedc7":"df[\"Salary\"].fillna(df[\"Salary\"].median(), inplace=True)","a563ba23":"df.isnull().sum()","c59be3ce":"sns.boxplot(x = df[\"Salary\"]);\nplt.show()","a3dd2d40":"def outlier_thresholds(dataframe, col_name, q1=0.10, q3=0.90):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","8e7c1fc4":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","94670f38":"def check_outlier(dataframe, col_name, q1=0.10, q3=0.90):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","006227fc":"for col in num_cols:\n    print(col, check_outlier(df, col))","a6647ab7":"for col in num_cols:\n    replace_with_thresholds(df, col)","ebe0b8c6":"for col in num_cols:\n    print(col, check_outlier(df, col))","4d29557e":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","520f673b":"for col in num_cols:\n    print(col, check_outlier(df, col))","86a834a7":"for col in num_cols:\n    replace_with_thresholds(df, col)","ee85d2ae":"for col in num_cols:\n    print(col, check_outlier(df, col))","3cdc5acb":"sns.boxplot(x = df[\"Salary\"]);\nplt.show()","f1031508":"q3 = 0.90\nsalary_up = int(df[\"Salary\"].quantile(q3))\ndf = df[(df[\"Salary\"] < salary_up)]","03f961a4":"sns.boxplot(x=df[\"Salary\"])\nplt.show()","8f3a106e":"binary_cols = [col for col in df.columns if df[col].dtype not in [int, float] and df[col].nunique() == 2]","2e3d7d0b":"binary_cols","58a28903":"for col in binary_cols:\n    labelencoder = LabelEncoder()\n    df[col] = labelencoder.fit_transform(df[col])","90983040":"df.head()","4f95f857":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","42cb0bdf":"cat_cols","38983a6b":"def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=False)\n    return dataframe","5dce782f":"df = one_hot_encoder(df, cat_cols)","f3a692b1":"scaler = RobustScaler()\nnum_cols = [col for col in num_cols  if col not in [\"Salary\"]]\ndf[num_cols] = scaler.fit_transform(df[num_cols])","40625f35":"X = df.drop(\"Salary\", axis=1)\ny = df[\"Salary\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\nreg_model = LinearRegression().fit(X_train, y_train)","c52b6419":"reg_model.intercept_","5d9e9fc8":"reg_model.coef_","76813e67":"y_pred = reg_model.predict(X_train)\nnp.sqrt(mean_squared_error(y_train, y_pred))","d34343fd":"reg_model.score(X_train, y_train)","99cead0e":"np.mean(np.sqrt(-cross_val_score(reg_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","6f1033ef":"pre_model = LGBMRegressor().fit(X, y)\nfeature_imp = pd.DataFrame({'Feature': X.columns, 'Value': pre_model.feature_importances_})\nfeature_imp.sort_values(\"Value\", ascending=False)","61a4bc2e":"pre_model = RandomForestRegressor().fit(X, y)\nfeature_imp = pd.DataFrame({'Feature': X.columns, 'Value': pre_model.feature_importances_})\nfeature_imp.sort_values(\"Value\", ascending=False)","768ebafe":"models = [('LR', LinearRegression()),\n          (\"Ridge\", Ridge()),\n          (\"Lasso\", Lasso()),\n          (\"ElasticNet\", ElasticNet()),\n          ('KNN', KNeighborsRegressor()),\n          ('CART', DecisionTreeRegressor()),\n          ('RF', RandomForestRegressor()),\n          ('SVR', SVR()),\n          ('GBM', GradientBoostingRegressor()),\n          (\"XGBoost\", XGBRegressor(objective='reg:squarederror')),\n          (\"LightGBM\", LGBMRegressor()),\n          ]\n\nfor name, regressor in models:\n    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")","75b803c1":"See just 'Salary' feature has NaN values. Now, correlation that is what's going between features. How are they strict relation between them. We gave correlation values more than 0.5 between features.","9ca1ee7d":"As can be seen, no threshold value problem was observed.","34687157":"We suppressed outliers according to the lower and upper bounds of the threshold values.","01b5c282":"There are 59 missing observation units in the \"Salary\" variable of our data.","c3367765":"1. **LINEAR REGRESSION**","e1969683":"**CONTEXT**\n\n**This dataset is part of the R-package ISLR and is used in the related book by G. James et al. (2013) \"An Introduction to Statistical Learning with applications in R\" to demonstrate how Ridge regression and the LASSO are performed using R.**","7d924755":"**ACKNOWLEDGEMENTS**\n\nPlease cite\/acknowledge: Games, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning with applications in R, www.StatLearning.com, Springer-Verlag, New York.","bad70121":"**DATASET STORY**\n\nThis dataset was originally taken from the StatLib library at Carnegie Mellon University. The dataset is part of the data used in the 1988 ASA Graphics Section Poster Session. Salary data originally from Sports Illustrated, April 20, 1987. 1986 and career statistics are from the 1987 Baseball Encyclopedia Update, published by Collier Books, Macmillan Publishing Company, New York.","125724bf":"**BUSINESS PROBLEM**\n\nMay a machine learning project be carried out to estimate the salary of baseball players whose salary information and career statistics for 1986 are shared?","8b55cbc7":"**CONTENT**\n\n**This dataset was originally taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.**","c260af24":"When we rechecked the variables with outlier values, we detected outlier values in the variables. Variables with outlier values are: \n* \"New_Hits\/AtBat_Rate\", \n* \"New_Runs\/Hits_Rate\", \n* \"New_Errors\/Walks_Rate\", \n* \"New_CHits\/CAtBat_Rate\", \n* \"New_Hit_Success\" \n* \"New_Best\"","3ec418f1":"**TASK**\n\nDevelop a salary forecasting model using data preprocessing and feature engineering techniques.","c0008cb5":"**FORMAT**\n\nA data frame with 322 observations of major league players on the following 20 variables.\n\n\n* ***AtBat*** Number of times at bat in 1986\n* ***Hits*** Number of hits in 1986\n* ***HmRun*** Number of home runs in 1986\n* ***Runs*** Number of runs in 1986\n* ***RBI*** Number of runs batted in in 1986\n* ***Walks*** Number of walks in 1986\n* ***Years*** Number of years in the major leagues\n* ***CAtBat*** Number of times at bat during his career\n* ***CHits*** Number of hits during his career\n* ***CHmRun*** Number of home runs during his career\n* ***CRuns*** Number of runs during his career\n* ***CRBI*** Number of runs batted in during his career\n* ***CWalks*** Number of walks during his career\n* ***League*** A factor with levels A and N indicating player\u2019s league at the end of 1986\n* ***Division*** A factor with levels E and W indicating player\u2019s division at the end of 1986\n* ***PutOuts*** Number of put outs in 1986\n* ***Assists*** Number of assists in 1986\n* ***Errors*** Number of errors in 1986\n* ***Salary*** 1987 annual salary on opening day in thousands of dollars\n* ***NewLeague*** A factor with levels A and N indicating player\u2019s league at the beginning of 1987","42335f19":"When we examine the dataset, we see that there is a difference between the mean and median values of the Assist variable. This difference is also supported by the standard deviation."}}