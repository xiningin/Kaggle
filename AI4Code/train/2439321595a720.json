{"cell_type":{"30c03a29":"code","b8928283":"code","9413c955":"code","35bc8cfd":"code","3526dc29":"code","66ba1554":"code","1934752f":"code","2254ae13":"code","78f991a6":"code","96f18c7e":"code","59214fa3":"code","a410e14b":"code","17b2d675":"code","2ae16833":"code","72d28418":"code","5ba4568c":"code","9bfb73a6":"code","9ec2eddb":"code","ccbed00b":"code","1eddfee4":"code","f2c98893":"code","8e7e7067":"code","13b0987c":"code","d5a79d6a":"markdown","4c15b2c2":"markdown"},"source":{"30c03a29":"!nvidia-smi","b8928283":"from tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.5\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","9413c955":"# import the libraries as shown below\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n#from keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob\n#import matplotlib.pyplot as plt","35bc8cfd":"# re-size all the images to this\nIMAGE_SIZE = [224, 224]\n\ntrain_path = '\/kaggle\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/'\nvalid_path = '\/kaggle\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/'\n","3526dc29":"# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n# Here we will be using imagenet weights\n\ninception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n\n","66ba1554":"# don't train existing weights\nfor layer in inception.layers:\n    layer.trainable = False","1934752f":"  # useful for getting number of output classes\nfolders = glob(train_path+'\/*')","2254ae13":"folders","78f991a6":"# our layers - you can add more if you want\nx = Flatten()(inception.output)","96f18c7e":"prediction = Dense(len(folders), activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=inception.input, outputs=prediction)","59214fa3":"\n# view the structure of the model\nmodel.summary()\n","a410e14b":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\n","17b2d675":"# Use the Image Data Generator to import the images from the dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","2ae16833":"# Make sure you provide the same target size as initialied for the image size\ntraining_set = train_datagen.flow_from_directory(train_path,\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')","72d28418":"test_set = test_datagen.flow_from_directory(valid_path,\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')","5ba4568c":"# fit the model\n# Run the cell. It will take some time to execute\nr = model.fit_generator(training_set,\n                        validation_data=test_set,\n                        epochs=10,\n                        steps_per_epoch=len(training_set),\n                        validation_steps=len(test_set),\n                        verbose=1\n                       )","9bfb73a6":"import matplotlib.pyplot as plt","9ec2eddb":"# plot the loss\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')","ccbed00b":"# save it as a h5 file\n\n\nfrom tensorflow.keras.models import load_model\n\nmodel.save('model_inception.h5')","1eddfee4":"\ny_pred = model.predict(test_set)\n","f2c98893":"y_pred","8e7e7067":"import numpy as np\ny_pred = np.argmax(y_pred, axis=1)","13b0987c":"y_pred","d5a79d6a":"Please download the dataset from the below url","4c15b2c2":"## Transfer Learning Inception V3 using Keras"}}