{"cell_type":{"b9be0fed":"code","53145456":"code","296dc7f2":"code","5211db91":"code","08726da7":"code","00167537":"code","83477140":"code","5aa3851d":"code","36b1ae32":"code","8e920b63":"code","e5f85373":"code","7781b011":"code","f74ac5dd":"code","080402c2":"code","a21588db":"code","398f6a68":"code","ad1ece96":"code","cf8bb4fb":"code","6e139e4d":"code","82764bf0":"code","876f0826":"code","27ffc60c":"code","e3398e8c":"code","e908614e":"code","fb1300f5":"code","a65d2b22":"code","24976e1f":"code","8191e83c":"code","fd8b1793":"code","36749af9":"code","2ce99601":"code","b9aceff6":"code","2f750dcb":"code","5358460d":"code","d90c46dd":"code","e1039191":"code","1907320b":"code","b07373c2":"code","490589ea":"code","30b3a158":"code","7fac530b":"code","5451b8e4":"code","4d7946f6":"code","6b9a5d8f":"code","f9a2154f":"code","a150d9b2":"code","2c7bfef1":"markdown","253267b3":"markdown","d9f9b366":"markdown","8ac59e93":"markdown"},"source":{"b9be0fed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","53145456":"#importing the basic libraries\nimport pandas as pd\nimport numpy as np","296dc7f2":"#importing the training dataset\ndata = pd.read_csv(\"..\/input\/titanic\/train.csv\")","5211db91":"#view the dataset\ndata.head()","08726da7":"# removing the useless contents from the dataset\ndata = data.drop(\"Name\", axis=1)\ndata = data.drop(\"Ticket\", axis=1)\ndata = data.drop(\"Fare\", axis=1)\ndata = data.drop(\"Cabin\", axis=1)","00167537":"data.head()","83477140":"data.describe()","5aa3851d":"#we need to make Parch and SibSp into one column\ndata[\"parents\"] = data[\"SibSp\"] + data[\"Parch\"]\ndata.head()","36b1ae32":"#drop both the columns\ndata.drop(\"SibSp\",axis = 1,inplace =True)","8e920b63":"data.drop(\"Parch\",axis=1,inplace=True)","e5f85373":"data.head()","7781b011":"data.isna().sum()","f74ac5dd":"#converting the object types into string type\ndata[\"Sex\"].dtype","080402c2":"data[\"Sex\"] = data[\"Sex\"].astype('str')","a21588db":"data[\"Embarked\"] = data[\"Embarked\"].astype('str')","398f6a68":"data[\"Embarked\"].dtype","ad1ece96":"#encoding categorical values into numerical ones\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndata[\"Sex\"] = le.fit_transform(data[\"Sex\"])\ndata[\"Embarked\"] = le.fit_transform(data[\"Embarked\"])","cf8bb4fb":"#create test series\nSex = pd.Series([\"male\", \"female\", \"male\"])\ntransformed = le.fit_transform(Sex)","6e139e4d":"data.head()","82764bf0":"data.isna().sum()","876f0826":"data = data.fillna(data[\"Sex\"].mean())","27ffc60c":"data.isna().sum()","e3398e8c":"# rearranging the columns\ndata = data[[\"PassengerId\", \"Pclass\" , \"Sex\", \"Age\", \"Embarked\", \"parents\", \"Survived\"]]\ndata.head()","e908614e":"X = data.iloc[:,:-1].values\ny = data.iloc[:, -1].values","fb1300f5":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=0)","a65d2b22":"#importing all the classifier \nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn import svm,tree\nimport xgboost","24976e1f":"#initializing all the classifiers and creating a constructor of the models\nclassifiers=[]\n\nmodel1 = RandomForestClassifier()\nclassifiers.append(model1)\n\nmodel2 = xgboost.XGBClassifier()\nclassifiers.append(model2)\n\nmodel3 = svm.SVC()\nclassifiers.append(model3)\n\nmodel4 = tree.DecisionTreeClassifier()\nclassifiers.append(model4)\n\nmodel5 = GradientBoostingClassifier()\nclassifiers.append(model5)","8191e83c":"#fitting our algorithm in classifier array\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfor clf in classifiers:\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    acc = accuracy_score(y_test,y_pred)\n    print(\"accuracy of the %s is %s\"%(clf,acc))\n    cm = confusion_matrix(y_test,y_pred)\n    print(\"Confusion matrix of the %s is %s\"%(clf,cm))","fd8b1793":"#importing our test data\ndata1 = pd.read_csv(\"..\/input\/titanic\/test.csv\")","36749af9":"data1.head()","2ce99601":"data1 = data1.drop(\"Name\", axis=1)\ndata1 = data1.drop(\"Ticket\", axis=1)\ndata1 = data1.drop(\"Fare\", axis=1)\ndata1 = data1.drop(\"Cabin\", axis=1)","b9aceff6":"data1.head()","2f750dcb":"#we need to make Parch and SibSp into one column\ndata1[\"parents\"] = data1[\"SibSp\"] + data1[\"Parch\"]\ndata1.head()","5358460d":"#drop both the columns\ndata1.drop(\"SibSp\",axis = 1,inplace =True)\ndata1.drop(\"Parch\",axis=1,inplace=True)","d90c46dd":"data1.head()","e1039191":"#converting bject type into str\ndata1[\"Sex\"] = data1[\"Sex\"].astype('str')\ndata1[\"Embarked\"] = data1[\"Embarked\"].astype('str')","1907320b":"#encoding categorical values into numerical ones\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndata1[\"Sex\"] = le.fit_transform(data1[\"Sex\"])\ndata1[\"Embarked\"] = le.fit_transform(data1[\"Embarked\"])","b07373c2":"#create test series\nSex = pd.Series([\"male\", \"female\", \"male\"])\ntransformed = le.fit_transform(Sex)","490589ea":"#removing the null values\ndata1.isna().sum()","30b3a158":"data1 = data1.fillna(data[\"Sex\"].mean())","7fac530b":"data1.isna().sum()","5451b8e4":"data1","4d7946f6":"y_preds = model5.predict(data1)","6b9a5d8f":"y_preds","f9a2154f":"data1[\"survival\"] = y_preds","a150d9b2":"output = pd.DataFrame({'PassengerId': data1.PassengerId, 'Survived': y_preds})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","2c7bfef1":" Hence we can say that the best accuracy was provided by GradientBoostingClassifier","253267b3":"# time to apply this on our test set","d9f9b366":"## please keep in mind this was my first submission in Kaggle so i wasn't sure how to make this submission.","8ac59e93":"## Since the Gradient boost gave the best results we will use model5"}}