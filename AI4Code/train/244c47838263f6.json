{"cell_type":{"eb41d65a":"code","3e460f94":"code","7561ac3b":"code","7d4f46e7":"code","a64b043e":"code","a122c7c9":"code","c86d81c6":"code","bb24349a":"code","c8d22048":"code","86e6b001":"code","ceed5c23":"code","819b48e1":"code","aedbad0a":"code","1ea8ba04":"code","3b94d1fe":"code","24847cd9":"code","f5f2a57d":"code","c5ac13b8":"code","9fbfb340":"code","3975f882":"code","d293ce6f":"code","3416d97f":"code","f83fd0c7":"code","80efee00":"code","232eea15":"code","59b4b503":"code","cd21b902":"code","29bbd577":"code","1aba1486":"code","9ad44228":"markdown","cd5ce875":"markdown","a6b81784":"markdown","ff1e847d":"markdown","ca580420":"markdown","1c29e5b3":"markdown","20c9db04":"markdown","7972e2e1":"markdown","26839719":"markdown","f2c819a6":"markdown","0df497a1":"markdown","4ec53c2f":"markdown","dc8eb07f":"markdown","691408a5":"markdown","4697274d":"markdown","c294517b":"markdown","35cb4b09":"markdown","1f04a702":"markdown","e8834905":"markdown","cdf93313":"markdown","481af995":"markdown","412d6d5d":"markdown","365a3a6f":"markdown","20d4c0b2":"markdown","354fc870":"markdown"},"source":{"eb41d65a":"import numpy as np\nimport pandas as pd\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import (\n    OneHotEncoder,\n    StandardScaler\n)\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm.sklearn import LGBMClassifier\nfrom sklearn.model_selection import (\n    RandomizedSearchCV,\n    cross_validate,\n    train_test_split,\n)\nimport altair as alt\nimport shap\nfrom scipy.stats import loguniform\nfrom sklearn.metrics import make_scorer, recall_score, f1_score\nfrom sklearn.metrics import classification_report","3e460f94":"# !pip install altair\n# !pip install altair_data_server","7561ac3b":"uci_df = pd.read_csv(\"..\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv\")\nuci_df.rename(columns={\"default.payment.next.month\": \"default\"}, inplace=True)","7d4f46e7":"train_df, test_df = train_test_split(uci_df, test_size=0.3)","a64b043e":"train_df.info()\ntrain_df.describe()\ntrain_df[\"default\"].value_counts(normalize=True)","a122c7c9":"cor = train_df.corr()\ncorr_df = cor.stack().reset_index(name='corr')\nalt.renderers.enable('mimetype')\n\ntitle = alt.TitleParams(\n        text=\"Correlation Heatmap\",\n        subtitle=\"Shows the Pearson's correlation coefficients between the different variables\")\n\nplot = alt.Chart(corr_df, title=title).mark_rect().encode(\n    x=alt.X('level_0', title=''),\n    y=alt.Y('level_1', title=''),\n    color=alt.Color('corr', scale=alt.Scale(domain=(-1, 1), scheme='purpleorange'))\n)\n\ntext = plot.mark_text(\n    size=8\n).encode(\n    text=alt.Text('corr', format=\".2f\"),\n    color=alt.value('black')\n)\n\nplot + text","c86d81c6":"# alt.data_transformers.enable('data_server')\n\n# train_df['default'] = train_df['default'].astype(\"category\")\n# alt.Chart(train_df).mark_area(opacity=0.6).encode(\n#     x=alt.X('PAY_0', bin=alt.Bin(maxbins=30), title=\"PAY_0\"),\n#     y=alt.Y('count()', stack=False, title=\"Count\"),\n#     color=alt.Color('default')\n# )","bb24349a":"# line = pd.DataFrame({\n#     'x': [0, 800000],\n#     'y': [0, 800000],\n# })\n\n# line_plot = alt.Chart(line).mark_line(color='red').encode(\n#     x='x',\n#     y='y'\n# )\n# alt.Chart(\n#     train_df,\n#     title=\"Amount of Payment VS Amount of Bill for July, 2005\"\n# ).mark_point().encode(\n#         alt.X(\"PAY_AMT3\", title=\"PAY_AMT2\"),\n#         alt.Y(\"BILL_AMT2\", title=\"BILL_AMT3\"),\n#         color=\"default\"\n# ) + line_plot","c8d22048":"recall_scorer = make_scorer(recall_score, average=\"macro\")\nf1_scorer = make_scorer(f1_score, average=\"macro\")\n\nscoring_metrics = {\"recall\": recall_scorer, \"f1\": f1_scorer}","86e6b001":"train_df[\"EDUCATION\"].value_counts()\ntrain_df[\"PAY_0\"].value_counts()","ceed5c23":"drop_features = [\"ID\"]\nbinary_features = [\"SEX\"]\ncategorical_features = ['EDUCATION', 'MARRIAGE']\ntarget = \"default\"\nnumeric_features = list(\n    set(train_df.columns)\n    - set(drop_features)\n    - set(binary_features)\n    - set(categorical_features)\n    - set([target])\n)\nassert train_df.columns.shape[0] == len(\n    drop_features\n    + binary_features\n    + categorical_features\n    + numeric_features\n    + [target]\n)","819b48e1":"preprocessor = make_column_transformer(\n    (StandardScaler(), numeric_features),\n    (OneHotEncoder(drop=\"if_binary\", dtype=\"int\"), binary_features),\n    (OneHotEncoder(handle_unknown=\"ignore\", dtype=\"int\"), categorical_features),\n    (\"drop\", drop_features),\n)","aedbad0a":"X_train, y_train = train_df.drop(columns=[target]), train_df[target]\nX_test, y_test = test_df.drop(columns=[target]), test_df[target]","1ea8ba04":"# Adopted from DSCI573 lecture notes\ndef mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n    \"\"\"\n    Returns mean and std of cross validation\n\n    Parameters\n    ----------\n    model :\n        scikit-learn model\n    X_train : numpy array or pandas DataFrame\n        X in the training data\n    y_train :\n        y in the training data\n\n    Returns\n    ----------\n        pandas Series with mean scores from cross_validation\n    \"\"\"\n\n    scores = cross_validate(model, X_train, y_train, **kwargs)\n\n    mean_scores = pd.DataFrame(scores).mean()\n    std_scores = pd.DataFrame(scores).std()\n    out_col = []\n\n    for i in range(len(mean_scores)):\n        out_col.append((f\"%0.3f (+\/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n\n    return pd.Series(data=out_col, index=mean_scores.index)","3b94d1fe":"results = {}\ndummy = DummyClassifier(strategy=\"stratified\")\nresults['Dummy'] = mean_std_cross_val_scores(\n    dummy, X_train, y_train,\n    return_train_score=True,\n    scoring=scoring_metrics)\n\npd.DataFrame(results).T","24847cd9":"pipe_lr = make_pipeline(\n    preprocessor, LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n)\n\nresults['Logistic regression'] = mean_std_cross_val_scores(\n    pipe_lr, X_train, y_train,\n    return_train_score=True,\n    scoring=scoring_metrics)","f5f2a57d":"param_dist = {\n    \"logisticregression__C\": loguniform(1e-5, 1e5)\n}\n\nrandom_search = RandomizedSearchCV(\n    pipe_lr,\n    param_dist,\n    n_iter=20,\n    verbose=1,\n    n_jobs=-1,\n    scoring=scoring_metrics,\n    refit=\"recall\"\n)\n\nrandom_search.fit(X_train, y_train);\n\npipe_best_lr = random_search.best_estimator_\nresults['Logistic regression_tuned'] = mean_std_cross_val_scores(\n    pipe_best_lr, X_train, y_train,\n    return_train_score=True,\n    scoring=scoring_metrics)\n\npd.DataFrame(results).T","c5ac13b8":"ratio = np.bincount(y_train)[0] \/ np.bincount(y_train)[1]\nratio","9fbfb340":"pipe_knn = make_pipeline(preprocessor, KNeighborsClassifier())\npipe_nb = make_pipeline(preprocessor, BernoulliNB())\npipe_rf = make_pipeline(preprocessor, RandomForestClassifier(class_weight=\"balanced\"))\npipe_lgbm = make_pipeline(preprocessor, LGBMClassifier(scale_pos_weight=ratio))\npipe_xgb = make_pipeline(\n    preprocessor,\n    XGBClassifier(\n        scale_pos_weight=ratio,\n        eval_metric=\"logloss\",\n        verbosity=0,\n        use_label_encoder=False\n    )\n)\n\n\nmodels = {\n    \"KNN\": pipe_knn,\n    \"Naive Bayes\": pipe_nb,\n    \"Random forest\": pipe_rf,\n    \"LightGBM\": pipe_lgbm,\n    \"XGBoost\": pipe_xgb\n}\n\nfor name, model in models.items():\n    results[name] = mean_std_cross_val_scores(\n        model, X_train, y_train,\n        return_train_score=True,\n        scoring=scoring_metrics\n    )\n\npd.DataFrame(results).T","3975f882":"param_dist_dict = {\n    \"KNN\": {\n        \"kneighborsclassifier__n_neighbors\": np.arange(1, 100, 10),\n    },\n    \"Naive Bayes\": {\n        \"bernoullinb__alpha\": loguniform(1e-3, 1e5)\n    },\n    \"LightGBM\": {\n        \"lgbmclassifier__n_estimators\":  np.arange(1, 1000, 100),\n        \"lgbmclassifier__max_depth\":  np.arange(1, 100, 10),\n        \"lgbmclassifier__learning_rate\": loguniform(1e-5, 1e5)\n    }\n}\n\npipe_best = {}\nscore_best = {}\n\nfor name, param_dist in param_dist_dict.items():\n    random_search = RandomizedSearchCV(\n        models[name],\n        param_distributions=param_dist,\n        n_iter=10,\n        verbose=1,\n        n_jobs=-1,\n        scoring=scoring_metrics,\n        refit=\"recall\"\n    )\n    random_search.fit(X_train, y_train)\n    pipe_best[name] = random_search.best_estimator_\n    score_best[name] = random_search.best_score_\n    results[name + '_tuned'] = mean_std_cross_val_scores(\n        pipe_best[name], X_train, y_train,\n        return_train_score=True,\n        scoring=scoring_metrics\n    )\n\npd.DataFrame(results).T","d293ce6f":"preprocessor.fit(X_train, y_train);\n\nfeature_names = (\n    numeric_features\n    + list(\n        pipe_best['LightGBM'].named_steps[\"columntransformer\"]\n        .named_transformers_[\"onehotencoder-1\"]\n        .get_feature_names()\n    )\n    + list(\n        pipe_best['LightGBM'].named_steps[\"columntransformer\"]\n        .named_transformers_[\"onehotencoder-2\"]\n        .get_feature_names()\n    )\n)\n\nX_train_enc = pd.DataFrame(\n    data=preprocessor.transform(X_train),\n    columns=feature_names,\n    index=X_train.index\n)\nX_train_enc.head()","3416d97f":"X_test_enc = pd.DataFrame(\n    data=preprocessor.transform(X_test),\n    columns=feature_names,\n    index=X_test.index\n)\nX_test_enc.head()","f83fd0c7":"pipe_best['LightGBM'].fit(X_train, y_train);\n\nlgbm_explainer = shap.TreeExplainer(pipe_best['LightGBM'].named_steps[\"lgbmclassifier\"])\ntrain_lgbm_shap_values = lgbm_explainer.shap_values(X_train_enc)\ntest_lgbm_shap_values = lgbm_explainer.shap_values(X_test_enc[:100])","80efee00":"shap.initjs()\nshap.summary_plot(train_lgbm_shap_values[1], X_train_enc, plot_type=\"bar\")","232eea15":"shap.summary_plot(train_lgbm_shap_values[1], X_train_enc)","59b4b503":"recall_score(y_test, pipe_best['LightGBM'].predict(X_test), average=\"macro\")","cd21b902":"print(\n    classification_report(\n        y_test, pipe_best['LightGBM'].predict(X_test), target_names=[\"non-default\", \"default\"]\n    )\n)","29bbd577":"X_train_enc = X_train_enc.round(3)\nX_test_enc = X_test_enc.round(3)\n\nshap.force_plot(\n    lgbm_explainer.expected_value[1],\n    test_lgbm_shap_values[1][8],\n    X_test_enc.iloc[8, :],\n    matplotlib=True,\n)","1aba1486":"lgbm_explainer.expected_value","9ad44228":"The selected model is the tuned LightGBM.\n- The features are ranked in descending order of feature importances. The second plot also shows the direction of how the features are going to drive the prediction.\n- From the plots above, we can see that `PAY_0` is the most important feature. The higher value of `PAY_0` seems to have higher SHAP value for class1.","cd5ce875":"## 6. Different models","a6b81784":"We tried KNN, Naive Bayes, Random forest, LightGBM and XGBoost","ff1e847d":"Read in data and rename the \"default.payment.next.month\" column to \"default\".","ca580420":"**1. Summary of important results**    \n\nThe test accuracy using tuned LightGBM is **0.76**. The test recall score is **0.71**.\n\nModel |Validation Recall Score | Training Recall Score | Validation f1 Score | Training f1 Score |\n-----------|      ------------|------------|---------|------|\nLogistic regression (tuned)  |  0.673   | 0.675   | 0.630 | 0.631 |\nKNN (tuned)   |  0.641 |  0.670  | 0.662 | 0.697 |\nNaive Bayes (tuned)  | 0.583    | 0.583  | 0.571 | 0.571 |\nLightGBM (tuned)  | 0.714 |  0.761  | 0.691  | 0.733 |\n\n**2. Conclusion:**\n- In this study, we compares 6 classification models in supervised machine learning that may be useful for credit card default. Since we want to detect as many \"real\" default cases as possible, we choose to optimize recall score when we do hyperparameter optimization and model comparison.\n- After hyperparameter optimization, LightGBM has the highest validation recall score (0.714) and the highest validation f1 score (0.691). Besides, LightGBM is also very fast. Therefore, we believe `LightGBM` is the optimal model for credit card default classification.\n\n\n**3. Other ideas:**\n- About feature engineering:\n    - Difference between `BILL_AMT`s and `PAY_AMT`s may be a good feature. We can add this feature and see if the performance can improve.\n    - There are many time-series features in this data set. For example, `PAY_0` to `PAY_6`, `BILL_AMT1` to `BILL_AMT6` and `PAY_AMT1` to `PAY_AMT6`. We may consider this time-series effect when we do feature engineering.\n    \n- Feature selection may also help improving the prediction accuracy.","1c29e5b3":"- For this dataset, we want to minimize False Negatives. Therefore, we prefer models with higher recall scores. \n- The tuned logistic regression performs a little bit better than the default balanced one for recall scores. F1 score gets higher as well.","20c9db04":"## 4. Baseline model -- DummyClassifier","7972e2e1":"## Import","26839719":"## 2. EDA","f2c819a6":"## 10. Summary of results","0df497a1":"## 1. Data splitting ","4ec53c2f":"**2) Visualization:**\n- Correlation matrix    \n  According to the correlation matrix, there is high multicolinearity between `BILL_AMT1` to `BILL_AMT6`, `PAY_0` to `PAY_6` and `MARRIAGE` and `AGE`. We can handle this with regularization.\n    \n- Exploratory data visualizations\n    - Second plot    \n      There is a clear tendency that those who have credit card default tend to have longer payment delay (higher `PAY_0` value). `PAY_0` may be an important feature in our model.\n      \n    - Third plot    \n      This plot shows the amount of payment VS amount of bill for July, 2005. We can see that for most data in class 1, the amount of bill is higher than the payment. ","dc8eb07f":"**1. The test recall score when using our best performing model on test data:**","691408a5":"## 7. Hyperparameter optimization ","4697274d":"## 9. Results on the test set","c294517b":"## 8. Interpretation and feature importances","35cb4b09":"## 5. Linear model -- Logistic Regression","1f04a702":"**2. Take one test prediction and explain with SHAP force plots:**","e8834905":"**3) Evaluation metrics:**    \nSince false negative is more important for us in this question, we choose `recall` and `f1` and focus on `recall`. We use macro-average f1 and recall score because of the class imbalance of the target.","cdf93313":"## 3. Preprocessing and transformations ","481af995":"**1) Summary statistics:**\n- There is no missing data here in this dataset, thus no need to impute missing values.\n- The target variable `default` has class imbalance, we need to consider this when building the model and the scoring metrics.","412d6d5d":"**Test predictions**\n- Everything is with respect to class 1, default payment for next month.\n- The plots above show the forces that drive the prediction. The red features are the ones push the prediction to a higher value, and the blue ones are pushing the prediction to a lower value.\n\n- In this case, the base value for class 1, default payment, is -0.378.\n\n- For this example, the raw model score is -1.32 < base value. It is predicted as class 0, no default on credit payment. Some of the forces driving the prediction towards lower value are:\n    - a positive value for `PAY_0`.\n    - a positive value for `PAY_AMT2`. This makes sense because the more amount of previous payment means the less tendency the occurence of default on credit payment.","365a3a6f":"- According to the results above, we can see that RandomForest overfits the most. Train scores for all scoring metrics equal or nearly equal to 1, while the test scores are much lower.\n- XGBoost also overfits. The test recall is about half of the train recall.\n- Considering the recall score and the fit time, LightGBM performs the best.","20d4c0b2":"_- We treat `EDUCATION` as a categorical feature instead of an ordinal feature, since there are a lot of values are 0, 5, or 6 which represents unknown. We just keep it as it is for now._\n\n_- We decide to treat `PAY_0` to `PAY_5` as numeric features since the values are just representing the number of months delayed for the payments. According to other documentations, `-2` means no consumption. We will ignore it for now._","354fc870":"- The tuned LightGBM is the best model, with the highest recall 0.714 and highest f1 score 0.691.\n- We decided to drop RandomForest and XGBoost because the tuned models were still overfitting while they took a very long time to run. "}}