{"cell_type":{"4c269281":"code","20c40920":"code","02201414":"code","9323eb6b":"code","5c092d1e":"code","b65f0379":"code","20bc9c05":"code","7cf57314":"code","2108b2d3":"code","d6e1c69b":"code","1a5e2a03":"code","8d4aad03":"code","ddb7e7f0":"code","60afa396":"code","268dde24":"code","9d2d5dc0":"code","05953f7a":"code","3b07ea9c":"markdown","f2117cb1":"markdown","8739c674":"markdown","2f9d2f5c":"markdown","523f7d32":"markdown","73e3edbb":"markdown","ecbaf752":"markdown","748ad472":"markdown","db1ad7f0":"markdown","acc85c00":"markdown","1304610d":"markdown","65dcf56b":"markdown","2c519cfd":"markdown","0bcaecab":"markdown","f8b9f553":"markdown","8336592a":"markdown"},"source":{"4c269281":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport time\nimport random\nimport collections\nimport cv2\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten,Dropout\nfrom keras.layers import Conv2D,MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom collections import defaultdict\nfrom tensorflow.keras.applications import ResNet50,ResNet101,ResNet152,ResNet50V2,ResNet101V2,ResNet152V2\n\n\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20c40920":"i = 0\nh=2\nv=3\n\nfig, axes=plt.subplots(h,v, figsize=(12,10))\n\nfor dirname,_,filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames[:4]:\n        img = cv2.imread(os.path.join(dirname,filename))\n        if i < h*v:                  \n             img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n             img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n             ax = list(axes.flatten())[i]\n             ax.imshow(img)\n             ax.set_title(dirname.split('\/')[6])\n             #ax.axis(\"off\")\n             ax.set_xlabel(\"Image\" + str(i+1),size=15)\n             i +=1\nplt.show()","02201414":"train_dir = \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/\"\ntest_dir = \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/\"\nval_dir = \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/\"\n\nprint('num_of_classes: {} \/'.format(len(os.listdir(train_dir))),'name_of_classes: {}'.format(os.listdir(train_dir)))\nprint('num_of_train_withoutmask {}\/'.format(len(os.listdir(train_dir+'WithoutMask'))),'num_of_train_withmask {}'.format(len(os.listdir(train_dir+'WithMask'))))\n\nprint('num_of_test_withoutmask {}\/'.format(len(os.listdir(test_dir+'WithoutMask'))),'num_of_test_withmask {}'.format(len(os.listdir(test_dir+'WithMask'))))\nprint('num_of_val_withoutmask {}\/'.format(len(os.listdir(val_dir+'WithoutMask'))),'num_of_val_withmask {}'.format(len(os.listdir(val_dir+'WithMask'))))","9323eb6b":"#start=time.perf_counter()\nimg_shape=[]\n\nfor dirname,_,filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        img = cv2.imread(os.path.join(dirname,filename))\n        img_shape.append(img.shape)\nimg_shape_df=pd.DataFrame(img_shape, columns=[\"Length\",'Width',\"Channel\"])\nimg_shape_df.head()\n#stop=time.perf_counter()\n\n#print('{:0.4f} secs elapsed'.format(stop-start))","5c092d1e":"\nlist_counts=[img_shape_df.Length.value_counts()]\nprint(list_counts)\nimg_shape_df.describe()\n","b65f0379":"list_counts=[img_shape_df.Length.value_counts()]\nsns.kdeplot(img_shape_df.Length,shade=True,bw_adjust=1,fill=True,color=\"green\")\nplt.grid()\nplt.show()","20bc9c05":"h=128\nw=128\n\n\ntrain_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\ntest_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'\nval_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'\n\n\n\ntrain_datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1,\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,vertical_flip=True,fill_mode=\"nearest\")\n\ntest_datagen=ImageDataGenerator(rescale=1.\/255)\nval_datagen=ImageDataGenerator(rescale=1.\/255)\n\n\ntrain_gen=train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(h,w),\n        batch_size=32,color_mode=\"rgb\",\n        class_mode='categorical')\ntest_gen=test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(h,w),\n        batch_size=32,color_mode=\"rgb\",\n        class_mode='categorical')\nval_gen=val_datagen.flow_from_directory(val_dir,target_size=(h,w),\n                                        batch_size=32,color_mode=\"rgb\",\n                                        class_mode=\"categorical\")\n\n\n","7cf57314":"input_shape=[128,128,3]\n\ninitializer = tf.keras.initializers.GlorotUniform()\n# Sometimes using initializer can converge loss function to minima faster.The Glorot uniform initializer is also know as Xavier uniform initializer.\ndef build_model():\n    model=Sequential()\n    \n    model.add(Conv2D(32,(3,3),padding=\"same\",input_shape=input_shape,activation='relu',kernel_initializer=initializer))\n    model.add(BatchNormalization(momentum=0.90)) #axis=-1, momentum=0.99 (0.9-0.99), epsilon=0.001, center=True, scale=True,\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.3))\n    \n    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n    model.add(BatchNormalization(momentum=0.90))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.4))\n  \n    model.add(Flatten())\n    model.add(Dense((128),activation='relu'))\n    model.add(BatchNormalization(momentum=0.90))\n    model.add(Dense((64),activation='relu'))\n    model.add(Dense(2, activation='sigmoid'))\n    \n    return model\n\n    \nmodel=build_model()   \n    \nmodel.summary()   \n","2108b2d3":"   tf.keras.utils.plot_model(model,\n    to_file=\"model.png\",\n    show_shapes=True,\n    show_dtype=False,\n    show_layer_names=True,\n    rankdir='TB',\n    expand_nested=False,\n    dpi=96,)","d6e1c69b":"pip install visualkeras","1a5e2a03":"import visualkeras\n\ncolor_map = defaultdict(dict)\ncolor_map[Conv2D]['fill'] = 'lightgreen'\ncolor_map[Dropout]['fill'] = \"red\"\ncolor_map[MaxPooling2D]['fill'] = 'gray'\ncolor_map[Dense]['fill'] = 'green'\ncolor_map[Flatten]['fill'] = 'orange'\ncolor_map[BatchNormalization]['fill']=\"lightblue\"\n\nvisualkeras.layered_view(model, spacing=70,color_map=color_map,scale_xy=4, scale_z=1, max_z=100)","8d4aad03":"start=time.perf_counter()\nloss_acc_values=[]\n\nmodel=build_model()\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\n\nCheckpoints = ModelCheckpoint('model_mask.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='min', save_freq='epoch')\n\n\nEarlystop =EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 20,verbose = 1,\n                                             restore_best_weights = True)\ncallbacks=[Earlystop,Checkpoints]\nepochs=10\ntrain_numbers=10000\nvalid_numbers=800\nloss_acc_values.append(model.fit_generator(generator=train_gen,validation_data=val_gen,epochs=epochs,callbacks=callbacks,\n                                   steps_per_epoch=train_numbers\/\/32,validation_steps=valid_numbers\/\/32))\n\nmodel.save('model_mask.h5')\n\n\nstop=time.perf_counter()\n\nprint('{:0.4f} mins elapsed'.format((stop-start)\/60))\n\n","ddb7e7f0":"\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\nfor i,value in enumerate(loss_acc_values[0].history):\n    ax = axes.flatten()[i]\n    layer_num = 0\n    for history in loss_acc_values:\n        ax.plot(history.history[value],color=\"g\")\n        if value==\"val_accuracy\":\n            ax.axhspan(0.988,0.995,color=\"skyblue\",alpha=0.7)\n        elif value==\"val_loss\":\n            ax.axhspan(0.05,0.01,color=\"lightgreen\",alpha=0.7)\n    ax.set_title(value,size=15, color=\"r\",loc=\"left\")\n    ax.set_xlabel(\"Number of Epocs\")\n    ax.grid()\nplt.show()\n","60afa396":"evaluation= model.evaluate_generator(test_gen)\nprint('Accuracy on test set:', evaluation[1])\nprint('Loss on test set:', evaluation[0])","268dde24":"\nResNet_models={\"ResNet50\":ResNet50(include_top=False,input_shape=(128,128,3)),\"ResNet101\":ResNet101(include_top=False, input_shape=(128, 128, 3)),\n              'ResNet152':ResNet152(include_top=False, input_shape=(128, 128, 3)),\"ResNet50V2\":ResNet50V2(include_top=False, input_shape=(128, 128, 3)),\n              'ResNet101V2':ResNet101V2(include_top=False, input_shape=(128, 128, 3)),'ResNet152V2':ResNet152V2(include_top=False, input_shape=(128, 128, 3))}","9d2d5dc0":"start=time.perf_counter()\nall_models=[]\n\ninitializer = tf.keras.initializers.GlorotNormal()\n\nfor model_ in ResNet_models:\n    print(model_)\n    model_=ResNet_models[model_]\n    for layer in model_.layers:\n        layer.trainable=False\n    \n    model=Sequential()\n    model.add(model_)\n    \n    model.add(Flatten())\n    model.add(BatchNormalization(momentum=0.98))\n    #Using BatchNormalization can help fast and more accurate results\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(BatchNormalization(momentum=0.98))\n    model.add(Dense(64,activation='relu'))\n    model.add(Dropout(0.4))\n    \n    model.add(Dense(2,activation=\"sigmoid\"))\n   \n\n    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n    Checkpoints = ModelCheckpoint('model_mask.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='min', save_freq='epoch')\n\n\n    Earlystop =EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 20,verbose = 1,\n                                             restore_best_weights = True)\n    callbacks=[Earlystop,Checkpoints]\n    epochs=20\n    train_numbers=10000\n    valid_numbers=800\n    all_models.append(model.fit_generator(generator=train_gen,validation_data=val_gen,epochs=epochs,callbacks=callbacks,\n                                   steps_per_epoch=train_numbers\/\/64,validation_steps=valid_numbers\/\/64))\n  \nstop=time.perf_counter()\n\nprint('{:0.4f} mins elapsed'.format((stop-start)\/60))\n\n\n\n    \n\n    ","05953f7a":"\nfig, axes = plt.subplots(2, 2, figsize=(15, 15))\nfor i,value in enumerate(all_models[0].history):\n    ax = axes.flatten()[i]\n    lab=0\n    for history in all_models:\n        label=list(ResNet_models)[lab]\n        ax.plot(history.history[value],label=label)\n        if value==\"accuracy\" or value==\"val_accuracy\":\n            ax.axhspan(0.97,1,color=\"skyblue\",alpha=0.2)\n        elif value==\"loss\" or value==\"val_loss\":\n            ax.axhspan(0.1,0.01,color=\"lightgreen\",alpha=0.2)\n        lab += 1\n    ax.set_title(value,size=15, color=\"r\",loc=\"left\")\n    ax.legend()\n    ax.set_xlabel(\"Number of Epocs\")\n    ax.grid()\nplt.show()","3b07ea9c":"#  **Mask Detection With Simple CNN & 6 ResNet Architectures**","f2117cb1":"# Data Augmentation","8739c674":"**Our model performed very well on the training and validation sets with few layers. Where the validation accuracy reachs 0.99, test set comes with 0.9889 accuracy and 0.043 loss.**","2f9d2f5c":"# Visualization","523f7d32":"# Residual Convolutional Neural Networks\n\n\n\n\n![](https:\/\/www.aimspress.com\/aimspress-data\/mbe\/2020\/5\/PIC\/mbe-17-05-328-g007.jpg)\n\n\n\nResNet is one of the usefull models for image recognition tasks. Most noticable feature of this neural network architecture is some direct connections which skip middle layers rather then subsequent layer (it might vary on different ResNet models). In Keras API, there are 6 different ResNet architectures (ResNet50,ResNet101,ResNet152,ResNet50V2,ResNet101V2,ResNet152V2) which we are going to use them with Transfer Learning method. [For more information about how to use those pre-build  ResNet models in Keras](https:\/\/keras.io\/api\/applications\/resnet\/#resnet50-function)","73e3edbb":"In transfer learning, we will be only training the layers we added after flattening part.","ecbaf752":"# Conclusion","748ad472":"First of all, lets see what is in the dataset.","db1ad7f0":"***The dataset consists of 10000 training image samples. As it can be seen above, the data looks like it has balanced classes. So let's go a bit deeper and analyse the image sizes.***","acc85c00":"Now it is time to run the model.","1304610d":"\nAfter building a CNN Model, Let's visualize it to see the layers.","65dcf56b":"*In this notebook, we are going to look into a FaceMask Dataset to clasify by using CNN Models. We will be building a simple CNN model firstly and then using transfer learning with 6 ResNet Architectures as ResNet50,ResNet101,ResNet152,ResNet50V2,ResNet101V2,ResNet152V2 to compare the performances each other. If you wonder how other CNN models perform on this dataset, I do recommend you to take a look into this notebook [Detecting Face Masks with 5 models](https:\/\/www.kaggle.com\/dabawse\/detecting-face-masks-with-5-models).*","2c519cfd":"So to resize and generate more training\/val\/set samples, we use ImageDataGenerator function which is avaliable in Keras. [For more information](https:\/\/keras.io\/api\/preprocessing\/image\/#imagedatagenerator-class)","0bcaecab":"In the this notebook we compared 6 ResNet Architectures as wel as seeing simple CNN model and its result. For this task we can even pick up simple CNN model as we only did binary classification. However when we need to solve more complex problems and different applications, we can safely try other trained models as transfer learning. \n\nPlease feel free if you have any questions.","f8b9f553":"**Having looked at the results above, we can presume that all images have square shapes as lengths and widths. The mean of lengths (and widths) is 152.861. Additionally, the majority length\/width is 224 (224 x 224 x 3) but also many other lenghts are around 100 or above a bit. Therefore, we will choice the 128 x 128 x 3 dimension, rather then picking up the 224x224x3 dimensions for the training set. Because taking 224x224x3 might cause a feature loss in the entire traning set whilst its training. **","8336592a":"Having looked at the results, we can see that ResNet152V2, ResNet101V2 and ResNet50V2 performed pretty good on the validation set as the loss is quite low. Also ResNet50 has lower loss and slightly higher accuracy result than ResNet101 and ResNet152."}}