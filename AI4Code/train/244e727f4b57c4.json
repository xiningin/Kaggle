{"cell_type":{"b97455c7":"code","d61fe4c1":"code","bc99af4a":"code","66b42ada":"code","eefc2a5b":"code","f26a3f7f":"code","60fadeec":"code","8989472b":"code","b97bad48":"code","aeec7ddb":"code","e509d124":"code","46747e6f":"code","14f32778":"code","9da764be":"code","5ae2144c":"code","c22de505":"code","c88fb2dd":"code","a68ce6ed":"code","156b0bf2":"code","c9a908b9":"code","81d9d5b7":"code","1565bfb3":"code","088bf886":"code","b42f6e0a":"code","411b886a":"code","1c128d3c":"code","c6deb155":"code","4257fcfa":"code","a257ca07":"markdown","758e7619":"markdown","606dbe75":"markdown","4f63ce97":"markdown","d97d0093":"markdown","ede6f9d1":"markdown","e3bc9f30":"markdown","80416bcf":"markdown","ea4a70df":"markdown","bfb644c7":"markdown"},"source":{"b97455c7":"# Importando principais bibliotecas a serem utilizadas.\n\nimport sklearn # algoritmos para tratar os dados\nimport matplotlib.pyplot as plt #gr\u00e1ficos\nimport numpy as np # \u00e1lgebra linear\nimport pandas as pd # processamento de dados\nimport scikitplot as skplt\nfrom sklearn.model_selection import cross_val_score","d61fe4c1":"treino = pd.read_csv(\"..\/input\/spambase\/train_data.csv\" , engine='python')\nteste = pd.read_csv(\"..\/input\/spambase\/test_features.csv\" , engine='python')\ntreino.head()","bc99af4a":"treino.describe()","66b42ada":"treino.corr(method='pearson').ham.sort_values(ascending=True)","eefc2a5b":"tab = pd.crosstab(treino['ham'], treino['char_freq_$'], margins = True,\nnormalize = 'columns')\ntab","f26a3f7f":"tab2 = pd.crosstab(treino['ham'], treino['char_freq_$'], margins = True)\ntab2","60fadeec":"tab3 = pd.crosstab(treino['ham'], treino['word_freq_hp'], margins = True, normalize = \"columns\")\ntab3","8989472b":"treino[\"ham\"].value_counts()","b97bad48":"_ham = treino.query(\"ham\").drop(columns=[\"Id\"])\n_ham[\"ham\"].value_counts()\n","aeec7ddb":"_spam = treino.query(\"ham == False\").drop(columns=[\"Id\"])\n_spam[\"ham\"].value_counts()","e509d124":"_spam.describe()","46747e6f":"_ham.describe()","14f32778":"data1 = _spam[\"word_freq_your\"]\ndata2 = _spam[\"word_freq_000\"]\ndata3 = _spam[\"char_freq_$\"]\nx = np.array(range(len(data1)))\n\nplt.plot( x, data1,  color='grey', label='your')\nplt.plot( x, data2,  color='blue', label = '000')\nplt.plot( x, data3,  color='yellow', label = '$') \n\nplt.rcParams['figure.figsize'] = (10,7)\n\n\nplt.title(\"Rela\u00e7\u00e3o de frequ\u00eancias com ser spam\")\nplt.legend()\n\nplt.grid(True)\nplt.xlabel(\"e-mails spam\")\nplt.ylabel(\"frequ\u00eancia de your, 000, $ \")\nplt.show()","9da764be":"data1 = _ham[\"word_freq_your\"]\ndata2 = _ham[\"word_freq_000\"]\ndata3 = _ham[\"char_freq_$\"]\nx = np.array(range(len(data1)))\n\nplt.plot( x,data1,  color='grey', label='your') \nplt.plot( x, data2,  color='blue', label = '000')  \nplt.plot( x, data3,  color='yellow', label = '$')  \n\nplt.rcParams['figure.figsize'] = (10,7)\n\nplt.legend()\nplt.title(\"Rela\u00e7\u00e3o de frequ\u00eancias com ser ham\")\n\nplt.grid(True)\nplt.xlabel(\"e-mails ham\")\nplt.ylabel(\"frequ\u00eancia de your, 000, $ \")\nplt.show()","5ae2144c":"data1 = _ham[\"word_freq_000\"]\ndata2 = _spam[\"word_freq_000\"]\ndata3 = _ham[\"char_freq_$\"]\ndata4 = _spam[\"char_freq_$\"]\nx = np.array(range(len(data1)))\nw = np.array(range(len(data2)))\n\nplt.plot( w, data2  , color='purple', label = '000 spam') \nplt.plot( w, data4 ,color='pink', label = '$ spam') \nplt.plot( x, data3 ,color='grey', label = '$ ham')  \nplt.plot( x, data1, color='cyan', label='000 ham') \n\nplt.rcParams['figure.figsize'] = (10,7)\n\nplt.legend()\nplt.title(\"Rela\u00e7\u00e3o de frequ\u00eancias com ser ham ou spam\")\n\nplt.grid(True)\nplt.xlabel(\"e-mails\")\nplt.ylabel(\"frequ\u00eancia de 000, $ \")\nplt.show()","c22de505":"#gaussiana sem Id\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\nrtr = treino[\"ham\"]                                  #rotulos treino\natr_si = treino.drop(columns=[\"ham\",\"Id\"])           #atributos treino\ny_pred_gnb = gnb.fit(atr_si, rtr).predict(atr_si)\nprint(\"N\u00famero de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr_si.shape[0],(rtr != y_pred_gnb).sum()))\nprint(\"Erro emp\u00edrico: {:.2%}\" .format((rtr != y_pred_gnb).sum()\/atr_si.shape[0]))\nscores = cross_val_score(gnb, atr_si, rtr, cv=10, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(rtr, y_pred_gnb,cmap=\"cool\",figsize=(6,6))","c88fb2dd":"#gaussiana com Id\nrtr = treino[\"ham\"]                               #rotulos treino\natr = treino.drop(columns=[\"ham\"])                #atributos treino\ny_pred_gnb2 = gnb.fit(atr, rtr).predict(atr)\nprint(\"N\u00famero de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr.shape[0],(rtr != y_pred_gnb2).sum()))\nprint(\"Erro emp\u00edrico: {:.2%}\" .format((rtr != y_pred_gnb2).sum()\/atr.shape[0]))\nscores = cross_val_score(gnb, atr, rtr, cv=10, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(treino[\"ham\"], y_pred_gnb2,cmap=\"cool\",figsize=(6,6))","a68ce6ed":"from sklearn.naive_bayes import BernoulliNB\nbnb = BernoulliNB()\ny_pred = bnb.fit(atr, rtr).predict(atr)\nprint(\"N\u00famero de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr.shape[0],(rtr != y_pred).sum()))\nprint(\"Erro emp\u00edrico: {:.2%}\" .format((rtr != y_pred).sum()\/atr.shape[0]))\nscores = cross_val_score(bnb, atr, rtr, cv=10, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(treino[\"ham\"], y_pred,cmap=\"cool\",figsize=(6,6))","156b0bf2":"from sklearn.naive_bayes import MultinomialNB\nmnb = MultinomialNB()\ny_pred_mnb = mnb.fit(atr_si, rtr).predict(atr_si)\nprint(\"N\u00famero de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr_si.shape[0],(rtr != y_pred_mnb).sum()))\nprint(\"Erro emp\u00edrico: {:.2%}\" .format((rtr != y_pred_mnb).sum()\/atr_si.shape[0]))\nscores = cross_val_score(mnb, atr_si, rtr, cv=10, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(treino[\"ham\"], y_pred_mnb,cmap=\"cool\",figsize=(6,6))","c9a908b9":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm='brute', leaf_size=30, metric=\"canberra\",\n           metric_params=None, n_jobs=8, n_neighbors=16,\n           weights='distance')\n\n\ny_pred_knn = knn.fit(atr_si,rtr).predict(atr_si)\nprint(\"N\u00famero de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr_si.shape[0],(rtr != y_pred_knn).sum()))\nprint(\"Erro emp\u00edrico: {:.2%}\" .format((rtr != y_pred_knn).sum()\/atr_si.shape[0]))\nscores = cross_val_score(knn, atr_si, rtr, cv=10, n_jobs=8, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.3%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(rtr, y_pred_knn,cmap=\"YlOrRd\",figsize=(6,6))","81d9d5b7":"knn2 = KNeighborsClassifier(n_neighbors=5, weights=\"uniform\", \n                           algorithm=\"auto\", leaf_size=30, p=2, \n                           metric=\"minkowski\", metric_params=None, n_jobs=None)\n\ny_pred_knn2 = knn2.fit(atr, rtr).predict(atr)\nprint(\"N\u00famero de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr.shape[0],(rtr != y_pred_knn2).sum()))\nprint(\"Erro emp\u00edrico: {:.2%}\" .format((rtr != y_pred_knn2).sum()\/atr.shape[0]))\nscores = cross_val_score(knn2, atr, rtr, cv=5, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(rtr, y_pred_knn2,cmap=\"YlOrRd\",figsize=(6,6))","1565bfb3":"y_teste1 = knn.fit(atr_si,rtr).predict(teste.drop(columns=\"Id\"))\ny_probas1 = bnb.fit(atr_si,rtr).predict_proba(teste.drop(columns=\"Id\"))\nskplt.metrics.plot_roc(y_teste1,y_probas1,classes_to_plot =None,cmap=\"spring\",)\nplt.show()","088bf886":"y_teste2= bnb.fit(atr,rtr).predict(teste)\ny_probas2 = knn.fit(atr,rtr).predict_proba(teste)\nskplt.metrics.plot_roc(y_teste2,y_probas2,classes_to_plot =None,cmap=\"spring\",)\nplt.show()","b42f6e0a":"submit = pd.DataFrame({'Id':teste[\"Id\"],'ham':y_teste1[:]})\nsubmit.to_csv(\"y_teste4.csv\", index = False)\nsubmit.head()","411b886a":"def facilitador(metrica,vizinhos,pe,nome):\n    knn3 = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric=metrica,\n               metric_params=None, n_jobs=8, n_neighbors=vizinhos, p = pe,\n               weights='distance')\n\n    y_pred_knn3 = knn3.fit(atr_si,rtr).predict(atr_si)\n\n    print(\"N\u00famero de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr_si.shape[0],(rtr != y_pred_knn3).sum()))\n    print(\"Erro emp\u00edrico: {:.2%}\" .format((rtr != y_pred_knn3).sum()\/atr_si.shape[0]))\n    \n    scores = cross_val_score(knn3, atr_si, rtr, cv=10, n_jobs=8, scoring='roc_auc')\n    print(\"Score por cross validation em 10 folds : {:.3%} \".format(np.mean(scores)))\n    \n\n    predtest = knn3.fit(atr_si,rtr).predict(teste.drop(columns=\"Id\"))\n\n    submit = pd.DataFrame({'Id':teste[\"Id\"],'ham':predtest[:]})\n    submit.to_csv(nome, index = False)\n    \nfacilitador(\"rogerstanimoto\",15,2, \"predicoes.csv\")","1c128d3c":"facilitador(\"sokalsneath\",16,1,\"predsokal.csv\")","c6deb155":"facilitador(\"rogerstanimoto\",18,1,\"predroger.csv\")","4257fcfa":"facilitador(\"minkowski\",10,1,\"predmink.csv\")","a257ca07":"Este Notebook utilizou as seguintes refer\u00eancias:\n*     Python Sotfware Foundation\n*     Naive Bayes Scikit Learn\n*     Pandas Documentation\n* MatPlotLib.org\n* Scikit Learn Documentation \n","758e7619":"Percebo na tabela acima, de estat\u00edstica destritiva, que algumas palavras tem mais varia\u00e7\u00e3o quanto a m\u00e9dia, outras menos, e algumas outras informa\u00e7\u00f5es podem ser obtidas.  Verificar as frequ\u00eancias de algumas palavras chave, dentre e-mails spam ou ham, pode ser muito eficiente para diferenci\u00e1-los. Ent\u00e3o, como partida, observar a correla\u00e7\u00e3o entre frequ\u00eancia de algumas palavras e o fato do e-mail ser ham. ","606dbe75":"Primeiro, nomeando a base de treino e entendendo os dados da spambase.","4f63ce97":"Concluo que o melhor classificador, dentre os Naive Bayes testados, \u00e9 o Bernoulli Naive Bayes. Al\u00e9m de score mais alto e mais acertos emp\u00edricos, tamb\u00e9m obteve o melhor desempenho na matriz de confus\u00e3o, ou seja, cometeu bem menos do \"pior tipo de erro\", em que o classificador moveria um e-mail importante para a caixa de spam.","d97d0093":"Nas tabelas acima, foi poss\u00edvel demonstrar que certos termos, como 000 e $ se apresentam de forma bem distinta nos e-mails spam ou ham.\n\nA partir disso, vou agora separar os labels, r\u00f3tulos, dos features, atributos, para come\u00e7ar o m\u00e9todo de Naive Bayes utilizando distribui\u00e7\u00e3o gaussiana, bernoulli e multinomial, com m\u00e9dia e desvio estimados utilizando m\u00e1xima verossimilhan\u00e7a. (implementado pela biblioteca sklearn.naive_bayes)\n\nUma m\u00e9trica muito interessante para se ter \u00e9 a matriz de confus\u00e3o para cada classificador.","ede6f9d1":"Na tabela acima, informa\u00e7\u00f5es bem relevantes est\u00e3o nas primeira e \u00faltima colunas, que s\u00e3o 0.0 e All. Podemos perceber que a aus\u00eancia do caractere $ diz muito sobre o e-mail ser spam ou ham. Esse caractere, em algumas frequ\u00eancias, como 0.030 e 0.032 tem mais de 70 porcento de ocorr\u00eancia de spam, enquanto 0.035 tem ocorr\u00eancia total de spam, e 0.033 tem total ocorr\u00eancia de ham. \u00c9 preciso tomar alguns cuidados com as faixas de porcentagem para o reconhecimento de padr\u00f5es, pois algumas tem poucos exemplos de e-mails com essa caracter\u00edstica. Sem normalizar:","e3bc9f30":"Acima, pude perceber que a presenca da coluna Id atrapalhou o desempenho do classificador gaussiano. Ainda assim, o erro esta muito alto, entao tentarei outra estrategia: em vez de gaussiana, utilizar o naive bayes para distribuicoes de bernoulli. Abaixo, vemos que de fato o erro empirico diminuiu bastante, porem o Id nao faz diferenca, pois sua \"binarizacao\" seria a mesma para todos os e-mails e igual a 1.","80416bcf":"Finalmente, rumo a outra forma de classifica\u00e7\u00e3o, a **kNN**. Testei diversos par\u00e2metros para a fun\u00e7\u00e3o K vizinhos mais pr\u00f3ximos, at\u00e9 obter um inacredit\u00e1vel erro pr\u00f3ximo de zero. Dentre poss\u00edveis m\u00e9tricas, algumas testadas foram canberra, sokalmichener, jaccard e dice. Primeiro, a fun\u00e7\u00e3o com seus par\u00e2metros alterados, e depois, com par\u00e2metros Default para compara\u00e7\u00e3o:","ea4a70df":"**PMR3508 - Tarefa 2 -\nClassificador de Spam ou Ham**","bfb644c7":"Entendendo o problema : verificando quantos ham e quantos spam. O objetivo \u00e9 separ\u00e1-los e classificar de acordo com as caracter\u00edsticas que mais os diferenciam. Para come\u00e7ar, dividir os conjuntos de dados entre spam e n\u00e3o spam."}}