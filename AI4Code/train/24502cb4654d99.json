{"cell_type":{"8c75d455":"code","8b2f2d06":"code","2c70805f":"code","d308bef7":"code","feb1cef5":"code","f925dcef":"code","4c30ad7f":"code","6641c700":"code","631de14e":"code","3c71dbb5":"code","5f954e4d":"code","109b429a":"code","eb144e9c":"code","0e6c86ec":"code","13865974":"code","58e47e2b":"code","4bdb45b9":"code","dc6bfe1a":"code","efdf0967":"code","ef7186f9":"code","d42392e7":"code","6c6a2930":"code","61b213d5":"code","09fd3e05":"code","bd82afe4":"code","9e76843e":"code","8225adee":"code","93f7d9ec":"code","e2a2be33":"code","3a9d4dfa":"code","f79576fa":"code","2b0d15d8":"code","dce8c967":"code","463a187a":"code","4a699596":"markdown","4071d840":"markdown","0ea076ae":"markdown","bb68f717":"markdown","0d1df5ab":"markdown","32b7330c":"markdown","a35c9c82":"markdown","24908c1f":"markdown","9b3acf11":"markdown","3a37de4f":"markdown","1a94daf4":"markdown","19c694eb":"markdown","0ee2d284":"markdown","b0669fe2":"markdown","5fd2aab7":"markdown","36e6cf1f":"markdown","0a6a9e14":"markdown","8c514435":"markdown","35b5e11c":"markdown","eee4d235":"markdown","728d4e0d":"markdown","f3fa69cc":"markdown","fea47d29":"markdown","3465e2ba":"markdown","038852d2":"markdown","a6d85285":"markdown","decb958e":"markdown","75cc8a3f":"markdown","0c98c4c8":"markdown","3324719a":"markdown","26f60b97":"markdown","4c04a922":"markdown","02e6e962":"markdown","c4045d0d":"markdown"},"source":{"8c75d455":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8b2f2d06":"# Read 'police.csv' into a DataFrame named ri\nri = pd.read_csv(\"..\/input\/Analyzing-traffic-stops-weather-policing-activity\/police.csv\")\n\n# Examine the head of the DataFrame\nprint(ri.head())\n\n# Count the number of missing values in each column\nprint(ri.isnull().sum())","2c70805f":"# Examine the shape of the DataFrame\nprint(ri.shape)\n\n# Drop the 'county_name' and 'state' columns\nri.drop(['county_name', 'state'], axis='columns', inplace=True)\n\n# Examine the shape of the DataFrame (again)\nprint(ri.shape)","d308bef7":"# Count the number of missing values in each column\nprint(ri.isnull().sum())\n\n# Drop all rows that are missing 'driver_gender'\nri.dropna(subset=['driver_gender'], inplace=True)\n\n# Count the number of missing values in each column (again)\nprint(ri.isnull().sum())\n\n# Examine the shape of the DataFrame\nprint(ri.shape)","feb1cef5":"# Examine the head of the 'is_arrested' column\nprint(ri.is_arrested.head())\n\n# Check the data type of 'is_arrested'\nprint(ri.is_arrested.dtype)\n\n# Change the data type of 'is_arrested' to 'bool'\nri['is_arrested'] = ri.is_arrested.astype('bool')\n\n# Check the data type of 'is_arrested'\nprint(ri.is_arrested.dtype)","f925dcef":"# Concatenate 'stop_date' and 'stop_time' (separated by a space)\ncombined = ri.stop_date.str.cat(ri.stop_time,sep=' ')\n\n# Convert 'combined' to datetime format\nri['stop_datetime'] = pd.to_datetime(combined)\n\n# Examine the data types of the DataFrame\nprint(ri.dtypes)","4c30ad7f":"# Set 'stop_datetime' as the index\nri.set_index('stop_datetime', inplace=True)\n\n# Examine the index\nprint(ri.index)\n\n# Examine the columns\nprint(ri.columns)","6641c700":"# Count the unique values in 'violation'\nprint(ri.violation.value_counts())\n\n# Express the counts as proportions\nprint(ri.violation.value_counts(normalize=True))","631de14e":"# Create a DataFrame of female drivers\nfemale = ri[ri['driver_gender']=='F']\n\n# Create a DataFrame of male drivers\nmale = ri[ri['driver_gender']=='M']\n\n# Compute the violations by female drivers (as proportions)\nprint(female.violation.value_counts(normalize=True))\n\n# Compute the violations by male drivers (as proportions)\nprint(male.violation.value_counts(normalize=True))","3c71dbb5":"# Create a DataFrame of female drivers stopped for speeding\nfemale_and_speeding = ri[(ri.driver_gender == 'F') & (ri.violation=='Speeding')]\n\n# Create a DataFrame of male drivers stopped for speeding\nmale_and_speeding = ri[(ri.driver_gender == 'M') & (ri.violation=='Speeding')]\n\n# Compute the stop outcomes for female drivers (as proportions)\nprint(female_and_speeding.stop_outcome.value_counts(normalize=True))\n\n# Compute the stop outcomes for male drivers (as proportions)\nprint(male_and_speeding.stop_outcome.value_counts(normalize=True))","5f954e4d":"# Check the data type of 'search_conducted'\nprint(ri.search_conducted.dtype)\n\n# Calculate the search rate by counting the values\nprint(ri.search_conducted.value_counts(normalize=True))\n\n# Calculate the search rate by taking the mean\nprint(ri.search_conducted.mean())","109b429a":"# Calculate the search rate for female drivers\nprint(ri[ri.driver_gender =='F'].search_conducted.mean())\n\n# Calculate the search rate for male drivers\nprint(ri[ri.driver_gender =='M'].search_conducted.mean())\n\n# Calculate the search rate for both groups simultaneously\nprint(ri.groupby('driver_gender').search_conducted.mean())","eb144e9c":"# Calculate the search rate for each combination of gender and violation\nprint(ri.groupby(['driver_gender','violation']).search_conducted.mean())","0e6c86ec":"# Count the 'search_type' values\nprint(ri.search_type.value_counts())\n\n# Check if 'search_type' contains the string 'Protective Frisk'\nri['frisk'] = ri.search_type.str.contains('Protective Frisk', na=False)\n\n# Check the data type of 'frisk'\nprint(ri.frisk.dtype)\n\n# Take the sum of 'frisk'\nprint(ri.frisk.sum())","13865974":"# Create a DataFrame of stops in which a search was conducted\nsearched = ri[ri.search_conducted == True]\n\n# Calculate the overall frisk rate by taking the mean of 'frisk'\nprint(searched.frisk.mean())\n\n# Calculate the frisk rate for each gender\nprint(searched.groupby('driver_gender').frisk.mean())","58e47e2b":"# Calculate the overall arrest rate\nprint(ri.is_arrested.mean())\n\n# Calculate the hourly arrest rate\nprint(ri.groupby(ri.index.hour).is_arrested.mean())\n\n# Save the hourly arrest rate\nhourly_arrest_rate = ri.groupby(ri.index.hour).is_arrested.mean()","4bdb45b9":"# Import matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\n\n# Create a line plot of 'hourly_arrest_rate'\nhourly_arrest_rate.plot()\n\n# Add the xlabel, ylabel, and title\nplt.xlabel('Hour')\nplt.ylabel('Arrest Rate')\nplt.title('Arrest Rate by Time of Day')\n\n# Display the plot\nplt.show()","dc6bfe1a":"# Calculate the annual rate of drug-related stops\nprint(ri.drugs_related_stop.resample('A').mean())\n\n# Save the annual rate of drug-related stops\nannual_drug_rate = ri.drugs_related_stop.resample('A').mean()\n\n# Create a line plot of 'annual_drug_rate'\nannual_drug_rate.plot()\n\n# Display the plot\nplt.show()\n","efdf0967":"# Calculate and save the annual search rate\nannual_search_rate = ri.search_conducted.resample('A').mean()\n\n# Concatenate 'annual_drug_rate' and 'annual_search_rate'\nannual = pd.concat([annual_drug_rate,annual_search_rate], axis='columns')\n\n# Create subplots from 'annual'\nannual.plot(subplots=True)\n\n# Display the subplots\nplt.show()","ef7186f9":"# Create a frequency table of districts and violations\nprint(pd.crosstab(ri.district,ri.violation))\n\n# Save the frequency table as 'all_zones'\nall_zones = pd.crosstab(ri.district,ri.violation)\n\n# Select rows 'Zone K1' through 'Zone K3'\nprint(all_zones.loc['Zone K1':'Zone K3'])\n\n# Save the smaller table as 'k_zones'\nk_zones = all_zones.loc['Zone K1':'Zone K3']","d42392e7":"# Create a bar plot of 'k_zones'\nk_zones.plot(kind='bar')\n\n# Display the plot\nplt.show()","6c6a2930":"# Create a stacked bar plot of 'k_zones'\nk_zones.plot(kind='bar',stacked=True)\n\n# Display the plot\nplt.show()","61b213d5":"# Print the unique values in 'stop_duration'\nprint(ri.stop_duration.unique())\n\n# Create a dictionary that maps strings to integers\nmapping =  {'0-15 Min':8,'16-30 Min':23,'30+ Min':45}\n\n# Convert the 'stop_duration' strings to integers using the 'mapping'\nri['stop_minutes'] = ri.stop_duration.map(mapping)\n\n# Print the unique values in 'stop_minutes'\nprint(ri.stop_minutes.unique())","09fd3e05":"# Calculate the mean 'stop_minutes' for each value in 'violation_raw'\nprint(ri.groupby('violation_raw').stop_minutes.mean())\n\n# Save the resulting Series as 'stop_length'\nstop_length = ri.groupby('violation_raw').stop_minutes.mean()\n\n# Sort 'stop_length' by its values and create a horizontal bar plot\nstop_length.sort_values().plot(kind='barh')\n\n# Display the plot\nplt.show()","bd82afe4":"# Read 'weather.csv' into a DataFrame named 'weather'\nweather=pd.read_csv(\"..\/input\/Analyzing-traffic-stops-weather-policing-activity\/weather.csv\")\n\n# Describe the temperature columns\nprint(weather[['TMIN','TAVG','TMAX']].describe())\n\n# Create a box plot of the temperature columns\nweather.plot(kind='box')\n\n# Display the plot\nplt.show()","9e76843e":"# Create a 'TDIFF' column that represents temperature difference\nweather['TDIFF']=weather.TMAX - weather.TMIN\n\n# Describe the 'TDIFF' column\nprint(weather['TDIFF'].describe())\n\n# Create a histogram with 20 bins to visualize 'TDIFF'\nweather.TDIFF.plot(kind='hist',bins=20)\n\n# Display the plot\nplt.show()","8225adee":"# Copy 'WT01' through 'WT22' to a new DataFrame\nWT = weather.loc[:,'WT01':'WT22']\n\n# Calculate the sum of each row in 'WT'\nweather['bad_conditions'] = WT.sum(axis='columns')\n\n# Replace missing values in 'bad_conditions' with '0'\nweather['bad_conditions'] = weather.bad_conditions.fillna(0).astype('int')\n\n# Create a histogram to visualize 'bad_conditions'\nweather.bad_conditions.plot(kind='hist',bins=20)\n\n# Display the plot\nplt.show()","93f7d9ec":"# Count the unique values in 'bad_conditions' and sort the index\nprint(weather.bad_conditions.value_counts().sort_index())\n\n# Create a dictionary that maps integers to strings\nmapping = {0:'good', 1:'bad', 2:'bad', 3:'bad', 4:'bad',5:'worse',6:'worse',7:'worse',8:'worse',9:'worse'}\n\n# Convert the 'bad_conditions' integers to strings using the 'mapping'\nweather['rating'] = weather.bad_conditions.map(mapping)\n\n# Count the unique values in 'rating'\nprint(weather.rating.value_counts())","e2a2be33":"from pandas.api.types import CategoricalDtype\n# Create a list of weather ratings in logical order\ncats = ['good','bad','worse']\n\n# Change the data type of 'rating' to category\nweather['rating'] = weather.rating.astype(CategoricalDtype(categories=cats, ordered=True))\n\n# Examine the head of 'rating'\nprint(weather.rating.head())","3a9d4dfa":"# Reset the index of 'ri'\nri.reset_index(inplace=True)\n\n# Examine the head of 'ri'\nprint(ri.head())\n\n# Create a DataFrame from the 'DATE' and 'rating' columns\nweather_rating=weather[['DATE','rating']]\n\n# Examine the head of 'weather_rating'\nprint(weather_rating.head())","f79576fa":"# Examine the shape of 'ri'\nprint(ri.shape)\n\n# Merge 'ri' and 'weather_rating' using a left join\nri_weather = pd.merge(left=ri, right=weather_rating, left_on='stop_date', right_on='DATE', how='left')\n\n# Examine the shape of 'ri_weather'\nprint(ri_weather.shape)\n\n# Set 'stop_datetime' as the index of 'ri_weather'\nri_weather.set_index('stop_datetime', inplace=True)","2b0d15d8":"# Calculate the overall arrest rate\nprint(ri_weather.is_arrested.mean()) \n# Calculate the arrest rate for each 'rating'\nprint(ri_weather.groupby('rating').is_arrested.mean())\n# Calculate the arrest rate for each 'violation' and 'rating'\nprint(ri_weather.groupby(['violation','rating']).is_arrested.mean())","dce8c967":"# Save the output of the groupby operation from the last exercise\narrest_rate = ri_weather.groupby(['violation', 'rating']).is_arrested.mean()\n\n# Print the 'arrest_rate' Series\nprint(arrest_rate)\n\n# Print the arrest rate for moving violations in bad weather\nprint(arrest_rate.loc['Moving violation','bad'])\n\n# Print the arrest rates for speeding violations in all three weather conditions\nprint(arrest_rate.loc['Speeding'])\n","463a187a":"# Unstack the 'arrest_rate' Series into a DataFrame\nprint(arrest_rate.unstack())\n\n# Create the same DataFrame using a pivot table\nprint(ri_weather.pivot_table(index='violation', columns='rating', values='is_arrested'))","4a699596":"## Preparing the data for analysis\n### Examining the dataset","4071d840":"### Comparing arrest rates by weather rating","0ea076ae":"### Counting bad weather conditions","bb68f717":"### Tallying violations by district","0d1df5ab":"### Setting the index","32b7330c":"### Changing the data type to category","a35c9c82":"## Analyzing the effect of weather on policing","24908c1f":"### Comparing frisk rates by gender","9b3acf11":"### Selecting from a multi-indexed Series","3a37de4f":"### Comparing search rates by gender","1a94daf4":"### Counting protective frisks","19c694eb":"### Examining traffic violations","0ee2d284":"### Converting stop durations to numbers","b0669fe2":"### Reshaping the arrest rate data","5fd2aab7":"### Plotting drug-related stops","36e6cf1f":"### Adding a second factor to the analysis","0a6a9e14":"### Dropping rows","8c514435":"### Fixing a data type","35b5e11c":"### Comparing speeding outcomes by gender","eee4d235":"### Plotting the temperature difference","728d4e0d":"### Preparing the DataFrames","f3fa69cc":"### Rating the weather conditions","fea47d29":"### Calculating the hourly arrest rate","3465e2ba":"### Merging the DataFrames","038852d2":"###  Creating datetime index","a6d85285":"### Comparing violations by gender","decb958e":"### Plotting the temperature","75cc8a3f":"## Exploring the relationship between gender and policing","0c98c4c8":"### Plotting the hourly arrest rate","3324719a":"## Visual exploratory data analysis","26f60b97":"The arrest rate has a significant spike overnight, and then dips in the early morning hours.","4c04a922":"### Calculating search rate","02e6e962":"### Dropping columns","c4045d0d":"### Comparing drug and search rates"}}