{"cell_type":{"63218803":"code","46cb1181":"code","35850665":"code","7783acf0":"code","9cf4ba05":"code","f0e70317":"code","515a4af0":"code","dab2482a":"code","31858315":"code","90a8fe66":"code","44a603a3":"code","688fbf5e":"code","8944d573":"code","09c38406":"code","e6bd3462":"code","e941ba6e":"code","49e85795":"code","0cae9ddc":"code","1630e1bb":"code","f152bc21":"code","66ac5753":"code","d20916e1":"code","998e3309":"code","322f0b91":"code","3fc25496":"code","a87f3556":"code","f24037f7":"code","2bcd6b7c":"code","f736b97b":"code","d3ff9e87":"markdown","2d279975":"markdown","d200a648":"markdown","9d8416c2":"markdown","02372d86":"markdown","ba27c9dd":"markdown","fc84af07":"markdown","57c1ce7f":"markdown","ad1bc16c":"markdown","7eb8ebef":"markdown"},"source":{"63218803":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46cb1181":"import tensorflow.compat.v2.feature_column as fc\n\nimport tensorflow as tf\ntf.__version__","35850665":"# Load dataset.\ndftrain = pd.read_csv('..\/input\/titanic\/train.csv', index_col='PassengerId')\ndftest = pd.read_csv('..\/input\/titanic\/test.csv', index_col='PassengerId')","7783acf0":"dftrain","9cf4ba05":"dftest","f0e70317":"dftrain.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\ndftest.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)","515a4af0":"age_mean = int(dftrain.Age.mean())\nage_mean","dab2482a":"dftrain.Age.fillna(age_mean, inplace=True)\ndftest.Age.fillna(age_mean, inplace=True)","31858315":"print(dftrain.isna().sum())","90a8fe66":"dftrain.Embarked.mode().loc[0]","44a603a3":"dftrain.Embarked.fillna(dftrain.Embarked.mode().loc[0], inplace=True)","688fbf5e":"print(dftest.isna().sum())","8944d573":"dftest.Fare.fillna(int(dftrain.Fare.mean()), inplace=True)","09c38406":"dfeval = dftrain.sample(frac=0.2, random_state=33)\ndftrain.drop(dfeval.index, inplace=True)\ny_train = dftrain.pop('Survived')\ny_eval = dfeval.pop('Survived')","e6bd3462":"dftrain.keys()","e941ba6e":"\nCATEGORICAL_COLUMNS = ['Sex', 'SibSp', 'Parch', 'Pclass', 'Embarked']\nNUMERIC_COLUMNS = ['Age', 'Fare']\n\nfeature_columns = []\nfor feature_name in CATEGORICAL_COLUMNS:\n  vocabulary = dftrain[feature_name].unique()\n  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n\nfor feature_name in NUMERIC_COLUMNS:\n  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\nfeature_columns","49e85795":"def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n  def input_function():\n    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n    if shuffle:\n      ds = ds.shuffle(1000)\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    return ds\n  return input_function","0cae9ddc":"train_input_fn = make_input_fn(dftrain, y_train)\neval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)","1630e1bb":"ds = make_input_fn(dftrain, y_train, batch_size=10)()\nfor feature_batch, label_batch in ds.take(1):\n  print('Some feature keys:', list(feature_batch.keys()))\n  print()\n  print('A batch of class:', feature_batch['Pclass'].numpy())\n  print()\n  print('A batch of Labels:', label_batch.numpy())","f152bc21":"age_x_gender = tf.feature_column.crossed_column(['Age', 'Sex'], hash_bucket_size=100)\nderived_feature_columns = [age_x_gender]","66ac5753":"linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns+derived_feature_columns)\nlinear_est.train(train_input_fn)\nresult = linear_est.evaluate(eval_input_fn)\nresult","d20916e1":"dftest.shape","998e3309":"y_test = pd.Series( [-1] * dftest.shape[0] )\ny_test","322f0b91":"test_input_fn = make_input_fn(dftest, y_test, num_epochs=1, shuffle=False)","3fc25496":"pred_dicts = list(linear_est.predict(test_input_fn))\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\nprobs","a87f3556":"predictions = []\nfor p in probs:\n    if p < 0.5:\n        predictions.append(0)\n    else:\n        predictions.append(1)\npredictions = pd.Series(predictions)\npredictions","f24037f7":"sub_df = pd.DataFrame(data={\n    'PassengerId': dftest.index,\n    'Survived': predictions\n})\nsub_df","2bcd6b7c":"sub_df.Survived.value_counts()","f736b97b":"sub_df.to_csv('submission.csv', index=False)","d3ff9e87":"# Import TF & check version ","2d279975":"# prepare test data ","d200a648":"# Load dataset","9d8416c2":"# Split data into train and eval ","02372d86":"# Prepare data ","ba27c9dd":"# predict test data ","fc84af07":"# prepare feature columns ","57c1ce7f":"# the model","ad1bc16c":"# derived feature ","7eb8ebef":"# convert dataframe into tensor data"}}