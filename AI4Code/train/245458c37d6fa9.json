{"cell_type":{"3d8534e6":"code","03c406a3":"code","29bcf6e8":"code","c1c2cea2":"code","83a748a1":"code","09b83b78":"code","5874f528":"code","7e9ff77d":"code","0c9097ab":"code","fab43dff":"code","71149c6e":"code","eb3377b1":"code","41a68f8a":"code","0f788abf":"code","c2f0a596":"code","868b52f7":"code","a13c28a2":"code","1c322b92":"code","8aea011c":"code","a6f76285":"code","916ededc":"code","60e2ef0a":"code","ab68cbc1":"code","c7779883":"code","a8850b24":"code","acb54a78":"code","9b36426c":"code","677ef5cc":"code","fa8d256b":"code","246652f9":"code","c27631e3":"code","cdde40c5":"code","a6e06f04":"code","ae7b7ce6":"code","ff595475":"code","33774ccf":"code","18469af9":"code","956eb227":"code","f95d6aa5":"code","d8520d90":"code","4aded7cf":"code","d18be743":"code","af132f77":"code","c15b0b0c":"code","ba0d9c7d":"code","65f21b68":"code","f874205a":"code","9263bfba":"code","055965a3":"code","ef5508ef":"code","2edf5000":"code","f43ce237":"code","85ec9309":"markdown","92c73e85":"markdown","b8a090db":"markdown","ada0e694":"markdown","c8eed677":"markdown","4e976878":"markdown"},"source":{"3d8534e6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","03c406a3":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","29bcf6e8":"housing = pd.read_csv(\"..\/input\/housing-california\/housing.csv\")\nhousing.head()","c1c2cea2":"housing.info()","83a748a1":"housing['ocean_proximity'].value_counts()","09b83b78":"housing.describe()","5874f528":"housing.hist(bins=50, figsize=(20,15))\nplt.show()","7e9ff77d":"# Splitting train and test datasets\nfrom sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)","0c9097ab":"#Checking median icnome as category\n\nf = plt.figure(figsize=(10,3))\nax1 = f.add_subplot(121)\nax2 = f.add_subplot(122)\n\nhousing[\"median_income\"].hist(ax=ax1, bins=30)\nax1.title.set_text('Median income')\nax1.set_xlabel('Median income')\nax1.set_ylabel('Median income count')\n\n\n#Creating category - income_cat - with values of median_income to 5 \n\nhousing['income_cat'] = np.ceil(housing['median_income']\/1.5)\nhousing['income_cat'].where(housing['income_cat'] <5, 5.0, inplace=True)\n\nhousing['income_cat'].hist(bins=20, ax=ax2)\nax2.title.set_text('Median income')\nax2.set_xlabel('Median income')\nax2.set_ylabel('Median income count')","fab43dff":"# Stratified sampling on median_income\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in split.split(housing, housing['income_cat']):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","71149c6e":"# Propotions of income_cat\n\nhousing['income_cat'].value_counts() \/len(housing)","eb3377b1":"# Droppping column income_cat in strain\n\nfor set_ in (strat_train_set, strat_test_set):\n    set_.drop('income_cat', axis=1, inplace=True)","41a68f8a":"# Geographical plot\n\nhousing.plot(kind='scatter', x='longitude', y='latitude', alpha=0.1,\n            s=housing['population']\/100, label='Population', figsize=(10,7),\n            c='median_house_value', cmap=plt.get_cmap('jet'), colorbar=True)\n\nplt.legend()","0f788abf":"# Checking correlations - Pearson\n\ncorr_matrix = housing.corr()","c2f0a596":"housing.head()","868b52f7":"corr_matrix['median_house_value'].sort_values(ascending=False)\n\n# The biggest correlation is between median_house_value and median_income","a13c28a2":"housing.plot(kind='scatter', x='median_income', y='median_house_value', alpha=0.1, figsize=(10,7))\n\n# We can see several points for horizontal median house values. We should clean this to protect further algorithm.","1c322b92":"#Creating additional atributes\n\nhousing['rooms_per_family'] = housing['total_rooms'] \/ housing['households']\nhousing['bedrooms_per_rooms'] = housing['total_bedrooms'] \/ housing['total_rooms']\nhousing['populations_per_family'] = housing['population'] \/ housing['households']","8aea011c":"corr_matrix = housing.corr()","a6f76285":"corr_matrix['median_house_value'].sort_values(ascending=False)","916ededc":"# Preparing data into machine learning model\n\n\nhousing = train_set.drop('median_house_value', axis=1)\nhousing_labels = train_set['median_house_value'].copy()","60e2ef0a":"housing_labels.head() # only median house value","ab68cbc1":"housing.isnull().sum()","c7779883":"from sklearn.impute import SimpleImputer \n\n# Dealing with missing values - median values\nimputer = SimpleImputer(strategy='median')\n\nimputer.fit(housing.iloc[:, 4:5])\nhousing.iloc[:,4:5] = imputer.transform(housing.iloc[:,4:5])","a8850b24":"# Testing for missing values - total_bedrooms\n\nhousing.isnull().sum()","acb54a78":"# Dealing with missing values further. Ocean_proximity is string column\n\nmissing_value = [housing.latitude, housing.housing_median_age, housing.total_rooms,\n                housing.population, housing.households, housing.median_income,\n                housing.median_house_value]","9b36426c":"def missing_values(column):\n    mean = column.mean()\n    column.fillna(mean, inplace=True)\n    column.isnull().sum()\n    \nfor col in missing_value:\n    missing_values(col)","677ef5cc":"housing.isnull().sum()","fa8d256b":"housing.ocean_proximity.fillna('<1H OCEAN', inplace=True)","246652f9":"# Because in ocean_proximity values are distributed in this way i decide to fill missing value with 1H OCEAN\nhousing.ocean_proximity.hist()\n\n","c27631e3":"housing.isnull().sum()","cdde40c5":"# Changing string values into numbers - ocean_proximity\n#Changing string values into cathegorical numbers\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder=LabelEncoder()\nhousing['ocean_proximity'] = label_encoder.fit_transform(housing['ocean_proximity'])\nhousing['ocean_proximity'].value_counts()","a6e06f04":"# The aim of the problem is to predit median_house_value\n\n# Preparing predicting columns and rest columns\nhousing_ind = housing.drop('median_house_value', axis=1)\nhousing_dep = housing['median_house_value']","ae7b7ce6":"# Splitting train and test datasets\n\nX_train, X_test, y_train, y_test = train_test_split(housing_ind, housing_dep,\n                                                   test_size=0.2, random_state=42)","ff595475":"# Standarizing data - standard scaler\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","33774ccf":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\n\n# Fitting model into train set - X and y\nlin_reg.fit(X_train, y_train)\n\nprint('Intercept: ' + str(lin_reg.intercept_))\nprint('Coefficients: ' +str(lin_reg.coef_))","18469af9":"# Predicting y on test data\n\ny_pred = lin_reg.predict(X_test)","956eb227":"# We can compare test values and predicted ones\n\nprint(y_pred[:5])\nprint(y_test[:5])","f95d6aa5":"# RMSE for linear model\n\nfrom sklearn.metrics import mean_squared_error\nlin_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(lin_rmse)\n\n# Value of RMSE = 69 597$ is very high. The reason is that probably model was not trained enough\n# Features are not giving apropriate information or model is not much good","d8520d90":"# Additiotnally we can see this on plot\n\npred = pd.DataFrame({'Predicted':y_pred,'Actual':y_test})\nfig= plt.figure(figsize=(16,8))\npred = pred.reset_index()\npred = pred.drop(['index'],axis=1)\nplt.plot(pred[:50])\nplt.legend(['Actual','Predicted'])","4aded7cf":"from sklearn.tree import DecisionTreeRegressor\n\nt_reg = DecisionTreeRegressor()\nt_reg.fit(X_train, y_train)\n\ntreg_y_pred = t_reg.predict(X_test)","d18be743":"# We can compare test values and predicted ones\n\nprint(treg_y_pred[:5])\nprint(y_test[:5])","af132f77":"tree_rmse = np.sqrt(mean_squared_error(y_test, treg_y_pred))\nprint(tree_rmse)","c15b0b0c":"# Model id better than linear regression but still not satisfying\n# K-fold cross-validation\n\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(t_reg, X_train, y_train, \n                        scoring='neg_mean_squared_error', cv=10)\n\ntree_rmse_scores = np.sqrt(-scores)","ba0d9c7d":"# Checking results\n\ndef display_scores(scores):\n    print('Results: ', scores)\n    print('Mean: ', scores.mean())\n    print('Std variation: ', scores.std())\n    \ndisplay_scores(tree_rmse_scores)","65f21b68":"# Tree model is also not good idea to predict values","f874205a":"# Cross validation for linear regression\n\nlin_scores = cross_val_score(lin_reg, X_train, y_train,\n                            scoring='neg_mean_squared_error', cv=10)\n\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","9263bfba":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor()\nforest_reg.fit(X_train, y_train)\n\nforest_reg_y_pred = forest_reg.predict(X_test)\n\nprint(forest_reg_y_pred[:5])\nprint(y_test[:5])","055965a3":"forest_rmse = np.sqrt(mean_squared_error(y_test, forest_reg_y_pred))\nprint(forest_rmse)","ef5508ef":"forest_scores = cross_val_score(forest_reg, X_train, y_train, \n                        scoring='neg_mean_squared_error', cv=10)\n\nforest_rmse_scores = np.sqrt(-forest_scores)\n\ndisplay_scores(forest_rmse_scores)\n\n# Model is over-trained","2edf5000":"#  GridSearchCV\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators': [3,10,30], 'max_features': [2,4,6,8]},\n    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2,3,4]},\n]\n\nforest_reg=RandomForestRegressor()\n\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n\ngrid_search.fit(X_train, y_train)","f43ce237":"grid_search.best_params_","85ec9309":"Choosing model and training data","92c73e85":"Choosing model - Linear Regression","b8a090db":"Cheking RandomForestRegressor","ada0e694":"Deicsion Tree Regression","c8eed677":"Cleaning data","4e976878":"EDA - look on dataset"}}