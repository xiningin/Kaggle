{"cell_type":{"7a5833ab":"code","32f43b54":"code","15811ddb":"code","bbaea3fb":"code","3403194e":"code","e034a828":"code","9fe5ccd6":"code","5a07166a":"code","75c2f5a2":"code","ad02d928":"code","894cba59":"code","3949098e":"code","47f9e1d5":"code","688201aa":"code","61730033":"code","5163208f":"code","46c0a569":"code","abb9820f":"code","44e98f9b":"code","2c60056d":"code","61884559":"code","5d305c9f":"code","aa811cd5":"code","d73b1e88":"code","77e97878":"code","e2dbdfaf":"code","32c41626":"code","a926ffea":"code","9b89966d":"code","1da8d9b8":"code","e697b22a":"code","60650cea":"code","bceef5f8":"code","a7d2b6e3":"code","b28ad45e":"code","f63e418b":"code","58d434d7":"code","8baf9347":"code","3480023f":"code","16291c0d":"code","2cbf4b04":"code","e0176072":"code","ed05486c":"code","dd0f546f":"code","db7d1d3e":"code","71726b21":"code","8f2cd610":"code","8153c3aa":"code","7b7a957b":"code","542a34a3":"code","406eb95e":"code","d6fb0999":"code","047af401":"code","380f2958":"code","32ad8d55":"code","6ee33855":"code","2c7e78c6":"code","acfbfda4":"code","8dcda390":"code","c7ff5f12":"code","dc2d7b45":"code","7df3f058":"code","6d15516d":"code","d10168f5":"code","dc55c4d8":"code","c40a9617":"code","ea818d3f":"code","74a6d989":"code","963fb567":"code","0ffec99c":"code","44be2929":"code","266fabdb":"code","626bce5b":"code","8c6ca7eb":"code","d66f96bc":"code","ce1e2858":"code","6551a39a":"code","9670e6b6":"code","8c609f97":"code","914b5650":"code","ead9ff0a":"code","8df0ad2b":"code","a9bc7f49":"code","fff25b90":"code","5b63f4d6":"code","308c4751":"code","0c90aad9":"code","a1a5245e":"code","72c0e279":"code","19c91969":"code","97309b70":"code","828fe8f4":"code","4055464f":"code","07261a23":"code","4de1483e":"code","a3d9a852":"code","949033be":"code","bb13e992":"code","41e5ce79":"code","ae51ba94":"code","d6280234":"code","49c31455":"code","dfb2f499":"code","febbcd1c":"code","5f19514b":"code","2c58632d":"code","6715d9af":"code","22b7b8d9":"code","a7d8fd31":"code","36019a93":"code","6f29d40e":"code","ad6b8d04":"code","d195879f":"code","4077f280":"markdown","9aa5db70":"markdown","b363dec8":"markdown","dcc4a7e7":"markdown","a5204bd5":"markdown","a8e1d8bc":"markdown","aeae97d0":"markdown","f0148058":"markdown","f696a8c1":"markdown","0f514f5c":"markdown","6cc722d2":"markdown","54728b72":"markdown","3ebc1678":"markdown","49dced37":"markdown","f38ed824":"markdown","534e4434":"markdown","eb16f6b5":"markdown","3fedd5bf":"markdown","821516bb":"markdown","1d1f1748":"markdown","cf2e0713":"markdown","c0a3f1e0":"markdown","6a268819":"markdown","d8663a9f":"markdown","2e526505":"markdown","8995fec5":"markdown","5335c43b":"markdown","aa1f9d5d":"markdown","4fcc8a02":"markdown","8186c40e":"markdown","1eab1722":"markdown","80801adf":"markdown","3076b8e5":"markdown","856c59a2":"markdown","2b0c51d1":"markdown","fdf2c2f3":"markdown","5c086b9c":"markdown","a72c97e5":"markdown","dddae458":"markdown","aed431db":"markdown","ca031719":"markdown","448d3ca2":"markdown","a3976a7d":"markdown","2f4974bd":"markdown","71000e82":"markdown","c10806d5":"markdown","c60c289a":"markdown"},"source":{"7a5833ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","32f43b54":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","15811ddb":"attrition = pd.read_csv('\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')\nattrition.head()","bbaea3fb":"attrition.shape","3403194e":"attrition.describe()","e034a828":"attrition.info()","9fe5ccd6":"attrition.isnull().sum()","5a07166a":"attrition['Attrition'].value_counts()","75c2f5a2":"plt.figure(figsize=(10,5))\nsns.countplot(attrition['Attrition'])\nplt.show()","ad02d928":"#visualizing the distribution of data for every attributes\n\nattrition.hist(edgecolor='black',linewidth=1.2,figsize=(20,20))\nplt.show()","894cba59":"plt.figure(figsize=(20,20))\n\nplt.subplot(3,3,1)\nsns.countplot(x='BusinessTravel', hue='Attrition',data=attrition,palette='spring')\n\nplt.subplot(3,3,2)\nsns.countplot(x='Department', hue='Attrition',data=attrition,palette='summer')\n\nplt.subplot(3,3,3)\nsns.countplot(x='EducationField', hue='Attrition',data=attrition,palette='spring')\nplt.xticks(rotation=90)\n\nplt.subplot(3,3,4)\nsns.countplot(x='Gender', hue='Attrition',data=attrition,palette='summer')\n\nplt.subplot(3,3,5)\nsns.countplot(x='JobRole', hue='Attrition',data=attrition,palette='spring')\nplt.xticks(rotation=90)\n\nplt.subplot(3,3,6)\nsns.countplot(x='MaritalStatus', hue='Attrition',data=attrition,palette='summer')\n\nplt.subplot(3,3,7)\nsns.countplot(x='OverTime', hue='Attrition',data=attrition,palette='spring')\n\nplt.show()","3949098e":"plt.figure(figsize=(25,25))\nsns.heatmap(attrition.corr(),annot=True,cmap='RdYlGn')\nplt.show()","47f9e1d5":"age = pd.DataFrame(attrition.groupby('Age')[['Education','JobInvolvement','JobLevel','JobSatisfaction','MonthlyIncome',\n                        'MonthlyRate','PerformanceRating','TotalWorkingYears','WorkLifeBalance']].mean())\nage['Count'] = attrition.Age.value_counts()\nage.reset_index(level=0, inplace=True)\nage.head()","688201aa":"plt.figure(figsize=(10,8))\nsns.barplot(x=age.Age,y=age.Count)\nplt.xticks(rotation=90)\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.title('Age Count')\nplt.show()","61730033":"plt.figure(figsize=(10,8))\nsns.barplot(x=age.Age,y=age.JobSatisfaction)\nplt.xticks(rotation=90)\nplt.xlabel('Age')\nplt.ylabel('JobSatisfaction')\nplt.title('Age vs Jobsatisfaction')\nplt.show()","5163208f":"plt.figure(figsize=(10,8))\nsns.barplot(x=age.Age,y=age.MonthlyIncome)\nplt.xticks(rotation=90)\nplt.xlabel('Age')\nplt.ylabel('MonthlyIncome')\nplt.title('Age vs MonthlyIncome')\nplt.show()","46c0a569":"income = pd.DataFrame(attrition.groupby('JobRole').MonthlyIncome.mean().sort_values(ascending=False))\nincome.reset_index(level=0, inplace=True)\n\nplt.figure(figsize=(10,8))\nsns.barplot(x=income.JobRole,y= income.MonthlyIncome)\nplt.xticks(rotation=90)\nplt.xlabel('JobRole')\nplt.ylabel('MonthlyIncome')\nplt.title('Jobrole Vs Monthlyincome')\nplt.show()","abb9820f":"plt.figure(figsize=(15,8))\n\nplt.subplot(1,2,1)\nsns.countplot(x='JobRole',hue='WorkLifeBalance',data=attrition)\nplt.xlabel('JobRole')\nplt.title('Jobrole vs Worklifebalance')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nsns.countplot(x='JobRole',hue='JobSatisfaction',data=attrition)\nplt.xlabel('JobRole')\nplt.title('Jobrole vs Jobsatisfaction')\nplt.xticks(rotation=90)\n\nplt.show()","44e98f9b":"sns.pairplot(attrition,vars=['MonthlyIncome','MonthlyRate'],hue='Department',height=5)\nplt.show()","2c60056d":"labels = attrition.EducationField.value_counts().index\ncolors = ['orange','olive','slateblue','lime','hotpink','cyan']\nsizes = attrition.EducationField.value_counts().values\nplt.figure(figsize=(7,7))\nplt.pie(sizes,labels=labels,colors=colors,autopct='%1.1f%%')\nplt.title('EducationFields',fontsize=14)\nplt.show()","61884559":"plt.figure(figsize=(10,8))\nsns.boxplot(x='Department',y='MonthlyIncome',hue='MaritalStatus',data=attrition)\nplt.show()","5d305c9f":"plt.figure(figsize=(10,8))\nsns.boxplot(x='BusinessTravel',y='Age',hue='Department',data=attrition,palette='hls')\nplt.show()","aa811cd5":"plt.figure(figsize=(15,8))\nsns.violinplot(x='JobRole',y='MonthlyIncome',hue='Department',data=attrition)\nplt.xticks(rotation=90)\nplt.show()","d73b1e88":"#drop unnecessary column\nattrition = attrition.drop(['Over18','RelationshipSatisfaction','StandardHours','StockOptionLevel','TrainingTimesLastYear'],axis=1)\nattrition.head()","77e97878":"#list of variable to map\n\nvarlist = ['Attrition','OverTime']\n#defining map function\ndef binary_map(x):\n    return x.map({'Yes':1,'No':0})\n\n#Applying the function to the list\nattrition[varlist] = attrition[varlist].apply(binary_map)","e2dbdfaf":"#creating dummy variable and dropping the 1st one.\ndummy = pd.get_dummies(attrition[['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus']],drop_first=True)\n\n#adding the result in masterframe\nattrition = pd.concat([attrition,dummy],axis=1)\n\nattrition.head()","32c41626":"#drop the repeated column\nattrition = attrition.drop(['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus'],axis=1)\nattrition.head()","a926ffea":"attrition.shape","9b89966d":"from sklearn.model_selection import train_test_split ","1da8d9b8":"#putting feature variable to x\n\nX = attrition.drop(['Attrition','EmployeeNumber'],axis=1)\nX.head()","e697b22a":"#putting respond variable to y\ny = attrition['Attrition']\ny.head()","60650cea":"#splitting the data into train and test split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,test_size=0.3,random_state=100)","bceef5f8":"X_train.head()","a7d2b6e3":"y_train.head()","b28ad45e":"print(X_train.shape)\nprint(y_train.shape)","f63e418b":"attrition.columns","58d434d7":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train[['Age','DailyRate', 'DistanceFromHome', 'Education','EmployeeCount', 'EnvironmentSatisfaction',\n       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction','MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n       'OverTime', 'PercentSalaryHike', 'PerformanceRating','TotalWorkingYears','WorkLifeBalance','YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n        'YearsWithCurrManager']] = scaler.fit_transform(X_train[['Age','DailyRate', 'DistanceFromHome', 'Education',\n       'EmployeeCount', 'EnvironmentSatisfaction','HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction',\n       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked','OverTime', 'PercentSalaryHike', 'PerformanceRating'\n       ,'TotalWorkingYears','WorkLifeBalance','YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion'\n       , 'YearsWithCurrManager']])\nX_train.head()","8baf9347":"#checking the attrition rate\nattrition_rate = (sum(attrition['Attrition'])\/len(attrition['Attrition'].index))*100\nattrition_rate","3480023f":"import statsmodels.api as sm","16291c0d":"#logostic regression model\nlogm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\ny_train.values.reshape(-1,1)\nlogm1.fit().summary()","2cbf4b04":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()","e0176072":"from sklearn.feature_selection import RFE\nrfe = RFE(logreg,25)\nrfe = rfe.fit(X_train,y_train)","ed05486c":"rfe.support_","dd0f546f":"list(zip(X_train.columns, rfe.support_,rfe.ranking_))","db7d1d3e":"col = X_train.columns[rfe.support_]\nX_train.columns[~rfe.support_]","71726b21":"X_train_sm = sm.add_constant(X_train[col])\nlogm2 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm2.fit()\nres.summary()","8f2cd610":"#dropping column with high p-value\ncol = col.drop('Department_Research & Development',1)","8153c3aa":"X_train_sm = sm.add_constant(X_train[col])\nlogm3 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm3.fit()\nres.summary()","7b7a957b":"#dropping column with high p-value\ncol = col.drop('JobRole_Sales Representative',1)","542a34a3":"X_train_sm = sm.add_constant(X_train[col])\nlogm4 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm4.fit()\nres.summary()","406eb95e":"#dropping column with high p-value\ncol = col.drop('EducationField_Life Sciences',1)","d6fb0999":"X_train_sm = sm.add_constant(X_train[col])\nlogm5 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm5.fit()\nres.summary()","047af401":"#dropping column with high p-value\ncol = col.drop('MaritalStatus_Married',1)","380f2958":"X_train_sm = sm.add_constant(X_train[col])\nlogm6 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm6.fit()\nres.summary()","32ad8d55":"#dropping column with high p-value\ncol = col.drop('EducationField_Medical',1)","6ee33855":"X_train_sm = sm.add_constant(X_train[col])\nlogm7 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm7.fit()\nres.summary()","2c7e78c6":"#dropping column with high p-value\ncol = col.drop('Gender_Male',1)","acfbfda4":"X_train_sm = sm.add_constant(X_train[col])\nlogm8 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm8.fit()\nres.summary()","8dcda390":"#dropping column with high p-value\ncol = col.drop('YearsAtCompany',1)","c7ff5f12":"X_train_sm = sm.add_constant(X_train[col])\nlogm9 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm9.fit()\nres.summary()","dc2d7b45":"#dropping column with high p-value\ncol = col.drop('TotalWorkingYears',1)","7df3f058":"X_train_sm = sm.add_constant(X_train[col])\nlogm10 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm10.fit()\nres.summary()","6d15516d":"#dropping column with high p-value\ncol = col.drop('BusinessTravel_Travel_Rarely',1)","d10168f5":"X_train_sm = sm.add_constant(X_train[col])\nlogm11 = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm11.fit()\nres.summary()","dc55c4d8":"#check for VIF values of the feature variables\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","c40a9617":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","ea818d3f":"#getting predict on train set\ny_train_pred = res.predict(X_train_sm)\ny_train_pred[:10]","74a6d989":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred[:10]","963fb567":"y_train_pred_final = pd.DataFrame({'Attrition':y_train.values, 'Attrition_prob':y_train_pred})\ny_train_pred_final['EmployeeNumber'] = y_train.index\ny_train_pred_final.head()","0ffec99c":"#rearrange column\ny_train_pred_final = y_train_pred_final.reindex(['EmployeeNumber','Attrition','Attrition_prob'],axis=1)\ny_train_pred_final.head()","44be2929":"y_train_pred_final['predicted'] = y_train_pred_final.Attrition_prob.map(lambda x:1 if x>0.5 else 0)\ny_train_pred_final.head()","266fabdb":"from sklearn import metrics","626bce5b":"#confusion metrics\n\nconfusion = metrics.confusion_matrix(y_train_pred_final.Attrition,y_train_pred_final.predicted)\nprint(confusion)","8c6ca7eb":"#Overall accuracy\nprint(metrics.accuracy_score(y_train_pred_final.Attrition,y_train_pred_final.predicted))","d66f96bc":"TP = confusion[1,1]\nTN = confusion[0,0]\nFP = confusion[0,1]\nFN = confusion[1,0]","ce1e2858":"#Sensitivity\nTP\/float(TP+FN)","6551a39a":"#specificity\nTN\/float(TN+FP)","9670e6b6":"#false positive rate\nFPR = FP\/float(TN+FP)\nprint(FPR)\n\n#positive predicted value\nPPV = TP\/float(TP+FP)\nprint(PPV)\n\n#Negative predicted value\nNPV = TN\/float(TN+FN)\nprint(NPV)","8c609f97":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve(area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","914b5650":"fpr,tpr,thresholds = metrics.roc_curve(y_train_pred_final.Attrition,y_train_pred_final.Attrition_prob,drop_intermediate=False)","ead9ff0a":"draw_roc(y_train_pred_final.Attrition,y_train_pred_final.Attrition_prob)","8df0ad2b":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Attrition_prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","a9bc7f49":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Attrition, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","fff25b90":"#plot\ncutoff_df.plot.line(x='prob',y=['accuracy','sensi','speci'])\nplt.show()","5b63f4d6":"y_train_pred_final['final_predicted'] = y_train_pred_final.Attrition_prob.map( lambda x: 1 if x > 0.2 else 0)\n\ny_train_pred_final.head()","308c4751":"#Accuracy\nTrain_accuracy = metrics.accuracy_score(y_train_pred_final.Attrition,y_train_pred_final.final_predicted)\nTrain_accuracy","0c90aad9":"confusion2 = metrics.confusion_matrix(y_train_pred_final.Attrition,y_train_pred_final.final_predicted)\nprint(confusion2)","a1a5245e":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] #false negative","72c0e279":"#Sensitivity\nTrain_sensitivity = TP\/float(TP+FN)\nTrain_sensitivity","19c91969":"#Specificity\nTrain_specificity = TN\/float(TN+FP)\nTrain_specificity","97309b70":"#false positive rate\nFPR = FP\/float(TN+FP)\nprint(FPR)\n\n#positive predicted value\nPPV = TP\/float(TP+FP)\nprint(PPV)\n\n#Negative predicted value\nNPV = TN\/float(TN+FN)\nprint(NPV)","828fe8f4":"#looking at the confusion matrix again\n\nconfusion = metrics.confusion_matrix(y_train_pred_final.Attrition,y_train_pred_final.predicted)\nprint(confusion)","4055464f":"#precision\nprecision = confusion[1,1]\/(confusion[0,1]+confusion[1,1])\nprecision","07261a23":"#Recall\nrecall = confusion[1,1]\/(confusion[1,0]+confusion[1,1])\nrecall","4de1483e":"from sklearn.metrics import precision_recall_curve ","a3d9a852":"y_train_pred_final.Attrition,y_train_pred_final.final_predicted\n\np, r, thresholds = precision_recall_curve(y_train_pred_final.Attrition, y_train_pred_final.Attrition_prob)","949033be":"plt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.show()","bb13e992":"X_test[['Age','DailyRate', 'DistanceFromHome', 'Education','EmployeeCount', 'EnvironmentSatisfaction',\n       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction','MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n       'OverTime', 'PercentSalaryHike', 'PerformanceRating','TotalWorkingYears','WorkLifeBalance','YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n        'YearsWithCurrManager']] = scaler.transform(X_test[['Age','DailyRate', 'DistanceFromHome', 'Education',\n       'EmployeeCount', 'EnvironmentSatisfaction','HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction',\n       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked','OverTime', 'PercentSalaryHike', 'PerformanceRating'\n       ,'TotalWorkingYears','WorkLifeBalance','YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion'\n       , 'YearsWithCurrManager']])\nX_test = X_test[col]\nX_test.head()","41e5ce79":"X_test_sm = sm.add_constant(X_test)","ae51ba94":"y_test_pred = res.predict(X_test_sm)\ny_test_pred[:10]","d6280234":"#converting y_test_pred into dataframe\ny_pred1 = pd.DataFrame(y_test_pred)\ny_pred1.head()","49c31455":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)\n\n#putting prospect ID\ny_test_df['EmployeeNumber'] = y_test_df.index\n\n#appending y_test_df and y_pred1\ny_pred_final = pd.concat([y_test_df, y_pred1],1)\n\ny_pred_final.head()","dfb2f499":"#Renaming column\ny_pred_final = y_pred_final.rename(columns={0:'Attrition_prob'})\ny_pred_final.head()","febbcd1c":"#Rearranging column\ny_pred_final = y_pred_final.reindex(['EmployeeNumber','Attrition','Attrition_prob'],axis=1)\ny_pred_final.head()","5f19514b":"y_pred_final['final_predicted'] = y_pred_final.Attrition_prob.map(lambda x:1 if x>0.2 else 0)\ny_pred_final.head()","2c58632d":"#accuracy\nTest_accuracy = metrics.accuracy_score(y_pred_final.Attrition, y_pred_final.final_predicted)\nTest_accuracy","6715d9af":"Confusion2 = metrics.confusion_matrix(y_pred_final.Attrition,y_pred_final.final_predicted)\nconfusion2","22b7b8d9":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","a7d8fd31":"#Test sensitivity\nTest_sensitivity = TP \/ float(TP+FN)\nTest_sensitivity","36019a93":"#Test specificity\nTest_specificity = TN \/ float(TN+FP)\nTest_specificity","6f29d40e":"from sklearn.metrics import precision_score, recall_score\n\nprecision = precision_score(y_pred_final.Attrition,y_pred_final.final_predicted)\nprecision","ad6b8d04":"recall = recall_score(y_pred_final.Attrition,y_pred_final.final_predicted)\nrecall","d195879f":"print(\"Train Accuracy: {} %\" .format(round((Train_accuracy*100),2)))\nprint(\"Train sensitivity: {} %\" .format(round((Train_sensitivity*100),2)))\nprint(\"Train specificity: {} %\" .format(round((Train_specificity*100),2)))\nprint(\"Test Accuracy: {} %\" .format(round((Test_accuracy*100),2)))\nprint(\"Test Sensitivity: {} %\" .format(round((Test_sensitivity*100),2)))\nprint(\"Test Specificity: {} %\" .format(round((Test_specificity*100),2)))","4077f280":"## **Data Description**","9aa5db70":"2. Analysis of Jobrole with MonthlyIncome","b363dec8":"Making prediction on test sets","dcc4a7e7":"![image.png](attachment:image.png)","a5204bd5":"## **Explanatory Data Analysis**","a8e1d8bc":"## **Plotting ROC curve**","aeae97d0":"6. Bivariate analysis of Employee Department,monthlyincome & marital status","f0148058":"![image.png](attachment:image.png)","f696a8c1":"## **Making Prediction on Test Set**","0f514f5c":"There is no null values in our dataset.Hence we can proceed further.","6cc722d2":"Now all variables are good with p-value and vifs. Hence we can proceed for the prediction.","54728b72":"## **Model Building**","3ebc1678":"## **Finding optimal cutoff**","49dced37":"5. Analyse of Educational feild percentage","f38ed824":"Row :1470\nColumn : 35","534e4434":"## **Precision & Recall**","eb16f6b5":"## **Numerical Analysis of dataset**","3fedd5bf":"## **Metrics beyond Simple Accuracy**","821516bb":"## **Import Libraries**","1d1f1748":"7.Bivariate analyse BusinessTravel, age & department","cf2e0713":"Assesing the model with Stasmodel","c0a3f1e0":"## **Train-Test Split**","6a268819":"Creating a dataframe with actual attrition and predicted probabilities.","d8663a9f":"p-value of 'JobRole_Sales Representative' is 0.466. we can drop it.","2e526505":"3. Analysis of JobRole with worklifebalance & Jobsatisfaction","8995fec5":"## **Feature Scaling**","5335c43b":"We having 16.12% attrition rate.","aa1f9d5d":"p-value of 'EducationField_Life Sciences' is 0.269. Hence we can dop it","4fcc8a02":"## **Heatmap**","8186c40e":"8. Analysis of employee jobrole with department & monthlyincome","1eab1722":"* We have finalize some features, where we can concentrate more to decrese our attrition rate for company.\n* Features are: YearsInCurrentRole,YearsWithCurrManager,YearsSinceLastPromotion,JobLevel, MaritalStatus_Single,JobRole_Laboratory Technician, Department_Sales, BusinessTravel_Travel_Frequently, EducationField_Technical Degree, NumCompaniesWorked,JobRole_Human Resources, OverTime, EnvironmentSatisfaction, JobInvolvement,JobSatisfaction, DistanceFromHome.\n* Hence our main motto is to decrease 'Yes': 1 (Attrition rate) and  increase 'No':0(Attrition rate).\n* We should more focus on 'Specificity'to decrease attrition rate.","80801adf":"p-value of 'YearsAtCompany' is 0.053. drop it","3076b8e5":"p-value of variable 'Department_Research & Development' is 0.999, we can drop it.","856c59a2":"* Employee attrition is defined as the natural process by which employees leave the workforce \u2013 for example, through resignation for personal reasons or retirement \u2013 and are not immediately replaced.\n* Some forms of attrition are unavoidable, like if an employee is retiring or is moving to another city. But after a certain threshold, attrition can make a big dent in company\u2019s bottom line as well as its culture. \n* Attrition is an inevitable part of any business. There will come a time when an employee wants to leave the company \u2013 for either personal or professional reasons.\n\n* In this dataset there are few attributes which may reasons for the attrition in given company. Therefore, we have analysed some data visualization and predictive modelling to see if we can predict employee attrition in certain company.\n* My notebook structured as follows:\n\n> 1.\tImport Libraries\n2.\tData Description\n3.\tChecking for Null values\n4.\tExplanatory data analysis\n5.\tData preparation\n6.\tTrain-Test split\n7.\tScaling variables\n8.\tModel Building using Logistic Regression\n9.\tConfusion matrix\n10.\tMetrics beyond simple accuracy\n11.\tPlotting ROC curve and finding optimal cutoff\n12.\tPrecision & Recall\n13.\tMaking Prediction on test set\n14.\tConclusion\n","2b0c51d1":"Creating new colum 'predicted' with 1 if Attrition_prob>0.5 else 0","fdf2c2f3":"## **Checking for null values**","5c086b9c":"**Checking VIFs**","a72c97e5":"p-value of 'EducationField_Medical' is 0.084. drop it","dddae458":"p-value of 'Gender_Male' is 0.073. drop it.","aed431db":"## **Categorical Analysis**","ca031719":"p-value of 'MaritalStatus_Married' is 0.176. hence drop it.","448d3ca2":"> **Observation:**\n* **BusinessTravel:** Employees, who travel frequesntly more likly to quit than other employee.\n* **Department:** Research & Development department employee more likely to stay than other department. \n* **Education Field:** The employees with 'Medical' & 'life science' are more likely to stay, on the other hand the employess with 'Marketing' & 'Technical Degree'having more chances to quit their job. \n* **Gender:** Male attrition rate is more than Female. \n* **JobRole:** The jobrole having 'Sales executive','Sales representative','Laboratory Technician'are more likely to quit their jobs.\n* **MaritalStatus:** The 'Married' employees are more likely to stay in job other than 'Single' & 'Divorce'.\n* **Overtime:** The employees who work more hours are likely to quit than others.","a3976a7d":"**1. Analysis few attributes with 'Age'** ","2f4974bd":"## **Conclusion**","71000e82":"## **Confusion Matrix**","c10806d5":"## **Data Preparation**","c60c289a":"4. Analysis of Month;yincome & monthlyrate with department"}}