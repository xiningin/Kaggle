{"cell_type":{"9657c454":"code","0ad06ad3":"code","8688e009":"code","a41297b7":"code","34e1f3dc":"code","088b1d3e":"code","1d83723a":"code","1c729a8e":"code","68fc0039":"code","3f7b616a":"code","139fbdbe":"code","baf11812":"code","4e64e676":"code","93e84375":"code","26702742":"code","45468bd7":"code","d2641c78":"code","41bdb64a":"code","3ac60875":"markdown","1b35e3d7":"markdown","a9d3fcae":"markdown","f61aae02":"markdown","db5bd252":"markdown","0f431075":"markdown","eece758f":"markdown","630e7639":"markdown","3a8491eb":"markdown","7f810098":"markdown","40bdd5db":"markdown","ad1ce763":"markdown","dd6a4165":"markdown","8bc3ede3":"markdown"},"source":{"9657c454":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.contrib.keras import models\nfrom tensorflow.contrib.keras import layers\nfrom tensorflow.contrib.keras import losses,optimizers,metrics\n\n%matplotlib inline\nsns.set_style('whitegrid')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0ad06ad3":"voice = pd.read_csv('..\/input\/voice.csv')\n\nprint(voice.columns)\nvoice.head()","8688e009":"voice.describe()","a41297b7":"voice = pd.get_dummies(voice)\nvoice.drop('label_male',axis=1,inplace=True)\nvoice.head()","34e1f3dc":"# change label if you want\nvoice['label'] = voice['label_female']\nvoice.drop('label_female',axis=1,inplace=True)","088b1d3e":"plt.figure(figsize=[16,9])\nmask = np.ones_like(voice.corr())\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(voice.corr(),mask=mask,vmin=-1,vmax=1,cmap='coolwarm',annot=True,linewidths=0.5)","1d83723a":"voice.drop('centroid',axis=1,inplace=True)","1c729a8e":"plt.figure(figsize=[9,6])\nsns.boxplot(x='label',y='meanfreq',data=voice)\nplt.xticks([0,1],['male','female'])\nplt.xlabel(xlabel=None)","68fc0039":"plt.figure(figsize=[9,6])\nsns.boxplot(x='label',y='meanfun',data=voice)\nplt.xticks([0,1],['male','female'])\nplt.xlabel(xlabel=None)","3f7b616a":"voice_data = voice.drop('label',axis=1)\nvoice_label = voice['label']","139fbdbe":"X_train, X_test, y_train, y_test = train_test_split(voice_data,voice_label,test_size=0.3)","baf11812":"scaler = MinMaxScaler()\n# only train the scaler on the training data\nscaled_x_train = scaler.fit_transform(X_train)\nscaled_x_test = scaler.transform(X_test)\n\nprint('Scaled training data shape: ',scaled_x_train.shape)","4e64e676":"dnn_keras_model = models.Sequential()","93e84375":"# can play around with the number of hidden layers but I found that one hidden layer was more than enough to give great metrics\ndnn_keras_model.add(layers.Dense(units=30,input_dim=19,activation='relu'))\n# dnn_keras_model.add(layers.Dense(units=30,activation='relu'))\ndnn_keras_model.add(layers.Dense(units=20,activation='relu'))\ndnn_keras_model.add(layers.Dense(units=10,activation='relu'))\ndnn_keras_model.add(layers.Dense(units=2,activation='softmax'))","26702742":"# compile model by selecting optimizer and loss function\ndnn_keras_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","45468bd7":"# train\/fit the model\ndnn_keras_model.fit(scaled_x_train,y_train,epochs=50)","d2641c78":"predictions = dnn_keras_model.predict_classes(scaled_x_test)","41bdb64a":"print('Metric for ')\nprint('Classification report:')\nprint(classification_report(predictions,y_test))\nprint('\\n')\nprint('Confusion matrix:')\nprint(confusion_matrix(predictions,y_test))\nprint('\\n')\nprint('Accuracy score is {:6.3f}.'.format(accuracy_score(predictions,y_test)))","3ac60875":"#### Read in data\n\nLook at standard description and information on dataset","1b35e3d7":"### Preprocessing 2\n\nNow onto the second part of preprocessing and separation of data from labels","a9d3fcae":"Now we can make our predictions with the test set","f61aae02":"Split the data into training and testing sets. For now just do training and testing but later split into 3: train, validation, and test.","db5bd252":"What would be cool is to check how seperable the label is for some of these higher correlation features. Can use some boxplots for this. Or if you want a massive pairplot. We will only do two boxplots here.","0f431075":"### Data exploration\n\nLet's begin exporing the data. First we can check for correlations.","eece758f":"From the correlation heatmap we can see a few things:\n1. *meanfun* seems to have the strongest correlation with the label\n2. Other feautures with correlations above abs(0.3) are *meanfreq, sd, Q25, IQR, sp.ent, sfm,* and * centroid*\n3. *Q75, skew, kurt* and *modindx* essentially have no correlation i.e. they are \"independent\" with regards to sex\n4. *centroid* and *meanfreq* are pefectly correlated as they are the same","630e7639":"## Gender Voice recognition using Tensorflow and Keras\n\nThis is my first Kernel for a Kaggle dataset. Will perform some exploratory data analysis and then move ahead with classification using Tensorflow and Keras.\n\nAlways happy to learn so please feel free to give feedback and thoughts! Thanks","3a8491eb":"Now scale the data for use in a neural network","7f810098":"*meanfun* seems to be able to separate the data really well.","40bdd5db":"Now start neural network model definition. We have 19 input features and we want our output to classify the data for either male or female. We therefore need two outputs using 'softmax' activation function. The hidden layers will use the standard 'relu' activation function.","ad1ce763":"We can remove *centroid* as we dont want to train on the \"same\" feature twice","dd6a4165":"So with the above setup, we are getting about 98% accuracy, precision and recall which is pretty good!","8bc3ede3":"### Preprocessing 1\nThe above shows us that all the data is numerical except for the 'label' column. In order to train the neural netowrk we will need to change the labels to a numeric form. Let's do this by using Male == 0 and Female == 1."}}