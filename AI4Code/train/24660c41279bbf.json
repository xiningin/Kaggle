{"cell_type":{"a2c29c2d":"code","ad239694":"code","c6a671af":"code","4efbb958":"code","c0515a95":"code","1a738cbd":"code","7c6a1325":"code","72c3159e":"code","3872204c":"code","d0e99d77":"code","79d786fd":"code","9951ca0d":"code","2d8f94fd":"code","bc8c226b":"code","fadfd5f6":"code","ee45e771":"code","2b23b61c":"code","0396b0cb":"code","0fa2edce":"code","086ecb36":"code","888dfd5d":"code","c95c1bb5":"code","b8a287ef":"code","4e62d4ff":"code","824e1efc":"code","258701b3":"code","816d39e3":"code","247e5674":"markdown","a542b3e3":"markdown","f3ff3861":"markdown","3b61889c":"markdown","45a43c83":"markdown","800f0ed3":"markdown","d3bfc78e":"markdown"},"source":{"a2c29c2d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nimport cupy\nimport spacy\nfrom sklearn.preprocessing import StandardScaler\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad239694":"main_path = '\/kaggle\/input\/nlp-getting-started\/'\ntrain = pd.read_csv(main_path + 'train.csv', index_col = 'id')\ntest =  pd.read_csv(main_path + 'test.csv', index_col = 'id')","c6a671af":"# See the train data\ntrain.head()","4efbb958":"# view the test data\ntest.head()","c0515a95":"train['keyword'].isna().sum(), test['keyword'].isna().sum()","1a738cbd":"train['keyword'].value_counts()","7c6a1325":"# As a test, I'll fill the NA for the keyword column with 'neutral'\ntrain['keyword'].fillna('neutral', inplace = True)\ntest['keyword'].fillna('neutral', inplace = True)","72c3159e":"# I wont use the location column so I will drop it\ntrain.drop(['location'], inplace = True, axis =1)\ntest.drop(['location'], inplace = True, axis =1)","3872204c":"test.head()","d0e99d77":"# Data without the other columns\ntrain.head()","79d786fd":"# Setup X and Y\nX = train[['keyword', 'text']]\ny = train.target.values\n\n# Train test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 11)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","9951ca0d":"# Need to load the large model to get the vectors\nnlp = spacy.load('en_core_web_lg')","2d8f94fd":"def make_embedding(texts):\n\n    with nlp.disable_pipes():\n        embeddings = [cupy.asnumpy(nlp(text).vector) for text in texts]\n        embeddings = np.array(embeddings)\n        \n        return embeddings","bc8c226b":"# make the embeddings on the train data and process it\ndef process_train(train):\n    # Make the word embedding \n    train = make_embedding(train)\n    \n    # Center the vectors by substracting the mean \n    mean = train.mean(axis = 0)\n    train = train - mean\n    \n    # Scaling the data\n    scaler = StandardScaler()\n    scaler.fit(train)\n    train = scaler.transform(train)\n    \n    return scaler,mean, train","fadfd5f6":"# Processing the texts from the train data\ntxt_scaler, txt_mean, train_txt= process_train(X_train.text.values)\n# Processing the keywords from the test data\nkw_scaler, kw_mean, train_kw = process_train(X_train.keyword.values)\n\n# Join the keywordws and the texts, each element will be an array of [text, keyword]\ntrain_data = np.array(list(zip(train_txt,train_kw)))\ntrain_data.shape","ee45e771":"def process_texts( scaler, texts, mean):\n    # Create the text embedding\n    texts = make_embedding(texts)\n    \n    # Center the vectors by substracting the mean of the train data\n    texts = texts - mean\n    \n    # Scale the data with sklearn's standardScaler fitted on the train data\n    texts = scaler.transform(texts)\n    \n    return texts","2b23b61c":"X_test.head()","0396b0cb":"# The same as for the train data but with the validation data\nval_txt = process_texts( txt_scaler, X_test.text.values, txt_mean)\nval_kw = process_texts( kw_scaler, X_test.keyword.values, kw_mean)\n\nval_data = np.array(list(zip(val_txt,val_kw)))\nval_data.shape","0fa2edce":"# Making the classifier keras model\nkeras_clf = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(2, 300)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.6),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(2, activation=\"softmax\")\n])\n\nkeras_clf.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n              metrics=['accuracy'])","086ecb36":"tf.random.set_seed(14)\n\n# Fitting the keras model\nkeras_clf.fit(train_data, y_train, epochs=29, validation_split = 0.1)","888dfd5d":"def keras_model_predict(texts):\n    preds = keras_clf.predict(texts)\n    preds = [a.argmax() for a in preds]\n    \n    return preds","c95c1bb5":"keras_train_preds = keras_model_predict(train_data)\nprint(classification_report(y_train, keras_train_preds, target_names=['not_disaster', 'disaster']))","b8a287ef":"keras_val_preds = keras_model_predict(val_data)\nprint(classification_report(y_test, keras_val_preds, target_names=['not_disaster', 'disaster']))","4e62d4ff":"# Making the test data\ntest_txt = process_texts( txt_scaler, test.text.values, txt_mean)\ntest_kw = process_texts( kw_scaler, test.keyword.values, kw_mean)\n\ntest_data = np.array(list(zip(test_txt,test_kw)))\ntest_data.shape","824e1efc":"# predicting on the test data\nkeras_test_preds = keras_model_predict(test_data)\nkeras_test_preds[:20]","258701b3":"keras_submission = pd.DataFrame({\n    'id': test.index,\n    'target': keras_test_preds\n})\nkeras_submission","816d39e3":"keras_submission.to_csv('submission.csv', index = False)","247e5674":"### Function for making the embeddings","a542b3e3":"# Keras model with word embeddings","f3ff3861":"## Function for predicting with the keras model and get the predicted label","3b61889c":"## Evaluating the keras model on train data","45a43c83":"## Evaluating the keras model on validation data","800f0ed3":"## Train-Test Split","d3bfc78e":"# Loading the data"}}