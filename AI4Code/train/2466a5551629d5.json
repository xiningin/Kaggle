{"cell_type":{"92938015":"code","3d6da65b":"code","5b3917c0":"code","5f5928e9":"code","3b3fcdda":"code","ab71cff9":"code","a3054abe":"code","f355299f":"code","fcdbde2e":"code","dcfedacf":"code","56f74ae1":"code","1138cc06":"code","94d9ef72":"code","178f54d7":"code","75e61579":"code","d96df5ab":"code","915f1e0f":"code","89966346":"code","4feece21":"code","e9757f5e":"code","96f0e173":"code","5ad9d149":"code","b10c6d25":"code","397fe088":"code","6da40215":"code","effc2ecb":"code","e5b03110":"code","88ef331b":"code","1ea2a0a2":"code","a918a206":"code","4c3820d3":"code","bc7ec379":"code","5b882219":"code","360b30fc":"code","59ae86a9":"code","74b7bad5":"code","97613a50":"code","4c5192e7":"code","9be9e96a":"code","19d8eded":"code","8d3584a5":"markdown","6b2e3d8a":"markdown","2c00c9da":"markdown","e5bbe14a":"markdown","b121a760":"markdown","6fa79bc6":"markdown","148fdb78":"markdown","0de15edd":"markdown","fa090a23":"markdown","ab763a95":"markdown","0fa85799":"markdown","b860ac4b":"markdown","06c7c6cd":"markdown","47f19bd9":"markdown","1c78687c":"markdown","7690b34d":"markdown","ab2415cd":"markdown","e6782399":"markdown","072a5f4c":"markdown","ed4b9e8b":"markdown","7e7f0f5a":"markdown","0ac8e830":"markdown","899944ab":"markdown","71f248e1":"markdown","2708a644":"markdown","e4871cce":"markdown","4b7bb2b8":"markdown","41431cd1":"markdown","14c5fa1e":"markdown"},"source":{"92938015":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3d6da65b":"import pandas as pd   # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np    # linear algebra\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.pyplot import figure, show\nfrom wordcloud import WordCloud\nimport plotly.graph_objects as go\n# i installed (Folium+wordcloud) module from Anaconda prompt = pip3 install folium\nimport folium \nfrom folium import Choropleth, Circle, Marker\nfrom folium.plugins import HeatMap, MarkerCluster\nimport os  # accessing directory structur\nimport math\nimport time\nfrom matplotlib import cm\nimport pylab as pl\n\n%matplotlib inline","5b3917c0":"#Read our Dataset that we get from Kaggle website\ndf = pd.read_csv('\/kaggle\/input\/crimes-in-boston\/crime.csv', encoding='latin-1')","5f5928e9":"#print the first fifth rows of my DataFrame \ndf.head()","3b3fcdda":"# we can see there are some null values\n# columns with numerical values are type int64\/float64, while text\/string values are object\ndf.info()","ab71cff9":"# count the missing values\ndf.isna().sum() ","a3054abe":"# drop some columns beacuse its unnecessery for me and its values are missed\ncrime_df = df.drop(['SHOOTING','OFFENSE_CODE'], axis=1)\ncrime_df.head()","f355299f":"#droping missing values in all Raw that contain Null value\ncrime_df.dropna(how='any',inplace=True)\n'''\nThere are many ways to drop null values: by using subset to drop only a null valuue in each column\ncrime_df.dropna(subset=['STREET'],inplace=True) \ncrime_df.dropna(subset=['Lat'],inplace=True) \ncrime_df.dropna(subset=['Long'],inplace=True) \n'''\n#make sure to drop duplicated data\ncrime_df.drop_duplicates(subset=\"INCIDENT_NUMBER\", inplace=True)","fcdbde2e":"#detect missing values again\ncrime_df.isna().sum()","dcfedacf":"#print statix information for all int\/float columns \ncrime_df.describe()","56f74ae1":"#print number of unique variables were found for each columns.\ncrime_df.apply(pd.Series.nunique)","1138cc06":"#first call the colums, and rename it to be more readable\ncrime_df.columns","94d9ef72":"crime_df.rename(columns={'INCIDENT_NUMBER':'Incident_num', 'OFFENSE_CODE_GROUP':\"Group\", 'OFFENSE_DESCRIPTION':\"Description\",\n       'DISTRICT':\"District\", 'REPORTING_AREA':\"Reporting_Area\", 'OCCURRED_ON_DATE':\"Date\", 'YEAR':\"Year\", 'MONTH':\"Month\",\n       'DAY_OF_WEEK':\"Day\", 'HOUR':\"Hour\", 'UCR_PART':\"UCR_Part\", 'STREET':\"Street\", 'Lat':\"Lati\", 'Long':\"Longi\", 'Location':\"Location\"}, inplace=True)","178f54d7":"#Check the data type for each columns, if we need to modify a column's type \ncrime_df.dtypes","75e61579":"#print the unique values for the column 'Group' and see if we need to use a Strip()\ncrime_df.Group.unique()","d96df5ab":"#create a dataframe for only 2016 & 2017 years\ndf_2016_2017=crime_df.loc[crime_df.loc[:,'Year'].between(2016,2017)].copy()\ndf_2016_2017.head()","915f1e0f":"#using groupby(Year) to display the common crimes during the years 2016,2017, sorted in descending order\ncrime_years =df_2016_2017.groupby('Year')['Group']\ncrime_years.value_counts().sort_values(ascending=False).head(6)","89966346":"#using .get_group (), for more datails in each year which most frequent crimes \n\n#print the most common crimes in year 2016\ncrime_df_2016=crime_years.get_group(2016).value_counts().sort_values(ascending=False).head(5)\n\n#print the most common crimes in year 2017\ncrime_df_2017=crime_years.get_group(2017).value_counts().sort_values(ascending=False).head(5)\n","4feece21":"crime_df_2016","e9757f5e":"crime_df_2017","96f0e173":"#Top Ten crimes that happned over the years 2016 and 2017\n#Check how many counts per unique value of Group\n\ntop_10=df_2016_2017['Group'].value_counts().sort_values(ascending=False).head(10)\ntop_10","5ad9d149":"# plot the Top Ten common crimes during the years 2016,2017\n# Set the width and height of the figure\nplt.figure(figsize=(13,8))\n\n# Add title\nplt.title(\"Top Ten common crimes durning the years 2016 & 2017\")\n\nsns.barplot(x=top_10.index,y=top_10)\n\n#Rotate x-labels, otherwise it's utterly hectic\nplt.xticks(rotation=60)\n\n# Add label for vertical axis\nplt.ylabel(\"Number of Crimes\");","b10c6d25":"years = df_2016_2017['Year'].value_counts()\nyears","397fe088":"plt.title('Number of crimes for a year 2016 & 2017',fontsize=20,color = 'r')\n\nexplode = (0.03, 0.03)\nlabels = ['2017','2016']\n\n\nplt.pie(years, explode=explode,startangle=60, labels=labels,autopct='%0.01f%%')\n\nplt.show()","6da40215":"sns.countplot(x =\"Month\", data = df_2016_2017.reset_index(), palette=\"ch:54\").set(title='Number Of Crimes Each Month');","effc2ecb":"def Seasons(mon):\n    if (mon == 12 or mon == 1 or mon == 2):\n       return \"Winter\"\n    elif(mon == 3 or mon == 4 or mon == 5):\n       return \"Spring\"\n    elif(mon ==6 or mon==7 or mon == 8):\n       return \"Summer\"\n    else:\n       return \"Fall\"","e5b03110":"df_2016_2017['Season'] =df_2016_2017.loc[:,'Month'].apply(Seasons).sort_values(ascending=False)\ndf_2016_2017.head()","88ef331b":"season_counts = df_2016_2017.groupby('Season')['Incident_num'].count().sort_values(ascending=False).to_frame().reset_index()\nax = sns.barplot(x = 'Season' , y = \"Incident_num\",data = season_counts, palette='YlGnBu')\nplt.title('Number Of Crimes Each Season');","1ea2a0a2":"day_counts = df_2016_2017.groupby('Day').count()['Incident_num'].sort_values(ascending=False).to_frame().reset_index()\nax = sns.barplot(x = 'Day', y=\"Incident_num\", data = day_counts, palette='OrRd_r')\nplt.xticks(rotation=60)\nplt.title('Number Of Crimes Each Day_of_Week')\nprint(day_counts)","a918a206":"x = df_2016_2017.Day\ny = df_2016_2017.Hour\n\nfig = go.Figure(go.Histogram2d(x=x,y=y))\n\n#I tried many times to add a title to this figure and finally i collected these methods from(fig.library).\n#I'm very happy when i see the results are easily coming True with me :) \n\nfig.update_layout(title_text='Number Of Crimes Each Hour in 2016 & 2017',title_font_color='darkred',title_font_size=25,title_x=0.5)\nfig.show()\n","4c3820d3":"#Create a function to display Most crimes happened in the morning, evening or night\ndef day_night(h): \n    if h>=12:\n        return \"Evening\"\n    elif h<=5:\n        return \"Night\"\n    else:\n        return \"Morning\"\n    ","bc7ec379":"# we add new column called Day\/nights to our data set def_2016_&2017\ndf_2016_2017['Day\/night'] = df_2016_2017.loc[:,'Hour'].apply(day_night).head()\ndf_2016_2017.head()\n","5b882219":"# the differnces btw crimes rate durning a day in years 2016,2017\nsns.countplot(x=df_2016_2017['Day\/night'],palette='magma_r',order=['Evening','Night','Morning']);\nplt.title('Most of crimes hppened durning a day in years 2016,2017');","360b30fc":"#  added new column called Day\/nights to our data set crime_df\ncrime_df['Day\/night'] = crime_df.loc[:,'Hour'].apply(day_night)\ncrime_df.sample(5)","59ae86a9":"# the differnces btw crimes rate durning a day in years 2015,2016,2017,2018\nsns.countplot(x=crime_df['Day\/night'],palette='Set1_r',order=['Evening','Night','Morning']);\nplt.title('Most of crimes hppened durning a day from year 2015 to 2018');","74b7bad5":"#sns.countplot(x='District',data=df_2016_2017, order=order);\norder = df_2016_2017['District'].value_counts(ascending=False).index\nsns.countplot(x='District', data=df_2016_2017, order=order);\nplt.title('The most dangerous places in Boston in year:2016 & 2017');","97613a50":"# i need all crimes that occurerd in 2018 to determine it on the map\ndf = crime_df[crime_df['Year'] == 2018]","4c5192e7":"m = folium.Map(location=[42.361145, -71.057083], zoom_start=13)\n \n#Add Markers to the map\ncluster = MarkerCluster()\n# for loop to more than point\nfor idx, row in df.iterrows():\n    \n    if not math.isnan(row['Longi']) and not math.isnan(row['Lati']):\n        \n        cluster.add_child(Marker([row['Lati'], row['Longi']]))\n\nm.add_child(cluster)","9be9e96a":"#calculate the highest cirems that occured in a Street,Year,Month, day and time\n\nmax_street_crime = df_2016_2017['Street'].value_counts().index[0]\nmax_year_crime = df_2016_2017['Year'].value_counts().index[0]\nmax_hour_crime = df_2016_2017['Hour'].value_counts().index[0]\nmax_month_crime = df_2016_2017['Month'].value_counts().index[0]\nmax_day_crime = df_2016_2017['Day'].value_counts().index[0]\nmax_Time_crime = df_2016_2017['Day\/night'].value_counts().index[0]\n\nprint('Street with higher occurrence of crimes:', max_street_crime)\nprint('Year with highest crimes occurrence:', max_year_crime)\nprint('Hour with highest crimes occurrence:', max_hour_crime)\nprint('Month with highest crime occurrence:',max_month_crime)\nprint('Day with highest crimes occurrence:', max_day_crime)\nprint('Time with highest crimes occurrence:', max_Time_crime)","19d8eded":"#our new data\ndf_2016_2017.head()","8d3584a5":"### We should Note:\nThis dataset start records from June 2015, untill Sep 2018, In this case we have three ways to preprocessing data and making a fair comparsions between Years, Months and days.\n   ### 1st way:\n    create a dataFrame for only (6,7,8,9) months for all years:2015,2016,2017,2018\n   ### 2nd way:\n    create a dataFrame for only two years (2016 & 2017) because we have a full records for only these two years\n   ### 3rd way:\n    creata a DataFrame for only (1 to 9 ) months for the years 2016,2017,2018\n    \n   ### In this stage I'll use the second way. ","6b2e3d8a":"  ### More details, Display a Time of day, night or morning do most crimes take place?","2c00c9da":"### Answer for Question 3:Which time of the day the most of crimes committed? \n","e5bbe14a":"we see from above more crimes were occured on Fridays while Sunday has the lowest num of crimes","b121a760":"### In addition to - Plotting interactive map in python using Folium library\n    \n    Folium is a python package that combines all the spectrum of tools python offers to manipulate data with the leaflet javascript library to create rich and interactive maps.\n","6fa79bc6":"### In another way, we can add a new columns to our df_2016_2107 and show (Season, Day\/Night)\nin our dataframe we have years and months, by defining a fun and create the season column to see year's season","148fdb78":"We can see that district B2 has the highest crime rate, and district A15 has the lowest crime rate.","0de15edd":"### Summery","fa090a23":"# Algorithms\n## 1- Cleaning data : Drop missing values and Duplicated values\n\n","ab763a95":"# Data Processing","0fa85799":"We found alot of null values in column(SHOOTING) ,this means we should drop it next step","b860ac4b":"Washington St,the most dangerous streets in Boston 2016-2017\". Probably because it is the longest street in Boston. Many motor vehicle accidents must happen in Washington St, as well as larceny, and drug violation in a less extent.","06c7c6cd":"### Answer for Question2- part 2: Does the frequencies of crimes change over the months?\n### The count-plot clarify the most crimes happend over the months of 2016, 2017.\nLooking at the next (count_plot),the crime rate increased in  6, 7 and 8 months","47f19bd9":"## Answer for Question2- part 1: Does the frequencies of crime change over the two years?","1c78687c":"# Tools\n- Python and Jupyter Notebook\n\n- Numpy and Pandas for data manipulation\n\n- Matplotlib and Seaborn for plotting visuialization\n\n- Wordcloud for data visualization\n\n- Folium for for visualizing geospatial data\n","7690b34d":"### Plotly Backage - 2D Histogram of a Bivariate Normal Distribution\nA 2D histogram, also known as a density heatmap, is the 2-dimensional generalization of a histogram which resembles a heatmap but is computed by grouping a set of points specified by their x and y coordinates into bins, and applying an aggregation function such as count or sum (if z is provided) to compute the color of the tile representing the bin.","ab2415cd":"# Introduction\nThe main goal of this project is to understand the basic concepts of data science, know when and how to apply Exploratory Data Analysis on a dataset. Therefore, it's important to collect a dataset from any open data resources,e.g: Kaggle.com and explore it by using common EDA techniques and tools.","e6782399":"## 2- Managing columns of data - rename columns\n\n","072a5f4c":"### Answer for Question4: Where are different types of crimes most likely to occur?\n### This count-plot shows us the most dangerous places \nIn this section, we'll try to find which features have district patterns in which crime is higher or lower.","ed4b9e8b":"### Answer for Question2- part 3: Number Of Crimes Each Day_of_Week:\n### Does the frequencies of crime change over the day?","7e7f0f5a":"# Data Visulization\n### Visualization is required all the time while working upon a dataset in Machine Learning.\n","0ac8e830":"# Data\nRecords the data begin in June 14, 2015 and continue to September 3, 2018.","899944ab":"the above figure show us the Motor vehical accidents were most crime happened in Boston in both years 2016 & 2017","71f248e1":"### Answer for Question1- What types of crimes are the most common? ","2708a644":"we notice most of crimes committed in the summer season.","e4871cce":"# Reading DataSet","4b7bb2b8":"# Design\nThis project aims to demonstrate the most common types of crimes, show the frequencies of crimes change over the day? week? Year?, clarify the day with the highest number of crimes and the most dangerous places in Boston. In fact, we analyzed this data that have been collected from Kaggle.com and visualizing the result in addition to gain insight into a future criminal works.","41431cd1":"# Import Packages and Libraries","14c5fa1e":"In Other hand, we can add the same column to whole our dataset (crime_df) to give me overall insights on the number of crimes that happend durning a day in all years 2015,2016,2017,2018"}}