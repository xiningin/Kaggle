{"cell_type":{"426a2513":"code","ae1f53f4":"code","7695f552":"code","6fa7dfcd":"code","d8c7528d":"code","ba5854a1":"code","c4fcd395":"code","7995eb43":"code","e52a9b1f":"code","f06fc428":"code","5f09f52f":"code","04528272":"code","6a8ca8e1":"code","51dc3783":"code","5d03b185":"code","43b31fa5":"code","d7fdbc2c":"code","0d5e71a2":"code","81dd6748":"code","b2043a71":"code","d728e862":"code","2ccc2e2a":"code","73b41c47":"code","a09fc289":"code","0c05878c":"code","12d0f48c":"code","b91a5599":"code","c3491e8b":"code","3e0f8e14":"code","1bc99553":"code","9be0b069":"code","cb81fffd":"markdown","5048751a":"markdown","24e2bdc9":"markdown","8a484b68":"markdown","9b71b93f":"markdown","acaa590e":"markdown","fc5976ee":"markdown","5754b8a6":"markdown","6ed0690e":"markdown","139c6e92":"markdown"},"source":{"426a2513":"import numpy as np\nimport pandas as pd\nimport os","ae1f53f4":"!ls -GFlash ..\/input\/deepfake-detection-challenge","7695f552":"import cv2\nimport seaborn as sns\nimport matplotlib.pyplot as plt","6fa7dfcd":"from PIL import Image, ImageDraw","d8c7528d":"os.listdir('\/kaggle\/input\/deepfake-detection-challenge')","ba5854a1":"INPUT_FOLDER = '..\/input\/deepfake-detection-challenge'\nTRAIN_SAMPLE_FOLDER = 'train_sample_videos'\nTEST_FOLDER = 'test_videos'","c4fcd395":"print(f'No of training sample videos : {len(os.listdir(os.path.join(INPUT_FOLDER, TRAIN_SAMPLE_FOLDER)))}')\nprint(f'No of test videos : {len(os.listdir(os.path.join(INPUT_FOLDER, TEST_FOLDER)))}')","7995eb43":"train_files = os.listdir(os.path.join(INPUT_FOLDER, TRAIN_SAMPLE_FOLDER))\nall_extensions = []\nfor file in train_files:\n    ext = file.split('.')[1]\n    if ext not in all_extensions:\n        all_extensions.append(ext)","e52a9b1f":"print(f'All extensions in Train folder are - {all_extensions}')","f06fc428":"json_file = [file for file in train_files if file.endswith('.json')][0]\nprint(f'Metadata filename is {json_file}')","5f09f52f":"df_metadata = pd.read_json(os.path.join(INPUT_FOLDER, TRAIN_SAMPLE_FOLDER, json_file)).T","04528272":"df_metadata","6a8ca8e1":"plt.figure(figsize = (13,8))\nax = sns.countplot(df_metadata['label'])\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.0f}\\n({p.get_height()\/df_metadata.shape[0] * 100:.1f}%)', xy = (p.get_x() + p.get_width()\/2., p.get_height()), ha = 'center', xytext = (-10, 5), textcoords = 'offset points')\nax.set_ylim(0, .9 * df_metadata.shape[0])\nplt.xlabel('Video Type', fontsize = 14)\nplt.ylabel('Count', fontsize = 14)\nplt.title('Distribution of Video type', fontsize = 14)\nplt.show()","51dc3783":"total = df_metadata.isnull().sum()\ncount = df_metadata.isnull().count()\npercent_missing = (total\/count * 100)\nprint(f'Original videos which are missing are {total.original} which is {percent_missing.original}% of the total')","5d03b185":"len(df_metadata[df_metadata['label'] == 'REAL'])","43b31fa5":"df_metadata.original.nunique()","d7fdbc2c":"df_metadata.original.value_counts()","0d5e71a2":"def grab_image_from_video(filename):\n    cap = cv2.VideoCapture(filename)\n    ret, frame = cap.read()\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    cap.release()\n    cv2.destroyAllWindows()\n    return frame","81dd6748":"def plot_frame(filename, type):\n    frame = grab_image_from_video(filename)\n    fig = plt.figure(figsize = (13,8))\n    ax = fig.add_subplot(111)\n    ax.imshow(frame)\n    ax.axis('off')\n    ax.set_title(f'Screen grab of {type} Video - {filename.split(\"\/\")[-1]}')","b2043a71":"fake_videos = list(df_metadata[df_metadata['label'] == 'FAKE'].sample(3).index)","d728e862":"for fake_video in fake_videos:\n    plot_frame(os.path.join(INPUT_FOLDER, TRAIN_SAMPLE_FOLDER, fake_video), 'FAKE')","2ccc2e2a":"real_videos = list(df_metadata[df_metadata['label'] == 'REAL'].sample(3).index)","73b41c47":"for real_video in real_videos:\n    plot_frame(os.path.join(INPUT_FOLDER, TRAIN_SAMPLE_FOLDER, real_video), 'REAL')","a09fc289":"def detect_faces(image):\n    face_cascade = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')\n    faces = face_cascade.detectMultiScale(image, 1.2, 3)\n    return faces","0c05878c":"sample_videos = list(df_metadata.sample(3).index)","12d0f48c":"for video in sample_videos:\n    screen_grab = grab_image_from_video(os.path.join(INPUT_FOLDER, TRAIN_SAMPLE_FOLDER, video))\n    faces = detect_faces(screen_grab)\n    for x, y, w, h in faces:\n        cv2.rectangle(screen_grab, (x,y), (x+w, y+h), (255, 0, 0), 3)\n    fig = plt.figure(figsize = (11, 11))\n    ax = fig.add_subplot(111)\n    image = cv2.cvtColor(screen_grab, cv2.COLOR_BGR2RGB)\n    ax.axis('off')\n    ax.imshow(image)","b91a5599":"!pip install face_recognition","c3491e8b":"import face_recognition\ndef detect_faces_using_face_recognition(image):\n    face_locations = face_recognition.face_locations(image)\n    print(f'Found {len(face_locations)} faces in image')\n    fig, axs = plt.subplots(1, 2, figsize = (21, 5))\n    axs[0].imshow(image)\n    axs[0].axis('off')\n    axs[0].set_title('Original Image')\n    for face_location in face_locations:\n        top, right, bottom, left = face_location\n        face_image = image[top:bottom, left:right]\n        axs[1].imshow(face_image)\n        axs[1].axis('off')\n        axs[1].set_title('Detected Face')","3e0f8e14":"sample_videos = list(df_metadata.sample(3).index)\nfor file in sample_videos:\n    screen_grab = grab_image_from_video(os.path.join(INPUT_FOLDER, TRAIN_SAMPLE_FOLDER, file))\n    detect_faces_using_face_recognition(screen_grab)","1bc99553":"def draw_face_landmarks(image):\n    img = Image.fromarray(image)\n    d = ImageDraw.Draw(img)\n    face_landmarks_list = face_recognition.face_landmarks(image)\n    for face_landmarks in face_landmarks_list:\n        for facial_feature in face_landmarks.keys():\n            #print(f'{facial_feature} has points: {face_landmarks[facial_feature]}')\n            d.line(face_landmarks[facial_feature], width = 3)\n            \n    display(img)","9be0b069":"sample_videos = list(df_metadata.sample(3).index)\nfor file in sample_videos:\n    screen_grab = grab_image_from_video(os.path.join(INPUT_FOLDER, TRAIN_SAMPLE_FOLDER, file))\n    draw_face_landmarks(screen_grab)","cb81fffd":"**Detect faces using Haar Cascade classifier**","5048751a":"**Let's check the extensions**","24e2bdc9":"**JSON file contains metadata. Let's explore it**","8a484b68":"**This number is exactly same as number of REAL videos. Does it mean that all Real label videos do not have original videos?\nLet us confirm our suspicion**","9b71b93f":"**Let's plot some Fake samples**","acaa590e":"**Thus for sideways looking subjects cascade classifier is not able to detect faces. Lets try another method of face detection using facial_recognition library and see if perfomance improves**","fc5976ee":"**Some Real videos too**","5754b8a6":"**Check Missing Data**","6ed0690e":"**Detect face using face_recognition library and zoom on it**","139c6e92":"**Out of total 323 original videos (which are all FAKE) only 209 are unique**"}}