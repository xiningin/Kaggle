{"cell_type":{"c9c0fb69":"code","22f4d0ee":"code","45324080":"code","157633c6":"code","cfddac28":"code","1e4b9946":"code","16d75c6f":"code","e5ed826f":"code","4ea1e08b":"code","738db0de":"code","46aa5c5d":"code","553edc64":"code","26868c02":"code","02f7c6cb":"code","4b9acc56":"markdown","90a30410":"markdown"},"source":{"c9c0fb69":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\npd.plotting.register_matplotlib_converters()\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22f4d0ee":"# Importing data, looking at it (getting nothing of value from it :( )\ntrain_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-spring-21-practice-assignment\/train.csv\")\nprint(train_data.describe())\nprint(\"\\n\")\nprint(train_data.head())\ntrain_data","45324080":"# This ID column was making my pretty pictures UGLY, so I'm getting rid of it\ntrain_data = train_data.drop(['Id'], axis = 1)\ntrain_data.loc[:, 'Species'].value_counts().sort_values(ascending=False) \/ train_data.loc[:, 'Species'].count()","157633c6":"# It looks like we don't have an even distribution of species\n# I don't think it really matters though, it is close enough for me!\nsns.countplot(data = train_data, x = 'Species')","cfddac28":"# I did this for practice but I don't think it really tells us anything about our dataset\n# We know that for some reason x3 and x4 have a huge spike on the low side, but thats about it\nf, axs = plt.subplots(2, 2, figsize = (8,6))\nsns.histplot(data = train_data, x = 'x1', ax = axs[0,0])\nsns.histplot(data = train_data, x = 'x2', ax = axs[0,1])\nsns.histplot(data = train_data, x = 'x3', ax = axs[1,0])\nsns.histplot(data = train_data, x = 'x4', ax = axs[1,1])\nf.tight_layout()\n","1e4b9946":"# This one makes it obvious that there at least is some correlation between species and whatever x1 through x4 are supposed to mean.\n# It also has lots of pretty colors\n# I like these graphs\ng = sns.PairGrid(train_data, hue = 'Species')\ng.map_diag(sns.histplot)\ng.map_offdiag(sns.scatterplot)\ng.add_legend()","16d75c6f":"# Here I set up what we're searching FOR (y) and what we're using to find it (X)\ny = train_data.Species\nfeats = ['x1', 'x2', 'x3', 'x4']\nX = train_data[feats]","e5ed826f":"# magical magical code block\nfrom sklearn.model_selection import train_test_split\n\n# The stratify argument basically splits our dataset nice and evenly among whatever y is (in this case SPECIES)\n\n# I think this would be called stratified sampling, this way we don't accidentally test all of our species 0 and like three 1s or something bad that could happen from going full random \nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = .5, random_state = 1)\n\n\n","4ea1e08b":"# Using Random Forest to predict\n# I just like this one\n# Relaxing pretty trees\n# ahhhhhh\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nforestModel = RandomForestClassifier(random_state = 1)\nforestModel.fit(X_train, y_train)\nprediction = forestModel.predict(X_test)\n\n","738db0de":"# Let's see how accurate we were when comparing against the rest of the training set!\nfrom sklearn.metrics import mean_absolute_error\n\nprint(mean_absolute_error(y_test, prediction))","46aa5c5d":"# Import our test set so we can do the REAL THING\ntest_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-spring-21-practice-assignment\/test.csv\")\n# Turns out I need these ID values, so I made a new list to store the ID-less list in\ntesty_data = test_data.drop(['Id'], axis = 1)\n# I'm really dumb, I didn't need to cut ID out at all here since feats was filtering it out and I wasn't drawing any graphs\n\n# Print out my test data so I can look at it and pretend to be smart\nprint(test_data)\n\nX_val = testy_data[feats]","553edc64":"# Let's make our REAL prediction now!\nprediction = forestModel.predict(X_val)\nprint(prediction)","26868c02":"# Must make sure I submit in the proper format!\nprint(pd.read_csv(\"\/kaggle\/input\/cap-4611-spring-21-practice-assignment\/sample_submission.csv\"))","02f7c6cb":"# Looks like we just need the ID and the species!\noutput = pd.DataFrame({'Id' : test_data.Id, 'Species' : prediction})\noutput.to_csv('JosephBrown_submission.csv', index=False)\n# Kaggle LOVES to hang so I'll make sure I'm CERTAIN when it is done (haha I totally didn't crash my browser earlier)\nprint(\"Save Complete!\")","4b9acc56":"Not gonna lie, that list looks suspiciously sorted! I'm willing to bet that if I switched that 2 in the center to a 1, I'd have 100% accuracy","90a30410":"Well, that's not 100% so that is more promising than before!"}}