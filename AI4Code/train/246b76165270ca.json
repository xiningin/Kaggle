{"cell_type":{"9391b79b":"code","87912944":"code","2d21396c":"code","df369719":"code","031bab39":"code","aae33b13":"code","6c33e953":"code","7a3c1d30":"code","9a7f53db":"code","7134a33d":"code","8adf903d":"code","0ceaddb7":"code","d4a1419d":"code","2cc31157":"code","82e9f2fb":"code","52cddc5b":"code","3eb93de0":"code","201a6ce4":"code","107c4ff9":"code","6315043b":"code","c4b31bd0":"code","82344f15":"code","7d42101a":"markdown","bcf9b9d7":"markdown","ac768a7e":"markdown","ba52e91a":"markdown","f1bfe2bb":"markdown","ebe446b5":"markdown","79209fb8":"markdown"},"source":{"9391b79b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport glob\nimport h5py\nimport shutil\nimport imgaug as aug\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport imgaug.augmenters as iaa\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D, MaxPool2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nfrom keras import backend as K\nfrom keras.applications import *\ncolor = sns.color_palette()\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","87912944":"import tensorflow as tf\nprint(tf.version)","2d21396c":"# Set the seed for hash based operations in python\nos.environ['PYTHONHASHSEED'] = '0'\n\n# Set the numpy seed\nnp.random.seed(111)\n\n# Disable multi-threading in tensorflow ops\nsession_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n\n# Set the random seed in tensorflow at graph level\ntf.compat.v1.set_random_seed(111)\n\n# Define a tensorflow session with above session configs\nsess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n\n# Set the session in keras\ntf.compat.v1.keras.backend.set_session(sess)\n\n# Make the augmentation sequence deterministic\naug.seed(111)","df369719":"# Define path to the data directory\ndata_dir = Path('..\/input\/donation-items-classification\/Donation Items Classification')\n\n# Path to train directory (Fancy pathlib...no more os.path!!)\ntrain_dir = data_dir \/ 'train'\n\n# Path to test directory\ntest_dir = data_dir \/ 'test'","031bab39":"# Get the path to the item sub-directories\nbook_cases_dir = train_dir \/ 'books'\nclothes_cases_dir = train_dir \/ 'clothes'\nlipstick_cases_dir = train_dir \/ 'lipstick'\nshoes_cases_dir = train_dir \/ 'shoes'\n\n# Get the list of all the images\nbook_cases = book_cases_dir.glob('*.jpg')\nclothes_cases = clothes_cases_dir.glob('*.jpg')\nlipstick_cases = lipstick_cases_dir.glob('*.jpg')\nshoes_cases = shoes_cases_dir.glob('*.jpg')\n\n# An empty list. We will insert the data into this list in (img_path, label) format\ntrain_data = []\n\n# Go through all the book class. The label for these cases will be 0\nfor img in book_cases:\n    train_data.append((img,0))\n\n# Go through all the clothes class. The label for these cases will be 1\nfor img in clothes_cases:\n    train_data.append((img,1))\n    \n# Go through all the lipstick class. The label for these cases will be 2\nfor img in lipstick_cases:\n    train_data.append((img,2))\n    \n# Go through all the shoes class. The label for these cases will be 3\nfor img in shoes_cases:\n    train_data.append((img,3))\n\n# Get a pandas dataframe from the data we have in our list \ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n\n# Shuffle the data \ntrain_data = train_data.sample(frac=1.).reset_index(drop=True)\n\n# How the dataframe looks like?\ntrain_data.head()","aae33b13":"# Get the counts for each class\ncases_count = train_data['label'].value_counts()\nprint(cases_count)\n\n# Plot the results \nplt.figure(figsize=(10,8))\nsns.barplot(x=cases_count.index, y= cases_count.values)\nplt.title('Number of class', fontsize=14)\nplt.xlabel('Class', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(cases_count.index)), ['Book(0)', 'Clothes(1)', 'Lipstick(2)', 'Shoes(3)'])\nplt.show()","6c33e953":"# Get few samples for all the classes\nbook_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\nclothes_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\nlipstick_samples = (train_data[train_data['label']==2]['image'].iloc[:5]).tolist()\nshoes_samples = (train_data[train_data['label']==3]['image'].iloc[:5]).tolist()\n\n# Concat the data in a single list and del the above three list\nsamples = book_samples + clothes_samples + lipstick_samples + shoes_samples \ndel book_samples, clothes_samples, lipstick_samples, shoes_samples  \n\n# Plot the data \nf, ax = plt.subplots(4,5, figsize=(40,20))\nfor i in range(20):\n    img = imread(samples[i])\n    ax[i\/\/5, i%5].imshow(img, cmap='gray')\n    if i<5:\n        ax[i\/\/5, i%5].set_title(\"Book\")\n    elif i<10:\n        ax[i\/\/5, i%5].set_title(\"Clothes\")\n    elif i<15:\n        ax[i\/\/5, i%5].set_title(\"Lipstick\")\n    else:\n        ax[i\/\/5, i%5].set_title(\"Shoes\")\n    ax[i\/\/5, i%5].axis('off')\n    ax[i\/\/5, i%5].set_aspect('auto')\nplt.show()","7a3c1d30":"# Path to validation directory\nval_dir = data_dir \/ 'test'\n\n# Get the path to the sub-directories\nbook_cases_dir = val_dir \/ 'books'\nclothes_cases_dir = val_dir \/ 'clothes'\nlipstick_cases_dir = val_dir \/ 'lipstick'\nshoes_cases_dir = val_dir \/ 'shoes'\n\n# Get the list of all the images\nbook_cases = book_cases_dir.glob('*.jpg')\nclothes_cases = clothes_cases_dir.glob('*.jpg')\nlipstick_cases = lipstick_cases_dir.glob('*.jpg')\nshoes_cases = shoes_cases_dir.glob('*.jpg')\n\n# List that are going to contain validation images data and the corresponding labels\nvalid_data = []\nvalid_labels = []\n\n\n# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n# We will normalize the pixel values and resizing all the images to 256x256 \n\nnum_vsamples = 10\n# Book\ni = 0\nfor img in book_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (256,256))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(0, num_classes=4)\n    valid_data.append(img)\n    valid_labels.append(label)\n    i=i+1\n    if i == num_vsamples:\n        break\n                      \n# Clothes  \ni = 0\nfor img in clothes_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (256,256))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(1, num_classes=4)\n    valid_data.append(img)\n    valid_labels.append(label)\n    i=i+1\n    if i == num_vsamples:\n        break\n\n# Lipstick   \ni = 0\nfor img in lipstick_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (256,256))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(2, num_classes=4)\n    valid_data.append(img)\n    valid_labels.append(label)\n    i=i+1\n    if i == num_vsamples:\n        break\n        \n# Shoes   \ni = 0\nfor img in shoes_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (256,256))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(3, num_classes=4)\n    valid_data.append(img)\n    valid_labels.append(label)\n    i=i+1\n    if i == num_vsamples:\n        break\n    \n# Convert the list into numpy arrays\nvalid_data = np.array(valid_data)\nvalid_labels = np.array(valid_labels)\n\nprint(\"Total number of validation examples: \", valid_data.shape)\nprint(\"Total number of labels:\", valid_labels.shape)","9a7f53db":"# Augmentation sequence \nseq = iaa.OneOf([\n    iaa.Fliplr(), # horizontal flips\n    iaa.Affine(rotate=20), # roatation\n    iaa.Multiply((1.2, 1.5))]) #random brightness","7134a33d":"def data_gen(data, batch_size):\n    # Get total number of samples in the data\n    n = len(data)\n    steps = n\/\/batch_size\n    \n    # Define two numpy arrays for containing batch data and labels\n    batch_data = np.zeros((batch_size, 256, 256, 3), dtype=np.float32)\n    batch_labels = np.zeros((batch_size,4), dtype=np.float32)\n\n    # Get a numpy array of all the indices of the input data\n    indices = np.arange(n)\n    \n    # Initialize a counter\n    i =0\n    while True:\n        np.random.shuffle(indices)\n        # Get the next batch \n        count = 0\n        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n        for j, idx in enumerate(next_batch):\n            img_name = data.iloc[idx]['image']\n            label = data.iloc[idx]['label']\n            \n            # one hot encoding\n            encoded_label = to_categorical(label, num_classes=4)\n            # read the image and resize\n            img = cv2.imread(str(img_name))\n            img = cv2.resize(img, (256,256))\n            \n            # check if it's grayscale\n            if img.shape[2]==1:\n                img = np.dstack([img, img, img])\n            \n            # cv2 reads in BGR mode by default\n            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            # normalize the image pixels\n            orig_img = img.astype(np.float32)\/255.\n            \n            batch_data[count] = orig_img\n            batch_labels[count] = encoded_label\n            \n            # generating more samples\n            if count < batch_size-2:\n                aug_img1 = seq.augment_image(img)\n                aug_img2 = seq.augment_image(img)\n                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n                aug_img1 = aug_img1.astype(np.float32)\/255.\n                aug_img2 = aug_img2.astype(np.float32)\/255.\n                \n                batch_data[count+1] = aug_img1\n                batch_labels[count+1] = encoded_label\n                batch_data[count+2] = aug_img2\n                batch_labels[count+2] = encoded_label\n                count +=2\n            \n            else:\n                count+=1\n            \n            if count==batch_size-1:\n                break\n            \n        i+=1\n        yield batch_data, batch_labels\n            \n        if i>=steps:\n            i=0","8adf903d":"def build_model():\n\n    baseModel = Xception(input_shape=(256, 256, 3), include_top=False, weights='imagenet')\n    x = baseModel.output\n    x = AveragePooling2D(pool_size=(4, 4))(x)\n    x = Flatten(name=\"flatten\")(x)\n    x = Dense(512, activation='relu', name='fc1')(x)\n    x = Dropout(0.7, name='dropout1')(x)\n    x = Dense(256, activation='relu', name='fc2')(x)\n    x = Dropout(0.5, name='dropout2')(x)\n    headModel = Dense(4, activation='softmax', name='fc3')(x)   \n    \n    model = Model(inputs=baseModel.input, outputs=headModel)\n        \n    return model","0ceaddb7":"model =  build_model()\nmodel.summary()","d4a1419d":"# opt = RMSprop(lr=0.0001, decay=1e-6)\nopt = Adam(lr=0.0001, decay=1e-5)\nes = EarlyStopping(patience=5)\nchkpt = ModelCheckpoint(filepath='best_model.hdf5', save_best_only=True, save_weights_only=True)\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=opt)","2cc31157":"batch_size = 32\nnb_epochs = 20\n\n# Get a train data generator\ntrain_data_gen = data_gen(data=train_data, batch_size=batch_size)\n\n# Define the number of training steps\nnb_train_steps = train_data.shape[0]\/\/batch_size\n\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))","82e9f2fb":"# Fit the model\nhistory = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n                              validation_data=(valid_data, valid_labels),callbacks=[es, chkpt])","52cddc5b":"from IPython.display import FileLink\nFileLink(r'best_model.hdf5')","3eb93de0":"# Load the model weights\nmodel.load_weights(\"..\/working\/best_model.hdf5\")\n\n# model.load_weights(\"..\/input\/xraybestmodel1\/best_model.hdf5\")","201a6ce4":"# Preparing test data\n# Get the path to the sub-directories\nbook_cases_dir = test_dir \/ 'books'\nclothes_cases_dir = test_dir \/ 'clothes'\nlipstick_cases_dir = test_dir \/ 'lipstick'\nshoes_cases_dir = test_dir \/ 'shoes'\n\n# Get the list of all the images\nbook_cases = book_cases_dir.glob('*.jpg')\nclothes_cases = clothes_cases_dir.glob('*.jpg')\nlipstick_cases = lipstick_cases_dir.glob('*.jpg')\nshoes_cases = shoes_cases_dir.glob('*.jpg')\n\n# List that are going to contain test images data and the corresponding labels\ntest_data = []\ntest_labels = []\n\n\n# Book\nfor img in book_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (256,256))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(0, num_classes=4)\n    test_data.append(img)\n    test_labels.append(label)\n                      \n# Clothes  \nfor img in clothes_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (256,256))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(1, num_classes=4)\n    test_data.append(img)\n    test_labels.append(label)\n\n# Lipstick   \nfor img in lipstick_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (256,256))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(2, num_classes=4)\n    test_data.append(img)\n    test_labels.append(label)\n        \n# Shoes   \nfor img in shoes_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (256,256))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(3, num_classes=4)\n    test_data.append(img)\n    test_labels.append(label)\n    \n# Convert the list into numpy arrays\ntest_data = np.array(test_data)\ntest_labels = np.array(test_labels)\n\nprint(\"Total number of test examples: \", test_data.shape)\nprint(\"Total number of labels:\", test_labels.shape)","107c4ff9":"# Evaluation on test dataset\ntest_loss, test_score = model.evaluate(test_data, test_labels, batch_size=32)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","6315043b":"# Get predictions\npreds = model.predict(test_data, batch_size=32)\npreds = np.argmax(preds, axis=-1)\n\n# Original labels\norig_test_labels = np.argmax(test_labels, axis=-1)\n\nprint(orig_test_labels.shape)\nprint(preds.shape)","c4b31bd0":"# Get the confusion matrix\ncm  = confusion_matrix(orig_test_labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8))\nplt.xticks(range(4), ['Book', 'Clothes', 'Lipstick', 'Shoes'], fontsize=16)\nplt.yticks(range(4), ['Book', 'Clothes', 'Lipstick', 'Shoes'], fontsize=16)\nplt.show()","82344f15":"# save model and architecture to single file \nmodel.save(\"model.h5\")\nFileLink(r'model.h5')","7d42101a":"# Training data generator","bcf9b9d7":"## How many samples for each class are there in the dataset?","ac768a7e":"# Import neccessary packages","ba52e91a":"# Model","f1bfe2bb":"# Preparing validation data","ebe446b5":"# Augmentation","79209fb8":"# Training Data"}}