{"cell_type":{"15ca0bdc":"code","adab3c31":"code","8b29fa97":"code","160842c2":"code","171a606f":"code","7a8b0e8c":"code","9243072b":"code","d99e8cb6":"code","a07e0bc7":"code","3189c61e":"code","bc1dcf80":"code","6016ad8e":"code","287ab321":"code","55dc5f55":"code","654c6e61":"code","1bff168a":"code","14ec3d49":"code","e31b6532":"code","8a130dfc":"code","3a5f8c26":"code","322acb83":"code","5f53f5fe":"code","d5822054":"code","6f842da1":"code","3e9241a0":"code","9c117247":"code","ca80ad34":"code","b7cadfa5":"code","c8017e9b":"code","a4a08061":"code","83f7d289":"markdown","ee9dbc17":"markdown","406d4196":"markdown","f8ee01a0":"markdown","d1aba1d5":"markdown","f2442b77":"markdown","735b9b72":"markdown","26757e2c":"markdown","606d1d7f":"markdown","37db1b66":"markdown","afb1cc7f":"markdown","e9fdb5aa":"markdown","57f4845d":"markdown","9a79cbb0":"markdown","93b9fd27":"markdown","537a2d11":"markdown","80557c45":"markdown","ec7e3838":"markdown"},"source":{"15ca0bdc":"!pip install console-progressbar\n!pip install pretrainedmodels","adab3c31":"# Preprocessing\nfrom console_progressbar import ProgressBar\nimport matplotlib.pyplot as plt\nimport pretrainedmodels\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv2\nimport scipy.io\nimport tarfile\nimport shutil\nimport random\nimport os\nr = range","8b29fa97":"train_path = '..\/input\/stanford-cars-dataset\/cars_train\/cars_train\/'\ntest_path  = '..\/input\/stanford-cars-dataset\/cars_test\/cars_test\/'\nimg_width, img_height = 224, 224\n\ntrain_output = '\/kaggle\/working\/data\/train\/' \nvalid_output = '\/kaggle\/working\/data\/valid\/'\ntest_output  = '\/kaggle\/working\/data\/test\/'","160842c2":"print(\"Lets see how many cars we have!\")\nprint('..............................')\ntrain = scipy.io.loadmat('..\/input\/stanford-devkit\/stanford_devkit\/devkit\/cars_train_annos.mat')\ntrain = np.transpose(train['annotations'])\ntrain_unique = [img[0][4][0][0] for img in train]\nprint(np.unique(train_unique))\nprint('')\nprint('Number of differenct cars is:', np.unique(train_unique).shape[0])","171a606f":"def create_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","7a8b0e8c":"def validate_train(fnames, bboxes, labels, data_str):\n    # We have to split train data into two dataset 0.8 for train and 0.2 for valid\n    train_num = int(round(len(fnames) * 0.8))\n    train_ids = random.sample(r(len(fnames)), train_num)\n    pb = ProgressBar(total=100, prefix='Save train data', suffix='', decimals=3, length=50, fill='=')\n    for index in r(len(fnames)):\n        # First find proper path(valid\/train)\n        if data_str == 'train':\n            label = labels[index]\n        fname = fnames[index]\n        if data_str == 'train':\n            new_path = train_path + fname\n        else:\n            new_path = test_path + fname\n        img = cv2.imread(new_path)\n        \n        # Create dist path\n        if data_str == 'train':\n            dst_path = valid_output\n            if index in train_ids:\n                dst_path = train_output\n\n            dst_path = dst_path + label + '\/'\n            create_folder(dst_path)\n            dst_path += fname\n        else:\n            dst_path = test_output + fname\n        # Take bboxes and crop the image\n        a1, b1, a2, b2 = bboxes[index]\n        a1, b1 = max(0, a1 - 16), max(0, b1 - 16)\n        a2, b2 = min(a2 + 16, img.shape[1]), min(b2 + 16, img.shape[0])\n        \n        # Crop image and save it to the path\n        img = cv2.resize(img[b1:b2, a1:a2], (img_width, img_height))\n        \n        cv2.imwrite(dst_path, img)\n        \n        # Print progress\n        pb.print_progress_bar((index + 1) * 100 \/ len(fnames))","9243072b":"def vaidate_data(data_str):\n    data = None\n    bbox_id, fname_id, label_id = r(4), 5, 4\n    fnames, bboxes, labels = [], [], None\n    if data_str == 'train':\n        labels = []\n        data = scipy.io.loadmat('..\/input\/devkit-test\/devkit\/cars_train_annos.mat')\n    else:\n        # We have no labels for test data.\n        data = scipy.io.loadmat('..\/input\/stanford-devkit\/stanford_devkit\/devkit\/cars_test_annos.mat')\n    data = np.transpose(data['annotations'])\n    \n    for image in data:\n        # bounding box coordinates!\n        bbox_arr = [] \n        for _ in bbox_id:\n            bbox_arr.append(image[0][_][0][0])\n        bboxes.append(bbox_arr)\n        \n        # Fnames\n        if data_str =='train':\n            fnames.append(image[0][fname_id][0])\n        else:\n            fnames.append(image[0][4][0])\n        # Labels\n        if data_str == 'train':\n            labels.append('%04d' % (image[0][label_id][0][0]))\n    if data_str == 'train':\n        validate_train(fnames, bboxes, labels, data_str)\n    else:\n        validate_train(fnames, bboxes, [], data_str)\n        ","d99e8cb6":"# create_folder('\/kaggle\/working\/data\/train')\n# create_folder('\/kaggle\/working\/data\/valid')\ncreate_folder('\/kaggle\/working\/data\/test')\n# vaidate_data('train')\nvaidate_data('test')","a07e0bc7":"from torch import nn\nimport torch.nn.functional as F\n# Model imports\nfrom fastai.metrics import error_rate\nfrom fastai.vision import *\nfrom fastai import *\nimport torchvision","3189c61e":"# This loss is taken from fastai forum page\nclass my_loss(nn.Module):\n    def __init__(self, alpha=1., gamma=2.):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets, **kwargs):\n        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-CE_loss)\n        F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n        return F_loss.mean()\n# This resnext preprocessing is taken from fastai forum page\ndef se_resnext50_32x4d(pretrained=False):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n    return nn.Sequential(*list(model.children()))","bc1dcf80":"test = scipy.io.loadmat('..\/input\/stanford-devkit\/stanford_devkit\/devkit\/cars_test_annos_withlabels.mat')\ntemp_arr = []\nfor _ in r(test['annotations'].shape[1]):\n    fname = test['annotations']['fname']\n    fname = np.array(fname)\n    fname = np.transpose(fname)[_][0][0]\n    temp_arr.append(fname)\n    \ntest_data = df=pd.DataFrame(data=np.transpose(np.array(test['annotations']['class'],dtype=np.int)),\n                  index=temp_arr)\ntest_data.to_csv('\/kaggle\/working\/data\/test_data.csv')","6016ad8e":"from fastai.imports import *","287ab321":"learn = load_learner('..\/input\/teeeeeeeest\/','fastai_model_vol2.0.pkl', test=ImageList.from_csv('\/kaggle\/working\/data','test_data.csv',folder='test'))\npreds,y = learn.TTA(ds_type=DatasetType.Test)","55dc5f55":"a = preds\nb = np.array(df[0] - 1,dtype=np.int) \nb = torch.from_numpy(b)\nacc=accuracy(a,b)\n\nacc","654c6e61":"cars_meta = scipy.io.loadmat('..\/input\/stanford-devkit\/stanford_devkit\/devkit\/cars_meta.mat')\nclass_names = cars_meta['class_names']  # shape=(1, 196)\nclass_names = np.transpose(class_names)\nprint('class_names.shape: ' + str(class_names.shape))","1bff168a":"path = '..\/input\/stanford-cars-dataset\/cars_test\/cars_test\/00002.jpg'\nim = open_image(path)\nim","14ec3d49":"pred_class,pred_idx,outputs = learn.predict(im)\nprint('Predicted class is:', int(pred_class))\nprint('Sample class_name: [{}]'.format(class_names[int(pred_class) + 1][0]))\n\nprint('')\nreal_num = np.transpose(np.array(test['annotations']['class']))[int(path.split('\/')[-1].split('.')[0]) - 1][0][0][0] - 1\nprint('Actuall class is:', real_num)\nprint('Sample class_name: [{}]'.format(class_names[real_num + 1][0]))","e31b6532":"path = '..\/input\/stanford-cars-dataset\/cars_test\/cars_test\/00100.jpg'\nim = open_image(path)\nim","8a130dfc":"pred_class,pred_idx,outputs = learn.predict(im)\nprint('Predicted class is:', int(pred_class))\nprint('Sample class_name: [{}]'.format(class_names[int(pred_class) + 1][0]))\n\nprint('')\nreal_num = np.transpose(np.array(test['annotations']['class']))[int(path.split('\/')[-1].split('.')[0]) - 1][0][0][0] - 1\nprint('Actuall class is:', real_num)\nprint('Sample class_name: [{}]'.format(class_names[real_num + 1][0]))","3a5f8c26":"path = '..\/input\/stanford-cars-dataset\/cars_test\/cars_test\/01000.jpg'\nim = open_image(path)\nim","322acb83":"pred_class,pred_idx,outputs = learn.predict(im)\nprint('Predicted class is:', int(pred_class))\nprint('Sample class_name: [{}]'.format(class_names[int(pred_class) + 1][0]))\n\nprint('')\nreal_num = np.transpose(np.array(test['annotations']['class']))[int(path.split('\/')[-1].split('.')[0]) - 1][0][0][0] - 1\nprint('Actuall class is:', real_num)\nprint('Sample class_name: [{}]'.format(class_names[real_num + 1][0]))","5f53f5fe":"cars_meta = scipy.io.loadmat('..\/input\/stanford-devkit\/stanford_devkit\/devkit\/cars_meta.mat')\nclass_names = cars_meta['class_names']  # shape=(1, 196)\nclass_names = np.transpose(class_names)\n\ntemp = pd.DataFrame(class_names)\n\ndef mark(val):\n    return val[0].split()[0]\n\ntemp[0] = temp[0].apply(mark)\n\nmy_map = {}\nfor _ in range(temp[0].shape[0]):\n    my_map[_] = temp[0][_]\nmy_map_id = {}\ncount = 0\nfor _ in temp[0].unique():\n    my_map_id[_] = count\n    count += 1","d5822054":"my_map_id","6f842da1":"my_map","3e9241a0":"# Now we take our predictions and labels and see how many correct model we have\ncorrect_ones = 0\nfor index in r(a.shape[0]):\n    pred_class = int(a[index].argmax())\n    true_class = int(b[index])\n    \n    pred_model = my_map_id[my_map[pred_class]]\n    true_model = my_map_id[my_map[true_class]]\n    if true_model == pred_model:\n        correct_ones += 1","9c117247":"print(\"acc on only model is:\", correct_ones*100\/a.shape[0])","ca80ad34":"path = '..\/input\/stanford-cars-dataset\/cars_test\/cars_test\/01002.jpg'\nim = open_image(path)\nim","b7cadfa5":"pred_class,pred_idx,outputs = learn.predict(im)\nprint('Predicted class is:', my_map_id[my_map[int(pred_class)]])\nprint('Sample class_name: [{}]'.format(class_names[int(pred_class) + 1][0]))\n\nprint('')\nreal_num = np.transpose(np.array(test['annotations']['class']))[int(path.split('\/')[-1].split('.')[0]) - 1][0][0][0] - 1\nprint('Actuall class is:', my_map_id[my_map[real_num]])\nprint('Sample class_name: [{}]'.format(class_names[real_num + 1][0]))","c8017e9b":"path = '..\/input\/stanford-cars-dataset\/cars_test\/cars_test\/01001.jpg'\nim = open_image(path)\nim","a4a08061":"pred_class,pred_idx,outputs = learn.predict(im)\nprint('Predicted class is:', my_map_id[my_map[int(pred_class)]])\nprint('Sample class_name: [{}]'.format(class_names[int(pred_class) + 1][0]))\n\nprint('')\nreal_num = np.transpose(np.array(test['annotations']['class']))[int(path.split('\/')[-1].split('.')[0]) - 1][0][0][0] - 1\nprint('Actuall class is:', my_map_id[my_map[real_num]])\nprint('Sample class_name: [{}]'.format(class_names[real_num + 1][0]))","83f7d289":"> **Model imports**","ee9dbc17":"This method takes bboxes, fnames and labels arrays\nIt takes this argument and crops image on given coordinates\nAfter that creates proper directory and save crop image on proper path in kaggle working directory","406d4196":"# Imports","f8ee01a0":"# Lets create two map!\nOne will save all the values of car marks\nOther one will only save the car models!","d1aba1d5":"**This method takes fnames, bbox coordinates and labels as parameter**\n\n**After that we crop the image, split them into the train and valid category and save it to the kaggle output directory**","f2442b77":"# Working on test data!!","735b9b72":"# Data looking","26757e2c":"# Modeling","606d1d7f":"> **Ploting the learning rate and choosing valid max_lr as parameter**","37db1b66":"> ****Taking pretrained model and also our own croosentropyloss****\n\n> Ideas are taken from fastai forum pages like https:\/\/docs.fast.ai\/basic_train.html","afb1cc7f":"# Now lets see accuracy on model only!","e9fdb5aa":"# Lets see we examples","57f4845d":"# Your own testing!","9a79cbb0":"**We have to open stanfrod matlab object and locate Labels, bboxes and names**\n\n\n**After that we have to split dataset into to category: Train, Valid**","93b9fd27":"**Lets open the data and save to train\/valid folders!**","537a2d11":"# Correct examples!!","80557c45":"# Correct model but mark mistaken","ec7e3838":"# Stanford dataset\nThis notebook is recognition of stanfrod car mark\/model.\nFor training and testing we have stanfrod data which has its own bbox coordinates and also labels.\nAfter quick look to the data, we discover that this data has 196 different car model.\nFor future development we can add myauto data with bboxes and labels to this notebook.\nWe are using fastai resnext model with trasnfer learning on our dataset. "}}