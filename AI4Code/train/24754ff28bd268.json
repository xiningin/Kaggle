{"cell_type":{"ce62e76c":"code","00975c2a":"code","fa2939c9":"code","0b4edb0d":"code","e9a8259f":"code","b6c78e91":"code","1fa3f90c":"code","741438c3":"code","4ccd2b11":"code","455e3b40":"code","bf8f8dc6":"code","9da3607a":"code","6163db3c":"code","0f8470cc":"code","7cf32390":"code","578e7a01":"code","0de67b73":"code","075812ef":"code","8fe798b2":"code","6a32030b":"code","4023e9a0":"code","737de19e":"code","676a7300":"code","aa9b637f":"code","ad3a056c":"code","43682333":"code","7ebc77da":"code","d08252a3":"code","b35c5a03":"code","efd1bbe2":"code","3ab3b916":"code","ce6a4092":"code","5cc7cf5e":"code","949b0416":"code","fead19fd":"code","999695f8":"code","a6489a9f":"code","54a37a45":"code","9b8621ce":"code","ec5b6267":"code","1da5c4cd":"code","a10e1c23":"code","38c16e0f":"code","92aae435":"code","cd698c77":"code","07008265":"code","a669bc85":"code","231a6ffd":"code","0b95cca7":"code","9a8ee73a":"code","ed4edf81":"code","831c9ae6":"code","3ebca2fb":"code","e232bd09":"code","c6400763":"code","f9593357":"code","3592a7d6":"code","732dc74a":"code","e4f3720b":"code","16bffe91":"code","59a71f24":"code","e4c5a842":"code","080b8c3c":"code","15125301":"code","0d68ec80":"code","82c0ce60":"code","32ac3bf2":"code","69499e9a":"code","9c4d3337":"code","4f9a57ea":"code","6f82d541":"code","d6f25dce":"code","64a11e27":"code","ec469326":"code","74ccdee6":"code","a7338018":"code","92a6b064":"code","dba98833":"code","2fa07fbd":"code","6e8dbe45":"code","16b28608":"code","cb1a4e8e":"markdown","dac7face":"markdown","1ea4b232":"markdown","f9d1acc9":"markdown","942fbacc":"markdown","5ed603c2":"markdown","364d758c":"markdown","dcba1a80":"markdown","2bad65c4":"markdown","720f329a":"markdown","1490087c":"markdown","86839ce3":"markdown","cc29ea20":"markdown","027d103b":"markdown","c4239af4":"markdown","9acd20a3":"markdown"},"source":{"ce62e76c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split  , GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier  \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix , classification_report\nimport warnings\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score,roc_curve\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nimport matplotlib.pyplot as plt\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\n\ndf = pd.read_csv('..\/input\/mushroom-classification\/mushrooms.csv')","00975c2a":"df.head()","fa2939c9":"df.shape","0b4edb0d":"df.isnull().sum()","e9a8259f":"df['class'].unique()\n","b6c78e91":"df['habitat'].value_counts()","1fa3f90c":"df.shape","741438c3":"from sklearn.preprocessing import LabelEncoder\ndef label_encoded(feat):\n    le = LabelEncoder()\n    le.fit(feat)\n    print(feat.name,le.classes_)\n#     print(le.classes_)\n    return le.transform(feat)","4ccd2b11":"for col in df.columns:\n    df[str(col)] = label_encoded(df[str(col)])","455e3b40":"df.head()","bf8f8dc6":"df.corr().T[:1]","9da3607a":"import seaborn as sns \nimport matplotlib.pyplot as plt \nplt.figure(figsize=(12,10))\nax = sns.heatmap(df.corr())","6163db3c":"fig = plt.figure(figsize = (20,15))\nax = fig.gca()\ndf.hist(ax=ax)\nplt.show()","0f8470cc":"sns.countplot(data=df, x=\"class\")\nplt.show()\n","7cf32390":"sns.countplot(data=df, x=\"habitat\")\nplt.show()\n","578e7a01":"sns.barplot(x = \"cap-shape\", y = \"class\", hue = \"cap-surface\", data = df);","0de67b73":"X = df.iloc[:,1:23]  # all rows, all the features and no labels\ny = df.iloc[:, 0]  # all rows, label only\nX.head()\ny.head()","075812ef":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX=scaler.fit_transform(X)\nX","8fe798b2":" from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test  = train_test_split(\n     X, y, test_size=0.2,random_state=42)","6a32030b":"loj_model = LogisticRegression()\nloj_model.fit(x_train, y_train)\npredicted=loj_model.predict(x_test)\nconf = confusion_matrix(y_test, predicted)","4023e9a0":"print (conf)","737de19e":"accuracy_score(y_test, predicted)","676a7300":"loj_model.coef_","aa9b637f":"print(classification_report(y_test, predicted))","ad3a056c":"loj_model.predict(x_test)[0:10]","43682333":"y_test","7ebc77da":"loj_model.predict_proba(x_train)[0:10]","d08252a3":"logit_roc_auc = roc_auc_score(y_test,loj_model.predict(x_test))\n\nfpr, tpr, thresholds = roc_curve(y_test, loj_model.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label=\"AUC (area = %0.2f)\" % logit_roc_auc)\nplt.plot([0, 1], [0, 1],\"r--\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Oran\u0131\")\nplt.ylabel(\"True Positive Oran\u0131\")\nplt.title(\"ROC\")\nplt.show()","b35c5a03":"X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = 0.30, \n                                                    random_state = 42)","efd1bbe2":"loj = LogisticRegression(solver = \"liblinear\")\nloj_model = loj.fit(X_train,y_train)\nloj_model","3ab3b916":"accuracy_score(y_test, loj_model.predict(X_test))","ce6a4092":"cross_val_score(loj_model, X_test, y_test, cv = 10).mean()","5cc7cf5e":"nb = GaussianNB()\nnb_model = nb.fit(X_train, y_train)\nnb_model","949b0416":"nb_model.predict(X_test)[0:10]","fead19fd":"nb_model.predict_proba(X_test)[0:10]","999695f8":"y_pred = nb_model.predict(X_test)","a6489a9f":"accuracy_score(y_test, y_pred)","54a37a45":"cross_val_score(nb_model, X_test, y_test, cv = 10).mean()","9b8621ce":"knn = KNeighborsClassifier()\nknn_model = knn.fit(X_train, y_train)\nknn_model","ec5b6267":"y_pred = knn_model.predict(X_test)\n\naccuracy_score(y_test, y_pred)","1da5c4cd":"cross_val_score(knn_model, X_test, y_test, cv = 10).mean()","a10e1c23":"print(classification_report(y_test, y_pred))","38c16e0f":"knn_params = { 'n_neighbors' : np.arange(3,20),\n              'leaf_size': np.arange(3,20)  }","92aae435":"knn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, knn_params, cv=10 , n_jobs = -1 ,  verbose = 2 )\nknn_cv.fit(X_train, y_train)","cd698c77":"print(\"best score:\" + str(knn_cv.best_score_))\nprint(\"The best parameters: \" + str(knn_cv.best_params_))","07008265":"knn = KNeighborsClassifier(leaf_size = 3 ,n_neighbors= 3  )\nknn_tuned = knn.fit(X_train, y_train)","a669bc85":"knn_tuned.score(X_test, y_test)","231a6ffd":"y_pred = knn_tuned.predict(X_test)","0b95cca7":"accuracy_score(y_test, y_pred)","9a8ee73a":"print(classification_report(y_test, y_pred))","ed4edf81":"svm_model = SVC(kernel = \"linear\").fit(X_train, y_train)\n\nsvm_model\n\ny_pred = svm_model.predict(X_test)\n\naccuracy_score(y_test, y_pred)","831c9ae6":"svc_params = {\"C\": np.arange(1,10),\n              'gamma': [1, 0.1, 0.01],\n              'kernel': ['rbf' ,\"linear\"]\n             }\n\nsvc = SVC()\n\nsvc_cv_model = GridSearchCV(svc,svc_params, \n                            cv = 10, \n                            n_jobs = -1, \n                            verbose = 2 )\n\nsvc_cv_model.fit(X_train, y_train)","3ebca2fb":"print(\"best score:\" + str(svc_cv_model.best_score_))\nprint(\"The best parameters: \" + str(svc_cv_model.best_params_))","e232bd09":"svc_tuned = SVC(kernel = \"rbf\", C = 1 , gamma = 0.1).fit(X_train, y_train)","c6400763":"y_pred = svc_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","f9593357":"svc_model = SVC(kernel = \"rbf\").fit(X_train, y_train)\n\ny_pred = svc_model.predict(X_test)\naccuracy_score(y_test, y_pred)","3592a7d6":"svc_params = {\"C\": [0.0001, 0.001, 0.1, 1, 5, 10 ,50 ,100],\n             \"gamma\": [0.0001, 0.001, 0.1, 1, 5, 10 ,50 ,100]}","732dc74a":"svc = SVC()\nsvc_cv_model = GridSearchCV(svc, svc_params, \n                         cv = 10, \n                         n_jobs = -1,\n                         verbose = 2)\n\nsvc_cv_model.fit(X_train, y_train)","e4f3720b":"print(\"best  params: \" + str(svc_cv_model.best_params_))","16bffe91":"svc_tuned = SVC(C = 1, gamma = 0.1).fit(X_train, y_train)","59a71f24":"y_pred = svc_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","e4c5a842":"cart = DecisionTreeClassifier()\ncart_model = cart.fit(X_train, y_train)","080b8c3c":"y_pred = cart_model.predict(X_test)\naccuracy_score(y_test, y_pred)","15125301":"cart_grid = {\"max_depth\": range(1,10),\n            \"min_samples_split\" : list(range(2,50)) }","0d68ec80":"cart =DecisionTreeClassifier()\ncart_cv = GridSearchCV(cart, cart_grid, cv = 10, n_jobs = -1, verbose = 2)\ncart_cv_model = cart_cv.fit(X_train, y_train)","82c0ce60":"print(\"best params : \" + str(cart_cv_model.best_params_))","32ac3bf2":"cart =DecisionTreeClassifier(max_depth = 7, min_samples_split = 2)\ncart_tuned = cart.fit(X_train, y_train)","69499e9a":"y_pred = cart_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","9c4d3337":"rf_model = RandomForestClassifier().fit(X_train, y_train)","4f9a57ea":"y_pred = rf_model.predict(X_test)\naccuracy_score(y_test, y_pred)","6f82d541":"rf_params = {\"max_depth\": [2,5,8,10],\n            \"max_features\": [2,3,4,5,6,7,8,9],\n            \"n_estimators\": [10,100,200],\n            \"min_samples_split\": [5,6,7,8,9,10]}","d6f25dce":"rf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                           n_jobs = -1, \n                           verbose = 2) ","64a11e27":"rf_cv_model.fit(X_train, y_train)","ec469326":"print(\"best params : \" + str(rf_cv_model.best_params_))","74ccdee6":"rf_tuned = RandomForestClassifier(max_depth = 10, \n                                  max_features = 3, \n                                  min_samples_split = 5,\n                                  n_estimators = 100)\n\nrf_tuned.fit(X_train, y_train)","a7338018":"y_pred = rf_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","92a6b064":"model = Sequential()\nmodel.add(Dense(32, input_dim=22, activation='relu'))\n\nmodel.add(Dense(16, activation='relu'))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","dba98833":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', patience=10,restore_best_weights=True)","2fa07fbd":"history=model.fit(x=X_train, \n          y=y_train, \n          epochs=80,\n          batch_size=200,\n          validation_data=(X_test, y_test),\n           callbacks=[early_stop]\n          )","6e8dbe45":"model.evaluate(X_test, y_test)","16b28608":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","cb1a4e8e":"# Gaussian Naive Bayes","dac7face":"#  CART","1ea4b232":"# Exploring Data","f9d1acc9":"#  Model Tuning","942fbacc":"# LogisticRegression\n","5ed603c2":"# Loading Data","364d758c":"# Model Tuning","dcba1a80":"# KNN","2bad65c4":"# SVC","720f329a":"## Split Data","1490087c":"# Model Tuning","86839ce3":"# Random Forests","cc29ea20":"# ANN","027d103b":"# RBF SVC","c4239af4":"# Model Tuning","9acd20a3":"# Model Tuning"}}