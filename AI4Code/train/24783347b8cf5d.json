{"cell_type":{"4f5d2ace":"code","fb685f50":"code","cbd83a25":"code","ae535ed3":"code","2f22819c":"code","05202b15":"code","f02bbd6f":"code","4b413e11":"code","8b22e4c5":"code","98ff00a3":"code","9125ee9b":"code","be16b046":"code","0d663e8e":"code","e1e84c2f":"code","a1597cbe":"code","77b4d4e4":"code","5f721de8":"code","491d7045":"code","c709abef":"code","b967ffc6":"code","364cd56e":"code","09da20bb":"code","f3def319":"code","8929508e":"code","07611618":"code","0cb806f9":"code","5a2325d9":"code","edf7d073":"code","bff6b83b":"code","6fe4319f":"code","e77468e7":"code","418f318d":"code","2fe92fc4":"code","8572c356":"code","47776d2c":"markdown","a717cfbc":"markdown","9adff1ad":"markdown","aa623953":"markdown","31e62c2c":"markdown"},"source":{"4f5d2ace":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fb685f50":"#Reading the Dataset\nmovie_data = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","cbd83a25":"# Check the head of the dataset\nmovie_data.head()","ae535ed3":"movie_data.describe()","2f22819c":"# Importing vader lexicon from NLTK\nimport nltk\nnltk.download('vader_lexicon')","05202b15":"#!pip3 install -U nltk[twitter]","f02bbd6f":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\nsia = SentimentIntensityAnalyzer()","4b413e11":"# Using SentimentIntensityAnalyzer lets get the polarity scores for each review\nmovie_data['scores'] = movie_data['review'].apply(lambda review: sia.polarity_scores(review))","8b22e4c5":"movie_data.head()","98ff00a3":"# Lets store the compound value alone in a column\nmovie_data['compound'] = movie_data['scores'].apply(lambda comp: comp['compound'])","9125ee9b":"# Based on the compound score mapping it as 0 or 1 \nmovie_data['comp_score'] = movie_data['compound'].apply(lambda c: 1 if c >= 0 else 0)","be16b046":"# mapping the sentiment as 0 for neg and 1 for positive\nmovie_data['sentiment'] = movie_data['sentiment'].map({'positive':1,'negative':0})","0d663e8e":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score","e1e84c2f":"f1 = f1_score(movie_data['sentiment'],movie_data['comp_score'],pos_label=1)\naccuracy = accuracy_score(movie_data['sentiment'],movie_data['comp_score'])\n\nprint(f\"Validation F1 Score  : {f1} and Accuracy Score {accuracy}\")","a1597cbe":"# Now lets try to do the same using Spacy\nimport spacy\nnlp = spacy.load('en_core_web_lg')","77b4d4e4":"# Fetching each of the review and storing it in a list\nreview_list = list(movie_data['review'].values)","5f721de8":"review_processed = list(nlp.pipe(review_list))","491d7045":"# Storing the values as a vector \nX = [review.vector for review in review_processed]\n\ny = movie_data['sentiment'].tolist()","c709abef":"# Splitting the data to train and test\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=77)","b967ffc6":"# Using DecisionTreeClassifier to predit the data\nfrom sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier()","364cd56e":"clf = clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","09da20bb":"f1 = f1_score(y_test, y_pred,pos_label=1)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"Validation F1 Score  : {f1} and Accuracy Score {accuracy}\")","f3def319":"# Using GradientBoostingClassifier to predit the data\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier()","8929508e":"gbc.fit(X_train, y_train)","07611618":"y_pred = gbc.predict(X_test)","0cb806f9":"f1 = f1_score(y_test, y_pred,pos_label=1)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"Validation F1 Score  : {f1} and Accuracy Score {accuracy}\")","5a2325d9":"# Using TFIDF and LinearSVC to predit the data\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC","edf7d073":"from sklearn.pipeline import Pipeline","bff6b83b":"text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                     ('clf', LinearSVC()),])","6fe4319f":"movie_data.head()","e77468e7":"X1 = movie_data['review']\n\ny1 = movie_data['sentiment']\n\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=77)","418f318d":"text_clf.fit(X1_train, y1_train)","2fe92fc4":"predictions = text_clf.predict(X1_test)","8572c356":"f1 = f1_score(y1_test, predictions,pos_label=1)\naccuracy = accuracy_score(y1_test, predictions)\n\nprint(f\"Validation F1 Score  : {f1} and Accuracy Score {accuracy}\")","47776d2c":"VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment \nanalysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.","a717cfbc":"We get the approx accuracy of 0.90 and an F1 score of 0.90\n\n\nDo let me know how to improve the models more for better predictions","9adff1ad":"We get the approx accuracy of 0.82 and an F1 score of 0.82","aa623953":"We get the approx accuracy of 0.69 and an F1 score of 0.74","31e62c2c":"We get the approx accuracy of 0.67 and an F1 score of 0.67"}}