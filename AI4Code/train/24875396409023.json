{"cell_type":{"cef09ae9":"code","a3d18296":"code","330e0305":"code","c517f948":"code","fb4a3b42":"code","163012f3":"code","d36ded6d":"code","a9fed930":"code","8182fa36":"code","27487a7f":"code","cd83ea44":"code","94817294":"code","fbd69418":"code","069b1aa3":"code","d048bdf4":"code","24dbdb76":"code","50a44347":"code","a63bb255":"code","282bb59c":"code","fe620cd9":"code","315db012":"code","c17261d7":"code","f8b73ca5":"markdown","336bea3c":"markdown","a6b3f73e":"markdown","4bf750aa":"markdown","ad00497d":"markdown","2fcfd56a":"markdown"},"source":{"cef09ae9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a3d18296":"import random\nimport gc\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve,RocCurveDisplay,ConfusionMatrixDisplay,confusion_matrix,roc_auc_score,accuracy_score\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn import preprocessing\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","330e0305":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\ny = train['target']","c517f948":"train.head()","fb4a3b42":"test.head()","163012f3":"train.info()","d36ded6d":"test.info()","a9fed930":"#Check if there'is null values\ntrain.isnull().sum()","8182fa36":"#Check if there'is null values\ntest.isnull().sum()","27487a7f":"train.describe()","cd83ea44":"test.describe()","94817294":"cols = ['f'+str(i) for i in range(100)]","fbd69418":"# plot the first 32 features \ni = 1\nplt.figure()\nfig, ax = plt.subplots(8, 4,figsize=(20, 22))\nfor feature in cols[:32]:\n    plt.subplot(8, 4,i)\n    sns.histplot(train[feature],color=\"blue\", kde=True,bins=100, label='train_'+feature)\n    sns.histplot(test[feature],color=\"olive\", kde=True,bins=100, label='test_'+feature)\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","069b1aa3":"sns.catplot(x=\"target\", kind=\"count\", palette=\"ch:.25\", data=train)","d048bdf4":"## Target distibution\npie, ax = plt.subplots(figsize=[18,8])\ntrain.groupby('target').size().plot(kind='pie',autopct='%.1f',ax=ax,title='Target distibution')","24dbdb76":"# apply standard scaler to the data\nscaler = StandardScaler()\ntrain[cols] = scaler.fit_transform(train[cols])\ntest[cols] = scaler.transform(test[cols])","50a44347":"preds = np.zeros(test.shape[0])\nkf = StratifiedKFold(n_splits=15,random_state=48,shuffle=True)\nauc=[]  # list contains auc for each fold\nacc=[]  # list contains accuracy for each fold\nn=0\nfor trn_idx, test_idx in kf.split(train[cols],y):\n    X_tr,X_val=train[cols].iloc[trn_idx],train[cols].iloc[test_idx]\n    y_tr,y_val=y.iloc[trn_idx],y.iloc[test_idx]\n    \n    model = LogisticRegression(solver='liblinear')\n    model.fit(X_tr,y_tr)\n    preds += model.predict_proba(test[cols])[:,1]\/kf.n_splits\n    \n    auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]))\n    acc.append(accuracy_score(y_val, model.predict(X_val)))\n\n    print(f\"fold: {n+1} , accuracy: {round(acc[n]*100,3)} , auc: {round(auc[n]*100,3)}\")\n    n+=1  ","a63bb255":"print(f\"the mean AUC is : {round(np.mean(auc)*100,2)} while the mean Accuracy is : {round(np.mean(acc)*100,2)} \")","282bb59c":"# Plot of confusion matrix for the last fold\ncm = confusion_matrix(model.predict(X_val),y_val)\ncm_display = ConfusionMatrixDisplay(cm).plot()","fe620cd9":"# Plot of roc curve for the last fold\ny_pred_proba = model.predict_proba(X_val)[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_val,  y_pred_proba)\nauc = metrics.roc_auc_score(y_val, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data, auc for fold 15=\"+str(round(auc*100,2)))\nplt.legend(loc=4)\nplt.show()","315db012":"sub['target']=preds\nsub.to_csv('submission.csv', index=False)","c17261d7":"sub","f8b73ca5":"* Binary classification problem has only two classes to classify like in this competition, preferably a positive and a negative class.\n* <b> True Positive (TP)<\/b>: It refers to the number of predictions where the classifier correctly predicts the positive class as positive.\n* <b>True Negative (TN)<\/b>: It refers to the number of predictions where the classifier correctly predicts the negative class as negative.\n* <b>False Positive (FP)<\/b>: It refers to the number of predictions where the classifier incorrectly predicts the negative class as positive.\n* <b>False Negative (FN)<\/b>: It refers to the number of predictions where the classifier incorrectly predicts the positive class as negative.\n<img src=\"https:\/\/miro.medium.com\/max\/1000\/1*fxiTNIgOyvAombPJx5KGeA.png\" width=\"600px\"\/>","336bea3c":"## I hope that you find this kernel usefull\ud83c\udfc4","a6b3f73e":"# Let's Make a Submission","4bf750aa":"# Modeling","ad00497d":"# Hi kagglers \ud83d\ude4b\ud83c\udffb\u200d\u2642\ufe0f and Welcome to this new competition!","2fcfd56a":"# Some Exploratory Data Analysis"}}