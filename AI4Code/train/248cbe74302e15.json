{"cell_type":{"0994292a":"code","3ada5676":"code","b473b906":"code","6dc81f12":"code","08191f07":"code","c87f056c":"code","3b7992be":"code","d3f3fc49":"code","daac57fd":"code","8168341d":"code","6653a600":"code","c91aab62":"code","ac01ac97":"code","b5bac9bc":"code","844b2f4a":"code","dc037a06":"code","64817cb0":"code","e3650809":"code","5d2a1d43":"code","035d8b7d":"code","ee13a8fb":"markdown","7e41a796":"markdown","4c9fb684":"markdown","f01c6cc3":"markdown","fbfd0cde":"markdown","386d1d0c":"markdown","0ff6ec88":"markdown","c1e16b4b":"markdown","0bb73a3e":"markdown","0e1ef2c7":"markdown","7eb50c7a":"markdown","cda9df7d":"markdown","0f99f15a":"markdown","760c33e8":"markdown"},"source":{"0994292a":"pip install segmentation-models","3ada5676":"import numpy as np\nimport pandas as pd \nimport cv2\nimport os\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nimport keras\nimport json\nimport tqdm\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\nimport gc\nfrom segmentation_models import Unet\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import Sequence\nfrom keras.optimizers import Adam\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir('..\/input'))\n","b473b906":"seed = 2019\nBATCH_SIZE = 8","6dc81f12":"traindf = pd.read_csv('..\/input\/severstal-steel-defect-detection\/train.csv')","08191f07":"traindf['ImageId'] = traindf['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntraindf['ClassId'] = traindf['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntraindf['hasMask'] = ~traindf['EncodedPixels'].isna()","c87f056c":"traindf.head()","3b7992be":"mask_counts = traindf.groupby('ImageId')['hasMask'].sum().reset_index()\nmask_counts.sort_values(by = 'hasMask', ascending = False).head()","d3f3fc49":"mask_counts['hasMask'].value_counts().plot.bar()","daac57fd":"mask_counts.shape","8168341d":"mask_counts = mask_counts.reset_index(drop = True)","6653a600":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","c91aab62":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='..\/input\/severstal-steel-defect-detection\/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=3,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}\/{im_name}\"\n            img = self.__load_rgb(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) \/ 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) \/ 255.\n\n        return img","ac01ac97":"all_index = mask_counts.index\ntrn_idx, val_idx = train_test_split(all_index, test_size = 0.2, random_state = seed)","b5bac9bc":"train_generator = DataGenerator(\n    trn_idx, \n    df=mask_counts,\n    target_df=traindf,\n    batch_size=BATCH_SIZE, \n    n_classes=4,\n    random_state = seed\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_counts,\n    target_df=traindf,\n    batch_size=BATCH_SIZE, \n    n_classes=4,\n    random_state = seed\n)","844b2f4a":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","dc037a06":"model = Unet('resnet18', classes=4, activation='softmax', input_shape = (256,1600,3))","64817cb0":"model.summary()","e3650809":"model.compile(Adam(lr = 0.005), loss=bce_jaccard_loss, metrics=[iou_score, dice_coef])","5d2a1d43":"checkpoint = ModelCheckpoint(\n    'Unet_resnet18.h5', \n    monitor='val_loss', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nreducelr = ReduceLROnPlateau(monitor = 'val_loss', min_lr = 1e-6, factor = 0.1, verbose = 1, patience = 5)\n\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint, reducelr],\n    use_multiprocessing=True,\n    workers=6,\n    epochs=15\n)","035d8b7d":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n    \n\nhistory_df = pd.DataFrame(history.history)\n\nplt.figure(figsize = (15,5))\nplt.title('Plot of Loss')\nhistory_df[['loss', 'val_loss']].plot()\n\nplt.figure(figsize = (15,5))\nplt.title('Plot of Dice Coefficient')\nhistory_df[['dice_coef', 'val_dice_coef']].plot()\n\nplt.figure(figsize = (15,5))\nplt.title('Plot of IOU score')\nhistory_df[['iou_score', 'val_iou_score']].plot()","ee13a8fb":"**Jaccard Loss** : This loss is usefull when you have unbalanced classes within a sample such as segmenting each pixel of an image\n\n**Read more** : https:\/\/segmentation-models.readthedocs.io\/en\/latest\/api.html","7e41a796":"<h1><center><font size=\"6\">SEVERSTAL STEEL <\/font><\/center><\/h1>\n\n\n<img src=\"https:\/\/thumbs.dreamstime.com\/b\/roll-steel-sheet-factory-d-rendering-79415588.jpg\" width=\"800\"><\/img>\n\n<br>","4c9fb684":"## Importing Libraries","f01c6cc3":"## Building and Training Unet with Resnet18 as Backbone","fbfd0cde":"Other backbones and architectures can be found here : https:\/\/github.com\/qubvel\/segmentation_models","386d1d0c":"# Contents :\n* Importing Libraries\n* Arranging DataSet\n* Utility Functions\n* Building and Training Unet with ResNet18 Backbone\n* Plotting the History of Model","0ff6ec88":"## Utility Functions","c1e16b4b":"## DataGenerator on the Fly","0bb73a3e":"## Arranging the Dataset","0e1ef2c7":"This kernel makes use of **segmentation_models** library for **Keras**. This library makes building segmentation models with different architectures and different backbones really easy. Very friendly for beginners like me ! \n\nBut to progress in this competition it will always help to know the intricacies of model, backbone and various training methods. \nSource of the library : https:\/\/github.com\/qubvel\/segmentation_models\n\n\n**Tip : To change the architecture of the model, just import the particular model from segmentation_models library. The available architectures are FPN, LinkNet, PSPNet. The available backbones are many like ResNets, DenseNets, EfficientNets, etc.** \n\n**If you like the kernel, please upvote it. It motivates me . Happy Kaggling**","7eb50c7a":"**Taken from** : https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-2-step-pipeline","cda9df7d":"## Plotting history of the Model","0f99f15a":"Some code is borrowed from : https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-2-step-pipeline\n\nThank you xhlulu. All beginners like me are learning a lot from you. ","760c33e8":"**Taken from** : https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-2-step-pipeline\n\n**Original work** : https:\/\/stanford.edu\/~shervine\/blog\/keras-how-to-generate-data-on-the-fly"}}