{"cell_type":{"2fce15d8":"code","bc21a21d":"code","3d3fe2cc":"code","b080571e":"code","b92e21f5":"code","3436e816":"code","44b4312d":"code","1a3623ee":"code","01a7b5da":"code","98677529":"code","c21367b8":"code","95bc80c3":"code","a2bb11d3":"code","34fbc0b9":"code","6d392e9f":"code","22ea348b":"code","580b6952":"code","59e77711":"code","b927e93d":"code","8c5d0f15":"code","d160382c":"code","e94f4b65":"code","cf96ff75":"code","a12e24d6":"code","d1e99df7":"code","963f165b":"code","49eeac80":"code","fb3cb383":"code","efec130e":"code","46f057ab":"code","75a34525":"code","309e8360":"code","9e2f19c2":"code","a50f391f":"markdown","c441e3c8":"markdown","5df44b97":"markdown","470628db":"markdown","a0f3c96f":"markdown","8730602b":"markdown","641aa3a1":"markdown","005c3f7e":"markdown","f957d894":"markdown","25440180":"markdown","a5deedf2":"markdown","5bdca224":"markdown","3e1b72b3":"markdown","d48f7b3e":"markdown","a7630f63":"markdown","a9cb317a":"markdown","d0ec2f88":"markdown","4adf2d64":"markdown","112e99cd":"markdown","abfb727b":"markdown","8b32cfd0":"markdown","8a824ffa":"markdown","f97d8eac":"markdown","10568bd4":"markdown","ccf1ec36":"markdown","cd25ab31":"markdown","8322c7fa":"markdown","7d9e90ea":"markdown"},"source":{"2fce15d8":"%matplotlib inline","bc21a21d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score","3d3fe2cc":"student_performance = pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")","b080571e":"student_performance.head()","b92e21f5":"student_performance.shape","3436e816":"student_performance.describe().T","44b4312d":"student_performance.isna().any()","1a3623ee":"student_performance[\"gender\"].value_counts()","01a7b5da":"fig, ax = plt.subplots(figsize = (8, 5)) \nsns.countplot(data = student_performance, x = \"gender\", hue = \"race\/ethnicity\", palette = \"Blues\")\nax.set(title = \"Students by gender and race\/ethnicity\", ylabel = \"number\")\nplt.show()","98677529":"student_performance[\"test preparation course\"].value_counts()","c21367b8":"fig, ax = plt.subplots(figsize = (8, 5)) \nsns.countplot(data = student_performance, x = \"test preparation course\", hue = \"parental level of education\", palette = \"Blues\")\nax.set(title = \"Students by test preparation and parental level of education\", ylabel = \"number\")\nplt.show()","95bc80c3":"# Encode categorical variables\nsp = student_performance.copy()\ncol = [\"gender\", \"race\/ethnicity\", \"parental level of education\", \"lunch\", \"test preparation course\"]\nfor title in col:\n    sp[title] = LabelEncoder().fit_transform(sp[title])\ncorr = sp.corr()","a2bb11d3":"plt.figure(figsize = (8, 6))\nsns.heatmap(corr, fmt = \".2f\", cmap = \"Blues\", annot = True,\n           linewidths = 2, vmin = -1.0, vmax = 1.0)\nplt.show()","34fbc0b9":"math = student_performance[\"math score\"]\nreading = student_performance[\"reading score\"]\nwriting = student_performance[\"writing score\"]","6d392e9f":"# Display score distribution in three subjects\nsns.set_palette(\"Paired\")\nplt.figure(figsize=(8,5))\nplt.hist(math, alpha = 0.8, label = \"math\")\nplt.hist(reading, alpha = 0.8, label = \"reading\")\nplt.hist(writing, alpha = 0.8, label = \"writing\")\nplt.xlabel(\"Scores\")\nplt.ylabel(\"Number of students\")\nplt.title(\"Students' scores in math, reading and writing\")\nplt.legend()\nplt.show()","22ea348b":"col = student_performance.loc[: , \"math score\":\"writing score\"]","580b6952":"student_performance[\"mean_score\"] = col.mean(axis = 1)","59e77711":"student_performance.head()","b927e93d":"student_performance = pd.get_dummies(student_performance)","8c5d0f15":"student_performance.head()","d160382c":"student_performance.dtypes","e94f4b65":"student_performance = student_performance.astype(\"float32\")","cf96ff75":"student_performance = student_performance[[\"gender_female\", \"gender_male\", \"race\/ethnicity_group A\", \"race\/ethnicity_group B\",\n                          \"race\/ethnicity_group C\", \"race\/ethnicity_group D\", \"race\/ethnicity_group E\",\n                          \"parental level of education_associate's degree\", \n                          \"parental level of education_bachelor's degree\",\n                          \"parental level of education_high school\", \n                          \"parental level of education_master's degree\", \"parental level of education_some college\",\n                          \"parental level of education_some high school\", \"lunch_free\/reduced\", \"lunch_standard\",\n                          \"test preparation course_completed\", \"test preparation course_none\", \n                          \"math score\", \"reading score\", \"writing score\", \"mean_score\"]]","a12e24d6":"features = student_performance.drop(\"mean_score\", axis = 1).values","d1e99df7":"target = student_performance[\"mean_score\"].values","963f165b":"scaler = StandardScaler()","49eeac80":"features_scaled = scaler.fit_transform(features)","fb3cb383":"features_train, features_test, target_train, target_test = train_test_split(features_scaled, target,\n                                                                        test_size = 0.1,\n                                                                        random_state = 42)","efec130e":"features_train.shape, target_train.shape, features_test.shape, target_test.shape","46f057ab":"lr = LinearRegression()","75a34525":"lr.fit(features_train, target_train)","309e8360":"predicted = lr.predict(features_test)","9e2f19c2":"print(f\"MSE, testing set: {mean_squared_error(target_test, predicted)}\")\nprint(f\"RMSE, testing set: {np.sqrt(mean_squared_error(target_test, predicted))}\")\nprint(f\"R-squared on testing set: {r2_score(target_test, predicted)}\")","a50f391f":"Linear regression is (perhaps) the simplest modelling algorithm. It does not have hyper parameters and does not require specific fine-tuning. Thus, the function is only instantiated as it is and the data (features and target) are passed to it.","c441e3c8":"Next step is to make all features numeric. To that end, all categorical variables are passed through `pd.get_dummies` and thus converted into numeric ones.","5df44b97":"## 1. Load data","470628db":"The dataset is loaded and stored in `student_performance`. Its features are displayed below.","a0f3c96f":"## 4. Modelling","8730602b":"### Imports","641aa3a1":"Furthermore, features are rearranged since `get_dummies` function placed dummies in the right side of the table. Now, scores and their mean are moved to the end.","005c3f7e":"Features should be scaled before being passed to a machine learning algorithm. `scikit-learn` `StandardScaler()` will do this job; it makes all values between 0 and 1.","f957d894":"The correlation matrix below indicates that there is a strong positive (linear) correlation only between exam scores. Other variables do not reveal any robust inter-links.","25440180":"The code line below confirms that there are not missing values in the dataset. ","a5deedf2":"Most columns hold \"uint8\" or \"int64\" values. It is important, however, all features to be floating point numbers. Therefore, their type is changed to \"float32\".","5bdca224":"Performance metrics (see below) suggest that model is quite good: Root Mean Squared Error is negligible and R-squared reached almost 100%.","3e1b72b3":"## 2. Exploratory Data Analysis","d48f7b3e":"Slightly more female than male students took the exams. Majority of girls and boys declared \"Group C\" ethicity, followed by those in \"Group D\".","a7630f63":"Predicting values is a supervised learning task. The latter means that an algorithm will expect independent (features) and dependent (target) variables. In this particular case, \"mean score\" is the target variable and is separated from \"features\" and stored in \"target\".","a9cb317a":"The dataset with mean scores is displayed below.","d0ec2f88":"## 3. Preprocessing","4adf2d64":"Data should be pre-processed before being passed to a modelling algorithm. First thing first is to calculate the target variable - a mean score computed as the average of math, reading, and writing.","112e99cd":"## Introduction","abfb727b":"All three subjects\u2019 mean score is around 66-69 with standard deviation of 14-15 points. Scores range between 0 and 100 but neither student got zero in reading or writing.","8b32cfd0":"Students' performance dataset holds 1000 samples with 8 features: gender, race or ethnicity, parental level of education, lunch mode, taken or not test preparation course, and scores in math, reading, and writing.","8a824ffa":"The last preprocessing step is to split data into training and testing set (validation step is skipped here) and to check if all sets are in proper shape. Only 10% of samples are withheld for testing.","f97d8eac":"Model's performance is evaluated by applying `predict` on the testing data.","10568bd4":"# Predicting students' performance on exams","ccf1ec36":"Scores in all three subjects have similar distribution.","cd25ab31":"A model using \"Students Performance in Exams\" dataset (available in Kaggle at this [link](https:\/\/www.kaggle.com\/spscientist\/students-performance-in-exams)) predicts a mean score (computed as the average of math, reading, and writing scores) that a student would get based on certain demographic, social, and academic features.","8322c7fa":"Data also show that two thirds of students didn't attend a test preparation course. This choice was not determined by the educational level attained by their parents.","7d9e90ea":"Thus, a student's background and success on exams are good predictors of the mean score he or she will most likely achieve."}}