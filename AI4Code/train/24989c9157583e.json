{"cell_type":{"60fc0e92":"code","535c5bb4":"code","968adcde":"code","373bd102":"code","833108c0":"code","e4a1d933":"code","b4882db5":"code","fba81d62":"code","143b1edd":"code","5b66f6e4":"code","c77b40cd":"code","932d88e4":"code","b80c3829":"markdown","3f9eb618":"markdown","f99473a0":"markdown","e98ae78d":"markdown","892c7ec8":"markdown","2f1296f9":"markdown","e8ce373b":"markdown","ca3f9b4e":"markdown","94e1cd12":"markdown","fbe37094":"markdown"},"source":{"60fc0e92":"import numpy as np \nimport pandas as pd \n\nfrom sklearn import ensemble\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_validate,GridSearchCV","535c5bb4":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","968adcde":"#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","373bd102":"train.info()","833108c0":"y = train['Survived']\nX = train.drop(['Survived'], axis=1)\nX_test = test","e4a1d933":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(  X, y, test_size=0.25, random_state=42)","b4882db5":"params={\"n_estimators\":np.arange(100,500,100),\n        \"max_depth\":np.arange(1,11,2)\n       }","fba81d62":"rf_est = ensemble.RandomForestClassifier(\n    criterion = 'gini', \n    max_features = 'sqrt', \n    n_jobs = -1, \n    random_state = 42, \n    verbose = 0)\n\ngr_rf_est=GridSearchCV(rf_est,params,cv=5,n_jobs=-1,verbose=10)\n\ngbm_est = ensemble.GradientBoostingClassifier(\n    learning_rate = 0.01, \n    loss = 'exponential', \n    max_features ='sqrt', \n    random_state = 2021, \n    verbose = 0)\ngr_gbm_est=GridSearchCV(gbm_est,params,cv=5,n_jobs=-1,verbose=10)\n\net_est = ensemble.ExtraTreesClassifier(\n    max_features = 'sqrt', \n    n_jobs = -1, \n    criterion = 'entropy', \n    random_state = 1004, \n    verbose = 0)\ngr_et_est=GridSearchCV(et_est,params,cv=5,n_jobs=-1,verbose=10)\n\n","143b1edd":"voting_clf = ensemble.VotingClassifier(\n    estimators = [('rf', gr_rf_est),('gbm', gr_gbm_est),('et', gr_et_est)],\n    voting = 'soft', \n    weights = [5,2,7],\n    n_jobs = -1,\n   verbose = 1)\n\nvoting_clf.fit(X_train, y_train)","5b66f6e4":"for clf in (voting_clf.estimators_ + [voting_clf]):\n    y_pred = clf.predict(X_val)\n    print(clf.__class__.__name__, accuracy_score(y_val, y_pred))","c77b40cd":"pred_test = voting_clf.predict(X_test)","932d88e4":"submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = (pred_test > 0.5).astype(int)\nsubmission.to_csv('sub.csv', index=False)\nsubmission.head()","b80c3829":"# GridSearch Ensembel ","3f9eb618":"# predict test data using voting model","f99473a0":"# submit result","e98ae78d":"# preprocessing","892c7ec8":"# evaluate model","2f1296f9":"# split data (train data \/ validation data)","e8ce373b":"# split data ( input data \/ label data )","ca3f9b4e":"# voting -> build model","94e1cd12":"# import libraries","fbe37094":"# load data "}}