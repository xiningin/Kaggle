{"cell_type":{"fe747414":"code","5adf76fa":"code","f9fd744f":"code","07a23c6e":"code","3b218487":"code","212974a9":"code","ddbaffc1":"code","1e6d98cf":"code","5d2bd7a1":"code","5df85203":"code","ecf20a99":"code","399c916d":"code","15d4a387":"code","79376a12":"code","f259551f":"code","947a561d":"code","aa63168d":"markdown","b89b7801":"markdown","340fc306":"markdown","b5c26733":"markdown","811c5f20":"markdown","b0aa8cbc":"markdown","1e90bd91":"markdown","9eefe209":"markdown","8ee46ac0":"markdown","1447d83d":"markdown","5d533989":"markdown"},"source":{"fe747414":"!pip install efficientnet tensorflow_addons > \/dev\/null","5adf76fa":"import os \nimport re\nimport warnings\nfrom glob import glob\nfrom tqdm.auto import tqdm \nfrom scipy.signal import get_window\nfrom typing import Optional, Tuple\n\n\nimport numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,KFold\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model , load_model, save_model \nfrom tensorflow.keras.layers import Input,Dropout,Conv2D,Flatten,GlobalAveragePooling2D,Dense,GlobalAvgPool2D\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nimport tensorflow_addons as tfa\n","f9fd744f":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","07a23c6e":"class config:\n    seed = 2021\n    # GCS_PATH = KaggleDatasets().get_gcs_path(\"cqt-g2net-v2-0-1\")\n    replicas = strategy.num_replicas_in_sync\n    batch_size = 32 * replicas\n    AUTO = tf.data.experimental.AUTOTUNE\n    dir_path = '.\/result'\n    epochs = 20\n    #augmentations\n    image_size = 512\n    aug = True \n    mix_up_p = 0.1\n    s_shift = 0.0\n    t_shift = 0.0\n    r_angle = 0 \/ 180 * np.pi\n    label_positive_shift = 0.99\n\nif not os.path.exists(config.dir_path):\n    os.makedirs(config.dir_path)","3b218487":"IMAGE_SIZE = 256\nBATCH_SIZE = 32\nEFFICIENTNET_SIZE = 1\nWEIGHTS = \"imagenet\"\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync","212974a9":"# Dataset of Hidehisa Arai\n\ntrain_files = ['gs:\/\/kds-fe725ba5a3259c712812aed413cfe61fc3827b135988e28e694e515c\/train0.tfrecords',\n 'gs:\/\/kds-fe725ba5a3259c712812aed413cfe61fc3827b135988e28e694e515c\/train1.tfrecords',\n 'gs:\/\/kds-fe725ba5a3259c712812aed413cfe61fc3827b135988e28e694e515c\/train2.tfrecords',\n 'gs:\/\/kds-fe725ba5a3259c712812aed413cfe61fc3827b135988e28e694e515c\/train3.tfrecords',\n 'gs:\/\/kds-fe725ba5a3259c712812aed413cfe61fc3827b135988e28e694e515c\/train4.tfrecords',\n 'gs:\/\/kds-ecd1c4515f350d79d5a8d2e9a07df52885278c6cce43ad116c8b03cb\/train5.tfrecords',\n 'gs:\/\/kds-ecd1c4515f350d79d5a8d2e9a07df52885278c6cce43ad116c8b03cb\/train6.tfrecords',\n 'gs:\/\/kds-ecd1c4515f350d79d5a8d2e9a07df52885278c6cce43ad116c8b03cb\/train7.tfrecords',\n 'gs:\/\/kds-ecd1c4515f350d79d5a8d2e9a07df52885278c6cce43ad116c8b03cb\/train8.tfrecords',\n 'gs:\/\/kds-ecd1c4515f350d79d5a8d2e9a07df52885278c6cce43ad116c8b03cb\/train9.tfrecords',\n 'gs:\/\/kds-2c0b3b314d8607851f6dddea1e976aab52547b68de5117cf3e76a85a\/train10.tfrecords',\n 'gs:\/\/kds-2c0b3b314d8607851f6dddea1e976aab52547b68de5117cf3e76a85a\/train11.tfrecords',\n 'gs:\/\/kds-2c0b3b314d8607851f6dddea1e976aab52547b68de5117cf3e76a85a\/train12.tfrecords',\n 'gs:\/\/kds-2c0b3b314d8607851f6dddea1e976aab52547b68de5117cf3e76a85a\/train13.tfrecords',\n 'gs:\/\/kds-2c0b3b314d8607851f6dddea1e976aab52547b68de5117cf3e76a85a\/train14.tfrecords',\n 'gs:\/\/kds-965e4184655c915b40b37bf7e5d3c8e310dd5751e8a2e1f5bdc8d70d\/train15.tfrecords',\n 'gs:\/\/kds-965e4184655c915b40b37bf7e5d3c8e310dd5751e8a2e1f5bdc8d70d\/train16.tfrecords',\n 'gs:\/\/kds-965e4184655c915b40b37bf7e5d3c8e310dd5751e8a2e1f5bdc8d70d\/train17.tfrecords',\n 'gs:\/\/kds-965e4184655c915b40b37bf7e5d3c8e310dd5751e8a2e1f5bdc8d70d\/train18.tfrecords',\n 'gs:\/\/kds-965e4184655c915b40b37bf7e5d3c8e310dd5751e8a2e1f5bdc8d70d\/train19.tfrecords']\n\ntest_files =  ['gs:\/\/kds-3af0f2c792ef9e6f5d3c87bb80c99a263fc9707106cd595aaf02e3eb\/test0.tfrecords',\n 'gs:\/\/kds-3af0f2c792ef9e6f5d3c87bb80c99a263fc9707106cd595aaf02e3eb\/test1.tfrecords',\n 'gs:\/\/kds-3af0f2c792ef9e6f5d3c87bb80c99a263fc9707106cd595aaf02e3eb\/test2.tfrecords',\n 'gs:\/\/kds-3af0f2c792ef9e6f5d3c87bb80c99a263fc9707106cd595aaf02e3eb\/test3.tfrecords',\n 'gs:\/\/kds-3af0f2c792ef9e6f5d3c87bb80c99a263fc9707106cd595aaf02e3eb\/test4.tfrecords',\n 'gs:\/\/kds-9eb3135b732342c0aec8339381fec9fd19f8a7ad94ca9c31ad51fe2b\/test5.tfrecords',\n 'gs:\/\/kds-9eb3135b732342c0aec8339381fec9fd19f8a7ad94ca9c31ad51fe2b\/test6.tfrecords',\n 'gs:\/\/kds-9eb3135b732342c0aec8339381fec9fd19f8a7ad94ca9c31ad51fe2b\/test7.tfrecords',\n 'gs:\/\/kds-9eb3135b732342c0aec8339381fec9fd19f8a7ad94ca9c31ad51fe2b\/test8.tfrecords',\n 'gs:\/\/kds-9eb3135b732342c0aec8339381fec9fd19f8a7ad94ca9c31ad51fe2b\/test9.tfrecords']","ddbaffc1":"# Function to create cqt kernel\ndef create_cqt_kernels(\n    q: float,\n    fs: float,\n    fmin: float,\n    n_bins: int = 84,\n    bins_per_octave: int = 12,\n    norm: float = 1,\n    window: str = \"hann\",\n    fmax: Optional[float] = None,\n    topbin_check: bool = True\n) -> Tuple[np.ndarray, int, np.ndarray, float]:\n    fft_len = 2 ** _nextpow2(np.ceil(q * fs \/ fmin))\n    \n    if (fmax is not None) and (n_bins is None):\n        n_bins = np.ceil(bins_per_octave * np.log2(fmax \/ fmin))\n        freqs = fmin * 2.0 ** (np.r_[0:n_bins] \/ np.float(bins_per_octave))\n    elif (fmax is None) and (n_bins is not None):\n        freqs = fmin * 2.0 ** (np.r_[0:n_bins] \/ np.float(bins_per_octave))\n    else:\n        warnings.warn(\"If nmax is given, n_bins will be ignored\", SyntaxWarning)\n        n_bins = np.ceil(bins_per_octave * np.log2(fmax \/ fmin))\n        freqs = fmin * 2.0 ** (np.r_[0:n_bins] \/ np.float(bins_per_octave))\n    if np.max(freqs) > fs \/ 2 and topbin_check:\n        raise ValueError(f\"The top bin {np.max(freqs)} Hz has exceeded the Nyquist frequency, \\\n                           please reduce the `n_bins`\")\n    \n    kernel = np.zeros((int(n_bins), int(fft_len)), dtype=np.complex64)\n    \n    length = np.ceil(q * fs \/ freqs)\n    for k in range(0, int(n_bins)):\n        freq = freqs[k]\n        l = np.ceil(q * fs \/ freq)\n        \n        if l % 2 == 1:\n            start = int(np.ceil(fft_len \/ 2.0 - l \/ 2.0)) - 1\n        else:\n            start = int(np.ceil(fft_len \/ 2.0 - l \/ 2.0))\n\n        sig = get_window(window, int(l), fftbins=True) * np.exp(\n            np.r_[-l \/\/ 2:l \/\/ 2] * 1j * 2 * np.pi * freq \/ fs) \/ l\n        \n        if norm:\n            kernel[k, start:start + int(l)] = sig \/ np.linalg.norm(sig, norm)\n        else:\n            kernel[k, start:start + int(l)] = sig\n    return kernel, fft_len, length, freqs\n\ndef _nextpow2(a: float) -> int:\n    return int(np.ceil(np.log2(a)))\n\n# Function to prepare cqt kernel\ndef prepare_cqt_kernel(\n    sr=22050,\n    hop_length=512,\n    fmin=32.70,\n    fmax=None,\n    n_bins=84,\n    bins_per_octave=12,\n    norm=1,\n    filter_scale=1,\n    window=\"hann\"\n):\n    q = float(filter_scale) \/ (2 ** (1 \/ bins_per_octave) - 1)\n    print(q)\n    return create_cqt_kernels(q, sr, fmin, n_bins, bins_per_octave, norm, window, fmax)\n# Function to create cqt image\ndef create_cqt_image(wave, hop_length=16):\n    CQTs = []\n    for i in range(3):\n        x = wave[i]\n        x = tf.expand_dims(tf.expand_dims(x, 0), 2)\n        x = tf.pad(x, PADDING, \"REFLECT\")\n\n        CQT_real = tf.nn.conv1d(x, CQT_KERNELS_REAL, stride=hop_length, padding=\"VALID\")\n        CQT_imag = -tf.nn.conv1d(x, CQT_KERNELS_IMAG, stride=hop_length, padding=\"VALID\")\n        CQT_real *= tf.math.sqrt(LENGTHS)\n        CQT_imag *= tf.math.sqrt(LENGTHS)\n\n        CQT = tf.math.sqrt(tf.pow(CQT_real, 2) + tf.pow(CQT_imag, 2))\n        CQTs.append(CQT[0])\n    return tf.stack(CQTs, axis=2)\n\nHOP_LENGTH = 64\ncqt_kernels, KERNEL_WIDTH, lengths, _ = prepare_cqt_kernel(\n    sr=2048,\n    hop_length=HOP_LENGTH,\n    fmin=20,\n    fmax=500,\n    bins_per_octave=12)\nLENGTHS = tf.constant(lengths, dtype=tf.float32)\nCQT_KERNELS_REAL = tf.constant(np.swapaxes(cqt_kernels.real[:, np.newaxis, :], 0, 2))\nCQT_KERNELS_IMAG = tf.constant(np.swapaxes(cqt_kernels.imag[:, np.newaxis, :], 0, 2))\nPADDING = tf.constant([[0, 0],\n                        [KERNEL_WIDTH \/\/ 2, KERNEL_WIDTH \/\/ 2],\n                        [0, 0]])","1e6d98cf":"def read_labeled_tfrecord(example):\n    tfrec_format = {\n        \"wave\": tf.io.FixedLenFeature([], tf.string),\n        \"wave_id\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    }\n    example = tf.io.parse_single_example(example, tfrec_format)\n    return prepare_image(example[\"wave\"], config.image_size), tf.reshape(tf.cast(example[\"target\"], tf.float32), [1])\n\n\ndef read_unlabeled_tfrecord(example, return_image_id):\n    tfrec_format = {\n        \"wave\": tf.io.FixedLenFeature([], tf.string),\n        \"wave_id\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrec_format)\n    return prepare_image(example[\"wave\"], config.image_size), example[\"wave_id\"] if return_image_id else 0\n\ndef count_data_items(fileids):\n    return len(fileids) * 28000\n\ndef count_data_items_test(fileids):\n    return len(fileids) * 22600\n\ndef prepare_image(wave, dim= config.image_size):\n    wave = tf.reshape(tf.io.decode_raw(wave, tf.float64), (3, 4096))\n    normalized_waves = []\n    for i in range(3):\n        normalized_wave = wave[i] \/ tf.math.reduce_max(wave[i])\n        normalized_waves.append(normalized_wave)\n    wave = tf.stack(normalized_waves)\n    wave = tf.cast(wave, tf.float32)\n    image = create_cqt_image(wave, HOP_LENGTH)\n    image = tf.image.resize(image, size=(dim, dim))\n    return tf.reshape(image, (dim, dim, 3))\n\ndef mixup(image, label, PROBABILITY = 1.0, AUG_BATCH= config.batch_size):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    DIM = config.image_size\n    \n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n        # MAKE CUTMIX LABEL\n        lab1 = label[j,]\n        lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,))\n    return image2,label2\n\ndef time_shift(img, shift= config.t_shift):\n    if shift > 0:\n        T = config.image_size\n        P = tf.random.uniform([],0,1)\n        SHIFT = tf.cast(T * P, tf.int32)\n        return tf.concat([img[-SHIFT:], img[:-SHIFT]], axis=0)\n    return img\n\n\ndef spector_shift(img, shift= config.s_shift):\n    if shift > 0:\n        T = config.image_size\n        P = tf.random.uniform([],0,1)\n        SHIFT = tf.cast(T * P, tf.int32)\n        return tf.concat([img[:, -SHIFT:], img[:, :-SHIFT]], axis=1)\n    return img\n  \ndef rotate(img, angle= config.r_angle):\n    if angle > 0:\n        P = tf.random.uniform([],0,1)\n        A = tf.cast(angle * P, tf.float32)\n        return tfa.image.rotate(img, A)\n    return img\n\ndef img_aug_f(img):\n    img = time_shift(img)\n    img = spector_shift(img)\n    # img = rotate(img)\n    return img\n\ndef imgs_aug_f(imgs, batch_size):\n    _imgs = []\n    DIM = config.image_size\n    for j in range(batch_size):\n        _imgs.append(img_aug_f(imgs[j]))\n    return tf.reshape(tf.stack(_imgs),(batch_size,DIM,DIM,3))\n\ndef label_positive_shift(labels):\n    return labels *  config.label_positive_shift\n\ndef aug_f(imgs, labels, batch_size):\n    imgs, label = mixup(imgs, labels, config.mix_up_p, batch_size)\n    imgs = imgs_aug_f(imgs, batch_size)\n    return imgs, label_positive_shift(label)\n","5d2bd7a1":"def get_dataset(files, batch_size=16, repeat=False, shuffle=False, aug=True, labeled=True, return_image_ids=True):\n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=config.AUTO, compression_type=\"GZIP\")\n    ds = ds.cache()\n\n    if repeat:\n        ds = ds.repeat()\n\n    if shuffle:\n        ds = ds.shuffle(1024 * 2)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n\n    if labeled:\n        ds = ds.map(read_labeled_tfrecord, num_parallel_calls= config.AUTO)\n    else:\n        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids), num_parallel_calls=config.AUTO)\n\n    ds = ds.batch(config.batch_size)\n    if aug:\n        ds = ds.map(lambda x, y: aug_f(x, y, config.batch_size), num_parallel_calls= config.AUTO)\n    ds = ds.prefetch(config.AUTO)\n    return ds","5df85203":"def create_model(backbone_model):\n    x = GlobalAvgPool2D()(backbone_model.output)\n    prediction_layer = Dense(1, activation = 'sigmoid')(x)\n    \n    model = Model(inputs = backbone_model.input , outputs = prediction_layer)\n    \n    return model\n","ecf20a99":"def get_predictions(dataset,fold_number):\n\n  #create model \n  print(\"creating model\")\n  with strategy.scope():\n    backbone_model = efn.EfficientNetB1(include_top= False, weights =\"imagenet\",input_shape=(config.image_size,config.image_size,3))\n    model = create_model(backbone_model)\n\n    #load weights\n    print(\"loading model weights\")\n    model.load_weights(f'..\/input\/efficientnetb1-weights-g2net\/result\/eff_net_fold_{fold_number}.h5')\n  \n  pred = model.predict(dataset , verbose = 1 )\n  pred = np.array(pred)\n\n  return pred\n","399c916d":"test_data = get_dataset(test_files, batch_size= config.batch_size * 2, repeat=False, shuffle=False, aug=False, labeled=False, return_image_ids=True)\nids = np.array([id.numpy().decode(\"utf-8\") for _, id in tqdm(test_data.unbatch())]).flatten()","15d4a387":"ds = get_dataset(test_files, batch_size= config.batch_size , repeat=False, shuffle=False, aug=False, labeled=False, return_image_ids=False)\nall_predictions = dict()\nfor fold in range(1,5):\n    print(f'*********** PREDICTING FOR FOLD {fold} ***********')\n    preds = get_predictions(ds,fold_number=fold)\n    all_predictions[fold] = preds","79376a12":"sub_preds = np.mean([all_predictions[1].flatten(),all_predictions[2].flatten(),all_predictions[3].flatten(),\n                     all_predictions[4].flatten()],axis = 0)","f259551f":"sub = pd.DataFrame()\nsub['id'] = ids\nsub['target'] = sub_preds\nsub","947a561d":"sub.to_csv('submission.csv', index=False)","aa63168d":"<h1 style='background:#1EA1A1; border:0; color:white'><center> \ud83d\udcdd Abstract <center><\/h1>\n\n * In this Inference Notebook EfficientNetB1 is inferred.\n\n**Versions**    \n* Version 3: EfficientNetB1 512 Augs CV:- **0.8684**  LB:- **0.8716**\n\n\n\n\n\n**References are mentioned at the end.**\n","b89b7801":"<a id = \"1\"> <\/a>\n<h1 style='background:#1EA1A1; border:0; color:white'><center> \ud83d\ude9a Imports <center><\/h1>","340fc306":"<a id = \"3\"> <\/a>\n<h1 style='background:#1EA1A1; border:0; color:white'><center> Reading TFrecords <center><\/h1>","b5c26733":"<a id = \"6\"> <\/a>\n<h1 style='background:#1EA1A1; border:0; color:white'><center> \ud83d\udd04 KFold Prediction  <center><\/h1>","811c5f20":"**Thanks for viewing, drop your suggestions down in the comments below. \ud83d\ude42**","b0aa8cbc":"<h1 style='background:#1EA1A1; border:0; color:white'><center> Creation of on fly CQT <center><\/h1>","1e90bd91":"<a id = \"7\"> <\/a>\n<h1 style='background:#1EA1A1; border:0; color:white'><center> \ud83d\udccc References <center><\/h1>\n \n **Thank You Hidehisa Arai for providing such good kernels**\n * Hidehisa's [Training Notebook](https:\/\/www.kaggle.com\/hidehisaarai1213\/g2net-tf-on-the-fly-cqt-tpu-training) and [Inference Notebook](https:\/\/www.kaggle.com\/hidehisaarai1213\/g2net-tf-on-the-fly-cqt-tpu-inference)\n * Hidehisa's [Train Dataset](https:\/\/www.kaggle.com\/hidehisaarai1213\/g2net-waveform-tfrecords-train-0-4) and [Test Dataset](https:\/\/www.kaggle.com\/hidehisaarai1213\/g2net-waveform-tfrecords-test-0-4)","9eefe209":"<a id=\"0\"><\/a>\n<h1 style='background:#1EA1A1; border:0; color:white'><center> \ud83d\udcc4 Table of Contents<center><\/h1>\n\n* [Imports](#1)\n* [Configs](#2)\n* [Reading TFRecords](#3) \n* [Dataset Creation](#4)\n* [Modelling](#5)\n* [KFold Prediction](#6)\n* [References](#7)","8ee46ac0":"<a id = \"2\"> <\/a>\n<h1 style='background:#1EA1A1; border:0; color:white'><center> \u2699\ufe0f Configs <center><\/h1>","1447d83d":"<a id = \"4\"> <\/a>\n<h1 style='background:#1EA1A1; border:0; color:white'><center> \ud83d\udcca Dataset Creation <center><\/h1>","5d533989":"<a id = \"5\"> <\/a>\n<h1 style='background:#1EA1A1; border:0; color:white'><center> \ud83e\udde0 Modelling <center><\/h1>"}}