{"cell_type":{"48e4da5e":"code","6affc3be":"code","c7396bc8":"code","f5b70265":"code","0f60624e":"code","c8dc4123":"code","c664a3dd":"code","faa9cc35":"code","64f51999":"code","a3bf49b4":"code","afc91688":"code","f7b7f422":"code","d6e12de0":"code","9a3166f1":"code","a2cdb522":"code","ea181965":"code","406467ee":"code","6fc0d504":"code","556ad7b0":"code","7ab21c30":"code","0652a205":"code","eec5e340":"code","bf650229":"code","be7be76b":"code","d36c374c":"code","e8ae4243":"code","402a884e":"code","a2af93f3":"code","115504e3":"code","82503f74":"code","e98bba98":"code","17b8e497":"code","a04a6227":"code","8fef2346":"code","fb52cd53":"code","c4cf21e6":"code","ddc85889":"code","9513c479":"code","42e81648":"code","1cd717e2":"code","1ddb4a54":"code","30d1353d":"code","6973e485":"code","66e70592":"code","17f57696":"code","461b7cc1":"code","78a4b21e":"code","6d2f7c0f":"code","9d3a51c8":"code","1f44581e":"markdown","bc605b7b":"markdown","a8630cf9":"markdown","23190cef":"markdown","06a4e6d1":"markdown","48983b47":"markdown","8232c66f":"markdown","d92f8a4d":"markdown","0c83592f":"markdown","b8c99d30":"markdown","1e6f236e":"markdown","e6081e72":"markdown","4ed19c5f":"markdown","36ba87ac":"markdown","5a34f8c4":"markdown","64fe7aa8":"markdown","1f8eb383":"markdown","e6612b4e":"markdown","38d33d75":"markdown","9622ac9e":"markdown","5df2a5f9":"markdown","e4c1d47b":"markdown","fab58e75":"markdown","7beebc8b":"markdown","e1b030f0":"markdown","89dcfe80":"markdown"},"source":{"48e4da5e":"# The following code is for the KNN regression from Scratch\n# Created by - Muhammad Ahmed Shuja\n\n# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport numpy.random as nr\nimport matplotlib.pyplot as plt","6affc3be":"df=pd.read_csv('..\/input\/insurance\/insurance.csv')\ndf.head()","c7396bc8":"df.info()","f5b70265":"df.describe()","0f60624e":"df.isnull().sum()","c8dc4123":"print(df['sex'].value_counts())\nprint()\nprint(df['region'].value_counts())\nprint()\nprint(df['smoker'].value_counts())","c664a3dd":"sns.pairplot(df)","faa9cc35":"df_healthy=df[(df['bmi']>18.5) & (df['bmi']<24.9)]\na=df_healthy.count()\nprint('healthy_people:')\nprint(a)\ndf_healthy_region=df_healthy.groupby('region')\ndf_healthy_region.describe().round(2)","64f51999":"sns.catplot(x=\"sex\", y=\"charges\", hue=\"smoker\",\n                col=\"region\", height=4, data=df_healthy)","a3bf49b4":"sns.boxplot(x=df_healthy[\"charges\"])","afc91688":"df1=df_healthy[df_healthy['charges']<33000]","f7b7f422":"sns.catplot(x=\"sex\", y=\"age\", hue=\"smoker\",\n                col=\"region\", height=4, data=df1)","d6e12de0":"df_underweight=df[(df['bmi']<18.5)]\na=df_underweight.count()\nprint('underweight_people:')\nprint(a)\ndf_underweigh_region=df_underweight.groupby('region')\ndf_underweigh_region.describe().round(2)\n","9a3166f1":"sns.boxplot(x=df_underweight[\"charges\"])\n","a2cdb522":"sns.boxplot(x=df_underweight[\"bmi\"])\n","ea181965":"df2=df_underweight[df_underweight['charges']<20000]\ndf2=df2[df2['bmi']>16.5]","406467ee":"sns.catplot(x=\"sex\", y=\"charges\", hue=\"smoker\",\n                col=\"region\", height=4, data=df2)","6fc0d504":"sns.catplot(x=\"sex\", y=\"age\", hue=\"smoker\",\n                col=\"region\", height=4, data=df2)","556ad7b0":"df_overweight=df[(df['bmi']>24.9)]\nb=df_overweight.count()\nprint('overweight_people:')\nprint(b)\ndf_overweight_region=df_overweight.groupby('region')\ndf_overweight_region.describe().round(2)","7ab21c30":"sns.boxplot(x=df_overweight[\"charges\"])","0652a205":"sns.boxplot(x=df_overweight[\"bmi\"])","eec5e340":"df3=df_overweight[df_overweight['charges']<50000]\ndf3=df3[df3['bmi']<47]","bf650229":"sns.catplot(x=\"sex\", y=\"charges\", hue=\"smoker\",\n                col=\"region\", height=4, data=df3)","be7be76b":"sns.catplot(x=\"sex\", y=\"age\", hue=\"smoker\",\n                col=\"region\", height=4, data=df3)\n","d36c374c":"df_final=pd.concat([df1,df2,df3])\ndf_final.head()\ndf_final['region'].unique()","e8ae4243":"data= pd.get_dummies(df, drop_first=True)\ndata.columns.values","402a884e":"cols=['age', 'bmi', 'children', 'sex_male', 'smoker_yes','region_northwest', 'region_southeast', 'region_southwest',\n       'charges']","a2af93f3":"dumies_data=data[cols]\ndumies_data.head()","115504e3":"inputs=dumies_data.drop(['charges'],axis=1)\ntarget=dumies_data['charges']\n\nimport sklearn.preprocessing as sp\nscalar=sp.StandardScaler()\nscalar.fit(inputs)\nscalar_input=scalar.transform(inputs)\n\nimport sklearn.model_selection as sm \nx_train,x_test,y_train,y_test=sm.train_test_split(scalar_input,target,test_size=0.2, random_state=365)\n\nimport sklearn.neighbors as sn\nKNN=sn.KNeighborsRegressor(n_neighbors=20)  # because this is a regression problem,p=2 euclidean_distance\nKNN.fit(x_train,y_train)","82503f74":"pred=KNN.predict(x_test)","e98bba98":"pred=KNN.predict(x_test)\nimport sklearn\nR=sklearn.metrics.r2_score(y_test,pred)  # R-Square score for model Evaluation\nR","17b8e497":"n = x_test.shape[0]\np = x_test.shape[1]\n\nadjusted_r2 = 1-(1-R)*(n-1)\/(n-p-1)\nadjusted_r2   # Adjusted R-Square Score","a04a6227":"import sklearn.feature_selection as sf\n# There are two output arrays\n# The first one contains the F-statistics for each of the regressions\n# The second one contains the p-values of these F-statistics\np_values = sf.f_regression(x_train,y_train)[1].round(4)\np_values\n","8fef2346":"df_1=pd.DataFrame()\ndf_1['smoker'] = df_final['smoker'].map({'yes': 1, 'no': 0})\ndf_2=pd.DataFrame()\ndf_2['sex'] = df_final['sex'].map({'male': 1, 'female': 0})\ndf_3=pd.DataFrame()\ndf_3['regions'] = df_final['region'].map({'northwest': 1,'northeast':2,'southwest': 3,'southeast': 4})\n\n","fb52cd53":"a1=df_final['age'].values\na2=df_final['charges'].values\na3=df_final['children'].values\na4=df_1['smoker'].values\na5=df_2['sex'].values\na6=df_3['regions'].values","c4cf21e6":"from numpy.random import rand\nfrom numpy.random import seed\nfrom scipy.stats import kendalltau\n# seed random number generator\nseed(1)\n# calculate kendall's correlation\ncoef, p = kendalltau(a2,a1)\nprint('Kendall correlation coefficient: %.3f' % coef)\n# interpret the significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","ddc85889":"from numpy.random import rand\nfrom numpy.random import seed\nfrom scipy.stats import kendalltau\n# seed random number generator\nseed(1)\n# calculate kendall's correlation\ncoef, p = kendalltau(a2,a5)\nprint('Kendall correlation coefficient: %.3f' % coef)\n# interpret the significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","9513c479":"from numpy.random import rand\nfrom numpy.random import seed\nfrom scipy.stats import kendalltau\n# seed random number generator\nseed(1)\n# calculate kendall's correlation\ncoef, p = kendalltau(a2,a3)\nprint('Kendall correlation coefficient: %.3f' % coef)\n# interpret the significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","42e81648":"from numpy.random import rand\nfrom numpy.random import seed\nfrom scipy.stats import kendalltau\n# seed random number generator\nseed(1)\n# calculate kendall's correlation\ncoef, p = kendalltau(a2,a6)\nprint('Kendall correlation coefficient: %.3f' % coef)\n# interpret the significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","1cd717e2":"from numpy.random import rand\nfrom numpy.random import seed\nfrom scipy.stats import kendalltau\n# seed random number generator\nseed(1)\n# calculate kendall's correlation\ncoef, p = kendalltau(a2,a4)\nprint('Kendall correlation coefficient: %.3f' % coef)\n# interpret the significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","1ddb4a54":"data11= pd.get_dummies(df_final, drop_first=True)\ndata11.columns.values","30d1353d":"cols=['age', 'bmi', 'children', 'smoker_yes',\n       'charges']","6973e485":"dumies_data=data11[cols]\ndumies_data.head()","66e70592":"inputs=dumies_data.drop(['charges'],axis=1)\ntarget=dumies_data['charges']\n\nimport sklearn.preprocessing as sp\nscalar=sp.StandardScaler()\nscalar.fit(inputs)\nscalar_input=scalar.transform(inputs)\n\nimport sklearn.model_selection as sm \nx_train,x_test,y_train,y_test=sm.train_test_split(scalar_input,target,test_size=0.2, random_state=365)\n","17f57696":"import sklearn.feature_selection as sf\n# There are two output arrays\n# The first one contains the F-statistics for each of the regressions\n# The second one contains the p-values of these F-statistics\np_values = sf.f_regression(x_train,y_train)[1].round(4)\np_values\n","461b7cc1":"import sklearn.neighbors as sn\nKNN=sn.KNeighborsRegressor(n_neighbors=19,p=2,metric='minkowski')  # because this is a regression problem,p=2 euclidean_distance\nKNN.fit(x_train,y_train)","78a4b21e":"pred=KNN.predict(x_test)\n\nimport sklearn\nR=sklearn.metrics.r2_score(y_test,pred)*100\nR","6d2f7c0f":"from sklearn import metrics\nrmse_val = []\nfor K in range(1,30):\n    \n    model = sn.KNeighborsRegressor(n_neighbors = K)\n\n    model.fit(x_train, y_train)  #fit the model\n    pred=model.predict(x_test) #make prediction on test set\n    error = np.sqrt(metrics.mean_squared_error(y_test,pred)) #calculate rmse\n    rmse_val.append(error) #store rmse values\n    print('RMSE value for k= ' , K , 'is:', error)\nprint()\nprint(\"Manimum error:-\",min(rmse_val),\"at K =\",rmse_val.index(min(rmse_val))+1)","9d3a51c8":"plt.figure(figsize=(11,5))\nplt.plot(range(1,30),rmse_val,color='blue', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\nplt.title('RMSE Error vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error ')\nplt.show()","1f44581e":"### Choosing the best value for 'K'","bc605b7b":"###  KNN Model after modification is 87.34 % accurate. First I've achieved 73% accuracy from the model but when I eliminate the outliers, corrupt data ,missing data and choose correct value of 'K' then I've achived a greater accuracy of the model that is 87.34%  ","a8630cf9":"#### Removing outlier charges and bmi from Overweight people","23190cef":"### Data types","06a4e6d1":"#### kendall's Rank Correlation between Charges and smoker","48983b47":"#### kendall's Rank Correlation between Charges and age","8232c66f":"### Data Summary","d92f8a4d":"# Exploratory Data analysis","0c83592f":"#### Removing outlier charges from healthy people","b8c99d30":"#### kendall's Rank Correlation between Charges and children","1e6f236e":"### Finding Null Values","e6081e72":"#### Model Evaluation in terms of R-Square score ","4ed19c5f":"### Underweight People","36ba87ac":"#### Removing outlier charges and bmi from Underweight people","5a34f8c4":"### Feature Selection","64fe7aa8":"#### changing categorial data into numeric data type","1f8eb383":"# We are using KNN Model","e6612b4e":"### Overweight People","38d33d75":"## KNN Model wihtout any Modification","9622ac9e":"### Classifying and counting total no. of 'sex' , 'region ' ,'smoker'","5df2a5f9":"### Healthy People","e4c1d47b":"## KNN Model After Modification","fab58e75":"#### kendall's Rank Correlation between Charges and sex","7beebc8b":"#### kendall's Rank Correlation between Charges and regions","e1b030f0":"### Many factors that affect how much you pay for health insurance are not within your control. \n### Nonetheless, it's good to have an understanding of what they are. \n### Here are some factors that affect how much health insurance premiums cost\n### age: age of primary beneficiary\n### sex: insurance contractor gender, female, male\n### bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n### objective index of body weight (kg \/ m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n### children: Number of children covered by health insurance \/ Number of dependents\n### smoker: Smoking\n### region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest","89dcfe80":"### Non-parametric Rank Correlation"}}