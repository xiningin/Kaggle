{"cell_type":{"37cefa1b":"code","68610b80":"code","6ee46412":"code","65e9764e":"code","2a2227af":"code","8b74988b":"code","ef0a7b40":"code","51b6b589":"code","31852664":"code","02cf70b8":"code","033d1ec1":"code","a6dfcbcc":"code","10b3d611":"code","deafc515":"code","353bab3d":"code","0a7077bb":"code","d6bc3050":"code","c57bdc85":"code","dde3681a":"code","83a33d01":"code","a9904b81":"code","6de4b9b7":"code","58e5d1c6":"code","9bfad5c8":"code","4e7e8c1c":"code","c3be0eae":"code","f535dc1d":"code","9ead94a9":"code","660fa3ed":"code","26a9c188":"code","51b2066b":"code","6551662c":"code","78daa62d":"code","382482a5":"code","80d33706":"code","37e6be9b":"code","8089b4e2":"code","0799b105":"code","9e698de2":"code","b127b12d":"code","976fa890":"code","cc2b3660":"code","7e96c996":"code","9965e6bb":"code","368fe305":"code","77fa162f":"code","f5e57314":"code","b00e6ac3":"code","5195d266":"code","ee3f8a09":"code","7e1979e8":"markdown","a2fc8256":"markdown","ab16cb1b":"markdown","881dadd9":"markdown","049f55cb":"markdown","bf84c83e":"markdown","c4b0b307":"markdown","092252b5":"markdown","d22416eb":"markdown","8c7c4306":"markdown","dc49e6a7":"markdown","38c00ee7":"markdown","2dbf024e":"markdown","3db2da91":"markdown","0c6a3eec":"markdown","279fb4be":"markdown","2a6cf563":"markdown","49c0c678":"markdown","d43177fe":"markdown","93f5ec40":"markdown","2c8da107":"markdown","3276ae0b":"markdown","442ad50a":"markdown","d17fced3":"markdown"},"source":{"37cefa1b":"#importing relevant libraries\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import accuracy_score,f1_score, classification_report\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","68610b80":"train_loan_df = pd.read_csv('..\/input\/loan-eligible-dataset\/loan-train.csv')\ntest_loan_df = pd.read_csv('..\/input\/loan-eligible-dataset\/loan-test.csv')","6ee46412":"train_loan_df.head()","65e9764e":"print('Rows: {0} \\nColumns: {1}'.format(train_loan_df.shape[0],train_loan_df.shape[1]))","2a2227af":"#Understanding data\ntrain_loan_df.describe()","8b74988b":"train_loan_df.info()","ef0a7b40":"train_loan_df.Credit_History.value_counts()","51b6b589":"df = train_loan_df.drop('Loan_ID', axis = 1)\ntest_df = test_loan_df.drop('Loan_ID', axis = 1)","31852664":"df.Loan_Status.describe()","02cf70b8":"df.Loan_Status = df.Loan_Status.map({'Y':1, 'N':0})\n","033d1ec1":"df['Credit_History'].value_counts()","a6dfcbcc":"df['Credit_History'].loc[df.Credit_History == 1.0] = 'one'\ndf['Credit_History'].loc[df.Credit_History == 0.0] = 'zero'\n\ntest_df['Credit_History'].loc[test_df.Credit_History == 1.0] = 'one'\ntest_df['Credit_History'].loc[test_df.Credit_History == 0.0] = 'zero'","10b3d611":"cat_cols = df.select_dtypes('object').columns \nnum_cols = df.select_dtypes(['int64', 'float64']).columns","deafc515":"print(cat_cols)\nprint(num_cols)","353bab3d":"for col in cat_cols:\n    sns.countplot(df[col])\n    plt.title(col)\n    plt.show()\n    print('\\n\\n')","0a7077bb":"for col in num_cols:\n    sns.distplot(df[col], bins = 20)\n    plt.title(col)\n    plt.show()\n    print('\\n\\n')","d6bc3050":"#plotting BAR CHARTS for Categorical data\nfor col in cat_cols:\n    sns.barplot( data = df.groupby(col)['Loan_Status'].mean().reset_index() ,x=col ,y=\"Loan_Status\")\n    plt.title('Eligibility percentage based on '+ col.upper())\n    plt.show()\n    print('\\n\\n') ","c57bdc85":"for i in num_cols:\n    if i != 'Loan_Status':\n        print(df.groupby('Loan_Status')[i].median().reset_index())\n        print('\\n\\n')","dde3681a":"df.isna().sum()","83a33d01":"for col in num_cols:\n        df[col].fillna(df[col].median(), inplace = True)\ndf.isna().sum()       ","a9904b81":"for col in cat_cols:\n    print(col, df[col].mode())","6de4b9b7":"test_df.isna().sum()","58e5d1c6":"df.Gender.fillna('Male', inplace = True)\ndf.Married.fillna('Yes', inplace = True)\ndf.Dependents.fillna('0', inplace = True)\ndf.Self_Employed.fillna('No', inplace = True)\n\n\ntest_df.Gender.fillna('Male', inplace = True)\ntest_df.Dependents.fillna('0', inplace = True)\ntest_df.Self_Employed.fillna('No', inplace = True)\ntest_df.LoanAmount.fillna(test_df.LoanAmount.median(), inplace = True)\ntest_df.Loan_Amount_Term.fillna(test_df.Loan_Amount_Term.median(), inplace = True)\n","9bfad5c8":"df.Credit_History.fillna('na', inplace = True)\n\ntest_df.Credit_History.fillna('na', inplace = True)","4e7e8c1c":"df.shape","c3be0eae":"df.isna().sum()","f535dc1d":"loan_1 = df.loc[df.Loan_Status == 1].sample(192, random_state = 0)\nloan_0 = df.loc[df.Loan_Status == 0]\ndata = pd.concat([loan_1, loan_0], axis = 0)","9ead94a9":"balanced_data = data.reset_index(drop = True)","660fa3ed":"X = balanced_data.drop('Loan_Status', axis = 1)\ny = balanced_data['Loan_Status']\n\nx_test = test_df","26a9c188":"num_cols = X.select_dtypes(['int64', 'float64']).columns\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(X[num_cols])\n\nscaled_test = scaler.fit_transform(x_test[num_cols])","51b2066b":"cat_cols = X.select_dtypes('object').columns\nencoder = OneHotEncoder(handle_unknown='ignore', sparse = False)\nencoded_data = encoder.fit_transform(X[cat_cols])\n\nencoded_test = encoder.fit_transform(test_df[cat_cols])","6551662c":"scaled_X = pd.DataFrame(scaled_data, columns = num_cols)\nencoded_X = pd.DataFrame(encoded_data, columns = encoder.get_feature_names())\nX_preprocessed = pd.concat([scaled_X, encoded_X], axis = 1)\n\n\nscaled_X_test = pd.DataFrame(scaled_test, columns = num_cols)\nencoded_X_test = pd.DataFrame(encoded_test, columns = encoder.get_feature_names())\nX_test_preprocessed = pd.concat([scaled_X_test,encoded_X_test ], axis = 1)","78daa62d":"X_preprocessed","382482a5":"x_train, x_valid, y_train, y_valid = tts(X_preprocessed,y , test_size = 0.1, random_state = 0, stratify = y)","80d33706":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\n\nmodel_rf = RandomForestClassifier(random_state = 0)\nmodel_rf.fit(x_train,y_train)\n\nmodel_lr = LogisticRegression(max_iter = 250)\nmodel_lr.fit(x_train,y_train)\n\nmodel_sv = svm.SVC(kernel='linear', random_state = 0)\nmodel_sv.fit(x_train,y_train)","37e6be9b":"preds_lr = model_lr.predict(x_valid)\npreds_rf = model_rf.predict(x_valid)\npreds_sv = model_sv.predict(x_valid)","8089b4e2":"print('Accuracy score for Logistic regression: {0}\\nF1 score for Logistic regression: {1} '.format(accuracy_score(preds_lr, y_valid),f1_score(preds_lr, y_valid)))","0799b105":"print('Accuracy score for Random_Forest: {0}\\nF1 score for Random Forest: {1} '.format(accuracy_score(preds_rf, y_valid),f1_score(preds_rf, y_valid)))","9e698de2":"print('Accuracy score for SVM: {0}\\nF1 score for SVM: {1} '.format(accuracy_score(preds_sv, y_valid),f1_score(preds_sv, y_valid)))","b127b12d":"print('LOGISTICS REGRESSION\\n')\nprint(classification_report(preds_lr, y_valid))","976fa890":"print('RANDOM FOREST\\n')\nprint(classification_report(preds_rf, y_valid))","cc2b3660":"print('SUPPORT VECTOR\\n')\nprint(classification_report(preds_sv, y_valid))","7e96c996":"f1scores_train = []\nf1scores_valid = []\n\ndepth = range (3, 15)\n\nfor i in depth:\n    model = RandomForestClassifier(max_depth = i, n_estimators = 25, random_state = 0)\n    model.fit(x_train, y_train)\n    \n    train_preds = model.predict(x_train)\n    valid_preds = model.predict(x_valid)\n    \n   # print(classification_report(valid_preds, y_valid))\n    \n    f1scores_train.append(f1_score(train_preds, y_train))\n    f1scores_valid.append(f1_score(valid_preds, y_valid))\n    \nplt.plot(depth, f1scores_train, color = 'r')\nplt.plot(depth ,f1scores_valid, color = 'b')\nplt.legend(['Training F1 score', 'Validation F1 score'])","9965e6bb":"final_model = RandomForestClassifier(max_depth = 5, n_estimators = 25, random_state = 0)\n#final_model = LogisticRegression()\nfinal_model.fit(x_train, y_train)\npreds = final_model.predict(x_valid)","368fe305":"print( 'Accuracy score for final model: {0}\\nF1 score for final model: {1} '.format(accuracy_score(preds, y_valid),f1_score(preds, y_valid)))","77fa162f":"print(classification_report(preds, y_valid))","f5e57314":"#Predictions on test_data\nmodel_lr.predict(X_test_preprocessed)","b00e6ac3":"import pickle \n#save the model to disk\nfilename = 'model.pkl'\npickle.dump(final_model, open(filename, 'wb')) # wb means write as binary","5195d266":"# load the model from disk\nloaded_model = pickle.load(open(filename, 'rb')) # rb means read as binary\npreds = loaded_model.predict(x_valid)","ee3f8a09":"print( 'Accuracy score : {0}\\nF1 score : {1} '.format(accuracy_score(preds, y_valid),f1_score(preds, y_valid)))","7e1979e8":"# Univariate Analysis","a2fc8256":"**From this we can conclude that:**\n*   Male has slightly higher chance for being eligible for loan\n*   Married people have more chances of being approved for the loan\n*   People with 2 or no dependents have more chances than people with more than 3 dependednts.\n*   Graduate individual has more chances of getting an approval\n*   Self employes or not, both has similar chance of getting an approval\n*   People living in semiurban area are more likely to get a loan approved\n*   People with credit history with 1.0 is more likely to get approved","ab16cb1b":"**Dropping Loan_Id as it does not hold any significance**","881dadd9":"**Mapping 'Y' as 1 and 'N'as 0**","049f55cb":"**Scaling data**","bf84c83e":"**We can conclude:**\n* The median Applicant income of eligible cadidates is  3812.5\n* The median Coapplicant income of eligible cadidates is 1239.5\n* The median Loan amount of eligible cadidates is 126.0\n* The median Loan amount term of eligible cadidates is 360.0\n","c4b0b307":"**Encoding categorical columns**","092252b5":"# Model Selection","d22416eb":"**Filling credit history with 'na'**","8c7c4306":"**Filling numerical data with median and categorical with mode**","dc49e6a7":"**Loading data**","38c00ee7":"**To read model from file**","2dbf024e":"**Model Evaluation**","3db2da91":"# Deploying model","0c6a3eec":"# Bivariate Analysis","279fb4be":"**Changing Credit History's data type as object**\nAs there are only two values '0' and '1'","2a6cf563":"# Loan Eligibility Prediction","49c0c678":"**Determinig optimal max_depth for RANDOM FOREST**","d43177fe":"**Dealing with missing values**","93f5ec40":"There is more precision with max_depth = 5","2c8da107":"**Final Model**","3276ae0b":"# Balancing dataset","442ad50a":"**Count plots for categorical columns and histograms for numerical  columns**","d17fced3":"**Splitting data into training and validation data**"}}