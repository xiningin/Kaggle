{"cell_type":{"e961561f":"code","53f085ef":"code","724dd8c4":"code","82cb8e98":"code","fa210468":"code","35ad400c":"code","5d5c7c3f":"code","ddb9aa99":"code","2c7b017f":"code","1e0df2e3":"code","0f388602":"code","e658818c":"code","87eaf87b":"code","dcb85d2c":"code","3f01f151":"code","419c49fb":"code","1e0f7a19":"code","c0d79fc6":"code","6f64ce59":"code","8df257ab":"code","f659dea0":"code","5af0f86c":"code","e0a0904e":"code","b5314224":"code","39769eb0":"code","2571f6fd":"code","726ee558":"code","3e62f980":"code","aa861708":"code","2392758a":"code","1ae354da":"code","5a7efde7":"code","181f5336":"code","070607d8":"code","df38ebb9":"code","c2c1b32c":"code","581d0bb4":"code","c4c34dcd":"code","f063d756":"code","c7d81bcd":"code","4fcd9618":"code","4aeb9c2d":"code","39555271":"code","d49d1099":"code","baf1f9a8":"code","a0051af8":"code","4d8c5e1e":"code","85d7136a":"code","5b2bc5cf":"code","d822fc7a":"code","dd7161c8":"code","11483d18":"code","61d7c415":"code","1a435e16":"code","d7a6e345":"code","fb96ebdf":"code","cdeec5c8":"code","9bc9e5ea":"code","4726814c":"code","8385fe35":"code","af4c9735":"code","8e652b31":"code","982f15aa":"code","d8b1dff2":"code","1411e35a":"code","100e2565":"code","11c01c50":"code","a2bfb98f":"code","f6e535c2":"code","b83525d5":"code","8d767e2d":"code","6386aaab":"code","6feb5a62":"code","cd059dd9":"code","5c8f7c23":"code","cc59ec90":"code","025e5bcf":"code","7b9110df":"code","826daeba":"code","310afe00":"code","c96c569f":"code","c68447a1":"code","4d46da15":"code","bf0cc095":"code","335c16d1":"code","c0d87175":"code","c1f2a2ff":"code","cf48e532":"code","2c2a7c43":"code","d163c5fe":"code","10060af1":"code","b9b54381":"code","a7944708":"code","98871832":"code","991a6f28":"code","ae68d579":"code","1ef681ee":"code","1d29673f":"code","a45aaa75":"code","1fe33bf7":"code","ccd33936":"code","09fcc0e6":"code","3cbecf59":"code","2aabd56a":"code","8d3cf885":"code","53d51649":"code","8754e8e4":"code","b56d9bae":"code","55ff97f9":"code","0216f948":"code","b7460718":"code","60c878a6":"code","b4736cfb":"code","65ebcbc4":"code","1af6492c":"code","b2d34ff1":"code","d44ce370":"markdown","fa81eb4e":"markdown","15d5901c":"markdown","c86fc2c2":"markdown","ae628a5b":"markdown","31d04681":"markdown","5b014b5b":"markdown","af3efe3d":"markdown","47098df7":"markdown","aa46d0f2":"markdown","d23fe0fc":"markdown","e4883e65":"markdown","24c30847":"markdown","43fc678c":"markdown","36913771":"markdown","60aa983e":"markdown","d0f1b33b":"markdown","9cbc5e91":"markdown","ee53ef6d":"markdown","1a9fc3e0":"markdown","32281b3e":"markdown"},"source":{"e961561f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","53f085ef":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsns.set(style=\"whitegrid\")","724dd8c4":"df=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","82cb8e98":"df.describe(percentiles=[0.1,0.25,0.45,0.55,0.75,0.95]).T","fa210468":"df.columns","35ad400c":"col = \"diagnosis\"\ngrouped = df[col].value_counts().reset_index()\ngrouped = grouped.rename(columns = {col : \"count\", \"index\" : col})\n\n## plot\ntrace = go.Pie(labels=grouped[col], values=grouped['count'], pull=[0.05, 0], marker=dict(colors=[\"#6ad49b\", \"#a678de\"]))\nlayout = go.Layout(title=\"\", height=600, legend=dict(x=0.1, y=1.1))\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig)","5d5c7c3f":"for i in df:\n    null=df[i].isnull().sum()\/len(df)\n    if null>0:\n        print(\"{} 's null rate {} %\".format(i, null))\n    ","ddb9aa99":"fig=px.scatter_3d(x=df['radius_mean'], y=df['texture_mean'], z=df['area_mean'], size=df['texture_mean'],\n                 hover_data=[df['diagnosis']])\n\nfig.show()","2c7b017f":"df.head()","1e0df2e3":"corr = df.corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","0f388602":"df.columns","e658818c":"from statsmodels.stats.outliers_influence import variance_inflation_factor\ncols=['diagnosis', 'Unnamed: 32']\nX=df.drop(cols, axis=1)","87eaf87b":"X.columns","dcb85d2c":"vif_data = pd.DataFrame()\nvif_data[\"feature\"] = X.columns\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n                          for i in range(len(X.columns))]\nprint(vif_data)","3f01f151":"df.columns","419c49fb":"df['diagnosis']","1e0f7a19":"diagnosis={'M':1, 'B':0}\ndf['diagnosis']=[diagnosis[x] for x in df['diagnosis']]","c0d79fc6":"df['diagnosis']","6f64ce59":"X=df.drop('Unnamed: 32', axis=1)\ny=df['diagnosis']\nX_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","8df257ab":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay","f659dea0":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf\n","5af0f86c":"lr=LogisticRegression()\nlr.fit(X_train, y_train)","e0a0904e":"y_pred=lr.predict(X_train)\n","b5314224":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","39769eb0":"y_test_pred=lr.predict(x_test)\n","2571f6fd":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","726ee558":"cfm=confusion_matrix(y_test, y_test_pred)\n","3e62f980":"disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot() \n","aa861708":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","2392758a":"y_test_pred_prob=lr.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","1ae354da":"metrics.roc_auc_score(y_test, y_test_pred_prob)\n","5a7efde7":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","181f5336":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","070607d8":"# predict the test data and show the first 5 predictions\npredict=lr.predict(x_test)\npredict[1:6]","df38ebb9":"#Convert the numericalinto nominal value and check the few result\n\nprediction_nominal=['M' if x<0.1 else 'B' for x in predict ]\nprediction_nominal[1:6]","c2c1b32c":"from sklearn.neighbors import KNeighborsClassifier","581d0bb4":"error_rate=[]\n\nfor i in range(1,11):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred=knn.predict(x_test)\n    error_rate.append(np.mean(pred!=y_test))\n    \nplt.figure(figsize=(15,10))\nplt.plot(range(1,11), error_rate,marker='o', markersize=9)","c4c34dcd":"knn=KNeighborsClassifier(n_neighbors=6)\nknn.fit(X_train, y_train)","f063d756":"y_pred=knn.predict(X_train)\n","c7d81bcd":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","4fcd9618":"y_test_pred=knn.predict(x_test)\n","4aeb9c2d":"knn_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","39555271":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=knn.classes_)\ndisp.plot() ","d49d1099":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","baf1f9a8":"y_test_pred_prob=knn.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","a0051af8":"metrics.roc_auc_score(y_test, y_test_pred_prob)\n","4d8c5e1e":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","85d7136a":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=knn.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","5b2bc5cf":"# predict the test data and show the first 5 predictions\npredict=knn.predict(x_test)\npredict[1:6]","d822fc7a":"\nprediction_nominal=['M' if x<0.1 else 'B' for x in predict ]\nprediction_nominal[1:6]","dd7161c8":"from sklearn.svm import SVC\nfrom sklearn import metrics","11483d18":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)","61d7c415":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","1a435e16":"svc=SVC() #Default hyperparameters\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","d7a6e345":"svc=SVC(kernel='linear')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","fb96ebdf":"svc=SVC(kernel='rbf')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","cdeec5c8":"kernel=['linear', 'rbf', 'poly', 'sigmoid']\nfor i in kernel:\n    svc=SVC(kernel=i)\n    svc.fit(X_train,y_train)\n    y_pred=svc.predict(X_test)\n    print(\"{} :- {} \".format(i, metrics.accuracy_score(y_test,y_pred)))","9bc9e5ea":"from sklearn.model_selection import cross_val_score    \nsvc=SVC(kernel=\"linear\")\nscores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)\nprint(\"----------------\")\nprint(scores.mean())","4726814c":"from sklearn.model_selection import cross_val_score    \nsvc=SVC(kernel=\"rbf\")\nscores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)\nprint(\"-------------------\")\nprint(scores.mean())","8385fe35":"from sklearn.model_selection import cross_val_score    \nsvc=SVC(kernel=\"poly\")\nscores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)\nprint(\"-------------------\")\nprint(scores.mean())","af4c9735":"from sklearn.model_selection import cross_val_score    \nsvc=SVC(kernel=\"sigmoid\")\nscores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)\nprint(\"-------------------\")\nprint(scores.mean())","8e652b31":"C_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='linear', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(range(1,26), acc_score)\nprint(acc_score)","982f15aa":"C_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='rbf', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(range(1,26), acc_score)\nprint(acc_score)","d8b1dff2":"C_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='poly', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(range(1,26), acc_score)\nprint(acc_score)","1411e35a":"C_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='sigmoid', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(range(1,26), acc_score)\nprint(acc_score)","100e2565":"C_range=[0.001, 0.01, 0.1, 1.0, 10]\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='sigmoid', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(C_range, acc_score)\nprint(acc_score)","11c01c50":"C_range=[0.001, 0.01, 0.1, 1.0, 10]\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='rbf', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(C_range, acc_score)\nprint(acc_score)","a2bfb98f":"C_range=[0.001, 0.01, 0.1, 1.0, 10]\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='poly', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(C_range, acc_score)\nprint(acc_score)","f6e535c2":"svc=SVC(kernel='poly', C=1.0) #Default hyperparameters\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_train)\n","b83525d5":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","8d767e2d":"y_test_pred=svc.predict(X_test)\n","6386aaab":"svc_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",svc_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","6feb5a62":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=svc.classes_)\ndisp.plot()","cd059dd9":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","5c8f7c23":"y_test_pred_prob=lr.predict_proba(X_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","cc59ec90":"metrics.roc_auc_score(y_test, y_test_pred_prob)\n","025e5bcf":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","7b9110df":"# import DecisionTreeClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier","826daeba":"X=df.drop('Unnamed: 32', axis=1)\ny=df['diagnosis']\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","310afe00":"# instantiate the DecisionTreeClassifier model with criterion gini index\n\nclf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\n\n\n# fit the model\nclf_gini.fit(X_train, y_train)","c96c569f":"y_pred_gini = clf_gini.predict(X_train)","c68447a1":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred_gini))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred_gini))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred_gini))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred_gini))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred_gini))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred_gini))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred_gini))","4d46da15":"y_test_pred= clf_gini.predict(X_test)","bf0cc095":"dc_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",dc_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","335c16d1":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=clf_gini.classes_)\ndisp.plot()","c0d87175":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","c1f2a2ff":"y_test_pred_prob=clf_gini.predict_proba(X_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","cf48e532":"metrics.roc_auc_score(y_test, y_test_pred_prob)\nfpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","2c2a7c43":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Decision Tree\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","d163c5fe":"# print the scores on training and test set\n\nprint('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))\n\nprint('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))","10060af1":"plt.figure(figsize=(12,8))\n\nfrom sklearn import tree\n\ntree.plot_tree(clf_gini.fit(X_train, y_train)) ","b9b54381":"# instantiate the DecisionTreeClassifier model with criterion entropy\n\nclf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n\n\n# fit the model\nclf_en.fit(X_train, y_train)","a7944708":"y_pred=clf_en.predict(X_train)","98871832":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","991a6f28":"y_test_pred=clf_en.predict(X_test)\n","ae68d579":"dc_en_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",dc_en_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","1ef681ee":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=clf_en.classes_)\ndisp.plot()","1d29673f":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","a45aaa75":"y_test_pred_prob=clf_gini.predict_proba(X_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","1fe33bf7":"metrics.roc_auc_score(y_test, y_test_pred_prob)\nfpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='DEcision Tree with Entropy')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","ccd33936":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Decision Tree with Entropy\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","09fcc0e6":"# predict the test data and show the first 5 predictions\npredict=clf_en.predict(X_test)\npredict[1:6]","3cbecf59":"#Convert the numericalinto nominal value and check the few result\n\nprediction_nominal=['M' if x<0.1 else 'B' for x in predict ]\nprediction_nominal[1:6]","2aabd56a":"# split data into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)","8d3cf885":"# import Random Forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n# instantiate the classifier \n\nrfc = RandomForestClassifier(random_state=0)\n\n\n\n# fit the model\n\nrfc.fit(X_train, y_train)\n","53d51649":"y_pred = rfc.predict(X_train)\n","8754e8e4":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","b56d9bae":"y_test_pred=rfc.predict(X_test)\n","55ff97f9":"rfc_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",rfc_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","0216f948":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=rfc.classes_)\ndisp.plot()","b7460718":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","60c878a6":"y_test_pred_prob=rfc.predict_proba(X_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","b4736cfb":"metrics.roc_auc_score(y_test, y_test_pred_prob)\nfpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Random Forest')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","65ebcbc4":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Random Forest\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","1af6492c":"# predict the test data and show the first 5 predictions\npredict=rfc.predict(x_test)\npredict[1:6]","b2d34ff1":"prediction_nominal=['M' if x<0.1 else 'B' for x in predict ]\nprediction_nominal[1:6]","d44ce370":"# Resource\n* Random FOrest- https:\/\/www.kaggle.com\/prashant111\/random-forest-classifier-tutorial\n* Decision Tree - https:\/\/www.kaggle.com\/prashant111\/decision-tree-classifier-tutorial\n* SVC- https:\/\/www.kaggle.com\/nirajvermafcb\/support-vector-machine-detail-analysis","fa81eb4e":"# Decision Tree Clasifiers","15d5901c":"# K-NN","c86fc2c2":"# Hence \n* we will use the KERNEL-Polynomial and C=1.0","ae628a5b":"# Conclusion:- \n* As we can see that the optimum K in KNN we get is K=6","31d04681":"# Default Linear kernel","5b014b5b":"# Default RBF kernel","af3efe3d":"# Conclusion:-\n* It is quite clear that it is overfitting\n* SO we are not gonna use this kernel\n* Look at  the other kernels","47098df7":"# Conclusion:\n* as we can see that using the all features of tha dataset we get the accuract level of 100% which itself shows that it is overfitting condition .\n* It is the first attempt using all the features of the dataset and predict the accuracy level\n* Next job is to predicting the accuracu after removing the some of the existing features of the dataset\n* If we get the accuracy level within 100 % , we can say it works.","aa46d0f2":"# Random Forest Classifiers","d23fe0fc":"# Data Standardisation\nStandardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance). It is useful to standardize attributes for a model. Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data.","e4883e65":"# Decision Tree Classifier with criterion entropy","24c30847":"# Visualize decision-trees","43fc678c":"# Performing K-fold cross validation with different kernels\n* CV on Linear kernel","36913771":"* As we can see that the acuraccy score for Linear KERNAL is very well . SInce the we are getting higher accuracy , it can be due to overfitting using LINEAR kernel.\n* But as it is clear that using the \"rbf\" and \"sigmoid\" will function well and produces the 99% accuracy.\n","60aa983e":"# Conclusion:\n* As we can see that as C value increase the accuracy is increasing respective of the KERNEl\n* Since C is the hyperparameter\n* As C increase the Overfitting occurs.\n* AS C decreases the underfitting occures.\n","d0f1b33b":"# SVC -Support Vector Classifier","9cbc5e91":"Here, the training-set accuracy score is 1.0 while the test-set accuracy to be 1.0. These two values are quite comparable. So, there is no sign of overfitting.","ee53ef6d":"# AS we can see the some of the correlation are very high\/ These may be due to the multcolinearity. We need to use VIF ","1a9fc3e0":"# Coclusion:-\n* As we are gonna use the SIGMOID kernel \n* Its accuracy is quite good\n* I think it is doing well \n* Henc it is best","32281b3e":"# Logistic Regresion"}}