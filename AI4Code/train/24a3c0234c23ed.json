{"cell_type":{"44b87dc5":"code","9625e7f8":"code","6c4430cb":"code","5f4bb7f0":"code","e4be059e":"code","c4363983":"code","875d8fb8":"code","b226a8f1":"code","145c9e4c":"code","b8a48a9b":"code","a450375d":"code","d1d8e044":"code","1b61ab36":"code","2907dee7":"code","66775055":"code","37b3569b":"code","77c14cfe":"code","2376e212":"code","953dcc12":"code","822f354f":"code","7175d1ce":"code","fb7f36da":"code","02c55fbf":"code","b0a8cb2f":"code","fe3efa58":"code","99da647b":"code","429ea07e":"code","6f33ba63":"code","7d45b64f":"code","f3cb262f":"code","0aa80d2a":"code","412ecc01":"code","1dcc1886":"code","8f9327e8":"markdown","4c698b89":"markdown","4e5c5bbc":"markdown","29b67f7c":"markdown","293d5962":"markdown","cbe63607":"markdown","3b457618":"markdown","254d35d4":"markdown","38262fd2":"markdown","23eb4120":"markdown","c31fe5b3":"markdown","325b02b6":"markdown","40896344":"markdown","4479c399":"markdown","37c0ef25":"markdown","b8a7e522":"markdown","5bd3e42b":"markdown","436e3ee5":"markdown","0641eee0":"markdown","0a41f060":"markdown","7daae7a9":"markdown","3c57bd0c":"markdown","414a40ef":"markdown","307e6e64":"markdown","7b37327e":"markdown","29d0acac":"markdown","86f9fe6f":"markdown","f26bb2ab":"markdown","d96a8e24":"markdown","fa4cb9d7":"markdown","4fe842d2":"markdown","0213d805":"markdown","313d2d8a":"markdown","ae0b6101":"markdown","e0d1d816":"markdown","d31afa90":"markdown","22a2f83a":"markdown","e4179cad":"markdown","02ebdb2d":"markdown"},"source":{"44b87dc5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9625e7f8":"#create data drame to read data set\ndf = pd.read_csv('\/kaggle\/input\/gold-price-data\/gld_price_data.csv')","6c4430cb":"df.head()","5f4bb7f0":"# check the df structure\ndf.info()","e4be059e":"# find number of rows and column\ndf.shape","c4363983":"# describe df numerical columns\ndf.describe()","875d8fb8":"# find missing values\nfeatures_na = [features for features in df.columns if df[features].isnull().sum() > 0]\nfor feature in features_na:\n    print(feature, np.round(df[feature].isnull().mean(), 4),  ' % missing values')\nelse:\n    print(\"No missing value found\")","b226a8f1":"for column in df.columns:\n    print(column,df[column].nunique())","145c9e4c":"categorical_features=[feature for feature in df.columns if ((df[feature].dtypes=='O') & (feature not in ['GLD']))]\ncategorical_features","b8a48a9b":"for feature in categorical_features:\n    print('The feature is {} and number of categories are {}'.format(feature,len(df[feature].unique())))","a450375d":"# list of numerical variables\nnumerical_features = [feature for feature in df.columns if ((df[feature].dtypes != 'O') & (feature not in ['GLD']))]\nprint('Number of numerical variables: ', len(numerical_features))\n\n# visualise the numerical variables\ndf[numerical_features].head()","d1d8e044":"discrete_feature=[feature for feature in numerical_features if len(df[feature].unique())<25]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","1b61ab36":"continuous_features=[feature for feature in numerical_features if feature not in discrete_feature+['GOD']]\nprint(\"Continuous feature Count {}\".format(len(continuous_features)))","2907dee7":"#plot a univariate distribution of continues observations\nplt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor continuous_feature in continuous_features:\n    ax = plt.subplot(12,3,plotnumber)\n    sns.distplot(df[continuous_feature])\n    plt.xlabel(continuous_feature)\n    plotnumber+=1\nplt.show()","66775055":"plt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor feature in continuous_features:\n    data=df.copy()\n    ax = plt.subplot(12,3,plotnumber)\n    plt.scatter(data[feature],data['GLD'])\n    plt.xlabel(feature)\n    plt.ylabel('GLD')\n    plt.title(feature)\n    plotnumber+=1\nplt.show()","37b3569b":"#boxplot on numerical features to find outliers\nplt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor numerical_feature in numerical_features:\n    ax = plt.subplot(12,3,plotnumber)\n    sns.boxplot(df[numerical_feature])\n    plt.xlabel(numerical_feature)\n    plotnumber+=1\nplt.show()","77c14cfe":"## Checking for correlation\ncor_mat=df.corr()\nfig = plt.figure(figsize=(15,7))\nsns.heatmap(cor_mat,annot=True)\nplt.show()","2376e212":"print (cor_mat['GLD'].sort_values(ascending=False), '\\n')","953dcc12":"df2=df.copy()","822f354f":"df2.head()","7175d1ce":"# drop Date\ndf2.drop(['Date'],axis=1, inplace=True)","fb7f36da":"X = df2.drop(['GLD'],axis=1)\ny = df2['GLD']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)","02c55fbf":"len(X_train)","b0a8cb2f":"len(X_test)","fe3efa58":"from sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import GridSearchCV","99da647b":"def find_best_model_using_gridsearchcv(X,y):\n    algos = {\n        'decision_tree': {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion' : ['mse','friedman_mse'],\n                'splitter': ['best','random']\n            }\n        },\n        'RandomForestRegressor':{\n        'model':RandomForestRegressor(),\n        'params':{\n            'n_estimators': [10, 50, 100, 130], \n            'criterion': ['mse'],\n            'max_depth': range(2, 4, 1), \n            'max_features': ['auto', 'log2']\n        }\n    },\n    'XGBRegressor':{\n        'model':XGBRegressor(),\n        'params':{\n           'learning_rate': [0.5, 0.1, 0.01, 0.001],\n            'max_depth': [2, 3],\n            'n_estimators': [10, 50, 100, 200]\n        }\n    }\n    }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        })\n\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])","429ea07e":"pd.set_option('display.max_colwidth', 100)\nfind_best_model_using_gridsearchcv(X,y)","6f33ba63":"model_xgb = XGBRegressor(learning_rate=0.5, max_depth=3, n_estimators=200)","7d45b64f":"model_xgb.fit(X_train,y_train)","f3cb262f":"model_xgb.score(X_test,y_test)","0aa80d2a":"y_pred= model_xgb.predict(X_test)","412ecc01":"y_pred","1dcc1886":"y_test","8f9327e8":"**Feature**\n\n- Date - mm\/dd\/yyyy\n- SPX - is a free-float weighted measurement stock market index of the 500 largest companies listed on stock exchanges in the United States.\n- USO - United States Oil Fund - Not Sure of UOM\n- SLV - Silver Price\n- EUR\/USD - currency pair quotation of the Euro against the US\n\n**Label**\n\n- GLD - Gold Price","4c698b89":"# Exploratory Data Analysis","4e5c5bbc":"**10. Find Continous Numerical Features**","29b67f7c":"**6. Relationship between Categorical Features and Label**","293d5962":"**Take-away**:\n    NA","cbe63607":"**12. Relation between Continous numerical Features and Labels**","3b457618":"**3. Find Features with One Value**","254d35d4":"if you like this kernel explaination, please vote this and put your comments. thank you.\n\nhttps:\/\/www.youtube.com\/watch?v=zrC7xE4CVIs&lc=UgzE8GMA3SI7TErWIF54AaABAg","38262fd2":"- Drop unwanted Features\n- Handle Missing Values\n- Handle Categorical Features\n- Handle Feature Scalling\n- Remove Outliers","23eb4120":"**Take-away**:\n- there are 4 numerical features","c31fe5b3":"**7. Explore the Numerical Features**","325b02b6":"**Take-away**:\n- for this kernal we will not consider Date Feature and hence we will drop this feature in feature engineering section.","40896344":"**4. Explore the Categorical Features**","4479c399":"**Take-away**:\n- there are 4 continuous numerical features","37c0ef25":"**8. Find Discrete Numerical Features**","b8a7e522":"**2. Find Missing Values**","5bd3e42b":"**9. Relation between Discrete numerical Features and Labels**\n- NA","436e3ee5":"**Data Description**\n\nThis is the gold price dataset. The dataset gives you information about a gold prices based on serveral other stock prices as given below in which you will have to analyze the gold price and build best machine learning model to predict the gold price.\n\n**Data set columns**\n\n- Date - mm\/dd\/yyyy\n- SPX - is a free-float weighted measurement stock market index of the 500 largest companies listed on stock exchanges in the United States.\n- GLD - Gold Price\n- USO - United States Oil Fund\n- SLV - Silver Price\n- EUR\/USD - currency pair quotation of the Euro against the US","0641eee0":"# Introduction\n\nHello Guys, In this kernel we will try to perform exploratory data analysis and build machine learning model to Predict Gold Price. it will be supervised machine learning and this model will try to solve the regression problem like predict the gold prices based on other stock prices. you can check below youtube link for same.\n\nhttps:\/\/www.youtube.com\/watch?v=zrC7xE4CVIs&lc=UgzE8GMA3SI7TErWIF54AaABAg","0a41f060":"**Take-away**:\n    NA","7daae7a9":"**Take-away**: \n- after applying model selection tech on algos like DecisionTreeRegressor, RandomForestRegressor and XGBRegressor. we found that XGBRegressor gives best result. and hence we will build model using XGBRegressor algorithm.","3c57bd0c":"**Take-away**: \n- it seems SPX,SLV and EUR\/USD distributed normally\n- USO heavely skewed towards right and seems to be have some outliers.","414a40ef":"**1. Find Unwanted Columns**","307e6e64":"**13. Find Outliers in numerical features**","7b37327e":"**5. Find Categorical Feature Distribution**","29d0acac":"# Model Selection","86f9fe6f":"**Take-away**:\n- there is no Discrete Variables in give dataset","f26bb2ab":"**Take-away**:\n- it seems USO and SLV has some outliers","d96a8e24":"# Feature Engineering","fa4cb9d7":"**Take-away**:\n- No missing value found","4fe842d2":"**Take-away**:\n- No feature with only one value","0213d805":"**Take-away**:\n- it seems SLV feature linearly progressing with GLD","313d2d8a":"**Take-away**:\n- there are 1 categorical features","ae0b6101":"As per Exploratory Data Analysis EDA, \n- for this session, we are not considering date feature and hence we will drop this feature\n- no missing value found\n- outliers found in USO and SLV. but for this session we will ignore those.","e0d1d816":"**Take-away**: \n- it seems SLV feature is heavily correlated with GLD","d31afa90":"# Split Dataset into Training set and Test set","22a2f83a":"**14. Explore the Correlation between numerical features**","e4179cad":"**11. Distribution of Continous Numerical Features**","02ebdb2d":"# Model Building"}}