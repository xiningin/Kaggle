{"cell_type":{"826852f8":"code","bdbfe798":"code","fc723af4":"code","94f2a825":"code","66bcd348":"code","451972fe":"code","f4ce078b":"code","7e33ab4f":"code","a9133139":"code","2ed836c1":"code","4907c607":"code","b31183c8":"code","2a3a4088":"code","bc83ff48":"code","0063118c":"code","6aa0f75c":"code","430d06fd":"code","495fb19f":"code","781b177e":"code","186e68d8":"code","8199cfe8":"code","edcda201":"code","c93cb5da":"code","4f03b35a":"code","5037aa36":"code","5d64e655":"code","1d35a726":"code","1b69aac0":"code","9f55887b":"code","1c62cb2e":"code","6e24b3a0":"code","c84cb80f":"code","e758aef7":"markdown","48b4e15b":"markdown","439fab8f":"markdown","9305b44e":"markdown","cc21ece6":"markdown"},"source":{"826852f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n%matplotlib inline \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV","bdbfe798":"cancer=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ncancer.head()","fc723af4":"cancer.shape","94f2a825":"cancer.columns","66bcd348":"cancer.diagnosis.value_counts()","451972fe":"cancer[cancer.isnull().any(axis=1)]","f4ce078b":"cancer = cancer.drop(['Unnamed: 32','id'],axis = 1)","7e33ab4f":"cancer.head()","a9133139":"cancer.describe().T","2ed836c1":"corr=cancer.corr()\ncorr.shape","4907c607":"plt.figure(figsize=(40,40))\nsns.heatmap(corr,cbar=True,square=True,fmt='.1f',annot=True,cmap='coolwarm')","b31183c8":"sns.FacetGrid(cancer,hue='diagnosis',height=10).map(sns.kdeplot,\"radius_mean\").add_legend()\nplt.show()","2a3a4088":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\nDiagnosis = label_encoder.fit_transform(cancer['diagnosis'])\nDiagnosis = pd.DataFrame({'diagnosis': Diagnosis})\ncancer.diagnosis = Diagnosis\ncancer","bc83ff48":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\ny= cancer['diagnosis']\nX = cancer.drop(columns =['diagnosis'])\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1)","0063118c":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(max_iter=10000)\nlogreg.fit(X_train,y_train)","6aa0f75c":"y_pred=logreg.predict(X_test)","430d06fd":"accuracy_lr = round(metrics.accuracy_score(y_test,y_pred)*100,2)\nprint(\"Logistic Regression Accuracy:\",accuracy_lr)","495fb19f":"from sklearn.metrics import classification_report, confusion_matrix\ncm = np.array(confusion_matrix(y_test, y_pred))\nconfusion = pd.DataFrame(cm, index=['is_cancer', 'is_healthy'],\n                         columns=['predicted_cancer','predicted_healthy'])\nconfusion","781b177e":"sns.heatmap(confusion, annot=True)","186e68d8":"print(classification_report(y_test, y_pred))","8199cfe8":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nmodel.fit(X_train,y_train)","edcda201":"y_pred=model.predict(X_test)\naccuracy_gnb = round(metrics.accuracy_score(y_test,y_pred)*100,2)\nprint(\"Gaussian NB Accuracy:\",accuracy_gnb)","c93cb5da":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier()","4f03b35a":"parameters = {'max_features':['log2','sqrt','auto'],\n             'criterion':['entropy','gini'],\n             'max_depth':[2,3,5,10,50],\n             'min_samples_split':[2,3,50,100],\n             'min_samples_leaf':[1,5,8,10]}\ngrid_obj = GridSearchCV(clf,parameters)\ngrid_obj = grid_obj.fit(X_train,y_train)\nclf = grid_obj.best_estimator_\nclf.fit(X_train,y_train)","5037aa36":"y_pred = clf.predict(X_test)\naccuracy_dt = round(metrics.accuracy_score(y_test,y_pred)*100,2)\nprint(\"Decision Tree Accuracy:\",accuracy_dt)\n","5d64e655":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nparameters = {'n_estimators': [4, 6, 9, 10, 15], \n              'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy', 'gini'],\n              'max_depth': [2, 3, 5, 10], \n              'min_samples_split': [2, 3, 5],\n              'min_samples_leaf': [1, 5, 8]\n             }\ngrid_obj = GridSearchCV(rf,parameters)\ngrid_obj = grid_obj.fit(X_train,y_train)\nrf = grid_obj.best_estimator_\nrf.fit(X_train,y_train)","1d35a726":"accuracy_rf = round(metrics.accuracy_score(y_test,y_pred)*100,2)\nprint(\"Random Forest Classifier Accuracy:\",accuracy_rf)","1b69aac0":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nparameters = { 'n_neighbors' :[3,4,5,10],\n              'weights' : ['uniform','distance'],\n             'algorithm': ['auto','ball_tree','kd_tree','brute'],\n             'leaf_size' : [10,20,30,50]}\ngrid_obj = GridSearchCV(knn,parameters)\ngrid_obj = grid_obj.fit(X_train,y_train)\nknn = grid_obj.best_estimator_\nknn.fit(X_train,y_train)","9f55887b":"y_pred = knn.predict(X_test)\naccuracy_knn = round(metrics.accuracy_score(y_test,y_pred)*100,2)\nprint(\"KNN Accuracy:\",accuracy_knn)","1c62cb2e":"from sklearn import svm\nsvc = svm.SVC()\nparameters = [\n  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n]\ngrid_obj = GridSearchCV(svc,parameters)\ngrid_obj = grid_obj.fit(X_train,y_train)\nsvc = grid_obj.best_estimator_\nsvc.fit(X_train,y_train)","6e24b3a0":"y_pred = svc.predict(X_test)\naccuracy_svm = round(metrics.accuracy_score(y_test,y_pred)*100,2)\nprint(\"SVM Accuracy:\",accuracy_svm)","c84cb80f":"models_used = pd.DataFrame({\n    'Model': ['Logistic Regression','Naive Bayes','Decision Tree','Random Forest',\n              'Support Vector Machines','K-Nearest Neighbors'],\n    'Score' : [accuracy_lr,accuracy_gnb,accuracy_dt,accuracy_rf,accuracy_svm,accuracy_knn]})\nmodels_used.sort_values(by='Score')","e758aef7":"dropping the Unnamed:32 and id column from the dataset as they are of use ","48b4e15b":"There are 357 Benign patients and 212 Malignant patients under the diagnosis column.","439fab8f":"Prediction","9305b44e":"Data Preparation & One-hot Encoding ","cc21ece6":"0 is for Malignant 1 is for Benign"}}