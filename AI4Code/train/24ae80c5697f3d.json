{"cell_type":{"66412342":"code","9bf94d0f":"code","b602c1b2":"code","c6acfeda":"code","2407f7a8":"code","9660efd7":"code","22a479af":"code","19f82eb2":"code","d67711b7":"code","8741c13c":"code","6ddb3d27":"code","15134902":"code","bf11f5b9":"code","c5fa8e3d":"code","966e158b":"code","9fc6f739":"code","b188d2dc":"code","42e5ec4d":"code","82f5be0b":"code","2fa763cb":"code","7cd085e0":"code","7e528843":"code","9b5225c3":"code","323903fb":"code","444aa659":"code","7c52ddb8":"code","ad3a92bd":"code","d2893baf":"code","6b183a64":"code","95525f5a":"code","11d7f995":"code","112300c6":"code","356e2913":"code","556c1afc":"code","1eb4e11d":"code","c878ab9b":"code","13ec5079":"code","b339ecf2":"code","ea2f3c48":"code","9920a784":"code","a03741a6":"code","86f0ce8b":"code","7fab3d47":"code","97e17117":"code","1c437b3a":"code","4ac86f44":"code","7b3bc26d":"code","83b5f052":"code","e806a480":"code","2cb07846":"code","380c8906":"code","ceac9a8e":"code","9c5d5663":"code","ac1189d6":"code","492ef037":"code","d7c6b0ae":"code","a36219ef":"code","ecee7bfc":"code","3367fb9e":"code","549767bd":"code","37003d36":"code","b789639c":"code","085181e2":"code","38b14dbb":"code","9d0ebf55":"code","2843dc4c":"code","ba0d594a":"code","42f0749d":"code","b0af41a9":"code","1a52c232":"code","22004d16":"code","21c0fec4":"code","37d51aaf":"code","c896db69":"code","f3373d6a":"code","602bba44":"code","bd1dc7af":"code","21889c14":"code","3a49936d":"code","923e0749":"code","8ba69d87":"code","35d80292":"code","bfd618c8":"code","fa2899dd":"code","2bb5a12e":"code","7807b4c7":"code","cfb262e2":"code","96ec8ca9":"code","1af7de79":"code","2100ecdd":"code","39a5d1ff":"code","cbce344d":"code","c76eab7d":"code","23ba4e10":"code","13002b78":"code","af4c9f18":"code","8c791a2b":"code","035868ff":"code","c9191e0a":"code","e5f1fb4b":"code","2edb4a6e":"code","fe8495c8":"code","0a49424b":"code","71b83435":"code","b2cadb39":"code","b88a6238":"code","bff1016e":"code","1141a7d6":"code","aac8022f":"code","b7c170af":"code","5628a8e8":"code","73bc6bd7":"code","f9b5b71a":"code","13e759d0":"code","ca30d88f":"code","54469bb4":"code","093dcd8a":"code","08e865e7":"code","17525c21":"code","82e5b9df":"code","08fdaadc":"code","5680975b":"code","17c70a01":"code","d83d0929":"code","f473a238":"code","e09bad16":"code","c1bc9877":"code","34e9dd21":"code","bafc006d":"code","3c075273":"code","bcc0a6a6":"code","9e092369":"code","fe3f3360":"code","d59392ec":"code","d9c4bfd1":"code","8c9d329f":"code","842aae64":"code","942f4ae7":"code","b51fd4f4":"code","7ea0a2cf":"code","dd69fda0":"code","1c0a4dd8":"code","c4cf2a2f":"code","21c90275":"code","0b393196":"code","879d258c":"code","ec1812e2":"code","a3da5db4":"code","9211cfc0":"code","66a3ad33":"code","54512d42":"code","376507a4":"code","ddc55620":"code","3c629f9e":"code","c3722d2b":"code","940f08c6":"code","96322efc":"code","593ca305":"code","87352d43":"code","60b38219":"code","0a4f7bdf":"code","0cd870eb":"code","af998ba5":"code","4805a037":"code","e92b75c1":"code","37f2b921":"code","21ef81f0":"code","c8d75c2d":"code","9922e610":"code","b308cb21":"code","bbb46a71":"code","a6eb6cb4":"code","e0f8187f":"code","e439e930":"code","6ca95251":"code","cbbcccbc":"code","07c9f2f9":"code","7dcdb0d8":"code","c27cf572":"code","3540c65e":"code","2552e339":"code","d32e1514":"code","bef35e69":"code","184ca5e0":"code","c4d7f20a":"code","447e98a8":"code","6608c766":"code","3f76802e":"code","fea0128c":"code","e2e4b02e":"code","27ada482":"code","13bae01f":"code","b8d1cb75":"code","ffba380a":"code","ca4d7934":"code","eefbcbda":"code","d084eaf9":"code","a01366eb":"code","37aa018f":"code","eb0f0fa1":"code","2ebee0ff":"code","03da1653":"code","9a30d22a":"code","b8ca6259":"code","b3cc2b8d":"code","a12a5025":"code","e2f1a829":"code","a00cb565":"code","06b8a995":"code","265c18d0":"code","5866e82d":"code","4140990b":"code","bcbd2aaf":"code","30cf7789":"code","d58a2d5c":"code","f7bd1de6":"code","b35f8af2":"code","f2150a23":"code","96d7ff6f":"code","64233378":"code","a6e98916":"code","044013c3":"code","696150cb":"code","5c8e46ce":"code","6d91a9ae":"code","6218fd3b":"code","291f778f":"code","a798ebee":"code","2fe45838":"code","12808e08":"code","993cb8c6":"code","805a1ca7":"code","5ce1b79f":"code","e1470fa1":"code","47f5a9f6":"code","1e6daa64":"code","cf244806":"code","d812dac8":"code","0e415808":"code","fe63333d":"code","c3037eea":"code","57b49330":"code","2e15c8c3":"code","f40d865d":"code","d3244004":"code","76180a18":"code","f005c3ac":"code","74d5a626":"code","55e51f08":"code","e375a406":"code","59fa740b":"code","44c171ad":"code","ae0fc5da":"code","c791a355":"code","e7545df5":"code","f03412b9":"code","f609f3f6":"code","aeec97a4":"code","ca1563bd":"code","ebe03db7":"code","2c1af37f":"code","3d5a060e":"code","cd449f6d":"code","9c146603":"code","f92696af":"code","ca29ea4d":"code","dfdb6fb5":"code","079de731":"code","8b1647fe":"code","62d3f722":"code","5046c761":"code","89de0665":"code","3e0c53ee":"code","a722d8ad":"code","6221dba4":"code","dc0f72fd":"code","231ed26b":"code","79187429":"code","78ac0ace":"code","28550b15":"code","750d73ea":"code","b0914440":"code","4baed33c":"code","ab3372fe":"code","75732c2e":"code","fbb427bc":"code","cf145787":"code","3130aefd":"code","ac556fc9":"code","1ebc1fc2":"code","e62878f0":"code","5afc7e83":"code","3948f92f":"code","b6d9c588":"code","c26ea3db":"code","1a362a3f":"code","7c8d2e22":"code","6bf74429":"code","bbd8d9fb":"code","af9518fb":"code","52586633":"code","96638f08":"code","7d1810a8":"code","c1482337":"code","499cbe4a":"code","dfe8ea87":"code","6ef8c039":"code","ec60585e":"code","5e17c61d":"code","9d1a4991":"code","b51bb56d":"code","2a6c7645":"code","7e8d1675":"code","c77081cd":"code","50f29995":"code","2a078af0":"code","47ca2c83":"code","5e230619":"code","90ac73bb":"code","1b83b979":"code","237980e3":"code","5579ab1e":"code","6c68c692":"code","492cd925":"code","8d71dda3":"code","1dedf820":"code","261e9f9f":"markdown","00c9de95":"markdown","01eb4b3c":"markdown","be87ffa3":"markdown","e68c299b":"markdown","0c90057e":"markdown","32f42d75":"markdown","bd937a6d":"markdown","7e718b16":"markdown","53c9ea8b":"markdown","caf03dd4":"markdown","fff63cdf":"markdown","a2d972b1":"markdown","e30b56ce":"markdown","84fb8395":"markdown","6421deb7":"markdown","50ea02d8":"markdown","2fec5617":"markdown","925576ab":"markdown","8b0b49f0":"markdown","03d7e21b":"markdown","1ce15671":"markdown","f4008200":"markdown","824ff0ba":"markdown","26fccfe5":"markdown","d4bb1c9c":"markdown","3e17e059":"markdown","e09982b7":"markdown","3be3e053":"markdown","ad522f4b":"markdown","d9822050":"markdown","c7e540f2":"markdown","1a0021c3":"markdown","811240c6":"markdown","97eabbd4":"markdown","db76fa44":"markdown","da4017e9":"markdown","1e41ec8c":"markdown","b7c8b4b2":"markdown","6cebec97":"markdown","536c4f3b":"markdown","3f1eff12":"markdown","c24d824b":"markdown","27440761":"markdown","88a2b519":"markdown","f1521b37":"markdown","afbebc6b":"markdown","21555ec7":"markdown","91de8b21":"markdown","c5919dc3":"markdown","6f990553":"markdown","945abbda":"markdown","12485cff":"markdown","870d5eed":"markdown","f95371f6":"markdown","085f17bd":"markdown","1a4f9c76":"markdown","fb646047":"markdown","409fbbb2":"markdown","0e43255b":"markdown","69751e30":"markdown","c89c1ccf":"markdown","1ce12224":"markdown","98991d85":"markdown","6dc749af":"markdown","fbdf0547":"markdown","3c71f19a":"markdown","fea2eba5":"markdown","0169de2c":"markdown"},"source":{"66412342":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","9bf94d0f":"df_train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_train","b602c1b2":"df_test=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ndf_test","c6acfeda":"# Copying original dataset.\ndf=df_train","2407f7a8":"df.info()","9660efd7":"df.columns[df.isnull().any()] # Missing values. Column with true values are printed.","22a479af":"a=df.columns[df.isnull().any()]\na","19f82eb2":"a=list(a)\na #easy to work with lists","d67711b7":"r,c=df.shape\nr,c","8741c13c":"missing_df=df[a]\nmissing_df","6ddb3d27":"r1,c1=missing_df.shape\nr1,c1","15134902":"missing_df.isna()\n","bf11f5b9":"missing_df.isna().sum()*100\/r1\n# miss_per_df.sum()*100\/r1","c5fa8e3d":"def percent_missing(df):\n    data = pd.DataFrame(df)\n    df_cols = list(pd.DataFrame(data)) #List of Columns of dataframe named 'data'\n    dict_x = {}\n    for i in range(0, len(df_cols)):\n        dict_x.update({df_cols[i]: round(data[df_cols[i]].isnull().mean()*100,2)}) #Make dictionary of missing columns as key and percentage (upto 2 decimal places rounded up ) as value\n    \n    return dict_x\n","966e158b":"missing = percent_missing(missing_df)\ndf_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)# lambda x:x[1] i.e. sorting acc. to second parameter i.e. percentage of missing values\nprint('Percent of missing data')\ndf_miss","9fc6f739":"import seaborn as sns\nimport matplotlib.pyplot as plt","b188d2dc":"sns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(8, 7))\nsns.set_color_codes(palette='deep') #Color of bar graph.\nmissing = round(missing_df.isnull().mean()*100,2)\n# missing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar(color=\"b\")\n\n# Tweak the visual presentation\nax.grid(True)\nax.set(ylabel=\"Percent of missing values\")\nax.set(xlabel=\"Features\")\nax.set(title=\"Percent missing data by feature\")\nsns.despine(trim=True, left=True)# Outer borders","42e5ec4d":"# Dropping columns with >=20% missing data\n# missing_data_20=missing_df.isna().sum()*100\/r1>=20\n# missing_data_20","82f5be0b":"# missing_data_20.values","2fa763cb":"dropping=[]\n# for i in range(c1):\n#     if missing_data_20.values[i]==True:\n#         dropping.append(missing_data_20.index[i])\ndropping=['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\ndropping","7cd085e0":"df_updated=df.drop(columns=dropping,axis=1)\ndf_updated","7e528843":"#test data is copied\nc_test=df_test","9b5225c3":"c_test=c_test.drop(columns=dropping,axis=1)\nc_test","323903fb":"y=df_updated.iloc[:,[-1]]\ny.head()","444aa659":"x=df_updated.iloc[:,:-1]\nx.head()","7c52ddb8":"# categorical_col=list(x.columns)\n# len(categorical_col)","ad3a92bd":"# s='LotFrontage LotArea MasVnrArea BsmtFinSF1 BsmtFinSF2 BsmtUnfSF TotalBsmtSF 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea GarageYrBlt GarageCars GarageArea WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea MiscVal MoSold YrSold'\n# non_categorical_col=s.split()","d2893baf":"len(missing_df.columns)","6b183a64":"missing_rest=list(missing_df.columns)\n(missing_rest)","95525f5a":"dropping","11d7f995":"missing_rest=list(set(missing_rest).difference(dropping))\nmissing_rest","112300c6":"missing_rest=df.loc[:, missing_rest] \nmissing_rest","356e2913":"missing_rest.describe()","556c1afc":"# mean and mode is same for GarageYrBlt and LotFRONTage. SO filling them by mean. THe data seems normally distributed","1eb4e11d":"b=pd.DataFrame(missing_rest['MasVnrArea'])  #External layer of house              \nb.plot(kind='hist')\n# Hence filling this volumn by zero.Better to drop it.No meaning of 0 sq. feet","c878ab9b":"b['MasVnrArea'].value_counts()","13ec5079":"missing_rest['BsmtFinType2'].value_counts()\n# 1256\/1460= 86%","b339ecf2":"missing_rest['BsmtQual'].value_counts()\n# 1423","ea2f3c48":"missing_rest['BsmtCond'].value_counts()\n# 1311\/1460 =","9920a784":"missing_rest['GarageType'].value_counts()\n# 1379","a03741a6":"missing_rest['BsmtFinType1'].value_counts()\n# 1423","86f0ce8b":"missing_rest['GarageQual'].value_counts()\n# 1311\/1460=","7fab3d47":"missing_rest['GarageFinish'].value_counts()\n# 1379","97e17117":"missing_rest['MasVnrType'].value_counts()\n# 1452","1c437b3a":"missing_rest['BsmtExposure'].value_counts()\n# 1422","4ac86f44":"missing_rest['GarageCond'].value_counts()\n# 1326\/1460= ","7b3bc26d":"from sklearn.impute import SimpleImputer\n","83b5f052":"c_test1=c_test\nc_test1","e806a480":"sns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(8, 7))\nsns.set_color_codes(palette='deep') #Color of bar graph.\nmissing = round(missing_rest.isnull().mean()*100,2)\n# missing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar(color=\"b\")\n\n# Tweak the visual presentation\nax.grid(True)\nax.set(ylabel=\"Percent of missing values\")\nax.set(xlabel=\"Features\")\nax.set(title=\"Percent missing data by feature\")\nsns.despine(trim=True, left=True)# Outer borders","2cb07846":"(df[df['GarageArea']==0]).index\n(df[df['GarageCars']==0]).index\n(df[df['GarageYrBlt'].isnull()]).index\n(df[df['GarageQual'].isnull()]).index\n(df[df['GarageCond'].isnull()]).index\n(df[df['GarageFinish'].isnull()]).index\n\n(df[df['GarageYrBlt'].isnull()]).index\n# (df[df['BsmtFinSF1'].isnull()]).index\n\n# df.loc[[17],[\"BsmtFinSF1\"]]\n","380c8906":"for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    missing_rest[col] = missing_rest[col].fillna('NA')","ceac9a8e":"for col in ['GarageYrBlt']:\n    missing_rest[col] = missing_rest[col].fillna(0)    ","9c5d5663":"(df[df['BsmtQual'].isnull()]).index\n(df[df['BsmtCond'].isnull()]).index\n(df[df['BsmtExposure'].isnull()]).index\n(df[df['BsmtFinType1'].isnull()]).index\n(df[df['BsmtFinType2'].isnull()]).index\n\ndf.loc[[39],[\"BsmtFinSF1\"]]\n# df['B']","ac1189d6":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    missing_rest[col] = missing_rest[col].fillna('NA') ","492ef037":"df['Neighborhood'].unique()","d7c6b0ae":"see=df.groupby('Neighborhood')['LotFrontage']\nsee.get_group('Blmngtn')","a36219ef":"missing_rest['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.mean()))","ecee7bfc":"(df[df['MasVnrArea'].isnull()]).index\ndf['MasVnrType'].value_counts()","3367fb9e":"seeyou=df.groupby('MasVnrType')['MasVnrArea']\nseeyou.get_group('None').sort_values(ascending=False)","549767bd":"# for col in ('MasVnrType')\nmissing_rest['MasVnrType'] = missing_rest['MasVnrType'].fillna('None') \nmissing_rest['MasVnrArea'] = missing_rest['MasVnrArea'].fillna(0) ","37003d36":"for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    c_test1[col] = c_test1[col].fillna('NA')\n\nfor col in ['GarageYrBlt']:\n    c_test1[col] = c_test1[col].fillna(0)    \n\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    c_test1[col] = c_test1[col].fillna('NA')\n    \nc_test1['MasVnrType'] = c_test1['MasVnrType'].fillna('None') \nc_test1['MasVnrArea'] = c_test1['MasVnrArea'].fillna(0) \n\n# c_test1['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.mean()))","b789639c":"c_test=c_test1","085181e2":"mode_imputer=SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n","38b14dbb":"missing_rest['Electrical'].value_counts()","9d0ebf55":"a1=missing_rest.loc[:,['Electrical']]\na1.info()","2843dc4c":"mode_imputer.fit(a1)\na11 = mode_imputer.transform(a1)\n","ba0d594a":"c_test1['Electrical'].value_counts()","42f0749d":"c_test1.loc[:,['Electrical']].info()","b0af41a9":"# c_test1.loc[:,['Electrical']]=mode_imputer.transform(c_test1.loc[:,['Electrical']])","1a52c232":"c_test=c_test1","22004d16":"(missing_rest[missing_rest['Electrical'].isnull()]).index\nmissing_rest['Electrical'][1379]='SBrkr'\n","21c0fec4":"missing_rest.info()","37d51aaf":"# c_test1.loc[:,['Electrical']].info()","c896db69":"from sklearn.preprocessing import LabelEncoder\n","f3373d6a":"zz=x\nzz","602bba44":"remove='GarageType BsmtExposure GarageQual BsmtCond GarageYrBlt MasVnrArea GarageFinish BsmtFinType2 GarageCond Electrical BsmtQual MasVnrType LotFrontage BsmtFinType1'","bd1dc7af":"remove=remove.split()\nremove","21889c14":"x=x.drop(columns=remove)\nx = pd.concat([x, missing_rest], axis=1, sort=False)","3a49936d":"x","923e0749":"c_test1_missing_values=c_test1.columns[c_test1.isnull().any()] # Missing values in test data.\nc_test1_missing_values=list(c_test1_missing_values)\nc_test1_missing_values","8ba69d87":"df_test_c_missing=c_test1.loc[:,c_test1_missing_values]\ndf_test_c_missing","35d80292":"c_test1.loc[:,c_test1_missing_values].info()","bfd618c8":"c_missing=SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n\nc_missing.fit(x.loc[:,c_test1_missing_values])\nc_test1.loc[:,c_test1_missing_values] = c_missing.transform(c_test1.loc[:,c_test1_missing_values])","fa2899dd":"c_test1.columns[c_test1.isnull().any()]\n","2bb5a12e":"c_test1.loc[:,c_test1_missing_values].info()","7807b4c7":"#For categorical columns:-","cfb262e2":"chalo=c_test1.loc[:,['Exterior2nd','Utilities','Exterior1st',\n 'SaleType',\n 'KitchenQual',\n 'Functional',\n 'MSZoning']]\nchalo","96ec8ca9":"set(chalo.columns)","1af7de79":"c_test1['Foundation'].unique()\n# 16, 10 ,5, 5, 25, 8, 6, 6, 9","2100ecdd":"# count=0\n# for i in range(0,1459):\n#     if type(chalo['Utilities'][i])==str:\n#         continue\n# #         print('hi')\n#     else:\n#          print(i,(chalo['Utilities'][i]),(chalo['Utilities'][i-1]))\n# #          count+=1\n# # print(count)\n#    ","39a5d1ff":"# Exterior 2nd --691---13.0\nchalo.Exterior2nd.value_counts()\nchalo['Exterior2nd'][691]='VinylSd'\nchalo['Exterior2nd'][691]","cbce344d":"# Utilities\n# 455 0.0 AllPub\n# 485 0.0 AllPub\nchalo.Utilities.value_counts()\nchalo['Utilities'][455]='AllPub'\nchalo['Utilities'][485]='AllPub'\n\nchalo['Utilities'][455], chalo['Utilities'][485]","c76eab7d":"# Exterior1st\n# 691 12.0 BrkFace\nchalo.Exterior1st.value_counts()\nchalo['Exterior1st'][691]='VinylSd'\nchalo['Exterior1st'][691]","23ba4e10":"# SaleType 1029 noo (8.0, 'WD')\nchalo.SaleType.value_counts()\nchalo['SaleType'][1029]='WD'\nchalo['SaleType'][1029]","13002b78":"# KitchenQual 95 noo (3.0, 'TA')\nchalo.KitchenQual.value_counts()\nchalo['KitchenQual'][95]='TA'\nchalo['KitchenQual'][95]","af4c9f18":"# # Functional\n# 756 noo (6.0, 'Typ')\n# 1013 noo (6.0, 'Typ')\nchalo.Functional.value_counts()\nchalo['Functional'][756]='Typ'\nchalo['Functional'][1013]='Typ'\nchalo['Functional'][756],chalo['Functional'][1013]","8c791a2b":"# \n# 455 noo (3.0, 'RM')\n# 756 noo (3.0, 'RM')\n# 790 noo (3.0, 'RL')\n# 1444 noo (3.0, 'RL')\n\nchalo.MSZoning.value_counts()\nchalo['MSZoning'][756]='RL'\nchalo['MSZoning'][455]='RL'\nchalo['MSZoning'][790]='RL'\nchalo['MSZoning'][1444]='RL'\n\nchalo['MSZoning'][756],chalo['MSZoning'][455],chalo['MSZoning'][790],chalo['MSZoning'][1444]","035868ff":"chalo_columns=[]","c9191e0a":"for i in chalo.columns:\n    chalo_columns.append(i)\nchalo_columns    ","e5f1fb4b":"x.loc[:,chalo_columns[0]]","2edb4a6e":"x_copy=x.loc[:,chalo_columns]\nx_copy","fe8495c8":"chalo","0a49424b":"chalo[chalo_columns[0]]","71b83435":"def chalo_encoder(i):\n    l=LabelEncoder()\n    \n    l.fit(x.loc[:,chalo_columns[i]])\n#     x.loc[:,chalo_columns[i]]=l.transform(x.loc[:,chalo_columns[i]])\n    chalo[chalo_columns[i]]=l.transform(chalo[chalo_columns[i]])","b2cadb39":"c_test1=c_test1.drop(columns=chalo.columns)","b88a6238":"c_test1 = pd.concat([c_test1, chalo], axis=1, sort=False)\nc_test1","bff1016e":"c_test=c_test1","1141a7d6":"num_cols = x._get_numeric_data().columns\nnum_cols,len(num_cols)","aac8022f":"categorical=list(set(x.columns) - set(num_cols))\ncategorical,len(categorical)","b7c170af":"zz=x\nzz","5628a8e8":"\nnum_cols = zz._get_numeric_data().columns\nlen(num_cols)","73bc6bd7":"num_co = c_test1._get_numeric_data().columns\nnum_co","f9b5b71a":"categorical_test=list(set(c_test1.columns) - set(num_co))\ncategorical_test,len(categorical_test)","13e759d0":"num_c = c_test1._get_numeric_data().columns\nlen(num_c)","ca30d88f":"num_cols = zz._get_numeric_data().columns\nlen(num_cols)\n# BEFORE","54469bb4":"num_cols = c_test1._get_numeric_data().columns\nlen(num_cols)\n# BEFORE","093dcd8a":"def lebel_enc(yoo):\n    l1=LabelEncoder()\n    \n    l1.fit_transform(zz[yoo])\n    zz[yoo]=l1.transform(zz[yoo])\n    c_test1[yoo]=l1.transform(c_test1[yoo])\n","08e865e7":"for i in categorical:\n    lebel_enc(i)","17525c21":"num_cols = zz._get_numeric_data().columns\nlen(num_cols)\n# AFter","82e5b9df":"num_cols = c_test1._get_numeric_data().columns\nlen(num_cols)\n# AFter","08fdaadc":"x","5680975b":"import seaborn as sns","17c70a01":"# from sklearn.feature_selection import SelectKBest\n# from sklearn.feature_selection import chi2\n","d83d0929":"\n# bestfeatures = SelectKBest(score_func=chi2, k=30)\n# fit = bestfeatures.fit(x,y)\n\n# dfscores = pd.DataFrame(fit.scores_)\n# dfcolumns = pd.DataFrame(x.columns)\n\n# #concat two dataframes for better visualization \n# featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n# featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n# print(featureScores.nlargest(30,'Score'))  #print 10 best features","f473a238":"# hi=featureScores.sort_values(by='Score',ascending=False).iloc[:30,[0]]\n# hi","e09bad16":"# hii_selectBestK=hi['Specs'].to_list()","c1bc9877":"# hii_selectBestK","34e9dd21":"# select_bestK_columns=hii_selectBestK","bafc006d":"# x_select_bestk=x.loc[:,select_bestK_columns]","3c075273":"# x_select_bestk","bcc0a6a6":"# c_test_select_bestk=c_test.loc[:,select_bestK_columns]","9e092369":"# c_test_select_bestk","fe3f3360":"temp_df=x.iloc[:,0:40]\ntemp_df=pd.concat([temp_df,y], axis=1, sort=False)\ntemp_df","d59392ec":"# Plotting 1st 40 columns ","d9c4bfd1":"plt.figure(figsize = (70,70))\ncorr1 = temp_df.corr()\n\nax = sns.heatmap(\n    corr1, \n    vmin=-1, vmax=1,\n    cmap=sns.diverging_palette(20, 220, n=200),linewidth=2\n    \n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right',size=40\n);\n\nax.set_yticklabels( ax.get_yticklabels(),size=(40), rotation=45,);","8c9d329f":"corr_heatmap1=corr1.loc[:,['SalePrice']].sort_values(by='SalePrice',ascending=False)*100 \ncorr_heatmap1=corr_heatmap1[corr_heatmap1['SalePrice']>10]\ncorr_heatmap1","842aae64":"corr_heatmap1.shape","942f4ae7":"corr1_columns=(corr_heatmap1.index.tolist()[1:])\nlen(corr1_columns)","b51fd4f4":"# Plotting 41 till last columns\ntemp_df=x.iloc[:,41:]\ntemp_df=pd.concat([temp_df,y], axis=1, sort=False)\ntemp_df","7ea0a2cf":"plt.figure(figsize = (70,70))\ncorr2 = temp_df.corr()\n\nax = sns.heatmap(\n    corr2, \n    vmin=-1, vmax=1,\n    cmap=sns.diverging_palette(20, 220, n=200),linewidth=2\n    \n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right',size=40\n);\n\nax.set_yticklabels( ax.get_yticklabels(),size=(40), rotation=45,);","dd69fda0":"corr_heatmap2=corr2.loc[:,['SalePrice']].sort_values(by='SalePrice',ascending=False)*100 \ncorr_heatmap2=corr_heatmap2[corr_heatmap2['SalePrice']>10]\ncorr_heatmap2","1c0a4dd8":"len(corr_heatmap2.index)","c4cf2a2f":"corr2_columns=(corr_heatmap2.index.tolist()[1:])\nlen(corr2_columns)\n","21c90275":"columns_from_heatmap=corr1_columns+corr2_columns\ncolumns_from_heatmap,len(columns_from_heatmap)","0b393196":"x_heatmap=x.loc[:,columns_from_heatmap]\n# x1.insert(0, \"Id\", x.iloc[:,0:1], True) \nx_heatmap","879d258c":"\nc_test_heatmap=c_test.loc[:,columns_from_heatmap]\n# c1_test.insert(0, \"Id\", c_test.iloc[:,0:1], True) \nc_test_heatmap","ec1812e2":"columns_from_heatmap","a3da5db4":"# X = x  #independent columns\n\n# from sklearn.ensemble import ExtraTreesClassifier\n# import matplotlib.pyplot as plt\n\n# model = ExtraTreesClassifier()\n# model.fit(X,y)\n\n# print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n# #plot graph of feature importances for better visualization\n\n# feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n# feat_importances.nlargest(10).plot(kind='barh')\n# plt.show()","9211cfc0":"# data = {'Specs':X.columns,\n#         'Score':model.feature_importances_}","66a3ad33":"# data","54512d42":"# feat_importance1 = pd.DataFrame(data)\n# feat_importance1","376507a4":"# hi=feat_importance1.sort_values(by='Score',ascending=False).iloc[1:31,[0]]\n# Taking from 1 to 31 as 1st one is 'Id' column. \n# hi","ddc55620":"# hii=hi['Specs'].to_list()\n# feature_importance_columns=hii\n\n# x_feature_importance=x.loc[:,feature_importance_columns]","3c629f9e":"# x_feature_importance","c3722d2b":"# c_test_feature_importance=c_test.loc[:,feature_importance_columns]\n# c_test_feature_importance","940f08c6":"# feature_importance_columns","96322efc":"# s1=set(hii_selectBestK)\n# s2=set(columns_from_heatmap)\n# s3=set(feature_importance_columns)","593ca305":"# set1=s1.intersection(s1)\n# len(set1)","87352d43":"# set2=s3.intersection(set1)\n# len(set2)","60b38219":"from sklearn.model_selection import train_test_split","0a4f7bdf":"xtrain,xtest,ytrain,ytest=train_test_split(x_heatmap,y,test_size=0.3,random_state=0)\n# x1 for heatmap\n# x_select_bestk for selectbest k\n# x_feature_importance for feature importance","0cd870eb":"ytest","af998ba5":" from sklearn.ensemble import RandomForestRegressor","4805a037":"reg=RandomForestRegressor(n_estimators=2000,random_state=0,max_depth=15)\nreg.fit(xtrain,ytrain)","e92b75c1":"randomForest_predict=reg.predict(xtest)","37f2b921":"randomForest_predict","21ef81f0":"# from sklearn.model_selection import cross_val_score\/","c8d75c2d":"# accuracies=cross_val_score(estimator=reg,X=xtrain,y=ytrain,cv=10)#Vector having accuracy computed by combinations of k models.Usually k=10 is taken","9922e610":"# accuracies.mean()*100\n","b308cb21":"# accuracies.std()*100\n","bbb46a71":"# print(accuracies.mean()*100-accuracies.std()*100,\n#       accuracies.mean()*100+accuracies.std()*100)\n","a6eb6cb4":"# (bootstrap=True, ccp_alpha=0.0, criterion='mse',\n#                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n#                       max_samples=None, min_impurity_decrease=0.0,\n#                       min_impurity_split=None, min_samples_leaf=1,\n#                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n#                       n_estimators=1000, n_jobs=None, oob_score=False,\n#                       random_state=0, verbose=0, warm_start=False)","e0f8187f":"# from sklearn.model_selection import GridSearchCV\n","e439e930":"# parameters = [{'n_estimators': [1, 10, 100, 1000,2000], 'max_depth': [10,15,50,100]}]\n","6ca95251":"\n# grid_search = GridSearchCV(estimator = reg,\n#                            param_grid = parameters,\n#                            scoring='neg_mean_squared_error',\n#                            cv = 10,\n#                            n_jobs = -1)\n","cbbcccbc":"\n# grid_search = grid_search.fit(xtrain, ytrain)\n","07c9f2f9":"\n# best_accuracy = grid_search.best_score_\n# best_parameters = grid_search.best_params_","7dcdb0d8":"# best_parameters","c27cf572":"from sklearn.preprocessing import StandardScaler as SS","3540c65e":"sc_x=SS()\nsc_y=SS()\n","2552e339":"xtrain.iloc[:,:]\n","d32e1514":"ytrain","bef35e69":"xtrain_SVR=sc_x.fit_transform(xtrain)\nxtest_SVR=sc_x.transform(xtest)\n","184ca5e0":"ytrain_SVR=sc_y.fit_transform(ytrain)\nytest_SVR=sc_y.transform(ytest)","c4d7f20a":"from sklearn.svm import SVR\nSVR_regressor=SVR(kernel='rbf') #Usually experiment with rbf 1st\nSVR_regressor.fit(xtrain_SVR,ytrain_SVR)","447e98a8":"SVR_regressor.predict(xtest_SVR)","6608c766":"SVR_xtest_prediction=sc_y.inverse_transform(SVR_regressor.predict(xtest_SVR))","3f76802e":"SVR_xtest_prediction","fea0128c":"SVR_xtrain_prediction=sc_y.inverse_transform(SVR_regressor.predict(xtrain_SVR))","e2e4b02e":"SVR_xtrain_prediction","27ada482":"ytest","13bae01f":"# # 1. Accuracy of SVR-----submit only svr pred too\n# 2. Which one is best\n# 3. Viz both w.r.t. to real answer\n# 4. Ensemble of both\n# 5. see what weights is good\n# 6. eval matrix","b8d1cb75":"import matplotlib.pyplot as plt","ffba380a":"plt.scatter(xtrain.index[0:1000],ytrain[0:1000])\nplt.scatter(xtrain.index[0:1000],SVR_xtrain_prediction[0:1000],color='red')\n# plt.scatter(xtrain.index[0:1000],reg.predict(xtrain)[0:1000],color='y')\n\n# ytest.plot(xtest.index,kind='scatter')","ca4d7934":"plt.scatter(xtrain.index[0:1000],ytrain[0:1000])\n# plt.scatter(xtrain.index[0:100],SVR_xtrain_prediction[0:100],color='red')\nplt.scatter(xtrain.index[0:1000],reg.predict(xtrain)[0:1000],color='yellow')","eefbcbda":"plt.scatter(xtrain.index[0:1000],SVR_xtrain_prediction[0:1000],color='red')\nplt.scatter(xtrain.index[0:1000],reg.predict(xtrain)[0:1000],color='yellow')","d084eaf9":"xtrain_ann,xtest_ann,ytrain_ann,ytest_ann=train_test_split(x_heatmap,df.iloc[:,-1],test_size=0.3,random_state=0)","a01366eb":"# xtrain_ann=xtrain_ann.drop(columns='Id')\n# xtrain_ann\n\n# xtest_ann=xtest_ann.drop(columns='Id')\n# xtest","37aa018f":"import tensorflow as tf","eb0f0fa1":"tf.__version__","2ebee0ff":"ann=tf.keras.models.Sequential() #Initialise the layer","03da1653":"ann.add(tf.keras.layers.Dense(units=69,activation='relu')) #1st Layer","9a30d22a":"ann.add(tf.keras.layers.Dense(units=69,activation='relu')) #2nd layer","b8ca6259":"ann.add(tf.keras.layers.Dense(units=1)) #O\/P layer----No activation function for last layer of regression","b3cc2b8d":"ann.compile(optimizer='adam',loss='mean_squared_error')","a12a5025":"ann.fit(xtrain_ann.values,ytrain_ann.values, batch_size=32, epochs=300)","e2f1a829":"ypred_ann=ann.predict(xtest_ann)","a00cb565":"ypred_ann.reshape(438,)","06b8a995":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n","265c18d0":"adaboost=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(),n_estimators=1000,learning_rate=0.1,random_state=20)","5866e82d":"adaboost.fit(xtrain,ytrain)","4140990b":"adaboost_xtest_prediction=adaboost.predict(xtest)","bcbd2aaf":"from sklearn.ensemble import GradientBoostingRegressor\n","30cf7789":"gradient= GradientBoostingRegressor(n_estimators=100)","d58a2d5c":"gradient","f7bd1de6":"\ngradient.fit(xtrain, ytrain)","b35f8af2":"gradient_xtest_prediction=gradient.predict(xtest)","f2150a23":"import xgboost as xgb\n","96d7ff6f":"xgboost=xgb.XGBRegressor()","64233378":"xgboost.fit(xtrain,ytrain)","a6e98916":"xgboost_xtest_prediction=xgboost.predict(xtest)","044013c3":"( 0.2* xgboost.predict(xtest)+ 0.5* reg.predict(xtest)+ 0.2* gradient.predict(xtest)+\n    0.2* adaboost.predict(xtest)+0.2*ann.predict(xtest).reshape(438,)).shape","696150cb":"xtest.shape[0]","5c8e46ce":"def all_pred(xtest):\n    r1=xtest.shape[0]\n    return(\n   0.3* xgboost.predict(xtest)+\n    0.2* gradient.predict(xtest)+\n    0.2* adaboost.predict(xtest)+\n    0.2* reg.predict(xtest)+\n    0.1*ann.predict(xtest).reshape(r1,))\n    ","6d91a9ae":"blend=all_pred(xtest)","6218fd3b":"blend.shape","291f778f":"from sklearn.model_selection import GridSearchCV","a798ebee":"params=[{'learning_rate':[0.1,0.5,1],\n         'gamma':[0.1,0.5,1],\n         'n_estimator':[10,50,100],\n         'max_depth':[2,6,8,12],\n         'min_child_weight':[1,3,5,7]}]","2fe45838":"grid_search = GridSearchCV(estimator = xgboost,\n                           param_grid = params,\n                           scoring='neg_mean_squared_error',\n                           cv = 10,\n                           n_jobs = -1)\n","12808e08":"grid_search = grid_search.fit(xtrain, ytrain)\n","993cb8c6":"best_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_","805a1ca7":"print(best_accuracy,best_parameters)","5ce1b79f":"xgboost=xgb.XGBRegressor(gamma= 0.1, learning_rate=0.1, max_depth= 6, min_child_weight= 3, n_estimator= 10)","e1470fa1":"xgboost.fit(xtrain,ytrain)","47f5a9f6":"xgboost_xtest_prediction=xgboost.predict(xtest)\nxgboost_xtest_prediction.shape","1e6daa64":"from sklearn.metrics import mean_absolute_error\n","cf244806":"mean_absolute_error(ytest,blend)","d812dac8":"from sklearn.metrics import mean_squared_error\nmean_squared_error(ytest, blend)","0e415808":"90,58,03,841\n1,46,62,19,706\n71,08,80,528\n73,49,95,111\n2,45,30,67,944\n74,86,54,667\n71,77,82,987","fe63333d":"(xgboost.predict(c_test_heatmap))","c3037eea":"xgboost_ypred=xgboost.predict(c_test_heatmap).astype(int)","57b49330":"all_pred(c_test_heatmap).astype(int)","2e15c8c3":"blend_final=all_pred(c_test_heatmap).astype(int)","f40d865d":"sc_y.inverse_transform(SVR_regressor.predict(sc_x.transform(c_test_heatmap)))","d3244004":"SVR_final_pred=sc_y.inverse_transform(SVR_regressor.predict(sc_x.transform(c_test_heatmap)))","76180a18":"ypred_ann_sub=ann.predict(c_test_heatmap)\nypred_ann_sub.shape","f005c3ac":"asd=[]\nfor i in range(len(ypred_ann_sub)):\n    asd.append(ypred_ann_sub[i][0])\n# asd=(ypred_ann)\n","74d5a626":"asd","55e51f08":"dfd = pd.DataFrame(asd, columns = ['SalePrice'])\ndfd\n","e375a406":"p1=pd.DataFrame({'Id':c_test.Id.values})\np1","59fa740b":"p1=p1.join(dfd)\np1","44c171ad":"p2= pd.DataFrame({'Id':c_test.Id.values,'SalePrice': blend_final})","ae0fc5da":"p2","c791a355":"p2['SalePrice'].value_counts()","e7545df5":"p2.to_csv('house_blend_5_per.csv',index=False)","f03412b9":"# Even after trying 1000 trees instead of 100 trees, only 6 jump up in leaderboard. Hence i think, data cleaning is required more.","f609f3f6":"# After few trys , i saw that taking very less fetures is results in bad score.","aeec97a4":"x[\"Condition1\"].value_counts()\n# 1260\/1460= 86%","ca1563bd":"x[\"Condition2\"].value_counts()\n# 1445\/1460= 98%","ebe03db7":"z=pd.DataFrame(x[['Condition1','Condition2']])\nz","2c1af37f":"# z['C'] = [(set(a) & set(b)) for a, b in zip(df.Condition1, df.Condition1) ]","3d5a060e":"z","cd449f6d":"x[\"Exterior1st\"].value_counts()\n","9c146603":"x[\"Exterior2nd\"].value_counts()\n","f92696af":"y.plot(kind='kde')","ca29ea4d":"y.plot(kind='hist')","dfdb6fb5":"# sns.set_style(\"white\") #Background color:- white, dark,etc.\n# sns.set_color_codes(palette='deep') #Color user chooses\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(y, color=\"b\");\n# ax.grid(True)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice distribution\")\n# sns.despine(trim=True, left=True) #Removes lines of boxes in which image is plotted\nplt.show()","079de731":"# sns.set_style(\"white\")\n# sns.set_color_codes(palette='coolwarm')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(y);\n# ax.grid(True)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","8b1647fe":"y.skew(), y.kurt()","62d3f722":"y=np.log1p(y) #or np.log(y + 1) ","5046c761":"from scipy.stats import norm #Ideal normal distribution curve","89de0665":"sns.set_style(\"white\")\n\nf, ax = plt.subplots(figsize=(8, 7))\n\nsns.distplot(y,fit=norm);\n(mu, sigma) = norm.fit(y)\nprint(mu,sigma) #mu is mean\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","3e0c53ee":"y.describe()","a722d8ad":"x['OverallQual'].plot(kind='hist')","6221dba4":"y.describe()","dc0f72fd":"df['SalePrice']","231ed26b":"x[(x['OverallQual']<5) & (df['SalePrice']>200000)].index","79187429":"x[(x['GrLivArea']>4500) & (df['SalePrice']>30000)].index","78ac0ace":"plt.scatter(x['OverallQual'],df['SalePrice'])","28550b15":"plt.scatter(x['GrLivArea'],df['SalePrice'])\nplt.scatter(x=4500, y=300000, color='r')\nplt.scatter(x=4676, y=184750, color='y')\nplt.scatter(x=5642, y=160000, color='g')\n","750d73ea":"a=df[x['GrLivArea']>4500]\n# a['GrLivArea']\na","b0914440":"def percent_missing(df):\n    data = pd.DataFrame(df)\n    df_cols = list(pd.DataFrame(data)) #List of Columns of dataframe named 'data'\n    dict_x = {}\n    for i in range(0, len(df_cols)):\n        dict_x.update({df_cols[i]: round(data[df_cols[i]].isnull().mean()*100,2)}) #Make dictionary of missing columns as key and percentage (upto 2 decimal places rounded up ) as value\n    \n    return dict_x","4baed33c":"\nmissing = percent_missing(missing_df)\ndf_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)# lambda x:x[1] i.e. sorting acc. to second parameter i.e. percentage of missing values\nprint('Percent of missing data')\ndf_miss","ab3372fe":"sns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(8, 7))\nsns.set_color_codes(palette='deep')\nmissing = round(missing_df.isnull().mean()*100,2)\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar(color=\"b\")\n# Tweak the visual presentation\nax.grid(True)\nax.set(ylabel=\"Percent of missing values\")\nax.set(xlabel=\"Features\")\nax.set(title=\"Percent missing data by feature\")\nsns.despine(trim=True, left=True)","75732c2e":"# df['MoSold']\n# all_features['YrSold']\n# all_features['MoSold']","fbb427bc":"df['MSZoning'].mode()","cf145787":"x['MSZoning'].plot(kind='hist')","3130aefd":"df['PoolQC'].value_counts()","ac556fc9":"df[df['GarageCars']==0]","1ebc1fc2":"(df[df['GarageYrBlt'].isnull()]).index","e62878f0":"(df[df['GarageArea']==0]).index","5afc7e83":"df.loc[[39],[\"GarageYrBlt\"]]","3948f92f":"# df[df['GarageYrBlt'].isnull()==True]","b6d9c588":"df['GarageYrBlt'].mean()","c26ea3db":"df.loc[:,['GarageQual', 'GarageCond']]","1a362a3f":"# df['GarageQual'].value_counts()\n(df[df['GarageQual'].isnull()]).index","7c8d2e22":"# df['GarageCond'].value_counts()\n(df[df['GarageCond'].isnull()]).index","6bf74429":"df['GarageType'].value_counts()\n(df[df['GarageType'].isnull()]).index","bbd8d9fb":"df['GarageFinish'].value_counts()\n(df[df['GarageFinish'].isnull()]).index","af9518fb":"df.loc[:,['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']]","52586633":"df['BsmtQual'].value_counts()\n(df[df['BsmtQual'].isnull()]).index","96638f08":"df['BsmtCond'].value_counts()\n(df[df['BsmtCond'].isnull()]).index","7d1810a8":"df['BsmtExposure'].value_counts()\n(df[df['BsmtExposure'].isnull()]).index","c1482337":"df['BsmtFinType1'].value_counts()\n(df[df['BsmtFinType1'].isnull()]).index","499cbe4a":"df['BsmtFinType2'].value_counts()\n(df[df['BsmtFinType2'].isnull()]).index","dfe8ea87":"df.loc[:,['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']]","6ef8c039":"def handle_missing(features):\n#     # the data description states that NA refers to typical ('Typ') values\n#     features['Functional'] = features['Functional'].fillna('Typ')\n#     # Replace the missing values in each of the columns below with their mode\n#     features['Electrical'] = features['Electrical'].fillna(\"SBrkr\")\n#     features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\")\n#     features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0])\n#     features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n#     features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n    features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n#     ---------->No logic\n\n    # the data description stats that NA refers to \"No Pool\"-------------------------------->No logic\n    features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n    \n  *  # Replacing the missing values with 0, since no garage (i.e. 'GarageArea'=0) = no cars in garage\n# GarageYrBlt is missing for GarageArea=0.\n#     for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n#         features[col] = features[col].fillna(0)\n        \n    # Replacing the missing values with None------------------------------------------------->No logic\n    for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n        features[col] = features[col].fillna('None')\n        \n    # NaN values for these categorical basement features, means there's no basement---------->No logic\n    for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n        features[col] = features[col].fillna('None')\n        \n    # Group the by neighborhoods, and fill in missing value by the median LotFrontage of the neighborhood---------->No logic\n    features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\n    # We have no particular intuition around how to fill in the rest of the categorical features\n    # So we replace their missing values with None\n    objects = []\n    for i in features.columns:\n        if features[i].dtype == object:\n            objects.append(i)\n    features.update(features[objects].fillna('None'))\n        \n    # And we do the same thing for numerical features, but this time with 0s\n    numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    numeric = []\n    for i in features.columns:\n        if features[i].dtype in numeric_dtypes:\n            numeric.append(i)\n    features.update(features[numeric].fillna(0))    \n    return features\n\nall_features = handle_missing(all_features)","ec60585e":"numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumeric = []\nfor i in df.columns:\n    if df[i].dtype in numeric_dtypes:\n        numeric.append(i)","5e17c61d":"from scipy.stats import skew","9d1a4991":"# Find skewed numerical features\nskew_features = df[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nprint(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\nskewness = pd.DataFrame({'Skew' :high_skew})\nskew_features","b51bb56d":"len(numeric)\n# numeric.remove('SalePrice')","2a6c7645":"# df['Utilities'].plot(kind='box')\n# Create box plots for all numeric features\nsns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(8, 7))\nax.set_xscale(\"log\") #For scaling x-axis\nax = sns.boxplot(data=df[numeric] , orient=\"h\", palette=\"Set1\")\n# ax.xaxis.grid(False)\n# ax.set(ylabel=\"Feature names\")\n# ax.set(xlabel=\"Numeric values\")\n# ax.set(title=\"Numeric Distribution of Features\")\n# sns.despine(trim=True, left=True)","7e8d1675":"from scipy.special import boxcox1p\nfor i in skew_index:\n    missing_df[i] = boxcox1p(missing_df[i], boxcox_normmax(all_features[i] + 1))","c77081cd":"z=pd.DataFrame()","50f29995":"z['BsmtFinType1_Unf'] = 1*(df['BsmtFinType1'] == 'Unf')","2a078af0":"df['BsmtFinType1']\n","47ca2c83":"df['BsmtFinType1'].value_counts()","5e230619":"df['BsmtFinType1']\nz","90ac73bb":"df['Street'].value_counts()","1b83b979":"df.loc[:,['OverallQual','OverallCond']]\n# df['YearRemodAdd'].value_counts()","237980e3":"df['TotalBsmtSF'].apply(lambda x: np.exp(6) if x <= 0.0 else x)","5579ab1e":"df[df['TotalBsmtSF']<0]","6c68c692":"df['TotalBsmtSF']","492cd925":"all_features['BsmtFinType1_Unf'] = 1*(all_features['BsmtFinType1'] == 'Unf')\nall_features['HasWoodDeck'] = (all_features['WoodDeckSF'] == 0) * 1\nall_features['HasOpenPorch'] = (all_features['OpenPorchSF'] == 0) * 1\n\nall_features['HasEnclosedPorch'] = (all_features['EnclosedPorch'] == 0) * 1\nall_features['Has3SsnPorch'] = (all_features['3SsnPorch'] == 0) * 1\nall_features['HasScreenPorch'] = (all_features['ScreenPorch'] == 0) * 1\n\n#******************************************#\nall_features['YearsSinceRemodel'] = all_features['YrSold'].astype(int) - all_features['YearRemodAdd'].astype(int)\nall_features['Total_Home_Quality'] = all_features['OverallQual'] + all_features['OverallCond']\nall_features = all_features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)#Logical to drop as all same values in cols\n\nall_features['TotalSF'] = all_features['TotalBsmtSF'] + all_features['1stFlrSF'] + all_features['2ndFlrSF']\nall_features['YrBltAndRemod'] = all_features['YearBuilt'] + all_features['YearRemodAdd']\n\nall_features['Total_sqr_footage'] = (all_features['BsmtFinSF1'] + all_features['BsmtFinSF2'] +\n                                 all_features['1stFlrSF'] + all_features['2ndFlrSF']) # See \n\nall_features['Total_Bathrooms'] = (all_features['FullBath'] + (0.5 * all_features['HalfBath']) +\n                               all_features['BsmtFullBath'] + (0.5 * all_features['BsmtHalfBath']))\n\nall_features['Total_porch_sf'] = (all_features['OpenPorchSF'] + all_features['3SsnPorch'] +\n                              all_features['EnclosedPorch'] + all_features['ScreenPorch'] +\n                              all_features['WoodDeckSF'])\n#****************************************#\n# WTH IS THIS\nall_features['TotalBsmtSF'] = all_features['TotalBsmtSF'].apply(lambda x: np.exp(6) if x <= 0.0 else x)\nall_features['2ndFlrSF'] = all_features['2ndFlrSF'].apply(lambda x: np.exp(6.5) if x <= 0.0 else x)\nall_features['GarageArea'] = all_features['GarageArea'].apply(lambda x: np.exp(6) if x <= 0.0 else x)\nall_features['GarageCars'] = all_features['GarageCars'].apply(lambda x: 0 if x <= 0.0 else x)\nall_features['LotFrontage'] = all_features['LotFrontage'].apply(lambda x: np.exp(4.2) if x <= 0.0 else x)\nall_features['MasVnrArea'] = all_features['MasVnrArea'].apply(lambda x: np.exp(4) if x <= 0.0 else x)\nall_features['BsmtFinSF1'] = all_features['BsmtFinSF1'].apply(lambda x: np.exp(6.5) if x <= 0.0 else x)\n\nall_features['haspool'] = all_features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\nall_features['has2ndfloor'] = all_features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nall_features['hasgarage'] = all_features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nall_features['hasbsmt'] = all_features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nall_features['hasfireplace'] = all_features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","8d71dda3":"df = pd.get_dummies(df).reset_index(drop=True)\ndf.shape\n","1dedf820":"df","261e9f9f":"# Testing on test data","00c9de95":"Exterior1st and Exterior2nd columns seems almost same.Majority of them are same. But intersection should be same too.It may happen that different rows are same and not same rows.  ","01eb4b3c":"# **<u>4. AdaBoost<\/u>**","be87ffa3":"# Handling skewed data by applying log(x+1). +1 as,if zero present thrn error.","e68c299b":"<!-- ## K-fold cross validation -->","0c90057e":"# **<u>5. Gradient Boost<\/u>**","32f42d75":"# Adaboost + D.T.:\n1. 36 features are selected\n        1. Absolute-ERROR:- 16,448\n        2. MSE:-71,08,80,528\n        Absolute Error decreased , but MSE increased as compared to RandomFore","bd937a6d":"mean and mode is same for GarageYrBlt and LotFRONTage. SO filling them by mean. THe data seems normally distributed","7e718b16":"# Some Missing values in test data","53c9ea8b":"# Questions:\n1. deal with positively skewed data\n2. handling bimodal distribution\n3. kurtosis?- i think length of tail\n4. https:\/\/towardsdatascience.com\/transforming-skewed-data-73da4c2d0d16\n5. \n6. **how does standard deviation affect data analysis?**\n7. https:\/\/towardsdatascience.com\/exploring-normal-distribution-with-jupyter-notebook-3645ec2d83f8\n8. ","caf03dd4":"# **<u>2.SVM<\/u>**","fff63cdf":"### Again check skewness\/ apply log, sq transformations...........see kernel","a2d972b1":"# Submission file","e30b56ce":"## SVR","84fb8395":"# **<u>3. ANN<\/u>**","6421deb7":"# Finding skewed columns","50ea02d8":"## ANN","2fec5617":"## Don;t know how to find outliers\nhttps:\/\/towardsdatascience.com\/ways-to-detect-and-remove-the-outliers-404d16608dba\nSee when to apply scatter( both continuous, or categorical?)\nSeebox plots","925576ab":"# SVR:\n1. 36 features are selected\n        1. Absolute-ERROR:- 18,740\n        2. MSE:-1,46,62,19,706\n        Absolute Error decreased , but MSE increased as compared to RandomForest\n","8b0b49f0":"<!-- ### Q)grid search for random forest regression\/ types of hyperparameter tuning -->","03d7e21b":"<!-- ## Grid Search -->","1ce15671":"### Same indices are missing.So it means that if area=0, those coln are missing.","f4008200":"## Label Encoding these","824ff0ba":"# Label Encoder of Train and test:-\n","26fccfe5":"## As of now simply encoding. Later try giving more rank to excellent  Then see o\/p. Similarly assign less rank to excell.","d4bb1c9c":"# Learning from others kernels","3e17e059":"# <u>**Teaser:- Hyperparam of XgBoost gave me Best place on leaderboard**","e09982b7":"# Train data of these columns used for label encoding","3be3e053":"<!-- ### Q)can k-fold cross validation be applied to regression -->","ad522f4b":"# **<u>6. XgBoost<\/u>**","d9822050":"2 outliers.   \n## coordinates of point on scatter plot seaborn?","c7e540f2":"## Now label encoding","1a0021c3":"### Q)when to use only fit and fit_transform? Only fit used below?","811240c6":"[Hyperparameter tuning of Gradient Boosting](https:\/\/medium.com\/all-things-ai\/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae)","97eabbd4":"### Applying box--cox1 transformation:   \nhttps:\/\/www.youtube.com\/watch?v=2gVA3TudAXI   \nhttps:\/\/medium.com\/@ODSC\/transforming-skewed-data-for-machine-learning-90e6cc364b0   \nhttps:\/\/medium.com\/@ronakchhatbar\/box-cox-transformation-cba8263c5206","db76fa44":"### Q) Ways to evaluate a model","da4017e9":"### Hyperparam of XgBoost","1e41ec8c":"## For test data","b7c8b4b2":"again find skewness after transformation","6cebec97":"# **<u>3.Feature Importance<\/u>**","536c4f3b":"Some of the non-numeric predictors are stored as numbers; convert them into strings ","3f1eff12":"# Vizualation after performing algos.","c24d824b":"## Imputer","27440761":"## GarageYrBlt column should be replaced by 0 not mean.","88a2b519":"# 6 Algos used are:-\n1. RandomForest\n2. SVM\n3. ANN\n4. AdaBoost\n5. Gradient Boost\n6. XgBoost \n\nEnsemble technique added\n\nIf you like it , please upvote & fork it. Keep learning , Keep Sharing:-)\n(Wait for more intresting insights like ensemble techniques, proper functions.)\n","f1521b37":"Boxplot:-   \nhttps:\/\/medium.com\/dayem-siddiqui\/understanding-and-interpreting-box-plots-d07aab9d1b6c\nhttps:\/\/towardsdatascience.com\/understanding-boxplots-5e2df7bcbd51","afbebc6b":"## Test data","21555ec7":"# DF for ANN","91de8b21":"# Ensemble- Blending","c5919dc3":"# how does standard deviation\/sigma affect data analysis?","6f990553":"## I now want to drop similar columns by looking at the data.But unable to find intersection between columns.","945abbda":"## Filling missing values.","12485cff":"# **<u> Using Heatmap<\/u>**","870d5eed":"### Before applying SVR, Scaling needs to be done......\n<!-- ## Q) Various types of scalar are there. See which is best? -->","f95371f6":"# One error according to me is label encoding too many columns.","085f17bd":"# Evaluation:\n1. All 70 columns after pre-processing:\n    a. n-estimator=1000\n        1. Absolute-ERROR:- 16,989 \n        2. MSE:- 87,41,82,817\n     ## Leaderboard RMSE:-0.47\n\n# <u> Heatmap:- <\/u>\n2. Selecting 47 columns from heatmap using pearson correlation--- (columns with corr>0 taken only)\n    a. n-estimator=1000\n        1. Absolute-ERROR:- 17207 \n        2. MSE:- 87,87,95,851\n      ## Error actually increased on xtest data. But predictions on C_Test Data gave error as 0.1513\n3. Selecting 47+'Id' columns from heatmap using pearson correlation\n    a. n-estimator=1000\n        1. Absolute-ERROR:- 17350 \n        2. MSE:- 88,88,11,105     \n4. Selecting 31 columns from heatmap using pearson correlation-- (columns with corr>40 taken only)  \n\n       a. n-estimator=1000\n            1. Absolute-ERROR:- 17112 \n            2. MSE:- 85,35,55,830 \n        \n        \n         b. n_estimators=10k  \n      \n            1. Absolute-ERROR:-17,102\n            2. MSE:- 84,61,60,610\n   \n36 columns selected.n_estimators=2k, max_depth=15   \n            1. Absolute-ERROR:-17,115   \n            2. MSE:- 84,25,83,579","1a4f9c76":"## Fitting for test data also","fb646047":"# **<u>1.Random Forests<\/u>**","409fbbb2":"The data is right skewed. It may not affect tree-based models but then we can't use other models. Hence to make it normal distribution, we apply Log transformation.\n","0e43255b":"### From viz. it seems svr performs better only for lower values. RF for both.\nIf value >350000 then use rf. See error for value less than this","69751e30":"# Missing value function","c89c1ccf":"<!-- # **<u> 1.Using Univariate Selection<\/u>** -->","1ce12224":"# Train,test,split:-","98991d85":"## Test data","6dc749af":"# Q)RandmoizedSearchCV vs GridSearchCV","fbdf0547":"## Dropping columns with missing values >= 20%","3c71f19a":"# These are Outliers","fea2eba5":"<!-- #### Types of scoring in grid? -->","0169de2c":"1. Feature Selection\n2. Feature Scaling\n3. Feature Engineering\n4. Normization vs Standardization\n5. Bell curves.\n6. Probab. density function\n7. z score for outliers."}}