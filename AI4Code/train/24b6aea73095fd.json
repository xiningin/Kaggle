{"cell_type":{"286cc2c9":"code","5ab6fbd2":"code","d1fe0125":"code","cd8697ff":"code","e44650d2":"code","84372f4d":"code","254c7142":"code","22443ef4":"code","b41e1a32":"code","7c3aef24":"code","d560d0b4":"code","21df7620":"code","27c0d44e":"markdown","7b857083":"markdown","07692684":"markdown","c2d42b62":"markdown","10f5bf5d":"markdown","2a0d652d":"markdown","ac221ffd":"markdown","20e9e5a9":"markdown","4bd7b41e":"markdown","92c2e984":"markdown","d66491c4":"markdown","9976ed65":"markdown","21870848":"markdown","6d43a626":"markdown","cdb9d181":"markdown","c0ca9357":"markdown","4dc0f1f4":"markdown","2de73b17":"markdown"},"source":{"286cc2c9":"import os\nimport warnings\nimport numpy as np\nimport pylab as pl\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.cm as cm\nfrom keras import backend as K\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.datasets import fashion_mnist\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten","5ab6fbd2":"warnings.simplefilter(\"ignore\")\n(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()","d1fe0125":"nb_classes = 10\nsize = 28\nchannels = 1\nclass_names = ['tshirt','trouser','pullover', 'dress', 'coat','sandal', 'shirt','sneaker','bag','boot']\n\ndef prepare_data(X, size, channels):\n    X = X.reshape(X.shape[0], size, size, channels)\n    X = X.astype(\"float32\")\n    return X\/255.\n\nX_train = prepare_data(X_train, size, channels)\nX_test = prepare_data(X_test, size, channels)\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)","cd8697ff":"print(\"x_train size:\", X_train.shape, \n      \"\\n\", \"x_test size:\", X_test.shape, \n      \"\\n\", \"y_train size:\", Y_train.shape, \n      \"\\n\",\"y_test size:\", Y_test.shape)","e44650d2":"i = 2\nfor i in range(25):\n    pl.imshow(X_train[i, :, :, ],\n              interpolation='nearest',\n              cmap=cm.binary)\nplt.show()","84372f4d":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape=(\n    size, size, channels), kernel_initializer='he_uniform', padding='same'))\nconvout1 = Activation('relu')\nmodel.add(convout1)\nmodel.add(Conv2D(32, (3, 3), activation='relu',\n          kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu',\n          kernel_initializer='he_uniform', padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='relu',\n          kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128, (3, 3), activation='relu',\n          kernel_initializer='he_uniform', padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='relu',\n          kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nD1 = (Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(D1)\nD2 = (Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(D2)\nmodel.add(Dense(10, activation='softmax'))","254c7142":"opt = SGD(lr=0.001, momentum=0.9)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy',\n              metrics=['accuracy'])","22443ef4":"model.summary()","b41e1a32":"model.fit(X_train, Y_train,\n          batch_size=32,\n          epochs=50,\n          verbose=1,\n          validation_data=(X_test, Y_test))\nscore = model.evaluate(X_test,\n                       Y_test,\n                       verbose=0)","7c3aef24":"print('Test score:', score[0])\nprint('Test accuracy:', score[1])","d560d0b4":"y_pred = np.argmax(model.predict(X_test), axis=1)\nsns.heatmap(confusion_matrix(y_test, y_pred), cmap='Greys', annot=True)\nplt.title('Confusion Matrix')","21df7620":"print(classification_report(y_test, y_pred))","27c0d44e":"## Compiling the model","7b857083":"## Importing the dataset","07692684":"The value of each pixel is in the range of [0,255], just like CIFAR10 and MNIST datasets.\n\nThe Normalization and reshaping process included.","c2d42b62":"<p style = \"text-shadow: 12px 12px 2px #333;color:brown;font-family:Segoe Print;font-weight:bold\" > If you have any doubts or idea, please leave a comment.<\/p>","10f5bf5d":"# Modeling","2a0d652d":"## Model summary","ac221ffd":"Regarding this dataset, I used 32 as for batching to achieve better accuracy. And set the **epochs** to **50**.","20e9e5a9":"# Importing libraries","4bd7b41e":"For different convolutional layers, I imported them from the core repository of the TensorFlow. As you may be noticed I imported SGD which brings a stochastic gradient approach for updating the weights of the layers.\n\nRegarding the plotting, you may use the pylab library without any problem.","92c2e984":"# About this notebook\n\nIn this notebook, I trained the Convolutional Neural Network over the Fashion MNIST dataset. To build the Convolutional model, I used the TensorFlow library and built the layer in the order which I know has the best performance. I decided to use this model structure because I ran different structures and had the results of previous experiments.\n\n\n<img src= \"https:\/\/d2908q01vomqb2.cloudfront.net\/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59\/2018\/05\/04\/ImagesSageMaker3.png\" alt =\"Titanic\" style='width: 300px;' class=\"center\">\n\n\n***This work is updating every day. ===> 25% Progress.***\n\n* Last update: 07.Jul.2021","d66491c4":"For this model, I have two convolutional layers, with 2D max Pooling, following by two more 2d-64 convolutional layers and the same pooling layer and 128 convolutional layers which supported by two dense layers. \n\nThe solver or optimizer is stochastic gradient descent. Different solvers have different convergence rates and training speeds. You may also need to change it based on your problem.","9976ed65":"# Dataset","21870848":"I downloaded the Fashion MNIST Dataset directly from the TensorFlow library.","6d43a626":"## Build the layers","cdb9d181":"## Exploring the dataset","c0ca9357":"## Preprocess the data","4dc0f1f4":"## Compile","2de73b17":"Here we defined the optimizer, which we imported directly and the model compile."}}