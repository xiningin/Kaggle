{"cell_type":{"5aafc7a5":"code","6dd72d33":"code","c24571a8":"code","aba0c448":"code","04ee6f98":"code","1123d867":"code","61f2e206":"code","554e8178":"code","e3015a5f":"code","4066db21":"code","293a4d49":"code","c3763c68":"code","45716dc7":"code","61b58649":"code","63e38b4b":"code","f84bf15a":"code","6cf53532":"code","c16ae7f1":"code","d7733fd7":"code","aa14bd66":"code","d3d85afb":"code","6d209437":"code","b7c4fb27":"code","89784a12":"code","b7950831":"code","1878a6d4":"markdown","5ca1bd25":"markdown","68cbf023":"markdown","42e1bfb6":"markdown","088c4512":"markdown","b11ea2d9":"markdown","e0f08d5f":"markdown"},"source":{"5aafc7a5":"import datetime as dt\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nsns.set_style('whitegrid')\n\n\nimport os\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nfrom scipy.stats import uniform\n\nfrom tqdm import tqdm\nfrom glob import glob\n\n\nfrom keras.models import Model, Sequential\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Masking\nfrom keras.utils import np_utils, to_categorical\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n","6dd72d33":"#copying the pretrained models to the cache directory\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n\n#copy the Xception models\n!cp ..\/input\/keras-pretrained-models\/xception* ~\/.keras\/models\/\n#show\n!ls ~\/.keras\/models","c24571a8":"base_folder = '..\/input\/plant-seedlings-classification'\ntrain_data_folder = os.path.join(base_folder, 'train')\n\n#get the plant categories\ncategories = os.listdir(train_data_folder)\nabbreviations = ['LSB', 'SP', 'FH', 'Ch', 'SB', 'Ma', 'CW', 'Cl', 'BG', 'SFC', 'SM', 'CC']\nlen_categories = len(categories)\n","aba0c448":"#read the images from train folder\nimage_count = {}\ntrain_data = []\nfor i, plant in tqdm(enumerate(categories)):\n    plant_folder_name = os.path.join(train_data_folder, plant)\n    plant_name = plant\n    image_count[plant] = []\n    for path in os.listdir(os.path.join(plant_folder_name)):\n        image_count[plant].append(plant)\n        train_data.append(['train\/{}\/{}'.format(plant, path), i, plant])\n#create a dataframe\ntrain_img = pd.DataFrame(train_data, columns=['filepath', 'id', 'class'])","04ee6f98":"#read the images from test folder\n\ntest_data = []\n\nfor file in os.listdir('..\/input\/plant-seedlings-classification\/test'):\n    test_data.append(['test\/{}'.format(file), file])\ntest_data = pd.DataFrame(test_data, columns=['filepath', 'filename'])\n\nprint('SHAPE OF TEST DATA: ', test_data.shape)\n#show dataframe\ntest_data.head()","1123d867":"#show image count per class\nfor key,value in image_count.items():\n    print(\"{0} -> {1} images\".format(key, len(value)))","61f2e206":"#show dataframe\ntrain_img.head()","554e8178":"#show number of images\ntrain_img.shape[0]","e3015a5f":"#get image samples per class and label them as traning data\nsample_per_class = 200\ntrain_data = pd.concat(train_img[train_img['class']==label][:sample_per_class] for label in categories ).sample(frac=1)\n#rest the index\ntrain_data.index = np.arange(train_data.shape[0])","4066db21":"# function to get an image\ndef read_img(filepath, size):\n    img = image.load_img(os.path.join(base_folder, filepath), target_size=size)\n    #convert image to array\n    img = image.img_to_array(img)\n    return img","293a4d49":"#show sample images\nnb_rows = 5\nnb_cols = 5\nfig, axs = plt.subplots(nb_rows, nb_cols, figsize=(10, 10))\nplt.suptitle('SAMPLE IMAGES')\nfor i in range(0, nb_rows):\n    for j in range(0, nb_cols):\n        axs[i, j].xaxis.set_ticklabels([])\n        axs[i, j].yaxis.set_ticklabels([])\n        axs[i, j].imshow((read_img(train_data['filepath'][np.random.randint(100)], (224,224)))\/255.)","c3763c68":"INPUT_SIZE = 255\nX_train  = np.zeros((len(train_data), INPUT_SIZE, INPUT_SIZE, train_data.shape[1]), dtype='float')\n\nfor i, file in tqdm(enumerate(train_data['filepath'])):\n    img = read_img(file, (INPUT_SIZE, INPUT_SIZE))\n    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n    X_train[i] = x","45716dc7":"print('Train Image Shape: ', X_train.shape)\nprint('Train Image Size: ', X_train.size)","61b58649":"y = to_categorical(train_data['id'])\ntrain_x, train_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=101)","63e38b4b":"xception_b  = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\nbf_train_x = xception_b.predict(train_x, batch_size=32, verbose=1)\nbf_train_val = xception_b.predict(train_val, batch_size=32, verbose=1)","f84bf15a":"print('TRAIN DATA SHAPE: ', bf_train_x.shape)\nprint('TRAIN DATA SIZE: ', bf_train_x.size)\nprint('VALIDATION DATA SHAPE: ', bf_train_val.shape)\nprint('VALIDATION DATA SIZE: ', bf_train_val.size)","6cf53532":"#keras Sequential model\nmodel = Sequential()\nmodel.add(Dense(units = 256 , activation = 'relu', input_dim=bf_train_x.shape[1]))\nmodel.add(Dense(units = 64 , activation = 'relu'))\nmodel.add(Dense(units = len_categories, activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","c16ae7f1":"#train the model @ 100 epochs\nhistory = model.fit(bf_train_x, y_train, epochs=200, batch_size=32)","d7733fd7":"fig, ax = plt.subplots(1,2,figsize=(14,5))\nax[0].set_title('TRAINING LOSS')\nax[1].set_title('TRAINING ACCURACY')\n\n\nax[0].plot(history.history['loss'], color= 'salmon',lw=2)\nax[1].plot(history.history['accuracy'], color= 'green',lw=2)","aa14bd66":"#predict the validation data\npredictions = model.predict_classes(bf_train_val)\ny_true = y_val.argmax(1)","d3d85afb":"#print classification report\nprint(classification_report(y_true, predictions))","6d209437":"#confusion matrix\ncon_mat = confusion_matrix(y_true, predictions)\n\nplt.figure(figsize=(15,10))\nplt.title('CONFUSION MATRIX', fontsize=20)\n\nsns.heatmap(con_mat, cmap='coolwarm', yticklabels=abbreviations, xticklabels=abbreviations, annot=True)\nplt.xlabel('True Class')\nplt.ylabel('Predicted Class')\n\nplt.savefig('Confusion Matrix.png', dpi=480)","b7c4fb27":"X_test = np.zeros((len(test_data), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, filepath in tqdm(enumerate(test_data['filepath'])):\n    img = read_img(filepath, (INPUT_SIZE, INPUT_SIZE))\n    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n    X_test[i] = x","89784a12":"bf_test = xception_b.predict(X_test, batch_size=32, verbose=1)\ntest_prediction = model.predict_classes(bf_test)","b7950831":"submission = pd.DataFrame(columns=['file', 'species'])\nsubmission['file'] = test_data['filename']\nsubmission['species'] = [categories[i] for i in test_prediction]\n\nsubmission.to_csv('submission.csv', index=False)","1878a6d4":"#### SPLIT THE DATA","5ca1bd25":"### PREDICTIVE MODELLING","68cbf023":"### SUBMISSION","42e1bfb6":"### XCEPTION FEATURE EXTRACTION","088c4512":"## OVERVIEW\n---\n* Image Preprocessing\n* Transfer Learning with Pretrained models\n* Bottleneck Feature Extraction\n* Deep Learning Model","b11ea2d9":"#### TRAINING LOSS AND ACCURACY","e0f08d5f":"### SHOW SAMPLE IMAGE"}}