{"cell_type":{"ec278f42":"code","cdaa1aeb":"code","21602b39":"code","fdc89e52":"code","cd248739":"code","1e9bf0b1":"code","b041bc69":"code","5843338c":"code","5357d78e":"code","8717bd08":"code","526fe592":"code","c1fa9fa0":"code","c24d15b0":"code","6c2dc23c":"code","d5eb87b8":"code","30a342a1":"code","4e809239":"code","66f23182":"code","a873e34b":"code","2664bd0d":"code","7ff707eb":"code","0aee1570":"code","a8b7ae37":"code","1d768c95":"code","832e30b8":"code","24c760c6":"code","0bc30c0d":"code","c194ef89":"code","1cf73c6a":"code","960e3acc":"code","d131d3eb":"code","2baa760c":"code","df87d116":"code","976ea9bc":"code","f5284cf4":"code","9fd4df88":"code","c40d1914":"code","ca759014":"code","f375e901":"code","2ebebc29":"code","296058f5":"code","2417c95f":"code","e9c916d1":"code","26b66284":"code","4111d84c":"code","70265b26":"code","870738da":"code","57cd2c56":"code","55b60e4c":"code","330da4d5":"code","88b23609":"code","b007c417":"code","a82e0dc1":"code","4c332f00":"code","92fbdd20":"code","4c05d14d":"code","bac78d5b":"code","03142dcc":"code","93f583b5":"code","2a638a21":"code","cc41c895":"code","c3d50d14":"code","c20c9d20":"code","4203f7f1":"code","9715de1b":"code","bd8056b5":"code","7bea15e2":"markdown","7a4e2f8b":"markdown","864617fd":"markdown","beb32b2d":"markdown","1711b883":"markdown","a4d89b37":"markdown","c640d21b":"markdown","233853ad":"markdown","78cd1cbb":"markdown","e483b645":"markdown","38b666bf":"markdown","f25001bb":"markdown","3357744a":"markdown","d58cdaf6":"markdown","19cfa535":"markdown","39340b47":"markdown","2b089bf7":"markdown","114936b1":"markdown","0fbfdba6":"markdown","53d0b41c":"markdown","2d36be6a":"markdown","a4a51a47":"markdown","54e84e46":"markdown","49264e69":"markdown","1c06a914":"markdown","cb7420a5":"markdown","e8f81a3b":"markdown"},"source":{"ec278f42":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\nsns.set_context(\"talk\", font_scale=1.2)\nimport plotly.express as px\nimport numpy as np","cdaa1aeb":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\", \n                    keep_default_na=False, na_values=[\"\"])\ntrain.shape","21602b39":"class Features:\n    \n    _num_cols = ['SalePrice', 'LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd','MasVnrArea', 'BsmtFinSF1',\n               'BsmtFinSF2', 'BsmtUnfSF',  'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n               'LowQualFinSF', 'GrLivArea', \n               'BsmtFullBath', 'BsmtHalfBath', 'FullBath', # check the values, expect discrete numeric\n               'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n               'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n               'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n               'MiscVal', 'MoSold', 'YrSold', 'OverallCond', 'OverallQual']\n\n\n    _cat_cols = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n               'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n               'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n               'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n               'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC',\n               'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu',\n               'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', \n                'PoolQC', 'Fence', 'SaleType', 'SaleCondition', 'MiscFeature']\n\n    _ordinal_cat = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n                  'BsmtExposure', # could be treated as ordinal except maybe one category\n                  'BsmtFinType1',\n                  'BsmtFinType2', # likely good choice of ordernal\n                  'HeatingQC', 'KitchenQual', 'Functional', 'FireplaceQu',\n                  'GarageFinish', 'GarageQual', 'GarageCond',\n                  'PoolQC',\n                  'Fence', # except no fence which does not fit in the order\n                  ] #\n\n    _mapping_features = {\"ExterQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n                       \"ExterCond\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n                       \"BsmtQual\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"BsmtCond\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"BsmtExposure\": {\"NA\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4},\n                        \"BsmtFinType1\": {\"NA\": 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6},\n                        \"BsmtFinType2\" : {\"NA\": 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6},\n                        \"HeatingQC\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n                        \"KitchenQual\" :  {\"Po\": 0, \"Fa\": 1, \"TA\": \"2\", \"Gd\": 3, \"Ex\": 4},\n                        \"Functional\": {\"Sal\": 0, \"Sev\": 1, \"Maj2\": 2, \"Maj1\": 3, \"Mod\": 4, \"Min2\": 5, \"Min1\": 6, \"Typ\": 7},\n                        \"FireplaceQu\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"GarageFinish\": {\"NA\": 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3},\n                        \"GarageQual\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"GarageCond\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"PoolQC\": {\"NA\": 0, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"Fence\": {\"NA\": 0, \"MnWw\": 1, \"GdWo\": 2, \"MnPrv\":3 , \"GdPrv\":4}}\n    \n    def __init__(self):\n        self.stats()\n        \n    def stats(self):\n        print(f\"num numeric cols: {len(self._num_cols)}, cat cols: {len(self._cat_cols)}, \\\n              ordinary cols: {len(self._ordinal_cat)}\")\n        \n    def remove(self, fnames):\n        \n        for fname in fnames:\n            if fname in self._num_cols:\n                self._num_cols.remove(fname)\n            elif fname in self._cat_cols:\n                self._cat_cols.remove(fname)\n            else:\n                print(f\" {fname} not in features\")\n            \n            if fname in self._ordinal_cat:\n                self._ordinal_cat.remove(fname)\n        self.stats()\n                \n    def get(self, ftype=\"all\"):\n        \n        if ftype==\"all\": return self._num_cols + self._cat_cols\n        elif ftype==\"num\": return self._num_cols\n        elif ftype=='cat': return self._cat_cols\n        elif ftype=='ord': return self._ordinal_cat\n        else:\n            print(f\" wrong ftype {ftype}\")\n            \n    def add(self, names, types):\n        \n        assert len(names) == len(types)\n        if type == \"cat\": raise(\"not implemented yet\")\n        for name, typef in zip(names, types):\n            if typef == \"num\": self._num_cols.extend([name])\n        self.stats()\n                \n    def map_ordinal(self, name):\n        assert name in self._mapping_features \n        assert name in self._ordinal_cat\n\n        return self._mapping_features[name]\n            ","fdc89e52":"features = Features()","cd248739":"def set_missing_vals(df, cols):\n    for col in cols:\n        df[col] = df[col].replace(\"NA\", np.nan).astype(float)\n    return df","1e9bf0b1":"train = set_missing_vals(train, ['GarageYrBlt', 'MasVnrArea', 'LotFrontage'])","b041bc69":"map_year_age = {} \ndef year_to_age(data):\n    this_year = 2021\n    \n    year_cols = [col for col in data.columns if \n                 'Year' in col or 'Yr' in col]\n    print(year_cols)\n    for col in year_cols:\n        print(col)\n        new_col = col.replace(\"Year\", \"Age\").replace(\"Yr\", \"Age\")\n        map_year_age[col] = new_col\n        data[new_col] = this_year - data[col]\n        data.drop(columns=[col], inplace=True)\n    print(map_year_age)\n    return train","5843338c":"train = year_to_age(train)","5357d78e":"map_year_age","8717bd08":"features.remove(map_year_age.keys())\nfeatures.add(map_year_age.values(), ['num']*4)","526fe592":"low_cat_vars = ['Street', 'Utilities', 'Condition2']","c1fa9fa0":"features.remove(low_cat_vars)","c24d15b0":"for i, col in enumerate(features.get(\"num\")):\n    print(col)\n    with sns.plotting_context(\"talk\", font_scale=0.4):\n        fig, axes = plt.subplots(2,1, figsize=(16,4)) # create figure and axes\n        train[col].hist(bins=50, grid=False, ax=axes[0])\n        sns.boxplot(x=train[col], ax=axes[1])\n        plt.show()","6c2dc23c":"log_transform_feat = [\"LotFrontage\", 'GrLivArea']","d5eb87b8":"train.loc[:, 'LotFrontageL'] = train['LotFrontage'].apply(np.log)\ntrain.loc[:, 'GrLivAreaL'] = train['GrLivArea'].apply(np.log)","30a342a1":"fig, axes= plt.subplots(2,1, figsize=(16, 4))\ntrain['LotFrontage'].plot(kind='hist',ax=axes[0])\ntrain['LotFrontageL'].plot(kind='hist',ax=axes[1])","4e809239":"fig, axes= plt.subplots(2,1, figsize=(16, 4))\ntrain.boxplot(['LotFrontage'], ax=axes[0], vert=False)\ntrain.boxplot(['LotFrontageL'], ax=axes[1], vert=False)\n","66f23182":"train.loc[:, 'LotFrontage'] = train['LotFrontageL']\ntrain.loc[:, 'GrLivArea'] =train.loc[:, 'GrLivAreaL'] ","a873e34b":"train.drop(columns=['LotFrontageL', 'GrLivAreaL'], inplace=True)","2664bd0d":"train[features.get()].isna().sum().sort_values().tail()","7ff707eb":"from sklearn.impute import SimpleImputer","0aee1570":"#imp_cat = SimpleImputer(strategy=\"most_frequent\")\nimp_num = SimpleImputer(strategy=\"median\")","a8b7ae37":" train.loc[:, features.get(\"num\")] = imp_num.fit_transform( train.loc[:, features.get(\"num\")])","1d768c95":"train.isna().sum().sum()","832e30b8":"from sklearn.preprocessing import OneHotEncoder","24c760c6":"train[features.get()].select_dtypes(\"object\").sample(20, random_state=42)","0bc30c0d":"unique_vals = (train[features.get()].select_dtypes(\"object\").nunique()\/train.shape[0]).sort_values().to_frame(\"fraction\")\nunique_vals['num'] = train[features.get()].select_dtypes(\"object\").nunique()\nunique_vals","c194ef89":"features.map_ordinal(\"ExterQual\")","1cf73c6a":"def encode_ordinal(df, mapping):\n    '''encode ordinal categorical based on mapping'''\n    df = df.copy()\n    for feat in mapping:\n        if feat in df.columns:\n            df[feat] = df[feat].map(mapping[feat])\n        else:\n            print(f\"feature {feat} not available in df\")\n    return df","960e3acc":"train_enc = encode_ordinal(train, features._mapping_features)","d131d3eb":"train_enc[features.get()].select_dtypes(\"object\").head()","2baa760c":"enc = OneHotEncoder(handle_unknown='ignore', sparse=False)","df87d116":"def encode_one_hot(data, features):\n    \n    encode_cols = data[features].select_dtypes(\"object\").columns\n    data_cat_oho = enc.fit_transform(data[encode_cols])\n    oho_cols = enc.get_feature_names(encode_cols)\n    oho_names_mapping = {}\n    for col in encode_cols:\n        oho_names_mapping[col] = []\n        for col_oho in oho_cols:\n            if col == col_oho.split(\"_\")[0]:\n                oho_names_mapping[col].append(col_oho)\n    print(f\"out of {len(encode_cols)} produced {len(oho_cols)} encoded features\")\n    return pd.DataFrame(data_cat_oho.T, oho_cols).T, oho_names_mapping","976ea9bc":"oh_encoded, oho_mapping = encode_one_hot(train, features.get())","f5284cf4":"oh_encoded.head(2)","9fd4df88":"oh_encoded.shape","c40d1914":"features.remove(oho_mapping.keys())","ca759014":"features.get('cat')","f375e901":"new_cols = [val for vals in oho_mapping.values() for val in vals]\nfeatures.add(new_cols, types=[\"num\"]*len(new_cols))","2ebebc29":"train_oho = pd.merge(train.drop(columns=oho_mapping.keys()), oh_encoded, left_index=True, right_index=True)","296058f5":"feature_nooho = [val for val in features.get() if not val in new_cols] \nlen(feature_nooho)","2417c95f":"train_oho.shape","e9c916d1":"train_oho[feature_nooho].shape","26b66284":"train_oho[features.get()].dtypes.unique()","4111d84c":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler","70265b26":"scaler = StandardScaler()","870738da":"train_scaled = train_oho[feature_nooho].copy()\ntrain_scaled = pd.DataFrame(scaler.fit_transform(train_scaled), columns=feature_nooho)","57cd2c56":"train_scaled.head()","55b60e4c":"from sklearn.decomposition import PCA","330da4d5":"pca = PCA(n_components=len(feature_nooho), random_state=42)","88b23609":"train_pca = pd.DataFrame(pca.fit_transform(train_scaled))\ntrain_pca.shape","b007c417":"def plot_variance_explained(pca_fitted, feature_names):\n    fig, ax = plt.subplots(figsize=(16,4))\n    _ = plt.plot(range(1, len(feature_names)+1),pca_fitted.explained_variance_ratio_.cumsum(), marker = 'x')\n    ax.set_xlabel(\"features\"); ax.set_ylabel(\"variance explained\")\nplot_variance_explained(pca, feature_nooho)","a82e0dc1":"np.argmax([pca.explained_variance_ratio_.cumsum()>0.8])","4c332f00":"# pca_nooho = PCA(n_components=len(feature_vis_nooho), random_state=42)\n# train_pca_nooho = pd.DataFrame(pca_nooho.fit_transform(train_scaled[feature_vis_nooho]))\n# train_pca_nooho.shape\n# plot_variance_explained(pca_nooho, feature_vis_nooho)","92fbdd20":"# np.argmax([pca_nooho.explained_variance_ratio_.cumsum()>0.8])","4c05d14d":"fig, ax = plt.subplots()\nsns.scatterplot(x=train_pca[0], y=train_pca[1], alpha=1)\nax.set_xlabel(\"PC 1\"); ax.set_ylabel(\"PC 2\")","bac78d5b":"table_pca_comps = train_pca.T\ntable_pca_comps.index = feature_nooho\ntable_pca_comps.iloc[:, [1,2, 3]].style.applymap(lambda val: 'background: green' if val > 0 else 'background: blue')","03142dcc":"from sklearn.manifold import TSNE","93f583b5":"tsne = TSNE(n_components = 2, perplexity=30.0, n_iter=1000,random_state=42, n_jobs=-1)","2a638a21":"%%time\ntrain_tsne = pd.DataFrame(tsne.fit_transform(train_scaled), columns=['comp1', 'comp2'])","cc41c895":"train_tsne.head()","c3d50d14":"train_tsne['SalePrice'] = train['SalePrice']","c20c9d20":"train_tsne['SalePrice'].hist()","4203f7f1":"fig, ax= plt.subplots(figsize=(14,6))\nsns.scatterplot(x='comp1', y='comp2', data=train_tsne, alpha=1,\n               size='SalePrice', hue='SalePrice', ax=ax)","9715de1b":"from tqdm import tqdm","bd8056b5":"for perpl in tqdm(range(10, 50, 5)):\n    tsne_perpl = TSNE(n_components = 2, perplexity=perpl, random_state=1, n_jobs=-1, n_iter=4000)\n    train_tsne_perpl = pd.DataFrame(tsne_perpl.fit_transform(train_scaled), columns=['comp1', 'comp2'])\n    fig, ax= plt.subplots(figsize=(14,6))\n    sns.scatterplot(x='comp1', y='comp2', data=train_tsne, alpha=1,\n                   size='SalePrice', hue='SalePrice', ax=ax)\n    ax.set_title(f\"perplexity: {perpl}\")\n    plt.show()\n","7bea15e2":"> oho encode rest of the categorical variables","7a4e2f8b":"## Outlier","864617fd":"> 16 out of 37 features together explain 80% of variance","beb32b2d":"### Nominal Variables - One-Hot Encoding","1711b883":"# I. Extract and Prepro Data","a4d89b37":"## T-SNE","c640d21b":"### Ordinal Categorical Variables","233853ad":"### Year to age transform","78cd1cbb":"> With changing perplexity the clusters stay fairly robust.","e483b645":"# Goal\n\n* Visualize the data through PCA and t-SNE\n* Gain insights into potential clusters\/groups\n\n### Goal\n\n### comments","38b666bf":"# III. Data Visualization","f25001bb":"Standardize features by removing the mean and scaling to unit variance.","3357744a":"### Testing different perplexity params","d58cdaf6":"Encode categorical variables\n\n> None of the categorical variables appear to be ordinal variables.","19cfa535":"## Low-variance Variables\n\nI drop categorical variables where second category contains just a few. See EDA.","39340b47":"> * the first component captures houses with large property area and large basement. Which might have additional value miscval and porch\n> * the second component captures more expensive houses wiht fireplace, smaller area, but cars in the garage and additional value\n> * the third component captures cheaper houses with larger garage area..\n\n> caution with the interpretation of the components as they do not represent much of the variance.","2b089bf7":"## A) PCA","114936b1":"> * Multiple clusters are visible which might correspond to different house types\n> * There is no distinct cluster dominated by high sales prices. However there are 3-4 clusters which have higher sales houses.\n> * One can distinguish roughly 9 clusters.","0fbfdba6":"No missing anymore.","53d0b41c":"Plenty of outlier, when defining as outliers those above the 1.5IQR.\n\nApproaches to deal with outliers:\n\n* log transform\n* Windsorization\n* fixing at thresholding\n* dropping based on criteria, e.g. IQR\n\nLog-transform only on non-zero features.\n","2d36be6a":"## Encode variables","a4a51a47":"Identitify type of features. Based on EDA.","54e84e46":"> None of the features are having too many categories, with a maximum of 25 categories for Neighbourhood. OHO encoding will not increase features dramatically.\n","49264e69":"## Scaling the Data\n\nwith previous data with one-hot encoded feautres I  would use a MinMax Scaler here.\nFirst I only use the non-one-hot encoded features","1c06a914":"## IMpute\n\n3 numerical features only need to be imputed.","cb7420a5":"# II. Data Prepro","e8f81a3b":"> Visually, there is little evidence for different clusters. PCA does not give good results."}}