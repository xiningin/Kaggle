{"cell_type":{"2778561b":"code","fb79b8b5":"code","15a31c67":"code","03b4626e":"code","f311fe91":"code","f5c05b74":"code","db625300":"code","39a19eb4":"code","86656650":"code","153c37e7":"code","b32979cf":"code","573a8041":"code","e058e5dd":"code","b76a68e4":"code","f48a382e":"markdown","e50dab9b":"markdown","9be01e32":"markdown","d2bd8556":"markdown","9ec43b0e":"markdown"},"source":{"2778561b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fb79b8b5":"train = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntrain.head()","15a31c67":"train_x = train[list(train.columns)[1:]].values\ntrain_y = train['label'].values","03b4626e":"# normalization\ntrain_x = train_x \/ 255","f311fe91":"from sklearn.model_selection import train_test_split\nfrom keras.models import Model\nfrom keras.layers import Dense, Input","f5c05b74":"# train test split\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2)","db625300":"# reshape the inputs\ntrain_x = train_x.reshape(-1, 784)\nval_x = val_x.reshape(-1, 784)","39a19eb4":"input_img = Input(shape=(784,))  # 28x28=784\n\n\n## encoding layers\nencode_layer1 = Dense(1500, activation='relu')(input_img)\nencode_layer2 = Dense(1000, activation='relu')(encode_layer1)\nencode_layer3 = Dense(500, activation='relu')(encode_layer2)\n\n## latent view\nlatent_view   = Dense(10, activation='sigmoid')(encode_layer3)\n\n## decoding layers\ndecode_layer1 = Dense(500, activation='relu')(latent_view)\ndecode_layer2 = Dense(1000, activation='relu')(decode_layer1)\ndecode_layer3 = Dense(1500, activation='relu')(decode_layer2)\n\n## output layer\noutput_layer  = Dense(784)(decode_layer3)\n\noutoencoder = model = Model(input_img, output_layer)","86656650":"model.summary()","153c37e7":"outoencoder.compile(optimizer='rmsprop', loss='binary_crossentropy')\nhist = outoencoder.fit(train_x, train_x, epochs=200, batch_size=2048,shuffle = True, validation_data=(val_x, val_x))","b32979cf":"encoder = Model(input_img, latent_view)\nencoding = encoder.predict(val_x)   # bu k\u0131s\u0131m kopyalarken \u00e7\u0131kard\u0131\u011f\u0131 featurelar\u0131 tuttu\u011fumuz k\u0131s\u0131m.\n","573a8041":"preds = model.predict(val_x)","e058e5dd":"# Inputs: Actual Images\nf, ax = plt.subplots(1,5)\nfor i in range(5):\n    ax[i].imshow(val_x[i].reshape(28, 28))\nplt.show()","b76a68e4":"# Predicted : Autoencoder Output\nf, ax = plt.subplots(1,5)\nfor i in range(5):\n    ax[i].imshow(preds[i].reshape(28, 28))\nplt.show()","f48a382e":"<a id=\"4\"><\/a> <br>\n## Implementation and UseCases\n<a id=\"5\"><\/a> <br>\n## Dataset EDA\nLoad the dataset, separate predictors and target, normalize the inputs.","e50dab9b":"<a id=\"7\"><\/a> <br>\n## Autoencoders Results","9be01e32":"<font color='red'>\n<br>Content:\n    \n* [Introduction](#1)\n    * [What are Autoencoders ?](#2)\n    * [How Autoencoders Work ?](#3)\n* [Implementation and UseCases](#4)\n    * [Dataset EDA](#5)\n    * [Create Autoencoders Model](#6)\n    * [Autoencoders Results](#7)","d2bd8556":"<a id=\"6\"><\/a> <br>\n## Create Autoencoders Model\n\nIn this section, lets create an autoencoder architecture. The encoding part comprises of three layers with 2000, 1200, and 500 nodes. Encoding architecture is connected to latent view space comprising of 10 nodes which is then connected to decoding architecture with 500, 1200, and 2000 nodes. The final layer comprises of exact number of nodes as the input layer.","9ec43b0e":"<a id=\"1\"><\/a> <br>\n## Introduction\n<a id=\"2\"><\/a> <br>\n## What are Autoencoders ?\nAutoencoders are a special type of neural network architectures in which the output is same as the input. Autoencoders are trained in an unsupervised manner in order to learn the exteremely low level repersentations of the input data. These low level features are then deformed back to project the actual data. An autoencoder is a regression task where the network is asked to predict its input (in other words, model the identity function). These networks has a tight bottleneck of a few neurons in the middle, forcing them to create effective representations that compress the input into a low-dimensional code that can be used by the decoder to reproduce the original input.\n\nA typical autoencoder architecture comprises of three main components: \n\n- **Encoding Architecture :** The encoder architecture comprises of series of layers with decreasing number of nodes and ultimately reduces to a latent view repersentation.  \n- **Latent View Repersentation :** Latent view repersents the lowest level space in which the inputs are reduced and information is preserved.  \n- **Decoding Architecture :** The decoding architecture is the mirro image of the encoding architecture but in which number of nodes in every layer increases and ultimately outputs the similar (almost) input.  \n\n\nA highly fine tuned autoencoder model should be able to reconstruct the same input which was passed in the first layer. In this kernel, I will walk you through the working of autoencoders and their implementation.  Autoencoders are widly used with the image data and some of their use cases are: \n\n- Dimentionality Reduction   \n- Image Compression   \n- Image Denoising   \n- Image Generation    \n- Feature Extraction  \n\n<a id=\"3\"><\/a> <br>\n## 1.2 How Autoencoders work \n\nLets understand the mathematics behind autoencoders. The main idea behind autoencoders is to learn a low level repersenation of a high level dimentional data. Lets try to understand the encoding process with an example.  Consider a data repersentation space (N dimentional space which is used to repersent the data) and consider the data points repersented by two variables : x1 and x2. Data Manifold is the space inside the data repersentation space in which the true data resides. "}}