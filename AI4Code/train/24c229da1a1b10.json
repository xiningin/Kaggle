{"cell_type":{"626e60e6":"code","437307d2":"code","4ca49534":"code","b238b17a":"code","064f1afb":"code","f3181e0a":"code","1da5ea2b":"code","be83cd53":"code","cd74775a":"code","25bf5ec2":"code","0ac5818f":"code","777acc72":"code","9748b284":"code","ce7e62c7":"markdown","f8d2aebf":"markdown","20a1bba1":"markdown"},"source":{"626e60e6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import file utilities\nimport os\nimport glob\n\n# import charting\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation, ArtistAnimation \n%matplotlib inline\n\nfrom IPython.display import HTML\n\n# import computer vision\nimport cv2\nfrom skimage.measure import compare_ssim","437307d2":"df_test = '..\/input\/deepfake-detection-challenge\/test_videos\/'\ndf_train = '..\/input\/deepfake-detection-challenge\/train_sample_videos\/'\ndf_meta = '..\/input\/deepfake-detection-challenge\/train_sample_videos\/metadata.json'","4ca49534":"DATA_FOLDER = '..\/input\/deepfake-detection-challenge'\nTRAIN_SAMPLE_FOLDER = 'train_sample_videos'\nTEST_FOLDER = 'test_videos'\n\nprint(f\"Train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\nprint(f\"Test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")","b238b17a":"df_meta = pd.read_json(df_meta).transpose()\ndf_meta.head()","064f1afb":"df_meta['label'].value_counts(normalize=True)\n","f3181e0a":"train_list = list(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))\next_dict = []\nfor file in train_list:\n    file_ext = file.split('.')[1]\n    if (file_ext not in ext_dict):\n        ext_dict.append(file_ext)\nprint(f\"Extensions: {ext_dict}\")","1da5ea2b":"meta = np.array(list(df_meta.index))\nstorage = np.array([file for file in train_list if  file.endswith('mp4')])\nprint(f\"Metadata: {meta.shape[0]}, Folder: {storage.shape[0]}\")\nprint(f\"Files in metadata and not in folder: {np.setdiff1d(meta,storage,assume_unique=False).shape[0]}\")\nprint(f\"Files in folder and not in metadata: {np.setdiff1d(storage,meta,assume_unique=False).shape[0]}\")","be83cd53":"import cv2 as cv\nfrom tqdm import tqdm\nimport os\nimport matplotlib.pylab as plt\ntrain_dir = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/'\nfig, ax = plt.subplots(1,1, figsize=(15, 15))\ntrain_video_files = [train_dir + x for x in os.listdir(train_dir)]\n# video_file = train_video_files[30]\nvideo_file = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/akxoopqjqz.mp4'\ncap = cv.VideoCapture(video_file)\nsuccess, image = cap.read()\nimage = cv.cvtColor(image, cv.COLOR_BGR2RGB)\ncap.release()   \nax.imshow(image)\nax.xaxis.set_visible(False)\nax.yaxis.set_visible(False)\nax.title.set_text(f\"FRAME 0: {video_file.split('\/')[-1]}\")\nplt.grid(False)","cd74775a":"video_file = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/akxoopqjqz.mp4'\n\ncap = cv2.VideoCapture(video_file)\n\nframes = []\nwhile(cap.isOpened()):\n    ret, frame = cap.read()\n    if ret==True:\n        frames.append(frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    else:\n        break\ncap.release()\n\nprint('The number of frames saved: ', len(frames))","25bf5ec2":"def show_first_frame(video_files, num_to_show=25):\n    root = int(num_to_show**.5)\n    fig, axes = plt.subplots(root,root, figsize=(root*5,root*5))\n    for i, video_file in tqdm(enumerate(video_files[:num_to_show]), total=num_to_show):\n        cap = cv.VideoCapture(video_file)\n        success, image = cap.read()\n        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n        cap.release()   \n        \n        axes[i\/\/root, i%root].imshow(image)\n        fname = video_file.split('\/')[-1]        \n        try:\n            label = train_metadata.loc[fname, 'label']\n            axes[i\/\/root, i%root].title.set_text(f\"{fname}: {label}\")\n        except:\n            axes[i\/\/root, i%root].title.set_text(f\"{fname}\")","0ac5818f":"show_first_frame(train_video_files, num_to_show=25)","777acc72":"test_video_files = [df_test + x for x in os.listdir(df_test)]\nshow_first_frame(test_video_files, num_to_show=25)","9748b284":"fig, ax = plt.subplots(1,1, figsize=(12,12))\ncap = cv.VideoCapture(df_test + 'ahjnxtiamx.mp4')\ncap.set(1,2)\nsuccess, image = cap.read()\nimage = cv.cvtColor(image, cv.COLOR_BGR2RGB)\ncap.release()   \n\nax.imshow(image)\nfname = 'ahjnxtiamx.mp4'\nax.title.set_text(f\"{fname}\")","ce7e62c7":"**Understanding the Data**","f8d2aebf":"**Video data exploration**","20a1bba1":"**Check files type**"}}