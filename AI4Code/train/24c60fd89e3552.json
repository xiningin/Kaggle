{"cell_type":{"ebd631d4":"code","2130f90a":"code","29f0d797":"code","3369a470":"code","0cc6862d":"code","27dad9dc":"code","098dbfbf":"code","85c60666":"code","f6ce5970":"code","d32b733a":"code","9a8f31bc":"code","98f05281":"code","067ba6c1":"code","8ec7c242":"code","43337b33":"code","2427f591":"code","52bb1227":"code","fd735109":"code","77ee0539":"code","ebcfc8fd":"code","b5bd3dfa":"code","ab7ab861":"code","321f9a2a":"code","7094555c":"code","a1d4e8e7":"code","d8e5ba7b":"code","be431902":"code","0e22586c":"code","8ebf8f31":"code","319131df":"code","43fb4699":"code","0a9cc5fc":"code","5a87d65c":"code","fc411ef7":"code","0708ad5f":"code","a30ca6c8":"markdown","868bf5c4":"markdown"},"source":{"ebd631d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold,KFold\nfrom datetime import datetime\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n# Suppr warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport itertools\nfrom scipy import interp\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import rcParams\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2130f90a":"from sklearn.preprocessing import StandardScaler\n\nimport fastai\nfrom fastai import *\nfrom fastai.tabular import *\n\n","29f0d797":"fastai.__version__","3369a470":"train_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv', index_col='TransactionID')\ntrain_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/test_identity.csv', index_col='TransactionID')\n","0cc6862d":"train_transaction.head()","27dad9dc":"train_df = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest_df = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(\"Train shape : \"+str(train_df.shape))\nprint(\"Test shape  : \"+str(test_df.shape))","098dbfbf":"train_df = train_df.reset_index()\ntest_df = test_df.reset_index()","85c60666":"train_df['nulls1'] = train_df.isna().sum(axis=1)\ntrain_df['nulls1'] = train_df.isna().sum(axis=1)","f6ce5970":"train_df = train_df.drop([\"TransactionDT\"], axis=1)\ntest_df = test_df.drop([\"TransactionDT\"], axis=1)","d32b733a":"train_df = train_df.iloc[:, :53]\ntest_df = test_df.iloc[:, :52]","9a8f31bc":"train_df.head()\n","98f05281":"del train_transaction, train_identity, test_transaction, test_identity","067ba6c1":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\nus_emails = ['gmail', 'net', 'edu']\n#https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/100499#latest_df-579654\nfor c in ['P_emaildomain', 'R_emaildomain']:\n    train_df[c + '_bin'] = train_df[c].map(emails)\n    test_df[c + '_bin'] = test_df[c].map(emails)\n    \n    train_df[c + '_suffix'] = train_df[c].map(lambda x: str(x).split('.')[-1])\n    test_df[c + '_suffix'] = test_df[c].map(lambda x: str(x).split('.')[-1])\n    \n    train_df[c + '_suffix'] = train_df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    test_df[c + '_suffix'] = test_df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","8ec7c242":"test_df['P_emaildomain_suffix']\n","43337b33":"for c1, c2 in train_df.dtypes.reset_index().values:\n    if c2=='O':\n        train_df[c1] = train_df[c1].map(lambda x: str(x).lower())\n        test_df[c1] = test_df[c1].map(lambda x: str(x).lower())","2427f591":"numerical = [\"TransactionAmt\", \"nulls1\", \"dist1\", \"dist2\"] + [\"C\" + str(i) for i in range(1, 15)] + \\\n            [\"D\" + str(i) for i in range(1, 16)] + \\\n            [\"V\" + str(i) for i in range(1, 340)]\ncategorical = [\"ProductCD\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\",\n               \"P_emaildomain_bin\", \"P_emaildomain_suffix\", \"R_emaildomain_bin\", \"R_emaildomain_suffix\",\n               \"P_emaildomain\", \"R_emaildomain\",\n              \"DeviceInfo\", \"DeviceType\"] + [\"id_0\" + str(i) for i in range(1, 10)] +\\\n                [\"id_\" + str(i) for i in range(10, 39)] + \\\n                 [\"M\" + str(i) for i in range(1, 10)]","52bb1227":"\n\nnumerical = [col for col in numerical if col in train_df.columns]\ncategorical = [col for col in categorical if col in train_df.columns]\n\n","fd735109":"def nan2mean(df):\n    for x in list(df.columns.values):\n        if x in numerical:\n            #print(\"___________________\"+x)\n            #print(df[x].isna().sum())\n            df[x] = df[x].fillna(0)\n           #print(\"Mean-\"+str(df[x].mean()))\n    return df\ntrain_df=nan2mean(train_df)\ntest_df=nan2mean(test_df)\n","77ee0539":"category_counts = {}\nfor f in categorical:\n    train_df[f] = train_df[f].replace(\"nan\", \"other\")\n    train_df[f] = train_df[f].replace(np.nan, \"other\")\n    test_df[f] = test_df[f].replace(\"nan\", \"other\")\n    test_df[f] = test_df[f].replace(np.nan, \"other\")\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n    train_df[f] = lbl.transform(list(train_df[f].values))\n    test_df[f] = lbl.transform(list(test_df[f].values))\n    category_counts[f] = len(list(lbl.classes_)) + 1\n# train_df = train_df.reset_index()\n# test_df = test_df.reset_index()\n","ebcfc8fd":"for column in numerical:\n    scaler = StandardScaler()\n    if train_df[column].max() > 100 and train_df[column].min() >= 0:\n        train_df[column] = np.log1p(train_df[column])\n        test_df[column] = np.log1p(test_df[column])\n    scaler.fit(np.concatenate([train_df[column].values.reshape(-1,1), test_df[column].values.reshape(-1,1)]))\n    train_df[column] = scaler.transform(train_df[column].values.reshape(-1,1))\n    test_df[column] = scaler.transform(test_df[column].values.reshape(-1,1))\n","b5bd3dfa":"\nfrom tensorflow.keras.callbacks import Callback\n\ndef auroc_score(input, target):\n    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n    return roc_auc_score(target, input)\n\nclass AUROC(Callback):\n    _order = -20 #Needs to run before the recorder\n\n    def __init__(self, learn, **kwargs): self.learn = learn\n    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])\n    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n    \n    def on_batch_end(self, last_target, last_output, train, **kwargs):\n        if not train:\n            self.output.append(last_output)\n            self.target.append(last_target)\n                \n    def on_epoch_end(self, last_metrics, **kwargs):\n        if len(self.output) > 0:\n            output = torch.cat(self.output)\n            target = torch.cat(self.target)\n            preds = F.softmax(output, dim=1)\n            metric = auroc_score(preds, target)\n            return add_metrics(last_metrics, [metric])\n\n","ab7ab861":"for i in fastai.tabular.__dict__:\n    print(i)","321f9a2a":"\ndep_var='isFraud' \nprocs = [FillMissing, Categorify, Normalize]\ntest_all = TabularList.from_df(test_df, cat_names=categorical,cont_names=numerical,procs=procs)\ndata = (TabularList.from_df(train_df, cat_names=categorical, cont_names=numerical,procs=procs)\n                           .split_subsets(train_size=0.85, valid_size=0.15, seed=34)\n                           .label_from_df(cols=dep_var)\n                           .add_test(test_all)\n                           .databunch())       ","7094555c":"learn = tabular_learner(data, layers=[200,100],metrics=accuracy, callback_fns=AUROC)","a1d4e8e7":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)\n\n","d8e5ba7b":"learn.fit(10,lr=1e-2)\n#learn.fit(30,lr=3e-3)","be431902":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)\n","0e22586c":"\n\nlearn.unfreeze()\n#learn.fit_one_cycle(10,max_lr=1e-6)\nlearn.fit_one_cycle(10,max_lr=5e-5)\n\n","8ebf8f31":"learn.recorder.plot_losses()","319131df":"#learn.freeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)\n","43fb4699":"#learn.freeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)\n","0a9cc5fc":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","5a87d65c":"test_pred = learn.get_preds(DatasetType.Test)","fc411ef7":"\n\nsample_submission.isFraud = test_pred[0][:,1].numpy()\nsample_submission.head()\n\n","0708ad5f":"sample_submission.to_csv('simple_fastai_v3.csv')\n","a30ca6c8":"Can anybody tell me why fillmissing is not defined.","868bf5c4":"### Fraud detection\n\nTrying to implement this slighly complex implementation implementation : https:\/\/www.kaggle.com\/a45632\/ieee-fastai-v4"}}