{"cell_type":{"176e35f5":"code","3867f00e":"code","498ee329":"code","715cec30":"code","1e9615c0":"code","0568bf06":"code","afc05a47":"code","2bb0ada2":"code","92dace38":"code","1d4f8a82":"code","2c54aeec":"code","fb2005d8":"code","cc46e97d":"code","7fc808c6":"code","dfea612e":"code","bd4fb675":"code","d72b717c":"code","2f17500d":"code","f790b147":"code","261ca6cb":"code","d40861bf":"code","d0ddd155":"code","95925775":"code","0e7f12ef":"code","c1324f16":"code","2aef9e2e":"code","62c0a831":"code","3d498c4d":"code","cfe68355":"code","e72249e8":"code","ec0f9da9":"code","cb0963de":"code","45a0d081":"code","53e5fff6":"code","74def9ab":"code","cfa3d261":"code","535f59e7":"code","8115b448":"code","2253a866":"code","fa23dca8":"code","9fd01912":"code","c2a6a059":"code","e02e3f68":"code","3e92513f":"code","c8ecfeb9":"code","20538497":"code","f0fe1fef":"code","ed2a5221":"code","df82f3ae":"code","a4ef7014":"code","90f40650":"code","73f94e2e":"code","dd9fce88":"code","4eac4703":"code","fb0d9e17":"code","399a6f22":"code","2a93d017":"code","55a9a2bf":"code","cfce44d0":"code","ef2c06d8":"code","fd97a776":"code","7b3b9b3b":"code","e8bac683":"code","bacd743a":"code","8db6475f":"code","b38058c7":"code","3ef3ce88":"code","c76abf98":"markdown"},"source":{"176e35f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3867f00e":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.models import Model\nfrom keras.utils import plot_model\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers import Flatten, Dense, GlobalAveragePooling2D, Dropout\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping","498ee329":"!pip list","715cec30":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","1e9615c0":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","0568bf06":"tf.debugging.set_log_device_placement(True)","afc05a47":"train_data_dir =  \"..\/input\/plantv\/PlantVillage\/train\"\nvalidation_data_dir =\"..\/input\/plantv\/PlantVillage\/val\"","2bb0ada2":"img_width, img_height = 224, 224 \nbatch = 64\nepochs = 2\n\n# input_sizes = {\n#     'alexnet' : (224,224),\n#     'densenet': (224,224),\n#     'resnet' : (224,224),  256, 256\n#     'inception' : (299,299),\n#     'squeezenet' : (224,224),#not 255,255 acc. to https:\/\/github.com\/pytorch\/pytorch\/issues\/1120\n#     'vgg' : (224,224)\n# }","92dace38":"train_datagen = ImageDataGenerator(\n    horizontal_flip=True,\n    zoom_range=0.1,\n    rotation_range=10,\n    preprocessing_function=preprocess_input\n)\n\nval_datagen = ImageDataGenerator(\n    horizontal_flip=True,\n    zoom_range=0.1,\n    rotation_range=10, \n    preprocessing_function=preprocess_input\n    )","1d4f8a82":"train_generator = train_datagen.flow_from_directory(\n    directory=train_data_dir,\n    target_size=(img_width, img_height),\n)\n\nval_generator = val_datagen.flow_from_directory(\n    directory=validation_data_dir,\n    target_size=(img_width, img_height),\n)","2c54aeec":"type(train_generator)","fb2005d8":"resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(img_width, img_height, 3))\nresnet50.trainable = False\n\nx = resnet50.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dense(39, activation=\"softmax\")(x)","cc46e97d":"from keras.applications.resnet152 import ResNet152\nresnet50 = tf.keras.applications.ResNet152(include_top=False, weights=\"imagenet\", input_shape=(img_width, img_height, 3))\nresnet50.trainable = False\n\nx = resnet50.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dense(39, activation=\"softmax\")(x)","7fc808c6":"from keras.applications.inception_v3 import InceptionV3, preprocess_input\nresnet50 = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(img_width, img_height, 3))\nresnet50.trainable = False\n\nx = resnet50.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dense(39, activation=\"softmax\")(x)","dfea612e":"from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nresnet50 = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_shape=(img_width, img_height, 3))\nresnet50.trainable = False\n\nx = resnet50.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dense(39, activation=\"softmax\")(x)","bd4fb675":"from keras.applications.densenet import DenseNet169, preprocess_input\nresnet50 = DenseNet169(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\nresnet50.trainable = False\n\nx = resnet50.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dense(39, activation=\"softmax\")(x)","d72b717c":"# base_model = InceptionV3(include_top=False, weights=\"imagenet\", input_tensor=Input(shape=(299,299,3)))\n# model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n# image_size = (299, 299)","2f17500d":"model = Model(resnet50.input, x)","f790b147":"model.summary()","261ca6cb":"from keras.utils.vis_utils import plot_model","d40861bf":"plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","d0ddd155":"from keras.optimizers import Adam, SGD","95925775":"model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy']) #0.0001","0e7f12ef":"model.compile(optimizer=SGD(lr=0.0001,momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy']) #0.0001","c1324f16":"checkpoint = ModelCheckpoint(\"resnet_2.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')","2aef9e2e":"#A callback is a set of functions to be applied at given stages of the training procedure. \n#You can use callbacks to get a view on internal states and statistics of the model during training.\nhistory = model.fit_generator(\n    train_generator,\n    epochs=30,\n    steps_per_epoch=50,\n    validation_data=val_generator,\n    validation_steps=25,\n    callbacks = [checkpoint, early]\n)","62c0a831":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","3d498c4d":"dic = {}","cfe68355":"dic['incep_resnet_v2'] = 93.34","e72249e8":"dic['inception_v3'] = 96.75","ec0f9da9":"dic['resnet_50'] = 97.52","cb0963de":"dic['densenet_169'] = 95.75","45a0d081":"import pandas as pd\ndf = pd.DataFrame()","53e5fff6":"df['Architecture'] = list(dic.keys())\ndf['Accuracy']=list(dic.values())","74def9ab":"import seaborn as sn","cfa3d261":"sn.catplot(\"Architecture\", \"Accuracy\", data=df, kind=\"bar\")","535f59e7":"scores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")","8115b448":"import pickle\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('DenseNet169_model98.pkl', 'wb'))","2253a866":"import io\nimport base64\nimport numpy as np\nfrom PIL import Image\nfrom keras.preprocessing.image import img_to_array\n\ndefault_image_size = tuple((256, 256))\n\ndef convert_image(image_data):\n    try:\n        image = Image.open(image_data)\n        if image is not None :\n            image = image.resize(default_image_size, Image.ANTIALIAS)   \n            image_array = img_to_array(image)\n            return np.expand_dims(image_array, axis=0), None\n        else :\n            return None, \"Error loading image file\"\n    except Exception as e:\n        return None, str(e)","fa23dca8":"image_path = \"..\/input\/plantv\/PlantVillage\/train\/Tomato___Leaf_Mold\/3d232a86-283d-45ec-b5cf-99829d78afa8___Crnl_L.Mold 6550.JPG\"","9fd01912":"image_array, err_msg = convert_image(image_path)","c2a6a059":"image_array = train_datagen.flow_from_directory(\n    directory=\"..\/input\/plantv\/PlantVillage\/val\/Corn_(maize)___Common_rust_\/\",\n    target_size=(img_width, img_height),\n)","e02e3f68":"from keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.applications.vgg16 import decode_predictions\n# from keras.applications.vgg16 import VGG16\n# from keras.models import Model\n\nimage = load_img(\"..\/input\/plantv\/PlantVillage\/train\/Tomato___Leaf_Mold\/90ceddb7-9fe6-4e76-b33e-d83983cf8ef5___Crnl_L.Mold 6540.JPG\", target_size=(224,224))\n# convert the image pixels to a numpy array\nimage = img_to_array(image)\n# reshape data for the model\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n# prepare the image for the VGG model\nimage = preprocess_input(image)","3e92513f":"import pickle\nmodel_file = \"resnet50_model.pkl\"\nmodel = pickle.load(open(model_file,'rb'))","c8ecfeb9":"pred = model.predict(image)","20538497":"dt = f\"{label_binarizer.inverse_transform(pred)[0]}\"\ndt","f0fe1fef":"np.argmax(pred)","ed2a5221":"from os import listdir\nimage_labels = listdir(\"..\/input\/plantv\/PlantVillage\/train\")\nimage_labels","df82f3ae":"'Tomato___Late_blight'.split(\"___\")[1]","a4ef7014":"for i,x in enumerate(image_labels):\n    print(i,\"==>\",x)","90f40650":"from sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(image_labels)\n# pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)\nn_classes","73f94e2e":"import cv2\ndefault_image_size =  tuple((256, 256))\ndef convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","dd9fce88":"from keras.preprocessing.image import img_to_array\nimage_list, label_list = [], []\ndirectory_root = '..\/input\/plantv\/PlantVillage'\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    print(root_dir)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in root_dir :\n        if plant_folder == \"val\":\n            plant_disease_folder_list = listdir(f\"{directory_root}\/{plant_folder}\")\n\n            for disease_folder in plant_disease_folder_list :\n                # remove .DS_Store from list\n                if disease_folder == \".DS_Store\" :\n                    plant_disease_folder_list.remove(disease_folder)\n\n            for plant_disease_folder in plant_disease_folder_list:\n                print(f\"[INFO] Processing {plant_disease_folder} ...\")\n                plant_disease_image_list = listdir(f\"{directory_root}\/{plant_folder}\/{plant_disease_folder}\/\")\n\n                for single_plant_disease_image in plant_disease_image_list :\n                    if single_plant_disease_image == \".DS_Store\" :\n                        plant_disease_image_list.remove(single_plant_disease_image)\n\n                for image in plant_disease_image_list[:200]:\n                    image_directory = f\"{directory_root}\/{plant_folder}\/{plant_disease_folder}\/{image}\"\n                    if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                        image_list.append(convert_image_to_array(image_directory))\n                        label_list.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")","4eac4703":"np_image_list = np.array(image_list, dtype=np.float16) \/ 225.0","fb0d9e17":"import pickle\nfrom sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\nimage_labels1 = label_binarizer.fit_transform(image_labels)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nlist(label_binarizer.classes_)","399a6f22":"label_binarizer.inverse_transform(np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]))","2a93d017":"from sklearn.preprocessing import LabelEncoder","55a9a2bf":"lst = [x for x in image_labels]\nlst","cfce44d0":"from numpy import array\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit_transform(lst) #[\"image_labels\",\"good\",\"bad\"]\npickle.dump(le,open('label_transformEnco2.pkl', 'wb'))\nn_classes = len(le.classes_)","ef2c06d8":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.5, random_state = 42) ","fd97a776":"model_file = \"densnet169more_model.pkl\"\nmodel = pickle.load(open(model_file,'rb'))","7b3b9b3b":"scores = model.evaluate(x_test, y_test,batch_size=128)\nprint(f\"Test Accuracy: {scores[1]*100}\")\n#test loss, test acc","e8bac683":"scores","bacd743a":"from flask import Flask, render_template , redirect, url_for, request\nimport random","8db6475f":"app = Flask(__name__)\napp.static_folder = 'static'\n@app.route('\/')\ndef homepage():\n    return \"\"\"Hello world!\"\"\"\n\nif __name__ == '__main__':\n    app.run( debug=True)","b38058c7":"import tkinter as tk\nclass Application(tk.Frame):\n    def __init__(self, master=None):\n        super().__init__(master)\n        self.master = master\n        self.pack()\n        self.create_widgets()\n\n    def create_widgets(self):\n        self.hi_there = tk.Button(self)\n        self.hi_there[\"text\"] = \"Hello World\\n(click me)\"\n        self.hi_there[\"command\"] = self.say_hi\n        self.hi_there.pack(side=\"top\")\n\n        self.quit = tk.Button(self, text=\"QUIT\", fg=\"red\",\n                              command=self.master.destroy)\n        self.quit.pack(side=\"bottom\")\n\n    def say_hi(self):\n        print(\"hi there, everyone!\")\n\nroot = tk.Tk()\napp = Application(master=root)\napp.mainloop()","3ef3ce88":"from flask import Flask, request, jsonify, abort\nimport traceback\nimport pandas as pd\nimport numpy as np\nimport socket\nimport pickle\nimport flask\n\napp = Flask(__name__)\n# model = pickle.load(open(\"model3.pkl\",\"rb\"))\n\n@app.route('\/api',methods=['GET','POST'])\ndef predict():\n    data = request.get_json(force=True)\n    predict_request = [data['Open'], data['Low'], data['High'], data['Adj Close']]\n    predict_request = np.array(predict_request)\n    y_hat = 0 #model(predict_request)\n    output = [y_hat[0]]\n    return flask.jsonify(results=response)\n\nif __name__ == '__main__':\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.bind(('localhost', 0))\n    port = sock.getsockname()[1]\n    sock.close()\n    app.run(port=port, debug=True)","c76abf98":"CODE FROM OTHER WEBSITE gogul.dev"}}