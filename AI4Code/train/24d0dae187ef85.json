{"cell_type":{"2186c6ba":"code","150957d9":"code","c0258ca5":"code","7e6efb04":"code","f6b62d4d":"code","46255884":"code","48f35a44":"code","2e267c96":"markdown","936ef002":"markdown","461bf76a":"markdown","52a6dc23":"markdown","a2021315":"markdown","cdd7570d":"markdown","2e00faae":"markdown","18645e2a":"markdown"},"source":{"2186c6ba":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set()\nsns.set_style('whitegrid')\n\nfrom pymssa import MSSA","150957d9":"# Read 20k rows and keep only acoustic data\ndf = pd.read_csv(\"..\/input\/train.csv\", nrows=20000, dtype={'acoustic_data': np.int16, \n                                                           'time_to_failure': np.float64})[['acoustic_data']]\n# Zero-center data\ndf['acoustic_data'] -= df['acoustic_data'].mean()\ndf.head(5)","c0258ca5":"FIGSIZE = (16, 16)\n\nfig, ax = plt.subplots(2, 1, figsize=FIGSIZE)\ng = sns.lineplot(x=df.index[::2], y=df['acoustic_data'][::2], ax=ax[0])\nax[0].ticklabel_format(useOffset=False)\nax[0].set_title('Waveform');\nax[0].set_xlabel('Time')\nax[0].set_ylabel('Amplitude')\ng = sns.lineplot(x=df.index[:100], y=df['acoustic_data'][:100], ax=ax[1])\nax[1].ticklabel_format(useOffset=False)\nax[1].set_title('Waveform 100 samples zoom');\nax[1].set_xlabel('Time')\nax[1].set_ylabel('Amplitude')\nplt.show()","7e6efb04":"N_COMPONENTS = 16\nmssa = MSSA(n_components=N_COMPONENTS, window_size=4096, verbose=True)","f6b62d4d":"mssa.fit(df)","46255884":"waveform = df['acoustic_data'].values\ncumulative_recon = np.zeros_like(waveform)\n\nfor comp in range(N_COMPONENTS):  \n    fig, ax = plt.subplots(figsize=(18, 7))\n    current_component = mssa.components_[0, :, comp]\n    cumulative_recon = cumulative_recon + current_component\n    \n    ax.plot(df.index, waveform, lw=3, alpha=0.2, c='k', label='waveform')\n    ax.plot(df.index, cumulative_recon, lw=3, c='darkgoldenrod', alpha=0.6, label='cumulative'.format(comp))\n    ax.plot(df.index, current_component, lw=3, c='steelblue', alpha=0.8, label='component={}'.format(comp))\n    \n    ax.legend()\n    plt.show()","48f35a44":"waveform = df['acoustic_data'].values[:100]\ncumulative_recon = np.zeros_like(waveform)\n\nfor comp in range(N_COMPONENTS):  \n    fig, ax = plt.subplots(figsize=(18, 7))\n    current_component = mssa.components_[0, :100, comp]\n    cumulative_recon = cumulative_recon + current_component\n    \n    ax.plot(df.index[:100], waveform, lw=3, alpha=0.2, c='k', label='Waveform 100 samples zoom')\n    ax.plot(df.index[:100], cumulative_recon, lw=3, c='darkgoldenrod', alpha=0.6, label='cumulative'.format(comp))\n    ax.plot(df.index[:100], current_component, lw=3, c='steelblue', alpha=0.8, label='component={}'.format(comp))\n    \n    ax.legend()\n    plt.show()","2e267c96":"# Conclusions\n\nDespite not being a perfect fit (well using only 16 coeff), SSA is quite effective for reducing the dimensionality of the waveform data (int16 continuous values) in a few coefficients. However, we need a lighter SVD decomposition to fit the whole dataset, we think that it can be done by using an online method, such as [Incremental PCA](https:\/\/scikit-learn.org\/stable\/auto_examples\/decomposition\/plot_incremental_pca.html).\n\nNontheless, we don't know if this is the way to go... Is it worth to implement the online approach for the SSA package? What do kagglers think?","936ef002":"# Load packages\n\nClone multivariate SSA python repo.","461bf76a":"# SSA (pca-like) dimensionality reduction of LANL data (toy example)\n\n**Assumption**: the acoustic waveform data is very sparse. Therefore, we play with the SSA transform to hopely get a dense data manifold; we aim to feed the most representative SSA coefficients to the model, instead of the full continuous waveform.  \n\nPlease refer to this [kernel](https:\/\/www.kaggle.com\/jdarcy\/introducing-ssa-for-time-series-decomposition) for a comprehensive introduction to SSA. All credit to [pymssa package](https:\/\/github.com\/kieferk\/pymssa).","52a6dc23":"### 20k samples reconstruction","a2021315":"# Fit SSA transform\n\nFit SSA transform using only 16 components and a window size of 4096 samples ([recording data bins](https:\/\/www.kaggle.com\/c\/LANL-Earthquake-Prediction\/discussion\/77526)).","cdd7570d":"# Read 20k train rows\n\nWe read just 20k rows, since SVD matrix decomposition is very memory hungry.","2e00faae":"### 100 first samples reconstruction","18645e2a":"# Plot reconstruction\n\nPlot waveform, each SSA component and the cumulative sum of the components."}}