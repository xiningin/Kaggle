{"cell_type":{"ab8a8e17":"code","0b196bf8":"code","38925b31":"code","9fc557d1":"code","9999a277":"code","9af0080e":"code","0940f2dd":"code","26fc4500":"code","b82f4858":"code","ba3914d1":"code","0ecb1564":"code","4349e9bd":"code","afbc2353":"code","7bd9cd8a":"code","1acb0be1":"code","d58244d6":"code","cc474fe1":"code","39d95aec":"code","8b88e1d0":"code","8b3a7be1":"code","c76e4cc7":"code","1d4b3dae":"code","45742461":"code","04b41d4c":"code","f239c968":"code","d9352504":"code","dba23448":"code","41c48ea0":"code","96bd574c":"code","d39b01bd":"code","c0c5b35a":"markdown","e6348a80":"markdown","a86287d3":"markdown","6db0c5bd":"markdown","913295b1":"markdown","f7a30fd7":"markdown","a4949d51":"markdown","691b70a1":"markdown"},"source":{"ab8a8e17":"import matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style('white')\n\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\n%matplotlib inline\n\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")\nimport tensorflow as tf\nimport os, sys, cv2, random\nimport numpy as np\nimport pandas as pd\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook\nfrom keras.layers.core import Lambda\nfrom keras.models import Model, load_model, save_model\nfrom keras.optimizers import SGD, Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.layers import (Input, Dense, Dropout, Conv2D, Conv2DTranspose, \n                          BatchNormalization, Activation, GlobalAveragePooling2D,\n                          MaxPooling2D, concatenate, Reshape, Add, multiply)\nfrom keras import backend as K\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\n\nimport time\nt_start = time.time()","0b196bf8":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","38925b31":"from zipfile import ZipFile\nZipFile('..\/input\/train.zip').extractall()\nZipFile('..\/input\/test.zip').extractall('test')","9fc557d1":"basic_name = f'Unet_resnet' # python3 f string formatting\nsave_model_name = basic_name + '.model'\nsubmission_file = basic_name + '.csv'\n\nTRAIN_IMAGE_DIR = '..\/working\/images\/'\nTRAIN_MASK_DIR = '..\/working\/masks\/'\nTEST_IMAGE_DIR = '..\/working\/test\/images\/'\n\nimg_size = 101\nseed=42\n\nbatch_size  = 128\nepochs = 120","9999a277":"# src : https:\/\/www.kaggle.com\/shaojiaxin\/u-net-with-simple-resnet-blocks-v2-new-loss\/notebook\n###########\n# Metrics\n#########\ndef get_iou_vector(A, B):\n    batch_size = A.shape[0] # first label's size\n    metric = []\n    for batch in range(batch_size):\n        t, p = A[batch]>0, B[batch]>0\n        intersection = np.logical_and(t, p)\n        union = np.logical_or(t, p)\n        iou = (np.sum(intersection > 0) + 1e-10 )\/ (np.sum(union > 0) + 1e-10)\n        thresholds = np.arange(0.5, 1, 0.05)\n        s = []\n        for thresh in thresholds:\n            s.append(iou > thresh)\n        metric.append(np.mean(s))\n        \n    return np.mean(metric)\n\ndef my_iou_metric(label, pred): # greater than 0.5\n    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n\ndef my_iou_metric_2(label, pred): # greater than 0, to catch defective ones in the early stopping\n    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)","9af0080e":"# src: https:\/\/www.kaggle.com\/aglotero\/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n    intersection = temp1[0]\n    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    intersection[intersection == 0] = 1e-9\n    \n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n        \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","0940f2dd":"# code download from: https:\/\/github.com\/bermanmaxim\/LovaszSoftmax\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    gts = tf.reduce_sum(gt_sorted)\n    intersection = gts - tf.cumsum(gt_sorted)\n    union = gts + tf.cumsum(1. - gt_sorted)\n    jaccard = 1. - intersection \/ union\n    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n    return jaccard\n\n###############\n# BINARY LOSSES\n###############\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        def treat_image(log_lab):\n            log, lab = log_lab\n            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n            log, lab = flatten_binary_scores(log, lab, ignore)\n            return lovasz_hinge_flat(log, lab)\n        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n        loss = tf.reduce_mean(losses)\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n\n    def compute_loss():\n        labelsf = tf.cast(labels, logits.dtype)\n        signs = 2. * labelsf - 1.\n        errors = 1. - logits * tf.stop_gradient(signs)\n        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n        gt_sorted = tf.gather(labelsf, perm)\n        grad = lovasz_grad(gt_sorted)\n        loss = tf.tensordot(tf.nn.elu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n        return loss\n\n    # deal with the void prediction case (only void pixels)\n    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n                   lambda: tf.reduce_sum(logits) * 0.,\n                   compute_loss, strict=True, name=\"loss\")\n    return loss","26fc4500":"def flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = tf.reshape(scores, (-1,))\n    labels = tf.reshape(labels, (-1,))\n    if ignore is None:\n        return scores, labels\n    valid = tf.not_equal(labels, ignore)\n    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n    return vscores, vlabels\n\ndef lovasz_loss(y_true, y_pred):\n    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n    logits = y_pred\n    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n    return loss\n\ndef symmetric_lovasz(y_true, y_pred):\n    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n    loss = ((lovasz_hinge(y_pred, y_true, per_image = True, ignore = None)) + \\\n            (lovasz_hinge(-y_pred, 1 - y_true, per_image = True, ignore = None))) \/2\n    return loss","b82f4858":"# Loading of training\/testing ids\ntrain_df = pd.read_csv(\"..\/input\/train.csv\", index_col=\"id\", usecols=[0])\n\n# Inserting 3 new columns into train_df\ntrain_df[\"images\"] = [np.array(load_img(TRAIN_IMAGE_DIR + \"{}.png\".format(idx), color_mode = \"grayscale\")) \/ 255 \n                      for idx in tqdm_notebook(train_df.index)]\n\ntrain_df[\"masks\"] = [np.array(load_img(TRAIN_MASK_DIR + \"{}.png\".format(idx), color_mode = \"grayscale\")) \/ 255 \n                     for idx in tqdm_notebook(train_df.index)]\n\n# Coverage of mask across the image\ntrain_df[\"coverage\"] = train_df.masks.map(np.sum) \/ pow(img_size, 2)\n\n# Classify every coverage from 0 to 10\ndef cov_to_class(val):    \n    for i in range(0, 11): \n        if val * 10 <= i : return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)","ba3914d1":"train_df.head()","0ecb1564":"fig, axs = plt.subplots(1, 2, figsize=(15,5))\nsns.distplot(train_df.coverage, kde=False, ax=axs[0], color= '#123456')\nsns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1], color= '#123456')\nplt.suptitle(\"Salt coverage\")\naxs[0].set_xlabel(\"Coverage\")\naxs[1].set_xlabel(\"Coverage class\");","4349e9bd":"plt.scatter(train_df.coverage, train_df.coverage_class)\nplt.xlabel(\"Coverage\")\nplt.ylabel(\"Coverage class\")","afbc2353":"# Create train\/validation split stratified by salt coverage\nX = np.array(train_df.images.tolist()).reshape(-1, img_size, img_size, 1)\ny = np.array(train_df.masks.tolist()).reshape(-1, img_size, img_size, 1)\nx_train, x_valid, y_train, y_valid = \\\ntrain_test_split(\n    X, y,\n    test_size=0.2, \n    stratify=train_df.coverage_class,\n    random_state=seed\n)","7bd9cd8a":"from keras.layers import LeakyReLU\n\ndef BatchActivate(x):\n    x = BatchNormalization()(x)\n    x = Activation('elu')(x)\n    return x\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    if activation==True: x = BatchActivate(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16, batch_activate=False):\n    x = BatchActivate(blockInput)\n    x = convolution_block(x, num_filters, (3,3))\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    if batch_activate: x = BatchActivate(x)\n    return x\n\ndef squeeze_excite_block_cSE(input_, ratio=2):\n    init = input_\n\n    filters = K.int_shape(init)[-1]\n    se_shape = (1, 1, filters)\n\n    se = GlobalAveragePooling2D()(init)\n    se = Reshape(se_shape)(se)\n    se = Dense(filters \/\/ ratio, activation='relu', kernel_initializer='he_normal', use_bias=True)(se)\n    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=True)(se)\n\n    x = multiply([init, se])\n    return x\n\ndef squeeze_excite_block_sSE(input_):\n    sSE_scale = Conv2D(1, (1, 1), activation='sigmoid', padding=\"same\", use_bias = True)(input_)\n    return multiply([input_, sSE_scale])\n\ndef unet_layer(blockInput, num_filters, use_csSE_ratio = 2):\n    x = Conv2D(num_filters, (3, 3), activation=None, padding=\"same\")(blockInput)\n    x = residual_block(x, num_filters )\n    x = residual_block(x, num_filters , batch_activate = True)\n\n    if use_csSE_ratio > 0:\n        sSEx = squeeze_excite_block_sSE(x)\n        cSEx = squeeze_excite_block_cSE(x,ratio = use_csSE_ratio ) #modified 10\/10\/2018\n        x = Add()([sSEx, cSEx])\n\n    return x","1acb0be1":"# Build Model\ndef build_model(input_layer, start_neurons, DropoutRatio=0.5):\n    \n    # 101 -> 50\n    conv1 = unet_layer(input_layer,start_neurons * 1,use_csSE_ratio=2)\n    pool1 = MaxPooling2D((2,2))(conv1)\n    pool1 = Dropout(DropoutRatio\/3)(pool1)\n    \n    # 50 -> 25\n    conv2 = unet_layer(pool1, start_neurons * 2,use_csSE_ratio=2)\n    pool2 = MaxPooling2D((2,2))(conv2)\n    pool2 = Dropout(DropoutRatio\/2)(pool2)\n    \n    # 25 -> 12\n    conv3 = unet_layer(pool2, start_neurons * 4,use_csSE_ratio=2)\n    pool3 = MaxPooling2D((2,2))(conv3)\n    pool3 = Dropout(DropoutRatio)(pool3)\n    \n    # 12 -> 6\n    conv4 = unet_layer(pool3, start_neurons * 8,use_csSE_ratio=2)\n    pool4 = MaxPooling2D((2,2))(conv4)\n    pool4 = Dropout(DropoutRatio)(pool4)\n    ##############\n    \n    # Middle\n    convm = Conv2D(start_neurons*16, (3,3), activation=None, padding='same')(pool4)\n    convm = residual_block(convm, start_neurons*16)\n    convm = residual_block(convm, start_neurons*16, True)\n    \n    # 6 -> 12\n    deconv4 = Conv2DTranspose(start_neurons*8, (3,3), strides=(2,2), padding='same')(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(DropoutRatio)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons*8, (3,3), activation=None, padding='same')(uconv4)\n    uconv4 = residual_block(uconv4, start_neurons*8)\n    uconv4 = residual_block(uconv4, start_neurons*8, True)\n    \n    # 12 -> 25\n    deconv3 = Conv2DTranspose(start_neurons*4, (3,3), strides=(2,2), padding='valid')(uconv4)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = Dropout(DropoutRatio)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons*4, (3,3), activation=None, padding='same')(uconv3)\n    uconv3 = residual_block(uconv3, start_neurons*4)\n    uconv3 = residual_block(uconv3, start_neurons*4, True)\n    \n    # 25 -> 50\n    deconv2 = Conv2DTranspose(start_neurons*2, (3,3), strides=(2,2), padding='same')(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Dropout(DropoutRatio)(uconv2)\n    \n    uconv2 = Conv2D(start_neurons*2, (3,3), activation=None, padding='same')(uconv2)\n    uconv2 = residual_block(uconv2, start_neurons*2)\n    uconv2 = residual_block(uconv2, start_neurons*2, True)\n    \n    # 50 -> 101\n    deconv1 = Conv2DTranspose(start_neurons*1, (3,3), strides=(2,2), padding='valid')(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Dropout(DropoutRatio)(uconv1)\n    \n    uconv1 = Conv2D(start_neurons*1, (3,3), activation=None, padding='same')(uconv1)\n    uconv1 = residual_block(uconv1, start_neurons*1)\n    uconv1 = residual_block(uconv1, start_neurons*1, True)\n    \n    output_layer_noActi = Conv2D(1, (1,1), padding='same', activation=None)(uconv1)\n    output_layer = Activation('sigmoid')(output_layer_noActi)\n    \n    return output_layer","d58244d6":"def do_augmentation(seqs, seq2_train, X_train, y_train):\n\n    seq_det = seqs.to_deterministic()\n    X_train_aug = seq_det.augment_image(X_train)\n    X_train_aug = seq2_train.augment_image(X_train_aug)\n    \n    y_train_aug = seq_det.augment_image(y_train)\n\n    if y_train_aug.shape != (101, 101):\n        X_train_aug = ia.imresize_single_image(X_train_aug, (101, 101), interpolation=\"linear\")\n        y_train_aug = ia.imresize_single_image(y_train_aug, (101, 101), interpolation=\"nearest\")\n\n    return np.array(X_train_aug), np.array(y_train_aug)\n\nsometimes = lambda aug: iaa.Sometimes(0.5, aug)\n\nseq = iaa.Sequential([\n    iaa.Fliplr(0.5),\n\n    iaa.OneOf([\n        iaa.Noop(),\n        iaa.Affine(rotate=(-10, 10), translate_percent={\"x\": (-0.25, 0.25)}, mode='symmetric', cval=(0), backend=\"cv2\"),\n        iaa.Noop(),\n        iaa.CropAndPad(\n            percent=(-0.2, 0.2),\n            pad_mode=\"reflect\",\n            pad_cval=0,\n            keep_size=False\n        ),\n    ])\n])\nseq_train = iaa.Sequential(\n    sometimes(iaa.Multiply((0.8, 1.2))),\n    sometimes(iaa.Add((-0.2, 0.2))),\n    sometimes(iaa.OneOf([\n        iaa.AdditiveGaussianNoise(scale=(0, 0.05)),\n        iaa.GaussianBlur(sigma=(0.0, 1.0)),\n    ]))\n)\n\n\ndef make_image_gen(features, labels, batch_size=32):\n    all_batches_index = np.arange(0, features.shape[0])\n    out_images = []\n    out_masks = []\n    \n    while True:\n        np.random.shuffle(all_batches_index)\n        for index in all_batches_index:\n            c_img, c_mask = do_augmentation(seq, seq_train, features[index], labels[index])\n\n            out_images += [c_img]\n            out_masks += [c_mask]\n            if len(out_images) >= batch_size:\n                yield np.stack(out_images, 0), np.stack(out_masks, 0)\n                out_images, out_masks = [], []","cc474fe1":"fig, axs = plt.subplots(2, 10, figsize=(15,3))\nfor i in range(10):\n    axs[0][i].imshow(x_train[i].squeeze(), cmap=\"Greys\")\n    axs[0][i].imshow(y_train[i].squeeze(), cmap=\"Greens\", alpha=0.3)\n    axs[1][i].imshow(x_train[int(len(x_train)\/2 + i)].squeeze(), cmap=\"Greys\")\n    axs[1][i].imshow(y_train[int(len(y_train)\/2 + i)].squeeze(), cmap=\"Greens\", alpha=0.3)\nfig.suptitle(\"Top row: original images, bottom row: augmented images\")","39d95aec":"# model\ninput_layer = Input((img_size, img_size, 1))\noutput_layer = build_model(input_layer, 16,0.5)\n\nmodel1 = Model(input_layer, output_layer)\nmodel1.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr = 0.005), metrics=[my_iou_metric])\n\n#model1.summary()","8b88e1d0":"early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=20, verbose=1)\nmodel_checkpoint = ModelCheckpoint(save_model_name, monitor='val_my_iou_metric', mode='max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode='max', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n\ntrain_generator = make_image_gen(x_train, y_train,batch_size)\n\nt_model1_start = time.time()\nhistory = model1.fit_generator(\n    train_generator,\n    steps_per_epoch = x_train.shape[0]*2\/\/batch_size,\n    validation_data=[x_valid, y_valid], \n    epochs=epochs,\n    callbacks = [early_stopping, model_checkpoint, reduce_lr],\n    verbose = 1\n)\nt_model1_end = time.time()\nprint(f\"Run time = {(t_model1_end-t_model1_start)\/3600} hours\")","8b3a7be1":"model1 = load_model(save_model_name, custom_objects={'my_iou_metric':my_iou_metric})\n\n# remove ;ast activation layer and use lovasz loss instead\ninput_x = model1.layers[0].input\noutput_layer = model1.layers[-1].input\n\nmodel2 = Model(input_x, output_layer)\nmodel2.compile(loss=symmetric_lovasz, optimizer=Adam(lr=0.01), metrics=[my_iou_metric_2])","c76e4cc7":"early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=30, verbose=1)\n\nmodel_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n                                   mode = 'max', save_best_only=True, verbose=1)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, \n                              patience=10, min_lr=0.00005, verbose=1)\n\ntrain_generator = make_image_gen(x_train, y_train,batch_size\/\/2)\n\nt_model2_start = time.time()\n\nhistory = model2.fit_generator(\n             train_generator,\n             steps_per_epoch = x_train.shape[0]*2\/\/batch_size,\n             validation_data=[x_valid, y_valid], \n             epochs=epochs + int(epochs*(1\/5)),\n             callbacks = [early_stopping, model_checkpoint, reduce_lr],\n             verbose = 1\n)\nt_model2_end = time.time()\nprint(f\"Run time = {(t_model2_end - t_model2_start)\/3600} hours\")","1d4b3dae":"fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\nax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\nax_loss.legend()\nax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\nax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\nax_score.legend();","45742461":"model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2, 'symmetric_lovasz': symmetric_lovasz})","04b41d4c":"def predict_result(model,x_test,img_size): # predict both orginal and reflect x\n    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n    preds_test = model.predict(x_test).reshape(-1, img_size, img_size)\n    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size, img_size)\n    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n    return preds_test\/2\n\npreds_valid = predict_result(model,x_valid,img_size)","f239c968":"## Scoring for last model, choose threshold by validation data \nthresholds_ori = np.linspace(0.3, 0.7, 31)\n# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\nthresholds = np.log(thresholds_ori\/(1-thresholds_ori)) \nious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\nprint(ious);","d9352504":"threshold_best_index = np.argmax(ious)\niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, 'xr', label='Best threshold')\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend();","dba23448":"def rle_encode(im):\n    '''\n    im: numpy array, 1-mask, 0-background\n    Returns run length as string\n    '''\n    pixels = im.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","41c48ea0":"test_images = os.listdir(TEST_IMAGE_DIR)\nx_test = np.array([(np.array(load_img(TEST_IMAGE_DIR + \"{}\".format(idx), color_mode = \"grayscale\"))) \/ 255 \n                   for idx in tqdm_notebook(test_images)]).reshape(-1, img_size, img_size, 1)\n\npreds_test = predict_result(model,x_test,img_size)\npred_dict = {idx[:10]: rle_encode(np.round(preds_test[i] > threshold_best)) \n             for i, idx in enumerate(tqdm_notebook(test_images))};","96bd574c":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv(submission_file)","d39b01bd":"t_finish = time.time()\nprint(f\"Kernel run time = {(t_finish-t_start)\/3600} hours\")","c0c5b35a":"## Create train\/validation split stratified by salt coverage","e6348a80":"# Calculating the salt coverage and salt coverage classes\nCounting the number of salt pixels in the masks and dividing them by the image size. Also create 11 coverage classes, -0.1 having no salt at all to 1.0 being salt only. Plotting the distribution of coverages and coverage classes, and the class against the raw coverage.","a86287d3":"* The **_loss function_** is that parameter one passes to Keras model.compile which is actually optimized while training the model . This loss function is generally minimized by the model.\n\n* Unlike the loss function , the **_metric_** is another list of parameters passed to Keras model.compile which is actually used for judging the performance of the model.","6db0c5bd":"# Lovasz as a Loss Function","913295b1":"Techniques that are used in this notebook: \n1. residual block\n2. lovasz loss\n3. unet\n4. iou\n\n\n<font color='blue'>* Public Score : 0.82909<\/font><br>\n\n<font color='green'>* Private Score : 0.85323<\/font>","f7a30fd7":"## Data augmentation","a4949d51":"* index_col=\"id\", usecols=[0] ==> I'm taking the first column, considering it as index","691b70a1":"# Import Packages"}}