{"cell_type":{"4cac4d19":"code","6d7c3eea":"code","8327f73f":"code","950737b9":"code","ca19fd90":"code","73d41d4c":"code","69edd95a":"code","ab2e20e5":"code","cced8beb":"markdown","7d7f0182":"markdown","fdf750ba":"markdown","6b5a1fb7":"markdown","9174ddec":"markdown","b67dd35a":"markdown","f158b424":"markdown"},"source":{"4cac4d19":"# Get the official BERT tokenizer (please feel free to use the tokenization scheme of your choice)\n!wget --quiet https:\/\/raw.githubusercontent.com\/tensorflow\/models\/master\/official\/nlp\/bert\/tokenization.py\n    \n# Import stuff\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tokenization\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam","6d7c3eea":"# I'm selecting this one\nmodule_url = \"https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-12_H-768_A-12\/2\"\n\n# The model is available as a layer. The intricacies are hidden inside, so it's just a quick line to call it.\nbert_layer = hub.KerasLayer(module_url, trainable=True)","8327f73f":"# Define tokenizer\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","950737b9":"# Define a function that'll create the inputs to be passed to your model\n# There are 3 inputs: token_ids, mask_ids, segment_ids\n# Please Google and read more about the inputs and outpus. That's how I learned about it.\ndef encode_text(texts, tokenizer, max_len):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","ca19fd90":"# Actually tokenize now using the function you defined\n# Assuming you have 2 pandas dataframes 'df_train' and 'df_test'\ntrain_text_enc = encode_text(df_train['text'].values, tokenizer, max_len=100)\ntest_text_enc = encode_text(df_test['text'].values, tokenizer, max_len=100)","73d41d4c":"# Absract out the model creation\ndef build_bert_model(bert_layer, max_len):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    \n    # Using [CLS] token output from sequence output\n    x = sequence_output[:, 0, :]  # use 0th output - belongs to CLS token - means classification\n    \n    out = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    \n    return model","69edd95a":"# Build model\nm = build_bert_model(bert_layer, max_len)\nm.summary()","ab2e20e5":"m.compile(Adam(lr=1e-1), loss='binary_crossentropy', metrics=['accuracy'])\nm.fit(train_text_enc, df_train['target'].values, epochs=2, validation_split=0.2, batch_size=16)","cced8beb":"This is just a starter piece of code for using Google's BERT that can be used for many NLP applications.\n<br>You can use this to quickly test how one of the state-of-the-art NLP models performs for your problem.\n\nThis code is not an end-to-end working example, but should be pretty easy to adapt.\n\n\n\n\n\nHope you find it useful!","7d7f0182":"# Simplifying BERT","fdf750ba":"## Grab the BERT model \nPlease visit https:\/\/tfhub.dev\/tensorflow and select a model<br>\nMake sure you read about the different models available to you\n","6b5a1fb7":"## Fit","9174ddec":"## Create model","b67dd35a":"## Import stuff","f158b424":"## Tokenize"}}