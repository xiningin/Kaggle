{"cell_type":{"73b73635":"code","c651e6aa":"code","b1be17cc":"code","234ef2cb":"code","23367e9a":"code","ac23e2dc":"code","b28c7583":"code","4be940a5":"code","eb34835a":"code","d588fa7e":"code","6b81f908":"code","4bc042e6":"code","32512e47":"code","ad21781c":"code","4aefbf6e":"code","142d2d29":"code","37ba71ec":"code","03f68d75":"code","940715ce":"code","8cbaf3e9":"code","f9ff754a":"code","6fdc64f9":"code","fe59cfa8":"code","e801aa81":"code","4a3ec269":"code","e69ed2e3":"code","664ffd4d":"code","2a018d2a":"code","eec11fad":"code","b7f39fb4":"code","d4317d73":"code","27351b8f":"code","7aadd343":"code","5bf900d6":"code","40d2e7b2":"code","cfb27e3a":"code","1edf7073":"code","d44b0db8":"code","bb7dc876":"code","2e88bc04":"code","ba578f9a":"code","57886eda":"code","27f55842":"code","2bea4e3e":"code","4f1db193":"code","4bd4ff40":"code","b392a372":"code","9cb2551b":"code","2fed04e9":"code","b2f9e195":"code","b8d23b99":"code","5e3cc89f":"code","845317c2":"code","293ee664":"code","4651a2eb":"code","307ec216":"code","5aa21d0b":"code","5a7e7ddd":"code","e6da863f":"code","6cdae9e1":"code","119da947":"code","d90a5fb6":"code","781a2e8f":"code","32a698da":"code","51263f88":"code","b076baf4":"code","29e3fa17":"code","f4833e09":"code","dfdc4384":"code","e5246f91":"code","3b06e5f4":"code","3751f7b8":"code","2b1c623a":"code","0cdd6aac":"code","da2d1627":"markdown","14ffe0e8":"markdown","4fba7e53":"markdown","9defcd29":"markdown","cec872e9":"markdown","22bf3009":"markdown","186d02fa":"markdown","c0eecda0":"markdown","74514b72":"markdown","f130aa59":"markdown","f851f8b3":"markdown","90990b82":"markdown","ab12ca93":"markdown","14a27f28":"markdown","2f63070d":"markdown","3c028df2":"markdown","ad369b73":"markdown","88525419":"markdown","1b77c69d":"markdown","1b2591ee":"markdown","cb25922c":"markdown","a1b0f7e5":"markdown"},"source":{"73b73635":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c651e6aa":"import pandas as pd \npd.set_option('display.max_columns',60)\n\nimport numpy as np \nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","b1be17cc":"#!pip install xlrd\n#!pip install openpyxl","234ef2cb":"#Reading training and testing dataset\ntrain = pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')\ntest =  pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Test_set.xlsx')\n","23367e9a":"#Checking the shape of the training and testing dataset\nprint('Size of training set is {}'.format(train.shape))\nprint('Size of testing set is  {}'.format(test.shape))","ac23e2dc":"train.info()","b28c7583":"test.info()","4be940a5":"train = train.dropna()\nprint('Size of training set is {}'.format(train.shape))\n","eb34835a":"#for training set \ntrain['Date_of_Journey']  =  pd.to_datetime(train['Date_of_Journey'], format='%d\/%m\/%Y')\ntrain['Journey_day']      =  train['Date_of_Journey'].dt.day\ntrain['Dep_day']          =  train['Date_of_Journey'].dt.dayofweek\ntrain['Dep_month']        =  train['Date_of_Journey'].dt.month\n\n\n#for testing set \ntest['Date_of_Journey']  =  pd.to_datetime(test['Date_of_Journey'], format='%d\/%m\/%Y')\ntest['Journey_day']      =  test['Date_of_Journey'].dt.day\ntest['Dep_day']          =  test['Date_of_Journey'].dt.dayofweek\ntest['Dep_month']        =  test['Date_of_Journey'].dt.month","d588fa7e":"#sns.countplot(train['Journey_day'])","6b81f908":"f, axes = plt.subplots(1, 2,figsize=(13,5))\nsns.barplot(train['Journey_day'],train['Price'], ax =axes[0])\nsns.boxplot(train['Journey_day'],train['Price'], ax =axes[1])\nplt.show()","4bc042e6":"#for training set\ntrain['Dep_month']    =  train['Dep_month'].replace({1:'Jan', 2:'Feb',    3:'Mar',  4:'April',   5:'May', 6:'June',\n                                                 7:'July',8:'August', 9:'Sept', 10:'Oct',   11:'Nov', 12:'Dec'})\n\n#for testing set\ntest['Dep_month']    =  test['Dep_month'].replace({1:'Jan', 2:'Feb',    3:'Mar',  4:'April',   5:'May', 6:'June',\n                                                 7:'July',8:'August', 9:'Sept', 10:'Oct',   11:'Nov', 12:'Dec'})","32512e47":"f, axes = plt.subplots(1, 2,figsize=(13,5))\nsns.barplot(train['Dep_month'],train['Price'], ax =axes[0])\nsns.boxplot(train['Dep_month'],train['Price'], ax =axes[1])\nplt.show()","ad21781c":"#fro training set\ntrain['Dep_day']      =  train['Dep_day'].replace({0:'Mon',1:'Tue',2:'Wed',\n                                            3:'Thur',4:'Fri',5:'Sat',6:'Sun'})\n#for testing set\n\ntest['Dep_day']      =  test['Dep_day'].replace({0:'Mon',1:'Tue',2:'Wed',\n                                            3:'Thur',4:'Fri',5:'Sat',6:'Sun'})","4aefbf6e":"f, axes = plt.subplots(1, 2,figsize=(13,5))\nsns.barplot(train['Dep_day'],train['Price'], ax =axes[0])\nsns.boxplot(train['Dep_day'],train['Price'], ax =axes[1])","142d2d29":"\n#for training set \ntrain['Journey_week']=train['Journey_day'].replace({1 :'first_week',\n                             3 :'first_week',\n                             6 :'first_week',\n                             9 :'second_week',\n                            12 :'second_week',\n                            15 :'third_week',\n                            18 :'third_week',\n                            21 :'third_week',\n                            24 :'fourth_week',\n                            27 :'fourth_week'})\n#for testing set\ntest['Journey_week']=test['Journey_day'].replace({1 :'first_week',\n                             3 :'first_week',\n                             6 :'first_week',\n                             9 :'second_week',\n                            12 :'second_week',\n                            15 :'third_week',\n                            18 :'third_week',\n                            21 :'third_week',\n                            24 :'fourth_week',\n                            27 :'fourth_week'})\n\n","37ba71ec":"#now we can drop the date of journey column\ntrain.drop(['Date_of_Journey'],axis=1,inplace=True)\n#now we can drop the date of journey column for \ntest.drop(['Date_of_Journey'],axis=1,inplace=True)\n","03f68d75":"\nf, axes = plt.subplots(1, 2,figsize=(13,5))\nsns.barplot(train['Journey_week'],train['Price'], ax =axes[0])\nsns.boxplot(train['Journey_week'],train['Price'], ax =axes[1])","940715ce":"#similarly converting the departure time column into a timestamp in training dataset\ntrain['Dep_Time']         =  pd.to_datetime(train['Dep_Time']).dt.time\ntrain['Dep_hr']           =  train['Dep_Time'].apply(lambda x:x.hour)\n\n#similarly converting the departure time column into a timestamp in testing dataset\ntest['Dep_Time']         =  pd.to_datetime(test['Dep_Time']).dt.time\ntest['Dep_hr']           =  test['Dep_Time'].apply(lambda x:x.hour)\n","8cbaf3e9":"def pod(x):\n    if (x > 4) and (x <= 8):\n        return 'Early Morning'\n    elif (x > 8) and (x <= 12 ):\n        return 'Morning'\n    elif (x > 12) and (x <= 16):\n        return'Noon'\n    elif (x > 16) and (x <= 20) :\n        return 'Eve'\n    elif (x > 20) and (x <= 24):\n        return'Night'\n    elif (x <= 4):\n        return'Late Night'","f9ff754a":"#for training set\ntrain['Dep_Part_of_day']=train['Dep_hr'].apply(pod)\ntrain.drop(['Dep_Time','Dep_hr'],axis=1,inplace=True)\n\n#for testing set\ntest['Dep_Part_of_day']=test['Dep_hr'].apply(pod)\ntest.drop(['Dep_Time','Dep_hr'],axis=1,inplace=True)","6fdc64f9":"\nf, axes = plt.subplots(1, 2,figsize=(13,5))\nsns.barplot(train['Dep_Part_of_day'],train['Price'], ax =axes[0])\nsns.boxplot(train['Dep_Part_of_day'],train['Price'], ax =axes[1])","fe59cfa8":"train['Arrival_Time']         =  pd.to_datetime(train['Arrival_Time']).dt.time\ntrain['Arrival_hr']           = train['Arrival_Time'].apply(lambda x :x.hour)\n\ntest['Arrival_Time']         =  pd.to_datetime(test['Arrival_Time']).dt.time\ntest['Arrival_hr']           = test['Arrival_Time'].apply(lambda x :x.hour)","e801aa81":"def pod(x):\n    if (x > 4) and (x <= 8):\n        return 'Early Morning'\n    elif (x > 8) and (x <= 12 ):\n        return 'Morning'\n    elif (x > 12) and (x <= 16):\n        return'Noon'\n    elif (x > 16) and (x <= 20) :\n        return 'Eve'\n    elif (x > 20) and (x <= 24):\n        return'Night'\n    elif (x <= 4):\n        return'Late Night'\n    \n","4a3ec269":"train['Arrival_Part_of_day']=train['Arrival_hr'].apply(pod)\ntrain.drop(['Arrival_Time','Arrival_hr'],axis=1,inplace=True)\n\ntest['Arrival_Part_of_day']=test['Arrival_hr'].apply(pod)\ntest.drop(['Arrival_Time','Arrival_hr'],axis=1,inplace=True)","e69ed2e3":"\nf, axes = plt.subplots(1, 2,figsize=(13,5))\nsns.barplot(train['Arrival_Part_of_day'],train['Price'], ax =axes[0])\nsns.boxplot(train['Arrival_Part_of_day'],train['Price'], ax =axes[1])","664ffd4d":"#converting the duration column into total mins \ntrain['Duration_mins']  =  train['Duration'].str.replace('h','*60').str.replace(' ','+').str.replace('m','*1').apply(eval)\ntrain['Duration']       =  train['Duration'].str.replace('h','*60').str.replace(' ','+').str.replace('m','*1').apply(eval)\n\n#converting the duration column into total mins \ntest['Duration_mins']  =  test['Duration'].str.replace('h','*60').str.replace(' ','+').str.replace('m','*1').apply(eval)\ntest['Duration']       =  test['Duration'].str.replace('h','*60').str.replace(' ','+').str.replace('m','*1').apply(eval)\n\n\n","2a018d2a":"train.drop('Duration',axis=1,inplace=True)\ntest.drop('Duration',axis=1,inplace=True)","eec11fad":"sns.scatterplot(train['Duration_mins'],train['Price'])","b7f39fb4":"train.groupby(['Additional_Info'])['Price'].agg({'mean','median','count'})","d4317d73":"#since most of the data in this column is non-info,I will consider this as null values and drop the column\ntrain.drop('Additional_Info',axis=1,inplace=True)\n\ntest.drop('Additional_Info',axis=1,inplace=True)","27351b8f":"#encoding by using mean of each group \ntrain['Mean_Route'] = train['Route'].replace(dict(train.groupby(['Route'])['Price'].mean()))\n\ntest['Mean_Route']  = test['Route'].replace(dict(train.groupby(['Route'])['Price'].mean()))","7aadd343":"sns.scatterplot(train['Mean_Route'],train['Price'])","5bf900d6":"#changing the total stops to numerical values\ntrain['Total_Stops']=train['Total_Stops'].replace({'non-stop': 0,\n                                                   '1 stop'  : 1,\n                                                   '2 stops' : 2,\n                                                   '3 stops' : 3,\n                                                   '4 stops' : 4})\n\n#changing the total stops to numerical values\ntest['Total_Stops']=test['Total_Stops'].replace({'non-stop': 0,\n                                                   '1 stop'  : 1,\n                                                   '2 stops' : 2,\n                                                   '3 stops' : 3,\n                                                   '4 stops' : 4})\n","40d2e7b2":"\nf, axes = plt.subplots(1, 2,figsize=(13,5))\nsns.barplot(train['Total_Stops'],train['Price'], ax =axes[0])\nsns.boxplot(train['Total_Stops'],train['Price'], ax =axes[1])","cfb27e3a":"#Renaming and creating a new feature combining the source and destination\ntrain['Source']        =  train['Source'].replace({'Banglore' :'B',\n                                                   'Kolkata'  :'K',\n                                                   'Delhi'    :'D',\n                                                   'Mumbai'   :'M',\n                                                   'Chennai'  :'C'})\ntrain['Destination']   =  train['Destination'].replace({'Cochin'    :'Co',\n                                                        'Kolkata'   :'Ko',\n                                                        'Delhi'     :'Del',\n                                                        'New Delhi' :'Nd',\n                                                        'Hyderabad' :'H',\n                                                        'Banglore'  :'Ba'})\n#creating a new feature combining the source and destination\ntrain['Flight_name']   =  train['Source'] +  '-'  +  train['Destination']\n\n","1edf7073":"#for testing set\n#Renaming and creating a new feature combining the source and destination\ntest['Source']        =  test['Source'].replace({'Banglore' :'B',\n                                                   'Kolkata'  :'K',\n                                                   'Delhi'    :'D',\n                                                   'Mumbai'   :'M',\n                                                   'Chennai'  :'C'})\ntest['Destination']   =  test['Destination'].replace({'Cochin'    :'Co',\n                                                        'Kolkata'   :'Ko',\n                                                        'Delhi'     :'Del',\n                                                        'New Delhi' :'Nd',\n                                                        'Hyderabad' :'H',\n                                                        'Banglore'  :'Ba'})\ntest['Flight_name']   =  test['Source'] +  '-'  +  test['Destination']","d44b0db8":"#combining total stops and flight name \ntrain['Flight_Stops']= train['Flight_name'] + train['Total_Stops'].astype(str)\n\ntest['Flight_Stops']= test['Flight_name'] + test['Total_Stops'].astype(str)\n\n#train.drop(['Flight_name'],axis=1,inplace=True)","bb7dc876":"#train.drop('Route',axis=1,inplace=True)","2e88bc04":"#renaming the airline column for simplicity and to create new variables\ntrain['Airline']=train['Airline'].replace({'Jet Airways':'JA','Air Asia' : 'AA','GoAir':'GA','Multiple carriers Premium economy'  :'MCEc',\n                          'IndiGo'     :'IG','Air India':'AI' ,'Multiple carriers':'MC','SpiceJet':'SJ','Vistara':'V',\n                         'Jet Airways Business':'JAB','Vistara Premium economy':'VEc','Trujet':'TJ'})\n\ntest['Airline']=test['Airline'].replace({'Jet Airways':'JA','Air Asia' : 'AA','GoAir':'GA','Multiple carriers Premium economy'  :'MCEc',\n                          'IndiGo'     :'IG','Air India':'AI' ,'Multiple carriers':'MC','SpiceJet':'SJ','Vistara':'V',\n                         'Jet Airways Business':'JAB','Vistara Premium economy':'VEc','Trujet':'TJ'})","ba578f9a":"#creating a new variable combining airline,flightname,and total stops \ntrain['Flight_Stops']= train['Airline'] + '\/' + train['Flight_name'] + train['Total_Stops'].astype(str)\n\ntest['Flight_Stops']= test['Airline'] + '\/' + test['Flight_name'] + test['Total_Stops'].astype(str)\n","57886eda":"#again using mean encoding instead of label encoding \ntrain['Mean_Flight_Stops']=train['Flight_Stops'].replace(dict(train.groupby(['Flight_Stops'])['Price'].mean()))\n\ntest['Mean_Flight_Stops']=test['Flight_Stops'].replace(dict(train.groupby(['Flight_Stops'])['Price'].mean()))","27f55842":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ntrain['Flight_Stops'] = le.fit_transform(train['Flight_Stops'])\n\n\ntest['Flight_Stops'] = le.fit_transform(test['Flight_Stops'])","2bea4e3e":"#sns.scatterplot(train['Flight_Stops'],train['Price'])","4f1db193":"train.drop('Route',axis=1,inplace=True)","4bd4ff40":"airline=pd.get_dummies(train['Airline'],drop_first=True)\ntrain.drop(['Airline'],axis=1,inplace=True)\nairline.head()","b392a372":"source=pd.get_dummies(train['Source'],drop_first=True)\ntrain.drop(['Source'],axis=1,inplace=True)\nsource.head()\n","9cb2551b":"destination=pd.get_dummies(train['Destination'],drop_first=True)\ntrain.drop(['Destination'],axis=1,inplace=True)\ndestination.head()","2fed04e9":"dep_day=pd.get_dummies(train['Dep_day'],drop_first=True)\ntrain.drop(['Dep_day'],axis=1,inplace=True)\n\ndep_day.head()","b2f9e195":"dep_month=pd.get_dummies(train['Dep_month'],drop_first=True)\ntrain.drop(['Dep_month'],axis=1,inplace=True)\n\n\ndep_month.head()","b8d23b99":"jour_week=pd.get_dummies(train['Journey_week'],drop_first=True)\ntrain.drop(['Journey_week'],axis=1,inplace=True)\n\n\njour_week.head()","5e3cc89f":"dep_pod=pd.get_dummies(train['Dep_Part_of_day'],drop_first=True)\ntrain.drop(['Dep_Part_of_day'],axis=1,inplace=True)\n\n\ndep_pod.head()","845317c2":"arr_pod=pd.get_dummies(train['Arrival_Part_of_day'],drop_first=True)\ntrain.drop(['Arrival_Part_of_day'],axis=1,inplace=True)\narr_pod.columns = ['eve_arr','late_night_arr','morn_arr','night_arr','noon_arr']\n\n\narr_pod.head()","293ee664":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain['Flight_name'] = le.fit_transform(train['Flight_name'])","4651a2eb":"#combining all the pre-procssed data\nfinal_train=pd.concat([train,airline,source,destination,dep_day,dep_month,\n                      jour_week,dep_pod,arr_pod],axis=1)\nfinal_train = final_train.drop('Flight_Stops',axis=1)\n","307ec216":"from sklearn.preprocessing import StandardScaler\nstd = StandardScaler()\nfinal_train['Journey_day'] = std.fit_transform(final_train[['Journey_day']])\nfinal_train['Duration_mins'] = std.fit_transform(final_train[['Duration_mins']])\n\n#final_train.drop(['Journey_day','Dep_hr','Arrival_hr','Duration_mins'],axis=1,inplace=True)","5aa21d0b":"final_train.head(4)","5a7e7ddd":"#dividing the target variable from predictors\nX = final_train.drop(['Price'],axis=1)\ny = final_train['Price']\n","e6da863f":"# let us look at some of the important features which is useful for predicting the target variable using mutual info\nfrom sklearn.feature_selection import mutual_info_classif\nfeat_imp = pd.DataFrame(mutual_info_classif(X,y),index=X.columns)\n","6cdae9e1":"feat_imp.sort_values(by=0,ascending=False).plot(kind='barh',figsize=(15,8))","119da947":"from sklearn.linear_model    import LinearRegression\nfrom sklearn.linear_model    import Ridge,Lasso\nfrom sklearn.neighbors       import KNeighborsRegressor\nfrom sklearn.tree            import DecisionTreeRegressor\nfrom sklearn.ensemble        import GradientBoostingRegressor,RandomForestRegressor\nfrom xgboost                 import XGBRegressor\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import KFold\n\n","d90a5fb6":"# spiliting the dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)","781a2e8f":"from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\ndef model_predict(ml_model):\n    print('Model used is     :  {}'.format(ml_model))\n    print('\\t')\n    #Training Info\n    model      = ml_model.fit(X_train,y_train)\n    train_pred = ml_model.predict(X_train)\n    print(\"Training R2 score :  {}\".format(round(model.score(X_train,y_train),2)))\n    print('Training MAE      :  {}'.format(round(mean_absolute_error(y_train,train_pred),2)))\n    print('Training MSE      :  {}'.format(round(mean_squared_error(y_train,train_pred),2)))\n    print('Training RMSE     :  {}'.format(np.sqrt(round(mean_squared_error(y_train,train_pred),2))))\n    print('\\t')\n    \n    #Test Info\n    predictions = model.predict(X_test)\n    r2score     = r2_score(y_test,predictions) \n    print(\"Test R2 score     :  {}\".format(round(r2score,2)))\n    print('Test MAE          :  {}'.format(round(mean_absolute_error(y_test,predictions),2)))\n    print('Test MSE          :  {}'.format(round(mean_squared_error(y_test,predictions),2)))\n    print('Test RMSE         :  {}'.format(np.sqrt(round(mean_squared_error(y_test,predictions),2))))","32a698da":"model_predict(DecisionTreeRegressor())","51263f88":"#Since there is a problem of overfitting let us generalize the model\n#depth      = list(range(4,30))\n#param_grid =  dict(max_depth=depth)\n#grid_search       = GridSearchCV(DecisionTreeRegressor(),param_grid,cv =10,n_jobs=-1)\n#grid_search.fit(X_train, y_train)","b076baf4":"model_predict(DecisionTreeRegressor(max_depth = 12))","29e3fa17":"model_predict(RandomForestRegressor())","f4833e09":"#tuned_params = {'n_estimators': [100, 200, 300, 400, 500], 'min_samples_split': [10, 20, 40], 'min_samples_leaf': [1, 2, 4]}\n#random_regressor = RandomizedSearchCV(RandomForestRegressor(), tuned_params, n_iter = 20, scoring = 'neg_mean_absolute_error', cv = 5, n_jobs = -1)\n#random_regressor.fit(X_train, y_train)","dfdc4384":"#random_regressor.best_params_","e5246f91":"model_predict(RandomForestRegressor(n_estimators=400,min_samples_split=10,min_samples_leaf=2))","3b06e5f4":"model_predict(LinearRegression())","3751f7b8":"model_predict(GradientBoostingRegressor())","2b1c623a":"model_predict(XGBRegressor())","0cdd6aac":"model_predict(XGBRegressor(reg_lambda=1.0,n_estimators=500,max_depth=5,learning_rate=0.05))","da2d1627":"**As you can see above stops play an important factor in deciding the price of the flights,\nmore stops leads to an increas in the price**","14ffe0e8":"**We can see that during march price is higher compared to other months.Again if we look into the boxplot this may be due to some of the flights available in the month of march**","4fba7e53":"# Feature engineering","9defcd29":"# Data Cleaning \n","cec872e9":"**I will prefer Gradient boosting because it is giving me a generalized model,Also the evaluation metric i'm using is RMSE since we have a lot of outliers**","22bf3009":"**Same is for arrival times,not much difference**","186d02fa":"# Data-Preprocessing","c0eecda0":"**Converting Date-time columns into pandas datetime format**","74514b72":"**Not much of a significant difference here**","f130aa59":"**A general assumption,I have is weekends the price should be higher but the data shows not much significant difference.One reason would be we have only datapoints of only 3 months**","f851f8b3":"**We can observe that first day of the month the price is high,if you look at the box plots median is similar to other days also there are some outliers.\nPossible due to some Flights runing on selected days**","90990b82":"**So, what i have done here is combining airline,flightname and total stops,this was done because I know one thing is depending on the airline ,the no.of stops and location price varies.I hope it gets borader perspective of the data**","ab12ca93":"# Modelling Part","14a27f28":"**Genereal assumption is that longer flight duration cost more,can't infer too much from the scatterplot above**","2f63070d":"**This feature engineering is optional,you can keep the days as it is**","3c028df2":"**Dividing the hours according to the parts of day,again it is my assumption that price varies according to various time**","ad369b73":"**AS you can see above**","88525419":"**Ok,now one thing I know is the price varies according to route,depending on the number of stops(also depending on where your flight has an hault),instead of label encoding,I have gone for mean encoding**\n\n**for ex : *Mum-Hyd-Delhi* price varies  for *Mum-Calcutta-Delhi***, so instead of label encoding,I have done mean encoding for better understanding of the groups","1b77c69d":"**According to our newly created feature,Mean_flight_Stops,Mean_Route has be give higher importance according to mutual info classif(feature selection)**","1b2591ee":"If you have reached till here, So i hope you liked my Approach,well it is slightly different from others.**I highly recommend you guys to give me a Honest opinion.**\n\nI recommend people to point to any mistakes I made \n\nAlso,Don't forget to upvote if you like it!.\n\n\nIf you have any doubt reagrding any part of the notebook, feel free to comment your doubt in the comment box.\n\nThank you!!","cb25922c":"**The data we have shows that there is not much of a significant difference between various parts of day(maybe because we have datapoints of 3 months)**","a1b0f7e5":"We can see that there is one null value in the training set and zero null value in the testing set.\n\n**Solution** : Either fill the null value with the mean\/median or delete the datapoint."}}