{"cell_type":{"abacc907":"code","a5ca6477":"code","5bc599b0":"code","61bfceb9":"code","7a6f4648":"code","127c00d7":"code","004554a0":"code","5957a84c":"code","e9ec05df":"code","67c28d56":"code","a097361c":"code","7cea3471":"code","2d05ae8a":"code","8c6eacb7":"code","ce9cbf5f":"code","4586acda":"code","bb299be8":"code","1c457882":"code","1686a51e":"code","f81cdd9f":"code","b90289f6":"code","f12b589d":"code","4c61d3a9":"code","ef8a748b":"code","413ccb51":"code","0f346907":"code","7f2e41dc":"code","71d53e66":"code","d404a326":"code","08674113":"code","7ce6b864":"code","3a27ee07":"markdown","8c4d3d59":"markdown","764e1259":"markdown","65e700bf":"markdown","d30b4e86":"markdown"},"source":{"abacc907":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import zscore","a5ca6477":"df_train = pd.read_csv(\"..\/input\/banking-dataset-classification\/new_train.csv\")\ndf_train\n","5bc599b0":"df_train.describe()","61bfceb9":"df_train.info()","7a6f4648":"set(df_train.marital), set(df_train.month), set(df_train.y)","127c00d7":"# I get yes as 0 and no as 1\nif type(df_train.y.iloc[0]) == str:\n    df_train['y'] = df_train['y'].apply(lambda x: 0 if x == \"yes\" else (1 if x == \"no\" else np.na))","004554a0":"def numerize(df, col,tuple):\n    if type(df[col].iloc[0]) == str:\n        df[col] = df[col].apply(lambda x: tuple.index(x))","5957a84c":"week_days = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']\nmonths = list(map(str.lower, ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']))\nnumerize(df_train, 'day_of_week', week_days)\nnumerize(df_train, 'month', months)","e9ec05df":"poutcome = ('failure','nonexistent','success')\ncontact = ('cellular','telephone')\nloan = ('no','yes','unknown')\nnumerize(df_train, 'poutcome', poutcome)\nnumerize(df_train, 'contact', contact)\nnumerize(df_train, 'loan', loan)","67c28d56":"job=('admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\nmarital=('divorced','married','single','unknown')   # note: 'divorced' means divorced or widowed)\neducation=('basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\ndefault=('no','yes','unknown')\nhousing=('no','yes','unknown')\nnumerize(df_train, 'job', job)\nnumerize(df_train, 'marital', marital)\nnumerize(df_train, 'education', education)\nnumerize(df_train, 'default', default)\nnumerize(df_train, 'housing', housing)","a097361c":"set(df_train.poutcome), set(df_train.contact), set(df_train.loan)","7cea3471":"df_train.info()","2d05ae8a":"df_train.dropna(inplace=True)\ndf_train.drop_duplicates(inplace=True)","8c6eacb7":"from scipy.stats import zscore      # indica per ogni elemento a quante deviazioni std si trova lontano dl valore medio (se > 3 \u00e8 un outlier)\nz_scores = np.abs(zscore(df_train, axis=0))\n#print(z_scores, z_scores.shape, type(z_scores))\ndf_train_filter_map = (z_scores < 4).all(axis=1)\n\ndf_train_filtered = df_train[df_train_filter_map]               # whole\ndf_y = df_train_filtered['y']                                   # train y \ndf_x = df_train_filtered.drop(['y'], axis=1)\ndf_x                                             # train x","ce9cbf5f":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nscaler = StandardScaler().fit(df_x)\ndf_scaled_x = pd.DataFrame(scaler.transform(df_x), columns=df_x.columns)\ndf_scaled_x\n","4586acda":"from sklearn.decomposition import PCA\npca = PCA(n_components=8)\ndf_x_ready = pca.fit_transform(df_scaled_x)\ndf_x_ready, df_x_ready.shape","bb299be8":"df_y","1c457882":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV","1686a51e":"rfc = RandomForestClassifier(max_depth=4, random_state=42, n_estimators=150)\nlr = LogisticRegression(random_state=42)\ndc = DummyClassifier(random_state=42, strategy=\"most_frequent\").fit(df_x_ready, df_y)\n\nrfc.fit(df_x_ready, df_y)\nlr.fit(df_x_ready, df_y)","f81cdd9f":"rfc.score(df_x_ready, df_y), lr.score(df_x_ready, df_y), dc.score(df_x_ready, df_y)","b90289f6":"df_x = df_x.drop(['pdays', 'previous'], axis=1)     # test data doesn't have these columns\ndf_x.shape, df_y.shape","f12b589d":"pipe = Pipeline([('scaler', StandardScaler()),('pca', PCA()), ('rfc', RandomForestClassifier())])\nparams = { 'pca__n_components':(12, 15), 'rfc__max_depth':( 12, 15, 30), 'rfc__n_estimators':(50, 100)}\nsearch = GridSearchCV(pipe, params, n_jobs=-1)\nsearch.fit(df_x, df_y)","4c61d3a9":"search.best_score_, search.best_params_","ef8a748b":"from sklearn.neighbors import KNeighborsClassifier\npipe_knn = Pipeline([('scaler', StandardScaler()),('pca', PCA()),('knn', KNeighborsClassifier())])\nknn_params = {'pca__n_components': (10,11, 13),'knn__n_neighbors':(1,2)}\nsearch_knn = GridSearchCV(pipe_knn, knn_params, n_jobs=-1)\nsearch_knn.fit(df_x, df_y)","413ccb51":"search_knn.best_score_, search_knn.best_params_","0f346907":"pipe_knn.fit(df_x, df_y)\npipe_knn.score(df_x, df_y)","7f2e41dc":"df_test = pd.read_csv(\"..\/input\/banking-dataset-classification\/new_test.csv\")\ndf_test","71d53e66":"test_preds = pipe_knn.predict(df_test)\ntest_preds_text = np.array(list(map(lambda x : 'yep' if x==0 else 'nope', test_preds)))\nprint(test_preds_text)\ntest_preds = pd.DataFrame(test_preds)","d404a326":"plt.hist(test_preds_text)\nplt.title(\"Histogram of predictions\")\nplt.show()","08674113":"test_preds.columns = ['y']\ntest_preds","7ce6b864":"test_preds.to_csv('submission.csv', index=False)","3a27ee07":"## Classification","8c4d3d59":"## KNN Pipeline","764e1259":"## Preprocessing del train set","65e700bf":"### Outliers removal","d30b4e86":"### Scaling & PCA"}}