{"cell_type":{"72369fbf":"code","0473ae4b":"code","24d42e87":"code","2fd2301d":"code","c898fc86":"code","6c54a772":"code","c125936c":"code","1f27b3bd":"code","06292abc":"code","aafd41cf":"code","217f9a19":"code","0b51ca5b":"code","e6d16d5a":"code","a518dda2":"code","f2ff5e00":"code","45129ccc":"code","ecec72f5":"code","53fd339d":"code","36f3561c":"code","ad669005":"code","9196477b":"code","b9837151":"code","a7552dda":"code","6a9e7087":"code","61b37263":"code","77548281":"code","e106b751":"code","6ebc2b42":"code","90de5b72":"code","78b2f8bb":"code","4dc5cc8d":"markdown","c9677567":"markdown","9ce990d4":"markdown","007bc119":"markdown","54de407d":"markdown","9c83f407":"markdown","eb8ed537":"markdown","1efec650":"markdown","bf7621b5":"markdown","4965c0e0":"markdown","7d8e34b9":"markdown","63a980d6":"markdown","84342b21":"markdown","4f834a7e":"markdown","54de9033":"markdown","af1dba51":"markdown","31fa51e4":"markdown","de5946cb":"markdown","0e40ebf4":"markdown","71da1cce":"markdown","df9b8737":"markdown","67b106ca":"markdown","f8c76b86":"markdown","e776eeaf":"markdown"},"source":{"72369fbf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0473ae4b":"## for geocoding the data\n!pip install country-converter","24d42e87":"## for data manipulation\nimport pandas as pd\nimport json\n\n## for data viz\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport plotly.express as px \n\n## for choropleth map\nimport folium as fol\nfrom folium import Map as fm\n\n## for geocoding the data\nimport country_converter as coco\nimport pycountry as pc # for getting proper country names\nfrom geopy.geocoders import Nominatim # for getting coordinates\nlocator = Nominatim(user_agent = \"project use\") # Nominatim API is a tool to search through OpenStreetMap","2fd2301d":"data_raw = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\", \n                       low_memory = False)","c898fc86":"pd.set_option('display.max_columns', 500) # to get an idea of all the columns\ndata_raw.head(5);","6c54a772":"len(data_raw)","c125936c":"## creating a list of all the column names for later use\ncol_list = data_raw.columns.tolist();","1f27b3bd":"## From col_list I extracted the column names corresponding to the question for later use\nq7_list = ['Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3', 'Q7_Part_4', 'Q7_Part_5', 'Q7_Part_6', 'Q7_Part_7', 'Q7_Part_8', 'Q7_Part_9', 'Q7_Part_10', 'Q7_Part_11', 'Q7_Part_12', 'Q7_OTHER']\nq9_list = ['Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4', 'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9', 'Q9_Part_10', 'Q9_Part_11', 'Q9_OTHER']\nq10_list = ['Q10_Part_1', 'Q10_Part_2', 'Q10_Part_3', 'Q10_Part_4', 'Q10_Part_5', 'Q10_Part_6', 'Q10_Part_7', 'Q10_Part_8', 'Q10_Part_9', 'Q10_Part_10', 'Q10_Part_11', 'Q10_Part_12', 'Q10_Part_13', 'Q10_OTHER']\nq14_list = ['Q14_Part_1', 'Q14_Part_2', 'Q14_Part_3', 'Q14_Part_4', 'Q14_Part_5', 'Q14_Part_6', 'Q14_Part_7', 'Q14_Part_8', 'Q14_Part_9', 'Q14_Part_10', 'Q14_Part_11', 'Q14_OTHER']\nq37_list = ['Q37_Part_1', 'Q37_Part_2', 'Q37_Part_3', 'Q37_Part_4', 'Q37_Part_5', 'Q37_Part_6', 'Q37_Part_7', 'Q37_Part_8', 'Q37_Part_9', 'Q37_Part_10', 'Q37_Part_11', 'Q37_OTHER']\nq39_list = ['Q39_Part_1', 'Q39_Part_2', 'Q39_Part_3', 'Q39_Part_4', 'Q39_Part_5', 'Q39_Part_6', 'Q39_Part_7', 'Q39_Part_8', 'Q39_Part_9', 'Q39_Part_10', 'Q39_Part_11', 'Q39_OTHER']\nq29_B_list = ['Q29_B_Part_1', 'Q29_B_Part_2', 'Q29_B_Part_3', 'Q29_B_Part_4', 'Q29_B_Part_5', 'Q29_B_Part_6', 'Q29_B_Part_7', 'Q29_B_Part_8', 'Q29_B_Part_9', 'Q29_B_Part_10', 'Q29_B_Part_11', 'Q29_B_Part_12', 'Q29_B_Part_13', 'Q29_B_Part_14', 'Q29_B_Part_15', 'Q29_B_Part_16', 'Q29_B_Part_17', 'Q29_B_OTHER']\nq31_B_list = ['Q31_B_Part_1', 'Q31_B_Part_2', 'Q31_B_Part_3', 'Q31_B_Part_4', 'Q31_B_Part_5', 'Q31_B_Part_6', 'Q31_B_Part_7', 'Q31_B_Part_8', 'Q31_B_Part_9', 'Q31_B_Part_10', 'Q31_B_Part_11', 'Q31_B_Part_12', 'Q31_B_Part_13', 'Q31_B_Part_14', 'Q31_B_OTHER']","06292abc":"## filtering for \"data analysts\" and selecting columns\nfilt = (data_raw.loc[: ,'Q5'] == 'Data Analyst') \nfig_data = data_raw.loc[filt, ['Q1','Q5']]","aafd41cf":"## creating the chart\norder = fig_data.loc[:, 'Q1'].value_counts().index.tolist()\n\nfig = sns.catplot(kind = 'count',\n                  data = fig_data,\n                  x = 'Q1',\n                  height = 7,\n                  aspect = 1.5,\n                  order = order,\n                  palette = sns.color_palette('rocket_r'))\n\nfig.set_xlabels('Age Group', size = 15)\nfig.set_ylabels('Number of Data Analysts', size = 15)\nfig.fig.suptitle(\"Data Analysts by age group\", fontweight = 'bold', size = 25)\n\nplt.show()","217f9a19":"## filtering for \"data analysts\" and selecting columns\nfilt = (data_raw.loc[: ,'Q5'] == 'Data Analyst')\nfig_data = data_raw.loc[filt, ['Q2','Q5']]","0b51ca5b":"## creating the chart\ncount_val = [1110, 348, 11, 5, 1] # fig_data.Q2.value_counts().tolist()\n\nlabels = ['Man', 'Woman', 'Prefer not to say', 'Prefer to self-describe', 'Nonbinary'] # fig_data.Q2.value_counts().index.tolist()\n\nfig = px.pie(names = labels,\n             values = count_val,\n             color = labels,\n             color_discrete_map = {'Man': '#95d0fc',\n                                   'Woman':'#ffd1df',\n                                   'Prefer not to say':'#fcb001',\n                                   'Prefer to self-describe':'#fcb001',\n                                   'Nonbinary':'#fcb001'},\n             template = 'ggplot2')\n\nfig.update_layout(title = {'text':'Data Analysts by Genders', 'font': {'size': 24, 'color': 'RoyalBlue'}},\n                  width = 900)\nfig.show()","e6d16d5a":"## filtering only data analysts\nfilt = (data_raw.loc[: ,'Q5'] == 'Data Analyst')\nfig_data = data_raw.loc[filt, ['Q3','Q5']]\n\n## replacing the following country names as they are unusually long\nfig_data.Q3.replace('United States of America', 'USA', inplace = True)\nfig_data.Q3.replace('United Kingdom of Great Britain and Northern Ireland', 'UK', inplace = True)\n\n## removing 'other' row values for countries\nfilt2 = (fig_data.loc[:, 'Q3'] != 'Other')\nfig_data = fig_data.loc[filt2, ['Q3', 'Q5']]\n\n# data for folium map\nfig_data_for_map = fig_data.loc[:, 'Q3'].value_counts().to_frame().reset_index().head(10)\nfig_data_for_map;","a518dda2":"## Getting proper names of the countries and their coordinates for folium map\ndef convert_to_alpha_3(country): # to return alpha_3 code of the country\n    return pc.countries.search_fuzzy(str(country))[0].alpha_3\n\ndef properName(country): # to return proper name of the country\n    return pc.countries.search_fuzzy(str(country))[0].name\n    \ndef lat(alpha_code): # to return latitude of the country\n    return locator.geocode(alpha_code).latitude\n\ndef long(alpha_code): # to return longitude of the country\n    return locator.geocode(alpha_code).longitude\n    \nfig_data_for_map['alpha_codes'] = fig_data_for_map['index'].apply(convert_to_alpha_3)\nfig_data_for_map.replace('UKR', 'GBR', inplace = True) # manually changing the alpha3 code of united kingdom\nfig_data_for_map['Country_name'] = fig_data_for_map['alpha_codes'].apply(properName)\nfig_data_for_map['latitude'] = fig_data_for_map['Country_name'].apply(lat)\nfig_data_for_map['longitude'] = fig_data_for_map['Country_name'].apply(long)\n\nfig_data_for_map;","f2ff5e00":"## creating the chart\norder = fig_data.loc[:, 'Q3'].value_counts().head(10).index.tolist()\n\nfig = sns.catplot(kind = 'count',\n                  data = fig_data,\n                  x = 'Q3',\n                  height = 7,\n                  aspect = 2,\n                  order = order,\n                  palette = sns.color_palette('GnBu_r',10))\n\nfig.set_xlabels('Country', size = 15)\nfig.ax.tick_params(axis = 'x', rotation = 20, labelsize = 15)\nfig.set_ylabels('Number of Data Analysts', size = 15)\nfig.fig.suptitle(\"Data Analysts by country\", fontweight = 'bold', size = 25)\n\nplt.show()","45129ccc":"## loading the geojson file for creating boundaries of the countries which will be needed for choropleth map\nwith open(\"..\/input\/countries-geojson\/countries.geojson\", mode = 'r') as f:\n    countries_geojson = json.load(f)","ecec72f5":"## Creating map using folium\n\n# Base map\nworld_map = fm(zoom_start = 2,\n               location = (48.792102, -6.610949))\n\n# Adding choropleth map on base map\nfol.Choropleth(geo_data = countries_geojson,\n               data = fig_data_for_map, \n               columns = ['alpha_codes', 'Q3'],\n               key_on = 'feature.properties.ISO_A3',\n               fill_opacity = 0.99,\n               fill_color = 'OrRd',\n               nan_fill_color='white',\n               legend_name = \"Number of Data Analysts\").add_to(world_map)\n\n# adding tags on base map\nfor country in range(0, len(fig_data_for_map)):\n    fol.Marker(location = (fig_data_for_map.loc[country, 'latitude'],\n                           fig_data_for_map.loc[country, 'longitude']),\n               tooltip = f'{fig_data_for_map.loc[country, \"Country_name\"]} (No. of DA:{fig_data_for_map.loc[country, \"Q3\"]})').add_to(world_map)\n\nworld_map","53fd339d":"## filtering for \"data analysts\" and selecting columns\nfilt = (data_raw.loc[: ,'Q5'] == 'Data Analyst')\nfig_data = data_raw.loc[filt, ['Q6','Q5']]\nfig_data.Q6.value_counts().index.tolist();","36f3561c":"## creating the chart\n\norder = fig_data.Q6.value_counts().index.tolist()\nplot1 = sns.catplot(kind = 'count',\n                    data = fig_data, \n                    x = 'Q6',\n                    order = order,\n                    palette = sns.color_palette('Purples_r', 10),\n                    height = 7, \n                    aspect = 2)\n\nplot1.fig.suptitle('Coding Experience of Data Analysts',\n                   fontsize = 25,\n                   weight = 'bold',\n                   x = .5,\n                   color = 'RoyalBlue')\nplot1.ax.set_xlabel('Coding Experience in Years',fontsize = 15)\nplot1.ax.set_ylabel('Number Of Data Analysts',fontsize = 15)\n\nplot1.set_xticklabels(fontsize = 11)\nplot1.set_yticklabels(fontsize = 11)\n\nplt.show()","ad669005":"## filtering for \"data analysts\" and selecting columns\nfilt = (data_raw.loc[: ,'Q5'] == 'Data Analyst')\nfig_data = data_raw.loc[filt, ['Q4','Q5']]\nfig_data.Q4.value_counts();","9196477b":"## replacing some values because name is too long\nfig_data.Q4.replace(to_replace = {'Some college\/university study without earning a bachelor\u2019s degree': \"Some College\",\n                    \"No formal education past high school\":\"High School\"},\n                    inplace = True);","b9837151":"## creating the chart\norder = fig_data.loc[:, 'Q4'].value_counts().index.tolist()\n\nfig = sns.catplot(kind = 'count',\n                  data = fig_data,\n                  x = 'Q4',\n                  height = 7,\n                  aspect = 2,\n                  order = order,\n                  palette = sns.color_palette('YlGnBu_r', 10))\n\nfig.set_xlabels('Highest Education', size = 16)\nfig.set_ylabels('Number of Data Analysts', size = 16)\nfig.fig.suptitle(\"Data Analysts by Highest Education\", fontweight = 'bold', size = 25)\n\nfig.set_xticklabels(fontsize = 12)\nfig.set_yticklabels(fontsize = 12)\n\nplt.show()","a7552dda":"## filtering and selecting columns\nfilt = ((data_raw.loc[: ,'Q5'] == 'Data Analyst') &\n        (data_raw.loc[: ,'Q6'].isin(['< 1 years','5-10 years', '10-20 years'])) &\n        (data_raw.loc[:,'Q8'] != 'Other') &\n        (data_raw.loc[:,'Q8'] != 'None'))\n\nfig_data = data_raw.loc[filt, ['Q8','Q6','Q5']]","6a9e7087":"## Creating the figure\norder = fig_data.loc[:, 'Q8'].value_counts().index.tolist()\n\nfig = sns.catplot(kind = 'count',\n                  data = fig_data,\n                  hue = 'Q6',\n                  x = 'Q8',\n                  height = 7,\n                  aspect = 1.5,\n                  order = order,\n                  palette = sns.color_palette('Set1'),\n                  legend_out = False)\n\nfig.set_xlabels('Programming Language', size = 15)\nfig.set_ylabels('Number of Data Analysts', size = 15)\nfig.fig.suptitle(\"Language Recommended By Data Analysts\", fontweight = 'bold', size = 25)\n\nfig.add_legend(title='Experience in Coding', fontsize = 13, loc = 'center right')\n\nplt.show()","61b37263":"## filtering for \"data analysts\" and selecting columns\nfilt = (data_raw.loc[: ,'Q5'] == 'Data Analyst') & (data_raw.loc[:,'Q30'] != 'Other')\nfig_data = data_raw.loc[filt, ['Q30','Q5']]\n\nfig_data.Q30.value_counts();","77548281":"## Creating the figure\norder = fig_data.loc[:, 'Q30'].value_counts().index.tolist()\n\nfig = plt.figure(figsize=(12, 10))\nax = fig.subplots()\nsns.countplot(data = fig_data,\n              y = 'Q30', \n              order = order,\n              ax = ax,\n              palette = sns.color_palette('Blues_r', 25))\n\nax.set_title('Big Data Products used most often by Data Analysts',\n             fontsize = '25',\n             x = 0.4,\n             y = 1.05)\n\nax.set_ylabel('Big Data Product', fontsize = 18)\nax.set_xlabel('Number of Data Analysts', fontsize = 18)\n\nplt.show()","e106b751":"## filtering and selecting columns\nfilt = (data_raw.loc[: ,'Q5'] == 'Data Analyst') & (data_raw.loc[:,'Q32'] != 'Other')\nfig_data = data_raw.loc[filt, ['Q32','Q5']]","6ebc2b42":"## Creating the chart\norder = fig_data.loc[:, 'Q32'].value_counts().index.tolist()\n\nfig = plt.figure(figsize=(12, 10))\nax = fig.subplots()\nsns.countplot(data = fig_data,\n              y = 'Q32', \n              order = order,\n              ax = ax,\n              palette = sns.color_palette('PuRd_r', 16))\n\nax.set_title('BI Products used most often by Data Analysts',\n             fontsize = '25',\n             x = 0.4,\n             y = 1.05)\n\nax.set_ylabel('Business Intelligence Product', fontsize = 18)\nax.set_xlabel('Number of Data Analysts', fontsize = 18)\n\nplt.show()","90de5b72":"## filtering and selecting columns\nfilt = (data_raw.loc[: ,'Q5'] == 'Data Analyst') & (data_raw.loc[:,'Q38'] != 'Other')\nfig_data = data_raw.loc[filt, ['Q38','Q5']]","78b2f8bb":"## creating the chart\norder = fig_data.loc[:, 'Q38'].value_counts().index.tolist()\n\nfig = plt.figure(figsize=(12, 10))\nax = fig.subplots()\nsns.countplot(data = fig_data,\n              y = 'Q38', \n              order = order,\n              ax = ax,\n              palette = sns.color_palette('YlGn_r', 7))\n\nax.set_title('Data Analyzing tools used most often by Data Analysts',\n             fontsize = '25',\n             x = 0.25,\n             y = 1.05)\n\nax.set_ylabel('Data Analyzing Tools', fontsize = 18)\nax.set_xlabel('Number of Data Analysts', fontsize = 18)\n\nplt.show()","4dc5cc8d":"### Analysis:\nA very huge number of computer engineering students graduating each year from India, add that to the growing craze in data science all over the world and we have highest number of Indian kagglers as data analysts. \nWhats strange is the low number of chinese data analysts in this dataset. The reason could be Alibaba Cloud's Tianchi platform which is a chinese alternative to kaggle with over 400,000 strong community. ","c9677567":"## Question7: What is the most favourite big data product of data analysts?","9ce990d4":"### Analysis:\nWith the flexibility and capabilities of handling large data sources of programming languages such as python and R , local development environments are the most popular data analyzing tools among data analysts. Second comes the spreadsheet softwares such as excel and google sheets which makes it easy to analyse data without writing code, but are limited to particular amount of data.","007bc119":"# 1. Importing libraries, loading data and setting pandas options","54de407d":"## Question9: What is the most favourite tool to analyse data of data analysts?","9c83f407":"## Question4: What is the average coding experience of data analysts?","eb8ed537":"## Question8: What is the most favourite BI Tool of data analysts?","1efec650":"# 2. Plan\n+ There's no need for data cleaning and manipulation as dataset is already clean, so I will straight skip to visualizations.\n+ To understand data refer kaggle_survey_2020_methodology.pdf & kaggle_survey_2020_answer_choices.pdf\n+ Since there is so much to infer from this data I will stick to only those questions(columns) which interests me.\n+ The questions that interests me are related to data analytics field.\n+ Overall the questions will include topics related to coding, data vizualisation, big data and business intelligence.\n+ For selecting the questions\/columns I will refer to the pdf which describes questions asked in the survey.\n### The columns which I think will be useful are 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 14, 29-B, 30, 31-B, 32, 37, 38 and 39.","bf7621b5":"### Analysis:\nAs it is clear from the chart that most of the data Analysts who use kaggle have coding experience between 1-5 years. This could be the indicator of rising popularity of python based data analysis libraries in the recent time although python, R or the related libraries in question are by no means \"new\".","4965c0e0":"## Question2: What is the gender ratio of data analysts?","7d8e34b9":"# Table of contents:\n1. **Importing libraries, loading data and setting pandas options**\n2. **Plan**\n3. **Questions that I want answers of from this dataset:**\n    + 1: What age group does most of the data analysts belong to?\n    + 2: What is the gender ratio of data analysts?\n    + 3: Which country have the highest number of data analysts?\n    + 4: What is the average coding experience of data analysts?\n    + 5: What highest education group does data analysts belong to?\n    + 6: What is the most favourite programming language of data analysts?\n    + 7: What is the most favourite big data product of data analysts?\n    + 8: What is the most favourite BI Tool of data analysts?\n    + 9: What is the most favourite tool to analyse data of data analysts?\n    ","63a980d6":"#### Analysis: \nThis field has become popular in the recent times due to increasing job opportunities with high salaries and young aspirants are aware of it, this must be the reason why many of the data analysts are in their 20's and early 30's.","84342b21":"### Analysis:\nA very huge number of computer engineering students graduating each year from India, add that to the growing craze in data science all over the world and we have highest number of Indian kagglers as data analysts. \nWhats strange is the low number of chinese data analysts in this dataset. The reason could be Alibaba Cloud's Tianchi platform which is a chinese alternative to kaggle with over 400,000 strong community. ","4f834a7e":"## Question1: What age group does most of the data analysts belong to?","54de9033":"## Question3: Which country have the highest number of data analysts?","af1dba51":"### Analysis:\nData Analytics is a maths and statistics intensive field which can also require deep understanding of programming languages, so it's clear that many get master\/bachelors degree before they break into the job market. Another factor could be growing competetion among candidates and growing complexity of this field which explains why most of them have master's degree. Reason for low number of \"PHD holder data analysts\" might be, that those who pursue PHD's are more interested in academia\/research rather than corporate jobs.","31fa51e4":"### Analysis:\nThis chart is reflective of the broader category of STEM fields. Be it school, university or workplace, the percentage of women is way less than men in STEM related institutions. What we can do is encourage all the women around us to break the stereo types and pursue STEM fields if they are interested in them.","de5946cb":"## Question5: What highest education group does data analysts belong to?","0e40ebf4":"### Analysis:\nTableau and Power BI are clearly the most popular BI tools used by data analysts followed by Google Data Studio. All three tools are used to create interactive visualizations and dashboards from different types of data sources.","71da1cce":"### Analysis:\nPython is the clear winner among all the experience groups. The reason must be the huge community support for almost all the problems,its a full fledged general programming language, its easy to use and easy to learn and python's huge collection of data science related libraries. SQL comes second because its still the industry standard when it comes to querying large amount of data in relational databases. R comes third which was once the most popular language among statisticians and data analysts but now is losing its popularity.","df9b8737":"## Question6: What is the most favourite programming language of data analysts?","67b106ca":"# ---","f8c76b86":"# 3. Questions that I want answers of from this dataset:\nAs an aspiring data analyst, I would like to know the answers of these following questions. ","e776eeaf":"### Analysis:\nWith MySQL at the top followed by SQL Server, PostgresSQL and Oracle Database, these are the most popular relational database management systems used by data analysts. Then there's MongoDB which is the most popular NoSQL database program among the others of the same category."}}