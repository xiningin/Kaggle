{"cell_type":{"1041fde9":"code","d2a11637":"code","3aafd6e8":"code","482e8756":"code","c1aa9738":"code","67664de9":"code","e5260629":"code","658783f0":"code","64ade2ac":"code","e3cc0376":"code","8357d68e":"code","957ce026":"code","e89fcbb1":"code","f1be4558":"code","f6da2d0b":"code","776dec05":"code","d857ee58":"code","04908f47":"code","1de409de":"code","fe68b760":"markdown","48ee2425":"markdown","81600467":"markdown","aeb5862d":"markdown","e95a1a62":"markdown","7e429771":"markdown","ce734d80":"markdown","6ecd67e0":"markdown","7b94bc98":"markdown","d7962364":"markdown","a63d38cf":"markdown","8b4f8c84":"markdown","811e7ef6":"markdown","ce0756ec":"markdown"},"source":{"1041fde9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport soundfile as sf\nimport librosa\nimport IPython\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings('ignore')","d2a11637":"df = pd.read_csv('\/kaggle\/input\/birdsong-recognition\/train.csv')\ndf['path'] = '\/kaggle\/input\/birdsong-recognition\/train_audio\/'+df['ebird_code']+'\/'+df['filename']","3aafd6e8":"df['secondary'] = df['secondary_labels'].str.replace(r\"\\[|\\]|\\'|\\\"\",\"\").str.split('\\,').apply(lambda x: [i.strip() for i in x])\nsecondary_labels = [item.strip() for sublist in df['secondary'].tolist() for item in sublist if item != '']\nsecondary_labels = pd.Series(secondary_labels, name='secondary_labels')","482e8756":"print(\"Describe\")\nprint(secondary_labels.describe())\n\nprint(\"\\n10 most commonly heard secondary birds\")\nprint(secondary_labels.groupby(by=secondary_labels).count().nlargest(10))\n\nprint(\"\\n10 least commonly heard secondary birds\")\nprint(secondary_labels.groupby(by=secondary_labels).count().nsmallest(10))\n\nsecondary_labels.groupby(by=secondary_labels).count().hist(bins=10);","c1aa9738":"species = df['species'].unique()\nsecondary_species = [arr[1] for arr in secondary_labels.str.split('_').tolist()]\nintersection = [s for s in species if s in secondary_species] ","67664de9":"len(intersection)","e5260629":"def count_intersection(species, arr):\n    count = 0\n    for s in species:\n        if s != '' and s.split(\"_\")[1] in arr:\n            count +=1\n    return count","658783f0":"additional_examples = df[df['secondary'].apply(lambda x: count_intersection(x, intersection) > 0)]['secondary'].tolist()\nadditional_examples = [s for sublist in additional_examples for s in sublist if s.split(\"_\")[1] in intersection]\nadditional_examples = pd.Series(additional_examples)","64ade2ac":"print(\"Count of secondary labels within examples that are also primary targets\")\nprint(additional_examples.describe())\n\nprint(\"\\n10 most common additional examples\")\nprint(additional_examples.groupby(by=additional_examples).count().nlargest(10))\n\nprint(\"\\n10 least common additional examples\")\nprint(additional_examples.groupby(by=additional_examples).count().nsmallest(10))\n\nadditional_examples.groupby(by=additional_examples).count().hist(bins=10);","e3cc0376":"def filter_secondary(arr, species):\n    for bird in arr:\n        if bird != '' and bird.split(\"_\")[1] == species:\n            return True\n    return False","8357d68e":"rewbla = df[df['secondary'].apply(lambda x: filter_secondary(x, 'Red-winged Blackbird'))]\nrewbla['ebird_code'].describe()\nrewbla['ebird_code'].groupby(by=rewbla['ebird_code']).count().nlargest(10)","957ce026":"rewbla_audio, sr = librosa.load('..\/input\/birdsong-recognition\/train_audio\/rewbla\/XC135672.mp3', sr=32000);\nIPython.display.Audio(rewbla_audio, rate=sr)","e89fcbb1":"wilsni1_audio, sr = librosa.load('..\/input\/birdsong-recognition\/train_audio\/wilsni1\/XC185863.mp3', sr=32000);\nwilsni1_audio = wilsni1_audio[17*sr:22*sr]\nIPython.display.Audio(wilsni1_audio, rate=sr)","f1be4558":"melspectrogram_parameters = {\n    \"n_mels\": 128,\n    \"fmin\": 20,\n    \"fmax\": 16000\n}\nrewbla_melspec = librosa.feature.melspectrogram(rewbla_audio, sr=32000, **melspectrogram_parameters)\nrewbla_melspec = librosa.power_to_db(rewbla_melspec).astype(np.float32)\n\nwilsni1_melspec = librosa.feature.melspectrogram(wilsni1_audio, sr=32000, **melspectrogram_parameters)\nwilsni1_melspec = librosa.power_to_db(wilsni1_melspec).astype(np.float32)\n\nfig=plt.figure(figsize=(16, 8))\nfig.add_subplot(1, 2, 1).set_title(\"Red-winged Blackbird\")\nplt.imshow(rewbla_melspec)\nfig.add_subplot(1, 2, 2).set_title(\"Wilson's Snipe\")\nplt.imshow(wilsni1_melspec)\nplt.show()","f6da2d0b":"rewbla=rewbla[rewbla.latitude!='Not specified']\nfig = go.Figure()\nfig.add_trace(go.Scattergeo(\n        lon = rewbla['longitude'],\n        lat = rewbla['latitude'],\n        text = rewbla['ebird_code'],\n        name='Co-occuring Locations',\n        marker = dict(\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode = 'area',\n        )))\n\n\nfig.add_trace(go.Scattergeo(\n        lon = df[df['ebird_code'] == 'rewbla']['longitude'],\n        lat = df[df['ebird_code'] == 'rewbla']['latitude'],\n        text = df[df['ebird_code'] == 'rewbla']['ebird_code'],\n        name='Red-winged Blackbird Locations',\n        marker = dict(\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode = 'area',\n        )))\n\nfig.update_layout(\n        title_text = 'Geographical Correlation between Red-winged Blackbird and co-occuring species',\n        showlegend = True,\n        geo = dict(\n            landcolor = 'rgb(217, 217, 217)',\n            scope=\"north america\",\n        )\n    )\n\nfig.show()","776dec05":"ebird_dict = {}\nfor bird in intersection:\n    ebird_dict[bird] = df[df['species'] == bird]['ebird_code'].iloc[0]","d857ee58":"secondary_dict = {}\nfor index, row in df.iterrows():\n    s = [ebird_dict[bird.split(\"_\")[1]] for bird in row['secondary'] if bird != \"\" and bird.split(\"_\")[1] in ebird_dict]\n    secondary_dict[row['filename']] = s","04908f47":"import pickle\nwith open('secondary_ebird.pkl', 'wb') as f:\n    pickle.dump(secondary_dict, f)","1de409de":"# to load it, use the following snippet\n# secondary_dict = {}\n# with open(PATH, 'rb') as f:\n#     secondary_dict = pickle.load(f)","fe68b760":"First, we notice that there are A LOT of secondary labels - 21259 of them. Amongst those labels, there is quite an imbalance here - some birds appear quite often as secondary labels, but a large number of birds only appear once. Next, we see how many of these secondary labels are also \"primary\" labels in the dataset","48ee2425":"It looks like the red-winged blackbird and Wilson's snipe commonly are heard together. Let's play one of the overlapping clips and see if we can hear the red-winged blackbird within it. First, this is what a red winged blackbird sounds like","81600467":"# Let's look at the red-winged blackbird in more detail\nFirst, we look at what other birds the red-winged blackbird is commonly featured with.","aeb5862d":"# Overview\nLet's look at the \"secondary labels\" provided in train.csv. These secondary labels describe other birds also heard in the clip, apart from the target \"primary\" label. Hopefully this notebook can help us understand what these secondary labels are and how to handle them.\n\nTLDR: 202\/264 species have overlap between secondary and primary labels. i.e. suppose some audio clip has label 'aldfly', representing the alder flycatcher. Some other audio for a different bird might have alder flycatcher as a secondary label - this occurs in 202 of the target species. See below for more details + implications.\n\nPS - I'm still kinda new here, so any thoughts\/advice would be appreciated!","e95a1a62":"There are 202 species which are in both the train set and are secondary labels! WOW. Keep in mind there are only 264 species we are tasked with predicting! Let's see how many additional secondary labels there are which also belong to species which appear as targets.","7e429771":"Next, let's look at geographic correlation - where are the red-winged blackbird recording's made, compared to recordings for birds it co-occurs with?","ce734d80":"# To be continued\nFor next steps, we may want to figure out the frequency of secondary labels within audio samples which have a different primary target. This can help us decide between the three options above.\n\nIn the meantime, below is a python dict which contains secondary ebird codes to experiment around with! It is indexed by file name, for example 'XC134874.mp3'","6ecd67e0":"# Let's look at summary statistics for the secondary labels","7b94bc98":"It's difficult to tell the presence of the red-winged blackbird visually - around t=50-100, there are some shadows that look similar to the red-winged blackbird's call","d7962364":"Compare that to a snippet with a label of Wilson's Snipe below - notice that faintly, around the 1-2 second mark you can hear the sound from the red-winged-blackbird.","a63d38cf":"So there are 13786 secondary labels which also belong to primary targets. In other words, we have 13786 additional unlabeled examples which we could train on, hidden somewhere within the audio we already have... You'll also notice that of the top 10 secondary labels, only one of them, the white-winged dove, is not a target","8b4f8c84":"# Now what?\n\nLet's take a minute to debrief. We are trying to predict 264 species. 202\/264 of those species have additional occurences in the train set as secondary labels. We now have three main choices as I see it.\n\n* Keep all secondary labels separate and still only predict primary targets\n     * Here, we wonder if this might cause our model too much confusion. It could identify a bird call correctly (since it is present, as a secondary label), but loss would only be computed against the primary labels.\n* Treat secondary labels as primary labels when predicting each clip\n     * This could be tricky. What we want to know is, within a given clip of train audio, how often does each secondary label appear? IF this is high, we could use the \"secondary label\" as a primary label for that clip, since it occurs frequently enough we're likely to catch it within some sample. If it's frequency is low, however, and the clip is long, then if we take a random sample from the clip, chances are it won't contain the secondary label - thus, it wouldn't be good to use it as a prediction target.\n* Include secondary labels but give secondary labels a different weight for target prediction\n    * This seems like a good option - it is a sort of combination between the first two, and helps give the model some recognition for the hard work it's doing predicting those secondary labels. Of course, we have the same concern as in option 2, so we still need to think carefully\n    \nOne last thing to think about is the test set we are scored against. Will a label that is considered a \"secondary label\" in the train audio  be treated as more of a \"primary\" label in the test audio? My hunch is yes, given the example_test_audio - there are many bird calls which appear within the sample 5 second interval in the test example, suggesting some of these \"secondary\" labels will be required to be predicted.","811e7ef6":"Let's visualize the mel spectrogram side by side and see if we notice anything.","ce0756ec":"![63744251-480px.jpg](attachment:63744251-480px.jpg)"}}