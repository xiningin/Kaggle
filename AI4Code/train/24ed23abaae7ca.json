{"cell_type":{"5668d8c0":"code","a078a54c":"code","6c8167a4":"code","2514a4c5":"code","4a2edd51":"code","2170f9d4":"code","52e79815":"code","8ee0d612":"code","1ca9fa4a":"code","cf696a0e":"code","c6e55e3d":"code","3e05fd77":"code","eeff78df":"code","5bd4e030":"code","24eb89af":"code","934978b4":"code","84beaa6a":"code","e657677f":"code","cde6e314":"code","58b7589b":"code","cf6a346b":"code","21b9f63c":"code","db00e1fc":"code","fc4b8dd5":"code","6ab8e8df":"code","7a83d8de":"code","1e205a79":"code","dccfd715":"code","d009d9b4":"code","bac975ec":"code","ad0d0c67":"code","dce90ac0":"code","151a1283":"code","9439a95f":"code","a31810f7":"code","ecda3579":"code","f291da92":"code","349a2b54":"code","26f77b50":"code","2f19216d":"code","7d37ce50":"code","8ab071b7":"code","890671c8":"code","7ee8a8d3":"code","bc4802ce":"code","178bcf8d":"code","05f191c4":"code","2ae7d7b2":"code","50792136":"code","3043af0a":"code","2bb9dbd4":"code","6a559790":"code","e07bcaa8":"code","1b0bf188":"code","90fece7c":"code","3a70d4d1":"code","a5c5ece3":"code","a8ed7dd6":"code","80b72952":"code","c31742b8":"code","5b366cae":"code","7023655d":"code","adabe71c":"code","001b4468":"code","3aa91048":"code","e5f8c423":"code","5977cb18":"code","be75dc03":"code","c45a9e23":"code","cb165dac":"code","2c40dc59":"code","ed18c195":"code","c6ac894f":"markdown","c04fff1f":"markdown","3fc70a93":"markdown","7e2a9b7f":"markdown","0931b688":"markdown","3d81c978":"markdown","a90a2240":"markdown","05313395":"markdown","74701279":"markdown"},"source":{"5668d8c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a078a54c":"#Link to data of CORONAVIRUS GOVERNMENT RESPONSE TRACKER from University of Oxford\nlink = 'https:\/\/raw.githubusercontent.com\/OxCGRT\/covid-policy-tracker\/master\/data\/OxCGRT_latest.csv'\n\n# df_data1 = pd.read_csv('OxCGRT_latest.csv', usecols=[0,2], keep_default_na=True, dtype='str')\ndf_data1 = pd.read_csv(link, usecols=[0,2], keep_default_na=True, dtype='str')\n\n# df_data2 = pd.read_csv('OxCGRT_latest.csv', usecols=[4,5,7,9,11,13,15,17,19,34], keep_default_na=True)\ndf_data2 = pd.read_csv(link, usecols=[5,6,8,10,12,14,16,18,20,35], keep_default_na=True)\n\nprint(df_data2.isna().sum())\n\ndf_data2 = df_data2.fillna(0)\nprint('df_data2.isna().sum()', df_data2.isna().sum())\n\ndf_data2 = df_data2.astype('int32')\n\nprint('df_data2.describe()',df_data2.describe())\n\ndf_data = pd.concat([df_data1, df_data2], axis=1)\nprint('df_data.shape',df_data.shape)\n\ndf_data['Date_'] = pd.to_datetime(df_data.Date, format='%Y%m%d', errors='ignore')\ndel df_data['Date']\n\ndf_data.rename(columns={'Date_':'Date'}, inplace=True)\n\ndf_data_Belgium = df_data[df_data['CountryName']=='France']\ndf_data_Belgium.plot(x='Date',y=[1,3,4,5,6,7,8,9], figsize=(20,5))\nplt.title('France')\nplt.show()\n\ndf_data_Belgium = df_data[df_data['CountryName']=='Belgium']\n\ndf_data_Belgium.plot(x='Date',y=[1,3,4,5,6,7,8,9], figsize=(20,5))\nplt.title('Belgium')\nplt.show()\n\ndf_data_Sweden = df_data[df_data['CountryName']=='Sweden']\n\ndf_data_Sweden.plot(x='Date',y=[1,3,4,5,6,7,8,9], figsize=(20,5))\nplt.title('Sweden')\nplt.show()\n\ndf_data_US = df_data[df_data['CountryName']=='United States']\n\ndf_data_US.plot(x='Date',y=[1,3,4,5,6,7,8,9], figsize=(20,5))\nplt.title('United States')\nplt.show()","6c8167a4":"# collecting the data as one feature in a new df_data_control with country as index and 'control_score' and 'first_action_delay'\n# cumulate the Closing and Controls (C1..C8) per country\n# for countries with Regions cumulate and divide by total number of Regions per Country\n# access the number of days between the first case and the start of the first restriction C2\/C4\/C5\/C6 any come first \ndef count_restrictions(df):\n    '''\n    input df holds alls data of one country\n    country: country we are counting\n    output: \n    '''\n    \n    restrictions = df.columns.values[2:-2]\n    control_score = 0\n    for C in restrictions:\n        control_score += df[C].sum()\n    \n    if len(df[df['ConfirmedCases'] > 0][0:1].Date.ravel()) > 0:\n\n        date_of_fist_case = df[df['ConfirmedCases'] > 0][0:1].Date.ravel()[0]\n        times = []\n        for C in restrictions:\n            #print(C)\n            if len(df[df[C] >=2][0:1].Date.ravel()) == 0:\n                #print(C, 'zero')\n                break\n            else:\n                date = df[df[C] >=2][0:1].Date.ravel()[0]\n            #print(date)\n            diff = date - date_of_fist_case\n            pd.to_timedelta([diff]).astype('timedelta64[h]')[0] # diff = diff.astype('timedelta64[D]')\n            times.append(diff\/np.timedelta64(1,'D'))\n        times = np.asanyarray(times)\n        if len(times) == 0:\n            first_action_delay = 365.0\n        else:\n            first_action_delay = times.min()\n    else:\n        first_action_delay = 365.0\n            \n    return (first_action_delay, control_score )\n    \n\n# collecting the data as one feature in a new df_data_control with country as index and 'control_score' and 'first_action_delay'\n# cumulate the Closing and Controls (C1..C8) per country\n# for countries with Regions cumulate and divide by total number of Regions per Country\n# access the number of days between the first case and the start of the first restriction C2\/C4\/C5\/C6 any come first \n\ncountry_as_index = df_data.CountryName.unique()\ndf_data_control = pd.DataFrame(index=country_as_index, columns=['first_action_delay', 'control_score'])\n\nfor ci in country_as_index:\n    #print(ci)\n    df_country = df_data[df_data.CountryName == ci ].copy()\n    if len(df_country.RegionName.unique()) == 1:\n        first_action_delay, control_score = count_restrictions(df_country)\n        if first_action_delay < 0:\n            first_action_delay = 365\n        df_data_control.at[ci, 'first_action_delay'] = first_action_delay\n        df_data_control.at[ci, 'control_score'] = control_score\n        \n    else:\n        print(ci)\n        regions = df_country.RegionName.unique()\n        print(len(regions))\n        first_action_delays = []\n        control_scores = []\n        numberof_regions = len(regions)\n        for region in regions:\n            df_region = df_data[df_data.RegionName == region].copy()\n            df_region['CountryName'] = df_region.RegionName\n            first_action_delay, control_score = count_restrictions(df_region)\n            first_action_delays.append(first_action_delay)\n            control_scores.append(control_score)\n        cs = (np.asanyarray(control_scores)).mean()\n        control_score = cs\n        first_action_delay = (np.asanyarray(first_action_delays)).mean()\n        df_data_control.at[ci, 'first_action_delay'] = first_action_delay\n        df_data_control.at[ci, 'control_score'] = control_score\n\ndf_data_control.head()","2514a4c5":"df_data_control = df_data_control.astype('float32')\ndf_data_control.info()","4a2edd51":"print(df_data_control[df_data_control.index == 'United States'])\nprint()\nprint(df_data_control[df_data_control.index == 'Belgium'])","2170f9d4":"\n# file_corona = '.\/novel-corona-virus-2019-dataset\/time_series_covid19_deaths_global.csv'\nlink_deaths_raw = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv'\n\ndf_corona_2 = pd.read_csv(link_deaths_raw)\ndf_corona_2.head(2)\n\n# sum up all provinces in one country and only the last date in a column\n\ntemp = df_corona_2.iloc[:,[1,-1]].copy()\ndf_corona = temp.groupby(temp['Country\/Region'], as_index=True).sum().copy()\ndf_corona.head()\n#df_corona = df_corona.drop('1\/23\/20', axis=1)\n#df_corona['Country'] = df_corona.index\ndf_corona.head()\n\n# rename 'Country\/Region' in Country\ndf_corona.reset_index(inplace=True)\ndf_corona.rename(columns={'Country\/Region':'Country'}, inplace=True)\ndf_corona.head(3)","52e79815":"# load all_health data from World Bank\nfile = '\/kaggle\/input\/covid19correlationswithdatafromworldbank\/World_Bank_Data_all_health.csv'\ndf_health = pd.read_csv(file)\ndf_health.head(3)","8ee0d612":"# the total number of different data items are:\n\nprint('Total number of different data items:' ,len(df_health['Series Code'].unique()))\nprint('different data items:', df_health['Series Name'].unique())","1ca9fa4a":"# load all_health data from World Bank\nfile = '\/kaggle\/input\/covid19correlationswithdatafromworldbank\/World_Bank_Data_all_health.csv'\ndf_health = pd.read_csv(file)\ndf_health.head(3)","cf696a0e":"# the total number of different data items are:\n\nprint('Total number of different data items:' ,len(df_health['Series Code'].unique()))\nprint('different data items:', df_health['Series Name'].unique())","c6e55e3d":"# dict with key = country name in World Bank total and value = country name in  data_corona\n\ndict_country_names_data_corona = {\n    'Bahamas, The' : 'Bahamas',\n    'Brunei Darussalam' : 'Brunei',\n    'Congo, Rep.' : 'Congo (Brazzaville)',\n    'Congo, Dem. Rep.'   : 'Congo (Kinshasa)',\n    'Czech Republic' : 'Czechia',\n    'Egypt, Arab Rep.' : 'Egypt',\n    'Gambia, The' : 'Gambia',\n    'Iran, Islamic Rep.' : 'Iran',\n    'Korea, Rep.' : 'Korea, South',\n    'Kyrgyz Republic' : 'Kyrgyzstan',\n    'Lao PDR' : 'Laos',\n    'Russian Federation' : 'Russia',\n    'Slovak Republic' : 'Slovakia',\n    'Syrian Arab Republic' : 'Syria',    \n    'United States' : 'US',\n    'Venezuela, RB' : 'Venezuela',\n    'Yemen, Rep.' : 'Yemen'\n        }","3e05fd77":"def change_name(df, country, dictionary):\n    '''\n    Canges the name from country column in df following the dict\n    input:\n    df:  DataFrame where country names have to be changed\n    country: the column with the country names to be changed\n    dictionary: the dic with old and nuw names\n    \n    output:\n    returns the changed dict with the column 'Country' holding the correct names\n    returns a list with the changed names\n    \n    '''\n\n    list_of_changed_countries = []\n    df['Country'] = df[country]\n    for index in range(df.shape[0]):\n        country_old = df.Country.iloc[index]\n        if country_old in dictionary.keys():\n            new_country = dictionary[country_old]\n            df.Country.iat[index] = new_country\n            list_of_changed_countries.append(country_old)\n            \n    return df, list_of_changed_countries","eeff78df":"# changing the country names\ndf_health , the_old_names = change_name(df_health, 'Country', dict_country_names_data_corona)\n#print(the_old_names)\nprint(len(dict_country_names_data_corona), len(the_old_names))","5bd4e030":"def add_corona_deaths(df_1, df_totals):\n    '''\n    op basis van 'Country' en 'Series Code' wordt df_1 en df_2 samengevoegd in df_totals\n    input = df_1 (df_corona), df_2 (df_health), df_totals\n    output = df_totals\n    '''\n    Series_Codes = df_totals['Series Code'].unique()\n    Countries = df_1['Country'].values\n    index = 0\n    while index < df_totals.shape[0]:\n        for code in Series_Codes[:]:\n            if df_totals['Series Code'].loc[index] == code:\n                country = df_totals['Country'].loc[index]\n                last_date = df_1.columns[1]\n                deaths = df_1[df_1['Country']==country][last_date].ravel()\n                #print(deaths)\n                if deaths.size > 0:\n                    df_totals['deaths'].iat[index] = deaths[0]\n                    #print(df_totals['deaths'].loc[index])\n        index +=1   \n    return df_totals","24eb89af":"df_totals = df_health.copy()\ndf_totals['deaths'] = -1.0\ndf_totals = add_corona_deaths(df_corona, df_totals)","934978b4":"df_totals.sort_values(['Series Code', 'Country'], axis='index', inplace=True)\ndf_totals = df_totals[df_totals['deaths'] >= 0. ].copy()\ndf_totals.reset_index(inplace=True)\ndel df_totals['index']","84beaa6a":"indexes_tot_drop = df_totals[df_totals.Value.isna() ].index.ravel()\nprint(df_totals.shape)\ndf_totals = df_totals.drop(indexes_tot_drop, axis='index')\nprint(df_totals.shape)","e657677f":"df_totals.sort_values(['Series Code', 'Country'], axis='index', inplace=True)\ndf_totals.reset_index(inplace=True)\ndel df_totals['index']\ndf_totals","cde6e314":"# what are the series code\n\nall_Series_Codes = df_totals['Series Code'].unique()\nprint(len(all_Series_Codes))","58b7589b":"# find all indexes that belong to the 'Series Code' per code\ndict_S_Code_indexes = {}\nfor code in all_Series_Codes:\n    df_temp = df_totals[df_totals['Series Code'] == code]\n    dict_S_Code_indexes[code] = df_temp.index.ravel()\n    \n    ","cf6a346b":"for key, value in dict_S_Code_indexes.items():\n    print('Series Code:', key, 'number of countries:', len(value))","21b9f63c":"for country in df_totals.Country.unique():\n    dummy = (df_totals[df_totals.Country == country]['Series Code']=='SP.POP.TOTL')\n    index = dummy[dummy].index.ravel()\n    if len(index) > 0:\n        index= index[0]\n        print(index, ';',country, 'population:', df_totals[index:index+1].Value.ravel()[0])\n    else:\n        print(country, df_totals[df_totals.Country== country])","db00e1fc":"# add a column 'deaths_pp' : number of deaths per 100.000 inhabitants\ndef ad_deaths_per_pop(df):\n    countries = df['Country'].unique()\n    for country in countries:\n        if country == 'Eritrea':\n            population = 6081196. # population of Eritrea is not in the df\n        else:\n            dummy = (df[df_totals.Country == country]['Series Code']=='SP.POP.TOTL')\n            index = dummy[dummy].index.ravel()\n            if len(index) > 0:\n                index= index[0]\n                population = df[index:index+1].Value.ravel()[0]\n            \n        dummy = (df[df.Country == country]['Series Code']=='SP.POP.TOTL')\n            \n        deaths = df[df.Country == country]['deaths'].values[0]\n        population_pp = deaths*100000\/(population)\n        indexes = df[df.Country == country].index .ravel()  \n        df.at[indexes, 'deaths_pp'] = population_pp\n        \n    return df","fc4b8dd5":"# # add a column 'deaths_pp' : number of deaths per 100.000 inhabitants\ndf_totals['deaths_pp'] = -100.\ndf_totals = ad_deaths_per_pop(df_totals)\ndf_totals.head(20)","6ab8e8df":"# normalize unnormalized series : \n# Smoking prevalence, total, ages 15+ : SH.PRV.SMOK\n# Gross domestic product 2019 (millions of US dollars)   :   GDP_USdollars\n# Population ages 65 and above, total     : SP.POP.65UP.TO\nseries_to_normalize = ['GDP_USdollars', 'SP.POP.65UP.TO']\n\n\nfor index in df_totals.index:\n    if df_totals['Series Code'].loc[index] in series_to_normalize:\n        scode = df_totals['Series Code'].loc[index]\n        country = df_totals.Country.loc[index]\n        dummy = (df_totals[df_totals.Country == country]['Series Code'] == 'SP.POP.TOTL')\n        if len(dummy[dummy].index.ravel()) > 0:\n            index_pop = dummy[dummy].index.ravel()[0]\n            population = df_totals.Value.loc[index_pop]\n            value = df_totals.Value.loc[index]\n            #print(value)\n            new_value = value*100 \/ population\n            #print(new_value)\n        else:\n            new_value = 0.\n        df_totals['Value'].at[index] = new_value\n\n\nimport seaborn as sns\n#sns.set_theme(style=\"ticks\")\n#A = dict_S_Code_indexes[all_Series_Codes[0]].ravel()\nB = dict_S_Code_indexes[all_Series_Codes[27]].ravel()\n#C = dict_S_Code_indexes[all_Series_Codes[29]].ravel()\nD = dict_S_Code_indexes[all_Series_Codes[30]].ravel()\nE = dict_S_Code_indexes[all_Series_Codes[31]].ravel()\nindexes = np.concatenate((B,D,E), axis=0)\n\n\n# Show the results of a linear regression within each dataset\npl  = sns.lmplot(x=\"deaths\", y=\"Value\", col=\"Series Code\", hue=\"Series Name\", data=df_totals.loc[indexes],\n           col_wrap=2, ci=None, palette=\"muted\", height=4, sharey=False,\n           scatter_kws={\"s\": 50, \"alpha\": 1})\n\nplt.savefig('corona_health_exp_3.jpg')","7a83d8de":"import seaborn as sns\n#sns.set_theme(style=\"ticks\")\nA = dict_S_Code_indexes[all_Series_Codes[1]].ravel()\nB = dict_S_Code_indexes[all_Series_Codes[2]].ravel()\nC = dict_S_Code_indexes[all_Series_Codes[3]].ravel()\nD = dict_S_Code_indexes[all_Series_Codes[4]].ravel()\nE = dict_S_Code_indexes[all_Series_Codes[5]].ravel()\nF = dict_S_Code_indexes[all_Series_Codes[6]].ravel()\nG = dict_S_Code_indexes[all_Series_Codes[7]].ravel()\nindexes = np.concatenate((A,B,C,D,E,F,G), axis=0)\n\n# Show the results of a linear regression within each dataset\npl  = sns.lmplot(x=\"deaths\", y=\"Value\", col=\"Series Code\", hue=\"Series Name\", data=df_totals.loc[indexes],\n           col_wrap=2, ci=None, palette=\"muted\", height=4, sharey=False,\n           scatter_kws={\"s\": 50, \"alpha\": 1})\n\n# plt.savefig('corona_health_exp2.jpg')","1e205a79":"import seaborn as sns\n#sns.set_theme(style=\"ticks\")\nA = dict_S_Code_indexes[all_Series_Codes[8]].ravel()\nB = dict_S_Code_indexes[all_Series_Codes[9]].ravel()\nC = dict_S_Code_indexes[all_Series_Codes[10]].ravel()\nD = dict_S_Code_indexes[all_Series_Codes[11]].ravel()\nE = dict_S_Code_indexes[all_Series_Codes[12]].ravel()\nF = dict_S_Code_indexes[all_Series_Codes[13]].ravel()\nG = dict_S_Code_indexes[all_Series_Codes[14]].ravel()\nH = dict_S_Code_indexes[all_Series_Codes[15]].ravel()\n\nindexes = np.concatenate((A,B,C,D,E,F,G,H), axis=0)\n\n\n# Show the results of a linear regression within each dataset\npl  = sns.lmplot(x=\"deaths\", y=\"Value\", col=\"Series Code\", hue=\"Series Name\", data=df_totals.loc[indexes],\n           col_wrap=2, ci=None, palette=\"muted\", height=4, sharey=False,\n           scatter_kws={\"s\": 50, \"alpha\": 1})\n\n# plt.savefig('corona_health_exp2.jpg')","dccfd715":"import seaborn as sns\n#sns.set_theme(style=\"ticks\")\nE = dict_S_Code_indexes[all_Series_Codes[0]].ravel()\nF = dict_S_Code_indexes[all_Series_Codes[29]].ravel()\nA = dict_S_Code_indexes[all_Series_Codes[16]].ravel()\nB = dict_S_Code_indexes[all_Series_Codes[17]].ravel()\nC = dict_S_Code_indexes[all_Series_Codes[18]].ravel()\nD = dict_S_Code_indexes[all_Series_Codes[19]].ravel()\nindexes = np.concatenate((A,B,C,D,E,F), axis=0)\n\n\n# Show the results of a linear regression within each dataset\npl  = sns.lmplot(x=\"deaths\", y=\"Value\", col=\"Series Code\", hue=\"Series Name\", data=df_totals.loc[indexes],\n           col_wrap=2, ci=None, palette=\"muted\", height=4, sharey=False,\n           scatter_kws={\"s\": 50, \"alpha\": 1})\n\n# plt.savefig('corona_health_exp2.jpg')","d009d9b4":"import seaborn as sns\n#sns.set_theme(style=\"ticks\")\nA = dict_S_Code_indexes[all_Series_Codes[20]].ravel()\nB = dict_S_Code_indexes[all_Series_Codes[21]].ravel()\nC = dict_S_Code_indexes[all_Series_Codes[22]].ravel()\nD = dict_S_Code_indexes[all_Series_Codes[23]].ravel()\nE = dict_S_Code_indexes[all_Series_Codes[24]].ravel()\nF = dict_S_Code_indexes[all_Series_Codes[25]].ravel()\nindexes = np.concatenate((A,B,C,D,E,F), axis=0)\n\n\n# Show the results of a linear regression within each dataset\npl  = sns.lmplot(x=\"deaths\", y=\"Value\", col=\"Series Code\", hue=\"Series Name\", data=df_totals.loc[indexes],\n           col_wrap=2, ci=None, palette=\"muted\", height=4, sharey=False,\n           scatter_kws={\"s\": 50, \"alpha\": 1})\n\n# plt.savefig('corona_health_exp2.jpg')","bac975ec":"import seaborn as sns\n#sns.set_theme(style=\"ticks\")\nA = dict_S_Code_indexes[all_Series_Codes[26]].ravel()\nB = dict_S_Code_indexes[all_Series_Codes[28]].ravel()\nC = dict_S_Code_indexes[all_Series_Codes[32]].ravel()\nD = dict_S_Code_indexes[all_Series_Codes[33]].ravel()\nindexes = np.concatenate((A,B,C,D), axis=0)\n\n\n# Show the results of a linear regression within each dataset\npl  = sns.lmplot(x=\"deaths\", y=\"Value\", col=\"Series Code\", hue=\"Series Name\", data=df_totals.loc[indexes],\n           col_wrap=2, ci=None, palette=\"muted\", height=4, sharey=False,\n           scatter_kws={\"s\": 50, \"alpha\": 1})\n\n# plt.savefig('corona_health_exp2.jpg')","ad0d0c67":"def make_df_wide_in_columns(df, code_col):\n    '''\n    takes in a df with codes in one culumn and puts each column as a group into one new column\n    input: df with series codes in 'code_col'\n    output: df_wide\n    \n    '''\n    df_wide = df.copy()\n    max_size = 0\n    for code in all_Series_Codes:\n        size = len(dict_S_Code_indexes[code])\n        if size > max_size:\n            max_size = size\n            \n    all_Series_Codes_list = all_Series_Codes.tolist()\n    all_Series_Codes_list.append('Country')\n    all_Series_Codes_list.append('deaths')\n    all_Series_Codes_list.append('deaths_pp')\n    \n    df_wide = pd.DataFrame( index=range(max_size+1), \n                           columns=all_Series_Codes_list,\n                          dtype='float')\n    df_wide.Country = df_wide.Country.astype('str')\n    #print(df_wide.shape, df_wide.columns)\n    df_wide = df_wide.fillna(-1.)\n    index_wide = 0\n    for country in df.Country.unique(): \n        country_indexes = df[df.Country == country].index.ravel()\n        df_dummy = df.loc[country_indexes]\n        #print('df_dummy.shape', df_dummy.shape)\n        for index_dummy in df_dummy.index:\n            #print(index_dummy)\n            series_code = df_dummy['Series Code'].loc[index_dummy]\n            value = df_dummy['Value'].loc[index_dummy]\n        \n            df_wide.at[index_wide, series_code] = value\n            df_wide.at[index_wide, 'deaths'] = df['deaths'].loc[index_dummy]\n            df_wide.at[index_wide, 'deaths_pp'] = df['deaths_pp'].loc[index_dummy]\n            df_wide.at[index_wide, 'Country'] = country\n            \n        index_wide += 1\n                \n    return df_wide","dce90ac0":"# make wide df\ndf_totals_wide = make_df_wide_in_columns(df_totals, 'Series Code')\ndf_totals_wide.head()","151a1283":"print('MAX Corona_deaths_per_capita*100000', df_totals_wide['deaths_pp'].max() )\nprint('MIN Corona_deaths_per_capita*100000' , df_totals_wide['deaths_pp'].min()  )\nprint('Mean Corona_deaths_per_capita*100000' , df_totals_wide['deaths_pp'].mean()  )","9439a95f":"# sort on deaths_pp ascending order\ndf_totals_wide = df_totals_wide.sort_values(['deaths_pp'], axis=0)\ndf_totals_wide.tail()","a31810f7":"df_totals_wide = df_totals_wide.reset_index()\ndel df_totals_wide['index']","ecda3579":"y = df_totals_wide['deaths_pp'].values\nx = df_totals_wide['Country'].values\nplt.figure(figsize=(25,10))\n\nplt.rc('xtick', labelsize=20) \nplt.rc('ytick', labelsize=20) \n\nplt.plot(x[-40:], y[-40:])\nplt.grid()\nplt.xticks(x[-40:], rotation=90)\nplt.show()","f291da92":"#import matplotlib\n#import matplotlib.pyplot as plt\n#import numpy as np\n\n\ny = df_totals_wide['deaths_pp'].values\nx = df_totals_wide['Country'].values\ny = y[:]\nx = x[:]\n\nplt.rc('xtick', labelsize=10) \nplt.rc('ytick', labelsize=10) \nwidth = 0.8  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,40))\nrects1 = ax.barh(x, y, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\n#ax.set_ylabel('')\nax.set_title('Covid-19 deaths per 100000 inhabitants')\n#ax.set_xticks(x)\n#ax.set_xticklabels(x)\n\n#ax.legend()\n\n\ndef autolabel(rects, y):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    label_nr = 0\n    for rect in rects:\n        #print(rect, rect.get_y())\n        height = rect.get_height()\n        ax.annotate('{:0.1f}'.format(y[label_nr]),\n                    xy = ( rect.get_width() , rect.get_y() + height\/2 ),\n                    xytext=(20, -5),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n        label_nr += 1\n\n\nautolabel(rects1, y)\n#autolabel(rects2)\n\n#fig.tight_layout()\nplt.savefig('Covid-19 deaths per 100000 inhabitants_2.png')\nplt.show()","349a2b54":"plt.hist(df_totals_wide['deaths_pp'].values, bins = 50)\nplt.show()","26f77b50":"# changing the country names\ndf_data_control.reset_index(inplace=True)\ndf_data_control = df_data_control.rename(columns={'index':'Country'})","2f19216d":"df_data_control , the_old_names = change_name(df_data_control, 'Country', dict_country_names_data_corona)\n#print(the_old_names)\nprint(len(dict_country_names_data_corona), len(the_old_names))","7d37ce50":"# make country the index\ndf_data_control.index = df_data_control.Country.values\n\n","8ab071b7":"# add control data from Oxford Univesity\ndf_totals_wide_control = df_totals_wide.copy()\ndf_totals_wide_control.index = df_totals_wide_control.Country.values\ndf_totals_wide_control['first_action_delay'] = 0.0\ndf_totals_wide_control['control_score'] = 0.0\n\nfor country in df_totals_wide_control.Country :\n    try:\n        first_action_delay = df_data_control.first_action_delay.loc[country]\n        control_score = df_data_control.control_score.loc[country]\n        df_totals_wide_control['first_action_delay'].at[country] = first_action_delay\n        df_totals_wide_control['control_score'].at[country] = control_score\n    except Exception as err:\n        print(err, df_totals_wide_control.shape)\n        df_totals_wide_control = df_totals_wide_control.drop(index=country, axis=index)\n        \n        pass","890671c8":"cols = list(df_totals_wide_control.columns.ravel())\n_ = cols.remove('deaths')\n_ = cols.remove('deaths_pp')","7ee8a8d3":"# make a dict with Series Codes as key and Series Name as value\ndict_Series_Codes = {}\ncodes = df_health['Series Code'].unique()\nnames = df_health['Series Name'].unique()\nfor i in range(len(codes)):\n    dict_Series_Codes[codes[i]] = names[i]\n    \ndict_Series_Codes['first_action_delay'] = 'number of days between first infection case and government action'\ndict_Series_Codes['control_score'] = 'total sum of actions over the total period till now'","bc4802ce":"# display a heatmap of the correlations with covid_19_deaths_per_e5_capita\ncorr = df_totals_wide_control.loc[:,cols].corrwith(df_totals_wide_control.deaths_pp)\ndata_corr = pd.DataFrame(corr)\ndata_corr.sort_values([0],ascending=False ,inplace=True)\n\nf, ax = plt.subplots(figsize=(20, 20))\nax = sns.heatmap(data_corr[:], square=True, annot=True)\nplt.title('Correlations with covid-19 deaths per 100,000')\nplt.show()\n\n","178bcf8d":"df_corr_high = data_corr[data_corr > .4].dropna()[:]\ndf_corr_high","05f191c4":"\nprint('features that have a significant correlation (> .4) with deaths:')\nhigh_corr = data_corr[data_corr > .4].dropna()[:].index\nfor high in high_corr:\n    print(high)\n    print('code:', high, 'name:', dict_Series_Codes[high], 'corr. : %.2f'% df_corr_high.loc[high][0])\n\n","2ae7d7b2":"# \"spearman\" correlations\n\ncorr = df_totals_wide_control.loc[:,cols].corrwith(df_totals_wide_control.deaths_pp, method='spearman')\ndata_corr = pd.DataFrame(corr)\ndata_corr.sort_values([0],ascending=False ,inplace=True)\n\nf, ax = plt.subplots(figsize=(20, 20))\nax = sns.heatmap(data_corr[:], square=True, annot=True)\nplt.title('Correlations with covid-19 deaths per 100,000')\nplt.show()\n\n\n","50792136":"# spearman : positive relation\ndf_corr_high = data_corr[data_corr > .4].dropna()[:]\ndf_corr_high","3043af0a":"# spearman : negative relation\ndf_corr_high = data_corr[data_corr < -.4].dropna()[:]\ndf_corr_high","2bb9dbd4":"df_totals_wide_control.reset_index(inplace=True)\ndel df_totals_wide_control['index']\n_ = cols.remove('Country')","6a559790":"from catboost import CatBoost\nmodel = CatBoost()\nX_train = df_totals_wide_control.loc[:,cols]\ny_train = df_totals_wide_control.loc[:,'deaths_pp'].ravel()\n\nfit = model.fit(X=X_train, y=y_train, verbose=False )","e07bcaa8":"f_importance = model.feature_importances_.ravel()\n\ny = X_train.columns.values\nplt.figure(figsize=(5,10))\nplt.barh(y,f_importance)\nplt.show()","1b0bf188":"df_feature_importance = pd.DataFrame(f_importance, index=y)\ndf_feature_importance = df_feature_importance.sort_values(by=[0] , axis=0, ascending=False)\ndf_feature_importance","90fece7c":"for index in range(len(df_feature_importance)):\n    #print(index, type(index))\n    if df_feature_importance.iloc[index][0] < 2:\n        print('feature %s importance is Lower than 2' %df_feature_importance.index[index])\n        print('importance = %.2f :' %df_feature_importance.iloc[index][0], dict_Series_Codes[df_feature_importance.index[index]])\n        print()\n    else:\n        print('feature %s importance is Higher than 2' %df_feature_importance.index[index])\n        print('importance = %.2f :' %df_feature_importance.iloc[index][0], dict_Series_Codes[df_feature_importance.index[index]])\n        print()","3a70d4d1":"df_totals_wide_control.index = df_totals_wide_control.Country\n","a5c5ece3":"# make list of indexes of the columns except Country and covid-19-deaths covid_19_deaths_per_e5_capita\ncat_features = [] \nlist_of_all_columns = list(df_totals_wide_control.columns.ravel())\n\nlist_not_include = ['Country', 'deaths', 'deaths_pp']\n\nfor col in list_of_all_columns:\n    if col in list_not_include:\n        pass\n    else:\n        cat_features.append(list_of_all_columns.index(col))\ncat_features.sort()\nprint(cat_features)\nprint(list_of_all_columns)","a8ed7dd6":"# run CatBoostRegressor over all countries except one\n\nfrom catboost import CatBoostRegressor\n# run Catboost model \ndf_result = pd.DataFrame(df_totals_wide_control.deaths_pp)\n#df_result = df_result.drop(index='deatsh_pp')\n\ndf_result['prediction'] = 0.0\ncounter = 0\nfor country in df_totals_wide_control.index  :\n    dummy = df_totals_wide_control.copy()\n    #print('dummy.shape', dummy.shape)\n    dummy = dummy.drop(index=country)\n    #print('dummy.shape', dummy.shape)\n    X = dummy.iloc[:,cat_features]\n    #print('X.shape', X.shape)\n    y = dummy.deaths_pp.values\n    #print('len(y)',len(y))\n    model = CatBoostRegressor(random_seed=20)\n    model.fit(X,y, verbose=False, plot=False, )\n    X_test = df_totals_wide_control.loc[country][cat_features].values\n    #print('X_test.shape', X_test.shape)\n    predict = model.predict(X_test)\n    df_result.prediction.at[country] = predict\n    if counter %2 == 0:\n        print(counter, ',', end=\"\")\n    counter +=1","80b72952":"plt.figure(figsize=(20,7))\nX = df_result.index.values\ny1 = df_result.deaths_pp.values\ny2 = df_result.prediction.values\nplt.scatter(X,y1, label='covid 19 deaths per 100 000')\nplt.scatter(X,y2, label='prediction')\nplt.xticks(rotation=90)\nplt.legend()\nplt.show()","c31742b8":"df_result.prediction.mean(), df_result.prediction.std(), df_result.prediction.max(), df_result.prediction.min()","5b366cae":"plt.hist(df_result.prediction, bins=50)\nplt.show()","7023655d":"from sklearn.metrics import mean_absolute_error\nprint('MAE : ', mean_absolute_error(df_result.deaths_pp, df_result.prediction))\n\nfrom sklearn.metrics import r2_score\nprint('R2 score: ',r2_score(df_result.deaths_pp, df_result.prediction))\n\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    \n    ## Note: does not handle mix 1d representation\n    #if _is_1d(y_true): \n    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n\n    return np.mean(np.abs((y_true - y_pred) \/ (y_true+1))) * 100\n\nprint('MAPE',mean_absolute_percentage_error(df_result.deaths_pp, df_result.prediction))","adabe71c":"import warnings\nwarnings.filterwarnings('ignore')","001b4468":"from sklearn.ensemble import ExtraTreesRegressor\nmodel_etr = ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n                    max_samples=None, min_impurity_decrease=0.0,\n                    min_impurity_split=None, min_samples_leaf=1,\n                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n                    n_estimators=100, n_jobs=-1, oob_score=False,\n                    random_state=1496, verbose=0, warm_start=False)\n\ndf_result_etr = pd.DataFrame(df_totals_wide_control.deaths_pp)\n\ndf_result_etr['prediction'] = 0.0\ncounter = 0\nfor country in df_totals_wide_control.index[:]  :\n    dummy = df_totals_wide_control.copy()\n    #print('dummy.shape', dummy.shape)\n    dummy = dummy.drop(index=country)\n    #print('dummy.shape', dummy.shape)\n    X = dummy.iloc[:,cat_features]\n    #print('X.shape', X.shape)\n    y = dummy.deaths_pp.ravel()\n    y = y.reshape(-1,1)\n    #print(y.shape)\n    #print('len(y)',len(y))\n    model_etr.fit(X,y)\n    X_test = df_totals_wide_control.loc[country][cat_features].ravel()\n    #print(X_test.shape)\n    X_test = X_test.reshape(1, len(X_test))\n    #print('X_test.shape', X_test.shape)\n    predict = model_etr.predict(X_test)\n    df_result_etr.prediction.at[country] = predict\n    if counter %3 == 0:\n        print(counter, ',', end=\"\")\n    counter +=1","3aa91048":"plt.figure(figsize=(20,10))\nX = df_result_etr.index.values\ny1 = df_result_etr.deaths_pp.values\ny2 = df_result_etr.prediction.values\nplt.scatter(X,y1, label='covid 19 deaths per 100 000')\nplt.scatter(X,y2, label='prediction')\nplt.xticks(rotation=90)\nplt.grid()\nplt.legend()\nplt.show()","e5f8c423":"df_result_etr.prediction.mean(), df_result_etr.prediction.std(), df_result_etr.prediction.max(), df_result_etr.prediction.min()","5977cb18":"plt.hist(df_result_etr.prediction, bins=50)\nplt.show()","be75dc03":"from sklearn.metrics import mean_absolute_error\nprint('MAE : ', mean_absolute_error(df_result_etr.deaths_pp, df_result_etr.prediction))\n\nfrom sklearn.metrics import r2_score\nprint('R2 score: ',r2_score(df_result_etr.deaths_pp, df_result_etr.prediction))\n\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    \n    ## Note: does not handle mix 1d representation\n    #if _is_1d(y_true): \n    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n\n    return np.mean(np.abs((y_true - y_pred) \/ (y_true+1))) * 100\n\nmean_absolute_percentage_error(df_result_etr.deaths_pp, df_result_etr.prediction)","c45a9e23":"from sklearn.ensemble import ExtraTreesRegressor\nmodel_etr = ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mae',\n                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n                    max_samples=None, min_impurity_decrease=0.0,\n                    min_impurity_split=None, min_samples_leaf=5,\n                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n                    n_estimators=100, n_jobs=8, oob_score=False,\n                    random_state=1496, verbose=0, warm_start=True)\n\ndf_result_etr = pd.DataFrame(df_totals_wide_control.deaths_pp)\n\ndf_result_etr['prediction'] = 0.0\ncounter = 0\nfor country in df_totals_wide_control.index[:]  :\n    dummy = df_totals_wide_control.copy()\n    #print('dummy.shape', dummy.shape)\n    dummy = dummy.drop(index=country)\n    #print('dummy.shape', dummy.shape)\n    X = dummy.iloc[:,cat_features]\n    #print('X.shape', X.shape)\n    y = dummy.deaths_pp.ravel()\n    y = y.reshape(-1,1)\n    #print(y.shape)\n    #print('len(y)',len(y))\n    model_etr.fit(X,y)\n    X_test = df_totals_wide_control.loc[country][cat_features].ravel()\n    #print(X_test.shape)\n    X_test = X_test.reshape(1, len(X_test))\n    #print('X_test.shape', X_test.shape)\n    predict = model_etr.predict(X_test)\n    df_result_etr.prediction.at[country] = predict\n    if counter %3 == 0:\n        print(counter, ',', end=\"\")\n    counter +=1","cb165dac":"plt.figure(figsize=(20,7))\nX = df_result_etr.index.values\ny1 = df_result_etr.deaths_pp.values\ny2 = df_result_etr.prediction.values\nplt.scatter(X,y1, label='covid 19 deaths per 100 000')\nplt.scatter(X,y2, label='prediction')\nplt.xticks(rotation=90)\nplt.grid()\nplt.legend()\nplt.show()","2c40dc59":"df_result_etr.prediction.mean(), df_result_etr.prediction.std(), df_result_etr.prediction.max(), df_result_etr.prediction.min()","ed18c195":"from sklearn.metrics import mean_absolute_error\nprint('MAE : ', mean_absolute_error(df_result_etr.deaths_pp, df_result_etr.prediction))\n\nfrom sklearn.metrics import r2_score\nprint('R2 score: ',r2_score(df_result_etr.deaths_pp, df_result_etr.prediction))\n\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    \n    ## Note: does not handle mix 1d representation\n    #if _is_1d(y_true): \n    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n\n    return np.mean(np.abs((y_true - y_pred) \/ (y_true+1))) * 100\n\nMAPE = mean_absolute_percentage_error(df_result_etr.deaths_pp, df_result_etr.prediction)\nprint('MAPE', MAPE)","c6ac894f":"# 1. load data from CORONAVIRUS GOVERNMENT RESPONSE TRACKER from University of Oxford","c04fff1f":"# Load the data from Wold Bank","3fc70a93":"# Make Series in colmuns","7e2a9b7f":"# load Covid-19 data ","0931b688":"# 2. Load the data from Wold Bank","3d81c978":"This notebook wants to see if it can find relations between the covid-19 deaths in a country and features \nthat reflect the countries public-health policies like immunization, health expenditures (both government and private) , Mamaria, tuberculosis, smoking, poverty, number of undernourished, GDP.\nAlso population density and % of people living in urban areas.  \n  \nAccording to Our World in Data:\nhttps:\/\/ourworldindata.org\/coronavirus#deaths-due-to-covid-19\n\nQuote: \n\n    1. the actual total death toll from COVID-19 is likely to be higher than the number of confirmed deaths \u2013 this is due to limited testing and problems in the attribution of the cause of death; the difference between reported confirmed deaths and total deaths varies by country  \n    2. how COVID-19 deaths are recorded may differ between countries (e.g. some countries may only count hospital deaths, whilst others have started to include deaths in homes)  \n    3. the reported death figures on a given date does not necessarily show the number of new deaths on that day: this is due to delays in reporting.","a90a2240":"# Merge health data with covid-19 death cases","05313395":"# The country names in both DataFrames are not the same\nMake a dict with names to be changed as keys ","74701279":"### There are 3 features that have a correlation with death (lager than .4)\n### URBAN_POP, SH.XPD.GHED.GE.ZS, SH.XPD.GHED.GD.ZS"}}