{"cell_type":{"763c0b5d":"code","799711e0":"code","06b7e3f7":"code","1adb3ca8":"code","724f7f77":"code","c780c9b8":"code","b12a5b60":"code","d4183073":"code","4f078305":"code","b6cd0ff9":"markdown","76146ecf":"markdown","a31db7df":"markdown","56cdd19a":"markdown","8398a28d":"markdown","ec24e786":"markdown"},"source":{"763c0b5d":"# writing a function to load the json file \n\nimport re\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\n\ndata_file = '..\/input\/arxiv\/arxiv-metadata-oai-snapshot.json'\n\n\"\"\" Using `yield` to load the JSON file in a loop to prevent Python memory issues if JSON is loaded directly\"\"\"\n\ndef get_metadata():\n    with open(data_file, 'r') as f:\n        for line in f:\n            yield line\n\n            \n            \n# we will consider below 3 categories for training \npaper_categories = [\"cs.AI\", # Artificial Intelligence\n                    \"cs.CV\", # Computer Vision and Pattern Recognition\n                    \"cs.LG\"] # Machine Learning\n\n\n\ndef build_dataset(categories=paper_categories):\n    titles = []\n    abstracts = []\n    metadata = get_metadata()\n    for paper in tqdm(metadata):\n        paper_dict = json.loads(paper)\n        category = paper_dict.get('categories')\n        if category in categories:\n            try:\n                year = int(paper_dict.get('journal-ref')[-4:])\n                titles.append(paper_dict.get('title'))\n                abstracts.append(paper_dict.get('abstract').replace(\"\\n\",\"\"))\n            except:\n                pass \n\n    papers = pd.DataFrame({'title': titles,'abstract': abstracts})\n    papers = papers.dropna()\n    papers[\"title\"] = papers[\"title\"].apply(lambda x: re.sub('\\s+',' ', x))\n    papers[\"abstract\"] = papers[\"abstract\"].apply(lambda x: re.sub('\\s+',' ', x))\n\n    del titles, abstracts\n    return papers","799711e0":"papers = build_dataset()","06b7e3f7":"# install simpleT5\n!pip install simplet5","1adb3ca8":"# simpleT5 expects training and validation dataframes to have 2 columns: \"source_text\" and \"target_text\"\npapers = papers[['abstract','title']]\npapers.columns = [\"source_text\", \"target_text\"]\n\n# let's add a prefix to source_text, to uniquely identify kind of task we are performing on the data, in this case --> \"summarize\"\npapers['source_text'] = \"summarize: \"+ papers['source_text']","724f7f77":"# split the data into training and test\nfrom sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(papers, test_size=0.1)","c780c9b8":"# import\nfrom simplet5 import SimpleT5\n\n# instatntiate\nmodel = SimpleT5()\n\n# load\nmodel.from_pretrained(\"t5\",\"t5-base\")\n\n# train\nmodel.train(train_df=train_df, eval_df=test_df, source_max_token_len=512, target_max_token_len=128, max_epochs=5, batch_size=8, use_gpu=True)","b12a5b60":"!ls outputs\/","d4183073":"# load a trained model\nmodel.load_model(\"outputs\/SimpleT5-epoch-4-train-loss-1.1577\", use_gpu=True)\n\n# generate\nmodel.generate(\"summarize: some text you want to test it on\")","4f078305":"# let's see how it performerd:\nsample_abstracts = test_df.sample(10)\n\nfor i, abstract in sample_abstracts.iterrows():\n    print(f\"===== Abstract =====\")\n    print(abstract['source_text'])\n    summary= model.predict(abstract['source_text'])[0]\n    print(f\"\\n===== Actual Title =====\")\n    print(f\"{abstract['target_text']}\")\n    print(f\"\\n===== Generated Title =====\")\n    print(f\"{summary}\")\n    print(\"\\n +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")","b6cd0ff9":"## Dataset Prepration","76146ecf":"**Load the dataset in Pandas DataFrame**","a31db7df":"## Training with simpleT5\u26a1\ufe0f","56cdd19a":"# simpleT5\u26a1\ufe0f: Generating one line summary of ArXiv research papers\nIn this notebook, we will see how to generate one line summary of ArXiv research papers with **simpleT5\u26a1\ufe0f**\n\n**simpleT5\u26a1\ufe0f** is built on top of PyTorch-lightning\u26a1\ufe0f and Transformers\ud83e\udd17 that lets you quickly train your T5 models (in just 3 lines of code). It can be used for several NLP tasks such as summarization, QA, QG, translation, text generation, and more.\n\nLet's get started...","8398a28d":"## Inferencing\n**simpleT5** saves your model at every epoch in \"outputs\" folder (default)","ec24e786":"### Voila \ud83c\udf89 ! you're done"}}