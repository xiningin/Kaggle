{"cell_type":{"efb1026f":"code","3153aab3":"code","06ecaa62":"code","7321819d":"code","bdde4320":"code","70092979":"code","2fea3bfb":"code","8fe9c529":"code","49e38068":"code","62335566":"code","7b4a4baa":"code","ca9e4d64":"code","a5ed29de":"code","7f197452":"code","74332cbf":"code","b26acc02":"code","605ab0e9":"code","8b735559":"code","4c9adc38":"code","a644c6cd":"code","8b9a6c79":"code","fb59d288":"code","da07f029":"code","910b9b49":"code","cda0be42":"code","d12b4e81":"code","b1e059ff":"code","e57216e4":"code","43b16e4a":"markdown","4404cbf7":"markdown","b8ad557a":"markdown","c85dbc15":"markdown","5cc6580d":"markdown","d1d989d7":"markdown","832bfb44":"markdown","f9f9f0c8":"markdown","3dca748e":"markdown","fc2ae246":"markdown","8f291561":"markdown","1e5bd582":"markdown","029f2ae5":"markdown","2561995c":"markdown"},"source":{"efb1026f":"import pandas\nimport numpy as np\nimport pandas as pd\nimport os\nimport keras\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras import regularizers\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","3153aab3":"testfile = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'\ntrainfile = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\n","06ecaa62":"ex = cv2.imread('..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/F\/F1009.jpg')","7321819d":"plt.imshow(ex)\nplt.show()","bdde4320":"ex.shape","70092979":"# **<span style=\"color:#6daa9f;\">2.Image Preprocessing <\/span>**\n","2fea3bfb":"from skimage import color\n\nex1 = cv2.cvtColor(ex, cv2.COLOR_BGR2GRAY)\nplt.imshow(ex1,cmap = 'gray')","8fe9c529":"def denoise(image):\n    \n    denoised_image = cv2.fastNlMeansDenoisingColored(image,None,h=2)\n    \n    return denoised_image\n\ndenoise_ex = denoise(ex)\n\nplt.figure()\nplt.subplot(1,2,1)\nplt.imshow(ex)\nplt.subplot(1,2,2)\nplt.imshow(denoise_ex)","49e38068":"# color of the image\nred = ex[:, :, 0]\nblue= ex[:, :, 1]\ngreen = ex[:,:,2]\n\n\n#set up the figure for plotting\nfig, axs = plt.subplots(2,2, figsize=(20, 10))\n\ncax_00 = axs[0,0].imshow(ex)\naxs[0,0].xaxis.set_major_formatter(plt.NullFormatter())  # kill xlabels\naxs[0,0].yaxis.set_major_formatter(plt.NullFormatter())  # kill ylabels\n\ncax_01 = axs[0,1].imshow(red, cmap='Reds')\nfig.colorbar(cax_01, ax=axs[0,1])\naxs[0,1].xaxis.set_major_formatter(plt.NullFormatter())\naxs[0,1].yaxis.set_major_formatter(plt.NullFormatter())\n\ncax_10 = axs[1,0].imshow(green, cmap='Greens')\nfig.colorbar(cax_10, ax=axs[1,0])\naxs[1,0].xaxis.set_major_formatter(plt.NullFormatter())\naxs[1,0].yaxis.set_major_formatter(plt.NullFormatter())\n\ncax_11 = axs[1,1].imshow(blue, cmap='Blues')\nfig.colorbar(cax_11, ax=axs[1,1])\naxs[1,1].xaxis.set_major_formatter(plt.NullFormatter())\naxs[1,1].yaxis.set_major_formatter(plt.NullFormatter())\nplt.show()\n\n#plot histograms\nfig, axs = plt.subplots(3, sharex=True, sharey=True, figsize=(20, 10))\n\naxs[0].hist(red.ravel(), bins=20, color = 'red')\naxs[0].set_title('Red',fontsize=24)\naxs[1].hist(green.ravel(), bins=20, color = 'green')\naxs[1].set_title('Green',fontsize=24)\naxs[2].hist(blue.ravel(), bins=20, color = 'blue')\naxs[2].set_title('Blue',fontsize=24)\n\nplt.show()","62335566":"labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n                   'Z':25,'space':26,'del':27,'nothing':28}\\\n\ndef load_data():\n    \"\"\"\n    Loads sign language dataset.\n    \"\"\"\n    #size = 60,60\n    images, labels = [], []\n\n    for folder in os.listdir(trainfile):\n        \n        print(folder, end = ' | ')\n        for image in os.listdir(trainfile + \"\/\" + folder):\n            temp_img = cv2.imread(trainfile + '\/' + folder + '\/' + image)\n            temp_img = cv2.resize(temp_img, (32,32))\n            #temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2GRAY)\n            images.append(temp_img)\n            labels.append(labels_dict[folder])\n\n            \n    images = np.array(images)\n    images = images.astype('float32')\/255.0\n    \n    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.05)\n    \n    \n    print()\n    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n    \n    return X_train, X_test, y_train, y_test","7b4a4baa":"X_train, X_test, y_train, y_test = load_data()\n\ny_test_ = keras.utils.to_categorical(y_test,29)\n","ca9e4d64":"y_train_ = keras.utils.to_categorical(y_train,29)\n","a5ed29de":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train_.shape)\nprint(y_test_.shape)","7f197452":"len(y_train)","74332cbf":"# function to create model that receives an optimizer as argument\ndef create_model(optimizer): \n    # create model (The Sequential model is a linear stack of layers)\n    model = Sequential()\n    \n    #add 64 filters \n    #(3,3) means 3x3 dimension that specifies height & width of the 2d convolution window\n    #relu is the name of the activation function to be applied after performing the convolution\n    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n    #max pooling to reduce the spatial dimensions of the output volume &reduce overfitting\n    model.add(MaxPool2D(pool_size=(2, 2)))\n     \n    # Relu to help network learn non-linear decision boundary \n    model.add(Conv2D(128, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    model.add(BatchNormalization())\n\n    model.add(Flatten())\n    model.add(Dropout(0.5))\n    # sigmoid classifier to predict input class label\n    model.add(Dense(1024, activation='sigmoid')) # adds an output layer(dense = regular deeply connected neural network layer)\n    # softmax classifier to predict input class label\n    model.add(Dense(29, activation='softmax'))# adds an output layer #\n    # compile or train the model with the optimizer, loss, & metrics\n    model.compile(optimizer = optimizer, loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\n    # Summarize the model\n    model.summary()\n    return model\n\n","b26acc02":"from keras import callbacks\n\n\ndef fit_model(model,epochs):\n    \n    earlystopping = callbacks.EarlyStopping(monitor = 'val_loss', min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=23, # how many epochs to wait before stopping\n    restore_best_weights = True)\n    \n    model_hist = model.fit(X_train, y_train_, batch_size = 50, epochs = epochs, validation_split = 0.1,callbacks =[earlystopping])\n    \n    return model_hist","605ab0e9":"epochs = 50 \nprint('Train and Baseline Model with adam Optimizer and',epochs,' epochs') \nmodel = create_model(optimizer = 'adam')\nhistory = fit_model(model,epochs)\n","8b735559":"print('Training accuracy:', np.mean(history.history['accuracy']))\nprint('Training loss:', np.mean(history.history['loss']))\nprint('Validation accuracy:', np.mean(history.history['val_accuracy']))\nprint('Validation loss:', np.mean(history.history['val_loss']))","4c9adc38":"def plot_performance(hist_model):\n    \n    plt.plot(hist_model.history['accuracy'])\n    plt.plot(hist_model.history['val_accuracy'])\n    plt.legend(['training accuracy', 'validation accuracy'], loc='lower right')\n    plt.title('accuracy plot - training vs validation')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.show()\n    \n    plt.plot(hist_model.history['loss'])\n    plt.plot(hist_model.history['val_loss'])\n    plt.legend(['training loss', 'validation loss'], loc = 'upper right')\n    plt.title('loss plot - training vs validation')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.show()","a644c6cd":"print(' Model with preprocesisng with adam Optimizer and',epochs,' epochs') \nplot_performance(history)","8b9a6c79":"def evaluate_model(model):\n    test_loss,test_acc = model.evaluate(X_test, y_test_)\n    print('Test accuracy:', test_acc)\n    print('Test loss:', test_loss)\n    \nevaluate_model(model)","fb59d288":"from sklearn.metrics import classification_report\n\nuniq_labels = sorted(os.listdir(trainfile))\n\npredictions = model.predict_classes(X_test)\nprint(classification_report(y_test,predictions))","da07f029":"def load_test_data():\n    images = []\n    names = []\n    size = 64,64\n    for image in os.listdir(testfile):\n        temp = cv2.imread(testfile + '\/' + image)\n        temp = cv2.resize(temp, (32,32))\n        #temp = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n        images.append(temp)\n        names.append(image)\n    images = np.array(images)\n    images = images.astype('float32')\/255.0\n    return images, names\n\ntest_images, test_img_names = load_test_data()\n","910b9b49":"# make predictions on an image and append it to the list (predictions).\npredictions = [model.predict_classes(image.reshape(1,32,32,3))[0] for image in X_test]\n","cda0be42":"def get_labels_for_plot(predictions):\n    predictions_labels = []\n    for i in range(len(predictions)):\n        for ins in labels_dict:\n            if predictions[i] == labels_dict[ins]:\n                predictions_labels.append(ins)\n                break\n    return predictions_labels\n\npredictions_labels_plot = get_labels_for_plot(predictions)","d12b4e81":"len(predictions)","b1e059ff":"# list out keys and values separately\nkey_list = list(labels_dict.keys())\nval_list = list(labels_dict.values())","e57216e4":"predfigure = plt.figure(figsize = (30,30))\ndef plot_image_1(fig, image,label, prediction, predictions_label, row, col, index):\n    fig.add_subplot(row, col, index)\n    plt.axis('off')\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    title = \"prediction : [\" + str(predictions_label) + \"] \"+ \"\\n\"+ key_list[label]\n    plt.title(title)\n    return\n\n \nimage_index = 700\nrow = 8\ncol = 8\nfor i in range(1,(row*col-1)):\n    plot_image_1(predfigure, X_test[image_index],val_list.index(y_test[image_index]),predictions[image_index], predictions_labels_plot[image_index], row, col, i)\n    image_index = image_index + 1\nplt.show()","43b16e4a":"# **<span style=\"color:#6daa9f;\">3.Visualization <\/span>**\n","4404cbf7":"Our image in the dataset is a 3d ndarray with the width and height of 200 and a color image as the size is 3","b8ad557a":"X_train = X_train.reshape(-1,32, 32, 1)\nX_test = X_test.reshape(-1,32,32,1)","c85dbc15":"**Denoising**","5cc6580d":"# **<span style=\"color:#6daa9f;\">1.Import Library & Packages <\/span>**\n","d1d989d7":"## ASL Classifier \n\n\n![](https:\/\/d.newsweek.com\/en\/full\/1394686\/asl-getty-images.jpg)\n\nsource : https:\/\/www.newsweek.com\/asl-day-2019-american-sign-language-1394695\n\n","832bfb44":"# **<span style=\"color:#6daa9f;\">4. Model <\/span>**","f9f9f0c8":"**RGB to GrayScale**","3dca748e":"Plot model performance metrics for model performance","fc2ae246":"# **<span style=\"color:#6daa9f;\">4. Load Data <\/span>**\n\n* Preprocess images(resize,denoise,enhance contrast)\n* Defining a dictionary which contains labels and its mapping to a number which acts as class label.\n* loading image data and labels and then mapping those labels to the dictionary defined before.\n* Normalizing image data.\n* converting labels to one hot format as our keras model don't accept categorical label\n* creating training and test data by splitting original data into 95% of training data and 5% testing data.\n","8f291561":"**Load Test Data**","1e5bd582":"**Viewing the image**","029f2ae5":"**Test Model**","2561995c":"implementing with keras library\nactivation: activation function, relu\nmetrics : accuracy\noptimizer:  adam optimizer\n\nAdam is one of the most effective optimization algorithms for training neural networks.\nSome advantages of Adam is that relatively low memory requirements and usually works well even with little tuning of hyperparameters"}}