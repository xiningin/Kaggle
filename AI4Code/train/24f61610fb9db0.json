{"cell_type":{"068f3880":"code","fc5c7f70":"code","5e0537e2":"code","c9c8d805":"code","30b55330":"code","bf39df5e":"code","c9955a20":"code","206e42af":"code","6b400b33":"code","0acd9595":"code","bd0809d0":"code","abd046cb":"code","306b22c0":"code","9bf2fb89":"code","7a7eafd3":"code","a9d9e597":"code","e039dc41":"code","44112840":"code","3acc224d":"code","e000dbf3":"code","d43404d1":"code","8e68528b":"code","88505805":"code","d66aa5f8":"code","98ef4615":"code","974f0485":"code","346bc2ac":"code","e75003e1":"code","adb048f2":"code","7a5c67e6":"code","4818731e":"code","2efa2595":"code","8eefffe0":"markdown","d000ac3f":"markdown"},"source":{"068f3880":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fc5c7f70":"#importing dataset using pandas\n\ndf = pd.read_csv('\/kaggle\/input\/Advertising.csv')\ndf.head()","5e0537e2":"df = df.drop('Unnamed: 0', axis =1)","c9c8d805":"df.describe()","30b55330":"import matplotlib.pyplot as plt\nimport seaborn as sns","bf39df5e":"sns.pairplot(df)","c9955a20":"df.corr()","206e42af":"sns.heatmap(df.corr(), annot = True)","6b400b33":"label = df['sales']\nfeatures = df.drop('sales', axis =1)","0acd9595":"df.shape","bd0809d0":"for x in features.columns:\n    sns.scatterplot(features[x], label)\n    plt.title(\"Sales vs \" + x)\n    plt.xlabel(x)\n    plt.ylabel(\"sales\")\n    plt.show()\n    ","abd046cb":"for x in features.columns:\n    sns.distplot(features[x], bins ='auto')\n    plt.title(\"Distribution plot of \" + x)\n    plt.xlabel(x)\n    plt.ylabel(\"Frequency\")\n    plt.show()","306b22c0":"from scipy import stats\n\n","9bf2fb89":"fig = plt.figure()\nax1 = fig.add_subplot(211)\nstats.probplot(df['newspaper'], dist= stats.norm, plot=ax1)\nplt.show()","7a7eafd3":"#Transforming the newspaper as the data is skewed towards right\nfig = plt.figure()\nax2 = fig.add_subplot(212)\ny, z= stats.boxcox(df['newspaper'])\nstats.probplot(y, dist= stats.norm, plot=ax2)\nplt.show()","a9d9e597":"#fitting the OLS model\nimport statsmodels.formula.api as sm\n\nmodel1 = sm.ols(formula = \"sales ~ TV+ radio + newspaper\", data = df).fit()\n","e039dc41":"model1.summary()","44112840":"# A high p-value for newspaper signifies that it is not a significant parameter and it should be removed from the model.\n\nmodel2 = sm.ols(formula= \"sales~ TV + radio\", data = df).fit()\nmodel2.summary()","3acc224d":"#testing a model without radio \n\nmodel3 = sm.ols(formula= \"sales ~ TV\", data = df).fit()\nmodel3.summary()","e000dbf3":"#Evaluting few more significant parameter\n\nprint('Parameters: ', model2.params)\nprint('R2: ', model2.rsquared)\nprint('Adj R2: ', model2.rsquared_adj)\nprint('Standard errors: ', model2.bse)","d43404d1":"#predicting sales values \n\ny_pred = model2.predict()\ndf_pred = pd.DataFrame({'Actual' : label, 'Predictions' :y_pred\n                       })\ndf_pred.head()","8e68528b":"#plotting a curve of best fit line by model2\nimport statsmodels.api as sm\nfig = plt.figure(figsize=(12,8))\nfig = sm.graphics.plot_regress_exog(model2, \"TV\", fig=fig)","88505805":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nlm = LinearRegression()\n\ntrain_x,test_x, train_y,test_y = train_test_split(features, label, test_size = 0.2, random_state = 42)\nprint(train_x.shape)\nprint(test_x.shape)\nprint(train_y.shape)\nprint(test_y.shape)","d66aa5f8":"import sklearn.preprocessing as skp\nnwsppr = np.array(train_x[['newspaper']])\nnormalizer = skp.PowerTransformer(method = 'box-cox', standardize = False)\ndf.newspaper = pd.DataFrame(normalizer.fit_transform(nwsppr))\n","98ef4615":"train_x.head()","974f0485":"lm.fit(train_x,train_y)","346bc2ac":"print(lm.score(train_x,train_y))\nprint(lm.coef_)\nprint(lm.intercept_)","e75003e1":"lm.score(test_x,test_y)","adb048f2":"features_2 = features.drop('newspaper', axis = 1)\ntrain_x,test_x, train_y,test_y = train_test_split(features_2, label, test_size = 0.2, random_state = 42)\nprint(train_x.shape)\nprint(test_x.shape)\nprint(train_y.shape)\nprint(test_y.shape)","7a5c67e6":"lm.fit(train_x,train_y)","4818731e":"print(lm.score(train_x,train_y))\nprint(lm.coef_)\nprint(lm.intercept_)","2efa2595":"lm.score(test_x,test_y)","8eefffe0":"**Sklearn Linear Model**","d000ac3f":"### The R-sq and adj_R-sq has sharply declined suggesting that model2 is the best fit wrt our data"}}