{"cell_type":{"d15d6366":"code","7e915eca":"code","74500e43":"code","17040398":"code","8aded692":"code","441510ed":"code","9596b963":"code","2e492a8f":"code","8d016285":"code","d4573953":"code","bc0d4fac":"code","6721c435":"code","0ab4e52a":"code","3a9b1cf8":"code","cefefe92":"code","200d47ea":"code","ffcfb8d6":"code","53bbf27e":"code","95c3abcb":"code","da8aa775":"code","ebc813b4":"code","4a78df7b":"code","d7f1da4f":"code","326d7a2b":"code","4a631522":"code","df1e720c":"code","4a517e8c":"code","74e97b64":"code","a4ff2281":"code","565078a9":"code","d735527b":"code","a7ed9b8d":"markdown","3b03f6d0":"markdown","73dd8151":"markdown","72251527":"markdown","96f741bf":"markdown","4aa64832":"markdown","c8915eda":"markdown","25134330":"markdown","9aebd3e4":"markdown","bfbcaecb":"markdown","a5eabe14":"markdown","421902f1":"markdown"},"source":{"d15d6366":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn.metrics import f1_score\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import l1, l2\nfrom tensorflow.keras.optimizers import RMSprop, Adam, SGD\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, Conv3D, Dense, Dropout, Flatten, InputLayer, Lambda, MaxPool2D, MaxPooling3D, LSTM\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n#, MultiGPUModelCheckpoint\nfrom tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom tensorflow.keras.utils import plot_model\n#, multi_gpu_model\nimport tensorflow as tf","7e915eca":"size_ResNet50 = (224,224,3)\nsize_VGG19 = (224,224,3)\nsize_IncpV3 = (299,299,3)","74500e43":"BATCH_size = 32\nOPT = Adam(learning_rate=0.001) #Adam, SGD, RMSprop, \nLOSS_func = tf.keras.losses.CategoricalCrossentropy() # \nEPOCHS = 20\nMETRICS = [\n      #tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\"),\n      #'acc',\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n]\nweight_decay = 0.001","17040398":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   validation_split = 0.2,\n                                  \n                                   rotation_range=5,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.1,\n                                   shear_range=0.2,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   fill_mode='nearest')","8aded692":"valid_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  validation_split = 0.1)","441510ed":"test_datagen  = ImageDataGenerator(rescale = 1.\/255,\n                                   validation_split=0.1\n                                  )","9596b963":"input_size = (224,224)\n#input_size = (299,299)\n\nimages_train = train_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',\n                                                target_size = input_size, \n                                                class_mode = 'categorical',\n                                                subset = 'training',\n                                                batch_size=BATCH_size)\n\nimages_validation = train_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',\n                                                target_size = input_size,\n                                                class_mode = 'categorical',\n                                                subset = 'validation',\n                                                batch_size=BATCH_size)\n\nimages_test = train_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test',\n                                                target_size = input_size,\n                                                class_mode = 'categorical',\n                                                #subset = 'testing'\n                                                batch_size=BATCH_size)\n","2e492a8f":"#import nibabel as nib\n#import numpy as np","8d016285":"import matplotlib.image as mpimg\nimport random","d4573953":"plt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/MildDemented\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","bc0d4fac":"plt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/ModerateDemented\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","6721c435":"plt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/NonDemented\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","0ab4e52a":"plt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/VeryMildDemented\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","3a9b1cf8":"base_model = VGG19(input_shape=size_VGG19, include_top=False, weights=\"imagenet\")","cefefe92":"#base_model = InceptionV3(input_shape=size_IncpV3, include_top=False, weights='imagenet')\n\n#base_model = ResNet50(input_shape=size_ResNet50, include_top=False, weights='imagenet')","200d47ea":"#Freezing the top layers (pre-trained model)\nfor each_layer in base_model.layers:\n    each_layer.trainable = False","ffcfb8d6":"plot_model(base_model) ","53bbf27e":"# Building Model (v3)\n\nmodel = Sequential()\n\n#model.add(Lambda(lambda image: tf.image.resize(image, input_size)))\nmodel.add(base_model)\n\nmodel.add(Flatten())\n\n\"\"\"\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay), \n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay), \n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\"\"\"\n\"\"\"\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\n\nmodel.add(Dense(128, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\"\"\"\nmodel.add(Dense(128, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\n\nmodel.add(Dense(64, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(32, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(32, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n        #model.add(Lambda(lambda x: tf.abs(x)))\n        #model.add(LSTM(256))\n        #model.add(LSTM(128))\nmodel.add(Dense(4, activation='softmax'))\n","95c3abcb":"plot_model(model)","da8aa775":"model.summary()","ebc813b4":"#input_shape = (None, None, None, 3)","4a78df7b":"\"\"\"\nmodel = Sequential()\n\nmodel.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\nmodel.add(MaxPooling3D(pool_size=(2, 2, 2)))\nmodel.add(BatchNormalization(center=True, scale=True))\nmodel.add(Dropout(0.5))\nmodel.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\nmodel.add(MaxPooling3D(pool_size=(2, 2, 2)))\nmodel.add(BatchNormalization(center=True, scale=True))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(5, activation='softmax'))\n\"\"\"","d7f1da4f":"#plot_model(model)","326d7a2b":"#Checking if there is more than 1 GPU available (This affects the ModelCheckpoint!)\n\"\"\"\nGPU_available = len(os.getenv(\"CUDA_VISIBLE_DEVICES\", \"1\").split(\",\"))\n\nif (GPU_available > 1):\n    model_train = multi_gpu_model(model, GPU_available)\n    checkpoint = MultiGPUModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5',\n                                         base_model=model)\nelse:\n    model_train = model\n    checkpoint = ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5', verbose=1)\n\"\"\"\ncheckpoint = ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5', verbose=1)","4a631522":"#Callbacks\nmy_callbacks = [checkpoint] #EarlyStopping(),","df1e720c":"model.compile(optimizer=OPT, loss=LOSS_func, metrics=METRICS)","4a517e8c":"history = model.fit(images_train ,validation_data=images_validation, epochs = EPOCHS, verbose = 1, callbacks=my_callbacks)","74e97b64":"scores = model.evaluate(images_test)","a4ff2281":"for c in scores:\n    print(c)","565078a9":"print(f\"Val_Loss: {scores[0]}\\nAccuracy: {scores[1]}\\nPrecision: {scores[2]}\\nRecall: {scores[3]}\\nAUC: {scores[4]}\\n\")","d735527b":"\"\"\"\nimport jovian\njovian.commit(project='alzheimer-mri-classif-project')\n\"\"\"","a7ed9b8d":"## Moderate Demented","3b03f6d0":"### Load in the data","73dd8151":"# **Transfer Learning Pre-Trained Model (2D CNNs)**","72251527":"## Mild Demented","96f741bf":"## Hyperparameters and Settings","4aa64832":"# Data Exploration","c8915eda":"### Model (3D CNNs)","25134330":"### **Data Augmentation\/ Dataset splitting**","9aebd3e4":"## Non Demented","bfbcaecb":"## Very Mild Demented","a5eabe14":"### Callbacks and Model Checkpoint","421902f1":"Not ready yet..."}}