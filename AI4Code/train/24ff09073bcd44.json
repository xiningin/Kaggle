{"cell_type":{"986ead5e":"code","7ca5e729":"code","d4a052a0":"code","c71bb575":"code","24c7051a":"code","ac6a9516":"code","c1c3ed03":"code","7e9d7b06":"code","2cde6a47":"code","d9fa63a4":"code","3634ad0a":"code","2286899c":"code","f0997e87":"code","b8bcfe27":"code","ef5a9f8e":"code","2903de07":"code","1ab9945d":"code","65800dda":"code","38366333":"code","3c20799c":"code","b65e4650":"code","11b847f4":"code","d1b8ae65":"code","e6c2a8ac":"code","99ce044a":"code","e0a1f612":"code","b4c155f0":"code","4b0b75ab":"code","1571afd9":"code","895b0c53":"code","583d283c":"code","ca171c16":"code","4a542a02":"code","b8a67278":"code","09097793":"markdown","5b784bab":"markdown","b138746e":"markdown","54a949fa":"markdown","7db067cd":"markdown","f54d22cd":"markdown","5686fba8":"markdown","69477a54":"markdown","bbc33041":"markdown","f901421a":"markdown","d2254ed4":"markdown","ca8a945d":"markdown","93606410":"markdown","8ca806cc":"markdown","42faa446":"markdown","c6d0b7b7":"markdown","68ac1890":"markdown","891c02ce":"markdown","4dd1672b":"markdown","d72c1172":"markdown","46ddffda":"markdown","e0959044":"markdown"},"source":{"986ead5e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()","7ca5e729":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n#train.drop('Cabin', axis=1, inplace=True)\ntrain.head(2)","d4a052a0":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest.head(2)","c71bb575":"print(train.shape)\ntrain.isnull().sum()","24c7051a":"print(test.shape)\ntest.isnull().sum()","ac6a9516":"train.drop('Cabin', axis=1, inplace=True)\ntest.drop('Cabin', axis=1, inplace=True)","c1c3ed03":"train['Title'] = train.Name.str.extract(' ([A-Za-z]+)\\.')\ntest['Title'] = test.Name.str.extract(' ([A-Za-z]+)\\.')\nprint(test.Title.value_counts()) \nprint(train.Title.value_counts())","7e9d7b06":"null_age_train = train[train['Age'].isnull()]\nnull_age_test = test[test['Age'].isnull()]\nprint(null_age_test.Title.value_counts())\nprint(null_age_train.Title.value_counts())","2cde6a47":"age_df = pd.concat([train[['Age', 'Title']], test[['Age', 'Title']]], axis=0)\nnnaa = age_df[age_df['Age'].notnull()]\nnnaa.shape","d9fa63a4":"median_ages = nnaa[['Age', 'Title']].groupby(['Title'], as_index=False).median()\nmedian_ages.set_index('Title', inplace=True)\nprint(median_ages.loc['Mr', 'Age'])\nmedian_ages","3634ad0a":"for title in train.Title:\n    if title == 'Mr':\n        train['Age'].fillna(value=median_ages.loc['Mr', 'Age'], inplace=True)\n    elif title == 'Miss':\n        train['Age'].fillna(value=median_ages.loc['Miss', 'Age'], inplace=True)\n    elif title == 'Mrs':\n        train['Age'].fillna(value=median_ages.loc['Mrs', 'Age'], inplace=True)\n    elif title == 'Master':\n        train['Age'].fillna(value=median_ages.loc['Master', 'Age'], inplace=True)\n    else:\n        train['Age'].fillna(value=median_ages.loc['Dr', 'Age'], inplace=True)","2286899c":"for title in test.Title:\n    if title == 'Mr':\n        test['Age'].fillna(value=median_ages.loc['Mr', 'Age'], inplace=True)\n    elif title == 'Miss':\n        test['Age'].fillna(value=median_ages.loc['Miss', 'Age'], inplace=True)\n    elif title == 'Mrs':\n        test['Age'].fillna(value=median_ages.loc['Mrs', 'Age'], inplace=True)\n    elif title == 'Master':\n        test['Age'].fillna(value=median_ages.loc['Master', 'Age'], inplace=True)\n    else:\n        test['Age'].fillna(value=median_ages.loc['Miss', 'Age'], inplace=True)","f0997e87":"train['Embarked'].fillna(value='S', inplace=True)\n(test[['Pclass','Age', 'Fare', 'Embarked']]).sort_values(by='Age', ascending=False).head(18)\ntest[['Pclass', 'Fare']].groupby(['Pclass'], as_index=False).median()\ntest['Fare'].fillna(value=7.8958, inplace=True)\ntest.loc[152, :]","b8bcfe27":"print(train.isnull().sum())\nprint(test.isnull().sum())","ef5a9f8e":"for title in train.Title:\n    train['Title'] = train['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Mlle', 'Jonkheer', 'Countess', 'Lady', 'Mme',\n                                            'Sir', 'Don', 'Capt'], 'Other')\n    train['Title'] = train['Title'].replace('Ms', 'Miss')\n    \nfor title in test.Title:\n    test['Title'] = test['Title'].replace(['Dr', 'Rev', 'Col', 'Dona',], 'Other')\n    test['Title'] = test['Title'].replace('Ms', 'Miss')","2903de07":"#Correlation between Sex and Survived\nprint(train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean())\nsns.barplot(x='Sex', y='Survived', data=train)","1ab9945d":"#Correlation between Pclass and Survived\nprint(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\nsns.barplot(x='Pclass', y='Survived', data=train)","65800dda":"#Correlation between Embarked and Survived\nprint(train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\nsns.barplot(x='Embarked', y='Survived', data=train)","38366333":"#Correlation between Parch and Survived\nprint(train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean())\nsns.barplot(x='Parch', y='Survived', data=train)","3c20799c":"#Correlation between SibSp and Survived\nprint(train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean())\nsns.barplot(x='SibSp', y='Survived', data=train)","b65e4650":"#Correlation between Title and Survived\nprint(train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\nsns.barplot(x='Title', y='Survived', data=train)","11b847f4":"#Correlation between [Pclass & Sex] and Survived\np_sex = pd.crosstab(train['Pclass'], train['Sex'])\nprint(p_sex)\nsns.factorplot('Sex', 'Survived', hue='Pclass', height=4, aspect=2, data=train)","d1b8ae65":"#selecting the features to train model with\ntrain = train.drop(['PassengerId', 'Name', 'SibSp', 'Ticket'], axis=1)\ntest = test.drop(['Name', 'SibSp', 'Ticket'], axis=1)\n\n#now we map the object dtypes of Sex, Embarked and Title\ntrain['Sex'] = train['Sex'].map({'female': 1, 'male': 0}).astype(int)\ntrain['Embarked'] = train['Embarked'].map({'S':0, 'Q':1, 'C':2}).astype(int)\ntrain['Title'] = train['Title'].map({'Mr':0, 'Mrs':1, 'Miss':2, 'Master':3, 'Other':4}).astype(int)\n\n#test dataset\ntest['Sex'] = test['Sex'].map({'female': 1, 'male': 0}).astype(int)\ntest['Embarked'] = test['Embarked'].map({'S':0, 'Q':1, 'C':2}).astype(int)\ntest['Title'] = test['Title'].map({'Mr':0, 'Mrs':1, 'Miss':2, 'Master':3, 'Other':4}).astype(int)\n","e6c2a8ac":"a_age_fare = train[['Age', 'Fare']]\nb_age_fare = test[['Age', 'Fare']]","99ce044a":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaled_train = scaler.fit_transform(a_age_fare)\nnew_aaf = pd.DataFrame(scaled_train, index=a_age_fare.index, columns=a_age_fare.columns)\n\nscaled_test = scaler.fit_transform(b_age_fare)\nnew_baf = pd.DataFrame(scaled_test, index=b_age_fare.index, columns=b_age_fare.columns)","e0a1f612":"train['Age'] = new_aaf['Age']\ntrain['Fare'] = new_aaf['Fare']\ntrain.head(2)","b4c155f0":"test['Age'] = new_baf['Age']\ntest['Fare'] = new_baf['Fare']\ntest.head(2)","4b0b75ab":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV","1571afd9":"X_train = train.drop('Survived', axis=1)\ny_train = train['Survived']\nX_test = test.drop('PassengerId', axis=1).copy()\n\nX_train.shape, X_test.shape, y_train.shape","895b0c53":"#Logistic Regression\nLog_model = LogisticRegression(solver='lbfgs')\nLog_model.fit(X_train, y_train)\ny_pred_Log = Log_model.predict(X_test)\nLog_reg_accuracy = round(Log_model.score(X_train, y_train) * 100, 2)\nprint(str(Log_reg_accuracy) + '%')","583d283c":"#SVC Model\nsvc_model = SVC(gamma='auto')\nsvc_model.fit(X_train, y_train)\ny_pred_svc = svc_model.predict(X_test)\nsvc_accuracy = round(svc_model.score(X_train, y_train) * 100, 2)\nprint(str(svc_accuracy) + '%')","ca171c16":"dtc = DecisionTreeClassifier()\ngs_dtc = GridSearchCV(dtc,\n                 {'max_depth': range(1, 10),\n                 'min_samples_split': range(5, 51, 5)},\n                 cv=5,\n                 n_jobs=2)\ngs_dtc.fit(X_train, y_train)\nprint(gs_dtc.best_params_)","4a542a02":"dtc_model = gs_dtc.best_estimator_\ndtc_model.fit(X_train, y_train)\ny_dtc = dtc_model.predict(X_test)\ny_dtc_accuracy = round(dtc_model.score(X_train, y_train) * 100, 2)\nprint(str(y_dtc_accuracy) + '%')","b8a67278":"submission = pd.DataFrame({'PassengerId': test['PassengerId'],\n                          'Survived': y_pred_svc})\n\nsubmission.to_csv('Final_submission.csv', index=False)\n#submission.head(4)","09097793":"As we can see, we have no more null values, our data is clean!","5b784bab":"# Feature Selection\nNow we select the features with which to train our model with. From our Feature observation, we can see that the most correlating features to surviving the Titanic are: [Sex, Pclass, Title, Embarked, Parch]. Others such as [SibSp, Ticket, PAssengerId, Ticket] have too many distinct values and therefore dont influence the dataset as much.\n\nThe Age and Fare Columns will be scaled using the StandardScaler","b138746e":"# Feature Importance\nNow we will look at the features of our training set and see the relationship between them and Survival. This step very is important for feature selection in our Classifier","54a949fa":"As you could have guessed, the better the Pclass, the better the chances of survival!","7db067cd":"We can see that the test data has 418 observations with 11 features. Age has 86 null values, Cabin has 327 null values and Fare has 1. In both datasets, the ratio of Null values in the Cabin column is too high compared to the non-null values. \nSo we drop the Cabin column in both datasets, it is of negligible importance.","f54d22cd":"## Data Cleaning\nWe've loaded the data, now lets examine and clean the data","5686fba8":"# Model Selection and Training\nNow for the fun stuff!","69477a54":"It appears the Decision Tree Model performed best. But in reality it still performed marginally worse than the SVC Model\n\n\n\n#### Kaggle Submission","bbc33041":"#### Logistic Regression Model","f901421a":"Bieng a Man on the Titanic was apparently a death sentence!","d2254ed4":"We will now combine the Age and Title of both datasets and create a new dataframe and fill those null values","ca8a945d":"#### SVC Model","93606410":"### Now lets train our models","8ca806cc":"We can see that the training data has 891 observations with 12 features. Age has 177 null values, Cabin has 687 null values and Embarked has 2. Now for the Test data.","42faa446":"Now to fill the missing values for the train and test datasets","c6d0b7b7":"From the this we can see, that a woman in 1st class has almost a 100% chance of Survival, women in 2nd class had a very good chance too. INFACT......Women in 3rd class had a better chance of survival than men in 1st class!!! WOW!!!!! JUST WOW!!!","68ac1890":"#### Train-Test Split","891c02ce":"It seems as though women have a much much higher survival rate than men do!","4dd1672b":"From the data shown here, there is no evidence that suggests SibSp has an influence on Survival.","d72c1172":"Now to handle the rest of the null values in both datasets","46ddffda":"#### Decision Tree Model","e0959044":"So we created a unique class called Title and from the above we can see that there are 4 major titles which are [Mr, Miss,Mrs,Master]. The rest will be later grouped into a class called Other, this should help prevent our model memorizing the data and overfitting. now we'll find which of these Titles has Age as null"}}