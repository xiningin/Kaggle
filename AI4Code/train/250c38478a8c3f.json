{"cell_type":{"5b600544":"code","432d4175":"code","cbd17c00":"code","07a0f777":"code","fecf1a20":"code","85859614":"code","0882fc3f":"code","bc9e8ba7":"code","a7ffb5ce":"code","45ceea45":"markdown","81513508":"markdown","5f93ad50":"markdown"},"source":{"5b600544":"import cv2\nimport torch\nimport urllib.request\n\nimport matplotlib.pyplot as plt\n\nurl, filename = (\"https:\/\/github.com\/pytorch\/hub\/raw\/master\/images\/dog.jpg\", \"dog.jpg\")\nurllib.request.urlretrieve(url, filename)\n","432d4175":"pip install timm","cbd17c00":"model_type = \"DPT_Large\" \nmidas = torch.hub.load(\"intel-isl\/MiDaS\", model_type)","07a0f777":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmidas.to(device)\nmidas.eval()","fecf1a20":"midas_transforms = torch.hub.load(\"intel-isl\/MiDaS\", \"transforms\")\n\nif model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n    transform = midas_transforms.dpt_transform\nelse:\n    transform = midas_transforms.small_transform\n","85859614":"img = cv2.imread(filename)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\ninput_batch = transform(img).to(device)","0882fc3f":"with torch.no_grad():\n    prediction = midas(input_batch)\n\n    prediction = torch.nn.functional.interpolate(\n        prediction.unsqueeze(1),\n        size=img.shape[:2],\n        mode=\"bicubic\",\n        align_corners=False,\n    ).squeeze()\n\noutput = prediction.cpu().numpy()\n","bc9e8ba7":"plt.imshow(img)","a7ffb5ce":"plt.imshow(output)","45ceea45":". Kindly UpVote if you liked it","81513508":"## Useful links\n\nhttps:\/\/pytorch.org\/hub\/intelisl_midas_v2\/\n\nhttps:\/\/www.pyimagesearch.com\/2022\/01\/17\/torch-hub-series-5-midas-model-on-depth-estimation\/","5f93ad50":"# MiDaS Image Depth Prediction"}}