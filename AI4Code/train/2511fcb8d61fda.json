{"cell_type":{"1853a17d":"code","e355d1aa":"code","b25e1cbb":"code","3fd0453e":"code","1958ad49":"code","f4095c46":"code","75a77e36":"code","7e4d1e70":"code","83d49d8e":"code","f85a54d2":"code","64f6aff6":"code","b177bc75":"code","ed953bc8":"code","44b02c9b":"code","6cbaee6d":"code","fd304927":"code","16b6257b":"code","84739199":"code","179549b6":"code","3da0e264":"code","803b58d6":"code","95bc10ba":"code","e4ad73f6":"code","4f830f13":"code","fff87490":"code","8f078bba":"code","09850b33":"code","56fc0c6d":"code","db5c7fdb":"code","a3903e7b":"code","bf0c780d":"code","a6c03d07":"code","ecb6f089":"code","ab3f0b1a":"code","baf2dcef":"code","14e11754":"code","172ff1e9":"code","89a47a2f":"code","d44fe900":"code","3fcd17bf":"code","18f5696c":"code","5f76dce4":"code","df342d9d":"code","f1808790":"code","fe1a93a9":"code","180e4eb2":"code","33500395":"code","44f876fb":"code","81711d46":"code","2f3db6bc":"code","b601173a":"code","dc348c65":"code","9f9f86e1":"code","74b06bae":"markdown","1b702e8f":"markdown","360f1aaa":"markdown","c06c17a8":"markdown","98424941":"markdown","26063163":"markdown","f9395a4e":"markdown","a81509d3":"markdown","f796c21c":"markdown","75bfb593":"markdown","bcd8be61":"markdown","affd744f":"markdown","69b2f435":"markdown","3d2e852b":"markdown","0c43d596":"markdown"},"source":{"1853a17d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e355d1aa":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","b25e1cbb":"data=pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv')","3fd0453e":"data","1958ad49":"data.info()","f4095c46":"data.describe().transpose()","75a77e36":"data.isnull().sum()\n# no null values","7e4d1e70":"columns=data.columns\ncolumns","83d49d8e":"data['class'].value_counts()","f85a54d2":"(data['class'].value_counts())\/len(data['class'])*100","64f6aff6":"plt.figure(figsize=(12,8))\nsns.countplot(data['class'])","b177bc75":"data['class']=data['class'].map({'p':0,'e':1})","ed953bc8":"X=data.drop('class',axis=1)\ny=data['class']","44b02c9b":"X.head()","6cbaee6d":"y.head()","fd304927":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=101)\nprint('size of train data',X_train.shape,y_train.shape)\nprint('size of test data',X_test.shape,y_test.shape)","16b6257b":"columns=[col for col in X_train.columns if X_train[col].dtypes =='object']\ncolumns","84739199":"category_train=[col for col in X_train.columns if X_train[col].dtypes =='object']\ncategory_test=[col for col in X_test.columns if X_test[col].dtypes =='object']","179549b6":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder=LabelEncoder()\nfor col in columns:\n    X_train[col]=label_encoder.fit_transform(X_train[col])\n    X_test[col]=label_encoder.transform(X_test[col])","3da0e264":"X_test","803b58d6":"data","95bc10ba":"X_train","e4ad73f6":"X_test","4f830f13":"y_train","fff87490":"y_test","8f078bba":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping","09850b33":"X_train.shape","56fc0c6d":"model=Sequential()\n\nmodel.add(Dense(22,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(16,activation='relu'))\nmodel.add(Dropout(0.2))\n \nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","db5c7fdb":"early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=12)","a3903e7b":"model.fit(X_train,y_train,validation_data=(X_test,y_test),callbacks=[early_stop],epochs=15,batch_size=256)","bf0c780d":"losses_df=pd.DataFrame(model.history.history)","a6c03d07":"losses_df.head()","ecb6f089":"losses_df[['loss','val_loss']].plot()\n","ab3f0b1a":"losses_df[['accuracy','val_accuracy']].plot()","baf2dcef":"from sklearn.metrics import classification_report,accuracy_score","14e11754":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint","172ff1e9":"model=RandomForestClassifier(n_jobs=-1)","89a47a2f":"parameters={'max_depth':[3,5,7,10,None],\n           'n_estimators':[100,200,300,400,500],\n           'max_features':randint(1,13),\n           'criterion':['gini','entropy'],\n           'bootstrap':[True,False],\n           'min_samples_leaf':randint(1,5)}","d44fe900":"def hyperparameter_tuning(model,parameters,n_of_itern,X_train,y_train):\n    random_search=RandomizedSearchCV(estimator=model,\n                                    param_distributions=parameters,\n                                    n_jobs=-1,\n                                     n_iter=n_of_itern,\n                                     cv=9)\n    random_search.fit(X_train,y_train)\n    params=random_search.best_params_\n    score=random_search.best_score_\n    return params,score","3fcd17bf":"final_params,final_score=hyperparameter_tuning(model,parameters,40,X_train,y_train)","18f5696c":"#this is our final best parameters for random forest classifier\nfinal_params","5f76dce4":"# final accuracy with tuned parameters\nfinal_score","df342d9d":"# import Random Forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# instantiate the classifier \nrfc = RandomForestClassifier(bootstrap=True,\n                             criterion='entropy',\n                            max_depth=None,\n                            max_features=8,\n                            min_samples_leaf=2,\n                            n_estimators=200)\n                             \n                            \n\n# fit the model\nrfc.fit(X_train, y_train)\n\n# Predict the Test set results\ny_pred = rfc.predict(X_test)\n\nprint('Model accuracy is : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","f1808790":"from sklearn.neighbors import KNeighborsClassifier","fe1a93a9":"k=4\nmodel=KNeighborsClassifier(n_neighbors=k)","180e4eb2":"model.fit(X_train,y_train)\npred=model.predict(X_test)","33500395":"print(classification_report(pred,y_test))","44f876fb":"from sklearn import svm","81711d46":"clf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train)","2f3db6bc":"yhat = clf.predict(X_test)\n# SVM has perform better than KNN\nprint(classification_report(yhat,y_test))","b601173a":"from sklearn.linear_model import LogisticRegression","dc348c65":"log_reg=LogisticRegression()\nlog_reg.fit(X_train,y_train)\nlog_predict=log_reg.predict(X_test)","9f9f86e1":"print(classification_report(log_predict,y_test))","74b06bae":"# **Checking Null values**","1b702e8f":"# **It infers Balanced dataset**","360f1aaa":"# Model Building","c06c17a8":"# **1.Neural Network**","98424941":"# RandomizedSearchCV","26063163":"**Categorical features**","f9395a4e":"# Hyperparameter Tuning","a81509d3":"# **Random Forest Classifier**","f796c21c":"# **Random Forest Classifier** ","75bfb593":"# Random Forest Classifier performs best with 100 % accuracy.","bcd8be61":"# **Convert target class to numerical**","affd744f":"# Logistic Regression","69b2f435":"# SVM","3d2e852b":"# **KNN Classifier**","0c43d596":"# **EDA**"}}