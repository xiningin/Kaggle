{"cell_type":{"dc61c3d8":"code","b8406bcc":"code","929c41aa":"code","0e3a6a68":"code","0b3b2ce4":"code","88b2c040":"code","7f7b98e7":"code","8d7bd540":"code","d6fab624":"code","cfa5989c":"code","421fef0f":"code","bc89f6ed":"code","a0dc8403":"code","b7b698ee":"code","82316e1a":"code","556dce77":"code","ed0beb6c":"code","f9f502f6":"code","20b3ab55":"code","6cc5ac97":"code","77604c51":"code","85b3f981":"code","56344a9f":"code","bbc3b818":"code","bfa75a8c":"code","ef27085c":"code","09cdd048":"code","744903e7":"code","7cbc4830":"code","642c7442":"code","a0cc52cb":"code","abeea80f":"code","d6e105cd":"code","fcfb24cb":"code","93e08a39":"code","219e7f1c":"code","8a440e9c":"code","0725591f":"code","c11366a5":"code","c34198a0":"code","555673b5":"code","aca04b37":"code","ca612c67":"code","3344c5c0":"code","bb403dd6":"code","e5fa2a3e":"code","f0751024":"code","57b6baf2":"code","5e17e042":"code","ce0443f6":"code","3ec97826":"code","4cc5bcb7":"code","69508203":"code","6099ddef":"code","3fa6ccbd":"code","5d1aa43d":"markdown","2c54166d":"markdown","b3c51aec":"markdown","a2c0f9a6":"markdown","4f63f238":"markdown","54a4d99b":"markdown","dd96596d":"markdown","a630a240":"markdown","e8001276":"markdown","f60fffa8":"markdown","6a55cd39":"markdown","5149b498":"markdown","894377d7":"markdown","d5680d67":"markdown","58b6078a":"markdown","8f18ae65":"markdown","096213ab":"markdown","dd2a7d49":"markdown","ef23ac36":"markdown"},"source":{"dc61c3d8":"# import the libraries we will use\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b8406bcc":"# read data\ndf = pd.read_csv('..\/input\/brazilian-real-bank-dataset\/MiBolsillo.csv',encoding = 'unicode_escape',sep=';')","929c41aa":"# we take a look at the data\ndf.head(5)","0e3a6a68":"# translate variable names into English\n\ndf.columns = ['id','branch_number','city','state','age','gender','total_credit_card_limit','current_available_limit' ,'date','amount','category_expense','purchase_city','purchase_country']","0b3b2ce4":"df.date = pd.to_datetime(df.date,dayfirst=True)\ndf.head()","88b2c040":"# I create a dataframe as customers with old and new customer names\n\ncustomers = pd.DataFrame(df.id.unique())\ncustomers.columns = ['old_customer_name']\nnew_list = list(range(1, len(customers)+1))\ncustomers['new_customer_name'] = new_list\ncustomers","7f7b98e7":"# I am changing id to understand customers more easily\n\ndf[\"id\"].replace(customers['old_customer_name'].values,customers['new_customer_name'].values, inplace=True)","8d7bd540":"# we have information about our dataset\ndf.info()","d6fab624":"# we need to float the type of amount variable\nfor i in range(0,len(df.amount)):\n    df.amount[i] = df.amount[i].replace('.','').replace(',','.')\n\n#I export values containing '-' in the amount variable as df_amount_nan\ndf_amount_nan = df[df.amount == ' -   ']\n\n# There are '-' values in the amount column. I am deleting theese rows because we can't convert it to the float type with these values\ndf = df[df.amount != ' -   ']\n\n# Now the amount variable is ready to convert to float type.\ndf.amount = df.amount.astype(float)","cfa5989c":"# I am converting the date variable to date_time format\ndf.date = pd.to_datetime(df.date,dayfirst=True)","421fef0f":"# We convert the gender variable to dummy_variable\ndms = pd.get_dummies(df['gender'])\ndf = pd.concat([df,dms],axis=1)\ndf.drop(['gender', 'M'], axis=1,inplace=True)\ndf.rename(columns={'F': 'Female'}, inplace=True)\ndf","bc89f6ed":"# I want to look at the total expense in each category\n\ncateg = df.category_expense.value_counts().sort_values(ascending=False)\n\n\nplt.figure(figsize=(15,10))\nsns.barplot(x=categ.index,y=categ.values)\nplt.xlabel('Cataegories')\nplt.ylabel('Count')\nplt.title(\"Cataegories Count\")\nplt.xticks(rotation= 45);","a0dc8403":"\n# I look at the number of transactions each client has with a credit card\n\nfreq = df.groupby('id')[['amount']].count().sort_values('amount',ascending=False)\nfreq.rename(columns={'amount': 'Frequency'}, inplace=True)\nfreq","b7b698ee":"# I look at the total spending of each customer\ntotal = df.groupby('id')[['amount']].sum().sort_values('amount',ascending=False)\ntotal.rename(columns={'amount': 'Total_spending'}, inplace=True)\ntotal","82316e1a":"# I want to look at the total spending of each customers\n\nplt.figure(figsize=(15,10))\nsns.barplot(x=total.index,y=total['Total_spending'])\nplt.xlabel('Customers')\nplt.ylabel('Total Spending')\nplt.title(\"Total Spending vs Customers\")\nplt.xticks(rotation= 45);","556dce77":"# I add the special days(Carnival,Good Friday,Christmas,Corpus Christi,New Year's Day,Black Friday,Halloween) of Brazil to the dataset\n\ndf['carnival'] = '0'\ndf[\"carnival\"].replace(df[(df.date == '2020-02-24') | (df.date == '2020-02-25') | (df.date == '2019-03-04') | (df.date == '2019-03-05')]['carnival'],'1', inplace=True)\n\ndf['good_friday'] = '0'\ndf[\"good_friday\"].replace(df[(df.date == '2019-04-19') | (df.date == '2020-04-10')]['good_friday'],'1', inplace=True)\n\n\ndf['christmas'] = '0'\ndf[\"christmas\"].replace(df[(df.date == '2019-12-25') | (df.date == '2020-12-25')]['christmas'],'1', inplace=True)\n\n\ndf['corpus_christi'] = '0' \ndf[\"corpus_christi\"].replace(df[(df.date == '2019-06-20') | (df.date == '2020-06-11')]['corpus_christi'],'1', inplace=True)\n\n\ndf['new_year'] = '0'\ndf[\"new_year\"].replace(df[(df.date == '2019-01-01') | (df.date == '2020-01-01')]['new_year'],'1', inplace=True)\n\n\ndf['black_friday'] = '0'\ndf[\"black_friday\"].replace(df[(df.date == '2019-11-29') | (df.date == '2020-11-27')]['black_friday'],'1', inplace=True)\n\n\ndf['halloween'] = '0'\ndf[\"halloween\"].replace(df[(df.date == '2019-10-31') | (df.date == '2020-10-31')]['halloween'],'1', inplace=True)\n\n","ed0beb6c":"# I want to see the total transaction on special days as a barplot\n\nspecial_days = ['carnival','good_friday','christmas','corpus_christi','new_year','black_friday','halloween']\ncounts = []\n\nfor i in special_days:\n    counts.append(df[i].value_counts()[1])\nspecial_days_dict = dict( zip( special_days, counts))\n\n\nplt.figure(figsize=(15,10))\nsns.barplot(x=list(special_days_dict.keys()),y=list(special_days_dict.values()))\nplt.xlabel('Special Days')\nplt.ylabel('Total Transaction')\nplt.title('Total Transaction of Special Days')\nplt.xticks(rotation= 45);","f9f502f6":"# I create data sets covid and pre covid\n\n# pre covid\npre_covid = df[(df.date > '2020-01-01') & (df.date < '2020-03-18')]\n\n#covid\ncovid = df[(df.date >= '2020-03-18')]","20b3ab55":"covid.head()","6cc5ac97":"# Frequency of use\n\ncovid_freq = covid.groupby('id')[['age']].count().sort_values('age',ascending=False)\ncovid_freq.columns = ['frequency']\nprint('average number of transactions frequency: ',covid_freq.frequency.mean())\nprint('max number of transactions frequency: ',covid_freq.frequency.max())\nprint('min number of transactions frequency: ',covid_freq.frequency.min())","77604c51":"plt.figure(figsize=(15,10))\nsns.barplot(x=covid_freq.index,y=covid_freq['frequency'])\nplt.xlabel('Customers')\nplt.ylabel('Frequency of use')\nplt.title(\"The frequency of transactions made by customers during the covid\")\nplt.xticks(rotation= 45);","85b3f981":"# The frequency of using credit card for each customer during covid\ncovid_freq","56344a9f":"covid['category_expense'].value_counts()","bbc3b818":"# Since there is no specific rule, I create the essential and non-essential list myself.\n\nessential_list = ['FARMACIAS','VAREJO','HOSP E CLINICA','SUPERMERCADOS','POSTO DE GAS','TRANS FINANC']\n\nnon_essential_list = ['SERVI\\x82O','M.O.T.O.','ARTIGOS ELETRO','LOJA DE DEPART','VESTUARIO','SEM RAMO','MAT CONSTRUCAO','RESTAURANTE','CIA AEREAS','MOVEIS E DECOR','JOALHERIA','AGENCIA DE TUR','HOTEIS','AUTO PE AS','INEXISTENTE','']","bfa75a8c":"# The transaction amount from the essential list during the COVID\n\ncovid[covid.category_expense.isin(essential_list)]['category_expense'].value_counts()","ef27085c":"# The transaction amount from the non-essential list during the COVID\n\ncovid[covid.category_expense.isin(non_essential_list)]['category_expense'].value_counts()","09cdd048":"# % of essential\nprint('Total spending during corid: ',covid['amount'].sum(),'Brazillian R')\nprint('Total spending in essential category during covid',covid[covid.category_expense.isin(essential_list)]['amount'].sum(),'Brazillian R')\nprint('Essential : %',covid[covid.category_expense.isin(essential_list)]['amount'].sum() * 100 \/ covid['amount'].sum())\nessential_covid = covid[covid.category_expense.isin(essential_list)]['amount'].sum() * 100 \/ covid['amount'].sum()","744903e7":"# % of non essential\nprint('Total spending during corid: ',covid['amount'].sum(),'Brazillian R')\nprint('Total spending in non essential category during covid',covid[covid.category_expense.isin(non_essential_list)]['amount'].sum(),'Brazillian R')\nprint('Non - Essential : %',covid[covid.category_expense.isin(non_essential_list)]['amount'].sum() * 100 \/ covid['amount'].sum())\nnon_essential_covid = covid[covid.category_expense.isin(non_essential_list)]['amount'].sum() * 100 \/ covid['amount'].sum()","7cbc4830":"# Top 3 essential expenses","642c7442":"covid[covid.category_expense.isin(essential_list)]['category_expense'].value_counts()[:3]","a0cc52cb":"# Top 3 non - essential expenses","abeea80f":"covid[covid.category_expense.isin(non_essential_list)]['category_expense'].value_counts()[:3]","d6e105cd":"# The lowest paid spending and category of each customers during covid\n\nfor i in range(1,30):\n    print(covid[covid['id'] == i].sort_values('amount')[:3][['category_expense','amount']].set_index(covid[covid['id'] == i]['id'][:3]))","fcfb24cb":"# The lowest paid spending and category of each customers during covid\n\nfor i in range(1,30):\n    print(covid[covid['id'] == i].sort_values('amount',ascending=False)[:3][['category_expense','amount']].set_index(covid[covid['id'] == i]['id'][:3]))","93e08a39":"pre_covid.head()","219e7f1c":"# Frequency of use\n\npre_covid_freq = pre_covid.groupby('id')[['age']].count().sort_values('age',ascending=False)\npre_covid_freq.columns = ['frequency']\nprint('average number of transactions frequency: ',pre_covid_freq.frequency.mean())\nprint('max number of transactions frequency: ',pre_covid_freq.frequency.max())\nprint('min number of transactions frequency: ',pre_covid_freq.frequency.min())","8a440e9c":"plt.figure(figsize=(15,10))\nsns.barplot(x=pre_covid_freq.index,y=pre_covid_freq['frequency'])\nplt.xlabel('Customers')\nplt.ylabel('Frequency of use')\nplt.title(\"The frequency of transactions made by customers before the covid\")\nplt.xticks(rotation= 45);","0725591f":"# The frequency of using credit card for each customer before covid\npre_covid_freq","c11366a5":"# Since there is no specific rule, I create the essential and non-essential list myself.\n\nessential_list = ['FARMACIAS','VAREJO','HOSP E CLINICA','SUPERMERCADOS','POSTO DE GAS','TRANS FINANC']\n\nnon_essential_list = ['SERVI\\x82O','M.O.T.O.','ARTIGOS ELETRO','LOJA DE DEPART','VESTUARIO','SEM RAMO','MAT CONSTRUCAO','RESTAURANTE','CIA AEREAS','MOVEIS E DECOR','JOALHERIA','AGENCIA DE TUR','HOTEIS','AUTO PE AS','INEXISTENTE','']","c34198a0":"# The transaction amount from the essential list before the COVID\n\npre_covid[pre_covid.category_expense.isin(essential_list)]['category_expense'].value_counts()","555673b5":"# The transaction amount from the non-essential list before the COVID \n\npre_covid[pre_covid.category_expense.isin(non_essential_list)]['category_expense'].value_counts()","aca04b37":"# % of essential\nprint('Total spending before covid: ',pre_covid['amount'].sum(),'Brazillian R')\nprint('Total spending in essential category before covid',pre_covid[pre_covid.category_expense.isin(essential_list)]['amount'].sum(),'Brazillian R')\nprint('Essential : %',pre_covid[pre_covid.category_expense.isin(essential_list)]['amount'].sum() * 100 \/ pre_covid['amount'].sum())\nessential_pre_covid = pre_covid[pre_covid.category_expense.isin(essential_list)]['amount'].sum() * 100 \/ pre_covid['amount'].sum()","ca612c67":"# % of non essential\nprint('Total spending before corid: ',pre_covid['amount'].sum(),'Brazillian R')\nprint('Total spending in non essential category before covid',pre_covid[pre_covid.category_expense.isin(non_essential_list)]['amount'].sum(),'Brazillian R')\nprint('Non - Essential : %',pre_covid[pre_covid.category_expense.isin(non_essential_list)]['amount'].sum() * 100 \/ pre_covid['amount'].sum())\nnon_essential_pre_covid = pre_covid[pre_covid.category_expense.isin(non_essential_list)]['amount'].sum() * 100 \/ pre_covid['amount'].sum()","3344c5c0":"# Top 3 essential expenses","bb403dd6":"pre_covid[pre_covid.category_expense.isin(essential_list)]['category_expense'].value_counts()[:3]","e5fa2a3e":"# Top 3 non - essential expenses","f0751024":"pre_covid[pre_covid.category_expense.isin(non_essential_list)]['category_expense'].value_counts()[:3]","57b6baf2":"# The lowest paid spending and category of each customers before covid\n\nfor i in range(1,30):\n    print(pre_covid[pre_covid['id'] == i].sort_values('amount')[:3][['category_expense','amount']].set_index(pre_covid[pre_covid['id'] == i]['id'][:3]))","5e17e042":"# The lowest paid spending and category of each customers before covid\n\nfor i in range(1,30):\n    print(pre_covid[pre_covid['id'] == i].sort_values('amount',ascending=False)[:3][['category_expense','amount']].set_index(pre_covid[pre_covid['id'] == i]['id'][:3]))","ce0443f6":"freq = pd.concat([covid_freq.sort_index(),pre_covid_freq.sort_index()],axis=1)\nfreq.columns = ['covid_freq','pre_covid_freq']","3ec97826":"# The frequency of using credit card for each customer before covid vs during covid\n\n\nfig, ax = plt.subplots(2,2,sharey=True)\n\n\nax[0,0].plot(pre_covid_freq.sort_index().index,pre_covid_freq.sort_index().values,color='g',marker='o')\nax[0,0].set_title('Pre Covid')\n\n\nax[0,1].plot(covid_freq.sort_index().index,covid_freq.sort_index().values,color='b',marker='o')\nax[0,1].set_title('Covid')\n\nplt.show();","4cc5bcb7":"# The frequency of using credit card for each customer before covid vs during covid\n\nimport plotly.graph_objs as go\n#import chart_studio.plotly as py\n\n\nfig = go.Figure()\nfig.add_trace(go.Box(y=freq.covid_freq, name='The frequency of using credit card for each customer during covid',\n                marker_color = 'indianred'))\nfig.add_trace(go.Box(y=freq.pre_covid_freq, name = 'The frequency of using credit card for each customer before covid',\n                marker_color = 'lightseagreen'))\n\nfig.show()","69508203":"from plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.graph_objs as go\n\n\n# Creating trace1\ntrace1 = go.Scatter(\n                    x = freq.index,\n                    y = freq.covid_freq,\n                    mode = \"lines\",\n                    name = \"Covid Freq\",\n                    marker = dict(color = 'rgba(16, 112, 2, 0.8)'),\n                    text= freq.covid_freq)\n# Creating trace2\ntrace2 = go.Scatter(\n                    x = freq.index,\n                    y = freq.pre_covid_freq,\n                    mode = \"lines+markers\",\n                    name = \"Pre Covidreq\",\n                    marker = dict(color = 'rgba(80, 26, 80, 0.8)'),\n                    text= freq.pre_covid_freq)\ndata = [trace1, trace2]\nlayout = dict(title = 'The frequency of using credit card for each customer before covid vs during covid',\n              xaxis= dict(title= 'Customers',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = data, layout = layout)\niplot(fig)","6099ddef":"df.corr()","3fa6ccbd":"f,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(df.corr(), annot=True, linewidths=0.1,linecolor=\"red\", fmt= '.2f',ax=ax);","5d1aa43d":"<font color='blue'>\n\nAccording to these expenditures, even the lowest expenditures of customers 4,7,10,13,17 and 18. appear high.","2c54166d":"% of essential vs % non-essential expenses. and in Brazilian R$\n","b3c51aec":"<font color='blue'>\n\nAccording to these expenses, the values of the 10th customer are high","a2c0f9a6":"# Thanks \n\n","4f63f238":"<br>Questions:\n1. [What would be the suggested steps to make this Supervised Learning](#1)\n\n1. [What are some of the challenges you oversee from the dataset shared?](#2)\n\n1. [Do you consider a need to apply any preprocessing on the training dataset? If so, why?](#3)\n\n1. [How would you execute data from any one of the indicators (highlighted in yellow on slide 4) for 1 of the profiles mentioned and across one of the 4 time frames referred on that same slide to analyze user consumption trends](#4)\n\n1. [If your were the client \"Bank\" how would you envision a dashboard where all this data is collected, which 3 features from the users' spending behavior do you think they'd be interested in taking a look at and why?](#5)","54a4d99b":"<font color='green'>\n","dd96596d":"<a id=\"2\"><\/a> <br>\n# 2 - What are some of the challenges you oversee from the dataset shared?\n<span style='color:green'> \nI had difficulties to group the customers called Group 3 because it was not in the data the credit card statement payment day.","a630a240":"# FINANCIAL ADVISOR PROJECT ","e8001276":"### Pre Covid","f60fffa8":"<font color='blue'>\nI think we can transfer at least 13,20,26 numbered customers to group 1 :)","6a55cd39":"% of essential vs % non-essential expenses. and in Brazilian R$\n","5149b498":"<span style='color:blue'> \nAs it is seen, the 19th customer is the person who spends the most among the customers.","894377d7":"### During Covid","d5680d67":"## For Group 1","58b6078a":"<a id=\"1\"><\/a> <br>\n# 1 - What would be the suggested steps to make this Supervised Learning Model? \n<font color='green'>\n    \n1. Firstly, data cleaning should be done. (The steps in question 3 are done at this stage) \n1. Train and test data is created according to the size of the data we have (we assume that customers are tagged).  \n1. We start using the logistic regression algorithm, which is the most basic algorithm.We are building our logistic regression model with the data we have\n1. We find the error of our test data with the model we created \n1. Then we need to repeat this process with all the algorithms used in classification problems (Random Forest, Decision Trees, Naive Bayes, SVM, Neural Network) and we have to find a test error in each\n1. Then, in all the algorithms we tried, we select the algorithm that we get the lowest error (I think that tree-based algorithms will be more suitable for our problem)\n1. We subject the algorithm we have chosen to tuning. With the cross-validation method, we are trying to find the best hyperparameter we will get the lowest error\n1. After finding the parameters that give the lowest error, we build our model with those parameters\n1. We can now use this algorithm with future data","8f18ae65":"<a id=\"4\"><\/a> <br>\n# 4 - How would you execute data from any one of the indicators (highlighted in yellow on slide 4) for 1 of the profiles mentioned and across one of the 4 time frames referred on that same slide to analyze user consumption trends ","096213ab":"<font color='blue'>\nThis chart shows us some things, but it is not right to compare the total transactions made on special days with this chart only. For example, we can look at the total number of transactions 1 week before the special days (not for black friday).","dd2a7d49":"<a id=\"3\"><\/a> <br>\n# 3 - Do you consider a need to apply any preprocessing on the training dataset? If so, why?\n\n<font color='green'>\n\n* Converting the date variable to DateTime variable so that we can operate using the date\n    \n* There are values that cannot be used in the Amount variable, such as \u2018-\u2018, we need to fill or destroy them. \n    \n* The use of \",\" and \".\" In the Amount variable is wrong, we need to edit them.\n    \n* We need to convert the Amount variable to float\n    \n* We need to convert the Gender variable to the dummy variable \n    \n* [OPTIONAL] If we want to control the expenditures made on special days, we need to add the days like black friday, national holidays, religious holidays, special days to the data set (for example, creating a variable called black_friday and making the values \u200b\u200bof black friday in the dataset as 1 other days 0)\n    \n* [OPTIONAL] dollar rates can be added to the dataset (spending may decrease on days when the dollar increases)\n    \n* [OPTIONAL] inflation data can be added to the dataset (we can see how the increase in inflation is reflected in expenditures)\n    \n* [OPTIONAL] A variable called vip_customer can be created. In this variable, customers with high credit card limit (for example 40000) and high spending can be regulated to be 1 other and 0. This can make our model work better.","ef23ac36":"<a id=\"5\"><\/a> <br>\n# 5 - If your were the client \"Bank\" how would you envision a dashboard where all this data is collected, which 3 features from the users' spending behavior do you think they'd be interested in taking a look at and why?\n<font color='green'>\n\nI would take the variables 'total_credit_card_limit', 'current_available_limit' and 'age'. When we look at the correlation matrix, the relationship between them is the most in these 3 variables.\n"}}