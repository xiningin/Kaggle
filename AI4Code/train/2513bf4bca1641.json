{"cell_type":{"4b08e44b":"code","11ecd9f3":"code","8e9807ee":"code","2470189d":"code","56851cda":"code","1dc3e602":"code","1368cfc6":"code","58572fc6":"code","c58ed531":"code","89c3ef0f":"code","028859b5":"code","7c9cb065":"code","4a7019e5":"code","e315846a":"code","d4382199":"code","25386ff4":"code","e253bdc7":"code","c244903b":"code","74de5558":"code","1acc2230":"code","621e817f":"code","5e7c4339":"code","9f734e9d":"code","b4213fca":"code","570f8aab":"code","5fc4f760":"code","c8b77524":"code","4944a752":"code","08e7b9b4":"code","e0cacaf2":"code","1f107f27":"code","4dfc8389":"markdown","a317e23b":"markdown","a43a34f3":"markdown","4e5bdd2b":"markdown","c6176c6b":"markdown","427b99dd":"markdown"},"source":{"4b08e44b":"\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","11ecd9f3":"from fastai.conv_learner import *","8e9807ee":"PATH = '..\/input\/planet-understanding-the-amazon-from-space\/'","2470189d":"ls {PATH}","56851cda":"from fastai.plots import *","1dc3e602":"def get_1st(path, pattern): return glob(f'{path}\/*{pattern}.*')[2]","1368cfc6":"dc_path = \"..\/input\/dogs-vs-cats-redux-kernels-edition\/train\"\nlist_paths = [get_1st(f\"{dc_path}\",\"cat\"), get_1st(f\"{dc_path}\", \"dog\")]\nplots_from_files(list_paths, titles=[\"cat\",\"dog\"], maintitle=\"Single-label classification\")","58572fc6":"list_paths = [f\"{PATH}train-jpg\/train_0.jpg\", f\"{PATH}train-jpg\/train_1.jpg\"]\ntitles=[\"haze primary\", \"agriculture clear primary water\"]\nplots_from_files(list_paths, titles=titles, maintitle=\"Multi-label classification\")","c58ed531":"# the planet.py file\n\nfrom fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.dataset import *\nfrom sklearn.metrics import fbeta_score\nimport warnings\n\ndef f2(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        return max([fbeta_score(targs, (preds>th), 2, average='samples')\n                   for th in np.arange(start,end,step)])","89c3ef0f":"metrics=[f2]\nf_model = resnet34","028859b5":"label_csv = f'{PATH}train_v2.csv'\nn = len(list(open(label_csv)))-1\nval_idxs = get_cv_idxs(n)","7c9cb065":"def get_data(sz):\n    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n    return ImageClassifierData.from_csv(PATH, 'train-jpg',label_csv, tfms=tfms,\n                                       suffix='.jpg', val_idxs=val_idxs, test_name='test-jpg-v2')","4a7019e5":"data = get_data(256)","e315846a":"x,y = next(iter(data.val_dl))","d4382199":"y","25386ff4":"list(zip(data.classes, y[0]))","e253bdc7":"plt.imshow(data.val_ds.denorm(to_np(x))[0]*1.4)","c244903b":"sz=64","74de5558":"data = get_data(sz)","1acc2230":"#this will go through our images and resize them\ndata = data.resize(int(sz*1.3), '\/tmp')","621e817f":"TMP_PATH = \"\/tmp\/tmp\"\nMODEL_PATH =\"\/tmp\/model\/\"","5e7c4339":"learn = ConvLearner.pretrained(f_model, data, metrics=metrics, tmp_name=TMP_PATH, models_name=MODEL_PATH)","9f734e9d":"lrf=learn.lr_find()\nlearn.sched.plot()","b4213fca":"lr = 0.2","570f8aab":"learn.fit(lr, 3, cycle_len=1, cycle_mult=2)","5fc4f760":"# we are now using differential learning rates\nlrs = np.array([lr\/9,lr\/3,lr])","c8b77524":"#unfreeze the previous layers so we can use our diff learning rates \nlearn.unfreeze()\nlearn.fit(lrs, 3, cycle_len=1, cycle_mult=2)","4944a752":"learn.save(f'{sz}')","08e7b9b4":"learn.sched.plot_loss()","e0cacaf2":"sz=128","1f107f27":"learn.set_data(get_data(sz))\nlearn.freeze()\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)","4dfc8389":"# Multilabel Classification","a317e23b":"# Multi-label vs single-label classification","a43a34f3":"The first image belongs to two classes: [haze, primary] and while the second image has four: [agriculture clear primary water]","4e5bdd2b":"# Multi-label models for Planet Dataset","c6176c6b":"Data augmentation step","427b99dd":"In this section we are trying to find the learning rate & setting up a pretrained model"}}