{"cell_type":{"75c1ac71":"code","bbdb6408":"code","bd3f54bc":"code","ef28748e":"code","79441def":"code","b4acf41d":"code","1da46c62":"code","a837ba61":"code","1ddf2487":"code","51eed75e":"code","0838d004":"code","2c297b31":"code","27ee0f4f":"code","49966f10":"code","e4fdf7a5":"code","8726939f":"code","493a24f4":"code","e7798102":"code","ac2317e0":"code","db3b1492":"code","ecc4243a":"code","3cace410":"code","219931e0":"code","03124d2c":"code","659ad07c":"code","d2b41e9e":"code","481d1346":"markdown","4d975adf":"markdown","f74dfe52":"markdown","68fdf28e":"markdown","6825f00f":"markdown","bbe6ab88":"markdown","85da9972":"markdown","b684732a":"markdown","1c0de3ec":"markdown","b0cb5db0":"markdown","a32833a1":"markdown","a0910b12":"markdown","9af2909c":"markdown","2b4416ee":"markdown","40081b09":"markdown","607e3b7a":"markdown","57b783a2":"markdown","afcac96a":"markdown","dbb8ee3b":"markdown","fd2e2c67":"markdown","69c456c2":"markdown","77e13c8f":"markdown"},"source":{"75c1ac71":"import numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport re\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.svm import LinearSVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV\nfrom scipy.stats import randint,uniform\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nimport warnings\nwarnings.filterwarnings('ignore')\n#import xgboost as xgb","bbdb6408":"data = pd.read_csv('\/kaggle\/input\/pune-air-quality-index\/PNQ_AQI.csv')","bd3f54bc":"data.head()\ndata.info()\ndata.isnull().sum()","ef28748e":"data['Date'] = pd.to_datetime(data['Date'])\n#data['Date'] = data['Date'].apply(lambda x: int(x.timestamp()))\ndata.sort_values(by=['Date'], inplace=True, ignore_index=True)","79441def":"for _, col in enumerate(list(data.columns[1:3])):\n    data[f'{col} BDL'] = data[f'{col}'].map(lambda x: 1 if 'BDL' in x else 0)\n    data[f'{col}'] = data[f'{col}'].apply(lambda x: x[-3:])\n    data[f'{col}'] = data[f'{col}'].apply(lambda x: 0 if 'NA' in x else int((re.findall(r'\\d+',x))[0]))","b4acf41d":"outlier_features = list(data.columns[1:5])\ndef detect_outliers(df,n,features):\n    outlier_indices = []\n    \n    for col in features:\n        q1 = np.nanpercentile(df[col], 25)\n        q3 = np.nanpercentile(df[col], 75)\n        iqr = q3 - q1\n        outlier_step = 1.5 * iqr\n        outlier_list_col = df[(df[col] < q1 - outlier_step) | (df[col] > q3 + outlier_step )].index\n        outlier_indices.extend(outlier_list_col)\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n)\n    return multiple_outliers\n\nOutliers_to_drop = detect_outliers(data,1,outlier_features)\ndata.loc[Outliers_to_drop]","1da46c62":"data.drop(Outliers_to_drop, axis = 0, inplace=True)","a837ba61":"rep={'MPCB-KR':'Karve Road','MPCB-SWGT':'Swargate','MPCB-BSRI':'Bhosari',\\\n     'MPCB-NS':'Nal Stop','MPCB-PMPR':'Pimpri','Pimpri Chinchwad':'Chinchwad'}\ndata['Location'].replace(rep,inplace=True)","1ddf2487":"data.dropna(axis=0, subset=['AQI'], inplace=True)\ndata.drop(['CO2 \u00b5g\/m3'], axis=1, inplace=True)\ndata.fillna(method='bfill', axis=0, inplace=True)","51eed75e":"data = data[['AQI'] + [c for c in data if c not in ['AQI']]]\ndata.describe()","0838d004":"g1 = sns.heatmap(data.iloc[:,:5].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")","2c297b31":"date_sampler = data.set_index('Date').groupby('Location').resample('W').bfill().droplevel(0).reset_index()\ng2 = sns.FacetGrid(date_sampler, row='Location', height=2, aspect=6)\ng2.map(sns.pointplot, 'Date', 'AQI', 'SO2 \u00b5g\/m3 BDL', palette='deep')\ng2.add_legend()","27ee0f4f":"g3 = sns.factorplot(y=\"AQI\",x=\"Location\", data=data,kind=\"violin\")\ng4 = sns.factorplot(y=\"Nox \u00b5g\/m3\",x=\"Location\", data=data,kind=\"violin\")","49966f10":"Location = pd.get_dummies(data.Location, prefix='Location')\nframes = [data, Location]\ndata = pd.concat(frames, axis=1)\ndata.drop(columns=['Location'], inplace=True)","e4fdf7a5":"target = data.AQI\ndata.drop(['AQI'], axis=1, inplace=True)\nX_train, X_test, y_train, y_test\\\n    = train_test_split(data.iloc[:,1:], target, test_size=0.25, random_state=42)\n\nXscaler = preprocessing.RobustScaler().fit(X_train)\nX_train_transformed = Xscaler.transform(X_train)\nX_test_transformed = Xscaler.transform(X_test)\nyscaler = preprocessing.RobustScaler().fit(y_train.to_frame())\ny_train = np.log1p(y_train)\ny_test = np.log1p(y_test)\ny_train_transformed = yscaler.transform(y_train.to_frame())\ny_test_transformed = yscaler.transform(y_test.to_frame())","8726939f":"reg = LinearRegression().fit(X_train_transformed, y_train_transformed)\ncv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\ncross_val_score(reg, X_train_transformed, y_train_transformed, cv=cv)","493a24f4":"y_pred = reg.predict(X_test_transformed)\nmean_absolute_error(y_test_transformed, y_pred)\nmean_squared_error(y_test_transformed, y_pred)","e7798102":"estimators = [('lr', RidgeCV()),('svr', LinearSVR(random_state=42))]\nstacking_reg = \\\n    StackingRegressor(estimators=estimators,\\\n                      final_estimator=RandomForestRegressor(n_estimators=10,random_state=42))\nstacked_reg = stacking_reg.fit(X_train_transformed, y_train_transformed)\ncv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\ncross_val_score(stacked_reg, X_train_transformed, y_train_transformed, cv=cv)","ac2317e0":"stacked_y_pred = stacked_reg.predict(X_test_transformed)\nmean_absolute_error(y_test_transformed, stacked_y_pred)\nmean_squared_error(y_test_transformed, stacked_y_pred)","db3b1492":"param_distributions = {'n_estimators': randint(1, 5),'max_depth': randint(5, 10)}\nsearch = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n                            n_iter=5,\n                            param_distributions=param_distributions,\n                            random_state=0)\nsearch.fit(X_train_transformed, y_train_transformed)\ncross_val_score(search, X_train_transformed, y_train_transformed, cv=cv)","ecc4243a":"y_pred = search.predict(X_test_transformed)\nmean_absolute_error(y_test_transformed, y_pred)\nmean_squared_error(y_test_transformed, y_pred)","3cace410":"ada_param_distributions = {'n_estimators': [50, 100],\n        'learning_rate': [0.01, 0.05, 0.1, 0.3, 1],\n        'loss': ['linear', 'square', 'exponential']}\nada_search = GridSearchCV(AdaBoostRegressor(random_state=0),ada_param_distributions)\nada_search.fit(X_train_transformed, y_train_transformed)\ncross_val_score(ada_search, X_train_transformed, y_train_transformed, cv=cv)","219931e0":"gbr_param_distributions = {\n        \"max_depth\": [3, 5, 8],\n        \"max_features\": [\"log2\", \"sqrt\"],\n        \"criterion\": [\"friedman_mse\", \"lad\"],\n        \"subsample\": [0.5, 0.75, 1.0]}\ngbr_search = GridSearchCV(GradientBoostingRegressor(random_state=0),gbr_param_distributions)\ngbr_search.fit(X_train_transformed, y_train_transformed)\ncross_val_score(gbr_search, X_train_transformed, y_train_transformed, cv=cv)","03124d2c":"estimators = [('abr', ada_search),('gbr', GradientBoostingRegressor(random_state=0))]\nstacking_reg = \\\n    StackingRegressor(estimators=estimators,\\\n                      final_estimator=search)\nstacked_reg = stacking_reg.fit(X_train_transformed, y_train_transformed)\ncv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\ncross_val_score(stacked_reg, X_train_transformed, y_train_transformed, cv=cv)","659ad07c":"stacked_y_pred = stacked_reg.predict(X_test_transformed)\nmean_absolute_error(y_test_transformed, stacked_y_pred)\nmean_squared_error(y_test_transformed, stacked_y_pred)","d2b41e9e":"print(f'\\nFinal MAE: {mean_absolute_error(y_test_transformed, y_pred)}')\nprint(f'\\nFinal MSE: {mean_squared_error(y_test_transformed, y_pred)}')","481d1346":"Find correlations between non-numeric features.","4d975adf":"Check data.","f74dfe52":"After several attempts at stacking random forest, adaboost and gradient boosting using different parameters with the help of gridsearch, I still didn't get a MSE as good as I did with random forset alone, so that's the one I'll stay with","68fdf28e":"Separate data from target, create train and test sets (without dates) and scale the data.","6825f00f":"After doing some Googling, I found that BDL probably means \"below detection limit\".\n\nSo I did the following:\n* Create a new feature of BDL for each column with such values\n* Extract the last 3 characters of each row (giving NA or a number)\n* Replace NA with 0 and convert the numbers to integers","bbe6ab88":"Pick and show outliers.","85da9972":"The aim is to build a machine learning model which can predict AQI based on the 7 features and the dataset consisting of 7844 records.\n\nWith inspiration from:\n* https:\/\/www.kaggle.com\/yassineghouzam\/titanic-top-4-with-ensemble-modeling\n* https:\/\/www.kaggle.com\/virajkadam\/notebookc835013f04\n* https:\/\/www.kaggle.com\/tzachymorad\/cancer-cost-beginner-s-guide-prep-and-stacking","b684732a":"Build a simple model, perform cross-validation on the training set, and predict and calculate the mean square error and absolute square error on the test.","1c0de3ec":"* It seems that more S02 measurements that were BDL generally happened earlier in the timeframe of the dataset.\n* It also seems like AQI got generally worse later in the timeframe.\n* Both of these points should be explored further, as together they indicate increasing levels of harmful substances in the air.","b0cb5db0":"* Drop rows without a label (i.e., where AQI is NaN).\n* Copy target into a new series.\n* Drop the copied target, and a column without relevant data.\n* Fill NaNs with nearest values","a32833a1":"Move AQI to beginning and summarize data.","a0910b12":"* Here we see that Chinchwad had the greatest variation in both AQI and Nox.\n* We also see that the distribution of AQI across all locations is similar to Nox (more centered for Karve Road and Pimpri, slightly skewed down for Swargate, and more skewed for Chinchwad).\n* Finally, Karve Road had some of the worst days in terms of AQI, but this didn't draastically change its median AQI compared to the other locations,\n* These points indicate a slight correlation between location and AQI. ","9af2909c":"All are positively correlated with the AQI; the strongest correlation is with Respirable Suspended Particulate Matter","2b4416ee":"Turn the Locations into categories.","40081b09":"* The cross-validation score for the stacked regressors was slightly higher, but the error in the test was also higher. Maybe fine-tuning the hyperparameters will help.\n* Check for best hyperparameters using GridSearchCV, to improve the models","607e3b7a":"Load data.","57b783a2":"Change Date strings to numbers and sort by date.","afcac96a":"Create a regression model by stacking a couple of models, perform cross-validation and calculate MSE\/MAE.","dbb8ee3b":"Delete multiple names for Locations.","fd2e2c67":"Show correlation between numerical features and the label.","69c456c2":"Remove outliers.","77e13c8f":"* This single model was better than all others because we found the optimal hyperparameters.\n* Create a new ensemble regressor with the optimized Ramdom Forest Regressor"}}