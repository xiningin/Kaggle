{"cell_type":{"bc50bbf6":"code","e1f96a8f":"code","95eda3bd":"code","c7e68d77":"code","9a08b339":"code","060fb3ed":"code","8743df21":"code","d07367e2":"code","9bbe60bf":"markdown"},"source":{"bc50bbf6":"! pip install imutils\n\nimport os\nimport math\nimport cv2\nimport dlib\nimport numpy as np\nimport pandas as pd\nfrom imutils import face_utils\nimport matplotlib.pyplot as plt","e1f96a8f":"# Define required maths functions\n\ndef slope(point1, point2, absolute=False):\n    x1,y1 = point1\n    x2,y2 = point2\n    deltaX = x2-x1\n    deltaY = y2-y1\n    if deltaX == 0:\n        return \"inf\"\n    slope = deltaY \/ deltaX\n    if absolute:\n        slope = abs(slope)\n    return round(slope,3)","95eda3bd":"# Define helper functions\n\ndef load_images_from_folder(folder):\n    images = []\n    filenames = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        if img is not None:\n            images.append(img)\n            filenames.append(filename)\n    return images, filenames","c7e68d77":"# Computer Vision functions\n\npredictor68 = dlib.shape_predictor('..\/input\/shape-predictor-68-face-landmarks\/shape_predictor_68_face_landmarks.dat')\npredictor81 = dlib.shape_predictor('..\/input\/shape-predictor81\/shape_predictor_81_face_landmarks.dat')\n\n# Function to determine the color range allowed to move landmarks points through image\ndef getAllowedColorRange(avgSkinColor):\n    # Dark skin\n    if (avgSkinColor < 100):\n        colorRange = (avgSkinColor-35, avgSkinColor+50)\n    # Somehow dark skin\n    elif(avgSkinColor <= 130): \n        colorRange = (avgSkinColor-30, avgSkinColor+30)\n    # Normal skin color (tends to dark)\n    elif(avgSkinColor <= 160):\n        colorRange = (avgSkinColor-40, avgSkinColor+40) \n    # Normal skin color \n    elif(avgSkinColor < 180):\n        colorRange = (avgSkinColor-50, avgSkinColor+50)\n    # Normal skin color (tends to white)\n    elif(avgSkinColor < 210):\n        colorRange = (avgSkinColor-50, avgSkinColor+30) \n    # white skin color\n    elif (avgSkinColor < 230):\n        colorRange = (avgSkinColor-40, avgSkinColor+20)\n    # Abnormal white skin color\n    else:\n        colorRange = (avgSkinColor-30, avgSkinColor+15)\n    return colorRange\n\n# Function to move landmarks points, based on skincolor\ndef moveUp(grayscale_image, point, avgSkinColor, foreheadHeight):\n    # Get color range & current color where the point is located in image\n    steps = 5\n    portionOfOriginalPointY = 0.275\n    originalPoint = np.copy(point)\n    colorRange = getAllowedColorRange(avgSkinColor)\n    currentPixelColor = grayscale_image.item(point[1],point[0])\n    \n    # move the landmark point up until a strong change of color happen (outside color range)\n    while currentPixelColor > colorRange[0] and currentPixelColor < colorRange[1]:\n        \n        # If point is going out of image boundary\n        if point[1] < 0:\n            # Get back to original point location, with a little bit higher\n            point[1] = originalPoint[1] - (originalPoint[1] * portionOfOriginalPointY)\n            break\n            \n        # move up (N steps) pixels & get the color\n        point[1] = point[1] - steps\n        \n        currentPixelColor = grayscale_image.item(point[1],point[0])\n        \n    # if the pixel is moved too high than expected (3\/4 forehead height): keep close to original\n    if abs( originalPoint[1] - point[1] ) > ( foreheadHeight * 0.75 ):\n        point[1] = originalPoint[1] - (originalPoint[1] * portionOfOriginalPointY)\n    return point\n\n# Function to detect if the forehead is clear or covered with hair (it corrupts the enhancement of landmarks points)\ndef clearForehead(forehead, avgSkinColor):\n    clarityThreshold = 85\n    colorRange = getAllowedColorRange(avgSkinColor)\n    \n    # Check if most of the forehead is the same as skin color\n    regionOK = np.logical_and(forehead > colorRange[0] , forehead < colorRange[1])\n    try:\n        percentage = (np.count_nonzero(regionOK) \/ forehead.size) * 100\n    except:\n        return False\n    isClear = True if percentage >= clarityThreshold else False\n    return isClear\n\n\n# Function to perform facial landmark detection on the whole face\ndef facial_landmarks(image, eyeOnlyMode=False, allowEnhancement=False):\n    # ARGUMENTS:\n    # - eyeOnlyMode: detect & return eye landmarks, used to align face\n    # - allowEnhancement: allow improvement (landmarks repositioning)\n    \n    # Return:\n    # - NumPy array of coordinates of landmarks\n    \n    # Use dlib 68 & 81 to predict landmarks points coordinates\n    detector = dlib.get_frontal_face_detector()\n    global predictor68\n    global predictor81\n    \n    # Grayscale image\n    try:\n        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    except:\n        grayscale_image = image\n    \n    # array of rectangles surrounding faces detected\n    rectangles = detector(grayscale_image, 1)\n\n    # If at least one face is detected   \n    if len(rectangles) > 0:\n        # Get 68 landmark points\n        faceLandmarks = predictor68(grayscale_image, rectangles[0])\n        faceLandmarks = face_utils.shape_to_np(faceLandmarks)\n        \n        if eyeOnlyMode:\n            # Return eye points to perform a calculated rotation\n            return np.array([faceLandmarks[39], faceLandmarks[42]])\n        \n        # Get 81 landmark points\n        foreheadLandmarks = predictor81(grayscale_image, rectangles[0])\n        foreheadLandmarks = face_utils.shape_to_np(foreheadLandmarks)\n        \n        # Get 68 point from -68- predictor (higher accuracy) + forehead from -81- predictor\n        fullFacePoints = np.concatenate((faceLandmarks, foreheadLandmarks[68:]))\n        \n        # Get forehead region & height to perform simple improvement\n        x,y,x2,y2 = (fullFacePoints[69,0]-10, fullFacePoints[68,1], fullFacePoints[80,0]+10, fullFacePoints[23, 1])\n        foreheadRegion = grayscale_image[y:y2,x:x2]\n        foreheadHeight = foreheadRegion.shape[0]\n        \n        if allowEnhancement:\n            # Perform progressive quality improvement\n            # Get nose region to get average skin color\n            x,y,x2,y2 = (fullFacePoints[28,0]-5, fullFacePoints[28,1], fullFacePoints[28,0]+5, fullFacePoints[30,1])\n            noseRegion = grayscale_image[y:y2, x:x2]\n            avgSkinColor = np.average(noseRegion[:,:])\n            \n            # Check if forehead is clear -> perform heuristic based enhancement\n            forehead_is_clear = clearForehead(foreheadRegion, avgSkinColor)\n            originalPoints = fullFacePoints[[69,70,71,73,80]]\n            \n            if forehead_is_clear:\n                avgSkinColor = np.average(foreheadRegion)\n                \n                # Modify some points for more accuracy\n                # Point[68] will be center between lower-lip & chin\n                distance = int((fullFacePoints[8,1]-fullFacePoints[57,1]) \/ 2)\n                fullFacePoints[68] = np.array([fullFacePoints[8,0], fullFacePoints[8,1]-distance])\n                \n                # Enhance points locations\n                enhancedPoints = np.array([moveUp(grayscale_image, orgPoint, avgSkinColor, foreheadHeight) for orgPoint in originalPoints])\n\n                # Assign original points to enhanced points (some maybe the same)\n                fullFacePoints[[69,70,71,73,80]] = enhancedPoints  \n                \n                # Adjust points to fix any corruptions\n                fullFacePoints[[69,70,71,73,80]] = adjustPoints(enhancedPoints, fullFacePoints[76], fullFacePoints[79])\n\n                #Prepare point[72] for center of forehead\n                distance = (fullFacePoints[22,0] - fullFacePoints[21,0]) \/ 2\n                distanceY = (fullFacePoints[21,1] - fullFacePoints[71,1]) \/ 2\n                fullFacePoints[72] = np.array([fullFacePoints[21,0] + distance, fullFacePoints[21,1]-distanceY])\n                \n                # Point[74] sometimes have a fixed corruption, this line helps :)\n                fullFacePoints[74,0] -= foreheadHeight * 0.1 # Arbitery heurestic\n                \n            else:\n                # If forehead isn't clear -> fix points with very simple heuristics\n                fullFacePoints[70,1] -= foreheadHeight * 0.2\n                fullFacePoints[71,1] -= foreheadHeight * 0.3\n                fullFacePoints[80,1] -= foreheadHeight * 0.2\n    \n        else:\n            # If Enhancement is False -> do the simple enhancement, better quality + low performance :)\n            fullFacePoints[70,1] -= foreheadHeight * 0.2\n            fullFacePoints[71,1] -= foreheadHeight * 0.3\n            fullFacePoints[80,1] -= foreheadHeight * 0.2\n            pass\n        \n        return fullFacePoints\n    # No faces found\n    else:\n        return None\n\n# Function to adjust landmarks points of the forehead \n# and fix corruptions of improvement (such as the bald man case)\ndef adjustPoints(points, leftSidePoint, rightSidePoint):    \n    # Use shape_predictor_81 as a reference for points indexes to fix:\n    # points = [69,70,71,73,80]\n    # LeftSidePoint = 76  |  rightSidePoint = 79\n    \n    slopes = []\n    slopeThreshold = 0.4 # slope > 0.4 = corruption -> fix\n    totalSlopeThreshold = 1 # sum of slopes > 1 = corruption -> fix\n    leftPoint = points[0]\n    rightPoint = points[3]\n    criticalLeftPoint = points[1]\n    criticalRightPoint = points[4]\n    \n    # if any point is higher than a (accurate located point) -> fix\n    if leftPoint[1] < criticalLeftPoint[1] :\n        points[0,1] = np.average([criticalLeftPoint[1], leftSidePoint[1]])\n    if rightPoint[1] < criticalRightPoint[1]:\n        points[3,1] = np.average([criticalRightPoint[1], rightSidePoint[1]])\n    \n    # Collect some slopes of the usually corrupted points\n    slopes.append(slope(points[1], points[2], True))\n    slopes.append(slope(points[2], points[4], True))\n    \n    # Calculate slope differences & sum\n    difference = abs(np.diff(slopes))\n    _sum = np.sum(slopes)\n    \n    # If calculation results (either) too high = corruption -> fix\n    if difference > slopeThreshold:\n        issueIndex = np.argmax(slopes)\n        if issueIndex == 0:\n            points[1,1] = max(points[4,1], points[2,1])\n        else:\n            points[4,1] = max(points[1,1], points[2,1])\n            \n    if _sum > totalSlopeThreshold:\n        points[1,1] = np.average(points[[4,2], 1])\n        points[4,1] = np.average(points[[1,2], 1])\n        points[2,1] = np.average(points[[4,1], 1])  \n        \n    return points\n\n# Function to extract the whole face\ndef cropFullFace(image, points, padding = True, xProportion = 0.025, yProportion = 0.025):    \n    imageShape = image.shape\n    # Get borders of the 4 directions\n    top = points[:,1].min()\n    bottom = points[:,1].max()\n    left = points[:,0].min()\n    right = points[:,0].max()\n    \n    if padding:\n        # X-factor is a an additional proportion of the image on X-axis, considered in the output \n        # Y-factor is the same for Y-axis \n        xFactor = int((xProportion) * imageShape[1])\n        yFactor = int((yProportion) * imageShape[0])\n        x,y,x2,y2 = (max(left-xFactor, 0), max(top-yFactor, 0) ,min(right+yFactor, imageShape[0]), min(bottom+yFactor, imageShape[0]) )\n    \n    else:\n        x,y,x2,y2 = (left,top ,right, bottom )\n\n    cropped = image[y:y2, x:x2]\n    return cropped\n\n# Function to rotate image to align the face\ndef align_face(image, eyePoints):\n    # Get left eye & right eye coordinates\n    leftEyeX,leftEyeY = eyePoints[0]\n    rightEyeX, rightEyeY = eyePoints[1]\n\n    # Calculate angle of rotation & origin point\n    angle = math.atan( (leftEyeY - rightEyeY) \/ (leftEyeX - rightEyeX) ) * (180\/math.pi)\n    origin_point = tuple(np.array(image.shape[1::-1]) \/ 2)\n\n    # Rotate using rotation matrix\n    rot_mat = cv2.getRotationMatrix2D(origin_point, angle, 1.0)\n    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n    return result\n    \n\n# Function to collect landmarks points, grouped, as polygons\ndef collectFaceComponents(facial_points):\n    faceShape = np.concatenate((facial_points[0:17],facial_points[[78,74,79,73,80,71,70,69,76,75,77,0]])) \n    leftEye = np.concatenate((facial_points[36:42],np.array([facial_points[36]])))\n    rightEye = np.concatenate((facial_points[42:47],np.array([facial_points[42]])))\n    leftIBrow = facial_points[17:22]\n    rightIBrow = facial_points[22:27]\n    noseLine = facial_points[27:31]\n    noseArc = facial_points[31:36]\n    upperLip = facial_points[[49,50,51,52,53,61,62,63]]\n    lowerLip = facial_points[[55,56,57,58,59,65,66,67]]\n    faceComponents = {\n            \"face_shape\":faceShape,\n            \"left_eye\":leftEye,\n            \"right_eye\":rightEye,\n            \"left_i_brow\":leftIBrow,\n            \"right_i_brow\":rightIBrow,\n            \"nose_line\":noseLine,\n            \"nose_arc\":noseArc,\n            \"upper_lip\":upperLip,\n            \"lower_lip\":lowerLip\n            }\n    return faceComponents\n\n\n","9a08b339":"# Facial Features Extraction\ndef extract_features(image, landmarks_points, options):\n   # Input:\n   #    + Image to process\n   #    + landmarks coordinates\n   #    + options: array of strings, features to be extracted\n   \n   # Output:\n   #    + dictionary => {feature_name : image, ...}\n   \n   \n    # Get & Initialize face components\n    faceComponents = collectFaceComponents(landmarks_points)\n    face_shape = faceComponents[\"face_shape\"]\n    leftEye, rightEye = faceComponents[\"left_eye\"], faceComponents[\"right_eye\"]\n    left_ibrow, right_ibrow = faceComponents[\"left_i_brow\"], faceComponents[\"right_i_brow\"]\n    nose_line, nose_arc = faceComponents[\"nose_line\"], faceComponents[\"nose_arc\"]\n    upper_lip = faceComponents[\"upper_lip\"]\n    \n    if 'all' in options:\n        options.extend([\n            'forehead', 'left_eyebrow', 'right_eyebrow',\n            'left_eye', 'right_eye', \n            'left_eye_eyebrow', 'right_eye_eyebrow',\n            'nose', 'mouth', 'eye_nose_mouth_eyebrow',\n            'both_eyebrow', 'both_eye', 'both_eye_eyebrow', \n            'clear_eyebrow', 'clear_eye', 'clear_eye_eyebrow',\n        ])\n    \n    # Initialize response\n    features = {}\n    \n    # Detect the clear face side (Better capture for eye+brows))\n    # distance between nose bottom-point & eyes angle-point \n    lefteyeside = leftEye[3]\n    righteyeside = rightEye[0]\n    noseTip = nose_line[nose_line.shape[0]-1]\n    if righteyeside[0] - noseTip[0] < 0: \n        # (in your perspective), person is looking to right direction -> so Left eye is clear\n        clear_eye = leftEye\n        clear_ibrow = left_ibrow\n        clearer_left_side = True\n    elif noseTip[0] - lefteyeside[0] < 0:\n        # Person is looking to left direction -> so right eye is clear\n        clear_eye = rightEye\n        clear_ibrow = right_ibrow\n        clearer_left_side = False\n    else:\n        # Decide which side is clearer (person is slightly looking to right or left)\n        nose_eye_diff = abs(noseTip[0]-lefteyeside[0]) - abs(noseTip[0]-righteyeside[0])\n        ibrow_position = \"right\" if nose_eye_diff <= 1 else \"left\"\n        clear_eye = faceComponents[ibrow_position+\"_eye\"]\n        clear_ibrow = faceComponents[ibrow_position+\"_i_brow\"]\n        clearer_left_side = True if ibrow_position == 'left' else False\n        \n    ##### Forehead #####\n    if 'forehead' in options:\n        x, y, x2, y2 = np.min(face_shape[:, 0]), np.min(face_shape[:, 1]), np.max(face_shape[:, 0]), np.min(clear_ibrow[:, 1])\n        forehead_img = image[y:y2, x:x2] # Best resolution (224, 64)\n        features['forehead'] = forehead_img\n        \n    \n    ##### Left eyebrow #####\n    if 'left_eyebrow' in options:\n        # x = between left eyebrow and left side faceshape landmark [index 0 of 81]\n        # x2 = nose top landmark (between eyebrows)\n        # y = top eyebrow landmark,   y2 = bottom eyebrow landmark\n        x = int((left_ibrow[0, 0] + face_shape[0, 0]) \/ 2)\n        x2 =  nose_line[0, 0]\n        y, y2 = np.min(left_ibrow[:, 1]), np.max(left_ibrow[:, 1])\n        left_ibrow_img = image[y:y2, x:x2]\n        features['left_eyebrow'] = left_ibrow_img\n    \n    ##### Right eyebrow #####\n    if 'right_eyebrow' in options:\n        # x =  nose top landmark (between eyebrows)\n        # x2 = between right eyebrow and right side faceshape landmark [index 16 of 81]\n        # y = top eyebrow landmark,   y2 = bottom eyebrow landmark\n        # y2 = eyebrow bottom landmark\n        x = nose_line[0,0]\n        x2 = int((right_ibrow[4, 0] + face_shape[16, 0]) \/ 2)\n        y, y2 = np.min(right_ibrow[:, 1]), np.max(right_ibrow[:, 1])  \n        right_ibrow_img = image[y:y2, x:x2]\n        features['right_eyebrow'] = right_ibrow_img\n    \n    \n    ##### Left eye #####\n    if 'left_eye' in options:\n        # x = between left eye and left side faceshape landmark [index 0 of 81]\n        # x2 = top landmark of nose (between eyes)\n        # y = between eye top landmark & eyebrow top landmark\n        # y2 = second top nose landmark\n        x = int((leftEye[0, 0] + face_shape[0, 0]) \/ 2)\n        x2 = nose_line[0, 0]\n        y = int((np.min(left_ibrow[:, 1]) + np.min(leftEye[:, 1])) \/ 2)\n        y2 = nose_line[1, 1]\n        leftEye_img = image[y:y2, x:x2]\n        features['left_eye'] = leftEye_img\n    \n    ##### Right eye #####\n    if 'right_eye' in options:\n        # x = top landmark of nose (between eyes)\n        # x2 = between right eye and right side faceshape landmark [index 16 of 81]\n        # y = between eye top landmark & eyebrow top landmark\n        # y2 = second top nose landmark\n        x = nose_line[0, 0]\n        x2 = int((rightEye[4, 0] + face_shape[16, 0]) \/ 2)\n        y = int((np.min(right_ibrow[:, 1]) + np.min(rightEye[:, 1])) \/ 2)\n        y2 = nose_line[1, 1]\n        rightEye_img = image[y:y2, x:x2]\n        features['right_eye'] = rightEye_img\n    \n    ##### Both eyebrows #####\n    if 'both_eyebrow' in options:\n        # x = between left eyebrow and left side faceshape landmark [index 0 of 81]\n        # x2 = between right eyebrow and right side faceshape landmark [index 16 of 81]\n        # y = top landmark of left\/right eyebrow (maximum top is selected)\n        # y2 = bottom landmark of left\/right eyebrow (maximum bottom is selected)\n        x = int((left_ibrow[0, 0] + face_shape[0, 0]) \/ 2)\n        x2 = int((right_ibrow[4, 0] + face_shape[16, 0]) \/ 2)\n        y = min(np.min(left_ibrow[:, 1]), np.min(right_ibrow[:, 1]))\n        y2 = max(np.max(left_ibrow[:, 1]), np.max(right_ibrow[:, 1]))\n        both_eyebrows_img = image[y:y2, x:x2]\n        features['both_eyebrow'] = both_eyebrows_img\n    \n    ##### Both eyes #####\n    if 'both_eye' in options:\n        # x = between left eye and left side faceshape landmark [index 0 of 81]\n        # x2 = between right eye and right side faceshape landmark [index 16 of 81]\n        # y = between clear eyebrow & clear eye\n        # y2 = second top nose landmark\n        x = int((leftEye[0, 0] + face_shape[0, 0]) \/ 2)\n        x2 = int((rightEye[4, 0] + face_shape[16, 0]) \/ 2)\n        y = int((np.min(clear_ibrow[:, 1]) + np.min(clear_eye[:, 1])) \/ 2)\n        y2 = nose_line[1, 1]\n        both_eyes_img = image[y:y2, x:x2]\n        features['both_eye'] = both_eyes_img\n    \n    ##### Eye and Eyebrow LEFT #####\n    if 'left_eye_eyebrow' in options:\n        # x = between left eyebrow and left side faceshape landmark [index 0 of 81]\n        # x2 = nose top landmark (between eyebrows)\n        # y = top left eyebrow landmark\n        # y2 = second top nose landmark\n        x = int((left_ibrow[0, 0] + face_shape[0, 0]) \/ 2)\n        x2 =  nose_line[0, 0]\n        y = np.min(left_ibrow[:, 1])\n        y2 = nose_line[1, 1]\n        eye_eyebrow_left =  image[y:y2, x:x2]\n        features['left_eye_eyebrow'] = eye_eyebrow_left\n    \n    ##### Eye and Eyebrow RIGHT #####\n    if 'right_eye_eyebrow' in options:\n        # x = top landmark of nose (between eyes)\n        # x2 = between right eyebrow and right side faceshape landmark [index 16 of 81]\n        # y = top right eyebrow landmark\n        # y2 = second top nose landmark\n        x = nose_line[0, 0]\n        x2 = int((right_ibrow[4, 0] + face_shape[16, 0]) \/ 2)\n        y = np.min(right_ibrow[:, 1])\n        y2 = nose_line[1, 1]\n        eye_eyebrow_right = image[y:y2, x:x2]\n        features['right_eye_eyebrow'] = eye_eyebrow_right\n    \n    ##### Eye and Eyebrow LEFT & RIGHT #####\n    if 'both_eye_eyebrow' in options:\n        # x = between left eyebrow and left side faceshape landmark [index 0 of 81]\n        # x2 = between right eyebrow and right side faceshape landmark [index 16 of 81]\n        # y = top eyebrow landmark\n        # y2 = second top nose landmark\n        x = int((left_ibrow[0, 0] + face_shape[0, 0]) \/ 2)\n        x2 = int((right_ibrow[4, 0] + face_shape[16, 0]) \/ 2)\n        y = min(np.min(left_ibrow[:, 1]), np.min(right_ibrow[:, 1]))\n        y2 = nose_line[1, 1]\n        eye_eyebrow_all = image[y:y2, x:x2]\n        features['both_eye_eyebrow'] = eye_eyebrow_all\n    \n    \n    ##### Clear Eyebrow #####\n    #'Clear' represents either left or right side, \n    # it means the closer side of the face to the view, \n    # it's useful when the face is NOT looking straight\n    if 'clear_eyebrow' in options:\n        # x =  left face side OR nose top landmark (between eyebrows)\n        # x2 = between clearer eyebrow and clearer side faceshape landmark [index 16 of 81]\n        # y = top eyebrow landmark\n        # y2 = eyebrow bottom landmark\n        x = int((left_ibrow[0, 0] + face_shape[0, 0]) \/ 2) if clearer_left_side else nose_line[0,0]\n        x2 = nose_line[0,0] if clearer_left_side else int((right_ibrow[4, 0] + face_shape[16, 0]) \/ 2)\n        y, y2 = np.min(clear_ibrow[:, 1]), np.max(clear_ibrow[:, 1])  \n        clear_ibrow_img = image[y:y2, x:x2]\n        features['clear_eyebrow'] = clear_ibrow_img\n    \n    \n    ##### Clear Eye #####\n    #'Clear' represents either left or right side, \n    # it means the closer side of the face to the view, \n    # it's useful when the face is NOT looking straight\n    if 'clear_eye' in options:\n        # x = leftEye.x OR rightEye.x\n        # x2 = leftEye.x2 OR rightEye.x2\n        # y = between clear eyebrow and clear eye\n        # y2 = second top nose landmark\n        x = int((leftEye[0, 0] + face_shape[0, 0]) \/ 2) if clearer_left_side else nose_line[0, 0]\n        x2 = nose_line[0, 0] if clearer_left_side else int((rightEye[4, 0] + face_shape[16, 0]) \/ 2)\n        y = int((np.min(clear_ibrow[:, 1]) + np.min(clear_eye[:, 1])) \/ 2)\n        y2 = nose_line[1,1]\n        clear_eye_img = image[y:y2, x:x2]\n        features['clear_eye'] = clear_eye_img\n        \n    \n    ##### Clear Eye and Eyebrow #####\n    #'Clear' represents either left or right side, \n    # it means the closer side of the face to the view, \n    # it's useful when the face is NOT looking straight\n    if 'clear_eye_eyebrow' in options:\n        # x =  left face side OR nose top landmark (between eyebrows)\n        # x2 = between clearer eyebrow and clearer side faceshape landmark [index 16 of 81]\n        # y = top eyebrow landmark\n        # y2 = second top nose landmark\n        x = int((left_ibrow[0, 0] + face_shape[0, 0]) \/ 2) if clearer_left_side else nose_line[0,0]\n        x2 = nose_line[0,0] if clearer_left_side else int((right_ibrow[4, 0] + face_shape[16, 0]) \/ 2)\n        y = np.min(clear_ibrow[:, 1])\n        y2 = nose_line[1,1]\n        clear_eye_eyebrow = image[y:y2, x:x2]\n        features['clear_eye_eyebrow'] = clear_eye_eyebrow\n        \n    \n    ##### Nose #####\n    if 'nose' in options:\n        # x = the most right landmark of left eye || nose bottom landmark if it's more left\n        # x2 = the most left landmark of right eye|| nose bottom landmark if it's more right\n        # y = average point on Y-axis of eyebrow\n        # y2 = upper lip top landmark\n        x = min(leftEye[3,0], nose_arc[0, 0])\n        x2 = max(rightEye[0,0], nose_arc[4, 0])\n        y = int(np.average(clear_ibrow[:, 1]))\n        y2 = upper_lip[2, 1]\n        nose = image[y:y2, x:x2]\n        features['nose'] = nose\n        \n\n    ##### Mouth #####\n    if 'mouth' in options:\n        # x = left cheek [index 5 of 81]\n        # x2 = right cheek [index 11 of 81]\n        # y = nose bottom landmark\n        # y2 = point between chin bottom landmark and lower lip [index 68 of 81]\n        x = face_shape[5,0]\n        x2 = face_shape[11,0]\n        y = nose_arc[2, 1]\n        y2 = landmarks_points[8,1] - int((landmarks_points[8,1]-landmarks_points[57,1]) \/ 2)\n        mouth = image[y:y2, x:x2]\n        features['mouth'] = mouth\n    \n    ##### Main Features: Eyebrow Eye Nose Mouth ##### \n    if 'eye_nose_mouth_eyebrow' in options:\n        # x = between left eyebrow and left side faceshape landmark [index 0 of 81]\n        # x2 = between right eyebrow and right side faceshape landmark [index 16 of 81]\n        # y = top eyebrow landmark\n        # y2 =point between chin bottom landmark and lower lip [index 68 of 81]\n        x = int((left_ibrow[0, 0] + face_shape[0, 0]) \/ 2)\n        x2 = int((right_ibrow[4, 0] + face_shape[16, 0]) \/ 2)\n        y = min(np.min(left_ibrow[:, 1]), np.min(right_ibrow[:, 1]))\n        y2 = landmarks_points[8,1] - int((landmarks_points[8,1]-landmarks_points[57,1]) \/ 2)\n        general_features = image[y:y2, x:x2]\n        features['eye_nose_mouth_eyebrow'] = general_features\n    \n    return features\n","060fb3ed":"# Drawing Functions\n\n# Function to draw points on facial features\ndef drawPoints(image, points, pointColor=(255,255,255), lineColor=(255,255,255), pointThickness=None, lineThickness=1):\n    if pointThickness is None:\n        pointThickness = round((7\/1200) * image.shape[1])\n    imgcopy = image.copy()\n    for i in points:\n        x,y = i\n        imgcopy = cv2.circle(imgcopy, (x,y), radius=0, color=pointColor, thickness=pointThickness)\n    return imgcopy\n\ndef plot_features(features):\n    figsize = (6,6)\n    plt.figure(figsize=figsize)\n    plt.title(\"Forehead\")\n    plt.imshow(features['forehead'])\n    plt.axis(\"off\")\n    plt.show()\n    \n    \n    f, ax = plt.subplots(1,2, figsize=figsize)\n    ax[0].imshow(features['left_eyebrow'])\n    ax[0].set_title(\"Left Eyebrow\")\n    ax[0].set_axis_off()\n    \n    ax[1].imshow(features['right_eyebrow'])\n    ax[1].set_title(\"Right Eyebrow\")\n    ax[1].set_axis_off()\n    \n    \n    plt.figure(figsize=figsize)\n    plt.imshow(features['both_eyebrow'])\n    plt.title(\"Both Eyebrows\")\n    plt.axis(\"off\")\n    plt.show()\n    \n    \n    f, ax = plt.subplots(1,2, figsize=figsize)\n    ax[0].imshow(features['left_eye'])\n    ax[0].set_title(\"Left Eye\")\n    ax[0].set_axis_off()\n    \n    ax[1].imshow(features['right_eye'])\n    ax[1].set_title(\"Right Eye\")\n    ax[1].set_axis_off()\n    \n    \n    plt.figure(figsize=figsize)\n    plt.imshow(features['both_eye'])\n    plt.title(\"Both Eyes\")\n    plt.axis(\"off\")\n    plt.show()\n    \n    \n    f, ax = plt.subplots(1,2, figsize=figsize)\n    ax[0].imshow(features['left_eye_eyebrow'])\n    ax[0].set_title(\"Left Eye & Eyebrow\")\n    ax[0].set_axis_off()\n    \n    ax[1].imshow(features['right_eye_eyebrow'])\n    ax[1].set_title(\"Right Eye & Eyebrow\")\n    ax[1].set_axis_off()\n    \n    \n    plt.figure(figsize=figsize)\n    plt.imshow(features['both_eye_eyebrow'])\n    plt.title(\"Both Eyes & Eyebrows\")\n    plt.axis(\"off\")\n    plt.show()\n    \n    plt.figure(figsize=(4,4))\n    plt.imshow(features['nose'])\n    plt.title(\"Nose\")\n    plt.axis(\"off\")\n    plt.show()\n    \n    \n    plt.figure(figsize=(4,4))\n    plt.imshow(features['mouth'])\n    plt.title(\"Mouth\")\n    plt.axis(\"off\")\n    plt.show()\n    \n    \n    plt.figure(figsize=figsize)\n    plt.imshow(features['eye_nose_mouth_eyebrow'])\n    plt.title(\"Main Features\")\n    plt.axis(\"off\")\n    plt.show()","8743df21":"def main():\n    # Capture all images in current folder & their names\n    images, filesnames = load_images_from_folder('..\/input\/face-sample')\n    \n    # Detect & Visualize a sample\n    for originalImage in images:\n        \n        # Convert BGR to RGB\n        originalImage = cv2.cvtColor(originalImage,cv2.COLOR_BGR2RGB)\n        \n        # Show Original Image\n        plt.figure(figsize=(6,6))\n        plt.imshow(originalImage)\n        plt.axis(\"off\")\n        plt.show()\n        \n        # Detect eyes landmarks (used for face alignment)\n        eyes_landmarks = facial_landmarks(originalImage, eyeOnlyMode=True)\n        \n        if eyes_landmarks is not None:\n            \n            # Align face\n            image = align_face(originalImage, eyes_landmarks)\n            \n            # Detect landmarks\n            improved_landmarks = facial_landmarks(image, allowEnhancement=True)\n\n            \n            # Select features to extract\n            options = ['all']\n            \n            # Available options:\n            \n#             'forehead', 'left_eyebrow', 'right_eyebrow',\n#             'left_eye', 'right_eye', \n#             'left_eye_eyebrow', 'right_eye_eyebrow',\n#             'nose', 'mouth', 'eye_nose_mouth_eyebrow',\n#             'both_eyebrow', 'both_eye', 'both_eye_eyebrow', \n#             'clear_eyebrow', 'clear_eye', 'clear_eye_eyebrow',\n    \n            # Extract features\n            features = extract_features(originalImage, improved_landmarks, options)\n            \n            # Plot 13 features out of 16 (ignoring last 3)\n            plot_features(features)\n","d07367e2":"main()","9bbe60bf":"# Facial Features Extraction\n\n<h3>Conclusion:<\/h3>\n<h5>Extract 16 facial features -13 unique-, with the ability to detect the clear side of the face (in case the face is NOT looking straight) and to extract the features of that side.<\/h5>\n<img src=\"https:\/\/user-images.githubusercontent.com\/50156227\/141173585-6027a668-13c5-4f9c-8dc0-85bda8f84732.jpg\" height=\"640\">\n<br>\n<h4><b>Note:<\/b><\/h4>\n<p>\n    Some improvements are applied to the landmarks detection, for more information visit <a href=\"https:\/\/www.kaggle.com\/zeyadkhalid\/full-face-81-landmarks-detection-highly-improved\" target=\"_blank\">(this)<\/a> notebook\n<\/p>\n\n<h3>Features:<\/h3>\n<ol>\n    <li>\n        <b>Forehead<\/b>\n    <\/li>\n     <li>\n        <b>Left Eyebrow<\/b>\n    <\/li>\n    <li>\n        <b>Right Eyebrow<\/b>\n    <\/li>\n    <li>\n        <b>Both Eyebrows<\/b>\n    <\/li>\n    <li>\n        <b>Left Eye<\/b>\n    <\/li>\n    <li>\n        <b>Right Eye<\/b>\n    <\/li>\n    <li>\n        <b>Both Eyes<\/b>\n    <\/li>\n    <li>\n        <b>Left Eye and Eyebrow<\/b>\n    <\/li>\n    <li>\n        <b>Right Eye and Eyebrow<\/b>\n    <\/li>\n    <li>\n        <b>Both Eyes and Eyebrows<\/b>\n    <\/li>\n    <li>\n        <b>Nose<\/b>\n    <\/li>\n    <li>\n        <b>Mouth<\/b>\n    <\/li>\n    <li>\n        <b>Main Features (Eyebrows, Eyes, Nose, Mouth)<\/b>\n    <\/li>\n    <li>\n        <b>Clear Eye<\/b>: 'Clear' represents either left or right side, it means the closer side of the face to the view, it's useful when the face is NOT looking straight\n    <\/li>\n    <li>\n        <b>Clear Eyebrow<\/b>\n    <\/li>\n    <li>\n        <b>Clear Eye and Eyebrow<\/b>\n    <\/li>\n<\/ol>\n<h3><b>Inspirational Ideas<\/b><\/h3>\n<ul>\n    <li>Emotion Recognition from facial features<\/li>\n    <li>Face Identification \/ Authentication<\/li>\n    <li>Detect personality traits from facial features<\/li>\n    <li>Gender Classification<\/li>\n    <li>Down Syndrome Detection<\/li>\n<\/ul>"}}