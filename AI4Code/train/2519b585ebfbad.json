{"cell_type":{"4deb91c8":"code","d31cc42e":"code","02144063":"code","52ca063f":"code","59a02846":"code","2b56717b":"code","dfb20acc":"code","11171786":"code","a17d1ccf":"code","64ce13ca":"code","94477666":"code","0f4da932":"code","264fd5c9":"code","b299a3cf":"code","fcdec74e":"code","5b7261de":"code","5482298d":"code","e05f68bf":"code","19785ccd":"code","d09ebcfc":"code","14d6669d":"code","8677e29b":"code","5019b496":"code","9e4e9bc2":"code","c36a0e32":"code","ffaac23d":"markdown","6ea97e12":"markdown","3dc26ef7":"markdown","98056b8c":"markdown","70afdf97":"markdown","af725798":"markdown","f7a9d607":"markdown"},"source":{"4deb91c8":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline","d31cc42e":"from keras.models import Model\nfrom keras.layers import Input,Dense, Dropout ,Lambda, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam ,RMSprop\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator","02144063":"for dirname, _, filenames in os.walk('\/kaggle\/input\/digit-recognizer'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","52ca063f":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain.head()","59a02846":"print(train.shape)","2b56717b":"test= pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntest.head()","dfb20acc":"print(test.shape)","11171786":"y_train = train['label'].values.astype('int32')\ny_train","a17d1ccf":"X_train = train.drop(['label'],axis = 1).values.astype('float32')\nX_train.shape","64ce13ca":"X_train","94477666":"X_test = test.values.astype('float32')\nX_test.shape","0f4da932":"pd.Series(y_train).value_counts().plot(kind='bar')\nplt.show()","264fd5c9":"## Reshape the data into image format \nn_images = X_train.shape[0]\npixel_size = 28\n\nX_train = X_train.reshape((n_images,pixel_size,pixel_size))\n\n## Plot random images\nfor i in range(100,105):\n    plt.subplot(550 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i]);","b299a3cf":"## Add one more dimension for color \nX_train = X_train.reshape((n_images,pixel_size,pixel_size,1))\nX_test = X_test.reshape((X_test.shape[0],pixel_size,pixel_size,1))\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")","fcdec74e":"X_train  = X_train\/255\nX_test = X_test\/255","5b7261de":"y_train= to_categorical(y_train)\nprint(f\"Number of classes {y_train.shape[1]}\")","5482298d":"\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)","e05f68bf":"def CNN(lr = 0.075):\n    optimizer = Adam(lr=lr)\n    inputs = Input((28,28,1))\n    X = Conv2D(32,(5,5), activation='relu')(inputs)\n    X = BatchNormalization()(X)\n    X = Conv2D(32,(5,5), activation='relu')(X)\n    X = MaxPool2D()(X)\n    X = Dropout(0.25)(X)\n    X = BatchNormalization()(X)\n    X = Conv2D(64,(3,3), activation='relu')(X)\n    X = BatchNormalization()(X)\n    X = Conv2D(64,(3,3), activation='relu')(X)\n    X = MaxPool2D()(X)\n    X = Dropout(0.25)(X)\n    X = Flatten()(X)\n    X = BatchNormalization()(X)\n    X = Dense(512, activation='relu')(X)\n    X = Dropout(0.5)(X)\n    X = BatchNormalization()(X)\n    X = Dense(10, activation='softmax')(X)\n    model = Model(inputs = inputs, outputs = X)\n    model.compile(optimizer = optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n    return model","19785ccd":"batch_size = 128\nepochs = 20\nmodel = CNN()\nmodel.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_val,y_val))\nscore = model.evaluate(X_val,y_val, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\nmodel.save(\"model.h5\")","d09ebcfc":"datagen = ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=10,\n    zoom_range = 0.1,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=False,\n    vertical_flip=False)\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ndatagen.fit(X_train)\n\n# fits the model on batches with real-time data augmentation:\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n                    steps_per_epoch=len(y_train) \/ batch_size, \n                    epochs = epochs, \n                    verbose = 2,\n                    validation_data = (X_val,y_val))","14d6669d":"model.save(\"model_aug.h5\")","8677e29b":"predictions = model.predict(X_test, verbose=0)\nprint(predictions)\n","5019b496":"y_classes = predictions.argmax(axis=-1)\nprint(y_classes)","9e4e9bc2":"submission = pd.DataFrame({\"ImageId\": list(range(1,len(y_classes)+1)),\n                         \"Label\": y_classes})\nsubmission.to_csv(\"submission_augumented.csv\", index=False)","c36a0e32":"submission.shape","ffaac23d":"### Test Model on Test Data","6ea97e12":"### Change shape of target label to a 10 dimensional one hot matrix","3dc26ef7":"### Build CNN","98056b8c":"### How can we improve accuracy further ?\nWe have around 42k samples in training data. Most of the times, accuracy can be improved by adding more training data. When we don't have more data available, you can use data augumentation techniques to increase the training data. Data Augumentation includes applying random rotations, resizing, shearing etc. We will use `ImageDataGenerator` utility from `Keras` library to generate more data. ","70afdf97":"### Train Validation Split","af725798":"### Normalize Pixel Values","f7a9d607":"## Preprocessing of data"}}