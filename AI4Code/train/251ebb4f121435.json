{"cell_type":{"b1b73e84":"code","e2a44724":"code","57b1d36d":"code","be179471":"code","898b58c8":"code","a31931b8":"code","65964ce0":"code","c7f9440b":"code","83ea5d29":"code","35bc0e2c":"code","0cdc0762":"code","ce390006":"code","35296e95":"code","c4d1a1a4":"code","045dba90":"code","fead88d0":"code","c7b24e43":"code","3033167c":"code","58f940fb":"code","577b0aff":"code","9dcd0cfa":"code","4b523b47":"code","f1c397f1":"code","1c262925":"code","e9c8e93b":"code","51780b81":"code","9786e772":"code","45752bea":"code","a182ed65":"code","1e97d30c":"markdown","ff4fa840":"markdown","694b5e7c":"markdown","111ea015":"markdown","3ead78af":"markdown","9c5ad16a":"markdown"},"source":{"b1b73e84":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/data-2\/test.csv\", dst = \"..\/working\/test.csv\"'')\ncopyfile(src = \"..\/input\/data-2\/train.csv\", dst = \"..\/working\/train.csv\")\ncopyfile(src = \"..\/input\/process-and-utils\/Data_Preprocessing.py\", dst = \"..\/working\/Data_Preprocessing.py\")\ncopyfile(src = \"..\/input\/process-and-utils\/Utils_funX.py\", dst = \"..\/working\/Utils_funX.py\")\ncopyfile(src = \"..\/input\/brightness-and-sharpness-augmented-data2\/Brightness_And_Sharpness_Augmented_data2.ipynb\", dst = \"..\/working\/Brightness_And_Sharpness_Augmented_data2.ipynb\")","e2a44724":"!pip install plantcv","57b1d36d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom Utils_funX import *\nfrom Data_Preprocessing import *\nfrom keras.layers import *","be179471":"%env JOBLIB_TEMP_FOLDER=\/tmp","898b58c8":"train_data = pd.read_csv(\"train.csv\")\ntest_data = pd.read_csv(\"test.csv\")","a31931b8":"#Since we have no Null values in the dataset--> we only remov the Duplicates\ntrain_data = remove_duplicates(train_data)\ntest_data = remove_duplicates(test_data)\nprint(\"\\nThe shape of the Traning samples after Data Preprocessing is {} \\n\".format(train_data.shape))\nprint(\"\\nThe shape of the Testing samples after after Data Preprocessing is {} \\n\".format(test_data.shape))","65964ce0":"x_train,y_train,x_test,y_test = Data_Preparation(train_data,test_data)","c7f9440b":"import gc\ndel train_data\ndel test_data\ngc.collect()","83ea5d29":"print(\"\\nThe train and test data Shapes are :\",x_train.shape,y_train.shape,x_test.shape,y_test.shape)","35bc0e2c":"x_train,x_test=Data_Normalization(x_train,x_test)","0cdc0762":"width = 48\nheight = 48","ce390006":"x_train = x_train.reshape(x_train.shape[0],width,height,)\nx_test = x_test.reshape(x_test.shape[0],width,height,)","35296e95":"x_train.shape","c4d1a1a4":"from keras.utils import to_categorical\n\ny_train = to_categorical(y_train,7)\nprint(y_train.shape)\ny_train","045dba90":"y_test = to_categorical(y_test,7)\nprint(y_test.shape)\ny_test","fead88d0":"x_train[0]","c7b24e43":"x_train.shape,x_test.shape","3033167c":"!pip3 install import_ipynb","58f940fb":"import cv2\nfrom PIL import Image\nfrom keras.preprocessing.image import array_to_img\nfrom keras.preprocessing.image import img_to_array","577b0aff":"x_t = []\n\nfor i in range(len(x_train)):\n    x = x_train[i]\n    x = array_to_img(np.reshape(x,(48,48,1)))\n    x = x.resize((96,96))\n    x = np.reshape(img_to_array(x),(96,96))\n    \n    x_t.append(x)\nx_train = np.array(x_t)\n\nx_train.shape","9dcd0cfa":"del x\ndel x_t\ngc.collect()","4b523b47":"x_t = []\n\nfor i in range(len(x_test)):\n    x = x_test[i]\n    x = array_to_img(np.reshape(x,(48,48,1)))\n    x = x.resize((96,96))\n    x = np.reshape(img_to_array(x),(96,96))\n    \n    x_t.append(x)\nx_test = np.array(x_t)\n\nx_test.shape","f1c397f1":"del x_t\ndel x\ngc.collect()","1c262925":"import import_ipynb\nfrom Brightness_And_Sharpness_Augmented_data2 import *","e9c8e93b":"# adding two type of data 1 -> vertically flipped and horizontally fliped\n# therefore After augmentation\n\nx_train1,y_train1=Brightness_And_Sharpness_Augmented_data(x_train,y_train,len(x_train))\nx_train2,y_train2=Data_Augmentation(x_train,y_train)\n\nx_train = np.concatenate((x_train1,x_train2)) \ny_train = np.concatenate((y_train1,y_train2))","51780b81":"del x_train1\ndel y_train1\ndel x_train2\ndel y_train2\ngc.collect()","9786e772":"x_train.shape, y_train.shape","45752bea":"x_train.shape, y_train.shape","a182ed65":"#Storing the final Augmented X and Y values in the  a csv file\nfrom numpy import savez_compressed\nsavez_compressed('x_train.npz',x_train)\nsavez_compressed('x_test.npz',x_test)\nsavez_compressed('y_train.npz',y_train)\nsavez_compressed('y_test.npz',y_test)","1e97d30c":"##### Normalization","ff4fa840":"#### Real Time Emotion Detection from Facial Expression using CNN","694b5e7c":"#### Data Augmentation","111ea015":"##### Cleaning the Data ","3ead78af":"##### Train and Test Data Preparation ","9c5ad16a":"##### Importing the dataset"}}