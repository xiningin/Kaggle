{"cell_type":{"865e4044":"code","8a76d867":"code","7d1bfde2":"code","e2136f5f":"code","bbdf4502":"code","090e2ef9":"code","0cf5b5ec":"code","5985373e":"code","3a3da608":"code","de5db462":"code","55f04d61":"code","911a1e87":"code","a9fff701":"code","7ccdaf25":"markdown","6c5c450a":"markdown","3f2937c8":"markdown","03a59555":"markdown","74a666e9":"markdown","34417dde":"markdown","b9f2d6eb":"markdown"},"source":{"865e4044":"import json\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import text, sequence","8a76d867":"def build_test(test_path):\n    with open(test_path) as f:\n        processed_rows = []\n\n        for line in tqdm(f):\n            line = json.loads(line)\n\n            text = line['document_text'].split(' ')\n            question = line['question_text']\n            example_id = line['example_id']\n\n            for candidate in line['long_answer_candidates']:\n                start = candidate['start_token']\n                end = candidate['end_token']\n\n                processed_rows.append({\n                    'text': \" \".join(text[start:end]),\n                    'question': question,\n                    'example_id': example_id,\n                    'PredictionString': f'{start}:{end}'\n\n                })\n\n        test = pd.DataFrame(processed_rows)\n    \n    return test","7d1bfde2":"directory = '\/kaggle\/input\/tensorflow2-question-answering\/'\ntest_path = directory + 'simplified-nq-test.jsonl'\ntest = build_test(test_path)\nsubmission = pd.read_csv(\"..\/input\/tensorflow2-question-answering\/sample_submission.csv\")\n\ntest.head()","e2136f5f":"def compute_text_and_questions(test, tokenizer):\n    test_text = tokenizer.texts_to_sequences(test.text.values)\n    test_questions = tokenizer.texts_to_sequences(test.question.values)\n    \n    test_text = sequence.pad_sequences(test_text, maxlen=300)\n    test_questions = sequence.pad_sequences(test_questions)\n    \n    return test_text, test_questions","bbdf4502":"model = load_model('\/kaggle\/input\/tf-qa-new-start\/model.h5')\nmodel.summary()","090e2ef9":"with open('\/kaggle\/input\/tf-qa-new-start\/tokenizer.pickle', 'rb') as f:\n    tokenizer = pickle.load(f)","0cf5b5ec":"test_text, test_questions = compute_text_and_questions(test, tokenizer)","5985373e":"del test['text']\ndel test['question']","3a3da608":"%%time\ntest_target = model.predict([test_text, test_questions], batch_size=512)","de5db462":"test['target'] = test_target\n\nresult = (\n    test.query('target > 0.3')\n    .groupby('example_id')\n    .max()\n    .reset_index()\n    .loc[:, ['example_id', 'PredictionString']]\n)\n\nresult.head()","55f04d61":"result = pd.concat([\n    result.assign(example_id=lambda example_id: example_id + '_long'),\n    result.assign(example_id=lambda example_id: example_id + '_short')\n])","911a1e87":"final_submission = (\n    submission.drop(columns='PredictionString')\n    .merge(result, on=['example_id'], how='left')\n)\n\nfinal_submission.head()","a9fff701":"final_submission.to_csv(\"submission.csv\", index=False)","7ccdaf25":"# Prediction","6c5c450a":"## Load Model and Tokenizer","3f2937c8":"# Submit","03a59555":"# Load Test dataframe","74a666e9":"# Infer using trained model","34417dde":"## Load test text and q's","b9f2d6eb":"# About this kernel\n\nThis is the inference kernel for my previous kernel, [TF2 QA: LSTM for long answers predictions](https:\/\/www.kaggle.com\/xhlulu\/tf2-qa-lstm-for-long-answers-predictions). "}}