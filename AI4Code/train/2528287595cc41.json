{"cell_type":{"75b14f4e":"code","81b09c2a":"code","d9be6176":"code","6f280651":"code","f17e76c7":"code","49e5675f":"code","9804c35f":"code","ca4ff232":"code","642e7004":"code","b1ce4ad2":"code","111edc9f":"code","70dafa78":"code","6aab8c1a":"code","463c74df":"code","f73358ec":"code","274f2ea4":"code","0bb96d20":"code","459bde15":"markdown","fa82fc8f":"markdown","fe5124c2":"markdown","7b36d3c6":"markdown","fcedfc5d":"markdown","87fc8710":"markdown","cd0e2a3f":"markdown","6cf2b7c6":"markdown"},"source":{"75b14f4e":"import pandas as pd\nimport numpy as np\nnp.random.seed(0)\nfrom sklearn.metrics import recall_score,precision_score,f1_score\nfrom sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\ntf.compat.v1.set_random_seed(0)\nfrom tensorflow import keras","81b09c2a":"data_train = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\nprint(\"Total missing values : \",sum(list(data_train.isna().sum())))\ndata_train","d9be6176":"train_features=[]\ntrain_labels = []\nfor i in range(60000):\n    train_features.append(np.array(data_train.iloc[i][1:]).reshape(28,28))\n    train_labels.append(data_train.iloc[i][0])","6f280651":"train_features = np.array(train_features)\ntrain_labels = np.array(train_labels).reshape(-1,1)\nprint(\"Train Features : \",train_features.shape)\nprint(\"Train Labels : \",train_labels.shape)","f17e76c7":"data_test = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\nprint(\"Total missing values : \",sum(list(data_test.isna().sum())))\ndata_test","49e5675f":"test_features=[]\ntest_labels = []\nfor i in range(10000):\n    test_features.append(np.array(data_test.iloc[i][1:]).reshape(28,28,1))\n    test_labels.append(data_test.iloc[i][0])","9804c35f":"test_features = np.array(test_features).reshape(-1,28,28,1)\ntrain_features = np.array(train_features).reshape(-1,28,28,1)\ntest_labels = np.array(test_labels).reshape(-1,1)\nprint(\"Test Features : \",test_features.shape)\nprint(\"Test Labels : \",test_labels.shape)","ca4ff232":"classes = [\"T-shirt\/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\nun,count = np.unique(train_labels,return_counts=True)\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nplt.bar([classes[i] for i in un],count)\nplt.xlabel(\"Classes\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Count\")\nplt.title(\"Train class balancing\")\n\nplt.subplot(1,2,2)\nun,count = np.unique(test_labels,return_counts=True)\nplt.bar([classes[i] for i in un],count)\nplt.xlabel(\"Classes\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Count\")\nplt.title(\"Test class balancing\")\nplt.show()","642e7004":"\nplt.figure(figsize=(10,10))\nplt.subplot(3,3,1)\nplt.imshow(train_features[0],cmap='gray')\nplt.title(classes[train_labels[0][0]])\n\nplt.subplot(3,3,2)\nplt.imshow(train_features[1],cmap='gray')\nplt.title(classes[train_labels[1][0]])\n\nplt.subplot(3,3,3)\nplt.imshow(train_features[2],cmap='gray')\nplt.title(classes[train_labels[2][0]])\n\nplt.subplot(3,3,4)\nplt.imshow(train_features[3],cmap='gray')\nplt.title(classes[train_labels[3][0]])\n\nplt.subplot(3,3,5)\nplt.imshow(train_features[4],cmap='gray')\nplt.title(classes[train_labels[4][0]])\n\nplt.subplot(3,3,6)\nplt.imshow(train_features[5],cmap='gray')\nplt.title(classes[train_labels[5][0]])\n\nplt.subplot(3,3,7)\nplt.imshow(train_features[6],cmap='gray')\nplt.title(classes[train_labels[6][0]])","b1ce4ad2":"train_features = train_features \/ 255.0\ntest_features = test_features \/ 255.0","111edc9f":"model = keras.models.Sequential()\nmodel.add(keras.layers.Conv2D(16,(2,2),activation='relu',input_shape=(28,28,1)))\nmodel.add(keras.layers.MaxPool2D((2,2)))\nmodel.add(keras.layers.Conv2D(32,(2,2),activation='relu'))\nmodel.add(keras.layers.MaxPool2D((2,2)))\n\nmodel.add(keras.layers.Flatten())\n\nmodel.add(keras.layers.Dense(1024,activation='relu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(128,activation='relu'))\nmodel.add(keras.layers.Dropout(0.3))\nmodel.add(keras.layers.Dense(10,activation='softmax'))\nmodel.summary()\n","70dafa78":"model.compile(optimizer=keras.optimizers.Adam(0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])","6aab8c1a":"ep = 7\nhistory = model.fit(train_features,\n                    train_labels,\n                    batch_size=64,\n                    validation_batch_size=1,\n                    validation_data = (test_features,test_labels),\n                    epochs = ep)","463c74df":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nplt.plot([str(i) for i in range(1,ep+1)],history.history['accuracy'],label=\"Train Accuracy\")\nplt.plot([str(i) for i in range(1,ep+1)],history.history['val_accuracy'],label=\"Validation Accuracy\")\nplt.title(\"Accuracy vs Epoch curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot([str(i) for i in range(1,ep+1)],history.history['loss'],label=\"Train Loss\")\nplt.plot([str(i) for i in range(1,ep+1)],history.history['val_loss'],label=\"Validation Loss\")\nplt.title(\"Loss vs Epoch curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","f73358ec":"print(\"Test accuracy : {:.2f} %\".format(model.evaluate(test_features,test_labels)[1]*100))\nprint(\"Test loss : {:.4f}\".format(model.evaluate(test_features,test_labels)[0]))","274f2ea4":"y_pred = model.predict(test_features)\ny_pred = np.argmax(y_pred,1)\nprint(\"Precision : {:.2f} %\".format(precision_score(test_labels,y_pred,average=\"macro\")*100))\nprint(\"Recall : {:.2f} %\".format(recall_score(test_labels,y_pred,average=\"macro\")*100))\nprint(\"F1 Score : {:.2f} %\".format(f1_score(test_labels,y_pred,average=\"macro\")*100))","0bb96d20":"fig,ax = plt.subplots(figsize=(20,8))\ncfm = confusion_matrix(test_labels,y_pred)\ndisp = ConfusionMatrixDisplay(cfm,display_labels=classes)\ndisp.plot(ax= ax)\nplt.show()","459bde15":"<h1>Data Analysis - Class Balancing<\/h1>","fa82fc8f":"<h1>Data Preparation<\/h1>\n<p>Since it is image data, let us scale the values to [0-1] range<\/p>","fe5124c2":"![](https:\/\/debuggercafe.com\/wp-content\/uploads\/2019\/04\/New-Fashion-Collection.png)","7b36d3c6":"<h1>Data Collection<\/h1>\n<p>Since data is provided in the form of a csv file, parse csv file and combine columns into 28x28 array. Train and test data are provide separately in two csv files<\/p>","fcedfc5d":"<h1>Data Modelling<\/h1>","87fc8710":"<h1>Model Evaluation<\/h1>\n<p>Generated model is evaluated using the following measures<\/p>\n<ul>\n    <li>Train and Test accuracy<\/li>\n    <li>Precision<\/li>\n    <li>Recall<\/li>\n    <li>F1 Score<\/li>\n    <li>Confusion Matrix<\/li>\n<\/ul>","cd0e2a3f":"<h1>Fashion MNIST Classification<\/h1>\n<p>In this notebook, we will generate a keras model for MNIST Fashion dataset<\/p>","6cf2b7c6":"<h1>Data Visualization<\/h1>"}}