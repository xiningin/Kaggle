{"cell_type":{"d202ffcd":"code","0196e926":"code","d7b1c160":"code","d8a7236b":"code","f477574b":"code","546074af":"code","f4ae6054":"code","de94532b":"code","4940af0d":"code","18b9529c":"code","cab646b9":"code","56011682":"code","a94b3461":"code","e7b21c95":"code","ff3c2813":"code","9c5a608d":"code","de88626d":"code","c6abfe6d":"code","c322e8b1":"code","d7b0bdee":"code","28ec6f8d":"code","ce242c51":"code","7938bcf6":"code","0128fdaa":"code","37655a6a":"code","efe6fb19":"code","54637133":"code","b50428dd":"code","6b576f9e":"code","fb1eeb6d":"markdown","d3ab9127":"markdown","4d838fc7":"markdown","bc7f4002":"markdown"},"source":{"d202ffcd":"import matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import confusion_matrix","0196e926":"!ls ..\/input","d7b1c160":"def feat_eng1(data):\n    data['norm_q'] = data['orientation_X'] ** 2 + data['orientation_Y'] ** 2 + data['orientation_Z'] ** 2 + data['orientation_W']**2\n    data['mod_q'] = data['norm_q'] ** 0.5\n    data['norm_X'] = data['orientation_X'] \/ data['mod_q']\n    data['norm_Y'] = data['orientation_Y'] \/ data['mod_q']\n    data['norm_Z'] = data['orientation_Z'] \/ data['mod_q']\n    data['norm_W'] = data['orientation_W'] \/ data['mod_q']\n    return data","d8a7236b":"def feat_eng2(data):\n    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 + data['angular_velocity_Z']**2)** 0.5\n    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 + data['linear_acceleration_Z']**2)**0.5\n    data['totl_orientation'] = (data['orientation_X']**2 + data['orientation_Y']**2 + data['orientation_Z']**2)**0.5\n    data['acc_vs_vel'] = data['totl_linr_acc'] \/ data['totl_anglr_vel']\n    return data","f477574b":"from astropy.stats import median_absolute_deviation\nfrom statsmodels.robust.scale import mad\n\ndef feat_eng3(data):\n    df = pd.DataFrame()\n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number']:\n            continue\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] \/ df[col + '_min']\n        df[col + 'median_abs_dev'] = data.groupby(['series_id'])[col].mad()\n    return df","546074af":"from fastai.imports import *\n","f4ae6054":"PATH = \"..\/input\/\"","de94532b":"train_df = pd.read_csv(f\"{PATH}X_train.csv\")\ntest_df = pd.read_csv(f\"{PATH}\/X_test.csv\")\ntrain_df = feat_eng1(train_df)\ntest_df = feat_eng1(test_df)\ntrain_df = feat_eng2(train_df)\ntest_df = feat_eng2(test_df)","4940af0d":"train_df = feat_eng3(train_df)\ntest_df = feat_eng3(test_df)","18b9529c":"label_df = pd.read_csv(f\"{PATH}y_train.csv\")","cab646b9":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","56011682":"le = LabelEncoder()","a94b3461":"le.fit(label_df.surface.unique())","e7b21c95":"y = le.transform(label_df.surface)","ff3c2813":"X_train, X_test, y_train, y_test = train_test_split(train_df, y, random_state=42)","9c5a608d":"model = RandomForestClassifier()","de88626d":"model.fit(X_train, y_train)","c6abfe6d":"accuracy_score(model.predict(X_test), y_test)","c322e8b1":"def feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)","d7b0bdee":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)","28ec6f8d":"fi = feat_importance(model, train_df)\nplot_fi(fi[:10])","ce242c51":"joined_df = train_df.join(label_df, on=\"series_id\")","7938bcf6":"joined_df.drop(\"surface\", axis=1, inplace=True)","0128fdaa":"group_model = RandomForestClassifier()","37655a6a":"X_train, X_test, y_train, y_test = train_test_split(joined_df, y, random_state=42)","efe6fb19":"group_model.fit(X_train, y_train)","54637133":"accuracy_score(group_model.predict(X_test), y_test)","b50428dd":"g_fi = feat_importance(group_model, X_train)\nplot_fi(g_fi[:10])","6b576f9e":"plot_fi(fi[:10])","fb1eeb6d":"# Importance of group ID\nI saw some posts on why group id is there in training and a [post from #1 placed submission how he co-related the orientation data with group id.](https:\/\/www.kaggle.com\/c\/career-con-2019\/discussion\/87239#latest-507715). So I though of exploring the feature importance of group id.","d3ab9127":"https:\/\/www.kaggle.com\/hiralmshah\/robot-sensor-eda-fe-and-prediction-improvement","4d838fc7":"I have done the same standard feature engineering as [this](https:\/\/www.kaggle.com\/hiralmshah\/robot-sensor-eda-fe-and-prediction-improvement) kernel. Else the results would have been even more skewed in the favour of group_id.","bc7f4002":"See how the feature importance shifts by including group_id"}}