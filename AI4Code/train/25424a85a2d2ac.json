{"cell_type":{"55e4dee3":"code","7fc2b617":"code","939a3bff":"code","3df40473":"code","07b1f8be":"code","b86aaea0":"code","4a563c15":"code","29f57d2e":"code","8692167a":"code","aa80b329":"code","0ab5ffb1":"code","5746fd42":"code","1c2772de":"code","e9f1fd6e":"code","d6a1b44f":"code","62220741":"code","b5fbef7a":"code","b0ea59e5":"code","c20fa9e1":"code","453bb73e":"code","62e8f504":"code","4d15c8a1":"code","3b8da7ed":"code","473bea7c":"code","cb182ac8":"code","6452075b":"code","7dacc9fc":"code","0c3fd162":"code","7d7ff49c":"code","8fbf1dc5":"code","e165a277":"code","49a625bc":"code","3a388db8":"code","7fd258d6":"code","ee8fd1d2":"code","ac4e32c0":"code","43b9d34a":"code","16b5c4c5":"code","14d93f0b":"code","fcc3142d":"markdown","c2d4151b":"markdown","9aa27a90":"markdown","7908c866":"markdown","79479974":"markdown","88dd6952":"markdown","b10be18b":"markdown","63571f16":"markdown","46ffdc00":"markdown","c0b62efa":"markdown","0bec759d":"markdown","b2818b2f":"markdown","bc7f4e24":"markdown","51fa8709":"markdown","4c5b0f61":"markdown","f9dc341b":"markdown","51256628":"markdown","f88830ef":"markdown","897a2cc4":"markdown","f51eec38":"markdown","323d0c0e":"markdown","cd0ea4b7":"markdown","30dfe21d":"markdown","ca5ecb10":"markdown","49646ab4":"markdown","a97ca384":"markdown","e6ad3f6e":"markdown","0084bfec":"markdown","140fa594":"markdown","9235a719":"markdown","5ee9cde2":"markdown","36bcf9ab":"markdown","d1fd963c":"markdown","0105f57c":"markdown","25af33fd":"markdown","5702b442":"markdown","60d5ce48":"markdown","c3931b68":"markdown","d5e73c6d":"markdown","8a5c4309":"markdown","67b7a02c":"markdown","a35e5693":"markdown","37198c76":"markdown","24e0c563":"markdown","ea6bc0d2":"markdown","79506c73":"markdown","d9b9a34f":"markdown","b229ede9":"markdown","a4d146fb":"markdown","9047b81a":"markdown","816a71f5":"markdown","d8f5a3c9":"markdown","00ced47c":"markdown","2e612802":"markdown","ebb58663":"markdown","8f86acb8":"markdown","05d86c0a":"markdown","8710c562":"markdown","2a38be89":"markdown","4c99182f":"markdown","bdb26fdb":"markdown","20c4497c":"markdown"},"source":{"55e4dee3":"from sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nimport torch\nfrom sklearn import svm\nfrom sklearn import tree\nimport pandas as pd\nimport pickle\nimport numpy as np\nimport seaborn as sns\nimport category_encoders as ce\nfrom sklearn.tree import DecisionTreeClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import tree","7fc2b617":"df = pd.read_csv(\"..\/input\/androidmalwaredetection\/Dataset.csv\", sep=\";\")\ndf.shape\ndf.columns = map(str.lower, df.columns)","939a3bff":"for column in df.columns.tolist():\n    print(column)","3df40473":"null_series = df.isnull().sum()\ncount =0\nfor _, val in null_series.iteritems():\n    if(val>0):\n        print (_ + \"      \"+ str(val))\n    else:\n        count = count +1\nprint(\"number of columns with no null values: \"+ str(count))\n\nna_series = df.isna().sum()\ncount =0\nfor _, val in na_series.iteritems():\n    if(val>0):\n        print (_ + \"      \"+ str(val))\n    else:\n        count = count +1\nprint(\"number of columns with no na values: \"+ str(count))","07b1f8be":"onezero = 0\nfor column in df.columns:\n    cnt = len(df[(df[column]!= 0) & (df[column]!= 1)])\n    if(cnt > 0):\n        print(column + \" has \"+ str(cnt) +\" rows with value other than 0,1\")\n    else:\n        onezero = onezero + 1\nprint(\"Total number of features with values as only 0,1: \" + str(onezero))","b86aaea0":"df = df.astype(\"int64\")","4a563c15":"df.head()","29f57d2e":"df.type.value_counts()","8692167a":"pd.Series.sort_values(df[df.type==1].sum(axis=0), ascending=False)[1:11]","aa80b329":"pd.Series.sort_values(df[df.type==0].sum(axis=0), ascending=False)[1:11]","0ab5ffb1":"fig, axs =  plt.subplots(nrows=2, sharex=True)\npd.Series.sort_values(df[df.type==0].sum(axis=0), ascending=False)[1:11].plot.bar(ax=axs[0], color=\"green\", title=\"Benign Apps\")\npd.Series.sort_values(df[df.type==1].sum(axis=0), ascending=False)[1:11].plot.bar(ax=axs[1], color=\"red\", title=\"Malware Apps\", ylabel=\"Count of apps\", xlabel=\"Permissions\")","5746fd42":"df_desc = df.describe()\ndf_desc","1c2772de":"df1= df.copy()\ndf1 = df1.loc[:,df1.columns.str.contains('type')  |  df1.columns.str.contains('write') | df1.columns.str.contains('delete') | df1.columns.str.contains('clear') | df1.columns.str.contains('boot') | df1.columns.str.contains('change')| df1.columns.str.contains('credential')|df1.columns.str.contains('admin')|df1.columns.str.contains('list')|df1.columns.str.contains('secure_storage')|df1.columns.str.contains('notifications')|df1.columns.str.contains('account')|df1.columns.str.contains('destroy')|df1.columns.str.contains('mount')|df1.columns.str.contains('authenticate')|df1.columns.str.contains('privileged')|df1.columns.str.contains('brick')|df1.columns.str.contains('transmit')|df1.columns.str.contains('capture')|df1.columns.str.contains('disable')|df1.columns.str.contains('install')|df1.columns.str.contains('certificate')|df1.columns.str.contains('send')|df1.columns.str.contains('shutdown')|df1.columns.str.contains('start_any_activity')|df1.columns.str.contains('lock')|df1.columns.str.contains('sms')|df1.columns.str.contains('call')|df1.columns.str.contains('danger')|df1.columns.str.contains('voicemail')]","e9f1fd6e":"df1.head()","d6a1b44f":"df1 = df1.loc[:, (df1 != 0).any(axis=0)]\ndf1.describe()","62220741":"bdf1 = pd.Series.sort_values(df1[df1.type==0].sum(axis=0), ascending=False)\nmdf1 = pd.Series.sort_values(df1[df1.type==1].sum(axis=0), ascending=False)\ndel bdf1['type']\ndel mdf1['type']\npd.concat({'Benign Apps': bdf1, 'Malware Apps': mdf1}, axis=1).plot.bar(figsize=(18,5))","b5fbef7a":"fig, axs =  plt.subplots(nrows=2, sharex=True)\nbdf1[1:11].plot.bar(ax=axs[1], color=\"green\", title=\"Benign Apps\")\nmdf1[1:11].plot.bar(ax=axs[0], color=\"red\", title=\"Malware Apps\", ylabel=\"Count of apps\", xlabel=\"Permissions\")","b0ea59e5":"X_train, X_test, y_train, y_test = train_test_split(df1.iloc[:, 1:42], df1['type'], test_size=0.20, random_state=42)","c20fa9e1":"X_train.shape, X_test.shape","453bb73e":"y_train.shape, y_test.shape","62e8f504":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)\npred = gnb.predict(X_test)\naccuracy = accuracy_score(pred, y_test)\nprint(\"Naive Bayes\")\nprint(\"Accuracy: \" + str(accuracy))\nprint(classification_report(pred, y_test, labels=None))","4d15c8a1":"for i in range(3,15,3):\n    \n    neigh = KNeighborsClassifier(n_neighbors=i)\n    neigh.fit(X_train, y_train)\n    pred = neigh.predict(X_test)\n    accuracy = accuracy_score(pred, y_test)\n    print(\"k-neighbors {}\".format(i))\n    print(\"Accuracy: \" + str(accuracy))\n    print(classification_report(pred, y_test, labels=None))\n    print(\"\")","3b8da7ed":"clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\nclf_gini.fit(X_train, y_train)","473bea7c":"y_pred_gini = clf_gini.predict(X_test)","cb182ac8":"print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))","6452075b":"y_pred_train_gini = clf_gini.predict(X_train)\n\ny_pred_train_gini","7dacc9fc":"print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_gini)))","0c3fd162":"print('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))\n\nprint('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))","7d7ff49c":"plt.figure(figsize=(12,8))\ntree.plot_tree(clf_gini.fit(X_train, y_train))","8fbf1dc5":"clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\nclf_en.fit(X_train, y_train)","e165a277":"y_pred_en = clf_en.predict(X_test)","49a625bc":"print('Model accuracy score with criterion entropy: {0:0.4f}'. format(accuracy_score(y_test, y_pred_en)))","3a388db8":"y_pred_train_en = clf_en.predict(X_train)\n\ny_pred_train_en","7fd258d6":"print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_en)))","ee8fd1d2":"print('Training set score: {:.4f}'.format(clf_en.score(X_train, y_train)))\n\nprint('Test set score: {:.4f}'.format(clf_en.score(X_test, y_test)))","ac4e32c0":"plt.figure(figsize=(12,8))\n\ntree.plot_tree(clf_en.fit(X_train, y_train)) ","43b9d34a":"cm = confusion_matrix(y_test, y_pred_en)\n\nprint('Confusion matrix\\n\\n', cm)","16b5c4c5":"print(classification_report(y_test, y_pred_en))","14d93f0b":"rdF=RandomForestClassifier(n_estimators=250, max_depth=50,random_state=45)\nrdF.fit(X_train,y_train)\npred=rdF.predict(X_test)\ncm=confusion_matrix(y_test, pred)\n\naccuracy = accuracy_score(y_test,pred)\nprint(\"Random Forest Classifier\")\nprint(\"Accuracy Score: \"+ str(accuracy))\nprint(classification_report(y_test,pred, labels=None))\nprint(\"cohen kappa score: \", cohen_kappa_score(y_test, pred))\nprint(\"\")\nprint('Confusion matrix\\n\\n',cm)","fcc3142d":"#### Plot 10 features","c2d4151b":"## Modeling","9aa27a90":"from above we can see that certain keywords in permission seems more suspicious so selecting those columns","7908c866":"Naive Bayes algorithm","79479974":"1.\tWe tried Naive Bayes which resulted in accuracy score of 1.0\n2.\tThen we tried K-neighbout which resulted in accuracy score as follows,\n    *     kneighbors:  3 Accuracy: 1.0\n    *     kneighbors:  6 Accuracy: 0.9125\n    *     kneighbors:  9 Accuracy: 0.9125\n    *     kneighbors: 12 Accuracy: 0.9\n3.\tSo we have built a Decision-Tree Classifier model for Android Malware Detection. We built two models, one with criterion gini index and another one with criterion entropy. These models yields a very good performance as indicated by the model accuracy in both the cases to be 1.0000\n4.\tIn the model with criterion gini index, the training-set accuracy score and the test-set accuracy to be 1.0000. These two values are same. So, there is no sign of overfitting.\n5.\tSimilarly, in the model with criterion entropy, the training-set accuracy score and the test-set accuracy to be 1.0000. These two values are same. So, there is no sign of overfitting.\n6.\tThen we tried Random forest classifier which resulted in accuracy score of  1.0 and cohen kappa score of 1.0\n7.\tThe confusion matrix and classification report yields excellent model performance.","88dd6952":"Let us find the top 10 features that determine whether the app is malware or not","b10be18b":"Get all non numeric values from the dataset","63571f16":"Since all values are either 0 or 1 no need to perform normalization","46ffdc00":"**Tasks in this assignment**","c0b62efa":"Top 10 permissions required by Malware apps","0bec759d":"Visualize decision-tree","b2818b2f":"Now, based on the above analysis we can conclude that our classification model accuracy is excellent. Our model is doing a very good job in terms of predicting the class labels.\n\nBut, it does not give the underlying distribution of values. Also, it does not tell anything about the type of errors our classifer is making.\n\nWe have another tool called Confusion matrix that comes to our rescue.","bc7f4e24":"Confusion matrix","51fa8709":"Visualize decision-trees","4c5b0f61":"So let's cast the dataframe columns to integer type to ease out our analysis process","f9dc341b":"Count of malware (1) vs benign apps (0) based on type column","51256628":"Check accuracy score with criterion gini index","f88830ef":"### Load Data","897a2cc4":"\nWith the popularity of Android devices, the number of applications made for the android operating system is\nalso increasing day by day. But the biggest challenge in this scenario is to identify if an application is an authentic\napplication or a malware. This project tries to identify an application as malware\/not based on the permissions\nrequired by the application","f51eec38":"There are no outliers in any column","323d0c0e":"Plot grouped bar chart to better understand the feature relationship","cd0ea4b7":"### Data wrangling and Pre-processing","30dfe21d":"**Expected Submissions**","ca5ecb10":"Find all outlier values in each column","49646ab4":"Random Forest","a97ca384":"#### Exploratory Analysis","e6ad3f6e":"k-neighbors algorithm","0084bfec":"We can see that the training-set score and test-set score is same as above. The training-set accuracy score is 1.0000 while the test-set accuracy to be 1.0000. These two values are quite comparable. So, there is no sign of overfitting","140fa594":"**Introduction**","9235a719":"View sample data","5ee9cde2":"**Dataset**","36bcf9ab":"#### Observation\nFrom the above bat chart it is evident that only Malware apps predominantly require permission that control sms, wifi, lock, call, apn and contacts","d1fd963c":"Here, the training-set accuracy score is 1.0000 while the test-set accuracy to be 1.0000. These two values are quite comparable. So, there is no sign of overfitting.","0105f57c":"#### Feature selection","25af33fd":"## Feature Engineering","5702b442":"Compare the train-set and test-set accuracy","60d5ce48":"Check accuracy score with criterion entropy","c3931b68":"1. Write a Data Science Proposal for achieving the objective mentioned.\n2. Perform exploratory analysis on the data and describe your understanding of the data.\n3. Perform data wrangling \/ pre-processing on the data if required\n    a. E.g., missing data, normalization, discretization, etc.\n4. Apply any two feature engineering techniques.\n5. Plot top 10 features.\n6. Implement any two Machine Learning models (SVM or Decision Tree or Random Forest or kNN or Na\u00efve Bayes etc)\n7. Compare the performance of the two models. Provide a table for comparison. (Here you may use the combination of FE1+ML1, FE1+ML2, FE2+ML1 and FE2+ML2 etc)\n8. Present the conclusions\/results in the format shared.\n","d5e73c6d":"List the features","8a5c4309":"Decision Tree","67b7a02c":"Here, y_test are the true class labels and y_pred_gini are the predicted class labels in the test-set.","a35e5693":"So there are no missing values in the dataset","37198c76":"Describing the features in the dataset","24e0c563":"Top 10 permissions required by benign apps","ea6bc0d2":"#### Import packages","79506c73":"top 10 features that determine malware","d9b9a34f":"\nRead dataset into pandas dataframe","b229ede9":"So there are 199 malwares and 199 benign apps in the dataset so the data is equally distributed","a4d146fb":"Check for overfitting and underfitting","9047b81a":"Analyze feautres ","816a71f5":"We have another tool called Confusion matrix that comes to our rescue.","d8f5a3c9":"Classification Report","00ced47c":"remove columns that contain only 0","2e612802":"Let us plot a bar char for the above top 10 features","ebb58663":"Compare the train-set and test-set accuracy to check for overfitting","8f86acb8":"# Android Malaware Detection","05d86c0a":"Predict the Test set results with criterion gini index","8710c562":"\nThe dataset given here is taken from Kaggle and consists of about 331 features which are the different android\npermissions asked by the application (0 denotes not required and 1 denotes required). The no rows\/malware\nreadings for each permission is 398. It is the \u2018type\u2019 label which represents a given row corresponding to whether\nan application is malware or not.","2a38be89":"Two files are expected as the assignment submission.\n1. The summary of the work in the template provided. (you may fill only the boxes relevant to this problem\nstatement)\n2. The executed ipynb file with clear subdivision of the codes and brief description of the purpose of\nrespective code. All the executed tables or graphs and results should be present in the ipynb file. The\nipynb file may be submitted as a single .pdf file.","4c99182f":"Check for overfitting and underfitting","bdb26fdb":"Predict the Test set results with criterion entropy","20c4497c":"Decision Tree Classifier with criterion entropy"}}