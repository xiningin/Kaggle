{"cell_type":{"2c4d104e":"code","5e5f8ec8":"code","51d753ef":"code","7dae1bde":"code","733bede5":"code","760d4417":"code","2a4dba83":"code","1cbcc2b2":"code","e24c16f3":"code","ea7f8359":"code","8a3e82c5":"code","e7c3e755":"code","d307727d":"code","b4490c66":"code","fdcb663f":"code","5d998055":"code","4f3a1fa5":"code","db8ade6b":"code","e405abdf":"code","e10601ba":"code","fe8a047a":"code","7fad368c":"code","894b22b3":"code","9aec81df":"code","12f3036b":"code","4a16f16a":"code","012a40f9":"code","e39a5477":"code","8c8495d7":"code","aa3d3990":"code","02b320a0":"code","1ac151e0":"code","33050cad":"code","437d29fb":"code","7de751d0":"code","5f4bf615":"code","c9db7e9c":"code","ebdb6a73":"code","11bcfa61":"code","f4fb0040":"code","386a14f6":"code","4b80e1ad":"code","5ab49281":"code","074aa80b":"code","46fcabf9":"code","69320fc8":"code","af98ad5b":"code","b7b02d5c":"code","dfdf4bb0":"code","7186f72a":"code","99bf0692":"code","d214e1de":"code","4053bd40":"code","f657dc16":"code","d488c1fc":"code","4b7b60ad":"code","b6d9e89b":"code","21c45b0d":"code","3314084d":"code","097279af":"code","44b40a7e":"code","e4e3f924":"code","63699ad1":"code","2a1e2fa4":"markdown","030a81f6":"markdown","9ab4b355":"markdown","4085d7f6":"markdown","dbbdfd33":"markdown","397bfdcc":"markdown","74ef87a9":"markdown","42f6ed60":"markdown","e179acfb":"markdown","86b1992a":"markdown","acf2517f":"markdown","c2e8bbce":"markdown","6052ce94":"markdown","d69af0b6":"markdown","f8ddbf0f":"markdown","153e61b0":"markdown","7713bb5c":"markdown","1c53c2f1":"markdown","45a1ba8c":"markdown","8c074ab8":"markdown","361f9996":"markdown","03d3a31a":"markdown","f970825d":"markdown","460ab174":"markdown","0e0d7fde":"markdown","749963e0":"markdown","d14e0f2a":"markdown","8f5339d7":"markdown","ab426a17":"markdown","b716e981":"markdown","7aff15d9":"markdown","99717c62":"markdown","d325ad6d":"markdown","a39bac64":"markdown","ec672615":"markdown","5a8e567b":"markdown","0c6ac8fd":"markdown","2106bcc4":"markdown","3605d41b":"markdown","8765725b":"markdown","bb9158b3":"markdown","cbc54399":"markdown","102a3177":"markdown","0b3b4e40":"markdown","8b546ed0":"markdown","47493173":"markdown","abc167eb":"markdown","a66586d2":"markdown","9e3ae847":"markdown","05b0da2a":"markdown","632bbb92":"markdown","761fa301":"markdown","68f9d620":"markdown","06e0a199":"markdown","a2e69bc9":"markdown","034ee997":"markdown","e17d4664":"markdown","01b63d66":"markdown","0b3e26f7":"markdown","f6583fa3":"markdown","b6b5505c":"markdown","f8acf290":"markdown","ac2c6c5d":"markdown","19fb7d67":"markdown","aa1914f2":"markdown","7a7c1549":"markdown","1863694b":"markdown","2edc05dd":"markdown","5593b5b9":"markdown","e435911f":"markdown","10e81428":"markdown","ec5fc7b2":"markdown","03727a57":"markdown","451d634e":"markdown","f20ea5c0":"markdown","d3696e70":"markdown","0ec83b83":"markdown","2e2f38dd":"markdown","313b2773":"markdown","a6e90d9f":"markdown","f5e861be":"markdown","51690145":"markdown","ab17ba6e":"markdown","5189b5e3":"markdown","865a41dd":"markdown","f107b090":"markdown","147a66ba":"markdown","85c80f38":"markdown","8c88c1cc":"markdown","b21ec001":"markdown","33e8fc5b":"markdown","2586fd8c":"markdown"},"source":{"2c4d104e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns # for statistical data visualization\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","5e5f8ec8":"import warnings\n\nwarnings.filterwarnings('ignore')","51d753ef":"data = '\/kaggle\/input\/predicting-a-pulsar-star\/pulsar_stars.csv'\n\ndf = pd.read_csv(data)","7dae1bde":"# view dimensions of dataset\n\ndf.shape","733bede5":"# let's preview the dataset\n\ndf.head()","760d4417":"# view the column names of the dataframe\n\ncol_names = df.columns\n\ncol_names","2a4dba83":"# remove leading spaces from column names\n\ndf.columns = df.columns.str.strip()","1cbcc2b2":"# view column names again\n\ndf.columns","e24c16f3":"# rename column names\n\ndf.columns = ['IP Mean', 'IP Sd', 'IP Kurtosis', 'IP Skewness', \n              'DM-SNR Mean', 'DM-SNR Sd', 'DM-SNR Kurtosis', 'DM-SNR Skewness', 'target_class']","ea7f8359":"# view the renamed column names\n\ndf.columns","8a3e82c5":"# check distribution of target_class column\n\ndf['target_class'].value_counts()","e7c3e755":"# view the percentage distribution of target_class column\n\ndf['target_class'].value_counts()\/np.float(len(df))","d307727d":"# view summary of dataset\n\ndf.info()","b4490c66":"# check for missing values in variables\n\ndf.isnull().sum()","fdcb663f":"# view summary statistics in numerical variables\n\nround(df.describe(),2)","5d998055":"# draw boxplots to visualize outliers\n\nplt.figure(figsize=(24,20))\n\n\nplt.subplot(4, 2, 1)\nfig = df.boxplot(column='IP Mean')\nfig.set_title('')\nfig.set_ylabel('IP Mean')\n\n\nplt.subplot(4, 2, 2)\nfig = df.boxplot(column='IP Sd')\nfig.set_title('')\nfig.set_ylabel('IP Sd')\n\n\nplt.subplot(4, 2, 3)\nfig = df.boxplot(column='IP Kurtosis')\nfig.set_title('')\nfig.set_ylabel('IP Kurtosis')\n\n\nplt.subplot(4, 2, 4)\nfig = df.boxplot(column='IP Skewness')\nfig.set_title('')\nfig.set_ylabel('IP Skewness')\n\n\nplt.subplot(4, 2, 5)\nfig = df.boxplot(column='DM-SNR Mean')\nfig.set_title('')\nfig.set_ylabel('DM-SNR Mean')\n\n\nplt.subplot(4, 2, 6)\nfig = df.boxplot(column='DM-SNR Sd')\nfig.set_title('')\nfig.set_ylabel('DM-SNR Sd')\n\n\nplt.subplot(4, 2, 7)\nfig = df.boxplot(column='DM-SNR Kurtosis')\nfig.set_title('')\nfig.set_ylabel('DM-SNR Kurtosis')\n\n\nplt.subplot(4, 2, 8)\nfig = df.boxplot(column='DM-SNR Skewness')\nfig.set_title('')\nfig.set_ylabel('DM-SNR Skewness')","4f3a1fa5":"# plot histogram to check distribution\n\n\nplt.figure(figsize=(24,20))\n\n\nplt.subplot(4, 2, 1)\nfig = df['IP Mean'].hist(bins=20)\nfig.set_xlabel('IP Mean')\nfig.set_ylabel('Number of pulsar stars')\n\n\nplt.subplot(4, 2, 2)\nfig = df['IP Sd'].hist(bins=20)\nfig.set_xlabel('IP Sd')\nfig.set_ylabel('Number of pulsar stars')\n\n\nplt.subplot(4, 2, 3)\nfig = df['IP Kurtosis'].hist(bins=20)\nfig.set_xlabel('IP Kurtosis')\nfig.set_ylabel('Number of pulsar stars')\n\n\n\nplt.subplot(4, 2, 4)\nfig = df['IP Skewness'].hist(bins=20)\nfig.set_xlabel('IP Skewness')\nfig.set_ylabel('Number of pulsar stars')\n\n\n\nplt.subplot(4, 2, 5)\nfig = df['DM-SNR Mean'].hist(bins=20)\nfig.set_xlabel('DM-SNR Mean')\nfig.set_ylabel('Number of pulsar stars')\n\n\n\nplt.subplot(4, 2, 6)\nfig = df['DM-SNR Sd'].hist(bins=20)\nfig.set_xlabel('DM-SNR Sd')\nfig.set_ylabel('Number of pulsar stars')\n\n\n\nplt.subplot(4, 2, 7)\nfig = df['DM-SNR Kurtosis'].hist(bins=20)\nfig.set_xlabel('DM-SNR Kurtosis')\nfig.set_ylabel('Number of pulsar stars')\n\n\nplt.subplot(4, 2, 8)\nfig = df['DM-SNR Skewness'].hist(bins=20)\nfig.set_xlabel('DM-SNR Skewness')\nfig.set_ylabel('Number of pulsar stars')\n","db8ade6b":"X = df.drop(['target_class'], axis=1)\n\ny = df['target_class']","e405abdf":"# split X and y into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","e10601ba":"# check the shape of X_train and X_test\n\nX_train.shape, X_test.shape","fe8a047a":"cols = X_train.columns","7fad368c":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)\n","894b22b3":"X_train = pd.DataFrame(X_train, columns=[cols])","9aec81df":"X_test = pd.DataFrame(X_test, columns=[cols])","12f3036b":"X_train.describe()","4a16f16a":"# import SVC classifier\nfrom sklearn.svm import SVC\n\n\n# import metrics to compute accuracy\nfrom sklearn.metrics import accuracy_score\n\n\n# instantiate classifier with default hyperparameters\nsvc=SVC() \n\n\n# fit classifier to training set\nsvc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=svc.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","012a40f9":"# instantiate classifier with rbf kernel and C=100\nsvc=SVC(C=100.0) \n\n\n# fit classifier to training set\nsvc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=svc.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","e39a5477":"# instantiate classifier with rbf kernel and C=1000\nsvc=SVC(C=1000.0) \n\n\n# fit classifier to training set\nsvc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=svc.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","8c8495d7":"# instantiate classifier with linear kernel and C=1.0\nlinear_svc=SVC(kernel='linear', C=1.0) \n\n\n# fit classifier to training set\nlinear_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred_test=linear_svc.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n","aa3d3990":"# instantiate classifier with linear kernel and C=100.0\nlinear_svc100=SVC(kernel='linear', C=100.0) \n\n\n# fit classifier to training set\nlinear_svc100.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=linear_svc100.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","02b320a0":"# instantiate classifier with linear kernel and C=1000.0\nlinear_svc1000=SVC(kernel='linear', C=1000.0) \n\n\n# fit classifier to training set\nlinear_svc1000.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=linear_svc1000.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","1ac151e0":"y_pred_train = linear_svc.predict(X_train)\n\ny_pred_train","33050cad":"print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","437d29fb":"# print the scores on training and test set\n\nprint('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n\nprint('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))","7de751d0":"# check class distribution in test set\n\ny_test.value_counts()","5f4bf615":"# check null accuracy score\n\nnull_accuracy = (3306\/(3306+274))\n\nprint('Null accuracy score: {0:0.4f}'. format(null_accuracy))","c9db7e9c":"# instantiate classifier with polynomial kernel and C=1.0\npoly_svc=SVC(kernel='poly', C=1.0) \n\n\n# fit classifier to training set\npoly_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=poly_svc.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n","ebdb6a73":"# instantiate classifier with polynomial kernel and C=100.0\npoly_svc100=SVC(kernel='poly', C=100.0) \n\n\n# fit classifier to training set\npoly_svc100.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=poly_svc100.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","11bcfa61":"# instantiate classifier with sigmoid kernel and C=1.0\nsigmoid_svc=SVC(kernel='sigmoid', C=1.0) \n\n\n# fit classifier to training set\nsigmoid_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=sigmoid_svc.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n","f4fb0040":"# instantiate classifier with sigmoid kernel and C=100.0\nsigmoid_svc100=SVC(kernel='sigmoid', C=100.0) \n\n\n# fit classifier to training set\nsigmoid_svc100.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=sigmoid_svc100.predict(X_test)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n","386a14f6":"# Print the Confusion Matrix and slice it into four pieces\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred_test)\n\nprint('Confusion matrix\\n\\n', cm)\n\nprint('\\nTrue Positives(TP) = ', cm[0,0])\n\nprint('\\nTrue Negatives(TN) = ', cm[1,1])\n\nprint('\\nFalse Positives(FP) = ', cm[0,1])\n\nprint('\\nFalse Negatives(FN) = ', cm[1,0])","4b80e1ad":"# visualize confusion matrix with seaborn heatmap\n\ncm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\n\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')","5ab49281":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred_test))","074aa80b":"TP = cm[0,0]\nTN = cm[1,1]\nFP = cm[0,1]\nFN = cm[1,0]","46fcabf9":"# print classification accuracy\n\nclassification_accuracy = (TP + TN) \/ float(TP + TN + FP + FN)\n\nprint('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n","69320fc8":"# print classification error\n\nclassification_error = (FP + FN) \/ float(TP + TN + FP + FN)\n\nprint('Classification error : {0:0.4f}'.format(classification_error))\n","af98ad5b":"# print precision score\n\nprecision = TP \/ float(TP + FP)\n\n\nprint('Precision : {0:0.4f}'.format(precision))\n","b7b02d5c":"recall = TP \/ float(TP + FN)\n\nprint('Recall or Sensitivity : {0:0.4f}'.format(recall))","dfdf4bb0":"true_positive_rate = TP \/ float(TP + FN)\n\n\nprint('True Positive Rate : {0:0.4f}'.format(true_positive_rate))","7186f72a":"false_positive_rate = FP \/ float(FP + TN)\n\n\nprint('False Positive Rate : {0:0.4f}'.format(false_positive_rate))","99bf0692":"specificity = TN \/ (TN + FP)\n\nprint('Specificity : {0:0.4f}'.format(specificity))","d214e1de":"# plot ROC Curve\n\nfrom sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n\nplt.figure(figsize=(6,4))\n\nplt.plot(fpr, tpr, linewidth=2)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\n\nplt.title('ROC curve for Predicting a Pulsar Star classifier')\n\nplt.xlabel('False Positive Rate (1 - Specificity)')\n\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()\n","4053bd40":"# compute ROC AUC\n\nfrom sklearn.metrics import roc_auc_score\n\nROC_AUC = roc_auc_score(y_test, y_pred_test)\n\nprint('ROC AUC : {:.4f}'.format(ROC_AUC))","f657dc16":"# calculate cross-validated ROC AUC \n\nfrom sklearn.model_selection import cross_val_score\n\nCross_validated_ROC_AUC = cross_val_score(linear_svc, X_train, y_train, cv=10, scoring='roc_auc').mean()\n\nprint('Cross validated ROC AUC : {:.4f}'.format(Cross_validated_ROC_AUC))","d488c1fc":"from sklearn.model_selection import KFold\n\n\nkfold=KFold(n_splits=5, shuffle=True, random_state=0)\n\n\nlinear_svc=SVC(kernel='linear')\n\n\nlinear_scores = cross_val_score(linear_svc, X, y, cv=kfold)\n","4b7b60ad":"# print cross-validation scores with linear kernel\n\nprint('Stratified cross-validation scores with linear kernel:\\n\\n{}'.format(linear_scores))","b6d9e89b":"# print average cross-validation score with linear kernel\n\nprint('Average stratified cross-validation score with linear kernel:{:.4f}'.format(linear_scores.mean()))","21c45b0d":"rbf_svc=SVC(kernel='rbf')\n\n\nrbf_scores = cross_val_score(rbf_svc, X, y, cv=kfold)","3314084d":"# print cross-validation scores with rbf kernel\n\nprint('Stratified Cross-validation scores with rbf kernel:\\n\\n{}'.format(rbf_scores))","097279af":"# print average cross-validation score with rbf kernel\n\nprint('Average stratified cross-validation score with rbf kernel:{:.4f}'.format(rbf_scores.mean()))","44b40a7e":"# import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n\n# import SVC classifier\nfrom sklearn.svm import SVC\n\n\n# instantiate classifier with default hyperparameters with kernel=rbf, C=1.0 and gamma=auto\nsvc=SVC() \n\n\n\n# declare parameters for hyperparameter tuning\nparameters = [ {'C':[1, 10, 100, 1000], 'kernel':['linear']},\n               {'C':[1, 10, 100, 1000], 'kernel':['rbf'], 'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n               {'C':[1, 10, 100, 1000], 'kernel':['poly'], 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05]} \n              ]\n\n\n\n\ngrid_search = GridSearchCV(estimator = svc,  \n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 5,\n                           verbose=0)\n\n\ngrid_search.fit(X_train, y_train)\n","e4e3f924":"# examine the best model\n\n\n# best score achieved during the GridSearchCV\nprint('GridSearch CV best score : {:.4f}\\n\\n'.format(grid_search.best_score_))\n\n\n# print parameters that give the best results\nprint('Parameters that give the best results :','\\n\\n', (grid_search.best_params_))\n\n\n# print estimator that was chosen by the GridSearch\nprint('\\n\\nEstimator that was chosen by the search :','\\n\\n', (grid_search.best_estimator_))","63699ad1":"# calculate GridSearch CV score on test set\n\nprint('GridSearch CV score on test set: {0:0.4f}'.format(grid_search.score(X_test, y_test)))","2a1e2fa4":"### Classification error","030a81f6":"ROC curve help us to choose a threshold level that balances sensitivity and specificity for a particular context.","9ab4b355":"**As always, I hope you find this kernel useful and your <font color=\"red\"><b>UPVOTES<\/b><\/font> would be highly appreciated**.","4085d7f6":"## **3.4 Sigmoid kernel**\n\nSigmoid kernel has its origin in neural networks. We can use it as the proxy for neural networks. Sigmoid kernel is given by the following equation \u2013\n\n**sigmoid kernel : k (x, y) = tanh(\u03b1xTy + c)**","dbbdfd33":"Here, **y_test** are the true class labels and **y_pred** are the predicted class labels in the test-set.","397bfdcc":"### Check for overfitting and underfitting","74ef87a9":"### Classification accuracy","42f6ed60":"# **2. Support Vector Machines intuition** <a class=\"anchor\" id=\"2\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nNow, we should be familiar with some SVM terminology. \n\n\n### Hyperplane\n\nA hyperplane is a decision boundary which separates between given set of data points having different class labels. The SVM classifier separates data points using a hyperplane with the maximum amount of margin. This hyperplane is known as the `maximum margin hyperplane` and the linear classifier it defines is known as the `maximum margin classifier`.\n\n\n### Support Vectors\n\nSupport vectors are the sample data points, which are closest to the hyperplane.  These data points will define the separating line or hyperplane better by calculating margins.\n\n\n### Margin\n\nA margin is a separation gap between the two lines on the closest data points. It is calculated as the perpendicular distance from the line to support vectors or closest data points. In SVMs, we try to maximize this separation gap so that we get maximum margin.\n\nThe following diagram illustrates these concepts visually.\n\n\n### Margin in SVM\n\n![Margin in SVM](https:\/\/static.wixstatic.com\/media\/8f929f_7ecacdcf69d2450087cb4a898ef90837~mv2.png)\n\n\n### SVM Under the hood\n\nIn SVMs, our main objective is to select a hyperplane with the maximum possible margin between support vectors in the given dataset. SVM searches for the maximum margin hyperplane in the following 2 step process \u2013\n\n\n1.\tGenerate hyperplanes which segregates the classes in the best possible way. There are many hyperplanes that might classify the data. We should look for the best hyperplane that represents the largest separation, or margin, between the two classes.\n\n2.\tSo, we choose the hyperplane so that distance from it to the support vectors on each side is maximized. If such a hyperplane exists, it is known as the **maximum margin hyperplane** and the linear classifier it defines is known as a **maximum margin classifier**. \n\n\nThe following diagram illustrates the concept of **maximum margin** and **maximum margin hyperplane** in a clear manner.\n\n\n### Maximum margin hyperplane\n\n![Maximum margin hyperplane](https:\/\/static.packt-cdn.com\/products\/9781783555130\/graphics\/3547_03_07.jpg)\n\n\n\n### Problem with dispersed datasets\n\n\nSometimes, the sample data points are so dispersed that it is not possible to separate them using a linear hyperplane. \nIn such a situation, SVMs uses a `kernel trick` to transform the input space to a higher dimensional space as shown in the diagram below. It uses a mapping function to transform the 2-D input space into the 3-D input space. Now, we can easily segregate the data points using linear separation.\n\n\n### Kernel trick - transformation of input space to higher dimensional space\n\n![Kernel trick](http:\/\/www.aionlinecourse.com\/uploads\/tutorials\/2019\/07\/11_21_kernel_svm_3.png)\n\n","e179acfb":"<a class=\"anchor\" id=\"0\"><\/a>\n# **Support Vector Machines Classifier Tutorial with Python** \n\nHello friends,\n\nSupport Vector Machines (SVMs in short) are supervised machine learning algorithms that are used for classification and regression purposes. In this kernel, I build a Support Vector Machines classifier to classify a Pulsar star. I have used the **Predicting a Pulsar Star** dataset for this project. \n\nSo, let's get started.","86b1992a":"We can see that the occurences of most frequent class `0` is 3306. So, we can calculate null accuracy by dividing 3306 by total number of occurences.","acf2517f":"We can see that sigmoid kernel is also performing poorly just like with polynomial kernel.","c2e8bbce":"### ROC  AUC\n\n\n**ROC AUC** stands for **Receiver Operating Characteristic - Area Under Curve**. It is a technique to compare classifier performance. In this technique, we measure the `area under the curve (AUC)`. A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5. \n\n\nSo, **ROC AUC** is the percentage of the ROC plot that is underneath the curve.","6052ce94":"### Handle outliers with SVMs\n\n\nThere are 2 variants of SVMs. They are `hard-margin variant of SVM` and `soft-margin variant of SVM`.\n\n\nThe `hard-margin variant of SVM` does not deal with outliers. In this case, we want to find the hyperplane with maximum margin such that every training point is correctly classified with margin at least 1. This technique does not handle outliers well.\n\n\nAnother version of SVM is called `soft-margin variant of SVM`. In this case, we can have a few points incorrectly classified or \nclassified with a margin less than 1. But for every such point, we have to pay a penalty in the form of `C` parameter, which controls the outliers. `Low C` implies we are allowing more outliers and `high C` implies less outliers.\n\n\nThe message is that since the dataset contains outliers, so the value of C should be high while training the model.","d69af0b6":"So, now we will come to the end of this kernel.\n\nI hope you find this kernel useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\nThank you\n","f8ddbf0f":"# **16. Confusion matrix** <a class=\"anchor\" id=\"16\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nA confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n\n\nFour types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n\n\n**True Positives (TP)** \u2013 True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n\n\n**True Negatives (TN)** \u2013 True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n\n\n**False Positives (FP)** \u2013 False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n\n\n\n**False Negatives (FN)** \u2013 False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n\n\n\nThese four outcomes are summarized in a confusion matrix given below.\n","153e61b0":"Polynomial kernel gives poor performance. It may be overfitting the training set.","7713bb5c":"### Stratified k-Fold Cross Validation with shuffle split with  linear kernel","1c53c2f1":"### Compare model accuracy with null accuracy\n\n\nSo, the model accuracy is 0.9832. But, we cannot say that our model is very good based on the above accuracy. We must compare it with the **null accuracy**. Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.\n\nSo, we should first check the class distribution in the test set. ","45a1ba8c":"# **21. Results and conclusion** <a class=\"anchor\" id=\"21\"><\/a>\n\n[Table of Contents](#0.1)\n\n\n\n1. There are outliers in our dataset. So, as I increase the value of C to limit fewer outliers, the accuracy increased. This is true with different kinds of kernels.\n\n2.\tWe get maximum accuracy with `rbf` and `linear` kernel with C=100.0 and the accuracy is 0.9832. So, we can conclude that our model is doing a very good job in terms of predicting the class labels. But, this is not true. Here, we have an imbalanced dataset. Accuracy is an inadequate measure for quantifying predictive performance in the imbalanced dataset problem. So, we must explore `confusion matrix` that provide better guidance in selecting models. \n\n3.\tROC AUC of our model is very close to 1. So, we can conclude that our classifier does a good job in classifying the pulsar star.\n\n4.\tI obtain higher average stratified k-fold cross-validation score of 0.9789 with linear kernel but the model accuracy is 0.9832. So, stratified cross-validation technique does not help to improve the model performance.\n\n5.\tOur original model test accuracy is 0.9832 while GridSearch CV score on test-set is 0.9835. So, GridSearch CV helps to identify the parameters that will improve the performance for this particular model.\n","8c074ab8":"# **5. Dataset description** <a class=\"anchor\" id=\"5\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nI have used the **Predicting a Pulsar Star** dataset for this project.\n\nPulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. Classification algorithms in particular are being adopted, which treat the data sets as binary classification problems. Here the legitimate pulsar examples form  minority positive class and spurious examples form the majority negative class.\n\nThe data set shared here contains 16,259 spurious examples caused by RFI\/noise, and 1,639 real pulsar examples. Each row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).\n\n\n### Attribute Information:\n\n\nEach candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile. The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:\n\n1. Mean of the integrated profile.\n\n2. Standard deviation of the integrated profile.\n\n3. Excess kurtosis of the integrated profile.\n\n4. Skewness of the integrated profile.\n\n5. Mean of the DM-SNR curve.\n\n6. Standard deviation of the DM-SNR curve.\n\n7. Excess kurtosis of the DM-SNR curve.\n\n8. Skewness of the DM-SNR curve.\n\n9. Class","361f9996":"We can see that the leading spaces are removed from the column name. But the column names are very long. So, I will make them short by renaming them.","03d3a31a":"### Run SVM with linear kernel and C=100.0","f970825d":"# **17. Classification metrices** <a class=\"anchor\" id=\"17\"><\/a>\n\n[Table of Contents](#0.1)","460ab174":" ### Run SVM with polynomial kernel and C=100.0","0e0d7fde":"In this case, we can see that the accuracy had decreased with C=1000.0","749963e0":"The confusion matrix shows `3289 + 230 = 3519 correct predictions` and `17 + 44 = 61 incorrect predictions`.\n\n\nIn this case, we have\n\n\n- `True Positives` (Actual Positive:1 and Predict Positive:1) - 3289\n\n\n- `True Negatives` (Actual Negative:0 and Predict Negative:0) - 230\n\n\n- `False Positives` (Actual Negative:0 but Predict Positive:1) - 17 `(Type I error)`\n\n\n- `False Negatives` (Actual Positive:1 but Predict Negative:0) - 44 `(Type II error)`","d14e0f2a":"## **3.2 Polynomial Kernel**\n\nPolynomial kernel represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables. The polynomial kernel looks not only at the given features of input samples to determine their similarity, but also combinations of the input samples.\n\nFor degree-d polynomials, the polynomial kernel is defined as follows \u2013\n\n**Polynomial kernel : K(xi , xj ) = (\u03b3xiT xj + r)d , \u03b3 > 0**\n\nPolynomial kernel is very popular in Natural Language Processing. The most common degree is d = 2 (quadratic), since larger degrees tend to overfit on NLP problems. It can be visualized with the following diagram.\n\n### Polynomial Kernel\n\n![Polynomial Kernel](https:\/\/www.researchgate.net\/profile\/Cheng_Soon_Ong\/publication\/23442384\/figure\/fig12\/AS:341444054274063@1458418014823\/The-effect-of-the-degree-of-a-polynomial-kernel-The-polynomial-kernel-of-degree-1-leads.png)","8f5339d7":"### Run SVM with rbf kernel and C=1000.0\n","ab426a17":"# **19. Stratified k-fold Cross Validation with shuffle split** <a class=\"anchor\" id=\"19\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nk-fold cross-validation is a very useful technique to evaluate model performance. But, it fails here because we have a imbalnced dataset. So, in the case of imbalanced dataset, I will use another technique to evaluate model performance. It is called `stratified k-fold cross-validation`.\n\n\nIn `stratified k-fold cross-validation`, we split the data such that the proportions between classes are the same in each fold as they are in the whole dataset.\n\n\nMoreover, I will shuffle the data before splitting because shuffling yields much better result.","b716e981":"# **15. Run SVM with sigmoid kernel** <a class=\"anchor\" id=\"15\"><\/a>\n\n[Table of Contents](#0.1)\n\n\n### Run SVM with sigmoid kernel and C=1.0","7aff15d9":"We can see that the training set and test-set accuracy are very much comparable.","99717c62":"Sigmoid kernel can be visualized with the following diagram-\n\n### Sigmoid kernel\n\n![Sigmoid kernel](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTKeXbOIlniBXYwMYlEYLKPwZZg8vFU1wVm3RWMACjVcT4iBVDy&s)","d325ad6d":"# **22. References** <a class=\"anchor\" id=\"22\"><\/a>\n\n[Table of Contents](#0.1)\n\nThe work done in this project is inspired from following books and websites:-\n\n  1. Hands on Machine Learning with Scikit-Learn and Tensorflow by Aure\u0301lie\u0301n Ge\u0301ron\n\n  2. Introduction to Machine Learning with Python by Andreas C. Mu\u0308ller and Sarah Guido\n\n  3. Udemy course \u2013 Machine Learning \u2013 A Z by Kirill Eremenko and Hadelin de Ponteves\n\n  4. Udemy course \u2013 Feature Engineering for Machine Learning by Soledad Galli\n\n  5. https:\/\/en.wikipedia.org\/wiki\/Support-vector_machine\n\n  6. https:\/\/www.datacamp.com\/community\/tutorials\/svm-classification-scikit-learn-python\n\n  7. http:\/\/dataaspirant.com\/2017\/01\/13\/support-vector-machine-algorithm\/\n\n  8. https:\/\/www.ritchieng.com\/machine-learning-evaluate-classification-model\/\n\n  9. https:\/\/en.wikipedia.org\/wiki\/Kernel_method\n\n  10. https:\/\/en.wikipedia.org\/wiki\/Polynomial_kernel\n\n  11. https:\/\/en.wikipedia.org\/wiki\/Radial_basis_function_kernel\n\n  12. https:\/\/data-flair.training\/blogs\/svm-kernel-functions\/","a39bac64":"We can see that we can obtain higher accuracy with C=100.0 and C=1000.0 as compared to C=1.0.","ec672615":"### Compare the train-set and test-set accuracy\n\n\nNow, I will compare the train-set and test-set accuracy to check for overfitting.","5a8e567b":"We can define a kernel function as follows-\n\n\n### Kernel function\n\n![Kernel function](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTodZptqcRor0LGo8Qn7_kJB9n9BACMt6jgIPZ4C3g_rgh_uSRZLQ&s)","0c6ac8fd":"We can see that we obtain a higher accuracy with C=100.0 as higher C means less outliers.\n\nNow, I will further increase the value of C=1000.0 and check accuracy.","2106bcc4":"### Run SVM with rbf kernel and C=100.0\n\n\nWe have seen that there are outliers in our dataset. So, we should increase the value of C as higher C means fewer outliers. \nSo, I will run SVM with kernel=`rbf` and C=100.0.","3605d41b":"### Explore missing values in variables","8765725b":"### f1-score\n\n\n**f1-score** is the weighted harmonic mean of precision and recall. The best possible **f1-score** would be 1.0 and the worst \nwould be 0.0.  **f1-score** is the harmonic mean of precision and recall. So, **f1-score** is always lower than accuracy measures as they embed precision and recall into their computation. The weighted average of `f1-score` should be used to \ncompare classifier models, not global accuracy.\n","bb9158b3":"We can see that there are 17898 instances and 9 variables in the data set.","cbc54399":"### Comments\n\n\nI obtain higher average stratified k-fold cross-validation score of 0.9789 with linear kernel but the model accuracy is 0.9832.\nSo, stratified cross-validation technique does not help to improve the model performance.","102a3177":"We can see that there are leading spaces (spaces at the start of the string name) in the dataframe. So, I will remove these leading spaces.","0b3b4e40":"# **12. Run SVM with default hyperparameters** <a class=\"anchor\" id=\"12\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nDefault hyperparameter means C=1.0,  kernel=`rbf` and gamma=`auto` among other parameters.","8b546ed0":"We now have `X_train` dataset ready to be fed into the Logistic Regression classifier. I will do it as follows.","47493173":"[Go to Top](#0)","abc167eb":"We can see that there are no missing values in the dataset.","a66586d2":"## **3.1 Linear kernel**\n\nIn linear kernel, the kernel function takes the form of a linear function as follows-\n\n**linear kernel : K(xi , xj ) = xiT xj**\n\nLinear kernel is used when the data is linearly separable. It means that data can be separated using a single line. It is one of the most common kernels to be used. It is mostly used when there are large number of features in a dataset. Linear kernel is often used for text classification purposes.\n\nTraining with a linear kernel is usually faster, because we only need to optimize the C regularization parameter. When training with other kernels, we also need to optimize the \u03b3 parameter. So, performing a grid search will usually take more time.\n\nLinear kernel can be visualized with the following figure.\n\n### Linear Kernel\n\n![Linear Kernel](https:\/\/scikit-learn.org\/stable\/_images\/sphx_glr_plot_svm_kernels_thumb.png)","9e3ae847":"We can see that the column names are shortened. IP stands for `integrated profile` and DM-SNR stands for `delta modulation and signal to noise ratio`. Now, it is much more easy to work with the columns.","05b0da2a":"### Run SVM with sigmoid kernel and C=100.0","632bbb92":"On closer inspection, we can suspect that all the continuous variables may contain outliers.\n\n\nI will draw boxplots to visualise outliers in the above variables. ","761fa301":"# **4. SVM Scikit-Learn libraries** <a class=\"anchor\" id=\"4\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nScikit-Learn provides useful libraries to implement Support Vector Machine algorithm on a dataset. There are many libraries that can help us to implement SVM smoothly. We just need to call the library with parameters that suit to our needs. In this project, I am dealing with a classification task. So, I will mention the Scikit-Learn libraries for SVM classification purposes.\n\nFirst, there is a **LinearSVC()** classifier. As the name suggests, this classifier uses only linear kernel. In LinearSVC() classifier, we don\u2019t pass the value of kernel since it is used only for linear classification purposes.\n\nScikit-Learn provides two other classifiers - **SVC()** and **NuSVC()** which are used for classification purposes. These classifiers are mostly similar with some difference in parameters. **NuSVC()** is similar to **SVC()** but uses a parameter to control the number of support vectors. We pass the values of kernel, gamma and C along with other parameters. By default kernel parameter uses rbf as its value but we can pass values like poly, linear, sigmoid or callable function.","68f9d620":"### Classification Report\n\n\n**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model. I have described these terms in later.\n\nWe can print a classification report as follows:-","06e0a199":"## **3.3 Radial Basis Function Kernel**\n\nRadial basis function kernel is a general purpose kernel. It is used when we have no prior knowledge about the data. The RBF kernel on two samples x and y is defined by the following equation \u2013\n\n\n### Radial Basis Function kernel\n\n![RBK Kernel](data:image\/png;base64,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)","a2e69bc9":"The following diagram demonstrates the SVM classification with rbf kernel.\n\n### SVM Classification with rbf kernel\n\n![SVM Classification with rbf kernel](https:\/\/www.researchgate.net\/profile\/Periklis_Gogas\/publication\/286180566\/figure\/fig5\/AS:304327777374210@1449568804246\/An-example-of-an-SVM-classification-using-the-RBF-kernel-The-two-classes-are-separated.png)","034ee997":"### Precision\n\n\n**Precision** can be defined as the percentage of correctly predicted positive outcomes out of all the predicted positive outcomes. It can be given as the ratio of true positives (TP) to the sum of true and false positives (TP + FP). \n\n\nSo, **Precision** identifies the proportion of correctly predicted positive outcome. It is more concerned with the positive class than the negative class.\n\n\n\nMathematically, precision can be defined as the ratio of `TP to (TP + FP)`.\n\n\n","e17d4664":"### Comments\n\n\n- ROC AUC is a single number summary of classifier performance. The higher the value, the better the classifier.\n\n- ROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a good job in classifying the pulsar star.","01b63d66":"Our target variable is the `target_class` column. So, I will check its distribution.","0b3e26f7":"# **7.Import dataset** <a class=\"anchor\" id=\"7\"><\/a>\n\n[Table of Contents](#0.1)","f6583fa3":"The training-set accuracy score is 0.9783 while the test-set accuracy to be 0.9830. These two values are quite comparable. So, there is no question of overfitting. \n","b6b5505c":"### Recall\n\n\nRecall can be defined as the percentage of correctly predicted positive outcomes out of all the actual positive outcomes.\nIt can be given as the ratio of true positives (TP) to the sum of true positives and false negatives (TP + FN). **Recall** is also called **Sensitivity**.\n\n\n**Recall** identifies the proportion of correctly predicted actual positives.\n\n\nMathematically, **recall** can be defined as the ratio of `TP to (TP + FN)`.\n\n","f8acf290":"### Stratified k-Fold Cross Validation with shuffle split with rbf kernel","ac2c6c5d":"### True Positive Rate\n\n\n**True Positive Rate** is synonymous with **Recall**.\n","19fb7d67":"In the context of SVMs, there are 4 popular kernels \u2013 `Linear kernel`,`Polynomial kernel`,`Radial Basis Function (RBF) kernel` (also called Gaussian kernel) and `Sigmoid kernel`. These are described below -","aa1914f2":"# **14. Run SVM with polynomial kernel** <a class=\"anchor\" id=\"14\"><\/a>\n\n[Table of Contents](#0.1)\n\n\n### Run SVM with polynomial kernel and C=1.0","7a7c1549":"### Comments\n\n\n- Our original model test accuracy is 0.9832 while GridSearch CV score on test-set is 0.9835.\n\n\n- So, GridSearch CV helps to identify the parameters that will improve the performance for this particular model.\n\n\n- Here, we should not confuse `best_score_` attribute of `grid_search` with the `score` method on the test-set. \n\n\n- The `score` method on the test-set gives the generalization performance of the model. Using the `score` method, we employ a model trained on the whole training set.\n\n\n- The `best_score_` attribute gives the mean cross-validation accuracy, with cross-validation performed on the training set.","1863694b":"# **9. Declare feature vector and target variable** <a class=\"anchor\" id=\"9\"><\/a>\n\n[Table of Contents](#0.1)","2edc05dd":"# **18. ROC - AUC** <a class=\"anchor\" id=\"18\"><\/a>\n\n[Table of Contents](#0.1)\n\n\n\n### ROC Curve\n\n\nAnother tool to measure the classification model performance visually is **ROC Curve**. ROC Curve stands for **Receiver Operating Characteristic Curve**. An **ROC Curve** is a plot which shows the performance of a classification model at various \nclassification threshold levels. \n\n\n\nThe **ROC Curve** plots the **True Positive Rate (TPR)** against the **False Positive Rate (FPR)** at various threshold levels.\n\n\n\n**True Positive Rate (TPR)** is also called **Recall**. It is defined as the ratio of `TP to (TP + FN)`.\n\n\n\n**False Positive Rate (FPR)** is defined as the ratio of `FP to (FP + TN)`.\n\n\n\nIn the ROC Curve, we will focus on the TPR (True Positive Rate) and FPR (False Positive Rate) of a single point. This will give us the general performance of the ROC curve which consists of the TPR and FPR at various threshold levels. So, an ROC Curve plots TPR vs FPR at different classification threshold levels. If we lower the threshold levels, it may result in more items being classified as positve. It will increase both True Positives (TP) and False Positives (FP).\n\n","5593b5b9":"# **6. Import libraries** <a class=\"anchor\" id=\"6\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nI will start off by importing the required Python libraries.","e435911f":"# **11. Feature Scaling** <a class=\"anchor\" id=\"11\"><\/a>\n\n[Table of Contents](#0.1)","10e81428":"### Summary of numerical variables\n\n\n- There are 9 numerical variables in the dataset.\n\n\n- 8 are continuous variables and 1 is discrete variable. \n\n\n- The discrete variable is `target_class` variable. It is also the target variable.\n\n\n- There are no missing values in the dataset.","ec5fc7b2":"# **8. Exploratory data analysis** <a class=\"anchor\" id=\"8\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nNow, I will explore the data to gain insights about the data. ","03727a57":"We can see that there are no missing values in the dataset and all the variables are numerical variables.","451d634e":"### Specificity","f20ea5c0":"We can see that percentage of observations of the class label `0` and `1` is 90.84% and 9.16%. So, this is a class imbalanced problem. I will deal with that in later section.","d3696e70":"We can see that all the 8 continuous variables are skewed. ","0ec83b83":"### Check the distribution of variables\n\n\nNow, I will plot the histograms to check distributions to find out if they are normal or skewed. ","2e2f38dd":"### Run SVM with linear kernel and C=1000.0","313b2773":"The above boxplots confirm that there are lot of outliers in these variables.","a6e90d9f":"### False Positive Rate","f5e861be":"### Outliers in numerical variables","51690145":"# **1. Introduction to Support Vector Machines** <a class=\"anchor\" id=\"1\"><\/a>\n\n[Table of Contents](#0.1)\n\n\n**Support Vector Machines** (SVMs in short) are machine learning algorithms that are used for classification and regression purposes. SVMs are one of the powerful machine learning algorithms for classification, regression and outlier detection purposes. An SVM classifier builds a model that assigns new data points to one of the given categories. Thus, it can be viewed as a non-probabilistic binary linear classifier.\n\nThe original SVM algorithm was developed by Vladimir N Vapnik and Alexey Ya. Chervonenkis in 1963. At that time, the algorithm was in early stages. The only possibility is to draw hyperplanes for linear classifier. In 1992, Bernhard E. Boser, Isabelle M Guyon and Vladimir N Vapnik suggested a way to create non-linear classifiers by applying the kernel trick to maximum-margin hyperplanes. The current standard was proposed by Corinna Cortes and Vapnik in 1993 and published in 1995.\n\nSVMs can be used for linear classification purposes. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using the **kernel trick**. It enable us to implicitly map the inputs into high dimensional feature spaces.\n\n\n","ab17ba6e":"<a class=\"anchor\" id=\"0.1\"><\/a>\n# **Table of Contents**\n\n\n1.\t[Introduction to Support Vector Machines](#1)\n2.\t[Support Vector Machines intuition](#2)\n3.\t[Kernel trick](#3)\n4.\t[SVM Scikit-Learn libraries](#4)\n5.\t[Dataset description](#5)\n6.\t[Import libraries](#6)\n7.\t[Import dataset](#7)\n8.\t[Exploratory data analysis](#8)\n9.\t[Declare feature vector and target variable](#9)\n10.\t[Split data into separate training and test set](#10)\n11.\t[Feature scaling](#11)\n12.\t[Run SVM with default hyperparameters](#12)\n13.\t[Run SVM with linear kernel](#13)\n14.\t[Run SVM with polynomial kernel](#14)\n15.\t[Run SVM with sigmoid kernel](#15)\n16.\t[Confusion matrix](#16)\n17.\t[Classification metrices](#17)\n18.\t[ROC - AUC](#18)\n19.\t[Stratified k-fold Cross Validation with shuffle split](#19)\n20.\t[Hyperparameter optimization using GridSearch CV](#20)\n21.\t[Results and conclusion](#21)\n22. [References](#22)\n","5189b5e3":"### Support\n\n\n**Support** is the actual number of occurrences of the class in our dataset.","865a41dd":"# **10. Split data into separate training and test set** <a class=\"anchor\" id=\"10\"><\/a>\n\n[Table of Contents](#0.1)","f107b090":"We can see that there are 9 variables in the dataset. 8 are continuous variables and 1 is discrete variable. The discrete variable is `target_class` variable. It is also the target variable.\n\n\nNow, I will view the column names to check for leading and trailing spaces.","147a66ba":"# **20. Hyperparameter Optimization using GridSearch CV** <a class=\"anchor\" id=\"20\"><\/a>\n\n[Table of Contents](#0.1)","85c80f38":"I have removed the leading spaces from the column names. Let's again view the column names to confirm the same.","8c88c1cc":"# **3. Kernel trick** <a class=\"anchor\" id=\"3\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nIn practice, SVM algorithm is implemented using a `kernel`. It uses a technique called the `kernel trick`. In simple words, a `kernel` is just a function that maps the data to a higher dimension where data is separable. A kernel transforms a low-dimensional input data space into a higher dimensional space. So, it converts non-linear separable problems to linear separable problems by adding more dimensions to it. Thus, the kernel trick helps us to build a more accurate classifier. Hence, it is useful in non-linear separation problems.","b21ec001":"We can see that our model accuracy score is 0.9830 but null accuracy score is 0.9235. So, we can conclude that our SVM classifier is doing a very good job in predicting the class labels.","33e8fc5b":"# **13. Run SVM with linear kernel** <a class=\"anchor\" id=\"13\"><\/a>\n\n[Table of Contents](#0.1)\n\n\n### Run SVM with linear kernel and C=1.0","2586fd8c":"### Comments\n\n\nWe get maximum accuracy with `rbf` and `linear` kernel with C=100.0. and the accuracy is 0.9832. Based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n\n\nBut, this is not true. Here, we have an imbalanced dataset. The problem is that accuracy is an inadequate measure for quantifying predictive performance in the imbalanced dataset problem.\n\n\nSo, we must explore alternative metrices that provide better guidance in selecting models. In particular, we would like to know the underlying distribution of values and the type of errors our classifer is making. \n\n\nOne such metric to analyze the model performance in imbalanced classes problem is `Confusion matrix`."}}