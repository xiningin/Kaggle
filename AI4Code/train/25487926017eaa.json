{"cell_type":{"de025978":"code","54427d5d":"code","c0616a18":"code","36d59080":"code","7190da3d":"code","57cf48da":"code","4385ee6c":"code","eda613a1":"code","4957a90a":"code","5f872b85":"code","b6d006fd":"code","44ba2071":"code","3d224405":"code","79f5e050":"markdown","312f5aea":"markdown","843679ec":"markdown","1d924b36":"markdown","972dc98a":"markdown","56b83676":"markdown","5286262d":"markdown","c263781d":"markdown","4293ce1f":"markdown","1baa8bd3":"markdown","eaee9cba":"markdown","5c6302fc":"markdown","81b3addf":"markdown","fa269856":"markdown"},"source":{"de025978":"%%capture\nimport os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n# Install Weights and Biases \n!pip3 install -r ..\/input\/rsnawrapper\/requirements.txt\n\n# Weights and Biases Setup\nimport wandb\nfrom wandb.keras import WandbCallback\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"WANDB_API_KEY\")\nwandb.login(key=api_key);\n\nfrom rsna.utils import load_dicom_images_3d\na = load_dicom_images_3d(\"00000\")\nprint(a.shape)\nprint(np.min(a), np.max(a), np.mean(a), np.median(a))","54427d5d":"if os.path.exists(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n    data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D\"\n    wrapperdir = \"..\/input\/rsnawrapper\"\n    \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nSIZE = 256\nNUM_IMAGES = 64\n\nsys.path.append(pytorch3dpath)\nsys.path.append(wrapperdir)\nfrom efficientnet_pytorch_3d import EfficientNet3D","c0616a18":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(21)","36d59080":"train_df = pd.read_csv(f\"{data_directory}\/train_labels.csv\")\ndisplay(train_df)\n\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.2, \n    random_state=12, \n    stratify=train_df[\"MGMT_value\"],\n)","7190da3d":"# Boiler Plate code from the library\nfrom rsna.dataloader import Dataset","57cf48da":"# Boiler Plate code from the library\nfrom rsna.nn import Model","4385ee6c":"# Boiler Plate code from the library\nfrom rsna.engine import Trainer","eda613a1":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nCONFIG = dict(\n    BATCH_SIZE = 4,\n    EPOCHS = 10,\n    PATIENCE = 10,\n    SIZE = 256,\n    NUM_IMAGES = 64,\n    competition = 'rsna-miccai-brain',\n    _wandb_kernel = 'sauravm'\n)\n\ndef train_mri_type(df_train, df_valid, mri_type):\n    if mri_type==\"all\":\n        train_list = []\n        valid_list = []\n        for mri_type in mri_types:\n            df_train.loc[:,\"MRI_Type\"] = mri_type\n            train_list.append(df_train.copy())\n            df_valid.loc[:,\"MRI_Type\"] = mri_type\n            valid_list.append(df_valid.copy())\n\n        df_train = pd.concat(train_list)\n        df_valid = pd.concat(valid_list)\n    else:\n        df_train.loc[:,\"MRI_Type\"] = mri_type\n        df_valid.loc[:,\"MRI_Type\"] = mri_type\n\n    print(df_train.shape, df_valid.shape)\n    display(df_train.head())\n    \n    train_data_retriever = Dataset(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values, \n        df_train[\"MRI_Type\"].values,\n        augment=False\n    )\n\n    valid_data_retriever = Dataset(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        df_valid[\"MRI_Type\"].values\n    )\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=CONFIG['BATCH_SIZE'],\n        shuffle=True,\n        num_workers=8,\n    )\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever, \n        batch_size=CONFIG['BATCH_SIZE'],\n        shuffle=False,\n        num_workers=8,\n    )\n    \n    run = wandb.init(project='RSNA-MICCAI', \n                     entity='sauravmaheshkar', \n                     group='4-types', \n                     job_type='train', \n                     config=CONFIG)\n\n    model = Model(model_name = \"efficientnet-b0\")\n    model.to(device)\n\n    wandb.watch(model)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n\n    criterion = torch_functional.binary_cross_entropy_with_logits\n\n    trainer = Trainer(\n        model, \n        device, \n        optimizer, \n        criterion\n    )\n\n    history = trainer.fit(\n        CONFIG['EPOCHS'], \n        train_loader, \n        valid_loader, \n        f\"{mri_type}\", \n        CONFIG['PATIENCE'],\n    )\n    \n    run.finish()\n    \n    return trainer.lastmodel\n\nmodelfiles = None\n\n\nif not modelfiles:\n    modelfiles = [train_mri_type(df_train, df_valid, m) for m in mri_types]\n    print(modelfiles)","4957a90a":"def predict(modelfile, df, mri_type, split):\n    print(\"Predict:\", modelfile, mri_type, df.shape)\n    df.loc[:,\"MRI_Type\"] = mri_type\n    data_retriever = Dataset(\n        df.index.values, \n        mri_type=df[\"MRI_Type\"].values,\n        split=split\n    )\n\n    data_loader = torch_data.DataLoader(\n        data_retriever,\n        batch_size=CONFIG['BATCH_SIZE'],\n        shuffle=False,\n        num_workers=8,\n    )\n   \n    model = Model()\n    model.to(device)\n    \n    checkpoint = torch.load(modelfile)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        print(f\"{e}\/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(batch[\"id\"].numpy().tolist())\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","5f872b85":"df_valid = df_valid.set_index(\"BraTS21ID\")\ndf_valid[\"MGMT_pred\"] = 0\nfor m, mtype in zip(modelfiles,  mri_types):\n    pred = predict(m, df_valid, mtype, \"train\")\n    df_valid[\"MGMT_pred\"] += pred[\"MGMT_value\"]\ndf_valid[\"MGMT_pred\"] \/= len(modelfiles)\nauc = roc_auc_score(df_valid[\"MGMT_value\"], df_valid[\"MGMT_pred\"])\nprint(f\"Validation ensemble AUC: {auc:.4f}\")\nsns.displot(df_valid[\"MGMT_pred\"])","b6d006fd":"submission = pd.read_csv(f\"{data_directory}\/sample_submission.csv\", index_col=\"BraTS21ID\")\n\nsubmission[\"MGMT_value\"] = 0\nfor m, mtype in zip(modelfiles, mri_types):\n    pred = predict(m, submission, mtype, split=\"test\")\n    submission[\"MGMT_value\"] += pred[\"MGMT_value\"]\n\nsubmission[\"MGMT_value\"] \/= len(modelfiles)\nsubmission[\"MGMT_value\"].to_csv(\"submission.csv\")","44ba2071":"submission","3d224405":"sns.displot(submission[\"MGMT_value\"])","79f5e050":"# \ud83c\udfe0 Model Class","312f5aea":"# \ud83d\udcbf Dataset","843679ec":"# \u2699\ufe0f Prediction","1d924b36":"# Random Seed \ud83c\udf31","972dc98a":"# \ud83d\udd25 Training","56b83676":"## This Kernel is a fork of [Efficientnet3D with one MRI type](https:\/\/www.kaggle.com\/rluethy\/efficientnet3d-with-one-mri-type)\n\nAs many others have said during the course of this competition, most models aren't learning anything. \n1. Be it the difference between the [**Public Leaderboard and Local CV AUC**](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification\/discussion\/255352)\n2. [**Models failing to generalize**](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification\/discussion\/266173)\n3. [**Models not training**](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification\/discussion\/265777) in the first place","5286262d":"# \u2702\ufe0f Train\/Test Split","c263781d":"# Models Don't Learn \ud83e\udd37\ud83c\udffb","4293ce1f":"![](https:\/\/raw.githubusercontent.com\/SauravMaheshkar\/RSNA-MICCAI\/main\/assets\/Fluke-Training-Loss.svg)\n\n![](https:\/\/raw.githubusercontent.com\/SauravMaheshkar\/RSNA-MICCAI\/main\/assets\/Fluke-Validation-Loss.svg)","1baa8bd3":"## Ensemble for submission","eaee9cba":"The motivation for these experiments come from [**Chai Time Kaggle Talks with Anjum Sayed (Datasaurus)**](https:\/\/youtu.be\/udw-uSV66EQ) Video on the [**Weights and Biases Channel**](https:\/\/www.youtube.com\/WeightsBiases). Anjum mentioned that a good way to check if the models are learning anything is to just change the random seeds and see if it affects the performance.\n\n[![Video Title](https:\/\/api.wandb.ai\/files\/sauravmaheshkar\/images\/projects\/436131\/cc7a6207.png)](https:\/\/youtu.be\/udw-uSV66EQ)","5c6302fc":"## [**Weights and Biases Report \u2b50\ufe0f**](https:\/\/wandb.ai\/sauravmaheshkar\/RSNA-MICCAI\/reports\/The-Fluke--VmlldzoxMDA2MDQy) | [**Weights and Biases Project**](https:\/\/wandb.ai\/sauravmaheshkar\/RSNA-MICCAI)","81b3addf":"## Ensemble for validation","fa269856":"# \ud83d\udcaa\ud83c\udffb Trainer Class"}}