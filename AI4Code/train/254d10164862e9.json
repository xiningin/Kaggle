{"cell_type":{"7889196a":"code","692fc146":"code","26204aa3":"code","6ae9000b":"code","fb069257":"code","39008437":"code","de29b427":"code","c01169f9":"code","689b49d3":"markdown","d55d5d3a":"markdown"},"source":{"7889196a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","692fc146":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')","26204aa3":"# Load the training data\nX = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\",encoding='utf-8', index_col=0)\ntest = pd.read_csv('..\/input\/30-days-of-ml\/test.csv',encoding='utf-8',index_col=0)","6ae9000b":"\n# Preview the data\nX.head()","fb069257":"y = X['target']\nX = X.drop(['target'], axis= 1)","39008437":"label = LabelEncoder()\ncategorical_feature = np.where(X.dtypes != 'float64')[0].tolist()\ncategorical_feature_columns = X.select_dtypes(exclude=['float64']).columns\n\nfor column in categorical_feature_columns:\n        label.fit(X[column])\n        X[column] = label.transform(X[column])\n        test[column] = label.transform(test[column])","de29b427":"lgbm_parameters = {\n    'metric': 'rmse', \n    'n_jobs': -1,\n    'n_estimators': 50000,\n    'reg_alpha': 10.924491968127692,\n    'reg_lambda': 17.396730654687218,\n    'colsample_bytree': 0.21497646795452627,\n    'subsample': 0.7582562557431147,\n    'learning_rate': 0.009985133666265425,\n    'max_depth': 18,\n    'num_leaves': 63,\n    'min_child_samples': 27,\n    'max_bin': 523,\n    'cat_l2': 0.025083670064082797\n}","c01169f9":"lgbm_val_pred = np.zeros(len(y))\nlgbm_test_pred =np.zeros(len(test))\nmse = []\nkf = KFold(n_splits=10, shuffle=True)\n\nfor trn_idx, val_idx in tqdm(kf.split(X,y)):\n    x_train_idx = X.iloc[trn_idx]\n    y_train_idx = y.iloc[trn_idx]\n    x_valid_idx = X.iloc[val_idx]\n    y_valid_idx = y.iloc[val_idx]\n\n    lgbm_model = LGBMRegressor(**lgbm_parameters)\n    lgbm_model.fit(x_train_idx, y_train_idx, eval_set = ((x_valid_idx,y_valid_idx)),verbose = -1, early_stopping_rounds = 400,categorical_feature=categorical_feature)  \n    lgbm_test_pred += lgbm_model.predict(test)\/10\n    mse.append(mean_squared_error(y_valid_idx, lgbm_model.predict(x_valid_idx)))\n    # \n    # mse.append(mean_squared_error(y_valid_idx, lgbm_model.predict(x_valid_idx)),squared=False)\n\nnp.mean(mse)\npd.DataFrame({'id':test.index,'target':lgbm_test_pred}).to_csv('submission.csv', index=False)","689b49d3":"# Future work: \nI hope to improve the perfomance of the present model by using \nthe ideas described in [this discussion](https:\/\/www.kaggle.com\/c\/30-days-of-ml\/discussion\/265788). The sources are [notebook1](https:\/\/www.kaggle.com\/maostack\/english-tps-feb-pseudo-labeling-11th-place) and [notebook2](https:\/\/www.kaggle.com\/ivezga\/lightgbm).","d55d5d3a":"# Inspired from [this notebook](https:\/\/www.kaggle.com\/svyatoslavsokolov\/tps-feb-2021-lgbm-simple-version)\n\nThe work we present here is a modification of the above notebook, a work from  [Svyatoslav Sokolov](https:\/\/www.kaggle.com\/svyatoslavsokolov).\nI present the notebook I was referring to in [this discussion](https:\/\/www.kaggle.com\/c\/30-days-of-ml\/discussion\/265958)."}}