{"cell_type":{"e4365cf1":"code","2cac76e1":"code","c614f78c":"code","2a348ca5":"code","dab75acf":"code","10e22ab0":"code","6bf725bb":"code","ed24321a":"code","fdda53e8":"code","27a0dea9":"code","1c6d0a57":"code","12233e7c":"code","80181f83":"code","28f2e740":"code","dac82349":"code","957206fa":"code","fe73b92d":"code","902f9970":"markdown"},"source":{"e4365cf1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2cac76e1":"#\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\u3001Shape\ntitanic_gender = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\nprint(\"gender_submission  : \" + str(titanic_gender.shape))\n\ntitanic_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nprint(\"train : \" + str(titanic_train.shape))\ntitanic_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nprint(\"test  : \" + str(titanic_test.shape))","c614f78c":"print(titanic_gender.dtypes)\ntitanic_gender.head()","2a348ca5":"print(titanic_train.dtypes)\ntitanic_train.head()","dab75acf":"titanic_train.describe()","10e22ab0":"titanic_train.describe(exclude='number')","6bf725bb":"#\u6b20\u640d\u5024\ntitanic_train.isnull().sum()","ed24321a":"#\u7537\u5973\u5225\u5e74\u9f62\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(15,3))\n\nplt.subplot(1,3,1)\nplt.title(\"Male\")\nplt.xlim([0,100])\nplt.ylim([0,150])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.hist(x=titanic_train[titanic_train.Sex == 'male'].Age, bins=10)\n\nplt.subplot(1,3,2)\nplt.title(\"Female\")\nplt.xlim([0,100])\nplt.ylim([0,150])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.hist(x=titanic_train[titanic_train.Sex == 'female'].Age, bins=10)\n\nplt.subplot(1,3,3)\nplt.pie(x=titanic_train.Sex.value_counts())\nplt.legend([\"male\", \"female\"])\n\nplt.show()","fdda53e8":"#\u524d\u51e6\u7406\n#\u4e88\u6e2c\u306b\u4f7f\u3046\u9805\u76ee\n#features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin']\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'Cabin']\n#\u4e88\u6e2c\u3059\u308b\u9805\u76ee\noutputs = ['Survived']\n\n#\u307e\u3068\u3081\u3066\u51e6\u7406\u3059\u308b\ntitanic_train['flag'] = 1\ntitanic_test['flag'] = 0\ntitanic_test['Survived'] = 0\n\ntitanic_all = pd.concat([titanic_train[features + outputs + ['flag']], titanic_test[features + outputs + ['flag']]])\nprint(titanic_all.shape)\ntitanic_all.head()","27a0dea9":"#cabin\u30c7\u30fc\u30bf\ntitanic_all[pd.isnull(titanic_all['Cabin']) == False]['Cabin'].head(30)","1c6d0a57":"import math\n#\u6b20\u640d\u5024\u3092\u5e73\u5747\u5024\u3067\u57cb\u3081\u308b\ntitanic_all = titanic_all.fillna({'Age' : titanic_all['Age'].mean(), 'Fare' : titanic_all['Fare'].mean()})\n#float > int\ntitanic_all['Age'] = titanic_all['Age'].apply(lambda x: math.ceil(x))\ntitanic_all['Fare'] = titanic_all['Fare'].apply(lambda x: math.ceil(x))\n\n#Cabin\u51e6\u7406(\u5024\u304c\u8907\u96d1\u306a\u306e\u3067\u3001\u5148\u982d1\u6587\u5b57\uff08A\u306a\u3069\uff09\u3060\u3051\u3092\u4f7f\u3046\uff09\ntitanic_all['Cabin_class'] = titanic_all['Cabin'].apply(lambda x: '' if pd.isnull(x) else x[0])\n#titanic_all['Cabin_no'] = titanic_all['Cabin'].apply(lambda x: 0 if pd.isnull(x) else int(x[1:2]))\ntitanic_all.drop('Cabin', axis=1, inplace=True)\n\n#category\ntitanic_all['Sex'] = titanic_all['Sex'].astype('category').cat.codes\ntitanic_all['Cabin_class'] = titanic_all['Cabin_class'].astype('category').cat.codes\nprint(titanic_all.dtypes)\ntitanic_all.head()","12233e7c":"#features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin_class']\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'Cabin_class']\n#features = ['Pclass', 'Sex', 'Age', 'Fare']\n\n#train\u3068test\u30c7\u30fc\u30bf\u306b\u308f\u3051\u308b\ntitanic_train_d = titanic_all[titanic_all.flag == 1]\ntitanic_train_d.drop('flag', axis=1, inplace=True)\n\ntitanic_test_d = titanic_all[titanic_all.flag == 0]\ntitanic_test_d.drop('flag', axis=1, inplace=True)\ntitanic_test_d.drop('Survived', axis=1, inplace=True)","80181f83":"#\u5404\u9805\u76ee\u306e\u76f8\u95a2\nprint(titanic_train_d.corr())","28f2e740":"#\u691c\u8a3c\u7528\u306b\u308f\u3051\u308b\nfrom sklearn.model_selection import train_test_split\ntitanic_train_dx = titanic_train_d[features]\ntitanic_train_dy = titanic_train_d[outputs]\ntitanic_train_train_x, titanic_train_test_x, titanic_train_train_y, titanic_train_test_y = train_test_split(titanic_train_dx, titanic_train_dy, test_size=0.4)\n\nprint(titanic_train_train_x.shape)\nprint(titanic_train_train_y.shape)\nprint(titanic_train_test_x.shape)\nprint(titanic_train_test_y.shape)","dac82349":"#\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\n\ndef RFC_Tuning(x, y, test_x, test_y, n, m, r):\n    model_dt = RandomForestClassifier(n_estimators=n, max_depth=m, random_state=r)\n    model_dt.fit(x, y.values.ravel())\n    preds_test = model_dt.predict(test_x)\n    return (1.0 - mean_absolute_error(test_y, preds_test))\n\nrfc_t = np.empty(4)\nn_estimators_list = [50, 80, 100, 120]\nmax_depth_list = [3, 5, 8]\nrandom_state_list = [0, 1, 2]\nfor max_d in max_depth_list:\n    for n_est in n_estimators_list:\n        for r_stat in random_state_list:\n            rfc_t = np.vstack((rfc_t, [n_est, max_d, r_stat, RFC_Tuning(titanic_train_train_x, titanic_train_train_y, titanic_train_test_x, titanic_train_test_y, n_est, max_d, r_stat)]))\n\nprint(\"\u7cbe\u5ea6\u306e\u9ad8\u304b\u3063\u305f\u7d44\u307f\u5408\u308f\u305b\")\nprint(rfc_t[np.argmax(rfc_t[:, 3])])\nn_est = int(rfc_t[np.argmax(rfc_t[:, 3])][0])\nmax_d = int(rfc_t[np.argmax(rfc_t[:, 3])][1])\nr_stat = int(rfc_t[np.argmax(rfc_t[:, 3])][2])\n        ","957206fa":"from xgboost import XGBRegressor\nmodel_xg = XGBRegressor()\nmodel_xg.fit(titanic_train_train_x, titanic_train_train_y.values.ravel())\npreds_test = model_xg.predict(titanic_train_test_x)\n#\u7d50\u679c\u304cfloat\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\nfor i in range(len(preds_test)):\n    preds_test[i] = int(np.round(preds_test[i]))\n    \nprint(1.0 - mean_absolute_error(titanic_train_test_y, preds_test))\npreds_test[0:10]","fe73b92d":"#\u63d0\u51fa\u7528\nmodel_dt = RandomForestClassifier(n_estimators=n_est, max_depth=max_d, random_state=r_stat)\nmodel_dt.fit(titanic_train_d[features], titanic_train_d[outputs].values.ravel())\npreds_test = model_dt.predict(titanic_test_d)\noutput = pd.DataFrame({'PassengerId': titanic_test.PassengerId, 'Survived': preds_test})\n\n#model_xg = XGBRegressor()\n#model_xg.fit(titanic_train_d[features], titanic_train_d[outputs].values.ravel())\n#preds_test = model_xg.predict(titanic_test_d)\n#preds_test_i = []\n#for i in range(len(preds_test)):\n#    preds_test_i.append(int(np.round(preds_test[i])))\n#output = pd.DataFrame({'PassengerId': titanic_test.PassengerId, 'Survived': preds_test_i})\n\noutput.to_csv('my_submission.csv', index=False)\nprint(output.shape)\noutput.head(10)\n","902f9970":"Survived\u3068\u5404\u9805\u76ee\u306e\u76f8\u95a2\u3067\u306f\u3001Sex(-0.54), Pclass(-0.34)\u304c\u9ad8\u3044\u3002"}}