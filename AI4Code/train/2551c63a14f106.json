{"cell_type":{"6dc4c309":"code","3c8ea228":"code","8ce68076":"code","d9215f82":"code","e7dfbc83":"code","0fe35b82":"code","a51656c1":"code","0fd1638b":"code","11d32b05":"code","8999f3f0":"code","70db2cee":"code","bb624f1a":"markdown"},"source":{"6dc4c309":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Activation, MaxPooling2D\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split","3c8ea228":"!nvidia-smi","8ce68076":"#Read training and test data\nX_train_full=pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv', header='infer').values\nX_test=pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv', header='infer').values\n\n#Separate label and images from the training data\nX_train=X_train_full[:,1:]\ny_train=X_train_full[:,0]\n\n#Normalize train and test images\nX_train = (X_train.astype(np.float32) - 127.5)\/127.5\nX_test = (X_test.astype(np.float32) - 127.5)\/127.5","d9215f82":"#Reshpae train and test images from 784 to 28 x 28 x 1\nX_train=X_train.reshape(-1,28,28,1)\nX_test=X_test.reshape(-1,28,28,1)\n\n#One-hot encode class labels\ny_train_vectors=to_categorical(y_train)\n\n#Create train and validation split\nX_train, X_val, y_train, y_val= train_test_split(X_train, y_train_vectors, test_size=0.2, random_state=2)","e7dfbc83":"#Define CNN\ncnn=Sequential()\n\ncnn.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False, input_shape=(X_train.shape[1:])))\ncnn.add(BatchNormalization())\ncnn.add(Activation('relu'))\ncnn.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False))\ncnn.add(BatchNormalization())\ncnn.add(Activation('relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\n\ncnn.add(Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False))\ncnn.add(BatchNormalization())\ncnn.add(Activation('relu'))\ncnn.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False))\ncnn.add(BatchNormalization())\ncnn.add(Activation('relu'))\n\n\ncnn.add(Flatten())\n    \ncnn.add(Dense(units=10))\ncnn.add(BatchNormalization())\ncnn.add(Activation('softmax'))\n\ncnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","0fe35b82":"#Create instance of ImageDataGenerator for augmenting training images.\n#Augmentation can help avoid overfitting\n#We are using rotation_range=10,zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1. \n#Nothing else for augmentation\n\ntrain_datagen = ImageDataGenerator(featurewise_center=False,\n                             samplewise_center=False,\n                             featurewise_std_normalization=False,\n                             samplewise_std_normalization=False,\n                             zca_whitening=False,\n                             rotation_range=10,\n                             zoom_range=0.1,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             horizontal_flip=False,\n                             vertical_flip=False\n                            )\n\n#Use flow method to pass images to fit method in the batches of size 120\ntrain_generator = train_datagen.flow(X_train, y_train,\n                                     batch_size=120,\n                                     shuffle=True)\n\nval_datagen = ImageDataGenerator()\nval_generator = val_datagen.flow(X_val, y_val,\n                                 batch_size=120,\n                                 shuffle=True)","a51656c1":"#Set how we plan to reduce learning rate on plateau\nreduceLROnPlateau = ReduceLROnPlateau(monitor='val_acc', \n                                patience=3,\n                                verbose=1, \n                                factor=0.5,\n                                min_lr=0.00001)","0fd1638b":"#Display model summary and plot\ncnn.summary()\n\ntf.keras.utils.plot_model(cnn)","11d32b05":"#Fit\/Train CNN\ncnn.fit(train_generator, epochs=150, callbacks=[reduceLROnPlateau], validation_data=val_generator, steps_per_epoch=400)","8999f3f0":"#Predict on test images, 10 probabilities for each test image as there are 10 classes.\n#So, basically prediction_vectors is 28K x 10\nprediction_vectors=cnn.predict(X_test)\n\n#Decide the label from probabilities, so now, prediction_final is 28K x 10\npredictions_final=np.argmax(prediction_vectors, axis=1)","70db2cee":"#Read sample_submission.csv in dataframe sub\nsub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\n\n#Overwrite labels in dataframe sub\nsub[\"Label\"] = predictions_final\n\n#Write updated dataframes as submission.csv\nsub.to_csv('submission.csv',index=False)\n\n#Please Upvote the notebook, if you find it useful.","bb624f1a":"Digit Recognizer:\n\nThe competion is about classifying popular MNIST images. These images are of handwritten English digits. Ten classes from 0 to 9. Images are of size 28 x 28 but they are flatten and given as row vectors in train and test file. Train and test files have 42K and 28K rows respectively corresponding to 42K train images and 28K test images. Training file has 785 columns.  The first column is class label and next 784 are pixel intensity of an image (flatten image). Test file has 784 columns as it does not have class label for the images. Sample Submission file has 2 columns, the first one is ImageId and the second one is Label. Read this file in a dataframe. We need to overwrite 28K predictied labels on Label column and save the dataframe as submission.csv\n\nIn this notebook, we use convolutional neural network (CNN) and create a baseline. In the next notebook, we will use better CNN with ensemble learning. If you want to refer to feed forward neural network (FFNN) baseline, you can refer to the notebook: https:\/\/www.kaggle.com\/priyankdl\/ffnn-baseline-in-keras\n\nSteps:\n1. Import require modules\/packages\/libraries\n2. Read training and test data\n3. Separate X_train (image) and y_train (class label) and get numpy arrays from training data\n4. Normalize train and test images\n5. One-hot encode class labels and create train and validation split for training.\n6. Define CNN model using Sequential or Model. Compile model\n7. Display model summary and model plot. \n8. Create instance of ImageDataGenerator for image augmentation with rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1. We don't augment images with anything else. Augmenting images is very important to ensure no overfitting. We create generator for train and validation.\n9. Use flow method of ImageDataGenerator with batch_size=128. This will allow fit method of the model to receive images in batches of size 128.\n10. Setup callbacks\n11. Fit Model\n12. Predict for test images\n13. Read sample_submission.csv in a dataframe\n14. Overwrite \"Label\" column in the dataframe with predictions\n15. Write dataframe as submission.csv\n\nPlease Upvote the notebook, if you find it useful."}}