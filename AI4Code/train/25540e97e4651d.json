{"cell_type":{"9af842d6":"code","88818012":"code","ced10cb5":"code","5cf9251c":"code","4dcb9b59":"code","5e197202":"code","f0fafafd":"code","ff4ce21b":"code","1ecd71b6":"code","96e94d32":"code","71304e6b":"code","a8ba193c":"code","9d7714b3":"code","3abfaec1":"code","e3d1cad3":"code","5cdef27e":"code","59fd3660":"code","910b4dd7":"code","5ce25d94":"code","40ece13a":"code","0ea9ccc3":"code","6a44e0f9":"code","592f8e5c":"code","ecee0e37":"code","2bb2697b":"code","74625f3a":"code","9c4b11f8":"code","ab99c9dd":"code","dd942ed8":"code","b22c0ae7":"code","d6e3f0f0":"code","e555e390":"code","d7b27053":"code","a211ccf7":"code","4deb30cf":"code","54825f36":"code","7247bf1c":"code","d086dc74":"code","784784f2":"code","54be7514":"code","c5b0429e":"code","07edd382":"code","c2e3bdef":"code","8428e167":"code","5e4ee82e":"code","7c3b2d6f":"code","94c7c7ee":"code","442e048c":"code","e03dd3a6":"code","cd5131fa":"code","51e25167":"code","ddf93f70":"code","a982bfe8":"code","115b17b3":"code","d485b714":"code","ce70294b":"code","3565b55f":"code","ef785a83":"code","bf4d63e6":"code","23c6ed66":"markdown","0e06b633":"markdown","ed6a13c1":"markdown","45d3d727":"markdown","8df8f51c":"markdown","6bde6890":"markdown","2b7f69ee":"markdown","eab93dce":"markdown","8c37c53b":"markdown"},"source":{"9af842d6":"import numpy as np \nimport pandas as pd\nfrom pandas.plotting import scatter_matrix\nimport seaborn as sns\nfrom scipy.stats import skew\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import Pipeline\n\n#from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_log_error\n\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore') # \u043e\u0442\u043a\u043b\u044e\u0447\u0438\u0442\u044c \u0432\u0441\u0435 \u043f\u0440\u0435\u0434\u0443\u043f\u0440\u0435\u0436\u0434\u0435\u043d\u0438\u044f\n\nsns.set(rc={'figure.figsize': (8, 5)})","88818012":"sample_submission = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","ced10cb5":"X_train = train.copy()\nX_test = test.copy()\n\nY = train['SalePrice']\nX_train = X_train.drop(['SalePrice'], axis=1)","5cf9251c":"Y.head()","4dcb9b59":"Y.shape","5e197202":"X_train_num = X_train.select_dtypes(include = ['float64', 'int64'])\nX_train_encoder = X_train.select_dtypes(include = ['object'])\n\nX_test_num = X_test.select_dtypes(include = ['float64', 'int64'])\nX_test_encoder = X_test.select_dtypes(include = ['object'])","f0fafafd":"sns.distplot(Y, kde_kws = {'color': 'gray', 'lw':1, 'label': 'Predictions' })","ff4ce21b":"#Y = np.log1p(Y)\n#sns.distplot(Y, kde_kws = {'color': 'gray', 'lw':1, 'label': 'Predictions' })","1ecd71b6":"scaler_imput = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n        ('RobustScaler', RobustScaler()),\n        (\"scaler\", MinMaxScaler())\n    ])","96e94d32":"X_train_num_tr = pd.DataFrame(scaler_imput.fit_transform(X_train_num), columns=X_train_num.columns)\nX_test_num_tr = pd.DataFrame(scaler_imput.transform(X_test_num), columns=X_test_num.columns)","71304e6b":"print(X_train_num_tr.shape)\nprint(X_test_num_tr.shape)","a8ba193c":"def Pearson_correlation():\n    cor_map = plt.cm.RdBu\n    plt.figure(figsize=(15,17))\n    plt.title('Pearson Correlation', y=1.05, size=15)\n    sns.heatmap(X_train_num_tr.astype(float).corr(),linewidths=0.1,vmax=1.0, \n                square=True, cmap=cor_map, linecolor='white', annot=True) ","9d7714b3":"Pearson_correlation()","3abfaec1":"#skewed_feats_train = X_train_num_tr.apply(lambda x: skew(x.dropna()))\n#skewed_feats_train = skewed_feats_train[skewed_feats_train > 0.75]\n#skewed_feats_train = skewed_feats_train.index\n#X_train_num_tr[skewed_feats_train] = np.log1p(X_train_num_tr[skewed_feats_train])","e3d1cad3":"#skewed_feats_test = X_test_num_tr.apply(lambda x: skew(x.dropna()))\n#skewed_feats_test = skewed_feats_test[skewed_feats_test > 0.75]\n#skewed_feats_test = skewed_feats_test.index\n#X_test_num_tr[skewed_feats_test] = np.log1p(X_test_num_tr[skewed_feats_test])","5cdef27e":"X_train_encoder.head(5)","59fd3660":"X_train_encoder['SalePrice'] = Y ","910b4dd7":"sns.set(rc={'figure.figsize': (24, 10)})\nsum_isnull_encodtrain = X_train_encoder.isnull().sum() \nsns.barplot(x=sum_isnull_encodtrain[sum_isnull_encodtrain > 0].index, \n            y=list(sum_isnull_encodtrain[sum_isnull_encodtrain > 0]))","5ce25d94":"sns.set(rc={'figure.figsize': (20, 5)})\nAlley_bar = X_train_encoder.groupby('Alley').aggregate({'Alley': 'count'})\nMasVnrType_bar = X_train_encoder.groupby('MasVnrType').aggregate({'MasVnrType': 'count'})\n\nplt.subplot(141)\nsns.barplot(x=Alley_bar.T.columns, y=Alley_bar['Alley'])\nplt.subplot(142)\nsns.barplot('Alley', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(143)\nsns.barplot(x=MasVnrType_bar.T.columns, y=MasVnrType_bar['MasVnrType'])\nplt.subplot(144)\nsns.barplot('MasVnrType', 'SalePrice', data=X_train_encoder)","40ece13a":"#X_train_encoder[\"Alley\"] = X_train_encoder[\"Alley\"].fillna(\"Grvl\")\n#X_train_encoder[\"MasVnrType\"] = X_train_encoder[\"MasVnrType\"].fillna(\"BrkFace\")","0ea9ccc3":"sns.set(rc={'figure.figsize': (20, 12)})\nBsmtQual_bar = X_train_encoder.groupby('BsmtQual').aggregate({'BsmtQual': 'count'})\nBsmtCond_bar = X_train_encoder.groupby('BsmtCond').aggregate({'BsmtCond': 'count'})\nBsmtExposure_bar = X_train_encoder.groupby('BsmtExposure').aggregate({'BsmtExposure': 'count'})\nBsmtFinType1_bar = X_train_encoder.groupby('BsmtFinType1').aggregate({'BsmtFinType1': 'count'})\nBsmtFinType2_bar = X_train_encoder.groupby('BsmtFinType2').aggregate({'BsmtFinType2': 'count'})\nElectrical_bar = X_train_encoder.groupby('Electrical').aggregate({'Electrical': 'count'})\n\nplt.subplot(341)\nsns.barplot(x=BsmtQual_bar.T.columns, y=BsmtQual_bar['BsmtQual'])\nplt.subplot(342)\nsns.barplot('BsmtQual', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(343)\nsns.barplot(x=BsmtCond_bar.T.columns, y=BsmtCond_bar['BsmtCond'])\nplt.subplot(344)\nsns.barplot('BsmtCond', 'SalePrice', data=X_train_encoder)\n\n\nplt.subplot(345)\nsns.barplot(x=BsmtExposure_bar.T.columns, y=BsmtExposure_bar['BsmtExposure'])\nplt.subplot(346)\nsns.barplot('BsmtExposure', 'SalePrice', data=X_train_encoder)\n\n\nplt.subplot(347)\nsns.barplot(x=BsmtFinType1_bar.T.columns, y=BsmtFinType1_bar['BsmtFinType1'])\nplt.subplot(348)\nsns.barplot('BsmtFinType1', 'SalePrice', data=X_train_encoder)","6a44e0f9":"#X_train_encoder[\"BsmtQual\"] = X_train_encoder[\"BsmtQual\"].fillna(\"TA\")\n#X_train_encoder[\"BsmtCond\"] = X_train_encoder[\"BsmtCond\"].fillna(\"TA\")\n#X_train_encoder[\"BsmtExposure\"] = X_train_encoder[\"BsmtExposure\"].fillna(\"No\")\n#X_train_encoder[\"BsmtFinType1\"] = X_train_encoder[\"BsmtFinType1\"].fillna(\"Unf\")","592f8e5c":"sns.set(rc={'figure.figsize': (20, 5)})\nplt.subplot(141)\nsns.barplot(x=BsmtFinType2_bar.T.columns, y=BsmtFinType2_bar['BsmtFinType2'])\nplt.subplot(142)\nsns.barplot('BsmtFinType2', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(143)\nsns.barplot(x=Electrical_bar.T.columns, y=Electrical_bar['Electrical'])\nplt.subplot(144)\nsns.barplot('Electrical', 'SalePrice', data=X_train_encoder)","ecee0e37":"#X_train_encoder[\"BsmtFinType2\"] = X_train_encoder[\"BsmtFinType2\"].fillna(\"Unf\")\n#X_train_encoder[\"Electrical\"] = X_train_encoder[\"Electrical\"].fillna(\"SBrkr\")","2bb2697b":"sns.set(rc={'figure.figsize': (20, 10)})\nGarageType_bar = X_train_encoder.groupby('GarageType').aggregate({'GarageType': 'count'})\nGarageFinish_bar = X_train_encoder.groupby('GarageFinish').aggregate({'GarageFinish': 'count'})\nGarageQual_bar = X_train_encoder.groupby('GarageQual').aggregate({'GarageQual': 'count'})\nGarageCond_bar = X_train_encoder.groupby('GarageCond').aggregate({'GarageCond': 'count'})\n\n\nplt.subplot(241)\nsns.barplot(x=GarageType_bar.T.columns, y=GarageType_bar['GarageType'])\nplt.subplot(242)\nsns.barplot('GarageType', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(243)\nsns.barplot(x=GarageFinish_bar.T.columns, y=GarageFinish_bar['GarageFinish'])\nplt.subplot(244)\nsns.barplot('GarageFinish', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(245)\nsns.barplot(x=GarageQual_bar.T.columns, y=GarageQual_bar['GarageQual'])\nplt.subplot(246)\nsns.barplot('GarageQual', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(247)\nsns.barplot(x=GarageCond_bar.T.columns, y=GarageCond_bar['GarageCond'])\nplt.subplot(248)\nsns.barplot('GarageCond', 'SalePrice', data=X_train_encoder)","74625f3a":"#X_train_encoder[\"GarageType\"] = X_train_encoder[\"GarageType\"].fillna(\"Attchd\")\n#X_train_encoder[\"GarageFinish\"] = X_train_encoder[\"GarageFinish\"].fillna(\"Unf\")\n#X_train_encoder[\"GarageQual\"] = X_train_encoder[\"GarageQual\"].fillna(\"TA\")\n#X_train_encoder[\"GarageCond\"] = X_train_encoder[\"GarageCond\"].fillna(\"TA\")","9c4b11f8":"sns.set(rc={'figure.figsize': (18, 10)})\nPoolQC_bar = X_train_encoder.groupby('PoolQC').aggregate({'PoolQC': 'count'})\nFence_bar = X_train_encoder.groupby('Fence').aggregate({'Fence': 'count'})\nMiscFeature_bar = X_train_encoder.groupby('MiscFeature').aggregate({'MiscFeature': 'count'})\nFireplaceQu_bar = X_train_encoder.groupby('FireplaceQu').aggregate({'FireplaceQu': 'count'})\n\n\nplt.subplot(241)\nsns.barplot(x=PoolQC_bar.T.columns, y=PoolQC_bar['PoolQC'])\nplt.subplot(242)\nsns.barplot('PoolQC', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(243)\nsns.barplot(x=Fence_bar.T.columns, y=Fence_bar['Fence'])\nplt.subplot(244)\nsns.barplot('Fence', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(245)\nsns.barplot(x=MiscFeature_bar.T.columns, y=MiscFeature_bar['MiscFeature'])\nplt.subplot(246)\nsns.barplot('MiscFeature', 'SalePrice', data=X_train_encoder)\n\nplt.subplot(247)\nsns.barplot(x=FireplaceQu_bar.T.columns, y=FireplaceQu_bar['FireplaceQu'])\nplt.subplot(248)\nsns.barplot('FireplaceQu', 'SalePrice', data=X_train_encoder)","ab99c9dd":"#X_train_encoder[\"PoolQC\"] = X_train_encoder[\"PoolQC\"].fillna(\"Gd\")\n#X_train_encoder[\"Fence\"] = X_train_encoder[\"Fence\"].fillna(\"MnPrv\")\n#X_train_encoder[\"MiscFeature\"] = X_train_encoder[\"MiscFeature\"].fillna(\"Shed\")\n#X_train_encoder[\"FireplaceQu\"] = X_train_encoder[\"FireplaceQu\"].fillna(\"Gd\")","dd942ed8":"X_train_encoder_cetegor_tr = pd.get_dummies(X_train_encoder)\nX_test_encoder_cetegor_tr = pd.get_dummies(X_test_encoder)","b22c0ae7":"print(X_train_encoder_cetegor_tr.shape)\nprint(X_test_encoder_cetegor_tr.shape)","d6e3f0f0":"# delete columns from train which are not in test\ncolums_X_train_encoder_cetegor_tr = list(X_train_encoder_cetegor_tr)\ncolums_X_test_encoder_cetegor_tr = list(X_test_encoder_cetegor_tr)\n\nmas_colums_ismissing_in = []\n\nfor i in colums_X_train_encoder_cetegor_tr:\n    if i not in colums_X_test_encoder_cetegor_tr:\n        mas_colums_ismissing_in.append(i)\n        \nX_train_encoder_cetegor_tr = X_train_encoder_cetegor_tr.drop(mas_colums_ismissing_in, axis=1)","e555e390":"print(X_train_encoder_cetegor_tr.shape)\nprint(X_test_encoder_cetegor_tr.shape)","d7b27053":"X_train_num_tr = X_train_num_tr.reset_index()\nX_train_encoder_cetegor_tr = X_train_encoder_cetegor_tr.reset_index()\n\nX_test_num_tr = X_test_num_tr.reset_index()\nX_test_encoder_cetegor_tr = X_test_encoder_cetegor_tr.reset_index()","a211ccf7":"X_train_new_df = pd.merge(X_train_num_tr, X_train_encoder_cetegor_tr)\nX_test_new_df = pd.merge(X_test_num_tr, X_test_encoder_cetegor_tr)","4deb30cf":"X_train_new_df = X_train_new_df.drop(['index', 'Id'], axis=1)\nX_test_new_df = X_test_new_df.drop(['index', 'Id'], axis=1)","54825f36":"print(X_train_new_df.shape) \nprint(X_test_new_df.shape)","7247bf1c":"sns.set(rc={'figure.figsize': (8, 5)})\nX_train_new_df['SalePrice'] = Y\nsns.scatterplot(x='GrLivArea', y='SalePrice', data=X_train_new_df) ","d086dc74":"X_train_new_df = X_train_new_df.drop(X_train_new_df[(X_train_new_df['GrLivArea']>0.8) & \n                                                    (X_train_new_df['SalePrice']<200000)].index)","784784f2":"sns.scatterplot(x='GrLivArea', y='SalePrice', data=X_train_new_df)  ","54be7514":"Y = X_train_new_df['SalePrice']\nX_train_new_df = X_train_new_df.drop(['SalePrice'], axis=1)","c5b0429e":"def plot_learning_curves(model, X, y):\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10)\n    train_errors, val_errors = [], [] \n    \n    for m in range(1, len(X_train)):\n        \n        model.fit(X_train[:m], y_train[:m]) \n        y_train_predict = abs(model.predict(X_train[:m])) \n        y_val_predict = abs(model.predict(X_val)) \n    \n        train_errors.append(mean_squared_log_error(y_train[:m], y_train_predict))\n        val_errors.append(mean_squared_log_error(y_val, y_val_predict))\n\n    plt.plot(np.sqrt(train_errors), \"r-\", linewidth=1, label=\"train\")\n    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=1, label=\"val\")\n    plt.legend(loc=\"upper right\", fontsize=14)   # not shown in the book\n    plt.xlabel(\"Training set size\", fontsize=14) # not shown\n    plt.ylabel(\"rmsle\", fontsize=14)              # not shown","07edd382":"def plot_SaleYandpredY(predict_X_test):\n    sns.kdeplot(Y, label = 'train')\n    sns.kdeplot(predict_X_test, label = 'test')","c2e3bdef":"def train_validate_test_split(df, train_percent=0.14, seed=None):\n    np.random.seed(seed)\n    perm = np.random.permutation(df.index) # \u041f\u0440\u043e\u0438\u0437\u0432\u043e\u043b\u044c\u043d\u043e \u043f\u0435\u0440\u0435\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u0438\u043b\u0438 \u0432\u0435\u0440\u043d\u0443\u0442\u044c \u043f\u0435\u0440\u0435\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0439 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d.\n    m = len(df.index)\n    \n    train_linREG_end = int(train_percent * m)  # 0.6 *10\n    train_SGD_end = int(train_percent * m) + train_linREG_end\n    train_Poly_end = int(train_percent * m) + train_SGD_end\n    train_Ridge_end = int(train_percent * m) + train_Poly_end\n    train_Lasso_end = int(train_percent * m) + train_Ridge_end\n    train_Enet_end = int(train_percent * m) + train_Lasso_end\n    \n    train_linREG = df.ix[perm[:train_linREG_end]] \n    train_SGD = df.ix[perm[train_linREG_end:train_SGD_end]] \n    train_Poly = df.ix[perm[train_SGD_end:train_Poly_end]] \n    train_Ridge = df.ix[perm[train_Poly_end:train_Ridge_end]] \n    train_Lasso = df.ix[perm[train_Ridge_end:train_Lasso_end]] \n    train_Enet = df.ix[perm[train_Lasso_end:train_Enet_end]] \n    train_RF = df.ix[perm[train_Enet_end:]]\n    \n    return train_linREG, train_SGD, train_Poly, train_Ridge, train_Lasso, train_Enet, train_RF","8428e167":"class SklearnHelper(object):\n    def __init__(self, clf, params=None):\n        if params:\n            self.clf = clf(**params)\n        else:\n            self.clf = clf\n\n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self,x,y):\n        return self.clf.fit(x,y)\n    \n    def RandomizedSearchCV(self, params_random, cv=5):\n        return RandomizedSearchCV(estimator = self.clf, param_distributions = params_random, cv=5)\n    \n    def GridSearchCV(self, params_random, cv=5):\n        return  GridSearchCV(estimator = self.clf, param_grid = params_random, cv=5)","5e4ee82e":"Stoch_gradient_descent_params = {\n    'max_iter': 3000, \n    'tol': 0.001, \n    'penalty': 'l2', \n    'eta0': 0.04, \n    'random_state': 42,\n    'learning_rate': 'invscaling', \n    'loss': 'squared_loss'\n}\n\nRidge_params = {\n    'alpha': 2, \n    'max_iter': 1000,\n    'tol': 0.001,\n    #'solver': \"saga\", \n    'normalize': False,\n    'fit_intercept': True,\n    'random_state': 42\n}\n\nLasso_params = {\n    'alpha': 5,\n    'max_iter': 1000,\n    'random_state': 42,\n    'tol': 0.001, \n    'warm_start': True,\n    'selection': 'random',\n    'normalize': True,\n    'positive': True,\n    \n}\n\n\nElasticNet_params = {\n    'alpha': 2, \n    'l1_ratio': 1, \n    'random_state': 42,\n    'max_iter': 3000,\n    'fit_intercept': True,\n    'selection': 'random',\n    'tol': 0.001,\n    'positive': True,\n    'precompute': False,\n    'warm_start': False\n    \n}\n\nrandom_grid_params = {\n    'max_depth': 14, \n    'min_samples_leaf': 1,\n    'min_samples_split': 2,\n    'n_estimators': 500,\n    'random_state': 42\n}\n\nGrad_boosting_params = {\n    'loss': 'lad',\n    'learning_rate': 0.04,\n    'n_estimators': 3000,\n    'criterion': 'mse',\n    'max_depth': 10,\n    'min_samples_leaf': 7,\n    'min_samples_split': 16,\n    'random_state': 42\n}","7c3b2d6f":"# Create 5 objects that represent our 4 models\nsgd_reg = SklearnHelper(clf=SGDRegressor, params=Stoch_gradient_descent_params)\nridge_reg = SklearnHelper(clf=Ridge, params=Ridge_params)\nlasso_reg = SklearnHelper(clf=Lasso, params=Lasso_params)\nelastic_net = SklearnHelper(clf=ElasticNet, params=ElasticNet_params)\nrf_search_one = SklearnHelper(clf=RandomForestRegressor, params=random_grid_params)\ngr_boos_search_one = SklearnHelper(clf=GradientBoostingRegressor, params=Grad_boosting_params)","94c7c7ee":"gr_boos_search_one.fit(X_train_new_df, Y)\npredict_gr_boos_search_one = gr_boos_search_one.predict(X_test_new_df)\n\nrf_search_one.fit(X_train_new_df, Y)\npredict_rf_search_one = rf_search_one.predict(X_test_new_df)\n\nsgd_reg.fit(X_train_new_df, Y)\npredict_X_test_stoch_gradient_descent = sgd_reg.predict(X_test_new_df)\n\nridge_reg.fit(X_train_new_df, Y)\nRidge_Standart = ridge_reg.predict(X_test_new_df)\n\nlasso_reg.fit(X_train_new_df, Y)\nLasso_Standart = lasso_reg.predict(X_test_new_df)\n\nelastic_net.fit(X_train_new_df, Y)\npredict_elastic_net = elastic_net.predict(X_test_new_df)","442e048c":"sns.set(rc={'figure.figsize': (15, 9)})\nplt.subplot (231)\nplot_SaleYandpredY(predict_gr_boos_search_one)\nplt.subplot (232)\nplot_SaleYandpredY(predict_rf_search_one)\nplt.subplot (233)\nplot_SaleYandpredY(predict_X_test_stoch_gradient_descent)\nplt.subplot (234)\nplot_SaleYandpredY(Ridge_Standart)\nplt.subplot (235)\nplot_SaleYandpredY(Lasso_Standart)\nplt.subplot (236)\nplot_SaleYandpredY(predict_elastic_net)","e03dd3a6":"sns.kdeplot(predict_gr_boos_search_one, label = 'predict_gr_boos_search_one')\nsns.kdeplot(predict_rf_search_one, label = 'predict_rf_search_one')\n\nsns.kdeplot(predict_X_test_stoch_gradient_descent, label = 'predict_X_test_stoch_gradient_descent')\nsns.kdeplot(Ridge_Standart, label = 'Ridge_Standart')\n\nsns.kdeplot(Lasso_Standart, label = 'Lasso_Standart')\nsns.kdeplot(predict_elastic_net, label = 'predict_elastic_net')","cd5131fa":"id_test = test[['Id']]\nid_test = id_test.astype(int)","51e25167":"predict_SalePrice = pd.DataFrame.from_dict({\n    \n    'GradientBoostingRegressor': predict_gr_boos_search_one,\n    'RandomForestRegressor': predict_rf_search_one,\n    'ElasticNet': predict_elastic_net,\n    'Lasso': Lasso_Standart,\n    'Ridge': Ridge_Standart,\n    'SGDRegressor': predict_X_test_stoch_gradient_descent\n})","ddf93f70":"predict_SalePrice.head()","a982bfe8":"scatter = scatter_matrix(predict_SalePrice, figsize=(19, 19))","115b17b3":"predict_SalePrice.plot(x = \"GradientBoostingRegressor\", y = \"Lasso\", kind = \"scatter\")","d485b714":"pred = predict_SalePrice.mean(axis=1)","ce70294b":"finall_F_mean = pd.DataFrame.from_dict({'Id': list(id_test.Id), \n                                  'SalePrice': pred})\n\nfinall_F_mean2 = pd.DataFrame.from_dict({'Id': list(id_test.Id), \n                                  'SalePrice': predict_SalePrice[['RandomForestRegressor', 'SGDRegressor']].mean(axis=1)})","3565b55f":"finall_F_mean.head()","ef785a83":"finall_F_mean2.head()","bf4d63e6":"finall_F_mean.to_csv(\"Submission_mean.csv\", index=False)\nfinall_F_mean2.to_csv(\"Submission_mean2.csv\", index=False)","23c6ed66":"## Feature Exploration: Table join","0e06b633":"## Modelling","ed6a13c1":"## Feature Exploration: Restore missing numerical values and scale them","45d3d727":"## Feature Exploration, Engineering and Cleaning","8df8f51c":"## Reduction of numerical values to a normal distribution","6bde6890":"## Outlier removal","2b7f69ee":"## Translation of categorical features into coding with one active state","eab93dce":"## prediction table","8c37c53b":"## Data loading"}}