{"cell_type":{"d107f379":"code","515040c8":"code","cc321d26":"code","05f4ba4e":"code","8d5ace0c":"code","828ef3c0":"code","43f29fa5":"code","fcbd57cd":"code","774f6669":"code","ed8d12c8":"code","f7bc4b3c":"code","3a44bd1e":"code","00696970":"code","443cea50":"code","1572c673":"code","14244187":"code","54c4eb14":"code","aae52988":"code","7c5141b5":"code","d1ff131f":"code","9d9c4ee3":"code","187885b8":"code","c44ba361":"code","d75a94d7":"code","5c2c8b0b":"code","df542a7a":"code","dd70a06e":"code","e1c62bd6":"markdown","ff639199":"markdown","0f8cd70a":"markdown","a8d18990":"markdown","264cc7e4":"markdown","ef640253":"markdown","577e345a":"markdown","0a92bc7c":"markdown","5e1a5088":"markdown","5b461df6":"markdown","80b60158":"markdown"},"source":{"d107f379":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\ndf_commenters  = pd.read_excel(r\"..\/input\/df-comentarios\/df_comentarios.xlsx\", sheet_name='Hoja1',usecols = 'A:F')\ndf_commenters.head()","515040c8":"# Algunas estad\u00edsticas\n#print('Total posts: ' + str(len(my_posts)))\nprint('---------')\nprint('Comentarios Totales: ' + str(df_commenters.shape[0]))\nprint('Distintas Campa\u00f1as: ' +str(df_commenters.campana.nunique()))\nprint('Promedio Comentarios por Campa\u00f1as: ' +str(df_commenters['campana'].value_counts().mean()))\n\ndf_commenters['campana'].value_counts()[:5].plot(kind='bar', figsize=(12,6), title='Top 5 campa\u00f1as comentadas')\n\n","cc321d26":"# Manejar el formato de la fecha \ndf_commenters.fecha = pd.to_datetime(df_commenters.fecha, unit='s')\npd.to_datetime(df_commenters['fecha'], format=\"MMddyyyyHHmmss\")\n\nax = df_commenters.fecha.dt.dayofweek.value_counts().sort_index().plot(kind='bar',\n                                                                       figsize=(12,6),                             \n                                                                       title='Comentarios por d\u00eda de la semana (0 - Sunday, 6 - Saturday)')\nax.set_xticklabels(['Do','Lu','Ma','Mi','Ju','Vi','Sa'])\nax.set_xlabel(\"D\u00eda de la Semana\")\nax.set_ylabel(\"N\u00b0 Comentarios\")","05f4ba4e":"df_commenters['created_at_cl'] = df_commenters.fecha.dt.tz_localize('UTC').dt.tz_convert('Chile\/Continental')\ndf_commenters.created_at_cl.dt.hour.value_counts().sort_index().plot(kind='bar', figsize=(12,6))","8d5ace0c":"# Cargamos librer\u00edas y stopswords\nimport collections\nimport numpy as np\nimport string\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom matplotlib import rcParams\nfrom wordcloud import WordCloud, STOPWORDS,ImageColorGenerator\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\n\nstop_words_sp = set(stopwords.words('spanish'))\nstop_words_en = set(stopwords.words('english'))\nstop_words = stop_words_sp | stop_words_en\nstop_words.add('si')\nstop_words.add('asi')\nstop_words.add('as\u00ed')\nsw_list = ['que','tbn','oie','tan','...',',']\nstop_words.update(sw_list)","828ef3c0":"#Limpiamos el texto de letras extra\u00f1as\nimport re\ndf_commenters['texto_c'] = df_commenters['texto'].map(lambda x: re.sub('[^A-Za-z0-9]+', ' ',str(x)))\n\n\ntext = ' '.join(df_commenters['texto_c'].str.lower())\n\nwordcloud = WordCloud().generate(text)\nwordcloud = WordCloud(stopwords=stop_words, background_color=\"white\", max_words=1500).generate(text)\n#wordcloud.most_common(20)\nplt.figure(figsize = (10,5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","43f29fa5":"filtered_words = [word for word in text.split() if word not in stop_words]\ncounted_words = collections.Counter(filtered_words)\n\nwords = []\ncounts = []\nfor letter, count in counted_words.most_common(10):\n    words.append(letter)\n    counts.append(count)\n    \ncolors = cm.rainbow(np.linspace(0, 1, 10))\nrcParams['figure.figsize'] = 10, 5\n\nplt.title('Principales palabras en los comentarios')\nplt.xlabel('Cantidad')\nplt.ylabel('Palabras')\nplt.barh(words, counts, color=colors)\n","fcbd57cd":"from nltk.probability import FreqDist\n\nfdist = FreqDist(filtered_words)\nfdist.plot(30,cumulative=False)\nplt.show()","774f6669":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nsenti = SentimentIntensityAnalyzer()\n#import nltk.data\n#nltk.data.load(r'C:\\Users\\Monin\\analisis\\Taller_IN7564\\vader_lexicon\\vader_lexicon.txt')\n#%%time\ndata = df_commenters.drop(['texto'],axis=1).copy() \ndata['Senti_Compound_Score'] = df_commenters.texto_c.apply(lambda x : senti.polarity_scores(x)['compound'])\ndata['Neutral_score'] = df_commenters.texto_c.apply(lambda x : senti.polarity_scores(x)['neu'])\ndata['Positive_score'] = df_commenters.texto_c.apply(lambda x : senti.polarity_scores(x)['pos'])\ndata['Negative_score'] = df_commenters.texto_c.apply(lambda x : senti.polarity_scores(x)['neg'])\n\ndata.loc[data.Senti_Compound_Score >0 ,'Overall_Sentiment']='Positive'\ndata.loc[data.Senti_Compound_Score == 0, 'Overall_Sentiment'] = 'Neutral'\ndata.loc[data.Senti_Compound_Score < 0,'Overall_Sentiment'] = 'Negative'","ed8d12c8":"plt.figure(figsize=(10,5)) \ndata.Overall_Sentiment.value_counts().plot(kind='bar',color = 'crimson')\nplt.xlabel('Sentimiento')\nplt.ylabel('Cantidad de comentarios')\nplt.title('Sentimientos en Campa\u00f1as')","f7bc4b3c":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer(stop_words=stop_words)\nX_train_counts = count_vect.fit_transform(data.texto_c)\nX_train_counts.shape","3a44bd1e":"# CountVectorizer supports counts of N-grams of words or consecutive characters.\n# Once fitted, the vectorizer has built a dictionary of feature indices:\ncount_vect.vocabulary_\ncount_vect.get_feature_names()","00696970":"from sklearn.feature_extraction.text import TfidfTransformer\ntf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n#TF\nX_train_tf = tf_transformer.transform(X_train_counts)\nX_train_tf.shape","443cea50":"#TF IDF\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nX_train_tfidf.shape","1572c673":"from sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nkm_model = KMeans(n_clusters=4)\nkm_model.fit(X_train_tfidf)\n \nclustering = collections.defaultdict(list)\n \nfor idx, label in enumerate(km_model.labels_):\n       clustering[label].append(idx)\n\nclusters = km_model.labels_.tolist()\ndata['grupo'] = clusters","14244187":"#C\u00f3digo para guardar modelo y cargarlo posteriormente.\n#import joblib\n#joblib.dump(km_model, r'C:\\Users\\MRJLhpnZT81QDZo1TiXUeMCEmyuUDrStCC3Qqter.pkl')\n\n# Y lo cargamos\n#km = joblib.load(r'C:\\Users\\MRJLhpnZT81QDZo1TiXUeMCEmyuUDrStCC3Qqter.pkl')\n#clusters = km.labels_.tolist()","54c4eb14":"#Estad\u00edstas por grupo creado\ndata.grupo.value_counts()","aae52988":"from sklearn.metrics.pairwise import cosine_similarity\ndist = 1 - cosine_similarity(X_train_tfidf)\n","7c5141b5":"cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a'}\ncluster_names = {0: 'Positivo', \n                 1: 'Neutro', \n                 2: 'Negativo', \n                 3: 'Super positivo', \n                 }\n","d1ff131f":"# An\u00e1lisis sentimiento promedio por grupo\ndata['Senti_Compound_Score'].groupby(data['grupo']).mean() #groupby cluster for aggregation purposes\n\n","9d9c4ee3":"vocab_frame = pd.DataFrame( { 'word' : count_vect.vocabulary_.keys() , 'id': count_vect.vocabulary_.values()})\nvocab_frame.head()\n#print('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')\n","187885b8":"print(\"Top t\u00e9rminos por grupo:\")\nprint()\n#sort cluster centers by proximity to centroid\norder_centroids = km_model.cluster_centers_.argsort()[:, ::-1] \n\nfor i in range(4):\n    print(\"Cluster %d words:\" % i, end='')\n    print(' %s' % vocab_frame.loc[vocab_frame.id.isin(list(order_centroids[i, :5])),'word'].to_list())\n    print() #add whitespace\n    print() #add whitespace    \nprint()\nprint()","c44ba361":"from sklearn.manifold import MDS\n\nMDS()\n\n# convert two components as we're plotting points in a two-dimensional plane\n# \"precomputed\" because we provide a distance matrix\n# we will also specify `random_state` so the plot is reproducible.\nmds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n\npos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n\nxs, ys = pos[:, 0], pos[:, 1]\nprint()\nprint()","d75a94d7":"#create data frame that has the result of the MDS plus the cluster numbers and titles\ndf = pd.DataFrame(dict(x=xs, y=ys, label=clusters, sentimiento = data['Overall_Sentiment'], campana = data['campana'])) \n#group by cluster\ngroups = df.groupby('label')\ngroups.head()","5c2c8b0b":"#some ipython magic to show the matplotlib plots inline\n%matplotlib inline \n# set up plot\nfig, ax = plt.subplots(figsize=(17, 9)) # set size\nax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n\n#iterate through groups to layer the plot\n#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color\/label\nfor name, group in groups:\n    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n            label=cluster_names[name], color=cluster_colors[name], \n            mec='none')\n    ax.set_aspect('auto')\n    ax.tick_params(\\\n        axis= 'x',          # changes apply to the x-axis\n        which='both',      # both major and minor ticks are affected\n        bottom='off',      # ticks along the bottom edge are off\n        top='off',         # ticks along the top edge are off\n        labelbottom='off')\n    ax.tick_params(\\\n        axis= 'y',         # changes apply to the y-axis\n        which='both',      # both major and minor ticks are affected\n        left='off',      # ticks along the bottom edge are off\n        top='off',         # ticks along the top edge are off\n        labelleft='off')\n    \nax.legend(numpoints=1)  #show legend with only 1 point\n\n#add label in x,y position with the label as the film title\nfor i in range(len(df)):\n    ax.text(df.loc[i]['x'], df.loc[i]['y'], df.loc[i]['campana'], size=8)  \n\n    \n    \nplt.show() #show the plot","df542a7a":"plt.close()\n","dd70a06e":"from scipy.cluster.hierarchy import ward, dendrogram\n\nlinkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n\nfig, ax = plt.subplots(figsize=(15, 20)) # set size\nax = dendrogram(linkage_matrix, orientation=\"right\", labels=clusters);\n\nplt.tick_params(\\\n    axis= 'x',          # changes apply to the x-axis\n    which='both',      # both major and minor ticks are affected\n    bottom='off',      # ticks along the bottom edge are off\n    top='off',         # ticks along the top edge are off\n    labelbottom='off')\n\nplt.tight_layout() #show plot with tight layout\n\n#uncomment below to save figure\n#plt.savefig('ward_clusters.png', dpi=200) #save figure as ward_clusters","e1c62bd6":"<a id=\"section-two\"><\/a>\n# Mapa de Palabras","ff639199":"# Text Analysis Example: Sentiments and Segmentation\nText-based reactions on online campaigns using Vader sentiment analysis and scikit-learn clustering techniques\n\n## An\u00e1lisis de texto\n\nEjemplo para an\u00e1lisis de texto. Primero hacemos algunas estad\u00edsticas b\u00e1sicas y un mapa de palabras, luego identificamos los sentimientos por cada comentario y, finalmente, aplicamos un modelo de segmentaci\u00f3n y lo graficamos de acuerdo a alguna categor\u00eda de los datos, en este caso analizamos campa\u00f1as. \n\n* [Carga de datos y librer\u00edas base](#section-one)\n* [Mapa de Palabras](#section-two)\n* [Modelos](#section-three)\n - [An\u00e1lisis de Sentimientos](#subsection-m1)\n - [Construcci\u00f3n de la matriz Palabra-Documento](#subsection-m2)\n - [Segmentaci\u00f3n](#subsection-m3)\n - [Modelo MDS](#subsection-m4)\n - [Dendograma](#subsection-m5)\n \n\n## Text analysis\n\nExample for text analysis. First we do some basic statistics and a word map, then we identify the feelings for each comment and, finally, we apply a segmentation model and graph it according to some category of data, in this case we analyze campaigns.\n\n* [Loading data and base libraries](#section-one)\n* [Word Map](#section-two)\n* [Models](#section-three)\n  - [Sentiment Analysis](#subsection-m1)\n  - [Construction of the Word-Document matrix](#subsection-m2)\n  - [Segmentation](#subsection-m3)\n  - [MDS Model](#subsection-m4)\n  - [Dendrogram](#subsection-m5)\n","0f8cd70a":"<a id=\"section-one\"><\/a>\n# Carga de datos y librer\u00edas base","a8d18990":"## Gr\u00e1fico con d\u00eda de la semana con m\u00e1s comentarios","264cc7e4":"<a id=\"section-three\"><\/a>\n# Modelos","ef640253":"<a id=\"subsection-m3\"><\/a>\n## Modelo para Generar Grupos (Clustering)","577e345a":"<a id=\"subsection-m4\"><\/a>\n## Modelo MDS","0a92bc7c":"<a id=\"subsection-m2\"><\/a>\n## Construcci\u00f3n de la matriz Palabra-Documento","5e1a5088":"## Gr\u00e1fico del horario con m\u00e1s comentarios","5b461df6":"<a id=\"subsection-m5\"><\/a>\n## Dendograma","80b60158":"<a id=\"subsection-m1\"><\/a>\n## An\u00e1lisis de Sentimientos"}}