{"cell_type":{"dca5a5c7":"code","8cd4e24a":"code","d61f3e9d":"code","359aeca3":"code","fe1197d5":"code","a57839ac":"code","0ead8f61":"code","66b2db7d":"code","c9e87875":"code","f5f29317":"code","2b45cf63":"code","f96e003d":"code","89a6fd34":"code","558290df":"code","3a48af08":"code","329fac9f":"code","0753daa6":"code","588b4240":"code","5a8e3354":"code","82197dc0":"code","ca03276f":"code","4e2fd189":"markdown","76343c69":"markdown","d6f72904":"markdown","5d7ff850":"markdown","2e81ceff":"markdown","3a552030":"markdown","d8cb0816":"markdown","df860be8":"markdown","747d22c6":"markdown","079cf232":"markdown","ff59e3ed":"markdown","1f9e6c90":"markdown","2d936ed8":"markdown","02baac3a":"markdown"},"source":{"dca5a5c7":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud,STOPWORDS\nstopwords = set(STOPWORDS)\n\nfrom textblob import TextBlob\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport re\nfrom collections import Counter\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         if (filename.endswith('Tweets.CSV')) :\n#             print(os.path.join(dirname, filename))","8cd4e24a":"# Reading data\n# df=pd.read_csv('\/kaggle\/input\/coronavirus-covid19-tweets-early-april\/2020-03-29 Coronavirus Tweets.CSV', skiprows=lambda i: i!=0 and (i) % 1000 != 0)\n\n# Read all files and down-sample\ndf2 = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if (filename.endswith('Tweets.CSV')):\n            df2.append(pd.read_csv(os.path.join(dirname, filename), header=0, skiprows=lambda i: i!=0 and (i) % 50 != 0))\ndf = pd.concat(df2, axis=0, ignore_index=True)\n\ndf.head()\ndf.shape","d61f3e9d":"# display columns\nprint (\"original columns: \")\ndf.columns\n\n# dropping columns\ntweet = df.copy()\ntweet.drop(['status_id','user_id','screen_name','source','reply_to_status_id','reply_to_user_id','is_retweet','place_full_name','place_type','reply_to_screen_name','is_quote','followers_count','friends_count','account_lang','account_created_at','verified'],axis=1, inplace = True)\ntweet.head()","359aeca3":"# filtering data with 'country_code = US' and 'language = en'\n# (tweet.country_code == \"US\") & \ntweet =tweet[(tweet.lang == \"en\")].reset_index(drop = True)\ntweet.drop(['country_code','lang'],axis=1,inplace=True)\n\n# check missing values\n# tweet.isna().sum()\n\ntweet.head()","fe1197d5":"# shape\ntweet.shape\n\n# # Top 5 most favourited tweets:\n# fav = tweet[['favourites_count','text']].sort_values('favourites_count',ascending = False)[:5].reset_index()\n# for i in range(5):\n#     print(i,']', fav['text'][i],'\\n')\n    \n# #Top 5 most retweeted tweets:\n# retweet = tweet[['retweet_count','text']].sort_values('retweet_count',ascending = False)[:5].reset_index()\n# for i in range(5):\n#     print(i,']', retweet['text'][i],'\\n')","a57839ac":"def show_wordcloud(data , title = None):\n    wordcloud = WordCloud(background_color='black',stopwords=stopwords,max_words=200,max_font_size=40).generate(str(data))\n  \n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    plt.title(title, size = 25)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()\n\nshow_wordcloud(tweet['text'])","0ead8f61":"# Extracting hashtags and accounts\nstoptags = ['#covid19', '#covid_19', '#covid-19', '#covid', '#coronavirus', '#outgreak', '#virus', '#pandemic']\n\ntweet['tags'] = tweet['text'].str.findall(r'(?:(?<=\\s)|(?<=^))#.*?(?=\\s|$|\\.,)')\ntweet['tags'] = tweet['tags'].apply(lambda word_list:list(map(lambda w: w.lower(), word_list))).apply(lambda word_list:list(filter(lambda w: w not in stoptags, word_list)))\n\ntweet['accts'] = tweet['text'].str.findall(r'(?:(?<=\\s)|(?<=^))@.*?(?=\\s|$)')\ntweet['entity_text'] = tweet['tags'].apply(' '.join) + ' ' + tweet['accts'].apply(' '.join)\ntweet.head()","66b2db7d":"# Tokenizing and Removing special charactors\nfor i in range(tweet.shape[0]) :\n    tweet['text'][i] = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\\/\\\/\\S+)|(#[A-Za-z0-9]+)\", \" \", tweet['text'][i]).split()).lower()\ntweet['text'].head()","c9e87875":"#Removing Stop Words\nstopwords\n\ntweet['text'] = tweet['text'].apply(lambda tweets: ' '.join([word for word in tweets.split() if word not in stopwords]))\ntweet['text'].head() ","f5f29317":"%time\ntweet['sentiment'] = ' '\ntweet['polarity'] = None\nfor i,tweets in enumerate(tweet.text) :\n    blob = TextBlob(tweets)\n    tweet['polarity'][i] = blob.sentiment.polarity\n    if blob.sentiment.polarity > 0 :\n        tweet['sentiment'][i] = 'positive'\n    elif blob.sentiment.polarity < 0 :\n        tweet['sentiment'][i] = 'negative'\n    else :\n        tweet['sentiment'][i] = 'neutral'\npd.set_option('display.max_colwidth', 400)\ntweet.head()","2b45cf63":"print(tweet.sentiment.value_counts())\nsns.countplot(x='sentiment', data = tweet);","f96e003d":"count = pd.DataFrame(tweet.groupby('sentiment')['favourites_count'].sum())\ncount.head()","89a6fd34":"count = pd.DataFrame(tweet.groupby('sentiment')['retweet_count'].sum())\ncount.head()","558290df":"plt.figure(figsize=(10,6))\nsns.distplot(tweet['polarity'], bins=30)\nplt.title('Sentiment Distribution',size = 15)\nplt.xlabel('Polarity',size = 15)\nplt.ylabel('Frequency',size = 15)\nplt.show();","3a48af08":"# format timestamp\ntweet['created_at'] = pd.to_datetime(tweet['created_at'])\ntweet['created_at'] = pd.IntervalIndex(pd.cut(tweet['created_at'], pd.date_range('2020-03-29', '2020-05-01', freq='2880T'))).left\n\n# count sentiment\ntweet_count1 = tweet.groupby(['created_at','sentiment'])['text'].count().reset_index().rename(columns={'text':'count'})\ntweet_count1.head()\n\n# check missing values\n# tweet_count1.isna().sum()","329fac9f":"#format sentiment table\ntimes = tweet_count1.loc[tweet_count1['sentiment'] == 'negative']['created_at'].reset_index(drop = True)\npos = tweet_count1.loc[tweet_count1['sentiment'] == 'positive']['count'].reset_index(drop = True)\nneutral = tweet_count1.loc[tweet_count1['sentiment'] == 'neutral']['count'].reset_index(drop = True)\nneg = tweet_count1.loc[tweet_count1['sentiment'] == 'negative']['count'].reset_index(drop = True)\n\nplt.figure(figsize=(10,6))\nplt.xticks(rotation='45')\nplt.title(\"Sentiment count vs. Time\")\n\nlin1=plt.plot(times, pos, 'ro-', label='positive')\nlin2=plt.plot(times, neutral, 'g^-', label='neutral')\nlin3=plt.plot(times, neg, 'b--', label='negative')\nplt.legend()\nplt.show","0753daa6":"# \"score\" is defined as percent of positive tweets minus percent of negative tweets\nscore = (pos - neg) \/ (pos + neutral + neg)\n\nplt.figure(figsize=(10,6))\nplt.xticks(rotation='45')\nplt.title(\"positive scroe (positive percent - negative percent) vs. Time\")\n\nlin1=plt.plot(times, score, 'ro-', label='positive score')\nplt.legend()\nplt.show","588b4240":"all_words = []\nall_words = [word for i in tweet.entity_text for word in i.split()]\npos_words = tweet['entity_text'][tweet['sentiment'] == 'positive']\nneg_words = tweet['entity_text'][tweet['sentiment'] == 'negative']\nneutral_words = tweet['entity_text'][tweet['sentiment'] == 'neutral']\n# show_wordcloud(pos_words , 'POSITIVE')\n# show_wordcloud(neg_words , 'NEGATIVE')\n# show_wordcloud(neutral_words , 'NEUTRAL')\n\ndef get_freq(word_list):\n    freq = Counter(word_list).most_common(100)\n    freq = pd.DataFrame(freq)\n    freq.columns = ['word', 'frequency']\n    return freq\n\nall_freq = get_freq(all_words)\npos_freq = get_freq([word for i in pos_words for word in i.split()])\nneg_freq = get_freq([word for i in neg_words for word in i.split()])\n\nfreq = pd.merge(all_freq,pos_freq,on='word',how='left').rename(columns={'frequency_x':'total','frequency_y':'pos'})\nfreq = pd.merge(freq,neg_freq,on='word',how='left').rename(columns={'frequency':'neg'}).fillna(0)\nfreq['score'] = (freq['pos'] - freq['neg'] ) \/ freq['total']\n\nneg_freq_filtered = freq[(freq['score'] < 0.2) & (freq['neg'] > 0)].head(40).sort_values('score',ascending = True)\n\nneg_freq_filtered.head(40)","5a8e3354":"#Positive \nfreq[(freq['score'] >0.4) & (freq['pos'] !=0)].head(40).sort_values('score',ascending = False)","82197dc0":"plt.figure(figsize = (20, 20))\nsns.barplot(y=\"word\", x=\"score\",data=freq);","ca03276f":"# tweet.to_csv('tweet.csv',index=False)","4e2fd189":"# Reading Data","76343c69":"### Expore favorite and retweet counts\nA quick look at these showed that they are mostly inline with tweet count. So, we will just use tweet count for our study.","d6f72904":"# COVID Tweets - Sentiment Analysis and Trends \n\n### Abstract\nThis notebook presents novel results of COVID sentiment analysis with concrete findings. I use off-the-shelf libraries with functional limitations, but overall results seem valid based on my analysis. \n\n### Introduction\nThe worldwide coronavirus pandemic has led to the establishment of worldwide curfews, quarantines and lockdown to mitigate further spread of the virus. During this time, it can be helpful to track the public's responses to these changes. This study aims to answer the following questions: \n1. How do people feel during the crisis? \n2. How does the general public sentiment change over time? \n3. What are the topics that most contribute to this sentiment shift? \n\nI filtered the data to only include tweets in English for ease of study. This section summarizes the result with a few graphs generated by the code in the latter section of the notebook. \n\n### Sentiment Analysis\nDuring the COVID pandemic, [sentiment Analysis](https:\/\/monkeylearn.com\/sentiment-analysis\/) can be a very useful tool to help policymakers gain insight into social media data trends. Normally, sentiment analysis requires training an ML model using labelled data. However, since we don't have training data in this dataset, we opt to use pre-training modeled from the \"TextBlob\" package, as performed in this [example](https:\/\/www.kaggle.com\/kartikmohan1999\/covid19-sentiment-analysis). Although not a state-of-the-art model, it at least gives reasonable results. (I confirmed a few output cases with manual spot checks.)\n\nFrom the graphs of Sentiment over Time, we notice that: \n* The overall sentiment increased in positivity by about 4% throughout the month of April, while tweet volume decreased slightly. This may reflect gradual subsiding of initial panic.\n* The end of April saw a positivity spike of about 2%, which occurs right before re-opening in the USA. This boosted sentiment may be caused by an increase in morale attributed to the re-opening policy decision.\n\n![covid_sentiment_trend.png](attachment:covid_sentiment_trend.png)\n![covid_sentiment_trend_score.png](attachment:covid_sentiment_trend_score.png)\n\n**Error analysis**: \n* The Sentiment trend graph is prone to random noise\/variance if not given enough data points. On the other hand, with too many data points, the notebook runs very slowly. After tuning the data size, I confirmed that the graph is stable when the random sample partition is changed.\n* I do not have measurement of the error\/bias for the sentiment analysis using the \"TextBlob\" package library. The result seems reasonable based on manual spot checks. \n\n### Topic-Specific Sentiment Analysis\nTo answer question #3 (What are the topics that contributed to people's sentiment?), we need to gain some insights into what people are discussing in the Twitter posts. To do that, I first tried \"topic modeling\" with [Latent Dirichlet allocation(LDA)](https:\/\/en.wikipedia.org\/wiki\/Latent_Dirichlet_allocation) in this [notebook](https:\/\/www.kaggle.com\/esthercao\/covid-topic-modelling-lda). However, the topics in COVID-related tweets seem too nuanced for the basic LDA library that I used, and the result was not promising. \n\nI then extracted tags and account names from the tweet corpus. This seemed to give good insights into what subjects people talk about. \n\nObservations from the below graphs: \nA. Negative\n* In USA, negative sentiment are related to political issues such as @GOP, @WhiteHouse, @SpeakerPolosi, #donaldtrump, @FoxNews (a conservative news network), #chinesevirus\/#wuhanvirus (controversial term popularized by President Trump), #trumpvirus, #maga (make america great again), @POTUS\/@realDonaldTrump\/#trump.\n* In Britian, negative sentiment tend to be related to prominent public figures testing positive for the virus: @MattHancock, #borisjohnson. \nB. Positive\n* Positive tweets seem to relate less to specific countries and more to universal topics: #love, #inthistogether, #washyourhands, #stayhomeandstaysafe. \n* The lack of topics from users in other countries (India, Austria, Canada) among the English dataset may require further investigation. Possible explanations include: they are more positive in general, are less outspoken about negative topics, or use Twitter hashtags less often.\n\n![Negative_tags.png](attachment:Negative_tags.png)![Positive_tags.png](attachment:Positive_tags.png)\n\n### What could be improved: \n* Better sentiment analysis tool. TextBlob sentiment analysis has a [pre-trained model](https:\/\/textblob.readthedocs.io\/en\/dev\/_modules\/textblob\/en\/sentiments.html) that uses nltk's NaiveBayesClassifier, which does not account for sentence structure. Also, the model is trained on movie review data, which may have reduced performance when used on Twitter data. \n* Error rate for the sentiment analysis step is unknown. To measure the error rate, we may label a small (~1000s of tweets) validation data set to test the model. \n* This study did not factor in the country of the Twitter user. The Country field in the input data is very sparsely populated; if it were given for most tweets, it would allow us to study each country's data separately.\n* Refine Twitter hashtag topics with NER. [Named Entity Extraction (NER)](https:\/\/towardsdatascience.com\/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da) is a very useful tool for extracting topics, such as person name, company, places, etc. This could help answer refine our answer to question 2: \"What are the topics that contributed to people's sentiment?\". If we did not already have Twitter hashtags and accounts in this data set, NER could be used to answer this question.\n* Better data mining tool. The LDA topic mining is an older algorithm (2003) that doesn't take advantage of newer NLP development such as [BERT](https:\/\/en.wikipedia.org\/wiki\/BERT_(language_model)), which leverages natural language understanding and sentence structure.\n* Improve processing speed. Due to speed limitations, this notebook only processed 2% of available tweets. The decreased sample set may result in more uncertainty and error margains. This notebook used python code to directly process text, which is slow. \n* Expand study to other languages\n* Deeper exploration of user profile information\n   1. friends_count and followers_count to quantify tweet's social media influence\n   2. reply_to_screen_name, to determine connected components of people retweeting each other\n\n### What I learned from this project: \n* General approach to sentiment analysis\n* Using Kaggle, Pandas, pyplot, various packages for NLP\n* Handling a large data set; loading the dataset with sampling for efficient processing\n\n\nt","5d7ff850":"# Cleaning Data","2e81ceff":"Using TextBlob to analyze tweets to predict text sentiment and categorize as 'Positive', 'Negative' or 'Neutral'.","3a552030":"# Data Processing","d8cb0816":"# Importing Packages","df860be8":"# Feature Extraction","747d22c6":"# Inspect data","079cf232":"### Word Cloud : \nThis word cloud doesn't help answer our questions, but is an interesting visualization. The following words can be seen: \"COVID19\", \"resp\", \"Trump\", \"affected\", \"businesses\"","ff59e3ed":"## Analyzing Text for Sentiment","1f9e6c90":"## Sentiment Distribution","2d936ed8":"# Tags with the most Negative and Postive Sentiment","02baac3a":"## Sentiment Over Time"}}