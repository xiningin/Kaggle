{"cell_type":{"7e794900":"code","a18e5d8b":"code","fc79a7dd":"code","23caf0d2":"code","fdc81ed5":"code","f3e3b63b":"code","1c05a827":"markdown","76c1f11b":"markdown","bb3e07a2":"markdown","18121f7e":"markdown"},"source":{"7e794900":"# Start by importing the bq_helper module and calling on the specific active_project and dataset_name for the BigQuery dataset.\nimport bq_helper\nfrom bq_helper import BigQueryHelper\n# https:\/\/www.kaggle.com\/sohier\/introduction-to-the-bq-helper-package\n\noce_assignment = bq_helper.BigQueryHelper(active_project=\"patents-public-data\",\n                                   dataset_name=\"uspto_oce_assignment\")","a18e5d8b":"# View table names under the uspto_oce_assignment data table\nbq_assistant = BigQueryHelper(\"patents-public-data\", \"uspto_oce_assignment\")\nbq_assistant.list_tables()","fc79a7dd":"# View the first three rows of the assignment data table\nbq_assistant.head(\"assignment\", num_rows=3)","23caf0d2":"# View information on all columns in the assignment data table\nbq_assistant.table_schema(\"assignment\")","fdc81ed5":"query1 = \"\"\"\nSELECT\n  AVG(CAST(page_count AS INT64))\nFROM\n  `patents-public-data.uspto_oce_assignment.assignment`\nLIMIT\n  20;\n        \"\"\"\nresponse1 = oce_assignment.query_to_pandas_safe(query1)\nresponse1.head(20)","f3e3b63b":"bq_assistant.estimate_query_size(query1)","1c05a827":"## Example SQL Query\nWhat is the average page count for all the patent assignment files?","76c1f11b":"# How to Query USPTO OCE Patent Assignment Data (BigQuery)\n[Click here](https:\/\/www.kaggle.com\/mrisdal\/safely-analyzing-github-projects-popular-licenses) for a detailed notebook demonstrating how to use the bq_helper module and best practises for interacting with BigQuery datasets.","bb3e07a2":"Interpretting this number, this means my query scanned about ~0.02 GB (or 20 MB) of data in order to return an average document page count from the dataset.","18121f7e":"## Importance of Knowing Your Query Sizes\n\nIt is important to understand how much data is being scanned in each query due to the free 5TB per month quota. For example, if a query is formed that scans all of the data in a particular column, given how large BigQuery datasets are it wouldn't be too surprising if it burns through a large chunk of that monthly quota!\n\nFortunately, the bq_helper module gives us tools to very easily estimate the size of our queries before running a query. Start by drafting up a query using BigQuery's Standard SQL syntax. Next, call the estimate_query_size function which will return the size of the query in GB. That way you can get a sense of how much data is being scanned before actually running your query."}}