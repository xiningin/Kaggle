{"cell_type":{"236d0568":"code","55a042c2":"code","22f86d42":"code","9162a796":"code","c6ab5a53":"code","863f9277":"code","eb11f8c0":"code","7eeec3cb":"code","5ff92833":"code","227ce6bb":"code","8ce36ac7":"code","8ad783c0":"code","c6f56376":"code","734cec08":"code","26a5d88e":"code","87bfe690":"code","85e10405":"code","8f3142df":"code","5b1326d5":"code","c3bb6f22":"code","bb9e7db8":"code","7f0f9138":"code","97805ae3":"code","77f35f4a":"markdown","2d324928":"markdown","1142999f":"markdown","27648043":"markdown","945d8aab":"markdown","48433288":"markdown"},"source":{"236d0568":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns \nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom gensim.similarities.annoy import AnnoyIndexer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom gensim.models.word2vec import Word2Vec\nimport nltk\nfrom sklearn.datasets import fetch_20newsgroups\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.gridspec as gridspec\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.preprocessing import sequence, text\nfrom keras.callbacks import EarlyStopping\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM, GRU\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom scipy import stats\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter","55a042c2":"df = pd.read_csv('..\/input\/iba-ml1-final-project\/train.csv')\ndf.head()","22f86d42":"df['Product_Category'] = df['Product_Category'].fillna(value=df['Product_Category'].mode()[0])\ndf['Department'] = df['Department'].fillna(value=df['Department'].mode()[0])\ndf['Division'] = df['Division'].fillna(value=df['Division'].mode()[0])\n\n# From the EDA I found out that rows with missing review or review title are more likely to recommend and rate higher\n# I am imputing them with the word 'perfecto'\ndf['Review'] = df['Review'].fillna(value='perfecto')\ndf['Review_Title'] = df['Review_Title'].fillna(value='perfecto')","9162a796":"# Convert numbers to string\ndf['Rating'] = df['Rating'].apply(lambda s: str(s))","c6ab5a53":"X = df['Review_Title'].values\ny1 = df['Rating']\ny2 = df['Recommended']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y2, random_state=42)","863f9277":"VOCAB_SIZE = 800\nencoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\nencoder.adapt(X_train)","eb11f8c0":"model = tf.keras.models.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),  # VOCAB_SIZE + 1 (1 for padding token)\n        output_dim=64,\n        mask_zero=True\n    ),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","7eeec3cb":"model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 3)\nhistory = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[early_stop])","5ff92833":"sdf = df['Review']\n\nX = sdf.values\ny1 = df['Rating']\ny2 = df['Recommended']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y2, random_state=42)\n\nVOCAB_SIZE = 3000\nencoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\nencoder.adapt(X_train)","227ce6bb":"model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 1)\nhistory = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stop])","8ce36ac7":"plt.figure(figsize=(15, 5))\nplt.plot(history.history['loss'], label='Train loss')\nplt.plot(history.history['val_loss'], label='Validation loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","8ad783c0":"plt.figure(figsize=(15, 5))\nplt.plot(history.history['accuracy'], label='Train accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","c6f56376":"# Convert Rating to dummy variables\nlabenc = LabelEncoder()\n\nlabenc.fit(y1)\nencoded_Y = labenc.transform(y1)\n\ndummy_y = np_utils.to_categorical(encoded_Y)","734cec08":"X = df['Review_Title']\nX_train, X_test, y_train, y_test = train_test_split(X, dummy_y)\n\nVOCAB_SIZE = 2500\nencoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\nencoder.adapt(np.array(X_train))","26a5d88e":"model1 = tf.keras.models.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),  # VOCAB_SIZE + 1 (1 for padding token)\n        output_dim=32,\n        mask_zero=True\n    ),\n    tf.keras.layers.LSTM(32),\n    tf.keras.layers.Dense(16),\n    tf.keras.layers.Dense(8),\n    tf.keras.layers.Dense(5, activation='softmax')\n])","87bfe690":"model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 3)\nhistory = model1.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stop])","85e10405":"X = df['Review']\nX_train, X_test, y_train, y_test = train_test_split(X, dummy_y)\n\nVOCAB_SIZE = 5000\nencoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\nencoder.adapt(np.array(X_train))","8f3142df":"model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 1)\nhistory = model1.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stop])","5b1326d5":"recommended_predicted_val = model.predict_classes(X_test)\n\nrating_predicted_val = model1.predict_classes(X_test)\n\nprint(\"Spearmans Correlation\")\nprint(stats.spearmanr(rating_predicted_val, recommended_predicted_val))","c3bb6f22":"test_df = pd.read_csv('..\/input\/iba-ml1-final-project\/test.csv')\ntest_df.head()","bb9e7db8":"test_df['Product_Category'] = test_df['Product_Category'].fillna(value=test_df['Product_Category'].mode()[0])\ntest_df['Department'] = test_df['Department'].fillna(value=test_df['Department'].mode()[0])\ntest_df['Division'] = test_df['Division'].fillna(value=test_df['Division'].mode()[0])\ntest_df['Review'] = test_df['Review'].fillna(value='perfecto')\ntest_df['Review_Title'] = test_df['Review_Title'].fillna(value='perfecto')","7f0f9138":"test_df.isna().sum()","97805ae3":"recommended_predicted = model.predict_classes(test_df['Review_Title'] + ' '+test_df['Review'] + ' ' + test_df['Review_Title'])\nnp.unique(recommended_predicted, return_counts=True)\n\nrating_predicted = model1.predict_classes(test_df['Review_Title'] + ' '+test_df['Review'] + ' ' + test_df['Review_Title'])\nnp.unique(rating_predicted, return_counts=True)\n\nsubmission = pd.read_csv('..\/input\/iba-ml1-final-project\/sample_submission.csv')\n\nsubmission['Rating'] = rating_predicted\nsubmission['Recommended'] = recommended_predicted\n\nsubmission.to_csv('submission_89.csv', index=False)\nstats.spearmanr(rating_predicted, recommended_predicted)","77f35f4a":"## First I train the model on Review Titles later I train the same model on review itself","2d324928":"# Model to predict Rating","1142999f":"# Model to Predict Recommended","27648043":"We will change data from Review_Title to Review and train again the pretrained model","945d8aab":"# For Submisson","48433288":"## Deal with missing value imputations (more detailed version is in EDA notebook)"}}