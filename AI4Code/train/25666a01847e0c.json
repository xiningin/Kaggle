{"cell_type":{"5bcdb344":"code","04ac2372":"code","22599d77":"code","fa1f1e01":"code","dfaccc19":"code","ab204883":"code","8b542f8d":"code","42222756":"code","fce71991":"code","14adcfd4":"code","0281e204":"code","cc9cde68":"code","13647a5c":"code","209471fe":"code","49393b84":"code","039900dc":"code","7b1e2750":"code","f2cc03f2":"code","ca900e4a":"code","fd7e05d4":"code","8a2977b8":"code","8a3a1b92":"code","d5fd4699":"code","b07da568":"code","ffadf679":"code","00ac8538":"code","c8bc1ba8":"code","8ce23e77":"code","f74605a1":"markdown","ab9ec382":"markdown","c8fe6898":"markdown","c19d60e1":"markdown","00a5d5fc":"markdown","e1889cfb":"markdown","a34a11c3":"markdown","8de8bda2":"markdown","e1ff6051":"markdown","aae49321":"markdown","c3efdb4d":"markdown","cb7c675a":"markdown","3053b1f2":"markdown","af6a463f":"markdown","e6563ca3":"markdown","431c42b0":"markdown","91f82aab":"markdown","9277f4b6":"markdown","b384d723":"markdown","8bb3f31a":"markdown","abedd5a0":"markdown","ee295c0f":"markdown","ba2f2d3b":"markdown","f7d035a8":"markdown"},"source":{"5bcdb344":"import sys\nfrom collections import Counter\nimport random\nimport itertools\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport skimage.filters\n\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.preprocessing.image import (\n    random_rotation, random_shift, random_shear, random_zoom,\n    random_channel_shift, img_to_array)\n\n%matplotlib inline","04ac2372":"np.random.seed(42) # here, this is set to a constant for a reproducible results. You may drop this line to gain proper randomness on every run.\nINPUT_DIR = '..\/input\/whale-categorization-playground\/'","22599d77":"def plot_images_for_filenames(filenames, labels, rows=4):\n    '''\n    Loads the images from the file paths provided in filenames,\n    and prints them with the provided labels.\n    '''\n    imgs = [plt.imread(f'{INPUT_DIR}\/train\/{filename}') for filename in filenames]\n    \n    return plot_images(imgs, labels, rows)\n    \n        \ndef plot_images(imgs, labels, rows=4):\n    '''\n    Plots the provided images with the labels in a grid with the provided number of rows.\n    '''\n    # Set figure to 13 inches x 8 inches\n    figure = plt.figure(figsize=(13, 8))\n\n    cols = len(imgs) \/\/ rows + 1\n\n    for i in range(len(imgs)):\n        subplot = figure.add_subplot(rows, cols, i + 1)\n        subplot.axis('Off')\n        if labels:\n            subplot.set_title(labels[i], fontsize=16)\n        plt.imshow(imgs[i], cmap='gray')\n        \ndef is_grey_scale(img_path):\n    \"\"\"\n    This checks whether the image is percievably grayscale = it returns true not only for\n    single channel images, but also for multichannel (RGB) grayscale images.\n    Thanks to https:\/\/stackoverflow.com\/questions\/23660929\/how-to-check-whether-a-jpeg-image-is-color-or-gray-scale-using-only-python-stdli\n    \"\"\"\n    im = Image.open(img_path)\n    if len(im.getbands()) == 1:\n        return True\n    im = im.convert('RGB')\n    w,h = im.size\n    for i in range(w):\n        for j in range(h):\n            r,g,b = im.getpixel((i,j))\n            if r != g != b: return False\n    return True\n\ndef random_greyscale(img, p):\n    '''\n    Converts image to grayscale with the given probability p.\n    The returned image has always three channels.\n    '''\n    # check whether image is not grayscale already\n    if len(img.shape) == 2 or img.shape[2] == 1:\n        return np.repeat(img[:, :, np.newaxis], 3, axis=2)\n    \n    # colour image - convert it with the given probability.\n    if random.random() < p:\n        return np.dot(img[...,:3], [0.299, 0.587, 0.114])\n    # otherwise just return original image\n    return img\n\n\ndef random_flip(img, p):\n    '''\n    Randomly flips the image from left-to-right, given the probability p.\n    '''\n    if random.random() < p:\n        return np.flip(img, 1)\n    return img\n\ndef random_blur(img, p, sigma=1.37):\n    '''\n    Randomly blurs the image with gaussian kernel with sigma, given the probability p. \n    '''\n    if random.random() < p:\n        return skimage.filters.gaussian(img \/ 255.0, sigma=sigma, multichannel=len(img.shape) == 3) * 255\n    return img\n\ndef augmentation_pipeline(img_arr):\n    '''All augumentations together'''\n    img_arr = random_rotation(img_arr, 18, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n    img_arr = random_shear(img_arr, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n    img_arr = random_zoom(img_arr, zoom_range=(0.7, 1.4), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') # we do not want to zoom out, as the net may learn the artifacts caused by the filled areas.\n    img_arr = random_greyscale(img_arr, 0.4)\n    img_arr = random_blur(img_arr, 0.33)\n    img_arr = random_flip(img_arr, 0.5)\n\n    return img_arr","fa1f1e01":"IMAGE_SIZE = (160,120) # width, height\nNUM_OF_AUGMENTATIONS = 5\n\ndef makeNewWhalesUnique(trainDataFrame):\n    '''\n    Renames all new_whale whales to new_whale_<Id>, so that every\n    new whale is unique.\n    Note: I am not sure wheter every new whale is unique.\n    '''\n    for i in range(len(trainDataFrame['Id'])):\n        if trainDataFrame['Id'][i] == 'new_whale':\n            trainDataFrame['Id'][i] = ('new_whale_%d' % i)\n    return trainDataFrame\n            \ndef loadImageAndAugument(imgPath, imageSize=IMAGE_SIZE, numOfAugumentations=NUM_OF_AUGMENTATIONS, inputDir=INPUT_DIR):\n    '''Loads image, randomly auguments it and returns list of images suitable for use in Resnet50'''\n    if not imgPath.startswith(inputDir):\n        imgPath = inputDir + '\/train\/' + imgPath\n    inputImage = Image.open(imgPath).resize(imageSize).convert('RGB')\n    inputImageArray = img_to_array(inputImage)\n    result = [inputImageArray \/ 255]\n    for i in range(numOfAugumentations):\n        result.append(augmentation_pipeline(inputImageArray) \/ 255)\n    return result\n\ndef loadBatch(imagePaths, labels, startIdx=0, numOfImages=None):\n    if numOfImages is None:\n        numOfImages = imagePaths.count() - startIdx\n    loadedLabels = []\n    loadedImages = []\n    #for index, imgPath in imagePaths.iteritems()[startIdx:min(startIdx+numOfImages, imagePaths.count())]:\n    for index, imgPath in itertools.islice(imagePaths.iteritems(), startIdx, min(startIdx+numOfImages, imagePaths.count())):\n        print(index, imgPath)\n        imgArrays = loadImageAndAugument(imgPath)\n        for img in imgArrays:\n            loadedLabels.append(labels[index])\n            loadedImages.append(img)\n    return (loadedImages, loadedLabels)\n\n\ndef laodAndPrepareDataset(datasetPath=f'{INPUT_DIR}\/train.csv', train_size=0.8, random_state=None):\n    '''\n    Loads the dataset and preprocess it so that it can be used to load batches for training.\n    '''\n    if random_state is None:\n        random_state = random.randrange(2**32 - 1)\n    # load data to Panda DataFrame\n    train_df = pd.read_csv(datasetPath)\n    # Make things unique\n    train_df = makeNewWhalesUnique(train_df)\n    # split to train\/validation subsets in the following order:\n    # trainInputImagePaths, validationInputImagePaths, trainInputLabels, validationInputLabels\n    return  train_test_split(train_df['Image'], \n                             train_df['Id'],\n                             train_size=train_size, \n                             test_size=1.0 - train_size,\n                             random_state=random_state)","dfaccc19":"train_df = pd.read_csv('..\/input\/whale-categorization-playground\/train.csv')\ntrain_df.head()","ab204883":"rand_rows = train_df.sample(frac=1.)[:20]\nimgs = list(rand_rows['Image'])\nlabels = list(rand_rows['Id'])\n\nplot_images_for_filenames(imgs, labels)","8b542f8d":"num_categories = len(train_df['Id'].unique())\n     \nprint(f'Number of categories: {num_categories}')","42222756":"size_buckets = Counter(train_df['Id'].value_counts().values)","fce71991":"plt.figure(figsize=(10, 6))\n\nplt.bar(range(len(size_buckets)), list(size_buckets.values())[::-1], align='center')\nplt.xticks(range(len(size_buckets)), list(size_buckets.keys())[::-1])\nplt.title(\"Num of categories by images in the training set\")\n\nplt.show()","14adcfd4":"train_df['Id'].value_counts().head(3)","0281e204":"total = len(train_df['Id'])\nprint(f'Total images in training set {total}')","cc9cde68":"train_df = makeNewWhalesUnique(train_df)\n# check whether the counts are still that bad...\ntrain_df['Id'].value_counts().head(3)","13647a5c":"w_1287fbc = train_df[train_df['Id'] == 'w_1287fbc']\nplot_images_for_filenames(list(w_1287fbc['Image']), None, rows=9)","209471fe":"w_98baff9 = train_df[train_df['Id'] == 'w_98baff9']\nplot_images_for_filenames(list(w_98baff9['Image']), None, rows=9)","49393b84":"one_image_ids = train_df['Id'].value_counts().tail(8).keys()\none_image_filenames = []\nlabels = []\nfor i in one_image_ids:\n    one_image_filenames.extend(list(train_df[train_df['Id'] == i]['Image']))\n    labels.append(i)\n    \nplot_images_for_filenames(one_image_filenames, labels, rows=3)","039900dc":"is_grey = [is_grey_scale(f'{INPUT_DIR}\/train\/{i}') for i in train_df['Image'].sample(frac=0.1)]\ngrey_perc = round(sum([i for i in is_grey]) \/ len([i for i in is_grey]) * 100, 2)\nprint(f\"% of grey images: {grey_perc}\")","7b1e2750":"img_sizes = Counter([Image.open(f'{INPUT_DIR}\/train\/{i}').size for i in train_df['Image']])\n\nsize, freq = zip(*Counter({i: v for i, v in img_sizes.items() if v > 1}).most_common(20))\n\nplt.figure(figsize=(10, 6))\n\nplt.bar(range(len(freq)), list(freq), align='center')\nplt.xticks(range(len(size)), list(size), rotation=70)\nplt.title(\"Image size frequencies (where freq > 1)\")\n\nplt.show()","f2cc03f2":"img = Image.open(f'{INPUT_DIR}\/train\/ff38054f.jpg')\nimg_arr = img_to_array(img)\nplt.imshow(img)","ca900e4a":"imgs = [\n    random_rotation(img_arr, 30, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') \/ 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)","fd7e05d4":"imgs = [\n    random_shift(img_arr, wrg=0.1, hrg=0.3, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') \/ 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)","8a2977b8":"imgs = [\n    random_shear(img_arr, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') \/ 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)","8a3a1b92":"imgs = [\n    random_zoom(img_arr, zoom_range=(1.5, 0.7), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') \/ 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)","d5fd4699":"imgs = [random_greyscale(img_arr \/ 255, 0.5)\n        for _ in range(5)]\n\nplot_images(imgs, None, rows=1)","b07da568":"imgs = [augmentation_pipeline(img_arr) \/ 255 for _ in range(20)]\nplot_images(imgs, None, rows=4)","ffadf679":"imgs = loadImageAndAugument('70238365.jpg')\nplot_images(imgs, None, rows=1)","00ac8538":"trainInputImagePaths, validationInputImagePaths, trainInputLabels, validationInputLabels = laodAndPrepareDataset()","c8bc1ba8":"#example:\ntrainAugumentedImages, trainAugumentedLabels = loadBatch(trainInputImagePaths, trainInputLabels, 0, 4)","8ce23e77":"plot_images(trainAugumentedImages, trainAugumentedLabels, rows=4)","f74605a1":"### Random rotation","ab9ec382":"New whale is the biggest category with 810, followed by `w_1287fbc`. New whale, I believe, is any whale that isn't in scientist's database. Since we can pick 5 potential labels per id, it's probably going to make sense to always include new_whale in our prediction set, since there's always an 8.2% change that's the right one. But, to have training nice, we should rename each of its instance to be unique:","c8fe6898":"...and see how they look like:","c19d60e1":"## Dataset-specific utility functions","00a5d5fc":"The competition states that it's hard because: \"there are only a few examples for each of 3,000+ whale ids\", so let's take a look at the breakdown of number of image per category.","e1889cfb":"There appear to be too many categories to graph count by category, so let's instead graph the number of categories by the number of images in the category.","a34a11c3":"### Random shift","8de8bda2":"From these small sample sizes, it seems like > 50% of images are black and white, suggesting that a good initial augementation might be to just convert colour images to greyscale and add to the training set. Let's confirm that by looking at a sample of the images.","e1ff6051":"We have loaded and split the data. Seems ok... Now, lets generate some of  the data, and store it in array.","aae49321":"## Important imports","c3efdb4d":"### Random zoom","cb7c675a":"As we can see, the vast majority of classes only have a single image in them. This is going to make predictions very difficult for most conventional image classification models.","3053b1f2":"### Prepare the data\n\nPrepare the data for training (and validation) process.","af6a463f":"Let's plot a couple of images at random.","e6563ca3":"## Exploring the dataset","431c42b0":"### Random shear","91f82aab":"\nLet's take a look at one of the classes, to get a sense what flute looks like from the same whale.","9277f4b6":"## Data Augmentation","b384d723":"### All together\n\nGoing to create an augmentation pipeline which will combine all the augs for *a* single predictions. We are not giving zoom too huge range to reduce weid lines at the side of the image.","8bb3f31a":"It's very difficult to build a validation set when most classes only have 1 image, so my thinking is to perform some aggressive data augmentation on the classes with < 10 images before creating a train\/validation split. Let's take a look at a few examples of whales with only one example.","abedd5a0":"## General utility functions","ee295c0f":"### Grey scale\n\nWe want to ensure that all colour images also have a grey scale version.","ba2f2d3b":"It might also be worth capturing the size of the images so we can get a sense of what we're dealing with.","f7d035a8":"# Acknowledgments\nThis notebook is a fork of *\"Humpback Whale ID: Data and Aug Exploration\"* by** Lex Toumbourou**, and contains also some parts coppied from other kernels\/notebooks. Unfortunatelly, I did not written them down, so I cannot provide you a list with proper citations. Sorry!\n\nIf you happen to identify part of your work in this notebook, please, let me know, and I will add a note about it to this section.\n\n# Intro\nThis notebook provides\/showcases a preprocessing of the input data for the Humpback Whale Identification Challenge. It firstly examine the data, and then it provide utilities to ease the augumentation."}}