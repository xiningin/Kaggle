{"cell_type":{"1da93fdd":"code","24f92ca0":"code","0d3efb6e":"code","ba8e7c4a":"code","8b8bf286":"code","4bbdb15c":"code","11ad090b":"code","c9377c84":"code","9cec2eaf":"code","8cbb0f74":"code","065d9dde":"code","970ad973":"code","8305a393":"code","b301dd1f":"code","a212e941":"code","0efcaecd":"code","08b6b6da":"code","9eace645":"code","4a1ebeaf":"code","c74daca4":"code","a0e3ddd1":"code","312b852e":"code","85c8b28b":"code","46875757":"code","951d8463":"markdown","d6b6a05f":"markdown"},"source":{"1da93fdd":"import sklearn.datasets\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score","24f92ca0":"cancer=sklearn.datasets.load_breast_cancer()","0d3efb6e":"X=cancer.data\nY=cancer.target\nprint(X.shape)\n#30 Columns (Features) and 569 Samples","ba8e7c4a":"dataframe=pd.DataFrame(cancer.data,columns=cancer.feature_names)","8b8bf286":"dataframe['target(Y)']=cancer.target","4bbdb15c":"print(cancer.target_names)\ndataframe['target(Y)'].value_counts()","11ad090b":"#O is for benign and 1 is for malignant\ndataframe.groupby('target(Y)').mean()\n#12.146524 is the mean radius for a malignant tumor","c9377c84":"#Train on one part i.e on the training data and predict on test data\nX=dataframe.drop('target(Y)',axis=1)\nY=dataframe['target(Y)']\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y)\n#from this 80% of the X data is X_train and rest is X_test\n","9cec2eaf":"#In order to change the test size we can use test_size for both X & Y as an argument as\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1)","8cbb0f74":"#As for the Y which is our true output we can check how many are malignant & benign after the split using Y_test_mean()\n#By getting the mean we can observe that as per our split which is 90% train and 10% test the mean of the test data have\n#changed significantly so to solve this we use an another argument named as stratify as\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1,stratify=Y)","065d9dde":"#One more thing at the input data split if we check the mean similarly to the Y train & test data we will get values\n# for every features, for a good model deployment practice we use an another argument named as random_state which\n#will ensure and apply a constant state to all features that are available to us\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1,stratify=Y,random_state=1)","970ad973":"plt.plot(X_train.T,'_')\nplt.xticks(rotation='vertical')\nplt.ylabel('Range of Numerical Values')\nplt.title('All features value range')\nplt.show()","8305a393":"#Data Normalization or convertig into a binary form {0,1}\nX_normal=X_train['mean area'].map(lambda x:0 if x<1000 else 1)\n","b301dd1f":"#In order to normalize all the data into binary format use pd.cut \nX_all_train=X_train.apply(pd.cut,bins=2,labels=[0,1]).values #used to convert the data into np arrays\nX_all_test=X_test.apply(pd.cut,bins=2,labels=[0,1]).values","a212e941":"#b=3 Inference of the model\nthreshold=3\nprint('Threshold value: {}'.format(threshold))\ni=100\nprint('Taking sample row number: {}'.format(i))\n#100th row and all the features\nif np.sum(X_all_train[i,:])>=threshold:\n    print('Result: Malignant')\nelse:\n    print('Result: Benign')\n\nif Y_train[i]==1:\n    print('Y_train output is Malignant')\nelse:\n    print('Y_train output is Benign')\n     ","0efcaecd":"Y_train[100]","08b6b6da":"threshold=0\npredictions=[]\ncorrect_predictions=0\nfor x,y in zip(X_all_train,Y_train):\n    predictions.append(np.sum(x)>=threshold)\n    correct_predictions+=(y==(np.sum(x)>=threshold))\n    \n\ntotal_samples=X_all_train.shape[0]\n\n\nprint('Accuracy is {}%'.format(round((correct_predictions\/total_samples)*100)))","9eace645":"\nfor threshold in range(X_all_train.shape[1]+1):\n    predictions=[]\n    correct_predictions=0\n    for x,y in zip(X_all_train,Y_train):\n        predictions.append(np.sum(x)>=threshold)\n        correct_predictions+=(y==(np.sum(x)>=threshold))\n    \n    total_samples=X_all_train.shape[0]\n    print('At threshold value: {}, Accuracy is {}%'.format(threshold,round((correct_predictions\/total_samples)*100)))","4a1ebeaf":"dataframe.groupby('target(Y)').mean()","c74daca4":"#At threshold=0 which is of course true, when it is benign i.e. 0 the feature{mean radius} is greater than the malignant one\n# and same for other features so the data is more shifted towards benign \n# When normalizing the data for values x<1000 change to 0 otherwise 1 but in actual manignant cases are less so the normalization\n# or can say the binarization is not up to the mark ##\n#In order to normalize all the data again as per our observation into binary format\nX_all_trainew=X_train.apply(pd.cut,bins=2,labels=[1,0]).values#used to convert the data into np arrays\nX_all_testnew=X_test.apply(pd.cut,bins=2,labels=[1,0]).values\n","a0e3ddd1":"for threshold in range(X_all_trainew.shape[1]+1):\n    predictions=[]\n    correct_predictions=0\n    for x,y in zip(X_all_trainew,Y_train):\n        predictions.append(np.sum(x)>=threshold)\n        correct_predictions+=(y==(np.sum(x)>=threshold))\n    \n    total_samples=X_all_trainew.shape[0]\n    print('At threshold value: {}, Accuracy is {}%'.format(threshold,round((correct_predictions\/total_samples)*100)))","312b852e":"#On test data\nthreshold=28\npredictions_test=[]\nfor x in (X_all_testnew):\n    predictions_test.append((np.sum(x)>=threshold))\n    \ntest_accuracy=accuracy_score(predictions_test,Y_test)\nprint(threshold,round(test_accuracy*100))","85c8b28b":"#Templating a Model\/function\nclass MPNeuron:\n    def __init__(self):\n        self.threshold=None\n    def model(self,x):\n        return (sum(x)>=self.threshold)\n    def predict(self,X):\n        Y=[]\n        for x in X:\n            Y.append(self.model(x))\n        return np.array(Y)\n    \n    def fit(self,X,Y):\n        accuracy={}\n        for threshold in range(X.shape[1]+1):\n            self.threshold=threshold\n            pred=self.predict(X)\n            accuracy[threshold]=accuracy_score(pred,Y)\n            \n        maximum_accuracy=max(accuracy,key=accuracy.get)\n        self.threshold=maximum_accuracy\n        \n        print(maximum_accuracy)\n        print(accuracy[maximum_accuracy])","46875757":"x=MPNeuron()\nx.fit(X_all_trainew,Y_train)","951d8463":">Source: PadhAI \n\nThanks!","d6b6a05f":"# MP Neuron Function\/Model Overview"}}