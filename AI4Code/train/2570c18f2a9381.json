{"cell_type":{"cdb2514b":"code","0e2f08de":"code","73b126a8":"code","7fcdf735":"code","640cf5f1":"code","2d8555dd":"code","9eaddbeb":"code","e1b25115":"code","2695bb6d":"code","e1b60078":"code","2722f72d":"code","4fceecb5":"code","155cba4b":"code","be6c5d01":"code","701adbd7":"code","7f29bf13":"code","07cda29d":"code","790d408d":"code","f85ba234":"code","8f0e0662":"code","f7099960":"code","bf8b294e":"code","840df9b0":"code","d72b1499":"code","42a8459a":"code","aad723c2":"code","c97d98fb":"code","b695b758":"code","cb3f6fbd":"code","0c567624":"code","90aee9d7":"code","3146d8c4":"code","12dc7f5a":"code","629e8c62":"code","11fb39c9":"code","4e4ef819":"markdown","03221b69":"markdown","103cd73d":"markdown"},"source":{"cdb2514b":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nfrom gensim.models import word2vec\n\nfrom sklearn.manifold import TSNE\nimport time\nfrom tqdm import tqdm\n\nimport lightgbm as lgb\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\n\nfrom scipy.sparse import hstack\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom sklearn import model_selection, preprocessing, metrics\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999","0e2f08de":"import os\nprint(os.listdir(\"..\/input\"))","73b126a8":"print(os.listdir(\"..\/input\/embeddings\"))","7fcdf735":"train_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/test.csv\")","640cf5f1":"#Size of datasets\nprint(\"Size of train data  (Rows, Columns): \",train_df.shape)\nprint(\"Size of test data  (Rows, Columns): \",test_df.shape)","2d8555dd":"#Snapshot of train data\ntrain_df.head()","9eaddbeb":"#Sanapshot of test data\ntest_df.head()","e1b25115":"np.unique(train_df['target'].values)","2695bb6d":"np.mean(train_df['target'].values)","e1b60078":"print('---------------------------------------------------------------------------------')\nprint(train_df['target'].value_counts())\nprint('---------------------------------------------------------------------------------')\nprint(train_df['target'].value_counts()\/train_df['target'].shape[0])\nprint('---------------------------------------------------------------------------------')\n#sns.set(style=\"darkgrid\")\nax = sns.countplot(x=train_df['target'], data=train_df)","2722f72d":"eng_stopwords = set(stopwords.words(\"english\"))","4fceecb5":"## Number of words in the text ##\ntrain_df[\"num_words\"] = train_df[\"question_text\"].apply(lambda x: len(str(x).split()))\ntest_df[\"num_words\"] = test_df[\"question_text\"].apply(lambda x: len(str(x).split()))","155cba4b":"cnt_srs = train_df[\"num_words\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of words in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()\n\n\n","be6c5d01":"## Number of unique words in the text ##\ntrain_df[\"num_unique_words\"] = train_df[\"question_text\"].apply(lambda x: len(set(str(x).split())))\ntest_df[\"num_unique_words\"] = test_df[\"question_text\"].apply(lambda x: len(set(str(x).split())))","701adbd7":"\ncnt_srs = train_df[\"num_unique_words\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of num_unique_words in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","7f29bf13":"## Number of characters in the text ##\ntrain_df[\"num_chars\"] = train_df[\"question_text\"].apply(lambda x: len(str(x)))\ntest_df[\"num_chars\"] = test_df[\"question_text\"].apply(lambda x: len(str(x)))","07cda29d":"\ncnt_srs = train_df[\"num_chars\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of char in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","790d408d":"## Number of stopwords in the text ##\ntrain_df[\"num_stopwords\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\ntest_df[\"num_stopwords\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))","f85ba234":"\ncnt_srs = train_df[\"num_stopwords\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of stopwords in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","8f0e0662":"## Number of punctuations in the text ##\ntrain_df[\"num_punctuations\"] =train_df['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\ntest_df[\"num_punctuations\"] =test_df['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )","f7099960":"\ncnt_srs = train_df[\"num_punctuations\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of punctuations in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","bf8b294e":"## Number of title case words in the text ##\ntrain_df[\"num_words_upper\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\ntest_df[\"num_words_upper\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))","840df9b0":"\ncnt_srs = train_df[\"num_words_upper\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of words_upper in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","d72b1499":"## Number of title case words in the text ##\ntrain_df[\"num_words_title\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\ntest_df[\"num_words_title\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n","42a8459a":"\ncnt_srs = train_df[\"num_words_title\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of words_title in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","aad723c2":"## Average length of the words in the text ##\ntrain_df[\"mean_word_len\"] = train_df[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ntest_df[\"mean_word_len\"] = test_df[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))","c97d98fb":"\ncnt_srs = train_df[\"mean_word_len\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of mean_word_len in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","b695b758":"features = ['num_words', 'num_unique_words', 'num_chars', \n                'num_stopwords', 'num_punctuations', 'num_words_upper', \n                'num_words_title', 'mean_word_len']","cb3f6fbd":"for i in features:\n    plt.figure(figsize=(8,4))\n    sns.set(style=\"whitegrid\")\n    sns.violinplot(data=train_df[i])\n    plt.show()","0c567624":"def missing_check(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data","90aee9d7":"missing_check(train_df)","3146d8c4":"missing_check(test_df)","12dc7f5a":"from bs4 import BeautifulSoup\ndef strip_html(text):\n    soup = BeautifulSoup(text, \"html.parser\")\n    return soup.get_text()\n","629e8c62":"train_df['question_text'] = train_df['question_text'].apply(strip_html)","11fb39c9":"STOP_WORDS = nltk.corpus.stopwords.words()\n\ndef clean_sentence(val):\n    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n    regex = re.compile('([^\\s\\w]|_)+')\n    sentence = regex.sub('', val).lower()\n    sentence = sentence.split(\" \")\n    \n    for word in list(sentence):\n        if word in STOP_WORDS:\n            sentence.remove(word)  \n            \n    sentence = \" \".join(sentence)\n    return sentence\n\ndef clean_dataframe(data):\n    \"drop nans, then apply 'clean_sentence' function to question1 and 2\"\n    data = data.dropna(how=\"any\")\n    data[\"question_text\"] = data[\"question_text\"].apply(clean_sentence)\n    \n    return data","4e4ef819":"Target Variable Distribution","03221b69":"__Insight:__ 6.1% of the training data are insincere questions and rest of them are sincere.","103cd73d":"#Work_in_Progress"}}