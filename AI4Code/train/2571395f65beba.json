{"cell_type":{"9c2166cc":"code","0c3e608f":"code","98ebde07":"code","bab659c1":"code","2b5f15a5":"code","c2a47e42":"code","50dac344":"code","91d905b6":"code","ba40ce99":"code","c89845db":"code","6b7dd74f":"code","50b6b77e":"code","38869950":"code","033f5330":"code","5bcda3d0":"code","fa570402":"code","40bc73f6":"code","1d4d5582":"code","64c3e5f7":"code","d954c056":"markdown","c5abc7a8":"markdown","969e7299":"markdown","c8a59309":"markdown","80af3d46":"markdown","d489200c":"markdown","60602936":"markdown","d76ccac4":"markdown","417590ae":"markdown","be743382":"markdown","4693d55e":"markdown","7fd6d0b5":"markdown","91ac590d":"markdown","a9291f93":"markdown","6e3c04c0":"markdown","e78c2e62":"markdown"},"source":{"9c2166cc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n%matplotlib inline","0c3e608f":"iris_ds = load_iris()\niris_df = pd.DataFrame(iris_ds.data, columns=iris_ds.feature_names)","98ebde07":"iris_df.shape","bab659c1":"iris_df.head()","2b5f15a5":"iris_df.info()","c2a47e42":"iris_df['petal width (cm)'].hist()","50dac344":"iris_df.describe()","91d905b6":"plt.title(\"Proportion of each species\")\nplt.pie(np.bincount(iris_ds.target), \n        labels=iris_ds.target_names, \n        autopct='%1.1f%%',\n        shadow=True, startangle=90);","ba40ce99":"fig, (ax1, ax2,ax3,ax4) = plt.subplots(1, 4) \nfig.set_size_inches(18, 5)\n\nax1.boxplot(iris_df['sepal length (cm)']);\nax1.set_title('sepal length (cm)');\n\nax2.boxplot(iris_df['sepal width (cm)']);\nax2.set_title('sepal width (cm)');\n\nax3.boxplot(iris_df['petal length (cm)']);\nax3.set_title('petal length (cm)');\n\nax4.boxplot(iris_df['petal width (cm)']);\nax4.set_title('petal width (cm)');","c89845db":"fig, (ax1, ax2,ax3,ax4) = plt.subplots(1, 4) \nfig.set_size_inches(18, 5)\n\nax1.hist(iris_df['sepal length (cm)']);\nax1.set_title('sepal length (cm)');\n\nax2.hist(iris_df['sepal width (cm)']);\nax2.set_title('sepal width (cm)');\n\nax3.hist(iris_df['petal length (cm)']);\nax3.set_title('petal length (cm)');\n\nax4.hist(iris_df['petal width (cm)']);\nax4.set_title('petal width (cm)');","6b7dd74f":"import matplotlib.pyplot as plt\n%matplotlib inline\n# Visualize the data sets\nplt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nfor target, target_name in enumerate(iris_ds.target_names):\n    X_plot = iris_ds.data[iris_ds.target == target]\n    plt.plot(X_plot[:, 0], X_plot[:, 1], linestyle='none', marker='o', label=target_name)\nplt.xlabel(iris_ds.feature_names[0])\nplt.ylabel(iris_ds.feature_names[1])\nplt.axis('equal')\nplt.legend();\n\nplt.subplot(1, 2, 2)\nfor target, target_name in enumerate(iris_ds.target_names):\n    X_plot = iris_ds.data[iris_ds.target == target]\n    plt.plot(X_plot[:, 2], X_plot[:, 3], linestyle='none', marker='o', label=target_name)\nplt.xlabel(iris_ds.feature_names[2])\nplt.ylabel(iris_ds.feature_names[3])\nplt.axis('equal')\nplt.legend();","50b6b77e":"#Parameters\n\ntrain_size = 0.75                  #float or int, default=None\ntest_size= 1- train_size           #float or int, default=None\nrandom_state=None                  #int or RandomState instance\nshuffle=True                       #bool\nstratify=None                      #array-like\n\n#Splitting test and train data\nX_train, X_test, y_train, y_test = train_test_split(iris_ds.data,\n                                                    iris_ds.target,\n                                                   train_size=train_size,\n                                                   test_size=test_size,\n                                                   random_state=random_state,\n                                                   shuffle=shuffle,\n                                                   stratify=stratify)","38869950":"#Parameters \n\ncriterion='gini'                            # {\u201cgini\u201d, \u201centropy\u201d},\nsplitter='best'                             # {\u201cbest\u201d, \u201crandom\u201d}\nmax_depth=None                              # int\nmin_samples_split =2                        # int or float\nmin_samples_leaf=1                          # int or float\nmin_weight_fraction_leaf=0.0                # float\nmax_features=None                           # int, float or {\u201cauto\u201d, \u201csqrt\u201d, \u201clog2\u201d}\nrandom_state=None                           # int, RandomState instance\nmax_leaf_nodes=None                         # int\nmin_impurity_decrease = 0.0                 # float\nclass_weight=None                           # dict, list of dict or \u201cbalanced\u201d\nccp_alpha=0.0                               # non-negative float, default=0.0\n\n#Creating model\nclassifier =  DecisionTreeClassifier(criterion=criterion,\n                                     splitter=splitter,\n                                    max_depth=max_depth,\n                                     min_samples_split=min_samples_split,\n                                    min_samples_leaf=min_samples_leaf,\n                                    max_features = max_features,\n                                    random_state = random_state,\n                                    max_leaf_nodes = max_leaf_nodes,\n                                    min_impurity_decrease  = min_impurity_decrease ,\n                                    class_weight = class_weight,\n                                    ccp_alpha = ccp_alpha)","033f5330":"classifier.fit(X_train,y_train)","5bcda3d0":"y_pred = classifier.predict(X_test)","fa570402":"classifier.score(X_test,y_test)","40bc73f6":"#Parameters\nlabels=[0,1,2]                      #array-like of shape (n_classes)\nsample_weight=None                  #array-like of shape (n_samples,)\nnormalize=None                      #{\u2018true\u2019, \u2018pred\u2019, \u2018all\u2019}\n\nconfusion_matrix(y_pred,y_test,\n                labels=labels,\n                sample_weight=sample_weight,\n                normalize=normalize)","1d4d5582":"#Parameters\nlabels=[0,1,2]                        #[n_labels]\ntarget_names= iris_ds.target_names    #list of strings\nsample_weight=None                    #array-like of shape (n_samples,)\ndigits=2                              #int\noutput_dict= False                    #bool\nzero_division=\"warn\"                  #\u201cwarn\u201d, 0 or 1\n\nprint(classification_report(y_pred,\n                            y_test,\n                            labels=labels,\n                            target_names=target_names,\n                            sample_weight=sample_weight,\n                            digits=digits,\n                            output_dict=output_dict,\n                            zero_division=zero_division))","64c3e5f7":"fig, ax = plt.subplots(figsize=(15, 15)) \n\n#Paramters\ndecision_tree=classifier             #decision tree regressor or classifier\nfilled = True                        #bool, optional (default=False)\nfeature_names=iris_ds.feature_names  #list of strings, optional (default=None)\nclass_names=iris_ds.target_names     #list of strings, bool or None, optional (default=None)\nmax_depth=None                       #int, optional (default=None)\nfontsize=10                          #int, optional (default=None)\nax=ax                                #matplotlib axis, optional (default=None)\nlabel='all'                          #{\u2018all\u2019, \u2018root\u2019, \u2018none\u2019}, optional\nimpurity=True                        #bool, optional \nnode_ids=False                       #bool, optional \nproportion=False                     #bool, optional\nrounded=True                         #bool, optional (default=False)\nprecision=3                          #int, optional\n\nplot_tree(decision_tree=decision_tree,\n          filled=filled,\n          feature_names=feature_names, \n          class_names=class_names,\n          fontsize=fontsize,\n          ax=ax,\n          max_depth=max_depth,\n          label=label,\n          impurity=impurity,\n          node_ids=node_ids,\n          proportion=proportion,\n          rounded=rounded,\n          precision=precision);","d954c056":"### Visualizing decision tree","c5abc7a8":"## Model creation","969e7299":"#### Features","c8a59309":"#### Accuracy ","80af3d46":"#### Train","d489200c":"## Results","60602936":"## Exploratory data analysis","d76ccac4":"### Loading data","417590ae":"#### Prediction","be743382":"#### Model creation","4693d55e":"#### Confusion matrix","7fd6d0b5":"### Visualizing data","91ac590d":"## Importing libraries","a9291f93":"#### Classification report","6e3c04c0":"### Stats","e78c2e62":"#### Test, train data split"}}