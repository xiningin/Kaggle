{"cell_type":{"f3c52914":"code","cda7f70c":"markdown"},"source":{"f3c52914":"import pandas as pd\nimport numpy as np\nimport gc\n\ndf_dtt = pd.read_csv('..\/input\/datathon-belcorp-prueba\/dtt_fvta_cl.csv', index_col=0)\n\ndf_campana = pd.read_csv('..\/input\/datathon-belcorp-prueba\/campana_consultora.csv', index_col=0)\n\ndf_merge = pd.merge(df_dtt, df_campana, left_on = ['idconsultora', 'campana'], right_on= ['IdConsultora', 'campana'], how='left')\n\ndel df_dtt, df_campana\ngc.collect()\n\ndf_consultora = pd.read_csv('..\/input\/datathon-belcorp-prueba\/maestro_consultora.csv', index_col=0)\n\ndf_merge = df_merge.merge(df_consultora, left_on = ['idconsultora'], right_on= ['IdConsultora'], how='left')\n\ndel df_consultora\ngc.collect()\n\ndf_merge.sort_values(by = ['idconsultora', 'campana'], inplace= True)\n\ndf_merge.head()\n\ndf_merge['campana_num'] = (df_merge['campana']\/\/100-2018)*18+(df_merge['campana']%100)\n\nvar_inutil =['codigocanalorigen', 'IdConsultora_x', 'codigofactura', 'IdConsultora_y']\n\ndf_merge.drop(columns=var_inutil, inplace = True)\n\nlist(df_merge)\n\n\ndf_merge['flagcorreovalidad'].count()\n\ndf_merge['flagcorreovalidad'].isnull().count()\n\ndf_merge[['preciocatalogo', 'ahorro', 'descuento', 'realanulmnneto', 'realdevmnneto','realvtamnneto', 'realvtamnfaltneto']]\n\n\n\n## Desde aqu\u00ed\n\n#flags dejar como flags o suma\/total (ratio)\n#categoricas1 necesitan label e\n\n#1. variables que necesitan label encoding\nvar_categoricas1 = ['canalingresoproducto', 'grupooferta', 'geografia', 'estadocivil', 'flagcorreovalidad']\n# flagcorreovalidad -> 1, 0 y NaN\n\n#2. variables que necesitan encoding manual\nvar_categoricas2 = ['palancapersonalizacion', 'segmentacion']\n\n#3. variables numericas\nvar_num = ['descuento', 'ahorro', 'preciocatalogo', 'realanulmnneto', 'realdevmnneto', 'realvtamnneto', \n           'realvtamnfaltneto', 'realvtamncatalogo', 'realvtamnfaltcatalogo', 'cantidadlogueos', 'edad']\n\n#4. flags\nvar_flags = ['flagactiva', 'flagdispositivo', 'flagofertadigital', 'flagsuscripcion', 'flagcelularvalidado']\n\n#5. otras variables\n# 'evaluacion_nuevas' -> 'ratio_evaluacion'\nvar_creadas = ['evaluacion_nuevas2']\n\ndef try_to_encode_eval(string_eval):\n    try:\n        return float(string_eval[-3])\/float(string_eval[-1])\n    except:\n        return 0.5\n\n#5. otras variables\ndf_merge['evaluacion_nuevas2'] = df_merge['evaluacion_nuevas'].apply(lambda x: try_to_encode_eval(x))\ndf_merge['evaluacion_nuevas2'] = np.where(df_merge['evaluacion_nuevas'] == 'C_1d1', 0.5, df_merge['evaluacion_nuevas2'])\n# queda probar si los 'Est' deben tener un valor mayor a 1 o dejarlo en 0.5\ndf_merge['evaluacion_nuevas2'] = np.where(df_merge['evaluacion_nuevas'] == 'Est', 2, df_merge['evaluacion_nuevas2'])\n\ndict_segmentacion ={\n    'Nuevas' : 1,\n    'Nivel2' : 2,\n    'Nivel3' : 3,\n    'Nivel4' : 4,\n    'Nivel5' : 5,\n    'Nivel6' : 6,\n    'Nivel7' : 7,\n    'Tops' : 8\n}\n\ndf_merge['segmentacion2'] = df_merge['segmentacion'].map(dict_segmentacion)\n\ndf_merge['segmentacion2'].value_counts()\n\ndf_merge['palancapersonalizacion2'] = df_merge['palancapersonalizacion'].str.split(' ')[0]\n\ndict_ppersonalizacion = {\n    'App' : 1, \n    'Desktop' : 2,\n    'Mobile' : 3,\n    'Ofertas' : 4,\n    'Showroom' : 5,\n    'Oferta' : 4,\n    'Favoritos' : 5\n}\n\ndf_merge['palancapersonalizacion2'] = df_merge['palancapersonalizacion'].str.split(' ').str[0].map(dict_ppersonalizacion)\n\n\n\n\n\n\n\n\n### Var nuevas sobre poblacion en zonas de chile\n\nzonas_dict = {'11 NORTE GRANDE': 'NORTE_GRANDE' ,                \n'14 SANTIAGO \/ SUR CHICO': 'ZONA_SUR',         \n'15 SUR GRANDE': 'ZONA_SUR',                   \n'12 SANTIAGO - NORTE CHICO': 'NORTE_CHICO',       \n'13 STGO. \/ VI?A DEL MAR \/ VA': 'STGO_VM_VA',   \n'17 SANTIAGO PONIENTE': 'ZONA_PONIENTE',           \n'16 SUR AUSTRAL': 'ZONA_AUSTRAL',                 \n'00 ADMINISTRATIVO': 'OTROS'}\n\ndf_merge['geografia'] = df_merge['geografia'].map(zonas_dict)\n\nsantiago = 7112808\nvalparaiso = 1815902\nbiobio = 1556805\nmaule = 1044950\naraucania = 957224\nhiggins = 914555\nlagos = 828708\ncoquimbo = 757586\nantofagasta = 607534\n\u00f1uble = 480609\nrios = 384837\ntarapaca = 330558\natacama = 286168\narica = 226068\niquique = 196562\nmagallanes = 166533\naysen = 103158\ncopiapo = 175162\nserena = 205635\nrancagua = 225563\ntalca = 203873\nconcepcion = 220746\ntemuco = 221375\nvaldivia = 143207\nmontt = 213119\ncoyhaique = 7290\narenas = 124169\nvi\u00f1a_mar = 326759\ncerrillos = 71906\nmaipu = 521627\nestacion_central = 147041\nquinta_normal = 110026\npudahuel = 230293\nprado_navia = 132622 + 96249\n\nNORTE_GRANDE = arica+iquique+antofagasta\nNORTE_CHICO = copiapo+serena\nZONA_CENTRAL = valparaiso+rancagua+talca+concepcion+santiago\nZONA_SUR = temuco+valdivia+montt\nZONA_AUSTRAL = coyhaique+arenas\nZONA_PONIENTE =  cerrillos+maipu+estacion_central+quinta_normal+pudahuel+prado_navia\nSTGO_VM_VA = santiago+valparaiso+vi\u00f1a_mar\n\npob_dict = {'NORTE_GRANDE': NORTE_GRANDE ,                \n'ZONA_SUR': ZONA_SUR,                            \n'NORTE_CHICO': NORTE_CHICO,\n'STGO_VM_VA': STGO_VM_VA,   \n'ZONA_PONIENTE': ZONA_PONIENTE,           \n'ZONA_AUSTRAL': ZONA_AUSTRAL,                 \n'OTROS': np.nan}\n\ndf_merge['POB_2017'] = df_merge['geografia'].map(pob_dict)\n\n### Rango edad propuesto por ex consultora\n\n#rango = 18-25, 25-35, 35-45, 45+\n\nbins = [18, 25, 35, 45, 100]\nnames = [1, 2, 3, 4]\n\ndf_merge['rango_edad'] = pd.cut(df_merge['edad'], bins=bins, labels=names)\n\ndf_merge.drop(columns='edad', inplace=True)\n\n#df_merge.to_csv('df_merge.csv', index=False)\n\n# Agregar df producto\n\ndf_producto = pd.read_csv('..\/input\/datathon-belcorp-prueba\/maestro_producto.csv', index_col=0)\n\ndf_producto = df_producto[['idproducto', 'codigounidadnegocio', 'codigomarca', 'codigocategoria', 'codigotipo']]\n\ndf_merge = pd.merge(df_merge, df_producto, left_on = 'idproducto', right_on= 'idproducto', how='left')\n\ndel df_producto\ngc.collect()\n\n\n\n\n\n\n\n\n\n\n## Hasta aqu\u00ed\n\ndf_merge['palancapersonalizacion2'].value_counts()\n\ndf_merge['cant_dcto'] = df_merge['descuento']*df_merge['preciocatalogo']\/100\n\ndf_merge['cant_interac'] = 1\n\ndf_merge['canalingresoproducto'].fillna('ND', inplace = True)\n\ndf_merge['canal_WEB'] = np.where(df_merge['canalingresoproducto'] == 'WEB', 1, 0)\ndf_merge['canal_APP'] = np.where(df_merge['canalingresoproducto'] == 'APP', 1, 0)\ndf_merge['canal_ND'] = np.where(df_merge['canalingresoproducto'] == 'ND', 1, 0)\ndf_merge['canal_DD'] = np.where(df_merge['canalingresoproducto'] == 'DD', 1, 0)\ndf_merge['canal_DIG'] = np.where(df_merge['canalingresoproducto'] == 'DIG', 1, 0)\ndf_merge['canal_MIX'] = np.where(df_merge['canalingresoproducto'] == 'MIX', 1, 0)\ndf_merge['canal_OCR'] = np.where(df_merge['canalingresoproducto'] == 'OCR', 1, 0)\n\ndf_merge.dropna(subset = ['segmentacion'], inplace = True)\n\ndf_merge['Flagpasopedido'].fillna(0, inplace = True)\ndf_merge['grupooferta'].fillna('ND', inplace = True)\ndf_merge['flagactiva'].fillna(0, inplace = True)\ndf_merge['flagpedidoanulado'].fillna(0, inplace = True)\ndf_merge['cantidadlogueos'].fillna(0, inplace = True)\ndf_merge['estadocivil'].fillna('Otros', inplace = True)\ndf_merge['flagcorreovalidad'].fillna(0, inplace = True)\ndf_merge['palancapersonalizacion2'].fillna(6.0, inplace = True)\ndf_merge['rango_edad'].fillna(4.0, inplace = True)\ndf_merge['POB_2017'].fillna(df_merge['POB_2017'].mean(), inplace = True)\n\ndf_merge['mean_ahorro'] = df_merge['ahorro']\ndf_merge['mean_preciocatalogo'] = df_merge['preciocatalogo']\ndf_merge['mean_realanulmnneto'] = df_merge['realanulmnneto']\ndf_merge['mean_realdevmnneto'] = df_merge['realdevmnneto']\ndf_merge['mean_realvtamnneto'] = df_merge['realvtamnneto']\ndf_merge['mean_realvtamnfaltneto'] = df_merge['realvtamnfaltneto']\ndf_merge['mean_realvtamncatalogo'] = df_merge['realvtamncatalogo']\ndf_merge['mean_cant_dcto'] = df_merge['cant_dcto']\n\ndf_merge['std_ahorro'] = df_merge['ahorro']\ndf_merge['std_preciocatalogo'] = df_merge['preciocatalogo']\ndf_merge['std_realanulmnneto'] = df_merge['realanulmnneto']\ndf_merge['std_realdevmnneto'] = df_merge['realdevmnneto']\ndf_merge['std_realvtamnneto'] = df_merge['realvtamnneto']\ndf_merge['std_realvtamnfaltneto'] = df_merge['realvtamnfaltneto']\ndf_merge['std_realvtamncatalogo'] = df_merge['realvtamncatalogo']\ndf_merge['std_cant_dcto'] = df_merge['cant_dcto']\n\n\n\n\n\n#df_merge.to_csv('df_merge_29_10.csv', index = False)\n\n#!pip install -q --upgrade pip\n#!pip install -q joblib\n#!pip install -q s3io\n#!pip install -q lightgbm==2.2.2\n#!pip install -q fastparquet\n#!pip install -q pyarrow\n\nimport pandas as pd\nimport numpy as np\nimport gc\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\n\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, auc, accuracy_score, precision_score, recall_score\n\ndef cols_tipos(df, exclude = [], cols_ord = [], Print = False):\n    # Tipo de variable\n    cols = [x for x in df.columns if x not in exclude]\n    cols_cat = [x for x in list(df.select_dtypes(include=['object'])) if x not in exclude]\n    cols_num = [x for x in list(df.select_dtypes(exclude=['object'])) if x not in exclude]\n\n    # Categor\u00edas nominales y ordinales\n    cols_nom = [x for x in cols_cat if x not in cols_ord]\n\n    if Print:\n        print ('Categ\u00f3ricas:\\n', cols_cat)\n        print ('\\nCateg\u00f3ricas Ordinal:\\n', cols_ord)\n        print ('\\nCateg\u00f3ricas Nominal:\\n', cols_cat)\n        print ('\\nNum\u00e9ricas:\\n', cols_num)\n    \n    return cols, cols_cat, cols_num, cols_nom\n\ndef impxgb(valores,variables):\n    dictimp={variables[a]:valores[a] for a in range(0,len(variables)) }\n    xgimp=sorted(dictimp.items(), key=lambda x: x[1],reverse=True)\n\n    return xgimp\n\ndef filter_threshold(probabilities, threshold):\n    return [1 if f >= threshold else 0 for f in probabilities]\n\ndef get_threshold_measures_df(probabilities, observed, steps=[x \/ 100.0 for x in range(0, 100, 5)]):\n    df = pd.DataFrame(columns=['Punto de corte', 'Recall', 'Accuracy', 'Precision'])\n\n    for i in range(len(steps)):\n        estimated_threshold = filter_threshold(probabilities, steps[i])\n        row = [\n            steps[i],\n            recall_score(observed, estimated_threshold),\n            accuracy_score(observed, estimated_threshold),\n            precision_score(observed, estimated_threshold),\n            #auc(observed, estimated_threshold),\n            #auc(observed, estimated_threshold)*2 - 1\n        ]\n        df.loc[i] = row\n\n    return df\n\ndef preparing_data(df):\n    \n    df['rango_edad'] = pd.DataFrame(pd.cut(df['edad'],10))\n    df.drop(columns=['edad', 'idconsultora'], inplace=True)\n    \n    df['campanaultimopedido'] = df['campanaultimopedido'].astype(str)\n    \n    cols, cols_cat, cols_num, cols_nom = cols_tipos(df, exclude = [], cols_ord = [], Print = False)\n    \n    c = {}\n    for l in cols_cat:\n        df[l]=df[l].map(str)\n        df[l]=df[l].fillna('NULL')\n        le = preprocessing.LabelEncoder()\n        le.fit(list(df[l]))\n        df[l]=le.transform(df[l])\n        c[l] = le\n        \n    cols.remove('TARGET_1')\n    \n    return cols, cols_cat, cols_num, cols_nom, c, df\n\ndef read_data(pc, path_file, pkl = False, **kwargs):\n    bucket, key = path_file.split('\/', maxsplit=1)\n    if pkl == True:\n        if pc == 's3':\n            with s3io.open('s3:\/\/{0}\/{1}'.format(bucket, key), mode='r') as s3_file:\n                obj = joblib.load(s3_file)\n        else:\n            obj = joblib.load(s3_file)\n    else:\n        s3_bool = False\n        if pc == 's3':\n            s3_bool = True\n        obj = raex.readCSV(path_file, s3=s3_bool, print_info = False, **kwargs)\n    return obj\n\ndf = df_merge.copy()\n\ndf.head()\n\ndf.shape\n\ndf_unos = df[df['campanaultimopedido']==201907]\n\ndf_unos.shape\n\ndf_zeros = df[df['campanaultimopedido']<201907]\n\ndf_zeros.shape\n\ndf['codigocombinadoproducto'] = df['codigocombinadoproducto'] = df['codigomarca'].astype(str) + df['codigocategoria'].astype(str) + df['codigotipo'].astype(str)\n\ndf[['codigomarca', 'codigocategoria', 'codigotipo']] = df[['codigomarca', 'codigocategoria', 'codigotipo']].astype(str)\n\nf = {'canalingresoproducto': lambda x: pd.Series.mode(x)[0], #pd.Series.mode,\n     'grupooferta': lambda x: pd.Series.mode(x)[0], #pd.Series.mode,\n     'geografia': 'first',\n     'estadocivil': 'last',\n     'flagcorreovalidad': 'max',\n     'palancapersonalizacion2': lambda x: pd.Series.mode(x)[0], #pd.Series.mode,\n     'segmentacion2': lambda x: pd.Series.mode(x)[0], #pd.Series.mode,\n     'descuento': 'mean', #sum\n     \n     'campanaultimopedido':'first',\n     'campanaingreso':'first',\n     'campanaprimerpedido':'first',\n     'codigomarca': lambda x: pd.Series.mode(x)[0],\n     'codigocategoria': lambda x: pd.Series.mode(x)[0],\n     'codigotipo': lambda x: pd.Series.mode(x)[0],     \n     \n     'ahorro': 'sum',\n     'preciocatalogo': 'sum',\n     'realanulmnneto': 'sum',\n     'realdevmnneto': 'sum',\n     'realvtamnneto': 'sum',\n     'realvtamnfaltneto': 'sum',\n     'realvtamncatalogo': 'sum',\n     'cant_dcto': 'sum',\n     \n     'mean_ahorro': 'mean',\n     'mean_preciocatalogo': 'mean',\n     'mean_realanulmnneto': 'mean',\n     'mean_realdevmnneto': 'mean',\n     'mean_realvtamnneto': 'mean',\n     'mean_realvtamnfaltneto': 'mean',\n     'mean_realvtamncatalogo': 'mean',\n     'mean_cant_dcto': 'mean',\n     \n     'std_ahorro': 'std',\n     'std_preciocatalogo': 'std',\n     'std_realanulmnneto': 'std',\n     'std_realdevmnneto': 'std',\n     'std_realvtamnneto': 'std',\n     'std_realvtamnfaltneto': 'std',\n     'std_realvtamncatalogo': 'std',\n     'std_cant_dcto': 'std',\n     \n     'cantidadlogueos': 'sum',\n     \n     'rango_edad': 'last',\n     'flagactiva': 'max',\n     'flagdispositivo': 'max',\n     'flagofertadigital': 'max',\n     'flagsuscripcion': 'max',\n     'flagcelularvalidado': 'max',\n     'evaluacion_nuevas2': 'last',\n     \n     'cant_interac': 'sum',\n     'canal_WEB': 'sum',\n     'canal_APP': 'sum',\n     'canal_ND': 'sum',\n     'canal_DD': 'sum',\n     'canal_DIG': 'sum',\n     'canal_MIX': 'sum',\n     'canal_OCR': 'sum',\n         \n\n     'POB_2017': 'mean',\n     'codigounidadnegocio':lambda x: pd.Series.mode(x)[0], #pd.Series.mode,\n     'codigocombinadoproducto': lambda x: pd.Series.mode(x)[0], #pd.Series.mode, #moda doble\n     'Flagpasopedido':'max'}\n\ndf_grouped = df.groupby(by='idconsultora', as_index=False).agg(f)\n\ndf_grouped['std_ahorro'].fillna(0, inplace = True)\ndf_grouped['std_preciocatalogo'].fillna(0, inplace = True)\ndf_grouped['std_realanulmnneto'].fillna(0, inplace = True)\ndf_grouped['std_realdevmnneto'].fillna(0, inplace = True)\ndf_grouped['std_realvtamnneto'].fillna(0, inplace = True)\ndf_grouped['std_realvtamnfaltneto'].fillna(0, inplace = True)\ndf_grouped['std_realvtamncatalogo'].fillna(0, inplace = True)\ndf_grouped['std_cant_dcto'].fillna(0, inplace = True)\n\ndf_pivot_sum = pd.pivot_table(df, index= 'idconsultora',columns= \"campana\", values= \"Flagpasopedido\", aggfunc=\"sum\").reset_index()\n\ndf_pivot_sum.fillna(0, inplace=True)\n\ndf_pivot = pd.pivot_table(df, index= 'idconsultora',columns= \"campana\", values= \"Flagpasopedido\", aggfunc=\"max\").reset_index()\n\ndf_pivot.fillna(0, inplace=True)\n\ndf_pivot['ultimas_seis_campanas_pedidas'] = df_pivot[[\n 201901,\n 201902,\n 201903,\n 201904,\n 201905,\n 201906]].sum(axis=1)\n\ndf_pivot['antiguas_campa\u00f1as_pedidas'] = df_pivot[[\n 201807,\n 201808,\n 201809,\n 201810,\n 201811,\n 201812]].sum(axis=1)\n\ndf_pivot_sum['cantidad_campanas_pedidas'] = df_pivot_sum[[201807,\n 201808,\n 201809,\n 201810,\n 201811,\n 201812,\n 201813,\n 201814,\n 201815,\n 201816,\n 201817,\n 201818,\n 201901,\n 201902,\n 201903,\n 201904,\n 201905,\n 201906]].sum(axis=1)\n\ndf_pivot_sum.rename(columns={\n    201807:'201807_sum',\n 201808:'201808_sum',\n 201809:'201809_sum',\n 201810:'201810_sum',\n 201811:'201811_sum',\n 201812:'201812_sum',\n 201813:'201813_sum',\n 201814:'201814_sum',\n 201815:'201815_sum',\n 201816:'201816_sum',\n 201817:'201817_sum',\n 201818:'201816_sum',\n 201901:'201901_sum',\n 201902:'201902_sum',\n 201903:'201903_sum',\n 201904:'201904_sum',\n 201905:'201905_sum',\n 201906:'201906_sum',\n    'cantidad_campanas_pedidas': 'cantidad_campanas_pedidas_sum',\n    'ultimas_seis_campanas_pedidas': 'ultimas_seis_campanas_pedidas_sum',\n    'antiguas_campa\u00f1as_pedidas': 'antiguas_campa\u00f1as_pedidas_sum'\n}, inplace=True)\n\ndf_grouped = pd.merge(df_grouped, df_pivot_sum, how='left', left_on='idconsultora', right_on='idconsultora')\n\ndf_grouped = pd.merge(df_grouped, df_pivot, how='left', left_on='idconsultora', right_on='idconsultora')\n\ndf_grouped.shape\n\ndf_grouped[['campanaingreso', 'campanaultimopedido', 'campanaprimerpedido', 'rango_edad']] = df_grouped[['campanaingreso', 'campanaultimopedido', 'campanaprimerpedido', 'rango_edad']].astype(str)\n\ncols, cols_cat, cols_num, cols_nom = cols_tipos(df_grouped, exclude = [], cols_ord = [], Print = False)\n\nc = {}\nfor l in cols_cat:\n    df_grouped[l]=df_grouped[l].map(str)\n    df_grouped[l]=df_grouped[l].fillna('ND')\n    le = preprocessing.LabelEncoder()\n    le.fit(list(df_grouped[l]))\n    df_grouped[l]=le.transform(df_grouped[l])\n    c[l] = le\n\ntmp = df[['idconsultora', 'campanaultimopedido']]\n\ntmp = tmp.groupby(by='idconsultora', as_index=False).agg({'campanaultimopedido':'first'})\n\ndf_grouped = pd.merge(df_grouped, tmp, how='left', left_on='idconsultora', right_on='idconsultora')\n\ndf_model = df_grouped[df_grouped['campanaultimopedido_y']<=201907.0]\n\ndf_predict = df_grouped[df_grouped['campanaultimopedido_y']>201907.0]\n\ndf_model['TARGET'] = np.where(df_model['campanaultimopedido_y']==201907.0, 1, 0)\n\ndf_model.head()\n\ndf_grouped.drop(columns='campanaultimopedido_y', inplace=True)\ndf_model.drop(columns='campanaultimopedido_y', inplace=True)\ndf_predict.drop(columns='campanaultimopedido_y', inplace=True)\n\nround((df_model['TARGET'].value_counts() \/ df_model.shape[0])*100, 2)\n\ndf_grouped.shape\n\n# Juntar vars extras\n\ndf_model = pd.merge(df_model, df_pivot_sum, how='left', left_on='idconsultora', right_on='idconsultora')\n\ndf_model = pd.merge(df_model, df_pivot, how='left', left_on='idconsultora', right_on='idconsultora')\n\ndf_model.shape\n\ndf_predict = pd.merge(df_predict, df_pivot_sum, how='left', left_on='idconsultora', right_on='idconsultora')\n\ndf_predict = pd.merge(df_predict, df_pivot, how='left', left_on='idconsultora', right_on='idconsultora')\n\ndf_predict.shape\n\n\n\n\n\n# LabelEncoding\n\n# MODELO\n\ndf_model['rand'] = np.random.RandomState(24).randn(*df_model['TARGET'].shape)\ndf_model = df_model.sort_values(by='rand')\n\ndf_model.reset_index(drop=True, inplace=True)\n\ndf_model.head()\n\ndf_train = df_model[df_model['rand']<0.7]\ndf_test = df_model[(df_model['rand']>=0.7)]\n\ncols.remove('campanaultimopedido')\n\ncols_cat.remove('campanaultimopedido')\n\ncols.remove('idconsultora')\n\n# Aqu\u00ed cambio para prospectar con toda la data\ndf_train = df_model\n\nd={}\ne={}\nmylist = list(range(1,6))\n\nX = df_train[cols].values\ny = df_train['TARGET'].ravel()\n\nindex_categorical=[cols.index(x) for x in cols_cat]\n\nindex_categorical\n\nfor k in mylist:\n    X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.20, random_state=k*64)\n\n    train_set = lgb.Dataset(X_train, y_train)\n    validation_sets = lgb.Dataset(X_validation, y_validation, reference=train_set)\n\n    params = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': { 'AUC' },\n        'num_leaves': 20, \n        'max_depth': 4, \n        'min_data_in_leaf': 200, \n        'feature_fraction': 0.5,\n        'bagging_freq': 1,\n        'bagging_fraction': 0.9,\n        'verbose': 1,\n        'is_unbalance':True\n    }\n   \n    model = lgb.train(\n        params,\n        train_set,\n        num_boost_round=2000,\n        valid_sets=validation_sets,\n        early_stopping_rounds=100,\n        categorical_feature=index_categorical\n        )\n    \n    d[k]=model\n    test=model.predict(X_validation, num_iteration=model.best_iteration)\n    e[k]=roc_auc_score(y_validation, test)\n\na = []\nfor k in mylist:\n    a.append(e[k])\nb = np.array((np.mean(a),np.std(a)))\nprint(b)\n\nmax(a), min(a)\n\nd2 = {k:v for k,v in d.items() if a[k-1]>0}\n\np = []\nfor k in d2.keys():\n    df_test['PROB_{}'.format(k)]=d2[k].predict(df_test[cols], num_iteration=d2[k].best_iteration)\n    p.append('PROB_{}'.format(k))\ndf_test['PROB'] = df_test[p].mean(axis=1)\nprint(roc_auc_score(df_test['TARGET'],df_test['PROB']))\n\ni = {}\nx = []\nmylist = list(range(1,6))\nfor k in mylist:\n    i[k] = d[k].feature_importance(importance_type=\"gain\")\n    x.append(i[k]) \ndx = pd.DataFrame(x)\nixg=impxgb(dx.mean(axis=0),cols)\nixg\n\n\np = []\nfor k in d2.keys():\n    df_predict['PROB_{}'.format(k)]=d2[k].predict(df_predict[cols], num_iteration=d2[k].best_iteration)\n    p.append('PROB_{}'.format(k))\ndf_predict['flagpasopedido'] = df_predict[p].mean(axis=1)\n\ntmp1 = df_predict[['idconsultora', 'flagpasopedido']]\n\ndf_submit_file = pd.read_csv('Data\/predict_submission.csv')\n\ntmp2 = pd.merge(df_submit_file, tmp1, how='left', left_on='idconsultora', right_on='idconsultora')\n\ntmp2.head()\n\ntmp2['aa']= np.where(tmp2['flagpasopedido_y']!=np.nan, tmp2['flagpasopedido_y'], tmp2['flagpasopedido_x'])\n\naaa = df_model[['TARGET', 'idconsultora']]\n\ntmp2 = pd.merge(tmp2, aaa, how='left', left_on='idconsultora', right_on='idconsultora')\n\ntmp2.head()\n\ntmp2.isna().sum()\n\ntmp2['TARGET']>=0\n\ntmp2['flagpasopedido']= np.where(tmp2['TARGET']>=0, tmp2['TARGET'], tmp2['aa'])\n\nfinal = tmp2[['idconsultora', 'flagpasopedido']]\n\nfinal.isna().sum()\n\nfinal.fillna(0, inplace=True)\n\nfinal.to_csv('finalcano.csv', index=False)\n\nfinal.shape","cda7f70c":"# DISCULPEN EL DESORDEN GENTE, NO TENIAMOS TIEMPO :P"}}