{"cell_type":{"443bf164":"code","939be35d":"code","fb7d313f":"code","e2afce19":"code","d177a0dc":"code","9b17b585":"code","131ea7f5":"code","c916e683":"code","8f47da99":"code","b145611f":"code","0573d63a":"code","0526c475":"code","d2f15b8e":"code","1a8bb390":"code","d278d4cb":"code","de3f9480":"code","2e3b6eaf":"code","1bc111e0":"code","22d8ab94":"code","ff49131b":"code","769d96c8":"code","6f6d96c6":"code","998d33d6":"code","446f1f78":"code","8a2da1be":"code","cc1b67f9":"code","26e80bae":"code","63f97fde":"code","740c1fa7":"code","b3f35126":"code","3c66443f":"code","ca58c011":"code","00e63785":"code","a70a31e4":"code","bc3eb298":"code","f8a6fc7b":"code","62b4420b":"code","60cb74d6":"code","f9490493":"code","26f1cad6":"code","5c6d87a1":"code","388accaa":"markdown","00272eb9":"markdown","367a1e86":"markdown"},"source":{"443bf164":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport bz2\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","939be35d":"trainfile = bz2.BZ2File('..\/input\/train.ft.txt.bz2','r')\nlines = trainfile.readlines()","fb7d313f":"lines[1]","e2afce19":"docSentimentList=[]\ndef getDocumentSentimentList(docs,splitStr='__label__'):\n    for i in range(len(docs)):\n        #print('Processing doc ',i,' of ',len(docs))\n        text=str(lines[i])\n        #print(text)\n        splitText=text.split(splitStr)\n        secHalf=splitText[1]\n        text=secHalf[2:len(secHalf)-1]\n        sentiment=secHalf[0]\n        #print('First half:',secHalf[0],'\\nsecond half:',secHalf[2:len(secHalf)-1])\n        docSentimentList.append([text,sentiment])\n    print('Done!!')\n    return docSentimentList","d177a0dc":"docSentimentList=getDocumentSentimentList(lines[:1000000],splitStr='__label__')","9b17b585":"train_df = pd.DataFrame(docSentimentList,columns=['Text','Sentiment'])\ntrain_df.head()","131ea7f5":"train_df['Sentiment'][train_df['Sentiment']=='1'] = 0\ntrain_df['Sentiment'][train_df['Sentiment']=='2'] = 1","c916e683":"train_df['Sentiment'].value_counts()","8f47da99":"train_df['word_count'] = train_df['Text'].str.lower().str.split().apply(len)\ntrain_df.head()","b145611f":"import string \ndef remove_punc(s):\n    table = str.maketrans({key: None for key in string.punctuation})\n    return s.translate(table)","0573d63a":"train_df['Text'] = train_df['Text'].apply(remove_punc)\ntrain_df.shape","0526c475":"train_df.head()","d2f15b8e":"len(train_df['word_count'][train_df['word_count']<=25])","1a8bb390":"train_df1 = train_df[:][train_df['word_count']<=25]\ntrain_df1.head()","d278d4cb":"train_df1.head()","de3f9480":"train_df1['Sentiment'].value_counts()","2e3b6eaf":"from sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import CountVectorizer\nst_wd = text.ENGLISH_STOP_WORDS\nc_vector = CountVectorizer(stop_words = st_wd,min_df=.0001,lowercase=1)\nc_vector.fit(train_df1['Text'].values)","1bc111e0":"word_list = list(c_vector.vocabulary_.keys())\nstop_words = list(c_vector.stop_words) ","22d8ab94":"len(stop_words),len(word_list)","ff49131b":"def remove_words(raw_sen,stop_words):\n    sen = [w for w in raw_sen if w not in stop_words]\n    return sen","769d96c8":"def reviewEdit(raw_sen_list,stop_words):\n    sen_list = []\n    for i in range(len(raw_sen_list)):\n        raw_sen = raw_sen_list[i].split()\n        sen_list.append(remove_words(raw_sen,stop_words))\n    return sen_list","6f6d96c6":"sen_list = reviewEdit(list(train_df1['Text']),stop_words)","998d33d6":"from gensim.models import word2vec\nwv_model = word2vec.Word2Vec(sen_list,size=100)","446f1f78":"wv_model.wv.syn0.shape","8a2da1be":"wv_model.wv.most_similar(\"car\")","cc1b67f9":"def fun(sen_list,wv_model):\n    word_set = set(wv_model.wv.index2word)\n    X = np.zeros([len(sen_list),25,100])\n    c = 0\n    for sen in sen_list:\n        nw=24\n        for w in list(reversed(sen)):\n            if w in word_set:\n                X[c,nw] = wv_model[w]\n                nw=nw-1\n        c=c+1\n    return X","26e80bae":"X = fun(sen_list,wv_model)","63f97fde":"from sklearn.model_selection import train_test_split\ny = train_df1['Sentiment'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)","740c1fa7":"X_train.shape","b3f35126":"import keras.backend as K\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense, Dropout, Activation,LSTM, SimpleRNN ,GRU , Bidirectional,Input ,Concatenate, Multiply,Lambda,Reshape\ninput_st  = Input(shape=(25,100))\nlstm1 = Bidirectional(GRU(200,input_shape=(25,100),activation='relu',return_sequences=True),merge_mode='mul')(input_st)\nlstm2 = Bidirectional(GRU(1,input_shape=(25,100),activation='relu',return_sequences=True),merge_mode='mul')(lstm1)\nprint(lstm1.shape,' ',lstm2.shape)\nlstm2 = Reshape((-1,))(lstm2)\nlstm2 = Activation('sigmoid')(lstm2)\nlstm2 = Reshape((-1,1))(lstm2)\nmult = Multiply()([lstm1,lstm2])\n\nadd = Lambda(lambda x: K.sum(x,axis=1))(mult)\ndense = Dense(100,activation='relu')(add)\noutput = Dense(1,activation='sigmoid')(dense)\n\nmodel = Model(inputs=input_st, outputs=output)\nprint(model.summary())","3c66443f":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhist = model.fit(X_train,y_train,validation_split=0.1,\n          epochs=10, batch_size=512)","ca58c011":"model.evaluate(X_test, y_test, batch_size=64)","00e63785":"prob_test = model.predict(X_test).reshape((-1,))\npred_test = np.array([1 if y>0.5 else 0 for y in prob_test])\ny_test = y_test.astype('int')\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred_test))","a70a31e4":"model.evaluate(X_train, y_train, batch_size=1024)","bc3eb298":"from keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints\n\n\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a \/= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","f8a6fc7b":"import keras.backend as K\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense, Dropout, Activation,LSTM, SimpleRNN ,GRU , Bidirectional,Input ,Concatenate, Multiply,Lambda,Reshape,Conv2D,Conv1D\ninput_st  = Input(shape=(25,100))\nlstm1 = Bidirectional(GRU(200,input_shape=(25,100),activation='relu',return_sequences=True),merge_mode='mul')(input_st)\nlstm2 = Reshape((25,200,1))(lstm1)\natten = Conv2D(1,kernel_size=(25,1),activation='relu',use_bias=True)(lstm2)\n##atten = Attention(25)(lstm1)\nprint(lstm1.shape,' ',atten.shape)\natten = Reshape((-1,))(atten)\n\ndense = Dense(100,activation='relu')(atten)\noutput = Dense(1,activation='sigmoid')(dense)\n\nmodel = Model(inputs=input_st, outputs=output)\nprint(model.summary())","62b4420b":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhist = model.fit(X_train,y_train,validation_split=0.1,\n          epochs=10, batch_size=512)","60cb74d6":"model.evaluate(X_test, y_test, batch_size=64)","f9490493":"model.evaluate(X_train, y_train, batch_size=1024)","26f1cad6":"prob_test = model.predict(X_test).reshape((-1,))\npred_test = np.array([1 if y>0.5 else 0 for y in prob_test])\ny_test = y_test.astype('int')\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred_test))","5c6d87a1":"pred_test.shape,y_test.shape","388accaa":"## **Text Preprocessing**##","00272eb9":"## **FastText File Reading** ##","367a1e86":" ## **Keras NN Model** ##"}}