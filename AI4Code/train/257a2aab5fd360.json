{"cell_type":{"a037b685":"code","ce945b78":"code","2b5a2b30":"code","88b1093f":"code","72504460":"code","1be13e91":"code","7a8089e4":"code","04da7572":"code","182ed6b9":"code","24b910f7":"code","86ac7661":"code","4b86902e":"code","6f411ab4":"code","419c989d":"code","2f65e904":"code","7df6e493":"code","316304f2":"code","f95f7167":"markdown","6c247923":"markdown","924a5cbe":"markdown","6f1919a1":"markdown","d45f2c60":"markdown","66d41524":"markdown","9281b49b":"markdown","4224f916":"markdown","641fa639":"markdown","d3bc5dd1":"markdown","e8d667aa":"markdown","203a3d5c":"markdown"},"source":{"a037b685":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom keras.models import load_model #e\u011fitimi saklamak\nfrom keras.callbacks import ReduceLROnPlateau  #e\u011fitimi tekrar geri \u00e7a\u011f\u0131rmak i\u00e7in kullan\u0131l\u0131r. \n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ce945b78":"df_train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\n","2b5a2b30":"df_train.tail()","88b1093f":"x_train = df_train.drop(columns=['label'],axis = 1)\n","72504460":"y_train = df_train[\"label\"]","1be13e91":"plt.figure(figsize=(15,7))\ng = sns.countplot(y_train, palette=\"icefire\")\nplt.title(\"Number of digit classes\")\ny_train.value_counts()","7a8089e4":"\nfrom PIL import Image\n\n# herhangi bir say\u0131y\u0131 yazd\u0131ran kod\nimg = x_train.iloc[0].as_matrix()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(df_train.iloc[0,0])\nplt.axis(\"off\")\nplt.show()\n\n# herhangi bir say\u0131y\u0131 yazd\u0131ran kod\nimg = x_train.iloc[8].as_matrix()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(df_train.iloc[8,0])\nplt.axis(\"off\")\nplt.show()","04da7572":"\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n\ny_train = to_categorical(df_train[\"label\"],num_classes = 10)\n","182ed6b9":"y_train","24b910f7":"x_train = x_train \/ 255.0\nprint(\"x_train shape: \",x_train.shape)\n","86ac7661":"x_train = x_train.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",x_train.shape)\n","4b86902e":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.1, random_state=2)\nprint(\"x_train shape\",x_train.shape)\nprint(\"x_test shape\",x_test.shape)\nprint(\"y_train shape\",y_train.shape)\nprint(\"y_test shape\",y_test.shape)","6f411ab4":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\ninput_shape = (28,28,1)\nnum_classes = 10\n\nmodel = Sequential()\nmodel.add(Conv2D(16, kernel_size = (3,3), activation = \"relu\", padding = \"Same\", input_shape = input_shape))\nmodel.add(Conv2D(16, kernel_size = (3,3), activation = \"relu\", padding = \"Same\"))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(32, kernel_size = (2,2), activation = \"relu\", padding = \"Same\"))\nmodel.add(Conv2D(32, kernel_size = (2,2), activation = \"relu\", padding = \"Same\"))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes,activation=\"softmax\"))\nmodel.summary()\n\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n\nepochs = 100\nbatch_size = 1000","419c989d":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.5,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(x_train)","2f65e904":"history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\nepochs = epochs, validation_data = (x_test,y_test), steps_per_epoch=x_train.shape[0] \/\/ batch_size)","7df6e493":"plt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","316304f2":"from sklearn.metrics import confusion_matrix\n\n\n# Predict the values from the validation dataset\ny_pred = model.predict(x_test)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_test,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","f95f7167":"**resmi 784 28'in karesi oldu\u011fu i\u00e7in x_train i\u00e7indeki t\u00fcm veriyi kareye \u00e7eviriyorum  28*28*1 \u015feklinde olmak zorunda **","6c247923":"**k\u00fct\u00fcphanelerimizi y\u00fckl\u00fcyoruz**","924a5cbe":"ba\u015far\u0131m\u0131z\u0131n \u00f6lc\u00fcs\u00fcn\u00fc test etti\u011fimiz k\u0131s\u0131m","6f1919a1":"**Yukar\u0131da elde etti\u011fimiz \u00e7\u0131kt\u0131, train.csv dosyas\u0131n\u0131n direk adresini verdi\u011fi i\u00e7in \u00f6nemli !\nPhytonda bir dataframe olu\u015fturmak i\u00e7in bu adresi kullan\u0131ca\u011f\u0131z.**","d45f2c60":"**ikinci \u00f6nemli k\u0131s\u0131mda s\u0131ral\u0131 yap\u0131 dedi\u011fimiz bu k\u0131s\u0131m **","66d41524":"**x_train ve y_train dataframelerini olu\u015fturdu\u011funuzda bu kes yap\u0131\u015ft\u0131r olarak \u00e7al\u0131\u015fabilecek haz\u0131r visulation kodlar\u0131ndan ikisi *her bir say\u0131ya ait resim say\u0131s\u0131***","9281b49b":"**datagen algoritmas\u0131 ile elimizdeki datay\u0131 farkl\u0131 \u0131\u015f\u0131k alt\u0131nda yada \u00e7e\u015fitli \u015fartlarda yapay olarak \u00fcretebiliyor ve bunu train dataya ekliyoruz.**","4224f916":"** matrislerde i\u015flen yap\u0131labilmesi i\u00e7in y_train dataframini onluk say\u0131 sisteminden  binary sistemine \u00e7evirmek zorunday\u0131z.**","641fa639":"**yukar\u0131da g\u00f6rd\u00fc\u011f\u00fcn\u00fcz gibi dataframin son 5 sat\u0131r\u0131n\u0131 g\u00f6r\u00fcnt\u00fcledim.\nbunun sebebi datam\u0131z\u0131n \u015fekil ve say\u0131s\u0131n\u0131 bilmek**","d3bc5dd1":"**\u015eimdi cnn'de en \u00f6nemli k\u0131s\u0131m olan  x_train ve y_train dataframelerini olu\u015fturmaya geldi...**","e8d667aa":"bu kod sayesinde x_train datam\u0131z\u0131 sorunsuz bir \u015fekilde x_test  datas\u0131na oran\u0131 belirterek b\u00f6lebiliyoruz. ","203a3d5c":"Normalle\u015ftirme yap\u0131yoruz  pikseller RGB den olu\u015ftu\u011fu i\u00e7in resimde standart bir normalle\u015ftirme kodu "}}