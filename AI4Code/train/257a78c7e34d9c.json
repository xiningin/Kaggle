{"cell_type":{"dc394331":"code","4942c066":"code","97f53928":"code","2a920e0b":"code","d74fe155":"code","9122fd5a":"code","36a7a983":"code","6a4bff44":"code","94705647":"code","095bc070":"code","83318ab1":"code","196b1628":"code","4a3519d7":"code","003e7e9f":"code","ea5cca5d":"code","ffe7b56e":"code","7da1d74f":"code","68d7d8af":"markdown","b4a788c0":"markdown","fe88b0c2":"markdown","1357304a":"markdown","af7ac881":"markdown","e04f157b":"markdown","0cf6306a":"markdown","3e51b1b3":"markdown","cfd2dc61":"markdown","96e8a0c3":"markdown","d1acd125":"markdown","eb8efa05":"markdown","02567673":"markdown","f7584750":"markdown","cf95c9d6":"markdown"},"source":{"dc394331":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #for graphing\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import export_graphviz  \nfrom sklearn.tree import DecisionTreeRegressor  \nfrom sklearn import tree\nfrom statistics import mode,median,mean\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import preprocessing\nfrom scipy.special import inv_boxcox\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\nimport re\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.datasets import make_regression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import ensemble\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import expit\nfrom sklearn.decomposition import PCA\nimport xgboost as xgb\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4942c066":"def subdivision_dict(df):\n    sub_df = pd.DataFrame()\n    sub_df['sub'] = df['Subdivision']\n    sub_df['sale_price'] = df['SalePrice']\n    sub_df['sale_price'] = sub_df['sale_price'].mask(sub_df['sale_price']>=1500000,1500000)\n    sub_df = sub_df.groupby(['sub'], as_index = False).mean()\n    sub_df['sub_labels'] = pd.qcut(sub_df['sale_price'], 11,\n        labels = [1,2,3,4,5,6,7,8,9,10,11])\n    sub_dict = dict(zip(sub_df['sub'],sub_df['sub_labels']))\n    return sub_dict","97f53928":"def categorize_subdivision(lst):\n    mean_dict = subdivision_dict(pd.read_csv(\"\/kaggle\/input\/wcob-spring-2021\/bc_train_0203.csv\"))\n    new_lst = []\n    for each in lst:\n        new_lst.append(mean_dict.get(each,6))\n    return new_lst  ","2a920e0b":"def score_model2(test_file, reg_model2, filename):\n    a2,b2 = prep_data(pd.read_csv(test_file))\n    score2 = xgb.DMatrix(a2, label=None)\n    answers2 = reg_model2.predict(score2)\n    answers2 = inv_boxcox(answers2,.41)\n    answers = pd.DataFrame(data={'parcel_id':list(a2.parcel_id),'SalePrice2':answers2})\n    answers['SalePrice'] = answers['SalePrice2']\n    answers[['parcel_id','SalePrice']].to_csv(f\"{filename}.csv\",index = False)\n    print(f\"{filename} has been created!\")","d74fe155":"def results_graph():\n    mapping = pd.DataFrame({'y_test':y_test,'y_pred':ypred})\n    mapping.sort_values('y_test', axis = 0,inplace = True,ascending = False)\n    mapping.reset_index(drop=True,inplace = True)\n    plt.figure(figsize=(20, 6))\n    Prediction = plt.scatter(mapping.y_pred,list(mapping.index), label = 'Prediction')\n    Actual = plt.scatter(mapping.y_test,list(mapping.index), label = 'Actual')\n    #plt.scatter(X_train, y_train, c=\"b\")\n    #plt.xlim([1000000, 5671])\n    plt.title(\"XGBoost Results\", fontsize = 20)\n    plt.xlabel(\"SalePrice (Millions)\")\n    #plt.yticks([])\n    plt.ylabel(\"Parcels\")\n    plt.legend((Actual, Prediction),\n               ('Actual SalePrice','Predicted SalePrice'),\n               scatterpoints=1,\n               loc='upper right',\n               ncol=1,\n               fontsize=12)\n    plt.show()","9122fd5a":"def build_categoricals(df):\n    cat_df = pd.DataFrame()\n    # create subdivisions updated to interval for tree\n    cat_df['subdivision_cat'] = categorize_subdivision(df['Subdivision'])\n    \n    # create year built as category changed to interval for tree\n    cat_df['year_built'] = df['Year Built'].replace('Year Built Not Available',0)\n    cat_df['year_built'] = cat_df['year_built'].fillna(0)\n    cat_df['year_built'] = cat_df.year_built.astype('int')\n    cat_df['year_built'] = [0 if len(str(y)) < 4 else y for y in cat_df['year_built']]\n    #cat_df['year_built'] = pd.cut(cat_df['year_built'],bins = [0,1,1899,1949,1959,1969,1979,1989,1999,2009,2014,2018,2030],labels = [0,1,2,3,4,5,6,7,8,9,10,11])                                                                                                                \n    #cat_df['year_built'] = cat_df['year_built'].astype('category')\n    \n    # create Construction Type as Category 'Construction Type',\n    cat_df['construction_type'] = df['Construction Type'].fillna('no_const_type')\n    cat_df['construction_type'] = cat_df['construction_type'].replace({'no_const_type':0,'A-Frame Pine':1,'Underground':2,\n                                                                       'Combo Brick Frame':4, 'Low Frame':2,'Std Frame':3, 'Masonry':5})\n    \n    # create 'Roof Type',\n    cat_df['roof_type'] = df['Roof Type'].replace('Unkown','mystery_roof')\n    cat_df['roof_type'] =  cat_df['roof_type'].replace({'Asphalt':4,\n                                                        'Fiberglass':6,\n                                                        'Galvalume':5,\n                                                        'Roll Cover':3,\n                                                        'Shakes':2,\n                                                        'Tile':7,\n                                                        'Wood Shingles':1,\n                                                        'mystery_roof':0}) \n        \n    # create 'Fireplace'\n    cat_df['fireplace'] = df['Fireplace'].str.slice(start = 0, stop = 1)\n    cat_df['fireplace'] = cat_df['fireplace'].replace(\" \", \"0\")\n    cat_df['fireplace'] = cat_df['fireplace'].astype(\"int\")\n    #cat_df['fireplace1'] = df['Fireplace'].str.extract(r\"(\\bAverage\\b|\\bGood\\b|\\bFair\\b)\")\n    #cat_df['fireplace1'] = cat_df['fireplace1'].fillna(\"Average\")\n    #cat_df['fireplace'] = cat_df['fireplace'].str.cat(others = cat_df['fireplace1'], sep = \"_\")\n    #cat_df['fireplace'] = cat_df['fireplace'].str.cat(others = ['_fireplaces'] * len(cat_df['fireplace']))\n    #cat_df['fireplace'] = cat_df['fireplace'].astype('category')   \n    \n    # create 'Foundation Type'\n    cat_df['foundation_type'] = df['Foundation Type'].replace('Unkown','mystery_foundation')\n    cat_df['foundation_type'] = cat_df['foundation_type'].replace({'Closed Piers':2, 'Open Piers':1, 'Slab':3, 'mystery_foundation':0,'Elevated Slab':3, 'Slab On Grade':3 })\n    \n    # create 'Floor Type'\n    #cat_df['floor_type'] = df['Floor Type'].replace('Unkown','mystery_floor')\n    #cat_df['floor_type'] = cat_df['floor_type'].astype('category')\n    \n    # create 'City' removed, multicolinearity\n    #cat_df['city'] = df['City'].fillna('ROGERS')\n    #cat_df['city'] = cat_df['city'].astype('category')\n    \n    #cleanup Total Acres - we decided to use both sequential variables and one hot categories \n    cat_df['tot_acres'] = df['Total Acres'].fillna(0)\n    #cat_df['tot_acres'] = pd.cut(cat_df['tot_acres'],bins = [0,1,25,500],labels = [1,2,3])\n    cat_df['tot_acres'] = cat_df['tot_acres'].fillna(1)\n    cat_df['tot_acres'] = cat_df['tot_acres'].astype('int')\n    #cat_df['tot_acres'].cat\n    \n    # create school district categorical\n    #cat_df['school_district'] = df['School District'].astype('category')\n    \n    # create has basement\n    cat_df['has_basement'] = [1 if b > 0 else 0 for b in df.sqft_bsmt_total]\n    \n    # let in over 65\n    cat_df['over_65'] = [1 if o else 0 for o in df['over_65']]\n    \n    # let in homestead ,\n    cat_df['is_homestead'] = [1 if h else 0 for h in df['is_homestead']]\n    \n    # Trim down to township-range\n    #cat_df['Sec-Twp-Rng'] = df['Sec-Twp-Rng'].str.replace('\/','-',regex = False)\n    #cat_df['twp'] = df['Sec-Twp-Rng'].str.extract(r\"\\-(\\d{1,3})\\-\")\n    #cat_df['rng'] = df['Sec-Twp-Rng'].str.slice(start=-2, step=1)\n    #cat_df['twp_rng'] = cat_df['twp'].str.cat(others = cat_df['rng'],sep = \"-\", na_rep = \"00\")\n    #cat_df['twp_rng'] = cat_df['twp_rng'].astype('category')\n    #cat_df.drop(['Sec-Twp-Rng','twp','rng'],\n        #axis = 1,\n        #inplace = True)\n    \n    # create dummies for land value\n    cat_df[\"land_value\"] = df[\"Land Value\"].fillna('Typical')\n    cat_df[\"land_value\"] = cat_df[\"land_value\"].replace({'AboveAvg':3, 'High':4, 'Low':1, 'Typical':2, 'VHigh':5})\n    \n    # code story height multi or not fillna with '1 Story' not a sequential variable\n    #cat_df[\"story_height\"] = df[\"Story Height\"].fillna('1 Story')\n    #cat_df[\"story_height\"] = cat_df[\"story_height\"].replace({'1 Plus':2, '1 Story':1, '2 Story':2, 'Bi Level':2, 'Split':2})\n    \n    # code sale year\n    cat_df[\"sale_year\"] = df[\"Sale Year\"]\n    \n    #code heat_ac\n    cat_df[\"heat_ac\"] = df[\"heat_ac\"].replace(\"None\",\"no_heat_ac\")\n    cat_df[\"heat_ac\"] = cat_df[\"heat_ac\"].replace({'Central':4,'Electric Base or Ceiling':3, 'Floor\/Wall Furnace':2,'Hot Air Forced':1, \n  'no_heat_ac':0,'Hot Water\/Steam':4})\n    \n    # create Grade kept sequential variables and one hot\n    #cat_df['grade'] = [g[0:2] for g in list(df.Grade)]\n    #cat_df['grade'] = cat_df['grade'].replace({\"D\":1,\"D6\":1,\"D5\":2,\"D4\":3,\"D3\":4,\"D2\":5,\"D1\":6})\n    #cat_df['grade'] = cat_df['grade'].astype('category')\n    \n    # killed dummies for tree\n    #cat_df = pd.get_dummies(cat_df,prefix = 'is')\n    \n    #A lot of this will be moved to a single combine function\n    #cat_df['parcel_id'] = df.parcel_id\n    \n    #try:\n        #cat_df['SalePrice'] = df.SalePrice\n        #cat_df['SalePrice'] = cat_df.drop(cat_df[cat_df[\"SalePrice\"]>=1000000].index)\n        #cat_df['SalePrice'] = cat_df.drop(cat_df[cat_df[\"SalePrice\"]<=0].index)\n        #cat_df['SalePrice'] = np.log1p(df[\"SalePrice\"])\n    #except: \n        #cat_df['SalePrice'] = None\n        \n    # return only columns which are in both dataframes\n    return cat_df","36a7a983":"def build_one_hot(df):\n    cat_df = pd.DataFrame()\n    # create subdivisions\n    cat_df['subdivision_cat'] = categorize_subdivision(df['Subdivision'])\n    \n    # create year built as category\n    cat_df['year_built'] = df['Year Built'].replace('Year Built Not Available',0)\n    cat_df['year_built'] = cat_df.year_built.astype('int')\n    cat_df['year_built'] = [0 if len(str(y)) < 4 else y for y in cat_df['year_built']]\n    cat_df['year_built'] = pd.cut(cat_df['year_built'],bins = [0,1,1899,1949,1959,1969,1979,1989,1999,2009,2014,2018,2030],labels = ['no_year_built','built_1800s','built_early_1900s','built_1960s','built_1970s',\n                                                                                            'built_1980s','built_1990s','built_2000s','built_2010s','built_2015s','built_recently','built_new'])                                                                                                                   \n    cat_df['year_built'] = cat_df['year_built'].astype('category')\n    \n    # create Construction Type as Category 'Construction Type',\n    cat_df['construction_type'] = df['Construction Type'].fillna('no_const_type')\n    cat_df['construction_type'] = cat_df['construction_type'].astype('category')\n    \n    # create 'Roof Type',\n    cat_df['roof_type'] = df['Roof Type'].replace('Unkown','mystery_roof')\n    cat_df['roof_type'] =  cat_df['roof_type'].astype('category') \n        \n    # create 'Fireplace'\n    cat_df['fireplace'] = df['Fireplace'].str.slice(start = 0, stop = 1)\n    cat_df['fireplace'] = cat_df['fireplace'].replace(\" \", \"0\")\n    #cat_df['fireplace1'] = df['Fireplace'].str.extract(r\"(\\bAverage\\b|\\bGood\\b|\\bFair\\b)\")\n    #cat_df['fireplace1'] = cat_df['fireplace1'].fillna(\"Average\")\n    #cat_df['fireplace'] = cat_df['fireplace'].str.cat(others = cat_df['fireplace1'], sep = \"_\")\n    cat_df['fireplace'] = cat_df['fireplace'].str.cat(others = ['_fireplaces'] * len(cat_df['fireplace']))\n    cat_df['fireplace'] = cat_df['fireplace'].astype('category')   \n    \n    # create 'Foundation Type'\n    cat_df['foundation_type'] = df['Foundation Type'].replace('Unkown','mystery_foundation')\n    cat_df['foundation_type'] = cat_df['foundation_type'].astype('category')\n    \n    # create 'Floor Type'\n    cat_df['floor_type'] = df['Floor Type'].replace('Unkown','mystery_floor')\n    cat_df['floor_type'] = cat_df['floor_type'].astype('category')\n    \n    # create 'City' removed, multicolinearity\n    cat_df['city'] = df['City'].fillna('ROGERS')\n    cat_df['city'] = cat_df['city'].astype('category')\n    \n    #cleanup Total Acres\n    cat_df['tot_acres'] = df['Total Acres'].fillna(0)\n    cat_df['tot_acres'] = pd.cut(cat_df['tot_acres'],bins = [0,1,25,500],labels = ['reg_acres','med_acres','large_acres'])\n    cat_df['tot_acres'] = cat_df['tot_acres'].fillna('reg_acres')\n    cat_df['tot_acres'].cat\n    \n    # create school district categorical\n    cat_df['school_district'] = df['School District'].astype('category')\n    \n    # create has basement\n    cat_df['has_basement'] = [1 if b > 0 else 0 for b in df.sqft_bsmt_total]\n    \n    # let in over 65\n    cat_df['over_65'] = [1 if o else 0 for o in df['over_65']]\n    \n    # let in homestead ,\n    cat_df['is_homestead'] = [1 if h else 0 for h in df['is_homestead']]\n    \n    # Trim down to township-range\n    cat_df['Sec-Twp-Rng'] = df['Sec-Twp-Rng'].str.replace('\/','-',regex = False)\n    cat_df['twp'] = df['Sec-Twp-Rng'].str.extract(r\"\\-(\\d{1,3})\\-\")\n    cat_df['rng'] = df['Sec-Twp-Rng'].str.slice(start=-2, step=1)\n    cat_df['twp_rng'] = cat_df['twp'].str.cat(others = cat_df['rng'],sep = \"-\", na_rep = \"00\")\n    cat_df['twp_rng'] = cat_df['twp_rng'].astype('category')\n    cat_df.drop(['Sec-Twp-Rng','twp','rng'],\n        axis = 1,\n        inplace = True)\n    \n    # create dummies for land value\n    cat_df[\"land_value\"] = df[\"Land Value\"].fillna('Typical')\n    cat_df[\"land_value\"] = cat_df[\"land_value\"].astype('category')\n    \n    # code story height multi or not fillna with '1 Story'\n    cat_df[\"story_height\"] = df[\"Story Height\"].fillna('1 Story')\n    cat_df[\"story_height\"] = cat_df[\"story_height\"].astype('category')\n    \n    # code sale year\n    cat_df[\"sale_year\"] = df[\"Sale Year\"].astype('category')\n    \n    #code heat_ac\n    cat_df[\"heat_ac\"] = df[\"heat_ac\"].replace(\"None\",\"no_heat_ac\")\n    cat_df[\"heat_ac\"] = cat_df[\"heat_ac\"].astype('category')\n    \n    # create Grade Column move this to categorical\n    cat_df['grade'] = [g[0:2] for g in list(df.Grade)]\n    cat_df['grade'] = cat_df['grade'].replace({\"D\":\"D6\"})\n    cat_df['grade'] = cat_df['grade'].astype('category')\n    \n    # create dummies\n    cat_df = pd.get_dummies(cat_df,prefix = 'is')\n    \n    #A lot of this will be moved to a single combine function\n    #cat_df['parcel_id'] = df.parcel_id\n    \n    #try:\n        #cat_df['SalePrice'] = df.SalePrice\n        #cat_df['SalePrice'] = cat_df.drop(cat_df[cat_df[\"SalePrice\"]>=1000000].index)\n        #cat_df['SalePrice'] = cat_df.drop(cat_df[cat_df[\"SalePrice\"]<=0].index)\n        #cat_df['SalePrice'] = np.log1p(df[\"SalePrice\"])\n    #except: \n        #cat_df['SalePrice'] = None\n        \n    # return only columns which are in both dataframes\n    return cat_df[[#'has_basement', \n       #'over_65', 'is_homestead', \n       #'is_no_year_built',\n       #'is_built_1800s', 'is_built_early_1900s', 'is_built_1960s',\n       #'is_built_1970s', 'is_built_1980s', 'is_built_1990s', 'is_built_2000s',\n       #'is_built_2010s', 'is_built_2015s', 'is_built_recently', 'is_built_new',\n       #'is_A-Frame Pine', 'is_Combo Brick Frame', 'is_Low Frame', 'is_Masonry',\n       #'is_Std Frame',\n       #'is_no_const_type',# removed to clean up low-ball estimates\n       #'is_Asphalt', 'is_Fiberglass','is_Galvalume','is_Roll Cover','is_Shakes', 'is_Tile','is_Wood Shingles', 'is_mystery_roof',\n       #'is_0_fireplaces', # removed to clean up some stranger values, put back in lol\n       #'is_1_fireplaces', 'is_2_fireplaces', 'is_3_fireplaces',\n       #'is_Closed Piers', 'is_Open Piers', 'is_Slab', 'is_mystery_foundation','is_Elevated Slab', 'is_Slab On Grade', \n       #'is_Wood Subfloor',#'is_mystery_floor', \n       #'is_BENTONVILLE', 'is_ROGERS',\n       'is_reg_acres',\n       'is_med_acres', 'is_large_acres', \n       #'is_C30 Rogers City','is_C6 Bentonville City','is_CB30 Rogers (Bentonville City)','is_CR6 Bentonville (Rogers City)',\n       #'is_00-29', 'is_00-30', 'is_00-31','is_19-29', 'is_19-30', 'is_19-31', 'is_20-29', 'is_20-30', 'is_20-31',\n       #'is_AboveAvg', 'is_High', 'is_Low', 'is_Typical', 'is_VHigh',\n       'is_1 Plus', 'is_1 Story', 'is_2 Story', 'is_Bi Level', 'is_Split',\n       #'is_2016', 'is_2017', 'is_2018', 'is_2019', 'is_2020',\n       'is_Central','is_Electric Base or Ceiling', 'is_Floor\/Wall Furnace','is_Hot Air Forced', \n       'is_no_heat_ac', # removed causing some entries to have lower values\n       'is_D1', 'is_D2', 'is_D3','is_D4', 'is_D5', 'is_D6'\n       #'is_sub_group_1','is_sub_group_2','is_sub_group_3','is_sub_group_4','is_sub_group_5','is_sub_group_6','is_sub_group_7','is_sub_group_8','is_sub_group_9'\n       ]]","6a4bff44":"def build_intervals(df):\n    int_df = pd.DataFrame()\n    \n    # create patio sqft  \n    int_df['patio_sqft'] = df['AGPS'] + df['PS']\n    int_df['patio_sqft'] = int_df['patio_sqft'].fillna(0)\n    int_df['patio_sqft'] = int_df['patio_sqft'].mask(int_df['patio_sqft']>250,other = 250)\n    #int_df['patio_sqft'] = int_df['patio_sqft'].replace(0,median(int_df['patio_sqft']))\n    #int_df['patio_sqft'] = np.log1p(int_df['patio_sqft']) # this didn't solve our skew problem\n\n    \n    # create driveway total\n    int_df['ADW'] = df['ADW'].fillna(0) \n    int_df['AGDW'] = df['AGDW'].fillna(0) \n    int_df['CDW'] = df['CDW'].fillna(0)\n    int_df['driveway_total'] = int_df['ADW'] + int_df['AGDW'] + int_df['CDW']\n    int_df['driveway_total'] = int_df['driveway_total'].fillna(0)\n    int_df.drop(['ADW','AGDW','CDW'], axis = 1, inplace = True)\n    int_df['driveway_total'] = int_df['driveway_total'].mask(int_df['driveway_total'] > 12000, other = 12000)\n    #int_df['driveway_total'] = int_df['driveway_total'].replace(0,median(int_df['driveway_total']))\n    #int_df['driveway_total'],bc3 = stats.boxcox(int_df['driveway_total'])\n    \n    # create total square foot column\n    int_df['sqft_total'] = [f1+f2+f3 for f1,f2,f3 in zip(list(df['sqft_first_floor']),list(df['sqft_second_floor']),list(df['sqft_bsmt_total']))]\n    int_df['sqft_total'] = int_df['sqft_total'].fillna(0)\n    int_df['sqft_total'] = int_df['sqft_total'].mask(int_df['sqft_total']<0, other = 0)\n    int_df['sqft_total'] = int_df['sqft_total'].replace(0,1)\n    #int_df['sqft_total'] = int_df['sqft_total'].replace(0,median(int_df['sqft_total']))\n    #int_df['sqft_total'],bc1 = stats.boxcox(int_df['sqft_total'])\n    #int_df['sqft_total'] = np.log1p(int_df['sqft_total'])\n    \n    #int_df = int_df.drop(['patio_sqft'],axis = 1)\n\n    # creating a modified total square footage column by coding Land Value and using it to modify Square Footage\n    # Professor Dereszynski may have hinted during class on Saturday about how Land Value was created. \n    # lol my theory didn't work\n    #dataframe[\"code_land_value\"] = dataframe[\"Land Value\"].replace({\"Low\": 1, \"Typical\": 1.05, \"AboveAvg\": 1.1, \"High\": 1.2, \"VHigh\": 1.3})\n    #dataframe[\"modified_sf\"] = dataframe[\"sqft_total\"] * dataframe[\"code_land_value\"]\n    #dataframe.modified_sf = np.log1p(dataframe[\"modified_sf\"])\n    #dataframe.modified_sf = dataframe.modified_sf.fillna(0)\n    \n    # create Baths Total Column\n    int_df['baths_total'] = [b1+(b2\/2) for b1,b2 in zip(list(df['baths_full']),list(df['baths_half']))]\n    int_df.baths_total = int_df.baths_total.fillna(0)\n    #int_df.baths_total = int_df.baths_total.replace(0,median(int_df.baths_total))\n    #int_df.baths_total = np.log1p(int_df.baths_total) nope\n    \n    # create porch\n    int_df['porch_total'] = df['GEP']+df['OP']+df['OP2']+df['SEP']+df['WD']\n    int_df['porch_total'] = int_df['porch_total'].fillna(0)\n    \n    # create Grade Column move this to categorical\n    int_df['grade'] = [g[0:2] for g in list(df.Grade)]\n    int_df['grade'] = int_df['grade'].replace({\"D\": 1, \"D6\": 1, \"D5\": 4, \"D4\": 9, \"D3\": 16, \"D2\": 25, \"D1\": 36}) # correlation with SalePrice of 0.767404\n    \n    #cleanup Effective Age\n    int_df['eff_age'] = df['Effective Age'].replace(99,median(df['Effective Age']))\n    int_df['eff_age'] = int_df['eff_age'].replace(99,median(int_df['eff_age']))\n    int_df['eff_age'] = int_df['eff_age'].fillna(median(int_df['eff_age']))\n    #int_df['eff_age'] = int_df['eff_age'].subtract([50]*len(int_df['eff_age']))\n    #int_df['eff_age'], bc2 = stats.boxcox(int_df['eff_age'])\n    \n    #garage total\n    int_df['MFA'] = df['MFA'].fillna(0)\n    int_df['MFB'] = df['MFB'].fillna(0)\n    int_df['MUA'] = df['MUA'].fillna(0)\n    int_df['FFA'] = df['FFA'].fillna(0)\n    int_df['FFB'] = df['FFB'].fillna(0)\n    int_df['garage_total'] = int_df['MFA'] + int_df['MFB'] + int_df['MUA'] +  int_df['FFA'] + int_df['FFB']\n    int_df['garage_total'] = int_df['garage_total'].fillna(0)\n    #int_df['garage_total'],bc4 = stats.boxcox(int_df['garage_total'])\n    int_df.drop(['MFA','MFB','MUA','FFA','FFB'], axis = 1, inplace = True)\n    \n    #scaler = StandardScaler(copy = False)\n    #scaler.fit(int_df)\n    #int_df = scaler.transform(int_df)\n    #int_df = pd.DataFrame(int_df)\n    \n    x = int_df.values #returns a numpy array\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    int_df = pd.DataFrame(x_scaled, columns = list(int_df.columns))\n    return int_df","94705647":"def prep_data(df):\n    one_hot = build_one_hot(df)\n    cat_df = build_categoricals(df)\n    int_df = build_intervals(df)\n    big_df = pd.concat([one_hot,cat_df,int_df,df['parcel_id']], axis = 1)\n    big_df = big_df.reset_index(drop = True)\n    try:\n        big_df['SalePrice'] = df['SalePrice']\n        # we tried keeping the nulls, negatives and 0 values, but the best score came from dropping them.\n        #big_df['SalePrice'] = big_df['SalePrice'].mask(big_df['SalePrice']<=0, other = 0\n        #big_df['SalePrice'] = big_df['SalePrice'].fillna(median(big_df['SalePrice']))\n        #big_df = big_df.drop(index = big_df[big_df[\"SalePrice\"]>=1500000].index) # keeping outliers improved rmse by about $500\n        big_df = big_df.drop(index = big_df[big_df[\"SalePrice\"]<=0].index)\n        big_df['SalePrice'] = stats.boxcox(big_df['SalePrice'], lmbda = .41)\n        #big_df['SalePrice'] = np.log1p(big_df[\"SalePrice\"])\n        t = big_df['SalePrice']\n        p = big_df.drop(['SalePrice'], axis = 1)\n    except: \n        t = big_df['SalePrice'] = None\n        p = big_df.drop(['SalePrice'], axis = 1)\n    return p, t","095bc070":"train_house = pd.read_csv(\"\/kaggle\/input\/wcob-spring-2021\/bc_train_0203.csv\")\ntest_house = pd.read_csv(\"\/kaggle\/input\/wcob-spring-2021\/bc_test_0203.csv\")\npredictors,target = prep_data(train_house)\ntests,miss = prep_data(test_house)","83318ab1":"X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.4, random_state = 100)","196b1628":"dtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test, label=y_test)\nparam = {'max_depth': 7, 'eta': .05, 'objective': 'reg:squarederror'}\nparam['nthread'] = 4\nparam['eval_metric'] = 'rmse'\nparam['process_type'] = 'default'\nparam['feature slector'] = 'thrifty'\nparam['subsample'] = .8\nparam['sampling_method'] = 'uniform'\nparam['colsample_bytree'] = .8\nparam['silent'] = 1\nparam['booster'] = 'dart'\nparam['min_child_weight'] = 2\nevallist = [(dtest, 'eval'), (dtrain, 'train')]","4a3519d7":"num_round = 200\nbst = xgb.train(param, dtrain, num_round, evallist)","003e7e9f":"ypred = bst.predict(dtest,ntree_limit=bst.best_ntree_limit)\nprint (\"Accuracy of xgb: \",mean_squared_error(inv_boxcox(y_test,.41),inv_boxcox(ypred,.41),squared = False))","ea5cca5d":"xgb.plot_importance(bst,max_num_features=30)","ffe7b56e":"results_graph()","7da1d74f":"score_model2(\"\/kaggle\/input\/wcob-spring-2021\/bc_test_0203.csv\",bst,\"submission-7\")","68d7d8af":"Create Interval Variables","b4a788c0":"Pull in csv files and preprocess the data","fe88b0c2":"Graph Results","1357304a":"Create function to score model","af7ac881":"Combine the three dfs and preprocess the data","e04f157b":"Clean up all categorical variables... A lot weren't used here...","0cf6306a":"Train the model","3e51b1b3":"validate the model","cfd2dc61":"Prep the data for XGBoost and Set Parameters","96e8a0c3":"partition the data","d1acd125":"Create dictionary for binning the subdivisions into more manageable categories by median sales price in each subdivision","eb8efa05":"Create some coded categorical variables... again a lot not used","02567673":"Create Function to graph the validation results :)","f7584750":"Create Submission","cf95c9d6":"What are our top 30 variables?"}}