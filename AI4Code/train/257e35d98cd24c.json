{"cell_type":{"d9d77001":"code","1ae85b45":"code","5c84b7fa":"code","baab7b44":"code","2c5eee09":"code","075908d0":"code","6943d214":"code","9f3fbbb9":"code","f656d865":"markdown"},"source":{"d9d77001":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm","1ae85b45":"data = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ndata_without_dup = data.drop_duplicates(subset='label_group')","5c84b7fa":"posting_id_dict = data.groupby('label_group')['posting_id'].unique().to_dict()\ntitle_dict = data.groupby('label_group')['title'].unique().to_dict()\nimage_dict = data.groupby('label_group')['image'].unique().to_dict()","baab7b44":"label_groups = data_without_dup.label_group.values.tolist()","2c5eee09":"new_data = []\nfor i,label_group in tqdm(enumerate(data_without_dup['label_group'])):\n    matches = posting_id_dict[label_group].tolist()\n    titles = title_dict[label_group].tolist()\n    images = image_dict[label_group].tolist()\n    \n    index = np.random.randint(2,len(label_groups)-2)\n    while (index== i):\n        index = np.random.randint(0,len(label_groups))\n    \n    if len(matches) == 2:\n        if len(titles) == 2:\n            matches.extend(titles)\n            matches.extend(images)\n            matches.extend([1])\n        else:\n            matches.extend([titles[0],titles[0]])\n            matches.extend(images)\n            matches.extend([1])\n        new_data.append(matches)\n        new_data.append([matches[0],posting_id_dict[label_groups[index]][0],titles[0],title_dict[label_groups[index]][0],images[0],image_dict[label_groups[index]][0],0])\n        new_data.append([matches[0],posting_id_dict[label_groups[index+1]][0],titles[0],title_dict[label_groups[index+1]][0],images[0],image_dict[label_groups[index+1]][0],0])\n        new_data.append([matches[0],posting_id_dict[label_groups[index-1]][0],titles[0],title_dict[label_groups[index-1]][0],images[0],image_dict[label_groups[index-1]][0],0])\n    \n    else:\n        for match,title,image in zip(matches[1:],titles[1:],images[1:]):\n            new_data.append([matches[0],match,titles[0],title,images[0],image,1])\n            new_data.append([matches[0],posting_id_dict[label_groups[index]][0],titles[0],title_dict[label_groups[index]][0],images[0],image_dict[label_groups[index]][0],0])","075908d0":"siamese_data = pd.DataFrame(new_data,columns=['posting_id_1','posting_id_2','title_1','title_2','image_1','image_2','label'])","6943d214":"siamese_data","9f3fbbb9":"siamese_data.to_csv('siamese_data.csv',index=False)","f656d865":"# About this Notebook\n\nFew weeks ago I shared code for Siamese Style Training Strategy with contrastive loss [here](https:\/\/www.kaggle.com\/tanulsingh077\/siamese-style-training-efficient-net-b0) and the dataset used was published [here](https:\/\/www.kaggle.com\/tanulsingh077\/shopee-siamese-training).\n\nThis is the helper code to generate data for Siamese Style Training with Contrastive Loss . @xhlulu has been kind enough to share code to generate data for Siamese Style training with Triplet Loss [here](https:\/\/www.kaggle.com\/xhlulu\/shopee-generate-data-for-triplet-loss)\n\nNow we all can train models with these two different losses and see what works for us . I will also upload the inference kernels as soon as I get promising results by any of these approaches\n\nThe Logic used in the following code is almost similar as xhlulu's only it differs in the way I extract titles . The one thing which I feel the data suffers from is the number of positive examples since the negative pairs will be much larger than the positive pairs for products having just 2 items\n\nPlease let me know in the comments if you don't understand the code ,I will update this notebook with line by line explanantion then"}}