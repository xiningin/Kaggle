{"cell_type":{"57d724f6":"code","064ec4e1":"code","5ef4452c":"code","c0a34d25":"code","b98c0e74":"code","92af6079":"code","9c458550":"code","f68e3c2e":"code","c1d8a704":"code","61f80ec5":"code","6aebbb65":"code","c7efee0d":"markdown","c63afbc5":"markdown","f1e8ec18":"markdown","7b00077e":"markdown","90306455":"markdown","4889a1e4":"markdown","9bb76677":"markdown","90eea691":"markdown"},"source":{"57d724f6":"!pip install tensorflow-addons","064ec4e1":"import os, random, json, PIL, shutil, re\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import Model, losses, optimizers\nimport time","5ef4452c":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\n\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')\nAUTO = tf.data.experimental.AUTOTUNE","c0a34d25":"HEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nEPOCHS = 50\nBATCH_SIZE = 32","b98c0e74":"try:\n    from kaggle_datasets import KaggleDatasets\n    GCS_PATH = KaggleDatasets().get_gcs_path('gan-getting-started')\nexcept:\n    GCS_PATH = \"gs:\/\/kds-2ee06126c50f46e241ae426668de2fce51b526beb231d382373580fa\"\n\n\nMONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '\/monet_tfrec\/*.tfrec'))\nPHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '\/photo_tfrec\/*.tfrec'))\n","92af6079":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n    image = (tf.cast(image, tf.float32) \/ 127.5) - 1\n    image = tf.reshape(image, [HEIGHT, WIDTH, CHANNELS])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        'image_name': tf.io.FixedLenFeature([], tf.string),\n        'image':      tf.io.FixedLenFeature([], tf.string),\n        'target':     tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n    return dataset","9c458550":"\nmonet_ds = load_dataset(MONET_FILENAMES).batch(1)\nphoto_ds = load_dataset(PHOTO_FILENAMES).batch(1)\n\n\nfast_photo_ds = load_dataset(PHOTO_FILENAMES).batch(32*strategy.num_replicas_in_sync).prefetch(32)\nfid_photo_ds = load_dataset(PHOTO_FILENAMES).take(1024).batch(32*strategy.num_replicas_in_sync).prefetch(32)\nfid_monet_ds = load_dataset(MONET_FILENAMES).batch(32*strategy.num_replicas_in_sync).prefetch(32)","f68e3c2e":"# model_path = '..\/input\/d0eb4546-f602-4898-9e06-29a68eddf64a\/model.h5'\nmodel_path = '..\/input\/300-pics-model\/model.h5'\n\n# load a model for inference\nloaded_model = tf.keras.models.load_model(model_path, compile=False)\n\n# do some inference and plot\nwith strategy.scope():\n    row = 4\n    col = 2\n    ds_iter = iter(photo_ds)\n    plt.figure(figsize=(24, 24))\n    for j in range(0, row * (col * 2), 2):\n        example_sample = next(ds_iter)\n        plt.subplot(row, col * 2, j + 1)\n        plt.title('Input image')\n        plt.imshow(example_sample[0] * 0.5 + 0.5)\n        plt.axis('off')\n        \n        generated_sample = loaded_model(example_sample)\n        plt.subplot(row, col * 2, j + 2)\n        plt.title('Generated image')\n        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n        plt.axis('off')\n    plt.show()","c1d8a704":"import PIL\n! mkdir ..\/images\n! mkdir ..\/original_images","61f80ec5":"i = 1\nfor img in fast_photo_ds:\n    prediction = loaded_model(img, training=False).numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    for pred in prediction:\n        im = PIL.Image.fromarray(pred)\n        im.save(\"..\/images\/\" + str(i) + \".jpg\")\n        i += 1\n#         if i % 500 == 0:\n#             print(str(i) + ' prediction images created')\n\ni = 1\nfor img in fast_photo_ds.unbatch():\n    orig_img = img.numpy()\n    orig_img = (orig_img * 127.5 + 127.5).astype(np.uint8)\n    orig_img = PIL.Image.fromarray(orig_img)\n    orig_img.save(\"..\/original_images\/\" + str(i) + \".jpg\")\n    i += 1\n#     if i % 500 == 0:\n#         print(str(i) + ' original images created')","6aebbb65":"import shutil\nshutil.make_archive(\"\/kaggle\/working\/images\/\", 'zip', \"..\/images\")\nshutil.make_archive(\"\/kaggle\/working\/original_images\", 'zip', \"..\/original_images\")","c7efee0d":"## Generating datasets","c63afbc5":"# Visualize predictions","f1e8ec18":"# Load data","7b00077e":"## Auxiliar functions","90306455":"# Model parameters","4889a1e4":"## Dependencies","9bb76677":"## Submission","90eea691":"## TPU configuration"}}