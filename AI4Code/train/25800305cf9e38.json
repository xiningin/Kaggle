{"cell_type":{"abc1770c":"code","d35d4ede":"code","a280d47f":"code","7f9f4247":"code","b9c1130e":"code","7b2d5d78":"code","d2cfd87d":"code","8262cd01":"code","b129257a":"code","5486611b":"code","1a471255":"code","c82c85d1":"code","8ebc2143":"code","279da971":"code","1a42d25e":"code","e247ec20":"code","659625ae":"code","56869d92":"code","79f7a9af":"code","1251aac6":"code","325fe34d":"code","baf3bd90":"code","184619af":"markdown","0ba78aae":"markdown","323f7b3c":"markdown","2aa6c08f":"markdown","aa62265b":"markdown","6bc9c510":"markdown","2a9efe15":"markdown","6048c9de":"markdown","c4e74300":"markdown","bb55fdce":"markdown","f81df1ad":"markdown","1676be1e":"markdown","eb7b34cb":"markdown","05f47dfd":"markdown","e58318af":"markdown","d73a8f0e":"markdown","35155baa":"markdown"},"source":{"abc1770c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nimport matplotlib.pyplot as plt\nimport itertools\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.utils.np_utils import to_categorical \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d35d4ede":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\ntrain.head()","a280d47f":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\ntest.head()","7f9f4247":"Y_train = train[\"label\"]\n\nX_train = train.drop(labels = [\"label\"],axis = 1)\nY_train.head()","b9c1130e":"plt.figure(figsize=(15,7))\ng = sns.countplot(Y_train, palette = 'Set3')\nplt.title(\"Number of Digit Classes\", size = 18)\nplt.xticks(size = 16)\nplt.xlabel(\"Digits\", size = 12)\nplt.ylabel(\"Count\", size =12)\nY_train.value_counts()","7b2d5d78":"rows = 4\ncols = 6\nf = plt.figure(figsize=(2*cols,2*rows))\nfor i in range(rows*cols): \n    f.add_subplot(rows,cols,i+1)\n    img = X_train.iloc[i].to_numpy()\n    img = img.reshape((28,28))\n    plt.imshow(img,cmap='gray')\n    plt.axis(\"off\")\n    plt.title(str(Y_train[i]), y=-0.18,color=\"red\")\nplt.show()","d2cfd87d":"X_train = X_train \/ 255.0\ntest = test \/ 255.0\nprint(\"X_train Shape: \",X_train.shape)\nprint(\"Test Shape: \",test.shape)","8262cd01":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"X_train Shape: \",X_train.shape)\nprint(\"Test Shape: \",test.shape)","b129257a":"Y_train = to_categorical(Y_train, num_classes = 10)","5486611b":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.3, random_state=42)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","1a471255":"plt.imshow(X_train[2][:,:,0],cmap='gray')\nplt.axis(\"off\")\nplt.show()","c82c85d1":"model = Sequential()\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","8ebc2143":"optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","279da971":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","1a42d25e":"epochs = 20\nbatch_size = 250","e247ec20":"datagen = ImageDataGenerator(featurewise_center=False,\n                             samplewise_center=False,\n                             featurewise_std_normalization=False,\n                             samplewise_std_normalization=False,\n                             zca_whitening=False,\n                             rotation_range=5,\n                             zoom_range = 0.1\n                             ,width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             horizontal_flip=False,\n                             vertical_flip=False)\ndatagen.fit(X_train)","659625ae":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              steps_per_epoch=X_train.shape[0] \/\/ batch_size)","56869d92":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize =(14,6))\nax1.plot(history.history['loss'], color='r', label=\"Loss\")\nax1.set_title(\"Test Loss\")\nax1.set_ylabel(\"Loss\")\nax1.set_xlabel(\"Epochs\")\n\nax2.plot(history.history['accuracy'], color='b', label=\"Accuracy\")\nax2.set_title(\"Test Accuracy\")\nax2.set_ylabel(\"Accuracy\")\nax2.set_xlabel(\"Epochs\")\nfig.tight_layout()","79f7a9af":"Y_pred = model.predict(X_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(Y_val,axis = 1) \nrows = 4\ncols = 6\nf = plt.figure(figsize=(2*cols,2*rows))\nf.suptitle(\"Predictions\", fontsize=20)\nfor i in range(rows*cols): \n    f.add_subplot(rows,cols,i+1)\n    img = X_val[i]\n    img = img.reshape((28,28))\n    plt.imshow(img,\n               cmap='gray')\n    plt.axis(\"off\")\n    plt.title(\"Prediction: {}\\nTrue Value: {}\".format(Y_pred_classes[i], Y_true[i]),\n              y=-0.35,color=\"blue\")\nf.tight_layout()\n    \nf.show()\n","1251aac6":"wrong_index = []\nfor i in range(2400):\n    if Y_pred_classes[i] != Y_true[i]:\n        wrong_index.append(i)\nprint(len(wrong_index))","325fe34d":"f = plt.figure(figsize=(2*cols,2*rows))\nf.suptitle(\"Some of Wrong Predictions\", fontsize=20)\nfor i in range(rows*cols): \n    f.add_subplot(rows,cols,i+1)\n    img = X_val[wrong_index[i]]\n    img = img.reshape((28,28))\n    plt.imshow(img,\n               cmap='gray')\n    plt.axis(\"off\")\n    plt.title(\"Prediction: {}\\nTrue Value: {}\".format(Y_pred_classes[wrong_index[i]],\n                                                      Y_true[wrong_index[i]]),y=-0.35,color=\"red\")\nf.tight_layout()\n    \nf.show()","baf3bd90":"confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(confusion_mtx, annot=True,\n            linewidths=3,cmap=\"Greens\",\n            fmt= '.0f',ax=ax,\n            cbar = False,\n           annot_kws={\"size\": 16})\nplt.yticks(rotation = 0)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\", size = 14)\nplt.show()","184619af":"<a id = \"7\"><\/a>\n## Label Encoding","0ba78aae":"<a id = \"12\"><\/a>\n# Epochs and Batch Size\nSay you have a dataset of 10 examples (or samples). You have a batch size of 2, and you've specified you want the algorithm to run for 3 epochs. Therefore, in each epoch, you have 5 batches (10\/2 = 5). Each batch gets passed through the algorithm, therefore you have 5 iterations per epoch.","323f7b3c":"<a id = \"13\"><\/a>\n# Data Augmentation\nWe need to expand artificially our handwritten digit datase to avoid overfitting problem. Alter the training data with small transformations to reproduce the variations of digit.\n\n![UKwFg%20%281%29.jpg](attachment:UKwFg%20%281%29.jpg)","2aa6c08f":"<a id = \"10\"><\/a>\n# Define Optimizer\nWe can change the learning rate with Adam Optimizer.","aa62265b":"<a id = \"3\"><\/a>\n# Loading Data","6bc9c510":"<a id = \"14\"><\/a>\n# Fit the Model","2a9efe15":"<a id = \"8\"><\/a>\n# Train Test Split","6048c9de":"<a id = \"6\"><\/a>\n## Reshaping","c4e74300":"# Digit Recognition with CNN\n\n![image.png](attachment:image.png)\n\n1. [Convolutional Neural Network](#1)\n2. [Libraries and Utilities](#2)\n3. [Loading Data](#3)\n4. [Visualization](#4)\n5. [Preprocessing](#17)\n    - [Normalization](#5)\n    - [Reshaping](#6)\n    - [Label Encoding](#7)\n8. [Train Test Split](#8)\n9. [Implementing with Keras](#9)\n10. [Define Optimizer](#10)\n11. [Compile Model](#11)\n12. [Epochs and Batch Size](#12)\n13. [Data Augmentation](#13)\n14. [Fit the Model](#14)\n15. [Evaluate the Model](#15)\n16. [Confusion Matrix](#16)","bb55fdce":"<a id = \"11\"><\/a>\n# Compile Model","f81df1ad":"<a id = \"2\"><\/a>\n# Libraries and Utilities","1676be1e":"<a id = \"15\"><\/a>\n# Evaluate the Model","eb7b34cb":"<a id = \"17\"><\/a>\n# Preprocessing\n\n<a id = \"5\"><\/a>\n## Normalization\nWe perform a grayscale normalization to reduce the effect of illuminations differences.","05f47dfd":"<a id = \"16\"><\/a>\n# Confusion Matrix","e58318af":"<a id = \"1\"><\/a>\n# Convolutional Neural Network\n\n![image.png](attachment:image.png)\n\nIn deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on the shared-weight architecture of the convolution kernels that scan the hidden layers and translation invariance characteristics. They have applications in image and video recognition, recommender systems, image classification, Image segmentation, medical image analysis, natural language processing, brain-computer interfaces, and financial time series.\n\nCNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"fully-connectedness\" of these networks makes them prone to overfitting data. Typical ways of regularization include varying the weights as the loss function gets minimized while randomly trimming connectivity. CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble patterns of increasing complexity using smaller and simpler patterns embossed in the filters. Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.\n\nConvolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\n\nCNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns to optimize the filters or convolution kernels that in traditional algorithms are hand-engineered. This independence from prior knowledge and human intervention in feature extraction is a major advantage.","d73a8f0e":"<a id = \"4\"><\/a>\n# Visualization","35155baa":"<a id = \"9\"><\/a>\n# Implementing with Keras\n\n![image.png](attachment:image.png)\n\nA single model can be used to simulate having a large number of different network architectures by randomly dropping out nodes during training. This is called dropout and offers a very computationally cheap and remarkably effective regularization method to reduce overfitting and improve generalization error in deep neural networks of all kinds."}}