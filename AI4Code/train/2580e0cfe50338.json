{"cell_type":{"078937af":"code","217cd9ef":"code","ea263e41":"code","a9b9474e":"code","7fdd8895":"code","19833c7d":"code","08175b50":"code","90fe5d58":"code","2e330815":"code","6fb13899":"code","19d87f0f":"code","97f3fe3f":"code","e73cb458":"code","5e8f7fe9":"code","420511f4":"code","0c8535bf":"code","0e2aca0f":"code","1e5caba4":"code","03bbfd76":"code","51cb2e96":"code","45bdc278":"code","767773a1":"code","30ce32c1":"code","b687152f":"code","6f87603b":"code","f328c2bb":"code","94d57393":"code","245b8e2e":"code","6e5882f2":"code","be4c6969":"code","3cdd0cc8":"code","646b0de6":"code","31485917":"code","d26ab6f8":"code","2b0d0186":"code","549e0e00":"code","cee1bee0":"code","3975a596":"code","9bbaf2ef":"code","75a4d7cd":"code","3ad3a22a":"code","d85c5ff3":"code","93b78837":"markdown","b8d2c1b1":"markdown","d3130080":"markdown","3cb87d4f":"markdown","f21bbe85":"markdown","bddc62db":"markdown","f3a46cce":"markdown","6f91858a":"markdown","bfca1171":"markdown","632903bd":"markdown","4c367c0d":"markdown","7ff4f2bd":"markdown","6aec30f8":"markdown"},"source":{"078937af":"import matplotlib.pyplot as plt # data visualisation\nimport seaborn as sb # data visualisation\nimport pandas as pd # dataframes\nimport math # math formulae","217cd9ef":"# importing training data\ndf = pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/train.csv', nrows = 1_000_000)\ndf.head()","ea263e41":"# removing 'key' column\ndf = df.drop(columns = ['key'])\ndf.head()","a9b9474e":"# dimensions of dataset\ndf.shape","7fdd8895":"# checking for duplicates\nduplicate_rows = df[df.duplicated()]\nduplicate_rows.shape","19833c7d":"# data type of features and target\ndf.dtypes","08175b50":"# statistical data for numerical features and target\ndf.describe()","90fe5d58":"# removing invalid coordinates\ndf = df[df['pickup_longitude'] <= -71.4725]\ndf = df[df['pickup_longitude'] >= -79.4554]\n\ndf = df[df['pickup_latitude'] <= 45.0042]\ndf = df[df['pickup_latitude'] >= 40.2940]\n\ndf = df[df['dropoff_longitude'] <= -71.4725]\ndf = df[df['dropoff_longitude'] >= -79.4554]\n\ndf = df[df['dropoff_latitude'] <= 45.0042]\ndf = df[df['dropoff_latitude'] >= 40.2940]\n\ndf.shape","2e330815":"# removing trips with zero\/negative fares\ndf = df[df['fare_amount'] > 0]\ndf.shape","6fb13899":"# removing trips with zero passengers\ndf = df[df['passenger_count'] > 0]\ndf.shape","19d87f0f":"# checking statistical data again\ndf.describe()","97f3fe3f":"# changing 'pickup_datetime' to datetime data type\ndf['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format = '%Y-%m-%d %H:%M:%S %Z')\ndf.dtypes","e73cb458":"# checking for null values\ndf.isnull().sum()","5e8f7fe9":"# sorting df by 'pickup_datetime'\ndf = df.sort_values('pickup_datetime')\ndf","420511f4":"# obtaining year, month and hour attributes from 'pickup_datetime'\ndf['year'] = df['pickup_datetime'].dt.strftime('%Y')\ndf['month'] = df['pickup_datetime'].dt.strftime('%m')\ndf['hour'] = df['pickup_datetime'].dt.strftime('%H')\ndf","0c8535bf":"# changing year, month and hour attributes\ndf[['year', 'month', 'hour']] = df[['year', 'month', 'hour']].apply(pd.to_numeric)\ndf.dtypes","0e2aca0f":"# calculating trip distance using haversine formula\ndef haversine(start_lon, start_lat, end_lon, end_lat):\n    earth_radius = 6371\n    start_lon, start_lat, end_lon, end_lat = map(math.radians, [start_lon, start_lat, end_lon, end_lat])\n    lat_diff = end_lat - start_lat\n    lon_diff = end_lon - start_lon\n    \n    a = pow(math.sin(lat_diff\/2), 2) + math.cos(start_lat) * math.cos(start_lat) * pow(math.sin(lon_diff\/2), 2)\n    c = 2 * math.asin(math.sqrt(a))\n    dist = earth_radius * c\n    \n    return dist","1e5caba4":"# adding distance column to dataframe\ndist_array = []\n\nfor i in range(df.shape[0]):\n    plon = df.iloc[i]['pickup_longitude']\n    plat = df.iloc[i]['pickup_latitude']\n    dlon = df.iloc[i]['dropoff_longitude']\n    dlat = df.iloc[i]['dropoff_latitude']\n    dist = haversine(plon, plat, dlon, dlat)\n    dist_array.append(dist)\n    \ndf['distance in kilometres'] = dist_array\ndf","03bbfd76":"df.describe()","51cb2e96":"# trips with zero distances\nzero_dist = df[df['distance in kilometres'] == 0]\nzero_dist.shape","45bdc278":"# removing zero distance trips\ndf = df[df['distance in kilometres'] > 0]\ndf.describe()","767773a1":"# relationship between distance in kilometres and fare_amount\nsb.relplot(data = df, x = 'distance in kilometres', y = 'fare_amount')","30ce32c1":"# frequency of fare_amount\ndf['fare_amount'].plot.hist(bins = 100, figsize=(8,2))","b687152f":"# mean by year\nyearly_mean = df.groupby(['year']).mean()\nyearly_mean","6f87603b":"years = df['year'].unique()\nsb.barplot(x = years, y = yearly_mean['fare_amount'])","f328c2bb":"# mean by month\nmonthly_mean = df.groupby('month').mean()\nmonthly_mean","94d57393":"months = df['month'].unique()\nsb.barplot(x = months, y = monthly_mean['fare_amount'])","245b8e2e":"# mean by hour\nhourly_mean = df.groupby('hour').mean()\nhourly_mean","6e5882f2":"hours = df['hour'].unique()\nsb.barplot(x = hours, y = hourly_mean['fare_amount'])","be4c6969":"# mean by number of passengers\npass_mean = df.groupby(['passenger_count']).mean()\npass_mean","3cdd0cc8":"num_of_pass = df['passenger_count'].unique()\nsb.barplot(x = num_of_pass, y = pass_mean['fare_amount'])","646b0de6":"# filter approach using Pearson correlation\npearson_corr = df.corr()\nplt.figure(figsize = (10,5))\nsb.heatmap(data = pearson_corr, cmap = \"Reds\", annot = True)","31485917":"# listing correlations of features with target\ncorrelations = abs(pearson_corr['fare_amount'])\ncorrelations","d26ab6f8":"df","2b0d0186":"# wrapper method: forward selection\n# estimator: LinearRegression\n# cross-validation: 5-fold\nfrom sklearn.linear_model import LinearRegression\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\n\nX = df.iloc[:,6:]\ny = df.iloc[:,0]\nlinear = LinearRegression()\nsfs = SFS(linear, k_features = 'best', forward = True, floating = False, verbose = 0, cv = 5)\nsfs = sfs.fit(X,y)","549e0e00":"# Best feature at each step\nsfs.subsets_","cee1bee0":"# name of top features\nsfs.k_feature_names_","3975a596":"# cross-validation score\nsfs.k_score_","9bbaf2ef":"# wrapper method: backward selection\n# estimator: LinearRegression\n# cross-validation: 5-fold\nfrom sklearn.linear_model import LinearRegression\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\n\nX = df.iloc[:,6:]\ny = df.iloc[:,0]\nlinear = LinearRegression()\nsfs = SFS(linear, k_features = 'best', forward = False, floating = False, verbose = 0, cv = 5)\nsfs = sfs.fit(X,y)","75a4d7cd":"# Best feature at each step\nsfs.subsets_","3ad3a22a":"# name of top features\nsfs.k_feature_names_","d85c5ff3":"# cross-validation score\nsfs.k_score_","93b78837":"Notes:\n* The number of passengers does not seem to impact the fare amount","b8d2c1b1":"**1. Studying the feature statistics**","d3130080":"**Notes**\n* Distance, year and passenger count were identified as better features in this order\n* Cross-validation score: 0.581","3cb87d4f":"**Notes**\n* Distance, year and passenger count were identified as better features in this order as well\n* Cross-validation score: 0.581","f21bbe85":"**2. Input missing values**","bddc62db":"**6. Feature Subset Selection**\n\n* Approaches:\n1. Filter -> Pearson coefficient to measure correlation between features\n2. Wrapper -> Forward selection and backward elimination","f3a46cce":"Notes:\n* Gradual increase in mean fare amount from 2009 to 2015\n* Mean fare amount increases sharply from 01:00 to 05:00\n* The month which the trip was taken does not seem to impact fare amount","6f91858a":"Notes:\n* Negative\/zero fares present\n* Zero passengers trips present\n* Outliers present -> 208 passengers\n* Invalid coordinates -> lat = (90,-90), lon = (180,-180)\n* New York coordinates -> lat = (40.2940,45.0042), lon = (71.4725,79.4554)\n* https:\/\/www.netstate.com\/states\/geography\/ny_geography.htm","bfca1171":"**3. Aggregation**\n\nTo group by:\n* Year\n* Month\n* Hour\n* Number of Passengers\n* Distance","632903bd":"**Data Preprocessing and Feature Engineering (Exploratory Data Analysis)**\n\n1. Studying the feature statistics\n2. Impute missing values (with mean, median, mode)\n3. Aggregation\n4. Sampling\n5. Dimensionality reduction (PCA)\n6. Feature subset selection\n7. Feature creation\n8. Discretization and binarization (with Gini Index \/ Entropy)\n9. Variable transformation and binning","4c367c0d":"**7. Feature Creation**","7ff4f2bd":"**Notes:**\n* Distance has the highest correlation with target with Pearson coefficient of 0.795","6aec30f8":"Notes:\n* To fill in null values with mean if any"}}