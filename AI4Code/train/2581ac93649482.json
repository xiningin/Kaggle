{"cell_type":{"ec09a6b0":"code","c7b7ce99":"code","265d30ba":"code","b87e7015":"code","dd5f1680":"code","c01eb151":"code","fc2270bb":"code","edb78f71":"code","f9773e3e":"code","cf3948ed":"code","771e274e":"code","2d4a8260":"code","70133e70":"code","b21c9927":"code","a5517638":"markdown","28cc4fb2":"markdown","5a5cc134":"markdown","3768061b":"markdown","1a4c4f49":"markdown"},"source":{"ec09a6b0":"import pandas as pd \nimport os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport matplotlib.pyplot as plt\nimport imagehash\nimport psutil\n\nfrom PIL import Image\nfrom joblib import Parallel, delayed\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom IPython import display\nimport time\n\n%matplotlib inline\n\nplt.style.use('ggplot')\npd.set_option('display.max_columns', 300)\npd.set_option('display.max_rows', 100)","c7b7ce99":"train = pd.read_csv(\"..\/input\/train.csv\")","265d30ba":"df = train[['diagnosis']]\ndf['path'] = glob.glob('..\/input\/train_images\/*.png')\ndf.head()","b87e7015":"def getImageMetaData(file_path):\n    with Image.open(file_path) as img:\n        img_hash = imagehash.phash(img)\n        return img.size, img.mode, str(img_hash), file_path\n\n    \nimg_meta_l = Parallel(n_jobs=psutil.cpu_count(), verbose=1)(\n    (delayed(getImageMetaData)(fp) for fp in glob.glob('..\/input\/train_images\/*.png'))\n)\nimg_meta_df = pd.DataFrame(np.array(img_meta_l))\nimg_meta_df.columns = ['Size', 'Mode', 'Hash', 'path']","dd5f1680":"df = df.merge(img_meta_df, on='path', how='left')\ndf.head()","c01eb151":"df.to_csv('.\/image_info.csv', index=False)","fc2270bb":"df_gb = df.groupby('Hash').count().reset_index()\ndf_gb.head()","edb78f71":"df_gb_dup = df_gb.query('path > 1')\ndf_gb_dup","f9773e3e":"df_gb_dup['path'].value_counts()","cf3948ed":"dup_hash_l = df_gb_dup['Hash'].values","771e274e":"df_dup = df.loc[df['Hash'].isin(dup_hash_l)].sort_values('Hash')\ndf_dup.to_csv('.\/duplicated_info.csv')\ndf_dup.head(10)","2d4a8260":"samp_hash = df_dup['Hash'].sample(1).values[0]\nprint(samp_hash)","70133e70":"dups = df_dup.query('Hash == @samp_hash')['path'].values\n\nfig, ax = plt.subplots(len(dups), 1, figsize=(7, 5 * len(dups)))\nfor i, d in enumerate(dups):\n    ax[i].imshow(mpimg.imread(d))\n    ax[i].grid(alpha=0.1)\nfig.tight_layout();","b21c9927":"dups = df_dup.query('Hash == \"969a6b60246f3967\"')['path'].values\n\nfig, ax = plt.subplots(len(dups), 1, figsize=(7, 5 * len(dups)))\nfor i, d in enumerate(dups):\n    ax[i].imshow(mpimg.imread(d))\n    ax[i].grid(alpha=0.1)\nfig.tight_layout();","a5517638":"---\n# <font color=dimgray> Load CSV <\/font>","28cc4fb2":"Calculating the Hash, Shape, Mode, Length and Ratio of each image","5a5cc134":"---\n# <font color=dimgray> EOF <\/font>","3768061b":"---\n# <font color=dimgray> Get Info of train images <\/font>\n\nGetting the path of the Image","1a4c4f49":"This kernel is a little bit modified version of [this kernel](https:\/\/www.kaggle.com\/manojprabhaakr\/similar-duplicate-images-in-aptos-data).   \nCredit to [@ManojPrabhakar](https:\/\/www.kaggle.com\/manojprabhaakr).  \n<br>\nYou can download the duplicated list from **output**.\n\n---\n# <font color=dimgray> Import Package <\/font>"}}