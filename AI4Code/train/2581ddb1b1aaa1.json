{"cell_type":{"4b30b6ab":"code","1230581d":"code","8c597686":"code","431313ed":"code","1b52c2c9":"code","bf33d101":"code","32c8ffbd":"code","0347438e":"code","7c03c89d":"code","3bc367d2":"code","68844efc":"code","5187c85f":"code","e84a719c":"code","cf27c000":"code","1cbb3c18":"code","a5102102":"code","6bbd2e9b":"code","b0f11718":"code","bf659d65":"code","4f2de0f1":"code","2663b313":"code","a89dc6f3":"markdown","722ed7f6":"markdown","1d522c9e":"markdown","3623fb9f":"markdown","ab8d9afb":"markdown","639af69b":"markdown","2a76ef69":"markdown","2669d266":"markdown","a1a8ed01":"markdown","d419fe6a":"markdown","e37d82dc":"markdown","b72b7051":"markdown","c0cf6dee":"markdown","34bbcedb":"markdown","6de47f33":"markdown","35d7bf67":"markdown","202b7734":"markdown","8e650991":"markdown","8739a340":"markdown","252dff65":"markdown","6bcad171":"markdown"},"source":{"4b30b6ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1230581d":"# Importamos las librer\u00edas adicionales que necesitaremos\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","8c597686":"data = pd.read_csv('..\/input\/titanic\/train.csv')","431313ed":"X = data.drop(columns=['PassengerId','Survived','Name','Ticket','Fare','Embarked'])\n","1b52c2c9":"X.Cabin = X.Cabin.str[0]","bf33d101":"X_men = X[X.Sex=='male']\nX_women = X[X.Sex=='female']\nX.loc[(X[\"Sex\"] == 'male') & (X[\"Age\"].isnull()),'Age'] = X_men.Age.mean()\nX.loc[(X[\"Sex\"] == 'female') & (X[\"Age\"].isnull()),'Age'] = X_women.Age.mean()","32c8ffbd":"X = pd.get_dummies(X)\n\n# Nos deshacemos de alguna de las dos variables de g\u00e9nero, ya que contienen la misma informaci\u00f3n\nX = X.drop(labels='Sex_male',axis=1)","0347438e":"print(X.head())","7c03c89d":"y = data.Survived\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=14, stratify=y)\ny.describe()","3bc367d2":"params = np.arange(1, 30)\ntrain_score = np.empty(len(params))\ntest_score = np.empty(len(params))\nfor i, k in enumerate(params):\n    dt = DecisionTreeClassifier(max_depth=k,random_state=14).fit(X_train, y_train)\n    train_score[i] = dt.score(X_train,y_train)\n    test_score[i] = dt.score(X_test,y_test)\n    \nplt.style.use('classic')\nplt.title('\u00c1rboles de decisi\u00f3n X_1: Cambiando la profundidad m\u00e1xima')\nplt.plot(params, test_score, label = 'Score de pruebas')\nplt.plot(params, train_score, label = 'Score de entrenamiento')\nplt.legend()\nplt.xlabel('Profundidad m\u00e1xima')\nplt.ylabel('Score')\nplt.show()\n\nprint(test_score)","68844efc":"dt = DecisionTreeClassifier(max_depth=4,random_state=14).fit(X_train, y_train)\nprint(dt.score(X_test,y_test))","5187c85f":"params = np.arange(1, 20)\n\ntrain_score = np.empty(len(params))\ntest_score = np.empty(len(params))\nfor i, k in enumerate(params):\n    gbt = GradientBoostingClassifier(max_depth=k, random_state=14).fit(X_train,y_train)\n    train_score[i] = gbt.score(X_train,y_train)\n    test_score[i] = gbt.score(X_test,y_test)\n\nplt.style.use('classic')\nplt.title('Gradient Boosting: Cambiando la profundidad m\u00e1xima')\nplt.plot(params, test_score, label = 'Score de pruebas')\nplt.plot(params, train_score, label = 'Score de entrenamiento')\nplt.legend()\nplt.xlabel('Profundidad m\u00e1xima')\nplt.ylabel('Score')\nplt.show()\n\nprint(test_score)","e84a719c":"gbt = GradientBoostingClassifier(max_depth=2, random_state=14).fit(X_train,y_train)\nprint(gbt.score(X_test,y_test))","cf27c000":"test = pd.read_csv('..\/input\/titanic\/test.csv')\nX_sub = test.drop(columns=['PassengerId','Name','Ticket','Fare','Embarked'])\nX_sub.Cabin = X_sub.Cabin.str[0]\n\n# Le asignamos la edad promedio de la base de pruebas\nX_sub.loc[(X_sub[\"Sex\"] == 'male') & (X_sub[\"Age\"].isnull()),'Age'] = X_men.Age.mean()\nX_sub.loc[(X_sub[\"Sex\"] == 'female') & (X_sub[\"Age\"].isnull()),'Age'] = X_women.Age.mean()\n\nX_sub = pd.get_dummies(X_sub)\nX_sub = X_sub.drop(labels='Sex_male',axis=1)\nprint(X_sub.head())","1cbb3c18":"print('Tama\u00f1o de la base original: '+str(X.shape))\nprint('Tama\u00f1o de la base para entrega: '+str(X_sub.shape))","a5102102":"X_sub['Cabin_T']=0","6bbd2e9b":"print(X_sub.head())","b0f11718":"print(X_sub.columns == X.columns)","bf659d65":"prediction = gbt.predict(X_sub)","4f2de0f1":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = prediction\nprint(submission.head())","2663b313":"submission.to_csv('gender_submission.csv',index=False)","a89dc6f3":"# Predicci\u00f3n","722ed7f6":"Para todos los datos faltantes de edad, le imputaremos la edad promedio por g\u00e9nero.","1d522c9e":"Asignamos el modelo con mejor exactitud","3623fb9f":"Ahora s\u00ed podemos hacer predicci\u00f3nes.","ab8d9afb":"# Gradient Boosting","639af69b":"Cuando ya tienen la misma longitud, ya podemos comparar si las columnas est\u00e1n en el mismo orden.","2a76ef69":"Vemos que falta una columna. Al analizar las columnas vemos que falta 'Cabin_T', por lo que se lo agregamos.","2669d266":"Corremos un modelo con varios valores del par\u00e1matro, para ver con cu\u00e1l obtenemos una mejor exactitud en la base de pruebas (no en la de entrenamiento).","a1a8ed01":"Hacemos un DataFrame para poner el ID del pasajero y su predicci\u00f3n correspondiente, como se indica en el formato para entrega.","d419fe6a":"Una vez que tenemos 'X' y 'y', separamos en bases de prueba y entrenamiento.","e37d82dc":"Vemos c\u00f3mo qued\u00f3 X:","b72b7051":"Con la variable 'Cabin', trabajaremos solo con la primera letra de la cabina.","c0cf6dee":"Nos aseguramos de que sean las mismas columnas.","34bbcedb":"Transformamos a dummies las variables categ\u00f3ricas.\n","6de47f33":"Usamos el modelo que obtuvimos para hacer predicciones sobre la base de pruebas para entrega. Lo primero que hay que hacer es transformar la base de pruebas al mismo formato con el que corrimos el modelo.","35d7bf67":"Asignamos el modelo con mayor exactitud","202b7734":"# \u00c1rbol de decisi\u00f3n","8e650991":"Trabajaremos sin las variables 'PassengerId', 'Name', 'Ticket', 'Fare' y 'Embarked'.","8739a340":"# Procesamiento de datos","252dff65":"Lo exportamos a csv para la entrega.","6bcad171":"Vemos c\u00f3mo se ve X_sub:"}}