{"cell_type":{"619d0c20":"code","87af5f4e":"code","52c123b4":"code","2d7803e3":"code","97e0b5d2":"code","8066d4f0":"code","46133d41":"code","ee641fbf":"code","208b16cc":"code","3176717d":"code","a94f5040":"code","2c88c571":"code","ba44862d":"code","38aeef51":"code","06c4de5c":"code","864edea4":"code","3cc5974c":"code","773ab18e":"code","456c7d3e":"code","d29cfe63":"code","cf9bac94":"code","97956905":"code","c575d457":"code","de82b5e2":"code","5fe7572c":"code","40535bd4":"code","98e43085":"code","518e1acb":"markdown","5e76ab80":"markdown","d83bb889":"markdown","2aacb3e9":"markdown","4e0f427c":"markdown","5945c0d1":"markdown","f0807636":"markdown","2f03a369":"markdown","df92c48a":"markdown"},"source":{"619d0c20":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87af5f4e":"from pandas import Series,DataFrame\ndata_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndata_train","52c123b4":"\"\"\"\nPassengerId => \u4e58\u5ba2ID\nPclass => \u4e58\u5ba2\u7b49\u7ea7(1\/2\/3\u7b49\u8231\u4f4d)\nName => \u4e58\u5ba2\u59d3\u540d\nSex => \u6027\u522b\nAge => \u5e74\u9f84\nSibSp => \u5802\u5144\u5f1f\/\u59b9\u4e2a\u6570\nParch => \u7236\u6bcd\u4e0e\u5c0f\u5b69\u4e2a\u6570\nTicket => \u8239\u7968\u4fe1\u606f\nFare => \u7968\u4ef7\nCabin => \u5ba2\u8231\nEmbarked => \u767b\u8239\u6e2f\u53e3\n\"\"\"\n\ndata_train.info()","2d7803e3":"data_train.describe()","97e0b5d2":"# \u4ee5\u4e0a\u5185\u5bb9\u4e3a\u521d\u6b65\u5904\u7406\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nfig.set(alpha=0.2)  # \u8bbe\u5b9a\u56fe\u8868\u989c\u8272alpha\u53c2\u6570\n\n#plt.subplot2grid((2,3),(0,0))             # \u5728\u4e00\u5f20\u5927\u56fe\u91cc\u5206\u5217\u51e0\u4e2a\u5c0f\u56fe\ndata_train.Survived.value_counts().plot(kind='bar')# \u67f1\u72b6\u56fe \nplt.title(u\"survived rate (1 for survived)\") # \u6807\u9898\nplt.ylabel(u\"count\")  \n\n#plt.subplot2grid((2,3),(0,1))\nplt.figure()\ndata_train.Pclass.value_counts().plot(kind=\"bar\")\nplt.ylabel(u\"count\")\nplt.title(u\"carbin level\")\n\n#\"\"\"\n#plt.subplot2grid((2,3),(0,2))\nplt.figure()\nplt.scatter(data_train.Survived, data_train.Age)\nplt.ylabel(u\"age\")                         # \u8bbe\u5b9a\u7eb5\u5750\u6807\u540d\u79f0\nplt.grid(b=True, which='major', axis='y') \nplt.title(u\"survived per age (1 for survived)\")\n\n\n#plt.subplot2grid((2,3),(1,0), colspan=2)\nplt.figure()\ndata_train.Age[data_train.Pclass == 1].plot(kind='kde')   \ndata_train.Age[data_train.Pclass == 2].plot(kind='kde')\ndata_train.Age[data_train.Pclass == 3].plot(kind='kde')\nplt.xlabel(u\"age\")# plots an axis lable\nplt.ylabel(u\"probility density\") \nplt.title(u\"age per carbin\")\nplt.legend((u'top carbin', u'2 carbin',u'3 carbin'),loc='best') # sets our legend for our graph.\n\n\n#plt.subplot2grid((2,3),(1,2))\nplt.figure()\ndata_train.Embarked.value_counts().plot(kind='bar')\nplt.title(u\"onboard per port\")\nplt.ylabel(u\"count\")  \n#\"\"\"\n\n\nplt.show()\n","8066d4f0":"#\u770b\u770b\u5404\u4e58\u5ba2\u7b49\u7ea7\u7684\u83b7\u6551\u60c5\u51b5\nfig = plt.figure()\nfig.set(alpha=0.2)  # \u8bbe\u5b9a\u56fe\u8868\u989c\u8272alpha\u53c2\u6570\n\nSurvived_0 = data_train.Pclass[data_train.Survived == 0].value_counts()\nSurvived_1 = data_train.Pclass[data_train.Survived == 1].value_counts()\ndf=pd.DataFrame({u'survied':Survived_1, u'descreased':Survived_0})\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"survived per carbin\")\nplt.xlabel(u\"carbin level\") \nplt.ylabel(u\"count\") \nplt.show()\n","46133d41":"#\u770b\u770b\u5404\u6027\u522b\u7684\u83b7\u6551\u60c5\u51b5\nfig = plt.figure()\nfig.set(alpha=0.2)  # \u8bbe\u5b9a\u56fe\u8868\u989c\u8272alpha\u53c2\u6570\n\nSurvived_m = data_train.Survived[data_train.Sex == 'male'].value_counts()\nSurvived_f = data_train.Survived[data_train.Sex == 'female'].value_counts()\ndf=pd.DataFrame({u'male':Survived_m, u'female':Survived_f})\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"survied per sex\")\nplt.xlabel(u\"sex\") \nplt.ylabel(u\"count\")\nplt.show()","ee641fbf":"\n #\u7136\u540e\u6211\u4eec\u518d\u6765\u770b\u770b\u5404\u79cd\u8231\u7ea7\u522b\u60c5\u51b5\u4e0b\u5404\u6027\u522b\u7684\u83b7\u6551\u60c5\u51b5\nfig=plt.figure()\n#fig.set(alpha=0.65) # \u8bbe\u7f6e\u56fe\u50cf\u900f\u660e\u5ea6\uff0c\u65e0\u6240\u8c13\nplt.title(u\"survived per age or carbin\")\n\nax1=fig.add_subplot(141)\ndata_train.Survived[data_train.Sex == 'female'][data_train.Pclass != 3].value_counts().plot(kind='bar', label=\"female highclass\", color='#FA2479')\nax1.set_xticklabels([u\"survived\", u\"decreased\"], rotation=0)\nax1.legend([u\"female\/top\"], loc='best')\n\nax2=fig.add_subplot(142, sharey=ax1)\n#plt.figure()\ndata_train.Survived[data_train.Sex == 'female'][data_train.Pclass == 3].value_counts().plot(kind='bar', label='female, low class', color='pink')\nax2.set_xticklabels([u\"decreased\", u\"survived\"], rotation=0)\nplt.legend([u\"female\/low\"], loc='best')\n\nax3=fig.add_subplot(143, sharey=ax1)\n#plt.figure()\ndata_train.Survived[data_train.Sex == 'male'][data_train.Pclass != 3].value_counts().plot(kind='bar', label='male, high class',color='lightblue')\nax3.set_xticklabels([u\"decreased\", u\"survived\"], rotation=0)\nplt.legend([u\"male\/top\"], loc='best')\n\nax4=fig.add_subplot(144, sharey=ax1)\n#plt.figure()\ndata_train.Survived[data_train.Sex == 'male'][data_train.Pclass == 3].value_counts().plot(kind='bar', label='male low class', color='steelblue')\nax4.set_xticklabels([u\"decreased\", u\"survived\"], rotation=0)\nplt.legend([u\"male\/low\"], loc='best')\n\n#plt.show()","208b16cc":"fig = plt.figure()\nfig.set(alpha=0.2)  # \u8bbe\u5b9a\u56fe\u8868\u989c\u8272alpha\u53c2\u6570\n\nSurvived_0 = data_train.Embarked[data_train.Survived == 0].value_counts()\nSurvived_1 = data_train.Embarked[data_train.Survived == 1].value_counts()\ndf=pd.DataFrame({u'survied':Survived_1, u'decreased':Survived_0})\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"survived per port\")\nplt.xlabel(u\"port\") \nplt.ylabel(u\"count\") \n","3176717d":"g = data_train.groupby(['SibSp','Survived'])\ndf = pd.DataFrame(g.count()['PassengerId'])\nprint(df)\n\ng = data_train.groupby(['SibSp','Survived'])\ndf = pd.DataFrame(g.count()['PassengerId'])\nprint(df)","a94f5040":"\n#ticket\u662f\u8239\u7968\u7f16\u53f7\uff0c\u5e94\u8be5\u662funique\u7684\uff0c\u548c\u6700\u540e\u7684\u7ed3\u679c\u6ca1\u6709\u592a\u5927\u7684\u5173\u7cfb\uff0c\u5148\u4e0d\u7eb3\u5165\u8003\u8651\u7684\u7279\u5f81\u8303\u7574\u628a\n#cabin\u53ea\u6709204\u4e2a\u4e58\u5ba2\u6709\u503c\uff0c\u6211\u4eec\u5148\u770b\u770b\u5b83\u7684\u4e00\u4e2a\u5206\u5e03\ndata_train.Cabin.value_counts()\n","2c88c571":"fig = plt.figure()\nfig.set(alpha=0.2)  # \u8bbe\u5b9a\u56fe\u8868\u989c\u8272alpha\u53c2\u6570\n\nSurvived_cabin = data_train.Survived[pd.notnull(data_train.Cabin)].value_counts()\nSurvived_nocabin = data_train.Survived[pd.isnull(data_train.Cabin)].value_counts()\ndf=pd.DataFrame({u'has':Survived_cabin, u'no':Survived_nocabin}).transpose()\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"Cabin has or not\")\nplt.xlabel(u\"Cabin has or not\") \nplt.ylabel(u\"count\")\nplt.show()","ba44862d":"from sklearn.ensemble import RandomForestRegressor\n \n### \u4f7f\u7528 RandomForestClassifier \u586b\u8865\u7f3a\u5931\u7684\u5e74\u9f84\u5c5e\u6027\ndef set_missing_ages(df):\n    \n    # \u628a\u5df2\u6709\u7684\u6570\u503c\u578b\u7279\u5f81\u53d6\u51fa\u6765\u4e22\u8fdbRandom Forest Regressor\u4e2d\n    age_df = df[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n    \n    \n    # \u4e58\u5ba2\u5206\u6210\u5df2\u77e5\u5e74\u9f84\u548c\u672a\u77e5\u5e74\u9f84\u4e24\u90e8\u5206\n    #known_age = age_df[age_df.Age.notnull()].as_matrix()\n    #unknown_age = age_df[age_df.Age.isnull()].as_matrix()\n    known_age = age_df[age_df.Age.notnull()].values\n    unknown_age = age_df[age_df.Age.isnull()].values\n    \n    # y\u5373\u76ee\u6807\u5e74\u9f84 \u53d6\u7b2c\u4e00\u884c\u540e\u9762\u7684\n    y = known_age[:, 0]\n\n    # X\u5373\u7279\u5f81\u5c5e\u6027\u503c \u53d6\u7b2c\u4e00\u884c\u540e\u9762\u7684\n    X = known_age[:, 1:]\n    \n    print(X.shape, y.shape, unknown_age.shape)\n    \n    # fit\u5230RandomForestRegressor\u4e4b\u4e2d \n    # \u6ce8\uff1aRandomForest\u662f\u4e00\u4e2a\u7528\u5728\u539f\u59cb\u6570\u636e\u4e2d\u505a\u4e0d\u540c\u91c7\u6837\uff0c\u5efa\u7acb\u591a\u9897DecisionTree\uff0c\u518d\u8fdb\u884caverage\u7b49\u7b49\u6765\u964d\u4f4e\u8fc7\u62df\u5408\u73b0\u8c61\uff0c\u63d0\u9ad8\u7ed3\u679c\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u6211\u4eec\u4e4b\u540e\u4f1a\u4ecb\u7ecd\u5230\n    rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)\n    rfr.fit(X, y)\n        \n    # \u7528\u5f97\u5230\u7684\u6a21\u578b\u8fdb\u884c\u672a\u77e5\u5e74\u9f84\u7ed3\u679c\u9884\u6d4b\n    predictedAges = rfr.predict(unknown_age[:, 1:])\n    \n    print(predictedAges)\n    \n    # \u7528\u5f97\u5230\u7684\u9884\u6d4b\u7ed3\u679c\u586b\u8865\u539f\u7f3a\u5931\u6570\u636e\n    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n    \n    return df, rfr\n\ndef set_Cabin_type(df):\n    df.loc[ (df.Cabin.notnull()), 'Cabin' ] = \"Yes\"\n    df.loc[ (df.Cabin.isnull()), 'Cabin' ] = \"No\"\n    return df\n\n#data_train.info\ndata_train, rfr = set_missing_ages(data_train)\ndata_train = set_Cabin_type(data_train)\n","38aeef51":"\ndef DataPreProccess(data_train):\n    data_train[\"Title\"] = data_train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n    #pd.crosstab(data_train['Title'], data_train['Sex'])\n\n    data_train['Title'] = data_train['Title'].replace('Mlle', 'Miss')\n    data_train['Title'] = data_train['Title'].replace('Ms', 'Miss')\n    data_train['Title'] = data_train['Title'].replace('Mme', 'Mrs')\n\n    data_train['Title'] = data_train['Title'].replace(['Lady', 'Countess','Capt','Col','Don', 'Dr', 'Major','Rev', 'Sir', 'Jonkheer', 'Dona'], 'Not married')\n    data_train['Title'] = data_train['Title'].replace(['Mr', 'Mrs'], 'Married')\n\n    #pd.crosstab(data_train['Title'], data_train['Sex'])\n    data_train[\"Surname\"] = data_train['Name'].str.split(',').str.get(0)\n\n    # \u8865\u5145family \u5c5e\u6027\n    data_train['Family']=data_train['SibSp']+data_train['Parch']+1\n    #data_train=data_train.drop(['SibSp','Parch'],axis=1)\n\n    def FamilyGroup(family):\n        a=''\n        if family<=1:\n            a='Solo'\n        elif family<=4:\n            a='Small'\n        else:\n            a='Large'\n        return a\n    data_train['FamilyGroup']=data_train['Family'].map(FamilyGroup)\n    #data_train=data_train.drop(['Family'],axis=1)  \n\n    # \u5e74\u9f84\u5206\u5c42\n    def AgeGroup(age):\n        a=''\n        if age<=15:\n            a='Child'\n        elif age<=30:\n            a='Young'\n        elif age<=50:\n            a='Adult'\n        else:\n            a='Old'\n        return a\n    data_train['AgeGroup']=data_train['Age'].map(AgeGroup)\n    #data_train=data_train.drop(['Age'],axis=1)\n\n    # \u540e\u9762\u4f1a drop \u540d\u5b57\u7684\n    #data_train\n\n    df=pd.get_dummies(data_train,columns=['Sex','Embarked','FamilyGroup','AgeGroup','Cabin', 'Pclass', 'Title'])\n\n    #df = pd.concat([data_train, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\n    df.drop(['Name', 'Ticket', 'Family', 'SibSp','Parch', 'Surname'], axis=1, inplace=True)\n    return df\ndf = DataPreProccess(data_train)\ndf","06c4de5c":"data_train.info\ndata_train.describe","864edea4":"# \u7279\u5f81\u56e0\u5b50\u5316 \u4e8c\u5143\u7684\u5e94\u8be5\u4e0d\u7528\u5427\n# https:\/\/blog.csdn.net\/zs15321583801\/article\/details\/79652045\n\"\"\"\ndummies_Cabin = pd.get_dummies(data_train['Cabin'], prefix= 'Cabin')\n\ndummies_Embarked = pd.get_dummies(data_train['Embarked'], prefix= 'Embarked')\n\ndummies_Sex = pd.get_dummies(data_train['Sex'], prefix= 'Sex')\n\ndummies_Pclass = pd.get_dummies(data_train['Pclass'], prefix= 'Pclass')\n\"\"\"\n\ndf=pd.get_dummies(data_train,columns=['Sex','Embarked','FamilyGroup','AgeGroup','Cabin', 'Pclass', 'Title'])\n\n#df = pd.concat([data_train, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\ndf.drop(['Name', 'Ticket', 'Family', 'SibSp','Parch', 'Surname'], axis=1, inplace=True)\ndf","3cc5974c":"# \u5bf9  age \u548c fare \u505a\u5f52\u4e00\u5316 \nimport sklearn.preprocessing as preprocessing\n\ndef stdAgeAndFare(df):\n    scaler = preprocessing.StandardScaler()\n    col_names = ['Age', 'Fare']\n    #age_scale_param = scaler.fit(df['Age'].values)\n    features = df[col_names]\n    scaler = scaler.fit(features.values)\n    features = scaler.transform(features.values)\n    df[col_names] = features\n    return df\ndf = stdAgeAndFare(df)\ndf","773ab18e":"from sklearn import linear_model\n\n# \u7528\u6b63\u5219\u53d6\u51fa\u6211\u4eec\u8981\u7684\u5c5e\u6027\u503c\n#train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n# \u8fd9\u4e2a\u76f4\u63a5\u53d6\u5217\u4e0d\u5c31\u884c\u4e86 \uff0c \u73ed\u95e8\u5f04\u65a7\n__regTxt__ = 'Survived|Age|Fare|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*|FamilyGroup_.*|AgeGroup_.*|Title_.*'\ntrain_df = df.filter(regex=__regTxt__)\ntrain_np = train_df.values\n\n# y\u5373Survival\u7ed3\u679c\ny = train_np[:, 0]\n\n# X\u5373\u7279\u5f81\u5c5e\u6027\u503c\nX = train_np[:, 1:]\n\n# fit\u5230RandomForestRegressor\u4e4b\u4e2d\nclf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\nclf.fit(X, y)\n    \nclf","456c7d3e":"\ndata_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ndata_test.loc[ (data_test.Fare.isnull()), 'Fare' ] = 0\n# \u63a5\u7740\u6211\u4eec\u5bf9test_data\u505a\u548ctrain_data\u4e2d\u4e00\u81f4\u7684\u7279\u5f81\u53d8\u6362\n# \u9996\u5148\u7528\u540c\u6837\u7684RandomForestRegressor\u6a21\u578b\u586b\u4e0a\u4e22\u5931\u7684\u5e74\u9f84\ntmp_df = data_test[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\nnull_age = tmp_df[data_test.Age.isnull()].values\n# \u6839\u636e\u7279\u5f81\u5c5e\u6027X\u9884\u6d4b\u5e74\u9f84\u5e76\u8865\u4e0a\nX = null_age[:, 1:]\npredictedAges = rfr.predict(X)\ndata_test.loc[ (data_test.Age.isnull()), 'Age' ] = predictedAges\n\ndata_test = set_Cabin_type(data_test)\n\"\"\"\ndummies_Cabin = pd.get_dummies(data_test['Cabin'], prefix= 'Cabin')\ndummies_Embarked = pd.get_dummies(data_test['Embarked'], prefix= 'Embarked')\ndummies_Sex = pd.get_dummies(data_test['Sex'], prefix= 'Sex')\ndummies_Pclass = pd.get_dummies(data_test['Pclass'], prefix= 'Pclass')\n\n\ndf_test = pd.concat([data_test, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\ndf_test.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n\"\"\"\ndf_test = DataPreProccess(data_test)\ndf_test = stdAgeAndFare(df_test)\n\n\"\"\"\nscaler = preprocessing.StandardScaler()\n\n\ncol_names = ['Age', 'Fare']\n#col_names2 = ['Age_scaled', 'Fare_scaled']\n#age_scale_param = scaler.fit(df['Age'].values)\nfeatures = df_test[col_names]\nscaler = scaler.fit(features.values)\nfeatures = scaler.transform(features.values)\ndf_test[col_names] = features\n\"\"\"\n\n#data_test, rfr_test = set_missing_ages(data_test)\n#data_test = set_Cabin_type(data_test)\n#df_test = DataPreProccess(data_test)\n#df_test = stdAgeAndFare(df_test)\n#df_test\ndata_test.info()","d29cfe63":"#test = df_test.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\ntest = df_test.filter(regex=__regTxt__)\npredictions = clf.predict(test)\n#result = pd.DataFrame({'PassengerId':data_test['PassengerId'].as_matrix(), 'Survived':predictions.astype(np.int32)})\nresult = pd.DataFrame({'PassengerId':data_test['PassengerId'].values, 'Survived':predictions.astype(np.int32)})\n#result.to_csv(\"\/logistic_regression_predictions.csv\", index=False)\nresult.to_csv(\"logistic_regression_predictions.csv\", index=False)","cf9bac94":"#!cat \/logistic_regression_predictions.csv\n#result.describe","97956905":"# \u7ebf\u6027\u56de\u5f52\u7684\u76f8\u5173\u6027\nDataFrame({\"columns\":list(train_df.columns)[1:], \"coef\":list(clf.coef_.T)})","c575d457":"from sklearn.model_selection import cross_val_score, train_test_split\n\n #\u7b80\u5355\u770b\u770b\u6253\u5206\u60c5\u51b5\nclf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\n#all_data = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\nall_data = df.filter(regex=__regTxt__)\nX = all_data.values[:,1:]\ny = all_data.values[:,0]\ncross_val_score(clf, X, y, cv=5)","de82b5e2":"# \u67e5badcase\n# \u5206\u5272\u6570\u636e\uff0c\u6309\u7167 \u8bad\u7ec3\u6570\u636e:cv\u6570\u636e = 7:3\u7684\u6bd4\u4f8b\n#reg_txt = 'Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*'\n#reg_txt = 'Survived|Age|SibSp|Parch|Fare|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*'\nsplit_train, split_cv = train_test_split(df, test_size=0.3, random_state=0)\ntrain_df = split_train.filter(regex=__regTxt__)\n# \u751f\u6210\u6a21\u578b\nclf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\nclf.fit(train_df.values[:,1:], train_df.values[:,0])\n\n# \u5bf9cross validation\u6570\u636e\u8fdb\u884c\u9884\u6d4b\n\ncv_df = split_cv.filter(regex=__regTxt__)\npredictions = clf.predict(cv_df.values[:,1:])\n\norigin_data_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nbad_cases = origin_data_train.loc[origin_data_train['PassengerId'].isin(split_cv[predictions != cv_df.values[:,0]]['PassengerId'].values)]\nbad_cases","5fe7572c":"data_train[data_train['Name'].str.contains(\"Major\")]","40535bd4":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\n\n# \u7528sklearn\u7684learning_curve\u5f97\u5230training_score\u548ccv_score\uff0c\u4f7f\u7528matplotlib\u753b\u51falearning curve\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, \n                        train_sizes=np.linspace(.05, 1., 20), verbose=0, plot=True):\n    \"\"\"\n    \u753b\u51fadata\u5728\u67d0\u6a21\u578b\u4e0a\u7684learning curve.\n    \u53c2\u6570\u89e3\u91ca\n    ----------\n    estimator : \u4f60\u7528\u7684\u5206\u7c7b\u5668\u3002\n    title : \u8868\u683c\u7684\u6807\u9898\u3002\n    X : \u8f93\u5165\u7684feature\uff0cnumpy\u7c7b\u578b\n    y : \u8f93\u5165\u7684target vector\n    ylim : tuple\u683c\u5f0f\u7684(ymin, ymax), \u8bbe\u5b9a\u56fe\u50cf\u4e2d\u7eb5\u5750\u6807\u7684\u6700\u4f4e\u70b9\u548c\u6700\u9ad8\u70b9\n    cv : \u505across-validation\u7684\u65f6\u5019\uff0c\u6570\u636e\u5206\u6210\u7684\u4efd\u6570\uff0c\u5176\u4e2d\u4e00\u4efd\u4f5c\u4e3acv\u96c6\uff0c\u5176\u4f59n-1\u4efd\u4f5c\u4e3atraining(\u9ed8\u8ba4\u4e3a3\u4efd)\n    n_jobs : \u5e76\u884c\u7684\u7684\u4efb\u52a1\u6570(\u9ed8\u8ba41)\n    \"\"\"\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    if plot:\n        plt.figure()\n        plt.title(title)\n        if ylim is not None:\n            plt.ylim(*ylim)\n        plt.xlabel(u\"sample count\")\n        plt.ylabel(u\"score\")\n        plt.gca().invert_yaxis()\n        plt.grid()\n    \n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n                         alpha=0.1, color=\"b\")\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n                         alpha=0.1, color=\"r\")\n        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\", label=u\"trainning sorce\")\n        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\", label=u\"cross validate sorce\")\n    \n        plt.legend(loc=\"best\")\n        \n        plt.draw()\n        plt.show()\n        plt.gca().invert_yaxis()\n    \n    midpoint = ((train_scores_mean[-1] + train_scores_std[-1]) + (test_scores_mean[-1] - test_scores_std[-1])) \/ 2\n    diff = (train_scores_mean[-1] + train_scores_std[-1]) - (test_scores_mean[-1] - test_scores_std[-1])\n    return midpoint, diff\n\nplot_learning_curve(clf, u\"learning curve\", X, y)","98e43085":"from sklearn.ensemble import BaggingRegressor\n\n#train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*|Mother|Child|Family|Title')\n#_reg_txt = 'Survived|Age|SibSp|Parch|Fare|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*|Mother|Child|Family|Title'\ntrain_df = df.filter(regex=__regTxt__)\ntrain_np = train_df.values\n\n# y\u5373Survival\u7ed3\u679c\ny = train_np[:, 0]\n\n# X\u5373\u7279\u5f81\u5c5e\u6027\u503c\nX = train_np[:, 1:]\n\n# fit\u5230BaggingRegressor\u4e4b\u4e2d\nclf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\nbagging_clf = BaggingRegressor(clf, n_estimators=20, max_samples=0.8, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=-1)\nbagging_clf.fit(X, y)\n\ntest = df_test.filter(regex=__regTxt__)\npredictions = bagging_clf.predict(test)\nresult = pd.DataFrame({'PassengerId':data_test['PassengerId'].values, 'Survived':predictions.astype(np.int32)})\nresult.to_csv(\"logistic_regression_bagging_predictions.csv\", index=False)","518e1acb":"# \u7279\u5f81\u5de5\u7a0b\uff0c\u5bf9\u7f3a\u5931\u503c\u8865\u5168","5e76ab80":"# \u903b\u8f91\u56de\u5f52baseline","d83bb889":"- Sex\u5c5e\u6027\uff0c\u5982\u679c\u662ffemale\u4f1a\u6781\u5927\u63d0\u9ad8\u6700\u540e\u83b7\u6551\u7684\u6982\u7387\uff0c\u800cmale\u4f1a\u5f88\u5927\u7a0b\u5ea6\u62c9\u4f4e\u8fd9\u4e2a\u6982\u7387\u3002\n- Pclass\u5c5e\u6027\uff0c1\u7b49\u8231\u4e58\u5ba2\u6700\u540e\u83b7\u6551\u7684\u6982\u7387\u4f1a\u4e0a\u5347\uff0c\u800c\u4e58\u5ba2\u7b49\u7ea7\u4e3a3\u4f1a\u6781\u5927\u5730\u62c9\u4f4e\u8fd9\u4e2a\u6982\u7387\u3002\n- \u6709Cabin\u503c\u4f1a\u5f88\u5927\u7a0b\u5ea6\u62c9\u5347\u6700\u540e\u83b7\u6551\u6982\u7387(\u8fd9\u91cc\u4f3c\u4e4e\u80fd\u770b\u5230\u4e86\u4e00\u70b9\u7aef\u502a\uff0c\u4e8b\u5b9e\u4e0a\u4ece\u6700\u4e0a\u9762\u7684\u6709\u65e0Cabin\u8bb0\u5f55\u7684Survived\u5206\u5e03\u56fe\u4e0a\u770b\u51fa\uff0c\u5373\u4f7f\u6709Cabin\u8bb0\u5f55\u7684\u4e58\u5ba2\u4e5f\u6709\u4e00\u90e8\u5206\u9047\u96be\u4e86\uff0c\u4f30\u8ba1\u8fd9\u4e2a\u5c5e\u6027\u4e0a\u6211\u4eec\u6316\u6398\u8fd8\u4e0d\u591f)\n- Age\u662f\u4e00\u4e2a\u8d1f\u76f8\u5173\uff0c\u610f\u5473\u7740\u5728\u6211\u4eec\u7684\u6a21\u578b\u91cc\uff0c\u5e74\u9f84\u8d8a\u5c0f\uff0c\u8d8a\u6709\u83b7\u6551\u7684\u4f18\u5148\u6743(\u8fd8\u5f97\u56de\u539f\u6570\u636e\u770b\u770b\u8fd9\u4e2a\u662f\u5426\u5408\u7406\uff09\n- \u6709\u4e00\u4e2a\u767b\u8239\u6e2f\u53e3S\u4f1a\u5f88\u5927\u7a0b\u5ea6\u62c9\u4f4e\u83b7\u6551\u7684\u6982\u7387\uff0c\u53e6\u5916\u4fe9\u6e2f\u53e3\u538b\u6839\u5c31\u6ca1\u5565\u4f5c\u7528(\u8fd9\u4e2a\u5b9e\u9645\u4e0a\u975e\u5e38\u5947\u602a\uff0c\u56e0\u4e3a\u6211\u4eec\u4ece\u4e4b\u524d\u7684\u7edf\u8ba1\u56fe\u4e0a\u5e76\u6ca1\u6709\u770b\u5230S\u6e2f\u53e3\u7684\u83b7\u6551\u7387\u975e\u5e38\u4f4e\uff0c\u6240\u4ee5\u4e5f\u8bb8\u53ef\u4ee5\u8003\u8651\u628a\u767b\u8239\u6e2f\u53e3\u8fd9\u4e2afeature\u53bb\u6389\u8bd5\u8bd5)\u3002\n- \u8239\u7968Fare\u6709\u5c0f\u5e45\u5ea6\u7684\u6b63\u76f8\u5173(\u5e76\u4e0d\u610f\u5473\u7740\u8fd9\u4e2afeature\u4f5c\u7528\u4e0d\u5927\uff0c\u6709\u53ef\u80fd\u662f\u6211\u4eec\u7ec6\u5316\u7684\u7a0b\u5ea6\u8fd8\u4e0d\u591f\uff0c\u4e3e\u4e2a\u4f8b\u5b50\uff0c\u8bf4\u4e0d\u5b9a\u6211\u4eec\u5f97\u5bf9\u5b83\u79bb\u6563\u5316\uff0c\u518d\u5206\u81f3\u5404\u4e2a\u4e58\u5ba2\u7b49\u7ea7\u4e0a\uff1f)\n","2aacb3e9":"# \u67e5\u9a8c\u6574\u4f53\u60c5\u51b5","4e0f427c":"# learning curve","5945c0d1":"- Age\u5c5e\u6027\u4e0d\u4f7f\u7528\u73b0\u5728\u7684\u62df\u5408\u65b9\u5f0f\uff0c\u800c\u662f\u6839\u636e\u540d\u79f0\u4e2d\u7684\u300eMr\u300f\u300eMrs\u300f\u300eMiss\u300f\u7b49\u7684\u5e73\u5747\u503c\u8fdb\u884c\u586b\u5145\u3002\n- Age\u4e0d\u505a\u6210\u4e00\u4e2a\u8fde\u7eed\u503c\u5c5e\u6027\uff0c\u800c\u662f\u4f7f\u7528\u4e00\u4e2a\u6b65\u957f\u8fdb\u884c\u79bb\u6563\u5316\uff0c\u53d8\u6210\u79bb\u6563\u7684\u7c7b\u76eefeature\u3002\n- Cabin\u518d\u7ec6\u5316\u4e00\u4e9b\uff0c\u5bf9\u4e8e\u6709\u8bb0\u5f55\u7684Cabin\u5c5e\u6027\uff0c\u6211\u4eec\u5c06\u5176\u5206\u4e3a\u524d\u9762\u7684\u5b57\u6bcd\u90e8\u5206(\u6211\u731c\u662f\u4f4d\u7f6e\u548c\u8239\u5c42\u4e4b\u7c7b\u7684\u4fe1\u606f) \u548c \u540e\u9762\u7684\u6570\u5b57\u90e8\u5206(\u5e94\u8be5\u662f\u623f\u95f4\u53f7\uff0c\u6709\u610f\u601d\u7684\u4e8b\u60c5\u662f\uff0c\u5982\u679c\u4f60\u4ed4\u7ec6\u770b\u770b\u539f\u59cb\u6570\u636e\uff0c\u4f60\u4f1a\u53d1\u73b0\uff0c\u8fd9\u4e2a\u503c\u5927\u7684\u60c5\u51b5\u4e0b\uff0c\u4f3c\u4e4e\u83b7\u6551\u7684\u53ef\u80fd\u6027\u9ad8\u4e00\u4e9b)\u3002\n- Pclass\u548cSex\u4fe9\u592a\u91cd\u8981\u4e86\uff0c\u6211\u4eec\u8bd5\u7740\u7528\u5b83\u4eec\u53bb\u7ec4\u51fa\u4e00\u4e2a\u7ec4\u5408\u5c5e\u6027\u6765\u8bd5\u8bd5\uff0c\u8fd9\u4e5f\u662f\u53e6\u5916\u4e00\u79cd\u7a0b\u5ea6\u7684\u7ec6\u5316\u3002\n- \u5355\u52a0\u4e00\u4e2aChild\u5b57\u6bb5\uff0cAge<=12\u7684\uff0c\u8bbe\u4e3a1\uff0c\u5176\u4f59\u4e3a0(\u4f60\u53bb\u770b\u770b\u6570\u636e\uff0c\u786e\u5b9e\u5c0f\u76c6\u53cb\u4f18\u5148\u7a0b\u5ea6\u5f88\u9ad8\u554a)\n- \u5982\u679c\u540d\u5b57\u91cc\u9762\u6709\u300eMrs\u300f\uff0c\u800cParch>1\u7684\uff0c\u6211\u4eec\u731c\u6d4b\u5979\u53ef\u80fd\u662f\u4e00\u4e2a\u6bcd\u4eb2\uff0c\u5e94\u8be5\u83b7\u6551\u7684\u6982\u7387\u4e5f\u4f1a\u63d0\u9ad8\uff0c\u56e0\u6b64\u53ef\u4ee5\u591a\u52a0\u4e00\u4e2aMother\u5b57\u6bb5\uff0c\u6b64\u79cd\u60c5\u51b5\u4e0b\u8bbe\u4e3a1\uff0c\u5176\u4f59\u60c5\u51b5\u4e0b\u8bbe\u4e3a0\n- \u767b\u8239\u6e2f\u53e3\u53ef\u4ee5\u8003\u8651\u5148\u53bb\u6389\u8bd5\u8bd5(Q\u548cC\u672c\u6765\u5c31\u6ca1\u6743\u91cd\uff0cS\u6709\u70b9\u8be1\u5f02)\n- \u628a\u5802\u5144\u5f1f\/\u5144\u59b9 \u548c Parch \u8fd8\u6709\u81ea\u5df1 \u4e2a\u6570\u52a0\u5728\u4e00\u8d77\u7ec4\u4e00\u4e2aFamily_size\u5b57\u6bb5(\u8003\u8651\u5230\u5927\u5bb6\u65cf\u53ef\u80fd\u5bf9\u6700\u540e\u7684\u7ed3\u679c\u6709\u5f71\u54cd)\n- Name\u662f\u4e00\u4e2a\u6211\u4eec\u4e00\u76f4\u6ca1\u6709\u89e6\u78b0\u7684\u5c5e\u6027\uff0c\u6211\u4eec\u53ef\u4ee5\u505a\u4e00\u4e9b\u7b80\u5355\u7684\u5904\u7406\uff0c\u6bd4\u5982\u8bf4\u7537\u6027\u4e2d\u5e26\u67d0\u4e9b\u5b57\u773c\u7684(\u2018Capt\u2019, \u2018Don\u2019, \u2018Major\u2019, \u2018Sir\u2019)\u53ef\u4ee5\u7edf\u4e00\u5230\u4e00\u4e2aTitle\uff0c\u5973\u6027\u4e5f\u4e00\u6837\u3002","f0807636":"# test \u6570\u636e\u9884\u5904\u7406 ","2f03a369":"# Refference\nhttps:\/\/blog.csdn.net\/yaoqiang2011\/article\/details\/49797143","df92c48a":"## \u589e\u52a0Title \u7b49\u5c5e\u6027"}}