{"cell_type":{"68fc13aa":"code","ad4b2ce3":"code","55e87706":"code","0e3d3e88":"code","657f4439":"code","244c5726":"code","76d944f5":"code","7074f896":"code","6d7fcef1":"code","c6cfbd98":"code","2016d042":"code","af47e518":"code","eb65645f":"code","5b1328e4":"code","d08e640d":"markdown","6eee7291":"markdown","7ea5de3f":"markdown","5b24677a":"markdown","4b6af6e8":"markdown","b4603f60":"markdown","9df6fc65":"markdown","712d4ff9":"markdown","34292c86":"markdown"},"source":{"68fc13aa":"import requests\nfrom bs4 import BeautifulSoup\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk import ngrams, FreqDist\n\nimport re\nfrom collections import Counter\n\nfrom wordcloud import WordCloud,STOPWORDS\nimport matplotlib.pyplot as plt\n%matplotlib inline","ad4b2ce3":"import codecs\n\nhtml = codecs.open(\"..\/input\/alice-in-wonderland-project-gutenberg\/11-h.htm\", 'r', 'utf-8')\nprint('Done!')","55e87706":"soup = BeautifulSoup(html)\n\ntext = soup.get_text()","0e3d3e88":"print(text[0:1500])","657f4439":"tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n\ntokens = tokenizer.tokenize(text)\n\nprint(tokens[:10])","244c5726":"print(\"Total number of words in the book is:\", len(tokens))","76d944f5":"counts = Counter(tokens)\nCounter(tokens).most_common(10)","7074f896":"words = [word.lower() for word in tokens]\n\nprint(words[:10])","6d7fcef1":"counts = Counter(words)\nCounter(counts).most_common(10)","c6cfbd98":"stop_words = nltk.corpus.stopwords.words('english')\n\nwords_filtered = [word for word in words if word not in stop_words]\nprint(words_filtered[:10])","2016d042":"len(words_filtered)","af47e518":"Counter(words_filtered).most_common(10)","eb65645f":"from matplotlib.pyplot import figure\n%matplotlib inline\n\nfreqdist = nltk.FreqDist(words_filtered)\n\n# Plotting the word frequency distribution\nfigure(figsize=(10,5))\nfreqdist.plot(25)","5b1328e4":"def show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        max_words=100,\n        max_font_size=50, \n        scale=3,\n        random_state=1 \n).generate(str(data))\n\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n\nshow_wordcloud(words_filtered)","d08e640d":"### 6. The most common words.\nFinally we can take a look at the most common words in the book.","6eee7291":"The goal of this text processing is to find the most common words. We can try to do this now.","7ea5de3f":"### 3. Removing non-words\nI will remove everything that isn't a word, for example whitespace, punctuation. Then I will split the text into list of seperate words - tokens. I will use the Natural Language Toolkit to do this.","5b24677a":"### 1. Workbook","4b6af6e8":"### 2. Get the text from the website","b4603f60":"No I will count all words in <em> Alice in Wonderland <\/em>.","9df6fc65":"### 4. Modify the words into lowercase.\nThe previous output is not reliable yet. We notice that the same words, such as `it` and `It`, which start with big or small letter, are counted as two different words. That is why, I will change all words to start with lower case.","712d4ff9":"### 5. Removing stop words\nWe may see that among the most occuring words are `the`, `a`, `of`. which are called **stop words**. For purpose of this text processing they are not too interesting, that is why I will remove them. \nNltk has a library of stop words.","34292c86":"\n<p><img style=\"float: centre ; margin: 5px 20px 5px 10px; width: 30%\" src=\"https:\/\/www.gutenberg.org\/files\/11\/11-h\/images\/cover.jpg\"> <\/p>\n<p>In this notebook I will scrape the novel by Lewis Carrol <em>Alice in Wonderland<\/em>, which is available on the website <a href=\"https:\/\/www.gutenberg.org\/\">Project Gutenberg<\/a>. <\/p>\n<p>The purpose of this text processing is to learn what are the most common words in the book. <\/p>\n"}}