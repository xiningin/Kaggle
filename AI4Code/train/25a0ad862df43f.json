{"cell_type":{"2e4d41bc":"code","494384d6":"code","3e4b1c91":"code","906dfb45":"code","18e69fb4":"code","ba5a2bf1":"code","57288633":"code","9c863b1b":"code","45450062":"code","39a4093c":"code","2ece1530":"code","999d6054":"code","be98689e":"code","6f02e306":"code","97e181c9":"code","5e6de1cb":"code","8a7b006b":"code","4a2473de":"code","8a05c972":"code","42148cd8":"code","c49a5924":"code","8e67b674":"code","c3a3467e":"code","70affb57":"code","a22fcd19":"code","ae5b9e06":"code","41ef664f":"code","cd59bd7c":"code","51138a5a":"code","9d7c5cd7":"code","894d34a1":"code","d954e187":"code","989e941e":"code","3244da19":"code","e04d5977":"code","255c75df":"code","426a164f":"code","b85e46ad":"code","8aa31118":"code","929aa9da":"code","0d945090":"code","1f741305":"code","955b1734":"code","a20e687a":"code","2fed313e":"code","3bb843f2":"code","6e0b72b0":"code","86abda02":"code","d25c9f5c":"code","3ca88291":"code","6b5c36ad":"markdown","5388fab2":"markdown","c5ed501f":"markdown","0699d238":"markdown","dcd44b43":"markdown","b47a2582":"markdown","90c914da":"markdown","24ed0ed2":"markdown","bfcc8904":"markdown","b9b27cb5":"markdown","985581ee":"markdown","3cbd06d5":"markdown","4d5e9319":"markdown","8fc66807":"markdown","0c266d48":"markdown","4db70aaa":"markdown"},"source":{"2e4d41bc":"!pip install -U seaborn","494384d6":"import seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly as pl\nimport lightgbm as lgb","3e4b1c91":"db=pd.read_csv('..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 4.csv',parse_dates=['Order Date'])\ndb.head()","906dfb45":"print('Checking null values in each Columns')\ndb.isnull().sum()","18e69fb4":"print(\"Bestseller :\",db['Book Name'].value_counts().nlargest(1,keep='all').to_frame().index.values[0]); # bestseller\nprint(\"Top City :\",db['City (Billing)'].value_counts().nlargest(1,keep='all').to_frame().index.values[0]); # top city for orders\n\ndb['Book Name'] = db['Book Name'].fillna('\u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba') # filling null values with most sold book\ndb['City (Billing)'] = db['City (Billing)'].fillna('Karachi') # filling null valuse with top city\n\ndisplay(\"Checking null values in each Columns\")\ndb.isnull().sum()","ba5a2bf1":"db['Date'] = [d.date() for d in db['Order Date']]\ndb['Time'] = [d.time() for d in db['Order Date']]\ndb['Month'] = [d.month for d in db['Order Date']]\ndb['Month_Year'] = [d.to_period(\"M\") for d in db['Order Date']]\ndb['Year'] = [d.year for d in db['Order Date']]\ndb['Weekday'] = [d.week for d in db['Order Date']]\ndb.head()","57288633":"cities=pd.read_csv('..\/input\/pakistan-cities\/pk.csv')\ncities.head()","9c863b1b":"cities['city'] = cities['city'].replace(['Sialkot City'],'Sialkot') # Replacing names for merggin DB","45450062":"geo=db['City (Billing)'].value_counts().rename_axis('City').reset_index(name='counts')\nclean_geo=geo.merge(cities,how='inner',left_on='City', right_on='city')\nclean_geo=clean_geo[[\"City\",\"lat\",\"lng\",\"admin_name\",\n         \"population_proper\",\"counts\"]]\nclean_geo=clean_geo.rename(columns={\"lat\":\"Latitude\",\"lng\":\"Longitude\",\n                                    \"population_proper\":\"Population\",\n                                    \"admin_name\":\"Province\",\"counts\":\"Total Orders\"})\nclean_geo.head()","39a4093c":"import plotly.graph_objects as go\n\n\nclean_geo['text'] = clean_geo['City'] + '<br> Book Sold ' + (clean_geo['Total Orders']).astype(str)\n# limits = [(0,99),(100,299),(300,499),(500,999),(1000,3000)]\n \nlimits = [(0,3),(3,9),(9,19),(19,49),(49,3000)]\ncolors = [\"royalblue\",\"crimson\",\"lightseagreen\",\"orange\",\"lightgrey\"]\nscale = 5000\n\nfig = go.Figure()\n\nfor i in range(len(limits)):\n    lim = limits[i]\n    df_sub = clean_geo[lim[0]:lim[1]]\n    fig.add_trace(go.Scattergeo(\n        lon = df_sub['Longitude'],\n        lat = df_sub['Latitude'],\n        text = df_sub['text'],\n        marker = dict(\n            size = df_sub['Total Orders'],\n            color = colors[i],\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode = 'area'\n        ),\n        name = 'Top {0} - {1}'.format(lim[0]+1,lim[1])))\n\nfig.update_layout(\n        title_text = 'Total Books Sold by Gufhtugu per City',\n        showlegend = True,\n        legend_title=\"Top Books\",\n        legend_title_font_size=14,\n        geo = dict(\n            scope = 'asia',\n            landcolor = 'rgb(217, 217, 217)',\n            lonaxis = dict(range = [60.578993, 82.65129]),\n            lataxis = dict(range = [24.407138, 36.885931]),\n            \n        ),\n        \n    )\n\nfig.show()","2ece1530":"month=db[['City (Billing)','Month']].value_counts().rename_axis(['City','Month']).reset_index(name='counts')\nmonth_geo=month.merge(clean_geo,how='inner',left_on='City', right_on='City').sort_values(['Month'])\nmonth_geo.head()","999d6054":"import plotly.express as px\n# df = px.data.gapminder()\npx.scatter(month_geo, x=\"Total Orders\", y=\"counts\", animation_frame=\"Month\", animation_group=\"City\",\n           size=\"counts\", color=\"Province\", hover_name=\"City\",title='Number of Books bought by cities over month',\n           log_x=True, size_max=40, range_x=[1,3000], range_y=[0,500])\n# px.update_xaxes(autorange=True)","be98689e":"weekday=db[['City (Billing)','Weekday']].value_counts().rename_axis(['City','Week']).reset_index(name='counts')\nweekday_geo=weekday.merge(clean_geo,how='inner',left_on='City', right_on='City').sort_values(['Week'])","6f02e306":"px.scatter(weekday_geo, x=\"Total Orders\", y=\"counts\", animation_frame=\"Week\", animation_group=\"City\",\n           size=\"counts\", color=\"Province\", hover_name=\"City\",title='Number of Books bought by cities over Week',\n           log_x=True, size_max=40, range_x=[1,3000], range_y=[0,200])","97e181c9":"# sns.set_theme(style=\"whitegrid\", palette=\"muted\")\ntotal_month=db['Month'].value_counts().rename_axis(['Month']).reset_index(name='counts')\nsns.set(rc={'figure.figsize':(12,8)},style=\"whitegrid\", palette=\"muted\")\n# Draw a categorical scatterplot to show each observation\nax = sns.barplot(data=total_month, x=\"Month\", y=\"counts\",palette='CMRmap')\nax.set(ylabel=\"\",title=\"Number of Books sold per month\",);\n# ax.legend(loc='upper right', bbox_to_anchor=(0.3, 1), ncol=1);","5e6de1cb":"db=db.merge(cities,how='left',left_on='City (Billing)', right_on='city').set_index('Order Number')\n","8a7b006b":"total=db[[\"Order Status\",\"Book Name\",\"Date\",\"Time\",\"City (Billing)\",\n         \"lat\",\"lng\",\"population_proper\",\"admin_name\",\"Month\"]]\ntotal=total.rename(columns={\"Order Status\":\"Status\",\"Book Name\":\"Book\",\"City (Billing)\":\"City\",\n         \"lat\":\"Latitude\",\"lng\":\"Longitude\",\"population_proper\":\"Population\",\"admin_name\":\"Province\"})\ntotal.head()","4a2473de":"import matplotlib as mpl\nax = sns.histplot(data=total, x=\"Month\", hue=\"Province\",\n    multiple=\"stack\",\n    palette=\"rocket\",\n    edgecolor=\".3\",binwidth=1,kde=True,\n    linewidth=.5)\nax.set(ylabel=\"\",title=\"Number of Books sold to province per month\")\nax.set_xticklabels([ \"\",'Feb', 'Apr','Jun','Aug','Oct','Dec']);","8a05c972":"status=db[['Order Status','Month']].value_counts().rename_axis(['Status','Month']).reset_index(name='counts')\npal = dict(Completed=\"#6495ED\", Returned=\"#F08080\",Canceled=\"#90ee90\")\n\n# Show the survival probability as a function of age and sex\ng = sns.lmplot(x=\"Month\", y=\"counts\", col=\"Status\", hue=\"Status\", data=status,\n               palette=pal, y_jitter=.02, logistic=False, truncate=True,);","42148cd8":"status_pro=total[['Status','Month','Province']].value_counts().rename_axis(['Status','Month','Province']).reset_index(name='counts')\n\n\ng = sns.relplot(\n    data=status_pro,\n    x=\"Month\", y=\"counts\",\n    hue=\"Status\", size=\"Province\",\n    palette=pal, sizes=(10, 200),alpha=0.9,height=8,aspect=1.2\n)\ng.set( yscale=\"log\")\ng.set(ylabel=\"\",title=\"Status of Books sold to Province per month\")\ng.despine(left=True, bottom=True);","c49a5924":"from catboost import CatBoostRegressor,Pool\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder","8e67b674":"train=db[['Order Status','Year','admin_name','City (Billing)','Weekday']].value_counts().rename_axis(['Status','Year','Province','City','Week']).reset_index(name='counts')","c3a3467e":"train[['Year','Week']]=train[['Year','Week']].astype('int')\n","70affb57":"DataX = train.drop(columns=['counts'])\nDatay = train['counts'].values\nx_train, x_val, y_train, y_val = train_test_split(DataX, Datay, test_size=0.3)","a22fcd19":"train_pool = Pool(x_train, \n                  y_train, \n                  cat_features=['Status','Province','City'])\ntest_pool = Pool(x_val, \n                  y_val, \n                  cat_features=['Status','Province','City'])","ae5b9e06":"model=CatBoostRegressor(iterations=10000,\n                             learning_rate=0.001,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             od_type='Iter',\n                             metric_period = 100,\n                             od_wait=100) # catboost is used for avoiding over fitting","41ef664f":"model.fit(train_pool,\n             eval_set=test_pool,\n             use_best_model=True,\n             verbose=False,plot=True);","cd59bd7c":"predict=model.predict(test_pool)","51138a5a":"res = model.calc_feature_statistics(train_pool,\n                                    feature=1,\n                                    plot=True)","9d7c5cd7":"import shap\nshap.initjs()","894d34a1":"explainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(x_train)\n\n# visualize the first prediction's explanation\nshap.force_plot(explainer.expected_value, shap_values[0,:], x_train.iloc[0,:])","d954e187":"shap.force_plot(explainer.expected_value, shap_values, x_train)","989e941e":"shap.dependence_plot(\"Week\", shap_values, x_train)","3244da19":"shap.summary_plot(shap_values, x_train)","e04d5977":"shap.force_plot(explainer.expected_value, shap_values[91,:],x_train.iloc[91,:])","255c75df":"x=range(len(predict))\ny=y_val\nax=sns.lineplot(x=x,y=y,label='Train',color='#9FD1FF')\nax=sns.lineplot(x=x,y=predict,label='Predicted',color='#FF8B8B')\nax.set(title='Trainig and predicted by Weekday data over the time');","426a164f":"Status ='Completed'\nYear = 2021\nProvince = 'Punjab'\nCity = 'Lahore'\nWeek= 20\ndata1 = [Status,Year,Province,City,Week]\ntest1 = model.predict(data1)","b85e46ad":"print(int(test1),\"Books Order\",Status,\"in week\",Week,\"-\",Year,\" from \",City,\",\",Province,\".\" )","8aa31118":"Status =['Completed','Completed','Completed','Returned']\nYear = [2021,2021,2022,2021]\nProvince = ['Punjab','Punjab','Sindh','Punjab']\nCity = ['Lahore','Bahawalpur','Karachi','Lahore']\nWeek= [20,10,13,14]\ndata2 = pd.DataFrame(np.transpose([Status,Year,Province,City,Week]),\n                     columns=['Status','Year','Province','City','Week'])\ntest2 = model.predict(data2).astype('int')","929aa9da":"for i in range(len(test2)):\n    print(i+1,')',test2[i],\"Books Order\",data2.Status[i],\"in\",\"in week\",data2.Week[i],\"-\",data2.Year[i],\n          \" from \",data2.City[i],\",\",data2.Province[i],\".\\n\" )","0d945090":"Week=DataX\nWeek['Year']=Week['Year'].replace([2019,2020],[2021,2022])\n\nypred=model.predict(Week)\nWeek['counts']=ypred.astype('int')\nTotaldf=pd.concat([train, Week], axis=0)\nTotaldf.shape","1f741305":"\nax=sns.lineplot(x='Week',y='counts',hue='Year',data=Totaldf,palette='Set2')\nax.set( yscale=\"log\")\nax.set(title='Trainig and predicted by Weekday data over the time');","955b1734":"train1=db[['Order Status','Month','Year','admin_name','City (Billing)']].value_counts().rename_axis(['Status','Month','Year','Province','City']).reset_index(name='counts')\ntrain1[['Year','Month']]=train1[['Year','Month']].astype('int')\nDataX = train1.drop(columns=['counts'])\nDatay = train1['counts'].values\nx_train, x_val, y_train, y_val = train_test_split(DataX, Datay, test_size=0.3)\ntrain_pool = Pool(x_train, \n                  y_train, \n                  cat_features=['Status','Province','City'])\ntest_pool = Pool(x_val, \n                  y_val, \n                  cat_features=['Status','Province','City'])","a20e687a":"model=CatBoostRegressor(iterations=10000,\n                             learning_rate=0.001,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             od_type='Iter',\n                             metric_period = 100,\n                             od_wait=100)\nmodel.fit(train_pool,\n             eval_set=test_pool,\n             use_best_model=True,\n             verbose=False,plot=True);","2fed313e":"predict=model.predict(test_pool)\nres = model.calc_feature_statistics(train_pool,\n                                    feature=1,\n                                    plot=True)","3bb843f2":"x=range(len(predict))\ny=y_val\nax=sns.lineplot(x=x,y=y,label='Train',color='#9FD1FF')\nax=sns.lineplot(x=x,y=predict,label='Predicted',color='#FF8B8B')\nax.set(title='Trainig and predicted by Month data over the time');","6e0b72b0":"Make = train1.drop(columns=['counts'])\nWeek=Make\nWeek['Year']=Week['Year'].replace([2019,2020],[2021,2022])\n\nypred=model.predict(Week)\nWeek['counts']=ypred.astype('int')\nTotal=pd.concat([train1, Week], axis=0)\nax=sns.lineplot(x='Month',y='counts',hue='Year',data=Total,palette='Set2')\nax.set( yscale=\"log\")\nax.set(title='Trainig and predicted by Month data over the time');","86abda02":"Year_books=db[['Book Name','Year']].value_counts().rename_axis(['Book','Year']).reset_index(name='counts')","d25c9f5c":"Year2019=Year_books[Year_books['Year']==2019].nlargest(10, 'counts')\nYear2020=Year_books[Year_books['Year']==2020].nlargest(10, 'counts')\nYear2021=Year_books[Year_books['Year']==2021].nlargest(10, 'counts')","3ca88291":"f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Generate some sequential data\nsns.barplot(x='Book', y='counts', palette=\"vlag\", ax=ax1,data=Year2019)\nax1.axhline(0, color=\"k\", clip_on=False)\nax1.set_ylabel(\"2019\")\n\n\n# Center the data to make it diverging\n\nsns.barplot(x='Book', y='counts', palette=\"vlag\", ax=ax2,data=Year2020)\nax2.axhline(0, color=\"k\", clip_on=False)\nax2.set_ylabel(\"2020\")\n\n# Randomly reorder the data to make it qualitative\n\nsns.barplot(x='Book', y='counts', palette=\"vlag\", ax=ax3,data=Year2021)\nax3.axhline(0, color=\"k\", clip_on=False)\nax3.set_ylabel(\"2021\")\n\n# Finalize the plot\nsns.despine(bottom=True)\nplt.setp(f.axes, yticks=[])\nfor p in ax1.patches:\n    ax1.annotate(format(p.get_height(), '1.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\nfor p in ax2.patches:\n    ax2.annotate(format(p.get_height(), '1.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\nfor p in ax3.patches:\n    ax3.annotate(format(p.get_height(), '1.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\n    \nax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\nax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\nax3.set_xticklabels(ax3.get_xticklabels(),rotation=90)\n\nax1.set_xticklabels([ \"Data Science\",'Kaggle', 'R ka Taaruf','(C++)','Apna Elaaj','Shaoor','Molo Masali',\n                    'Kaggle for Begginers','CryptoCurrency','Blockchain']);\nax2.set_xticklabels([ \"Earn Money\",'Python Programming','Product Management', 'Blockchain','Justju ka safar',\n                     'Artificial Intelligence','Molo Masali','(C++)',\n                    'Python Programming 2020','Sukkur To Florida','Blockchain']);\nax3.set_xticklabels([ \"Lucky Draw\",'Earn Money','Column Nigari', 'Python Programming','Waqfa e Pareshani',\n                     'Data Science','Arif Kareem','Machine Learning',\n                    'Artificial Intelligence','Blockchain']);\nplt.tight_layout(h_pad=2);","6b5c36ad":"## I dont know maybe this model need more featurse to predict better.","5388fab2":"# Work in progress \ud83d\udc68\u200d\ud83d\udd27 and if you like my work do \"up vote\" \u261d","c5ed501f":"## Simple Regression on Status","0699d238":"## Prediction by Month","dcd44b43":"# I will be updating my notebook everday so stay tune to learn more about how to used visulization and machine learning model for simple Classification and Regression.  \n\n> I will start explaining my thought prosse and explain the stroy of Gufhtugu Publications when I am done with coding.","b47a2582":"# Geographical Analysis ","90c914da":"# Exploring","24ed0ed2":"## **Importing Library**","bfcc8904":"## **Importing Datasets**","b9b27cb5":"## Catboost for Futher prediction","985581ee":"## Test model with real world orders","3cbd06d5":"## Best Seller","4d5e9319":"### Best Seller per year","8fc66807":"* In 2019 Data Science was a bestseller with 303 copies and the rest of the top ten don't even compete.\n* In 2020 trend changed as the pandemic started and people were stuck in the home so more people order the books online and the bestseller was Earn Money online with 2206 copies, which have a direct relationship with people losing jobs and stuck in their homes.\n* In 2021 we have limited data so we can assume that the sales have increased since the pandemic and people reading trend have changed. the best seller is Lucy Draw book which is a gift and the second, best was Earn Money online with 373 copies sold in the first few days.","0c266d48":"## Cleaning","4db70aaa":"## Prediction By Weekday"}}