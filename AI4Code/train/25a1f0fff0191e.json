{"cell_type":{"98f2de8b":"code","9bf9eafd":"code","ee1767bc":"code","cf94fe83":"code","64af2913":"code","e441d3a6":"code","5c2651b9":"code","de6c1326":"code","def979de":"code","59fa367d":"code","18246c23":"code","247d39ae":"code","20ef7f12":"code","7fa478f4":"code","211ad3b5":"code","1bad5244":"code","2e911d9f":"code","c9982a61":"code","156e6cdc":"code","a18bdbba":"code","861767aa":"code","f9022e0d":"code","324e88a7":"markdown","e3a26d35":"markdown","ec8d0957":"markdown","920c571e":"markdown","0fc8282b":"markdown","48581c6a":"markdown","688992d7":"markdown","a479789a":"markdown","9e4267ff":"markdown","12db9855":"markdown","bb6cb766":"markdown"},"source":{"98f2de8b":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","9bf9eafd":"df = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ndf.head()","ee1767bc":"import re\nimport string\nimport nltk\n# nltk.download('stopwords')\n# nltk.download('punkt')\n# nltk.download('wordnet')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\n\ndef preprocessing_text(text):\n    text = text.lower()\n    text = re.sub(r'd+','', text)\n    # remove punctuation\n    text = text.translate(str.maketrans('','',string.punctuation))\n    # removing spaces\n    text = text.strip()\n    # remove stopwords\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(text)\n    filtered_text = [word for word in word_tokens if word not in stop_words]\n    text = ' '.join(str(elem) for elem in filtered_text)\n    # steaming\n    stemmer = PorterStemmer()\n    token_text = word_tokenize(text)\n    for word in token_text:\n        # print(stemmer.stem(word))\n        text = text +' '+stemmer.stem(word)\n    # lemmatization\n    lemmatizer = WordNetLemmatizer()\n    input_text = word_tokenize(text)\n    for word in input_text:\n        text = text + '' + lemmatizer.lemmatize(word)\n    return text","cf94fe83":"df['process_text'] = ''\nfor i in range(0,len(df)):\n    df['process_text'][i] = preprocessing_text(df.excerpt[i])","64af2913":"df.head()","e441d3a6":"X = df.process_text\ny = df.target\n\n# splitting dataset for training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, shuffle=False)","5c2651b9":"# Initialize the `tfidf_vectorizer` \ntfidf_vectorizer = TfidfVectorizer() \n\n# Fit and transform the training data \ntfidf_train = tfidf_vectorizer.fit_transform(X_train) \n\n# Transform the test set \ntfidf_test = tfidf_vectorizer.transform(X_test)","de6c1326":"tfidf_train.shape, X_train.shape, tfidf_test.shape, X_test.shape","def979de":"type(tfidf_train)","59fa367d":"# converting sparse matrix to pandas dataframe\ntfidf_train_df = pd.DataFrame(tfidf_train.toarray())\ntfidf_test_df = pd.DataFrame(tfidf_test.toarray())","18246c23":"# keras tuner help us to choose number of layer and neurons in that layer\n# using randomsearch\n!pip install -U keras-tuner","247d39ae":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kerastuner.tuners import RandomSearch","20ef7f12":"def build_model(hp): # hp as a Hyperparameter\n    model = keras.Sequential()\n    for i in range(hp.Int('num_layers',2,30)): # minimum hidden layers 2 and maximum 30\n        model.add(layers.Dense(units=hp.Int('units_' + str(i), # he can choose any between them\n                                            min_value=20, # minimum neuron 20\n                                            max_value=1000, # maximum neuron 1000\n                                            step=32),\n                               activation='relu'))\n        model.add(layers.Dense(1,activation='linear')) # output layer only only contain 1 neuron\n        model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',[1e-2,1e-3,1e-4])), # hp.Choice we restrict his choice between fiven learning rates\n                      loss=keras.losses.MeanSquaredError(),metrics=['mse'])\n    return model","7fa478f4":"tuner = RandomSearch(\n    build_model,\n    objective='val_mse',\n    max_trials=3,  # total number of trials\n    executions_per_trial=3, # number of models that should be built and fit for each trial \n    directory='weights',\n    project_name='commonLit'\n)","211ad3b5":"tuner.search_space_summary()","1bad5244":"tuner.search(tfidf_train_df, y_train,\n             epochs=15,\n             validation_data=(tfidf_test_df, y_test))","2e911d9f":"tuner.results_summary()","c9982a61":"# give us best top 2 models\nmodels = tuner.get_best_models(num_models=2)","156e6cdc":"# we are predicting using best model\ny_pred = models[0].predict(tfidf_test_df)","a18bdbba":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrmse = sqrt(mean_squared_error(y_test, y_pred))\nprint('Root mean Square is :',rmse)","861767aa":"# structure of model\nmodels[0].summary()","f9022e0d":"from keras.models import load_model\n\nmodels[0].save('CommonLit NN.h5')  # creates a HDF5 file 'my_model.h5'\n\n# returns a compiled model\n# identical to the previous one\n# model = load_model('my_model.h5')","324e88a7":"# Read Data","e3a26d35":"# importing libraries","ec8d0957":"## Apply preprocessing on dataset","920c571e":"## Define a model-building function","0fc8282b":"## Best Model","48581c6a":"# Text Preprocessing","688992d7":"## seperate dependent and independent variables","a479789a":"### same as model.fit()","9e4267ff":"# Neural Network","12db9855":"## You can increase executions_per_trial & max_trial to reduce RMSE","bb6cb766":"# Apply TF-IDF"}}