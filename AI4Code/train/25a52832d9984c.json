{"cell_type":{"c0304698":"code","cbd66828":"code","9825b21b":"code","8d8645e0":"code","260040b7":"code","4cee5992":"code","b1952842":"code","bd0604c1":"code","3d442929":"code","8e75d30b":"code","98464c66":"code","07b4d00a":"code","4b281cd7":"code","21cac14f":"code","4b45befc":"code","99ca36f0":"code","89f767e5":"code","26394d5d":"code","31b360b1":"code","4e67631a":"code","aac52baa":"code","0f7408b5":"code","fa805da7":"code","7b6b6db1":"code","b1986057":"code","720f61d3":"code","439c223c":"code","8f809f0f":"code","c8e2f17a":"code","28b59255":"code","e335a359":"markdown","334840b3":"markdown","0508cb55":"markdown","887d7853":"markdown","47a1b9e8":"markdown"},"source":{"c0304698":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy\nfrom scipy.optimize import fmin # for blending\nimport os\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import linear_model\n","cbd66828":"def set_seed(seed = 42):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed()","9825b21b":"path = '..\/input\/tabular-playground-series-mar-2021\/'\n\ntrain_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\nsample_sub = pd.read_csv(path + 'sample_submission.csv')","8d8645e0":"cat_cols = train_df.select_dtypes(include='object').columns\ncont_cols = train_df.select_dtypes(exclude='object').columns","260040b7":"train_df['target'] = train_df['target'].astype(float)","4cee5992":"train_df.target.hist()","b1952842":"train_df.target.value_counts()","bd0604c1":"f, axes = plt.subplots(nrows=len(cat_cols), ncols=1, figsize=(30, 4 * len(cat_cols)))\n\nfor col, ax in zip(cat_cols, axes):\n    ax.hist(train_df[col])\n    ax.set_title(col)","3d442929":"f, axes = plt.subplots(nrows=len(cont_cols), ncols=3, figsize=(30, 4 * len(cont_cols)))\n\nfor col, ax in zip(cont_cols, axes):\n    g = sns.kdeplot(train_df[col], shade=True, label=\"%.2f\"%(train_df[col].skew()), ax=ax[0])\n    g = g.legend(loc=\"best\")\n    scipy.stats.probplot(train_df[col], plot=ax[1])\n    sns.boxplot(x=col, data=train_df, orient='h', ax=ax[2]);","8e75d30b":"corr = train_df[cont_cols].corr().abs()\n\nfig, ax = plt.subplots(figsize=(14, 14))\n\nsns.heatmap(corr, mask=None, annot=True, fmt=\".2f\", cmap='coolwarm',\n            cbar_kws={\"shrink\": .8}, vmin=0, vmax=1)\n\nplt.yticks(rotation=0)\nplt.show()","98464c66":"n_folds = 5\n\ndef trainFn(model_fn, data, target, cv=None, test=None, predict_proba=False):\n    \n    if cv is not None:\n        OOF = np.zeros_like(train_df.target.values)\n    else:\n        cv = KFold(5)\n\n    if test is not None:\n        test_preds = np.zeros_like(sample_sub.target.values)\n\n    for fold, (train_idx, val_idx) in enumerate(cv.split(data)):\n        \n        print(f'Fold: {fold + 1}')\n        \n        train_X, val_X = data[train_idx], data[val_idx]\n        train_y, val_y = target[train_idx], target[val_idx]\n        model = model_fn()\n        \n        \n        model.fit(train_X, train_y)\n        \n        if predict_proba:\n            preds = model.predict_proba(val_X)[:, -1]\n        else:\n            preds = model.predict(val_X)\n        \n        OOF[val_idx] += preds\n        \n        print(f'\\tauc: {roc_auc_score(val_y, preds)}')\n        \n        if test is not None:\n            if predict_proba:\n                test_preds += model.predict_proba(test)[:, -1]\n            else:\n                test_preds += model.predict(test)\n    \n    oof_auc = roc_auc_score(train_df.target.astype(int).values, OOF)\n    print(f'OOF auc: {oof_auc}')\n    \n    if test is not None and cv is not None:\n        test_preds \/= n_folds\n        \n    return OOF, oof_auc, test_preds","07b4d00a":"# one hot encoding\npipeline1 = make_pipeline(\n    ColumnTransformer([\n        ('oh', OneHotEncoder(handle_unknown = 'ignore'), cat_cols)\n    ],\n    remainder = 'passthrough')\n)","4b281cd7":"results = dict()","21cac14f":"OOF1, oof_auc1, test_preds1 = trainFn(model_fn = linear_model.LinearRegression,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df))\n\nresults['LinearRegression'] = oof_auc1","4b45befc":"OOF2, oof_auc2, test_preds2 = trainFn(model_fn = linear_model.Ridge,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df))\n\nresults['Ridge'] = oof_auc2","99ca36f0":"OOF3, oof_auc3, test_preds3 = trainFn(model_fn = linear_model.BayesianRidge,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)).toarray(),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df).toarray())\n\nresults['BayesianRidge'] = oof_auc3","89f767e5":"OOF4, oof_auc4, test_preds4 = trainFn(model_fn = linear_model.ARDRegression,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)).toarray(),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df).toarray())\n\nresults['ARDRegression'] = oof_auc4","26394d5d":"class Blender():\n    def __init__(self):\n        self.best_weights = None\n    \n    def _blend(self, preds, weights):\n        return np.matmul(weights, preds).reshape(preds.shape[-1])\n        \n    def blend(self, preds):\n        return self._blend(preds, self.best_weights)\n    \n    def fit(self, oof, target = train_df.target.values):\n        initial_weights = np.ones(len(oof), dtype=np.float32).reshape(1, -1) \/ len(oof)\n        \n        print(f'Initial auc: {roc_auc_score(target, self._blend(oof, initial_weights))}')\n        \n        def objective(weights):\n            blend = self._blend(oof, weights)\n            \n            return -roc_auc_score(target, blend)\n        \n        self.best_weights = fmin(objective, initial_weights)\n        \n        print(f'After: {roc_auc_score(target, self.blend(oof))}')\n        \nblender  = Blender()","31b360b1":"OOF = np.array([OOF1, OOF2, OOF3, OOF4])\ntest_preds = np.array([test_preds1, test_preds2, test_preds3, test_preds4])\n\nblender.fit(OOF)","4e67631a":"sample_sub['target'] = blender.blend(test_preds)\nsample_sub.to_csv('submission_lin.csv', index=False)","aac52baa":"from sklearn.experimental import enable_hist_gradient_boosting\n\nfrom sklearn import ensemble","0f7408b5":"OOF5, oof_auc5, test_preds5 = trainFn(model_fn = ensemble.AdaBoostClassifier,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df).toarray(),\n        predict_proba = True)\n\nresults['AdaBoostClassifier'] = oof_auc5","fa805da7":"OOF6, oof_auc6, test_preds6 = trainFn(model_fn = ensemble.BaggingClassifier,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)).toarray(),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df).toarray(),\n        predict_proba = True)\n\nresults['BaggingClassifier'] = oof_auc6","7b6b6db1":"OOF7, oof_auc7, test_preds7 = trainFn(model_fn = ensemble.ExtraTreesClassifier,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)).toarray(),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df).toarray(),\n        predict_proba = True)\n\nresults['ExtraTreesClassifier'] = oof_auc7","b1986057":"OOF8, oof_auc8, test_preds8 = trainFn(model_fn = ensemble.GradientBoostingClassifier,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)).toarray(),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df).toarray(),\n        predict_proba = True)\n\nresults['GradientBoostingClassifier'] = oof_auc8","720f61d3":"OOF9, oof_auc9, test_preds9 = trainFn(model_fn = ensemble.RandomForestClassifier,\n        data = pipeline1.fit_transform(train_df.drop(['target'], axis = 1)).toarray(),\n        target = train_df.target.values,\n        cv=KFold(n_folds),\n        test=pipeline1.transform(test_df).toarray(),\n        predict_proba = True)\n\nresults['RandomForestClassifier'] = oof_auc9","439c223c":"OOF = np.array([OOF5, OOF6, OOF7, OOF8, OOF9])\ntest_preds = np.array([test_preds5, test_preds6, test_preds7, test_preds8, test_preds9])\n\nblender.fit(OOF)","8f809f0f":"sample_sub['target'] = blender.blend(test_preds)\nsample_sub.to_csv('submission_tree.csv', index=False)","c8e2f17a":"OOF = np.array([OOF1, OOF2, OOF3, OOF4, OOF5, OOF6, OOF7, OOF8, OOF9])\ntest_preds = np.array([test_preds1, test_preds2, test_preds3, test_preds4, test_preds5, test_preds6, test_preds7, test_preds8, test_preds9])\n\nblender.fit(OOF)","28b59255":"sample_sub['target'] = blender.blend(test_preds)\nsample_sub.to_csv('submission_all.csv', index=False)","e335a359":"### Blending","334840b3":"Blending sklearn models pipeline without any hyperparameters optimalization.\n\nversion 1\n","0508cb55":"## Short EDA","887d7853":"## Linear models","47a1b9e8":"## Tree models"}}