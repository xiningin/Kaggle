{"cell_type":{"b6fd4fd3":"code","da0c1626":"code","aafaf81d":"code","fc078ceb":"code","c51ac5bb":"code","2041406d":"code","748076ec":"code","ba572aba":"code","62c267f8":"code","63a2358c":"code","92b2041c":"code","d02acc6a":"code","70567223":"code","339e50fa":"code","e7c6b98a":"code","236dbb41":"code","0bfbfdad":"code","63753249":"code","379250d6":"markdown","67c2cd4f":"markdown","dca06809":"markdown","972b5081":"markdown","0cf033fc":"markdown","f7d22983":"markdown","17c75bc7":"markdown","4f34e97a":"markdown","0cd8c9eb":"markdown","276774e0":"markdown","b7f17d40":"markdown","c65ed8b0":"markdown","fe7640dc":"markdown","32d2c8e9":"markdown","f26a6c2a":"markdown","7d137105":"markdown","1c907a35":"markdown","a61f042d":"markdown","7fab28f8":"markdown","c15e5ce5":"markdown","b88520a1":"markdown"},"source":{"b6fd4fd3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras import models, layers, regularizers\nimport seaborn as sns\nfrom scipy import stats\n","da0c1626":"def standardize_m_s(ts):\n    sts = (ts - np.mean(ts))\/(np.std(ts))\n    return sts\n\ndef one_hot_encoding(data, exclusions):\n    \n    columns      = data.columns\n    n_samples    = data.shape[0]\n    one_hot_data = pd.DataFrame()\n    for col in columns:\n        if col not in exclusions:\n                unique_vals = np.unique(data.loc[:,col])\n                for val in unique_vals:\n                    new_col_name = col + \"_\" + str(val)\n                    zeros_array  = np.zeros(n_samples)\n                    zeros_array[(data[col] == val)] = 1\n                    one_hot_data[new_col_name] = zeros_array\n    for col in exclusions:\n        one_hot_data[col] = data[col]\n    return one_hot_data\n    \ndef build_model(regression_problem, hidden_layers_neurons, hidden_activation_function, L1_coeffs, L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, shape, model_optimizer, loss_function, metrics):\n    \n    model = models.Sequential()\n    \n    for i in range(len(hidden_activation_function)):\n        \n        if (i == 0):\n            model.add(layers.Dense(hidden_layers_neurons[i], \n                                   kernel_regularizer = regularizers.l1_l2(l1 = L1_coeffs[i], l2 = L2_coeffs[i]),                             \n                                   activation=hidden_activation_function[i], \n                                   input_shape=(shape,)))\n        else:\n            model.add(layers.Dense(hidden_layers_neurons[i], \n                                   kernel_regularizer = regularizers.l1_l2(l1 = L1_coeffs[i], l2 =  L2_coeffs[i]),  \n                                   activation=hidden_activation_function[i]))\n        if (hidden_layers_dropout[i] > 0.0):\n            model.add(layers.Dropout(hidden_layers_dropout[i]))\n    if regression_problem:\n            model.add(layers.Dense(final_layer_neurons))\n    else:\n            model.add(layers.Dense(final_layer_neurons,activation = final_activation_function))\n            \n    model.compile(optimizer = model_optimizer, loss = loss_function, metrics = metrics)\n    \n    return model\n\n            \n    ","aafaf81d":"datapath                   = \"\/kaggle\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv\"\nregression_problem         = True\ntraining_set_size          = 400\nk_fold_shuffles            = 15\nk_folds_range              = [2,3,4,5,6,7]\nhidden_activation_function = ['sigmoid','sigmoid']\nhidden_layers_neurons      = [16,8,8]\nhidden_layers_L1_coeffs    = [0.00,0.00,0.00]\nhidden_layers_L2_coeffs    = [0.00,0.00,0.00]\nhidden_layers_dropout      = [0.00,0.00,0.00]\nfinal_activation_function  = ''\nfinal_layer_neurons        = 1\nmodel_optimizer            = 'Adam'\nloss_function              = 'mse'\nmetrics                    = [\"mae\"]\nn_epochs                   = 75\nbatch_size                 = 20","fc078ceb":"df  = pd.read_csv(datapath,sep=',')\ndf  = df.iloc[:,1:]\ndf.head()","c51ac5bb":"df.loc[:(training_set_size-1),'Dataset'] = 1\ndf.loc[training_set_size:,'Dataset'] = 2","2041406d":"fig, ax = plt.subplots(2,4, figsize=(30, 15))\nfor var, subplot in zip(['GRE Score','TOEFL Score','University Rating','SOP','LOR ','CGPA','Research','Chance of Admit '], ax.flatten()):\n    sns.distplot(df.loc[df['Dataset'] == 1,var], color = 'red', label = 'Train', ax = subplot)\n    sns.distplot(df.loc[df['Dataset'] == 2,var], color='green', label='Test', ax=subplot)\n    subplot.set(title = \"Histogram of \" + var, ylabel= 'frequency')\n    subplot.legend()\nplt.show()","748076ec":"fig, axes = plt.subplots(1,4, figsize=(40, 10))\nfor var, subplot in zip(['SOP','LOR ','University Rating','Research'], axes.flatten()):\n        sns.boxplot(x = var, y= \"Chance of Admit \", data=df, ax= subplot)\n        subplot.set(ylabel='Chance of admission ',title = \"Chance of admission within the \" + var + \" class.\")\n        subplot.legend(loc='upper right')\nplt.show()","ba572aba":"fig, axes = plt.subplots(1,3, figsize=(30, 10))\nfor var, col, subplot in zip(['GRE Score','TOEFL Score','CGPA'], ['red','blue','green'], axes.flatten()):\n        sns.scatterplot(x = var, y= \"Chance of Admit \", color= col, data=df, ax= subplot)\n        subplot.set(ylabel='Chance of admission ',title = \"Chance of admission within the \" + var + \" class.\")\n        subplot.legend(loc='upper right')\nplt.show()","62c267f8":"df = one_hot_encoding(df, ['Chance of Admit ','GRE Score','TOEFL Score','CGPA','Dataset'])","63a2358c":"fig, axes = plt.subplots(1,1, figsize=(30, 20))\nsns.heatmap(df.loc[df['Dataset']==1,:].corr(), annot = True, ax = axes)\nplt.show()","92b2041c":"abs_corr                  = abs(df.loc[df['Dataset']==1,:].corr())\nselected_features         = (abs_corr.loc['Chance of Admit ',:] > 0.35)\ndf = df.filter(items = list(abs_corr.loc[selected_features,:].index) + ['Dataset'])","d02acc6a":"for dataset_id, column in zip(3*[1,2],2*['GRE Score','TOEFL Score','CGPA']):\n        df.loc[df['Dataset']==dataset_id, column] = standardize_m_s(df.loc[df['Dataset']==dataset_id,column])","70567223":"train_data = df.loc[df['Dataset'] == 1, :]\ntest_data = df.loc[df['Dataset'] == 2, :]\ntrain_labels = train_data['Chance of Admit '].values\ntest_labels = test_data['Chance of Admit '].values\ntrain_data.drop(columns = ['Chance of Admit ','Dataset'],inplace = True)\ntest_data.drop(columns = ['Chance of Admit ','Dataset'],inplace = True)\ntrain_data = train_data.to_numpy()\ntest_data = test_data.to_numpy()\nn_samples = train_data.shape[0]\nn_features = train_data.shape[1]\ntotal_experiments = np.sum(k_folds_range)*k_fold_shuffles","339e50fa":"k_fold_sample_sizes             = [n_samples\/\/k_folds for k_folds in k_folds_range]\nMAE_matrix                      = pd.DataFrame(data = np.zeros((len(k_folds_range)*k_fold_shuffles, 2 + n_epochs)), columns = ['K','Shuffle #'] + [str(ij + 1) for ij in range(n_epochs)])\nRMSE_matrix                     = pd.DataFrame(data = np.zeros((len(k_folds_range)*k_fold_shuffles, 3)), columns = ['K','Shuffle #','<RMSE>'])\nrow_idx                         = 0\nexperiment_counter              = 0\nfor j in range(0,len(k_folds_range),1):\n    \n        for p in range(k_fold_shuffles):\n\n                mean_MAE_matrix_list   = []\n                mean_RMSE_matrix_list  = []\n                \n                shuffled_indexes       = list(range(n_samples))\n                np.random.shuffle(shuffled_indexes)\n                shuffled_train_data    = train_data[shuffled_indexes]\n                shuffled_train_labels  = train_labels[shuffled_indexes]\n\n                k_fold_sample_size     = k_fold_sample_sizes[j]\n                current_K              = k_folds_range[j]\n                \n                for i in range(0,current_K,1):\n\n\n                            validation_data         = shuffled_train_data[(i*k_fold_sample_size):((i+1)*k_fold_sample_size)]\n                            validation_labels       = shuffled_train_labels[(i*k_fold_sample_size):((i+1)*k_fold_sample_size)]\n\n                            current_train_data_1    = shuffled_train_data[:(i*k_fold_sample_size)]\n                            current_train_labels_1  = shuffled_train_labels[:(i*k_fold_sample_size)]\n\n                            current_train_data_2    = shuffled_train_data[((i+1) * k_fold_sample_size):]\n                            current_train_labels_2  = shuffled_train_labels[((i+1) * k_fold_sample_size):]\n\n                            current_train_data      = np.concatenate([current_train_data_1,current_train_data_2],axis=0)\n                            current_train_labels    = np.concatenate([current_train_labels_1, current_train_labels_2], axis=0)\n\n                            model                   = build_model(regression_problem, hidden_layers_neurons, hidden_activation_function, \n                                                                      hidden_layers_L1_coeffs, hidden_layers_L2_coeffs, hidden_layers_dropout,\n                                                                      final_layer_neurons, final_activation_function, current_train_data.shape[1], \n                                                                      model_optimizer, loss_function, metrics)\n\n                            history                 = model.fit(current_train_data, current_train_labels, \n                                                                validation_data = (validation_data,validation_labels), \n                                                                epochs=n_epochs, \n                                                                batch_size=batch_size,\n                                                                verbose=0)\n                            \n                            mean_MAE_matrix_list.append(history.history['val_mae'])\n                            \n                            forecasts               = np.array([pred[0] for pred in model.predict(test_data)])\n                            RMSE                    = np.sqrt(np.average((forecasts - test_labels)**2))\n                            mean_RMSE_matrix_list.append(RMSE)\n                            \n\n                            if (row_idx == 0):\n                                best_model = model\n                                best_RMSE  = RMSE\n                            else:\n                                current_MAE= np.min(history.history['val_mae'])\n                                if (RMSE < best_RMSE):\n                                    best_model = model\n                                    best_RMSE  = RMSE\n                            \n                            experiment_counter += 1\n                            print('Processed window #: {0:.0f} out of {1:.0f}, current shuffle #: {2:.0f}, RMSE: {3:.4f}, Best RMSE: {4:.4f}, % experiment completed: {5:.2f}'.format(i+1,\n                                                                                                                                                                                      current_K,\n                                                                                                                                                                                      p,\n                                                                                                                                                                                      RMSE,\n                                                                                                                                                                                      best_RMSE,\n                                                                                                                                                                                      100*(experiment_counter\/float(total_experiments))))\n\n                            \n\n                MAE_matrix.iloc[row_idx]  = np.concatenate((np.array([current_K, p + 1]), np.mean(np.array(mean_MAE_matrix_list),axis=0)))\n                RMSE_matrix.iloc[row_idx] = np.array([current_K, p + 1,np.mean(mean_RMSE_matrix_list)])\n                row_idx += 1\n","e7c6b98a":"validation_df                   = pd.DataFrame()\nvalidation_df ['Epoch']         = range(1,n_epochs + 1)\nvalidation_df ['<MAE>']         = np.average(np.array(MAE_matrix.iloc[:,2:].to_numpy()),axis=0)\n\nf, ax = plt.subplots(figsize=(24, 12))\nsns.barplot(x=\"Epoch\",y=\"<MAE>\", data=validation_df, palette=\"Blues_d\") \\\n.set_title('Average mean absolute error (<MAE>) as a function of the training epoch.')\nplt.show()\n\n","236dbb41":"f, ax = plt.subplots(figsize=(18, 18*((len(k_folds_range)*k_fold_shuffles)\/float(n_epochs))))\nyticklabels = \"(K: \" + MAE_matrix['K'].apply(int).apply(str) + \", #: \" + MAE_matrix['Shuffle #'].apply(int).apply(str) + \")\"\nsns.heatmap(MAE_matrix.iloc[:,2:], yticklabels=yticklabels, annot=False,linewidths=.5, ax=ax)\\\n.set_title('Mean absolute error (<MAE>) in each training fold (x:epoch, y:(K, # shuffle))')\nplt.show()","0bfbfdad":"f, ax = plt.subplots(figsize=(18, 18*((len(k_folds_range)*k_fold_shuffles)\/float(n_epochs))))\nyticklabels = [str(k) for k in k_folds_range]\nxticklabels = [str(ij + 1) for ij in range(k_fold_shuffles)]\ndata = (RMSE_matrix.iloc[:,2:]).to_numpy()\nsns.heatmap(data.reshape((len(k_folds_range),k_fold_shuffles)), xticklabels=xticklabels, yticklabels=yticklabels, \n            annot=True,linewidths=.5, ax=ax)\nax.set_title('Average root mean squared erros (<RMSE>) in each k-fold shuffle (x:# shuffle, y:K)')\nax.set_xlabel(\"Shuffle #\")\nax.set_ylabel(\"K\")\nplt.show()","63753249":"forecasts                      = np.array([pred[0] for pred in best_model.predict(test_data)])\nRMSE                           = np.sqrt(np.average((forecasts - test_labels)**2))\nprediction_df                  = pd.DataFrame()\nprediction_df['True']          = test_labels\nprediction_df['Forecast']      = forecasts\nprediction_df['Squared error'] = (forecasts - test_labels)**2\nsns.jointplot(x=\"True\", y=\"Forecast\", data=prediction_df, height = 12, color = 'red');\nplt.show\nslope, intercept, r_value, p_value, std_err = stats.linregress(test_labels, forecasts)\nprint(\"The lowest recorded RMSE is: {0:.4f}\".format(RMSE))\nprint(\"The R^2 of the linear model test data vs. prediction is: {0:.4f}\".format(r_value**2))","379250d6":"## DEFINE AUXILIARY FUNCTIONS\n\nThe following cell supplies auxiliary functions that are used throughout the scripts\n\n1. standardize_m_s -> takes a time series as an input and \"standardize\" it by removing the sample mean from each observation and dividing this difference by the sample standard deviation.\n2. one_hot_encoding -> one-hot encode categorical variables. The user must specify those columns that should not undergo this process.\n3. build_model -> return a Keras model object of an artificial neural network built according to input specs provided by the user.  ","67c2cd4f":"## SIMPLE FEATURE REDUCTION\n\nWe apply a very naive feature reduction approach which consists in dropping those features that have an absolute Pearson correlation coefficient vs. \"Chance of Admit\" below 0.35.","dca06809":"## DESCRIPTIVE ANALYSIS OF THE DATASET\n\nAs a first step, we examine the empirical frequencies of each variable and plot basic histograms + kde density, see https:\/\/en.wikipedia.org\/wiki\/Kernel_density_estimation#:~:text=In%20statistics%2C%20kernel%20density%20estimation,on%20a%20finite%20data%20sample.","972b5081":"We add a column to link each sample with its subset of data (train vs. test)\n","0cf033fc":"Next, we study how each discrete variable relates with the chance of admission (i.e., the variable we want to predict) by drawing box-plots","f7d22983":"## TRAINING \n\nWe finally set-up the training phase. To train our neural network, we adopt a shuffling k-fold approach:\n\n1. Randomly shuffle the training dataset\n2. Split it into K folds, i.e., K adjacent partitions containing the same number of samples.\n3. K - 1 folds are used to train the model, i.e., parameter estimation, and 1 fold is used as a validation sample, i.e., the predictive ability of the newly trained model is assessed on this subset.\n4. Collect the vector containing the value of the mean absolute error (MAE) over the validation dataset in each epoch.\n5. Test the trained network on previously unseen data, i.e., the test data set, and collect the root mean squared error (RMSE).\n6. Go back to (3) and ensure that another fold will serve as a validation set. This can be done in a sliding fashion. For instance, for K = 3 we have:\n\n        6.1. |Validation fold|Training fold 1|Training fold 2| -> |Validation data|       Training data       |  -> perform step (4)-(5)\n\n        6.2. |Training fold 2|Validation fold|Training fold 1| -> |Training data|Validation data|Training data|  -> perform step (4)-(5)\n    \n        6.3. |Training fold 1|Training fold 2|Validation fold| -> |       Training data       |Validation data|  -> perform step (4)-(5)\n        \n\n7. Go back to (1) and perform steps (2)-(6) j times, i.e., the user defined k_fold shuffles.\n8. Consider the other values of K, i.e., the number of folds specified by the user in k_folds_range, and repeat steps (1)-(7).\n\nDuring this cycle, we have k_fold shuffles*(sum_{i = 0}^{L - 1}k_folds_range[i]), where L is len(k_folds_range), experiments. An experiment includes a training phase over K - 1 folds, a validation over the remaining fold and a test over the unseen test set. For each experiment, we are interested in three things:\n\n* The value of the MAE in each epoch to assess whether adding more epochs to the training improves our validation.\n* The value of the RMSE to assess how well the current trained model performs on the test data set.\n* Whether the current trained model achieves the running minimum RMSE. If this the case, the object \"model\" is kept in memory.\n\n![grid_search_cross_validation.png](attachment:grid_search_cross_validation.png)\n\nSchematics of the underlying logic of k-fold cross validation.\n\nImage source: https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html","17c75bc7":"Finally, we look at how the model performed in the test set by examing the rooted mean squared error (RMSE) across different shuffles and values of K. In this case, a single entry of the matrix represents the value of RMSE in a given shuffle (x-axis) and fold (y-axis).","4f34e97a":"## CORRELATION MATRIX\n\nHaving obtained a \"one-hot encoded\" dataset, we compute the Pearson correlation coefficient for each pair of feature and visualize this measure of linear correlation in a heatmap.","0cd8c9eb":"## SUMMARY\n\n**Context**\n\nThis dataset is created for prediction of Graduate Admissions from an Indian perspective.\n\n**Content**\n\nThe dataset contains several parameters which are considered important during the application for Masters Programs.\nThe parameters included are :\n\n* GRE Scores ( out of 340 )\n* TOEFL Scores ( out of 120 )\n* University Rating ( out of 5 )\n* Statement of Purpose and Letter of Recommendation Strength ( out of 5 )\n* Undergraduate GPA ( out of 10 )\n* Research Experience ( either 0 or 1 )\n* Chance of Admit ( ranging from 0 to 1 )\n\n**Acknowledgements**\n\nThis dataset is inspired by the UCLA Graduate Dataset. The test scores and GPA are in the older format.\nThe dataset is owned by Mohan S Acharya.\n\n**Inspiration**\n\nThis dataset was built with the purpose of helping students in shortlisting universities with their profiles. The predicted output gives them a fair idea about their chances for a particular university.\n\n**Overview of the notebook**\n\nThis notebook implements a neural network model to predict the graduate admission of Indian students.\n\nThe input dataset is available at https:\/\/www.kaggle.com\/mohansacharya\/graduate-admissions.\n\nThe code allows the user to buy a customized, i.e., number of nodes, layers, activation functions etc., artificial neural network.\nThe training phase adopt a k-fold validation approach.\n\nIn this experiment, our model achieves very satisfactory accuracy levels, i.e., RMSE < 0.04, in predicting previously unseen samples.\n\n![The-Ultimate-Guide-to-Resume-Screening.png](attachment:The-Ultimate-Guide-to-Resume-Screening.png)\n\n\nImage source: https:\/\/fitsmallbusiness.com\/resume-screening\/","276774e0":"Next, we study how each continuous variable relates with the chance of admission (i.e., the variable we want to predict) by drawing scatter plots","b7f17d40":"## \"CONTINUOUS\" FEATURES NORMALIZATION\n\nWe normalize continuous features as follows\n\n$$ z = \\frac{x - \\langle x \\rangle}{\\sqrt{\\langle x^2 \\rangle - \\langle x \\rangle^{2}}},$$\n\nwhere $\\langle x \\rangle$ is the sample average and $\\sqrt{\\langle x^2 \\rangle - \\langle x \\rangle^{2}}$ is the sample standard deviation.\n\nNote that the normalization procedure is performed separately in the training and test sample to avoid \"leakages\" of information into the test set.\n\n\n","c65ed8b0":"## SCATTER PLOT OF FORECASTS vs. TRUE VALUES\n\nTo conclude, we use the best performing weights to forecast the values of the probability of admission in the test. To examine the quality of the predictions, we display a scatter plot of (true value, forecast) pairs and report the $R^2$ statistics of a simple linear regression fit on the forecasts-true values dataset. ","fe7640dc":"## INPUT DASHBOARD\n\nThen, we let the user set several variables that affect the estimation of the model:\n\n* datapath -> set the path (including the target file name) where the code finds the input data\n* regression_problem -> indicates whether we are facing a regression problem. If = True, the final layer of a neural network won't have any specified activation function.         \n* training_set_size -> the number of samples forming the training data set.\n* K_fold_shuffles -> given a number of folds K, this sets the number of k-fold validations j performed on j different                shuffled versions of the same training data set.\n* K_fold_range -> the number of folds the training data set must be split into. The training loop can consider                        multiple values of this variable.\n* hidden_activation_function -> list containing the name of the activation functions (available in Keras) used in the hidden layers of the neural network.\n* hidden_layers_neurons -> list containing the number of neurons forming each hidden layer of the neural network\n* hidden_layers_L1_coeffs -> scalars multiplying the L1-penalty terms for each hidden layer weights during the training phase. Set it to 0 to avoid L1-regularization.\n* hidden_layers_L2_coeffs -> scalars multiplying the L2-penalty terms for each hidden layer weights during the training phase. Set it to 0 to avoid L2-regularization.\n* hidden_layers_dropouts -> fractions of weights that are randomly set to zero for each hidden layer during the training phase. Set it to 0 to avoid dropout regularization.\n* final_activation_function -> name of the activation function (available in Keras) used in the terminal layer of the neural network.\n* final_layer_neurons -> number of neurons forming the terminal layer of the neural network.\n* model_optimizer -> name of the method (available in Keras) to iteratively update the search of the set of parameters that minimize the loss function.\n* loss_function -> name the loss function (available in Keras) that measures how well model predictions match the data during the training phase.\n* metrics -> list containing the name of the metrics (available in Keras) that we use to measure how well the model using the current set of parameters predicts the validation data set.\n* n_epochs -> the times the optimization algorithm goes through the entire training data set.\n* batch_size -> the number of samples included in a single batch.\n       ","32d2c8e9":"## REFERENCES\n\n1. Some segments of this notebook are inspired by the contents of the book \"Deep Learning with Python\", Francois Chollet, Manning.","f26a6c2a":"## ONE-HOT ENCODING OF INTEGER FEATURES\n\nOne-hot encoding converts an integer feature, e.g., taking values in S = {1,2,3}, into k binary features, i.e., taking values in {0,1}, where k is the cardinality of S.\n\nA function that performs one-hot encoding can be found in the early segments of this notebook\n\n![0_T5jaa2othYfXZX9W_.jpg](attachment:0_T5jaa2othYfXZX9W_.jpg)\n\nSchematics of the underlying logic of one-hot enconding\n\nImage source: https:\/\/medium.com\/@michaeldelsole\/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179","7d137105":"## DATA IMPORT\n\nWe load the full dataset first and then we retrieve the features and the targer vector.","1c907a35":"## IMPORT LIBRARIES\n\nWe begin by importing the libraries needed to perform the incoming tasks.","a61f042d":"## RESULTS ANALYSIS\n\nWe look at different plots to analyze the outcomes of the training process.\nFirst, we examine how the average mean absolute error <MAE> changes with the training epoch. In this case, the statistics of interest is obtained by averaging the MAE values on a given epoch regardless the value of K or the id of the shuffle.","7fab28f8":"## NOTES\n\nAuthor: Alberto Ciacci\n\nE-mail: alberto.ciacci16@imperial.ac.uk\n\nLanguage: python\n\nComments, corrections and suggestions are very much welcome.","c15e5ce5":"## TRAINING PREPARATION\n\nWe apply some final refinements to the dataset before entering the training phase.","b88520a1":"Next, we look at how the average mean absolute error ($<$MAE$>$) changed throughout the training phase. In this case, a single entry of the matrix represents the value of $<$MAE$>$ in a given epoch (x-axis), shuffle and fold (y-axis)."}}