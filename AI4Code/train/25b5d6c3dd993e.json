{"cell_type":{"93e46951":"code","bf4c787b":"code","edd3908b":"code","d4530e02":"code","925508ed":"code","58937b91":"code","43085025":"code","5545cd6e":"code","1529e8b3":"code","92764812":"code","e8d15c4e":"code","999e83f9":"code","122a7e41":"code","0202ece0":"code","4b23e5b5":"code","a1395e41":"code","591cf834":"code","ae51b0d3":"code","0318b6ab":"code","f39f2577":"code","6bb23d29":"code","f5407c82":"code","ff2da5ef":"code","a238e0fa":"code","1e2acdf4":"code","3f0f315e":"code","e6e10e9c":"code","8477c397":"code","54e3e7cc":"code","48b69401":"code","98c396c1":"code","7dfc62e5":"code","17610384":"code","698bae78":"code","f977ae8e":"code","999275bf":"code","dfdb5263":"code","05ef28f8":"markdown","a03b6394":"markdown","d6fe031e":"markdown","5317c21b":"markdown","7d7aebaa":"markdown","0a0af892":"markdown"},"source":{"93e46951":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bf4c787b":"import pandas as pd\n\ntrain = pd.read_csv(f'..\/input\/train-test\/train.tsv', sep='\\t') #sep='\\t'\u3067\u30bf\u30d6\u533a\u5207\u308a\ntest = pd.read_csv(f'..\/input\/train-test\/test.tsv', sep='\\t')","edd3908b":"#item_condition_id\u5225\u306b\u898b\u3066\u307f\u308b\n\ntrain['item_condition_id'].value_counts()","d4530e02":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set()\nplt.figure(figsize=(15, 10))\nplt.subplot(2, 3, 1)\nplt.hist(train.loc[train['item_condition_id'] == 1, 'price'].dropna(),\n        range=(0, 250), bins=30, label='1')\nplt.ylim(0, 220000)\nplt.title('id=1')\nplt.xlabel('price')\nplt.ylabel('count')\nplt.subplot(2, 3, 2)\nplt.hist(train.loc[train['item_condition_id'] == 2, 'price'].dropna(),\n        range=(0, 250), bins=30, label='2')\nplt.ylim(0, 220000)\nplt.title('id=2')\nplt.subplot(2, 3, 3)\nplt.hist(train.loc[train['item_condition_id'] == 3, 'price'].dropna(),\n        range=(0, 250), bins=30, label='3')\nplt.ylim(0, 220000)\nplt.title('id=3')\nplt.subplot(2, 3, 4)\nplt.hist(train.loc[train['item_condition_id'] == 4, 'price'].dropna(),\n        range=(0, 250), bins=30, label='4')\nplt.ylim(0, 220000)\nplt.title('id=4')\nplt.subplot(2, 3, 5)\nplt.hist(train.loc[train['item_condition_id'] == 5, 'price'].dropna(),\n        range=(0, 250), bins=30, label='5')\nplt.ylim(0, 220000)\nplt.title('id=5')","925508ed":"print(train.loc[train['item_condition_id'] == 1, 'price'].mean())\nprint(train.loc[train['item_condition_id'] == 2, 'price'].mean())\nprint(train.loc[train['item_condition_id'] == 3, 'price'].mean())\nprint(train.loc[train['item_condition_id'] == 4, 'price'].mean())\nprint(train.loc[train['item_condition_id'] == 5, 'price'].mean())","58937b91":"#\u7bb1\u3072\u3052\u56f3\u63cf\u753b\nimport numpy as np\n\nsns.set()\nprice_1 = [np.log1p(w) for w in train.loc[train['item_condition_id'] == 1, 'price']]\nprice_2 = [np.log1p(w) for w in train.loc[train['item_condition_id'] == 2, 'price']]\nprice_3 = [np.log1p(w) for w in train.loc[train['item_condition_id'] == 3, 'price']]\nprice_4 = [np.log1p(w) for w in train.loc[train['item_condition_id'] == 4, 'price']]\nprice_5 = [np.log1p(w) for w in train.loc[train['item_condition_id'] == 5, 'price']]\npoints = (price_1, price_2, price_3, price_4, price_5)\nplt.boxplot(points)\nplt.xticks([1, 2, 3, 4, 5])\nplt.xlabel('item_condition_id')\nplt.ylabel('log(price+1)')","43085025":"from contextlib import contextmanager\nimport time\n\n#contextmanager\u306fwith\u6587\u306e\u5b9f\u884c\u6642\u9593\u3092\u8a08\u6e2c\u3059\u308b\n#@\u306f\u30c7\u30b3\u30ec\u30fc\u30bf\n#print f \u306f\u6587\u5b57\u5217\u5185\u306b\u5909\u6570\u3092\u76f4\u63a5\u6e21\u305b\u308b\n#xf\u306f\u5c0f\u6570\u70b9\u7b2cx\u4f4d\u307e\u3067\u3092\u51fa\u529b\u3059\u308b\n\n\"\"\"with\u6587\u306e\u5b9f\u884c\u6642\u9593\u3092\u8fd4\u3059\u30c7\u30b3\u30ec\u30fc\u30bf\"\"\"\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield \n    print(f'[name] done in {time.time() - t0:.0f} s')","5545cd6e":"import pandas as pd\n\n#: -> \u306f\u578b\u6307\u5b9a(\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3)\n#fillna(\u4efb\u610f\u306e\u6587\u5b57\u5217)\u3067\u6b20\u640d\u5024\u3092\u7f6e\u63db\n\n\"\"\"\u76f8\u95a2\u306e\u3042\u308b\u30ab\u30e9\u30e0\u3092\u7d50\u5408\"\"\"\ndef preprocess(df: pd.DataFrame) -> pd.DataFrame:\n    #name\u30ab\u30e9\u30e0\u306fname\u3068brand_name\u30ab\u30e9\u30e0\u3067\u7d50\u5408\n    df['name'] = df['name'].fillna('') + ' ' + df['brand_name'] + fillna('')\n    #text\u30ab\u30e9\u30e0\u3092\u8ffd\u52a0\u3057,item_description\u3068name\u3068category_name\u3067\u7d50\u5408\n    df['text'] = df['item_description'].fillna('') + ' ' + df['name'].fillna('') + ' ' + df['category_name'].fillna('')\n    return df[['name', 'text', 'shipping', 'item_condition_id']]","1529e8b3":"from sklearn.pipeline import make_pipeline, make_union, Pipeline\nfrom sklearn.preprocessing import FunctionTransformer, StandardScaler\nfrom operator import itemgetter\n\n#\u4f4d\u7f6e\u5f15\u6570\u306e*\u306f\u5f15\u6570\u3092\u30bf\u30d7\u30eb\u5316\u3059\u308b(\u30dd\u30a4\u30f3\u30bf\u3067\u306f\u306a\u3044!).\n#FunctionTransformer : itemgetter()\u306f\u6587\u5b57\u5217\u3092\u62bd\u51fa\u3059\u308b.validate=True\u3067numpy\u914d\u5217\u306b\u5909\u63db.\n#make_pipeline\u306fPipiline\u306e\u7701\u7565\u5f62.\u63a8\u5b9a\u91cf\u306e\u540d\u524d\u304c\u63a8\u5b9a\u91cf\u306e\u6307\u5b9a\u30bf\u30a4\u30d7\u306e\u5c0f\u6587\u5b57\u306b\u306a\u308b.\n#>>> make_pipeline(StandardScaler(), GaussianNB(priors=None))\n#    Pipeline(steps=[('standardscaler', StandardScaler()),\n                #('gaussiannb', GaussianNB())])\n\n\"\"\"\u72ec\u81ea\u30e1\u30bd\u30c3\u30c9\u306ePipeline\u4f5c\u6210\"\"\"\ndef on_field(f: str, *vec) -> Pipeline:\n    return make_pipeline(FunctionTransformer(itemgetter(f), validate=True), *vec)","92764812":"from typing import List, Dict\n\n#\u30aa\u30d7\u30b7\u30e7\u30f3\u306borient='records'\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u884c\u3054\u3068\u306e\u8f9e\u66f8\u3092\u4fdd\u6301\u3057\u305fJSON\u306b\u306a\u308b\n\n\"\"\"pd.DataFrame\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u8f9e\u66f8\u578b\u306b\u5909\u63db\u3059\u308b\"\"\"\ndef to_records(df : pd.DataFrame) -> List[Dict]:\n    return df.to_dict(orient='records')","e8d15c4e":"import tensorflow as tf\n\na = tf.constant(1.5)\nb = tf.constant(2.0)\nc = tf.constant(-1.0)\nd = tf.constant(3.0)\n\nx = tf.add(a, b)\ny = tf.multiply(c, d)\nz = tf.add(x, y)\n\ntf.print([x, y, z])","999e83f9":"import pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport math\n\n\nfrom subprocess import check_output\n#\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u53c2\u7167\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","122a7e41":"#assert\u6587:\u5358\u4f53\u30c6\u30b9\u30c8\n\n\"\"\"RMSLE\u306e\u5b9a\u7fa9\"\"\"\ndef RMSLE(y, y_pred):\n    assert len(y)==len(y_pred), \"Length of y and y_pred are not equal.\"\n    to_sum = math.sqrt(sum([(math.log(y_pred[i] + 1) - math.log(y[i] + 1))**2 for i in range(len(y))])*(1.0\/len(y)))\n    return to_sum","0202ece0":"train.info()","4b23e5b5":"#\u5404\u30ab\u30e9\u30e0\u306e\u6b20\u640d\u5024\u3092missing\u3067\u7f6e\u63db\n\ndef handle_missing(dataset):\n    dataset.category_name.fillna(value='missing', inplace=True)\n    dataset.brand_name.fillna(value='missing', inplace=True)\n    dataset.item_description.fillna(value='missing', inplace=True)\n    return (dataset)\n\ntrain = handle_missing(train)\ntest = handle_missing(test)\nprint(train.shape)\nprint(test.shape)","a1395e41":"train.head()","591cf834":"from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n\n#np.hstack()\u306f\u5217\u65b9\u5411\u306b\u30c7\u30fc\u30bf\u3092\u7d50\u5408(\u884c\u65b9\u5411\u306fnp.vstack)\n\n\"\"\"category_name\u3092\u6570\u5024\u30c7\u30fc\u30bf\u306b\u5909\u63db\"\"\"\nle = LabelEncoder()\nle.fit(np.hstack([train.category_name, test.category_name]))\ntrain.category_name = le.transform(train.category_name)\ntest.category_name = le.transform(test.category_name)\n\nle.fit(np.hstack([train.brand_name, test.brand_name]))\ntrain.brand_name = le.transform(train.brand_name)\ntest.brand_name = le.transform(test.brand_name)\ndel le","ae51b0d3":"train.head()","0318b6ab":"from keras.preprocessing.text import Tokenizer\n\n#name\u3068item_description\u3092\u5217\u65b9\u5411\u3067\u3064\u306a\u3052\u308b\nraw_text = np.hstack([train.name.str.lower(), train.item_description.str.lower()])\n\n#keras\u306b\u304a\u3051\u308b\u524d\u51e6\u7406:\u30c6\u30ad\u30b9\u30c8\u3092token\u5358\u4f4d\u306b\u5206\u5272\ntok_raw = Tokenizer()\n#fit_on_texts\u30e1\u30bd\u30c3\u30c9\u3067\u5358\u8a9e\u3068\u6570\u5024(\u30d9\u30af\u30c8\u30eb)\u3092\u5bfe\u5fdc\u3065\u3051\u308b(\u6570\u5024\u306b\u5909\u63db\u306f\u307e\u3060\u3057\u306a\u3044)\n#\u30c6\u30ad\u30b9\u30c8\u3092\u5358\u8a9e\u5358\u4f4d\u306b\u5206\u5272\u3059\u308b\u5fc5\u8981\u3082\u306a\u304f,\u3059\u3054\u304f\u4fbf\u5229\ntok_raw.fit_on_texts(raw_text)\n\n#\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u6570\u5217\u306b\u5909\u63db\ntrain[\"seq_item_description\"] = tok_raw.texts_to_sequences(train.item_description.str.lower())\ntest[\"seq_item_description\"] = tok_raw.texts_to_sequences(test.item_description.str.lower())\n\ntrain[\"seq_name\"] = tok_raw.texts_to_sequences(train.name.str.lower())\ntest[\"seq_name\"] = tok_raw.texts_to_sequences(test.name.str.lower())","f39f2577":"train.head()","6bb23d29":"#SEQUENCES VARIABLES ANALYSIS\n\n#name\u306e\u5358\u8a9e\u6570\u306e\u6700\u5927\u5024\nmax_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\n#item_description\u306e\u6700\u5927\u5024\nmax_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\n\nprint(\"max name seq \"+str(max_name_seq))\nprint(\"max item desc seq \"+str(max_seq_item_description))","f5407c82":"train.seq_name.apply(lambda x: len(x)).hist()\nplt.xlabel('seq_name\\'s length')\nplt.ylabel('seq_name\\'s word counts')","ff2da5ef":"train.seq_item_description.apply(lambda x: len(x)).hist()\nplt.xlabel('seq_item_description\\'s length')\nplt.ylabel('seq_item_description\\'s word counts')","a238e0fa":"#EMBEDDINGS MAX VALUE\n#Base on the histograms, we select the next lengths\nMAX_NAME_SEQ = 10 #\u672c\u5f53\u306f17\u3060\u304c,\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u304b\u3089\u4ef6\u6570\u304c\u5c11\u306a\u3044\u306e\u306710\u3068\u3057\u305f.\nMAX_ITEM_DESC_SEQ = 75\n#seq_name\u3068seq_item_description\u306e\u4e2d\u3067\u6700\u9577\u306e\u30c6\u30ad\u30b9\u30c8\u306e\u5358\u8a9e\u6570\u3092\u62bd\u51fa\nMAX_TEXT = np.max([np.max(train.seq_name.max())\n                   , np.max(test.seq_name.max())\n                  , np.max(train.seq_item_description.max())\n                  , np.max(test.seq_item_description.max())])+2\n\n#category\u306e\u6700\u5927\u5024\nMAX_CATEGORY = np.max([train.category_name.max(), test.category_name.max()])+1\n#brand_name\u306e\u6700\u5927\u5024\nMAX_BRAND = np.max([train.brand_name.max(), test.brand_name.max()])+1\n#item_condiion_id\u306e\u6700\u5927\u5024\nMAX_CONDITION = np.max([train.item_condition_id.max(), test.item_condition_id.max()])+1","1e2acdf4":"from sklearn.preprocessing import MinMaxScaler\n\n#SCALE target variable\ntrain['target'] = np.log(train.price+1)\n#MinMaxScaler\u306f\u5909\u63db\u5f8c\u306e\u30c7\u30fc\u30bf\u306e\u6700\u5927\u30fb\u6700\u5c0f\u3092\u72ec\u81ea\u306b\u5909\u63db\u30fb\u8a2d\u5b9a\u3059\u308b\ntarget_scaler = MinMaxScaler(feature_range=(-1, 1))\n#\u30c7\u30fc\u30bf\u5909\u63db\u306e\u65bd\u884c\narray = np.empty(len(train.target)) #maximum supported dimension for an ndarray is 32, found 1482535 \u306e\u56de\u907f\narray[:] = train.target             ##maximum supported dimension for an ndarray is 32, found 1482535 \u306e\u56de\u907f\ntrain['target'] = target_scaler.fit_transform(array.reshape(-1,1)) #-1\u304b\u30891\u306e\u7bc4\u56f2\u3067\u6a19\u6e96\u5316\npd.DataFrame(train.target).hist()\nplt.xlabel('log(price + 1)')\nplt.ylabel('count')","3f0f315e":"#\u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u8a13\u7df4\u3068\u691c\u8a3c\u7528\u306b\u5206\u3051\u308b\ndtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)\nprint(dtrain.shape)\nprint(dvalid.shape)","e6e10e9c":"\"\"\"keras\u306b\u3088\u308b\u5b66\u7fd2\u7528\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5b9a\u7fa9\"\"\"\nfrom keras.preprocessing.sequence import pad_sequences\n\n#pad_sequences\u306f\u30ea\u30b9\u30c8\u306e\u30ea\u30b9\u30c8\u306e\u5404\u8981\u7d20\u306b\u5bfe\u3057\u3066maxlen\u3067\u6307\u5b9a\u3057\u305f\u9577\u3055\u306e\u30b7\u30fc\u30b1\u30f3\u30b9\u3092\u8fd4\u3059.\n#pad_sequences\u306e\u623b\u308a\u5024: shape\u304c(len(sequences), maxlen)\u306eNumpy\u914d\u5217\uff0e\n\n#keras\u3067\u306e\u5b66\u7fd2\u7528\u306b\u30c7\u30fc\u30bf\u3092\u6574\u5f62(dict(\u30ad\u30fc, value=Numpy\u5f62\u5f0f))\ndef get_keras_data(dataset):\n    X = {\n        'name' : pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ),\n        'item_desc' : pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ),\n        'brand_name' : np.array(dataset.brand_name),\n        'category_name' : np.array(dataset.category_name),\n        'item_condition' : np.array(dataset.item_condition_id),\n        'num_vars' : np.array(dataset[[\"shipping\"]])\n    }\n    return X\n\nX_train = get_keras_data(dtrain)\nX_valid = get_keras_data(dvalid)\nX_test = get_keras_data(test)","8477c397":"\"\"\"\u6e96\u5099\"\"\"\n\nprint(X_train[\"item_condition\"].shape)\nprint(X_train[\"name\"].shape[1])","54e3e7cc":"print(X_train[\"item_condition\"].shape)","48b69401":"#keras\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9(nn)\nfrom keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras import backend as K\n\n\"\"\"\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u95a2\u6570\u306e\u5b9a\u7fa9(\u8a13\u7df4\u4e2d\u306b\u30e2\u30c7\u30eb\u5185\u90e8\u306e\u72b6\u614b\u3068\u7d71\u8a08\u91cf\u3092\u53ef\u8996\u5316\u3059\u308b\u969b\u306b\u4f7f\u3046)\"\"\"\ndef get_callbacks(filepath, patience=2):\n    #earlystopping:2\u30a8\u30dd\u30c3\u30af\u6570\u9593\u3067\u6539\u5584\u304c\u898b\u3089\u308c\u306a\u3044\u5834\u5408\u51e6\u7406\u3092\u7d42\u4e86\n    es = EarlyStopping('val_loss', patience=patience, mode='min')\n    #\u5404\u30a8\u30dd\u30c3\u30af\u7d42\u4e86\u5f8c\u306b\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\n\n\"\"\"\u8aa4\u5dee\u95a2\u6570\"\"\"\n#\u3053\u308c\u306f\u5b66\u7fd2\u5185\u306b\u304a\u3051\u308b\u640d\u5931\u95a2\u6570\u3068\u3057\u3066\u5b9a\u7fa9\ndef rmsle_cust(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n\n\"\"\"\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\"\"\"\ndef get_model():\n    \"\"\"\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4f5c\u6210\"\"\"\n    #params\n    #\u30c9\u30ed\u30c3\u30d7\u30a2\u30a6\u30c8\u3059\u308b\u5272\u5408\n    dr_r = 0.1\n    \n    #keras\u30c6\u30f3\u30bd\u30eb\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316\n    #Inputs\n    #shape\u5f15\u6570\u306f\u671f\u5f85\u3055\u308c\u308b\u5165\u529b\u6b21\u5143\u306e\u5024\n    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n    brand_name = Input(shape=[1], name=\"brand_name\")\n    #\u30ab\u30c6\u30b4\u30ea\u30fc\u306f\u3082\u3068\u3082\u3068\u968e\u5c64\u69cb\u9020\u306b\u306a\u3063\u3066\u3044\u305f\u304b\u3089\u3001\u305d\u308c\u3092\u5206\u3051\u3066\u5225\u3005\u306e\u5165\u529b\u3068\u3057\u3066\u4e88\u6e2c\u3057\u3066\u307f\u305f\u3044.\n    category_name = Input(shape=[1], name=\"category_name\")\n    item_condition = Input(shape=[1], name=\"item_condition\")\n    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n    \n    #\u6b63\u306e\u6574\u6570(\u30a4\u30f3\u30c7\u30c3\u30af\u30b9)\u3092\u56fa\u5b9a\u6b21\u5143\u306e\u5bc6\u30d9\u30af\u30c8\u30eb\u306b\u5909\u63db\u3059\u308b\n    #Embedding(\u5165\u529b\u6b21\u5143\u6570\u306e\u4e0a\u9650, \u51fa\u529b\u6b21\u5143\u6570)\n    emb_name = Embedding(MAX_TEXT, 50)(name)\n    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n    \n    #rnn layers\n    #GRU\u3067\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u51e6\u7406\n    #name\u3068item_description\u306f\u6587\u7ae0\u3067,\u5358\u8a9e\u306e\u4e26\u3073\u306b\u610f\u5473\u304c\u3042\u308b\u304b\u3089\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3068\u3057\u3066\u51e6\u7406\u3059\u308b\n    #\u6d3b\u6027\u5316\u95a2\u6570(activation=)\u3092\u6307\u5b9a\u3057\u306a\u3051\u308c\u3070tanh\u304c\u4f7f\u308f\u308c\u308b\n    rnn_layer1 = GRU(16)(emb_item_desc)\n    rnn_layer2 = GRU(8)(emb_name)\n    \n    #main layer\n    #\u5165\u529b\u5c64\n    #concatenate\u306f\u5e73\u6ed1\u5316\u3057\u305f\u540c\u3058shape\u306e\u8907\u6570\u306e\u30c6\u30f3\u30bd\u30eb\u3092\u307e\u3068\u3081\u3066\u3072\u3068\u3064\u306e\u30c6\u30f3\u30bd\u30eb\u306b\u3059\u308b(\u5f15\u6570\u306f\u30ea\u30b9\u30c8\u3068\u3068\u3057\u3066\u6e21\u3059)\n    main_layer = concatenate([\n                Flatten()(emb_brand_name), #brand_name\n                Flatten()(emb_category_name), #category_name\n                Flatten()(emb_item_condition), #item_condition_id\n                rnn_layer1, #item_description\n                rnn_layer2, #name\n                num_vars #shipping\n                ])\n    \n    #\u96a0\u308c\u5c64\n    #Dropout\u3092\u9069\u7528\u3057\u3066\u904e\u5b66\u7fd2\u3092\u9632\u304e\u305f\u3044\n    #Dense:\u5168\u7d50\u5408\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af, actiovation=\u306b\u4f55\u3082\u6307\u5b9a\u3057\u306a\u3051\u308c\u3070\u7dda\u5f62\u6d3b\u6027\u5316\u95a2\u6570\u304c\u4f7f\u308f\u308c\u308b\n    main_layer = Dropout(dr_r)(Dense(128) (main_layer))\n    main_layer = Dropout(dr_r)(Dense(64) (main_layer))\n    \n    #output\n    #\u51fa\u529b\u5c64\n    output = Dense(1, activation=\"linear\")(main_layer)\n    \n    #Model\u30af\u30e9\u30b9\u306fa\u3092\u5165\u529b\u3068\u3057\u3066b\u3092\u8a08\u7b97\u3059\u308b\u969b\u306b\u5fc5\u8981\u3068\u306a\u308b\u3042\u3089\u3086\u308b\u5c64\u3092\u542b\u3080.\n    model = Model(inputs=[name, item_desc, brand_name, category_name, item_condition, num_vars], outputs=output)\n    \"\"\"\u5b66\u7fd2\u30e2\u30c7\u30eb\u306e\u4f5c\u6210\"\"\"\n    #\u5b66\u7fd2\u30e2\u30c7\u30eb\u306e\u4f5c\u6210\u306fcompile\u30e1\u30bd\u30c3\u30c9\n    #metrics\u306b\u30ea\u30b9\u30c8\u3092\u6e21\u3059\u3053\u3068\u3067\u8907\u6570\u306e\u8a55\u4fa1\u95a2\u6570\u3067\u5bfe\u7167\u5b9f\u9a13\u3067\u304d\u308b(mae: Mean Absolute Error \u7d76\u5bfe\u5024\u5e73\u5747\u8aa4\u5dee)\n    model.compile(loss='mse', optimizer='adam', metrics=[\"mae\", rmsle_cust])\n    \n    return model    ","98c396c1":"model = get_model()\nmodel.summary()","7dfc62e5":"\"\"\"\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\"\"\"\n#\u30df\u30cb\u30d0\u30c3\u30c1\u306e\u30b5\u30a4\u30ba\nBATCH_SIZE = 20000\n#\u30a8\u30dd\u30c3\u30af\u6570(\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u30b7\u30e3\u30c3\u30d5\u30eb\u3057\u3066\u5b66\u7fd2\u3057\u76f4\u3059\u56de\u6570)\nepochs = 5\n\nmodel = get_model()\n#\u5b66\u7fd2\nmodel.fit(X_train, #\u8a13\u7df4\u30c7\u30fc\u30bf\n         dtrain.target, #\u4e88\u6e2c\u30bf\u30fc\u30b2\u30c3\u30c8: log(price + 1)\n         epochs=epochs, #\u30a8\u30dd\u30c3\u30af\u6570\n         batch_size=BATCH_SIZE, #\u7121\u4f5c\u70ba\u62bd\u51fa\u306e\u6570\n         validation_data=(X_valid, dvalid.target), #\u30e2\u30c7\u30eb\u8a55\u4fa1\u7528\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8(\u691c\u8a3c\u30c7\u30fc\u30bf).\u5b66\u7fd2\u3067\u306f\u3053\u3053\u3067\u5ba3\u8a00\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306f\u7528\u3044\u306a\u3044\n         verbose=1 #\u9032\u884c\u72b6\u6cc1\u306e\u8868\u793a\u30e2\u30fc\u30c9(0, 1, 2)\n         )\n","17610384":"#\u691c\u8a3c\u30c7\u30fc\u30bf\u3067\u8a55\u4fa1\nval_preds = model.predict(X_valid) #\u5b66\u7fd2\u304b\u3089\u9664\u3044\u305f\u691c\u8a3c\u30c7\u30fc\u30bf\u3067\u8a55\u4fa1(\u51fa\u529b\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u3067\u3042\u308blog(price + 1)\u306e\u4e00\u6b21\u5143\u30ea\u30b9\u30c8)\nval_preds = target_scaler.inverse_transform(val_preds) #\u6a19\u6e96\u5316\u304b\u3089\u5143\u306b\u623b\u3059\nval_preds = np.exp(val_preds) - 1 #log(price + 1)\u304b\u3089price\u3078\u306e\u5909\u63db\n\n#rmsle\ny_true = np.array(dvalid.price.values)\ny_pred = val_preds \n\nv_rmsle = RMSLE(y_true, y_pred)\nprint('RMSLE ERROR : ' + str(v_rmsle))","698bae78":"submission = test[[\"test_id\"]]\nsubmission","f977ae8e":"#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\npreds = model.predict(X_test, batch_size=BATCH_SIZE) #\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067log(price+1)\u3092\u4e88\u6e2c\npreds = target_scaler.inverse_transform(preds) #\u6a19\u6e96\u5316\u304b\u3089\u5143\u306b\u623b\u3059\npreds = np.exp(preds) - 1\n\nsubmission[\"price\"] = preds","999275bf":"submission.head()","dfdb5263":"submission.to_csv(\".\/mercari_submission_sub.csv\", index=False)","05ef28f8":"        Model\u30af\u30e9\u30b9\u306e\u30b5\u30f3\u30d7\u30eb\n        from keras.models import Model\n        from keras.layers import Input, Dense\n\n        a = Input(shape=(32,))\n        b = Dense(32)(a)\n        model = Model(inputs=a, outputs=b)\n        \n        \u3061\u306a\u307f\u306bSequential()\u30e2\u30c7\u30eb\u306e\u5834\u5408\u306fstack\u306e\u8981\u9818\u3067\u30e2\u30c7\u30eb\u306b\u5c64\u3092\u7a4d\u307f\u4e0a\u3052\u3066\u69cb\u7bc9\u3067\u304d\u308b.","a03b6394":"tensorflow\u6e96\u5099","d6fe031e":"# Make a code while refering Top score's code","5317c21b":"# tensorflow2.0\u3067\u306f\u3067\u304d\u306a\u3044\u3068\u5224\u660e\u3057\u305f\u306e\u3067\u3001Keras\u3067nn\u69cb\u7bc9\u3057\u305f\u65b9\u306e\u30b3\u30fc\u30c9\u3092\u53c2\u7167\u3059\u308b","7d7aebaa":"\u305d\u3093\u306a\u306b\u6563\u3089\u3070\u308a\u306f\u7121\u304b\u3063\u305f.","0a0af892":"# Investigation of item_condition_id"}}