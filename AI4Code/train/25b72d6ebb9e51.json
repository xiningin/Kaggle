{"cell_type":{"d40059b2":"code","5e57c417":"code","7b6b0eec":"code","fe7b6d6a":"code","3c6f8e29":"code","1c2ff221":"code","7016e315":"code","ce603d5e":"code","abc7585e":"code","142205c8":"code","53ef989b":"code","b3fdd0e5":"code","1b65dc31":"code","224e4543":"code","124d206d":"code","7736c729":"code","f8923592":"code","1627dbae":"code","94225811":"code","29c7581d":"code","2d8d0389":"code","657a4971":"code","d7255b0f":"code","8a87d1b2":"code","1426b92f":"code","c8a02406":"code","e3a17382":"code","a9bd5984":"code","87391fb4":"code","f3fffeb2":"code","2477e8f6":"code","7dc78253":"code","e678c195":"code","5a524249":"code","3b9d3a2c":"code","9a563547":"code","c39ba8a1":"code","d10ce6c1":"code","843f7ae3":"code","11e711bf":"code","9d947b69":"code","d2161ce3":"code","7ade99bb":"markdown","2150b57b":"markdown","cd8324e5":"markdown","f04e1217":"markdown","47b61e39":"markdown","5a3ca262":"markdown","dbe71797":"markdown","86b14f08":"markdown","24dbad94":"markdown","f5f781bb":"markdown","e511f5e7":"markdown","9c184732":"markdown","47521e33":"markdown","31fbc420":"markdown","92c6732b":"markdown","adb91f9f":"markdown","39197392":"markdown"},"source":{"d40059b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5e57c417":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import pandas_datareader as web\nimport plotly.graph_objects as go\nfrom itertools import cycle\nimport plotly.express as px\nfrom sklearn.preprocessing import MinMaxScaler\nimport math\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n#from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import LSTM, GRU","7b6b0eec":"#import dataset\nimport os\ndata = pd.read_csv('..\/input\/apple-stock-price-prediction\/AAPL.csv')\ndata.tail()","fe7b6d6a":"data.describe()","3c6f8e29":"data.isnull().sum()\n#No any missing values","1c2ff221":"#check the data type\ndata.dtypes","7016e315":"print(\"Total number of days: \",data.shape[0])\nprint(\"Total number of fields: \",data.shape[1])","ce603d5e":"# convert date field from string to Date format \ndata['Date'] = pd.to_datetime(data['Date'])","abc7585e":"data.head()","142205c8":"data.info()","53ef989b":"data.shape #1258 rows and 7 columns that the data frame have ","b3fdd0e5":"#Find the duration of dataset\nprint(\"Starting date: \",data.iloc[0][0])\nprint(\"Ending date: \", data.iloc[-1][0])\nprint(\"Duration: \", data.iloc[-1][0]-data.iloc[0][0])","1b65dc31":"# Monthwise comparision between Stock open and close price\nmonthvise = data.groupby(data['Date'].dt.strftime('%B'))[['Open','Close']].mean()\nnew_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', \n             'September', 'October', 'November', 'December']\nmonthvise = monthvise.reindex(new_order, axis=0)\nmonthvise","224e4543":"#plotting the data\nplt.figure(figsize=(16,8))\nplt.title('Close Price History')\nplt.plot(data['Close'], color='red')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD', fontsize = 18)\nplt.show()","124d206d":"fig = go.Figure()\nfig.add_trace(go.Bar(\n    x=monthvise.index,\n    y=monthvise['Open'],\n    name='Stock Open Price',\n    marker_color='crimson'\n))\nfig.add_trace(go.Bar(\n    x=monthvise.index,\n    y=monthvise['Close'],\n    name='Stock Close Price',\n    marker_color='lightsalmon'\n))\n\nfig.update_layout(barmode='group', xaxis_tickangle=-45, \n                  title='Monthwise comparision between Stock open and close price')\nfig.show()","7736c729":"#Monthwise High and Low stock price\ndata.groupby(data['Date'].dt.strftime('%B'))['Low'].min()\nmonthvise_high = data.groupby(data['Date'].dt.strftime('%B'))['High'].max()\nmonthvise_high = monthvise_high.reindex(new_order, axis=0)\n\nmonthvise_low = data.groupby(data['Date'].dt.strftime('%B'))['Low'].min()\nmonthvise_low = monthvise_low.reindex(new_order, axis=0)\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=monthvise_high.index,\n    y=monthvise_high,\n    name='Stock high Price',\n    marker_color='rgb(0, 153, 204)'\n))\nfig.add_trace(go.Bar(\n    x=monthvise_low.index,\n    y=monthvise_low,\n    name='Stock low Price',\n    marker_color='rgb(255, 128, 0)'\n))\n\nfig.update_layout(barmode='group', \n                  title=' Monthwise High and Low stock price')\nfig.show()","f8923592":"#Trend comparision between stock open price, close price, high price, low price\nnames = cycle(['Stock Open Price','Stock Close Price','Stock High Price','Stock Low Price'])\n\nfig = px.line(data, x=data.Date, y=[data['Open'], data['Close'], \n                                          data['High'], data['Low']],\n             labels={'date': 'Date','value':'Stock value'})\nfig.update_layout(title_text='Stock analysis chart', font_size=15, font_color='black',legend_title_text='Stock Parameters')\nfig.for_each_trace(lambda t:  t.update(name = next(names)))\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.show()","1627dbae":"#Make separate dataframe of close price\nclosedf = data[['Date','Close']]\nprint(\"Shape of close dataframe:\", closedf.shape)","94225811":"#Plotting Stock Close price chart\nfig = px.line(closedf, x=closedf.Date, y=closedf.Close,labels={'date':'Date','close':'Close Stock'})\nfig.update_traces(marker_line_width=2, opacity=0.8)\nfig.update_layout(title_text='Stock close price chart', plot_bgcolor='white', font_size=15, font_color='black')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","29c7581d":"closedf = closedf[closedf['Date'] > '2020-08-16']\nclose_stock = closedf.copy()\nprint(\"Total data for prediction: \",closedf.shape[0])","2d8d0389":"fig = px.line(closedf, x=closedf.Date, y=closedf.Close,labels={'date':'Date','close':'Close Stock'})\nfig.update_traces(marker_line_width=2, opacity=0.8, marker_line_color='orange')\nfig.update_layout(title_text='Considered period to predict Stock close price', plot_bgcolor='white', font_size=15, font_color='black')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()\n","657a4971":"# create a new data frame with only 'Close column'\ndata = data.filter(['Close'])\ndataset = data.values #convert the data frame to a numpy array\ntraining_data_len = math.ceil(len(dataset)*.8)  # number of rows to train the model on\ntraining_data_len","d7255b0f":"#scale the data\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\nscaled_data","8a87d1b2":"print(scaled_data.shape)","1426b92f":"#Normalizing close price\ndel closedf['Date']\nscaler=MinMaxScaler(feature_range=(0,1))\nclosedf=scaler.fit_transform(np.array(closedf).reshape(-1,1))\nprint(closedf.shape)","c8a02406":"training_size=int(len(closedf)*0.60)\ntest_size=len(closedf)-training_size\ntrain_data,test_data=closedf[0:training_size,:],closedf[training_size:len(closedf),:1]\nprint(\"train_data: \", train_data.shape)\nprint(\"test_data: \", test_data.shape) ","e3a17382":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, time_step=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-time_step-1):\n        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n        dataX.append(a)\n        dataY.append(dataset[i + time_step, 0])\n    return np.array(dataX), np.array(dataY)\ntime_step = 15\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, y_test = create_dataset(test_data, time_step)\n\nprint(\"X_train: \", X_train.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"X_test: \", X_test.shape)\nprint(\"y_test\", y_test.shape)","a9bd5984":"# reshape input to be [samples, time steps, features] which is required for LSTM\nX_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n\nprint(\"X_train: \", X_train.shape)\nprint(\"X_test: \", X_test.shape)","87391fb4":"tf.keras.backend.clear_session()\nmodel=Sequential()\nmodel.add(GRU(32,return_sequences=True,input_shape=(time_step,1)))\nmodel.add(GRU(32,return_sequences=True))\nmodel.add(GRU(32))\nmodel.add(Dropout(0.20))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')","f3fffeb2":"model.summary()","2477e8f6":"history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=200,batch_size=32,verbose=1)","7dc78253":"import matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()\n","e678c195":"### Lets Do the prediction and check performance metrics\ntrain_predict=model.predict(X_train)\ntest_predict=model.predict(X_test)\ntrain_predict.shape, test_predict.shape","5a524249":"# Transform back to original form\n\ntrain_predict = scaler.inverse_transform(train_predict)\ntest_predict = scaler.inverse_transform(test_predict)\noriginal_ytrain = scaler.inverse_transform(y_train.reshape(-1,1)) \noriginal_ytest = scaler.inverse_transform(y_test.reshape(-1,1)) ","3b9d3a2c":"# Evaluation metrices RMSE and MAE\nprint(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_ytrain,train_predict)))\nprint(\"Train data MSE: \", mean_squared_error(original_ytrain,train_predict))\nprint(\"Train data MAE: \", mean_absolute_error(original_ytrain,train_predict))\nprint(\"-------------------------------------------------------------------------------------\")\nprint(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_ytest,test_predict)))\nprint(\"Test data MSE: \", mean_squared_error(original_ytest,test_predict))\nprint(\"Test data MAE: \", mean_absolute_error(original_ytest,test_predict))","9a563547":"print(\"Train data explained variance regression score:\", explained_variance_score(original_ytrain, train_predict))\nprint(\"Test data explained variance regression score:\", explained_variance_score(original_ytest, test_predict))","c39ba8a1":"print(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\nprint(\"Test data R2 score:\", r2_score(original_ytest, test_predict))","d10ce6c1":"# shift train predictions for plotting\n\nlook_back=time_step\ntrainPredictPlot = np.empty_like(closedf)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\nprint(\"Train predicted data: \", trainPredictPlot.shape)\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(closedf)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-1, :] = test_predict\nprint(\"Test predicted data: \", testPredictPlot.shape)\n\nnames = cycle(['Original close price','Train predicted close price','Test predicted close price'])\nplotdf = pd.DataFrame({'Date': close_stock['Date'],\n                       'original_close': close_stock['Close'],\n                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n\nfig = px.line(plotdf,x=plotdf['Date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n                                          plotdf['test_predicted_close']],\n              labels={'value':'Stock price','date': 'Date'})\nfig.update_layout(title_text='Comparision between original close price vs predicted close price',\n                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\nfig.for_each_trace(lambda t:  t.update(name = next(names)))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","843f7ae3":"x_input=test_data[len(test_data)-time_step:].reshape(1,-1)\ntemp_input=list(x_input)\ntemp_input=temp_input[0].tolist()\n\nfrom numpy import array\n\nlst_output=[]\nn_steps=time_step\ni=0\npred_days = 30\nwhile(i<pred_days):\n    \n    if(len(temp_input)>time_step):\n        \n        x_input=np.array(temp_input[1:])\n        #print(\"{} day input {}\".format(i,x_input))\n        x_input = x_input.reshape(1,-1)\n        x_input = x_input.reshape((1, n_steps, 1))\n        \n        yhat = model.predict(x_input, verbose=0)\n        #print(\"{} day output {}\".format(i,yhat))\n        temp_input.extend(yhat[0].tolist())\n        temp_input=temp_input[1:]\n        #print(temp_input)\n        lst_output.extend(yhat.tolist())\n        i=i+1\n        \n    else:\n        \n        x_input = x_input.reshape((1, n_steps,1))\n        yhat = model.predict(x_input, verbose=0)\n        temp_input.extend(yhat[0].tolist())\n        \n        lst_output.extend(yhat.tolist())\n        i=i+1\n               \nprint(\"Output of predicted next days: \", len(lst_output))\n\n\n","11e711bf":"last_days=np.arange(1,time_step+1)\nday_pred=np.arange(time_step+1,time_step+pred_days+1)\nprint(last_days)\nprint(day_pred)","9d947b69":"temp_mat = np.empty((len(last_days)+pred_days+1,1))\ntemp_mat[:] = np.nan\ntemp_mat = temp_mat.reshape(1,-1).tolist()[0]\n\nlast_original_days_value = temp_mat\nnext_predicted_days_value = temp_mat\n\nlast_original_days_value[0:time_step+1] = scaler.inverse_transform(closedf[len(closedf)-time_step:]).reshape(1,-1).tolist()[0]\nnext_predicted_days_value[time_step+1:] = scaler.inverse_transform(np.array(lst_output).reshape(-1,1)).reshape(1,-1).tolist()[0]\n\nnew_pred_plot = pd.DataFrame({\n    'last_original_days_value':last_original_days_value,\n    'next_predicted_days_value':next_predicted_days_value\n})\nnames = cycle(['Last 15 days close price','Predicted next 30 days close price'])\n\nfig = px.line(new_pred_plot,x=new_pred_plot.index, y=[new_pred_plot['last_original_days_value'],\n                                                      new_pred_plot['next_predicted_days_value']],\n              labels={'value': 'Stock price','index': 'Timestamp'})\nfig.update_layout(title_text='Compare last 15 days vs next 30 days',\n                  plot_bgcolor='white', font_size=15, font_color='black',legend_title_text='Close Price')\n\nfig.for_each_trace(lambda t:  t.update(name = next(names)))\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","d2161ce3":"lstmdf=closedf.tolist()\nlstmdf.extend((np.array(lst_output).reshape(-1,1)).tolist())\nlstmdf=scaler.inverse_transform(lstmdf).reshape(1,-1).tolist()[0]\n\nnames = cycle(['Close price'])\n\nfig = px.line(lstmdf,labels={'value': 'Stock price','index': 'Timestamp'})\nfig.update_layout(title_text='Plotting whole closing stock price with prediction',\n                  plot_bgcolor='white', font_size=15, font_color='black',legend_title_text='Stock')\n\nfig.for_each_trace(lambda t:  t.update(name = next(names)))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","7ade99bb":"Model Evaluation","2150b57b":"Consider only last 1 year data for prediction","cd8324e5":"Model Building (GRU) GRUs (Gated Recurrent Units) are very similar to Long Short Term Memory(LSTM). Just like LSTM, GRU uses gates to control the flow of information. They are relatively new as compared to LSTM. This is the reason they offer some improvement over LSTM and have simpler architecture.","f04e1217":"Regression Loss Mean Gamma deviance regression loss (MGD) and Mean Poisson deviance regression loss (MPD)","47b61e39":"Here, We are going to predict close price for next 30 days\n\nPrepare Stock Close price","5a3ca262":"Data Preprocessing","dbe71797":"Explained variance regression score The explained variance score explains the dispersion of errors of a given dataset, and the formula is written as follows: Here, and Var(y) is the variance of prediction errors and actual values respectively. Scores close to 1.0 are highly desired, indicating better squares of standard deviations of errors.","86b14f08":"R2 score for regression R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\n\n1 = Best 0 or < 0 = worse","24dbad94":"Plotting entire Closing Stock Price with next 30 days period of prediction","f5f781bb":"Plotting last 15 days of dataset and next predicted 30 days","e511f5e7":"Prepare Data for train and test","9c184732":"EDA - Exploratory Data Analysis","47521e33":"Transform Close price base on Time-series-analysis forecasting requirement","31fbc420":"> ","92c6732b":"Comparision of original stock close price and predicted close price","adb91f9f":"Plotting loss chart","39197392":"Predicting next 30 days\n\n"}}