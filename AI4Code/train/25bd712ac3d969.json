{"cell_type":{"435ad4d8":"code","0a04aa54":"code","2929a7df":"code","cfefdd66":"code","7d0a14aa":"code","8f6e03b9":"code","318b93c4":"code","7f4cf17b":"code","05ef23ad":"code","75219d8d":"code","b6225e05":"code","ac724724":"code","e059e983":"code","1b6419a8":"code","ca65f9e2":"code","dd3fc1f3":"code","2299d8da":"code","50c07563":"code","94741475":"code","e12797f8":"code","47016146":"code","a54edf3a":"code","4166c96b":"code","b17a0d3a":"code","914daefb":"code","c8336cd6":"code","9a03834a":"code","1fd5bdae":"code","86f206ca":"code","4626cf7c":"code","d0046f96":"code","15463861":"code","f97f3078":"code","8c8715bf":"markdown"},"source":{"435ad4d8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\ntweets=pd.read_csv(\"..\/input\/demonetization-tweets.csv\",encoding = \"ISO-8859-1\")\ntweets.head()\n","0a04aa54":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\n\nfrom nltk import tokenize\n\nsid = SentimentIntensityAnalyzer()\n\ntweets['sentiment_compound_polarity']=tweets.text.apply(lambda x:sid.polarity_scores(x)['compound'])\ntweets['sentiment_neutral']=tweets.text.apply(lambda x:sid.polarity_scores(x)['neu'])\ntweets['sentiment_negative']=tweets.text.apply(lambda x:sid.polarity_scores(x)['neg'])\ntweets['sentiment_pos']=tweets.text.apply(lambda x:sid.polarity_scores(x)['pos'])\ntweets['sentiment_type']=''\ntweets.loc[tweets.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\ntweets.loc[tweets.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\ntweets.loc[tweets.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\ntweets.head()","2929a7df":"tweets.sentiment_type.value_counts().plot(kind='bar',title=\"sentiment analysis\", color=['g','b','r'])","cfefdd66":"import bokeh\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS\nimport re\nimport seaborn as sns\nfrom IPython.display import display\npd.options.mode.chained_assignment = None\nimport matplotlib\nimport re\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import plot_importance\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nfrom sklearn.preprocessing import LabelEncoder\nfrom nltk import tokenize\nmatplotlib.style.use('ggplot')\n\n#Getting data\ntweets = pd.read_csv('..\/input\/demonetization-tweets.csv', encoding = \"ISO-8859-1\")\ndisplay(tweets.text.head(10))","7d0a14aa":"tweets['tweetos'] = '' \n\n# add tweetos first part\nfor i in range(len(tweets['text'])):\n    try:\n        tweets['tweetos'][i] = tweets['text'].str.split(' ')[i][0]\n    except AttributeError:    \n        tweets['tweetos'][i] = 'other'\n\n# Preprocessing tweetos. select tweetos contains 'RT @'\nfor i in range(len(tweets['text'])):\n    if tweets['tweetos'].str.contains('@')[i]  == False:\n        tweets['tweetos'][i] = 'other'\n        \n# remove URLs, RTs, and twitter handles\nfor i in range(len(tweets['text'])):\n    tweets['text'][i] = \" \".join([word for word in tweets['text'][i].split()\n                                if 'http' not in word and '@' not in word and '<' not in word])   \n        \ndisplay(tweets.text.head(10))","8f6e03b9":"tweets.columns","318b93c4":"def wordcloud_by_province(tweets):\n    stopwords = set(STOPWORDS)\n    stopwords.add(\"https\")\n    stopwords.add(\"00A0\")\n    stopwords.add(\"00BD\")\n    stopwords.add(\"00B8\")\n    stopwords.add(\"ed\")\n    stopwords.add(\"demonetization\")\n    stopwords.add(\"Demonetization co\")\n    #Narendra Modi is the Prime minister of India\n    stopwords.add(\"lakh\")\n    wordcloud = WordCloud(background_color=\"white\",stopwords=stopwords,random_state = 2016).generate(\" \".join([i for i in tweets['text'].str.upper()]))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.title(\"Demonetization\")\n\nwordcloud_by_province(tweets)  ","7f4cf17b":"print(tweets['retweetCount'].describe())","05ef23ad":"tweets['nb_words'] = 0\nfor i in range(len(tweets['text'])):\n    tweets['nb_words'][i] = len(tweets['text'][i].split(' '))","75219d8d":"tweets['hour'] = pd.DatetimeIndex(tweets['created']).hour\ntweets['date'] = pd.DatetimeIndex(tweets['created']).date\ntweets['minute'] = pd.DatetimeIndex(tweets['created']).minute","b6225e05":"tweets_hour = tweets.groupby(['hour'])['retweetCount'].sum()\ntweets_minute = tweets.groupby(['minute'])['retweetCount'].sum()\ntweets['text_len'] = tweets['text'].str.len()\ntweets_avgtxt_hour = tweets.groupby(['hour'])['text_len'].mean()\ntweets_avgwrd_hour = tweets.groupby(['hour'])['nb_words'].mean()","ac724724":"import seaborn as sns\ntweets_hour.transpose().plot(kind='line',figsize=(6.5, 4))\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.title('The number of retweet by hour', bbox={'facecolor':'0.8', 'pad':0})","e059e983":"tweets_minute.transpose().plot(kind='line',figsize=(6.5, 4))\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.title('The number of retweet by minute', bbox={'facecolor':'0.8', 'pad':0})","1b6419a8":"tweets_avgtxt_hour.transpose().plot(kind='line',figsize=(6.5, 4))\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.title('The Average of length of Tweets by hour', bbox={'facecolor':'0.8', 'pad':0})","ca65f9e2":"def get_stop_words(s, n):\n    '''\n    :s : pd.Series; each element as a list of words from tokenization\n    :n : int; n most frequent words are judged as stop words \n\n    :return : list; a list of stop words\n    '''\n    from collections import Counter\n    l = get_corpus(s)\n    l = [x for x in Counter(l).most_common(n)]\n    return l\n\ndef get_corpus(s):\n    '''\n    :s : pd.Series; each element as a list of words from tokenization\n\n    :return : list; corpus from s\n    '''\n    l = []\n    s.map(lambda x: l.extend(x))\n    return l\n\nfreqwords = get_stop_words(tweets['text'],n=60)\n\nfreq = [s[1] for s in freqwords]\n\nplt.title('frequency of top 60 most frequent words', bbox={'facecolor':'0.8', 'pad':0})\nplt.plot(freq)\nplt.xlim([-1,60])\nplt.ylim([0,1.1*max(freq)])\nplt.ylabel('frequency')\nplt.show()","dd3fc1f3":"tweets['statusSource_new'] = ''\n\nfor i in range(len(tweets['statusSource'])):\n    m = re.search('(?<=>)(.*)', tweets['statusSource'][i])\n    try:\n        tweets['statusSource_new'][i]=m.group(0)\n    except AttributeError:\n        tweets['statusSource_new'][i]=tweets['statusSource'][i]\n        \n#print(tweets['statusSource_new'].head())   \n\ntweets['statusSource_new'] = tweets['statusSource_new'].str.replace('<\/a>', ' ', case=False)","2299d8da":"tweets['statusSource_new'] = tweets['statusSource_new'].str.replace('<\/a>', ' ', case=False)\nprint(tweets[['statusSource_new','retweetCount']])\n\ntweets_by_type= tweets.groupby(['statusSource_new'])['retweetCount'].sum()\n\n","50c07563":"print(sorted(tweets_by_type))","94741475":"tweets_by_type.transpose().plot(kind='bar',figsize=(10, 5))\n#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.title('Number of retweetcount by Source', bbox={'facecolor':'0.8', 'pad':0})","e12797f8":"tweets['statusSource_new2'] = ''\n\nfor i in range(len(tweets['statusSource_new'])):\n    if tweets['statusSource_new'][i] not in ['Twitter for Android ','Twitter Web Client ','Twitter for iPhone ']:\n        tweets['statusSource_new2'][i] = 'Others'\n    else:\n        tweets['statusSource_new2'][i] = tweets['statusSource_new'][i] \n#print(tweets['statusSource_new2'])       \n\ntweets_by_type2 = tweets.groupby(['statusSource_new2'])['retweetCount'].sum()","47016146":"tweets_by_type2.rename(\"\",inplace=True)\nexplode = (0, 0, 0, 1.0)\ntweets_by_type2.transpose().plot(kind='pie',figsize=(6.5, 4),autopct='%1.1f%%',shadow=True,explode=explode)\nplt.legend(bbox_to_anchor=(1, 1), loc=6, borderaxespad=0.)\nplt.title('Number of retweetcount by Source bis', bbox={'facecolor':'0.8', 'pad':5})","a54edf3a":"from sklearn.feature_extraction.text import TfidfVectorizer\n####\nfrom nltk.stem import WordNetLemmatizer\n#tweets['text_sep'] = [''.join(z).strip() for z in tweets['text_new']]\ntweets['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in tweets['text']]       \n####\nvectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\nX = vectorizer.fit_transform(tweets['text_lem'].str.upper())\nprint(X.shape)\n#print(tweets['text_sep'])\n#print(tweets['text_new'])","4166c96b":"from sklearn.cluster import KMeans\nkm = KMeans(n_clusters=5,init='k-means++',max_iter=200,n_init=1)","b17a0d3a":"km.fit(X)\nterms = vectorizer.get_feature_names()\norder_centroids = km.cluster_centers_.argsort()[:,::-1]\nfor i in range(5):\n    print(\"cluster %d:\" %i, end='')\n    for ind in order_centroids[i,:10]:\n        print(' %s' % terms[ind], end='')\n    print()    ","914daefb":"le = LabelEncoder()\ntweets['favorited'] = le.fit_transform(tweets['favorited'])\ntweets['replyToSN'] = tweets['replyToSN'].fillna(-999)\ntweets['truncated'] = le.fit_transform(tweets['truncated'])\ntweets['replyToSID'] = tweets['replyToSID'].fillna(-999)\ntweets['id'] = le.fit_transform(tweets['id'])\ntweets['replyToUID'] = tweets['replyToUID'].fillna(-999)\ntweets['statusSource_new'] = le.fit_transform(tweets['statusSource_new'])\ntweets['isRetweet'] = le.fit_transform(tweets['isRetweet'])\ntweets['retweeted'] = le.fit_transform(tweets['retweeted'])\ntweets['screenName'] = le.fit_transform(tweets['screenName'])\ntweets['tweetos'] = le.fit_transform(tweets['tweetos'])\n\ntweets_num = tweets[tweets.select_dtypes(exclude=['object']).columns.values]\ntweets_num.drop('Unnamed: 0',inplace=True,axis=1)\ntweets_num.drop('retweeted',inplace=True,axis=1)\ntweets_num.drop('favorited',inplace=True,axis=1)\nprint(tweets.select_dtypes(exclude=['object']).columns.values)","c8336cd6":"import seaborn as sns\n\nsns.set(style=\"white\")\n# Compute the correlation matrix\ncorr = tweets_num.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(10, 4))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(920, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.1,\n            square=True, xticklabels=True, yticklabels=True,\n            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\nplt.title('Correlation between numerical features', bbox={'facecolor':'0.8', 'pad':0})","9a03834a":"sid = SentimentIntensityAnalyzer()\ntweets['sentiment_compound_polarity']=tweets.text_lem.apply(lambda x:sid.polarity_scores(x)['compound'])\ntweets['sentiment_neutral']=tweets.text_lem.apply(lambda x:sid.polarity_scores(x)['neu'])\ntweets['sentiment_negative']=tweets.text_lem.apply(lambda x:sid.polarity_scores(x)['neg'])\ntweets['sentiment_pos']=tweets.text_lem.apply(lambda x:sid.polarity_scores(x)['pos'])\ntweets['sentiment_type']=''\ntweets.loc[tweets.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\ntweets.loc[tweets.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\ntweets.loc[tweets.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\ntweets.head()","1fd5bdae":"matplotlib.style.use('ggplot')\n\ntweets_sentiment = tweets.groupby(['sentiment_type'])['sentiment_neutral'].count()\ntweets_sentiment.rename(\"\",inplace=True)\nexplode = (0, 0, 1.0)\nplt.subplot(221)\ntweets_sentiment.transpose().plot(kind='barh',figsize=(10, 6))\nplt.title('Sentiment Analysis 1', bbox={'facecolor':'0.8', 'pad':0})\nplt.subplot(222)\ntweets_sentiment.plot(kind='pie',figsize=(10, 6),autopct='%1.1f%%',shadow=True,explode=explode)\nplt.legend(bbox_to_anchor=(1, 1), loc=3, borderaxespad=0.)\nplt.title('Sentiment Analysis 2', bbox={'facecolor':'0.8', 'pad':0})\nplt.show()","86f206ca":"tweets['count'] = 1\ntweets_filtered = tweets[['hour', 'sentiment_type', 'count']]\npivot_tweets = tweets_filtered.pivot_table(tweets_filtered, index=[\"sentiment_type\", \"hour\"], aggfunc=np.sum)\nprint(pivot_tweets.head(50))","4626cf7c":"sentiment_type = pivot_tweets.index.get_level_values(0).unique()\n#f, ax = plt.subplots(2, 1, figsize=(8, 10))\nplt.setp(ax, xticks=list(range(0,24)))\n\nfor sentiment_type in sentiment_type:\n    split = pivot_tweets.xs(sentiment_type)\n    split[\"count\"].plot( legend=True, label='' + str(sentiment_type))\nplt.title('Evolution of sentiments by hour', bbox={'facecolor':'0.8', 'pad':0})","d0046f96":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\ntweets_num_mod = tweets[tweets.select_dtypes(exclude=['object']).columns.values]\ntarget = tweets_num_mod['retweetCount']\ntweets_num_mod.drop('retweetCount',inplace=True,axis=1)\ntweets_num_mod.drop('Unnamed: 0',inplace=True,axis=1)\n\n#Just simple  and single model\nmodel_xg = XGBRegressor()\nmodel_rf = RandomForestRegressor()\nmodel_gb = GradientBoostingRegressor()\nmodel_dt = DecisionTreeRegressor()","15463861":"scores_xg = cross_val_score(model_xg, tweets_num_mod, target, cv=5,scoring='r2')\nscores_rf = cross_val_score(model_rf, tweets_num_mod, target, cv=5,scoring='r2')\nscores_dt = cross_val_score(model_dt, tweets_num_mod, target, cv=5,scoring='r2')\nscores_gb = cross_val_score(model_gb, tweets_num_mod, target, cv=5,scoring='r2')","f97f3078":"print(\"Mean of scores for XG:\", sum(scores_xg) \/ float(len(scores_xg)))\nprint(\"Mean of scores for RF:\", sum(scores_rf) \/ float(len(scores_rf)))\nprint(\"Mean of scores for DT:\", sum(scores_dt) \/ float(len(scores_dt)))\nprint(\"Mean of scores for gb:\", sum(scores_gb) \/ float(len(scores_gb)))\n","8c8715bf":"**Model for Retweet Count**"}}