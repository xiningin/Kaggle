{"cell_type":{"88586e8e":"code","ad85879d":"code","0ef3ba83":"code","e3aa590a":"code","d316d1af":"code","9cc73b0b":"code","5c49c7bd":"code","0dc21714":"code","229b99ce":"code","13d036be":"code","e2b32cf9":"code","ac53a8a3":"code","5bbc7a1d":"code","5523f775":"code","17b7d06e":"code","a0a146b1":"code","cbd54df7":"code","977d3497":"code","f8635151":"code","49672562":"code","2cba25a0":"code","425a298a":"code","29285275":"code","cff25b9e":"code","2aba7ede":"code","39218486":"code","ec9cafe2":"code","5ecabc5e":"code","2c9c85e8":"code","d077c835":"code","ec9ea04b":"code","95ed2061":"code","585769b8":"code","456e48ee":"markdown","7a539470":"markdown","ba702db2":"markdown","506e2322":"markdown","e2c086ec":"markdown","1cb5e309":"markdown","f0174f7c":"markdown","d76e6351":"markdown","e91e9bb9":"markdown","52d87519":"markdown","9808b2d4":"markdown","b0799aca":"markdown","8b792ee2":"markdown","db6d6ef1":"markdown","b7cc71f2":"markdown","2937890e":"markdown","101c21b0":"markdown","86451342":"markdown","ec227469":"markdown","6d1db5d8":"markdown","1fab2a3b":"markdown","686d56a1":"markdown","f70182e6":"markdown","b75bf0e4":"markdown","4ee1ac21":"markdown","a12172ce":"markdown","9e65fb79":"markdown","772f778b":"markdown","09eb35ec":"markdown"},"source":{"88586e8e":"import os\nimport numpy as np\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\nfrom scipy.stats import shapiro\nfrom scipy.stats import levene\nimport missingno\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\nfrom collections import Counter\nfrom lightgbm import LGBMClassifier\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import plot_roc_curve\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ad85879d":"heart = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\ndf = heart.copy()\ndf.head()","0ef3ba83":"def check_df(dataframe, head=5):\n    \n    print(\" SHAPE \".center(70,'#'))\n    print('Rows: {}'.format(dataframe.shape[0]))\n    print('Columns: {}'.format(dataframe.shape[1]))\n    print(\" TYPES \".center(70,'#'))\n    print(dataframe.dtypes)\n    print(\" HEAD \".center(70,'#'))\n    print(dataframe.head(head))\n    print(' TAIL '.center(70,'#'))\n    print(dataframe.tail(head))\n    print(' MISSING VALUES '.center(70,'#'))\n    print(dataframe.isnull().sum())\n    print(' DUPLICATED VALUES '.center(70,'#'))\n    print(dataframe.duplicated().sum())\n    print(\" QUANTILES \".center(70,'#'))\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n    \ncheck_df(df)","e3aa590a":"desc = df.describe().T\ndesc_df = pd.DataFrame(index= [col for col in df.columns if df[col].dtype != 'O'], \n                   columns= df.describe().T.columns.tolist(),data= desc )\n\nf,ax = plt.subplots(figsize=(12,8))\nsns.heatmap(desc_df, annot=True,cmap = \"Purples\", fmt= '.0f',\n            ax=ax,linewidths = 5, cbar = False,\n            annot_kws={\"size\": 16})\n\nplt.xticks(size = 18)\nplt.yticks(size = 14, rotation = 0)\nplt.title(\"Descriptive Statistics\", size = 16)\nplt.show()","d316d1af":"missingno.matrix(df, fontsize = 18)\nplt.show()","9cc73b0b":"df.profile_report()","5c49c7bd":"cat_cols = [col for col in df.columns if df[col].dtypes == 'O']\nnum_but_cat = [col for col in df.columns if df[col].nunique() < 10 and df[col].dtypes != 'O']\ncat_but_car = [col for col in df.columns if df[col].nunique() > 20 and df[col].dtypes == 'O']\ncat_cols = cat_cols + num_but_cat\ncat_cols = [col for col in cat_cols if col not in cat_but_car]\n\ndef cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"#\"*50)\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe,palette='Accent')\n        plt.show()\n        \nfor i in cat_cols:\n    print((' '+i.upper()+' ').center(50,'#'))\n    cat_summary(df,i,plot=True)","0dc21714":"num_cols = [col for col in df.columns if col not in cat_cols and df[col].dtypes != 'O']\nfor i in num_cols:\n    fig, axes = plt.subplots(1, 2,figsize=(12,4))\n    fig.suptitle(i.title(),size=12)\n    sns.boxplot(ax=axes[0],y=i,x='output',data=df,palette='Accent')\n    sns.histplot(ax=axes[1],x=i,hue='output',data=df,palette='Accent')\n    plt.show()","229b99ce":"num_cols.append('output')\nplt.figure(figsize=(20,20))\nsns.pairplot(df[num_cols],hue='output',palette='Accent')\nplt.show()\nnum_cols.remove('output')","13d036be":"sns.set_style(\"white\")\nmatrix = np.triu(df.corr(method=\"pearson\"))\nf,ax=plt.subplots(figsize = (14,14))\nsns.heatmap(df.corr(),annot= True,fmt = \".2f\",ax=ax,\n            vmin = -1, vmax = 1, mask = matrix, cmap = \"PRGn\",\n            linewidth = 0.4,linecolor = \"white\",annot_kws={\"size\": 12})\nplt.xticks(rotation=60,size=14)\nplt.yticks(rotation=0,size=14)\nplt.title('Pearson Correlation Map', size = 14)\nplt.show()","e2b32cf9":"color = ['#A75BD5','#66D461']\nfig = go.Figure()\nfor i in df['output'].unique():\n    fig.add_trace(go.Scatter(x=df[df['output']==i]['age'],\n                            y=df[df['output']==i]['thalachh'],\n                            mode='markers', name=str(i),showlegend = True,\n                            marker = dict(color = color[i],size = 16,\n                                          opacity = 0.65,line=dict(color='black', width=0.9))))\n    \nfig.update_layout(title=dict(text='age & thalachh',\n                               y=0.9,x=0.5,xanchor= 'center',yanchor= 'top'),\n                               xaxis = dict(title='age'),\n                               yaxis =dict(title='thalachh'),template='plotly_white')\n\niplot(fig)","ac53a8a3":"data = go.Scatter3d(x = df['age'],y = df['trtbps'],z = df['chol'],\n                    mode='markers',text=df['output'], marker=dict(color=df['output'],size=7,\n                                                colorscale='Sunsetdark',showscale=False,opacity=0.65))\n\nlayout = go.Layout(title=dict(text='Age - trtbps - chol',y=0.9,x=0.5,xanchor= 'center',yanchor= 'top'),\n                   scene = dict(xaxis = dict(title='Age'),\n                                yaxis = dict(title = 'trtbps'),\n                                zaxis = dict(title='chol')),template='plotly_white')\n\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","5bbc7a1d":"fig = go.Figure(data=[go.Pie(labels=['Yes','No'],\n                             values=df['output'].value_counts()[0:5].values,\n                             pull=[0, 0.1])])\n\nfig.update_traces(hoverinfo='label', textinfo='percent', textfont_size=20,textposition ='auto',\n                  marker=dict(colors=color, line=dict(color='black', width=2)))\n\nfig.update_layout(title=dict(text='Heart Attack',\n                               y=0.9,x=0.5,xanchor= 'center',yanchor= 'top'),\n                               xaxis = dict(title='age'),\n                               yaxis =dict(title='thalachh'),template='plotly_white')\n\niplot(fig)","5523f775":"data = [go.Histogram(x= df['age'],\n                     xbins = dict(start = 0,end =100,size =5),\n                    marker=dict(color='#A75BD5',line=dict(color='black', width=2)))]\n\nlayout = go.Layout(title=dict(text='Age Distribution',\n                               y=0.9,x=0.5,xanchor= 'center',yanchor= 'top'),\n                               xaxis = dict(title='Age Groups'),\n                               yaxis =dict(title='Frequency'),template='plotly_white')\n\nfig = go.Figure(data = data, layout = layout)\n\niplot(fig)","17b7d06e":"data = go.Bar(x = [var for var in df.columns],\n              y = [round(shapiro(df[var])[0],2) for var in df.columns],\n              text =[round(shapiro(df[var])[0],2) for var in df.columns],\n              textposition= 'outside',marker = dict(color = '#66D461',line_color = 'black',line_width=3))\n\nlayout = go.Layout(title=dict(text='Shapiro-Wilks Test for Normality',\n                               y=0.9,x=0.5,xanchor= 'center',yanchor= 'top'),\n                               xaxis = dict(title='Variables'),\n                               yaxis =dict(title='Test Stats'),template='plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\niplot(fig)","a0a146b1":"stat, p = levene(df[\"age\"],df[\"sex\"],df[\"cp\"],df[\"trtbps\"],df[\"chol\"],\n                 df[\"fbs\"],df[\"restecg\"],df[\"thalachh\"],df[\"exng\"],\n                 df[\"oldpeak\"],df[\"slp\"],df[\"thall\"],df[\"output\"])\nprint('Test Stat: {}'.format(stat))\nprint('p-value: {}'.format(p))","cbd54df7":"def check_duplications(dataframe):\n    if dataframe.duplicated().sum() > 0:\n        if dataframe.duplicated().sum() == 1:\n            print('There is {} duplicated value in data'.format(dataframe.duplicated().sum()))\n        else:\n            print('There are {} duplicated values in data'.format(dataframe.duplicated().sum()))\n    else:\n        print('There are no duplicated values in data')\n        \ncheck_duplications(df)","977d3497":"df[df.duplicated()]","f8635151":"df.drop_duplicates(keep='first',inplace=True)\ncheck_duplications(df)","49672562":"def check_missing(dataframe):\n    if dataframe.isnull().sum().sum() > 0:\n        print(dataframe.isnull().sum(), '\\n')\n        print('There are {} missing values'.format(dataframe.isnull().sum().sum()))\n    else:\n        print('There are no missing values')\n\ncheck_missing(df)","2cba25a0":"outlier_indices = []\n\nfor feature in num_cols:    \n    q1 = np.percentile(df[feature],25)\n    q3 = np.percentile(df[feature],75)\n    iqr = q3-q1\n    outlier_step = iqr*1.5\n    upper = q3 + outlier_step\n    lower = q1 - outlier_step\n    outlier_list_col = df[(df[feature] < lower) | (df[feature] > upper)].index\n    for a in outlier_list_col:\n        outlier_indices.append(a)\n    if len(outlier_list_col) > 0:\n        df[feature].iloc[outlier_list_col.values.tolist(),] = np.NaN\n        \ncols = [col for col in df.columns if col not in df.columns[df.isnull().any()].tolist()]\nDT_pipe = Pipeline(steps=[('scale',StandardScaler()),\n                          ('lr',DecisionTreeRegressor(random_state=42))])\n\nfor feature in [missing for missing in df.columns if df[missing].isnull().any()]:\n    print('{} Outlier(s) detected in {}'.format(df[feature].isnull().sum(),feature))\n    X = df[['age','sex','slp',feature]].copy()\n    Missing = X[X[feature].isna()]\n    X = X[~X[feature].isna()]\n    Y = X.pop(feature)\n    DT_pipe.fit(X,Y)\n    predicted = pd.Series(DT_pipe.predict(Missing[['age','sex','slp']]),index=Missing.index)\n    df.loc[Missing.index,str(feature)] = predicted","425a298a":"test_size = 0.3\nrandom_state = 42\n\nfor i in cat_cols:\n    df[i] = pd.Categorical(df[i])\n\nx = df.drop(\"output\",axis=1) #independent variables\ny = df[\"output\"] #dependent variable\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size= test_size, random_state= random_state)\n\nscaler = StandardScaler() #StandardScaler - RobustScaler\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","29285275":"def initiate_model(model):    \n    y_pred = model.fit(X_train, y_train).predict(X_test)\n    print('#'*60)\n    print((model.__class__.__name__).center(60,' '))\n    print('#'*60)\n    print('Number of mislabeled points out of a total {} points : {} \\n'.format(X_test.shape[0], (y_test != y_pred).sum()))\n    print(classification_report(y_test, y_pred, target_names=['0','1']))\n    print('#'*60)\n    cm = confusion_matrix(y_test, y_pred)\n    df1 = pd.DataFrame(columns=[\"0\",\"1\"], index= [\"0\",\"1\"], data= cm )\n    f,ax = plt.subplots(figsize=(5,5))\n    sns.heatmap(df1, annot=True,cmap=\"Purples\", fmt= '.0f',\n                ax=ax,linewidths = 5, cbar = False,annot_kws={\"size\": 16})\n    plt.xlabel(\"Predicted Label\")\n    plt.xticks(size = 12)\n    plt.yticks(size = 12, rotation = 0)\n    plt.ylabel(\"True Label\")\n    plt.title(\"{} Confusion Matrix\".format(model.__class__.__name__), size = 14)\n    plt.show()\ninitiate_model(GaussianNB())","cff25b9e":"bnb = BernoulliNB()\ninitiate_model(bnb)","2aba7ede":"sgd = SGDClassifier(loss='hinge',random_state=random_state)\ninitiate_model(sgd)","39218486":"classifier = [DecisionTreeClassifier(random_state = random_state),\n              SVC(random_state = random_state, probability = True),\n              RandomForestClassifier(random_state = random_state),\n              LogisticRegression(random_state = random_state),\n              KNeighborsClassifier(),\n              GradientBoostingClassifier(random_state = random_state),\n              LGBMClassifier(random_state = random_state)]\n\nlda = LinearDiscriminantAnalysis(solver='svd',n_components = 1)\ndata = go.Bar(x = [round(accuracy_score(y_test, i.fit(lda.fit_transform(X_train,y_train), y_train).predict(lda.transform(X_test))),2) for i in classifier],\n              y = [i.__class__.__name__ for i in classifier],\n              name = str([i.__class__.__name__ for i in classifier]),\n              text = [round(accuracy_score(y_test, i.fit(lda.fit_transform(X_train,y_train), y_train).predict(lda.transform(X_test))),4) for i in classifier],\n              textposition = 'outside',orientation='h',\n              marker = dict(color = '#A75BD5',line_color = 'black',line_width=3))\n\nlayout = go.Layout(title=dict(text='Linear Discriminant Analysis',y=0.9,x=0.5,\n                              xanchor= 'center',yanchor= 'top'),xaxis = dict(title='Accuracy Score'),\n                   template='plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_xaxes(range=[0,1])\niplot(fig)","ec9cafe2":"fig = make_subplots(rows=1, cols=2,shared_yaxes=True,subplot_titles=('2 Components','3 Components'))\n\nfor a in [2,3]:\n    pca = PCA(n_components = a)\n    fig.add_trace(go.Bar(x = [round(accuracy_score(y_test, i.fit(pca.fit_transform(X_train,y_train), y_train).predict(pca.transform(X_test))),2) for i in classifier],\n              y = [i.__class__.__name__ for i in classifier],\n              name = str([i.__class__.__name__ for i in classifier]),\n              text = [round(accuracy_score(y_test, i.fit(pca.fit_transform(X_train,y_train), y_train).predict(pca.transform(X_test))),4) for i in classifier],\n              textposition = 'outside',orientation='h',showlegend=False,\n              marker = dict(color = '#66D461',line_color = 'black',line_width=3)),row=1,col=a-1)\n    \nfig.update_layout(title=dict(text='Principal Component Analysis',y=0.9,x=0.5,xanchor= 'center',\n                             yanchor= 'top'),template = 'plotly_white')\n\nfig.update_xaxes(range=[0,1],row=1,col=1)\nfig.update_xaxes(range=[0,1],row=1,col=2)\niplot(fig)","5ecabc5e":"models = ['DecisionTreeClassifier',\n          'SVC',\n          'RandomForestClassifier',\n          'LogisticRegression',\n          'KNeighborsClassifier',\n          'GBClassifier',\n          'LGBMClassifier']\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {'C': [0.1, 1, 10, 100, 1000], \n                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n                  'kernel': ['rbf']} \n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-4, 4, 20),\n                    \"penalty\": [\"l1\",\"l2\",\"none\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(2,20,12, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\",\"minkowski\"],\n                 \"leaf_size\": [1,3,5,12,30]}\n    \ngbc_param_grid = {\"learning_rate\": [0.05, 0.1, 0.2],\n                  \"min_samples_split\": [2,3,10],\n                  \"min_samples_leaf\": [1,3,10]}\n\nlgbmc_param_grid = {'num_leaves': [31, 127],\n                    'reg_alpha': [0.1, 0.5],\n                    'min_data_in_leaf': [30, 50, 100, 300],\n                    'lambda_l1': [0, 1, 1.5],\n                    'lambda_l2': [0, 1]}\n\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid,\n                   gbc_param_grid,\n                   lgbmc_param_grid]\n\naccuracy = []\nbest_estimators = []\nmean_squared_errors = []\nroc_auc_scores = []\nrecall_scores = []\nprecision_scores = []\nf1_scores = []\nfor i in range(len(classifier)):\n    print('#'*70)\n    print((models[i]).center(70,' ')+'\\n'+'#'*70)\n    clf = GridSearchCV(classifier[i],param_grid=classifier_param[i],\n                       cv = StratifiedKFold(n_splits = 10),\n                       scoring = \"accuracy\",n_jobs = -1,verbose = 2)\n    \n    clf.fit(X_train,y_train)\n    accuracy.append(accuracy_score(clf.predict(X_test),y_test))\n    mean_squared_errors.append(mean_squared_error(y_test,clf.predict(X_test)))\n    roc_auc_scores.append(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n    recall_scores.append(recall_score(y_test, clf.predict(X_test)))\n    precision_scores.append(precision_score(y_test, clf.predict(X_test), average='weighted'))\n    f1_scores.append(f1_score(y_test, clf.predict(X_test), average='weighted'))\n    best_estimators.append(clf.best_estimator_)\n    \n    print(\"Accuracy: {}%\".format(round(accuracy[i]*100,2)))\n    print(\"MSE: {}\".format(round(mean_squared_errors[i],3)))\n    print(\"ROC AUC: {}\".format(round(roc_auc_scores[i],3)))\n    print(\"Recall: {}\".format(round(recall_scores[i],3)))\n    print(\"Precision: {}\".format(round(precision_scores[i],3)))\n    print(\"F1-Score: {}\".format(round(f1_scores[i],3)))\n    print(\"Best Estimator: {}\".format(clf.best_estimator_))\n    \nprint(\"#\"*70)\ncv_results = pd.DataFrame({\"Accuracy\":accuracy,\n                           \"MSE\":mean_squared_errors,\n                           \"ROC AUC\":roc_auc_scores,\n                           \"Recall\": recall_scores,\n                           \"Precision\": precision_scores,\n                           \"F1-Score\":f1_scores,\n                           \"Models\": models})\n\ncv_results.index = cv_results[\"Models\"]\ncv_results  = cv_results.drop([\"Models\"], axis = 1)\n\nf,ax = plt.subplots(figsize=(14,10))\nsns.heatmap(cv_results, annot=True,cmap = \"Purples\",\n            fmt= '.3f',ax=ax,linewidths = 5,\n            cbar = False,annot_kws={\"size\": 18})\n\nplt.xticks(size = 16)\nplt.yticks(size = 16, rotation = 0)\nplt.title(\"Grid Search Results\", size = 16)\nplt.show()","2c9c85e8":"color = ['#EA3434','#EA9A34','#EAE234','#97EA34','#34EA47','#34EACC','#34ABEA']\ndata = go.Bar(x = [round(i,5) for i in cv_results['Accuracy']],y = models,\n             text = [round(i,3) for i in cv_results['Accuracy']],orientation='h',\n             textposition = 'outside',marker = dict(color = color,line_color = 'black',line_width=2))\n\nlayout = go.Layout(title=dict(text='Grid Search Results',y=0.9,x=0.5,\n                              xanchor= 'center',yanchor= 'top'),xaxis = dict(title='Accuracy Score'),\n                   template='plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_xaxes(range=[0,1])\niplot(fig)","d077c835":"lgbm = best_estimators[6]\ninitiate_model(lgbm)","ec9ea04b":"knn = best_estimators[4]\ninitiate_model(knn)","95ed2061":"rf = best_estimators[2]\ninitiate_model(rf)","585769b8":"best_indices = cv_results.reset_index().sort_values('Accuracy',ascending=False)[0:3].index.tolist()\n\nvotingC = VotingClassifier(estimators = [(\"rf\",best_estimators[best_indices[0]]),\n                                        (\"knn\",best_estimators[best_indices[1]]),\n                                        (\"lgbm\",best_estimators[best_indices[2]])])\n\ninitiate_model(votingC)","456e48ee":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Stochastic Gradient Descent<\/span>","7a539470":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Levene's Test Homogeneity of Variance<\/span>","ba702db2":"<a id = \"6\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#BB85C6; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:22px; color:#FBFAFC; \">Model Preparations<\/span><\/h1>","506e2322":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Heart Attack<\/span>","e2c086ec":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Tuned LGBMClassifier<\/span>","1cb5e309":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Hyperparameter Tuning - Grid Search<\/span>","f0174f7c":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Tuned KNN<\/span>","d76e6351":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Principal Component Analysis<\/span>","e91e9bb9":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Shapiro-Wilks Test for Normality<\/span>","52d87519":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Pearson Correlation Map<\/span>","9808b2d4":"<div style=\"color:white;\n           display:fill;\n           border-radius:16px;\n           background-color:#BB85C6;\n           font-size:120%;\n           font-family:Verdana\">\n\n<p style=\"padding: 10px;\n          color:White;\n          font-weight: bold;\n          text-align: center;\n          font-size:120%;\">\nHeart Attack EDA & Prediction\n\n<\/p>\n<\/div>  \n\n<img src= \"https:\/\/media.giphy.com\/media\/xT5LMBk9CIQXji0wNy\/giphy.gif\">\n<div class=\"inner_cell\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<p><\/p><div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\" style = \"border:2px solid #BB85C6; background-color:#BB85C6;font-weight: bold; color:white; font-family:Verdana;\">Notebook Content<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#1\" role=\"tab\" aria-controls=\"profile\" target=\"_self\" style = \"color:#BB85C6;font-weight: bold; font-family:Verdana;font-size:16px;\">Libraries and Utilities<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#2\" role=\"tab\" aria-controls=\"messages\" target=\"_self\" style = \"color:#BB85C6;font-weight: bold; font-family:Verdana;font-size:16px;\">Load and Check Data<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#BB85C6;font-weight: bold; font-family:Verdana;font-size:16px;\">Understanding Data<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#BB85C6;font-weight: bold; font-family:Verdana;font-size:16px;\">Exploratory Data Analysis<span class=\"badge badge-primary badge-pill\">4<\/span><\/a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#5\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#BB85C6;font-weight: bold; font-family:Verdana;font-size:16px;\">Data Preprocessing<span class=\"badge badge-primary badge-pill\">5<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#BB85C6;font-weight: bold; font-family:Verdana;font-size:16px;\">Model Preparation<span class=\"badge badge-primary badge-pill\">6<\/span><\/a>\n      <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#7\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#BB85C6;font-weight: bold; font-family:Verdana;font-size:16px;\">Models<span class=\"badge badge-primary badge-pill\">7<\/span><\/a>\n\n<\/div>\n<\/div>\n<\/div>","b0799aca":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Linear Discriminant Analysis<\/span>","8b792ee2":"<a id = \"4\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#BB85C6; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:22px; color:#FBFAFC; \">Exploratory Data Analysis<\/span><\/h1>\n\n<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Analysis of Categorical Variables<\/span>","db6d6ef1":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Pairwise Relationships<\/span>","b7cc71f2":"<a id = \"2\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#BB85C6; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:22px; color:#FBFAFC; \">Load and Check Data<\/span><\/h1>","2937890e":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">If you liked this notebook, please upvote \ud83d\ude0a<\/span>\n\n<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">If you have any suggestions or questions, feel free to comment!<\/span>\n\n<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Best Wishes!<\/span>","101c21b0":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Age & Thalachh<\/span>","86451342":"<a id = \"7\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#BB85C6; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:22px; color:#FBFAFC; \">Models<\/span><\/h1>\n\n<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Gaussian Naive Bayes<\/span>","ec227469":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Voting Classifier<\/span>","6d1db5d8":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Missing Values<\/span>","1fab2a3b":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Outliers<\/span>","686d56a1":"<a id = \"5\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#BB85C6; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:22px; color:#FBFAFC; \">Data Preprocessing<\/span><\/h1>\n\n<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Duplicated Values<\/span>","f70182e6":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Analysis of Numerical Variables<\/span>","b75bf0e4":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Bernoulli Naive Bayes<\/span>","4ee1ac21":"<a id = \"3\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#BB85C6; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:22px; color:#FBFAFC; \">Understanding Data<\/span><\/h1>","a12172ce":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Variable Description<\/span>\n\n**Age :** Age of the patient\n\n**Sex :** Sex of the patient\n\n**exang:** exercise induced angina (1 = yes; 0 = no)\n\n**ca:** number of major vessels (0-3)\n\n**cp :** Chest Pain type chest pain type\n\n- Value 1: typical angina\n- Value 2: atypical angina\n- Value 3: non-anginal pain\n- Value 4: asymptomatic\ntrtbps : resting blood pressure (in mm Hg)\n\n**chol :** cholestoral in mg\/dl fetched via BMI sensor\n\n**fbs :** (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n\n**rest_ecg :** resting electrocardiographic results\n\n- Value 0: normal\n- Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\nthalach : maximum heart rate achieved\n\n**target :** 0= less chance of heart attack 1= more chance of heart attack","9e65fb79":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Tuned Random Forest<\/span>","772f778b":"<a id = \"1\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#BB85C6; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:22px; color:#FBFAFC; \">Libraries and Utilities<\/span><\/h1>","09eb35ec":"<span style=\"font-weight: bold; font-family:Verdana; font-size:18px; color:#BB85C6; \">Missing Values<\/span>"}}