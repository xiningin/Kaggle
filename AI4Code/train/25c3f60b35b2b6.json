{"cell_type":{"bd1d8d7f":"code","d2f7bc9b":"code","6f3cc2ce":"code","5cb61235":"code","ade60566":"code","09823394":"code","1416427e":"code","03e39e6a":"code","e39a298a":"code","57749e55":"code","e0292bd2":"code","d91fbd5d":"code","1ba2faf0":"code","5af9b54d":"code","6152cd19":"code","cdf1f076":"code","144408bf":"code","8864aafb":"code","7009dc8a":"code","0bbfaa1d":"code","2f1087f4":"code","25d79adf":"code","84c01db8":"code","9773e19e":"markdown","e0bb996c":"markdown"},"source":{"bd1d8d7f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d2f7bc9b":"import matplotlib.pyplot as plt\nimport pandas_datareader as web\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nimport math","6f3cc2ce":"df = pd.read_csv('\/kaggle\/input\/tesla-stock-price\/Tesla.csv - Tesla.csv.csv')","5cb61235":"df.info()","ade60566":"df['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date',inplace=True)","09823394":"df.shape #1692 rows and 7 columns that the data frame have ","1416427e":"#plotting the data\nplt.figure(figsize=(16,8))\nplt.title('Close Price History')\nplt.plot(df['Close'], color='red')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD', fontsize = 18)\nplt.show()","03e39e6a":"# create a new data frame with only 'Close column'\ndata = df.filter(['Close'])\ndataset = data.values #convert the data frame to a numpy array\ntraining_data_len = math.ceil(len(dataset)*.8)  # number of rows to train the model on\ntraining_data_len","e39a298a":"#scale the data\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\nscaled_data","57749e55":"#create the training dataset\n#create the scaled training dataset\n\ntrain_data = scaled_data[0:training_data_len, :]\n#Split the data into x_train, y_train datasets\nx_train = []\ny_train = []\nfor i in range(60,len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i,0])\n    if i<=60:\n        print(x_train)\n        print(y_train)\n        print()","e0292bd2":"#convert the x_train and y_train  to numppy array\nx_train,y_train = np.array(x_train), np.array(y_train)","d91fbd5d":"#reshape the data\nx_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\nx_train.shape","1ba2faf0":"#Buil the LSTM model\nmodel =Sequential()\nmodel.add(LSTM(64,return_sequences=True, input_shape=(x_train.shape[1],1)))\nmodel.add(LSTM(64, return_sequences= False))\nmodel.add(Dense(32))\nmodel.add(Dense(1))","5af9b54d":"#Complie the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')","6152cd19":"#Train the model\nmodel.fit(x_train,y_train, batch_size=1, epochs=10)","cdf1f076":"#create the testing data sets\n#create a new array containing scale values from index 1543 to 2003\ntest_data= scaled_data[training_data_len-60:, :]\n#create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:,:]\nfor i in range(60,len(test_data)):\n    x_test.append(test_data[i-60:i,0])","144408bf":"#convert the data to a numpy array\nx_test = np.array(x_test)","8864aafb":"#reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1))\nx_test.shape","7009dc8a":"#predicting the data\npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)","0bbfaa1d":"#get the root mean square error(RMSE)\nrmse = np.sqrt(np.mean(predictions - y_test)**2)\nrmse","2f1087f4":"#plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n#Visialization the data\nplt.figure(figsize=(16,8))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price' ,fontsize=18)\nplt.plot(train['Close'],linewidth=3.5)\nplt.plot(valid[['Close','Predictions']],linewidth=3.5)\nplt.legend(['Train','Valid','Predictions'], loc='upper_center')","25d79adf":"#show the valid and predicted price\nvalid","84c01db8":"#get the quote\ntesla_quote = pd.read_csv('\/kaggle\/input\/tesla-stock-price\/Tesla.csv - Tesla.csv.csv')\n#Create new data frame\nnew_df = tesla_quote.filter(['Close'])\n#get the last 60 days closing price values and convert the dataframe to an array\nlast_60_days = new_df[-60:].values\n#scaled the data to be values between 0 and 1\nlast_60_days_scaled = scaler.transform(last_60_days)\n#create an empty list\nX_test = []\n#append the past 60 days \nX_test.append(last_60_days_scaled)\n#convert the X_test data set to a numpy array\nX_test = np.array(X_test)\n#Reshape the data\nX_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1],1))\n#get the predicted scaled price\npred_price= model.predict(X_test)\n#undo the scalling\npred_price = scaler.inverse_transform(pred_price)\npred_price","9773e19e":"If you like it please vote:)","e0bb996c":"Today, We will predict tesla stock price. Let's start!"}}