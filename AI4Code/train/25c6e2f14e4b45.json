{"cell_type":{"eb3bd84f":"code","6b235ec0":"code","92d17291":"code","71e61874":"code","646b6f3a":"code","d063ea3b":"code","986e904e":"code","41ec90cf":"code","d2ccf687":"code","d5798bca":"code","5c069a84":"code","29ca4690":"code","c45b7fec":"code","953369e8":"code","40d2af6f":"code","1ecdf00a":"code","1a459106":"code","a41750e3":"code","6263c0e0":"code","fd626503":"code","b36fc749":"code","1f7fcb8e":"code","5d9ba0f9":"code","9665063e":"code","427b184e":"code","1a2c9387":"code","b9bcc61a":"code","913a189d":"code","82f84c71":"code","1840543e":"code","32049027":"code","feb79bdf":"code","40beab73":"code","ff081dd9":"code","0921dfe1":"code","2636534f":"markdown","386ca8ca":"markdown","fbd9af4d":"markdown","065d02db":"markdown","89ea9352":"markdown","50820700":"markdown","c4c55e4b":"markdown","e24e4e6d":"markdown","3956f7c5":"markdown","1a20ba61":"markdown","6b16ac12":"markdown","6e2ac0d5":"markdown","0160b7c9":"markdown","eec7eee4":"markdown","1d58d5eb":"markdown","94dc68e6":"markdown","3ab3571b":"markdown","4e92d6a7":"markdown","77e85104":"markdown","88ddac51":"markdown","38e6487b":"markdown","55523404":"markdown","8006d444":"markdown","3d4e1a08":"markdown","9da1e4f1":"markdown","aa9f80b5":"markdown","51e8c8bf":"markdown","c73840b8":"markdown","a5957a40":"markdown","33a9b7a1":"markdown","f84e50c9":"markdown","406a9f83":"markdown","cdc7dd5d":"markdown","a3cd87b4":"markdown","0eea39ac":"markdown","ffbac49f":"markdown"},"source":{"eb3bd84f":"# Instalacion previa de librerias empleadas\n!pip install wordcloud # Generador de nube de palabras\n!pip install textblob # Procesamiento de texto","6b235ec0":"# Basicas\nimport pandas as pd # Analisis y manipulacion de datos\nimport numpy as np # Tratamiento de matrices\nimport matplotlib.pyplot as plt # Graficos\nimport seaborn as sns # Visualizacion de datos\n\n### NLTK\nimport nltk # Procesamiento del lenguaje natural\nnltk.download('averaged_perceptron_tagger') # Etiquetar las palabras\nnltk.download('vader_lexicon') # Analisis de sentimiento\nnltk.download('wordnet') # Categorizacion de las palabras\nnltk.download('stopwords') # Quitar palabras comunes\nfrom nltk.corpus import wordnet\nfrom nltk import pos_tag # Clasificacion de palabras\nfrom nltk.corpus import stopwords # Eliminar palabras vacias\nfrom nltk.tokenize import WhitespaceTokenizer # Tokenizar\nfrom nltk.stem import WordNetLemmatizer # Lematizar\nfrom nltk.stem.wordnet import WordNetLemmatizer # Lematizar\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer # Analisis de sentimiento\n\n### TRATAMIENTO DE TEXTO\nfrom wordcloud import WordCloud # Nube de palabras\nimport string # Operaciones de cadenas de caracteres\nfrom textblob import TextBlob # Procesamiento del lenguaje\n\n### SKLEARN\nfrom sklearn.feature_extraction.text import TfidfVectorizer # Codificacion de documentos, segun frecuenca de las palabras\nfrom sklearn.model_selection import train_test_split # Dividir los datos en entrenamiento y validacion\nfrom imblearn.over_sampling import SMOTE # Balanceo de los datos\nfrom sklearn.linear_model import LogisticRegression # Clasificador\nfrom sklearn.ensemble import RandomForestClassifier # Clasificador\nfrom sklearn.metrics import classification_report # Metricas para valoracion del modelo\nfrom sklearn.metrics import f1_score, confusion_matrix # Metricas para valoracion del modelo\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score # Metricas para valoracion del modelo\nfrom sklearn.metrics import plot_confusion_matrix # Metricas para valoracion del modelo\nfrom sklearn.model_selection import GridSearchCV # Ajuste de hiper-parametros\n\nimport pickle # Guardar modelo\n\n### ADICIONALES\nimport warnings # Control de advertencias\nwarnings.filterwarnings('ignore')\nfrom tqdm import tqdm \ntqdm.pandas(desc='Processing Dataframe') # Barra de progreso","92d17291":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","71e61874":"# Cargar dataset\ndf = pd.read_csv(\"\/kaggle\/input\/515k-hotel-reviews-data-in-europe\/Hotel_Reviews.csv\")","646b6f3a":"# Funci\u00f3n para limpiar el texto\ndef limpiar_texto(texto):\n    # Poner el texto en min\u00fasculas\n    texto = texto.lower()\n    # Tokenizar el texto y quitar los signos de puntuaci\u00f3n\n    texto = [word.strip(string.punctuation) for word in texto.split(\" \")]\n    # Quitar las palabras que contengan n\u00fameros\n    texto = [word for word in texto if not any(c.isdigit() for c in word)]\n    # Quitar las stop words\n    stop = stopwords.words('english')\n    texto = [x for x in texto if x not in stop]\n    # Quitar los tokens vac\u00edos\n    texto = [t for t in texto if len(t) > 0]\n    # Pos tags\n    pos_tags = pos_tag(texto)\n    # Lematizar el texto\n    texto = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # Quitar las palabras con s\u00f3lo una letra\n    texto = [t for t in texto if len(t) > 1]\n    # Unir todo\n    texto = \" \".join(texto)\n    return(texto)\n\n# Funci\u00f3n para dibujar la nube de palabras\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color = 'white',\n        max_words = 200,\n        max_font_size = 40, \n        scale = 3,\n        random_state = 42\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize = (20, 20))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize = 20)\n        fig.subplots_adjust(top = 2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n    \n\n# Etiquetado de nombres, verbos, adjetivos o adverbios\ndef get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n    \n# Para el train_validate_test_split (para probar los modelos y mejorarlos)\ndef train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=101):\n    np.random.seed(seed)\n    perm = np.random.permutation(df.index)\n    m = len(df.index)\n    train_end = int(train_percent * m)\n    validate_end = int(validate_percent * m) + train_end\n    train = df.loc[perm[:train_end]]\n    validate = df.loc[perm[train_end:validate_end]]\n    test = df.loc[perm[validate_end:]]\n    return train, validate, test","d063ea3b":"print(\"El df tiene un total de {} columnas y un total de {} registros\".format(df.shape[1], df.shape[0]))","986e904e":"# Columnas df1\ndf.columns","41ec90cf":"df","d2ccf687":"# En Reviews se a\u00f1aden los dos tipos de Review concatenadas con un espacio\ndf[\"Reviews\"] = df[\"Positive_Review\"] + \" \" + df[\"Negative_Review\"]\n\n# Se quitan los \"No Negative\" y \"No Positive\" de las reviews\ndf[\"Reviews\"] = df[\"Reviews\"].astype(str)\ndf[\"Reviews\"] = df[\"Reviews\"].apply(lambda x: x.replace(\"No Negative\", \"\").replace(\"No Positive\", \"\"))\n\n# Se crea la columna \"Is_Positive_Review\" para aquellas Review cuyo score es mayor a 5. \ndf['Is_Positive_Review'] = df['Reviewer_Score'].progress_apply(lambda x: 1 if x >= 5 else 0)","d5798bca":"print(\"El df tiene un conjunto de {} opiniones positivas y un conjunto de {} opiniones negativas\".format(df[\"Is_Positive_Review\"].value_counts()[1], df[\"Is_Positive_Review\"].value_counts()[0]))\nprint(\"En porcentaje, el {0:.2f}% de las reviews son positivas y el {1:.2f}% de las reviews son negativas\".format(df[\"Is_Positive_Review\"].value_counts(normalize=True)[1]*100, df[\"Is_Positive_Review\"].value_counts(normalize=True)[0]*100))","5c069a84":"# Selecci\u00f3n de las variables de inter\u00e9s\ndf = df.loc[:, ['Reviews', 'Is_Positive_Review']]\n\nprint(\"Dimensiones de df1: {}\".format(df.shape))","29ca4690":"# A\u00f1adir n\u00famero de caracteres\ndf[\"Caracteres_len\"] = df[\"Reviews\"].progress_apply(lambda x: len(x))\n\n# A\u00f1adir n\u00famero de palabras\ndf[\"Palabras_len\"] = df[\"Reviews\"].progress_apply(lambda x: len(x.split(\" \")))","c45b7fec":"# Para el n\u00famero de caracteres\nfig = plt.figure(figsize=(10,6))\nplt1 = sns.distplot(df[df[\"Is_Positive_Review\"]==0].Caracteres_len, hist=True)\nplt2 = sns.distplot(df[df[\"Is_Positive_Review\"]==1].Caracteres_len, hist=True)\nfig.legend(labels=['Review negativa','Review positiva'])\nplt.show()","953369e8":"# Para el n\u00famero de palabras\nfig = plt.figure(figsize=(10,6))\nplt1 = sns.distplot(df[df[\"Is_Positive_Review\"]==0].Palabras_len, hist=True)\nplt2 = sns.distplot(df[df[\"Is_Positive_Review\"]==1].Palabras_len, hist=True)\nfig.legend(labels=['Review negativa','Review positiva'])\nplt.show()","40d2af6f":"# Se imprime la nube de palabras con la funci\u00f3n cargada anteriormente\nshow_wordcloud(df[\"Reviews\"])","1ecdf00a":"# Se aplica la funci\u00f3n anterior\ndf['Reviews_procesadas'] = df['Reviews'].progress_apply(lambda x: limpiar_texto(x))","1a459106":"# Con Vader, del m\u00f3dulo nltk. Este m\u00f3dulo a\u00f1ade un score positivo, negativo, neutro y una integraci\u00f3n de todas las anteriores\nanalizador = SentimentIntensityAnalyzer()\ndf[\"Sentimiento\"] = df[\"Reviews\"].progress_apply(lambda x: analizador.polarity_scores(x))\ndf = pd.concat([df.drop(['Sentimiento'], axis=1), df['Sentimiento'].apply(pd.Series)], axis=1)","a41750e3":"# Con TextBlob\ndf['Polaridad'] = df['Reviews'].progress_apply(lambda x: TextBlob(x).sentiment.polarity) \ndf['Subjetividad'] = df['Reviews'].progress_apply(lambda x: TextBlob(x).sentiment.subjectivity) ","6263c0e0":"vectorizador = TfidfVectorizer(ngram_range = (1,4), min_df = 3, max_features = 200,\n                               use_idf = True, smooth_idf = True, norm = 'l2') \n\nvector_corpus = vectorizador.fit_transform(df['Reviews_procesadas'].to_list()) \n\ntype(vector_corpus) # Ya est\u00e1 transformado el texto.","fd626503":"# Reviews con positividad m\u00e1s alta en cuanto a sentimientos seg\u00fan Vader (m\u00e1s de 10 palabras)\ndf[df[\"Palabras_len\"] >= 10].sort_values(\"pos\", ascending = False)[[\"Reviews\", \"pos\"]].head(10)","b36fc749":"# Reviews con negatividad m\u00e1s alta en cuanto a sentimientos seg\u00fan Vader (m\u00e1s de 10 palabras)\ndf[df[\"Palabras_len\"] >= 10].sort_values(\"neg\", ascending = False)[[\"Reviews\", \"neg\"]].head(10)","1f7fcb8e":"# Selecci\u00f3n de variables para la construcci\u00f3n del modelo (en resumen, s\u00f3lo nos quedamos con los campos num\u00e9ricos)\ntarget = 'Is_Positive_Review'\ncampos_ignorar = ['Reviews', 'Reviews_procesadas', 'Caracteres_len', 'Palabras_len']\ncampos_features = [i for i in df.columns if i not in campos_ignorar]\n\n# Divisi\u00f3n en conjuntos de test, validate y train\ntrain, validate, test = train_validate_test_split(df[campos_features])\nX_train = train.drop('Is_Positive_Review',1)\ny_train = train['Is_Positive_Review']\nX_validation = validate.drop('Is_Positive_Review', 1)\ny_validation = validate['Is_Positive_Review']\nX_test = test.drop('Is_Positive_Review', 1)\ny_test = test['Is_Positive_Review']","5d9ba0f9":"campos_features","9665063e":"# SMOTE para balancear los datos (se aplica s\u00f3lo en el conjunto de entrenamiento)\nbalancear = SMOTE(random_state = 41)\nX_train_balanceado, y_train_balanceado = balancear.fit_resample(X_train, y_train) # Se aplica al conjunto de train\n\n# Se crean los dataframes con los conjuntos balanceados\nX_train_balanceado = pd.DataFrame(data = X_train_balanceado, columns = X_train.columns) # X_train_balanceado\nY_train_balanceado = pd.DataFrame(data= y_train_balanceado, columns = ['Is_Positive_Review'])","427b184e":"# Regresi\u00f3n log\u00edstica\nreg_logistica = LogisticRegression()\nreg_logistica.fit(X_train_balanceado, Y_train_balanceado)","1a2c9387":"# Predicci\u00f3n\ny_pred = reg_logistica.predict(X_test)\n\nprint('Precisi\u00f3n de la regresi\u00f3n log\u00edstica en el test: {:.2f}'.format(reg_logistica.score(X_test, y_test)))","b9bcc61a":"# Matriz de confusi\u00f3n\nplot_confusion_matrix(reg_logistica, X_test, y_test, normalize = None)\n\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred)) # Por si no se ve bien en el dibujo","913a189d":"# ROC\ny_pred = [x[1] for x in reg_logistica.predict_proba(X_test)]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label = 1)\n\nroc_auc = auc(fpr, tpr)\n\nplt.figure(1, figsize = (15, 10))\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","82f84c71":"# Mejorar las caracter\u00edsticas de la regresi\u00f3n con otros par\u00e1metros. \n# En este caso se sacar\u00e1n los mejores valores para, sobre todo, threshold. En regresi\u00f3n log\u00edstica el valor predeterminado es\n# de 0.5\n\nfpr, tpr, thresholds = roc_curve(y_validation, reg_logistica.predict_proba(X_validation)[:,1])\ni = np.arange(len(tpr)) \nroc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),\n                    'tpr' : pd.Series(tpr, index = i), \n                    '1-fpr' : pd.Series(1-fpr, index = i), \n                    'tf' : pd.Series(tpr - (1-fpr), index = i), \n                    'thresholds' : pd.Series(thresholds, index = i)})\n\nroc.iloc[(roc.tf-0).abs().argsort()[:1]]","1840543e":"# Threshold = 0.467\nthreshold = 0.467\npreds = np.where(reg_logistica.predict_proba(X_test)[:,1] > threshold, 1, 0)\nprint('Precisi\u00f3n: {:.2f}'.format(reg_logistica.score(X_test, preds)))","32049027":"# GridSearch\n\ngrid = {\"C\":np.array([0.001,0.01,0.1,1,10]), \"penalty\":[\"l1\",\"l2\"]}\n\nreg_logistica_gridsearchcv = GridSearchCV(reg_logistica, grid, cv=10)\n\nreg_logistica_gridsearchcv.fit(X_validation, y_validation)\nprint('Mejor Penalty:', reg_logistica_gridsearchcv.best_estimator_.get_params()['penalty'])\nprint('Mejor C:', reg_logistica_gridsearchcv.best_estimator_.get_params()['C'])","feb79bdf":"# Aplicaci\u00f3n del GridSearch y del Threshold \u00f3ptimo\n\nregr_log = LogisticRegression(penalty='l2', C=0.01) # Se ponen el mejor penalty y el mejor C calculados previamente\n\nregr_log.fit(X_train_balanceado, y_train_balanceado) # Entrenamos el modelo con los datos balanceados\n\nthreshold = 0.482 # \u00f3ptimo, ya guardado previamente\nprediccion = np.where(regr_log.predict_proba(X_test)[:,1] > threshold, 1, 0) # Predicci\u00f3n con los valores \u00f3ptimos\n\nprint(classification_report(y_test, prediccion))\nprint('Precisi\u00f3n de la regresi\u00f3n log\u00edstica en el test: {:.2f}'.format(regr_log.score(X_test, prediccion)))","40beab73":"# Matriz de confusi\u00f3n\nplot_confusion_matrix(regr_log, X_test, y_test, normalize = None)\n\nprint(classification_report(y_test, prediccion))\nprint(confusion_matrix(y_test, prediccion))","ff081dd9":"# ROC\ny_pred = [x[1] for x in regr_log.predict_proba(X_test)]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label = 1)\n\nroc_auc = auc(fpr, tpr)\n\nplt.figure(1, figsize = (15, 10))\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","0921dfe1":"# Guardar el modelo (descomentar para guardarlo en formato .pkl)\n\"\"\"\nwith open(\".\/model_sentiment_analysis.pkl\", 'wb') as f:\n    pickle.dump(regr_log, f)\n\"\"\"","2636534f":"#### 5.4 Distribuci\u00f3n de longitud de las reviews seg\u00fan si son positivas o negativas","386ca8ca":"## 7. Exploraci\u00f3n previa al modelado","fbd9af4d":"# <h1 align=\"center\">Modelo NLP para el an\u00e1lisis de sentimiento en review's de hoteles<\/h1>","065d02db":"## 3. Creaci\u00f3n de las funciones que se utilizar\u00e1n","89ea9352":"Como se puede observar no hay mucha diferencia en cuanto a longitud (tanto de caracteres como de palabras) en las reviews negativas y positivas. Por el motivo citado, no se incorporar\u00e1n estas variable en el modelo, puesto que no parecen ayudar a ditinguir entre valoraciones positivas y negativas.","50820700":"El an\u00e1lisis de sentimiento, para que sea m\u00e1s completo, se va a realizar con dos librer\u00edas diferentes. La primera va a ser con Vader, del m\u00f3dulo nltk. Vader proporciona cuatro nuevos campos (score positivo, score negativo, score neutro y un score llamado compound que integra todos los score anteriores, esto es, que cuanto m\u00e1s positivo, m\u00e1s positiva es la review mientras que cuanto m\u00e1s negativo, m\u00e1s negativa ser\u00e1 la review). La segunda librer\u00eda ser\u00e1 la de TextBlob. TextBlob proporciona una tupla con dos: polaridad y subjetividad. La polaridad va del valor -1 hasta el 1. Si es negativa significa que tiene sentimientos negativos mientras que si es positiva significa que tiene sentimientos positivos. La subjetividad va entre 0 y 1, y cuantifica la opini\u00f3n personal contenida en el texto. Una mayor subjetividad significa que el texto contiene mucha m\u00e1s opini\u00f3n personal que una informaci\u00f3n objetiva.\n\nPara extraer el sentimiento se utilizar\u00e1n las reviews sin procesar.","c4c55e4b":"#### 5.1 Creaci\u00f3n del campo 'Is_Positive_Review' ","e24e4e6d":"#### 8.3 Mejora del modelo","3956f7c5":"#### 5.5 Nube de palabras","1a20ba61":"Se crea el campo Is_Positive_Review (si es positiva = 1, si es negativa = 0)","6b16ac12":"#### 5.7.1 Con Vader","6e2ac0d5":"#### 5.7.2 Con TextBlob","0160b7c9":"Para este apartado se aplicar\u00e1 la funci\u00f3n definida previamente de limpieza de texto. Aplicando esa funci\u00f3n al conjunto de datos, lo que se har\u00e1 ser\u00e1:\n\n- Poner el texto en min\u00fascula\n- Tokenizar el texto\n- Quitar las palabras que contengan n\u00fameros\n- Quitar las stop words\n- Quitar los tokens vac\u00edos\n- Lematizar el texto\n- Quitar las palabras con una letra","eec7eee4":"Se ha mejorado much\u00edsimo la precisi\u00f3n (ahora es 0.99). Se va a intentar mejorar m\u00e1s a\u00fan el modelo con el tuneo de los hiperpar\u00e1metros (GridSearch)","1d58d5eb":"## 5. Exploraci\u00f3n y transformaci\u00f3n de los datos","94dc68e6":"#### 5.2 Selecci\u00f3n de variables","3ab3571b":"## 9. Guardar modelo","4e92d6a7":"## 4. An\u00e1lisis preliminar","77e85104":"Como se ha comentado previamente, al realizar el primer an\u00e1lisis exploratorio, el texto est\u00e1 desbalanceado. Sin embargo, adem\u00e1s de esa conclusi\u00f3n se pueden sacar otras conclusiones mediante la exploraci\u00f3n de los resultados que tenemos actualmente antes de construir cualquier modelo.","88ddac51":"#### 8.1 Balanceo de los datos\n\nYa se ha visto que est\u00e1n desbalanceados, con muchas m\u00e1s reviews positivas que negativas. Los datos se balancear\u00e1n con la librer\u00eda SMOTE. ","38e6487b":"## 1. Importaci\u00f3n de librer\u00edas y datos","55523404":"Se van a extraer las caracter\u00edsticas del texto utilizando TFIDFVectorizer. En este caso se quiere:\n\n- Utilizar como m\u00e1ximo 200 caracter\u00edsticas\n- Unigramas, bigramas, trigramas y cuatrigramas\n- Que el sistema ignore los elemenos que al menos no aparezcan en 3 reviews\n- Que, puesto que el texto ya est\u00e1 tokenizado, no utilice la funci\u00f3n tokenizadora de Scikit-Learn","8006d444":"## 2. Carga de los datos","3d4e1a08":"Se puede observar que Vader interpreta 'no' y 'nothing' como negativo, mientras que muchas veces no significa algo negativo. Por ejemplo si se comenta que no se ha tenido ning\u00fan problema con el hotel. Sin embargo, afortunadamente, la gran mayor\u00eda de reviews son negativas de verdad.","9da1e4f1":"Como se puede observar, el dataset est\u00e1 claramente desbalanceado, cuesti\u00f3n que ser\u00e1 importante y que hay que tener en cuenta al entrenar el modelo.","aa9f80b5":"#### 5.6 Normalizaci\u00f3n","51e8c8bf":"## 8. Construcci\u00f3n del modelo","c73840b8":"## 6. Vectorizaci\u00f3n del texto","a5957a40":"#### 5.3 Longitud de palabras y de caracteres","33a9b7a1":"En las regresiones log\u00edsticas, el par\u00e1metro threshold viene predeterminado con un valor de 0.5. En este caso, seg\u00fan lo anterior, el \u00f3ptimo es 0.482. Vamos a probar con este par\u00e1metro, a ver si mejora la precisi\u00f3n.","f84e50c9":"#### [Enlace al conjunto de datos (kaggle)](https:\/\/www.kaggle.com\/jiashenliu\/515k-hotel-reviews-data-in-europe)","406a9f83":"**Analisis preliminar df**\n\nEl dataframe tiene la columna \"Negative_Review\", que recoge las reviews negativas y \"Positive_Review\", que recoge las reviews positivas. Por lo tanto, para recoger todas estas reviews habr\u00eda que unirlas en un nuevo campo, el cual se llamar\u00e1 \"Reviews\".\n\nAdem\u00e1s, se crear\u00e1 el campo Is_Positive_Review donde si es 1, es que la review ha recibido un 5 o m\u00e1s, y, por lo tanto, es positiva, mientras que si es 0 es que la review ha recibido menos de un 5 de score y por lo tanto es negativa. Esto es porque en este dataframe las puntuaciones van del 0 al 10.","cdc7dd5d":"#### 5.7 An\u00e1lisis de sentimiento","a3cd87b4":"#### 8.2 Regresi\u00f3n log\u00edstica","0eea39ac":"Las variables que se van a seleccionar para el dataframe van a ser las siguientes: Reviews, Is_Positive_Review.","ffbac49f":"   ### \u00cdndice:\n   \n       1. Importaci\u00f3n de librer\u00edas \n       \n       2. Carga de los datos\n\n       3. Creaci\u00f3n de funciones\n       \n       4. An\u00e1lisis preliminar\n       \n       5. Exploraci\u00f3n y transformaci\u00f3n de los datos\n       \n           5.1. Creaci\u00f3n del campo 'Is_Positive_Review' \n           5.2. Selecci\u00f3n de variables\n           5.3. Longitud de palabras y de caracteres\n           5.4. Distribuci\u00f3n de longitud de las reviews seg\u00fan si son positivas o negativas\n           5.5. Nube de palabras\n           5.6. Normalizaci\u00f3n\n           5.7. An\u00e1lisis de sentimiento\n               \n               5.7.1. Con Vader\n               5.7.2. Con TextBlob\n               \n       6. Vectorizaci\u00f3n del texto\n       \n       7. Exploraci\u00f3n previa al modelado\n       \n       8. Construcci\u00f3n del modelo\n       \n           8.1. Balanceo de los datos\n           8.2. Regresi\u00f3n log\u00edstica\n           8.3. Mejora del modelo\n           \n       9. Guardar modelo"}}