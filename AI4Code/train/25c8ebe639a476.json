{"cell_type":{"a3a533fe":"code","9784c5f7":"code","078a7506":"code","7e73bafe":"code","f226b24a":"code","1e00bc59":"code","be956107":"code","e57e9578":"code","d497c9a8":"code","00f21907":"code","c37cd8e3":"code","c989b0e7":"code","37fc0178":"code","4ab16487":"code","7e89a145":"code","ca5591e0":"code","423c10c7":"code","3c387c1b":"markdown","4afed532":"markdown","a69ebe51":"markdown","50396cce":"markdown","e7fb32f7":"markdown","b2062fad":"markdown","2afaceae":"markdown"},"source":{"a3a533fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9784c5f7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime","078a7506":"df = pd.read_csv('\/kaggle\/input\/wind-power-forecasting\/Turbine_Data.csv')\ndf.info()","7e73bafe":"df[\"Unnamed: 0\"] = df[\"Unnamed: 0\"].apply(lambda x : datetime.strptime(x[:19],'%Y-%m-%d %H:%M:%S'))\ndf.describe()","f226b24a":"drop_list = []\nfor i in df.columns:\n    print(i,len(df[i].value_counts()))\n    if len(df[i].value_counts()) == 1:\n        drop_list.append(i)\ndf = df.drop(drop_list,axis = 1)","1e00bc59":"df = df.dropna()","be956107":"plt.figure(figsize=(18,16))\nsns.heatmap(df.corr(),square=True,annot=True,linewidths=0.1,cmap=\"coolwarm\")\nplt.show()","e57e9578":"var = df.columns.values\n\ni = 0\n\nsns.set_style('whitegrid')\nfig, ax = plt.subplots(5,4,figsize=(24,30))\n\nfor feature in var:\n    if feature in ['WindSpeed','Unnamed: 0']:\n        pass\n    else:\n        i += 1\n        plt.subplot(5,4,i)\n        sns.scatterplot(x=feature,y='WindSpeed', data=df[[feature,'WindSpeed']])\n        plt.xlabel(feature, fontsize=12)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='both', which='major', labelsize=12)\n        \nplt.show()","d497c9a8":"plt.figure(figsize=(50,5))\nsns.lineplot(x='Unnamed: 0',y='WindSpeed', data=df[['Unnamed: 0','WindSpeed']])\nplt.show()","00f21907":"from sklearn.preprocessing import RobustScaler, StandardScaler\n\nrs = RobustScaler()\ncolumns = df.columns.values.tolist()\ncolumns.remove('Unnamed: 0')\n\npreprocessed = rs.fit_transform(df[columns])\npreprocessed = pd.DataFrame(preprocessed,columns=columns)\n\npreprocessed['Time'] = pd.to_datetime(df['Unnamed: 0'].astype(str).values.tolist())\n\npreprocessed.dtypes","c37cd8e3":"def accuracy(predicted, observed):\n    mse = abs(predicted - observed).mean()      # MSE, Mean Square Error\n    rmse = ((predicted - observed)**2).mean()**.5  # RMSE, Root Mean Square Error\n    mae = abs(predicted - observed).mean()      # MAE, Mean Absolute Error\n    mape = abs((predicted - observed)\/observed).mean()  # MAPE, Mean Absolute Percentage Error\n    smape = (abs(predicted - observed)\/((abs(predicted)+abs(observed))\/2)).mean() # SMAPE, Symmetric Mean Absolute Percentage Error\n\n    return({'MSE, Mean Square Error': mse, \n            'RMSE, Root Mean Square Error':rmse, \n            'MAE, Mean Absolute Error': mae, \n            'MAPE, Mean Absolute Percentage Error': mape , \n            'SMAPE, Symmetric Mean Absolute Percentage Error':smape})","c989b0e7":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\n\n\ncolumn_list = ['ActivePower', 'AmbientTemperatue', 'BearingShaftTemperature',\n       'Blade1PitchAngle', 'Blade2PitchAngle', 'Blade3PitchAngle',\n       'GearboxBearingTemperature', 'GearboxOilTemperature', 'GeneratorRPM',\n       'GeneratorWinding1Temperature', 'GeneratorWinding2Temperature',\n       'HubTemperature', 'MainBoxTemperature', 'NacellePosition',\n       'ReactivePower', 'RotorRPM', 'WindDirection']\n\nx = preprocessed[column_list]\n\ny = preprocessed['WindSpeed']\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.33, random_state=100)\nmodel = DecisionTreeRegressor().fit(train_x,train_y)\npredict_y = model.predict(test_x)\n\n\nfor i in range(len(column_list)):\n    print('%s: %.5f'%(column_list[i],model.feature_importances_[i]))","37fc0178":"x = range(len(predict_y))\ny1 = test_y.values\ny2 = predict_y\n\n\nplt.figure(figsize=(40,5))\nsns.scatterplot(x=x, y=y1, legend= 'full')\nsns.scatterplot(x=x, y=y2, legend= 'full')\nplt.legend(['Accurency','Predicted'])\nplt.show()","4ab16487":"accuracy(y2, y1)","7e89a145":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nx = preprocessed[column_list]\n\ny = preprocessed['WindSpeed']\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.33, random_state=100)\n\nmodel = LinearRegression().fit(train_x, train_y)\npredict_y = model.predict(test_x)\n\nfor i in range(len(column_list)):\n    print('%s: %.5f'%(column_list[i], model.coef_[i]))","ca5591e0":"x = range(len(predict_y))\ny1 = test_y.values\ny2 = predict_y\n\n\nplt.figure(figsize=(40,5))\nsns.scatterplot(x=x, y=y1, legend= 'full')\nsns.scatterplot(x=x, y=y2, legend= 'full')\nplt.legend(['Accurency','Predicted'])\nplt.show()","423c10c7":"accuracy(y2, y1)","3c387c1b":"## Transform the Time columns which type was Object into DateTime Datatype.","4afed532":"#### I'm not sure the missing values are really missed or not measured. And I decide to drop the rows with missing values rather than filling them by median or mean.","a69ebe51":"Use RobustScalr to preprocess the data.","50396cce":"### At this step I decided to drop the columns with same values which is useless I think.","e7fb32f7":"To check the distributions for diffferent features with the WindSpeed.","b2062fad":"## For the first step, import the packages needed.","2afaceae":"And here I used the heatmap to check the correlations between different measures."}}