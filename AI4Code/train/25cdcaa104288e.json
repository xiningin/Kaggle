{"cell_type":{"4558b11e":"code","613e7540":"code","09d9a009":"code","cb983e94":"code","6065fde0":"code","69cbaabf":"code","8e1333c7":"code","d3d11938":"code","ee50b927":"code","73fb86df":"code","dc003d5e":"code","354f35ba":"code","0d6422f4":"code","7b86cd14":"code","a9e60c03":"code","231db465":"code","4e47f5ed":"code","0c2fda48":"markdown","f6d844e5":"markdown","0eee334d":"markdown","9923a29e":"markdown","56e81093":"markdown"},"source":{"4558b11e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport cv2\nimport seaborn as sns\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPool2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nplt.rcParams['figure.figsize'] = (12,7)\n\n# Checking the data files\nimport os\nprint(os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\"))","613e7540":"# Setting paths and showing the number of images\ninfected = os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\")\ninfected_path = \"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\"\nprint(\"Length of infected data = \", len(infected), 'images')\nuninfected = os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\")\nuninfected_path = \"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\"\nprint(\"Length of uninfected data = \", len(uninfected), 'images')","09d9a009":"# Infected cells\n\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(cv2.imread(infected_path + '\/' + infected[i]))\n    plt.title('INFECTED CELLS')\n    plt.tight_layout()\nplt.show()","cb983e94":"# Uninfected cells\n\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(cv2.imread(uninfected_path + '\/' + uninfected[i]))\n    plt.title('UNINFECTED CELLS')\n    plt.tight_layout()\nplt.show()","6065fde0":"dim1 = []\ndim2 = []\nfor file in infected:\n    try:\n        imag = imread(infected_path + '\/' +file)\n        d1,d2,colors = imag.shape\n        dim1.append(d1)\n        dim2.append(d2)\n    except:\n        None\n        \nsns.jointplot(dim1, dim2)","69cbaabf":"print('Mean of X dimensions - ',np.mean(dim1))\nprint('Mean of Y dimensions - ',np.mean(dim2))","8e1333c7":"# Defining Image Data Gen\n\nimg_shape = (130, 130, 3)\nimage_gen = ImageDataGenerator(rotation_range=20,\n                              width_shift_range=0.1,\n                              height_shift_range=0.1,\n                              rescale=1\/225,\n                              shear_range=0.1,\n                              zoom_range=0.1,\n                              horizontal_flip=True,\n                              fill_mode='nearest',\n                              validation_split=0.2)","d3d11938":"train = image_gen.flow_from_directory('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images',\n                                     target_size = img_shape[:2],\n                                     color_mode = 'rgb',\n                                     batch_size = 32,\n                                     class_mode = 'binary',\n                                     subset = 'training',\n                                     shuffle = True)\n\nvalidation = image_gen.flow_from_directory('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images',\n                                     target_size = img_shape[:2],\n                                     color_mode ='rgb',\n                                     batch_size = 32,\n                                     class_mode = 'binary',\n                                     subset = 'validation',\n                                     shuffle = False)","ee50b927":"train.class_indices","73fb86df":"model = Sequential()\n\n\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),input_shape = (130,130,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","dc003d5e":"model.summary()","354f35ba":"early = EarlyStopping(monitor='val_loss',patience=2,verbose=1)\nmodel.metrics_names","0d6422f4":"model.fit_generator(train,\n                   epochs=20,\n                   validation_data=validation,\n                   callbacks=[early])","7b86cd14":"losses = pd.DataFrame(model.history.history)\nlosses[['loss','val_loss']].plot()","a9e60c03":"losses[['accuracy','val_accuracy']].plot()","231db465":"predictions = model.predict_generator(validation)\npredictions = predictions>0.5\nprint('Confusion Matrix: \\n',confusion_matrix(validation.classes,predictions),'\\n')\nprint('Classification Report: \\n\\n',classification_report(validation.classes,predictions))","4e47f5ed":"model.save('model.h5')","0c2fda48":"Generating train and test splits of images","f6d844e5":"# Visualising the images","0eee334d":"# Creating the CNN Model","9923a29e":"We can find out the mean of dimensions and take those","56e81093":"# Deciding ideal dimensions to crop images to "}}