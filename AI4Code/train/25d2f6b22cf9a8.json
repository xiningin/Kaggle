{"cell_type":{"cd560a0f":"code","731203eb":"code","450e4161":"code","e41fba98":"code","79df721e":"code","5c69662d":"code","c7501bac":"code","bd05dc72":"code","b11f7d9d":"code","385df044":"code","e0216e76":"code","a2e0525e":"code","6585be92":"code","a54ca235":"code","2d677d09":"code","b8b0ab36":"code","0ad49588":"code","97ea04ae":"code","6564a379":"code","2678e36f":"code","64394efb":"code","c66ff8c6":"code","5796f98f":"code","0fb43633":"code","efa7cc7d":"code","4aff3d40":"code","d58882bb":"code","a4e6d809":"code","f28067b0":"code","a4ef4dd3":"code","9edb687c":"code","3e332396":"code","f901aaee":"code","ef8db2e7":"code","f4d31d55":"markdown","5cbab3f5":"markdown","4a53cefc":"markdown","141600f7":"markdown","3236a44a":"markdown","03a1ec3c":"markdown","7a08d998":"markdown","a641d982":"markdown"},"source":{"cd560a0f":"!pip install ..\/input\/python-datatable\/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl","731203eb":"import pandas as pd\nimport datatable as dt\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport os\n\nimport riiideducation\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization,Dropout,Dense,Flatten,Conv1D\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.metrics import BinaryAccuracy\nfrom keras import backend as K","450e4161":"import warnings\nwarnings.filterwarnings(\"ignore\")","e41fba98":"os.listdir('..\/input\/riiid-test-answer-prediction')","79df721e":"data_types_dict = {\n    'user_id': 'int32', \n    'content_id': 'int16', \n    'answered_correctly': 'int8', \n    'prior_question_elapsed_time': 'float32', \n    'prior_question_had_explanation': 'boolean',\n    'content_type_id': 'int8',\n    'timestamp': 'int64'\n}","5c69662d":"lectures_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/lectures.csv\")\nexample_test_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/example_test.csv\")\n#train_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/train.csv\", low_memory=False)\ntrain_csv = dt.fread('..\/input\/riiid-test-answer-prediction\/train.csv', columns=set(data_types_dict.keys())).to_pandas()\nquestions_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/questions.csv\")\nexample_test_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/example_test.csv\")","c7501bac":"# 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture. So, let's keep just the questions\ntrain_csv = train_csv[train_csv.content_type_id == 0]\n# read -1 as null, for lectures\ntrain_csv = train_csv[train_csv.answered_correctly != -1]","bd05dc72":"train_csv = train_csv.sort_values(['timestamp'], ascending=True).reset_index(drop = True)","b11f7d9d":"train_csv.head(5)","385df044":"content_mean_final = train_csv[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean', 'count', 'skew',\n                                                          'std', 'var', 'sem',\n                                                                               'sum'])\n \ncontent_mean_final.columns = [\n    'content_mean',\n    'question_asked',\n    'content_skew',\n    'content_std',\n    'content_var',\n    'content_sem',\n    'content_sum'\n]\n\n","e0216e76":"user_mean_final = train_csv[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'count', 'skew',\n                                                        'std', 'var', 'sem',\n                                                                               'sum'])\n\nuser_mean_final.columns = [\n    'mean_user_accuracy',\n    'questions_answered',\n    'questions_skew',\n    'questions_std',\n    'questions_var',\n    'questions_sem',\n    'questions_sum'\n]\n\n","a2e0525e":"#saving value to fillna\nelapsed_time_mean_final = train_csv.prior_question_elapsed_time.mean()","6585be92":"train_csv.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)","a54ca235":"validation = pd.DataFrame()\nfor i in range(5):\n    last_records = train_csv.drop_duplicates('user_id', keep = 'last')\n    train_csv = train_csv[~train_csv.index.isin(last_records.index)]\n    validation = validation.append(last_records)","2d677d09":"X = pd.DataFrame()\nfor i in range(15):\n    last_records = train_csv.drop_duplicates('user_id', keep = 'last')\n    train_csv = train_csv[~train_csv.index.isin(last_records.index)]\n    X = X.append(last_records)","b8b0ab36":"results_c = train_csv[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean', 'count', 'skew',\n                                                          'std', 'var', 'sem',\n                                                                               'sum'])\n\n\nresults_c.columns = [\n    'content_mean',\n    'question_asked',\n    'content_skew',\n    'content_std',\n    'content_var',\n    'content_sem',\n    'content_sum'\n]","0ad49588":"results_u = train_csv[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'count', 'skew',\n                                                        'std', 'var', 'sem',\n                                                                               'sum'])\n\nresults_u.columns = [\n    'mean_user_accuracy',\n    'questions_answered',\n    'questions_skew',\n    'questions_std',\n    'questions_var',\n    'questions_sem',\n    'questions_sum'\n]","97ea04ae":"result_time_mean = train_csv.prior_question_elapsed_time.mean()","6564a379":"#clearing memory\ndel(train_csv)","2678e36f":"X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c, on=['content_id'], how=\"left\")","64394efb":"validation = pd.merge(validation, results_u, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_c, on=['content_id'], how=\"left\")","c66ff8c6":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","5796f98f":"X.columns","0fb43633":"lencoder = LabelEncoder()\n\nX['prior_question_had_explanation'].fillna(False, inplace = True)\nX['prior_question_had_explanation_enc'] = lencoder.fit_transform(X['prior_question_had_explanation'])\n\nX['prior_question_elapsed_time'].fillna(result_time_mean, inplace = True)\nX = X.fillna(X.mean())\n\nX_val['prior_question_had_explanation'].fillna(False, inplace = True)\nX_val['prior_question_had_explanation_enc'] = lencoder.fit_transform(X_val['prior_question_had_explanation'])\n\nX_val['prior_question_elapsed_time'].fillna(result_time_mean, inplace = True)\n\nX_val = X_val.fillna(X_val.mean())","efa7cc7d":"feature_columns = [\n \n    'prior_question_elapsed_time',\n    'prior_question_had_explanation_enc',\n    \n    'mean_user_accuracy',\n    'questions_skew',\n    'questions_std',\n    'questions_var',\n    'questions_sem',\n\n    'content_mean',\n    'content_skew',\n    'content_std',\n    'content_var',\n    'content_sem'\n]","4aff3d40":"X = X[feature_columns]\nX_val = X_val[feature_columns]","d58882bb":"scaler = StandardScaler()\nX = scaler.fit_transform(X)\nX_val = scaler.transform(X_val)","a4e6d809":"K.clear_session()\nX_train = X.reshape(X.shape[0], X.shape[1], 1)\nX_test = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n    \nmodel=Sequential()\nmodel.add(Conv1D(32, 2, activation='relu', input_shape=X_train[0].shape))\nmodel.add(Conv1D(64, 2, activation='relu', padding='causal'))\nmodel.add(Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryAccuracy()])","f28067b0":"history = model.fit(X_train, y, epochs=35, verbose=2, batch_size=50000)","a4ef4dd3":"y_pred = model.predict(X_test)\ny_true = np.array(y_val)","9edb687c":"roc_auc_score(y_true, y_pred)","3e332396":"env = riiideducation.make_env()","f901aaee":"iter_test = env.iter_test()","ef8db2e7":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = pd.merge(test_df, user_mean_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, content_mean_final, on=['content_id'],  how=\"left\")\n    \n    \n    test_df['prior_question_elapsed_time'].fillna(elapsed_time_mean_final, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lencoder.transform(test_df[\"prior_question_had_explanation\"])\n    \n   \n\n    test_df = test_df.fillna(X.mean())\n    \n    # fit transform cnn\n    X = scaler.transform(test_df[feature_columns])\n    test_df['answered_correctly'] = model.predict(X.reshape(X.shape[0], X.shape[1], 1))\n    \n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","f4d31d55":"### cnn","5cbab3f5":"### Check data available","4a53cefc":"## Import necessary libraries","141600f7":"## Pre-Processing","3236a44a":"## Validation\/Train datasets","03a1ec3c":"## Prediction","7a08d998":"Here, i did basic EDA https:\/\/www.kaggle.com\/yaroslavmavliutov\/riiid-answer-correctness-prediction-basic-eda","a641d982":"We have 4 datasets at our disposal"}}