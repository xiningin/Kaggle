{"cell_type":{"c1f5bb17":"code","7d5d0ffb":"code","6abbe94e":"code","d74c3283":"code","5ecacccb":"code","0bf3c454":"code","cb7c35fd":"code","d60db8f9":"code","4c84f8ae":"code","d99f0042":"code","35e402f7":"code","d9718c5f":"code","94804e1e":"code","d3d3a48c":"code","80327b7c":"code","8eaac8c8":"code","eb016580":"code","28bd5617":"code","3214b31d":"code","8597aa8d":"code","a630daec":"code","9d874abb":"code","4f656665":"code","8ffa349a":"code","f6921ceb":"code","74ce69fd":"code","9c552e9b":"code","b54274c9":"code","196467ae":"code","ed7c3fed":"code","673c6c5c":"code","a8a12cac":"code","f861795c":"code","638ada14":"code","629587d9":"code","ff91f694":"code","de5d40ea":"markdown","f4d4ff82":"markdown"},"source":{"c1f5bb17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d5d0ffb":"all_xray_df = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input', 'data', 'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n# all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\nall_xray_df.sample(3)","6abbe94e":"all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\nall_xray_df.sample(3)","d74c3283":"all_xray_df[\"labels\"] = all_xray_df.apply(lambda x: x[\"Finding Labels\"].split(\"|\"), axis=1)","5ecacccb":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(all_xray_df, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = all_xray_df['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","0bf3c454":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (256, 256)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","cb7c35fd":"train_gen = core_idg.flow_from_dataframe(dataframe=train_df,\n                                             directory=None,\n                                             x_col='path',\n                                             y_col='labels',\n                                             class_mode='categorical',\n                                             batch_size=32,\n                                             classes=all_labels,\n                                             color_mode='grayscale',\n                                             target_size=IMG_SIZE)\n\nvalid_gen = core_idg.flow_from_dataframe(dataframe=valid_df,\n                                             directory=None,\n                                             x_col='path',\n                                             y_col='labels',\n                                             class_mode='categorical',\n                                             batch_size=256,\n                                             classes=all_labels,\n                                             color_mode='grayscale',\n                                             target_size=IMG_SIZE) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(core_idg.flow_from_dataframe(dataframe=valid_df,\n                                                   directory=None,\n                                                   x_col='path',\n                                                   y_col='labels',\n                                                   class_mode='categorical',\n                                                   batch_size=1024,\n                                                   classes=all_labels,\n                                                   color_mode='grayscale',\n                                                   target_size=IMG_SIZE))","d60db8f9":"from tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom tensorflow.keras.models import Sequential","4c84f8ae":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_nih_pretrained.h5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min')\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early]","d99f0042":"with tf.device(\"\/gpu:0\"):\n\n    base_mobilenet_model = MobileNet(input_shape =  (256, 256, 1), \n                                     include_top = False, weights = None)\n    multi_disease_model = Sequential()\n    multi_disease_model.add(base_mobilenet_model)\n    multi_disease_model.add(GlobalAveragePooling2D())\n    multi_disease_model.add(Dropout(0.5))\n    multi_disease_model.add(Dense(512))\n    multi_disease_model.add(Dropout(0.5))\n    multi_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\n    multi_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                               metrics = ['binary_accuracy', 'mae'])\n    multi_disease_model.summary()\n\n\n    multi_disease_model.fit(train_gen, \n                            steps_per_epoch=100,\n                            validation_data = (test_X, test_Y), \n                            epochs = 15, \n                            callbacks = callbacks_list)","35e402f7":"y_preds = multi_disease_model.predict(test_X)","d9718c5f":"print(np.around(y_preds[4], 2))\nprint(test_Y[4])","94804e1e":"path = \"..\/input\/chexpert-dataset\/\"\n\ntrain_df = pd.read_csv('..\/input\/modified-chexpert\/modifiedv2_train.csv')\nvalid_df = pd.read_csv('..\/input\/modified-chexpert\/modifiedv2_valid.csv')\ntrain_df[\"path\"] = path + train_df[\"Path\"]\nvalid_df[\"path\"] = path + valid_df[\"Path\"]\n\ndfs = [train_df, valid_df]\nall_xray_df = pd.concat(dfs)\nall_xray_df.sample(3)","d3d3a48c":"all_xray_df.drop(\"No Finding\", axis=1, inplace=True)\nall_xray_df.columns","80327b7c":"all_xray_df = all_xray_df[all_xray_df[\"Finding Labels\"].notnull()]","8eaac8c8":"all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))","eb016580":"all_labels = ['Atelectasis'\n, 'Consolidation'\n, 'Infiltration'\n, 'Pneumothorax'\n, 'Edema'\n, 'Emphysema'\n, 'Fibrosis'\n, 'Pleural Effusion'\n, 'Mass'\n, 'Pneumonia'\n, 'Pleural_thickening'\n, 'Cardiomegaly'\n, 'Nodule Mass'\n, 'Hernia'\n, 'Enlarged Cardiom'\n, 'Lung Lesion'\n, 'Lung Opacity'\n, 'Pleural Other'\n,'Fracture']\n\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))","28bd5617":"for c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\nall_xray_df.sample(3)","3214b31d":"all_xray_df.columns","8597aa8d":"all_xray_df.drop(\"Enlarged Cardiomediastinum\", axis=1, inplace=True)","a630daec":"all_xray_df[\"labels\"] = all_xray_df.apply(lambda x: x[\"Finding Labels\"].split(\"|\"), axis=1)","9d874abb":"all_xray_df[\"labels\"]","4f656665":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(all_xray_df, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = all_xray_df['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","8ffa349a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (256, 256)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","f6921ceb":"train_df.head()","74ce69fd":"train_gen = core_idg.flow_from_dataframe(dataframe=train_df,\n                                             directory=None,\n                                             x_col='path',\n                                             y_col='labels',\n                                             class_mode='categorical',\n                                             batch_size=32,\n                                             classes=all_labels,\n                                             color_mode='grayscale',\n                                             target_size=IMG_SIZE)\n\nvalid_gen = core_idg.flow_from_dataframe(dataframe=valid_df,\n                                             directory=None,\n                                             x_col='path',\n                                             y_col='labels',\n                                             class_mode='categorical',\n                                             batch_size=256,\n                                             classes=all_labels,\n                                             color_mode='grayscale',\n                                             target_size=IMG_SIZE) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(core_idg.flow_from_dataframe(dataframe=valid_df,\n                                                   directory=None,\n                                                   x_col='path',\n                                                   y_col='labels',\n                                                   class_mode='categorical',\n                                                   batch_size=1024,\n                                                   classes=all_labels,\n                                                   color_mode='grayscale',\n                                                   target_size=IMG_SIZE))","9c552e9b":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_chexpert_finetuned.h5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min')\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early]","b54274c9":"for x, y in train_gen:\n    print(x.shape)\n    break","196467ae":"new_model = tf.keras.Sequential()\nfor layer in multi_disease_model.layers[0:-2]:\n    new_model.add(layer)","ed7c3fed":"new_model.add(tf.keras.layers.Dense(200, activation=\"relu\"))\nnew_model.add(tf.keras.layers.Dense(19, activation=\"sigmoid\"))","673c6c5c":"new_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                 loss=tf.keras.losses.BinaryCrossentropy(),\n                 metrics=[\"binary_accuracy\", \"mae\"])","a8a12cac":"new_model.summary()","f861795c":"new_model.fit(train_gen, \n                            steps_per_epoch=100,\n                            validation_data = (test_X, test_Y), \n                            epochs = 15, \n                            callbacks = callbacks_list)","638ada14":"# new_model.predict(test_X[0])\n\ny_preds = new_model.predict(test_X)","629587d9":"np.around(y_preds[0], 2)","ff91f694":"test_Y[0]","de5d40ea":"> * Train: 0.8854\n> * Val: 0.8720\n> * loss_train: 0.3102\n> * loss_val: 0.4242","f4d4ff82":"# Fine tune on CheXpert"}}