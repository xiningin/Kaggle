{"cell_type":{"3692a5aa":"code","65164e10":"code","f19b81a3":"code","2a25a9e5":"code","2633e65f":"code","43b6bbc9":"code","c53ba79b":"code","72a0f526":"code","042590fd":"code","4ca9ac1e":"code","0a4d3168":"code","c37dc097":"code","e2ca2b59":"code","adebb48b":"code","67a008b1":"code","90873bac":"code","61f15d2a":"code","35e659a6":"code","dcd253c3":"code","f4d3f38d":"code","93bb1c90":"code","40145c9c":"code","86308e1c":"code","8de29c2a":"markdown","96a4542b":"markdown","63a9ac7d":"markdown","5fe9214a":"markdown"},"source":{"3692a5aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65164e10":"import re\nimport nltk\nnltk.download('stopwords')\nfrom  nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","f19b81a3":"def preprocess(data):\n\n    porter=PorterStemmer()\n    tweets=[]\n\n    rows=len(data)\n    for index in range(rows):\n        tweet=re.sub(\"[^\\w]\",\" \",data[index])\n        tweet=tweet.lower().split()\n        tweet=[porter.stem(word) for word in tweet if word not in stopwords.words('english')]\n        tweet=' '.join(tweet)\n        tweets.append(tweet)\n    return tweets\n","2a25a9e5":"train=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","2633e65f":"train.head()","43b6bbc9":"train.info()","c53ba79b":"train.isna().sum()","72a0f526":"from sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer()","042590fd":"tweets=preprocess(train['text'])\n","4ca9ac1e":"#tweets\nX=cv.fit_transform(tweets).toarray()","0a4d3168":"X.shape","c37dc097":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB()","e2ca2b59":"from sklearn.model_selection import train_test_split\n","adebb48b":"x_train,x_test,y_train,y_test=train_test_split(X,train['target'],test_size=0.33,random_state=35)","67a008b1":"model.fit(x_train,y_train)","90873bac":"model.score(x_train,y_train)","61f15d2a":"model.score(x_test,y_test)","35e659a6":"t=preprocess(test['text'])","dcd253c3":"test_X=cv.transform(t).toarray()","f4d3f38d":"test_X.shape","93bb1c90":"output=model.predict(test_X)","40145c9c":"df=pd.DataFrame(columns=['id','target'])\ndf['id']=test['id']\ndf['target']=output","86308e1c":"df.to_csv('submission.csv',index=False,sep=',')","8de29c2a":"###  Model training","96a4542b":"### Reading the files","63a9ac7d":"### function to Preprocess the data","5fe9214a":"## Importing the required libraries"}}