{"cell_type":{"3ba70089":"code","2522135a":"code","07c59436":"code","52a9a78c":"code","6da28110":"code","a4fcc253":"code","7c494acd":"code","d1246e34":"code","e42384ed":"code","5909ea99":"code","491afc87":"code","febdb397":"code","0b38f88a":"code","8010c2de":"code","79307f26":"code","5bf52364":"code","a78ba3e6":"code","dfe45a95":"code","6fa18a28":"code","70c8727d":"code","caea6f36":"code","d7eae47b":"code","7c799970":"code","baff84e4":"code","a9bd8caa":"code","bceb98fe":"code","b2ee1cd8":"code","83890aa6":"code","51d14fae":"code","e5594b3e":"code","3cd062ba":"code","c6468786":"code","3b6181b3":"code","36b3abbf":"code","1a1a4d0d":"code","1e56d6d9":"code","47ae47a7":"code","ec1b995b":"code","cdc7f346":"code","a0678885":"code","db6387b8":"markdown"},"source":{"3ba70089":"cd \/kaggle\/input\/pokemon-images-and-types\/images\/","2522135a":"dir = \"images\/\"","07c59436":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nimport imageio","52a9a78c":"def load_pokemon():\n    data = []\n    for i in os.listdir(dir):\n        \n        img = imageio.imread(dir + i)\n        img = Image.fromarray(img)\n        img.load()\n        \n        if(len(img.split()) == 4):\n        \n        # replace alpha channel with white color\n            im = Image.new('RGB', img.size, (255, 255, 255))\n            im.paste(img, mask=img.split()[3])\n           \n        \n        else:\n            im = img\n        pixels = tf.keras.preprocessing.image.img_to_array(im)\n        pixels = pixels.astype(\"float32\")\n        pixels \/= 255.\n        data.append(pixels)\n    return np.stack(data)","6da28110":"dataset = load_pokemon()","a4fcc253":"dataset.shape","7c494acd":"plt.figure(figsize = (15,15))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.axis(\"off\")\n    plt.imshow(dataset[i])\nplt.show()","d1246e34":"def discriminator2(inp_shape = (120,120,3)):\n    tf.keras.backend.clear_session()\n    base_model = tf.keras.applications.MobileNetV2(input_shape = inp_shape, include_top = False, weights=\"imagenet\")\n    base_model.trainable = True\n    glob_avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n    pred_layer = tf.keras.layers.Dense(1, \"sigmoid\")\n    model = tf.keras.models.Sequential([base_model,\n            glob_avg_pool,\n            pred_layer])\n    model.compile(optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5), loss = \"binary_crossentropy\", metrics = ['acc'])\n    return model","e42384ed":"def discriminator(inp_shape = (120,120,3)):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(128, (3,3), strides = (2,2), padding=\"same\", input_shape = inp_shape),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(128, (3,3), padding=\"same\",  strides = (2,2)),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(64, (3,3), padding=\"same\",  strides = (2,2)),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(64, (3,3), padding = \"same\", strides = (2,2)),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Flatten(),\n        \n        tf.keras.layers.Dense(1, activation = \"sigmoid\")\n    ])\n    model.compile(optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5), loss = \"binary_crossentropy\", metrics = ['acc'])\n    return model","5909ea99":"d_model = discriminator()","491afc87":"d_model.summary()","febdb397":"cd \/kaggle\/working","0b38f88a":"tf.keras.utils.plot_model(d_model, show_shapes = True)","8010c2de":"def generate_fake_samples(n_samples):\n    rand_samp = np.random.randn(120 * 120 * 3 * n_samples)\n    rand_samp = -1 + rand_samp * 2\n    X = rand_samp.reshape(n_samples, 120, 120, 3)\n    y = np.zeros(shape = (n_samples,1))\n    return X,y","79307f26":"def train_discriminator(model, dataset, num_iterations = 20, n_batch = 128):\n    half_batch = int(n_batch\/2)\n    for i in range(num_iterations):\n        X_real, y_real = generate_real_samples(dataset, half_batch)\n       \n        _, real_acc = model.train_on_batch(X_real, y_real)\n        \n        X_fake, y_fake = generate_fake_samples(half_batch)\n      \n        _, fake_acc = model.train_on_batch(X_fake, y_fake)\n        print(\"Batch {}: Real acc: {} and Fake acc: {}\".format(i+1, real_acc*100, fake_acc* 100))","5bf52364":"train_discriminator(d_model, dataset)","a78ba3e6":"X_real, y_real = generate_real_samples(dataset,800)\nX_fake, y_fake = generate_fake_samples(800)\nX,y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))","dfe45a95":"history = d_model.fit(X,y, epochs = 5)","6fa18a28":"history","70c8727d":"plt","caea6f36":"def generator(latent_dim = 100):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Dense(128 * 15 * 15, input_dim = latent_dim),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Reshape((15,15,128)),\n        \n        # 30 * 30\n        tf.keras.layers.Conv2DTranspose(128, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        #60 * 60\n        tf.keras.layers.Conv2DTranspose(128, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        # 120 * 120\n        tf.keras.layers.Conv2DTranspose(64, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(3, (3,3), padding = \"same\", activation = \"sigmoid\")\n        \n    ])\n    return model","d7eae47b":"d_model.summary()","7c799970":"g_model = generator()","baff84e4":"g_model.summary()","a9bd8caa":"def generate_real_samples(dataset, n_size = 128):\n    ind = np.random.randint(0, dataset.shape[0], n_size)\n    data = dataset[ind]\n    y = np.ones((n_size, 1))\n    return data, y","bceb98fe":"# plt.imshow(generate_fake_examples(g_model)[0][3])","b2ee1cd8":"def generate_latent_space(n_size = 128, latent_dim = 100):\n    points = np.random.randn(n_size * latent_dim)\n    points = points.reshape((n_size, latent_dim))\n    return points","83890aa6":"def generate_fake_examples(g_model, n_size = 128, latent_dim = 100):\n    latent_space = generate_latent_space(n_size, latent_dim)\n    preds = g_model.predict(latent_space)\n    y = np.zeros((n_size , 1))\n    return preds, y","51d14fae":"def gan(g_model, d_model):\n    d_model.trainable = False\n    model = tf.keras.models.Sequential([\n        g_model,\n        d_model\n    ])\n    model.compile(optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5), loss = \"binary_crossentropy\")\n    return model","e5594b3e":"gan_model = gan(g_model, d_model)","3cd062ba":"gan_model.summary()","c6468786":"def plot_samples(data):\n    plt.figure(figsize = (15,15))\n    for i in range(7*7):\n        plt.subplot(7,7,i+1)\n        plt.axis(\"off\")\n        plt.imshow(data[i])\n    plt.show()","3b6181b3":"def summarize_performance(g_model, dataset, n_size = 128):\n    X_real, y_real = generate_real_samples(dataset)\n    _,accr = d_model.evaluate(X_real, y_real)\n    \n    X_fake, y_fake = generate_fake_examples(g_model)\n    _, accf = d_model.evaluate(X_fake, y_fake)\n    \n    print(\"Real samples Acc: {}\".format(accr*100))\n    print(\"Fake samples Acc: {}\".format(accf*100))\n    \n    plot_samples(X_fake)\n    ","36b3abbf":"cd ","1a1a4d0d":"cd \/kaggle\/working","1e56d6d9":"def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n\t# plot loss\n\tplt.subplot(2, 1, 1)\n\tplt.plot(d1_hist, label='d-real')\n\tplt.plot(d2_hist, label='d-fake')\n\tplt.plot(g_hist, label='gen')\n\tplt.legend()\n\t# plot discriminator accuracy\n\tplt.subplot(2, 1, 2)\n\tplt.plot(a1_hist, label='acc-real')\n\tplt.plot(a2_hist, label='acc-fake')\n\tplt.legend()\n\t# save plot to file\n\tplt.close()","47ae47a7":"def train(g_model, d_model, gan_model, dataset,epochs = 1500, latent_dim = 100, batch_size = 128):\n    half_batch = int(batch_size\/2)\n    batch_per_epoch = int(len(dataset)\/batch_size)\n    d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n    for i in range(epochs):\n        for j in range(batch_per_epoch):\n            X_real, y_real = generate_real_samples(dataset, half_batch)\n            d_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n            \n            X_fake, y_fake = generate_fake_examples(g_model, half_batch)\n            d_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n            \n            X_gan = generate_latent_space()\n            y_gan = np.ones((batch_size, 1))\n            \n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            \n            d1_hist.append(d_loss1)\n            d2_hist.append(d_loss2)\n            g_hist.append(g_loss)\n            a1_hist.append(d_acc1)\n            a2_hist.append(d_acc2)\n            \n            if((j+1) % 5 == 0):\n                print('>%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n                    (i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n        \n        if((i+1) % 50 == 0):\n            summarize_performance(g_model, dataset)\n    plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist)\n            ","ec1b995b":"# Trained for 1500 epochs\ntrain(g_model, d_model, gan_model, dataset)","cdc7f346":"g_model.save(\"pokemon.h5\")","a0678885":"X_input = generate_latent_space(n_size = 49)\npreds = g_model.predict(X_input)\nplot_samples(preds)","db6387b8":"## Vizualizaing Generated Pokemons "}}