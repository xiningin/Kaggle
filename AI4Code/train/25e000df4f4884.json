{"cell_type":{"23937438":"code","9fccb20a":"code","1db04a28":"code","cf43738c":"code","7ad8279a":"code","9f1f0d63":"code","8afda0cc":"code","8fefa7c6":"code","70917a66":"code","2a50bf11":"code","4c7ddbc0":"code","f9eca534":"code","7499b109":"code","020d23f6":"code","c8da8dd5":"code","3d21b3d0":"code","41f36473":"code","f721e5c0":"code","04564298":"code","01a3f332":"code","021dee6e":"code","b306d78c":"code","9371b35e":"code","764a6f20":"code","060090e0":"code","3fba0f74":"code","57080dcc":"code","a07c3c8c":"code","cf2c9ea8":"code","7eaf6a8b":"code","64390911":"code","892b2bec":"code","112d4943":"code","68738ef3":"code","ab3a2a64":"code","de962b18":"code","38f35f54":"code","87b45e4b":"code","031adb56":"code","b54adb0b":"markdown","209ae6ac":"markdown","151b80ab":"markdown","3dd9d58e":"markdown","45e35b66":"markdown"},"source":{"23937438":"# Importing required packages\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 50)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score,confusion_matrix,roc_curve,auc\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures,LabelEncoder,OneHotEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.neural_network import MLPClassifier","9fccb20a":"train = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/test.csv\")\ntest_ids = test[\"id\"]","1db04a28":"# Check number of features and data points in train and test\nprint(\"Number of data points in train: %d\" % train.shape[0])\nprint(\"Number of features in train: %d\" % train.shape[1])\n\nprint(\"Number of data points in test: %d\" % test.shape[0])\nprint(\"Number of features in test: %d\" % test.shape[1])","cf43738c":"train.head()","7ad8279a":"test.tail(10).T","9f1f0d63":"# Unique values in each column\nfor col in train.columns:\n    print(\"Unique entries in\",col,\" -\", train[col].nunique())","8afda0cc":"train['bin_3'] = train[\"bin_3\"].apply(lambda x: 0 if x == \"F\" else 1)\ntrain['bin_4'] = train[\"bin_4\"].apply(lambda x: 0 if x == \"N\" else 1)\n\ntest['bin_3'] = test[\"bin_3\"].apply(lambda x: 0 if x == \"F\" else 1)\ntest['bin_4'] = test[\"bin_4\"].apply(lambda x: 0 if x == \"N\" else 1)\n\ntrain['ord_5a'] = train[\"ord_5\"].str[0]\ntrain['ord_5b'] = train[\"ord_5\"].str[1]\n\ntest['ord_5a'] = test[\"ord_5\"].str[0]\ntest['ord_5b'] = test[\"ord_5\"].str[1]","8fefa7c6":"train.info()","70917a66":"test.info()","2a50bf11":"# Checking for NULL\/missing values\ntrain.isnull().sum()","4c7ddbc0":"# Checking for NULL\/missing values\ntest.isnull().sum()","f9eca534":"# Univariate analysis\nprint(train['target'].value_counts(),'\\n')\nprint(train['target'].value_counts(normalize=True)*100,'\\n')\nsns.countplot(train[\"target\"])","7499b109":"train.head()","020d23f6":"train['ord_1'].str.lower().value_counts().sort_values()","c8da8dd5":"train['ord_2'].str.lower().value_counts().sort_values()","3d21b3d0":"train.head()","41f36473":"test.head()","f721e5c0":"high_card_feats = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nfor col in high_card_feats:\n    train[f'hash_{col}'] = train[col].apply( lambda x: hash(str(x)) % 5000 )\n    test[f'hash_{col}'] = test[col].apply( lambda x: hash(str(x)) % 5000 )\n\ntrain.drop([\"id\",\"nom_5\",\"nom_6\",\"nom_7\",\"nom_8\",\"nom_9\",\"ord_5\"], axis=1, inplace=True)\ntest.drop([\"id\",\"nom_5\",\"nom_6\",\"nom_7\",\"nom_8\",\"nom_9\",\"ord_5\"], axis=1, inplace=True)","04564298":"train.head()","01a3f332":"test.head()","021dee6e":"# train_new = pd.DataFrame()\n# le = LabelEncoder()\n# for c in train.columns:\n#     if(train[c].dtype == 'object'): train_new[c] = le.fit_transform(train[c])\n#     else:      train_new[c] = train[c]\n\n# train_new.head()","b306d78c":"# test_new = pd.DataFrame()\n# for c in test.columns:\n#     if(test[c].dtype == 'object'): test_new[c] = le.transform(test[c])\n#     else:      test_new[c] = test[c]\n\n# test_new.head()","9371b35e":"# One Hot Encoding\n\n# str_cols= train.loc[:, train.dtypes=='object'].columns.tolist()\n# str_cols\n\n# train = pd.get_dummies(train, columns=str_cols, drop_first=True)\n# test = pd.get_dummies(test, columns=str_cols, drop_first=True)\n\n# onehot_enc = OneHotEncoder()\n# # train = onehot_enc.fit_transform(train)\n# # test = onehot_enc.transform(test)\n\n# import category_encoders as ce\n# ohe = ce.OneHotEncoder(handle_unknown='ignore', use_cat_names=True)\n# train = ohe.fit_transform(train)\n# test = ohe.transform(test)","764a6f20":"target = train.pop('target')\ndata = pd.concat([train, test])\ndummies = pd.get_dummies(data, columns=data.columns, drop_first=True, sparse=True)\ntrain = dummies.iloc[:train.shape[0], :]\ntest = dummies.iloc[train.shape[0]:, :]\ntrain = train.sparse.to_coo().tocsr()\ntest = test.sparse.to_coo().tocsr()","060090e0":"# train2 = train.drop(['target'], axis=1)\n# target = train[\"target\"]\n# train2 = train2.loc[:, test.columns]","3fba0f74":"# # Using imblearn for Balancing Data\n# from imblearn.over_sampling import SMOTE\n# sm = SMOTE(random_state=2019)\n\n# from imblearn.over_sampling import ADASYN\n# sm = ADASYN()\n\n# from imblearn.over_sampling import SVMSMOTE\n# sm = SVMSMOTE(random_state=2019)\n\n# from imblearn.combine import SMOTETomek\n# sm = SMOTETomek(ratio='auto')\n\n# from imblearn.combine import SMOTEENN\n# sm = SMOTEENN(random_state=2019)\n\n# train2, target = sm.fit_sample(train2, target.ravel())\n\n# from collections import Counter\n# print('Resampled dataset shape %s' % Counter(target))\n\n# from imblearn.under_sampling import NearMiss\n# nr = NearMiss()\n# train2, target = nr.fit_sample(train2, target.ravel())\n# np.bincount(target)","57080dcc":"# # Scaling Data\n# #scaler = MinMaxScaler()\n# scaler = StandardScaler()\n# train2 = scaler.fit_transform(train2)\n# test = scaler.transform(test)","a07c3c8c":"# poly = PolynomialFeatures(degree=1)\n# train2 = poly.fit_transform(train2)\n# test = poly.transform(test)\n# poly\n# print(\"train2 shape:\", train2.shape)\n\n# # # train2 shape: (14272, 44)","cf2c9ea8":"# pca = PCA(random_state=2019)\n# #pca = PCA(random_state=2019, n_components=200)\n# train2 = pca.fit_transform(train2)\n\n# test = pca.transform(test)\n# pca","7eaf6a8b":"x_train, x_val, y_train, y_val = train_test_split(train, target, test_size=0.25, random_state=123)\nprint(x_train.shape, x_val.shape)","64390911":"sns.set('talk', 'whitegrid', 'dark', font_scale=1, font='Ricty',rc={\"lines.linewidth\": 2, 'grid.linestyle': '--'})\n\n# Receiver Operating Characteristic\ndef plotAUC(truth, pred, lab):\n    fpr, tpr, _ = roc_curve(truth,pred)\n    roc_auc = auc(fpr, tpr)\n    lw = 2\n    c = (np.random.rand(), np.random.rand(), np.random.rand())\n    plt.plot(fpr, tpr, color= c,lw=lw, label= lab +'(AUC = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve')\n    plt.legend(loc=\"lower right\")","892b2bec":"# #clf_NN = MLPClassifier(random_state=2019, hidden_layer_sizes=(100, 100, 100))\n# clf_NN = MLPClassifier(activation='tanh', alpha=0.0001, max_iter=200, hidden_layer_sizes=(50, 50, 50), random_state=2019, solver='sgd')\n# clf_NN.fit(x_train, y_train)\n# y_val_pred = clf_NN.predict(x_val)\n# predictprob = clf_NN.predict_proba(x_val)[:,1]\n# y_val_pred\n# y_pred = clf_NN.predict(test)","112d4943":"#clf_NN","68738ef3":"# Random Forest\n# rf = RandomForestClassifier(n_estimators=800, random_state = 2019).fit(x_train, y_train)\n# rf","ab3a2a64":"rf = LogisticRegression(C=0.1338, solver=\"lbfgs\", tol=0.003, max_iter=4000)\nrf.fit(x_train, y_train)","de962b18":"y_val_pred = rf.predict(x_val)\npredictprob = rf.predict_proba(x_val)[:,1]\ny_pred = rf.predict(test)\ny_pred","38f35f54":"Accuracy = accuracy_score(y_val, y_val_pred)\nprint(Accuracy)\nplotAUC(y_val, predictprob, 'MLP')\nplt.show()\n\n# ROC 0.745\n# AUC 0.76","87b45e4b":"# Confusion Matrix\ncm = confusion_matrix(y_val, y_val_pred).T\ncm = cm.astype('float')\/cm.sum(axis=0)\nax = sns.heatmap(cm, annot=True, cmap='Blues');\nax.set_xlabel('True Label',size=12)\nax.set_ylabel('Predicted Label',size=12)\n\n# # TP 0.815 TN 0.44\n# RF # TP 0.96 TN 0.17\n# SMOTE TP 0.96 TN 0.63","031adb56":"submission = pd.DataFrame(data = {\"id\":test_ids, \"target\":y_pred})\nprint(submission['target'].value_counts())\nsubmission.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","b54adb0b":"## **Importing Libraries & Reading Data**","209ae6ac":"## Machine Learning\/Neural Networks","151b80ab":"## Exploratory Data Analysis (EDA)","3dd9d58e":"## Preparding Data for modelling","45e35b66":"## Kaggle - Categorical Feature Encoding Challenge\n## Target Prediction Analysis (Cat in the Dat) in Python using sklearn package\n\n## **[https:\/\/satya-python.blogspot.com](https:\/\/satya-python.blogspot.com)**"}}