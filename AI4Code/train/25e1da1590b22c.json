{"cell_type":{"2094b59c":"code","a93711b2":"code","f9b41bb4":"code","37b66dd6":"code","557e7495":"code","e6f80a3c":"code","d4731091":"code","4543e5bd":"code","1063fbed":"code","cedf96df":"code","f4e589a3":"code","18cd78d1":"code","f06b42d2":"code","14169814":"code","b57befc9":"markdown","2a17ae83":"markdown","8442bd97":"markdown","20fd89ea":"markdown","ae87b5a5":"markdown"},"source":{"2094b59c":"from IPython.core.display import display, HTML\n\nimport pandas as pd\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport gc\nimport plotly.graph_objects as go\n\nfrom joblib import Parallel, delayed\nfrom sklearn import preprocessing, model_selection\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom tqdm import tqdm\n\n\ndata_dir = '..\/input\/optiver-realized-volatility-prediction\/'","a93711b2":"!mkdir -p \/tmp\/pip\/cache\/\n!cp ..\/input\/hdbscan0827-whl\/hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl \/tmp\/pip\/cache\/\n!pip install --no-index --find-links \/tmp\/pip\/cache\/ hdbscan","f9b41bb4":"import hdbscan\nfrom sklearn import datasets\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport seaborn as sns","37b66dd6":"def read_train_test():\n    train = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\n    # Create a key to merge with book and trade data\n    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n    print(f'Our training set has {train.shape[0]} rows')\n    return train\n\ndef trade_preprocessor(file_path):\n    df = pd.read_parquet(file_path)\n    stock_id = file_path.split('=')[1]\n    df['row_id'] = df['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    df = df.drop('time_id',axis=1)\n    return df\n\ndef preprocessor(list_stock_ids, is_train = True):\n    \n    # Parrallel for loop\n    def for_joblib(stock_id):\n        # Train\n        file_path_trade = data_dir + \"trade_train.parquet\/stock_id=\" + str(stock_id)\n        df_tmp = trade_preprocessor(file_path_trade)\n        return df_tmp\n    \n    # Use parallel api to call paralle for loop\n    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n    # Concatenate all the dataframes that return from Parallel\n    df = pd.concat(df, ignore_index = True)\n    return df","557e7495":"# Read train and test\ntrain = read_train_test()\n\n# preprocess stock-id = 0\ntrain_ = preprocessor([0], is_train = True)\ntrain = train.merge(train_, on = ['row_id'], how = 'left')","e6f80a3c":"train[train['stock_id']==0]","d4731091":"train = train.groupby(['stock_id','time_id'])['price','size','order_count'].agg(['mean', 'std', 'max', 'min', ]).reset_index()\ntrain","4543e5bd":"train = train.dropna()\ntrain = train[train['stock_id']==0]\nX = np.array(train)","1063fbed":"np.array(train)","cedf96df":"train","f4e589a3":"projection = TSNE().fit_transform(X)\nplt.scatter(*projection.T,)","18cd78d1":"clusterer = hdbscan.HDBSCAN(min_cluster_size=10, prediction_data=True).fit(X)\ncolor_palette = sns.color_palette('Paired', 12)\ncluster_colors = [color_palette[x] if x >= 0\n                  else (0.5, 0.5, 0.5)\n                  for x in clusterer.labels_]\ncluster_member_colors = [sns.desaturate(x, p) for x, p in\n                         zip(cluster_colors, clusterer.probabilities_)]\nplt.scatter(*projection.T, s=50, linewidth=0, c=cluster_member_colors, alpha=0.25)","f06b42d2":"u, counts = np.unique(clusterer.labels_, return_counts=True)\nprint(u)\nprint(counts)","14169814":"len(clusterer.labels_)","b57befc9":"## HDBSCAN\n\nClustering with HDBSCAN and mapping the result to the t-SNE plot generated in the figure above.","2a17ae83":"## About this notebook\n\nDimensionality reduction by t-SNE and clustering by HDBSCAN.\nIn order to prevent the data from becoming too large, only cases with stock_id =0 will be handled.\n\nAlso, the installation and implementation of HDBSCAN was done by referring to [\nOptiver HDBSCAN](https:\/\/www.kaggle.com\/something4kag\/optiver-hdbscan), and on top of that, this notebook was created for this competition.\n\nThank you for @something4kag\n \nI wrote about UMAP and HDBSCAN in separate notebooks.[UMAP & HDBSCAN (stock_id=0)](https:\/\/www.kaggle.com\/takemi\/umap-hdbscan-stock-id-0)","8442bd97":"## Simple Preprocess\n\nConcat the elements of train.csv and train_trade.parquet to create train data.\n","20fd89ea":"Group by stock_id and time_id, and calculate mean, max, min, and std values for price, size, and orde_count, respectively, and use them as features.","ae87b5a5":"## t-SNE"}}