{"cell_type":{"4b276a69":"code","3a768b47":"code","4b0d5128":"code","03e92194":"code","16450e6a":"code","92421a72":"code","64dc3c9a":"code","7b2a9934":"code","f1b1ea4c":"code","15274586":"code","e6c26546":"code","86122e83":"code","e90022d6":"code","8abac81b":"code","8d293eed":"code","e8970b44":"code","5caf2131":"code","99ac0eac":"code","0b81d584":"code","93f4b524":"code","614c802d":"code","eb84da1a":"code","9bf35074":"code","9952bfc1":"code","dfb164f1":"code","ca3d41ea":"code","33af5afd":"code","0c9eaade":"code","475225b8":"code","8266dbba":"code","a8ea84e2":"code","42807275":"code","90abf777":"code","9e448982":"code","94aa2df6":"code","1fdb2fbf":"code","0ed4b9c0":"code","a47d283a":"code","124e6525":"code","06c8e924":"code","c3fcbc48":"code","458bafff":"code","43cb4aa1":"code","5d663fa6":"code","33721abc":"code","4cfdb9d1":"code","a4ae0e46":"code","2816833c":"code","71c5b6d2":"code","bb621693":"code","d4f1bd5f":"code","e18e6d6e":"code","b4b1ba20":"code","17885f34":"code","9b945e06":"code","c44cae60":"code","1834d5a7":"code","c5be2997":"code","77f0dd6e":"code","e7d24d30":"code","62ab59a5":"code","0428912d":"code","4a7449f8":"code","ed49ecdd":"code","a818f246":"code","80b2d976":"code","51755a3e":"code","641d9920":"code","fc4dd86d":"code","48762b4a":"code","a8749d07":"code","6b905a96":"code","afb0cc5e":"code","028a1a54":"code","eff2fd90":"code","3d216c56":"code","d1c65f6a":"code","e21b6e40":"markdown","829cd8ca":"markdown","c48eb79b":"markdown","f3c0c801":"markdown","e5a15436":"markdown","572aae98":"markdown","ff53653e":"markdown","1cc893ec":"markdown","57a610ad":"markdown","ef58274d":"markdown","fa203811":"markdown","dab9fb0b":"markdown","51bad450":"markdown","ac94f673":"markdown","9619a798":"markdown","0b392e67":"markdown","3cc30338":"markdown","9ad9aad3":"markdown","d7424505":"markdown","a1b74e1e":"markdown","05ead56d":"markdown","b26eafe7":"markdown","c0d9a66d":"markdown","a000f43d":"markdown","a6f3c2ed":"markdown","d9b78233":"markdown","e6d1924f":"markdown","9b07dc8e":"markdown","2e2fbc15":"markdown","f2f816c1":"markdown","b9f32aa3":"markdown","15c35895":"markdown","f800ec43":"markdown","bd090c39":"markdown","5d236807":"markdown","72bf4055":"markdown","90e9c017":"markdown","0e2d819e":"markdown","b5adb1bb":"markdown","8b89609d":"markdown","89bad788":"markdown","51364672":"markdown","e959f461":"markdown","7c72b68e":"markdown","90b75879":"markdown","cbfd8f1f":"markdown","aaa1d949":"markdown","bcef9046":"markdown","b9b18449":"markdown","2fc35a80":"markdown"},"source":{"4b276a69":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","3a768b47":"# reading data into fishes\nfishes = pd.read_csv('..\/input\/fish-market\/Fish.csv')\nfishes.head()","4b0d5128":"fishes.info()","03e92194":"fishes.describe()","16450e6a":"fishes.hist(bins= 25, figsize=(16, 8))","92421a72":"cat = np.arange(0, 4)\nbins = [-0.1, 330., 660., 990., np.inf]\n\n# feature 'Weight_cat':\n# Categorised Weight in accordance with bins\nfishes['Weight_cat'] = pd.cut(fishes.Weight, bins=bins, labels=cat)","64dc3c9a":"fishes.Weight_cat.value_counts()","7b2a9934":"fishes.Weight_cat.hist()","f1b1ea4c":"from sklearn.model_selection import StratifiedShuffleSplit\n\n# stratified train test split by 'Weight_cat' \nstat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2 ,random_state=90)\n\nfor train_index, test_index in stat_split.split(fishes, fishes.Weight_cat):\n    strat_train = fishes.loc[train_index]\n    strat_test = fishes.loc[test_index]","15274586":"# dropping 'Weight_cat' from train test sets\nfor set_ in (strat_train, strat_test):\n    set_.drop('Weight_cat', axis=1, inplace=True)","e6c26546":"fishes = strat_train.copy()","86122e83":"fishes.sort_index(inplace=True)","e90022d6":"def SelectIndicesZeroVal(df):\n    \"\"\"\n    Searching for rows with zero values and\n    return thier indices in list\n    \n    df: DataFrame\n    \"\"\"\n    zero = []\n\n    for column in df.columns:\n        zero.extend(df[df[column] == 0].index.values)\n        \n    return zero","8abac81b":"zero = SelectIndicesZeroVal(fishes)\nfishes.loc[zero]","8d293eed":"def PlotSpecies(ax_):\n    \"\"\"\n    Takes ax object and plots with it \n    species frequencies\n    \"\"\"\n    ax_.bar(species.index, species.values)\n    ax_.set_ylabel('frequencies')","e8970b44":"# species frequencies\nspecies = fishes.Species.value_counts()\n\nfig, ax = plt.subplots(figsize=(12,6))\nPlotSpecies(ax)\nax.set_title('Species', fontsize=19)","5caf2131":"import seaborn as sns\n\nWeights = fishes.Weight\n\nfig, ax = plt.subplots(figsize=(8,6))\nsns.ecdfplot(fishes, x='Weight', ax=ax)\nplt.vlines(np.median(Weights), 0, 1, color='orange', label='median')\nplt.vlines(np.mean(Weights), 0, 1, color='red', label='mean')\nplt.title('Weight CDF', fontsize=19)\nplt.legend()","99ac0eac":"species_groups = fishes.groupby('Species')\n\ncolumns_num = list(fishes)\ncolumns_num.remove('Species')\n\ndef SpeciesColAvr(df, columns):\n    \"\"\"\n    Grouping by 'Species' and calculating\n    column means in groups\n    \n    df: DataFrame\n    columns: column names\n    \"\"\"\n    species_groups_ = df.groupby('Species')\n    \n    species_col_avr_ = pd.DataFrame(columns=columns)\n    means = []\n\n    for name, group in species_groups_:\n\n        for column in columns:\n            means.append(np.mean(group[column]))\n\n        species_col_avr_.loc[name] = means\n\n        means.clear()\n\n    species_col_avr_ = species_col_avr_.loc[species.index]\n    return species_col_avr_","0b81d584":"species_col_avr = SpeciesColAvr(fishes, columns_num)\nspecies_col_avr","93f4b524":"def PlotSpeciesFeature(ax_, feat_name):\n    \"\"\"\n    Takes ax object, feature name and plots \n    Species means of provided feature\n    \"\"\"\n    ax_.plot(species.index, species_col_avr[feat_name].values, label=feat_name)\n    ax_.set_ylabel(feat_name)","614c802d":"def PlotSpeciesCombinations(axs_, feat_names_):\n    \"\"\"\n    Takes ax object, feature names. \n    Plots Species means of provided features\n    \"\"\"\n    indices = np.arange(len(axs_))\n    for index in indices:\n        PlotSpeciesFeature(axs_[index], feat_names_[index])","eb84da1a":"def PlotSpeciesLength(ax_):\n    \"\"\"\n    Takes ax object and plots with it \n    Species mean lengths (3 of them)\n    \"\"\"\n    len_col = ['Length1', 'Length2', 'Length3']\n    for column in len_col:\n        PlotSpeciesFeature(ax_, column)\n    ax_.set_ylabel('Length')\n    ax_.legend()","9bf35074":"fig, ax = plt.subplots(2, figsize=(8,6))\nPlotSpecies(ax[0])\nPlotSpeciesFeature(ax[1], 'Weight')\nax[0].set_title('Species frequencies and mean weight', fontsize=19)","9952bfc1":"fig, axs = plt.subplots(5, figsize=(8,14))\n\nPlotSpecies(axs[0])\nPlotSpeciesLength(axs[1])\n\nfeat_names = ['Weight', 'Height', 'Width']\nPlotSpeciesCombinations(axs[2:5], feat_names)\n\naxs[0].set_title('Species frequencies and means', fontsize=19)","dfb164f1":"corr_map = fishes.corr()","ca3d41ea":"fig, ax = plt.subplots(figsize=(9, 7))\nsns.heatmap(corr_map, ax=ax, annot=True)","33af5afd":"corr_map['Weight']","0c9eaade":"fishes['Diff_Length21'] = fishes['Length2'] - fishes['Length1']\nfishes['Diff_Length31'] = fishes['Length3'] - fishes['Length1']\nfishes['Volume'] = fishes['Length2'] * fishes['Height'] * fishes['Width']        ","475225b8":"corr_map_new_feat = fishes.corr()\ncorr_map_new_feat['Weight'].sort_values(ascending=False)","8266dbba":"fishes = fishes.drop(['Diff_Length21', 'Diff_Length31', 'Volume'], axis=1)","a8ea84e2":"fishes_labels = fishes['Weight']\nfishes = fishes.drop('Weight', axis=1)","42807275":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass ZeroToNan(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Custom transformer transformers zero values \n    to Nan in given columns\n    \n    variables: column names iterable\n    \"\"\"\n    def __init__(self, variables):\n        self.variables = variables\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X_c = X.copy()\n        X_c[self.variables] = X_c[self.variables].replace(0, np.nan)\n        return X_c","90abf777":"class ImputerSpeciesFeatureMean(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Custom transformer replaces Nan \n    in provided columns with \n    column mean in groups\n    \n    variables: column names iterable\n    by: column to group by\n    \"\"\"\n    def __init__(self, variables, by):\n        self.variables = variables\n        self.by = by\n            \n    def fit(self, X, y=None):\n        self.map = X.groupby(self.by)[self.variables].mean()\n        return self\n    \n    def transform(self, X, y=None):\n        Xc = X.copy()\n        for variable in self.variables:\n            Xc[variable] = Xc[variable].fillna(value = Xc[self.by].map(self.map[variable]))\n        return Xc[self.variables]","9e448982":"label_species = pd.concat([fishes_labels, fishes['Species']], axis=1)\nzero_nan = ZeroToNan('Weight')\nXY = zero_nan.fit_transform(label_species)","94aa2df6":"XY.loc[40]","1fdb2fbf":"imputer_species_mean = ImputerSpeciesFeatureMean(['Weight'], 'Species')\nXY = imputer_species_mean.fit_transform(XY)","0ed4b9c0":"XY.loc[40]","a47d283a":"from sklearn.pipeline import Pipeline\n\nsteps = [\n    ('zero_nan', ZeroToNan('Weight')),\n    ('imputer_species_mean', ImputerSpeciesFeatureMean(['Weight'], 'Species'))\n]\n\npipe_label = Pipeline(steps)\nfishes_label_prepared = pipe_label.fit_transform(label_species)","124e6525":"fishes_label_prepared['Weight']","06c8e924":"fishes_label_prepared = fishes_label_prepared['Weight']","c3fcbc48":"from sklearn.preprocessing import OneHotEncoder\n\nfishes_cat = fishes[['Species']]\ncolumns_cat = ['Species']\n\ncat_encoder = OneHotEncoder()\nfishes_cat_1hot = cat_encoder.fit_transform(fishes_cat)","458bafff":"columns_num_exog = columns_num.copy()\ncolumns_num_exog.remove('Weight')\nfishes_num = fishes[columns_num_exog]","43cb4aa1":"class FeaturesCalculator(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Calculates new features\n    \"\"\"\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X_c = X.copy()\n        \n        X_c['Diff_Length21'] = X_c['Length2'] - X_c['Length1']\n        X_c['Diff_Length31'] = X_c['Length3'] - X_c['Length1']\n        X_c['Volume'] = X_c['Length2'] * X_c['Height'] * X_c['Width']\n        \n        return X_c","5d663fa6":"calc_feat = FeaturesCalculator()\ncalc_feat.fit_transform(fishes_num)","33721abc":"from sklearn.preprocessing import StandardScaler\n\nstandard_scaler = StandardScaler()\nstandard_scaler.fit_transform(fishes_num)[:10]","4cfdb9d1":"# dictionary to store X prepared\nfishes_prepared = {}","a4ae0e46":"from sklearn.pipeline import Pipeline\n\nsteps = [\n    ('feat_calc', FeaturesCalculator()),\n    ('standard_scaler', StandardScaler())\n]\n\npipe_num_stdsclr = Pipeline(steps=steps)\nfishes_num_transformed = pipe_num_stdsclr.fit_transform(fishes_num)","2816833c":"from sklearn.compose import ColumnTransformer\n\nsteps = [\n    ('pipe_num_stdsclr', pipe_num_stdsclr, columns_num_exog),\n    ('encoder_1hot', OneHotEncoder(), columns_cat)\n]\n\ncolumn_transformer_stdsclr = ColumnTransformer(steps)\nfishes_prepared['stdsclr'] = column_transformer_stdsclr.fit_transform(fishes)\n","71c5b6d2":"steps = [\n    ('feat_calc', FeaturesCalculator(), columns_num_exog),\n    ('encoder_1hot', OneHotEncoder(), columns_cat)\n]\n\ncolumn_transformer_base = ColumnTransformer(steps)\nfishes_prepared['base'] = column_transformer_base.fit_transform(fishes)","bb621693":"from sklearn.preprocessing import MinMaxScaler\n\nsteps = [\n    ('feat_calc', FeaturesCalculator()),\n    ('min_max_scaler', MinMaxScaler())\n]\n\npipe_num_minmax_sclr = Pipeline(steps=steps)\nfishes_num_transformed = pipe_num_minmax_sclr.fit_transform(fishes_num)","d4f1bd5f":"steps = [\n    ('pipe_num_minmax_sclr', pipe_num_minmax_sclr, columns_num_exog),\n    ('encoder_1hot', OneHotEncoder(), columns_cat)\n]\n\ncolumn_transformer_minmax_sclr = ColumnTransformer(steps)\nfishes_prepared['minmax_sclr'] = column_transformer_minmax_sclr.fit_transform(fishes)","e18e6d6e":"columns = ['score', 'rmse']\n# df to store scores and rmse\npreprcss_pipes = pd.DataFrame(columns=columns)","b4b1ba20":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\ndef FitLinearToDataSet(X_, y_):\n    \"\"\"\n    Takes predictors and labels.\n    Fit them to linear model.\n    Calculates R2 and RMSE.\n    \n    X_: predictors\n    y_: labels\n    return: linear model, statistic in dictionary\n    \"\"\"\n    stats = {}\n    linear_regression = LinearRegression()\n    linear_regression.fit(X_, y_)\n    predictions = linear_regression.predict(X_)\n    stats['score'] = linear_regression.score(X_, y_)\n    mse = mean_squared_error(predictions, y_)\n    stats['rmse'] = np.sqrt(mse)\n    return linear_regression, stats ","17885f34":"base_model, row = FitLinearToDataSet(fishes_prepared['base'], \n                                      fishes_label_prepared)\npreprcss_pipes.loc['base'] = row","9b945e06":"from sklearn.compose import TransformedTargetRegressor\n\ndef FitTargetVariableTransf(X_, y_, targ_transf, regr=LinearRegression()):\n    stats = {}\n    transf_target_reg = TransformedTargetRegressor(regressor=regr, transformer=targ_transf)\n    transf_target_reg.fit(X_, y_)\n\n    predictions_ = transf_target_reg.predict(X_)\n\n    stats['score'] = transf_target_reg.score(X_, y_)\n    \n    mse = mean_squared_error(predictions_, y_)\n    stats['rmse'] = np.sqrt(mse)\n    return stats","c44cae60":"fishes_prepared_transf = fishes_prepared.copy()\nfishes_prepared_transf.pop('base')\nSetTransformer = {'stdsclr': StandardScaler(),\n                  'minmax_sclr': MinMaxScaler()}\n\n\nfor name, X_ in fishes_prepared_transf.items():\n    preprcss_pipes.loc[name] = FitTargetVariableTransf(X_, \n                                                       fishes_label_prepared, \n                                                       SetTransformer[name])","1834d5a7":"preprcss_pipes","c5be2997":"from sklearn.model_selection import cross_val_score\n\nlinear_regression = LinearRegression()\n        \nscores = cross_val_score(linear_regression, fishes_prepared['base'], fishes_label_prepared,\n                         scoring='neg_mean_squared_error', cv=4)\nrmse = np.sqrt(-scores)\nrmse = np.mean(rmse)\nprint('RMSE: ', rmse)","77f0dd6e":"R2 = base_model.score(fishes_prepared['base'], fishes_label_prepared)\nprint('R2: ', R2)","e7d24d30":"def FeatureCoef(X_, y_):\n    \"\"\"\n    Takes predictors and labels.\n    Fitting them to linear model.\n    Return Feature Coefficients from \n    the linear model.\n    \"\"\"\n    linear_regression = LinearRegression()\n    linear_regression.fit(X_, y_)\n    \n    linear_coef = linear_regression.coef_\n    # sorting and discarding last ellement\n    linear_coef = np.sort(linear_coef)[:-1]\n    # shifting numbers with step 1\n    # so last element now first\n    linear_coef = np.roll(linear_coef, 1)\n    # replace first element with inf\n    linear_coef[0] = -np.inf\n    return linear_coef","62ab59a5":"linear_coef = FeatureCoef(fishes_prepared['base'], \n                          fishes_label_prepared)\nlinear_coef","0428912d":"from sklearn.feature_selection import SelectFromModel\n\nsteps = [\n    ('select_from_model', SelectFromModel(LinearRegression())),\n    ('linear_regression', LinearRegression())\n]\n\nregressor_feature_selector = Pipeline(steps = steps)","4a7449f8":"from sklearn.model_selection import GridSearchCV\n\ngrid_params = [\n    {'select_from_model__threshold': linear_coef}\n]\n\ngrid_search = GridSearchCV(regressor_feature_selector, grid_params, \n                           scoring='neg_mean_squared_error',\n                           cv=4)\ngrid_search.fit(fishes_prepared['base'], fishes_label_prepared)","ed49ecdd":"score = grid_search.best_estimator_.score(fishes_prepared['base'], fishes_label_prepared)\nprint('Score: ', score)","a818f246":"grid_search.best_params_","80b2d976":"mse = grid_search.best_score_\nrmse = np.sqrt(-mse)\nprint('RMSE: ', rmse)","51755a3e":"transf_target_regr = TransformedTargetRegressor(regressor=LinearRegression(), \n                                                func=np.log, inverse_func=np.exp)\ntransf_target_regr.fit(fishes_prepared['base'], fishes_label_prepared)\n","641d9920":"y_test = strat_test['Weight']\ny_test.head()","fc4dd86d":"X_test = strat_test.drop('Weight', axis=1)\nX_test.shape","48762b4a":"sum(y_test == 0)","a8749d07":"# transfroming X_test\nX_test_prepared = column_transformer_base.transform(X_test)","6b905a96":"predictions_test = base_model.predict(X_test_prepared)","afb0cc5e":"r2 = base_model.score(X_test_prepared, y_test)\nmse = mean_squared_error(predictions_test, y_test)\nrmse = np.sqrt(mse)\nprint('R2: ', r2)\nprint('RMSE: ', rmse)","028a1a54":"predictions_test = transf_target_regr.predict(X_test_prepared)","eff2fd90":"r2 = transf_target_regr.score(X_test_prepared, y_test)\nmse = mean_squared_error(predictions_test, y_test)\nrmse = np.sqrt(mse)\nprint('R2: ', r2)\nprint('RMSE: ', rmse)","3d216c56":"pd.DataFrame([predictions_test[:10], y_test[:10].values], \n             index=['predictions', 'original'])","d1c65f6a":"import scipy.stats as stats\nconfidence = 0.95\nsquared_errors = (predictions_test - y_test) ** 2\n\nnp.sqrt(stats.t.interval(confidence, len(y_test)-1,\n                         loc=squared_errors.mean(),\n                         scale=stats.sem(squared_errors)))","e21b6e40":"`pipe_label`: preprocesses `Weight` by replacing zeros with Species mean weight, which stored in  `fishes_label_prepared`","829cd8ca":"Testing","c48eb79b":"Checking if there is any zero weights","f3c0c801":"Separating test dataset into:\n\n- `y_test`: labels\n\n- `X_test`: predictors","e5a15436":"Testing","572aae98":"Plotting `Species` Frequencies along with `Species` mean body measurements","ff53653e":"### Transformations ","1cc893ec":"## Preprocessing ","57a610ad":"Comparing predictions with original values","ef58274d":"## Modeling","fa203811":"Dropping new features. They will be added in other way.","dab9fb0b":"Cross Validating","51bad450":"Best coefficient is inf which means that all features combination produces max score","ac94f673":"\nDataSet source: https:\/\/www.kaggle.com\/aungpyaeap\/fish-market\n\nTask: Predict the Weight of Fish","9619a798":"Estimating confidence interval of best predictions","0b392e67":"### Categorical ","3cc30338":"<b>Full pipeline version 3<\/b>\n\n`pipe_num_minmax_sclr`: numerical pipeline. Calculates new numercial features and scale using MinMaxScaler","9ad9aad3":"### Weight","d7424505":"Correlation matrix","a1b74e1e":"Starting with building models based on matrices from 3 diffrent pipelines and comparing them.","05ead56d":"Custom transformer `FeaturesCalculator` calculates new features","b26eafe7":"<b>Full pipeline version 2<\/b>\n\n\n`column_transformer_base`: basic column_transformer. Calculates new numerical features and encodes `Species` using OneHotEncoder. Does not scale numerical features ","c0d9a66d":"While writting the notebook one of my goals was to practise `sklearn` library, thus for some tasks were created `sklearn` custom transformers insted of using `pandas` in few lines of code.","a000f43d":"Stratified Train Test split by 'Weight' ","a6f3c2ed":"<b>Full pipeline version 1<\/b>\n\n`pipe_num_stdsclr`: numerical pipeline. Calculates new numercial features and scale using StandardScaler","d9b78233":"## Beginning ","e6d1924f":"There were found that simple linear regression model produces negative weights, which of course not acceptable, so to solve the problem log of labels will be taken before fitting and after predictions placed into `np.exp` to get them back to the normal state. ","9b07dc8e":"As we can see below there is no diffrence between matrices from diffrent pipelines, so we will continue working only with matrix from `column_transformer_base`","2e2fbc15":"Trying OneHotEncoder for `Species`","f2f816c1":"In this section I'm creating, testing new transformers as well as trying existing ones separately","b9f32aa3":"Custom transformer `ZeroToNan` transformers zero values to Nan in given columns ","15c35895":"### Constructing pipelines ","f800ec43":"# Predicting fish weight","bd090c39":"`column_transformer_minmax_sclr`: Using `pipe_num_minmax_sclr` and OneHotEncoder to encode `Species`","5d236807":"`column_transformer_stdsclr`: Using `pipe_num_stdsclr` and OneHotEncoder to encode `Species` ","72bf4055":"Fitting matrix from `column_transformer_base` to linear model","90e9c017":"Custom transformer `ImputerSpeciesFeatureMean` replaces Nan in provided attributes with Species attribute mean","0e2d819e":"Searching for zero values in 'fishes'","b5adb1bb":"#### Validating on test set ","8b89609d":"Predicting with `np.log`","89bad788":"Estimating linear coefficients","51364672":"Calculating column means in `Species` groups","e959f461":"## Exploratry analysis ","7c72b68e":"Calculating new features and thier correlations with `Weight`","90b75879":"Fitting matrices from `column_transformer_stdsclr` and `column_transformer_minmaxsclr` to linear model","cbfd8f1f":"### Numerical ","aaa1d949":"Separating train dataset into:\n\n- `fishes_labels`: labels\n\n- `fishes`: predictors","bcef9046":"Predicting without `np.log`","b9b18449":"Using grid search to find best linear coefficient","2fc35a80":"Trying StandardScaler"}}