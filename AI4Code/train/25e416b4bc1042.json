{"cell_type":{"23f3ea1e":"code","bc8023db":"code","f99c43f2":"code","915bd066":"code","3dd2316a":"code","caaddf88":"code","afad8e95":"code","3884cbcc":"code","eab91299":"code","5481c580":"code","f6e2cde8":"code","5e9780dc":"code","3e7ee2af":"code","30adfd8b":"code","245837ef":"code","f9071777":"code","e74493e4":"code","e8b2f47d":"code","b5a1a72d":"code","05ffd6d5":"code","a9a63649":"code","9d2f765d":"markdown","65ce45be":"markdown","46fc3d88":"markdown","e668f2d4":"markdown","0e732416":"markdown","58472a4b":"markdown","2a6aa89f":"markdown","649f76cd":"markdown","f8466cf3":"markdown","2e406dbb":"markdown","ab9a5eff":"markdown"},"source":{"23f3ea1e":"!pip install beautifulsoup4\n!pip install geopy","bc8023db":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom tqdm.notebook import tqdm","f99c43f2":"import requests\nfrom bs4 import BeautifulSoup","915bd066":"url = \"https:\/\/www.thailandexhibition.com\/Event-77\/PRAM=2020_0_0_0_0&p=9\"\ncontent_covid = requests.get(url).content\ncontent_covid = content_covid.decode('utf-8')","3dd2316a":"soup = BeautifulSoup(content_covid, 'html.parser')","caaddf88":"title = soup.find_all('div', class_='text')\ntitle[0].text","afad8e95":"cate = soup.find_all('div', class_='cate')\ncate[0].text","3884cbcc":"venue = soup.find_all('div', class_='venue')\nvenue[0].text[1:].split('\\n')[0]","eab91299":"provice = soup.find_all('div', class_='provice')\nprovice[0].text[1:-1]","5481c580":"month = ['\u0e21\u0e01\u0e23\u0e32\u0e04\u0e21','\u0e01\u0e38\u0e21\u0e20\u0e32\u0e1e\u0e31\u0e19\u0e18\u0e4c','\u0e21\u0e35\u0e19\u0e32\u0e04\u0e21','\u0e40\u0e21\u0e29\u0e32\u0e22\u0e19','\u0e1e\u0e24\u0e29\u0e20\u0e32\u0e04\u0e21','\u0e21\u0e34\u0e16\u0e38\u0e19\u0e32\u0e22\u0e19','\u0e01\u0e23\u0e01\u0e0e\u0e32\u0e04\u0e21','\u0e2a\u0e34\u0e07\u0e2b\u0e32\u0e04\u0e21','\u0e01\u0e31\u0e19\u0e22\u0e32\u0e22\u0e19','\u0e15\u0e38\u0e25\u0e32\u0e04\u0e21','\u0e1e\u0e24\u0e28\u0e08\u0e34\u0e01\u0e32\u0e22\u0e19','\u0e18\u0e31\u0e19\u0e27\u0e32\u0e04\u0e21']\nyear = '2563'","f6e2cde8":"date = soup.find_all('div', class_='date')\n\ndef clean_date(date):\n    date = date.text.replace('\u0e07\u0e32\u0e19\u0e2a\u0e34\u0e49\u0e19\u0e2a\u0e38\u0e14\u0e40\u0e40\u0e25\u0e49\u0e27 ', '')[1:].split('-')\n    \n    #ds --> date start, de --> date end\n    if len(date) == 1: # has 1 date\n        ds = date[0]\n        de = date[0]\n    else: # has 2 date ex 1 - 3 \u0e21\u0e01\u0e23\u0e32\u0e04\u0e21\n        ds = date[0][:-1]\n        de = date[1][1:]\n        \n    if max([ds.find(m) for m in month]) == -1: # does not have month\n        month_index = max([de.find(m) for m in month])\n        ds += ' ' + de[month_index:]\n\n    if ds.find(year) == -1: # does not have year\n        ds += ' ' + year\n        \n    ds = ds.replace('2563', '2020').replace('2564', '2021')\n    de = de.replace('2563', '2020').replace('2564', '2021')\n    \n    # replace name of month to index ;ex \u0e21\u0e35\u0e19\u0e32\u0e04\u0e21 --> 3\n    for idx, m in enumerate(month):\n        if ds.find(m) != -1:\n            ms = ds.find(m)\n            me = ds.find(m)+len(m)\n            m_name = ds[ms:me]\n            ds = ds.replace(m_name, str(idx+1))\n\n        if de.find(m) != -1:\n            ms = de.find(m)\n            me = de.find(m)+len(m)\n            m_name = de[ms:me]\n            de = de.replace(m_name, str(idx+1))\n            \n    ds = pd.to_datetime(ds, format='%d %m %Y')\n    de = pd.to_datetime(de, format='%d %m %Y')\n    return ds, de\n\nclean_date(date[0])","5e9780dc":"event_name = []\nevent_date_start = []\nevent_date_end = []\nevent_cate = []\nevent_venue = []\nevent_province = []\nfor i in tqdm(range(1,72)):\n    url = f\"https:\/\/www.thailandexhibition.com\/Event-77\/PRAM=2020_0_0_0_0&p={i}\"\n    content_covid = requests.get(url).content\n    content_covid = content_covid.decode('utf-8')\n    \n    soup = BeautifulSoup(content_covid, 'html.parser')\n    \n    title = soup.find_all('div', class_='text')\n    cate = soup.find_all('div', class_='cate')\n    venue = soup.find_all('div', class_='venue')\n    provice = soup.find_all('div', class_='provice')\n    date = soup.find_all('div', class_='date')\n    \n    for name, cat, ve, prov, dt in zip(title, cate, venue, provice, date):\n        ds, de = clean_date(dt)\n        name = name.text.split('\\n')[0]\n        ve = ve.text[1:].split('\\n')[0]\n        prov = prov.text[1:-1]\n        event_name += [name]\n        event_date_start += [ds]\n        event_date_end += [de]\n        event_province += [prov]\n        event_cate += [cat.text]\n        event_venue += [ve]","3e7ee2af":"df_event = pd.DataFrame({'event_date_start': event_date_start,\n                         'event_date_end': event_date_end,\n                         'event_name': event_name,\n                         'event_cate': event_cate,\n                         'event_venue': event_venue,\n                         'event_prov': event_province})","30adfd8b":"df_event","245837ef":"from geopy.geocoders import OpenCage, Here, Nominatim\n\ncage = OpenCage('33515df789ae4eb4a058fd91f41dd5ba')\n\nhere = Here(apikey='DLUjEsgvBXlfPZfPXHGqHkcxVmxmf0lJuwEBu2D3JVo')\n\nnomina = Nominatim(user_agent=\"scraping_event\")","f9071777":"ltt_venue_cage = []\nlgt_venue_cage = []\n\nltt_venue_here = []\nlgt_venue_here = []\n\nltt_venue_nomina = []\nlgt_venue_nomina = []\n\nltt_prov = []\nlgt_prov = []\n\nfor address in tqdm(zip(df_event['event_venue'], df_event['event_prov']), total=df_event.shape[0]):\n    venue, prov = address\n    \n    loc_prov = nomina.geocode(prov)\n    \n    ltt_prov += [loc_prov.latitude if loc_prov != None else None]\n    lgt_prov += [loc_prov.longitude if loc_prov != None else None]\n    \n#     loc_venue_cage = cage.geocode(venue)\n#     loc_venue_here = here.geocode(venue)\n    loc_venue_nomina = nomina.geocode(venue)\n    \n#     ltt_venue_cage += [loc_venue_cage.latitude if loc_venue_cage != None else None]\n#     lgt_venue_cage += [loc_venue_cage.longitude if loc_venue_cage != None else None]\n    \n#     ltt_venue_here += [loc_venue_here.latitude if loc_venue_here != None else None]\n#     lgt_venue_here += [loc_venue_here.longitude if loc_venue_here != None else None]\n    \n    ltt_venue_nomina += [loc_venue_nomina.latitude if loc_venue_nomina != None else None]\n    lgt_venue_nomina += [loc_venue_nomina.longitude if loc_venue_nomina != None else None]","e74493e4":"# df_event['ltt_venue_cage'] = ltt_venue_cage\n# df_event['lgt_venue_cage'] = lgt_venue_cage\n\n# df_event['ltt_venue_here'] = ltt_venue_here\n# df_event['lgt_venue_here'] = lgt_venue_here\n\ndf_event['ltt_venue_nomina'] = ltt_venue_nomina\ndf_event['lgt_venue_nomina'] = lgt_venue_nomina\n\ndf_event['ltt_prov'] = ltt_prov\ndf_event['lgt_prov'] = lgt_prov","e8b2f47d":"df_event.to_csv('Event_2020_ltt_lgt_venue_cage_here_nomina.csv')","b5a1a72d":"df_event","05ffd6d5":"df_event","a9a63649":"plt.figure(figsize=(25,10))\nplt.xticks(fontsize=24)\nplt.yticks(fontsize=24)\nplt.title('Number of Event in 2020', fontsize=24)\neve_date = df_event.groupby('event_date_start').count()\nplt.plot(eve_date['event_name'])","9d2f765d":"# Get Latitude, Longtitude","65ce45be":"https:\/\/www.kaggle.com\/pollakrit\/scraping-event","46fc3d88":"# Scraping Data","e668f2d4":"# Download CSV","0e732416":"# Find Date start, Date end","58472a4b":"# Library","2a6aa89f":"# Scraping Data","649f76cd":"# Example of scraping","f8466cf3":"Data from https:\/\/www.thailandexhibition.com\/Event-77\/PRAM=2020_0_0_0_0","2e406dbb":"# Install Library","ab9a5eff":"# Kaggle Link"}}