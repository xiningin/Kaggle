{"cell_type":{"3a471004":"code","4e8cb90e":"code","fc24f827":"code","7b8d7f91":"code","0ba6e735":"code","1fe6bf26":"code","774ab3c0":"code","288ade05":"code","4862aac4":"code","14de4922":"code","f1cfec57":"code","e53b37cd":"code","6253ba14":"code","85cc8654":"code","2702b78d":"code","75b8f26a":"code","e2c6a051":"code","aee902a1":"code","8a61cc0d":"code","2f3b0a6c":"code","23507b14":"code","b798a644":"code","ac15f128":"code","a78f3db2":"code","ec8e2ae0":"code","181bd651":"code","16153dae":"code","b5747c30":"code","ddcd316f":"code","e350fea8":"markdown","14883c66":"markdown","dc3356ab":"markdown","44ef393f":"markdown","55aed1eb":"markdown","b5fc6a06":"markdown","4f7ff3dc":"markdown","3541f09b":"markdown","035f246a":"markdown","f26e5509":"markdown","e0bcf8f4":"markdown"},"source":{"3a471004":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2 #opencv library\nimport random\nimport h5py\n\nimport matplotlib.pyplot as plt  #plotting library\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom PIL import Image\nfrom IPython.display import Image, SVG\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport tensorflow\nfrom keras import layers, models, optimizers\nfrom keras.utils import np_utils\nfrom keras.utils.vis_utils import plot_model, model_to_dot\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nprint(os.listdir(\"..\/input\"))","4e8cb90e":"# Set Constant Values\nnum_train = 1000\nnum_test = 1000\nimg_width = 240\nimg_height = 240\nbatch_size = 64\nnb_epochs = 12","fc24f827":"# Define paths\ntrain_path = '..\/input\/state-farm-distracted-driver-detection\/imgs\/train'\ntest_path = '..\/input\/state-farm-distracted-driver-detection\/imgs\/test\/'\nclasses = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\ndriver_img_list = '..\/input\/state-farm-distracted-driver-detection\/driver_imgs_list.csv'\n# read image csv file\nimg_list = pd.read_csv(driver_img_list)","7b8d7f91":"for category in classes:\n    i=0\n    path = os.path.join(train_path,category)\n    for img in os.listdir(path):\n           i+=1\n    print('Numer of instances of class {} in Train: {}'.format(category, i))\n\ni=0\nfor img in os.listdir(test_path):\n    i+=1\nprint('\\nTotal number of images in Test: ', i)","0ba6e735":"nf = img_list['classname'].value_counts(sort=False)\nlabels = img_list['classname'].value_counts(sort=False).index.tolist()\ny = np.array(nf)\nwidth = 1\/1.5\nN = len(y)\nx = range(N)\n\nfig = plt.figure(figsize=(20,15))\nay = fig.add_subplot(211)\nplt.xticks(x, labels, size=15)\nplt.yticks(size=15)\nay.bar(x, y, width, color=\"blue\")\nplt.title('Class Distribution',size=25)\nplt.xlabel('Class Name',size=15)\nplt.ylabel('Count',size=15)\nplt.show()","1fe6bf26":"# explanation for each of the classes\nclass_dict = {\n    'c0': 'hands on the wheel',\n    'c1': 'mobile in right hand',\n    'c2': 'talking on the phone with right hand',\n    'c3': \"mobile in left hand\",\n    'c4': 'talking on the phone with left hand',\n    'c5': 'touching at the dash',\n    'c6': 'drinking',\n    'c7': 'reaching behind',\n    'c8': 'touching the head',\n    'c9': 'looking to the side'\n}","774ab3c0":"# Sample Image for each class\nfor i in classes:\n    path = os.path.join(train_path, i)\n    print(\"Class \", i, ': ', class_dict[i])\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n        plt.imshow(img_array, cmap='gray')\n        plt.show()\n        print('\\n')\n        break","288ade05":"training_data = []\ntesting_data = []","4862aac4":"def create_training_data():\n    for category in classes:\n        i=0\n        path = os.path.join(train_path,category)\n        class_num = classes.index(category)\n        for img in os.listdir(path):\n            # return num_train instances of each class\n            if i < num_train:\n                img_array = cv2.imread(os.path.join(path,img))\n                # resize image\n                new_img = cv2.resize(img_array,(img_width,img_height), cv2.INTER_LINEAR)\n                # get image and class type\n                training_data.append([new_img, class_num])\n                i+=1\n    return training_data","14de4922":"def create_testing_data():\n    i=0\n    for img in os.listdir(test_path):\n        # return num_test test images\n        if i < num_test:\n            img_array = cv2.imread(os.path.join(test_path,img))\n            new_img = cv2.resize(img_array,(img_width,img_height), cv2.INTER_LINEAR)\n            testing_data.append([img, new_img])\n            i+=1\n    return testing_data","f1cfec57":"training_data = create_training_data()\ntesting_data = create_testing_data()","e53b37cd":"# Shuffling data\nrandom.shuffle(training_data)\nx, y = list(), list()\nfor features, label in training_data:\n    x.append(features)\n    y.append(label)","6253ba14":"y[0:20]","85cc8654":"Y = np_utils.to_categorical(y, num_classes=10)\nY[0:10]","2702b78d":"# Reshaping the image to fit the batch size (batch count,w,h,c)\nX = np.array(x).reshape(-1,img_width,img_height,1)\nX[0].shape","75b8f26a":"X_train,X_test,y_train,y_test = train_test_split(X, Y,test_size=0.2,random_state=123)","e2c6a051":"print(\"Shape of train images is:\", X_train.shape)\nprint(\"Shape of validation images is:\", X_test.shape)\nprint(\"Shape of labels is:\", y_train.shape)\nprint(\"Shape of labels is:\", y_test.shape)","aee902a1":"# build the model\nmodel = Sequential()\n\n## CNN 1\nmodel.add(Conv2D(64,(3,3),activation='relu',input_shape=(img_width,img_height,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.2))\n\n## CNN 2\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.1))\n\n## CNN 3\nmodel.add(Conv2D(256,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.1))\n\n## CNN 3\nmodel.add(Conv2D(512,(5,5),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.1))\n\n## Dense & Output\nmodel.add(Flatten())\nmodel.add(Dense(units = 256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(units = 128,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation='softmax'))","8a61cc0d":"model.summary()","2f3b0a6c":"plot_model(model,show_shapes=True)\nImage(filename = 'model.png')","23507b14":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","b798a644":"callbacks = [EarlyStopping(monitor='val_acc',patience=5), ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True, verbose=0, mode='auto'),]\nhistory = model.fit(X_train,y_train,batch_size=batch_size,epochs=nb_epochs,verbose=1,validation_data=(X_test,y_test),callbacks=callbacks)","ac15f128":"import matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\n\n\nplt.figure(figsize=(7, 5))\nplt.plot(loss)\nplt.plot(val_loss)\nplt.xlabel('Epochs')\nplt.title('Training and validation loss')\nplt.legend(['Train Loss','Test Loss'], loc='best')\nplt.savefig('losses.png')\n\nplt.figure(figsize=(7, 5))\nplt.plot(accuracy)\nplt.plot(val_accuracy)\nplt.xlabel('Epochs')\nplt.title('Training and validation Accuracy')\nplt.legend(['Train Acc','Test Acc'], loc='best')\nplt.savefig('accuracy.png')","a78f3db2":"y_val_pred = []\ny_val_actual = []\nfor n in range(len(X_test)):\n    preds = model.predict(np.array([X_test[n]]))\n    y_val_pred.append(np.argmax(preds[0]))\n    y_val_actual.append(np.nonzero(y_test[n])[0][0])","ec8e2ae0":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","181bd651":"# Confusion Matrix\ndata = {'y_Actual':    y_val_actual,\n        'y_Predicted': y_val_pred}\ndf = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\nconfusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n\nplt.figure(figsize=(10,10))\nsns.heatmap(confusion_matrix, annot=True)\nplt.show()","16153dae":"print(classification_report(y_val_actual, y_val_pred, target_names=class_dict.keys()))","b5747c30":"y_pred = []\nfor n in range(num_test):\n    test_img = np.array(testing_data[n][1]).reshape(-1,img_width,img_height,1)\n    preds = model.predict(test_img)\n    class_idx = np.argmax(preds[0])\n    y_pred.append(class_idx)","ddcd316f":"# Sample Predictions\nfor n in range(10):\n    img_array = cv2.imread(os.path.join(test_path, testing_data[n][0]), cv2.IMREAD_COLOR)\n    plt.imshow(img_array, cmap='gray')\n    title_val = y_pred[n]\n    plt.title('Predicted c{}: {}'.format(title_val, class_dict['c{}'.format(title_val)]))\n    plt.show()\n    print('\\n')","e350fea8":"#### Predict on Validation Data","14883c66":"## Exploratory Analysis","dc3356ab":"### Creating model architecture","44ef393f":"### Compile and fit model","55aed1eb":"#### Convert y to dummy variables","b5fc6a06":"### Split into Train\/test sets using train_test_split","4f7ff3dc":"### Predict on Testing Data","3541f09b":"## Predict and Evaluate Model","035f246a":"# State Farm Distracted Driver Detection","f26e5509":"## Create Training and Testing Data","e0bcf8f4":"#### Reshape"}}