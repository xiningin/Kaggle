{"cell_type":{"51abe647":"code","be3f11f1":"code","5c101bbf":"code","3dbf3728":"code","1b453649":"code","7086e98c":"code","330b9afb":"code","3eefa3aa":"code","b0f1b49e":"code","eb900ec5":"code","bd089fa6":"code","98fca18b":"code","6be42aee":"code","5152d4c6":"code","9b78e5a0":"code","6e8c7dcc":"code","59a3ec2f":"code","6d9e56df":"code","724c4076":"code","2a3bfe5c":"code","dbeb68b5":"code","1300802a":"code","44f55aa7":"code","99ca5fca":"code","77f6e739":"code","1c04a51f":"code","ca63e254":"markdown","d9d9448c":"markdown","8833f15b":"markdown","db3444e3":"markdown","8f25155d":"markdown"},"source":{"51abe647":"import pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom tensorflow import feature_column\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import DenseFeatures, Dense, Dropout\n\n\nfrom sklearn.model_selection import train_test_split","be3f11f1":"def missing(df):\n    df_missing = pd.DataFrame(df.isna().sum().sort_values(ascending = False), columns = ['missing_count'])\n    df_missing['missing_share'] = df_missing.missing_count \/ len(df)\n    return df_missing","5c101bbf":"train_df = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv')\n\ntrain_df.head(5)","3dbf3728":"len(train_df)","1b453649":"missing(train_df)","7086e98c":"# Drop all train columns with any missing values\ntrain_df = train_df.dropna(axis=1)","330b9afb":"exclude_columns = test_df.columns[test_df.isna().any()].tolist() + ['Id', 'SalePrice']","3eefa3aa":"all_numeric_columns = list(set(train_df._get_numeric_data().columns) - set(exclude_columns))\nall_categorical_columns = list(set(train_df.columns) - set(all_numeric_columns) - set(exclude_columns))","b0f1b49e":"all_numeric_columns","eb900ec5":"all_categorical_columns","bd089fa6":"numeric_features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\ncategorical_features = ['SaleType', 'SaleCondition', 'LotShape', 'Neighborhood', 'ExterQual', 'ExterCond', 'HeatingQC', 'CentralAir']","98fca18b":"features = numeric_features + categorical_features\n\nX = train_df[features]\ny = train_df.SalePrice\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1, test_size=0.1)\nprint(len(train_X), 'train examples')\nprint(len(val_X), 'validation examples')","6be42aee":"feature_columns = []\nfor header in numeric_features:\n    feature_columns.append(feature_column.numeric_column(header))\n    \nfor header in categorical_features:\n    categorical = feature_column.categorical_column_with_vocabulary_list(header, train_df[header].unique())\n    feature_columns.append(feature_column.indicator_column(categorical))","5152d4c6":"kernel_initializer = tf.keras.initializers.GlorotNormal()\nactivation='relu'\n\nmodel = Sequential()\n\n# Input Layer\nmodel.add(DenseFeatures(feature_columns))\n\n# Hidden Layers\nmodel.add(Dense(16, kernel_initializer=kernel_initializer, activation=activation))\n#model.add(Dropout(0.2))\nmodel.add(Dense(8, kernel_initializer=kernel_initializer, activation=activation))\n#model.add(Dropout(0.2))\nmodel.add(Dense(4, kernel_initializer=kernel_initializer, activation=activation))\n# Output Layer\nmodel.add(Dense(1, kernel_initializer=kernel_initializer, activation=activation))\n\nmodel.compile(\n  loss=tf.keras.losses.MeanAbsoluteError(), \n  optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9), \n  metrics=[tf.keras.metrics.MeanAbsoluteError()]\n)","9b78e5a0":"# Convert Pandas Dataframe into tf.data dataset\ndef df_to_ds(X, y, shuffle=True, batch_size=32):\n    ds = tf.data.Dataset.from_tensor_slices((dict(X.copy()), y))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(X))\n    return ds.batch(batch_size)","6e8c7dcc":"train_ds = df_to_ds(train_X, train_y)\nval_ds = df_to_ds(val_X, val_y)","59a3ec2f":"history = model.fit(train_ds,\n          validation_data=val_ds,\n          callbacks=[\n            tf.keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error', \n                                             min_delta=200, \n                                             patience=30, \n                                             verbose=1, \n                                             restore_best_weights=True)\n          ],\n          epochs=300,\n          verbose=0)","6d9e56df":"loss, mae = model.evaluate(val_ds)\nprint(\"Validation Loss:\", loss)\nprint(\"Validation MAE:\", mae)","724c4076":"plt.ylabel('MAE')\nplt.xlabel('epoch')\nplt.plot(history.history['mean_absolute_error'])\nplt.plot(history.history['val_mean_absolute_error'])\nplt.legend(['Train', 'Validation'])\nplt.show()\n","2a3bfe5c":"test_df.dtypes","dbeb68b5":"test_df[all_numeric_columns] = test_df[all_numeric_columns].astype(int)","1300802a":"test_X = test_df[features]\nmissing(test_X)","44f55aa7":"test_X[test_X.SaleType.isna()]\ntest_X.loc[1029, 'SaleType'] = \"Oth\"\nmissing(test_X)","99ca5fca":"test_y = pd.DataFrame(np.zeros(shape=(len(test_X),1)), columns=[\"SalePrice\"])\ntest_ds = df_to_ds(test_X, test_y)","77f6e739":"test_preds = model.predict(test_ds)\ntest_preds","1c04a51f":"flatten = lambda l: [item for sublist in l for item in sublist]\noutput = pd.DataFrame({'Id': test_df.Id,\n                      'SalePrice': pd.Series(flatten(test_preds))})\noutput.to_csv('submission.csv', index=False)","ca63e254":"# Test","d9d9448c":"# Prepare","8833f15b":"# Model","db3444e3":"# Explore","8f25155d":"# Introduction\n\nThis works aims to do as little data cleaning and feature engineering as possible and leave all the hard work for the deep neural network model.\n* columns with any missing values are just dropped"}}