{"cell_type":{"4112f854":"code","9e5b07ce":"code","790fc859":"code","5f49c50a":"code","8e8b1eec":"code","ec0b5b48":"code","6660c657":"code","f9dd436e":"code","2c822b06":"code","e76dbbc8":"code","9faf50bb":"code","ac9f76ac":"code","f94a0abe":"code","b401c8b6":"code","e587594f":"code","daec4940":"code","daf4d05e":"code","8c30fcfe":"code","ac03ee0b":"code","b0c1ee67":"code","00954e57":"code","76799b72":"code","c26bbf98":"code","647e249a":"code","24d54753":"code","ab17e521":"code","1637cc38":"code","dd333952":"code","92f8112a":"code","4b529f23":"code","85ad80f5":"code","d57dfc01":"code","ae61c35b":"code","ebeebbfc":"code","a7abcc2d":"code","f380ebac":"code","eaf1ec08":"code","48307014":"code","a99bd719":"code","cae5466b":"code","e89ad086":"code","41154b72":"code","1e2281d3":"code","e6e031fb":"code","722c1a06":"code","89d3de38":"code","5684dc40":"code","bf1b07e3":"code","9f853bb9":"code","e75eb34c":"code","aca2d244":"code","a416f21e":"code","ff595d62":"code","b77538b5":"code","87e7b5e9":"code","6a8e33e3":"code","9d8a86e4":"code","e3e014ad":"code","1977804a":"code","b8ac9a34":"code","6c3c94fd":"code","aebd3230":"code","3ff7ce78":"code","1c33dff6":"code","f1e713c9":"code","3d2259c9":"code","92540a18":"code","ed80b63f":"code","d2f8d0e9":"code","354efbdd":"code","88534abe":"code","c9b03c56":"code","8cc8e5e4":"code","0ad2bbec":"code","06f5983f":"code","e00c10c3":"code","411fbc3d":"code","f0a8ab0b":"code","de0341ae":"code","87e09565":"code","8b5c2708":"code","0f9c7c75":"code","645fd9ae":"code","964dc07f":"code","cfd45000":"code","80e1bf6f":"code","e0c89ecc":"markdown","992ebad1":"markdown","418e7206":"markdown","9f054b79":"markdown","f9c8f6d3":"markdown","8ded7193":"markdown","2d6ba096":"markdown","b707b075":"markdown","bfc797cf":"markdown","b45ac7c9":"markdown","b5c38b8c":"markdown","a576a7b1":"markdown","53ebd6ce":"markdown","bd355172":"markdown","dbd7f0ad":"markdown","e50bd76e":"markdown","4d00627d":"markdown"},"source":{"4112f854":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e5b07ce":"data=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')\ndata","790fc859":"data.info()","5f49c50a":"data['SibSp'].value_counts()","8e8b1eec":"data['Fare'].describe()","ec0b5b48":"ax=data['Age'].hist(bins=20,density=True,stacked=True,alpha=0.6)\ndata['Age'].plot(kind='density')\nax.set(xlabel='Age')\nplt.show()","6660c657":"data['Age'].fillna(data['Age'].median(),inplace=True)","f9dd436e":"data.drop('Cabin',axis=1,inplace=True)","2c822b06":"data['Embarked'].value_counts()","e76dbbc8":"data['Embarked'].fillna('S',inplace=True)","9faf50bb":"data.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)","ac9f76ac":"data['Pclass']=data['Pclass'].astype(str)","f94a0abe":"data['Accompanied']=0","b401c8b6":"for i in range(data.shape[0]):\n    if (data.loc[i,'SibSp']+data.loc[i,'Parch'])>0:\n        data.loc[i,'Accompanied']=1","e587594f":"data['Accompanied']=data['Accompanied'].astype(str)","daec4940":"data","daf4d05e":"data.drop(['SibSp','Parch'],axis=1,inplace=True)","8c30fcfe":"data","ac03ee0b":"data=pd.get_dummies(data)","b0c1ee67":"data","00954e57":"#data.drop(['Pclass_1','Sex_female','Embarked_C','Accompanied_0'],axis=1,inplace=True)","76799b72":"data","c26bbf98":"X=data[['Age','Fare','Pclass_1','Pclass_2','Pclass_3','Sex_female','Sex_male','Embarked_C','Embarked_Q','Embarked_S','Accompanied_0','Accompanied_1']]\ny=data['Survived']","647e249a":"test['Fare'].fillna(test['Fare'].median(),inplace=True)\ntest['Age'].fillna(data['Age'].median(),inplace=True)\ntest.drop('Cabin',axis=1,inplace=True)\ntest['Embarked'].fillna('S',inplace=True)\ntest.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\ntest['Pclass']=test['Pclass'].astype(str)\ntest['Accompanied']=0\nfor i in range(test.shape[0]):\n    if (test.loc[i,'SibSp']+test.loc[i,'Parch'])>0:\n        test.loc[i,'Accompanied']=1\ntest['Accompanied']=test['Accompanied'].astype(str)\ntest.drop(['SibSp','Parch'],axis=1,inplace=True)\ntest=pd.get_dummies(test)","24d54753":"from typing import Tuple, Union, Dict, List, Optional\ndef prepare_for_light_gbm(\n    data, target_col, \n    drop_cols) -> Tuple[lgb.Dataset, pd.Series,pd.Series, pd.DataFrame]:\n    \"\"\"\n    Prepare a dataframe containing processed titanic data for modelling.\n\n    Creates a lbg.Dataset using the columns as specified.\n\n    :param data: Dataframe to process.\n    :param target_col: The column containing the labels\/targets\n    :param id_col:\n    :param drop_cols: List of columns to drop.\n    :return: prepared lbb.Dataset.\n    \"\"\"\n    # Drop target column\n    if target_col is not None:\n        labels = data[target_col]\n        drop_cols = drop_cols + [target_col]\n    else:\n        labels = []\n\n\n    if drop_cols is not None:\n        data = data.drop(drop_cols, axis=1)\n\n    # Create LGB mats\n    lgb_data = lgb.Dataset(data, label=labels, free_raw_data=False,\n                           feature_name=list(data.columns), \n                           categorical_feature='auto')\n\n    return lgb_data, labels, data","ab17e521":"from sklearn.model_selection import GridSearchCV\nfrom xgboost.sklearn import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn.ensemble import GradientBoostingClassifier as gbr","1637cc38":"xgb=XGBClassifier(learning_rate=0.1,n_estimators=500,max_depth=5,min_child_weight=1,gamma=0,\nsubsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',seed=0)","dd333952":"#help(XGBClassifier)","92f8112a":"param_test = {'n_estimators':range(400,900,100)}","4b529f23":"gs = GridSearchCV(estimator = xgb,param_grid = param_test, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)","85ad80f5":"gs.fit(X,y)","d57dfc01":"print(gs.best_params_,gs.best_score_)\nprint(gs.cv_results_['mean_test_score'])","ae61c35b":"param_test = {'max_depth':range(3,10,2),'min_child_weight':range(1,6,2)}","ebeebbfc":"gs = GridSearchCV(estimator = xgb,param_grid = param_test, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)","a7abcc2d":"gs.fit(X,y)","f380ebac":"print(gs.best_params_,gs.best_score_)\nprint(gs.cv_results_['mean_test_score'])","eaf1ec08":"xgb=XGBClassifier(learning_rate=0.1,n_estimators=500,max_depth=5,min_child_weight=5,gamma=0,\nsubsample=0.8,colsample_bytree=0.8,objective='reg:logistic',seed=0)","48307014":"param_test={'gamma':[i\/10.0 for i in range(0,5)]}","a99bd719":"gs = GridSearchCV(estimator = xgb,param_grid = param_test, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)","cae5466b":"gs.fit(X,y)","e89ad086":"print(gs.best_params_,gs.best_score_)\nprint(gs.cv_results_['mean_test_score'])","41154b72":"param_test = {\n 'subsample':[i\/10.0 for i in range(6,10)],\n 'colsample_bytree':[i\/10.0 for i in range(6,10)]\n}","1e2281d3":"xgb=XGBClassifier(learning_rate=0.1,n_estimators=500,max_depth=5,min_child_weight=5,gamma=0.3,\nsubsample=0.8,colsample_bytree=0.8,objective='reg:logistic',seed=0)","e6e031fb":"gs = GridSearchCV(estimator = xgb,param_grid = param_test, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)","722c1a06":"gs.fit(X,y)","89d3de38":"print(gs.best_params_,gs.best_score_)\nprint(gs.cv_results_['mean_test_score'])","5684dc40":"xgb=XGBClassifier(learning_rate=0.1,n_estimators=500,max_depth=5,min_child_weight=5,gamma=0.3,\nsubsample=0.7,colsample_bytree=0.8,objective='reg:logistic',seed=0)","bf1b07e3":"param_test = {\n 'reg_lambda':[1e-5, 1e-2, 0.1, 1, 10]\n}","9f853bb9":"gs = GridSearchCV(estimator = xgb,param_grid = param_test, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)","e75eb34c":"gs.fit(X,y)","aca2d244":"print(gs.best_params_,gs.best_score_)\nprint(gs.cv_results_['mean_test_score'])","a416f21e":"xgb=XGBClassifier(learning_rate=0.1,n_estimators=500,max_depth=5,min_child_weight=5,gamma=0.3,\nsubsample=0.7,colsample_bytree=0.8,reg_lambda=0.1,objective='reg:logistic',seed=0)","ff595d62":"xgb.fit(X,y)","b77538b5":"y_predict_xgb=xgb.predict(test)\ny_predict_xgb","87e7b5e9":"params = {'boosting_type': 'gbdt', 'max_depth': -1, 'objective': 'binary', \n              'num_leaves': 64, 'learning_rate': 0.05, 'max_bin': 512, \n              'subsample_for_bin': 200, 'subsample': 1, 'subsample_freq': 1,\n              'colsample_bytree': 0.8, 'reg_alpha': 5, 'reg_lambda': 10, \n              'min_split_gain': 0.5, 'min_child_weight': 1, \n              'min_child_samples': 5, 'scale_pos_weight': 1, 'num_class': 1, \n              'metric': 'binary_error'}","6a8e33e3":"grid_params = {'learning_rate': [0.01], 'n_estimators': [8, 24],\n                   'num_leaves': [6, 8, 12, 16], 'boosting_type': ['gbdt'], \n                   'objective': ['binary'], 'seed': [500],\n                   'colsample_bytree': [0.65, 0.75, 0.8], \n                   'subsample': [0.7, 0.75], 'reg_alpha': [1, 2, 6],\n                   'reg_lambda': [1, 2, 6]}","9d8a86e4":"mod = lgb.LGBMClassifier(params)\nmod.get_params()","e3e014ad":"grid = GridSearchCV(mod, param_grid=grid_params, verbose=1, cv=5, n_jobs=-1)","1977804a":"grid.fit(X, y)","b8ac9a34":"print(grid.best_score_)\nprint(grid.best_params_)","6c3c94fd":"best_params = {k: grid.best_params_.get(k, v) for k, v in params.items()}\nbest_params['verbosity'] = -1\nbest_params","aebd3230":"from sklearn.model_selection import train_test_split\nk = 5\nvalid_preds, train_preds, test_preds = 0, 0, 0\nfor m in range(k):\n    print('Fitting model', m)\n\n        # Prepare the data set for fold\n    train_split_df, valid_split_df = train_test_split(data, test_size=0.4)\n    \n    (train_lgb_dataset, train_labels,\n        train_split_df) = prepare_for_light_gbm(\n        train_split_df, target_col='Survived',\n        drop_cols=[])\n    \n    (valid_lgb_dataset, valid_labels,\n        valid_split_df) = prepare_for_light_gbm(\n    valid_split_df, target_col='Survived',\n    drop_cols=[])\n    \n    \n        # Train\n    gbm = lgb.train(best_params, train_lgb_dataset, num_boost_round=100000,\n                    valid_sets=[train_lgb_dataset, valid_lgb_dataset],\n                    early_stopping_rounds=50, verbose_eval=50)\n\n        # Plot importance\n    lgb.plot_importance(gbm)\n    plt.show()\n    \n    valid_preds += gbm.predict(valid_split_df, \n                                   num_iteration=gbm.best_iteration) \/ k\n    train_preds += gbm.predict(train_split_df, \n                                   num_iteration=gbm.best_iteration) \/ k\n    test_preds += gbm.predict(test, num_iteration=gbm.best_iteration) \/ k","3ff7ce78":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import  metrics","1c33dff6":"gbm = GradientBoostingClassifier(random_state=0)\ngbm.fit(X,y)\ny_predict = gbm.predict(X)\ny_predictprob = gbm.predict_proba(X)[:,1]\nprint (\"Accuracy : %.4g\" % metrics.accuracy_score(y.values, y_predict))\nprint (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y, y_predictprob))","f1e713c9":"gbm=GradientBoostingClassifier(learning_rate=0.1, min_samples_split=10,\n                                  min_samples_leaf=3,max_depth=8,max_features='sqrt', subsample=0.8,random_state=0)","3d2259c9":"param_test = {'n_estimators':range(20,81,10)}\ngsearch1 = GridSearchCV(estimator=gbm, param_grid = param_test, scoring='roc_auc',\n                        iid=False,cv=5)","92540a18":"gsearch1.fit(X,y)","ed80b63f":"print(gsearch1.best_params_, gsearch1.best_score_)\nprint(gsearch1.cv_results_['mean_test_score'])","d2f8d0e9":"gbm=GradientBoostingClassifier(learning_rate=0.1, n_estimators=30,min_samples_split=10,\n                                  min_samples_leaf=3,max_depth=8,max_features='sqrt', subsample=0.8,random_state=0)","354efbdd":"param_test = {'max_depth':range(3,14,2), 'min_samples_split':range(5,30,5)}\ngsearch2 = GridSearchCV(estimator = gbm, \n   param_grid = param_test, scoring='roc_auc',iid=False, cv=5)","88534abe":"gsearch2.fit(X,y)","c9b03c56":"print(gsearch2.best_params_,gsearch2.best_score_)","8cc8e5e4":"gbm=GradientBoostingClassifier(learning_rate=0.1, n_estimators=30,min_samples_split=20,\n                                  min_samples_leaf=3,max_depth=13,max_features='sqrt', subsample=0.8,random_state=0)","0ad2bbec":"param_test = {'max_depth':range(13,17), 'min_samples_leaf':range(3,10)}\ngsearch3 = GridSearchCV(estimator = gbm, \n                       param_grid = param_test, scoring='roc_auc',iid=False, cv=5)","06f5983f":"gsearch3.fit(X,y)","e00c10c3":"print(gsearch3.best_params_,gsearch3.best_score_)","411fbc3d":"param_test = {'max_features':range(6,13,1)}\ngsearch4 = GridSearchCV(estimator = gbm, \n                       param_grid = param_test, scoring='roc_auc',iid=False, cv=5)","f0a8ab0b":"gsearch4.fit(X,y)","de0341ae":"print(gsearch4.best_params_,gsearch4.best_score_)\nprint(gsearch4.cv_results_['mean_test_score'])","87e09565":"gbm=GradientBoostingClassifier(learning_rate=0.02, n_estimators=30,min_samples_split=20,\n                                  min_samples_leaf=3,max_depth=13,max_features=6, subsample=0.8,random_state=0)","8b5c2708":"gbm.fit(X,y)","0f9c7c75":"y_predict_gbdt=gbm.predict(test)","645fd9ae":"y_predict_gbdt","964dc07f":"submission_lgb = pd.DataFrame()\nsubmission_lgb['PassengerId']=np.arange(892,1310)\nsubmission_lgb['Survived'] = np.int32(test_preds > 0.5)\nsubmission_lgb.set_index(\"PassengerId\",inplace=True)\nsubmission_lgb.to_csv('submission_lgb.csv')","cfd45000":"submission_xgb = pd.DataFrame()\nsubmission_xgb['PassengerId']=np.arange(892,1310)\nsubmission_xgb['Survived'] = y_predict_xgb\nsubmission_xgb.set_index(\"PassengerId\",inplace=True)\nsubmission_xgb.to_csv('submission_xgb.csv')","80e1bf6f":"submission_gbdt = pd.DataFrame()\nsubmission_gbdt['PassengerId']=np.arange(892,1310)\nsubmission_gbdt['Survived'] = y_predict_gbdt\nsubmission_gbdt.set_index(\"PassengerId\",inplace=True)\nsubmission_gbdt.to_csv('submission_gbdt.csv')","e0c89ecc":"## XGBoost","992ebad1":"## LightGBM","418e7206":"Convert the type of column 'Pclass' from float64 to string.","9f054b79":"Score:0.77272","f9c8f6d3":"Find features with missing values.","8ded7193":"Drop the column 'Cabin' because most values are missing.","2d6ba096":"Drop column 'PassengerId','Name','Ticket' because of the difficulty of processing them.","b707b075":"## GBDT","bfc797cf":"Fill the missing values in column 'Embarked' with the mode.","b45ac7c9":"One-Hot Encoding","b5c38b8c":"GridSearch the hyper-paramets.","a576a7b1":"Create the feature 'Accompanied' to replace 'SibSp' and 'Parch'.","53ebd6ce":"## Preprocessing","bd355172":"Fill the missing values in column 'Age' with the median of age.","dbd7f0ad":"Score:0.76794","e50bd76e":"Score:0.77511","4d00627d":"## Read Data"}}