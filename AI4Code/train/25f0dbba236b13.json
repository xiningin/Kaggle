{"cell_type":{"97dfc263":"code","1fe59e10":"code","c8631571":"code","91bf1d22":"code","951da7f2":"code","765094c0":"code","5f1e8691":"code","7ef08a4d":"code","c3dc72c2":"code","85db8c21":"code","8d4a3a6f":"code","1c096530":"code","83093246":"code","669978e5":"code","d81c1882":"code","2705e538":"code","61f81ed6":"code","ebf4f58b":"code","3b991cdf":"code","5fc81fd0":"code","1091fa76":"code","aed5664c":"code","aee7dc72":"code","31673fa1":"code","f35da53b":"code","17155bfa":"code","b481cb4c":"code","769a62cb":"code","4c6c8620":"code","1bf9b712":"code","4583a813":"code","a1b39786":"code","aa469e21":"code","46669c30":"code","47d632cc":"code","8a61fc80":"code","fcf0a262":"code","eaecf257":"code","e229b34b":"code","46f00df3":"code","ecff530b":"code","b0b32e22":"code","d54f5e7d":"code","4b134c3a":"code","2e525e31":"code","cedd2746":"code","a87b0754":"code","2443ecb3":"code","4bfb67e2":"code","52801868":"code","c232127a":"code","82de1085":"code","5390a232":"code","ab12c233":"code","a8ea5978":"code","fb0fbc67":"code","445608ad":"code","a75291b6":"code","2391e770":"code","ca14195d":"markdown","66b81a91":"markdown","b9a5da97":"markdown","154ec7db":"markdown","212f0b28":"markdown","6c457920":"markdown","95efa747":"markdown","36ba009d":"markdown","fadbbc1c":"markdown","2f6a9c45":"markdown","afda8798":"markdown","24381081":"markdown","eab88a01":"markdown","24b56068":"markdown","572e155e":"markdown","105bd491":"markdown","014761aa":"markdown","8fecaffa":"markdown","8bd9a471":"markdown","4997265a":"markdown","94738eeb":"markdown","43bf3b2d":"markdown","b1cbc2d9":"markdown","ea552f77":"markdown","ec37cf21":"markdown","3b0f2f78":"markdown","4e0ebd1d":"markdown","56788f9b":"markdown","641f642d":"markdown","a8840ef8":"markdown","2f7908c3":"markdown","516a6abf":"markdown","c5295902":"markdown","feaa44e3":"markdown","2c0203c0":"markdown","7a0d4e81":"markdown","c4c0aba4":"markdown","879e0bb4":"markdown","187f62d7":"markdown","bd9ef973":"markdown","8ccfcebd":"markdown","936d3158":"markdown","22239c86":"markdown","af874df1":"markdown","7dadb0c3":"markdown","d376ba36":"markdown","4ba71da7":"markdown","f308bb17":"markdown","405db2f5":"markdown","c053f1c1":"markdown","2a8266e6":"markdown","36810369":"markdown","932ca6f0":"markdown","41cfef0e":"markdown","4b824023":"markdown"},"source":{"97dfc263":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport seaborn as sns\nfrom pandas import DataFrame,Series\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn import metrics, svm\nfrom sklearn.linear_model           import LinearRegression\nfrom sklearn.linear_model           import LogisticRegression\nfrom sklearn.tree                   import DecisionTreeClassifier\nfrom sklearn.neighbors              import KNeighborsClassifier\nfrom sklearn.discriminant_analysis  import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes            import GaussianNB\nfrom sklearn.svm                    import SVC\nfrom sklearn import preprocessing\nfrom sklearn import utils\n\ndata = pd.read_csv('..\/input\/TestMissingData.csv')\ndata.head(10)","1fe59e10":"# Check the current values\ndata = data.drop(['City'], axis = 1)\ndata.describe()","c8631571":"total = data.isnull().sum().sort_values(ascending=False)\npercent =(data.isnull().sum()\/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","91bf1d22":"dataFillMean = data.fillna(data.mean())\ndataFillMean.describe()","951da7f2":"def CovSimilarity(data):\n    cov = data.corr()\n    return cov\n    \nCovSimilarity(dataFillMean)","765094c0":"from matplotlib.collections import EllipseCollection\ndef plot_corr_ellipses(data, ax=None, **kwargs):\n    \n    M = np.array(data)\n    if not M.ndim == 2:\n        raise ValueError('data must be a 2D array')\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, subplot_kw={'aspect':'equal'})\n        ax.set_xlim(-0.5, M.shape[1] - 0.5)\n        ax.set_ylim(-0.5, M.shape[0] - 0.5)\n    # xy locations of each ellipse center\n    xy = np.indices(M.shape)[::-1].reshape(2, -1).T\n    \n    # set the relative sizes of the major\/minor axes according to the strength\n    # the positive\/negative correlation\n    w = np.ones_like(M).ravel()\n    h = 1 - np.abs(M).ravel()\n    a = 45 * np.sign(M).ravel()\n    \n    ec = EllipseCollection(widths=w, heights=h, angles=a, units='x', offsets=xy,\n                           transOffset=ax.transData, array=M.ravel(), **kwargs)\n    ax.add_collection(ec)\n    \n    if isinstance(data, pd.DataFrame):\n        ax.set_xticks(np.arange(M.shape[1]))\n        ax.set_xticklabels(data.columns, rotation=90)\n        ax.set_yticks(np.arange(M.shape[0]))\n        ax.set_yticklabels(data.index)\n    \n    return ec\n \nfig, ax = plt.subplots(1, 1)\nm = plot_corr_ellipses(data.corr(), ax=ax, cmap='Greens')\ncb = fig.colorbar(m)\ncb.set_label('Correlation coefficient')\nax.margins(0.1)\ncurrent_fig = plt.gcf()  \ncurrent_fig.savefig('my_0.pdf', bbox_inches='tight')  \n \nimport seaborn as sns\nsns.clustermap(data=data.corr(), annot=True, cmap='Greens').savefig('my_1.pdf', bbox_inches='tight')","5f1e8691":"def CosSimilarity(data):\n    col = data.shape[1]\n    row = data.shape[0]\n    # Standardize data sets and convert them to multidimensional arrays\n    dataPre = preprocessing.scale(data)\n\n    dataRel = np.array(dataPre)\n    dataRel = dataRel.reshape(col,row)\n    \n    # Cosine similarity matrix\n    cos = pd.DataFrame(cosine_similarity(dataRel))\n    return cos\n\nCosSimilarity(dataFillMean)","7ef08a4d":"# Clustering via Geography Attributes\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Loading Geography Features subdataset\ndataGeo = data[['AQI', 'Longititute', 'Latitude', 'Altitude']]\n# print(dataGeo.head())\n\n# Creat a #d Plot Project\nx, y, z = dataGeo['Longititute'], dataGeo['Latitude'], dataGeo['Altitude']\nax = plt.subplot(111, projection='3d')\n\n# Use K-Means Clustering\nfrom sklearn.cluster import KMeans\ny_pred = KMeans(n_clusters=5, random_state=6).fit_predict(dataGeo)\nax.scatter(x, y, z, c = y_pred)  \n\n# Plot Axis\nax.set_zlabel('Altitude') \nax.set_ylabel('Latitude')\nax.set_xlabel('Longititute')\nplt.title('K-Means Clustering 3D Graph')\nplt.show()\n\n#\u805a\u7c7b\u4e8c\u7ef4\u5e73\u9762\u56fe\nplt.scatter(x,y,c = y_pred)\nplt.xlabel('Longititude')\nplt.ylabel('Latitude')\nplt.title('K-Means Clustering Planar Graph')\nplt.show()#\u663e\u793a\u6a21\u5757\u4e2d\u7684\u6240\u6709\u7ed8\u56fe\u5bf9\u8c61\n\n# Merging the Dataset and Labels from Cluster\nlabel = pd.DataFrame(y_pred)\nlabel.columns = ['label']\nlabel.head()\ndataLab = pd.merge(data, label, how='right', left_index=True, right_index=True, sort=False)\n\n\n# Function to Fix the Dataset\ndef FillMean(S):\n    cluNum = S['label'].value_counts()\n    for i in range(len(cluNum)):\n        cluName = cluNum.index[i]\n        sub = S[S['label'] == cluName]\n        S[S['label'] == cluName] = sub.fillna(sub.mean())\n    return S\n\ndataFixed = FillMean(dataLab)\ndataFixed.describe()","c3dc72c2":"# Evaluate the K-Means clustering model effects of the currently selected parameters\nfrom sklearn import metrics\nmetrics.calinski_harabaz_score(dataGeo, y_pred)  ","85db8c21":"# The similarity calculation of filled in the missing data after k-means clustering\ndata_corr1 = CovSimilarity(dataFixed)\ndata_corr1","8d4a3a6f":"# Visualization of similarity calculation results\nimport seaborn as sns\nsns.clustermap(data=data_corr1, annot=True, cmap='Blues').savefig('my_1.pdf', bbox_inches='tight')","1c096530":"# Create a 3D drawing project\nx, y, z = dataGeo['Longititute'], dataGeo['Latitude'], dataGeo['Altitude']\nax = plt.subplot(111, projection='3d')\n\n# Use DBSCAN clustering\nfrom sklearn.cluster import DBSCAN\ny_pred2 = DBSCAN(eps =15, min_samples = 7).fit_predict(dataGeo)\nax.scatter(x, y, z, c = y_pred2) \n\n# print(y_pred[:20])\n\n# Draw axes\nax.set_zlabel('Altitude') \nax.set_ylabel('Latitude')\nax.set_xlabel('Longititute')\nplt.title('DBSCAN Clustering 3D Graph')\nplt.show()\n\n# Clustering 2D plan\nplt.scatter(x,y,c = y_pred2)\nplt.xlabel('Longititude')\nplt.ylabel('Latitude')\nplt.title('DBSCAN Clustering Planar Graph')\nplt.show()#\u663e\u793a\u6a21\u5757\u4e2d\u7684\u6240\u6709\u7ed8\u56fe\u5bf9\u8c61\n\n# Merging the Dataset and Labels from Cluster\nlabel = pd.DataFrame(y_pred2)\nlabel.columns = ['label']\nlabel.head()\ndataLab = pd.merge(data, label, how='right', left_index=True, right_index=True, sort=False)\n\ndataLab = pd.merge(data, label, how='right', left_index=True, right_index=True, sort=False)\ndataFixed2 = FillMean(dataLab)\ndataFixed2.describe()","83093246":"# Evaluate the DBSCAN clustering model effects of the currently selected parameters\nfrom sklearn import metrics\nmetrics.calinski_harabaz_score(dataGeo, y_pred2)","669978e5":"data_corr2 = CovSimilarity(dataFixed2)\ndata_corr2","d81c1882":"# Visualization of similarity calculation results\nimport seaborn as sns\nsns.clustermap(data=data_corr2, annot=True, cmap='Purples').savefig('my_1.pdf', bbox_inches='tight')","2705e538":"# Build up a dataset\nmissing_precipitation = dataFixed\n\n# The complete data part of Precipitation as training sets and missing data part of Precipitation as test sets\nmissing_precipitation_train = missing_precipitation[data['Precipitation'].notnull()]\nmissing_precipitation_test = missing_precipitation[data['Precipitation'].isnull()]\n\n# Constructing the X and Y values of the training set and prediction set respectively\nX_train = missing_precipitation_train.drop(['Precipitation'], axis=1)\nY_train = missing_precipitation_train['Precipitation']\nX_test = missing_precipitation_test.drop(['Precipitation'], axis=1)\nY_test = missing_precipitation_test['Precipitation']\n\n\n# Standardize data\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\n\n# Trainning the test sets and standardize it\nss.fit(X_train)\nX_train = ss.transform(X_train)\nX_test = ss.transform(X_test)\n\n# Bayesian\nfrom sklearn import linear_model\nlin = linear_model.BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n        fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n        normalize=False, tol=0.001, verbose=False)\nlin.fit(X_train,Y_train)\n\n\ndataFixed3 = dataFixed\ndataFixed3.loc[(data['Precipitation'].isnull()), 'Precipitation'] = lin.predict(X_test)\n\ndataFixed3.describe()","61f81ed6":"data_corr3 = CovSimilarity(dataFixed3)\ndata_corr3","ebf4f58b":"b = plt.subplots(figsize=(15,9))\nb = sns.heatmap(data_corr3, vmin=-1, vmax=1 , annot=True , square=True)","3b991cdf":"from sklearn.model_selection import train_test_split # Split data module\nfrom sklearn.neighbors import KNeighborsClassifier # kNN\uff0ck-NearestNeighbor\n\n# k-NN modelling\nknn = KNeighborsClassifier()\n\n# Training model\nknn.fit(X_train, Y_train.astype('int'))\n\ndataFixed4 = dataFixed\ndataFixed4.loc[(data['Precipitation'].isnull()), 'Precipitation'] = knn.predict(X_test)\ndataFixed4.describe()\n","5fc81fd0":"data_corr4 = CovSimilarity(dataFixed4)\ndata_corr4","1091fa76":"import seaborn as sns\nsns.clustermap(data=data_corr4, annot=True, cmap='Reds').savefig('my_1.pdf', bbox_inches='tight')","aed5664c":"# SVR\nsvr = svm.SVR()\nsvr.fit(X_train, Y_train)\n\ndataFixed5 = dataFixed\ndataFixed5.loc[(data['Precipitation'].isnull()), 'Precipitation'] = svr.predict(X_test)\ndataFixed5.describe()","aee7dc72":"data_corr5 = CovSimilarity(dataFixed5)\ndata_corr5","31673fa1":"import seaborn as sns\nsns.clustermap(data=data_corr5, annot=True, cmap='Oranges').savefig('my_1.pdf', bbox_inches='tight')","f35da53b":"lr = LogisticRegression()\nlr.fit(X_train, Y_train.astype('int'))\n\ndataFixed6 = dataFixed\ndataFixed6.loc[(data['Precipitation'].isnull()), 'Precipitation'] = lr.predict(X_test)\ndataFixed6.describe()","17155bfa":"data_corr6 = CovSimilarity(dataFixed6)\ndata_corr6","b481cb4c":"import seaborn as sns\nsns.clustermap(data=data_corr6, annot=True, cmap='Greys').savefig('my_1.pdf', bbox_inches='tight')","769a62cb":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, Y_train.astype('int'))\n\ndataFixed7 = dataFixed\ndataFixed7.loc[(data['Precipitation'].isnull()), 'Precipitation'] = dtc.predict(X_test)\ndataFixed7.describe()","4c6c8620":"data_corr7 = CovSimilarity(dataFixed7)\ndata_corr7","1bf9b712":"import seaborn as sns\nsns.clustermap(data=data_corr7, annot=True, cmap='Blues').savefig('my_1.pdf', bbox_inches='tight')","4583a813":"lda = LinearDiscriminantAnalysis()\nlda.fit(X_train, Y_train.astype('int'))\n\ndataFixed8 = dataFixed\ndataFixed8.loc[(data['Precipitation'].isnull()), 'Precipitation'] = lda.predict(X_test)\ndataFixed8.describe()","a1b39786":"data_corr8 = CovSimilarity(dataFixed8)\ndata_corr8","aa469e21":"import seaborn as sns\nsns.clustermap(data=data_corr8, annot=True, cmap='Reds').savefig('my_1.pdf', bbox_inches='tight')","46669c30":"svc = SVC()\nsvc.fit(X_train, Y_train.astype('int'))\n\ndataFixed9 = dataFixed\ndataFixed9.loc[(data['Precipitation'].isnull()), 'Precipitation'] = svc.predict(X_test)\ndataFixed9.describe()","47d632cc":"data_corr9 = CovSimilarity(dataFixed9)\ndata_corr9","8a61fc80":"import seaborn as sns\nsns.clustermap(data=data_corr9, annot=True, cmap='Purples').savefig('my_1.pdf', bbox_inches='tight')","fcf0a262":"gnb = GaussianNB()\ngnb.fit(X_train, Y_train.astype('int'))\n\ndataFixed10 = dataFixed\ndataFixed10.loc[(data['Precipitation'].isnull()), 'Precipitation'] = gnb.predict(X_test)\ndataFixed10.describe()","eaecf257":"data_corr10 = CovSimilarity(dataFixed10)\ndata_corr10","e229b34b":"import seaborn as sns\nsns.clustermap(data=data_corr10, annot=True, cmap='Oranges').savefig('my_1.pdf', bbox_inches='tight')","46f00df3":"# Draw the global scatter diagram of the results of k-means method filling\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='whitegrid', context='notebook')\ncols = ['AQI','Precipitation','GDP','Temperature','Longititute','Latitude','Altitude','PopulationDensity','Coastal','GreenCoverageRate','Incineration(10,000ton)']\nsns.pairplot(dataFixed[cols], size=2.5)\nplt.tight_layout()\n# plt.savefig('.\/figures\/scatter.png', dpi=300)\nplt.show()","ecff530b":"# Draw the global scatter diagram of the results of Decision Tree Classify method filling\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='whitegrid', context='notebook')\ncols = ['AQI','Precipitation','GDP','Temperature','Longititute','Latitude','Altitude','PopulationDensity','Coastal','GreenCoverageRate','Incineration(10,000ton)']\nsns.pairplot(dataFixed7, size=2.5)\nplt.tight_layout()\n# plt.savefig('.\/figures\/scatter.png', dpi=300)\nplt.show()","b0b32e22":"# Draw the global scatter diagram of the results of Gaussian Naive Bayes (GNB) method filling\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='whitegrid', context='notebook')\ncols = ['AQI','Precipitation','GDP','Temperature','Longititute','Latitude','Altitude','PopulationDensity','Coastal','GreenCoverageRate','Incineration(10,000ton)']\nsns.pairplot(dataFixed10, size=2.5)\nplt.tight_layout()\n# plt.savefig('.\/figures\/scatter.png', dpi=300)\nplt.show()","d54f5e7d":"data1 = dataFixed7[['AQI', 'Precipitation']]\ndata1 = data1.sort_values(by = 'Precipitation', ascending = 'False')\nplt.subplots(figsize=(15,9))\nx = data1.Precipitation\ny = data1.AQI\nplt.plot(x, y, marker='o', mec='y', mfc='y')\nplt.xlabel('Precipitation') \nplt.ylabel(\"AQI\") \nplt.title(\"Relations between Precipitation and AQI\") \nplt.show()","4b134c3a":"data2 = dataFixed7[['AQI', 'GDP']]\ndata2 = data.sort_values(by = 'GDP', ascending = 'False')\nplt.subplots(figsize=(30,9))\nx = data2.GDP\n#x = Latitude_normed\n#normalized_x = preprocessing.normalize(x).fit(x).values.reshape(-1,1)\ny = data2.AQI\n#y = AQI_normed\n#normalized_y = preprocessing.normalize(y).fit(y).values.reshape(-1,1)\nplt.plot(x, y, marker='o', mec='g', mfc='y')\nplt.xlabel('GDP') \nplt.ylabel(\"AQI\") \nplt.title(\"Relations between GDP and AQI\") \nplt.show()","2e525e31":"data3 = dataFixed7[['AQI', 'Temperature']]\ndata3 = data3.sort_values(by = 'Temperature', ascending = 'False')\nplt.subplots(figsize=(30,10))\nx = data3.Temperature\ny = data3.AQI\nplt.plot(x, y, marker='o', mec='r', mfc='y')\nplt.xlabel('Temperature') \nplt.ylabel(\"AQI\") \nplt.title(\"Relations between Temperature and AQI\") \nplt.show()","cedd2746":"# 3D diagram of longitude, latitude and AQI\nfrom mpl_toolkits.mplot3d import Axes3D\ndata4 = dataFixed7[['AQI', 'Longititute', 'Latitude']]\nplt.subplots(figsize=(20,10))\nx, y, z = data4['Longititute'], data4['Latitude'], dataGeo['AQI']\nax = plt.subplot(111, projection='3d')\nax.scatter(x, y, z, linewidths = 4)  \nax.set_zlabel('AQI') \nax.set_ylabel('Latitude')\nax.set_xlabel('Longititute')\nplt.title('Relations between Longititute, Latitude and AQI')\nplt.show()","a87b0754":"# AQI and Latitude\ndata5 = dataFixed7[['AQI', 'Latitude']]\ndata5 = data5.sort_values(by = 'Latitude', ascending = 'False')\nplt.subplots(figsize=(20,10))\nx = data5.Latitude\ny = data5.AQI\nplt.plot(x, y, marker='o', mec='r', mfc='y')\nplt.xlabel('Latitude') \nplt.ylabel(\"AQI\") \nplt.title(\"Relations between Latitude and AQI\") \nplt.show()","2443ecb3":"# AQI and Longititute\ndata6 = dataFixed7[['AQI', 'Longititute']]\ndata6 = data6.sort_values(by = 'Longititute', ascending = 'False')\nplt.subplots(figsize=(30,10))\nx = data6.Longititute\ny = data6.AQI\nplt.plot(x, y, marker='o', mec='c', mfc='y')\nplt.xlabel('Longititute') \nplt.ylabel(\"AQI\") \nplt.title(\"Relations between Longititute and AQI\") \nplt.show()","4bfb67e2":"# AQI and Altitude\ndata7 = dataFixed7[['AQI', 'Altitude']]\ndata7 = data7.sort_values(by = 'Altitude', ascending = 'False')\nplt.subplots(figsize=(30,10))\nx = data7.Altitude\ny = data7.AQI\nplt.plot(x, y, marker='o', mec='r', mfc='y')\nplt.xlabel('Altitude') \nplt.ylabel(\"AQI\") \nplt.title(\"Relations between Altitude and AQI\") \nplt.show()","52801868":"# AQI and PopulationDensity\ndata8 = dataFixed7[['AQI', 'PopulationDensity']]\ndata8 = data8.sort_values(by = 'PopulationDensity', ascending = 'False')\nplt.subplots(figsize=(30,10))\nx = data8.PopulationDensity\ny = data8.AQI\nplt.plot(x, y, marker='o', mec='g', mfc='y')\nplt.xlabel('PopulationDensity') \nplt.ylabel(\"AQI\") \nplt.title(\"Relations between PopulationDensity and AQI\") \nplt.show()","c232127a":"aqi_Coastal = 0\naqi_no_Coastal = 0\nc_Coastal = 0\nc_no_Coastal = 0\nfor i in range(len(dataFixed7)):\n    if dataFixed7.Coastal.loc[i] == 0:\n        aqi_no_Coastal += dataFixed7.AQI.loc[i]\n        c_no_Coastal += 1\n    else:\n        aqi_Coastal += dataFixed7.AQI.loc[i]\n        c_Coastal += 1\n\nmean_aqi_Coastal = aqi_Coastal\/ (c_Coastal * 1.0 )\nmean_aqi_no_Coastal = aqi_no_Coastal\/ (c_no_Coastal * 1.0 )\nname_list2 = ['Coastal', 'Non Coastal']\nnum_list2 = [mean_aqi_Coastal, mean_aqi_no_Coastal]\nplt.figure(figsize = (8,8))\nrects=plt.bar(range(len(num_list2)), num_list2, color='y')\nindex=[0,1]\nindex=[float(c) for c in index]\nplt.xticks(index, name_list2)\nplt.ylabel(\"Mean AQI Value\")\nplt.title('Relations between Coastal and AQI')\n#plt.ylim((0, 0.5))\nfor i, rect in enumerate(rects):\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width() \/ 2, height,  '%.4f' %num_list2[i], ha='center', va='bottom')\nplt.show()","82de1085":"data9 = dataFixed7[['AQI', 'GreenCoverageRate']]\ndata9 = data9.sort_values(by = 'GreenCoverageRate', ascending = 'False')\nplt.subplots(figsize=(30,10))\nx = data9.GreenCoverageRate\ny = data9.AQI\nplt.plot(x, y, marker='o', mec='b', mfc='y')\nplt.xlabel('GreenCoverageRate') \nplt.ylabel(\"AQI\") \nplt.title(\"Relations between GreenCoverageRate and AQI\") \nplt.show()","5390a232":"import numpy as np \nimport matplotlib.pyplot as plt\nx = dataFixed7[['Precipitation']].values\nX = x.reshape(-1, 1)\ny = dataFixed7['AQI'].values\nplt.scatter(x, y)\nplt.show()","ab12c233":"# To compile the least square method classes\nclass LinearRegressionGD(object):\n    def __init__(self, eta=0.001, n_iter=20):\n        self.eta = eta\n        self.n_iter = n_iter\n    def fit(self, X, y):   # X is a column vector,y is a row vector\n        self.w_ = np.zeros(1 + X.shape[1])   #Initialize (1,2) row vectors which are all 0 and store the two coefficients of the line fitting by the iterative process\n        self.cost_ = []\n        for i in range(self.n_iter):\n            output = self.net_input(X)\n            errors = (y - output)   # The errors are the error entries for row vectors that have the same dimension as y\n            self.w_[1:] += self.eta * X.T.dot(errors)   # Fitting the primary coefficient of the line\n            self.w_[0] += self.eta * errors.sum()   # Fitting constant term of line\n            cost = (errors**2).sum() \/ 2.0   # The sum of the squares of the residuals and half the objective function\n            self.cost_.append(cost)\n        return self\n    def net_input(self, X):\n        return np.dot(X, self.w_[1:]) + self.w_[0]   \n    def predict(self, X):\n        return self.net_input(X)\n# Cost_ is a statistical list of the squares and halves of residuals for each iteration,\n# w_ contains two parameters of the line for each iteration, and errors are residuals for each iteration\n\nX = dataFixed7[['Temperature']].values   #X is (*,1) dimensional column vector\ny = dataFixed7['AQI'].values   #y is (*, ) row vector\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nsc_y = StandardScaler()\nX_std = sc_x.fit_transform(X)   \n# The fit_transform method can be divided into fit and transform steps in StanderdScalar, which will be merged in order to differentiate the LinearRegressionGD class\ny_std = sc_y.fit_transform(y[:, np.newaxis]).flatten()   \n#y[:, np.newaxis] equal to y[np.newaxis].T,that is, df[['MEDV']].values\uff1bflatten method is used to change back to 1*n vectors\n#fit_transform method is in order to regularize the \u201ccolumn vector\u201d directly\nlr = LinearRegressionGD()\nlr.fit(X_std, y_std)   # This fit is the class of LinearRegressionGD, Note the difference between the different fit methods used in sklearn and their environments\n#Output:<__main__.LinearRegressionGD at 0x16add278>\nplt.plot(range(1, lr.n_iter+1), lr.cost_)\nplt.ylabel('Temperature')\nplt.xlabel('AQI')\nplt.tight_layout()\n# plt.savefig('.\/figures\/cost.png', dpi=300)\nplt.show()","a8ea5978":"def lin_regplot(X, y, model):\n    plt.scatter(X, y, c='lightblue')\n    plt.plot(X, model.predict(X), color='red', linewidth=2)    \n    return \nlin_regplot(X_std, y_std, lr)\nplt.xlabel('Temperature')\nplt.ylabel('AQI')\nplt.tight_layout()\n# plt.savefig('.\/figures\/gradient_fit.png', dpi=300)\nplt.show()","fb0fbc67":"import numpy\nfrom sklearn.tree import DecisionTreeRegressor\n#http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\nX = data[['Altitude']].values\ny = data['AQI'].values\n \ntree = DecisionTreeRegressor(max_depth=5)   #max_depth Setting the depth of tree\ntree.fit(X, y)   # Various attributes obtained after modeling: tree, features used and importance of features\n \nsort_idx = X.flatten().argsort()   #The vectors constructed by the index of the smallest element to the largest element in X\n \nlin_regplot(X[sort_idx], y[sort_idx], tree)\nplt.xlabel('Altitude')\nplt.ylabel('AQI')\n# plt.savefig('.\/figures\/tree_regression.png', dpi=300)\nplt.show()\n#The horizontal red line represents the c value, and the vertical red line represents the shard point selected by the feature column","445608ad":"X = data[['PopulationDensity']].values\ny = data['AQI'].values\n \ntree = DecisionTreeRegressor(max_depth=8)   #max_depth Setting the depth of tree\ntree.fit(X, y)   # Various attributes obtained after modeling: tree, features used and importance of features\n \nsort_idx = X.flatten().argsort()   #The vectors constructed by the index of the smallest element to the largest element in X\n \nlin_regplot(X[sort_idx], y[sort_idx], tree)\nplt.xlabel('PopulationDensity')\nplt.ylabel('AQI')\n# plt.savefig('.\/figures\/tree_regression.png', dpi=300)\nplt.show()\n#The horizontal red line represents the c value, and the vertical red line represents the shard point selected by the feature column","a75291b6":"X = data[['Incineration(10,000ton)']].values\ny = data['AQI'].values\n \ntree = DecisionTreeRegressor(max_depth=8)   #max_depth Setting the depth of tree\ntree.fit(X, y)   # Various attributes obtained after modeling: tree, features used and importance of features\n \nsort_idx = X.flatten().argsort()   #The vectors constructed by the index of the smallest element to the largest element in X\n \nlin_regplot(X[sort_idx], y[sort_idx], tree)\nplt.xlabel('Incineration(10,000ton)')\nplt.ylabel('AQI')\n# plt.savefig('.\/figures\/tree_regression.png', dpi=300)\nplt.show()\n#The horizontal red line represents the c value, and the vertical red line represents the shard point selected by the feature column","2391e770":"X = data[['GreenCoverageRate']].values\ny = data['AQI'].values\n \ntree = DecisionTreeRegressor(max_depth=8)   #max_depth Setting the depth of tree\ntree.fit(X, y)   # Various attributes obtained after modeling: tree, features used and importance of features\n \nsort_idx = X.flatten().argsort()   #The vectors constructed by the index of the smallest element to the largest element in X\n \nlin_regplot(X[sort_idx], y[sort_idx], tree)\nplt.xlabel('GreenCoverageRate')\nplt.ylabel('AQI')\n# plt.savefig('.\/figures\/tree_regression.png', dpi=300)\nplt.show()\n#The horizontal red line represents the c value, and the vertical red line represents the shard point selected by the feature column","ca14195d":"**Similarity Calculation (Tentative)**","66b81a91":"**Filling the missing data using prediction of Support Vector Regression (SVR) method**","b9a5da97":"**Draw the global scatter diagram of the results of k-means method filling**","154ec7db":"**Fitting the scatter points using Linear regression Least squares**","212f0b28":"**Filling the missing data using prediction of Gaussian Naive Bayes (GNB) method**","6c457920":"**Visualization of similarity calculation results after K-Means clustering**","95efa747":"**Filling the missing data using prediction of Support Vector Classification (SVC) method**","36ba009d":"**The Calinski_harabaz scoring model evaluates the DBSCAN clustering results obtained by the current k-means parameters setting**","fadbbc1c":"**The similarity calculation of filled in the missing data after k-means clustering**","2f6a9c45":"**Check for missing data**","afda8798":"**AQI and Temperature**","24381081":"**Filling the mean values in missing data**","eab88a01":"**Correlation analysis of filled the result of precipitation features using Linear Discriminant Analysis (LDA) model**","24b56068":"**AQI and Longititute and Latitude**","572e155e":"**AQI and Latitude**","105bd491":"**Filling the missing data using prediction of Linear Discriminant Analysis (LDA) method**","014761aa":"**Filling the missing data using prediction of Logistic Regression (LR) method**","8fecaffa":"**Fitting the scatter points of AQI and Population Density using Decision Tree Regression**","8bd9a471":"**Visualization of similarity calculation results of SVR prediction**","4997265a":"**AQI and Precipitation**","94738eeb":"**Check for cosine similarity matrix**","43bf3b2d":"**AQI and GreenCoverageRate**","b1cbc2d9":"**Visualization of similarity calculation results of Support Vector Classification (SVC) prediction**","ea552f77":"**Filling the missing data using prediction of Bayesian Regression method**","ec37cf21":"**Correlation analysis of filled the result of precipitation features using Logistic Regression (LR)  model**","3b0f2f78":"**Visualization of similarity calculation results of Logistic Regression (LR) prediction**","4e0ebd1d":"**Filling the missing data using prediction of Decision Tree Classifier (DTC) method**","56788f9b":"**Visualization of similarity calculation results of Bayesian Regression prediction**","641f642d":"**Filling the missing data using prediction of k-NN method**","a8840ef8":"**Clustering method 1: k-means clustering**","2f7908c3":"**Draw the global scatter diagram of the results of Decision Tree Classify (DTC) method filling**","516a6abf":"**The Calinski_harabaz scoring model evaluates the K-Means clustering results obtained by the current k-means parameters setting**","c5295902":"**Correlation analysis of filled the result of missing data using DBSCAN clustering model**","feaa44e3":"1. **Fitting the scatter points of AQI and Incineration using Decision Tree Regression**","2c0203c0":"**Draw the global scatter diagram of the results of Gaussian Naive Bayes (GNB) method filling**","7a0d4e81":"**Check the Dataset**","c4c0aba4":"**Correlation analysis of filled the result of precipitation features using Gaussian Naive Bayes (GNB) model**","879e0bb4":"**Correlation analysis of filled the result of precipitation features using SVR model**","187f62d7":"**Visualization of similarity calculation results of k-NN prediction**","bd9ef973":"> **AQI and Altitude**","8ccfcebd":"**Correlation analysis of filled the result of precipitation features using Decision Tree Classifier (DTC) model**","936d3158":"**Fitting the scatter points of AQI and Green Coverage Rate using Decision Tree Regression**","22239c86":"**AQI and GDP**","af874df1":"**Visualization of similarity calculation results of Gaussian Naive Bayes (GNB) prediction**","7dadb0c3":"**Fitting the scatter points of AQI and Altitude using Decision Tree Regression**","d376ba36":"**Correlation analysis of filled the result of missing data using k-NN model**","4ba71da7":"**Visualization of similarity calculation results of Decision Tree Classifier (DTC) prediction**","f308bb17":"**Correlation analysis of filled the result of precipitation features using Support Vector Classification (SVC) model**","405db2f5":"**AQI and PopulationDensity**","c053f1c1":"**Visualization of similarity calculation results (Tentative)**","2a8266e6":"**Visualization of similarity calculation results of Linear Discriminant Analysis (LDA) prediction**","36810369":"**Visualized the analysis of Linear regression least square method**","932ca6f0":"**Clustering method 2: DBSCAN clustering fills in the missing data**","41cfef0e":"**AQI and Longititute**","4b824023":"**Correlation analysis of filled the result of missing data using Bayesian Regression model**"}}