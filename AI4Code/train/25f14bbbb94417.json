{"cell_type":{"5b5d408e":"code","fef02266":"code","e1532e31":"code","af123a1b":"code","4bd3ef6f":"code","85efff97":"code","82c7186a":"code","d5b088fa":"code","75dfa92d":"code","f51995e7":"code","f31f4b95":"code","b130de90":"code","778afdbb":"code","44daafe6":"code","d26aeafe":"code","9b2cc2fb":"code","54749c8f":"markdown","9d1ec435":"markdown","66021d38":"markdown","0057148b":"markdown","b92b94eb":"markdown","a690156e":"markdown","68154a3e":"markdown","ccc60f5e":"markdown","3733380f":"markdown","c4261b94":"markdown","e789bf39":"markdown","8b4345c3":"markdown","8834b988":"markdown","bda1d0ff":"markdown","59454264":"markdown","6ef965c4":"markdown","b59d9efa":"markdown","a0e24d23":"markdown","f0b01dec":"markdown","acf1780a":"markdown","abd9467c":"markdown","86ed0920":"markdown","cd49ee84":"markdown"},"source":{"5b5d408e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fef02266":"# Bize laz\u0131m olacak k\u00fcp\u00fcphaneleri alal\u0131m\nimport matplotlib.pyplot as plt # Grafik \u00e7izimleri i\u00e7in\nimport seaborn as sns           # G\u00f6rselle\u015ftirme i\u00e7in","e1532e31":"data = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\") # datam\u0131z\u0131 \u00e7ekiyoruz.\ndata.head()  # datan\u0131n ilk 5 sat\u0131r\u0131n\u0131 g\u00f6rmemizi sa\u011flar\n","af123a1b":"data.shape","4bd3ef6f":"data.info() # data ile ilgili bilgilere eri\u015fmek i\u00e7in","85efff97":"data.describe()","82c7186a":"#Columnlar\u0131n birbiriyle korelasyonu\nplt.figure(figsize=(15,9))\nsns.heatmap(data.corr(),cmap='Blues',annot=True) \nplt.show()","d5b088fa":"# Boxplot\nl = data.columns.values\nnumber_of_columns=14\nnumber_of_rows = len(l)-1\/number_of_columns\nplt.figure(figsize=(number_of_columns,5*number_of_rows))\nfor i in range(0,len(l)):\n    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n    sns.set_style('whitegrid')\n    sns.boxplot(data[l[i]],color='green',orient='v')\n    plt.tight_layout()\n","75dfa92d":"# targetin ka\u00e7 hastada oldu\u011funu bulabiliriz.\nsns.countplot(x=\"target\", data=data)\ndata.loc[:,'target'].value_counts()\n","f51995e7":"from sklearn.model_selection import train_test_split # Datam\u0131z\u0131 train ve test olarak b\u00f6l\u00fcyoruz.\nx,y = data.loc[:,data.columns != 'target'], data.loc[:,'target']\nx_train, x_test, y_train, y_test  =train_test_split(x,y, test_size =0.3 , random_state = 42)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5) # n_neighbors : K de\u011feridir. Bak\u0131lacak eleman say\u0131s\u0131d\u0131r.\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\n\nprint('K=5 i\u00e7in do\u011fruluk : ',knn.score(x_test,y_test)) \n","f31f4b95":"# k'y\u0131 1'dan 25'e kadar se\u00e7iyoruz ve bizim i\u00e7in en uygun de\u011feri bulal\u0131m.\n\naral\u0131k = np.arange(1,25)\ntrain_dogruluk =[]\ntest_dogruluk = []\n\nfor i ,k in enumerate(aral\u0131k):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    # knn ile fit ediyoruz.\n    knn.fit(x_train,y_train)\n    #train do\u011fruluk\n    train_dogruluk.append(knn.score(x_train, y_train))\n    # test do\u011fruluk\n    test_dogruluk.append(knn.score(x_test, y_test))\n    \n# \u015eimdi do\u011fruluk grafi\u011fini \u00e7izdirece\u011fiz\n\n\n\nplt.figure(figsize=[13,8])\nplt.plot(aral\u0131k, test_dogruluk, label = 'Test Do\u011frulu\u011fu')\nplt.plot(aral\u0131k, train_dogruluk, label = 'Training Do\u011frulu\u011fu')\nplt.legend()\nplt.title('-value VS Do\u011fruluk')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.xticks(aral\u0131k)\nplt.savefig('graph.png')\nplt.show()\nprint(\"En iyi do\u011fruluk {} with K = {}\".format(np.max(test_dogruluk),1+test_dogruluk.index(np.max(test_dogruluk))))\n\n    \n    ","b130de90":"#SWM\nfrom sklearn.svm import SVC\n\nsvc = SVC(random_state = 42)\n\nsvc.fit(x_train,y_train)\n\nprint(\"SWM modelinin do\u011frulu {}\".format(svc.score(x_test,y_test)))\n\nresult = svc.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,result)\nprint(cm)\n","778afdbb":"# NA\u0130VE BAYES\nfrom sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\nprint(\"Naive Bayes modelinin do\u011frulu\u011fu {}\".format(nb.score(x_test,y_test)))\n\n# Confusion Matrix\nresult = svc.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,result)\nprint(cm)","44daafe6":"#Decision Tree\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier(random_state=42)\n\ndtc.fit(x_train,y_train)\n\nresult = dtc.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test,result)\nprint(cm)\n\nprint(\"Decision Tree modeli do\u011fruluk oran\u0131 {}\".format(dtc.score(x_test,y_test)))","d26aeafe":"from sklearn.ensemble import RandomForestClassifier\n# RandomForestClassifier s\u0131n\u0131f\u0131n\u0131 import ettik\n\nrf = RandomForestClassifier (n_estimators =100 , random_state = 42) \n# n_estimators = Olu\u015fturulacak karar a\u011fac\u0131 say\u0131s\u0131d\u0131r. De\u011fi\u015ftirildi\u011finde ba\u015far\u0131 oran\u0131da de\u011fi\u015fir.\nrf.fit(x_train,y_train)\n\nprint(\"Random Forest modeli Do\u011frulu\u011fu {}\".format(rf.score(x_test,y_test)))\n","9b2cc2fb":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\n\n#normalizition\nx = (x - np.min(x))\/(np.max(x)-np.min(x)).values\nfrom sklearn.model_selection import train_test_split # Datam\u0131z\u0131 train ve test olarak b\u00f6l\u00fcyoruz.\nx,y = data.loc[:,data.columns != 'target'], data.loc[:,'target']\nx_train, x_test, y_train, y_test  =train_test_split(x,y, test_size =0.3 , random_state = 42)\n\n\nlr = LogisticRegression(random_state=42)\nlr.fit(x_train,y_train)\n\nprint(\"Logistic Regression modeli do\u011frulu\u011fu {}\".format(lr.score(x_test,y_test)))\n\n","54749c8f":"\u00dcstteki kodumuzu yazarak datam\u0131z\u0131n\u0131 shape bilgisini \u00f6\u011frenebiliyoruz.\nDatada 14 \u00f6zellik (age,thalach vb.) ve 303 g\u00f6zlem -bunlar da hasta oluyor- bulunuyor.","9d1ec435":"**Classification modellerinin kar\u015f\u0131la\u015ft\u0131r\u0131lmas\u0131**\n\n* KNN modeli           : 0.6923\n* SWM modeli           : 0.7032\n* Naive Bayes modeli   : 0.8351\n* Decision Tree modeli : 0.73626\n* Random Forest modeli : 0.8241\n* Logistic Regression modeli : 0.81318\n\nG\u00f6r\u00fcld\u00fc\u011f\u00fc \u00fczere datasetimiz i\u00e7in en uygun modelin Naive Bayes modeli oldu\u011funu g\u00f6rm\u00fc\u015f olduk.\n\n\nBe\u011fenilerinizi ve Ele\u015ftirilerinizi bekliyorum.\nTe\u015fekk\u00fcrler !\n","66021d38":"**K-NEAREST NEIGHBORS (KNN)**\n\nAlgoritman\u0131n \u00e7al\u0131\u015fmas\u0131nda bir K de\u011feri belirlenir. Bu K de\u011ferinin anlam\u0131 bak\u0131lacak eleman say\u0131s\u0131d\u0131r. Bir de\u011fer geldi\u011finde en yak\u0131n K kadar eleman al\u0131narak gelen de\u011fer aras\u0131ndaki uzakl\u0131k hesaplan\u0131r. Uzakl\u0131k hesapland\u0131ktan sonra s\u0131ralan\u0131r ve gelen de\u011fer uygun olan s\u0131n\u0131fa atan\u0131r.\n","0057148b":"**Random Forest **\n\n\u00c7al\u0131\u015fma mant\u0131\u011f\u0131 birden fazla karar a\u011fac\u0131 olu\u015fturur. Bir sonu\u00e7 \u00fcretece\u011fi zaman bu karar a\u011fa\u00e7lar\u0131ndaki ortalama de\u011fer al\u0131n\u0131r ve sonu\u00e7 \u00fcretilir.","b92b94eb":"Peki en uygun K de\u011ferini nas\u0131l bulabiliriz ?","a690156e":"**SUPPORT VECTOR MACH\u0130NE (SWM) CLASS\u0130F\u0130CAT\u0130ON**","68154a3e":"Koyu tonlar pozitif korelasyonu, daha a\u00e7\u0131k tonlar negatif korelasyonu temsil eder.\nBurada target'in cp ile pozitif korelasyon exang ile negatif korelasyona sahip oldu\u011funu g\u00f6r\u00fcyoruz.\nTraget'in fbs ile nerdeyse hi\u00e7 korelasyonu olmad\u0131\u011f\u0131 g\u00f6z\u00fck\u00fcyor.\n","ccc60f5e":"Kutu grafikleri, be\u015f say\u0131 \u00f6zetine (\u201cminimum\u201d, ilk \u00e7eyrek (Q1), median, \u00fc\u00e7\u00fcnc\u00fc \u00e7eyrek (Q3) ve \u201cmaksimum\u201d) dayal\u0131 olarak veri da\u011f\u0131l\u0131m\u0131n\u0131 g\u00f6r\u00fcnt\u00fclemenin standart bir yoludur.\n\n\n* Medyan (Q2 \/ 50. Y\u00fczdelik) : veri k\u00fcmesinin orta de\u011feri.\n\n* \u0130lk \u00e7eyrek (Q1 \/ 25. Y\u00fczde): en k\u00fc\u00e7\u00fck say\u0131 (\u201cminimum\u201d de\u011fil) ve veri k\u00fcmesinin ortancas\u0131 aras\u0131ndaki orta say\u0131.\n\n* \u00dc\u00e7\u00fcnc\u00fc \u00e7eyrek (Q3 \/ 75. Y\u00fczdelik): veri k\u00fcmesinin ortanca de\u011feri ile en y\u00fcksek de\u011feri (\u201cmaksimum\u201d de\u011fil) aras\u0131ndaki orta de\u011fer.\n\n* \u00e7eyrekler aras\u0131 aral\u0131k (IQR): 25. ila 75. persentil.\n\n* whiskers (mavi renkle g\u00f6sterilir)\n\n* Outliers(ayk\u0131r\u0131 de\u011ferler) : ye\u015fil daireler olarak g\u00f6sterilir.\n* \u201cMaksimum\u201d: Q3 + 1,5 * IQR\n* \u201cMinimum\u201d: Q1 -1,5 * IQR\n* Outlier'ler verinin %7 sini olu\u015fturur..","3733380f":"S\u0131n\u0131fland\u0131rma (Classification) konusunda kullan\u0131lan olduk\u00e7a etkili ve basit y\u00f6ntemlerden birisidir. S\u0131n\u0131fland\u0131rma i\u00e7in bir d\u00fczlemde bulunan iki grup aras\u0131nda bir s\u0131n\u0131r \u00e7izilerek iki grubu ay\u0131rmak m\u00fcmk\u00fcnd\u00fcr. Bu s\u0131n\u0131r\u0131n \u00e7izilece\u011fi yer ise iki grubun da \u00fcyelerine en uzak olan yer olmal\u0131d\u0131r. \u0130\u015fte SVM bu s\u0131n\u0131r\u0131n nas\u0131l \u00e7izilece\u011fini belirler.\n\nBu i\u015flemin yap\u0131lmas\u0131 i\u00e7in iki gruba da yak\u0131n ve birbirine paralel iki s\u0131n\u0131r \u00e7izgisi \u00e7izilir ve bu s\u0131n\u0131r \u00e7izgileri birbirine yakla\u015ft\u0131r\u0131larak ortak s\u0131n\u0131r \u00e7izgisi \u00fcretilir.","c4261b94":"**EXPLORATORY DATA ANALYSIS ( Ke\u015fifsel Veri Analizi ) **\n\nKe\u015fifsel Veri Analizi(EDA), kal\u0131plar\u0131 ke\u015ffetmek, anormallikleri tespit etmek, hipotezi test etmek ve \u00f6zet istatistikler ve grafiksel g\u00f6sterimler yard\u0131m\u0131yla varsay\u0131mlar\u0131 kontrol etmek i\u00e7in veriler \u00fczerinde ilk ara\u015ft\u0131rmalar\u0131n yap\u0131lmas\u0131 kritik s\u00fcrecini ifade eder.\n\u00d6ncelikle verileri anlamak ve ondan \u00e7ok fazla bilgi toplamaya \u00e7al\u0131\u015fmak iyi bir uygulamad\u0131r. EDA, verileri kirletmeden \u00f6nce eldeki verileri anlamland\u0131rmakla ilgilidir.\n","e789bf39":"Verimizde trestbps ve chol gibi columnlar\u0131n outliere sahip oldu\u011funu g\u00f6r\u00fcyoruz.","8b4345c3":"**Decision Tree**\n \nDecision Tree'nin amac\u0131 veri \u00f6zelliklerinden basit kurallar \u00e7\u0131kar\u0131p bu kurallar\u0131 \u00f6\u011frenerek bir de\u011fi\u015fkenin de\u011ferini tahmin eden modeli olu\u015fturmakt\u0131r.","8834b988":"Boxplot veri da\u011f\u0131l\u0131m\u0131n\u0131 g\u00f6r\u00fcnt\u00fclemenin  bir yoludur. Size ayk\u0131r\u0131 de\u011ferleriniz ve de\u011ferlerinin ne oldu\u011fu hakk\u0131nda bilgi verebilir. Ayr\u0131ca verilerinizin simetrik olup olmad\u0131\u011f\u0131n\u0131, verilerinizin ne kadar s\u0131k\u0131 bir \u015fekilde grupland\u0131\u011f\u0131n\u0131 ve verilerinizin e\u011fri olup olmad\u0131\u011f\u0131n\u0131 ve nas\u0131l e\u011fildi\u011fini size s\u00f6yleyebilir.","bda1d0ff":"![boxplot.png](attachment:boxplot.png)","59454264":"![supervised.png](attachment:supervised.png)","6ef965c4":"**BOXPLOTS**","b59d9efa":"**Logistic Regression**\n\nLogistic Regression s\u0131n\u0131fland\u0131rma i\u015flemi yapmaya yarayan bir regresyon y\u00f6ntemidir. Kategorik veya say\u0131sal verilerin s\u0131n\u0131fland\u0131r\u0131lmas\u0131nda kullan\u0131l\u0131r. Ba\u011f\u0131ml\u0131 de\u011fi\u015fkenin yani sonucun sadece 2 farkl\u0131 de\u011fer alabilmesi durumda \u00e7al\u0131\u015f\u0131r. ","a0e24d23":"\n**NA\u0130VE BAYES CLASS\u0130F\u0130CAT\u0130ON **","f0b01dec":"**SUPERVISED LEARNING (DENET\u0130ML\u0130 \u00d6\u011eRENME)**\n\nDenetimli \u00f6\u011frenme, bir girdiyi \u00f6rnek girdi-\u00e7\u0131kt\u0131 \u00e7iftlerine dayal\u0131 olarak \u00e7\u0131kt\u0131yla e\u015fleyen bir i\u015flevi \u00f6\u011frenmenin makine \u00f6\u011frenme g\u00f6revidir. Bir dizi e\u011fitim \u00f6rne\u011finden olu\u015fan etiketli e\u011fitim verilerinden bir i\u015flevi ihlal eder.","acf1780a":"Naive Bayes s\u0131n\u0131fland\u0131r\u0131c\u0131s\u0131n\u0131n temeli Bayes teoremine dayan\u0131r. lazy ( tembel ) bir \u00f6\u011frenme algoritmas\u0131d\u0131r ayn\u0131 zamanda dengesiz veri k\u00fcmelerinde de \u00e7al\u0131\u015fabilir. Algoritman\u0131n \u00e7al\u0131\u015fma \u015fekli bir eleman i\u00e7in her durumun olas\u0131l\u0131\u011f\u0131n\u0131 hesaplar ve olas\u0131l\u0131k de\u011feri en y\u00fcksek olana g\u00f6re s\u0131n\u0131fland\u0131r\u0131r. Az bir e\u011fitim verisiyle \u00e7ok ba\u015far\u0131l\u0131 i\u015fler \u00e7\u0131kartabilir. Test k\u00fcmesindeki bir de\u011ferin e\u011fitim k\u00fcmesinde g\u00f6zlemlenemeyen bir de\u011feri varsa olas\u0131l\u0131k de\u011feri olarak 0 verir yani tahmin yapamaz. Bu durum genellikle Zero Frequency ( S\u0131f\u0131r Frekans ) ad\u0131yla bilinir. Bu durumu \u00e7\u00f6zmek i\u00e7in d\u00fczeltme teknikleri kullan\u0131labilir. En basit d\u00fczeltme tekniklerinden biri Laplace tahmini olarak bilinir.","abd9467c":"![SWM.png](attachment:SWM.png)","86ed0920":"Describe () i\u015flevi, columnlar ile ilgili istatistiklerin bir \u00f6zetini hesaplar.\n\n","cd49ee84":"Columnlarda hi\u00e7 null de\u011fer olmad\u0131\u011f\u0131n\u0131 g\u00f6r\u00fcyoruz.\n13 column integer 1 column ise float type'a sahip\n"}}