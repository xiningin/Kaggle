{"cell_type":{"85c5746a":"code","d76c7e9e":"code","779d031f":"code","405df27b":"code","bd40e3be":"code","335f5b3c":"code","6e07fcc6":"code","6944f78f":"code","a7596420":"code","2adf729d":"code","f956cdb5":"code","481f412b":"code","479ecfaf":"code","7ddaa6ef":"code","427895f4":"code","ccb6eb69":"code","b3644a36":"code","a98432e7":"code","2f524cde":"code","dba9a187":"code","56a8f1aa":"code","a5f61d29":"code","b8dbf11a":"code","08d9e6bf":"code","bcccd956":"code","e2955ff0":"code","250a1226":"code","ba82a659":"code","94ac5071":"code","7ec36e65":"markdown","7e3c10cb":"markdown","d2a88d4f":"markdown","b2b8c09e":"markdown","0a8035bb":"markdown","d5bea4f2":"markdown","44ab7f16":"markdown"},"source":{"85c5746a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d76c7e9e":"import pandas as pd\nimport numpy as np\nimport re\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom tqdm import tqdm","779d031f":"from sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.dummy import DummyClassifier\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom xgboost import XGBRegressor, XGBRFRegressor\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import ngrams\n\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\nfrom string import punctuation","405df27b":"import warnings\nwarnings.filterwarnings('ignore')","bd40e3be":"# set plot rc parameters\n\n# jtplot.style(grid=False)\nplt.rcParams['figure.facecolor'] = 'white'\nplt.rcParams['axes.facecolor'] = '#464646'\n#plt.rcParams['axes.edgecolor'] = '#FFFFFF'\nplt.rcParams['figure.figsize'] = 10, 7\nplt.rcParams['text.color'] = '#666666'\nplt.rcParams['axes.labelcolor'] = '#333333'\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['axes.titlesize'] = 16\nplt.rcParams['xtick.color'] = '#666666'\nplt.rcParams['xtick.labelsize'] = 14\nplt.rcParams['ytick.color'] = '#666666'\nplt.rcParams['ytick.labelsize'] = 14\n\n# plt.rcParams['font.size'] = 16\n\nsns.color_palette('dark')\n%matplotlib inline\n\ntqdm.pandas()","335f5b3c":"dftrain = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ndftest = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\nsample_submission = pd.read_csv('..\/input\/commonlitreadabilityprize\/sample_submission.csv')","6e07fcc6":"sample_submission.head()","6944f78f":"dftrain.shape, dftest.shape","a7596420":"dftrain.head()","2adf729d":"wctrain = dftrain['excerpt'].apply(lambda x: len(x.split()))\nwctest = dftest['excerpt'].apply(lambda x: len(x.split()))","f956cdb5":"wctrain.max()","481f412b":"wctest","479ecfaf":"def clean_text(sentence):\n    # remove numbers\n    pattern = re.compile(r'[0-9]+')\n    sentence = sentence.lower()\n    sentence = pattern.sub(' ', sentence).strip()\n    # remove punctuations\n    newSentence = ''\n    for char in sentence:\n        if char not in punctuation:\n            newSentence += char\n    # Tokenize\n    word_list = word_tokenize(newSentence)\n    # stop words\n    stopwords_list = set(stopwords.words('english'))\n    # remove stop words\n    word_list = [word for word in word_list if word not in stopwords_list]\n    # stemming\n    ps  = PorterStemmer()\n    word_list = [ps.stem(word) for word in word_list]\n    # list to sentence\n    sentence = ' '.join(word_list)\n    \n    return word_list","7ddaa6ef":"dftrain['clean_text'] = dftrain['excerpt'].progress_apply(clean_text)","427895f4":"dftest['clean_text'] = dftest['excerpt'].apply(clean_text)","ccb6eb69":"X = dftrain['clean_text'].to_list()","b3644a36":"# tfidf = TfidfVectorizer()\n# X = tfidf.fit_transform(dftrain['clean_text'])\n# Xtest = tfidf.transform(dftest['clean_text'])","a98432e7":"Xtrain, Xcv, Ytrain, Ycv = train_test_split(X, dftrain['target'], test_size=0.25, random_state=21)","2f524cde":"documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(Xtrain)]\nmodel = Doc2Vec(documents, vector_size=700, window=4, min_count=1, workers=4)","dba9a187":"train_list = [model.infer_vector(doc) for doc in Xtrain]\ncv_list = [model.infer_vector(doc) for doc in Xcv]\ntest_list = [model.infer_vector(doc) for doc in dftest['clean_text'].to_list()]","56a8f1aa":"train_arr = np.array(train_list)\ncv_arr = np.array(cv_list)\ntest_arr = np.array(test_list)","a5f61d29":"def print_summary(model, Xtrain, Ytrain, Xcv, Ycv):\n    Ytrain_pred = model.predict(Xtrain)\n    Ycv_pred = model.predict(Xcv)\n    \n    train_rmse = np.sqrt(metrics.mean_squared_error(Ytrain, Ytrain_pred))\n    cv_rmse = np.sqrt(metrics.mean_squared_error(Ycv, Ycv_pred))\n    \n    print('Training RMSE: {}'.format(train_rmse))\n    print('Validation RMSE: {}'.format(cv_rmse))","b8dbf11a":"xgb = XGBRegressor()\nxgb.fit(train_arr, Ytrain)","08d9e6bf":"print_summary(xgb, train_arr, Ytrain, cv_arr, Ycv)","bcccd956":"xgbrf = XGBRFRegressor()\nxgbrf.fit(train_arr, Ytrain)","e2955ff0":"print_summary(xgbrf, train_arr, Ytrain, cv_arr, Ycv)","250a1226":"Ytest = xgb.predict(test_arr)","ba82a659":"submission = pd.DataFrame({'id': dftest['id'], 'target': Ytest})","94ac5071":"submission.to_csv('submission.csv', index=False)","7ec36e65":"## Prediction","7e3c10cb":"### XGBoost","d2a88d4f":"## Load Data","b2b8c09e":"## Vectorize text data","0a8035bb":"## Train models","d5bea4f2":"## Import Libraries","44ab7f16":"## EDA"}}