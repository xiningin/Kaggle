{"cell_type":{"3c8b41bc":"code","4f1f94b9":"code","63bed83d":"code","3348b5b6":"code","2a40ab2f":"code","4d931d7d":"code","7fa70af7":"code","c9c52f47":"code","6d10a205":"code","cb5fdd1a":"code","83bad158":"code","c023a9b2":"code","e143fe58":"code","8a38627e":"code","bb2770ec":"code","419d22e2":"markdown","c4be0ac4":"markdown","8f505366":"markdown","73d84257":"markdown","08fe02b2":"markdown","19bd10af":"markdown","ea98ec5c":"markdown","9ccb6d75":"markdown","aebb62f1":"markdown","fd0d201a":"markdown","d48def91":"markdown","43a5863f":"markdown","ea413a0f":"markdown","bfb4eaf3":"markdown"},"source":{"3c8b41bc":"import pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Loading data\n        \ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\")\nsub = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv\")","4f1f94b9":"train.head()","63bed83d":"train.shape, test.shape","3348b5b6":"train.dtypes #, test.dtypes","2a40ab2f":"train.isnull().sum().sum(), test.isnull().sum().sum()","4d931d7d":"train.shape","7fa70af7":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.scatter(train['Elevation'], train['Cover_Type'])\nplt.scatter(train['Slope'], train['Cover_Type'])\nplt.scatter(train['Aspect'], train['Cover_Type'])\nplt.show()","c9c52f47":"sns.set()\ncols = ['Elevation', 'Aspect', 'Slope']\nsns.pairplot(train[cols])\nplt.show()","6d10a205":"X = train.drop('Cover_Type', axis=1)\ny = train['Cover_Type']\nX.shape, y.shape","cb5fdd1a":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","83bad158":"from xgboost import XGBClassifier\n\nmodel_xgbc = XGBClassifier()\n\nmodel_xgbc.fit(x_train, y_train, verbose=1)\n#model_xgbc.score(x_train, y_train), model_xgbc.score(x_test, y_test)","c023a9b2":"y_predict_xgbc = model_xgbc.predict(test)","e143fe58":"result = pd.DataFrame()\nresult['Id'] = test['Id']\nresult['Cover_Type'] = y_predict_xgbc\nresult.head()","8a38627e":"result.shape","bb2770ec":"result.to_csv('submission.csv', index=False)","419d22e2":"> ## train_test_split","c4be0ac4":"#### Variance","8f505366":"> ## Submission","73d84257":"> ## Data analysis","08fe02b2":"##### And wow, no missing value\n##### Let's remove our dependent variable and make it y as target variable","19bd10af":"#### Wow no missing value!","ea98ec5c":"#### Correlation","9ccb6d75":"> ## Data visualization","aebb62f1":"> ## Data modelling aka ML","fd0d201a":"##### Wow so amused to see that there are all integer variables.","d48def91":"**Hi all, this is my 2nd Kaggle notebook. Please support.**\n#### 1st one can be found here -> [Easiest price prediction, full explanation](http:\/\/www.kaggle.com\/zwartfreak\/easiest-price-prediction-full-explanation)","43a5863f":"> ## Finding and treating missing values","ea413a0f":"* XGBoost","bfb4eaf3":"##### This problem is a multiclass classification problem, which requires dense classification or neural networks involvement.\n#### **Also, this dataset is very hige, we have to reduce it somehow without losing any relevant data.**\n##### This notebook is not complete yet.\n### Task: Reducing the dataset size as this is taking too much time"}}