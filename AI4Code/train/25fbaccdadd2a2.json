{"cell_type":{"d3c64c97":"code","3fbbd4ac":"code","f53abbc9":"code","a98735e7":"code","690e8a00":"code","af4cd83e":"code","86cda1f4":"code","b4e559a2":"code","f7e538ec":"code","6205719b":"code","11f87141":"code","fef19085":"code","450d504d":"code","19a94bb5":"code","172f95c6":"code","875b1cab":"code","c0720009":"code","3d5ed858":"code","d9b517ac":"markdown","86084e3c":"markdown","d39762d5":"markdown","b4d698fc":"markdown","70aaa981":"markdown","7199b46e":"markdown","557d9f11":"markdown","054fc16d":"markdown","27eb434d":"markdown","6b8df49d":"markdown","82df2990":"markdown","ac4a6eaa":"markdown","46a4741d":"markdown","60a13691":"markdown"},"source":{"d3c64c97":"# Importing all neccessary packages\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n# Data Visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix\n\n# Classifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n# Models\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n\n# Data Cleaning\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# Pipeline\nfrom sklearn.pipeline import Pipeline\n\nprint('Import complete')","3fbbd4ac":"# Importing training and test data\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv', index_col='PassengerId')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\nprint('Data loaded')","f53abbc9":"train_data.head()","a98735e7":"train_data.shape","690e8a00":"num_data = train_data.select_dtypes(exclude='object')\ncorr = num_data.corr()\nsns.heatmap(corr)\n","af4cd83e":"num_data = train_data.select_dtypes(exclude='object')\ncat_data = train_data.select_dtypes(include='object')","86cda1f4":"num_data.isna().sum()","b4e559a2":"num_data = num_data.drop('Survived', axis=1)","f7e538ec":"cat_data.head()","6205719b":"cat_data.isna().sum()","11f87141":"len(cat_data.Ticket.unique())","fef19085":"cat_data = cat_data.drop(['Cabin', 'Ticket', 'Name'], axis=1)\n#num_data = num_data.drop(['Fare'], axis=1)","450d504d":"data_copy = train_data.copy()\n\ncat_cols_to_drop = ['Cabin', 'Ticket', 'Name']\ndata_copy = data_copy.drop(cat_cols_to_drop, axis=1)\n\n#num_cols_to_drop = ['Fare']\n#data_copy = data_copy.drop(num_cols_to_drop, axis=1)\n\n\n\ndata_copy.Embarked = data_copy.Embarked.fillna('S')\ndata_copy.isna().sum()","19a94bb5":"X = data_copy.drop('Survived', axis=1)\ny = data_copy['Survived']\n\nnumerical_transformer = SimpleImputer(strategy='median')\ncategorical_transformer = OneHotEncoder()\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, num_data.columns),\n    ('cat', categorical_transformer, cat_data.columns)\n])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n","172f95c6":"from sklearn.model_selection import GridSearchCV\n\nrf_classifier = RandomForestClassifier(n_estimators=100)\nxgb_classifier = XGBClassifier(nthread=4, n_estimators=100, learning_rate=0.05)\n\n\n\nrf_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', rf_classifier)])\nxgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', xgb_classifier)])\n\n\n\nxgb_pipeline.fit(X_train, y_train)\nprint(\"model score: %.3f\" % xgb_pipeline.score(X_test, y_test))","875b1cab":"# Applying all data cleaning to the test data\n\ntest_X = test_data.copy()\n\ntest_X = test_X.drop(cat_cols_to_drop, axis=1)\ntest_X = test_X.drop('PassengerId', axis=1)","c0720009":"test_preds = xgb_pipeline.predict(test_X)\ntest_preds","3d5ed858":"output = pd.DataFrame({'PassengerId': test_data.PassengerId,\n                      'Survived': test_preds})\noutput.to_csv('submission.csv', index=False)\nprint('Submitted')","d9b517ac":"About 900 rows and 11 columns.","86084e3c":"These are the test predictions that will be submitted to the competition.","d39762d5":"The model score ranges from about 0.75 to 0.83 with different training and validation sets. Will probably implement cross-validation to get a more reliable score.","b4d698fc":"We can see very clear trends for which people are survivng and which dont. For example females had a higher chance to survive than males.","70aaa981":"# 1. EDA (exploratory data analysis)","7199b46e":"687 of 891 Cabin Numbers are not available. <br>\nThe 'Ticket' column contains 681 unique categorical values. This would be useless to one-hot-encode. <br>\nName of passenger doesnt have influence on the probability to die. <br>\n\nSo I will remove the 'Cabin', 'Ticket' and 'Name' column.","557d9f11":"Next, the data has to be split in categorical and numerical data to make data cleaning a lot easier.","054fc16d":"It looks like we have 177 missing entries in the 'Age' column.\nI will use the SimpleImputer form sklearn to get mean values for those missing Ages.","27eb434d":"# 3. Creating Pipelines","6b8df49d":"# 2. Data Cleaning","82df2990":"# 4. Predictions and Submission","ac4a6eaa":"# Numerical Data","46a4741d":"# Categorical Data","60a13691":"# Titanic Survival Prediction (Classifier)\n<br>\n\nThis is still a work in progress! <br>\nTo-do:\n* Cross Validation\n* Searching for outliers \/ wrong data\n* Feature Engineering\n* Try other models and tune model parameters"}}