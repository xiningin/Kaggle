{"cell_type":{"98b91ed4":"code","2b91245c":"code","3e331e01":"code","38c31304":"code","755de2fd":"code","78267365":"code","7c8c305a":"code","0d3657d0":"code","620af80f":"code","c83802e9":"code","7ac1889b":"code","cca4f107":"code","2efd9a4c":"code","5b7d4c52":"code","3923fd76":"code","f250b66e":"code","d4800089":"code","e8562cbf":"code","355e9f72":"code","4c649931":"code","edcf2d6b":"markdown","db1af250":"markdown","c31e0254":"markdown","4ee3e944":"markdown","2b5ad7d6":"markdown","6427b0e4":"markdown","80725000":"markdown","0ce5cb23":"markdown","86a7056d":"markdown","f60974fb":"markdown","11088166":"markdown","567ec191":"markdown","09ad22d8":"markdown","fd2af683":"markdown","d7117340":"markdown","1c0e56cc":"markdown","15915501":"markdown"},"source":{"98b91ed4":"!pip install tez -q","2b91245c":"import gc\nimport pandas as pd\nimport numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport transformers\nimport tez\nfrom transformers import AdamW, AutoTokenizer, AutoModel\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nimport time\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\nimport optuna","3e331e01":"class Config:\n    model_name = 'roberta-base'\n    batch_size = 96\n    lr = 1e-4\n    weight_decay = 0.01\n    scheduler = 'CosineAnnealingLR'\n    early_stopping_epochs = 1\n    epochs = 20\n    max_length = 128","38c31304":"class ToxicDataset:\n    def __init__(self, data, tokenizer, max_len):\n        self.comments = data['comment_text'].values\n        self.tokenizer = tokenizer\n        self.targets = data[[\n            'toxic', 'severe_toxic', 'obscene',\n            'threat','insult', 'identity_hate']].values\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.comments)\n    \n    def __getitem__(self, idx):\n        \n        tokenized = self.tokenizer.encode_plus(\n            self.comments[idx],\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length'\n        )\n        \n        input_ids = tokenized['input_ids']\n        attention_mask = tokenized['attention_mask']\n        \n        toxic, severe_toxic, obscene, threat, insult, identity_hate = self.targets[idx]\n\n        return {\n            'input_ids' : torch.tensor(input_ids, dtype=torch.long),\n            'attention_mask' : torch.tensor(attention_mask, dtype=torch.long),\n            'toxic' : torch.tensor(toxic, dtype=torch.float),\n            'severe_toxic' : torch.tensor(severe_toxic, dtype=torch.float),\n            'obscene' : torch.tensor(obscene, dtype=torch.float),\n            'threat' : torch.tensor(threat, dtype=torch.float),\n            'insult' : torch.tensor(insult, dtype=torch.float),\n            'identity_hate' : torch.tensor(identity_hate, dtype=torch.float)\n        }","755de2fd":"class ToxicModel(nn.Module):\n    def __init__(self, args, model_name):\n        super(ToxicModel, self).__init__()\n        self.args = args\n        self.model = AutoModel.from_pretrained(self.args.model_name)\n        self.dropout = nn.Dropout(p=0.2)\n        self.toxic = nn.Linear(768, 1)\n        self.stoxic = nn.Linear(768, 1)\n        self.obs = nn.Linear(768, 1)\n        self.threat = nn.Linear(768, 1)\n        self.insult = nn.Linear(768, 1)\n        self.id_hate = nn.Linear(768, 1)\n    \n        \n    def forward(self, input_ids, attention_mask):\n        \n        out = self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            output_hidden_states=False\n        )\n        \n        out = self.dropout(out[1])\n        \n        toxic = self.toxic(out)\n        stoxic = self.stoxic(out)\n        obs = self.obs(out)\n        threat = self.threat(out)\n        insult = self.insult(out)\n        id_hate = self.id_hate(out)\n\n        return [toxic, stoxic, obs, threat, insult, id_hate]\n        ","78267365":"def loss_fn(outputs, targets):\n    o1, o2, o3, o4, o5, o6 = outputs\n    t1, t2, t3, t4, t5, t6 = targets\n    l1 = nn.BCEWithLogitsLoss()(o1, t1.view(-1,1))\n    l2 = nn.BCEWithLogitsLoss()(o2, t2.view(-1,1))\n    l3 = nn.BCEWithLogitsLoss()(o3, t3.view(-1,1))\n    l4 = nn.BCEWithLogitsLoss()(o4, t4.view(-1,1))\n    l5 = nn.BCEWithLogitsLoss()(o5, t5.view(-1,1))\n    l6 = nn.BCEWithLogitsLoss()(o6, t6.view(-1,1))\n    \n    total_loss = (l1+l2+l3+l4+l5+l6)\/6\n    \n    return total_loss","7c8c305a":"def metrics(outputs, targets):\n    auc_scores=[]\n    for o, t in zip(outputs, targets):\n        o = o.cpu().detach().numpy()\n        t = t.cpu().detach().numpy()\n        auc = roc_auc_score(o, t)\n        auc_scores(auc)\n\n    return np.mean(auc_scores)","0d3657d0":"def train_epoch(args, dataloader, model, optimizer, scheduler, epoch):\n    model.train()\n    epoch_loss = 0.0\n    running_loss = 0.0\n    dataset_size=0\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        optimizer.zero_grad()\n        \n        input_ids = data['input_ids'].cuda()\n        attention_mask = data['attention_mask'].cuda()\n        toxic = data['toxic'].cuda()\n        severe_toxic = data['severe_toxic'].cuda()\n        obscene = data['obscene'].cuda()\n        threat = data['threat'].cuda()\n        insult = data['insult'].cuda()\n        identity_hate = data['identity_hate'].cuda()\n        \n        batch_size = args.batch_size\n        \n        targets = (toxic, severe_toxic, obscene, threat, insult, identity_hate)\n        outputs = model(input_ids, attention_mask)\n        \n        \n        loss = loss_fn(outputs, targets)\n\n        \n        loss.backward()\n        optimizer.step()\n        if scheduler is not None:\n            scheduler.step()\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss = running_loss \/ dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    return epoch_loss","620af80f":"def validation(args, dataloader, model):\n    model.eval()\n    epoch_loss = 0.0\n    running_loss = 0.0\n    dataset_size=0\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = args.batch_size\n\n            input_ids = data['input_ids'].cuda()\n            attention_mask = data['attention_mask'].cuda()\n            toxic = data['toxic'].cuda()\n            severe_toxic = data['severe_toxic'].cuda()\n            obscene = data['obscene'].cuda()\n            threat = data['threat'].cuda()\n            insult = data['insult'].cuda()\n            identity_hate = data['identity_hate'].cuda()\n\n            targets = (toxic, severe_toxic, obscene, threat, insult, identity_hate)\n\n            outputs = model(input_ids, attention_mask)\n\n            loss = loss_fn(outputs, targets)\n\n            running_loss += (loss.item() * batch_size)\n            dataset_size += batch_size\n\n            epoch_loss = running_loss \/ dataset_size\n\n            bar.set_postfix(Valid_Loss=epoch_loss,\n                            Stage='Validation') \n    return epoch_loss","c83802e9":"def get_optimizer(args, params):\n    opt = AdamW(params, lr=args.lr, weight_decay=args.weight_decay)\n    return opt","7ac1889b":"def get_scheduler(args, optimizer):\n    if args.scheduler == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=500, \n                                                   eta_min=1e-6)\n    else:\n        schduler = None\n    return scheduler","cca4f107":"def run(data, fold, args=None, save_model=False):\n    print('-'*50)\n    print(f'Fold : {fold}')\n    print('-'*50)\n    \n    if args is None:\n        args = Config()\n        \n    start = time.time()\n    model = ToxicModel(args, args.model_name)\n    model = model.cuda()\n    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n    \n    optimizer = get_optimizer(args, model.parameters())\n    scheduler = get_scheduler(args, optimizer)\n    \n    train = data[data['kfold']!=fold]\n    valid = data[data['kfold']==fold]\n    \n    train_dataset = ToxicDataset(train, tokenizer, args.max_length)\n    valid_dataset = ToxicDataset(valid, tokenizer, args.max_length)\n    \n    train_loader = DataLoader(train_dataset, batch_size=args.batch_size)\n    valid_loader = DataLoader(valid_dataset, batch_size=2*args.batch_size)\n    \n    best_val_loss = np.inf\n    patience_counter = 0\n\n    for epoch in range(args.epochs):\n        train_loss = train_epoch(args, train_loader, model, optimizer, scheduler, epoch)\n        \n        valid_loss = validation(args, valid_loader, model)\n        \n        if valid_loss <= best_val_loss:\n            print(f\"Validation Loss Improved ({best_val_loss} ---> {valid_loss})\")\n            best_val_loss = valid_loss\n            \n            if save_model:\n                PATH = f\"model_fold_{fold}.bin\"\n                torch.save(model.state_dict(), PATH)\n                print(f\"----------Model Saved----------\")\n        \n        else:\n            patience_counter += 1\n            print(f'Early stopping counter {patience_counter} of {args.early_stopping_epochs}')\n            if patience_counter == args.early_stopping_epochs:\n                print('*************** Early Stopping ***************')\n                break\n    \n    end = time.time()\n    time_elapsed = end-start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 3600, (time_elapsed % 3600) \/\/ 60, (time_elapsed % 3600) % 60))\n    print(\"Best Loss: {:.4f}\".format(best_val_loss))\n    \n    del model, train_loader, valid_loader\n    gc.collect()\n    return best_val_loss","2efd9a4c":"df = pd.read_csv('..\/input\/multi-label-stratified-k-fold-toxic-comments\/5folds.csv')","5b7d4c52":"df = df.dropna()","3923fd76":"df.isnull().sum()","f250b66e":"# df_trial = df[:100]","d4800089":"# def objective(trial):\n#     args = Config()\n#     args.epochs=1\n#     args.lr = trial.suggest_uniform('lr',1e-6, 1e-3)\n#     all_losses = []\n#     for fold in range(5):\n#         temp_loss = run(df_trial, fold, args=args)\n#         all_losses.append(temp_loss)\n    \n#     return np.mean(all_losses)","e8562cbf":"# study = optuna.create_study(direction='minimize')\n# study.optimize(objective, n_trials=10)\n\n# print('Best Trial:')\n# trial_ = study.best_trial\n# print(trial_.values)","355e9f72":"# trial_.params['lr']","4c649931":"args=Config()\nargs.lr = 0.0005149849355804644\nrun(df, fold=0, save_model=True, args=args)","edcf2d6b":"# Loss Function","db1af250":"# Scheduler","c31e0254":"# Optuna","4ee3e944":"# Validation Epoch","2b5ad7d6":"# The Model","6427b0e4":"# Using Toxic Comment Classification\n\nHere I have used the multi-label Toxic Comment Classification Dataset (by Jigsaw).\n\nI have used Roberta-base to predict 6 different outputs each belonging to one label (toxic, severe_toxic, etc...)\n\nI have not passed the output logits through any sigmoid function. Just used the outputs for these 6 labels and taken a linear average of them.\n\nThat's what I have used as the score for comparison.\n\n#### I have used:\n\n* BCELogitsLoss as the loss funtion : It already applies a sigmoid function on the output before calculating the loss\n* Early stooping with a patience of 1 : You can modify according to your need\n* Used CosineAnnealingLR scheduler : It changes the LR per step following a cosine funtion.\n\n","80725000":"It has 6 output heads giving outputs to the 6 different labels to determine.\n\nThis 6 different heads are attached on top the roberta-base (for now) will implement roberta-large too.","0ce5cb23":"# Training and validation Loop","86a7056d":"I have used 5 folds that I have cleaned using this notebook: [Multi-Label Stratified K-fold | Toxic Comments](https:\/\/www.kaggle.com\/kishalmandal\/multi-label-stratified-k-fold-toxic-comments)\n\nThe data is the same data used in the toxicity classification challenge by Jigsaw","f60974fb":"# Run training","11088166":"### Please <span style=\"color:red\">UPVOTE<\/span> If it Helps :)\n\nModel used : RoBERTa-base (RoBERTa-large is way too big and takes a whole lot of time training O.o)\n\n#### The Inference Kernel : [INFER | ToxicComments | \ud83c\udf1f](https:\/\/www.kaggle.com\/kishalmandal\/inference-comments\/edit)\n\n**I have trained only 2 folds till now and got 0.798 on the LB (made public)**","567ec191":"# Config","09ad22d8":"## The final layer of the model looks like this:\n\n ![NN](https:\/\/user-images.githubusercontent.com\/74188336\/141213710-3a1b7473-8436-4683-841e-64d87789f47e.png)","fd2af683":"# Training epoch","d7117340":"# Optimizer","1c0e56cc":"# Read the data","15915501":"# Dataset"}}