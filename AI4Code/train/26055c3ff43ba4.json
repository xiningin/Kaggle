{"cell_type":{"d5776d8b":"code","ba56aa4a":"code","725b97fb":"code","42e0a4c9":"code","22c7813d":"code","d8bbcd1c":"code","60521a1a":"code","c7ae08cc":"code","8657e0dc":"code","3fe07842":"code","159840c2":"code","7578edd9":"code","302bdd61":"code","3bf548f5":"code","1bf8f565":"code","0a7eb378":"code","48a87c89":"code","75273b5d":"code","be4b2244":"code","88afb47f":"code","ef72c834":"code","7b736c0a":"code","aebb7994":"code","26f796b5":"code","dfe2f7db":"code","188a01c0":"code","e64fadbb":"code","d724e99b":"code","68bbbbd2":"code","e4f2d918":"markdown","995e5e18":"markdown","7e3ac233":"markdown","7f0539b4":"markdown","44a5d309":"markdown","9114098d":"markdown","2fd69519":"markdown","9d983b63":"markdown","74aef353":"markdown","2fe23902":"markdown","1149d3a2":"markdown","5777f1af":"markdown","5e44b721":"markdown","b18d05f1":"markdown","9f29d6cd":"markdown","93dae2b9":"markdown","b56bd569":"markdown","9b3707d4":"markdown","b7067eab":"markdown","d8628fe3":"markdown","840c126b":"markdown","4574d11b":"markdown","9783d2ee":"markdown","4329f94b":"markdown","d134463b":"markdown"},"source":{"d5776d8b":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport datetime as dt\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ba56aa4a":"df = pd.read_csv('\/kaggle\/input\/retailtransactiondata\/Retail_Data_Transactions.csv')\ndf.head()","725b97fb":"df.info()","42e0a4c9":"data_missing_value = df.isnull().sum().reset_index()\ndata_missing_value.columns = ['feature','missing_value']\ndata_missing_value","22c7813d":"numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndisplay(df.select_dtypes(include=numerics).columns)\nprint(df.select_dtypes(include=numerics).shape)\ndata_num = df.select_dtypes(include=numerics)\ndata_num.head(3)","d8bbcd1c":"display(df.select_dtypes(include=['object']).columns)\nprint(df.select_dtypes(include=object).shape)\ndata_cat = df.select_dtypes(include=['object'])\ndata_cat.head(3)","60521a1a":"#convert string to date type\ndf['trans_date'] = pd.to_datetime(df['trans_date'])","c7ae08cc":"df['trans_date'] = df['trans_date'].dt.strftime('%Y-%m-%d')","8657e0dc":"df['trans_date'] = df['trans_date'].astype('datetime64[ns]')","3fe07842":"#first and last date available in our dataset\nprint(df['trans_date'].min(), df['trans_date'].max())","159840c2":"#use latest date in our data as current date\nimport datetime as dt\nnow = dt.datetime(2015,3,17)\ndf['hist']=now - df['trans_date']\ndf['hist'].astype('timedelta64[D]')\ndf['hist']=df['hist'] \/ np.timedelta64(1, 'D')\ndf.head()","7578edd9":"df.head()","302bdd61":"#groupby `customer_id` and aggregate the three features to become new features.\nrfm_table = df.groupby('customer_id').agg({'hist': lambda x:x.min(),# Recency\n                                        'customer_id': lambda x: len(x),# Frequency\n                                        'tran_amount': lambda x: x.sum()})# Monetary Value","3bf548f5":"#change the column name to `recency`,` frequency`, and `monetary`\nrfm_table.rename(columns={'hist': 'recency', \n                         'customer_id': 'frequency', \n                         'tran_amount': 'monetary'}, inplace=True)","1bf8f565":"rfm_table.head()","0a7eb378":"#check the value from one of the customer data\ndf[df['customer_id']=='CS1112']","48a87c89":"rfm_table.describe()","75273b5d":"#create a new data frame from the dataframe `rfm_table`\nrfm_segmentation = rfm_table.copy()","be4b2244":"feats = ['recency','frequency','monetary']\nX = rfm_segmentation[feats].values\n\nfrom sklearn.preprocessing import StandardScaler\nX_std = StandardScaler().fit_transform(X)\nnew_df = pd.DataFrame(data = X_std, columns = feats)\nnew_df.describe()","88afb47f":"#K-Means Internal Evaluation: Elbow Method\nfrom sklearn.cluster import KMeans\ninertia = []\n\nfor i in range(1, 11):\n  kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n  kmeans.fit(new_df.values)\n  inertia.append(kmeans.inertia_)\n\nplt.figure(figsize=(12, 6))\nplt.plot(inertia)","ef72c834":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\nkmeans.fit(new_df.values)","7b736c0a":"#make new column `fit` with cluster values\nnew_df['cluster'] = kmeans.labels_","aebb7994":"#check our hypothesis\nnew_df[new_df.cluster == 0].head()","26f796b5":"#see the distribution of recency feature based on cluster\nsns.boxplot(new_df.cluster,new_df.recency)","dfe2f7db":"#see the distribution of frequency feature based on cluster\nsns.boxplot(new_df.cluster,new_df.frequency)","188a01c0":"#see the distribution of monetary feature based on cluster\nsns.boxplot(new_df.cluster,new_df.monetary)","e64fadbb":"#see clustering distribution based on three features\nsns.scatterplot(data=new_df, x='monetary', y='recency', size='frequency', \n                hue='cluster')","d724e99b":"from sklearn.cluster import AgglomerativeClustering\nac = AgglomerativeClustering(n_clusters=3)\nac.fit(new_df.values)","68bbbbd2":"#see clustering distribution based on three features\nsns.scatterplot(data=new_df, x='monetary', y='recency', size='frequency',\n                hue='cluster')","e4f2d918":"**The maximum data of the last transaction is taken as a reference for calculating the recency value.<\/br>\nThe maximum data is then added by one day so that there are no blank values.**","995e5e18":"**The cluster results from K-Means Clustering are put into the `cluster` column**","7e3ac233":"## Check Null and Missing Values","7f0539b4":"**Besides using k-means clustering, I also use aggomerative clustering to compare the customer segmentation of the two clustering models.**","44a5d309":"**Based on the results of the elbow method, to obtain the optimal number of clusters, a point is chosen after the inertia begins to decline linearly.<\/br>\nSo that the optimal number of clusters for the model to be carried out is three clusters.**","9114098d":"**standardization is done so that the distance of each feature is the same and makes machine learning fair and not in favor of one feature.**","2fd69519":"# Modeling","9d983b63":"## Load Dataset ","74aef353":"**There are no duplicate data in this dataset**","2fe23902":"# Load and Describe Data","1149d3a2":"## Convert `trans_date` column to date data type","5777f1af":"**Objective**<br>\n* create prediction models to determine customer segmentation based on RFM features<\/br>\n\n**About The Dataset**\n* This dataset is obtained from [Retail Transaction Data | Kaggle](https:\/\/www.kaggle.com\/regivm\/retailtransactiondata)","5e44b721":"**There is no significant difference from the results of the two clustering models, so that customer segmentation is carried out in 3 clusters based on their RFM features.**","b18d05f1":"**Features which are numeric and non-numeric data are separated into two different objects.<\/br>\nthe `tran_amount` feature is numeric data<\/br>Change the date data type in the `tran_date` feature to be an integer based date data type\nthe `customer_id` and` tran_date` features are non-numeric data**","9f29d6cd":"# Data Pre-Processing","93dae2b9":"# Features Standardization","b56bd569":"## Make recency, frequency, and monetary column from `customer_id` groupby","9b3707d4":"## Numerical Data","b7067eab":"## Data Description","d8628fe3":"# Introduction","840c126b":"**Loyal customers have low `recency` values and high `frequency` and `monetary` values, while regular customers have high `recency` values and lower `frequency` and `monetary` values.<\/br>\nIt can be seen in the `recency`,` frequency`, and `monetary` feature boxplot that the order of customers from most loyal to regular customers is cluster 2, cluster 1, and cluster 0**","4574d11b":"**Change the date data type in the `tran_date` feature to be an integer based date data type**","9783d2ee":"## Non Numerical Data","4329f94b":"## Agglomerative Clustering","d134463b":"## K-Means Clustering"}}