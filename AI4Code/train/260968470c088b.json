{"cell_type":{"74488bbf":"code","341c01d9":"code","dd5eeb9f":"code","e1eda958":"code","45ef588a":"code","2069b758":"code","4c6d51b1":"code","3d8a6a4a":"code","b0c23b3f":"code","b0b9467d":"code","240720ff":"code","dd14e643":"code","fa4ed8fa":"code","62ace599":"code","58405727":"code","491f4658":"code","5b6ebe59":"code","f99b32e5":"code","55bd4279":"code","cf06af61":"code","8ce7d55d":"code","e324a7a9":"markdown","e3a3a395":"markdown"},"source":{"74488bbf":"# importing Required Packages \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nimport statsmodels.api as sm\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns","341c01d9":"from sklearn.neighbors import KNeighborsClassifier","dd5eeb9f":"# Reading the Data\ndata=pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")","e1eda958":"data","45ef588a":"# Finding the Null Values\ndata.isnull().sum()","2069b758":"#Verifying The Correlation between Independent Variables\nsns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.heatmap(data.corr(),annot=True)\n","4c6d51b1":"# Building a Logistic Regression Model\nlogreg=LogisticRegression()","3d8a6a4a":"# Performing Recursive Feature Elimination to Pick out Best Features available\nrfe=RFE(logreg,5)","b0c23b3f":"y=data.pop(\"DEATH_EVENT\")\nX=data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n","b0b9467d":"model=rfe.fit(X_train,y_train)","240720ff":"rfe.support_","dd14e643":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","fa4ed8fa":"# Fitting a Logistic Regression model to the train data\nlogreg.fit(X_train,y_train)","62ace599":"y_train_pred=logreg.predict(X_train)\ny_test_pred=logreg.predict(X_test)","58405727":"# Predicting it with the test data \nlogreg.score(X_test,y_test)","491f4658":"\n# Performing Logsistic Regresion using Stats models for better Statistical analysis\nlogml=sm.GLM(y_train,(sm.add_constant(X_train)),family=sm.families.Binomial())","5b6ebe59":"#predicting Accuracy by removing columns \nfor i in X_train.columns:\n    X_train_df=X_train.drop(i,axis=1)\n    X_test_df=X_test.drop(i,axis=1)\n    logreg.fit(X_train_df,y_train)\n    y_train_pred=logreg.predict(X_train_df)\n    y_test_pred=logreg.predict(X_test_df)\n    print(metrics.accuracy_score(y_test_pred, y_test), i)\n    \n    ","f99b32e5":"# Predicting Using KNN \nfor i in range(1,10,2):\n    neigh = KNeighborsClassifier(n_neighbors=i)\n    neigh.fit(X_train, y_train)\n    Y_train_pred=neigh.predict(X_train)\n    Y_test_pred=neigh.predict(X_test)\n    print(neigh.score(X_test,y_test),\" \",i)\n    ","55bd4279":"#Performing Random Forest Modeling\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(random_state=1)\nclf.fit(X_train, y_train)","cf06af61":"Y_test_pred=clf.predict(X_test)","8ce7d55d":"clf.score(X_test,y_test)","e324a7a9":"For the above methods, the accuracy is as follows :\n\nLogistic Regression -> 86%\nKNN                 -> 68 %\nRandom Forest       -> 93%\n\nRandom-Forest Fits the Model and becomes the best precdictor for the Heart Failure Data ","e3a3a395":"Variables are not correlated "}}