{"cell_type":{"5bbfe49b":"code","84a115ea":"code","1a561f83":"code","32deb1c1":"code","ef811710":"code","fbe3ce78":"code","3fb4e323":"code","396bbf1c":"code","4010036b":"code","0fdadc16":"code","9a87586b":"code","cdce902b":"code","c37b4c59":"code","4708f8b8":"code","63c2a823":"code","d71e1225":"code","527077b0":"code","8a1ec5e0":"code","d7ece55a":"code","c9bad4c7":"code","118dc534":"code","26f55e40":"code","d05e9878":"code","dd7ca18e":"code","bcfa6448":"code","eae46f17":"code","fbdda507":"code","f636cf07":"code","0f6e47ba":"code","6f8a7159":"code","9b49254f":"code","3590c17c":"code","aa96abbe":"code","6797e6ae":"code","31e33198":"code","9ad28789":"code","6f556438":"code","857e78b3":"code","daff3ded":"code","1cbe1bd2":"code","09cfc4c1":"code","d4945d3a":"code","fae1a598":"code","4167ceea":"code","a2294675":"code","edf3c9c8":"code","d8f4bbba":"code","59d086cf":"code","4e6fea4e":"code","fa9defa0":"code","d8910954":"code","62d192c1":"code","4f9c8ec8":"code","2a11b638":"code","33105622":"code","7db90cb4":"code","3d00be1e":"code","6c27055b":"code","263aa8c0":"code","dc70105b":"code","bda410ca":"code","54950941":"code","30bbcd7a":"code","5a0139ae":"code","f9cdb9c0":"code","f66c012e":"code","9d45b3ae":"code","b35c67ac":"code","165a57e7":"code","d62f9eb1":"code","e646afb6":"code","21079e9b":"code","212a9647":"code","cdcae8cf":"code","45638f2a":"code","c27b04d7":"code","26fb4cf1":"code","e67be6d9":"code","b5d7a586":"code","2048375b":"code","ac30948b":"markdown","762c03c5":"markdown","80dbab84":"markdown","18054a73":"markdown","cd9f8623":"markdown","d08403a0":"markdown","b76487ec":"markdown","8678e683":"markdown","5738f07f":"markdown","db4fd94a":"markdown","f729002f":"markdown","edae7a03":"markdown","32e221e1":"markdown","b5732a87":"markdown","ec6774be":"markdown","a322b0de":"markdown","4511a85a":"markdown","ae35e9ac":"markdown","8f718165":"markdown","f3822387":"markdown","d2472aa1":"markdown"},"source":{"5bbfe49b":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport missingno as msno\nimport yaml\nfrom collections import Counter\nimport plotly.graph_objects as go\nimport plotly.express as xp\n\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.manifold import TSNE\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.metrics import accuracy_score\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\ncolormap = ['#050A30', '#000C66', '#0000FF', '#7EC8E3', '#D4F1F4']\nsns.palplot(colormap)","84a115ea":"# Let's read the files and check the info\nPATH = \"..\/input\/mymusicalprefrences\/\" \ntrain_data = pd.read_csv(f\"{PATH}train.csv\")\ntest_data = pd.read_csv(f\"{PATH}test.csv\")\ndescription = yaml.load(open(f\"{PATH}Description.yaml\",'r'),Loader=yaml.FullLoader)\n\n# We merge train- and test-data for now\ndf = pd.concat([train_data,test_data], axis = 0, ignore_index = True)\ntrain_mask = ~df.Category.isna()\ndf.info()","1a561f83":"df","32deb1c1":"df.describe()","ef811710":"# Plot missing values\nmsno.bar(df, color=colormap)","fbe3ce78":"df.columns","3fb4e323":"# Rename some features\n\n# Remove the space after 'Vocal '\ndf = df.rename(columns = {'Vocal ':'Vocal'})\n\n# (Optional) Remove '_'\ndf = df.rename(columns = {'Artists_Genres':'ArtistsGenres', 'Release_year':'ReleaseYear', 'Album_type':'AlbumType'})\n\n# (Optional) Correct spelling mistakes\ndf = df.rename(columns = {'Dancebility':'Danceability'})\ndf.columns","396bbf1c":"# Let's see the categorical and numerical features\n\ncategorical_features = {\"Artists\",\"Track\",\"Version\",\"ArtistsGenres\",\"Album\",\"AlbumType\",\"Labels\",\"Vocal\",\"Country\",\"Key\"}\nnumerical_features = {\"Duration\",\"ReleaseYear\",\"BPM\",\"Energy\",\"Danceability\",\"Happiness\"}\ndisplay(df[categorical_features].head())\ndisplay(df[numerical_features].head())","4010036b":"# Let's check for some dependencies visually\nsns.pairplot(df[list(numerical_features)+[\"Category\"]],palette=colormap[2:4], hue=\"Category\")","0fdadc16":"# For more easy usage of the Category feature\ndf[\"Category\"] = df[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})","9a87586b":"# Let's check the missing value(s) in 'Artists'\ndf.loc[df['Artists'].isna()==True]","cdce902b":"# We can drop this record as it has the least amount of parameters\ndf = df.drop([661])\ndf = df.reset_index(drop=True)\ndf.loc[df['Artists'].isna()==True]","c37b4c59":"# Let's check the missing value(s) in 'Album'\ndf.loc[df['Album'].isna()==True]","4708f8b8":"# We replace it with 'none'\ndf[\"Album\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Album'].isna()==True]","63c2a823":"# Let's check the missing value(s) in 'Vocal'\ndf.loc[df['Vocal'].isna()==True]","d71e1225":"# We replace it with 'none'\ndf[\"Vocal\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Vocal'].isna()==True]","527077b0":"# Let's check the missing value(s) in 'Country'\ndf.loc[df['Country'].isna()==True]","8a1ec5e0":"# We replace it with 'none'\ndf[\"Country\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Country'].isna()==True]","d7ece55a":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['Labels'].isna()]","c9bad4c7":"# We replace it with 'none'\ndf[\"Labels\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Labels'].isna()==True]","118dc534":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['Version'].isna()]","26f55e40":"# We replace it with 'none'\ndf[\"Version\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Version'].isna()==True]","d05e9878":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['AlbumType'].isna()]","dd7ca18e":"# We replace it with 'none'\ndf[\"AlbumType\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['AlbumType'].isna()==True]","bcfa6448":"msno.bar(df, color=colormap)","eae46f17":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which are only present in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique genre values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimensionality of the dataset.\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    \n    return embedded\n\ndef plot_cumulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation.\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k,marker=dict(color=colormap[i+1])))\n    fig.show()","fbdda507":"# Let's see how the description\nprint(description[\"Country\"])","f636cf07":"# We split to onehot vector and plot the countries\ncountry_onehot = split_to_onehot(df, \"Country\")\nplot_cumulative_onehot(country_onehot)","0f6e47ba":"# We drop the old column and replace it by the new onehot vector\ncountry_onehot = country_onehot.drop(\"Category\", axis=1)\ndf = pd.concat([df,country_onehot], axis=1)\ndf = df.drop([\"Country\", \"none\"], axis=1)\ndf.head()","6f8a7159":"# Let's check what is in 'Vocal'\nprint(description[\"Vocal\"])","9b49254f":"# Create a new array and split the vocal types\nonehot = np.zeros((len(df),2))\nfor i in range(len(df)):\n    v = df.iloc[i][\"Vocal\"]\n    if v == 'F':\n        onehot[i] = [1,0]\n    elif v == 'M':\n        onehot[i] = [0,1]\n    elif v == 'F|M':\n        onehot[i] = [1,1]\n        \n# We drop the old column and replace it by the new onehot vector\ndf[[\"FemaleVocal\",\"MaleVocal\"]] = onehot\ndf = df.drop(\"Vocal\",axis=1)\ndf.head()","3590c17c":"# Let's check the key feature\ndescription[\"Key\"]","aa96abbe":"# Create a scatterplot\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","6797e6ae":"# We correct some keys and replace them with the same value (C# = D\u266d, etc)\ndf[\"Major\"], df[\"Key\"] = df[\"Key\"].apply(lambda x: x.split(\" \")[1]), df[\"Key\"].apply(lambda x: x.split(\" \")[0])\ndf.loc[:,\"Key\"] = df[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\n\n# Create a scatterplot\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","31e33198":"# We put the Major\/Minor part into new feature, to make it more easy for our model in the fitting process\ndf.loc[:,\"Major\"] = (df[\"Major\"]==\"Major\").astype(int)\n_df = df.groupby([\"Major\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df,x=\"Major\", y=\"Track\",color=\"Category\", height=400, color_discrete_sequence=colormap[1:4])","9ad28789":"# Let's plot a full overview (key + major\/minor)\n_df = df.copy(deep=True)\n_df[\"Key_precise\"] = _df[\"Key\"] +\"_major:\"+ _df[\"Major\"].astype(str)\n_df = _df.groupby([\"Key_precise\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df, x=\"Key_precise\", y=\"Track\", color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","6f556438":"# Replace the old column with our onehot vector\ndf[list(set(df[\"Key\"].values))] = OneHotEncoder().fit_transform(df[[\"Key\"]]).toarray()\ndf = df.drop(\"Key\", axis=1)\ndf.head()","857e78b3":"# Check the description\nfor k in [\"Energy\",\"Happiness\",\"Dancebility\"]:\n    print(f\"{k}:{description[k]}\")","daff3ded":"# Let's scale energy, happiness and danceabilty down proportionally\ndf[['Energy%', 'Happiness%', 'Danceability%']] = df[['Energy', 'Happiness', 'Danceability']].apply(lambda x: x\/sum(x), axis=1)\ndf = df.drop([\"Energy\", \"Danceability\", \"Happiness\"], axis=1)\ndf.head()","1cbe1bd2":"# Let's see how the feature is structured\nprint(description[\"Artists\"])","09cfc4c1":"# How many artists are there\nall_artists = []\nfor i in df.index:\n    all_artists.extend(df.loc[i, \"Artists\"].split(\"|\"))\nlen(set(all_artists))","d4945d3a":"# We will put some threshold, not to put some rare artists into one-hot vector.\nthreshold = 3\nrare_artists = Counter(all_artists)\nrare_artists = [k for k in rare_artists if rare_artists[k]<=threshold]\nlen(rare_artists)","fae1a598":"# Drop all artists who are only in the test-set or the train-set\nin_train, in_test = [], []\nfor i in df.loc[train_mask].index:\n    in_train.extend(df.loc[i, \"Artists\"].split(\"|\"))\nfor i in df.loc[~train_mask].index:\n    in_test.extend(df.loc[i, \"Artists\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\ndisplay(len(only_test))\ndisplay(len(only_train))","4167ceea":"all_artists = list(set(all_artists) - set(rare_artists) - only_test - only_train)\nprint(len(all_artists))\nrare_artists = set(rare_artists) | only_test | only_train\nprint(len(rare_artists))","a2294675":"# Create onehot vector for artists\nresult = []\ndef prune(x):\n    vector = np.zeros(len(all_artists)+1) # for rare artists\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(all_artists)):\n        vector[i]=1 if all_artists[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    result.append(vector)\n\ndf[\"Artists\"].apply(prune)\nonehot_artists = pd.DataFrame(result, columns = all_artists + [\"Others\"], index=df.index)\n\nonehot_artists","edf3c9c8":"# We drop the rare artists (Others) column, it's not really relevant.\nonehot_artists = onehot_artists.drop(\"Others\", axis=1)\n\n# Let's plot the artists\nonehot_artists[\"Category\"] = df[\"Category\"]\nplot_cumulative_onehot(onehot_artists)","d8f4bbba":"# Since there are too many features in the onehot vector, we will apply tsne (dimensionality reduction)\nartists_embedded = onehot_to_tsne2(onehot_artists, \"Artists\")\n_df = artists_embedded.copy(deep=True)\n_df[[\"Category\",\"Artists\"]] = df[[\"Category\",\"Artists\"]]\n\n# Create scatterplot to visualize artists, now reduced to 2 tsne values\nxp.scatter(_df,x=\"Artists_tsne1\",y=\"Artists_tsne2\",color=\"Category\", hover_data=[\"Artists\"], height=500, color_discrete_sequence=colormap[1:4])","59d086cf":"# Replace the old artists column\ndf = pd.concat([df,artists_embedded[[\"Artists_tsne1\",\"Artists_tsne2\"]]], axis=1)\ndf = df.drop(\"Artists\", axis=1)\ndf.head()","4e6fea4e":"# Check what's in the feature\ndescription[\"Release year\"]","fa9defa0":"# Let's create a scatterplot\nxp.scatter(df, x=\"ReleaseYear\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","d8910954":"# Let's create a decade feature, to detect some music of 80s, 90s etc. as a specific genre\ndf.loc[:,\"ReleaseDecade\"] = (df.loc[:,\"ReleaseYear\"]\/\/10 * 10)\n# Because of the small number of values, we will put all <80s values in the 80s genre\ndf.loc[df.loc[:,\"ReleaseDecade\"]<1990,\"ReleaseDecade\"] = 1980 \n_df = df.groupby([\"ReleaseDecade\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"ReleaseDecade\", y=\"Track\",color=\"Category\",height=500, color_discrete_sequence=colormap[1:4])","62d192c1":"# Create onehot vector with the decades\ndf[list(set(df[\"ReleaseDecade\"].values))] = OneHotEncoder().fit_transform(df[[\"ReleaseDecade\"]]).toarray()\ndf = df.drop([\"ReleaseDecade\", \"ReleaseYear\"], axis=1)\ndf.head()","4f9c8ec8":"# Let's see the description\nprint(description[\"Labels\"])","2a11b638":"# Split the lables into onehot vector\nlabels_onehot = split_to_onehot(df, \"Labels\")\nplot_cumulative_onehot(labels_onehot)","33105622":"# Use tsne function to reduce dimensionality\nlabels_embedded = onehot_to_tsne2(labels_onehot, \"Labels\")\n_df = labels_embedded.copy(deep=True)\n_df[[\"Category\",\"Labels\"]] = df[[\"Category\",\"Labels\"]]\n\n# Create scatterplot\nxp.scatter(_df,x=\"Labels_tsne1\",y=\"Labels_tsne2\",color=\"Category\", hover_data=[\"Labels\"], height=500, color_discrete_sequence=colormap)","7db90cb4":"# Replace old column\ndf = pd.concat([df,labels_embedded[[\"Labels_tsne1\",\"Labels_tsne2\"]]], axis=1)\ndf = df.drop(\"Labels\", axis=1)\ndf.head()","3d00be1e":"# Read the description\ndescription[\"Artists Genres\"]","6c27055b":"# To onehot vector\ngenres_onehot = split_to_onehot(df, \"ArtistsGenres\")\nplot_cumulative_onehot(genres_onehot)","263aa8c0":"# We have too much values, so we reduce the dimensionality\ngenres_embedded = onehot_to_tsne2(genres_onehot, \"Genres\")\n_df = genres_embedded.copy(deep=True)\n_df[[\"Category\",\"ArtistsGenres\"]] = df[[\"Category\",\"ArtistsGenres\"]]\n\n# Create scatterplot\nxp.scatter(_df,x=\"Genres_tsne1\",y=\"Genres_tsne2\",color=\"Category\", hover_data=[\"ArtistsGenres\"], height=500, color_discrete_sequence=colormap)","dc70105b":"# Replace the old column\ndf = pd.concat([df,genres_embedded], axis=1)\ndf = df.drop(\"ArtistsGenres\", axis=1)\ndf.head()","bda410ca":"# See description\nprint(description[\"Album\"])","54950941":"# To onehot vector\nalbum_onehot = split_to_onehot(df, \"Album\")\nplot_cumulative_onehot(album_onehot)","30bbcd7a":"# Again, too much values, so reduce to 2 tsne values\nalbum_embedded = onehot_to_tsne2(onehot_artists, \"Album\")\n_df = album_embedded.copy(deep=True)\n_df[[\"Category\",\"Album\"]] = df[[\"Category\",\"Album\"]]\n\n# Scatterplot\nxp.scatter(_df,x=\"Album_tsne1\",y=\"Album_tsne2\",color=\"Category\", hover_data=[\"Album\"], height=500, color_discrete_sequence=colormap)","5a0139ae":"# Replace column\ndf = pd.concat([df,album_embedded[[\"Album_tsne1\",\"Album_tsne2\"]]], axis=1)\ndf = df.drop(\"Album\", axis=1)\ndf.head()","f9cdb9c0":"# Check the description\nfor i in [\"Track\", \"Version\", \"Album_type\"]:\n    print(description[i])","f66c012e":"# We do not have features, so we use label encoder\ntrack_encoder = LabelEncoder()\ndf[\"Track\"] = track_encoder.fit_transform(df[\"Track\"])\ndf.head()","9d45b3ae":"# Let's see if there is a dependency\n_df = df.groupby([\"Version\",\"Category\"], as_index=False).count()\n\n# Plot a bar chart\nxp.bar(_df,x=\"Version\",y=\"Id\",color=\"Category\", color_discrete_sequence=colormap)","b35c67ac":"# To onehot vector and replace column\nversions = set(df[\"Version\"])\ndf[list(versions)] = OneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\ndf = df.drop([\"Version\",\"none\"], axis=1)\ndf.head()","165a57e7":"# Let's see for any relevance\n_df = df.groupby([\"AlbumType\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df,x=\"AlbumType\",y=\"Id\",color=\"Category\", color_discrete_sequence=colormap)","d62f9eb1":"# Create onehot vector and replace old column\nalbumTypes = set(df[\"AlbumType\"])\ndf[list(albumTypes)] = OneHotEncoder().fit_transform(df[[\"AlbumType\"]]).toarray()\ndf = df.drop([\"AlbumType\",\"none\"], axis=1)\ndf.head()","e646afb6":"# Check the description\nfor k in [\"Duration\",\"BPM\"]:\n    print(f\"{k}:{description[k]}\")","21079e9b":"# Let's see if there is a dependency\n_df = df.groupby([\"Duration\",\"Category\"], as_index=False).count()\n\n# Create scatterplot\nxp.scatter(df, x=\"Track\", y=\"Duration\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","212a9647":"# No dependency really, so we leave duration as it is\n# We drop the column\ndf.drop('Duration', axis=1, inplace=True)","cdcae8cf":"# Let's see if there is a dependency between BPM and (no) likes\n_df = df.groupby([\"BPM\",\"Category\"], as_index=False).count()\n\n# Create scatterplot\nxp.scatter(df, x=\"Track\", y=\"BPM\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","45638f2a":"# No dependency I guess, so we leave BPM as it is\n# We drop the column\ndf.drop('BPM', axis=1, inplace=True)","c27b04d7":"df","26fb4cf1":"df.info()","e67be6d9":"# Let's select our features\nfeatures = df.columns[2:]\ndummies = pd.get_dummies(df[features])\nx = dummies[:-370]\nx_acc = dummies[-370:-300]\nx_test = dummies[-300:]\n\ntrain_data = df[:-370]\ny = train_data['Category']\ntrain_data_acc = df[-370:-300]\ny_test = train_data_acc[\"Category\"]","b5d7a586":"# Try different models\nmodel = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with RandomForest is: ', accuracy)\n\nmodel = AdaBoostClassifier(n_estimators = 1000)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with AdaBoost is: ', accuracy)\n\nmodel = GradientBoostingClassifier(n_estimators = 1000)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with GradientBoosting is: ', accuracy)\n\nmodel = DecisionTreeClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with DecisionTree is: ', accuracy)\n\nmodel = LinearDiscriminantAnalysis()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with LinearDiscriminant is: ', accuracy)\n\nmodel = SVC()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with SupportVectorMachine: ', accuracy)\n\nmodel = ExtraTreesClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with ExtraTrees: ', accuracy)\n\nmodel = MLPClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with MLPClassifier: ', accuracy)\n\nmodel = GaussianProcessClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with GaussianProcess: ', accuracy)\n\nmodel = KNeighborsClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with KNeighbors: ', accuracy)\n\nmodel = CatBoostClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with CatBoost: ', accuracy)","2048375b":"# RandomForest gives the best accuracy\n\nfinal_model = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42)\nfinal_model.fit(x, y)\n\nsample = pd.read_csv(\"..\/input\/mymusicalprefrences\/sample_submition.csv\")\nsample[\"Category\"] = final_model.predict(x_test)\nsample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)\nsample.to_csv(\".\/submission.csv\", index=False)","ac30948b":"Duration","762c03c5":"# **4. MODEL SELECTION**","80dbab84":"**3.5 ARTISTS**  ","18054a73":"**3.10 TRACK, VERSION, ALBUM TYPE**","cd9f8623":"**3.4 ENERGY, HAPPINESS, DANCEABILITY**","d08403a0":"AlbumType","b76487ec":"**3.1 COUNTRY**","8678e683":"**3.8 ARTISTS GENRES**","5738f07f":"# **3. FEATURE ENGINEERING**","db4fd94a":"Version","f729002f":"# **2. DATA PREPARATION**","edae7a03":"# **1. DATA ANALYSIS**","32e221e1":"**3.2 VOCAL**","b5732a87":"BPM","ec6774be":"Track","a322b0de":"**3.9 ALBUM**","4511a85a":"***SOME USEFUL FUNCTIONS***","ae35e9ac":"**3.6 RELEASE YEAR**","8f718165":"**3.11 DURATION, BPM**","f3822387":"**3.3 KEY**","d2472aa1":"**3.7 LABELS**"}}