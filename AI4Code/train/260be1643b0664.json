{"cell_type":{"9ffeaee8":"code","157e3138":"code","967657d2":"code","3a89d1d9":"code","2d06bd1a":"code","d31a2831":"code","adc06d90":"code","719b9423":"code","58cb0560":"code","7ff41461":"code","cc60b0b5":"code","6213b809":"code","0d70b044":"code","d0db157c":"code","48c75a13":"code","0d275fdb":"code","1212f2cb":"code","35da3aff":"code","f3b696ee":"code","7160b792":"code","5e77727f":"code","5959cf6b":"code","d9095a69":"code","ff75c4ee":"code","fafdf9b8":"code","1c391927":"code","8ad5871b":"code","788d6228":"code","6e135638":"code","ad40013e":"code","4fbb73b7":"code","ef7807c3":"code","abdb02e2":"code","44ab8dc0":"code","e2d2573f":"code","d4468ba6":"code","a293bf29":"code","21b8ccdf":"code","a3a96289":"code","e037a29c":"code","cabf2ff5":"code","89ba2afd":"code","cc46de52":"code","4af2a9a0":"code","c88d29bf":"code","38627ac4":"code","89e23744":"code","bf990ecc":"code","80fa4a10":"code","3d519f5d":"code","b6f07fe5":"code","7446d45d":"code","1f8e869a":"markdown","9ee12ca9":"markdown","edf07f80":"markdown","156ab61b":"markdown","bf17b218":"markdown","7cd753f4":"markdown","9bce8437":"markdown","a2b11de2":"markdown","c567973a":"markdown","e41cc71e":"markdown","ca8bca1f":"markdown","a6df9007":"markdown","6415291e":"markdown"},"source":{"9ffeaee8":"# For Dataset handling\nimport numpy as np\nimport pandas as pd\n\n# For Checking Distribution Data\nfrom scipy.stats import chisquare, kstest, normaltest\n\n# For Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","157e3138":"df = pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')","967657d2":"pd.set_option('display.max_columns', None)","3a89d1d9":"df.head()","2d06bd1a":"((df['target'].value_counts()\/len(df))*100).round(2)","d31a2831":"sizes = list(df['target'].value_counts().sort_values().values)\nlabels = list(df['target'].value_counts().sort_values().index)\n\nexplode = [0, 0.1]\n\nplt.figure(figsize=(6,6))\nplt.pie(sizes, labels=labels, explode = explode,\n        autopct=lambda p:f'{p:.2f}%')\nplt.title('Looking for New Job Percentage', fontsize=25)\nplt.tight_layout()\nplt.show()","adc06d90":"df.info()","719b9423":"df.describe().T","58cb0560":"df.describe(include = 'object').T","7ff41461":"dataDesc= []\n\nfor i in df.columns:\n    dataDesc.append([\n        i, \n        df[i].dtypes,\n        df[i].isna().sum(),\n        round((((df[i].isna().sum()) \/ len(df)) * 100),2),\n        df[i].nunique(),\n        df[i].sample(20).drop_duplicates().values\n    ])\npd.DataFrame(dataDesc, columns=[\n    \"Data features\", \n    \"Data types\",\n    \"Null\",\n    \"Null Percentage\",\n    \"Unique\",\n    \"Unique Sample\"\n])","cc60b0b5":"df.isna().sum()","6213b809":"for column in ['gender','enrolled_university','education_level','major_discipline', 'experience', 'company_size', 'company_type','last_new_job']:\n    df[column].fillna(df[column].mode()[0], inplace=True)","0d70b044":"df.isna().sum()","d0db157c":"df[df.duplicated()]","48c75a13":"df.duplicated().sum()","0d275fdb":"df.drop_duplicates(keep='first',inplace=True)\ndf.info()","1212f2cb":"df['city'] = df['city'].str.replace('city_','')","35da3aff":"df['city'].value_counts()","f3b696ee":"df.head()","7160b792":"from sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()","5e77727f":"for col in df.columns:\n    df[col] = enc.fit_transform(df[col])","5959cf6b":"df.head()","d9095a69":"x = df.drop(columns='target')\ny = df['target']","ff75c4ee":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","fafdf9b8":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)","1c391927":"ss = StandardScaler()\nss.fit(xtrain)\nxtrain = ss.transform(xtrain)\nxtest = ss.transform(xtest)","8ad5871b":"from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report, roc_curve,roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier","788d6228":"forest = RandomForestClassifier(max_depth=32, n_estimators= 2250, class_weight = {0:0.7, 1:0.3})\nforest.fit(xtrain, ytrain)\nypred_tr = forest.predict(xtrain)\nypred_ts = forest.predict(xtest)\nprint(\"Training Results:\\n\")\nprint(classification_report(ytrain, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","6e135638":"def log_evaluation(data_sample_train,data_sample_test, aktual_train,aktual_test, model):\n    hasil_model_train = model.predict(data_sample_train)\n    accuracy_train = accuracy_score(aktual_train, hasil_model_train)\n    recall_train = recall_score(aktual_train, hasil_model_train)\n    precision_train = precision_score(aktual_train, hasil_model_train)\n    f1_train = f1_score(aktual_train, hasil_model_train)\n    rocauc_train = roc_auc_score(aktual_train,hasil_model_train)\n\n    hasil_model_test = model.predict(data_sample_test)\n    accuracy_test = accuracy_score(aktual_test, hasil_model_test)\n    recall_test = recall_score(aktual_test, hasil_model_test)\n    precision_test = precision_score(aktual_test, hasil_model_test)\n    f1_test = f1_score(aktual_test, hasil_model_test)\n    rocauc_test = roc_auc_score(aktual_test,hasil_model_test)\n    \n    cm = confusion_matrix(aktual_test, hasil_model_test, labels=[1,0])\n    df_cm = pd.DataFrame(cm, index = [\"akt1\", \"akt0\"],columns=[\"pred 1\" , \"pred 0\"])\n    cr = classification_report(aktual_test, hasil_model_test)\n\n\n    hasil_evaluation = pd.DataFrame(data= {\"Training\" : [accuracy_train, recall_train, precision_train,f1_train,rocauc_train],\"Testing\" : [accuracy_test, recall_test, precision_test,f1_test,rocauc_test]}, index=[\"accuracy\", \"recall\" , \"precission\", \"F1 Score\", \"ROCAUC\"] )\n\n    return hasil_model_train, hasil_model_test, hasil_evaluation, df_cm, cr","ad40013e":"rf_hasil_train, rf_hasil_test, rf_evaluation, rf_cm, rf_cr = log_evaluation(xtrain, xtest, ytrain, ytest, forest)","4fbb73b7":"rf_evaluation","ef7807c3":"rf_cm","abdb02e2":"print(rf_cr)","44ab8dc0":"#pip install -U imbalanced-learn","e2d2573f":"#conda install -c conda-forge imbalanced-learn","d4468ba6":"from imblearn.over_sampling import SMOTE,ADASYN, SVMSMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom sklearn.model_selection import train_test_split\n","a293bf29":"to_smote = SMOTE(random_state=101) #,sampling_strategy='minority', k_neighbors=5)\nx_to_smote, y_to_smote = to_smote.fit_resample(x,y)","21b8ccdf":"x_to_smote.shape","a3a96289":"y_to_smote.shape","e037a29c":"x_train_smote, x_test_smote, y_train_smote, y_test_smote = train_test_split(x_to_smote,y_to_smote, test_size=0.20, random_state=101)","cabf2ff5":"x_train_smote.shape","89ba2afd":"x_test_smote.shape","cc46de52":"sc = StandardScaler()\nX_train = sc.fit_transform(x_train_smote)\nX_test = sc.transform(x_test_smote)","4af2a9a0":"forest_smote = RandomForestClassifier(max_depth=32, n_estimators= 1250)\nforest_smote.fit(X_train, y_train_smote)\nypred_tr_smote = forest_smote.predict(X_train)\nypred_ts_smote = forest_smote.predict(X_test)\nprint(\"Training Results:\\n\")\nprint(classification_report(y_train_smote, ypred_tr_smote))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(y_test_smote, ypred_ts_smote))","c88d29bf":"rf_hasil_train_smote, rf_hasil_test_smote, rf_evaluation_smote, rf_cm_smote, rf_cr_smote = log_evaluation(X_train, X_test, y_train_smote, y_test_smote, forest_smote)","38627ac4":"rf_evaluation_smote","89e23744":"rf_cm_smote","bf990ecc":"print(rf_cr_smote)","80fa4a10":"print(rf_cr)","3d519f5d":"print(rf_cr_smote)","b6f07fe5":"pd.concat([rf_evaluation,rf_evaluation_smote], axis= 1).round(2)","7446d45d":"pd.concat([rf_cm,rf_cm_smote], axis= 1)","1f8e869a":"## C.1 Preprocessing using LabelEncoder","9ee12ca9":"after finding the best model in https:\/\/www.kaggle.com\/astryekacitrasari\/hr-analytics-job-change-xg-boost-and-svm-model.\nI tried to enhance again the accuracy using standardscaler and this time without pipeline and using label encoding instead of one hot encoder","edf07f80":"## C.3 Random Forest with SMOTE Imbalanced Data and StandardScaler preprocessing","156ab61b":"## C.2 Random Forest with StandardScaler Preprocessing","bf17b218":"## A.2 Checking Data Info and Statistical Data","7cd753f4":"As SMOTE increase the number of Target = 1, so the True Positif also increase rapidly. However, we can see True Negatif decrease as much as 300","9bce8437":"# B. Data Cleaning","a2b11de2":"# A. Data Understanding","c567973a":"# C. Data Preprocessing","e41cc71e":"- From numerical descriptive result : \n    - \"training_hours\" features having big differences between Q3 (75%) and max value which indicates an outlier. \n    ","ca8bca1f":"# D. Comparison between non SMOTE and SMOTE","a6df9007":"## A.1. Checking Data Proportion","6415291e":"### Split main dataset"}}