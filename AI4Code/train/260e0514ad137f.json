{"cell_type":{"a4f3140e":"code","789a19f8":"code","26c4c5dc":"code","b133cdc8":"code","46cac756":"code","886599c9":"code","4daaaa56":"code","2e928858":"code","3749ff7c":"code","2f6351c1":"code","6e6ca54a":"code","12035a70":"code","57af4ec4":"code","ca9a962c":"code","70f76c02":"code","dcc7b27c":"code","ad1157d2":"code","5078e877":"code","40be2945":"code","4c19bad4":"code","5acd7ac6":"code","be986f99":"code","eae4a5a7":"code","c186e2a9":"code","e9c8e3a8":"code","29109126":"code","aa90def3":"code","db5915ac":"code","c34cd826":"markdown","8cc05cdc":"markdown","ec4f1e45":"markdown","8d42267c":"markdown","f02ad6fb":"markdown","da6e57d7":"markdown","7b7f5932":"markdown","066c2b64":"markdown"},"source":{"a4f3140e":"import os\nos.listdir('..\/input\/adult-census-income')","789a19f8":"#import the required packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","26c4c5dc":"# Read the census data from github \n# github.com\/sumathi16\/ML_FDP_SVEC\npath = '..\/input\/adult-census-income\/adult.csv'\ndata = pd.read_csv(path)","b133cdc8":"data.head()","46cac756":"# seperate the features and target\n# features\nX_data = data.drop('income',axis=1)\n# target\ny_data = data.income\n# check the shape of X_data and y_data\nprint(X_data.shape,y_data.shape)","886599c9":"numerical_cols=X_data.columns[X_data.dtypes!=object]\nnumerical_cols","4daaaa56":"# Check the distribution of data for all the columns\nX_data.hist()","2e928858":"X_data[['capital.gain','capital.loss']].describe()","3749ff7c":"# Applying log1p for skewed columns\nX_data[['capital.gain','capital.loss']] =\\\n  np.log1p(X_data[['capital.gain','capital.loss']])\nX_data[['capital.gain','capital.loss']].describe()","2f6351c1":"# Observe the min,max vlaues for all columns\nX_data.describe()","6e6ca54a":"# Applying MinMAXScaler for numerical cols\n#import the scaler\nfrom sklearn.preprocessing import MinMaxScaler\n# create an instance\nsc = MinMaxScaler()\n# Fit the model with the data to which we need to \n# apply scaling\nsc.fit(X_data[numerical_cols])\n#update the values with scaled values\nX_data[numerical_cols] = \\\n        sc.transform(X_data[numerical_cols])","12035a70":"# Observe the min,max values for all columns are 0,1\nX_data.describe()","57af4ec4":"cat_cols=X_data.columns[X_data.dtypes==object]\ncat_cols","ca9a962c":"# check the no of columns before applying OHE\nprint(X_data.shape)\n# Applying one hot encoding for all categorical\n# columns\nX_data = pd.get_dummies(X_data)\n# check the no of columns after applying OHE\nprint(X_data.shape)","70f76c02":"# Observe the column names\nX_data.columns","dcc7b27c":"# Check the top five rows\nX_data.head()","ad1157d2":"# check the output you shoud get 0,1's\ny_data.apply(lambda x: 1 if x=='>50K' else 0)","5078e877":"# y_data = data.income\n# Store the result in y_data\ny_data=y_data.apply(lambda x: 1 if x=='>50K' else 0)\n# check the no of zeros and ones in y_data\ny_data.value_counts()","40be2945":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = \\\n    train_test_split(X_data,y_data,random_state=42,test_size=0.3)\nprint(X_train.shape)\nprint(y_train.shape)\nX_train.head()","4c19bad4":"y_data.value_counts(normalize=True)","5acd7ac6":"y_train.value_counts(normalize=True)","be986f99":"y_test.value_counts(normalize=True)","eae4a5a7":"#import the classifier\nfrom sklearn.neighbors import KNeighborsClassifier\n# create an instance\nknn = KNeighborsClassifier()\n# train the model\nknn.fit(X_train,y_train)","c186e2a9":"# predict the outcome for test data\ny_pred = knn.predict(X_test)\n# import the metric\nfrom sklearn.metrics import accuracy_score\n#caluculate the test data accuracy\nprint('test accuracy score',\\\n      accuracy_score(y_test,y_pred))","e9c8e3a8":"# predict the outcome for test data\ny_train_pred = knn.predict(X_train)\n#caluculate the test data accuracy\nprint('train  accuracy score',\\\n      accuracy_score(y_train,y_train_pred))","29109126":"from sklearn.linear_model import LogisticRegression\nLr =  LogisticRegression()\nLr.fit(X_train,y_train)","aa90def3":"accuracy_score(y_test,Lr.predict(X_test))","db5915ac":"accuracy_score(y_train,Lr.predict(X_train))","c34cd826":"#### Preprocessing the Data\n##### Numerical data","8cc05cdc":"##### Applying Logistic Regression Classifier","ec4f1e45":"Convert the y_data ","8d42267c":"##### Applying KNN CLASSIFIER","f02ad6fb":"**Don't run the below cell more than once**","da6e57d7":"##### Categorical Columns","7b7f5932":"##### Split the data","066c2b64":" # FINDING DONORS"}}