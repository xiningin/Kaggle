{"cell_type":{"7ce0daed":"code","ef26fd9b":"code","b4f3938a":"code","d2df3887":"code","b096c966":"code","ce9259f8":"code","a2263711":"code","9f9dcbb2":"code","db31f3e1":"code","ad815257":"code","b0578f74":"code","83587c44":"code","cb3c10a5":"code","af0dc55e":"code","0587e751":"code","6fc21661":"code","cce3f005":"code","140b49c7":"code","836d5423":"markdown","a8d59c7b":"markdown","a1d9ad37":"markdown","54e94b34":"markdown","6ef3c609":"markdown","be14c5f2":"markdown","59c19c6c":"markdown","820fdb93":"markdown"},"source":{"7ce0daed":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf","ef26fd9b":"label_code = {'Eight':0,'Half':1,'Quarter':2,'Sixteenth':3,'Whole':4}\nlabel_decode = ['Eight','Half','Quarter','Sixteenth','Whole']","b4f3938a":"df = pd.DataFrame(columns = ['path', 'label'])","d2df3887":"for dirname, _, filenames in os.walk('..\/input\/music-notes-datasets\/datasets\/datasets\/Notes'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        name = dirname.split('\/')[-1]\n        label = label_code[name]\n        df = df.append({'path' : path, 'label' : label}, ignore_index = True)","b096c966":"df.head()","ce9259f8":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df, test_size=0.2, random_state = 77)","a2263711":"train.head()","9f9dcbb2":"test.head()","db31f3e1":"from tensorflow.keras.preprocessing.image import load_img\n\nclass dataloader(tf.keras.utils.Sequence):\n       \n    def __init__(self, batch_size, img_width, img_height, data):\n        self.bs = batch_size\n        self.h = img_height\n        self.w = img_width\n        self.path = data['path'].values\n        self.label = data['label'].values\n        \n    def __len__(self):\n        return len(self.path) \/\/ self.bs\n    \n    def __getitem__(self, idx):\n        \n        i = idx * self.bs\n        batch_paths = self.path[i : i + self.bs]\n        batch_labels = self.label[i : i + self.bs]\n        \n        X = np.zeros((self.bs, self.h, self.w, 3), dtype=\"float32\")\n        y = np.zeros((self.bs, 5), dtype=\"int32\")\n        \n        for j in range(self.bs): \n            img = load_img(batch_paths[j], color_mode = \"rgb\", target_size=(self.h, self.w)) # color_mode = \"grayscale\" \n            img = np.array(img, dtype = 'float32') \n            img = 1-img\/127.5\n            X[j] = img     \n            y[j,batch_labels[j]] = 1  \n        return X, y","ad815257":"train_gen = dataloader(5, 224, 224, train)\n\ntest_gen = dataloader(5, 224, 224, test)","b0578f74":"batch1 = test_gen[3]\n\nimages = batch1[0]\n\nlabels = batch1[1]\n\nprint(\"images in batch = \", images.shape)\nprint(\"labels in batch = \", labels.shape)","83587c44":"for i, j in zip(images, labels):\n    plt.subplots()\n    plt.imshow(i)\n    plt.title(label_decode[np.argmax(j)])","cb3c10a5":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n\nmodel = Sequential()\nmodel.add(Conv2D(8, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(Conv2D(4, (4, 4), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(4, (3, 3), activation='relu'))\nmodel.add(Conv2D(3, (3, 3), activation='relu'))\nmodel.add(Conv2D(3, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(5,activation='softmax'))    #output_channel = 5","af0dc55e":"model.summary()","0587e751":"model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])","6fc21661":"model.fit(train_gen, epochs=20, validation_data=test_gen, verbose=1)","cce3f005":"path = '..\/input\/music-notes-datasets\/datasets\/datasets\/Notes\/Sixteenth\/s1.jpg'\n\nimg = load_img(path , color_mode = \"rgb\", target_size=(224, 224)) # (h ,w) color_mode = \"grayscale\" \nimg = np.array(img, dtype = 'float32') \nimg = 1-img\/127.5\n\nimg = img.reshape(1,224,224,3)\n\ny1 = model.predict(img)","140b49c7":"s = np.argmax(y1)\n\nprint(label_decode[s])","836d5423":"## Trainning testing split","a8d59c7b":"## TRAINNING","a1d9ad37":"## MODEL SETUP","54e94b34":"## Label enconding and decoding","6ef3c609":"## Testing samples","be14c5f2":"## Dataframe for datasets","59c19c6c":"## TESTING ON SINGLE IMAGE","820fdb93":"# DATA LOADER"}}