{"cell_type":{"3d8c960e":"code","199f1deb":"code","579ef3dc":"code","9ca354f7":"code","3f2407d1":"code","b3462311":"code","5b2e3109":"code","cab48a1a":"code","17490c2e":"code","89b9379c":"code","f7074e9f":"code","6ddb1269":"code","91f5aada":"code","a29e4ead":"code","b8ea6942":"code","cf601aa7":"code","7b1de528":"markdown"},"source":{"3d8c960e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","199f1deb":"import pandas as pd\nimport numpy as np","579ef3dc":"df=pd.read_csv(\"..\/input\/position-salary-dataset\/Position_Salaries.csv\")\ndf.head()","9ca354f7":"df.size","3f2407d1":"df.isnull().sum()","b3462311":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.scatterplot(x=\"Level\",y=\"Salary\",data=df)\nplt.show()","5b2e3109":"X = df.iloc[:, 1:-1].values\ny = df.iloc[:, -1].values","cab48a1a":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()\nlr.fit(X,y)\nlr_model=lr.fit(X,y)\npredict_lr=lr_model.predict(X)\nplt.scatter(X,y, color = 'red')\nplt.plot(X, lr_model.coef_*X + lr_model.intercept_, '-b')\nplt.title(\"Linear regression\")\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","17490c2e":"from sklearn.metrics import r2_score\nr2=r2_score(y,predict_lr)\nprint(\"r2=\",r2,\"\\n\")","89b9379c":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\npoly_reg=make_pipeline(PolynomialFeatures(degree=2),LinearRegression())\npoly_reg_model=poly_reg.fit(X,y)\nplt.scatter(X,y, color = 'red')\nplt.plot(X,poly_reg_model.predict(X),color=\"black\")\nplt.title(\"Polynomial regression with degree 2\")\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","f7074e9f":"from sklearn.metrics import r2_score\npredict_poly_reg=poly_reg_model.predict(X)\nr2=r2_score(y,predict_poly_reg)\nprint(\"polynomial regression with degree 2 \\n\")\nprint(\"r2=\",r2,\"\\n\")","6ddb1269":"poly_reg=make_pipeline(PolynomialFeatures(degree=4),LinearRegression())\nmodel=poly_reg.fit(X,y)\nplt.scatter(X,y, color = 'red')\nplt.plot(X,model.predict(X),color=\"black\")\nplt.title(\"Polynomial regression with degree 4\")\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","91f5aada":"# Increasing degree of the polynomial, the complexity of the model also increases.\n# Overfitting problem.\n# Training error will be low & test error will be high\nfrom sklearn.metrics import r2_score\npredict_=model.predict(X)\nr2=r2_score(y,predict_)\nprint(\"polynomial regression with degree 4 \\n\") \nprint(\"r2=\",r2,\"\\n\")","a29e4ead":"# predicted value using linear regression\npredict_= lr_model.predict([[8]])\npredict_","b8ea6942":"# predicted value using polynomial regression\npredict_= model.predict([[8]])\npredict_","cf601aa7":"df.loc[df['Level'] == 8] # actual value ","7b1de528":"Polynomial Regression is a one of the types of linear regression in which the relationship between the independent variable x and dependent variable y is modeled as an nth degree polynomial.The 1-degree polynomial is a simple linear regression; therefore, the value of degree must be greater than 1 in Polynomial Regression."}}