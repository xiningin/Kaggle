{"cell_type":{"71a97b56":"code","261351ab":"code","b21ac55a":"code","eaec2332":"code","213a965a":"code","8f1412f6":"code","d8ebd242":"code","ebbb23c2":"code","09aebd87":"code","28481170":"code","69f7dcb5":"code","42667107":"code","74756c43":"code","9470fad5":"code","a2098ceb":"code","8e5436bd":"code","f035790c":"code","dd2ece4d":"code","fd558050":"code","19855581":"code","4c7eaee4":"code","9ddb48d0":"code","c5265b2c":"code","ffcfd532":"code","32ef17a0":"code","a53a2ede":"code","2bd76a5a":"code","2f6a601e":"code","1db1b24e":"code","7a74e6c3":"code","0c82426f":"code","8426e857":"code","7b6d3b94":"code","167ff4c8":"code","1dbfed41":"code","0fb8a751":"code","4d43de69":"code","5a8d760a":"code","586f1359":"code","62de7737":"markdown","a5830898":"markdown","e34a94d4":"markdown","0f38b4ef":"markdown","9649831e":"markdown","15e72ee8":"markdown","9fd8d294":"markdown","51abe89b":"markdown","aade045b":"markdown","deee5083":"markdown","52a35412":"markdown","4c492787":"markdown","04e97306":"markdown","970a9ba2":"markdown","0db31b08":"markdown","45dc84c3":"markdown","46403904":"markdown","5c5560e1":"markdown"},"source":{"71a97b56":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","261351ab":"#Importing necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nsns.set()\n\n\n#Encoding Libraries\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\n\n#Feature Selection\nfrom sklearn.feature_selection import VarianceThreshold\n\nfrom scipy.stats import norm\n\n#Library for Model Selection\nfrom sklearn.feature_selection import RFE\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost.sklearn import XGBRegressor\n\n#Imporing Library for Tree based Model Building\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve , KFold, StratifiedKFold\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n\n#Importing Libraries for scoring\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","b21ac55a":"#Loading the Dataset\ntrain_original = pd.read_csv('..\/input\/hackerearth-carnival-wars-challenge\/train.csv')\ntest_original = pd.read_csv('..\/input\/hackerearth-carnival-wars-challenge\/test.csv')\nsample_submission = pd.read_csv('..\/input\/hackerearth-carnival-wars-challenge\/sample_submission.csv')","eaec2332":"#Original should remain intact\ntrain = train_original.copy()\ntest = test_original.copy()","213a965a":"train.head()","8f1412f6":"test.head()","d8ebd242":"#Shape of the Train Data\nprint(f\"Train Datset shape : {train.shape}\")\n\n#Shape of the Test Data\nprint(f\"Test Datset shape : {test.shape}\")","ebbb23c2":"# Dataset Columns\nprint(train.columns)","09aebd87":"#Lets checkout the dataypes of the data\ntrain.info()","28481170":"train.describe()","69f7dcb5":"\n#Function to show all the missing values of the dataset\ndef showMissingValues(dataset):\n    for col in dataset.columns.tolist():          \n        print(f\" {col} column missing values: {dataset[col].isnull().sum()}\")\n    print('\\n')\n    \n\nprint(\"Train data-------------------------------------\")\nshowMissingValues(train)\n\nprint(\"Validation dataset--------------------------------------\")\nshowMissingValues(test)","42667107":"train['Stall_no'] = train['Stall_no'].fillna(train['Stall_no'].median())#Initaly mode\ntest['Stall_no'] = test['Stall_no'].fillna(test['Stall_no'].median())","74756c43":"#train[train['Customer_name'].isnull()]\ntrain['Customer_name'] = train['Customer_name'].fillna(\"Missing\")","9470fad5":"train[train['Customer_name'] == \"Missing\"].head()","a2098ceb":"train['Discount_avail'] = train['Discount_avail'].fillna((train['Discount_avail'].mean()))#Initially 0\ntest['Discount_avail'] = test['Discount_avail'].fillna((test['Discount_avail'].mean()))","8e5436bd":"sns.distplot(train['charges_1'])","f035790c":"train['charges_1'] = train['charges_1'].fillna((train['charges_1'].mean()))\ntest['charges_1'] = test['charges_1'].fillna((test['charges_1'].mean()))","dd2ece4d":"sns.distplot(train['charges_2 (%)'])","fd558050":"train = train.rename(columns={'charges_2 (%)': 'charges_2'})\ntest = test.rename(columns={'charges_2 (%)': 'charges_2'})\n\n#Imputing missing values\ntrain['charges_2'] = train['charges_2'].fillna((train['charges_1'].median())) #Initially mean\ntest['charges_2'] = test['charges_1'].fillna((test['charges_1'].median()))","19855581":"train['Minimum_price'] = train['Minimum_price'].fillna((train['Minimum_price'].median())) #initially mean\ntest['Minimum_price'] = test['Minimum_price'].fillna((test['Minimum_price'].median()))\n\ntrain['Maximum_price'] = train['Maximum_price'].fillna((train['Maximum_price'].median()))\ntest['Maximum_price'] = test['Maximum_price'].fillna((test['Maximum_price'].median()))","4c7eaee4":"sns.distplot(train['Selling_Price'])","9ddb48d0":"#Avoiding the Null Selling Prices\ntrain = train[~train['Selling_Price'].isna()]\ntrain.shape","c5265b2c":"#Function to show all the missing values of the dataset\ndef showMissingValues(dataset):\n    for col in dataset.columns.tolist():          \n        print(f\" {col} column missing values: {dataset[col].isnull().sum()}\")\n    print('\\n')\n    \n\nprint(\"Train data-------------------------------------\")\nshowMissingValues(train)\n\nprint(\"Test dataset--------------------------------------\")\nshowMissingValues(test)","ffcfd532":"train['instock_date'] = pd.to_datetime(train['instock_date'])\ntest['instock_date'] = pd.to_datetime(test['instock_date'])","32ef17a0":"train.info()","a53a2ede":"train['Product_Category'].nunique()","2bd76a5a":"#Function to analye how Purchase amount is dependent upon Product categories.\nfig = plt.figure(figsize=(15,8))\nmost_freq_category = train.groupby('Product_Category')['Selling_Price'].sum().reset_index()\nsns.barplot(x='Product_Category',y='Selling_Price',data = most_freq_category,palette=\"muted\")","2f6a601e":"train['Loyalty_customer'].nunique()","1db1b24e":"train['Loyalty_customer'].value_counts()","7a74e6c3":"#Label Encoding of loyality customers \nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nfor cat_var in ['Loyalty_customer','Product_Category']:\n    train[cat_var] = le.fit_transform(train[cat_var])\n    test[cat_var] = le.fit_transform(test[cat_var])","0c82426f":"train['Customer_name'].nunique()","8426e857":"def create_date_features(data):\n    data['instock_date_day'] = data['instock_date'].dt.day\n    data['instock_date_quarter'] = data['instock_date'].dt.quarter\n    data['instock_date_month'] = data['instock_date'].dt.month\n    data['instock_date_week'] = data['instock_date'].dt.week\n    data['instock_date_weekday'] = data['instock_date'].dt.weekday\n    data['instock_date_year'] = data['instock_date'].dt.year\n    data['instock_date_hour'] = data['instock_date'].dt.hour\n    data['instock_date_minute'] = data['instock_date'].dt.minute\n    return data","7b6d3b94":"train = create_date_features(train)","167ff4c8":"def create_derived_cols(data):\n    data['Diff'] = data['Maximum_price'] - data['Minimum_price']\n    data['Total'] = data['Maximum_price'] + data['Minimum_price']\n    data['Average_price'] = (data['Maximum_price'] + data['Minimum_price'])\/2\n    data['Max_Min_ratio'] = data['Maximum_price'] \/ data['Minimum_price']\n    \n    \n    data['Max_Min_mul'] = data['Maximum_price'] * data['Minimum_price']\n    return data","1dbfed41":"train = create_derived_cols(train)\ntest = create_derived_cols(test)","0fb8a751":"#Best features Set\nbest_feats = ['Market_Category',\n 'Product_Category',\n 'Grade',\n 'Demand',\n 'Discount_avail',\n 'charges_1',\n 'charges_2',\n 'Minimum_price',\n 'Maximum_price',\n 'instock_date_day',\n 'instock_date_year',\n 'Diff',\n 'Total',\n 'Average_price',\n 'Max_Min_ratio',\n 'Max_Min_mul']","4d43de69":"train[best_feats].head()","5a8d760a":"fig = plt.figure(figsize=(20,10))\nsns.heatmap(train[best_feats].corr(),annot=True)","586f1359":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import FunctionTransformer\nfrom copy import copy\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.linear_model import LassoLarsCV\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.svm import LinearSVR\nfrom tpot.builtins import StackingEstimator\nfrom sklearn.feature_selection import SelectFwe, f_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\n#Pipeline 3 - 90.21707\nexported_pipeline = make_pipeline(\n    StackingEstimator(ExtraTreesRegressor(bootstrap=False, max_features=0.9500000000000001, min_samples_leaf=1, min_samples_split=6, n_estimators=1500,random_state=0)),\n    ExtraTreesRegressor(bootstrap=False, max_features=0.9500000000000001, min_samples_leaf=1, min_samples_split=6, n_estimators=1650,random_state=0)\n    \n)\n\n\nexported_pipeline.fit(train[best_feats],train['Selling_Price'])\n\nfinal_pred_tpot = exported_pipeline.predict(test[best_feats])\n\ntest['Selling_Price'] = final_pred_tpot\nproduct_ids = test_original['Product_id'].tolist()\n\n\nfinal_sub = pd.DataFrame({'Product_id':product_ids, 'Selling_Price':final_pred_tpot})\n#final_sub['Selling_Price'] = final_sub['Selling_Price'] + 0.5\nfinal_sub.to_csv('Submission_final.csv',index=False)","62de7737":"### <center style=\"background-color:yellow; width:350px;\">Imputing Max and Min Purchases.<\/center>\n\nFor Imputing these values we will use mean.","a5830898":"<a id=\"0\"><\/a>\n# <center style=\"background-color:#63809e; color:white;\">HackerEarth Machine Learning Challenge: Carnival Wars!<\/center>\n\n<center><img src=\"https:\/\/media-fastly.hackerearth.com\/media\/hackathon\/hackerearth-machine-learning-challenge-predict-selling-price\/images\/89b38bb825-Halloween_FB_image.jpg\" width=70%><\/center>","e34a94d4":"4. Imputation **charges_1** column\n\nFor imputing the charges 1 we will use mean as it will relevant.","0f38b4ef":"### <center style=\"background-color:yellow; width:350px;\">Imputing Stall No Column.<\/center>\n\nFor stall number it is better to impute the missing values with most frequent values rather than mean.","9649831e":"# <center style=\"background-color:yellow; width:350px;\">Exploatory Data Analysis<\/center>","15e72ee8":"# <center style=\"background-color:yellow; width:350px;\">Feature Engineering<\/center>\n\nData preprocessing is ready, now is to create some features to consider.","9fd8d294":"All the missing values are Handled","51abe89b":"### My Solution\nIn this hackathon I am currenly in Rank 15 in the Public Leaderboard. I hope this notebook will give you a better understanding of the data and the approach methods.\nMy Score is 90.28","aade045b":"# <center style=\"background-color:yellow; width:450px;\">2 Data Preprocessing.<\/center>\n\n## <center style=\"background-color:orange; width:450px;\">2.1 Missing Values Handling.<\/center>\nAs from the below plot it is visible that there are some missing values in the dataset. showMissingValues function will show all the missing values in the dataset.","deee5083":"# <center style=\"background-color:yellow; width:350px;\">Modeling<\/center>","52a35412":"### <center style=\"background-color:yellow; width:350px;\">Imputing Discount Available Column.<\/center>\n\nFor this column we will impute these as 0 as it is not relevant to impute with mean or others.","4c492787":"### <center style=\"background-color:yellow; width:350px;\">Imputing Customer Name Column.<\/center>\n\nWe will impute missing customer names wiha separate label named \"Missing\"","04e97306":"---------","970a9ba2":"### <center style=\"background-color:yellow; width:350px;\">Imputing charges_2 Column.<\/center>\n\nFor imputing the charges 2 we will use medain or mode as it will be relevant as these are in the %.","0db31b08":"### <center style=\"background-color:yellow; width:250px;\">Problem Statement<\/center>\n\n\nBoo yeah, it\u2019s the holiday season again! You are visiting your folks who live by the countryside. On Halloween night, their neighbors hosted a phenomenal carnival with the greatest pomp and show. People dressed up in their spookiest costumes; families went trick-or-treating; almost everyone came together to have a great time.\n\nFor the carnival, your neighbors had set up multiple stalls for entertaining their guests. When it\u2019s your turn to host a carnival during Christmas, you wish to promote local businesses and help boost their sales. \n\nYou plan to unleash the inner Machine Learning expert in you and build a sophisticated Machine Learning model that predicts selling prices of products based on the mentioned factors.\n\nChallenge link - [Carnival wars](https:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-machine-learning-challenge-predict-selling-price\/)","45dc84c3":"### <center style=\"background-color:orange; width:650px;\">Please Upmote my work if it helps you to boost up your Understanding.<\/center>","46403904":"For the Modeling Purpose I have used Stacking Approach of Two extra Trees regressor.","5c5560e1":"### <center style=\"background-color:yellow; width:150px;\">Dataset Loading.<\/center>"}}