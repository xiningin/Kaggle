{"cell_type":{"75e90ce7":"code","993dc8f0":"code","c1dcc51f":"code","a08e641c":"code","ce5de11d":"code","e5e1831f":"code","b66f397a":"code","28ba12f3":"code","82691297":"code","41f0d973":"code","61264067":"code","fa691803":"code","2317e30c":"code","0fe157cc":"code","088e3ac1":"code","f73ce61c":"code","e7d3b80c":"markdown","0493c107":"markdown","09319de9":"markdown","ded56850":"markdown","106f758f":"markdown","22ab385b":"markdown"},"source":{"75e90ce7":"from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\n\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nfrom keras.layers import Dropout,Flatten,Dense\nfrom keras.optimizers import Adam,SGD\nfrom keras.models import Sequential\nimport os\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","993dc8f0":"# load pre-trained VGG16 model,full connected layer is not included\nmodel = VGG16(weights='imagenet', include_top=False)","c1dcc51f":"model.summary()","a08e641c":"from keras.utils.vis_utils import plot_model\nimport matplotlib.pyplot as plt\n\nplot_model(model,to_file='model.png',show_shapes=True,show_layer_names='False',rankdir='TB')\nplt.figure(figsize=(30,30))\nimg = plt.imread('model.png')\nplt.imshow(img)\nplt.axis=('off')\nplt.show()","ce5de11d":"totalFileCount_1 = sum(len(files) for root,dir,files in os.walk('..\/input\/cat-and-dog\/training_set\/training_set'))\ntotalFileCount_1","e5e1831f":"totalFileCount_2 = sum(len(files) for root,dir,files in os.walk('..\/input\/cat-and-dog\/test_set\/test_set'))\ntotalFileCount_2","b66f397a":"datagen = ImageDataGenerator(\n        rotation_range = 40,\n        width_shift_range = 0.2,\n        height_shift_range = 0.2,\n        rescale = 1.\/255,\n        shear_range = 0.2,\n        zoom_range = 0.2,\n        horizontal_flip = True,\n        fill_mode = 'nearest'\n        )","28ba12f3":"batch_size = 32\ntrain_steps = int((8000 + batch_size - 1)\/batch_size)*10\ntest_steps = int((2000 + batch_size - 1)\/batch_size)*10\ngenerator = datagen.flow_from_directory(\n        '..\/input\/cat-and-dog\/training_set\/training_set',\n        target_size = (150,150),\n        batch_size = batch_size,\n        class_mode = None,    # no lables\n        shuffle = False       # no shuffle\n        )\n\n# get train data of final pooling layer\nbottleneck_features_train = model.predict(generator, train_steps)\nbottleneck_features_train = bottleneck_features_train[0:8000]\nprint(bottleneck_features_train.shape)\nnp.save(open('bottleneck_features_train.npy','wb'),bottleneck_features_train)\n\ngenerator = datagen.flow_from_directory(\n        '..\/input\/cat-and-dog\/test_set\/test_set',\n        target_size = (150,150),\n        batch_size = batch_size,\n        class_mode = None,    # no lables\n        shuffle = False       # no shuffle\n        )\nbottleneck_features_test = model.predict(generator, test_steps)\nbottleneck_features_test = bottleneck_features_test[0:2000]\nprint(bottleneck_features_test.shape)\nnp.save(open('bottleneck_features_test.npy','wb'),bottleneck_features_test)","82691297":"train_data = np.load(open('bottleneck_features_train.npy','rb'))\nlabels = np.array([0] * 4000 + [1] * 4000)\ntrain_lables = np.array([])\nfor _ in range(10):\n    train_labels=np.concatenate((train_lables,labels))\n    \ntest_data = np.load(open('bottleneck_features_test.npy','rb'))\nlabels = np.array([0] * 1000 + [1] * 1000)\ntest_lables = np.array([])\nfor _ in range(10):\n    test_labels=np.concatenate((train_lables,labels))\n\ntrain_labels = np_utils.to_categorical(train_labels,num_classes=2)\ntest_labels = np_utils.to_categorical(test_labels,num_classes=2)\nprint(train_labels.shape)\nprint(test_labels.shape)","41f0d973":"model = Sequential()\n# start with data format (not samples)\u2192(samples,4,4,512)\nmodel.add(Flatten(input_shape=train_data.shape[1:]))\nmodel.add(Dense(units=256,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=2,activation='softmax'))\n\nadam = Adam(lr=1e-4)\n\nmodel.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.fit(train_data, train_labels,\n          epochs=20, batch_size=batch_size,\n          validation_data=(test_data,test_labels))\n\nmodel.save_weights('bottleneck_fc_model.h5')","61264067":"vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))","fa691803":"top_model = Sequential()\n# start with data format (not samples)\u2192(samples,4,4,512)\ntop_model.add(Flatten(input_shape=train_data.shape[1:]))\ntop_model.add(Dense(units=256,activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(units=2,activation='softmax'))\n\n# load trained weights\ntop_model.load_weights('.\/bottleneck_fc_model.h5')\n\nmodel = Sequential()\nmodel.add(vgg16_model)\nmodel.add(top_model)","2317e30c":"plot_model(model,to_file='model.png',show_shapes=True,show_layer_names='False',rankdir='TB')\nplt.figure(figsize=(10,10))\nimg = plt.imread('model.png')\nplt.imshow(img)\nplt.axis=('off')\nplt.show()","0fe157cc":"# processing train data\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n# processing test data(just normalization)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","088e3ac1":"batch_size = 32\n\n# generate train data\ntrain_generator = datagen.flow_from_directory(\n        '..\/input\/cat-and-dog\/training_set\/training_set',\n        target_size = (150,150),\n        batch_size = batch_size,\n        )\n\n\n# generate test data\ntest_generator = datagen.flow_from_directory(\n        '..\/input\/cat-and-dog\/test_set\/test_set',\n        target_size = (150,150),\n        batch_size = batch_size,\n        )","f73ce61c":"model.compile(loss='categorical_crossentropy',\n              optimizer=SGD(lr=1e-4,momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.fit_generator(\n        train_generator,\n        steps_per_epoch=totalFileCount_1\/batch_size,\n        epochs=10,\n        validation_data=test_generator,\n        validation_steps=totalFileCount_2\/batch_size\n        )","e7d3b80c":"- Because the final number of pictures is odd, I decied round off the photos and take the whole number.\n- 8007\u21928000\uff1b2025\u21922000","0493c107":"- Define full connected layers and other opimizers by ourself\n- Fit model and save model","09319de9":"![image.png](attachment:image.png)","ded56850":"# Finetune\uff1a","106f758f":"# Bottleneck\n- Bottleneck will lock the parameters of convolution layer and pooling layer of vgg16. Put the image into the convolution layer and pooling layer, and finally get the data of pooling layer, and then we can customize the full connection layer.\n\n# Finetune\n- Finetune will adjust the parameters of the build-up layer and pooling layer, which can be fine tuned.\n","22ab385b":"# Bottleneck\uff1a"}}