{"cell_type":{"28d4e4a7":"code","eac9d29b":"code","ed62624e":"code","e7db4cdb":"code","b79d8dd9":"code","d760ec8e":"code","796df22d":"code","447cc673":"code","1dbd10c4":"code","67ec0f01":"code","3089d1c2":"code","85cc3a57":"code","73b05d8d":"code","e79f517a":"code","21a71338":"code","304cdb6e":"code","80591277":"code","1ac16cf5":"code","0b4c3cc2":"code","7fb4759b":"code","3ad8bcfa":"code","8e5fa4f1":"code","33b3a397":"code","99e2aa58":"code","b8ca7d74":"code","3bd8dba0":"code","48585b98":"code","7a487668":"code","a3f7f44b":"markdown","c3cbfa3c":"markdown"},"source":{"28d4e4a7":"import argparse\nimport random\nimport os\nimport glob\nimport numpy as np\nimport pickle as pkl\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch.utils.data as data\nimport torch.nn.functional as F\n\nfrom sklearn.metrics import confusion_matrix\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport matplotlib.patches as mpatches\nimport rasterio\nfrom PIL import Image\n\nif torch.cuda.is_available():        \n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")    \n    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n    print('We will use the GPU:', torch.cuda.get_device_name(0))# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n    \nfrom sklearn.ensemble import RandomForestClassifier as RFClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn\nimport pandas as pd\nimport glob ","eac9d29b":"# -------------------------------------- utils.py --------------------------------------------------\ndef convert_to_np(tensor):\n    # convert pytorch tensors to numpy arrays\n    if not isinstance(tensor, np.ndarray):\n        tensor = tensor.cpu().numpy()\n    return tensor\n\n\ndef labels_to_dfc(tensor, no_savanna):\n    \"\"\"\n    INPUT:\n    Classes encoded in the training scheme (0-9 if savanna is a valid label\n    or 0-8 if not). Invalid labels are marked by 255 and will not be changed.\n\n    OUTPUT:\n    Classes encoded in the DFC2020 scheme (1-10, and 255 for invalid).\n    \"\"\"\n\n    # transform to numpy array\n    tensor = convert_to_np(tensor)\n\n    # copy the original input\n    out = np.copy(tensor)\n\n    # shift labels if there is no savanna class\n    if no_savanna:\n        for i in range(2, 9):\n            out[tensor == i] = i + 1\n    else:\n        pass\n\n    # transform from zero-based labels to 1-10\n    out[tensor != 255] += 1\n\n    # make sure the mask is intact and return transformed labels\n    assert np.all((tensor == 255) == (out == 255))\n    return out\n\n\ndef display_input_batch(tensor, display_indices=0, brightness_factor=3):\n\n    # extract display channels\n    tensor = tensor[:, display_indices, :, :]\n\n    # restore NCHW tensor shape if single channel image\n    if len(tensor.shape) == 3:\n        tensor = tensor.unsqueeze(1)\n\n    # scale image\n    tensor = torch.clamp((tensor * brightness_factor), 0, 1)\n\n    return tensor\n\n\ndef display_label_batch(tensor, no_savanna=False):\n\n    # get predictions if input is one-hot encoded\n    if len(tensor.shape) == 4:\n        tensor = tensor.max(1)[1]\n\n    # convert train labels to DFC2020 class scheme\n    tensor = labels_to_dfc(tensor, no_savanna)\n\n    # colorize labels\n    cmap = mycmap()\n    imgs = []\n    for s in range(tensor.shape[0]):\n        im = (tensor[s, :, :] - 1) \/ 10\n        im = cmap(im)[:, :, 0:3]\n        im = np.rollaxis(im, 2, 0)\n        imgs.append(im)\n    tensor = np.array(imgs)\n\n    return tensor\n\n\ndef display_dfc_labels(tensor, no_savanna=True):\n    cmap = mycmap()\n    imgs = []\n    for s in range(tensor.shape[0]):\n        im = (tensor[s, :, :]-1)\/10\n        im = cmap(im)[:, :, 0:3]\n        im = np.rollaxis(im, 2, 0)\n        imgs.append(im)\n    tensor = np.array(imgs)\n    \n    return tensor\n\n\ndef classnames(no_savanna=True):\n    \n    if no_savanna:\n        return [\"Forest\", \"Shrubland\", \"Grassland\", \"Wetlands\",\n            \"Croplands\", \"Urban\/Built-up\", \"Snow\/Ice\", \"Barren\", \"Water\"]\n    \n    return [\"Forest\", \"Shrubland\", \"Savanna\", \"Grassland\", \"Wetlands\",\n        \"Croplands\", \"Urban\/Built-up\", \"Snow\/Ice\", \"Barren\", \"Water\"]\n\n\ndef mycmap():\n    cmap = colors.ListedColormap(['#009900',\n                                  '#c6b044',\n                                  '#fbff13',\n                                  '#b6ff05',\n                                  '#27ff87',\n                                  '#c24f44',\n                                  '#a5a5a5',\n                                  '#69fff8',\n                                  '#f9ffa4',\n                                  '#1c0dff',\n                                  '#ffffff'])\n    return cmap\n\n\ndef mypatches():\n    patches = []\n    for counter, name in enumerate(classnames()):\n        patches.append(mpatches.Patch(color=mycmap().colors[counter],\n                                      label=name))\n    return patches\n\ndef cvt_rgb(img):\n    r, g, b = np.expand_dims(img[0, :, :], axis=2), np.expand_dims(img[1, :, :], axis=2), np.expand_dims(img[2, :, :], axis=2)\n    rgb = np.concatenate((r, g, b), axis=2)\n    \n    return rgb","ed62624e":"def get_ndvi(s2_data):\n    nir, red = s2_data[7], s2_data[3]\n    # print(nir.shape, red.shape)\n    return (nir-red)\/(nir+red)\n\ndef get_ndwi(s2_data):\n    nir, green = s2_data[7], s2_data[2]\n    return (green-nir)\/(green+nir)\n\ndef get_ndbi(s2_data):\n    swir, nir = s2_data[10], s2_data[7]\n    return (swir - nir)\/(swir + nir)\n\ndef get_mndwi(s2_data):\n    green, swir = s2_data[2], s2_data[10]\n    return (green - swir)\/(green + swir)\n\ndef get_savi(s2_data):\n    nir, red = s2_data[7], s2_data[3]\n    return (1.428 * (nir - red)) \/ (nir + red + 1.428)\n\ndef get_ibi(s2_data):\n    ndbi = get_ndbi(s2_data)\n    savi = get_savi(s2_data)\n    mndwi = get_mndwi(s2_data)\n\n    return (ndbi - 0.5 * (savi + mndwi))\/(ndbi + 0.5 * (savi + mndwi))\n\ndef get_sipi(s2_data):\n    nir, blue, red = s2_data[7], s2_data[1], s2_data[3]\n    return (nir - blue)\/(nir - red)\n\ndef get_gvi(s2_data):\n    return (-0.2848 * s2_data[1]) + (-0.2435 * s2_data[2]) + (-0.5436 * s2_data[3]) + (0.7243 * s2_data[8]) + (0.0840 * s2_data[10]) + (-0.1800 * s2_data[11])\n\ndef indices2labels(tensor):\n    \n    \"\"\"\n    input: tensor will be size (256, 256, 6)\n    output lables \n    \"\"\"\n\n    row, col, ch = tensor.shape\n    refined_label = np.zeros((row, col))\n\n    for i in range(row):\n        for j in range(col):\n\n            if tensor[i, j, 0] > 0.4:\n                refined_label[i, j] = 1\n            \n            elif 0.1 < tensor[i, j, 0] < 0.4:\n\n                if 0 < tensor[i, j, 5] < 400 and tensor[i, j, 4] < 0:\n                    refined_label[i, j] = 2\n\n                elif tensor[i, j, 0] > 0.3 and (tensor[i, j, 3] < 0 or tensor[i, j, 5] > 0):\n                    refined_label[i, j] = 4\n\n                elif tensor[i, j, 0] > 0.3 and (tensor[i, j, 1] < 0.1 or tensor[i, j, 5] > 400):\n                    refined_label[i, j] = 5\n                \n            elif tensor[i, j, 0] > 0.1 and tensor[i, j, 4] < 0:\n                refined_label[i, j] = 6\n                \n\n            elif tensor[i, j, 0] < 0.4:\n            \n                if tensor[i, j, 2] > -0.1 and tensor[i, j, 4] < 0:\n                    refined_label[i, j] = 7\n                \n                if tensor[i, j, 1] > 0 and tensor[i, j, 2] > 0 and tensor[i, j, 5] < 0:\n                    refined_label[i, j] = 9\n                \n\n            elif tensor[i, j, 4] > 0 and tensor[i, j, 5] > 0:\n                refined_label[i, j] = 10\n\n    return refined_label\n","e7db4cdb":"# -------------------------------- metrics.py -------------------------------------------------------\nclass ConfMatrix():\n\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n        self.state = np.zeros((self.num_classes, self.num_classes))\n\n    def calc(self, gt, pred):\n        \"\"\" calcs and returns the CM without saveing it to state \"\"\"\n        return confusion_matrix(gt.flatten(),\n                                pred.flatten(),)\n#                                 labels=np.arange(self.num_classes))\n\n    def get_existing_classes(self):\n        return sum(np.sum(self.state, axis=1) > 0)\n\n    def add(self, gt, pred):\n        \"\"\" adds one label mask to the confusion matrix \"\"\"\n\n        assert gt.shape == pred.shape\n        # assert gt.shape == (256, 256)\n\n        gt = gt.flatten()\n        pred = pred.flatten()\n        pred = pred[gt != 255]\n        gt = gt[gt != 255]\n\n        # print(gt.shape, pred.shape)\n        if not gt.size == 0:\n            self.state += confusion_matrix(gt, pred,\n                                          labels=np.arange(self.num_classes))\n\n        return None\n\n    def add_batch(self, gt, pred):\n        \"\"\" adds a batch of label masks to the confusion matrix \"\"\"\n\n        # convert pytorch tensors to numpy arrays\n        if not isinstance(gt, np.ndarray):\n            gt = gt.cpu().numpy()\n            pred = pred.cpu().numpy()\n\n        assert len(gt.shape) == 3       # assert C x W x H\n\n        noc = gt.shape[0]               # number of channels\n        for batchindex in range(noc):   # iterate over batch\n            self.add(gt[batchindex], pred[batchindex])\n\n        return None\n\n    def norm_on_lines(self):\n        \"\"\" norms along the lines of the matrix \"\"\"\n\n        a = self.state\n        b = np.sum(self.state, axis=1)[:, None]\n        return np.divide(a, b, out=np.zeros_like(a), where=b != 0)\n    \n    def class_acc(self):\n        confmatrix = self.norm_on_lines()\n        return np.diagonal(confmatrix)\n\n    def get_aa(self):\n        confmatrix = self.norm_on_lines()\n        return np.diagonal(confmatrix).sum() \/ self.get_existing_classes()\n\n    def get_IoU(self):\n        res = np.zeros(self.num_classes)\n        for i in range(self.num_classes):\n            cm = self.state\n            a = cm[i, i]\n            b = (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n            res[i] = np.divide(a, b, out=np.zeros_like(a), where=b != 0)\n        return res\n\n    def get_mIoU(self):\n        return np.mean(self.get_IoU())\n\n\ndef AA(gt, pred, num_classes):\n    \"\"\" This is the mean over the diagonal of the confusion\n    matrix when it's normed \"\"\"\n\n    cm = ConfMatrix(num_classes)\n    cm.add(gt, pred)\n    confmatrix = cm.norm_on_lines()\n\n    return np.mean(np.diagonal(confmatrix)),\n\n\ndef IoU(gt, pred, num_classes):\n    \"\"\"\n    the intersection over union for class i can be calculated as follows:\n\n\n    get the intersection:\n        >>> thats the element [i,i] of the confusion matrix (cm)\n\n    the union:\n        >>> is the sum over row with index i plus the sum over line with index\n        i minux the diagonal element [i,i] (otherwise its counted twice)\n\n    \"\"\"\n\n    cm = ConfMatrix(num_classes).calc(gt, pred)\n\n    res = np.zeros(num_classes)\n    for i in range(num_classes):\n        res[i] = cm[i, i] \/ (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n\n    return res\n\n\ndef mIoU(gt, pred, num_classes):\n    return np.mean(IoU(gt, pred, num_classes))","b79d8dd9":"# ----------------------------- datasets.py -----------------------------------------------\n# mapping from igbp to dfc2020 classes\nDFC2020_CLASSES = [\n    0,  # class 0 unused in both schemes\n    1,\n    1,\n    1,\n    1,\n    1,\n    2,\n    2,\n    3,  # --> will be masked if no_savanna == True\n    3,  # --> will be masked if no_savanna == True\n    4,\n    5,\n    6,  # 12 --> 6\n    7,  # 13 --> 7\n    6,  # 14 --> 6\n    8,\n    9,\n    10\n    ]\n\n# indices of sentinel-2 high-\/medium-\/low-resolution bands\nS2_BANDS_HR = [2, 3, 4, 8]\nS2_BANDS_MR = [5, 6, 7, 9, 12, 13]\nS2_BANDS_LR = [1, 10, 11]\n\ndef load_indices(path, use_hr, use_mr, use_lr):\n    bands_selected = []\n    if use_hr:\n        bands_selected = bands_selected + S2_BANDS_HR\n    if use_mr:\n        bands_selected = bands_selected + S2_BANDS_MR\n    if use_lr:\n        bands_selected = bands_selected + S2_BANDS_LR\n    bands_selected = sorted(bands_selected)\n    with rasterio.open(path) as data:\n        s2 = data.read(bands_selected)\n\n    # print(\"s2 shape: {}\".format(s2.shape))\n    \n    indices = np.expand_dims(get_ndvi(s2), axis=0)\n    indices = np.concatenate((indices, np.expand_dims(get_ndbi(s2), axis=0)), axis=0)\n    indices = np.concatenate((indices, np.expand_dims(get_ibi(s2), axis=0)), axis=0)\n    indices = np.concatenate((indices, np.expand_dims(get_ndwi(s2), axis=0)), axis=0)\n    indices = np.concatenate((indices, np.expand_dims(get_mndwi(s2), axis=0)), axis=0)\n    indices = np.concatenate((indices, np.expand_dims(get_gvi(s2), axis=0)), axis=0)\n    return indices\n    \n    \n\n# util function for reload_s2ading s2 data\ndef load_s2(path, use_hr, use_mr, use_lr):\n    bands_selected = []\n    if use_hr:\n        bands_selected = bands_selected + S2_BANDS_HR\n    if use_mr:\n        bands_selected = bands_selected + S2_BANDS_MR\n    if use_lr:\n        bands_selected = bands_selected + S2_BANDS_LR\n    bands_selected = sorted(bands_selected)\n    with rasterio.open(path) as data:\n        s2 = data.read(bands_selected)\n    s2 = s2.astype(np.float32)\n    s2 = np.clip(s2, 0, 10000)\n    s2 \/= 10000\n    s2 = s2.astype(np.float32)\n    return s2\n\n\n# util function for reading s1 data\ndef load_s1(path):\n    with rasterio.open(path) as data:\n        s1 = data.read()\n    s1 = s1.astype(np.float32)\n    s1 = np.nan_to_num(s1)\n    s1 = np.clip(s1, -25, 0)\n    s1 \/= 25\n    s1 += 1\n    s1 = s1.astype(np.float32)\n    return s1\n\n\ndef load_dfc(path, no_savanna):\n    with rasterio.open(path) as data:\n        dfc = data.read()\n    dfc = dfc[0]\n    \n    # adjust class scheme to ignore class savanna\n    # if no_savanna:\n    #    dfc[dfc == 3] = 0\n    #    dfc[dfc > 3] -= 1\n\n    # convert to zero-based labels and set ignore mask\n    # dfc -= 1\n    # dfc[dfc == -1] = 255\n    return dfc\n\n\n# util function for reading lc data\ndef load_lc(path, no_savanna=False, igbp=True):\n\n    # load labels\n    with rasterio.open(path) as data:\n        lc = data.read(1)\n\n    # convert IGBP to dfc2020 classes\n    if igbp:\n        lc = np.take(DFC2020_CLASSES, lc)\n    else:\n        lc = lc.astype(np.int64)\n\n    # adjust class scheme to ignore class savanna\n    # if no_savanna:\n    #    lc[lc == 3] = 0\n    #    lc[lc > 3] -= 1\n\n    # convert to zero-based labels and set ignore mask\n    # lc -= 1\n    # lc[lc == -1] = 255\n    return lc\n\n\n# util function for reading data from single sample\ndef load_sample(sample, use_s1, use_s2hr, use_s2mr, use_s2lr, subset,\n                use_indices=True, no_savanna=False, igbp=True, unlabeled=False):\n\n    use_s2 = use_s2hr or use_s2mr or use_s2lr\n\n    # load s2 data\n    if use_s2:\n        img = load_s2(sample[\"s2\"], use_s2hr, use_s2mr, use_s2lr)\n\n    # load s1 data\n    if use_s1:\n        if use_s2:\n            img = np.concatenate((img, load_s1(sample[\"s1\"])), axis=0)\n        else:\n            img = load_s1(sample[\"s1\"])\n            \n    # print(\"img shape: \", img.shape)\n    # print(\"indices shape: \", load_indices(sample[\"s2\"], use_s2hr, use_s2mr, True).shape)\n    if use_indices:\n        img = np.concatenate((img, \n                              load_indices(sample[\"s2\"], use_s2hr, use_s2mr, True)), \n                             axis=0)\n\n    # load label\n    if unlabeled:\n        return {'image': img, 'id': sample[\"id\"]}\n    else:\n#         if subset == \"val\":\n#             print(\"subset is val, using DFC\")\n#             lc = load_dfc(sample[\"dfc\"], no_savanna=no_savanna)\n#         else:\n#             print(\"subset is train, using LC\")\n        lc = load_lc(sample[\"lc\"], no_savanna=no_savanna, igbp=igbp)\n        \n        return {'image': img, 'label': lc, 'id': sample[\"id\"]}\n\n\n# calculate number of input channels\ndef get_ninputs(use_s1, use_s2hr, use_s2mr, use_s2lr):\n    n_inputs = 0\n    if use_s2hr:\n        n_inputs += len(S2_BANDS_HR)\n    if use_s2mr:\n        n_inputs += len(S2_BANDS_MR)\n    if use_s2lr:\n        n_inputs += len(S2_BANDS_LR)\n    if use_s1:\n        n_inputs += 2\n    return n_inputs\n\n\n# select channels for preview images\ndef get_display_channels(use_s2hr, use_s2mr, use_s2lr):\n    if use_s2hr and use_s2lr:\n        display_channels = [3, 2, 1]\n        brightness_factor = 3\n    elif use_s2hr:\n        display_channels = [2, 1, 0]\n        brightness_factor = 3\n    elif not (use_s2hr or use_s2mr or use_s2lr):\n        display_channels = 0\n        brightness_factor = 1\n    else:\n        display_channels = 0\n        brightness_factor = 3\n    return (display_channels, brightness_factor)\n\n\nclass DFC2020(data.Dataset):\n    \"\"\"PyTorch dataset class for the DFC2020 dataset\"\"\"\n\n    def __init__(self,\n                 path,\n                 subset=\"val\",\n                 no_savanna=False,\n                 use_s2hr=False,\n                 use_s2mr=False,\n                 use_s2lr=False,\n                 use_s1=False):\n        \"\"\"Initialize the dataset\"\"\"\n\n        # inizialize\n        super(DFC2020, self).__init__()\n\n        # make sure parameters are okay\n        if not (use_s2hr or use_s2mr or use_s2lr or use_s1):\n            raise ValueError(\"No input specified, set at least one of \"\n                             + \"use_[s2hr, s2mr, s2lr, s1] to True!\")\n        self.use_s2hr = use_s2hr\n        self.use_s2mr = use_s2mr\n        self.use_s2lr = use_s2lr\n        self.use_s1 = use_s1\n        assert subset in [\"train\", \"val\", \"test\"]\n        self.no_savanna = no_savanna\n        self.subset = subset\n\n        # provide number of input channels\n        self.n_inputs = get_ninputs(use_s1, use_s2hr, use_s2mr, use_s2lr)\n        # print(\"no of inputs: \", self.n_inputs)\n\n        # provide index of channel(s) suitable for previewing the input\n        self.display_channels, self.brightness_factor = get_display_channels(\n                                                            use_s2hr,\n                                                            use_s2mr,\n                                                            use_s2lr)\n\n        # provide number of classes\n        if no_savanna:\n            self.n_classes = max(DFC2020_CLASSES) - 1\n        else:\n            self.n_classes = max(DFC2020_CLASSES)\n        # print(\"no of classes: \", self.n_classes)\n\n        # make sure parent dir exists\n        assert os.path.exists(path)\n\n        # create dataset for training:\n        if subset == \"train\":\n            path = os.path.join(path, \"s2_0\")\n            # print(len(folders))\n\n            s2_locations = glob.glob(os.path.join(path, \"*.tif\"), recursive=True)\n\n            self.samples = []\n            for s2_loc in tqdm(s2_locations, desc=\"[Load]\"):\n                # print(\"s2_loc:\", s2_loc)\n                s1_loc = s2_loc.replace(\"_s2_\", \"_s1_\").replace(\"s2_\", \"s1_\")\n                # print(\"s1_loc:\", s1_loc)\n                lc_loc = s2_loc.replace(\"_s2_\", \"_lc_\").replace(\"s2_\", \"lc_\")\n                # print(\"lc_loc:\", lc_loc)\n                dfc_loc = s2_loc.replace(\"_s2_\", \"_dfc_\").replace(\"s2_\", \"dfc_\")\n                self.samples.append({\"lc\": lc_loc, \"s1\": s1_loc, \"s2\": s2_loc, \"dfc\": dfc_loc,\n                                        \"id\": os.path.basename(s2_loc)})\n            \n            \n        else:\n            # build list of sample paths\n            if subset == \"val\":\n                path = os.path.join(path, \"ROIs0000_validation\", \"s2_validation\")\n                # print(\"path\", path)\n            else:\n                path = os.path.join(path, \"ROIs0000_test\", \"s2_0\")\n        \n            s2_locations = glob.glob(os.path.join(path, \"*.tif\"), recursive=True)\n            \n            self.samples = []\n            for s2_loc in tqdm(s2_locations, desc=\"[Load]\"):\n                # print(\"s2_loc:\", s2_loc)\n                s1_loc = s2_loc.replace(\"_s2_\", \"_s1_\").replace(\"s2_\", \"s1_\")\n                # print(\"s1_loc:\", s1_loc)\n                lc_loc = s2_loc.replace(\"_dfc_\", \"_lc_\").replace(\"s2_\", \"dfc_\")\n                dfc_loc = s2_loc.replace(\"_s2_\", \"_dfc_\").replace(\"s2_\", \"dfc_\")\n                # print(\"lc_loc:\", lc_loc)\n                self.samples.append({\"lc\": lc_loc, \"s1\": s1_loc, \"s2\": s2_loc, \"dfc\": dfc_loc,\n                                    \"id\": os.path.basename(s2_loc)})\n\n        # sort list of samples\n        self.samples = sorted(self.samples, key=lambda i: i['id'])\n\n        print(\"loaded\", len(self.samples),\n              \"samples from the dfc2020 subset\", subset)\n\n    def __getitem__(self, index):\n        \"\"\"Get a single example from the dataset\"\"\"\n\n        # get and load sample from index file\n        sample = self.samples[index]\n        return load_sample(sample, self.use_s1, self.use_s2hr, self.use_s2mr,\n                           self.use_s2lr, self.subset, use_indices=True, \n                           no_savanna=self.no_savanna, igbp=True)\n\n    def __len__(self):\n        \"\"\"Get number of samples in the dataset\"\"\"\n        return len(self.samples)","d760ec8e":"args = {\n    \"experiment_name\": \"exp1\",\n    \"seed\": None,\n    \"val_freq\": 100,\n    \"save_freq\": 100,\n    \"log_freq\": 10,\n    \n    \"use_s2hr\": True,\n    \"use_s2mr\": True,\n    \"use_s2lr\": False,\n    \"use_s1\": True,\n    \"no_savanna\": True,\n    \n    \"lr\": 0.01,\n    \"momentum\": 0.9,\n    \"weight_decay\": 5e-4,\n    \"batch_size\": 4,\n    \"workers\": 1,\n    \"max_epochs\": 2,\n    \n    \"model\": \"unet\",\n    \n    \"pretrained_backbone\": False,\n    \"out_stride\": 16,\n    \n    \"data_dir_train\": \"..\/input\/dfc-2020\/train\/zips\/\",\n    \"dataset_val\": \"dfc2020_val\",\n    \"data_dir_val\": \"..\/input\/dfc-2020\/val\/\",\n    \"log_dir\": None,\n}","796df22d":"train_set = DFC2020(args[\"data_dir_train\"],\n                    subset=\"train\",\n                    no_savanna=args[\"no_savanna\"],\n                    use_s2hr=args[\"use_s2hr\"],\n                    use_s2mr=args[\"use_s2mr\"],\n                    use_s2lr=args[\"use_s2lr\"],\n                    use_s1=args[\"use_s1\"])\nn_classes = train_set.n_classes\nn_inputs = train_set.n_inputs\n\ndfc2020_subset = args[\"dataset_val\"].split(\"_\")[-1]\nval_set = DFC2020(args[\"data_dir_val\"],\n                    subset=dfc2020_subset,\n                    no_savanna=args[\"no_savanna\"],\n                    use_s2hr=args[\"use_s2hr\"],\n                    use_s2mr=args[\"use_s2mr\"],\n                    use_s2lr=args[\"use_s2lr\"],\n                    use_s1=args[\"use_s1\"])","447cc673":"# from cuml import RandomForestClassifier as cuRF\n# cu_rf_params = {'n_estimators':10, 'max_depth':40, 'min_samples_split':2000, 'verbose':1}\n# cu_RF = cuRF(**cu_rf_params)\n\n# print(cu_RF)","1dbd10c4":"def get_train_data_4_RF(train_set, req_samples=20000000):\n    \n    # req_samples = 20000000\n    cnt_samples = 0\n    img2return, label2return = None, None\n    \n    while(req_samples > cnt_samples):\n        idx = np.random.randint(low=0, high=5128)\n        if idx == 2704:\n            continue\n        \n        sample = train_set.__getitem__(idx)\n        n_ = np.random.randint(low=1, high=req_samples-cnt_samples+1)\n        idx2 = np.random.randint(low=0, high=256*256, size = n_)\n        # print(req_samples, cnt_samples, n_)\n\n        img = np.reshape(sample['image'], (18, -1)).T\n        label = np.expand_dims(sample['label'].flatten(), axis=1)\n        \n        if img2return is None:\n            img2return, label2return = img[idx2], label[idx2]\n        else:\n            img2return = np.concatenate((img2return, img[idx2]))\n            label2return = np.concatenate((label2return, label[idx2]))\n            \n        cnt_samples += n_\n    return img2return, label2return\n\ndef get_RFclf(use_class_wt):\n    if use_class_wt:\n        return RFClassifier(n_estimators=20, max_depth=40, \n                       min_samples_split=2000, verbose=2,\n                       n_jobs=4, class_weight=\"balanced\")\n    \n    return RFClassifier(n_estimators=20, max_depth=40, \n                       min_samples_split=2000, verbose=2,\n                       n_jobs=4)\n\ndef get_acc_val(rf_clf):\n    \n    rf_clf.verbose = 0\n    conf_mat = ConfMatrix(num_classes=10)\n\n    for i in tqdm(range(len(val_set))):\n\n        sample = val_set.__getitem__(i)\n        \n        img = np.reshape(sample['image'], (18, -1)).T\n        pred = np.reshape(rf_clf.predict(img), (256, 256))\n        \n        conf_mat.add(pred, sample['label'])\n    return conf_mat\n\ndef get_acc_trainset(rf_clf):\n    \n    rf_clf.verbose = 0\n    conf_mat = ConfMatrix(num_classes=10)\n\n    for i in tqdm(range(len(val_set))):\n\n        sample = train_set.__getitem__(i)\n        \n        img = np.reshape(sample['image'], (18, -1)).T\n        pred = np.reshape(rf_clf.predict(img), (256, 256))\n        \n        conf_mat.add(pred, sample['label'])\n    return conf_mat\n     \n\ndef train20RFs(use_cls_wt):\n    \n    clf_names = ['RF_clf' + str(i) for i in range(1, 21)]\n    results = []\n    \n    clf, img2train, label2train = None, None, None\n    \n    folder_path = \"output\"\n    if not os.path.exists(folder_path):\n        os.mkdir(folder_path)\n    \n    for i in range(20):\n        print(\"==\"*40)\n        result = {}\n        print(\"Training RF classifier: {}\".format(clf_names[i]))\n        result[\"model\"] = clf_names[i]\n        \n        \n        print(\"loading training samples....\")\n        img2train, label2train = get_train_data_4_RF(train_set)\n        \n        result['uniq_labels'] = str(list(np.unique(label2train)))\n        \n        clf = get_RFclf(use_cls_wt)\n         \n        print(\"Training model\")\n        clf.fit(img2train, label2train)\n        \n        print(\"Saving model.....\")\n        file_name = os.path.join(folder_path, clf_names[i] + \".pkl\")\n        with open(file_name, \"wb\") as f:\n            pkl.dump(clf, f)\n        print(clf_names[i], \":: Saved @ \", file_name)\n        \n        train_scr = clf.score(img2train, label2train)\n        train_cm = confusion_matrix(clf.predict(img2train), label2train)\n        \n        result['train_scr'] = train_scr\n        result['train_cm'] = train_cm\n        \n        # val_cm = get_acc_val(clf)\n        \n        # result['val_scr'] = val_cm.get_aa()\n        # result['val_cm'] = val_cm.state\n        \n        results.append(result)\n        \n        clf, img2train, label2train = None, None, None\n        \n    print(\"saving results to csv file\")\n    df = pd.DataFrame(results)\n    df.to_csv(os.path.join(folder_path, 'RF20_same_wt.csv'))\n    print(\"saved :)\")","67ec0f01":"def main(use_class_wt):\n    \n#     if use_class_wt:\n#         lc_class_wt = get_lc_samples_wt()   \n    \n#         with open(\"sample_wt_org.txt\", \"w\") as f:\n#             f.write(str(lc_class_wt))\n        \n#         mod_dct = {}\n\n#         for x in lc_class_wt.keys():\n#             mod_dct[x] = 1 \/ lc_class_wt[x]\n    if use_class_wt:\n        print(\"use class weights\")\n    else:\n        print(\"use equal weights\")\n    train20RFs(use_class_wt)","3089d1c2":"# main(1)","85cc3a57":"def update_val_acc():\n\n    df = pd.read_csv(\"..\/input\/k\/sameerkoleshwar\/train-rf\/output\/RF20_same_wt.csv\")\n    \n    val = []\n    class_acc_lst = []\n    \n    path = \"..\/input\/k\/sameerkoleshwar\/train-rf\/output\"\n    \n    files = list(df['model'])\n    \n    \n    for name in files:\n        \n        clf_path = os.path.join(path, name + \".pkl\")\n        print(clf_path)\n        with open(clf_path, \"rb\") as f:\n            clf = pkl.load(f)\n\n        clf.verbose=0\n        conf_mat = ConfMatrix(11)\n\n        for i in tqdm(range(len(val_set))):\n            sample = val_set.__getitem__(i)\n            img = np.reshape(sample['image'], (18, -1)).T\n            label = sample['label']\n            pred = np.reshape(clf.predict(img), (256, 256))\n\n            conf_mat.add(label, pred)\n            \n        cls_names = classnames(no_savanna=False)\n        cls_acc = conf_mat.class_acc()[1:]\n\n        lst = []\n        for i in range(len(cls_acc)):\n            lst.append([cls_names[i], cls_acc[i]])\n        class_acc_lst.append(lst)\n        val.append(conf_mat.get_aa())\n        \n        print(conf_mat.get_aa(), lst)\n        \n    df['val_acc'] = val\n    df['class_acc_lst'] = class_acc_lst\n    \n    return df","73b05d8d":"update_df = update_val_acc()\nupdate_df.to_csv(\"updated_csv.csv\", index=False)","e79f517a":"from sklearn.ensemble import VotingClassifier\nfrom scipy.stats import mode\n\ndef ensemble_RF(dataset):\n    \n    df = pd.read_csv(\"..\/input\/k\/sameerkoleshwar\/train-rf\/output\/RF20_same_wt.csv\")\n    model_lst = list(df['model'])\n    conf_mat = ConfMatrix(11)\n    path = \"..\/input\/k\/sameerkoleshwar\/train-rf\/output\"\n    \n    estimator = []\n    for i, name in enumerate(model_lst):\n        clf_path = os.path.join(path, name + \".pkl\")\n        with open(clf_path, \"rb\") as f:\n            clf = pkl.load(f)\n        clf.verbose = 0\n        estimator.append((name, clf))\n    \n#     soft_voting_clf = VotingClassifier(estimators=estimator, voting='soft')\n#     print(soft_voting_clf)\n#     \n#     soft_voting_clf.fit()\n    \n    for i in tqdm(range(len(dataset))):\n        sample = val_set.__getitem__(i)\n        img = np.reshape(sample['image'], (18, -1)).T\n        label = sample['label']\n        y_pred_all = np.zeros((256*256, 20))\n        for x in range(20):\n            y_pred_all[:, i] = estimator[i][1].predict(img)\n        \n        y_pred =  np.reshape(mode(y_pred_all, axis=1)[0],(256, 256))\n        \n        conf_mat.add(label, y_pred)\n        \n    return conf_mat","21a71338":"cnf_mat_all = ensemble_RF(val_set)\n\nprint(\"val acc: {}\".format(cnf_mat_all.get_aa()))\nplt.figure(figsize=(15, 6))\nseaborn.heatmap(cnf_mat_all.state, \n                fmt='.1f', cmap='YlGnBu', annot=True, \n                xticklabels=classnames(False), yticklabels=classnames(False))\n\nplt.savefig(\"cnf_mat_all.png\")\nplt.show()\n","304cdb6e":"# df = pd.read_csv(\"..\/input\/k\/sameerkoleshwar\/train-rf\/output\/RF20_same_wt.csv\")\n# model_lst = list(df['model'])\n# conf_mat = ConfMatrix(11)\n# path = \"..\/input\/k\/sameerkoleshwar\/train-rf\/output\"","80591277":"# estimator = []\n# for i, name in enumerate(model_lst):\n#     clf_path = os.path.join(path, name + \".pkl\")\n#     with open(clf_path, \"rb\") as f:\n#         clf = pkl.load(f)\n#     clf.verbose = 0\n#     estimator.append((name, clf))\n\n# # estimator","1ac16cf5":"# sample = val_set.__getitem__(i)\n# img = np.reshape(sample['image'], (18, -1)).T\n# label = sample['label']\n# y_pred_all = np.zeros((256*256, 20))\n# for x in range(20):\n#     y_pred_all[:, i] = estimator[i][1].predict(img)\n\n# y_pred =  np.reshape(mode(y_pred_all, axis=1)[0], (256, 256))\n\n# conf_mat.add(label, y_pred)","0b4c3cc2":"# conf_mat.state","7fb4759b":"\"\"\"\nRF1 RF2 RF3 RF4 RF5 RF6 RF7 ....   RF18 RF19 RF20 y_pred y_true\n1    2  2   2   2   2              3    10   5    2      4\n\n\"\"\"","3ad8bcfa":"# with open(\"..\/input\/k\/sameerkoleshwar\/train-rf\/output\/RF_clf1.pkl\", \"rb\") as f:\n#     clf = pkl.load(f)\n# clf.verbose = 0","8e5fa4f1":"# conf_mat = ConfMatrix(11)\n# # \n# for i in tqdm(range(len(val_set))):\n#     sample = val_set.__getitem__(i)\n\n#     # print(sample['image'].shape, sample['label'].shape)\n\n#     img = np.reshape(sample['image'], (18, -1)).T\n#     label = sample['label']\n#     pred = np.reshape(clf.predict(img), (256, 256))\n    \n#     # print(sample['id'], np.unique(label), np.unique(pred))\n    \n#     #print(img.shape, pred.shape, label.shape)\n#     conf_mat.add(label, pred)","33b3a397":"# print(\"val acc: {}\".format(conf_mat.get_aa()))\n# plt.figure(figsize=(15, 6))\n# seaborn.heatmap(conf_mat.state[1:, 1:], \n#                 fmt='.1f', cmap='YlGnBu', annot=True, \n#                 xticklabels=classnames(False), yticklabels=classnames(False))\n# plt.show()","99e2aa58":"# cls_names = classnames(False)\n# cls_acc = conf_mat.class_acc()[1:]\n\n# for i in range(len(cls_acc)):\n#     print(\"{:.2f} {}\".format(cls_acc[i]*100, cls_names[i]))","b8ca7d74":"# df = pd.read_csv(\"..\/input\/k\/sameerkoleshwar\/train-rf\/output\/RF20_same_wt.csv\")\n# df","3bd8dba0":"# df['val_acc'] = np.zeros((20, 1))","48585b98":"# df[df['model']=='RF_clf1']['val_acc']","7a487668":"# list(df['model'])","a3f7f44b":"def get_lc_samples_wt():\n    \n    lc_class_samples = {}\n    \n    for i in tqdm(range(len(train_set))):\n        if i == 2704:\n            continue\n\n        with rasterio.open(train_set.samples[i]['lc']) as data2:\n            lc = data2.read(1)\n        lc = np.take(DFC2020_CLASSES, lc)\n\n        uniq = np.unique(lc)\n        for j in uniq:\n            lc_class_samples[j] = lc_class_samples.get(j, 0) + (lc == j).sum()\n    \n    return lc_class_samples","c3cbfa3c":"#### **Test RF classifier**"}}