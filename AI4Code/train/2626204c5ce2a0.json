{"cell_type":{"fe250b89":"code","7da66c2c":"code","10329eb8":"code","4e93a867":"code","7391355d":"code","5d9719d3":"code","ca802dfd":"code","0649520e":"code","58ad8476":"code","f1bbdd5d":"code","068d0283":"code","ca975394":"code","60d03c86":"code","4c53d5ae":"code","e0e71065":"code","c7733e35":"code","bc0cc2d2":"code","1b7ce9b5":"markdown","751ab2ca":"markdown","1a61b0d4":"markdown","10193e84":"markdown","a01b178a":"markdown","05719242":"markdown","d4bb69df":"markdown","5c4bf7ba":"markdown","70e49f20":"markdown","306f295c":"markdown","3e2ac329":"markdown","3ce9da95":"markdown","62e0b353":"markdown","2b3805f0":"markdown","ab291bb7":"markdown"},"source":{"fe250b89":"# To obtain the file path\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","7da66c2c":"import pandas as pd\nimport numpy as np","10329eb8":"df = pd.read_csv(\"\/kaggle\/input\/ecommerce-purchases\/Ecommerce Purchases\")","4e93a867":"df.head()","7391355d":"df.info()","5d9719d3":"df[\"Purchase Price\"].mean()","ca802dfd":"df[\"Purchase Price\"].max()","0649520e":"df[\"Purchase Price\"].min()","58ad8476":"(df[\"Language\"] == \"en\").value_counts()","f1bbdd5d":"df[df[\"Job\"] == \"Lawyer\"].count()","068d0283":"df[\"AM or PM\"].value_counts()","ca975394":"df[\"Job\"].value_counts().head()","60d03c86":"df[df[\"Lot\"] == \"90 WT\"][\"Purchase Price\"]","4c53d5ae":"df[df[\"Credit Card\"] == 4926535242672853 ][\"Email\"]","e0e71065":"df[(df[\"CC Provider\"] == \"American Express\")\n    & (df[\"Purchase Price\"] > 95)].count()","c7733e35":"\nsum(df[\"CC Exp Date\"].apply(lambda x: x[3:] == \"24\"))","bc0cc2d2":"df[\"Email\"].apply(lambda x: x.split(\"@\")[1]).value_counts().head()","1b7ce9b5":"**Check the head of the DataFrame.**","751ab2ca":"### How many people have the job title of \"Lawyer\" ? \n\n- Using the value_counts() method on the series object yields:\n       (df[\"Job\"] == \"Lawyer\").value_counts()\n\n- Alternatively, count() method on the dataframe object could have been used as below:\n","1a61b0d4":"### Hard: How many people have a credit card that expires in 2025? **\n\n- Use a lambda expression to find every entry in the card expiration column that has the last two characters == \"25\" in in quote because the type of the column in object (string)\n- Sum the resulting selection\n","10193e84":"### How many rows and columns are there? \n\n- Use the info() method on the dataframe object to obtain the required information\n\n        Ans: 10000 rows and 14 columns","a01b178a":"### What were the highest and lowest purchase prices?\n\n- Use max() and min() methods on the pandas series object.","05719242":"### Hard: What are the top 5 most popular email providers\/hosts (e.g. gmail.com, yahoo.com, etc...) **\n\n- Select the column on which operation is to be performed\n- Use the apply method to write a lambda expression to extract the email address from every entry in the column\n- Still within the lambda expression, use the split method to split every entry in the email address based on the \"@\" symbol\n- Select the item at index \"1\" of the resulting list. This corrsponds to the email domain.\n- Use the value_counts() method of a pandas series to arrange the entries in descending order of frequencies.\n- Use the head method to extract the first five observations.","d4bb69df":"### What are the 5 most common Job Titles? \n\n- The value_counts() fetches the unique entries in the series object in descending order of frequencies.\n- The head() method fetches the first first entries in the series object","5c4bf7ba":"# Ecommerce Purchases Exercise\n\nIn this Exercise you will be given some Fake Data about some purchases done through Amazon! Just go ahead and follow the directions and try your best to answer the questions and complete the tasks. Feel free to reference the solutions. Most of the tasks can be solved in different ways. For the most part, the questions get progressively harder.\n\nPlease excuse anything that doesn't make \"Real-World\" sense in the dataframe, all the data is fake and made-up.\n\nAlso note that all of these questions can be answered with one line of code.\n____\n** Import pandas and read in the Ecommerce Purchases csv file and set it to a DataFrame called df. **","70e49f20":"### How many people have English 'en' as their Language of choice on the website? \n\n- Using the value_counts() method on the series object yields:\n        (df[\"Language\"] == \"en\").value_counts()\n\n- Alternatively, count on the dataframe object could have been used as below:\n        df[df[\"Language\"] == \"en\"].count()","306f295c":"### Someone made a purchase that came from Lot: \"90 WT\" , what was the Purchase Price for this transaction? \n\n- Use double bracket indexing to fetch the dataframe containing the transaction based on the transaction details \"Lot = 90 WT\"\n- Use another square bracket to index the price from the resulting dataframe","3e2ac329":"### What is the average Purchase Price? \n\n- Use the mean() method on the pandas series","3ce9da95":"### What is the email of the person with the following Credit Card Number: 4926535242672853 \n\n- Use double bracket indexing to fetch the dataframe containing the credit card information\"\n- Use another square bracket to index the email from the resulting dataframe\n","62e0b353":"### How many people made the purchase during the AM and how many people made the purchase during PM ? \n\n- Using value_counts() method will return the unique entries in a column in descending order of frequencies\n\n**(Hint: Check out [value_counts()](http:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.value_counts.html) ) **","2b3805f0":"### How many people have American Express as their Credit Card Provider *and* made a purchase above $95 ?\n\n- Enclose each condition in parenthesis, then use the and \"&\" operator to make sure that both conditions must  be valid for the selection to be made.\n- Fit both conditions into a dataframe selection using a square bracket so that count() method can be used on it.","ab291bb7":"# Great Job!"}}