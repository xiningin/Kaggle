{"cell_type":{"a46faf17":"code","7f642e18":"code","b5119874":"code","cdd32a7c":"code","e1993ad2":"code","90928fd1":"code","32c0e9b9":"code","0d71055a":"code","e882fda0":"code","3db4ca3d":"code","2d30e0f8":"code","4cdc5b4e":"code","2493ef92":"code","edec899d":"code","c6d0fbde":"code","9be6e1c1":"markdown","67547757":"markdown","4b38b0e0":"markdown","c473e457":"markdown","f09c6e39":"markdown","0ab2ec13":"markdown","da73f008":"markdown","fb276c91":"markdown","066c8b04":"markdown","18c1a135":"markdown","ec8e3355":"markdown"},"source":{"a46faf17":"import os\nimport tensorflow as tf\nimport glob\nimport pathlib\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input","7f642e18":"train=\"..\/input\/100-bird-species\/train\"\ntest=\"..\/input\/100-bird-species\/test\"\nvalid=\"..\/input\/100-bird-species\/valid\"","b5119874":"def process(data):\n    path=pathlib.Path(data)#converting the dtring to path\n    filepaths=list(path.glob(r\"*\/*.jpg\"))#Going through all the subpaths \n    labels=list(map(lambda x: os.path.split(os.path.split(x)[0])[1],filepaths))#Separating the label from filepath and storing it\n    df1=pd.Series(filepaths,name='filepaths').astype(str)\n    df2=pd.Series(labels,name='labels')\n    df=pd.concat([df1,df2],axis=1)#Making the dataframe\n    return df","cdd32a7c":"df_train=process(train)\ndf_test=process(test)\ndf_valid=process(valid)","e1993ad2":"df_train.head(6)","90928fd1":"df_train=df_train.sample(frac=1).reset_index(drop=True)#Shuffling the dataframe so we can get random bird pictures\nfig,axes=plt.subplots(nrows=6,ncols=4,figsize=(12,12))\n\nfor i,ax in enumerate(axes.flat):\n    x=plt.imread(df_train['filepaths'][i])#reading the image\n    ax.imshow(x)\n    ax.set_title(df_train['labels'][i])\nplt.tight_layout()    \nplt.show() ","32c0e9b9":"train_generator=ImageDataGenerator( preprocessing_function=preprocess_input)\ntest_generator=ImageDataGenerator( preprocessing_function=preprocess_input)\nvalid_generator=ImageDataGenerator( preprocessing_function=preprocess_input)","0d71055a":"train_image=train_generator.flow_from_dataframe(dataframe=df_train,\n                                                x_col='filepaths',\n                                                y_col='labels',\n                                                target_size=(224,224),\n                                                batch_size=16,\n                                                subset='training',\n                                                random_seed=42)\n\ntest_image = test_generator.flow_from_dataframe(\n    dataframe=df_test,\n    x_col='filepaths',\n    y_col='labels',\n    target_size=(224,224),\n    batch_size=32\n)\n\nvalid_image = test_generator.flow_from_dataframe(\n    dataframe=df_valid,\n    x_col='filepaths',\n    y_col='labels',\n    subset='training',\n    target_size=(224,224),\n    batch_size=32)","e882fda0":"\nfor i in range(3):\n    img, label = train_image[i]\n    print(img.shape) \n    plt.imshow(img[0])\n    plt.show()","3db4ca3d":"vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n\nvgg_model.trainable = False\n\nlayer0 = tf.keras.layers.Flatten(name='flatten')(vgg_model.output)\nlayer1 = tf.keras.layers.Dense(4096, activation='relu',name='fc1')(layer0)\nlayer2 = tf.keras.layers.Dense(4096, activation='relu',name='fc2')(layer1)\nout_layer = tf.keras.layers.Dense(315, activation='softmax')(layer2)\nvgg_model = tf.keras.Model(vgg_model.input, out_layer)\nvgg_model.summary()","2d30e0f8":"opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\nvgg_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])","4cdc5b4e":"callbacks = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)","2493ef92":"history = vgg_model.fit(\n      train_image, \n      epochs=15,\n      verbose=1,\n      validation_data = valid_image,\n      callbacks=callbacks, batch_size = 64)","edec899d":"vgg_model.evaluate(test_image,use_multiprocessing=True,workers=10)","c6d0fbde":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","9be6e1c1":"# Model Evaluation","67547757":"# Train The Model ","4b38b0e0":"# **Visulaize image after preprocessing by VGG16**","c473e457":"**Import the necessary libraries**\n","f09c6e39":"# **Create a model**","0ab2ec13":"# **Data augmentation**","da73f008":"# Using VGG16(Transfer learning)","fb276c91":"# **Data preprocesssing**","066c8b04":"#  Model Plotting\n\n","18c1a135":"# **Reading the images from dataframe**\n\n\n","ec8e3355":"# **Data Visualization**"}}