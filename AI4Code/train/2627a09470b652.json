{"cell_type":{"7d9437d3":"code","080f8758":"code","b1044c59":"code","ad9f0830":"code","c11abab0":"code","76a62bb3":"code","cd532d01":"code","60a9c9d8":"code","c8328552":"code","08cafc26":"code","8d16f7a3":"code","e9ca5bde":"code","739158d0":"code","014a0920":"code","fe8c5107":"code","8379e426":"code","a9bfdfb0":"code","7c570fc1":"code","d8baa289":"code","9154c2d5":"code","b743b487":"code","401b62fb":"code","eee7229a":"markdown","f665a28c":"markdown","086d5483":"markdown","d4dc74be":"markdown","7f981c91":"markdown","3a1c6b1c":"markdown"},"source":{"7d9437d3":"import plotly.offline as pyo\npyo.init_notebook_mode()\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2 \nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing\nimport random\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n!pip install visualkeras","080f8758":"os.listdir('..\/input\/face-expression-recognition-dataset\/images\/images\/')","b1044c59":"def Create_Directory_DataFrame():\n    df =pd.DataFrame(columns=['Class','Location'])\n    basedir = '..\/input\/face-expression-recognition-dataset\/images\/images\/'\n    for folder in os.listdir(basedir):\n        for Class in os.listdir(basedir+folder+'\/'):\n            for location in os.listdir(basedir+folder+'\/'+Class+'\/'):\n                df = df.append({'Class':Class,'Location':basedir+folder+'\/'+Class+'\/'+location},ignore_index=True)\n    df = df.sample(frac = 1) \n    return df\ndf = Create_Directory_DataFrame()\nprint(df.shape)\ndf.head()","ad9f0830":"count = 1\nf = plt.figure(figsize=(50,13))\nfor Class in df['Class'].unique():\n    seg = df[df['Class']==Class]\n    address =  seg.sample().iloc[0]['Location']\n    img = cv2.imread(address,0)\n    ax = f.add_subplot(2, 5,count)\n    ax = plt.imshow(img)\n    ax = plt.title(Class,fontsize= 30)\n    count = count + 1\nplt.suptitle(\"Blood Cell Type\", size = 32)\nplt.show()","c11abab0":"# EDITABLE\nw , h= 32,32\nfinal_class = 7","76a62bb3":"from tqdm import tqdm\nfrom sklearn.preprocessing import OneHotEncoder\ntrain_image = []\nfor location in tqdm(df.iloc[:]['Location']):\n    img = cv2.imread(location,0)\n    img = cv2.resize(img, (w,h), interpolation = cv2.INTER_AREA)\n    img = img.reshape(w,h,1)\n    train_image.append(img)\nX = np.array(train_image)\ny = np.array(df.iloc[:]['Class'])\ny = y.reshape(y.shape[0],1)\nenc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(y)\nprint(enc.categories_)\ny = enc.transform(y).toarray()\nprint('Data   :   '+str(X.shape))\nprint('Output :   '+str(y.shape))","cd532d01":"def sample(ind):\n    print(X[ind].reshape(w,h))\n    print('Output'+str(y[ind]))\n    plt.figure(figsize=(25,8))\n    plt.imshow(X[ind].reshape(w,h))\n    plt.title(enc.inverse_transform(y[0].reshape(1,final_class))[0][0],size = 20)\n    plt.show()\n    \nsample(65)","60a9c9d8":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\nprint('Train data    :'+str(X_train.shape))\nprint('Test data     :'+str(X_test.shape))\nprint('Train Output  :'+str(y_train.shape))\nprint('Test Output   :'+str(y_test.shape))","c8328552":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ]\n    )\n    return block\ndef dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    return block\ndef build_model(act , final_class , w , h ):\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(w , h , 1)),\n        \n        tf.keras.layers.Conv2D(16, 3, activation=act, padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation=act, padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(final_class, activation='sigmoid')\n    ])\n    return model\ndef wrap(Training_Output_Results , lr ,  history):\n    epoch  = len(history.history['loss'])\n    epochs = list(np.arange(1,epoch + 1,1))\n    Optimizer = np.repeat(lr,epoch).tolist()\n    cumiliated_res = {}\n    cumiliated_res['Epochs']=epochs\n    cumiliated_res['Learning Rate']=Optimizer\n    cumiliated_res['Train_Loss']=history.history['loss']\n    cumiliated_res['Train_Accuracy']=history.history['accuracy']\n    cumiliated_res['Train_Precision']=history.history['precision']\n    cumiliated_res['Val_Loss']=history.history['val_loss']\n    cumiliated_res['Val_Accuracy']=history.history['val_accuracy']\n    cumiliated_res['Val_Precision']=history.history['val_precision']\n    convertDictionary = pd.DataFrame(cumiliated_res)\n    Training_Output_Results = Training_Output_Results.append(convertDictionary)\n    return Training_Output_Results\n","08cafc26":"Training_Output_Results =pd.DataFrame(columns=['Epochs','Learning Rate','Train_Loss','Train_Accuracy','Train_Precision','Val_Loss','Val_Accuracy','Val_Precision'])\ndef LR_verify(Training_Output_Results):\n        model = build_model('relu', final_class , w , h)\n        METRICS = [\n                'accuracy',\n                tf.keras.metrics.Precision(name='precision')\n        ]  \n        model.compile(\n                optimizer=tf.keras.optimizers.Adam(),\n                loss='categorical_crossentropy',\n                metrics=METRICS\n            )\n        # EDITABLE epochs\n        history = model.fit(X_train, y_train, epochs=10, validation_split=0.3, batch_size=15,verbose=1,shuffle=True)\n        Training_Output_Results = wrap(Training_Output_Results , 0.00002548,history)\n        return Training_Output_Results,model,history\n    \n    \nTraining_Output_Results ,model,history= LR_verify(Training_Output_Results)","8d16f7a3":"Training_Output_Results.head()","e9ca5bde":"import visualkeras\nvisualkeras.layered_view(model)","739158d0":"from keras.utils import plot_model\nplot_model(model, to_file='model.png',show_shapes=True)","014a0920":"def Plot(history , name , model):\n    model.save(name+'.h5')\n    epochs = range(1,len(history.history['loss']) + 1)\n    epochs = list(epochs)\n    fig = make_subplots(rows=2, cols=3,subplot_titles=(\"Train Loss\", \"Train Accuracy\" , \"Train Precision\",\"Train Recall\", \"Validation Loss\", \"Validation Accuracy\",\n                                                      \"Validation Precision\",\"Validation Recall\"))\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['loss']), row=1, col=1)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['accuracy']), row=1, col=2)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['precision']), row=1, col=3)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_loss']), row=2, col=1)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_accuracy']), row=2, col=2)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_precision']), row=2, col=3)\n    fig.update_layout(showlegend=False,height=1000, width=1200, title_text=name)\n    pyo.iplot(fig, filename = 'Act_train_rec')","fe8c5107":"Plot(history , 'final_model',model)","8379e426":"from keras.models import Model\nimport matplotlib.pyplot as pyplot\nfrom matplotlib.pyplot import figure\nfrom numpy import expand_dims\ndef image_transform_gray(image):\n    plt.figure(figsize=(25,8))\n    plt.imshow(image.reshape(w,h))\n    plt.title(enc.inverse_transform(y[0].reshape(1,final_class))[0][0],size = 20)\n    plt.show()\n    img = expand_dims(image, axis=0)\n    model1 = Model(inputs=model.inputs, outputs=model.layers[0].output)\n    feature_maps = model1.predict(img)\n    figure(num=None, figsize=(25, 30), dpi=80, facecolor='w', edgecolor='k')\n    square = 4\n    ix = 1\n    for _ in range(square):\n        for _ in range(square):\n            # specify subplot and turn of axis\n            ax = pyplot.subplot(square, square, ix)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            # plot filter channel in grayscale\n            pyplot.imshow(feature_maps[0, :, :, ix-1])\n            ix += 1\n    # show the figure\n    pyplot.show()","a9bfdfb0":"image_transform_gray(X[89])","7c570fc1":"import plotly.graph_objects as go\nfrom sklearn.metrics import classification_report\ndef binary_classify(y_pred):\n    for inp in y_pred:\n        maximum = 0\n        index = 0\n        for i in range(final_class):\n            if(maximum != max(maximum,inp[i])):\n                maximum = max(maximum,inp[i])\n                index = i\n            inp[i] = 0\n        inp[index]=1\n    return y_pred\ndef create_result(y):\n    y_final = []\n    for i in range(y.shape[0]):\n        y_final.append(enc.inverse_transform(y[i].reshape(1,final_class))[0][0])\n    return y_final \ndef remove_none(y , y_pred):\n    index = []\n    for i in range(len(y)-1,0,-1):\n        if y_pred[i] == None :\n            del y[i]\n            del y_pred[i]\n    return y , y_pred\ndef label_encode(y , y_pred):\n    le = preprocessing.LabelEncoder()\n    le.fit(y)\n    print('Classes   :    '+str(le.classes_))\n    y = le.transform(y)\n    y_pred = le.transform(y_pred)\n    return y , y_pred\ndef Test_Results_compiled(model,history, name =''):\n    print('Results '+name)\n    y_pred = model.evaluate(X_test , y_test,verbose =1)\n    index = len(history.history['loss']) - 1\n    fig = go.Figure(data=[\n        go.Bar(name = 'Accuracy',x=['Training','Validation','Real World Data'], y=[history.history['accuracy'][index] ,history.history['val_accuracy'][index],y_pred[1] ]),\n        go.Bar(name = 'Precision',x=['Training','Validation','Real World Data'], y=[history.history['precision'][index] ,history.history['val_precision'][index],y_pred[2] ]),\n        go.Bar(name = 'Loss',x=['Training','Validation','Real World Data'], y=[history.history['loss'][index] ,history.history['val_loss'][index],y_pred[0] ]),\n\n    ])\n    fig.update_layout(barmode='group')\n    fig.update_yaxes(type = \"log\")\n    pyo.iplot(fig, filename = 'Act_train_rec')\n    y_prediction = model.predict(X_test)\n    y_class_result = create_result(y_prediction)\n    y_class_desired = create_result(y_test)\n    y_label_desired , y_label_result = label_encode(y_class_desired , y_class_result) \n    tn = []\n    for cat in enc.categories_[0].reshape(final_class,1):\n        tn.append(cat[0])\n    target_names = tn\n    print(classification_report(y_label_desired, y_label_result, target_names=target_names))\n    count = 1\n    f = plt.figure(figsize=(20,24))\n    for i in range(20):\n        ind = random.sample(list(y_label_result),1)[0]\n        img = X_test[ind]\n        Class = str(y_class_desired[ind]) + '  vs  '+str(y_class_result[ind])\n        ax = f.add_subplot(5, 4,count)\n        ax = plt.imshow(img.reshape(w,h))\n        ax = plt.title(Class,fontsize= 11)\n        count = count + 1\n    plt.suptitle(\"Emotion Detection\", size = 32)\n    plt.show()\n\n","d8baa289":"Test_Results_compiled(model,history,'CNN Based Model')","9154c2d5":"def Create_Directory_DataFrame():\n    df =pd.DataFrame(columns=['Name','Location'])\n    basedir = '..\/input\/emotion-testing-db\/'\n    for location in os.listdir(basedir):\n        df = df.append({'Name':location , 'Location':basedir+location},ignore_index=True)\n    df = df.sample(frac = 1) \n    return df\ndf_real = Create_Directory_DataFrame()\nprint(df_real.shape)\ndf_real.head()","b743b487":"count = 1\nf = plt.figure(figsize=(20,13))\nfor i in df_real.index:\n    \n    address =  df_real.iloc[i,1]\n    img = cv2.imread(address,0)\n    ax = f.add_subplot(8, 5,count)\n    ax = plt.imshow(img)\n    ax = plt.title(df_real.iloc[i,0],fontsize= 12)\n    count = count + 1\nplt.suptitle(\"Real World Data\", size = 32)\nplt.show()","401b62fb":"for location in (df_real.iloc[:]['Location']):\n    img = cv2.imread(location,0)\n    img = cv2.resize(img, (w,h), interpolation = cv2.INTER_AREA)\n    img = img.reshape(1,w,h,1)\n    model = load_model('final_model.h5')\n    op = model.predict(img)\n    op_tuned = create_result(op)\n    plt.imshow(img.reshape(w,h))\n    plt.title(op_tuned,size = 20)\n    plt.show()\n","eee7229a":"# Model\nTo make our model more modular and easier to understand, let's define some blocks. As we're building a convolution neural network, we'll create a convolution block and a dense layer block. The following method will define the function to build our model for us. The Dropout layers are important as they \"drop out,\" hence the name, certain nodes to reduce the likelikhood of the model overfitting. We want to end the model with a Dense layer of one node For our metrics, we want to include precision and recall as they will provide use with a more informed picture of how good our model is. Accuracy tells us what fractions are the labels are correct. Since our data is not balanced, accuracy might give a skewed sense of a good model (i.e. a model that always predicts PNEUMONIA will be 74% accurate but is not a good model).\n\nPrecision is the number of true positives (TP) over the sum of TP and false positives (FP). It shows what fraction of labeled positives are actually correct.\n\nRecall is the number of TP over the sum of TP and false negatves (FN). It shows what fraction of actual positives are correct.","f665a28c":"# SAMPLES","086d5483":"# Real World Test","d4dc74be":"# Visualization","7f981c91":"# Create A Stacked Numpy Array\nI Brief Idea for Image Loading\n\nRead Images\nResize them\nAdd to a list\nConvert the list to np array\n\n\nII Output array\n\nRead the classes\nreshape to 1 D array\nOne hot encode the same","3a1c6b1c":"# Segmentation in Traing and Test Data Sets\nTraining : 80%\nTest : 20%\nValidation : 30%"}}