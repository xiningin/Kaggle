{"cell_type":{"7f474fdc":"code","13523d13":"code","9008810d":"code","1398af09":"code","ede079a3":"code","c56ce477":"code","080284b5":"code","03883b73":"code","8de6bb48":"code","3d5d0617":"code","15c0d44d":"code","c81929fa":"code","c4bfc3ad":"code","fe69350c":"code","8c2439a0":"code","06dec5a3":"code","c557f5f1":"code","e969bbad":"code","48fc3bc8":"code","fa2c5948":"code","87ade3b3":"code","0eaaff0d":"code","58ff1188":"code","f7ebb1b6":"code","1b1c481d":"code","f7911aab":"code","5d6ee93d":"code","c5a355d3":"code","e0a36ada":"code","5110fe60":"code","41460d6e":"markdown","6cdcbedd":"markdown","23893e15":"markdown","99aa39bc":"markdown","480822ba":"markdown","2d46e39f":"markdown","d8ca5380":"markdown","91674dc4":"markdown","8e5228bc":"markdown","18a6f1bf":"markdown","57d6195a":"markdown","005420f4":"markdown"},"source":{"7f474fdc":"\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport keras\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","13523d13":"(X_train, y_train), (X_test, y_test)= keras.datasets.fashion_mnist.load_data()","9008810d":"X_train.shape , y_train.shape","1398af09":"X_test.shape , y_test.shape","ede079a3":"class_labels = ['T-shirt\/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneakers','Bag','Ankle boot']","c56ce477":"plt.imshow(X_train[0],cmap='Greys')","080284b5":"plt.imshow(X_train[11],cmap='Greys')","03883b73":"plt.figure(figsize=(16,16))\nj=1\nfor i in np.random.randint(0,1000,25):\n    plt.subplot(5,5,j); j+=1\n    plt.imshow(X_train[i],cmap='Greys')\n    plt.axis('off')\n    plt.title('{} \/ {}'.format(class_labels[y_train[i]],y_train[i]))","8de6bb48":"X_train.ndim","3d5d0617":"X_train  = np.expand_dims(X_train,-1)\nX_test  = np.expand_dims(X_test,-1)","15c0d44d":"X_train.ndim","c81929fa":"X_train.shape","c4bfc3ad":"X_train = X_train\/255\nX_test = X_test\/255","fe69350c":"from sklearn.model_selection import train_test_split\nX_train, X_val , y_train , y_val = train_test_split(X_train,y_train , test_size = 0.2 , random_state = 2020)","8c2439a0":"X_train.shape, y_train.shape  ","06dec5a3":"X_val.shape, y_val.shape","c557f5f1":"model = keras.models.Sequential([\n                         keras.layers.Conv2D(filters = 64 , kernel_size = 3,strides = (1,1), padding = 'valid',activation = 'relu',input_shape = [28,28,1]), # 1st Layer\n                         keras.layers.MaxPooling2D(pool_size = (2,2)),\n\n                         keras.layers.Conv2D(filters = 128 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'relu',input_shape = [28,28,1]), # 2nd Layer\n                         keras.layers.MaxPooling2D(pool_size = (2,2)),\n\n                         keras.layers.Conv2D(filters = 64 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'relu',input_shape = [28,28,1]), # 3rd Layer\n                         keras.layers.MaxPooling2D(pool_size = (2,2)),\n\n                         keras.layers.Flatten(),\n                         keras.layers.Dense(units = 128,activation = 'relu'),\n                         keras.layers.Dropout(0.25),\n                         keras.layers.Dense(units = 256,activation = 'relu'),\n                         keras.layers.Dropout(0.5),\n                         keras.layers.Dense(units = 256,activation = 'relu'),\n                         keras.layers.Dropout(0.25),\n                         keras.layers.Dense(units = 128,activation = 'relu'),\n                         keras.layers.Dropout(0.10),\n                         keras.layers.Dense(units = 10,activation = 'softmax')  # Output layer\n                        \n])","e969bbad":"keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","48fc3bc8":"model.summary()","fa2c5948":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])","87ade3b3":"model.fit(X_train,y_train,epochs = 20,batch_size = 512,verbose = 1, validation_data=(X_val,y_val))","0eaaff0d":"model.predict(np.expand_dims(X_test[0],axis = 0)).round(2)\n# np.expand is used to change the 3 dimension data into 4 dimension","58ff1188":"np.argmax(model.predict(np.expand_dims(X_test[0],axis = 0)).round(2))","f7ebb1b6":"# cross check \ny_test[0]","1b1c481d":"y_pred = model.predict(X_test).round(2)\ny_pred","f7911aab":"model.evaluate(X_test,y_test)","5d6ee93d":"plt.figure(figsize=(16,30))\nj = 1\nfor i in np.random.randint(0,1000,60):\n  plt.subplot(10,6,j); j+=1\n  plt.imshow(X_test[i].reshape(28,28),cmap = 'Greys')\n  plt.axis('off')\n  plt.title('Actual = {} \/ {} \\nPredicted = {} \/ {}'.format(class_labels[y_test[i]],y_test[i],class_labels[np.argmax(y_pred[i])],np.argmax(y_pred[i])))","c5a355d3":"from sklearn.metrics import confusion_matrix\nplt.figure(figsize = (16,9))\ny_pred_labels = [np.argmax(label) for label in y_pred]\ncm = confusion_matrix(y_test,y_pred_labels)\n\n# HeatMap\nsns.heatmap(cm , annot = True,fmt = 'd',xticklabels = class_labels,yticklabels = class_labels)","e0a36ada":"from sklearn.metrics import classification_report\ncr = classification_report (y_test,y_pred_labels,target_names = class_labels)\nprint(cr)","5110fe60":"model.save('Fashion_MNIST.h5')","41460d6e":"# Changing Dimensions & Feature Scaling","6cdcbedd":"# Testing the Model","23893e15":"# **Show Images**","99aa39bc":"# Convolution Neural Networks","480822ba":"Accuracy given by Train set is 0.94 and Accuracy given by Test set is 0.90, Thus we can we say that our model is generalized so no overfitting nor underfitting.","2d46e39f":"# Evaluation","d8ca5380":"# Plotting the Neural Network Work Flow","91674dc4":"# Visualization","8e5228bc":"For the convolutional front-end, we can start with a Three convolutional layer with a small filter size and a modest number of filters (64) followed by a max pooling layer. The filter maps can then be flattened to provide features to the classifier.\n\nGiven that the problem is a multi-class classification, we know that we will require an output layer with 10 nodes in order to predict the probability distribution of an image belonging to each of the 10 classes. This will also require the use of a softmax activation function. Between the feature extractor and the output layer, we can add a dense layer to interpret the features, in this case with 128 nodes.\n\nAll layers will use the ReLU activation function and the He weight initialization scheme, both best practices.","18a6f1bf":"# **Spliting Dataset for Validation Set**","57d6195a":"# Compile and Model Fitting","005420f4":"# **Spliting Data**"}}