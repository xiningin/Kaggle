{"cell_type":{"b3908790":"code","18480edc":"code","54c7e9cc":"code","86d00e4c":"code","7bd0c0c5":"code","4cb88bbe":"code","71829aa6":"code","1551214a":"code","0ce58d57":"code","97436c15":"code","942b7173":"code","6a9231aa":"code","ba4d2b09":"code","2d0455fb":"code","3c143a3f":"code","c785488d":"code","f15fc708":"code","600331b2":"code","2ff9d9ae":"code","ce4f88b0":"code","85ca468d":"code","5d226ea8":"code","ba0ea50a":"code","5d2e60f2":"code","a8e63f48":"code","e21e1d94":"code","81f901a8":"code","dcbeef6d":"code","5441a03f":"markdown"},"source":{"b3908790":"!pip install pyparsing==2.4.2\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom PIL import Image, ImageDraw\n# import tensorflow as tf\n\nimport os\nimport ast\nimport sys\nimport time\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport greatbarrierreef\n","18480edc":"# data imports\nDATA_PATH = '\/kaggle\/input\/tensorflow-great-barrier-reef'\nimages_path = os.path.join(DATA_PATH,'train_images')\ndf_test = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/test.csv\")\ndf_train = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/train.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/example_sample_submission.csv\")\nexample = np.load(\"..\/input\/tensorflow-great-barrier-reef\/example_test.npy\")","54c7e9cc":"df_train['img_path'] = os.path.join('..\/input\/tensorflow-great-barrier-reef\/train_images')+\"\/video_\"+df_train.video_id.astype(str)+\"\/\"+df_train.video_frame.astype(str)+\".jpg\"\ndf_train['annotations'] = df_train['annotations'].apply(lambda x: ast.literal_eval(x))\ndf_train['Number_bbox'] = df_train['annotations'].apply(lambda x:len(x)) ","86d00e4c":"def bbox_areas(annotations):\n    if not annotations:\n        return [0]\n    area_list = []\n    for annotation in annotations:\n        area_list.append(annotation['width']*annotation['height'])\n    return area_list\ndf_train[\"bbox_area\"] = df_train[\"annotations\"].apply(bbox_areas)\ndf_train[\"max_area\"] = df_train[\"bbox_area\"].apply(lambda x : max(x))\ndf_train[\"min_area\"] = df_train[\"bbox_area\"].apply(lambda x : min(x))\ndf_train.head()\n","7bd0c0c5":"def img_viz(df_train, id):\n    image = df_train['img_path'][id]\n    img = Image.open(image)\n    \n    for box in df_train['annotations'][id]:\n        shape = [box['x'], box['y'], box['x']+box['width'], box['y']+box['height']]\n        ImageDraw.Draw(img).rectangle(shape, outline =\"red\", width=3)\n    display(img)\ndf_train.sort_values(\"max_area\", ascending=False).head()\n","4cb88bbe":"# data imports\nDATA_PATH = '\/kaggle\/input\/tensorflow-great-barrier-reef'\nimages_path = os.path.join(DATA_PATH,'train_images')\ndf_test = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/test.csv\")\ndf_train = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/train.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/example_sample_submission.csv\")\nexample = np.load(\"..\/input\/tensorflow-great-barrier-reef\/example_test.npy\")\ndata = pd.read_csv(\"..\/input\/datagreatbarrier\/data.csv\")","71829aa6":"data","1551214a":"actual_train_data = data.query(\"Number_bbox>0\")","0ce58d57":"!git clone https:\/\/github.com\/tensorflow\/models.git\n# !cd models\/research\n# !export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`\/slim\n# !protoc object_detection\/protos\/*.proto --python_out=.","97436c15":"!wget -O protobuf.zip https:\/\/github.com\/protocolbuffers\/protobuf\/releases\/download\/v3.19.0\/protoc-3.19.0-linux-x86_64.zip -q\n!unzip -o protobuf.zip\n!rm protobuf.zip","942b7173":"!pwd\n!cd models\/research\n!pwd","6a9231aa":"# %bash cd models\/research\nos.chdir('models\/research')\n# !pwd\n!protoc object_detection\/protos\/*.proto --python_out=.","ba4d2b09":"import os\n\nos.environ['AUTOGRAPH_VERBOSITY'] = '0'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONPATH']=os.environ['PYTHONPATH']+':\/kaggle\/models\/research\/slim:\/kaggle\/models\/research'\nos.environ['PYTHONPATH']\n\n","2d0455fb":"!cp object_detection\/packages\/tf2\/setup.py .\n!python -m pip install --use-feature=2020-resolver .","3c143a3f":"!pwd\n!python object_detection\/builders\/model_builder_tf2_test.py","c785488d":"data['annotations'] = data['annotations'].apply(eval)\n","f15fc708":"os.chdir(\"\/kaggle\/working\")\n!mkdir workspace workspace\/train_images workspace\/test_images","600331b2":"label_map = \"\"\"item {\n    id: 1\n    name: 'starfish'\n}\"\"\"\nwith open(\"\/kaggle\/working\/workspace\/annotations\", \"w\") as label_file:\n    label_file.write(label_map)\nlabel_file.close()\n    ","2ff9d9ae":"# !cp \/kaggle\/input\/reef-labels\/labelmap.pbtxt \/kaggle\/working\/workspace\/annotations","ce4f88b0":"from tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport json\nimport copy\nimport os\nimport cv2\nimport ast\n\n# functions\n","85ca468d":"image_annotation_dict = dict(zip(data.img_path, data.annotations))\nannotated_images = {key:value for key, value in image_annotation_dict.items() if len(value)>0}","5d226ea8":"def get_xml_template(image_path, folder=\"\/kaggle\/working\/workspace\/train_images\"):\n    img = Image.open(image_path)\n    img_width, img_height = img.size\n    file_name = '_'.join(image_path.split('\/')[-2:])\n    image_info_dict = {\n    \"folder\": folder.split('\/')[-1],\n    \"filename\": file_name,\n    \"path\": folder + '\/' + file_name,\n    \"source\":{\"database\": \"Unknown\"},\n    \"size\":{\"width\": str(img_width), \"height\": str(img_height), \"depth\":\"3\"},\n    \"segmented\": \"0\",\n        }\n    return image_info_dict\n\ndef get_annotation_template(annotation):\n    annotation_dict = {\"name\": \"starfish\",\n                      \"pose\": \"unknown\",\n                      \"difficult\": \"0\",\n                      \"bbox\":{\"xmin\": str(annotation['x']),\n                              \"xmax\": str(annotation['x']+annotation['width']),\n                              \"ymin\": str(annotation['y']),\n                               \"ymax\": str(annotation['y']+annotation['height'])}}\n    return annotation_dict","ba0ea50a":"import xml.etree.ElementTree as ET\n\ndef add_child(key, value, parent):\n    child = ET.SubElement(parent, key)\n    if isinstance(value, dict):\n        for key_child, value_child in list(value.items()):\n            add_child(key_child, value_child, child)\n    else:\n        child.text = value\n    return  \n\ndef get_xml(image_data,folder=\"\/kaggle\/working\/workspace\/train_images\"):\n    image_info = get_xml_template(image_data[0], folder=folder)\n    file_path = folder+'\/'+image_info[\"filename\"]\n    xml_file_path = file_path.split('.')[0] +'.xml'\n    annotation_list = image_data[1]\n    root = ET.Element(\"annotations\")\n    for k,v in image_info.items():\n        add_child(k,v,root)\n    for annotation in annotation_list:\n        annotation_root = ET.SubElement(root, \"object\")\n        annotation_info = get_annotation_template(annotation)\n        for k,v in annotation_info.items():\n            add_child(k,v,annotation_root)\n    return root,file_path,xml_file_path\n\n","5d2e60f2":"from sklearn.model_selection import train_test_split\nimport shutil\ntrain_data, test_data = train_test_split(data,random_state=22, test_size=0.1)","a8e63f48":"def transfer_images_xml(image_data_list, folder=\"\/kaggle\/working\/workspace\/train_images\"):\n    for image_data in tqdm(image_data_list):\n        xml_details, image_path, xml_path = get_xml(image_data, folder=folder)\n        shutil.copy(image_data[0], image_path)\n        xml_tree = ET.ElementTree(xml_details)\n        xml_tree.write(xml_path)","e21e1d94":"test_image_annotation_dict = tuple(zip(test_data.img_path, test_data.annotations))\n","81f901a8":"transfer_images_xml(test_image_annotation_dict, folder=\"\/kaggle\/working\/workspace\/test_images\")","dcbeef6d":"# !rm \/kaggle\/working\/workspace\/test_images\/*\n# !rm \/kaggle\/working\/workspace\/train_images\/*\n","5441a03f":"The below code will be useful in setting up TF object detection API. Part of it will be in the next notebook.Cheers! You can also refer to (https:\/\/tensorflow-object-detection-api-tutorial.readthedocs.io\/en\/latest\/install.html) for details."}}