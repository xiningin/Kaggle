{"cell_type":{"2a41ca06":"code","90e6925b":"code","70737bde":"code","0c1056c7":"code","ac014a78":"code","18a908ba":"code","68fbef4f":"code","cd86246d":"code","1dd81c96":"code","c4d4d6b9":"code","7bc50e37":"code","686585b8":"code","ac938e14":"code","45b8db4a":"code","44789181":"code","10bac346":"code","d4e0156b":"code","41611fc9":"code","70e36214":"code","c5e6382f":"code","9d5e9ca6":"code","5dbf5ba0":"markdown","d6d39648":"markdown","459612b0":"markdown","3b2a0385":"markdown","01eaccc2":"markdown","9ffa6794":"markdown","2c76ace0":"markdown","dbe69290":"markdown"},"source":{"2a41ca06":"# Library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, gc, warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# TensorFlow\nimport tensorflow as tf\ntf.random.set_seed(42)\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve\n\n# Display\nfrom IPython.display import clear_output","90e6925b":"# Load Data\nurl = '..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv'\ndf = pd.read_csv(url, header='infer')\nprint(\"Total Records: \", df.shape[0])","70737bde":"# Check for empty \/ missing values\nprint(\"Is Dataset Empty?: \", df.empty)","0c1056c7":"num_cols = ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium', 'time']\ncat_cols = ['anaemia', 'diabetes', 'high_blood_pressure','sex', 'smoking', 'DEATH_EVENT']\n\n#Stat Summary\ndf[num_cols].describe().transpose()","ac014a78":"#Garbage Collection\ngc.collect()","18a908ba":"# Map\ncat_map = {\"anaemia\":  {0:\"No\", 1:\"Yes\"},\n           \"diabetes\": {0:\"No\", 1:\"Yes\"},\n           \"high_blood_pressure\": {0:\"No\", 1:\"Yes\"},\n           \"sex\": {0:\"Male\", 1:\"Female\"},\n           \"smoking\": {0:\"No\", 1:\"Yes\"},\n           \"DEATH_EVENT\": {0:\"No\", 1:\"Yes\"}} \n          \n\n# Creating a seperate dataframe\ndf_1 = df.replace(cat_map)\n\n# Creating Age Group \nbins = [18, 30, 40, 50, 60, 70, 100]\nlabels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70+']\ndf_1['age_grp'] = pd.cut(df_1.age, bins, labels = labels,include_lowest = True)\n\ndf_1.head()","68fbef4f":"plt.figure(figsize=(10,8))\ndf.age.hist(bins=20, histtype='bar',color='wheat')\nplt.title(\"Age Distribution\", fontsize=20)\nplt.show()","cd86246d":"plt.figure(figsize=(10,8))\nflatui = [\"#e74c3c\", \"#34495e\"]\nsns.countplot(x=\"age_grp\", hue=\"sex\", data=df_1, saturation=0.25, dodge=True, palette=sns.color_palette(flatui))\nplt.title(\"Gender Distribution per Age Group\", fontsize=20)\nplt.show()","1dd81c96":"# Correlation Heatmap\n\nplt.figure(figsize=(10,10))\nplt.title (\"Correlation Heatmap\", fontsize=20)\ncorr = df_1.corr()\n\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","c4d4d6b9":"plt.figure(figsize=(15,10))\nsns.stripplot(x=\"age_grp\", y=\"serum_creatinine\", hue=\"sex\",\n              data=df_1, dodge=True, zorder=1, palette=sns.cubehelix_palette(2), jitter=True)\nplt.title(\"Age vs Serum Creatinine\", fontsize=20)","7bc50e37":"sns.catplot(x=\"ejection_fraction\", y=\"serum_sodium\", hue=\"sex\", data=df_1, \n            height=8, kind=\"boxen\", aspect=2.5, palette = sns.cubehelix_palette(8, start=.5, rot=-.75))\nplt.title(\"Ejection Fraction vs Serum Sodium\", fontsize=25)","686585b8":"# Garbage Collection\ngc.collect()","ac938e14":"''' Feature Engineering & Data Split '''\n\ntarget = ['DEATH_EVENT']\nfeatures = df.columns[:-1]\n\nX = df[features]\ny = df[target]\n\n#Training = 90% & Validation = 10%\ntest_size = 0.1\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True) \n\nprint(\"Training Data Records: \", X_train.shape[0])\nprint(\"Validation Data Records: \", X_val.shape[0])\n\n#Reset Index\nX_val.reset_index(drop=True, inplace=True)\ny_val.reset_index(drop=True, inplace=True)","45b8db4a":"'''TensorFlow Feature Columns Creation '''\n\ncat_cols = ['anaemia','diabetes','high_blood_pressure','sex','smoking']   # Categorical Data Columns\nfloat_cols = ['age','platelets','serum_creatinine']  # Num Float Data Columns\nint_cols = ['creatinine_phosphokinase','ejection_fraction','serum_sodium', 'time']  # Num Int Data Columns\n\n\n# One Hot Encoding Custom Function\ndef one_hot_encode(feature, vocab):\n    return tf.feature_column.indicator_column(\n        tf.feature_column.categorical_column_with_vocabulary_list(feature, vocab))\n\n\nfeatures_cols = []\n\n# Categorical Features\nfor feature in cat_cols:\n    vocabulary = X_train[feature].unique()\n    features_cols.append(one_hot_encode(feature,vocabulary))\n\n# Numerical Float Features    \nfor feature in float_cols:\n    features_cols.append(tf.feature_column.numeric_column(feature, dtype=tf.float32))\n\n# Numerical Int Features    \nfor feature in int_cols:\n    features_cols.append(tf.feature_column.numeric_column(feature, dtype=tf.int32))\n","44789181":"''' TensorFlow Input Function Creation  '''\n\nnum_examples = len(y_train)\n\ndef make_input_fn(X, y, n_epochs=None, shuffle=True):\n       \n    def input_fn():\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n\n        if shuffle:\n            dataset = dataset.shuffle(num_examples)\n            \n        # For training, cycle thru dataset as many times as need (n_epochs=None).\n        dataset = dataset.repeat(n_epochs)\n        \n        # In memory training doesn't use batching.\n        dataset = dataset.batch(num_examples)\n        \n        return dataset\n    \n    return input_fn\n\n# Training and evaluation input functions.\ntrain_input_fn = make_input_fn(X_train, y_train)\nval_input_fn = make_input_fn(X_val, y_val, shuffle=False, n_epochs=1)","10bac346":"''' Linear Classifier: Train & Evaluate Model'''\nlinear_clf = tf.estimator.LinearClassifier(features_cols)\n\n# Train\nlinear_clf.train(train_input_fn, max_steps=100)\n\n# Evaluation\nresult = linear_clf.evaluate(val_input_fn)\nclear_output()\nres = [(result[k]) for k in ['accuracy'] if k in result]\nfor acc in res:\n    print(\"Linear Classifier Benchmark Accuracy: \",'{:.1%}'.format(acc))","d4e0156b":"#Garbage Collection\ngc.collect()","41611fc9":"'''Using entire dataset per layer'''\nbatches = 1\n\nbt_clf = tf.estimator.BoostedTreesClassifier(features_cols, n_batches_per_layer=batches)\n\n# Train\nbt_clf.train(train_input_fn, max_steps=100)\n\n# Evaluation\nresult = bt_clf.evaluate(val_input_fn)\nclear_output()\nres = [(result[k]) for k in ['accuracy'] if k in result]\nfor acc in res:\n    print(\"Boosted Trees Classifier Accuracy: \",'{:.1%}'.format(acc))","70e36214":"# Predicted Probabilities\npred_dicts = list(bt_clf.predict(val_input_fn))\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n\n#ROC\nfpr, tpr, _ = roc_curve(y_val, probs)\n\n\n# Plot\nfig=plt.figure(figsize=(20,15))\n\nax1=fig.add_subplot(221)\nsns.distplot(probs, bins=15, ax=ax1,color='maroon')\nax1.set_title('Predicted Probabilities',size=15)\n\nax2=fig.add_subplot(222)\nsns.lineplot(fpr, tpr, ax=ax2,color='darkolivegreen')\nax2.set_title('ROC Curve',size=15)\nax2.set_xlabel('false positive rate')\nax2.set_ylabel('true positive rate')","c5e6382f":"#Garbage Collection\ngc.collect()","9d5e9ca6":"# Class Prediction\ncls_id = pd.DataFrame([pred['class_ids'][0] for pred in pred_dicts])\n\n# Validation dataframe\nX_Val_df = X_val.copy()\n\n# Adding Actual Death Event Column\nX_Val_df['ACTUAL_DEATH_EVENT'] = y_val\n\n# Adding Predicted Death Event Column\nX_Val_df['PRED_DEATH_EVENT'] = cls_id\n\nX_Val_df.head(10)","5dbf5ba0":"## Benchmarking with linear classifier (logistic regression model)","d6d39648":"Observing the above correlation heatmap, there seems to be a positive correlation between:\n\n* Age - Serum Creatinine\n* Serum_Sodium - Ejection Fraction\n\nLet's Explore that...","459612b0":"# Basic EDA\n\nFor performing basic EDA, converting the categorical data with numerical values to string value. Following are the assumptions:\n\n0 = No , 1 = Yes\n\n0 = Male, 1 = Female","3b2a0385":"# Setup","01eaccc2":"# Heart Failure Prediction using TensorFlow Estimators (Boosted Trees)\n\nThis is notebook consisting the training of a **Gradient Boosting model** using **decision trees** with the **tf.estimator** API. **Boosted Trees models** are among the most popular and effective machine learning approaches for both **regression** and **classification**. It is an ensemble technique that combines the predictions from several tree models. Boosted Trees models are popular with many machine learning practitioners as they can achieve impressive performance with minimal hyperparameter tuning.\n\nI have used the **BoostedTreesClassifier** on [Heart-Failure-Data](https:\/\/www.kaggle.com\/andrewmvd\/heart-failure-clinical-data) to predict the Death_Event due to Heart Failure on\n\n\n### Please do consider to UPVOTE if you find it helpful :-)","9ffa6794":"# Boosted trees Classification using TensorFlow Estimators ","2c76ace0":"## Predictions","dbe69290":"## Training Boosted Trees Model"}}