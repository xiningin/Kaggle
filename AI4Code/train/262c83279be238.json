{"cell_type":{"6fdf71e7":"code","04695dcc":"code","118d7210":"code","b52295c3":"code","60ffe2e5":"code","d7593dc6":"code","e7421e39":"code","3fb5e8db":"code","bfb27cc5":"code","7be1eab4":"code","69588829":"code","717750e3":"code","6966aead":"code","b052419e":"code","c4211d6f":"code","c11fa508":"code","be5b38cb":"code","f22763dd":"code","e0340787":"code","def57b05":"code","00386a06":"code","2119dabc":"code","ca988a47":"code","18c79411":"code","9d47a229":"code","4ffe1096":"code","ec72d602":"code","74033850":"code","cafb4ff5":"code","ec64ef0c":"code","c22959de":"code","ed40b9fd":"code","43338f7f":"code","e875bad2":"code","b98a82b0":"code","c2f98b42":"code","5ace243a":"code","e1eb3c11":"code","d44f85f2":"code","f2013c26":"code","bab2e9cd":"code","4dded854":"code","c1905f1a":"code","021866d7":"code","6047c5f0":"code","1e18b88d":"code","1160a1cc":"code","a36abe01":"markdown","a5279ea4":"markdown","04358295":"markdown","c0754a6c":"markdown","7cfa89d3":"markdown","02abe77a":"markdown","ee2d2462":"markdown","d693ab5b":"markdown","375d15ee":"markdown","1093713d":"markdown","79ed923d":"markdown","c31845f9":"markdown","179f7298":"markdown","36bf1114":"markdown"},"source":{"6fdf71e7":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.cm as cm\nimport seaborn as sns\nimport os\nimport cv2\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.layers import GlobalAveragePooling2D ,Input, Flatten , Dense , Dropout , Concatenate ,Activation\nfrom tensorflow.keras.models import Model , Sequential , load_model\nfrom tensorflow.keras.preprocessing.image import load_img , img_to_array , array_to_img\nfrom tensorflow.keras.applications import mobilenet_v2 , imagenet_utils\nimport shutil\nfrom glob import glob","04695dcc":"data_entry = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\nbbox_list = pd.read_csv('..\/input\/data\/BBox_List_2017.csv')\n","118d7210":"all_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input','data', 'images*','*','*.png'))}\n\n","b52295c3":"data_entry.head()","60ffe2e5":"data_entry.shape","d7593dc6":"bbox_list.head()","e7421e39":"bbox_list.shape","3fb5e8db":"fig , ax  = plt.subplots(figsize=(12,6))\nsns.countplot(bbox_list['Finding Label'] , ax=ax)\nax.set_title('Class Distribution')\nplt.show()","bfb27cc5":"bbox_list['Finding Label'].value_counts()","7be1eab4":"data_entry['Finding Labels'].nunique()","69588829":"len(data_entry[data_entry['Finding Labels'] == 'No Finding'])","717750e3":"df_one_hot = data_entry.copy()\nfor i, v in enumerate(df_one_hot['Finding Labels'].values):\n    v = v.split('|')\n    for c in v:\n        df_one_hot.loc[i , c] = 1\n","6966aead":"df_one_hot.head()","b052419e":"df_one_hot.columns","c4211d6f":"df = df_one_hot[['Image Index', 'Cardiomegaly', 'Emphysema', 'Effusion', 'No Finding', 'Hernia',\n       'Infiltration', 'Mass', 'Nodule', 'Atelectasis', 'Pneumothorax',\n       'Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema',\n       'Consolidation']]","c11fa508":"df = df.fillna(0)\ndf.head()","be5b38cb":"for c in df.columns[1:]:\n    df[c] = df[c].astype(int)\n    \ndf.head()","f22763dd":"class_dist = { i : df[i].sum() for i in df.columns[1:]}\ncl = list(class_dist.keys())\nfreq = list(class_dist.values())\nfig , ax = plt.subplots(figsize=(12,6))\nsns.barplot(x=freq , y = cl , ax=ax)\nax.set_title('Class Distibtuion')\nfig.show()","e0340787":"class_dist","def57b05":"df_inf = df.loc[df['Infiltration'] == 1]\nprint(df_inf.shape)\ndf_inf.head()","00386a06":"fig = plt.figure(figsize=(15, 15))\ni = 1\nfor ii in df_inf['Image Index'].values[:9]:\n    img = plt.imread(all_image_paths[ii])\n    fig.add_subplot(3,3,i)\n    plt.imshow(img , cmap='Greys_r')\n    i+=1\n    \nplt.title('Some examples of infiltration')\nfig.tight_layout(pad=2)\nfig.show()","2119dabc":"def decode_png(path):\n    img = all_image_paths[path.numpy().decode()]\n    img = tf.io.read_file(img)\n    img = tf.io.decode_png(img , channels=3)\n    img = tf.image.resize(img , [128 , 128])\n    return img","ca988a47":"def get_ds(df , label , shuffle=True , repeat= True):\n    ds = tf.data.Dataset.from_tensor_slices((df['Image Index'].values , df[label].values))\n    ds = ds.map(lambda img , y : (tf.py_function(func=decode_png , inp=[img] , Tout=tf.float32) , y))\n    return ds","18c79411":"ds = get_ds(df , 'Infiltration')\nfor i in ds.take(5):\n    a = i[0].numpy()\n    a = a\/255.0\n    plt.imshow(a)","9d47a229":"bbox_list.columns","4ffe1096":"def plot_image_bb(label , save_name=None):\n    df = bbox_list.loc[bbox_list['Finding Label'] == label]\n    df = df.reset_index()\n    df = df.loc[:4]\n    fig = plt.figure(figsize=(20,10))\n    i = 1\n    for ii in df['Image Index']:\n        dfs = df.loc[df['Image Index'] == ii]\n        #print(dfs)\n        img = plt.imread(all_image_paths[ii])\n        ax = fig.add_subplot(1,5,i)\n        ax.imshow(img , cmap = 'Greys_r')\n        rect = patches.Rectangle((dfs['Bbox [x'].values , dfs['y'].values) , dfs['w'].values , dfs['h]'].values , linewidth=2,edgecolor='r',facecolor='none')\n        ax.add_patch(rect)\n        i+=1\n    fig.show()\n    if save_name != None:\n        plt.savefig(save_name)","ec72d602":"l = bbox_list['Finding Label'].unique()[7]\nprint(l)\nplot_image_bb(l , l+'.png')","74033850":"for l in bbox_list['Finding Label'].unique():\n    plot_image_bb(l , l+'.png')","cafb4ff5":"bbox_list.shape","ec64ef0c":"bbox_list['Finding Label'].value_counts()","c22959de":"# for efficeintnet\nbaseName_eff = 'efficientnetb'\nlayerName_eff = 'top_conv'\n\n# for mobileNetV2\nbaseName_mb = 'mobilenetv2'\nlayerName_mb = 'Conv_1'","ed40b9fd":"class GradCAM:\n    def __init__(self, model , classID, layerName ,base_model=None):\n        self.model = model\n        self.classId = classID\n        self.layerName = layerName\n        self.base = base_model\n        \n        # for debugging purposes\n        for layers in self.model.layers:\n            print(layers.name)\n            \n            \n        if base_model != None:\n            for layers in self.model.layers:\n                if (layers.name).startswith(self.base):\n                    self.base_model = self.model.get_layer(layers.name)\n\n        \n    def generate_heatmap(self , image , eps=1e-8):\n        if self.base == None:\n            GModel = Model( inputs = [self.model.inputs] ,\n                        outputs = [self.model.get_layer(self.layerName).output , self.model.output])\n        else:\n            GModel = Model( inputs = [self.base_model.inputs] ,\n                            outputs = [self.base_model.get_layer(self.layerName).output , self.base_model.output])\n\n        with tf.GradientTape() as GTape:\n            inputs = tf.cast(image , tf.float32)\n            (convOut , predictions) = GModel(inputs)\n            loss = predictions[0,0]\n        #print(convOut)\n        #print(loss)\n        grads = GTape.gradient(loss , convOut)\n\n        castConvOutputs = tf.cast(convOut > 0 , \"float32\")\n        #print(grads)\n        castGrads = tf.cast(grads > 0 , \"float32\")\n        guidedGrads = castConvOutputs * castGrads * grads\n\n        convOut = convOut[0]\n        guidedGrads = guidedGrads[0]\n\n        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n        cam = tf.reduce_sum(tf.multiply(weights, convOut), axis=-1)\n\n        (w, h) = (image.shape[2], image.shape[1])\n        heatmap = cv2.resize(cam.numpy(), (w, h))\n\n        numer = heatmap - np.min(heatmap)\n        denom = (heatmap.max() - heatmap.min()) + eps\n        heatmap = numer \/ denom\n        heatmap = (heatmap * 255).astype(\"uint8\")\n\n        return heatmap","43338f7f":"def Preporcess_image(image):\n    orig = cv2.imread(image)\n    resized = cv2.resize(orig, (256, 256))\n    # load the input image from disk (in Keras\/TensorFlow format) and\n    # preprocess it\n    image = load_img(image, target_size=(256, 256))\n    image = img_to_array(image)\n    image = np.expand_dims(image, axis=0)\n    image = imagenet_utils.preprocess_input(image)\n    return image","e875bad2":"def get_img(label):\n    df = bbox_list.loc[bbox_list['Finding Label'] == label]\n    df = df.reset_index()\n    i = df.loc[10  , 'Image Index']\n    img = Preporcess_image(all_image_paths[i])\n    return img , all_image_paths[i]\n    ","b98a82b0":"def plot_img(heatmap , img , save_name=None):\n    fig  = plt.figure(figsize=(6, 12))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax1.imshow(img , 'gray_r')\n    \n    ax2 = fig.add_subplot(1,2,2)\n    ax2.imshow(img , 'gray_r')\n    hm = ax2.imshow(heatmap , alpha = 0.4 , cmap = 'inferno')\n    \n    ax1.set_xticks([])\n    ax2.set_xticks([])\n    \n    ax1.set_yticks([])\n    ax2.set_yticks([])\n    #fig.colorbar(hm)\n    fig.show()\n    if save_name:\n        plt.savefig(save_name)\n    ","c2f98b42":"def infer(model , num_images , label , base_model = 'efficientnetb0' , layerName='top_conv',  name = 'efficientnetb0'):\n    model.layers[-1].activation = None\n    cam = GradCAM(model , 1, layerName ,base_model)\n    df_temp = df.loc[df[label] == 1]\n    df_temp = df_temp.sample(n=num_images)\n    i = 1\n    for d in df_temp['Image Index']:\n        path = all_image_paths[d]\n        img = Preporcess_image(path)\n        heatmap = cam.generate_heatmap(img)\n        \n        orig = plt.imread(path)\n        #print(orig.shape)\n        heatmap = cv2.resize(heatmap , (orig.shape[1] , orig.shape[0]))\n        #print(heatmap.shape)\n        save_name = 'Gcam_output_'+label+'_'+name +'_'+str(i)+'.png'\n        plot_img(heatmap , orig , save_name)\n        i += 1\n        ","5ace243a":"def get_bb_img(label , n):\n    df = bbox_list.loc[bbox_list['Finding Label'] == label]\n    df = df.reset_index()\n    df = df.sample(n=n)\n    return df\n\ndef plot_bb_img(dfs ,heatmap , img , save_name=None):\n    fig  = plt.figure(figsize=(6, 12))\n    \n    ax1 = fig.add_subplot(1, 2, 1)\n    ax1.imshow(img , cmap = 'Greys_r')\n    rect = patches.Rectangle((dfs['Bbox [x'].values , dfs['y'].values) , dfs['w'].values , dfs['h]'].values , linewidth=2,edgecolor='r',facecolor='none')\n    ax1.add_patch(rect)\n    \n    ax2 = fig.add_subplot(1,2,2)\n    ax2.imshow(img , 'gray_r')\n    hm = ax2.imshow(heatmap , alpha = 0.4 , cmap = 'inferno')\n    \n    ax1.set_xticks([])\n    ax2.set_xticks([])\n    \n    ax1.set_yticks([])\n    ax2.set_yticks([])\n    #fig.colorbar(hm)\n    fig.show()\n    if save_name:\n        plt.savefig(save_name)\n\ndef infer_with_bb(model ,n ,  label , base_model= 'efficientnetb0' , layerName='top_conv' , name = 'efficientnetb0'):\n    temp_df = get_bb_img(label , n)\n    model.layers[-1].activation = None\n    cam = GradCAM(model , 1 , layerName,base_model )\n    i = 1\n    for d in temp_df['Image Index']:\n        dfs = temp_df.loc[temp_df['Image Index'] == d]\n        path = all_image_paths[d]\n        img = Preporcess_image(path)\n        heatmap = cam.generate_heatmap(img)\n        \n        orig = plt.imread(path)\n        #print(orig.shape)\n        heatmap = cv2.resize(heatmap , (orig.shape[1] , orig.shape[0]))\n        #print(heatmap.shape)\n        save_name = 'Gcam_output_[bb]'+label+'_'+name+ '_' +str(i)+'.png'\n        plot_bb_img(dfs , heatmap , orig , save_name)\n        i += 1\n    ","e1eb3c11":"def Localize(label ,n ,  bb = False):\n    main_path = '..\/input\/nih-trained-models\/'\n    path = main_path + label\n    \n    for file in os.listdir(path):\n        if file.endswith('.h5'):\n            # model path \n            p = path + '\/' + file\n            # loading model\n            model = load_model(p)\n            if file.endswith('mb_v2_moodel.h5'):\n                # gradcam for mobile nets\n                ##########################\n                base_model = baseName_mb\n                layerName = layerName_mb\n            else:\n                # gradCam for efficentnets\n                ###########################\n                base_model = baseName_eff\n                layerName = layerName_eff\n\n                \n            # get the name of the model\n            for layers in model.layers:\n                if (layers.name).startswith(base_model):\n                    name = layers.name\n            # print the name of the model being used\n            print('=====================================================')\n            print(f'=========== MODEL = {name} ==================')\n            print('=====================================================')\n\n            #### Performance Inference ############\n            # if bounding box is set true and is available in the data\n            if bb and label in bbox_list['Finding Label'].unique():\n                infer_with_bb(model , n , label , base_model , layerName , name)\n            else:\n                infer(model , n , label , base_model , layerName , name)\n             \n        \n        #### end #####################\n","d44f85f2":"Localize('Atelectasis' , 5 , bb=True)","f2013c26":"# for layers in ex_model_2.layers:\n#     print(layers.name)","bab2e9cd":"# for layers in ex_model_2.get_layer('mobilenetv2_1.00_224').layers:\n#     print(layers.name)","4dded854":"#ex_model = load_model('..\/input\/nih-trained-models\/Hernia\/NIH_Hernia_eff_b0_moodel.h5')\n#ex_model_2 = load_model('..\/input\/nih-trained-models\/Atelectasis\/NIH_Atelectasis_mb_v2_moodel.h5')","c1905f1a":"# for layers in ex_model.get_layer('efficientnetb0').layers:\n#     print(layers.name)","021866d7":"# img , path = get_img('Cardiomegaly')","6047c5f0":"# cardiomegaly.layers[-1].activation = None\n# cam = GradCAM(cardiomegaly , i ,base_model= 'efficientnetb0' , layerName='top_conv')\n# heatmap = cam.generate_heatmap(img)","1e18b88d":"# image = cv2.imread(path)\n# heatmap = cv2.resize(heatmap , (image.shape[1] , image.shape[0]) , interpolation = cv2.INTER_CUBIC)","1160a1cc":"# img = plt.imread(path)\n# heatmap = cv2.resize(heatmap , (img.shape[1] , img.shape[0]))\n# plt.imshow(img , cmap='gray')\n# plt.imshow(heatmap , alpha = 0.4 , cmap = 'inferno')\n# plt.colorbar()\n# plt.xticks([])\n# plt.yticks([])\n# plt.show()","a36abe01":"looking at bbox list table","a5279ea4":"## Putting it all together","04358295":"# Final infer function to make inference using gradCAM","c0754a6c":"Fibding the class distribution in the overall dataset","7cfa89d3":"### Rouggh Work \"Just ignore\" (- _ <)","02abe77a":"looking at the data entry table","ee2d2462":"## Visualizing the X-Rays\nLets looks at some images for infiltraion","d693ab5b":"## For plotting the overlayed heatmap","375d15ee":"Reading the dataset","1093713d":"Class distribution in bbox_list","79ed923d":"# The Grad CAM class","c31845f9":"preparing the filepaths dict","179f7298":"## For preprocessing image","36bf1114":"## infer with bounding box"}}