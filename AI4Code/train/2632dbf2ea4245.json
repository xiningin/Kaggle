{"cell_type":{"3927b371":"code","959d5fdf":"code","b03e2ff9":"code","f036ca70":"code","b15a7077":"code","bc666dff":"code","bd5d473f":"code","cb757892":"code","f8715ff9":"code","b62caa7b":"code","0bdcbcc6":"code","e05074ea":"code","d02ee203":"code","38987434":"code","8d6f7423":"code","41a7bdf4":"code","2feb4c9c":"code","542fb08f":"code","a6f7c72a":"code","e0120305":"code","1bdb23f3":"markdown","8298c57e":"markdown","917edfa8":"markdown","22a81a14":"markdown","a168eb30":"markdown","f43b7ca5":"markdown","1bf8b570":"markdown","456a6898":"markdown","5b5c8ca5":"markdown","2ac33cb0":"markdown","af487365":"markdown"},"source":{"3927b371":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport gc\n\nfrom wordcloud import STOPWORDS\nimport string\nimport seaborn as sns\n","959d5fdf":"!ls ..\/input","b03e2ff9":"DATA_PATH='..\/input\/nlp-getting-started'","f036ca70":"train=pd.read_csv(f'{DATA_PATH}\/train.csv')\ntest=pd.read_csv(f'{DATA_PATH}\/test.csv')","b15a7077":"train.head()","bc666dff":"print(f'Train data has {train.shape[0]} rows')\nprint(f'Test data has {test.shape[0]} rows')","bd5d473f":"train['keyword'].isna().sum()","cb757892":"print(f'The percentage of NA values in the keyword column {round((train.keyword.isna().sum()\/train.shape[0])*100,2)} %')","f8715ff9":"print(f'There are {train.keyword.nunique()} unique keyword in the column')","b62caa7b":"real_keywords=train.loc[train['target']==1]['keyword'].dropna().unique()\nnonreal_keywords=train.loc[train['target']==0]['keyword'].dropna().unique()","0bdcbcc6":"print(f'There are {len(real_keywords)} real keywords and {len(nonreal_keywords)} non real keywords in the train dataset')","e05074ea":"print(f'Unique keywords found in real tweets only {set(real_keywords)-set(nonreal_keywords)}')\nprint(f'Unique keywords found in non real tweets only {set(nonreal_keywords)-set(real_keywords)}')","d02ee203":"train.loc[train['keyword'].str.startswith('derail',na=False)]['keyword'].unique()","38987434":"train.loc[train['keyword'].str.startswith('wreck',na=False)]['keyword'].unique()","8d6f7423":"train[train.target==1]['keyword'].dropna().value_counts()[0:5]","41a7bdf4":"train[train.target==0]['keyword'].dropna().value_counts()[0:5]","2feb4c9c":"## Creating the features:\n\ntrain['n_words']=train['text'].apply(lambda x:len(str(x).split()))\ntrain['n_unique_words']=train['text'].apply(lambda x:len(set(str(x).split())))\ntrain['n_characters']=train['text'].apply(lambda x:len(str(x)))\ntrain['n_stopwords']=train['text'].apply(lambda x:len([w for w in str(x).lower().split() if w in STOPWORDS]))\ntrain['n_punctuations']=train['text'].apply(lambda x:len([w for w in str(x) if w in string.punctuation ]))\ntrain['n_avg_words']=train['text'].apply(lambda x:np.mean([len(w) for w in str(x).split()]))","542fb08f":"train.head()","a6f7c72a":"columns=['n_words','n_unique_words','n_characters','n_stopwords','n_punctuations','n_avg_words']","e0120305":"for c in columns:\n    plt.figure(figsize=(8,8))\n    ax=sns.boxplot(x='target',y=c,data=train)\n    ax.set_xlabel(xlabel='Target')\n    ax.set_ylabel(ylabel=c)\n    plt.title(r'Boxplot of {} vs Target'.format(c))\n    plt.show()","1bdb23f3":"Similarly for wreck which is represented in three different ways.Lets check the most used keywords to for real vs non-real emergency.","8298c57e":"Thus from the above we see that there are 3 keywords found only in the real tweets whereas there is 1 keyword unique to non real tweets .But , this might not provide a holistic view since there are keywords which convey the same meaning , let us take an example of derail.","917edfa8":"**Inference**:\nFrom the plots it is understood that,\n\n1.There is no significant difference between the number of words and the targets.\n\n2.The median number of unique words for real tweets is slighly higher than that of non-real tweets.\n\n3.The number of characters between real and non-real tweets is significantly different.The median number of characters for real tweets is higher.\n\n4.There are many outliers when it comes to the number of stopwords and non-real tweets seems to have more of them when compared to real tweets.\n\n5.Non-real tweets sentences have lot of outliers in the number of punctuations( going upto 60) when compared to real tweets.\n\n6.The median value of real tweets for number of average words is higher compared to non real tweets.This distribution is also with lot of outliers.","22a81a14":"Let us check the unique keywords found in the train dataset.But before this let us check the number of NA values in that column.","a168eb30":"Now that we have checked on the text columns and create some features which might help during our modelling.I have considered popular kernel of [SRK](https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-notebook-qiqc) as a reference for this analysis.The features we will look at are \n\n1.Number of words in the text\n\n2.Number of unique words in the text\n\n3.Number of characters in the text\n\n4.Number of stopwords\n\n5.Number of punctuations\n\n6.Average length of the words\n","f43b7ca5":"Lets check how many unique keywords are represented for target =1 ie.when the tweet represents real emergency.","1bf8b570":"## Simple Exploratory Analysis of tweets","456a6898":"We see that there are 3 keywords which convey the same meaning of derail out of which the derailment keyword is used in the real tweets only whereas derail and derailed are present in both real and non real tweets.","5b5c8ca5":"**work in progress**","2ac33cb0":"In this kernel , I have done a exploratory analysis of the real vs non real tweets.I have considered following kernel as references while preparing this kernel.If you consider upvoting my kernel,pls upvote these kernels too.\n\n1.https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-notebook-qiqc\n\n2.https:\/\/www.kaggle.com\/arthurtok\/spooky-nlp-and-topic-modelling-tutorial","af487365":"There is a possibility that the keywords might be the same in case of real as well as non real tweets.Lets check the unique keywords in the real tweets alone."}}