{"cell_type":{"ddf16691":"code","38a4dfc3":"code","e163ebba":"code","ce2b31e9":"code","7bcedbda":"code","712bdaec":"code","dae08438":"code","ae2c1ce1":"code","bc75bef4":"code","510513d1":"code","9985a4f5":"code","d49fdcf5":"code","da5e9e10":"code","92331ad7":"code","cddc2067":"code","80eebb12":"code","b3e7e913":"code","2038de71":"code","1e314c0a":"code","37c773c0":"code","126f4dfc":"code","aa0e6275":"code","8a209403":"code","04d77ca0":"code","311dca3e":"code","b746b532":"code","8a6aeaf4":"code","9b4cac0d":"markdown","45eaa48f":"markdown","1c63e7aa":"markdown","344f91a2":"markdown","50c92504":"markdown","2dab04a5":"markdown","291964a0":"markdown"},"source":{"ddf16691":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38a4dfc3":"df = pd.read_csv('\/kaggle\/input\/beer-consumption-sao-paulo\/Consumo_cerveja.csv')","e163ebba":"df.dropna(inplace=True)","ce2b31e9":"df.head()","7bcedbda":"df['Data'] = pd.to_datetime(df['Data'])","712bdaec":"df['Mes'] = df['Data'].dt.month","dae08438":"df.head()","ae2c1ce1":"df.drop('Data', axis=1, inplace=True)","bc75bef4":"df.head()","510513d1":"df.dtypes","9985a4f5":"for col in df.columns.values:\n    if df[col].dtype == object:\n        df[col] = df[col].map(lambda x: x.replace(',', '.')).astype(float)","d49fdcf5":"df.dtypes","da5e9e10":"import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler","92331ad7":"X = df.drop('Consumo de cerveja (litros)', axis=1).values\nfeatures = df.drop('Consumo de cerveja (litros)', axis=1).columns.values","cddc2067":"y = df['Consumo de cerveja (litros)'].values","80eebb12":"scaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)","b3e7e913":"lr = LinearRegression()\nlr.fit(X_scaled, y)","2038de71":"coefs = lr.coef_","1e314c0a":"for (feature, coef) in zip(features, coefs):\n    print('%s: %f'%(feature, coef))","37c773c0":"cov_matrix  = np.cov(X_scaled, rowvar=False)\ndf_cov = pd.DataFrame(cov_matrix, columns=features)","126f4dfc":"df_cov","aa0e6275":"feature_impact = list(range(0, len(features), 1))","8a209403":"for i in range(0, len(features), 1):\n    for j in range(0, len(features), 1):\n        if i == j:\n            feature_impact[i] += np.var(X_scaled.T[i])*(coefs[i]**2)\n        else:\n            part_of_i = np.var(X_scaled.T[i])*(coefs[i]**2)\n            part_of_j = np.var(X_scaled.T[j])*(coefs[j]**2)\n            part_of_covar = (part_of_i\/(part_of_i+part_of_j))*(2*cov_matrix[i][j]*coefs[i]*coefs[j])\n            feature_impact[i] += part_of_covar","04d77ca0":"plt.figure(figsize=(15,8))\nplt.bar(features, feature_impact)\nplt.xticks(rotation=90)\nplt.title('Impact of each feature')\nplt.show()","311dca3e":"print('************* Feature impact: *************')\nfor (feature, impact) in zip(features, feature_impact):\n    print('%s: %.5f'%(feature, impact))","b746b532":"pairs = []\npairs_impact = []\n\nfor i in range(0, len(features), 1):\n    for j in range(0, len(features), 1):\n        if i != j:\n            pairs_impact.append(2*cov_matrix[i][j]*coefs[i]*coefs[j])\n            pairs.append(features[i]+'\/'+features[j])\n        ","8a6aeaf4":"plt.figure(figsize=(15,8))\nplt.title('Impact of ')\nplt.bar(pairs, pairs_impact)\nplt.xticks(rotation=90)\nplt.show()","9b4cac0d":"# Data Management\n\nFirst, I'll extract the month of the Date column to use as a feature. I won't extract the day of the week because the information of if is a weekend day or not already is in the dataset.","45eaa48f":"It's also needed to transform the object values into float. To do that, I need to change the comma to a dot, for each column.","1c63e7aa":"# Finding the features with most influence\n\nThe method I'll use is decribed with more detail in this [Medium Article](http:\/\/https:\/\/towardsdatascience.com\/relative-importance-analysis-a-better-way-to-communicate-multiple-regression-results-d70a6fbbaf9c), from Tim Bednall. The basic idea is to find which variables have more impact in the R-Squared result.\n\nFrom the R-Squared formula, we have that: \n\n\n$$ R^2 = \\dfrac{(\\sum_{i=1}^j \\beta_i*SD(X_i))^2}{SD(Y)^2} $$ Where $\\beta_i$ is the linear regression coefficient for the variable $X_i$ and $Y$ is our target.\n\nFrom that, we can find how much each feature is impacting the R-Squared by just simplifying the numerator. For example, for two variables, we would have: \n\n$$\n(\\sum_{i=1}^j \\beta_i*SD(X_i))^2 = (\\beta_1*SD(X_1) + \\beta_2*SD(X_2))^2 = (\\beta_1^2Var(X_1) + \\beta_2^2Var(X_2) + 2Cov(X_1, X_2)\\beta_1\\beta_2)\n$$\n\nWhere $\\beta_1^2Var(X_1)$ is the impact by only feature 1 in the target, $\\beta_2^2Var(X_2)$ is the impact by only feature two in the target, and $2Cov(X_1, X_2)\\beta_1\\beta_2$ is the impact by these two features togheter. \n\nThe \"trick\" to see how much of $2Cov(X_1, X_2)\\beta_1\\beta_2$ is from $X_1$ and $X_2$ is use this formula: \n\n$$From(X_1) = \\dfrac{Var(X_1)\\beta_1^2}{Var(X_1)\\beta_1^2 + Var(X_2)\\beta_2^2} * 2Cov(X_1, X_2)\\beta_1\\beta_2$$\n\nAnd, then, sum this value to $\\beta_1^2Var(X_1)$","344f91a2":"## Regression model\n\nThe first step is fit the regression and find each coefficient.","50c92504":"We can show the result by two ways: \n\n- First, would be the sum explained above, which each value represents the impact that a feature has on a result:","2dab04a5":"Now, we need to create a matrix with the values of covariance for each pair of feature.","291964a0":"- Second, would be how much a pair of features is impacting the outcome (the value of $2Cov(X_1, X_2)\\beta_1\\beta_2)$):"}}