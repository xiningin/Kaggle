{"cell_type":{"bead64f6":"code","ab56df5d":"code","88b485dd":"code","2dd6412a":"code","02461c80":"code","850fcad6":"code","cf829cb7":"code","bb1bc88c":"code","2044973f":"code","098e1697":"code","6362cb74":"code","97143cb0":"code","0d29cd6d":"code","3acfd776":"code","caf71c28":"code","14021597":"code","cdc24f96":"code","a3fa1d91":"code","d7ff2b86":"code","1b73745e":"code","a1c751ff":"code","5f27a814":"code","be989eaa":"code","3cddd8fc":"code","eb829be5":"code","381c8598":"code","06256123":"code","dcedbd94":"code","272d5a9d":"code","338ce04a":"code","7024b2c4":"code","23774500":"code","1fa0a024":"code","91227572":"code","57f096ea":"code","98ff8f9c":"code","692504ba":"code","3c18c6b0":"code","f383e6a7":"code","2faac443":"code","f4d51d22":"code","6b72a1b9":"code","a6303c27":"code","ab0b5375":"code","e2796c48":"code","dece5578":"code","6bb579e5":"code","41f60b0f":"code","ef407efe":"code","9ca35fe4":"code","55745372":"code","a5e9d4fc":"code","73a9d26d":"code","a8ae97bc":"code","aede0099":"code","6c8f47c0":"code","38f166ee":"code","82237884":"code","c0bf4fe1":"code","2c7f3758":"code","edee7a3b":"code","0c9a8af7":"code","521a0c5f":"code","046dd0e8":"code","a1330248":"code","c45e5823":"code","a26ef8c4":"code","c37e6ca2":"code","e575b8f2":"code","001239de":"code","9287b56f":"code","8886e45b":"code","62820fa9":"code","1c797d33":"code","7204a7be":"code","50f56e7a":"code","d2f26abb":"code","4695d8bb":"code","4f71454f":"code","6469c933":"code","8a6661c0":"code","fc4338f6":"code","41caed84":"code","a7a467b8":"code","e1c4dfc4":"code","3ba1e2da":"code","9eac541a":"code","a6a525be":"code","c000da0d":"code","dcfd8445":"code","d5a22fa0":"code","db15f429":"code","33b2fe17":"code","fe5de074":"code","bff44952":"code","6ce1cbcf":"code","65fe100f":"code","ffe01476":"code","d5294cde":"code","ae7dc644":"code","206fb595":"code","1f9b69d2":"code","de407bcf":"code","7097f806":"code","252ec44c":"code","a7010958":"code","72419add":"code","1e2520f1":"code","20e332e8":"code","59967faf":"code","da9f55c5":"code","c8bfca68":"code","81b98f0f":"code","a769225c":"code","6449e30d":"code","8535d194":"code","3517d807":"code","bb3e78b5":"markdown","3468b60c":"markdown","82740ced":"markdown","a89a3137":"markdown","f725e67a":"markdown","8e7fdace":"markdown","f511bac9":"markdown","b6b3678c":"markdown","b6457f24":"markdown","57d54fcf":"markdown","69e2072a":"markdown","5bffbee6":"markdown","50d9c341":"markdown"},"source":{"bead64f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # visualization tool\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab56df5d":"#get the data from csv file to dataframe\n\ndata = pd.read_csv('\/kaggle\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv')","88b485dd":"# looking for data columns to have an idea about data type and data content\n\ndata.info()","2dd6412a":"#to arrange the data columns name \ndata = data.rename(columns={\"Volume_(BTC)\": \"Volume_BTC\", \"Volume_(Currency)\": \"Volume_Currency\"})\ndata.info()","02461c80":"# to make lower_case all_columns\n\ndata.columns= data.columns.str.lower()\ndata.columns\n","850fcad6":"# to see first five data in dataframe\n\ndata.head() # if you want to see more or less than five data, you need to use number in brackets..like->data.head(10) \n\n# data.tail() # to see last five data","cf829cb7":"#there are null(NaN) values and we need to clean the missing data\n\ndata = data.dropna(how='any',axis=0)\ndata","bb1bc88c":"data.info()","2044973f":"# encode the date to period column and delete timestamp column\n\ndata['period'] = pd.to_datetime(data['timestamp'],unit='s').dt.to_period('M') # monthly period\ndata = data.drop([\"timestamp\"],axis=1)   # column drop with column name\ndata","098e1697":"#data = data.groupby('period')\n#data.head()\n\ndata = data.groupby('period').agg({'weighted_price': ['mean'], 'volume_btc': ['sum'], 'volume_currency': ['sum']})\ndata.columns = ['weighted_price_mean', 'volume_btc_sum', 'volume_currency_sum']\ndata.head(10)\n\n\"\"\"\ngrouped_multiple = data.groupby(['period', 'weighted_price']).agg({'volume_btc': ['mean', 'min', 'max']})\ngrouped_multiple.columns = ['volume_btc_mean', 'volume_btc_min', 'volume_btc_max']\ngrouped_multiple = grouped_multiple.reset_index()\ngrouped_multiple\n\"\"\"","6362cb74":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\n#data.volume_btc_sum.plot(color = 'g',label = 'volume_btc_sum',linewidth=1, alpha = 0.5,grid = True,linestyle = ':')\n#data.volume_currency_sum.plot(color = 'r',label = 'volume_currency_sum',linewidth=1, alpha = 0.5,grid = True,linestyle = '-.')\ndata.weighted_price_mean.plot(kind = 'line', color = 'g',label = 'weighted_price_mean',linewidth=1,alpha = 0.9,grid = True,linestyle = ':')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","97143cb0":"# Scatter Plot \n# as you can in the Scatter Plot, we can say when volume currency increase, weighted price also increse\n\n# x = volume_currency_sum, y = weighted_price_mean\ndata.plot(kind='scatter', x='volume_currency_sum', y='weighted_price_mean',alpha = 0.5,color = 'red')\nplt.xlabel('volume_currency_sum')  # label = name of label\nplt.ylabel('weighted_price_mean') \nplt.title('volume_currency_sum & weighted_price_mean Scatter Plot')            # title = title of plot\nplt.show()\n\n","0d29cd6d":"# Histogram\n# bins = number of weighted_price_mean in figure \ndata.weighted_price_mean.plot(kind = 'hist',bins = 50,figsize = (10,5))\nplt.show()","3acfd776":"#data filtering for price > 11K\n\nx = data['weighted_price_mean']>11000\ndata[x]","caf71c28":"#data filtering with more than one conditions\n\ndata[np.logical_and(data['weighted_price_mean']>5, data['weighted_price_mean']<10)]","14021597":"# Correlation map \n# We can say volume_currency_sum and weighted_price_mean are positively correlated (when values close to 1)\n# And there is no negative correlation (when values close to -1)\n\nf,ax = plt.subplots(figsize=(18,18))\nsns.heatmap(data.corr(),annot=True,linewidths=.5,fmt='.1f',ax=ax)\nplt.show()","cdc24f96":"# AND SOME EXAMPLES FOR DICTIONARY, PANDAS series and dataframe, COMPARISON, WHILE AND FOR LOOPS","a3fa1d91":"#create dictionary and look its keys and values\ndictionary = {'spain' : 'madrid','usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","d7ff2b86":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\n\ndictionary['spain'] = \"barcelona\"    # update existing entry\nprint(dictionary)\n\n\ndictionary['france'] = \"paris\"       # Add new entry\nprint(dictionary)\n\ndel dictionary['spain']              # remove entry with key 'spain'\nprint(dictionary)\n\nprint('france' in dictionary)        # check include or not, returns boolean\n\ndictionary.clear()                   # remove all entries in dict\nprint(dictionary)\n","1b73745e":"#del dictionary         # delete entire dictionary     \n\nprint(dictionary)       # when delete ::: it gives error because dictionary is deleted","a1c751ff":"#PANDAS series and dataframe \n\nseries = data['weighted_price_mean']        # data['weighted_price_mean'] = series\nprint(type(series))\n\ndata_frame = data[['weighted_price_mean']]  # data[['weighted_price_mean']] = data frame\nprint(type(data_frame))\n\nprint(series)\nprint(data_frame)","5f27a814":"# Comparison operator\nprint(5 > 2)\nprint(1!=2)\n\n\n# Boolean operators\nprint(True and False)\nprint(True or False)","be989eaa":"# WHILE and FOR LOOPS\n# Stay in loop if condition( i is not equal 5) is true\n\ni = 0\nwhile i != 5 :\n    print('i is: ',i)\n    i +=1\nprint(i,' is equal to 5')\n\n\n\nfor j in range(5):\n    print('j is:',j)\n    j+=1\nprint(j,' is equal to 5')\n\n\nlist1 = [0,1,2,3,4]\nfor i in list1:\n    print('i is: ',i)\nprint(i,' is equal to 5')\n","3cddd8fc":"# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nlist2 = [1,2,3,4,5]\nfor index, value in enumerate(list2):\n    print(index,\" : \",value)\nprint('')   \n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value before with examples\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index,value in data[['weighted_price_mean']][0:2].iterrows():\n    print(index,\" : \",value)","eb829be5":"# USER DEFINED FUNCTION\n\"\"\"\ntuple: sequence of immutable python objects.\ncant modify values\ntuple uses paranthesis like tuble = (1,2,3)\nunpack tuple into several variables like a,b,c = tuple\n\"\"\"\n\ndef tuple_ex():\n    \"\"\" return defined t tuple\"\"\"\n    t = (data.agg({'weighted_price_mean': ['min']}),data.agg({'weighted_price_mean': ['max']}))\n    return t\n\nmin_mean,max_mean = tuple_ex()\n\nprint(min_mean)\nprint(max_mean)\n\n","381c8598":"#NESTED function\ndef min_max_average():\n    \n    def tuple_ex():\n        \"\"\" return defined t tuple\"\"\"\n        t = data.weighted_price_mean.min(),data.weighted_price_mean.max()\n        print(\"t is a tuple and values are : \",t)\n        return t\n\n    min_mean,max_mean = tuple_ex()\n    print(\"minimum mean is : \", min_mean)\n    print(\"maximum mean is : \", max_mean)\n    \n    return (min_mean+max_mean)\/2\n\nprint(\"Average price is : \", min_max_average())\n  ","06256123":"# flexible arguments *args --> we can send any count of parameters\ndef f(*args):\n    for i in args:\n        print(i)\n        \nf(data.weighted_price_mean.sum()) #we can send one or more(below) parameters\nprint(\" \")\nf(data.weighted_price_mean.min(),data.weighted_price_mean.max(),data.weighted_price_mean.mean())\nprint(\"\")\n\n\n# flexible arguments **kwargs that is dictionary --> --> Again we can send any count of parameters\ndef g(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    i = 0\n    for key, value in kwargs.items():  \n        i = i+1\n        print(i)\n        print(key, \" \", value)\n        if i==3: #as you can see there is no 3 output data, all of it fetch and after that writes one time\n            break\n\ng(montly_weighted_price_mean = data.weighted_price_mean.head(10))","dcedbd94":"# lambda function\nsquare = lambda x: x**2     # where x is name of argument\nprint(square(5))\ntot = lambda x,y,z: x-y+z   # where x,y,z are names of arguments\nprint(tot(3,4,5))","272d5a9d":"#ANONYMOUS FUNCT\u0130ON\n#Like lambda function but it can take more than one arguments.\n\n#map(func,seq) : applies a function to all the items in a list\n    \nnumber_list = [1,2,3]\ny = map(lambda x:x**2,number_list)\nprint(list(y))","338ce04a":"#ITERATORS\n# iteration example\n\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it))    # print next iteration\nprint(next(it))    # print next iteration\nprint(next(it))    # print next iteration\n\nprint(*it)         # print remaining iteration","7024b2c4":"# zip example\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1,list2)\nprint(z)  # it keeps an address\n\nz_list = list(z)\nprint(z_list)","23774500":"un_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip) # unzip returns tuple\nprint(un_list1)\nprint(un_list2)\nprint(type(un_list2))","1fa0a024":"# Example of list comprehension\nnum1 = [1,2,3]\nnum2 = [i + 1 for i in num1 ]\nprint(num2)","91227572":"# Conditionals on iterable\nnum1 = [5,10,15,20]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)","57f096ea":"# lets return btc csv data and make one more list comprehension example\n# lets classify btc mohtly_mean whether they have high or low price according to all_time mean. \n# Our threshold is all_time mean.\nthreshold = sum(data.weighted_price_mean)\/len(data.weighted_price_mean)\ndata['threshold'] = sum(data.weighted_price_mean)\/len(data.weighted_price_mean)\ndata[\"weighted_price_level\"] = [\"higher\" if i > threshold else \"lower\" for i in data.weighted_price_mean]\ndata.loc[:,[\"weighted_price_mean\",\"threshold\",\"weighted_price_level\"]] ","98ff8f9c":"# CLEANING DATA\n\n#DIAGNOSE DATA for CLEANING","692504ba":"data.head() #first five data","3c18c6b0":"data.tail() #last five data","f383e6a7":"# columns gives column names of features\ndata.columns","2faac443":"# shape gives number of rows and columns in a tuble\ndata.shape","f4d51d22":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","6b72a1b9":"#EXPLORATORY DATA ANALYSIS\n#value_counts(): Frequency counts\n#outliers: the value that is considerably higher or lower from rest of the data\n\n# For example lets look frequency of Volume_(BTC)\ndata\nprint(data['weighted_price_level'].value_counts(dropna =False))  # if there are nan values that also be counted\n\n# As it can be seen below there are 1241716 NaN values in the data","a6303c27":"# You can see sum basic information about data with describe() method \n\ndata.describe() #ignore null entries","ab0b5375":"#VISUAL EXPLORATORY DATA ANALYSIS\n\n# Box plots: visualize basic statistics like outliers, min\/max or quantiles\n\n#What is quantile?\n#1,4,5,6,8,9,11,12,13,14,15,16,17\n#The median is the number that is in middle of the sequence. In this case it would be 11.\n#The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n#The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.\n\n# For example: compare weighted_price_mean of BTC that are weighted_price_level is Higher or Lower\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\n\ndata.boxplot(column='weighted_price_mean',by = 'weighted_price_level')\n","e2796c48":"# TIDY DATA\n# We tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it.\n\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","dece5578":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'weighted_price_mean', value_vars= ['volume_btc_sum','volume_currency_sum'])\nmelted","6bb579e5":"#PIVOTING DATA\n#Reverse of melting.\n\n# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\n\nmelted.pivot(index = 'weighted_price_mean', columns = 'variable',values='value')","41f60b0f":"# CONCATENATING DATA\n# We can concatenate two dataframe\n\n# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) #axis=0 : adds dataframes in row \nconc_data_row","ef407efe":"data1 = data['weighted_price_mean'].head()\ndata2= data['volume_btc_sum'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in column\nconc_data_col","9ca35fe4":"\n# DATA TYPES\n# There are 5 basic data types: object(string),boolean, integer, float and categorical.\n# We can make conversion data types like from str to categorical or from int to float\n# Why is category important:\n# make dataframe smaller in memory\n# can be utilized for anlaysis especially for sklearn(we will learn later)","55745372":"# type(data) this is about all data like DataFrame\n\ndata.dtypes # this is about columns\n","a5e9d4fc":"# lets convert object(str) to categorical and float to int.\ndata['weighted_price_level'] = data['weighted_price_level'].astype('category')\ndata['threshold'] = data['threshold'].astype('int')","73a9d26d":"# As you can see weighted_price_level is converted from object to category\n# And threshold is converted from float to int\ndata.dtypes","a8ae97bc":"# MISSING DATA and TESTING WITH ASSERT\n\n# If we encounter with missing data, what we can do:\n\n# leave as is\n# drop them with dropna()\n# fill missing value with fillna()\n# fill missing values with test statistics like mean\n# Assert statement: check that you can turn on or turn off when you are done with your testing of the program","aede0099":"# Lets look at does btc data have nan value\n# As you can see there are 106 entries. However there is no null object because of i clean them before\ndata.info()","6c8f47c0":"# Lets check weighted_price_mean\ndata[\"threshold\"].value_counts(dropna =False)\n# As you can see, there is no NAN value","38f166ee":"data[\"test\"] = [None if i<10 else 1 for i in data.weighted_price_mean] #added sum NaN values for test column","82237884":"data[\"test\"].value_counts(dropna = False)  #lets see count of values with NaN values","c0bf4fe1":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","2c7f3758":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false you can check and see error","edee7a3b":"# In order to run all code, we need to make this line comment\n#assert data['test'].notnull().all() # returns error  because it is false\n","0c9a8af7":"assert data['weighted_price_mean'].notnull().all() # returns nothing because we drop nan values","521a0c5f":"# Lets fill drop NaN values \n# data = data[\"test\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n\n# Lets fill nan values with empty\ndata[\"test\"].fillna('empty',inplace = True)\ndata[\"test\"].value_counts(dropna = False)  #lets see count of empty values ","046dd0e8":"assert data['test'].notnull().all() # returns nothing  because it is true","a1330248":"# We can build data frames from csv as we did earlier.\n# Also we can build dataframe from dictionaries\n\n# data frames from dictionary\ncountry = [\"Spain\",\"France\",\"Germany\",\"Turkey\"]\nteam = [\"Barcelona\",\"PSG\",\"Bayern\",\"Fenerbahce\"]\nlist_label = [\"country\",\"team\"]\nlist_col = [country,team]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf\n","c45e5823":"# Add new columns\ndf[\"fan\"] = [\"11\",\"12\",\"13\",\"35\"]\ndf","a26ef8c4":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","c37e6ca2":"# Plotting all data \ndata1 = data.loc[:,[\"weighted_price_mean\",\"volume_btc_sum\",\"volume_currency_sum\"]]\ndata1.plot()\nplt.show()","e575b8f2":"# subplots\ndata1.plot(subplots = True)\nplt.show()","001239de":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"volume_currency_sum\",y = \"weighted_price_mean\")\nplt.show()","9287b56f":"# histogram plot  \ndata1.plot(kind = \"hist\",y = \"weighted_price_mean\",bins = 50,range= (0,20000))\nplt.show()","8886e45b":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"weighted_price_mean\",bins = 50,range= (0,20000),ax = axes[0]) #non cumu\u015fative\ndata1.plot(kind = \"hist\",y = \"weighted_price_mean\",bins = 50,range= (0,20000),ax = axes[1],cumulative = True) #cumulative\n#plt.savefig('graph.png')\nplt.show()","62820fa9":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))\n\nprint(\"\")\nprint(datetime_object)","1c797d33":"# as you can see we have PeriodIndex\ntype(data.index)\n\n# you can see here PeriodIndex again at head of output\n# data.info() ","7204a7be":"data.loc[\"2018-09\"]","50f56e7a":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# In order to practice lets take head of btc data and add it a time list \ndata2 = data.head()\ndate_list = [\"2012-01-30\",\"2012-01-31\",\"2013-01-31\",\"2013-02-28\",\"2013-04-30\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","d2f26abb":"# Now we can select according to our DateIndex\n\nprint(data2.loc[\"2012-01-30\"])\nprint(data2.loc[\"2012-01-31\":\"2013-02-28\"])","4695d8bb":"# We will use data2 that we create at previous part \ndata2.resample(\"A\").mean()","4f71454f":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are lots of NaN because data2 does not include all months","6469c933":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# For example we can interpolete from with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","8a6661c0":"a = [0,1,2,3,4]\n\na[0]\n\nfor a[0] in a:\n\n    print(a[0])","fc4338f6":"data.info() # we have PeriodIndex","41caed84":"#then and we want to change the index to number 0-105\ndata[\"new_index\"] = 0\n\n\ni=0 \nfor i in range(106):\n    data[\"new_index\"][i] = i\n    \ndata.head() # we added new column to assign new index (new_index column)\n","a7a467b8":"data= data.set_index(\"new_index\") #we are changing the index to new_index column\ndata.head()","e1c4dfc4":"# indexing using square brackets\ndata[\"weighted_price_mean\"][1]   #second value will turn","3ba1e2da":"# indexing using column attribute and row label\ndata.weighted_price_mean[1]","9eac541a":"# using loc accessor\ndata.loc[1,[\"weighted_price_mean\"]]","a6a525be":"# Selecting only some columns\ndata[[\"weighted_price_mean\",\"threshold\",\"weighted_price_level\"]]","c000da0d":"data.head()","dcfd8445":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"weighted_price_mean\"]))     # series\nprint(type(data[[\"weighted_price_mean\"]]))   # data frames","d5a22fa0":"# Slicing and indexing series\ndata.loc[1:10,\"weighted_price_mean\":\"volume_currency_sum\"]   # 10 and \"volume_currency_sum\" are inclusive","db15f429":"# Reverse slicing \ndata.loc[10:1:-1,\"weighted_price_mean\":\"volume_currency_sum\"] ","33b2fe17":"# From something to end\ndata.loc[1:10,\"threshold\":] ","fe5de074":"# Creating boolean series\nboolean = data.weighted_price_mean > 10000  \n\ndata[boolean]  #returns true values","bff44952":"# Combining filters\nfirst_filter = data.weighted_price_mean > 10000\nsecond_filter = data.volume_btc_sum > 400000\n\ndata[first_filter & second_filter]  # apply 2 filter with and condition","6ce1cbcf":"# Filtering column based others\ndata.weighted_price_mean[data.volume_btc_sum>800000]","65fe100f":"# Plain python functions\ndef div(n):\n    return n\/2\n\ndata.weighted_price_mean.apply(div)","ffe01476":"# Or we can use lambda function\ndata.weighted_price_mean.apply(lambda n : n\/2)","d5294cde":"# Defining column using other columns\ndata[\"total_volume\"] = data.volume_btc_sum + data.volume_currency_sum\ndata.head()","ae7dc644":"# our index name is this:\nprint(data.index.name)\n\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","206fb595":"# Overwrite index\n\n# if we want to modify index, we need to change all of them.\ndata.head()\n\n# first copy of our data to data1 then change index \ndata1 = data.copy()\n\n# lets make index start from 100. It is not remarkable change but it is just example\ndata1.index = range(100,206,1)\ndata1.head()","1f9b69d2":"# We can make one of the column as index. We actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"new_index\")\n# also you can use \n# data.index = data[\"new_index\"]","de407bcf":"# lets read data frame one more time to start from beginning\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","7097f806":"# Setting index : test column is outer weighted_price_level is inner index\ndata1 = data.set_index([\"test\",\"weighted_price_level\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","252ec44c":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","a7010958":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","72419add":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","1e2520f1":"# level determines indexes\ndf1.unstack(level=0)","20e332e8":"df1.unstack(level=1)","59967faf":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","da9f55c5":"df","c8bfca68":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","81b98f0f":"df","a769225c":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","6449e30d":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","8535d194":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","3517d807":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","bb3e78b5":"# HIERARCHICAL INDEXING\n* Setting indexing","3468b60c":"\n# INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","82740ced":"# SLICING DATA FRAME\n*     Difference between selecting columns\n    *     Series and data frames\n*     Slicing and indexing series\n*     Reverse slicing\n*     From something to end","a89a3137":"\n# FILTERING DATA FRAMES\nCreating boolean series Combining filters Filtering column based others","f725e67a":"# MELTING DATA FRAMES\n* Reverse of pivoting","8e7fdace":"# MANIPULATING DATA FRAMES WITH PANDAS\n  INDEXING DATA FRAMES\n    * Indexing using square brackets\n    * Using column attribute and row label\n    * Using loc accessor\n    * Selecting only some columns","f511bac9":"VISUAL EXPLORATORY DATA ANALYSIS\n\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","b6b3678c":"# TRANSFORMING DATA\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns","b6457f24":"# RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    *   Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019\n    *   https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html","57d54fcf":"# CATEGORICALS AND GROUPBY","69e2072a":"# STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","5bffbee6":"# INDEX OBJECTS AND LABELED DATA\n* index: sequence of label","50d9c341":"\n# PIVOTING DATA FRAMES\n* pivoting: reshape tool"}}