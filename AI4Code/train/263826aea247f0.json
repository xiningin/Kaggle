{"cell_type":{"cd73e35b":"code","b87f1d03":"code","c48faa9f":"code","7070fec2":"code","a378e7b5":"code","e9796604":"code","259634c2":"code","2990b2e8":"code","01bf957c":"code","25e16556":"code","0e023170":"code","8c32297e":"code","8c112b1a":"code","47885083":"code","879099ca":"code","888c4cb0":"code","5f7b1d5d":"code","4c221d5c":"code","9e01e89e":"markdown","d684a286":"markdown","65a1f84c":"markdown"},"source":{"cd73e35b":"from glob import glob\n\nimport numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.datasets import load_files \nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.python.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.utils import np_utils\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint\nfrom tensorflow.python.keras.preprocessing import image\n\nfrom tensorflow.python.keras.applications import ResNet50,VGG16, InceptionResNetV2\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\nfrom keras import optimizers\n\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"..\/input\/testimgs\/testplant\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom tqdm import tqdm\n\nfrom PIL import ImageFile                            \nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nfrom shutil import copyfile\n\nplt.rcParams[\"figure.figsize\"] = (20,3)\n\nfrom prettytable import PrettyTable\nimport random","b87f1d03":"from tensorflow.python.keras.optimizers import Adam\nfrom tensorflow.python.keras.optimizers import SGD\n#myOPT = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n#mySGD = SGD(lr=0.1, momentum = 0.9, decay=1e-5)\n\n# Add top 2 accuracy metric for compiling purpose\nimport functools\nfrom tensorflow.python.keras import metrics\ntop2_acc = functools.partial(metrics.top_k_categorical_accuracy, k=2)\ntop2_acc.__name__ = 'top2_acc'","c48faa9f":"from matplotlib.pyplot import figure\n\ndef plot_images(images,adr):\n    figure(figsize=(20,8))\n    for i in range(len(images)):\n        plt.subplot(2,len(images)\/2,i+1)\n        #split the name \n        fulldata = images[i]\n        rightdata=fulldata[:-6]\n        data=rightdata[2:]\n        # finish\n        plt.title(data)\n        image = mpimg.imread(adr+images[i])\n        #print(base_dir+images[i])\n        plt.imshow(image)","7070fec2":"from matplotlib.pyplot import figure\n\ndef plotModelHistory(modeHistory, model_name=\"\"):\n    figure(figsize=(6,4))\n    # summarize history for accuracy\n    history = modeHistory\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy: %s'%(model_name))\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    figure(figsize=(6,4))\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss: %s'%(model_name))\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()","a378e7b5":"base_dir = \"..\/input\/vegetablesweek3\/w3plantdataset\/\"\ncategories = os.listdir(base_dir)\ntest_dir=\"..\/input\/testimgs\/testplant\/testplant\/\"\ntestimg_dir = os.listdir(test_dir)\n","e9796604":"%rm -rf data\n%mkdir -p data\/pngFiles\n%mkdir -p data\/testFiles\n%ls data\/pngFiles","259634c2":"import shutil\ni=[]\ndst = 'data\/pngFiles'\ndst2 = 'data\/testFiles'\nimport fnmatch\nfor file_name in categories:\n     if fnmatch.fnmatch(file_name, '*.png'):\n        shutil.copy2(base_dir+file_name, dst)\nfor file_name in testimg_dir:\n     if fnmatch.fnmatch(file_name, '*.png'):\n        shutil.copy2(test_dir+file_name, dst2)","2990b2e8":"AllpngFiles = os.listdir('data\/pngFiles')\nAlltestFiles = os.listdir('data\/testFiles')\n\n","01bf957c":"plot_images(random.sample(AllpngFiles, 10),base_dir)\n","25e16556":"#test data\nplot_images(random.sample(AlltestFiles, 10),test_dir)\n","0e023170":"\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\n\nimage_size = 224\nbatch_size = 64\ndirectory = \"..\/input\/vegetablesweek3\/w3plantdataset\/\"\nlabels = pd.read_csv(\"..\/input\/vegetablesweek3\/w3plantdataset\/labels.csv\")\nfrom sklearn.utils import shuffle\nlabels = shuffle(labels)\nlabelsTest = pd.read_csv( \"..\/input\/testimgs\/testplant\/testplant\/labels.csv\")\n\n\n\n### With Augmentation\ndata_generator = ImageDataGenerator(\n                                    preprocessing_function=preprocess_input,\n#                                     zoom_range=0.3,\n                                    #horizontal_flip=True,\n                                    validation_split = 0.2\n                                   )\n#  no augmentation for test data\ndata_generator_no_aug = ImageDataGenerator()\n\n# 0.8*2250=1804 # train-epoch should be 200\ntrain_generator = data_generator.flow_from_dataframe(dataframe = labels, \n                                                    directory = directory,\n                                                    target_size = (image_size, image_size),\n                                                    batch_size = 9,\n                                                    shuffle= True,\n                                                    class_mode = 'categorical',\n                                                    subset = 'training')\n\n# 0.2*2250 = 450 # validation step = 90\nvalidation_generator = data_generator.flow_from_dataframe(dataframe = labels, \n                                                    directory = directory,\n                                                    target_size = (image_size, image_size), \n                                                    batch_size = 5,\n                                                    shuffle=True,\n                                                    class_mode = 'categorical',\n                                                    subset = 'validation')\n# 21\ntest_generator = data_generator_no_aug.flow_from_dataframe(dataframe = labelsTest, \n                                                directory = '..\/input\/testimgs\/testplant\/testplant', \n                                                target_size=(image_size, image_size),\n                                                batch_size=2,\n                                                shuffle=False       \n                                            )","8c32297e":"#Drawing what we have in training imgs with augmention\nx,y = validation_generator.next()\nfig = plt.figure(figsize=(18,13))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\n\nfor i in range(0,5):\n    ax = fig.add_subplot( 4, 5, i+1)\n    image = x[i]\n    ax.imshow(image.astype('uint8'))","8c112b1a":"#Drawing what we have in testing imgs without augmention\nx,y = test_generator.next()\nfig = plt.figure(figsize=(18,7))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nfor i in range(0,2):\n    ax = fig.add_subplot( 1, 4, i+1)\n    image = x[i]\n    ax.imshow(image.astype('uint8'))","47885083":"models={}\noptimizers={} \nnb_classes = 10","879099ca":"modelName = \"ResNet50\"\nfrom keras import optimizers\nweights = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# base_model = ResNet50(include_top=False, pooling='avg', weights=weights, input_shape=(224,224,3))\n# x = base_model.output\n# predictions = Dense(nb_classes, activation='softmax')(x)\n# model = Model(inputs=base_model.input, outputs=predictions, name=modelName)\n\n# #freez all base_model\n# for layer in base_model.layers:\n#     layer.trainable = False\n\n# ### Spsecify Model\n# my_new_model = kr.Sequential()\n# my_new_model.add(ResNet50(include_top = False, pooling='avg', weights='..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'))\n# my_new_model.add(Dense(num_classes, activation='softmax'))\n# my_new_model.layers[0].trainable = False\n\n# ### Compile Model\n# my_new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# ### Summary of model\n# my_new_model.summary()\n# ############################\n\n\nmodel = Sequential(name=modelName)\n\nmodel.add(ResNet50(include_top=False, pooling='avg', weights=weights, input_shape=(224,224,3)))\nmodel.add(Dense(nb_classes, activation='softmax'))\n\nmodel.layers[0].trainable = False\n\n# Learning rate is changed to 0.001\n# The original is 0.01\nopt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\n# add this to our models list\nmodels[model.name] = model\n","888c4cb0":"def test_me(model, v = 1):\n    # reset the generator, just in case\n    test_generator.reset()    \n    # predict all test data\n    pred = model.predict_generator(test_generator,verbose = v)    \n    # store predicted indices\n    predicted_class_indices = np.argmax(pred,axis=1)    \n    labels = (test_generator.class_indices)    \n    # map indoces to actual labels\n    labels = dict((v,k) for k,v in labels.items())\n    predictions = [labels[k] for k in predicted_class_indices]\n    return (pred,predictions)\n","5f7b1d5d":"vb = 2\nnb_epochs = 50\nresults = []\n\nfor model_name, model in models.items():      \n    result={}\n    result['model_name'] = model.name \n    print(\"===> [1\/4] Training : \" + model.name)    \n    h = model.fit_generator(\n            train_generator,\n            steps_per_epoch = 210,\n            epochs= nb_epochs,\n            initial_epoch=0,\n            validation_data = validation_generator,\n            validation_steps=100,)\n\n\n\n","4c221d5c":"result['train_acc'] = h.history['acc'][-1]\nprint(\"===> [2\/4] Ploting : \" + model.name)\nplotModelHistory(h, model.name)\nprint(\"===> [3\/4] Evaluating : \" + model.name)\ntest_generator.reset()\nevs = model.evaluate_generator(generator=test_generator,verbose = vb)\nprint(\" \")\nfor i,ev in enumerate(evs):\n    if i is not 0:\n        result[model.metrics_names[i]] = 100*ev\n        print(\"%10s : %.4f%%\"%(model.metrics_names[i], 100*ev))\nprint(\" \")\nprint(\"===> [4\/4] visualize results : \" + model.name)\n    \n# predict\n(predictions,p_labels) = test_me(model)\n\n# list of categories\ncateories = (test_generator.class_indices)\ncateories = [k for k,v in cateories.items()]\n\nfor i in range(1,19):\n    fig = plt.figure(figsize=(14,5))\n    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n    file_name = test_generator.filenames[i]\n    predicted_lable = p_labels[i]\n    p = predictions[i]\n\n    ax = fig.add_subplot(1, 2, 1)\n    image = mpimg.imread(test_dir+file_name)\n    ax.imshow(image)\n\n    ax = fig.add_subplot(1, 2, 2)\n    y_pos = np.arange(len(cateories))\n    ax.barh(y_pos, p, align='center',color='green', ecolor='black')\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(cateories)\n    #ax.invert_yaxis()\n    ax.set_xlabel('probability')\n    ax.set_title('Model:%s | Label:%s | Predicted:%s'%(model.name, file_name.split('\/')[0],predicted_lable))\n    for i, v in enumerate(p):\n        ax.text(v + .05, i-.1 , \"%%%2.3f\"%(100*v), color='green')\n    plt.show()\nresults.append(result)\n","9e01e89e":"**Folders 3 **","d684a286":"**\nData generation**\nFrom image files, we need to generate data that is cunsumable for Keras framework. This is done using ImageDataGenerator\nFor our train and validation sets, some image augmentation is used, but for test set, no augmentation applies.","65a1f84c":"**copy imgs to folders and plot the png files**"}}