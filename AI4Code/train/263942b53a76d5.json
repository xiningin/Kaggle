{"cell_type":{"481a4d23":"code","8bb461cb":"code","8a4b545e":"code","d7cf6459":"code","bafab1f4":"code","23b69b1f":"code","3977328d":"code","75c28f0a":"code","8555ff63":"code","d5c97163":"code","2e36c547":"code","0f65f9e6":"code","f6c6628b":"code","290e1f7d":"code","124977b9":"code","0ddcafae":"code","9da1be99":"code","5c6a276c":"code","66ef8d43":"code","4e95fe7a":"code","4135aa38":"code","1149da4d":"code","f5c9cb15":"code","cf6fadb2":"code","1e3a5fc5":"code","3f9c0a13":"code","aa4fe099":"code","cd2cfbe9":"code","a6e64519":"code","00215c1c":"code","ac9f354d":"code","d88517be":"code","748d4201":"markdown","4dc268c0":"markdown","4588a7a1":"markdown","3f2d512c":"markdown","a08edafc":"markdown","83b47a60":"markdown","9f9fd638":"markdown","1ae703d1":"markdown","a1dbf786":"markdown","9c9738ff":"markdown","11fef003":"markdown","9f859a17":"markdown","8b7ce1ff":"markdown"},"source":{"481a4d23":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport random\nimport librosa, IPython\nimport librosa.display as lplt\nseed = 12\nnp.random.seed(seed)","8bb461cb":"df = pd.read_csv('\/kaggle\/input\/gtzan-dataset-music-genre-classification\/Data\/features_3_sec.csv')\ndf.head()","8a4b545e":"print(\"Dataset has\",df.shape)\nprint(\"Count of Positive and Negative samples\")\ndf.label.value_counts().reset_index()","d7cf6459":"audio_fp = '\/kaggle\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/blues\/blues.00000.wav'\naudio_data, sr = librosa.load(audio_fp)\naudio_data, _ = librosa.effects.trim(audio_data)","bafab1f4":"# play sample file\nIPython.display.Audio(audio_data, rate=sr)","23b69b1f":"# plot sample file\nplt.figure(figsize=(15,5))\nlplt.waveplot(audio_data)\nplt.show()","3977328d":"# Default FFT window size\nn_fft = 2048 # window size\nhop_length = 512 # window hop length for STFT\n\nstft = librosa.stft(audio_data, n_fft=n_fft, hop_length=hop_length)\nstft_db = librosa.amplitude_to_db(stft, ref=np.max)\n\nplt.figure(figsize=(12,4))\nlplt.specshow(stft, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()\nplt.title(\"Spectrogram with amplitude\")\nplt.show()\n\nplt.figure(figsize=(12,4))\nlplt.specshow(stft_db, sr=sr, x_axis='time', y_axis='log', cmap='cool')\nplt.colorbar()\nplt.title(\"Spectrogram with decibel log\")\nplt.show()","75c28f0a":"# plot zoomed audio wave \nstart = 1000\nend = 1200\nplt.figure(figsize=(16,4))\nplt.plot(audio_data[start:end])\nplt.show()","8555ff63":"mel_spec = librosa.feature.melspectrogram(audio_data, sr=sr)\nmel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\nplt.figure(figsize=(16,6))\nlplt.specshow(mel_spec_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', cmap='cool')\nplt.colorbar()\nplt.title(\"Mel Spectrogram\")\nplt.show()","d5c97163":"chroma = librosa.feature.chroma_stft(audio_data, sr=sr)\nplt.figure(figsize=(16,6))\nlplt.specshow(chroma, sr=sr, x_axis='time', y_axis='chroma', cmap='coolwarm')\nplt.colorbar()\nplt.title(\"Chroma Features\")\nplt.show()","2e36c547":"# Computing the Correlation Matrix\nspike_cols = [col for col in df.columns if 'mean' in col]\ncorr = df[spike_cols].corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(16, 11));\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(0, 25, as_cmap=True, s = 90, l = 45, n = 5)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\nplt.title('Correlation Heatmap (for the MEAN variables)', fontsize = 20)\nplt.xticks(fontsize = 10)\nplt.yticks(fontsize = 10);\nplt.savefig(\"Corr_Heatmap.png\")","0f65f9e6":"x = df[[\"label\", \"tempo\"]]\n\nfig, ax = plt.subplots(figsize=(16, 8));\nsns.boxplot(x = \"label\", y = \"tempo\", data = x, palette = 'husl');\n\nplt.title('BPM Boxplot for Genres', fontsize = 20)\nplt.xticks(fontsize = 14)\nplt.yticks(fontsize = 10);\nplt.xlabel(\"Genre\", fontsize = 15)\nplt.ylabel(\"BPM\", fontsize = 15)\nplt.savefig(\"BPM_Boxplot.png\")","f6c6628b":"data = df.iloc[0:, 1:]\ny = data['label']\nX = data.loc[:, data.columns != 'label']\n\n# normalize\ncols = X.columns\nmin_max_scaler = skp.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X)\nX = pd.DataFrame(np_scaled, columns = cols)\n\n# Top 2 pca components\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(X)\nprincipalDf = pd.DataFrame(data = principalComponents, columns = ['pc1', 'pc2'])\n\n# concatenate with target label\nfinalDf = pd.concat([principalDf, y], axis = 1)\n\nplt.figure(figsize = (16, 9))\nsns.scatterplot(x = \"pc1\", y = \"pc2\", data = finalDf, hue = \"label\", alpha = 0.7, s = 100);\n\nplt.title('PCA on Genres', fontsize = 20)\nplt.xticks(fontsize = 14)\nplt.yticks(fontsize = 10);\nplt.xlabel(\"Principal Component 1\", fontsize = 15)\nplt.ylabel(\"Principal Component 2\", fontsize = 15)\nplt.savefig(\"PCA_Scattert.png\")","290e1f7d":"# find all columns with any NA values\nprint(\"Columns with NA values are\",list(df.columns[df.isnull().any()]))","124977b9":"# map labels to index\nlabel_index = dict()\nindex_label = dict()\nfor i, x in enumerate(df.label.unique()):\n    label_index[x] = i\n    index_label[i] = x\nprint(label_index)\nprint(index_label)","0ddcafae":"# update labels in df to index\ndf.label = [label_index[l] for l in df.label]","9da1be99":"# shuffle samples\ndf_shuffle = df.sample(frac=1, random_state=seed).reset_index(drop=True)","5c6a276c":"# remove irrelevant columns\ndf_shuffle.drop(['filename', 'length'], axis=1, inplace=True)\ndf_y = df_shuffle.pop('label')\ndf_X = df_shuffle\n\n# split into train dev and test\nX_train, df_test_valid_X, y_train, df_test_valid_y = skms.train_test_split(df_X, df_y, train_size=0.7, random_state=seed, stratify=df_y)\nX_dev, X_test, y_dev, y_test = skms.train_test_split(df_test_valid_X, df_test_valid_y, train_size=0.66, random_state=seed, stratify=df_test_valid_y)","66ef8d43":"print(f\"Train set has {X_train.shape[0]} records out of {len(df_shuffle)} which is {round(X_train.shape[0]\/len(df_shuffle)*100)}%\")\nprint(f\"Dev set has {X_dev.shape[0]} records out of {len(df_shuffle)} which is {round(X_dev.shape[0]\/len(df_shuffle)*100)}%\")\nprint(f\"Test set has {X_test.shape[0]} records out of {len(df_shuffle)} which is {round(X_test.shape[0]\/len(df_shuffle)*100)}%\")","4e95fe7a":"print(y_train.value_counts()[0]\/y_train.shape[0]*100)\nprint(y_dev.value_counts()[0]\/y_dev.shape[0]*100)\nprint(y_test.value_counts()[0]\/y_test.shape[0]*100)","4135aa38":"scaler = skp.StandardScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\nX_dev = pd.DataFrame(scaler.transform(X_dev), columns=X_train.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)","1149da4d":"import tensorflow as tf\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\ntf.random.set_seed(seed)","f5c9cb15":"ACCURACY_THRESHOLD = 0.94\n\nclass myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True\n\ndef trainModel(model, epochs, optimizer):\n    batch_size = 128\n    callback = myCallback()\n    model.compile(optimizer=optimizer,\n                  loss='sparse_categorical_crossentropy',\n                  metrics='accuracy'\n    )\n    return model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=epochs, \n                     batch_size=batch_size, callbacks=[callback])\n\ndef plotHistory(history):\n    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n    pd.DataFrame(history.history).plot(figsize=(12,6))\n    plt.show()\n","cf6fadb2":"model_1 = k.models.Sequential([\n    k.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n    k.layers.Dense(128, activation='relu'),\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dense(10, activation='softmax'),\n])\nprint(model_1.summary())\nmodel_1_history = trainModel(model=model_1, epochs=70, optimizer='adam')","1e3a5fc5":"plotHistory(model_1_history)","3f9c0a13":"model_2 = k.models.Sequential([\n    k.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n    k.layers.Dropout(0.2),\n    \n    k.layers.Dense(256, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(128, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(10, activation='softmax'),\n])\nprint(model_2.summary())\nmodel_2_history = trainModel(model=model_2, epochs=100, optimizer='adam')","aa4fe099":"plotHistory(model_2_history)","cd2cfbe9":"model_3 = k.models.Sequential([\n    k.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n    k.layers.Dropout(0.2),\n    \n    k.layers.Dense(256, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(128, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(10, activation='softmax'),\n])\nprint(model_3.summary())\nmodel_3_history = trainModel(model=model_3, epochs=700, optimizer='sgd')","a6e64519":"plotHistory(model_3_history)","00215c1c":"model_4 = k.models.Sequential([\n    k.layers.Dense(1024, activation='relu', input_shape=(X_train.shape[1],)),\n    k.layers.Dropout(0.3),\n    \n    k.layers.Dense(512, activation='relu'),\n    k.layers.Dropout(0.3),\n\n    k.layers.Dense(256, activation='relu'),\n    k.layers.Dropout(0.3),\n\n    k.layers.Dense(128, activation='relu'),\n    k.layers.Dropout(0.3),\n\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dropout(0.3),\n\n    k.layers.Dense(10, activation='softmax'),\n])\nprint(model_4.summary())\nmodel_4_history = trainModel(model=model_4, epochs=500, optimizer='rmsprop')","ac9f354d":"plotHistory(model_4_history)","d88517be":"test_loss, test_acc  = model_4.evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"\\nThe Best test Accuracy is :\",test_acc*100)","748d4201":"# Data Preparation\n\n- Treat missing values.\n- Outlier Treatment\n- Define dummy variables for categorical variables.","4dc268c0":"# Reading & Understanding Data\n## Importing Libraries","4588a7a1":"### About the dataset","3f2d512c":"## Missing Value Treatment","a08edafc":"# Data Visualization","83b47a60":"### Loading Dataset","9f9fd638":"# Model Evaluation","1ae703d1":"## Scale the Features","a1dbf786":"# Model Building","9c9738ff":"# GTZAN - Deep Learning\n\n`Music Genre Classification Problem`. Experts have been trying for a long time to understand sound & what differentiates one from another. How to visualize sound. What makes one tone different from another.\n\nWe are going to analyze the features extracted from the GTZAN dataset and build different type of ensemble models to see how better we can differentiate one genre from another.\n\nOur Datasets contains 10 genres:-\n- Blues\n- Classical\n- Country\n- Disco\n- Hiphop\n- Jazz\n- Metal\n- Pop\n- Reggae\n- Rock\n","11fef003":"## Encode Genre Label","9f859a17":"# Split Train, Dev & Test Sets","8b7ce1ff":"`No null values in the dataset`\n\n\n\n`There are no categorical variable as such. Hence, Dummy variable creation is not needed.`"}}