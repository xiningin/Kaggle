{"cell_type":{"1a7cb3d9":"code","229d5c88":"code","5556897a":"code","3b4bede5":"code","1dd6487d":"code","409ae723":"code","c72c46b4":"code","360653bc":"code","a9cb8e82":"code","f315bfd4":"code","2fce9854":"code","9c16c05d":"code","e08a16a1":"code","95754e2d":"code","637001cc":"code","7a840a1f":"code","06a78d5b":"code","ca507d08":"code","eb8a0d5d":"code","48a0034d":"code","7aede8a6":"code","dc160408":"code","a4ce1cfb":"code","1e841ab5":"code","e32b2eb0":"code","8a045691":"code","69e8a181":"code","e3f2c44f":"code","bca660af":"code","783a13a9":"code","bdb8b6c5":"code","9d591d38":"code","4a667e98":"code","ff42824e":"code","1f994c52":"code","a6a3566a":"code","6c2e3fe1":"code","f462c0fd":"code","80d671ce":"code","84b57f5f":"code","4aadb5c6":"code","9803cf02":"code","4466c069":"code","8110a3a6":"code","a57dd8fd":"code","3d015e7f":"code","e7b2d1db":"code","4d29e96f":"code","fd9f076a":"code","74151ce7":"code","081c9009":"code","2848f188":"code","ac43216b":"code","a420a7fd":"code","df837831":"code","e042b82c":"code","54be2eac":"code","8f40069e":"code","804de4e6":"code","e2e0c5c7":"code","554ae981":"code","7b5fd6b3":"code","ff0fcfab":"code","6e0b93fb":"markdown","01dd95ed":"markdown","63ee5cd3":"markdown","829f89b3":"markdown","15028e28":"markdown","2360c0fc":"markdown","be370d5b":"markdown","186b6358":"markdown","9e2e6704":"markdown","f7f66d5a":"markdown","435746b8":"markdown","c9380772":"markdown","93026c11":"markdown","82f4a070":"markdown","47bc82be":"markdown","ecee8d6e":"markdown","de288a69":"markdown","ba38d3ad":"markdown","d7c53120":"markdown","044c5587":"markdown","356159b5":"markdown","e48d3b23":"markdown","2c677162":"markdown","56efad06":"markdown","18c8caeb":"markdown","28474e2b":"markdown","8134c057":"markdown","0dd4fc88":"markdown","d5c73a9c":"markdown"},"source":{"1a7cb3d9":"# if afinn modulue not installed\n! pip install afinn","229d5c88":"# im using sklearn version 1.0.2\n! pip uninstall scikit-learn -y","5556897a":"pip install scikit-learn","3b4bede5":"import pandas as pd\nfrom collections import Counter\nimport plotly.graph_objects as go\nimport collections\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport emoji\nimport regex\nimport itertools\nimport re\nfrom matplotlib.image import imread\nfrom afinn import Afinn\nafinn = Afinn(language='en')\nimport plotly.express as px\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.metrics import classification_report\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nfrom tensorflow.keras.backend import clear_session\nimport tensorflow","1dd6487d":"class TwitterCyberBullying:\n    \n    DataFrameDirectory = '..\/input\/cyberbullying-classification\/cyberbullying_tweets.csv'\n    TweetColumns = 'tweet_text'\n    LabelColumns = 'cyberbullying_type'\n    LabelColumnsEncoded = 'cyberbullying_type_encoding'\n\n    TrainSenctence = None\n    TestSentence = None\n    TrainY = None\n    TestY = None\n\n    LogisticRegressionModel_ = None\n    XGBClassifierModel_ = None\n    NaiveBayesClassifier_ = None\n    NeuralNetworkModel_ = None\n\n    Vectorizer_ = None\n    LabelMapping_ = None\n\n    def __init__(self):\n\n        pass\n\n    @classmethod\n    def UpdateVariableVectorized(cls, TrainSentence, TestSentence, TrainY, TestY):\n        cls.TrainSenctence = TrainSentence    \n        cls.TestSentence = TestSentence\n        cls.TrainY = TrainY\n        cls.TestY = TestY\n\n    @classmethod\n    def UpdateModel(cls, ModelName, Model):\n        if ModelName == 'Logistic Regression':\n            cls.LogisticRegressionModel_ = Model\n        if ModelName == 'XGB Classifier':\n            cls.XGBClassifierModel_ = Model\n        if ModelName == 'Naive Bayes Classifier':\n            cls.NaiveBayesClassifier_ = Model\n        if ModelName == 'Neural Network':\n            cls.NeuralNetworkModel_ = Model\n\n    @classmethod\n    def UpdateVectorizer(cls, Vectorizer):\n        cls.Vectorizer_ = Vectorizer\n\n    @classmethod\n    def UpdateLabelMapping(cls, LabelDict):\n        cls.LabelMapping_ = LabelDict\n\n    # Reading CSV\n    def ReadingData(self):\n        return pd.read_csv(TwitterCyberBullying.DataFrameDirectory)\n\n    # Data Shape\n    def KnowingShape(self):\n        Rows = self.ReadingData().shape[0]\n        Cols = self.ReadingData().shape[1]\n\n        print(f'Total Rows: {Rows}')\n        print(f'Total Cols: {Cols}') \n\n        pass \n    \n    # Label Counter\n    def LabelUnique(self):\n        Label = self.ReadingData()[TwitterCyberBullying.LabelColumns]\n        return Counter(Label)\n\n    # Parsing Lable\n    def ParsingLable(self):\n\n        Label = []\n        Values = []\n\n        for i in self.LabelUnique().keys():\n            Label.append(i)\n\n        for i in self.LabelUnique().values():\n            Values.append(i)\n\n        return Label, Values\n\n    # Bar Update Figure\n    def BarUpdateFigure(self, Fig, Title):\n        return Fig['layout'].update(\n#                              height=300, \n#                              width=500,\n                             showlegend=False,\n                             uniformtext_minsize=12,\n                             uniformtext_mode='hide',\n                             title=Title,\n#                              plot_bgcolor='rgba(0,0,0,0)',\n#                              paper_bgcolor='rgba(0,0,0,0)',\n                             legend_title= ' ',\n                             font=dict(\n                                       family=\"Old Standard TT, serif'\",\n                                       size=12,\n                                       color=\"black\"))\n\n    # Baru Update Trace\n    def BarUpdateTrace(self, Fig):\n        Fig.for_each_xaxis(lambda axis: axis.title.update(font=dict(size=3)))\n        Fig.for_each_yaxis(lambda axis: axis.title.update(font=dict(size=3)))\n        \n        # Fig.update_layout(yaxis_range=[-5,180])\n\n        Fig.update_xaxes(showgrid=False)\n        Fig.update_yaxes(showgrid=False)\n\n        pass\n\n    # Pie Update Trace\n    def PieUpdateTrace(self, Fig):\n        return Fig.update_traces(textposition='inside')\n\n    # Pie Update Figure\n    def PieUpdateFigure(self, Fig, Title, Legend):\n        return Fig.update_layout(uniformtext_minsize = 12, \n                                 uniformtext_mode = 'hide',\n#                                  height = 300, \n#                                  width = 500, \n                                 title = Title,\n#                                  plot_bgcolor = 'rgba(0,0,0,0)',\n#                                  paper_bgcolor = 'rgba(0,0,0,0)',\n                                 font=dict(family = \"Old Standard TT, serif'\",\n                                           size = 12,\n                                           color = \"black\"),\n                                 legend_title = Legend)\n\n    # Pie Label Distribution\n    def DisplayPieChartLabel(self):\n        Label, Values = self.ParsingLable()\n        fig = go.Figure(data=[go.Pie(labels=Label, values=Values)])\n\n        self.PieUpdateTrace(fig)\n        self.PieUpdateFigure(fig, 'Label Distribution', 'Label:')\n\n        return fig.show()\n\n    # Getting Twitter in a List\n    def GetListOfAllTweet(self):\n        AllTweet = self.ReadingData()[TwitterCyberBullying.TweetColumns]\n        AllTweet = AllTweet.tolist()\n\n        return AllTweet\n\n    # Get Username\n    def GetAttribute(self, String):\n\n        Attribute = []\n        for i in self.GetListOfAllTweet():\n            Text = i.split()\n            for j in Text:\n                if j.startswith(String):\n                    Attribute.append(j)\n                                    \n        return Attribute\n\n    # Username Counter\n    def UsernameCounter(self):\n        return Counter(self.GetAttribute('@'))\n\n    # Hastag Counter\n    def HashtagCounter(self):\n        return Counter(self.GetAttribute('#'))\n\n    # Parsing Username Count\n    def ParsingUsernameCount(self):\n\n        Label = []\n        Values = []\n\n        for i in self.UsernameCounter().keys():\n            Label.append(i)\n\n        for i in self.UsernameCounter().values():\n            Values.append(i)\n\n        return Label, Values        \n\n    # Parsing Hashtaf Count\n    def ParsingHashTagCount(self):\n\n        Label = []\n        Values = []\n\n        for i in self.HashtagCounter().keys():\n            Label.append(i)\n\n        for i in self.HashtagCounter().values():\n            Values.append(i)\n\n        return Label, Values                \n\n    # Creating Dataframe From List\n    def DataFrameFromList(self, List, ColumnsName):\n        return pd.DataFrame(List, index = ColumnsName).T\n\n    # Dataframe Contain Username and Count\n    def CountUsernameDataFrame(self):\n        Label, Values = self.ParsingUsernameCount()\n        DataFrame = self.DataFrameFromList([Label, Values], ['Username', 'Count'])\n        DataFrame = DataFrame.sort_values(by='Count', ascending=False)\n\n        return DataFrame\n\n    # Dataframe Contain Username and Count\n    def CountHastagDataframe(self):\n        Label, Values = self.ParsingHashTagCount()\n        DataFrame = self.DataFrameFromList([Label, Values], ['Hashtag', 'Count'])\n        DataFrame = DataFrame.sort_values(by='Count', ascending=False)\n\n        return DataFrame\n\n    # X conversion for single columns clustering\n    def ArrayForCluster(self, XValues):\n        X = np.array(XValues)\n        X = X.reshape(-1,1)\n        return X\n\n    # Within Cluster Sum of Square searching\n    def ClusterSearching(self, Values):\n\n        WithinClusterSumOfSquare = []\n\n        for i in range(1,10):\n            KMeans_ = KMeans(i)\n            KMeans_.fit(Values)\n            WCSSIter = KMeans_.inertia_\n            WithinClusterSumOfSquare.append(WCSSIter)   \n\n        return WithinClusterSumOfSquare     \n\n    # Plot elblow for optimal number of cluster username count\n    def ElbowClusterUsernameCount(self):\n        Values = self.ClusterSearching(self.ArrayForCluster(self.CountUsernameDataFrame()['Count']))\n        ClusterNumber = range(1,10)\n        plt.plot(ClusterNumber,Values)\n        plt.title('Elbow Cluster of Username Count')\n        plt.xlabel('Number of Clusters')\n        plt.ylabel('WCSS')\n\n        return plt.plot()\n\n    # Plot elblow for optimal number of cluster hastag count\n    def ElbowClusterHashtagCount(self):\n        Values = self.ClusterSearching(self.ArrayForCluster(self.CountHastagDataframe()['Count']))\n        ClusterNumber = range(1,10)\n        plt.plot(ClusterNumber,Values)\n        plt.title('Elbow Cluster of Hashtag Count')\n        plt.xlabel('Number of Clusters')\n        plt.ylabel('WCSS')\n\n        return plt.plot()\n\n    # K Means Initiator\n    def KMeansInitiator(self, NumberOfCluster, Values):\n        KMeans_ = KMeans(NumberOfCluster)\n        KMeans_.fit(Values)\n\n        return KMeans_\n\n    # Clustering Username Count\n    def CountUsernameDataFrameWithCluster(self):\n        Dataframe = self.CountUsernameDataFrame()\n        Values = self.ArrayForCluster(Dataframe['Count'])\n\n        Dataframe['Cluster'] = self.KMeansInitiator(4, Values).predict(Values)\n\n        return Dataframe\n\n    # Clustering Hashtag Count\n    def CountHashtagDataFrameWithCluster(self):\n        Dataframe = self.CountHastagDataframe()\n        Values = self.ArrayForCluster(Dataframe['Count'])\n\n        Dataframe['Cluster'] = self.KMeansInitiator(2, Values).predict(Values)\n\n        return Dataframe\n\n    # Username Count Cluster Counter\n    def UsernameCountClusterCounter(self):\n        return Counter(self.CountUsernameDataFrameWithCluster()['Cluster'])\n\n    # Hashtag Count Cluster Counter\n    def HashtagCountClusterCounter(self):\n        return Counter(self.CountHashtagDataFrameWithCluster()['Cluster'])\n\n    # Parsing Username Cluster\n    def ParsingUsernameCluster(self):\n\n        Label = []\n        Values = []\n\n        for i in self.UsernameCountClusterCounter().keys():\n            Label.append(i)\n\n        for i in self.UsernameCountClusterCounter().values():\n            Values.append(i)\n\n        return Label, Values             \n\n    # Pie Username Cluster Distribution\n    def DisplayPieUsernameCluster(self):\n        Label, Values = self.ParsingUsernameCluster()\n        fig = go.Figure(data=[go.Pie(labels=Label, values=Values)])\n\n        # self.PieUpdateTrace(fig)\n        self.PieUpdateFigure(fig, 'Cluster from Username Count Distribution', 'Cluster Count:')\n\n        return fig.show()\n\n    # Top 10 Username Barchart\n    def Top10UsernameBar(self):\n        DataFrame = self.CountUsernameDataFrame().head(10)\n        Label = DataFrame['Username'].tolist()\n        Values = DataFrame['Count'].tolist()\n\n        fig = go.Figure(data=[go.Bar(x=Label, y=Values)])\n\n        self.BarUpdateFigure(fig, 'Top 10 Username Appears in Tweet')\n        self.BarUpdateTrace(fig)\n\n        return fig.show()        \n\n    # Top 10 Hashtag Barchart\n    def Top10Hashtag(self):\n        DataFrame = self.CountHastagDataframe().head(10)\n        Label = DataFrame['Hashtag'].tolist()\n        Values = DataFrame['Count'].tolist()\n\n        fig = go.Figure(data=[go.Bar(x=Label, y=Values)])\n\n        self.BarUpdateFigure(fig, 'Top 10 Hashtag Appears in Tweet')\n        self.BarUpdateTrace(fig)\n\n        return fig.show()                \n\n    # Select Rows by Label\n    def SlicedDataFrame(self, Class):\n        DataFrame = self.ReadingData()\n        DataFrame = DataFrame.loc[DataFrame[TwitterCyberBullying.LabelColumns] == Class]        \n        return DataFrame\n\n    # Finding Characters\n    def SplitCountEmoji(self, Text):\n        \n        EmojiList = []\n        data = regex.findall(r'\\X', Text)\n        for word in data:\n            if any(char in emoji.UNICODE_EMOJI['en'] for char in word):\n                EmojiList.append(word)\n        \n        return EmojiList\n\n    # Finding Emoji\n    def FindingEmoji(self):\n\n        Emoji = []\n\n        for i in self.GetListOfAllTweet():\n\n            Emot = self.SplitCountEmoji(i)\n\n            if Emot:\n            \n                Emoji.append(Emot)\n\n        return list(itertools.chain.from_iterable(Emoji))\n\n    # Counter of Emoji\n    def EmojiCounter(self):\n        return Counter(self.FindingEmoji())\n\n    # Parsing Emoji\n    def ParsingEmoji(self):\n\n        Label = []\n        Values = []\n\n        for i in self.EmojiCounter().keys():\n            Label.append(i)\n\n        for i in self.EmojiCounter().values():\n            Values.append(i)\n\n        return Label, Values                     \n\n    # Pie Emoji Distribution\n    def DisplayPieChartEmoji(self):\n        Label, Values = self.ParsingEmoji()\n        fig = go.Figure(data=[go.Pie(labels=Label, values=Values)])\n\n        self.PieUpdateTrace(fig)\n        self.PieUpdateFigure(fig, 'Emoji Distribution', 'Emoji:')\n\n        return fig.show()\n\n    # Count Characters\n    def CountTweetCharacters(self):\n        DataFrame = self.ReadingData()\n        TweetList = DataFrame[TwitterCyberBullying.TweetColumns].to_list()\n\n        CountList = []\n\n        for i in TweetList:\n            Count = len(re.findall(r'\\w+', i))\n            CountList.append(Count)\n\n        return CountList\n\n    # Wrapping Dataframe With Characters Count\n    def DataframeWithCharactersCount(self):\n        DataFrame = self.ReadingData()\n        DataFrame['Count'] = self.CountTweetCharacters()\n\n        return DataFrame\n\n    # This will aggregate 2 colums\n    def CharactersCustomAggregation(self, Method):\n\n        custom_aggregation = {}\n        custom_aggregation['Count'] = Method\n        df = self.DataframeWithCharactersCount().groupby(TwitterCyberBullying.LabelColumns).agg(custom_aggregation)\n        df.columns = ['Count']\n        df[TwitterCyberBullying.LabelColumns] = df.index    \n        df.reset_index(drop=True, inplace=True)\n        df = df.sort_values(by='Count', ascending=False)\n        return df\n\n    # Characters Method Barplot\n    def CharactersBarCustom(self, Method):\n        DataFrame = self.CharactersCustomAggregation(Method)\n        Label = DataFrame[TwitterCyberBullying.LabelColumns].tolist()\n        Values = DataFrame['Count'].tolist()\n\n        fig = go.Figure(data=[go.Bar(x=Label, y=Values)])\n\n        self.BarUpdateFigure(fig, f'Characters {Method} on Tweet Based on Label')\n        self.BarUpdateTrace(fig)\n\n        return fig.show()                \n\n    # Checking AfinScore\n    def ApplyAfinScore(self):\n\n        DataFrame = self.ReadingData()\n\n        TweetList = DataFrame[TwitterCyberBullying.TweetColumns].to_list()\n\n        AfinScore = []\n\n        for i in TweetList:\n            AfinScore.append(afinn.score(i))\n\n        DataFrame['Afin Sentence Score'] = AfinScore\n        DataFrame = DataFrame.sort_values(by='Afin Sentence Score', ascending= True)\n\n        return DataFrame\n\n    # Apply Histogram For Afin Score\n    def AfinScoreHistogram(self):\n\n        fig = px.histogram(self.ApplyAfinScore(), \n                           x=\"Afin Sentence Score\", \n                           color = 'cyberbullying_type', \n                           opacity=0.5,\n                           title=\"Afin Score Histogram Based on Label\")\n\n        fig.update_layout(xaxis=dict(range=[-30, 10]))\n\n        return fig.show()\n\n    # Check Most Toxic Tweet\n    def Check2MostToxicTweet(self, Class):\n\n        DataFrame = self.ApplyAfinScore()\n        DataFrame = DataFrame.loc[DataFrame['cyberbullying_type'] == Class]\n        Tweet = DataFrame['tweet_text'].head(2).tolist()\n\n        Count = 0\n        for i in Tweet:\n\n            Count += 1\n\n            print(f'Number {Count} Toxic Tweet by {Class} is: {i}')\n            print('')\n\n        pass\n    \n    # Opening Boundary Wordcloud using PIL\n    def OpeningBoundaryWordCloud(self):\n        return np.array(Image.open(TwitterCyberBullying.BoundaryWordCloud))\n\n    # Initiate WordCloud\n    def WordCloudInitiator(self, Text):\n\n        wc = WordCloud(background_color=\"white\", \n#                        mask= self.OpeningBoundaryWordCloud(),\n                       max_words=100, \n                       contour_width=0, \n                       contour_color='firebrick')\n\n\n        return wc.generate(Text)\n\n    # Visualize WordCloud\n    def VisualizeWordCloud(self, Class):\n\n        DataFrame = self.SlicedDataFrame(Class)\n        Tweet = \" \".join(review for review in DataFrame.tweet_text)\n\n        plt.figure(figsize=[10,100])\n        plt.imshow(self.WordCloudInitiator(Tweet), interpolation='bilinear')\n        plt.axis(\"off\")\n\n        return plt.show()        \n\n    # Can Remove # @ http    \n    def RemovingWordWithSpecialChar(self, DataFrame, StatrsWith):\n\n        Tweet = DataFrame[TwitterCyberBullying.TweetColumns].tolist()\n\n        Count = 0\n        CleanedTweet = []\n        for i in Tweet:\n            Text = i.split()\n\n            Char = []\n            for j in Text:\n\n                if j.startswith(StatrsWith):\n                    Count += 1\n                    pass\n                else:\n                    Char.append(j)\n\n            Char = ' '.join(str(e) for e in Char)\n            CleanedTweet.append(Char)\n        \n        print(f'Removing {StatrsWith} Total : {Count}')\n        DataFrame[TwitterCyberBullying.TweetColumns] = CleanedTweet\n\n        return DataFrame\n\n    # Lower case all the word\n    def LowerCasingTweet(self, DataFrame):\n\n        Tweet = DataFrame[TwitterCyberBullying.TweetColumns].tolist()\n\n        CleanedTweet = []\n        for i in Tweet:\n            Text = i.split()\n\n            Char = []\n            for j in Text:\n                \n                Char.append(j.lower())\n\n            Char = ' '.join(str(e) for e in Char)\n            CleanedTweet.append(Char)\n                        \n        DataFrame[TwitterCyberBullying.TweetColumns] = CleanedTweet\n\n        return DataFrame\n\n    # Remove New Line Characters\n    def RemovingNewLineCharacters(self, DataFrame):\n\n        Tweet = DataFrame[TwitterCyberBullying.TweetColumns].tolist()\n\n        CleanedTweet = []\n\n        for i in Tweet:\n            CleanedTweet.append(i.strip())\n\n        DataFrame[TwitterCyberBullying.TweetColumns] = CleanedTweet\n\n        return DataFrame\n\n    # Preprocessing Data\n    def PreProcessing(self):\n        DataFrame = self.ReadingData()\n        DataFrame = self.RemovingWordWithSpecialChar(DataFrame, '@')\n        DataFrame = self.RemovingWordWithSpecialChar(DataFrame, '#')\n        DataFrame = self.RemovingWordWithSpecialChar(DataFrame, 'http')        \n        DataFrame = self.RemovingNewLineCharacters(DataFrame)\n        DataFrame = self.LowerCasingTweet(DataFrame)             \n\n        return DataFrame   \n\n    # Label Encoding\n    def LabelEncoding(self):\n        DataFrame = self.PreProcessing()\n        LabelEncoder_ = LabelEncoder()\n\n        DataFrame[TwitterCyberBullying.LabelColumnsEncoded] = LabelEncoder_.fit_transform(DataFrame[TwitterCyberBullying.LabelColumns])\n\n        LabelEncoder_.fit(DataFrame[TwitterCyberBullying.LabelColumns])\n        LabelMapping = dict(zip(LabelEncoder_.classes_, LabelEncoder_.transform(LabelEncoder_.classes_)))\n\n        self.UpdateLabelMapping(LabelMapping)\n\n        return DataFrame\n\n    # Splitting\n    def TrainTestSplitting(self):\n        DataFrame = self.LabelEncoding()\n        Sentence = DataFrame[TwitterCyberBullying.TweetColumns].values\n        Y = DataFrame[TwitterCyberBullying.LabelColumnsEncoded].values\n\n        TrainSentence, TestSentence, TrainY, TestY = train_test_split(Sentence, Y, test_size=0.25, random_state=1000)\n\n        return TrainSentence, TestSentence, TrainY, TestY\n\n    # Vectorizing\n    def Vectorizer(self):\n\n        TrainSentence, TestSentence, TrainY, TestY = self.TrainTestSplitting()\n\n        Vectorizer_ = CountVectorizer()\n        Vectorizer_.fit(TrainSentence)\n\n        TrainSentence = Vectorizer_.transform(TrainSentence)\n        TestSentence  = Vectorizer_.transform(TestSentence)    \n\n        self.UpdateVariableVectorized(TrainSentence, TestSentence, TrainY, TestY)\n        self.UpdateVectorizer(Vectorizer_)\n\n        pass\n    \n    # Calculate Metrics\n    def ModelEvaluation(self, YTrue, YTest):\n        Accuracy = accuracy_score(YTrue, YTest)\n        Precision = precision_score(YTrue, YTest, average='weighted')     \n        Recal = recall_score(YTrue, YTest, average='weighted')     \n        F1Score = f1_score(YTrue, YTest, average='weighted')\n\n        return Accuracy, Precision, Recal, F1Score\n\n    # Logistic Regression Model\n    def LogisticRegressionModel(self):\n\n        Model = LogisticRegression(max_iter=1000)\n        Model.fit(TwitterCyberBullying.TrainSenctence, TwitterCyberBullying.TrainY)\n        YPred = Model.predict(TwitterCyberBullying.TestSentence)\n\n        Accuracy, Precision, Recal, F1Score = self.ModelEvaluation(TwitterCyberBullying.TestY, YPred)\n\n        self.UpdateModel('Logistic Regression', Model)\n\n        return Accuracy, Precision, Recal, F1Score\n\n    # XGB Classifier Model\n    def XGBClassifierModel(self):\n\n        Model = XGBClassifier()\n        Model.fit(TwitterCyberBullying.TrainSenctence, TwitterCyberBullying.TrainY)\n        YPred = Model.predict(TwitterCyberBullying.TestSentence)\n\n        Accuracy, Precision, Recal, F1Score = self.ModelEvaluation(TwitterCyberBullying.TestY, YPred)\n\n        self.UpdateModel('XGB Classifier', Model)\n\n        return Accuracy, Precision, Recal, F1Score\n\n    # Naive Bayes Classifier Model\n    def NaiveBayesClassifier(self):\n\n        Model = MultinomialNB()\n        Model.fit(TwitterCyberBullying.TrainSenctence, TwitterCyberBullying.TrainY)\n        YPred = Model.predict(TwitterCyberBullying.TestSentence)\n\n        Accuracy, Precision, Recal, F1Score = self.ModelEvaluation(TwitterCyberBullying.TestY, YPred)\n\n        self.UpdateModel('Naive Bayes Classifier', Model)\n\n        return Accuracy, Precision, Recal, F1Score    \n\n    # https:\/\/realpython.com\/python-keras-text-classification\/\n    # History Plotting\n    def HistoryPlotting(self, history):\n\n        acc = history.history['accuracy']\n        val_acc = history.history['val_accuracy']\n        loss = history.history['loss']\n        val_loss = history.history['val_loss']\n        x = range(1, len(acc) + 1)\n\n        plt.figure(figsize=(12, 5))\n        plt.subplot(1, 2, 1)\n        plt.plot(x, acc, 'b', label='Training acc')\n        plt.plot(x, val_acc, 'r', label='Validation acc')\n        plt.title('Training and validation accuracy')\n        plt.legend()\n        plt.subplot(1, 2, 2)\n        plt.plot(x, loss, 'b', label='Training loss')\n        plt.plot(x, val_loss, 'r', label='Validation loss')\n        plt.title('Training and validation loss')\n        plt.legend()        \n\n    # Number of Lable\n    def CheckNumberOfLable(self):\n        return int(len(self.LabelUnique().keys()))\n\n    # Multilable Additional Step for Neural Network\n    def TrainOneHot(self, Data):\n\n        Data = tensorflow.one_hot(Data, depth=self.CheckNumberOfLable())      \n\n        return Data\n\n    # Simple Neural Network Model\n    def NeuralNetworkModel(self):\n\n        TrainY = self.TrainOneHot(TwitterCyberBullying.TrainY)\n        TestY = self.TrainOneHot(TwitterCyberBullying.TestY)\n\n        InputDimention = TwitterCyberBullying.TrainSenctence.shape[1]\n\n        clear_session()\n\n        model = Sequential()\n        model.add(layers.Dense(5, input_dim=InputDimention, activation='relu'))\n        model.add(layers.Dense(self.CheckNumberOfLable(), activation='sigmoid'))   \n\n        model.compile(loss='binary_crossentropy', \n                      optimizer='adam', \n                      metrics=['accuracy'])\n        \n        model.summary()             \n\n        history = model.fit(TwitterCyberBullying.TrainSenctence, TrainY,\n                            epochs=10,\n                            verbose=1,\n                            validation_data=(TwitterCyberBullying.TestSentence, TestY),\n                            batch_size=10)      \n\n        self.HistoryPlotting(history)\n\n        YPred = model.predict(TwitterCyberBullying.TestSentence)\n        YPred = YPred.round()\n\n        Accuracy, Precision, Recal, F1Score = self.ModelEvaluation(TestY, YPred)\n\n        self.UpdateModel('Neural Network', model)        \n\n        return Accuracy, Precision, Recal, F1Score            \n\n    # Model Pipeline\n    def ModelPipeline(self):\n\n        self.Vectorizer()\n\n        LogisticRegressionAccuracy, LogisticRegressionPrecision, LogisticRegressionRecal, LogisticRegressionF1Score = self.LogisticRegressionModel()\n        XGBClassifierAccuracy, XGBClassifierPrecision, XGBClassifierRecal, XGBClassifierF1Score = self.XGBClassifierModel()\n        NaiveBayesAccuracy,  NaiveBayesPrecision,  NaiveBayesRecal,  NaiveBayesF1Score = self.NaiveBayesClassifier()\n        NeuralNetworkAccuracy,  NeuralNetworkPrecision,  NeuralNetworkRecal,  NeuralNetworkF1Score = self.NeuralNetworkModel()\n        \n        Evaluation = {'Model':['Logistic Regression', 'XGB Classifier', 'Naive Bayes Classifier', 'Neural Network'], \n                      'Accuracy':[LogisticRegressionAccuracy, XGBClassifierAccuracy, NaiveBayesAccuracy, NeuralNetworkAccuracy],\n                      'Precision':[LogisticRegressionPrecision, XGBClassifierPrecision, NaiveBayesPrecision, NeuralNetworkPrecision],\n                      'Recall':[LogisticRegressionRecal, XGBClassifierRecal, NaiveBayesRecal, NeuralNetworkRecal],\n                      'F1 Score':[LogisticRegressionF1Score, XGBClassifierF1Score, NaiveBayesF1Score, NeuralNetworkF1Score]                                            \n                      }                      \n                      \n        EvaluationDataFrame = pd.DataFrame(Evaluation)  \n\n        return EvaluationDataFrame\n\n    # Evaluation Visualization\n    def EvalVisualization(self, DataFrame, Metrics):\n\n        Label = DataFrame['Model'].tolist()\n        Values = DataFrame[Metrics].tolist()\n\n        fig = go.Figure(data=[go.Bar(x=Label, y=Values)])\n\n        self.BarUpdateFigure(fig, f'Model Performance on Testing Data Based on {Metrics}')\n        self.BarUpdateTrace(fig)\n        fig.update_layout(yaxis_range=[0,1])\n\n        return fig.show()                        \n\n    # Check Predict Label\n    def CheckPredictLabel(self, Predict):\n        return (list(tools.LabelMapping_.keys())[list(tools.LabelMapping_.values()).index(Predict)]) \n\n    # Predict New Tweet\n    def PredictTweet(self, Model, Sentence):\n        Tweet = np.array([Sentence])\n        Tweet = TwitterCyberBullying.Vectorizer_.transform(Tweet)\n        Result = Model.predict(Tweet)\n        \n        try:\n            Predict = Result.item()\n        except:\n            Predict = np.argmax(Result)\n\n        Label = self.CheckPredictLabel(int(Predict))\n\n        print(f'This Tweet:\\n{Sentence}\\nPredicted as {Label} tweet')\n\n        pass","409ae723":"tools = TwitterCyberBullying()","c72c46b4":"tools.ReadingData()","360653bc":"tools.KnowingShape()","a9cb8e82":"tools.LabelUnique()","f315bfd4":"tools.DisplayPieChartLabel()","2fce9854":"tools.CountUsernameDataFrame()","9c16c05d":"tools.ElbowClusterUsernameCount()","e08a16a1":"tools.CountUsernameDataFrameWithCluster()","95754e2d":"tools.UsernameCountClusterCounter()","637001cc":"tools.DisplayPieUsernameCluster()","7a840a1f":"tools.Top10UsernameBar()","06a78d5b":"tools.CountHastagDataframe()","ca507d08":"tools.ElbowClusterHashtagCount()","eb8a0d5d":"tools.CountHashtagDataFrameWithCluster()","48a0034d":"tools.HashtagCountClusterCounter()","7aede8a6":"tools.Top10Hashtag()","dc160408":"tools.EmojiCounter()","a4ce1cfb":"tools.DisplayPieChartEmoji()","1e841ab5":"tools.DataframeWithCharactersCount()","e32b2eb0":"tools.CharactersBarCustom('sum')","8a045691":"tools.CharactersBarCustom('max')","69e8a181":"tools.CharactersBarCustom('min')","e3f2c44f":"tools.ApplyAfinScore()","bca660af":"tools.AfinScoreHistogram()","783a13a9":"tools.Check2MostToxicTweet('ethnicity')","bdb8b6c5":"tools.Check2MostToxicTweet('other_cyberbullying')","9d591d38":"tools.Check2MostToxicTweet('gender')","4a667e98":"tools.Check2MostToxicTweet('age')","ff42824e":"tools.Check2MostToxicTweet('religion')","1f994c52":"tools.Check2MostToxicTweet('not_cyberbullying')","a6a3566a":"tools.VisualizeWordCloud('ethnicity')","6c2e3fe1":"tools.VisualizeWordCloud('other_cyberbullying')","f462c0fd":"tools.VisualizeWordCloud('gender')","80d671ce":"tools.VisualizeWordCloud('age')","84b57f5f":"tools.VisualizeWordCloud('religion')","4aadb5c6":"tools.VisualizeWordCloud('not_cyberbullying')","9803cf02":"tools.LabelEncoding()","4466c069":"tools.LabelMapping_","8110a3a6":"tools.Vectorizer()","a57dd8fd":"tools.TrainSenctence","3d015e7f":"tools.TestSentence","e7b2d1db":"tools.TrainY","4d29e96f":"tools.TestY","fd9f076a":"Eval = tools.ModelPipeline()","74151ce7":"Eval","081c9009":"tools.LogisticRegressionModel_","2848f188":"tools.XGBClassifierModel_","ac43216b":"tools.NaiveBayesClassifier_","a420a7fd":"tools.NeuralNetworkModel_","df837831":"tools.EvalVisualization(Eval, 'Accuracy')","e042b82c":"tools.EvalVisualization(Eval, 'Precision')","54be2eac":"tools.EvalVisualization(Eval, 'Recall')","8f40069e":"tools.EvalVisualization(Eval, 'F1 Score')","804de4e6":"Sentence = 'Lets not spread bullying all over the world!'","e2e0c5c7":"tools.PredictTweet(tools.XGBClassifierModel_, Sentence)","554ae981":"tools.PredictTweet(tools.LogisticRegressionModel_, Sentence)","7b5fd6b3":"tools.PredictTweet(tools.NaiveBayesClassifier_, Sentence)","ff0fcfab":"tools.PredictTweet(tools.NeuralNetworkModel_, Sentence)","6e0b93fb":"# **About This Dataset**\n> With rise of social media coupled with the Covid-19 pandemic, cyberbullying has reached all time highs. We can combat this by creating models to automatically flag potentially harmful tweets as well as break down the patterns of hatred.\n\n> As social media usage becomes increasingly prevalent in every age group, a vast majority of citizens rely on this essential medium for day-to-day communication. Social media\u2019s ubiquity means that cyberbullying can effectively impact anyone at any time or anywhere, and the relative anonymity\n> of the internet makes such personal attacks more difficult to stop than traditional bullying.\n\n> On April 15th, 2020, UNICEF issued a warning in response to the increased risk of cyberbullying during the COVID-19 pandemic due to widespread school closures, increased screen time, and decreased face-to-face social interaction. The statistics of cyberbullying are outright alarming: 36.5% of middle and high school students have felt cyberbullied and 87% have observed cyberbullying, with effects ranging from decreased academic performance to depression to suicidal thoughts.\n\n> In light of all of this, this dataset contains more than 47000 tweets labelled according to the class of cyberbullying: Age, Ethnicity, Gender, Religion, Other type of cyberbullying, Not cyberbullying. The data has been balanced in order to contain ~8000 of each class.\n\n> Trigger Warning These tweets either describe a bullying event or are the offense themselves, therefore explore it to the point where you feel comfortable.\n\n# **Task**\n1. Create a multiclassification model to predict cyberbullying type;\n2. Create a binary classification model to flag potentially harmful tweets;\n3. Explore words and patterns associated with each type of cyberbullying.","01dd95ed":"# **Can We Measure 'Toxicness' in Every Tweet?**","63ee5cd3":"# **Conclusion**","829f89b3":"I removed words starts with @, #, and also http. It means will removed username, hashtag, and also linked that attached in tweet.","15028e28":"# **How Our Model Perform on Testing Data?**","2360c0fc":"Username which most appears in every tweet in our data is @tayyoung_ with 480 times. I try to make cluster based on number of username count. Based on elbow clustering method we can see that number of count supposed to clustered in 4 cluster. Cluster 1 is cluster with most frequently appears and only 1 username belongs to that cluster.","be370d5b":"Yes, one method that we can use is using Afinn Score. Afinn is the simplest yet popular lexicons used for sentiment analysis developed by Finn \u00c5rup Nielsen. It contains 3300+ words with a polarity score associated with each word. In python, there is an in-built function for this lexicon. Low Afinn score indicated that it was a bad tweet, meanwhile more positive means good tweet.","186b6358":"# **Model Pipeline**","9e2e6704":"# **What is Most Toxic Tweet in Each Label?**","f7f66d5a":"Most dominating emoji is Laugh Emoji (8.3% in our data).","435746b8":"# **Data Preprocessing & Label Encoding**","c9380772":"# **What is Most Frequently Words Appears on Tweet?**","93026c11":"# **How This Data Looks Like?**","82f4a070":"Please keep your word on social media. Let's stop this bullying chain. We don't know whether the person we are bullying is mentally strong or not right? Thank you for visiting my Notebook, don't forget to upvote :)!","47bc82be":"For model pipeline i used Logistic Regression, XGB Classifier, Naive Bayes Classifier, and Neural Network. After testing on test data, XGB Classifier seems have good performace (Accuracy, Precision, Recall and F1 Score) compared to other algorithm.","ecee8d6e":"# **Defining Class**","de288a69":"# **What is Most Frequently Appears Hashtag? Can We Clustered Them?**","ba38d3ad":"# **How About The Tweet Characters Length?**","d7c53120":"# **What is Most Frequently Appears Username? Can We Clustered Them?**","044c5587":"# **Train Test Splitting & Vectorizing**","356159b5":"In order to proceed text data into modelling, after cleansing we need to do vectorizing.\n\n![](https:\/\/www.oreilly.com\/library\/view\/applied-text-analysis\/9781491963036\/assets\/atap_0408.png)","e48d3b23":"Based on clustering, we can see that hashtag supposed to clustered to 2 cluster. Most dominating hastag is MKR.","2c677162":"# **How About Label Distribution?**","56efad06":"![](https:\/\/www.u-tokyo.ac.jp\/content\/400141878.png)","18c8caeb":"# **Model Blind Test**","28474e2b":"This data consist 47692 rows, and 2 columns where cyberbullying_type columns is our target columns.","8134c057":"# **Can We Find Emojis in Every Tweet?**","0dd4fc88":"# **Import Package**","d5c73a9c":"Target variable consist 6 class which is: not_cyberbullying, gender, religion, other_cyberbullying, age, and ethnicity. We can see that our target variable seems to have balance composition (around 16% per class). So we dont need to do balancing."}}