{"cell_type":{"03c5cf83":"code","457233c6":"code","40bdb801":"code","46cc344b":"code","b56976c2":"code","04da25d0":"code","ebf4da8b":"code","093827c4":"code","fc7eceb9":"code","572a3fbe":"code","4d8e870c":"code","2f3c4e2b":"code","06af76a8":"code","f62f1cbb":"code","80a222ce":"code","29910117":"code","64b45922":"code","0aaf8a45":"code","da69a7a6":"code","a5a9bedd":"code","053b08f0":"code","909a1eca":"code","78bb527d":"code","b72ba3ba":"code","1b392baa":"code","47f63e85":"code","2535c226":"code","2a1a6088":"code","ed60071e":"code","d0f8ee02":"code","90183fa8":"code","d116b9f7":"code","fc57defd":"code","28e35303":"code","0d2917ce":"code","1ded9280":"code","7ececadd":"code","a14f8620":"code","1bfa965f":"code","7eca85a8":"code","67f704bc":"markdown","c7f39e55":"markdown"},"source":{"03c5cf83":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.preprocessing import StandardScaler \nfrom scipy.stats import describe\n%matplotlib inline\nimport lightgbm as lgb\nfrom sklearn.linear_model import Ridge\nimport time\nfrom sklearn import preprocessing\n\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('max_colwidth', 500)\npd.set_option('max_columns', 500)\n\nimport gc\nfrom sklearn.tree import DecisionTreeRegressor\n#from sklearn.linear_model import Ridge\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, train_test_split\n\nfrom sklearn.model_selection import RepeatedKFold \nfrom sklearn.ensemble import ExtraTreesRegressor\nimport datetime\n\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,BaggingRegressor\nfrom sklearn.pipeline import make_pipeline\n#from xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\n#from sklearn.linear_model import Lasso\n\n#from sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error \nfrom xgboost import XGBRegressor","457233c6":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","40bdb801":"nmt = reduce_mem_usage(pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/new_merchant_transactions.csv',parse_dates=['purchase_date']))\nht = reduce_mem_usage(pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/historical_transactions.csv',parse_dates=['purchase_date']))","46cc344b":"def cleaning(df):\n  scaler = StandardScaler()\n  for col in ['authorized_flag', 'category_1']:\n    df[col] = df[col].map({'Y':1, 'N':0})  \n    df[col] = df[col].apply(pd.to_numeric, errors='coerce')\n  for col in ['installments']:\n    df[col] = df[col].map({-1:14, 0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9,10:10,11:11,12:12,999:13})\n    df[col] = df[col].apply(pd.to_numeric, errors='coerce')\n  for col in ['category_3']:\n    df[col] = df[col].map({'A':1, 'B':2,'C':3})\n    df[col] = df[col].apply(pd.to_numeric, errors='coerce')\n  for col in ['category_2']:\n    df[col] = df[col].apply(pd.to_numeric, errors='coerce')   \n  for col in ['purchase_amount']:        \n    df[col] = scaler.fit_transform(df[[col]])      \n  return df\n\nht = cleaning(ht)\nnmt = cleaning(nmt)\n\nfrom datetime import datetime\n# Missing values handling\nfor df in [ht, nmt]: # Filling with most common value\n  df['category_2'].fillna(1,inplace=True)\n  df['category_3'].fillna(1,inplace=True)\n  df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\n  # Purchase date - year, month, week, hour\n  df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n  df['year'] = df['purchase_date'].dt.year\n  df['weekofyear'] = df['purchase_date'].dt.weekofyear\n  df['weekday'] = df['purchase_date'].dt.weekday\n  df['month'] = df['purchase_date'].dt.month\n  df['dayofweek'] = df['purchase_date'].dt.dayofweek\n  df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n  df['hour'] = df['purchase_date'].dt.hour  \n  df['month_diff'] = ((datetime.today() - df['purchase_date']).dt.days)\/\/30\n  df['month_diff'] += df['month_lag']\n\n  df['duration'] = df['purchase_amount']*df['month_diff']\n  df['amount_month_ratio'] = df['purchase_amount']\/df['month_diff']\n  df['price'] = df['purchase_amount'] \/ df['installments']\n\ngc.collect()\nlen(ht.columns), len(nmt.columns)","b56976c2":"from datetime import datetime\n# Here we are trying to calculate recency, frequency, monetary and age.\n# Recency is how many days back did customer perform a last transaction.\n# Frequency is how many transactions are performed in time period from dataset.\n# Monetary is how much was spent in all the transactions.\n\nhist = ht[['card_id','purchase_date','purchase_amount']]\nhist = hist.sort_values(by=['card_id', 'purchase_date'], ascending=[True, True])\nprint(hist.head())\n\nz = hist.groupby('card_id')['purchase_date'].max().reset_index()\nq = hist.groupby('card_id')['purchase_date'].min().reset_index()\n\nz.columns = ['card_id', 'Max']\nq.columns = ['card_id', 'Min']\n\n## Extracting current timestamp\nnow = datetime.now()\ncurr_date = now.strftime(\"%m-%d-%Y, %H:%M:%S\")\ncurr_date = pd.to_datetime(curr_date)\n\nrec = pd.merge(z,q,how = 'left',on = 'card_id')\nrec['Min'] = pd.to_datetime(rec['Min'])\nrec['Max'] = pd.to_datetime(rec['Max'])\n\n## Recency value \nrec['Recency'] = (curr_date - rec['Max']).astype('timedelta64[D]') ## current date - most recent date\n\n## Age value\nrec['Age'] = (rec['Max'] - rec['Min']).astype('timedelta64[D]') ## Age of customer, MAX - MIN\n\nrec = rec[['card_id','Age','Recency']]\n\n## Frequency\nfreq = hist.groupby('card_id').size().reset_index()\nfreq.columns = ['card_id', 'Frequency']\n\n## Monetary\nmon = hist.groupby('card_id')['purchase_amount'].sum().reset_index()\nmon.columns = ['card_id', 'Monetary']\n\nfinal = pd.merge(freq,mon,how = 'left', on = 'card_id')\nfinal = pd.merge(final,rec,how = 'left', on = 'card_id')\n\nfinal['AvOrderValue'] = final['Monetary']\/final['Frequency'] ## AOV - Average order value (i.e) total_purchase_amt\/total_trans\nfinal['AgeRecencyRatio'] = final['Age']\/final['Recency'] ## \nfinal = final[['card_id','AvOrderValue','AgeRecencyRatio']]\nfinal.head()","04da25d0":"def aggregate_transactions_hist(history):\n    \n    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).\\\n                                      astype(np.int64) * 1e-9\n    \n    agg_func = { \n    'purchase_date': ['max', 'min'],            \n    'merchant_category_id': ['nunique'],\n    'month': ['mean','nunique','min'],     \n    'hour': ['mean','min','max'],    \n    'weekofyear': ['mean','nunique','min','max'],     \n    'month_diff': ['mean'],     \n    'weekend': ['sum'],\n    'weekday': ['sum','mean'],   \n    'card_id': ['size','count'],\n    'category_1' : ['sum', 'mean'],   \n    'purchase_amount': ['sum', 'mean', 'max', 'min','median'],\n    'installments': ['sum', 'mean', 'max', 'min','median'],     \n    'authorized_flag': ['sum'],\n    'subsector_id': ['nunique'],\n    'month_lag': ['mean'],\n    'price' :['sum','mean','min','var'],\n    'duration' : ['mean','min','max','var','skew'],\n    'amount_month_ratio':['mean','min','max','var','skew']        \n    }\n    \n    agg_history = history.groupby(['card_id']).agg(agg_func)\n    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n    agg_history.reset_index(inplace=True)\n    \n    df = (history.groupby('card_id')\n          .size().reset_index(name='transactions_count'))\n    \n    agg_history = pd.merge(df, agg_history, on='card_id', how='left')    \n    return agg_history\n  \nhistory = aggregate_transactions_hist(ht)\nhistory.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n\nagg_func = {'mean': ['mean'], }\n\nfor col in ['category_2','category_3']:\n    history[col+'_mean'] = ht['purchase_amount'].groupby(ht[col]).agg('mean')\n    history[col+'_max'] = ht['purchase_amount'].groupby(ht[col]).agg('max')\n    history[col+'_min'] = ht['purchase_amount'].groupby(ht[col]).agg('min')\n    history[col+'_sum'] = ht['purchase_amount'].groupby(ht[col]).agg('sum')\n    agg_func[col+'_mean'] = ['mean']\n    \ngc.collect()\nlen(ht.columns), len(history.columns)","ebf4da8b":"def aggregate_transaction_new(trans):  \n        \n    agg_func = {\n        'purchase_amount' : ['sum','max','min','mean'],\n        'installments' : ['sum','max','mean'],\n        'purchase_date' : ['max','min'],\n        'month_lag' : ['mean'],\n        'month_diff' : ['mean'],\n        'weekend' : ['sum'],\n        'weekday' : ['sum', 'mean'],\n        'authorized_flag': ['sum'],\n        'category_1': ['sum','mean'],\n        'card_id' : ['size', 'count'],\n        'month': ['nunique', 'mean', 'min'],\n        'hour': ['mean', 'min', 'max'],\n        'weekofyear': ['nunique', 'mean', 'min', 'max'],       \n        'subsector_id': ['nunique'],\n        'merchant_category_id' : ['nunique'],\n        'price' :['sum','mean','min','var'],\n        'duration' : ['mean','min','max','var','skew'],\n        'amount_month_ratio':['mean','min','max','var','skew']\n    }\n    \n    agg_history = trans.groupby(['card_id']).agg(agg_func)\n    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n    agg_history.reset_index(inplace=True)\n    \n    df = (trans.groupby('card_id')\n          .size().reset_index(name='transactions_count'))\n    \n    agg_history = pd.merge(df, agg_history, on='card_id', how='left')    \n    return agg_history\n\n\nnew = aggregate_transaction_new(nmt)\nnew.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n\nagg_func = {'mean': ['mean'], }\n\nfor col in ['category_2','category_3']:\n    new[col+'_mean'] = nmt['purchase_amount'].groupby(ht[col]).agg('mean')\n    new[col+'_max'] = nmt['purchase_amount'].groupby(nmt[col]).agg('max')\n    new[col+'_min'] = nmt['purchase_amount'].groupby(nmt[col]).agg('min')\n    new[col+'_sum'] = nmt['purchase_amount'].groupby(nmt[col]).agg('sum')\n    agg_func[col+'_mean'] = ['mean']\n    \ngc.collect()\nlen(new.columns)","093827c4":"test = reduce_mem_usage(pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/test.csv'))\nprint(test.isnull().sum())\ndate_time_str = '2017-04-01'\nprint(test[test['first_active_month'].isnull() ] )\ntest.loc[11578,'first_active_month'] = date_time_str\nprint(test.isnull().sum() )\ntest['first_active_month'] = test['first_active_month'].astype('datetime64[ns]')\ntest.info()","fc7eceb9":"train = reduce_mem_usage(pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/train.csv',parse_dates=['first_active_month']))\n\n# Merge all dataframes based on card_id\ntrain = pd.merge(train, history, on='card_id', how='left')\ntest = pd.merge(test, history, on='card_id', how='left')\n\ntrain = pd.merge(train, final, on='card_id', how='left')\ntest = pd.merge(test, final, on='card_id', how='left')\n\ntrain = pd.merge(train, new, on='card_id', how='left')\ntest = pd.merge(test, new, on='card_id', how='left')\ntrain.shape, test.shape","572a3fbe":"#Feature Engineering - Adding new features inspired by Chau's first kernel\ntrain['new_purchase_date_max'] = pd.to_datetime(train['new_purchase_date_max'])\ntrain['new_purchase_date_min'] = pd.to_datetime(train['new_purchase_date_min'])\ntrain['new_purchase_date_diff'] = (train['new_purchase_date_max'] - train['new_purchase_date_min']).dt.days\ntrain['new_purchase_date_average'] = train['new_purchase_date_diff']\/train['new_card_id_size']\ntrain['new_purchase_date_uptonow'] = (datetime.today() - train['new_purchase_date_max']).dt.days\ntrain['new_purchase_date_uptomin'] = (datetime.today() - train['new_purchase_date_min']).dt.days\ntrain['new_first_buy'] = (train['new_purchase_date_min'] - train['first_active_month']).dt.days\ntrain['new_last_buy'] = (train['new_purchase_date_max'] - train['first_active_month']).dt.days\n\n\n#Feature Engineering - Adding new features inspired by Chau's first kernel\ntest['new_purchase_date_max'] = pd.to_datetime(test['new_purchase_date_max'])\ntest['new_purchase_date_min'] = pd.to_datetime(test['new_purchase_date_min'])\ntest['new_purchase_date_diff'] = (test['new_purchase_date_max'] - test['new_purchase_date_min']).dt.days\ntest['new_purchase_date_average'] = test['new_purchase_date_diff']\/test['new_card_id_size']\ntest['new_purchase_date_uptonow'] = (datetime.today() - test['new_purchase_date_max']).dt.days\ntest['new_purchase_date_uptomin'] = (datetime.today() - test['new_purchase_date_min']).dt.days\ntest['new_first_buy'] = (test['new_purchase_date_min'] - test['first_active_month']).dt.days\ntest['new_last_buy'] = (test['new_purchase_date_max'] - test['first_active_month']).dt.days\n\ngc.collect()","4d8e870c":"train['card_id_total'] = train['new_card_id_size']+train['hist_card_id_size']\ntrain['card_id_cnt_total'] = train['new_card_id_count']+train['hist_card_id_count']\ntrain['card_id_cnt_ratio'] = train['new_card_id_count']\/train['hist_card_id_count']\ntrain['purchase_amount_total'] = train['new_purchase_amount_sum']+train['hist_purchase_amount_sum']\ntrain['purchase_amount_mean'] = train['new_purchase_amount_mean']+train['hist_purchase_amount_mean']\ntrain['purchase_amount_max'] = train['new_purchase_amount_max']+train['hist_purchase_amount_max']\ntrain['purchase_amount_min'] = train['new_purchase_amount_min']+train['hist_purchase_amount_min']\ntrain['purchase_amount_ratio'] = train['new_purchase_amount_sum']\/train['hist_purchase_amount_sum']\ntrain['month_diff_mean'] = train['new_month_diff_mean']+train['hist_month_diff_mean']\ntrain['month_diff_ratio'] = train['new_month_diff_mean']\/train['hist_month_diff_mean']\ntrain['month_lag_mean'] = train['new_month_lag_mean']+train['hist_month_lag_mean']\n#train['month_lag_max'] = train['new_month_lag_max']+train['hist_month_lag_max']\n#train['month_lag_min'] = train['new_month_lag_min']+train['hist_month_lag_min']\ntrain['category_1_mean'] = train['new_category_1_mean']+train['hist_category_1_mean']\n#train['category_2_mean'] = train['new_category_2_mean']+train['hist_category_2_mean']\n#train['category_3_mean'] = train['new_category_3_mean']+train['hist_category_3_mean']\n\n\ntrain['installments_total'] = train['new_installments_sum']+train['hist_installments_sum']\ntrain['installments_mean'] = train['new_installments_mean']+train['hist_installments_mean']\ntrain['installments_max'] = train['new_installments_max']+train['hist_installments_max']\ntrain['installments_ratio'] = train['new_installments_sum']\/train['hist_installments_sum']\ntrain['price_total'] = train['purchase_amount_total'] \/ train['installments_total']\ntrain['price_mean'] = train['purchase_amount_mean'] \/ train['installments_mean']\ntrain['price_max'] = train['purchase_amount_max'] \/ train['installments_max']\ntrain['duration_mean'] = train['new_duration_mean']+train['hist_duration_mean']\ntrain['duration_min'] = train['new_duration_min']+train['hist_duration_min']\ntrain['duration_max'] = train['new_duration_max']+train['hist_duration_max']\ntrain['amount_month_ratio_mean']=train['new_amount_month_ratio_mean']+train['hist_amount_month_ratio_mean']\ntrain['amount_month_ratio_min']=train['new_amount_month_ratio_min']+train['hist_amount_month_ratio_min']\ntrain['amount_month_ratio_max']=train['new_amount_month_ratio_max']+train['hist_amount_month_ratio_max']\ntrain['new_CLV'] = train['new_card_id_count'] * train['new_purchase_amount_sum'] \/ train['new_month_diff_mean']\ntrain['hist_CLV'] = train['hist_card_id_count'] * train['hist_purchase_amount_sum'] \/ train['hist_month_diff_mean']\ntrain['CLV_ratio'] = train['new_CLV'] \/ train['hist_CLV']\n\n#test['card_id_total'] = test['new_card_id_size']+test['hist_card_id_size']\n#test['card_id_cnt_total'] = test['new_card_id_count']+test['hist_card_id_count']\n#test['card_id_cnt_ratio'] = test['new_card_id_count']\/test['hist_card_id_count']\ntest['purchase_amount_total'] = test['new_purchase_amount_sum']+test['hist_purchase_amount_sum']\ntest['purchase_amount_mean'] = test['new_purchase_amount_mean']+test['hist_purchase_amount_mean']\ntest['purchase_amount_max'] = test['new_purchase_amount_max']+test['hist_purchase_amount_max']\ntest['purchase_amount_min'] = test['new_purchase_amount_min']+test['hist_purchase_amount_min']\ntest['purchase_amount_ratio'] = test['new_purchase_amount_sum']\/test['hist_purchase_amount_sum']\ntest['month_diff_mean'] = test['new_month_diff_mean']+test['hist_month_diff_mean']\ntest['month_diff_ratio'] = test['new_month_diff_mean']\/test['hist_month_diff_mean']\ntest['month_lag_mean'] = test['new_month_lag_mean']+test['hist_month_lag_mean']\n#test['month_lag_max'] = test['new_month_lag_max']+test['hist_month_lag_max']\n#test['month_lag_min'] = test['new_month_lag_min']+test['hist_month_lag_min']\ntest['category_1_mean'] = test['new_category_1_mean']+test['hist_category_1_mean']\ntest['installments_total'] = test['new_installments_sum']+test['hist_installments_sum']\ntest['installments_mean'] = test['new_installments_mean']+test['hist_installments_mean']\ntest['installments_max'] = test['new_installments_max']+test['hist_installments_max']\ntest['installments_ratio'] = test['new_installments_sum']\/test['hist_installments_sum']\ntest['price_total'] = test['purchase_amount_total'] \/ test['installments_total']\ntest['price_mean'] = test['purchase_amount_mean'] \/ test['installments_mean']\ntest['price_max'] = test['purchase_amount_max'] \/ test['installments_max']\ntest['duration_mean'] = test['new_duration_mean']+test['hist_duration_mean']\ntest['duration_min'] = test['new_duration_min']+test['hist_duration_min']\ntest['duration_max'] = test['new_duration_max']+test['hist_duration_max']\ntest['amount_month_ratio_mean']=test['new_amount_month_ratio_mean']+test['hist_amount_month_ratio_mean']\ntest['amount_month_ratio_min']=test['new_amount_month_ratio_min']+test['hist_amount_month_ratio_min']\ntest['amount_month_ratio_max']=test['new_amount_month_ratio_max']+test['hist_amount_month_ratio_max']\ntest['new_CLV'] = test['new_card_id_count'] * test['new_purchase_amount_sum'] \/ test['new_month_diff_mean']\ntest['hist_CLV'] = test['hist_card_id_count'] * test['hist_purchase_amount_sum'] \/ test['hist_month_diff_mean']\ntest['CLV_ratio'] = test['new_CLV'] \/ test['hist_CLV']","2f3c4e2b":"print(train.shape, test.shape)\ntrain_back = train.copy()\ntest_back = test.copy()\n\ntrain = train.drop(['card_id', 'first_active_month'], axis = 1)\ntest = test.drop(['card_id', 'first_active_month'], axis = 1)\nprint(train.shape, test.shape)","06af76a8":"train[\"new_transactions_count\"].fillna(train[\"new_transactions_count\"].median(),inplace=True)\ntrain[\"new_purchase_amount_sum\"].fillna(train[\"new_purchase_amount_sum\"].median(),inplace=True)\ntrain[\"new_purchase_amount_max\"].fillna(train[\"new_purchase_amount_max\"].median(),inplace=True)\ntrain[\"new_purchase_amount_min\"].fillna(train[\"new_purchase_amount_min\"].median(),inplace=True)\ntrain[\"new_purchase_amount_mean\"].fillna(train[\"new_purchase_amount_mean\"].median(),inplace=True)\ntrain[\"new_installments_sum\"].fillna(train[\"new_installments_sum\"].median(),inplace=True)\ntrain[\"new_installments_max\"].fillna(train[\"new_installments_max\"].median(),inplace=True)\ntrain[\"new_installments_mean\"].fillna(train[\"new_installments_mean\"].median(),inplace=True)\ntrain[\"new_purchase_date_max\"].fillna(train[\"new_purchase_date_max\"].mean(),inplace=True)\ntrain[\"new_purchase_date_min\"].fillna(train[\"new_purchase_date_min\"].mean(),inplace=True)\n#train[\"new_month_lag_max\"].fillna(train[\"new_month_lag_max\"].median(),inplace=True)\n#train[\"new_month_lag_min\"].fillna(train[\"new_month_lag_min\"].median(),inplace=True)\ntrain[\"new_month_lag_mean\"].fillna(train[\"new_month_lag_mean\"].median(),inplace=True)\n#train[\"new_month_diff_max\"].fillna(train[\"new_month_diff_max\"].median(),inplace=True)\n#train[\"new_month_diff_min\"].fillna(train[\"new_month_diff_min\"].median(),inplace=True)\ntrain[\"new_month_diff_mean\"].fillna(train[\"new_month_diff_mean\"].median(),inplace=True)\ntrain[\"new_weekend_sum\"].fillna(train[\"new_weekend_sum\"].median(),inplace=True)\n#train[\"new_weekend_mean\"].fillna(train[\"new_weekend_mean\"].median(),inplace=True)\ntrain[\"new_weekday_sum\"].fillna(train[\"new_weekday_sum\"].median(),inplace=True)\ntrain[\"new_weekday_mean\"].fillna(train[\"new_weekday_mean\"].median(),inplace=True)\ntrain[\"new_authorized_flag_sum\"].fillna(train[\"new_authorized_flag_sum\"].median(),inplace=True)\n#train[\"new_authorized_flag_mean\"].fillna(train[\"new_authorized_flag_mean\"].median(),inplace=True)\ntrain[\"new_category_1_sum\"].fillna(train[\"new_category_1_sum\"].median(),inplace=True)\ntrain[\"new_category_1_mean\"].fillna(train[\"new_category_1_mean\"].median(),inplace=True)\n#train[\"new_category_1_max\"].fillna(train[\"new_category_1_max\"].median(),inplace=True)\n#train[\"new_category_1_min\"].fillna(train[\"new_category_1_min\"].median(),inplace=True)\n\ntrain[\"new_card_id_size\"].fillna(train[\"new_card_id_size\"].median(),inplace=True)\ntrain[\"new_card_id_count\"].fillna(train[\"new_card_id_count\"].median(),inplace=True)\ntrain[\"new_month_nunique\"].fillna(train[\"new_month_nunique\"].median(),inplace=True)\ntrain[\"new_month_mean\"].fillna(train[\"new_month_mean\"].median(),inplace=True)\ntrain[\"new_month_min\"].fillna(train[\"new_month_min\"].median(),inplace=True)\n#train[\"new_month_max\"].fillna(train[\"new_month_max\"].median(),inplace=True)\n#train[\"new_hour_nunique\"].fillna(train[\"new_hour_nunique\"].median(),inplace=True)\ntrain[\"new_hour_mean\"].fillna(train[\"new_hour_mean\"].median(),inplace=True)\ntrain[\"new_hour_min\"].fillna(train[\"new_hour_min\"].median(),inplace=True)\ntrain[\"new_hour_max\"].fillna(train[\"new_hour_max\"].median(),inplace=True)\n\ntrain[\"new_weekofyear_nunique\"].fillna(train[\"new_weekofyear_nunique\"].median(),inplace=True)\ntrain[\"new_weekofyear_max\"].fillna(train[\"new_weekofyear_max\"].median(),inplace=True)\ntrain[\"new_weekofyear_mean\"].fillna(train[\"new_weekofyear_mean\"].median(),inplace=True)\ntrain[\"new_weekofyear_min\"].fillna(train[\"new_weekofyear_min\"].median(),inplace=True)\n\ntrain[\"new_subsector_id_nunique\"].fillna(train[\"new_subsector_id_nunique\"].median(),inplace=True)\ntrain[\"new_merchant_category_id_nunique\"].fillna(train[\"new_merchant_category_id_nunique\"].median(),inplace=True)\n\ntrain[\"new_price_sum\"].fillna(train[\"new_price_sum\"].median(),inplace=True)\ntrain[\"new_price_min\"].fillna(train[\"new_price_min\"].median(),inplace=True)\n#train[\"new_price_max\"].fillna(train[\"new_price_max\"].median(),inplace=True)\ntrain[\"new_price_mean\"].fillna(train[\"new_price_mean\"].median(),inplace=True)\ntrain[\"new_price_var\"].fillna(train[\"new_price_var\"].median(),inplace=True)\n\ntrain[\"new_duration_mean\"].fillna(train[\"new_duration_mean\"].median(),inplace=True)\ntrain[\"new_duration_min\"].fillna(train[\"new_duration_min\"].median(),inplace=True)\ntrain[\"new_duration_max\"].fillna(train[\"new_duration_max\"].median(),inplace=True)\ntrain[\"new_duration_var\"].fillna(train[\"new_duration_var\"].median(),inplace=True)\ntrain[\"new_duration_skew\"].fillna(train[\"new_duration_skew\"].median(),inplace=True)\n\ntrain[\"new_amount_month_ratio_mean\"].fillna(train[\"new_amount_month_ratio_mean\"].median(),inplace=True)\ntrain[\"new_amount_month_ratio_min\"].fillna(train[\"new_amount_month_ratio_min\"].median(),inplace=True)\ntrain[\"new_amount_month_ratio_max\"].fillna(train[\"new_amount_month_ratio_max\"].median(),inplace=True)\ntrain[\"new_amount_month_ratio_var\"].fillna(train[\"new_amount_month_ratio_var\"].median(),inplace=True)\ntrain[\"new_amount_month_ratio_skew\"].fillna(train[\"new_amount_month_ratio_skew\"].median(),inplace=True)\n\ntrain[\"category_1_mean\"].fillna(train[\"category_1_mean\"].median(),inplace=True)\n#train[\"category_2_mean\"].fillna(train[\"category_2_mean\"].median(),inplace=True)\n#train[\"category_3_mean\"].fillna(train[\"category_3_mean\"].median(),inplace=True)\n\ntrain[\"category_2_min_y\"].fillna(train[\"category_2_min_y\"].median(),inplace=True)\ntrain[\"category_2_mean_y\"].fillna(train[\"category_2_mean_y\"].median(),inplace=True)\ntrain[\"category_2_max_y\"].fillna(train[\"category_2_max_y\"].median(),inplace=True)\ntrain[\"category_2_sum_y\"].fillna(train[\"category_2_sum_y\"].median(),inplace=True)\n\ntrain[\"category_2_min_x\"].fillna(train[\"category_2_min_y\"].median(),inplace=True)\ntrain[\"category_2_mean_x\"].fillna(train[\"category_2_mean_y\"].median(),inplace=True)\ntrain[\"category_2_max_x\"].fillna(train[\"category_2_max_y\"].median(),inplace=True)\ntrain[\"category_2_sum_x\"].fillna(train[\"category_2_sum_y\"].median(),inplace=True)\n\ntrain[\"category_3_min_y\"].fillna(train[\"category_3_min_y\"].median(),inplace=True)\ntrain[\"category_3_mean_y\"].fillna(train[\"category_3_mean_y\"].median(),inplace=True)\ntrain[\"category_3_max_y\"].fillna(train[\"category_3_max_y\"].median(),inplace=True)\ntrain[\"category_3_sum_y\"].fillna(train[\"category_3_sum_y\"].median(),inplace=True)\n\ntrain[\"category_3_min_x\"].fillna(train[\"category_3_min_x\"].median(),inplace=True)\ntrain[\"category_3_sum_x\"].fillna(train[\"category_3_sum_x\"].median(),inplace=True)\ntrain[\"category_3_mean_x\"].fillna(train[\"category_3_mean_x\"].median(),inplace=True)\ntrain[\"category_3_max_x\"].fillna(train[\"category_3_max_x\"].median(),inplace=True)\n\ntrain[\"new_first_buy\"].fillna(train[\"new_first_buy\"].median(),inplace=True)\ntrain[\"new_last_buy\"].fillna(train[\"new_last_buy\"].median(),inplace=True)\n\ntrain[\"hist_price_mean\"].fillna(train[\"hist_price_mean\"].median(),inplace=True)\ntrain[\"hist_price_sum\"].fillna(train[\"hist_price_sum\"].median(),inplace=True)\ntrain[\"hist_price_var\"].fillna(train[\"hist_price_var\"].median(),inplace=True)\ntrain[\"hist_duration_skew\"].fillna(train[\"hist_duration_skew\"].median(),inplace=True)\ntrain[\"hist_amount_month_ratio_skew\"].fillna(train[\"hist_amount_month_ratio_skew\"].median(),inplace=True)\n\ntrain[\"price_mean\"].fillna(train[\"price_mean\"].median(),inplace=True)\ntrain[\"price_max\"].fillna(train[\"price_max\"].median(),inplace=True)\ntrain[\"price_total\"].fillna(train[\"price_total\"].median(),inplace=True)\n\ntrain[\"installments_total\"].fillna(train[\"installments_total\"].median(),inplace=True)\ntrain[\"installments_mean\"].fillna(train[\"installments_mean\"].median(),inplace=True)\ntrain[\"installments_max\"].fillna(train[\"installments_max\"].median(),inplace=True)\ntrain[\"installments_ratio\"].fillna(train[\"installments_ratio\"].median(),inplace=True)\n\ntrain[\"new_purchase_date_diff\"].fillna(train[\"new_purchase_date_diff\"].median(),inplace=True)\ntrain[\"new_purchase_date_average\"].fillna(train[\"new_purchase_date_average\"].median(),inplace=True)\ntrain[\"new_purchase_date_uptonow\"].fillna(train[\"new_purchase_date_uptonow\"].median(),inplace=True)\ntrain[\"new_purchase_date_uptomin\"].fillna(train[\"new_purchase_date_uptomin\"].median(),inplace=True)\n\ntrain[\"month_diff_mean\"].fillna(train[\"month_diff_mean\"].median(),inplace=True)\ntrain[\"month_diff_ratio\"].fillna(train[\"month_diff_ratio\"].median(),inplace=True)\n\ntrain[\"month_lag_mean\"].fillna(train[\"month_lag_mean\"].median(),inplace=True)\n#train[\"month_lag_min\"].fillna(train[\"month_lag_min\"].median(),inplace=True)\n#train[\"month_lag_max\"].fillna(train[\"month_lag_max\"].median(),inplace=True)\n\ntrain[\"card_id_total\"].fillna(train[\"card_id_total\"].median(),inplace=True)\ntrain[\"card_id_cnt_total\"].fillna(train[\"card_id_cnt_total\"].median(),inplace=True)\ntrain[\"card_id_cnt_ratio\"].fillna(train[\"card_id_cnt_ratio\"].median(),inplace=True)\n\ntrain[\"purchase_amount_total\"].fillna(train[\"purchase_amount_total\"].median(),inplace=True)\ntrain[\"purchase_amount_mean\"].fillna(train[\"purchase_amount_mean\"].median(),inplace=True)\ntrain[\"purchase_amount_max\"].fillna(train[\"purchase_amount_max\"].median(),inplace=True)\ntrain[\"purchase_amount_min\"].fillna(train[\"purchase_amount_min\"].median(),inplace=True)\ntrain[\"purchase_amount_ratio\"].fillna(train[\"purchase_amount_ratio\"].median(),inplace=True)\n\ntrain[\"duration_mean\"].fillna(train[\"duration_mean\"].median(),inplace=True)\ntrain[\"duration_min\"].fillna(train[\"duration_min\"].median(),inplace=True)\ntrain[\"duration_max\"].fillna(train[\"duration_max\"].median(),inplace=True)\n\ntrain[\"CLV_ratio\"].fillna(train[\"CLV_ratio\"].median(),inplace=True)\ntrain[\"new_CLV\"].fillna(train[\"new_CLV\"].median(),inplace=True)\n\ntrain[\"amount_month_ratio_mean\"].fillna(train[\"amount_month_ratio_mean\"].median(),inplace=True)\ntrain[\"amount_month_ratio_min\"].fillna(train[\"amount_month_ratio_min\"].median(),inplace=True)\ntrain[\"amount_month_ratio_max\"].fillna(train[\"amount_month_ratio_max\"].median(),inplace=True)","f62f1cbb":"\ntest[\"new_transactions_count\"].fillna(test[\"new_transactions_count\"].median(),inplace=True)\ntest[\"new_purchase_amount_sum\"].fillna(test[\"new_purchase_amount_sum\"].median(),inplace=True)\ntest[\"new_purchase_amount_max\"].fillna(test[\"new_purchase_amount_max\"].median(),inplace=True)\ntest[\"new_purchase_amount_min\"].fillna(test[\"new_purchase_amount_min\"].median(),inplace=True)\ntest[\"new_purchase_amount_mean\"].fillna(test[\"new_purchase_amount_mean\"].median(),inplace=True)\ntest[\"new_installments_sum\"].fillna(test[\"new_installments_sum\"].median(),inplace=True)\ntest[\"new_installments_max\"].fillna(test[\"new_installments_max\"].median(),inplace=True)\ntest[\"new_installments_mean\"].fillna(test[\"new_installments_mean\"].median(),inplace=True)\ntest[\"new_purchase_date_max\"].fillna(test[\"new_purchase_date_max\"].mean(),inplace=True)\ntest[\"new_purchase_date_min\"].fillna(test[\"new_purchase_date_min\"].mean(),inplace=True)\n#test[\"new_month_lag_max\"].fillna(test[\"new_month_lag_max\"].median(),inplace=True)\n#test[\"new_month_lag_min\"].fillna(test[\"new_month_lag_min\"].median(),inplace=True)\ntest[\"new_month_lag_mean\"].fillna(test[\"new_month_lag_mean\"].median(),inplace=True)\n#test[\"new_month_diff_max\"].fillna(test[\"new_month_diff_max\"].median(),inplace=True)\n#test[\"new_month_diff_min\"].fillna(test[\"new_month_diff_min\"].median(),inplace=True)\ntest[\"new_month_diff_mean\"].fillna(test[\"new_month_diff_mean\"].median(),inplace=True)\ntest[\"new_weekend_sum\"].fillna(test[\"new_weekend_sum\"].median(),inplace=True)\n#test[\"new_weekend_mean\"].fillna(test[\"new_weekend_mean\"].median(),inplace=True)\ntest[\"new_weekday_sum\"].fillna(test[\"new_weekday_sum\"].median(),inplace=True)\ntest[\"new_weekday_mean\"].fillna(test[\"new_weekday_mean\"].median(),inplace=True)\ntest[\"new_authorized_flag_sum\"].fillna(test[\"new_authorized_flag_sum\"].median(),inplace=True)\n#test[\"new_authorized_flag_mean\"].fillna(test[\"new_authorized_flag_mean\"].median(),inplace=True)\ntest[\"new_category_1_sum\"].fillna(test[\"new_category_1_sum\"].median(),inplace=True)\ntest[\"new_category_1_mean\"].fillna(test[\"new_category_1_mean\"].median(),inplace=True)\n#test[\"new_category_1_max\"].fillna(test[\"new_category_1_max\"].median(),inplace=True)\n#test[\"new_category_1_min\"].fillna(test[\"new_category_1_min\"].median(),inplace=True)\n\ntest[\"new_card_id_size\"].fillna(test[\"new_card_id_size\"].median(),inplace=True)\ntest[\"new_card_id_count\"].fillna(test[\"new_card_id_count\"].median(),inplace=True)\ntest[\"new_month_nunique\"].fillna(test[\"new_month_nunique\"].median(),inplace=True)\ntest[\"new_month_mean\"].fillna(test[\"new_month_mean\"].median(),inplace=True)\ntest[\"new_month_min\"].fillna(test[\"new_month_min\"].median(),inplace=True)\n#test[\"new_month_max\"].fillna(test[\"new_month_max\"].median(),inplace=True)\n#test[\"new_hour_nunique\"].fillna(test[\"new_hour_nunique\"].median(),inplace=True)\ntest[\"new_hour_mean\"].fillna(test[\"new_hour_mean\"].median(),inplace=True)\ntest[\"new_hour_min\"].fillna(test[\"new_hour_min\"].median(),inplace=True)\ntest[\"new_hour_max\"].fillna(test[\"new_hour_max\"].median(),inplace=True)\n\ntest[\"new_weekofyear_nunique\"].fillna(test[\"new_weekofyear_nunique\"].median(),inplace=True)\ntest[\"new_weekofyear_max\"].fillna(test[\"new_weekofyear_max\"].median(),inplace=True)\ntest[\"new_weekofyear_mean\"].fillna(test[\"new_weekofyear_mean\"].median(),inplace=True)\ntest[\"new_weekofyear_min\"].fillna(test[\"new_weekofyear_min\"].median(),inplace=True)\n\ntest[\"new_subsector_id_nunique\"].fillna(test[\"new_subsector_id_nunique\"].median(),inplace=True)\ntest[\"new_merchant_category_id_nunique\"].fillna(test[\"new_merchant_category_id_nunique\"].median(),inplace=True)\n\ntest[\"new_price_sum\"].fillna(test[\"new_price_sum\"].median(),inplace=True)\ntest[\"new_price_min\"].fillna(test[\"new_price_min\"].median(),inplace=True)\n#test[\"new_price_max\"].fillna(test[\"new_price_max\"].median(),inplace=True)\ntest[\"new_price_mean\"].fillna(test[\"new_price_mean\"].median(),inplace=True)\ntest[\"new_price_var\"].fillna(test[\"new_price_var\"].median(),inplace=True)\n\ntest[\"new_duration_mean\"].fillna(test[\"new_duration_mean\"].median(),inplace=True)\ntest[\"new_duration_min\"].fillna(test[\"new_duration_min\"].median(),inplace=True)\ntest[\"new_duration_max\"].fillna(test[\"new_duration_max\"].median(),inplace=True)\ntest[\"new_duration_var\"].fillna(test[\"new_duration_var\"].median(),inplace=True)\ntest[\"new_duration_skew\"].fillna(test[\"new_duration_skew\"].median(),inplace=True)\n\ntest[\"new_amount_month_ratio_mean\"].fillna(test[\"new_amount_month_ratio_mean\"].median(),inplace=True)\ntest[\"new_amount_month_ratio_min\"].fillna(test[\"new_amount_month_ratio_min\"].median(),inplace=True)\ntest[\"new_amount_month_ratio_max\"].fillna(test[\"new_amount_month_ratio_max\"].median(),inplace=True)\ntest[\"new_amount_month_ratio_var\"].fillna(test[\"new_amount_month_ratio_var\"].median(),inplace=True)\ntest[\"new_amount_month_ratio_skew\"].fillna(test[\"new_amount_month_ratio_skew\"].median(),inplace=True)\n\ntest[\"category_1_mean\"].fillna(test[\"category_1_mean\"].median(),inplace=True)\n#test[\"category_2_mean\"].fillna(test[\"category_2_mean\"].median(),inplace=True)\n#test[\"category_3_mean\"].fillna(test[\"category_3_mean\"].median(),inplace=True)\n\ntest[\"category_2_min_y\"].fillna(test[\"category_2_min_y\"].median(),inplace=True)\ntest[\"category_2_mean_y\"].fillna(test[\"category_2_mean_y\"].median(),inplace=True)\ntest[\"category_2_max_y\"].fillna(test[\"category_2_max_y\"].median(),inplace=True)\ntest[\"category_2_sum_y\"].fillna(test[\"category_2_sum_y\"].median(),inplace=True)\n\ntest[\"category_2_min_x\"].fillna(test[\"category_2_min_y\"].median(),inplace=True)\ntest[\"category_2_mean_x\"].fillna(test[\"category_2_mean_y\"].median(),inplace=True)\ntest[\"category_2_max_x\"].fillna(test[\"category_2_max_y\"].median(),inplace=True)\ntest[\"category_2_sum_x\"].fillna(test[\"category_2_sum_y\"].median(),inplace=True)\n\ntest[\"category_3_min_y\"].fillna(test[\"category_3_min_y\"].median(),inplace=True)\ntest[\"category_3_mean_y\"].fillna(test[\"category_3_mean_y\"].median(),inplace=True)\ntest[\"category_3_max_y\"].fillna(test[\"category_3_max_y\"].median(),inplace=True)\ntest[\"category_3_sum_y\"].fillna(test[\"category_3_sum_y\"].median(),inplace=True)\n\ntest[\"category_3_min_x\"].fillna(test[\"category_3_min_x\"].median(),inplace=True)\ntest[\"category_3_sum_x\"].fillna(test[\"category_3_sum_x\"].median(),inplace=True)\ntest[\"category_3_mean_x\"].fillna(test[\"category_3_mean_x\"].median(),inplace=True)\ntest[\"category_3_max_x\"].fillna(test[\"category_3_max_x\"].median(),inplace=True)\n\ntest[\"new_first_buy\"].fillna(test[\"new_first_buy\"].median(),inplace=True)\ntest[\"new_last_buy\"].fillna(test[\"new_last_buy\"].median(),inplace=True)\n\ntest[\"hist_price_mean\"].fillna(test[\"hist_price_mean\"].median(),inplace=True)\ntest[\"hist_price_sum\"].fillna(test[\"hist_price_sum\"].median(),inplace=True)\ntest[\"hist_price_var\"].fillna(test[\"hist_price_var\"].median(),inplace=True)\ntest[\"hist_duration_skew\"].fillna(test[\"hist_duration_skew\"].median(),inplace=True)\ntest[\"hist_amount_month_ratio_skew\"].fillna(test[\"hist_amount_month_ratio_skew\"].median(),inplace=True)\n\ntest[\"price_mean\"].fillna(test[\"price_mean\"].median(),inplace=True)\ntest[\"price_max\"].fillna(test[\"price_max\"].median(),inplace=True)\ntest[\"price_total\"].fillna(test[\"price_total\"].median(),inplace=True)\n\ntest[\"installments_total\"].fillna(test[\"installments_total\"].median(),inplace=True)\ntest[\"installments_mean\"].fillna(test[\"installments_mean\"].median(),inplace=True)\ntest[\"installments_max\"].fillna(test[\"installments_max\"].median(),inplace=True)\ntest[\"installments_ratio\"].fillna(test[\"installments_ratio\"].median(),inplace=True)\n\ntest[\"new_purchase_date_diff\"].fillna(test[\"new_purchase_date_diff\"].median(),inplace=True)\ntest[\"new_purchase_date_average\"].fillna(test[\"new_purchase_date_average\"].median(),inplace=True)\ntest[\"new_purchase_date_uptonow\"].fillna(test[\"new_purchase_date_uptonow\"].median(),inplace=True)\ntest[\"new_purchase_date_uptomin\"].fillna(test[\"new_purchase_date_uptomin\"].median(),inplace=True)\n\ntest[\"month_diff_mean\"].fillna(test[\"month_diff_mean\"].median(),inplace=True)\ntest[\"month_diff_ratio\"].fillna(test[\"month_diff_ratio\"].median(),inplace=True)\n\ntest[\"month_lag_mean\"].fillna(test[\"month_lag_mean\"].median(),inplace=True)\n#test[\"month_lag_min\"].fillna(test[\"month_lag_min\"].median(),inplace=True)\n#test[\"month_lag_max\"].fillna(test[\"month_lag_max\"].median(),inplace=True)\n\n#test[\"card_id_total\"].fillna(test[\"card_id_total\"].median(),inplace=True)\n#test[\"card_id_cnt_total\"].fillna(test[\"card_id_cnt_total\"].median(),inplace=True)\n#test[\"card_id_cnt_ratio\"].fillna(test[\"card_id_cnt_ratio\"].median(),inplace=True)\n\ntest[\"purchase_amount_total\"].fillna(test[\"purchase_amount_total\"].median(),inplace=True)\ntest[\"purchase_amount_mean\"].fillna(test[\"purchase_amount_mean\"].median(),inplace=True)\ntest[\"purchase_amount_max\"].fillna(test[\"purchase_amount_max\"].median(),inplace=True)\ntest[\"purchase_amount_min\"].fillna(test[\"purchase_amount_min\"].median(),inplace=True)\ntest[\"purchase_amount_ratio\"].fillna(test[\"purchase_amount_ratio\"].median(),inplace=True)\n\ntest[\"duration_mean\"].fillna(test[\"duration_mean\"].median(),inplace=True)\ntest[\"duration_min\"].fillna(test[\"duration_min\"].median(),inplace=True)\ntest[\"duration_max\"].fillna(test[\"duration_max\"].median(),inplace=True)\n\ntest[\"CLV_ratio\"].fillna(test[\"CLV_ratio\"].median(),inplace=True)\ntest[\"new_CLV\"].fillna(test[\"new_CLV\"].median(),inplace=True)\n\ntest[\"amount_month_ratio_mean\"].fillna(test[\"amount_month_ratio_mean\"].median(),inplace=True)\ntest[\"amount_month_ratio_min\"].fillna(test[\"amount_month_ratio_min\"].median(),inplace=True)\ntest[\"amount_month_ratio_max\"].fillna(test[\"amount_month_ratio_max\"].median(),inplace=True)\ntrain.shape, test.shape","80a222ce":"train['card_id_total'] = train['new_card_id_size']+train['hist_card_id_size']\ntrain['card_id_cnt_total'] = train['new_card_id_count']+train['hist_card_id_count']\ntrain['card_id_cnt_ratio'] = train['new_card_id_count']\/train['hist_card_id_count']\ntrain['purchase_amount_total'] = train['new_purchase_amount_sum']+train['hist_purchase_amount_sum']\ntrain['purchase_amount_mean'] = train['new_purchase_amount_mean']+train['hist_purchase_amount_mean']\ntrain['purchase_amount_max'] = train['new_purchase_amount_max']+train['hist_purchase_amount_max']\ntrain['purchase_amount_min'] = train['new_purchase_amount_min']+train['hist_purchase_amount_min']\ntrain['purchase_amount_ratio'] = train['new_purchase_amount_sum']\/train['hist_purchase_amount_sum']\ntrain['month_diff_mean'] = train['new_month_diff_mean']+train['hist_month_diff_mean']\ntrain['month_diff_ratio'] = train['new_month_diff_mean']\/train['hist_month_diff_mean']\ntrain['month_lag_mean'] = train['new_month_lag_mean']+train['hist_month_lag_mean']\n#train['month_lag_max'] = train['new_month_lag_max']+train['hist_month_lag_max']\n#train['month_lag_min'] = train['new_month_lag_min']+train['hist_month_lag_min']\ntrain['category_1_mean'] = train['new_category_1_mean']+train['hist_category_1_mean']\n\n\ntrain['installments_total'] = train['new_installments_sum']+train['hist_installments_sum']\ntrain['installments_mean'] = train['new_installments_mean']+train['hist_installments_mean']\ntrain['installments_max'] = train['new_installments_max']+train['hist_installments_max']\ntrain['installments_ratio'] = train['new_installments_sum']\/train['hist_installments_sum']\ntrain['price_total'] = train['purchase_amount_total'] \/ train['installments_total']\ntrain['price_mean'] = train['purchase_amount_mean'] \/ train['installments_mean']\ntrain['price_max'] = train['purchase_amount_max'] \/ train['installments_max']\ntrain['duration_mean'] = train['new_duration_mean']+train['hist_duration_mean']\ntrain['duration_min'] = train['new_duration_min']+train['hist_duration_min']\ntrain['duration_max'] = train['new_duration_max']+train['hist_duration_max']\ntrain['amount_month_ratio_mean']=train['new_amount_month_ratio_mean']+train['hist_amount_month_ratio_mean']\ntrain['amount_month_ratio_min']=train['new_amount_month_ratio_min']+train['hist_amount_month_ratio_min']\ntrain['amount_month_ratio_max']=train['new_amount_month_ratio_max']+train['hist_amount_month_ratio_max']\ntrain['new_CLV'] = train['new_card_id_count'] * train['new_purchase_amount_sum'] \/ train['new_month_diff_mean']\ntrain['hist_CLV'] = train['hist_card_id_count'] * train['hist_purchase_amount_sum'] \/ train['hist_month_diff_mean']\ntrain['CLV_ratio'] = train['new_CLV'] \/ train['hist_CLV']\n\ntest['card_id_total'] = test['new_card_id_size']+test['hist_card_id_size']\ntest['card_id_cnt_total'] = test['new_card_id_count']+test['hist_card_id_count']\ntest['card_id_cnt_ratio'] = test['new_card_id_count']\/test['hist_card_id_count']\ntest['purchase_amount_total'] = test['new_purchase_amount_sum']+test['hist_purchase_amount_sum']\ntest['purchase_amount_mean'] = test['new_purchase_amount_mean']+test['hist_purchase_amount_mean']\ntest['purchase_amount_max'] = test['new_purchase_amount_max']+test['hist_purchase_amount_max']\ntest['purchase_amount_min'] = test['new_purchase_amount_min']+test['hist_purchase_amount_min']\ntest['purchase_amount_ratio'] = test['new_purchase_amount_sum']\/test['hist_purchase_amount_sum']\ntest['month_diff_mean'] = test['new_month_diff_mean']+test['hist_month_diff_mean']\ntest['month_diff_ratio'] = test['new_month_diff_mean']\/test['hist_month_diff_mean']\ntest['month_lag_mean'] = test['new_month_lag_mean']+test['hist_month_lag_mean']\n#test['month_lag_max'] = test['new_month_lag_max']+test['hist_month_lag_max']\n#test['month_lag_min'] = test['new_month_lag_min']+test['hist_month_lag_min']\ntest['category_1_mean'] = test['new_category_1_mean']+test['hist_category_1_mean']\n\ntest['installments_total'] = test['new_installments_sum']+test['hist_installments_sum']\ntest['installments_mean'] = test['new_installments_mean']+test['hist_installments_mean']\ntest['installments_max'] = test['new_installments_max']+test['hist_installments_max']\ntest['installments_ratio'] = test['new_installments_sum']\/test['hist_installments_sum']\ntest['price_total'] = test['purchase_amount_total'] \/ test['installments_total']\ntest['price_mean'] = test['purchase_amount_mean'] \/ test['installments_mean']\ntest['price_max'] = test['purchase_amount_max'] \/ test['installments_max']\ntest['duration_mean'] = test['new_duration_mean']+test['hist_duration_mean']\ntest['duration_min'] = test['new_duration_min']+test['hist_duration_min']\ntest['duration_max'] = test['new_duration_max']+test['hist_duration_max']\ntest['amount_month_ratio_mean']=test['new_amount_month_ratio_mean']+test['hist_amount_month_ratio_mean']\ntest['amount_month_ratio_min']=test['new_amount_month_ratio_min']+test['hist_amount_month_ratio_min']\ntest['amount_month_ratio_max']=test['new_amount_month_ratio_max']+test['hist_amount_month_ratio_max']\ntest['new_CLV'] = test['new_card_id_count'] * test['new_purchase_amount_sum'] \/ test['new_month_diff_mean']\ntest['hist_CLV'] = test['hist_card_id_count'] * test['hist_purchase_amount_sum'] \/ test['hist_month_diff_mean']\ntest['CLV_ratio'] = test['new_CLV'] \/ test['hist_CLV']\ntrain.shape, test.shape","29910117":"train.replace({np.inf: 0, -np.inf: 0}, inplace=True)\ntest.replace({np.inf: 0, -np.inf: 0}, inplace=True)\n\ntrain = train.drop(['new_purchase_date_max', 'hist_purchase_date_max', 'hist_purchase_date_min', 'hist_price_min'], axis =1 )\ntest = test.drop(['new_purchase_date_max','hist_purchase_date_max', 'hist_purchase_date_min', 'hist_price_min'], axis =1 )\n\nprint(\"Train\/Test Shape: \",train.shape,test.shape)\n\ny = train['target']\nprint(\"y shape: \",y.shape)\nprint(\"Before drop - X shape: \",train.shape)\nX = train.drop(['target'], axis=1)\nprint(\"After drop - X shape: \",X.shape)\nprint(\"Nulls in X: \",(X.isnull().sum() > 0 ).sum())\nprint(\"Nulls in y: \",(y.isnull().sum() > 0 ).sum())\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n#print(\"X_train, X_test, y_train, y_test shape:\",X_train.shape, X_test.shape, y_train.shape, y_test.shape)","64b45922":"X[\"installments_ratio\"].fillna(X[\"installments_ratio\"].median(),inplace=True)\ndf= X.isnull().sum() > 0\nprint(df[130:160])","0aaf8a45":"del history;\ngc.collect() \ndel new;\ngc.collect() \ndel final;\ngc.collect() \ndel ht;\ngc.collect() \ndel nmt;\ngc.collect() \ntrain.head(5)","da69a7a6":"train_cols= ['card_id_total', 'card_id_cnt_total', 'card_id_cnt_ratio', 'purchase_amount_total' , 'purchase_amount_mean' ,'purchase_amount_max',\n'purchase_amount_min', 'purchase_amount_ratio', 'month_diff_mean' , 'month_diff_ratio', 'month_lag_mean', 'category_1_mean', 'installments_total',\n'installments_mean', 'installments_max', 'installments_ratio', 'price_total', 'price_mean','price_max', 'duration_mean', 'duration_min' , 'duration_max',\n'amount_month_ratio_mean', 'amount_month_ratio_min','amount_month_ratio_max', 'new_CLV', 'hist_CLV', 'CLV_ratio','AvOrderValue','AgeRecencyRatio']","a5a9bedd":"\ndf = test_min.isnull().sum() > 0\ndf[:20]","053b08f0":"from sklearn.linear_model import LinearRegression\n\nX_min = X[train_cols]\ny_min = y\ntest_min = test[train_cols]\nX_min.replace({np.inf: 0, -np.inf: 0}, inplace=True)\ntest_min.replace({np.inf: 0, -np.inf: 0}, inplace=True)\ntest_min[\"installments_ratio\"].fillna(test_min[\"installments_ratio\"].median(),inplace=True)\n\n# Fitting Linear Regression to the dataset\nregressor = LinearRegression() \nregressor.fit(X_min, y_min) #training the algorithm\n\ny_pred_linear = regressor.predict(test_min)\nprint(y_pred_linear.shape)\n\nsubmission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv') \nprint(submission.head())\nsubmission['target'] = y_pred_linear \nprint(submission.head())\nsubmission.to_csv('linear.csv', index=False)","909a1eca":"# Using Ridge Regression \nridge=Ridge() \n\nparameters={'alpha': [1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]} \nridge_regressor=GridSearchCV(ridge,parameters,scoring='neg_root_mean_squared_error',cv=5) \nridge_regressor.fit(X_min, y_min)\ny_pred_ridge = regressor.predict(test_min)\nprint(y_pred_ridge.shape)\n\nsubmission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv') \nprint(submission.head())\nsubmission['target'] = y_pred_ridge \nprint(submission.head())\nsubmission.to_csv('ridge.csv', index=False)","78bb527d":"from sklearn.linear_model import Lasso \n\nlasso=Lasso() \nparameters={'alpha':[1e-3]} \nlasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_root_mean_squared_error',cv=5)\nlasso_regressor.fit(X_min,y_min)\nprediction_lasso = lasso_regressor.predict(test_min) \n\nsubmission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv') \nprint(submission.head())\nsubmission['target'] = prediction_lasso \nprint(submission.head())\nsubmission.to_csv('lasso.csv', index=False)","b72ba3ba":"treeRegressor = DecisionTreeRegressor() \n\nparam_grid = {\"criterion\": [\"mse\"], \"max_depth\": [5], \"min_samples_split\": [8], \"max_leaf_nodes\": [15], \"max_features\": [25], \"min_impurity_decrease\":[0.1] }\ngrid_decision = GridSearchCV(treeRegressor, param_grid, cv=3,verbose=1,n_jobs=-1) \ngrid_decision.fit(X_min, y_min)\ny_pred_decision = grid_decision.predict(test_min)\n\nsubmission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv') \nprint(submission.head())\nsubmission['target'] = y_pred_decision \nprint(submission.head())\nsubmission.to_csv('decision.csv', index=False)","1b392baa":"param_grid = {\"criterion\": [\"mse\"], 'n_estimators': [1000], \"max_depth\": [5], \"max_leaf_nodes\" : [5], \"min_samples_split\":[8] , \"max_features\": [25], \"min_impurity_decrease\":[0.1] } \nforestRegressor = RandomForestRegressor(random_state = 10) \n\ngrid_forest = GridSearchCV(forestRegressor, param_grid, cv=3, verbose=1,n_jobs=-1) \ngrid_forest.fit(X_min, y_min)\ny_pred_forest = grid_forest.predict(test_min)\n\nsubmission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv') \nprint(submission.head())\nsubmission['target'] = y_pred_forest \nprint(submission.head())\nsubmission.to_csv('forest.csv', index=False)","47f63e85":"# Fitting Extra Trees regressor to the dataset \nextraRegressor = ExtraTreesRegressor(random_state = 10)\nparam_grid = {\"criterion\": [\"mse\"], 'n_estimators': [500], \"max_depth\": [5], \"max_leaf_nodes\" : [5], \"min_samples_leaf\":[2], \"min_samples_split\":[2] , \"max_features\": [25], \"min_impurity_decrease\":[0.1] }\n\ngrid_extra = GridSearchCV(extraRegressor, param_grid, cv=3, verbose=1,n_jobs=-1)\ngrid_extra.fit(X_min, y_min) \ny_pred_extra = grid_extra.predict(test_min)\n\nsubmission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv') \nprint(submission.head())\nsubmission['target'] = y_pred_extra \nprint(submission.head())\nsubmission.to_csv('extra.csv', index=False)","2535c226":" from sklearn.ensemble import AdaBoostRegressor\nparam = { 'n_estimators':[50], 'learning_rate':[1e-2], 'loss':['exponential'] }\nadaRegressor = AdaBoostRegressor(random_state = 10) \n\ngrid_ada = GridSearchCV(adaRegressor, param, cv = 3, n_jobs = -1, verbose=1)\ngrid_ada.fit(X_min, y_min) \ny_pred_ada = grid_ada.predict(test_min)\n\nsubmission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv') \nprint(submission.head())\nsubmission['target'] = y_pred_ada \nprint(submission.head())\nsubmission.to_csv('ada.csv', index=False)\n","2a1a6088":"SEED = 10\n\n# Using Decision Tree as a base model\ndef get_model():   \n  dt = DecisionTreeRegressor(criterion = 'mse', max_depth = 5, max_features = 25, max_leaf_nodes = 15, min_impurity_decrease = 0.1, min_samples_split = 8, random_state=SEED)    \n  return dt","ed60071e":"from random import choices\ndef get_samples(D1_train, D2_train, n_estimators):\n  print(\"\\nCalculating Samples with replacement...\")\n  samples_train_appender = []\n  samples_test_appender = []\n  all_indexes = D1_train.index\n  population_size = D1_train.shape[0]  \n  sample_size = round(population_size\/n_estimators)  \n  bumpedup_sample_size = int(sample_size * 1.85)  \n\n  for s in range(n_estimators):\n    samples_index = choices(all_indexes, k = sample_size)        \n    sample_train_df = D1_train[D1_train.index.isin(samples_index)]\n    sample_test_df = D2_train[D2_train.index.isin(samples_index)]   \n    samples_train_appender.append(sample_train_df)\n    samples_test_appender.append(sample_test_df)\n\n  all_train_samples = pd.concat(samples_train_appender,ignore_index=True)\n  all_test_samples = pd.concat(samples_test_appender,ignore_index=True)\n  print(\"Samples calculation Done.\")    \n  return all_train_samples, all_test_samples, sample_size\n\n# Calculate RMSE\ndef evaluate_model(y_pred, y_actual):\n  print(\"Evaluating Score...\\n\")\n  mse = mean_squared_error(y_actual, y_pred)\n  print('RMSE %.3f' % (np.sqrt(mse)))\n\ndef train_predict(n_estimators, all_train_samples, all_test_samples, D1_test,D2_test, sample_size):\n  \"\"\"Fit models in list on training set and return preds\"\"\"\n  P = np.zeros((D2_test.shape[0], n_estimators))\n  P = pd.DataFrame(P)\n  models_list = []\n\n  print(\"Sample size: \", sample_size)\n  cols = list()\n  print(\"Base models {} - fitting and predicting ...\".format(n_estimators))\n  \n  for i in range(0,n_estimators):    \n    j = sample_size * i\n    k = sample_size * (i + 1)\n    x_data = all_train_samples[j:k]\n    y_data = all_test_samples[j:k]\n    model = get_model() \n    \n    model.fit(x_data, y_data)  \n    models_list.append(model)           \n    pred = (model.predict(D1_test))        \n    P.iloc[:,i] = pred\n    cols.append(i)\n    \n  P.columns = cols\n  print(\"Base models done.\")\n  return P, models_list","d0f8ee02":"def custom_ensemble(X_train,y_train,n_estimators):\n  print(\"Preparing Custom Ensemble...\")\n  #Split X_train into D1,D2 (50-50)\n  D1_train, D1_test, D2_train, D2_test = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n  print(\"D1_train, D1_test, D2_train, D2_test: \",D1_train.shape, D1_test.shape, D2_train.shape, D2_test.shape)\n  \n  #Get Samples\n  all_samples_train, all_samples_test, sample_size = get_samples(D1_train, D2_train, n_estimators)\n  \n  #Get predictions\n  P, models_list = train_predict(n_estimators, all_samples_train, all_samples_test,D1_test, D2_test, sample_size)\n  print(\"Custom Ensemble Done.\")\n  return P, models_list, D2_test\n\ndef super_train_predict(n_estimators, models_list, test_set):\n  \"\"\"Fit models in list on training set and return preds\"\"\"\n  meta_pred = np.zeros((test_set.shape[0] , n_estimators))\n  meta_pred = pd.DataFrame(meta_pred)\n    \n  print(\"Predicting {} models from metalearner...\".format(n_estimators))\n  cols = list()\n  for i in range(0,n_estimators):    \n    model = models_list[i]                    \n    pred = (model.predict(test_set))          \n    meta_pred.iloc[:,i] = pred\n    cols.append(i)\n    \n  meta_pred.columns = cols       \n    \n  print(\"Meta Learner prediction Done.\")\n  return meta_pred","90183fa8":"X_train.replace({np.inf: 0, -np.inf: 0}, inplace=True)\nX_test.replace({np.inf: 0, -np.inf: 0}, inplace=True)\nX_train[\"installments_ratio\"].fillna(X_train[\"installments_ratio\"].median(),inplace=True)\nX_test[\"installments_ratio\"].fillna(X_test[\"installments_ratio\"].median(),inplace=True)\n\nX_t = X_train.copy()\nprint(X_t.shape)\nX_t = X_t[train_cols]\nprint(X_t.shape)\n\nX_tt = X_test.copy()\nprint(X_tt.shape)\nX_tt = X_tt[train_cols]\nprint(X_tt.shape)","d116b9f7":"test.replace({np.inf: 0, -np.inf: 0}, inplace=True)\ntest[\"installments_ratio\"].fillna(test[\"installments_ratio\"].median(),inplace=True)\nte = test.copy()\nte = te[train_cols]\nte.shape","fc57defd":"df = te.isnull().sum()\ndf[0:35]","28e35303":"import timeit\nfrom sklearn.model_selection import StratifiedKFold\n\nstart = timeit.default_timer()\n\nxgb = XGBRegressor()\nparameters = {   'gamma': [8],  'eval_metric' :['rmse'],'eta': [0.5], 'colsample_bytree':[0.3],\n               'min_child_weight': [3], 'max_depth' :[3], 'max_features':[5],'subsample': [0.7],'tree_method':['auto'],\n               'reg_alpha':[1000], \"criterion\": [\"mse\"],'n_estimators': [1000] ,'seed':[11] }\n\n\nmeta_learner = GridSearchCV(xgb, parameters, cv = 6, n_jobs = -1, verbose=1)\n\n\nn_estimators = 100\nprint(\"Fitting models to meta-learner.\")\nP, models_list, D2_test = custom_ensemble(X_t,y_train,n_estimators)\nmeta_learner.fit(P, D2_test)\n\n# Ensemble final prediction and evaluation\nmeta_pred = super_train_predict(n_estimators, models_list, X_tt) # X_test brought from first split\npred_final = meta_learner.predict(meta_pred)\n\nrmse = evaluate_model(pred_final,y_test)\n\nstop = timeit.default_timer()\nexecution_time = (stop - start)\/60\n\nprint(\"Ensemble Executed in {} minutes\".format(str(execution_time)))","0d2917ce":"train.tail()","1ded9280":"print(\"Best Score = \",meta_learner.best_score_)\nprint(\"Best Params = \",meta_learner.best_params_)","7ececadd":"start = timeit.default_timer()\n\ntest_meta_pred = super_train_predict(n_estimators, models_list, te) # test.csv \ntest_pred_final = meta_learner.predict(test_meta_pred)\n\nstop = timeit.default_timer()\nexecution_time = (stop - start)\/60\n\nprint(\"Test Ensemble Executed in {} minutes\".format(str(execution_time)))","a14f8620":"test_pred_final.shape","1bfa965f":"submission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv') \nprint(submission.head())\nsubmission['target'] = test_pred_final \nprint(submission.head())\nsubmission.to_csv('sub.csv', index=False)","7eca85a8":"print(train.shape, test.shape)","67f704bc":"**Custom Ensemble**","c7f39e55":"predictions = np.zeros(len(test))\nsubmission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv')\nsubmission['target'] = predictions\nsubmission.to_csv('lgb.csv', index=False)"}}