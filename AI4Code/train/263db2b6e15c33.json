{"cell_type":{"67f4ad68":"code","794de916":"code","619e062e":"code","09a7cd10":"code","347fe455":"code","87638edc":"code","d088ae8d":"code","1a8fd052":"code","4b94e795":"code","e58f7ac4":"code","d9a162cf":"code","ca33ccdb":"code","6dadfd0d":"code","ce066c55":"code","d463c56b":"code","7d02160d":"markdown","35b6134d":"markdown","7d68794a":"markdown","cb8d7ed1":"markdown","838702e6":"markdown"},"source":{"67f4ad68":"!pip install '..\/input\/pytorch-190\/torch-1.9.0+cu111-cp37-cp37m-linux_x86_64.whl'","794de916":"!pip install '\/kaggle\/input\/mmdetectionv2140\/addict-2.4.0-py3-none-any.whl' \n!pip install '\/kaggle\/input\/mmdetectionv2140\/yapf-0.31.0-py2.py3-none-any.whl' \n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminal-0.4.0-py3-none-any.whl'\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminaltables-3.1.0-py3-none-any.whl'\n!pip install '\/kaggle\/input\/mmdetection-v217\/mmdetection\/mmcv_full-1.3.x-py2.py3-none-any\/mmcv_full-1.3.16-cp37-cp37m-manylinux1_x86_64.whl'\n!pip install '\/kaggle\/input\/mmdetectionv2140\/pycocotools-2.0.2\/pycocotools-2.0.2'\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmpycocotools-12.0.3\/mmpycocotools-12.0.3'\n\n!rm -rf mmdetection\n\n!cp -r \/kaggle\/input\/mmdetection-v217\/mmdetection\/mmdetection-2.18.0 \/kaggle\/working\/\n!mv \/kaggle\/working\/mmdetection-2.18.0 \/kaggle\/working\/mmdetection\n%cd \/kaggle\/working\/mmdetection\n!pip install -e .\n\n%cd ..\n\n# !rm -rf mmdetection\n# !git clone https:\/\/github.com\/open-mmlab\/mmdetection.git \/kaggle\/working\/mmdetection","619e062e":"# !pip install openmim\n# !mim install mmdet","09a7cd10":"import sys, os\nsys.path.append('.\/mmdetection')\nsys.path.append('..\/input\/tensorflow-great-barrier-reef\/greatbarrierreef')\nimport numpy as np\nimport mmdet\nimport mmcv\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","347fe455":"seed = 42\nset_random_seed(seed, deterministic=False)","87638edc":"\n\n%%writefile .\/mmdetection\/configs\/swin\/TFGBR_swin_base_faster_rcnn_fp16.py\n\n_base_ = [\n    '..\/_base_\/models\/cascade_rcnn_r50_fpn.py',\n    '..\/_base_\/datasets\/coco_detection.py',\n    '..\/_base_\/schedules\/schedule_1x.py', '..\/_base_\/default_runtime.py'\n]\npretrained = 'https:\/\/github.com\/SwinTransformer\/storage\/releases\/download\/v1.0.0\/swin_small_patch4_window7_224.pth'\nmodel = dict(\n    backbone=dict(\n        _delete_=True,\n        type='SwinTransformer',\n        embed_dims=96,\n        depths=[2, 2, 18, 2],\n        num_heads=[3, 6, 12, 24],\n        window_size=7,\n        mlp_ratio=4,\n        qkv_bias=True,\n        qk_scale=None,\n        drop_rate=0.,\n        attn_drop_rate=0.,\n        drop_path_rate=0.3,\n        patch_norm=True,\n        out_indices=(0, 1, 2, 3),\n        with_cp=False,\n        convert_weights=True,\n        init_cfg=dict(type='Pretrained', checkpoint=pretrained)),\n    neck=dict(in_channels=[96, 192, 384, 768]),\n    roi_head=dict(\n        type='CascadeRoIHead',\n        num_stages=3,\n        stage_loss_weights=[1, 0.5, 0.25],\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                reg_decoded_bbox=True,\n                loss_bbox=dict(type='GIoULoss', loss_weight=10.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                reg_decoded_bbox=True,\n                loss_bbox=dict(type='GIoULoss', loss_weight=10.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                reg_decoded_bbox=True,\n                loss_bbox=dict(type='GIoULoss', loss_weight=10.0))\n        ]))\n\noptimizer = dict(\n    _delete_=True,\n    type='AdamW',\n    lr=0.0004,\n    betas=(0.9, 0.999),\n    weight_decay=0.05,\n    paramwise_cfg=dict(\n        custom_keys={\n            'absolute_pos_embed': dict(decay_mult=0.),\n            'relative_position_bias_table': dict(decay_mult=0.),\n            'norm': dict(decay_mult=0.)\n        }))\nlr_config = dict(warmup_iters=500, step=[8, 11])\nrunner = dict(max_epochs=14)","d088ae8d":"from mmcv import Config\ncfg = Config.fromfile('.\/mmdetection\/configs\/swin\/TFGBR_swin_base_faster_rcnn_fp16.py')","1a8fd052":"%%writefile labels.txt \ncots","4b94e795":"img_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile',to_float32=True),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(\n        type='AutoAugment',\n        policies=[[\n            dict(\n                type='Resize',\n                img_scale=[(480, 1333), (512, 1333), (544, 1333), (576, 1333),\n                           (608, 1333), (640, 1333), (672, 1333), (704, 1333),\n                           (736, 1333), (768, 1333), (800, 1333)],\n                multiscale_mode='value',\n                keep_ratio=True)\n        ],\n                  [\n                      dict(\n                          type='Resize',\n                          img_scale=[(400, 1333), (500, 1333), (600, 1333)],\n                          multiscale_mode='value',\n                          keep_ratio=True),\n                      dict(\n                          type='RandomCrop',\n                          crop_type='absolute_range',\n                          crop_size=(384, 600),\n                          allow_negative_crop=True),\n                      dict(\n                          type='Resize',\n                          img_scale=[(480, 1333), (512, 1333), (544, 1333),\n                                     (576, 1333), (608, 1333), (640, 1333),\n                                     (672, 1333), (704, 1333), (736, 1333),\n                                     (768, 1333), (800, 1333)],\n                          multiscale_mode='value',\n                          override=True,\n                          keep_ratio=True),\n                      dict(\n                            type='PhotoMetricDistortion',\n                            brightness_delta=32,\n                            contrast_range=(0.5, 1.5),\n                            saturation_range=(0.5, 1.5),\n                            hue_delta=18),\n                    dict(\n                            type='MinIoURandomCrop',\n                            min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n                            min_crop_size=0.3),\n                    dict(\n                            type='CutOut',\n                            n_holes=(5, 10),\n                            cutout_shape=[(4, 4), (4, 8), (8, 4), (8, 8),\n                                          (16, 32), (32, 16), (32, 32),\n                                          (32, 48), (48, 32), (48, 48)]\n                            )\n                  ]]),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\n\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n","e58f7ac4":"cfg.classes = '\/kaggle\/working\/labels.txt'\ncfg.work_dir = '\/kaggle\/working\/model_output'\ncfg.data_root = '\/kaggle\/working'\n\n# cfg.model.roi_head.bbox_head.num_classes = 1\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '\/kaggle\/working'\ncfg.data.test.ann_file = '..\/input\/tfreef-coco-dataset-notebook\/val_dataset.json'\ncfg.data.test.img_prefix = ''\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '\/kaggle\/working'\ncfg.data.train.ann_file = '..\/input\/tfreef-coco-dataset-notebook\/train_dataset.json'\ncfg.data.train.img_prefix = ''\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '\/kaggle\/working'\ncfg.data.val.ann_file = '..\/input\/tfreef-coco-dataset-notebook\/val_dataset.json'\ncfg.data.val.img_prefix = ''\ncfg.data.val.classes = 'labels.txt'\n\n\ncfg.train_pipeline = train_pipeline\ncfg.val_pipeline = test_pipeline\ncfg.test_pipeline = test_pipeline\n\ncfg.data.train.pipeline = cfg.train_pipeline\ncfg.data.val.pipeline = cfg.val_pipeline\n\n# cfg.optimizer.lr = 0.02 \/ 8\n# cfg.lr_config = dict(\n#     policy='CosineAnnealing', \n#     by_epoch=False,\n#     warmup='linear', \n#     warmup_iters= 125, \n#     warmup_ratio= 1\/12,\n#     min_lr=1e-07)\n\ncfg.runner.max_epochs = 12\ncfg.evaluation.save_best='auto'\n\ncfg.seed = seed\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n","d9a162cf":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)","ca33ccdb":"import greatbarrierreef\n\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()  ","6dadfd0d":"model = init_detector(cfg, '..\/input\/mmdetection-swin-transformer-fasterrcnn-training\/model_output\/epoch_14.pth')","ce066c55":"#################################### faster rcnn ############################################\n# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\n# checkpoint = load_checkpoint(model, WEIGHTS_FILE, map_location='cpu')\n\n# model.CLASSES = dataset.CLASSES\n\n# model = MMDataParallel(model, device_ids=[0])\n# outputs = single_gpu_test(model, data_loader, False, None, 0.5)\n\nresults = []\n\nfor (pixel_array, sample_prediction_df) in iter_test:\n    result = inference_detector(model, pixel_array[:, :, ::-1])\n#     show_result_pyplot(model, pixel_array[:, :, ::-1], result)    \n    boxes = result[0][:, :4]\n    scores = result[0][:, 4]\n\n    boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n    boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n\n    \n    sample_prediction_df['annotations'] = format_prediction_string(boxes, scores)\n    \n    env.predict(sample_prediction_df)","d463c56b":"import shutil\nshutil.rmtree('\/kaggle\/working\/mmdetection')","7d02160d":"# **Import Libraries**","35b6134d":"# **Inference**","7d68794a":"# 1. Inference Notebook, follow up [Training Notebook](https:\/\/www.kaggle.com\/mlneo07\/swin-transformer-fasterrcnn-training) ","cb8d7ed1":"# **Model**","838702e6":"# **Install Offline MMDetection**"}}