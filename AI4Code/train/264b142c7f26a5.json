{"cell_type":{"399a10c7":"code","d7aa1855":"code","1b4bc970":"code","045fbc13":"code","c8d5eb2a":"code","67f5c660":"code","5c8610d6":"code","1ae4878e":"code","ab9d2611":"code","feae9bd1":"code","cce90197":"code","a79bf031":"code","f8c2e59c":"code","9da23727":"code","360927cb":"code","4f4f39a6":"code","0b448bd7":"code","fd7e00ed":"code","5068ec25":"code","f6ab4ccf":"code","83c896d0":"code","7d04e98d":"code","c5fe1ba3":"code","882265bf":"code","7b37655a":"code","5c6bb511":"code","d225b79e":"code","aaa80bae":"code","70e197e1":"code","18bb181d":"code","336ad1a8":"code","d374d2dd":"code","017cec6a":"code","99b3c17f":"code","bb494abc":"code","93848ffe":"code","10341285":"code","f7593a2a":"code","b9d556b0":"code","41b35f9d":"markdown","81970dce":"markdown","636c9b77":"markdown","f77ad370":"markdown","b6e268f1":"markdown","7dfc4a0e":"markdown","05e16714":"markdown","5b851739":"markdown","2d9fd4e2":"markdown","938b367d":"markdown","2c90e756":"markdown","1da59ef1":"markdown","f667727c":"markdown","92732063":"markdown"},"source":{"399a10c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7aa1855":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix , classification_report\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","1b4bc970":"data=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndata.head()","045fbc13":"data.info()","c8d5eb2a":"## here id and Unnamed is not useful feature so drop it from the data","67f5c660":"data.drop(['id','Unnamed: 32'], axis=1, inplace=True)","5c8610d6":"data.isnull().sum()","1ae4878e":"data.describe()","ab9d2611":"## check the target feature \ndata.diagnosis.value_counts()","feae9bd1":"sns.countplot(data['diagnosis'])","cce90197":"## check the distribution of some feature\nsns.distplot(data['radius_mean'])\nplt.ylabel(\"probability \")","a79bf031":"sns.distplot(data['texture_mean'])","f8c2e59c":"sns.distplot(data['concavity_mean'])","9da23727":"sns.FacetGrid(data, hue='diagnosis').map(plt.scatter, 'radius_mean','texture_mean').add_legend()  ## a lot of overlapping with the target feature","360927cb":"plt.figure(figsize=(20,15))\nsns.heatmap(data.corr(), annot=True, cmap='viridis')","4f4f39a6":"corr_matrix=data.corr().abs()\nupper=corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop=[column for column in upper.columns if any(upper[column]>0.95)]","0b448bd7":"data[to_drop]","fd7e00ed":"## check these feature with the target feature(diagnosis)\nsns.FacetGrid(data,hue='diagnosis').map(plt.plot, 'area_mean').add_legend()","5068ec25":"sns.FacetGrid(data,hue='diagnosis').map(plt.plot, 'perimeter_mean').add_legend()","f6ab4ccf":"sns.FacetGrid(data,hue='diagnosis').map(plt.plot, 'perimeter_worst').add_legend()","83c896d0":"sns.FacetGrid(data,hue='diagnosis').map(plt.plot, 'area_worst').add_legend()","7d04e98d":"data.drop(to_drop, axis=1, inplace=True)","c5fe1ba3":"data.shape","882265bf":"sns.pairplot(data, hue='diagnosis', size=7)","7b37655a":"x=data.drop('diagnosis', axis=1)\ny=data['diagnosis']\n","5c6bb511":"x.head()\nprint(x.shape)","d225b79e":"x_train ,x_test, y_train ,y_test=train_test_split(x, y, test_size=0.3, random_state=0)\n## apply the peprocessing \nscaler=StandardScaler()\nx_train_scaler=scaler.fit_transform(x_train)\nx_test_scaler=scaler.fit_transform(x_test)\n","aaa80bae":"logistic=LogisticRegression()\nlogistic.fit(x_train_scaler, y_train)\npredict1=logistic.predict(x_test_scaler)\nprint(\"training set score:\", logistic.score(x_train_scaler, y_train))\nprint('testing set score :', logistic.score(x_test_scaler, y_test))","70e197e1":"print(\"confusion matrix : \", confusion_matrix(y_test, predict1))\nprint(\"classification report :\", classification_report(y_test, predict1))","18bb181d":"neighbor=KNeighborsClassifier(n_neighbors=3)\nneighbor.fit(x_train_scaler, y_train)\npredict2=neighbor.predict(x_test_scaler)\nprint(\"training set score:\", neighbor.score(x_train_scaler, y_train))\nprint('testing set score :', neighbor.score(x_test_scaler, y_test))","336ad1a8":"print(\"confusion matrix : \", confusion_matrix(y_test, predict2))\nprint(\"classification report :\", classification_report(y_test, predict2))","d374d2dd":"decision=DecisionTreeClassifier(max_depth=3)\ndecision.fit(x_train_scaler, y_train)\npredict3=decision.predict(x_test_scaler)\nprint(\"training set score:\", decision.score(x_train_scaler, y_train))\nprint('testing set score :', decision.score(x_test_scaler, y_test))","017cec6a":"print(\"confusion matrix : \", confusion_matrix(y_test, predict3))\nprint(\"classification report :\", classification_report(y_test, predict3))","99b3c17f":"random_forest=RandomForestClassifier(max_depth=3)\nrandom_forest.fit(x_train_scaler, y_train)\npredict4=random_forest.predict(x_test_scaler)\nprint(\"training set score:\", random_forest.score(x_train_scaler, y_train))\nprint('testing set score :', random_forest.score(x_test_scaler, y_test))","bb494abc":"print(\"confusion matrix : \", confusion_matrix(y_test, predict4))\nprint(\"classification report :\", classification_report(y_test, predict4))","93848ffe":"svm=SVC(C=10)\nsvm.fit(x_train_scaler, y_train)\npredict5=svm.predict(x_test_scaler)\nprint(\"training set score:\", svm.score(x_train_scaler, y_train))\nprint('testing set score :', svm.score(x_test_scaler, y_test))","10341285":"print(\"confusion matrix : \", confusion_matrix(y_test, predict5))\nprint(\"classification report :\", classification_report(y_test, predict5))","f7593a2a":"## best accuray score for the testing data is 97.07 which is SVC\n## so it the best model","b9d556b0":"## SVC\nprint('prediction of SVC is :', predict5)","41b35f9d":"#### logisticregression","81970dce":"## support vector classifier","636c9b77":"## check the highly correlated feature","f77ad370":"## identify the correlated feature ","b6e268f1":"## load the dataset","7dfc4a0e":"## KNeighborsClassifier","05e16714":"### import the library","5b851739":"## Apply the machine learning model","2d9fd4e2":"## Exploratory data analysis","938b367d":"## random forest Classifier","2c90e756":"## Decision tree classifier","1da59ef1":"## best model ","f667727c":"### split the data into dependent and independent set","92732063":"#### here you can see that to drop feature is not correlated with the target feature so drop it from the dataset"}}