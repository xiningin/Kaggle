{"cell_type":{"32757d7e":"code","c4ac25bf":"code","026058db":"code","effdea20":"code","1e69a341":"code","24ee93f8":"code","e24ff6f8":"code","b29450d5":"code","ff37579d":"code","b4a3b668":"code","b1a6ae72":"code","278b14a3":"code","4a915d2b":"code","500efdd2":"code","b44399d7":"code","b1177f36":"code","2e0d6302":"code","6e09ad76":"code","c0bfbd04":"code","5d1e5bb5":"code","18811256":"code","7de0bf00":"code","5688b424":"code","a56b165f":"code","cd45f60e":"code","5bfe3709":"code","8465a3d7":"code","81e3e828":"code","3645ae94":"code","f653768e":"code","7a3e706f":"code","3f2f6fac":"code","83d36064":"code","cea68aaf":"code","8d6c7be7":"code","8bd97102":"code","a85cd198":"markdown","42444692":"markdown","c924cc5e":"markdown","b355a182":"markdown","1e80050a":"markdown","d503206d":"markdown","e72a1966":"markdown","b0324502":"markdown","66e21980":"markdown","c9300f0a":"markdown","527844da":"markdown","24962f56":"markdown","25046658":"markdown","f065cc1b":"markdown","4df1927b":"markdown","e27259b4":"markdown","69079f87":"markdown","cc01bad2":"markdown","06fcbe82":"markdown","20564dc1":"markdown","04a76356":"markdown","3d637dd0":"markdown","e433243b":"markdown","a88bc950":"markdown","f8fa733c":"markdown","e5de4a31":"markdown","876a71fa":"markdown","b030eec7":"markdown","0a1de42e":"markdown","c58f2a3f":"markdown","431f8172":"markdown","333aaf57":"markdown","c67b58b1":"markdown","e3991953":"markdown"},"source":{"32757d7e":"import numpy as np \nimport pandas as pd \nimport os\nimport missingno as msno\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestRegressor\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n","c4ac25bf":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","026058db":"rain = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\nrain.head(10)","effdea20":"print(f'The number of rows are {rain.shape[0] } and the number of columns are {rain.shape[1]}')","1e69a341":"rain.info()","24ee93f8":"categorical_col, contin_val=[],[]\n\nfor i in rain.columns:\n    \n    if rain[i].dtype == 'object':\n        categorical_col.append(i)\n    else:\n        contin_val.append(i)\n        \nprint(categorical_col)\nprint(contin_val)","e24ff6f8":"rain.nunique()\n","b29450d5":"rain.isnull().sum()","ff37579d":"msno.matrix(rain)\n","b4a3b668":"msno.bar(rain, sort='ascending')\n","b1a6ae72":"msno.heatmap(rain)\n","278b14a3":"rain['RainTomorrow'] = rain['RainTomorrow'].map({'Yes': 1, 'No': 0})\nrain['RainToday'] = rain['RainToday'].map({'Yes': 1, 'No': 0})\n\nprint(rain.RainToday)\nprint(rain.RainTomorrow)\n","4a915d2b":"#Checking percentage of missing data in every column\n\n(rain.isnull().sum()\/len(rain))*100\n","500efdd2":"#Filling the missing values for continuous variables with mean\nrain['MinTemp']=rain['MinTemp'].fillna(rain['MinTemp'].mean())\nrain['MaxTemp']=rain['MinTemp'].fillna(rain['MaxTemp'].mean())\nrain['Rainfall']=rain['Rainfall'].fillna(rain['Rainfall'].mean())\nrain['Evaporation']=rain['Evaporation'].fillna(rain['Evaporation'].mean())\nrain['Sunshine']=rain['Sunshine'].fillna(rain['Sunshine'].mean())\nrain['WindGustSpeed']=rain['WindGustSpeed'].fillna(rain['WindGustSpeed'].mean())\nrain['WindSpeed9am']=rain['WindSpeed9am'].fillna(rain['WindSpeed9am'].mean())\nrain['WindSpeed3pm']=rain['WindSpeed3pm'].fillna(rain['WindSpeed3pm'].mean())\nrain['Humidity9am']=rain['Humidity9am'].fillna(rain['Humidity9am'].mean())\nrain['Humidity3pm']=rain['Humidity3pm'].fillna(rain['Humidity3pm'].mean())\nrain['Pressure9am']=rain['Pressure9am'].fillna(rain['Pressure9am'].mean())\nrain['Pressure3pm']=rain['Pressure3pm'].fillna(rain['Pressure3pm'].mean())\nrain['Cloud9am']=rain['Cloud9am'].fillna(rain['Cloud9am'].mean())\nrain['Cloud3pm']=rain['Cloud3pm'].fillna(rain['Cloud3pm'].mean())\nrain['Temp9am']=rain['Temp9am'].fillna(rain['Temp9am'].mean())\nrain['Temp3pm']=rain['Temp3pm'].fillna(rain['Temp3pm'].mean())\n\n","b44399d7":"#Filling the missing values for continuous variables with mode\n\nrain['RainToday']=rain['RainToday'].fillna(rain['RainToday'].mode()[0])\nrain['RainTomorrow']=rain['RainTomorrow'].fillna(rain['RainTomorrow'].mode()[0])\n","b1177f36":"#Filling the missing values for continuous variables with mode\nrain['WindDir9am'] = rain['WindDir9am'].fillna(rain['WindDir9am'].mode()[0])\nrain['WindGustDir'] = rain['WindGustDir'].fillna(rain['WindGustDir'].mode()[0])\nrain['WindDir3pm'] = rain['WindDir3pm'].fillna(rain['WindDir3pm'].mode()[0])","2e0d6302":"#Checking percentage of missing data in every column\n\n(rain.isnull().sum()\/len(rain))*100\n","6e09ad76":"fig, ax =plt.subplots(1,2)\nprint(rain.RainToday.value_counts())\nprint(rain.RainTomorrow.value_counts())\n\nplt.figure(figsize=(20,20))\nsns.countplot(data=rain,x='RainToday',ax=ax[0])\nsns.countplot(data=rain,x='RainTomorrow',ax=ax[1])","c0bfbd04":"fig, ax =plt.subplots(3,1)\nplt.figure(figsize=(10,10))\n\nsns.countplot(data=rain,x='WindDir9am',ax=ax[0])\nsns.countplot(data=rain,x='WindDir3pm',ax=ax[1])\nsns.countplot(data=rain,x='WindGustDir',ax=ax[2])\nfig.tight_layout()\n","5d1e5bb5":"#Dropping date column\nrain=rain.iloc[:,1:]\nrain","18811256":"le = preprocessing.LabelEncoder()\nrain['Location'] = le.fit_transform(rain['Location'])\nrain['WindDir9am'] = le.fit_transform(rain['WindDir9am'])\nrain['WindDir3pm'] = le.fit_transform(rain['WindDir3pm'])\nrain['WindGustDir'] = le.fit_transform(rain['WindGustDir'])\n\n","7de0bf00":"rain.head(5)","5688b424":"plt.figure(figsize=(15,15))\nax = sns.heatmap(rain.corr(), square=True, annot=True, fmt='.2f')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)          \nplt.show()","a56b165f":"fig, ax =plt.subplots(2,1)\nplt.figure(figsize=(10,10))\nsns.boxplot(rain['Humidity3pm'],orient='v',color='c',ax=ax[0])\nsns.boxplot(rain['Humidity9am'],orient='v',color='c',ax=ax[1])\nfig.tight_layout()\n","cd45f60e":"fig, ax =plt.subplots(2,1)\nplt.figure(figsize=(10,10))\nsns.boxplot(rain['Pressure3pm'],orient='v',color='c',ax=ax[0])\nsns.boxplot(rain['Pressure9am'],orient='v',color='c',ax=ax[1])\nfig.tight_layout()\n","5bfe3709":"\nsns.violinplot(x='RainToday',y='MaxTemp',data=rain,hue='RainTomorrow')\n","8465a3d7":"sns.violinplot(x='RainToday',y='MinTemp',data=rain,hue='RainTomorrow')\n","81e3e828":"print('Shape of DataFrame Before Removing Outliers', rain.shape )\nrain=rain[(np.abs(stats.zscore(rain)) < 3).all(axis=1)]\nprint('Shape of DataFrame After Removing Outliers', rain.shape )\n","3645ae94":"rain=rain.drop(['Temp3pm','Temp9am','Humidity9am'],axis=1)\nrain.columns","f653768e":"\nos = SMOTE()\nx, y = os.fit_resample(rain.iloc[:,:-1], rain.iloc[:,-1])\ncount = Counter(y)\nprint(count)","7a3e706f":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","3f2f6fac":"model = LogisticRegression(max_iter=500)\nmodel.fit(x_train, y_train)\npredicted=model.predict(x_test)\n\nconf = confusion_matrix(y_test, predicted)\nprint (\"The accuracy of Logistic Regression is : \", accuracy_score(y_test, predicted)*100, \"%\")\nprint()\nprint(\"F1 score for logistic regression is :\",f1_score(y_test, predicted,)*100, \"%\")\n","83d36064":"xgbc = XGBClassifier(objective='binary:logistic')\nxgbc.fit(x_train,y_train)\npredicted = xgbc.predict(x_test)\nprint (\"The accuracy of Logistic Regression is : \", accuracy_score(y_test, predicted)*100, \"%\")\nprint()\nprint(\"F1 score for XGBoost is :\",f1_score(y_test, predicted,)*100, \"%\")\n","cea68aaf":"model = GaussianNB()\nmodel.fit(x_train, y_train)\n  \npredicted = model.predict(x_test)\n  \nprint(\"The accuracy of Gaussian Naive Bayes model is : \", accuracy_score(y_test, predicted)*100, \"%\")\nprint()\nprint(\"F1 score for Gaussian Naive Bayes is :\",f1_score(y_test, predicted,)*100, \"%\")\n","8d6c7be7":"model = BernoulliNB()\nmodel.fit(x_train, y_train)\n  \npredicted = model.predict(x_test)\n  \nprint(\"The accuracy of Gaussian Naive Bayes model is : \", accuracy_score(y_test, predicted)*100, \"%\")\nprint()\nprint(\"F1 score for Bernoulli Naive Bayes is :\",f1_score(y_test, predicted,)*100, \"%\")","8bd97102":"model = RandomForestRegressor(n_estimators = 100, random_state = 0)  \nmodel.fit(x_train, y_train)  \npredicted = model.predict(x_test)\nprint(\"The accuracy of Random Forest is : \", accuracy_score(y_test, predicted.round())*100, \"%\")\n","a85cd198":"# **1.9 Dealing with the missing values**","42444692":"**2.3 HeatMap**","c924cc5e":"**6 columns are of type 'object' and remaining of 'float'**","b355a182":"****2.5 Bivariate Analysis****","1e80050a":"# **2. Data Visualization**","d503206d":"**2.7 Dropping highly correlated columns**","e72a1966":"**2.6 Removing the outliers**","b0324502":"**2.8 Balancing the data using SMOTE**","66e21980":"# **1.5 Finding all the categorical and continuous values**","c9300f0a":"**3.4 Bernoulli Naive Bayes**","527844da":"**3.3 Gaussian Naive Bayes**","24962f56":"# **1.7 Visualizing the missing values**","25046658":"# **1.3 Shape of DataFrame**","f065cc1b":"**2.1 Count of rain today and tomorrow**","4df1927b":"**2.4 Boxplots**","e27259b4":"# **1.1 Reading the dataset**","69079f87":"**2.2 Direction of wind at 9 am, 3 pm.**","cc01bad2":"# **1.2 Creating DataFrame**","06fcbe82":"**3.1 Logistic Regression**","20564dc1":"The above graphs show that the number of missing values are high in: Sunshine, Evaporation, Cloud3pm and Cloud9am.","04a76356":"**Violin Plot**","3d637dd0":"# **1.6 Checking Null values**","e433243b":"# **3. Training The Models**","a88bc950":"# **1.8 Changing yes and no to 1 and 0 in some columns**","f8fa733c":"# **1. Importing the modules**","e5de4a31":"* At 9 am, it is highest for direction N.\n* At 3 pm, it is highest for direction SE.\n","876a71fa":"**All the missing values have been removed now.**","b030eec7":"**3.5 RandomForest**","0a1de42e":"**Encoding the categorical variables**","c58f2a3f":"*  MinTemp and Temp9am highly correlated.\n*  MinTemp and Temp3pm highly correlated.\n*  MaxTemp and Temp9am highly correlated.\n*  MaxTemp and Temp3pm highly correlated.\n\n*  Temp3pm and Temp9am highly correlated.\n*  Humidity9am and Humidity3pm highly correlated.","431f8172":"**2.9 Train test split**","333aaf57":"**3.2 XGBoost**","c67b58b1":"# **1.4 Describing the attributes**","e3991953":"# **1.6 Unique values**"}}