{"cell_type":{"5372ed6d":"code","a265461f":"code","f793904a":"code","a744f297":"code","d27de593":"code","d1a2015e":"code","68b200fd":"code","c6b1a32d":"code","5f33f836":"code","c1177e08":"code","175e3800":"code","96ad22df":"code","1249db63":"code","e534e81e":"markdown","e61fca1a":"markdown","9a2136ab":"markdown","73862810":"markdown","31f358d3":"markdown","4b89a33f":"markdown","9a4e64a2":"markdown","c95d24a4":"markdown","474e0dbd":"markdown","c62e7618":"markdown","bb65428e":"markdown","96d0f67f":"markdown","dbaa3619":"markdown","0a2b823a":"markdown","f677195a":"markdown","d005d532":"markdown","9b5bef6e":"markdown","c4e5f88a":"markdown","11536636":"markdown","8d36c3ea":"markdown"},"source":{"5372ed6d":"from IPython.display import Image\nImage('..\/input\/pyboard-neuroshield-neurobrick\/PyBoard_NeuroShield_NeuroBrick.png')","a265461f":"from timeit import default_timer\nfrom collections import Counter\nimport math\nimport json\nimport pandas as pd\nimport numpy as np\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\n# The following module is the desktop\/laptop side of a two-part serial communication protocol,\n# with one part running on a desktop\/laptop and the other running on a PyBoard connected by\n# USB\/serial. Its import is commented out here, since the Kaggle environment has no knowledge\n# of it, and even if it did, there is no PyBoard physically connected to which to connect.\n\n# Commented out since this demonstrative code cannot actually be run on Kaggle\n# from PyBoard_NeuroShield_serial_port_interface import *","f793904a":"%%time\n\nwith open('..\/input\/ships-in-satellite-imagery\/shipsnet.json') as data_file:\n    dataset = json.load(data_file)\nshipsnet= pd.DataFrame(dataset)\nprint(shipsnet.shape)\nprint(shipsnet.columns)\nprint(shipsnet['data'][0:5])\n\ndata = np.array(dataset['data']).astype('uint8')\nlabels = np.array(dataset['labels']).astype('uint8')\ndata = data.reshape([-1, 3, 80, 80]).transpose([0,2,3,1])\nprint(shipsnet.shape)","a744f297":"%%time\n\ndata_prepared = pd.DataFrame(columns=['label', 'image'])\n\nCULL_INTERVAL = 1  # For quick experiments, only use a subset of the images\nFIGSIZE = 20\nDISPLAY_IMAGES = True\nDRAW_INTERVAL = 200  # How often should a sample image be shown\n\nlabel_counts = Counter()\nfor img_idx, img_rgb in enumerate(data):\n    if img_idx % CULL_INTERVAL != 0:\n        continue\n    if len(data_prepared) % DRAW_INTERVAL == 0:\n        print(\"Progress: {:>8} of {:>8} {:>8}\".format(img_idx, len(data), len(data_prepared)))\n    \n    label = labels[img_idx]\n    label_counts[label] += 1\n    \n    # Convert to normalized grayscale\n    img_gray = np.mean(img_rgb, axis=2)\n    img_gray -= img_gray.min()\n    img_gray \/= img_gray.max() \/ 255\n    \n    # Calculate the magnitude spectrum in decibels, which seems to give the best orientation results\n    img_fft = np.fft.fftshift(np.fft.fft2(img_gray))\n    img_ms = 20 * np.log(np.abs(img_fft))\n    \n    # Mask the power spectrum to a circle as opposed to the default square so as to accumulate a fair amount of energy at all angles\n    # Also, mask out the DC term. It's a distraction that can corrupt the orientation calculation.\n    height_half_2 = (img_ms.shape[0] \/ 2)**2\n    for y in range(80):\n        for x in range(80):\n            r2 = (y-40)**2 + (x-40)**2\n            if (x == 40 and y == 40) or r2 > height_half_2:\n                img_ms[y][x] = 0\n    \n    # Accumulate the value for every spectrum pixel into an angular bin.\n    # The goal here is to find the \"ray\" through the center of the spectrum with the brightest accumulation of values.\n    # That ray will indicate the image's primary orientation.\n    height, width = img_ms.shape\n    height_half, width_half = height \/ 2, width \/ 2\n    height_quarter_2 = (height \/ 4)**2\n    img_gray_polar = np.zeros([181, 181])\n    img_gray_polar_counts = [0] * 181\n    for y in range(height):\n        for x in range(width):\n            y_shift = round(y - height_half)\n            x_shift = round(x - width_half)\n            r2 = y_shift**2 + x_shift**2\n            if r2 > height_quarter_2:\n                continue\n            angle = math.atan2(y_shift, x_shift) * (180. \/ math.pi) + 180\n            if angle >= 180:\n                angle -= 180  # For orientation, we only need 180 degrees, not 360\n            angle_bin = round(angle)\n            img_gray_polar[180][angle_bin] += img_ms[y][x]\n            img_gray_polar_counts[angle_bin] += 1\n    for x in range(181):\n        if img_gray_polar_counts[x] > 0:\n            img_gray_polar[180][x] \/= img_gray_polar_counts[x]\n    img_gray_polar \/= img_gray_polar.max() \/ 255\n    img_gray_polar = img_gray_polar.round()\n    for x in range(181):\n        for y in range(160, 180):\n            img_gray_polar[y][x] = img_gray_polar[180][x]\n        for yy in range(10):\n            img_gray_polar[160 - yy - int(round(img_gray_polar[180][x] * (150 \/ 255)))][x] = img_gray_polar[180][x]\n    max_loc = np.unravel_index(img_gray_polar.argmax(), img_gray_polar.shape)\n    rot_angle_2 = max_loc[1]\n    \n    # This isn't very important, but there is no point in rotating more than 90 degrees\n    if rot_angle_2 >= 90:\n        rot_angle_2 = -180 + rot_angle_2\n    \n    # Rotate the image to align its central orientation vertically\n    img_rot = scipy.ndimage.rotate(img_rgb, rot_angle_2, reshape=False, mode='nearest')\n    \n    # Recalculate the grayscale image\n    img_rot_gray = np.mean(img_rot, axis=2)\n    img_rot_gray -= img_rot_gray.min()\n    img_rot_gray \/= img_rot_gray.max() \/ 255\n    \n    # Downsample to 16x16 pixels\n    img_rot_gray_16x16 = scipy.ndimage.zoom(img_rot_gray, .2, order=3)\n    img_rot_gray_256 = img_rot_gray_16x16.flatten().round().astype(np.int64)\n    img_rot_gray_256 -= img_rot_gray_256.min()\n    img_rot_gray_256_norm = np.divide(img_rot_gray_256, np.max(img_rot_gray_256) \/ 255).astype(np.int64)\n    \n    # Store the prepared image\n    data_prepared = data_prepared.append({'label': label, 'image': img_rot_gray_256_norm}, ignore_index=True)\n        \n    # Draw the images\n    if DISPLAY_IMAGES and img_idx % DRAW_INTERVAL == 0:\n        fig, (ax_rgb, ax_gray, ax_freq, ax_polar, ax_rot, ax_gray_16) = plt.subplots(1, 6)\n\n        fig.set_figwidth(FIGSIZE)\n        fig.set_figheight(FIGSIZE)\n        \n        ax_rgb.axis('off')\n        ax_gray.axis('off')\n        ax_freq.axis('off')\n        ax_polar.axis('off')\n        ax_rot.axis('off')\n        ax_gray_16.axis('off')\n\n        ax_rgb.imshow(img_rgb, vmax=255)\n        ax_gray.imshow(img_gray, cmap='gray', vmax=255)\n        ax_freq.imshow(img_ms, cmap='gray')\n        ax_polar.imshow(img_gray_polar, cmap='rainbow', vmax=255)\n        ax_rot.imshow(img_rot_gray, cmap='gray', vmax=255)\n        ax_gray_16.imshow(img_rot_gray_16x16, cmap='gray', vmax=255)\n\nprint(\"Final data count: {}\".format(len(data_prepared)))\nprint(\"Label counts: {}\".format(label_counts.most_common()))","d27de593":"%%time\n\ndef shuffle(df, seed=None):\n    return df.reindex(np.random.RandomState(seed=seed).permutation(df.index))\n\ndef split_train_test(df, random_state=None, test_size=0.2):\n    test_data = pd.DataFrame(columns=['label', 'image'])\n    train, test = train_test_split(df, test_size=test_size, random_state=random_state)\n    return train, test\n\ndef split_labels(df):\n    df_true = df.loc[df['label'] == True]\n    df_false = df.loc[df['label'] == False]\n    return df_true, df_false\n\n# Fix the random see so we can maintain consistency between repeated runs\nRANDOM_SEED = 1\n\ndata_shuffled = shuffle(data_prepared, RANDOM_SEED)\ndata_train, data_test = split_train_test(data_shuffled, RANDOM_SEED)\ndata_train_true, data_train_false = split_labels(data_train)\ndata_test_true, data_test_false = split_labels(data_test)\n\nprint(\"PREPARED ({})\".format(len(data_prepared)))\nprint(\"SHUFFLED ({})\".format(len(data_shuffled)))\nprint(\"TRAIN ({})\".format(len(data_train)))\nprint(\"TEST ({})\".format(len(data_test)))\nprint(\"TRAIN TRUE ({})\".format(len(data_train_true)))\nprint(\"TRAIN FALSE ({})\".format(len(data_train_false)))\nprint(\"TEST TRUE ({})\".format(len(data_test_true)))\nprint(\"TEST FALSE ({})\".format(len(data_test_false)))","d1a2015e":"# Commented out since this demonstrative code cannot actually be run on Kaggle\n# init_pyboard_serial_connection()","68b200fd":"from timeit import default_timer\n\ndef train_network_method_1(start_start_id, max_rows, data):\n    \"\"\"\n    Send training examples to the network, one by one.\n    Positive examples will either be added to the network if they lie outside the active\n    influence fields of all previously stored positive examples, or will be discarded.\n    Negative examples will shrink the active influence fields of all overlapping stored\n    positive examples.\n    \"\"\"\n    start_time = default_timer()\n    set_compression(True)\n    \n    verbose_level = get_verbose_level()\n    print(\"< verbose_level: {}\".format(verbose_level))\n    \n    # Send the training (learning) data\n    columns = data.columns\n    labels = data[columns[0]]\n    rows = data[columns[1:]]\n    \n    labels_np = np.array(labels)\n    rows_np = np.array(rows)\n    \n    print(\"< Num rows available: {}\".format(len(rows_np)))\n    \n    for start_id in range(start_start_id, len(data), max_rows):\n        status_found = False\n        for attempt in range(0, 2):\n            print(\"< \" + \"=\" * 100)\n            print(\"< start_id: {}\".format(start_id))\n\n            start_time_one_batch = default_timer()\n\n            num_rows_sent = 0\n            for i in range(len(rows_np)):\n                if i < start_id:\n                    continue\n                if num_rows_sent >= max_rows:\n                    break\n\n                learn_one_pattern(i + 1, context, 1 if labels_np[i] else 0, rows_np[i][0], False)\n                num_rows_sent += 1\n\n            if verbose_level >= 1:\n                print(\"< Num rows sent: {}\".format(num_rows_sent))\n                print(\"< \" + \"_\" * 100)\n                print(\"< Flushing last bundle\")\n\n            finalize_bundle()\n\n            if verbose_level >= 2:\n                print(\"< \" + \"_\" * 100)\n                print(\"< Resending messages as necessary\")\n\n            status_found, response = resend_messages_as_necessary(\"Learning pattern #{}\".format(start_id + num_rows_sent), 1, \"Learning pattern\")\n            print(\"< status_found: {}\".format(status_found))\n            if verbose_level >= 2:\n                print(\"< Response:\\n{}\".format(response.replace(\"\\n> \", \"\\n] \")))\n\n            end_time_one_batch = default_timer()\n            elapsed_time_one_batch = end_time_one_batch - start_time_one_batch\n            print(\"< Elapsed time one batch: {}\".format(elapsed_time_one_batch))\n            \n            if status_found:\n                break\n            else:\n                print(\"< Stale, trying one more time.\")\n        if not status_found:\n            break\n    \n    end_time = default_timer()\n    elapsed_time = end_time - start_time\n    print(\"< Elapsed time: {}\".format(elapsed_time))","c6b1a32d":"def write_true_data_to_network(start_start_id, end_id, max_rows, reset):\n    \"\"\"\n    Write all positive training examples directly to the network, ignoring overlapping active\n    influence fields.\n    They will be stored with the default maximum AIF.\n    The AIFs will later be shrunk in a second pass by exposing the network to negative\n    training examples.\n    \n    Parameters:\n        start_start_id (int): Training sample id from which to begin training enumeration\n        end_id (int): Training sample id at which to end training enumeration\n        max_rows (int): The PyBoard's serial buffer can overflow, so only send a few rows at a time\n    \"\"\"\n    start_time = default_timer()\n    \n    set_compression(True)\n    \n    verbose_level = get_verbose_level()\n    print(\"< verbose_level: {}\".format(verbose_level))\n    \n    # Send the training (learning) data\n    columns = data_train_true.columns\n    labels = data_train_true[columns[0]]\n    rows = data_train_true[columns[1:]]\n    \n    labels_np = np.array(labels)\n    rows_np = np.array(rows)\n    \n    print(\"< Num rows available: {}\".format(len(rows_np)))\n    \n    for start_id in range(start_start_id, end_id, max_rows):\n        print(\"< \" + \"=\" * 100)\n        print(\"< start_id: {}\".format(start_id))\n        num_rows_sent = 0\n        for i in range(len(rows_np)):\n            if i < start_id:\n                continue\n            if num_rows_sent >= max_rows:\n                break\n\n            write_one_pattern(i + 1, context, 1 if labels_np[i] else 0, rows_np[i][0], reset)\n            reset = False  # At most, only reset for the very first pattern\n            num_rows_sent += 1\n\n        if verbose_level >= 1:\n            print(\"< Num rows sent: {}\".format(num_rows_sent))\n            print(\"< \" + \"_\" * 100)\n            print(\"< Flushing last bundle\")\n\n        finalize_bundle()\n\n        if verbose_level >= 2:\n            print(\"< \" + \"_\" * 100)\n            print(\"< Resending messages as necessary\")\n\n        status_found, response = resend_messages_as_necessary(\"Writing pattern #{}\".format(start_id + num_rows_sent), 1, \"Writing pattern\")\n        print(\"< status_found: {}\".format(status_found))\n        if verbose_level >= 2:\n            print(\"< Response:\\n{}\".format(response.replace(\"\\n> \", \"\\n] \")))\n    \n    end_time = default_timer()\n    elapsed_time = end_time - start_time\n    print(\"< Elapsed time: {}\".format(elapsed_time))","5f33f836":"%%time\n\nstart_id = 0\n# Commented out since this demonstrative code cannot actually be run on Kaggle\n# write_true_data_to_network(start_id, end_id=len(data_train_true), max_rows=50, reset=(start_id==0))","c1177e08":"%%time\n\n# Commented out since this demonstrative code cannot actually be run on Kaggle\n# train_network_method_1(0, 100, data_train_false)","175e3800":"def get_classifications(start_id, max_num_rows_to_classify):\n    \"\"\"\n    Send query patterns to the NM500 and get a response string back,\n    but don't parse the classifications (labels) out of the string\n    \n    Parameters:\n        start_id (int): Training sample id from which to begin query enumeration\n        max_num_rows_to_classify (int): The PyBoard's serial buffer can overflow, so only send a few rows at a time\n    \"\"\"\n    start_time = default_timer()\n    \n    rows_available = len(data_test)\n    max_num_rows_to_classify = min(max_num_rows_to_classify, rows_available)\n    verbose_level = get_verbose_level()\n    if verbose_level >= 0:\n        print(\"< Start id: {}\".format(start_id))\n        print(\"< Num rows to classify: {}\".format(max_num_rows_to_classify))\n    \n    # Classify the test data\n    queries = []\n    columns = data_test.columns\n    labels = data_test[columns[0]]\n    rows = data_test[columns[1:]]\n    labels_np = np.array(labels)\n    rows_np = np.array(rows)\n    \n    for i in range(len(rows_np)):\n        if i < start_id:\n            continue\n\n        label = labels_np[i]\n\n        if verbose_level >= 2:\n            print(\"< Classifying #{:>3}, Cxt {}, GT lbl {}\".format(len(queries) + 1, context, label))\n        \n        classify_one_pattern(i + 1, context, rows_np[i][0])\n        queries.append((context, label))\n\n        if len(queries) >= max_num_rows_to_classify:\n            break\n\n    if verbose_level >= 1:\n        print(\"< Flushing last bundle\")\n    \n    finalize_bundle()\n\n    status_found, response = resend_messages_as_necessary(\"Classification result #{}\".format(start_id + len(queries)), 1, \"Classifying pattern\")\n    print(\"< status_found: {}\".format(status_found))\n    if verbose_level >= 2:\n        print(\"< Response:\\n{}\".format(response.replace(\"\\n> \", \"\\n] \")))\n    \n    end_time = default_timer()\n    elapsed_time = end_time - start_time\n    print(\"< Classification elapsed time:   {:5.5}s ({:5.5}m)\".format(elapsed_time, elapsed_time \/ 60.))\n    \n    return response, queries\n\ndef analyze_performance(response, queries, accumulating_result=None):\n    \"\"\"\n    Parse query classifications (labels) out of a response string returned by the PyBoard as received from the NM500.\n    Pair the labels up with the queries and, assuming the queries included ground-truth labels (i.e., test queries as opposed to in-the-wild queries),\n    compute performance statistics of the network against the test dataset.\n    \n    Parameters:\n        accumulating_result (list): Since we must send queries in small batches to protect the PyBoard's serial buffer from overflowing,\n            we must accumulate the results from multiple batches together for final statistical analysis.\n    \"\"\"\n    verbose_level = get_verbose_level()\n    if verbose_level >= 3 or \"Exception\" in response or \"Error\" in response:\n        print(response)\n    \n    groups = response.split(\"Classification result\")\n    \n    num_queries = len(queries)\n\n    num_test_events = accumulating_result[0] if accumulating_result else 0\n    num_test_nonevents = accumulating_result[1] if accumulating_result else 0\n    tp = accumulating_result[3] if accumulating_result else 0\n    tn = accumulating_result[4] if accumulating_result else 0\n    fp = accumulating_result[5] if accumulating_result else Counter()\n    fn = accumulating_result[6] if accumulating_result else Counter()\n    \n    for i, group in enumerate(groups):\n        if i == 0:\n            pass\n        if i > num_queries:\n            print(\"Too many groups: {}\".format(group))\n            continue\n        query = queries[i - 1]\n\n        lines = group.split('\\n') if response else []\n        for line in lines:\n            if \"Category=\" in line:\n                if query[1] != 0:\n                    num_test_events += 1\n                else:\n                    num_test_nonevents += 1\n\n                words = line.split()\n                category = int(words[6])\n                if category == 65535:\n                    category = 0\n                elif category & 1 << 15:\n                    # NM500's degenerate neuron flag (fully shrunk AIF)\n                    category &= 0x7FFF\n                reverse_label = category\n                if reverse_label == query[1]:\n                    if query[1] == 0:\n                        tn += 1\n                        if verbose_level >= 2:\n                            print(\"< #{:>3}    Cxt {}    GT lbl {} == {} (cat {})   TN\".format(i, query[0], query[1], reverse_label, category))\n                    else:\n                        tp += 1\n                        if verbose_level >= 2:\n                            print(\"< #{:>3}    Cxt {}    GT lbl {} == {} (cat {}) TP\".format(i, query[0], query[1], reverse_label, category))\n                else:\n                    if query[1] == 0:\n                        fp[(query[1], reverse_label)] += 1\n                        if verbose_level >= 2:\n                            print(\"< #{:>3}    Cxt {}    GT lbl {} != {} (cat {})     FP\".format(i, query[0], query[1], reverse_label, category))\n                    else:\n                        fn[(query[1], reverse_label)] += 1\n                        if verbose_level >= 2:\n                            print(\"< #{:>3}    Cxt {}    GT lbl {} != {} (cat {})       FN\".format(i, query[0], query[1], reverse_label, category))\n\n    if accumulating_result:\n        num_queries += accumulating_result[2]\n                            \n    fp_total = sum(fp.values())\n    fn_total = sum(fn.values())\n    accuracy = (tp + tn) \/ num_queries if num_queries != 0 else math.nan\n    error = (fp_total + fn_total) \/ num_queries if num_queries != 0 else math.nan\n    precision = tp \/ (tp + fp_total) if (tp != 0 or fp_total != 0) else math.nan\n    recall = tp \/ (tp + fn_total) if (tp != 0 or fn_total != 0) else math.nan\n    specificity = tn \/ (tn + fp_total) if (tn != 0 or fp_total != 0) else math.nan\n\n    result = (num_test_events, num_test_nonevents, num_queries, tp, tn, fp, fn, accuracy, error, precision, recall, specificity)\n    return result\n    \ndef classify(start_id, max_num_rows_to_classify, accumulating_result=None):\n    \"\"\"\n    Classify a set of queries, analyze the performance of those classifications against test ground-truth labels,\n    and accumulate statistical performance metrics.\n    \"\"\"\n    response, queries = get_classifications(start_id, max_num_rows_to_classify)\n    result = analyze_performance(response, queries, accumulating_result)\n    return result","96ad22df":"%%time\n\nstart_start_id = 0\nmax_rows = 200  # The PyBoard's serial buffer can overflow, so only send a few rows at a time\n\naccumulating_result = None\n\nfor start_id in range(start_start_id, len(data_test), max_rows):\n    start_time = default_timer()\n\n    print(\"< \" + \"=\" * 100)\n    print(\"< start_id: {}\".format(start_id))\n    \n    # Commented out since this demonstrative code cannot actually be run on Kaggle\n    # accumulating_result = classify(start_id, max_rows, accumulating_result)\n    print(\"< Accumulating result: {}\".format(accumulating_result))\n    \n    end_time = default_timer()\n    elapsed_time = end_time - start_time\n    print(\"< One experiment elapsed time:   {:5.5}s ({:5.5}m)\".format(elapsed_time, elapsed_time \/ 60.))\n\nprint()","1249db63":"num_test_events, num_test_nonevents, num_queries, tp, tn, fp, fn, accuracy, error, precision, recall, specificity \\\n    = accumulating_result\n\nfp_total = sum(fp.values())\nfn_total = sum(fn.values())\n\ns = \"\"\n#     s += \"\\n< Max    train events & nonevents: {:>5}, {:>5}    (user-specified max, but may exceed data availability)\".format(max_events, max_nonevents)\n#     s += \"\\n< Actual train events & nonevents: {:>5}, {:>5}    ({:>5} total)\".format(num_train_events, num_train_nonevents, num_train_events + num_train_nonevents)\n#     s += \"\\n< Max and actual classifications:  {:>5}           ({:>5} actual)\".format(num_classifications, num_queries)\ns += \"\\n< Actual test events & nonevents: {} + {} = {} total\".format(num_test_events, num_test_nonevents, num_test_events + num_test_nonevents)\ns += \"\\n\"\ns += \"\\n< TP:          {:>5} (out of {})\".format(tp, num_queries)\ns += \"\\n< TN:          {:>5} (out of {})\".format(tn, num_queries)\ns += \"\\n< FP:          {:>5} (out of {})\".format(fp_total, num_queries)\ns += \"\\n< FN:          {:>5} (out of {})\".format(fn_total, num_queries)\ns += \"\\n\"\nfor k, v in fp.items():\n    s += \"\\n< FP ({}) => {}: {:>5} (out of {})\".format('T' if k[0] else 'F', k[1], v, num_queries)\nfor k, v in fn.items():\n    s += \"\\n< FN ({}) => {}: {:>5} (out of {})\".format('T' if k[0] else 'F', k[1], v, num_queries)\ns += \"\\n\"\ns += \"\\n< TP+TN:       {:>5} (out of {}, correct overall, aka accuracy)\".format(tp + tn, num_queries)\ns += \"\\n< FP+FN:       {:>5} (out of {}, incorrect overall, aka error)\".format(fp_total + fn_total, num_queries)\ns += \"\\n\"\ns += \"\\n< Accuracy:    {:>5.4}% [(TP+TN)\/TOTAL] (correct classification regardless of pos.\/neg.)\".format(accuracy * 100)\ns += \"\\n< Error:       {:>5.4}% [(FP+FN)\/TOTAL] (incorrect classification regardless of pos.\/neg.)\".format(error * 100)\ns += \"\\n< Precision:   {:>5.4}% [TP\/(TP+FP)]    (pos. predictive value, or how informative is a TP prediction)\".format(precision * 100)\ns += \"\\n< Recall:      {:>5.4}% [TP\/(TP+FN)]    (true pos. rate, % of pos. cases actually discovered, aka sensitivity & hit rate)\".format(recall * 100)\ns += \"\\n< Specificity: {:>5.4}% [TN\/(TN+FP)]    (true neg. rate, % of neg. cases actually discovered)\".format(specificity * 100)\n\nprint(s)","e534e81e":"# Ships in Satellite Imagery by neuromorphic chip","e61fca1a":"# Discussion\n\nAs we can see above, this initial experiment achieved about 97% accuracy, including a 0% false-negative rate (Type II errors), indicating that no true ships were rejected as nonships. All errors consisted of nonship images that were incorrectly classified as ships (false-positives, or Type I errors). This sort of error would be alleviated with a greater supply of negative training examples, so as to further shrink the active influence fields (AIFs) of the network's neurons. But of course doing so would run the risk of increasing the false negative rate since shrinking the neurons' AIFs might push some true cases outside the radii of the network's neurons.\n\nAlso, refer back to the initial processing of the images, which shows how much information we had to throw away to fit the images into the NM500's 256-byte pattern. We could likely improve performance by preparing the data in different ways with an eye toward preserving the high-resolution or color information of the original images, as discussed below.","9a2136ab":"## This notebook does not demonstrate an experiment that can be run on Kaggle's platform because it relies on additional hardware, namely a neuromorphic chip and any supporting interface infrastructure. This is all explained below. Rather, this notebook serves as a presentation of the discussed method, along with a walkthrough from a fully deployed system.","73862810":"General Vision's architecture supports patterns of up to 256 bytes. This is a pretty small pattern size. The images in the *Ships in Satellite Imagery* dataset are 80x80 pixels of 3-byte color for an uncompressed size of 19,200 bytes, 75 times larger than the NM500 can accommodate. There are multiple ways to handle this problem. More complex solutions might break the image into tiles, classify the tiles independently, and apply a vote or merge to combine the tile classifications into a final classification. However, the simplest approach is to fit the entire image into a single pattern somehow. For this experiment, we will flatten the color channels into a single channel (average the channels into a grayscale image) and downsample from 80x80 to 16x16. The resulting images will lack much of the potentially useful information and detail of the original images, yet rather remarkably, we will achieve 96%-97% accuracy anyway.","31f358d3":"Here is a photo of the hardware used in this experiment. At the bottom we see a PyBoard. At the top we see a NeuroShield with a single NeuroBrick attached to it (the much smaller board suspended above the main board with a green LED glowing beneath it). The two tiny black squares on the NeuroBrick are two additional NM500 chips, while the tiny ports at both ends of the NeuroBrick illustrate how multiple NeuroBricks can be layered up on the NeuroShield. The wires connecting the two larger boards form a SPI connection, while both boards are also connected by USB to the desktop (although as explained above, the NeuroShield is only using USB for power, not communications).","4b89a33f":"The images will be transformed in a number of ways. As described above, the NM500 stores and compares patterns of up to 256 bytes so, aside from the tiling approach briefly proposed above, the only remaining option is to transform the images to a 256 byte representation. This will be accomplished by converting 3-byte color to 1-byte grayscale and downsampling 80x80 pixels to 16x16 pixels. Obviously, this transformation will destroy much of the useful classification information offered by the images. In order to alleviate the problems posed by such drastic information-erasure, we will perform another transformation, namely aligning the long, thin shape of the ships to a common orientation, vertical for no particular reason. By aligning the ships to a single orientation, we can greatly reduce the variability and diversity of their representation, which will decrease false negatives in which a new image of a true ship is discarded as a nonship simply because its arbitrary orientation is not sufficiently represented in the database.","9a4e64a2":"## When the notebook is run on a system that includes the required interface module, PyBoard, and NeuroShield, we get the following output:","c95d24a4":"## Prepare the images for the NM500","474e0dbd":"## Split the data for training and testing","c62e7618":"[PyBoard](https:\/\/micropython.org\/) is a [MicroPython](https:\/\/micropython.org\/) device that is similar to Arduino and Raspberry Pi. It provides hobbyists with the basic hardware architecture of robotics or other hardware electronics projects. It has the advantage of running a version of Python called MicroPython, which (to no surprise) can run interactively in a terminal instead of relying on a compile-and-transfer development cycle as would be required for Arduino. Furthermore, some programmers are more comfortable with Python than C or C++, as Arduino utilizes.","bb65428e":"I am not including the PyBoard MicroPython code here, for reasons I can't go into much detail on (proprietary business interests and such).","96d0f67f":"## From here on down, the notebook will involve opaque serial interface calls to a USB-connected PyBoard, which in turn will pass commands on to a SPI-connected NeuroShield. The notebook will, similarly, receive responses and results back from the PyBoard and NeuroShield.\n\n## Obviously, the cells below can't be run on Kaggle, since the PyBoard interface module (see cell above with all the imports), to say nothing of the PyBoard and NeuroShield hardware, are not available in this environment.","dbaa3619":"# Future Work\n\nThere are several directions in which this initial experiment could be extended. For one thing, the performance analysis would obviously benefit from crossfold validation. I didn't bother for this cursory demonstration but any formal analysis would require that sort of additional scrutiny.\n\nThere are more creative ways of preparing and representing the ship imagery for the NM500, given the 256-byte pattern-length constraint. To preserve higher image resolution, we could pass tiles in for independent analysis, with each tile classified using a distinct subset of neurons responsible for that tile's location within an image. Subsets of neurons can be assigned in this manner with the NM500's *context* parameter. The conglomerated classifications from the tiles would then be combined via a voting or merging scheme of some sort. Similarly, instead of discarding color information as we did, color could be exploited by classifying the original RGB color channels (or an HSV or similar variant on color representation) independently with different NM500 contexts, again applying a vote or merge at the end. We could also attempt to classify the images in radically different representations, such as histograms or by including frequency domain information (Fourier transform, power spectra, wavelet transforms, etc.).\n\nIt is also possible to apply the NM500 in a multilayered network by representing each layer with a distinct NM500 neuron context, as mentioned just above. A context is a set of neurons trained on a particular type or representation of data. Different layers of a deeper network can be evaluated with independent subsets of neurons, with the output of one layer fed as input to another layer. This approach increases the chip's processing time linearly with the number of layers, but the hardware parallelism offers such a significant benefit, that we might be able to afford the overhead of a multilayered approach.","0a2b823a":"It is difficult to provide desktop\/laptop computers with SPI communications. Generally, some intermediate hardware layer is required between the computer and the SPI device. In our case, we will use the PyBoard for that purpose. It will communicate with the computer via a USB-serial line and will communicate with the NeuroShield via SPI. The NeuroShield will also be plugged in to the computer via USB, but only for power (it could just as easily be powered from a USB-converted outlet). ","f677195a":"[General Vision](http:\/\/https:\/\/www.general-vision.com\/) has brought to market a handful of simple neuromorphic chips over the years. They started with the [CM1K](https:\/\/www.general-vision.com\/chips\/cm1k\/) and have since moved on to the [NM500](https:\/\/www.general-vision.com\/chips\/nm500\/). These chips are essentially identical in function. They implement a hardware parallel simplified *Radial Basis Function Network*. The NM500 offers 576 truly parallel artificial neurons. Multiple NM500s can be combined modularly into a larger network of any multiple of 576 for practically no additional running time overhead. While the NM500 is available as a solitary IC, General Vision also offers various circuit boards that ease developer access, namely the [NeuroShield](https:\/\/www.general-vision.com\/hardware\/neuroshield\/), which is compatible with Arduino, Raspberry PI, or direct SPI communication. The NeuroShield comes with a single NM500 (576 neurons) but can be expanded with multiple [NeuroBrick](https:\/\/www.general-vision.com\/hardware\/neurobrick\/) modules as described above.","d005d532":"<pre>\n< Actual test events & nonevents: 204 + 596 = 800 total\n\n< TP:            204 (out of 800)\n< TN:            569 (out of 800)\n< FP:             27 (out of 800)\n< FN:              0 (out of 800)\n\n< FP (F) => 1:    27 (out of 800)\n\n< TP+TN:         773 (out of 800, correct overall, aka accuracy)\n< FP+FN:          27 (out of 800, incorrect overall, aka error)\n\n< Accuracy:    96.62% [(TP+TN)\/TOTAL] (correct classification regardless of pos.\/neg.)\n< Error:       3.375% [(FP+FN)\/TOTAL] (incorrect classification regardless of pos.\/neg.)\n< Precision:   88.31% [TP\/(TP+FP)]    (pos. predictive value, or how informative is a TP prediction)\n< Recall:      100.0% [TP\/(TP+FN)]    (true pos. rate, % of pos. cases actually discovered, aka sensitivity & hit rate)\n< Specificity: 95.47% [TN\/(TN+FP)]    (true neg. rate, % of neg. cases actually discovered)\n<\/pre>\n","9b5bef6e":"The next two cells load the positive training examples into the NM500 and them shrink their active influence fields (AIFs) with a subsequent exposure to the negative training examples. Note that the train\/test split and the true\/false split (positive\/negative cases) was shown above to provide 794 true training examples, which exceeds the NM500's 576 neuron capacity. This problem was alleviated by adding a single NeuroBrick to the NeuroShield, which added two additional NM500 chips to the network, for a total neuron capacity of 1728.","c4e5f88a":"There are two sets of code for this project: a Jupyter notebook running on the computer, and a MicroPython script (and some supporting imported MicroPython modules) loaded onto the PyBoard. The PyBoard code serves primarily to send and receive serial messages to and from the computer and to send and receive SPI messages to and from the NeuroShield, while the Jupyter notebook on the computer organizes, manages, and runs the ML data preprocessing, training, classification queries, and final performance analysis.","11536636":"## Open the image dataset","8d36c3ea":"## Now that the NM500 is loaded with a trained RBF network, we can classify test patterns with it"}}