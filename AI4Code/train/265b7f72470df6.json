{"cell_type":{"221400f3":"code","afbcc577":"code","de80aac3":"code","55056401":"code","54b2cb1c":"code","e6bcea23":"code","d85ab2cb":"code","e13f7689":"code","bebdbaca":"code","630dce5d":"markdown"},"source":{"221400f3":"import numpy as np #for math functions, linear algebra\nimport pandas as pd #for dataframe management, data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf","afbcc577":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()","de80aac3":"# Extracting the labels and features from the train dataset\nY_train = train.label.astype('float32')\nX_train = train.drop(labels = 'label', axis=1).astype('float32')\nX_test = test.astype('float32')\nX_train = X_train.values.reshape(-1, 28, 28, 1)\nX_train = X_train \/ 255.0\nX_test = X_test.values.reshape(-1, 28, 28, 1)\nX_test = X_test \/ 255.0\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train = x_train.reshape(-1, 28, 28, 1)\nx_train \/= 255\nx_test = x_test.reshape(-1, 28, 28, 1)\nx_test \/= 255","55056401":"from tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Activation, Dropout, BatchNormalization","54b2cb1c":"y_train = tf.keras.utils.to_categorical(y_train, 10)\nY_train = tf.keras.utils.to_categorical(Y_train, 10)\n# Configurations\nstrategy = tf.distribute.get_strategy()\nEPOCHS = 50\nBATCH_SIZE = 512 \n\n# Class to stop fitting when it needs\nclass Callback(tf.keras.callbacks.Callback):\n    def end_if(self, epoch, logs={}):\n        if (logs.get('accuracy') > 0.999):\n            print('Reached 0.99 accuracy')\n            self.model.stop_training = True\n\noptimizer = tf.keras.optimizers.Adam(\n                    learning_rate=0.001, \n                    beta_1=0.9, \n                    beta_2=0.999, \n                    epsilon=1e-07, \n                    name='Adam'\n            )\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    shear_range=15,\n    validation_split=0.25,\n    \n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.1, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=False,  # randomly flip images\n    vertical_flip=False # randomly flip images\n)\n\ntrain_generator = datagen.flow(\n    x_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    subset='training',\n)\n\nvalidation_generator = datagen.flow(\n    x_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    subset='validation',\n)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                 factor=0.1,\n                                                 patience=5,\n                                                 min_lr=0.000001,\n                                                 verbose=1)\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath='model.hdf5',\n                                                monitor='val_loss',\n                                                save_best_only=True,\n                                                save_weights_only=True,\n                                                verbose=1)","e6bcea23":"\nmodel = Sequential([\n        Flatten(input_shape=(28, 28, 1)),\n        BatchNormalization(),\n        Dense(512, activation='relu'), \n        Dropout(0.2),\n        Dense(512, activation='relu'), \n        Dropout(0.2),\n        Dense(10, activation=\"softmax\"),  \n    ])","d85ab2cb":"import time\n\ndef train_model(model):\n    start = time.time()\n    history = model.fit(\n        train_generator, \n        epochs=EPOCHS,\n        validation_data=validation_generator,\n        callbacks=[reduce_lr,checkpoint, Callback()],\n        verbose=1)\n    print(\"Total time: \", time.time() - start, \"seconds\")\n    return history\n\nmodel.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy', \n        metrics=['accuracy']\n    )\n\nwith strategy.scope():\n    if ( tf.test.is_gpu_available() ) :\n        print(\"Using '\/GPU:0'\")\n        with tf.device('\/GPU:0'):\n            history = train_model(model)\n    else:\n        history = train_model(model)","e13f7689":"import matplotlib.pyplot as plt # for graphical visualization\n%matplotlib inline\n\nmodel.load_weights('model.hdf5')\n\ndef plot_acuracy_progress(history):\n    try:\n        fig, ax = plt.subplots(1,2, figsize=(15, 5))\n        ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n        ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n        \n        ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n        ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n        \n    except Exception as e:\n        print(f\"No idea what happened: {e!r}\")\n    except BaseException as err:\n        print(f\"Unexpected {err}, {type(err)}\")\n        raise\n    finally:\n        legend = ax[0].legend(loc='best', shadow=True)\n        legend = ax[1].legend(loc='best', shadow=True)\n\nplot_acuracy_progress(history)\n\nfinal_loss, final_acc = model.evaluate(x_train,  y_train, verbose=2)\nprint(\"Model accuracy: \", final_acc, \", model loss: \", final_loss)","bebdbaca":"results = model.predict(X_test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1, 28001), name='ImageID'), results], axis=1)\nsubmission.to_csv('submission.csv', index=False)","630dce5d":"Modelization"}}