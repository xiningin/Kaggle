{"cell_type":{"2bf61374":"code","2d2d3292":"code","e4e9d361":"code","ca1c0f44":"code","de00234a":"code","a8cf29a4":"code","3286c3ea":"code","6158a2bf":"code","76d2df69":"code","047e6173":"code","9bfd97ef":"code","2da24075":"code","113428f8":"code","f2da7fd8":"code","b7f84fcd":"code","badf1d97":"code","acdb16f1":"code","aad3a974":"code","5deeb0b8":"code","57aef621":"code","552bc9ce":"code","4843549a":"code","ae38d245":"code","94c746cd":"code","b6828edd":"code","428ea01c":"code","89bc2fdc":"code","c82656e6":"code","9c1765ce":"code","13c2ab8d":"code","e9a089c4":"code","7c8f54c0":"code","44a98878":"code","02ad48c2":"code","707c426a":"code","f8c116d9":"code","c9cc950f":"code","b6444d06":"code","6da782e1":"code","9e1aad7c":"code","d1baaa06":"markdown","60b192d8":"markdown","b5ecc80b":"markdown","c2497138":"markdown","4c4b22eb":"markdown","816cbaac":"markdown","82045bb4":"markdown","5ed3d236":"markdown","2a4ae683":"markdown"},"source":{"2bf61374":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2d2d3292":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e4e9d361":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.info()","ca1c0f44":"train.describe().T","de00234a":"X = ['Female','Male']\n\nfemale = train.loc[train[\"Sex\"] == 'female']\nmale = train.loc[train[\"Sex\"] == 'male']\n\ntotal_female = len(female)\ntotal_male = len(male)\n\nSurvived = [(len(female.loc[female[\"Survived\"] == 1])\/total_female)*100,\n            (len(male.loc[male[\"Survived\"] == 1])\/total_male)*100]\nSuccumbed = [(len(female.loc[female[\"Survived\"] == 0])\/total_female)*100,\n             (len(male.loc[male[\"Survived\"] == 0])\/total_male)*100]\n  \nX_axis = np.arange(len(X))\n  \nplt.bar(X_axis - 0.2, Survived, 0.4, label = 'Survived')\nplt.bar(X_axis + 0.2, Succumbed, 0.4, label = 'Succumbed')\n  \nplt.xticks(X_axis, X)\nplt.xlabel(\"Groups\")\nplt.ylabel(\"Percentage of passengers\")\nplt.title(\"Sex of the passenger vs Survival\")\nplt.legend()\nplt.show()","a8cf29a4":"df = train\n\ndef hist(df,feature,title,color):\n    \n    sns.set(palette=color)\n    fig = plt.figure(figsize = (10,4))\n    sns.histplot(df[feature], kde=True)\n    plt.title(title)\n    plt.show()\n    \nhist(df,'Age','Age hist','RdBu')","3286c3ea":"#Children (0-14 years) - C\n#Youth (15-24 years) - Y\n#Adults (25-64 years) - A\n#Seniors (65 years and over) - S\n\ndef graphCat(female,male,xlabel,ylabel,title):\n    \n    X = ['Female','Male']\n\n    total_female = len(female)\n    total_male = len(male)\n    \n    Survived = []\n    Succumbed = []\n    \n    if(total_female == 0):\n        \n        Survived = [0,(len(male.loc[male[\"Survived\"] == 1])\/total_male)*100]  \n        Succumbed = [0,(len(male.loc[male[\"Survived\"] == 0])\/total_male)*100]\n    \n    else:\n        \n        Survived = [(len(female.loc[female[\"Survived\"] == 1])\/total_female)*100\n                        ,(len(male.loc[male[\"Survived\"] == 1])\/total_male)*100]\n        Succumbed = [(len(female.loc[female[\"Survived\"] == 0])\/total_female)*100\n                         ,(len(male.loc[male[\"Survived\"] == 0])\/total_male)*100]\n        \n    X_axis = np.arange(len(X))\n\n    plt.bar(X_axis - 0.2, Survived, 0.4, label = 'Survived')\n    plt.bar(X_axis + 0.2, Succumbed, 0.4, label = 'Succumbed')\n\n    plt.xticks(X_axis, X)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.show()\n\nfemaleC = female[female['Age'] < 15]                   \nmaleC = male[male['Age'] < 15]\n\ngraphCat(femaleC,maleC,\"Children\",\"Percentage of Children\",\"Sex of the Child vs Survival\")\n","6158a2bf":"\nfemaleY = female[(female['Age'] >= 15) & (female['Age'] < 25)]\nmaleY = male[(male['Age'] >= 15) & (male['Age'] < 25)]\n\ngraphCat(femaleY,maleY,\"Youth\",\"Number of Youths\",\"Sex of the Youth vs Survival\")","76d2df69":"\nfemaleA = female[(female['Age'] >= 25) & (female['Age'] < 65)]\nmaleA = male[(male['Age'] >= 25) & (male['Age'] < 65)]\n\ngraphCat(femaleA,maleA,\"Adults\",\"Number of Adults\",\"Sex of the Adult vs Survival\")","047e6173":"\nfemaleS = female[female['Age'] >= 65]\nmaleS = male[male['Age'] >= 65]\n\ngraphCat(femaleS,maleS,\"Senior\",\"Number of Seniors\",\"Sex of the Senior vs Survival\")","9bfd97ef":"train.plot.scatter(x = 'Survived', y = 'Fare', s = 10);","2da24075":"\ndef familyFirst(category,xlabel,ylabel,title):\n    \n    p = train.groupby(category)\n    \n    sizes_total = list(p.size())\n    num = list(p.groups.keys())  \n    \n    fam = train[train['Survived'] == 1].groupby(category)\n    sizes = list(fam.size())\n    \n    perc = []\n    \n    for i in range(len(sizes_total)):\n        \n        if i <= len(sizes)-1:\n            perc.append((sizes[i]\/sizes_total[i])*100)\n        else:\n            perc.append(0)\n    \n    \n    fig = plt.figure(figsize = (10, 5))\n    plt.bar(num, perc, color ='purple')\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.show()\n    \nfamilyFirst('SibSp','Number of Siblings\/Spouse','Fraction of passengers who survived','Family and survival')","113428f8":"\nfamilyFirst('Parch','Number of Parents\/Children','Number of passengers who survived','Family and survival')\n","f2da7fd8":"def Pclass(df,xlabel,ylabel,title):\n    \n    pc1 = df[df['Pclass'] == 1]\n    pc2 = df[df['Pclass'] == 2]\n    pc3 = df[df['Pclass'] == 3]\n\n    total_pc1 = len(pc1)\n    total_pc2 = len(pc2)\n    total_pc3 = len(pc3)\n\n    X = ['class 1','class 2','class 3']\n\n    Survived = [(len(pc1[pc1['Survived'] == 1])\/total_pc1)*100,\n                (len(pc2[pc2['Survived'] == 1])\/total_pc2)*100,\n                (len(pc3[pc3['Survived'] == 1])\/total_pc3)*100]\n\n    Succumbed = [(len(pc1[pc1['Survived'] == 0])\/total_pc1)*100,\n                 (len(pc2[pc2['Survived'] == 0])\/total_pc2)*100,\n                 (len(pc3[pc3['Survived'] == 0])\/total_pc3)*100]\n\n    X_axis = np.arange(len(X))\n\n    plt.bar(X_axis - 0.2, Survived, 0.4, label = 'Survived')\n    plt.bar(X_axis + 0.2, Succumbed, 0.4, label = 'Succumbed')\n\n    plt.xticks(X_axis, X)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.show()\n    \nPclass(train,\"Socio-economic standing\",\"Percentage of passengers\",\"Socio-economic status vs Survival\")","b7f84fcd":"Pclass(female,\"Socio-economic standing\",\"Percentage of passengers\",\"Socio-economic status vs Survival\")","badf1d97":"emb_surv = train[train['Survived'] == 1].groupby('Embarked')\nsurv = list(emb_surv.size())\n\ntotal = list(train.groupby('Embarked').size())\n\nX = ['C','Q','S']\n\nperc_surv = []\n\nfor i in range(len(total)):\n    \n    survived = int(surv[i])\n    tot = int(total[i])\n    percentage = (survived\/tot)*100\n    \n    perc_surv.append(percentage)\n    \nfig, ax = plt.subplots(1)\nax.bar(X, perc_surv, color ='purple')\nax.set(xlabel='Embarked at', ylabel='Survival Rate')\n","acdb16f1":"sns.boxplot(train['Fare'])","aad3a974":"train.head()","5deeb0b8":"test = pd.read_csv('..\/input\/titanic\/test.csv')\ntest.head()","57aef621":"print(\"Numerical features in\")\nprint('train df')\nnumf_train = [feature for feature in list(train.columns) if ((train[feature].dtype == int) or (train[feature].dtype == float))]\nprint(numf_train)\nprint('test df')\nnumf_test = [feature for feature in list(test.columns) if ((test[feature].dtype == int) or (test[feature].dtype == float))]\nprint(numf_test)","552bc9ce":"print(\"Non-numerical features in\")\nprint('train df')\nnonnumf_train = [feature for feature in list(train.columns) if (train[feature].dtype == object)]\nprint(nonnumf_train)\nprint('test df')\nnonnumf_test = [feature for feature in list(test.columns) if (train[feature].dtype == object)]\nprint(nonnumf_test)\n","4843549a":"print('Numerical features with NaN in')\nprint('train df')\nnumf_train_NaN = [feature for feature in numf_train if train[feature].isnull().sum() > 0]\nprint(numf_train_NaN)\nprint('test df')\nnumf_test_NaN = [feature for feature in numf_test if test[feature].isnull().sum() > 0]\nprint(numf_test_NaN)","ae38d245":"print('Non-numerical features with NaN in')\nprint('train df')\nnonnumf_train_NaN = [feature for feature in nonnumf_train if train[feature].isnull().sum() > 0]\nprint(nonnumf_train_NaN)\nprint('test df')\nnonnumf_test_NaN = [feature for feature in nonnumf_test if test[feature].isnull().sum() > 0]\nprint(nonnumf_test_NaN)","94c746cd":"from sklearn.impute import SimpleImputer\n\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n\nfor feature in numf_train_NaN:\n    imp_mean = imp_mean.fit(train[feature].values.reshape(-1,1))\n    train[feature] = imp_mean.transform(train[feature].values.reshape(-1,1))\n    \nfor feature in numf_test_NaN:\n    imp_mean = imp_mean.fit(test[feature].values.reshape(-1,1))\n    test[feature] = imp_mean.transform(test[feature].values.reshape(-1,1))\n\nfor feature in nonnumf_train_NaN:\n    imp_mode = imp_mode.fit(train[feature].values.reshape(-1,1))\n    train[feature] = imp_mode.transform(train[feature].values.reshape(-1,1))\n    \nfor feature in nonnumf_test_NaN:\n    imp_mode = imp_mode.fit(test[feature].values.reshape(-1,1))\n    test[feature] = imp_mode.transform(test[feature].values.reshape(-1,1))\n","b6828edd":"sns.heatmap(train.isnull(), cbar=False)","428ea01c":"sns.heatmap(test.isnull(), cbar=False)","89bc2fdc":"#train['Name'].values","c82656e6":"def extractNameComponents(df):  \n    \n    lastList = []\n    honorificList = []\n\n    for string in list(df['Name']):\n        \n        first_split = string.split(\", \")\n        lastList.append(first_split[0])\n        \n        second_split = first_split[1].split(\" \")\n        honorificList.append(second_split[0])\n\n       \n    return lastList,honorificList\n        \nlastList,honorificList = extractNameComponents(train)\n\ns_last = pd.Series(lastList, index=np.arange(891))\ntrain.insert(len(train.columns)-1, 'Last Name', s_last.values)\n\ns_honorific = pd.Series(honorificList, index=np.arange(891))\ntrain.insert(len(train.columns)-1, 'Honorific', s_honorific.values)     \n\n\ntrain = train.drop(['Name'],axis=1)","9c1765ce":"lastList,honorificList = extractNameComponents(test)\n\ns_last = pd.Series(lastList, index=np.arange(418))\ntest.insert(len(test.columns)-1, 'Last Name', s_last.values)\n\ns_honorific = pd.Series(honorificList, index=np.arange(418))\ntest.insert(len(test.columns)-1, 'Honorific', s_honorific.values)     \n\ntest = test.drop(['Name'],axis=1)","13c2ab8d":"#train['Last Name'].value_counts().to_dict()\n#train['Honorific'].value_counts()","e9a089c4":"#test['Last Name'].value_counts().to_dict()\n#test['Honorific'].value_counts()","7c8f54c0":"#sns.set(rc={'figure.figsize':(15,5)})\n#sns.histplot(data=train, x=\"Honorific\")\n\nfig, ax = plt.subplots(figsize=(15,8))\n\nfor a in [train, train[train['Survived'] == 1]]:\n    sns.histplot(a, x = 'Honorific', ax=ax, kde=False)\n","44a98878":"f,axes = plt.subplots(1,2,figsize=(10,4))\nsns.distplot(x=train['Age'],ax=axes[0])\nsns.distplot(x=train['Fare'],ax=axes[1])\n\nplt.tight_layout()","02ad48c2":"y = train['Survived']\ntrain = train.drop('Survived',axis=1)\ntrain = train.drop('Embarked',axis=1)\ntest = test.drop('Embarked',axis=1)\n\nsub2 = test['PassengerId']","707c426a":"overall = pd.concat([train.assign(ind=\"train\"),test.assign(ind=\"test\")])\noverall.reset_index(inplace=True, drop=True)\n","f8c116d9":"from sklearn.preprocessing import OneHotEncoder\n\n# creating instance of one-hot-encoder\nenc = OneHotEncoder(handle_unknown='ignore')\n\nto_encode = ['Sex','Ticket','Cabin','Last Name','Honorific']\n\ndef encode_and_join(df,to_encode,enc):\n    \n    for feature in to_encode:        \n\n        enc.fit(df[feature].values.reshape(-1,1))\n        new = pd.DataFrame(enc.transform(df[feature].values.reshape(-1,1)).toarray())\n        new.columns = enc.get_feature_names([feature])\n        df = pd.concat([df,new],axis=1)\n        df.drop(feature, inplace=True, axis=1)\n        \n    return df\n\n        \noverall = encode_and_join(overall,to_encode,enc)\n\noverall","c9cc950f":"test, train = overall[overall[\"ind\"].eq(\"test\")], overall[overall[\"ind\"].eq(\"train\")]\ntrain = train.drop(['ind'],axis=1)\ntest = test.drop(['ind'],axis=1)\ntest.reset_index()\ntrain","b6444d06":"'''\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.decomposition import PCA\n\npca = PCA()\n\npipe_lr = Pipeline(steps=[(\"pca\", pca), (\"lr\", LogisticRegression(solver='liblinear',penalty='l2'))])\npipe_rf = Pipeline(steps=[(\"pca\", pca), (\"rf\", RandomForestClassifier(max_features='sqrt'))])\npipe_gnb = Pipeline(steps=[(\"pca\", pca), (\"gnb\", GaussianNB())])\n\nparam_grid_lr = {\n    'pca__n_components': [5,10,25,47,64],\n    'lr__C': np.logspace(-4, 4, 4)\n}\n\nparam_grid_rf = {'pca__n_components': [5,10,25,47,64],\n                 'rf__n_estimators': [10, 100, 1000]\n                }\n\nparam_grid_gnb = {\"pca__n_components\": [5,10,25,47,64],\n                 'gnb__var_smoothing': np.logspace(0,-9, num=100)}\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\ngrid_search = GridSearchCV(estimator=pipe_lr, param_grid=param_grid_lr, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(train, y)\nprint('linear regression',grid_result.best_score_,grid_result.best_params_)\n\ngrid_search = GridSearchCV(estimator=pipe_rf, param_grid=param_grid_rf, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(train, y)\nprint('random forest',grid_result.best_score_,grid_result.best_params_)\n\ngrid_search = GridSearchCV(estimator=pipe_gnb, param_grid=param_grid_gnb, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(train, y)\nprint('naive bayes',grid_result.best_score_,grid_result.best_params_)\n'''","6da782e1":"from sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PowerTransformer\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\n\nct = ColumnTransformer([\n        ('scaler', StandardScaler(), ['Age', 'Fare'])\n    ], remainder='passthrough')\n\n\nmodel = Pipeline(steps=[(\"scaler\", ct),\n                        (\"pca\", PCA(n_components=47)),\n                        (\"rf\", RandomForestClassifier(max_features='sqrt',n_estimators=100))])\n\nmodel.fit(train,y)\npred = model.predict(test)\npred","9e1aad7c":"sub = pd.DataFrame(pred)\nsub1 = sub.rename({0 : 'Survived'},axis=1)\nsub1.reset_index(drop=True, inplace=True)\n\nsub2.reset_index(drop=True, inplace=True)\n\nsub3 = pd.merge(sub2, sub1, left_index=True, right_index=True)\n\nsub3.to_csv('submission.csv', index=False)","d1baaa06":"# Imputation","60b192d8":"# Feature Scaling","b5ecc80b":"# Categorical Encoding","c2497138":"# Finding Numerical and Non-numerical features.","4c4b22eb":"# **Feature Engineering**","816cbaac":"# Model Building","82045bb4":"# **Exploratory Data Analysis**","5ed3d236":"# Find features with NaN values.","2a4ae683":"# Feature Splitting"}}