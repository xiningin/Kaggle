{"cell_type":{"ae4768de":"code","3f975e17":"code","95e28d09":"code","f98cc179":"code","e7a3369b":"code","ae7f7ffb":"code","96ad35d3":"code","266dbc61":"code","49e3f747":"code","8ea6a67b":"code","6a7e96cb":"code","f4845467":"code","f2e3296b":"code","2a62219b":"code","22f38f19":"code","b3c73e56":"code","c56684c8":"code","5d16a96c":"code","12e98681":"code","184e18bd":"code","72deba02":"code","ae9dade0":"code","d6267514":"code","3ffb1b85":"code","4c675796":"code","1b477fdb":"code","29afc91b":"code","bfa9d118":"code","aea18134":"code","313a6266":"code","d406ec19":"code","cb7a7d1c":"markdown"},"source":{"ae4768de":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re","3f975e17":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","95e28d09":"data_dir = \"\"\"..\/input\/sinhala-sign-language-dataset-tdj\/Sn_sign_language_dataset\"\"\"\nclasses = []\n\nfor directory in os.listdir(data_dir):\n    if \".\" not in directory:           # Removes .txt and segmentation script\n        classes.append(directory)   \nprint(classes)","f98cc179":"fp = []\nclass_name = []\nfor cls in classes:\n    files = os.listdir(f'{data_dir}\/{cls}')\n    for file in files:\n        fp.append(f'{data_dir}\/{cls}\/{file}')\n        class_name.append(cls)","e7a3369b":"data = pd.DataFrame({\"File Path\":fp,\"Class\":class_name})","ae7f7ffb":"data['Class'].value_counts()","96ad35d3":"data['Class'] = data['Class'].apply(lambda x:x.title().replace(\"_\",\"\"))\ndata['Class'] = data['Class'].apply(lambda x:re.sub(r'[0-9]+', '', x))","266dbc61":"data['Class'].value_counts()","49e3f747":"clases_to_remove = ['When','Why','What','Who']","8ea6a67b":"data = data[data['Class'].apply(lambda x: True if x not in clases_to_remove else False)]","6a7e96cb":"data['Class'].value_counts()","f4845467":"transform = transforms.Compose([\n        transforms.Resize((300,300)),\n        transforms.Grayscale(num_output_channels=1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5),std=(0.5))\n    ])","f2e3296b":"str_to_int = {key:val for val,key in enumerate(data['Class'].unique())}","2a62219b":"# str_to_int['One & Ten & Eleven'] = 1\n# str_to_int['Two'] = 2\n# str_to_int['Three & Thirteen'] = 3\n# str_to_int['Four & Fourteen'] = 4\n# str_to_int['Five'] = 5\n# str_to_int['Six'] = 6\n# str_to_int['Seven'] = 7\n# str_to_int['Eight'] = 8\n# str_to_int['Nine'] = 9\n# str_to_int['Ten'] = 10\n# str_to_int['Eleven'] = 11\n# str_to_int['Thirteen'] = 13\n# str_to_int['Fourteen'] = 14\n# str_to_int['Twenty'] = 20\n# str_to_int['Thirty'] = 30\n# str_to_int['Fifty'] = 50","22f38f19":"class MarkeDataset(Dataset):\n    def __init__(self, data, root_dir, transform=transforms.ToTensor()):\n        self.data = data\n        self.root_dir = root_dir\n        self.transform = transform\n        self.device = device\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        img_name = self.data.iloc[idx, 0]\n        image = Image.open(img_name)\n        y_label = torch.tensor(str_to_int[self.data.iloc[idx, 1]]).to(self.device)\n        \n        if self.transform:\n            image = self.transform(image).to(self.device)\n    \n        return (image, y_label)","b3c73e56":"dataset = MarkeDataset(\n    data=data,\n    root_dir=data_dir,\n    transform=transform\n)","c56684c8":"randIds = np.random.randint(0,1000,size=10)\nfig,ax = plt.subplots(2,5,figsize=(15,5))\nfor i,axi in zip(randIds,ax.flatten()):\n    img, lab = dataset[i]\n    axi.imshow(img.cpu().numpy().transpose((1, 2, 0)),cmap='gray')\n    axi.text(x = 150,y =2,s =f'Label :{str(lab.item())}',ha='center',backgroundcolor='y')\n    axi.axis('off')\nplt.tight_layout()\nplt.show()","5d16a96c":"len(dataset)","12e98681":"batch_size = 16\ntrain_set, test_set = torch.utils.data.random_split(dataset, [8000,1419])\ntrainLoader = DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True,drop_last=True)\ntestLoader = DataLoader(dataset=test_set,batch_size=1419)","184e18bd":"kernel_size = 5\nstride = 1\npadding = 1\n\nmetrixSize1 = int(np.floor(300+2*padding-kernel_size\/stride)+1)\nmetrixSize1 = int(np.floor(metrixSize1\/2)) #applying 2x2 Max pooling operation\n\nmetrixSize2 = int(np.floor(metrixSize1+2*padding-kernel_size\/stride)+1)\nmetrixSize2 = int(np.floor(metrixSize2\/2)) #applying 2x2 Max pooling operation\n\nprint(f'Metrix size after 1st conv. and maxpool layer: {metrixSize1} X {metrixSize1}')\nprint(f'Metrix size after 2nd conv. and maxpool layer: {metrixSize2} X {metrixSize2}')","72deba02":"class theCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv01 = nn.Conv2d(\n            in_channels = 1,\n            out_channels = 10,\n            kernel_size = 5,\n            stride = 1,\n            padding = 1\n        )\n        \n        self.conv02 = nn.Conv2d(\n            in_channels = 10,\n            out_channels = 20,\n            kernel_size = 5,\n            stride = 1,\n            padding = 1\n        )\n        \n        expectedSize = np.floor((73+2*0-1)\/1) +1 \n        expectedSize = 20*int(expectedSize**2)\n        \n        self.fc01 = nn.Linear(expectedSize,50)\n        self.output = nn.Linear(50,16)\n    \n    def forward(self,x):\n        \n        #convo -> maxpool -> relu\n        x = F.relu(F.max_pool2d(self.conv01(x),2))\n        \n        #convo -> maxpool -> relu\n        x = F.relu(F.max_pool2d(self.conv02(x),2))\n        \n        nUnits = x.shape.numel()\/x.shape[0]\n        x = x.view(-1,int(nUnits))\n        \n        x = F.relu(self.fc01(x))\n        \n        return torch.softmax(self.output(x),axis=1)","ae9dade0":"def createModel(lr):\n    net = theCNN()\n    lossFun = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(params=net.parameters(),lr=lr)\n    \n    return net,lossFun,optimizer","d6267514":"createModel(0.01)[0](torch.randn(1,1,300,300))","3ffb1b85":"def trainModel(epochs,lr):\n  net,LossFun,optimizer = createModel(lr)\n  net = net.to(device)\n  losses = torch.zeros(epochs)\n  testAccuracy = torch.zeros(epochs)\n  trainAccurscy = torch.zeros(epochs)\n\n  for i in range(epochs):\n    net.train()\n    batchLoss = []\n    batchAccuracy = []\n    for X,y in trainLoader:\n      yHat = net(X)\n      loss = LossFun(yHat,y)\n      # print(yHat.item())\n\n      accuracy = 100*torch.mean((torch.argmax(yHat,axis=1)==y).float())\n      batchAccuracy.append(accuracy.item())\n      batchLoss.append(loss.item())\n\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n\n    losses[i] = np.mean(batchLoss)\n    trainAccurscy[i] = np.mean(batchAccuracy)\n\n    net.eval()\n    X,y = next(iter(testLoader))\n    with torch.no_grad():\n      yHat = net(X)\n    loss = LossFun(yHat,y)\n    accuracy = 100*torch.mean((torch.argmax(yHat,axis=1)==y).float())\n    testAccuracy[i] = accuracy\n    print(f'Test Accuracy: {accuracy:.3f}')\n  return net,losses,testAccuracy,trainAccurscy,yHat,X","4c675796":"%%time\nnet,losses,testAccuracy,trainAccuracy,yHat,X = trainModel(100,1e-4)","1b477fdb":"plt.title(f'Final test accuracy: {testAccuracy[-1]:.3f}')\nplt.plot(testAccuracy,label='Test')\nplt.plot(trainAccuracy,label='Train')\nplt.legend()\nplt.plot()","29afc91b":"plt.title(f'Final train loss: {losses[-1]:.3f}')\nplt.plot(losses)\nplt.plot()","bfa9d118":"inv_map = dict(zip(str_to_int.values(), str_to_int.keys()))","aea18134":"predictions = torch.argmax(yHat,axis=1).cpu().detach().numpy().tolist()","313a6266":"predictions = list(map(lambda x: inv_map[x],predictions))","d406ec19":"randIds = np.random.randint(0,1000,size=10)\nfig,ax = plt.subplots(2,5,figsize=(15,5))\nfor i,axi in zip(randIds,ax.flatten()):\n    img = X[i]\n    axi.imshow(img.cpu().numpy().transpose((1, 2, 0)),cmap='gray')\n    axi.text(x = 150,y =2,s =f'Prediction :{predictions[i]}',ha='center',backgroundcolor='y')\n    axi.axis('off')\nplt.tight_layout()\nplt.show()","cb7a7d1c":"## Todo\n - Add Dropout\n - Try Image augmentation techniques"}}