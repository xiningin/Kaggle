{"cell_type":{"33e48af8":"code","fc56fb44":"code","7aaf3674":"code","35a4f010":"code","ca04d4fa":"code","07e53f60":"code","e9569c0d":"code","6a4df0b4":"code","ee0a0d94":"code","1d268d60":"code","83fcba61":"code","844485dd":"code","2104220e":"code","3561bc3d":"code","b1c65328":"code","901ce491":"code","48caa99e":"code","f3f67082":"code","06729a48":"code","41998ff7":"code","d141b870":"markdown","5189e3e1":"markdown"},"source":{"33e48af8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc56fb44":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nprint(\"Setup Complete\")","7aaf3674":"#load the dataset\nfile_path=\"..\/input\/flipkart-mobile-dataset\/Flipkart Mobile - 2.csv\"\nflipkart_data=pd.read_csv(file_path)","35a4f010":"flipkart_data.head()","ca04d4fa":"#categorical columns\nlow_cardinality_cols = [cname for cname in flipkart_data.columns if flipkart_data[cname].nunique() < 10 and flipkart_data[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in flipkart_data.columns if flipkart_data[cname].dtype in ['int64', 'float64']]\nmy_cols=low_cardinality_cols+numerical_cols","07e53f60":"#handle categorical data\nflipkart_mod = flipkart_data[my_cols].copy()\n\n\n# Apply ordinal encoder to each column with categorical data\nfrom sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nflipkart_mod[low_cardinality_cols] = ordinal_encoder.fit_transform(flipkart_mod[low_cardinality_cols])\n\nflipkart_mod.head()","e9569c0d":"#heatmap\ncorrmat=flipkart_mod.corr()\ntop_corr=corrmat.index\nplt.figure(figsize=(20,20))\n\nsns.heatmap(flipkart_data[top_corr].corr(),annot=True)","6a4df0b4":"y=flipkart_mod.sales_price\nx=flipkart_mod.drop(['num_of_ratings','battery_capacity','sales_price'],axis=1)","ee0a0d94":"#split the dataset\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=0)","1d268d60":"#parameter tuning\nimport numpy as np\nn_estimators=[int(x) for x in np.linspace(start=100,stop=1200,num=12)]\nprint(n_estimators)","83fcba61":"from sklearn.model_selection import RandomizedSearchCV","844485dd":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","2104220e":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","3561bc3d":"# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations\nfrom sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","b1c65328":"rf_random.fit(x_train,y_train)","901ce491":"rf_random.best_params_","48caa99e":"predictions=rf_random.predict(x_test)","f3f67082":"sns.displot(y_test-predictions)","06729a48":"plt.scatter(y_test,predictions)","41998ff7":"from sklearn import metrics\nprint('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","d141b870":"From the heatmap, we can see that 'num_of_ratings' and 'battery_capacity' are less important.","5189e3e1":"As we can see, there are some categorical variables. So we need to handle categorical variables first."}}