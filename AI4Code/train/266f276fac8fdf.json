{"cell_type":{"bfd35807":"code","4c75b778":"code","8425cf2e":"code","605d53cb":"code","bbd1d359":"code","01653d1a":"code","48f399dd":"code","afe340ba":"code","9d9a3b33":"code","c0b97166":"code","c5d93eb6":"code","f22fb62a":"code","1c198521":"code","de5a8b57":"code","7906928a":"code","7b7569fa":"code","32c0e1e4":"code","f472e2e0":"code","58382053":"code","a1ffc151":"code","21fece31":"code","18fcbece":"code","d69b22d0":"markdown","12d4c985":"markdown","ce38ee91":"markdown","a63608f3":"markdown","320eb02b":"markdown","3c3221fc":"markdown","67eef946":"markdown","f01aba31":"markdown","e7a86387":"markdown","72de3f3c":"markdown","aed2f510":"markdown","399be153":"markdown","51013f95":"markdown","b07fe7c8":"markdown","0ba0ee26":"markdown","3ef033c6":"markdown","586d64d4":"markdown","e2bc7a24":"markdown","c041278f":"markdown","da652135":"markdown"},"source":{"bfd35807":"#import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib \nfrom matplotlib import pyplot as plt\n%matplotlib inline\nmatplotlib.rcParams[\"figure.figsize\"] = (12,10)\nimport seaborn as sns\n#import model\nfrom sklearn.preprocessing import StandardScaler,OrdinalEncoder,LabelEncoder\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split,cross_val_score,KFold\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.impute import SimpleImputer\n","4c75b778":"\ndf = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ndf_t = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\n\nprint(df.shape,df_t.shape)\n\n","8425cf2e":"# identify the null values\ndf.isnull().sum()","605d53cb":"#fix the null values issues\nimputer = SimpleImputer()\ntrain_imputer = pd.DataFrame(imputer.fit_transform(df))\ntest_imputer = pd.DataFrame(imputer.fit_transform(df_t))\n\n#imputation removed columns \ntrain_imputer.columns = df.columns\ntest_imputer.columns = df_t.columns\n\ndf = train_imputer\ndf_t = test_imputer","bbd1d359":"#insert the kfold columns\ndf['kfold'] = -1\n#distributing the data\nkfold = KFold(n_splits = 5,shuffle=True,random_state = 42)\nfor fold, (tr_i,va_i) in enumerate(kfold.split(X=df)):\n    df.loc[va_i,'kfold'] = fold\n    \nprint(df.kfold.value_counts())\ndf.to_csv(\"folds_5.csv\",index=False)\nprint(\"successfully folds\")","01653d1a":"sns.heatmap(df.corr(),cmap='PiYG_r')","48f399dd":"df.columns","afe340ba":"#Folds data\ndf = pd.read_csv(\".\/folds_5.csv\")\n\n#features taken to train\nfeatures = [f for f in df.columns if f not in(\"id\",\"kfold\",\"claim\")]\nnum_cols = [cols for cols in features if 'f' in cols]\n\ntest= df_t[features]\n","9d9a3b33":"prediction = []\nscore = []\n\nfor fold in range (5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = test.copy()\n    \n    ytrain = xtrain.claim\n    yvalid = xvalid.claim\n    \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    lE = StandardScaler()\n    xtrain[num_cols] = lE.fit_transform(xtrain[num_cols])\n    xvalid[num_cols] = lE.transform(xvalid[num_cols])\n    xtest[num_cols] = lE.transform(xtest[num_cols])\n    \n    #xgboost model\n    xgb_m = XGBRegressor(learning_rate=0.01,\n                         n_estimators=5000,\n                        random_state=42,\n                        gpu_id=0,\n                        tree_method='gpu_hist',\n                        predictor='gpu_predictor')\n    xgb_m.fit(xtrain,ytrain,early_stopping_rounds=100,eval_set=[(xvalid,yvalid)],verbose=1000)\n    predict_valid = xgb_m.predict(xvalid)\n    test_predict = xgb_m.predict(xtest)\n    prediction.append(test_predict)\n    \n    #Root_mean_square\n    rms = mean_squared_error(yvalid,predict_valid,squared=False)\n    \n    #Score \n    score.append(rms)\n    print(f\"fold|split:{fold},rmse:{rms}\")\n    \nprint(np.mean(score),np.std(score))\n\n\n#reconfigure of split data\nfinal_predict = np.mean(np.column_stack(prediction),axis=1)\nprint(final_predict)\nsample_submission.claim = final_predict\nsample_submission.to_csv(\"First_submission_xgb.csv\",index=False)\nprint(\"Final achieve to send xgboost output data\")\n\n    ","c0b97166":"import h2o\nfrom h2o.automl import H2OAutoML\n#initial the process\nh2o.init() ","c5d93eb6":"df= pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")\nsample = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")","f22fb62a":"#fix the null values issues\nimputer = SimpleImputer()\ntrain_imputer = pd.DataFrame(imputer.fit_transform(df))\ntest_imputer = pd.DataFrame(imputer.fit_transform(df_test))\n\n#imputation removed columns \ntrain_imputer.columns = df.columns\ntest_imputer.columns = df_t.columns\n\ndf = train_imputer\ndf_test = test_imputer","1c198521":"#convert to h20 frame format\ntrain = h2o.H2OFrame(df) \ntest =  h2o.H2OFrame(df_test)","de5a8b57":"x= train.columns\ny= \"claim\"\nx.remove(y)\n#binary classifying\ntrain[y] = train[y].asfactor() ","7906928a":"automl = H2OAutoML(nfolds=5,#folds\n                  seed=42,#random seed\n                  max_models=20,\n                  include_algos = [\"XGBoost\",\"StackedEnsemble\",\"GBM\"],\n                  max_runtime_secs = 3600*3,#time in sec's\n                  stopping_metric = 'AUC'\n                  )\nautoml.train(x=x,y=y,training_frame=train)","7b7569fa":"l_b = automl.leaderboard\nl_b","32c0e1e4":"corr = automl.model_correlation_heatmap(train)","f472e2e0":"model = h2o.get_model(l_b[2,\"model_id\"])\n#Learning curve\nmodel.learning_curve_plot()","58382053":"model.varimp_plot()","a1ffc151":"#generate test data\ntest_pred = automl.leader.predict(test)","21fece31":"sub = pd.DataFrame({\n    'id':test['id'].as_data_frame().id,\n    'claim':test_pred.as_data_frame().predict\n})\nsub.to_csv(\"Mysubmission_H2o.csv\",index=False)\nprint(\"Final achieve AutoML output send data\")","18fcbece":"sub","d69b22d0":"**End Hyperparameter tuning xgboostregressor**\n\n**And now try automl**","12d4c985":"# KFold - 5 Splits","ce38ee91":"# Test data","a63608f3":"# Check voting model\n***Apply leaderboard***","320eb02b":"**Covert the h2oformat**","3c3221fc":"# AutoML-H20\n\n**H2O is an open source, in-memory, distributed, fast, and scalable machine learning and predictive analytics platform that allows you to build machine learning models on big data and provides easy productionalization of those models in an enterprise environment.**\n\n","67eef946":"#### **Reference:**\ud83d\ude0d\n\n**@Abishek thaur**\n\n**Day1** version2-simple baseline kfold and xgboost process\n\n**Day2** version3- simple imputer apply for null data (mean,median process)","f01aba31":"# **Features**","e7a86387":"## **Thank you**","72de3f3c":"## **AutoML** \ud83d\udc40\ud83d\udd25\ud83d\udca5\ud83c\udf89\n**Reference:**\n\n[https:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/welcome.html](http:\/\/)\n\n[https:\/\/www.kaggle.com\/mhslearner\/starter-simple-eda-h2oautoml\/comments](http:\/\/)\n\n[https:\/\/www.kaggle.com\/sudalairajkumar\/getting-started-with-h2o](http:\/\/)\ud83d\ude0d","aed2f510":"# Identify null data and fix the issues\n\n### **Apply simple Imputer:**\n#### SimpleImputer is a scikit-learn class which is helpful in handling the missing data in the predictive model dataset.\n\n[https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.impute.SimpleImputer.html](http:\/\/)\n","399be153":"# Read the data","51013f95":"# Build the Model \ud83d\udca5\n\n## Basic model\n\n**XGBoostRegressor**","b07fe7c8":"# Train AutoML model","0ba0ee26":"## Install packages","3ef033c6":"**Learning curves represent**","586d64d4":"# Tabular-Playground-Series - Sep 2021 \ud83d\udc40\ud83d\udd25\ud83d\udca5\ud83c\udf89\n\n# AutoML  \ud83c\udf89\n\n1. **import library**\n2. **Read the data**\n3. **KFOlD - 5splits**\n4. **Identify the null datasand apply simpleimputer**\n4. **Correlation the input data**\n5. **Preprocessing the input data**\n6. **Build the model**\n7. **AutoML(H20)** --> 1st time try\n7. **Submit predict output**\n","e2bc7a24":"1. **Identify predictors and response**\n2. **for binary classifyication,response should be as factor**","c041278f":"# Submission \ud83d\udc40","da652135":"**correlation of data's**"}}