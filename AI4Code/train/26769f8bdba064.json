{"cell_type":{"b0664544":"code","bf9760e3":"code","07bb4a39":"code","6d5db39c":"code","547e4484":"code","bfbbdac0":"code","8b052f7f":"code","8195869a":"code","bbc12866":"code","2dc5afb0":"code","6df285f6":"code","8a16d487":"code","84506c59":"code","71f13b0f":"code","be7f978b":"code","72e577c2":"code","90ceba2d":"code","6e66197e":"code","bfea7ce4":"code","80dfe3b5":"code","4c6bc4a6":"code","48c1009a":"code","c587e247":"code","f713de8a":"code","f2981dac":"code","9b553733":"code","498f0b0a":"code","d1134839":"code","32509ad4":"code","a8989064":"code","e63baac8":"code","86a7d60d":"code","01d14871":"code","d9f5faa3":"code","33de12f2":"code","3176e446":"code","8d490b58":"code","2ba58221":"code","07f31189":"code","18c37082":"code","b3375c70":"code","5815dcda":"code","409b7f73":"code","0ed0e2b8":"code","3037016e":"code","4bc21eb5":"code","4a247ebf":"markdown","51c31f25":"markdown","7523951e":"markdown","9b30b442":"markdown","ad12bc6c":"markdown","6eaf43d8":"markdown","84dbb612":"markdown","94cb0546":"markdown","8fa2fc75":"markdown","f68c9bd2":"markdown","d7f26c65":"markdown","e540d433":"markdown","3b5b8f84":"markdown","97365a82":"markdown","f946322b":"markdown","7ab17d6a":"markdown","408c1648":"markdown","43b53f86":"markdown","463ad841":"markdown","b44f9cdb":"markdown"},"source":{"b0664544":"import numpy as np\nimport pandas as pd\nimport random\n\nimport os\npath_in = \"..\/input\/aptos2019-blindness-detection\/\"\nprint(os.listdir(path_in))\nprint(os.listdir('..\/input\/models'))","bf9760e3":"import cv2\nimport matplotlib.pyplot as plt","07bb4a39":"import warnings\nwarnings.filterwarnings(\"ignore\")","6d5db39c":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer","547e4484":"from keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.applications import VGG19","bfbbdac0":"q_size = 150\nimg_channel = 3\nnum_classes = 5","8b052f7f":"train_data = pd.read_csv(path_in+'train.csv')\ntest_data = pd.read_csv(path_in+'test.csv')\nsub_org = pd.read_csv(path_in+'sample_submission.csv')","8195869a":"def plot_bar(data):\n    \"\"\"Simple function to plot the distribution of the classes.\"\"\"\n    dict_data = dict(zip(range(0, num_classes), (((data.value_counts()).sort_index())).tolist()))\n    names = list(dict_data.keys())\n    values = list(dict_data.values())\n    plt.bar(names, values)\n    plt.grid()\n    plt.show()","bbc12866":"def read_images(filepath, data, file_list, size):\n    \"\"\"Read and edit the images of a given folder.\"\"\"\n    for file in file_list:\n        img = cv2.imread(filepath+file+'.png')\n        img = cv2.resize(img, (size, size))\n        img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), 10), -4, 128)\n        data[file_list.index(file), :, :, :] = img","2dc5afb0":"def add_flip_image(data, file_list):\n    \"\"\"Simple function to flip images by a given list.\"\"\"\n    temp = np.empty((1, data.shape[1], data.shape[2], data.shape[3]), dtype=np.uint8)\n    for index in file_list.index:\n        img = data[index, :, :, :]\n        vertical_img = cv2.flip(img, 1)\n        temp[0, :, :, :] = vertical_img\n        data = np.concatenate((data, temp), axis=0)\n    return data","6df285f6":"def add_rot_image(data, file_list):\n    \"\"\"Simple function to rotate images by a given list.\"\"\"\n    degrees = 15\n    temp = np.empty((1, data.shape[1], data.shape[2], data.shape[3]), dtype=np.uint8)\n    for index in file_list.index:\n        img = data[index, :, :, :]\n        rows,cols, channel = img.shape\n        Matrix = cv2.getRotationMatrix2D((cols\/2,rows\/2), degrees, 1)\n        rotate_img = cv2.warpAffine(img, Matrix, (cols, rows))\n        temp[0, :, :, :] = rotate_img\n        data = np.concatenate((data, temp), axis=0)\n    return data","8a16d487":"def add_zoom_image(data, file_list):\n    \"\"\"Simple function to zoom in images by a given list.\"\"\"\n    temp = np.empty((1, data.shape[1], data.shape[2], data.shape[3]), dtype=np.uint8)\n    for index in file_list.index:\n        img = data[index, :, :, :]\n        size = img.shape[0]\n        pts1 = np.float32([[10,10],[size-10, 10],[10, size-10],[size-10, size-10]])\n        pts2 = np.float32([[0, 0],[size-20, 0],[0, size-20],[size-20, size-20]])\n        Matrix = cv2.getPerspectiveTransform(pts1, pts2)\n        # zoom image\n        img_zoom = cv2.warpPerspective(img, Matrix, (size-20, size-20))\n        dim = img.shape \n        # resize image\n        rows,cols, channel = img.shape\n        dim=(rows, cols)\n        img_scale = cv2.resize(img_zoom, dim, interpolation = cv2.INTER_AREA)\n        temp[0, :, :, :] = img_scale\n        data = np.concatenate((data, temp), axis=0)\n    return data","84506c59":"def get_multilabel(diagnosis):\n    \"\"\"A function to get multi-label from single-label.\"\"\"\n    return ','.join([str(i) for i in range(diagnosis + 1)])","71f13b0f":"X_train_org = np.empty((len(train_data), q_size, q_size, img_channel), dtype=np.uint8)\nX_test = np.empty((len(test_data), q_size, q_size, img_channel), dtype=np.uint8)","be7f978b":"read_images(path_in+'train_images\/', X_train_org, train_data['id_code'].tolist(), q_size)\nread_images(path_in+'test_images\/', X_test, sub_org['id_code'].tolist(), q_size)","72e577c2":"plot_bar(train_data['diagnosis'])","90ceba2d":"list_flip = train_data[train_data['diagnosis'] != 0]","6e66197e":"X_train_org = add_flip_image(X_train_org, list_flip)\ntrain_data = train_data.append(list_flip, ignore_index=True, sort=False)","bfea7ce4":"plot_bar(train_data['diagnosis'])","80dfe3b5":"list_rot = train_data[(train_data['diagnosis'] != 0)&\n                      (train_data['diagnosis'] != 2)]","4c6bc4a6":"X_train_org = add_rot_image(X_train_org, list_rot)\ntrain_data = train_data.append(list_rot, ignore_index=True, sort=False)","48c1009a":"plot_bar(train_data['diagnosis'])","c587e247":"list_zoom = train_data[(train_data['diagnosis'] == 3)|\n                       (train_data['diagnosis'] == 4)]","f713de8a":"X_train_org = add_zoom_image(X_train_org, list_zoom)\ntrain_data = train_data.append(list_zoom, ignore_index=True, sort=False)","f2981dac":"plot_bar(train_data['diagnosis'])","9b553733":"num_val = (train_data['diagnosis'].value_counts()).min()\nlist_new = []\nfor i in range(num_classes):\n    temp = random.choices(train_data[train_data['diagnosis']==i].index, k=num_val)\n    list_new.extend(temp)\ntrain_data = train_data.loc[list_new]\nX_train_org = X_train_org[list_new]","498f0b0a":"plot_bar(train_data['diagnosis'])","d1134839":"image_number=4019\nprint(train_data.iloc[image_number])\nplt.imshow(X_train_org[image_number], cmap='gray')\nplt.show()","32509ad4":"train_data['multilabel'] = train_data['diagnosis'].apply(get_multilabel)","a8989064":"category =['0','1','2','3','4']\nMLB = MultiLabelBinarizer(category)\ny_train_org_multi = MLB.fit_transform(train_data['multilabel']).astype('float32')","e63baac8":"class_weight = dict(zip(range(0, num_classes), (((train_data['diagnosis'].value_counts()).sort_index())\/len(train_data)).tolist()))","86a7d60d":"mean = X_train_org.mean(axis=0)\nX_train_org = X_train_org.astype('float32')\nX_train_org -= X_train_org.mean(axis=0)\nstd = X_train_org.std(axis=0)\nX_train_org \/= X_train_org.std(axis=0)\nX_test = X_test.astype('float32')\nX_test -= mean\nX_test \/= std","01d14871":"X_train, X_val, y_train, y_val = train_test_split(X_train_org, y_train_org_multi,\n                                                  test_size=0.1, random_state=0)","d9f5faa3":"conv_base = VGG19(weights='..\/input\/models\/model_weights_vgg19.h5',\n                  include_top=False,\n                  input_shape=(q_size, q_size, img_channel))\nconv_base.trainable = True","33de12f2":"model = Sequential()\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='sigmoid'))","3176e446":"model.compile(optimizer = Adam(lr=5e-7),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])","8d490b58":"model.summary()","2ba58221":"epochs = 100\nbatch_size = 32","07f31189":"history = model.fit(X_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    validation_data=(X_val, y_val),\n                    class_weight=class_weight)","18c37082":"y_test = model.predict(X_test)","b3375c70":"y_test_classes = np.where(y_test>0.5, 1, 0).sum(axis=1)-1","5815dcda":"output = pd.DataFrame({'id_code': sub_org['id_code'],\n                       'diagnosis': y_test_classes})\noutput.to_csv('submission.csv', index=False)","409b7f73":"plot_bar(output['diagnosis'])","0ed0e2b8":"loss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, loss, 'bo', label='loss_train')\nplt.plot(epochs, loss_val, 'b', label='los_val')\nplt.title('Value of the loss-function')\nplt.xlabel('Epochs')\nplt.ylabel('Value of the loss-function')\nplt.legend()\nplt.grid()\nplt.show()","3037016e":"acc = history.history['binary_accuracy']\nacc_val = history.history['val_binary_accuracy']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, acc, 'bo', label='Accuracy_Train')\nplt.plot(epochs, acc_val, 'b', label='Accuracy_Val')\nplt.title('Value of the accurarcy')\nplt.xlabel('Epochs')\nplt.ylabel('Value of the accuracy')\nplt.legend()\nplt.grid()\nplt.show()","4bc21eb5":"del model","4a247ebf":"### Abstract\nWe consider a starter code for beginner of this dataset. There is a unbalanced distribution of the classes. To overcome this drawback we want to add images by modifying the given images. We use the following geometric transformations:\n* vertical flip,\n* rotation,\n* perspective transformation (zoom).\n\nAfter that we select randomly images by the same number of images of every class. \n\nIn consideration of the medical fact that there exists a course of disease we use multi-labels instead of single-labels. That means we set\n\n| diagnosis | single-label |multi-label |\n|---| ---| ---|\n| 0 | 0 | 0 |\n| 1 | 1 | 0, 1|\n| 2 | 2 | 0, 1, 2|\n| 3 | 3 | 0, 1, 2, 3|\n| 4 | 4 | 0, 1, 2, 3, 4|\n\nWe trained the model by using a pretrained model. ","51c31f25":"### Visualize the results","7523951e":"### Select random images for train\nThe aim is to get equally distributed images for every class.","9b30b442":"### Split train and validation data","ad12bc6c":"### Predict on the test images","6eaf43d8":"### Add images by zooming\nDublicate the images from class 3 and 4 by zooming every image.","84dbb612":"### Create the model","94cb0546":"### Read the input csv files","8fa2fc75":"### Train the model","f68c9bd2":"### Convert and scale image data","d7f26c65":"### Add flipped images\nDublicate the images from class 1 to 4 by vertical flip every image.","e540d433":"### Define some parameters","3b5b8f84":"### Define some functions","97365a82":"### Add rotated images\nDublicate the images from class 1, 3 and 4 by rotate every image.","f946322b":"### Read the image data","7ab17d6a":"### Prepare the labels\nUsing multi-label instead of single-label.","408c1648":"### Write output for submission","43b53f86":"### Define class weights","463ad841":"### Initialize the original train and test data","b44f9cdb":"### Plot an image"}}