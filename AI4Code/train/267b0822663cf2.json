{"cell_type":{"df9d40f9":"code","a78b1d5a":"code","ce472f4a":"code","d78e2a05":"code","89f416d1":"code","b7dd9422":"code","01de27b9":"code","bac51239":"code","f6675d3c":"code","7ac07dc8":"code","ddb2d54d":"code","d0a85888":"code","46724a8a":"code","97e404ee":"code","47f6c4b7":"code","df6e1464":"code","80994aad":"code","9212074e":"code","cd55d270":"code","f934974b":"code","1e118841":"code","fdd5664b":"code","0eded644":"code","d3b9afb6":"code","7ce68e21":"code","135d5440":"code","9b2d6fb1":"code","42ae3857":"code","80991173":"code","01335fee":"code","80acf531":"code","2d5acff8":"code","2ec3063a":"code","cd7d164c":"code","69e1e20f":"code","2f5bf417":"code","00bc6f43":"code","ee125cee":"code","17275dc4":"code","6726ce63":"code","f7754c4d":"code","f62cc1bc":"code","08d015ce":"code","539140c3":"code","e3c9fd65":"code","247e8ccd":"code","f0001883":"code","1958d093":"code","82a8f501":"code","37a3748d":"code","b52dffed":"code","1980e4fc":"code","e9bc7d78":"code","f7440ba1":"code","a4a97bb5":"code","4ffa3a33":"code","b6a0f4e6":"code","91db51c2":"code","2ebd1560":"code","1be7bdbe":"code","982ab809":"code","6f78732c":"code","e4dae90e":"code","20ad8d00":"code","c5e627e4":"code","8732438f":"code","94bd2c1b":"code","7c2b345c":"code","e4951f3b":"code","cb9e3b0c":"code","864e89d5":"code","4e90642a":"code","fc4616d5":"code","d1d954a4":"code","6bc48574":"code","6de1e63f":"code","ba9d7693":"code","143b2594":"code","907724a7":"code","94487c5a":"code","67f162e2":"code","a0cebeab":"code","7741f697":"code","2bf2bdc5":"code","70e758cd":"code","ab46beda":"code","091cccd3":"code","3cdde820":"code","ddd51b8b":"code","3fb0d940":"code","12e0a5c5":"code","be56ba8c":"code","c05b793b":"code","28067ddf":"code","03315229":"markdown","5e791b52":"markdown","59ec5ddd":"markdown","6dd46cde":"markdown","50433663":"markdown","5a20e4cc":"markdown","9d2a7c05":"markdown","c01becfe":"markdown","7706f7b7":"markdown","ddf341d3":"markdown","4130ba4e":"markdown","b6ee9b8b":"markdown","85f24023":"markdown","59dc914c":"markdown","0a168482":"markdown","34e64cd1":"markdown","ed5f3450":"markdown","f70edb69":"markdown","e29ca661":"markdown","d45a084d":"markdown","8154a6dc":"markdown","70c1ef70":"markdown","185cc025":"markdown","5942bf77":"markdown","748754fb":"markdown","40ad79bd":"markdown"},"source":{"df9d40f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a78b1d5a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set_theme(style = 'darkgrid', palette = 'Set2')","ce472f4a":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","d78e2a05":"train.head()","89f416d1":"train.info()","b7dd9422":"print('Percentage of missing values per column:')\nround((train.isnull().sum())\/len(train)*100, 3)","01de27b9":"import missingno as msn\nplt.title('Number of non-null values per column', fontsize = 30)\nmsn.bar(train, color = 'g', fontsize = 20)","bac51239":"df = train.drop('Cabin', axis = 1)\nprint('The Cabin column has been dropped:')\ndf.head()","f6675d3c":"data = df.copy()\ndata.loc[0,'Name'].split('.')[0].split(',')[-1].strip()","7ac07dc8":"for row in df.index:\n    df.loc[row,'Name'] = df.loc[row,'Name'].split('.')[0].split(',')[-1].strip()","ddb2d54d":"df.Name.value_counts()","d0a85888":"df['Name'].replace({'Mr':1,\n                     'Mrs':2,'Mme':2,'Ms': 2,\n                    'Miss': 3, 'Mlle': 3, \n                    'Dr':3, 'Rev': 3,\n                     'Col':3, 'Major': 3,'Capt': 3,\n                     'Master': 4,\n                     'Lady':5, 'the Countess':5, 'Jonkheer':5, 'Don': 5, 'Sir': 5\n                     }, inplace = True)","46724a8a":"df.head()","97e404ee":"plt.figure(figsize = (10,7))\ndf.groupby('Name')['Survived'].mean().plot.bar()\nplt.title('Avg. Survival rate Vs Title Group', fontsize = 20)\nplt.xlabel('Title')","47f6c4b7":"df['Embarked'].fillna(df['Embarked'].mode()[0], axis = 0, inplace = True)\nprint('The Missing values in the Embarked column have been filled by the mode of that column')\ndf.isnull().sum()\n","df6e1464":"fig = plt.figure(figsize = (7,5))\nplt.title('Age Distribution',fontsize = 20)\nsns.distplot(df.Age,bins = 8)\nplt.show()","80994aad":"df.fillna(df['Age'].median(), axis = 0, inplace = True)\nprint('All the NaN values have been dealt with,')\ndf.isna().sum()","9212074e":"fig = plt.figure(figsize = (10,7))\nc = df.corr()\nsns.heatmap(c, linewidths = 2, annot = True)","cd55d270":"fig = plt.figure(figsize = (10,7))\nsns.heatmap(c[(c>=0.5) | (c<=-0.5)], linewidths = 2, annot = True)","f934974b":"sns.distplot(df['Fare'])","1e118841":"data = df.copy()\nfor row in data.index:\n    if data.loc[row,'Fare'] == 0:\n        pass\n    else:\n        data.loc[row,'Fare'] = np.log(data.loc[row,'Fare'])","fdd5664b":"sns.distplot(data['Fare'])","0eded644":"data2 = df.copy()\nfor row in data2.index:\n    #if data2.loc[row,'Fare'] == 0:\n        #pass\n    #else:\n    data2.loc[row,'Fare'] = np.sqrt(data2.loc[row,'Fare'])","d3b9afb6":"sns.distplot(data2['Fare'])","7ce68e21":"#df.drop('Fare', axis = 1, inplace = True)\n#print('Fare has been dropped:')\n#df.head()\nfor row in df.index:\n    if df.loc[row,'Fare'] == 0:\n        pass\n    else:\n        df.loc[row,'Fare'] = np.log(df.loc[row,'Fare'])","135d5440":"plt.title('Number of passengers survived\/not survived based on their gender')\nsns.countplot(df.Sex, hue = df.Survived, palette = 'Set1')\nplt.show()","9b2d6fb1":"#df[df['Sex'] == 'female'].value_counts().sum()\n#df[df['Sex'] == 'male'].value_counts().sum()\n#df[df['Survived'] == 1].Sex.value_counts()\n\nper_male_sur = round((df[(df['Survived'] == 1) & (df['Sex'] == 'male')].Sex.value_counts()\/df[df['Sex'] == 'male'].value_counts().sum())*100, 2)\nprint('Percentage of Men survived: {}%'.format(per_male_sur[0]))\n\nper_female_sur = round((df[(df['Survived'] == 1) & (df['Sex'] == 'female')].Sex.value_counts()\/df[df['Sex'] == 'female'].value_counts().sum())*100, 2)\nprint('Percentage of Women survived: {}%'.format(per_female_sur[0]))","42ae3857":"plt.title('Class-wise Survival of passengers', fontsize = 20)\nsns.countplot(df.Pclass, hue = df.Survived, palette = 'Set3')\nplt.show()","80991173":"for i in range(1,4):\n    pclass_sur = df[df.Survived == 1].Pclass.value_counts().loc[i]\n    pclass = df.Pclass.value_counts().loc[i]\n    percent_sur = round((pclass_sur\/pclass)*100,2)\n    \n    print('Percentage of passengers survived who were travelling in class {} is: {}%'.format(i, percent_sur))\n    ","01335fee":"fig = plt.figure(figsize = (7,5))\nplt.title('Age Distribution',fontsize = 20)\nsns.distplot(df.Age,bins = 10, color = 'orange')\nplt.show()","80acf531":"fig = plt.figure(figsize = (7,7))\nplt.subplot(1,3,1)\nplt.title('Total Passengers')\nsns.boxplot(y = df.Age)\nplt.subplot(1,3,2)\nplt.title('Passengers Survived')\nsns.boxplot(y = df[df.Survived == 1].Age, color = 'b')\nplt.subplot(1,3,3)\nplt.title('Passengers who died')\nsns.boxplot(y = df[df.Survived == 0].Age, color = 'r')\nplt.show()\n","2d5acff8":"ll,ul = np.percentile(df.Age, [1, 99])\nprint('Number of outliers in the Age column are : {}'.format(df[(df['Age']<ll) | (df['Age']>ul)].value_counts().sum()))","2ec3063a":"df2 = df[(df['Age']>=ll) & (df['Age']<=ul)]\nprint('The outliers have been dropped from the training set:')\ndf2.info()","cd7d164c":"fig = plt.figure(figsize = (10,7))\nsns.histplot(df2[df2.Survived == 0].Age, bins = 13, color = 'r', legend = True)\nsns.histplot(df2[df2.Survived == 1].Age, bins = 13, color = 'g', legend = True)\nplt.legend(['Dead', 'Survived'])","69e1e20f":"fig = plt.figure(figsize = (10,7))\nsns.countplot(x = df['SibSp'], hue = df.Survived, palette = 'Set1')\nplt.title('Number of passengers survived Vs the number of siblings\/spouse they had', fontsize = 20)\nplt.ylabel('No. of passengers')","2f5bf417":"for i in df['SibSp'].unique():\n    if i not in df[df.Survived == 1].SibSp.unique():\n        print('Perecentage of passengers survived who has {} Siblings\/Spouse is 0%'.format(i))\n    \n    if i in df[df.Survived == 1].SibSp.unique():\n        sur_sib = df[(df.Survived == 1) & (df.SibSp == i)].SibSp.value_counts()\n        tot_sib = df[(df.SibSp == i)].SibSp.value_counts()\n        per = float(round((sur_sib\/tot_sib)*100, 2))\n        print('Perecentage of passengers survived who has {} Siblings\/Spouse is: {} %'.format(i, per))\n","00bc6f43":"fig = plt.figure(figsize = (10,7))\nsns.countplot(x = df['Parch'], hue = df.Survived, palette = 'Set1')\nplt.title('Number of passengers survived Vs the number of Parents\/Children they had on board', fontsize = 20)\nplt.ylabel('No. of passengers')\n","ee125cee":"print('Total passengers on board classified according to Parch: ')\ndf.Parch.value_counts()","17275dc4":"print('Total passengers who survived classified according to Parch: ')\ndf[df['Survived'] == 1].Parch.value_counts()","6726ce63":"for i in df['Parch'].unique():\n    if i not in df[df.Survived == 1].Parch.unique():\n        print('Perecentage of passengers survived who has {} Parents\/Children on board is 0%'.format(i))\n    \n    if i in df[df.Survived == 1].Parch.unique():\n        sur_p = df[(df.Survived == 1) & (df.Parch == i)].Parch.value_counts()\n        tot_p = df[(df.Parch == i)].Parch.value_counts()\n        per = float(round((sur_p\/tot_p)*100, 2))\n        print('Perecentage of passengers survived who has {} Parents\/Children on board is: {} %'.format(i, per))","f7754c4d":"df['Embarked'].value_counts()","f62cc1bc":"df[df.Survived == 1]['Embarked'].value_counts()","08d015ce":"em = {\n    'S': 'Southampton',\n    'Q': 'Queenstown',\n    'C': 'Cherbourg'\n}\nfor i in df.Embarked.unique():\n    sur_em = df[(df.Survived == 1) & (df.Embarked == i)].Embarked.value_counts()\n    tot_em = df[(df.Embarked == i)].Embarked.value_counts()\n    per = float(round((sur_em\/tot_em)*100, 2))\n    print('Perecentage of passengers survived who embarked at {} Parents\/Children on board is: {} %'.format(em[i], per))","539140c3":"fig = plt.figure(figsize = (10,7))\nsns.countplot(df.Embarked, hue = df.Survived)\nplt.ylabel('Count of passengers')\nplt.title('No. of passengers survived based on the port of embarkment')","e3c9fd65":"df2 = df.drop(['PassengerId', 'Ticket'], axis = 1)\nprint('Dropped the PassengerId, Ticket column')\ndf2.head()","247e8ccd":"df2['Sex'] = np.where(df2['Sex'] == 'male', 1, 0)\ndf2.head()","f0001883":"dummy_s = pd.get_dummies(df2['SibSp'], drop_first = True)\nprint('SibSp has been encoded using pd.get_dummies()')\ndummy_s.columns = ['SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8']\ndummy_s.head()","1958d093":"dummy_p = pd.get_dummies(df2['Parch'], drop_first = True)\nprint('Parch has been encoded using pd.get_dummies()')\ndummy_p.columns = ['Parch_1', 'Parch_2', 'Parch_3', 'Parch_4', 'Parch_5', 'Parch_6']\ndummy_p.head()","82a8f501":"dummy_e = pd.get_dummies(df2['Embarked'], drop_first = True)\nprint('Embarked has been encoded using pd.get_dummies()')\ndummy_e.columns = ['Q', 'S']\ndummy_e.head()","37a3748d":"dfnew = pd.concat([df2, dummy_s, dummy_p, dummy_e], axis = 1)\ndfnew.drop(['Parch', 'SibSp', 'Embarked'], axis = 1, inplace = True)\ndfnew.head()","b52dffed":"x = dfnew.drop('Survived', axis = 1)\ny = dfnew.Survived","1980e4fc":"#from sklearn.preprocessing import MinMaxScaler\n#data = x.copy()\n#scaler = MinMaxScaler()\n#scaler.fit_transform(data)","e9bc7d78":"#dat = pd.DataFrame(scaler.fit_transform(data), columns = data.columns)","f7440ba1":"#dat.head()","a4a97bb5":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n\nprint('''The dimension of the training set is {}\nThe dimension of the test set is {}'''.format(X_train.shape, X_test.shape))","4ffa3a33":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier","b6a0f4e6":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","91db51c2":"mod = {\n    'logreg': {\n        'model': LogisticRegression(max_iter = 5000),\n        'params': {\n            'C': np.arange(0.1, 10, 0.5),\n            'solver': ['liblinear', 'saga']\n        }\n    },\n    'svm': {\n        'model': SVC(gamma = 'auto'),\n        'params': {\n            'C': np.arange(0.1, 10, 0.5),\n            'kernel':['rbf', 'linear']\n        }\n    },\n    'randomforest': {\n        'model': RandomForestClassifier(),\n        'params': {\n            'criterion': ['gini', 'entropy'],\n            'n_estimators': np.arange(50,150,10)\n        }\n    },\n    'ada': {\n        'model': AdaBoostClassifier(),\n        'params': {\n           'n_estimators' : np.arange(50,160,10),\n            'learning_rate': np.arange(0.1, 1.1, 0.1)\n        }\n    },\n    'grad': {\n        'model': GradientBoostingClassifier(),\n        'params': {\n            'n_estimators' : np.arange(50,160,10),\n            'learning_rate': np.arange(0.1, 1.1, 0.1)\n        }\n    },\n    'xg': {\n        'model': XGBClassifier(),\n        'params': {\n            'n_estimators': np.arange(50,160,10),\n            'learning_rate': np.arange(0.1, 1.1, 0.1)\n        }\n    }\n}","2ebd1560":"scores = []\nfor model_name, mp in mod.items():\n    clf = GridSearchCV(mp['model'], mp['params'], cv = 5)\n    clf.fit(X_train, y_train)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })","1be7bdbe":"dfres = pd.DataFrame(scores,columns = ['model', 'best_score', 'best_params'])\ndfres","982ab809":"dfres.loc[3, 'best_params']","6f78732c":"lr_cv = cross_val_score(LogisticRegression(C = 6.6, solver = 'liblinear', max_iter = 5000), X_test, y_test, cv = 5).sum()\/5\nsvm_cv = cross_val_score(SVC(C = 3.1, kernel = 'linear'), X_test, y_test, cv = 5).sum()\/5\nrf_cv = cross_val_score(RandomForestClassifier(n_estimators = 60, criterion = 'gini'), X_test, y_test, cv = 5).sum()\/5\nada_cv = cross_val_score(AdaBoostClassifier(n_estimators = 150, learning_rate = 0.2), X_test, y_test, cv = 5).sum()\/5\ngrad_cv = cross_val_score(GradientBoostingClassifier(n_estimators = 60, learning_rate = 0.2), X_test, y_test, cv = 5).sum()\/5\nxg_cv = cross_val_score(XGBClassifier(n_estimators = 50, learning_rate = 0.1), X_test, y_test, cv = 5).sum()\/5\nprint('''Cross Validation Score for the test dataset using,\nLogistic Regression is {}\nsvm is {}\nRandom Forest is {}\nAdaBoost is {}\nGradientBoosting is {}\nXgBoost is {}'''.format(lr_cv, svm_cv, rf_cv, ada_cv, grad_cv, xg_cv))","e4dae90e":"test.head()","20ad8d00":"df = test.drop(['PassengerId', 'Ticket', 'Cabin'], axis = 1)\ndf['Sex'] = np.where(df['Sex'] == 'male', 1, 0)\nprint('The unused columns have been dropeed and Sex column has been encoded')\ndf.head()","c5e627e4":"df.isna().sum()","8732438f":"print('We can see some missing values in the Age column and Fare column')\ndf.info()","94bd2c1b":"df.fillna(df['Age'].median(), axis = 0, inplace = True)\ndf.fillna(df['Fare'].mean(), axis = 0, inplace = True)\nprint('Missing values have been dealt with in a similar fashion')\ndf.info()","7c2b345c":"for row  in df.index:\n    if df.loc[row, 'Fare'] == 0:\n        pass\n    else:\n        df.loc[row, 'Fare'] = np.log(df.loc[row, 'Fare'])","e4951f3b":"for row in df.index:\n    df.loc[row,'Name'] = df.loc[row,'Name'].split('.')[0].split(',')[-1].strip()","cb9e3b0c":"df['Name'].replace({'Mr':1,\n                     'Mrs':2,'Mme':2,'Ms': 2,\n                    'Miss': 3, 'Mlle': 3, \n                    'Dr':3, 'Rev': 3,\n                     'Col':3, 'Major': 3,'Capt': 3,\n                     'Master': 4,\n                     'Lady':5, 'the Countess':5, 'Jonkheer':5, 'Don': 5,'Dona': 5, 'Sir': 5\n                     }, inplace = True)","864e89d5":"df.head()","4e90642a":"d_s = pd.get_dummies(df['SibSp'], drop_first = True)\nprint('SibSp has been encoded using pd.get_dummies()')\nd_s.columns = ['SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8']\nd_s.head()","fc4616d5":"d_p = pd.get_dummies(df['Parch'], drop_first = True)\nd_p.drop(9, axis = 1, inplace = True)\nprint('Parch has been encoded using pd.get_dummies()')\nd_p.columns = ['Parch_1', 'Parch_2', 'Parch_3', 'Parch_4', 'Parch_5', 'Parch_6']\nd_p.head()","d1d954a4":"d_e = pd.get_dummies(df['Embarked'], drop_first = True)\nprint('Embarked has been encoded using pd.get_dummies()')\nd_e.head()","6bc48574":"dft = pd.concat([df, d_s, d_p, d_e], axis = 1)\ndft.drop(['SibSp', 'Parch', 'Embarked'], axis = 1, inplace = True)\ndft.head()","6de1e63f":"x.head()","ba9d7693":"dft.isna().sum()","143b2594":"print('The test dataset is ready!')","907724a7":"lr_cv = cross_val_score(LogisticRegression(C = 4.1, solver = 'liblinear', max_iter = 5000), X_test, y_test, cv = 5).sum()\/5\nsvm_cv = cross_val_score(SVC(C = 6.6, kernel = 'linear'), X_test, y_test, cv = 5).sum()\/5\nrf_cv = cross_val_score(RandomForestClassifier(n_estimators = 130, criterion = 'gini'), X_test, y_test, cv = 5).sum()\/5\nada_cv = cross_val_score(AdaBoostClassifier(n_estimators = 130, learning_rate = 0.2), X_test, y_test, cv = 5).sum()\/5\ngrad_cv = cross_val_score(GradientBoostingClassifier(n_estimators = 110, learning_rate = 0.2), X_test, y_test, cv = 5).sum()\/5\nxg_cv = cross_val_score(XGBClassifier(n_estimators = 80, learning_rate = 0.2), X_test, y_test, cv = 5).sum()\/5\nprint('''Cross Validation Score for the test dataset using,\nLogistic Regression is {}\nsvm is {}\nRandom Forest is {}\nAdaBoost is {}\nGradientBoosting is {}\nXgBoost is {}'''.format(lr_cv, svm_cv, rf_cv, ada_cv, grad_cv, xg_cv))","94487c5a":"logreg = LogisticRegression(solver = 'liblinear', C = 4.1)\n\nlogreg.fit(X_train,y_train)\ny_predlr = logreg.predict(dft)\ny_predlr","67f162e2":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = y_predlr\nsubmission.head()","a0cebeab":"submission.to_csv('lr.csv', index = False)","7741f697":"xg = XGBClassifier(n_estimators = 80, learning_rate = 0.2)\nxg.fit(X_train,y_train)\ny_predxg = xg.predict(dft)\ny_predxg","2bf2bdc5":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = y_predxg\nsubmission.head()","70e758cd":"submission.to_csv('xg.csv', index = False)","ab46beda":"ada = AdaBoostClassifier(n_estimators = 130, learning_rate = 0.2)\nada.fit(X_train,y_train)\ny_predada = ada.predict(dft)\ny_predada","091cccd3":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = y_predada\nsubmission.head()","3cdde820":"submission.to_csv('ada.csv', index = False)","ddd51b8b":"gb = GradientBoostingClassifier(n_estimators = 110, learning_rate = 0.2)\ngb.fit(X_train,y_train)\ny_predgb = gb.predict(dft)\ny_predgb","3fb0d940":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = y_predgb\nsubmission.head()","12e0a5c5":"submission.to_csv('gb.csv', index = False)","be56ba8c":"svm = SVC(C = 6.6, kernel = 'linear')\nsvm.fit(X_train,y_train)\ny_predsvm = svm.predict(dft)\ny_predsvm","c05b793b":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = y_predsvm\nsubmission.head()","28067ddf":"submission.to_csv('svm.csv', index = False)","03315229":"- The Name column has been substituted withe their respective title","5e791b52":"#### The **'Sex'** column has been encoded: 1 for male and 0 for female\n#### The **'Pclass'** is already label encoded so we will have to encode **'SibSp'**, **'Parch'**, **'Embarked'**","59ec5ddd":"#### - taking the threshold to be -0.5 and 0.5:","6dd46cde":"#### The above analysis shows that we have a few outliers in the **'Age'** column and they need to be removed","50433663":"## 4. Sibsp","5a20e4cc":"## 3. Age","9d2a7c05":"#### - **'Pclass'** and **'Fare'** are significantly correlated so we will drop **'Fare'** from our analysis.","c01becfe":"#### Now let us look at our test dataset,","7706f7b7":"#### The above analysis shows that the richer section of the society had a better chance of survival as:\n#### 1. almost 63% of the people aboard the 1st class survived.\n#### 2. 47% aboard the 2nd class survived.\n#### 3. only 24% of the passengers aboard the 3rd class survived.","ddf341d3":"## 5. Parch","4130ba4e":"#### The above analysis shows that the women and children were given preference to get aboard the lifeboats as:\n#### 1. 74.2% of the women survived and only 18.89% men could make it.","b6ee9b8b":"#### Now we will split our dataset into training and testing with test size of 20% of the total size of the dataset.","85f24023":"## 2. Pclass","59dc914c":"#### The above analysis shows that 3 out of 5 families with 3 Parents\/Children survived.\n#### 55% of those who had 1 Parent\/Child survived.\n#### 34% of the people who boarded the Titanic alone survived.","0a168482":"- 'Mr' is the general title gireplaceto a man\n- 'Mrs' is for women\n- 'Miss' title of respect to an unmarried woman\n- 'Master' a boy\n- 'Dr' Doctor\n- 'Rev' Reverend: officially appointed religious leader\n- 'col' Colonel: senior military officer rank\n- 'Mlle' 'Madamoiselle' the french equivalent of 'Miss'\n- 'Major' below the rank of colonel\n- 'Lady' title of nobility\n- 'the countess' another title of nobility\n- 'Jonkheer' lowest rank within the nobility\n- 'Don' also an honorary title\n- 'Capt' captain of the ship\n- 'mme' similar to 'Mlle'","34e64cd1":"#### This is how our final dataframe looks like, now we will separate the target variable from features","ed5f3450":"#### The above analysis shows that passengers with 1 or 2 Siblings\/Spouse had a higher chance of survival compared to those who had more Siblings\/Spouse.","f70edb69":"## 6. Embarked","e29ca661":"#### - For simplicity, we can fill the NaN values in the **'Age'** column with the median of that column","d45a084d":"- It will be better to group together a few titles as there are not a lot of some of them present. \n\n1. 'Mr.', 'Sir' and 'Capt group 1\n2. 'Mrs.', 'Miss', 'Mlle', 'mme', 'Ms' group 2\n3. 'Dr', 'rev' group 3\n4. 'col', 'major' group 4\n5. 'master' group 5\n6. 'Lady', 'countess', 'Jonkheer', 'Don' group 6","8154a6dc":"#### - The **'Cabin'** column has more than 75% missing values so we will just drop it from our analysis.\n#### - The **'Embarked'** column has just 2 missing values so we can fill then by the mode of the column.\n#### - The **'Age'** column has a significant number of missing values and we will have to come up with a good way to deal with them.\n","70c1ef70":"#### The above analysis shows us that children(age between 0-15) had a better chance of survival than others.","185cc025":"#### Now we will concatenate all the dummies with our original dataframe and drop the corresponding columns","5942bf77":"## Encoding Categorical Variables","748754fb":"## 1.Sex","40ad79bd":"#### The above analysis shows that 55% of the people whose port was Cherbourg survived."}}