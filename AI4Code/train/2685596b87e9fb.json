{"cell_type":{"1ae9d43d":"code","c4985ab1":"code","b0428e30":"code","88a11257":"code","a5fd35e2":"code","08ef996f":"code","7469e7b0":"code","749a4057":"code","bebec32f":"code","cd51f225":"code","d6a50863":"code","6088f759":"code","1233a2b8":"code","d5965b17":"code","76140660":"code","3ad7de42":"code","cbe6e632":"code","4d036556":"code","8828e8d1":"code","ede5ed67":"markdown","a53fc955":"markdown","d9ee4785":"markdown","f14bb4bc":"markdown","74960f33":"markdown","c7f15dce":"markdown","c6a6ba91":"markdown","74e6c954":"markdown","9d1270d9":"markdown"},"source":{"1ae9d43d":"# Created by Viswadeep Sarangi\n# Last updated: 14 August 2020\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4985ab1":"from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz","b0428e30":"import torch","88a11257":"df = pd.read_csv('\/kaggle\/input\/us-border-crossing-data\/Border_Crossing_Entry_Data.csv')\n\nprint(df.info())","a5fd35e2":"def encode_target(df, target_column, drop_original_column=False):\n    \"\"\"Add column to df with integers for the target.\n\n    Args\n    ----\n    df -- pandas DataFrame.\n    target_column -- column to map to int, producing\n                     new Target column.\n\n    Returns\n    -------\n    df_mod -- modified DataFrame.\n    targets -- list of target names.\n    \"\"\"\n    df_mod = df.copy()\n    targets = df_mod[target_column].unique()\n    map_to_int = {name: n for n, name in enumerate(targets)}\n    df_mod[\"Target\"] = df_mod[target_column].replace(map_to_int)\n\n    if(drop_original_column):\n        df_mod = df_mod.drop(columns=[target_column])\n        print(\"Dropped Column: {}\".format(target_column))\n    \n    return (df_mod, targets)","08ef996f":"def encode_and_replace_column(df, target_column):\n    \"\"\"Add column to df with integers for the target.\n\n    Args\n    ----\n    df -- pandas DataFrame.\n    target_column -- column to map to int, producing\n                     new Target column.\n\n    Returns\n    -------\n    df_mod -- modified DataFrame.\n    targets -- list of target names.\n    \"\"\"\n    df_mod = df.copy()\n    targets = df_mod[target_column].unique()\n    map_to_int = {name: n for n, name in enumerate(targets)}\n    df_mod[target_column] = df_mod[target_column].replace(map_to_int)\n\n    return (df_mod, targets)","7469e7b0":"def visualize_tree(tree, feature_names):\n    \"\"\"Create tree png using graphviz.\n\n    Args\n    ----\n    tree -- scikit-learn DecsisionTree.\n    feature_names -- list of feature names.\n    \"\"\"\n    with open(\"dt.dot\", 'w') as f:\n        export_graphviz(tree, out_file=f,\n                        feature_names=feature_names)\n\n    command = [\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"]\n    try:\n        subprocess.check_call(command)\n    except:\n        exit(\"Could not run dot, ie graphviz, to \"\n             \"produce visualization\")","749a4057":"# Creating the numerical targets instead of the categorical state names\ndf_state, targets_state = encode_target(df, \"State\", drop_original_column=True)\n\n# Converting a lot of categorical values into numerical values\ndf_state, _ = encode_and_replace_column(df_state, \"Border\")\ndf_state, _ = encode_and_replace_column(df_state, \"Measure\")\n\n# Converting the Date column into numerical values for now only. TODO. Convert them into proper DateTime formats\ndf_state, _ = encode_and_replace_column(df_state, \"Date\")\n\n# Don't really need the \"Port Name\" column, \"Port Code\" is sufficient\ndf_state = df_state.drop(columns=[\"Port Name\"], axis = 1)","bebec32f":"print(\"@@@ Before\")\nprint(df.info())\nprint(df.head())\nprint(\"\\n@@@ After\")\nprint(df_state.info())\nprint(df_state.head())","cd51f225":"train, test = train_test_split(df_state, test_size=0.2)\n\nprint(train.info())\nprint()\nprint(test.info())","d6a50863":"print(train.info())\nprint()\nprint(test.info())\nprint()\nprint(targets_state)\nprint()\nprint(train.head())\nprint()\nprint(test.head())","6088f759":"features = list(df_state.columns[:5])\nprint(\"* features:\", features, sep=\"\\n\")","1233a2b8":"y = train[\"Target\"]\nX = train[features]\ndt = DecisionTreeClassifier(min_samples_split=20, random_state=99)\ndt.fit(X, y)","d5965b17":"visualize_tree(dt, features)","76140660":"b = test[\"Target\"]\nA = test[features]\nb_np = b.to_numpy()\n\nprint(b)\nprint()\nprint(b_np)\nprint()\nprint(A.info())","3ad7de42":"accuracy = dt.score(A, b)\nprint(\"Mean Accuracy: {}%\".format(accuracy*100))","cbe6e632":"predictions = dt.predict(A)\n\nfor i in range(len(predictions)):\n    print(\"Predicted: {}, Actual:{}\".format(targets_state[predictions[i]], targets_state[b_np[i]]))","4d036556":"dtype = torch.float\ndevice = torch.device(\"cpu\")\n# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n\n# N is batch size; D_in is input dimension;\n# H is hidden dimension; D_out is output dimension.\nN, D_in, H, D_out = 64, 1000, 100, 10\n","8828e8d1":"# Create random Tensors to hold inputs and outputs\nx = torch.randn(N, D_in)\ny = torch.randn(N, D_out)\n\n# Use the nn package to define our model and loss function.\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(D_in, H),\n    torch.nn.ReLU(),\n    torch.nn.Linear(H, D_out),\n)\nloss_fn = torch.nn.MSELoss(reduction='sum')\n\n# Use the optim package to define an Optimizer that will update the weights of\n# the model for us. Here we will use Adam; the optim package contains many other\n# optimization algorithms. The first argument to the Adam constructor tells the\n# optimizer which Tensors it should update.\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nfor t in range(500):\n    # Forward pass: compute predicted y by passing x to the model.\n    y_pred = model(x)\n\n    # Compute and print loss.\n    loss = loss_fn(y_pred, y)\n    if t % 100 == 99:\n        print(t, loss.item())\n\n    # Before the backward pass, use the optimizer object to zero all of the\n    # gradients for the variables it will update (which are the learnable\n    # weights of the model). This is because by default, gradients are\n    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n    # is called. Checkout docs of torch.autograd.backward for more details.\n    optimizer.zero_grad()\n\n    # Backward pass: compute gradient of the loss with respect to model\n    # parameters\n    loss.backward()\n\n    # Calling the step function on an Optimizer makes an update to its\n    # parameters\n    optimizer.step()","ede5ed67":"http:\/\/chrisstrelioff.ws\/sandbox\/2015\/06\/08\/decision_trees_in_python_with_scikit_learn_and_pandas.html\n\nIn order to pass this data into scikit-learn we need to encode the Names to integers. To do this we\u2019ll write another function and return the modified data frame as well as a list of the target (class) names:","a53fc955":"Now that the Decision Tree is trained, time to test it","d9ee4785":"# 2. Objective : Create a Feed Forward Neural Network in PyTorch to classify State","f14bb4bc":"Loading up the csv file","74960f33":"We can now fit the Decision Tree in classifying the \"State\"","c7f15dce":"## **Preprocessing**","c6a6ba91":"Splitting the dataframe into train and test","74e6c954":"### Random Test","9d1270d9":"## 1. Objective: To use a ID3 decision tree from sklearn to classify \"State\""}}