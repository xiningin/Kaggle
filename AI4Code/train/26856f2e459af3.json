{"cell_type":{"d8e088b9":"code","6f14482b":"code","5de1ff82":"code","4265acf1":"code","0caaaf65":"code","2db78dd0":"code","467cd85f":"code","34bdd009":"code","4efb3a2b":"code","e1e2a9a8":"code","da25ac93":"code","d4347e29":"code","34d37917":"code","7f766ad9":"code","a708dd5e":"code","35322739":"code","5332e943":"code","3fd7731d":"code","ad8de3f8":"code","fea0c973":"code","424e7d68":"code","5bf8aa74":"code","56988c94":"code","fe0c7940":"code","0c5f5005":"code","ba49aa22":"code","b315150d":"code","ec462e90":"code","400a1c04":"code","2c7e141a":"code","f3e1d168":"code","de890352":"code","4b40e4f5":"code","63f74416":"code","3efcb305":"code","d592f14e":"code","fa4d2cbf":"code","ef36886b":"code","fa1c56cf":"code","38a944db":"markdown","3e27e32b":"markdown","784762b9":"markdown","51224abc":"markdown","9c7cfa64":"markdown","fdc975c3":"markdown","7ffafee6":"markdown","e7e467b4":"markdown","6621f108":"markdown","37235e3e":"markdown","ce3551b2":"markdown","62575064":"markdown","42b36bbf":"markdown","1220cc14":"markdown","9629462d":"markdown","a84c62f4":"markdown","644cb06a":"markdown","7b5f1c22":"markdown","34d59584":"markdown","1265a0ca":"markdown","418d29f8":"markdown","6a31083b":"markdown","b86acd8d":"markdown"},"source":{"d8e088b9":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt","6f14482b":"from keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AvgPool2D, BatchNormalization, Reshape\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n","5de1ff82":"# Lecture du r\u00e9pertoire Kaggle\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4265acf1":"import pickle","0caaaf65":"with open('..\/input\/traffic-signs-preprocessed\/data3.pickle', 'rb') as f:\n    data = pickle.load(f, encoding='latin1')","2db78dd0":"X_train = data['x_train']\ny_train = data['y_train']","467cd85f":"X_train.shape","34bdd009":"X_train = X_train.transpose(0,2,3,1)","4efb3a2b":"X_train.shape","e1e2a9a8":"y_train.shape","da25ac93":"y_train[0]","d4347e29":"labels = ['Speed limit (20km\/h)',\n 'Speed limit (30km\/h)',\n 'Speed limit (50km\/h)',\n 'Speed limit (60km\/h)',\n 'Speed limit (70km\/h)',\n 'Speed limit (80km\/h)',\n 'End of speed limit (80km\/h)',\n 'Speed limit (100km\/h)',\n 'Speed limit (120km\/h)',\n 'No passing',\n 'No passing for vehicles over 3.5 metric tons',\n 'Right-of-way at the next intersection',\n 'Priority road',\n 'Yield',\n 'Stop',\n 'No vehicles',\n 'Vehicles over 3.5 metric tons prohibited',\n 'No entry',\n 'General caution',\n 'Dangerous curve to the left',\n 'Dangerous curve to the right',\n 'Double curve',\n 'Bumpy road',\n 'Slippery road',\n 'Road narrows on the right',\n 'Road work',\n 'Traffic signals',\n 'Pedestrians',\n 'Children crossing',\n 'Bicycles crossing',\n 'Beware of ice\/snow',\n 'Wild animals crossing',\n 'End of all speed and passing limits',\n 'Turn right ahead',\n 'Turn left ahead',\n 'Ahead only',\n 'Go straight or right',\n 'Go straight or left',\n 'Keep right',\n 'Keep left',\n 'Roundabout mandatory',\n 'End of no passing',\n 'End of no passing by vehicles over 3.5 metric tons']","34d37917":"plt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(X_train[i])\n    plt.title(labels[y_train[i]])","7f766ad9":"X_test = data['x_test'].transpose(0,2,3,1)\ny_test = data['y_test']","a708dd5e":"num_classes = len(labels)","35322739":"unique_elements, counts_elements = np.unique(y_test, return_counts=True)\nprint(\"Comptage des valeurs :\")\nprint(np.asarray((unique_elements, counts_elements)))","5332e943":"# Normalisation entre 0 et 1\nX_train = X_train \/ 255\nX_test = X_test \/ 255","3fd7731d":"y_train1 = to_categorical(y_train)\ny_test1 = to_categorical(y_test)","ad8de3f8":"y_test1","fea0c973":"# R\u00e9seau convolutionnel simple\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","424e7d68":"model.summary()","5bf8aa74":"# Apprentissage\ntrain = model.fit(X_train, y_train1, validation_data=(X_test, y_test1), epochs=20, batch_size=200, verbose=1)","56988c94":"# Test\nscores = model.evaluate(X_test, y_test1, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","fe0c7940":"print(train.history['accuracy'])","0c5f5005":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","ba49aa22":"plot_scores(train)","b315150d":"# Prediction\ny_cnn = model.predict_classes(X_test)","ec462e90":"cm = confusion_matrix(y_cnn,y_test)\nprint(cm)\nplt.figure(figsize = (12,10))","400a1c04":"X_test = X_test * 255\nplt.figure(figsize=(30,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j]) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        pred_classe = y_cnn[j].argmax(axis=-1)\n        plt.title('%s \/ %s' % (labels[int(y_cnn[j])], labels[int(y_test[j])]))\n        i+=1\nX_test = X_test \/ 255","2c7e141a":"# Mod\u00e8le CNN plus profond\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu'))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))","f3e1d168":"# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","de890352":"model.summary()","4b40e4f5":"train = model.fit(X_train, y_train1, validation_data=(X_test, y_test1), epochs=50, batch_size=200, verbose=1)","63f74416":"# Test\nscores = model.evaluate(X_test, y_test1, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","3efcb305":"plot_scores(train)","d592f14e":"X_test = X_test * 255\nplt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j]) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        pred_classe = y_cnn[j].argmax(axis=-1)\n        plt.title('%s \/ %s' % (labels[int(y_cnn[j])], labels[int(y_test[j])]))\n        i+=1\nX_test = X_test \/ 255","fa4d2cbf":"model.save('mnist_cnn2.h5')","ef36886b":"from keras.models import Sequential, load_model\n\nnew_model = load_model('mnist_cnn2.h5')\nnew_model.summary()","fa1c56cf":"scores = new_model.evaluate(X_test, y_test1, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","38a944db":"On remarque que le mod\u00e8le se trompe sur des images toute noir, ce qui est strictement impossible d'identifier que ce soit par une machine ou un humain, ce qui signifit que ces erreurs sont normales. Elle se trompe \u00e9galement sur des images tr\u00e8s sombres et sur l'identification des symboles et des vitesses qui est aussi impossible pour un humain surtout vue la qualit\u00e9 de l'image.\nLe score de 83% est un bon score sachant qu'il y a des images \u00e9rron\u00e9s dans le tableau.","3e27e32b":"On peut afficher la structure du mod\u00e8le :","784762b9":"On lit le fichier \"data3.pickle\" qui contient les images pr\u00e9trait\u00e9es","51224abc":"# Mod\u00e8le CNN plus profond","9c7cfa64":"# Une couche convolutionnelle","fdc975c3":"# Reconnaissance des signalisations routi\u00e8res","7ffafee6":"<img src=\"https:\/\/saferautohome.files.wordpress.com\/2019\/04\/traffic-signs-gtsdb.png?w=1400\">","e7e467b4":"Il existe plusieurs datasets de \"traffic signs\", cf par exemple :  \nhttps:\/\/saferauto.home.blog\/2019\/04\/03\/3o-databases-for-traffic-signs-detection\/  \nOu :  \nhttps:\/\/github.com\/dctian\/DeepPiCar\/tree\/master\/models\/object_detection\/data\/images\/train  \n(avec identification des zones pour de la d\u00e9tection d'objet)","6621f108":"## Lecture des donn\u00e9es","37235e3e":"On remarque que certaines images sont quasiement toutes noires et sont inreconnaissable par l'humain et ne devrait non plus \u00eatre possible pour la machine.","ce3551b2":"## Importation des librairies","62575064":"On remarque que cette m\u00e9thode est bien plus efficace que la pr\u00e9c\u00e9dente avec une pr\u00e9cision de 95.56% compar\u00e9 au 83% pr\u00e9c\u00e9dent.  \nOn observe \u00e9galement que la courbe des tests est quasi similaire \u00e0 la courbe d'apprentissage ce qui montre l'efficacit\u00e9 de cette m\u00e9thode.  \nL'une des solutions enivisageable pour une am\u00e9lioration serait de retirer les images peut petinente (totue noir ou presque) ce qui permetrait d'am\u00e9liorer le la pr\u00e9cision d'apprentissage. Ou de ne pas prendre en compte les images toutes noirs pour les tests.","42b36bbf":"On peut ensuite utiliser le mod\u00e8le sans recommencer l'entra\u00eenement :","1220cc14":"On affiche 50 images o\u00f9 l'algorithme s'est tromp\u00e9 :","9629462d":"On va utiliser ici un dataset Kaggle :  \nhttps:\/\/www.kaggle.com\/valentynsichkar\/traffic-signs-preprocessed","a84c62f4":"## Exercice : utiliser les r\u00e9seaux convolutionnels, et ensuite le transfer learning pour reconna\u00eetre les signalisations routi\u00e8res","644cb06a":"On teste un mod\u00e8le avec plus de couches convolutionnelles :","7b5f1c22":"Les donn\u00e9es sont encod\u00e9es avec Pickle :  \nhttps:\/\/docs.python.org\/3\/library\/pickle.html","34d59584":"On va utiliser utiliser une couche convolutionnelle pour l'extraction des caract\u00e9ristiques, et une couche dense pour la classification :","1265a0ca":"Le mod\u00e8le entrain\u00e9 peut \u00eatre sauvegard\u00e9 :","418d29f8":"La variable train m\u00e9morise l'historique des scores sur l'ensemble d'apprentissage :","6a31083b":"On d\u00e9finit une fonction pour afficher un graphique des scores :","b86acd8d":"On peut afficher la matrice de confusion :"}}