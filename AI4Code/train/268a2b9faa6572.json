{"cell_type":{"cd292098":"code","e824eb49":"code","9ab78ce3":"code","aadae99c":"code","5b9492cb":"code","d65b1749":"code","9245d3cc":"code","f30200fa":"code","cc02b703":"code","a1859592":"code","828c7755":"code","c0641b4e":"code","29ff5ff6":"code","8c1deb52":"code","2b44aa1c":"code","d9f45cd6":"code","cef5261b":"code","08fae12e":"code","80135d0a":"code","a0c06ab2":"code","6cec6619":"code","d92e6fa9":"code","7857e92d":"code","aa07325a":"code","53fceb6c":"code","b4e05bfd":"code","7c2acd73":"markdown","9e7665bf":"markdown","0f0d3428":"markdown","ba0c71ea":"markdown","cc608f59":"markdown","03fcaa1d":"markdown","2f8ae370":"markdown","d44e721b":"markdown","fdee32a9":"markdown","0a31bc92":"markdown","24827bc1":"markdown","cda88830":"markdown","50cfed8e":"markdown","d34123dd":"markdown","58ea840d":"markdown","47e4be69":"markdown","5fc27950":"markdown","251b4597":"markdown","94df99b4":"markdown","889419f7":"markdown","755e5cf9":"markdown","9c6eff77":"markdown","ad131e37":"markdown","d850f349":"markdown","3c61961a":"markdown","1bfc69ec":"markdown","80322efb":"markdown","cbe4683f":"markdown"},"source":{"cd292098":"import numpy as np \nimport pandas as pd \n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style(\"whitegrid\")\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e824eb49":"training = pd.read_csv(\"..\/input\/train.csv\")\ntesting = pd.read_csv(\"..\/input\/test.csv\")","9ab78ce3":"training.head()","aadae99c":"print(training.shape)","5b9492cb":"X_train = training.drop(\"label\", axis=1)\ny_train = training[\"label\"]","d65b1749":"ax = plt.hist(y_train)","9245d3cc":"plt.figure(figsize=(14, 10))\n\ndef show_images(numbers):\n    for i in range(1, numbers + 1):\n        plt.subplot(5, 10, i)\n        image = X_train.iloc[i].as_matrix()\n        image = image.reshape((28,28))\n        plt.imshow(image, cmap='gray')\n        plt.xticks([]), plt.yticks([])\n        plt.title(y_train[i])\n\nshow_images(50)","f30200fa":"max(training[\"pixel99\"])","cc02b703":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\ndef rescale_table(table):\n    table = table.astype(\"float32\")\n    for i in table:\n        reshaped_array = np.array(table[i]).reshape(-1, 1)\n        table[i] = scaler.fit_transform(reshaped_array)\n    return table\n\nX_train = rescale_table(X_train)\n\nX_test = testing\nX_test = rescale_table(X_test)\n\n#delete old sets to free space\ndel training\ndel testing","a1859592":"X_train.sample(10)","828c7755":"max(X_train[\"pixel99\"])","c0641b4e":"set(y_train)","29ff5ff6":"def one_hot_encode(series):\n    return pd.get_dummies(series).as_matrix()\n\ny_train = one_hot_encode(y_train)","8c1deb52":"y_train","2b44aa1c":"from sklearn.model_selection import train_test_split\n\nX_training, X_valid, y_training, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)","d9f45cd6":"import tensorflow as tf","cef5261b":"learning_rate = 0.3\nepochs = 100\n\nx = tf.placeholder(tf.float32, [None, 784])\nW = tf.Variable(tf.zeros([784, 10]))\nbias = tf.Variable(tf.zeros([10]))\n\ny_true = tf.placeholder(tf.float32, [None, 10])\ny_prediction = tf.nn.softmax(tf.matmul(x, W) + bias)","08fae12e":"#our loss function is cross entropy\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_prediction, labels=y_true))","80135d0a":"correct_predictions = tf.equal(tf.argmax(y_prediction,1), tf.argmax(y_true,1))\naccuracy_measure = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))","a0c06ab2":"#optimizer we will use\ntraining_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)","6cec6619":"sess = tf.InteractiveSession()\n\ninit = tf.global_variables_initializer()\nsess.run(init)","d92e6fa9":"#training the model with Gradient Descent\nfor i in range(epochs + 1):\n    sess.run(training_step, feed_dict={x: X_train, y_true: y_train})\n    print(\"Epoch \" + str(i) + \" accuracy: \" + str(sess.run(accuracy_measure, feed_dict={x: X_valid, y_true: y_valid})))","7857e92d":"sess.run(accuracy_measure, feed_dict={x: X_valid, y_true: y_valid})","aa07325a":"predictions = tf.argmax(y_prediction, 1)\npredicted_labels = predictions.eval(feed_dict={x: X_test})\nprint(predictions.eval(feed_dict={x: X_test}))","53fceb6c":"sess.close()","b4e05bfd":"np.savetxt('submission_softmax.csv', \n           np.c_[range(1,len(X_test)+1), predicted_labels], \n           delimiter = ',', \n           header = 'ImageId,Label', \n           comments = '', \n           fmt = '%d')","7c2acd73":"This is just a sample of what the different numbers that we're trying to classify look like. The label is on top of each number, and you can see the contrast between the black and white pixels, which is highlighted by our data.","9e7665bf":"# TensorFlow Softmax Regression to Classify Numbers\n\nThis problem is more complicated than the regular classification\/regression Machine Learning problems like House Prices or Titanic Survivors. In this problem, we have to classify a number, given the pixels. We are given a data set with pixels at different locations of the entire grid of the number. This is known as a Deep Learning problem, a more advanced application of Machine Learning. In this kernel, we will build a TensorFlow Softmax Regression model with a SGD optimizer to help us with the classification. \n\nBefore we get started, however, you should know the basics of Machine Learning beforehand. TensorFlow has a larger library than sklearn and is more complicated to use. Be sure to read my kernel on [regression](https:\/\/www.kaggle.com\/samsonqian\/predicting-house-prices-with-regression) and [classification](https:\/\/www.kaggle.com\/samsonqian\/titanic-guide-with-sklearn-and-eda) before this one!\n\n*Please upvote if this kernel helps you! Feel free to fork this notebook to play with the code yourself.* If you may have any questions about the code, or any step of the process, please comment and I will clear up any confusion.","0f0d3428":"<a id=\"p2\"><\/a>\n# 2. Exploring and Visualizing Data\nWe will now load and inspect our data. Since it's data of the pixels of the numbers, we don't need to do any visual analysis of the features, but we can take a peek at the visuals that the data generates. We should however, inspect the values of the data to make sure there are no extraneous values.","ba0c71ea":"Here is the accuracy of our model for the validation set:","cc608f59":"So it seems that the pixel values go from 0 all the way to 255. This may cause problems for us, and we should definitely seek to normalize the data so that our results are better. We'll do the preprocessing in the next section.","03fcaa1d":"## One-Hot-Encoding\nNow that we're done preprocessing our features, let's work with our label. The fact that the labels go from 1-9 is going to be troublesome because it implies that 8 is more similar to 9 than 2, just because the numbers are closer. This is not true, so we should remove this bias somehow. One-Hot-Encoding does a good job for this, since we can make a numpy array that describes each number with a 1. If this is confusing, look below and you will understand.","2f8ae370":"The special thing about TesnorFlow is that you can define operations and computations as variables. TensorFlow doesn't run these computations until you actually tell it to during a session, which we will get to later. For now, let's define our learning rate and epochs (number of times we want the model to iterate). These are constants that can be played around with and adjusted for better model performance.\n\nAlso, we need to define our prediction function. This will be in the form of y = W*x + b (bias). We need to define W, x, and bias first. Since we have the data we are going to feed the model, we define x as a placeholder where we will asign its value later. W and bias, however, are variables that will be changed when the model iterates. We also have the values of y_true, which are the actual labels, so we define that as a placeholder as well.","d44e721b":"Let's launch our session! In TensorFlow, you always launch a session to run computations and assign placeholder values. We also will train our model during the session. Let's initialize all the variables we defined.","fdee32a9":"First things first, we should always create a validation data set to evaluate our model and avoid overfitting. We use sklearn's train_test_split.","0a31bc92":"We also need a way to evaluate our model's performance for classifying the numbers. We can do this with the accuracy since it's a classification problem. ","24827bc1":"Pandas has a get_dummies method that helps us with one-hot-encoding, so we can use it on y_train!","cda88830":"Great! Now let's take another peek at our data.","50cfed8e":"Mostly zeros, but it's fine because they're float values and there are many values not shown that display a value greater than zero. As we can now see, the max value for our pixels is 1. Now, our data is normalized and we are ready to go.","d34123dd":"Ok, now let's make some predictions with the test set. We will submit these predictions to the competition.","58ea840d":"Always, Always, Always remember to close the session after you are done with the computations. ","47e4be69":"<a id=\"p1\"><\/a>\n# 1. Importing Packages\nThese will look familiar if you've seen my previous kernels. We will use the below Python packages to inspect and manipulate our data. We can visualize with seaborn and matplotlib. We always use these same packages when we are doing any type of Machine Learning. ","5fc27950":"<a id=\"p3\"><\/a>\n# 3. Preprocessing Data\nBefore we build our TensorFlow model, we should prepare the data first. We'll define our features and label and we'll scale all the data so it's more representative of what we're trying to predict.","251b4597":"Now let's train our model several times, depending on what we set epochs to be. We need a feed dictionary to tell the the function what the placeholder values are. ","94df99b4":"We need a goal for our model that we're building. If you read my previous kernel on regression, the goal was to minimize the RMSE. In this case, however, ince we are doing Softmax Regression, a common metric to use is cross-entropy, defined below. We would want to minimize our cross-entropy.","889419f7":"Here is our optimizer. We will use Gradient Descent since it is a very common and powerful method to minimize cross-entropy. We also give it a learning rate that we defined earlier to define how fast it should learn. We need to find a balance in the learning rate since both too low and high will yield bad results.","755e5cf9":"Now, as you can see, the numbers are all represented by 1s instead of the actual number. This gets rid of the bias we had before and we are ready to use this data in our model. Let's get to work building our model!","9c6eff77":"Seems like a pretty uniform distribution of all numbers 1-9! Let's take a look at what the numbers themselves actually look like.","ad131e37":"<a id=\"p4\"><\/a>\n# 4. TensorFlow Modelling\nIn this section, we will actually build our model and go over step-by-step of the process of doing so. If you are new to TensorFlow, this may be confusing at first, but you will eventually pick up on it. ","d850f349":"Looks like a lot of zeros. This doesn't tell us much about the what the numbers look like, so let's take a look at what this pixel data generates.","3c61961a":"<a id=\"p5\"><\/a>\n# 5. Submission\nWe will create a Data Frame to submit our predictions we made in the previous section.","1bfc69ec":"# Contents\n1. [Importing Packages](#p1)\n2. [Exploring and Visualizing Data](#p2)\n3. [Preprocessing Data](#p3)\n4. [TensorFlow Modelling](#p4)\n5. [Submission](#p5)","80322efb":"Of course we're also going to need to import TensorFlow.","cbe4683f":"First, we need to define the label and feature. We will convert these to float values so we can scale them by dividing by the max value, 255. We'll do this for both the training and test set."}}