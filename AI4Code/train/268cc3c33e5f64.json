{"cell_type":{"43f6b43a":"code","3a46dbcb":"code","0f0fde14":"code","a1d2fcd6":"code","df9dbb96":"code","d2cd6c03":"code","a681a49b":"code","669def47":"code","77d7ebd0":"code","fc2a3ea7":"code","798b5abf":"code","a00847bc":"code","e657ad34":"code","1a629364":"code","62c5a196":"code","cc113409":"code","bc0275e9":"code","c5f01a9b":"code","e9705f00":"code","5acc2478":"code","52a452ba":"code","dc1f1e48":"code","aa8f07ae":"code","c396c6f8":"code","2725fda0":"code","c4d65b41":"code","d6050b34":"code","03d781da":"code","9275cee5":"code","cc962367":"code","1dad2701":"code","8a4c881e":"code","860578fa":"code","fccc8edf":"markdown","2549335f":"markdown","b76123fa":"markdown","e5bc093b":"markdown","fc9081d1":"markdown","3bcf89f7":"markdown","9b3c81e0":"markdown","eac635bb":"markdown","4bb3f8e0":"markdown","5f4c492b":"markdown","e8556a00":"markdown","acfc8d9a":"markdown","f77432e4":"markdown","43cae0fb":"markdown","c992cbf9":"markdown","2741b250":"markdown","8baf89a1":"markdown"},"source":{"43f6b43a":"import numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nfrom tqdm import tqdm","3a46dbcb":"import torch \nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport pytorch_lightning as pl\n\nnp.random.seed(123)\n","0f0fde14":"tag = pd.read_csv(\"..\/input\/movielens-20m-dataset\/tag.csv\")\nmovies = pd.read_csv(\"..\/input\/movielens-20m-dataset\/movie.csv\")\nrating = pd.read_csv(\"..\/input\/movielens-20m-dataset\/rating.csv\")\nlink = pd.read_csv(\"..\/input\/movielens-20m-dataset\/link.csv\")\ngenome_tags = pd.read_csv(\"..\/input\/movielens-20m-dataset\/genome_tags.csv\")\ngenome_scores = pd.read_csv(\"..\/input\/movielens-20m-dataset\/genome_scores.csv\")","a1d2fcd6":"tag.head()","df9dbb96":"movies.head()","d2cd6c03":"rating.head()","a681a49b":"link.head()","669def47":"genome_tags.head()","77d7ebd0":"genome_scores.head()","fc2a3ea7":"el = rating[\"rating\"].value_counts().reset_index()\nel.columns = [\"rating\", \"percent\"]\nel[\"percent\"] \/= rating.shape[0]\n\nfig = px.pie(el,\n            names=\"rating\",\n            values=\"percent\",\n            title = \"Rating Percent\",\n            width = 800,\n            height=500\n            )\nfig.show()","798b5abf":"genres = movies[\"genres\"].values\ngenres = [genre.split(\"|\") for genre in genres]\ngenres_list = [item for sublist in genres for item in sublist]\nuniq_genres = list(set(genres_list))","a00847bc":"genres2count = {}\nfor item in uniq_genres:\n    genres_count = genres_list.count(item)\n    genres2count[item] = genres_count","e657ad34":"df_genres2count = pd.DataFrame(genres2count.items(), columns=['genres', 'count'])","1a629364":"genres_values = df_genres2count.genres.values\ncount_values = df_genres2count[\"count\"].values","62c5a196":"plt.figure(figsize=(12, 8))\nsns.barplot(genres_values, count_values, alpha=0.8)\nplt.ylabel('Number of Data', fontsize=12)\nplt.xlabel('target', fontsize=9)\nplt.xticks(rotation=90)\nplt.show()","cc113409":"movies['year'] = movies.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\nmovies.year = pd.to_datetime(movies.year, format='%Y')\nmovies.year = movies.year.dt.year \nmovies.title = movies.title.str[:-7]\ngenres_unique = pd.DataFrame(movies.genres.str.split('|').tolist()).stack().unique()\ngenres_unique = pd.DataFrame(genres_unique, columns=['genre']) # Format into DataFrame to store later\nmovies = movies.join(movies.genres.str.get_dummies().astype(bool))\nmovies.drop('genres', inplace=True, axis=1)\nmovies.dropna(inplace=True)\nmovies.sort_values(by='movieId', inplace=True)\nmovies.reset_index(inplace=True, drop=True)\n","bc0275e9":"plt.figure(figsize=(10,5))\n\n\ndftmp = movies[['movieId', 'year']].groupby('year')\ndf = pd.DataFrame({'All_movies' : dftmp.movieId.nunique().cumsum()})\n\nfor genre in genres_unique.genre:\n    dftmp = movies[movies[genre]][['movieId', 'year']].groupby('year')\n    df[genre]=dftmp.movieId.nunique().cumsum()\ndf.fillna(method='ffill', inplace=True)\ndf.loc[:,df.columns!='All_movies'].plot.area(stacked=True, figsize=(10,5))\n\nplt.plot(df['All_movies'], marker='o', markerfacecolor='black')\nplt.xlabel('Year')\nplt.ylabel('Cumulative number of movies-genre')\nplt.title('Total movies-genre') # Many movies have multiple genres, so counthere is higher than number of movies\nplt.legend(loc=(1.05,0), ncol=2)\nplt.show()\n","c5f01a9b":"dftmp = rating[['userId', 'movieId']].groupby('movieId').count()\ndftmp.columns=['num_ratings']\nrating.set_index('movieId').loc[dftmp.index[dftmp.num_ratings>40000]].groupby('movieId').mean().rating.plot(style='o')\nplt.ylabel('Average rating')\nplt.title('Most popular movies rating')\nplt.show()","e9705f00":"ratings = pd.read_csv('\/kaggle\/input\/movielens-20m-dataset\/rating.csv',\n                     parse_dates=['timestamp'])","5acc2478":"rand_userIds = np.random.choice(ratings['userId'].unique(),\n                               size=int(len(ratings['userId'].unique())*0.1),\n                               replace=False)\n\nratings = ratings.loc[ratings['userId'].isin(rand_userIds)]\n\nprint('There are {} rows of data from {} users'.format(len(ratings),len(rand_userIds)))","52a452ba":"ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'] \\\n                                .rank(method='first', ascending=False)\n\ntrain_ratings = ratings[ratings['rank_latest'] != 1]\ntest_ratings = ratings[ratings['rank_latest'] == 1]\n\n# ihtiyac\u0131m\u0131z olamyan s\u00fctunlar\u0131 at\u0131yoruz\ntrain_ratings = train_ratings[['userId', 'movieId', 'rating']]\ntest_ratings = test_ratings[['userId', 'movieId', 'rating']]","dc1f1e48":"train_ratings","aa8f07ae":"train_ratings.loc[:, 'rating'] = 1\n\ntrain_ratings.sample(5)","c396c6f8":"# movie id listesi\nall_movieIds = ratings['movieId'].unique()\n\n# e\u011fitim verilerini tutaca\u011f\u0131m\u0131z de\u011fi\u015fkenler\nusers, items, labels = [], [], []\n\n# her kullan\u0131c\u0131n\u0131n etkile\u015fimde bulundu\u011fu filmler k\u00fcmesi\nuser_item_set = set(zip(train_ratings['userId'], train_ratings['movieId']))\n\n# 4:1 pozitif ve negatif \u00f6rnek oran\u0131\nnum_negatives = 4\n\nfor (u, i) in tqdm(user_item_set):\n    users.append(u)\n    items.append(i)\n    labels.append(1) # kullan\u0131c\u0131lar\u0131n etkile\u015fimde bulundu\u011fu filmler pozitiftir.\n    for _ in range(num_negatives):\n        # rastgele \u00f6rnek se\u00e7ilmesi\n        negative_item = np.random.choice(all_movieIds) \n        # kullan\u0131c\u0131n\u0131n bu film ile etkile\u015fime girmedi\u011fini kontrol edin\n        while (u, negative_item) in user_item_set:\n            negative_item = np.random.choice(all_movieIds)\n        users.append(u)\n        items.append(negative_item)\n        labels.append(0) # kullan\u0131c\u0131lar\u0131n etkile\u015fimde bulunmad\u0131\u011f\u0131 filmler pozitiftir.","2725fda0":"class MovieLensTrainDataset(Dataset):\n    \"\"\"MovieLens PyTorch Dataset for Training\n    \n    Args:\n        ratings (pd.DataFrame): film ratinglerini bulunduruan dataframe \n        all_movieIds (list): b\u00fct\u00fcn movieIdlerinin blundu\u011fu liste\n    \n    \"\"\"\n\n    def __init__(self, ratings, all_movieIds):\n        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds)\n\n    def __len__(self):\n        return len(self.users)\n  \n    def __getitem__(self, idx):\n        return self.users[idx], self.items[idx], self.labels[idx]\n\n    def get_dataset(self, ratings, all_movieIds):\n        users, items, labels = [], [], []\n        user_item_set = set(zip(ratings['userId'], ratings['movieId']))\n\n        num_negatives = 4\n        for u, i in user_item_set:\n            users.append(u)\n            items.append(i)\n            labels.append(1)\n            for _ in range(num_negatives):\n                negative_item = np.random.choice(all_movieIds)\n                while (u, negative_item) in user_item_set:\n                    negative_item = np.random.choice(all_movieIds)\n                users.append(u)\n                items.append(negative_item)\n                labels.append(0)\n\n        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)","c4d65b41":"class NCF(pl.LightningModule):\n    \"\"\" Neural Collaborative Filtering (NCF)\n    \n        Args:\n            num_users (int): benzersiz kullan\u0131c\u0131lar\u0131n say\u0131s\u0131\n            num_items (int): benzersiz filmlerinsay\u0131s\u0131\n            ratings (pd.DataFrame): e\u011fitim i\u00e7in film ratinglerini bulunduruan dataframe \n            all_movieIds (list): e\u011fitim ve test k\u00fcmesi dahil b\u00fct\u00fcn filmler\n    \"\"\"\n    \n    def __init__(self, num_users, num_items, ratings, all_movieIds):\n        super().__init__()\n        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n        self.fc1 = nn.Linear(in_features=16, out_features=64)\n        self.fc2 = nn.Linear(in_features=64, out_features=32)\n        self.output = nn.Linear(in_features=32, out_features=1)\n        self.ratings = ratings\n        self.all_movieIds = all_movieIds\n        \n    def forward(self, user_input, item_input):\n        \n        # embedding katmalar\u0131ndan ge\u00e7irilme\n        user_embedded = self.user_embedding(user_input)\n        item_embedded = self.item_embedding(item_input)\n\n        # embedding katmanlar\u0131n\u0131n birle\u015ftirilmesi\n        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n\n        # Dense katman\u0131ndan ge\u00e7irilmesi\n        vector = nn.ReLU()(self.fc1(vector))\n        vector = nn.ReLU()(self.fc2(vector))\n\n        # \u00e7\u0131kt\u0131 katman\u0131\n        pred = nn.Sigmoid()(self.output(vector))\n\n        return pred\n    \n    def training_step(self, batch, batch_idx):\n        user_input, item_input, labels = batch\n        predicted_labels = self(user_input, item_input)\n        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters())\n\n    def train_dataloader(self):\n        return DataLoader(MovieLensTrainDataset(self.ratings, self.all_movieIds),\n                          batch_size=512, num_workers=4)","d6050b34":"train_ratings","03d781da":"num_users = ratings['userId'].max()+1\nnum_items = ratings['movieId'].max()+1\n\nall_movieIds = ratings['movieId'].unique()\n\nmodel = NCF(num_users, num_items, train_ratings, all_movieIds)","9275cee5":"model","cc962367":"trainer = pl.Trainer(max_epochs=1, gpus=1, reload_dataloaders_every_epoch=True,\n                     progress_bar_refresh_rate=100, logger=False, checkpoint_callback=False)\n\n","1dad2701":"trainer","8a4c881e":"trainer.fit(model)","860578fa":"# User-item pairs for testing\ntest_user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n\n# Dict of all items that are interacted with by each user\nuser_interacted_items = ratings.groupby('userId')['movieId'].apply(list).to_dict()\n\nhits = []\nfor (u,i) in tqdm(test_user_item_set):\n    interacted_items = user_interacted_items[u]\n    not_interacted_items = set(all_movieIds) - set(interacted_items)\n    selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n    test_items = selected_not_interacted + [i]\n    \n    predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n                                        torch.tensor(test_items)).detach().numpy())\n    \n    top10_items = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n    \n    if i in top10_items:\n        hits.append(1)\n    else:\n        hits.append(0)\n        \nprint(\"The Hit Ratio @ 10 is {:.2f}\".format(np.average(hits)))","fccc8edf":"# Visualization","2549335f":"Derecelendirmenin yan\u0131 s\u0131ra, incelemenin g\u00f6nderildi\u011fi tarih ve saati g\u00f6steren bir `timestamp` s\u00fctunu da vard\u0131r. `timestamp` s\u00fctunun kullanarak train-test ay\u0131rma i\u015flemini  `leave-one-out` metodolojisini kullanarak yapaca\u011f\u0131z.\nHer kullan\u0131c\u0131 i\u00e7in, en son inceleme test seti olarak kullan\u0131l\u0131r (yani bir tanesini d\u0131\u015far\u0131da b\u0131rak\u0131n), geri kalan\u0131 ise e\u011fitim verisi olarak kullan\u0131lacakt\u0131r.\n\nBu train-test ay\u0131rma stratejisi, genellikle tavsiye sistemlerini e\u011fitirken ve de\u011ferlendirirken kullan\u0131l\u0131r. Bir kullan\u0131c\u0131n\u0131n e\u011fitim i\u00e7in son incelemelerini ve test i\u00e7in daha \u00f6nceki incelemeleri kullan\u0131yor olabilece\u011fimiz i\u00e7in rastgele bir b\u00f6lme yapmak adil olmaz. Rasgle b\u00f6lersek b\u00f6yle bir durum ortaya \u00e7\u0131kabilece\u011fi i\u00e7in e\u011fitilmi\u015f modelin performans\u0131, ger\u00e7ek d\u00fcnya performans\u0131na genelle\u015ftirilemez.","b76123fa":"Veri setimizi ikili hale getirdikten sonra, veri setindeki her \u00f6rne\u011fin art\u0131k pozitif s\u0131n\u0131fa ait oldu\u011funu g\u00f6r\u00fcyoruz. Bununla birlikte, modellerimizi e\u011fitmek, kullan\u0131c\u0131n\u0131n etkile\u015fimde bulunmad\u0131\u011f\u0131 filmleri belirtmek i\u00e7in negatif \u00f6rneklere de ihtiyac\u0131m\u0131z var. Bu t\u00fcr filmlerin kullan\u0131c\u0131n\u0131n ilgilenmedi\u011fi filmler oldu\u011funu varsay\u0131yoruz - bu do\u011fru olmayabilecek kapsaml\u0131 bir varsay\u0131m olsa da, uygulamada genellikle olduk\u00e7a iyi sonu\u00e7 veriyor.\n\nA\u015fa\u011f\u0131daki kod, her veri sat\u0131r\u0131 i\u00e7in 4 negatif \u00f6rnek olu\u015fturur. Ba\u015fka bir deyi\u015fle, negatif \u00f6rneklerin pozitif \u00f6rneklere oran\u0131 4:1'dir. Bu oran\u0131 Kaggle'da g\u00f6rd\u00fc\u011f\u00fcm di\u011fer kodlardan buldum ve iyi sonu\u00e7 verdi\u011fi yaz\u0131yordu yeni bir otran denemedim.","e5bc093b":"Yukar\u0131daki bilgilerle birlikte hangi tarihte en\u00e7ok hangi t\u00fcr filmin oldu\u011fu blgisi de bize \u0131\u015f\u0131k tutacak bir bilgi olabilir. Bu y\u00fczden bu bilgi de g\u00f6rsel olarak ortaya konuldu.","fc9081d1":"# Deep Learning Based Recommendation System","3bcf89f7":"# Neural Collaborative Filtering (NCF)\n\n\u00d6neri sistemlerinde genellikle Collaborative Filtering y\u00f6nteminin uyguland\u011f\u0131n\u0131 g\u00f6rd\u00fcm. State-of-the-art sistemlerde genellikle deep learning based modeller kullan\u0131l\u0131yor bu y\u00fczden deep lerning based modeller ara\u015ft\u0131r\u0131rken  Neural Collaborative Filtering (NCF) modelinin buldum. Bu modelin uygulanabilir oldu\u011funu ve Kaggle'da da \u00f6rnekleri oldu\u011fu i\u00e7in bu modeli uygulamaya karar verdim.\n\n### User Embeddings\n\nModelin mimarisine girmeden \u00f6nce, embedding kavram\u0131na bakmam\u0131z gerekir.\n\nKullan\u0131c\u0131lar\u0131m\u0131z\u0131 iki t\u00fcr film i\u00e7in tercihlerine g\u00f6re temsil etmek istedi\u011fimizi hayal edin - aksiyon ve romantizm filmleri. \u0130lk boyut kullan\u0131c\u0131n\u0131n aksiyon filmlerini ne kadar sevdi\u011fi, ikinci boyut ise kullan\u0131c\u0131n\u0131n a\u015fk filmlerini ne kadar sevdi\u011fi olsun.\n\n![](https:\/\/i.imgur.com\/XENzqXq.png)\n\n\u015eimdi, Bob'un ilk kullan\u0131c\u0131m\u0131z oldu\u011funu varsayal\u0131m. Bob aksiyon filmlerini sever ama romantik filmlerin hayran\u0131 de\u011fildir. Bob'u iki boyutlu bir vekt\u00f6r olarak temsil etmek i\u00e7in onu tercihine g\u00f6re grafi\u011fe yerle\u015ftiriyoruz.\n\n![](https:\/\/i.imgur.com\/rSStTCj.png)\n\nS\u0131radaki kullan\u0131c\u0131m\u0131z Joe. Joe, hem aksiyon hem de romantik filmlerin b\u00fcy\u00fck bir hayran\u0131d\u0131r. Joe'yu Bob gibi iki boyutlu bir vekt\u00f6r kullanarak temsil ediyoruz.\n\n![](https:\/\/i.imgur.com\/gmmkrEU.png)\n\nBu iki boyutlu uzay, bir g\u00f6mme olarak bilinir. Asl\u0131nda, embeddingler, kullan\u0131c\u0131lar\u0131m\u0131z\u0131 daha d\u00fc\u015f\u00fck boyutlu bir uzayda anlaml\u0131 bir \u015fekilde temsil edilebilecek \u015fekilde azalt\u0131r. Bu embeddingte, benzer film tercihlerine sahip kullan\u0131c\u0131lar birbirine yak\u0131n yerle\u015ftirilir ve bunun tersi de ge\u00e7erlidir. \n\n![](https:\/\/i.imgur.com\/9s9Z7JT.png)\n\nKullan\u0131c\u0131lar\u0131m\u0131z\u0131 temsil etmek i\u00e7in sadece 2 boyut kullanmakla s\u0131n\u0131rl\u0131 de\u011filiz. Kullan\u0131c\u0131lar\u0131m\u0131z\u0131 temsil etmek i\u00e7in iste\u011fe ba\u011fl\u0131 say\u0131da boyut kullanabiliriz. Daha fazla say\u0131da boyut her kullan\u0131c\u0131n\u0131n \u00f6zelliklerini daha do\u011fru bir \u015fekilde yakalamam\u0131z\u0131 sa\u011flar. Kodumuzda 8 boyut kullanaca\u011f\u0131z.\n\n\n### Learned Embeddings\n \nBenzer \u015fekilde, filmlerin \u00f6zelliklerini daha d\u00fc\u015f\u00fck boyutlu bir alanda temsil etmek i\u00e7in ayr\u0131 bir embedding katman\u0131 kullanaca\u011f\u0131z. Kullan\u0131c\u0131lar\u0131n ve filmlerin embeddinglerinin a\u011f\u0131rl\u0131klar\u0131n\u0131n do\u011fru \u015fekilde tespit edilmesi gerekiyor. \u00d6nceki \u00f6rne\u011fimizde, embeddinglerimizi manuel olarak olu\u015fturmak i\u00e7in Bob ve Joe'nun aksiyon ve a\u015fk filmlerini kulland\u0131k. Bunun otomatik yap\u0131lmas\u0131 gerekiyor. Bu k\u0131s\u0131mda **Collaborative Filtering** devreye giriyor. Rating veri setini kullanarak, benzer kullan\u0131c\u0131lar\u0131 ve filmleri belirleyebilir, mevcut ratinglerden \u00f6\u011frenilen kullan\u0131c\u0131 ve film embeddinglerini olu\u015fturabiliriz.\n\n\n### Model Architecture\n\nArt\u0131k yerle\u015ftirmeleri daha iyi anlad\u0131\u011f\u0131m\u0131za g\u00f6re, model mimarisini tan\u0131mlamaya haz\u0131r\u0131z. G\u00f6rece\u011finiz gibi, kullan\u0131c\u0131 ve film embeddingleri modelin anahtar\u0131d\u0131r.\n\n<!-- ![NCF](https:\/\/i.imgur.com\/EZh1HHf.png)\n -->\n \nLet's walk through the model architecture using the following training sample:\n\n| userId | movieID | interacted |\n|-|-|-|\n| 3 | 1 | 1 |\n\n \n![](https:\/\/i.imgur.com\/cNWbIce.png)\n\n\nModelin inputlar\u0131 `userId = 3` ve `movieId = 1` i\u00e7in one-hot encoded olarak temsil edilmi\u015f kullan\u0131c\u0131 ve film vekt\u00f6rleridir. Bu pozitif bir \u00f6rnek oldu\u011fundan (film ger\u00e7ekten kullan\u0131c\u0131 taraf\u0131ndan derecelendirilir), ger\u00e7ek etiket (`interacted`)  1'dir.\n\nThe user input vector and item input vector are fed to the user embedding and item embedding respectively, which results in a smaller, denser user and item vectors.\n\nKullan\u0131c\u0131 input vekt\u00f6r\u00fc ve film input vekt\u00f6r\u00fc, s\u0131ras\u0131yla kullan\u0131c\u0131 embedding ve \u00f6\u011fe embeddingleri ile beslenir, bu da daha k\u00fc\u00e7\u00fck, daha yo\u011fun bir kullan\u0131c\u0131 ve \u00f6\u011fe vekt\u00f6rleri ortaya \u00e7\u0131kar\u0131lmas\u0131n\u0131 sa\u011flar.\n\n\nKullan\u0131c\u0131 ve film vekt\u00f6rleri, birle\u015ftirilmi\u015f embeddingleri \u00e7\u0131kt\u0131 olarak bir tahmin vekt\u00f6r\u00fcne veren bir dizi fully-connected  katmandan ge\u00e7meden \u00f6nce birle\u015ftirilir. Son olarak, en olas\u0131 s\u0131n\u0131f\u0131 elde etmek i\u00e7in bir 'Sigmoid' fonksiyonun uygular\u0131z. Yukar\u0131daki \u00f6rnekte, 0,8 > 0,2 oldu\u011fundan en olas\u0131 s\u0131n\u0131f 1'dir (pozitif s\u0131n\u0131f).\n\n\n\u015eimdi bu NCF modelini PyTorch Lightning kullanarak olu\u015ftural\u0131m!\n\n","9b3c81e0":"# References\n\nhttps:\/\/www.kaggle.com\/jamesloy\/deep-learning-based-recommender-systems\n","eac635bb":"# Building Recommender Systems using Implicit Feedback\n\nModelimizi olu\u015fturmadan \u00f6nce, tavsiye sistemleri ba\u011flam\u0131nda **implicit** ve **explicit** geri bildirim aras\u0131ndaki fark\u0131 ve modern tavsiye sistemlerinin neden implicit feedback \u00fczerine kuruldu\u011funu anlamak \u00f6nemlidir.\n\n### Explicit Feedback\n\nTavsiye sistemleri ba\u011flam\u0131nda, explicit feedback, kullan\u0131c\u0131lardan toplanan **do\u011frudan** ve **nicel** verilerdir. \u00d6rne\u011fin Amazon, kullan\u0131c\u0131lar\u0131n sat\u0131n al\u0131nan \u00fcr\u00fcnleri 1-10 aras\u0131nda derecelendirmesine olanak tan\u0131r. Bu derecelendirmeler do\u011frudan kullan\u0131c\u0131lardan sa\u011flan\u0131r ve Amazon'un kullan\u0131c\u0131 tercihini \u00f6l\u00e7meye olanak tan\u0131r. Explicit feedback'in bildirimin ba\u015fka bir \u00f6rne\u011fi, kullan\u0131c\u0131lar\u0131n belirli bir videoya ili\u015fkin a\u00e7\u0131k tercihlerini (yani be\u011fenme veya be\u011fenmeme) yakalayan YouTube'daki be\u011fen d\u00fc\u011fmesidir.\n\n### Implicit Feedback\n\u00d6te yandan, dolayl\u0131 olarak kullan\u0131c\u0131 **etkile\u015fimlerinden** implicit feedback toplan\u0131r ve bunlar kullan\u0131c\u0131 tercihinin temsili g\u00f6revini g\u00f6r\u00fcr. \u00d6rne\u011fin; YouTube'da izledi\u011finiz videolar, videolar\u0131 a\u00e7\u0131k\u00e7a derecelendirmeseniz bile size \u00f6zel \u00f6nerilerde bulunmak i\u00e7in implicit feedback olarak kullan\u0131l\u0131r. Ba\u015fka bir implicit feedback \u00f6rne\u011fi, sizin i\u00e7in ba\u015fka benzer \u00fcr\u00fcnler \u00f6nermek i\u00e7in kullan\u0131lan Amazon'da g\u00f6z att\u0131\u011f\u0131n\u0131z \u00fcr\u00fcnlerdir.\n\nImplicit Feedback'in avantaj\u0131, bol olmas\u0131d\u0131r. Implicit Feedback kullan\u0131larak olu\u015fturulan \u00f6neri sistemleri, \u00f6nerileri her t\u0131klama ve etkile\u015fimle ger\u00e7ek zamanl\u0131 olarak uyarlamam\u0131za da olanak tan\u0131r. Bug\u00fcn, \u00e7evrimi\u00e7i \u00f6neri sistemleri, sistemin \u00f6nerisini her kullan\u0131c\u0131 etkile\u015fimi ile ger\u00e7ek zamanl\u0131 olarak ayarlamas\u0131n\u0131 sa\u011flayan implicit feedback kullan\u0131larak olu\u015fturulmu\u015ftur.","4bb3f8e0":"# READ DATA","5f4c492b":"Son olarak filmlerin en \u00e7ok hangi puan\u0131 ald\u0131\u011f\u0131n\u0131 g\u00f6steren g\u00f6rselle\u015ftirme yap\u0131ld\u0131.","e8556a00":"Geleneksel olarak, \u00f6neri sistemleri k\u00fcmeleme, en yak\u0131n kom\u015fu ve matris \u00e7arpanlar\u0131na ay\u0131rma gibi y\u00f6ntemlere dayanmaktad\u0131r. Bununla birlikte, son y\u0131llarda, derin \u00f6\u011frenme, g\u00f6r\u00fcnt\u00fc tan\u0131madan do\u011fal dil i\u015flemeye kadar bir\u00e7ok alanda muazzam bir ba\u015far\u0131 sa\u011flad\u0131. \u00d6neri sistemleri de derin \u00f6\u011frenmenin ba\u015far\u0131s\u0131ndan yararland\u0131. Asl\u0131nda, YouTube ve Amazon'dakiler gibi g\u00fcn\u00fcm\u00fcz\u00fcn son teknoloji tavsiye sistemleri derin \u00f6\u011frenme sistemlerini kullanmaktad\u0131rlar.","acfc8d9a":"# IMPORTS","f77432e4":"## Train test split","43cae0fb":"Hangi film t\u00fcr\u00fcdnen datam\u0131zda ne kadar var bilgisi de bizim i\u00e7in \u00f6nemli. Bu bilginin g\u00f6rselle\u015ftirebilmesi i\u00e7in \u00f6ncelikle data haz\u0131rland\u0131 ve t\u00fcrlerin say\u0131lar\u0131 \u00e7\u0131kar\u0131ld\u0131.","c992cbf9":"Daha \u00f6nce tart\u0131\u015f\u0131ld\u0131\u011f\u0131 gibi, implicit bir tavsiye sistemi e\u011fitece\u011fiz. Ancak, kulland\u0131\u011f\u0131m\u0131z MovieLens veri k\u00fcmesi, explicit feedback y\u00f6ntemine dayanmaktad\u0131r. Bu veri k\u00fcmesini implicit feedback veri k\u00fcmesine d\u00f6n\u00fc\u015ft\u00fcrmek i\u00e7in, derecelendirmeleri '1' (yani pozitif s\u0131n\u0131f) olacak \u015fekilde ikili hale getirece\u011fiz. '1' de\u011feri, kullan\u0131c\u0131n\u0131n film etkile\u015fime girdi\u011fini g\u00f6sterir.","2741b250":"# Evaluating our Recommender System\nArt\u0131k modelimiz e\u011fitildi\u011fine g\u00f6re, test verilerini kullanarak onu de\u011ferlendirmeye haz\u0131r\u0131z. Geleneksel Makine \u00d6\u011frenimi projelerinde, Modellerimizi Do\u011fruluk (s\u0131n\u0131fland\u0131rma problemleri i\u00e7in) ve RMSE (regresyon problemleri i\u00e7in) gibi metrikleri kullanarak de\u011ferlendiririz. Ancak, bu t\u00fcr metrikler, \u00f6neri sistemlerini de\u011ferlendirmek i\u00e7in \u00e7ok basittir.\n\nTavsiye sistemlerini de\u011ferlendirmek i\u00e7in iyi bir \u00f6l\u00e7\u00fc tasarlamak istiyorsak \u00f6ncelikle modern tavsiye sistemlerinin nas\u0131l kullan\u0131ld\u0131\u011f\u0131n\u0131 anlamam\u0131z gerekir.\n\nNetflix'e bakt\u0131\u011f\u0131m\u0131zda, a\u015fa\u011f\u0131dakine benzer bir \u00f6neri listesi g\u00f6r\u00fcyoruz:\n\n![](https:\/\/i.imgur.com\/5QRWcYy.jpg)\n\nAmazon'un \u00f6neri listesi debenzer \u015fekildedir:\n\n![](https:\/\/i.imgur.com\/XZZ2Ni8.png)\n\nBuradaki anahtar, kullan\u0131c\u0131n\u0131n \u00f6neriler listesindeki *her* tek bir \u00f6\u011feyle etkile\u015fime girmesine ihtiyac\u0131m\u0131z olmamas\u0131d\u0131r. Bunun yerine, kullan\u0131c\u0131n\u0131n listedeki en az bir \u00f6\u011feyle etkile\u015fime girmesine ihtiyac\u0131m\u0131z var - kullan\u0131c\u0131 bunu yapt\u0131\u011f\u0131 s\u00fcrece \u00f6neriler i\u015fe yarar.\n\nBunu sim\u00fcle etmek i\u00e7in, her kullan\u0131c\u0131 i\u00e7in \u00f6nerilen 10 filmin bir listesini olu\u015fturmak i\u00e7in a\u015fa\u011f\u0131daki de\u011ferlendirme sistemini \u00e7al\u0131\u015ft\u0131ral\u0131m.\n\n* Her kullan\u0131c\u0131 i\u00e7in, kullan\u0131c\u0131n\u0131n **etkile\u015fimde bulunmad\u0131\u011f\u0131** 99 \u00f6\u011feyi rastgele se\u00e7in\n* Bu 99 \u00f6\u011feyi test \u00f6\u011fesiyle (kullan\u0131c\u0131n\u0131n etkile\u015fimde bulundu\u011fu ger\u00e7ek \u00f6\u011fe) birle\u015ftirin. \u015eimdi 100 adet \u00fcr\u00fcn\u00fcm\u00fcz var.\n* Modeli bu 100 madde \u00fczerinde \u00e7al\u0131\u015ft\u0131r\u0131n ve tahmin edilen olas\u0131l\u0131klar\u0131na g\u00f6re s\u0131ralay\u0131n\n* 100 maddelik listeden ilk 10 maddeyi se\u00e7in. Test \u00f6\u011fesi ilk 10 \u00f6\u011fe i\u00e7inde yer al\u0131yorsa, bunun bir hit oldu\u011funu s\u00f6yl\u00fcyoruz.\n* \u0130\u015flemi t\u00fcm kullan\u0131c\u0131lar i\u00e7in tekrarlay\u0131n. Do\u011fruluk Oran\u0131 daha sonra ortalama tahminlerdir.\n\nBu de\u011ferlendirme sistemi **Hit Ratio @ 10** olarak bilinir ve genellikle tavsiye sistemlerini de\u011ferlendirmek i\u00e7in kullan\u0131l\u0131r.","8baf89a1":"Datam\u0131z\u0131 anlamak ve do\u011fru bir de\u011ferlendirme yapabilmek i\u00e7in verileri g\u00f6rsel halde g\u00f6rmek daha faydal\u0131 olacakt\u0131r.\n\nA\u015fa\u011f\u0131daki g\u00f6rselle\u015ftirmede verilen rating puan\u0131n\u0131n oran\u0131 verilmektedir. Model olu\u015ftururken ratinglere g\u00f6re filtreleme yap\u0131lmas\u0131 planland\u0131\u011f\u0131 i\u00e7in bunlar\u0131n oran\u0131 bize yol g\u00f6stterecektir."}}