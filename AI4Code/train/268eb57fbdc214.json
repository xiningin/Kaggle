{"cell_type":{"96db9555":"code","47400a47":"code","7764cb99":"code","41aa844d":"code","4e26a2ff":"code","aa6f53fe":"code","97936525":"code","8dcc437e":"code","27c14df2":"code","05003762":"code","28c417ae":"code","b1add0a3":"code","679ba915":"code","4569d2b5":"code","3e9b0413":"code","23ca1f68":"code","9348cd8a":"code","39b037ed":"code","9c460fb0":"code","ea19a240":"code","e0b5839e":"code","f1781b99":"code","99413491":"code","38e8a18d":"code","dfe4db50":"code","1141112b":"code","cd92d230":"code","97c43e32":"code","4d94a3b1":"code","cb06a5fe":"code","e82b7871":"code","a04607c1":"code","4a5ce35f":"code","c4705fe9":"code","b7ceb870":"code","28374f1b":"code","638a669b":"code","252317e5":"code","6e30c52c":"code","0cc60255":"code","387ffdd3":"code","084bd11f":"code","82811b2e":"code","3dfd6084":"code","ede1ca32":"code","f889866a":"code","5cc41884":"code","9498532d":"code","9f265b19":"code","e489ae0f":"code","92dfd02e":"code","c51e17cd":"code","46ed6329":"code","45275b29":"code","c2cb1ab1":"code","47fe0f6b":"code","a11546ac":"code","cd337cb5":"code","ada19eac":"code","3c084c47":"code","b4bb5572":"code","ec866595":"code","0cfa0627":"code","96105abd":"code","acd9847a":"code","fba13c10":"code","ec23a18a":"code","8b228c8c":"markdown"},"source":{"96db9555":"#importing all the required libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom mlxtend.feature_selection import SequentialFeatureSelector\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport os # accessing directory structure\npd.set_option('display.max_columns',None)   #code to dispaly all the columns in the dataframe\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(action='ignore')\n%matplotlib inline","47400a47":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7764cb99":"df = pd.read_csv('\/kaggle\/input\/housesalesprediction\/kc_house_data.csv')","41aa844d":"df.head()","4e26a2ff":"df.shape\n#21613 rows , 21 columns","aa6f53fe":"df.info()","97936525":"df[~df.apply(np.isreal).any(1)]    #checking for any non real value in the dataset\n#there are no non real values in any column","8dcc437e":"#extrating just the year from the date column as we will be using only the year\ndf['new_date']=df['date'].str[:4]","27c14df2":"#dropping the date column as we made a new_date column which has just the year\ndf.drop(['date','id'],axis=1,inplace=True)","05003762":"df['new_date']=df['new_date'].astype('int')","28c417ae":"df.dtypes","b1add0a3":"df['age']=np.NaN   #adding a new column 'age' to identify how old is the house","679ba915":"for i,j in enumerate(df['yr_renovated']):\n    if(j==0):\n        df['age'][i]=df['new_date'][i]-df['yr_built'][i]\n    else:\n        df['age'][i]=df['new_date'][i]-df['yr_renovated'][i]\n        \n#calculating how old the house is and storing it in the age column","4569d2b5":"# as we have used the yr_renovated , yr_built,new_date column to find the age of the house so we drop these column as these are of no use\ndf.drop(['yr_built','yr_renovated','new_date'],axis=1,inplace=True)","3e9b0413":"#we will not be using the zipcode,lat,long columns\ndf.drop(['lat','zipcode','long'],axis=1,inplace=True)","23ca1f68":"#checking the distribution of all the variables\nfor i in df.columns:\n    sns.distplot(df[i])\n    plt.show()","9348cd8a":"df.skew()","39b037ed":"#Almost all the columns have skewness\n#But sqft_lot15,sqft_lot are highly right skewed","9c460fb0":"plt.figure(figsize=(15,15))\nsns.pairplot(df,diag_kind='kde')\nplt.show()","ea19a240":"plt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","e0b5839e":"# sqft_living have a positive linear relationship with the price\n# sqft_above have a positive linear relationship with the price","f1781b99":"#sqft_living15,sqft_above,grade,sqft_living,bathrooms seems to have correlation","99413491":"#checking for outliers in the dataset\nfor i in df.columns:\n    sns.boxplot(df[i])\n    plt.show()","38e8a18d":"#The bedroom column has some outliers\n#The bathroom column has some outliers\n#The sqft_living has outliers\n#The sqft_lot column has lot of outliers\n#The floor column has no outliers\n#The grade column has many otliers\n#The sqft_above has lot of outliers\n#The sqft_basement has lot of outliers\n#The sqft_living15 has lot of outliers\n#The sqft_lot15 has lot of outliers\n#The age column has no outliers","dfe4db50":"X=df.drop('price',axis=1)\ny=df['price']","1141112b":"vif_df=pd.DataFrame()   #making a dataframe for the vif of all the columns","cd92d230":"vif_df['Columns']=X.columns\nvif_df['VIF']=[variance_inflation_factor(X.values,i) for i in range(len(X.columns))]","97c43e32":"vif_df","4d94a3b1":"#Bedroom,bathroom,floors,condition,grade,sqft_living have high multicolinearity\n#sqft_living,sqft_above,sqft_basement have very high multicolinearity","cb06a5fe":"#splitting data into test set and train set\nxtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.25,random_state=10)","e82b7871":"xtrain.shape","a04607c1":"ytrain.shape","4a5ce35f":"xtest.shape","c4705fe9":"ytest.shape","b7ceb870":"#performing scaling, transformation on the training set and then building a Linear Regression Model\npipe=Pipeline((\n('scale',StandardScaler()),\n('transform',PowerTransformer(method='yeo-johnson')),\n('lr',LinearRegression())\n))\npipe.fit(xtrain,ytrain)\npipe.score(xtest,ytest)\n#the performance of the model is not good","28374f1b":"#building a linear regression model\npipe=Pipeline((\n('lr',LinearRegression()),\n))\npipe.fit(xtrain,ytrain)\nlr_score=pipe.score(xtest,ytest)\n#the model performs better without scaling and transformation","638a669b":"#building a lasso regression model\npipe=Pipeline((\n('lasso',Lasso()),\n))\npipe.fit(xtrain,ytrain)\nlasso_score=pipe.score(xtest,ytest)\n#no improvement in the model with lasso model as well","252317e5":"#building a ridge regression model\npipe=Pipeline((\n('lasso',Ridge()),\n))\npipe.fit(xtrain,ytrain)\nridge_score=pipe.score(xtest,ytest)\n#no improvement in the model with ridge model as well","6e30c52c":"#building a Decision tree regression model\npipe=Pipeline((\n('pt',PowerTransformer()),\n('dt',DecisionTreeRegressor()),\n))\npipe.fit(xtrain,ytrain)\ndt_score=pipe.score(xtest,ytest)\n#no improvement in the model with Decision tree model as well","0cc60255":"#building a RandomForest regression model\npipe=Pipeline((\n('pt',PowerTransformer()),\n('rf',RandomForestRegressor()),\n))\npipe.fit(xtrain,ytrain)\nrf_score=pipe.score(xtest,ytest)\n#the model performed better RandomForest model as well","387ffdd3":"#building a GradientBossting regression model\npipe=Pipeline((\n('pt',PowerTransformer()),\n('gb',GradientBoostingRegressor()),\n))\npipe.fit(xtrain,ytrain)\ngb_score=pipe.score(xtest,ytest)\n#we can see that there is an increase in the performance","084bd11f":"#building a AdaBoost regression model\npipe=Pipeline((\n('adaboost',AdaBoostRegressor()),\n))\npipe.fit(xtrain,ytrain)\nadgb_score=pipe.score(xtest,ytest)\n#the performace degraded with adaBoost madel","82811b2e":"#building a K-nn regression model\npipe=Pipeline((\n('adaboost',KNeighborsRegressor()),\n))\npipe.fit(xtrain,ytrain)\nknn_score=pipe.score(xtest,ytest)\n#the performace degraded with K-nn madel","3dfd6084":"l1=['LinerRegression','Lasso','Ridge','DecisionTree','RandomForest','GradientBoost','AdaBoost','K-nn']\nl2=[lr_score,lasso_score,ridge_score,dt_score,rf_score,gb_score,adgb_score,knn_score]","ede1ca32":"score_df=pd.DataFrame({'Models':l1,'Score':l2})","f889866a":"score_df","5cc41884":"plt.figure(figsize=(10,5))\nsns.barplot(score_df['Models'],score_df['Score'])\nplt.xticks(rotation=90)\nplt.show()","9498532d":"#as we see from the graph random forest and gradient bossting performs better than other and both have almost equal score\n#so we perform cross-validation to find the best out of the two","9f265b19":"#now we perform the k-fold cross validation on RandomForestAlgorithm\nrandomforest_score=cross_val_score(estimator=RandomForestRegressor(),X=X,y=y,cv=10,scoring='r2')","e489ae0f":"randomforest_score","92dfd02e":"np.mean(randomforest_score)\n#mean score for RandomforestRegressor","c51e17cd":"#now we perform the k-fold cross validation on GradientBoostingRegressorAlgorithm\ngradientboosting_score=cross_val_score(estimator=GradientBoostingRegressor(),X=X,y=y,cv=10,scoring='r2')","46ed6329":"gradientboosting_score","45275b29":"np.mean(gradientboosting_score)\n#mean score for RandomforestRegressor","c2cb1ab1":"#Out of the RandomForestRegressor and GradiantBoostingRegressor, RandomForestRegressor performs better so we tune the hyperparameters for better result","47fe0f6b":"#finding the best hyperparameters so as to increase the accuracy of the model\nparams={'n_estimators':[10,20,50,100,200,500],'max_depth':[2,5,8,9,12]}\ngrid=GridSearchCV(estimator=RandomForestRegressor(),param_grid=params,cv=10,scoring='r2',n_jobs=-1)","a11546ac":"grid.fit(xtrain, ytrain)","cd337cb5":"grid.best_score_","ada19eac":"grid.best_params_","3c084c47":"#final model with RandomForestRegressor","b4bb5572":"X1=df.drop(['price'],axis=1)\ny1=df['price']","ec866595":"xtrain1,xtest1,ytrain1,ytest1=train_test_split(X1,y1,test_size=0.25,random_state=10)","0cfa0627":"pipe=Pipeline((\n('pt',PowerTransformer()),\n('rf',RandomForestRegressor(n_estimators=200,max_depth=12)),\n))\npipe.fit(xtrain1,ytrain1)\npipe.score(xtest1,ytest1)","96105abd":"#Final model with RandomForestRegressor with 74.48% accuracy","acd9847a":"df.head()","fba13c10":"price_pred=pipe.predict(xtest1)","ec23a18a":"df=pd.DataFrame({'price_actual':ytest1,'price_predicted':price_pred})\ndf.head()","8b228c8c":"### Building a base model with all the features"}}