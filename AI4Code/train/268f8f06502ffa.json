{"cell_type":{"9fb89903":"code","f0a8fb16":"code","4d0d6248":"code","abcddb20":"code","57625ed3":"code","8833b25b":"code","a2f6c12d":"code","1de2ba74":"code","ad93730e":"code","cc6f8017":"code","6bbc9e98":"code","56bef7b0":"code","e0adc4e2":"code","bfa5fd9a":"code","31b4240b":"code","808dfbdb":"code","3b335c5e":"code","52b277ad":"code","d05a7012":"code","24588702":"code","b6c17087":"code","5997bf41":"code","aa28fb53":"code","0ada94f4":"code","d589edf6":"code","4dbb50f8":"code","101bef53":"code","5661ac90":"code","fa77e17a":"code","ceec39ff":"code","4afd3a56":"code","972947cd":"code","f4c461dc":"code","452825c5":"code","55fe73a0":"code","400e0917":"code","b257f801":"code","a9ffff06":"markdown","08d07bc3":"markdown","78d4d79b":"markdown","a49ad922":"markdown","99e79c06":"markdown","b38aab4b":"markdown","742147d2":"markdown","66ef4784":"markdown","9f016ba6":"markdown","50137a49":"markdown","d56f6596":"markdown","f9587be8":"markdown","35f4f5ad":"markdown","2be07579":"markdown","2a159206":"markdown","302ba5c2":"markdown","d3b985a9":"markdown","545d46c4":"markdown","d9d2475d":"markdown","28aed9de":"markdown","79ad85c2":"markdown","ee5e3f46":"markdown","8e5ecdc7":"markdown","0509d318":"markdown"},"source":{"9fb89903":"# data processing and analysis\nimport pandas as pd \nprint(\"pandas version: {}\". format(pd.__version__))\n\n# scientific computing\nimport numpy as np \nprint(\"NumPy version: {}\". format(np.__version__))\n\n# scientific and publication-ready visualization\nimport matplotlib \nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\n\n# scientific and publication-ready visualization \nimport seaborn as sns\nprint(\"seaborn version: {}\". format(sns.__version__))\n\n# machine learning algorithms\nimport sklearn \nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\n# machine learning algorithms\nimport statsmodels\nprint(\"statsmodels version: {}\". format(statsmodels.__version__))\n\n# scientific computing and advance mathematics\nimport scipy as sp \nprint(\"SciPy version: {}\". format(sp.__version__))\n\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score, confusion_matrix","f0a8fb16":"#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns","4d0d6248":"data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\n# a dataset should be broken into 3 splits: train, test, and (final) validation\n# we will split the train set into train and test data in future sections\ndata_val  = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\n# to play with our data, create copy\ndata1 = data.copy(deep = True)\n\n# however passing by reference is convenient, because we can clean both datasets at once\ndata_cleaner = [data1, data_val]","abcddb20":"data1.head()","57625ed3":"data_val.head()","8833b25b":"data1.shape","a2f6c12d":"data_val.shape","1de2ba74":"data1.info()","ad93730e":"data1.describe()","cc6f8017":"print(data1.isnull().sum())\nprint(\"-\"*10)\nprint(data_val.isnull().sum())","6bbc9e98":"# Data description\ndata.describe(include = 'all')","56bef7b0":"for dataset in data_cleaner:    \n    # age: median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    # embarked: mode\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n\n    # fare: median\n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n    \n    # drop Cabin as it has 687 as null out of 891 (approx 77% of data)\n    dataset.drop('Cabin', axis=1, inplace=True)","e0adc4e2":"print(data1.isnull().sum())\nprint(\"-\"*10)\nprint(data_val.isnull().sum())","bfa5fd9a":"# List of variables to map\n\nvarlist =  ['Sex']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'male': 1, \"female\": 0})\n\n# Applying the function to the housing list\nfor dataset in data_cleaner:\n    dataset[varlist] = dataset[varlist].apply(binary_map)","31b4240b":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(data1['Embarked'], prefix='Embarked', drop_first=True)\n    \n# Adding the results to the master dataframe\ndata1 = pd.concat([data1, dummy1], axis=1)","808dfbdb":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(data_val['Embarked'], prefix='Embarked', drop_first=True)\n    \n# Adding the results to the master dataframe\ndata_val = pd.concat([data_val, dummy1], axis=1)","3b335c5e":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(data1['Pclass'], prefix='Pclass', drop_first=True)\n    \n# Adding the results to the master dataframe\ndata1 = pd.concat([data1, dummy1], axis=1)","52b277ad":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(data_val['Pclass'], prefix='Pclass', drop_first=True)\n    \n# Adding the results to the master dataframe\ndata_val = pd.concat([data_val, dummy1], axis=1)","d05a7012":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(data1['Sex'], prefix='Male', drop_first=True)\n    \n# Adding the results to the master dataframe\ndata1 = pd.concat([data1, dummy1], axis=1)","24588702":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(data_val['Sex'], prefix='Male', drop_first=True)\n    \n# Adding the results to the master dataframe\ndata_val = pd.concat([data_val, dummy1], axis=1)","b6c17087":"data1['FamilySize'] = data1['SibSp'] + data1['Parch'] + 1\ndata1.head(2)","5997bf41":"data_val['FamilySize'] = data_val['SibSp'] + data_val['Parch'] + 1\ndata_val.head(2)","aa28fb53":"PassengerId = data_val.PassengerId","0ada94f4":"# Renaming the column \ndata1= data1.rename(columns={ 'Male_1' : 'Male'})\ndata_val= data_val.rename(columns={ 'Male_1' : 'Male'})","d589edf6":"drop_column = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Ticket', 'Fare', 'Embarked']\ndata1.drop(drop_column, axis=1, inplace = True)","4dbb50f8":"# Checking for outliers in the continuous variables\ncont_col = data1['Age']\n\n# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\ncont_col.describe(percentiles=[.25, .5, .75, .90, .95, .99])","101bef53":"# Let's see the correlation matrix \nplt.figure(figsize = (10,5))        # Size of the figure\nsns.heatmap(data1.corr(),annot = True)\nplt.show()","5661ac90":"# Plot the scatter plot of the data\n\nsns.pairplot(data1, x_vars=['Age'], y_vars='Survived',size=4, aspect=1, kind='scatter')\nplt.show()","fa77e17a":"#graph distribution of quantitative data\nplt.figure(figsize=[4,5])\n\n#plt.subplot(231)\nplt.boxplot(x=data1['Age'], showmeans = True, meanline = True)\nplt.title('Age Boxplot')\nplt.ylabel('Age')","ceec39ff":"plt.figure(figsize=[10,4])\n\nplt.hist(x = [data1[data1['Survived']==1]['Age'], data1[data1['Age']==0]['Age']], \n         stacked=False, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Age Histogram by Survival')\nplt.xlabel('Age ')\nplt.ylabel('# of Passengers')\nplt.legend()","4afd3a56":"plt.figure(figsize=[10,4])\n\nplt.hist(x = [data1[data1['Survived']==1]['SibSp'], data1[data1['Survived']==0]['SibSp']], \n         stacked=False, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('SibSp Histogram by Survival')\nplt.xlabel('SibSp')\nplt.ylabel('# of Passengers')\nplt.legend()","972947cd":"plt.figure(figsize=[10,4])\n\nplt.hist(x = [data1[data1['Survived']==1]['Parch'], data1[data1['Survived']==0]['Parch']], \n         stacked=False, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Parch Histogram by Survival')\nplt.xlabel('Parch')\nplt.ylabel('# of Passengers')\nplt.legend()","f4c461dc":"plt.figure(figsize=[10,4])\n\nplt.hist(x = [data1[data1['Survived']==1]['Male'], data1[data1['Survived']==0]['Male']], \n         stacked=False, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Sex Histogram by Survival')\nplt.xlabel('Sex')\nplt.ylabel('# of Passengers')\nplt.legend()","452825c5":"# Plot the heatmap of the data to show the correlation\n\nsns.heatmap(data1.corr(), cmap=\"YlGnBu\", annot = True)\nplt.show()","55fe73a0":"from sklearn.model_selection import train_test_split\n\n# Separating target column from other features\n\ntarget = 'Survived'\n\ny = data1[target]\nx = data1.drop(columns = target)\n\n# Train and Test dataset split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state = 42)\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = data1[\"Survived\"]\n\n#features = [\"Age\", \"Sex_male\", \"Embarked_S\", \"Embarked_Q\"]\nfeatures = [\"Age\", \"Male\",\"Pclass_2\", \"Pclass_3\",\"FamilySize\"]\nX = pd.get_dummies(data1[features])\nX_test = pd.get_dummies(x_test[features])","400e0917":"from sklearn.metrics import accuracy_score\nmodel = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\nscore = accuracy_score(y_test, predictions)\nprint(\"Score: \",score)","b257f801":"X_val = pd.get_dummies(data_val[features])\npredictions_test = model.predict(X_val)\noutput = pd.DataFrame({'PassengerId': PassengerId, 'Survived': predictions_test})\noutput.to_csv('my_submission_RFC.csv', index=False)\nprint(\"Your submission was successfully saved!\")","a9ffff06":"### 3.6. Check for Outliers","08d07bc3":"# 4. Visualising the Data","78d4d79b":"### 5.1. Build Model","a49ad922":"### 2.4. describe()","99e79c06":"### 3.7. Check for correlations and fix\/drop them","b38aab4b":"### 3.2. Convert binary variable (e.g., Sex: male\/female) to 0\/1","742147d2":"# 3. Data cleaning and preparation","66ef4784":"### 3.3. For categorical variables with multiple levels, create dummy features (one-hot encoded)","9f016ba6":"### 3.5. Drop repeated\/unnecessary Variables","50137a49":"### 2.1. head()","d56f6596":"# 2. Understanding\/Inspecting the data","f9587be8":"### 4.1. Visualise numeric values","35f4f5ad":"##### 4.2.3. heatmap","2be07579":"# 5. Model Building","2a159206":"### 1.1. Reading Data from any data source (local\/online repository)","302ba5c2":"### 2.2. shape","d3b985a9":"##### 4.1.1. pairplot","545d46c4":"### 4.2. Visualise categorical values","d9d2475d":"### 3.4. Create derived variables","28aed9de":"##### 4.2.1. boxplot","79ad85c2":"### 2.3. info()","ee5e3f46":"# 1. Reading\/Importing the Data","8e5ecdc7":"### 3.1. Checking for Missing Values and Fix\/Drop them","0509d318":"##### 4.2.2. histogram"}}