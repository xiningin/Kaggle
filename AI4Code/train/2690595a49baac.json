{"cell_type":{"19039eeb":"code","d419228b":"code","110b96b2":"code","9f0e4244":"code","d8fb34e9":"code","41b011a5":"code","17da4830":"code","ae6d11f8":"code","8c1c7e8e":"code","81ed9c9c":"code","1587a1a2":"code","7587e896":"code","dd01af87":"code","56acc14f":"code","7749ca2b":"code","ea97ea61":"code","71a5760d":"code","f35e3543":"code","3a971a7f":"code","9a8cbb70":"code","30209463":"code","1eca747b":"code","f7e19360":"code","ab58468c":"markdown"},"source":{"19039eeb":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score,confusion_matrix , precision_score,recall_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder","d419228b":"iris = load_iris()\n#make data ready for binary classification\n#take only first 2 feature and the two non-linearly separable classes are labeled with the same category\nX = iris.data[:,:2]\ny = (iris.target != 0) * 1","110b96b2":"plt.scatter(x=X[y==0][:,0],y=X[y==0][:,1],color='red',label='0')\nplt.scatter(x=X[y==1][:,0],y=X[y==1][:,1],color='green',label='1')\nplt.legend()","9f0e4244":"class LogisticRegression_o:\n    def __init__(self,lr=0.01,num_itre = 5000,fit_intercept=True,verbose=False):\n        self.lr = lr\n        self.num_itre = num_itre\n        self.fit_intercept =fit_intercept\n        self.verbose = verbose\n        \n    def __add_intercept(self):\n        intercept = np.ones((X.shape[0],1))\n        return np.concatenate((intercept,X) , axis=1)\n    \n    def __sigmoid(self,z):\n        return 1\/(1+np.exp(-z))\n    \n    def __loss(self,hypo,y):\n        return (-y*np.log(hypo) + (1-y)*np.log(1-hypo)).mean()\n    \n    def fit(self,X,y):\n        if self.fit_intercept:\n            X = self.__add_intercept()\n        self.theta = np.zeros(X.shape[1])\n        for i in range(self.num_itre):\n            z = np.dot(X,self.theta)\n            hypo = self.__sigmoid(z)\n            gre = np.dot(hypo-y , X) \/ y.shape[0]\n            self.theta = self.theta - self.lr* gre\n            if self.verbose==True and i%10000 == 0:\n                z = np.dot(X,self.theta)\n                hypo = self.__sigmoid(z)\n                print(f'loss: {self.__loss(hypo)}')\n                \n    def predict_prob(self,X):\n        if self.fit_intercept:\n            X = self.__add_intercept()\n        z = np.dot(X,self.theta)\n        return self.__sigmoid(z)\n    \n    def predict(self,X,threshold=0.5):\n        return self.predict_prob(X) >= threshold","d8fb34e9":"lr = LogisticRegression_o(lr=0.1,num_itre=300000)\nlr.fit(X,y)\npre = lr.predict(X)\n(pre == y).mean()","41b011a5":"t = lr.theta\nt","17da4830":"plt.scatter(x=X[y==0][:,0],y=X[y==0][:,1],color='red',label='0')\nplt.scatter(x=X[y==1][:,0],y=X[y==1][:,1],color='green',label='1')\nplt.legend()\n\n#plot \u03b8.T * X = 0\n#plot the line defined by theta[0] + theta[1]*x + theta[2]*y = 0\n\nde_x = np.linspace(4,8,50)\nde_y = -(t[0]+t[1] * de_x)\/t[2]\nplt.plot(de_x,de_y)","ae6d11f8":"#using sklearn libray\nX = iris.data[:,:2]\ny = (iris.target != 0) * 1\nmodel = LogisticRegression(C=1e20,solver='liblinear')\nmodel.fit(X,y)\npre1 = model.predict(X)\n(y==pre1).mean()\n\nplt.scatter(x=X[y==0][:,0],y=X[y==0][:,1],color='red',label='0')\nplt.scatter(x=X[y==1][:,0],y=X[y==1][:,1],color='green',label='1')\nplt.legend()\n\n#plot \u03b8.T * X = 0\n#plot the line defined by theta[0] + theta[1]*x + theta[2]*y = 0\n\nde_x = np.linspace(4,8,50)\nde_y = -(model.intercept_+model.coef_[0][0] * de_x)\/model.coef_[0][1]\nplt.plot(de_x,de_y)","8c1c7e8e":"heart_data = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\n#heart_data=heart_data.sample(frac=1) #shuffle the data\n\nX = heart_data.iloc[:,:-1]\ny = heart_data.iloc[:,-1]\nprint(heart_data['target'].value_counts())","81ed9c9c":"print(heart_data.isna().sum())","1587a1a2":"heart_data.head()","7587e896":"import seaborn as sns\nplt.figure(figsize=(12,13))\ncor = heart_data.corr().round(2)\n#sns.heatmap(data=cor,annot=True)","dd01af87":"#handle categorical data\ndef coder(X_1,col_name):\n    label = LabelEncoder()\n    X_1 = label.fit_transform(X_1)\n    X_1 = X_1.reshape(len(X_1),1)\n    one = OneHotEncoder(categories='auto',sparse=False)\n    X_1 = one.fit_transform(X_1)\n    df = pd.DataFrame(X_1)\n    df = rename_col(df,col_name)\n    return df\ndef rename_col(df,col_name):\n    col_name_list=[]\n    for i in range(len(df.columns)):\n        col_name_list.append(col_name+'_'+ str(i))\n    df.columns = col_name_list\n    return df","56acc14f":"new_sex = coder(heart_data['sex'],'sex').astype(float)\nnew_cp = coder(heart_data['cp'],'cp').astype(float)\nnew_fbs = coder(heart_data['fbs'],'fbs').astype(float)\nnew_exang = coder(heart_data['exang'],'exang').astype(float)\nnew_slope = coder(heart_data['slope'],'slope').astype(float)\nnew_ca = coder(heart_data['ca'],'ca').astype(float)\nnew_thal = coder(heart_data['thal'],'thal').astype(float)\nnew_restecg = coder(heart_data['restecg'],'restecg').astype(float)\nnew_age = heart_data['age'].astype(float)\nnew_trestbps = heart_data['trestbps'].astype(float)\nnew_chol = heart_data['chol'].astype(float)\nnew_oldpeak = heart_data['oldpeak'].astype(float)\nnew_thalach = heart_data['thalach'].astype(float)","7749ca2b":"#New X\nX = pd.concat([new_age,new_sex,new_trestbps,new_chol,new_fbs,new_restecg,new_thalach,new_exang,\n              new_oldpeak,new_slope,new_ca,new_thal],axis=1)\nX.columns\nX.head()","ea97ea61":"from sklearn.preprocessing import MinMaxScaler\npre = MinMaxScaler()\nX = pre.fit_transform(X)\nX = pd.DataFrame(X)\nX.head()","71a5760d":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=100,shuffle=True)\nX_train.shape , X_test.shape","f35e3543":"#select diffrent method\ndef cal(method,c=1,p='l2'):\n    lr = LogisticRegression(C=c,solver=method,penalty=p)\n    lr.fit(X_train,y_train)\n    pre_test = lr.predict(X_test)\n    pre_train = lr.predict(X_train)\n    train_score = accuracy_score(y_train,pre_train)\n    test_score = accuracy_score(y_test,pre_test)\n    cm = confusion_matrix(y_test,pre_test)\n    \n    TP = cm[1][1]\n    FP = cm[0][1]\n    FN = cm[1][0]\n    TN = cm[0][0]\n    Precision = precision_score(y_test,pre_test)\n    Recall = recall_score(y_test,pre_test)\n    return train_score,test_score,TP,FP,FN,TN,Precision,Recall\n","3a971a7f":"method = ['newton-cg','lbfgs','liblinear','sag','saga']\ntrain_list , test_list , TP_list,FP_list,FN_list,TN_list,Precision_list,Recall_list =[],[],[],[],[],[],[],[]","9a8cbb70":"for i in method:\n    method_df = pd.DataFrame()\n    train_score,test_score,TP,FP,FN,TN,Precision,Recall = cal(i)\n    train_list.append(train_score)\n    test_list.append(test_score)\n    TP_list.append(TP)\n    FP_list.append(FP)\n    FN_list.append(FN)\n    TN_list.append(TN)\n    Precision_list.append(Precision)\n    Recall_list.append(Recall)\nmethod_df['method'] = method\nmethod_df['train_score'] = train_list\nmethod_df['test_score'] = test_list\nmethod_df['TP'] = TP_list\nmethod_df['FP'] = FP_list\nmethod_df['FN'] = FN_list\nmethod_df['TN'] = TN_list\nmethod_df['Precision'] = Precision_list\nmethod_df['Recall'] = Recall_list\nmethod_df","30209463":"N=5\nind = np.arange(N)\nwidth=0.35\nplt.bar(ind,train_list,width,color='b',label='Train acc')\nplt.bar(ind+width,test_score,width,color='r',label='Test acc')\nplt.ylabel('acc')\nplt.xticks(ind+width\/2,(method))\nplt.show()","1eca747b":"#select diff C value with liblinear\ntrain_list , test_list , TP_list,FP_list,FN_list,TN_list,Precision_list,Recall_list =[],[],[],[],[],[],[],[]\nc_value=[0.0001,0.001,0.01,0.1,1,2,3,5,9,10,20,30,40,50]\nfor i in c_value:\n    c_df = pd.DataFrame()\n    train_score,test_score,TP,FP,FN,TN,Precision,Recall = cal(method='liblinear',c=i)\n    train_list.append(train_score)\n    test_list.append(test_score)\n    TP_list.append(TP)\n    FP_list.append(FP)\n    FN_list.append(FN)\n    TN_list.append(TN)\n    Precision_list.append(Precision)\n    Recall_list.append(Recall)\nc_df['c_value'] = c_value\nc_df['train_score'] = train_list\nc_df['test_score'] = test_list\nc_df['TP'] = TP_list\nc_df['FP'] = FP_list\nc_df['FN'] = FN_list\nc_df['TN'] = TN_list\nc_df['Precision'] = Precision_list\nc_df['Recall'] = Recall_list\nc_df","f7e19360":"%matplotlib inline\nplt.plot(c_value,train_list,'r-',label='train acc')\nplt.plot(c_value,test_list,'b-',label='test acc')\nplt.xlabel('C parm')\nplt.ylabel('acc')\nplt.legend()\nplt.show()","ab58468c":"Binary classification with more number of feature"}}