{"cell_type":{"b6fb7343":"code","b80f179e":"code","8ab579c2":"code","4f1fa247":"code","4055b83a":"code","a448c781":"code","45ec05eb":"code","9ba396eb":"code","fb70fe6e":"code","60b262e8":"code","afba8f1d":"code","a2fa4f40":"markdown","04b22495":"markdown","120f2523":"markdown","fb813894":"markdown","8bf09c43":"markdown","f9f50d69":"markdown","f1155480":"markdown","e85a49b4":"markdown","d7a57cee":"markdown"},"source":{"b6fb7343":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport PIL\nimport zipfile\nimport os","b80f179e":"# Path to zip file\n\npath_to_train_zip = '..\/input\/train.zip'\npath_to_test_zip = '..\/input\/test1.zip'\ndirectory_to_extract = '.'\n\nBATCH_SIZE = 256\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nEPOCHS = 1\n\ntrain_imgs_path = '.\/train'\ntest_imgs_path = '.\/test1'\n\nlabel_map = {\n    'dog' : 1,\n    'cat' : 0\n}\n\ninverse_label_map = {\n    1 : 'dog',\n    0 : 'cat'\n}","8ab579c2":"with zipfile.ZipFile(path_to_train_zip, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract)\n    \nwith zipfile.ZipFile(path_to_test_zip, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract)","4f1fa247":"class DVCLoader(torch.utils.data.Dataset):\n    def __init__(self, path_to_images, label_map, dim_img):\n        '''\n        Provide link to images directory in path_to_images\n        '''\n        super().__init__()\n        self.all_images = [f\"{path_to_images}\/{img}\" for img in os.listdir(path_to_images)]\n        self.labels = [label.split('.')[0] for label in os.listdir(path_to_images)]\n        \n        self.length = len(self.all_images)\n        \n        self.label_map = label_map\n        self.transforms = torchvision.transforms.Compose([\n            torchvision.transforms.Resize((dim_img, dim_img)),\n            torchvision.transforms.ToTensor(),            \n            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n        \n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self, idx):\n        '''\n        Return PIL Image\n        '''\n        label_numeric = torch.tensor(self.label_map[self.labels[idx]], dtype = torch.float32)\n        img_pil = PIL.Image.open(self.all_images[idx])\n        img_final = self.transforms(img_pil)\n        return (img_final, label_numeric)","4055b83a":"a = DVCLoader(train_imgs_path, label_map, dim_img = 250)\ntrain_data, val_data = torch.utils.data.random_split(a, [15000, 10000])","a448c781":"train_dl = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True, num_workers = 8, pin_memory=True)\nval_dl = torch.utils.data.DataLoader(val_data, batch_size = BATCH_SIZE, shuffle = True, num_workers = 8, pin_memory=True)","45ec05eb":"class CVDClassifier(torch.nn.Module):\n    '''\n    cats v\/s dogs\n    '''\n    def __init__(self):\n        super().__init__()\n        self.backbone = torchvision.models.squeezenet1_0(pretrained=True)\n        # outputs 1x1000 dimensional vector\n        self.out = torch.nn.Linear(1000, 1)\n        # just outputs the logits, loss optimizer handled separately\n        \n    def forward(self, img_tensor):\n        return self.out(self.backbone(img_tensor))","9ba396eb":"# set optimizer, loss, metric\nmodel = CVDClassifier()\nmodel = model.to(DEVICE)\nloss_function = torch.nn.BCEWithLogitsLoss(reduction = 'mean').cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","fb70fe6e":"# # training loop\n# for epoch in range(EPOCHS):\n#     model.train()\n#     for batch_idx, (img, labels) in enumerate(train_dl):\n        \n#         labels = labels.cuda()\n        \n#         output = model(img.cuda())\n#         loss = loss_function(output, labels.view(-1, 1))\n        \n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n        \n#         # Validation\n#         if epoch % 5 == 0 and batch_idx % 5 == 0:\n#             with torch.no_grad():\n#                 model.eval()\n#                 img, label = next(iter(val_dl))\n#                 output = model(img.cuda())\n#                 loss = loss_function(output, labels.view(-1, 1).float())\n#                 print(f\"Loss EPOCH {epoch} BATCH {batch_idx} {loss.detach()}\")","60b262e8":"submission = pd.DataFrame()\nid_col = []\nlabel_col = []\ntfs = torchvision.transforms.Compose([\n            torchvision.transforms.Resize((250, 250)),\n            torchvision.transforms.ToTensor(),            \n            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n\nmodel.eval()\n\nfor _img in os.listdir(test_imgs_path):\n    img_id = int(_img.split('.')[0])\n    img = PIL.Image.open(f\"{test_imgs_path}\/{_img}\")\n    img_tensor = tfs(img)\n    with torch.no_grad():\n        pred = int(model(img_tensor.unsqueeze(0).cuda()) > 0.5)\n        \n    id_col.append(img_id)\n    label_col.append(pred)\n    \n    \n\n# Final Submission file\nsubmission['id'] = id_col\nsubmission['label'] = label_col\n\nSUBMISSION_IDENTIFIER = 'run_1_torch_squeezenet'\nsubmission.to_csv(f'submission_{SUBMISSION_IDENTIFIER}.csv', index=False)","afba8f1d":"!rm -r .\/train\n!rm -r .\/test1","a2fa4f40":"# dataLoader","04b22495":"# Data Splitting","120f2523":"# Define Model","fb813894":"# Extract the data","8bf09c43":"# Training Loop Parameters","f9f50d69":"# Data Loader","f1155480":"# Submission file","e85a49b4":"# Cats v\/s Dogs kernel rewritten for practice","d7a57cee":"# Define Global Variables"}}