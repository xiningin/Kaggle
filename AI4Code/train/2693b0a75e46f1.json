{"cell_type":{"00e4efaf":"code","1672aa3c":"code","54441329":"code","13179299":"code","7ec61025":"code","6a17fc00":"code","520273ca":"code","b7942149":"code","6b62ed67":"code","1f60cdeb":"code","cbf7c041":"code","86a45635":"code","6ae6317c":"code","15bfdb97":"code","8f265d97":"code","f663480f":"code","caf2b32c":"code","4b3d4d0f":"code","79557b8f":"code","8750bfe3":"code","4b6ace25":"code","7d70e2d1":"code","56d5b943":"code","1c64f8bc":"code","08d7f1dc":"code","797ad7c1":"code","0451afca":"code","7dffa052":"code","d0b2fc7e":"code","5294bccb":"code","70131f84":"code","f93d93e2":"code","53202fb4":"code","cc7ff68c":"code","69496f15":"markdown","ed0d9602":"markdown","b402673d":"markdown","15ecb4de":"markdown","a2c56cbb":"markdown","256e53b5":"markdown"},"source":{"00e4efaf":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)","1672aa3c":"train_dir='..\/input\/fruits\/fruits-360\/Training\/'\ntest_dir='..\/input\/fruits\/fruits-360\/Test\/'","54441329":"#create dataframe from training and test directory\ntraindf=pd.DataFrame(columns=['img_path','class'])\ntest_df=pd.DataFrame(columns=['img_path','class'])","13179299":"for className in os.listdir(train_dir):\n    for filename in os.listdir(os.path.join(train_dir,className)):\n        img_path=(os.path.join(train_dir,className,filename))\n        traindf=traindf.append({'img_path':img_path,'class':className},ignore_index=True)","7ec61025":"for className in os.listdir(test_dir):\n    for filename in os.listdir(os.path.join(test_dir,className)):\n        img_path=(os.path.join(test_dir,className,filename))\n        test_df=test_df.append({'img_path':img_path,'class':className},ignore_index=True)","6a17fc00":"#create validation set from training data\ntrain_df,valid_df=train_test_split(traindf,test_size=0.1,random_state=0)\nlen(train_df), len(test_df), len(valid_df)","520273ca":"print(train_df.info())","b7942149":"print(train_df.head())","6b62ed67":"print(test_df.info())","1f60cdeb":"print(valid_df.info())","cbf7c041":"tf=train_df['class'].value_counts().to_frame().reset_index() \ntf.rename(columns={\"index\": \"class\", \"class\": \"train_counts\"},inplace=True)\ntf1=test_df['class'].value_counts().to_frame().reset_index() \ntf1.rename(columns={\"index\": \"class\", \"class\": \"test_counts\"},inplace=True)\ntf2=valid_df['class'].value_counts().to_frame().reset_index() \ntf2.rename(columns={\"index\": \"class\", \"class\": \"valid_counts\"},inplace=True)\ndf=pd.merge(tf,tf1,on='class')\ndf=pd.merge(df,tf2,on='class')\ndf","86a45635":"# Visualization (No of samples in each class of training data)\nplt.figure(figsize=(20,30))\ng=sns.countplot(y='class',data=train_df)\n#g.set_xticklabels(g.get_xticklabels(), rotation=90)","6ae6317c":"#top 10 classes in training data (highest number of samples)\ntf=train_df['class'].value_counts()[:10]\ntf=tf.to_frame().reset_index() \ntf.rename(columns={\"index\": \"class\", \"class\": \"counts\"},inplace=True)\nplt.figure(figsize=(15,5))\ng=sns.barplot(x='class',y='counts',data=tf)","15bfdb97":"#bottom 10 classes in training data (lowest number of samples)\ntf=train_df['class'].value_counts()[-11:-1]\ntf=tf.to_frame().reset_index() \ntf.rename(columns={\"index\": \"class\", \"class\": \"counts\"},inplace=True)\nplt.figure(figsize=(15,5))\ng=sns.barplot(x='class',y='counts',data=tf)","8f265d97":"#top 10 classes in testing data(highest number of samples)\ntf=test_df['class'].value_counts()[:10]\ntf=tf.to_frame().reset_index() \ntf.rename(columns={\"index\": \"class\", \"class\": \"counts\"},inplace=True)\nplt.figure(figsize=(20,5))\ng=sns.barplot(x='class',y='counts',data=tf)","f663480f":"#bottom 10 classes in testing data(lowest number of samples)\ntf=test_df['class'].value_counts()[-10:-1]\ntf=tf.to_frame().reset_index() \ntf.rename(columns={\"index\": \"class\", \"class\": \"counts\"},inplace=True)\nplt.figure(figsize=(15,5))\ng=sns.barplot(x='class',y='counts',data=tf)","caf2b32c":"img=cv2.imread(train_df['img_path'][1])\nimg=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nprint(f'The size of image is {img.shape}')","4b3d4d0f":"#plot 10 random images of fruits from the training set\nplt.figure(figsize=(20,10))\nfor i in range(10):\n    rand_int=np.random.randint(1,len(train_df))\n    print(rand_int)\n    img=cv2.imread(train_df['img_path'][rand_int])\n    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.subplot(2,5,i+1)\n    plt.imshow(img)\n    plt.grid(b=False)\n    plt.title(train_df['class'][rand_int])","79557b8f":"fig,axes=plt.subplots(1,3,figsize=(15,5))\ng1=sns.histplot(data=img[:,:,0].ravel(),ax=axes[0])\ng2=sns.histplot(data=img[:,:,1].ravel(),ax=axes[1])\ng3=sns.histplot(data=img[:,:,2].ravel(),ax=axes[2])","8750bfe3":"train_df.head()","4b6ace25":"train_datagen=ImageDataGenerator(rescale=1.\/255)\ntest_datagen=ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator=train_datagen.flow_from_dataframe(\ndataframe=train_df,\nx_col=\"img_path\",\ny_col='class',\nbatch_size=32,\nseed=42,\nshuffle=True,\nclass_mode=\"categorical\",target_size=(224,224))\n\nvalidation_generator=train_datagen.flow_from_dataframe(\ndataframe=valid_df,\nx_col=\"img_path\",\ny_col='class',\nbatch_size=32,\nseed=42,\nshuffle=True,\nclass_mode=\"categorical\",target_size=(224,224))\n\ntest_generator=test_datagen.flow_from_dataframe(\ndataframe=test_df,\nx_col=\"img_path\",\ny_col='class',\nbatch_size=1,\nseed=42,\nshuffle=True,\nclass_mode=\"categorical\",target_size=(224,224))","7d70e2d1":"train_generator.image_shape","56d5b943":"img1=train_generator.next()[0]\nfig=plt.imshow(img1[0,:,:,:])","1c64f8bc":"from keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras import layers\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping\nimport keras","08d7f1dc":"model=VGG16(input_shape=(224,224,3), weights='imagenet')\nearlystopping = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=3 )","797ad7c1":"for layer in model.layers[:-1]: \n    layer.trainable=False\n#for layer in model.layers[15:]: \n    #layer.trainable=True    ","0451afca":"model.summary()","7dffa052":"pretrained_last_layer=model.get_layer(name=model.layers[-2].name)\npretrained_output=pretrained_last_layer.output\nnext_layer= layers.Dense(131, activation='softmax')(pretrained_output)\npretrained_vgg = Model(model.input, next_layer)","d0b2fc7e":"pretrained_vgg.summary()","5294bccb":"pretrained_vgg.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam() ,metrics=['accuracy'])","70131f84":"batch_size=64\nhistory=pretrained_vgg.fit(train_generator,validation_data=validation_generator,epochs=8,callbacks=earlystopping)","f93d93e2":"loss, accuracy = pretrained_vgg.evaluate(test_generator)\nprint(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))","53202fb4":"json_model=pretrained_vgg.to_json()\nwith open('vgg_fruit131.json','w') as json_file:\n    json_file.write(json_model)\npretrained_vgg.save_weights('vgg_fruit131.h5')","cc7ff68c":"#model_finetune=VGG16(input_shape=(224,224,3),include_top=False, weights='imagenet')\n#print(f'The total number of layers in VGG16 is {len(model_finetune.layers)}.')\n#print(f'The last layer in model is {model_finetune.layers[-1].name}.')\n#print(f'The weights upto layer 14 which is {model_finetune.layers[14].name} will remain pretrained. ')\n#for layer in model_finetune.layers[:15]: \n#    layer.trainable=False\n#for layer in model_finetune.layers[15:]: \n#    layer.trainable=True  \n#model_finetune.summary()","69496f15":"# Classification using VGG16 with Imagenet pretrained weights ","ed0d9602":"# Save model","b402673d":"# Data Visualization","15ecb4de":"# Sample count","a2c56cbb":"# Fine tune VGG16 using Fruit database","256e53b5":"# Data preparation"}}