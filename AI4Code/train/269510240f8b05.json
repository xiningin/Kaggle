{"cell_type":{"792b7620":"code","1e394dc4":"code","a70f549e":"code","f119d399":"code","5bf02629":"code","cd4603fa":"code","2da1973f":"code","37392ea6":"code","f8cd5104":"code","8dc5215e":"code","b9575189":"code","16e2036b":"code","2dc6da0d":"code","e60059ab":"code","c483fbd8":"code","675c8b93":"code","abcc6ec7":"code","0d00030b":"code","5f1a5829":"code","dc12f0e1":"code","78331a3a":"code","6e6466b5":"code","c610047f":"code","694f0bce":"code","87d4b9b0":"code","4469cb3c":"code","402b0313":"code","1fae175b":"code","b7c2adea":"code","ed738850":"code","d4838a4b":"code","c43d4ff6":"code","96f8b39b":"code","993e189b":"code","7a76947c":"code","ba7a8688":"code","19d5d7c2":"code","dd5ced69":"markdown","6d33118c":"markdown","c5b4754d":"markdown","5662edc4":"markdown","e604c094":"markdown","ba96e3ff":"markdown","795dbe1b":"markdown","d8470bb6":"markdown","89def68c":"markdown","ab64ab0b":"markdown","9e87830a":"markdown","432c7caf":"markdown","0a957e00":"markdown","9a07343f":"markdown","049c0f5f":"markdown","309fcfa2":"markdown","ab9d73a4":"markdown","ab3b2482":"markdown","af96403a":"markdown","7c0f79a7":"markdown","3d85450e":"markdown","0ae064d4":"markdown"},"source":{"792b7620":"import os\nimport re\nimport gc\nimport sys\nimport yaml\nimport copy\nimport random\nimport shutil\nimport typing as tp\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import mean_squared_error\n\nimport cv2\nimport albumentations\nfrom albumentations.core.transforms_interface import ImageOnlyTransform, DualTransform\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data\n\nsys.path.append(\"..\/input\/pytorch-pfn-extras\/pytorch-pfn-extras-0.3.2\")\nimport pytorch_pfn_extras as ppe\nfrom pytorch_pfn_extras.training import extensions as ppe_exts\n\nsys.path.append(\"..\/input\/iterative-stratification\/iterative-stratification-master\")\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nsys.path.append(\"..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\")\nimport timm","1e394dc4":"ROOT = Path.cwd().parent\nINPUT = ROOT \/ \"input\"\nDATA = INPUT \/ \"bms-molecular-translation\"\nTRAIN = DATA \/ \"train\"\nTRAIN_224 = INPUT \/ \"bms-molecular-224px-jpg-padded\" \/ \"train\"\nTEST = DATA \/ \"test\"\nTEST_224 = INPUT \/ \"bms-molecular-224px-jpg-padded\" \/ \"test\"\n\nTMP = ROOT \/ \"tmp\"\nTMP.mkdir(exist_ok=True)\n\nRANDAM_SEED = 1086\n\nFOLDS = [0, 1, 2, 3, 4]\nN_FOLD = len(FOLDS)\n# FOLDS = [0,]\n# N_FOLD = 5\n\nTARGETS = [\n    'B', 'Br', 'C', 'Cl',\n    'F', 'H', 'I', 'N',\n    'O', 'P', 'S', 'Si']\n\nN_TARGETS = len(TARGETS)","a70f549e":"train = pd.read_csv(DATA \/ \"train_labels.csv\")\ntrain.head()","f119d399":"# # extract chemical formula\ntrain[\"formula\"] = train.InChI.str.extract(\"InChI=1S\/([^\/]+)\/.+\")\ntrain.head()","5bf02629":"elem_regex = re.compile(r\"[A-Z][a-z]?[0-9]*\")\natom_regex = re.compile(r\"[A-Z][a-z]?\")\ndgts_regex = re.compile(r\"[0-9]*\")\n\nformula_examples = [\n    \"C23H19ClIN3O\",\n    \"C33H49B2N3O4\",\n    \"C13H12BrF3N4OS\",\n    \"C5H18O2P2Si2\"]\n\nfor i, fml in enumerate(formula_examples):\n    print(f\"[example{i + 1}: {fml}]\")\n    print(\"\\tatom with digits:\", elem_regex.findall(fml))\n    print(\"\\tatom:\", atom_regex.findall(fml))\n    print(\"\\tdigits\", dgts_regex.findall(fml))","cd4603fa":"# # example for counting method\nfor fml in formula_examples:\n    atom_dict = dict()\n    print(f\"[formula: {fml}]\")\n    for elem in elem_regex.findall(fml):\n        atom = dgts_regex.sub(\"\", elem)\n        dgts = atom_regex.sub(\"\", elem)\n        atom_cnt = int(dgts) if len(dgts) > 0 else 1\n        atom_dict[atom] = atom_cnt\n        print(f\"\\t[elem:\\t{elem}]\\tatom: {atom},\\tdgts: {dgts},\\tatom_cnt: {atom_cnt}\")\n    print(f\"\\tresult: {atom_dict}\")","2da1973f":"# # apply to all train data\natom_dict_list = []\nfor fml in tqdm(train[\"formula\"].values):\n    atom_dict = dict()\n    for elem in elem_regex.findall(fml):\n        atom = dgts_regex.sub(\"\", elem)\n        dgts = atom_regex.sub(\"\", elem)\n        atom_cnt = int(dgts) if len(dgts) > 0 else 1\n        atom_dict[atom] = atom_cnt\n    atom_dict_list.append(atom_dict)\n    \natom_df = pd.DataFrame(\n    atom_dict_list).fillna(0).astype(int)\natom_df = atom_df.sort_index(axis=\"columns\")","37392ea6":"# # merge\nfor atom in TARGETS:\n    train[atom] = atom_df[atom]\ntrain.head()","f8cd5104":"del atom_df\ndel atom_dict\ndel atom_dict_list\ngc.collect()","8dc5215e":"# # total number of each atoms\ndisplay(train[TARGETS].sum(axis=0))\n_ = train[TARGETS].sum(axis=0).T.plot(kind=\"bar\")","b9575189":"# # distribution of n_atoms for each example\ntrain[\"n_atoms\"] = train[TARGETS].sum(axis=1)\n_ = train[\"n_atoms\"].hist(bins=100)","16e2036b":"settings = yaml.safe_load(\"\"\"\nglobals:\n  seed: 1086\n  device: cuda\n  max_epoch: 15\n  patience: -1\n  use_amp: True\n  reduce_data: True\n  reduce_div_factor: 25\n\ndataset:\n  name: LabeledImageDataset\n  train:\n    transform_list:\n      # - [Resize, {always_apply: True, height: 224, width: 224}]\n      - [HorizontalFlip, {p: 0.5}]\n      - [VerticalFlip, {p: 0.5}]\n      - [ShiftScaleRotate, {\n          p: 0.5, shift_limit: 0.2, scale_limit: 0.2,\n          rotate_limit: 20, border_mode: 0, value: 0, mask_value: 0}]\n      - [RandomResizedCrop, {height: 224, width: 224, scale: [0.9, 1.0]}]\n      - [Normalize, {always_apply: True}]\n      - [ToTensorV2, {always_apply: True}]\n  val:\n    transform_list:\n      # - [Resize, {always_apply: True, height: 224, width: 224}]\n      - [Normalize, {always_apply: True}]\n      - [ToTensorV2, {always_apply: True}]\n\nloader:\n  train:\n    batch_size: 64\n    shuffle: True\n    num_workers: 4\n    pin_memory: True\n    drop_last: True\n  val:\n    batch_size: 128\n    shuffle: False\n    num_workers: 4\n    pin_memory: True\n    drop_last: False\n\nmodel:\n  name: BasicImageModel\n  params:\n    base_name: resnet18d\n    dims_head: [null, 12]\n    pretrained: True\n\nloss:\n  name: MSELoss\n  params: {}\n\neval:\n  - {name: MyMSELoss, report_name: loss, params: {}}\n\noptimizer:\n  name: AdamW\n  params:\n    lr: 1.0e-06\n    weight_decay: 1.0e-02\n\nscheduler:\n  name: OneCycleLR\n  params:\n    epochs: 15\n    max_lr: 1.0e-3\n    pct_start: 0.2\n    anneal_strategy: cos\n    div_factor: 1.0e+3\n    final_div_factor: 1.0e+3\n\"\"\")","2dc6da0d":"class BasicImageModel(nn.Module):\n    \n    def __init__(\n        self, base_name, dims_head: tp, pretrained=False\n    ):\n        \"\"\"Initialize\"\"\"\n        self.base_name = base_name\n        super(BasicImageModel, self).__init__()\n        \n        # # prepare backbone\n        if hasattr(timm.models, base_name):\n            # # # load base model\n            base_model = timm.create_model(base_name, pretrained=pretrained)\n            in_features = base_model.num_features\n            # # remove head classifier\n            base_model.reset_classifier(0)\n        else:\n            raise NotImplementedError\n\n        self.backbone = base_model\n        \n        # # prepare head clasifier\n        if dims_head[0] is None:\n            dims_head[0] = in_features\n\n        layers_list = []\n        for i in range(len(dims_head) - 2):\n            in_dim, out_dim = dims_head[i: i + 2]\n            layers_list.extend([\n                nn.Linear(in_dim, out_dim),\n                nn.ReLU(), nn.Dropout(0.5),])\n        layers_list.append(\n            nn.Linear(dims_head[-2], dims_head[-1]))\n        self.head = nn.Sequential(*layers_list)\n\n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        h = self.backbone(x)\n        h = self.head(h)\n        return h","e60059ab":"class ImageTransformBase:\n    \"\"\"\n    Base Image Transform class.\n\n    Args:\n        data_augmentations: List of tuple(method: str, params :dict), each elems pass to albumentations\n    \"\"\"\n\n    def __init__(self, data_augmentations: tp.List[tp.Tuple[str, tp.Dict]]):\n        \"\"\"Initialize.\"\"\"\n        augmentations_list = [\n            self._get_augmentation(aug_name)(**params)\n            for aug_name, params in data_augmentations]\n        self.data_aug = albumentations.Compose(augmentations_list)\n\n    def __call__(self, pair: tp.Tuple[np.ndarray]) -> tp.Tuple[np.ndarray]:\n        \"\"\"You have to implement this by task\"\"\"\n        raise NotImplementedError\n\n    def _get_augmentation(self, aug_name: str) -> tp.Tuple[ImageOnlyTransform, DualTransform]:\n        \"\"\"Get augmentations from albumentations\"\"\"\n        if hasattr(albumentations, aug_name):\n            return getattr(albumentations, aug_name)\n        else:\n            return eval(aug_name)\n\n\nclass ImageTransformForCls(ImageTransformBase):\n    \"\"\"Data Augmentor for Classification Task.\"\"\"\n\n    def __init__(self, data_augmentations: tp.List[tp.Tuple[str, tp.Dict]]):\n        \"\"\"Initialize.\"\"\"\n        super(ImageTransformForCls, self).__init__(data_augmentations)\n\n    def __call__(self, in_arrs: tp.Tuple[np.ndarray]) -> tp.Tuple[np.ndarray]:\n        \"\"\"Apply Transform.\"\"\"\n        img, label = in_arrs\n        augmented = self.data_aug(image=img)\n        img = augmented[\"image\"]\n\n        return img, label","c483fbd8":"class LabeledImageDataset(data.Dataset):\n    \"\"\"Dataset class for (image, label) pairs\"\"\"\n\n    def __init__(\n        self,\n        file_list: tp.List[\n            tp.Tuple[tp.Union[str, Path], tp.Union[int, float, np.ndarray]]],\n        transform_list: tp.List[tp.Dict],\n    ):\n        \"\"\"Initialize\"\"\"\n        self.file_list = file_list\n        self.transform = ImageTransformForCls(transform_list)\n\n    def __len__(self):\n        \"\"\"Return Num of Images.\"\"\"\n        return len(self.file_list)\n\n    def __getitem__(self, index):\n        \"\"\"Return transformed image and mask for given index.\"\"\"\n        img_path, label = self.file_list[index]\n        img = self._read_image_as_array(img_path)\n\n        img, label = self.transform((img, label))\n        return img, label\n\n    def _read_image_as_array(self, path: str):\n        \"\"\"Read image file and convert into numpy.ndarray\"\"\"\n        img_arr = cv2.imread(str(path))\n        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n        return img_arr","675c8b93":"class EvalFuncManager(nn.Module):\n    \"\"\"Manager Class for evaluation at the end of epoch\"\"\"\n\n    def __init__(\n        self,\n        evalfunc_dict: tp.Dict[str, nn.Module],\n        iters_per_epoch: int,\n        prefix: str = \"val\"\n    ) -> None:\n        \"\"\"Initialize\"\"\"\n        self.tmp_iter = 0\n        self.iters_per_epoch = iters_per_epoch\n        self.prefix = prefix\n        self.metric_names = []\n        super(EvalFuncManager, self).__init__()\n        for k, v in evalfunc_dict.items():\n            setattr(self, k, v)\n            self.metric_names.append(k)\n        self.reset()\n\n    def reset(self) -> None:\n        \"\"\"Reset State.\"\"\"\n        self.tmp_iter = 0\n        for name in self.metric_names:\n            getattr(self, name).reset()\n\n    def __call__(self, y: torch.Tensor, t: torch.Tensor) -> None:\n        \"\"\"Forward.\"\"\"\n        for name in self.metric_names:\n            getattr(self, name).update(y, t)\n        self.tmp_iter += 1\n\n        if self.tmp_iter == self.iters_per_epoch:\n            ppe.reporting.report({\n                \"{}\/{}\".format(self.prefix, name): getattr(self, name).compute()\n                for name in self.metric_names\n            })\n            self.reset()\n            \n            \nclass MeanLoss(nn.Module):\n    \n    def __init__(self):\n        super(MeanLoss, self).__init__()\n        self.loss_sum = 0\n        self.n_examples = 0\n        \n    def forward(self, y: torch.Tensor, t: torch.Tensor):\n        \"\"\"Compute metric at once\"\"\"\n        return self.loss_func(y, t)\n\n    def reset(self):\n        \"\"\"Reset state\"\"\"\n        self.loss_sum = 0\n        self.n_examples = 0\n    \n    def update(self, y: torch.Tensor, t: torch.Tensor):\n        \"\"\"Update metric by mini batch\"\"\"\n        self.loss_sum += self(y, t).item() * y.shape[0]\n        self.n_examples += y.shape[0]\n\n    def compute(self):\n        \"\"\"Compute metric for dataset\"\"\"\n        return self.loss_sum \/ self.n_examples\n    \n    \nclass MyMSELoss(MeanLoss):\n\n    def __init__(self, **params):\n        super(MyMSELoss, self).__init__()\n        self.loss_func = nn.MSELoss(**params)","abcc6ec7":"def get_file_list(stgs, train_all):\n    \"\"\"Get file path and target info.\"\"\"\n    use_fold = stgs[\"globals\"][\"val_fold\"]\n    \n    train_df = train_all[train_all[\"fold\"] != use_fold]\n    val_df = train_all[train_all[\"fold\"] == use_fold]\n    \n#     train_data_dir = TRAIN\n    train_data_dir = TRAIN_224\n    train_file_list = list(zip([\n#         train_data_dir \/ f\"{img_id[0]}\/{img_id[1]}\/{img_id[2]}\/{img_id}.png\"\n        train_data_dir \/ f\"{img_id}.jpg\"\n        for img_id in train_df[\"image_id\"].values\n    ], train_df[TARGETS].values.astype(\"f\")))\n\n    val_file_list = list(zip([\n#         train_data_dir \/ f\"{img_id[0]}\/{img_id[1]}\/{img_id[2]}\/{img_id}.png\"\n        train_data_dir \/ f\"{img_id}.jpg\"\n        for img_id in val_df[\"image_id\"].values\n    ], val_df[TARGETS].values.astype(\"f\")))\n\n    if stgs[\"globals\"][\"reduce_data\"]:\n        div = stgs[\"globals\"][\"reduce_div_factor\"]\n        trn_smpl_idx = np.random.choice(range(len(train_df)), len(train_df) \/\/ div)\n        val_smpl_idx = np.random.choice(range(len(val_df)), len(val_df) \/\/ div)\n        train_file_list = [train_file_list[idx] for idx in trn_smpl_idx]\n        val_file_list = [val_file_list[idx] for idx in val_smpl_idx]\n        \n    return train_file_list, val_file_list\n\n\ndef get_dataloaders(\n    stgs: tp.Dict,\n    train_file_list: tp.List[tp.List],\n    val_file_list: tp.List[tp.List],\n    dataset_class: data.Dataset\n):\n    \"\"\"Create DataLoader\"\"\"\n    train_loader = val_loader = None\n    if train_file_list is not None:\n        train_dataset = dataset_class(\n            train_file_list, **stgs[\"dataset\"][\"train\"])\n        train_loader = data.DataLoader(\n            train_dataset, **stgs[\"loader\"][\"train\"])\n\n    if val_file_list is not None:\n        val_dataset = dataset_class(\n            val_file_list, **stgs[\"dataset\"][\"val\"])\n        val_loader = data.DataLoader(\n            val_dataset, **stgs[\"loader\"][\"val\"])\n\n    return train_loader, val_loader","0d00030b":"def get_model(args):\n    \"\"\"\"\"\"\n    return eval(args[\"name\"])(**args[\"params\"])\n\n\ndef get_optimizer(args, model):\n    \"\"\"\"\"\"\n    if hasattr(torch.optim, args[\"name\"]):\n        opt_class = getattr(torch.optim, args[\"name\"])\n    else:\n        opt_class = eval(args[\"name\"])\n\n    return opt_class(model.parameters(), **args[\"params\"])\n\n\ndef get_scheduler(args, optimizer, max_epoch, steps_per_epoch):\n    \"\"\"\"\"\"\n    if args[\"name\"] == \"OneCycleLR\":\n        args[\"params\"][\"epochs\"] = max_epoch\n        args[\"params\"][\"steps_per_epoch\"] = steps_per_epoch\n\n    if hasattr(torch.optim.lr_scheduler, args[\"name\"]):\n        scdr_class = getattr(torch.optim.lr_scheduler, args[\"name\"])\n    else:\n        scdr_class = eval(args[\"name\"])\n\n    return scdr_class(optimizer, **args[\"params\"])\n\n\ndef get_loss_function(args):\n    \"\"\"\"\"\"\n    if hasattr(nn, args[\"name\"]):\n        loss_class = getattr(nn, args[\"name\"])\n    else:\n        loss_class = eval(args[\"name\"])\n\n    return loss_class(**args[\"params\"])\n\n\ndef get_stepper(manager, stgs, scheduler):\n    \"\"\"\"\"\"\n    if stgs[\"scheduler\"][\"name\"] == \"CosineAnnealingWarmRestarts\":\n        def step_scheduler_by_epoch():\n            pass\n\n        def step_scheduler_by_iter():\n            scheduler.step(manager.epoch_detail)\n\n    elif stgs[\"scheduler\"][\"name\"] == \"OneCycleLR\":\n        def step_scheduler_by_epoch():\n            pass\n\n        def step_scheduler_by_iter():\n            scheduler.step()\n\n    else:\n        def step_scheduler_by_epoch():\n            scheduler.step()\n\n        def step_scheduler_by_iter():\n            pass\n\n    return step_scheduler_by_epoch, step_scheduler_by_iter","5f1a5829":"def get_manager(\n    stgs, model, device, train_loader, val_loader, optimizer,\n    eval_manager, output_path, print_progress: bool = False,\n):\n    \"\"\"\"\"\"\n    # # initialize manager\n    if stgs[\"globals\"][\"patience\"] > 0:\n        trigger = ppe.training.triggers.EarlyStoppingTrigger(\n            check_trigger=(1, 'epoch'), monitor='val\/loss', mode=\"min\",\n            patience=stgs[\"globals\"][\"patience\"], verbose=True,\n            max_trigger=(stgs[\"globals\"][\"max_epoch\"], 'epoch'))\n    else:\n        trigger = None    \n    manager = ppe.training.ExtensionsManager(\n        model, optimizer, stgs[\"globals\"][\"max_epoch\"],\n        iters_per_epoch=len(train_loader), stop_trigger=trigger, out_dir=output_path)\n\n    # # for logging\n    eval_names = [\"val\/{}\".format(name) for name in eval_manager.metric_names]    \n    log_extentions = [\n        ppe_exts.observe_lr(optimizer=optimizer),\n        ppe_exts.LogReport(),\n        ppe_exts.PlotReport([\"train\/loss\", \"val\/loss\"], 'epoch', filename='loss.png'),\n        # ppe_exts.PlotReport([\"val\/metric\"], 'epoch', filename='metric.png'),\n        ppe_exts.PlotReport([\"lr\"], 'epoch', filename='lr.png'),\n        ppe_exts.PrintReport([\n            \"epoch\", \"iteration\", \"lr\", \"train\/loss\", *eval_names, \"elapsed_time\"])\n    ]\n    if print_progress:\n        log_extentions.append(ppe_exts.ProgressBar(update_interval=20))\n\n    for ext in log_extentions:\n        manager.extend(ext)\n        \n    # # for evaluation\n    def eval_func(*batch):\n        return run_eval(stgs, model, device, batch, eval_manager)\n    manager.extend(\n        ppe_exts.Evaluator(val_loader, model, eval_func=eval_func),\n        trigger=(1, \"epoch\"))\n    \n    # # for saving snapshot\n    manager.extend(\n        ppe_exts.snapshot(target=model, filename=\"snapshot_by_loss_epoch_{.epoch}.pth\"),\n        trigger=ppe.training.triggers.MinValueTrigger(key=\"val\/loss\", trigger=(1, 'epoch')))\n\n    return manager","dc12f0e1":"def set_random_seed(seed: int = 42, deterministic: bool = False):\n    \"\"\"Set seeds\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)  # type: ignore\n    torch.backends.cudnn.deterministic = deterministic  # type: ignore","78331a3a":"def run_train_loop(\n    manager, stgs, model, device, train_loader, optimizer, scheduler, loss_func\n):\n    \"\"\"Run minibatch training loop\"\"\"\n    step_scheduler_by_epoch, step_scheduler_by_iter = get_stepper(manager, stgs, scheduler)\n \n    use_amp = stgs[\"globals\"][\"use_amp\"]\n    while not manager.stop_trigger:\n        model.train()\n        scaler = torch.cuda.amp.GradScaler() if use_amp else None\n        for batch in train_loader:\n            with manager.run_iteration():\n                x = batch[0].to(device)\n                t = batch[-1].to(device)\n                optimizer.zero_grad()\n                if use_amp:\n                    with torch.cuda.amp.autocast():\n                        y = model(x)\n                        loss = loss_func(y, t)    \n                    scaler.scale(loss).backward()\n                    scaler.step(optimizer)\n                    scaler.update()\n                else:\n                    y = model(x)\n                    loss = loss_func(y, t)\n                    loss.backward()\n                    optimizer.step()\n\n                ppe.reporting.report({'train\/loss': loss.item()})    \n                step_scheduler_by_iter()\n        step_scheduler_by_epoch()\n\n\ndef run_eval(stgs, model, device, batch, eval_manager):\n    \"\"\"Run evaliation for val or test. this function is applied to each batch.\"\"\"\n    model.eval()\n    x = batch[0].to(device)\n    t = batch[-1].to(device)\n    if stgs[\"globals\"][\"use_amp\"]:\n        with torch.cuda.amp.autocast(): \n            y = model(x)\n            eval_manager(y, t)\n    else:\n        y = model(x)\n        eval_manager(y, t)","6e6466b5":"def train_one_fold(stgs, train_all, output_path, print_progress=False):\n    \"\"\"train one fold\"\"\"\n    torch.backends.cudnn.benchmark = True\n    set_random_seed(stgs[\"globals\"][\"seed\"])\n\n    # # prepare train, valid paths\n    train_file_list, val_file_list = get_file_list(stgs, train_all)\n    print(\"train: {}, val: {}\".format(len(train_file_list), len(val_file_list)))\n\n    device = torch.device(stgs[\"globals\"][\"device\"])\n    # # get data_loader\n    train_loader, val_loader = get_dataloaders(\n        stgs, train_file_list, val_file_list, LabeledImageDataset)\n\n    # # get model\n    model = BasicImageModel(**stgs[\"model\"][\"params\"])\n    model.to(device)\n\n    # # get optimizer\n    optimizer = getattr(\n        torch.optim, stgs[\"optimizer\"][\"name\"]\n    )(model.parameters(), **stgs[\"optimizer\"][\"params\"])\n\n    # # get scheduler\n    if stgs[\"scheduler\"][\"name\"] == \"OneCycleLR\":\n        stgs[\"scheduler\"][\"params\"][\"epochs\"] = stgs[\"globals\"][\"max_epoch\"]\n        stgs[\"scheduler\"][\"params\"][\"steps_per_epoch\"] = len(train_loader)\n    scheduler = getattr(\n        torch.optim.lr_scheduler, stgs[\"scheduler\"][\"name\"]\n    )(optimizer, **stgs[\"scheduler\"][\"params\"])\n\n    # # get loss\n    if hasattr(nn, stgs[\"loss\"][\"name\"]):\n        loss_func = getattr(nn, stgs[\"loss\"][\"name\"])(**stgs[\"loss\"][\"params\"])\n    else:\n        loss_func = eval(stgs[\"loss\"][\"name\"])(**stgs[\"loss\"][\"params\"])\n    loss_func.to(device)\n\n    eval_manager = EvalFuncManager(\n        {\n            metric[\"report_name\"]: eval(metric[\"name\"])(**metric[\"params\"])\n            for metric in stgs[\"eval\"]\n        }, len(val_loader))\n    eval_manager.to(device)\n\n    # # get manager\n    manager = get_manager(\n        stgs, model, device, train_loader, val_loader,\n        optimizer, eval_manager, output_path, print_progress)\n\n    run_train_loop(\n        manager, stgs, model, device, train_loader,\n        optimizer, scheduler, loss_func)","c610047f":"mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=RANDAM_SEED)\ntrain[\"fold\"] = -1\nfor fold_id, (trn_idx, val_idx) in enumerate(\n    mskf.split(train.InChI, (train[TARGETS] > 0).astype(int))\n):\n    train.loc[val_idx, \"fold\"] = fold_id","694f0bce":"train.groupby(\"fold\")[TARGETS].sum()","87d4b9b0":"train.groupby(\"fold\")[\"n_atoms\"].agg(\n    [\"sum\", \"mean\", \"median\", \"std\", \"max\", \"min\"])","4469cb3c":"(train.InChI.str.len()).groupby(train[\"fold\"]).agg(\n    [\"sum\", \"mean\", \"median\", \"std\", \"max\", \"min\"])","402b0313":"torch.cuda.empty_cache()\ngc.collect()","1fae175b":"stgs_list = []\nfor fold_id in FOLDS:\n    tmp_stgs = copy.deepcopy(settings)\n    tmp_stgs[\"globals\"][\"val_fold\"] = fold_id\n    stgs_list.append(tmp_stgs)","b7c2adea":"for fold_id, tmp_stgs in zip(FOLDS, stgs_list):\n    train_one_fold(tmp_stgs, train, TMP \/ f\"fold{fold_id}\", False)\n    torch.cuda.empty_cache()\n    gc.collect()","ed738850":"best_log_list = []\nfor fold_id, tmp_stgs in enumerate(stgs_list):\n    exp_dir_path = TMP \/ f\"fold{fold_id}\"\n    log = pd.read_json(exp_dir_path \/ \"log\")\n    best_log = log.iloc[[log[\"val\/loss\"].idxmin()],]\n    best_epoch = best_log.epoch.values[0]\n    best_log_list.append(best_log)\n    \n    best_model_path = exp_dir_path \/ f\"snapshot_by_loss_epoch_{best_epoch}.pth\"\n    copy_to = f\".\/best_loss_model_fold{fold_id}.pth\"\n    shutil.copy(best_model_path, copy_to)\n    \n    for p in exp_dir_path.glob(\"*.pth\"):\n        p.unlink()\n    \n    shutil.copytree(exp_dir_path, f\".\/fold{fold_id}\")\n    \n    with open(f\".\/fold{fold_id}\/settings.yml\", \"w\") as fw:\n        yaml.dump(tmp_stgs, fw)\n    \npd.concat(best_log_list, axis=0, ignore_index=True)","d4838a4b":"def run_inference_loop(stgs, model, loader, device):\n    model.to(device)\n    model.eval()\n    pred_list = []\n    with torch.no_grad():\n        for x, t in tqdm(loader):\n            if stgs[\"globals\"][\"use_amp\"]:\n                with torch.cuda.amp.autocast():\n                    y = model(x.to(device))\n            else:\n                y = model(x.to(device))\n            pred_list.append(y.detach().cpu().numpy())\n        \n    pred_arr = np.concatenate(pred_list)\n    del pred_list\n    return pred_arr","c43d4ff6":"oof_pred_arr = np.zeros((len(train), N_TARGETS))\nlabel_arr = train[TARGETS].values\nscore_list = []\n\nfor fold_id in range(N_FOLD):\n    print(f\"[fold {fold_id}]\")\n    tmp_dir = Path(f\".\/fold{fold_id}\")\n    with open(tmp_dir \/ \"settings.yml\", \"r\") as fr:\n        tmp_stgs = yaml.safe_load(fr)\n    device = torch.device(tmp_stgs[\"globals\"][\"device\"])\n    val_idx = train.query(\"fold == @fold_id\").index.values\n    \n    # # get data_loader\n    tmp_stgs[\"globals\"][\"reduce_data\"] = False\n    _, val_file_list = get_file_list(tmp_stgs, train)\n    _, val_loader = get_dataloaders(\n        tmp_stgs, None, val_file_list, LabeledImageDataset)\n#     val_idx = val_idx[:len(val_file_list)]\n    \n    # # get and load model\n    model_path =f\".\/best_loss_model_fold{fold_id}.pth\"\n    tmp_stgs[\"model\"][\"params\"][\"pretrained\"] = False\n    model = BasicImageModel(**tmp_stgs[\"model\"][\"params\"])\n    model.load_state_dict(torch.load(model_path, map_location=device))\n\n    val_pred = run_inference_loop(tmp_stgs, model, val_loader, device)\n    val_loss = mean_squared_error(label_arr[val_idx], val_pred)\n    print(f\"[fold {fold_id}] val loss: {val_loss:.5f}\")\n    oof_pred_arr[val_idx] = val_pred\n    score_list.append([fold_id, val_loss])\n    \n    del model\n    del val_pred\n    torch.cuda.empty_cache()\n    gc.collect()","96f8b39b":"oof_loss = mean_squared_error(label_arr, oof_pred_arr)\nscore_list.append([\"oof\", oof_loss])","993e189b":"pd.DataFrame(score_list, columns=[\"fold\", \"mse\"])","7a76947c":"oof_pred_arr.shape","ba7a8688":"oof_df = train.copy()\noof_df[TARGETS] = oof_pred_arr\noof_df.to_csv(\".\/oof_prediction.csv\", index=False)","19d5d7c2":"train.to_pickle(\".\/train_formula_mlskf_5fold.pkl\")","dd5ced69":"### training utils","6d33118c":"### inference","c5b4754d":"### copy best model","5662edc4":"# Training Multi-Output Regression\n\n## summary\n\n* base model: resnet18d\n* CV Strategy: Multi-Label Stratified KFold(K=5) by atoms in each chemical formula\n* image size: 224x224 (simply resize)\n* batch size: 64\n* epoch: 15\n* optimizer: AdamW\n* schedular: OneCycleLR\n* augmentation: HorizontalFlip, VerticalFlip, ShiftScaleRotate, RandomResizedCrop\n\n**NOTE**: I use **only 4%** of training data for faster trainng.","e604c094":"### model","ba96e3ff":"### get XXX","795dbe1b":"## read label data","d8470bb6":"## settings","89def68c":"### split fold","ab64ab0b":"## Inference OOF","9e87830a":"### counting number of atoms for each example","432c7caf":"## import","0a957e00":"### extract chemical formula from InChI","9a07343f":"### image dataset","049c0f5f":"## train","309fcfa2":"# About\n\n`InChI` string can be split by `\/` into some parts (max number of parts in training data is 11). The first part is the format which is uniform string(`InChI=1S`) in this competition, and the second part is **chemical formula** which represents **the number of atoms** in each molecular.\n\nLet me take `InChI=1S\/C13H20OS\/c1-9(2)8-15-13-6-5-10(3)7-12(13)11(4)14\/h5-7,9,11,14H,8H2,1-4H3`(`image_id`: `000011a64c74`) as an example.\nThe second part is `C13H20OS`, which means that the molecular have 13`Carbon`s, 20`Hydrogen`s, a `Oxygen` and a `Sulfur`.\n\nAll the parts of `InChI` have **variable length** except for the second one (chemical formula) because the kind of atoms in training data is **limited** to 12(`B`, `Br`, `C`, `Cl`, `F`, `H`, `I`, `N`, `O`, `P`, `S`, and `Si`). Therefore, we can represents a chemical formula by a **fixed length** vector and treat chemical formula prediction task as **multi-output regression task**.\n\n\nIn this notebook, I try to train a model which predicts chemical furmula by multi-variate regression. I think precisse prediction of chemical furmula is helpful to predict other parts of `InChI`.\n\nThere are some notebooks which forcus on atoms or chemical formulas.\n\n* [Bristol-Myers Squibb_count_atom](https:\/\/www.kaggle.com\/kalfirst\/bristol-myers-squibb-count-atom)\n* [Bristol-Myers Squibb: Counting Elements](https:\/\/www.kaggle.com\/stainsby\/bristol-myers-squibb-counting-elements)\n* [Step by Step 2: LS dist < 1 chemical formula](https:\/\/www.kaggle.com\/wineplanetary\/step-by-step-2-ls-dist-1-chemical-formula)\n\nThe last one already did what I want to do (Thank you for sharing @wineplanetary). I noticed that when I was almost done with this notebook\ud83d\ude05\n\nTo make the difference, I will show you training process in this notebook, and try solving the competition task by utilizing predicted chemical formula in inference notebook.","ab9d73a4":"### metric for evaluation","ab3b2482":"## definition","af96403a":"### check atom distribution","7c0f79a7":"## preprocess","3d85450e":"# Prepare","0ae064d4":"### run training"}}