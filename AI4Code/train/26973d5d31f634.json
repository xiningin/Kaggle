{"cell_type":{"aaaf6bef":"code","0994b8e8":"code","902884b3":"code","cd21ccb1":"code","ad77b85c":"code","f4f99374":"code","8f02a65d":"code","7f01a4a8":"code","ada9f8b9":"code","5174a85a":"code","035e4dca":"code","70aeb751":"code","3b36d416":"code","afb056b8":"code","a63d7dcf":"code","3bed3ea8":"code","231ceb73":"code","4db2d124":"code","7d70bcac":"code","ffa58e72":"code","f7ad63a0":"code","67ba3664":"code","10ddb2cf":"markdown","971dbd56":"markdown","5f1bc93f":"markdown","76acaef4":"markdown","49fb17f0":"markdown","dc9cb863":"markdown","248850b1":"markdown","5043bdcd":"markdown","da04ffec":"markdown"},"source":{"aaaf6bef":"!pip install tensorflow==2.3.0 -q","0994b8e8":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import python\nfrom tensorflow import keras \nfrom keras import applications\nfrom keras.models import Model\nfrom keras.models import load_model\nfrom keras.applications import vgg16\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.applications.vgg16 import decode_predictions\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras.losses import categorical_crossentropy\nfrom keras.layers import Dropout, Flatten, Dense , MaxPooling2D\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom glob import glob\nimport PIL\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","902884b3":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 100 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [224, 224]\nEPOCHS = 800","cd21ccb1":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/alzheimermridataset\/Alzheimer_s Dataset\/train\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/alzheimermridataset\/Alzheimer_s Dataset\/train\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)","ad77b85c":"print(train_ds)","f4f99374":"class_names = ['MildDementia', 'ModerateDementia', 'NonDementia', 'VeryMildDementia']\ntrain_ds.class_names = class_names\nval_ds.class_names = class_names\n\nNUM_CLASSES = len(class_names)","8f02a65d":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(12):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(train_ds.class_names[labels[i]])\n    plt.axis(\"off\")","7f01a4a8":"NUM_IMAGES = []\n\nfor label in class_names:\n    dir_name = \"..\/input\/alzheimermridataset\/Alzheimer_s Dataset\/train\/\" + label[:-2] + 'ed'\n    NUM_IMAGES.append(len([name for name in os.listdir(dir_name)]))","ada9f8b9":"def one_hot_label(image, label):\n    label = tf.one_hot(label, NUM_CLASSES)\n    return image, label\n\ntrain_ds = train_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)","5174a85a":"datagen = ImageDataGenerator(\n        rotation_range=5,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=False,\n        fill_mode='nearest')\n\nimg = load_img('..\/input\/alzheimermridataset\/Alzheimer_s Dataset\/train\/MildDemented\/mildDem0.jpg')  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\nx = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n\n# the .flow() command below generates batches of randomly transformed images\n# and saves the results to the `preview\/` directory\ni = 0\nfor batch in datagen.flow(x, batch_size=1,\n                          save_to_dir=None , save_prefix=\"\", save_format='jpeg'):\n    i += 1\n    if i > 20:\n        break  # otherwise the generator would loop indefinitely","035e4dca":"folders = glob('..\/input\/alzheimermridataset\/Alzheimer_s Dataset\/train')","70aeb751":"train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","3b36d416":"# Generate the trained model and set all layers to be trainable\ntrained_model = VGG16(input_shape=(224,224,3), include_top=False,weights=\"imagenet\")\n\nfor layer in trained_model.layers:\n    layer.trainable = True\n\n# Construct the model and compile\nmod1 = Flatten()\nmod_final = Dense(4, activation='softmax')\n\nmodel = Sequential([trained_model, mod1, mod_final])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\nmodel.summary()","afb056b8":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.01**(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 20)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",\n                                                    save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=500,\n                                                     restore_best_weights=True)","a63d7dcf":"history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n    epochs=EPOCHS\n)","3bed3ea8":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","231ceb73":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","4db2d124":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['recall']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","7d70bcac":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/alzheimermridataset\/Alzheimer_s Dataset\/test\",\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)\n\ntest_ds = test_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","ffa58e72":"_ = model.evaluate(test_ds)","f7ad63a0":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy']):\n    ax[i].plot(history.history[met])\n   # ax[i].plot(history.history[ met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    #ax[i].legend(['train', 'test'])","67ba3664":"model.save_weights('first_try.h5')","10ddb2cf":"# Evaluate the Model\n\nAlthough we used the validatation dataset to continually evaluate the model, we also have a separate testing dataset. Let's prepare the testing dataset.","971dbd56":"The following cell makes calling images from our dataset more efficient.","5f1bc93f":"# Feature Engineering\n\nBecause we are working with categorical and noncontinuous data, we want to convert our model into one-hot encodings. One-hot encodings are a way for the model to understand that we're looking at categorial instead of continuous data. Transforming features so that they'll be more understandable is called feature engineering. Learn more about feature engineering [here](https:\/\/developers.google.com\/machine-learning\/crash-course\/representation\/feature-engineering).","76acaef4":"It's always a good idea to set constant variables instead of hard coding numbers into your code. It saves time later when you want to change certain parameters.","49fb17f0":"We'll be renaming the class names and specifying the number of classes. In this case, we have 4 classes of dementia.","dc9cb863":"# Visualize the data\n\nNow that our data has been easily loaded in, the next step is to visualize our images. This helps us understand what is being used as an input for our model. It also serves as a check to see if our images have been loaded in correctly.","248850b1":"# Introduction + Set-up\n\nMachine learning has a phenomenal range of application in the health sciences. This tutorial will go over the complete pipeline to build a model that can determine the dementia level of an Alzheimer's patient from their MRI image. This model achieves an a high ROC AUC score.\n\nThis tutorial highlights the ease of building a CNN using `tf.keras`. Additionally, TensorFlow 2.3 has new features, including easy data loading utilities that were previously not available in TensorFlow 2.2. We'll be seeing how easy data loading is with these additional features.\n\nWe'll be using a GPU accelerator for this NB.","5043bdcd":"# Visualize Model Metrics\n\nLet's graph the ROC AUC metric and loss after each epoch for the training and validation data. Although we didn't use a random seed for our notebook, the results may slightly vary, generally the scores for the validataion data is similar, if not better, than the training dataset.","da04ffec":"# Data Loading\n\nWe'll be using a [Kaggle Alzheimer's dataset](https:\/\/www.kaggle.com\/tourist55\/alzheimers-dataset-4-class-of-images) for our tutorial. `tf.keras` has a new preprocessing function that can easily load in images for a directory. In order for this function to work, the data has to be structured in a file directory format.\n\n```\nmain_directory\/\n    class1\/\n        class1_images\n    class2\/\n        class2_images\n```\n\nIf you input the `main_directory` into the `tf.keras` function, it will figure out the rest!\nIn our case, the `train` directory is our main directory.\n\nWe are also specifying a 80:20 split for our training and validation datasets. To learn more about the importance of having a validation split, check out this [lesson](https:\/\/developers.google.com\/machine-learning\/crash-course\/validation\/another-partition) from Google's Machine Learning Crash Course."}}