{"cell_type":{"25101c70":"code","ede12d9a":"code","72661572":"code","303898d4":"code","01329f49":"code","299b1fe6":"code","f332a699":"code","972e480b":"code","497d21c8":"code","9d2f7997":"code","fa4b88d3":"code","3c5c62a9":"code","9b7be99a":"code","9bc843c4":"code","0c0518a0":"code","e5bb658e":"markdown","e4e9cf49":"markdown","d1e0306f":"markdown","58bbc10e":"markdown","67051bc5":"markdown","75c5489d":"markdown","69549d9b":"markdown","d2f05690":"markdown","d9422f02":"markdown","a0cb1f11":"markdown"},"source":{"25101c70":"# Loading the packages \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly \nimport time\nimport os \nimport folium \nimport scipy.stats\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial import distance\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom sklearn import preprocessing\nfrom plotly import tools\nimport plotly.plotly as py\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport sklearn.semi_supervised \nfrom sklearn import datasets\nfrom sklearn.semi_supervised import LabelPropagation\nfrom sklearn.ensemble import RandomForestClassifier","ede12d9a":"# Loading files from last pre-processing from kernel 1\npath_to_save_dfs = '..\/input\/passnyc-label-propagation-algorithm\/'\nbayes_df = pd.read_csv(path_to_save_dfs + \"Bayes_df.csv\")\nSAT_summary = pd.read_csv(path_to_save_dfs + \"SAT_summary.csv\")\nclass_size = pd.read_csv(path_to_save_dfs + \"Class_size.csv\")\nsafety_df = pd.read_csv(path_to_save_dfs + \"crime_df.csv\")\nlabel_df = pd.read_csv(path_to_save_dfs + \"Labels.csv\")\nprint(\"Files Loading done!!\")","72661572":"# 1. Function for creating bins for bayesian network for causal inference \ndef binning(col, labels=None):\n    \"\"\"Function to define bins for bayesian network analysis\"\"\"\n    #Define min and max values\n    minval = col.min()\n    maxval = col.max()\n\n    #create list by adding min and max to cut_points\n    delta = (maxval - minval)\/5.0\n    cut_points = []\n    for j in [1,2,3,4]:\n        cut_points.append((minval+j*delta))\n    # print(cut_points)   \n    break_points =  [minval]+ cut_points + [maxval]\n    # print(break_points)\n    len_ = list(set(list(break_points))).__len__()\n\n        \n    #print(break_points)\n    #if no labels provided, use default labels 0 ... (n-1)\n    if not labels:\n        labels = list(range(len(cut_points)+1))\n\n    #Binning using cut function of pandas\n    colBin = pd.cut(col,bins=break_points,labels=labels,include_lowest=True)\n    return(colBin)\n\ndef to_upper(row):\n    \"\"\"Function to convert a string to upper case \"\"\"\n    return(row.upper())\n\n# 2. prepare data for bayesian network \ndef prepare_bayesian_network_input(new_df, cols_for_binning):\n    \"\"\"Function to prepare the input for bayesian network\"\"\"\n    df = new_df.copy()\n    new_cols = []\n    for col in cols_for_binning:\n        # print(cols_for_binning)\n        new_cols.append(\"bin_\"+col)\n        df[\"bin_\"+col] = binning(df[col])\n    return(df[new_cols])\n\n\ndef Assign_k_means_cluster(df, n):\n    \"\"\"function to assign k-means clusters \n        n = number of clusters\n    \"\"\"\n    columns = ['Latitude','Longitude']\n    df_new = df[columns]\n    kmeans = MiniBatchKMeans(n_clusters=n).fit(df_new)\n    df.loc[:, 'location_cluster'] = kmeans.predict(df[columns])\n    #test_meta.loc[:, 'k_means_cluster'] = kmeans.predict(test_meta[columns])\n    return(df)\n\n# bayes_df = Assign_k_means_cluster(bayes_df, 10)","303898d4":"# Merging data for making master dataframe \nbayes_df.head()\nprint(\"Shape of bayes df is {}\".format(bayes_df.shape[0]))\n\n\n# Merging SAT score and bayes data \nSAT_summary['School name'] = list(map(to_upper, SAT_summary['School name']))\nmaster_df = bayes_df.merge(SAT_summary, left_on = 'Location Code', right_on = 'DBN', how = 'left')\nprint(\"Shape of master df is {}\".format(master_df.shape[0]))\n\n\n\n# Crime data pre-processing before merging to get district wise crime data\naggregate_crime_stats = {'Major N':np.mean,\n                         'Oth N':np.mean,\n                         'NoCrim N':np.mean,\n                         'Prop N':np.mean,\n                         'Vio N':np.mean}\ncrime_summary = pd.DataFrame(safety_df.groupby(['Geographical District Code']).agg(aggregate_crime_stats))\ncrime_summary.reset_index(inplace = True)\ncrime_summary['Geographical District Code'] = list(map(int, crime_summary['Geographical District Code']))\nprint(\"The shape of locatio wise crime data is {}\".format(crime_summary.shape))\ncrime_summary.head()\n\n\n\n# Merging class df for class size \nmaster_df = master_df.merge(crime_summary, left_on = 'District', right_on = 'Geographical District Code', how = 'left')\nprint(\"Shape of master_df is {}\".format(master_df.shape[0]))\nmaster_df.head()\n\nA = master_df.copy()\n# Merging class_size data somehow - Later -if time permits \n# Add perdicted_underperforming by label_df\nlabel = label_df[['School Name','Predicted_underperforming']]\nlabel.drop_duplicates(subset = ['School Name'],keep = 'first',inplace = True)\nmaster_df = master_df.merge(label, left_on = 'School Name', right_on = 'School Name', how = \"left\")\nmaster_df.head()\nprint(master_df.shape)\nmaster_df.head()","01329f49":"# Creating economic disadvantage features \nmaster_df.head()\n# Grade 8 Math 4s - Limited English Proficient\n# Grade 8 Math 4s - Economically Disadvantaged\n# Grade 8 Math - All Students Tested\n\ncreated_perc_col = []\ngrades_name = [6,7,8]\nfor grade in grades_name:\n    for subj in ['ELA', 'Math']:\n        for suffix in [' 4s - Limited English Proficient', ' 4s - Economically Disadvantaged']:\n            col_name = subj+'_'+str(grade)+suffix\n            created_perc_col.append(col_name)\n            All_4s = 'Grade '+str(grade)+' '+subj+suffix\n            All = 'Grade '+str(grade)+' '+subj+' - All Students Tested'\n            master_df.loc[:,col_name] = (master_df[All_4s].values*100.0)\/master_df[All].values\ncreated_perc_col","299b1fe6":"# Cols for decision tree model \ncols_for_binning = ['Economic Need Index',\n                    'Percent Black \/ Hispanic', \n                    'Student Attendance Rate',\n                    'Percent of Students Chronically Absent',\n                    'Rigorous Instruction Rating',\n                    'Collaborative Teachers Rating',\n                    'Supportive Environment Rating',\n                    'Effective School Leadership Rating',\n                    'Trust Rating',\n                    'Student Achievement Rating',\n                    'Average Math Proficiency',\n                    'Average ELA Proficiency',\n                    'location_cluster',\n                    'ELA_6_4s',\n                    'Math_6_4s',\n                    'ELA_7_4s',\n                    'Math_7_4s',\n                    'ELA_8_4s',\n                    'Math_8_4s', \n                    'Oth N',\n                    'NoCrim N',\n                    'Prop N',\n                    'Vio N',\n                    'Major N']\n                    #'Predicted_underperforming'\n                   \ncols_for_binning_crime = ['Major N',\n                          #'Predicted_underperforming',\n                          #'location_cluster',\n                          'Average Math Proficiency',\n                          'Average ELA Proficiency'\n                         ]\n\n# renaming columns for better visualization \nrename_dict = {'bin_Economic Need Index':'ENI',\n               'bin_Percent Black \/ Hispanic':'P_black',\n               'bin_Student Attendance Rate':'Atd',\n               'bin_Percent of Students Chronically Absent':'chr_abt',\n               'bin_Rigorous Instruction Rating':'Rig_inst',\n               'bin_Collaborative Teachers Rating':'coll_teach',\n               'bin_Supportive Environment Rating':'SUpp_env',\n               'bin_Effective School Leadership Rating':'Leadership',\n               'bin_Trust Rating':'Trust',\n               'bin_Student Achievement Rating':\"Achmt\",\n               'bin_Average Math Proficiency':'Math',\n               'bin_Average ELA Proficiency':'ELA',\n               'bin_location_cluster':'Loc',\n               'bin_ELA_6 4s - Limited English Proficient':'E6_LEP',\n               'bin_ELA_6 4s - Economically Disadvantaged':'E6_disadv',\n               'bin_Math_6 4s - Limited English Proficient':'M6_LEP',\n               'bin_Math_6 4s - Economically Disadvantaged':'M6_disadv',\n               'bin_ELA_7 4s - Limited English Proficient':'E7_LEP',\n               'bin_ELA_7 4s - Economically Disadvantaged':'E7_disadv',\n               'bin_Math_7 4s - Limited English Proficient':'M7_LEP',\n               'bin_Math_7 4s - Economically Disadvantaged':'M7_disadv',\n               'bin_ELA_8 4s - Limited English Proficient':'E8_LEP',\n               'bin_ELA_8 4s - Economically Disadvantaged':'E8_disadv',\n               'bin_Math_8 4s - Limited English Proficient':'M8_LEP',\n               'bin_Math_8 4s - Economically Disadvantaged':'M8_disadv',\n               'bin_ELA_7_4s':'E7_4s',\n               'bin_Math_7_4s':'M7_4s',\n               'bin_ELA_8_4s':'E8_4s',\n               'bin_Math_8_4s':'M8_4s',\n               'Predicted_underperforming':'Low_perf'}\n\ncreated_cols = ['ELA_8 4s - Limited English Proficient',\n                 'ELA_8 4s - Economically Disadvantaged',\n                 'Math_8 4s - Limited English Proficient',\n                 'Math_8 4s - Economically Disadvantaged']  \n\nclass_columns = ['ELA_6_4s',\n                 'Math_6_4s',\n                 'ELA_7_4s',\n                 'Math_7_4s',\n                 'ELA_8_4s',\n                 'Math_8_4s']","f332a699":"## Decision tree workflow for an easy executive level explanation\n## But it can also be used as primary model as PASSNYC gets more data\nmaster_df.head()\nmaster_df['community_school']  = np.where(master_df['Community School?']=='No', 0,1)\ncols_rf = list(set(['community_school'] + cols_for_binning + created_cols +class_columns))\ny = master_df.Predicted_underperforming.values\n     \n    \ntrain = master_df[cols_rf].copy()\nrf = RandomForestClassifier(n_estimators=150, max_depth=8, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=0)\nrf.fit(train, y)\nfeatures = train.columns.values\nprint(\"----- Training Done -----\")","972e480b":"from sklearn import tree\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\nimport re\ndecision_tree = tree.DecisionTreeClassifier(max_depth = 8,splitter = \"random\", random_state=0)\ndecision_tree.fit(train, y)\n\n# Export our trained model as a .dot fil\n\n\nwith open(\"tree1.dot\", 'w') as f:\n     f = tree.export_graphviz(decision_tree,\n                              out_file=f,\n                              max_depth = 8,\n                              impurity = False,\n                              feature_names = train.columns.values,\n                              class_names = ['No', 'Yes'],\n                              rounded = True,\n                              filled= True)\n","497d21c8":"import pydot\nimport graphviz\nimport sys\nfrom subprocess import check_call\n\nfrom subprocess import check_call\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n\n#! dot -Tpng tree1.dot -o tree1.png\n# Annotating chart with PIL\nimg = Image.open(\"tree1.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\")","9d2f7997":"# Scatter plot \ntrace = go.Scatter(\n    y = rf.feature_importances_,\n    x = features,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 13,\n        #size= rf.feature_importances_,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = rf.feature_importances_,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = features\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Proxy measure to determine underperforming school',\n    hovermode= 'closest',\n     xaxis= dict(\n         ticklen= 5,\n         showgrid=False,\n        zeroline=False,\n        showline=False\n     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        showgrid=False,\n        zeroline=False,\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig,filename='scatter2010')","fa4b88d3":"cols_for_binning = ['Economic Need Index',\n                    #'Percent Black \/ Hispanic', \n                    'Student Attendance Rate',\n                    'Percent of Students Chronically Absent',\n                    #'Rigorous Instruction Rating',\n                    #'Collaborative Teachers Rating',\n                    #'Supportive Environment Rating',\n                    #'Effective School Leadership Rating',\n                    #'Trust Rating',\n                    'Student Achievement Rating',\n                    'Average Math Proficiency',\n                    'Average ELA Proficiency',\n                    #'location_cluster',\n                    #'ELA_6_4s',\n                    #'Math_6_4s',\n                    #'ELA_7_4s',\n                    #'Math_7_4s',\n                    'ELA_8_4s',\n                    'Math_8_4s', \n                    #'Oth N',\n                    #'NoCrim N',\n                    #'Prop N',\n                    #'Vio N',\n                    #'Major N']\n                    #'Predicted_underperforming'] \n                   ]\ncols_for_binning_crime = ['Major N',\n                          #'Predicted_underperforming',\n                          #'location_cluster',\n                          'Average Math Proficiency',\n                          'Average ELA Proficiency'\n                         ]\n\n# renaming columns for better visualization \nrename_dict = {'bin_Economic Need Index':'ENI',\n               'bin_Percent Black \/ Hispanic':'P_black',\n               'bin_Student Attendance Rate':'Atd',\n               'bin_Percent of Students Chronically Absent':'chr_abt',\n               'bin_Rigorous Instruction Rating':'Rig_inst',\n               'bin_Collaborative Teachers Rating':'coll_teach',\n               'bin_Supportive Environment Rating':'SUpp_env',\n               'bin_Effective School Leadership Rating':'Leadership',\n               'bin_Trust Rating':'Trust',\n               'bin_Student Achievement Rating':\"Achmt\",\n               'bin_Average Math Proficiency':'Math',\n               'bin_Average ELA Proficiency':'ELA',\n               'bin_location_cluster':'Loc',\n               'bin_ELA_6 4s - Limited English Proficient':'E6_LEP',\n               'bin_ELA_6 4s - Economically Disadvantaged':'E6_disadv',\n               'bin_Math_6 4s - Limited English Proficient':'M6_LEP',\n               'bin_Math_6 4s - Economically Disadvantaged':'M6_disadv',\n               'bin_ELA_7 4s - Limited English Proficient':'E7_LEP',\n               'bin_ELA_7 4s - Economically Disadvantaged':'E7_disadv',\n               'bin_Math_7 4s - Limited English Proficient':'M7_LEP',\n               'bin_Math_7 4s - Economically Disadvantaged':'M7_disadv',\n               'bin_ELA_8 4s - Limited English Proficient':'E8_LEP',\n               'bin_ELA_8 4s - Economically Disadvantaged':'E8_disadv',\n               'bin_Math_8 4s - Limited English Proficient':'M8_LEP',\n               'bin_Math_8 4s - Economically Disadvantaged':'M8_disadv',\n               'bin_ELA_7_4s':'E7_4s',\n               'bin_Math_7_4s':'M7_4s',\n               'bin_ELA_8_4s':'E8_4s',\n               'bin_Math_8_4s':'M8_4s',\n               'Predicted_underperforming':'Low_perf'}\n\ncreated_cols = ['ELA_8 4s - Limited English Proficient',\n                 'ELA_8 4s - Economically Disadvantaged',\n                 'Math_8 4s - Limited English Proficient',\n                 'Math_8 4s - Economically Disadvantaged']  \n\nclass_columns = ['ELA_6_4s',\n                 'Math_6_4s',\n                 'ELA_7_4s',\n                 'Math_7_4s',\n                 'ELA_8_4s',\n                 'Math_8_4s']","3c5c62a9":"# Making dataframes for bayesian networks \nbn_All = prepare_bayesian_network_input(master_df, (cols_for_binning + created_cols))\nbn_crime = prepare_bayesian_network_input(master_df, cols_for_binning_crime+created_cols)\nbn_class = prepare_bayesian_network_input(master_df, class_columns)\nbn_all_ = pd.concat([bn_All, master_df[['Predicted_underperforming']]], axis =1)\nbn_crime_ = pd.concat([bn_crime, master_df[['Predicted_underperforming']]], axis =1)\nbn_class_ = pd.concat([bn_class, master_df[['Predicted_underperforming']]], axis =1)\nprint(bn_all_.shape)\nprint(bn_crime_.shape)\nprint(bn_class_.shape)\n# Talk and clear how \n\nbn_all_.rename(columns = rename_dict, inplace = True)\nbn_crime_.rename(columns = rename_dict, inplace = True)\nbn_class_.rename(columns = rename_dict, inplace = True)\nbn_all_.to_csv(\"Bayesian_network_all_data.csv\", index = False)\nbn_crime_.to_csv(\"Bayesian_network_crime_data.csv\", index = False)\nbn_class_.to_csv(\"Bayesian_network_class_data.csv\", index = False)","9b7be99a":"from IPython.display import Image\nImage(filename = \"..\/input\/helper-notebook-for-bayesian-network\/Basyesian_network_all_data.jpg\", width = 700, height =500)","9bc843c4":"from IPython.display import Image\nImage(filename = \"..\/input\/helper-notebook-for-bayesian-network\/Basyesian_network_crime_data.jpg\", width = 700, height =500)","0c0518a0":"master_df.to_csv(\"Performance_of_schools.csv\", index = False)","e5bb658e":"#### List of revised proxy measures which can be used to explain it to stckholders and partners - \nThis list is in decreasing order of importance (first one being highest important and last one being of lowest importance) -\n- **Math_7_4s** ( Math 7 score can be considered as a base for Math_8 and further SAT registration)\n- **Math 8_4s**\n- **ELA_6_4s**\n- **Math_6_4s**\n- **ELA_8_4s**\n- **Avg ELA proficiency**\n- **ELA_7_4s**\n- **Avg Math Proficiency**\n- **% of black\/hispanic people**\n- **Economic need index**\n- **ELA_8_4s ecomonically disadvantage**\n- **Student attendance rate**","e4e9cf49":"## Data preparation","d1e0306f":"\n## FInal results are provided in Performance_of_schools.csv file\n\n**Note**- When **predicted_underperfoming** variable takes the value 1, the school is underperforming else it's performing well.","58bbc10e":"### Findings from driving factor network analysis - \n- Math proficiency is the most important measure for a school and is driving most of the other proxy measures, and ist main driving factor behind low performing schools. (N1)\n- The Math proficiency is shown to drive ELA proficiency, means making students good with maths will increase their logical and analytical capabilities and which are necessaru for having good ELA proficiency. (N2)\n- If a school perorming low, students of that school are more likely to get involved in some sort of crimes. (N2)\n- Chronic absent from the schools is major driving factor behind low math proficiency\n","67051bc5":"## Thanks for reading.. \nI hope this unique analysis helps PASSNYC in helping others","75c5489d":"### Why decision tree workflow ? To explain the results business people and partner organizations\n**Whenever one has to explain a difficult statistical model to stakeholders, one can use decision trees. Decision trees basically unfolds the complete process of decision making and series of decision to reach to the conclusion. Here we will have to focus on \"yes\" class, as it means yes that particular school is underperforming.** This is one of the simplest methods and most convinient methods when it comes to explain the statistical model to partners (or even to layman population) ","69549d9b":"# Graph based Decision Making and Causal Inference\n## This is kernel 2 for PASSNYC\nThis kernel is kernel 2 for PASSNYC analysis and uses kernel 1's results so please go through kernel 1 for better understanding how the labeling is assigned using label propagation. Link - **https:\/\/www.kaggle.com\/maheshdadhich\/passnyc-label-propagation-algorithm**\n\nIn this kernel, we will talk about a supervised learning model to make a complete workflow process to behind any school being assigned as underperforming. This model is a tree-based model and can also be used when the data for all other districts (SHSAT registration data) is available. The other reason behind using this model is to get the proxy measures. The proxy measures are necessary to give an explanation about under-performing schools, they are necessary to convince stakeholders and partners to agree with the model's results. At last, this will try to draw a causal inference from the available data using the Bayesian network. This network is a deep learning model and with more and more data, its accuracy will increase but even with less amount of data, data preparation is done is the intelligible fashion to get it to work and give us the driving factors behind multiple proxy-measures. \n\n### This kernel will have three parts - \n-  **Decision tree to get the decision workflow to assign a school as underperforming** - This can be used to explain stakeholders and partners the results we are getting from kernel 1. This should be used if partners or stakeholder wants to know the way decisions are taken. \n-  **Proxy measures** - It analyses the Label propagation results using a decision tree model and gives us the new and revised proxy measures.\n- **Driving factor analysis using Bayesian networks** - We create a discrete Bayesian network to get the underlying driving factors for different proxy measures.","d2f05690":"## 3. Analyzing driving factors using Bayesian Network\nAssumptions - \n- Bayesian network being a deep learning model, its hard to fit it so we are using at max 5 levels for each variables\n- Sometimes the results look opposite in Hill climb algorithm (used here), so sujective decision should be made in such cases.****\n- A helper kernel is made for easy implementation of bayesian network. Results are taken from that helper kernel only. Link - https:\/\/www.kaggle.com\/maheshdadhich\/helper-notebook-for-bayesian-network\n- This helper kernel is written with keeping in mind that if PASSNYC has to run a causal inference in future they can directly use this and run it, Another reason is to not make technicalities if bayesian network a part of this analysis, so it's kept seperate.","d9422f02":"## 2. Revised Proxy Measures ","a0cb1f11":"## 1. Decision trees and providing decision workflow"}}