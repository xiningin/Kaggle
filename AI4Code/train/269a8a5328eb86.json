{"cell_type":{"b9396e8a":"code","17aa8fb8":"code","87e95063":"code","b8ee552c":"code","ea314e68":"code","008c97af":"code","d51904a6":"code","add267c5":"code","c8a00df5":"code","7b766678":"code","03e87242":"code","f3c5fdf2":"code","e96ce0c0":"code","5dddf39c":"code","712c178b":"code","e2156531":"code","643348cb":"code","92adf078":"code","cbced01c":"code","cc240560":"code","8bb955cc":"markdown","6539531f":"markdown","d787d376":"markdown","6db8e98f":"markdown","c961623e":"markdown","8a7cbb81":"markdown","0acdf9ea":"markdown"},"source":{"b9396e8a":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport os\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk import PorterStemmer\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","17aa8fb8":"os.listdir('..\/input\/')","87e95063":"data = pd.read_csv('..\/input\/spam_or_not_spam.csv')\ndata.head()","b8ee552c":"data.dropna(inplace=True)\nchange_labels = lambda x: 1 if x==0 else 0\ndata['label'] = data['label'].apply(change_labels)\ndata.head()","ea314e68":"remove_non_alphabets =lambda x: re.sub(r'[^a-zA-Z]',' ',x)","008c97af":"tokenize = lambda x: word_tokenize(x)","d51904a6":"ps = PorterStemmer()\nstem = lambda w: [ ps.stem(x) for x in w ]","add267c5":"lemmatizer = WordNetLemmatizer()\nleammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]","c8a00df5":"print('Processing : [=', end='')\ndata['email'] = data['email'].apply(remove_non_alphabets)\nprint('=', end='')\ndata['email'] = data['email'].apply(tokenize) # [ word_tokenize(row) for row in data['email']]\nprint('=', end='')\ndata['email'] = data['email'].apply(stem)\nprint('=', end='')\ndata['email'] = data['email'].apply(leammtizer)\nprint('=', end='')\ndata['email'] = data['email'].apply(lambda x: ' '.join(x))\nprint('] : Completed', end='')\ndata.head()","7b766678":"max_words = 10000\ncv = CountVectorizer(max_features=max_words, stop_words='english')\nsparse_matrix = cv.fit_transform(data['email']).toarray()","03e87242":"sparse_matrix.shape","f3c5fdf2":"x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(data['label']))","e96ce0c0":"class LogisticRegression(nn.Module):\n    def __init__(self):\n        super(LogisticRegression, self).__init__()\n        self.linear1 = nn.Linear(10000, 100)\n        self.linear2 = nn.Linear(100, 10)\n        self.linear3 = nn.Linear(10, 2)\n        \n    def forward(self, x):\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x","5dddf39c":"model = LogisticRegression()","712c178b":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)","e2156531":"x_train = Variable(torch.from_numpy(x_train)).float()\ny_train = Variable(torch.from_numpy(y_train)).long()","643348cb":"epochs = 20\nmodel.train()\nloss_values = []\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    y_pred = model(x_train)\n    loss = criterion(y_pred, y_train)\n    loss_values.append(loss.item())\n    pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n    acc = pred * 100.0 \/ len(x_train)\n    print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n    loss.backward()\n    optimizer.step()\n","92adf078":"plt.plot(loss_values)\nplt.title('Loss Value vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Loss'])\nplt.show()","cbced01c":"x_test = Variable(torch.from_numpy(x_test)).float()\ny_test = Variable(torch.from_numpy(y_test)).long()","cc240560":"model.eval()\nwith torch.no_grad():\n    y_pred = model(x_test)\n    loss = criterion(y_pred, y_test)\n    pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n    print (\"Accuracy : {}%\".format(100*pred\/len(x_test)))\n","8bb955cc":"# Creating a Spam and Not Spam Classifier with PyTorch","6539531f":"#### Let's Preprocess text data\n* We will remove non words, lower it, then Tokenize, Lemmatize and Vectorize and Remove Stopwords from the data","d787d376":"#### Changing lables for ease of understanding","6db8e98f":"> New to Pytorch Trying out stuff","c961623e":"# Testing","8a7cbb81":"## Preprocessing Data","0acdf9ea":"## Reading Data"}}