{"cell_type":{"17cf366f":"code","7ee066dc":"code","73d07ed3":"code","05bf9a2c":"code","a49987f9":"code","cd03a2a1":"code","d90d1bca":"code","ce41ef30":"code","1bfd3648":"code","020823da":"code","ae82e1e7":"code","1eecda2e":"code","cf5a92c8":"code","64f3230d":"code","00a16f7b":"code","cc133fcf":"code","a851633b":"code","077bb9b4":"code","84895d60":"code","e0ad4858":"code","4fe6daeb":"code","8442f60a":"code","0fc47baa":"code","cf166342":"code","62611d48":"code","ee926fc2":"code","4a799add":"code","9a54538d":"code","002c51fc":"code","6684fbda":"code","8b66e9b9":"code","d463dd84":"code","b6a0db32":"code","701234aa":"code","1d89f1d0":"code","0764cb22":"code","8da751aa":"code","7a0ed879":"code","7c530028":"code","3a550e68":"code","7f09e45f":"code","fcfde30c":"code","bbb72f3a":"code","c065c735":"code","f1e303c1":"code","56996d7f":"code","fb82da53":"code","ea772809":"code","a55760fe":"markdown","417a6dfd":"markdown","5c8a33a5":"markdown","7c4e5985":"markdown","0dd98865":"markdown","2746db12":"markdown","12c7660b":"markdown","272420cd":"markdown","fd05a88c":"markdown","25941153":"markdown","6a8b2f3a":"markdown","ec6df231":"markdown","c573103e":"markdown","f1d11fb9":"markdown","bb8e127a":"markdown"},"source":{"17cf366f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ee066dc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","73d07ed3":"df=pd.read_csv('\/kaggle\/input\/vehicle-dataset-from-cardekho\/Car details v3.csv')","05bf9a2c":"df.head()","a49987f9":"df.drop('name',axis=1,inplace=True)","cd03a2a1":"df.drop_duplicates(subset=None,keep='first',inplace=True)","d90d1bca":"df['Current year']=2021","ce41ef30":"years_driven=df['Current year']-df['year']","1bfd3648":"df['years_driven']=years_driven","020823da":"df.head()","ae82e1e7":"df.drop(['year','Current year'],axis=1,inplace=True)","1eecda2e":"df.isnull().sum()","cf5a92c8":"df.dropna(inplace=True)","64f3230d":"df.dtypes","00a16f7b":"df.mileage=df.mileage.str.replace(' kmpl','')","cc133fcf":"df.mileage=df.mileage.str.replace(' km\/kg','')","a851633b":"df.engine=df.engine.str.replace(' CC','')","077bb9b4":"df.max_power=df.max_power.str.replace(' bhp','')","84895d60":"df['torque']=df.torque.str.extract('(^\\d*)')","e0ad4858":"df.head()","4fe6daeb":"df['mileage']=df.mileage.astype(float)","8442f60a":"df['mileage']=df.mileage.astype(int)","0fc47baa":"df['engine']=df.engine.astype(int)","cf166342":"df['max_power']=df.max_power.astype(float)","62611d48":"df['max_power']=df.max_power.astype(int)","ee926fc2":"df['torque']=df.torque.astype(int)","4a799add":"df['seats']=df.seats.astype(int)","9a54538d":"df.dtypes","002c51fc":"sns.pairplot(df)","6684fbda":"gg=pd.get_dummies(df)","8b66e9b9":"gg.head()","d463dd84":"gg.columns","b6a0db32":"X=gg.drop('selling_price',axis=1)","701234aa":"y=gg['selling_price']","1d89f1d0":"from sklearn.model_selection import train_test_split","0764cb22":"X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=36)","8da751aa":"from sklearn.tree import DecisionTreeRegressor","7a0ed879":"dt=DecisionTreeRegressor()","7c530028":"dt.fit(X_train,y_train)","3a550e68":"dt.score(X_train,y_train)","7f09e45f":"dt.score(X_test,y_test)","fcfde30c":"y_predict=dt.predict(X_test)","bbb72f3a":"plt.figure(figsize=[10,8])\nplt.scatter(y_test,y_predict)\nplt.title('Comparision')\nplt.savefig('scatter.png')","c065c735":"from sklearn.metrics import mean_absolute_error,mean_squared_error,accuracy_score","f1e303c1":"mean_absolute_error(y_test,y_predict)","56996d7f":"mean_squared_error(y_test,y_predict)","fb82da53":"rmse=np.sqrt(mean_squared_error(y_test,y_predict))","ea772809":"rmse","a55760fe":"# Part-1 Data Preprocessing","417a6dfd":"Removing column name as it has too many unique values and high cardinality.","5c8a33a5":"# Part-3 evaluating model using different metrics","7c4e5985":"Dropping null values","0dd98865":"Fitting the modelon our data","2746db12":"# Part-2 Working on the model","12c7660b":"Loading the data","272420cd":"Visualising the data using a pairplot.","fd05a88c":"Dropping duplicate values","25941153":"Getting dummy variables for categorical values.","6a8b2f3a":"Adding a column years_driven","ec6df231":"Splitting the data into train and test parts","c573103e":"Importing required libraries","f1d11fb9":"Splitting the data into feature and target.","bb8e127a":"Converting datatypes of values so that we can use it later in the model."}}