{"cell_type":{"a1e6ec3b":"code","0e90bbc6":"code","2585367c":"code","5473bd04":"code","2bc29728":"code","4350bb63":"code","06b99ad7":"code","a953d428":"code","e8a019d9":"code","ae7ccdd2":"code","a23b69c2":"code","61004377":"code","2224e758":"code","fb2818b6":"code","e72e5cbb":"code","8345ac11":"code","ae37a8f4":"code","9838126a":"code","50c284d5":"code","d56036ae":"code","5c55714e":"code","aa90d560":"code","d330d11f":"code","451b9975":"code","168d9a7c":"code","6fb596da":"code","6c068d7c":"code","ef70c9b5":"code","67ee961f":"code","38fe4e85":"code","c8c9597a":"code","00c1b485":"code","b562246c":"markdown"},"source":{"a1e6ec3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e90bbc6":"image_path = '\/kaggle\/input\/vocdataset\/VOCdevkit\/VOC2012\/JPEGImages\/'","2585367c":"#len(os.listdir('\/kaggle\/working\/sketch-img'))","5473bd04":"os.mkdir('\/kaggle\/working\/real-img')","2bc29728":"os.mkdir('\/kaggle\/working\/sketch-img')","4350bb63":"os.mkdir('\/kaggle\/working\/real-img-test')\nos.mkdir('\/kaggle\/working\/sketch-img-test')\n","06b99ad7":"len(os.listdir('\/kaggle\/working\/real-img-test'))","a953d428":"def dodge(front,back):\n    result=front*255\/(255-back) \n    result[result>255]=255\n    result[back==255]=255\n    return result.astype('uint8')\nimport numpy as np\ndef grayscale(rgb):\n    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\n# img =\"girrafe.jpg\"\n\n\nimport imageio\nimport scipy.ndimage\n\nimport matplotlib.pyplot as plt\n\n# plt.imsave('imggirrafe1.jpg', r, cmap='gray', vmin=0, vmax=255)\ncount = 0\nfor images in os.listdir(image_path):\n    if count > 3000 and count < 4000:\n        img = str(image_path + '\/'+images)\n        s = imageio.imread(img)\n        g=grayscale(s)\n        i = 255-g\n        b = scipy.ndimage.filters.gaussian_filter(i,sigma=10)\n        r= dodge(b,g)\n        save_image = '\/kaggle\/working\/sketch-img-test\/img_'+ str(count)+'.jpeg'\n        plt.imsave(save_image, r, cmap='gray', vmin=0, vmax=255)\n    count += 1 \n    if count == 4000:\n        break","e8a019d9":"from PIL import Image\ncount = 0\nfor files in os.listdir(image_path):\n    if count > 3000 and count < 4000:\n        img = Image.open(image_path +'\/'+files)\n        path = '\/kaggle\/working\/real-img-test\/imgreal_'+str(count)+'.jpeg'\n        img.save(path)\n    count += 1\n    if count == 4000:\n        break","ae7ccdd2":"from PIL import Image\ncount = 0\nfor files in os.listdir(image_path):\n    img = Image.open(image_path +'\/'+files)\n    path = '\/kaggle\/working\/real-img\/imgreal_'+str(count)+'.jpeg'\n    img.save(path)\n    count += 1\n    if count == 3000:\n        break","a23b69c2":"def dodge(front,back):\n    result=front*255\/(255-back) \n    result[result>255]=255\n    result[back==255]=255\n    return result.astype('uint8')\nimport numpy as np\ndef grayscale(rgb):\n    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\n# img =\"girrafe.jpg\"\n\n\nimport imageio\nimport scipy.ndimage\n\nimport matplotlib.pyplot as plt\n\n# plt.imsave('imggirrafe1.jpg', r, cmap='gray', vmin=0, vmax=255)\ncount = 0\nfor images in os.listdir(image_path):\n    \n    img = str(image_path + '\/'+images)\n    s = imageio.imread(img)\n    g=grayscale(s)\n    i = 255-g\n    b = scipy.ndimage.filters.gaussian_filter(i,sigma=10)\n    r= dodge(b,g)\n    save_image = '\/kaggle\/working\/sketch-img\/img_'+ str(count)+'.jpeg'\n    plt.imsave(save_image, r, cmap='gray', vmin=0, vmax=255)\n    count += 1 \n    if count == 3000:\n        break","61004377":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.imshow(Image.open('\/kaggle\/working\/real-img\/imgreal_1500.jpeg'))","2224e758":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.imshow(Image.open('\/kaggle\/working\/sketch-img\/img_1500.jpeg'))","fb2818b6":"# def dodge(front,back):\n#     result=front*255\/(255-back) \n#     result[result>255]=255\n#     result[back==255]=255\n#     return result.astype('uint8')\n# import numpy as np\n# def grayscale(rgb):\n#     return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\n# # img =\"girrafe.jpg\"\n\n\n# import imageio\n# import scipy.ndimage\n\n# import matplotlib.pyplot as plt\n\n# # plt.imsave('imggirrafe1.jpg', r, cmap='gray', vmin=0, vmax=255)\n# count = 0\n# for images in os.listdir(image_path):\n#     img = str(image_path + '\/'+images)\n#     s = imageio.imread(img)\n#     g=grayscale(s)\n#     i = 255-g\n#     b = scipy.ndimage.filters.gaussian_filter(i,sigma=10)\n#     r= dodge(b,g)\n#     save_image = '\/kaggle\/working\/sketch-img\/img_'+ str(count)+'.jpg'\n#     count += 1\n#     plt.imsave(save_image, r, cmap='gray', vmin=0, vmax=255)\n#     if count == 3000:\n#         break","e72e5cbb":"loadEpochs = 10","8345ac11":" \nimport os\nimport tensorflow as tf\n\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\ntf.compat.v1.enable_eager_execution(config=config)\n\nimport numpy as np\nfrom tqdm import tqdm\n\n# edit by your path\n__SAVED_MODEL_PATH__ = \"\/kaggle\/working\/PaintsTensorFlowDraftModel\/\"\n","ae37a8f4":"os.mkdir('\/kaggle\/working\/PaintsTensorFlowDraftModel\/')","9838126a":"import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom glob import glob\n","50c284d5":"# hyperparame\n\n#  Do not mind\nbatch_steps = 0\n\n# for Model\ngf_dim = 64\ndf_dim = 64\nc_dim = 3\n\nlr = 1e-5\nbeta1 = 0.9\nbeta2 = 0.99\n\nl1_scaling = 100\nl2_scaling = 10\n\n# for Train\nepoch = 2\nbatch_size = 4\n\nlog_interval = 10\nsampling_interval = 200\nsave_interval = 4000\n\n# data & save Path\ntrain_image_datasets_path = \"\/kaggle\/working\/real-img\/\"\ntrain_line_datasets_path = \"\/kaggle\/working\/sketch-img\/\"\ntest_image_datasets_path = \"\/kaggle\/working\/real-img-test\/\"\ntest_line_datasets_path = \"\/kaggle\/working\/sketch-img-test\/\"","d56036ae":"#utils file\nimport numpy as np\nimport cv2\nimport os\n\n\ndef get_line(imgs):\n    def img_liner(img):\n        k = 3\n        kernal = np.ones((k, k), dtype=np.uint8)\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        dilated = cv2.dilate(gray, kernal, iterations=1)\n        diff = cv2.absdiff(dilated, gray)\n        img = 255 - diff\n        return img\n\n    lines = np.array([img_liner(l) for l in imgs])\n    return np.expand_dims(lines, 3)\n\n\ndef convert2f32(img):\n    img = img.astype(np.float32)\n    return (img \/ 127.5) - 1.0\n\n\ndef convert2uint8(img):\n    img = (img + 1) * 127.5\n    return img.astype(np.uint8)\n\n\ndef convertRGB(imgs):\n    imgs = np.asarray(imgs, np.uint8)\n    return np.array([cv2.cvtColor(img, cv2.COLOR_YUV2RGB) for img in imgs])\n\n\ndef mkdir(path):\n    try:\n        os.mkdir(path)\n    except FileExistsError:\n        pass\n\n\ndef initdir(model_name):\n    base = os.path.join(\"\/kaggle\/working\/\", model_name)\n    mkdir(base)\n    mkdir(os.path.join(base, \"board\"))\n    mkdir(os.path.join(base, \"image\"))","5c55714e":"#subnet.py\n__INITIALIZER__ = tf.random_normal_initializer(0., 0.02)\n__MOMENTUM__ = 0.9\n__EPSILON__ = 1e-5\n\n\ndef res_net_block_v2(inputs, filters):\n    with tf.name_scope(\"ResNetBlock\"):\n        shortcut = inputs\n        tensor = tf.keras.layers.BatchNormalization()(inputs)\n        tensor = tf.keras.layers.ReLU()(tensor)\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"SAME\")(tensor)\n\n        tensor = tf.keras.layers.BatchNormalization()(tensor)\n        tensor = tf.keras.layers.ReLU()(tensor)\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"SAME\")(tensor)\n        tensor = tf.keras.layers.add([shortcut, tensor])\n    return tensor\n\n\ndef GenConvBlock(inputs, filters, k, s, res_net_block=True, name=\"GenConvBlock\"):\n    filters = int(filters)\n    with tf.name_scope(name):\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=k, strides=s, use_bias=False,\n                                        padding=\"SAME\", kernel_initializer=__INITIALIZER__)(inputs)\n\n        if res_net_block:\n            tensor = res_net_block_v2(tensor, filters)\n        else:\n            tensor = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)(tensor)\n            tensor = tf.keras.layers.LeakyReLU()(tensor)\n\n        return tensor\n\n\ndef GenUpConvBlock(inputs_a, inputs_b, filters, k, s, res_net_block=True, name=\"GenUpConvBlock\"):\n    filters = int(filters)\n    with tf.name_scope(name):\n        tensor = tf.keras.layers.Concatenate(3)([inputs_a, inputs_b])\n        tensor = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=k, strides=s, use_bias=False,\n                                                 padding=\"SAME\", kernel_initializer=__INITIALIZER__)(tensor)\n\n        if res_net_block:\n            tensor = res_net_block_v2(tensor, filters)\n        else:\n            tensor = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)(tensor)\n            tensor = tf.keras.layers.ReLU()(tensor)\n\n        return tensor\n\n\nclass DisConvBlock(tf.keras.Model):\n    def __init__(self, filters, k, s, apply_bat_norm=True, name=None):\n        super(DisConvBlock, self).__init__(name=name)\n        initializer = tf.random_normal_initializer(0., 0.02)\n        filters = int(filters)\n        self.apply_bat_norm = apply_bat_norm\n        self.conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=k, strides=s,\n                                           padding=\"SAME\", kernel_initializer=initializer)\n        if self.apply_bat_norm:\n            self.bn = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)\n\n        self.act = tf.keras.layers.LeakyReLU(alpha=0.2)\n\n    def call(self, inputs, training):\n        tensor = self.conv(inputs)\n\n        if self.apply_bat_norm:\n            tensor = self.bn(tensor, training=training)\n\n        tensor = self.act(tensor)\n        return tensor\n\n\ndef tf_int_round(num):\n    return tf.cast(tf.round(num), dtype=tf.int32)\n\n\nclass resize_layer(tf.keras.layers.Layer):\n    def __init__(self, size=(512, 512), **kwargs, ):\n        super(resize_layer, self).__init__(**kwargs)\n        (self.height, self.width) = size\n\n    def build(self, input_shape):\n        super(resize_layer, self).build(input_shape)\n\n    def call(self, x, method=\"nearest\"):\n        height = 512\n        width = 512\n\n        if method == \"nearest\":\n            return tf.image.resize_nearest_neighbor(x, size=(height, width))\n        elif method == \"bicubic\":\n            return tf.image.resize_bicubic(x, size=(height, width))\n        elif method == \"bilinear\":\n            return tf.image.resize_bilinear(x, size=(height, width))\n\n    def get_output_shape_for(self, input_shape):\n        return (self.input_shape[0], 512, 512, 3)","aa90d560":"#paintstensorflow.py\ndef Generator(inputs_size=None, res_net_block=True, name=\"PaintsTensorFlow\"):\n    inputs_line = tf.keras.Input(shape=[inputs_size, inputs_size, 1], dtype=tf.float32, name=\"inputs_line\")\n    inputs_hint = tf.keras.Input(shape=[inputs_size, inputs_size, 3], dtype=tf.float32, name=\"inputs_hint\")\n    tensor = tf.keras.layers.Concatenate(3)([inputs_line, inputs_hint])\n\n    e0 = GenConvBlock(tensor,gf_dim \/ 2, 3, 1, res_net_block=res_net_block, name=\"E0\")  # 64\n    e1 = GenConvBlock(e0, gf_dim * 1, 4, 2, res_net_block=res_net_block, name=\"E1\")\n    e2 = GenConvBlock(e1, gf_dim * 1, 3, 1, res_net_block=res_net_block, name=\"E2\")\n    e3 = GenConvBlock(e2, gf_dim * 2, 4, 2, res_net_block=res_net_block, name=\"E3\")\n    e4 = GenConvBlock(e3, gf_dim * 2, 3, 1, res_net_block=res_net_block, name=\"E4\")\n    e5 = GenConvBlock(e4, gf_dim * 4, 4, 2, res_net_block=res_net_block, name=\"E5\")\n    e6 = GenConvBlock(e5, gf_dim * 4, 3, 1, res_net_block=res_net_block, name=\"E6\")\n    e7 = GenConvBlock(e6, gf_dim * 8, 4, 2, res_net_block=res_net_block, name=\"E7\")\n    e8 = GenConvBlock(e7, gf_dim * 8, 3, 1, res_net_block=res_net_block, name=\"E8\")\n\n    d8 = GenUpConvBlock(e7, e8, gf_dim * 8, 4, 2, res_net_block=res_net_block, name=\"D8\")\n    d7 = GenConvBlock(d8, gf_dim * 4, 3, 1, res_net_block=res_net_block, name=\"D7\")\n    d6 = GenUpConvBlock(e6, d7, gf_dim * 4, 4, 2, res_net_block=res_net_block, name=\"D6\")\n    d5 = GenConvBlock(d6, gf_dim * 2, 3, 1, res_net_block=res_net_block, name=\"D5\")\n    d4 = GenUpConvBlock(e4, d5, gf_dim * 2, 4, 2, res_net_block=res_net_block, name=\"D4\")\n    d3 = GenConvBlock(d4, gf_dim * 1, 3, 1, res_net_block=res_net_block, name=\"D3\")\n    d2 = GenUpConvBlock(e2, d3, gf_dim * 1, 4, 2, res_net_block=res_net_block, name=\"D2\")\n    d1 = GenConvBlock(d2, gf_dim \/ 2, 3, 1, res_net_block=res_net_block, name=\"D1\")\n\n    tensor = tf.keras.layers.Concatenate(3)([e0, d1])\n    outputs = tf.keras.layers.Conv2D(c_dim, kernel_size=3, strides=1, padding=\"SAME\",\n                                     use_bias=True, name=\"output\", activation=tf.nn.tanh,\n                                     kernel_initializer=tf.random_normal_initializer(0., 0.02))(tensor)\n\n    inputs = [inputs_line, inputs_hint]\n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n    return model\n\nclass Discriminator(tf.keras.Model):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.h0 = DisConvBlock(df_dim \/ 2, 4, 2)\n        self.h1 = DisConvBlock(df_dim \/ 2, 3, 1)\n        self.h2 = DisConvBlock(df_dim * 1, 4, 2)\n        self.h3 = DisConvBlock(df_dim * 1, 3, 1)\n        self.h4 = DisConvBlock(df_dim * 2, 4, 2)\n        self.h5 = DisConvBlock(df_dim * 2, 3, 1)\n        self.h6 = DisConvBlock(df_dim * 4, 4, 2)\n        self.flatten = tf.keras.layers.Flatten()\n        self.last = tf.keras.layers.Dense(1, activation=\"linear\", kernel_initializer=tf.initializers.he_normal())\n\n#     @tf.contrib.eager.defun\n    def call(self, inputs, training):\n        tensor = self.h0(inputs, training)\n        tensor = self.h1(tensor, training)\n        tensor = self.h2(tensor, training)\n        tensor = self.h3(tensor, training)\n        tensor = self.h4(tensor, training)\n        tensor = self.h5(tensor, training)\n        tensor = self.h6(tensor, training)\n        tensor = self.flatten(tensor)  # (?,16384)\n        tensor = self.last(tensor)\n        return tensor","d330d11f":"\nimport glob\nclass Datasets:\n    def __init__(self, prefetch=-1, batch_size=1, shuffle=False):\n        self.prefetch = prefetch\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n\n    def _preprocess(self, image, line, training):\n        if training:\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 0)\n                line = cv2.flip(line, 0)\n                line = np.expand_dims(line, 3)\n\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 1)\n                line = cv2.flip(line, 1)\n                line = np.expand_dims(line, 3)\n\n        return image, line, self._buildHint_resize(image)\n\n    def _buildHint_resize(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 120)\n\n        if random() < 0.4:\n            leak_count = 0\n        elif random() < 0.7:\n            leak_count = np.random.randint(2, 16)\n\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n\n        for i in range(leak_count):\n            paintCel(i)\n\n        return hint\n\n    def convert2float(self, image):\n        image = tf.cast(image, tf.float32)\n        image = (image \/ 127.5) - 1\n        return image\n\n    def __line_threshold(self, line):\n        if np.random.rand() < 0.3:\n            line = np.reshape(line, newshape=(512, 512))\n            _, line = cv2.threshold(line, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            line = np.reshape(line, newshape=(512, 512, 1))\n        return line\n\n    def loadImage(self, imagePath, linePath, train):\n        print(imagePath)\n        image = tf.io.read_file(str(imagePath))\n        image = tf.image.decode_jpeg(image, channels=3)\n\n        line = tf.io.read_file(str(linePath))\n        line = tf.image.decode_jpeg(line, channels=1)\n\n        image = tf.compat.v1.image.resize(image, (128, 128), method=3)\n        line = tf.compat.v1.image.resize(line, (128, 128), method=3)\n\n        image = self.convert2float(image)\n        line = self.convert2float(line)\n\n        image, line, hint = tf.compat.v1.py_func(self._preprocess,\n                                       [image, line, train],\n                                       [tf.float32, tf.float32, tf.float32])\n\n        return image, line, hint\n\n    def buildDataSets(self):\n        def build_dataSets(image, line, shuffle=False, isTrain=False):\n            image = glob.glob(image+\"*.jpg\")\n            image.sort()\n            line = glob.glob(line + \"*.jpg\")\n            line.sort()\n\n            if shuffle is False and isTrain is False:\n                image.reverse()\n                line.reverse()\n\n            batch_steps = int(len(line) \/ self.batch_size)\n            datasets = tf.data.Dataset.from_tensor_slices((image, line))\n            print(datasets)\n            datasets = datasets.map(lambda x, y: self.loadImage(x, y, isTrain))\n            datasets = datasets.batch(self.batch_size)\n\n            if shuffle:\n                datasets = datasets.shuffle(100)\n\n            return datasets\n\n        testDatasets = build_dataSets(test_image_datasets_path,\n                                      test_line_datasets_path,\n                                      shuffle=False, isTrain=False)\n\n        trainDatasets = build_dataSets(train_image_datasets_path,\n                                       train_line_datasets_path,\n                                       shuffle=self.shuffle, isTrain=True)\n\n        return trainDatasets, testDatasets\n","451b9975":"class Datasets_512(Datasets):\n    def __init__(self ,batch_size):\n        self.batch_size = batch_size\n        super().__init__(self, batch_size = self.batch_size)\n    def _flip(self, image, line, training):\n        if training:\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 0)\n                line = cv2.flip(line, 0)\n                line = np.expand_dims(line, 3)\n\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 1)\n                line = cv2.flip(line, 1)\n                line = np.expand_dims(line, 3)\n\n        return image, line\n\n    def _buildHint(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 128)\n\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n\n        for i in range(leak_count):\n            paintCel(i)\n        return hint\n\n    def loadImage(self, imagePath, linePath, train):\n        image = tf.io.read_file(imagePath)\n        image = tf.image.decode_jpeg(image, channels=3)\n        line = tf.io.read_file(linePath)\n        line = tf.image.decode_jpeg(line, channels=1)\n\n        image_128 = tf.image.resize(image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        line_128 = tf.image.resize(line, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        image = self.convert2float(image)\n        line = self.convert2float(line)\n        image_128 = self.convert2float(image_128)\n        line_128 = self.convert2float(line_128)\n\n        hint_128 = tf.py_function(self._buildHint,\n                                  [image_128],\n                                  tf.float32)\n\n        hint_128.set_shape(shape=image_128.shape)\n        hint = tf.image.resize(hint_128, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        return line_128, hint_128, image, line, hint","168d9a7c":"!pip3 install tensorlayer\n","6fb596da":"# import os\n# import tensorflow as tf\n\n# config = tf.compat.v1.ConfigProto()\n# config.gpu_options.allow_growth = True\n# tf.compat.v1.enable_eager_execution(config=config)\nimport tensorlayer as tl\nimport numpy as np\nfrom tqdm import tqdm\n#from dataset.Datasets import Datasets\n#from model.PaintsTensorFlow import Generator, Discriminator\n#import utils\n#import hyperparameter as hp\n\n\nclass PaintsTensorFlowDraftModelTrain:\n    def __init__(self, model_name=\"PaintsTensorFlowDraftModel\"):\n        self.data_sets = Datasets(batch_size=batch_size)\n        self.model_name = model_name\n        initdir(self.model_name)\n\n        self.global_steps = tf.compat.v1.train.get_or_create_global_step()\n        self.epochs = tf.Variable(0, trainable=False, dtype=tf.int32)\n\n        self.generator_optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2)\n        self.discriminator_optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2)\n        self.ckptPath = \".\/ckpt\/{}\/\".format(self.model_name) + \"ckpt_E:{}\"\n        self.ckptPrefix = os.path.join(self.ckptPath, \"model_GS:{}\")\n\n        self.generator = Generator(name=\"PaintsTensorFlowDraftNet\")\n        self.discriminator = Discriminator()\n\n        self.logWriter = tf.summary.create_file_writer(\".\/ckpt\/{}\/board\/log\".format(self.model_name))\n        self.logWriter.set_as_default()\n\n        self.check_point = tf.train.Checkpoint(generator=self.generator,\n                                               genOptimizer=self.generator_optimizer,\n                                               disOptimizer=self.discriminator_optimizer,\n                                               discriminator=self.discriminator,\n                                               globalSteps=self.global_steps,\n                                               epochs=self.epochs)\n\n\n    def __discriminator_loss(self, real, fake):\n        SCE = tf.losses.sigmoid_cross_entropy\n        self.real_loss = SCE(multi_class_labels=tf.ones_like(real), logits=real)\n        self.fake_loss = SCE(multi_class_labels=tf.zeros_like(fake), logits=fake)\n        loss = self.real_loss + self.fake_loss\n        return loss\n\n    def __generator_loss(self, disOutput, output, target):\n        SCE = tf.losses.sigmoid_cross_entropy\n        self.gan_loss = SCE(multi_class_labels=tf.ones_like(disOutput), logits=disOutput)\n        self.image_loss = tf.reduce_mean(tf.abs(target - output)) * hp.l1_scaling\n        loss = self.image_loss + self.gan_loss\n        return loss\n\n    def __pred_image(self, model, image, line, hint, epoch=None):\n        global_steps = self.global_steps.numpy()\n        pred_image = model.predict([line, hint])\n\n        zero_hint = tf.ones_like(hint)\n        zero_hint += 1\n        pred_image_zero = model.predict([line, zero_hint])\n\n        dis_fake = self.discriminator(pred_image, training=False)\n        loss = self.__generator_loss(dis_fake, pred_image, image)\n\n        self.__loging(\"Sample_LOSS\", loss)\n        loss = \"{:0.05f}\".format(loss).zfill(7)\n        print(\"Epoch:{} GS:{} LOSS:{}\".format(epoch, global_steps, loss))\n        file_name = \".\/ckpt\/{}\/image\/{}_loss:{}.jpg\".format(self.model_name, global_steps, loss)\n\n        hint = np.array(hint)\n        hint[hint > 1] = 1\n\n        line_image = np.concatenate([line, line, line], -1)\n        save_img = np.concatenate([line_image, hint, pred_image_zero, pred_image, image], 1)\n        save_img = utils.convert2uint8(save_img)\n        tl.visualize.save_images(save_img, [1, save_img.shape[0]], file_name)\n\n    def __loging(self, name, scalar):\n        with tf.contrib.summary.always_record_summaries():\n            tf.contrib.summary.scalar(name, scalar)\n\n    def __check_point_save(self):\n        file_prefix = self.ckptPrefix.format(self.epochs.numpy(), self.global_steps.numpy())\n        self.check_point.save(file_prefix=file_prefix)\n\n    def training(self, loadEpochs=0):\n        train_sets, test_sets = self.data_sets.buildDataSets()\n        log = self.__loging\n\n        self.check_point.restore(tf.train.latest_checkpoint(self.ckptPath.format(loadEpochs)))\n\n        for epochs in range(epoch):\n            print(\"GS: \", self.global_steps.numpy(), \"Epochs:  \", self.epochs.numpy())\n\n            for image, line, hint in tqdm(train_sets, total=batch_steps):\n                # get loss\n                with tf.GradientTape() as genTape, tf.GradientTape() as discTape:\n\n                    pred_image = self.generator(inputs=[line, hint], training=True)\n\n                    dis_real = self.discriminator(inputs=image, training=True)\n                    dis_fake = self.discriminator(inputs=pred_image, training=True)\n\n                    generator_loss = self.__generator_loss(dis_fake, pred_image, image)\n                    discriminator_loss = self.__discriminator_loss(dis_real, dis_fake)\n\n                # Gradients\n                discriminator_gradients = discTape.gradient(discriminator_loss, self.discriminator.variables)\n                generator_gradients = genTape.gradient(generator_loss, self.generator.variables)\n\n                self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.variables))\n                self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.variables),\n                                                         global_step=self.global_steps)\n                gs = self.global_steps.numpy()\n\n                if gs % hp.log_interval == 0:\n                    log(\"LOSS_G\", generator_loss)\n                    log(\"LOSS_G_Image\", self.image_loss)\n                    log(\"LOSS_G_GAN\", self.gan_loss)\n                    log(\"LOSS_D\", discriminator_loss)\n                    log(\"LOSS_D_Real\", self.real_loss)\n                    log(\"LOSS_D_Fake\", self.fake_loss)\n\n                    if gs % hp.sampling_interval == 0:\n                        for image, line, hint in test_sets.take(1):\n                            self.__pred_image(self.generator, image, line, hint, self.epochs.numpy())\n\n                    if gs % hp.save_interval == 0:\n                        self.__check_point_save()\n                        print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\"\n                              .format(self.epochs.numpy(), gs))\n            self.epochs = self.epochs + 1\n\n        self.generator.summary()\n        save_path = \".\/ckpt\/\" + self.model_name + \"\/{}.h5\".format(self.generator.name)\n        self.generator.save(save_path, include_optimizer=False)  # for keras Model\n        save_path = tf.keras.models.save_model(self.generator, \".\/saved_model\")  # saved_model\n        print(\"saved_model path = {}\".format(save_path))\n\n        print(\"------------------------------Training Done-------------------------------------\")\n","6c068d7c":"class PaintsTensorFlowTrain:\n    def __init__(self, model_name=\"PaintsTensorFlow\"):\n        self.data_sets = Datasets_512(batch_size=batch_size)\n        self.model_name = \"{}\".format(model_name)\n        initdir(self.model_name)\n\n        self.global_steps = tf.compat.v1.train.get_or_create_global_step()\n        self.epochs = tf.Variable(0, trainable=False, dtype=tf.int32)\n        self.ckpt_path = \".\/ckpt\/{}\/\".format(self.model_name) + \"ckpt_E:{}\"\n        self.ckpt_prefix = os.path.join(self.ckpt_path, \"model_GS:{}\")\n\n#         self.generator_128 =  tf.keras.models.load_model(__SAVED_MODEL_PATH__)\n        self.generator_512 = Generator(res_net_block=False)\n        self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n\n        self.check_point = tf.train.Checkpoint(generator_512=self.generator_512,\n                                               optimizer=self.optimizer,\n                                               globalSteps=self.global_steps,\n                                               epochs=self.epochs)\n\n    def __loging(self, name, scalar):\n        with tf.contrib.summary.always_record_summaries():\n            tf.contrib.summary.scalar(name, scalar)\n\n    def __loss(self, output, target):\n        loss = tf.reduce_mean(tf.abs(target - output))\n        return loss\n\n    def __pred_image(self, model, image, line, hint, draft, epoch=None):\n        gs = self.global_steps.numpy()\n        predImage = model.predict([line, draft])\n        file_name = \".\/ckpt\/{}\/image\/{}.jpg\".format(self.model_name, gs)\n\n        if epoch is not None:\n            loss = self.__loss(predImage, image)\n            self.__loging(\"Sample_LOSS\", loss)\n            loss = \"{:0.05f}\".format(loss).zfill(7)\n            print(\"Epoch:{} GS:{} LOSS:{}\".format(epoch, self.global_steps.numpy(), loss))\n            file_name = \".\/ckpt\/{}\/image\/{}_loss:{}.jpg\".format(self.model_name, gs, loss)\n\n        hint = np.array(hint)\n        hint[hint > 1] = 1\n\n        lineImage = np.concatenate([line, line, line], -1)\n        save_img = np.concatenate([lineImage, hint, draft, predImage, image], 1)\n        save_img = utils.convert2uint8(save_img)\n        tl.visualize.save_images(save_img, [1, save_img.shape[0]], file_name)\n\n    def __draft_image(self, line_128, hint_128):\n        draft = self.generator_128.predict([line_128, hint_128])\n        draft = tf.image.resize(draft, size=(512, 512),\n                                       method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        return draft\n\n    def training(self, loadEpochs=0):\n        train_sets, test_sets = self.data_sets.buildDataSets()\n        print (train_sets, test_sets)\n        log = self.__loging\n\n        self.check_point.restore(tf.train.latest_checkpoint(self.ckpt_path.format(loadEpochs)))\n\n        if self.global_steps.numpy() == 0:\n            self.check_point.save(file_prefix=self.ckpt_prefix.format(0, 0))\n            print(\"------------------------------SAVE_INIT-------------------------------------\")\n\n        for epochss in range(epoch):\n            print(\"GS: \", self.global_steps.numpy())\n\n            for line_128, hint_128, image, line, hint in tqdm(train_sets, total=batch_steps):\n                draft = self.__draft_image(line_128, hint_128)\n\n                with tf.GradientTape() as tape:\n                    genOut = self.generator_512(inputs=[line, draft], training=True)\n                    loss = self.__loss(genOut, image)\n\n                # Training\n                gradients = tape.gradient(loss, self.generator_512.variables)\n                self.optimizer.apply_gradients(zip(gradients, self.generator_512.variables),\n                                               global_step=self.global_steps)\n                # Loging\n                gs = self.global_steps.numpy()\n                if gs % log_interval == 0:\n                    log(\"LOSS\", loss)\n                    if gs % sampling_interval == 0:\n                        # test image Save\n                        for line_128, hint_128, image, line, hint in test_sets.take(1):\n                            draft = self.__draft_image(line_128, hint_128)\n                            self.__pred_image(self.generator_512, image, line, hint, draft, self.epochs.numpy())\n\n                    if gs % save_interval == 0:\n                        self.check_point.save(file_prefix=self.ckpt_prefix.format(self.epochs.numpy(), gs))\n                        print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\"\n                              .format(self.epochs.numpy(), gs))\n\n            self.check_point.save(file_prefix=self.ckpt_prefix.format(self.epochs.numpy(), self.global_steps.numpy()))\n            self.epochs = self.epochs + 1\n\n        for line_128, hint_128, image, line, hint in test_sets.take(1):\n            hint = hint.numpy()\n            draft = self.__draft_image(line_128, hint_128)\n            self.__pred_image(self.generator_512, image, line, hint, draft, self.epochs.numpy())\n\n        self.generator_512.summary()\n        print(self.global_steps)\n\n        save_path = \"\/kaggle\/working\/model-save\" + self.model_name + \"\/{}.h5\".format(self.generator_512.name)\n        self.generator_512.save(save_path, include_optimizer=False)  # for keras Model\n        save_path = tf.keras.models.save_model(self.generator_512, save_path)  # saved_model\n        print(\"saved_model path = {}\".format(save_path))\n        print(\"------------------------------Training Done-------------------------------------\")","ef70c9b5":"os.mkdir('\/kaggle\/working\/model-save\/')","67ee961f":"model =PaintsTensorFlowDraftModelTrain()","38fe4e85":"model.training(loadEpochs=loadEpochs)","c8c9597a":"model1 = PaintsTensorFlowTrain()","00c1b485":"model1.training(loadEpochs=loadEpochs)","b562246c":"**converting color image to sketch**"}}