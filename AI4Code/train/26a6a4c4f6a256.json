{"cell_type":{"dcb9b484":"code","6eea26fb":"code","e9f40334":"code","f4273793":"code","6c0ed202":"code","44ec34ad":"code","ac7d1f2e":"code","00e437dd":"code","183597a0":"code","54d81540":"code","0ea6fbb8":"code","05ad2268":"code","ca64b34d":"code","68418349":"code","b892f5a2":"code","2380ead6":"code","554178df":"code","a86522bb":"code","3e217509":"code","d4e3c8d5":"code","919f9e4b":"code","30702d14":"code","7c25534a":"code","d634d891":"code","0185a08c":"code","91309b48":"code","cbfd00e0":"code","e2942712":"code","c6381e00":"code","8ac8b4be":"code","10d0c8c8":"code","87e42de2":"code","8b31ee9a":"code","73684efc":"code","04dce6b6":"code","6d68f6fb":"code","32205c3a":"code","77692a4f":"code","deb463a7":"code","62c2b8d9":"code","c6ed4620":"markdown","6cc6de13":"markdown","6bb7b484":"markdown","50da8eef":"markdown","8ca8d8d8":"markdown","35f077d5":"markdown","a4b4d1d1":"markdown","fa9d28f9":"markdown","37b84d37":"markdown","bd65dde4":"markdown","1dc6fd19":"markdown","24dfad8e":"markdown","1765af56":"markdown","13276912":"markdown","0ce37335":"markdown","6741fe91":"markdown","5e4a6bde":"markdown","b6092d8a":"markdown"},"source":{"dcb9b484":"import numpy as np\nimport pandas as pd\nfrom skimage.io import imread,imshow,imsave\nimport matplotlib.pyplot as plt\nimport random\nimport seaborn as sns","6eea26fb":"dir_path = \"..\/input\/shopee-product-matching\/\"\ntrain_dir = dir_path+'train_images\/'\ntest_dir = dir_path+'test_images'","e9f40334":"train_df = pd.read_csv(dir_path+'train.csv')","f4273793":"train_df.head()","6c0ed202":"train_df.shape","44ec34ad":"#loading all the images from the training dataset is leading to memory overflow","ac7d1f2e":"print(\"unique label groups = \",train_df.label_group.nunique())","00e437dd":"label_group_list = random.sample(list(train_df.label_group),5)","183597a0":"label_group_list","54d81540":"fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(20,20))\nfor i,lg in enumerate(label_group_list):\n    image_names = train_df[train_df.label_group == lg]['image']\n    print(\"label_group = \",lg,\"number of images = \",len(image_names))\n    for j,img_name in enumerate(image_names):\n        if(j>=5): \n            break\n        img = plt.imread(train_dir+img_name)\n        ax[i,j].imshow(img)","0ea6fbb8":"train_df['image_phash'].value_counts()","05ad2268":"#feting images with the same phash value\nphash_list = train_df['image_phash'].value_counts()[:5].index","ca64b34d":"phash_list","68418349":"fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(20,20))\nfor i,val in enumerate(phash_list):\n    image_names = train_df[train_df.image_phash == val]['image']\n    print(val,len(image_names))\n    for j,img_name in enumerate(image_names):\n        if(j>=5): \n            break\n        img = plt.imread(train_dir+img_name)\n        ax[i,j].imshow(img)","b892f5a2":"label_group_list","2380ead6":"def hammingDistance(str1, str2) : \n    n1 = int(str1,16)\n    n2 = int(str2,16)\n  \n    x = n1 ^ n2  \n    setBits = 0\n  \n    while (x > 0) : \n        setBits += x & 1\n        x >>= 1\n      \n    return setBits ","554178df":"df = train_df[train_df['label_group'] == 4159286058][['image_phash','image']]\nphash_values = df['image_phash'].values\nimage_name = df['image'].values","a86522bb":"# Finding difference of all hashing values\nfig, ax = plt.subplots(nrows=3,ncols=2,figsize=(20,20))\nk = 0\nfor i in range(len(phash_values)):\n    for j in range(i+1,len(phash_values)):\n        img1 = plt.imread(train_dir+image_name[i])\n        img2 = plt.imread(train_dir+image_name[j])\n        ax[k,0].imshow(img1)\n        ax[k,1].imshow(img2)\n        k = k+1\n        print(\"phash 1 - \",phash_values[i],\n              \"phash 2 - \",phash_values[j],\n              \"hamming distance - \",hammingDistance(phash_values[i],phash_values[j]))","3e217509":"label_group_list = random.sample(list(train_df.label_group),100)  #taking 100 random label_group","d4e3c8d5":"min_hamming_list = []\nmax_hamming_list = []\nfor lg in label_group_list:\n    phash_values = train_df[train_df['label_group'] == lg]['image_phash'].values\n    min_hamming_value = 65\n    max_hamming_value = -1\n    for p1 in range(len(phash_values)):\n        for p2 in range(p1+1,len(phash_values)):\n            hd = hammingDistance(phash_values[p1],phash_values[p2])\n            min_hamming_value = min(min_hamming_value,hd)\n            max_hamming_value = max(max_hamming_value,hd)\n    min_hamming_list.append(min_hamming_value)\n    max_hamming_list.append(max_hamming_value)\n            ","919f9e4b":"hamming_df = pd.DataFrame({'maximum Hamming Distance':max_hamming_list,\n              'minimum Hamming Distance':min_hamming_list})","30702d14":"sns.boxplot(y=\"maximum Hamming Distance\",data=hamming_df)","7c25534a":"sns.boxplot(y=\"minimum Hamming Distance\",data=hamming_df)","d634d891":"!pip install sentence-transformers","0185a08c":"from sentence_transformers import SentenceTransformer\nsbert_model = SentenceTransformer('bert-base-nli-mean-tokens')","91309b48":"label_group_list = random.sample(list(train_df.label_group),100)  #taking 100 random label_group","cbfd00e0":"title_df = train_df[train_df['label_group'].isin(label_group_list)][['label_group','title']]\ntitle_df.reset_index(drop=True,inplace=True)","e2942712":"title_df.head()","c6381e00":"sentence_embeddings = sbert_model.encode(title_df.title.values)","8ac8b4be":"print('BERT embedding vector - length', len(sentence_embeddings[0]))","10d0c8c8":"title_df['embeddings'] = title_df.index.map(mapper=(lambda i:sentence_embeddings[i]))","87e42de2":"title_df.head()","8b31ee9a":"lg = random.choice(label_group_list)","73684efc":"#checking cosine similarity within a label group\nsample_df = title_df[title_df.label_group == lg][['title','embeddings']]\nembedding_vectors = sample_df['embeddings'].values\ntitles = sample_df['title'].values","04dce6b6":"from scipy.spatial.distance import cosine","6d68f6fb":"for i in range(len(embedding_vectors)):\n    for j in range(i+1,len(embedding_vectors)):\n        print(\"cosine similaity between \",titles[i],\" and \\n\",titles[j],\" = \",\n              cosine(embedding_vectors[i], embedding_vectors[j]))\n        print(\"\\n\")","32205c3a":"min_sim_list = []\nmax_sim_list = []\nfor lg in label_group_list:\n    sample_df = title_df[title_df.label_group == lg][['title','embeddings']]\n    embedding_vectors = sample_df['embeddings'].values\n    titles = sample_df['title'].values\n    min_sim_value = 2\n    max_sim_value = -1\n    for i in range(len(embedding_vectors)):\n        for j in range(i+1,len(embedding_vectors)):\n            cosine_sim_val = cosine(embedding_vectors[i], embedding_vectors[j])\n            min_sim_value = min(min_sim_value,cosine_sim_val)\n            max_sim_value = max(max_sim_value,cosine_sim_val)\n    min_sim_list.append(min_sim_value)\n    max_sim_list.append(max_sim_value)\n            ","77692a4f":"similarity_df = pd.DataFrame({'maximum cosine similarity':max_sim_list,\n              'minimum cosine similarity':min_sim_list})","deb463a7":"sns.boxplot(y=\"maximum cosine similarity\",data=similarity_df)","62c2b8d9":"sns.boxplot(y=\"minimum cosine similarity\",data=similarity_df)","c6ed4620":"**viewing pictures related to same label group**","6cc6de13":"## Exploring phash column ","6bb7b484":"**Images whose phash values are same, are exactly similar**","50da8eef":"![image.png](attachment:image.png)","8ca8d8d8":"**We see that for similar images, hamming distance of phash values are close.**","35f077d5":"**Finding Minimum and Maximum Cosine Similarities within Label Groups**","a4b4d1d1":"**Hamming Distance of phash values could be an importance Feature in grouping Images.**","fa9d28f9":"### **Stay tuned for more!**","37b84d37":"**Cosine Similarity Between titles of images can be used for image grouping**","bd65dde4":"# <h1 align=\"center\" style=\"font-family:verdana;\"> \u2b06\ufe0f\u2b06\ufe0f\u2b06\ufe0f If you find this note book helpful. <b>please upvote!<\/b> \u2b06\ufe0f\u2b06\ufe0f\u2b06\ufe0f <\/h1>","1dc6fd19":"## Problem Statement","24dfad8e":"## Exploring title column ","1765af56":"Let us find minimum and maximum values of hamming distance in a Label group.","13276912":"Finding near-duplicates in large datasets is an important problem for many online businesses. In Shopee's case, everyday users can upload their own images and write their own product descriptions, adding an extra layer of challenge. Your task is to identify which products have been posted repeatedly. The differences between related products may be subtle while photos of identical products may be wildly different!","0ce37335":"[Competition Link](https:\/\/www.kaggle.com\/c\/shopee-product-matching)","6741fe91":"**After checking multiple images, I saw that images with hamming distance <= 32 are very similar**","5e4a6bde":"## Exploring label_group column","b6092d8a":"Let us take few images with same label_group and find the hamming distance of the phash values"}}