{"cell_type":{"dbee0b89":"code","c9ad38a1":"code","55944144":"code","09050300":"code","3faa7ef1":"code","a063fd5d":"code","11751150":"code","31a136cc":"code","7693baba":"code","07ca6846":"code","347b38e6":"code","810065a4":"code","787b664a":"code","b34b08d7":"code","11b40448":"code","e5518506":"code","03c050c2":"code","186dd31c":"code","20418875":"code","b2a638b5":"code","44faf42c":"code","022870d1":"code","aafa9cad":"code","642adecd":"code","2c84556c":"code","f447a166":"code","8707867e":"code","1bf1acab":"code","8d78d3be":"code","327cca03":"code","bce4c7bf":"code","3a2a941d":"code","d1e89b29":"code","90f9ef57":"code","740be5e4":"code","eb5ed3be":"code","cd4c2d1e":"code","0239a6ce":"code","1816b3e6":"code","ce46e558":"code","b62d5b9e":"code","fbf2c106":"code","0bfd5bc4":"code","9add14a6":"code","52faf46f":"code","4c4afa56":"code","420143fa":"code","1e958224":"code","7f5eea2d":"code","17b25112":"code","39c53375":"code","d94d0db2":"code","1c40fe61":"code","a340041f":"code","d9c2bf48":"code","22ceb05a":"code","34610d05":"code","eee1817d":"code","505df042":"code","d70cb60c":"code","f223adbb":"code","65e7e7dd":"code","2543ee3c":"code","75752158":"code","299ec972":"code","3ae3565a":"code","1a7dac98":"code","cf614aa3":"code","5473d4f5":"code","4320e150":"code","0ffae6d8":"code","9885e853":"code","df648511":"code","6566c1f2":"code","0bf0513e":"code","5d092b28":"code","3673f86f":"code","2e0cd73a":"code","5ebf9d03":"code","777fc31c":"code","9afde2da":"code","05a5588f":"code","52639559":"code","907d6590":"code","91fac4f4":"code","bbdc0c80":"markdown","a6409a92":"markdown","5407f41a":"markdown","7c8b9e53":"markdown","c5197ea4":"markdown","a67dd21b":"markdown","6fd816cd":"markdown","1efd7fd9":"markdown","440857b6":"markdown","4da013d6":"markdown","dc3d817f":"markdown","4d4e963c":"markdown","b8c37ef7":"markdown","1f25060f":"markdown","8e10e972":"markdown","c8f36dd8":"markdown","80868c42":"markdown","7294eacb":"markdown","b174217f":"markdown","a164e71c":"markdown","14db72db":"markdown","44e2863f":"markdown","486272ca":"markdown","31877b64":"markdown","913f1aac":"markdown","074e6eff":"markdown","41771d91":"markdown","8290c609":"markdown","2d01666d":"markdown","c9f8cb99":"markdown","0c734c57":"markdown","baccb82b":"markdown","d6ea032a":"markdown","0487a23e":"markdown","3f6eea7a":"markdown","a8b82d8f":"markdown","c48d3bfe":"markdown"},"source":{"dbee0b89":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline","c9ad38a1":"train_df=pd.read_csv('..\/input\/amazon-employee-access-challenge\/train.csv')\ntrain_df.head()","55944144":"target_df=pd.DataFrame(train_df['ACTION'],columns=['ACTION'])","09050300":"target_df['ACTION'].value_counts()","3faa7ef1":"sns.catplot('ACTION',data=target_df,kind='count')\nplt.title('Action distributions',size=20)","a063fd5d":"train_df.dtypes","11751150":"train_df.isna().any()","31a136cc":"train_df.drop('ACTION',axis=1,inplace=True)","7693baba":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score\nfrom sklearn.metrics import confusion_matrix,roc_curve,precision_recall_curve,auc\nfrom sklearn.preprocessing import StandardScaler","07ca6846":"param_grid={'n_neighbors':[3,5,7]}\nknn=KNeighborsClassifier()","347b38e6":"X=train_df.values\ny=target_df['ACTION'].values\nscaler=StandardScaler()\nX_scaled=scaler.fit_transform(X)\nX_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.2,random_state=0)","810065a4":"grid_search=GridSearchCV(knn,param_grid,scoring='roc_auc')","787b664a":"grid_result=grid_search.fit(X_train,y_train)","b34b08d7":"grid_result.best_params_","11b40448":"grid_result.score(X_train,y_train)","e5518506":"scores=[]\nfor i in range(1,13):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    cv_scores=cross_val_score(knn,X,y,cv=15)\n    scores.append(cv_scores.mean())\n    ","03c050c2":"neighbors=np.arange(1,13)\nplt.figure(figsize=(10,8))\nsns.set(style='white')\nplt.plot(neighbors,scores,color='b')\nplt.axvline(7,color='g')\nplt.axhline(0.94,color='red')\nplt.title('Accuracy Vs Neighbors',size=20)\nplt.xlabel('Number of neighbors')\nplt.ylabel('Accuracy score')\nticks=np.arange(1,13)\nplt.xticks(ticks)","186dd31c":"knn=KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train,y_train)\ny_knn_pred=knn.predict(X_test)","20418875":"knn_score=knn.score(X_test,y_test)\nknn_score","b2a638b5":"conf_mat_knn=confusion_matrix(y_test,y_knn_pred)\nsns.heatmap(conf_mat_knn,annot=True,fmt='g',cmap='gnuplot')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","44faf42c":"from sklearn.svm import SVC","022870d1":"svm=SVC(gamma=1e-07,C=1e9)\nsvm.fit(X_train,y_train)","aafa9cad":"svm.score(X_train,y_train)","642adecd":"y_pred_svc=svm.predict(X_test)\nsvm.score(X_test,y_test)","2c84556c":"conf_mat_svc=confusion_matrix(y_test,y_pred_svc)\nsns.heatmap(conf_mat_svc,annot=True,fmt='g',cmap='summer')","f447a166":"y_svc=svm.fit(X_train,y_train).decision_function(X_test)","8707867e":"fpr,tpr,_=roc_curve(y_test,y_svc)\nplt.plot(fpr,tpr,color='indianred')\nplt.plot([0,1],[0,1],color='blue',linestyle='--')\nplt.xlabel('False postive rate')\nplt.ylabel('True positive rate')\nauc_svc=auc(fpr,tpr)\nplt.title('ROC curve for SVC with AUC: {0:.2f}'.format(auc_svc))","1bf1acab":"precision,recall,threshold=precision_recall_curve(y_test,y_svc)\nclosest_zero=np.argmin(np.abs(threshold))\nclosest_zero_p=precision[closest_zero]\nclosest_zero_r = recall[closest_zero]\nplt.plot(precision,recall)\nplt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\nplt.title('Precision-Recall curve with SVC')\nplt.xlabel('Precision')\nplt.ylabel('Recall')","8d78d3be":"from sklearn.linear_model import LogisticRegression","327cca03":"reg_log=LogisticRegression()","bce4c7bf":"reg_log.fit(X_train,y_train)","3a2a941d":"reg_log.score(X_train,y_train)","d1e89b29":"y_pred_log=reg_log.predict(X_test)\nreg_log.score(X_test,y_test)","90f9ef57":"conf_mat_log=confusion_matrix(y_pred_log,y_test)\nsns.heatmap(conf_mat_log,annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","740be5e4":"y_log=reg_log.fit(X_train,y_train).decision_function(X_test)","eb5ed3be":"fpr,tpr,_=roc_curve(y_test,y_log)\nplt.plot(fpr,tpr,color='indianred')\nplt.plot([0,1],[0,1],color='blue',linestyle='--')\nplt.xlabel('False postive rate')\nplt.ylabel('True positive rate')\nauc_svc=auc(fpr,tpr)\nplt.title('ROC curve for Logistic regression with AUC: {0:.2f}'.format(auc_svc))","cd4c2d1e":"from sklearn.linear_model import SGDClassifier","0239a6ce":"sgd=SGDClassifier()","1816b3e6":"sgd.fit(X_train,y_train)","ce46e558":"sgd.score(X_train,y_train)","b62d5b9e":"y_pred_sgd=sgd.predict(X_test)\nsgd.score(X_test,y_test)","fbf2c106":"conf_mat_sgd=confusion_matrix(y_pred_sgd,y_test)\nsns.heatmap(conf_mat_sgd,annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","0bfd5bc4":"y_sgd=sgd.fit(X_train,y_train).decision_function(X_test)\nfpr,tpr,_=roc_curve(y_test,y_sgd)\nplt.plot(fpr,tpr,color='indianred')\nplt.plot([0,1],[0,1],color='blue',linestyle='--')\nplt.xlabel('False postive rate')\nplt.ylabel('True positive rate')\nauc_svc=auc(fpr,tpr)\nplt.title('ROC curve for SGD with AUC: {0:.2f}'.format(auc_svc))","9add14a6":"from sklearn.tree import DecisionTreeClassifier","52faf46f":"dtc=DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ndtc.score(X_train,y_train)","4c4afa56":"y_pred_dtc=dtc.predict(X_test)\ndtc.score(X_test,y_test)","420143fa":"conf_mat_dtc=confusion_matrix(y_pred_dtc,y_test)\nsns.heatmap(conf_mat_dtc,annot=True,fmt='g',cmap='winter')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","1e958224":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nparam_grid={'n_estimators':[3,5,7,9],'max_depth':[5,7,9]}\ngrid_search=GridSearchCV(rfc,param_grid,scoring='roc_auc')","7f5eea2d":"grid_search.fit(X_train,y_train)","17b25112":"grid_search.best_params_","39c53375":"grid_search.score(X_train,y_train)","d94d0db2":"y_pred_rfc=grid_search.predict(X_test)","1c40fe61":"grid_search.score(X_test,y_test)","a340041f":"conf_mat_rfc=confusion_matrix(y_pred_rfc,y_test)\nsns.heatmap(conf_mat_rfc,annot=True,fmt='g',cmap='gnuplot')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","d9c2bf48":"from sklearn.ensemble import GradientBoostingClassifier","22ceb05a":"gbdt=GradientBoostingClassifier()","34610d05":"params={'max_depth':[6,7,8,10,12]}\ngrid_search=GridSearchCV(gbdt,params,scoring='roc_auc')","eee1817d":"grid_search.fit(X_train,y_train)","505df042":"print('Best parameter:{}'.format(grid_search.best_params_))\nprint('Best cross validated score: {:.2f}'.format(grid_search.best_score_))","d70cb60c":"grid_search.score(X_train,y_train)","f223adbb":"y_pred_gbdt=grid_search.predict(X_test)\ngrid_search.score(X_test,y_test)","65e7e7dd":"conf_mat_gbdt=confusion_matrix(y_pred_gbdt,y_test)\nsns.heatmap(conf_mat_gbdt,annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","2543ee3c":"import xgboost as xgb","75752158":"xgb_class=xgb.XGBClassifier(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)","299ec972":"xgb_class.fit(X_train,y_train)","3ae3565a":"xgb_class.score(X_train,y_train)","1a7dac98":"y_pred_xgb=xgb_class.predict(X_test)","cf614aa3":"xgb_class.score(X_test,y_test)","5473d4f5":"conf_mat_xgb=confusion_matrix(y_pred_xgb,y_test)","4320e150":"sns.heatmap(conf_mat_xgb,annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","0ffae6d8":"from lightgbm import LGBMClassifier","9885e853":"lgbm=LGBMClassifier(num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 30, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","df648511":"lgbm.fit(X_train,y_train)","6566c1f2":"lgbm.score(X_train,y_train)","0bf0513e":"y_pred_lgbm=lgbm.predict(X_test)","5d092b28":"lgbm.score(X_test,y_test)","3673f86f":"conf_mat_lgbm=confusion_matrix(y_pred_lgbm,y_test)\nsns.heatmap(conf_mat_lgbm,annot=True,fmt='g')","2e0cd73a":"test_df=pd.read_csv('..\/input\/amazon-employee-access-challenge\/test.csv')\ntest_df.head()","5ebf9d03":"test_id=pd.DataFrame(test_df.iloc[:,0],columns=['id'])\ntest_id.head()","777fc31c":"test_df.drop('id',axis=1,inplace=True)","9afde2da":"X_test=scaler.fit_transform(test_df)\nX_test","05a5588f":"y_final_knn=knn.predict(X_test)","52639559":"knn_df=pd.DataFrame(columns=['Id','Action'])\nknn_df['Action']=y_final_knn\nknn_df['Id']=test_id['id']\nknn_df.head()","907d6590":"y_final_dtc=dtc.predict(X_test)\ndtc_df=pd.DataFrame(columns=['Id','Action'])\ndtc_df['Action']=y_final_dtc\ndtc_df['Id']=test_id['id']\ndtc_df.head()","91fac4f4":"dtc_df.to_csv('DTC_predictions.csv',index=False)","bbdc0c80":"Let us check how the Reciever operating characteristic curve and Precision recall curve look like.","a6409a92":"## Gradient boosted Decision Trees","5407f41a":"It is seen that for low max_depth of tree, the model couldn't predict the 0s correctly. As the max_depth was increased, it was seen that number of correct 0 predictions increased. Hence, we tried to tune the max_depth hyperparameter using a grid search technique. According to the grid search, the best max_depth was found to be 8. The correct 0 detection is however not satisfactory.","7c8b9e53":"As we can see, the area under curve is only 0.5. This shows that the model is performing **quite average** .\n\n\nLet us see how the precision-recall curve looks like.","c5197ea4":"Let us separate out the action column into another dataframe called the target_df.","a67dd21b":"### KNN predictions","6fd816cd":"We have already seen that the linear models and svc  performed poorly. Let us now go ahead with ensemble models to check how we well they can predict.","1efd7fd9":"However, to dig deeper into what value of K will be good, let us make a graph of accuracy Vs K for better understanding.","440857b6":"### Decision tree predictions","4da013d6":"Initially, let us use the KNearestNeighbor classifier to see how it classifies the ACTION correctly. For our classification, we will use a range of K values from 1 to 12.","dc3d817f":"## Data description\nAfter eyeballing the above data, it is clear that the first column which is the action is our target variable. Let us check what each of the columns actually mean.\n\nColumn Name\tDescription\n\n**ACTION**\tACTION is 1 if the resource was approved, 0 if the resource was not\n\n**RESOURCE**\tAn ID for each resource\n\n**MGR_ID**\tThe EMPLOYEE ID of the manager of the current EMPLOYEE ID record; an employee may have only one manager at a time\n\n**ROLE_ROLLUP_1**\tCompany role grouping category id 1 (e.g. US Engineering)\n\n**ROLE_ROLLUP_2**\tCompany role grouping category id 2 (e.g. US Retail)\n\n**ROLE_DEPTNAME**\tCompany role department description (e.g. Retail)\n\n**ROLE_TITLE**\tCompany role business title description (e.g. Senior Engineering Retail Manager)\n\n**ROLE_FAMILY_DESC**\tCompany role family extended description (e.g. Retail Manager, Software Engineering)\n\n**ROLE_FAMILY**\tCompany role family description (e.g. Retail Manager)\n\n**ROLE_CODE**\tCompany role code; this code is unique to each role (e.g. Manager)","4d4e963c":"As we can see, the decision tree has relatively done a better job than the other models since it could capture the 0s correctly as well.","b8c37ef7":"From the above graph, it is clear that at **N neighbors=7** , the accuracy is quite high. This was confirmed by the GridSearchCV aswell. We try not to exceed 7 neighbors even if the accuracy is slightly increasing. Too many neighbors lead to underfitting of the data.\n\nLet us now make the predictions on the test dataset.","1f25060f":"As we can see, the model will implement a L2 regularisation (or penalty) for each incorrect prediction.","8e10e972":"Upon checking the various models, we shall take the following models under consideration for our test dataset:\n\n* KNN\n* Decision Tree\n* GBDT\n* XGBoost","c8f36dd8":"Let us import the test data and use standard scaling for the input data.","80868c42":"# 1. Data preprocessing and visualisations\n## Importing libraries and datasets","7294eacb":"## LightGBM classification","b174217f":"## Decision tree","a164e71c":"## Stochastic gradient descent","14db72db":"# 2. Machine Learning\n\n## KNN","44e2863f":"As we can see, the logistic regression could not capture any of the targets with 0 (or access denied). This clearly indicates that the model is only accurate at capturing the 1s.","486272ca":"From the ROC, it is clearly visible how poor the model is predicting. In fact, it has performed almost as poor as the  Logistic regression model.","31877b64":"# 3. Testing phase","913f1aac":"As we can see, majority of the entries had the resources approved. Let us visualise this using a barplot.","074e6eff":"## SVM","41771d91":"As we can see, we have no particular missing values at all in the dataframe. Hence, it can be said that the dataframe is already preprocessed with removal of all the missing values.\n\nThis means we can directly head towards machine learning.","8290c609":"This is another extremely poor model as shown by the above ROC curve. This was already indicated by the confusion matrix.","2d01666d":"## XGBoost classification","c9f8cb99":"As we can see, the results are exactly same as the logistic regression model. Hence, no improvements could be seen using SGD.","0c734c57":"As we can see, all the data is in integer form. This is extremely helpful for machine learning purpose as it doesn't require any further feature engineering or preprocessing to be done.\n\nInfact, it could be said that most of the preprocessing was already done for us. This is because although we have many categorical features, the data is in integer form. This suggests that the categorical data that we have is already label or ordinal encoded for us.\n\n\nLet us check if we have any missing variables to be take care of.","baccb82b":"As we can see, the model again failed to correctly predict the 0s.","d6ea032a":"Let us check the various data types in the dataframe presented to us.","0487a23e":"The red dot above shows the optimum precision and recall value balance.","3f6eea7a":"As we can see, the model made quite a few errors in predicting the 0s correctly. This has been a clear problem with most of the models we have dealt so far.","a8b82d8f":"## Random forest","c48d3bfe":"## Logistic Regression"}}