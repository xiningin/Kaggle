{"cell_type":{"39d047ba":"code","c5fc0b0d":"code","bf9d5367":"code","a157446d":"code","0810c3d2":"code","04cfcded":"code","c9eae875":"code","aabb42f3":"code","7ac0cbc1":"code","7eade312":"code","c64cb884":"code","e4d0ca96":"code","00ef775d":"code","18b9ca9b":"code","0dca22ee":"code","90a71375":"code","1c01572e":"code","fbf52f4d":"code","13ba5af9":"code","776cb4eb":"code","a6ce06bc":"code","1b586f3f":"code","818d5a40":"code","b1edc97e":"code","b2d833ea":"code","8e726798":"code","9eec4482":"code","fb35e738":"code","68a716ad":"code","cf418706":"code","96e792d8":"code","6dc2a62d":"code","76dd58dd":"code","db9c36f2":"code","eb064d63":"code","884255ed":"code","e29559af":"code","21985876":"code","4c89a6b2":"code","c3695d57":"code","f6cd5924":"code","b1274315":"markdown","18d0990d":"markdown","1b26600c":"markdown","321dd6ce":"markdown","f595f52c":"markdown","2753d759":"markdown","053e9569":"markdown","f9fce203":"markdown","41810c70":"markdown","56642c3b":"markdown","5deaceb6":"markdown","be2e6dca":"markdown"},"source":{"39d047ba":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport pylab as plot\n\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c5fc0b0d":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n \n\n \n","bf9d5367":"train.isnull().sum(), test.isnull().sum(), ","a157446d":"fare_cap = 300\ntrain.loc[train['Fare'] > fare_cap, 'Fare'] = fare_cap\ntest.loc[test['Fare'] > fare_cap, 'Fare'] = fare_cap","0810c3d2":"Title_Dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\"\n}\n\n# fix error data\ntest.loc[test['Ticket']=='PC 17758', 'Name'] = 'Oliva y Ocana, Don. Fermina'\n\ndef get_title(_df):\n    df = _df.copy()\n    df['Title'] = df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    df['Title'] = df.Title.map(Title_Dictionary)\n    return df['Title']\n\n\ntrain['Title'] = get_title(train)\ntest['Title'] = get_title(test)\n\n\n","04cfcded":"#train = train.drop(train[train['Embarked'].isnull()].index)\ntrain['Embarked'] = train['Embarked'].fillna('S') ","c9eae875":"def getSameTicketList(df):\n    same_ticket_list = (df.reset_index().groupby('Ticket')['PassengerId'].agg([len]).query('len > 1')).index\n    return same_ticket_list\n\n#train_same_ticket_list = getSameTicketList(train)\n#train.loc[train['Ticket'].isin(train_same_ticket_list)==False, 'Ticket'] = 'UNIQUE'\n \n#test_same_ticket_list = getSameTicketList(test)\n#test.loc[test['Ticket'].isin(test_same_ticket_list)==False, 'Ticket'] = 'UNIQUE'\n\n#train.loc[~(train['Ticket']=='UNIQUE'), 'Ticket'] = 'NON_UNIQUE'\n#test.loc[~(test['Ticket']=='UNIQUE'), 'Ticket'] = 'NON_UNIQUE'\n","aabb42f3":"#train.loc[~(train['Ticket']=='UNIQUE'), 'Ticket'] = 'NON_UNIQUE'\n#test.loc[~(test['Ticket']=='UNIQUE'), 'Ticket'] = 'NON_UNIQUE'","7ac0cbc1":"test['Ticket'].sort_values()\ntest['Ticket'].value_counts()","7eade312":"len(test)","c64cb884":"def get_ticket_prefix(obj):\n    if (isinstance(obj, list)):\n        if (obj[0].isdigit()):\n            return '_'\n        else:\n            return obj[0]\n     \n    return obj\n    \ndef get_first_item_from_list(obj):\n    if (isinstance(obj, list)):\n        return obj[0]  \n     \n    return obj\n\ndef extract_ticket_no(_df):\n    df = _df.copy()\n    df['ticket_prefix'] = df['Ticket'] \\\n    .str.split(' ').map(get_ticket_prefix).str.replace('.','') \\\n    .str.split('\/').map(get_first_item_from_list)\n    df['ticket_no'] = df['Ticket'].str.extract('(\\d+)', expand=False).fillna(-1).astype(int)\n    return df\n\ntrain = extract_ticket_no(train)\ntest = extract_ticket_no(test)\n","e4d0ca96":"#train['is_ticket_prefix_na'] = np.where(train['ticket_prefix']=='_' , 1 , 0)\n#test['is_ticket_prefix_na'] = np.where(test['ticket_prefix']=='_' , 1 , 0)\n\n#train['ticket_prefix'].value_counts()\/ len(train)\n#train['cabin_prefix'].value_counts()\/ len(train)","00ef775d":"\ntrain['is_cabin_na'] = np.where(train['Cabin'].isnull() , 1 , 0)\ntest['is_cabin_na'] = np.where(test['Cabin'].isnull(), 1 , 0)\n","18b9ca9b":"def fill_cabin(_df):\n    \n    df = _df.copy()\n    df['cabin_prefix'] = df['Cabin'].str.get(0)\n    df['cabin_prefix'].fillna('_', inplace=True)\n    df['cabin_no'] = df['Cabin'].str.extract('(\\d+)', expand=False).fillna(-1).astype(int)\n    return df\n\ntrain = fill_cabin(train) \ntest = fill_cabin(test) \n\n   ","0dca22ee":" train","90a71375":"#train['is_age_na'] = np.where(train['Age'].isnull() , 1 , 0)\n#test['is_age_na'] = np.where(test['Age'].isnull() , 1 , 0)\n\n","1c01572e":"def guess_age():\n    #\n    train.loc[train['PassengerId']==693, 'Age'] = 32\n    train.loc[train['PassengerId']==827, 'Age'] = 26\n    train.loc[train['PassengerId']==644, 'Age'] = 26\n    #\n    #train.loc[train['PassengerId']==307, 'Age'] = 0\n    #train.loc[train['PassengerId']==307, 'Cabin'] = 'C68'\n    #\n    train.loc[train['PassengerId']==850, 'Age'] = 40\n    #\n    train.loc[train['PassengerId']==670, 'Age'] = 40\n    #\n    train.loc[train['PassengerId']==597, 'Age'] = 26\n    #\n    train.loc[train['PassengerId']==496, 'Age'] = 19\n    #\n    train.loc[train['PassengerId']==241, 'Age'] = 14\n    #\n    train.loc[train['PassengerId']==534, 'Cabin'] = 'F E69'\n    test.loc[test['PassengerId']==1309, 'Cabin'] = 'F E69'\n    # 141\n    train.loc[train['PassengerId']==141, 'Age'] = 30\n    # 761\n    train.loc[train['PassengerId']==761, 'Age'] = 19\n    # 302 331 ??\n    #train.loc[train['PassengerId']==302, 'Age'] = 22\n    #train.loc[train['PassengerId']==331, 'Age'] = 20\n    # 32 ?\n    train.loc[train['PassengerId']==32, 'Age'] = 58\n    # 376\n    train.loc[train['PassengerId']==376, 'Age'] = 24\n    # 335\n    train.loc[train['PassengerId']==335, 'Age'] = 40\n    # 816\n    train.loc[train['PassengerId']==816, 'Age'] = 49\n    # 476\n    train.loc[train['PassengerId']==476, 'Age'] = 47\n\n    # 167\n    train.loc[train['PassengerId']==167, 'Age']= 45\n    # 603\n    train.loc[train['PassengerId']==603, 'Age'] = 47\n    # 271\n    train.loc[train['PassengerId']==271, 'Age'] = 32\n    # 1038\n    test.loc[test['PassengerId']==1038, 'Age'] = 54\n    # 458\n    train.loc[train['PassengerId']==458, 'Age'] = 37\n  \n    # train 66,710 : age=0,0\n    # train 719 test 1092 : age ~ 20\n    # train 47 test 1165: age ~ 22, 20\n    # test 1236\n    test.loc[test['PassengerId']==1236, 'Age'] = 12\n    # train 498\n    train.loc[train['PassengerId']==498, 'Age'] = 40\n\n    # all avg ~ 18\n    # train 181, test 1252 train 864, train 202 793 847 325 160 test 1080\n    # test 1257 ~ 50, test 1234 ~ 55\n\n    # 528\n    train.loc[train['PassengerId']==528, 'Age'] = 33\n    # 32\n    train.loc[train['PassengerId']==32, 'Age'] = 55\n    # 257\n    train.loc[train['PassengerId']==257, 'Age'] = 40\n    # 335\n    train.loc[train['PassengerId']==335, 'Age'] = 45\n\n\n\n\n# \ntest.loc[test['PassengerId']==1033, 'Cabin'] = 'C22 C26'\n# 1080\ntest.loc[test['PassengerId']==1080, 'Age'] = 14\n# 957\ntest.loc[test['PassengerId']==957, 'Age'] = 22\n \n    \n#\nguess_age()\n    ","fbf52f4d":"def combine_parch_sibsp(_df):\n    df = _df.copy()\n    df['family_member'] = df['Parch'] + df['SibSp']\n    return df\n    \n#train = combine_parch_sibsp(train) \n#test = combine_parch_sibsp(test) ","13ba5af9":"train.shape, test.shape","776cb4eb":"train = train.set_index('PassengerId')\ntest = test.set_index('PassengerId')\nX_train, X_test, y_train, y_test = train_test_split(\n    train.drop(columns=['Survived']), train['Survived'],\n    test_size=0.1, random_state=0)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n","a6ce06bc":" train.columns","1b586f3f":"def get_dict_to_group_rare_labels(df, var, cutoff):\n    total = len(df)\n    temp_df = df[var].value_counts() \/ total\n    group_dict = {\n        k: ('rare' if k not in temp_df.loc[temp_df >= cutoff].index else k)\n        for k in temp_df.index\n    }\n    return group_dict\n    \ncabin_prefix_rare_dict = get_dict_to_group_rare_labels(X_train, 'cabin_prefix', 0.03)\n#ticket_prefix_rare_dict = get_dict_to_group_rare_labels(X_train, 'ticket_prefix', 0.011)\nticket_prefix_rare_dict = get_dict_to_group_rare_labels(X_train, 'ticket_prefix', 0.04)\ntitle_rare_dict = get_dict_to_group_rare_labels(X_train, 'Title', 0.04)\n\ndef reduce_rare_labels(_df):\n    df = _df.copy()\n    df['cabin_prefix'] = df['cabin_prefix'].map(cabin_prefix_rare_dict)\n    df['ticket_prefix'] = df['ticket_prefix'].map(ticket_prefix_rare_dict)\n    #df['Title'] = df['Title'].map(title_rare_dict)\n    return df\n\nX_train = reduce_rare_labels(X_train)\nX_test = reduce_rare_labels(X_test)\ntest = reduce_rare_labels(test)\n\nX_train.isnull().sum(), X_test.isnull().sum(), test.isnull().sum()\n\n#\n#X_train.loc[X_train['Title'].isnull()==True, 'Title'] = 'rare'\n#X_test.loc[X_test['Title'].isnull()==True, 'Title'] = 'rare'\n#test.loc[test['Title'].isnull()==True, 'Title'] = 'rare'\n#\nX_test.loc[X_test['ticket_prefix'].isnull()==True, 'ticket_prefix'] = 'rare'\ntest.loc[test['ticket_prefix'].isnull()==True, 'ticket_prefix'] = 'rare'","818d5a40":"#\nselect_age_map_0 = X_train.groupby([ 'Pclass' , 'Sex', 'Title', 'SibSp', 'Parch'  ]).agg('mean')['Age']\nselect_age_map_1 = X_train.groupby([ 'Pclass' , 'Sex', 'Title', 'SibSp'  ]).agg('mean')['Age']\nselect_age_map_2 = X_train.groupby([ 'Pclass' , 'Sex', 'Title'   ]).agg('mean')['Age']\nselect_age_map_3 = X_train.groupby([ 'Pclass' , 'Sex'   ]).agg('mean')['Age']\n\ndef fill_age_data(_df, select_map):\n    \n    df = _df.copy()\n    missing_age_mask = (df['Age'].isnull() == True)\n    #df.loc[missing_age_mask, 'Age'] = df.loc[missing_age_mask].apply(lambda row: select_age_map_1[(row['Pclass'], row['Sex'], row['Title'], row['SibSp'], row['Parch']  )], axis=1)\n    df.loc[missing_age_mask, 'Age'] = df.loc[missing_age_mask].apply(lambda row: select_age_map_1[(row['Pclass'], row['Sex'], row['Title'], row['SibSp']  )], axis=1)\n    df.loc[missing_age_mask, 'Age'] = df.loc[missing_age_mask].apply(lambda row: select_age_map_2[(row['Pclass'], row['Sex'], row['Title']  )], axis=1)\n    \n    return df\n\nX_train = fill_age_data(X_train, select_age_map_1)\nX_test = fill_age_data(X_test, select_age_map_1)\ntest = fill_age_data(test, select_age_map_1)\n\nX_train.Age.isnull().sum(), X_test.Age.isnull().sum(),test.Age.isnull().sum()","b1edc97e":"X_train['Age'] = X_train['Age'].astype(int)\nX_test['Age'] = X_test['Age'].astype(int)\ntest['Age'] = test['Age'].astype(int)\n","b2d833ea":"# Fare ~ Pclass + Sex + Age\n\ndef estimateFare(row):\n    print(row['Pclass'], row['Sex'], row['Age'])\n    mask =  (X_train['Pclass']==row['Pclass']) & (X_train['Sex']==row['Sex']) & (X_train['Age'] >= (row['Age']-10)) & (X_train['Age'] <= (row['Age']+10))\n    df = X_train.loc[mask]\n    return df['Fare'].mean()\n    \nmissing_fare_mask = (test['Fare'].isnull() == True)\n\ntest.loc[missing_fare_mask, 'Fare'] = test.loc[missing_fare_mask].apply(lambda row: estimateFare(row), axis=1)\n\n#\nX_train['Fare'] = X_train['Fare'].astype(int)\nX_test['Fare'] = X_test['Fare'].astype(int)\ntest['Fare'] = test['Fare'].astype(int)\n\nprint(test.loc[test.index==1044, 'Fare'] )\n\n ","8e726798":"X_train['Sex']","9eec4482":" X_train.columns","fb35e738":"train['cabin_prefix'].value_counts() ","68a716ad":"test[test['ticket_prefix'].isnull()==True]","cf418706":"#X_train['Title'].value_counts() \/ len(X_train)","96e792d8":"def get_full_dummies_non_missing(full_cols, partial_series, prefix):\n\n    adjusted_cols = [(x) for x in full_cols]\n\n    dummies = pd.get_dummies(partial_series, prefix=prefix)\n    dummies = dummies.T.reindex(adjusted_cols).T.fillna(0)\n    return dummies\n\ndef getDictFromSeries(_series):\n    series = _series.sort_values();\n    map_dict = {k: v for k, v in zip(series.unique(), np.arange(len(series.unique())))}\n    return map_dict\n\n#\n#embarked_map = getDictFromSeries(X_train['Embarked'])\n#ticket_prefix_map = getDictFromSeries(X_train['ticket_prefix'])\n#sex_map = getDictFromSeries(X_train['Sex'])\n#title_map = getDictFromSeries(X_train['Title'])\n#cabin_prefix_map = getDictFromSeries(X_train['cabin_prefix'])\n\n \ndef find_category_mapping(df, variable, target):\n    tmp = pd.DataFrame( df.groupby([variable])[target].mean())\n    tmp['non_' + target] = 1 - tmp[target]\n    tmp['target_ratio'] = tmp[target] \/ tmp['non_' + target]\n    return tmp['target_ratio'].to_dict()\n    \ndef integer_encode_col(x_train, x_test, test, variable, _map_dict):\n    x_train[variable] = x_train[variable].map(_map_dict)\n    x_test[variable] = x_test[variable].map(_map_dict)\n    test[variable] = test[variable].map(_map_dict)\n    \ndef AgeGroups(age_series):\n    new_age = []\n    for i in age_series:\n        if i == 0:\n            new_age.append(0)\n        if i > 0 and i <= 16:\n            new_age.append(1)\n        elif i > 16 and i <= 32:\n            new_age.append(2)\n        elif i > 32 and i <= 48:\n            new_age.append(3)\n        elif i > 48 and i <= 64:\n            new_age.append(4)\n        elif i > 64:\n            new_age.append(5)\n    return new_age\n\n \n\n\ndef prepare_data_for_model(_df):\n    \n    df = _df.copy()\n \n    #\n    #df['Sex'] = df['Sex'].map(sex_map)\n    #df['embarked_int'] = df['Embarked'].map(embarked_map)\n    #df['ticket_prefix'] = df['ticket_prefix'].map(ticket_prefix_map)\n    #df['Title'] = df['Title'].map(title_map)\n    #df['cabin_prefix'] = df['cabin_prefix'].map(cabin_prefix_map)\n   \n    #\n    titles_dummies = pd.get_dummies(df['Title'], prefix='Title')\n    #df = pd.concat([df, titles_dummies], axis=1)\n    \n    #\n    sex_dummies = pd.get_dummies(df['Sex'], prefix='Sex')\n    df = pd.concat([df, sex_dummies], axis=1)\n    \n    #is_cabin_na_dummies = pd.get_dummies(df['is_cabin_na'], prefix='is_cabin_na')\n    #df = pd.concat([df, is_cabin_na_dummies], axis=1)\n     \n    \n    #\n    #ticket_dummies = pd.get_dummies(df['Ticket'], prefix='Ticket')\n    #df = pd.concat([df, ticket_dummies], axis=1)\n    \n    \n    #\n    #embarked_dummies = pd.get_dummies(df['Embarked'], prefix='Embarked')\n    #df = pd.concat([df, embarked_dummies], axis=1)\n \n \n    #\n    #pclass_dummies = pd.get_dummies(df['Pclass'], prefix='Pclass')\n    #df = pd.concat([df, pclass_dummies], axis=1)\n \n    #df['family'] = df['Parch'] + df['SibSp']\n\n    #df['PassengerId'] = df.index\n    \n    #df['Age'] = AgeGroups(df['Age'])\n\n    try:\n        df = df.drop(columns=['is_cabin_na', 'Embarked', 'Sex', 'Ticket', 'Title', 'cabin_prefix', 'ticket_prefix',  'Cabin', 'Name',  'cabin_no', 'ticket_no' ])\n    except:\n        print('drop columns failed')\n\n    return df\n\n\n\n\nX_train_y = pd.concat([X_train, pd.DataFrame(y_train, columns=['Survived'])], axis=1)\n\n\n#\n#cabin_prefix_ratio_map = find_category_mapping(X_train_y, 'cabin_prefix', 'Survived')\n#print(cabin_prefix_ratio_map)\n#integer_encode_col(X_train, X_test, test, 'cabin_prefix', cabin_prefix_ratio_map)\n\n#embarked_prefix_ratio_map = find_category_mapping(X_train_y, 'Embarked', 'Survived')\n#print(embarked_prefix_ratio_map)\n#integer_encode_col(X_train, X_test, test, 'Embarked', embarked_prefix_ratio_map)\n\npclass_prefix_ratio_map = find_category_mapping(X_train_y, 'Pclass', 'Survived')\nprint(pclass_prefix_ratio_map)\ninteger_encode_col(X_train, X_test, test, 'Pclass', pclass_prefix_ratio_map)\n\n#is_cabin_na_ratio_map = find_category_mapping(X_train_y, 'is_cabin_na', 'Survived')\n#print(is_cabin_na_ratio_map)\n#integer_encode_col(X_train, X_test, test, 'is_cabin_na', is_cabin_na_ratio_map)\n \n\n#X_train_cabin_prefix = pd.get_dummies(X_train_y['cabin_prefix'], variable='cabin_prefix', )\n#X_test_cabin_prefix = get_full_dummies_non_missing(X_train_cabin_prefix.columns, X_test['cabin_prefix'], 'cabin_prefix')\n#test_cabin_prefix = get_full_dummies_non_missing(X_train_cabin_prefix.columns, test['cabin_prefix'], 'cabin_prefix')\n\n#X_train = pd.concat([X_train, X_train_cabin_prefix], axis=1)\n#X_test = pd.concat([X_test, X_test_cabin_prefix], axis=1)\n#test = pd.concat([test, test_cabin_prefix], axis=1)\n\n#\n#X_train_ticket_prefix = pd.get_dummies(X_train['ticket_prefix'], prefix='ticket_prefix')\n#X_test_ticket_prefix = get_full_dummies_non_missing(X_train_ticket_prefix.columns, X_test['ticket_prefix'], 'ticket_prefix')\n#test_ticket_prefix = get_full_dummies_non_missing(X_train_ticket_prefix.columns, test['ticket_prefix'], 'ticket_prefix')\n\n#X_train = pd.concat([X_train, X_train_ticket_prefix], axis=1)\n#X_test = pd.concat([X_test, X_test_ticket_prefix], axis=1)\n#test = pd.concat([test, test_ticket_prefix], axis=1)\n\n\n#\nX_train = prepare_data_for_model(X_train)\nX_test = prepare_data_for_model(X_test)\ntest = prepare_data_for_model(test)\n\nX_train.shape, X_test.shape, test.shape\n\n","6dc2a62d":"def compareDecisionTreeBin(input_series):\n    score_ls = []\n    score_std_ls = []\n\n    for tree_depth in [1,2,3,4]:\n            tree_model = DecisionTreeClassifier(max_depth=tree_depth)\n            scores = cross_val_score(tree_model, input_series.to_frame(), y_train, cv=3, scoring='roc_auc')\n            score_ls.append(np.mean(scores))\n            score_std_ls.append(np.std(scores))\n            temp = pd.concat([pd.Series([1,2,3,4]), pd.Series(score_ls), pd.Series(score_std_ls)], axis=1)\n            temp.columns = ['depth','auc_roc_mean','roc_auc_std']\n\n    return temp\n        \nfare_bin_compare = compareDecisionTreeBin(X_train['Fare'])\nfare_bin_compare\n# choose depth=3\n\n","76dd58dd":"#fare_tree_model = DecisionTreeClassifier(max_depth=4)\n#fare_tree_model.fit(X_train['Fare'].to_frame(), y_train)\n#X_train['Fare_tree'] = fare_tree_model.predict_proba(X_train['Fare'].to_frame())[:,1]\n#X_test['Fare_tree'] = fare_tree_model.predict_proba(X_test['Fare'].to_frame())[:,1]\n#test['Fare_tree'] = fare_tree_model.predict_proba(test['Fare'].to_frame())[:,1]\n#pd.concat([X_train, y_train], axis=1).groupby(['Fare_tree'])['Survived'].mean().plot()","db9c36f2":"#X_train.groupby(['Fare_tree'])['Fare'].count().plot.bar()\n#X_test.groupby(['Fare_tree'])['Fare'].count().plot.bar()\n#test.groupby(['Fare_tree'])['Fare'].count().plot.bar()\n\n#X_train = X_train.drop(columns=['Fare'])\n#X_test = X_test.drop(columns=['Fare'])\n#test = test.drop(columns=['Fare'])   ","eb064d63":" \nX_train","884255ed":"def examine_features():\n    \n    #\n    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n                    'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n\n    #\n    clf = RandomForestClassifier(**parameters, random_state=0)\n    clf = clf.fit(X_train, y_train)\n\n    #\n    features = pd.DataFrame()\n    features['feature'] = X_train.columns\n    features['importance'] = clf.feature_importances_\n    features.sort_values(by=['importance'], ascending=True, inplace=True)\n    features.set_index('feature', inplace=True)\n\n    features.plot(kind='barh', figsize=(25, 25)) \n    \n\nexamine_features()\n","e29559af":"# turn run_gs to True if you want to run the gridsearch again.\nrun_gs = False\n\nif run_gs:\n    parameter_grid = {\n                 'max_depth' : [5, 6, 7, 8, 10],\n                 'n_estimators': [10, 30, 50, 100],\n                 'max_features': ['sqrt', 'auto', 'log2'],\n                 'min_samples_split': [2, 3, 5, 7],\n                 'min_samples_leaf': [1, 3, 5, 7] \n                 }\n    forest = RandomForestClassifier()\n    cross_validation = StratifiedKFold(n_splits=5)\n\n    grid_search = GridSearchCV(forest,\n                               scoring='accuracy',\n                               param_grid=parameter_grid,\n                               cv=cross_validation,\n                               verbose=1\n                              )\n\n    \n    grid_search.fit(X_train, y_train)\n    model = grid_search\n    parameters = grid_search.best_params_\n\n    print('Best score: {}'.format(grid_search.best_score_))\n    print('Best parameters: {}'.format(grid_search.best_params_))\n    \nelse: \n\n    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n    \n    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 200, \n                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n    \n    \n    # best params\n    #parameters = {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 10}\n\n\n#\nmodel = RandomForestClassifier(**parameters, random_state=0)\n \nmodel.fit(X_train, y_train)\n\n","21985876":"from sklearn.metrics import confusion_matrix as cm\nfrom sklearn.metrics import roc_auc_score\n\ny_pred = model.predict(X_test).astype(int)\nprint(\"confusion matri x: \\n\", cm(y_test, y_pred))\nprint(\"roc_auc_score: \", roc_auc_score(y_test, y_pred))\n \n#    \ndef compute_score(clf, X, y, scoring='accuracy'):\n    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n    return np.mean(xval)\n\nprint('Cross-validation of : {0}'.format(model.__class__))\nscore = compute_score(clf=model, X=X_train, y=y_train, scoring='accuracy')\nprint('CV score = {0}'.format(score))\nprint('****')\n","4c89a6b2":"output = model.predict(test).astype(int)\ndf_output = pd.DataFrame()\naux = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_output['PassengerId'] = aux['PassengerId']\ndf_output['Survived'] = output\ndf_output[['PassengerId','Survived']].to_csv('\/kaggle\/working\/gridsearch_rf.csv', index=False)\n\n","c3695d57":" test.columns","f6cd5924":"X_train \n","b1274315":"# group Rare Labels","18d0990d":"# Ticket","1b26600c":"# Cleaning After train_test_split to estimate mean from X_train only","321dd6ce":"# Fare","f595f52c":"# Embarked","2753d759":"# Title","053e9569":"# Fare Discretation","f9fce203":"# Cleaning Before train_test_split","41810c70":"# Examine Useful Features","56642c3b":"# Age","5deaceb6":"# Fare","be2e6dca":"# Test Run"}}