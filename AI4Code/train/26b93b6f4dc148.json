{"cell_type":{"d4d7c21c":"code","840fe708":"code","5b7ce37e":"code","498ac83d":"code","82469bd1":"code","b2276cd1":"code","1918194d":"code","88ce5f02":"code","e1603d5f":"code","6cd18bb3":"code","1b4fe1d4":"code","f0ae05e0":"markdown","46816740":"markdown","b47fde6e":"markdown","871e12e4":"markdown","211ef651":"markdown","87b36d32":"markdown","67a1aaf0":"markdown","ca9468b9":"markdown"},"source":{"d4d7c21c":"import pandas as pd\nimport numpy as np","840fe708":"train_df = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest_df =pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\nsample_sub = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\ntrain_df.head()","5b7ce37e":"train_df['year'] = pd.to_datetime(train_df['date']).dt.year\ntrain_df['week'] = pd.to_datetime(train_df['date']).dt.week\ntrain_df['day'] = pd.to_datetime(train_df['date']).dt.day\ntrain_df['weekday'] = pd.to_datetime(train_df['date']).dt.dayofweek\n\ntest_df['year'] = pd.to_datetime(test_df['date']).dt.year\ntest_df['week'] = pd.to_datetime(test_df['date']).dt.week\ntest_df['day'] = pd.to_datetime(test_df['date']).dt.day\ntest_df['weekday'] = pd.to_datetime(test_df['date']).dt.dayofweek\n\ntrain_df.drop('date', axis=1, inplace=True)\ntest_df.drop('date', axis=1, inplace=True)\ntrain_df.head()","498ac83d":"train_ohe = pd.get_dummies(train_df, columns = ['country', 'store', 'product'])\ntest_ohe = pd.get_dummies(test_df, columns = ['country', 'store', 'product'])\ntrain_ohe.head()","82469bd1":"train_ohe.drop('row_id', axis=1, inplace=True)\ntest_ohe.drop('row_id', axis=1, inplace=True)\ntrain_ohe.head()","b2276cd1":"train_ohe.drop('num_sold', axis=1, inplace=True)","1918194d":"print('trian shape',train_ohe.shape)\nprint('test shape',test_ohe.shape)","88ce5f02":"# Use PolynomialFeatures in sklearn.preprocesingto create two-way interaction for all features\nfrom itertools import combinations\nfrom sklearn.preprocessing import PolynomialFeatures\n\ndef add_interactions(df):\n\n    # Get feature name\n    combos = list(combinations(list(df.columns), 2))\n    colnames = list(df.columns)+['_'.join(x) for x in combos]\n\n    # Find Interactions\n    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n    df = poly.fit_transform(df)\n    df = pd.DataFrame(df)\n    df.columns = colnames\n\n    # Removing INteractions terms with all 0 values\n    noint_indices = [i for i, x in enumerate(list((df==0).all())) if x]\n    df = df.drop(df.columns[noint_indices], axis=1)\n\n    return df","e1603d5f":"X = add_interactions(train_ohe)\ntest_ohe = add_interactions(test_ohe)\nX.head()","6cd18bb3":"print('X shape: ',X.shape)","1b4fe1d4":"# Use PCA from sklearn.decomposition to find principle component\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=15)\nX_pca = pd.DataFrame(pca.fit_transform(X))\ntest_ohe_pca = pd.DataFrame(pca.fit_transform(test_ohe ))\nX_pca.head()","f0ae05e0":"### Conclusion:\n<b>*It added many extra features to dataset\n<br>71 Features can lead to curse of dimension\n<br>So need to reduce the Dimension using PCA*<\/b>","46816740":"### Importing Libraries","b47fde6e":"### Converting Categorical Features into Numerical By One Hot Encoding","871e12e4":"### Creating Two-Way Interaction between all Features","211ef651":"### Dimensionality Reduction Using PCA","87b36d32":"### Splitting Date Column","67a1aaf0":"### Importing Datasets","ca9468b9":"### Droping Irrelevent Features "}}