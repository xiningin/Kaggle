{"cell_type":{"9819e593":"code","f5c1ccbc":"code","a0168b96":"code","93c2e6a4":"code","e1561e9e":"code","8fb4b582":"code","ab2d4364":"code","c891158d":"code","08950772":"code","8eb89c23":"code","455c77d6":"code","215d99f9":"code","112530de":"code","463d1673":"code","7e67eeb3":"code","ec2e12a4":"code","9f004e95":"code","3b7f9112":"code","e502aa60":"code","01277047":"code","a33c17a5":"code","80a0919f":"code","6db2f44f":"code","755e79fc":"code","55b7593b":"code","e1bd3f93":"code","36ed72b5":"code","ece57681":"code","91858f5a":"code","d79419c3":"code","3a37cd5a":"code","d170d7b2":"code","a80408ab":"code","fed5d705":"markdown","dec3e88f":"markdown","f9ae0da9":"markdown","5aee1d4e":"markdown","8337cc7b":"markdown","2625bb59":"markdown","4d6293b6":"markdown","5440c72c":"markdown","82e81e99":"markdown","c5b74bce":"markdown","0d9d1ee5":"markdown","e0114a39":"markdown","4e117aa8":"markdown","e34b3c79":"markdown","1e7bcf77":"markdown","6ef170a9":"markdown","46c24b96":"markdown","c32a50c3":"markdown","14d09f59":"markdown","2d02f2a3":"markdown"},"source":{"9819e593":"#Import libraries\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f5c1ccbc":"#reading data\ndata= pd.read_csv('\/kaggle\/input\/drug-classification\/drug200.csv')\nprint(\"Dataframe Shape: \",data.shape)","a0168b96":"#check data\ndata.head()","93c2e6a4":"# Target variable analysis\ndata['Drug'].value_counts()","e1561e9e":"#Feature variables analysis\n#Check for missing values\ndata.isnull().sum()","8fb4b582":"data.describe()","ab2d4364":"# col-Age\nsns.distplot(data['Age'])","c891158d":"pd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","08950772":"data.groupby(['Age', 'Drug']).size()","8eb89c23":"# col- Sex\ndata.Sex.value_counts()","455c77d6":"data.groupby(['Sex', 'Drug']).size()","215d99f9":"# col- BP\ndata.BP.value_counts()","112530de":"sns.catplot(x=\"Drug\", y=\"BP\", data=data)","463d1673":"data.groupby(['BP', 'Drug']).size()","7e67eeb3":"# col- Cholesterol\ndata.Cholesterol.value_counts()","ec2e12a4":"data.groupby(['Cholesterol', 'Drug']).size()","9f004e95":"# col- Na_to_K\nprint(data.Na_to_K.nunique())\nsns.distplot(data['Na_to_K'])","3b7f9112":"sns.catplot(x=\"Drug\", y=\"Na_to_K\", data=data)","e502aa60":"# Positive skewness also tells, (mean and median) > mode\n#mean, median, mode: lets check\nprint(data.Na_to_K.mean())\nprint(data.Na_to_K.median())\nprint(data.Na_to_K.mode()[0])","01277047":"#skewness and kurtosis\nprint(\"Skewness= \", data['Na_to_K'].skew())\nprint(\"Kurtosis= \", data['Na_to_K'].kurt())","a33c17a5":"data.Age.max()","80a0919f":"# feature engg\n# Binning Age into Age groups\nbins= [13,18,65,80]\nlabels = ['Teen','Adult','Elderly']\ndata['AgeGroup'] = pd.cut(data['Age'], bins=bins, labels=labels, right=False)\ndata.drop('Age', axis=1, inplace=True)\nprint (data.head())","6db2f44f":"data.AgeGroup.value_counts()","755e79fc":"data['is_Na2K_greater15'] = [1 if x>15 else 0 for x in data['Na_to_K']]","55b7593b":"# Na_to_K groups\ndata['Na_to_K_groups'] = pd.qcut(data['Na_to_K'],\n                            q=[0, .2, .4, .6, .8, 1],\n                            labels=False)\ndata.drop('Na_to_K', axis=1, inplace=True)\ndata.Na_to_K_groups.value_counts()","e1bd3f93":"# Binarize Sex variable\ndata['Sex'].replace(['F','M'],[0,1],inplace=True)","36ed72b5":"#Label encoding\nfrom sklearn import preprocessing \n  \nle = preprocessing.LabelEncoder() \ndata['BP']= le.fit_transform(data['BP']) \ndata['Cholesterol']= le.fit_transform(data['Cholesterol'])\ndata['AgeGroup']= le.fit_transform(data['AgeGroup']) \ndata.head()","ece57681":"data.columns","91858f5a":"#features\nfeatures = ['Sex', 'BP', 'Cholesterol', 'AgeGroup','is_Na2K_greater15', 'Na_to_K_groups']","d79419c3":"#model\nfrom sklearn import tree\nfrom sklearn import ensemble\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import metrics","3a37cd5a":"kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\nX = data[features]\ny = data.Drug\n\nscores= []\ni=1\nfor train_index,test_index in kf.split(X, y):\n    print('Fold no. = ', i)\n    \n    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    #model\n    model1 = tree.DecisionTreeClassifier(random_state=42)\n    model1.fit(x_train, y_train)\n     \n    test_pred= model1.predict(x_test)\n    test_acc = metrics.accuracy_score(y_test, test_pred)\n    print('Accuracy score over test set:',test_acc)\n    scores.append(test_acc)    \n    \n    i+=1\n    \n#mean score\nprint()\nprint('Mean Accuracy for Decision Tree: ', np.mean(scores))","d170d7b2":"#RandomForestClassifier\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\nX = data[features]\ny = data.Drug\n\nscores= []\ni=1\nfor train_index,test_index in kf.split(X, y):\n    print('Fold no. = ', i)\n    \n    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    #model\n    model2 = ensemble.RandomForestClassifier(random_state=42)\n    model2.fit(x_train, y_train)\n     \n    test_pred= model2.predict(x_test)\n    test_acc = metrics.accuracy_score(y_test, test_pred)\n    print('Accuracy score over test set:',test_acc)\n    scores.append(test_acc)    \n    \n    i+=1\n    \n#mean score\nprint()\nprint('Mean Accuracy for Random Forest Classifier: ', np.mean(scores))","a80408ab":"# model-random forest classifier feature importance\nfeat_importances = pd.Series(model2.feature_importances_, index=features)\nfeat_importances.plot(kind='barh')","fed5d705":"### Drug Classification\n\n**Problem Type: MultiClass Classification**\n\nIn this begineer friendly notebook, I have done exploratory data analysis, Modelling using DecisionTreeClassifier and RandomForestClassifier with StratifiedKFold cross validation strategy. \n\nI have noted my observations at many places. Still if you have any queries or suggestions please ask. Kindly Upvote if you find it interesting :)","dec3e88f":"* Skewness > 1, suggests distribution is somewhat moderate to highly skewed (positive)\n* kurtosis < 3, suggests distribution is shorter, tails are thinner than the normal distribution. The peak is lower and broader, which means that data are light-tailed or lack of outliers.\n\n*NOTE: We can apply some kind of transformation technique to make distribution normal.*","f9ae0da9":"* No missing values in data.","5aee1d4e":"* 5 Features: ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']\n* 1 Target Variable: Drug","8337cc7b":"* Out of 200 dataset 198 rows have unique values for Na_to_K ratio, It is not distinctive and useful. We need to group it into different bins in order to make sense from this data.\n* We can observe deviation from normal distribution here. Data is skewed.\n* Positive skewness","2625bb59":"* Most Important feature is is_Na2K_greater15 (Sodium to Potassium ratio) that we created.\n* Second important feature is Blood pressure.\n* Agegroups and Cholesterol level have similar level of importance.","4d6293b6":"* Its distinctive in case of drugC, drugA, drugB","5440c72c":"### PART 3: Modelling & Evaluation","82e81e99":"#### Now the next challenge is how do we group the Sodium to Potassium ratio data. We dont have any distinct groups as Age. \n#### So, I will group the data based on percentile distribution of data.","c5b74bce":"* We have age distribution from 15-74 years. Need to create Age bins for different age groups.","0d9d1ee5":"* BP (Blood Pressure) feature is ordinal categorical variable(having some kind of order between values, LOW, NORMAL, HIGH). Label encoding would be suitable for this.","e0114a39":"* We have imbalanced dataset with 5 classes in target. Need to use StratifiedKFold cross validation strategy.","4e117aa8":"### PART 2: Data Preparation","e34b3c79":"#### We got an Accuracy of 0.96 with Decision Tree (default parameters). But the good thing we avoided Overfitting using StratifiedKFold approach. Ofcourse this accuracy can be improved by hyperparameter tuning and feature selection\/feature engg.\n\n#### Lets try another ML model, RandomForestClassifier.\n","1e7bcf77":"* Cholesterol is again ordinal categorical variable (NORMAL, HIGH). Need to use label encoder.","6ef170a9":"* Cool, when Na_to_K ratio > 15, only DrugY is used. Create new feature.","46c24b96":"#### Cool!!! we got better accuracy 0.96 with RandomForestClassifier.\n\n**Lets plot feature importance and visualize.**","c32a50c3":"#### Thank you for making it till the end.  \n\n#### Kindly upvote and comment if you have any suggestions or queries. Happy learning :)","14d09f59":"* Sex feature is low cardinality nominal variable. Need to use One hot encoding technique here or since we have only two labels, we can binarize it.\n* Almost equal distribution of drugs over both sexes.","2d02f2a3":"### PART 1: Exploratory data analysis"}}