{"cell_type":{"cef71143":"code","3d7264cf":"code","42b37d1e":"code","42d209fd":"code","763d3451":"code","1218cca6":"code","cf9f0795":"code","5d2d2441":"code","dfa2f1a4":"code","8e64e4de":"code","bb054c25":"code","bb477484":"code","e172f49b":"code","7aebfd02":"code","45770746":"code","bee356c1":"code","da0a47cd":"code","c6c2544e":"code","5e8741c4":"code","d2163e76":"code","c8b6e18d":"code","a410815c":"code","3e1951e8":"code","d4fef223":"code","4ac4f736":"code","233b9134":"code","142b41b3":"code","87b93fd7":"code","a617a7d1":"code","25616d62":"code","f4a52932":"code","04edd9ca":"code","72befa34":"code","c6ad96b0":"code","fb2b768d":"code","e9abe4fc":"code","306113e7":"code","42d516a6":"code","99781e21":"code","bbc4bec4":"code","20db4e63":"code","5984b6ff":"code","31a9dc86":"code","d84cc83c":"code","7c44226d":"code","b42d5564":"code","2a8c6704":"markdown","c3080681":"markdown","39e659c2":"markdown","7229512d":"markdown","ffe022ec":"markdown","64b9980c":"markdown","0b29f382":"markdown","bd43b13d":"markdown"},"source":{"cef71143":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3d7264cf":"import imageio\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image, ImageOps, ImageFilter\nimport scipy.ndimage as ndi\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing import image\nfrom keras.utils import plot_model","42b37d1e":"jpg_counter = 0\npng_counter = 0\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename[-3:] == \"jpg\":\n            jpg_counter = jpg_counter + 1\n        elif filename[-3:] == \"png\":\n            png_counter = png_counter + 1\n\nprint(\"Number of jpg: {}\\nNumber of png: {}\".format(jpg_counter, png_counter))","42d209fd":"dirname = '\/kaggle\/input\/chessman-image-dataset\/Chessman-image-dataset\/Chess'\ndir_chess_folders = os.listdir(dirname)\ndir_chess_paths = [os.path.join(dirname, path) for path in dir_chess_folders]","763d3451":"dir_chess_paths","1218cca6":"os.mkdir('\/kaggle\/working\/chess')\n\nos.mkdir('\/kaggle\/working\/chess\/bishop')\nos.mkdir('\/kaggle\/working\/chess\/knight')\nos.mkdir('\/kaggle\/working\/chess\/queen')\nos.mkdir('\/kaggle\/working\/chess\/rook')\nos.mkdir('\/kaggle\/working\/chess\/king')\nos.mkdir('\/kaggle\/working\/chess\/pawn')","cf9f0795":"dirname_work = '\/kaggle'\ndir_work = os.path.join('\/kaggle', 'working')\ndir_work_chess = os.path.join(dir_work, 'chess')\n\n\nbishop_path_work = os.path.join(dir_work_chess, 'bishop')\n\nknight_path_work = os.path.join(dir_work_chess, 'knight')\n\nqueen_path_work = os.path.join(dir_work_chess, 'queen')\n\nrook_path_work = os.path.join(dir_work_chess, 'rook')\n\nking_path_work = os.path.join(dir_work_chess, 'king')\n\npawn_path_work = os.path.join(dir_work_chess, 'pawn')\n","5d2d2441":"dir_chess_folders_work = os.listdir(dir_work_chess)\ndir_chess_paths_work = [os.path.join(dir_work_chess, path) for path in dir_chess_folders_work]","dfa2f1a4":"def plot_imgs(item_dir, title=\" \", num_imgs=4, cmap='viridis'):\n    all_item_dirs = os.listdir(item_dir)\n    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_imgs]\n\n    plt.figure(figsize=(15, 15))\n    for idx, img_path in enumerate(item_files):\n        plt.subplot(8, 8, idx+1)\n        img = plt.imread(img_path, 0)\n        plt.title(title)\n        plt.imshow(img, cmap=cmap)\n\n    plt.tight_layout()","8e64e4de":"for path in dir_chess_paths:\n    head, tail = os.path.split(path)\n    plot_imgs(path, tail, 8)","bb054c25":"chess_dic = {}\nfor path in dir_chess_paths:\n    head, tail = os.path.split(path)\n    chess_dic[tail] = len(os.listdir(path))","bb477484":"label_list = [\"{}: {}\".format(key, chess_dic[key]) for key in chess_dic]","e172f49b":"plt.figure(figsize=(8, 8))\nplt.bar(range(len(chess_dic)), list(chess_dic.values()), color=\"green\")\nplt.xticks(range(len(chess_dic)), list(label_list))\nplt.show();","7aebfd02":"def plot_img_hist(item_dir, num_img=6):\n    all_item_dirs = os.listdir(item_dir)\n    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_img]\n\n    #plt.figure(figsize=(10, 10))\n    for idx, img_path in enumerate(item_files):\n        fig1 = plt.figure(idx,figsize=(10, 10))\n        fig1.add_subplot(2, 2, 1)\n        img = mpimg.imread(img_path, 0)\n        plt.imshow(img)\n        fig1.add_subplot(2, 2, 2)\n        plt.hist(img.ravel(),bins=256, fc='k', ec='k')\n\n    plt.tight_layout()","45770746":"for path in dir_chess_paths:\n    plot_img_hist(path, 8)","bee356c1":"def image_binarization(path_from, path_to):\n\n    i=1\n    files = os.listdir(path_from)\n    for file in files: \n        try:\n            file_dir = os.path.join(path_from, file)\n            file_dir_save = os.path.join(path_to, file)\n            img = Image.open(file_dir)\n            img = img.convert(\"1\")\n            img.save(file_dir_save) \n            i=i+1\n        except:\n            continue","da0a47cd":"image_binarization(dir_chess_paths[0], bishop_path_work)","c6c2544e":"image_binarization(dir_chess_paths[1], king_path_work)","5e8741c4":"image_binarization(dir_chess_paths[2], rook_path_work)","d2163e76":"image_binarization(dir_chess_paths[3], pawn_path_work)","c8b6e18d":"image_binarization(dir_chess_paths[4], queen_path_work)","a410815c":"image_binarization(dir_chess_paths[5], knight_path_work)","3e1951e8":"for path in dir_chess_paths_work:\n    head, tail = os.path.split(path)\n    plot_imgs(path, tail, 8, 'binary')","d4fef223":"def image_median_filtering(path_from, path_to, window_size=3):\n\n    i=1\n    files = os.listdir(path_from)\n    for file in files: \n        try:\n            file_dir = os.path.join(path_from, file)\n            file_dir_save = os.path.join(path_to, file)\n            img = Image.open(file_dir)\n            img = img.filter(ImageFilter.MedianFilter(window_size))\n            img.save(file_dir_save) \n            i=i+1\n        except:\n            continue","4ac4f736":"image_median_filtering(bishop_path_work, bishop_path_work)","233b9134":"image_median_filtering(king_path_work, king_path_work)","142b41b3":"image_median_filtering(rook_path_work, rook_path_work)","87b93fd7":"image_median_filtering(pawn_path_work, pawn_path_work)","a617a7d1":"image_median_filtering(queen_path_work, queen_path_work)","25616d62":"image_median_filtering(knight_path_work, knight_path_work)","f4a52932":"for path in dir_chess_paths_work:\n    head, tail = os.path.split(path)\n    plot_imgs(path, tail, 8, 'binary')","04edd9ca":"for path in dir_chess_paths_work:\n    plot_img_hist(path, 4)","72befa34":"img_size_h = 300\nimg_size_w = 300","c6ad96b0":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.3,\n    rotation_range=90,\n    width_shift_range=0.6,\n    height_shift_range=0.6,\n    shear_range=3, \n    zoom_range=50,\n    horizontal_flip=True,\n    vertical_flip=True)","fb2b768d":"input_shape = (img_size_h, img_size_w, 1) ","e9abe4fc":"batch_size = 16\ntrain_generator = train_datagen.flow_from_directory(\n    dir_work_chess,\n    target_size=(img_size_h, img_size_w),\n    color_mode='grayscale',\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True, #we shuffle our images for better performance\n    seed=8)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    dir_work_chess,\n    target_size=(img_size_h, img_size_w),\n    color_mode='grayscale',\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=True,\n    seed=7)","306113e7":"model = Sequential([\n\n    Conv2D(16, (5,5), input_shape=input_shape, padding='same', activation='relu'),\n    Conv2D(32, (3,3), padding='same', activation='relu'),\n    Conv2D(32, (3,3), padding='same', activation='relu'),\n\n    Conv2D(32, (3,3), padding='same', activation='relu'),\n    MaxPool2D((2,2)),\n    BatchNormalization(momentum=0.3),\n    Dropout(0.2),\n    \n    Conv2D(32, (5,5), padding='same', activation='relu'),    \n    Conv2D(64, (3,3), padding='same', activation='relu'),\n    Conv2D(64, (3,3), padding='same', activation='relu'),\n\n    Conv2D(64, (3,3), padding='same', activation='relu'),\n    MaxPool2D((2,2)),\n    BatchNormalization(momentum=0.3),\n    Dropout(0.2),\n\n    \n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.4),\n    Dense(6, activation='softmax')\n    \n    \n])","42d516a6":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","99781e21":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0005) \ncallback = [learning_rate_reduction]","bbc4bec4":"history = model.fit_generator(\n    train_generator,\n    epochs=500,\n    validation_data=validation_generator,\n    callbacks = callback\n    )","20db4e63":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","5984b6ff":"# https:\/\/gist.github.com\/RyanAkilos\/3808c17f79e77c4117de35aa68447045\nnum_of_test_samples = 162 \n#Confution Matrix and Classification Report\nY_pred = model.predict_generator(validation_generator, num_of_test_samples \/\/ batch_size+1)\ny_pred = np.argmax(Y_pred, axis=1)\n\nmatrix1 = confusion_matrix(validation_generator.classes, y_pred)\n\n","31a9dc86":"# Using: https:\/\/getaravind.com\/blog\/confusion-matrix-seaborn-heatmap\/\n\nsns.heatmap(matrix1,annot=True,cbar=False);\nplt.ylabel('True Label');\nplt.xlabel('Predicted Label');\nplt.title('Confusion Matrix');","d84cc83c":"print('\\nClassification Report')\ntarget_names = ['Bishop',\n                 'King',\n                 'Rook',\n                 'Pawn',\n                 'Queen',\n                 'Knight']\nclass_report = classification_report(validation_generator.classes, y_pred, target_names=target_names)\nprint(class_report)","7c44226d":"!ls","b42d5564":"import shutil\nshutil.rmtree(\"\/kaggle\/working\/chess\")","2a8c6704":"We can see that there are PNG and JPG images. Let's see how many.","c3080681":"Now we can prepare directories for image preprocessing.","39e659c2":"For this analisys I used a lot of my code from \"X-ray - classification and visualisation\" kernel.\nhttps:\/\/www.kaggle.com\/wojciech1103\/x-ray-classification-and-visualisation","7229512d":"I'm curious how a model will deal with distinguishing King and Queen. They are often very similar...","ffe022ec":"Let's see how histograms look like. ","64b9980c":"Ok, we can see that pictures have various sizes. Now, let's see how many pictures each class has.","0b29f382":"I don't think that it will cause troubles but it is worth to remember. \nAnd now we will see what images we have here.","bd43b13d":"I think as a next step I'm going to work on converting all images into grayscale and equalizing all histograms. "}}