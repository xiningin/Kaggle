{"cell_type":{"3ce707ea":"code","ed3b0e2a":"code","72cf1520":"code","72a54c71":"code","1a601379":"code","0172d24e":"code","11178239":"code","230485aa":"code","fa4ffd8e":"code","d7f65d0d":"code","990043fc":"code","454e7cc2":"code","c7e21327":"code","0a7c799b":"code","df6b45fe":"code","6345876e":"code","1e14e325":"code","f7b5817b":"code","691418d1":"code","ac9aab04":"code","f16bcc59":"code","2d542325":"code","f402f47c":"code","2a199fba":"code","532ad380":"code","530b7615":"code","63141660":"code","53648ce1":"code","157ede52":"code","097bd799":"code","3da4a10e":"code","ef3f1c6e":"code","cb91d1c2":"code","9a12947e":"code","3c4f2e52":"code","a78c6b2e":"code","10b5c468":"code","ad7409c2":"code","bafeff4b":"code","c42d1022":"code","f5668194":"code","e8b4ab1c":"code","73a3ce80":"code","0267fee7":"code","56c0c7a5":"code","a46e07c3":"markdown","6eaa9ea4":"markdown","b974d505":"markdown","78ad4082":"markdown","d8ca25bd":"markdown","c306e110":"markdown","d0aa92d7":"markdown","c1aa0c27":"markdown","55dbfed5":"markdown","281809b2":"markdown","7076ecab":"markdown","efc6f26b":"markdown","30f29ea8":"markdown","7eddd748":"markdown","a02f52e8":"markdown","7ef04f96":"markdown","ea8be1ac":"markdown","f6b95f15":"markdown","e52591ce":"markdown","0043e6e2":"markdown","0e6194e7":"markdown","fdbe1958":"markdown","e0bf6873":"markdown","eef70b34":"markdown","6c1170f7":"markdown","bd611e96":"markdown","4e93c55e":"markdown","9e0339a3":"markdown","a09794c2":"markdown","8e1fbbe1":"markdown","e96418b4":"markdown","464225be":"markdown","89391630":"markdown","6eeb005a":"markdown","632513dc":"markdown","73633a34":"markdown","30f528a4":"markdown","39e96d80":"markdown","4f2d9d59":"markdown","f3b81282":"markdown","7a5fb226":"markdown","9adfd6e5":"markdown","06b57b54":"markdown","5f6511ef":"markdown","abe26e03":"markdown","3ce5df0a":"markdown","f84f57cc":"markdown","ba6bac3a":"markdown","82d48941":"markdown","97461a8d":"markdown"},"source":{"3ce707ea":"pip install vaderSentiment","ed3b0e2a":"#import comet_ml in the top of your file\n#from comet_ml import Experiment\n\n#Inspecting\nimport numpy as np \nimport pandas as pd \npd.set_option('display.max_colwidth', -1)\nimport emoji\nimport re\nimport string\n\n\n#Visuals\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom wordcloud import WordCloud\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Text preprocessing and cleaning\nimport nltk\nfrom nltk.tokenize import word_tokenize, TreebankWordTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.probability import FreqDist\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\n#Modelling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score,KFold\nfrom sklearn.metrics import fbeta_score, make_scorer\n\n\n#Metrics for analysis\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,f1_score,classification_report,confusion_matrix,accuracy_score","72cf1520":"train = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\ntest = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv')","72a54c71":"train.head()","1a601379":"test.head()","0172d24e":"train.info()","11178239":"test.info()","230485aa":"#bar graph plot to show the count for each sentiment class \ncnt_srs = train['sentiment'].value_counts()\n\nplt.figure(figsize=(6,7))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8,palette='GnBu_d')\nplt.title('Number of tweets for each sentiment class', fontsize=14)\nplt.ylabel('Number of Tweets', fontsize=12)\nplt.xlabel('Sentiment Class', fontsize=12)\nplt.ylabel(\"Sentiment Count\")\nplt.xticks([0,1,2,3],['Anti(-1)','Neutral(0)','Pro(1)','News(2)']);\nplt.show()\n","fa4ffd8e":"#calc total number of emojis in the dataset and total number of emojis in each sentiment class.\nno_emoji=train['message'].apply(lambda x: emoji.demojize(x)).apply(lambda x: len(re.findall(r':[a-z_&]+:',x))).sum()\nno_emoji1=train['message'].apply(lambda x: emoji.demojize(x)).apply(lambda x: len(re.findall(r':[a-z_&]+:',x))).groupby(train['sentiment']).sum()\nprint(\"The total number of emojis in the dataset is : \" + str(no_emoji)+\"\\n\")\nprint(\"The no. of emojis in each sentiment :\")\nprint(no_emoji1)","d7f65d0d":"#find the total number of hashtags as well as total nuumber of hashtags for each sentiment class.\nno_hash=train['message'].apply(lambda x: len(re.findall(r'#\\w+',x))).sum()\nno_hash1=train['message'].apply(lambda x: len(re.findall(r'#\\w+',x))).groupby(train['sentiment']).sum()\nprint(\"The number of hashtags in the dataset is : \" + str(no_hash)+\"\\n\")\nprint(\"The no. of hashtags in each sentiment :\")\nprint(no_hash1)","990043fc":"#calc the total number of urls in dataset and total number of urls for each sentiment class.\nnum_url=train['message'].apply(lambda x: (len(re.findall(r'http.?:\/\/[^\\s]+[\\s]?',x)))).sum()\nnum_url1=train['message'].apply(lambda x: (len(re.findall(r'http.?:\/\/[^\\s]+[\\s]?',x)))).groupby(train['sentiment']).sum()\nprint(\"The number of urls in the dataset is : \" + str(num_url)+\"\\n\")\nprint(\"The no. of urls in each sentiment :\")\nprint(num_url1)","454e7cc2":"word_df= pd.DataFrame()\nword_df['words'] = train['message'].apply(lambda x: len(re.findall(r'\\w+',x)))\nword_df['sentiment'] = train.sentiment\nneg = word_df[word_df['sentiment']==-1]\nneu = word_df[word_df['sentiment']==0]\npro = word_df[word_df['sentiment']==1]\nnews = word_df[word_df['sentiment']==2]","c7e21327":"fig, axis = plt.subplots(ncols=2,nrows=2,figsize=(11,11))\nfig.suptitle('Distribution of words in each sentiment class', fontsize=16)\n\naxis[1,1].hist(neg['words'], bins=12,rwidth=0.95)\naxis[1,1].set_title('Anti(-1)')\naxis[1,1].set_xlabel('Word Count')\naxis[1,1].set_ylabel('Frequency')\n\naxis[1,0].hist(neu['words'], bins=12,rwidth=0.95)\naxis[1,0].set_title('Neutral(0)')\naxis[1,0].set_ylabel('Frequency')\naxis[1,0].set_xlabel('Word Count')\n\naxis[0,1].hist(pro['words'], bins=12,rwidth=0.95)\naxis[0,1].set_title('Pro(1)')\naxis[0,1].set_ylabel('Frequency')\naxis[0,1].set_xlabel('Word Count')\n\naxis[0,0].hist(news['words'], bins=12,rwidth=0.95)\naxis[0,0].set_title('News(2)')\naxis[0,0].set_ylabel('Frequency')\naxis[0,0].set_xlabel('Word Count')\n\nplt.show()","0a7c799b":"print('Average no. of words for each sentiment class:')\nprint('Anti(-1): '+str(round(neg['words'].mean(),2)))\nprint('Neutral(0): '+str(round(neu['words'].mean(),2)))\nprint('Pro(1): '+str(round(pro['words'].mean(),2)))\nprint('News(2): '+str(round(news['words'].mean(),2)))","df6b45fe":"def vader_score(df):\n    \"\"\"\n    Computes the compund score of each tweet using Vader Analysis and converts the score\n    into a string representing the sentiment which is then added to the tweet.\n    \n    Parameters\n    ------------\n    df: dataframe\n        Takes in a dataframe\n        \n    Output\n    ------------\n    output: dataframe\n        Returns a dataframe\n    \"\"\"\n    analyser = SentimentIntensityAnalyzer()\n    com_score=[]\n    for sentence in train['message']:\n        score = analyser.polarity_scores(sentence)['compound']\n        if score >= 0.05:\n            com_score.append(' Positive')\n        elif score <= -0.05 : \n            com_score.append(' Negative')\n        else:\n            com_score.append(' Neutral')\n    df['compound score'] = pd.DataFrame(com_score)\n    return df\n\ntrain = vader_score(train)\ntest = vader_score(test)","6345876e":"def correct_spelling(text):\n    \n    \"\"\"\n    This function takes a string of text as input. It corrects the spelling by applying textblob's correction\n    method and returns the modified text string.\n    \"\"\"\n    \n    # instantiate TextBlob object\n    blob = TextBlob(text)\n    \n    # correct spelling and return modified string\n    return str(blob.correct())","1e14e325":"def contn_replace(df):\n    \n    \"\"\"\n    Expand contraction words in a dataframe\n    \n    Parameters\n    ------------\n    df: dataframe\n        Takes in a dataframe\n        \n    Output\n    ------------\n    output: dataframe\n        Returns a dataframe\n    \"\"\"\n    \n    df['message'] = df['message'].str.replace(r'\\'ve', ' have')\n    df['message'] = df['message'].str.replace(r'\\'ll', ' will')\n    df['message'] = df['message'].str.replace(r'\\'d', ' would')\n    df['message'] = df['message'].str.replace(r'n\\'t', ' not')\n    df['message'] = df['message'].str.replace(r'\\'s', ' is')\n    df['message'] = df['message'].str.replace(r'\\'m', ' am')\n    df['message'] = df['message'].str.replace(r'\\'re', ' are')\n    \n    return df\n\ntrain=contn_replace(train)\ntest=contn_replace(test)","f7b5817b":"def url_replace(df):\n    \"\"\"\n    Replace url links in a dataframe with the string 'url'\n    \n    Parameters\n    ------------\n    df: dataframe\n        Takes in a dataframe\n        \n    Output\n    ------------\n    output: dataframe\n        Returns a dataframe\n    \"\"\"\n    df['message'] = df['message'].str.replace(r'http.?:\/\/[^\\s]+[\\s]?', 'url ')\n    return df\n\ntrain=url_replace(train)\ntest=url_replace(test)","691418d1":"def emoji_rep(df):\n    \"\"\"\n    Replace emoticons with the word 'emoji'\n    \n    Parameters\n    ------------\n    df: dataframe\n        Takes in a dataframe\n        \n    Output\n    ------------\n    output: dataframe\n        Returns a dataframe\n    \"\"\"\n    df['message']= df['message'].apply(lambda x: emoji.demojize(x)).apply(lambda x: re.sub(r':[a-z_&]+:','emoji ',x))\n    return df\n\ntrain=emoji_rep(train)\ntest=emoji_rep(test)","ac9aab04":"def noise_removal(df):\n    \"\"\"\n    Removes noise such as special characters from text.\n    \n    Parameters\n    ------------\n    df: dataframe\n        Takes in a dataframe\n        \n    Output\n    ------------\n    output: dataframe\n        Returns a dataframe\n    \"\"\"\n    \n    df['message'] = df['message'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+','',x)) #removes unicode characters\n    df['message'] = df['message'].str.replace(r\"[',.():|-]\", \" \")                #removes some special characters\n    df['message'] = df['message'].str.replace(r'^(RT|rt)( @\\w*)?', '')           #removes twitter handles\n    df['message'] = df['message'].apply(lambda x: re.sub(r'\\d','',x))            #removes digits\n    df['message'] = df['message'].apply(lambda x: re.sub('[^a-zA-z\\s]','',x))    #removes punctuation\n    df['message'] = df['message'].str.lower()                                    #converts text to lowercase\n    return df\n\ntrain=noise_removal(train)\ntest=noise_removal(test)","f16bcc59":"#initalize a tokenizer and lemmatizer object and apply it to on the cleaned tweets\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.stem import WordNetLemmatizer\nget_tokens = TweetTokenizer()\nget_lemmas = WordNetLemmatizer()\n\ndef tokenize_lemmatize(df):\n    \"\"\"\n    Tokenize and Lemmatize the message column in the dataframe\n    \n    Parameters\n    ------------\n    df: dataframe\n        Takes in a dataframe\n        \n    Output\n    ------------\n    output: dataframe\n        Returns a dataframe\n    \"\"\"\n    df['message'] = df.apply(lambda row: [get_lemmas.lemmatize(w) for w in get_tokens.tokenize(row['message'])], axis=1)\n    \n    return df\n\ntrain=tokenize_lemmatize(train)\ntest=tokenize_lemmatize(test)","2d542325":"stopwords=[ 'i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself','yourselves','he','him','his','himself','she','her','hers','herself','it','itself','they','them','their','theirs','themselves','what','which','who','whom','this','that','these','those','am','is','are','was','were','be','been','being','have','has','had','having','do','does','did','doing','a','an','the','and','but','if','or','because','as','until','while','of','at','by','for','with','about','between','into','through','during','before','after','above','below','to','from','up','down','in','out','on','off','over','under','again','further','then','once','here','there','when','where','why','how','all','any','both','each','few','more','most','other','some','such','only','own','same','so','than','too','very','s','t','can','will','just','should','now','d','ll','m','o','re','ve','y','rt','u','doe','going','ha','wa','#','&','%','+','v','*','$','http',';','\/']","f402f47c":"#remove the stop words from our data\ndef remove_stopwords(df,stoplist):\n    \"\"\"\n    Remove words contained in a list from a text column.\n    \n    Parameters\n    ------------\n    df: dataframe\n        Takes in a dataframe\n    stoplist : list   \n        Takes in a list of words\n        \n    Output\n    ------------\n    output: dataframe\n        Returns a dataframe\n    \"\"\"\n    df['message']=df['message'].apply(lambda x: [item for item in x if item not in stoplist])\n    return df\n\ntrain=remove_stopwords(train,stopwords)\ntest=remove_stopwords(test,stopwords)","2a199fba":"#join words in a list to make it a string line\ntrain['message']=train['message'].apply(lambda x: ' '.join(str(v) for v in x ))\ntest['message']=test['message'].apply(lambda x: ' '.join(str(v) for v in x ))","532ad380":"#convert messages in df into one string for each sentiment \nanti_str =' '.join([line for line in train['message'][train['sentiment'] == -1]])\nneu_str =' '.join([line for line in train['message'][train['sentiment'] == 0]])\npro_str =' '.join([line for line in train['message'][train['sentiment'] == 1]])\nnews_str =' '.join([line for line in train['message'][train['sentiment'] == 2]])","530b7615":"#Create wordcloud for each sentiment \nfig, axis = plt.subplots(nrows=2,ncols=2,figsize=(18,12))\nanti_wc = WordCloud(width=900, height=600, background_color='black', colormap='summer').generate(anti_str)\n\naxis[0,0].imshow(anti_wc)\naxis[0,0].set_title('Anti(-1)',fontsize=16)\naxis[0,0].axis(\"off\") \n\nneu_wc = WordCloud(width=900, height=600, background_color='black', colormap='summer').generate(neu_str)\naxis[0,1].imshow(neu_wc)\naxis[0,1].set_title('Neutral(0)',fontsize=16)\naxis[0,1].axis(\"off\") \n\npro_wc = WordCloud(width=900, height=600, background_color='black', colormap='summer').generate(pro_str)\naxis[1,0].imshow(pro_wc)\naxis[1,0].set_title('Pro(1)',fontsize=16)\naxis[1,0].axis(\"off\") \n\nnews_wc = WordCloud(width=900, height=600, background_color='black', colormap='summer').generate(news_str)\naxis[1,1].imshow(news_wc)\naxis[1,1].set_title('News(2)',fontsize=16)\naxis[1,1].axis(\"off\") \n\nplt.show()","63141660":"#select the columns that are going to be used to train the models\nX = train['message']\ny = train['sentiment']\n\ny_df = test['message']","53648ce1":"#split train dataset into train and test components\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","157ede52":"#Creating our vectorizer and applying it to our data\nvectorizer=TfidfVectorizer(min_df=1, max_df=0.9, stop_words='english', decode_error='ignore')\nX_train=vectorizer.fit_transform(X_train)\nX_test=vectorizer.transform(X_test)\nX_val = vectorizer.fit_transform(y_df)","097bd799":"#Multinomial Naive Bayes\nmnb = MultinomialNB()\nmnb.fit(X_train,y_train)\nprediction_mnb = mnb.predict(X_test)\n\nprint(classification_report(prediction_mnb,y_test))\nprint(\"Accuracy score: \"+str(accuracy_score(prediction_mnb,y_test)))\n\n#multinb_f1 = round(f1_score(y_val, NB_predictions, average='weighted'),2)\n","3da4a10e":"#Random Forest Classifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train,y_train)\nprediction_rfc = rfc.predict(X_test)\n\nprint(classification_report(prediction_rfc,y_test))\nprint(\"Accuracy score: \"+str(accuracy_score(prediction_rfc,y_test)))","ef3f1c6e":"#Logistic regression\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\nprediction_lr = lr.predict(X_test)\n\nprint(classification_report(y_test,prediction_lr))\nprint(\"Accuracy score: \"+str(accuracy_score(y_test,prediction_lr)))","cb91d1c2":"# Linear SVC\nlsvc = LinearSVC()\nlsvc.fit(X_train,y_train)\nprediction_lsvc = lsvc.predict(X_test)\n\nprint(classification_report(y_test,prediction_lsvc))\nprint(\"Accuracy score: \"+str(accuracy_score(y_test,prediction_lsvc )))","9a12947e":"#Gradient Boosting Classifier \ngbc = GradientBoostingClassifier(n_estimators=200,max_depth=6,random_state=10)\ngbc.fit(X_train,y_train)\nprediction_gbc = gbc.predict(X_test)\n\nprint(classification_report(y_test,prediction_gbc))\nprint(\"Accuracy score: \"+str(accuracy_score(y_test,prediction_gbc)))","3c4f2e52":"#K-Nearest Neighbours\nknc = KNeighborsClassifier(n_neighbors = 10)\nknc.fit(X_train,y_train)\nprediction_knc = knc.predict(X_test)\n\nprint(classification_report(y_test,prediction_knc))\nprint(\"Accuracy score: \"+str(accuracy_score(y_test,prediction_knc)))","a78c6b2e":"#Tuning parameters for Linear Support Vector Classifier \nC_list = [0.1, 0.5, 0.75, 1, 5, 10, 25]\npenalty_list = ['l1','l2']\nloss =['hinge','squared_hinge']\n   \nscorer = make_scorer(f1_score, average = 'weighted')    \n   \nparameters = {'C':C_list,'penalty': penalty_list,'loss' : loss}\n#fitting model with new parameters\ntune = GridSearchCV(lsvc, parameters, scoring = scorer, cv=5, n_jobs=-1, verbose=3)\nlsvc_tune = tune.fit(X_train,y_train)\nprediction_lsvc_tune = lsvc_tune.predict(X_test)\n","10b5c468":"#Displaying best parameters\nprint(\"Best parameters set:\")\nprint(lsvc_tune.best_estimator_)\n#showing summary statisitics \nprint(classification_report(y_test,prediction_lsvc_tune))\nprint(\"Accuracy score: \"+str(accuracy_score(y_test,prediction_lsvc_tune)))","ad7409c2":"#choosing parameters and it's values to test\nC_list = [0.01, 0.1, 0.5, 0.75, 1, 5, 10, 25]\npenalty_list = ['l1','l2']\nrandom_state = ['random_state', 1, 10]\ntol = ['tol', 1e-10, 1]\n    \nscorer = make_scorer(f1_score, average = 'weighted')\n    \nparameters = {'C':C_list,'penalty': penalty_list,\n              'random_state' : random_state,'tol': tol}\n#fitting model with new parameters\ntune = GridSearchCV(lr, parameters, scoring = scorer,cv=5, n_jobs=-1, verbose=3)\nlr_tune=tune.fit(X_train,y_train)\nprediction_lr_tune = lr_tune.predict(X_test)","bafeff4b":"#Displaying best parameters\nprint(\"Best parameters set:\")\nprint(lr_tune.best_estimator_)\n#showing summary statisitics \nprint(classification_report(y_test,prediction_lr_tune))\nprint(\"Accuracy score: \"+str(accuracy_score(y_test,prediction_lr_tune)))\n","c42d1022":"#Calculating our weighted f1 scores for each model tested\nmnbf1 = round(f1_score(y_test,prediction_mnb,average='weighted'),3)\nrfcf1 = round(f1_score(y_test,prediction_rfc,average='weighted'),3)\nlrf1 = round(f1_score(y_test,prediction_lr,average='weighted'),3)\nlsvcf1 = round(f1_score(y_test,prediction_lsvc,average='weighted'),3)\ngbcf1 = round(f1_score(y_test,prediction_gbc,average='weighted'),3)\nkncf1 = round(f1_score(y_test,prediction_knc,average='weighted'),3)","f5668194":"#Visualising and comparing the weighted f1 scores of the various models\nplt.subplots(figsize=(12, 6))\nx_var = ['Multinomial Naive Bayes','Random Forest Classifier','Logistic Regression','Linear SVC','Gradient Boosting','KN Neighbors Classifier']\ny_var = [mnbf1,rfcf1,lrf1,lsvcf1,gbcf1,kncf1]\nax = sns.barplot(x=x_var,y=y_var,palette='GnBu_d')\nplt.title('Weighted F1 score for each model',fontsize=14)\nplt.xticks(rotation=90)\nplt.xlabel('')\nplt.ylabel('Weighted F1 score')\nfor a in ax.patches:\n    ax.text(a.get_x() + a.get_width()\/2, a.get_y() + a.get_height(),round(a.get_height(),3),fontsize=12, ha=\"center\", va='bottom')\n    \nplt.show()","e8b4ab1c":"#calculating new f1 scores for the trained models\nlsvcf1_tuned = round(f1_score(y_test,prediction_lsvc_tune,average='weighted'),3)\nlrf1_tuned = round(f1_score(y_test,prediction_lr_tune,average='weighted'),3)","73a3ce80":"#Visualising new weighted F1 scores after tuning\nx = [u'Linear SVC', u'Linear SVC tuned', u'Logistic Regression', u'Logistic Regression Tuned']\ny = [lsvcf1, lsvcf1_tuned, lrf1, lrf1_tuned]\n\nfig, ax = plt.subplots(figsize=(12, 5))    \nwidth = 0.5 # the width of the bars \nind = np.arange(len(y))  # the x locations for the groups\nax.barh(ind, y, width, color=\"skyblue\")\nax.set_yticks(ind+width\/2)\nax.set_yticklabels(x, minor=False)\nplt.title('Comparison of weighted F1 scores before and after tuning')\nplt.xlabel('Weighted F1 Score')\nplt.ylabel('Models')\nfor i, v in enumerate(y):\n    ax.text(v , i , str(v), color='blue', fontweight='bold')\nplt.show()  ","0267fee7":"train1 = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\ntest1 = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv')\n\nX1 = train1['message']\ny1 = train1['sentiment']\n\ny_df1 = test1['message']\n\nvectorizer=TfidfVectorizer(min_df=1, max_df=0.9, stop_words='english', decode_error='ignore')\nX1=vectorizer.fit_transform(X1)\nX_val = vectorizer.transform(y_df1)\n\nlr_best=LogisticRegression(C=5, random_state=1, tol=1e-10)\nlr_best_model = lr_best.fit(X1,y1)\npred_lr_best = lr_best_model.predict(X_val)","56c0c7a5":"my_submission = pd.DataFrame({'tweetid': test1['tweetid'], 'sentiment': pred_lr_best})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('lr_best.csv', index=False)","a46e07c3":"<a id='model_performance'><\/a>\n## 9.Model Performance\n[Back to Table of Contents](#Table_Contents)<br><br>\nLet us visualise the weighted F1 scores of our models to gain insights into our models performance.","6eaa9ea4":"We can notice after applying parameter tuning that the weighted F1 scores increase for the models above. We notice a larger increase in the Logistic Regression model than the Linear SVC.","b974d505":"# <h1><center> Climate Change Belief Analysis<\/center><\/h1>","78ad4082":"#### Tokenization and lemmatization \nAfter cleaning our data we can now move on to tokenizing and lemmatizing. This is to ensure that the words in the message are in it's base form which will allow the models to better understand them. With TweetTokenizer we are able to convert the stream of words into small tokens so that we can analyse.","d8ca25bd":"<a id='modelling'><\/a>\n## 7.Modelling\n[Back to Table of Contents](#Table_Contents)<br><br>\nIn this section we will be building various models, that we will use to help us predict our sentiments.<br>\nWe have included a short description of each model and will summarize our findings in the next section.<br> \n<br><b>Calssifer models being used:<\/b><br>\n* Multinomial Naive Bayes \n* Random Forest Classifer\n* Logistic Regresion\n* Linear SVC\n* Gradient Boosting Classifier\n* K Nearest Neighbours  \n","c306e110":"In this section we present the various variables found in our datasets.\n<br><br><b>Variable definitions:<\/b><br><b>sentiment:<\/b> Sentiment of the tweet<br><b>message:<\/b> Tweet body<br><b>tweetid:<\/b> Unique number identifying the tweet<br><br>\nThese variables are found in both the train and test datasets, the only difference being that the test\ndataset does not include the sentiment as that is what we are going to predict.<br>\nBelow we shall look at what each <b>dataset looks like<\/b>, it's <b>data types<\/b> and <b>summary statistics<\/b>.","d0aa92d7":"#### Dealing with urls in tweets\nWe will replace the url contained in tweets with the string 'url'. This is done to keep the value of the url as it relates to sentiment noticed in the EDA. ","c1aa0c27":"The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected.","55dbfed5":"<a id='conclusion'><\/a>\n## 10.Conclusion\n[Back to Table of Contents](#Table_Contents) ","281809b2":"#### Expanding Contractions\nLet's start by dealing with the commonly used contracted words such as \"didn't\".<br> \nWe will do this by removing the contraction part and adding the relevant word.","7076ecab":"#### Linear SVC ","efc6f26b":"### Predictions for Submission  ","30f29ea8":"From the above bar graph we notice that there seems to be an imbalance of data since more than 50 percent of the datapoints are being classfied as sentiment (1)Pro.<br>At a later stage we will look at ways in which to solve this issue. ","7eddd748":"<b>Parameter Tuning<\/b><br>\nHere we look at improving some of our best performing models by using GridSearchCV to find the optimal parameters for the models below. ","a02f52e8":"#### Message Sentiment ","7ef04f96":"We notice from the above graph that our best berforming models are the Linear SVC and Logistic Regression.","ea8be1ac":"### WordCloud \nHere we take a look at wordclouds for the cleaned data in order to visualise the words and their frequency, which is indiated by how large it appears in the image. ","f6b95f15":"<b>From the above summary, we notice the following :<\/b>\n* message is a sring object\n* tweetid is an int type\n* sentiment is an int type\n<br><br>\n* Total enteries in out train dataset is 15 818\n* Total enteries in our test dataset is 10 545\n* In the test dataset there is no sentiment column, as this is what we want to predict\n","e52591ce":"We now begin our analysis of the dataset before advancing to cleaning of the data.<br>\nLet's take a look at the various feautures found in the tweets, starting with the distribution of the tweet's sentiment.","0043e6e2":"#### Urls\nWe can do a count of urls contained in the tweets that would help in classifying tweets since it may be based on factual and news articles.<br> Below is a count of all urls as well as a count of urls for each sentiment.\n","0e6194e7":"####  Multinomial Naive Bayes\nNaive Bayes classifier is a general term which refers to conditional independence of each of the features in the model, while Multinomial Naive Bayes classifier is a specific instance of a Naive Bayes classifier which uses a multinomial distribution for each of the features.","fdbe1958":"#### Linear SVC \nThe objective of a Linear SVC (Support Vector Classifier) is to fit to the data you provide, returning a \"best fit\" hyperplane that divides, or categorizes, your data. From there, after getting the hyperplane, you can then feed some features to your classifier to see what the \"predicted\" class is.","e0bf6873":"<a id='Table_Contents'><\/a><br>\n## Table of Contents\n\n[1.Importing Packages](#Importing_Packages)<br>\n[2.Loading Datasets](#Loading_datasets)<br>\n[3.Data Description](#Data_Description)<br>\n[4.Exploratory Data Analysis (EDA)](#EDA)<br>\n[5.Data Preprocessing](#Data_clean)<br>\n[6.Variable Selection](#Var_selection)<br>\n[7.Modelling](#modelling)<br>\n[8.Performance Optimization](#performance)<br>\n[9.Model Performance](#model_performance)<br>\n[10.Conclusion](#conclusion)<br>","eef70b34":"<a id='Loading_datasets'><\/a>\n## 2.Loading Datasets\n[Back to Table of Contents](#Table_Contents)","6c1170f7":"#### Removal of Noise\nHere we shall remove digits,punctuations and special characters since this does not add value to our analysis.<br> \nWe will also replace twitter handles with the string 'twithandle'.","bd611e96":"#### Logistic Regression \nLogistic Regression is easy to implement and can be used as the baseline for any binary classification problem. It's basic fundamental concepts are also constructive in deep learning. Logistic regression describes and estimates the relationship between one dependent binary variable and independent variables.","4e93c55e":"#### Logistic Regression","9e0339a3":"Based on our anlaysis done throughout this notebook, we can confidently say that there is value in classifying tweets. This tool can be used to help businesses and organizations to understand the sentiment of the public regarding various topics, our's being climate change. There are endless applications of this tool, such as gaining insights into people's feelings towards competitor's products and businesses. As well as as the sentiment towards one's own company and products. Thus allowing a company to refine flaws that the user's may be experiencing or to improve on what user's don't like about competitor companies.<br><br>\nTo summarize our models,our best perfoming being the logistic regression with an accuracy of 0.74 and weighted f1 score of 0.734 on the pre-processed data.<br><br>\nThrough our testing we have noticed that the un-processed data has performed slighty better than the preprocessed data.This is likely due to the un-processed data having a higher word count, thus more information in each tweet which is allowing the models to better predict. The preprocessed data looks much cleaner but may have lost some sort of information needed for a better prediction.<br>\nThis can be later worked on by extracting more features from the tweets and adding it to the training set for more accurate model predictions.","a09794c2":"<p>This notebook introduces a novel solution to the Climate Change Belief Analysis competition, which was originally hosted on the Kaggle data science competition platform.<br>\n    \n<br>\"Many companies are built around lessening one\u2019s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product\/service may be received.\"\n\nIn this context, we are required to view twitter data and make a prediction of the user's sentiment towards climate change based on their tweet. Analysis, pre-proceeing and modelling will be required to sucessfully gain insights into helping a company to better undertand the thoughts and feelings of twitter users reagrsing various topics. We specifically are focusing on the topic of climate change beliefs. \n\nTwitter, a social networking site launched in 2006, is undoubtedly one of the most popular social media platforms available today, with 100 million daily active users and 500 million tweets sent daily.Using the twitter platform is an easier way for companies to obtain information spanning across multiple demographics and goegraphical locations.<br>\n    \n    \n<br><b>The object of this project is to predict an individual's belief in climate change based on historical tweet data.<\/b><br> We are required to analyse the given dataset of tweets and classify it's sentiment into one of four categories.<br><br> <b>The categories are :<\/b><br> <b>(-1) Anti :<\/b> the tweet does not believe in man-made climate change<br> <b>(0) Neutral :<\/b> the tweet neither supports nor refutes the belief of man-made climate change<br> <b>(1) Pro :<\/b> the tweet supports the belief of man-made climate change<br> <b>(2) News :<\/b> the tweet links to factual news about climate change<br>","8e1fbbe1":"<a id='EDA'><\/a>\n## 4.Exploratory Data Analysis (EDA) \n[Back to Table of Contents](#Table_Contents)","e96418b4":"#### Word Count \nLet us take a look at the average number of words in each tweet for each sentiment.","464225be":"<a id='performance'><\/a>\n## 8.Performance Optimization \n[Back to Table of Contents](#Table_Contents)","89391630":"<a id='Var_selection'><\/a>\n## 6.Variable Selection \n[Back to Table of Contents](#Table_Contents)","6eeb005a":"<a id='Data_clean'><\/a>\n## 5. Data Preprocessing\n[Back to Table of Contents](#Table_Contents)","632513dc":"Below we will use call and use the TF-IDF Vectorizer on our dataset.The TF-IDF Vectorizer is used to transform text into feautures that is input into the models for estimations and predictions. ","73633a34":"#### Hashtags\nLet us count the number of hashtags in the tweets as this may add strong sentiment to our analysis.<br> As well as look at the number of tweets found in each sentiment class.","30f528a4":"#### Random Forest Classifier \nRandom forests is a supervised learning algorithm. It can be used both for classification and regression. It is also the most flexible and easy to use algorithm. A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance.","39e96d80":"#### Dealing with emojis in tweets\nWe will replace emojis found in tweets with the word 'emoji'.","4f2d9d59":"### Models \nNow we can go ahead and build our models, train the models with our data and view the prediction statistics. ","f3b81282":"<a id='Importing_Packages'><\/a>\n## 1.Importing Packages \n[Back to Table of Contents](#Table_Contents)\n","7a5fb226":"<a id='Data_Description'><\/a>\n## 3. Data Description\n[Back to Table of Contents](#Table_Contents)","9adfd6e5":"#### Data Types and Summary","06b57b54":"### Feature Engineering\nWe will first take a look at the sentiment of each tweet using Vader analysis. This will allow us to see the each tweet's words being categorised as either neutral,negative or positive. We can then look at the compund score (overall sentiment of the tweet).<br>\nThis compund score can be added to the dataset as a feature column to be included when training models. ","5f6511ef":"#### Emojis \nWe know that tweets can contain emojis.These emojis play an important role in Sentiment analysis to understand the feelings of users, thus being able to classify the tweets better.<br>Below we will check the total number of emojis in the dataset as well as the number of emojis found in each sentiment.","abe26e03":"#### Gradient Boosting Classifer \nThe classifier uses Bayes Theorem. It predicts membership probabilities for each class (in this case sentiment) such as the probability given a certain obervation belongs to a particular class. The class with highest probability is considered as the most likely class in this case sentiment 1. Given the features, it selects proability of class with highest outcome.","3ce5df0a":"## Abstract:","f84f57cc":"Now we will visualise the difference hyperparameter tuninig has made to our top 2 best performing models i.e Linear SVC and Logistic Regression. We notice that the weighted f1 score from the model's classifcation report is higher that the weighted f1 score when we call f1_score on our models.","ba6bac3a":"#### Removing Stopwords \nIn this part we now remove stopwords i.e words that hold no sentiment and are not important to us. ","82d48941":"#### Split into training and validation ","97461a8d":"#### K Nearest Neighbors \nK-nearest neighbors (KNN) algorithm assumes that similar things exist in close proximity. This is used to predict new data values that are assigned values depending on how close it matches the training set points.A majority vote of an object's neighbours is what classifes is based on the most common classs among it's neighbors."}}