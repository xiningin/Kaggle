{"cell_type":{"3fc37f9b":"code","47e999f3":"code","1579ec08":"code","989b74b3":"code","2116309d":"code","d957331f":"code","5ba96242":"code","aececa05":"code","66d6a324":"code","8fb23f5e":"code","e3a1d325":"code","793b3305":"code","fc8ec054":"code","0ad720a0":"code","5433cfd8":"code","ba4c9770":"code","9ddb846d":"code","909bc734":"code","733a08e3":"markdown","3e5f1425":"markdown"},"source":{"3fc37f9b":"import pandas  as pd\nimport numpy as np\nimport matplotlib.pyplot  as plt\nfrom sklearn.utils import shuffle\nimport cv2\n\nimport tensorflow as tf \nfrom tensorflow.keras import applications\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n\nimport os, json\nfrom PIL import Image\nimport seaborn as sns\nimport datetime\nimport albumentations as A","47e999f3":"data_path = \"..\/input\/cassava-leaf-disease-classification\/\"\ntrain_csv_data_path = data_path+\"train.csv\"\nlabel_json_data_path = data_path+\"label_num_to_disease_map.json\"\nimages_dir_data_path = data_path+\"train_images\"","1579ec08":"import os\nprint('Train images: %d' %len(os.listdir(\n    os.path.join(data_path, \"train_images\"))))","989b74b3":"with open(os.path.join(data_path, \"label_num_to_disease_map.json\")) as file:\n    print(json.dumps(json.loads(file.read()), indent=4))","2116309d":"train_csv = pd.read_csv(train_csv_data_path)\ntrain_csv['label'] = train_csv['label'].astype('string')\n\nlabel_class = pd.read_json(label_json_data_path, orient='index')\nlabel_class = label_class.values.flatten().tolist()","d957331f":"sns.set_style(\"whitegrid\")\nfig, ax = plt.subplots(figsize = (6, 4))\n\nfor i in ['top', 'right', 'left']:\n    ax.spines[i].set_visible(False)\nax.spines['bottom'].set_color('black')\n\nsns.countplot(train_csv.label, edgecolor = 'black',\n              palette = reversed(sns.color_palette(\"viridis\", 5)))\nplt.xlabel('Classes', fontfamily = 'serif', size = 15)\nplt.ylabel('Count', fontfamily = 'serif', size = 15)\nplt.xticks(fontfamily = 'serif', size = 12)\nplt.yticks(fontfamily = 'serif', size = 12)\nax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\nplt.show()","5ba96242":"def visualize(image):\n    plt.figure(figsize=(10, 10))\n    plt.axis('off')\n    plt.imshow(image)\n    \ndef visualize_multiple(nrows, ncols, img, transform):\n    fig, axes = plt.subplots(nrows,ncols)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n    num_iter = 0\n    for row in range(nrows):\n        for col in range(ncols):\n            augmented_img = transform[num_iter](image=img)['image']\n            axes[row,col].imshow(augmented_img)\n            axes[row,col].grid(False)\n            axes[row,col].set_xticks([])\n            axes[row,col].set_yticks([])\n            num_iter += 1\n    return fig, axes","aececa05":"#seed_everything(100)\nimg = cv2.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/100042118.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nvisualize(img)","66d6a324":"blur_limits = np.arange(3,39,4)\ntransform = [A.Blur(p=1, blur_limit=[limit,limit], always_apply=True) for limit in blur_limits]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Blur kernel size: ({}, {})'.format(blur_limits[num_iter], blur_limits[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","8fb23f5e":"params = np.arange(3,30,3)\ntransform = [A.CLAHE(clip_limit=[param, param], tile_grid_size=(param, param), always_apply=True) for param in params]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Clip limit: ({}, {}), tile grid size: ({}, {})'.format(params[num_iter], params[num_iter], params[num_iter], params[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","e3a1d325":"print(\"Label names :\")\nfor i, label in enumerate(label_class):\n    print(f\" {i}. {label}\")","793b3305":"train_csv.head()","fc8ec054":"BATCH_SIZE = 18\nIMG_SIZE = 224","0ad720a0":"from keras.models import load_model\n# model_model = load_model('..\/input\/resnet\/ResNet50 (1).h5') # for resnet50 224px\n# model_model = load_model('..\/input\/private01\/EfficientNetB7.h5') # for EfficientNetB7 300px\n# model_model = load_model('..\/input\/private02\/ResNet152(1).h5') # for ResNet152 224px\nmodel_model = load_model('..\/input\/4feb2\/4Feb-2.h5') # for ResNet152 224px","5433cfd8":"model_model.summary()","ba4c9770":"test_img_path = data_path+\"test_images\/2216849948.jpg\"\n\nimg = cv2.imread(test_img_path)\nresized_img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\/255\n\nplt.figure(figsize=(8,4))\nplt.title(\"TEST IMAGE\")\nplt.imshow(resized_img[0])","9ddb846d":"preds = []\nss = pd.read_csv(data_path+'sample_submission.csv')\n\nfor image in ss.image_id:\n    img = tf.keras.preprocessing.image.load_img(data_path+'test_images\/' + image)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = tf.keras.preprocessing.image.smart_resize(img, (IMG_SIZE, IMG_SIZE))\n    img = tf.reshape(img, (-1, IMG_SIZE, IMG_SIZE, 3))\n    prediction = model_model.predict(img\/255)\n    preds.append(np.argmax(prediction))\n\nmy_submission = pd.DataFrame({'image_id': ss.image_id, 'label': preds})\nmy_submission.to_csv('submission.csv', index=False) ","909bc734":"# Submission file ouput\nprint(\"Submission File: \\n---------------\\n\")\nprint(my_submission.head())","733a08e3":"# # CLAHE","3e5f1425":"# # Blur"}}