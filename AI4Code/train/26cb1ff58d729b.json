{"cell_type":{"39687442":"code","94337bd9":"code","28510a85":"code","88a01ceb":"code","cdfaa334":"code","5e6fea1f":"code","2f872b61":"code","d5b05fe9":"code","a740af46":"code","a83f1da2":"code","1b9d7b1c":"code","054e7c14":"code","7aefbddb":"code","d6e42b03":"code","10d31d66":"code","c6ca37e9":"code","384dd1fe":"code","f620a63f":"code","e9534cac":"code","3186a374":"code","3cb7d819":"code","0ba9576c":"code","d6b3ce5b":"code","f507bacf":"code","3dfc853e":"code","a1320634":"code","3836c006":"code","5b615d9e":"code","de8838ea":"code","524ef409":"code","3a8ea151":"code","dccf411c":"code","92ec4f03":"code","6120726b":"code","97276e51":"code","cdc5f6f3":"code","b9d65e58":"code","a588eb8f":"code","7345419d":"code","6c65c181":"code","e687e365":"code","27ec6a4e":"code","5926ddd5":"markdown","edb94686":"markdown","aad1ebf2":"markdown","bef712f7":"markdown","6515da19":"markdown","a70d9e5a":"markdown","06cdc200":"markdown","f2f07aa9":"markdown","24f5330c":"markdown","63d550c3":"markdown","687533a0":"markdown","b14b3499":"markdown","b2a77f02":"markdown","75f943f6":"markdown","03118ccd":"markdown"},"source":{"39687442":"#pip install scikit-learn==0.22.1","94337bd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/heartdata\"))\n\n# Any results you write to the current directory are saved as output.","28510a85":"from sklearn import metrics \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n","88a01ceb":"dataset = pd.read_csv('..\/input\/heartdata\/heart.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, 13].values\n                ","cdfaa334":"dataset","5e6fea1f":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(x[:, 0:13])\nx[:, 0:13] = imputer.transform(x[:, 0:13])","2f872b61":"x[0]","d5b05fe9":"import matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nfrom matplotlib.cm import rainbow\n%matplotlib inline\n","a740af46":"rcParams['figure.figsize'] = 20,14\nplt.matshow(dataset.corr())\nplt.yticks(np.arange(dataset.shape[1]), dataset.columns)\nplt.xticks(np.arange(dataset.shape[1]), dataset.columns)\nplt.colorbar()","a83f1da2":"rcParams['figure.figsize'] = 8,6\nplt.bar(dataset['Column14'].unique(), dataset['Column14'].value_counts(), color = ['red' , 'green'])\nplt.xticks([0, 1])\nplt.xlabel('Target Classes')\nplt.ylabel('Count')\nplt.title('Count of each Target Class')\nx_c,y_c= dataset['Column14'].value_counts()\nprint(\"Count of heart disease: \", x_c)\nx_c,y_c= dataset['Column14'].value_counts()\nprint(\"Count of without heart disease: \", y_c)","1b9d7b1c":"from sklearn.preprocessing import StandardScaler\nx_std = StandardScaler().fit_transform(x)","054e7c14":"from sklearn.decomposition import PCA\npca = PCA().fit(x_std)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlim(0,14)\nplt.xlabel('Number of components')\nplt.ylabel('Cumulative explained variances')","7aefbddb":"from sklearn.decomposition import PCA\nsklearn_pca = PCA(n_components=11)\npca_heart = sklearn_pca.fit_transform(x_std)","d6e42b03":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(pca_heart,y,test_size=0.3,random_state=1)","10d31d66":"from sklearn import svm\nclf=svm.SVC(kernel='linear') \nclf.fit(X_train, y_train)\ny_pred=clf.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy*100.0))","c6ca37e9":"confusion_matrix(y_test,y_pred)","384dd1fe":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test, y_pred)\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred)\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred)\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","f620a63f":"from sklearn import svm\nclf=svm.SVC(kernel='rbf')\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"Accuracy: %.2f%%\" %(accuracy*100.0))","e9534cac":"confusion_matrix(y_test,y_pred)","3186a374":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test, y_pred)\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred)\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred)\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","3cb7d819":"from sklearn import svm\nclf=svm.SVC(kernel='poly') \nclf.fit(X_train, y_train)\ny_pred=clf.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy*100.0))","0ba9576c":"confusion_matrix(y_test,y_pred)\n","d6b3ce5b":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test, y_pred)\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred)\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred)\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","f507bacf":"from sklearn import svm\nclf=svm.SVC(kernel='sigmoid') \nclf.fit(X_train, y_train)\ny_pred=clf.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy*100.0))","3dfc853e":"confusion_matrix(y_test,y_pred)","a1320634":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test, y_pred)\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred)\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred)\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","3836c006":"from sklearn.ensemble import RandomForestClassifier\nclf=RandomForestClassifier(n_estimators=700,random_state=0)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy*100.0))","5b615d9e":"confusion_matrix(y_test,y_pred)","de8838ea":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test, y_pred)\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred)\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred)\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","524ef409":"from sklearn.tree import DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier(max_features = 11, random_state = 11)\ndt_classifier.fit(X_train, y_train)\ny_pred =  dt_classifier.predict(X_test)\n#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy*100.0))","3a8ea151":"confusion_matrix(y_test,y_pred)","dccf411c":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test, y_pred)\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred)\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred)\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","92ec4f03":"#Import knearest neighbors Classifier model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=16)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy*100.0))","6120726b":"confusion_matrix(y_test,y_pred)","97276e51":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test, y_pred)\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred)\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred)\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","cdc5f6f3":"#Import Gaussian Naive Bayes model\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\n#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy*100.0))","b9d65e58":"confusion_matrix(y_test,y_pred)","a588eb8f":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test, y_pred)\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred)\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred)\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","7345419d":"from keras.models import Sequential\nfrom keras.layers import Dense\nclassifier = Sequential()\nclassifier.add(Dense(output_dim = 10, init = 'uniform', activation = 'relu', input_dim = 11))\nclassifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\nclassifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\ntraining = classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 150)","6c65c181":"from sklearn.metrics import accuracy_score \ny_pred = classifier.predict(X_test)\n#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))\naccuracy = accuracy_score(y_test,y_pred.round())\nprint(\"Accuracy: %.2f%%\" % (accuracy*100.0))","e687e365":"confusion_matrix(y_test,y_pred.round())","27ec6a4e":"#precision tp \/ (tp + fp)\nprecision=precision_score(y_test,y_pred.round())\nprint(\"Precision: %.2f%%\" % (precision * 100.0))\n\n# recall: tp \/ (tp + fn)\nrecall=recall_score(y_test, y_pred.round())\nprint(\"recall: %.2f%%\" % (recall * 100.0))\n\n\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1=f1_score(y_test, y_pred.round())\nprint(\"F1: %.2f%%\" % (f1 * 100.0))","5926ddd5":"* **SVM(Sigmoid Kernel)**","edb94686":"* **K-Nearest Neighbors**","aad1ebf2":"* **Data Preprocessing**","bef712f7":"* **SVM(RBF Kernel)**","6515da19":"* **SVM(Linear)**","a70d9e5a":"* **Decision Tree Classifier**","06cdc200":"* **Feature Selection**","f2f07aa9":"* **Data Splitting**","24f5330c":"* **Random Forest**","63d550c3":"* **ANN Classifier**","687533a0":"* **Data Understanding**","b14b3499":"* **SVM(Poly)**","b2a77f02":"* **Naive Bayes Classifier**","75f943f6":"**Classification Model Apply**","03118ccd":"* **Data Standardisation**"}}