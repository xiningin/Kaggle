{"cell_type":{"b5cb5dad":"code","f51f30f1":"code","4da7069e":"code","7f2d8dae":"code","7523d9d4":"code","a86775df":"code","03d09846":"code","0df1a5ce":"code","f4bcbac0":"code","12e977f6":"code","db0743a1":"code","7c1fe8b2":"code","96a5c0a3":"code","3ba2b07b":"code","0e26c433":"code","2bd7ba77":"code","1eeb24b2":"code","041edd88":"code","e26cd075":"code","0716136a":"code","45825b1b":"code","6c262956":"code","bbc7442c":"code","0c5de3ac":"markdown","c288588a":"markdown","1a298efb":"markdown","3c7ca8ff":"markdown","c53ee011":"markdown","0f9598c7":"markdown","3b4a530f":"markdown","0a0370e9":"markdown","98f4568e":"markdown","054b711f":"markdown","985bb020":"markdown","db6b1aab":"markdown","8fb26cb5":"markdown","88c83e33":"markdown","ceff9f20":"markdown","c36a3bcc":"markdown"},"source":{"b5cb5dad":"# Import Packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport matplotlib.mlab as mlab\nplt.style.use('ggplot') # default plot style.\n\nimport scipy\nfrom scipy import stats\nfrom scipy.stats import norm","f51f30f1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4da7069e":"# Import Data\nCD = pd.read_csv(\"\/kaggle\/input\/credit-card-customers\/BankChurners.csv\")\nCD.head()","7f2d8dae":"# Step 1 - Set ClientNum as Index Value\nCD = CD.set_index(\"CLIENTNUM\");","7523d9d4":"# Step 2 - Describe the Customer Dataset (i.e., Customer Age, Credit Limits, etc)\nCD.describe()","a86775df":"# Step 3 - Identify NA Values and Replace w\/ appropriate values\nCD.isna().sum()","03d09846":"# Step 3 - Identify NA Values and Replace w\/ appropriate values\nCD = CD.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2', \n              'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'], axis = 1)","0df1a5ce":"# Step 4 - Understand Factor Variables (i.e., Income_Category, Marital Status, Card Category)\nIncomes = CD.groupby(\"Income_Category\")[\"Income_Category\"].count()\nprint(Incomes)\nprint()\n\nMS = CD.groupby(\"Marital_Status\")[\"Marital_Status\"].count()\nprint(MS)\nprint()\n\nCC = CD.groupby(\"Card_Category\")[\"Card_Category\"].count()\nprint(CC)\nprint()\n\nEL = CD.groupby(\"Education_Level\")[\"Education_Level\"].count()\nprint(EL)\n","f4bcbac0":"# Step 5 - Convert Factor Variables to Dummary Variables for Regression Analysis\nCD['Attrition_Flag_Num'] = CD['Attrition_Flag'].map({'Existing Customer':1, 'Attrited Customer':0})\nCD['Gender_Num'] = CD['Gender'].map({'M':1, 'F':2})\nCD['Income_Category_Num'] = CD['Income_Category'].map({'Unknown':1, 'Less than $40K':2, '$40K - $60K':3, '$60K - $80K':4, '$80K - $120K':5, '$120K +':6})\nCD['Marital_Status_Num'] = CD['Marital_Status'].map({'Unknown':1, 'Divorced':2, 'Single':3, 'Married':4})\nCD['Education_Level_Num'] = CD['Education_Level'].map({'Unknown':1, 'Uneducated':1, 'High School':2, 'College':3,'Graduate':4,'Post-Graduate':5,'Doctorate':6})\nCD['Card_Category_Num'] = CD['Card_Category'].map({'Blue':1, 'Silver':2, 'Gold':3, 'Platinum':4})","12e977f6":"Categories = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\n\nfor category in Categories:\n    names = list(set(CD[category]))\n    values = []\n    EC = []\n    AC = []\n    for element in names:\n        num = len(CD[CD[category] == element])\n        values.append(num)\n        EC1 = len(CD[(CD['Attrition_Flag'] == 'Existing Customer') & (CD[category] == element)])\n        EC.append(EC1)\n        AC1 = len(CD[(CD['Attrition_Flag'] == 'Attrited Customer') & (CD[category] == element)])\n        AC.append(AC1)\n    \n    width = 0.5       # the width of the bars: can also be len(x) sequence\n\n    fig, ax = plt.subplots(figsize = (10, 5))\n\n    ax.bar(names, EC , width, label='Existing Customer')\n    ax.bar(names, AC , width, bottom=EC, label='Attrited Customer')\n    ax.legend()\n","db0743a1":"Numericals = ['Customer_Age','Credit_Limit','Months_on_book','Avg_Utilization_Ratio','Avg_Open_To_Buy','Total_Trans_Amt']\n\nfor element in Numericals:\n    num_bins = 20\n    x = CD[element]\n    sigma = x.std()\n    mu = x.mean()\n    \n    fig, ax = plt.subplots(figsize = (10, 5))\n\n    n, bins, patches = ax.hist(x, num_bins, density=1)\n    y = ((1 \/ (np.sqrt(2 * np.pi) * sigma)) *\n    np.exp(-0.5 * (1 \/ sigma * (bins - mu))**2))\n    ax.plot(bins, y, '--')\n    ax.set_xlabel(element)\n    ax.set_ylabel('Frequency')\n    plt.show()\n    ","7c1fe8b2":"x1 = CD[['Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio', 'Gender_Num', 'Income_Category_Num', 'Marital_Status_Num', 'Education_Level_Num', 'Card_Category_Num']]\ny1 = CD['Attrition_Flag_Num']","96a5c0a3":"#Review Skewness of Dataset, consider performing log transformation on highly skewed independent variables. \ndf_skew = pd.DataFrame(x1.skew(), columns=['Skewness']).sort_values(by='Skewness')\ndf_skew","3ba2b07b":"# Import Statsmodels\nimport statsmodels.api as sm\n\n# Perform Logistic Regression & output summary\nlogit_model = sm.Logit(y1, x1).fit(method = 'minimize')\nprint(logit_model.summary()) ","0e26c433":"# Import Packages for ML Tool\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","2bd7ba77":"# Split the dataset into a test & training data set. \n# Our model will train on 70% of the customer data then predict on the remaining 30%. \nx_train,x_test,y_train,y_test = train_test_split(x1,y1,test_size=0.3,random_state=0)","1eeb24b2":"# Run a Logistic Regression and fit the dataset to the model\nlogistic_regression = LogisticRegression(max_iter = 10000)\nlogistic_regression.fit(x_train,y_train)\ny_pred = logistic_regression.predict(x_test)","041edd88":"# Build a confusion matrix, which will provide insights into the accuracy of the model. \nconfusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\nprint(confusion_matrix)\nprint('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\nplt.show()","e26cd075":"Features = ['Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio', 'Gender_Num', 'Income_Category_Num', 'Marital_Status_Num', 'Education_Level_Num', 'Card_Category_Num']\n\nimportance = logistic_regression.coef_[0]\nimportance\n\ncm = sns.light_palette(\"green\", as_cmap=True)\n\nFeatureImportance = pd.DataFrame(Features, columns = ['Feature'])\nFeatureImportance['Score'] = importance\nFeatureImportance = FeatureImportance.sort_values(by=['Score']).style.background_gradient(cmap=cm)\nFeatureImportance","0716136a":"# Import Packages for ML Tool\nfrom sklearn.ensemble import RandomForestClassifier","45825b1b":"# Run a Random Forest Classifier and fit the dataset to the model\nRF = RandomForestClassifier(n_estimators=20, random_state=0)\nRF.fit(x_train,y_train)\ny_predRF = RF.predict(x_test)","6c262956":"# Build a confusion matrix, which will provide insights into the accuracy of the model. \nconfusion_matrixRF = pd.crosstab(y_test, y_predRF, rownames=['Actual'], colnames=['Predicted'])\nprint(confusion_matrixRF)\nprint('Accuracy: ',metrics.accuracy_score(y_test, y_predRF))\nplt.show()","bbc7442c":"Features = ['Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio', 'Gender_Num', 'Income_Category_Num', 'Marital_Status_Num', 'Education_Level_Num', 'Card_Category_Num']\n\nimportanceRF = RF.feature_importances_\nimportanceRF\n\ncm = sns.light_palette(\"green\", as_cmap=True)\n\nFeatureImportanceRF = pd.DataFrame(Features, columns = ['Feature'])\nFeatureImportanceRF['Score'] = importanceRF\nFeatureImportanceRF = FeatureImportanceRF.sort_values(by=['Score']).style.background_gradient(cmap=cm)\nFeatureImportanceRF","0c5de3ac":"### Regression Takeaways\n\n* Regression runs w\/ outputs in Jupyter Notebook. Results are not showing up in Kaggle. See below for our analysis.\n* Customer Age, Months on Book, Credit Limit, Revolving Balance, Open to Buy, Utilization Ratio, and Education Level are not statistically significant and our model cannot prove that these attributes have influence over whether or not a customer decides to leave the bank or not. \n* Our simple Logistic Regression only explains ~45% of the variation within customer accounts. A stronger model is needed","c288588a":"## Visualization Takeaways\n<br>\n\n**Categorial**\n* Balanced amount of Male\/Female cardholders. Males appear slightly more likely to leave the firm. \n* Majority of cardholders hold a graduate degree, graduate degree holders appear slighly more likely to leave the firm. \n* Majority of cardholders make < 40K, which is interested given the point above\n* Blue Card is the most popular offering\n\n**Numerical**\n* Mean Age is between 40-50\n* Most cardholders have a low credit limit & low credit utilization rate\n* Most customers have been with the bank for 3 years\n* It appears there is some skewness in our data, we should analyze to ensure no issues with modeling. ","1a298efb":"### Logistic ML Model Takeaways\n\n* The most important features to determine if a customer will leave the bank or not are: Total Transaction Counts, Marital Status, Total Amount Change Quarter over Quarter, Total Relationships with Bank, and Total Count of Transactions Quarter over Quarter\n\n* Our logistic model can accurately predict if a customer will leave the bank ~90% of the time.","3c7ca8ff":"## Categorical Features\n\nMapping attributes with dummy variables \n* Attrition_Flag    (1: Attrited Customer, 0: Existing Customer)\n* Gender            (1: Female, 2: Male)\n* Education_Level   (1: Unknown, 1: Uneducated, 2: High School, 3: College, 4: Graduate, 5: Post-Graduate, 6: Doctorate)\n* Marital_Status    (1: Unknown, 2: Divorced, 3: Single, 4: Married)\n* Income_Category   (1: Unknown, 2: Less than 40K, 3: 40K - 60K, 4: 60K - 80K, 5:80K - 120K, 6: 120K +)\n* Card_Category     (1: Blue, 2: Silver, 3: Gold, 4: Platinum)","c53ee011":"## Categorial Features\n* Customer_Age: Customer's Age in Years\n* Dependent_count: Number of dependents\n* Months_on_book: Period of relationship with bank\n* Total_Relationship_Count: Total no. of products held by the customer\n* Months_Inactive_12_mon: No. of months inactive in the last 12 months\n* Contacts_Count_12_mon: No. of Contacts in the last 12 months\n* Credit_Limit: Credit Limit on the Credit Card\n* Total_Revolving_Bal: Total Revolving Balance on the Credit Card\n* Avg_Open_To_Buy: Open to Buy Credit Line (Average of last 12 months)\n* Total_Amt_Chng_Q4_Q1: Change in Transaction Amount (Q4 over Q1)\n* Total_Trans_Amt: Total Transaction Amount (Last 12 months)\n* Total_Trans_Ct: Total Transaction Count (Last 12 months)\n* Total_Ct_Chng_Q4_Q1: Change in Transaction Count (Q4 over Q1)\n* Avg_Utilization_Ratio: Average Card Utilization Ratio","0f9598c7":"## Numerical Plotting","3b4a530f":"###  Logistic Regression to review Independent Variables\nLogistic Regressions are used to identify the statistical impact that independent variables have on a binary dependent variable. In our case, the dependent variable is whether or not the customer leaves the bank (leave or stay, binary). Our independent variables are all datapoints we have on the customer (except for whether they are current customers or have left the bank)","0a0370e9":"### Random Forest ML Model Takeaways\n\n* The most important features to determine if a customer will leave the bank or not are: Total Transaction Counts, Total Transaction Amount, and Total Revolving Balance. \n\n* Our random forest model can accurately predict if a customer will leave the bank ~95% of the time.","98f4568e":"# Customer Visualizations","054b711f":"# Data Preprocessing:\nA required process by Data Scientists to allow for dataset to be workable\n\n* Step 1 - Set Index Value to Client Number\n* Step 2 - Describe the Customer Dataset (i.e., descriptive statistics)\n* Step 3 - Identify NA Values and Replace w\/ appropriate values\n* Step 4 - Understand Factor Variables (i.e., Income_Category, Marital Status, Card Category)\n* Step 5 - Convert Factor Variables to Dummary Variables for Regression Analysis","985bb020":"# Analyzing CC Customers\nProblem: A business manager of a consumer credit card portfolio is facing the problem of customer attrition. They want to analyze the data to find out the reason behind this and leverage the same to predict customers who are likely to drop off.","db6b1aab":"## Categorical Plotting","8fb26cb5":"   # Customer Analytics\n   \n   ","88c83e33":"### Feature Importance","ceff9f20":"# Random Forest Machine Learning Model","c36a3bcc":"### Feature Importance\nFeature Importance helps \"humans\" understand the logic behind the black box. Please review the information below objectivity."}}