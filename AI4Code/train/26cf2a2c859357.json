{"cell_type":{"812a2655":"code","8f6615e7":"code","36c55398":"code","0d310143":"code","490eeaac":"code","401aa081":"code","1b49f168":"code","2eb4ed0a":"code","58bc2f44":"code","9282d420":"code","38b19a26":"code","da2c2dd9":"code","946dc1dd":"code","034a9127":"code","2d9318d4":"markdown","4b387a10":"markdown","c0af29c0":"markdown","a79f130f":"markdown","5e075160":"markdown","e8b0c953":"markdown","08793b52":"markdown","76c13635":"markdown","9df3de33":"markdown","2a226d1b":"markdown","295a553f":"markdown","cca48b6b":"markdown","90b1730a":"markdown","b44f00c5":"markdown","2a2483d8":"markdown","2ff8319f":"markdown","213bff14":"markdown"},"source":{"812a2655":"import numpy as np\nimport keras\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8f6615e7":"# let's upload train data\ntrain_data_file = open('..\/input\/mnist-train\/mnist_train.csv','r')\ntrain_data_list = train_data_file.readlines()\ntrain_data_file.close()\n\n# # let's upload test data\ntest_data_file = open('..\/input\/mnist-ml-crash-course\/mnist_test.csv','r')\ntest_data_list = test_data_file.readlines()\ntest_data_file.close()","36c55398":"print('Number of training examples: ',len(train_data_list))\nprint('Number of test examples: ',len(test_data_list))","0d310143":"# y - targets\n# X - features\ny_train = []\nX_train = []\n\nfor record in range(len(train_data_list)):\n    y_train.append(train_data_list[record][0])\n    values = train_data_list[record].split(',')\n    X_train.append(values[1:])\n\ny_test = []\nX_test = []\n\nfor record in range(len(test_data_list)):\n    y_test.append(test_data_list[record][0])\n    values = test_data_list[record].split(',')\n    X_test.append(values[1:])","490eeaac":"# converting to numpy array\ny_train = np.asfarray(y_train)\nX_train = np.asfarray(X_train)\n\ny_test = np.asfarray(y_test)\nX_test = np.asfarray(X_test)","401aa081":"train_images = X_train.reshape((-1, 784))\ntest_images = X_test.reshape((-1, 784))\n\n# check the shapes\nprint('y_train shape:',y_train.shape)\nprint('X_train shape: ',X_train.shape)\n\nprint('X_test shape: ',y_test.shape)\nprint('X_test shape: ',X_test.shape)","1b49f168":"# Normalize the images.\ntrain_images = ((train_images \/ 255) * 0.99) + 0.01\ntest_images = ((test_images \/ 255) * 0.99) + 0.01","2eb4ed0a":"# instantiate model\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential([\n    Dense(784,activation='relu',input_shape=(784,)),\n    Dense(200,activation='relu',kernel_regularizer='l2',bias_regularizer='l2'),\n    Dense(200,activation='relu',kernel_regularizer='l2',bias_regularizer='l2'),\n    Dense(10,activation='softmax')\n]);","58bc2f44":"model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","9282d420":"from keras.utils import to_categorical\n\nmodel.fit(\n    x=train_images, #train data-set\n    y=to_categorical(y_train), #labels\n    epochs=5,\n    batch_size=32,\n    validation_split=0.15\n)","38b19a26":"model.evaluate(\n    test_images,\n    to_categorical(y_test)\n)","da2c2dd9":"model = Sequential([\n    Dense(64,activation='relu'),\n    Dense(64,activation='relu'),\n    Dense(10,activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nfrom keras.utils import to_categorical\n\nmodel.fit(\n    x=train_images, #train data-set\n    y=to_categorical(y_train), #labels\n    epochs=10,\n    batch_size=32\n)\n\nprint('test accuracy: ')\n\nmodel.evaluate(\n  test_images,\n  to_categorical(y_test)\n)\n","946dc1dd":"# more layers\nmodel = Sequential([\n    Dense(64,activation='relu'),\n    Dense(64,activation='relu'),\n    Dense(100,activation='relu'),\n    Dense(100,activation='relu'),\n    Dense(10,activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nfrom keras.utils import to_categorical\n\nmodel.fit(\n    x=train_images, #train data-set\n    y=to_categorical(y_train), #labels\n    epochs=5,\n    batch_size=32\n)\n\n\nmodel.evaluate(\n  test_images,\n  to_categorical(y_test)\n)\n","034a9127":"\nmodel = Sequential([\n    Dense(64,activation='sigmoid'),\n    Dense(64,activation='sigmoid'),\n    Dense(10,activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nfrom keras.utils import to_categorical\n\nmodel.fit(\n    x=train_images, #train data-set\n    y=to_categorical(y_train), #labels\n    epochs=5,\n    batch_size=32\n)\n\nprint('test accuracy: ')\n\nmodel.evaluate(\n  test_images,\n  to_categorical(y_test)\n)","2d9318d4":"Keras provides to build **Sequential** or **Functional** models. Sequential model is the simplest model where layers of neurons stacked and fuly connected. Functional model is more customizable. Here we're going to build Sequential model.","4b387a10":"Great! After 25 epochs of training we achieved 0.99 accuracy, and 0.97 validation accuracy. It may look promising but it doesn't tell us much. We need to test the model.","c0af29c0":"Let's split labels and features into separate data sets.","a79f130f":"## Compile the Model\n\nNow we need to compile our model before we start training. We need to define 3 main key factors:\n* Optimizer - gradient descent\n* Loss function\n* Metric\n\nKeras has many <a href='https:\/\/keras.io\/api\/optimizers\/'>optimizers<\/a>. In our model we will use <a href='https:\/\/arxiv.org\/abs\/1412.6980'>**Adam** - gradient based optimization<\/a>. \nFor the Loss function **Cross-Entropy Loss**. To learn more about loss functions, go to Keras documentation: <a href='https:\/\/keras.io\/api\/losses\/'>Keras' loss functions<\/a>. As for the metric we'll use **accuracy**.\n","5e075160":"### Different Activation: Sigmoid?","e8b0c953":"## Testing the Model","08793b52":"May be **overfitting**? ","76c13635":"### Number of epochs?","9df3de33":"Then we normalize our data. Instead of having pixel values from [0-255] we center them from [0.01 to 0.99]. Usually smaller and centered values are better to train.","2a226d1b":"## Building the Model","295a553f":"## Training the Model","cca48b6b":"### Network Depth?","90b1730a":"## Data Preparation","b44f00c5":"## Data set","2a2483d8":"Uploading the data set. You can download it from here: http:\/\/pjreddie.com\/projects\/mnist-in-csv\/","2ff8319f":"# Building Simple Neural Network with Keras\n\nThe problem: MNIST handwritten digit classification\nMNIST data-set is classic deep learning problem. It's a collection of handwritten digits from 0 to 9.\n\nKeras is simple and powerfull deep learning library for Python. You can learn more by reading the <a href='https:\/\/keras.io\/getting_started\/intro_to_keras_for_engineers\/'>documentation<\/a>.","213bff14":"## Experiment with Model\n\nLet's try out different parameters to compare the results."}}