{"cell_type":{"46075485":"code","6a2eab78":"code","3a1517b6":"code","71ecfc4b":"code","61afc0ed":"code","72ae7a20":"code","ec357b18":"code","25a06732":"code","fbcbabbf":"code","e3902419":"code","808abb0d":"code","5815698a":"code","4e7cf927":"code","ee3f75fa":"code","763cafc8":"code","7b6bd07c":"code","3f0bb02b":"code","7af5a821":"code","a7c9e7e4":"code","31782932":"code","3240f407":"code","bf89f3de":"code","8b935906":"code","182d8f4c":"code","25fa4360":"code","6cc42cbb":"code","fb6b0896":"code","d0366d48":"code","314a5804":"code","0ed5c524":"code","523cf31d":"code","93dd57a9":"code","1c61d2d3":"code","a96a2a16":"code","7a11562a":"code","1a0e67d0":"code","6c754988":"code","b4a45a49":"code","df215d71":"code","89263e9c":"code","22f7def5":"code","8ad866c7":"code","70c07216":"markdown","7ed717d8":"markdown","7c7e7867":"markdown","21e47844":"markdown","480977af":"markdown","1a32bc59":"markdown","cd19ac28":"markdown","b70f68d5":"markdown","1f8ee818":"markdown","ec9959db":"markdown","0b225145":"markdown","0fc1a55d":"markdown","633f8903":"markdown","92596e8a":"markdown","2c62b739":"markdown","1afec09b":"markdown","1f243c0b":"markdown","e58a6b38":"markdown","d49535ca":"markdown","4705986e":"markdown","6452527c":"markdown","df338026":"markdown","be1c005c":"markdown","531d2e40":"markdown","45590e5b":"markdown","9a3835f0":"markdown","10ff1ec5":"markdown","01f13e0f":"markdown","84b69a02":"markdown","1eb3f82f":"markdown","1ca77540":"markdown","235c6199":"markdown","29458f8e":"markdown","5738f7a6":"markdown","f0a5d7bb":"markdown","1eaf3888":"markdown","e55cbd99":"markdown","03a05ac9":"markdown","f62bbba0":"markdown","8af8a98b":"markdown","fccafc0b":"markdown","3729f83f":"markdown","0291f7ec":"markdown","c5957335":"markdown"},"source":{"46075485":"from keras.models import Model, Sequential\nfrom keras.layers import Activation, Dense, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\nfrom keras import backend as K\nfrom keras.optimizers import Adam, SGD\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport glob\nimport PIL\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom warnings import filterwarnings\n\nfilterwarnings('ignore')\nplt.rcParams[\"axes.grid\"] = False\nnp.random.seed(101)","6a2eab78":"import re\nnumbers = re.compile(r'(\\d+)')\ndef numericalSort(value):\n    parts = numbers.split(value)\n    parts[1::2] = map(int, parts[1::2])\n    return parts","3a1517b6":"filelist_trainx_ph2 = sorted(glob.glob('..\/input\/*\/*\/trainx\/*.bmp'), key=numericalSort)\nX_train_ph2 = np.array([np.array(Image.open(fname)) for fname in filelist_trainx_ph2])\n\nfilelist_trainy_ph2 = sorted(glob.glob('..\/input\/*\/*\/trainy\/*.bmp'), key=numericalSort)\nY_train_ph2 = np.array([np.array(Image.open(fname)) for fname in filelist_trainy_ph2])","71ecfc4b":"plt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.imshow(X_train_ph2[0])\nplt.xlabel(\"Dimensions: \"+str(np.array(X_train_ph2[0]).shape))\nplt.subplot(1,2,2)\nplt.imshow(Y_train_ph2[0], plt.cm.binary_r)\nplt.xlabel(\"Dimensions: \"+str(np.array(Y_train_ph2[0]).shape))\nplt.show()","61afc0ed":"def resize(filename, size = (256,192)):\n    im = Image.open(filename)\n    im_resized = im.resize(size, Image.ANTIALIAS)\n    return (im_resized)\n#   im_resized.save('\/resized_ph2\/X_train\/X_img_'+str(i)+'.bmp', dpi = (192,256))","72ae7a20":"X_train_ph2_resized = []\nY_train_ph2_resized = []\n\nfor i in range(len(filelist_trainx_ph2)):\n    X_train_ph2_resized.append(resize(filelist_trainx_ph2[i]))\n    Y_train_ph2_resized.append(resize(filelist_trainy_ph2[i]))    ","ec357b18":"plt.figure(figsize=(12,6))\nplt.suptitle(\"Images from PH2 dataset\")\nplt.subplot(1,2,1)\nplt.imshow(X_train_ph2_resized[0])\nplt.xlabel(\"Dimensions: \"+str(np.array(X_train_ph2_resized[0]).shape))\nplt.subplot(1,2,2)\nplt.imshow(Y_train_ph2_resized[0], plt.cm.binary_r)\nplt.xlabel(\"Dimensions: \"+str(np.array(Y_train_ph2_resized[0]).shape))\nplt.show()","25a06732":"X_train_ph2 = np.array([np.array(img) for img in X_train_ph2_resized])\nY_train_ph2 = np.array([np.array(img) for img in Y_train_ph2_resized])","fbcbabbf":"plt.figure(figsize=(12,6))\nplt.suptitle(\"Images from PH2 dataset after resize\")\nplt.subplot(1,2,1)\nplt.imshow(X_train_ph2[123])\nplt.xlabel(\"Dimensions: \"+str(np.array(X_train_ph2_resized[0]).shape))\nplt.subplot(1,2,2)\nplt.imshow(Y_train_ph2[123], plt.cm.binary_r)\nplt.xlabel(\"Dimensions: \"+str(np.array(Y_train_ph2_resized[0]).shape))\nplt.show()","e3902419":"x_train, x_test, y_train, y_test = train_test_split(X_train_ph2, Y_train_ph2, test_size = 0.25, random_state = 101)","808abb0d":"plt.figure(figsize=(20,9))\nplt.subplot(2,4,1)\nplt.imshow(X_train_ph2[0])\nplt.subplot(2,4,2)\nplt.imshow(X_train_ph2[3])\nplt.subplot(2,4,3)\nplt.imshow(X_train_ph2[54])\nplt.subplot(2,4,4)\nplt.imshow(X_train_ph2[77])\nplt.subplot(2,4,5)\nplt.imshow(X_train_ph2[100])\nplt.subplot(2,4,6)\nplt.imshow(X_train_ph2[125])\nplt.subplot(2,4,7)\nplt.imshow(X_train_ph2[130])\nplt.subplot(2,4,8)\nplt.imshow(X_train_ph2[149])\nplt.show()","5815698a":"plt.figure(figsize=(20,9))\nplt.subplot(2,4,1)\nplt.imshow(Y_train_ph2[0], cmap = plt.cm.binary_r)\nplt.subplot(2,4,2)\nplt.imshow(Y_train_ph2[3], cmap = plt.cm.binary_r)\nplt.subplot(2,4,3)\nplt.imshow(Y_train_ph2[54], cmap = plt.cm.binary_r)\nplt.subplot(2,4,4)\nplt.imshow(Y_train_ph2[77], cmap = plt.cm.binary_r)\nplt.subplot(2,4,5)\nplt.imshow(Y_train_ph2[100], cmap = plt.cm.binary_r)\nplt.subplot(2,4,6)\nplt.imshow(Y_train_ph2[125], cmap = plt.cm.binary_r)\nplt.subplot(2,4,7)\nplt.imshow(Y_train_ph2[130], cmap = plt.cm.binary_r)\nplt.subplot(2,4,8)\nplt.imshow(Y_train_ph2[149], cmap = plt.cm.binary_r)\nplt.show()","4e7cf927":"def iou(y_true, y_pred, smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac","ee3f75fa":"def dice_coef(y_true, y_pred, smooth = 100):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","763cafc8":"def precision(y_true, y_pred):\n    '''Calculates the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    '''\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision","7b6bd07c":"def recall(y_true, y_pred):\n    '''Calculates the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    '''\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall","3f0bb02b":"def accuracy(y_true, y_pred):\n    '''Calculates the mean accuracy rate across all predictions for binary\n    classification problems.\n    '''\n    return K.mean(K.equal(y_true, K.round(y_pred)))","7af5a821":"def random_rotation(x_image, y_image):\n    rows_x,cols_x, chl_x = x_image.shape\n    rows_y,cols_y = y_image.shape\n    rand_num = np.random.randint(-40,40)\n    M1 = cv2.getRotationMatrix2D((cols_x\/2,rows_x\/2),rand_num,1)\n    M2 = cv2.getRotationMatrix2D((cols_y\/2,rows_y\/2),rand_num,1)\n    x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n    y_image = cv2.warpAffine(y_image.astype('float32'),M2,(cols_y,rows_y))\n    return np.array(x_image), np.array(y_image.astype('int'))\n\ndef horizontal_flip(x_image, y_image):\n    x_image = cv2.flip(x_image, 1)\n    y_image = cv2.flip(y_image.astype('float32'), 1)\n    return x_image, y_image.astype('int')","a7c9e7e4":"def img_augmentation(x_train, y_train):\n    x_rotat = []\n    y_rotat = []\n    x_flip = []\n    y_flip = []\n    for idx in range(len(x_train)):\n        x,y = random_rotation(x_train[idx], y_train[idx])\n        x_rotat.append(x)\n        y_rotat.append(y)\n        \n        x,y = horizontal_flip(x_train[idx], y_train[idx])\n        x_flip.append(x)\n        y_flip.append(y)\n        \n    return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)","31782932":"x_rotated, y_rotated, x_flipped, y_flipped = img_augmentation(x_train, y_train)\nx_rotated_t, y_rotated_t, x_flipped_t, y_flipped_t = img_augmentation(x_test, y_test)","3240f407":"img_num = 112\nplt.figure(figsize=(12,12))\nplt.subplot(3,2,1)\nplt.imshow(x_train[img_num])\nplt.title('Original Image')\nplt.subplot(3,2,2)\nplt.imshow(y_train[img_num], plt.cm.binary_r)\nplt.title('Original Mask')\nplt.subplot(3,2,3)\nplt.imshow(x_rotated[img_num])\nplt.title('Rotated Image')\nplt.subplot(3,2,4)\nplt.imshow(y_rotated[img_num], plt.cm.binary_r)\nplt.title('Rotated Mask')\nplt.subplot(3,2,5)\nplt.imshow(x_flipped[img_num])\nplt.title('Flipped Image')\nplt.subplot(3,2,6)\nplt.imshow(y_flipped[img_num], plt.cm.binary_r)\nplt.title('Flipped Mask')\nplt.show()","bf89f3de":"# For training Set\nx_train_full = np.concatenate([x_train, x_rotated, x_flipped])\ny_train_full = np.concatenate([y_train, y_rotated, y_flipped])","8b935906":"x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.20, random_state = 101)","182d8f4c":"print(\"Length of the Training Set   : {}\".format(len(x_train)))\nprint(\"Length of the Test Set       : {}\".format(len(x_test)))\nprint(\"Length of the Validation Set : {}\".format(len(x_val)))","25fa4360":"def segnet(epochs_num,savename):\n\n    # Encoding layer\n    img_input = Input(shape= (192, 256, 3))\n    x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n    x = BatchNormalization(name='bn1')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n    x = BatchNormalization(name='bn3')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n    x = BatchNormalization(name='bn4')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n    x = BatchNormalization(name='bn5')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n    x = BatchNormalization(name='bn6')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n    x = BatchNormalization(name='bn7')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n    x = BatchNormalization(name='bn8')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n    x = BatchNormalization(name='bn9')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n    x = BatchNormalization(name='bn10')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n    x = BatchNormalization(name='bn11')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n    x = BatchNormalization(name='bn12')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n    x = BatchNormalization(name='bn13')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    x = Dense(1024, activation = 'relu', name='fc1')(x)\n    x = Dense(1024, activation = 'relu', name='fc2')(x)\n    # Decoding Layer \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n    x = BatchNormalization(name='bn14')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n    x = BatchNormalization(name='bn15')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n    x = BatchNormalization(name='bn16')(x)\n    x = Activation('relu')(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n    x = BatchNormalization(name='bn17')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n    x = BatchNormalization(name='bn18')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n    x = BatchNormalization(name='bn19')(x)\n    x = Activation('relu')(x)\n\n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n    x = BatchNormalization(name='bn20')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n    x = BatchNormalization(name='bn21')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n    x = BatchNormalization(name='bn22')(x)\n    x = Activation('relu')(x)\n\n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n    x = BatchNormalization(name='bn23')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n    x = BatchNormalization(name='bn24')(x)\n    x = Activation('relu')(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n    x = BatchNormalization(name='bn25')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n    x = BatchNormalization(name='bn26')(x)\n    x = Activation('sigmoid')(x)\n    pred = Reshape((192,256))(x)\n    \n    model = Model(inputs=img_input, outputs=pred)\n    \n    model.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n    model.summary()\n    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 18, validation_data= (x_val, y_val), verbose=1)\n    \n    model.save(savename)\n    return model,hist","6cc42cbb":"model, hist = segnet(1, 'segnet_1_epoch.h5')","fb6b0896":"# Encoding layer\nimg_input = Input(shape= (192, 256, 3))\nx = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\nx = BatchNormalization(name='bn1')(x)\nx = Activation('relu')(x)\nx = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\nx = BatchNormalization(name='bn2')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\nx = BatchNormalization(name='bn3')(x)\nx = Activation('relu')(x)\nx = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\nx = BatchNormalization(name='bn4')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\nx = BatchNormalization(name='bn5')(x)\nx = Activation('relu')(x)\nx = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\nx = BatchNormalization(name='bn6')(x)\nx = Activation('relu')(x)\nx = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\nx = BatchNormalization(name='bn7')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\nx = BatchNormalization(name='bn8')(x)\nx = Activation('relu')(x)\nx = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\nx = BatchNormalization(name='bn9')(x)\nx = Activation('relu')(x)\nx = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\nx = BatchNormalization(name='bn10')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\nx = BatchNormalization(name='bn11')(x)\nx = Activation('relu')(x)\nx = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\nx = BatchNormalization(name='bn12')(x)\nx = Activation('relu')(x)\nx = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\nx = BatchNormalization(name='bn13')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Dense(1024, activation = 'relu', name='fc1')(x)\nx = Dense(1024, activation = 'relu', name='fc2')(x)\n# Decoding Layer \nx = UpSampling2D()(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\nx = BatchNormalization(name='bn14')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\nx = BatchNormalization(name='bn15')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\nx = BatchNormalization(name='bn16')(x)\nx = Activation('relu')(x)\n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\nx = BatchNormalization(name='bn17')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\nx = BatchNormalization(name='bn18')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\nx = BatchNormalization(name='bn19')(x)\nx = Activation('relu')(x)\n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\nx = BatchNormalization(name='bn20')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\nx = BatchNormalization(name='bn21')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\nx = BatchNormalization(name='bn22')(x)\nx = Activation('relu')(x)\n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\nx = BatchNormalization(name='bn23')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\nx = BatchNormalization(name='bn24')(x)\nx = Activation('relu')(x)\n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\nx = BatchNormalization(name='bn25')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\nx = BatchNormalization(name='bn26')(x)\nx = Activation('sigmoid')(x)\npred = Reshape((192,256))(x)\n","d0366d48":"model_0 = Model(inputs=img_input, outputs=pred)\n\nmodel_0.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n              , metrics=[iou, dice_coef, precision, recall, accuracy])","314a5804":"model_0.load_weights('segnet_1_epoch.h5')","0ed5c524":"print('\\n~~~~~~~~~~~~~~~Stats after 1 epoch~~~~~~~~~~~~~~~~~~~')\nprint('\\n-------------On Train Set--------------------------\\n')\nres = model_0.evaluate(x_train, y_train, batch_size= 18)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')\nprint('\\n-------------On Test  Set--------------------------\\n')\nres = model_0.evaluate(x_test, y_test, batch_size= 18)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')\nprint('\\n-------------On validation Set---------------------\\n')\nres = model_0.evaluate(x_val, y_val, batch_size= 18)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')","523cf31d":"model, hist = segnet(epochs_num= 100, savename= 'segnet_100_epoch.h5')","93dd57a9":"model_1 = Model(inputs=img_input, outputs=pred)\nmodel_1.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n              , metrics=[iou, dice_coef, precision, recall, accuracy])","1c61d2d3":"model_1.load_weights('segnet_100_epoch.h5')","a96a2a16":"print('\\n~~~~~~~~~~~~~~~Stats after 100 epoch~~~~~~~~~~~~~~~~~~~')\nprint('\\n-------------On Train Set--------------------------\\n')\nres = model_1.evaluate(x_train, y_train, batch_size= 18)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')\nprint('\\n-------------On Test  Set--------------------------\\n')\nres = model_1.evaluate(x_test, y_test, batch_size= 18)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')\nprint('\\n-------------On validation Set---------------------\\n')\nres = model_1.evaluate(x_val, y_val, batch_size= 18)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')","7a11562a":"plt.figure(figsize=(20, 14))\nplt.suptitle('Training Statistics on Train Set')\nplt.subplot(2,2,1)\nplt.plot(hist.history['loss'], 'red')\nplt.title('Loss')\nplt.subplot(2,2,2)\nplt.plot(hist.history['accuracy'], 'green')\nplt.title('Accuracy')\nplt.subplot(2,2,3)\nplt.plot(hist.history['val_loss'], 'red')\nplt.yticks(list(np.arange(0.0, 1.0, 0.10)))\nplt.title('Valdiation Loss')\nplt.subplot(2,2,4)\nplt.plot(hist.history['val_accuracy'], 'green')\nplt.yticks(list(np.arange(0.0, 1.0, 0.10)))\nplt.title('Validation Accuracy')\nplt.show()","1a0e67d0":"img_num = 49\nimg_pred = model_0.predict(x_test[img_num].reshape(1,192,256,3))\nplt.figure(figsize=(16,16))\nplt.subplot(1,3,1)\nplt.imshow(x_test[img_num])\nplt.title('Original Image')\nplt.subplot(1,3,2)\nplt.imshow(y_test[img_num], plt.cm.binary_r)\nplt.title('Ground Truth')\nplt.subplot(1,3,3)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Output')\nplt.show()","6c754988":"img_num = 36\nimg_pred = model_1.predict(x_test[img_num].reshape(1,192,256,3))\nplt.figure(figsize=(16,16))\nplt.subplot(1,3,1)\nplt.imshow(x_test[img_num])\nplt.title('Original Image')\nplt.subplot(1,3,2)\nplt.imshow(y_test[img_num], plt.cm.binary_r)\nplt.title('Ground Truth')\nplt.subplot(1,3,3)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Output')\nplt.show()","b4a45a49":"img_num = 32\nimg_pred = model_1.predict(x_test[img_num].reshape(1,192,256,3))\nplt.figure(figsize=(16,16))\nplt.subplot(1,3,1)\nplt.imshow(x_test[img_num])\nplt.title('Original Image')\nplt.subplot(1,3,2)\nplt.imshow(y_test[img_num], plt.cm.binary_r)\nplt.title('Ground Truth')\nplt.subplot(1,3,3)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Output')\nplt.show()","df215d71":"img_num = 29\nimg_pred = model_1.predict(x_test[img_num].reshape(1,192,256,3))\nplt.figure(figsize=(16,16))\nplt.subplot(1,3,1)\nplt.imshow(x_test[img_num])\nplt.title('Original Image')\nplt.subplot(1,3,2)\nplt.imshow(y_test[img_num], plt.cm.binary_r)\nplt.title('Ground Truth')\nplt.subplot(1,3,3)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Output')\nplt.show()","89263e9c":"img_num = 21\nimg_pred = model_1.predict(x_test[img_num].reshape(1,192,256,3))\nplt.figure(figsize=(16,16))\nplt.subplot(1,3,1)\nplt.imshow(x_test[img_num])\nplt.title('Original Image')\nplt.subplot(1,3,2)\nplt.imshow(y_test[img_num], plt.cm.binary_r)\nplt.title('Ground Truth')\nplt.subplot(1,3,3)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Output')\nplt.show()","22f7def5":"def enhance(img):\n    sub = (model_1.predict(img.reshape(1,192,256,3))).flatten()\n\n    for i in range(len(sub)):\n        if sub[i] > 0.2:\n            sub[i] = 1\n        else:\n            sub[i] = 0\n    return sub","8ad866c7":"plt.figure(figsize=(12,12))\nplt.suptitle('Comparing the Prediction after enhancement')\nplt.subplot(3,2,1)\nplt.imshow(y_test[21],plt.cm.binary_r)\nplt.title('Ground Truth')\nplt.subplot(3,2,2)\nplt.imshow(enhance(x_test[21]).reshape(192,256), plt.cm.binary_r)\nplt.title('Predicted')\nplt.subplot(3,2,3)\nplt.imshow(y_test[19],plt.cm.binary_r)\nplt.title('Ground Truth')\nplt.subplot(3,2,4)\nplt.imshow(enhance(x_test[19]).reshape(192,256), plt.cm.binary_r)\nplt.title('Predicted')\nplt.subplot(3,2,5)\nplt.imshow(y_test[36],plt.cm.binary_r)\nplt.title('Ground Truth')\nplt.subplot(3,2,6)\nplt.imshow(enhance(x_test[36]).reshape(192,256), plt.cm.binary_r)\nplt.title('Predicted')\nplt.show()","70c07216":"Converting the transformed Images into numpy arrays","7ed717d8":"Defining a function to load the data in sorted order","7c7e7867":"We are going to define to methods for augmentation, one for **random rotation** and one for **horizontal flipping**","21e47844":"### Visualising Predicted Lesions","480977af":"#### Dice Coefficient\nThe Dice score is not only a measure of how many positives you find, but it also penalizes for the false positives that the method finds, similar to precision. so it is more similar to precision than accuracy.","1a32bc59":"![i](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/4c233366865312bc99c832d1475e152c5074891b)","cd19ac28":"![i](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/26106935459abe7c266f7b1ebfa2a824b334c807)","b70f68d5":"![i](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*Z1hkDvyhFBogT9EkzVkX2A.png)","1f8ee818":"Optimizer and Learning Rate  \n* We adopt SGD optimization algorithm, to adjust the learning rate.\n* It is well known that learning rate is one of the critical hyperparameters that have a signi\ufb01cant impact on classi\ufb01cation performance.\n* On large datasets, SGD can converge faster than batch training because it performs updates more frequently. We can get away with this because the data often contains redundant information, so the gradient can be reasonably approximated without using the full dataset. Minibatch training can be faster than training on single data points because it can take advantage of vectorized operations to process the entire minibatch at once. The stochastic nature of online\/minibatch training can also make it possible to hop out of local minima that might otherwise trap batch training.\n* The learning rate is the conventional 0.001.","ec9959db":"## Image Augmentation","0b225145":"### Importing the Libraries","0fc1a55d":"Splitting the dataset into training set and test set to verify our model performance without any bias.","633f8903":"Defining the model in a function which takes two arguments when called\n\n\n* **epoch_num**: number of epochs to run  \n* **savename**: the name of the model for saving after training  ","92596e8a":"### *de nada!*","2c62b739":"#### After 100 epochs","1afec09b":"* Currently the predicted outputs are blurry because the predicted pixel values are in the range 0 - 1.\n* To make clear edge preditions we can enhance our image by rounding up the pixel values to 1 which are > 0.2 .\n* While rounding down the pixel values to 0 which are < 0.2.\n* We can enhance the image to look for absolute shape predicted by ceiling and flooring the predicted values","1f243c0b":"#### After 1 epoch","e58a6b38":"We can observe that the images are of dimensions **(572, 765)** so we will scale dow the images. It will also reduce the training time of the network.","d49535ca":"![i](https:\/\/www.d2l.ai\/_images\/iou.svg)","4705986e":"Now we join all the augmentations image arrays to the original training arrays.","6452527c":"![ii](https:\/\/raw.githubusercontent.com\/hashbanger\/PersonalStuff\/master\/test2.jpg)","df338026":"## Defining Evaluation Metrics","be1c005c":"#### Resizing","531d2e40":"We have trained the model on the **training set**.  \nWe will make predictions on the unseen **test set**","45590e5b":"* The above network is a variation of the architecture proposed [here](https:\/\/arxiv.org\/pdf\/1511.00561.pdf), we have customised it for our problem of lesion segmentation.\n* The advised parameters can't exactly be applied to our problem.\n* We will switch the final activation function from **Softmax** to **Sigmoid** as using softmax was producing blank dark images.\n* The loss function in segnet is suggested **categorical crossentropy** due to it's genral use of multiclass segmentation problem but in our case we only have 1 class i.e. the melanoma. So, we will use **binary crossentropy**.","9a3835f0":"#### Model Function","10ff1ec5":"We will split our full training set into train and validation set.  \nValidation dataset is used to validate the performance after each epoch","01f13e0f":"## Loading the data","84b69a02":"#### Intersection over Union\nThe Jaccard index, also known as Intersection over Union and the Jaccard similarity coefficient is a statistic used for gauging the similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets:","1eb3f82f":"* First we will load the filenames in a list.  \n* Then we will open each filename as an Image and convert it to numpy array and create list of such numpy arrays.\n* Same will be done for both Feature Images and Label Images","1ca77540":"To build a powerful image classifier using very little training data, image augmentation is usually required to boost the performance of deep networks. Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc.","235c6199":"calling the functions for the training data.","29458f8e":"### Final Enhance","5738f7a6":"### Plotting Training Statistics","f0a5d7bb":"#### Recall\nRecall actually calculates how many of the Actual Positives our model capture through labeling it as Positive (True Positive). Applying the same understanding, we know that Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative","1eaf3888":"Here we can load a pre-trained model","e55cbd99":"#### Accuracy","03a05ac9":"So we can observe that our results are very good on the Test dataset which suggests that the model is quite robust and well performing too","f62bbba0":"### Loading the Model","8af8a98b":"#### Precision\nPrecision is a good measure to determine, when the costs of False Positive is high","fccafc0b":"## The Model","3729f83f":"#### Making a Validation Set","0291f7ec":"Let us check the new images","c5957335":"Let us have a look at our transformations."}}