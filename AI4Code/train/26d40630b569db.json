{"cell_type":{"5fe9c3f7":"code","4ba8585d":"code","5f87ba13":"code","8b76a76e":"code","fd9474bd":"code","ab19ad8d":"code","8fccd621":"code","f271fa6d":"code","18a92c22":"code","71f831c3":"code","e677edc5":"code","7f8dc787":"code","ba057678":"markdown","140e83bd":"markdown","21d62cb7":"markdown","17e350eb":"markdown","d3bc3a55":"markdown","b5920290":"markdown"},"source":{"5fe9c3f7":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","4ba8585d":"data = pd.read_csv('..\/input\/kepler-exoplanet-search-results\/cumulative.csv')","5f87ba13":"data","8b76a76e":"data.info()","fd9474bd":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unused columns\n    df = df.drop(['rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_pdisposition', 'koi_score'], axis=1)\n    \n    # Limit target values to CANDIDATE and CONFIRMED\n    false_positive_rows = df.query(\"koi_disposition == 'FALSE POSITIVE'\").index\n    df = df.drop(false_positive_rows, axis=0).reset_index(drop=True)\n    \n    # Drop columns with all missing values\n    df = df.drop(['koi_teq_err1', 'koi_teq_err2'], axis=1)\n    \n    # Fill remaining missing values\n    df['koi_tce_delivname'] = df['koi_tce_delivname'].fillna(df['koi_tce_delivname'].mode()[0])\n    for column in df.columns[df.isna().sum() > 0]:\n        df[column] = df[column].fillna(df[column].mean())\n    \n    # One-hot encode koi_tce_delivname column\n    delivname_dummies = pd.get_dummies(df['koi_tce_delivname'], prefix='delivname')\n    df = pd.concat([df, delivname_dummies], axis=1)\n    df = df.drop('koi_tce_delivname', axis=1)\n    \n    # Split df into X and y\n    y = df['koi_disposition']\n    X = df.drop('koi_disposition', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","ab19ad8d":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","8fccd621":"X_train","f271fa6d":"y_train.value_counts()","18a92c22":"models = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"      Decision Tree\": DecisionTreeClassifier(),\n    \"     Neural Network\": MLPClassifier(),\n    \"      Random Forest\": RandomForestClassifier(),\n    \"  Gradient Boosting\": GradientBoostingClassifier(),\n    \"            XGBoost\": XGBClassifier(eval_metric='logloss'),\n    \"           LightGBM\": LGBMClassifier(),\n    \"           CatBoost\": CatBoostClassifier(verbose=0)\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","71f831c3":"def get_classifications(y_test, y_pred, positive_label='CONFIRMED'):\n    tp = 0\n    fn = 0\n    fp = 0\n    tn = 0\n    \n    for y_t, y_p in zip(y_test, y_pred):\n        if y_t == positive_label:\n            if y_p == positive_label:\n                tp += 1\n            else:\n                fn += 1\n        else:\n            if y_p == positive_label:\n                fp += 1\n            else:\n                tn += 1\n    \n    return tp, fn, fp, tn\n\ndef get_accuracy(tp, fn, fp, tn):\n    acc = (tp + tn) \/ (tp + fn + fp + tn)\n    return acc\n\ndef get_precision(tp, fn, fp, tn):\n    precision = tp \/ (tp + fp)\n    return precision\n\ndef get_recall(tp, fn, fp, tn):\n    recall = tp \/ (tp + fn)\n    return recall\n\ndef get_f1_score(tp, fn, fp, tn):\n    precision = get_precision(tp, fn, fp, tn)\n    recall = get_recall(tp, fn, fp, tn)\n    f1_score = (2 * precision * recall) \/ (precision + recall)\n    return f1_score","e677edc5":"for name, model in models.items():\n    y_pred = model.predict(X_test)\n    print(name + \" Accuracy: {:.3f}%\".format(get_accuracy(*get_classifications(y_test, y_pred)) * 100))","7f8dc787":"for name, model in models.items():\n    y_pred = model.predict(X_test)\n    print(name + \" F1 Score: {:.5f}\".format(get_f1_score(*get_classifications(y_test, y_pred))))","ba057678":"# Preprocessing","140e83bd":"# Task for Today  \n\n***\n\n## Exoplanet Identification  \n  \nGiven *data collected about objects in space*, let's try to predict whether a given object is an **exoplanet** or not.  \n  \nWe will use a variety of classification models to make our predictions.","21d62cb7":"# Training","17e350eb":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/nklFC-_xi2U","d3bc3a55":"# Getting Started","b5920290":"# Results"}}