{"cell_type":{"0301b09c":"code","21b08f91":"code","7b679be1":"code","6dfe0f38":"code","6aa8de37":"code","c685565a":"code","97c48e97":"code","a9e86231":"code","18663eb4":"code","76bc9530":"code","753dfdda":"code","8e2954a8":"code","48dd3a7f":"code","f621f9d1":"code","2c14d7de":"code","ac9879c1":"code","eb8c7bd1":"code","bfc803c2":"code","811669b7":"code","e681b610":"code","0a3515a9":"code","721a0533":"code","ea0340e3":"code","eabd01fd":"code","e8a57156":"code","a4852f62":"code","a3c1ac5e":"code","4d5df87e":"code","18b02378":"code","33aa0613":"code","546c8fc4":"code","57b1f2fb":"code","5e6ccef3":"code","9315a316":"code","b40a3925":"code","ea752400":"code","8c3c2ff0":"code","9b59b8c4":"code","6d0bc0c8":"code","328dc59d":"code","f2616e4a":"code","ee2fea8a":"code","973f55eb":"code","4646747d":"code","950957ab":"code","ee243c97":"code","a7a784ea":"code","c7fd934c":"code","4e258677":"code","b938a835":"code","37babb9d":"code","81e7ad62":"markdown","9aec9642":"markdown","d4e0a259":"markdown","769f7b24":"markdown","4646716c":"markdown","d34ff2bc":"markdown","d8fdaeb3":"markdown","27e3731a":"markdown","fbfb1795":"markdown","52cc4b5d":"markdown","832e379b":"markdown","613ab27a":"markdown","82632e8e":"markdown","49871d62":"markdown","69fc9a61":"markdown"},"source":{"0301b09c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","21b08f91":"import pandas as pd\nimport numpy as np\ndf_train = pd.read_csv('\/kaggle\/input\/workshop-shopee-machine-learning-ann-scikitlearn\/HR-Employee-Attrition_train.csv')\ndf_train","7b679be1":"#check if there is any missing value\ndf_train.info()","6dfe0f38":"#Check numerical data columns\nprint('There are %s numerical columns.'%(str(len(df_train.select_dtypes(include=['int64']).columns))))\ndf_train.select_dtypes(include=['int64']).columns","6aa8de37":"#check categorical data columns \nprint('There are %s numerical columns.'%(str(len(df_train.select_dtypes(include=['object']).columns))))\ndf_train.select_dtypes(include=['object']).columns","c685565a":"id_col = 'EmployeeNumber'\n\ntarget_col = 'Attrition'\n\n#25 numerical columns\nnumerical_cols = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EmployeeCount', 'EnvironmentSatisfaction', \n                'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', \n                'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', \n                'StandardHours', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', \n                'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n\n#8 categorical columns\ncategorical_cols = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', \n                 'Over18', 'OverTime']","97c48e97":"#check 8 categorical columns\nnunique_values = []\nna_values = []\nfor col in categorical_cols:\n    nunique_values.append(df_train[col].nunique())\n    na_values.append(len(df_train.loc[df_train[col].isna()]))\ndf_train_stats_categorical = pd.DataFrame(list(zip(categorical_cols,nunique_values,na_values)),columns=['Column_Name','#Unique_Values','#Null_Value'])\ndf_train_stats_categorical","a9e86231":"#check Null columns\ndf_train_stats_categorical[df_train_stats_categorical['#Null_Value']>0]","18663eb4":"#check columns with only 1 value\ndf_train_stats_categorical[df_train_stats_categorical['#Unique_Values'] == 1]","76bc9530":"#check 25 numerical columns\nna_values = []\nfor col in numerical_cols:\n    na_values.append(len(df_train.loc[df_train[col].isna()]))\ndf_train_stats_numerical = pd.DataFrame(list(zip(numerical_cols,na_values)),columns=['Column_Name','#Null_Value'])\ndf_train_stats_numerical","753dfdda":"#check Null columns\ndf_train_stats_numerical[df_train_stats_numerical['#Null_Value']>0]","8e2954a8":"df_train_stats_numerical = df_train[numerical_cols].describe().T\ndf_train_stats_numerical","48dd3a7f":"#check columns with only 1 value\ndf_train_stats_numerical[df_train_stats_numerical['std']==0]","f621f9d1":"#check categorical columns\ndef explore_categorical_columns(df,categorical_cols):\n    nunique_values = []\n    na_values = []\n    for col in categorical_cols:\n        nunique_values.append(df[col].nunique())\n        na_values.append(len(df.loc[df[col].isna()]))\n    df_stats_categorical = pd.DataFrame(list(zip(categorical_cols,nunique_values,na_values)),columns=['Column_Name','#Unique_Values','#Null_Value'])\n    df_null = df_stats_categorical[df_stats_categorical['#Null_Value']>0]\n    df_unique_value = df_stats_categorical[df_stats_categorical['#Unique_Values'] == 1]\n    if len(df_null) > 0:\n        print('Columns with Null value: %s'%(str(df_null['Column_Name'])))\n    else:\n        print('There is no Null values in the categorical columns')\n    if len(df_unique_value) > 0:\n        print('Columns with only 1 unique value: %s'%(str(list(df_unique_value['Column_Name']))))\n    else:\n        print('All categorical columns have more than 1 value.')\n        \n#check numerical columns\ndef explore_numerical_columns(df,numerical_cols):\n    na_values = []\n    for col in numerical_cols:\n        na_values.append(len(df.loc[df[col].isna()]))\n    df_stats_numerical = pd.DataFrame(list(zip(numerical_cols,na_values)),columns=['Column_Name','#Null_Value'])\n    df_null = df_stats_numerical[df_stats_numerical['#Null_Value']>0]\n    df_stats = df[numerical_cols].describe().T\n    df_unique_value = df_stats[df_stats['std']==0]\n    \n    if len(df_null) > 0:\n        print('Columns with Null value: %s'%(str(df_null['Column_Name'])))\n    else:\n        print('There is no Null values in the numerical columns')\n    \n    if len(df_unique_value) > 0:\n        print('Columns with only 1 unique value: %s'%(str(list(df_unique_value.index))))\n    else:\n        print('All numerical columns have more than 1 value. \\n')\n\n#check categorical columns\nprint('Categorical_Columns'.center(50,\"*\"))\nexplore_categorical_columns(df_train,categorical_cols)\nprint('Numerical_Columns'.center(50,\"*\"))\n#check numerical columns\nexplore_numerical_columns(df_train,numerical_cols)","2c14d7de":"# Check target variable\ndf_train[target_col].unique()","ac9879c1":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\ndef process_numerical_data(df,numerical_cols,drop_numerical_columns):\n    sacalar = MinMaxScaler()\n    # sacalar = StandardScaler() if using StandardScaler\n    scale_numerical_cols = list(set(numerical_cols)-set(drop_numerical_columns))\n    df_numerical = sacalar.fit_transform(df[scale_numerical_cols])\n    df_numerical = pd.DataFrame(df_numerical,columns=scale_numerical_cols)\n    return df_numerical\n\ndrop_numerical_columns = ['EmployeeCount', 'StandardHours']\ndf_train_numerical = process_numerical_data(df_train,numerical_cols,drop_numerical_columns)\ndf_train_numerical","eb8c7bd1":"df_train[categorical_cols]","bfc803c2":"?pd.get_dummies","811669b7":"def process_categorical_data(df,categorical_cols,drop_categorical_columns):\n    df_categorical = pd.get_dummies(df[[var for var in categorical_cols if var not in drop_categorical_columns]])\n    return df_categorical","e681b610":"drop_categorical_columns = ['Over18']\ndf_train_categorical = process_categorical_data(df_train, categorical_cols, drop_categorical_columns)\ndf_train_categorical","0a3515a9":"df_train_numerical.shape, df_train_categorical.shape","721a0533":"df_train_features = pd.concat([df_train_numerical, df_train_categorical],axis=1)\ndf_train_features.shape","ea0340e3":"df_train_features","eabd01fd":"def process_label(df):\n    target_col_dict = {'Yes': 1, 'No': 0}\n    df_labels = df[target_col].map(target_col_dict).values\n    return df_labels\ndf_train_labels = process_label(df_train)\ndf_train_labels.shape","e8a57156":"df_train_labels","a4852f62":"# split the data into train and test\nfrom sklearn.model_selection import train_test_split\ntrain_x, test_x, train_y, test_y = train_test_split(df_train_features,df_train_labels,test_size=0.3,random_state=23)","a3c1ac5e":"from sklearn.neural_network import MLPClassifier\nNN = MLPClassifier()\nNN.fit(train_x,train_y)","4d5df87e":"NN_predicted_y = NN.predict(test_x)","18b02378":"from sklearn.metrics import accuracy_score\naccuracy_score(test_y,NN_predicted_y)","33aa0613":"df_test = pd.read_csv('\/kaggle\/input\/workshop-shopee-machine-learning-ann-scikitlearn\/HR-Employee-Attrition_test.csv')\ndf_test","546c8fc4":"df_test.info()","57b1f2fb":"print('Missing columns in test dataset(campared with train dataset): %s'%(str(set(df_train.columns)-set(df_test.columns))))","5e6ccef3":"id_col = 'EmployeeNumber'\n\nnumerical_cols = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EmployeeCount', 'EnvironmentSatisfaction', 'HourlyRate', \n                  'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', \n                  'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel', \n                  'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', \n                  'YearsSinceLastPromotion', 'YearsWithCurrManager']\n\ncategorical_cols = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']","9315a316":"#check 8 categorical columns\nprint('Categorical_Columns'.center(50,\"*\"))\nexplore_categorical_columns(df_test,categorical_cols)\nprint('Numerical_Columns'.center(50,\"*\"))\nexplore_numerical_columns(df_test,numerical_cols)","b40a3925":"drop_numerical_columns = ['EmployeeCount', 'StandardHours']\ndf_test_numerical = process_numerical_data(df_test,numerical_cols,drop_numerical_columns)\ndf_test_numerical","ea752400":"# to check if there's any missing numerical columns in test dataset\nset(df_train_numerical.columns)-set(df_test_numerical.columns)","8c3c2ff0":"drop_categorical_columns = ['Over18']\ndf_test_categorical = process_categorical_data(df_test,categorical_cols,drop_categorical_columns)\ndf_test_categorical","9b59b8c4":"# to check if there's any missing categorical columns in test dataset\nset(df_train_categorical.columns)-set(df_test_categorical.columns)","6d0bc0c8":"df_test_features = pd.concat([df_test_numerical, df_test_categorical],axis=1)\ndf_test_features","328dc59d":"predicted_test = NN.predict(df_test_features)\npredicted_test","f2616e4a":"answer = df_test[['EmployeeNumber']]\nanswer['Attrition'] = ['Yes' if i == 1 else 'No' for i in predicted_test]\nanswer","ee2fea8a":"answer.to_csv('submission.csv',index=False)","973f55eb":"%%time\nimport time\nstart_time = time.time()\nNN_new = MLPClassifier(max_iter=1000)\nparameter_space = {\n    'hidden_layer_sizes': [(50,50,50), (50,100,50), (50,100,50,25)],\n    'activation': ['tanh', 'relu','logistic'],\n    'solver': ['adam', 'lbfgs'],\n    'alpha': [0.001, 0.01],\n    'learning_rate': ['constant','adaptive'],\n}\nfrom sklearn.model_selection import GridSearchCV\n\nclf = GridSearchCV(NN_new, parameter_space, n_jobs=-1, cv=10)\nclf.fit(train_x, train_y)\nprint('Time taken for training the model: '+ str(time.time() - start_time))","4646747d":"# Best paramete set\nprint('Best parameters found:\\n', clf.best_params_)","950957ab":"# All results\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n    print(\"%0.3f (+\/-%0.03f) for %r\" % (mean, std * 2, params))","ee243c97":"y_true, y_pred = test_y , clf.predict(test_x)\nfrom sklearn.metrics import classification_report\nprint('Results on the test set:')\nprint(classification_report(y_true, y_pred))","a7a784ea":"accuracy_score(y_true, y_pred)","c7fd934c":"test_y_pred = clf.predict(df_test_features)","4e258677":"df_result = pd.DataFrame.from_dict(dict({'EmployeeNumber':list(df_test['EmployeeNumber']),\n                                         'Attrition':['Yes' if i == 1 else 'No' for i in test_y_pred]}))\ndf_result","b938a835":"# difference predictions between 2 models\ntemp = pd.merge(df_result,answer,on='EmployeeNumber',how='inner')\ntemp.loc[~(temp['Attrition_x']==temp['Attrition_y'])]","37babb9d":"df_result.to_csv(\"submission.csv\", index=False)","81e7ad62":"we can continue using the same 4 group column types:","9aec9642":"The column 'Over18' only contains 1 unique value, therefore we could drop it.","d4e0a259":"# Data Process","769f7b24":"- The column 'Over18' only contains 1 unique value, therefore we could drop it.\n- Columns like 'EmployeeCount' and 'StandardHours' have 0 std, meaning all the values are the same, therefore we can drop them.","4646716c":"    # Scaling Numerical Data\n<img src=\"https:\/\/miro.medium.com\/max\/1276\/0*_apuT0HdrVYMUCh7\">","d34ff2bc":"# Now we can divide all these 35 columns into 4 parts:\n1. id column\n2. target column\n3. numerical columns\n4. categorical columns","d8fdaeb3":"# Set up and train the model","27e3731a":"source: https:\/\/drive.google.com\/drive\/u\/1\/folders\/11dkedNqANAZbpxuG5Krd5d7n8XD3FGH3","fbfb1795":"# Loading data and do EDA(Exploratory Data Analysis)","52cc4b5d":"    # Convert categorical columns into numerical columns\n<img src=\"https:\/\/i.imgur.com\/mtimFxh.png\">\n    ","832e379b":"# Loading the test dataset and do the EDA","613ab27a":"# Make prediction on test dataset","82632e8e":"# GridSearch to find the optimal parameter setting\nMost used parameter\n\n1\uff09The ith element represents the number of neurons in the ith hidden layer.\n    example: ``hidden_layer_sizes``=(10)\n    \n2\uff09activation function\n    example: ``activation``=\"relu\"\n\n3\uff09The solver for weight optimization. {'lbfgs', 'sgd', 'adam'}\n    example: ``solver``='adam'\n\n4\uff09L2 penalty (regularization term) parameter\n    example: ``alpha``=0.0001\n\n5\uff09Size of minibatches for stochastic optimizers.\n    If the solver is 'lbfgs', the classifier will not use minibatch.\n    When set to 'auto', 'batch_size=min(200, n_samples)'\n    example: ``batch_size``='auto'\n\n6\uff09Learning rate schedule for weight updates.\n    example: ``learning_rate``=\"constant\"\n\n7\uff09The initial learning rate used. It controls the step-size in updating the weights. Only used when solver='sgd' or 'adam'.\n    example: ``learning_rate_init``=0.001\n\n8\uff09Maximum number of iterations. The solver iterates until convergence\n    example: ``max_iter``=200\n\n9\uff09Tolerance for the optimization. When the loss or score is not improving\n    by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n    unless ``learning_rate`` is set to 'adaptive', convergence is\n    considered to be reached and training stops.\n    example: ``tol``=1e-4","49871d62":"Columns like 'EmployeeCount' and 'StandardHours' have 0 std, meaning all the values are the same, therefore we can drop them.","69fc9a61":"<img src= 'https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F4342316%2F9c2161bc579fae87686285d953bdf56d%2Fdata%20description.png?generation=1591008771269892&alt=media'>"}}