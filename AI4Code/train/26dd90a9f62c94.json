{"cell_type":{"498beb94":"code","2cdfb650":"code","93cf5501":"code","83ebf789":"code","1f8dac90":"code","e5724766":"code","223323cb":"code","8be4d506":"code","9dc2c8d3":"code","4028ca45":"code","2fd74aa4":"code","37422e24":"code","303ca6c7":"code","81d7ba21":"markdown","7ac00f04":"markdown"},"source":{"498beb94":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as pimg\nfrom IPython.display import clear_output\nimport os\nfrom tensorflow.keras.callbacks import ModelCheckpoint","2cdfb650":"ds_directory = '..\/input\/malerial-cell-classification-dataset\/cell_images\/cell_images'","93cf5501":"train = keras.preprocessing.image_dataset_from_directory(\n    ds_directory,\n    labels='inferred',\n    label_mode='binary',\n    color_mode='rgb',\n    batch_size=256,\n    image_size=(128,128),\n    shuffle=True,\n    seed=64,\n    validation_split=0.1,\n    subset=\"training\"\n)\nval = keras.preprocessing.image_dataset_from_directory(\n    ds_directory,\n    labels='inferred',\n    label_mode='binary',\n    color_mode='rgb',\n    batch_size=256,\n    image_size=(128,128),\n    shuffle=True,\n    seed=64,\n    validation_split=0.1,\n    subset=\"validation\"\n)","83ebf789":"data_augmentation = tf.keras.Sequential([\n  keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n  keras.layers.experimental.preprocessing.RandomRotation(0.2),\n], name='data_augmentation') # copied directly from TensorFlow's website","1f8dac90":"model = keras.Sequential([\n      keras.layers.InputLayer(input_shape=[128,128,3]),\n      data_augmentation,\n      keras.layers.experimental.preprocessing.Normalization(axis=None), #added a normalization layer                                    \n      keras.layers.Conv2D(16, (3,3)),\n      keras.layers.LeakyReLU(0.3),\n      keras.layers.MaxPooling2D(),\n      keras.layers.Conv2D(32, (3,3)),\n      keras.layers.LeakyReLU(0.3),\n      keras.layers.MaxPooling2D(),\n      keras.layers.Conv2D(64, (3,3)), \n      keras.layers.LeakyReLU(0.3),\n      keras.layers.MaxPooling2D(),\n      keras.layers.Flatten(),\n      keras.layers.Dense(128, activation='relu'),\n      keras.layers.Dropout(0.1),\n      keras.layers.Dense(64, activation='relu'),\n      keras.layers.Dropout(0.1),\n      keras.layers.Dense(1, activation='sigmoid')\n])\n\nopt = keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(\n  optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n)\n\nmodel.summary()","e5724766":"checkpoint = ModelCheckpoint('m_weights.hdf5', monitor='loss', verbose=1, save_best_only=True, mode='min')\nchkpt_callback = [checkpoint]","223323cb":"history = model.fit(train, epochs=15, validation_data=val, callbacks=chkpt_callback)","8be4d506":"checkpoint = ModelCheckpoint('m2_weights.hdf5', monitor='loss', verbose=1, save_best_only=True, mode='min')\nchkpt_callback = [checkpoint]","9dc2c8d3":"history2 = model.fit(train, epochs=10, validation_data=val, callbacks=chkpt_callback)","4028ca45":"v_prec1 = history.history['val_precision_4'][-1]\nv_rec1 = history.history['val_recall_4'][-1]\nprec1 = history.history['precision_4'][-1]\nrec1 = history.history['recall_4'][-1]\ndef f1(prec, rec):\n    f1 = 2 * ((prec * rec) \/ (prec + rec))\n    return f1\n    \nprint(f'Training Data F1 Score: {f1(prec1, rec1)}')\nprint(f'Validation Data F1 Score: {f1(v_prec1, v_rec1)}')","2fd74aa4":"def remove_num(string):\n    a = string.replace('_', ' ')\n    ints = range(10)\n    for i in ints:\n        if str(i) in a:\n            a = a.replace(str(i), '')\n    return a","37422e24":"metrics = {}\n\nfor (metric, values), (metric2, values2) in zip(history.history.items(), history2.history.items()):\n    metrics[remove_num(metric)] = values + values2 ","303ca6c7":"plt.plot(metrics['loss'][1:])\nplt.plot(metrics['val loss'])\nplt.plot(metrics['accuracy'])\nplt.plot(metrics['val accuracy'])","81d7ba21":"I'm going to train the model for a bit more, but just in case it overfits I'm creating another checkpoint.","7ac00f04":"I need to combine the two histories together so I can show the loss\/accuracy graph"}}