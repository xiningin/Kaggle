{"cell_type":{"d8eebd08":"code","341fb5b9":"markdown","e8f90e4c":"markdown","042d35fe":"markdown","b48aea5e":"markdown","953b4e7a":"markdown","ba3705ba":"markdown","90937244":"markdown","fb9efefc":"markdown","5daeda35":"markdown","e7cd963a":"markdown","db538d9d":"markdown","d5e588a7":"markdown"},"source":{"d8eebd08":"#############","341fb5b9":"* Problem definition - Understand the business problem ( problem formalization )\n* Scatter plot - To identify the type of relationship between two quantative variables\n* Box plot - Descriptive statistics\n* Histogram - Distribution\n* Multivariate plot - Interactions between variables","e8f90e4c":"* Predictive models\n* Statistical models\n* Descriptive models\n* Visualization models","042d35fe":"## The following methods can be used to screen outliers:\n\n* Boxplot: A box plot represents the distribution of the data and its variability. The box plot contains the upper and lower quartiles, so the box basically spans the Inter-Quartile Range (IQR). One of the main reasons why box plots are used is to detect outliers in the data. Since the box plot spans the IQR, it detects the data points that lie outside this range. These data points are nothing but outliers.\n* Probabilistic and statistical models: Statistical models such as normal distribution and exponential distribution can be used to detect any variations in the distribution of data points. If any data point is found outside the distribution range, it is rendered as an outlier.\n* Linear models: Linear models such as logistic regression can be trained to flag outliers. In this manner, the model picks up the next outlier it sees.\n* Proximity-based models: An example of this kind of model is the K-means clustering model wherein, data points form multiple or \u2018k\u2019 number of clusters based on features such as similarity or distance. Since similar data points form clusters, the outliers also form their own cluster. In this way, proximity-based models can easily help detect outliers.\n## How do you handle these outliers?\n\n    If your data set is huge and rich then you can risk dropping the outliers.\n    However, if your data set is small then you can cap the outliers, by setting a threshold percentile. For example, the data points that are above the 95th percentile can be used to cap the outliers.\n    Lastly, based on the data exploration stage, you can narrow down some rules and impute the outliers based on those business rules.","b48aea5e":"* Perform an exploratory data analysis (EDA) on your dataset\n* Build a quick and dirty model or a baseline model which can serve as a comparison against later models that you will build\n* Iterate this process. You will do more EDA and vuild another model.\n* Engineer features: Take the features that you alredy have and combine them to extract more infromation from them to eventually come to the last point\n* Get a model that works better\n* Fine tune your model","953b4e7a":"# **Data Science workflow**","ba3705ba":"* Sampling \/ Feature Engineering \/ Correlations\n* Descriptive statistics\n* Feature Engineering\n* Feature Selection\n* **Challenges:**\n        * Missing values\n        * Outliers\n        * Anomalies","90937244":"## Machine Learning Project Template\n\n1. Prepare Problem\n    * Load libraries\n    * Load dataset\n\n2. Summarize Data\n    * Descriptive statistics (summary, varType, corr Matrix, Count of class labels)\n    * Visualizations (histogram, density, whisker plot, scatter & correlation matrix)\n\n3. Prepare Data\n    * Data Cleaning\n    * Feature selection\n    * Testing the assumptions\n    * Data transforms\n    \n4. Evaluate algorithms\n    * Split out validation dataset\n    * Test options and evaluation matrix\n    * Spot check algorithms\n    * Compare algorithms\n    \n5. Improve accuracy\n    * Algorithm tuning\n    * Ensembles\n\n6. Finalize model\n    * Predictions on validation dataset\n    * Create standalone model on entire training dataset\n    * save model for later use","fb9efefc":"** Exploratory Data Analysis **\n\n* Import Data\n* Descriptive statistics checking- \n    * head\n    * tail\n    * info\n    * describe\n* Deeper look on data using query and indexing. Bring basic hypothesis.\n* Feature enginering and selection\n* Challenges:\n    * Missing values\n    * Outliers\n* Find the pattern or compare the correlation between attributes - \n    * Basic description of the data\n    * Visualize it\n    * Identify pattern in it\n    * Identify challenges of using the data\n    * **Data Profiling**\n* **Sampling**\n* **Queries**\n* **Challenges**\n    * **Missing values**\n        * Either delete missing records\n        * Impute missing data\n        * Use anova or logistic regression or other modeling technique\n        * Or use KNN\n* **Filling missing values**\n* **Drop label with missing values**\n* **Interpolation**\n* **Outliers**\n    * box plot\n    * scatter plot\n        * Delete, transfer, impute\n* **Data's feature**\n    * Feature engineering\n        * Factorize a feature\n        * Bin continuous variable into group\n        * Scale feature\n    * Feature selection\n        * Evaluate the quality\n        * Predictive power\n        * Random forest algorithm\n    * Patterns in your data\n        * correlation identification with matplotlib\n        * PCA\n        * Correlation identification with Bokeh\n        * Correlation identification with pandas","5daeda35":"1. Get the dataset\n2. Try to understand the problem and also the given dataset\n3. Read the column descriptions\n4. Read the dataset shape\n5. Try to visualize the data by reading head and tail\n6. Clean and validate -\n    * .value_counts()\n    * .describe()\n    * .info()\n    * .replace()\n    * Compare your data with provided data source documentation\n    * Clean a variable if there is no representation of it in the data source documentation\n    * Compute a variable\n    * Filter and visualize\n    * Make a histogram - \n        * Distribution of a variable\n    ","e7cd963a":"**Draft stage, ignore decoration please**","db538d9d":"** Unsupervised Learning **\n* Concept learning\n* Function learning\n* Predictive modeling\n* Clusturing\n* Finding Pattern","d5e588a7":"** EDA steps **\n* Seeing the types of data and separate them as different features\n* Figuring out target feature to train the network\n* Ignore the not needed feature and feature's value\n* Missing no. library to matrix missing values\n* Imputing missing values\n* Feature Engineering: Adding, removing and changing "}}