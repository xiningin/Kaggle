{"cell_type":{"b83536ed":"code","793067d2":"code","eaad4c72":"code","e1e11940":"code","b99bf0a9":"code","79334410":"code","b2398150":"code","170029ef":"code","5dd63d5d":"code","309f0025":"code","882c95b5":"code","22dfc24a":"code","729213f9":"code","185619f7":"code","35e68044":"code","8ba9f22f":"code","1a375105":"code","64d2b71c":"code","e2626a26":"code","5108bac0":"code","9a72e7e7":"code","3591a3c0":"code","afa442ce":"code","d8c5950a":"code","e347a1f4":"code","f99edf96":"code","0fe57464":"code","6c3d9257":"code","5c8e057e":"code","f8e7b559":"code","954ff070":"code","7cbfa9c7":"code","bfc47324":"code","b7b9c3a6":"code","db3b08f9":"code","b29b07aa":"code","388d56fa":"code","8a0bd708":"code","c85639a9":"code","c6109590":"code","0116e46c":"code","945b4320":"code","46259336":"code","f0fbee94":"code","636971aa":"code","11ff5fa2":"code","734e2d90":"code","dcd600f2":"code","cb7e41c2":"code","b8522d39":"markdown","5676ed94":"markdown","d6363a6a":"markdown","069cf7f6":"markdown","ff7fd30b":"markdown","3a0b15bc":"markdown","93f4c39b":"markdown","6c7dc3e4":"markdown","9a0e50e2":"markdown","6d8c30ac":"markdown","d7420def":"markdown","fa21274d":"markdown","79787459":"markdown","34aab353":"markdown","57f13a47":"markdown","ac2fec73":"markdown","d6adda08":"markdown","9c271e19":"markdown","8d85dcdf":"markdown","c27e7e0c":"markdown","aadab953":"markdown","f9d1e7b9":"markdown","67310010":"markdown","55c7ce36":"markdown","f18b1211":"markdown","c4b4bf5f":"markdown","c93d8e2d":"markdown","fb4a0782":"markdown","1c4eae7a":"markdown","c91c9629":"markdown","c1b40169":"markdown","6abd9ee5":"markdown","41596df2":"markdown","c16184f5":"markdown","8dd33a36":"markdown","52d47fb0":"markdown","20fd9cd5":"markdown","3bcbb2e8":"markdown","2a4d8c5d":"markdown","89d1ade0":"markdown","a2a317c0":"markdown","03caedea":"markdown","be88e7ea":"markdown","0f1c5e7a":"markdown","48b4e9f1":"markdown","80a8a41b":"markdown","b056e61a":"markdown"},"source":{"b83536ed":"import os\nimport gc\nimport re\nimport cv2\nimport sys\nimport glob\nimport keras\n\nimport numpy  as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style  as style\n\nfrom tqdm  import tqdm\nfrom keras import backend as K\nfrom sklearn.metrics     import accuracy_score, roc_auc_score\nfrom keras.layers        import Dense, Dropout, Flatten, BatchNormalization, GlobalMaxPooling2D\nfrom keras.models        import Sequential, Model, load_model\nfrom keras.callbacks     import ModelCheckpoint,ReduceLROnPlateau, CSVLogger\nfrom keras.activations   import elu\nfrom keras.engine        import Layer, InputSpec\nfrom keras.applications  import MobileNetV2\nfrom keras.optimizers    import Adam\nfrom keras.preprocessing import image\nfrom sklearn.linear_model      import LogisticRegression\nfrom sklearn.model_selection   import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.mobilenetv2 import preprocess_input, decode_predictions","793067d2":"# Disable SetCopyWarnings\npd.options.mode.chained_assignment = None","eaad4c72":"# Compose filenames\nfilelist_montgommery = glob.glob('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png\/*.png')\nfilelist_shenzen     = glob.glob('..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png\/*.png')\nfilelist             = filelist_montgommery + filelist_shenzen","e1e11940":"def extract_label(file_list):\n    '''\n    Label Extraction Function\n    Reads a filename and extracts label from it\n    '''\n    labels = []\n    for file in tqdm(file_list):\n        current_label = re.findall('[0-9]{4}_(.+?).png', file)\n        labels.append(current_label[0])\n    return(labels)","b99bf0a9":"labels = extract_label(filelist)","79334410":"# Create dataframe\nfull_data = pd.DataFrame(filelist, columns=['filepath'])\nfull_data['target'] = labels\nfull_labels         = pd.DataFrame(full_data.pop('target'), columns=['target'])\n\n# Preview dataframe\nfull_data.head()","b2398150":"# Split data into training and testing sets\ntrain_df,test_df,train_y,test_y = train_test_split(full_data,\n                                                   full_labels,\n                                                   stratify     = full_labels,\n                                                   test_size    = 0.3,\n                                                   random_state = 451)","170029ef":"# Reassign labels so that we can split them again\ntrain_df['target'] = train_y['target']\ntest_df['target']  = test_y['target']","5dd63d5d":"# Split once more, so that we may produce a validation set\nlabels = train_df.pop('target')\ntrain_df, probe_df, train_y, probe_y = train_test_split(train_df,\n                                                        labels,\n                                                        stratify     = labels,\n                                                        test_size    = 0.2,\n                                                        random_state = 451)\n\n# Reassemble labels\ntrain_df['target'] = train_y\nprobe_df['target'] = probe_y","309f0025":"# Inspect Training Dataframe\ntrain_df.head()","882c95b5":"def plot_multiple_images(image_dataframe, rows = 4, columns = 4, figsize = (16, 20), resize=(1024,1024), preprocessing=None):\n    '''\n    Plots Multiple Images\n    Reads, resizes, applies preprocessing if desired and plots multiple images from a given dataframe\n    '''\n    image_dataframe = image_dataframe.reset_index(drop=True)\n    fig = plt.figure(figsize=figsize)\n    ax  = []\n\n    for i in range(rows * columns):\n        img = plt.imread(image_dataframe.loc[i,'filepath'])\n        img = cv2.resize(img, resize)\n        \n        if preprocessing:\n            img = preprocessing(img)\n        \n        ax.append(fig.add_subplot(rows, columns, i+1) )\n        ax[-1].set_title(\"Xray \"+str(i+1))\n        plt.imshow(img, alpha=1, cmap='gray')\n    \n    plt.show()","22dfc24a":"plot_multiple_images(train_df)","729213f9":"def load_image(image_path, image_dims = (128,128), grayscale=True, flatten=True, interpolation = cv2.INTER_AREA):\n    '''\n    Loads an image, resizes and removes redudant channels if so desired\n    '''\n    image         = cv2.imread(image_path)\n    resized_image = cv2.resize(image, image_dims, interpolation = interpolation)\n    \n    if grayscale:\n        resized_image = resized_image[:,:,0]\n    \n    if flatten:\n        resized_image = resized_image.flatten()\n    \n    return(resized_image)","185619f7":"def create_flattened_dataframe(df, interpolation = cv2.INTER_AREA):\n    df     = df.reset_index(drop=True)\n    result = pd.DataFrame()\n    \n    for i in tqdm(range(df.shape[0])):\n        im_path = df.loc[i,'filepath']\n        current = load_image(im_path, interpolation = interpolation).tolist()\n        current = pd.DataFrame(current).T\n        result  = result.append(current)\n    \n    return(result)","35e68044":"# Flatten Training dataframe\ntrain_df_flat = create_flattened_dataframe(train_df)\nprobe_df_flat = create_flattened_dataframe(probe_df)\ntest_df_flat  = create_flattened_dataframe(test_df)","8ba9f22f":"train_df_flat.head()","1a375105":"# Create Logistic Regression\nlogit_model = LogisticRegression(random_state=451, solver='lbfgs', max_iter=1000)\nlogit_model.fit(train_df_flat, train_df['target'])","64d2b71c":"def evaluate_predictions(preds, eval_df = test_df):\n    '''\n    Evaluate Predictions Function\n    Returns accuracy and auc of the model\n    '''\n    auroc = roc_auc_score(eval_df['target'].astype('uint8'), preds)\n    accur = accuracy_score(eval_df['target'].astype('uint8'), preds >= 0.5)\n    print('Accuracy: ' + str(auroc))\n    print('AUC: ' + str(accur))","e2626a26":"# Evaluate Model Results - Validation Set\nlogit_preds_val  = logit_model.predict_proba(probe_df_flat)\nevaluate_predictions(logit_preds_val[:,1], eval_df = probe_df)","5108bac0":"# Evaluate Model Results - Testing Set\nlogit_preds  = logit_model.predict_proba(test_df_flat)\nevaluate_predictions(logit_preds[:,1], eval_df = test_df)","9a72e7e7":"batch_size = 32\ninput_size = (224,224)","3591a3c0":"# Create training data generator\ntrain_generator = ImageDataGenerator(rescale = 1.\/255,\n                                     horizontal_flip = True,\n                                     zoom_range      = 0.1,\n                                     shear_range     = 0,\n                                     rotation_range  = 5,\n                                     width_shift_range  = 0.05,\n                                     height_shift_range = 0.05,\n                                     fill_mode = 'constant',\n                                     cval      = 0,\n                                     preprocessing_function = preprocess_input)\n\n# Create testing data generator\ntest_generator  = ImageDataGenerator(rescale = 1.\/255,\n                                     preprocessing_function = preprocess_input)","afa442ce":"train = train_generator.flow_from_dataframe(dataframe = train_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'filepath',\n                                    y_col       = 'target',\n                                    shuffle     = True,\n                                    batch_size  = batch_size,\n                                    target_size = input_size,\n                                    seed=451)\n\nprobe = train_generator.flow_from_dataframe(dataframe = probe_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'filepath',\n                                    y_col       = 'target',\n                                    shuffle     = True,\n                                    batch_size  = batch_size,\n                                    target_size = input_size,\n                                    seed=451)","d8c5950a":"# Create model instance\nmodel = Sequential()\n\n# Add Pretrained Model\nmodel.add(MobileNetV2(weights = 'imagenet', input_shape = (224,224,3), include_top=False))\n\n# Add FC and Output layers\nmodel.add(GlobalMaxPooling2D())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile Model\nmodel.compile(optimizer=Adam(lr=1e-1), loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()","e347a1f4":"# Create callback\ncsv_logger = CSVLogger('training_log_mobilenet_try_1.csv')","f99edf96":"# Train model\nmodel.fit_generator(\n        train,\n        callbacks = [csv_logger],\n        epochs    = 10,\n        steps_per_epoch  = train.samples \/\/ batch_size,\n        validation_data  = probe,\n        validation_steps = probe.samples \/\/ batch_size)","0fe57464":"# Create test generator\ntest = test_generator.flow_from_dataframe(dataframe = test_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'filepath',\n                                    y_col       = 'target',\n                                    shuffle     = False,\n                                    batch_size  = batch_size,\n                                    target_size = input_size)\n\n# Generate Predictions\npreds = model.predict_generator(test, steps= test.samples \/ batch_size)\n\n# Evaluate Model Results\nevaluate_predictions(preds)","6c3d9257":"def plot_training_hist(keras_model):\n    '''\n    Plot training History\n    Creates two plots of model training logs\n    '''\n    hist = keras_model.history.history\n    style.use('fivethirtyeight')\n    \n    # Loss Plot\n    fig = plt.figure(figsize=(12,4))\n    plt.title('Loss Plot')\n    plt.plot(hist['loss'], '#07e9ed')\n    plt.plot(hist['val_loss'], '#0791ed')\n    plt.ylim([0,1.2 * max(max(hist['loss'], hist['val_loss']))])\n    plt.legend(['train', 'validation'], loc='lower right')\n    plt.show()\n    \n    # Accuracy Plot\n    fig = plt.figure(figsize=(12,4))\n    plt.title('Accuracy Plot')\n    plt.plot(hist['acc'], '#07e9ed')\n    plt.plot(hist['val_acc'], '#0791ed')\n    plt.legend(['train', 'validation'], loc='lower right')\n    plt.ylim([0,1])\n    \n    # Show Plot, reset style\n    plt.show()\n    style.use('default')","5c8e057e":"plot_training_hist(model)","f8e7b559":"# Create model instance\nmodel = Sequential()\n\n# Add Pretrained Model\nmodel.add(MobileNetV2(weights = 'imagenet', input_shape = (224,224,3), include_top=False))\n\n# Add FC and Output layers\nmodel.add(GlobalMaxPooling2D())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile Model\nmodel.compile(optimizer=Adam(lr=2e-4), loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()","954ff070":"# Train model\nmodel.fit_generator(\n        train,\n        callbacks = [csv_logger],\n        epochs    = 15,\n        steps_per_epoch  = train.samples \/\/ batch_size,\n        validation_data  = probe,\n        validation_steps = probe.samples \/\/ batch_size)","7cbfa9c7":"# Create test generator\ntest = test_generator.flow_from_dataframe(dataframe = test_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'filepath',\n                                    y_col       = 'target',\n                                    shuffle     = False,\n                                    batch_size  = batch_size,\n                                    target_size = input_size)\n\n# Generate Predictions\npreds = model.predict_generator(test, steps= test.samples \/ batch_size)\n\n# Evaluate Model Results\nevaluate_predictions(preds)","bfc47324":"plot_training_hist(model)","b7b9c3a6":"# Save Model Weights as a File\nmodel.save_weights('mobilenetv2_12sep.h5')","db3b08f9":"# Create function to extract bottlenet features\nintermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(index=1).output)\n\n# Create training dataset using bottleneck features\nintermediate_output = intermediate_layer_model.predict_generator(test_generator.flow_from_dataframe(dataframe = train_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'filepath',\n                                    y_col       = 'target',\n                                    shuffle     = False,\n                                    batch_size  = batch_size,\n                                    target_size = input_size,\n                                    seed        = 451), steps = train_df.shape[0] \/ batch_size)\n\nintermediate_output_df = pd.DataFrame(intermediate_output)\nintermediate_output_df.head()\n\n# Create bottleneck features dataset for testing set\nintermediate_output_df_test = pd.DataFrame(intermediate_layer_model.predict_generator(test_generator.flow_from_dataframe(dataframe = test_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'filepath',\n                                    y_col       = 'target',\n                                    shuffle     = False,\n                                    batch_size  = batch_size,\n                                    target_size = input_size,\n                                    seed        = 451), steps = test_df.shape[0] \/ batch_size))","b29b07aa":"# Our new model\nviceroy_logreg = LogisticRegression(multi_class='auto', solver='lbfgs', random_state=451, max_iter=1000)\nviceroy_logreg.fit(intermediate_output_df, train_y)\n\n# Evaluate Model Results\nviceroy_logit_preds  = viceroy_logreg.predict_proba(intermediate_output_df_test)\nevaluate_predictions(viceroy_logit_preds[:,1])","388d56fa":"def TTA_wraper(dl_model, df = test_df, steps = 10, bs = batch_size, sz = input_size, seed = 451):\n    # Taken from: https:\/\/towardsdatascience.com\/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d\n    tta_steps   = steps\n    predictions = []\n\n    for i in tqdm(range(tta_steps)):\n        tta_pred = dl_model.predict_generator(train_generator.flow_from_dataframe(dataframe = df,\n                                        class_mode  = 'binary',\n                                        x_col       = 'filepath',\n                                        y_col       = 'target',\n                                        shuffle     = False,\n                                        batch_size  = bs,\n                                        target_size = sz,\n                                        seed        = seed * i), steps = df.shape[0] \/ batch_size)\n        predictions.append(tta_pred)\n\n    tta_preds = np.mean(predictions, axis=0)\n    return(tta_preds)","8a0bd708":"tta_preds = TTA_wraper(model)\nevaluate_predictions(tta_preds)","c85639a9":"all_interpolations = ['cv2.INTER_AREA', 'cv2.INTER_LINEAR', 'cv2.INTER_NEAREST', 'cv2.INTER_CUBIC', 'cv2.INTER_LANCZOS4']\n\ndef interpolation_experiment(interpolation_list):\n    for current_interpolation in interpolation_list:\n        # Create flattenned dataframes\n        experimental_train_df_flat = create_flattened_dataframe(train_df, interpolation = eval(current_interpolation))\n        experimental_probe_df_flat = create_flattened_dataframe(probe_df, interpolation = eval(current_interpolation))\n        experimental_test_df_flat  = create_flattened_dataframe(test_df,  interpolation = eval(current_interpolation))\n        \n        print(current_interpolation)\n        \n        # Create Logistic Regression Model\n        experimental_logit_model = LogisticRegression(random_state=451, solver='lbfgs', max_iter=1000)\n        experimental_logit_model.fit(experimental_train_df_flat, train_df['target'])\n        \n        # Evaluate Results\n        print('--------------------------')\n        print('Validation Set Results')\n        print('--------------------------')\n        # Evaluate Model Results - Testing Set\n        experimental_logit_preds  = logit_model.predict_proba(experimental_probe_df_flat)\n        evaluate_predictions(experimental_logit_preds[:,1], eval_df = probe_df)\n        \n        print('--------------------------')\n        print('Testing Set Results')\n        print('--------------------------')\n        # Evaluate Model Results - Testing Set\n        experimental_logit_preds  = logit_model.predict_proba(experimental_test_df_flat)\n        evaluate_predictions(experimental_logit_preds[:,1], eval_df = test_df)","c6109590":"interpolation_experiment(all_interpolations)","0116e46c":"# Compose masks for each lung\nleft_mask  = glob.glob('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/leftMask\/*.png')\nright_mask = glob.glob('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/rightMask\/*.png')\n\n# Sort all image files so that the filenames match\nleft_mask.sort()\nright_mask.sort()\nfilelist_montgommery.sort()","945b4320":"# Create dataframe with all Montgommery data\nmont_df = pd.DataFrame(filelist_montgommery, columns=['filepath'])\nmont_df['target'] = extract_label(filelist_montgommery)\nmont_df.head()","46259336":"def fuse_masks(list1,list2, dir_name='fused_images'):\n    '''\n    Fuse Masks Functions\n    Fuses left and right lung mask into a single mask\n    '''\n    try:\n        os.mkdir(dir_name)\n    except:\n        print('Directory {} already exists'.format(dir_name))\n        pass\n    \n    for i in tqdm(range(len(list1))):\n        # Read and fuse arrays together\n        array1 = cv2.imread(list1[i])\n        array2 = cv2.imread(list2[i])\n        fused  = np.add(array1,array2)\n        \n        # Export to disk\n        filename = 'M' + re.findall(r'Mask\\\/M(.+?)\\.png', list1[i])[0] + '.png'\n        cv2.imwrite(os.path.join(dir_name, filename), fused)","f0fbee94":"# Fuse masks together\nfuse_masks(left_mask,right_mask)","636971aa":"# Add fused masks to dataframe\nfused_masks_list    = glob.glob('fused_images\/*.png')\nmont_df['maskpath'] = fused_masks_list","11ff5fa2":"# Split Mont. Data into training and testing set\nmont_train, mont_test = train_test_split(mont_df,\n                                         test_size = 0.3,\n                                         stratify  = mont_df['target'],\n                                         random_state = 451)\n\n# Pop labels\nmont_train_y = mont_train.pop('target')\nmont_test_y  = mont_test.pop('target')","734e2d90":"def iou_loss_core(y_true, y_pred, smooth=1):\n    '''\n    IoU, aka jacquard index\n    Usable as a metric for keras\n    '''\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    union        = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n    iou          = (intersection + smooth) \/ ( union + smooth)\n    return(iou)","dcd600f2":"def dice_coef(y_true, y_pred):\n    '''\n    Dice Coefficient\n    Usable as metric for keras\n    '''\n    y_true_f     = K.flatten(y_true)\n    y_pred_f     = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    result       = (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n    return(result)","cb7e41c2":"# Clean up\n!rm -rf fused_images","b8522d39":"Soon","5676ed94":"Augmentation is one thing, but we also need to configure how the `ImageDataGenerator` will walk - or rather flow - through our dataset.","d6363a6a":"One of the experiments we had was checking how the interpolation can change the result of the model performance.\n\nLet's use a consistent model to check which interpolation produces better scores (and by how much).","069cf7f6":"# Contents\n- Preparing Data\n- Creating a Simple Model\n- Adding Augmentations\n- Creating a Simple Neural Network\n- Some black magic techniques...","ff7fd30b":"# Experiment 3: Lung Segmentation","3a0b15bc":"# Train a Simple Logistic Regression Model","93f4c39b":"![](https:\/\/miro.medium.com\/max\/1552\/1*Nv2NNALuokZEcV6hYEHdGA.png)","6c7dc3e4":"Garbage confirmed!\n\nLet's have a look at the training history","9a0e50e2":"# Experiment 4: Lung Detection","6d8c30ac":"# Viceroy Model","d7420def":"Data augmentation plays a major role in increasing the assertiveness of our models, especially when the dataset is rather small (as it is the case here).\nLet's create a generator to do that.","fa21274d":"![](http:\/\/pwmpcnhis.bkt.clouddn.com\/gitpage\/deeplearning.ai\/neural-networks-deep-learning\/programming_assignments\/week1_week2\/2.png)","79787459":"We'll create a logistic regression model, using `random state` for reproducibility and setting the `max iterations` to `1000` so that the model has more than enough iterations to converge.","34aab353":"For now we are not allowed to use NN as our final deliverable, so let's dial down a bit.\n\nHowever...we can use the convolutional layers to better interpret the information and then train a logistic regression on what the previous neural network 'saw'...\n\nLet's try that...","57f13a47":"We can add support elements to our training, also known in keras as `callbacks`. They can help us manage our learning rate, create model checkpoints, use tensorboard and many more things.\n\nFor now we'll just use the `CSVLogger`, which save training logs a csv file.","ac2fec73":"# Visualizing ConvNet Outputs","d6adda08":"# Simple CNN - MobileNetV2","9c271e19":"Yeet!\n\nOur Logistic regression is doing quite well.\nNow let's create simple CNN.","8d85dcdf":"We can use augmentation to improve the training of neural nets.\n\nWe can also use it to ","c27e7e0c":"![](https:\/\/rock-it.pl\/content\/images\/2017\/05\/doggs.jpg)","aadab953":"Instead of going for a fancy model, we'll start simple.\nThe most simple approach might be to just resize and flatten the pixels and send them to a simple model, such as a logistic regression.","f9d1e7b9":"From the documentation, we know that the label is contained within the filename. To extract such label, we'll use the `re` module to implement regex to get the label. ","67310010":"This is rather strange, our model seems like garbage...let's see the performance on the testing set.","55c7ce36":"Now, let's make some small changes to our model.\nWe'll just lower the learning rate. Just that.","f18b1211":"With that, our flattened dataframe is ready to go and we can now create our model.","c4b4bf5f":"# Performing Test Time Augmentation","c93d8e2d":"Notice that, for our last exercise, we loaded all images in memory and this is not ideal.\nIn the case of massive models, we usually create generators that will load a few instances of images each time, hence the idea of `batch_size`.\n\nOur model, MobileNetV2 was created with the input size of 224x224, so we'll keep that in our model.","fb4a0782":"That concludes the core part of our workshop.\nWe created a simple model and used it as baseline to improve creating another simple CNN model.\n\nFrom here on, we will dive into some neat tricks you can use.","1c4eae7a":"Our model is now ready, let us now create a function to evaluate the `Accuracy` and `AUC` of our model.","c91c9629":"# Masked Classification\n\nUnfinished;\n\nMontgommery only","c1b40169":"With that done, we can now build our neural network.","6abd9ee5":"Soon","41596df2":"Our network is way worse than our logistic regression, how can that be?\n\nIn many ways this is a lesson in deep learning vs machine learning.\n\nThe idea that deep learning is superior is in many ways inadequate.\nAnd the role of the human behind those models is often more important than the methods thenselves.\n\n\nDeep learning often overshadows machine learning for it's capacity to accomplish many tasks.\nWhile it certainly has some merit, other aproaches can also be just as good, sometimes better and frequently more `consistent`.\n\nGiba, ranked 1st in kaggle for a couple years mentioned that on a comment once: while deep learning is great it might take you the whole day to make it good\nWhile you can get as of a result with a single hour using ML methods.\n\nEither way, we can improve our CNN model, but don't walk the path of becoming closed minded about CNNs as the single possible solution.\nI teach this workshop so that you expand your way of thinking - not constrain it to a single method.","c16184f5":"# Experiment 1: Interpolation","8dd33a36":"Now that we have our sets, let's have a look at them and check some images as well.","52d47fb0":"We'll start by importing some dependencies:","20fd9cd5":"Let's now transform our lists into a dataframe.","3bcbb2e8":"Now that's far better, and we managed to improve our previous baseline score from the logistic regression model.\n\nLet's same the model weights to disk so that we can use them later if we want to.","2a4d8c5d":"# Experiment 2: Preprocessing","89d1ade0":"In order to help us load few images at a time, we'll use keras `ImageDataGenerator` - a class that allows us to load some images at a time using it's `flow` method and add data augmentation as well.","a2a317c0":"# Simple CNN - Trying Again","03caedea":"Now we have all the data into a single dataframe, but we need to split a certain amount for **model selection** (validation \/ probe) and for evaluating the model generalisation - the **testing set**.","be88e7ea":"# Exploratory Analysis","0f1c5e7a":"# Data Preparation","48b4e9f1":"Soon","80a8a41b":"The first thing we'll do is index all the images we have from both datasets, we will use `glob` to accomplish this.","b056e61a":"Soon"}}