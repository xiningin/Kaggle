{"cell_type":{"474e3b9d":"code","63f68888":"code","2e0d1769":"code","a4044c0d":"code","c7ed0b3d":"code","21fda287":"code","c4a10a51":"code","56c90686":"code","a2264b1b":"code","c8dff6b4":"code","31fc113c":"code","72243500":"code","07482edc":"code","678b3364":"code","b55e2c01":"code","aeabffd4":"code","2c808bfe":"code","c3caed79":"code","a3e80c35":"code","d71dd13c":"code","a6279acd":"code","2a1452ae":"code","fb547cbc":"code","4f876fb4":"markdown","2cbc4062":"markdown","72a2f42c":"markdown","5aa9695a":"markdown","986171f0":"markdown","fc8dcdf5":"markdown","7b4760f8":"markdown","1562479f":"markdown","256120f1":"markdown"},"source":{"474e3b9d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nseed = 42\nnp.random.RandomState(seed)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn","63f68888":"# Kers modules\nfrom keras.optimizers import SGD\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, Model\nfrom keras.callbacks import EarlyStopping, History\nfrom keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPool2D, GlobalMaxPool2D","2e0d1769":"import cv2\nimport scipy as sp\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nplt.rcParams['figure.figsize'] = (16, 10)","a4044c0d":"dir_path = \"\/kaggle\/input\"","c7ed0b3d":"# size of the image\nIMG_SIZE = 28","21fda287":"# read the input data\ntrain_df = pd.read_csv(os.path.join(dir_path, \"train.csv\"))\n\n# print the dimension of the data\nprint(\"Shape of the input data: \", train_df.shape)\n\n# display 5 records\ntrain_df.head(5)","c4a10a51":"def display_images(images, true_labels, pred_labels=None, cam_act=None):\n    \"\"\"\n        Function to display the provided images along with their labels and if provided, predicted labels.\n        Also, if provided the class activations will be overlayed on the original image.\n    \"\"\"\n    \n    # get number of images\n    num_images = len(images)\n    \n    # we will display only 5 images in a row, so, we will calculate number of rows\n    columns = 5\n    rows = math.ceil(num_images\/columns)\n    \n    # prepare the title of each image which will be True label and Predicted labels\n    if pred_labels != None:\n        titles = [\"True-{} | Pred-{}\".format(true, pred) for true, pred in zip(true_labels, pred_labels)]\n    else:\n        titles = list(map(lambda x: \"True-{}\".format(x), true_labels))\n        \n    # also specify the color of title if prediction was accurate and when not\n    if pred_labels != None:\n        colors = ['green' if true==pred else 'red' for true, pred in zip(true_labels, pred_labels)]\n    else:\n        # if pred lables do not exists put default color\n        colors = ['black' for i in range(num_images)]\n        \n    # now plot the images\n    fig, axes = plt.subplots(rows, columns, sharex=True, sharey=True)\n    \n    for r in range(rows):\n        for c in range(columns):\n            \n            # calculate the index\/position of an image\n            img_index = (r*columns + c)\n            \n            # if we have displayed required number of images, then break the loop\n            if (img_index + 1) > num_images:\n                break\n            \n            # display the image\n            axes[r, c].imshow(images[img_index], alpha=0.6 if cam_act else 1)\n            \n            # display the CAM if provided\n            if cam_act:\n                axes[r, c].imshow(cam_act[img_index], cmap='jet', alpha=0.4)\n                \n            # display the true and predicted labels\n            axes[r, c].set_title(titles[img_index], fontdict=dict(color=colors[img_index]))\n                \n    pass","56c90686":"# filter out some images to display along with their labels\nsample_images = train_df.iloc[:15, 1:].values.reshape(-1, 28, 28)\ntrue_labels = train_df.iloc[:15, 0].values\n\n# display using the provided function\ndisplay_images(sample_images, true_labels)","a2264b1b":"# for tutorial only, so that it trains during the course\ntrain_df = train_df.sample(frac=.10)","c8dff6b4":"# get the image features and normalize the values\nX = train_df.values[:, 1:] \/ 255.0\n\n# also, CNN expects the image to be of 3D, so, we will reshape the image\nX = X.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\n# get and One-hot encode the labels\nY = to_categorical(train_df.values[:, 0])\n\n# print the dimensions of the data\nprint(\"X shape-{}\\tY shape-{}\".format(X.shape, Y.shape))","31fc113c":"# split the data into train, validation and test datasets\nTEST_SPLIT = 0.3\nVALIDATION_SPLIT = .2\n\n# split into train and test datasets first\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=TEST_SPLIT, random_state=seed)\n\n# now, split the train data into train and validation data\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, stratify=Y_train, test_size=VALIDATION_SPLIT, random_state=seed)\n\nprint(\"Train:      \\tX shape-{}\\tY shape-{}\\n\".format(X_train.shape, Y_train.shape))\nprint(\"Validation: \\tX shape-{}\\tY shape-{}\\n\".format(X_val.shape, Y_val.shape))\nprint(\"Test:       \\tX shape-{}\\tY shape-{}\\n\".format(X_test.shape, Y_test.shape))","72243500":"# means that the layers will be executed in sequential manner i.e. one after the other\nmodel = Sequential()\n\n# here we will add a convolution layer, which Conv2D takes multiple inputs, which are \n# filters: number of times to make the convolutions, can be imagined as number of dimensions in the convolved image\n# input_shape: shape of an input image\n# kernel_size: size of the kernel which is the area of an image to focus on\n# padding: whether to keep the size of the image after convolution or not\n# strides: number of steps to shift the kernel, with stride of 1image size will remain same, but it will be halved with stride as 2\n# activation: the activation function\nmodel.add(Conv2D(filters=5, input_shape=(28, 28, 1), kernel_size=3, padding='same', strides=1, activation='relu'))\n\n# we also add a pooling layer, which takes average or maximum of the pixel values in the provided window\/pool_size\n# for pool_size of 2, we will take max\/average of all the values in size a 2x2 window and will result into a single value\n# padding: here has the same purpose as the Conv2D\n# after this step the size of the image will be halved\nmodel.add(MaxPool2D(pool_size=2, padding=\"same\"))\n\n# adding another Conv2D layer, but here we increase the number of filters\nmodel.add(Conv2D(filters=10, kernel_size=3, padding='same', strides=1, activation='relu'))\nmodel.add(Conv2D(filters=10, kernel_size=3, padding='same', strides=1, activation='relu'))\n\n# another pooling layer\nmodel.add(MaxPool2D(pool_size=2, padding=\"same\"))\n\nmodel.add(GlobalMaxPool2D())\n\n# flatten the previous layer, i.e. align all the nodes in a single layer\n# model.add(Flatten())\n\n# add the dropout layer, which will randomly turn off x% of the nodes while training\n# model.add(Dropout(rate=0.2))\n\n# add a dense layer containing 2048 nodes\n# model.add(Dense(2048, activation='relu'))\n\n# finally a soft-max layer which will give the probabilities of predicting each of the class\nmodel.add(Dense(10, activation='softmax'))\n\n# we will compile the model and use the Adam optimizer, we can also use SGD in place of that\n# the model will try to minimize the loss given by 'categorical_crossentropy'\n# also, the model will track the accuracy during training\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","07482edc":"# to stop training the model if no incremental benefit is gained in subsequent EPOCHS\nearly_stopping_monitor = EarlyStopping(patience=3, min_delta=1e-3)","678b3364":"# train the model\nmodel.fit(X_train, Y_train, epochs=20, callbacks=[early_stopping_monitor], validation_data=(X_val, Y_val), verbose=True)","b55e2c01":"# get the loss and accuracy for each epoch using history\nhistory = model.history.history\n\n# visualize the loss for each epochs\nplt.figure(figsize=(20, 4))\nsns.lineplot(x=range(len(history[\"loss\"])),y=history[\"loss\"], label=\"loss\")\nsns.lineplot(x=range(len(history[\"val_loss\"])),y=history[\"val_loss\"], label=\"val_loss\")","aeabffd4":"print(\"Train accuracy:      \", model.evaluate(X_train, Y_train, verbose=0)[1])\nprint(\"Validation accuracy: \", model.evaluate(X_val, Y_val, verbose=0)[1])\nprint(\"Test accuracy:       \", model.evaluate(X_test, Y_test, verbose=0)[1])","2c808bfe":"# filter out some images to display along with their labels\n\n# get the raw images\nsample_images = X_test[:20, ]\n\n# get their true labels\ntrue_labels = np.argmax(Y_test[:20,], axis=1)\n\n# get their pred labels by predicting from model\npred_labels = np.argmax(model.predict(sample_images), axis=1).tolist()\n\n# display using the provided function\ndisplay_images(sample_images.reshape(-1, IMG_SIZE, IMG_SIZE), true_labels, pred_labels)","c3caed79":"def get_cam(model, images):\n    \"\"\"\n        Function returns the Class Activation Maps for the provided images.\n    \"\"\"\n    \n    global pred_label_weights, img_features\n    \n    # get the weights to the last layer which is softmax layer\n    # also, the weights contains a pair of input weights and bias weights and we need only the non bias weights\n    weights = model.layers[-1].get_weights()[0]\n    \n    # create a model to get the outputs from 'x'th layer and the predicted values\n    cam_model = Model(inputs = model.input, outputs = (model.layers[-3].output, model.layers[-1].output))\n    \n    # get the outputs for the provided images\n    features, predictions = cam_model.predict(images)\n    \n    # to store the activation overlapped images\n    images_w_cam = []\n    \n    # iterate over each provided input image\n    for idx, img in enumerate(images):\n        \n        # predict the label\n        pred_label = np.argmax(predictions[idx])\n        \n        # get the weights of the predicted label\n        pred_label_weights = weights[:, pred_label]\n        #print(pred_label_weights.shape)\n        \n        # get the features of the image\n        img_features = features[idx]\n        #print(img_features.shape)\n        \n        # get the size of the feature\n        F_SIZE = img_features.shape[0]\n        #print(F_SIZE)\n        \n        # take a dot product of weights and img features\n        cam_activation = np.dot(img_features, pred_label_weights)\n        #print(cam_activation.shape)\n        \n        # map the feature map to the original size\n        height_roomout = IMG_SIZE * 1.0 \/ F_SIZE\n        width_roomout = IMG_SIZE *1.0 \/ F_SIZE\n        \n        # zoom in\/out the cam_activation to the original image size\n        cam_activation = sp.ndimage.zoom(cam_activation, (height_roomout, width_roomout), order=2).astype('float64')\n        \n        # append the overlayed_img\n        images_w_cam.append(cam_activation)\n        \n    return images_w_cam","a3e80c35":"# get the CAM for the sample images using the above function\noverlayed_imgs = get_cam(model, sample_images)\n\n# display using the provided function\ndisplay_images(sample_images.reshape(-1, IMG_SIZE, IMG_SIZE), true_labels, pred_labels, overlayed_imgs)","d71dd13c":"# load the prediction dataset\npredict_df = pd.read_csv(os.path.join(dir_path, \"test.csv\"))\nprint(\"Shape of the test dataset: \", predict_df.shape)\npredict_df.head(2)","a6279acd":"# extract the features and normalize it\nX_predict = predict_df.values \/ 255.0\nX_predict = X_predict.reshape(-1, IMG_SIZE, IMG_SIZE, 1)","2a1452ae":"# make the predictions\npredictions = model.predict_classes(X_predict)\nprint(\"Shape of the predictions: \", predictions.shape)\n\nprint(\"\\nSome predicted outputs: \")\nprint(predictions[:10])","fb547cbc":"## create output final in the required format\noutput = pd.DataFrame()\n\noutput[\"ImageId\"] = [i for i in range(1, predictions.shape[0]+1)]\noutput[\"Label\"] = predictions\n\noutput.to_csv(\"predictions.csv\", index=False)","4f876fb4":"## Prepare the dataset for training","2cbc4062":"# Class Activation Maps","72a2f42c":"## Display some of the images with predicted labels","5aa9695a":"## Explore the data","986171f0":"# Load & Prepare data","fc8dcdf5":"# Simple Convolution Network to Classify MNIST Digits","7b4760f8":"**In this notebook you will learn how to read the data, display some of the input images, create a very basic CNN model. Also, you will learn how to visualize how the model makes the decision**","1562479f":"# Make Predictions","256120f1":"# Build the Convolution Neural Network"}}