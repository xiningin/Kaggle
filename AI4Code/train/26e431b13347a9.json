{"cell_type":{"3c64cd51":"code","2bbcf1f8":"code","ee38e250":"code","1564a7cc":"code","94c05f25":"code","16261342":"code","99843a36":"code","bc52de59":"code","aa902f17":"code","7abf60dd":"code","678e6539":"code","887bb73a":"code","13ab3e43":"code","66f2bced":"code","9a894992":"code","227b5e9c":"markdown","89781083":"markdown","fb8ff0f8":"markdown","bc759113":"markdown","dbc821b9":"markdown","a0e74cfa":"markdown","d09ee2a8":"markdown","75740eaa":"markdown","859839ac":"markdown","14795062":"markdown","a2aee26f":"markdown","f5040f25":"markdown","64177674":"markdown"},"source":{"3c64cd51":"!pip install --no-index \\\n..\/input\/detectron2-download-code-for-offline-install-ii\/detectron2\/detectron2-0.6-cp37-cp37m-linux_x86_64.whl \\\n--find-links=..\/input\/detectron2-download-code-for-offline-install-ii\/detectron2","2bbcf1f8":"!cp \/kaggle\/input\/sartorius-tta-with-weighted-segments-fusion\/wbf_tracking.py .","ee38e250":"%cd \/kaggle\/working\n!cp -R ..\/input\/train-sartorius-detectron2-centermask2\/centermask2 centermask2","1564a7cc":"import numpy as np\nimport pandas as pd\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\nimport glob, gc\nfrom skimage import measure\nimport albumentations as A\nfrom skimage import measure\nfrom wbf_tracking import weighted_boxes_fusion_tracking\nfrom scipy import stats\nimport torch\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog","94c05f25":"%cd \/kaggle\/working\/centermask2\n\nfrom centermask.config import get_cfg # important! Use get_cfg from the centermask repo and not Detectron2\n\ncfg = get_cfg()\ncfg.merge_from_file(\".\/configs\/centermask\/test.yaml\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\ncfg.MODEL.WEIGHTS = '.\/output\/model_final.pth'\ncfg.MODEL.FCOS.POST_NMS_TOPK_TEST = 800 # Max number of detections per image\npredictor = DefaultPredictor(cfg)","16261342":"test_files = glob.glob('\/kaggle\/input\/sartorius-cell-instance-segmentation\/test\/*')","99843a36":"def plt_pred(file):\n    im = cv2.imread(file)\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1])\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.figure(figsize=(20,15))\n    plt.imshow(out.get_image()[:, :, ::-1]);\n\nif len(test_files) == 3:\n    plt_pred(test_files[0])","bc52de59":"if len(test_files) == 3:\n    plt_pred(test_files[1])","aa902f17":"if len(test_files) == 3:\n    plt_pred(test_files[2])","7abf60dd":"cell_df = pd.read_pickle('\/kaggle\/input\/sartorius-cell-shape-analysis\/shape_data.pkl')\ncell_df","678e6539":"# Augmentations must be \"bidirectional\" - applying twice will get back to original\n# also augmentations must support image, bboxes and masks\nAUGMENTATIONS = [None, A.HorizontalFlip(p=1.0), A.VerticalFlip(p=1.0), A.Rotate(limit=(180,180), p=1.0)]\n\n# create dict key from bbox\ndef bbox_to_key(bbox):\n    return str(np.round(bbox, 6))\n\n# TTA function takes file name as input\ndef TTA(file, predictor):\n    boxes = []\n    box_scores = []\n    masks = []\n    masks_lkup =[]\n    pclass = []\n    im = cv2.imread(file)\n    for aug in AUGMENTATIONS:\n        if aug is not None:\n            transform = aug\n            ima = transform(image=im)['image']\n        else:\n            ima = im\n        pred = predictor(ima)\n        h, w = pred['instances'].image_size[0], pred['instances'].image_size[1]\n        classes = pred['instances'].pred_classes.cpu().numpy()-1\n        if len(pclass) == 0:\n            pclass = classes\n        else:\n            pclass = np.concatenate((pclass, classes))\n        # get box predictions\n        pred_boxes = [A.normalize_bbox(box, h, w) for box in pred['instances'].pred_boxes.tensor.cpu().numpy()]\n        # transform back to original\n        if aug is not None:\n            pred_boxes = transform(image=ima, bboxes=pred_boxes)['bboxes']\n        # get mask prediction\n        pred_masks = pred['instances'].pred_masks.cpu().numpy()*1\n        # transform back to original\n        if aug is not None:\n            pred_masks = transform(image=ima, masks=pred_masks)['masks']\n        # lookup table for bbox to mask index reference\n        pred_dict = {}\n        for i in range(len(pred_boxes)):\n            pred_dict[bbox_to_key(pred_boxes[i])] = i\n        # append results to list\n        boxes.append(np.array(pred_boxes))\n        box_scores.append(np.array(pred['instances'].scores.detach().cpu().numpy()))\n        masks.append(np.array(pred_masks, dtype=np.uint8))\n        masks_lkup.append(pred_dict)\n    \n        del pred, pred_boxes, pred_masks, ima, pred_dict\n    \n    del im\n    gc.collect()\n    predicted_class = stats.mode(pclass)[0][0]\n    return boxes, box_scores, masks, masks_lkup, predicted_class","887bb73a":"def get_wsf_mask(wbf_box, wbf_org, pmasks, pmasks_lkup, thres=0.5):\n    w, h = 520, 704\n    mask = np.zeros((w, h), dtype=np.uint8)\n    for i in range(len(wbf_org)):\n        key = bbox_to_key(wbf_org[i][4:])\n        model = int(wbf_org[i][3])\n        try:\n            ind = pmasks_lkup[model][key]\n            mask = mask + pmasks[model][ind]\n        except:\n            pass\n    # convert thres to integer based on number of boxes\n    threshold = max(1, int(thres*len(wbf_org)))\n    # remove pixels outside WBF box\n    m2 = np.zeros((w, h), dtype=np.uint8)\n    x1 = max(0, int(h * wbf_box[0]))\n    y1 = max(0, int(w * wbf_box[1]))\n    x2 = min(h, int(h * wbf_box[2]))\n    y2 = min(w, int(w * wbf_box[3]))\n    m2[y1:y2, x1:x2] = 1\n    mask = (mask >= threshold) * m2\n    return mask.astype(np.uint8)","13ab3e43":"DEBUG = False\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nTHRESHOLDS = [.53, .45, .55]\nCLASS_LABELS = ['background', 'shsy5y', 'astro', 'cort']\n\n# Implement WSF for TTA\ndef get_masks_tta(fn, predictor, thres=-1):\n    im = cv2.imread(str(fn))\n    h, w = im.shape[0], im.shape[1]\n    # do TTA\n    boxes, box_scores, masks, masks_lkup, pred_class = TTA(str(fn), predictor)\n    # create dummy labels\n    labels = []\n    for i in range(len(boxes)):\n        labels.append(np.ones(len(boxes[i]), dtype=np.uint8))\n    # weighted boxes fusion\n    wbf_boxes, wbf_scores, _, wbf_originals = weighted_boxes_fusion_tracking(boxes, \n                                                                             box_scores, \n                                                                             labels_list=labels, \n                                                                             iou_thr=0.55, \n                                                                             skip_box_thr=THRESHOLDS[pred_class])\n    # Finally, process masks, making sure there is no overlap\n    res = []\n    used = np.zeros(im.shape[:2], dtype=int)\n    # extract limits from DataFrame\n    pred_label = CLASS_LABELS[pred_class+1]\n    min_key = pred_label+' min'\n    major_axis_len_min = cell_df[cell_df.feature == 'major_axis_len'][min_key].iloc[0]\n    # process\n    for i in range(len(wbf_boxes)):\n        mask = get_wsf_mask(wbf_boxes[i], wbf_originals[i], masks, masks_lkup, thres=.5)\n        # get shape properties\n        try:\n            props = measure.regionprops(mask)\n        except:\n            continue\n        # if there are multiple separated masks, pick the larger one\n        areas = []\n        for a in range(len(props)):\n            areas.append(props[a].area)\n        try:\n            target = np.argmax(areas)\n        except:\n            continue\n        # extract properties of interest \n        major_axis_len = props[target].major_axis_length\n        # check against limits\n        if major_axis_len >= major_axis_len_min:\n            mask = mask * (1-used)\n            # check if mask is chopped up by previous detections\n            if len(measure.find_contours(mask, 0.5, positive_orientation='low')) == 1:\n                used += mask\n                res.append(rle_encode(mask))\n            else:\n                if DEBUG:\n                    print('{}: Chopped\\'n\\'dropped #{}'.format(fn.split('\/')[-1], i))\n        else:\n            if DEBUG:\n                print('{}: Failed limits #{}'.format(fn.split('\/')[-1], i))\n                \n    if DEBUG:\n        print('{}: {}, {} boxes of {} left after processing'.format(fn.split('\/')[-1], pred_label, len(res), len(wbf_boxes)))\n                \n    del boxes, box_scores, masks, masks_lkup\n    del wbf_boxes, wbf_scores, labels, wbf_originals\n    gc.collect()\n          \n    return res","66f2bced":"ids, masks=[],[]\n\nfor fn in test_files:\n    fid = fn.split('\/')[-1].split('.')[0]\n    #print('------------------- {} --------------------'.format(fid))\n    encoded_masks = get_masks_tta(fn, predictor)\n    if len(encoded_masks) > 0:\n        for enc in encoded_masks:\n            ids.append(fid)\n            masks.append(enc)\n    else:\n        ids.append(fid)\n        masks.append('')\n        \ndf = pd.DataFrame({'id':ids, 'predicted':masks})\ndf.to_csv('\/kaggle\/working\/submission.csv', index=False)\ndf.head()","9a894992":"%cd \/kaggle\/working\n!rm -fr \/kaggle\/working\/centermask2\n!rm -fr \/kaggle\/working\/detectron2\n!rm wbf_tracking.py","227b5e9c":"Configure model for inference:","89781083":"## Weighted Segments Fusion\nThe function below will fuse masks based on WBF boxes.","fb8ff0f8":"## TTA function\nWe define three transformations plus original image.","bc759113":"Go for it:","dbc821b9":"# Sanity check on the three public test images\nThe number of detections per image is set high, so the unfiltered predictions below will look cluttered...","a0e74cfa":"Copy CenterMask2 from [training notebook](https:\/\/www.kaggle.com\/mistag\/train-sartorius-detectron2-centermask2):","d09ee2a8":"Then install Weighted Segments Boxes for Segments Fusion:","75740eaa":"Cleanup:","859839ac":"![logo](https:\/\/raw.githubusercontent.com\/facebookresearch\/detectron2\/main\/.github\/Detectron2-Logo-Horz.svg)","14795062":"# Inference\nThis is the final step in a series:  \n  * [Create COCO annotations for Sartorius dataset](https:\/\/www.kaggle.com\/mistag\/sartorius-create-coco-annotations)\n  * [Cell shape analysis](https:\/\/www.kaggle.com\/mistag\/sartorius-cell-shape-analysis)\n  * [Offline Detectron2 files](https:\/\/www.kaggle.com\/mistag\/detectron2-download-code-for-offline-install-ii)\n  * [Train CenterMask2 model](https:\/\/www.kaggle.com\/mistag\/train-sartorius-detectron2-centermask2)\n  * [Sartorius: TTA with Weighted Segments Fusion](https:\/\/www.kaggle.com\/mistag\/sartorius-tta-with-weighted-segments-fusion)\n  \nStart by installing Dectectron2:","a2aee26f":"# Inference for submission\nThe code below is principally based on [Positive score with Detectron 3\/3 - Inference](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-3-3-inference\/notebook) by [Slawek Biel](https:\/\/www.kaggle.com\/slawekbiel). Some major additions are made:  \n  * TTA with Weighted Segments Fusion\n  * Shape property measurement and filtering based on findings in [this notebook](https:\/\/www.kaggle.com\/mistag\/sartorius-cell-shape-analysis)\n  * Check for chopping of predictions by higher score masks\n  \nStart by reading in properties from cell shape analysis:","f5040f25":"Install a few libraries:","64177674":"## Prediction function\nTTA + WSF is applied below."}}