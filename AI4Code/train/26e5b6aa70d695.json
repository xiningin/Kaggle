{"cell_type":{"33ceee85":"code","ef9914b4":"code","44834b94":"code","f4eff0c5":"code","85335a51":"code","17041c65":"code","9bffba32":"code","18e9fe87":"code","cf00a4dd":"code","36a20c4e":"code","69e819dd":"code","d0ae45e5":"code","2ec23393":"code","4958206b":"code","fcd82b0b":"code","b4ab17ae":"code","0e90e0e1":"code","d32fb38c":"code","5708370f":"code","de677e8e":"code","bd33cbda":"code","74ed7f77":"code","e9552876":"code","2c6429ff":"code","01d3ddf4":"code","112a376b":"code","841adda9":"code","b1c9ab13":"code","e605b84e":"code","4d81825e":"code","4a454448":"code","d9b25f6b":"code","ca7cf37e":"code","6426654b":"code","ee764af0":"code","b6fb1737":"code","b6da6ca9":"code","c2f1bc82":"code","0080bcf5":"code","a7189977":"code","d105db63":"code","319b3234":"code","e8737895":"code","1906b96f":"code","fd489d59":"code","730874d2":"code","073a849a":"code","48f92177":"code","253e6df2":"code","4751c85c":"markdown","f627023e":"markdown","da600f7d":"markdown","22e11326":"markdown","db38c1b8":"markdown","13f08973":"markdown","11db61e1":"markdown","11c31d90":"markdown","e8af3b58":"markdown","b625be14":"markdown"},"source":{"33ceee85":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ef9914b4":"from collections import defaultdict\nfrom datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nimport os\nfrom pprint import pprint\nimport warnings\nfrom fbprophet import Prophet\nfrom fbprophet.plot import add_changepoints_to_plot\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom matplotlib.ticker import ScalarFormatter\n%matplotlib inline\nimport numpy as np\nimport optuna\noptuna.logging.disable_default_handler()\nimport pandas as pd\npd.plotting.register_matplotlib_converters()\nimport seaborn as sns\nfrom scipy.optimize import curve_fit\nfrom scipy.integrate import solve_ivp\nimport pystan.misc","44834b94":"plt.style.use(\"seaborn-ticks\")\nplt.rcParams[\"xtick.direction\"] = \"in\"\nplt.rcParams[\"ytick.direction\"] = \"in\"\nplt.rcParams[\"font.size\"] = 11.0\nplt.rcParams[\"figure.figsize\"] = (9, 6)","f4eff0c5":"warnings.simplefilter(\"ignore\")","85335a51":"def line_plot(df, title, xlabel=None, ylabel=\"Cases\", h=None, v=None,\n              xlim=(None, None), ylim=(0, None), math_scale=True, y_logscale=False, y_integer=False):\n    \"\"\"\n    Show chlonological change of the data.\n    \"\"\"\n    ax = df.plot()\n    if math_scale:\n        ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n        ax.ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n    if y_logscale:\n        ax.set_yscale(\"log\")\n    if y_integer:\n        fmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\n        fmt.set_scientific(False)\n        ax.yaxis.set_major_formatter(fmt)\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_xlim(*xlim)\n    ax.set_ylim(*ylim)\n    ax.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n    if h is not None:\n        ax.axhline(y=h, color=\"black\", linestyle=\"--\")\n    if v is not None:\n        if not isinstance(v, list):\n            v = [v]\n        for value in v:\n            ax.axvline(x=value, color=\"black\", linestyle=\"--\")\n    plt.tight_layout()\n    plt.show()","17041c65":"def select_area(ncov_df, group=\"Date\", places=None, areas=None, excluded_places=None,\n                start_date=None, end_date=None, date_format=\"%d%b%Y\"):\n    \"\"\"\n    Select the records of the palces.\n    @ncov_df <pd.DataFrame>: the clean data\n    @group <str or None>: group-by the group, or not perform (None)\n    @area or @places:\n        if ncov_df has Country and Province column,\n            @places <list[tuple(<str\/None>, <str\/None>)]: the list of places\n                - if the list is None, all data will be used\n                - (str, str): both of country and province are specified\n                - (str, None): only country is specified\n                - (None, str) or (None, None): Error\n        if ncov_df has Area column,\n            @areas <list[str]>: the list of area names\n                - if the list is None, all data will be used\n                - eg. Japan\n                - eg. US\/California\n    @excluded_places <list[tuple(<str\/None>, <str\/None>)]: the list of excluded places\n        - if the list is None, all data in the \"places\" will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @start_date <str>: the start date or None\n    @end_date <str>: the start date or None\n    @date_format <str>: format of @start_date and @end_date\n    @return <pd.DataFrame>: index and columns are as same as @ncov_df\n    \"\"\"\n    # Select the target records\n    df = ncov_df.copy()\n    if (places is not None) or (excluded_places is not None):\n        c_series = df[\"Country\"]\n        p_series = df[\"Province\"]\n        if places is not None:\n            df = pd.DataFrame(columns=ncov_df.columns)\n            for (c, p) in places:\n                if c is None:\n                    raise Exception(\"places: Country must be specified!\")\n                if p is None:\n                    new_df = ncov_df.loc[c_series == c, :]\n                else:\n                    new_df = ncov_df.loc[(c_series == c) & (p_series == p), :]\n                df = pd.concat([df, new_df], axis=0)\n        if excluded_places is not None:\n            for (c, p) in excluded_places:\n                if c is None:\n                    raise Exception(\"excluded_places: Country must be specified!\")\n                if p is None:\n                    df = df.loc[c_series != c, :]\n                else:\n                    c_df = df.loc[(c_series == c) & (p_series != p), :]\n                    other_df = df.loc[c_series != c, :]\n                    df = pd.concat([c_df, other_df], axis=0)\n    if areas is not None:\n        df = df.loc[df[\"Area\"].isin(areas), :]\n    if group is not None:\n        df = df.groupby(group).sum().reset_index()\n    # Range of date\n    if start_date is not None:\n        df = df.loc[df[\"Date\"] >= datetime.strptime(start_date, date_format), :]\n    if end_date is not None:\n        df = df.loc[df[\"Date\"] <= datetime.strptime(end_date, date_format), :]\n    # Only use the records with Confirmed > 0\n    try:\n        df = df.loc[df[\"Confirmed\"] > 0, :]\n    except KeyError:\n        pass\n    # Aleart empty\n    if df.empty:\n        raise Exception(\"The output dataframe is empty!\")\n    return df","9bffba32":"def show_trend(ncov_df, name=None, variable=\"Confirmed\", n_changepoints=2, **kwargs):\n    \"\"\"\n    Show trend of log10(@variable) using fbprophet package.\n    @ncov_df <pd.DataFrame>: the clean data\n    @variable <str>: variable name to analyse\n        - if Confirmed, use Infected + Recovered + Deaths\n    @n_changepoints <int>: max number of change points\n    @kwargs: keword arguments of select_area()\n    \"\"\"\n    # Data arrangement\n    df = select_area(ncov_df, **kwargs)\n    df = df.loc[:, [\"Date\", variable]]\n    df.columns = [\"ds\", \"y\"]\n    # Log10(x)\n    warnings.resetwarnings()\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        df[\"y\"] = np.log10(df[\"y\"]).replace([np.inf, -np.inf], 0)\n    # fbprophet\n    model = Prophet(growth=\"linear\", daily_seasonality=False, n_changepoints=n_changepoints)\n    model.fit(df)\n    future = model.make_future_dataframe(periods=0)\n    forecast = model.predict(future)\n    # Create figure\n    fig = model.plot(forecast)\n    _ = add_changepoints_to_plot(fig.gca(), model, forecast)\n    if name is None:\n        try:\n            name = f\"{kwargs['places'][0][0]}: \"\n        except Exception:\n            name = str()\n    else:\n        name = f\"{name}: \"\n    plt.title(f\"{name}log10({variable}) over time and chainge points\")\n    plt.ylabel(f\"log10(the number of cases)\")\n    plt.xlabel(\"\")","18e9fe87":"def create_target_df(ncov_df, total_population,\n                     confirmed=\"Confirmed\", recovered=\"Recovered\", fatal=\"Deaths\", **kwargs):\n    \"\"\"\n    Select the records of the places, calculate the number of susceptible people,\n     and calculate the elapsed time [day] from the start date of the target dataframe.\n    @ncov_df <pd.DataFrame>: the clean data\n    @total_population <int>: total population in the places\n    column names in @ncov_df:\n        @confirmed <str>: column name of the number of confirmed cases\n        @recovered <str>: column name of the number of recovered cases\n        @fatal <str>: column name of the number of fatal cases\n    @kwargs: keword arguments of select_area()\n    @return <tuple(2 objects)>:\n        - 1. first_date <pd.Timestamp>: the first date of the selected records\n        - 2. target_df <pd.DataFrame>:\n            - column T: elapsed time [min] from the start date of the dataset\n            - column Susceptible: the number of patients who are in the palces but not infected\/recovered\/died\n            - column Infected: the number of infected cases\n            - column Recovered: the number of recovered cases\n            - column Deaths: the number of death cases\n    \"\"\"\n    # Select the target records\n    df = select_area(ncov_df, **kwargs)\n    first_date = df.loc[df.index[0], \"Date\"]\n    # column T\n    df[\"T\"] = ((df[\"Date\"] - first_date).dt.total_seconds() \/ 60).astype(int)\n    # coluns except T\n    cols = [confirmed, recovered, fatal]\n    if not set(cols).issubset(set(df.columns)):\n        raise KeyError(f\"ncov_df must have {', '.join(cols)} column!\")\n    df[\"Susceptible\"] = total_population - df[confirmed]\n    df[\"Infected\"] = df[confirmed] - df[recovered] - df[fatal]\n    df[\"Recovered\"] = df[recovered]\n    df[\"Fatal\"] = df.loc[:, fatal]\n    response_variables = [\"Susceptible\", \"Infected\", \"Recovered\", \"Fatal\"]\n    # Return\n    target_df = df.loc[:, [\"T\", *response_variables]]\n    return (first_date, target_df)","cf00a4dd":"def simulation(model, initials, step_n, **params):\n    \"\"\"\n    Solve ODE of the model.\n    @model <ModelBase>: the model\n    @initials <tuple[float]>: the initial values\n    @step_n <int>: the number of steps\n    @params: the paramerters of the model\n    \"\"\"\n    tstart, dt, tend = 0, 1, step_n\n    sol = solve_ivp(\n        fun=model(**params),\n        t_span=[tstart, tend],\n        y0=np.array(initials, dtype=np.float64),\n        t_eval=np.arange(tstart, tend + dt, dt),\n        dense_output=False\n    )\n    t_df = pd.Series(data=sol[\"t\"], name=\"t\")\n    y_df = pd.DataFrame(data=sol[\"y\"].T.copy(), columns=model.VARIABLES)\n    sim_df = pd.concat([t_df, y_df], axis=1)\n    return sim_df","36a20c4e":"class ModelBase(object):\n    NAME = \"Model\"\n    VARIABLES = [\"x\"]\n    PRIORITIES = np.array([1])\n    QUANTILE_RANGE = [0.3, 0.7]\n    MONOTONIC = [\"x\"]\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        \"\"\"\n        Define parameters without tau. This function should be overwritten.\n        @train_df_divided <pd.DataFrame>:\n            - column: t and non-dimensional variables\n        @q_range <list[float, float]>: quantile rage of the parameters calculated by the data\n        @return <dict[name]=(min, max):\n            @min <float>: min value\n            @max <float>: max value\n        \"\"\"\n        param_dict = dict()\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        \"\"\"\n        Calculate the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        \"\"\"\n        Calculate measurable variables using the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @classmethod\n    def create_dataset(cls, ncov_df, total_population, **kwargs):\n        \"\"\"\n        Create dataset with the model-specific varibles.\n        The variables will be divided by total population.\n        The column names (not include T) will be lower letters.\n        **kwargs: See the function named create_target_df()\n        @return <tuple(objects)>:\n            - start_date <pd.Timestamp>\n            - initials <tuple(float)>: the initial values\n            - Tend <int>: the last value of T\n            - df <pd.DataFrame>: the dataset\n        \"\"\"\n        start_date, target_df = create_target_df(ncov_df, total_population, **kwargs)\n        df = cls.calc_variables(target_df).set_index(\"T\") \/ total_population\n        df.columns = [n.lower() for n in df.columns]\n        initials = df.iloc[0, :].values\n        df = df.reset_index()\n        Tend = df.iloc[-1, 0]\n        return (start_date, initials, Tend, df)\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0. This function should be overwritten.\n        \"\"\"\n        return None\n\n    def calc_days_dict(self, tau):\n        \"\"\"\n        Calculate 1\/beta [day] etc.\n        This function should be overwritten.\n        @param tau <int>: tau value [hour]\n        \"\"\"\n        return dict()","69e819dd":"class SIRF(ModelBase):\n    NAME = \"SIR-F\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, theta, kappa, rho, sigma):\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * (1 - self.theta) * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho * self.theta * x * y + self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx\/dt) \/ x \/ y\n            rho_series = 0 - df[\"x\"].diff() \/ df[\"t\"].diff() \/ df[\"x\"] \/ df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz\/dt) \/ y\n            sigma_series = df[\"z\"].diff() \/ df[\"t\"].diff() \/ df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) \/ (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1\/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1\/alpha2 [day]\"] = int(tau \/ 24 \/ 60 \/ self.kappa)\n        _dict[\"1\/beta [day]\"] = int(tau \/ 24 \/ 60 \/ self.rho)\n        if self.sigma == 0:\n            _dict[\"1\/gamma [day]\"] = 0\n        else:\n            _dict[\"1\/gamma [day]\"] = int(tau \/ 24 \/ 60 \/ self.sigma)\n        return _dict","d0ae45e5":"class Estimator(object):\n    def __init__(self, model, ncov_df, total_population, name=None, places=None, areas=None,\n                 excluded_places=None, start_date=None, end_date=None, date_format=\"%d%b%Y\", **params):\n        \"\"\"\n        Set training data.\n        @model <ModelBase>: the model\n        @name <str>: name of the area\n        @params: fixed parameter of the model\n        @the other params: See the function named create_target_df()\n        \"\"\"\n        # Fixed parameters\n        self.fixed_param_dict = params.copy()\n        if None in params.values():\n            self.fixed_param_dict = {\n                k: v for (k, v) in params.items() if v is not None\n            }\n        # Register the dataset arranged for the model\n        dataset = model.create_dataset(\n            ncov_df, total_population, places=places, areas=areas,\n            excluded_places=excluded_places,\n            start_date=start_date, end_date=end_date, date_format=date_format\n        )\n        self.start_time, self.initials, self.Tend, self.train_df = dataset\n        self.total_population = total_population\n        self.name = name\n        self.model = model\n        self.param_dict = dict()\n        self.study = None\n        self.optimize_df = None\n\n    def run(self, n_trials=500):\n        \"\"\"\n        Try estimation (optimization of parameters and tau).\n        @n_trials <int>: the number of trials\n        \"\"\"\n        if self.study is None:\n            self.study = optuna.create_study(direction=\"minimize\")\n        self.study.optimize(\n            lambda x: self.objective(x),\n            n_trials=n_trials,\n            n_jobs=-1\n        )\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        param_dict[\"R0\"] = self.calc_r0()\n        param_dict[\"score\"] = self.score()\n        param_dict.update(self.calc_days_dict())\n        self.param_dict = param_dict.copy()\n        return param_dict\n\n    def history_df(self):\n        \"\"\"\n        Return the hsitory of optimization.\n        @return <pd.DataFrame>\n        \"\"\"\n        optimize_df = self.study.trials_dataframe()\n        optimize_df[\"time[s]\"] = optimize_df[\"datetime_complete\"] - \\\n            optimize_df[\"datetime_start\"]\n        optimize_df[\"time[s]\"] = optimize_df[\"time[s]\"].dt.total_seconds()\n        self.optimize_df = optimize_df.drop(\n            [\"datetime_complete\", \"datetime_start\", \"system_attrs__number\"], axis=1)\n        return self.optimize_df.sort_values(\"value\", ascending=True)\n\n    def history_graph(self):\n        \"\"\"\n        Show the history of parameter search using pair-plot.\n        \"\"\"\n        if self.optimize_df is None:\n            self.history_df()\n        df = self.optimize_df.copy()\n        sns.pairplot(df.loc[:, df.columns.str.startswith(\n            \"params_\")], diag_kind=\"kde\", markers=\"+\")\n        plt.show()\n\n    def objective(self, trial):\n        # Time\n        try:\n            tau = self.fixed_param_dict[\"tau\"]\n        except KeyError:\n            tau = trial.suggest_int(\"tau\", 1, 1440)\n        train_df_divided = self.train_df.copy()\n        train_df_divided[\"t\"] = (train_df_divided[\"T\"] \/ tau).astype(np.int64)\n        # Parameters\n        param_dict = self.model.param_dict(train_df_divided)\n        p_dict = {\"tau\": None}\n        p_dict.update(\n            {\n                k: trial.suggest_uniform(k, *v)\n                for (k, v) in param_dict.items()\n            }\n        )\n        p_dict.update(self.fixed_param_dict)\n        p_dict.pop(\"tau\")\n        # Simulation\n        t_end = train_df_divided.loc[train_df_divided.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **p_dict)\n        return self.error_f(train_df_divided, sim_df)\n\n    def error_f(self, train_df_divided, sim_df):\n        \"\"\"\n        We need to minimize the difference of the observed values and estimated values.\n        This function calculate the difference of the estimated value and obsereved value.\n        \"\"\"\n        n = self.total_population\n        df = pd.merge(train_df_divided, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        diffs = [\n            # Weighted Average: the recent data is more important\n            p * np.average(\n                abs(df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]) \/ (df[f\"{v}_observed\"] * n + 1),\n                weights=df[\"t\"]\n            )\n            for (p, v) in zip(self.model.PRIORITIES, self.model.VARIABLES)\n        ]\n        return sum(diffs) * n\n\n    def compare_df(self):\n        \"\"\"\n        Show the taining data and simulated data in one dataframe.\n\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        observed_df = self.train_df.drop(\"T\", axis=1)\n        observed_df[\"t\"] = (self.train_df[\"T\"] \/ tau).astype(int)\n        t_end = observed_df.loc[observed_df.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **est_dict)\n        df = pd.merge(observed_df, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        df = df.set_index(\"t\")\n        return df\n\n    def compare_graph(self):\n        \"\"\"\n        Compare obsereved and estimated values in graphs.\n        \"\"\"\n        df = self.compare_df()\n        use_variables = [\n            v for (i, (p, v)) in enumerate(zip(self.model.PRIORITIES, self.model.VARIABLES))\n            if p != 0 and i != 0\n        ]\n        val_len = len(use_variables) + 1\n        fig, axes = plt.subplots(\n            ncols=1, nrows=val_len, figsize=(9, 6 * val_len \/ 2))\n        for (ax, v) in zip(axes.ravel()[1:], use_variables):\n            df[[f\"{v}_observed\", f\"{v}_estimated\"]].plot.line(\n                ax=ax, ylim=(0, None), sharex=True,\n                title=f\"{self.model.NAME}: Comparison of observed\/estimated {v}(t)\"\n            )\n            ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n            ax.ticklabel_format(style=\"sci\",  axis=\"y\", scilimits=(0, 0))\n            ax.legend(bbox_to_anchor=(1.02, 0),\n                      loc=\"lower left\", borderaxespad=0)\n        for v in use_variables:\n            df[f\"{v}_diff\"] = df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]\n            df[f\"{v}_diff\"].plot.line(\n                ax=axes.ravel()[0], sharex=True,\n                title=f\"{self.model.NAME}: observed - estimated\"\n            )\n        axes.ravel()[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n        axes.ravel()[0].yaxis.set_major_formatter(\n            ScalarFormatter(useMathText=True))\n        axes.ravel()[0].ticklabel_format(\n            style=\"sci\",  axis=\"y\", scilimits=(0, 0))\n        axes.ravel()[0].legend(bbox_to_anchor=(1.02, 0),\n                               loc=\"lower left\", borderaxespad=0)\n        fig.tight_layout()\n        fig.show()\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_r0()\n\n    def calc_days_dict(self):\n        \"\"\"\n        Calculate 1\/beta etc.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_days_dict(tau)\n\n    def predict_df(self, step_n):\n        \"\"\"\n        Predict the values in the future.\n        @step_n <int>: the number of steps\n        @return <pd.DataFrame>: predicted data for measurable variables.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        df = simulation(self.model, self.initials, step_n=step_n, **est_dict)\n        df[\"Time\"] = (\n            df[\"t\"] * tau).apply(lambda x: timedelta(minutes=x)) + self.start_time\n        df = df.set_index(\"Time\").drop(\"t\", axis=1)\n        df = (df * self.total_population).astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.model.calc_variables_reverse(df).drop(upper_cols, axis=1)\n        return df\n\n    def predict_graph(self, step_n, name=None, excluded_cols=None):\n        \"\"\"\n        Predict the values in the future and create a figure.\n        @step_n <int>: the number of steps\n        @name <str>: name of the area\n        @excluded_cols <list[str]>: the excluded columns in the figure\n        \"\"\"\n        if self.name is not None:\n            name = self.name\n        else:\n            name = str() if name is None else name\n        df = self.predict_df(step_n=step_n)\n        if excluded_cols is not None:\n            df = df.drop(excluded_cols, axis=1)\n        r0 = self.param_dict[\"R0\"]\n        title = f\"Prediction in {name} with {self.model.NAME} model: R0 = {r0}\"\n        line_plot(df, title, v=datetime.today(), h=self.total_population)\n\n    def rmsle(self, compare_df):\n        \"\"\"\n        Return the value of RMSLE.\n        @param compare_df <pd.DataFrame>\n        \"\"\"\n        df = compare_df.set_index(\"t\") * self.total_population\n        score = 0\n        for (priority, v) in zip(self.model.PRIORITIES, self.model.VARIABLES):\n            if priority == 0:\n                continue\n            observed, estimated = df[f\"{v}_observed\"], df[f\"{v}_estimated\"]\n            diff = (np.log(observed + 1) - np.log(estimated + 1))\n            score += (diff ** 2).sum()\n        rmsle = np.sqrt(score \/ len(df))\n        return rmsle\n\n    def score(self):\n        \"\"\"\n        Return the value of RMSLE.\n        \"\"\"\n        rmsle = self.rmsle(self.compare_df().reset_index(\"t\"))\n        return rmsle\n\n    def info(self):\n        \"\"\"\n        Return Estimater information.\n        @return <tupple[object]>:\n            - <ModelBase>: model\n            - <dict[str]=str>: name, total_population, start_time, tau\n            - <dict[str]=float>: values of parameters of model\n        \"\"\"\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        info_dict = {\n            \"name\": self.name,\n            \"total_population\": self.total_population,\n            \"start_time\": self.start_time,\n            \"tau\": param_dict[\"tau\"],\n            \"initials\": self.initials\n        }\n        param_dict.pop(\"tau\")\n        return (self.model, info_dict, param_dict)","2ec23393":"class Predicter(object):\n    \"\"\"\n    Predict the future using models.\n    \"\"\"\n    def __init__(self, name, total_population, start_time, tau, initials, date_format=\"%d%b%Y\"):\n        \"\"\"\n        @name <str>: place name\n        @total_population <int>: total population\n        @start_time <datatime>: the start time\n        @tau <int>: tau value (time step)\n        @initials <list\/tupple\/np.array[float]>: initial values of the first model\n        @date_format <str>: date format to display in figures\n        \"\"\"\n        self.name = name\n        self.total_population = total_population\n        self.start_time = start_time.replace(hour=0, minute=0, second=0, microsecond=0)\n        self.tau = tau\n        self.date_format = date_format\n        # Un-fixed\n        self.last_time = start_time\n        self.axvlines = list()\n        self.initials = initials\n        self.df = pd.DataFrame()\n        self.title_list = list()\n        self.reverse_f = lambda x: x\n        self.model_names = list()\n\n    def add(self, model, end_day_n=None, count_from_last=False, vline=True, **param_dict):\n        \"\"\"\n        @model <ModelBase>: the epidemic model\n        @end_day_n <int\/None>: day number of the end date (0, 1, 2,...), or None (now)\n            - if @count_from_last <bool> is True, start point will be the last date registered to Predicter\n        @vline <bool>: if True, vertical line will be shown at the end date\n        @**param_dict <dict>: keyword arguments of the model\n        \"\"\"\n        # Validate day number, and calculate step number\n        vline_yesterday = False\n        if end_day_n == 0:\n            end_day_n = 1\n            vline_yesterday = True\n        if end_day_n is None:\n            end_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n        else:\n            if count_from_last:\n                end_time = self.last_time + timedelta(days=end_day_n)\n            else:\n                end_time = self.start_time + timedelta(days=end_day_n)\n        if end_time <= self.last_time:\n            raise Exception(f\"Model on {end_time.strftime(self.date_format)} has been registered!\")\n        step_n = int((end_time - self.last_time).total_seconds() \/ 60 \/ self.tau) + 1\n        self.last_time = end_time.replace(hour=0, minute=0, second=0, microsecond=0)\n        # Perform simulation\n        new_df = simulation(model, self.initials, step_n=step_n, **param_dict)\n        new_df[\"t\"] = new_df[\"t\"] + len(self.df)\n        self.df = pd.concat([self.df, new_df.iloc[1:, :]], axis=0).fillna(0)\n        self.initials = new_df.set_index(\"t\").iloc[-1, :]\n        # For title\n        self.model_names.append(model.NAME)\n        if vline:\n            vline_date = end_time.replace(hour=0, minute=0, second=0, microsecond=0)\n            if vline_yesterday:\n                vline_date -= timedelta(days=1)\n            self.axvlines.append(vline_date)\n            r0 = model(**param_dict).calc_r0()\n            if len(self.axvlines) == 1:\n                self.title_list.append(f\"{model.NAME}(R0={r0}, -{vline_date.strftime(self.date_format)})\")\n            else:\n                if model.NAME == self.model_names[-1]:\n                    self.title_list.append(f\"({r0}, -{vline_date.strftime(self.date_format)})\")\n                else:\n                    self.title_list.append(f\"{model.NAME}({r0}, -{end_time.strftime(self.date_format)})\")\n        # Update reverse function (X, Y,.. to Susceptible, Infected,...)\n        self.reverse_f = model.calc_variables_reverse\n        return self\n\n    def restore_df(self, min_infected=1):\n        \"\"\"\n        Return the dimentional simulated data.\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @return <pd.DataFrame>\n        \"\"\"\n        df = self.df.copy()\n        df[\"Time\"] = self.start_time + df[\"t\"].apply(lambda x: timedelta(minutes=x * self.tau))\n        df = df.drop(\"t\", axis=1).set_index(\"Time\") * self.total_population\n        df = df.astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.reverse_f(df).drop(upper_cols, axis=1)\n        df = df.loc[df[\"Infected\"] >= min_infected, :]\n        return df\n\n    def restore_graph(self, drop_cols=None, min_infected=1, **kwargs):\n        \"\"\"\n        Show the dimentional simulate data as a figure.\n        @drop_cols <list[str]>: the columns not to be shown\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @kwargs: keyword arguments of line_plot() function\n        \"\"\"\n        df = self.restore_df(min_infected=min_infected)\n        if drop_cols is not None:\n            df = df.drop(drop_cols, axis=1)\n        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n        axvlines = [today, *self.axvlines] if len(self.axvlines) == 1 else self.axvlines[:]\n        line_plot(\n            df,\n            title=f\"{self.name}: {', '.join(self.title_list)}\",\n            v=axvlines[:-1],\n            h=self.total_population,\n            **kwargs\n        )","4958206b":"class Scenario(object):\n    \"\"\"\n    Class for scenario analysis.\n    \"\"\"\n    SUFFIX_DICT = defaultdict(lambda: \"th\")\n    SUFFIX_DICT.update({1: \"st\", 2: \"nd\", 3: \"rd\"})\n\n    def __init__(self, ncov_df, name, date_format=\"%d%b%Y\", **kwargs):\n        \"\"\"\n        @ncov_df <pd.DataFrame>: the cleaned data\n        @name <str>: name of the country\/area\n        @date_format <str>: string format of date\n        @kwargs: keyword arguments of select_area() function\n        \"\"\"\n        record_df = select_area(ncov_df, **kwargs)\n        record_df = record_df.set_index(\"Date\").resample(\"D\").last()\n        record_df = record_df.interpolate(method=\"linear\")\n        record_df = record_df.loc[:, [\"Confirmed\", \"Infected\", \"Deaths\", \"Recovered\"]]\n        self.record_df = record_df.reset_index()\n        self.name = name\n        self.date_format = date_format\n        self.phase_dict = dict()\n        self.estimator_dict = dict()\n        self.param_df = pd.DataFrame()\n        self.future_phase_dict = dict()\n        self.future_param_dict = dict()\n        self.phases_without_vline = list()\n        self.last_model = ModelBase\n\n    def show_record(self):\n        \"\"\"\n        Show the records.\n        \"\"\"\n        line_plot(\n            self.record_df.drop(\"Confirmed\", axis=1).set_index(\"Date\"),\n            f\"{self.name}: Cases over time\",\n            y_integer=True\n        )\n        return self.record_df\n\n    def growth_factor(self, days_to_predict=0, until_stopping=False, show_figure=True):\n        \"\"\"\n        Return growth factor group and the history of growth factor values.\n        @days_to_predict <int>: how many days to predict\n        @until_stopping <bool>:\n            if True and days_to_predict > 0,\n            calculate growth factor values until the group will shift stopping\n            after the last observation date\n        @show_figure <bool>: if True, show line plot of cases over time\n        \"\"\"\n        # Calculate growth factor\n        if days_to_predict <= 0:\n            # Value\n            records = self.record_df.set_index(\"Date\")[\"Confirmed\"]\n            growth = records.diff() \/ records.diff().shift(freq=\"D\")\n        else:\n            records = self.predict(days=days_to_predict, show_figure=False)\n            records = records[\"Confirmed\"].fillna(\"ffill\")\n            growth = records.diff() \/ records.diff().shift()\n        growth = growth.replace(np.inf, np.nan).fillna(1.0)\n        growth = growth.rolling(7).mean().dropna().round(2)\n        # Group\n        if days_to_predict > 0 and until_stopping:\n            last_observe_date = self.record_df[\"Date\"].max().round(\"D\")\n            df = pd.DataFrame(\n                {\"Date\": growth.index.round(\"D\"), \"Value\": growth}\n            )\n            df = df.set_index(\"Date\").resample(\"D\").last().reset_index()\n            df = df.loc[df[\"Date\"] > (last_observe_date - timedelta(days=8)), :]\n            date_df = df.loc[(df[\"Value\"] < 1).rolling(7).sum() >= 7, \"Date\"]\n            try:\n                calc_date = date_df.reset_index(drop=True)[0]\n            except IndexError:\n                calc_date = df[\"Date\"].max()\n            group = \"Stopping\"\n            growth = df.loc[df[\"Date\"] <= calc_date, :]\n            more_n = (growth[\"Value\"] > 1)[::-1].cumprod().sum()\n            less_n = (growth[\"Value\"] < 1)[::-1].cumprod().sum()\n            growth = growth.set_index(\"Date\")\n            date_str = calc_date.strftime(\"%d%b%Y\")\n            fig_title = f\"{self.name}: Growth factor over time with prediction until {date_str}\"\n        else:\n            more_n = (growth > 1)[::-1].cumprod().sum()\n            less_n = (growth < 1)[::-1].cumprod().sum()\n            calc_date = growth.index[-1]\n            group = \"Outbreaking\" if more_n >= 7 else \"Stopping\" if less_n >= 7 else \"Crossroad\"\n            fig_title = f\"{self.name}: Growth Factor over time\"\n        group_df = pd.DataFrame(\n            {\n                \"Date\": calc_date,\n                \"Group\": group,\n                \"GF > 1 [straight days]\": more_n,\n                \"GF < 1 [straight days]\": less_n\n            },\n            index=[self.name]\n        )\n        # Growth factor over time\n        if show_figure:\n            growth.plot(title=fig_title, legend=False)\n            plt.axhline(1.0, color=\"black\", linestyle=\"--\")\n            plt.xlabel(None)\n            today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n            plt.axvline(today, color=\"black\", linestyle=\"--\")\n            plt.show()\n        return group_df\n        \n    def trend(self, variables=[\"Confirmed\", \"Deaths\", \"Recovered\"], **kwargs):\n        \"\"\"\n        Perform trend analysis.\n        @variables <list[str]>: list of variables\n        @kwargs: keyword arguments of show_trend() function\n        \"\"\"\n        if \"variable\" in kwargs.keys():\n            raise KeyError(\"Please use variables argument rather than variable arugument.\")\n        for val in variables:\n            show_trend(self.record_df, name=self.name, variable=val, **kwargs)\n        return None\n\n    def set_phase(self, start_dates, population):\n        \"\"\"\n        Set phase for hyperparameter estimation.\n        @start_dates <list[str]>: list of start dates of the phases\n        @population <int or list[int]>: total population or list of total population\n        \"\"\"\n        end_dates = [\n            (datetime.strptime(s, self.date_format) - timedelta(days=1)).strftime(self.date_format)\n            for s in start_dates[1:]\n        ]\n        end_dates.append(None)\n        if isinstance(population, int):\n            population_values = [population for _ in range(len(start_dates))]\n        elif len(population) == len(start_dates):\n            population_values = population[:]\n        else:\n            raise Exception(\"start_date and population must have the same length!\")\n        self.phase_dict = {\n            self._num2str(n): {\"start_date\": s, \"end_date\": e, \"population\": p}\n            for (n, (s, e, p)) in enumerate(zip(start_dates, end_dates, population_values), 1)\n        }\n        self.estimator_dict = dict()\n        return pd.DataFrame.from_dict(self.phase_dict, orient=\"index\").fillna(\"-\")\n\n    def estimate(self, model, n_trials=100, same_tau=True):\n        \"\"\"\n        Perform hyperparameter estimation.\n        @model <ModelBase>: math model\n        @n_trials <int>: the number of trials\n        @same_tau <bool>:\n            whether apply the tau value of first phase to the following phases or not.\n        \"\"\"\n        if not self.phase_dict:\n            raise Exception(\"Please use Scenario.set_phase() at first.\")\n        tau = None\n        est_start_time = datetime.now()\n        for num in self.phase_dict.keys():\n            print(f\"Hyperparameter estimation of {num} phase.\")\n            target_dict = self.phase_dict[num]\n            while True:\n                # Create estimator\n                est_start_time_class = datetime.now()\n                self.estimator_dict[num] = Estimator(\n                    model, self.record_df, target_dict[\"population\"],\n                    name=self.name,\n                    start_date=target_dict[\"start_date\"],\n                    end_date=target_dict[\"end_date\"],\n                    date_format=self.date_format,\n                    tau=tau\n                )\n                print(\"\\tEstimator was created.\")\n                # Run trials\n                while True:\n                    print(f\"\\t\\t{n_trials} trials\", end=\" \")\n                    est_start_time_run = datetime.now()\n                    with warnings.catch_warnings():\n                        warnings.simplefilter(\"ignore\")\n                        _ = self.estimator_dict[num].run(n_trials=n_trials)\n                    minutes, seconds = divmod(int((datetime.now() - est_start_time_run).total_seconds()), 60)\n                    print(f\"finished in {minutes} min {seconds} sec.\")\n                    # Check if estimated in (observed * 0.8, observed * 1.2)\n                    compare_df = self.estimator_dict[num].compare_df()\n                    targets = [\n                        (compare_df[f\"{val}_estimated\"], compare_df[f\"{val}_observed\"])\n                        for val in model.MONOTONIC\n                    ]\n                    max_ok = [obs.max() * 0.8 <= est.max() <= obs.max() * 1.2 for (est, obs) in targets]\n                    monotonic_ok = [target[0].is_monotonic for target in targets]\n                    elapsed = (datetime.now() - est_start_time_class).total_seconds()\n                    if all(max_ok) or not all(monotonic_ok) or elapsed > 60 * 3:\n                        break\n                if all(monotonic_ok) and all(max_ok):\n                    print(\"\\tSuccessfully estimated.\")\n                    break\n                vals = [val for (val, ok) in zip(model.MONOTONIC, monotonic_ok) if not ok]\n                try:\n                    print(f\"\\tEstimator will be replaced because estimated {vals[0]} is non-monotonic.\")\n                except IndexError:\n                    print(f\"\\tEstimator will be replaced because it is incapable of improvement.\")\n            tau = self.estimator_dict[num].param_dict[\"tau\"]\n        minutes, seconds = divmod(int((datetime.now() - est_start_time).total_seconds()), 60)\n        print(f\"Total: {minutes} min {seconds} sec.\")\n        self.show_parameters()\n        self.last_model = model\n\n    def accuracy_graph(self, phase_n=1):\n        \"\"\"\n        Show observed - estimated graph.\n        @phase_n <int>: phase number\n        \"\"\"\n        phase_numbers = self.estimator_dict.keys()\n        phase = self._num2str(phase_n)\n        if phase not in phase_numbers:\n            raise KeyError(f\"phase_n must be in {list(phase_numbers)[0]} - {list(phase_numbers)[-1]}\")\n        self.estimator_dict[phase].compare_graph()\n\n    def _num2str(self, num):\n        \"\"\"\n        Convert numbers to 1st, 2nd etc.\n        @num <int>: number\n        @return <str>\n        \"\"\"\n        q, mod = divmod(num, 10)\n        suffix = \"th\" if q == 1 else self.SUFFIX_DICT[mod]\n        return f\"{num}{suffix}\"\n\n    def show_parameters(self):\n        \"\"\"\n        Show the parameter values.\n        @retunr <pd.DataFrame>\n        \"\"\"\n        # Phase information\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        df1 = pd.DataFrame.from_dict(phase_dict, orient=\"index\")\n        # Parameter information\n        _dict = {\n            k: estimator.param_dict\n            for (k, estimator) in self.estimator_dict.items()\n        }\n        _future_dict = {\n            k: {\n                \"tau\": _dict[\"1st\"][\"tau\"],\n                **param_dict,\n                \"R0\": self.last_model(**param_dict).calc_r0(),\n                \"score\": None,\n                **self.last_model(**param_dict).calc_days_dict(_dict[\"1st\"][\"tau\"])\n            }\n            for (k, param_dict) in self.future_param_dict.items()\n        }\n        _dict.update(_future_dict)\n        df2 = pd.DataFrame.from_dict(_dict, orient=\"index\")\n        # Rename R0 to Rt\n        df2 = df2.rename({\"R0\": \"Rt\"}, axis=1)\n        self.param_df = pd.concat([df1, df2], axis=1).fillna(\"-\")\n        return self.param_df\n\n    def param(self, phase, param_name):\n        \"\"\"\n        Return parameter value.\n        @phase <str>: phase name, like 1st, 2nd..., or last\n        @param_name <str>: name of parameter, like rho\n        \"\"\"\n        if phase == \"last\":\n            phase = list(self.phase_dict.items())[-1][0]\n        try:\n            estimator = self.estimator_dict[phase]\n        except KeyError:\n            raise KeyError(\"Please revise phase name (NOT iinclude future params). e.g. 1st, 2nd,... or last\")\n        try:\n            param_name = \"R0\" if param_name == \"Rt\" else param_name\n            return estimator.param_dict[param_name]\n        except KeyError:\n            raise KeyError(\"Please revise parameter name. e.g. rho, gamma, R0 or R0\")\n\n    def param_history(self, targets=None, box_plot=True, **kwargs):\n        \"\"\"\n        Show the ratio to 1st parameters as a figure (bar plot).\n        @targets <list[str] or str>: parameters to show (including Rt etc.)\n        @box_plot <bool>: if True, box plot. if False, line plot.\n        @kwargs: keword arguments of pd.DataFrame.plot or line_plot()\n        \"\"\"\n        _ = self.show_parameters()\n        targets = self.param_df.columns if targets is None else targets\n        targets = [targets] if isinstance(targets, str) else targets\n        if \"R0\" in targets:\n            targets = [t.replace(\"R0\", \"Rt\") for t in targets]\n        df = self.param_df.loc[:, targets]\n        df.index = self.param_df[[\"start_date\", \"end_date\"]].apply(\n            lambda x: f\"{x[0]}-{x[1].replace('-', 'today')}\",\n            axis=1\n        )\n        df = df \/ df.iloc[0]\n        if box_plot:\n            df.plot.bar(title=\"Ratio to 1st parameters\", **kwargs)\n            plt.xticks(rotation=0)\n            plt.show()\n        else:\n            _df = df.reset_index(drop=True)\n            _df.index = _df.index + 1\n            line_plot(\n                _df, title=\"Ratio to 1st parameters\",\n                xlabel=\"Phase\", ylabel=str(), math_scale=False,\n                **kwargs\n            )\n\n    def compare_estimated_numbers(self, phases=None):\n        \"\"\"\n        Compare the number of confimred cases estimated with the parameters and show graph.\n        @variable <str>: variable to compare\n        @phases <list[str]>: phase to show (if None, all)\n        \"\"\"\n        phases = list(self.phase_dict.keys()) if phases is None else phases\n        # Observed\n        df = pd.DataFrame(self.record_df.set_index(\"Date\")[\"Confirmed\"])\n        # Estimated\n        for (num, estimator) in self.estimator_dict.items():\n            model, info_dict, param_dict = estimator.info()\n            day_n = int((datetime.today() - info_dict[\"start_time\"]).total_seconds() \/ 60 \/ 60 \/ 24 + 1)\n            predicter = Predicter(**info_dict)\n            predicter.add(model, end_day_n=day_n, **param_dict)\n            # Calculate the number of confirmed cases\n            new_df = predicter.restore_df().drop(\"Susceptible\", axis=1).sum(axis=1)\n            new_df = new_df.resample(\"D\").last()\n            df = pd.concat([df, new_df], axis=1)\n        # Show graph\n        df = df.fillna(0).astype(np.int64)\n        df.columns = [\"Observed\"] + [f\"{phase}_param\" for phase in self.phase_dict.keys()]\n        df = df.loc[self.phase_dict[\"1st\"][\"start_date\"]: self.record_df[\"Date\"].max(), :]\n        for col in df.columns[1:]:\n            if col[:col.find(\"_\")] not in phases:\n                continue\n            line_plot(\n                df.replace(0, np.nan)[[\"Observed\", col]],\n                f\"Confirmed cases over time: Actual and predicted with {col}\",\n                y_integer=True\n            )\n\n    def clear_future_param(self):\n        \"\"\"\n        Clear the future parameters.\n        \"\"\"\n        self.future_param_dict = dict()\n        self.future_phase_dict = dict()\n        last_phase = list(self.phase_dict.items())[-1][0]\n        self.phase_dict[last_phase][\"end_date\"] = None\n        return self\n\n    def add_future_param(self, start_date, vline=True, **kwargs):\n        \"\"\"\n        Add parameters of the future.\n        @start_date <str>: the start date of the phase\n        @vline <bool>: if True, add vertical line in the figure of predicted number of cases\n        @kwargs: keword argument of parameters to change\n        \"\"\"\n        yesterday_of_start = (pd.to_datetime(start_date) - timedelta(days=1)).strftime(self.date_format)\n        # Last phase registered\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        last_phase = list(phase_dict.items())[-1][0]\n        # Set the end date of the last phase\n        if self.future_phase_dict:\n            self.future_phase_dict[last_phase][\"end_date\"] = yesterday_of_start\n        else:\n            self.phase_dict[last_phase][\"end_date\"] = yesterday_of_start\n        # Set the new phase\n        try:\n            param_dict = self.estimator_dict[last_phase].info()[2]\n            population = self.phase_dict[last_phase][\"population\"]\n        except KeyError:\n            param_dict = self.future_param_dict[last_phase].copy()\n            population = self.future_phase_dict[last_phase][\"population\"]\n        param_dict.update(**kwargs)\n        new_phase = self._num2str(len(phase_dict) + 1)\n        self.future_param_dict[new_phase] = param_dict\n        self.future_phase_dict[new_phase] = {\n            \"start_date\": start_date,\n            \"end_date\": None,\n            \"population\": population\n        }\n        if not vline:\n            self.phases_without_vline.append(new_phase)\n        return pd.DataFrame.from_dict(self.future_param_dict, orient=\"index\")\n\n    def add_future_param_gradually(self, start_date, end_date, param, first, last):\n        \"\"\"\n        Set the future parameters. The value will be gradually (log-scale) changed.\n        @start_date <str>: the start date of change\n        @end_date <str>: the end date of change\n        @param <str>: parameter name\n        @first <float>: parameter value of the start date\n        @last <float>: parameter value of the end date\n        \"\"\"\n        start = (pd.to_datetime(start_date) - timedelta(days=1)).strftime(self.date_format)\n        dates = pd.date_range(start=start, end=end_date, freq=\"D\")\n        values = np.logspace(\n            start=np.log10(first), stop=np.log10(last), num=len(dates), base=10.0\n        )\n        for (d, v) in zip(dates[1:], values[1:]):\n            vline = True if d in dates[-2:] else False\n            self.add_future_param(d.strftime(self.date_format), vline=vline, **{param: v})\n        return pd.DataFrame.from_dict(self.future_param_dict, orient=\"index\")\n\n    def predict(self, days=1000, min_infected=1, show_figure=True):\n        \"\"\"\n        Predict the future.\n        @days <int or None>: how many days to predict from the last records date\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @show_figure <bool>: if True, show line plot of cases over time\n        \"\"\"\n        if not isinstance(days, int):\n            raise TypeError(\"days must be integer!\")\n        # Create parameter dictionary\n        predict_param_dict = {\n            phase: self.estimator_dict[phase].info()[2]\n            for (phase, _) in self.phase_dict.items()\n        }\n        predict_param_dict.update(self.future_param_dict)\n        # Define phases\n        model, info_dict, _ = self.estimator_dict[\"1st\"].info()\n        predicter = Predicter(**info_dict)\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        # Simulation with Predicter\n        for (phase, date_dict) in phase_dict.items():\n            start = pd.to_datetime(date_dict[\"start_date\"])\n            end = pd.to_datetime(date_dict[\"end_date\"])\n            if end is None:\n                day_n = days\n            elif start == end:\n                day_n = 0\n            else:\n                day_n = int((end - start).total_seconds() \/ 60 \/ 60 \/ 24) + 1\n            param_dict = predict_param_dict[phase].copy()\n            vline = False if phase in self.phases_without_vline else True\n            predicter.add(model, end_day_n=day_n, count_from_last=True, vline=vline, **param_dict)\n        # Restore\n        df = predicter.restore_df(min_infected=min_infected)\n        try:\n            df[\"Confirmed\"] = df[\"Infected\"] + df[\"Recovered\"] + df[\"Fatal\"]\n        except KeyError:\n            pass\n        # Graph: If max(other variables) < min(Susceptible), not show Susceptible\n        if show_figure:\n            without_s = df.drop(\"Susceptible\", axis=1).sum(axis=1).max()\n            drop_cols = [\"Susceptible\"] if without_s < df[\"Susceptible\"].min() else None\n            predicter.restore_graph(drop_cols=drop_cols, min_infected=min_infected, y_integer=True)\n        return df","fcd82b0b":"def log_curve(x, k, x_0, ymax):\n    return ymax \/ (1 + np.exp(-k*(x-x_0)))","b4ab17ae":"def log_fit(train_df, area, metric):\n    area_data = select_area(train_df, areas=[area])\n    area_data = area_data.loc[area_data[metric] > 0, :]\n    x_data = range(len(area_data.index))\n    y_data = area_data[metric]\n    if len(y_data) < 5:\n        estimated_k = -1  \n        estimated_x_0 = -1 \n        ymax = -1\n    elif max(y_data) == 0:\n        estimated_k = -1  \n        estimated_x_0 = -1 \n        ymax = -1\n    else:\n        try:\n            popt, pcov = curve_fit(\n                log_curve, x_data, y_data, bounds=([0,0,0],np.inf),\n                p0=[0.3,100,10000], maxfev=1000000\n            )\n            estimated_k, estimated_x_0, ymax = popt\n        except RuntimeError:\n            print(area)\n            print(\"Error - curve_fit failed\") \n            estimated_k = -1  \n            estimated_x_0 = -1 \n            ymax = -1\n    estimated_parameters = pd.DataFrame(\n        np.array([[area, estimated_k, estimated_x_0, ymax]]), columns=['Area', 'k', 'x_0', 'ymax']\n    )\n    return estimated_parameters","0e90e0e1":"def get_parameters(metric):\n    parameters = pd.DataFrame(columns=['Area', 'k', 'x_0', 'ymax'], dtype=np.float)\n    for area in train_df['Area'].unique():\n        estimated_parameters = log_fit(train_df, area, metric)\n        parameters = parameters.append(estimated_parameters)\n    parameters['k'] = pd.to_numeric(parameters['k'], downcast=\"float\")\n    parameters['x_0'] = pd.to_numeric(parameters['x_0'], downcast=\"float\")\n    parameters['ymax'] = pd.to_numeric(parameters['ymax'], downcast=\"float\")\n    parameters = parameters.replace({'k': {-1: parameters[parameters['ymax']>0].median()[0]}, \n                                     'x_0': {-1: parameters[parameters['ymax']>0].median()[1]}, \n                                     'ymax': {-1: parameters[parameters['ymax']>0].median()[2]}})\n    return parameters","d32fb38c":"train_raw = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv\")\ntest_raw = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv\")\nsubmission_sample_raw = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/submission.csv\")\n# Population\npopulation_raw = pd.read_csv(\n    \"\/kaggle\/input\/covid19-global-forecasting-locations-population\/locations_population.csv\"\n)","5708370f":"submission_sample_raw.head()","de677e8e":"df = pd.DataFrame(\n    {\n        \"Nunique_train\": train_raw.nunique(),\n        \"Nunique_test\": test_raw.nunique(),\n        \"Null_Train\": train_raw.isnull().sum(),\n        \"Null_Test\": test_raw.isnull().sum(),\n    }\n)\ndf.fillna(\"-\").T","bd33cbda":"population_raw.head()","74ed7f77":"df = population_raw.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1)\ndf[\"Country\/Province\"] = df[[\"Country\", \"Province\"]].apply(\n    lambda x: f\"{x[0]}\/{x[0]}\" if x[1] is np.nan else f\"{x[0]}\/{x[1]}\",\n    axis=1\n)\ndf = df.loc[:, [\"Country\/Province\", \"Population\"]]\n# Culculate total value of each country\/province\ndf = df.groupby(\"Country\/Province\").sum()\n# Global population\ndf.loc[\"Global\", \"Population\"] = df[\"Population\"].sum()\n# DataFrame to dictionary\npopulation_dict = df.astype(np.int64).to_dict()[\"Population\"]\npopulation_dict","e9552876":"df = pd.merge(\n    train_raw.rename({\"Province_State\": \"Province\", \"Country_Region\": \"Country\"}, axis=1),\n    population_raw.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1),\n    on=[\"Country\", \"Province\"],\n    how=\"left\"\n)\n# Area: Country or Country\/Province\ndf[\"Area\"] = df[[\"Country\", \"Province\"]].apply(\n    lambda x: f\"{x[0]}\" if x[1] is np.nan else f\"{x[0]}\/{x[1]}\",\n    axis=1\n)\n# Date\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\n# The number of cases\ndf = df.rename({\"ConfirmedCases\": \"Confirmed\", \"Fatalities\": \"Fatal\"}, axis=1)\ndf[[\"Confirmed\", \"Fatal\"]] = df[[\"Confirmed\", \"Fatal\"]].astype(np.int64)\n# Show data\ndf = df.loc[:, [\"Date\", \"Area\", \"Population\", \"Confirmed\", \"Fatal\"]]\ntrain_df = df.copy()\ntrain_df.tail()","2c6429ff":"df = pd.merge(\n    test_raw.rename({\"Province_State\": \"Province\", \"Country_Region\": \"Country\"}, axis=1),\n    population_raw.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1),\n    on=[\"Country\", \"Province\"],\n    how=\"left\"\n)\ndf[\"Area\"] = df[[\"Country\", \"Province\"]].apply(\n    lambda x: f\"{x[0]}\" if x[1] is np.nan else f\"{x[0]}\/{x[1]}\",\n    axis=1\n)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf = df.loc[:, [\"ForecastId\", \"Date\", \"Area\", \"Population\"]]\ntest_df = df.copy()\ntest_df.tail()","01d3ddf4":"%%time\nconfirmed_param_df = get_parameters(\"Confirmed\")\nconfirmed_param_df.head()","112a376b":"df = train_df.loc[train_df[\"Confirmed\"] > 0, [\"Date\", \"Area\"]].groupby(\"Area\").first()\ndf = df.rename({\"Date\": \"First_date\"}, axis=1).reset_index()\ndf = pd.merge(confirmed_param_df, df)\nconfirmed_df = df.copy()\nconfirmed_df.head()","841adda9":"fatal_param_df = get_parameters(\"Fatal\")\nfatal_param_df.head()","b1c9ab13":"df = train_df.loc[train_df[\"Fatal\"] > 0, [\"Date\", \"Area\"]].groupby(\"Area\").first()\ndf = df.rename({\"Date\": \"First_date\"}, axis=1).reset_index()\ndf = pd.merge(fatal_param_df, df)\nfatal_df = df.copy()\nfatal_df.head()","e605b84e":"df = pd.merge(confirmed_df, fatal_df, on=\"Area\", suffixes=[\"_confirmed\", \"_fatal\"])\n# k\ndf[\"k\"] = df[\"k_confirmed\"]\n# x_0\ndf[\"First_date_recovered\"] = df[\"First_date_fatal\"]\ndf[\"x_0\"] = df[[\"x_0_confirmed\", \"x_0_fatal\"]].max(axis=1)\n# ymax\ndf[\"ymax\"] = df[\"ymax_confirmed\"] - df[\"ymax_fatal\"]\n# save\ndf = df.loc[:, [\"Area\", \"First_date_recovered\", \"k\", \"x_0\", \"ymax\"]]\nrecovered_df = df.copy()\nrecovered_df.head()","4d81825e":"df = train_df.loc[train_df[\"Confirmed\"] > 0, :]\ndf = pd.merge(df, recovered_df, on=\"Area\", how=\"left\")\ndf[\"date_diff\"] = (df[\"Date\"] - df[\"First_date_recovered\"]).dt.total_seconds() \/ 60 \/ 60 \/ 24\ndf.loc[(df[\"date_diff\"] < 0) | (df[\"date_diff\"].isnull()), \"date_diff\"] = -1\ndf[\"date_diff\"] = df[\"date_diff\"].astype(np.int64)\ndf[\"Recovered\"] = df[[\"date_diff\", \"k\", \"x_0\", \"ymax\"]].apply(\n    lambda x: 0 if x[0] < 0 else log_curve(x[0], x[1], x[2], x[3]),\n    axis=1\n).astype(np.int64)\ndf = df.rename({\"Fatal\": \"Deaths\"}, axis=1)\ndf[\"Infected\"] = df[\"Confirmed\"] - df[\"Recovered\"] - df[\"Deaths\"]\nncov_df = df.copy()\nncov_df.head()","4a454448":"scenario = Scenario(ncov_df, name=\"Global\")","d9b25f6b":"scenario.show_record().tail()","ca7cf37e":"scenario.growth_factor()","6426654b":"scenario.trend(variables=[\"Confirmed\"])","ee764af0":"scenario.trend(variables=[\"Confirmed\"], start_date=\"07Mar2020\")","b6fb1737":"scenario.set_phase(\n    start_dates=[\"04Apr2020\"],\n    population=population_dict[\"Global\"]\n)","b6da6ca9":"scenario.estimate(SIRF)","c2f1bc82":"scenario.accuracy_graph(phase_n=1)","0080bcf5":"scenario.show_parameters()","a7189977":"days_to_predict = int((test_df[\"Date\"].max() - datetime.today()).total_seconds() \/ 3600 \/ 24 + 10)\ndays_to_predict","d105db63":"global_predict = scenario.predict(days=days_to_predict)\nglobal_predict.tail(7).style.background_gradient(axis=0)","319b3234":"# Current record\ndf = ncov_df.copy()\ndf = df.loc[df[\"Date\"] == df[\"Date\"].max(), [\"Area\", \"Confirmed\", \"Deaths\"]]\ndf[\"Confirmed\"] = df[\"Confirmed\"] \/ df[\"Confirmed\"].sum()\ndf[\"Deaths\"] = df[\"Deaths\"] \/ df[\"Deaths\"].sum()\ncurrent_df = df.rename({\"Deaths\": \"Fatal\"}, axis=1)\ncurrent_df.tail()","e8737895":"df = global_predict.copy()\ndf[\"Date\"] = df.index.date\ndf[\"Confirmed\"] = df[\"Infected\"] + df[\"Recovered\"] + df[\"Fatal\"]\ndf = df.groupby(\"Date\").last().reset_index()[[\"Date\", \"Confirmed\", \"Fatal\"]]\nglobal_df = df.copy()\nglobal_df.tail()","1906b96f":"record_df = pd.DataFrame()\n\nfor i in range(len(global_df)):\n    date, confirmed, fatal = global_df.iloc[i, :].tolist()\n    df = current_df.copy()\n    df[\"Date\"] = date\n    df[\"Confirmed\"] = (confirmed * df[\"Confirmed\"]).astype(np.int64)\n    df[\"Fatal\"] = (fatal * df[\"Fatal\"]).astype(np.int64)\n    record_df = pd.concat([record_df, df], axis=0)\n\nrecord_df[\"Date\"] = pd.to_datetime(record_df[\"Date\"])\nrecord_df = record_df.loc[:, [\"Date\", \"Area\", \"Confirmed\", \"Fatal\"]].reset_index(drop=True)\nrecord_df","fd489d59":"submission_sample_raw.shape","730874d2":"df = pd.merge(record_df, test_df, on=[\"Date\", \"Area\"], how=\"right\")\ndf = df.sort_values(\"ForecastId\").reset_index()\ndf = df.groupby([\"Area\"]).fillna(method=\"bfill\")\ndf = df.loc[:, [\"ForecastId\", \"Confirmed\", \"Fatal\"]]\ndf = df.rename({\"Confirmed\": \"ConfirmedCases\", \"Fatal\": \"Fatalities\"}, axis=1)\ndf = df.fillna(0).astype(np.int64)\nsubmission_df = df.copy()\nsubmission_df","073a849a":"submission_df.shape","48f92177":"len(submission_df) == len(submission_sample_raw)","253e6df2":"submission_df.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","4751c85c":"## Tool","f627023e":"## Data","da600f7d":"# Logistic curve fitting and SIR-F model\nUsing curve fitting method and SIR-F model, we will predict the number of confirmed cases and fatal cases with COVID-19 global data. SIR-F model was created in another notebook of an auther. Please refer to the references.  \n\nContents:\n* Preparation\n* Prediction of the number of recovered cases with logistic curve\n* Prameter estimation with SIR-F model\n* Prediction of global data\n* Data submission\n\nReferences:\n* [COVID-19 - Growth of Virus in Specific Countries](https:\/\/www.kaggle.com\/wjholst\/covid-19-growth-of-virus-in-specific-countries) by Bill Holst\n* [COVID-19 data with SIR model](https:\/\/www.kaggle.com\/lisphilar\/covid-19-data-with-sir-model) by Lisphilar","22e11326":"## Trend Analysis","db38c1b8":"## Prepare for SIR-F model hyperparameter optumization","13f08973":"## Area lebel","11db61e1":"## Submit data","11c31d90":"### Predict the number of recovered cases","e8af3b58":"### Curve fitting: Confirmed, Fatal","b625be14":"## Prediction of the number of recovered cases with logistic curve"}}