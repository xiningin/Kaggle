{"cell_type":{"443bc68f":"code","d12baf97":"code","d950168c":"code","0dddb5be":"code","5059cfb8":"code","e1f03a89":"code","4d204140":"code","61d40013":"code","9ab28071":"code","b439d240":"code","f6f20ff8":"code","0ff776db":"code","4f925ab3":"code","ddc9528c":"code","3d0eb54e":"code","f03fed08":"code","d6ea2039":"code","ef51aabe":"code","2fd411dc":"code","8932cbb0":"code","0fd9bda7":"code","35852030":"code","f7beeefc":"markdown","1edbfa29":"markdown","75ca1b80":"markdown","f117c377":"markdown","bed350a5":"markdown","651f4806":"markdown","83cf19a8":"markdown","0ae35cd7":"markdown","7a843095":"markdown","1aac161f":"markdown","aa0ffb0d":"markdown","1cf6f2a2":"markdown","560d4aa4":"markdown","2d8f0676":"markdown"},"source":{"443bc68f":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom math import sin, cos, pi\n\nfrom keras.applications import ResNet50\nfrom keras.layers import Conv2D, LeakyReLU, GlobalAveragePooling2D, Dropout, Dense\nfrom keras.models import Sequential","d12baf97":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)","d950168c":"!unzip ..\/input\/facial-keypoints-detection\/training.zip\n!unzip ..\/input\/facial-keypoints-detection\/test.zip","0dddb5be":"train_file = pd.read_csv('.\/training.csv')\ntest_file = pd.read_csv('.\/test.csv')\nidlookup_file = pd.read_csv('..\/input\/facial-keypoints-detection\/IdLookupTable.csv')","5059cfb8":"train_file.head()","e1f03a89":"test_file.head()","4d204140":"idlookup_file.head()","61d40013":"train_file.isnull().sum()","9ab28071":"clean_train_file = train_file.dropna() # we use this for augmentation\ntrain_file = train_file.fillna(method='ffill')","b439d240":"train_file.isnull().sum()","f6f20ff8":"def load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)\/255.\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop(['Image'], axis=1)\n    keypoint_features = []\n    for idx, features in keypoint_data.iterrows():\n        keypoint_features.append(features)\n    keypoint_features = np.array(keypoint_features, dtype=float)\n    return keypoint_features\n\ntrain_images = load_images(train_file)\nimages = load_images(clean_train_file)\ntrain_keypoints = load_keypoints(train_file)\nkeypoints = load_keypoints(clean_train_file)\ntest_images = load_images(test_file)","0ff776db":"class aug_config:\n    rotation_augmentation = True\n    brightness_augmentation = True\n    shift_augmentation = True\n    random_noise_augmentation = True\n    rotation_angles = [15]\n    pixel_shifts = [15]","4f925ab3":"def rotate_augmentation(images, keypoints, rotation_angles):\n    rotated_images = []\n    rotated_keypoints = []\n    for angle in rotation_angles:\n        for angle in [angle, -angle]:\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.)\n            angle_rad = -angle*pi\/180.\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.\n                for idx in range(0, len(rotated_keypoint), 2):\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   \n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\nif aug_config.rotation_augmentation:\n    rotated_train_images, rotated_train_keypoints = rotate_augmentation(images, keypoints, aug_config.rotation_angles)\n    train_images = np.concatenate((train_images, rotated_train_images))\n    train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(rotated_train_images[19], rotated_train_keypoints[19], axis, \"Rotation Augmentation\")","ddc9528c":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    \n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    \n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\nif aug_config.brightness_augmentation:\n    altered_brightness_images, altered_brightness_keypoints = alter_brightness(images, keypoints)\n    train_images = np.concatenate((train_images, altered_brightness_images))\n    train_keypoints = np.concatenate((train_keypoints, altered_brightness_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_images[19], altered_brightness_keypoints[19], axis, \"Alter Brightness Augmentation\")","3d0eb54e":"def shift_images(images, keypoints, pixel_shifts):\n    shifted_images = []\n    shifted_keypoints = []\n    for shift in pixel_shifts:    \n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n    return shifted_images, shifted_keypoints\n\nif aug_config.shift_augmentation:\n    shifted_train_images, shifted_train_keypoints = shift_images(images, keypoints, aug_config.pixel_shifts)\n    train_images = np.concatenate((train_images, shifted_train_images))\n    train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(shifted_train_images[19], shifted_train_keypoints[19], axis, \"Shift Augmentation\")","f03fed08":"def add_noise(images):\n    noisy_images = []\n    for image in images:\n        noisy_image = cv2.add(image, 0.008*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n        noisy_images.append(noisy_image.reshape(96,96,1))\n    return noisy_images\n\nif aug_config.random_noise_augmentation:\n    noisy_train_images = add_noise(images)\n    train_images = np.concatenate((train_images, noisy_train_images))\n    train_keypoints = np.concatenate((train_keypoints, keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(noisy_train_images[19], keypoints[19], axis, \"Random Noise Augmentation\")","d6ea2039":"print(train_images.shape)\nprint(train_keypoints.shape)","ef51aabe":"model = Sequential()\npretrained_model = ResNet50(input_shape=(96,96,3), include_top=False, weights='imagenet')\npretrained_model.trainable = True\n\nmodel.add(Conv2D(3, (1,1), padding='same', input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(pretrained_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","2fd411dc":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearlyStopping = EarlyStopping(monitor='loss', patience=30, mode='min',\n                             baseline=None)\n\nrlp = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, min_lr=1e-15, mode='min', verbose=1)\n\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n\nhistory = model.fit(train_images, train_keypoints, epochs=200, batch_size=64, validation_split=0.15, callbacks=[earlyStopping, rlp])","8932cbb0":"sns.set_style('darkgrid')\n\nfig, ax = plt.subplots(2, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['loss', 'val_loss']].plot(ax=ax[0])\ndf[['accuracy', 'val_accuracy']].plot(ax=ax[1])\nax[0].set_title('Model Loss', fontsize=12)\nax[1].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","0fd9bda7":"test_preds = model.predict(test_images)","35852030":"feature_names = list(idlookup_file['FeatureName'])\nimage_ids = list(idlookup_file['ImageId']-1)\nrow_ids = list(idlookup_file['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","f7beeefc":"### Training the Model","1edbfa29":"### Shift images","75ca1b80":"### Rotation","f117c377":"## Load images and keypints","bed350a5":"#### Training file include 31 columns - represents for 30 features and 1 for the image","651f4806":"## Modeling","83cf19a8":"### Change Brightness","0ae35cd7":"#### We can observe that approximate 68% of data is missing for several keypoints\nSo, we can drop all rows with missing data or fill nullvalues","7a843095":"## Import necessary packages","1aac161f":"## Predicting on Test Set and Submission","aa0ffb0d":"## Loading Data","1cf6f2a2":"## Augmentation","560d4aa4":"## Check for the null values","2d8f0676":"### Add noise"}}