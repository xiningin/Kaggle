{"cell_type":{"59210c8e":"code","d053fbc8":"code","aa369758":"code","9076bb9e":"code","b9f19d58":"code","09234626":"code","1d0d9be0":"code","08428dfc":"code","c7047ed5":"code","2a17f5fe":"code","3b5aecd0":"code","89b20593":"code","9a700d72":"code","9317ef9e":"code","acf1332b":"code","df8fd728":"code","6f9c4427":"code","695fb5f4":"code","22f44d8e":"code","1df84078":"code","0d37c72c":"code","d0f020fb":"code","0f088349":"code","ec59237a":"code","c2bd9534":"code","2b621fcc":"code","c1eb10e3":"code","85d932aa":"code","1fc6f84f":"code","859e46fb":"code","b66fbe6b":"code","35152ae3":"code","864cb308":"code","1e4514ef":"code","a373b3b9":"code","86f1918f":"code","f55090d2":"code","fe4a739d":"code","8cdd268f":"code","5cf26947":"code","c67118f3":"code","b2a90c73":"code","3021ec40":"code","8fe8e5ee":"markdown","d412225b":"markdown","66b56ffd":"markdown","8317f5b4":"markdown","9790355f":"markdown","15be3d39":"markdown","7fba8d8c":"markdown","b40bde0a":"markdown","45152621":"markdown","1e8ff9c7":"markdown","f7ee59f5":"markdown","2d8cc9f3":"markdown","a8f1c404":"markdown","9033e587":"markdown","6ea3b87f":"markdown","88db2113":"markdown","71a4332f":"markdown","a301ea40":"markdown","db4679ae":"markdown","a380b8f2":"markdown","e5109825":"markdown","901b9823":"markdown","1ed46831":"markdown","ccb84f65":"markdown","cfc5b20f":"markdown","97ce0f27":"markdown","061d2cdb":"markdown","54e12664":"markdown","d2cad25b":"markdown","1d419c00":"markdown","b7144b69":"markdown","45dc31a8":"markdown","3c254615":"markdown"},"source":{"59210c8e":"import os, random\nimport itertools\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix","d053fbc8":"INDEX = 'ID'\nTARGET = 'ACTIVITY'\n\nSEED = 2021\nNUM_CLASSES = 6\nNFOLDS = 5\n\n# lightgbm\u306e\u30d1\u30e9\u30e1\u30bf\u53ca\u3073\u5b66\u7fd2\u8a2d\u5b9a\nparams = {\n    'objective': 'multiclass',\n    'boosting': 'gbdt',\n    'metric': 'multi_logloss',\n    'feature_pre_filter': False,\n    'num_leaves': 39,\n    'bagging_freq': 3,\n    'min_child_samples': 32,\n    'learning_rate': 0.0926,\n    'lambda_l1': 0.00000049,\n    'lambda_l2': 0.00000058,\n    'feature_fraction': 0.56,\n    'bagging_fraction': 0.99,\n    'max_bin': 349,\n    'verbosity': -1,\n    'num_class': NUM_CLASSES,\n    'seed': SEED\n}\n\nnum_boost_round = 10000\nearly_stopping_rounds = 100\nverbose_eval = 1000","aa369758":"def seed_everything(seed=42, is_tensorflow=False, is_torch=False, verbose=True):\n\n    os.environ['PYTHONHASHSEED'] = str(seed) # os\n    random.seed(seed) # random\n    np.random.seed(seed) # numpy\n\n    if is_tensorflow:\n        import tensorflow as tf\n        tf.random.set_seed(seed)\n        os.environ['TF_DETERMINISTIC_OPS'] = '1'\n        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n        tf.config.threading.set_inter_op_parallelism_threads(1)\n        tf.config.threading.set_intra_op_parallelism_threads(1)\n\n    if is_torch:\n        import torch\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False # True: \u518d\u73fe\u6027\u306a\u304f\u306a\u308b\u304c\u3001\u8a08\u7b97\u901f\u304f\u306a\u308b False: \u518d\u73fe\u6027\u304c\u62c5\u4fdd\u3055\u308c\u308b\u304c\u3001\u8a08\u7b97\u9045\u304f\u306a\u308b\n\n    if verbose:\n        print(f'set random seed: {seed}')\n        \ndef lgb_get_feature_importance(model_array, features):\n    val_gain = model_array[0].feature_importance(importance_type='gain')\n    val_gain = pd.Series(val_gain)\n    \n    for m in model_array[1:]:\n        s = pd.Series(m.feature_importance(importance_type='gain'))\n        val_gain = pd.concat([val_gain, s], axis=1)\n        \n    val_mean = val_gain.mean(axis=1)\n    val_mean = val_mean.values\n    df = pd.DataFrame(val_mean, index=features, columns=['importance']).sort_values('importance')\n    df = df.sort_values('importance', ascending=True)\n    \n    ids = len(df.index) # \u7279\u5fb4\u91cf\u304c30\u4ee5\u4e0a\u3042\u308b\u3068\u304d\u306f\u4e0a\u4f4d30\u307e\u3067\u3092\u8868\u793a\n    if ids > 30:\n        df = df.iloc[-30:]\n    \n    return df\n\ndef display_ture_pred(y, oof_train):\n    ''' \u6b63\u89e3\u30e9\u30d9\u30eb\u3068\u4e88\u6e2c\u30e9\u30d9\u30eb\u306e\u5206\u5e03\u30d7\u30ed\u30c3\u30c8\u51fa\u529b\u7528 '''\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.histplot(oof_train, label='pred', ax=ax, color='black')\n    sns.histplot(y, label='true', ax=ax)\n    ax.legend()\n    ax.grid()\n    plt.show()\n\ndef display_cmx(y, oof_train):\n    ''' \u6df7\u540c\u884c\u5217\u306e\u30d7\u30ed\u30c3\u30c8\u51fa\u529b\u7528 '''\n    labels = sorted(list(set(y)))\n    cmx_data = confusion_matrix(y_true=y, y_pred=oof_train, labels=labels)\n    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n    plt.figure(figsize = (10,7))\n    sns.heatmap(df_cmx, annot=True)\n    plt.xlabel(\"predict\", fontsize=13)\n    plt.ylabel(\"true\", fontsize=13)\n    plt.show()\n    \ndef display_fi(fi_df):\n    ''' feature imporance\u306e\u30d7\u30ed\u30c3\u30c8\u51fa\u529b\u7528 '''\n    plt.figure(figsize = (10,7))\n    sns.barplot(data=fi_df, y=fi_df.index, x='importance', orient='h')\n    plt.show()\n\ndef run_train(train_df, is_weight=True) -> list:\n    ''' \u5b66\u7fd2\u3068\u5404\u7a2e\u5b66\u7fd2\u7d50\u679c\u306e\u51fa\u529b '''\n    X = train_df.drop([INDEX, TARGET], axis=1)\n    features = list(X.columns)\n    \n    X = X.values\n    y = train_df[TARGET].astype('int')\n    \n    seed_everything(seed=SEED)\n    fold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n    oof_train = np.zeros(len(X))\n    model_array = []\n    for i, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n        print(f'**************** FOLD {i+1} ****************')\n        X_train, X_val = X[train_idx], X[val_idx]\n        y_train, y_val = y.values[train_idx], y.values[val_idx]\n\n        if is_weight:\n            # train weight\n            w_tr = 1 \/ pd.DataFrame(y_train).reset_index().groupby(0).count().values\n            w_tr = w_tr[y_train].ravel()\n            w_tr \/= w_tr.sum()\n            train_weight = list(w_tr)\n\n            # test weight\n            w_vl = 1 \/ pd.DataFrame(y_val).reset_index().groupby(0).count().values\n            w_vl = w_vl[y_val].ravel()\n            w_vl \/= w_vl.sum()\n            valid_weight = list(w_vl)\n        else:\n            train_weight = None\n            valid_weight = None\n\n        lgb_train = lgb.Dataset(X_train, label=y_train, weight=train_weight)\n        lgb_val = lgb.Dataset(X_val, label=y_val, weight=valid_weight)\n        \n        model = lgb.train(params,\n                      lgb_train,\n                      valid_names=[\"train\", \"valid\"],\n                      valid_sets=[lgb_train, lgb_val],\n                      num_boost_round=num_boost_round,\n                      early_stopping_rounds=early_stopping_rounds,\n                      verbose_eval=verbose_eval)\n\n        model_array.append(model)\n\n        # evaluation\n        oof_val = model.predict(X_val, num_iteration=model.best_iteration)\n        y_val_pred = np.argmax(oof_val, axis=1)\n        oof_train[val_idx] = y_val_pred\n        print(f'[FOLD {i+1}] OOF Accuracy: {accuracy_score(y_true=y_val, y_pred=y_val_pred):.5f}\\n')\n\n    print(f'[RESULT] Accuracy: {accuracy_score(y_true=y, y_pred=oof_train):.5f}\\n')\n    \n    print('\u6b63\u89e3\u30e9\u30d9\u30eb\u3068\u4e88\u6e2c\u30e9\u30d9\u30eb\u306e\u5206\u5e03\u30d7\u30ed\u30c3\u30c8\uff1a')\n    display_ture_pred(y, oof_train)\n    print('\\n')\n    \n    print('\u6df7\u540c\u884c\u5217\uff1a')\n    display_cmx(y, oof_train)\n    print('\\n')\n    \n    fi_df = lgb_get_feature_importance(model_array, features=features)\n    print('\u7279\u5fb4\u91cd\u8981\u5ea6\uff1a')\n    display_fi(fi_df)\n    print('\\n')","9076bb9e":"train = pd.read_csv(\"..\/input\/cdleyouth01\/df_train.csv\")","b9f19d58":"run_train(train, is_weight=True)","09234626":"train.describe()","1d0d9be0":"train_time_drop = train.copy()\ntrain_time_drop = train_time_drop.drop('TIME', axis=1)\nrun_train(train_time_drop)","08428dfc":"train_log = train.copy()\n# log\u8a08\u7b97\u3067\u30de\u30a4\u30ca\u30b9\u3092\u5165\u308c\u308b\u3068\u8a08\u7b97\u3067\u304d\u306a\u3044\u306e\u3067\u3001EEG\u306e\u6700\u5c0f\u5024\u304c\u30bc\u30ed\u306b\u306a\u308b\u3088\u3046\u306b\u8db3\u3057\u7b97\u3057\u3066\u3044\u307e\u3059\u3002\nEEG_min = train_log['EEG'].min()\ntrain_log['EEG'] += abs(EEG_min)\n\nfor col in ['SL', 'EEG', 'CIRCLUATION']:\n    new_colname = 'log_' + col\n    train_log[new_colname] = np.log1p(train_log[col])","c7047ed5":"run_train(train_log)","2a17f5fe":"from sklearn.preprocessing import PowerTransformer\ntransformer = PowerTransformer(method='yeo-johnson')\n\ncols = ['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']\ntrain_yeo = transformer.fit_transform(train[cols])\ntrain_yeo = pd.DataFrame(train_yeo, columns=cols)\ntrain_yeo[INDEX] = train[INDEX].values\ntrain_yeo[TARGET] = train[TARGET].values","3b5aecd0":"run_train(train_yeo)","89b20593":"from sklearn.preprocessing import QuantileTransformer\ntransformer = QuantileTransformer(n_quantiles=10000, output_distribution='normal', random_state=SEED)\n\ncols = ['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']\ntrain_gauss = transformer.fit_transform(train[cols])\ntrain_gauss = pd.DataFrame(train_gauss, columns=cols)\ntrain_gauss[INDEX] = train[INDEX].values\ntrain_gauss[TARGET] = train[TARGET].values","9a700d72":"run_train(train_gauss)","9317ef9e":"train_exp = train.copy()\nfor col in ['TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']:\n    new_colname = 'exp2_' + col\n    train_exp[new_colname] = train_exp[col] ** 2","acf1332b":"run_train(train_exp)","df8fd728":"train_arith = train.copy()\nfor (col1, col2) in itertools.combinations(['SL', 'EEG', 'HR'], 2):\n    new_colname = col1 + '_+_' + col2\n    train_arith[new_colname] = train_arith[col1] + train_arith[col2]\n    new_colname = col1 + '_-_' + col2\n    train_arith[new_colname] = train_arith[col1] - train_arith[col2]\n    new_colname = col1 + '_*_' + col2\n    train_arith[new_colname] = train_arith[col1] * train_arith[col2]\n    new_colname = col1 + '_\/_' + col2\n    train_arith[new_colname] = train_arith[col1] \/ (train_arith[col2] + 1e-8) # 0\u9664\u7b97\u9632\u6b62\n    \n# \u4eca\u56de\u4f55\u3082\u8003\u3048\u3066\u307e\u305b\u3093\u304c\u3001\u5272\u308a\u7b97\u306b\u95a2\u3057\u3066\u306f\u8a08\u7b97\u9806\u5e8f\u3067\u610f\u5473\u304c\u5909\u308f\u3063\u3066\u304f\u308b\u306e\u3067\u6c17\u3092\u3064\u3051\u305f\u307b\u3046\u304c\u3044\u3044\u3067\u3059\u3002","6f9c4427":"run_train(train_arith)","695fb5f4":"def create_stat_feature(df, cols: list):\n    for col in cols:\n        # min, max, std, mean, median\n        new_colname = f'{col}_min_ratio'\n        df[new_colname] = df[col].map(lambda x: x \/ (np.min(x) + 1e-8))\n        new_colname = f'{col}_max_ratio'\n        df[new_colname] = df[col].map(lambda x: x \/ (np.max(x) + 1e-8))\n        new_colname = f'{col}_std_ratio'\n        df[new_colname] = df[col].map(lambda x: x \/ (np.std(x) + 1e-8))\n        new_colname = f'{col}_mean_ratio'\n        df[new_colname] = df[col].map(lambda x: x \/ (np.mean(x) + 1e-8))\n        new_colname = f'{col}_median_ratio'\n        df[new_colname] = df[col].map(lambda x: x \/ (np.median(x) + 1e-8))\n        \n    return df","22f44d8e":"train_stat = train.copy()\ntrain_stat = create_stat_feature(train_stat, cols=['SL', 'BP', 'CIRCLUATION'])","1df84078":"run_train(train_stat)","0d37c72c":"train_bin = train.copy()\n# log\u8a08\u7b97\u3067\u30de\u30a4\u30ca\u30b9\u3092\u5165\u308c\u308b\u3068\u8a08\u7b97\u3067\u304d\u306a\u3044\u306e\u3067\u3001EEG\u306e\u6700\u5c0f\u5024\u304c\u30bc\u30ed\u306b\u306a\u308b\u3088\u3046\u306b\u8db3\u3057\u7b97\u3057\u3066\u3044\u307e\u3059\u3002\nEEG_min = train_bin['EEG'].min()\ntrain_bin['EEG'] += abs(EEG_min)\n\nfor col in ['SL', 'EEG', 'CIRCLUATION']:\n    new_colname = 'log_' + col\n    train_bin[new_colname] = np.log1p(train_bin[col])","d0f020fb":"train_bin","0f088349":"sns.histplot(train_bin, x='log_SL', hue='ACTIVITY')","ec59237a":"sns.histplot(train_bin, x='log_CIRCLUATION', hue='ACTIVITY')","c2bd9534":"train_bin['log_SL_bins'] = pd.cut(train_bin['log_SL'], bins=4, labels=False)\ntrain_bin['log_EEG_bins'] = pd.cut(train_bin['log_EEG'], bins=4, labels=False)\ntrain_bin['log_CIRCLUATION_bins'] = pd.cut(train_bin['log_CIRCLUATION'], bins=4, labels=False)","2b621fcc":"run_train(train_bin)","c1eb10e3":"train_clip = train.copy()\nfor col in ['SL', 'EEG', 'CIRCLUATION']:\n    p01 = train_clip[col].quantile(0.01)\n    p99 = train_clip[col].quantile(0.99)\n    new_colname = col + '_clipped'\n    train_clip[new_colname] = train_clip[col].clip(p01, p99) # \u4e0a\u754c\u30fb\u4e0b\u754c1%\u3092\u30af\u30ea\u30c3\u30d7","85d932aa":"run_train(train_clip)","1fc6f84f":"train","859e46fb":"train_ = train.copy()\nfor col in ['TIME', 'SL', 'EEG']:\n    new_colname1 = col + '_int'\n    new_colname2 = col + '_float'\n    train_[new_colname2] = train_[col].map(lambda x: math.modf(x)[0])\n    train_[new_colname1] = train_[col].map(lambda x: math.modf(x)[1])","b66fbe6b":"run_train(train_)","35152ae3":"train_ = train.copy()\nfor col in ['SL']:\n    new_colname1 = col + '_int'\n    new_colname2 = col + '_float'\n    train_[new_colname2] = train_[col].map(lambda x: math.modf(x)[0])\n    train_[new_colname1] = train_[col].map(lambda x: math.modf(x)[1])\nrun_train(train_)","864cb308":"def aggregations(df: pd.DataFrame, cat_features: list, num_features: list) -> pd.DataFrame:\n    for ccol in cat_features:\n        for ncol in num_features:\n\n            # min, max, std, mean, median, skew, kurt\n            new_colname = f'{ccol}_groupby_{ncol}_min'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('min')\n            new_colname = f'{ccol}_groupby_{ncol}_max'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('max')\n            new_colname = f'{ccol}_groupby_{ncol}_std'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('std')\n            new_colname = f'{ccol}_groupby_{ncol}_mean'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('mean')\n            new_colname = f'{ccol}_groupby_{ncol}_median'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('median')\n            new_colname = f'{ccol}_groupby_{ncol}_skew'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('skew')\n            new_colname = f'{ccol}_groupby_{ncol}_kurt'\n            tmp = df.groupby(ccol)[ncol].apply(pd.DataFrame.kurt).to_dict()\n            df[new_colname] = df[ccol].map(tmp)\n\n            # Q1, Q3\n            q25_map = df.groupby(ccol)[ncol].quantile(0.25)\n            q75_map = df.groupby(ccol)[ncol].quantile(0.75)\n            # IQ, range, ratio\n            new_colname = f'{ccol}_{ncol}_iqr'\n            df[new_colname] = df[ccol].map(q75_map) - df[ccol].map(q25_map)\n            new_colname = f'{ccol}_{ncol}_iqr_ratio'\n            df[new_colname] = df[ccol].map(q75_map) \/ (df[ccol].map(q25_map) + 1e-8)\n\n            # min-max range, ratio\n            new_colname = f'{ccol}_{ncol}_range'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('max') - df.groupby(ccol)[ncol].transform('min')\n            new_colname = f'{ccol}_{ncol}_range_ratio'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('max') \/ (df.groupby(ccol)[ncol].transform('min') + 1e-8)\n\n            # mean variance\n            new_colname = f'{ccol}_{ncol}_mean_var'\n            df[new_colname] = df.groupby(ccol)[ncol].transform('std') \/ (df.groupby(ccol)[ncol].transform('mean') + 1e-8)\n\n            # mean absolute deviation\n            new_colname = f'{ccol}_{ncol}_mean_absolute_deviation'\n            df[new_colname] = df.groupby(ccol)[ncol].apply(lambda x: np.abs(x - x.mean()))\n\n            # median absolute deviation\n            new_colname = f'{ccol}_{ncol}_median_absolute_deviation'\n            df[new_colname] = df.groupby(ccol)[ncol].apply(lambda x: np.abs(x - x.median()))\n\n            # diff, ratio\n            new_colname = f'{ccol}_{ncol}_diff'\n            df[new_colname] = df.groupby(ccol)[ncol].apply(lambda x: x - x.mean())\n            new_colname = f'{ccol}_{ncol}_ratio'\n            df[new_colname] = df.groupby(ccol)[ncol].apply(lambda x: x \/ (x.mean() + 1e-8))\n\n            # z-score\n            new_colname = f'{ccol}_{ncol}_zscore'\n            df[new_colname] = df.groupby(ccol)[ncol].apply(lambda x: (x - x.mean()) \/ (x.std() + 1e-8))\n\n            # high low ratio\n            new_colname = f'{ccol}_{ncol}_hl_ratio'\n            _mean = df.groupby(ccol)[ncol].transform('mean')\n            high_map = df[df[ncol] >= _mean].groupby(ccol)[ncol].sum()\n            low_map = df[df[ncol] < _mean].groupby(ccol)[ncol].sum()\n            df[new_colname] = df[ccol].map(high_map \/ (low_map + 1e-8))\n\n    return df","1e4514ef":"train_bin_agg = train_bin.copy()\ntrain_bin_agg = aggregations(df=train_bin_agg, \n                             cat_features=['log_SL_bins', 'log_EEG_bins', 'log_CIRCLUATION_bins'],\n                             num_features=['SL', 'BP', 'CIRCLUATION'])","a373b3b9":"run_train(train_bin_agg)","86f1918f":"def feature_engineering(df):\n    # log\n    EEG_min = df['EEG'].min()\n    df['EEG'] += abs(EEG_min)\n\n    for col in ['SL', 'EEG', 'CIRCLUATION']:\n        new_colname = 'log_' + col\n        df[new_colname] = np.log1p(df[col])\n\n    # binning\n    df['log_SL_bins'] = pd.cut(df['log_SL'], bins=4, labels=False)\n    df['log_EEG_bins'] = pd.cut(df['log_EEG'], bins=4, labels=False)\n    df['log_CIRCLUATION_bins'] = pd.cut(df['log_CIRCLUATION'], bins=4, labels=False)\n\n\n    # cliping\n    for col in ['SL', 'EEG', 'CIRCLUATION']:\n        p01 = df[col].quantile(0.01)\n        p99 = df[col].quantile(0.99)\n        new_colname = col + '_clipped'\n        df[new_colname] = df[col].clip(p01, p99) # \u4e0a\u754c\u30fb\u4e0b\u754c1%\u3092\u30af\u30ea\u30c3\u30d7\n        \n    # \u7d71\u8a08\u91cf\u7cfb\n    df = create_stat_feature(df, cols=['SL', 'BP', 'CIRCLUATION'])\n\n    # \u6841\u5206\u96e2\n    df['SL_float'] = df['SL'].map(lambda x: math.modf(x)[0])\n    df['SL_int'] = df['SL'].map(lambda x: math.modf(x)[1])\n\n    # aggregation\n    df = aggregations(df=df, \n                      cat_features=['log_SL_bins', 'log_EEG_bins', 'log_CIRCLUATION_bins'],\n                      num_features=['SL', 'BP', 'CIRCLUATION'])\n    \n    return df","f55090d2":"train = pd.read_csv(\"..\/input\/cdleyouth01\/df_train.csv\")\ntest = pd.read_csv(\"..\/input\/cdleyouth01\/df_test.csv\")\n# train + test\ndata = pd.concat([train, test], axis=0).reset_index(drop=True)\ndata = feature_engineering(data)","fe4a739d":"train = data[data[TARGET].isnull()==False].reset_index(drop=True)\ntest = data[data[TARGET].isnull()==True].reset_index(drop=True)\n\n\nX = train.drop([INDEX, TARGET], axis=1)\ny = train[TARGET].astype('int')\ntest_id = test[INDEX].values\ntest = test.drop([INDEX, TARGET], axis=1)\n\n# \u7d71\u8a08\u91cf\u8a08\u7b97\u306e\u904e\u7a0b\u3067\u3067\u304d\u305f\u6b20\u640d\u5024\u306a\u3069\u306e\u88dc\u5b8c\uff08\u4eca\u56de\u306f-999\u3067\u57cb\u3081\u307e\u3057\u305f\uff09\nX = X.replace([np.inf, -np.inf], np.nan).fillna(-999)\ntest = test.replace([np.inf, -np.inf], np.nan).fillna(-999)\n\nfeatures = list(X.columns)\n\nseed_everything(seed=SEED)\nfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)","8cdd268f":"oof_train = np.zeros(len(X))\nmodel_array = []\nfor i, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n    print(f'**************** FOLD {i+1} ****************')\n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y.values[train_idx], y.values[val_idx]\n\n    # train weight\n    w_tr = 1 \/ pd.DataFrame(y_train).reset_index().groupby(0).count().values\n    w_tr = w_tr[y_train].ravel()\n    w_tr \/= w_tr.sum()\n    train_weight = list(w_tr)\n\n    # test weight\n    w_vl = 1 \/ pd.DataFrame(y_val).reset_index().groupby(0).count().values\n    w_vl = w_vl[y_val].ravel()\n    w_vl \/= w_vl.sum()\n    valid_weight = list(w_vl)\n\n    lgb_train = lgb.Dataset(X_train, label=y_train, weight=train_weight)\n    lgb_val = lgb.Dataset(X_val, label=y_val, weight=valid_weight)\n    \n    model = lgb.train(params,\n                      lgb_train,\n                      valid_names=[\"train\", \"valid\"],\n                      valid_sets=[lgb_train, lgb_val],\n                      num_boost_round=num_boost_round,\n                      early_stopping_rounds=early_stopping_rounds,\n                      verbose_eval=verbose_eval)\n\n    model_array.append(model)\n\n    # evaluation\n    oof_val = model.predict(X_val, num_iteration=model.best_iteration)\n    y_val_pred = np.argmax(oof_val, axis=1)\n    oof_train[val_idx] = y_val_pred\n    print(f'[FOLD {i+1}] OOF Accuracy: {accuracy_score(y_true=y_val, y_pred=y_val_pred):.5f}\\n')\n\n    # prediction\n    if i == 0:\n        preds = model.predict(test, num_iteration=model.best_iteration)\n    else:\n        preds += model.predict(test, num_iteration=model.best_iteration)\n        \nprint(f'[RESULT] Accuracy: {accuracy_score(y_true=y, y_pred=oof_train):.5f}')\n\npreds = preds \/ NFOLDS\ntest_pred = np.argmax(preds, axis=1)","5cf26947":"display_ture_pred(y, oof_train)","c67118f3":"display_cmx(y, oof_train)","b2a90c73":"fi_df = lgb_get_feature_importance(model_array, features)\ndisplay_fi(fi_df)","3021ec40":"sub = pd.DataFrame([])\nsub[INDEX] = test_id\nsub[TARGET] = test_pred\nsub.to_csv('submission.csv', index=False)","8fe8e5ee":"\u7cbe\u5ea6\u306f\u307b\u3068\u3093\u3069\u5909\u308f\u308a\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u5165\u308c\u305f\u307b\u3046\u304c\u3044\u3044\u306e\u304b\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u3002  \n\u7279\u5fb4\u91cd\u8981\u5ea6\u3092\u898b\u3066\u307f\u3066\u3082\u3001\u3044\u3044\u7279\u5fb4\u91cf\u304c\u4f5c\u308c\u305f\u3068\u306f\u601d\u3048\u307e\u305b\u3093\u3002","d412225b":"\u7cbe\u5ea6\u4e0a\u304c\u308a\u307e\u3057\u305f\u306d\u3002","66b56ffd":"\u7cbe\u5ea6\u306f\u308f\u305a\u304b\u306b\u60aa\u5316\u3002","8317f5b4":"\u3067\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u51e6\u7406\u3092\u9069\u7528\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002","9790355f":"## 8. binning + aggregation\n\u30d3\u30cb\u30f3\u30b0\u51e6\u7406\u306b\u3088\u3063\u3066\u30af\u30e9\u30b9\u5206\u3051\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u96c6\u7d04\u7279\u5fb4\u91cf\u3092\u4f5c\u308b\u3002","15be3d39":"## 7. \u6841\u5206\u96e2\n\u4f8b\u3048\u3070\u3001\u4e8c\u6841\u306e\u6570\u5b57\u3092\u5341\u306e\u4f4d\u306e\u6570\u3068\u4e00\u306e\u4f4d\u306e\u6570\u305d\u308c\u305e\u308c\u306b\u5206\u3051\u3066\u305d\u308c\u3092\u7279\u5fb4\u91cf\u3068\u3059\u308b\u51e6\u7406\u3067\u3059\u3002","7fba8d8c":"\u3053\u3053\u306b\u66f8\u3044\u3066\u304a\u3044\u3066\u306a\u3093\u3067\u3059\u304c\u3001\u9577\u304f\u306a\u308a\u305d\u3046\u306a\u306e\u3067\u5225\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306b\u66f8\u304d\u307e\u3059\u3002","b40bde0a":"\u307b\u307c\u5909\u5316\u306a\u3057","45152621":"\u4f7f\u7528\u3059\u308b\u7279\u5fb4\u91cf\u306f\u4e0a\u8ff0\u3057\u305f\u4e2d\u3067\u3001\u6709\u529b\u305d\u3046\u306a\u306e\u3092\u3044\u304f\u3064\u304b\u9078\u3073\u307e\u3057\u305f\u3002","1e8ff9c7":"## 2. \u6570\u5024\u5909\u63db\n\u3044\u304f\u3064\u304b\u306e\u6570\u5024\u5909\u63db\u3092\u7528\u3044\u3066\u7cbe\u5ea6\u6bd4\u8f03\u3092\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n### 2.1. \u5bfe\u6570\u5909\u63db\n\u4eca\u56de\u7279\u306b\u6700\u5c0f\u6700\u5927\u306e\u4e56\u96e2\u306e\u6fc0\u3057\u3044SL\u3001EEG\u3001CIRCULATION\u306b\u5bfe\u3057\u3066\u9069\u7528\u3057\u307e\u3059\u3002","f7ee59f5":"\u304a\u304a\u3001\u7cbe\u5ea6\u4e0a\u304c\u308a\u307e\u3057\u305f\u306d\u3002","2d8cc9f3":"## \u5b66\u7fd2\u5468\u308a\u306e\u6e96\u5099\n\u4eca\u56de\u524d\u51e6\u7406\u306b\u6ce8\u529b\u3057\u305f\u3044\u306e\u3067\u3001\u5b66\u7fd2\u5468\u308a\u306f\u9069\u5f53\u306b\u307e\u3068\u3081\u3066\u304a\u304d\u307e\u3059\u3002\u5b66\u7fd2\u90e8\u5206\u306b\u95a2\u3057\u3066\u306f\u524d\u56de\u306e\u30b3\u30fc\u30c9\u3068\u540c\u4e00\u3067\u3059\u3002","a8f1c404":"SL\u306e\u5c11\u6570\u90e8\u5206\u304c\u4f7f\u3048\u308b\u304b\u3082\u3057\u308c\u306a\u3044\uff01  \n\u3084\u3063\u3066\u307f\u307e\u3059\u3002","9033e587":"# \u524d\u51e6\u7406\u306a\u3057\u306e\u30e2\u30c7\u30eb(\u524d\u56de\u306e\u30e2\u30c7\u30eb)","6ea3b87f":"## 8. \u30dc\u30e9\u30f3\u30c6\u30a3\u30a2\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n\u3053\u306e\u30b3\u30f3\u30da\u30aa\u30ea\u30b8\u30ca\u30eb\u306e\u7279\u5fb4\u91cf\u4f5c\u6210\u306b\u306a\u308a\u307e\u3059\u3002  \n\u767a\u60f3\u3068\u3057\u3066\u306f\u300114\u4eba\u306e\u30dc\u30e9\u30f3\u30c6\u30a3\u30a2\u3092\u7279\u5b9a\u3059\u308c\u3070\u3088\u308a\u7d30\u304b\u3044\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u304c\u7d44\u3081\u307e\u3059\u3057\u3001\u5404\u500b\u4eba\u306e\u3082\u3064\u751f\u4f53\u60c5\u5831\u3092\u5f15\u304d\u51fa\u305b\u308b\u306e\u3067\u306f\u3068\u601d\u3063\u305f\u304b\u3089\u3067\u3059\u3002  \n\u57fa\u672c\u7684\u306a\u7279\u5fb4\u91cf\u4f5c\u6210\u304c\u7d42\u308f\u3063\u305f\u3042\u3068\u306f\u3053\u306e\u3088\u3046\u306b\u3057\u3066\u3001\u4e0e\u3048\u3089\u308c\u305f\u8ab2\u984c\u306b\u5bfe\u3059\u308b\u72ec\u81ea\u306e\u4eee\u8aac\u306b\u57fa\u3065\u3044\u3066\u7279\u5fb4\u91cf\u3092\u3064\u304f\u3063\u305f\u308a\u3057\u307e\u3059\u3002  \n\u81ea\u5206\u3082\u3053\u306e\u30c7\u30fc\u30bf\u306b\u95a2\u3059\u308b\u77e5\u8b58\u306f\u3042\u308a\u307e\u305b\u3093\u304c\u3001\u30b0\u30b0\u3063\u305f\u308a\u3057\u3066\u306a\u3093\u3068\u304b\u3057\u3066\u6709\u529b\u306a\u60c5\u5831\u3092\u30c7\u30fc\u30bf\u304b\u3089\u5f15\u304d\u51fa\u305b\u306a\u3044\u304b\u8003\u3048\u3066\u3044\u304f\u3064\u3082\u308a\u3067\u3059\u3002\u305c\u3072\u8003\u3048\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002","88db2113":"# \u524d\u56de\u8003\u3048\u305f\u524d\u51e6\u7406\u30fb\u7279\u5fb4\u91cf\u4f5c\u6210\u30a2\u30a4\u30c7\u30a2\n- TIME\u30ab\u30e9\u30e0\u306e\u6271\u3044\n- \u30c7\u30fc\u30bf\u751f\u6210\u306e\u969b\u306b\u53c2\u52a0\u3057\u305f\u30dc\u30e9\u30f3\u30c6\u30a3\u30a214\u4eba\u306e\u3056\u3063\u304f\u308a\u3068\u3057\u305f\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\uff08\u3067\u304d\u305f\u3089\uff09\n- HR\u3068CIRCULATION\u30da\u30a2\u306b\u306a\u3063\u3066\u3044\u308b -> \u30dc\u30e9\u30f3\u30c6\u30a3\u30a2\u306e\u5404\u500b\u4eba\u3092\u8868\u3057\u3066\u308b\uff1f\n- \u4e00\u822c\u7684\u306a\u7d71\u8a08\u91cf\uff1a\u5bfe\u6570\u30fb\u3079\u304d\u4e57\u30fbbinning\u30fbbinning + aggregation\u30fb\u56db\u5247\u6f14\u7b97\n- \u6570\u5024\u5909\u63db\uff1a\u5bfe\u6570\u5909\u63db\u30fb\u6a19\u6e96\u5316\u30fbbox-cox\u5909\u63db\u30fb\u30e9\u30f3\u30af\u30ac\u30a6\u30b9\u5909\u63db","71a4332f":"\u60aa\u5316\u3057\u3066\u3044\u307e\u3059\u3002TIME\u304c\u610f\u5473\u3042\u308b\u3082\u306e\u3068\u306f\u601d\u3048\u307e\u305b\u3093\u304c\u3001TIME\u304b\u3089\u4f55\u304b\u3057\u3089\u8aad\u307f\u53d6\u308c\u308b\u3082\u306e\u304c\u3042\u308b\u306e\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002","a301ea40":"## 5. \u7d71\u8a08\u91cf\u7cfb\n\u5404\u30ab\u30e9\u30e0\u306e\u6700\u5927\u30fb\u6700\u5c0f\u30fb\u6a19\u6e96\u504f\u5dee\u306a\u3069\u8a08\u7b97\u3057\u307e\u3059\u3002\u7b97\u51fa\u3055\u308c\u305f\u3082\u306e\u3067\u9664\u7b97\u306a\u3069\u3057\u307e\u3059\u3002","db4679ae":"\u7cbe\u5ea6\u306f\u82e5\u5e72\u60aa\u5316\u3002\u5f53\u305f\u308a\u524d\u3067\u3059\u304c\u3001\u7279\u5fb4\u91cd\u8981\u5ea6\u3092\u898b\u3066\u308f\u304b\u308b\u3068\u304a\u308a\u3001\u3082\u3068\u3082\u3068\u91cd\u8981\u5ea6\u304c\u9ad8\u304b\u3063\u305f\u7279\u5fb4\u91cf\u306b\u95a2\u9023\u3059\u308b\u7279\u5fb4\u91cf\u304c\u4e0a\u4f4d\u306b\u6765\u3066\u3044\u307e\u3059\u3002","a380b8f2":"### 2.2. Yeo-Johnson\u5909\u63db\n\u5192\u982d\u3067\u306fBox-Cox\u5909\u63db\u3068\u66f8\u304d\u307e\u3057\u305f\u304c\u3001sklearn\u3067\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u304c\u3053\u308c\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u3053\u3061\u3089\u306e\u5909\u63db\u3092\u9069\u7528\u3057\u307e\u3059\u3002\u3069\u3061\u3089\u3082\u3001\u51e6\u7406\u306e\u610f\u5473\u5408\u3044\u306f\u307b\u307c\u540c\u3058\u3067\u3059\u3002\u5404\u7279\u5fb4\u91cf\u3092\u5f37\u5f15\u306b\u6b63\u898f\u5206\u5e03\u306b\u5909\u63db\u3059\u308b\u3082\u306e\u306b\u306a\u308a\u307e\u3059\u3002LightGBM\u306ftree\u30e2\u30c7\u30eb\u306a\u306e\u3067\u3001\u6b63\u76f4\u3042\u307e\u308a\u610f\u5473\u304c\u3042\u308b\u3068\u306f\u601d\u3048\u307e\u305b\u3093\u304c\u591a\u5c11\u306e\u5909\u5316\u306f\u3042\u308b\u306f\u305a\u306a\u306e\u3067\u3001\u4e00\u5fdc\u898b\u3066\u307f\u307e\u3059\u3002****","e5109825":"## 4. \u56db\u5247\u6f14\u7b97\u7cfb\n\u9069\u5f53\u306a\u7279\u5fb4\u91cf\u540c\u58eb\u3067\u306e\u639b\u3051\u7b97\u30fb\u5272\u308a\u7b97\u30fb\u8db3\u3057\u7b97\u30fb\u5f15\u304d\u7b97\u3067\u3059\u3002\u305f\u3060\u3053\u306e\u65b9\u6cd5\u3067\u4f5c\u3089\u308c\u305f\u7279\u5fb4\u91cf\u306f\u3001\u5f53\u305f\u308a\u524d\u3067\u3059\u304c\u5143\u306e\u7279\u5fb4\u91cf\u306b\u5bfe\u3057\u3066\u76f8\u95a2\u304c\u5f37\u3044\u3082\u306e\u3068\u306a\u308a\u307e\u3059\u3002\u3053\u308c\u304b\u3089\u7279\u5fb4\u91cf\u4f5c\u6210\u3057\u3066\u3044\u304d\u307e\u3059\u304c\u3001\u500b\u4eba\u7684\u306b\u306f\u610f\u5473\u306e\u3042\u308b\u5834\u5408\u3092\u9664\u3044\u3066\u304a\u3059\u3059\u3081\u3067\u304d\u308b\u624b\u6cd5\u3067\u306f\u306a\u3044\u3067\u3059\u3002  \n\u610f\u5473\u3042\u308b\u5834\u5408\u3068\u3044\u3046\u306e\u306f\u4f8b\u3048\u3070\u3001\u3042\u308b\u7bb1\u306e\u7e26\u3068\u6a2a\u3001\u9ad8\u3055\u304c\u4e0e\u3048\u3089\u308c\u3066\u3044\u308b\u3068\u304d\u306b\u639b\u3051\u7b97\u3067\u305d\u306e\u7bb1\u306e\u4f53\u7a4d\u30fb\u5074\u9762\u7a4d\u30fb\u5e95\u9762\u7a4d\u306a\u3069\u3001\u305d\u306e\u7bb1\u306e\u60c5\u5831\u3092\u3088\u308a\u5897\u3084\u305b\u308b\u5834\u5408\u306a\u3069\u3067\u3059\u3002\u3053\u3046\u3044\u3046\u5834\u5408\u306b\u306f\u30c9\u30e1\u30a4\u30f3\u77e5\u8b58\u304c\u975e\u5e38\u306b\u91cd\u8981\u306b\u306a\u3063\u3066\u304d\u307e\u3059\u3002\n\n- SL\u30fb\u8840\u7cd6\u5024:\u8840\u6db2\u4e2d\u306e\u30d6\u30c9\u30a6\u7cd6\u306e\u91cf\u306e\u3053\u3068\n- EEG\u30fb\u8133\u6ce2\u306e\u4f55\u304b:\u52d5\u3057\u3066\u3044\u308b\u8133\u306e\u96fb\u6c17\u73fe\u8c61\u3092\u982d\u76ae\u4e0a\u306b\u304a\u3044\u305f\u96fb\u6975\u304b\u3089\u5c0e\u51fa\u3057\u3001\u3053\u308c\u3092\u8133\u6ce2\u8a08\u306b\u5897\u5e45\u8a18\u9332\u3057\u305f\u3082\u306e\n- BP\u30fb\u8840\u5727:\u304a\u305d\u3089\u304f\u6700\u9ad8\u3068\u6700\u4f4e\u306e\u5e73\u5747\u5024\u3002\u300c\u5fc3\u81d3\u304b\u3089\u51fa\u308b\u8840\u6d41\u91cf\uff58\u8840\u7ba1\u306e\u786c\u3055\u300d\u306b\u3088\u3063\u3066\u5c0e\u51fa\u3055\u308c\u308b\u3002\u30b9\u30c8\u30ec\u30b9\u3084\u74b0\u5883\u306b\u5de6\u53f3\u3055\u308c\u308b\u3002\u904b\u52d5\u3057\u305f\u308a\u3059\u308b\u3068\u5897\u52a0\n- HR\u30fb\u5fc3\u62cd\u6570:\u4e00\u5b9a\u306e\u6642\u9593\u5185\u306b\u5fc3\u81d3\u304c\u62cd\u52d5\u3059\u308b\u56de\u6570\u3002\u904b\u52d5\u3057\u305f\u308a\u3059\u308b\u3068\u5897\u52a0\n- CIRCULATION\u30fb\u5faa\u74b0\u8840\u6d41\u91cf:\u5fc3\u81d3\u304b\u3089\u51fa\u308b\u8840\u6d41\u91cf\u306b\u4f9d\u5b58\u3002\n\n\u3061\u3087\u3063\u3068\u8abf\u3079\u3066\u307f\u307e\u3057\u305f\u304c\u3001\u5168\u304f\u308f\u304b\u3089\u306a\u3044\u306e\u3067\u9069\u5f53\u306b\u6f14\u7b97\u3057\u307e\u3059\u3002","901b9823":"# \u3053\u306eNoteBook\u3067\u306fLightGBM\u30e2\u30c7\u30eb\u306b\u5bfe\u3057\u3066\u69d8\u3005\u306a\u524d\u51e6\u7406\u3092\u65bd\u3057\u305f\u30c7\u30fc\u30bf\u3067\u7cbe\u5ea6\u6bd4\u8f03\u3057\u3066\u307f\u307e\u3059\n\u203b\u4e88\u6e2c\u306f\u51fa\u3057\u307e\u305b\u3093","1ed46831":"## 1. \u524d\u51e6\u7406\n\u3053\u3053\u3067\u306f\u3001\u30ce\u30a4\u30ba\u306b\u306a\u308a\u305d\u3046\u306a\u30c7\u30fc\u30bf\u306a\u3069\u3092\u524a\u9664\u30fb\u5909\u63db\u3057\u3066\u3044\u304d\u307e\u3059\u3002","ccb84f65":"### 2.3. \u30e9\u30f3\u30af\u30ac\u30a6\u30b9\u5909\u63db\nyeo-johnson\u306e\u6b63\u898f\u5206\u5e03\u3078\u306e\u8fd1\u4f3c\u306e\u624b\u6cd5\u304c\u7570\u306a\u308b\u7248\u3067\u3059\u3002\u4e00\u822c\u306b\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30e2\u30c7\u30eb\u306b\u6709\u52b9\u3089\u3057\u3044\u3067\u3059\u304c\u3001\u3084\u3063\u3066\u307f\u307e\u3059\u3002","cfc5b20f":"\u8840\u5727\u306e\u6700\u5c0f\u5024\u304c0(\u6b7b\u3093\u3067\u308b...)\u3060\u3063\u305f\u308a\u3001\u5faa\u74b0\u8840\u6d41\u91cf\u306e\u6700\u5c0f\u304c5\u3060\u3063\u305f\u308a\u3068\u7b97\u51fa\u57fa\u6e96\u304c\u5168\u304f\u308f\u304b\u3089\u306a\u3044\u306e\u3067\u3001\u4eca\u306f\u89e6\u308c\u306a\u3044\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002\n\u4eca\u5f8c\u8b70\u8ad6\u3057\u307e\u3057\u3087\u3046\uff01  \n\u3068\u308a\u3042\u3048\u305a\u3001TIME\u3092\u524a\u9664\u3057\u305f\u5834\u5408\u3060\u3051\u3092\u898b\u3066\u307f\u307e\u3059\u3002","97ce0f27":"## 6. binning clipping\n- binning: \u9023\u7d9a\u5024\u3092\u4efb\u610f\u306e\u5883\u754c\u5024\u3067\u533a\u5207\u308a\u30ab\u30c6\u30b4\u30ea\u5206\u3051\u3057\u3066\u96e2\u6563\u5024\u306b\u5909\u63db\u3059\u308b\u51e6\u7406\u3002\n- clipping: \u5024\u3092\u4efb\u610f\u306e\u6700\u5927\u30fb\u6700\u5c0f\u306b\u53ce\u3081\u3066\u51e6\u7406\n\n\u4eca\u56de\u30d3\u30cb\u30f3\u30b0\u3059\u308b\u306b\u3042\u305f\u3063\u3066\u3001\u5bfe\u6570\u5909\u63db\u3057\u305f\u5024\u306b\u5bfe\u3057\u3066\u884c\u3046\u3053\u3068\u306b\u3057\u307e\u3059\u3002\u7406\u7531\u3068\u3057\u3066\u306f\u3001\u5bfe\u6570\u3068\u3063\u305f\u307b\u3046\u304c\u6570\u5024\u9593\u306e\u5dee\u304c\u9855\u8457\u306b\u306a\u308b\u304b\u3089\u3067\u3059\u3002","061d2cdb":"# \u524d\u56de\u63d0\u51fa\u3057\u305f\u30e2\u30c7\u30eb\n- \u524d\u51e6\u7406\u306a\u3057\u3067ID\u3068ACTIVITY\u9664\u3044\u305f\u30ab\u30e9\u30e0\u5168\u3066\u3092\u4f7f\u7528\n- \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306fLightGBM\uff08\u30af\u30e9\u30b9\u30a6\u30a7\u30a4\u30c8\u4f7f\u7528\uff09\n- \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306e\u5207\u308a\u65b9\u306fStratifiedKfold\n- \u624b\u5143\u306e\u30b9\u30b3\u30a2\uff08CV\u30b9\u30b3\u30a2\uff09\u306f**0.73725**\n- \u30ea\u30fc\u30c0\u30fc\u30dc\u30fc\u30c9\u30b9\u30b3\u30a2\uff08LB\u30b9\u30b3\u30a2\uff09\u306f**0.84662**\n\nCV\/LB\u30b9\u30b3\u30a2\u306b\u3060\u3044\u3076\u4e56\u96e2\u304c\u3042\u308b\u306e\u3067\u3001\u3082\u3057\u304b\u3057\u305f\u3089\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306e\u5207\u308a\u65b9\u5909\u3048\u305f\u307b\u3046\u304c\u3044\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002  \n\u30e2\u30c7\u30eb\u3092\u8a55\u4fa1\u306e\u4ed5\u65b9\u306b\u554f\u984c\u304c\u3042\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3067\u3059\u3002\u305f\u3060\u4eca\u5f8c\u63d0\u51fa\u3057\u3066\u3044\u304f\u4e2d\u3067\u3001\u624b\u5143\u306e\u30b9\u30b3\u30a2\u3068LB\u30b9\u30b3\u30a2\u306b\u76f8\u95a2\u304c\u3042\u308b\u3088\u3046\u306a\u3089\u305d\u306e\u9650\u308a\u3067\u306f\u306a\u3044\u3067\u3059\u3002","54e12664":"# \u524d\u51e6\u7406\uff0b\u7279\u5fb4\u91cf\u4f5c\u6210\n1. \u524d\u51e6\u7406\n2. \u6570\u5024\u5909\u63db\n3. \u3079\u304d\u4e57\n4. \u56db\u5247\u6f14\u7b97\u7cfb\n5. \u7d71\u8a08\u91cf\u7cfb\n6. binning\u30fbclipping\n7. \u6841\u5206\u96e2\n8. binning + aggregation\n9. \u30dc\u30e9\u30f3\u30c6\u30a3\u30a2\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0","d2cad25b":"\u307b\u307c\u5909\u5316\u306a\u3057\u3067\u3059\u3002","1d419c00":"# \u3053\u3053\u307e\u3067\u3067\u4f5c\u3063\u305f\u7279\u5fb4\u91cf\u3063\u3066\u3069\u3046\u306a\u306e\uff1f\n\u4e00\u822c\u7684\u306a\u7279\u5fb4\u91cf\u3092\u4f5c\u6210\u3057\u3066\u304d\u307e\u3057\u305f\u3002  \n\u624b\u5143\u3067\u306f\u78ba\u304b\u306b\u7cbe\u5ea6\u5411\u4e0a\u3067\u304d\u3066\u3044\u308b\u3063\u307d\u3044\u3067\u3059\u304c\u3001\u5b9f\u969b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u306f\u3069\u3046\u306a\u3093\u3067\u3057\u3087\u3046\u304b\u3002\u30b5\u30d6\u30df\u30c3\u30c8\u3057\u3066\u8a66\u3057\u3066\u307f\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002  \n\u3053\u3053\u3067\u3001\u624b\u5143\u304c\u5411\u4e0a\u3057\u3066\u3044\u308b\u306e\u306bLB\u30b9\u30b3\u30a2\u304c\u843d\u3061\u3066\u3057\u307e\u3063\u3066\u3044\u308b\u3068\u306a\u308b\u3068\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306e\u5207\u308a\u65b9\u304b\u3089\u898b\u76f4\u3059\u5fc5\u8981\u51fa\u3066\u304f\u308b\u306e\u3067\u3001\u4e0a\u304c\u3063\u3066\u3066\u307b\u3057\u3044\u3068\u3053\u308d\u3067\u3059\u3002  \n\u3067\u306f\u3001\u3084\u3063\u3066\u3044\u304d\u307e\u3059\u3002","b7144b69":"\u7cbe\u5ea6\u5411\u4e0a\u3057\u307e\u3057\u305f\u306d\u3002\u30ce\u30a4\u30ba\u306e\u3042\u308b\u7279\u5fb4\u91cf\u3092\u524a\u9664\u3059\u308b\u3053\u3068\u3067\u3001\u7cbe\u5ea6\u5411\u4e0a\u304c\u3067\u304d\u305f\u308a\u306f\u3057\u307e\u3059\u304c(\u6841\u5206\u96e2\u306e\u969b\u306e\u3084\u3064)\u3053\u3053\u307e\u3067\u591a\u3044\u3068\u4f55\u304c\u60aa\u3044\u306e\u304b\u308f\u304b\u308a\u307e\u305b\u3093\u3002  \n\u5b9f\u306f\u3001\u7279\u5fb4\u91cf\u9078\u629e\u306b\u95a2\u3057\u3066\u306f\u3044\u304f\u3064\u304b\u306e\u624b\u6cd5\u304c\u63d0\u6848\u3055\u308c\u3066\u3044\u307e\u3059\u3002[\u3053\u3061\u3089](https:\/\/qiita.com\/shimopino\/items\/5fee7504c7acf044a521)\u3067\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u898b\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002","45dc31a8":"## 3. \u3079\u304d\u4e57\n\u8a00\u8449\u901a\u308a\u3001\u3079\u304d\u4e57\u3057\u305f\u3082\u306e\u3067\u3059\u3002\u4eca\u56de\u306f2\u4e57\u3057\u307e\u3059\u3002  \n\u305f\u3060\u3053\u306e\u65b9\u6cd5\u3067\u4f5c\u3089\u308c\u305f\u7279\u5fb4\u91cf\u306f\u3001\u5f53\u305f\u308a\u524d\u3067\u3059\u304c\u5143\u306e\u7279\u5fb4\u91cf\u306b\u5bfe\u3057\u3066\u76f8\u95a2\u304c\u5f37\u3044\u3082\u306e\u3068\u306a\u308a\u307e\u3059\u3002\u3053\u308c\u304b\u3089\u7279\u5fb4\u91cf\u4f5c\u6210\u3057\u3066\u3044\u304d\u307e\u3059\u304c\u3001\u500b\u4eba\u7684\u306b\u306f\u610f\u5473\u306e\u3042\u308b\u5834\u5408\u3092\u9664\u3044\u3066\u304a\u3059\u3059\u3081\u3067\u304d\u308b\u624b\u6cd5\u3067\u306f\u306a\u3044\u3067\u3059\u3002","3c254615":"\u7279\u5fb4\u91cd\u8981\u5ea60\uff08\u7b11\uff09\u7121\u8996\u3055\u308c\u3066\u307e\u3059\u3002"}}