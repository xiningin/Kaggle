{"cell_type":{"6b5e4ed7":"code","4a00fb6b":"code","0b105408":"code","9416f4bc":"code","124f3139":"code","3d82f328":"code","ba1b30b1":"code","a3d2a31e":"code","773e123e":"code","22778a04":"code","7cb231d7":"code","d0131eb9":"code","6a956c38":"code","407e9be8":"code","e270b6c6":"code","d5c37bf5":"code","f00f1d68":"code","1f8d67b6":"code","9d9e4219":"code","6b7207e9":"code","0b23633f":"code","aafd937c":"code","50c6b193":"code","b3ca9ddc":"code","9cf9cd93":"code","b45e0933":"code","0f263795":"markdown","0c6eb87c":"markdown","6da54920":"markdown","cc8b6280":"markdown","ad8ce908":"markdown","2ccb545b":"markdown","3e791060":"markdown"},"source":{"6b5e4ed7":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcSHb_BRaRtfYTn1h1zUpnSQDANmFqHyH2fl-It_13KOfAdvRzse&usqp=CAU',width=400,height=400)","4a00fb6b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b105408":"tf.__version__","9416f4bc":"ls ..\/input\/hackathon\/task_1-google_search_txt_files_v2\/MG\/","124f3139":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTQKT7Z4u-AksusuZKTm1vIVNtqOOJDNNpmCp6vzCS9CamwFj0J&usqp=CAU',width=400,height=400)","3d82f328":"path_to_file = '..\/input\/hackathon\/task_1-google_search_txt_files_v2\/MG\/Madagascar-fr-result-24.txt'","ba1b30b1":"text = open(path_to_file, 'r',encoding='utf-8',\n                 errors='ignore').read()","a3d2a31e":"print(text[:2500])","773e123e":"# The unique characters in the file\nvocab = sorted(set(text))\nprint(vocab)\nlen(vocab)","22778a04":"char_to_ind = {u:i for i, u in enumerate(vocab)}\nind_to_char = np.array(vocab)\nencoded_text = np.array([char_to_ind[c] for c in text])\nseq_len = 250\ntotal_num_seq = len(text)\/\/(seq_len+1)\ntotal_num_seq","7cb231d7":"# Create Training Sequences\nchar_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n\nsequences = char_dataset.batch(seq_len+1, drop_remainder=True)\n\ndef create_seq_targets(seq):\n    input_txt = seq[:-1]\n    target_txt = seq[1:]\n    return input_txt, target_txt\n\ndataset = sequences.map(create_seq_targets)","d0131eb9":"# Batch size\nbatch_size = 128\n\n# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\nbuffer_size = 10000\n\ndataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n\n# Length of the vocabulary in chars\nvocab_size = len(vocab)\n\n# The embedding dimension\nembed_dim = 64\n\n# Number of RNN units\nrnn_neurons = 2052","6a956c38":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy","407e9be8":"def sparse_cat_loss(y_true,y_pred):\n    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)","e270b6c6":"def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n    model = Sequential()\n    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n    # Final Dense Layer to Predict\n    model.add(Dense(vocab_size))\n    model.compile(optimizer='adam', loss=sparse_cat_loss) \n    return model","d5c37bf5":"model = create_model(\n  vocab_size = vocab_size,\n  embed_dim=embed_dim,\n  rnn_neurons=rnn_neurons,\n  batch_size=batch_size)","f00f1d68":"model.summary()","1f8d67b6":"epochs = 3 ","9d9e4219":"model.fit(dataset,epochs=epochs)","6b7207e9":"model.save('Madagascar-fr-result-24.txt')","0b23633f":"from tensorflow.keras.models import load_model","aafd937c":"model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n\nmodel.load_weights('..\/input\/hackathon\/task_1-google_search_txt_files_v2\/MG\/Madagascar-fr-result-24.txt')\n\nmodel.build(tf.TensorShape([1, None]))","50c6b193":"model.summary()","b3ca9ddc":"def generate_text(model, start_seed,gen_size=100,temp=1.1):\n  num_generate = gen_size\n  input_eval = [char_to_ind[s] for s in start_seed]\n  input_eval = tf.expand_dims(input_eval, 0)\n  text_generated = []\n  temperature = temp\n  model.reset_states()\n  for i in range(num_generate):\n      predictions = model(input_eval)\n      predictions = tf.squeeze(predictions, 0)\n      predictions = predictions \/ temperature\n      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n      input_eval = tf.expand_dims([predicted_id], 0)\n      text_generated.append(ind_to_char[predicted_id])\n  return (start_seed + ''.join(text_generated))","9cf9cd93":"print(generate_text(model,\"vaccination\",gen_size=1000))","b45e0933":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQwM9O-OQyYV4tLHM6NwEdGhC-zlfI4mGESJu-WYXcEHXpq2ss_&usqp=CAU',width=400,height=400)","0f263795":"#Codes from Nayan Kapri https:\/\/www.kaggle.com\/nrkapri\/asking-machine-learning-to-write-a-bengali-poem\/comments","0c6eb87c":"#What are the tools used to collect data?\n\n#Who is in charge of collecting data?\n\n#Which data should be collected and how?\n\n#When and how data should be object of report?\n\n#How data should be interpreted and used?\n\n#PEV = Position-effect variegation (PEV) \n\nIs a variegation caused by the silencing of a gene in some cells through its abnormal juxtaposition with heterochromatin via rearrangement or transposition. It is also associated with changes in chromatin conformation.https:\/\/en.wikipedia.org\/wiki\/Position-effect_variegation","6da54920":"I don't know to fix the issues above.","cc8b6280":"Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","ad8ce908":"caarapoonline.com.br","2ccb545b":"youtube.com","3e791060":"goeco.org."}}