{"cell_type":{"aaa58b5a":"code","eaedd739":"code","d5b7994d":"code","b7ddcde2":"code","fb4f7db9":"code","e29250db":"code","bfafbccd":"code","106b7e2f":"code","e86c765a":"code","92e73724":"code","7acc0ff4":"code","266a0a97":"code","b5b5143d":"code","16df9128":"code","b3953a73":"code","27134971":"code","1d59e6fc":"code","713109d0":"code","ff8516bd":"code","049f92ea":"code","a755b2d5":"code","34df6f6f":"code","6be1ba89":"code","cb8abb5d":"code","aa0af1a6":"code","0f098a7a":"code","b739a233":"code","c42c0d52":"code","50ecfda1":"code","407e663d":"code","e7328fa2":"code","a7d8c90d":"markdown","2ee635c0":"markdown","20b28cc4":"markdown","38f2e1c4":"markdown","665c34c5":"markdown","8f874277":"markdown","8dd2fad8":"markdown","ce00819a":"markdown","f9a7bad2":"markdown","769171e2":"markdown","8cd6e1f1":"markdown"},"source":{"aaa58b5a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns","eaedd739":"import tensorflow as tf\ntf.__version__","d5b7994d":"train_csv_path: str = '\/kaggle\/input\/titanic\/train.csv'\n\ndata: pd.DataFrame = pd.read_csv(train_csv_path)\ndata.info()","b7ddcde2":"data.head()","fb4f7db9":"data = data.drop(['PassengerId','Name','Ticket','Cabin','Parch'],axis=1)\ndata.head()","e29250db":"data.isnull().sum()","bfafbccd":"data.dropna(subset=['Embarked'], inplace=True)","106b7e2f":"data['Age'].fillna(data['Age'].mean(),inplace = True)","e86c765a":"data.isnull().sum()","92e73724":"sex_col = data['Sex'] == 'male'\nsex_col = sex_col.astype('int32')\n\n\ndata = data.drop(['Sex'],axis=1)\n\ndata['Sex'] = sex_col\n\ndata.head()","7acc0ff4":"data = pd.get_dummies(data, columns = ['Embarked'])\ndata.head()","266a0a97":"X = data.drop('Survived', axis=1).to_numpy()\ny = data['Survived'].to_numpy()","b5b5143d":"X.shape, y.shape","16df9128":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","b3953a73":"from sklearn.model_selection import train_test_split\n\ntf.random.set_seed(42)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","27134971":"# let's build a model to find patterns in it\n\n# Set random seed\ntf.random.set_seed(42)\n\n# 1. Create a model\nmodel_1 = tf.keras.Sequential([\n           tf.keras.layers.Dense(9, activation='relu'),\n           tf.keras.layers.Dense(15, activation='relu'),\n           tf.keras.layers.Dense(50, activation='relu'),\n           tf.keras.layers.Dense(2, activation='softmax')\n])\n\n# 2. Comile the model\nmodel_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                 metrics=['accuracy'])\n\n# 3. Fit the model\nhistory = model_1.fit(X_train, \n                      tf.one_hot(y_train, depth=2), \n                      epochs=250,\n                      verbose = 1,\n                      validation_data=(X_valid, tf.one_hot(y_valid, depth=2)))","1d59e6fc":"model_1.summary()","713109d0":"# Let's check out a way of viewing our deep learning models\nfrom tensorflow.keras.utils import plot_model\n\n# See the inputs and outputs of each layer\nplot_model(model_1, show_shapes=True)","ff8516bd":"test_dataset = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","049f92ea":"test_passengerIds = test_dataset['PassengerId'].values\ntest_dataset=test_dataset.drop(['PassengerId', 'Name','Ticket','Cabin', 'Parch'],axis=1)","a755b2d5":"test_dataset.head()","34df6f6f":"test_dataset.isna().sum()","6be1ba89":"test_dataset.info()","cb8abb5d":"test_dataset['Age'].fillna(test_dataset['Age'].mean(),inplace = True)\ntest_dataset['Fare'].fillna(test_dataset['Fare'].mean(),inplace = True)\ntest_dataset.isna().sum()","aa0af1a6":"sex_col = test_dataset['Sex'] == 'male'\nsex_col = sex_col.astype('int32')\n\n\ntest_dataset = test_dataset.drop(['Sex'],axis=1)\n\ntest_dataset['Sex'] = sex_col\n\ntest_dataset.head()","0f098a7a":"test_dataset = pd.get_dummies(test_dataset, columns = ['Embarked'])\ntest_dataset.head()","b739a233":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ntest_dataset = sc.fit_transform(test_dataset)","c42c0d52":"y_pred = model_1.predict(test_dataset).argmax(axis = 1)\ny_pred.shape","50ecfda1":"test_passengerIds.shape","407e663d":"output = pd.DataFrame({'PassengerId':test_passengerIds, 'Survived': y_pred})\noutput.to_csv('submission.csv', index=False)","e7328fa2":"output","a7d8c90d":"# Building and Training our model","2ee635c0":"# Test Data","20b28cc4":"# Quick Look at the Data\nLet\u2019s take a look at the top five rows:","38f2e1c4":"# Remove any columns that aren't needed from the dataset.","665c34c5":"# Split Data","8f874277":"# Import Packages\nLets load all the needed packages for this notebook:","8dd2fad8":"# Splitting traning set","ce00819a":"# Feature scaling","f9a7bad2":"# The Dataset\nFor this notebook we will use the Titanic competition dataset.\n\nLet's define the path to the dataset:","769171e2":"# Filling null values","8cd6e1f1":"# Checking null values"}}