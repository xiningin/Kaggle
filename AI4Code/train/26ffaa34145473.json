{"cell_type":{"51828a3a":"code","469f9b6a":"code","c9747e7e":"code","14ad0a0a":"code","529d585b":"code","1f865b48":"code","a2f17d6a":"code","b394177b":"code","008be5bb":"code","e4910b4f":"code","a493f844":"code","2520086e":"code","38c43e9c":"code","d29bedfc":"code","da9321ff":"code","e13f63cf":"code","a0aef465":"code","915d611f":"code","619f8869":"code","34fa3951":"code","05a5b360":"code","268932ce":"code","1ad4c550":"code","ca3c3aa4":"code","61c9dba4":"markdown","cbde64b6":"markdown","e3cacd44":"markdown","880c7be6":"markdown","3a24ae58":"markdown","b177ab1d":"markdown","22bb9356":"markdown","e6e2ba45":"markdown","f9d0bc68":"markdown","0de854c9":"markdown","9b4f85bb":"markdown","e0f304bf":"markdown","d2670e86":"markdown","610a4b9b":"markdown","7410a566":"markdown","6fe294ec":"markdown","2094f537":"markdown","e20fbbef":"markdown"},"source":{"51828a3a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","469f9b6a":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\n\n\nfrom numpy import loadtxt\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom pandas_profiling import ProfileReport\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n","c9747e7e":"# Read files\ntrain = pd.read_csv(\"\/kaggle\/input\/song-popularity-prediction\/train.csv\")\ntrain.set_index([\"id\"], inplace=True)\n\ntest = pd.read_csv(\"\/kaggle\/input\/song-popularity-prediction\/test.csv\")\ntest.set_index([\"id\"], inplace=True)","14ad0a0a":"train.head(10).style.highlight_null('yellow')","529d585b":"test.head(10).style.highlight_null('yellow')","1f865b48":"print(f\"Train Shape: {train.shape}\")\nprint(f\"Test Shape: {test.shape}\")","a2f17d6a":"train.describe()","b394177b":"fig = px.imshow(train.isnull().T, color_continuous_scale='thermal')\nfig.show()","008be5bb":"prof = ProfileReport(train)\nprof.to_file(output_file='Pandas_Profile_Report.html')","e4910b4f":"prof_minimal = ProfileReport(train, minimal=True)\nprof_minimal.to_file(output_file='Pandas_Profile_Report_Minimal.html')","a493f844":"train.fillna(train.median(), inplace=True)\ntrain.head(10)","2520086e":"test.fillna(test.median(), inplace=True)\ntest.head(10)","38c43e9c":"custom_input = False\n\nif custom_input:\n    pass\nelse:\n    test_size = 0.33\n    \nprint(f\"Custom test split: {test_size}\")","d29bedfc":"X = train.iloc[:,:-1].values\n# X","da9321ff":"y = train.iloc[:,-1:].values\n# y","e13f63cf":"print(f\"test_size: {test_size}\")\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y) #","a0aef465":"# one hot encode outputs\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\ncount_classes = y_test.shape[1]\nprint(count_classes)","915d611f":"model = Sequential()\nmodel.add(Dense(5, activation=\"relu\", input_dim=X_train.shape[1], name=\"layer1\"))\nmodel.add(Dense(3, activation='relu', name=\"layer2\"))\n\nmodel.add(Dense(2, activation=\"softmax\", name=\"output_layer\"))\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), \n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, epochs=10)","619f8869":"model.summary()","34fa3951":"from keras.utils.vis_utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True)","05a5b360":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()","268932ce":"pred_train= model.predict(X_train)\nscores = model.evaluate(X_train, y_train, verbose=0)\nprint('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n \npred_test= model.predict(X_test)\nscores2 = model.evaluate(X_test, y_test, verbose=0)\nprint('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))    ","1ad4c550":"pred_test2= model.predict(test.values)","ca3c3aa4":"submission = pd.DataFrame(np.argmax(pred_test2, axis=1), columns=[\"song_popularity\"])\nsubmission.index.names = [\"id\"]\nsubmission.to_csv(\"submission.csv\")","61c9dba4":"### Read the train and test files into memory","cbde64b6":"### Take a sneak-peak at the test data ","e3cacd44":"### Run the model prediction on train and test","880c7be6":"### Take a look at the model schematic","3a24ae58":"### Converting class labels to one-hot encoded labels","b177ab1d":"### Look at the detailed description for the train data","22bb9356":"### Make submission","e6e2ba45":"### Take a sneak-peak at the train data ","f9d0bc68":"### Import required dependencies","0de854c9":"### Prediction with Test data","9b4f85bb":"### Clean the train and test data","e0f304bf":"### Take a look at the model schematic graphically","d2670e86":"### Checking the null value distribution","610a4b9b":"### Quickly check out the shape of the data","7410a566":"### Plot the model Accuracy and Loss curve","6fe294ec":"### EDA the easy way -- Pandas Profiling","2094f537":"### Split the data into train test sets","e20fbbef":"### Build the model and fit it on the train data"}}