{"cell_type":{"b71ca9c3":"code","896782f7":"code","48da415d":"code","68bd1fae":"code","bd0b2df5":"code","5eb8d358":"code","5ab2be5f":"code","acfd9754":"code","ba447218":"code","a4392ee5":"code","8735915f":"code","c49ea4ba":"code","eb477c70":"code","13878e41":"code","29c95715":"code","73d93009":"code","7de2074f":"code","1ef9bff6":"code","49e82331":"code","46dd91da":"code","2b945bf1":"code","6372936a":"code","7e84405c":"code","06334285":"code","43fdc072":"markdown","22c8393f":"markdown","b70a32cd":"markdown","9f450deb":"markdown","3d177f82":"markdown","9ed098f5":"markdown","44d3954d":"markdown","21e0d50f":"markdown","b36b4d86":"markdown","93b8c116":"markdown","10a18d8e":"markdown","230b0595":"markdown","a3992225":"markdown","b510c636":"markdown","c011e4a8":"markdown","07e4c849":"markdown","04bed650":"markdown","f59338a8":"markdown","f9281a65":"markdown","a9aa4d06":"markdown","56b6ee30":"markdown","b550f504":"markdown"},"source":{"b71ca9c3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, cross_validate\nfrom sklearn.metrics import  recall_score,roc_auc_score, roc_curve\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\nfrom sklearn.tree import DecisionTreeClassifier\nimport warnings\nimport itertools\nwarnings.filterwarnings('ignore')\n%matplotlib inline","896782f7":"df = pd.read_csv('..\/input\/covid19-data\/data.csv',index_col=0)","48da415d":"#Negative hours changed to positive\nfor i in range(len(df)):\n    df.iloc[i, 12] = df.iloc[i, 12] * -1 if df.iloc[i, 12] < 0 else df.iloc[i, 12]\n\n#Gender value 2 changed to the most common gender\ndf['gender'] = df['gender'].mask(df['gender'] == 2, 1)","68bd1fae":"# Splits the given dataframe into 70% training set, 15% validation set, 15% testing set\ndef split(df):\n    x = df.drop('result', axis=1)\n    y = df['result']\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,shuffle=True, random_state=42, stratify=y)\n    X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size=0.5,shuffle=True, random_state=42, stratify=y_test)\n    return X_train, X_validate, X_test, y_train, y_validate, y_test","bd0b2df5":"# one hot encoding\ndef encode(df, columns):\n    df_encoded = df.copy()\n    for col in columns:\n        encoding = pd.get_dummies(df[col], prefix=col)\n        df_encoded = df_encoded.join(encoding)\n        df_encoded.drop(col, axis=1, inplace=True)\n    return df_encoded\n","5eb8d358":"def svm_validate(X_train, y_train, X_validate, y_validate):\n    dic = {'clf':[], 'recall':[]}\n    # Regularization parameter. The strength of the regularization \n    # is inversely proportional to C\n    c_values = [0.1, 1, 10, 100, 1000]\n    \n    #Kernel coefficient for \u2018rbf\u2019\n    gamma_values = [1, 0.1, 0.01, 0.001, 0.0001]\n    \n    #Degree of the polynomial kernel function\n    degrees = np.arange(1, 11, 1)\n\n    parameters = list(itertools.product(c_values, gamma_values, degrees))\n    for c, gamma, degree in parameters:\n        \n        #Perform scaling on the data then fit the model\n        rbf_kernel_svm_clf = Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"svm_clf\", SVC(C=c, gamma=gamma, degree=degree, random_state= 2, probability=True))\n        ])\n        rbf_kernel_svm_clf.fit(X_train, y_train)\n        y_pred = rbf_kernel_svm_clf.predict(X_validate)\n        recall = recall_score(y_validate, y_pred)\n        dic['clf'].append(rbf_kernel_svm_clf)\n        dic['recall'].append(recall)\n    df_scores = pd.DataFrame(dic)\n    return df_scores.iloc[df_scores['recall'].idxmax(), 0]","5ab2be5f":"def DT_validate(X_train, y_train, X_validate, y_validate):\n    dic = {'clf':[], 'recall':[]}\n    \n    # The function to measure the quality of a split.\n    criterion = ['entropy','gini']\n    \n    # The strategy used to choose the split at each node.\n    splitter = ['best','random']\n    \n    # Weights associated with classes\n    class_weight = ['balanced',None]\n    \n    # The number of features to consider when looking for the best split\n    max_features = [i for i in range(1,X_train.shape[1])]\n    \n    parameters = list(itertools.product(criterion, splitter, class_weight, max_features))\n    for crit, splitter, weight, max_features in parameters:\n        DT = DecisionTreeClassifier(criterion = crit, splitter=splitter, class_weight=weight, max_features=max_features, random_state=2)\n        DT.fit(X_train, y_train)\n        y_pred = DT.predict(X_validate)\n        recall = recall_score(y_validate, y_pred)\n        dic['clf'].append(DT)\n        dic['recall'].append(recall)\n    df_scores = pd.DataFrame(dic)\n    return df_scores.iloc[df_scores['recall'].idxmax(), 0]\n    ","acfd9754":"def draw_roc_curve(clf,X_test,y_test):\n    y_predict =  clf.predict_proba(X_test)\n    y_pred_proba = y_predict[::,1]\n    fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n    roc_auc = roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","ba447218":"X_train, X_validate, X_test, y_train, y_validate, y_test = split(df)\nbest_svm = svm_validate(X_train, y_train, X_validate, y_validate)\ny_predict = best_svm.predict(X_test)\nprint(best_svm)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(best_svm,X_test,y_test)","a4392ee5":"cols = ['location', 'country', 'symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6']\ndf_encoded = encode(df, cols)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\nbest_svm = svm_validate(X_train, y_train, X_validate, y_validate)\ny_predict = best_svm.predict(X_test)\nprint(best_svm)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(best_svm,X_test,y_test)","8735915f":"dropped_cols = ['symptom6', 'symptom5', 'symptom4','symptom2']\nencoded_cols = ['country','location', 'symptom1', 'symptom3']\ndf_encoded = encode(df.drop(dropped_cols, axis=1), encoded_cols)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\nbest_svm = svm_validate(X_train, y_train, X_validate, y_validate)\ny_predict = best_svm.predict(X_test)\nprint(best_svm)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(best_svm,X_test,y_test)","c49ea4ba":"dic = {'clf':[], 'recall':[]}\nc_values = [0.1, 1, 10, 100, 1000] \ngamma_values = [1, 0.1, 0.01, 0.001, 0.0001]\ndegrees = np.arange(1, 11, 1)\n\nparameters = list(itertools.product(c_values, gamma_values, degrees))\nfor c, gamma, degree in parameters:\n    rbf_kernel_svm_clf = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", SVC(C=c, gamma=gamma, degree=degree, random_state = 2, probability=True))\n    ])\n    bagging_clf = BaggingClassifier(base_estimator=rbf_kernel_svm_clf, n_estimators=10, random_state=2)\n    bagging_clf.fit(X_train, y_train)\n    y_pred = bagging_clf.predict(X_validate)\n    recall = recall_score(y_validate, y_pred)\n    dic['clf'].append(bagging_clf)\n    dic['recall'].append(recall)\ndf_scores = pd.DataFrame(dic)","eb477c70":"bagging_clf = df_scores.iloc[df_scores['recall'].idxmax(), 0]\ny_predict = bagging_clf.predict(X_test)\nprint(bagging_clf)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(bagging_clf,X_test,y_test)","13878e41":"dropped_cols = ['symptom6', 'symptom5', 'symptom4', 'symptom3', 'symptom2']\ndf_dropped = df.drop(dropped_cols, axis=1)\nros = RandomOverSampler(random_state=42)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_dropped)\nX_train, y_train= ros.fit_resample(X=X_train, y=y_train)\nbest_svm = svm_validate(X_train, y_train, X_validate, y_validate)\ny_predict = best_svm.predict(X_test)\nprint(best_svm)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(best_svm,X_test,y_test)","29c95715":"dropped_cols = ['symptom6', 'symptom5', 'symptom4', 'symptom3', 'symptom2']\ndf_dropped = df.drop(dropped_cols, axis=1)\nros = RandomOverSampler(random_state=42)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_dropped)\nX_train, y_train= ros.fit_resample(X=X_train, y=y_train)\ndic = {'clf':[], 'recall':[]}\nc_values = [0.1, 1, 10, 100, 1000] \ngamma_values = [1, 0.1, 0.01, 0.001, 0.0001]\ndegrees = np.arange(1, 11, 1)\n\nparameters = list(itertools.product(c_values, gamma_values, degrees))\nfor c, gamma, degree in parameters:\n    rbf_kernel_svm_clf = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", SVC(C=c, gamma=gamma, degree=degree, random_state = 2))\n    ])\n    bagging_clf = BaggingClassifier(base_estimator=rbf_kernel_svm_clf, n_estimators=10, random_state=2)\n    bagging_clf.fit(X_train, y_train)\n    y_pred = bagging_clf.predict(X_validate)\n    recall = recall_score(y_validate, y_pred)\n    dic['clf'].append(bagging_clf)\n    dic['recall'].append(recall)\ndf_scores = pd.DataFrame(dic)\nbagging_clf = df_scores.iloc[df_scores['recall'].idxmax(), 0]\ny_predict = bagging_clf.predict(X_test)\nprint(bagging_clf)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(bagging_clf,X_test,y_test)","73d93009":"df = pd.read_csv('..\/input\/covid19-data\/data.csv',index_col=0)","7de2074f":"X_train, X_validate, X_test, y_train, y_validate, y_test = split(df)\nbest_DT = DT_validate(X_train, y_train, X_validate, y_validate)\ny_predict = best_DT.predict(X_test)\nprint(best_DT)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(best_DT,X_test,y_test)","1ef9bff6":"cols = ['location', 'country', 'symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6']\ndf_encoded = encode(df, cols)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\nbest_DT = DT_validate(X_train, y_train, X_validate, y_validate)\ny_predict = best_DT.predict(X_test)\nprint(best_DT)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(best_DT,X_test,y_test)","49e82331":"dropped_cols = ['symptom6', 'symptom5', 'symptom4']\ndf_dropped = df.drop(dropped_cols, axis=1)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_dropped)\nbest_DT = DT_validate(X_train, y_train, X_validate, y_validate)\ny_predict = best_DT.predict(X_test)\nprint(best_DT)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(best_DT,X_test,y_test)","46dd91da":"dic = {'clf':[], 'recall':[]}\ncriterion = ['entropy','gini']\nsplitter = ['best','random']\nclass_weight = ['balanced', None]\nmax_features = [i for i in range(1,X_train.shape[1])]\nparameters = list(itertools.product(criterion, splitter, class_weight,max_features))\nfor crit, splitter, weight, max_features in parameters:\n    DT = DecisionTreeClassifier(criterion = crit, splitter=splitter, class_weight=weight, random_state = 2, max_features = max_features)\n    bagging_clf = BaggingClassifier(base_estimator= DT, random_state=2)\n    bagging_clf.fit(X_train, y_train)\n    y_pred = bagging_clf.predict(X_validate)\n    recall = recall_score(y_validate, y_pred)\n    dic['clf'].append(bagging_clf)\n    dic['recall'].append(recall)\ndf_scores = pd.DataFrame(dic)\n","2b945bf1":"bagging_clf = df_scores.iloc[df_scores['recall'].idxmax(), 0]\ny_predict = bagging_clf.predict(X_test)\nprint(bagging_clf)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(bagging_clf,X_test,y_test)","6372936a":"dropped_cols = ['symptom6', 'symptom5', 'symptom4', 'symptom3', 'symptom2']\ndf_dropped = df.drop(dropped_cols, axis=1)\nros = RandomOverSampler(random_state=42)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_dropped)\nX_train, y_train= ros.fit_resample(X=X_train, y=y_train)\nbest_DT = DT_validate(X_train, y_train, X_validate, y_validate)\ny_predict = best_DT.predict(X_test)\n\nprint(best_DT)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(best_DT,X_test,y_test)\n","7e84405c":"dropped_cols = ['symptom6', 'symptom5', 'symptom4', 'symptom3', 'symptom2']\nencoded_cols = []\ndf_encoded = encode(df.drop(dropped_cols, axis=1), encoded_cols)\n\nros = RandomOverSampler(random_state=42)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\nX_train, y_train= ros.fit_resample(X=X_train, y=y_train)\n\ndic = {'clf':[], 'recall':[]}\ncriterion = ['entropy','gini']\nsplitter = ['best','random']\nclass_weight = ['balanced', None]\nmax_features = [i for i in range(1,X_train.shape[1])]\n\nparameters = list(itertools.product(criterion, splitter, class_weight,max_features))\n\nfor crit, splitter, weight, max_features in parameters:\n    DT = DecisionTreeClassifier(criterion = crit, splitter=splitter, class_weight=weight, random_state = 2, max_features = max_features)\n    bagging_clf = BaggingClassifier(base_estimator= DT, random_state=2)\n    bagging_clf.fit(X_train, y_train)\n    y_pred = bagging_clf.predict(X_validate)\n    recall = recall_score(y_validate, y_pred)\n    dic['clf'].append(bagging_clf)\n    dic['recall'].append(recall)\n\ndf_scores = pd.DataFrame(dic)\nbagging_clf = df_scores.iloc[df_scores['recall'].idxmax(), 0]\n\ny_predict = bagging_clf.predict(X_test)\nprint(bagging_clf)\nprint(classification_report(y_test, y_predict))\nprint(f'ROC_AUC', roc_auc_score(y_test, y_predict))\ndraw_roc_curve(bagging_clf,X_test,y_test)","06334285":"comparision_dic = {\n    'Model':['SVM', 'SVM', 'Decision Tree','Decision Tree'],\n    'class': ['one', 'zero', 'one', 'zero'],\n    'Recall': ['0.88', '1.00','0.88', '0.99'],\n    'Precision': ['1.00', '0.98' ,'0.93', '0.98'],\n    'f1-score': ['0.93', '0.99', '0.90', '0.99'],\n    'roc_auc': ['0.94', '0.94', '0.93', '0.93'],\n}\n\ncomparision_df = pd.DataFrame(comparision_dic)\ncomparision_df","43fdc072":"This method will take the training and validation data, perform hyperparameter tuning and evaluate based on the best recall from the different models for DT. More hyperparameters were tested (such as max_depth) but they resulted in worse metrics thus they were removed.","22c8393f":"## Feature selection\nHere we experimentally select features. After some experiments this is the best result. Some features were removed based on their low correlation with the data while others were removed after experimentally testing that their removal improved recall.","b70a32cd":"## Final Model\nWe recommend using the model found in the \"Feature Selection\" section. As it leads to the highest values of recall and a good balance between recall and precsion.\n\n### Model hyperparameters\n\nPipeline(steps=[('scaler', StandardScaler()),\n                ('svm_clf',\n                 SVC(C=100, degree=1, gamma=0.001, probability=True,\n                     random_state=2))])\n                     \n### Classification report\n\n              precision    recall  f1-score\n\n           0       0.98      1.00      0.99 \n           1       1.00      0.88      0.93  \n\n    accuracy                           0.98\n    ROC_AUC                            0.94","9f450deb":"# Helper Methods\nThese methods will be used to perform different operations such as encoding the data. As well as splitting the dataframe to train, test, and validation sets.","3d177f82":"# Decision Tree","9ed098f5":"## Oversampling\nSince the data is imbalanced for the '1' class we utilise a random oversampler to balance the data by duplicating existing data from the '1' class.","44d3954d":"## Over sampling\nSince the data is imbalanced for the '1' class we utilise a random oversampler to balance the data by duplicating existing data from the '1' class.","21e0d50f":"## Using a Bagging Classifier on Oversampled Data","b36b4d86":"This method will take the training and validation data, perform hyperparameter tuning and evaluate based on the best recall from the different models for SVM.","93b8c116":"## Using a Bagging Classifier on Oversampled Data","10a18d8e":"# Cleaning\nBy inspecting the values in the different columns we noticed some irregular values especially in the gender and diff_sym_hos columns.","230b0595":"## Bagging with Validation\nIn this section, we utilise a bagging classifier to attempt to improve the recall.","a3992225":"Performing one-hot encoding on the data decreases the information gain of each column thus worsening the performance metrics of the model. Thus we use the encoding that was given in the dataset.","b510c636":"## Without Encoding\nFirst we attempt to fit the model without any changes to act as a baseline.","c011e4a8":"## Model Comparison","07e4c849":"# SVM","04bed650":"## Final Model\n\nWe recommend using the model found in the \"Using a Bagging Classifier on Oversampled Data\" section. As it leads to the highest values of recall and a good balance between recall and precsion.\n\n### Model hyperparameters\n\nBaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n                                                        criterion='entropy',\n                                                        max_features=2,\n                                                        random_state=2), random_state=2)\n                     \n### Classification report\n\n\n\n              precision    recall  f1-score   \n\n           0       0.98      0.99      0.99      \n           1       0.93      0.88      0.90        \n\n    accuracy                           0.98       \n    roc_auc                            0.93\n\n\n","f59338a8":"## Encoding\nWe then encode some of the categorical data in the dataset to improve the metrics.","f9281a65":"## Bagging with Validation\nIn this section, we utilise a bagging classifier to attempt to improve the recall.","a9aa4d06":"## Encoding\nWe then encode some of the categorical data in the dataset to attempt to improve the metrics.","56b6ee30":"## Without Encoding\nFirst we attempt to fit the model without any changes to act as a baseline.","b550f504":"## Feature Selection\nHere we experimentally select features. After some experiments this is the best result. Some features were removed based on their low correlation with the data while others were removed after experimentally testing that their removal improved recall."}}