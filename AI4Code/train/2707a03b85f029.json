{"cell_type":{"95a72607":"code","08fac7d1":"code","031e5bc6":"code","8a527604":"code","4d1a156a":"code","6e180cc7":"code","16ff547b":"code","bcf0feb3":"code","9f0125b7":"code","ad9c53e2":"code","b7c6f6a8":"code","6a8cc63a":"code","f24eaeaa":"code","78ac4bc7":"code","5dc73f76":"code","bf3e1ba6":"code","b18710d6":"code","d0777ef0":"markdown"},"source":{"95a72607":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08fac7d1":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split","031e5bc6":"dir0 = '..\/input\/lish-moa\/'\n# dir0 = \"\"\ntrain_features = pd.read_csv(dir0 + 'train_features.csv')\ntrain_targets_scored = pd.read_csv(dir0 + 'train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv(dir0 + 'train_targets_nonscored.csv')\nsample_submission = pd.read_csv(dir0 + 'sample_submission.csv')\ntest_features = pd.read_csv(dir0 + 'test_features.csv')","8a527604":"def make_features(train_features):\n    train_features['cp_type'] = (train_features['cp_type'] == 'ctl_vehicle').astype(int)\n    train_features['cp_time'] = (train_features['cp_time'] - 48) \/ 24\n    train_features['cp_dose'] = (train_features['cp_dose'] == 'D1').astype(int)\n    train_features_ids = train_features.pop('sig_id')\n    return (train_features, train_features_ids)","4d1a156a":"train_features, train_features_ids = make_features(train_features)\ntest_features, test_features_ids = make_features(test_features)\n\ntrain_targets_scored_sig_id = train_targets_scored.pop('sig_id')\n\nprint (train_features.shape, test_features.shape)","6e180cc7":"ii = train_features.cp_type.values==0\ntrain_features = train_features.loc[ii]\ntrain_targets_scored = train_targets_scored.loc[ii]\nprint (train_features.shape, test_features.shape)","16ff547b":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","bcf0feb3":"train_targets_scored.head()","9f0125b7":"train_dataset = TensorDataset(torch.tensor(train_features.values, dtype=torch.float32).to(device),\n                              torch.tensor(train_targets_scored.values, dtype=torch.float32).to(device))\ntrain_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)","ad9c53e2":"train_features.shape, train_targets_scored.shape","b7c6f6a8":"class MyModel(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.model = nn.Sequential(\n            nn.BatchNorm1d(in_features),\n            nn.Dropout(0.3),\n            nn.Linear(in_features, 800),\n            nn.Sigmoid(),\n\n            nn.BatchNorm1d(800),            # nn.Dropout(0.1),\n            nn.Dropout(0.3),\n            nn.Linear(800, 600),\n            nn.Sigmoid(),\n\n            nn.BatchNorm1d(600),            # nn.Dropout(0.1),\n            nn.Dropout(0.3),\n            nn.Linear(600, 400),\n            nn.Sigmoid(),\n\n            nn.BatchNorm1d(400),\n            nn.Linear(400, out_features),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.model(x)\n    \n# class MyModel(nn.Module):\n#     def __init__(self, in_features, out_features):\n#         super().__init__()\n#         self.in_features = in_features\n#         self.out_features = out_features\n\n#         self.model = nn.Sequential(\n#             nn.BatchNorm1d(in_features),\n#             nn.Linear(in_features, 800),\n#             nn.ReLU(),\n\n#             nn.BatchNorm1d(800),            # nn.Dropout(0.1),\n#             nn.Linear(800, 600),\n#             nn.ReLU(),\n\n#             nn.BatchNorm1d(600),            # nn.Dropout(0.1),\n#             nn.Linear(600, 400),\n#             nn.ReLU(),\n\n#             nn.BatchNorm1d(400),\n#             nn.Linear(400, out_features),\n#             nn.Sigmoid()\n#         )\n\n#     def forward(self, x):\n#         return self.model(x)","6a8cc63a":"%%time\nmodel = MyModel(train_features.shape[1], train_targets_scored.shape[1]).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3) #SGD(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 0.05, 10)\ncriterion = nn.BCELoss()\nmax_epoch = 20\n\nfor epoch in range(max_epoch):\n    model.train()\n    for i, (x_batch, y_batch) in enumerate(train_dataloader):\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n        preds = model(x_batch)\n\n        optimizer.zero_grad()\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        if i % 20 == 0:\n            print(f'Epoch: {epoch}, train loss: {loss.item():12.5f}')\n\n    model.eval()\n    with torch.no_grad():\n        train, y_train = train_dataset.tensors\n        train, y_train = train.to(device), y_train.to(device)\n        train_preds = model(train)\n        train_loss = criterion(train_preds, y_train).item()","f24eaeaa":"# model = MyModel(train_features.shape[1], train_targets_scored.shape[1])\n# optimizer = torch.optim.Adam(model.parameters()) #SGD(model.parameters(), lr=1e-3)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 0.05, 10)\n# criterion = nn.BCELoss()\n# max_epoch = 6\n\n# for epoch in range(max_epoch):\n#     model.train()\n#     for i, (x_batch, y_batch) in enumerate(train_dataloader):\n#         preds = model(x_batch)\n\n#         optimizer.zero_grad()\n#         loss = criterion(preds, y_batch)\n#         loss.backward()\n#         optimizer.step()\n\n#         if i % 20 == 0:\n#             print(f'Epoch: {epoch}, train loss: {loss.item():12.5f}')\n\n#     model.eval()\n#     with torch.no_grad():\n#         train, y_train = train_dataset.tensors\n#         train_preds = model(train)\n#         train_loss = criterion(train_preds, y_train).item()\n        \n# #         test, y_test = test_dataset.tensors\n# #         test_preds = model(test)\n# #         test_loss = criterion(test_preds, y_test).item()\n#         print(f'Epoch {epoch} final: train loss: {train_loss}')#, f'test loss: {test_loss}')","78ac4bc7":"model.eval()\nwith torch.no_grad():\n    probs = model(torch.tensor(test_features.values, dtype=torch.float32).to(device))\n    \nprobs = probs.to(\"cpu\").numpy()","5dc73f76":"ii2 = test_features.cp_type.values==1 # 1 !!!!\nprobs[ii2,:] = 0.0","bf3e1ba6":"df = pd.DataFrame(probs, index=test_features_ids, columns=train_targets_scored.columns)","b18710d6":"df.to_csv('submission.csv')","d0777ef0":"\u041f\u0435\u0440\u0432\u0430\u044f \u0432\u0435\u0440\u0441\u0438\u044f - 6 \u044d\u043f\u043e\u0445 lb = 0.01918\n\n\u0412\u0442\u043e\u0440\u0430\u044f \u0432\u0435\u0440\u0441\u0438\u044f - 20 \u044d\u043f\u043e\u0445 + GPU \u0441\u0434\u0435\u043b\u0430\u043b lb = 0.02666 (\u043f\u043b\u043e\u0445\u043e!)\n\n\u0422\u0440\u0435\u0442\u044c\u044f \u0432\u0435\u0440\u0441\u0438\u044f - DropOut + Sigmoid"}}