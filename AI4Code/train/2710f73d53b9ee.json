{"cell_type":{"9ac37428":"code","2e8b3247":"code","0fc81a49":"code","e8af3fb7":"code","24b849f2":"code","d63e6e51":"code","26e8fe1b":"code","c76860fd":"code","7e494d6a":"code","be67a89f":"code","2712ebbb":"markdown","8c6e8a34":"markdown"},"source":{"9ac37428":"from fastai.vision.all import *\nfrom fastai.metrics import *","2e8b3247":"sys.path.insert(0,'..\/input\/dm-nfnet')\nimport timm\n\n\nclass NFNet(nn.Module):\n    def __init__(self, num_classes=11, model_nr=3, pretrained=True):\n        super(NFNet, self).__init__()\n        self.model = timm.create_model(f'dm_nfnet_f{model_nr}', pretrained=pretrained)\n        self.model.head.fc = nn.Linear(self.model.head.fc.in_features, num_classes)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","0fc81a49":"dataset_path = Path('..\/input\/ranzcr-clip-catheter-line-classification')\ntrain_df = pd.read_csv(dataset_path\/'train.csv')\ntrain_df['path'] = train_df['StudyInstanceUID'].map(lambda x:str(dataset_path\/'train'\/x)+'.jpg')\ntrain_df = train_df.drop(columns=['StudyInstanceUID'])","e8af3fb7":"img_sizes = [192, 224, 256, 320, 384, 416, 448]\nmodel_nr = 0 # Between 0 and 5\npartial_data = .05\nsize = img_sizes[model_nr]","24b849f2":"aug_intensity = 1.1\nitem_tfms = RandomResizedCrop(size * 2, min_scale=.85, ratio=(.75, 1.33333))\nbatch_tfms = [*aug_transforms(mult=aug_intensity, do_flip=True, flip_vert=True, max_rotate=45, size=size, max_warp=0), Normalize.from_stats(*imagenet_stats)]\n\ndb = DataBlock(blocks=(ImageBlock, MultiCategoryBlock(encoded=True, vocab=list(train_df.columns[:11]))),\n               #splitter = RandomSplitter(.01),\n               splitter=RandomSubsetSplitter(partial_data * .85, partial_data * .15),\n               get_x = ColReader(12),\n               get_y = ColReader(list(range(11))),\n               item_tfms = item_tfms,\n               batch_tfms = batch_tfms)","d63e6e51":"bs = [128, 72, 36, 14, 6, 4]\ndls = db.dataloaders(train_df, batch_size=bs[model_nr])\nm = NFNet(model_nr=model_nr)\nl = Learner(dls, m, loss_func=nn.BCEWithLogitsLoss(), metrics=[accuracy_multi]).to_fp16()","26e8fe1b":"l.fine_tune(4, base_lr=2e-5)","c76860fd":"sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\nsample_df['PatientID'] = 'None'\nsample_df['path'] = sample_df['StudyInstanceUID'].map(lambda x:str(dataset_path\/'test'\/x)+'.jpg')\nsample_df = sample_df.drop(columns=['StudyInstanceUID'])\ntest_dl = dls.test_dl(sample_df, batch_size = int(bs[model_nr] \/ 2))","7e494d6a":"l = l.to_fp32()\npreds, _ = l.tta(dl=test_dl, n=2, beta=0.25)","be67a89f":"submission_df = sample_df.copy()\nlabel_names = list(train_df.columns[:11])\nfor i in range(len(submission_df)):\n    for j in range(len(label_names)):\n        submission_df.iloc[i, j+1] = preds[i][j].numpy().astype(np.float32)\n\nsubmission_df.to_csv(f'submission.csv', index=False)\nprint(submission_df.head(10))","2712ebbb":"Tune model_nr and data augmentation. Batch size and image size are automatically adapted to the capacity of the Kaggle GPU","8c6e8a34":"For test runs use partial_data by uncommenting the commented line and commenting the line above"}}