{"cell_type":{"27723db7":"code","307081ec":"code","96bdf9b6":"code","355d60c2":"code","ea3bed76":"code","a7b48b5e":"code","5619d23f":"code","45d55098":"code","abb882c9":"code","5ef364d0":"code","155bc7e8":"code","f25e4a9a":"code","50b40515":"code","13943013":"code","dc9f41ab":"code","9e3477c8":"code","6ceefe3c":"code","2ce6f0ec":"markdown","14be485a":"markdown","c87bbcea":"markdown","df2c0a7b":"markdown","a5f3131e":"markdown"},"source":{"27723db7":"import datetime\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style(\"darkgrid\")\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n!pip install -q tensorflow==2.0.0-alpha0\nimport tensorflow as tf\n# Load the TensorBoard notebook extension\n%load_ext tensorboard.notebook\n\n# Imports for the HParams plugin\nfrom tensorboard.plugins.hparams import api_pb2\nfrom tensorboard.plugins.hparams import summary as hparams_summary\nfrom google.protobuf import struct_pb2\n\n# Clear any logs from previous runs\n!rm -rf .\/logs\/ \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","307081ec":"tf.__version__","96bdf9b6":"data=pd.read_csv(\"..\/input\/heart.csv\")","355d60c2":"data.head()","ea3bed76":"data.info()","a7b48b5e":"data.describe()","5619d23f":"# Just to see the correlation\nplt.figure(figsize=(10,8))\nsns.heatmap(data.corr(method='pearson'),annot=True,cmap='YlGnBu',fmt='.2f',linewidths=2)","45d55098":"# A utility method to create a tf.data dataset from a Pandas Dataframe\ndef df_to_dataset(dataframe, shuffle=True, batch_size=32):\n  dataframe = dataframe.copy()\n  labels = dataframe.pop('target')\n  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  return ds","abb882c9":"feature_columns = []\n\n# numeric cols\nfor header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']:\n  feature_columns.append(tf.feature_column.numeric_column(header))\n\n# bucketized cols\nage = tf.feature_column.numeric_column(\"age\")\nage_buckets = tf.feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\nfeature_columns.append(age_buckets)\n\n# indicator cols\ndata[\"thal\"] = data[\"thal\"].apply(lambda x: str(x))\nthal = tf.feature_column.categorical_column_with_vocabulary_list(\n      'thal', ['3', '6', '7'])\nthal_one_hot = tf.feature_column.indicator_column(thal)\nfeature_columns.append(thal_one_hot)\n\ndata[\"sex\"] = data[\"sex\"].apply(str)\nsex = tf.feature_column.categorical_column_with_vocabulary_list(\n      'sex', ['0', '1'])\nsex_one_hot = tf.feature_column.indicator_column(sex)\nfeature_columns.append(sex_one_hot)\n\ndata[\"cp\"] = data[\"cp\"].apply(lambda x: str(x))\ncp = tf.feature_column.categorical_column_with_vocabulary_list(\n      'cp', ['0', '1', '2', '3'])\ncp_one_hot = tf.feature_column.indicator_column(cp)\nfeature_columns.append(cp_one_hot)\n\ndata[\"slope\"] = data[\"slope\"].apply(str)\nslope = tf.feature_column.categorical_column_with_vocabulary_list(\n      'slope', ['0', '1', '2'])\nslope_one_hot = tf.feature_column.indicator_column(slope)\nfeature_columns.append(slope_one_hot)\n\n# embedding cols\nthal_embedding = tf.feature_column.embedding_column(thal, dimension=8)\nfeature_columns.append(thal_embedding)\n\n# crossed cols\nage_thal_crossed = tf.feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)\nage_thal_crossed = tf.feature_column.indicator_column(age_thal_crossed)\nfeature_columns.append(age_thal_crossed)\n\ncp_slope_crossed = tf.feature_column.crossed_column([cp, slope], hash_bucket_size=1000)\ncp_slope_crossed = tf.feature_column.indicator_column(cp_slope_crossed)\nfeature_columns.append(cp_slope_crossed)","5ef364d0":"train, test = train_test_split(data, test_size=0.2)\ntrain, val = train_test_split(train, test_size=0.2)\nprint(len(train), 'train examples')\nprint(len(val), 'validation examples')\nprint(len(test), 'test examples')","155bc7e8":"batch_size = 32\ntrain_ds = df_to_dataset(train, batch_size=batch_size)\nval_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\ntest_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)","f25e4a9a":"num_units_list = [128, 256]\ndropout_rate_list = [0.2, 0.5] \noptimizer_list = ['adam', 'sgd'] ","50b40515":"# Utility method to create summary for tensorboard\ndef create_experiment_summary(num_units_list, dropout_rate_list, optimizer_list):\n  num_units_list_val = struct_pb2.ListValue()\n  num_units_list_val.extend(num_units_list)\n  dropout_rate_list_val = struct_pb2.ListValue()\n  dropout_rate_list_val.extend(dropout_rate_list)\n  optimizer_list_val = struct_pb2.ListValue()\n  optimizer_list_val.extend(optimizer_list)\n  return hparams_summary.experiment_pb(\n      # The hyperparameters being changed\n      hparam_infos=[\n          api_pb2.HParamInfo(name='num_units',\n                             display_name='Number of units',\n                             type=api_pb2.DATA_TYPE_FLOAT64,\n                             domain_discrete=num_units_list_val),\n          api_pb2.HParamInfo(name='dropout_rate',\n                             display_name='Dropout rate',\n                             type=api_pb2.DATA_TYPE_FLOAT64,\n                             domain_discrete=dropout_rate_list_val),\n          api_pb2.HParamInfo(name='optimizer',\n                             display_name='Optimizer',\n                             type=api_pb2.DATA_TYPE_STRING,\n                             domain_discrete=optimizer_list_val)\n      ],\n      # The metrics being tracked\n      metric_infos=[\n          api_pb2.MetricInfo(\n              name=api_pb2.MetricName(\n                  tag='accuracy'),\n              display_name='Accuracy'),\n      ]\n  )\n\nexp_summary = create_experiment_summary(num_units_list, dropout_rate_list, optimizer_list)\nroot_logdir_writer = tf.summary.create_file_writer(\"logs\/hparam_tuning\")\nwith root_logdir_writer.as_default():\n  tf.summary.import_event(tf.compat.v1.Event(summary=exp_summary).SerializeToString())","13943013":"# Model compiler\ndef train_test_model(hparams):\n\n  model = tf.keras.models.Sequential([\n    tf.keras.layers.DenseFeatures(feature_columns),\n    tf.keras.layers.Dense(hparams['num_units'], activation='relu'),\n    tf.keras.layers.Dropout(hparams['dropout_rate']),\n      tf.keras.layers.Dense(hparams['num_units'], activation='relu'),\n    tf.keras.layers.Dense(2, activation='sigmoid')\n  ])\n  model.compile(optimizer=hparams['optimizer'],\n                loss='binary_crossentropy',\n                metrics=['accuracy'])\n\n  model.fit(train_ds, \n            validation_data=val_ds, \n            epochs=50,\n            use_multiprocessing=True,)\n  _, accuracy = model.evaluate(test_ds)\n  return accuracy","dc9f41ab":"# Model runner\ndef run(run_dir, hparams):\n  writer = tf.summary.create_file_writer(run_dir)\n  summary_start = hparams_summary.session_start_pb(hparams=hparams)\n\n  with writer.as_default():\n    accuracy = train_test_model(hparams)\n    summary_end = hparams_summary.session_end_pb(api_pb2.STATUS_SUCCESS)\n      \n    tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")\n    tf.summary.import_event(tf.compat.v1.Event(summary=summary_start).SerializeToString())\n    tf.summary.import_event(tf.compat.v1.Event(summary=summary_end).SerializeToString())","9e3477c8":"session_num = 0\n\nfor num_units in num_units_list:\n  for dropout_rate in dropout_rate_list:\n    for optimizer in optimizer_list:\n      hparams = {'num_units': num_units, 'dropout_rate': dropout_rate, 'optimizer': optimizer}\n      print('--- Running training session %d' % (session_num + 1))\n      print(hparams)\n      run_name = \"run-%d\" % session_num\n      run(\"logs\/hparam_tuning\/\" + run_name, hparams)\n      session_num += 1","6ceefe3c":"# %tensorboard --logdir logs\/hparam_tuning","2ce6f0ec":"All the feature columns are in numeric format. This is not the case in real world scenarios. Let's look at the statistics for each feature.","14be485a":"## Define Feature columns for tensorflow\nExamples of each column type","c87bbcea":"# In TnesorFlow 2.0 they included the capabiluity to run tensorboard directly inside notebooks. This is working on local jupyter but not here. Hope kaggle fixes this and update","df2c0a7b":"## Hyperparameter tuning","a5f3131e":"# Reading and analyzing the data"}}