{"cell_type":{"b34b0d25":"code","5e9f474d":"code","f2a1d372":"code","ebd86980":"code","8454588c":"code","d9bf87ec":"markdown"},"source":{"b34b0d25":"import lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport glob\nimport os\nimport sklearn.datasets\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\n\nimport optuna\n","5e9f474d":"feature_dir = \"..\/input\/indoor-wifi-features\/\"","f2a1d372":"# the metric used in this competition\ndef comp_metric(xhat, yhat, fhat, x, y, f):\n    intermediate = np.sqrt(np.power(xhat - x,2) + np.power(yhat-y,2)) + 15 * np.abs(fhat-f)\n    return intermediate.sum()\/xhat.shape[0]\n\n# get our train and test files\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\nprint (train_files)\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nssubm = pd.read_csv('..\/input\/indoor-location-navigation\/sample_submission.csv', index_col=0)","ebd86980":"file = \"..\/input\/indoor-wifi-features\/5a0546857ecc773753327266_1000_train.csv\"\ndata = pd.read_csv(file, index_col=0)\ndata","8454588c":"\n# FYI: Objective functions can take additional arguments\n# (https:\/\/optuna.readthedocs.io\/en\/stable\/faq.html#objective-func-additional-args).\ndef objective(trial):\n    #data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n    file = \"..\/input\/indoor-wifi-features\/5a0546857ecc773753327266_1000_train.csv\"\n    data = pd.read_csv(file, index_col=0)\n    \n    x_train = data.iloc[:,:-3]\n    y_trainy = data.iloc[:,-2]\n    \n    train_x, valid_x, train_y, valid_y = train_test_split(x_train, y_trainy, test_size=0.25)\n    dtrain = lgb.Dataset(train_x, label=train_y)\n    '''\n    param = {\n        \"objective\": \"regression\",\n        \"metric\": \"binary_logloss\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    '''\n    param = {\"objective\": \"regression\",\"metric\": \"l2\",\"verbosity\": -1,\"boosting_type\": \"gbdt\",\"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 150)}\n\n    gbm = lgb.train(param, dtrain)\n    preds = gbm.predict(valid_x)\n    pred_labels = np.rint(preds)\n    accuracy = sklearn.metrics.mean_squared_error(valid_y, pred_labels)\n    return accuracy\n\n\nif __name__ == \"__main__\":\n    study = optuna.create_study(direction=\"minimize\")\n    ## increase n_trails to test more params\n    study.optimize(objective, n_trials=5)\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Value: {}\".format(trial.value))\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))\n","d9bf87ec":"This notbook is a basic application of optuna on one wifi to tune the parameters of LGBM regressor. It currently only tunes based on 1 wifi trian set.\n\nBased on the example: https:\/\/github.com\/optuna\/optuna\/blob\/master\/examples\/lightgbm_simple.py\n\nAlso credit to @devinanzelmo for the beginning notebook and dataset for wifi"}}