{"cell_type":{"8df9fbc0":"code","ca6ef130":"code","7ce8e173":"code","31283376":"code","22fb1fff":"code","1cae4e2f":"code","8c0e09cf":"code","815752b4":"code","e5147a0f":"code","24c49780":"code","59c75152":"code","8cd47fda":"code","e598aa7a":"code","ced8ad0c":"code","91341e6f":"code","6d5cb843":"code","111d8681":"code","e6e0437c":"code","cd214638":"code","59ecba22":"code","2a12bfa5":"code","3c5ee303":"code","eb82499f":"code","fe4ce220":"code","9ea208fe":"code","ff625351":"code","4665b4bd":"code","6c7ab42e":"code","c2d15c46":"code","6d011966":"code","f47c0801":"code","f8e19040":"code","69ae65f9":"code","bd2106b7":"code","89574884":"code","178f68dc":"code","1b28c011":"code","10b0ff6c":"markdown","293e0fb0":"markdown","530af07d":"markdown","52cfb539":"markdown","de4e7b6d":"markdown","7ed97a34":"markdown","b85538a3":"markdown","e4cad7b6":"markdown","65b74c17":"markdown","baf23207":"markdown","0d59af11":"markdown","417d14f2":"markdown","54bf3b37":"markdown","92cc4b04":"markdown","3c850352":"markdown","08481cf6":"markdown"},"source":{"8df9fbc0":"# Importing Required Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv1D\nimport wfdb                            # Package for loading the ecg and annotation\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\nimport warnings\nwarnings.filterwarnings(\"ignore\") \nimport random\nfrom keras.layers import Bidirectional, LSTM\n# Random Initialization\nrandom.seed(42)","ca6ef130":"# Importing Data\ndata = '..\/input\/mit-bih-arrhythmia-database\/'","7ce8e173":"# List of Patients\npatients = ['100','101','102','103','104','105','106','107',\n           '108','109','111','112','113','114','115','116',\n           '117','118','119','121','122','123','124','200',\n           '201','202','203','205','207','208','209','210',\n           '212','213','214','215','217','219','220','221',\n           '222','223','228','230','231','232','233','234']","31283376":"# Creating a Empty Dataframe\nsymbols_df = pd.DataFrame()\n\n# Reading all .atr files \nfor pts in patients:\n    # Generating filepath for all .atr file names\n    file = data + pts\n    # Saving annotation object\n    annotation = wfdb.rdann(file, 'atr')\n    # Extracting symbols from the object\n    sym = annotation.symbol\n    # Saving value counts\n    values, counts = np.unique(sym, return_counts=True)\n    # Writing data points into dataframe\n    df_sub = pd.DataFrame({'symbol':values, 'Counts':counts, 'Patient Number':[pts]*len(counts)})\n    # Concatenating all data points  \n    symbols_df = pd.concat([symbols_df, df_sub],axis = 0)","22fb1fff":"# Symbols Dataframe\nsymbols_df","1cae4e2f":"# Value Counts of Different symbols in data\nsymbols_df.groupby('symbol').Counts.sum().sort_values(ascending = False)","8c0e09cf":"# Non Beat Symbols\nnonbeat = ['[','!',']','x','(',')','p','t','u','`',\n           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n\n# Abnormal Beat Symbols\nabnormal = ['L','R','V','\/','A','f','F','j','a','E','J','e','S']\n\n# Normal Beat Symbols\nnormal = ['N']","815752b4":"# Classifying normal, abnormal or nonbeat\nsymbols_df['category'] = -1\nsymbols_df.loc[symbols_df.symbol == 'N','category'] = 0\nsymbols_df.loc[symbols_df.symbol.isin(abnormal), 'category'] = 1","e5147a0f":"# Value counts of different categories\nsymbols_df.groupby('category').Counts.sum()","24c49780":"def load_ecg(file):    \n    # load the ecg\n    record = wfdb.rdrecord(file)\n    # load the annotation\n    annotation = wfdb.rdann(file, 'atr')\n    \n    # extracting the signal\n    p_signal = record.p_signal\n\n    # extracting symbols and annotation index\n    atr_sym = annotation.symbol\n    atr_sample = annotation.sample\n    \n    return p_signal, atr_sym, atr_sample","59c75152":"# Accessing the ecg points for \nfile = data + patients[8]","8cd47fda":"# Accessing the load ECG function and getting annotation.symbol, annotation.sample, signals\np_signal, atr_sym, atr_sample = load_ecg(file)","e598aa7a":"# Analysing annotations value counts for a single record\nvalues, counts = np.unique(sym, return_counts=True)\nfor v,c in zip(values, counts):\n    print(v,c)","ced8ad0c":"# get abnormal beat index\nab_index = [b for a,b in zip(atr_sym,atr_sample) if a in abnormal][:10]\nab_index","91341e6f":"# Generating evenly spaced values\nx = np.arange(len(p_signal))\n\nleft = ab_index[5]-20000\nright = ab_index[5]+20000\n\nplt.figure(figsize=(20,8))\nplt.plot(x[left:right],p_signal[left:right,0],'-',label='ecg',)\nplt.plot(x[atr_sample],p_signal[atr_sample,0],'go',label ='normal')\nplt.plot(x[ab_index],p_signal[ab_index,0],'ro',label='abnormal')\n\nplt.xlim(left,right)\nplt.ylim(p_signal[left:right].min()-0.05,p_signal[left:right,0].max()+0.05)\nplt.xlabel('time index')\nplt.ylabel('ECG signal')\nplt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\nplt.show()","6d5cb843":"def make_dataset(pts, num_sec, fs, abnormal):\n    # function for making dataset ignoring non-beats\n    # input:\n    #   pts - list of patients\n    #   num_sec = number of seconds to include before and after the beat\n    #   fs = frequency\n    # output: \n    #   X_all = signal (nbeats , num_sec * fs columns)\n    #   Y_all = binary is abnormal (nbeats, 1)\n    #   sym_all = beat annotation symbol (nbeats,1)\n    \n    # initialize numpy arrays\n    num_cols = 2*num_sec * fs\n    X_all = np.zeros((1,num_cols))\n    Y_all = np.zeros((1,1))\n    sym_all = []\n    \n    # list to keep track of number of beats across patients\n    max_rows = []\n    \n    for pt in pts:\n        file = data + pt\n        \n        p_signal, atr_sym, atr_sample = load_ecg(file)\n        \n        # grab the first signal\n        p_signal = p_signal[:,0]\n        \n        # make df to exclude the nonbeats\n        df_ann = pd.DataFrame({'atr_sym':atr_sym,\n                              'atr_sample':atr_sample})\n        df_ann = df_ann.loc[df_ann.atr_sym.isin(abnormal + ['N'])]\n        \n        X,Y,sym = build_XY(p_signal,df_ann, num_cols, abnormal)\n        sym_all = sym_all+sym\n        max_rows.append(X.shape[0])\n        X_all = np.append(X_all,X,axis = 0)\n        Y_all = np.append(Y_all,Y,axis = 0)\n        \n    # drop the first zero row\n    X_all = X_all[1:,:]\n    Y_all = Y_all[1:,:]\n\n    return X_all, Y_all, sym_all\n","111d8681":"def build_XY(p_signal, df_ann, num_cols, abnormal):\n    # this function builds the X,Y matrices for each beat\n    # it also returns the original symbols for Y\n    \n    num_rows = len(df_ann)\n\n    X = np.zeros((num_rows, num_cols))\n    Y = np.zeros((num_rows,1))\n    sym = []\n    \n    # keep track of rows\n    max_row = 0\n\n    for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n\n        left = max([0,(atr_sample - num_sec*fs) ])\n        right = min([len(p_signal),(atr_sample + num_sec*fs) ])\n        x = p_signal[left: right]\n        if len(x) == num_cols:\n            X[max_row,:] = x\n            Y[max_row,:] = int(atr_sym in abnormal)\n            sym.append(atr_sym)\n            max_row += 1\n    X = X[:max_row,:]\n    Y = Y[:max_row,:]\n    return X,Y,sym","e6e0437c":"# Parameter Values\nnum_sec = 3\nfs = 360","cd214638":"# Accessing the fuction and creating a dataset with ECG digital Points\nX_all, Y_all, sym_all = make_dataset(patients, num_sec, fs, abnormal)","59ecba22":"# Train Test Split\nX_train, X_valid, y_train, y_valid = train_test_split(X_all, Y_all, test_size=0.33, random_state=42)","2a12bfa5":"# Relu for activation function and drop out for regularization\nmodel = Sequential()\nmodel.add(Dense(32, activation = 'relu', input_dim = X_train.shape[1]))\nmodel.add(Dropout(rate = 0.25))\nmodel.add(Dense(1, activation = 'sigmoid'))","3c5ee303":"# Compiling model with  binary crossentropy and the adam optimizer\nmodel.compile(loss = 'binary_crossentropy',\n                optimizer = 'adam',\n                metrics = ['accuracy'])","eb82499f":"# Fitting the model\nmodel.fit(X_train, y_train, batch_size = 32, epochs= 10, verbose = 1)","fe4ce220":"# Evaluation Metrics\ndef print_report(y_actual, y_pred, thresh):\n    # Function to print evaluation metrics\n    auc = roc_auc_score(y_actual, y_pred)\n    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n    recall = recall_score(y_actual, (y_pred > thresh))\n    precision = precision_score(y_actual, (y_pred > thresh))\n    specificity = sum((y_pred < thresh) & (y_actual == 0)) \/sum(y_actual ==0)\n    prevalence = (sum(y_actual)\/len(y_actual))\n    print('AUC:%.3f'%auc)\n    print('Accuracy:%.3f'%accuracy)\n    print('Recall:%.3f'%recall)\n    print('Precision:%.3f'%precision)\n    print('Specificity:%.3f'%specificity)\n    print('Prevalence:%.3f'%prevalence)\n    print(' ')\n    return auc, accuracy, recall, precision, specificity","9ea208fe":"# Predictions\ny_train_preds_dense = model.predict(X_train,verbose = 1)\ny_valid_preds_dense = model.predict(X_valid,verbose = 1)","ff625351":"# Threshold Value\nthresh = (sum(y_train)\/len(y_train))[0]","4665b4bd":"# Accessing Evaluation Metrics Function\nprint('On Train Data')\nprint_report(y_train, y_train_preds_dense, thresh)\nprint('On Valid Data')\nprint_report(y_valid, y_valid_preds_dense, thresh)","6c7ab42e":"# reshape input to [samples, time steps, features = 1] for CNN\nX_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_valid_cnn = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n\nprint(X_train_cnn.shape)\nprint(X_valid_cnn.shape)","c2d15c46":"# Relu for activation function & Dropout for reducing overfitting by randomly removing some nodes.\nmodel = Sequential()\nmodel.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu', input_shape = (2160,1)))\nmodel.add(Dropout(rate = 0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n# compile the model with binary crossentropy, and the adam optimizer\nmodel.compile(loss = 'binary_crossentropy',\n                optimizer = 'adam',\n                metrics = ['accuracy'])\n","6d011966":"# Fitting data in model\nmodel.fit(X_train_cnn, y_train, batch_size = 32, epochs= 2, verbose = 1)","f47c0801":"# Predictions\ny_train_preds_cnn = model.predict(X_train_cnn,verbose = 1)\ny_valid_preds_cnn = model.predict(X_valid_cnn,verbose = 1)","f8e19040":"# Metrics\nprint('Train');\nprint_report(y_train, y_train_preds_cnn, thresh)\nprint('Valid');\nprint_report(y_valid, y_valid_preds_cnn, thresh);","69ae65f9":"# Bidirectional LSTM with Dropout for reducing overfitting by randomly removing some nodes.\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(64, input_shape=(X_train_cnn.shape[1], X_train_cnn.shape[2]))))\nmodel.add(Dropout(rate = 0.25))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(\n                loss = 'binary_crossentropy',\n                optimizer = 'adam',\n                metrics = ['accuracy'])","bd2106b7":"# Fitting Data\nmodel.fit(X_train_cnn[:10000], y_train[:10000], batch_size = 32, epochs= 1, verbose = 1)","89574884":"# Prediction\ny_train_preds_lstm = model.predict(X_train_cnn[:10000],verbose = 1)\ny_valid_preds_lstm = model.predict(X_valid_cnn,verbose = 1)","178f68dc":"# Metrics\nprint('Train');\nprint_report(y_train[:10000], y_train_preds_lstm, thresh)\nprint('Valid');\nprint_report(y_valid, y_valid_preds_lstm, thresh);","1b28c011":"from sklearn.metrics import roc_curve, roc_auc_score\n\nfpr_valid_cnn, tpr_valid_cnn, t_valid_cnn = roc_curve(y_valid, y_valid_preds_cnn)\nauc_valid_cnn = roc_auc_score(y_valid, y_valid_preds_cnn)\n\nfpr_valid_dense, tpr_valid_dense, t_valid_dense = roc_curve(y_valid, y_valid_preds_dense)\nauc_valid_dense = roc_auc_score(y_valid, y_valid_preds_dense)\n\nfpr_valid_lstm, tpr_valid_lstm, t_valid_lstm = roc_curve(y_valid, y_valid_preds_lstm)\nauc_valid_lstm = roc_auc_score(y_valid, y_valid_preds_lstm)\n\nplt.plot(fpr_valid_cnn, tpr_valid_cnn, 'g-', label = 'CNN AUC:%.3f'%auc_valid_cnn)\nplt.plot(fpr_valid_dense, tpr_valid_dense, 'r-', label = 'Dense AUC:%.3f'%auc_valid_dense)\nplt.plot(fpr_valid_lstm, tpr_valid_lstm, 'b-', label = 'LSTM AUC:%.3f'%auc_valid_lstm)\n\nplt.plot([0,1],[0,1], 'k--')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\nplt.title('Validation Set')\nplt.show()\n","10b0ff6c":"<div style=\"background:#5990f7;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Convolutional Neural Networks(CNN)<\/font><\/h4>\n    <\/strong>\n<\/div>","293e0fb0":"<center><h1 class=\"list-group-item list-group-item-success\">Thank You<\/h1><\/center>","530af07d":"<div style=\"background:#5990f7;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Dense Neural Networks(DNN)<\/font><\/h4>\n    <\/strong>\n<\/div>","52cfb539":"<center><img src = \"https:\/\/res.cloudinary.com\/qna\/image\/upload\/v1636913992\/heart-arrhythmia_f8yxcp.jpg\"><\/center>\n\n<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Research Objective<\/font><\/h4>\n    <\/strong>\n<\/div><br>\n<font size = 4>Comparing accuracy of Convolutional Neural Networks (CNN), Dense Neural Networks(DNN), Long Short Term Memory(LSTM) in arrhythmia detetction on graphical representation of electrocardiographic signals.<\/font><br><br><br>\n\n<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Data Description<\/font><\/h4>\n    <\/strong>\n<\/div><br>\n<font size = 4>The MIT-BIH Arrhythmia Database contains 48 half-hour excerpts of two-channel ambulatory ECG recordings, obtained from 47 subjects studied by the BIH Arrhythmia Laboratory between 1975 and 1979. Twenty-three recordings were chosen at random from a set of 4000 24-hour ambulatory ECG recordings collected from a mixed population of inpatients (about 60%) and outpatients (about 40%) at Boston's Beth Israel Hospital; the remaining 25 recordings were selected from the same set to include less common but clinically significant arrhythmias that would not be well-represented in a small random sample.<br>\n\nThe recordings were digitized at 360 samples per second per channel with 11-bit resolution over a 10 mV range. Two or more cardiologists independently annotated each record; disagreements were resolved to obtain the computer-readable reference annotations for each beat (approximately 110,000 annotations in all) included with the database.\nPredict if a heart beat from the first ECG signal has an arrhythmia for each 6 second window centered on the peak of the heart beat.<br>\n\nTo simplify the problem, we will assume that a QRS detector is capable of automatically identifying the peak of each heart beat. We will ignore any non-beat annotations and any heart beats in the first or last 3 seconds of the recording due to reduced data. We will use a window of 6 seconds so we can compare the current beat to beats just before and after. This decision was based after talking to a physician who said it is easier to identify if you have something to compare it to.<\/font><br><br><br>\n\n<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Contents<\/font><\/h4>\n    <\/strong>\n<\/div><br>\n<font size = 3.5 color = \"blue\">\n<li>Importing Packages<\/li><br>\n<li>Importing Data<\/li><br>\n<li>Analysing Data<\/li><br>\n<li>Data Transformation<\/li><br>\n<li>Data Visualization<\/li><br>\n<li>Data Preprocessing<\/li><br>\n<li>Training Models<\/li><br>\n<li>Evaluation Metrics<\/li><br>\n<\/font>","de4e7b6d":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Importing Data<\/font><\/h4>\n    <\/strong>\n<\/div>","7ed97a34":"#### LSTM is not working good on data because we are using a subset of data","b85538a3":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Data Transformation<\/font><\/h4>\n    <\/strong>\n<\/div>","e4cad7b6":"<center><h1 class=\"list-group-item list-group-item-success\">Arrhythmia Detection<\/h1><\/center>","65b74c17":"<div style=\"background:#5990f7;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Long Short Term Memory (LSTM)<\/font><\/h4>\n    <\/strong>\n<\/div>","baf23207":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Data Preprocessing<\/font><\/h4>\n    <\/strong>\n<\/div>","0d59af11":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Evaluation Metrics<\/font><\/h4>\n    <\/strong>\n<\/div>","417d14f2":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Analysing Data<\/font><\/h4>\n    <\/strong>\n<\/div>","54bf3b37":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Data Visualization<\/font><\/h4>\n    <\/strong>\n<\/div>","92cc4b04":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Importing Packages<\/font><\/h4>\n    <\/strong>\n<\/div>","3c850352":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Training Models<\/font><\/h4>\n    <\/strong>\n<\/div>","08481cf6":"### Here we can conclude that Dense Layer Network work good on predicting Arrhythmia \ud83d\ude0a"}}