{"cell_type":{"61c48c36":"code","f456d75d":"code","6083dc65":"code","4c652e17":"code","abe92e87":"code","015daf93":"code","9bdb7154":"code","6ebfa5f3":"code","0528fdc9":"code","dd8d2432":"code","d02e3713":"code","5f863741":"code","bd815ad6":"code","4790eb69":"code","8290680e":"code","99e4d7c6":"code","f7d7b09e":"code","a3975954":"code","7a9d3a65":"code","d0f35a2a":"code","53396ee3":"code","3e46d7f4":"code","b8c6d67a":"code","9f8a9985":"code","20c78a33":"code","97f0e103":"code","8476d37e":"code","6c2c77e9":"code","bcaf91e7":"code","2c0f9a29":"markdown","a0525310":"markdown","359ed279":"markdown","3b82fcdf":"markdown","7292b88c":"markdown","cbd231cc":"markdown","a4eae4be":"markdown","050c6dde":"markdown","10a893d5":"markdown","a681208c":"markdown","b9c88e82":"markdown","f1d2766d":"markdown","afbdd6cc":"markdown","7e7d1eb4":"markdown","ab9c54c7":"markdown","0c4277c1":"markdown","c8f5f641":"markdown","30676b2a":"markdown","d30d86ec":"markdown","5385d3f5":"markdown","65b68db2":"markdown","0dec9ab9":"markdown","d9fc91c0":"markdown","fb1f4110":"markdown","9ba05964":"markdown"},"source":{"61c48c36":"!pip install -q nnAudio\n!pip install  timm","f456d75d":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    print_freq=100\n    num_workers=2\n    model_names=['resnet50d', 'resnext50_32x4d', 'tf_efficientnet_b7_ns' ] \n    resnet50d_dir='..\/input\/ptb-xl-ecg-resnet50d-training\/'\n    resnext50_32x4d_dir='..\/input\/ptb-xl-ecg-resnext50-32x4d-weights\/'\n    batch_size=32\n    gradient_accumulation_steps=1\n    qtransform_params={\"sr\": 2048, \"fmin\": 20, \"fmax\": 1024, \"hop_length\": 32, \"bins_per_octave\": 8}\n    seed=42\n    target_size=5\n    target_col=['CD', 'HYP', 'MI', 'NORM', 'STTC']\n    n_fold=9\n    trn_fold=[1, 2, 3, 4, 5, 6 ,7 ,8, 9] # [0, 1, 2, 3, 4]","6083dc65":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom tqdm.auto import tqdm\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score, roc_curve, f1_score, precision_score, recall_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nfrom nnAudio.Spectrogram import CQT1992v2\n\nimport warnings\n#warnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npd.set_option('max_columns', None)","4c652e17":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred, average='macro')\n    return score\n\ndef find_optimal_cutoff_threshold(target, predicted):\n    \"\"\" \n    Find the optimal probability cutoff point for a classification model related to event rate\n    \"\"\"\n    fpr, tpr, threshold = roc_curve(target, predicted)\n    optimal_idx = np.argmax(tpr - fpr)\n    optimal_threshold = threshold[optimal_idx]\n    return optimal_threshold\n\ndef find_optimal_cutoff_thresholds(y_true, y_pred):\n\treturn [find_optimal_cutoff_threshold(y_true[:,i], y_pred[:,i]) for i in range(y_true.shape[1])]\n\n\ndef get_result(result_df):\n    preds = result_df['preds'].values\n    labels = result_df['target'].values\n    score = get_score(labels, preds)\n    return score\n    \n\ndef apply_thresholds(preds, thresholds):\n\t\"\"\"\n\t\tapply class-wise thresholds to prediction score in order to get binary format.\n\t\tBUT: if no score is above threshold, pick maximum. This is needed due to metric issues.\n\t\"\"\"\n\ttmp = []\n\tfor p in preds:\n\t\ttmp_p = (p > thresholds).astype(int)\n\t\tif np.sum(tmp_p) == 0:\n\t\t\ttmp_p[np.argmax(p)] = 1\n\t\ttmp.append(tmp_p)\n\ttmp = np.array(tmp)\n\treturn tmp\n    \ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","abe92e87":"train = pd.read_csv('..\/input\/ptbxl-ecg-100hz\/ptbxl_ecg_train.csv') \ntest  = pd.read_csv('..\/input\/ptbxl-ecg-100hz\/ptbxl_ecg_test.csv')\n\n\nif CFG.debug:\n    test = test.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)\n    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)\n\n\ndef get_file_paths(filename):\n    filename_lr = filename.split('\/')[-1].split('_')[0]\n    return f\"..\/input\/ptbxl-ecg-100hz\/ptbxl_data_signals100\/{filename_lr}.npy\"\n    \nclean_tags = lambda x: [e.replace(\"'\", \"\")  for e in x[1:-1].split(', ')]\n\ntrain['file_paths'] = train[\"filename_lr\"].apply(get_file_paths)\ntest[\"file_paths\"]  = test[\"filename_lr\"].apply(get_file_paths)\ntrain[\"superdiagnostic\"] = train[\"superdiagnostic\"].apply(clean_tags)\ntest[\"superdiagnostic\"] = test[\"superdiagnostic\"].apply(clean_tags)","015daf93":"from sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\nmlb.fit(test[\"superdiagnostic\"].values)\nmlb.classes_.tolist()\ntrain_labels = mlb.transform(train[\"superdiagnostic\"].tolist())\ntrain[mlb.classes_.tolist()] = train_labels\ny_train = train[CFG.target_col].values\ntest_labels = mlb.transform(test[\"superdiagnostic\"].tolist())\ntest[mlb.classes_.tolist()] = test_labels\ny_test = test[CFG.target_col].values\ndel train_labels, test_labels\n_ = gc.collect()","9bdb7154":"# ====================================================\n# Valid Dataset\n# ====================================================\nclass ValidDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_paths'].values\n        self.labels = df[CFG.target_col].values\n        self.wave_transform = CQT1992v2(**CFG.qtransform_params)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def apply_qtransform(self, waves, transform):\n        waves = np.hstack(waves)\n        waves = waves \/ np.max(waves)\n        waves = torch.from_numpy(waves).float()\n        image = transform(waves)\n        return image\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        waves = np.load(file_path)\n        image = self.apply_qtransform(waves, self.wave_transform)\n        image = image.squeeze().numpy()\n        if self.transform:\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image, label\n\n\n# ====================================================\n# Test Dataset\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_paths'].values\n        self.wave_transform = CQT1992v2(**CFG.qtransform_params)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def apply_qtransform(self, waves, transform):\n        waves = np.hstack(waves)\n        waves = waves \/ np.max(waves)\n        waves = torch.from_numpy(waves).float()\n        image = transform(waves)\n        return image\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        waves = np.load(file_path)\n        image = self.apply_qtransform(waves, self.wave_transform)\n        image = image.squeeze().numpy()\n        if self.transform:\n            image = self.transform(image=image)['image']\n        return image","6ebfa5f3":"# =========================================================\n# Transforms\n# =========================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            ToTensorV2(),\n        ])","0528fdc9":"from matplotlib import pyplot as plt\n\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n\nfor i in range(5):\n    plt.figure(figsize=(16,12))\n    image = test_dataset[i]\n    plt.imshow(image[0])\n    plt.show() ","dd8d2432":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, model_name, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=1)\n        \n        if 'resne' in model_name:\n            self.in_features = self.model.fc.in_features\n            self.model.fc = nn.Linear(self.in_features, self.cfg.target_size)\n            \n        elif 'nfnet' in model_name:\n            self.in_features = self.model.head.fc.in_features\n            self.model.head.fc = nn.Linear(self.in_features, self.cfg.target_size)\n        \n        elif model_name.split('_')[1] == \"efficientnet\":\n            self.n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(self.n_features, self.cfg.target_size)\n            \n        elif model_name.split('_')[0] == 'vit':\n            n_features = self.model.head.in_features\n            self.model.head = nn.Linear(n_features, cfg.target_size, bias=True)\n\n    def forward(self, x):\n        output = self.model(x)\n        return output","d02e3713":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}\/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)\/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","5f863741":"# ====================================================\n# Valid loop\n# ====================================================\ndef valid_loop(folds, fold, dir_model, model_name):\n    \n\n    # loader\n    trn_idx = folds[folds['strat_fold'] != fold].index\n    val_idx = folds[folds['strat_fold'] == fold].index\n\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_col].values\n\n    valid_dataset = ValidDataset(valid_folds, transform=get_transforms(data='valid'))\n\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    # model\n    model_score = CustomModel(CFG, model_name, pretrained=False)\n    state = torch.load(dir_model+f'{model_name}_fold{fold}_best_score.pth')['model']\n    model_score.load_state_dict(state)\n    model_score.to(device)\n    \n    model_loss = CustomModel(CFG, model_name, pretrained=False)\n    state = torch.load(dir_model+f'{model_name}_fold{fold}_best_score.pth')['model']\n    model_loss.load_state_dict(state)\n    model_loss.to(device)\n\n    # loop\n    criterion = nn.BCEWithLogitsLoss()\n \n    oof_score = np.zeros((folds.shape[0], CFG.target_size))\n    oof_loss = np.zeros((folds.shape[0], CFG.target_size))\n    # eval\n    _, preds_score = valid_fn(valid_loader, model_score, criterion, device)\n    _, preds_loss  = valid_fn(valid_loader, model_loss, criterion, device)\n    oof_score[val_idx] = preds_score\n    oof_loss[val_idx]  = preds_loss\n    \n    return oof_score, oof_loss","bd815ad6":"# ====================================================\n# inference\n# ====================================================\ndef inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state['model'])\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n            avg_preds.append(y_preds.sigmoid().to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","4790eb69":"%%time\n# Create new array for valid predictions\noof_resnet50d_score = np.zeros((train.shape[0], CFG.target_size))\noof_resnet50d_loss = np.zeros((train.shape[0], CFG.target_size))\nfor fold in range(1, CFG.n_fold+1):\n    oof_score_, oof_loss_ = valid_loop(train, fold, CFG.resnet50d_dir, CFG.model_names[0])\n    oof_resnet50d_score += oof_score_\n    oof_resnet50d_loss += oof_loss_\n\n# Roc Auc score\nauc_resnet50d_score_oof = get_score(y_train, oof_resnet50d_score)\nauc_resnet50d_loss_oof  = get_score(y_train, oof_resnet50d_loss)\nprint('\\n')\nprint(f\"ROC AUC Score CV (resnet50d_score): {auc_resnet50d_score_oof}\")\nprint(f\"ROC AUC Score CV (resnet50d_loss): {auc_resnet50d_loss_oof}\")\n# Optimal thresholds for each label\noptimal_cutoffs_score = find_optimal_cutoff_thresholds(y_train, oof_resnet50d_score)\noptimal_cutoffs_loss = find_optimal_cutoff_thresholds(y_train, oof_resnet50d_loss)\nresnet50_score_label_oof = apply_thresholds(oof_resnet50d_score, optimal_cutoffs_score)\nresnet50_loss_label_oof = apply_thresholds(oof_resnet50d_loss, optimal_cutoffs_loss)\n# Weighted Scores\nweighted_f1_resnet50_score = f1_score(y_train, resnet50_score_label_oof, average='weighted')\nweighted_f1_resnet50_loss = f1_score(y_train, resnet50_loss_label_oof, average='weighted')\nweighted_precision_resnet50_score = precision_score(y_train, resnet50_score_label_oof, average='weighted')\nweighted_precision_resnet50_loss = precision_score(y_train, resnet50_loss_label_oof, average='weighted')\nweighted_recall_resnet50_score = recall_score(y_train, resnet50_score_label_oof, average='weighted')\nweighted_recall_resnet50_loss = recall_score(y_train, resnet50_loss_label_oof, average='weighted')\n\n# Macro Scores\nmacro_f1_resnet50_score = f1_score(y_train, resnet50_score_label_oof, average='macro')\nmacro_f1_resnet50_loss = f1_score(y_train, resnet50_loss_label_oof, average='macro')\nmacro_precision_resnet50_score = precision_score(y_train, resnet50_score_label_oof, average='macro')\nmacro_precision_resnet50_loss = precision_score(y_train, resnet50_loss_label_oof, average='macro')\nmacro_recall_resnet50_score = recall_score(y_train, resnet50_score_label_oof, average='macro')\nmacro_recall_resnet50_loss = recall_score(y_train, resnet50_loss_label_oof, average='macro')\n\n# Micro Scores\nmicro_f1_resnet50_score = f1_score(y_train, resnet50_score_label_oof, average='micro')\nmicro_f1_resnet50_loss = f1_score(y_train, resnet50_loss_label_oof, average='micro')\nmicro_precision_resnet50_score = precision_score(y_train, resnet50_score_label_oof, average='micro')\nmicro_precision_resnet50_loss = precision_score(y_train, resnet50_loss_label_oof, average='micro')\nmicro_recall_resnet50_score = recall_score(y_train, resnet50_score_label_oof, average='micro')\nmicro_recall_resnet50_loss = recall_score(y_train, resnet50_loss_label_oof, average='micro')\n\nprint('======================== Weighted Scores =========================')\nprint(f\"Weighted F1 Score on CV (resnet50d_score): {weighted_f1_resnet50_score}\")\nprint(f\"Weighted F1 Score on CV (resnet50d_loss): {weighted_f1_resnet50_loss}\")\nprint('\\n')\nprint(f\"Weighted precision Score on CV (resnet50d_score): {weighted_precision_resnet50_score}\")\nprint(f\"Weighted precision Score on CV (resnet50d_loss): {weighted_precision_resnet50_loss}\")\nprint('\\n')\nprint(f\"Weighted recall Score on CV (resnet50d_score): {weighted_recall_resnet50_score}\")\nprint(f\"Weighted recall Score on CV (resnet50d_loss): {weighted_recall_resnet50_loss}\")\nprint('==================================================================')\nprint('\\n')\nprint('======================== Macro Scores =========================')\nprint(f\"Macro F1 Score on CV (resnet50d_score): {macro_f1_resnet50_score}\")\nprint(f\"Macro F1 Score on CV (resnet50d_loss): {macro_f1_resnet50_loss}\")\nprint('\\n')\nprint(f\"Macro precision Score on CV (resnet50d_score): {macro_precision_resnet50_score}\")\nprint(f\"Macro precision Score on CV (resnet50d_loss): {macro_precision_resnet50_loss}\")\nprint('\\n')\nprint(f\"Macro recall Score on CV (resnet50d_score): {macro_recall_resnet50_score}\")\nprint(f\"Macro recall Score on CV (resnet50d_loss): {macro_recall_resnet50_loss}\")\nprint('================================================================')\nprint('\\n')\nprint('======================== Micro Scores =========================')\nprint(f\"Micro F1 Score on CV (resnet50d_score): {micro_f1_resnet50_score}\")\nprint(f\"Micro F1 Score on CV (resnet50d_loss): {micro_f1_resnet50_loss}\")\nprint('\\n')\nprint(f\"Micro precision Score on CV (resnet50d_score): {micro_precision_resnet50_score}\")\nprint(f\"Micro precision Score on CV (resnet50d_loss): {micro_precision_resnet50_loss}\")\nprint('\\n')\nprint(f\"Micro recall Score on CV (resnet50d_score): {micro_recall_resnet50_score}\")\nprint(f\"Micro recall Score on CV (resnet50d_loss): {micro_recall_resnet50_loss}\")\nprint('===============================================================')","8290680e":"resnet50d = CustomModel(CFG, CFG.model_names[0], pretrained=False)\nscore_states = [torch.load(CFG.resnet50d_dir+f'{CFG.model_names[0]}_fold{fold}_best_score.pth') for fold in CFG.trn_fold]\nloss_states  = [torch.load(CFG.resnet50d_dir+f'{CFG.model_names[0]}_fold{fold}_best_loss.pth') for fold in CFG.trn_fold]\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\nresnet50d_score_predictions = inference(resnet50d, score_states, test_loader, device)\nresnet50d_loss_predictions = inference(resnet50d, loss_states, test_loader, device)","99e4d7c6":"auc_resnet50d_score = get_score(y_test, resnet50d_score_predictions)\nauc_resnet50d_loss  = get_score(y_test, resnet50d_loss_predictions)\nprint(f\"ROC AUC Score on test set (resnet50d_score): {auc_resnet50d_score}\")\nprint(f\"ROC AUC Score on test set (resnet50d_loss): {auc_resnet50d_loss}\")","f7d7b09e":"# Optimal thresholds for each label\noptimal_cutoffs_score = find_optimal_cutoff_thresholds(y_test, resnet50d_score_predictions)\noptimal_cutoffs_loss = find_optimal_cutoff_thresholds(y_test, resnet50d_loss_predictions)\nresnet50_score_label = apply_thresholds(resnet50d_score_predictions, optimal_cutoffs_score)\nresnet50_loss_label = apply_thresholds(resnet50d_loss_predictions, optimal_cutoffs_loss)\n# Weighted Scores\nweighted_f1_resnet50_score = f1_score(y_test, resnet50_score_label, average='weighted')\nweighted_f1_resnet50_loss = f1_score(y_test, resnet50_loss_label, average='weighted')\nweighted_precision_resnet50_score = precision_score(y_test, resnet50_score_label, average='weighted')\nweighted_precision_resnet50_loss = precision_score(y_test, resnet50_loss_label, average='weighted')\nweighted_recall_resnet50_score = recall_score(y_test, resnet50_score_label, average='weighted')\nweighted_recall_resnet50_loss = recall_score(y_test, resnet50_loss_label, average='weighted')\n\n# Macro Scores\nmacro_f1_resnet50_score = f1_score(y_test, resnet50_score_label, average='macro')\nmacro_f1_resnet50_loss = f1_score(y_test, resnet50_loss_label, average='macro')\nmacro_precision_resnet50_score = precision_score(y_test, resnet50_score_label, average='macro')\nmacro_precision_resnet50_loss = precision_score(y_test, resnet50_loss_label, average='macro')\nmacro_recall_resnet50_score = recall_score(y_test, resnet50_score_label, average='macro')\nmacro_recall_resnet50_loss = recall_score(y_test, resnet50_loss_label, average='macro')\n\n# Micro Scores\nmicro_f1_resnet50_score = f1_score(y_test, resnet50_score_label, average='micro')\nmicro_f1_resnet50_loss = f1_score(y_test, resnet50_loss_label, average='micro')\nmicro_precision_resnet50_score = precision_score(y_test, resnet50_score_label, average='micro')\nmicro_precision_resnet50_loss = precision_score(y_test, resnet50_loss_label, average='micro')\nmicro_recall_resnet50_score = recall_score(y_test, resnet50_score_label, average='micro')\nmicro_recall_resnet50_loss = recall_score(y_test, resnet50_loss_label, average='micro')\n\nprint('======================== Weighted Scores =========================')\nprint(f\"Weighted F1 Score on test set (resnet50d_score): {weighted_f1_resnet50_score}\")\nprint(f\"Weighted F1 Score on test set (resnet50d_loss): {weighted_f1_resnet50_loss}\")\nprint('\\n')\nprint(f\"Weighted precision Score on test set (resnet50d_score): {weighted_precision_resnet50_score}\")\nprint(f\"Weighted precision Score on test set (resnet50d_loss): {weighted_precision_resnet50_loss}\")\nprint('\\n')\nprint(f\"Weighted recall Score on test set (resnet50d_score): {weighted_recall_resnet50_score}\")\nprint(f\"Weighted recall Score on test set (resnet50d_loss): {weighted_recall_resnet50_loss}\")\nprint('==================================================================')\nprint('\\n')\nprint('======================== Macro Scores =========================')\nprint(f\"Macro F1 Score on test set (resnet50d_score): {macro_f1_resnet50_score}\")\nprint(f\"Macro F1 Score on test set (resnet50d_loss): {macro_f1_resnet50_loss}\")\nprint('\\n')\nprint(f\"Macro precision Score on test set (resnet50d_score): {macro_precision_resnet50_score}\")\nprint(f\"Macro precision Score on test set (resnet50d_loss): {macro_precision_resnet50_loss}\")\nprint('\\n')\nprint(f\"Macro recall Score on test set (resnet50d_score): {macro_recall_resnet50_score}\")\nprint(f\"Macro recall Score on test set (resnet50d_loss): {macro_recall_resnet50_loss}\")\nprint('================================================================')\nprint('\\n')\nprint('======================== Micro Scores =========================')\nprint(f\"Micro F1 Score on test set (resnet50d_score): {micro_f1_resnet50_score}\")\nprint(f\"Micro F1 Score on test set (resnet50d_loss): {micro_f1_resnet50_loss}\")\nprint('\\n')\nprint(f\"Micro precision Score on test set (resnet50d_score): {micro_precision_resnet50_score}\")\nprint(f\"Micro precision Score on test set (resnet50d_loss): {micro_precision_resnet50_loss}\")\nprint('\\n')\nprint(f\"Micro recall Score on test set (resnet50d_score): {micro_recall_resnet50_score}\")\nprint(f\"Micro recall Score on test set (resnet50d_loss): {micro_recall_resnet50_loss}\")\nprint('===============================================================')","a3975954":"df_resnet50d = pd.DataFrame(data=resnet50_score_label)\ndf_resnet50d.columns = ['CD', 'HYP', 'MI', 'NORM', 'STTC']\ndf_resnet50d['color_tags'] = df_resnet50d.values.tolist()\ndf_resnet50d[\"color_tags\"] = df_resnet50d[\"color_tags\"].apply(lambda x : [int(element) for element in x] )\nres50d_predict_colors = df_resnet50d[\"color_tags\"].copy()\nliste_colors = df_resnet50d.columns.values\nfor i, liste in enumerate(res50d_predict_colors):\n    liste_string = []\n    for j in range(len(liste)) : \n        if liste[j] == 1: \n            liste_string.append(liste_colors[j])\n    res50d_predict_colors[i] = liste_string\nres50d_predict_colors.head()\ntest['res50d_predictions'] = res50d_predict_colors","7a9d3a65":"test[['patient_id', 'res50d_predictions', 'superdiagnostic']].head(30)","d0f35a2a":"%%time\n# Create new array for valid predictions\noof_resnext50_32x4d_score = np.zeros((train.shape[0], CFG.target_size))\noof_resnext50_32x4d_loss = np.zeros((train.shape[0], CFG.target_size))\nfor fold in range(1, CFG.n_fold+1):\n    oof_score_, oof_loss_ = valid_loop(train, fold, CFG.resnext50_32x4d_dir, CFG.model_names[1])\n    oof_resnext50_32x4d_score += oof_score_\n    oof_resnext50_32x4d_loss += oof_loss_\n\n# Roc Auc score\nauc_resnext50_32x4d_score_oof = get_score(y_train, oof_resnext50_32x4d_score)\nauc_resnext50_32x4d_loss_oof  = get_score(y_train, oof_resnext50_32x4d_loss)\nprint('\\n')\nprint(f\"ROC AUC Score CV (resnext50_32x4d_score): {auc_resnext50_32x4d_score_oof}\")\nprint(f\"ROC AUC Score CV (resnext50_32x4d_loss): {auc_resnext50_32x4d_loss_oof}\")\n# Optimal thresholds for each label\noptimal_cutoffs_score = find_optimal_cutoff_thresholds(y_train, oof_resnext50_32x4d_score)\noptimal_cutoffs_loss = find_optimal_cutoff_thresholds(y_train, oof_resnext50_32x4d_loss)\nresnext50_32x4d_score_label_oof = apply_thresholds(oof_resnext50_32x4d_score, optimal_cutoffs_score)\nresnext50_32x4d_loss_label_oof = apply_thresholds(oof_resnext50_32x4d_loss, optimal_cutoffs_loss)\n# Weighted Scores\nweighted_f1_resnext50_32x4d_score = f1_score(y_train, resnext50_32x4d_score_label_oof, average='weighted')\nweighted_f1_resnext50_32x4d_loss = f1_score(y_train, resnext50_32x4d_loss_label_oof, average='weighted')\nweighted_precision_resnext50_32x4d_score = precision_score(y_train, resnext50_32x4d_score_label_oof, average='weighted')\nweighted_precision_resnext50_32x4d_loss = precision_score(y_train, resnext50_32x4d_loss_label_oof, average='weighted')\nweighted_recall_resnext50_32x4d_score = recall_score(y_train, resnext50_32x4d_score_label_oof, average='weighted')\nweighted_recall_resnext50_32x4d_loss = recall_score(y_train, resnext50_32x4d_loss_label_oof, average='weighted')\n\n# Macro Scores\nmacro_f1_resnext50_32x4d_score = f1_score(y_train, resnext50_32x4d_score_label_oof, average='macro')\nmacro_f1_resnext50_32x4d_loss = f1_score(y_train, resnext50_32x4d_loss_label_oof, average='macro')\nmacro_precision_resnext50_32x4d_score = precision_score(y_train, resnext50_32x4d_score_label_oof, average='macro')\nmacro_precision_resnext50_32x4d_loss = precision_score(y_train, resnext50_32x4d_loss_label_oof, average='macro')\nmacro_recall_resnext50_32x4d_score = recall_score(y_train, resnext50_32x4d_score_label_oof, average='macro')\nmacro_recall_resnext50_32x4d_loss = recall_score(y_train, resnext50_32x4d_loss_label_oof, average='macro')\n\n# Micro Scores\nmicro_f1_resnext50_32x4d_score = f1_score(y_train, resnext50_32x4d_score_label_oof, average='micro')\nmicro_f1_resnext50_32x4d_loss = f1_score(y_train, resnext50_32x4d_loss_label_oof, average='micro')\nmicro_precision_resnext50_32x4d_score = precision_score(y_train, resnext50_32x4d_score_label_oof, average='micro')\nmicro_precision_resnext50_32x4d_loss = precision_score(y_train, resnext50_32x4d_loss_label_oof, average='micro')\nmicro_recall_resnext50_32x4d_score = recall_score(y_train, resnext50_32x4d_score_label_oof, average='micro')\nmicro_recall_resnext50_32x4d_loss = recall_score(y_train, resnext50_32x4d_loss_label_oof, average='micro')\n\nprint('======================== Weighted Scores =========================')\nprint(f\"Weighted F1 Score on CV (resnext50_32x4d_score): {weighted_f1_resnext50_32x4d_score}\")\nprint(f\"Weighted F1 Score on CV (resnext50_32x4d_loss): {weighted_f1_resnext50_32x4d_loss}\")\nprint('\\n')\nprint(f\"Weighted precision Score on CV (resnext50_32x4d_score): {weighted_precision_resnext50_32x4d_score}\")\nprint(f\"Weighted precision Score on CV (resnext50_32x4d_loss): {weighted_precision_resnext50_32x4d_loss}\")\nprint('\\n')\nprint(f\"Weighted recall Score on CV (resnext50_32x4d_score): {weighted_recall_resnext50_32x4d_score}\")\nprint(f\"Weighted recall Score on CV (resnext50_32x4d_loss): {weighted_recall_resnext50_32x4d_loss}\")\nprint('==================================================================')\nprint('\\n')\nprint('======================== Macro Scores =========================')\nprint(f\"Macro F1 Score on CV (resnext50_32x4d_score): {macro_f1_resnext50_32x4d_score}\")\nprint(f\"Macro F1 Score on CV (resnext50_32x4d_loss): {macro_f1_resnext50_32x4d_loss}\")\nprint('\\n')\nprint(f\"Macro precision Score on CV (resnext50_32x4d_score): {macro_precision_resnext50_32x4d_score}\")\nprint(f\"Macro precision Score on CV (resnext50_32x4d_loss): {macro_precision_resnext50_32x4d_loss}\")\nprint('\\n')\nprint(f\"Macro recall Score on CV (resnext50_32x4d_score): {macro_recall_resnext50_32x4d_score}\")\nprint(f\"Macro recall Score on CV (resnext50_32x4d_loss): {macro_recall_resnext50_32x4d_loss}\")\nprint('================================================================')\nprint('\\n')\nprint('======================== Micro Scores =========================')\nprint(f\"Micro F1 Score on CV (resnext50_32x4d_score): {micro_f1_resnext50_32x4d_score}\")\nprint(f\"Micro F1 Score on CV (resnext50_32x4d_loss): {micro_f1_resnext50_32x4d_loss}\")\nprint('\\n')\nprint(f\"Micro precision Score on CV (resnext50_32x4d_score): {micro_precision_resnext50_32x4d_score}\")\nprint(f\"Micro precision Score on CV (resnext50_32x4d_loss): {micro_precision_resnext50_32x4d_loss}\")\nprint('\\n')\nprint(f\"Micro recall Score on CV (resnext50_32x4d_score): {micro_recall_resnext50_32x4d_score}\")\nprint(f\"Micro recall Score on CV (resnext50_32x4d_loss): {micro_recall_resnext50_32x4d_loss}\")\nprint('===============================================================')","53396ee3":"resnext50_32x4d = CustomModel(CFG, CFG.model_names[1], pretrained=False)\nscore_states = [torch.load(CFG.resnext50_32x4d_dir+f'{CFG.model_names[1]}_fold{fold}_best_score.pth') for fold in CFG.trn_fold]\nloss_states  = [torch.load(CFG.resnext50_32x4d_dir+f'{CFG.model_names[1]}_fold{fold}_best_loss.pth') for fold in CFG.trn_fold]\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\nresnext50_32x4d_score_predictions = inference(resnext50_32x4d, score_states, test_loader, device)\nresnext50_32x4d_loss_predictions = inference(resnext50_32x4d, loss_states, test_loader, device)","3e46d7f4":"auc_resnext50_32x4d_score = get_score(y_test, resnext50_32x4d_score_predictions)\nauc_resnext50_32x4d_loss  = get_score(y_test, resnext50_32x4d_loss_predictions)\nprint(f\"ROC AUC Score on test set (resnext50_32x4d_score): {auc_resnext50_32x4d_score}\")\nprint(f\"ROC AUC Score on test set (resnext50_32x4d_loss): {auc_resnext50_32x4d_loss}\")","b8c6d67a":"# Optimal thresholds for each label\noptimal_cutoffs_score = find_optimal_cutoff_thresholds(y_test, resnext50_32x4d_score_predictions)\noptimal_cutoffs_loss = find_optimal_cutoff_thresholds(y_test, resnext50_32x4d_loss_predictions)\nresnext50_32x4d_score_label = apply_thresholds(resnext50_32x4d_score_predictions, optimal_cutoffs_score)\nresnext50_32x4d_loss_label = apply_thresholds(resnext50_32x4d_loss_predictions, optimal_cutoffs_loss)\n# Weighted Scores\nweighted_f1_resnext50_32x4d_score = f1_score(y_test, resnext50_32x4d_score_label, average='weighted')\nweighted_f1_resnext50_32x4d_loss = f1_score(y_test, resnext50_32x4d_loss_label, average='weighted')\nweighted_precision_resnext50_32x4d_score = precision_score(y_test, resnext50_32x4d_score_label, average='weighted')\nweighted_precision_resnext50_32x4d_loss = precision_score(y_test, resnext50_32x4d_loss_label, average='weighted')\nweighted_recall_resnext50_32x4d_score = recall_score(y_test, resnext50_32x4d_score_label, average='weighted')\nweighted_recall_resnext50_32x4d_loss = recall_score(y_test, resnext50_32x4d_loss_label, average='weighted')\n\n# Macro Scores\nmacro_f1_resnext50_32x4d_score = f1_score(y_test, resnext50_32x4d_score_label, average='macro')\nmacro_f1_resnext50_32x4d_loss = f1_score(y_test, resnext50_32x4d_loss_label, average='macro')\nmacro_precision_resnext50_32x4d_score = precision_score(y_test, resnext50_32x4d_score_label, average='macro')\nmacro_precision_resnext50_32x4d_loss = precision_score(y_test, resnext50_32x4d_loss_label, average='macro')\nmacro_recall_resnext50_32x4d_score = recall_score(y_test, resnext50_32x4d_score_label, average='macro')\nmacro_recall_resnext50_32x4d_loss = recall_score(y_test, resnext50_32x4d_loss_label, average='macro')\n\n# Micro Scores\nmicro_f1_resnext50_32x4d_score = f1_score(y_test, resnext50_32x4d_score_label, average='micro')\nmicro_f1_resnext50_32x4d_loss = f1_score(y_test, resnext50_32x4d_loss_label, average='micro')\nmicro_precision_resnext50_32x4d_score = precision_score(y_test, resnext50_32x4d_score_label, average='micro')\nmicro_precision_resnext50_32x4d_loss = precision_score(y_test, resnext50_32x4d_loss_label, average='micro')\nmicro_recall_resnext50_32x4d_score = recall_score(y_test, resnext50_32x4d_score_label, average='micro')\nmicro_recall_resnext50_32x4d_loss = recall_score(y_test, resnext50_32x4d_loss_label, average='micro')\n\nprint('======================== Weighted Scores =========================')\nprint(f\"Weighted F1 Score on test set (resnext50_32x4d_score): {weighted_f1_resnext50_32x4d_score}\")\nprint(f\"Weighted F1 Score on test set (resnext50_32x4d_loss): {weighted_f1_resnext50_32x4d_loss}\")\nprint(f\"Weighted precision Score on test set (resnext50_32x4d_score): {weighted_precision_resnext50_32x4d_score}\")\nprint(f\"Weighted precision Score on test set (resnext50_32x4d_loss): {weighted_precision_resnext50_32x4d_loss}\")\nprint(f\"Weighted recall Score on test set (resnext50_32x4d_score): {weighted_recall_resnext50_32x4d_score}\")\nprint(f\"Weighted recall Score on test set (resnext50_32x4d_loss): {weighted_recall_resnext50_32x4d_loss}\")\nprint('==================================================================')\nprint('\\n')\nprint('======================== Macro Scores =========================')\nprint(f\"Macro F1 Score on test set (resnext50_32x4d_score): {macro_f1_resnext50_32x4d_score}\")\nprint(f\"Macro F1 Score on test set (resnext50_32x4d_loss): {macro_f1_resnext50_32x4d_loss}\")\nprint(f\"Macro precision Score on test set (resnext50_32x4d_score): {macro_precision_resnext50_32x4d_score}\")\nprint(f\"Macro precision Score on test set (resnext50_32x4d_loss): {macro_precision_resnext50_32x4d_loss}\")\nprint(f\"Macro recall Score on test set (resnext50_32x4d_score): {macro_recall_resnext50_32x4d_score}\")\nprint(f\"Macro recall Score on test set (resnext50_32x4d_loss): {macro_recall_resnext50_32x4d_loss}\")\nprint('===============================================================')\nprint('\\n')\nprint('======================== Micro Scores =========================')\nprint(f\"Micro F1 Score n test set (resnext50_32x4d_score): {micro_f1_resnext50_32x4d_score}\")\nprint(f\"Micro F1 Score on test set (resnext50_32x4d_loss): {micro_f1_resnext50_32x4d_loss}\")\nprint(f\"Micro precision Score n test set (resnext50_32x4d_score): {micro_precision_resnext50_32x4d_score}\")\nprint(f\"Micro precision Score on test set (resnext50_32x4d_loss): {micro_precision_resnext50_32x4d_loss}\")\nprint(f\"Micro recall Score n test set (resnext50_32x4d_score): {micro_recall_resnext50_32x4d_score}\")\nprint(f\"Micro recall Score on test set (resnext50_32x4d_loss): {micro_recall_resnext50_32x4d_loss}\")\nprint('===============================================================')","9f8a9985":"#efficientnet7 = CustomModel(CFG, CFG.model_names[2], pretrained=False)\n#score_states = [torch.load(CFG.efficientnet7_dir+f'{CFG.model_names[2]}_fold{fold}_best_score.pth') for fold in CFG.trn_fold]\n#loss_states  = [torch.load(CFG.efficientnet7_dir+f'{CFG.model_names[2]}_fold{fold}_best_loss.pth') for fold in CFG.trn_fold]\n#test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n#test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n#                         num_workers=CFG.num_workers, pin_memory=True)\n#efficient7_score_predictions = inference(efficientnet7, score_states, test_loader, device)\n#efficient7_loss_predictions = inference(efficientnet7, loss_states, test_loader, device)","20c78a33":"#auc_efficientnet7_score = get_score(y_test, efficientnet7_score_predictions)\n#auc_efficientnet7_loss  = get_score(y_test, efficientnet7_loss_predictions)\n#print(f\"ROC AUC Score on test set (efficientnet7_score): {auc_efficientnet7_score}\")\n#print(f\"ROC AUC Score on test set (efficientnet7_loss): {auc_efficientnet7_loss}\")","97f0e103":"# Optimal thresholds for each label\n#optimal_cutoffs_score = find_optimal_cutoff_thresholds(y_test, efficientnet7_score_predictions)\n#optimal_cutoffs_loss = find_optimal_cutoff_thresholds(y_test, efficientnet7_loss_predictions)\n#efficientnet7_score_label = apply_thresholds(auc_efficientnet7_score, optimal_cutoffs_score)\n#efficientnet7_loss_label = apply_thresholds(auc_efficientnet7_loss, optimal_cutoffs_loss)\n#weighted_f1_efficientnet7_score = f1_score(y_test, efficientnet7_score_label, average='weighted')\n#weighted_f1_efficientnet7_loss = f1_score(y_test, efficientnet7_loss_label, average='weighted')\n#macro_f1_efficientnet7_score = f1_score(y_test, efficientnet7_score_label, average='macro')\n#macro_f1_efficientnet7_loss = f1_score(y_test, efficientnet7_loss_label, average='macro')\n#micro_f1_efficientnet7_score = f1_score(y_test, efficientnet7_score_label, average='micro')\n#micro_f1_efficientnet7_loss = f1_score(y_test, efficientnet7_loss_label, average='micro')\n#print(f\"Weighted F1 Score on test set (efficientnet7_score): {weighted_f1_efficientnet7_score}\")\n#print(f\"Weighted F1 Score on test set (efficientnet7_loss): {weighted_f1_efficientnet7_loss}\")\n#print(f\"Macro F1 Score on test set (efficientnet7_score): {macro_f1_efficientnet7_score}\")\n#print(f\"Macro F1 Score on test set (efficientnet7_loss): {macro_f1_efficientnet7_loss}\")\n#print(f\"Micro F1 Score on test set (efficientnet7_score): {micro_f1_efficientnet7_score}\")\n#print(f\"Micro F1 Score on test set (efficientnet7_loss): {micro_f1_efficientnet7_loss}\")","8476d37e":"ensemble_score_predictions = 0.7 * resnet50d_score_predictions + 0.3 * resnext50_32x4d_score_predictions \nensemble_loss_predictions  = 0.7 * resnet50d_loss_predictions  + 0.3 * resnext50_32x4d_loss_predictions ","6c2c77e9":"auc_ensemble_score = get_score(y_test, ensemble_score_predictions)\nauc_ensemble_loss  = get_score(y_test, ensemble_loss_predictions)\nprint(f\"ROC AUC Score on test set (ensemble_score): {auc_ensemble_score}\")\nprint(f\"ROC AUC Score on test set (ensemble_loss): {auc_ensemble_loss}\")","bcaf91e7":"# Optimal thresholds for each label\noptimal_cutoffs_score = find_optimal_cutoff_thresholds(y_test, ensemble_score_predictions)\noptimal_cutoffs_loss = find_optimal_cutoff_thresholds(y_test, ensemble_loss_predictions)\nensemble_score_label = apply_thresholds(ensemble_score_predictions, optimal_cutoffs_score)\nensemble_loss_label = apply_thresholds(ensemble_loss_predictions, optimal_cutoffs_loss)\n# Weighted Scores\nweighted_f1_ensemble_score = f1_score(y_test, ensemble_score_label, average='weighted')\nweighted_f1_ensemble_loss = f1_score(y_test, ensemble_loss_label, average='weighted')\nweighted_precision_ensemble_score = precision_score(y_test, ensemble_score_label, average='weighted')\nweighted_precision_ensemble_loss = precision_score(y_test, ensemble_loss_label, average='weighted')\nweighted_recall_ensemble_score = recall_score(y_test, ensemble_score_label, average='weighted')\nweighted_recall_ensemble_loss = recall_score(y_test, ensemble_loss_label, average='weighted')\n\n# Macro Scores\nmacro_f1_ensemble_score = f1_score(y_test, ensemble_score_label, average='macro')\nmacro_f1_ensemble_loss = f1_score(y_test, ensemble_loss_label, average='macro')\nmacro_precision_ensemble_score = precision_score(y_test, ensemble_score_label, average='macro')\nmacro_precision_ensemble_loss = precision_score(y_test, ensemble_loss_label, average='macro')\nmacro_recall_ensemble_score = recall_score(y_test, ensemble_score_label, average='macro')\nmacro_recall_ensemble_loss = recall_score(y_test, ensemble_loss_label, average='macro')\n\n# Micro Scores\nmicro_f1_ensemble_score = f1_score(y_test, ensemble_score_label, average='micro')\nmicro_f1_ensemble_loss = f1_score(y_test, ensemble_loss_label, average='micro')\nmicro_precision_ensemble_score = precision_score(y_test, ensemble_score_label, average='micro')\nmicro_precision_ensemble_loss = precision_score(y_test, ensemble_loss_label, average='micro')\nmicro_recall_ensemble_score = recall_score(y_test, ensemble_score_label, average='micro')\nmicro_recall_ensemble_loss = recall_score(y_test, ensemble_loss_label, average='micro')\n\nprint('======================== Weighted Scores ==========================')\nprint(f\"Weighted F1 Score on test set (ensemble_score): {weighted_f1_ensemble_score}\")\nprint(f\"Weighted F1 Score on test set (ensemble_loss): {weighted_f1_ensemble_loss}\")\nprint(f\"Weighted precision Score on test set (ensemble_score): {weighted_precision_ensemble_score}\")\nprint(f\"Weighted precision Score on test set (ensemble_loss): {weighted_precision_ensemble_loss}\")\nprint(f\"Weighted recall Score on test set (ensemble_score): {weighted_recall_ensemble_score}\")\nprint(f\"Weighted recall Score on test set (ensemble_loss): {weighted_recall_ensemble_loss}\")\nprint('===================================================================')\nprint('\\n')\nprint('======================== Macro Scores ===========================')\nprint(f\"Macro F1 Score on test set (ensemble_score): {macro_f1_ensemble_score}\")\nprint(f\"Macro F1 Score on test set (ensemble_loss): {macro_f1_ensemble_loss}\")\nprint(f\"Macro precision Score on test set (ensemble_score): {macro_precision_ensemble_score}\")\nprint(f\"Macro precision Score on test set (ensemble_loss): {macro_precision_ensemble_loss}\")\nprint(f\"Macro recall Score on test set (ensemble_score): {macro_recall_ensemble_score}\")\nprint(f\"Macro recall Score on test set (ensemble_loss): {macro_recall_ensemble_loss}\")\nprint('=================================================================')\nprint('\\n')\nprint('======================== Micro Scores ===========================')\nprint(f\"Micro F1 Score n test set (ensemble_score): {micro_f1_ensemble_score}\")\nprint(f\"Micro F1 Score on test set (ensemble_loss): {micro_f1_ensemble_loss}\")\nprint(f\"Micro precision Score n test set (ensemble_score): {micro_precision_ensemble_score}\")\nprint(f\"Micro precision Score on test set (ensemble_loss): {micro_precision_ensemble_loss}\")\nprint(f\"Micro recall Score n test set (ensemble_score): {micro_recall_ensemble_score}\")\nprint(f\"Micro recall Score on test set (ensemble_loss): {micro_recall_ensemble_loss}\")\nprint('=================================================================')","2c0f9a29":"### F1 Score on test Ensemble","a0525310":"# inference","359ed279":"### ROC AUC Score on test set for resnet50d","3b82fcdf":"### F1 Score on test set for resnet50d","7292b88c":"# Validation","cbd231cc":"# Data Loading","a4eae4be":"# CFG","050c6dde":"## Validation Resnet50d","10a893d5":"# Validation Loop","a681208c":"# Dataset","b9c88e82":"# Transform predictions to labels resnet50d","f1d2766d":"## Resnext50_30x4d Inference","afbdd6cc":"### ROC AUC Score on test set for Efficientnet7","7e7d1eb4":"# Data Preprocessing","ab9c54c7":"### Roc Auc score on test Ensemble","0c4277c1":"## Resnet50d Inference","c8f5f641":"## Ensemble models","30676b2a":"# Library","d30d86ec":"# Transforms","5385d3f5":"### F1 Score on test set for resnext50_32x4d","65b68db2":"### ROC AUC Score on test set for resnext50_32x4d","0dec9ab9":"## Validation Resnext50_30x4d","d9fc91c0":"### F1 Score on test set for Efficientnet7","fb1f4110":"## Efficientnet7 Inference","9ba05964":"# Utils"}}