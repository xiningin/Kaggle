{"cell_type":{"9d979043":"code","3c1281c1":"code","915ec42a":"code","93fe6594":"code","1a6cd078":"code","fe74100e":"code","57971954":"code","22fd4bb7":"code","ed11d288":"code","d9224017":"code","21fdc874":"code","06f67bb4":"code","17b8373c":"code","58b38948":"code","6ac8f22d":"code","da891a33":"code","a6e85b1e":"code","d929c676":"code","fe8d5673":"code","257c4126":"code","6bd282f4":"code","838ce0b4":"code","86401ccf":"code","b6e69518":"code","6dca96a0":"markdown","d023ed73":"markdown","e3ec4321":"markdown","7c562768":"markdown","65de9839":"markdown","7fd7f26a":"markdown","cd004056":"markdown","c6b490ab":"markdown","6f79d531":"markdown","571182a8":"markdown","1e982323":"markdown","b1475b25":"markdown","05ea5fd0":"markdown","500b5e53":"markdown","064d655a":"markdown","629bc8ab":"markdown","70e33a72":"markdown","721cedcf":"markdown","a5cf8768":"markdown","8a0104cf":"markdown","e0de846f":"markdown","02f9b2ee":"markdown","93ad055b":"markdown","6b2604ca":"markdown","1505e8a5":"markdown","36fbf644":"markdown","5205a463":"markdown","af6ec6f6":"markdown","04260973":"markdown","2620862e":"markdown"},"source":{"9d979043":"# load libraries for data manipulation\nimport numpy as np\nimport pandas as pd\n# load visualization libraries\nimport matplotlib.pyplot as plt\nplt.style.use('classic')\n%matplotlib inline\nimport seaborn as sb\nsb.set()\n# load modelling libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.model_selection import  cross_val_score\n# warnings\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')","3c1281c1":"# load the train and test data sets\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain_len = len(train)\n# combine train and test data sets\ndata_all = train.append(test, sort=False, ignore_index=True)\n# no. of missing values \ndata_all.isnull().sum()","915ec42a":"# impute missing values\ndata_all['Age'] = data_all.groupby(['Pclass', 'Sex'])['Age'].apply(lambda x: x.fillna(x.median()))\ndata_all['Fare'] = data_all.groupby('Pclass')['Fare'].apply(lambda x: x.fillna(x.median()))\ndata_all['Embarked'] = data_all['Embarked'].fillna('S')# internet search indicate 2 passengers from Southampton","93fe6594":"bar = sb.barplot(x='Pclass', y='Survived' , data=data_all)","1a6cd078":"# convert Pclass to ordinal rank\ndata_all['Pclass'].replace([1, 2, 3], [3, 2, 1],inplace=True)","fe74100e":"scatter = sb.regplot(x='Age', y='Survived', data=data_all)","57971954":"scatter = sb.lmplot(x='Age', y='Survived',  data=data_all, hue='Sex')","22fd4bb7":"# create age bins as Infant 1, Children 2, Adults 3 and Elderly 4.\ndata_all['Age'] = pd.cut(data_all.Age, bins=[0,2,17,65,99], labels=[1, 2, 3, 4]).astype(str)\ndata_all['Sex'].replace(['female', 'male'], ['F', 'M'],inplace=True)\ndata_all['SexAge'] = data_all['Sex'] + data_all['Age']\nbar = sb.barplot(x='SexAge', y='Survived' , data=data_all)","ed11d288":"scatter = sb.regplot(x='Fare', y='Survived', data=data_all)","d9224017":"# create Fare bins as Low 1, 1stQuartile-median 2, median-3rdQuartile 3, High 4.\ndata_all['Fare'] = pd.cut(data_all.Fare, bins=[-1.0,7.8958,14.4542,31.2750,512.3292], labels=[1, 2, 3, 4]).astype(int)\nbar = sb.barplot(x='Fare', y='Survived' , data=data_all)","21fdc874":"bar = sb.barplot(x='Embarked', y='Survived' , data=data_all)","06f67bb4":"# add the columns SibSp and Parch to create FamilySize\ndata_all['FamilySize'] = data_all['SibSp'] + data_all['Parch'] + 1\n# add families with 4 or more members together\nfor i in  np.where(pd.notnull(data_all.FamilySize) & (data_all['FamilySize'] >  3 )  ):\n    data_all.at[i, 'FamilySize'] = 4\nbar = sb.barplot(x='FamilySize', y='Survived' , data=data_all)","17b8373c":"bar = sb.barplot(x='Sex', y='Survived' , data=data_all)","58b38948":"# extracting titles and storing in Title field\nfor i in data_all:\n    data_all['Title'] = [x[1].split(\".\")[0].strip(\" \") for x in data_all['Name'].str.split(\",\")]\n\nprint(pd.crosstab(data_all['Title'], data_all['Sex']))","6ac8f22d":"# reducing the titles to Mr, Mrs, Master and Miss\nfor i in data_all:\n    data_all['Title'] = data_all['Title'].replace(['Capt', 'Col', 'Don', 'Major', 'Rev', 'Sir', 'Jonkheer'], 'Mr')\n    data_all['Title'] = data_all['Title'].replace(['Mlle', 'Ms'], 'Miss')\n    data_all['Title'] = data_all['Title'].replace(['Dona', 'Lady', 'the Countess', 'Mme'], 'Mrs')\nfor i in np.where(pd.notnull(data_all.Title) & (data_all['Title'] ==  'Dr') & (data_all['Sex'] == 'M' )  ):\n     data_all.at[i, 'Title'] = 'Mr'\nfor i in np.where(pd.notnull(data_all.Title) & (data_all['Title'] ==  'Dr') & (data_all['Sex'] == 'F' )  ):\n     data_all.at[i, 'Title'] = 'Mrs'\nbar = sb.barplot(x='Title', y='Survived' , data=data_all)","da891a33":"# check correlation of numeric features with the target\ndata_all_corr = data_all.corr().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\ndata_all_corr.rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation Coefficient'}, inplace=True)\ndata_all_corr[data_all_corr['Feature 1'] == 'Survived']","a6e85b1e":"numeric = ['Pclass', 'Fare', 'FamilySize']\ndata_num = data_all[numeric]","d929c676":"categorical = ['SexAge', 'Embarked', 'Sex', 'Title']\ndata_cat = data_all[categorical]\ndata_cat = pd.get_dummies(data_cat)","fe8d5673":"y = train.Survived\ndf_all = pd.concat([data_num, data_cat], axis = 1)\nfeatures = (data_num.columns).append(data_cat.columns)\ndf_train = df_all[:891]\ndf_test = df_all[891:]\ntarget = 'Survived'\nX = df_train[features]\nX_test = df_test[features]","257c4126":"from sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits=5)\ndef auc_cv(model):\n    roc_auc = cross_val_score(model, X, y, scoring='roc_auc', cv=kfold)\n    return (roc_auc)","6bd282f4":"# LogisticRegression CV and model fitting\nlogreg2 = LogisticRegression(C = .4, penalty='l2')\nauc_cv_logreg = auc_cv(logreg2)\nlogreg2.fit(X, y)\nprint('LogisticRegression CV score min: ' + str(auc_cv_logreg.min()) + ' mean: ' + str(auc_cv_logreg.mean()) \n      + ' max: ' + str(auc_cv_logreg.max()) )","838ce0b4":"# LogisticRegression L2 features\ncoef_table = pd.DataFrame(list(X.columns)).copy()\ncoef_table.insert(len(coef_table.columns), 'Coefs', logreg2.coef_.transpose())\ncoef_table = coef_table[abs(coef_table['Coefs']) > 0.0]\ncoef_table.sort_values('Coefs')","86401ccf":"# GradientBoosting CV and model fitting\ngbct = GradientBoostingClassifier(n_estimators=1000, learning_rate=.01, max_depth=3, max_features=3, min_samples_split=4,\n                                 min_samples_leaf=7, loss='exponential', subsample=.6, random_state=0)\nauc_cv_gbct = auc_cv(gbct)\ngbct.fit(X, y)\nprint('GBoost CV score min: ' + str(auc_cv_gbct.min()) + ' mean: ' + str(auc_cv_gbct.mean()) \n      + ' max: ' + str(auc_cv_gbct.max()) )","b6e69518":"from datetime import datetime\n#model blending \ndef blend_models(X):\n    return ((logreg2.predict(X)) + (gbct.predict(X)))\/2\n\nlogreg2_preds =  logreg2.predict(X_test)\ngbct_preds =  gbct.predict(X_test)\nlogreg2_gbct_preds = blend_models(X_test).astype(int)\ntitanic_logreg2_gbct = pd.DataFrame({'PassengerId':test.PassengerId, 'Survived':logreg2_gbct_preds})\ntitanic_logreg2_gbct.to_csv('solution.csv', index = False)\nprint('Version 3 submitted on', datetime.now())","6dca96a0":"Select categorical features","d023ed73":"There is increasing survival from Southampton - Queenstown - Cherbourg. ","e3ec4321":"The above figure indicates inreasing survival with Fare.","7c562768":"There will be no imputation of missing values for Cabin.","65de9839":"#### 2.5 FamilySize\nTwo variables SibSp(sibling\/spouse) and Parch(parent\/child) refer to the number of SibSp and Parch present in the titanic. Both variables are closely related that they can be pulled together to form a new column named FamilySize. FamilySize will contain the number of family members present in the titanic plus the passenger.","7fd7f26a":"#### 3.1.1  Logistic Regression","cd004056":"The above figure indicates 1st class passengers have the highest chance of survival, followed by second class passengers, and lastly third class passengers.","c6b490ab":"The female age groups follow the pattern of increasing survival with age while male age groups follow the pattern of decreasing survival with age. There are no elderly females as indicated by F4.","6f79d531":"Separate train and test sets for modeling","571182a8":"Select numeric features","1e982323":"#### 2.6 Sex","b1475b25":"#### 2.8 Data Transformations\nSelect numerical and and categorical features for modeling, encode variables and prepare train and test sets for modeling.","05ea5fd0":"#### 2.7 Title\nExtract title from the name field and group passengers with the titles Mr, Master, Miss and Mrs. Title is a derived feature based on Sex.","500b5e53":"### Introduction\nThis notebook  will  perform feature engineering and exploratory data analysis to see how they impact on titanic survival. The result of the impact analysis will be used to train a model and make predictions on titanic survival. Hyperparameter tuning and blending will be utilized to extend model performance.","064d655a":"There is increasing survival in the fare bins from low to high.","629bc8ab":"#### 3.1.2 GradientBoosting","70e33a72":"### 1. Data Preparation\nLoad the train and test data sets. Explore missing data, tidy data, and data wrangling","721cedcf":"### 2.0 EDA and Data Manipulation\nData visualization and manipulations to gain insights for modelling.","a5cf8768":"The graph above indicates that alone passengers indicated by bin 1 have the least survival.","8a0104cf":"### 3.2  Model Evaluation","e0de846f":"### 3. Modeling\nCross validation and model evaluation","02f9b2ee":"#### 2.2 Age","93ad055b":"#### 2.4 Embarked","6b2604ca":"The regression line for the above figure indicates decreasing rate of survival with increasing age. Younger people have a better chance of survival than old people. ","1505e8a5":"LB score of 0.78947, top 17%","36fbf644":"There is increasing survival of females with age, that is older females are more likely to survive than younger ones. The reverse is the case for males that follow the general decreasing survival with age. A new varaible will be formed to combine the interaction between  Sex and Age.","5205a463":"#### 2.1 Pclass\nPclass is better represented as an ordinal rank data and will be converted","af6ec6f6":"Survival increases as we move down the table from top to bottom. ","04260973":"The above figure indicates average survival between male and female passengers. It indicates females have a higher chance of survical than males.","2620862e":"#### 2.3 Fare"}}