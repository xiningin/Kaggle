{"cell_type":{"0b5e6644":"code","5092a5d7":"code","c3747558":"code","28dce406":"code","ad46dcb8":"code","75705bdc":"code","86f6376f":"code","054169c3":"code","d22a8844":"code","bb6ab2c7":"code","093ecb5e":"code","56a61dc1":"code","e4a75a8c":"code","81753742":"code","09146ccd":"code","2248d397":"code","b4bf1ebb":"code","f21d4c37":"code","2c886850":"code","cd24177e":"code","3d3448b2":"code","e8923e01":"code","fcedfe0b":"code","22fc559e":"code","230fb0c1":"code","ba7cb3bc":"code","77eb1ac4":"code","320c2dc1":"code","0749ed47":"code","61f68988":"code","27d40b69":"code","9400643a":"code","9435004b":"code","f9cedf9d":"code","f527671c":"code","9e88e0ee":"code","1022cd98":"code","ef3b14f6":"code","3c04a916":"code","70efa0d2":"code","a9d9491d":"markdown","a0f20cd9":"markdown","3602c97e":"markdown","baa124b7":"markdown","87254e3b":"markdown","36298ca0":"markdown","a0611c0b":"markdown","0b9740c5":"markdown","f2e8fc63":"markdown","dabde16a":"markdown","32cf3626":"markdown","2d802b90":"markdown","464e90b1":"markdown","9e347c33":"markdown","b96769ac":"markdown","2d77d4fe":"markdown","67632a76":"markdown","60e391cb":"markdown"},"source":{"0b5e6644":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5092a5d7":"# Importing librabries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader                   \nimport torchvision.datasets as datasets                   \nimport torchvision.transforms as transforms\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt","c3747558":"# import necessary libraries\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\n  \n# load the image\nimg_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/IM-0001-0001.jpeg'\nimg = Image.open(img_path)\n  \n# convert PIL image to numpy array\nimg_np = np.array(img)\n  \n# plot the pixel values\nplt.hist(img_np.ravel(), bins=50, density=True)\nplt.xlabel(\"pixel values\")\nplt.ylabel(\"relative frequency\")\nplt.title(\"distribution of pixels\")","28dce406":"# Python code for converting PIL Image to\n# PyTorch Tensor image and plot pixel values\n\n# import necessary libraries\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n\n# define custom transform function\ntransform = transforms.Compose([\n\ttransforms.ToTensor()\n])\n\n# transform the pIL image to tensor\n# image\nimg_tr = transform(img)\n\n# Convert tensor image to numpy array\nimg_np = np.array(img_tr)\n\n# plot the pixel values\nplt.hist(img_np.ravel(), bins=50, density=True)\nplt.xlabel(\"pixel values\")\nplt.ylabel(\"relative frequency\")\nplt.title(\"distribution of pixels\")\n","ad46dcb8":"# get tensor image\nimg_tr = transform(img)\n  \n# calculate mean and std\nmean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n  \n# print mean and std\nprint(\"mean and std before normalize:\")\nprint(\"Mean of the image:\", mean)\nprint(\"Std of the image:\", std)","75705bdc":"# python code to normalize the image\n\n\nfrom torchvision import transforms\n\n# define custom transform\n# here we are using our calculated\n# mean & std\ntransform_norm = transforms.Compose([\n\ttransforms.ToTensor(),\n\ttransforms.Normalize(mean, std)\n])\n\n# get normalized image\nimg_normalized = transform_norm(img)\n\n# convert normalized image to numpy\n# array\nimg_np = np.array(img_normalized)\n\n# plot the pixel values\nplt.hist(img_np.ravel(), bins=50, density=True)\nplt.xlabel(\"pixel values\")\nplt.ylabel(\"relative frequency\")\nplt.title(\"distribution of pixels\")","86f6376f":"# Python Code to visualize normalized image\n\n# get normalized image\nimg_normalized = transform_norm(img)\n\n# convert tis image to numpy array\nimg_normalized = np.array(img_normalized)\n\n# transpose from shape of (3,,) to shape of (,,3)\nimg_normalized = img_normalized.transpose(1, 2, 0)\n\n# display the normalized image\nplt.imshow(img_normalized)\nplt.xticks([])\nplt.yticks([])","054169c3":"# Python code to calculate mean and std\n# of normalized image\n  \n# get normalized image\nimg_nor = transform_norm(img)\n  \n# cailculate mean and std\nmean, std = img_nor.mean([1,2]), img_nor.std([1,2])\n  \n# print mean and std\nprint(\"Mean and Std of normalized image:\")\nprint(\"Mean of the image:\", mean)\nprint(\"Std of the image:\", std)","d22a8844":"variable = transforms.Compose(\n    [\n        transforms.Resize((224,224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(\n        [0.5 for _ in range(3)], [0.2 for _ in range(3)]),\n    ]\n)","bb6ab2c7":"Train_data = datasets.ImageFolder(root = '..\/input\/chest-xray-pneumonia\/chest_xray\/train', transform =variable )\nTrain_loader = DataLoader(Train_data, batch_size = 128, shuffle= True, drop_last=True)\nval_data = datasets.ImageFolder(root = '..\/input\/chest-xray-pneumonia\/chest_xray\/val', transform =variable )\nval_loader = DataLoader(val_data, batch_size = 4, shuffle= True, drop_last=True)\ntest_data = datasets.ImageFolder(root = '..\/input\/chest-xray-pneumonia\/chest_xray\/test', transform =variable )\ntest_loader = DataLoader(test_data, batch_size = 128, shuffle= True, drop_last=True)","093ecb5e":"# Checking the images from the test dataset\nexamples = enumerate(Train_loader)\nbatch_idx, (example_data, example_targets) = next(examples)\nprint('Shape of the Image: ',example_data.shape)\nprint('Shape of the label: ', example_targets.shape)\nprint(example_targets[0:6])","56a61dc1":"#checking the labels\nclass_name_train = Train_data.classes\nprint(class_name_train)\nprint(Train_data.class_to_idx)","e4a75a8c":"# Visualizing the test dataset images with ground truth values\nfig = plt.figure()\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.tight_layout()\n    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n    #print(example_targets[i])\n    plt.xticks([])\n    plt.yticks([])\nfig","81753742":"# Set Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","09146ccd":"# CNN Architechture\nclass ConvNet(nn.Module):\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 16, kernel_size= 5, stride=1,padding=0)\n        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=1)\n        self.conv2 = nn.Conv2d(16, out_channels= 32, kernel_size= 5, stride=1,padding=0)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(32*27*27, 128)\n        self.fc2 = nn.Linear(128,64)\n        self.fc3 = nn.Linear(64,2)\n    \n    def forward(self, x):\n        out = F.relu(self.conv1(x))\n        #print(out.shape)\n        out = self.pool1(out)\n        #print(out.shape)\n        out = F.relu(self.conv2(out))\n        #print(out.shape)\n        out = self.pool2(out)\n        #print(out.shape)\n        \n        # flattening the layer\n        out = out.reshape(out.size(0),-1)\n        #print(out.shape)\n        out = F.relu(self.fc1(out))\n        out = F.relu(self.fc2(out))\n        out = self.fc3(out)\n        \n        return out","2248d397":"class ConvNet2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1,padding = 1), # (64*224*224)\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4,stride=2, padding=1), #(128*112*112)\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding = 1),                             #(128*112*112)\n            # layer 1 complete\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4,stride=2, padding=1), #(256*56*56)\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding = 1),                             #(256*56*56)\n            #layer 2 complete\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4,stride=2, padding=1), #(512*28*28)\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding = 1),                             #(512*28*28)\n            # Layer 3 complete\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4,stride=2, padding=1), #(512*14*14)\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding = 1),                             #(512*14*14)\n            # layer 4 complete\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4,stride=2, padding=1), #(512*7*7)\n            nn.BatchNorm2d(512),\n            nn.ReLU(), \n        )\n        self.fc = nn.Sequential(\n            nn.Linear(512*7*7,256),\n            nn.Linear(256, 128),\n            nn.Linear(128,64),\n            nn.Linear(64,2)\n        )\n        \n    def forward(self,x):\n        out = self.conv2(x)\n        out = out.reshape(out.size(0),-1)\n        out = self.fc(out)\n        return out\n        \n            ","b4bf1ebb":"#hecking the desired output with random input\nmodel = ConvNet2()\nx = torch.rand(10,3, 224,224)\nprint(model(x).shape)\noutput = model(x)\n#print(output)","f21d4c37":"#hecking the desired output with random input\nmodel = ConvNet()\nx = torch.rand(128,3, 64,64)\nprint(model(x).shape)\noutput = model(x)\n#print(output)","2c886850":"# Setting the hyperparameters\nlearning_rate = 0.01\nnum_classes = 2\nnum_epochs = 5\nchannel_img = 3\nfeature_d = 64","cd24177e":"# Initializing the ConvNet\nmodel = ConvNet2().to(device)","3d3448b2":"# loss criterion and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\nwriter = SummaryWriter(f'runs\/CNN\/Plotting_on_tensorBoard')","e8923e01":"# Training loop\nnum_total_steps = len(Train_loader.dataset)\nstep = 0\nlosses = []\naccuracies = []\nsteps = []\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    train_acc = 0.0\n    for i , (images, labels) in enumerate(Train_loader):\n        images = images.to(device)\n        #print(len(images))\n        labels = labels.to(device)\n        #print(labels)\n        \n        #forward\n        outputs = model(images)\n        #print(outputs)\n        loss = criterion(outputs, labels)\n        losses.append(loss.item())\n        \n        \n        # backwards and optimizer\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Calculating running training accuracies\n        _, predictions = outputs.max(1)\n        #print((predictions))\n        num_correct = (predictions == labels).sum()\n        running_train_acc = float(num_correct)\/float(images.shape[0])\n        accuracies.append(running_train_acc)\n        \n        train_acc += running_train_acc\n        train_loss += loss.item()\n        \n        avg_train_acc = train_acc \/ len(Train_loader)\n        avg_train_loss = train_loss \/ len(Train_loader)\n        \n        writer.add_scalar('Training Loss', loss, global_step= step)\n        writer.add_scalar('Training Accuracy', running_train_acc, global_step=step)\n        step += 1\n        steps.append(step)\n        \n        \n        if (i+1) % 10 == 0:\n            print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i*len(images), num_total_steps, loss.item()))\n            \nprint('Training Ended')","fcedfe0b":"print(\"Model's state_dict:\")\nfor param_tensor in model.state_dict():\n    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n\n# Print optimizer's state_dict\nprint(\"Optimizer's state_dict:\")\nfor var_name in optimizer.state_dict():\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n    \n    \n#torch.save(critic.state_dict(), \"model_trained.h5\")\ntorch.save(model.state_dict(), \"ConvNet_1.pth\")","22fc559e":"plt.title('Training Loss')\nplt.xlabel('Steps')\nplt.ylabel('Losses')\nplt.plot(steps, losses)\nplt.show()","230fb0c1":"plt.title('Training accuracy')\nplt.xlabel('Steps')\nplt.ylabel('Accuracy')\nplt.plot(steps, accuracies)\nplt.show()","ba7cb3bc":"# Training loop\nnum_total_steps = len(Train_loader.dataset)\nvalid_loss_min = np.Inf\nstep = 0\ntraining_loss = []\nvalidation_loss = []\ntraining_accuracy = []\nvalidation_accuracy = []\naccuracies = []\nsteps = []\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    val_loss = 0.0\n    train_acc = 0.0\n    val_acc = 0.0 \n    \n    model.train()\n    for _ , (images, labels) in enumerate(Train_loader):\n        images = images.to(device)\n        #print(len(images))\n        labels = labels.to(device)\n        \n        #forward\n        outputs = model_1(images)\n        loss = criterion(outputs, labels)\n        training_loss.append(loss.item())\n        \n        \n        # backwards and optimizer\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Calculating running training accuracies\n        _, predictions = outputs.max(1)\n        num_correct = (predictions == labels).sum()\n        running_train_acc = float(num_correct)\/float(images.shape[0])\n        training_accuracy.append(running_train_acc)\n        train_acc += running_train_acc\n        train_loss += loss.item()\n        \n        avg_train_acc = train_acc \/ len(Train_loader)\n        avg_train_loss = train_loss \/ len(Train_loader)\n        \n        model.eval()\n        with torch.no_grad():\n            for _ , (images, labels) in enumerate(val_loader):\n                images = images.to(device)\n                #print(len(images))\n                labels = labels.to(device)\n                \n                outputs = model_1(images)\n                loss = criterion(outputs, labels)\n                validation_loss.append(loss)\n                \n                # Calculating running training accuracies\n                _, predictions = outputs.max(1)\n                num_correct = (predictions == labels).sum()\n                running_val_acc = float(num_correct)\/float(images.shape[0])\n                validation_accuracy.append(running_val_acc)\n                val_acc += running_val_acc\n                val_loss += loss.item()\n            \n            avg_valid_acc = val_acc \/ len(val_loader)\n            avg_valid_loss = val_loss \/ len(val_loader)\n        step += 1\n        steps.append(step)\n            \n#             if avg_valid_loss <= valid_loss_min:\n#                 print('Validation loss decreased ({:.6f} --> {:.6f}).   Saving model ...'.format(valid_loss_min,avg_valid_loss))\n#                 torch.save({\n#                 'epoch' : i,\n#                 'model_state_dict' : model.state_dict(),\n#                 'optimizer_state_dict' : optimizer.state_dict(),\n#                 'valid_loss_min' : avg_valid_loss\n#                       },'Pneumonia_model.pt')\n#                 valid_loss_min = avg_valid_loss\n\n    print(\"Epoch : {} Train Loss : {:.6f} Train Acc : {:.6f}\".format(epoch+1,avg_train_loss,avg_train_acc))\n    print(\"Epoch : {} Valid Loss : {:.6f} Valid Acc : {:.6f}\".format(epoch+1,avg_valid_loss,avg_valid_acc))\n","77eb1ac4":"print(len(steps))\nprint(len(training_accuracy))\nprint(len(validation_accuracy[0:400]))\nprint(len(training_loss))\nprint(len(validation_loss[0:400]))","320c2dc1":"fig = plt.figure()\n\nax = fig.add_axes([0,0,1,1])\n\nax.plot(steps, training_accuracy, label=\"training accuracy\")\nax.plot(steps, validation_accuracy[0:400], label=\"validation accuracy\")\nax.legend()","0749ed47":"fig = plt.figure()\n\nax = fig.add_axes([0,0,1,1])\n\nax.plot(steps, training_loss, label=\"training accuracy\")\nax.plot(steps, validation_loss[0:400], label=\"validation accuracy\")\nax.legend()","61f68988":"print(\"Model's state_dict:\")\nfor param_tensor in model.state_dict():\n    print(param_tensor, \"\\t\", model_1.state_dict()[param_tensor].size())\n\n# Print optimizer's state_dict\nprint(\"Optimizer's state_dict:\")\nfor var_name in optimizer.state_dict():\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n    \n    \n#torch.save(critic.state_dict(), \"model_trained.h5\")\ntorch.save(model_1.state_dict(), \"ConvNet_3.pth\")","27d40b69":"# Model class must be defined somewhere\nmodel_1 = ConvNet2()\nmodel_1.load_state_dict(torch.load('ConvNet_2.pth', map_location='cuda'))\nmodel_1.cuda()\n","9400643a":"print(len(steps))\nprint(len(training_accuracy))\nprint(len(validation_accuracy))\nvalidation_accuracy\n","9435004b":"# testing \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('validation Accuracy of the model on the val images: {} %'.format(100 * correct \/ total))","f9cedf9d":"# testing \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))","f527671c":"# we can not use numpy with GPU so here the images has beeb transfered to numpy array\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)             # sending images to GPU bcz model is trained on GPU\n        labels = labels.to(device)             # sending the labels to GPU bcz model is trained on GPU\n        outputs = model(images)                # running calculation on GPU\n        img = images.data.cpu().numpy()        # now to plot the images converting them to numpy\n        lab = labels.data.cpu().numpy()\n        out = outputs.data.cpu().numpy()\n        ","9e88e0ee":"fig = plt.figure()\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.tight_layout()\n    plt.imshow(img[i][0], cmap='gray', interpolation='none')        # using images availble on CPU\n    plt.title(\"Prediction: {}\\n Ground Truth: {} \".format(\n    outputs.data.max(1, keepdim=True)[1][i].item(),labels[i]))                # directly retriving image label from GPU  \n    plt.xticks([])\n    plt.yticks([])\nfig","1022cd98":"# Hyperparameter Tunning\nbatch_sizes = [2, 64, 128]\nlearning_rates = [0.1,0.001 ,0.0001]\nnum_epochs = 1\n\nfor batch_size in batch_sizes:\n    for learning_rate in learning_rates:\n        # Initializing the ConvNet\n        model = ConvNet2().to(device)\n        model.train()\n        Train_loader = DataLoader(Train_data, batch_size = batch_size, shuffle= True, drop_last=True)\n        \n        # Loss and Optimizer\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n        writer = SummaryWriter(f'HP_tunning\/MNIST_CNN\/Hyperparameter_tunning {batch_size} LR {learning_rate}')\n        \n        num_total_steps = len(Train_loader)\n        step = 0\n        losses = []\n        accuracies = []\n        steps = []\n        for epoch in range(num_epochs):\n            for i , (images, labels) in enumerate(Train_loader):\n                images = images.to(device)\n                labels = labels.to(device)\n\n                #forward\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                losses.append(loss.item())\n\n                # backwards and optimizer\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                # Calculating running training accuracies\n                _, predictions = outputs.max(1)\n                num_correct = (predictions == labels).sum()\n                running_train_acc = float(num_correct)\/float(images.shape[0])\n                accuracies.append(running_train_acc)\n\n                writer.add_scalar('Training Loss', loss, global_step= step)\n                writer.add_scalar('Training Accuracy', running_train_acc, global_step=step)\n                step += 1\n                steps.append(step)\n        \n\n                if (i+1) % 1000 == 0:\n                    print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}' \n                           .format(epoch+1, num_epochs, i+1, num_total_steps, loss.item()))\n            writer.add_hparams({'lr': learning_rate, 'bsize': batch_size},\n                              {'accuracy':sum(accuracies)\/len(accuracies), 'loss':sum(losses)\/len(losses)})\n            \n            \n    print(f'Training Ended : Batch_size: {batch_size}')\n        ","ef3b14f6":"%load_ext tensorboard\n%tensorboard --logdir runs","3c04a916":"# Model class must be defined somewhere\nmodel_1 = ConvNet2()\nmodel_1.load_state_dict(torch.load('ConvNet2.h5', map_location='cuda'))\nmodel_1.cuda()\nmodel_1.eval()","70efa0d2":"# testing \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model_1(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))","a9d9491d":"# Setting the optimizer function and the loss function","a0f20cd9":"# Hyperparameter setting","3602c97e":"# Visualizing the training dataset images","baa124b7":"# Visualizing the predicted and True labels","87254e3b":"# CNN Architecture","36298ca0":"# GFG Imported code ends here","a0611c0b":"# Setting the device \"GPU\" or \"CPU\"","0b9740c5":"# Checking the final dimensions of the output","f2e8fc63":"# Importing libraries","dabde16a":"# Saving the trained model parameters and the weights","32cf3626":"# Loading the trained model","2d802b90":"# Loading the dataset","464e90b1":"# Pytorch Training Loop","9e347c33":"# This Code block is used from GFG\n### To find out the mean and Std to Normalize the dataset approximately","b96769ac":"# Plotting the training loss and the training accuracy","2d77d4fe":"# Applying transformation on the dataset","67632a76":"# Checking the labels","60e391cb":"# Checking the model accuracy"}}