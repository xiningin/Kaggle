{"cell_type":{"277e8a28":"code","140d8875":"code","dfc0e218":"code","0d575f8f":"code","cd94510d":"code","ee13d19f":"code","78d8e52a":"code","a3d60c94":"code","edf8e6f7":"code","ff942b39":"code","1de1dd3d":"code","6afb42c9":"code","1ec94a35":"code","a5547aac":"code","8de329be":"code","34db97c6":"code","b6441fb0":"code","5c70d94a":"code","ffb4cc74":"code","066d12d2":"code","f4798991":"code","9321fb9c":"code","31891d19":"code","a21c11e2":"code","2e30914d":"code","1d683ba6":"code","230f41c8":"code","09c5dff1":"code","d0afa031":"code","3f8606da":"code","07bbcaaa":"code","bec42bfa":"code","954fedb7":"code","8023cfa6":"code","12e303a9":"code","0afd9746":"code","5a043d6b":"code","9c6c4573":"code","49d15e16":"code","e46eac27":"code","8a6eecd3":"code","fe7fe0a3":"code","5fc79474":"code","f589f190":"code","a8d6a6a0":"code","ce31390f":"code","d2e3c013":"code","693bc87a":"code","81dcaaae":"code","f3c22e9f":"code","375a891e":"code","5b9c59c4":"code","c3fb237c":"code","b49bb98f":"code","e4302545":"code","76b73f3c":"code","7bef5410":"code","4625da2a":"code","92d336a9":"code","a625db0f":"code","375c51a6":"code","f2acb2df":"code","aa1a08f0":"code","a6b769c9":"code","6275e0e1":"code","b04a8535":"code","702a9257":"code","56b2c4e7":"code","3aecc713":"code","75c3da35":"code","20df88e6":"code","d6849184":"code","f3da635f":"code","b1771cc3":"code","d6d8429b":"code","f0d5f4d1":"code","78fbb647":"code","147dc3dd":"code","e9f1dfb8":"code","d04df104":"code","6c1ae1c9":"code","06cfba10":"code","dbed885f":"code","b77135eb":"code","338467dd":"code","8b8090e9":"code","8fd877c3":"code","84c992bb":"code","15543f1b":"code","15dff449":"code","eb3e7e95":"code","3f364ca3":"code","0327a9ec":"code","552ccaab":"code","5a96fe06":"code","48b36f91":"code","cd72b31a":"code","afae1644":"code","978f52c2":"code","3e8cd93d":"code","00187d73":"code","fc8740e8":"code","cdb53823":"code","ca66e614":"code","59509f4e":"code","f82518ba":"code","ba11f53f":"code","a3737e5f":"code","67214249":"code","3bb16371":"code","a4f291d5":"code","76fa1668":"code","f7f9776f":"code","9afa722a":"code","ec2e9756":"code","0aec69ca":"code","558fb657":"code","7f76f7cf":"code","438cd3c7":"code","4fc1c4eb":"code","d2eb5ace":"code","0fe1ee04":"code","96a75119":"code","1b07b57d":"code","a84cacd0":"code","5099f1d5":"code","c9e962df":"code","12a9a4d8":"code","19bebc12":"code","67935c72":"code","e4477977":"code","36984283":"code","159a2ef6":"code","5706d33b":"code","b1610d4a":"code","0113120f":"code","09cd6530":"code","fc8f5d85":"code","d52e9217":"markdown","f3ddbdcb":"markdown","316ed012":"markdown","77564078":"markdown","7adc924c":"markdown","e70e6c30":"markdown","f6647772":"markdown","76d1a160":"markdown","435f1e10":"markdown","60905956":"markdown","f36b9bd7":"markdown","14a71d41":"markdown","c773d483":"markdown","dc2ba13e":"markdown","94e7dfb5":"markdown","886b223d":"markdown","82336a88":"markdown","54608b62":"markdown","239ea424":"markdown","7a6a2af0":"markdown","ade8b0a8":"markdown","9ef0f9ce":"markdown","91bae538":"markdown","e2c009e1":"markdown","e1a54cbb":"markdown","65ea5164":"markdown","ede66fa4":"markdown","cc448e25":"markdown","47a44c74":"markdown","d83b5a75":"markdown","038b7284":"markdown","db0ae5a4":"markdown","9825b685":"markdown","70de8190":"markdown","eabe1368":"markdown","29fa2fed":"markdown","dbc3dd1d":"markdown","c5e8625f":"markdown","8b086f69":"markdown","989304fc":"markdown","bddbecd7":"markdown","154e7b6e":"markdown","ebae651a":"markdown","b5b22655":"markdown","968cf4b2":"markdown","54fb3c4d":"markdown","61ededbe":"markdown","1fa44c98":"markdown","f1b27048":"markdown","937f619b":"markdown","f9cc31bd":"markdown","864b9ab8":"markdown","ef470517":"markdown","0339ab7a":"markdown","4abd03bd":"markdown","76d5d477":"markdown","465218e5":"markdown","d362ceb5":"markdown","0cce3f1d":"markdown"},"source":{"277e8a28":"# Importing required libraries\nimport numpy as np\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\n# Setting options\nnp.set_printoptions(precision=4)                 # To display values upto Four decimal places. \nplt.style.use('seaborn-whitegrid')               # To apply seaborn whitegrid style to the plots.\nplt.rc('figure', figsize=(20, 12))               # Set the default figure size of plots.\nsns.set(style='whitegrid')                       # To apply whitegrid style to the plots.\nwarnings.filterwarnings('ignore')                # To ignore warnings, if any","140d8875":"# Importing the dataset as data\ndata = pd.read_csv('..\/input\/avocado-prices\/avocado.csv', index_col=0)\ndata.sample(8)    # Preview of random 8 rows ","dfc0e218":"data.shape       # Number of (records, features) of data","0d575f8f":"data.info()      # Info of data","cd94510d":"data.describe()     # Descriptive statistics of data","ee13d19f":"pre_profile = data.profile_report(title='Avacado Pre-Profiling')   # Performing Pre Profiling on data.","78d8e52a":"pre_profile.to_file('pre-profiling.html')                          # Saving report to pre-profiling.html","a3d60c94":"# pre_profile.to_notebook_iframe()                                 # Displaying the profiling report inline. ","edf8e6f7":"# Unique values in data index - doing this as profiling shows there are zeros in index\nprint('No. of unique index values:', data.index.nunique())                          ","ff942b39":"data.reset_index(drop=True, inplace=True)    # reseting index as index values seems to be incorrect\n\n# Unique values in data index after ressetting\nprint('No. of unique index values after resetting index: ', data.index.nunique())   ","1de1dd3d":"# Renaming column names\ndata.rename(columns={'4046':'PLU_4046','4225':'PLU_4225','4770':'PLU_4770'}, inplace=True) # Renaming size as per description\n# Renaming columns to remove spaces and capitalize first letter\ndata.columns = data.columns.str.replace(' ','').map(lambda x : x[0].upper() + x[1:]) \ndata.head(2)  # Preview of column header","6afb42c9":"data.dtypes # Looking for data types","1ec94a35":"data['Date'] = pd.to_datetime(data['Date'])    # Converting date to datetime type\ndata['Year'] = data['Year'].astype('object')   # Converting Year to object from numeric","a5547aac":"# Utility \/ Helper Function - To categorize season based on date\n\ndef categorizing_seasons(date):\n    month = date.month\n\n    # Source - https:\/\/en.wikipedia.org\/wiki\/Season#Meteorological\n    winter, spring, summer, autumn = ([12, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11])\n    if month in winter:\n        return 'Winter'\n    elif month in spring:\n        return 'Spring'\n    elif month in summer:\n        return 'Summer'\n    else:\n        return 'Autumn'","8de329be":"data['Month'] = data['Date'].dt.month_name()             # Deriving Month from Date\ndata['Quarter'] = data['Date'].dt.quarter                # Deriving Qurter from Date\ndata['Season'] = data['Date'].map(categorizing_seasons)  # Deriving Season from Date","34db97c6":"# Utility \/ Helper Function - To update the variables as per data\n\ndef get_variables_from_data():\n    # Target Variables\n    y_column = 'AveragePrice'                                          \n     \n    # Categorical Feature variables \n    X_columns_cat = list(data.dtypes[data.dtypes.values == 'object'].index)  \n\n    # Numeric Feature variables\n    X_columns_num = list(data.dtypes[(data.dtypes.values != 'object') & (data.dtypes.index != y_column)].index)    \n\n    # Feature variables\n    X_columns = X_columns_num + X_columns_cat\n    \n    print('y_column:', y_column)\n    print('X_columns: ',X_columns) \n    print('X_columns_num: ',X_columns_num) \n    print('X_columns_cat: ',X_columns_cat) \n    \n    # Returning as a tuple\n    return y_column, X_columns, X_columns_num, X_columns_cat","b6441fb0":"# Updating Variables\ny_column, X_columns, X_columns_num, X_columns_cat = get_variables_from_data()","5c70d94a":"data.groupby('Month')[y_column].agg(['max', 'mean', 'min'])   # Understanding TV w.r.t 'Month'","ffb4cc74":"data.groupby('Quarter')[y_column].agg(['max', 'mean', 'min'])  # Understanding TV w.r.t 'Quarter'","066d12d2":"data.groupby('Season')[y_column].agg(['max', 'mean', 'min'])  # Understanding TV w.r.t 'Season'","f4798991":"f, ax = plt.subplots(1, 3, figsize=(15,5))\nf.suptitle('Spread of mean AveragePrice Over Season, Quarter and Month', fontsize=16)\ndata.groupby('Season')[y_column].mean().plot(kind='bar',ax=ax[0])\ndata.groupby('Quarter')[y_column].mean().plot(kind='bar',ax=ax[1])\ndata.groupby('Month')[y_column].mean().plot(kind='bar',ax=ax[2])","9321fb9c":"X_columns          # Preview of existing Feature columns ","31891d19":"# Replacing date with less cordinal column month\ndata.drop(columns=['Date', 'Season', 'Quarter'], inplace=True)   # Droping Data, Quarter and Season columns","a21c11e2":"# Updating Variables\ny_column, X_columns, X_columns_num, X_columns_cat = get_variables_from_data()","2e30914d":"f, ax =  plt.subplots(1, 2, figsize=(15, 8))\nf.suptitle('Box plot on Target Variable and Target Variable Distribution - Before', fontsize=16)\nsns.boxplot(y=y_column, data=data, ax=ax[0]) # Box plot on TV before droping extreme values\nsns.distplot(data[y_column], ax=ax[1])       # Distribution of Target Vaiable","1d683ba6":"# Checking mean|median and limiting data to 2 * (mean|median) - To eliminate extreme right values\ndata[y_column].describe()                  ","230f41c8":"data.drop(data[data[y_column] > 2.8].index, inplace=True) # Droping records where price > 3\nprint(data.shape)                                         # Shape of data after droping few records\ndata.sample(5)                                            # Preview of data after droping few records","09c5dff1":"f, ax =  plt.subplots(1, 2, figsize=(15, 8))\nf.suptitle('Box plot on Target Variable and Target Variable Distribution - After', fontsize=16)\nsns.boxplot(y=y_column, data=data, ax=ax[0]) # Box plot on TV after droping extreme values\nsns.distplot(data[y_column], ax=ax[1])       # Distribution of Target Vaiable","d0afa031":"data.head()   # Preview of data","3f8606da":"# Density of mean price w.r.t categorical columns\nf, ax = plt.subplots(2,2)\nfor x_var, subplot in zip(X_columns_cat, ax.flatten()):\n    subplot.set_xlabel(x_var)\n    data.groupby(x_var)[y_column].mean().plot(kind='kde', ax=subplot, label='Test')","07bbcaaa":"# Mean price w.r.t categorical columns\nf, ax = plt.subplots(2,2)\nplt.subplots_adjust(hspace=0.5)\nfor x_var, subplot in zip(X_columns_cat, ax.flatten()):\n    subplot.set_xlabel(x_var)\n    subplot.set_ylabel('Mean Avg price')\n    data.groupby(x_var)[y_column].mean().plot(kind='bar', ax=subplot, label='Test')","bec42bfa":"# Bot plot to check outliers in categorical columns\n\nf, ax = plt.subplots(1,2, figsize=(15,5))\nfor x_var, subplot in zip(X_columns_cat[0:2], ax.flatten()):\n    sns.boxplot(data = data, x=x_var, y=y_column, ax=subplot)\n\nf, ax = plt.subplots(1, figsize=(15,5))\nsns.boxplot(data = data, x=X_columns_cat[-1], y=y_column, ax=ax)\n\nf, ax = plt.subplots(1, figsize=(15,5))\nsns.boxplot(data = data, x=X_columns_cat[2], y=y_column, ax=ax)\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()","954fedb7":"# Checking for relation of numeric columns w.r.t Target Variable\nf, ax = plt.subplots(1, len(X_columns_num), figsize=(20, 5))\n\nfor x_var, sp in zip(X_columns_num, ax.flatten()):\n    sns.regplot(x=data[x_var], y=data[y_column], ax=sp)","8023cfa6":"# Heatmap to check correlation\nplt.figure(figsize=(10,8))\nsns.heatmap(data[X_columns_num].corr(), annot=True, cmap='viridis')","12e303a9":"# Droping highly correlated columns\ndata.drop(columns=['PLU_4046', 'PLU_4225', 'TotalBags', 'SmallBags'], inplace=True)","0afd9746":"data.head(2)   # Preview after droping columns","5a043d6b":"# Updating Variables\ny_column, X_columns, X_columns_num, X_columns_cat = get_variables_from_data()","9c6c4573":"sns.distplot(data[y_column]) # Normal Distribution of Target Vaiable","49d15e16":"# Pair Plot of data\nsns.pairplot(data, size = 2, aspect = 1.5)","e46eac27":"# Checking for relation of Numeric Features with Target Variable\nsns.pairplot(data, x_vars=X_columns_num, y_vars=y_column, size=5, aspect=1, kind='reg') ","8a6eecd3":"post_profile = data.profile_report(title='Avacado Post-Profiling')   # Performing Post Profiling on data.","fe7fe0a3":"post_profile.to_file('post-profiling.html')                          # Saving report to post-profiling.html","5fc79474":"# post_profile.to_notebook_iframe()                                    # View report inline here","f589f190":"data.head(2) # Preview of data","a8d6a6a0":"X_columns   # Preview of feature columns","ce31390f":"X = data[X_columns]           # Features data\ny = data[y_column]            # TV data","d2e3c013":"print(X.shape)\nX.head()                      # Preview of X","693bc87a":"print(y.shape)\ny.head()                     # Preview of y","81dcaaae":"# Splitting the dataset into training and test sets 80-20 split.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","f3c22e9f":"# Reset index of split data sets\nX_train.reset_index(drop=True, inplace=True)\nX_test.reset_index(drop=True, inplace=True)\ny_train.reset_index(drop=True, inplace=True)\ny_test.reset_index(drop=True, inplace=True)","375a891e":"print(X_train.shape)\nX_train.head()        # Preview of X_train","5b9c59c4":"print(X_test.shape)\nX_test.head()         # Preview of X_test","c3fb237c":"X_train_num = X_train[X_columns_num]       # Numeric X_train \nX_test_num = X_test[X_columns_num]         # Numeric X_test","b49bb98f":"from sklearn.preprocessing import StandardScaler         # Importing Standard Scalar\nscaler = StandardScaler().fit(X_train_num)               # Fitting with train data","e4302545":"X_train_s = pd.DataFrame(scaler.transform(X_train_num), columns=X_columns_num)  # Transforming train data\nX_test_s = pd.DataFrame(scaler.transform(X_test_num), columns=X_columns_num)    # Transforming test data","76b73f3c":"print(X_train_s.shape)\nX_train_s.head()            # Scaled train data - Numeric","7bef5410":"print(X_test_s.shape)\nX_test_s.head()             # Scaled test data - Numeric","4625da2a":"X_train[X_columns_cat].head()         # Preview of categorical features","92d336a9":"# One Hot Encoding on Type for Train set.\nX_train_type_dummies = pd.get_dummies(X_train['Type'], prefix='Type', drop_first=True)\nprint(X_train_type_dummies.shape)       # Shape of Dummies\nX_train_type_dummies.head()             # Preview of Type Dummies               ","a625db0f":"X_train_s = pd.concat([X_train_s, X_train_type_dummies], 1) # Merging type dummies to Scaled Train set\nprint(X_train_s.shape)                                      # Shape of merged train set\nX_train_s.head()                                            # Preview of merged train set","375c51a6":"# One Hot Encoding on Type for Test set.\nX_test_type_dummies = pd.get_dummies(X_test['Type'], prefix='Type', drop_first=True)\nprint(X_test_type_dummies.shape)       # Shape of Dummies\nX_test_type_dummies.head()             # Preview of Type Dummies               ","f2acb2df":"X_test_s = pd.concat([X_test_s, X_test_type_dummies], 1)   # Merging type dummies to Scaled test set\nprint(X_test_s.shape)                                      # Shape of merged test set\nX_test_s.head()                                            # Preview of merged test set","aa1a08f0":"# Label Encoding on Year for Train set.\nfrom sklearn.preprocessing import LabelEncoder         # Importing Label Encoder\nlabel_encoder = LabelEncoder().fit(X_train['Year'])    # Fitting on train set","a6b769c9":"X_train_year_dummies = pd.DataFrame(label_encoder.transform(X_train['Year']), columns=['Year'])\nprint(X_train_year_dummies.shape)       # Shape of Transformed Year\nX_train_year_dummies.head()             # Preview of Transformed Year ","6275e0e1":"X_train_s = pd.concat([X_train_s, X_train_year_dummies], 1)   # Merging type dummies to Scaled train set\nprint(X_train_s.shape)                                        # Shape of merged train set\nX_train_s.head()                                              # Preview of merged train set","b04a8535":"X_test_year_dummies = pd.DataFrame(label_encoder.transform(X_test['Year']), columns=['Year'])\nprint(X_test_year_dummies.shape)       # Shape of Transformed Year\nX_test_year_dummies.head()             # Preview of Transformed Year ","702a9257":"X_test_s = pd.concat([X_test_s, X_test_year_dummies], 1)   # Merging type dummies to Scaled test set\nprint(X_test_s.shape)                                      # Shape of merged test set\nX_test_s.head()                                            # Preview of merged test set","56b2c4e7":"# Installing category_encoders to import TargetEncoder\n# !pip install category_encoders","3aecc713":"# Label Encoding on Year for Train set.\nfrom category_encoders import TargetEncoder                                # Importing Target Encoder\ntarget_encoder_region = TargetEncoder().fit(X_train['Region'], y_train)    # Fitting on train set","75c3da35":"X_train_region_dummies = target_encoder_region.transform(X_train['Region'])\nprint(X_train_region_dummies.shape)       # Shape of Transformed region\nX_train_region_dummies.head()             # Preview of Transformed region ","20df88e6":"X_train_s = pd.concat([X_train_s, X_train_region_dummies], 1)   # Merging region dummies to Scaled train set\nprint(X_train_s.shape)                                          # Shape of merged train set\nX_train_s.head()                                                # Preview of merged train set","d6849184":"X_test_region_dummies = target_encoder_region.transform(X_test['Region'])\nprint(X_test_region_dummies.shape)       # Shape of Transformed region\nX_test_region_dummies.head()             # Preview of Transformed region ","f3da635f":"X_test_s = pd.concat([X_test_s, X_test_region_dummies], 1)     # Merging region dummies to Scaled train set\nprint(X_test_s.shape)                                          # Shape of merged train set\nX_test_s.head()                                                # Preview of merged train set","b1771cc3":"target_encoder_month = TargetEncoder().fit(X_train['Month'], y_train)    # Fitting on train set for Month","d6d8429b":"X_train_month_dummies = target_encoder_month.transform(X_train['Month'])\nprint(X_train_month_dummies.shape)       # Shape of Transformed region\nX_train_month_dummies.head()             # Preview of Transformed region ","f0d5f4d1":"X_train_s = pd.concat([X_train_s, X_train_month_dummies], 1)    # Merging region dummies to Scaled train set\nprint(X_train_s.shape)                                          # Shape of merged train set\nX_train_s.head()                                                # Preview of merged train set","78fbb647":"X_test_month_dummies = target_encoder_month.transform(X_test['Month'])\nprint(X_test_month_dummies.shape)       # Shape of Transformed region\nX_test_month_dummies.head()             # Preview of Transformed region ","147dc3dd":"X_test_s = pd.concat([X_test_s, X_test_month_dummies], 1)      # Merging month dummies to Scaled train set\nprint(X_test_s.shape)                                          # Shape of merged train set\nX_test_s.head()                                                # Preview of merged train set","e9f1dfb8":"print(X_train_s.shape)\nX_train_s.head()                    # Preview of X_train","d04df104":"print(y_train.shape)\ny_train.head()                    # Preview of y_train","6c1ae1c9":"print(X_test_s.shape)\nX_test_s.head()                    # Preview of X_test","06cfba10":"print(y_test.shape)\ny_test.head()                    # Preview of y_test","dbed885f":"# Importing Models\nfrom sklearn.linear_model import LinearRegression              # Importing LinearRegression Algo\nfrom sklearn.tree import DecisionTreeRegressor                 # Importing DecisionTreeRegressor Algo\nfrom sklearn.ensemble import RandomForestRegressor             # Importing RandomForestRegressor Algo","b77135eb":"# Creating our LinearRegression model and fitting the data into it.\nlinreg_model = LinearRegression()\nlinreg_model.fit(X_train_s, y_train)","338467dd":"# Creating our DecisionTreeRegressor model and fitting the data into it.\ndt_model = DecisionTreeRegressor()\ndt_model.fit(X_train_s, y_train)","8b8090e9":"# Creating our RandomForestRegressor model and fitting the data into it.\nrf_model=RandomForestRegressor()\nrf_model.fit(X_train_s,y_train)","8fd877c3":"# Preparations for Hyper Parameter Tuning\n\nfrom sklearn.model_selection import GridSearchCV          # Importing GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV    # Importing RandomizedSearchCV\n\nn_estimators = [10,50,100,200,300,500]                    # Number of trees in random forest\nmax_features = ['auto', 'log2',2,4,8,12]                  # Number of features to consider at every split\nmax_depth = [2,4,8,16,25]                                 # Maximum number of levels in tree=\n\n# Creating param_grid for hyper-parameter tuning.\nrandom_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth,}","84c992bb":"# Creating our RandomForestRegressor model from GridSearchCV and fitting the data into it.\nrf_model_grid = GridSearchCV(estimator = rf_model, param_grid=random_grid, cv = 3, n_jobs = -1 )\nrf_model_grid.fit(X_train_s,y_train)","15543f1b":"# Creating our RandomForestRegressor model from RandomizedSearchCV and fitting the data into it.\nrf_model_random = RandomizedSearchCV(estimator = rf_model, param_distributions = random_grid, \n                                     n_iter = 10, cv = 3, verbose=2, random_state=100, n_jobs = -1)\nrf_model_random.fit(X_train_s, y_train)","15dff449":"# Predictions from `linreg_model` - TRAIN Set\ny_train_pred_lr = linreg_model.predict(X_train_s)     # Predicted Target Values for TRAIN set.\nprint(y_train_pred_lr.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_lr[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","eb3e7e95":"# Predictions from `linreg_model` - TEST Set\ny_test_pred_lr = linreg_model.predict(X_test_s)     # Predicted Target Values for TEST set.\nprint(y_test_pred_lr.shape)                         # Shape of Predicted Target Value - TEST set.\ny_test_pred_lr[:10]                                 # Top 10 Predicted Target Values for TEST set.","3f364ca3":"# Predictions from `dt_model` - TRAIN Set\ny_train_pred_dt = dt_model.predict(X_train_s)         # Predicted Target Values for TRAIN set.\nprint(y_train_pred_dt.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_dt[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","0327a9ec":"# Predictions from `dt_model` - TEST Set\ny_test_pred_dt = dt_model.predict(X_test_s)          # Predicted Target Values for TEST set.\nprint(y_test_pred_dt.shape)                          # Shape of Predicted Target Value - TEST set.\ny_test_pred_dt[:10]                                  # Top 10 Predicted Target Values for TEST set.","552ccaab":"# Predictions from `rf_model` - TRAIN Set\ny_train_pred_rf = rf_model.predict(X_train_s)         # Predicted Target Values for TRAIN set.\nprint(y_train_pred_rf.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_rf[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","5a96fe06":"# Predictions from `rf_model` - TEST Set\ny_test_pred_rf = rf_model.predict(X_test_s)          # Predicted Target Values for TEST set.\nprint(y_test_pred_rf.shape)                          # Shape of Predicted Target Value - TEST set.\ny_test_pred_rf[:10]                                  # Top 10 Predicted Target Values for TEST set.","48b36f91":"# Predictions from `rf_model_grid` - TRAIN Set\ny_train_pred_rf_grid = rf_model_grid.predict(X_train_s)    # Predicted Target Values for TRAIN set.\nprint(y_train_pred_rf_grid.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_rf_grid[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","cd72b31a":"# Predictions from `rf_model_grid` - TEST Set\ny_test_pred_rf_grid = rf_model_grid.predict(X_test_s)     # Predicted Target Values for TEST set.\nprint(y_test_pred_rf_grid.shape)                          # Shape of Predicted Target Value - TEST set.\ny_test_pred_rf_grid[:10]                                  # Top 10 Predicted Target Values for TEST set.","afae1644":"# Predictions from `rf_model_random` - TRAIN Set\ny_train_pred_rf_random = rf_model_random.predict(X_train_s)  # Predicted Target Values for TRAIN set.\nprint(y_train_pred_rf_random.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_rf_random[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","978f52c2":"# Predictions from `rf_model_random` - TEST Set\ny_test_pred_rf_random = rf_model_random.predict(X_test_s)     # Predicted Target Values for TEST set.\nprint(y_test_pred_rf_random.shape)                          # Shape of Predicted Target Value - TEST set.\ny_test_pred_rf_random[:10]                                  # Top 10 Predicted Target Values for TEST set.","3e8cd93d":"# Utility \/ Helper Function - Regression Model Evaluation\n\ndef regression_model_evaluation(y, y_pred, set_type='', features_count=None):\n    '''\n    Utility\/Helper method to calulate the Evaluation parameters for a regression model\n    '''\n    from sklearn import metrics # Importing metrics from SK-Learn\n    result = {}\n    \n    if set_type != '':\n        set_type = '_'+set_type\n        \n    # Mean Absolute Error on train set.\n    result['MAE'] = metrics.mean_absolute_error(y, y_pred) \n    # Mean Squared Error on train set.\n    result['MSE'] = metrics.mean_squared_error(y, y_pred)  \n    # Root Mean Squared Error on train set.\n    result['RMSE'] = np.sqrt(result['MSE'])                      \n    # R_squared on train set.\n    result['R_squared'] = metrics.r2_score(y, y_pred)      \n    \n    # Adj r2 = 1-(1-R2)*(n-1)\/(n-p-1)\n    if features_count:\n        # Adjusted R_squared on train set.\n        result['Adj_R_squared'] = 1 - (((1 - result['R_squared']) * (len(y)-features_count))\/(len(y)-features_count-1))\n    # Returning with appending type to key and rounding value \n    return {f'{k}'+set_type: round(v, 4) for k, v in result.items()} ","00187d73":"# Evaluation metrics for LinearRegression - TRAIN set\nmetrics_lr_train = regression_model_evaluation(y_train, y_train_pred_lr, features_count=8)\nmetrics_lr_train","fc8740e8":"# Evaluation metrics for LinearRegression - TEST set\nmetrics_lr_test = regression_model_evaluation(y_test, y_test_pred_lr, features_count=8)\nmetrics_lr_test","cdb53823":"# Converting metrics map to DataFrame\nLR_Train_mertrics = pd.DataFrame(metrics_lr_train.items(), columns=['Metrics', 'LR_Train'])\nLR_Test_mertrics = pd.DataFrame(metrics_lr_test.items(), columns=['Metrics', 'LR_Test'])","ca66e614":"# To get the intercept of the model.\nlinreg_model.intercept_","59509f4e":"# To get the coefficients of the model.\ncoefs = linreg_model.coef_\nfeatures = X_train_s.columns\n\nlist(zip(features,coefs))","f82518ba":"# Evaluation metrics for DecisionTreeRegressor - TRAIN set\nmetrics_dt_train = regression_model_evaluation(y_train, y_train_pred_dt, features_count=8)\nmetrics_dt_train","ba11f53f":"# Evaluation metrics for DecisionTreeRegressor - TEST set\nmetrics_dt_test = regression_model_evaluation(y_test, y_test_pred_dt, features_count=8)\nmetrics_dt_test","a3737e5f":"# Converting metrics map to DataFrame\nDT_Train_mertrics = pd.DataFrame(metrics_dt_train.items(), columns=['Metrics', 'DT_Train'])\nDT_Test_mertrics = pd.DataFrame(metrics_dt_test.items(), columns=['Metrics', 'DT_Test'])","67214249":"# DecisionTreeRegressor Score; Same as R-Squared from X and y; So it internally calculates r-squared of y and y_pred (-from X)\nprint('Train set: ',dt_model.score(X_train_s,y_train))\nprint('Test set: ',dt_model.score(X_test_s,y_test))","3bb16371":"# Evaluation metrics for RandomForestRegressor - TRAIN set\nmetrics_rf_train = regression_model_evaluation(y_train, y_train_pred_rf, features_count=8)\nmetrics_rf_train","a4f291d5":"# Evaluation metrics for RandomForestRegressor - TEST set\nmetrics_rf_test = regression_model_evaluation(y_test, y_test_pred_rf, features_count=8)\nmetrics_rf_test","76fa1668":"# Converting metrics map to DataFrame\nRF_Train_mertrics = pd.DataFrame(metrics_rf_train.items(), columns=['Metrics', 'RF_Train'])\nRF_Test_mertrics = pd.DataFrame(metrics_rf_test.items(), columns=['Metrics', 'RF_Test'])","f7f9776f":"# RandomForestRegressor Score; Same as R-Squared from X and y; So it internally calculates r-squared of y and y_pred (-from X)\nprint('Train set: ',rf_model.score(X_train_s,y_train))\nprint('Test set: ',rf_model.score(X_test_s,y_test))","9afa722a":"# Evaluation metrics for RandomForestRegressor with GridSearchCV - TRAIN set\nmetrics_rf_grid_train = regression_model_evaluation(y_train, y_train_pred_rf_grid, features_count=8)\nmetrics_rf_grid_train","ec2e9756":"# Evaluation metrics for RandomForestRegressor with GridSearchCV - TEST set\nmetrics_rf_grid_test = regression_model_evaluation(y_test, y_test_pred_rf_grid, features_count=8)\nmetrics_rf_grid_test","0aec69ca":"# Converting metrics map to DataFrame\nRF_Grid_Train_mertrics = pd.DataFrame(metrics_rf_grid_train.items(), columns=['Metrics', 'RF_Grid_Train'])\nRF_Grid_Test_mertrics = pd.DataFrame(metrics_rf_grid_test.items(), columns=['Metrics', 'RF_Grid_Test'])","558fb657":"# Evaluation metrics for RandomForestRegressor with RandomizedSearchCV - TRAIN set\nmetrics_rf_random_train = regression_model_evaluation(y_train, y_train_pred_rf_random, features_count=8)\nmetrics_rf_random_train","7f76f7cf":"# Evaluation metrics for RandomForestRegressor with RandomizedSearchCV - TEST set\nmetrics_rf_random_test = regression_model_evaluation(y_test, y_test_pred_rf_random, features_count=8)\nmetrics_rf_random_test","438cd3c7":"# Converting metrics map to DataFrame\nRF_Random_Train_mertrics = pd.DataFrame(metrics_rf_random_train.items(), columns=['Metrics', 'RF_Random_Train'])\nRF_Random_Test_mertrics = pd.DataFrame(metrics_rf_random_test.items(), columns=['Metrics', 'RF_Random_Test'])","4fc1c4eb":"# Converting Train metrics df\nTrain_mertrics = LR_Train_mertrics.merge(\n                    DT_Train_mertrics, on='Metrics').merge(\n                    RF_Train_mertrics, on='Metrics').merge(\n                    RF_Grid_Train_mertrics, on='Metrics').merge(\n                    RF_Random_Train_mertrics, on='Metrics').set_index(keys='Metrics')\nTrain_mertrics","d2eb5ace":"# Converting Train metrics df\nTest_mertrics = LR_Test_mertrics.merge(DT_Test_mertrics, on='Metrics').merge(\n                    RF_Test_mertrics, on='Metrics').merge(\n                    RF_Grid_Test_mertrics, on='Metrics').merge(\n                    RF_Random_Test_mertrics, on='Metrics').set_index(keys='Metrics')\nTest_mertrics","0fe1ee04":"model_mertrics = Train_mertrics.merge(Test_mertrics, on='Metrics')\nmodel_mertrics = model_mertrics.reindex(\n    columns=['LR_Train', 'LR_Test', 'DT_Train', 'DT_Test', 'RF_Train', 'RF_Test', 'RF_Grid_Train', 'RF_Grid_Test', 'RF_Random_Train', 'RF_Random_Test'])\n\nmodel_mertrics","96a75119":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_lr},columns=['Y_ACT','Y_Pred']) \ntrain_diff.head()    # Preview of DF - y_train and y_train_pred","1b07b57d":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_lr},columns=['Y_ACT','Y_Pred'])\ntest_diff.head()    # Preview of DF - y_test and y_test_pred","a84cacd0":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - LinearRegression')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","5099f1d5":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_dt},columns=['Y_ACT','Y_Pred'])\ntrain_diff.head() # Preview of DF - y_train and y_train_pred","c9e962df":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_dt},columns=['Y_ACT','Y_Pred'])\ntest_diff.head()   # Preview of DF - y_test and y_test_pred","12a9a4d8":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - DecisionTreeRegressor')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","19bebc12":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_rf},columns=['Y_ACT','Y_Pred'])\ntrain_diff.head() # Preview of DF - y_train and y_train_pred","67935c72":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_rf},columns=['Y_ACT','Y_Pred'])\ntest_diff.head()   # Preview of DF - y_test and y_test_pred","e4477977":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - RandomForestRegressor')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","36984283":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_rf_grid},columns=['Y_ACT','Y_Pred'])\ntrain_diff.head() # Preview of DF - y_train and y_train_pred","159a2ef6":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_rf_grid},columns=['Y_ACT','Y_Pred'])\ntest_diff.head()  # Preview of DF - y_test and y_test_pred","5706d33b":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - RandomForestRegressor With GridSearchCV')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","b1610d4a":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_rf_random},columns=['Y_ACT','Y_Pred'])\ntrain_diff.head() # Preview of DF - y_train and y_train_pred","0113120f":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_rf_random},columns=['Y_ACT','Y_Pred'])\ntest_diff.head() # Preview of DF - y_test and y_test_pred","09cd6530":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - RandomForestRegressor With RandomizedSearchCV')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","fc8f5d85":"model_mertrics # Preview of Model Evaluation Metrics","d52e9217":"There are 4 categorical features and as per below table we will perform encoding on each feature.\n\n|Column|Type of Encoding|\n|--:|:--|\n|Type|**OneHot** - As there are only 2 unique values|\n|Year|**Label** - To keep the ordinal importance|\n|Region|**Target** - As it has high cardinality we can use TargetEncoding to have effect of each Region on AveragePrice|\n|Month|**Target** - As it has high cardinality we can use TargetEncoding to have effect of each Month on AveragePrice|","f3ddbdcb":"__Observations__\n\n*   Average price drops in the months of December, January, February, May, June, July\n*   No much varience in price w.r.t Quarter - So we can drop this column. \n*   In winters Avacado prices drops more than any other seasons - as seasons are correlated and gives more info we can drop `Season`, `Date` and have `Month` column as an important feature.\n\n\n","316ed012":"#### Assumptions - Checking for No Multicollinearity","77564078":"Rename columns as per conveniance","7adc924c":"### Model Predictions","e70e6c30":"#### 1. Evaluation Parameters for - linreg_model","f6647772":"* There are total of 18249 and 13 columns \n* From `info`, we can infer that there are no missing values.\n* Target Variable 'Average Price' looks normally distribured as mean and median(50 percentile value) are almost similar, but TV seems to be right skewed\n\n","76d1a160":"### Preparing X and y","435f1e10":"#### Final data after Scalings and Encodings","60905956":"Converting `Year` to `object` from `numeric`","f36b9bd7":"###  Pre processing data\n\n* __Handling issues found in pre-profiling__\n* __Preparing data for modelling__\n      - Handling missing values\n      - Type conversions\n      - Feature engineering\n      - Transforming exploratory variable\n      \n---\n\nFrom the above observations we will:\n- Reset_index\n- Rename features as per conveniance\n- Altering the type of features\n- Feature engineer some columns\n- Drop ineffective features\n- Drop highly correlated features\n- Drop records with right skewed target variable","14a71d41":"#### 5. RandomForestRegressor - RandomizedSearchCV","c773d483":"## 6. Model Evaluations\n\n\n---\n\n","dc2ba13e":"#### 4. RandomForestRegressor - GridSearchCV","94e7dfb5":"Converting `Date` to `datetime` from `object`","886b223d":"### Building Models","82336a88":"\n<p>\nThe dataset consists of the information about HASS Avocado. \n\nHistorical data on avocado prices and sales volume in multiple US markets. Various variables present in the dataset includes Date, AveragePrice,Total Volume, Total Bags,Year,Type etc.\n\nThe dataset comprises of 18249 observations of 14 columns. Below is a table showing names of all the columns and their description.\n<\/p>\n\n|Column|Description|\n|--:|:--|\n|**Date**|The date of the observation|\n|**AveragePrice**|Average price of a single avocado - ***Target Variable***|\n|**Total Volume**|Total number of avocados sold|\n|**4046**|Total avocados with PLU 4046 - *Small\/Medium Hass Avocado (\\~3-5oz avocado)* sold|\n|**4225**|Total number of avocados with PLU 4225 - *Large Hass Avocado (\\~8-10oz avocado)* sold|\n|**4770**|Total number of avocados with PLU 4770 - *Extra Large Hass Avocado (\\~10-15oz avocado)* sold|\n|**type**|Conventional or Organic|\n|**year**|Year of observation|\n|**Region**|City or region of the observation|\n\n\n\n","54608b62":"#### 2. Evaluation Parameters for - dt_model","239ea424":"We will remove extreme values above avg price 2.8, this makes our TV symetric","7a6a2af0":"## Table of Contents\n\n1. Problem Statement\n2. Importing Libraries\n3. Data\n  - Loading data\n  - Description of data columns\n  - Understanding data - Pre-Profiling\n4. Exploratory Data Analysis\n  - Pre processing data\n      - Handling missing values\n      - Type conversions\n      - Feature engineering\n      - Transforming exploratory variable\n  - Post profiling\n5. Modelling using sklearn\n  - Data Preparation\n    - Splitting data as train and test\n    - Scaling and encoding\n  - Building Models\n  - Model Predictions\n6. Model Evaluations\n7. Model Plotting\n    - Comparing models\n8. Conclusions\n    - Analyzing and finalizing best-fit model\n  \n","ade8b0a8":"Scaling numerical fields using StandardScaler","9ef0f9ce":"Creating DataFrames of Metrics for 5 Models","91bae538":"## 4. Exploratory Data Analysis\n---","e2c009e1":"### Hyper Parameter Tuning \n    - To find best RandomForestRegressor Using GridSearchCV and RandomizedSearchCV","e1a54cbb":"### Understanding data - Pre-Profiling","65ea5164":"#### 3. Predictions from RandomForestRegressor Model - rf_model","ede66fa4":"#### 2. Predictions from DecisionTreeRegressor Model - dt_model","cc448e25":"#### 4. Predictions from RandomForestRegressor - GridSearchCV  - rf_model_grid","47a44c74":"## 1. Problem Statement\n---","d83b5a75":"### Description of data columns","038b7284":"Deriving some insightful columns from __Date__ - like 'Season', 'Month', 'Quarter'","db0ae5a4":"## 8. Conclusions\n\n---\n\n\n  - Analyzing and finalizing best-fit model","9825b685":"#### 3. RandomForestRegressor","70de8190":"Scaling numerical fields using StandardScaler","eabe1368":"There are 3 categorical columns\n* __Type__ has on two values and distriburted uniformly\n* __Date__ and __Region__ are highly cardinal, so we will work on how to proceed further...","29fa2fed":"So droping 'PLU_4046', 'PLU_4225', 'TotalBags', 'SmallBags' which has very high Correlation","dbc3dd1d":"From the above table we can observe,\n1. LinearRegression Model has lease R-Squared Value - **UnderFit Model**\n2. DecisionTreeRegressor Model has maximum R-Squared Value for train data and less R-Squared Value for test data - **OverFit Model**\n3. RandomForestRegressor Model has better R-Squared Value for test data\n4. We can best version of RandomForestRegressor by *hyper parameter tuning* with GridSearchCV or RandomizedSearchCV","c5e8625f":"Working with type of features...","8b086f69":"### Post profiling","989304fc":"## 3. Data\n---","bddbecd7":"EDA\nHow Price are varying wrt to Region\n\nPrice and Type relation\n\n\nSeperate X and y \n  - Do correlation and drop few columns\n  - Joint plot\n  - Dist Plot\n  - Linear relation amoing x and y","154e7b6e":"#### Assumptions - Target Variable is Normally Distributed","ebae651a":"#### 2. DecisionTreeRegressor","b5b22655":"Given historical data on avocado prices and sales volume in multiple US markets and various other factors like Date, AveragePrice,Total Volume, Total Bags,Year,Type etc.\n\nThe goal is to predict average price of avocado using best regression model among Linear Regression, Decision Tree Regressor and Randon Forest Regressor.","968cf4b2":"## 5. Modelling using sklearn\n---","54fb3c4d":"There are some outliers present but these are not too extreme so we do not drop any records","61ededbe":"#### 5. Evaluation Parameters for - rf_model_random","1fa44c98":"#### 1. Predictions from LinearRegression Model - linreg_model","f1b27048":"#### 1. LinearRegression","937f619b":"#### 3. Evaluation Parameters for - rf_model","f9cc31bd":"### Loading data...","864b9ab8":"#### 4. Evaluation Parameters for - rf_model_grid","ef470517":"**Profiling before Data Processing** <br><br>\n__Dataset info__:\n- Number of variables: 13\n- Number of observations: 18249\n- Missing cells: 0\n\n\n__Variables types__: \n- Numeric: 10\n- Categorical: 3\n\n__Observations__: \n* There seems to be some problem with __index__, as there are only 53 unique values and total records are 18000+\n* __Target variable__ in normally distributed but wiht slight skewedness at right\n* There is equal distribution of __conventional__ and __organic__ avacado types\n* __Region__ and __Date__ are uniformly distributed and have high cardinality\n* Most of variables like _4046, 4225, Total Bags, Small Bags, Large Bags_ are highly corellated with **Total Volume**","0339ab7a":"#### 5. Predictions from RandomForestRegressor - RandomizedSearchCV  - rf_model_random","4abd03bd":"## 7. Model Plotings","76d5d477":"Fixing issues with index","465218e5":"Analyzing how `AveragePrice` varies w.r.t `Month`, `Quarter`, `Season`. ","d362ceb5":"## 2. Importing Libraries\n---","0cce3f1d":"# Avacado Price Prediction Regression Models"}}