{"cell_type":{"ad28cb0c":"code","91bf2461":"code","1ff273e7":"code","7160cc98":"code","9ead27e5":"code","cfe1974c":"code","1146cd87":"code","67e10eb8":"code","10d4c695":"code","8eeb4be5":"code","9b6c736e":"code","5b73a3cd":"code","f4a6cbac":"code","300deadc":"code","8bff0968":"code","36616d18":"code","e55341ff":"code","dea9de9a":"code","a4f6261d":"code","c79b68be":"code","35b9ee27":"code","d5d9ee7f":"code","e00f47b4":"code","36fa22e4":"code","c27f5343":"code","cf74111d":"code","92f30038":"code","5c4a27f5":"code","bc27546a":"code","53ea03d2":"code","4c1576bc":"code","2df3c45d":"code","88150c91":"code","d558bf21":"code","88a3dcd1":"code","53deddd8":"code","7dbeff27":"code","bc25aac0":"code","a1ef8d73":"code","b7ca89fb":"code","50c08afe":"code","e8dc57c6":"code","52da7291":"code","82f09720":"code","f728b70a":"code","9538864a":"code","45f85414":"code","2465cd4c":"code","c057ae27":"code","836237f3":"code","a63e96ab":"markdown","aff4fe49":"markdown","d7276f93":"markdown","ddbbf09d":"markdown","2d65dffe":"markdown","c43115d8":"markdown","c4066e19":"markdown","f5a1b0e1":"markdown","2d559bda":"markdown","471406d2":"markdown","ede27b4d":"markdown","59206fa6":"markdown","9feaf762":"markdown","63a110e9":"markdown","253ec9b5":"markdown","5155ea27":"markdown","44a5a506":"markdown","59894009":"markdown","46ee9f10":"markdown","25ac64dd":"markdown","61ddf652":"markdown","9d489eab":"markdown","b83e3e49":"markdown","e268c185":"markdown"},"source":{"ad28cb0c":"import pandas as pd\nimport numpy as np\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","91bf2461":"#importing data\ndf = pd.read_csv('..\/input\/country-data-test-2020\/Country-data.csv')","1ff273e7":"df.head()","7160cc98":"df.shape","9ead27e5":"#We have no null values in the data\ndf.isnull().sum(axis=0)","cfe1974c":"#Check duplicate records in data\ndf.duplicated(subset=None, keep='first').sum()","1146cd87":"#There are 3 columns: exports, health and imports which have been reported as percentage of GDPP.\n#We will be convering these to absolute values.\ndf['health'] = round(df['health']*df['gdpp']\/100,2)\ndf['exports'] = round(df['exports']*df['gdpp']\/100,2)\ndf['imports'] = round(df['imports']*df['gdpp']\/100,2)\ndf.head()","67e10eb8":"#Let's see the distribution of all the variables available in the dataset\nplt.figure(figsize=(20,20))\nfor i,col in enumerate (list(df.drop(['country'],axis=1).columns)):\n    plt.subplot(3,3,i+1)\n    sns.distplot(df[col])\nplt.show()","10d4c695":"#Visualizing variables using box plots. This will also help us identify outliers.\nplt.figure(figsize=(16,10))\nfor i,col in enumerate (list(df.drop(['country'],axis=1).columns)):\n    plt.subplot(3,3,i+1)\n    sns.boxplot(df[col])\nplt.show()","8eeb4be5":"#In this scatter, we can see a strong correlation between GDP per capita and child mortality rates\nsns.scatterplot(x='child_mort', y='gdpp',data=df)","9b6c736e":"#Let's visualize correlations between different variables\nplt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True,cmap='YlGnBu')","5b73a3cd":"#To get a better understanding of how all variables are related to one another, we can also use a pair plot.\nsns.pairplot(df)","f4a6cbac":"df.describe()","300deadc":"for each in list(df.drop(['child_mort','country'],axis=1).columns):\n    df[each][df[each]>=df[each].quantile(0.99)] = df[each].quantile(0.99)\ndf.describe()","8bff0968":"df['child_mort'][df['child_mort']<=df['child_mort'].quantile(0.01)] = df['child_mort'].quantile(0.01)\ndf.describe()","36616d18":"#Visualizing variables using box plots. This will also help us identify outliers again.\nplt.figure(figsize=(16,10))\nfor i,col in enumerate (list(df.drop(['country'],axis=1).columns)):\n    plt.subplot(3,3,i+1)\n    sns.boxplot(df[col])\nplt.show()","e55341ff":"for each in ['gdpp','imports','exports','income','health']:\n    df[each][df[each]>=df[each].quantile(0.90)] = df[each].quantile(0.90)\ndf.describe()","dea9de9a":"#Visualizing variables using box plots. This will also help us identify outliers again.\nplt.figure(figsize=(16,10))\nfor i,col in enumerate (list(df.drop(['country'],axis=1).columns)):\n    plt.subplot(3,3,i+1)\n    sns.boxplot(df[col])\nplt.show()","a4f6261d":"#Function to calculate hopkins score\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nimport numpy as np\nfrom math import isnan\nfrom statistics import median, mean\n \ndef hopkins(X):\n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    H = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","c79b68be":"#Since hopkins score can vary due to the randomness of the sample chosen, we will take 20 samples and look at the mean and median. \nh_scores = []\nfor i in range(20):\n    h_scores.append(round(hopkins(df.drop('country', axis = 1)),2))\nprint(h_scores)\nprint('Median of 20 samples: ',median(h_scores))\nprint('Mean of 20 samples: ',mean(h_scores))\n","35b9ee27":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf1 = scaler.fit_transform(df.drop('country', axis = 1))\ndf1 = pd.DataFrame(df1, columns = df.drop(['country'],axis=1).columns)\ndf1.head()","d5d9ee7f":"df1.describe()","e00f47b4":"# We first need to determine the valye of K. There are two methods for this - \n# Silhouette score\n# Elbow curve (SSD)\n\n#First, we will be looking at silhouette score metric\n\nfrom sklearn.metrics import silhouette_score\nss = []\nfor k in range(2, 11):\n    kmean = KMeans(n_clusters = k).fit(df1)\n    ss.append([k, silhouette_score(df1, kmean.labels_)])\ntemp = pd.DataFrame(ss)    \nplt.plot(temp[0], temp[1])","36fa22e4":"#Let's look at the elbow curve now\nssd = []\nfor k in range(2, 11):\n    kmean = KMeans(n_clusters = k).fit(df1)\n    ssd.append([k, kmean.inertia_])\n    \ntemp = pd.DataFrame(ssd)\nplt.plot(temp[0], temp[1])","c27f5343":"# Selecting K=3\n# Final Kmean Clustering\n\nkmean = KMeans(n_clusters = 3, random_state = 1) #fixing random state so the cluster IDs do not change\nkmean.fit(df1)","cf74111d":"#Let's make a copy of the original dataframe to add the cluster labels.\ndf_km = df.copy()","92f30038":"#We'll name the new column as 'labels'\nlabel = pd.DataFrame(kmean.labels_, columns = ['label'])\nlabel.head()","5c4a27f5":"#Next, we append this column to the original data frame copy.\ndf_km = pd.concat([df_km, label], axis =1)\ndf_km.head()","bc27546a":"#We'll run another iteration of K-means with value of K set to 4, using similar process as we did for k=3\nkmean4 = KMeans(n_clusters = 4, random_state = 1) #fixing random state so the cluster IDs do not change\nkmean4.fit(df1)\ndf_km4 = df.copy()\nlabel = pd.DataFrame(kmean4.labels_, columns = ['label'])\ndf_km4 = pd.concat([df_km4, label], axis =1)\ndf_km4.head()","53ea03d2":"#Let's see how the labels are spread out now. \ndf_km.label.value_counts().plot.barh()","4c1576bc":"#Let's also see the spread for k=4\ndf_km4.label.value_counts().plot.barh()","2df3c45d":"#We can use scatterplots to see how our data points have been assigned. \nplt.figure(figsize=(20,10))\nplt.subplot(131)\nsns.scatterplot(x='gdpp',y='child_mort',hue='label',data=df_km,palette='Set1')\nplt.subplot(132)\nsns.scatterplot(x='gdpp',y='income',hue='label',data=df_km,palette='Set1')\nplt.subplot(133)\nsns.scatterplot(x='income',y='child_mort',hue='label',data=df_km,palette='Set1')\nplt.show()","88150c91":"# We can visualize using boxplots for each feature\nplt.figure(figsize=(16,8))\nfor i,each in enumerate(['gdpp','income','child_mort']):\n    plt.subplot(1,3,i+1)\n    ax=sns.boxplot(y=df_km[each],x=df_km.label)\n    ax.set_yscale('log') #Using log scale to better visualize child mortality\nplt.show()","d558bf21":"#Let's see how the mean of features, broken down by cluster\nax=df_km.drop(['country'],axis=1).groupby('label')['child_mort','gdpp','income'].mean().plot(kind='barh',figsize=(16,6))\nax.set_xscale('log') #using log scale to be able to see child_mort next to other features\nplt.show()","88a3dcd1":"#We can use scatterplots to see how our data points have been assigned. \nplt.figure(figsize=(20,10))\nplt.subplot(131)\nsns.scatterplot(x='gdpp',y='child_mort',hue='label',data=df_km4,palette='Set1')\nplt.subplot(132)\nsns.scatterplot(x='gdpp',y='income',hue='label',data=df_km4,palette='Set1')\nplt.subplot(133)\nsns.scatterplot(x='income',y='child_mort',hue='label',data=df_km4,palette='Set1')\nplt.show()","53deddd8":"# We can visualize using boxplots for each feature\nplt.figure(figsize=(16,8))\nfor i,each in enumerate(['gdpp','income','child_mort']):\n    plt.subplot(1,3,i+1)\n    ax=sns.boxplot(y=df_km4[each],x=df_km4.label)\n    ax.set_yscale('log') #Using log scale to better visualize child mortality\nplt.show()","7dbeff27":"#Let's see how the mean of features, broken down by cluster\nax=df_km4.drop(['country'],axis=1).groupby('label')['child_mort','gdpp','income'].mean().plot(kind='barh',figsize=(16,6))\nax.set_xscale('log') #using log scale to be able to see child_mort next to other features\nplt.show()","bc25aac0":"#Now, let us filter the data on our target cluster and see the top 5 countries in direst need of financial support\n#We will be using the sorting criteria as GDPP (ascending), Child Mortality (Descending) and Income (ascending) as the sort levels, in that order.\ntarget_km = df_km[df_km['label']==2].sort_values(by=['gdpp','child_mort','income'], ascending=[True,False,True])","a1ef8d73":"#Let's see what our top five countries are from K-Means clustering\ntarget_km[:5]['country']","b7ca89fb":"#We will use the scaled dataset\ndf1.head()","50c08afe":"#We will first try to run the algorithm using single linkage\nmergings = linkage(df1, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","e8dc57c6":"#Let's also take a look at results using complete linkage\nmergings = linkage(df1, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","52da7291":"# We choose are cutting point to get 3 clusters\ncluster_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )","82f09720":"#We create a copy of the oriignal DF, and add these labels to it. \ndf_hc = df.copy()\ndf_hc['label']=cluster_labels\ndf_hc.head()","f728b70a":"#Plotting the value counts for our clusters, and relating this with the dendrogram above, we can see that even if we had chosen 4 as the number of clusters, our target cluster (0) would remain unaffected. Since upon choosing 4, the cluster 1 (the biggest one) would just break up into two smaller ones, while our target cluster still remains the same (as explained in the cluster profiling section below)\ndf_hc.label.value_counts().plot.barh()","9538864a":"#We can use scatterplots to see how our data points have been assigned. \nplt.figure(figsize=(20,10))\nplt.subplot(131)\nsns.scatterplot(x='gdpp',y='child_mort',hue='label',data=df_hc,palette='Set1')\nplt.subplot(132)\nsns.scatterplot(x='gdpp',y='income',hue='label',data=df_hc,palette='Set1')\nplt.subplot(133)\nsns.scatterplot(x='income',y='child_mort',hue='label',data=df_hc,palette='Set1')\nplt.show()","45f85414":"# We can visualize using boxplots for each feature\nplt.figure(figsize=(16,8))\nfor i,each in enumerate(['gdpp','income','child_mort']):\n    plt.subplot(1,3,i+1)\n    ax=sns.boxplot(y=df_hc[each],x=df_hc.label)\n    ax.set_yscale('log') #Using log scale to better visualize child mortality\nplt.show()","2465cd4c":"#Let's see how the mean of features, broken down by cluster\nax=df_hc.drop(['country'],axis=1).groupby('label')['child_mort','gdpp','income'].mean().plot(kind='barh',figsize=(16,6))\nax.set_xscale('log') #using log scale to be able to see child_mort next to other features\nplt.show()","c057ae27":"#Now, let us filter the data on our target cluster and see the top 5 countries in direst need of financial support\n#We will be using the sorting criteria as GDPP (ascending), Child Mortality (Descending) and Income (ascending) as the sort levels, in that order.\ntarget_hc = df_hc[df_hc['label']==0].sort_values(by=['gdpp','child_mort','income'], ascending=[True,False,True])","836237f3":"#We now observe that the list of countries we get from hierarchical clustering is exactly the same as we had obtained from K-means. \n#Hence, we can present these findings to the CEO with a fair amount of confidence and evidence to back our deductions.\ntarget_hc[:5]['country']","a63e96ab":"## Results from Hierarchical Clustering","aff4fe49":"## Cleaning the data","d7276f93":"## K-Means Clustering","ddbbf09d":"From what we can obseve during cluster profiling, we have the below three clusters: \n* Cluster 1\n    * Contains data points with the highest income and GDPP, and lowest child mortality rates\n* Cluster 2\n    * Contains data points with lowest income and GDPP, and highest child mortality rates\n    * This should our target cluster that needs to be reported to the business.\n    \n* Cluster 0\n    * Contains data points with a medium level income and GDPP and moderately high child mortality rate","2d65dffe":"We can make several observations here. \n* All the factors that would be impacted by the financial strenght of a country show a strong positive correlation with the GDPP.\n* Child mortality and Total Fertility are seen to be decreasing as the GDPP increases. \n* Total fertility and child mortality have a strong positive correlation, indicating counntries with a high fertility rate also have much higher child mortality rates. \n* In summary, income and GDP seem to be playing a major role in determining the socio economic well being of a country, and most importantly, the child mortaliy and life expectancy rates. ","c43115d8":"* Our variables now seem to be in an adequate range relatively free of major outliers that could have heavily impacted the clustering process.\n* We will move forward to model building now.","c4066e19":"## Results from K-Means Clustering","f5a1b0e1":"## Final decision for value of K\nFrom the plots seen above, we observe that our target cluster can be set as the one with high value of child mortality and low GDP and income parameters. Thus, we can achieve the business objective promptly by using the value of k as 3. We can move forward with K set to 3. ","2d559bda":"We get a fairly good value of the Hopkins statistic indicating that our dataset is not completely randomly distributed and there are some inherent clusters present in the data. \nWe can proceed with building our model further.","471406d2":"## Scaling of features\nWe will be using the standard scaler provided by sklearn for this purpose. ","ede27b4d":"## Outlier treatment\nWe need to treat the outliers in the data. However, as pointed out earlier we would need to be careful in our approach keeping in mind that we must not lose information valudable to the business objective in this process. \n* Since the size of the data set is not huge and every country needs representation in the final result, we must not drop the rows that contain the outliers. \n* A good approach to follow here would be capping. We can perform capping on a soft range (retaining values between the 1st and 99th percentile.\n    * We will not be capping any outliers in the lower range for all columns except child mortality. This is because since the business objective is to identify countries with immediate need of help we must retain the low values in data to make sure these countries get the weightage they deserve in our model. \n    * We will be applying a cap on the lower end of child mortality since a high child mortality could end up being an extremely important parameter in determining which countries require support. ","59206fa6":"The elbow curve seems to bend at around k=3. Hence, we can proceed 3 as our final number of clusters.","9feaf762":"## Performing Exploratory Data Analysis","63a110e9":"We can spot some outliers in the data now in all the columns. When we treat these outliers, we will need to keep in mind the business objective so that valuable information does not get capped or lost.","253ec9b5":"## Hopkins Score","5155ea27":"We also conduct cluster profiling for our data set when clustered using k=4","44a5a506":"**Problem Statement**\n\nHELP International is an international humanitarian NGO that is committed to fighting poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities. It runs a lot of operational projects from time to time along with advocacy drives to raise awareness as well as for funding purposes.\n\n \nAfter the recent funding programmes, they have been able to raise around $ 10 million. Now the CEO of the NGO needs to decide how to use this money strategically and effectively. The significant issues that come while making this decision are mostly related to choosing the countries that are in the direst need of aid. \n\n \nYour job is to categorise the countries using some socio-economic and health factors that determine the overall development of the country. Then you need to suggest the countries which the CEO needs to focus on the most.","59894009":"We now have the data frame df1 which has all the numerical variables scaled down using standard scaler.","46ee9f10":"## Cluster profiling from the model built using hierarchical clustering","25ac64dd":"## Cluster profiling from the model built using k-means\n\nWe will be using the features gdpp, child_mort and income for performing cluster performing cluster profiling. \nThis is because as per business understanding and objective, these would be the major deciding factors and they also showed a good spread when performing EDA.","61ddf652":"We are still seeing a significant number of outliers in the financial variables like gdpp, income, imports, exports, health. Let's further cap these down to 90th percentile on the upper end. ","9d489eab":"We see similar clusters here, as we saw in k-means. Our target cluster would be cluster 0, where the child mortality is high and income and GDPP are low. ","b83e3e49":"We can observe that the average silhouette score sees a dip on going from 2 to 3, and then a very big dip on going from 4 to 5. From here, we may pick 3 as our value of k. This can be further confirmed by looking at the elbow curve below","e268c185":"## Hierarchical Clustering\nWe now move on to building the clusters using hierarchical clustering algorithm. This will help us build more confidence in the clusters that we obtained using k-means clustering, and help boost business value."}}