{"cell_type":{"1ca13537":"code","ab29851f":"code","35cbd47b":"code","1a1418c4":"code","063297a1":"code","cb4b5628":"code","67f7e63d":"code","af8b4f26":"code","cf300d42":"code","8470c5f6":"code","310847b2":"code","48b30ef2":"code","13239322":"code","a81f15d3":"code","7b386891":"code","3cbbef25":"code","c6724057":"code","148fbf10":"code","80ff03c8":"code","1fa47301":"code","91232699":"code","3a07dba0":"code","06ddb0d8":"code","485cb871":"code","866f962c":"markdown","d9de7b7c":"markdown","f9ec62dd":"markdown","a8f62a17":"markdown","20733d4e":"markdown","28c085bc":"markdown","ba2a1688":"markdown","144a7de5":"markdown","0222b7d7":"markdown","771a7e7a":"markdown","299e4ec9":"markdown"},"source":{"1ca13537":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport copy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score","ab29851f":"link='..\/input\/german\/german_credit_data new.csv'\ngerman=pd.read_csv(link)\nprint(german.head(20))\n\n#Changing the name of the dependent variable as class is already defined in python and thereafter dropping it\ngerman['risk']=german['class']\ngerman=german.drop('class', axis=1)","35cbd47b":"#Changing the dependent categorical variavble to numeric\ngerman['risk']=german['risk'].replace('good', 1)\ngerman['risk']=german['risk'].replace('bad', 0)\n\ngerman['risk'].value_counts()","1a1418c4":"#Describing the dataset\ngerman.corr()","063297a1":"#Selecting the categorical columns\n\ncat_data=german.select_dtypes(exclude='int64')\ncat_columns=cat_data.columns\n\n#Showing the category wise distribution\nfor cat in cat_columns:\n    print(german[cat].value_counts())\n    print()","cb4b5628":"cat=cat_data['savings_status'].value_counts()\nsns.barplot(cat.index, cat.values)\nplt.xticks(rotation=90)","67f7e63d":"pd.crosstab(german.checking_status, german['risk']).plot(kind='bar')","af8b4f26":"pd.crosstab(german.credit_history, german['risk']).plot(kind='bar')","cf300d42":"pd.crosstab(german.purpose, german['risk']).plot(kind='bar')","8470c5f6":"pd.crosstab(german.savings_status, german['risk']).plot(kind='bar')","310847b2":"pd.crosstab(german.employment, german['risk']).plot(kind='bar')","48b30ef2":"len(german['credit_history'].unique())\ndf=german.credit_history.value_counts().to_dict()\n\ngerman['credit_history']=german.credit_history.map(df)\ngerman['credit_history']","13239322":"lb_make=LabelEncoder()\nfor col in cat_columns:\n   # if col!='credit_history':\n        german[col]=lb_make.fit_transform(german[col])\n\ngerman.head(20)","a81f15d3":"#german=pd.get_dummies(german, columns=['purpose'])","7b386891":"german.columns","3cbbef25":"import statsmodels.api as sm\n\ncolumns=german.columns.drop('risk')\n\nmodel=sm.GLM.from_formula(\"risk ~ checking_status+duration+credit_history+credit_amount+savings_status+employment+installment_commitment+personal_status+other_parties+residence_since+property_magnitude+age+other_payment_plans+housing+ existing_credits+job+num_dependents+own_telephone+foreign_worker+purpose\", family=sm.families.Binomial(), data=german)\n\nresult=model.fit()\nprint(result.summary())","c6724057":"#drop=german.select_dtypes(include='int64')\n#trial=drop.copy()\n\nreduced_columns=['checking_status', 'duration','credit_history', 'credit_amount','savings_status','installment_commitment', 'personal_status', 'purpose','own_telephone']\ny=german['risk']\nreduced=german[reduced_columns]\n\n#x=trial.loc[:, trial.columns!='risk']\nx_train, x_test, y_train, y_test=train_test_split(reduced, y,test_size=0.25, random_state=42)\n#x_train.head()\nreduced","148fbf10":"def find_best_parameter(clf,parameter,X_train,y_train):\n    best_model = GridSearchCV(clf,parameter).fit(X_train,y_train)\n    return best_model.best_estimator_","80ff03c8":"#Finding the best parameter using grid search CV\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Logistic Regression \nlog_reg_params = {'C': [0.01, 0.1, 1]}\nlogreg = find_best_parameter(LogisticRegression(max_iter = 10000), log_reg_params,x_train,y_train)\n\nlogreg.fit(x_train, y_train)\npredict=logreg.predict(x_test)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, predict))\nprint(\"Precision:\",metrics.precision_score(y_test, predict))\nprint(\"Recall:\",metrics.recall_score(y_test, predict))\nprint(\"Confusion Matrix:\")\nprint(metrics.confusion_matrix(y_test, predict))\n\nprint(\"Classification Report:\")\nprint(classification_report(predict, y_test))\n\nrandom=RandomForestClassifier()\n\nrandom.fit(x_train, y_train)\nprint(random.score(x_test, y_test))\npred2=random.predict(x_test)","1fa47301":"#Logistic Regression ROC Curve\n\nfpr, tpr, _=roc_curve(y_test, predict)\n\nroc_auc=auc(fpr, tpr)\n\nplt.plot(fpr, tpr, color='darkorange', label=\"ROC Curve (area=%0.2f)\" %roc_auc)\nplt.plot([0,1], [0,1], color='blue', linestyle='--')\nplt.xlim([0,1])\nplt.ylim([0,1.05])\nplt.xlabel('False Poistive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC AUC Curve')\nplt.legend(loc='lower right')","91232699":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\ntree=DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n\ntree.fit(x_train, y_train)\n\npred=tree.predict(x_test)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred))\nprint(\"Precision:\",metrics.precision_score(y_test, pred))\nprint(\"Recall:\",metrics.recall_score(y_test, pred))\nprint(\"Confusion Matrix:\")\nprint(metrics.confusion_matrix(y_test, pred))\n\nprint(\"Classification Report:\")\nprint(classification_report(pred, y_test))\n\n\nbag=BaggingClassifier()\nbag.fit(x_train, y_train)\nprint(bag.score(x_test, y_test))\npred1=bag.predict(x_test)","3a07dba0":"#Decision Tree ROC Curve\n\nfpr, tpr, _=roc_curve(y_test, pred)\n\nroc_auc=auc(fpr, tpr)\n\nplt.plot(fpr, tpr, color='darkorange', label=\"ROC Curve (area=%0.2f)\" %roc_auc)\nplt.plot([0,1], [0,1], color='blue', linestyle='--')\nplt.xlim([0,1])\nplt.ylim([0,1.05])\nplt.xlabel('False Poistive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC AUC Curve')\nplt.legend(loc='lower right')","06ddb0d8":"#Bagging ROC Curve\n\nfpr, tpr, _=roc_curve(y_test, pred1)\n\nroc_auc=auc(fpr, tpr)\n\nplt.plot(fpr, tpr, color='darkorange', label=\"ROC Curve (area=%0.2f)\" %roc_auc)\nplt.plot([0,1], [0,1], color='blue', linestyle='--')\nplt.xlim([0,1])\nplt.ylim([0,1.05])\nplt.xlabel('False Poistive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC AUC Curve')\nplt.legend(loc='lower right')","485cb871":"#Random Forest ROC Curve\n\nfpr, tpr, _=roc_curve(y_test, pred2)\n\nroc_auc=auc(fpr, tpr)\n\nplt.plot(fpr, tpr, color='darkorange', label=\"ROC Curve (area=%0.2f)\" %roc_auc)\nplt.plot([0,1], [0,1], color='blue', linestyle='--')\nplt.xlim([0,1])\nplt.ylim([0,1.05])\nplt.xlabel('False Poistive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC AUC Curve')\nplt.legend(loc='lower right')","866f962c":"# Fitting the data on Decision Tree Classifier","d9de7b7c":"# Importing data","f9ec62dd":"# Transforming the categorical values using label encoder","a8f62a17":"# Visual Exploratory data Analysis","20733d4e":"# Plotting category wise distribution of the good and bad accounts","28c085bc":"# Applying Logistic Regression","ba2a1688":"# Developing the model and finding out the significant variables","144a7de5":"# Importing the necessary libraries","0222b7d7":"# Only taking the necessary variables","771a7e7a":"# Plotting the ROC Curve","299e4ec9":"# Converting the purpose field using one hot encoding"}}