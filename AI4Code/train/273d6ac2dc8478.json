{"cell_type":{"ec2a58b1":"code","5b2ebd93":"code","b75d4ba7":"code","885daf92":"code","b784f2e5":"code","de5fc5f7":"code","29095aa2":"code","0031520f":"code","b89c6435":"code","e2dc20e2":"code","b8f36fca":"code","96ccc59f":"code","12039f73":"code","056acf8a":"markdown","c7d3c751":"markdown","338d5a54":"markdown","f0b93ead":"markdown","7f714d43":"markdown","fd650623":"markdown","c54868df":"markdown","e2cf6dbd":"markdown","92f990e0":"markdown","3bf9d110":"markdown","6a5c8027":"markdown","33492541":"markdown","ab8c61a7":"markdown","bb982f0a":"markdown","f84ca964":"markdown","f30a5425":"markdown","9df85840":"markdown","b442b812":"markdown"},"source":{"ec2a58b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Visualiztion:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# Machine Learning\/Modleing:\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\n# ignore warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Any results you write to the current directory are saved as output.","5b2ebd93":"DF_data_2c = pd.read_csv(\"..\/input\/column_2C_weka.csv\")\nDF_data_3c = pd.read_csv(\"..\/input\/column_3C_weka.csv\")\n\nprint('Preview of 2 Category data:')\nprint(DF_data_2c.shape)\nprint(DF_data_2c.keys())\nprint(DF_data_2c.dtypes)\n\nprint('\\n Preview of 3 Category data:')\nprint(DF_data_3c.shape)\nprint(DF_data_3c.keys())\nprint(DF_data_3c.dtypes)","b75d4ba7":"DF_data_3c.head()","885daf92":"DF_data_3c.describe()","b784f2e5":"print(DF_data_3c['class'].value_counts())\nsns.countplot(DF_data_3c['class']);","de5fc5f7":"vars = DF_data_3c.keys().drop('class')\n\n# Here we use a simple for loop to quickly create subplot boxplots of each variable.\nplt.figure(figsize=(20,10))\nfor idx, var in enumerate(vars):\n    plt.subplot(2,3,idx+1)\n    sns.boxplot(x='class', y=var, data=DF_data_3c)\n","29095aa2":"# Alternatively, we can visualize the data using violin plots...\nplt.figure(figsize=(20,10))\nfor idx, var in enumerate(vars):\n    plt.subplot(2,3,idx+1)\n    sns.violinplot(x='class', y=var, data=DF_data_3c)","0031520f":"# seaborn has an awesome tool (pairplot) to do this very easily:\ng = sns.pairplot(DF_data_3c, hue='class', height=4)\n# g.map_upper(sns.regplot) # some plot options: 'regplot', 'residplot', 'scatterplot'\n# g.map_lower(sns.kdeplot)\n#g.map_diag(plt.hist)","b89c6435":"# Create X (independant vars) and y (dependant var) \nX = DF_data_3c.copy().drop(['class'], axis=1)\ny = DF_data_3c[\"class\"].copy()\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1, test_size = 0.20)\n\nprint(train_X.shape)\nprint(val_X.shape)","e2dc20e2":"DTC_model = DecisionTreeClassifier()\nDTC_model.fit(train_X,train_y)\n\n# Make PredicitonsL:\nDTC_predictions = DTC_model.predict(val_X)\n\n#Print accuracy Results for DTR model\nDTC_accuracy =  DTC_model.score(val_X, val_y)\nprint(\"Accuracy score for Decision Tree Classifier Model : \" + str(DTC_accuracy))\n\nprint('\\nVariable Importance:')\nfor idx, var in enumerate(vars):\n    print(var, ':', str(DTC_model.feature_importances_[idx]))","b8f36fca":"RF_model = RandomForestClassifier(random_state=1)\nRF_model.fit(train_X, train_y)\n\n# make predictions\nRF_predictions = RF_model.predict(val_X)\n\n# Print Accuracy for initial RF model\nRF_accuracy = RF_model.score(val_X, val_y)\nprint(\"Accuracy score for Random Forest Model : \" + str(RF_accuracy))\n\nprint('\\nVariable Importance:')\nfor idx, var in enumerate(vars):\n    print(var, ':', str(RF_model.feature_importances_[idx]))","96ccc59f":"XGBC_model = XGBClassifier(random_state=1)\nXGBC_model.fit(train_X, train_y)\n\n# make predictions\nXGBC_predictions = XGBC_model.predict(val_X)\n\n# Print Accuracy for initial RF model\nXGBC_accuracy = accuracy_score(val_y, XGBC_predictions)\nprint(\"Accuracy score for XGBoost Classifier model : \" + str(XGBC_accuracy))\n\nprint('\\nVariable Importance:')\nfor idx, var in enumerate(vars):\n    print(var, ':', str(XGBC_model.feature_importances_[idx]))","12039f73":"%%time\n# Slightly Tuned XGB Model:\nXGBC_model = XGBClassifier(random_state=1, objective = 'multi:softprob', num_class=3) # \n\nparameters = {'learning_rate': [0.01, 0.015, 0.02, 0.025], # also called `eta` value\n              'max_depth': [2, 3, 4, 5],\n              'min_child_weight': [0.75, 1.0, 1.25, 2, 5],\n              'n_estimators': [100, 150, 200, 250, 300, 500]}\n\nXGBC_grid = GridSearchCV(XGBC_model,\n                        parameters,\n                        cv = 3,\n                        n_jobs = 5,\n                        verbose=True)\n\nXGBC_grid.fit(train_X, train_y)\n\n#print(XGBC_grid.best_score_)\nprint(XGBC_grid.best_params_)\n\n# make predictions\nXGBC_grid_predictions = XGBC_grid.predict(val_X)\n# Print MAE for initial XGB model\nXGBC_grid_accuracy = accuracy_score(XGBC_grid_predictions, val_y)\nprint(\"Accuracy Score for Tuned XGBoost Classifier Model : \" + str(XGBC_grid_accuracy))\n\nprint('\\nVariable Importance:')\nfor idx, var in enumerate(vars):\n    print(var, ':', str(XGBC_grid.best_estimator_.feature_importances_[idx]))","056acf8a":"Here we can see that these biomechanical variables can definitely differ by class. For instance, the Spondy. class has greater pelvic incidence, lumbar lordosis, sacral slope, and degree spondylolisthesis than the other gorups. \n\n**Next we can see how these variable relate to eachother, as well:**\n\n(notice how you can customize the upper\/lower\/diagonal plot by modifying the commented portions)","c7d3c751":"# Load Data:","338d5a54":"**XGBoost Model:**","f0b93ead":"From a very simple Random Forest model, we were able to predict the class ~ 80% of the time. Not bad, but not great... Next we will try a boosted tree classifier...****","7f714d43":"**Decision Tree Model:**","fd650623":"**Preview DataFrame:**","c54868df":"# First, We need to understand what we are classifying:\n\n**Heriated disk:**\n![](https:\/\/www.mayoclinic.org\/-\/media\/kcms\/gbs\/patient-consumer\/images\/2016\/11\/22\/17\/38\/mcdc7_herniated_disk-8col.jpg)\n\n**spondylolisthesis**:\n\n![](https:\/\/www.cartersvillechiro.com\/images\/New-art\/Sponylo-Grades01.jpg)","e2cf6dbd":"here we improved our classification accuracy to almost 84% with some minor XGBoost model tuning.","92f990e0":"**Random Forest Model:**","3bf9d110":"# Imports:","6a5c8027":"# Let's Examine the Data a Bit Deeper:\n\nHere we can see that there are more Spondylolidthesis than Normal than Hernia...","33492541":"# Let's start by examining the dataset w\/ 3 Categories:\nClassifying people into 3 categories should be moredifficult than 2, so let's start with that...","ab8c61a7":"Here we can see that, surprisingly, accuracy was not improved by using a XGBoost Classifier model. Luckily, these models are easy to tune. Let's Try that next...","bb982f0a":"# Predicting Back Dysfunction From Biomechanics\n![](https:\/\/media.giphy.com\/media\/l2JebyxjfgZuhPXl6\/giphy.gif)\n\nThis kernal will go through some basic EDA and data visualization using python tools like Pandas Dataframes and Seaborn.\n\nI will also develop some simple models to attempt to classify back dysfunction based on biomechanical variables.\n\n\n","f84ca964":"**Let's See how each variable varies by classification:**","f30a5425":"**Split data into Training and Test Data:**","9df85840":"**Tuned XGBoost Classifier Model:**","b442b812":"# Simple Machine Learning Models:"}}