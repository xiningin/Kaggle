{"cell_type":{"9719044a":"code","4a1c7bad":"code","e56056c0":"code","e3c18b54":"code","91e86e7c":"code","53e957e1":"code","9f66b7b6":"code","686004d6":"code","ed2c0633":"code","9368708a":"code","ea19d43e":"code","19d16327":"code","a2abf525":"code","76d1a9a3":"code","311ba55f":"code","c205dccc":"code","dba14749":"markdown","e788c405":"markdown","35a9b8ad":"markdown","1441a730":"markdown","c3f6b6c3":"markdown","8756a23e":"markdown","2872231e":"markdown","fbf7d309":"markdown"},"source":{"9719044a":"!git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n!pip install -qr yolov5\/requirements.txt  # install dependencies (ignore errors)\n%cd yolov5\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\nfrom utils.google_utils import gdrive_download  # to download models\/datasets\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","4a1c7bad":"# Download COCO val2017\ngdrive_download('1Y6Kou6kEB0ZEMCCpJSKStCor4KAReE43','coco2017val.zip')  # val2017 dataset\n!mv .\/coco ..\/  # move folder alongside \/yolov5","e56056c0":"# Run YOLOv5x on COCO val2017\n!python test.py --weights runs\/exp1\/weights\/best.pt --data kkctbn.yaml --img 416","e3c18b54":"!mkdir ..\/kkctbn\n!cp -r \/kaggle\/input\/kkctbn ..\/kkctbn","91e86e7c":"!mkdir ..\/kkctbn\/images\n!mkdir ..\/kkctbn\/labels\n!mv ..\/kkctbn\/dataset\/*.txt ..\/kkctbn\/labels\n!mv ..\/kkctbn\/dataset\/*.jpg ..\/kkctbn\/images","53e957e1":"!cp \/kaggle\/input\/kkctbn\/kkctbn.yaml .\/data\n!cp \/kaggle\/input\/kkctbn\/yolov5s.yaml .\/models\/yolov5s2.yml","9f66b7b6":"!ls .\/models","686004d6":"!ls data","ed2c0633":"# Start tensorboard (optional)\n%load_ext tensorboard\n%tensorboard --logdir runs","9368708a":"# Train YOLOv5s on coco128 for 3 epochs\n!python train.py --img 416 --batch 16 --epochs 50 --data kkctbn.yaml --cfg yolov5s2.yml --weights yolov5s.pt --nosave --cache","ea19d43e":"Image(filename='runs\/exp0\/train_batch1.jpg', width=900)  # view augmented training mosaics","19d16327":"Image(filename='runs\/exp0\/test_batch0_gt.jpg', width=900)  # view test image labels","a2abf525":"!ls runs\/exp1","76d1a9a3":"Image(filename='runs\/exp1\/results.png', width=900)","311ba55f":"Image(filename='runs\/exp1\/test_batch0_pred.jpg', width=900)  # view test image predictions","c205dccc":"from utils.utils import plot_results; plot_results()  # plot results.txt files as results.png","dba14749":"### 2.1 val2017\nDownload COCO val 2017 dataset, 1GB, 5000 images, and test model accuracy.","e788c405":"Training losses and performance metrics are saved to Tensorboard and also to a `runs\/exp0\/results.txt` logfile. `results.txt` is plotted as `results.png` after training completes. Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`. Here we show YOLOv5s trained on coco128 to 300 epochs, starting from scratch (blue), and from pretrained `yolov5s.pt` (orange).","35a9b8ad":"# Setup\n\nClone repo, install dependencies, `%cd` into `.\/yolov5` folder and check GPU.","1441a730":"View `test_batch0_pred.jpg` to see test batch 0 *predictions*.","c3f6b6c3":"View `test_batch0_gt.jpg` to see test batch 0 *ground truth* labels.","8756a23e":"# 2. Test\nTest a model on COCO val or test-dev dataset to determine trained accuracy. Models are auto-downloaded from [Google Drive](https:\/\/drive.google.com\/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be 1-2% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation.","2872231e":"# 4. Visualize\n\nView `runs\/exp0\/train*.jpg` images to see training images, labels and augmentation effects. A **Mosaic Dataloader** is used for training (shown below), a new concept developed by Ultralytics and first featured in [YOLOv4](https:\/\/arxiv.org\/abs\/2004.10934).","fbf7d309":"# 3. Train"}}