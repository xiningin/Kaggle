{"cell_type":{"9af230c2":"code","51984c9b":"code","85fb23f6":"code","ab22ef54":"code","c2611c1e":"code","26a50254":"code","86742508":"code","82dee9a4":"code","e23a4ad2":"code","ca2ce2ea":"code","e0ed46d0":"code","12e15948":"code","66efdafc":"code","ede8ca84":"code","a88f3421":"code","a1d0a94c":"code","3d2a6f61":"code","da525e08":"code","c707a435":"code","c06456a7":"code","366cf1c9":"code","9e6816ea":"code","b2b4463c":"code","d7f27a76":"code","0eda784d":"code","542ad12d":"code","2637c119":"code","a6f9a9ef":"code","eaa4815f":"code","ba8ae790":"code","079f60c3":"code","d01e342f":"code","b6cc4a5d":"code","70340c89":"code","4fd48819":"markdown","9c8f63b1":"markdown","60d399a8":"markdown","da6e79c0":"markdown","3794a210":"markdown","94171bf1":"markdown","b8535457":"markdown","661f736a":"markdown","4e0f8454":"markdown","dab3fc23":"markdown","3903b83b":"markdown","d4160a11":"markdown","6b79c5ac":"markdown","56f248df":"markdown","4b062c3b":"markdown","ae233f5b":"markdown","c4d043bc":"markdown"},"source":{"9af230c2":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQeyIuhXNV4WfW7V8AEQJEdI592V-PwaGQbR928Obn5z0AEVZPT&usqp=CAU',width=400,height=400)","51984c9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","85fb23f6":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('..\/input\/covid19-open-datasets-for-brazil\/Flu-Like Syndrome\/dados-nacional_01_06.csv', delimiter=';', encoding = \"ISO-8859-1\", nrows = nRowsRead)\ndf.dataframeName = 'dados-nacional_01_06.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","ab22ef54":"df.head()","c2611c1e":"df.isnull().sum()","26a50254":"na_percent = (df.isnull().sum()\/len(df))[(df.isnull().sum()\/len(df))>0].sort_values(ascending=False)\n\nmissing_data = pd.DataFrame({'Missing Percentage':na_percent*100})\nmissing_data","86742508":"na = (df.isnull().sum() \/ len(df)) * 100\nna = na.drop(na[na == 0].index).sort_values(ascending=False)\n\nf, ax = plt.subplots(figsize=(12,8))\nsns.barplot(x=na.index, y=na)\nplt.xticks(rotation='90')\nplt.xlabel('Features', fontsize=15)\nplt.title('Percentage Missing', fontsize=15)","82dee9a4":"for col in ('evolucaoCaso', 'dataEncerramento', 'cbo', 'dataNotificacao'):\n    df[col] = df[col].fillna('None')","e23a4ad2":"for col in ('condicoes', 'resultadoTeste', 'tipoTeste', 'classificacaoFinal', 'dataTeste', 'bairro', 'estadoTeste'):\n    df[col] = df[col].fillna(df[col].mode()[0])","ca2ce2ea":"categorical_cols = [cname for cname in df.columns if\n                    df[cname].nunique() < 10 and \n                    df[cname].dtype == \"object\"]\n\n\n# Select numerical columns\nnumerical_cols = [cname for cname in df.columns if \n                df[cname].dtype in ['int64', 'float64']]","e0ed46d0":"print(categorical_cols)","12e15948":"from sklearn.preprocessing import LabelEncoder\ncategorical_col = ('profissionalSaude', 'estadoTeste', 'tipoTeste', 'resultadoTeste', 'paisOrigem', 'sexo', 'estado', 'origem', 'estadoNotificacao', 'excluido', 'validado', 'evolucaoCaso', 'classificacaoFinal')\n        \n        \nfor col in categorical_col:\n    label = LabelEncoder() \n    label.fit(list(df[col].values)) \n    df[col] = label.transform(list(df[col].values))\n\nprint('Shape all_data: {}'.format(df.shape))","66efdafc":"from scipy.stats import norm, skew\nnum_features = df.dtypes[df.dtypes != 'object'].index\nskewed_features = df[num_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_features})\nskewness.head(15)","ede8ca84":"numerical_df = df.select_dtypes(exclude='object')\n\nfor i in range(len(numerical_df.columns)):\n    f, ax = plt.subplots(figsize=(7, 4))\n    fig = sns.distplot(numerical_df.iloc[:,i].dropna(), rug=True, hist=False, label='UW', kde_kws={'bw':0.1})\n    plt.xlabel(numerical_df.columns[i])","a88f3421":"from sklearn.model_selection import train_test_split\n# Hot-Encode Categorical features\ndf = pd.get_dummies(df) \n\n# Splitting dataset back into X and test data\nX = df[:len(df)]\ntest = df[len(df):]\n\nX.shape","a1d0a94c":"# Save target value for later\ny = df.resultadoTeste.values\n\n# In order to make imputing easier, we combine train and test data\ndf.drop(['resultadoTeste'], axis=1, inplace=True)\ndf = pd.concat((df, test)).reset_index(drop=True)","3d2a6f61":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=0)","da525e08":"from sklearn.model_selection import KFold\n# Indicate number of folds for cross validation\nkfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Parameters for models\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [0.00005, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]","c707a435":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LassoCV\n# Lasso Model\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas = alphas2, random_state = 42, cv=kfolds))\n\n# Printing Lasso Score with Cross-Validation\nlasso_score = cross_val_score(lasso, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlasso_rmse = np.sqrt(-lasso_score.mean())\nprint(\"LASSO RMSE: \", lasso_rmse)\nprint(\"LASSO STD: \", lasso_score.std())","c06456a7":"# Training Model for later\nlasso.fit(X_train, y_train)","366cf1c9":"from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas = alphas_alt, cv=kfolds))\nridge_score = cross_val_score(ridge, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nridge_rmse =  np.sqrt(-ridge_score.mean())\n# Printing out Ridge Score and STD\nprint(\"RIDGE RMSE: \", ridge_rmse)\nprint(\"RIDGE STD: \", ridge_score.std())","9e6816ea":"# Training Model for later\nridge.fit(X_train, y_train)","b2b4463c":"elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\nelastic_score = cross_val_score(elasticnet, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nelastic_rmse =  np.sqrt(-elastic_score.mean())\n\n# Printing out ElasticNet Score and STD\nprint(\"ELASTICNET RMSE: \", elastic_rmse)\nprint(\"ELASTICNET STD: \", elastic_score.std())","d7f27a76":"# Training Model for later\nelasticnet.fit(X_train, y_train)","0eda784d":"from lightgbm import LGBMRegressor\nlightgbm = make_pipeline(RobustScaler(),\n                        LGBMRegressor(objective='regression',num_leaves=5,\n                                      learning_rate=0.05, n_estimators=720,\n                                      max_bin = 55, bagging_fraction = 0.8,\n                                      bagging_freq = 5, feature_fraction = 0.2319,\n                                      feature_fraction_seed=9, bagging_seed=9,\n                                      min_data_in_leaf =6, \n                                      min_sum_hessian_in_leaf = 11))\n\n# Printing out LightGBM Score and STD\nlightgbm_score = cross_val_score(lightgbm, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlightgbm_rmse = np.sqrt(-lightgbm_score.mean())\nprint(\"LIGHTGBM RMSE: \", lightgbm_rmse)\nprint(\"LIGHTGBM STD: \", lightgbm_score.std())","542ad12d":"# Training Model for later\nlightgbm.fit(X_train, y_train)","2637c119":"from xgboost import XGBRegressor\nxgboost = make_pipeline(RobustScaler(),\n                        XGBRegressor(learning_rate =0.01, n_estimators=3460, \n                                     max_depth=3,min_child_weight=0 ,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,nthread=4,\n                                     scale_pos_weight=1,seed=27, \n                                     reg_alpha=0.00006))\n\n# Printing out XGBOOST Score and STD\nxgboost_score = cross_val_score(xgboost, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nxgboost_rmse = np.sqrt(-xgboost_score.mean())\nprint(\"XGBOOST RMSE: \", xgboost_rmse)\nprint(\"XGBOOST STD: \", xgboost_score.std())","a6f9a9ef":"# Training Model for later\nxgboost.fit(X_train, y_train)","eaa4815f":"results = pd.DataFrame({\n    'Model':['Lasso',\n            'Ridge',\n            'ElasticNet',\n            'LightGBM',\n            'XGBOOST',\n            ],\n    'Score':[lasso_rmse,\n             ridge_rmse,\n             elastic_rmse,\n             lightgbm_rmse,\n             xgboost_rmse,\n             \n            ]})\n\nsorted_result = results.sort_values(by='Score', ascending=True).reset_index(drop=True)\nsorted_result","ba8ae790":"f, ax = plt.subplots(figsize=(14,8))\nplt.xticks(rotation='90')\nsns.barplot(x=sorted_result['Model'], y=sorted_result['Score'])\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Performance', fontsize=15)\nplt.ylim(0.10, 0.12)\nplt.title('RMSE', fontsize=15)","079f60c3":"# Predict every model\nlasso_pred = lasso.predict(test)\nridge_pred = ridge.predict(test)\nelasticnet_pred = elasticnet.predict(test)\nlightgbm_pred = lightgbm.predict(test)\nxgboost_pred = xgboost.predict(test)","d01e342f":"elasticnet_pred = elasticnet.predict(test)\n# Combine predictions into final predictions\nfinal_predictions = np.expm1((0.3*elasticnet_pred) + (0.3*lasso_pred) + (0.2*ridge_pred) + \n               (0.1*xgboost_pred) + (0.1*lightgbm_pred))","b6cc4a5d":"#submission = pd.DataFrame()\n#submission['Id'] = test_Id\n#submission['resultadoTeste'] = final_predictions\n#submission.to_csv('house_pricing_submission.csv',index=False)","70340c89":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcR4VMlKNr5b886C0n7yTB-XHxufMF6P7jlpBgSiPhpIRYnHgEGZ&usqp=CAU',width=400,height=400)","4fd48819":"Thanks for the script Pratik Barua https:\/\/www.kaggle.com\/pratikbarua\/house-pricing-predictions","9c8f63b1":"I have no clue why there is no bar and how to fix it.","60d399a8":"flu-likesymptons.com","da6e79c0":"Stacking - Predict every model, then combine every prediction into a final predictions used for submission","3794a210":"Viewing Model Performance - View Model Performance through a DataFrame and a barplot","94171bf1":"Imputing some features with 'None'. Any of the below features with a missing value likely indicates that it doesn't exist (?)","b8535457":"#Creating a Visualization of every feature with missing values","661f736a":"Checking Skew - Create a new variable containing the dataset of only numerical features","4e0f8454":"Stacking: At this point we basically trained and predicted each model so we can combine its predictions into a 'final_predictions' variable for submission","dab3fc23":"#Label Encoding.\nOur dataset cannot run with categorical columns so we must Label Encode these columns in order to make them numerical","3903b83b":"pt-br.facebook.com","d4160a11":"Imputing some features with their mode\n\nThe reason we fill in these features with their mode (most common value), meaning that if these values are missing it has to be because of the data, not because of the fact they are missing the feature.","6b79c5ac":"#Codes from  Pratik Barua https:\/\/www.kaggle.com\/pratikbarua\/house-pricing-predictions","56f248df":"#My 1st Lasso","4b062c3b":"Influenza-like illness (ILI), also known as flu-like syndrome\/symptoms, is a medical diagnosis of possible influenza or other illness causing a set of common symptoms. \n\nSymptoms commonly include fever, shivering, chills, malaise, dry cough, loss of appetite, body aches, and nausea, typically in connection with a sudden onset of illness. In most cases, the symptoms are caused by cytokines released by immune system activation, and are thus relatively non-specific. \n\nCommon causes of ILI include the common cold and influenza, which tends to be less common but more severe than the common cold. Less-common causes include side effects of many drugs and manifestations of many other diseases https:\/\/en.wikipedia.org\/wiki\/Influenza-like_illness\n\nHowever don't think to treat Covid-19 as Flu. The best succeeded countries were those that treated the outbreak like Sars, the killer virus that hit Asia in 2003, and saved lives. By contrast, the ones which response to coronavirus was based on planning for a flu pandemic had higher rates.  ","ae233f5b":"Skew Visualization - Visualize each numerical feature with distplot","c4d043bc":"Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke"}}