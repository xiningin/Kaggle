{"cell_type":{"f4885c8e":"code","d95ea08b":"code","39d1bea8":"code","61c41682":"code","7a4f475c":"code","139091e6":"code","a2a2d189":"code","108199d9":"code","e51493d1":"code","7523e3de":"code","7af15500":"code","6efac7c9":"code","5e17caa9":"code","4ac3d566":"code","f92812ce":"markdown","963879e5":"markdown","2ce19834":"markdown","a08480e5":"markdown","9ce908b2":"markdown","96e56180":"markdown","582f4c5a":"markdown","e33cf732":"markdown","90a48dfe":"markdown","e2db41d9":"markdown","5627f359":"markdown","daad8789":"markdown","e45b3312":"markdown","8320efc2":"markdown","6278271c":"markdown","f8e2ef7b":"markdown","59aaf83b":"markdown","7638103b":"markdown","77e7ed89":"markdown","4ce60cdc":"markdown","19545888":"markdown"},"source":{"f4885c8e":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport pylab as pl\nimport numpy as np\nimport tensorflow.compat.v1 as tf\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\ntf.disable_v2_behavior()\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10, 6)","d95ea08b":"X = np.arange(0.0, 5.0, 0.1)\nX","39d1bea8":"##You can adjust the slope and intercept to verify the changes in the graph\na = 1\nb = 0\n\nY= a * X + b \n\nplt.plot(X, Y) \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","61c41682":"!wget -O FuelConsumption.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/FuelConsumptionCo2.csv","7a4f475c":"df = pd.read_csv(\"FuelConsumption.csv\")\n\n# take a look at the dataset\ndf.head()","139091e6":"train_x = np.asanyarray(df[['ENGINESIZE']])\ntrain_y = np.asanyarray(df[['CO2EMISSIONS']])","a2a2d189":"a = tf.Variable(20.0)\nb = tf.Variable(30.2)\ny = a * train_x + b","108199d9":"loss = tf.reduce_mean(tf.square(y - train_y))","e51493d1":"optimizer = tf.train.GradientDescentOptimizer(0.05)","7523e3de":"train = optimizer.minimize(loss)","7af15500":"init = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)","6efac7c9":"loss_values = []\ntrain_data = []\nfor step in range(100):\n    _, loss_val, a_val, b_val = sess.run([train, loss, a, b])\n    loss_values.append(loss_val)\n    if step % 5 == 0:\n        print(step, loss_val, a_val, b_val)\n        train_data.append([a_val, b_val])","5e17caa9":"plt.plot(loss_values, 'ro')","4ac3d566":"cr, cg, cb = (1.0, 1.0, 0.0)\nfor f in train_data:\n    cb += 1.0 \/ len(train_data)\n    cg -= 1.0 \/ len(train_data)\n    if cb > 1.0: cb = 1.0\n    if cg < 0.0: cg = 0.0\n    [a, b] = f\n    f_y = np.vectorize(lambda x: a*x + b)(train_x)\n    line = plt.plot(train_x, f_y)\n    plt.setp(line, color=(cr,cg,cb))\n\nplt.plot(train_x, train_y, 'ro')\n\n\ngreen_line = mpatches.Patch(color='red', label='Data Points')\n\nplt.legend(handles=[green_line])\n\nplt.show()","f92812ce":"<a id=\"ref2\"><\/a>\n<h1>Linear Regression with TensorFlow<\/h1>\nA simple example of a linear function can help us understand the basic mechanism behind TensorFlow.\n\nFor the first part we will use a sample dataset, and then we'll use TensorFlow to adjust and get the right parameters. We download a dataset that is related to fuel consumption and Carbon dioxide emission of cars. \n","963879e5":"Let's define the independent variable:","2ce19834":"They are also used to describe properties of different materials:","a08480e5":"<a id=\"ref1\"><\/a>\n<h1>Linear Regression<\/h1>\n\nDefining a linear regression in simple terms, is the approximation of a linear model used to describe the relationship between two or more variables. In a simple linear regression there are two variables, the dependent variable, which can be seen as the \"state\" or \"final goal\" that we study and try to predict, and the independent variables, also known as explanatory variables, which can be seen as the \"causes\" of the \"states\". \n\nWhen more than one independent variable is present the process is called multiple linear regression. <br>\nWhen multiple dependent variables are predicted the process is known as multivariate linear regression.\n\nThe equation of a simple linear model is\n\n$$Y = a X + b $$\n\nWhere Y is the dependent variable and X is the independent variable, and <b>a<\/b> and <b>b<\/b> being the parameters we adjust. <b>a<\/b> is known as \"slope\" or \"gradient\" and <b>b<\/b> is the \"intercept\". You can interpret this equation as Y being a function of X, or Y being dependent on X.\n\nIf you plot the model, you will see it is a line, and by adjusting the \"slope\" parameter you will change the angle between the line and the independent variable axis, and the \"intercept parameter\" will affect where it crosses the dependent variable's axis.\n\nLet's first import the required packages:","9ce908b2":"Now, we are going to define a loss function for our regression, so we can train our model to better fit our data. In a linear regression, we minimize the squared error of the difference between the predicted values(obtained from the equation) and the target values (the data that we have). In other words we want to minimize the square of the predicted values minus the target value. So we define the equation to be minimized as loss.\n\nTo find value of our loss, we use <b>tf.reduce_mean()<\/b>. This function finds the mean of a multidimensional tensor, and the result can have a different dimension.","96e56180":"Then, we define the optimizer method. The gradient Descent optimizer takes in parameter: learning rate, which corresponds to the speed with which the optimizer should learn; there are pros and cons for increasing the learning-rate parameter, with a high learning rate the training model converges quickly, but there is a risk that a high learning rate causes instability and the model will not converge. <b>Please feel free to make changes to learning parameter and check its effect<\/b>. On the other hand decreasing the learning rate might reduce the convergence speed, but it would increase the chance of converging to a solution. You should note that the solution might not be a global optimal solution as there is a chance that the optimizer will get stuck in a local optimal solution. Please review other material for further information on the optimization. Here we will use a simple gradient descent with a learning rate of 0.05: <br>  ","582f4c5a":"<h2>Understanding the Data<\/h2>\n\n<h3><code>FuelConsumption.csv<\/code>:<\/h3>\nWe have downloaded a fuel consumption dataset, <b><code>FuelConsumption.csv<\/code><\/b>, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada. <a href=\"http:\/\/open.canada.ca\/data\/en\/dataset\/98f1a129-f628-4ce4-b24d-6f16bf24dd64\">Dataset source<\/a>\n\n- **MODELYEAR** e.g. 2014\n- **MAKE** e.g. Acura\n- **MODEL** e.g. ILX\n- **VEHICLE CLASS** e.g. SUV\n- **ENGINE SIZE** e.g. 4.7\n- **CYLINDERS** e.g 6\n- **TRANSMISSION** e.g. A6\n- **FUEL CONSUMPTION in CITY(L\/100 km)** e.g. 9.9\n- **FUEL CONSUMPTION in HWY (L\/100 km)** e.g. 8.9\n- **FUEL CONSUMPTION COMB (L\/100 km)** e.g. 9.2\n- **CO2 EMISSIONS (g\/km)** e.g. 182   --> low --> 0","e33cf732":"Don't forget to initialize the variables before executing a graph:","90a48dfe":"Lets visualize how the coefficient and intercept of line has changed to fit the data:","e2db41d9":"Lets say we want to use linear regression to predict Co2Emission of cars based on their engine size. So, lets define X and Y value for the linear regression, that is, train_x and train_y:","5627f359":"<hr>","daad8789":"OK... but how can we see this concept of linear relations with a more meaningful point of view?\n\nSimple linear relations were used to try to describe and quantify many observable physical phenomena, the easiest to understand are speed and distance traveled:","e45b3312":"<b><pre>\n\n$$Distance Traveled = Speed \\times Time + Initial Distance$$\n\n$$Speed = Acceleration \\times Time + Initial Speed$$\n<\/pre><\/b>","8320efc2":"First, we initialize the variables <b>a<\/b> and <b>b<\/b>, with any random guess, and then we define the linear function:","6278271c":"Lets plot the loss values to see how it has changed during the training:","f8e2ef7b":"<b><pre>\n\n$$Force = Deformation \\times Stiffness$$\n\n$$Heat Transfered = Temperature Difference \\times Thermal Conductivity$$\n\n$$Electrical Tension (Voltage) = Electrical Current \\times Resistance$$\n\n$$Mass =  Volume \\times Density$$\n<\/pre><\/b>","59aaf83b":"<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<font size=\"3\"><strong>In this notebook we will overview the implementation of Linear Regression with TensorFlow<\/strong><\/font>\n<br>\n<br>\n<h2>Table of Contents<\/h2>\n<ol>\n <li><a href=\"#ref1\">Linear Regression<\/a><\/li>\n <li><a href=\"#ref2\">Linear Regression with TensorFlow<\/a><\/li>\n<\/ol>\n<\/div>\n<br>\n<br>\n<p><\/p>\n<hr>","7638103b":"---------------","77e7ed89":"When we perform an experiment and gather the data, or if we already have a dataset and we want to perform a linear regression, what we will do is adjust a simple linear model to the dataset, we adjust the \"slope\" and \"intercept\" parameters to the data the best way possible, because the closer the model comes to describing each ocurrence, the better it will be at representing them.\n\nSo how is this \"regression\" performed?","4ce60cdc":"Now we will define the training method of our graph, what method we will use for minimize the loss? We will use the <b>.minimize()<\/b> which will minimize the error function of our optimizer, resulting in a better model.","19545888":"Now we are ready to start the optimization and run the graph:"}}