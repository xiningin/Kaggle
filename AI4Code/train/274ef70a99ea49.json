{"cell_type":{"f99e9b55":"code","844e2dcb":"code","4e93f2fc":"code","c388c4d8":"code","1fd91578":"code","0ab6e1ba":"code","a302fd19":"code","c3723a48":"code","f17d321a":"code","ebc4fcff":"code","00709164":"code","9d71578e":"code","d38b17e1":"code","d23d53fe":"code","d2c2fb07":"code","81789b6b":"code","a715126f":"code","7cc96e0a":"code","021e2386":"code","6b313a17":"code","c90483d4":"code","d6054b04":"code","be1c0f1a":"code","1e0de8c9":"code","61aaeb44":"code","e44375a1":"code","dcd18ccf":"markdown","31bed63c":"markdown","56356287":"markdown","79307ef1":"markdown","1b3acbd9":"markdown"},"source":{"f99e9b55":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","844e2dcb":"gender = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","4e93f2fc":"train.head()","c388c4d8":"def CLEAN(train):\n    print(train.groupby(train['Age'].isnull()).median())\n\n    print(train.groupby('Pclass')['Age'].describe())\n\n    for i,j in enumerate(train['Age'].isnull()):\n        if train.loc[i,['Pclass']].values ==1:\n            train.loc[i,['Age']] =train.loc[i,['Age']].fillna(38.233441)\n        elif train.loc[i,['Pclass']].values ==2:\n            train.loc[i,['Age']] =train.loc[i,['Age']].fillna(29.877630)\n        else:\n            train.loc[i,['Age']] =train.loc[i,['Age']].fillna(25.140620)\n\n\n    train.groupby(train['Cabin'].isnull()).mean()\n    train['Cabin'] = np.where(train['Cabin'].isnull(),0,1)\n\n    train['title']= train['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip() )\n    li = ['Dr','Master','Miss','Mr','Mrs']\n\n    train['title'] = train['title'].apply(lambda x : x if x in li else 'Other')\n\n    train = train.drop(['Name','Ticket','PassengerId'],axis=1)\n\n    print(train.head())\n\n    from sklearn.preprocessing import LabelEncoder\n    li = ['Sex','Embarked','title']\n\n    train = train.dropna()\n\n    for i in li:\n      train[i] = LabelEncoder().fit_transform(train[i])\n\n    train['family'] = train['SibSp']+train['Parch']\n    train = train.drop(['SibSp','Parch'],axis=1)\n    \n    return train\n\n","1fd91578":"train = CLEAN(train)","0ab6e1ba":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","a302fd19":"support = SVC(kernel='linear',random_state= 42)\nrandom = RandomForestClassifier(random_state=42)","c3723a48":"model = [support,random]","f17d321a":"test = pd.merge(test,gender,on='PassengerId')","ebc4fcff":"feature = train.drop('Survived',axis=1)\nlabel = train['Survived']\n\n\n","00709164":"test = CLEAN(test)","9d71578e":"testf = test.drop('Survived',axis=1)\ntestl = test['Survived']\n\n\n","d38b17e1":"def fitAndScore(feature,label,testf,testl):\n    for i in model:\n        i.fit(feature,label)\n\n    acc = []\n    for i in model:\n        acc.append(i.score(testf,testl))\n    print(acc)","d23d53fe":"from imblearn.combine import SMOTEENN\nos = SMOTEENN(random_state=42)\nfeature,label = os.fit_resample(feature,label)","d2c2fb07":"fitAndScore(feature,label,testf,testl)","81789b6b":"def remove(data):\n  Q1 = np.percentile(data, 25, interpolation = 'midpoint')\n  \n# Third quartile (Q3)\n  Q3 = np.percentile(data, 75, interpolation = 'midpoint')\n  iqr = Q3 - Q1\n  percentile25 = data.quantile(0.25)\n  percentile75 = data.quantile(0.75)\n\n  upper_limit = percentile75 + 1.5 * iqr\n  lower_limit = percentile25 - 1.5 * iqr\n  data = np.where(\n    data > upper_limit,upper_limit,\n    np.where(\n        data < lower_limit,\n        lower_limit,\n        data\n    )\n  )\n  return data\n\n#train[train['discount_percent'] > upper_limit]\n#train[train['discount_percent'] < lower_limit]\n\n","a715126f":"plt.figure(figsize=(15,10))\nfor i in enumerate(train.columns):\n  plt.subplot(3,5,i[0]+1)\n  sns.boxplot(train[i[1]])\n","7cc96e0a":"for i in ['Age','Fare']:\n    train[i] = remove(train[i])\n    test[i] = remove(test[i])","021e2386":"feature = train.drop('Survived',axis=1)\nlabel = train['Survived']\n\ntestf = test.drop('Survived',axis=1)\ntestl = test['Survived']\n\nfrom imblearn.combine import SMOTEENN\nos = SMOTEENN(random_state=42)\nfeature,label = os.fit_resample(feature,label)","6b313a17":"fitAndScore(feature,label,testf,testl)","c90483d4":"plt.figure(figsize=(15,10))\nfor i in enumerate(train.columns):\n  plt.subplot(3,4,i[0]+1)\n  sns.distplot(train[i[1]])","d6054b04":"plt.figure(figsize=(15,10))\nfor i in enumerate(test.columns):\n  plt.subplot(3,4,i[0]+1)\n  sns.distplot(test[i[1]])","be1c0f1a":"li = ['Age','Fare','family']\nfrom sklearn.preprocessing import  StandardScaler\n\nfor i in li:\n  train[i] = StandardScaler().fit_transform(train[[i]])\n  testf[i] = StandardScaler().fit_transform(testf[[i]])","1e0de8c9":"feature = train.drop('Survived',axis=1)\nlabel = train['Survived']\n\nfrom imblearn.combine import SMOTEENN\nos = SMOTEENN(random_state=42)\nfeature,label = os.fit_resample(feature,label)","61aaeb44":"fitAndScore(feature,label,testf,testl)","e44375a1":"from sklearn.model_selection import GridSearchCV\n\nparams = {\n    'criterion':['gini','entropy'],\n    'n_estimators':[x**2 for x in range(3,10)],\n    'n_jobs':[-1,None],\n    'random_state':[1,42,None],\n    'max_depth': [3,5,None]\n}\n\ncv = GridSearchCV(random,params,cv=5)\ncv.fit(feature,label)\n#print(cv._best_params,cv._best_result)\n\nprint(cv.best_params_,cv.best_score_)\n\nbestmodel = cv.best_estimator_\nbestmodel.score(testf,testl)","dcd18ccf":"# Load dataset","31bed63c":"# GridSearchCV","56356287":"# Transform","79307ef1":"# Delete outliers","1b3acbd9":"# Cleaning data"}}