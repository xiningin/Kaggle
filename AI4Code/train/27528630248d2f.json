{"cell_type":{"bd4069d1":"code","7123c0ae":"code","bcf6cf23":"code","ab29417d":"code","468adf24":"code","a59f1ce6":"code","bb601956":"code","f0efe84e":"code","1c7a2667":"code","cd39848c":"code","1fff3bd7":"code","d8679856":"code","20026455":"code","e7fac5c2":"code","073a94a0":"code","74c4af7d":"code","dd7d3671":"code","be864dcd":"code","1d736432":"code","f7d88f7c":"code","b09744ff":"code","bd030b8c":"code","4489c18d":"code","e3d68cd4":"code","4faad1c1":"code","c42c635f":"code","8718c99a":"code","fba4f0e3":"code","88d0ebf0":"code","33a40453":"code","fb45da92":"code","333a37e9":"code","11101b0e":"code","a26d9616":"code","faf17f55":"code","aa57b765":"code","8ac3f127":"code","0128a067":"code","35093b82":"code","4d224821":"code","02fe1625":"code","cab4fc05":"code","f912eeb0":"code","e048a3e3":"code","3cfac66e":"code","67fb09fa":"code","cfc915eb":"code","31cf8774":"code","1df14c04":"code","445a33f2":"code","49e26ffe":"code","d86e41c7":"code","e834b386":"code","a9b8946e":"code","aa59fe0e":"code","8eb0442b":"code","b04727e1":"code","f5703541":"code","7a8429c6":"code","c1a6ef1c":"code","a213ea9b":"code","cff8b4e2":"code","a353f06c":"code","3e34a08f":"code","d71428ad":"code","71537787":"code","89b00a56":"code","f14796de":"code","5fe6d33c":"code","b980cb78":"code","afc1a47d":"markdown","0ad8ccc8":"markdown","eb029620":"markdown","bf36b806":"markdown","dc2120c8":"markdown","fdb0c0b8":"markdown","4b11dd41":"markdown","1b25aae3":"markdown"},"source":{"bd4069d1":"import numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\nfrom statsmodels.tsa.arima_model import ARIMA, ARMAResults \n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline","7123c0ae":"datapath   = '..\/input\/covid19-global-forecasting-week-1\/'\ntrain      = pd.read_csv(datapath+'train.csv')\ntest       = pd.read_csv(datapath+'test.csv')","bcf6cf23":"print(\"Train dataset: \", train.head())\nprint(\"Train period: \", train.Date.min(), train.Date.max())\nprint(\"Test dataset: \", test.head())\nprint(\"Test period: \", test.Date.min(), test.Date.max())","ab29417d":"# check metadata of train\ntrain.info()","468adf24":"# check metadata of test\ntest.info()","a59f1ce6":"train['Date'] = train['Date'].astype('datetime64[ns]')\ntest['Date'] = test['Date'].astype('datetime64[ns]')\n\nprint(\"Train Date type: \", train['Date'].dtype)\nprint(\"Test Date type: \",test['Date'].dtype)","bb601956":"train.columns = ['id','state','country','lat','lon','date','ConfirmedCases','Fatalities']\ntest.columns  = ['ForecastId', 'state','country','lat','lon','date']","f0efe84e":"train['place'] = train['state'].fillna('') + '_' + train['country']\ntest['place'] = test['state'].fillna('') + '_' + test['country']","1c7a2667":"print('How many places?: ', 'Train: ', len(train['place'].unique()), \n      'Test: ', len(test['place'].unique()))\nprint('Unique place similar as test?: ',(train['place'].unique() == test['place'].unique()).sum())","cd39848c":"fig,ax = plt.subplots(2,1, sharex=True)\nax[0].plot(train.groupby('date')['ConfirmedCases'].sum(),color='blue')\nax[1].plot(train.groupby('date')['Fatalities'].agg(sum),color='red')\n\nax[0].set_ylabel('Frequency of cases')\nax[1].set_ylabel('Death count')\nax[1].set_xlabel('Date')\nplt.xticks(rotation=45)\n\nax[0].set_title('Total confirmed cases and fatalities (Jan 22-Mar 22, 2020)')\nplt.show()","1fff3bd7":"china_cases     = train[train['place'].str.contains('China')][['date',\n                                                               'ConfirmedCases',\n                                                               'Fatalities']].reset_index(drop=True)\nrestworld_cases = train[-train['place'].str.contains('China')][['date',\n                                                                'ConfirmedCases',\n                                                                'Fatalities']].reset_index(drop=True)","d8679856":"#plot total confirmed cases and fatalities in China (Jan 22-Mar 22, 2020)\n\nfig,ax = plt.subplots(2,1, sharex=True)\nax[0].plot(china_cases.groupby('date')['ConfirmedCases'].sum(), marker='o',color='b', \n            linestyle='--')\nax[1].plot(china_cases.groupby('date')['Fatalities'].sum(), marker='v',color='r',\n            linestyle='--')\nax[0].set_ylabel('Frequency of cases')\nax[1].set_ylabel('Death count')\nax[1].set_xlabel('Date')\nplt.xticks(rotation=45)\n\nax[0].set_title('Total confirmed cases and fatalities in China (Jan 22-Mar 22, 2020)')\nplt.show()","20026455":"# plot total confirmed cases and fatalities outside of China (Jan 22-Mar 22, 2020)\n\nfig,ax = plt.subplots(2,1, sharex=True)\nax[0].plot(restworld_cases.groupby('date')['ConfirmedCases'].sum(), marker='o',color='b', \n            linestyle='--')\nax[1].plot(restworld_cases.groupby('date')['Fatalities'].sum(), marker='v',color='r',\n            linestyle='--')\nax[0].set_ylabel('Frequency of cases')\nax[1].set_ylabel('Death count')\nax[1].set_xlabel('Date')\nplt.xticks(rotation=45)\n\nax[0].set_title('Total confirmed cases and fatalities in China (Jan 22-Mar 22, 2020)')\nplt.show()","e7fac5c2":"top10cases = train.groupby('place')['ConfirmedCases'].sum().sort_values(ascending=False).head(10)\n\nplt.barh(top10cases.index, top10cases)\nplt.ylabel('Places')\nplt.xlabel('Total confirmed cases')\nplt.title('Top 10 places with highest confirmed cases')\nplt.show()","073a94a0":"# let's look at US states\n\nus_cases     = train[train['place'].str.contains('US')][['date','place',\n                                                         'ConfirmedCases',\n                                                               'Fatalities']].reset_index(drop=True)","74c4af7d":"top10uscases = us_cases.groupby('place')['ConfirmedCases'].sum().sort_values(ascending=False).head(10)\n\nplt.barh(top10uscases.index, top10cases)\nplt.ylabel('Places')\nplt.xlabel('Total confirmed cases')\nplt.title('Top 10 US States with highest confirmed cases')\nplt.show()","dd7d3671":"def RMSLE(predicted, actual):\n    return np.sqrt(np.mean(np.power((np.log(predicted+1)-np.log(actual+1)),2)))","be864dcd":"train_sub = train[['id','place','date','ConfirmedCases','Fatalities']] \ntrain_sub['logConfirmedCases'] = np.log(train_sub['ConfirmedCases'])\ntrain_sub = train_sub.set_index('date')","1d736432":"list= []\n# using rolling window = 3 days\n\nfor place in train_sub.place.unique():    \n    a = train_sub[train_sub['place']==place]\n    a['z_cases'] = (a['logConfirmedCases']- a['logConfirmedCases'].rolling(window=3).mean())\/a['logConfirmedCases'].rolling(window=3).std()\n    a['zp_cases']= a['z_cases']- a['z_cases'].shift(3)\n    a['z_death'] =(a['Fatalities']-a['Fatalities'].rolling(window=3).mean())\/a['Fatalities'].rolling(window=3).std()\n    a['zp_death']= a['z_death']- a['z_death'].shift(3)\n    list.append(a)\n    \nrolling_df = pd.concat(list)","f7d88f7c":"def plot_rolling(df, variable, z, zp):\n    fit, ax= plt.subplots(2, figsize=(10,9), sharex=True)\n    ax[0].plot(df.index, df[variable], label='raw data')\n    ax[0].plot(df[variable].rolling(window=3).mean(), label=\"rolling mean\");\n    ax[0].plot(df[variable].rolling(window=3).std(), label=\"rolling std (x10)\");\n    ax[0].legend()\n    \n    ax[1].plot(df.index, df[z], label=\"de-trended data\")\n    ax[1].plot(df[z].rolling(window=3).mean(), label=\"rolling mean\");\n    ax[1].plot(df[z].rolling(window=3).std(), label=\"rolling std (x10)\");\n    ax[1].legend()\n    \n    ax[1].set_xlabel('Date')\n    plt.xticks(rotation=45)\n    ax[0].set_title('{}'.format(place))\n    \n    plt.show()\n    plt.close()","b09744ff":"# rolling plots for Confirmed Cases\n\nfor place in rolling_df.place.unique()[:5]:\n    plot_rolling(df= rolling_df[rolling_df['place']==place], \n                 variable='logConfirmedCases', z= 'z_cases', \n                                 zp= 'zp_cases')","bd030b8c":"# rolling plots for Fatalities\n\nfor place in rolling_df.place.unique()[:5]:\n    plot_rolling(df= rolling_df[rolling_df['place']==place], \n                 variable='Fatalities', z= 'z_death', \n                                 zp= 'zp_death')","4489c18d":"stationary_data =[]\nfor place in train_sub.place.unique():\n    a= rolling_df[(rolling_df['place']==place) & (rolling_df['logConfirmedCases'] > 0)]['logConfirmedCases'].dropna()\n    try:   \n        dftest = adfuller(a, autolag='AIC')\n        if (dftest[1] < 0.001):\n            stationary_data.append(place)\n        else: \n            pass\n    except:\n        pass\n    \nprint(len(stationary_data))","e3d68cd4":"station_death_data =[]\nfor place in train_sub.place.unique():\n    dftest = adfuller(rolling_df[rolling_df['place']==place]['Fatalities'], autolag='AIC')\n    if (dftest[1] < 0.001):\n        station_death_data.append(place)\n    else: \n        pass\n    \nprint(len(station_death_data))","4faad1c1":"# ACF and PACF plots for Confirmed Cases\nfor place in stationary_data:\n    fig,ax = plt.subplots(2,figsize=(12,6))\n    ax[0] = plot_acf(rolling_df[rolling_df['place']==place]['logConfirmedCases'].dropna(), ax=ax[0], lags=2)\n    ax[1] = plot_pacf(rolling_df[rolling_df['place']==place]['logConfirmedCases'].dropna(), ax=ax[1], lags=2)\n    plt.title('{}'.format(place))","c42c635f":"# ACF and PACF plots for Fatalities\nfor place in stationary_data:\n    fig,ax = plt.subplots(2,figsize=(12,6))\n    ax[0] = plot_acf(np.log(rolling_df[rolling_df['place']==place]['Fatalities']).dropna(), ax=ax[0], lags=2)\n    ax[1] = plot_pacf(np.log(rolling_df[rolling_df['place']==place]['Fatalities']).dropna(), ax=ax[1], lags=2)\n    plt.title('{}'.format(place))","8718c99a":"# list of places with lags for Confirmed Cases\nconfirmedc_lag = ['Anhui_China', 'Chongqing_China','Guangdong_China',\n                  'Guizhou_China', 'Hainan_China', 'Hebei_China','Hubei_China',\n                 'Ningxia_China','Shandong_China','Shanxi_China', 'Sichuan_China']","fba4f0e3":"# list of places with non-stationary confirmed cases data\nallplaces = train_sub.place.unique().tolist()\nnon_stationary_data = [ele for ele in allplaces]\n\nfor place in confirmedc_lag:\n    if place in allplaces:\n        non_stationary_data.remove(place)\n\nprint(len(non_stationary_data))","88d0ebf0":"# list of places with lags for Fatality\nfatalities_lag = ['Hubei_China']","33a40453":"# list of places with non-stationary fatalities data\nnon_stationary_death_data = [ele for ele in allplaces]\n\nfor place in fatalities_lag:\n    if place in allplaces:\n        non_stationary_death_data.remove(place)\n\nprint(len(non_stationary_death_data))","fb45da92":"from numpy import inf\ntrain_sub['logConfirmedCases']= train_sub['logConfirmedCases'].replace(to_replace=-inf,\n                                                                      value=0)","333a37e9":"poly_data = train[['date','place',\n                  'ConfirmedCases','Fatalities']].merge(test[['date','place']], \n                                                      how='outer', \n                                                        on=['date','place']).sort_values(['place',\n                                                                                          'date'])\n\nprint(poly_data.date.min(), test.date.min(), train.date.max(), poly_data.date.max())","11101b0e":"# create label for each date by each place\nlabel = []\nfor place in poly_data.place.unique():\n    labelrange = range(1,len(poly_data[poly_data['place']==place])+1)\n    label.append([i for i in labelrange])\nlab = [item for lab in label for item in lab]\npoly_data['label'] = lab\npoly_data.head()","a26d9616":"XYtrain = poly_data[(poly_data['date']>'2020-01-21')&((poly_data['date']<'2020-03-25'))]\nprint(XYtrain.date.min(), XYtrain.date.max(), XYtrain.isna().sum())","faf17f55":"XYtest = poly_data[(poly_data['date']>'2020-03-11')&(poly_data['date']<'2020-04-24')]\nprint(XYtest.date.min(), XYtest.date.max(), XYtest.isna().sum())","aa57b765":"XYtrain['intercept']= -1\n\nresult=pd.DataFrame()\nfor place in poly_data.place.unique():\n    for degree in [2,3,4,5]:\n        features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n        target    = XYtrain[XYtrain['place']==place]['ConfirmedCases']\n        model  = make_pipeline(PolynomialFeatures(degree), Ridge())\n        model.fit(np.array(features), target)\n        y_pred = model.predict(np.array(features))\n        rmsle  = RMSLE(y_pred, target)\n        result = result.append(pd.DataFrame({'place':[place],\n                                             'degree':[degree],'RMSLE': [rmsle]}))\n    \n# if you want to look at the plot\n        #plt.plot(features, y_pred, \n        #         label= \"degree %d\" % degree\n        #         +';$RMSLE: %.2f' % RMSLE(y_pred, target))\n    #plt.legend(loc='upper left')\n    #plt.xlabel('date')\n    #plt.ylabel('predictedcase')\n    #plt.title(\"Polynomial model for confirmed cases in {}\".format(place) )\n    #plt.show()","8ac3f127":"best_degree = pd.DataFrame()\nfor place in result.place.unique():\n    a = result[result['place']==place]\n    best_degree = best_degree.append(a[a['RMSLE'] == a['RMSLE'].min()])\nprint(best_degree.groupby('degree')['place'].nunique())\nprint('Zero polynomial (no fit): ',best_degree[best_degree['RMSLE']<0.00001]['place'].unique())","0128a067":"fit_best_degree = best_degree[best_degree['RMSLE']>0.00001]\ntwodeg_places   = fit_best_degree[fit_best_degree['degree']==2]['place'].unique()\nthreedeg_places = fit_best_degree[fit_best_degree['degree']==3]['place'].unique()\nfourdeg_places  = fit_best_degree[fit_best_degree['degree']==4]['place'].unique()\nfivedeg_places  = fit_best_degree[fit_best_degree['degree']==5]['place'].unique()\nnofit_places1    = best_degree[best_degree['RMSLE']<0.00001]['place'].unique()\nprint(fit_best_degree.nunique())\nprint(len(twodeg_places), len(threedeg_places), \n      len(fourdeg_places), len(fivedeg_places), len(nofit_places1))","35093b82":"XYtest = XYtest.reset_index(drop=True)\nXYtest['intercept'] = -1","4d224821":"poly_predicted_confirmedcases = pd.DataFrame() \nfor place in twodeg_places:\n    features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n    target    = XYtrain[XYtrain['place']==place]['ConfirmedCases']\n    Xtest     = XYtest[XYtest['place']==place][['label','intercept']]\n    model  = make_pipeline(PolynomialFeatures(2), Ridge())\n    model.fit(np.array(features), target)\n    y_pred = model.predict(np.array(Xtest))\n    a = pd.DataFrame(zip(XYtrain[XYtrain['place']==place]['place'], \n                              y_pred),columns=['place','ConfirmedCases'])\n    poly_predicted_confirmedcases = poly_predicted_confirmedcases.append(a)\n    \nfor place in threedeg_places:\n    features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n    target    = XYtrain[XYtrain['place']==place]['ConfirmedCases']\n    Xtest     = XYtest[XYtest['place']==place][['label','intercept']]\n    model  = make_pipeline(PolynomialFeatures(3), Ridge())\n    model.fit(np.array(features), target)\n    y_pred = model.predict(np.array(Xtest))\n    b = pd.DataFrame(zip(XYtrain[XYtrain['place']==place]['place'], \n                              y_pred.tolist()),columns=['place','ConfirmedCases'])\n    poly_predicted_confirmedcases = poly_predicted_confirmedcases.append(b)\n    \n    \nfor place in fourdeg_places:\n    features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n    target    = XYtrain[XYtrain['place']==place]['ConfirmedCases']\n    Xtest     = XYtest[XYtest['place']==place][['label','intercept']]\n    model  = make_pipeline(PolynomialFeatures(4), Ridge())\n    model.fit(np.array(features), target)\n    y_pred = model.predict(np.array(Xtest))\n    c = pd.DataFrame(zip(XYtrain[XYtrain['place']==place]['place'], \n                              y_pred.tolist()),columns=['place','ConfirmedCases'])\n    poly_predicted_confirmedcases = poly_predicted_confirmedcases.append(c)\n    \n    \nfor place in fivedeg_places:\n    features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n    target    = XYtrain[XYtrain['place']==place]['ConfirmedCases']\n    Xtest     = XYtest[XYtest['place']==place][['label','intercept']]\n    model  = make_pipeline(PolynomialFeatures(5), Ridge())\n    model.fit(np.array(features), target)\n    y_pred = model.predict(np.array(Xtest))\n    d = pd.DataFrame(zip(XYtrain[XYtrain['place']==place]['place'], \n                              y_pred.tolist()),columns=['place','ConfirmedCases'])\n    poly_predicted_confirmedcases = poly_predicted_confirmedcases.append(d)\n","02fe1625":"fatalities_result=pd.DataFrame()\nfor place in poly_data.place.unique():\n    for degree in [2,3,4,5]:\n        features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n        target    = XYtrain[XYtrain['place']==place]['Fatalities']\n        model  = make_pipeline(PolynomialFeatures(degree), Ridge())\n        model.fit(np.array(features), target)\n        y_pred = model.predict(np.array(features))\n        rmsle  = RMSLE(y_pred, target)\n        fatalities_result = fatalities_result.append(pd.DataFrame({'place':[place],\n                                             'degree':[degree],'RMSLE': [rmsle]}))","cab4fc05":"fat_best_degree = pd.DataFrame()\nfor place in fatalities_result.place.unique():\n    a = fatalities_result[fatalities_result['place']==place]\n    fat_best_degree = fat_best_degree.append(a[a['RMSLE'] == a['RMSLE'].min()])\nprint(fat_best_degree.groupby('degree')['place'].nunique())\nprint('Zero polynomial (no fit): ',\n      fat_best_degree[fat_best_degree['RMSLE']<0.000001]['place'].unique())","f912eeb0":"fit_best_degree = fat_best_degree[fat_best_degree['RMSLE']>0.000001]\ntwodeg_places   = fit_best_degree[fit_best_degree['degree']==2]['place'].unique()\nthreedeg_places = fit_best_degree[fit_best_degree['degree']==3]['place'].unique()\nfourdeg_places  = fit_best_degree[fit_best_degree['degree']==4]['place'].unique()\nfivedeg_places  = fit_best_degree[fit_best_degree['degree']==5]['place'].unique()\nnofit_places2    = fat_best_degree[fat_best_degree['RMSLE']<0.000001]['place'].unique()\nprint(fit_best_degree.nunique())\nprint(len(twodeg_places), len(threedeg_places), \n      len(fourdeg_places), len(fivedeg_places), len(nofit_places2))","e048a3e3":"poly_predicted_fatalities = pd.DataFrame() \nfor place in twodeg_places:\n    features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n    target    = XYtrain[XYtrain['place']==place]['Fatalities']\n    Xtest     = XYtest[XYtest['place']==place][['label','intercept']]\n    model  = make_pipeline(PolynomialFeatures(2), Ridge())\n    model.fit(np.array(features), target)\n    y_pred = model.predict(np.array(Xtest))\n    a = pd.DataFrame(zip(XYtrain[XYtrain['place']==place]['place'], \n                              y_pred.tolist()),columns=['place','Fatalities'])\n    poly_predicted_fatalities = poly_predicted_fatalities.append(a)\n    \nfor place in threedeg_places:\n    features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n    target    = XYtrain[XYtrain['place']==place]['Fatalities']\n    Xtest     = XYtest[XYtest['place']==place][['label','intercept']]\n    model  = make_pipeline(PolynomialFeatures(3), Ridge())\n    model.fit(np.array(features), target)\n    y_pred = model.predict(np.array(Xtest))\n    b = pd.DataFrame(zip(XYtrain[XYtrain['place']==place]['place'], \n                              y_pred.tolist()),columns=['place','Fatalities'])\n    poly_predicted_fatalities = poly_predicted_fatalities.append(b)\n    \n    \nfor place in fourdeg_places:\n    features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n    target    = XYtrain[XYtrain['place']==place]['Fatalities']\n    Xtest     = XYtest[XYtest['place']==place][['label','intercept']]\n    model  = make_pipeline(PolynomialFeatures(4), Ridge())\n    model.fit(np.array(features), target)\n    y_pred = model.predict(np.array(Xtest))\n    c = pd.DataFrame(zip(XYtrain[XYtrain['place']==place]['place'], \n                              y_pred.tolist()),columns=['place','Fatalities'])\n    poly_predicted_fatalities = poly_predicted_fatalities.append(c)\n    \n    \nfor place in fivedeg_places:\n    features  = XYtrain[XYtrain['place']==place][['label','intercept']]\n    target    = XYtrain[XYtrain['place']==place]['Fatalities']\n    Xtest     = XYtest[XYtest['place']==place][['label','intercept']]\n    model  = make_pipeline(PolynomialFeatures(5), Ridge())\n    model.fit(np.array(features), target)\n    y_pred = model.predict(np.array(Xtest))\n    d = pd.DataFrame(zip(XYtrain[XYtrain['place']==place]['place'], \n                              y_pred.tolist()),columns=['place','Fatalities'])\n    poly_predicted_fatalities = poly_predicted_fatalities.append(d)\n","3cfac66e":"# forward fill no fit places for confirmed cases\nfor place in nofit_places1:\n    e = poly_data[(poly_data['place']==place) & (poly_data['date']>'2020-03-11')]\n    f = e['ConfirmedCases'].fillna(method = 'ffill')\n    g = pd.DataFrame(zip(e['place'], f),columns=['place','ConfirmedCases'])\n    poly_predicted_confirmedcases = poly_predicted_confirmedcases.append(g)\n\n# forward fill no fit places for fatalities\nfor place in nofit_places2:\n    h = poly_data[(poly_data['place']==place) & (poly_data['date']>'2020-03-11')]\n    i = h['Fatalities'].fillna(method = 'ffill')\n    j = pd.DataFrame(zip(h['place'], i),columns=['place','Fatalities'])\n    poly_predicted_fatalities = poly_predicted_fatalities.append(j)","67fb09fa":"poly_predicted_confirmedcases2= pd.DataFrame({'date':XYtest.date,\n                                              'place':poly_predicted_confirmedcases['place'].tolist(),\n                                              'ConfirmedCases':poly_predicted_confirmedcases['ConfirmedCases'].tolist()})\npoly_predicted_confirmedcases2.head()","cfc915eb":"poly_predicted_fatalities2= pd.DataFrame({'date':XYtest.date,\n                                              'place':poly_predicted_fatalities['place'].tolist(),\n                                              'Fatalities':poly_predicted_fatalities['Fatalities'].tolist()})\npoly_predicted_fatalities2.head()","31cf8774":"poly_compiled = poly_predicted_confirmedcases2.merge(poly_predicted_fatalities2, how='inner', on=['place','date'])","1df14c04":"test_poly_compiled= test.merge(poly_compiled, how='inner', on=['place','date'])\ntest_poly_compiled","445a33f2":"submission= pd.read_csv(datapath+'submission.csv')","49e26ffe":"sub2 = submission[['ForecastId']].merge(test_poly_compiled[['ForecastId','ConfirmedCases','Fatalities']],\n                                      how='left',on='ForecastId') ","d86e41c7":"sub2['ConfirmedCases'] = sub2['ConfirmedCases'].round(0)\nsub2['Fatalities'] = sub2['Fatalities'].round(0).abs()","e834b386":"sub2","a9b8946e":"sub2.to_csv('submission.csv', index=False)","aa59fe0e":"# # create a function to find best model for the non-stationary ConfirmedCases and Fatalities\n# def pred_ets(fcastperiod,fcastperiod1,actual,ffcast,variable='ConfirmedCases',verbose=False):\n    \n#     actual=actual[actual[variable]>0]\n#     index=pd.date_range(start=ffcast.index[0], end=ffcast.index[-1], freq='D')\n#     data=ffcast[variable].values\n#     ffcast1 = pd.Series(data, index)\n#     index=pd.date_range(start=actual.index[0], end=actual.index[-1], freq='D')\n#     data=actual[variable].values\n#     daily_analysis_dat = pd.Series(data, index)\n#     livestock2=daily_analysis_dat\n#     fit=[]\n#     fcast=[]\n#     fname=[]\n#     try:\n#         fit1 = SimpleExpSmoothing(livestock2).fit()\n#         fcast1 = fit1.forecast(fcastperiod1).rename(\"SES\")\n#         fit.append(fit1)\n#         fcast.append(fcast1)\n#         fname.append('SES')\n#     except:\n#         1==1\n#     try:\n#         fit2 = Holt(livestock2).fit()\n#         fcast2 = fit2.forecast(fcastperiod1).rename(\"Holt\")\n#         fit.append(fit2)\n#         fcast.append(fcast2)\n#         fname.append('Holt')\n#     except:\n#         1==1\n#     try:\n#         fit3 = Holt(livestock2, exponential=True).fit()\n#         fcast3 = fit3.forecast(fcastperiod1).rename(\"Exponential\")\n#         fit.append(fit3)\n#         fcast.append(fcast3)\n#         fname.append('Exponential')\n#     except:\n#         1==1\n#     try:\n#         fit4 = Holt(livestock2, damped=True).fit(damping_slope=0.98)\n#         fcast4 = fit4.forecast(fcastperiod1).rename(\"AdditiveDamped\")\n#         fit.append(fit4)\n#         fcast.append(fcast4)\n#         fname.append('AdditiveDamped')\n#     except:\n#         1==1\n#     try:\n#         fit5 = Holt(livestock2, exponential=True, damped=True).fit()\n#         fcast5 = fit5.forecast(fcastperiod1).rename(\"MultiplicativeDamped\")\n#         fit.append(fit5)\n#         fcast.append(fcast5)\n#         fname.append('MultiplicativeDamped')\n#     except:\n#         1==1\n#     try:\n#         fit6 = Holt(livestock2, damped=True).fit()\n#         fcast6 = fit6.forecast(fcastperiod1).rename(\"AdditiveDampedC\")\n#         fit.append(fit6)\n#         fcast.append(fcast6)\n#         fname.append('AdditiveDampedC')\n#     except:\n#         1==1\n    \n#     pred_all_result=pd.concat([pd.DataFrame(k.fittedvalues) for k in fit],axis=1)\n#     pred_all_result.columns=fname\n#     all_result=pd.concat([pd.DataFrame(k) for k in fcast],axis=1)\n#     col_chk=[]\n#     vvvl=ffcast[variable].values.shape[0]\n#     for k in all_result.columns:\n#         if verbose: print(\"actual value for method %s  is = %s\" % (k,\n#                                                                    RMSLE(all_result[k].values,\n#                                                                          ffcast[variable].values)))\n#         if RMSLE(all_result[k].values[:vvvl],ffcast[variable].values) is not np.nan:\n#             col_chk.append(k)\n#     col_chk_f=[]\n#     min_acc=-1\n#     for k in col_chk:\n#         acc=RMSLE(pred_all_result[k].values,actual[variable].values)\n#         # if k =='AdditiveDamped' and acc>0.01:\n#         # acc=acc-0.01\n#         if verbose: print(\"pred value for method %s  is = %s\" % (k,acc))\n#         if acc is not np.nan:\n#             col_chk_f.append(k)\n#             if min_acc==-1:\n#                 min_acc=acc\n#                 model_select=k\n#             elif acc<min_acc:\n#                 min_acc=acc\n#                 model_select=k\n#     all_result=all_result.append(pred_all_result,sort=False)\n#     all_result['best_model']=model_select\n#     all_result['best_pred']=all_result[model_select]\n#     return all_result","8eb0442b":"# warnings.filterwarnings(\"ignore\")\n# import sys\n# orig_stdout = sys.stdout\n\n# Fatalities_all_result_final=pd.DataFrame()\n# ConfirmedCases_all_result_Final=pd.DataFrame()\n# for keys in allplaces:\n#     chk=train[train['place']==keys]\n#     chk.index=chk.date\n#     fcastperiod=0\n#     fcastperiod1=35\n#     actual=chk[:chk.shape[0]-fcastperiod]\n#     ffcast=chk[chk.shape[0]-fcastperiod-1:]\n#     ffcast\n#     try:\n#         Fatalities_all_result_1=pred_ets(fcastperiod,fcastperiod1,actual,\n#                                          ffcast,'Fatalities').reset_index()\n        \n#     except:\n#         Fatalities_all_result_1=pd.DataFrame(pd.date_range(start=chk.date.min(), \n#                                                            periods=60+fcastperiod1+1, \n#                                                            freq='D')[1:])\n#         Fatalities_all_result_1.columns=['index']\n#         Fatalities_all_result_1['best_model']='naive'\n#         Fatalities_all_result_1['best_pred']=0\n        \n#     Fatalities_all_result_1['place']=keys\n#     Fatalities_all_result_final=Fatalities_all_result_final.append(Fatalities_all_result_1,\n#                                                                    sort=True)\n#     try:\n#         ConfirmedCases_all_result_1=pred_ets(fcastperiod,fcastperiod1,actual,\n#                                              ffcast,'ConfirmedCases').reset_index()\n\n#     except:\n#         ConfirmedCases_all_result_1=pd.DataFrame(pd.date_range(start=train.date.min(), \n#                                                                periods=60+fcastperiod1+1, \n#                                                                freq='D')[1:])\n#         ConfirmedCases_all_result_1.columns=['index']\n#         ConfirmedCases_all_result_1['best_model']='naive'\n#         ConfirmedCases_all_result_1['best_pred']=1\n    \n#     ConfirmedCases_all_result_1['place']=keys\n#     ConfirmedCases_all_result_Final=ConfirmedCases_all_result_Final.append(ConfirmedCases_all_result_1,sort=True)\n# print(' done')\n\n# sys.stdout = orig_stdout","b04727e1":"# # place with lack of data to forecast\n# print(Fatalities_all_result_1['place'].unique())\n# print(ConfirmedCases_all_result_1['place'].unique())","f5703541":"# ConfirmedCases_all_result_Final.groupby('best_model')['place'].nunique().sort_values(ascending=False)","7a8429c6":"# Fatalities_all_result_final.groupby('best_model')['place'].nunique().sort_values(ascending=False)","c1a6ef1c":"# ConfirmedCases_all_result_Final.isna().sum()","a213ea9b":"# ConfirmedCases_all_result_Final.isna().sum()","cff8b4e2":"# ConfirmedCases_compiled_res = ConfirmedCases_all_result_Final[['best_pred','index','place']]\n# Fatalities_compiled_res  = Fatalities_all_result_final[['best_pred','index','place']]","a353f06c":"# ConfirmedCases_compiled_res.columns = ['ConfirmedCases','date','place']\n# Fatalities_compiled_res.columns     = ['Fatalities','date','place']","3e34a08f":"# ConfirmedCases_compiled_res.columns","d71428ad":"# Fatalities_compiled_res.columns","71537787":"# a = ConfirmedCases_compiled_res.merge(test[['ForecastId','date','place']], \n#                                       how='right',on=['place','date'])\n# a = a.sort_values(['ForecastId'])\n# a","89b00a56":"# b = Fatalities_compiled_res.merge(test[['ForecastId','date','place']], \n#                                       how='right',on=['place','date'])\n# b = b.sort_values(['ForecastId'])\n# b","f14796de":"# sub = a.merge(b[['ForecastId','Fatalities']], on=['ForecastId'],  how='left')\n# sub","5fe6d33c":"# sub[['ConfirmedCases','Fatalities']] = sub[['ConfirmedCases','Fatalities']].fillna(0)","b980cb78":"# sub.isna().sum()","afc1a47d":"#### SUBMISSION","0ad8ccc8":"# Forecasting using Polynomial Regression","eb029620":"#### Compiling results","bf36b806":"#### TRY POLYNOMIAL REGRESSION","dc2120c8":"#### For fatalities","fdb0c0b8":"#### Consider other methods","4b11dd41":"#### Predict for Confirmed Cases","1b25aae3":"#### FOR CONFIRMED CASES"}}