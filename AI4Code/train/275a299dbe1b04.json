{"cell_type":{"995b1630":"code","8b30fa9f":"code","4ce50cc2":"code","1fba7a02":"code","ec1320b7":"code","a4775fa1":"code","5d3de76a":"code","5e954ffa":"code","1888b7be":"code","b933b0c5":"code","8e39d2a6":"code","0873b77a":"code","d95b3acf":"code","2636a5cb":"code","6dcad703":"code","d70bbe07":"code","45327df5":"code","bfbb9921":"code","8bbd306c":"code","8e4692fd":"code","85f59218":"code","7ecf745d":"code","f720ea5d":"code","c261d13f":"code","75d2c739":"code","ab2fc53a":"code","c4d9f6ff":"code","3820aa61":"code","57a046b5":"code","e03cbb0a":"code","41fa4ed2":"code","444d631c":"code","14c5dcd5":"code","cd345bea":"code","7064f5a0":"markdown","20787e9a":"markdown","18ef8842":"markdown","b49c2746":"markdown","831f3ac1":"markdown","f21f5215":"markdown","809223a9":"markdown","adeb0d61":"markdown","b75c6cfd":"markdown","e1f4c4a3":"markdown","9d980b09":"markdown","7929293c":"markdown","ac7efa9e":"markdown","bf4e07b1":"markdown","9787f404":"markdown","45973273":"markdown","dbd31b70":"markdown","d72bced2":"markdown","ba888df2":"markdown","3b4535bd":"markdown","75d48b6c":"markdown","735b05d9":"markdown","b1054cc3":"markdown","3cfb45ca":"markdown","6158c131":"markdown","4558013c":"markdown","d1cfa51c":"markdown","ba367ed7":"markdown","01c5c503":"markdown","607483bc":"markdown","5d1e3c31":"markdown","7c97818c":"markdown","1d73a12c":"markdown","564348e5":"markdown","6442b734":"markdown","997d768d":"markdown","a1bacd81":"markdown","65a7674f":"markdown","0cfd8a56":"markdown","dfc9a1ac":"markdown","43e4ae35":"markdown","435dcfe2":"markdown","cdda87a1":"markdown","8f4a909d":"markdown","3e8895c6":"markdown","4e70e078":"markdown","579129cd":"markdown","d2b84460":"markdown","d959aa1d":"markdown","7cdc74fb":"markdown","c171beb6":"markdown","b2cbf858":"markdown","48fd34e3":"markdown","cd2f6587":"markdown","f064ad1b":"markdown","af6142bf":"markdown","170a468e":"markdown","2f337238":"markdown","178ee2f4":"markdown","47ec7796":"markdown","536af2c1":"markdown","4ea1bf8a":"markdown","654e2cac":"markdown","6a8f201b":"markdown","ee837483":"markdown","cbffa5d1":"markdown","5abd25f0":"markdown","b315d2a9":"markdown","567bdd15":"markdown","3b6f733f":"markdown","fad4fc0e":"markdown","3e70bed7":"markdown","5cf7e88b":"markdown","fbccd3e3":"markdown","4ca114dd":"markdown","fd2ea07b":"markdown","2668fec8":"markdown","76be7cc6":"markdown","28e783e3":"markdown","f0e80ded":"markdown","791bcafd":"markdown","06d93f68":"markdown","4f7fa99a":"markdown","1ab7e47b":"markdown","8bac2328":"markdown","e3b26b78":"markdown","4282dedb":"markdown","e21deb45":"markdown","801bb552":"markdown","9d0cd60d":"markdown","ba8b9aba":"markdown","dc8dedb9":"markdown","0a85d9ad":"markdown","6ed56bcc":"markdown","8307d59e":"markdown","a72b6673":"markdown","4389cdd4":"markdown","425d4d34":"markdown","cdaa7243":"markdown"},"source":{"995b1630":"import numpy as np                              #numpy library is used to work with multidimensional array.\nimport pandas as pd                             #panda used for data manipulation and analysis.\n                 \nimport os                                       #os library is used for loading file to use in the program\nimport json                                     #json library parses json into a string or dict, and convert string or dict to json file.\nfrom pathlib import Path                        #support path\n\nimport matplotlib.pyplot as plt                 #support ploting a figure\nfrom matplotlib import colors                   #colors support converting number or argument into colors\n\nfrom itertools import combinations              #get different combinations of elements from numpy array.\n\n# get the path for training_task, evaluation_task, and test_task\ndata_path = Path('\/kaggle\/input\/abstraction-and-reasoning-challenge\/')\ntraining_path = data_path \/ 'training'\nevaluation_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'\n\n#from the path above, we load the tests file's directory into our training_tasks, evaluation_tasks, and test_tasks variables\n#the sorted() function is just for the list of directory to maintain some order\ntraining_tasks = sorted(os.listdir(training_path))\nevaluation_tasks = sorted(os.listdir(evaluation_path))\ntest_tasks = sorted(os.listdir(test_path))\n\n#Get the first file of the training_tasks\ntraining_task_file = str(training_path \/ training_tasks[0])\n\n#Get the first file of the evaluation_tasks\nevaluation_task_file = str(evaluation_path \/ evaluation_tasks[0])\n\n#Get the first file of the test_tasks\ntest_task_file = str(test_path \/ test_tasks[0])\n\n#open the file and load it\nwith open(training_task_file, 'r') as f:   \n    #can change training_task_file to evaluation_task_file or test_task_file to have a look at evaluation file or test file\n    task = json.load(f)\n\ncmap = colors.ListedColormap(\n    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n\n#plotting the training task and the test task.\n#use only for task in training tasks and evaluation tasks\ndef plot_task(task):\n    n = len(task[\"train\"]) + len(task[\"test\"])\n    fig, axs = plt.subplots(2, n, figsize=(4*n,8), dpi=50)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    fig_num = 0\n    for i, t in enumerate(task[\"train\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Train-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Train-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    for i, t in enumerate(task[\"test\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Test-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Test-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    \n    plt.tight_layout()\n    plt.show()\n    ","8b30fa9f":"# plot_pictures is a function to plot our prediction of a specific task, it includes two variables pictures and labels\n# pictures will be the list which contains input, output(in case of file in TEST part there is no output) and our prediction.\n# labels is the list of labels \"Input\", \"Output\", \"Prediction\" that will be shown in the plotted figure.\ndef plot_pictures(pictures, labels):\n        fig, axs = plt.subplots(1, len(pictures), figsize=(2 * len(pictures), 32))\n        for i, (pict, label) in enumerate(zip(pictures, labels)):\n            axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n            axs[i].set_title(label)\n        plt.show()","4ce50cc2":"file_name = \"db3e9e38.json\"                   #the name of the file containing the task\n\n","1fba7a02":"# Although we know that this file locates in the training set, we generalize it to make sure that no matter\n# where the file locates, we can open it. How we can do it is shown in the code below.\ndef init_task(file_name):\n    task_file = None\n    task = None\n    if file_name in training_tasks:\n        task_file = str(training_path \/ file_name)\n    elif file_name in evaluation_tasks:\n        task_file = str(evaluation_path \/ file_name)\n    elif file_name in test_tasks:\n        task_file = str(test_path \/ file_name)\n    with open(task_file, 'r') as f:   \n        task = json.load(f)\n    return task","ec1320b7":"task = init_task(file_name)\nprint(task)\nplot_task(task)","a4775fa1":"observations = None              #Our memory, the data structure that we gonna use for remembering information\ninput_ = None                    #As we go through each sample in the task, we will assign the input to input_\noutput = None                    #As we go through each sample in the task, we will assign the output to output_\ninput_original = None            #As we go through each sample, we will modify the input as you can see above, so we need\n                                 #a variable to keep the original sample's input, and that is input_original mission\n#Every grid that we store in the memory for this task is 3x3 grid. If we enumerate the grid from top to bottom, from left to \n#right by number from 0 -> 8, the square that we care about (which is in the center) has index 4. That is what the two\n#following variables mean. Stay tuned for how we will use them ...\nremove_idxs = 4                  \nconclusion_idx = 4\n\ndistance = 1                     #how far from a square that we want to observe and save to memory, in this case only 1 because\n                                 #we only look at the squares next to it vertically, horizontally or diagonally.\nk = 9                            #number of cells in the grid that we save to the memory,3x3 = 9","5d3de76a":"#_pad_image helps us to create a border of zeros around whatever numpy array that we give it.\ndef _pad_image(image):\n    return np.pad(image, distance, constant_values=0)","5e954ffa":"#example for the usage of _pad_image\n#define arr as a numpy array\narr = np.array([[1,2],[3,4]])\nprint(arr)\nprint(\"after using _pad_image\")\nprint(_pad_image(arr))","1888b7be":"def _remove_padding(frame):\n    return frame[distance: -distance, distance: -distance]","b933b0c5":"def _sample_handler(sample):\n    global input_, output, input_original\n    input_ = np.array(sample[\"input\"])\n    input_ = _pad_image(input_)\n    if \"output\" in sample:\n        output = np.array(sample[\"output\"])\n        output = _pad_image(output)\n    else:\n        output = None\n    input_original = input_.copy()","8e39d2a6":"def _grid_walk():\n    global input_\n    rows, cols = input_.shape[0], input_.shape[1]\n    r0 = reversed(range(distance, rows-distance))\n    for i in r0:\n        r1 = range(distance, cols - distance)\n        for j in r1:\n            yield i, j","0873b77a":"def get_neighbours(frame, row, col):\n    #get the grid (row, col) and its 8 neighbors as a 3x3 numpy array\n    kernel = frame[row-distance:row+distance+1, col-distance:col+distance+1]\n    #flatten the kernel and delete the value at index number remove_idxs = 4 (which is the board[i,j]'s value, not its neighbors)\n    neighs = np.delete(kernel.flatten(), remove_idxs)\n    return neighs","d95b3acf":"#Example for usage of get_neighbors:\n#initiate a numpy array\narr = np.array([[1,2,3],[4,5,6],[7,8,9]])\nprint(get_neighbours(arr,1,1))","2636a5cb":"def get_label(output, row, col):\n    global distance, conclusion_idx\n    kernel = output[row-distance:row+distance+1, col-distance:col+distance+1]\n    label = kernel.flatten()[conclusion_idx]\n    return label","6dcad703":"def _sum_neighs(neighs):\n    return neighs.sum()","d70bbe07":"def _generate_observation(neighs, conclusion):\n    return neighs.tolist() + [conclusion] if conclusion is not None else neighs.tolist()","45327df5":"def observe(task):\n    global observations, input_, output, input_original\n    train = task[\"train\"].copy()                                         #get all \"train\" samples in a task.\n    observations = []                                                    #initialize a list of observations.\n    for sample in train:                                                 \n        _sample_handler(sample)                                          #add padding\n        for i, j in _grid_walk():                                        #walk through the grid in determined direction.\n            neighs = get_neighbours(input_, i, j)                        #get neighbors' value  \n            conclusion = get_label(output, i, j)                         #get the color of the examined grid from the output \n            if _sum_neighs(neighs) > 0:                                  #check if neighbors are not all black\n                observation = _generate_observation(neighs, conclusion)  #get the full observation\n                if observation not in observations:                      \n                    observations.append(observation)                     #add the observation in memory\n                input_[i, j] = output[i, j]                              #assign the output's value of (i,j) square to input_[i,j]\n    input_ = input_original.copy()  # reset input","bfbb9921":"observe(task)","8bbd306c":"#LIST OF NUMBER VIEW\nprint(observations)","8e4692fd":"#COLOR VIEW\n\ndef unflatten(arr):\n    #take the observations that have been flatten and bring it back to the 3 * 3 shape\n    #initiate a 3x3 array\n    three_by_three = np.zeros([3,3])\n    index = 0\n    for i in range(len(three_by_three)):\n        for j in range(len(three_by_three[0])): \n            if i == (len(three_by_three) - 1) \/ 2 and i == j:\n                three_by_three[i,j] = arr[-1]\n            else:\n                three_by_three[i, j] = arr[index]\n                index += 1\n    return three_by_three\n\ndef plot_array():\n    global observations\n    n = len(observations)\n    fig, axs = plt.subplots(1, n, figsize=(4*n,8), dpi=50)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    fig_num = 0\n    for i, t in enumerate(observations):\n        t_in = unflatten(observations[i])\n        axs[fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[fig_num].set_title(f'Test-{i} in')\n        axs[fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[fig_num].set_xticks(list(range(t_in.shape[1])))\n        fig_num += 1\n    \n    plt.tight_layout()\n    plt.show()\n\nplot_array()\n","85f59218":"def my_prediction(task):\n    global observations, input_, output, input_original\n    colors = [0,7,8]\n    all_predictions = []\n    for sample in task[\"test\"]:\n        _sample_handler(sample)\n        for i, j in _grid_walk():\n            neighs = get_neighbours(input_, i, j)\n            if _sum_neighs(neighs) > 0:\n                for color in colors:\n                    if (neighs.tolist() + [color]) in observations:\n                        input_[i,j] = color\n        input_ = _remove_padding(input_)\n        guess = input_.tolist()\n        all_predictions.append(guess)\n    input_ = input_original.copy()\n    return all_predictions\n\n# And plot my predictions\ndef plot_predictions(task, predictions):\n    n = len(task[\"train\"]) + len(task[\"test\"])\n    fig, axs = plt.subplots(2, n, figsize=(4*n,8), dpi=50)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    fig_num = 0\n    for i, t in enumerate(task[\"train\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Train-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Train-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    for i, t in enumerate(task[\"test\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(predictions[i])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Test-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'My prediction-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    \n    plt.tight_layout()\n    plt.show()\n    \npredictions = my_prediction(task)\nplot_predictions(task, predictions)     \n","7ecf745d":"explanations = None      #data structure we use to store our inference. Explanations will be initialized as a dictionary","f720ea5d":"def _combination_walk(k):\n    r_min = 1\n    r_max = 3                                   #we can even set r_max to 8 but for this task, 3 is more than enough\n    indices = np.arange(k-1).tolist()           #generate a list in range(k-1), remember that k == 9\n    for r in range(r_min, r_max+1):\n        for combi in combinations(indices, r):  #generate all diffrent r-element sets from a list, int this case (indices)\n            yield combi","c261d13f":"def _generate_explanation(observation, combi):\n    explanation = \",\".join(\n        [str(s) if i in combi else \"-\" for i, s in enumerate(observation[:k-1])])\n    return explanation","75d2c739":"obs = [0,0,0,0,0,0,0,7,8] #the 7 first elements are the features, the last element is the conclusion\ncombi = [7]            #hinting at position indexed 0 and 7\nprint(_generate_explanation(obs, combi))","ab2fc53a":"# this is the function to check if our labelling we have just talked about is good or bad.\ndef _explanation_handler(explanations, freq_threshold):\n        explanations_ = explanations.copy()          # explanations_ now store all of our labelling\n        for explanation in explanations.keys():      \n            if len(set(explanations[explanation][\"conclusion\"])) == 1:  # no contradiction condition, which means our labelling is good\n                freq = len(explanations_[explanation][\"conclusion\"])\n                if freq >= freq_threshold:\n                    explanations_[explanation][\"frequency\"] = freq     #How many times a particular labelling happens\n                                                                       #For example, in observations the explanation\n                                                                       #(-,-,-,-,-,-,-,7 : 8) happens 8 times so frequency = 8\n                    explanations_[explanation][\"conclusion\"] = int(explanations[explanation][\"conclusion\"][0])\n                else:\n                    del explanations_[explanation]\n            else:\n                del explanations_[explanation]\n        return explanations_","c4d9f6ff":"def reason():\n        global explanations\n        freq_threshold = 2\n        explanations = {}\n        for combi in _combination_walk(k):\n            for observation in observations:\n                explanation = _generate_explanation(observation, combi)  #generate an explanation by ignore other position \n                                                                         #in observation but position in combi\n                if explanation in explanations:\n                    explanations[explanation][\"conclusion\"].append(observation[-1])  #labelling the explanation above\n                                                                                     #If the explanation is already in explanations\n                                                                                     #just add the label (conclusion) to it.\n                else:\n                    explanations[explanation] = {\"conclusion\": [observation[-1]]}\n        explanations = _explanation_handler(explanations, freq_threshold)            #check for correctness of the explanation","3820aa61":"reason()","57a046b5":"print(explanations)","e03cbb0a":"def _decide_conclusion(conclusions):\n        conclusion = None\n        val = - np.inf\n        df = pd.DataFrame(conclusions, columns=[\"conclusion\", \"frequency\"])\n        for conc in df.conclusion.unique():\n            val_ = df[(df.conclusion == conc)].frequency.shape[0]\n            if val_ > val:\n                conclusion, val = conc, val_\n        return conclusion","41fa4ed2":"# remove padding for everything\ndef _revert_sample_padding():\n        global input_original, input_, output\n        input_original = _remove_padding(input_original)\n        input_ = _remove_padding(input_)\n        if output is not None:\n            output = _remove_padding(output)\n\ndef _compute_score(prediction):\n        global output\n        score = None\n        if output is not None:\n            _revert_sample_padding()\n            score = 1 if np.array_equal(output, prediction) else 0\n        return score","444d631c":"def plot_sample(predict=None):\n    global input_original, output\n    pictures = [input_original, output] if output is not None else [input_original]\n    labels = ['Input', 'Output'] if output is not None else [\"Input\"]\n    if predict is not None:\n        pictures = pictures + [predict]\n        labels = labels + [\"Predict\"]\n    plot_pictures(pictures, labels)","14c5dcd5":"def predict(is_train=False, visualize=False):\n        global input_, explanations\n        num_loops = 1\n        visualize_prediction = False\n        samples = task[\"test\"] if not is_train else task[\"train\"]\n        predictions, scores = [], []\n        \n        for sample in samples:\n            _sample_handler(sample)\n            prediction = input_.copy()\n            for loop in range(num_loops):\n                for i, j in _grid_walk():\n                    neighs = get_neighbours(prediction, i, j)\n                    if _sum_neighs(neighs) > 0:\n                        explanation_set, conclusions = [], []\n                        for combi in _combination_walk(k):\n                            observation = _generate_observation(neighs, None)          #getting the neighbours list\n                            explanation = _generate_explanation(observation, combi)    #generate possible explanation by combi\n                            if explanation in explanations.keys():\n                                con = explanations[explanation][\"conclusion\"]          \n                                freq = explanations[explanation][\"frequency\"]\n                                conclusions.append((con, freq))                        #adding in possible explanations for\n                                                                                       #defining the final conclusions.\n                                explanation_set.append(explanation)\n                        conclusion = _decide_conclusion(conclusions)                   #decide conclusion as explained above.\n                        prediction[i, j] = conclusion if conclusion is not None else prediction[i, j]\n                        if visualize_prediction:\n                            plot_sample(prediction)\n            prediction = _remove_padding(prediction)\n            predictions.append(prediction)\n            scores.append(_compute_score(prediction))\n            if visualize:\n                plot_sample(prediction)\n        return predictions, scores","cd345bea":"predict(visualize = True)","7064f5a0":"![image.png](attachment:image.png)","20787e9a":"![image.png](attachment:image.png)","18ef8842":"Let's run the observe function","b49c2746":"*7. _generate_observation(neighs, conclusion)*","831f3ac1":"The approach takes MEMORY as a factor of learning. When you are in the process of preparing for a test, it is highly likely that you will revise the lectures, learn by heart some key contents, and when the test time comes, you try your best to pull those knowledge out of your memory. The same thing happens here, recall that every task has two parts: the \"train\" part and the \"test\" part, what we gonna do here is that we will go through the \"train\" part, save necessary information (in some data structures) using our STRATEGY, then go through the input of \"test\" part and apply what we have saved in our memory.","f21f5215":"FINALLY, IT'S TIME FOR THE PREDICTION AND PLOT IT OUT.","809223a9":"* *After observing the square and save the info to the memory, assign the color of the output square to the input square that you are looking at*\n\nFor example, after doing all of the above steps, we assign the color BLACK of the output square to the input square we are looking at, which is the yellow-border grid. But since the input square we are looking at is already black, so nothing changes.","adeb0d61":"A list return without the value at position (1,1)","b75c6cfd":"*6. sum_neighs(neighs)*","e1f4c4a3":"Okay, that is the explanation on how we observe the task's training samples. It is time for some implementations.","9d980b09":"![image.png](attachment:image.png)","7929293c":"*2. _sample_handler(sample)*","ac7efa9e":"This code has been clearly explained in PART 1, so if some part in this code is hard to be understood, feel free to visit my Part 1 [here](http:\/\/https:\/\/www.kaggle.com\/giangpt\/arc-complete-beginner-guide-part-1)","bf4e07b1":"Let me give you an example on this function:","9787f404":"Remember that at some point we need to refer to the training sample's output to learn what is the color of the examined square? _get_label(output, row, col) do just that. ","45973273":"![image.png](attachment:image.png)","dbd31b70":"Just take the neighs numpy array that we have just found in get_neighbors() and calculate the sum of that numpy array. The purpose is to check whether or not all of the square's neighbors are BLACK (number 0). If all of them are BLACK, we move on to examine other square, as mentioned before.","d72bced2":"   * For each training sample\n    * Go through every square in the sample board from left to right, from the bottom to the top. For each grid, observe the grids surrounding it, and save them to our memory. ","ba888df2":"Besides, I will add one more function to plot our predictions later on.","3b4535bd":"This is the order we gonna look through the sample. From the red square following the direction of the red arrow.\n\n![image.png](attachment:image.png)","75d48b6c":"In the article, the author shows how his approach can be used to solve two examples. In this notebook, I will demonstrate in clear details what his approach is and how he implements it.","735b05d9":"It is time to save it to the memory. SAVE!!","b1054cc3":"Then the yellow-border square tries all the colors (black, orange, blue) and find if the pattern exists in the memory or not. Unfortunately, there is nothing like that in the memory, so it keeps the color black, which is obviously the wrong answer, and the other wrong answers just follow.","3cfb45ca":"First, let's have an overview of the idea, I will demonstrate it through a task in training set. So let's load the task in.","6158c131":"3. plot_sample(): plotting the prediction","4558013c":"![image.png](attachment:image.png)","d1cfa51c":"As we can see, the task is represented as a dictionary data structure. And we use plot_task() function to turn it into picture that we can visualize.","ba367ed7":"1. _combination_walk():","01c5c503":"What is the purpose of this function? It is to choose between possible explanations. Let's take an example for clearer understanding.\n\nAssume that you are examining a square (this is just an example, not necessarily to be true), the square has the neighbors [7,0,8,7,0,7,0,7]. Then there are multiple explanations can be generated from this neighbors pattern.\n+ Case 1: -,-,-,-,-,-,-,7 ---> this explanation is labelled 8 as the conclusion.\n+ Case 2: 7,-,8,-,-,-,-,- ---> this explanation is labelled 0 as the conclusion.\n+ Case 3: 7,-,8,-,-,-,-,7 ---> this explanation is labelled 8 as the conclusion.\n\nSuppose that there are only three cases like this (the assumption maybe wrong, but it is just for the purpose of an easy-to-understand example). From here, we can observe that the value 8 is labelled in 2 cases, while number 0 is only labelled once. Then the _decide_conclusion() chooses 8 as the final conclusion and return it.","607483bc":"Last step, assign that blue color to the square we are looking at from the input. Now the input becomes","5d1e3c31":"# ROAD TO ABSTRACTION AND REASONING CORPUS PART 2","7c97818c":"2. compute_score()","1d73a12c":"FINALLY, IT IS TIME FOR THE REASONING.","564348e5":"3. _explanation_handler()","6442b734":"First, let's create some more variables","997d768d":"_generate_explanation() takes two inputs:\n+ observation: one of the observations in the memory, observation is a list of 9 numbers, numbers indexed from 0->7 are the 8 features, number indexed 8 is the coclusion of the value in examined square\n+ combi: list of position selected that we have generated from  _combination_walk()","a1bacd81":"Return 1 if the prediction == the output. Else 0","65a7674f":"So as I go through notebooks and webpages to extract some insights into the problem. I stumble upon this awesome article, where the author explained his way to solve some of the problems in the competition. If you want to check it out yourself, you can visit [here](https:\/\/medium.com\/@matlihan\/solving-the-abstraction-and-reasoning-corpus-with-logical-reasoning-abductive-reasoner-9845de9714b1)","0cfd8a56":"Now, one question arises, can we use what we have observed and apply directly to solve the test output?\nThere is only one way to know. Let's try it out.","dfc9a1ac":"# OBSERVE","43e4ae35":"# View the task","435dcfe2":"Now, again, let's have look at what we haved achieve after reasoning through different views.\n\nConsole view, print out the explanations variable.","cdda87a1":"That is the overview of what we gonna do. Now being more specific, what is exactly the STRATEGY of getting information that I am talking about. It is simple as this:","8f4a909d":"![image.png](attachment:image.png)","3e8895c6":"# INFERENCE","4e70e078":"Now, refer to the output to see the yellow-border square color","579129cd":"A function to load the task.","d2b84460":"But now, from the key insight that we have discovered before, whenever the feature_8 (bottom right corner) is 7 (orange), then the examined square (square in yellow border) has the value of 8 (which is blue), and that gives us the correct answer. And maybe that one piece of information is just enough to solve our task. ","d959aa1d":"Combine get_neighbors() and get_label() to generate the full observation.","7cdc74fb":"So, that is it, the task has been solved by our approach after 3 steps: Observe, Inference and Predict. Thanks for reading till the end. Upvote if you think this notebook has brought you some values. \n\nAnd, as a complete beginner, I really want to have some recommendations on what I should read next about this subject. So I would be so thankful you guys can recommend me some. \n\nThank you for reading this far and have a nice day !!!!","c171beb6":"  In this case, we refer to the output of the sample and figure out that the square we are looking at in the input is actually black in the output.\n  As a result, we save the following to our memory.\n \n![image.png](attachment:image.png)","b2cbf858":"1. _decide_conclusion()","48fd34e3":"And we find out that it is blue.","cd2f6587":"![image.png](attachment:image.png)","f064ad1b":"Let's have a look at another example.\n\n","af6142bf":"This is how we gonna look at each grid. When we look at the grid there are two possibilities happen:\n* There is nothing around.\nIn the image below, the square we are looking at, which has yellow border, has nothing around it. In that case, we just move on, because if the squares surrounding it are all black, then any prediction might not be yet accurate.\n\n![image.png](attachment:image.png)\n\n* There is something around.\nThe square that we mark yellow is the square that we are looking at. As we can see, on the top right corner of it, there is a square in orange.\n\n","170a468e":"The function returns a 1D color list of all neighbors of the examined square.","2f337238":"![image.png](attachment:image.png)","178ee2f4":"Hey! The square we are looking at is on the edge of the board, how come that we save a 3x3 board to the memory? \nWell, just for consistency, we just add three more squares under the yellow-border grid, the colors of which are all black. How we implement this in the code will be discussed later.\n\nOkay, now, whenever we look at an input square that has its 8 neighbors, 7 of which are black but the top right corner neighbor is orange, then you should predict the square you are looking at to be black.\n\nIf your square is in the corner or on the edge and you want to predict its color. Well, just add more squares around it as we do above, and make sure that the square you are looking at is in the center. Then use the same method as before to predict the color of that square.","47ec7796":"FINALLY, THE OBSERVE() FUNCTION","536af2c1":"# Import the Data and Basic Data Manipulation","4ea1bf8a":"What is the purpose of this function? It generates knowledge and key insights like what we do at the beginning of this INFERENCE PART. Just take the result of this _generate_explanation() function, label it with a conclusion (in our case 8) like this: {-,-,-,-,-,-,-,7 : 8} and store it in our explanations, we have a new explanation that basically means that in a set of features, if the last feature (feature_8) is 7, then the conclusion is 8.\n\nHowever, we also need something to verify whether our labelling is correct or not. So more about that later on ... Stay tuned!!","654e2cac":"   For example, let's have a look at the first training sample of the task. On the left is the input, on the right is the output\n   \n   ![image.png](attachment:image.png)","6a8f201b":"![image.png](attachment:image.png)","ee837483":"If we want to predict the test part's output right now, the approach is simple. Go through the test grid from bottom to top, from left to right. For each square we go through, we check the neighbors, and search in the memory to find something similar to it, if the pattern of neighbors can be found in the memory, we assign the examined square to the relevant color.\n\nThe code below will do just that.","cbffa5d1":"Now it's time to have a look at it.","5abd25f0":"As we can see, the code in observe() function strictly follows the step that we have discussed before.","b315d2a9":"![image.png](attachment:image.png)","567bdd15":"Anyway, it is time to implement such thing that we have just talked about, in this implementation part, we will not only try to find out only 1 key insight like the one we have done above, but we gonna try to find all of them. So let's do it!!!","3b6f733f":"And we continue to visit other squares... And if you want to see all the transformations of the input. You are welcome!!","fad4fc0e":"Well, perhaps no colorful grid view for this part.","3e70bed7":"Well, does that mean this approach has failed?\nHmmm, YES and NO.\n\nYES if you only stop right here.\nNO if we gonna dig further and extract valuable knowledge from our observations.\n\nThe Exam Metaphor now strikes again, if you ONLY learning by heart the lectures' content, you will have a pretty tough time with the test. Because it is likely that the test has many parts that are not in the lectures, but can be INFERRED quite easily from the lectures' content. That leads us to the next PART, that is to create INFERENCE from the observations we have found.","5cf7e88b":"After we go through all of different cases in our memory, we realize that whenever feature_8 is 7, the conclusion is 8, as you can see above. So, it is somewhat reasonable to conclude that if we know that feature_8 is 7, then the examined square should have the value of 8. (Note that number 7 represents the color orange and number 8 represents the color blue)\n\nSo gaining only one more piece of knowledge, can we somehow improve the memory-based prediction that we have made before. Lucky for us, the answer is YES. Remember the reason we discuss before about why memory-based prediction cannot give us the correct answer? It is because we encounter a square whose neighbors' pattern cannot be found anywhere in our observed memory. I will show it again here.","fbccd3e3":"Okay it is time to find out how our approach will succeed. But first, let's define helper functions","4ca114dd":"![image.png](attachment:image.png)","fd2ea07b":"2. _generate_explanation()","2668fec8":"Now, let's turn that dictionary into CSV File for more viewer friendly.\n\nCSV FILE VIEW (maybe not enough explanations here)","76be7cc6":"Now let's introduce some more helper function for inference","28e783e3":"*5. get_label(output, row, col)*","f0e80ded":"*1. _pad_image() and _remove_padding()*","791bcafd":"Remember the example that we have to add three squares to the bottom of the examined square? _pad_image() do just that, it ensure that each square of the original grid being padded has exactly 8 neighbors.","06d93f68":"Let's now define some of the variables that we are going to use for observation.","4f7fa99a":"After observing, let's see what is now in the observation memory. (Through different views)","1ab7e47b":"_remove_padding removes all 0 surrounding the array. This will counter the effect of _pad_image()","8bac2328":"![image.png](attachment:image.png)","e3b26b78":"This notebook is the next part of *ARC COMPLETE BEGINNER GUIDE PART 1*, where I, as a complete begginer, go through each and every notebook and article to gain deeper understanding on the ARC subject. In part 1, I have given the introduction to the ARC problem and basic manipulation of the data. If you have not viewed it yet, you can have a look at it in the link below.\n\nHere is the link: https:\/\/www.kaggle.com\/giangpt\/arc-complete-beginner-guide-part-1","4282dedb":"Okay, now I will explain this approach in details.","e21deb45":"When it comes to examine the yellow-border square. The algorithm checks its neighbours","801bb552":"Now the square we are examining is in the middle of the board, looking at its neighbors and we get this:","9d0cd60d":"CSV FILE VIEW:\nNote: feature 1 to 8 is the value of the examined square's neighbors, and the conclusion is the value of the examined square.\n\n![image.png](attachment:image.png)\n\n","ba8b9aba":"*4. get_neighbours(frame, row, col)*","dc8dedb9":"So, now, what we can reason from our observations. Let's first have a quick look through the CSV file that we have created before, with a little bit more insight into them.","0a85d9ad":"Next, I will define some helper function for our observation","6ed56bcc":"# PREDICTION","8307d59e":"OOPSIE!!!! What just happens.\nOne possible guess is that it goes through a square, check the neighbors and cannot find something similar in the memory. And that is exactly what happens right here.","a72b6673":"The misson of _sample_handler() is to pad input_, output with 0 outside using the previous function. Also assign input_original as a copy of input_.","4389cdd4":"Is our reasoning strong enough to solve this puzzle? Let's come to the last step to find out.","425d4d34":"Remember the direction we have to go to examine each sample in \"train\" part? It is from the bottom to the top, from left to right, and _grid_walk() returns the pair of i, j in the order that enables us to do that.\n\nNote that the input_ in the function is the input_ after being padded by _pad_image().So The reason we have range(distance, rows - distance) and range(distance, cols - distance) for i and j is that we do not want to examine the padded part of the board.","cdaa7243":"*3. _grid_walk()*"}}