{"cell_type":{"ced0fa91":"code","d27e1951":"code","1a8b7f92":"code","5c530c8c":"code","9c36e1e6":"code","d02b0482":"code","d87523f2":"code","ba095f30":"code","f9959e2a":"code","ef3d91c1":"code","d4c4e5bd":"code","259b4465":"code","732d2978":"code","e28b40f5":"code","77f34575":"code","53296b9e":"code","951183bc":"code","0ee8277d":"code","f3c5ee44":"code","e04c4624":"code","cefd8925":"code","49c0e0f0":"code","232b3409":"code","b1627304":"code","c91a712f":"code","57f61d76":"code","4bffc4e4":"code","e040f5c0":"code","f497b821":"code","3379b05c":"code","99597f2b":"code","a37c8fac":"code","9a9f948f":"code","5601503f":"code","6560df52":"code","7b5d46c9":"markdown","8e5c4efc":"markdown","8d2b8931":"markdown","8e76185a":"markdown","ba95ae40":"markdown","25fc0e39":"markdown","42b20018":"markdown","39705748":"markdown","1272f514":"markdown","5604dc09":"markdown","b0b51ad3":"markdown","ab926ac9":"markdown","49816bff":"markdown","8df7bce0":"markdown","ed7ebe8a":"markdown"},"source":{"ced0fa91":"\n#import libraries\nimport sys\nprint('Python: {}'.format(sys.version))\nimport scipy\nprint('scipy: {}'.format(scipy.__version__))\nimport numpy as np\nprint('numpy: {}'.format(np.__version__))\nimport matplotlib\nimport matplotlib.pyplot as plt\nprint('matplotlib: {}'.format(matplotlib.__version__))\nimport pandas as pd\nprint('pandas: {}'.format(pd.__version__))\nimport sklearn \nprint('sklearn: {}'.format(sklearn.__version__))\nimport seaborn as sns\nprint('seaborn: {}'.format(sns.__version__))","d27e1951":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","1a8b7f92":"#Load datasets\ndf_train=pd.read_csv(\"https:\/\/raw.githubusercontent.com\/TracyRenee61\/House-Prices\/master\/train.csv\")\ndf_train","5c530c8c":"\n#Load datasets\ndf_test=pd.read_csv(\"https:\/\/raw.githubusercontent.com\/TracyRenee61\/House-Prices\/master\/test.csv\")\ndf_test\n","9c36e1e6":"sns.distplot(df_train['SalePrice']);","d02b0482":"var = 'OverallQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(14, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","d87523f2":"total = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","ba095f30":"total = df_test.isnull().sum().sort_values(ascending=False)\npercent = (df_test.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","f9959e2a":"obj_df_train = df_train.select_dtypes(include=['object']).copy().reset_index()\nobj_df_train","ef3d91c1":"obj_df_train = obj_df_train.fillna(\"Not Listed\")\nobj_df_train","d4c4e5bd":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nobj_df_train = obj_df_train.apply(le.fit_transform)\nobj_df_train","259b4465":"int_df_train = df_train.select_dtypes(include=['int64']).copy().reset_index()\nint_df_train","732d2978":"int_df_train = int_df_train.fillna(0)\nint_df_train","e28b40f5":"float_df_train = df_train.select_dtypes(include=['float64']).copy().reset_index()\nfloat_df_train","77f34575":"float_df_train = float_df_train.fillna(0)\nfloat_df_train","53296b9e":"train = obj_df_train.merge(int_df_train, on=\"index\").merge(float_df_train, on=\"index\")\ntrain","951183bc":"obj_df_test = df_test.select_dtypes(include=['object']).copy().reset_index()\nobj_df_test","0ee8277d":"obj_df_test = obj_df_test.fillna(\"Not Listed\")\nobj_df_test","f3c5ee44":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nobj_df_test = obj_df_test.apply(le.fit_transform)\nobj_df_test","e04c4624":"int_df_test = df_test.select_dtypes(include=['int64']).copy().reset_index()\nint_df_test","cefd8925":"int_df_test = int_df_test.fillna(0)\nint_df_test","49c0e0f0":"float_df_test = df_test.select_dtypes(include=['float64']).copy().reset_index()\nfloat_df_test","232b3409":"float_df_test = float_df_test.fillna(0)\nfloat_df_test","b1627304":"test = obj_df_test.merge(int_df_test, on=\"index\").merge(float_df_test, on=\"index\")\ntest","c91a712f":"# checking for any null value left\ntrain.isnull().sum().sum(), test.isnull().sum().sum()","57f61d76":"id = test.Id\n\ny = train.SalePrice.values\nX = train.drop(['Id','index',  'SalePrice'], axis = 1)\nX_test = test.drop(['Id', 'index'], axis = 1)","4bffc4e4":"from sklearn.model_selection import train_test_split\n\n# Split into validation and training data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1)\nX_train.shape, X_val.shape, y_train.shape,y_val.shape, X_test.shape","e040f5c0":"# Import `StandardScaler` from `sklearn.preprocessing`\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# Define the scaler \nscaler = StandardScaler().fit(X_train)\n# Scale the train set\nX_train = scaler.transform(X_train)\n# Scale the validation set\nX_val = scaler.transform(X_val)\n# Scale the test set\nX_test = scaler.transform(X_test)","f497b821":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15),random_state=1,n_estimators=1000, loss='exponential').fit(X_train, y_train)\nprint(model.score(X_train, y_train))","3379b05c":"y_pred = model.predict(X_val)\ny_pred = y_pred.astype(int)\nprint(model.score(X_val, y_val))","99597f2b":"from sklearn.metrics import mean_squared_error\n\nrmse = mean_squared_error(y_val, y_pred, squared=False)\nrmse","a37c8fac":"final_labels = model.predict(X_test)\nfinal_labels[final_labels < 0] = 0\nfinal_labels = final_labels.astype(int)\nfinal_labels","9a9f948f":"final_result = pd.DataFrame({'Id': id, 'SalePrice': final_labels})","5601503f":"final_result.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","6560df52":"#upload submission\nsubmission = pd.read_csv(\"submission.csv\")\nsubmission","7b5d46c9":"Predict on validation set","8e5c4efc":"Graph of SalePrice","8d2b8931":"Predict on test set","8e76185a":"Import libraries","ba95ae40":"Problem statement","25fc0e39":"Scaler","42b20018":"Submit predictions","39705748":"Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\nAcknowledgments\n\nThe Ames Housing dataset was compiled by Dean De Cock for use in data science education. It's an incredible alternative for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset.","1272f514":"Load and read csv files","5604dc09":"Impute missing","b0b51ad3":"Split X for training and validation","ab926ac9":"Define model","49816bff":"Check for null values","8df7bce0":"Prepare submission","ed7ebe8a":"Define X, y and X_test"}}