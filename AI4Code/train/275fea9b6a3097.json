{"cell_type":{"ae807b88":"code","e98a7ed9":"code","763d1364":"code","65e40bdb":"code","db1dc944":"code","411ab6b9":"code","8de27b86":"code","517ca847":"code","96f00557":"code","751b9a44":"code","76f28301":"code","10f339bd":"code","0210d72b":"code","68e71858":"code","9ffcfc21":"code","05b255fb":"code","58e355c9":"code","d1c7b608":"code","e6737689":"code","78489bb7":"code","7cf0e0f1":"code","33a65015":"code","fda9adf9":"code","2fb5ae76":"code","63c873a3":"code","2660fc79":"code","d8d7a9d0":"code","b414117a":"code","06249b4e":"code","6bcd3cb4":"code","ff10af03":"code","af5e92f7":"code","123d94a4":"code","bc2f1470":"code","15d864d4":"code","e543192c":"code","30cb5e5f":"code","7acc56a3":"code","9e05d43f":"code","b3ff9ab4":"code","4fd17fb4":"code","22a2a338":"code","2648d679":"code","f9a45530":"code","2052e1be":"code","a779fadf":"code","467d1628":"code","8e539f53":"code","2a87c9a5":"code","c49002a4":"code","d56388fb":"code","9c66153f":"code","12b40f4e":"code","ef99e3ef":"code","dd0bf1a4":"code","1ecc09d3":"code","c9ecd949":"code","493356db":"code","a07aa84b":"code","d045587d":"code","ab642d41":"code","a6fb8989":"code","a2de1803":"code","14d46a1f":"code","3be0dce9":"code","6a171658":"code","7ea35486":"code","d53c7a63":"code","4db57679":"code","e2720333":"code","55c340de":"code","88afee4b":"code","fff918d5":"code","a9a7120f":"code","86a4b113":"code","f1f0016e":"code","fbdcf1c5":"code","af2e1d80":"code","01f19359":"code","e0c2600c":"code","7d89420e":"code","2ec6adae":"code","13e389ef":"code","81664387":"code","58e2d3d0":"code","477928a8":"code","c4e0d7a7":"code","3c211ce2":"code","87b53d04":"code","16bc4fa5":"code","2cec9ac1":"code","6f4fe952":"code","f1dd4320":"code","a1aebd41":"code","ae19569f":"code","b60635db":"code","7554423d":"code","1f49440c":"code","9e8a9390":"code","4a363c7f":"code","6141c06f":"code","4173b183":"code","40b25012":"code","c95fda00":"code","65a965e6":"code","c2268a13":"code","e057d1d0":"code","5fbbb374":"code","fd1e61cc":"code","915145cd":"code","bfb1e258":"code","cb13a2d6":"code","cb8f2260":"code","9f0f8407":"code","a7ce4db2":"code","b35f616b":"markdown","25336c7a":"markdown","e6bec1b3":"markdown","180818a4":"markdown","3c19f345":"markdown","0f929fcc":"markdown","6b45a00f":"markdown","3608554d":"markdown","9e67ec6b":"markdown","c5b432eb":"markdown","ca61cbf5":"markdown","bef4dc5b":"markdown","15199223":"markdown","75422624":"markdown","b5d61914":"markdown","7af049e0":"markdown","405e9a19":"markdown","e5d45248":"markdown","cc1dec63":"markdown","1133dafd":"markdown","4d84a2a8":"markdown","33206432":"markdown","6a6990a0":"markdown","a58a9ca9":"markdown","e403ed61":"markdown","8ea61634":"markdown","90de8802":"markdown","d9653791":"markdown","7784b9bb":"markdown","15b7017a":"markdown","642f6615":"markdown","5346aa7a":"markdown","1ec58146":"markdown","493effc1":"markdown","cee21a31":"markdown","af853e36":"markdown","5d9bfbad":"markdown","cfe4833f":"markdown","c8b5d099":"markdown","2aa21b7f":"markdown","5dbe6352":"markdown","733fac5c":"markdown","b70a016c":"markdown","a3146df1":"markdown","b8ff7000":"markdown","fb80df5b":"markdown","244620b4":"markdown","653705b5":"markdown"},"source":{"ae807b88":"%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom nltk.stem.porter import PorterStemmer\n\nimport re\n# Tutorial about Python regular expressions: https:\/\/pymotw.com\/2\/re\/\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nimport pickle\n\nfrom tqdm import tqdm\nimport os","e98a7ed9":"# using SQLite Table to read data.\ncon = sqlite3.connect('..\/input\/database.sqlite') \n\n# filtering only positive and negative reviews i.e. \n# not taking into consideration those reviews with Score=3\n# SELECT * FROM Reviews WHERE Score != 3 LIMIT 500000, will give top 500000 data points\n# you can change the number to any other number based on your computing power\n\n# filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 LIMIT 500000\"\"\", con) \n# for tsne assignment you can take 5k data points\n\nfiltered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3\"\"\", con) \n\n# Give reviews with Score>3 a positive rating(1), and reviews with a score<3 a negative rating(0).\ndef partition(x):\n    if x < 3:\n        return 0\n    return 1\n\n#changing reviews with score less than 3 to be positive and vice-versa\nactualScore = filtered_data['Score']\npositiveNegative = actualScore.map(partition) \nfiltered_data['Score'] = positiveNegative\nprint(\"Number of data points in our data\", filtered_data.shape)\nfiltered_data.head(3)","763d1364":"display = pd.read_sql_query(\"\"\"\nSELECT UserId, ProductId, ProfileName, Time, Score, Text, COUNT(*)\nFROM Reviews\nGROUP BY UserId\nHAVING COUNT(*)>1\n\"\"\", con)","65e40bdb":"print(display.shape)\ndisplay.head()","db1dc944":"display[display['UserId']=='AZY10LLTJ71NX']","411ab6b9":"display['COUNT(*)'].sum()","8de27b86":"display= pd.read_sql_query(\"\"\"\nSELECT *\nFROM Reviews\nWHERE Score != 3 AND UserId=\"AR5J8UI46CURR\"\nORDER BY ProductID\n\"\"\", con)\ndisplay.head()","517ca847":"#Sorting data according to ProductId in ascending order\nsorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')","96f00557":"#Deduplication of entries\nfinal=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\nfinal.shape","751b9a44":"#Checking to see how much % of data still remains\n(final['Id'].size*1.0)\/(filtered_data['Id'].size*1.0)*100","76f28301":"display= pd.read_sql_query(\"\"\"\nSELECT *\nFROM Reviews\nWHERE Score != 3 AND Id=44737 OR Id=64422\nORDER BY ProductID\n\"\"\", con)\n\ndisplay.head()","10f339bd":"final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]","0210d72b":"#Before starting the next phase of preprocessing lets see the number of entries left\nprint(final.shape)\n\n#How many positive and negative reviews are present in our dataset?\nfinal['Score'].value_counts()","68e71858":"# printing some random reviews\nsent_0 = final['Text'].values[0]\nprint(sent_0)\nprint(\"=\"*50)\n\nsent_1000 = final['Text'].values[1000]\nprint(sent_1000)\nprint(\"=\"*50)\n\nsent_1500 = final['Text'].values[1500]\nprint(sent_1500)\nprint(\"=\"*50)\n\nsent_4900 = final['Text'].values[4900]\nprint(sent_4900)\nprint(\"=\"*50)","9ffcfc21":"# remove urls from text python: https:\/\/stackoverflow.com\/a\/40823105\/4084039\nsent_0 = re.sub(r\"http\\S+\", \"\", sent_0)\nsent_1000 = re.sub(r\"http\\S+\", \"\", sent_1000)\nsent_150 = re.sub(r\"http\\S+\", \"\", sent_1500)\nsent_4900 = re.sub(r\"http\\S+\", \"\", sent_4900)\n\nprint(sent_0)","05b255fb":"# https:\/\/stackoverflow.com\/questions\/16206380\/python-beautifulsoup-how-to-remove-all-tags-from-an-element\nfrom bs4 import BeautifulSoup\n\nsoup = BeautifulSoup(sent_0, 'lxml')\ntext = soup.get_text()\nprint(text)\nprint(\"=\"*50)\n\nsoup = BeautifulSoup(sent_1000, 'lxml')\ntext = soup.get_text()\nprint(text)\nprint(\"=\"*50)\n\nsoup = BeautifulSoup(sent_1500, 'lxml')\ntext = soup.get_text()\nprint(text)\nprint(\"=\"*50)\n\nsoup = BeautifulSoup(sent_4900, 'lxml')\ntext = soup.get_text()\nprint(text)","58e355c9":"# https:\/\/stackoverflow.com\/a\/47091490\/4084039\nimport re\n\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","d1c7b608":"sent_1500 = decontracted(sent_1500)\nprint(sent_1500)\nprint(\"=\"*50)","e6737689":"#remove words with numbers python: https:\/\/stackoverflow.com\/a\/18082370\/4084039\nsent_0 = re.sub(\"\\S*\\d\\S*\", \"\", sent_0).strip()\nprint(sent_0)","78489bb7":"#remove spacial character: https:\/\/stackoverflow.com\/a\/5843547\/4084039\nsent_1500 = re.sub('[^A-Za-z0-9]+', ' ', sent_1500)\nprint(sent_1500)","7cf0e0f1":"# https:\/\/gist.github.com\/sebleier\/554280\n# we are removing the words from the stop words list: 'no', 'nor', 'not'\n# <br \/><br \/> ==> after the above steps, we are getting \"br br\"\n# we are including them into stop words list\n# instead of <br \/> if we have <br\/> these tags would have revmoved in the 1st step\n\nstopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"])","33a65015":"# Combining all the above stundents \nfrom tqdm import tqdm\npreprocessed_reviews = []\n# tqdm is for printing the status bar\nfor sentance in tqdm(final['Text'].values):\n    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n    sentance = decontracted(sentance)\n    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n    # https:\/\/gist.github.com\/sebleier\/554280\n    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n    preprocessed_reviews.append(sentance.strip())","fda9adf9":"preprocessed_reviews[1500]","2fb5ae76":"final['cleaned_text']=preprocessed_reviews","63c873a3":"data_pos = final[final[\"Score\"] == 1].sample(n = 10000)\ndata_neg = final[final[\"Score\"] == 0].sample(n = 10000)\nfinal1 = pd.concat([data_pos, data_neg])\nfinal1.shape","2660fc79":"Y = final1['Score'].values\nX = final1['cleaned_text'].values\nprint(Y.shape)\nprint(type(Y))\nprint(X.shape)\nprint(type(X))","d8d7a9d0":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=12)\nX_train,X_cv,Y_train,Y_cv=train_test_split(X_train,Y_train,test_size=0.2,random_state=12)\nprint('='*100)\nprint(\"After splitting\")\nprint(X_train.shape,Y_train.shape)\nprint(X_cv.shape,Y_cv.shape)\nprint(X_test.shape,Y_test.shape)","b414117a":"vectorizer=CountVectorizer()\nvectorizer=vectorizer.fit(X_train)\nX_train_bow=vectorizer.transform(X_train)\nX_cv_bow=vectorizer.transform(X_cv)\nX_test_bow=vectorizer.transform(X_test)\nprint('='*100)\nprint(\"After transform\")\nprint(X_train_bow.shape,Y_train.shape)\nprint(X_cv_bow.shape,Y_cv.shape)\nprint(X_test_bow.shape,Y_cv.shape)","06249b4e":"print(Y_train.shape)\nprint(Y_cv.shape)","6bcd3cb4":"train_auc = []\ncv_auc = []\nK = list(range(1, 150, 10))\nfor i in tqdm(K):\n    neigh = KNeighborsClassifier(n_neighbors=i, algorithm='brute')\n    neigh.fit(X_train_bow, Y_train)\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n    # not the predicted outputs\n    Y_train_pred =  neigh.predict_proba(X_train_bow)[:,1]\n    Y_cv_pred =  neigh.predict_proba(X_cv_bow)[:,1]\n    \n    train_auc.append(roc_auc_score(Y_train,Y_train_pred))\n    cv_auc.append(roc_auc_score(Y_cv, Y_cv_pred))\n\nplt.plot(K, train_auc, label='Train AUC')\nplt.scatter(K, train_auc, label='Train AUC')\nplt.plot(K, cv_auc, label='CV AUC')\nplt.scatter(K, cv_auc, label='CV AUC')\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","ff10af03":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nneighbors = list(range(80, 100, 2))\ncv_score = []\nfor k in tqdm(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n    scores = cross_val_score(knn, X_train_bow, Y_train, cv=10, scoring='accuracy')\n    cv_score.append(scores.mean())","af5e92f7":"MSE = [1 - x for x in cv_score]\noptimal_k1 = neighbors[MSE.index(min(MSE))]\nprint(\"_\" * 101)\nprint(\"Optimal number of neighbors: \", optimal_k1)\nprint(\"_\" * 101)\nprint(\"Missclassification error for each k values: \", np.round(MSE, 3))\nprint(\"_\" * 101)\n\nplt.plot(neighbors, MSE)\nplt.title(\"Number of neighbors and error\")\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Missclassification error\")\nplt.show()","123d94a4":"optimal_model = KNeighborsClassifier(n_neighbors=optimal_k1,algorithm='brute')\noptimal_model.fit(X_train_bow, Y_train)\nprediction = optimal_model.predict(X_test_bow)","bc2f1470":"train_fpr, train_tpr, thresholds = roc_curve(Y_train, optimal_model.predict_proba(X_train_bow)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(Y_test, optimal_model.predict_proba(X_test_bow)[:,1])\nAUC1=str(auc(test_fpr, test_tpr))\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","15d864d4":"training_accuracy = optimal_model.score(X_train_bow, Y_train)\ntraining_error = 1 - training_accuracy\ntest_accuracy = accuracy_score(Y_test, prediction)\ntest_error = 1 - test_accuracy\n\n\nprint(\"_\" * 101)\nprint(\"Training Accuracy: \", training_accuracy)\nprint(\"Train Error: \", training_error)\nprint(\"Test Accuracy: \", test_accuracy)\nprint(\"Test Error: \", test_error)\nprint(\"_\" * 101)","e543192c":"import seaborn as sb\nconf_matrix = confusion_matrix(Y_test, optimal_model.predict(X_test_bow))\nclass_label = [0, 1]\ndf_conf_matrix = pd.DataFrame(\n    conf_matrix, index=class_label, columns=class_label)\nsb.heatmap(df_conf_matrix, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\nprint(\"_\" * 101)","30cb5e5f":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test, prediction))","7acc56a3":"# Please write all the code with proper documentation\ntf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=5)\ntf_idf_vect.fit(X_train)\nX_train_tfidf= tf_idf_vect.transform(X_train)\nX_cv_tfidf=tf_idf_vect.transform(X_cv)\nX_test_tfidf=tf_idf_vect.transform(X_test)","9e05d43f":"train_auc = []\ncv_auc = []\nK = list(range(1, 400, 10))\nfor i in tqdm(K):\n    neigh = KNeighborsClassifier(n_neighbors=i, algorithm='brute')\n    neigh.fit(X_train_tfidf, Y_train)\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n    # not the predicted outputs\n    Y_train_pred =  neigh.predict_proba(X_train_tfidf)[:,1]\n    Y_cv_pred =  neigh.predict_proba(X_cv_tfidf)[:,1]\n    \n    train_auc.append(roc_auc_score(Y_train,Y_train_pred))\n    cv_auc.append(roc_auc_score(Y_cv, Y_cv_pred))\n\nplt.plot(K, train_auc, label='Train AUC')\nplt.scatter(K, train_auc, label='Train AUC')\nplt.plot(K, cv_auc, label='CV AUC')\nplt.scatter(K, cv_auc, label='CV AUC')\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","b3ff9ab4":"neighbors = list(range(151, 400,10))\ncv_score = []\nfor k in tqdm(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n    scores = cross_val_score(knn, X_train_tfidf, Y_train, cv=10, scoring='accuracy')\n    cv_score.append(scores.mean())","4fd17fb4":"MSE = [1 - x for x in cv_score]\noptimal_k2 = neighbors[MSE.index(min(MSE))]\nprint(\"_\" * 101)\nprint(\"Optimal number of neighbors: \", optimal_k2)\nprint(\"_\" * 101)\nprint(\"Missclassification error for each k values: \", np.round(MSE, 3))\nprint(\"_\" * 101)\n\nplt.plot(neighbors, MSE)\nplt.title(\"Number of neighbors and error\")\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Missclassification error\")\nplt.show()","22a2a338":"optimal_model = KNeighborsClassifier(n_neighbors=optimal_k2, algorithm='brute')\noptimal_model.fit(X_train_tfidf, Y_train)\nprediction = optimal_model.predict(X_test_tfidf)","2648d679":"train_fpr, train_tpr, thresholds = roc_curve(Y_train, optimal_model.predict_proba(X_train_tfidf)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(Y_test, optimal_model.predict_proba(X_test_tfidf)[:,1])\nAUC2=str(auc(test_fpr, test_tpr))\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","f9a45530":"training_accuracy = optimal_model.score(X_train_tfidf, Y_train)\ntraining_error = 1 - training_accuracy\ntest_accuracy = accuracy_score(Y_test, prediction)\ntest_error = 1 - test_accuracy\n\n\nprint(\"_\" * 101)\nprint(\"Training Accuracy: \", training_accuracy)\nprint(\"Train Error: \", training_error)\nprint(\"Test Accuracy: \", test_accuracy)\nprint(\"Test Error: \", test_error)\nprint(\"_\" * 101)","2052e1be":"import seaborn as sb\nconf_matrix = confusion_matrix(Y_test, optimal_model.predict(X_test_tfidf))\nclass_label = [0, 1]\ndf_conf_matrix = pd.DataFrame(\n    conf_matrix, index=class_label, columns=class_label)\nsb.heatmap(df_conf_matrix, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\nprint(\"_\" * 101)","a779fadf":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test, prediction))","467d1628":"# Please write all the code with proper documentation\ni=0\nlist_of_sentance_train=[]\nfor sentance in X_train:\n    list_of_sentance_train.append(sentance.split())\n\n# this line of code trains your w2v model on the give list of sentances\nw2v_model=Word2Vec(list_of_sentance_train,min_count=5,size=50, workers=4)\n\nw2v_words = list(w2v_model.wv.vocab)\nprint(\"number of words that occured minimum 5 times \",len(w2v_words))\nprint(\"sample words \", w2v_words[0:50])","8e539f53":"# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors_train = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in tqdm(list_of_sentance_train): # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    sent_vectors_train.append(sent_vec)\nsent_vectors_train = np.array(sent_vectors_train)\nprint(sent_vectors_train.shape)\nprint(sent_vectors_train[0])","2a87c9a5":"i=0\nlist_of_sentance_cv=[]\nfor sentance in X_cv:\n    list_of_sentance_cv.append(sentance.split())\n# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors_cv = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in tqdm(list_of_sentance_cv): # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    sent_vectors_cv.append(sent_vec)\nsent_vectors_cv = np.array(sent_vectors_cv)\nprint(sent_vectors_cv.shape)\nprint(sent_vectors_cv[0])","c49002a4":"i=0\nlist_of_sentance_test=[]\nfor sentance in X_test:\n    list_of_sentance_test.append(sentance.split())\n# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors_test = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in tqdm(list_of_sentance_test): # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    sent_vectors_test.append(sent_vec)\nsent_vectors_test = np.array(sent_vectors_test)\nprint(sent_vectors_test.shape)\nprint(sent_vectors_test[0])","d56388fb":"train_auc = []\ncv_auc = []\nK = list(range(1,150,10))\nfor i in K:\n    neigh = KNeighborsClassifier(n_neighbors=i, algorithm='brute')\n    neigh.fit(sent_vectors_train, Y_train)\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n    # not the predicted outputs\n    Y_train_pred =  neigh.predict_proba(sent_vectors_train)[:,1]\n    Y_cv_pred =  neigh.predict_proba(sent_vectors_cv)[:,1]\n    \n    train_auc.append(roc_auc_score(Y_train,Y_train_pred))\n    cv_auc.append(roc_auc_score(Y_cv, Y_cv_pred))\n\nplt.plot(K, train_auc, label='Train AUC')\nplt.scatter(K, train_auc, label='Train AUC')\nplt.plot(K, cv_auc, label='CV AUC')\nplt.scatter(K, cv_auc, label='CV AUC')\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","9c66153f":"neighbors = list(range(31,45, 2))\ncv_score = []\nfor k in tqdm(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n    scores = cross_val_score(knn, sent_vectors_train, Y_train, cv=10, scoring='f1')\n    cv_score.append(scores.mean())","12b40f4e":"MSE = [1 - x for x in cv_score]\noptimal_k3 = neighbors[MSE.index(min(MSE))]\nprint(\"_\" * 101)\nprint(\"Optimal number of neighbors: \", optimal_k3)\nprint(\"_\" * 101)\nprint(\"Missclassification error for each k values: \", np.round(MSE, 3))\nprint(\"_\" * 101)\n\nplt.plot(neighbors, MSE)\nplt.title(\"Number of neighbors and error\")\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Missclassification error\")\nplt.show()","ef99e3ef":"optimal_model = KNeighborsClassifier(n_neighbors=optimal_k3, algorithm='brute')\noptimal_model.fit(sent_vectors_train, Y_train)\nprediction = optimal_model.predict(sent_vectors_test)","dd0bf1a4":"train_fpr, train_tpr, thresholds = roc_curve(Y_train, optimal_model.predict_proba(sent_vectors_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(Y_test, optimal_model.predict_proba(sent_vectors_test)[:,1])\nAUC3=str(auc(test_fpr, test_tpr))\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","1ecc09d3":"training_accuracy = optimal_model.score(sent_vectors_train, Y_train)\ntraining_error = 1 - training_accuracy\ntest_accuracy = accuracy_score(Y_test, prediction)\ntest_error = 1 - test_accuracy\n\n\nprint(\"_\" * 101)\nprint(\"Training Accuracy: \", training_accuracy)\nprint(\"Train Error: \", training_error)\nprint(\"Test Accuracy: \", test_accuracy)\nprint(\"Test Error: \", test_error)\nprint(\"_\" * 101)","c9ecd949":"import seaborn as sb\nconf_matrix = confusion_matrix(Y_test, optimal_model.predict(sent_vectors_test))\nclass_label = [0, 1]\ndf_conf_matrix = pd.DataFrame(\n    conf_matrix, index=class_label, columns=class_label)\nsb.heatmap(df_conf_matrix, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\nprint(\"_\" * 101)","493356db":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test, prediction))","a07aa84b":"# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\nmodel = TfidfVectorizer()\ntf_idf_matrix = model.fit(X_train)\n# we are converting a dictionary with word as a key, and the idf as a value\ndictionary = dict(zip(model.get_feature_names(), list(model.idf_)))","d045587d":"# TF-IDF weighted Word2Vec\ni=0\nlist_of_sentance_train=[]\nfor sentance in X_train:\n    list_of_sentance_train.append(sentance.split())\ntfidf_feat = tf_idf_vect.get_feature_names() # tfidf words\/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors_train = []; # the tfidf-w2v for each sentence\/review is stored in this list\nrow=0;\nfor sent in tqdm(list_of_sentance_train): # for each review\/sentence \n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words and word in tfidf_feat:\n            vec = w2v_model.wv[word]\n#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n            # to reduce the computation we are \n            # dictionary[word] = idf value of word in whole courpus\n            # sent.count(word) = tf valeus of word in this review\n            tf_idf = dictionary[word]*(sent.count(word)\/len(sent))\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n    if weight_sum != 0:\n        sent_vec \/= weight_sum\n    tfidf_sent_vectors_train.append(sent_vec)\n    row += 1","ab642d41":"# TF-IDF weighted Word2Vec\ni=0\nlist_of_sentance_cv=[]\nfor sentance in X_cv:\n    list_of_sentance_cv.append(sentance.split())\ntfidf_feat = tf_idf_vect.get_feature_names() # tfidf words\/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors_cv = []; # the tfidf-w2v for each sentence\/review is stored in this list\nrow=0;\nfor sent in tqdm(list_of_sentance_cv): # for each review\/sentence \n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words and word in tfidf_feat:\n            vec = w2v_model.wv[word]\n#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n            # to reduce the computation we are \n            # dictionary[word] = idf value of word in whole courpus\n            # sent.count(word) = tf valeus of word in this review\n            tf_idf = dictionary[word]*(sent.count(word)\/len(sent))\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n    if weight_sum != 0:\n        sent_vec \/= weight_sum\n    tfidf_sent_vectors_cv.append(sent_vec)\n    row += 1","a6fb8989":"# TF-IDF weighted Word2Vec\ni=0\nlist_of_sentance_test=[]\nfor sentance in X_test:\n    list_of_sentance_test.append(sentance.split())\ntfidf_feat = tf_idf_vect.get_feature_names() # tfidf words\/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors_test = []; # the tfidf-w2v for each sentence\/review is stored in this list\nrow=0;\nfor sent in tqdm(list_of_sentance_test): # for each review\/sentence \n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words and word in tfidf_feat:\n            vec = w2v_model.wv[word]\n#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n            # to reduce the computation we are \n            # dictionary[word] = idf value of word in whole courpus\n            # sent.count(word) = tf valeus of word in this review\n            tf_idf = dictionary[word]*(sent.count(word)\/len(sent))\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n    if weight_sum != 0:\n        sent_vec \/= weight_sum\n    tfidf_sent_vectors_test.append(sent_vec)\n    row += 1","a2de1803":"train_auc = []\ncv_auc = []\nK = list(range(1,150,10))\nfor i in K:\n    neigh = KNeighborsClassifier(n_neighbors=i, algorithm='brute')\n    neigh.fit(tfidf_sent_vectors_train, Y_train)\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n    # not the predicted outputs\n    Y_train_pred =  neigh.predict_proba(tfidf_sent_vectors_train)[:,1]\n    Y_cv_pred =  neigh.predict_proba(tfidf_sent_vectors_cv)[:,1]\n    \n    train_auc.append(roc_auc_score(Y_train,Y_train_pred))\n    cv_auc.append(roc_auc_score(Y_cv, Y_cv_pred))\n\nplt.plot(K, train_auc, label='Train AUC')\nplt.scatter(K, train_auc, label='Train AUC')\nplt.plot(K, cv_auc, label='CV AUC')\nplt.scatter(K, cv_auc, label='CV AUC')\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","14d46a1f":"neighbors = list(range(21, 50, 2))\ncv_score = []\nfor k in tqdm(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n    scores = cross_val_score(knn, tfidf_sent_vectors_train, Y_train, cv=10, scoring='f1')\n    cv_score.append(scores.mean())  ","3be0dce9":"MSE = [1 - x for x in cv_score]\noptimal_k4 = neighbors[MSE.index(min(MSE))]\nprint(\"_\" * 101)\nprint(\"Optimal number of neighbors: \", optimal_k4)\nprint(\"_\" * 101)\nprint(\"Missclassification error for each k values: \", np.round(MSE, 3))\nprint(\"_\" * 101)\n\nplt.plot(neighbors, MSE)\nplt.title(\"Number of neighbors and error\")\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Missclassification error\")\nplt.show()","6a171658":"optimal_model = KNeighborsClassifier(n_neighbors=optimal_k4, algorithm='brute')\noptimal_model.fit(tfidf_sent_vectors_train, Y_train)\nprediction = optimal_model.predict(tfidf_sent_vectors_test)","7ea35486":"train_fpr, train_tpr, thresholds = roc_curve(Y_train, optimal_model.predict_proba(tfidf_sent_vectors_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(Y_test, optimal_model.predict_proba(tfidf_sent_vectors_test)[:,1])\nAUC4=str(auc(test_fpr, test_tpr))\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","d53c7a63":"training_accuracy = optimal_model.score(tfidf_sent_vectors_train, Y_train)\ntraining_error = 1 - training_accuracy\ntest_accuracy = accuracy_score(Y_test, prediction)\ntest_error = 1 - test_accuracy\n\n\nprint(\"_\" * 101)\nprint(\"Training Accuracy: \", training_accuracy)\nprint(\"Train Error: \", training_error)\nprint(\"Test Accuracy: \", test_accuracy)\nprint(\"Test Error: \", test_error)\nprint(\"_\" * 101)\n\nimport seaborn as sb","4db57679":"conf_matrix = confusion_matrix(Y_test, optimal_model.predict(tfidf_sent_vectors_test))\nclass_label = [0, 1]\ndf_conf_matrix = pd.DataFrame(\n    conf_matrix, index=class_label, columns=class_label)\nsb.heatmap(df_conf_matrix, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\nprint(\"_\" * 101)","e2720333":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test, prediction))","55c340de":"data_pos1 = final[final[\"Score\"] == 1].sample(n = 1000)\ndata_neg1 = final[final[\"Score\"] == 0].sample(n = 1000)\nfinal2 = pd.concat([data_pos1, data_neg1])\nfinal2.shape\n\nA = final2['cleaned_text'].values\nB = final2['Score'].values\nprint(A.shape)\nprint(type(B))\nprint(B.shape)\nprint(type(B))","88afee4b":"A_train,A_test,B_train,B_test=train_test_split(A,B,test_size=0.2,random_state=12)\nA_train,A_cv,B_train,B_cv=train_test_split(A_train,B_train,test_size=0.2,random_state=12)\nprint('='*100)\nprint(\"After splitting\")\nprint(A_train.shape,B_train.shape)\nprint(A_cv.shape,B_cv.shape)\nprint(A_test.shape,B_test.shape)","fff918d5":"vectorizer=CountVectorizer(min_df=10, max_features=500)\nvectorizer=vectorizer.fit(A_train)\nA_train_bow_kdtree=vectorizer.transform(A_train)\nA_cv_bow_kdtree=vectorizer.transform(A_cv)\nA_test_bow_kdtree=vectorizer.transform(A_test)\nprint('='*100)\nprint(\"After transform\")\nprint(A_train_bow_kdtree.shape,B_train.shape)\nprint(A_cv_bow_kdtree.shape,B_cv.shape)\nprint(A_test_bow_kdtree.shape,B_cv.shape)","a9a7120f":"train_auc = []\ncv_auc = []\nK = list(range(1,200,10))\nfor i in K:\n    neigh = KNeighborsClassifier(n_neighbors=i, algorithm='kd_tree')\n    neigh.fit(A_train_bow_kdtree.todense(), B_train)\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n    # not the predicted outputs\n    B_train_pred =  neigh.predict_proba(A_train_bow_kdtree.todense())[:,1]\n    B_cv_pred =  neigh.predict_proba(A_cv_bow_kdtree.todense())[:,1]\n    \n    train_auc.append(roc_auc_score(B_train,B_train_pred))\n    cv_auc.append(roc_auc_score(B_cv, B_cv_pred))\n\nplt.plot(K, train_auc, label='Train AUC')\nplt.scatter(K, train_auc, label='Train AUC')\nplt.plot(K, cv_auc, label='CV AUC')\nplt.scatter(K, cv_auc, label='CV AUC')\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","86a4b113":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nneighbors = list(range(31, 71, 2))\ncv_score = []\nfor k in tqdm(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n    scores = cross_val_score(knn, A_train_bow_kdtree.todense(), B_train, cv=10, scoring='accuracy')\n    cv_score.append(scores.mean())","f1f0016e":"MSE = [1 - x for x in cv_score]\noptimal_k5 = neighbors[MSE.index(min(MSE))]\nprint(\"_\" * 101)\nprint(\"Optimal number of neighbors: \", optimal_k5)\nprint(\"_\" * 101)\nprint(\"Missclassification error for each k values: \", np.round(MSE, 3))\nprint(\"_\" * 101)\n\nplt.plot(neighbors, MSE)\nplt.title(\"Number of neighbors and error\")\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Missclassification error\")\nplt.show()","fbdcf1c5":"optimal_model = KNeighborsClassifier(n_neighbors=optimal_k5,algorithm='kd_tree')\noptimal_model.fit(A_train_bow_kdtree.todense(), B_train)\nprediction = optimal_model.predict(A_test_bow_kdtree.todense())","af2e1d80":"train_fpr, train_tpr, thresholds = roc_curve(B_train, optimal_model.predict_proba(A_train_bow_kdtree.todense())[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(B_test, optimal_model.predict_proba(A_test_bow_kdtree.todense())[:,1])\nAUC5=str(auc(test_fpr, test_tpr))\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","01f19359":"training_accuracy = optimal_model.score(A_train_bow_kdtree.todense(), B_train)\ntraining_error = 1 - training_accuracy\ntest_accuracy = accuracy_score(B_test, prediction)\ntest_error = 1 - test_accuracy\n\n\nprint(\"_\" * 101)\nprint(\"Training Accuracy: \", training_accuracy)\nprint(\"Train Error: \", training_error)\nprint(\"Test Accuracy: \", test_accuracy)\nprint(\"Test Error: \", test_error)\nprint(\"_\" * 101)","e0c2600c":"import seaborn as sb\nconf_matrix = confusion_matrix(B_test, optimal_model.predict(A_test_bow_kdtree.todense()))\nclass_label = [0, 1]\ndf_conf_matrix = pd.DataFrame(\n    conf_matrix, index=class_label, columns=class_label)\nsb.heatmap(df_conf_matrix, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\nprint(\"_\" * 101)","7d89420e":"from sklearn.metrics import classification_report\nprint(classification_report(B_test, prediction))","2ec6adae":"tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=100)\ntf_idf_vect.fit(A_train)\nA_train_tfidf =tf_idf_vect.transform(A_train)\nA_cv_tfidf=tf_idf_vect.transform(A_cv)\nA_test_tfidf=tf_idf_vect.transform(A_test)\nprint(A_train_tfidf.shape)","13e389ef":"train_auc = []\ncv_auc = []\nK = list(range(1,200,10))\nfor i in K:\n    neigh = KNeighborsClassifier(n_neighbors=i, algorithm='kd_tree')\n    neigh.fit(A_train_tfidf.todense(), B_train)\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n    # not the predicted outputs\n    B_train_pred =  neigh.predict_proba(A_train_tfidf.todense())[:,1]\n    B_cv_pred =  neigh.predict_proba(A_cv_tfidf.todense())[:,1]\n    \n    train_auc.append(roc_auc_score(B_train,B_train_pred))\n    cv_auc.append(roc_auc_score(B_cv, B_cv_pred))\n\nplt.plot(K, train_auc, label='Train AUC')\nplt.scatter(K, train_auc, label='Train AUC')\nplt.plot(K, cv_auc, label='CV AUC')\nplt.scatter(K, cv_auc, label='CV AUC')\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","81664387":"from sklearn.metrics import accuracy_score\nneighbors = list(range(109,125,2))\ncv_score = []\nfor k in tqdm(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n    scores = cross_val_score(knn, A_train_tfidf.todense(), B_train, cv=3, scoring='accuracy')\n    cv_score.append(scores.mean())","58e2d3d0":"MSE = [1 - x for x in cv_score]\noptimal_k6 = neighbors[MSE.index(min(MSE))]\nprint(\"_\" * 101)\nprint(\"Optimal number of neighbors: \", optimal_k6)\nprint(\"_\" * 101)\nprint(\"Missclassification error for each k values: \", np.round(MSE, 3))\nprint(\"_\" * 101)\n\nplt.plot(neighbors, MSE)\nplt.title(\"Number of neighbors and error\")\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Missclassification error\")\nplt.show()","477928a8":"optimal_model = KNeighborsClassifier(n_neighbors=optimal_k6, algorithm='kd_tree')\noptimal_model.fit(A_train_tfidf.todense(), B_train)\nprediction = optimal_model.predict(A_test_tfidf.todense())","c4e0d7a7":"train_fpr, train_tpr, thresholds = roc_curve(B_train, optimal_model.predict_proba(A_train_tfidf.todense())[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(B_test, optimal_model.predict_proba(A_test_tfidf.todense())[:,1])\nAUC6=str(auc(test_fpr, test_tpr))\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","3c211ce2":"training_accuracy = optimal_model.score(A_train_tfidf.todense(), B_train)\ntraining_error = 1 - training_accuracy\ntest_accuracy = accuracy_score(B_test, prediction)\ntest_error = 1 - test_accuracy\n\n\nprint(\"_\" * 101)\nprint(\"Training Accuracy: \", training_accuracy)\nprint(\"Train Error: \", training_error)\nprint(\"Test Accuracy: \", test_accuracy)\nprint(\"Test Error: \", test_error)\nprint(\"_\" * 101)","87b53d04":"import seaborn as sb\nconf_matrix = confusion_matrix(B_test, optimal_model.predict(A_test_tfidf.todense()))\nclass_label = [0, 1]\ndf_conf_matrix = pd.DataFrame(\n    conf_matrix, index=class_label, columns=class_label)\nsb.heatmap(df_conf_matrix, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\nprint(\"_\" * 101)","16bc4fa5":"from sklearn.metrics import classification_report\nprint(classification_report(B_test, prediction))","2cec9ac1":"i=0\nlist_of_sentance_train=[]\nfor sentance in X_train:\n    list_of_sentance_train.append(sentance.split())\n\n# this line of code trains your w2v model on the give list of sentances\nw2v_model=Word2Vec(list_of_sentance_train,min_count=5,size=50, workers=4)\n\nw2v_words = list(w2v_model.wv.vocab)\nprint(\"number of words that occured minimum 5 times \",len(w2v_words))\nprint(\"sample words \", w2v_words[0:50])","6f4fe952":"# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors_train = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in tqdm(list_of_sentance_train): # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    sent_vectors_train.append(sent_vec)\nsent_vectors_train = np.array(sent_vectors_train)\nprint(sent_vectors_train.shape)\nprint(sent_vectors_train[0])","f1dd4320":"i=0\nlist_of_sentance_cv=[]\nfor sentance in X_cv:\n    list_of_sentance_cv.append(sentance.split())\n# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors_cv = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in tqdm(list_of_sentance_cv): # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    sent_vectors_cv.append(sent_vec)\nsent_vectors_cv = np.array(sent_vectors_cv)\nprint(sent_vectors_cv.shape)\nprint(sent_vectors_cv[0])","a1aebd41":"i=0\nlist_of_sentance_test=[]\nfor sentance in X_test:\n    list_of_sentance_test.append(sentance.split())\n# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors_test = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in tqdm(list_of_sentance_test): # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    sent_vectors_test.append(sent_vec)\nsent_vectors_test = np.array(sent_vectors_test)\nprint(sent_vectors_test.shape)\nprint(sent_vectors_test[0])","ae19569f":"train_auc = []\ncv_auc = []\nK = list(range(1,200,10))\nfor i in tqdm(K):\n    neigh = KNeighborsClassifier(n_neighbors=i, algorithm='kd_tree')\n    neigh.fit(sent_vectors_train, Y_train)\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n    # not the predicted outputs\n    Y_train_pred =  neigh.predict_proba(sent_vectors_train)[:,1]\n    Y_cv_pred =  neigh.predict_proba(sent_vectors_cv)[:,1]\n    \n    train_auc.append(roc_auc_score(Y_train,Y_train_pred))\n    cv_auc.append(roc_auc_score(Y_cv, Y_cv_pred))\n\nplt.plot(K, train_auc, label='Train AUC')\nplt.scatter(K, train_auc, label='Train AUC')\nplt.plot(K, cv_auc, label='CV AUC')\nplt.scatter(K, cv_auc, label='CV AUC')\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","b60635db":"neighbors = list(range(9,35,2))\ncv_score = []\nfor k in tqdm(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n    scores = cross_val_score(knn, sent_vectors_train, Y_train, cv=10, scoring='f1')\n    cv_score.append(scores.mean())","7554423d":"MSE = [1 - x for x in cv_score]\noptimal_k7 = neighbors[MSE.index(min(MSE))]\nprint(\"_\" * 101)\nprint(\"Optimal number of neighbors: \", optimal_k7)\nprint(\"_\" * 101)\nprint(\"Missclassification error for each k values: \", np.round(MSE, 3))\nprint(\"_\" * 101)\n\nplt.plot(neighbors, MSE)\nplt.title(\"Number of neighbors and error\")\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Missclassification error\")\nplt.show()","1f49440c":"optimal_model = KNeighborsClassifier(n_neighbors=optimal_k7, algorithm='kd_tree')\noptimal_model.fit(sent_vectors_train, Y_train)\nprediction = optimal_model.predict(sent_vectors_test)","9e8a9390":"train_fpr, train_tpr, thresholds = roc_curve(Y_train, neigh.predict_proba(sent_vectors_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(Y_test, neigh.predict_proba(sent_vectors_test)[:,1])\nAUC7=str(auc(test_fpr, test_tpr))\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","4a363c7f":"training_accuracy = optimal_model.score(sent_vectors_train, Y_train)\ntraining_error = 1 - training_accuracy\ntest_accuracy = accuracy_score(Y_test, prediction)\ntest_error = 1 - test_accuracy\n\n\nprint(\"_\" * 101)\nprint(\"Training Accuracy: \", training_accuracy)\nprint(\"Train Error: \", training_error)\nprint(\"Test Accuracy: \", test_accuracy)\nprint(\"Test Error: \", test_error)\nprint(\"_\" * 101)","6141c06f":"import seaborn as sb\nconf_matrix = confusion_matrix(Y_test, optimal_model.predict(sent_vectors_test))\nclass_label = [0, 1]\ndf_conf_matrix = pd.DataFrame(\n    conf_matrix, index=class_label, columns=class_label)\nsb.heatmap(df_conf_matrix, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\nprint(\"_\" * 101)","4173b183":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test, prediction))","40b25012":"# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\nmodel = TfidfVectorizer()\ntf_idf_matrix = model.fit(X_train)\n# we are converting a dictionary with word as a key, and the idf as a value\ndictionary = dict(zip(model.get_feature_names(), list(model.idf_)))","c95fda00":"# TF-IDF weighted Word2Vec\ni=0\nlist_of_sentance_train=[]\nfor sentance in X_train:\n    list_of_sentance_train.append(sentance.split())\ntfidf_feat = tf_idf_vect.get_feature_names() # tfidf words\/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors_train = []; # the tfidf-w2v for each sentence\/review is stored in this list\nrow=0;\nfor sent in tqdm(list_of_sentance_train): # for each review\/sentence \n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words and word in tfidf_feat:\n            vec = w2v_model.wv[word]\n#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n            # to reduce the computation we are \n            # dictionary[word] = idf value of word in whole courpus\n            # sent.count(word) = tf valeus of word in this review\n            tf_idf = dictionary[word]*(sent.count(word)\/len(sent))\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n    if weight_sum != 0:\n        sent_vec \/= weight_sum\n    tfidf_sent_vectors_train.append(sent_vec)\n    row += 1","65a965e6":"#TF-IDF weighted Word2Vec\ni=0\nlist_of_sentance_cv=[]\nfor sentance in X_cv:\n    list_of_sentance_cv.append(sentance.split())\ntfidf_feat = tf_idf_vect.get_feature_names() # tfidf words\/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors_cv = []; # the tfidf-w2v for each sentence\/review is stored in this list\nrow=0;\nfor sent in tqdm(list_of_sentance_cv): # for each review\/sentence \n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words and word in tfidf_feat:\n            vec = w2v_model.wv[word]\n            # tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n            # to reduce the computation we are \n            # dictionary[word] = idf value of word in whole courpus\n            # sent.count(word) = tf valeus of word in this review\n            tf_idf = dictionary[word]*(sent.count(word)\/len(sent))\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n    if weight_sum != 0:\n        sent_vec \/= weight_sum\n    tfidf_sent_vectors_cv.append(sent_vec)\n    row += 1","c2268a13":"# TF-IDF weighted Word2Vec\ni=0\nlist_of_sentance_test=[]\nfor sentance in X_test:\n    list_of_sentance_test.append(sentance.split())\ntfidf_feat = tf_idf_vect.get_feature_names() # tfidf words\/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors_test = []; # the tfidf-w2v for each sentence\/review is stored in this list\nrow=0;\nfor sent in tqdm(list_of_sentance_test): # for each review\/sentence \n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words and word in tfidf_feat:\n            vec = w2v_model.wv[word]\n#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n            # to reduce the computation we are \n            # dictionary[word] = idf value of word in whole courpus\n            # sent.count(word) = tf valeus of word in this review\n            tf_idf = dictionary[word]*(sent.count(word)\/len(sent))\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n    if weight_sum != 0:\n        sent_vec \/= weight_sum\n    tfidf_sent_vectors_test.append(sent_vec)\n    row += 1","e057d1d0":"train_auc = []\ncv_auc = []\nK = list(range(1,200,10))\nfor i in tqdm(K):\n    neigh = KNeighborsClassifier(n_neighbors=i, algorithm='kd_tree')\n    neigh.fit(sent_vectors_train, Y_train)\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n    # not the predicted outputs\n    Y_train_pred =  neigh.predict_proba(sent_vectors_train)[:,1]\n    Y_cv_pred =  neigh.predict_proba(sent_vectors_cv)[:,1]\n    \n    train_auc.append(roc_auc_score(Y_train,Y_train_pred))\n    cv_auc.append(roc_auc_score(Y_cv, Y_cv_pred))\n\nplt.plot(K, train_auc, label='Train AUC')\nplt.scatter(K, train_auc, label='Train AUC')\nplt.plot(K, cv_auc, label='CV AUC')\nplt.scatter(K, cv_auc, label='CV AUC')\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","5fbbb374":"from sklearn.model_selection import cross_val_score\nneighbors = list(range(13, 50, 2))\ncv_score = []\nfor k in tqdm(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n    scores = cross_val_score(knn, tfidf_sent_vectors_train, Y_train, cv=10, scoring='accuracy')\n    cv_score.append(scores.mean())","fd1e61cc":"MSE = [1 - x for x in cv_score]\noptimal_k8 = neighbors[MSE.index(min(MSE))]\nprint(\"_\" * 101)\nprint(\"Optimal number of neighbors: \", optimal_k8)\nprint(\"_\" * 101)\nprint(\"Missclassification error for each k values: \", np.round(MSE, 3))\nprint(\"_\" * 101)\n\nplt.plot(neighbors, MSE)\nplt.title(\"Number of neighbors and error\")\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Missclassification error\")\nplt.show()","915145cd":"optimal_model = KNeighborsClassifier(n_neighbors=optimal_k8, algorithm='kd_tree')\noptimal_model.fit(tfidf_sent_vectors_train, Y_train)\nprediction = optimal_model.predict(tfidf_sent_vectors_test)","bfb1e258":"train_fpr, train_tpr, thresholds = roc_curve(Y_train, neigh.predict_proba(tfidf_sent_vectors_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(Y_test, neigh.predict_proba(tfidf_sent_vectors_test)[:,1])\nAUC8=str(auc(test_fpr, test_tpr))\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"K: hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","cb13a2d6":"training_accuracy = optimal_model.score(tfidf_sent_vectors_train, Y_train)\ntraining_error = 1 - training_accuracy\ntest_accuracy = accuracy_score(Y_test, prediction)\ntest_error = 1 - test_accuracy\n\n\nprint(\"_\" * 101)\nprint(\"Training Accuracy: \", training_accuracy)\nprint(\"Train Error: \", training_error)\nprint(\"Test Accuracy: \", test_accuracy)\nprint(\"Test Error: \", test_error)\nprint(\"_\" * 101)","cb8f2260":"import seaborn as sb\nconf_matrix = confusion_matrix(Y_test, optimal_model.predict(tfidf_sent_vectors_test))\nclass_label = [0, 1]\ndf_conf_matrix = pd.DataFrame(\n    conf_matrix, index=class_label, columns=class_label)\nsb.heatmap(df_conf_matrix, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\nprint(\"_\" * 101)","9f0f8407":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test, prediction))","a7ce4db2":"from prettytable import PrettyTable\ncomparison = PrettyTable()\ncomparison.field_names = [\"Vectorizer\", \"Model\", \"Hyperparameter\", \"AUC\"]\ncomparison.add_row([\"BOW\", 'brute', optimal_k1, np.round(float(AUC1),3)])\ncomparison.add_row([\"TFIDF\", 'brute', optimal_k2, np.round(float(AUC2),3)])\ncomparison.add_row([\"AVG W2V\", 'brute', optimal_k3, np.round(float(AUC3),3)])\ncomparison.add_row([\"Weighted W2V\", 'brute', optimal_k4,np.round(float(AUC4),3)])\ncomparison.add_row([\"BOW\", 'kd_tree', optimal_k5, np.round(float(AUC5),3)])\ncomparison.add_row([\"TFIDF\", 'kd_tree', optimal_k6, np.round(float(AUC6),3)])\ncomparison.add_row([\"AVG W2V\", 'kd_tree', optimal_k7, np.round(float(AUC7),3)])\ncomparison.add_row([\"Weighted W2V\", 'kd_tree', optimal_k8, np.round(float(AUC8),3)])\nprint(comparison)","b35f616b":"Confusion Matrix","25336c7a":"**Classification Report**","e6bec1b3":"**Accuracy Check**","180818a4":"**Applying KNN kd-tree on BOW**","3c19f345":"**Preprocessing**","0f929fcc":"**Classification Report**","6b45a00f":"Plotting the AUC Curve","3608554d":"**Confusion matrix**","9e67ec6b":"Classification Matrix","c5b432eb":"**Applying KNN kd-tree on TFIDF**","ca61cbf5":"Confusion Matrix","bef4dc5b":"Accuracy Check","15199223":"Classification Report","75422624":"Accuracy Check","b5d61914":"**Accuracy Check**","7af049e0":"**Confusion Matrix**","405e9a19":"**Classification Matrix**","e5d45248":"**Accuracy Check**","cc1dec63":"**Applying KNN kd-tree**","1133dafd":"**Exploratory Data Analysis**","4d84a2a8":"Classification Matrix","33206432":"Plotting the AUC Curve","6a6990a0":"Classification Report","a58a9ca9":"**Plotting the AUC Curve**","e403ed61":"Plotting the AUC Curve","8ea61634":"**Accuracy Check**","90de8802":"**Applying KNN brute force**","d9653791":"Confusion Matrix","7784b9bb":"Plotting The AUC Curve","15b7017a":"**BOW**","642f6615":"**Conclusions**","5346aa7a":"**Classification report**","1ec58146":"**Confusion matrix**","493effc1":"Data Cleaning: Deduplication","cee21a31":"**Applying KNN kd-tree on TFIDF W2V**","af853e36":"Accuracy Check","5d9bfbad":"**Applying KNN brute force on TFIDF**","cfe4833f":"**Plotiing the AUC**","c8b5d099":"**Applying KNN brute force on BOW, SET 1**","2aa21b7f":"**Confusion Matrix**","5dbe6352":"Accuracy Check","733fac5c":"**Applying KNN brute force on TFIDF W2V**","b70a016c":"**Applying KNN kd-tree on AVG W2V**","a3146df1":"**Plotting the AUC Curve**","b8ff7000":"Confusion Matrix","fb80df5b":"**Applying KNN brute force on AVG W2V**","244620b4":"**Plotting the AUC Curve**","653705b5":"**Preprocessing Review Text**"}}