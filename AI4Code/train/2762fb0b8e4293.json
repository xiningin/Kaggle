{"cell_type":{"6e4268dd":"code","b785150e":"code","2abe41f7":"code","7b9ea3cd":"code","773f75b6":"code","ec5b522c":"code","80212e0d":"code","989169e9":"code","686c7ac5":"code","680bf2cf":"code","6165e479":"code","ce9497b3":"code","7fab3b11":"code","0d59e51a":"code","cdf54ac2":"code","f3675328":"markdown","c0544f0c":"markdown","dda92352":"markdown","d3c81724":"markdown","239f1c0c":"markdown","d0188564":"markdown","b6bde569":"markdown","d75b5da2":"markdown","a4c50e12":"markdown"},"source":{"6e4268dd":"from __future__ import division\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os \n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torchvision\nimport torch.nn.functional as fun\nimport torch.nn as nn \nimport torch.utils.data\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST","b785150e":"!pip install torchsummary","2abe41f7":"train_df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\n#display(train_df.head())\n\ntest_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\n\ny = torch.tensor(train_df.label.values)\nx = torch.tensor(train_df.iloc[:,1:].values)\n\n\nx_tr, x_ts, y_tr, y_ts = train_test_split(x,y, test_size = 0.1, random_state=42)\n\n\nprint(f'Train size: {len(y_tr)} \\nTest size: {len(y_ts)}')","7b9ea3cd":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, labels, transform = None):\n        'Initialization'\n        self.labels = labels\n        self.inp_feats = inputs\n        self.transform = transform\n    \n    def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.labels)\n    \n    def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select\/Load sample data and get label\n        X = self.inp_feats[index].type('torch.FloatTensor')\n        X *= 1\/255.0\n        y = self.labels[index]\n        \n        if self.transform is not None:\n            X = self.transform(X)\n\n        return X, y","773f75b6":"# Parameters\nparams = {'batch_size': 128,\n          'shuffle': True,\n          'num_workers': 0}\n\ntraining_set = Dataset(x_tr, y_tr)\ntrain_gen = torch.utils.data.DataLoader(training_set, **params, drop_last=True)\n\ntesting_set = Dataset(x_ts, y_ts)\ntest_gen = torch.utils.data.DataLoader(testing_set, **params, drop_last=True)","ec5b522c":"torch.manual_seed(1)\ntorch.cuda.manual_seed(1)","80212e0d":"# define cuda device: \n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","989169e9":"' construct VAE architecture '\n\nclass VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        \n        \n        \n        self.encoder = nn.Sequential(\n            nn.Linear(784, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, 3*2),\n            nn.BatchNorm1d(3*2)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(3, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, 784),\n            nn.Sigmoid(),\n    \n        )\n        \n        \n    def reparam_trick(self, mu, logvar):\n        if self.training:\n            std = logvar.mul(0.5).exp_()\n            eps = std.data.new(std.size()).normal_()\n            return eps.mul(std).add_(mu)\n        else:\n            return mu\n        \n    def forward(self, x):\n        mu_logvar = self.encoder(x.view(-1, 784)).view(-1, 2, 3)\n        mu = mu_logvar[:, 0, :]\n        logvar = mu_logvar[:, 1, :]\n        z = self.reparam_trick(mu, logvar)\n        return self.decoder(z), z, mu, logvar\n        \nwidth = 25\n# initialize the NN     \nmodel = VAE().to(device)\n#print(model)\n        \nfrom torchsummary import summary\nsummary(model, (1, 28*28))\n        \n        ","686c7ac5":"lrate = 0.00100031312\noptimizer = torch.optim.Adam(\n            model.parameters(),\n            lr = lrate)\n","680bf2cf":"def VAE_loss(x_tilde, x, mu, logvar, beta):\n    BCE = fun.binary_cross_entropy(x_tilde, x.view(-1, 784), reduction = 'sum')\n    KL = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n    return BCE + beta * KL \n    ","6165e479":"def train_model(beta, epochs, model):\n    dic = dict(latent_space = list(), mu_list=list(), logsig2_list=list(), y=list())\n    for epoch in range(0, epochs + 1):\n        # ========= TRAINING =========\n        if epoch > 0: \n            model.train()\n            train_loss = 0\n            for X, _ in train_gen:\n                X = X.to(device)\n                # forward pass ...\n                x_tilde, z, mu, logvar = model(X)\n                loss = VAE_loss(x_tilde, X, mu, logvar, beta)\n                train_loss += loss.item()\n                # backward pass ...\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            # log ...\n            print(f'----> Epoch: {epoch} Average loss: {train_loss \/ len(train_gen.dataset):.4f}')\n\n        # ========= TESTING ========= \n\n        z_list, means, logvars , labels = list(), list(), list(), list()\n        with torch.no_grad():\n            model.eval()\n            test_loss = 0\n            for X, Y in test_gen:\n                X = X.to(device)\n                # forward ...\n                x_tilde, z, mu, logvar = model(X)\n                test_loss += VAE_loss(x_tilde, X, mu, logvar, beta).item()\n                # log ...\n                z_list.append(z.detach())\n                means.append(mu.detach())\n                logvars.append(logvar.detach())\n                labels.append(Y.detach())\n        # log ...\n        dic['latent_space'].append(torch.cat(z_list))\n        dic['mu_list'].append(torch.cat(means))\n        dic['logsig2_list'].append(torch.cat(logvars))\n        dic['y'].append(torch.cat(labels))\n        test_loss \/= len(test_gen.dataset)\n        print(f'----> Test set loss: {test_loss:.4f}')\n    return dic\n    \nbeta = 1\nepochs = 50\ndic = train_model(beta, epochs, model)","ce9497b3":"z_arr = dic['latent_space'][0].cpu().numpy()\ny_arr = dic['y'][0].cpu().numpy()\nplt.figure(figsize = (10,5))\nplt.subplot(1,2,1)\nplt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr)\nplt.subplot(1,2,2)\nplt.scatter(z_arr[:,1], z_arr[:,2], c = y_arr)\nplt.colorbar()\nplt.tight_layout()\n","7fab3b11":"# all we need to do now is call the VAE model and define beta > 1 \nwidth = 25\n# initialize the NN     \nmodel = VAE().to(device)\nprint(model)\n        \nfrom torchsummary import summary\nsummary(model, (1,28*28), 1)\n\nbeta = 3 # beta becomes an additional hyperparameter\nepochs = 100","0d59e51a":"dic = train_model(beta, epochs, model)","cdf54ac2":"z_arr = dic['latent_space'][0].cpu().numpy()\ny_arr = dic['y'][0].cpu().numpy()\nplt.figure(figsize = (10,5))\nplt.subplot(1,2,1)\nplt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr)\nplt.subplot(1,2,2)\nplt.scatter(z_arr[:,1], z_arr[:,2], c = y_arr)\nplt.colorbar()\nplt.tight_layout()\n","f3675328":"#### train $\\beta$-VAE","c0544f0c":"#### Plot latent space ","dda92352":"The above latent space did not do a great job in disentangling the mnist digits; however, this should ideally be fixed by increasing the latent space dimension. For example, we expand the dimension size from 3 to width parameter, albeit we lose the ability to visualize it. If you do plan to expand the latent space dimension from 3 to width parameter, you can then implement t-SNE to map the latent space to a lower dimension so that you potentially visualize distinct MNIST digit clusters.","d3c81724":"#### Train model","239f1c0c":"## Preprocess data","d0188564":"## Vanilla Variational Autoencoder (VAE):","b6bde569":"#### plot latent space","d75b5da2":"## Beta Variational Autoencoder\n\nHere we introduce the $\\beta$-VAE, where $\\beta$>1 restricts the reconstruction accuracy and increases the degree of disentanglement of learn features. ","a4c50e12":"## Ref:\n\nOverall, the workflow was adapted from Alfredo Canziani work at https:\/\/atcold.github.io\/pytorch-Deep-Learning\/ with changes to the preprocessing step, specific architectures details, and model extention by including $\\beta$-VAE. "}}