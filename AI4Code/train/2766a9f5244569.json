{"cell_type":{"1c030087":"code","b7f9b528":"code","0b172106":"code","54de40e2":"code","393526fc":"code","a475377b":"code","6adf8e3d":"code","7e216265":"code","301a6bde":"code","e4ae6517":"code","5b63785a":"code","4cef5711":"code","0af6b6fa":"code","941d69b5":"code","de01a7b3":"code","b5a1bf63":"code","adc10095":"code","e7b9988f":"code","2cedb6dc":"code","e8371f72":"code","09e785c6":"code","69ed30e7":"code","f19b61b7":"code","6db45910":"code","79e28678":"code","38c969a8":"code","fda32941":"code","74d20a38":"code","0fba6a98":"markdown","3ae96bd2":"markdown","6730d8d4":"markdown","e342a39d":"markdown","ece9bebc":"markdown","11d618b5":"markdown","d14dcb8c":"markdown","11d82c36":"markdown","1cdccbf7":"markdown","d5672985":"markdown","f8098ca2":"markdown","1570616f":"markdown","91f0faf5":"markdown","e749521d":"markdown","e3e93d66":"markdown"},"source":{"1c030087":"# importing required python packages\nimport datetime\nimport warnings\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nfrom typing import Optional, List, Dict\nfrom fbprophet import Prophet\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nwarnings.filterwarnings('ignore')\nplt.style.use('fivethirtyeight')","b7f9b528":"# loading and preprocessing the data\nts = pd.read_csv('\/kaggle\/input\/hourly-energy-consumption\/PJME_hourly.csv',\n                 parse_dates=[0])\nts = ts.rename(columns={\"Datetime\":\"datetime\",\n                        \"PJME_MW\":\"observation\"}).sort_values(by=\"datetime\")\nMIN_DATE = datetime.datetime(2014, 1, 1)\nMAX_DATE = datetime.datetime(2018, 1, 1)\nts = ts.loc[(ts[\"datetime\"] > MIN_DATE) &\n            (ts[\"datetime\"] < MAX_DATE)\n           ].reset_index(drop=True)\nts.head()","0b172106":"def generate_datetime_features(df: pd.DataFrame, datetime_col: str) -> pd.DataFrame:\n    \"\"\"\n    Creates time series features from datetime column.\n    :param df: Dataframe containing `datetime_col`\n    :param datetime_col: Column name for datetime dtype series.\n    :return: Input df with additional time frequency feature columns.\n    \"\"\"\n    df[datetime_col] = pd.to_datetime(df[datetime_col])\n    df['date_hour'] = df[datetime_col].dt.floor('H')\n    df['date'] = df[datetime_col].dt.floor('D')\n    df['hour_of_day'] = df[datetime_col].dt.hour\n    df['day_of_week'] = df[datetime_col].dt.dayofweek\n    df['quarter_of_year'] = df[datetime_col].dt.quarter\n    df['month_of_year'] = df[datetime_col].dt.month\n    df['year'] = df[datetime_col].dt.year\n    df['day_of_year'] = df[datetime_col].dt.dayofyear\n    df['day_of_month'] = df[datetime_col].dt.day\n    df['week_of_year'] = df[datetime_col].dt.weekofyear\n    \n    return df","54de40e2":"# generating datetime features\nts = generate_datetime_features(ts, \"datetime\")\nts.head()","393526fc":"# plotting time series\nfig = ts.plot(x=\"datetime\", y=\"observation\", style='.', figsize=(15,5))","a475377b":"# plotting interactive time series\nfig = px.scatter(ts, x=\"datetime\", y=\"observation\", hover_data=[\"day_of_week\"])\nfig.update_traces(mode='markers+lines', marker_size=5)\nfig.show()","6adf8e3d":"def lineplot_agg_grouped(\n    df: pd.DataFrame,\n    group_col: str,\n    target_col: str,\n    y_label: str,\n    agg_type: str = \"mean\",\n    x_ticks: int = 0,\n) -> None:\n    \"\"\"\n    plots the aggregate value of a column in a df grouped by another column\n    :param df: pd.DataFrame with columns `group_col` and `target_col`.\n    :param group_col: column name in `df` to group by.\n    :param target_col: column name in `df` to average over.\n    :param y_label: y axis label.\n    :param agg_type: aggregate type (e.g. mean, sum, first)\n    :param x_ticks: rotation (degree) of x axis ticks.\n    :return: None but plot is generated.\n    \"\"\"\n    agg_df = df.groupby([group_col]).agg({target_col:agg_type}).reset_index()\n    \n    plt.figure(figsize=(8,5))\n    ax = sns.lineplot(data=agg_df, x=agg_df[group_col], y=target_col, marker=\"o\")   \n    ax.set(ylabel=y_label)\n    plt.xticks(rotation=x_ticks)\n\n    return","7e216265":"# plotting average observation grouped by different datetime features\nts_features = ['hour_of_day',\n               'day_of_week',\n               'day_of_month',\n               'week_of_year',\n               'month_of_year',\n               'quarter_of_year',\n               'year']\nfor ts_feature in ts_features:\n    lineplot_agg_grouped(\n        df = ts,\n        group_col = ts_feature,\n        target_col = 'observation',\n        y_label = 'average observation',\n        agg_type = \"mean\",\n        x_ticks = 0\n    )","301a6bde":"# splitting train and test data\nSPLIT_DATE = 2017\nts['type'] = 'train'\nts.loc[ts['year'] >= SPLIT_DATE, 'type'] = 'test'\ntrain = ts.loc[ts['type'] == \"train\"].reset_index(drop=True)\ntest = ts.loc[ts['type'] == \"test\"].reset_index(drop=True)","e4ae6517":"# plotting time series grouped by train and test datasets\nfig = px.scatter(ts, x=\"datetime\", y=\"observation\",\n                 hover_data=[\"day_of_week\"], color=\"type\")\nfig.update_traces(mode='markers+lines', marker_size=5)\nfig.show()","5b63785a":"def evaluate_forecast_metrics(\n    y_true: pd.Series,\n    y_pred: pd.Series,\n    mape_cutoff: int = 100,\n) -> Dict:\n    \"\"\"\n    Calculates forecasting metrics (MAE, RMSE, MAPE, and cutoff MAPE)\n    :param y_true: actual values as pandas Series.\n    :param y_pred: predicted values as pandas Series.\n    :param mape_cutoff: minimum actuals to avoid really high MAPE values.\n    :return: dictionary with MAE, RMSE, MAPE, and CMAPE metrics.\n    \"\"\"\n    # mean absolute error (MAE)\n    mae = mean_absolute_error(y_true, y_pred)\n    \n    # root mean squared error (RMSE)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    \n    # mean absolute percentage error (MAPE)\n    mape = np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n    \n    # cutoff mean absolute percentage error (CMAPE)\n    temp = pd.DataFrame()\n    temp['actual'] = y_true\n    temp['prediction'] = y_pred\n    temp = temp.loc[temp['actual'] >= mape_cutoff]\n    ytrue, ypred = np.array(temp['actual']), np.array(temp['prediction'])\n    cmape = np.mean(np.abs((ytrue - ypred) \/ ytrue)) * 100\n    \n    return {\"MAE\":round(mae, 3),\n            \"RMSE\":round(rmse, 3),\n            \"MAPE\":round(mape, 3),\n            \"CMAPE\":round(cmape, 3)}","4cef5711":"# training a simple prophet model with default parameters\nmodel_prophet = Prophet()\nmodel_prophet.fit(train.rename(columns={\"datetime\":\"ds\", \"observation\":\"y\"}))\ntest_prophet = model_prophet.predict(\n    df=test.rename(columns={\"datetime\":\"ds\", \"observation\":\"y\"}))","0af6b6fa":"test_prophet.info()","941d69b5":"# plotting historical values and forecast values\nfig = model_prophet.plot(test_prophet, figsize=(15,5))","de01a7b3":"# plotting the components of the model\nfig = model_prophet.plot_components(test_prophet)","b5a1bf63":"# plotting actual vs forecast\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(test[\"datetime\"], test['observation'], color='r')\nfig = model_prophet.plot(test_prophet, ax=ax)","adc10095":"# calculating model performance metrics\nevaluate_forecast_metrics(test[\"observation\"], test_prophet[\"yhat\"])","e7b9988f":"# adding prediction results to the test dataset as a new column\ntest = pd.merge(left=test,\n                right=test_prophet.rename(columns={\"ds\":\"datetime\",\n                                                   \"yhat\":\"prediction_prophet\"}),\n                on=\"datetime\",\n                how=\"left\")","2cedb6dc":"# plotting actual vs forecast in an interactive plot\nfig = px.scatter(test, x=\"datetime\",\n                 y=[\"observation\", \"prediction_prophet\"],\n                 hover_data=[\"day_of_week\"])\nfig.update_traces(mode='markers+lines', marker_size=5)\nfig.show()","e8371f72":"# defining features and target variables\nFEATURES = ['hour_of_day',\n            'day_of_week', \n            'quarter_of_year',\n            'month_of_year',\n            'year', \n            'day_of_year',\n            'day_of_month',\n            'week_of_year'\n           ]\nTARGET = \"observation\"","09e785c6":"# splitting data into train, evaluation and test sets\ny_train_val = train[TARGET]\ny_test = test[TARGET]\nX_train_val = train[FEATURES]\nX_test = test[FEATURES]\nX_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1)\n\n# building an XGBoost model\nmodel_xgb = xgb.XGBRegressor(n_estimators=1000)\nmodel_xgb.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_val, y_val)],\n              early_stopping_rounds=50,\n              verbose=False)\n\n# getting prediction values on test set\ntest['prediction_xgboost'] = model_xgb.predict(X_test)","69ed30e7":"_ = plot_importance(model_xgb, height=0.9)","f19b61b7":"# plotting actual vs forecast\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(test[\"datetime\"], test['observation'], color='r')\nax.scatter(train[\"datetime\"], train['observation'], color='k')\nax.scatter(test[\"datetime\"], test['prediction_xgboost'])","6db45910":"evaluate_forecast_metrics(y_test, test['prediction_xgboost'])","79e28678":"# plotting time series grouped by train and test datasets\nts_all = pd.concat([train, test])\nfig = px.scatter(ts_all, x=\"datetime\",\n                 y=[\"observation\", \"prediction_prophet\", \"prediction_xgboost\"],\n                 hover_data=[\"day_of_week\"])\nfig.update_traces(mode='markers+lines', marker_size=5)\nfig.show()","38c969a8":"# building a quantile regression model for predicting upper bound\nmodel_quantile_upper = lgb.LGBMRegressor(objective='quantile', alpha=0.975)\nmodel_quantile_upper.fit(X_train_val, y_train_val)\n\n# getting upper quantile regression prediction values on test set\ntest['prediction_quantile_upper'] = model_quantile_upper.predict(X_test)\n\n# building a quantile regression model for predicting lower bound\nmodel_quantile_lower = lgb.LGBMRegressor(objective='quantile', alpha=0.025)\nmodel_quantile_lower.fit(X_train_val, y_train_val)\n\n# getting lower quantile regression prediction values on test set\ntest['prediction_quantile_lower'] = model_quantile_lower.predict(X_test)","fda32941":"# plotting actual vs forecast\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(train[\"datetime\"], train['observation'], color='k')\nax.scatter(test[\"datetime\"], test['prediction_quantile_lower'], color='lightblue')\nax.scatter(test[\"datetime\"], test['prediction_quantile_upper'], color='lightblue')\nax.scatter(test[\"datetime\"], test['observation'], color='r')\nax.scatter(test[\"datetime\"], test['prediction_xgboost'])","74d20a38":"# plotting actual vs forecast for all results\nts_all = pd.concat([train, test])\nfig = px.scatter(ts_all, x=\"datetime\",\n                 y=[\"observation\",\n                    \"prediction_quantile_lower\", \"prediction_quantile_upper\",\n                    \"prediction_xgboost\"],\n                 hover_data=[\"day_of_week\"])\nfig.update_traces(mode='markers+lines', marker_size=5)\nfig.show()","0fba6a98":"## TS Forecasting with Prophet \nIn this section, we will be using  Facebook's Prophet package to build an hourly TS forecasting model. Since Prophet model expects the dataset to be named a specific way, we will first rename our dataframe columns before feeding it into the model. Hourly TS forecasting model will be built using train dataset and predictions will be obtained on the test dataset.","3ae96bd2":"In the following section, visualiztions and performance evaluation metrics are presented.","6730d8d4":"## TS Forecasting with XGBoost\nIn this section, we will be using a Machine Learning technique (XGBoost Regression) to build an hourly TS forecasting model. Date time features such as, hour_of_day, day_of_week, month_of_year, etc. will be used as features and observation will be the target variable. Note that you can add any other relevant features (e.g. rolling avg of past observations, a TS that is related the target variable) to the feature list to improve the performance of the model. Similar to the Prophet model, hourly TS forecasting model will be built using train dataset and predictions will be obtained on the test dataset.","e342a39d":"# Time Series Forecasting\nIn this notebook, we will perform time series forecasting using several techniques, such as Prophet (an open-source library, maintained by Facebook) and XGBoost Regression methods. We will also predict upper and lower bounds for our predictions using Quantile Regression framework.","ece9bebc":"## Preparing Data for Modeling","11d618b5":"## Exploratory Data Analysis (EDA)\nIn this section, we will be exploring data and identifying trend and seasonalities of the times series through visualizations.","d14dcb8c":"Following plots show the hourly observed values over time both in static and interactive versions.","11d82c36":"In order to build and evaluate TS forecasting models, we first split the data into two parts, train and test sets. Train dataset will be used for model training, and test dataset will only be used for evaluating the performance of trained models. Here, we will use the first 3 years of data (2014-2016) as our train set and the last year (2017) as our test set.","1cdccbf7":"In the following section, visualiztions and performance evaluation metrics are presented.","d5672985":"## Upper\/Lower Bound TS Forecasting with Quantile Regression\nIn this section, we will predict upper and lower bounds for our predictions using Quantile Regression framework. In usecases where overestimation and underestimation of the target variable is preferred, quantile regression model output can be considered as the TS forecast predictions.","f8098ca2":"In the following section, we will be plotting the average of the observed values grouped by different time series features, such as day of week, hour of day, month of year, etc.","1570616f":"Here is the list of outputs that Prophet model generated and yhat is the model predictions.","91f0faf5":"## Data\nThe time series data that we will be using in this notebook is hourly energy consumption data from PJM (see [here](https:\/\/www.kaggle.com\/robikscube\/hourly-energy-consumption) to learn more about the data). For simplicity, we will only use 4 years of data, from the beginning 2014 to the end of 2017.","e749521d":"Next, we will compare the predictions obtained from Prophet and XGBoost models. As observed in the following plot and in the metrics reported previously, in this example, XGBoost model is performing better comparing to the Prophet model.","e3e93d66":"## Defining Evaluation Metrics\nWe will evaluate the performance of TS forecasting modelsusing the following metrics: mean absolute error (MAE), root mean squared error (RMSE), mean absolute percentage error (MAPE), and cutoff mean absolute percentage error (CMAPE which eliminates records with low actual values to avoid getting really high MAPEs)."}}