{"cell_type":{"a22c1270":"code","88ae4633":"code","6484425e":"code","c7077e8e":"code","a0cd2bac":"code","dee2f80e":"code","bd3cf6f0":"code","769ab424":"code","6bf5d61b":"code","41f4aca9":"code","d6e21331":"code","77db229d":"code","291a89a0":"code","e2a95c3b":"code","d0eaaab9":"code","584ab64b":"code","a90ffa57":"markdown","e05cb341":"markdown"},"source":{"a22c1270":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","88ae4633":"#Importing required packages.\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\n#from sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n%matplotlib inline","6484425e":"#Loading dataset\nrwine = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","c7077e8e":"#Let's check how the data is distributed\nrwine.head()","a0cd2bac":"#knowing number of features and data size\nrow,col=rwine.shape\nprint(row,\",\",col)","dee2f80e":"#Data Information \nrwine.info()\n# There is no null values, and no categorical data","bd3cf6f0":"#knowing the number of red wine quality classes\nrwine['quality'].value_counts()","769ab424":"#Making binary classificaion for the target by dividing wine as g for good and b for bad.\n#Dividing wine as good and bad by giving the limit for the quality\nbins = (2, 5.5, 8)\ngroups = ['b', 'g']\nrwine['quality'] = pd.cut(rwine['quality'], bins = bins, labels = groups)","6bf5d61b":"L_quality = LabelEncoder()","41f4aca9":"rwine['quality'] = L_quality.fit_transform(rwine['quality'])\n","d6e21331":"rwine['quality'].value_counts()","77db229d":"#fig, axs = plt.subplots(5,2,figsize=(15,15))\n#axs[0, 0].hist(rwine['fixed acidity'],bins=10) #original data\n#axs[0, 0].set_title('fixed acidity')\n#axs[0, 1].hist(rwine['volatile acidity'],bins=10) \n#axs[0, 1].set_title('volatile acidity')\n","291a89a0":"df_train = rwine.sample(frac=0.7, random_state=0)\ndf_test = rwine.drop(df_train.index)\n\n# Split features and target\nX_train = df_train.drop('quality', axis=1)\nX_test = df_test.drop('quality', axis=1)\ny_train = df_train['quality']\ny_test = df_test['quality']","e2a95c3b":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    layers.Dense(1024, activation='relu', input_shape=[11]),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.Dense(1024, activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.Dense(1024, activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.Dense(1, activation='sigmoid'),])","d0eaaab9":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    batch_size=250,\n    epochs=100,\n    verbose=0\n)\n\n\n# Show the learning curves\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot();","584ab64b":"history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['val_loss'].min(), \n              history_df['val_binary_accuracy'].max()))","a90ffa57":"***If you find this notebook useful then please upvote.***\n","e05cb341":"## Data Preprocessing and Visualization"}}