{"cell_type":{"044b6372":"code","c8dfe1dc":"code","8a98520d":"code","34d4bd9c":"code","644e51e0":"markdown"},"source":{"044b6372":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport csv\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c8dfe1dc":"def load_data(file_name, is_train):\n    data = pd.read_csv(file_name)  # \u6570\u636e\u6587\u4ef6\u8def\u5f84\n    pd.set_option('display.width', 200)\n    print('data.describe() = \\n', data.describe())\n\n    # \u6027\u522b\n    # data['Sex'] = data['Sex'].map({'female': 0, 'male': 1}).astype(int)\n    data['Sex'] = pd.Categorical(data['Sex']).codes\n\n    # \u8865\u9f50\u8239\u7968\u4ef7\u683c\u7f3a\u5931\u503c\n    if len(data.Fare[data.Fare == 0]) > 0:\n        fare = np.zeros(3)\n        for f in range(0, 3):\n            fare[f] = data[data['Pclass'] == f + 1]['Fare'].dropna().median()\n        print(fare)\n        for f in range(0, 3):  # loop 0 to 2\n            data.loc[(data.Fare == 0) & (data.Pclass == f + 1), 'Fare'] = fare[f]\n\n    print('data.describe() = \\n', data.describe())\n    # \u5e74\u9f84\uff1a\u4f7f\u7528\u5747\u503c\u4ee3\u66ff\u7f3a\u5931\u503c\n    # mean_age = data['Age'].dropna().mean()\n    # data.loc[(data.Age.isnull()), 'Age'] = mean_age\n    if is_train:\n        # \u5e74\u9f84\uff1a\u4f7f\u7528\u968f\u673a\u68ee\u6797\u9884\u6d4b\u5e74\u9f84\u7f3a\u5931\u503c\n        print('\u968f\u673a\u68ee\u6797\u9884\u6d4b\u7f3a\u5931\u5e74\u9f84\uff1a--start--')\n        data_for_age = data[['Age', 'Survived', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n        age_exist = data_for_age.loc[(data.Age.notnull())]   # \u5e74\u9f84\u4e0d\u7f3a\u5931\u7684\u6570\u636e\n        age_null = data_for_age.loc[(data.Age.isnull())]\n        print(age_exist)\n        x = age_exist.values[:, 1:]\n        y = age_exist.values[:, 0]\n        rfr = RandomForestRegressor(n_estimators=20)\n        rfr.fit(x, y)\n        age_hat = rfr.predict(age_null.values[:, 1:])\n        # print age_hat\n        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n        print('\u968f\u673a\u68ee\u6797\u9884\u6d4b\u7f3a\u5931\u5e74\u9f84\uff1a--over--')\n    else:\n        print('\u968f\u673a\u68ee\u6797\u9884\u6d4b\u7f3a\u5931\u5e74\u9f842\uff1a--start--')\n        data_for_age = data[['Age', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n        age_exist = data_for_age.loc[(data.Age.notnull())]  # \u5e74\u9f84\u4e0d\u7f3a\u5931\u7684\u6570\u636e\n        age_null = data_for_age.loc[(data.Age.isnull())]\n        # print age_exist\n        x = age_exist.values[:, 1:]\n        for i in range(332):\n            for j in range(4):\n                if np.isnan(x[i][j]):\n                    x[i][j] = 0\n        y = age_exist.values[:, 0]\n        rfr = RandomForestRegressor(n_estimators=1000)\n        rfr.fit(x, y)\n        age_hat = rfr.predict(age_null.values[:, 1:])\n        # print age_hat\n        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n        print('\u968f\u673a\u68ee\u6797\u9884\u6d4b\u7f3a\u5931\u5e74\u9f842\uff1a--over--')\n    data['Age'] = pd.cut(data['Age'], bins=6, labels=np.arange(6))\n\n    # \u8d77\u59cb\u57ce\u5e02\n    data.loc[(data.Embarked.isnull()), 'Embarked'] = 'S'  # \u4fdd\u7559\u7f3a\u5931\u51fa\u53d1\u57ce\u5e02\n    embarked_data = pd.get_dummies(data.Embarked)\n    print('embarked_data = ', embarked_data)\n    # embarked_data = embarked_data.rename(columns={'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown', 'U': 'UnknownCity'})\n    embarked_data = embarked_data.rename(columns=lambda x: 'Embarked_' + str(x))\n    data = pd.concat([data, embarked_data], axis=1)\n\n    print(data.describe())\n    data.to_csv('New_Data.csv')\n\n    x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n    # x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n    y = None\n    if 'Survived' in data:\n        y = data['Survived']\n\n    x = np.array(x)\n    y = np.array(y)\n\n    # \u601d\u8003\uff1a\u8fd9\u6837\u505a\uff0c\u5176\u5b9e\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f\n    x = np.tile(x, (5, 1))\n    y = np.tile(y, (5, ))\n    if is_train:\n        return x, y\n    return x, data['PassengerId']\n\nx, y = load_data('..\/input\/train.csv', True)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)","8a98520d":"def show_accuracy(a, b, tip):\n    acc = a.ravel() == b.ravel()\n    acc_rate = 100 * float(acc.sum()) \/ a.size\n    print('%s\u6b63\u786e\u7387\uff1a%.3f%%' % (tip, acc_rate))\n    return acc_rate\n\ndef write_result(c, c_type):\n    file_name = '..\/input\/test.csv'\n    x, passenger_id = load_data(file_name, False)\n\n    if c_type == 3:\n        x = xgb.DMatrix(x)\n    y = c.predict(x)\n    y[y > 0.5] = 1\n    y[~(y > 0.5)] = 0\n\n    predictions_file = open(\"Prediction_%d.csv\" % c_type, \"wb\")\n    open_file_object = csv.writer(predictions_file)\n    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n    open_file_object.writerows(list(zip(passenger_id, y)))\n    predictions_file.close()\n","34d4bd9c":"data_train = xgb.DMatrix(x_train, label=y_train)\ndata_test = xgb.DMatrix(x_test, label=y_test)\nwatch_list = [(data_test, 'eval'), (data_train, 'train')]\nparam = {'max_depth': 6, 'eta': 0.8, 'silent': 1, 'objective': 'binary:logistic'}\n         # 'subsample': 1, 'alpha': 0, 'lambda': 0, 'min_child_weight': 1}\nbst = xgb.train(param, data_train, num_boost_round=20, evals=watch_list)\ny_hat = bst.predict(data_test)\nwrite_result(bst, 3)\ny_hat[y_hat > 0.5] = 1\ny_hat[~(y_hat > 0.5)] = 0\nxgb_acc = accuracy_score(y_test, y_hat)","644e51e0":"**Funcation**"}}