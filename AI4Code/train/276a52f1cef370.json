{"cell_type":{"9aee884e":"code","da31db78":"code","8476b720":"code","4e8b87e4":"code","6fda7590":"code","104b39fd":"code","78ffdea4":"code","6a6f3376":"code","b630ff33":"code","d37dcdb0":"code","4efd1af9":"code","06ab9555":"code","089cd41f":"code","e8d60116":"code","b45a465c":"code","001dec62":"code","f949a5ec":"code","ac42c0a1":"code","4b4c9273":"code","65ab438e":"code","0ecae8c0":"code","834fb875":"code","c1f6554a":"code","add36b38":"markdown","842e2e06":"markdown","adcd661b":"markdown","cc3d00bf":"markdown","75d7a933":"markdown","e4b6e771":"markdown","b94eb459":"markdown"},"source":{"9aee884e":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp","da31db78":"train=pd.read_csv('..\/input\/30-days-of-ml\/train.csv')\ntrain.head()","8476b720":"test=pd.read_csv('..\/input\/30-days-of-ml\/test.csv')\ntest.head()","4e8b87e4":"train.info()","6fda7590":"train.shape","104b39fd":"test.shape","78ffdea4":"train.isnull().sum()","6a6f3376":"test.isnull().sum()","b630ff33":"# missing value\nprint('Missing values in train dataset:', sum(train.isnull().mean()*100))\nprint('Missing values in test dataset:', sum(test.isnull().mean()*100))","d37dcdb0":"train.describe().T.style.bar().background_gradient(cmap='coolwarm')","4efd1af9":"test.describe().T.style.bar().background_gradient(cmap='coolwarm')","06ab9555":"CAT_FEATURES = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\nNUM_FEATURES = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8',\n                'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\nALL_FEATURES = CAT_FEATURES+NUM_FEATURES","089cd41f":"plt.figure(figsize=(20,8))\nplt.subplots_adjust(hspace=0.5, wspace=0.5)\n#sns.set_palette(\"Spectral\")\nfor i, col in enumerate(CAT_FEATURES):\n    plt.subplot(2, 5, i+1)\n    sns.barplot(x=col, y=\"target\", data=train,\n                estimator=lambda x: len(x) \/ len(train) * 100,\n                order=np.sort(train[col].unique()))\n    plt.title(col)\nplt.show()","e8d60116":"plt.figure(figsize=(20,8))\nplt.subplots_adjust(hspace=0.5, wspace=0.5)\nfor i, col in enumerate(CAT_FEATURES):\n    plt.subplot(2, 5, i+1)\n    sns.barplot(x=col, y=\"cont0\", data=test,\n                estimator=lambda x: len(x) \/ len(test) * 100,\n                order=np.sort(test[col].unique()))\n    plt.title(col)\nplt.show()\n","b45a465c":"cat_features = [feature for feature in train.columns if 'cat' in feature]\ncont_features = [feature for feature in train.columns if 'cont' in feature]","001dec62":"x = train.drop(['target'], axis=1)\ny = train['target']\nX_test = test.copy()","f949a5ec":"# data encoding\nfrom sklearn.preprocessing import OrdinalEncoder\n\nordinal_encoder = OrdinalEncoder()\nx[cat_features] = ordinal_encoder.fit_transform(x[cat_features])\nX_test[cat_features] = ordinal_encoder.transform(X_test[cat_features])\nx.head()","ac42c0a1":"train.drop(\"id\", axis=1, inplace=True)\ntest.drop(\"id\", axis=1, inplace=True)","4b4c9273":"# trai test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(x, y,test_size=0.2, random_state=22)","65ab438e":"from scipy import stats\n\nf, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 12))\n\nf.suptitle('Target', fontsize=16)\ng = sns.kdeplot(train['target'], shade=True, label=\"%.2f\"%(train['target'].skew()), ax=axes[0])\ng = g.legend(loc=\"best\")\nstats.probplot(train['target'], plot=axes[1])\nsns.boxplot(x='target', data=train, orient='h', ax=axes[2]);\n\nplt.tight_layout()\nplt.show()","0ecae8c0":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nmodel_rf = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=30,\n           max_features='sqrt', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=2, min_samples_split=5,\n           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n           oob_score=False, random_state=22, verbose=0, warm_start=False)\n\nmodel_rf.fit(X_train, y_train)\npred_Rand = model_rf.predict(X_valid)\nprint(mean_squared_error(y_valid, pred_Rand, squared=False))","834fb875":"from xgboost import XGBRegressor\n\nxgb_params = {'objective': 'reg:squarederror',\n              'n_estimators': 10000,\n              'learning_rate': 0.036,\n              'subsample': 0.926,\n              'colsample_bytree': 0.118,\n              'grow_policy':'lossguide',\n              'max_depth': 3,\n              'booster': 'gbtree', \n              'reg_lambda': 45.1,\n              'reg_alpha': 34.9,\n              'random_state': 42,\n              'reg_lambda': 0.00087,\n              'reg_alpha': 23.132}\n\nmodel_XGB = XGBRegressor(**xgb_params)\nmodel_XGB.fit(X_train, y_train) \npred_XGB = model_XGB.predict(X_valid)\nprint(mean_squared_error(y_valid, pred_XGB, squared=False))","c1f6554a":"predictions = model_rf.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)\n","add36b38":"# One Hot Encoding for Encoding Categorical Features","842e2e06":"# Target distribution","adcd661b":"The distribution in train data and test data are simillor","cc3d00bf":"# Making a Submission","75d7a933":"# XG BOOST","e4b6e771":"No null values","b94eb459":"# RANDOM FOREST"}}