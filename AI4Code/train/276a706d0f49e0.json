{"cell_type":{"616ceb9e":"code","50423b96":"code","9637284e":"code","e6ec4dd9":"code","c6fc3f67":"code","5d127fa1":"code","2e672fbe":"code","2ecdfe47":"code","46c6dc3a":"code","f96ccd3d":"code","06fd5744":"code","628bb05c":"code","7145743e":"code","6fe67ecc":"code","70cfc1fc":"code","1bdfe003":"code","9991663c":"code","0b47f6d7":"code","a67cfd7d":"code","5fd96103":"code","c3991000":"code","62964284":"code","a9390c4b":"code","8fcac981":"code","fbb05c0f":"code","5275c03e":"code","a88dfe47":"code","edf05a8b":"code","05086e72":"code","82f2e1a4":"code","f17c3c69":"markdown","2cb1df0b":"markdown","46d80ee9":"markdown","775300c0":"markdown","66669395":"markdown","6bcdb41e":"markdown","51c7ae5c":"markdown","459ca075":"markdown","b95b83ba":"markdown","55e89d35":"markdown","49ca4349":"markdown","3d210727":"markdown","bc09c139":"markdown","d68788d1":"markdown","81c8ef73":"markdown","5ab61732":"markdown","5fa91fc6":"markdown","881298ee":"markdown","e039df22":"markdown","6baaef1e":"markdown","c925a1a6":"markdown","c41fe703":"markdown","9a86a8ba":"markdown","8626cfb4":"markdown","b40601a7":"markdown"},"source":{"616ceb9e":"%%HTML\n<style type=\"text\/css\">\n\ndiv.h2 {\n    background-color: steelblue; \n    color: white; \n    padding: 8px; \n    padding-right: 300px; \n    font-size: 20px; \n    max-width: 1500px; \n    margin: auto; \n    margin-top: 50px;\n}\ndiv.h3 {\n    color: steelblue; \n    font-size: 14px; \n    margin-top: 20px; \n    margin-bottom:4px;\n}\ndiv.h4 {\n    font-size: 15px; \n    margin-top: 20px; \n    margin-bottom: 8px;\n}\nspan.note {\n    font-size: 5; \n    color: gray; \n    font-style: italic;\n}\nspan.captiona {\n    font-size: 5; \n    color: dimgray; \n    font-style: italic;\n    margin-left: 130px;\n    vertical-align: top;\n}\nhr {\n    display: block; \n    color: gray\n    height: 1px; \n    border: 0; \n    border-top: 1px solid;\n}\nhr.light {\n    display: block; \n    color: lightgray\n    height: 1px; \n    border: 0; \n    border-top: 1px solid;\n}\ntable.dataframe th \n{\n    border: 1px darkgray solid;\n    color: black;\n    background-color: white;\n}\ntable.dataframe td \n{\n    border: 1px darkgray solid;\n    color: black;\n    background-color: white;\n    font-size: 14px;\n    text-align: center;\n} \ntable.rules th \n{\n    border: 1px darkgray solid;\n    color: black;\n    background-color: white;\n    font-size: 14px;\n}\ntable.rules td \n{\n    border: 1px darkgray solid;\n    color: black;\n    background-color: white;\n    font-size: 13px;\n    text-align: center;\n} \ntable.rules tr.best\n{\n    color: green;\n}\n\n<\/style>","50423b96":"# Core\nimport pandas as pd\nimport numpy as np\n# Data Visualization\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nimport matplotlib.pyplot as plt\n# SKlearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score\n# PyTorch \nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n# Transformers \nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n# Catalyst\nfrom catalyst.dl import SupervisedRunner\nfrom catalyst.dl.callbacks import AccuracyCallback, F1ScoreCallback, OptimizerCallback\nfrom catalyst.dl.callbacks import CheckpointCallback, InferCallback\nfrom catalyst.utils import set_global_seed, prepare_cudnn\n# Extras\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport logging\nfrom typing import Mapping, List\nimport datetime as dt\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nfrom IPython.display import HTML, Image\n# Better Reports\npd.set_option(\"display.max_columns\", 100)\nth_props = [('font-size', '13px'), ('background-color', 'white'), \n            ('color', '#666666')]\ntd_props = [('font-size', '15px'), ('background-color', 'white')]\nstyles = [dict(selector=\"td\", props=td_props), dict(selector=\"th\", \n            props=th_props)]\n# Plots visualization improvement\n%config InlineBackend.figure_format = 'retina'","9637284e":"# It's a good practice to save on a plain text the modules and its versions\n# It's help others when running your experiments\n!pip freeze > requirements.txt","e6ec4dd9":"data_path = \"\/kaggle\/input\/news-category-dataset\/\"\ndata = pd.read_json(data_path+\"News_Category_Dataset_v2.json\", lines=True)","c6fc3f67":"# General Info\ndisplay(HTML('<span style=\"font-weight:bold\">' + 'Table 1 - General Dataset Information'\\\n             + '<\/span>'),data.head(3)) \nprint(f\"Number of Samples: {data.shape[0]}\")\nprint(f\"Number of Features: {data.shape[1]}\")\n# Missing Values\naux = data.isnull().sum()\/data.shape[0] * 100.00\nif sum(aux) == 0:\n    print(\"No Missing Data!\")\nelse:\n    aux = aux[aux > 0]\n    aux = pd.DataFrame({'Feature': aux.index,\n                    'Percent_Missing': aux.values})\n    aux.sort_values('Percent_Missing', inplace=True)\n    display(aux)","5d127fa1":"data['category'].value_counts().plot(kind='barh', figsize=(15,10))\nplt.xlabel(\"Total\")\nplt.ylabel(\"Category\")\nplt.title(\"Figure 1 - Category Distribution on HuffPost News (2012-2018)\",\n          fontweight=\"bold\", size=12);","2e672fbe":"data['category']=data['category'].replace({\"HEALTHY LIVING\": \"WELLNESS\",\n\"QUEER VOICES\": \"GROUPS VOICES\",\n\"BUSINESS\": \"BUSINESS & FINANCES\",\n\"PARENTS\": \"PARENTING\",\n\"BLACK VOICES\": \"GROUPS VOICES\",\n\"THE WORLDPOST\": \"WORLD NEWS\",\n\"STYLE\": \"STYLE & BEAUTY\",\n\"GREEN\": \"ENVIRONMENT\",\n\"TASTE\": \"FOOD & DRINK\",\n\"WORLDPOST\": \"WORLD NEWS\",\n\"SCIENCE\": \"SCIENCE & TECH\",\n\"TECH\": \"SCIENCE & TECH\",\n\"MONEY\": \"BUSINESS & FINANCES\",\n\"ARTS\": \"ARTS & CULTURE\",\n\"COLLEGE\": \"EDUCATION\",\n\"LATINO VOICES\": \"GROUPS VOICES\",\n\"CULTURE & ARTS\": \"ARTS & CULTURE\",\n\"FIFTY\": \"MISCELLANEOUS\",\n\"GOOD NEWS\": \"MISCELLANEOUS\"})","2ecdfe47":"data['category'].value_counts().plot(kind='barh', figsize=(15,10))\nplt.xlabel(\"Total\")\nplt.ylabel(\"Category\")\nplt.title(\"Figure 2 - Merged Category Distribution on HuffPost News (2012-2018)\",\n          fontweight=\"bold\", size=12);","46c6dc3a":"categories = data[\"category\"].unique()\naux = []\nj = 0\nfor i in categories:\n    df_aux = data[data[\"category\"] == i]\n    aux.append(np.mean(df_aux['headline'].apply(lambda x : len(x.split()))))\n    j = j+1\n\ndf_aux = pd.DataFrame({\n    \"Category\" : categories,\n    \"Average\": aux\n}\n)\n\ndf_aux = df_aux.sort_values(['Average'], ascending=False).reset_index(drop=True)\n\nsns.set(rc={'figure.figsize':(15,8)})\n\nax = sns.barplot(x=\"Category\", y=\"Average\", data=df_aux, palette=\"Blues_d\")\nplt.title(\"Figure 3 - Average Word Length in Headlines by Category\",\n          fontweight=\"bold\", size=12)\nplt.xticks(rotation=80);","f96ccd3d":"categories = data[\"category\"].unique()\naux = []\nj = 0\nfor i in categories:\n    df_aux = data[data[\"category\"] == i]\n    aux.append(np.mean(df_aux['short_description'].apply(lambda x : len(x.split()))))\n    j = j+1\n\ndf_aux = pd.DataFrame({\n    \"Category\" : categories,\n    \"Average\": aux\n}\n)\n\ndf_aux = df_aux.sort_values(['Average'], ascending=False).reset_index(drop=True)\n\nsns.set(rc={'figure.figsize':(15,8)})\n\nax = sns.barplot(x=\"Category\", y=\"Average\", data=df_aux, palette=\"Blues_d\")\nplt.title(\"Figure 4 - Average Word Length in Short Descriptions by Category\",\n          fontweight=\"bold\", size=12)\nplt.xticks(rotation=80);","06fd5744":"data[\"year\"] = data[\"date\"].dt.year\ndf_aux = data['year'].value_counts()\ndf_aux = pd.DataFrame({'Year': df_aux.index,\n                    'Count': df_aux.values})\ndf_aux = df_aux.sort_values(['Count'], ascending=False).reset_index(drop=True)\nax = sns.lineplot(x=\"Year\", y=\"Count\", data=df_aux)\nplt.title(\"Figure 5 - News Posted Through the Years (2012-2018)\",\n          fontweight=\"bold\", size=12);","628bb05c":"df_aux_a = data[data[\"year\"] == 2013]\ndf_aux_b = data[data[\"year\"] == 2017]\n\nfig, axes = plt.subplots(nrows=1, ncols=2)\ndf_aux_a['category'].value_counts().sort_values(ascending=False).plot(kind='bar', ax=axes[0], figsize=(166,8),\n                                                                     title=\"Figure 6(a) - News Category Distribution (2013)\")\ndf_aux_b['category'].value_counts().sort_values(ascending=False).plot(kind='bar', ax=axes[1], figsize=(16,8), \n                                                                     title=\"Figure 6(b) - News Category Distribution (2017)\");","7145743e":"stopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(background_color='white',\n                      max_words=100,\n                      width=500,\n                      height=500\n)\n\nwordcloud.generate(str(data.query('year == 2013')['short_description']))\nplt.rcParams['figure.figsize'] = (8,8)\nplt.axis('off')\nplt.suptitle('Figure 7 - Short Descriptions Word Cloud (2013)', fontsize=16, fontweight='bold')\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.show()","6fe67ecc":"wordcloud = WordCloud(background_color='white',\n                      max_words=100,\n                      width=500,\n                      height=500\n)\n\nwordcloud.generate(str(data.query('year == 2017')['short_description']))\nplt.rcParams['figure.figsize'] = (8,8)\nplt.axis('off')\nplt.suptitle('Figure 8 - Short Descriptions Word Cloud (2017)', fontsize=16, fontweight='bold')\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.show()","70cfc1fc":"aux = pd.DataFrame(\n    {\n        \"Setting\": [\"Model Name\", \"Number of Epochs\", \"Batch Size\",\n                   \"Max Sequence Length\", \"Learning Rate\", \"Accumulation Steps\",\n                   \"Random Seed\"],\n        \"Value\": [\"distilbert-base-uncased\", 3, 80, 256, 5e-5, 4, 42]\n    }\n)\n\ndisplay(HTML('<span style=\"font-weight:bold\">' + 'Table 2 - Model Setup'\\\n             + '<\/span>'),aux) ","1bdfe003":"MODEL_NAME = \"distilbert-base-uncased\"\nLOG_DIR = \".\/news-classification\"    \nNUM_EPOCHS = 3                         \nBATCH_SIZE = 80                        \nMAX_SEQ_LENGTH = 256                   \nLEARN_RATE = 5e-5                      \nACCUM_STEPS = 4                        \nSEED = 42                              \nFP16_PARAMS = None","9991663c":"%%writefile setup.sh\ngit clone https:\/\/github.com\/NVIDIA\/apex\ncd apex\npip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\/\nrm -rf .\/apex","0b47f6d7":"%%capture\n!sh setup.sh\nFP16_PARAMS = dict(opt_level=\"O1\") ","a67cfd7d":"# Use it if you need just to test if the model is working\n# with a few samples\n#data = data.head(1000)","5fd96103":"text = pd.DataFrame({\n    \"text\" : data.headline+\" \"+data.short_description,\n    \"label\" : data.category  \n})\n\ntrain, val = train_test_split(\n    text, test_size=0.30, random_state=SEED)\n\ntrain.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)\n\nval, test = train_test_split(\n    val, test_size=0.10, random_state=SEED)\n\nval.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)\n\ntest_true = pd.DataFrame({\n    \"label\" : test.label\n})\n\ntest.drop(columns=[\"label\"], axis=1, inplace=True)\n\n#del data","c3991000":"class TextClassificationDataset(Dataset):\n\n    def __init__(self,\n                 texts: List[str],\n                 labels: List[str] = None,\n                 label_dict: Mapping[str, int] = None,\n                 max_seq_length: int = 512,\n                 model_name: str = 'distilbert-base-uncased'):\n\n        self.texts = texts\n        self.labels = labels\n        self.label_dict = label_dict\n        self.max_seq_length = max_seq_length\n\n        if self.label_dict is None and labels is not None:\n            self.label_dict = dict(zip(sorted(set(labels)),\n                                       range(len(set(labels)))))\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        logging.getLogger(\n            \"transformers.tokenization_utils\").setLevel(logging.FATAL)\n\n        self.sep_vid = self.tokenizer.vocab[\"[SEP]\"]\n        self.cls_vid = self.tokenizer.vocab[\"[CLS]\"]\n        self.pad_vid = self.tokenizer.vocab[\"[PAD]\"]\n\n    def __len__(self):\n\n        return len(self.texts)\n\n    def __getitem__(self, index) -> Mapping[str, torch.Tensor]:\n\n        x = self.texts[index]\n        x_encoded = self.tokenizer.encode(\n            x,\n            add_special_tokens=True,\n            max_length=self.max_seq_length,\n            return_tensors=\"pt\",\n        ).squeeze(0)\n\n        true_seq_length = x_encoded.size(0)\n        pad_size = self.max_seq_length - true_seq_length\n        pad_ids = torch.Tensor([self.pad_vid] * pad_size).long()\n        x_tensor = torch.cat((x_encoded, pad_ids))\n\n        mask = torch.ones_like(x_encoded, dtype=torch.int8)\n        mask_pad = torch.zeros_like(pad_ids, dtype=torch.int8)\n        mask = torch.cat((mask, mask_pad))\n\n        output_dict = {\n            \"features\": x_tensor,\n            'attention_mask': mask\n        }\n\n        if self.labels is not None:\n            y = self.labels[index]\n            y_encoded = torch.Tensor(\n                [self.label_dict.get(y, -1)]\n            ).long().squeeze(0)\n            output_dict[\"targets\"] = y_encoded\n\n        return output_dict","62964284":"train_dataset = TextClassificationDataset(\n    texts=train['text'].values.tolist(),\n    labels=train['label'].values.tolist(),\n    label_dict=None,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)\n\nvalid_dataset = TextClassificationDataset(\n    texts=val['text'].values.tolist(),\n    labels=val['label'].values.tolist(),\n    label_dict=train_dataset.label_dict,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)\n\ntest_dataset = TextClassificationDataset(\n    texts=test['text'].values.tolist(),\n    labels=None,\n    label_dict=None,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)","a9390c4b":"NUM_CLASSES = len(train_dataset.label_dict)","8fcac981":"train_val_loaders = {\n    \"train\": DataLoader(dataset=train_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=True),\n    \"valid\": DataLoader(dataset=valid_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=False)    \n}","fbb05c0f":"class DistilBertForSequenceClassification(nn.Module):\n\n    def __init__(self, pretrained_model_name: str, num_classes: int = None):\n\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(\n            pretrained_model_name, num_labels=num_classes)\n\n        self.distilbert = AutoModel.from_pretrained(pretrained_model_name,\n                                                    config=config)\n        self.pre_classifier = nn.Linear(config.dim, config.dim)\n        self.classifier = nn.Linear(config.dim, num_classes)\n        self.dropout = nn.Dropout(config.seq_classif_dropout)\n\n    def forward(self, features, attention_mask=None, head_mask=None):\n\n        assert attention_mask is not None, \"attention mask is none\"\n        distilbert_output = self.distilbert(input_ids=features,\n                                            attention_mask=attention_mask,\n                                            head_mask=head_mask)\n\n        hidden_state = distilbert_output[0]  \n        pooled_output = hidden_state[:, 0] \n        pooled_output = self.pre_classifier(pooled_output)  \n        pooled_output = nn.ReLU()(pooled_output)  \n        pooled_output = self.dropout(pooled_output)  \n        logits = self.classifier(pooled_output)  \n\n        return logits","5275c03e":"model = DistilBertForSequenceClassification(pretrained_model_name=MODEL_NAME,\n                                            num_classes=NUM_CLASSES)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)","a88dfe47":"os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"   \nset_global_seed(SEED)                       \nprepare_cudnn(deterministic=True)           ","edf05a8b":"%%time \nrunner = SupervisedRunner(\n    input_key=(\n        \"features\",\n        \"attention_mask\"\n    )\n)\n\nrunner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    loaders=train_val_loaders,\n    callbacks=[\n        AccuracyCallback(num_classes=NUM_CLASSES),\n#       F1ScoreCallback(activation='Softmax'), # Tried it, but got an error on tensor shape\n        OptimizerCallback(accumulation_steps=ACCUM_STEPS)\n    ],\n    fp16=FP16_PARAMS,\n    logdir=LOG_DIR,\n    num_epochs=NUM_EPOCHS,\n    verbose=True\n)","05086e72":"test_loaders = {\n    \"test\": DataLoader(dataset=test_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=False) \n}\n\nrunner.infer(\n    model=model,\n    loaders=test_loaders,\n    callbacks=[\n        CheckpointCallback(\n            resume=f\"{LOG_DIR}\/checkpoints\/best.pth\"\n        ),\n        InferCallback(),\n    ],   \n    verbose=True\n)","82f2e1a4":"predicted_probs = runner.state.callbacks[0].predictions['logits']\ntest_pred = pd.DataFrame(\n    {\n        \"label\": predicted_probs.argmax(axis=1)\n    }\n)\ntest_pred[\"label\"] = test_pred[\"label\"].map({v:k for k, v in train_dataset.label_dict.items()})\n\nunique_label = train[\"label\"].unique()\ncmtx = pd.DataFrame(\n    confusion_matrix(test_true, test_pred, labels=unique_label), \n    index=['{:}'.format(x) for x in unique_label], \n    columns=['{:}'.format(x) for x in unique_label]\n)\n\nplt.figure(figsize=(15, 10))\nax = sns.heatmap(cmtx, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\nax.set_ylabel('Predicted')\nax.set_xlabel('Target');\nax.set_title(\"Figure 9 - Test Set Confusion Matrix\", size=12)\n\nacc = accuracy_score(test_true, test_pred)\nprec = precision_score(test_true, test_pred, average=\"weighted\")\nf1 = f1_score(test_true, test_pred, average=\"weighted\")\nprint(f\"Test Accuracy: {acc}\")\nprint(f\"Test Precision: {prec}\")\nprint(f\"Test F1 Score: {f1}\");","f17c3c69":"<a id='cc'><\/a>\n<div class=\"h2\">Category Classification<\/div>\n<br>\nOn this section is made the prediction of the News Categories.<br>\nThe DistilBERT model is trained with FP16, just changing to Floating Point 32 (FP32) when needed. This [Kernel](https:\/\/www.kaggle.com\/kashnitsky\/distillbert-catalyst-amazon-product-reviews) is a great guide on how to work with it.<br>\nOn the Table 2 is shown the model setup","2cb1df0b":"And define the number of classes of the output feature based on the train set.","46d80ee9":"Finally, the load the model with the criterion, optimizer and learning rate scheduler.<br>\nAnd setting the GPU devices to use and Random Seed.","775300c0":"<a id='end'><\/a>\n<div class=\"h2\">Conclusion<\/div>\n<br>\nOn the EDA, was shwon that HuffPost changed a lot its content from the year, from a website with many posts about wellness to a site with opinions and news about politics.<br> \nAs seen by the results, the three metrics got a good score (above 0.7) and the matrix confusion revealed a few samples with wrong classification.<br> DistilBERT showed how can it be powerful for NLP.<br>","66669395":"The Figure 5 shows a peak on the amount of posts on the year of 2013 and the lowest amount on 2018, but why?<br>\nThe Dataset was published in 2018, maybe the not get the news for the whole year like the pasts, then the lowest point is 2017 for the analysis.<br>\nAnd what content was posted in 2013 and 2017? The Figure 6 shows the distributuion.","6bcdb41e":"It's curious to note on the figure 6 how HuffPost changed its content in four yers, from many posts about wellness to 2013 from much more posts about politcs in 2017.<br>\nLet's see the wordclouds for these years on the Figures 7 and 8.","51c7ae5c":"For the `short_description` the differences are big! Maybe it will helpful to use as input on the classification model.<br>\nLet's see how many the news were posted through the years on the Figure 5.","459ca075":"On the Figure 7, can be seen positive words like \"beautiful\", related to wellness, while on the Figure 8 can be seen words like \"Nations\", \"Sanctions\" and \"protests\", related to Politcs.<br>\n<br>\nThis concludes the EDA.","b95b83ba":"When working with PyTorch, the sets need to be loaded in dictionaries.","55e89d35":"Kaggle Kernels doesn't has Apex installed by default. The following two blocks of code have the scripts to install it.","49ca4349":"To finish it, let's make an inference on Test Set to predict the results later.","3d210727":"The model training starts now with Catalyst doing a good amount of work.","bc09c139":"# Predicting News Category with DistilBERT\n<p style=\"margin-top:40px\"> \nSections:  <\/p>\n\n  - <a href='#bg'>Introduction<\/a>\n  - <a href='#il'>Import Modules and Load Data<\/a>\n  - <a href='#eda'>Exploratory Data Analysis<\/a>\n  - <a href='#cc'>Category Classification<\/a>\n  - <a href='#re'>Results<\/a>\n  - <a href='#end'>Conclusion<\/a>","d68788d1":"![](https:\/\/cinedapt.com\/wp-content\/uploads\/2019\/11\/huffpost-logo.png)","81c8ef73":"PyTorch uses a specific input called tensors, all the dataset needs to be converted to tensors.<br>\nIt's needed to create a class to convert to tensors and after load every set (Train, Validation and Test).","5ab61732":"<a id='bg'><\/a>\n<div class=\"h2\">Introduction<\/div>\n<br>\n[HuffPost](https:\/\/www.huffpost.com\/) is an american website about opinions and news like politcs, culture, wellness, etc. It was founded in 2005 by Andrew Breitbart, Arianna Huffington, Kenneth Lerer, and Jonah Peretti. The dataset provides data from 2012 to 2018.<br>\n<br>\nIn this work is made a exploratory data analysis (EDA) and category classification of the news posted in HuffPost using the Headlines and Short Descriptions of these news.<br>\nFor the EDA, Headlines, Short Descriptions and Categories are analysed through the years, and for the classification task, it's used a lighter version of the popular Natural Language Processing (NLP) framework [BERT](https:\/\/arxiv.org\/abs\/1810.04805) developed by Google, called [DistilBERT](https:\/\/medium.com\/huggingface\/distilbert-8cf3380435b5), in this developed by huggingface.<br>\n<br>\nThe code is hidden for a better notebook readbility. Anytime it's possible to click on the code button to see the script content.","5fa91fc6":"<a id='eda'><\/a>\n<div class=\"h2\">  Exploratory Data Analysis<\/div>\n<br>\nA good way to start an EDA is showing the General Information about the available data. It's summarized on the Table 1.","881298ee":"And now the distribution seems a little better in the categories presents in a few samples.<br>\nContinuing the exploration, time to check how is the content on the `headline` feature. The Figure 3 shows the Average Word Length of the Headlines for each category.","e039df22":"<a id='il'><\/a>\n<div class=\"h2\">  Import Modules and Load Data<\/div>\n<br>\nFor the task, the data is organized in DataFrames for the EDA and on Tensors for the classification. All the plots are made with Pandas, Matplotlib or Seaborn.<br>\n[PyTorch](https:\/\/pytorch.org\/), [Catalyst](https:\/\/github.com\/catalyst-team\/catalyst) and [NVIDIA Apex](https:\/\/github.com\/NVIDIA\/apex) are used on the classification task using Deep Learning, the pre-trained DistilBERT model. <br>\n<br>\nPyTorch has been my weapon of choice when working with Deep Learning, Catalyst is a wonderful PyTorch tool to make the train more clean and with a focus on reproducibility and Apex allow to use Floating Point 16 (FP16) to speed up the train, using [Mixed-precision training](https:\/\/devblogs.nvidia.com\/mixed-precision-training-deep-neural-networks\/).","6baaef1e":"Some categories are just the same with different names, like `WORLDPOST` and `THE WORLDPOSt`, to fix it and remove some imbalance from the data (`POLITCS` is present in a lot of samples), the similar categories are merged and the new distribution is shown on the Figure 2.","c925a1a6":"<a id='re'><\/a>\n<div class=\"h2\">Results<\/div>\n<br>\nWith the Inference made on the Test Set, let's predict the probabilities of classes for each samples and get class with the high probability and save as the prediction.<br>\nThe Results for the accuracy, precision and F1 Score for the Test Set are given followed by the Confusion Matrix on The Figure 9.","c41fe703":"A class defines the model with its forward pass.","9a86a8ba":"There's a little difference in the average for each category, about two points, making each to similar in length, but how about `short_description`?<br>\nThe Figure 4 shows the results for this feature.","8626cfb4":"The Dataset is split in 70% for the Train set and 30% for the Validation set.<br>\nA Test set with separeted labels is created from 10% of the Validation set.","b40601a7":"And the dataset has a good amount of data, about 200000 samples. The feature to be predict is `category`.<br>\nAll EDA uses `category`, `headline`, `short_description` and `date` features.<br>\nThere's no missing data on this dataset and it's very good for unstructured data.<br>\nA check on Category Distributuon as shown on the Figure 1."}}