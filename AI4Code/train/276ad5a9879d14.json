{"cell_type":{"0acc9b3f":"code","6eadd993":"code","715fd13b":"code","0ab6d845":"code","a3df36c2":"code","1d1cc2a5":"code","80616594":"code","2c136bf1":"code","cb0fe882":"code","c791c775":"code","9a6b16f0":"code","e394a972":"code","3d07327a":"code","4434bc50":"code","d9e3dfd9":"code","06bb3ff8":"code","1be3e17f":"code","e485b80d":"code","0564e1dc":"code","7bcc5c27":"code","beec5316":"code","ae18fa1b":"code","d863d46b":"code","185c61d3":"code","82c35fb4":"code","151d45a3":"code","b5ceb1bd":"code","bf3e7140":"code","28e12830":"code","0c297035":"code","fcc1dbb5":"code","55e422bc":"code","f73e7156":"code","4e786dae":"code","60b55ca4":"code","50525e13":"code","bfec3257":"code","2878ea6a":"code","41641953":"code","98d4a987":"code","91e02f3e":"code","62dc92d1":"code","b21c8d1b":"code","46a224bc":"code","0f4cb52c":"code","1aa47be5":"code","2ae8835e":"code","039a34b4":"code","e9dd49a8":"code","91290449":"code","d02a56de":"code","e19decc6":"code","9741b612":"code","741a71d5":"code","4616d5c9":"code","88e99848":"code","bb805304":"code","eeb52041":"code","e2fd16f1":"code","aa540b86":"code","223a779c":"code","488a4015":"code","079fcfcc":"code","164ebeb3":"code","e1ad9059":"code","1ad94243":"code","0cde82a8":"code","b22d6d99":"code","7c5d1029":"markdown","4e55ae78":"markdown","625f4dcf":"markdown","515f4d0d":"markdown","d724e56b":"markdown","83f15b49":"markdown","cbe30b91":"markdown","6c41f534":"markdown","c14c6eeb":"markdown","b92ce54f":"markdown","18dc0832":"markdown","abf1a131":"markdown","121ed2de":"markdown","2906fed3":"markdown","4c5904a6":"markdown","3d850083":"markdown","8d345098":"markdown","df890d05":"markdown","acb7a0b3":"markdown","52503d28":"markdown","02f4bb70":"markdown","89f79781":"markdown","c253c2d5":"markdown","dacb3d3e":"markdown","00906870":"markdown","d6d5bcc0":"markdown","ea866269":"markdown","06907373":"markdown","52c1a033":"markdown","56cfce86":"markdown","7b0eacfa":"markdown","d7ccf549":"markdown","6c57ee4c":"markdown","0cffb092":"markdown","d328f5a6":"markdown","bcec545b":"markdown","de9ece9c":"markdown","02214ad6":"markdown","ff7cc2cc":"markdown","762e6476":"markdown","9fbeba93":"markdown","26cdcb04":"markdown","03451020":"markdown","e046c0f1":"markdown","4223650a":"markdown","051024f9":"markdown","d937b0be":"markdown","186ee225":"markdown","be55049f":"markdown","f12c759d":"markdown","bc226de0":"markdown","3b772cf8":"markdown","fb3b2b63":"markdown","35d96681":"markdown","582b522d":"markdown","9c955fcc":"markdown","743b2242":"markdown","2ff1daab":"markdown","0697cee4":"markdown","892dcc27":"markdown","0035ab2b":"markdown"},"source":{"0acc9b3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6eadd993":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","715fd13b":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")","0ab6d845":"train_data.head()","a3df36c2":"train_data.tail()","1d1cc2a5":"train_data.columns","80616594":"print('lenght of data is', len(train_data))","2c136bf1":"train_data.shape","cb0fe882":"train_data.info()","c791c775":"train_data.dtypes","9a6b16f0":"train_data[train_data.isnull().any(axis=1)].head()","e394a972":"np.sum(train_data.isnull().any(axis=1))","3d07327a":"train_data.isnull().values.any()","4434bc50":"train_data.isnull().sum()","d9e3dfd9":"NANColumns=[]\ni=-1\nfor a in train_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(train_data.columns[i],a)\n        NANColumns.append(train_data.columns[i])","06bb3ff8":"carrier_count = train_data[\"Pclass\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of pclass')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('pclass', fontsize=12)\nplt.show()","1be3e17f":"train_data[\"Pclass\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","e485b80d":"carrier_count = train_data[\"Survived\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of survived    ')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('survived    ', fontsize=12)\nplt.show()","0564e1dc":"train_data[\"Survived\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","7bcc5c27":"train_data[\"Sex\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","beec5316":"train_data[\"Age\"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","ae18fa1b":"train_data[\"Embarked\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","d863d46b":"train_data.hist(figsize=(15,12),bins = 20, color=\"#107009AA\")\nplt.title(\"Features Distribution\")\nplt.show()","185c61d3":"test_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nids_test_data = test_data['PassengerId'].values","82c35fb4":"test_data.head()","151d45a3":"test_data.columns","b5ceb1bd":"print('lenght of data is', len(test_data))","bf3e7140":"test_data.info()","28e12830":"test_data[test_data.isnull().any(axis=1)].head()","0c297035":"np.sum(test_data.isnull().any(axis=1))","fcc1dbb5":"test_data.isnull().values.any()","55e422bc":"test_data.isnull().sum()","f73e7156":"NANColumns=[]\ni=-1\nfor a in test_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(test_data.columns[i],a)\n        NANColumns.append(test_data.columns[i])","4e786dae":"carrier_count = test_data[\"Pclass\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of pclass')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('pclass', fontsize=12)\nplt.show()","60b55ca4":"test_data[\"Pclass\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","50525e13":"test_data[\"Sex\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","bfec3257":"test_data[\"Age\"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","2878ea6a":"test_data[\"Embarked\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","41641953":"test_data.hist(figsize=(15,12),bins = 20, color=\"#107009AA\")\nplt.title(\"Features Distribution\")\nplt.show()","98d4a987":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_data.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","91e02f3e":"train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","62dc92d1":"train_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","b21c8d1b":"train_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","46a224bc":"train_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","0f4cb52c":"g = sns.FacetGrid(train_data, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","1aa47be5":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","2ae8835e":"grid = sns.FacetGrid(train_data, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","039a34b4":"y = train_data[\"Survived\"]","e9dd49a8":"all_data = pd.concat([train_data,test_data],axis=0).reset_index(drop=True)","91290449":"all_data = all_data.drop([\"Survived\",\"PassengerId\"],axis=1)","d02a56de":"def missing_value(df):\n    number = df.isnull().sum().sort_values(ascending=False)\n    number = number[number > 0]\n    percentage = df.isnull().sum() *100 \/ df.shape[0]\n    percentage = percentage[percentage > 0].sort_values(ascending=False)\n    return  pd.concat([number,percentage],keys=[\"Total\",\"Percentage\"],axis=1)\nmissing_value(all_data)","e19decc6":"## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features\nall_data[\"Cabin\"] = all_data[\"Cabin\"].transform(lambda x: x.fillna(x.mode()[0]))","9741b612":"## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features\nall_data[\"Embarked\"] = all_data[\"Embarked\"].transform(lambda x: x.fillna(x.mode()[0]))","741a71d5":"#Mapping the Age into 5 groups from 0 to 4\nall_data['Age']=all_data.loc[ all_data['Age'] <= 16, 'Age'] = 0\nall_data['Age']=all_data.loc[(all_data['Age'] > 16) & (all_data['Age'] <= 32), 'Age'] = 1\nall_data['Age']=all_data.loc[(all_data['Age'] > 32) & (all_data['Age'] <= 48), 'Age'] = 2\nall_data['Age']=all_data.loc[(all_data['Age'] > 48) & (all_data['Age'] <= 64), 'Age'] = 3\nall_data['Age']=all_data.loc[ all_data['Age'] > 64, 'Age'] = 4","4616d5c9":"#Mapping the Fare into 5 groups from 0 to 4\nall_data['Fare']=all_data.loc[ all_data['Fare'] <= 7.91, 'Fare'] = 0\nall_data['Fare']=all_data.loc[(all_data['Fare'] > 7.91) & (all_data['Fare'] <= 14.454), 'Fare'] = 1\nall_data['Fare']=all_data.loc[(all_data['Fare'] > 14.454) & (all_data['Fare'] <= 31), 'Fare']   = 2\nall_data['Fare']=all_data.loc[ all_data['Fare'] > 31, 'Fare'] = 3\nall_data['Fare']=all_data['Fare'] = all_data['Fare'].astype(int)","88e99848":"#Checking missing values now\nmissing_value(all_data)","bb805304":"all_data = pd.get_dummies(all_data).reset_index(drop=True)","eeb52041":"n = len(y)\ntrain_data = all_data[:n]\ntest_data = all_data[n:]","e2fd16f1":"X = np.array(train_data)\ny = np.array(y)","aa540b86":"rf = RandomForestClassifier(min_samples_leaf=1, min_samples_split=2)\nkf = KFold(n_splits=5)\noutcomes1 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes1.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome1 = np.mean(outcomes1)\nprint(\"Total Average Accuracy of Random Forest Classifier is : {0}\".format(mean_outcome1))","223a779c":"rf = KNeighborsClassifier(n_neighbors=2)\nkf = KFold(n_splits=5)\noutcomes2 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes2.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome2 = np.mean(outcomes2)\nprint(\"Total Average Accuracy of KNN Classifier is : {0}\".format(mean_outcome2))","488a4015":"rf = DecisionTreeClassifier(random_state=10)\nkf = KFold(n_splits=5)\noutcomes3 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes3.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome3 = np.mean(outcomes3)\nprint(\"Total Average Accuracy of Decision Trees Classifier is : {0}\".format(mean_outcome3))","079fcfcc":"a=pd.DataFrame()\na['outcomes1']=outcomes1\na['outcomes2']=outcomes2\na['outcomes3']=outcomes3\n\nplt.figure(figsize=(25, 10))\nplt.subplot(1,1,1)\nplt.plot(a.outcomes1.values,color='blue',label='Random Forest')\nplt.plot(a.outcomes2.values,color='green',label='KNN')\nplt.plot(a.outcomes3.values,color='red',label='Decision Trees')\nplt.title('Algorithms Comparison')\nplt.xlabel('Number of time')\nplt.ylabel('Accuracy')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()","164ebeb3":"a=a.rename(columns={'outcomes1':'Random Forest', 'outcomes2':'KNN','outcomes3':'Decision Tree'})\na.plot(kind='bar',figsize=(25, 10))","e1ad9059":"a","1ad94243":"final_model = DecisionTreeClassifier(min_samples_leaf=1, min_samples_split=2)\nfinal_model = final_model.fit(X,y)","0cde82a8":"submission_results = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission_results.iloc[:,1] = np.floor(np.expm1(final_model.predict(test_data)))\nsubmission_results.to_csv('submission_results', index=False)","b22d6d99":"# Save test predictions to file\nsubmission_results = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission_results.iloc[:,1] = np.floor(np.expm1(final_model.predict(test_data)))\nsubmission_results.to_csv('submission_results', index=False)","7c5d1029":"# **Frequency Distribution of pclass**","4e55ae78":"**Coloumns\/features in data**","625f4dcf":"**Comparison of all algorithms Results**","515f4d0d":"**Counts of missing values in each column**","d724e56b":"# **Exploratory data analysis of test data**","83f15b49":"# **Looking at correlated features with Survived**","cbe30b91":"# **Random Forest Algorithm**","6c41f534":"# **Building the models for training and testing**","c14c6eeb":"# **Frequency Distribution of pclass**","b92ce54f":"**Imputing the Missing Values of all data**","18dc0832":"**All features of train data distrubution**","abf1a131":"int = numrical features\nobject = categorical features","121ed2de":"# **Frequency Distribution of embarked**","2906fed3":"**A function for checking the missing values**","4c5904a6":"**Five last records of data**","3d850083":"# **Checking missing Values**","8d345098":"# **Embarked plot**","df890d05":"# **Pclass plot**","acb7a0b3":"# **Decision Tree Algorithm**","52503d28":"# ****Importing Python Libraries**","02f4bb70":"**Five top records of data**","89f79781":"# **Features engineering and preparation**","c253c2d5":"**Frequency Distribution of sex**","dacb3d3e":"**Is there any missing values?**","00906870":"**Is there any missing values?**","d6d5bcc0":"**Frequency Distribution of embarked**","ea866269":"**Data information**","06907373":"**Coloumns\/features in data**","52c1a033":"**Shape of data**","56cfce86":"**Length of data**","7b0eacfa":"# **Frequency Distribution of top 10 age**","d7ccf549":"# **Exploratory data analysis of train data**","6c57ee4c":"**Correlation Survived with SEX**","0cffb092":"**Count of missing values**","d328f5a6":"# **Loading training data**","bcec545b":"# **Age plot**","de9ece9c":"**Comparison of all algorithms Results**","02214ad6":"# **Frequency Distribution of survived**","ff7cc2cc":"# **Looking at the test data missing values.**","762e6476":"# **All features of test data distrubution**","9fbeba93":"**Five top records of data**","26cdcb04":"**Count of missing values**","03451020":"# ****Loading testing data**","e046c0f1":"**Frequency Distribution of top 10 age**","4223650a":"**Coverting the categorical features into numeric form by applying the get_dummies function**","051024f9":"**Correlation Survived with Parch**","d937b0be":"**Correlation Survived with Pclass**","186ee225":"**Combining the train and test dataset**","be55049f":"**Looking at the train data missing values.**","f12c759d":"# **KNN Algorithm**","bc226de0":"# **Best and final model**","3b772cf8":"# **Frequency Distribution of sex**","fb3b2b63":"**Data types of all coloumns**","35d96681":"**Checking missing Values**","582b522d":"**Correlation Survived with SibSp**","9c955fcc":"**Counts of missing values in each column**","743b2242":"**Now splitting the data for training and testing with same index ID's**","2ff1daab":"**Length of data**","0697cee4":"**Extract the Survived out from the train data**","892dcc27":"**Drop the Survived & PassengerId columns**","0035ab2b":"**Data information**"}}