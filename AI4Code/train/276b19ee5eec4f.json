{"cell_type":{"9e5aab4d":"code","66378a09":"code","c2764057":"code","6476ca8e":"code","ff585587":"code","3a2c6324":"code","c01fc47f":"code","f6e189f0":"code","f82cc270":"code","25dffb84":"code","124cf4b3":"code","0c3a23cd":"code","a3cd364e":"code","c70c863e":"code","12056ce3":"code","84433013":"code","2fe3e3e3":"code","82b51f3d":"code","7c0023b0":"code","2582e7af":"code","4fb6ae9a":"code","386beb77":"code","b9bd2995":"code","3f731549":"code","41a07c64":"code","95f033be":"code","36ad676c":"code","c5ac9427":"code","8e18b25b":"code","df157a1d":"markdown","421e2ffb":"markdown","3f403abc":"markdown"},"source":{"9e5aab4d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Dropout, LayerNormalization\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img","66378a09":"#load data\ndata = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_3_data.txt\",sep = \"\\t\" )\ndata1 = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_1_data.txt\",sep = \"\\t\")\ndata2 = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_2_data.txt\",sep = \"\\t\")\ndata3 = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_0_data.txt\",sep = \"\\t\")\ndata4 = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_4_data.txt\",sep = \"\\t\")","c2764057":"total_data = pd.concat([data, data1, data2, data3, data4], ignore_index=True)\nprint(data.shape)\nprint(total_data.shape)","6476ca8e":"total_data.info()","ff585587":"total_data.head()","3a2c6324":"#pie_graph\nplt.figure(1, figsize=(8,8))\ntotal_data.age.value_counts().plot.pie(autopct=\"%1.1f%%\")\nplt.show()","c01fc47f":"#bar chart\ngender = ['f','m','u']\nplt.bar(gender, total_data.gender.value_counts(), align='center', alpha=0.5)\nplt.show()","f6e189f0":"path = \"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/faces\/\"+total_data.user_id.loc[0]+\"\/coarse_tilt_aligned_face.\"+str(total_data.face_id.loc[0])+\".\"+total_data.original_image.loc[0]\nimg = load_img(path)\nplt.imshow(img)\nplt.show()","f82cc270":"total_data.gender.value_counts()","25dffb84":"df = total_data[['age', 'gender', 'x', 'y', 'dx', 'dy']].copy()\ndf.info()","124cf4b3":"img_path = []\nfor row in total_data.iterrows():\n    path = \"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/faces\/\"+row[1].user_id+\"\/coarse_tilt_aligned_face.\"+str(row[1].face_id)+\".\"+row[1].original_image\n    img_path.append(path)\n\ndf['img_path'] = img_path","0c3a23cd":"df.head()","a3cd364e":"age_mapping = [('(0, 2)', '0-2'), ('2', '0-2'), ('3', '0-2'), ('(4, 6)', '4-6'), ('(8, 12)', '8-13'), ('13', '8-13'), ('22', '15-20'), ('(8, 23)','15-20'), ('23', '25-32'), ('(15, 20)', '15-20'), ('(25, 32)', '25-32'), ('(27, 32)', '25-32'), ('32', '25-32'), ('34', '25-32'), ('29', '25-32'), ('(38, 42)', '38-43'), ('35', '38-43'), ('36', '38-43'), ('42', '48-53'), ('45', '38-43'), ('(38, 43)', '38-43'), ('(38, 42)', '38-43'), ('(38, 48)', '48-53'), ('46', '48-53'), ('(48, 53)', '48-53'), ('55', '48-53'), ('56', '48-53'), ('(60, 100)', '60+'), ('57', '60+'), ('58', '60+')]\n\nage_mapping_dict = {each[0]: each[1] for each in age_mapping}\ndrop_labels = []\nfor idx, each in enumerate(df.age):\n    if each == 'None':\n        drop_labels.append(idx)\n    else:\n        df.age.loc[idx] = age_mapping_dict[each]\n\ndf = df.drop(labels=drop_labels, axis=0) #droped None values\ndf.age.value_counts(dropna=False)","c70c863e":"df = df.dropna()\nunbiased_data = df[df.gender != 'u'].copy()\nunbiased_data.info()","12056ce3":"gender_to_label_map = {\n    'f' : 0,\n    'm' : 1\n}\n\nage_to_label_map = {\n    '0-2'  :0,\n    '4-6'  :1,\n    '8-13' :2,\n    '15-20':3,\n    '25-32':4,\n    '38-43':5,\n    '48-53':6,\n    '60+'  :7\n}\n\n# label_to_age_map = {value: key for key, value in age_to_label_map.items()}\n# label_to_gender_map = {value: key for key, value in gender_to_label_map.items()}\n\nunbiased_data['age'] = unbiased_data['age'].apply(lambda age: age_to_label_map[age])\nunbiased_data['gender'] = unbiased_data['gender'].apply(lambda g: gender_to_label_map[g])\n\nunbiased_data.head()","84433013":"X = unbiased_data[['img_path']]\ny = unbiased_data[['gender']]\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('Train data shape {}'.format(X_train.shape))\nprint('Test data shape {}'.format(X_test.shape))","2fe3e3e3":"train_images = []\ntest_images = []\n\nfor row in X_train.iterrows():\n    image = Image.open(row[1].img_path)\n    image = image.resize((227, 227))   # Resize the image\n    data = np.asarray(image)\n    train_images.append(data)\n\nfor row in X_test.iterrows():\n    image = Image.open(row[1].img_path)\n    image = image.resize((227, 227))  # Resize the image\n    data = np.asarray(image)\n    test_images.append(data)\n\ntrain_images = np.asarray(train_images)\ntest_images = np.asarray(test_images)\n\nprint('Train images shape {}'.format(train_images.shape))\nprint('Test images shape {}'.format(test_images.shape))","82b51f3d":"model = Sequential()\nmodel.add(Conv2D(input_shape=(227, 227, 3), filters=96, kernel_size=(7, 7), strides=4, padding='valid', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=2, activation='softmax'))","7c0023b0":"model.summary()","2582e7af":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\nhistory = model.fit(train_images, y_train, batch_size=32, epochs=5, validation_data=(test_images, y_test), callbacks=[callback])","4fb6ae9a":"# model.save('gender_model.h5')","386beb77":"test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\nprint(test_acc)","b9bd2995":"X = unbiased_data[['img_path']]\ny = unbiased_data[['age']]\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('Train data shape {}'.format(X_train.shape))\nprint('Test data shape {}'.format(X_test.shape))","3f731549":"train_images = []\ntest_images = []\n\nfor row in X_train.iterrows():\n    image = Image.open(row[1].img_path)\n    image = image.resize((227, 227))   # Resize the image\n    data = np.asarray(image)\n    train_images.append(data)\n\nfor row in X_test.iterrows():\n    image = Image.open(row[1].img_path)\n    image = image.resize((227, 227))  # Resize the image\n    data = np.asarray(image)\n    test_images.append(data)\n\ntrain_images = np.asarray(train_images)\ntest_images = np.asarray(test_images)\n\nprint('Train images shape {}'.format(train_images.shape))\nprint('Test images shape {}'.format(test_images.shape))","41a07c64":"model = Sequential()\nmodel.add(Conv2D(input_shape=(227, 227, 3), filters=96, kernel_size=(7, 7), strides=4, padding='valid', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=8, activation='softmax'))","95f033be":"model.summary()","36ad676c":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\nhistory = model.fit(train_images, y_train, batch_size=32, epochs=5, validation_data=(test_images, y_test), callbacks=[callback])","c5ac9427":"# model.save('age_model.h5')","8e18b25b":"test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\nprint(test_acc)","df157a1d":"## Read Data","421e2ffb":"## Gender-Only model","3f403abc":"## Age-only Model"}}