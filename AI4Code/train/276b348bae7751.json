{"cell_type":{"67ced106":"code","4685b233":"code","e44d9278":"code","02c71925":"code","d42ec5f9":"code","c1105d93":"code","e4bdaa80":"code","291e5625":"code","887a8b65":"code","eb739354":"code","d431573d":"code","b4f6aa74":"code","c213c203":"code","3e3b58a9":"code","1ddf8539":"code","b9412314":"code","1a11fd4d":"code","09d8eb96":"code","ed62931f":"code","71a652e0":"code","7dabd52f":"code","996268fa":"code","6fc683a5":"code","2d952405":"code","68a069bf":"code","d1fed2d7":"code","f784a763":"code","505d1851":"code","a3a26881":"code","5eae1072":"code","14b3b2c6":"code","360a9a9b":"code","df24057b":"code","ec8a0511":"code","fb5b9083":"code","869fd646":"code","5e26080a":"code","54907577":"code","7cec7dec":"code","a61a01d5":"code","99abfb0b":"code","e05129ab":"code","d09158f5":"code","bbe62057":"code","7101c081":"code","8f434735":"code","552a11bc":"code","8fd3f205":"code","073a3253":"code","75450a1c":"code","9cfa5284":"code","f81971ab":"code","48388e84":"code","ee7e25d8":"code","6442dd13":"code","6d58e198":"code","9413a350":"code","1130a5e9":"markdown","cd94e2a0":"markdown","5a10e85b":"markdown","e6bb48e1":"markdown","b7133d8e":"markdown","b7f0259a":"markdown","e6095f0c":"markdown","ec5d93f3":"markdown","9769c0ea":"markdown","519eb630":"markdown","c85e06af":"markdown"},"source":{"67ced106":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4685b233":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","e44d9278":"df = pd.read_csv(\"\/kaggle\/input\/lower-back-pain-symptoms-dataset\/Dataset_spine.csv\")","02c71925":"df.head()","d42ec5f9":"df.info()","c1105d93":"df[\"Unnamed: 13\"][:30]","e4bdaa80":"df.drop(\"Unnamed: 13\",axis=1,inplace=True)","291e5625":"df.columns=[\"pelvic_incidence\",\"pelvic_tilt\",\"lumbar_lordosis_angle\",\"sacral_slope\",\n            \"pelvic_radius\",\"degree_spondylolisthesis\",\"pelvic_slope\",\"Direct_tilt\",\n            \"thoracic_slope\",\"cervical_tilt\",\"sacrum_angle\",\"scoliosis_slope\",\"state\"]","887a8b65":"df.head()","eb739354":"df.info()","d431573d":"df.describe()","b4f6aa74":"df.isnull().sum()","c213c203":"sns.set()\nsns.regplot(x=\"pelvic_incidence\", y = \"pelvic_tilt\",data = df)\nplt.show()","3e3b58a9":"sns.set()\nsns.regplot(x = \"pelvic_tilt\",y=\"lumbar_lordosis_angle\", data = df)\nplt.show()","1ddf8539":"df[\"state\"].value_counts()","b9412314":"mapping ={\"Abnormal\": 0,\"Normal\": 1}\ndf[\"state\"] = df[\"state\"].map(mapping)","1a11fd4d":"df[\"state\"].value_counts()","09d8eb96":"df.head()","ed62931f":"sns.set()\nsns.pairplot(df,hue=\"state\")\nplt.show()","71a652e0":"sns.set()\nsns.countplot(x = \"state\",data=df)\nplt.show()","7dabd52f":"sns.set()\nsns.distplot(df[\"pelvic_incidence\"])\nplt.show()","996268fa":"sns.set()\nsns.distplot(df[\"lumbar_lordosis_angle\"])\nplt.show()","6fc683a5":"sns.set()\ndf.hist(figsize=(20,10),bins = 15,color=\"purple\")\nplt.title(\"Distribution of Features\")\nplt.show()","2d952405":"plt.figure(figsize=(20,10))\nsns.set()\nsns.boxplot(data=df,palette= \"Set3\")\nplt.show()","68a069bf":"df.columns","d1fed2d7":"lower_limit = df[\"pelvic_incidence\"].mean() - 3*df[\"pelvic_incidence\"].std()\nupper_limit = df[\"pelvic_incidence\"].mean() + 3*df[\"pelvic_incidence\"].std()","f784a763":"df2 = df[(df[\"pelvic_incidence\"] > lower_limit) & (df[\"pelvic_incidence\"] < upper_limit)]","505d1851":"df.shape[0] - df2.shape[0]","a3a26881":"lower_limit = df2[\"pelvic_tilt\"].mean() - 3*df2[\"pelvic_tilt\"].std()\nupper_limit = df2[\"pelvic_tilt\"].mean() + 3*df2[\"pelvic_tilt\"].std()","5eae1072":"df3 = df2[(df2[\"pelvic_tilt\"] > lower_limit) & (df2[\"pelvic_tilt\"] < upper_limit)]","14b3b2c6":"df2.shape[0] - df3.shape[0]","360a9a9b":"lower_limit = df3[\"lumbar_lordosis_angle\"].mean() - 3*df3[\"lumbar_lordosis_angle\"].std()\nupper_limit = df3[\"lumbar_lordosis_angle\"].mean() + 3*df3[\"lumbar_lordosis_angle\"].std()","df24057b":"df4 = df3[(df3[\"pelvic_tilt\"] > lower_limit) & (df3[\"pelvic_tilt\"] < upper_limit)]","ec8a0511":"df3.shape[0] - df4.shape[0]","fb5b9083":"lower_limit = df4[\"degree_spondylolisthesis\"].mean() - 2*df4[\"degree_spondylolisthesis\"].std()\nupper_limit = df4[\"degree_spondylolisthesis\"].mean() + 2*df4[\"degree_spondylolisthesis\"].std()","869fd646":"df5 = df4[(df4[\"degree_spondylolisthesis\"] > lower_limit) & (df4[\"degree_spondylolisthesis\"] < upper_limit)]","5e26080a":"df4.shape[0] - df5.shape[0]","54907577":"df5.head()","7cec7dec":"df5.info()","a61a01d5":"import missingno as msno\nn = msno.bar(df5,color='purple')","99abfb0b":"x = df5.drop(\"state\",axis=1)\ny = df5[\"state\"]","e05129ab":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx = scaler.fit_transform(x)","d09158f5":"x","bbe62057":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression","7101c081":"model_params ={\n    \"svm\": {\n        \"model\" : SVC(gamma=\"auto\"),\n        \"params\": {\n            \"C\" : [1,10,20],\n            \"kernel\": [\"rbf\"],\n            \"random_state\":[0,10,100]\n        }\n    },\n    \n    \"decision_tree\":{\n        \"model\": DecisionTreeClassifier(),\n        \"params\":{\n            \"criterion\": [\"entropy\",\"gini\"],\n            \"max_depth\": [5,8,9],\n            \"random_state\":[0,10,100]\n        }\n    },\n    \"random_forest\":{\n        \"model\": RandomForestClassifier(),\n        \"params\": {\n            \"n_estimators\" : [1,5,10],\n            \"max_depth\" : [5,8,9],\n            \"random_state\":[0,10,100]\n        }\n    },\n    \"naive_bayes\":{\n        \"model\": GaussianNB(),\n        \"params\": {}\n    },\n    \n    \"logistic_regression\":{\n        \"model\" : LogisticRegression(solver='liblinear',multi_class = 'auto'),\n        \"params\":{\n            \"C\" : [1,5,10],\n            \"random_state\":[0,10,100]\n        }\n    },\n    \"knn\" : {\n        \"model\" : KNeighborsClassifier(),\n        \"params\": {\n            \"n_neighbors\" : [5,12,13]\n        }\n    }\n    \n    \n}","8f434735":"scores =[]\nfor model_name,mp in model_params.items():\n    clf = GridSearchCV(mp[\"model\"],mp[\"params\"],cv=12,return_train_score=False)\n    clf.fit(x,y)\n    scores.append({\n        \"Model\" : model_name,\n        \"Best_Score\": clf.best_score_,\n        \"Best_Params\": clf.best_params_\n    })","552a11bc":"result_score = pd.DataFrame(scores, columns = [\"Model\",\"Best_Score\",\"Best_Params\"])","8fd3f205":"result_score","073a3253":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state= 10)","75450a1c":"clf_rf = RandomForestClassifier(max_depth = 8,n_estimators =10,random_state=0)\nclf_rf.fit(x_train,y_train)","9cfa5284":"y_pred = clf_rf.predict(x_test)","f81971ab":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","48388e84":"clf_lr = LogisticRegression(C=12,random_state = 100)\nclf_lr.fit(x_train,y_train)","ee7e25d8":"y_pred = clf_lr.predict(x_test)","6442dd13":"accuracy_score(y_test,y_pred)","6d58e198":"result = pd.DataFrame({\"Actual_Value\": y_test, \"Predicted_Value\": y_pred})","9413a350":"result","1130a5e9":"## So there are some Outlier,Let's remove those outliers","cd94e2a0":"## So we can see that, by using Logistic Regression we are getting 84% accuracy","5a10e85b":"## Now let's see our Actual vs Predicted Value","e6bb48e1":"## We can see that there is no Null Values","b7133d8e":"## Now let's scale our Dataset","b7f0259a":"## Here is a column which is unnamed,let's see whats this column contains","e6095f0c":"## so this column hold the names of the other columns,so let's named those columns & we don't need this column for further purposes,so first drop this column ","ec5d93f3":"## Let's convert the string value of \"state\" column into numerical value","9769c0ea":"## Let's find the best model for our Dataset","519eb630":"## Let's Visualize the Data","c85e06af":"## Looks like Most of the Data are Not Normally Distributed"}}