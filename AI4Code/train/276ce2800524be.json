{"cell_type":{"0732e8bb":"code","86ed83d7":"code","a657946f":"code","22d1dab4":"code","c2ea7c18":"code","90687c35":"code","3e711855":"code","86b1a072":"markdown","ddf2774c":"markdown"},"source":{"0732e8bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nimport tensorflow.keras\nfrom PIL import Image, ImageOps\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt","86ed83d7":"# Disable scientific notation for clarity\nnp.set_printoptions(suppress=True)","a657946f":"# Load the model\nmodel = tensorflow.keras.models.load_model('\/kaggle\/input\/keras-model-google\/keras_model.h5')","22d1dab4":"def show_image_label(path):\n    # Create the array of the right shape to feed into the keras model\n    # The 'length' or number of images you can put into the array is\n    # determined by the first position in the shape tuple, in this case 1.\n    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n    \n    \n    # Replace this with the path to your image\n    image = Image.open(path)\n\n    #resize the image to a 224x224 with the same strategy as in TM2:\n    #resizing the image to be at least 224x224 and then cropping from the center\n    size = (224, 224)\n    image = ImageOps.fit(image, size,Image.ANTIALIAS)\n\n    #turn the image into a numpy array\n    image_array = np.asarray(image)\n\n    # Normalize the image\n    normalized_image_array = (image_array.astype(np.float32) \/ 127.0) - 1\n\n    # Load the image into the array\n    data[0] = normalized_image_array\n\n    emotion_dict = {0:'Anger',1:'contempt',2:'disgust',3:'fear',4:'happy',5:'sadness',6:'surprise'}\n\n    imgplot = plt.imshow(image)\n    plt.show()\n\n    # run the inference\n    prediction = np.argmax(model.predict(data),axis=1)\n    print(emotion_dict[prediction[0]])","c2ea7c18":"test_imge_list = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/test-images\/test_image'):\n    for filename in filenames:\n        a = os.path.join(dirname, filename)\n        test_imge_list.append(a)","90687c35":"test_imge_list","3e711855":"for image in test_imge_list:\n    show_image_label(image)","86b1a072":"*CKPLUS+48 dataset is train in Google Machine Teaachable. A model is gained. The same model is used to test images. All other process is similar.A cocnept of training MNIST dataset is enough for understanding how this works.*","ddf2774c":"**Loading other images**"}}