{"cell_type":{"67009c63":"code","f643c81f":"code","e9b55991":"code","5dfa043a":"code","0285a8a0":"code","8a21c72b":"code","1a388776":"code","9cdf5459":"code","3e654ad0":"code","07527e54":"code","57eb9de1":"code","79c3d6c6":"code","200980fe":"code","96634fd2":"code","9401a5bf":"code","4e6883c7":"code","e192736f":"code","0fc0c1fa":"code","ddd96a14":"code","e10224f4":"code","f33c12a0":"code","0ea9662e":"code","6c1692db":"code","1576c4b9":"code","f32fb4cb":"code","c3a04839":"code","e6340c13":"code","8b5be2d2":"code","dec16228":"code","f12789ee":"code","cd0345c3":"code","29222364":"code","c25512a3":"code","e93efa66":"code","1e01018d":"code","fa0eba7c":"code","8a15ee45":"code","adb7a8d3":"code","24e88b3a":"code","81bd0b3b":"code","8512bbf2":"code","651d0cbf":"code","5caf324b":"code","945a575d":"code","c8791d9f":"code","1f5fcfcb":"code","fc145dd6":"code","31f9a080":"code","1270450b":"code","c5084237":"markdown","44ecee1c":"markdown","5b8cf847":"markdown","6d8fb4af":"markdown","84541ca4":"markdown","9a764e91":"markdown","8150c1b7":"markdown","6c7b37dd":"markdown","7fde2043":"markdown","b8ba546a":"markdown","a97ab1ae":"markdown"},"source":{"67009c63":"# Import relevant libraries---------------------------------------------------------\n\n#Standard libraries for data analysis:----------------------\n    \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom scipy.stats import norm, skew\nfrom scipy import stats\nimport statsmodels.api as sm\n\n\n# sklearn modules for data preprocessing-------------------------------------\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler \n\n\n#sklearn modules for Model Selection--------------------------------------\n\nfrom sklearn import svm, tree, linear_model, neighbors\nfrom sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom xgboost import XGBClassifier\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n#sklearn modules for Model Evaluation & Improvement---------------------------\n    \nfrom sklearn.metrics import confusion_matrix, accuracy_score \nfrom sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import KFold\n\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\nfrom sklearn.metrics import classification_report, precision_recall_curve\nfrom sklearn.metrics import auc, roc_auc_score, roc_curve\nfrom sklearn.metrics import make_scorer, recall_score, log_loss\nfrom sklearn.metrics import average_precision_score\n  \n\n#Standard libraries for data visualization---------------------\n\nimport seaborn as sn\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport matplotlib \n%matplotlib inline\ncolor = sn.color_palette()\nimport matplotlib.ticker as mtick\nfrom IPython.display import display\npd.options.display.max_columns = None\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.metrics import roc_curve\n\n\n#Miscellaneous Utilitiy Libraries--------------------------------------\n    \nimport random\nimport os\nimport re\nimport sys\nimport timeit\nimport string\nimport time\nfrom datetime import datetime\nfrom time import time\nfrom dateutil.parser import parse\nimport joblib\n","f643c81f":"pd.set_option('max_columns',100)\npd.set_option('max_rows',900)\n\npd.set_option('max_colwidth',200)\n\ndataset  = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndataset .head()\n","e9b55991":"from datetime import datetime, timedelta\n\ndef datetime_range(start=None, end=None):\n    span = end - start\n    for i in range(span.days + 1):\n        yield start + timedelta(days=i)\n\ndate_list = pd.to_datetime(list(datetime_range(start=datetime(2021, 6, 1), end=datetime(2021, 8, 31))))\ndataset[\"date_col\"] = np.random.choice(date_list, size = len(dataset))","5dfa043a":"dataset['tenure']= dataset['tenure'].astype(float)\ndataset['tenure']=dataset['tenure'].replace(0,np.nan)\ndataset['MultipleLines']= dataset['MultipleLines'].replace('No phone service','No')\ndataset['TotalCharges']= dataset['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\ndataset['ActualCharges']=dataset['MonthlyCharges']*dataset['tenure']\ndataset['ExtraCharges_Discount']=dataset['TotalCharges']-dataset['ActualCharges']\ndataset[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= dataset[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n","0285a8a0":"dataset.dtypes","8a21c72b":"#Recheck Column Datatypes and Missing Values:\n    \ndataset.columns.to_series().groupby(dataset.dtypes).groups","1a388776":"dataset.info()","9cdf5459":"dataset.isna().any()","3e654ad0":"dataset[\"Churn\"].value_counts()\n\n\n# ======================================================================================================\n#In this case, we have class imbalance with few negatives. In our business challenge, \n#false negatives are costly. Hence let's keep an eye onto the Precision, Recall & F2 score besides accuracy\n# ======================================================================================================","07527e54":"\n\n\ndataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'],errors='coerce')\n\ndataset['TotalCharges'] = dataset['TotalCharges'].astype(\"float\")","57eb9de1":"dataset.info()","79c3d6c6":"dataset.isna().any()","200980fe":"#*Find the average and fill missing values of each columns programmatically.\n\nna_cols = dataset.isna().any()\n\nna_cols = na_cols[na_cols == True].reset_index()\n\nna_cols = na_cols[\"index\"].tolist()\n\nfor col in dataset.columns[1:]:\n     if col in na_cols:\n        if dataset[col].dtype != 'object':\n             dataset[col] =  dataset[col].fillna(dataset[col].mean()).round(0)","96634fd2":"#Revalidate:\n  \ndataset.isna().any()  ","9401a5bf":"\n#Create a label encoder object\nle = LabelEncoder()\n\n# Label Encoding will be used for columns with 2 or less unique values\nle_count = 0\nfor col in dataset.columns[1:]:\n    if dataset[col].dtype == 'object':\n        if len(list(dataset[col].unique())) <= 2:\n            le.fit(dataset[col])\n            dataset[col] = le.transform(dataset[col])\n            le_count += 1\nprint('{} columns were label encoded.'.format(le_count))","4e6883c7":"dataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'tenure', 'PhoneService', 'PaperlessBilling',\n        'MonthlyCharges', 'TotalCharges','ExtraCharges_Discount']]\n\n#Histogram:\n    \nfig = plt.figure(figsize=(15, 12))\nplt.suptitle('Histograms of Numerical Columns\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = 24, fontfamily = \"sans-serif\")\nfor i in range(dataset2.shape[1]):\n    plt.subplot(6, 3, i + 1)\n    f = plt.gca()\n    f.set_title(dataset2.columns.values[i])\n\n    vals = np.size(dataset2.iloc[:, i].unique())\n    if vals >= 100:\n        vals = 100\n    \n    plt.hist(dataset2.iloc[:, i], bins=vals, color = '#ec838a')\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","e192736f":"def hist_plot(col_name):\n    df_plot = dataset.groupby(['Churn',col_name]).size().reset_index().pivot(columns='Churn',index=col_name,values=0)\n    df_plot.plot(kind='bar',stacked=True)","0fc0c1fa":"print (f'A female customer has a probability of {round(dataset[dataset[\"gender\"]==\"Female\"][\"Churn\"].mean()*100,2)} % churn')\n\nprint()\n\nprint (f'A male customer has a probability of {round(dataset[dataset[\"gender\"]==\"Male\"][\"Churn\"].mean()*100,2)} % churn')\n\nprint()\nhist_plot(\"gender\")","ddd96a14":"print (f'A customer with a partner has a probability of {round(dataset[dataset[\"Partner\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn')\n\nprint()\n\nprint (f'A customer without any partner has a probability of {round(dataset[dataset[\"Partner\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn')\n\nprint()\n\nhist_plot(\"Partner\")","e10224f4":"print (f'A customer with dependents has a probability of {round(dataset[dataset[\"Dependents\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn')\n\nprint()\n\nprint (f'A customer without any dependents has a probability of {round(dataset[dataset[\"Dependents\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn')\n\nprint()\nhist_plot(\"Dependents\")","f33c12a0":"print (f'A customer with a phone service has a probability of {round(dataset[dataset[\"PhoneService\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn')\n\nprint()\n\nprint (f'A customer without any phone service has a probability of {round(dataset[dataset[\"PhoneService\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn')\n\nprint()\nhist_plot(\"PhoneService\")","0ea9662e":"#Step 10.4. Plot positive & negative correlation with Response Variable-----------------------------\n\ncorrelations = dataset2.corrwith(dataset.Churn)\ncorrelations = correlations[correlations!=1]\n\ncorrelations.plot.bar(\n        figsize = (18, 10), fontsize = 15, color = '#ec838a',\n        rot = 45, grid = True)\n\nplt.title('Correlation with Churn Rate \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")","6c1692db":"## Set and compute the Correlation Matrix\nsn.set(style=\"white\")\ncorr = dataset2.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure and a diverging colormap\nf, ax = plt.subplots(figsize=(18, 15))\ncmap = sn.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsn.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","1576c4b9":"def calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)\n\ndataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'tenure', 'PhoneService', 'PaperlessBilling','MonthlyCharges','TotalCharges','ExtraCharges_Discount']]\n\ncalc_vif(dataset2)","f32fb4cb":"#Total Charges seem to be colinear with Monthly Charges.\n\n#check colinearity:\n    \ndataset2[['MonthlyCharges', 'TotalCharges']].plot.scatter(figsize = (15, 10), x = 'MonthlyCharges',\n                                                              y='TotalCharges', color =  '#ec838a')\n\n\nplt.title('Co-linearity of Monthly Charges and Total Charges \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")","c3a04839":"#dropping TotalCharges:\n    \ndataset2 = dataset2.drop(columns = \"TotalCharges\")\n\n#Revalidate Colinearity:\n\ndataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'tenure', 'PhoneService', 'PaperlessBilling','MonthlyCharges','ExtraCharges_Discount']]\n\ncalc_vif(dataset2)","e6340c13":"#Applying changes in the main dataset:\n    \ndataset = dataset.drop(columns = \"TotalCharges\")  ","8b5be2d2":"#Incase if user_id is an object:\n    \nidentity = dataset[\"customerID\"]\n\ndataset = dataset.drop(columns=\"customerID\")\n\n# convert rest of categorical variable into dummy\n\ndataset= pd.get_dummies(dataset)\n\n#Rejoin userid to dataset (column concatenation)\n\ndataset = pd.concat([dataset, identity], axis = 1)","dec16228":"df_train = dataset[dataset['date_col']<'2021-08-01']\ndf_test = dataset[(dataset['date_col']>'2021-08-01') & (dataset['date_col']<'2021-08-16')]\ndf_eval =  dataset[dataset['date_col']>'2021-08-16']\n\nX_train= df_train.drop(['Churn','ActualCharges','date_col'], axis=1)\ny_train= df_train['Churn']\nX_test= df_test.drop(['Churn','ActualCharges','date_col'], axis=1)\ny_test= df_test['Churn']\nX_eval= df_eval.drop(['Churn','ActualCharges','date_col'], axis=1)\ny_eval= df_eval['Churn']\n\n\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","f12789ee":"# Step 13: Removing Identifiers-------------------------------------------------------------------\n\ntrain_identity = X_train['customerID']\nX_train = X_train.drop(columns = ['customerID'])\n\ntest_identity = X_test['customerID']\nX_test = X_test.drop(columns = ['customerID'])\n\nvalid_identity = X_eval['customerID']\nX_eval = X_eval.drop(columns = ['customerID'])","cd0345c3":"# Step 14: Feature Scaling-----------------------------------------------------------------------\n\nsc_X = StandardScaler()\nX_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\nX_train2.columns = X_train.columns.values\nX_train2.index = X_train.index.values\nX_train = X_train2\n\nX_test2 = pd.DataFrame(sc_X.transform(X_test))\nX_test2.columns = X_test.columns.values\nX_test2.index = X_test.index.values\nX_test = X_test2\n\nX_eval2 = pd.DataFrame(sc_X.transform(X_eval))\nX_eval2.columns = X_eval.columns.values\nX_eval2.index = X_eval.index.values\nX_eval = X_eval2","29222364":"#Compare Baseline Classification Algorithms - First Iteration\n#Using Accuracy and ROC AUC Mean Metrics\n\n\nmodels = []\n\nmodels.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state = 0,\n                                                         class_weight='balanced')))\n\nmodels.append(('SVC', SVC(kernel = 'linear', random_state = 0)))\n\n\nmodels.append(('Kernel SVM', SVC(kernel = 'rbf', random_state = 0)))\n\n\nmodels.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)))\n\n\nmodels.append(('Gaussian NB', GaussianNB()))\n\n\nmodels.append(('Decision Tree Classifier',\n               DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\n\n\nmodels.append(('Random Forest', RandomForestClassifier(\n    n_estimators=100, criterion = 'entropy', random_state = 0)))\n\n\n\n#Evaluating Model Results: \n\n    \nacc_results = []\nauc_results = []\nnames = []\n# set table to table to populate with performance results\ncol = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', \n       'Accuracy Mean', 'Accuracy STD']\n\nmodel_results = pd.DataFrame(columns=col)\ni = 0\n# evaluate each model using k-fold cross-validation\nfor name, model in models:\n    kfold = model_selection.KFold(\n        n_splits=10, random_state=0)  # 10-fold cross-validation\n\n    cv_acc_results = model_selection.cross_val_score(  # accuracy scoring\n        model, X_train, y_train, cv=kfold, scoring='accuracy')\n\n    cv_auc_results = model_selection.cross_val_score(  # roc_auc scoring\n        model, X_train, y_train, cv=kfold, scoring='roc_auc')\n\n    acc_results.append(cv_acc_results)\n    auc_results.append(cv_auc_results)\n    names.append(name)\n    model_results.loc[i] = [name,\n                         round(cv_auc_results.mean()*100, 2),\n                         round(cv_auc_results.std()*100, 2),\n                         round(cv_acc_results.mean()*100, 2),\n                         round(cv_acc_results.std()*100, 2)\n                         ]\n    i += 1\n    \nmodel_results.sort_values(by=['ROC AUC Mean'], ascending=False)","c25512a3":"# Visualize Classification Algorithms Accuracy Comparisons:-----------------------------------\n\n  \n#Using Accuracy Mean:\n    \nfig = plt.figure(figsize=(15, 7))\nax = fig.add_subplot(111)\nplt.boxplot(acc_results)\nax.set_xticklabels(names)\n\n\n\n#plt.ylabel('ROC AUC Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n#plt.xlabel('\\n Baseline Classification Algorithms\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\nplt.title('Accuracy Score Comparison \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n#plt.legend(loc='top right', fontsize = \"medium\")\nplt.xticks(rotation=0, horizontalalignment=\"center\")\nplt.yticks(rotation=0, horizontalalignment=\"right\")\n\n\nplt.show()\n","e93efa66":"\n#Identify optimal number of K neighbors for KNN Model:\n\n\nscore_array = []\nfor each in range(1,25):\n    knn_loop = KNeighborsClassifier(n_neighbors = each) #set K neighbor as 3\n    knn_loop.fit(X_train,y_train)\n    score_array.append(knn_loop.score(X_test,y_test))\n\nfig = plt.figure(figsize=(15, 7))\nplt.plot(range(1,25),score_array, color = '#ec838a')\n\n\nplt.ylabel('Range\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\nplt.xlabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\nplt.title('Optimal Number of K Neighbors \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n#plt.legend(loc='top right', fontsize = \"medium\")\nplt.xticks(rotation=0, horizontalalignment=\"center\")\nplt.yticks(rotation=0, horizontalalignment=\"right\")\n\n\nplt.show()\n#optimal number of K neigbors = 22","1e01018d":"#Identify optimal number of trees for Random Forest Model:\n \nscore_array = []\nfor each in range(1,100):\n    rf_loop = RandomForestClassifier(n_estimators = each, random_state = 1) \n    rf_loop.fit(X_train,y_train)\n    score_array.append(rf_loop.score(X_test,y_test))\n \nfig = plt.figure(figsize=(15, 7))\nplt.plot(range(1,100),score_array, color = '#ec838a')\n\n\nplt.ylabel('Range\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\nplt.xlabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\nplt.title('Optimal Number of Trees for Random Forest Model \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n#plt.legend(loc='top right', fontsize = \"medium\")\nplt.xticks(rotation=0, horizontalalignment=\"center\")\nplt.yticks(rotation=0, horizontalalignment=\"right\")\n\n\nplt.show()\n#Optimal number of decision trees = 72","fa0eba7c":"# Fitting Logistic Regression to the Training set \nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n#Evaluate results\n\nacc = accuracy_score(y_test, y_pred )\nprec = precision_score(y_test, y_pred )\nrec = recall_score(y_test, y_pred )\nf1 = f1_score(y_test, y_pred )\nf2 = fbeta_score(y_test, y_pred, beta=2.0)\n\nresults = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n\n\n\n# Support Vector Machine (linear classifier)------------------------\n\n\n# Fitting SVM (SVC class) to the Training set:\n\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results \ny_pred = classifier.predict(X_test)\n\n#Evaluate results\n\nacc = accuracy_score(y_test, y_pred )\nprec = precision_score(y_test, y_pred )\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred )\nf2 = fbeta_score(y_test, y_pred, beta=2.0)\n\nmodel_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1, f2]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n\nresults = results.append(model_results, ignore_index = True)\n\n\n# K-Nearest Neighbours------------------------\n\n\n# Fitting KNN to the Training set:\n\nclassifier = KNeighborsClassifier(n_neighbors = 22, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results \ny_pred  = classifier.predict(X_test)\n\n#Evaluate results\nacc = accuracy_score(y_test, y_pred )\nprec = precision_score(y_test, y_pred )\nrec = recall_score(y_test, y_pred )\nf1 = f1_score(y_test, y_pred )\nf2 = fbeta_score(y_test, y_pred, beta=2.0)\n\nmodel_results = pd.DataFrame([['K-Nearest Neighbours', acc, prec, rec, f1, f2]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n\nresults = results.append(model_results, ignore_index = True)\n\n\n\n# Kernel SVM------------------------\n\n# Fitting Kernel SVM to the Training set:\n\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results \ny_pred = classifier.predict(X_test)\n\n#Evaluate results\n\nacc = accuracy_score(y_test, y_pred )\nprec = precision_score(y_test, y_pred )\nrec = recall_score(y_test, y_pred )\nf1 = f1_score(y_test, y_pred )\nf2 = fbeta_score(y_test, y_pred, beta=2.0)\n\nmodel_results = pd.DataFrame([['Kernel SVM', acc, prec, rec, f1, f2]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n\nresults = results.append(model_results, ignore_index = True)\n\n\n# Naive Byes------------------------------------------------\n\n# Fitting Naive Byes to the Training set:\n    \nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results \ny_pred = classifier.predict(X_test)\n\n#Evaluate results\nacc = accuracy_score(y_test, y_pred )\nprec = precision_score(y_test, y_pred )\nrec = recall_score(y_test, y_pred )\nf1 = f1_score(y_test, y_pred )\nf2 = fbeta_score(y_test, y_pred, beta=2.0)\n\nmodel_results = pd.DataFrame([['Naive Byes', acc, prec, rec, f1, f2]],\n                columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n\nresults = results.append(model_results, ignore_index = True)\n\n\n\n#Decision Tree---------------------------------------------\n\n\n# Fitting Decision Tree to the Training set:\n\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n\n# Predicting the Test set results \ny_pred = classifier.predict(X_test)\n\n#Evaluate results\nacc = accuracy_score(y_test, y_pred )\nprec = precision_score(y_test, y_pred )\nrec = recall_score(y_test, y_pred )\nf1 = f1_score(y_test, y_pred )\nf2 = fbeta_score(y_test, y_pred, beta=2.0)\n\nmodel_results = pd.DataFrame([['Decision Tree', acc, prec, rec, f1, f2]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n\nresults = results.append(model_results, ignore_index = True)\n\n\n#Random Forest--------------------------------------------\n\n\n# Fitting Random Forest to the Training set:\n    \nclassifier = RandomForestClassifier(n_estimators = 72, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n\n\n# Predicting the Test set results \ny_pred = classifier.predict(X_test)\n\n#Evaluate results\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\nacc = accuracy_score(y_test, y_pred )\nprec = precision_score(y_test, y_pred )\nrec = recall_score(y_test, y_pred )\nf1 = f1_score(y_test, y_pred )\nf2 = fbeta_score(y_test, y_pred, beta=2.0)\n\nmodel_results = pd.DataFrame([['Random Forest', acc, prec, rec, f1, f2]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","8a15ee45":"\n# =======================================================================================================================\n#Sort results based on the right classification metric:\n#(Accuracy\/ROC_AUC \/ Precision\/Recall\/F1\/F2 scores)\n\n#Since we have class imbalance. When we look into the business challenge, \n# our false negatives will be costly and hence we need to Keep an eye onto the Precision, Recall & F2 score besides accuracy\n# =======================================================================================================================\n\nresults = results.sort_values([\"Precision\", \"Recall\", \"F2 Score\"], ascending = False)\n    \n\nprint (results)","adb7a8d3":"# Fit Logistic Regression on the Training dataset:\n    \nclassifier = LogisticRegression(random_state = 0, penalty = 'l2')\nclassifier.fit(X_train, y_train)\n\n\n# Predict the Test set results\n\ny_pred = classifier.predict(X_test)\ny_pred_eval = classifier.predict(X_eval)\n\n#Evaluate Model Results on Test Set:\n\nacc = accuracy_score(y_test, y_pred )\nprec = precision_score(y_test, y_pred )\nrec = recall_score(y_test, y_pred )\nf1 = f1_score(y_test, y_pred )\nf2 = fbeta_score(y_test, y_pred, beta=2.0)\n\nresults = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n\nprint (results)","24e88b3a":"# Re-check k-Fold Cross Validation:\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Logistic Regression Classifier Accuracy: %0.2f (+\/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))","81bd0b3b":"#Evaluate Model Results on Test Set:\n\nacc = accuracy_score(y_eval, y_pred_eval )\nprec = precision_score(y_eval, y_pred_eval )\nrec = recall_score(y_eval, y_pred_eval )\nf1 = f1_score(y_eval, y_pred_eval )\nf2 = fbeta_score(y_eval, y_pred_eval, beta=2.0)\nresults_1 = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\nresults_1","8512bbf2":"    \ncm = confusion_matrix(y_eval, y_pred_eval) \ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\nplt.figure(figsize = (28,20))\n\n\nfig, ax = plt.subplots()\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g'#,cmap=\"YlGnBu\" \n           )\nclass_names=[0,1]\ntick_marks = np.arange(len(class_names))\nplt.tight_layout()\nplt.title('Confusion matrix\\n', y=1.1)\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nax.xaxis.set_label_position(\"top\")\nplt.ylabel('Actual label\\n')\nplt.xlabel('Predicted label\\n')\n","651d0cbf":"# Evaluate the model using ROC Graph\n\nclassifier.fit(X_train, y_train) \nprobs = classifier.predict_proba(X_test) \nprobs = probs[:, 1] \nclassifier_roc_auc = accuracy_score(y_test, y_pred )\n\n\nrf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\nplt.figure(figsize=(14, 6))\n\n# Plot Logistic Regression ROC\nplt.plot(rf_fpr, rf_tpr, label='Logistic Regression (area = %0.2f)' % classifier_roc_auc)\n# Plot Base Rate ROC\nplt.plot([0,1], [0,1],label='Base Rate' 'k--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\n\n\n\nplt.ylabel('True Positive Rate \\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\nplt.xlabel('\\nFalse Positive Rate \\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\nplt.title('ROC Graph \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\nplt.legend(loc=\"lower right\", fontsize = \"medium\")\nplt.xticks(rotation=0, horizontalalignment=\"center\")\nplt.yticks(rotation=0, horizontalalignment=\"right\")\n\n\n\nplt.show()","5caf324b":"# Analyzing Coefficients\nfeature_importances = pd.concat([pd.DataFrame(dataset.drop(columns = 'customerID').columns, columns = [\"features\"]),\n           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n           ],axis = 1)\n\nfeature_importances.sort_values(\"coef\", ascending = False)","945a575d":"#Hyper parameter Tuning  --------------------------------------\n\n\n# Round 1: -----------------------------------------------------------------\n \n# Select Regularization Method   \nimport time\npenalty = ['l1', 'l2']\n\n# Create regularization hyperparameter space\nC = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n\n# Combine Parameters\nparameters = dict(C=C, penalty=penalty)\n\nlr_classifier = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = \"balanced_accuracy\",\n                           cv = 10,\n                           n_jobs = -1)\nt0 = time.time()\nlr_classifier  = lr_classifier .fit(X_train, y_train)\nt1 = time.time()\nprint(\"Took %0.2f seconds\" % (t1 - t0))\n\nlr_best_accuracy = lr_classifier.best_score_\nlr_best_parameters = lr_classifier.best_params_\nlr_best_accuracy, lr_best_parameters\n","c8791d9f":"# Select Regularization Method\nimport time\npenalty = ['l2']\n\n# Create regularization hyperparameter space\nC = [ 0.0001, 0.001, 0.01, 0.02, 0.05]\n\n# Combine Parameters\nparameters = dict(C=C, penalty=penalty)\n\nlr_classifier = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = \"balanced_accuracy\",\n                           cv = 10,\n                           n_jobs = -1)\nt0 = time.time()\nlr_classifier  = lr_classifier .fit(X_train, y_train)\nt1 = time.time()\nprint(\"Took %0.2f seconds\" % (t1 - t0))\n\nlr_best_accuracy = lr_classifier.best_score_\nlr_best_parameters = lr_classifier.best_params_\nlr_best_accuracy, lr_best_parameters","1f5fcfcb":"# Final Hyper parameter tuning and selection --------------------------------------\n\n\nlr_classifier = LogisticRegression(random_state = 0, penalty = 'l2')\nlr_classifier.fit(X_train, y_train)\n\n\n# Predict the Test set results\n\ny_pred = lr_classifier.predict(X_test)\n\n#probability score\ny_pred_probs = lr_classifier.predict_proba(X_test)\ny_pred_probs  = y_pred_probs [:, 1] ","fc145dd6":"#visualize Confusion Matrix:\n\ncm = confusion_matrix(y_test, y_pred) \ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\nplt.figure(figsize = (28,20))\n\n\nfig, ax = plt.subplots()\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nclass_names =[0,1]\ntick_marks = np.arange(len(class_names))\nplt.tight_layout()\nplt.title('Confusion matrix\\n', y=1.1)\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nax.xaxis.set_label_position(\"top\")\nplt.ylabel('Actual label\\n')\nplt.xlabel('Predicted label\\n')\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","31f9a080":"#Final Results:-------------------------------------------------------\n\n\nfinal_results = pd.concat([test_identity, y_test], axis = 1).dropna()\n\nfinal_results['predictions'] = y_pred \n\nfinal_results[\"propensity_to_convert(%)\"] = y_pred_probs \n\nfinal_results[\"propensity_to_convert(%)\"] = final_results[\"propensity_to_convert(%)\"]*100\n\nfinal_results[\"propensity_to_convert(%)\"]=final_results[\"propensity_to_convert(%)\"].round(2)\n\nfinal_results = final_results[['customerID', 'Churn', 'predictions', 'propensity_to_convert(%)']]\n\nfinal_results ['Ranking'] = pd.qcut(final_results['propensity_to_convert(%)'].rank(method = 'first'),10,labels=range(10,0,-1))\n\nprint (final_results)","1270450b":"filename = 'final_model.model'\ni = [lr_classifier]\njoblib.dump(i,filename)","c5084237":"## Having Partner and Churn","44ecee1c":"### **Data Dictionary**\n\n1. **`CustomerID`**: A unique ID that identifies each customer.\n\n2. **`Gender`**: The customer\u2019s gender: Male, Female\n\n3. **`Age`**: The customer\u2019s current age, in years, at the time the fiscal quarter ended.\n\n4. **`Senior Citizen`**: Indicates if the customer is 65 or older: Yes, No\n\n5. **`Married (Partner)`**: Indicates if the customer is married: Yes, No\n\n6. **`Dependents`**: Indicates if the customer lives with any dependents: Yes, No. Dependents could be children, parents, grandparents, etc.\n\n7. **`Number of Dependents`**: Indicates the number of dependents that live with the customer.\n\n8. **`Phone Service`**: Indicates if the customer subscribes to home phone service with the company: Yes, No\n\n9. **`Multiple Lines`**: Indicates if the customer subscribes to multiple telephone lines with the company: Yes, No\n\n10. **`Internet Service`**: Indicates if the customer subscribes to Internet service with the company: No, DSL, Fiber Optic, Cable.\n\n11. **`Online Security`**: Indicates if the customer subscribes to an additional online security service provided by the company: Yes, No\n\n12. **`Online Backup`**: Indicates if the customer subscribes to an additional online backup service provided by the company: Yes, No\n\n13. **`Device Protection Plan`**: Indicates if the customer subscribes to an additional device protection plan for their Internet equipment provided by the company: Yes, No\n\n14. **`Premium Tech Support`**: Indicates if the customer subscribes to an additional technical support plan from the company with reduced wait times: Yes, No\n\n15. **`Streaming TV`**: Indicates if the customer uses their Internet service to stream television programing from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n16. **`Streaming Movies`**: Indicates if the customer uses their Internet service to stream movies from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n17. **`Contract`**: Indicates the customer\u2019s current contract type: Month-to-Month, One Year, Two Year.\n\n18. **`Paperless Billing`**: Indicates if the customer has chosen paperless billing: Yes, No\n\n19. **`Payment Method`**: Indicates how the customer pays their bill: Bank Withdrawal, Credit Card, Mailed Check\n\n20. **`Monthly Charge`**: Indicates the customer\u2019s current total monthly charge for all their services from the company.\n\n21. **`Total Charges`**: Indicates the customer\u2019s total charges, calculated to the end of the quarter specified above.\n\n22. **`Tenure`**: Indicates the total amount of months that the customer has been with the company.\n\n23. **`Churn`**: Yes = the customer left the company this quarter. No = the customer remained with the company. Directly related to Churn Value.\n\n","5b8cf847":"Customer without any relationship, single customer almost 1.7 times more likely churn than cutomer with a partner.","6d8fb4af":"Customer without any dependents, almost 2.03 times more likely churn than cutomer with a dependent.","84541ca4":"# **Telecom Customer Churn**","9a764e91":"## Gender and Churn","8150c1b7":"## Having Dependents and Churn","6c7b37dd":"Churn rate difference between customer has a phone service with the company and customer does not have a home phone service with the company is very small.","7fde2043":"There is not much difference between gender on the churn rate.","b8ba546a":"- Based on the data and data dictionary, We have a classification problem.\n- We wil make classification on the target variable **`Churn`**\n- And we will build a model to get best classification possible on the target variable.\n- For that we will look at the balance of the target variable.\n- As we will see later, our target variable has imblanced data\n- For that reason we are not going to use Accuracy score, \n- Based on the problem on the hand, we will use **`Recall score`**.","a97ab1ae":"## Phone Service and Churn"}}