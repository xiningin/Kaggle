{"cell_type":{"b460de8a":"code","adf05fdd":"code","53ee343c":"code","a51a9e22":"code","019bd09e":"code","92d804dc":"code","c6b1038e":"code","2ae931d6":"code","ee3f855c":"code","cb617012":"code","c446532a":"markdown","9037370d":"markdown","5e0a7a8c":"markdown","fdb1fe55":"markdown","168ae2e3":"markdown","ea217cd4":"markdown","e0cd95ca":"markdown","7031f59a":"markdown"},"source":{"b460de8a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","adf05fdd":"# read data and import packages\nsales = pd.read_csv(\"..\/input\/sales_train.csv\")\nitem_cat = pd.read_csv(\"..\/input\/item_categories.csv\")\nitem = pd.read_csv(\"..\/input\/items.csv\")\nshops = pd.read_csv(\"..\/input\/shops.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns","53ee343c":"sales.date = pd.to_datetime(sales.date, format='%d.%m.%Y')\n\ngroup = sales.groupby(['shop_id','item_id','date_block_num']).item_cnt_day.sum()\n\ntrain = group.reset_index()\ntrain = train.rename(columns={'item_cnt_day':'item_cnt_month'}).drop('date_block_num',axis=1)\n\ntest.item_id = test.item_id.fillna(test.item_id.median())","a51a9e22":"# number of items for month per shop\nx = train.groupby('shop_id').item_cnt_month.sum().reset_index()\n\nplt.figure(figsize=(30,4))\nax = sns.barplot(x.shop_id, x.item_cnt_month)\nplt.title(\"Items per shop\")\nplt.ylabel('number of items for month', fontsize=12)\nplt.xlabel('shop id', fontsize=12)\nplt.show()","019bd09e":"shops['city'] = shops['shop_name'].str.split().map(lambda x: x[0])\nshops['city_id'] = LabelEncoder().fit_transform(shops['city'])\n\n# add shops city_id feature\nsci = pd.Series(data=shops.city_id,index=shops.shop_id)\ntrain['city_id'] = train.shop_id.map(sci)\ntest['city_id'] = test.shop_id.map(sci)\n\n\n# add item_category_id feature\nici = pd.Series(data=item.item_category_id,index=item.item_id)\ntrain['item_category_id'] = train.item_id.map(ici)\ntest['item_category_id'] = test.item_id.map(ici)\ntrain.head()","92d804dc":"# expanding mean encoding\nfor col in ['shop_id','item_id','item_category_id','city_id']:\n    cumsum = train.groupby(col).item_cnt_month.cumsum() - train.item_cnt_month\n    cumcnt = train.groupby(col).cumcount()\n    means = cumsum\/cumcnt\n    global_mean = train.item_cnt_month.mean()\n    train[col+'_mean'] = means.fillna(global_mean)\n    test[col+'_mean'] = test[col].map(means).fillna(global_mean)\ntrain.head()","c6b1038e":"# prepare train and test\nX_train = train.drop('item_cnt_month',axis=1)\ny_train = train.item_cnt_month\nX_test = test.drop('ID',axis=1)","2ae931d6":"gb = GradientBoostingRegressor(learning_rate=0.01,n_estimators=2000,min_samples_split=30)\ngb.fit(X_train,y_train)\ngb_result = gb.predict(X_test)","ee3f855c":"result = (gb_result).clip(0, 20)","cb617012":"submission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": result\n})\nsubmission.to_csv('submission.csv', index=False)","c446532a":"Models from different classes are utilized (at least two from the following: KNN, linear models, RF, GBDT, NN)\n* KNN\n* linear models\n* GBDT\n\nHyperparameters of at least half of all models are not default","9037370d":"For non-tree-based models preprocessing is used or the absence of it is explained\n* normalize:[True] for Ridge model","5e0a7a8c":"At least one feature from \"Advanced Features II\" is utilized (Statistics and distance-based features, Matrix factorizations, Feature interactions, t-SNE)\n* Matrix factorizations with PCA","fdb1fe55":"Ensembling is utilized (linear combination counts)\n* linear combination\n\nFinal solution optimized for RMSE","168ae2e3":"Features from text are extracted\n* extract city name from the beginning of the shop_name","ea217cd4":"Several interesting observations about data are discovered and explained. This may be visualization of a target distribution, analysis of a time trend in data or investigation which led to a new feature creation.\n* number of items for month per shop visualization","e0cd95ca":"We can see that shops' montly sales approximately have a normal distribution so that we can use mean encoding later","7031f59a":"Mean-encoding is set up correctly, i.e. KFold or expanding mean methods are utilized\n* expanding mean methods are utilized"}}