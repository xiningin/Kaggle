{"cell_type":{"e6862de4":"code","512564d2":"code","8cac94b0":"code","e2fc9431":"code","8399f12b":"code","36c7e734":"code","70a355aa":"code","e49be1e8":"code","5a651291":"code","eb0286f8":"code","132b68d5":"code","573d6db4":"code","919b1941":"code","9a0c0598":"code","259ee0e7":"code","f272644d":"code","3f7a7e85":"code","558c5de9":"code","38e6d202":"code","6a64a024":"code","deffe284":"code","0b1cd912":"code","e271433d":"code","a9b0fc95":"code","3d3e1c87":"code","e1519e76":"code","bc667bf5":"code","57d0c54c":"code","41e6abde":"code","5756147a":"markdown","24fc0b2b":"markdown","9737f67d":"markdown","f362a9e7":"markdown","478d8c4a":"markdown","03ef7a9f":"markdown","7da4d1d6":"markdown","57b5ffc8":"markdown","4c11274e":"markdown","0795c495":"markdown","a19fec19":"markdown","ee4840c9":"markdown","a0968ef1":"markdown","72689fbc":"markdown","c5a9f2b9":"markdown","5ab490fc":"markdown","e7c860b8":"markdown","e1ad9941":"markdown","43020d90":"markdown","6e17148b":"markdown","b4312890":"markdown","986791e3":"markdown","0982b219":"markdown"},"source":{"e6862de4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","512564d2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nimport sys\nimport os\nimport pickle\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow import keras","8cac94b0":"audio_data = '..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/classical\/classical.00096.wav'\ndata , sr = librosa.load(audio_data)\nprint(type(data), type(sr))","e2fc9431":"librosa.load(audio_data, sr=45600)","8399f12b":"import IPython\nIPython.display.Audio(data, rate=sr)","36c7e734":"plt.figure(figsize=(12, 4))\nlibrosa.display.waveplot(data, color = \"#2B4F72\")\nplt.show()","70a355aa":"X = librosa.stft(data)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14, 6))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()","e49be1e8":"plt.figure(figsize=(14, 6))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\nplt.colorbar()","5a651291":"from sklearn.preprocessing import normalize\nspectral_rolloff = librosa.feature.spectral_rolloff(data+0.01, sr=sr)[0]\nplt.figure(figsize=(12, 4))\nlibrosa.display.waveplot(data, sr=sr, alpha=0.4, color = \"#2B4F72\")","eb0286f8":"plt.figure(figsize=(12, 4))\nlibrosa.display.waveplot(data, sr=sr, color=\"#2B4F72\")","132b68d5":"# Zooming in\nn0 = 9000\nn1 = 9100\nplt.figure(figsize=(14, 5))\nplt.plot(data[n0:n1], color=\"#2B4F72\")\nplt.grid()","573d6db4":"zero_crossings = librosa.zero_crossings(data[n0:n1], pad=False)\nprint(\"The number of zero-crossings is :\",sum(zero_crossings))","919b1941":"chromagram = librosa.feature.chroma_stft(data, sr=sr)\nplt.figure(figsize=(15, 5))\nlibrosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', cmap='coolwarm')","9a0c0598":"%matplotlib inline\nfrom keras import layers\nimport keras","259ee0e7":"df1 = pd.read_csv('..\/input\/gtzan-dataset-music-genre-classification\/Data\/features_3_sec.csv')\ndf1.head()","f272644d":"df1.shape","3f7a7e85":"df1.dtypes","558c5de9":"df1 = df1.drop(labels='filename',axis=1)","38e6d202":"genre_list = df1.iloc[:, -1]\nencoder = LabelEncoder()","6a64a024":"y = encoder.fit_transform(genre_list)","deffe284":"print(y)","0b1cd912":"print(df1.iloc[:, :-1])","e271433d":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(np.array(df1.iloc[:, :-1], dtype = float))","a9b0fc95":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)","3d3e1c87":"from keras.models import Sequential","e1519e76":"# Neural network\nmodel = Sequential()\nmodel.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","bc667bf5":"classifier = model.fit(X_train,\n                    y_train,\n                    epochs=100,\n                    batch_size=128)","57d0c54c":"test_loss, test_acc  = model.evaluate(X_test, y_test, batch_size=128)","41e6abde":"print(\"The test loss is :\",test_loss, \"\\nThe test accuracy is :\",test_acc)","5756147a":"In this Project we will see  how to handle sound files in python, compute sound and audio features from them, and run machine learning algorithms on them.","24fc0b2b":"**Plot Raw Wave File** : \n\nPlot Raw Wave plot is the amplitude envelope of a waveform","9737f67d":"We will drop the first column of \"filename\":","f362a9e7":"**Plot Spectrogram**:\n\nA spectrogram is a visual way of representing the signal loudness, of a signal over time at various frequencies present in a particular waveform. Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.","478d8c4a":"# Import the Libraries needed","03ef7a9f":"**Chroma feature**\n\nis a powerful tool for analyzing music whose pitches can be meaningfully categorized (often into twelve categories) and whose tuning approximates to the equal-tempered scale. One main property of chroma features is that they capture harmonic and melodic characteristics of music, while being robust to changes in timbre and instrumentation.\n\nThe link of the image: [https:\/\/wikivisually.com\/wiki\/Chroma_feature](http:\/\/)\n\n[![image.png](attachment:image.png)](http:\/\/)","7da4d1d6":"**pandas :** is a library written for the Python programming language allowing data manipulation and analysis. In particular, it provides data structures and operations for manipulating numerical arrays and time series.\n\n**numpy :** is an extension of the Python programming language, designed to manipulate multidimensional matrices or arrays as well as mathematical functions operating on these arrays.\n\n**matplotlib :** Matplotlib is a library of the Python programming language for plotting and visualizing data in graphical form. It can be combined with the NumPy and SciPy python libraries for scientific computation.\n\n**Scipy :** is a project aiming to unify and federate a set of Python libraries for scientific use. Scipy uses the arrays and matrices of the NumPy module.\n\n**Pickle :** is a python module that allows you to save one or more variables in a file and retrieve their values later. Variables can be of any type.\n\n**librosa :** It is a Python module to analyze audio signals in general but geared more towards music. It includes the nuts and bolts to build a MIR(Music information retrieval) system.\n\n**IPython.display :** lets you play audio directly in your notebook.\n\n**Librosa :**  is a python package for music and audio analysis. It provides the building blocks necessary to create music information retrieval systems.\n","57b5ffc8":"**Zero-Crossing Rate**:\n\na zero crossing is said to occur if successive samples have different\nalgebraic signs. The rate at which zero crossings occur is a simple measure of the frequency content of a\nsignal. Zero-crossing rate is a measure of number of times in a given time interval\/frame that the\namplitude of the speech signals passes through a value of zero\n\n[![image.png](attachment:image.png)](http:\/\/)","4c11274e":"This step :\n\n```\ndata , sr = librosa.load(audio_data)\n```\n\nloads and decodes the audio as a time series y, represented as a one-dimensional NumPy floating point array. The variable sr contains the sampling rate of y, that is, the number of samples per second of audio. By default, all audio is mixed to mono and resampled to 22050 Hz at load time. This behavior can be overridden by supplying additional arguments to librosa.load().\n\nAudio will be automatically resampled to the given rate (default sr=22050).\n\nTo preserve the native sampling rate of the file, use sr=None.\n\nWe can change this behavior by resampling at 45.6KHz.","0795c495":"This returns an audio time series as a numpy array with a default sampling rate(sr)","a19fec19":"# Visualizing Audio :","ee4840c9":"**Classification**","a0968ef1":"# Playing Audio:","72689fbc":"# Objectif:","c5a9f2b9":"# Training Our Model","5ab490fc":"With the use of IPython.display.Audio we will play the audio in our notebook.","e7c860b8":"Our Datasets contains 10 genres :\n*   Blues\n*   Classical\n*   Country\n*   Disco\n*   Hiphop\n*   Jazz\n*   Metal\n*   Pop\n*   Reggae\n*   Rock","e1ad9941":"**Preprocessing the Data**","43020d90":"The vertical axis represents frequencies (from 0 to 10kHz), and the horizontal axis represents the time of the clip. \n\n\nLet's Convert the frequency axis to a logarithm , because we see that all actions (in red) is taking place at the bottom of the spectrum.","6e17148b":"[![image.png](attachment:image.png)](http:\/\/)","b4312890":"We will now focus on the last column \"label\" the categorical column and we will try to encode it with the function LabelEncoder() of sklearn.preprocessing.","986791e3":"[](http:\/\/)**Spectral Rolloff**\n\n\nis the frequency below which a specified percentage of the total spectral energy","0982b219":"The graph shows 11 zero crossings. Let\u2019s verify it with Librosa."}}