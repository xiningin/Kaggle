{"cell_type":{"e9c65e1c":"code","b2aefe06":"code","54c7cc8f":"code","fad36c5c":"code","5e23fdf3":"code","4dc5d7da":"code","0571b554":"code","005e25e6":"code","537d3ba8":"code","9f6511f7":"code","e034741e":"code","36301472":"code","e1efd798":"code","e75b8e39":"code","6ff86398":"code","b56314f3":"code","614d9015":"code","4cea917a":"code","03e46ee1":"code","fcd72e18":"code","3d1e81aa":"markdown","a4dab19b":"markdown","d142acf2":"markdown","291822e2":"markdown","9818ec7b":"markdown","21bbe7dd":"markdown","97c0953f":"markdown"},"source":{"e9c65e1c":"import os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport numpy as np \nimport pandas as pd\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b2aefe06":"test = pd.read_csv('..\/input\/ubiquant-market-prediction\/example_test.csv')\nsub = pd.read_csv('..\/input\/ubiquant-market-prediction\/example_sample_submission.csv')\ncols = [f'f_{i}' for i in range(300)]","54c7cc8f":"%%time \ntrain = pd.read_pickle('..\/input\/ump-train-picklefile\/train.pkl')","fad36c5c":"train.head()","5e23fdf3":"test.head()","4dc5d7da":"train.info()","0571b554":"#Check if there'is null values\ntrain.isnull().sum()","005e25e6":"# When time_id = 0\ntrain[train['time_id']==0]","537d3ba8":"# When time_id = 1\ntrain[train['time_id']==1] ","9f6511f7":"train[cols].describe()","e034741e":"train['investment_id'].value_counts()","36301472":"train['investment_id'].nunique()","e1efd798":"train['time_id'].value_counts()","e75b8e39":"train['time_id'].nunique()","6ff86398":"train['target'].describe()","b56314f3":"# target distribution\nplt.figure(figsize=(18, 6))\nsns.histplot(train['target'],color=\"blue\", kde=True,bins=100)","614d9015":"# let's see the bahavior of the target by time.\ntrain['avg_target_per_time'] = train.groupby('time_id').target.transform('mean') ","4cea917a":"data = train[['time_id','avg_target_per_time']].set_index(\"time_id\")\nmoving_average = data['avg_target_per_time'].rolling(window=1,\n    center=True,      # puts the average at the center of the window \n).mean()              # compute the mean (could also do median, std, min, max, ...)\n\nax = data['avg_target_per_time'].plot(style=\".\", color=\"0.5\",figsize=(24,5))\nmoving_average.plot(ax=ax, linewidth=3, title=\"avg_target_per time_id\", legend=False);","03e46ee1":"import ubiquant \nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","fcd72e18":"for (test, sub) in iter_test:\n    preds = model.predict(test[features].values)\n    sub['target'] = preds  # make your predictions here\n    env.predict(sub)   # register your predictions","3d1e81aa":"# Submission","a4dab19b":"#### Great Thanks to [colum2131](https:\/\/www.kaggle.com\/columbia2131) for his [kernel](https:\/\/www.kaggle.com\/columbia2131\/speed-up-reading-csv-to-pickle) that reduces the size of the dataset. \n","d142acf2":"* No null values \ud83d\ude03","291822e2":"# In Progress .... \ud83c\udfc2\ud83c\udffb","9818ec7b":"# Hello kagglers \ud83d\ude4b\ud83c\udffb\u200d\u2642\ufe0f and Welcome to this new competition!","21bbe7dd":"# Exploratory Data Analysis (EDA)","97c0953f":"### Notes\n* The train dataset contains 3 141 410 rows and 304 columns.\n* So our objective is to predict the target column \"target\", First we will train our model with the train dataset and then test it with the test dataset \ud83e\uddd7\n* row_id - A unique identifier for the row.\n* time_id - The ID code for the time the data was gathered. The time IDs are in order, but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set.\n* investment_id - The ID code for an investment. Not all investment have data in all time IDs.\n* [f_0:f_299] - Anonymized features generated from market data."}}