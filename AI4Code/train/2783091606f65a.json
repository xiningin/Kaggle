{"cell_type":{"bf3b046e":"code","e7100d8e":"code","e4b4aef6":"code","7142f9ce":"code","cc31fad5":"code","fb8857b0":"code","96299118":"code","07e071a1":"code","96778cf0":"code","5bc1cff2":"code","ffda122e":"code","701d2a99":"code","7b4737cc":"code","5b2d2a88":"code","fd40e7a1":"code","9110ce15":"code","5833fb3b":"code","9cdb48df":"code","0e00d71a":"code","ccf367c5":"code","75bdbf94":"code","75d279eb":"code","5a45c994":"code","3835b2ac":"code","26c00edc":"code","ad957aeb":"code","22247242":"code","ad8b9403":"code","d3ebba62":"code","63ca42d5":"code","86fc2722":"code","bc154893":"code","2907726f":"code","8a53b155":"code","1959f332":"code","71ca2091":"code","b50127a7":"code","67efda08":"code","874623bd":"code","9d19bd18":"code","23a943bb":"code","722bc225":"code","7b93ca73":"code","4517c46b":"code","6d28661a":"code","ffde3c7e":"code","67e97245":"code","4d74a0d9":"code","83854844":"code","ec894a86":"code","2ac9634f":"code","a5502b2c":"code","2ed16952":"code","b43ff104":"code","deef6e38":"code","c65ecac9":"code","edecfb3b":"code","8388ada9":"code","f6d74491":"code","9fdec4cd":"code","7c638f21":"markdown","a59a118d":"markdown","1df86dfd":"markdown","2e6a9baf":"markdown","f8302b5b":"markdown","1717f672":"markdown","4bd21476":"markdown","a915a0aa":"markdown"},"source":{"bf3b046e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e7100d8e":"dataset = pd.read_csv('..\/input\/train.csv')\nresource = pd.read_csv('..\/input\/resources.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n ","e4b4aef6":"resource = resource.drop('description' , 1)\nresource = resource.set_index('id').sum(level = 0).reset_index()\ndataset = dataset.merge(resource , how= 'left' , on = 'id')\ntest = test.merge(resource , how= 'left' , on = 'id')\n","7142f9ce":"dataset['cost'] = dataset['quantity'] + dataset['price']\ntest['cost'] = test['quantity'] + test['price']","cc31fad5":"dataset.isna().sum()","fb8857b0":"test.isna().sum()","96299118":"\ndataset = dataset.drop(['quantity' , 'price'] ,1)\ndataset = dataset.drop(['project_essay_3', 'project_essay_4'] ,1)\n\ntest = test.drop(['quantity' , 'price'] ,1)\ntest = test.drop(['project_essay_3', 'project_essay_4'] ,1)\n","07e071a1":"dataset","96778cf0":"sns.catplot(x='school_state', y='project_is_approved',  kind='bar', data=dataset)","5bc1cff2":"sns.catplot(x='project_grade_category', y='project_is_approved',  kind='bar', data=dataset)","ffda122e":"dataset.drop(['project_grade_category' , 'school_state'] , axis =1 , inplace = True)\ntest.drop(['project_grade_category' , 'school_state'] , axis =1 , inplace = True)","701d2a99":"print(dataset[['project_subject_categories', 'project_is_approved']].groupby(['project_subject_categories']).mean())\nsns.catplot(x='project_subject_categories', y='project_is_approved',  kind='bar', data=dataset)","7b4737cc":"dataset.columns","5b2d2a88":"print(dataset[['teacher_prefix', 'project_is_approved']].groupby(['teacher_prefix']).mean())\nsns.catplot(x='teacher_prefix', y='project_is_approved',  kind='bar', data=dataset)","fd40e7a1":"print(dataset[['project_subject_subcategories', 'project_is_approved']].groupby(['project_subject_subcategories']).mean())\nsns.catplot(x='project_subject_subcategories', y='project_is_approved',  kind='bar', data=dataset)","9110ce15":"dataset['cost'].hist()","5833fb3b":"print(len(dataset))\nprint(dataset['project_is_approved'].sum())","9cdb48df":"group = pd.cut(dataset.cost, [0,1000,20000])\npiv_fare = dataset.pivot_table(index=group, columns='project_is_approved', values = 'cost', aggfunc='count')\npiv_fare.plot(kind='bar')","0e00d71a":"dataset['cost'][dataset['cost'] ==0].shape","ccf367c5":"dataset","75bdbf94":"group = pd.cut(dataset.teacher_number_of_previously_posted_projects, [0,5 , 10 , 20 , 30 ,40 , 50 , 60])\npiv_fare = dataset.pivot_table(index=group, columns='project_is_approved', values = 'teacher_number_of_previously_posted_projects', aggfunc='count')\npiv_fare.plot(kind='bar')\n\n","75d279eb":"print(dataset[['teacher_number_of_previously_posted_projects', 'project_is_approved']].groupby(pd.cut(dataset.teacher_number_of_previously_posted_projects, [0, 100 , 500 ])).mean())","5a45c994":"topic_prob = dataset[['project_subject_subcategories', 'project_subject_categories', 'project_is_approved']].groupby(['project_subject_categories' , 'project_subject_subcategories']).mean()\n","3835b2ac":"dataset = dataset.merge(topic_prob , how= 'left' , on = ['project_subject_categories' , 'project_subject_subcategories'])\ntest = test.merge(topic_prob , how= 'left' , on = ['project_subject_categories' , 'project_subject_subcategories'])\n","26c00edc":"dataset.drop(['project_subject_categories' , 'project_subject_subcategories'] , axis =1 , inplace = True)\ntest.drop(['project_subject_categories' , 'project_subject_subcategories'] , axis =1 , inplace = True)","ad957aeb":"dataset['project_essay_1'] = dataset['project_essay_1'] + dataset['project_essay_2']\ntest['project_essay_1'] = test['project_essay_1'] + test['project_essay_2']","22247242":"dataset.drop('project_essay_2' , axis =1 , inplace = True)\ntest.drop('project_essay_2' , axis =1 , inplace = True)","ad8b9403":"\"\"\"\nimport datetime\ndef dow(date):\n    days=[\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n    dayNumber=date.weekday()\n    return days[dayNumber]\ndef preprocess_price(price1):\n    for i in range(len(price1)): \n       price1.loc[i,'Day'] = int(price1.loc[i,'project_submitted_datetime'].split(' ')[0].split('-')[2])    \n       price1.loc[i,'Month'] = int(price1.loc[i,'project_submitted_datetime'].split(' ')[0].split('-')[1])    \n       price1.loc[i,'Year'] = int(price1.loc[i,'project_submitted_datetime'].split(' ')[0].split('-')[0])    \n       price1.loc[i , 'weekday'] = dow(datetime.date(int(price1.loc[i,'Year']) , int(price1.loc[i,'Month']) , int(price1.loc[i,'Day'])))\n    price1 = price1.drop('project_submitted_datetime' , axis =1)\n    return price1\n\"\"\"","d3ebba62":"#new_data = preprocess_price(dataset)","63ca42d5":"dataset","86fc2722":"dataset['topic_prob'] = dataset['project_is_approved_y']\ntest['topic_prob'] = test['project_is_approved']","bc154893":"dataset.drop('project_is_approved_y' , axis = 1 , inplace =True)\n","2907726f":"test.drop('project_is_approved' , axis = 1 , inplace =True)","8a53b155":"dataset","1959f332":"dataset.drop(['teacher_id' , 'project_resource_summary' , 'project_essay_1' , 'project_title'] , axis = 1 , inplace = True)\ntest.drop(['teacher_id' , 'project_resource_summary' , 'project_essay_1' , 'project_title'] , axis = 1 , inplace = True)","71ca2091":"dataset","b50127a7":"dataset['teacher_prefix'] = dataset['teacher_prefix'].replace('Mr.', 'general').replace('Mrs.', 'general').replace('Ms.', 'general').replace('Dr.', 'professional').replace('Teacher', 'professional')\ntest['teacher_prefix'] = test['teacher_prefix'].replace('Mr.', 'general').replace('Mrs.', 'general').replace('Ms.', 'general').replace('Dr.', 'professional').replace('Teacher', 'professional')","67efda08":"dataset.drop('project_submitted_datetime' , axis = 1 , inplace =True)\ntest.drop('project_submitted_datetime' , axis = 1 , inplace =True)","874623bd":"dataset","9d19bd18":"[dataset] = [pd.get_dummies(data = df, columns = ['teacher_prefix']) for df in [dataset]]\n[test] = [pd.get_dummies(data = df, columns = ['teacher_prefix']) for df in [test]]","23a943bb":"y = np.array(dataset['project_is_approved_x']).reshape( (len(dataset) , 1) )\ndataset.drop(['id', 'project_is_approved_x'] , axis = 1, inplace = True)\nid = test['id']\ntest.drop(['id'] , axis = 1, inplace = True)","722bc225":"from sklearn.preprocessing import Normalizer\nnormalizer = Normalizer()\ndataset.iloc[: , :3] = normalizer.fit_transform(dataset.iloc[: , :3])\n","7b93ca73":"test.fillna(test['topic_prob'].mean() , inplace = True , axis =1)","4517c46b":"test.iloc[: , :3] = normalizer.transform(test.iloc[: , :3])","6d28661a":"from sklearn.model_selection import train_test_split\nx_train , x_val , y_train , y_val = train_test_split(dataset , y , test_size = 0.2) ","ffde3c7e":"x_train.shape","67e97245":"# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(x_train, y_train, batch_size = 100, epochs = 10)\n\n# Part 3 - Making pred","4d74a0d9":"y_pred_ann = classifier.predict(x_val)\ny_pred_ann_threshold = classifier.predict(x_train)","83854844":"len(y_pred_ann_threshold[y_train == 0])","ec894a86":"y_pred_ann_threshold[y_train == 1][:22154]","2ac9634f":"y_train_thresh = np.concatenate(( y_pred_ann_threshold[y_train == 0] , y_pred_ann_threshold[y_train == 1][:28000]) , axis =0)","a5502b2c":"y_y_thresh = np.concatenate(( y_train[y_train == 0] , y_train[y_train == 1][:28000]) , axis =0)","2ed16952":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(y_train_thresh.reshape((len(y_train_thresh) , 1)) , y_y_thresh.reshape((len(y_y_thresh) , 1)))","b43ff104":"y_pred = log_reg.predict(y_pred_ann)","deef6e38":"from sklearn.metrics import confusion_matrix , accuracy_score\nprint(confusion_matrix(y_pred , y_val))\nprint(accuracy_score(y_pred , y_val))\n","c65ecac9":"print(len(y_val))\nprint(y_val.sum())","edecfb3b":"result = classifier.predict(test)","8388ada9":"result = log_reg.predict(result)","f6d74491":"final = pd.DataFrame()\nfinal['id'] = id\nfinal['project_is_approved'] = result","9fdec4cd":"final.to_csv('result_1.csv' , index = False)","7c638f21":"HENCE THE CHANCE OF A PROJECT BEING APPROVED IS ALMOST QUALLY LIKELY FROM ANY GRADE","a59a118d":"**NOW CHECKING WHETHER THE DATE OF PROPOSAL OF PROJECTS EFFECTS ITS CHANCES OF GETTING APPROVED**","1df86dfd":"**Hence no significant information based on date of proposal. therefore we can dop the date feature**","2e6a9baf":"**Hence the low cost projects are more likely to be approved**","f8302b5b":"HENCE MR. MRS. AND MS. HAVE ALMOST EQUALLY LIKELY RATE OF APPROVAL, WHICH IS HIGHER THAN TEACHER AND DR.","1717f672":"**hence the history of the person regarding projects proposed, effects the approval of currant project**\n\n\n","4bd21476":"AS WE HAVE OBSERVED EARLIER THAT, PROJECTS PITCHED BY MR. MRS. MS HAVE GREATER CHANCE TO BE SELECTED, RATHER THAN BY DR. OR TEACHER\n\nMR. , MRS. , MS -> GENERAL\nDR. , TEACHER -> PROFESSIONAL","a915a0aa":"HENCE THE CHANCE OF A PROJECT BEING APPROVED IS ALMOST QUALLY LIKELY FROM ANY STATE"}}