{"cell_type":{"5cfc48a3":"code","aa96ff2c":"code","47b2da3d":"code","2a9ebb59":"code","ae90d9ef":"code","da94c27c":"code","88164065":"code","2e3fde8a":"code","d2511e2f":"code","98be8de8":"code","ef027e08":"code","caf3d608":"code","9b9ed513":"code","594330bb":"code","478b84ce":"markdown"},"source":{"5cfc48a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# these are usuful libs for modeling\nfrom keras import models, layers\nfrom keras.utils import to_categorical\nfrom keras.layers import Convolution2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Dense, Lambda\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\") # suppress warnings\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","aa96ff2c":"# reading csv files\ntrain_data = pd.read_csv(r'\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv(r'\/kaggle\/input\/digit-recognizer\/test.csv')","47b2da3d":"print(train_data.shape)\nprint(test_data.shape)","2a9ebb59":"# scaling the value in 0-1 , so \/255. \nX = train_data.iloc[:,1:]\nX \/= 255\n#X = np.array(X, dtype='float32')\nprint(\"X matrix shape:\", X.shape)\n\ny = train_data.iloc[:,0]\n#y = np.array(y, dtype='float32')\nprint(\"y matrix shape:\", y.shape)\n\ntest = test_data\/255\n#test = np.array(test, dtype='float32')","ae90d9ef":"X = X.values.reshape(train_data.shape[0],28,28,1)\ntest = test.values.reshape(test_data.shape[0],28,28,1)","da94c27c":"# Plot examples of the data.\nplt.figure(1, figsize=(14,3))\nfor i in range(10):\n    plt.subplot(1,10,i+1)\n    plt.imshow(X[i].reshape(28,28), cmap='gray', interpolation='nearest')\n    plt.xticks([])\n    plt.yticks([])","88164065":"# one hot of target values using keras's to_categorical class\ny = to_categorical(y)\n\n# splits train\/test set \nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size =0.3,random_state=29)","2e3fde8a":"Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape","d2511e2f":"# need BatchNormalization, normalize the batch\nmean_px = Xtrain.mean().astype(np.float32)\nstd_px = Xtrain.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)\/std_px","98be8de8":"# this is a sequential model with the classic keras CNN architecture with batch added layers of: \n#normalization, Conv2D, MaxPooling, Flatten, Dense, Dropout\n#rectified linear unit 'relu' and 'softmax' for activation\n#adaptive moment estimation 'adam' for optimizer (rmsprop not the best to use for this scenario)\n#categorical cross entropy performs better than binary loss function\n#\ndef digit_model():\n    model = models.Sequential()\n    model.add(Lambda(standardize,input_shape=(28,28,1)))\n    model.add(Convolution2D(32,(3,3), activation = 'relu'))\n    model.add(BatchNormalization(axis=1))   \n    model.add(Convolution2D(64,(3,3), activation = 'relu'))\n    model.add(MaxPooling2D())\n    model.add(Convolution2D(128,(3,3), activation = 'relu'))\n    model.add(BatchNormalization(axis=1))\n    model.add(Convolution2D(128,(2,2), activation = 'relu'))\n    model.add(MaxPooling2D())\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(10, activation='softmax'))          \n    model.compile(optimizer='adam', loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model   ","ef027e08":"classifier = digit_model()\n# traing the model with 10 epochs and 1000 batch size\nclassifier.fit(Xtrain, ytrain, epochs=40,batch_size=1000,validation_data=(Xtest,ytest))","caf3d608":"#prediction of submission_test set\nprediction = classifier.predict(test)\npredictions = np.argmax(prediction, axis=1)","9b9ed513":"# submission\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\n\nsubmissions.shape","594330bb":"import os\nos.chdir(r'\/kaggle\/working')\n\nsubmissions.to_csv('sub20.csv', index=False)\n#print(\"save success\")\n\nfrom IPython.display import FileLink\nFileLink(r'sub20.csv')","478b84ce":"* 42,00 images in train dataset and the image size (28,28) represents image size as 28 x 28 pixels \n* need to convert images to 4-dim for keras api"}}