{"cell_type":{"b612846a":"code","aab64f58":"code","07ecc91a":"code","b66e4a26":"code","fba24e44":"code","dbd1bbbe":"markdown","74c388d2":"markdown","c6020940":"markdown","f1d63fc5":"markdown"},"source":{"b612846a":"import pandas as pd\nimport plotly.express as px","aab64f58":"data_path = \"..\/input\/commonlit-text-features\/augmented_df.csv\"\ndf = pd.read_csv(data_path)","07ecc91a":"print(df.columns)\ndf.head()","b66e4a26":"target_col = \"target\"\nfeature_cols = df.columns[4:]","fba24e44":"for feat in feature_cols:\n    fig = px.scatter(df, x=feat, y=target_col)\n    fig.show()","dbd1bbbe":"# Plotting time!","74c388d2":"# Conclusion\n\nA visual inspection shows there are some potentially useful correlations between these metrics and the target variable. This means they might be used in some models, or as a quick sanity check for out-of-sample forecasting, to ensure models don't return crazy values when seeing test data.","c6020940":"# Objective\n\nThe goal of this notebook is to show the correlation of text features such as readability scores with the relative complexity rating (the \"target\" variable) of the CommonLit Readability challenge.","f1d63fc5":"# Data\n\nLet's see how the data looks like:"}}