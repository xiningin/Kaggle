{"cell_type":{"21009c86":"code","92d2e832":"code","99547931":"code","eeb20989":"code","0d39e91a":"code","fa71a352":"code","7c89c9a6":"code","0c3ba3c5":"code","8953f127":"code","5b86da10":"code","f7ae9e84":"code","205ec5f4":"code","81621a64":"code","3fc56bd7":"code","d04f5b07":"code","f8c7e729":"code","221ccaae":"code","7a25ef94":"code","9b8347af":"code","73295837":"code","6978e284":"code","f664d9be":"code","10132117":"code","b183a3f4":"code","7e2f6d39":"code","b187fa2b":"code","5715923d":"code","77cf1feb":"code","c60f447f":"code","65b5d253":"code","df9ea4fb":"code","ce7c0437":"code","05832580":"markdown","f85c0cfb":"markdown","a41acb4d":"markdown","f425386a":"markdown","7630e43a":"markdown","d0bac5c7":"markdown","fb7c1495":"markdown","87d31bd1":"markdown","d2ff6b67":"markdown","899be971":"markdown","0412782c":"markdown","600209e3":"markdown"},"source":{"21009c86":"import pandas as pd\nimport numpy as np\nimport re\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom nltk.corpus import words\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import preprocessing\n\nfrom nltk.stem import WordNetLemmatizer","92d2e832":"train = pd.read_csv('\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv', encoding=\"ISO-8859-1\", low_memory=False)\ntest = pd.read_csv('\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv', encoding=\"ISO-8859-1\", low_memory=False) \ndf = train.append(test, sort = False)","99547931":"df.head(20)","eeb20989":"df['Sentiment'].unique()","0d39e91a":"mapping = {'Neutral' : 0, 'Positive' : 1, 'Extremely Negative' : -1, 'Negative' : -1,'Extremely Positive' : 1}\ndf['label'] = df['Sentiment'].map(mapping)","fa71a352":"df.head(20)","7c89c9a6":"columns_to_keep = ['OriginalTweet','label']\ndf = df[columns_to_keep]","0c3ba3c5":"df.head(20)","8953f127":"df.dropna(inplace=True)","5b86da10":"def url_cleaning(tweet):\n    url_pattern = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url_pattern.sub(r'link', tweet)\n\ndf['OriginalTweet'] = df['OriginalTweet'].apply(url_cleaning)\ndisplay(df['OriginalTweet'].head(5))","f7ae9e84":"\ndef text_cleaning_1(tweet):\n    tweet = re.sub(r\" usa \", \" America \", tweet)\n    tweet = re.sub(r\" USA \", \" America \", tweet)\n    tweet = re.sub(r\" u s \", \" America \", tweet)\n    tweet = re.sub(r\" uk \", \" England \", tweet)\n    tweet = re.sub(r\" UK \", \" England \", tweet)\n    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n    tweet = re.sub(r\"the US\", \"America\", tweet)\n    tweet = re.sub(r\"Coronavirus\", \" covid \", tweet)\n    tweet = re.sub(r\"Covid19\", \" covid \", tweet)\n    tweet = re.sub(r\"\\W\", \" \", tweet)\n    tweet = re.sub(r\"_\", \" \", tweet)\n    return str(tweet)","205ec5f4":"df['OriginalTweet'] = df['OriginalTweet'].apply(text_cleaning_1)\ndisplay(df['OriginalTweet'].head(5))","81621a64":"df.head(20)","3fc56bd7":"df['OriginalTweet'] = df['OriginalTweet'].str.lower()","d04f5b07":"def stop_word(tweet): \n    stop_words = set(stopwords.words('english')) \n\n    word_tokens = word_tokenize(tweet) \n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    filtered_sentence = [] \n\n    for w in word_tokens: \n        if w not in stop_words: \n            filtered_sentence.append(w) \n    return ' '.join(filtered_sentence)","f8c7e729":"df['OriginalTweet'] = df['OriginalTweet'].apply(stop_word)","221ccaae":"df['OriginalTweet'].head(20)","7a25ef94":"#spell = SpellChecker()\ndef correct_spellings(text):\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    words = text.split()\n    for word in words:\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        elif word not in misspelled_words:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)","9b8347af":"#df['OriginalTweet'] = df['OriginalTweet'].apply(correct_spellings)","73295837":"df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)\nlem = WordNetLemmatizer()\ndef lemma_wordnet(input):\n    return [lem.lemmatize(w) for w in input]\ndf['OriginalTweet'] = df['OriginalTweet'].apply(lemma_wordnet)","6978e284":"def combine_word(tweet):\n    return \" \".join(tweet)\ndf['OriginalTweet'] = df['OriginalTweet'].apply(combine_word)","f664d9be":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(df['OriginalTweet'], \n                                                    df['label'], \n                                                    random_state=0)","10132117":"vect = CountVectorizer(min_df=5, ngram_range=[1,4], analyzer='char_wb').fit(X_train)\nX_train_vect = vect.transform(X_train)\nX_test_vect = vect.transform(X_test)","b183a3f4":"vect = TfidfVectorizer(min_df=3, ngram_range=[1,4]).fit(X_train)\nX_train_vect_TFID = vect.transform(X_train)\nX_test_vect_TFID = vect.transform(X_test)","7e2f6d39":"def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = preprocessing.LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)","b187fa2b":"print(\"MultinomialNB with CountVectorizer\\n\")\nalpha = [0.01, 0.1, 1.0, 5.0, 10.0, 20.0, 100.0]\nfor value in alpha:\n    model = MultinomialNB(alpha = value).fit(X_train_vect, y_train)\n    y_predicted = model.predict(X_test_vect)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With alpha set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","5715923d":"print(\"MultinomialNB with Tfid Vectorizer\\n\")\nalpha = [0.01, 0.1, 1.0, 5.0, 10.0, 20.0, 100.0]\nfor value in alpha:\n    model = MultinomialNB(alpha = value).fit(X_train_vect_TFID, y_train)\n    y_predicted = model.predict(X_test_vect_TFID)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With alpha set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","77cf1feb":"print(\"DecisionTreeClassifier with CountVectorizer\\n\")\ndepth = [3,6,9,12,15]\nfor value in depth:\n    model = DecisionTreeClassifier(max_depth = value).fit(X_train_vect, y_train)\n    y_predicted = model.predict(X_test_vect)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With max_depth set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","c60f447f":"print(\"DecisionTreeClassifier with CountVectorizer\\n\")\ndepth = [3,6,9,12,15]\nfor value in depth:\n    model = DecisionTreeClassifier(max_depth = value).fit(X_train_vect_TFID, y_train)\n    y_predicted = model.predict(X_test_vect_TFID)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With max_depth set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","65b5d253":"print(\"Logistic Regression with CountVectorizer\\n\")\nC = [ 1, 5, 10, 20, 100, 1000]\nfor value in C:\n    model = LogisticRegression(C = value,solver='lbfgs').fit(X_train_vect, y_train)\n    y_predicted = model.predict(X_test_vect)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With C set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","df9ea4fb":"print(\"Logistic Regression with Tfid Vectorizer\\n\")\nC = [ 1, 5, 10, 20, 100, 1000]\nfor value in C:\n    model = LogisticRegression(C = value,solver='lbfgs').fit(X_train_vect_TFID, y_train);\n    y_predicted = model.predict(X_test_vect_TFID); \n    score = multiclass_roc_auc_score(y_test, y_predicted);\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With C set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\");","ce7c0437":"print(\"Rigid with Tfid Vectorizer\\n\")\nC = [ 1, 5, 10, 20, 100, 1000]\nfor value in C:\n    model = RidgeClassifier(alpha = value).fit(X_train_vect_TFID, y_train)\n    y_predicted = model.predict(X_test_vect_TFID)\n    score = accuracy_score(y_test, y_predicted)\n    acc_score = multiclass_roc_auc_score(y_test, y_predicted)\n    print(f\"With C set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\");","05832580":"### Tokenize and Lemmatizer","f85c0cfb":"## Vectorization with TFID vectorizer","a41acb4d":"####  Decision Tree Classifier","f425386a":"#### Split data into Train and Test data sets ","7630e43a":"### Lower Case","d0bac5c7":"#### Rigid","fb7c1495":"### Removing Urls","87d31bd1":"## Applying ML","d2ff6b67":"## Vectorization with CountVectorizer","899be971":"#### MultinomialNB","0412782c":"### Logistic Regression","600209e3":"### Removing Stop words"}}