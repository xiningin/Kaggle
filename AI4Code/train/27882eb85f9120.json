{"cell_type":{"0d967348":"code","4c507720":"code","8506abd8":"code","4d8f475e":"code","f04350c4":"code","d19cb5e8":"code","c46be565":"code","a2d10de4":"code","982465c1":"code","a0e658fa":"code","84dcecd8":"markdown","30dd35b5":"markdown","77538b12":"markdown","3a88ca24":"markdown","6fd4bf93":"markdown","e9c293dc":"markdown","91a348f7":"markdown","ed1cf2db":"markdown","8f1bc484":"markdown","9289ce01":"markdown"},"source":{"0d967348":"# \u4e0b\u8f7d\u6570\u636e\u96c6\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom pathlib import Path\nfrom colorama import Fore, Back, Style\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, Image\n\n\nROOT_DIR = Path(\"\/kaggle\/input\/tensorflow-great-barrier-reef\")\n\nTRAIN_CSV = ROOT_DIR \/ \"train.csv\"\nTRAIN_DF = pd.read_csv(TRAIN_CSV)\n\nTEST_CSV = ROOT_DIR \/ \"test.csv\"\nTEST_DF = pd.read_csv(TEST_CSV)\n\nlist(ROOT_DIR.iterdir())","4c507720":"import json\n\n# \u8ba1\u6570\u68c0\u6d4b\nif \"detection_count\" not in TRAIN_DF.columns:\n    det_counts = TRAIN_DF.apply(lambda row: len(eval(row.annotations)), axis=1)\n    TRAIN_DF[\"detection_count\"] = det_counts","8506abd8":"print(TRAIN_DF.info())\nprint()","4d8f475e":"eq_frames = TRAIN_DF[TRAIN_DF[\"video_frame\"] == TRAIN_DF[\"sequence_frame\"]]\nuneq_frames = TRAIN_DF[TRAIN_DF[\"video_frame\"] != TRAIN_DF[\"sequence_frame\"]]\nprint(\"eq frames, uneq frames:\", eq_frames.size, uneq_frames.size)\nprint()\n#\u5e8f\u5217\u4ece0\u5f00\u59cb\uff0c\u53ef\u80fd\u5728\u770b\u4e0d\u5230\u6d77\u661f\u7684\u5730\u65b9\u526a\u8f91\u4e86\u89c6\u9891\n#\u89c6\u9891\u88ab\u5206\u5272\u6210\u5e8f\u5217\uff0c\u6bcf\u4e2a\u5e8f\u5217\u4ece0\u5e27\u5230n\u5e27","f04350c4":"print(\"Sequence frames sequential and start from 0?\")\nfor seq_name in TRAIN_DF[\"sequence\"].unique():\n    sequential = True\n    numbers = TRAIN_DF[TRAIN_DF[\"sequence\"] == seq_name][\"sequence_frame\"].values\n    numbers.sort()\n    \n    i = 0\n    for num in numbers:\n        while i < num:\n            print(f\"Seq {seq_name}: {Fore.RED}Missing {i}{Fore.RESET}\")\n            i += 1\n        i += 1\n\n    if sequential:\n        print(f\"Seq {seq_name}: {Fore.GREEN}Yes{Fore.RESET}\")\nprint()\n# \u53ef\u4ee5  ","d19cb5e8":"print(\"Video frames sequential?\")\nfor seq_name in TRAIN_DF[\"sequence\"].unique():\n    sequential = True\n    numbers = TRAIN_DF[TRAIN_DF[\"sequence\"] == seq_name][\"video_frame\"].values\n    numbers.sort()\n    \n    i = numbers[0]\n    for num in numbers:\n        while i < num:\n            print(f\"Seq {seq_name}: {Fore.RED}Missing {i}{Fore.RESET}\")\n            i += 1\n        i += 1\n\n    if sequential:\n        print(f\"Seq {seq_name}: {Fore.GREEN}Yes{Fore.RESET}\")\nprint()\n#\u5728\u8bc4\u4f30\u65f6\u662f\u5426\u4f1a\u7ed9\u51fa\u987a\u5e8f\u6570\u636e\u3002\n# image id\u662f\u5426\u53ea\u8fde\u63a5frame id\u548cvideo id \nnew_vid_ids = TRAIN_DF[\"video_id\"].astype(str) + \"-\" + TRAIN_DF[\"video_frame\"].astype(str)\nprint(\"How many images have strange image_ids:\", (TRAIN_DF[\"image_id\"] != new_vid_ids).sum())\n# \u662f\u7684","c46be565":"vid_seq_pairs = TRAIN_DF[[\"video_id\", \"sequence\"]].drop_duplicates()\nrepeated_sequence_count = (vid_seq_pairs[\"sequence\"].value_counts() != 1).sum()\nprint(\"How many repeated sequences:\", repeated_sequence_count)\n# \u5e8f\u5217\u662f\u552f\u4e00\u7684","a2d10de4":"print(f\"Starfish per image:\", TRAIN_DF[\"detection_count\"].value_counts())\n\nbin_count = len(TRAIN_DF[\"detection_count\"].unique())\nplot = TRAIN_DF.hist(column=\"detection_count\", figsize=(16,6), bins=bin_count)\nax = plot[0][0]\nax.set_title(\"Starfish count, per image\")\n\nTRAIN_DF_WITH_STARFISH = TRAIN_DF[TRAIN_DF[\"detection_count\"] > 0]\nbin_count = len(TRAIN_DF_WITH_STARFISH[\"detection_count\"].unique())\nplot = TRAIN_DF_WITH_STARFISH.hist(column=\"detection_count\", figsize=(16,4), bins=bin_count)\nax = plot[0][0]\nax.set_title(\"Starfish count, per image (with 0 detections removed)\");","982465c1":"import math \n\n\nSEQUENCE_COUNT = len(TRAIN_DF[\"sequence\"].drop_duplicates())\nFIG_COLS = 3\nFIG_ROWS = math.ceil(SEQUENCE_COUNT \/ FIG_COLS)\nfig = plt.figure(figsize=(30, 30), constrained_layout=True)\n# fig.tight_layout(pad=10.0)\n# fig.tight_layout()\n\ndet_data = TRAIN_DF[[\"sequence\", \"video_id\", \"sequence_frame\", \"detection_count\"]].drop_duplicates()\nfor i, seq_num in enumerate(det_data[\"sequence\"].unique()):  # we know seq numbers are unique in train data\n    #\u83b7\u53d6\u6570\u636e\n    seq_data = det_data[det_data[\"sequence\"] == seq_num].sort_values(by=\"sequence_frame\")\n    seq_data = seq_data.set_index(seq_data[\"sequence_frame\"]).drop(columns=\"sequence_frame\")\n    video_id = seq_data[\"video_id\"].iloc[0]\n    \n    #\u9009\u62e9\u56fe\u5f62\u4f4d\u7f6e\n    col = (i % FIG_COLS) + 1\n    row = (i \/\/ FIG_COLS) + 1\n    \n    #\u7ec6\u8282\n    ax = plt.subplot(FIG_ROWS, FIG_COLS, i+1)\n    ax = seq_data[\"detection_count\"].plot.line(ax=ax)\n    ax.set_title(f\"Video {video_id}, Sequence {seq_num}\", fontsize=22)\n    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n    ax.set_xlabel('Detections', fontsize=16)\n    ax.set_ylabel('Sequence Frame', fontsize=16)\n    \n","a0e658fa":"#\u7f13\u5b58\nvideo_ids = TRAIN_DF[\"video_id\"].unique()\nsel_video_id = 0\nsel_video_df = TRAIN_DF[TRAIN_DF[\"video_id\"] == sel_video_id]\n\nsequences = sel_video_df[\"sequence\"].unique()\nsel_sequence = sequences[0]\nsel_sequence_df = sel_video_df[sel_video_df[\"sequence\"] == sel_sequence]\n\nlast_frame = sel_sequence_df[\"sequence_frame\"].max()\nsel_sequence_frame = 0\nsel_sequence_frames = sel_sequence_df[sel_sequence_df[\"sequence_frame\"] == sel_sequence_frame]\nassert len(sel_sequence_frames) == 1\nsel_video_frame = sel_sequence_frames[\"video_frame\"].values[0]\nsel_annotation = eval(sel_sequence_frames[\"annotations\"].values[0])\n  \n#UI\u5143\u7d20\ndd_video_id = widgets.Dropdown(options=video_ids, description='Video ID:')\ndd_sequence = widgets.Dropdown(options=sequences, description='Sequence:')\nbtn_first = widgets.Button(description=\"\u23ee\ufe0f\")\nbtn_back_50 = widgets.Button(description=\"\u23ea\")\nbtn_back = widgets.Button(description=\"\u25c0\ufe0f\")\nbtn_forward = widgets.Button(description=\"\u25b6\ufe0f\")\nbtn_forward_50 = widgets.Button(description=\"\u23e9\")\nbtn_last = widgets.Button(description=\"\u23ef\")\n\nout = widgets.Output()\n\ndd_row = widgets.HBox([dd_video_id, dd_sequence])\nbtn_row = widgets.HBox([btn_first, btn_back_50, btn_back, btn_forward, btn_forward_50, btn_last])\nall_widgets = widgets.VBox([dd_row, btn_row, out])\n\n#\u9009\u62e9\u52a9\u624b-\u53ea\u66f4\u6539\u6570\u636e\ndef set_frame(new_number):\n    global sel_sequence_frame\n    global sel_sequence_frames\n    global sel_video_frame\n    global sel_annotation\n    \n    sel_sequence_frame = max(0, min(new_number, last_frame))\n    sel_sequence_frames = sel_sequence_df[sel_sequence_df[\"sequence_frame\"] == sel_sequence_frame]\n    assert len(sel_sequence_frames) == 1\n    sel_video_frame = sel_sequence_frames[\"video_frame\"].values[0]\n    \n    sel_annotation = eval(sel_sequence_frames[\"annotations\"].values[0])\n\ndef set_sequence(new_number):\n    global sel_sequence\n    global sel_sequence_df\n    global last_frame\n\n    sel_sequence = new_number\n    sel_sequence_df = sel_video_df[sel_video_df[\"sequence\"] == sel_sequence]\n    last_frame = sel_sequence_df[\"sequence_frame\"].max()\n\n    set_frame(0)\n    \ndef set_video_id(new_id):\n    global sel_video_id\n    global sel_video_df\n    global sequences\n    \n    sel_video_id = new_id\n    sel_video_df = TRAIN_DF[TRAIN_DF[\"video_id\"] == sel_video_id]\n\n    sequences = sel_video_df[\"sequence\"].unique()\n    set_sequence(sequences[0])\n    \n#UI\u52a9\u624b-\u5904\u7406UI\u4e8b\u4ef6+\u8c03\u7528\u9009\u62e9\u52a9\u624b\ndef clear_output():\n    out.clear_output()\n    \ndef draw_image():\n    img_path = ROOT_DIR \/ \"train_images\" \/ f\"video_{sel_video_id}\" \/ f\"{sel_video_frame}.jpg\"\n    assert img_path.is_file(), f\"Cannot find image {img_path}\"\n    cv_img = cv2.imread(str(img_path))\n    cv_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n    \n    draw_bboxes(cv_img, sel_annotation)\n\n    with out:\n        print(\"Image\", img_path)\n\n        #\u627e\u5230\u4e00\u79cd\u65b9\u6cd5\u6765\u66f4\u65b0\u56fe\u50cf\u800c\u4e0d\u6e05\u9664\u8f93\u51fa\n        img_fig = plt.figure(figsize=(20,16), facecolor=\"#123456ff\", frameon=False)\n        img_ax = img_fig.add_subplot(1, 1, 1)\n        img_ax.get_xaxis().set_visible(False)\n        img_ax.get_yaxis().set_visible(False)\n        img_ax.use_sticky_edges = False\n        # img_ax.margins(x=0)  \n        #\u7528\u989c\u8272\u900f\u660e\u4ee3\u66ff\u4f5c\u4e3a\u4e00\u4e2ahack\u3002\n\n        img_ax.imshow(cv_img)\n        plt.show()\n\n    \ndef draw_bboxes(cv_img, annotations):\n    BBOX_COLOR_RGB = (255,126,0)\n    for ann in annotations:\n        cv2.rectangle(\n            cv_img,\n            (ann[\"x\"] ,ann[\"y\"]),\n            (ann[\"x\"] + ann[\"width\"], ann[\"y\"] + ann[\"height\"]),\n            color=BBOX_COLOR_RGB,\n            thickness=3\n        )\n\ndef on_click_forward(b):\n    with out:\n        set_frame(sel_sequence_frame + 1)\n        clear_output()\n        draw_image()\nbtn_forward.on_click(on_click_forward)\ndef on_click_back(b):\n    with out:\n        set_frame(sel_sequence_frame - 1)\n        clear_output()\n        draw_image()\nbtn_back.on_click(on_click_back)\ndef on_click_forward_50(b):\n    with out:\n        set_frame(sel_sequence_frame + 50)\n        clear_output()\n        draw_image()\nbtn_forward_50.on_click(on_click_forward_50)\ndef on_click_back_50(b):\n    with out:\n        set_frame(sel_sequence_frame - 50)\n        clear_output()\n        draw_image()\nbtn_back_50.on_click(on_click_back_50)\ndef on_click_first(b):\n    with out:\n        set_frame(0)\n        clear_output()\n        draw_image()\nbtn_first.on_click(on_click_first)\ndef on_click_last(b):\n    with out:\n        set_frame(last_frame)\n        clear_output()\n        draw_image()\nbtn_last.on_click(on_click_last)\n\ndef on_sequence_change(change):\n    with out:\n        if change[\"old\"] == change[\"new\"]:\n            return\n        set_sequence(change[\"new\"])\n\n        clear_output()\n        draw_image()\ndd_sequence.observe(on_sequence_change, names=\"value\")\n\ndef on_video_id_change(change):\n    with out:\n        if change[\"old\"] == change[\"new\"]:\n            return\n        set_video_id(change[\"new\"])\n        dd_sequence.options = sequences\n        \n        clear_output()\n        draw_image()\ndd_video_id.observe(on_video_id_change, names=\"value\")\n\n\ndisplay(all_widgets)\ndraw_image()","84dcecd8":"### video_frames\u987a\u5e8f","30dd35b5":"## \u7528\u5e38\u7528\u7684\u4e1c\u897f\u6765\u6269\u5145","77538b12":"## \u6ce8\u91ca","3a88ca24":"### \u89c6\u9891\u72ec\u7279\u7684\u5e8f\u5217\u540d\u00b6","6fd4bf93":"# Data Exploration","e9c293dc":"## \u5728\u5e27\u4e2d\u68c0\u6d4b\u5982\u4f55\u6539\u53d8\u7684","91a348f7":"## \u5217","ed1cf2db":"### sequence_frame\u4e0evideo_frame","8f1bc484":"## sequence_frames\u4ece0\u5230N","9289ce01":"##\u6ce8\u91ca\u7684\u5206\u53d1"}}