{"cell_type":{"b3b857f1":"code","31fae310":"code","98d7a5aa":"code","0d102c66":"code","011610ba":"code","c15e9f8e":"code","6063a156":"code","9041d53d":"code","02d1507c":"code","8445ebcc":"code","d0861112":"code","f20a41ae":"code","cc7db273":"code","eb97418d":"code","57f249ae":"code","bd617874":"code","23f9b0e3":"code","2f0bf029":"code","bdbd7c71":"code","3334f659":"code","5deea3a2":"code","0b1aaeaf":"code","a41df76a":"code","c6f3c2df":"code","df6b1cc0":"code","ec13de20":"code","433210bf":"code","a0c918cb":"code","7346abe0":"code","9193b41b":"code","1e597a0a":"code","0dd33880":"code","4718cd46":"code","3dbbbdf2":"markdown","792f750a":"markdown","a999a571":"markdown","205fee3a":"markdown","bb0696e3":"markdown"},"source":{"b3b857f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","31fae310":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n%matplotlib inline","98d7a5aa":"df_train = pd.read_csv('..\/input\/train.csv')","0d102c66":"df_test = pd.read_csv('..\/input\/test.csv')","011610ba":"print(df_train.shape)\nprint(df_test.shape)","c15e9f8e":"## as we have many column, set below properties, else all column will not be shown when you will describe\npd.set_option('display.max_columns', None) ","6063a156":"df_train.describe()","9041d53d":"df_train.info()","02d1507c":"## check if any column is null\ndf_train.isnull().sum().any()","8445ebcc":"df_train.columns","d0861112":"df_train.Cover_Type.value_counts()\n## we can see 7 cover types are there and count is also same","f20a41ae":"data_corr = df_train.corr()\nsize=10\nthreshold=0.5\n#create a dataframe with only 'size' features\ndata=df_train.iloc[:,:size] \n\n#get the names of all the columns\ncols=data.columns \ncorr_list=[]\nfor i in range(0,size):\n    for j in range(i+1, size):\n        if (data_corr.iloc[i,j] >= threshold and data_corr.iloc[i,j] < 1) or (data_corr.iloc[i,j] < 0 and data_corr.iloc[i,j] <= -threshold):\n            corr_list.append([data_corr.iloc[i,j],i,j])","cc7db273":"#Sort to show higher ones first            \ns_corr_list = sorted(corr_list,key=lambda x: -abs(x[0]))\n\n#Print correlations and column names\nfor v,i,j in s_corr_list:\n    print (\"%s and %s = %.2f\" % (cols[i],cols[j],v))","eb97418d":"## check the skewness of the data\ndf_train.skew()","57f249ae":"col_list=df_train.columns\ncol_list = [col for col in col_list if not 'Soil' in col]","bd617874":"plt.figure(figsize=(12,8))\nsns.heatmap(df_train[col_list].corr(),annot=True)","23f9b0e3":"sns.pairplot(df_train[col_list],hue='Cover_Type')","2f0bf029":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score","bdbd7c71":"X = df_train.drop(['Id','Cover_Type'],axis=1)\ny = df_train['Cover_Type']","3334f659":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nmodels = []\nmodels.append(('LR',LogisticRegression()))\nmodels.append(('DT',DecisionTreeClassifier()))\nmodels.append(('GB',GaussianNB()))\nmodels.append(('RFC',RandomForestClassifier()))\n\nresults=[]\nnames=[]\nscoring='accuracy'\nfor name,model in models:\n    kfold = model_selection.KFold(n_splits=20,random_state=12345)\n    cv_results = model_selection.cross_val_score(model,X, y, cv=kfold,scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name,cv_results.mean(),cv_results.std())\n    print(msg)","5deea3a2":"rf = RandomForestClassifier()","0b1aaeaf":"train_X = df_train.drop(['Id','Cover_Type'],axis=1)\ntrain_Y = df_train['Cover_Type']\ntest_x = df_test.drop('Id',axis=1)","a41df76a":"from sklearn.model_selection import train_test_split\n##Split the training set into training and validation sets\nX_train,X_test,Y_train,Y_test = train_test_split(train_X,train_Y,test_size=0.2)","c6f3c2df":"rf.fit(X_train,Y_train)","df6b1cc0":"y_predict = rf.predict(X_test)","ec13de20":"from sklearn.metrics import classification_report,accuracy_score\nprint(classification_report(Y_test,y_predict))\nprint(accuracy_score(Y_test,y_predict))","433210bf":"\ntest_id = pd.DataFrame(df_test.Id)","a0c918cb":"test_id.head()","7346abe0":"test_id['Cover_Type']=rf.predict(df_test.drop('Id',axis=1))","9193b41b":"test_id.head()","1e597a0a":"data_to_submit = pd.DataFrame({\n    'Id':test_id['Id'],\n    'Cover_Type':test_id['Cover_Type']\n})","0dd33880":"data_to_submit.head()","4718cd46":"data_to_submit.to_csv('Forest_Cover_Type.submit.csv', index = False)","3dbbbdf2":"### Visualization","792f750a":"#### Comapre the model which gives best accuracy with this data","a999a571":"### Random Forest model gives best accuracy than any other model","205fee3a":"#### No attribute is missing as count is 15120 for all attributes. Hence, all rows can be used\n#### Soil_Type7 and Soil_Type15 are constant. we can drop\n#### Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology,Horizontal_Distance_To_Roadways --skewed\n#### Vertical_Distance_To_Hydrology is negetive.\n#### Wilderness_Area and Soil_Type are one hot encoded. Hence, they could be converted back for some analysis\u00b6","bb0696e3":"#### Get the top 5 correlated feature"}}