{"cell_type":{"257cabf4":"code","3d470e03":"code","c13be67f":"code","765a5995":"code","d3b4647e":"code","606297f6":"code","e4f2c925":"code","49bae5a7":"code","0438b014":"code","2340077c":"code","a675d906":"code","6f8bdb1a":"code","4015ccc2":"code","67d1e417":"code","803e78ce":"code","a2951d96":"code","506791c7":"code","ad539c8a":"code","738fded8":"code","fc3882af":"code","87772abc":"code","9954fcfe":"code","c457e70b":"code","0f9f3954":"code","d574cf1f":"code","f04515dd":"code","f0c3fc22":"code","bcdee847":"code","09570619":"code","d1023307":"code","f8199ccd":"code","ee4ed75b":"code","634bafeb":"code","64daee52":"code","7bd8c636":"code","cbaa70ce":"code","7aa0570b":"code","5a432c4e":"code","f736ac97":"code","36ff740b":"code","d2d5f943":"code","c193ca14":"code","c67d49e9":"code","04efbd86":"code","83afac84":"code","a298d4fe":"code","2f185b1f":"code","62ec61ba":"code","85566a4d":"code","bda8d921":"code","24dc300d":"code","d46fb033":"code","0417b719":"code","804cd938":"code","19edf3f7":"markdown","3dca077d":"markdown","575b863c":"markdown","2615353c":"markdown","c111b91c":"markdown","7536ec5b":"markdown","4b9c7e1f":"markdown","dd0232d9":"markdown","e4295613":"markdown","0615cdc2":"markdown","45a9ab2c":"markdown","87af5dd6":"markdown","65f6ac08":"markdown","c9d4f85e":"markdown","137b8ba1":"markdown","46475923":"markdown"},"source":{"257cabf4":"\nimport sys \nimport numpy as np \nfrom scipy.stats import randint\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler # for normalization\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn import metrics # for the check the error and accuracy of the model\nfrom sklearn.metrics import mean_squared_error,r2_score\n\n## for Deep-learing:\nimport keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras.optimizers import SGD \nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nimport itertools\nfrom keras.layers import LSTM\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\nfrom keras.layers import Dropout\n","3d470e03":"data = pd.read_csv(\"..\/input\/electric-power-consumption-data-set\/household_power_consumption.txt\")","c13be67f":"data.head()","765a5995":"data = data = pd.read_csv(\"..\/input\/electric-power-consumption-data-set\/household_power_consumption.txt\",sep=';')","d3b4647e":"data.head()","606297f6":"data = data = pd.read_csv(\"..\/input\/electric-power-consumption-data-set\/household_power_consumption.txt\",sep=';',\n                         parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format = True)","e4f2c925":"data.head()","49bae5a7":"data = data = pd.read_csv(\"..\/input\/electric-power-consumption-data-set\/household_power_consumption.txt\",sep=';',\n                         parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format = True,\n                         low_memory=False, na_values=['nan','?'],index_col='dt')","0438b014":"data.head()","2340077c":"data.info()","a675d906":"data.shape","6f8bdb1a":"data.describe()","4015ccc2":"data.columns","67d1e417":"\n\n## finding all columns that have nan:\ndata.isna().sum()\n\n","803e78ce":"\n# filling nan with mean in any columns\n\nfor j in range(0,7):\n    data.iloc[:,j] = data.iloc[:,j].fillna(data.iloc[:,j].mean())","a2951d96":"# check\ndata.isnull().sum()","506791c7":"data.Global_active_power.resample(\"D\").sum().plot(title=\"Global_active_Power resampled over day for sum\",color='orange')\nplt.tight_layout()\nplt.show()","ad539c8a":"data.Global_active_power.resample(\"D\").mean().plot(title=\"Global_active_power resampled over day for mean\",color=\"pink\")\nplt.tight_layout()\nplt.show()","738fded8":"# Below i show mean and std of \"Global_intensity\" resampled over day\nr = data.Global_intensity.resample('D').agg(['mean','std'])\nr.plot(subplots=True, title=\"Global_intensity resampled over day\",color='black')\nplt.show()","fc3882af":"# sum of 'Global_active_power' resampled over month\n\ndata['Global_active_power'].resample('M').mean().plot(kind='bar',color='green')\nplt.xticks(rotation=60)\nplt.ylabel('global_active_power')\nplt.title(\"Global_active_power per month (averaged over month)\")\n","87772abc":"# mean of Global_active_power resampled over quarter\ndata['Global_active_power'].resample('Q').mean().plot(kind='bar',color='red')\nplt.xticks(rotation=60)\nplt.ylabel(\"Global_active_power\")\nplt.title(\"Global_active_power per quarter (averaged over quarter)\")\nplt.show()","9954fcfe":"# mean of 'voltange' resampled over month\ndata['Voltage'].resample('M').mean().plot(kind='bar',color='Salmon')\nplt.xticks(rotation=60)\nplt.ylabel(\"Voltage\")\nplt.title(\"Voltage per quarter (summed over quarter)\")\nplt.show()","c457e70b":"data.Sub_metering_1.resample(\"M\").mean().plot(kind='bar',color='Chartreuse')\nplt.xticks(rotation=60)\nplt.ylabel(\"Sub_metering_1\")\nplt.title(\"Sub_metering_1 per quarter (summed over quarter)\")\nplt.show()","0f9f3954":"# below I compare the mean of different featuresampled over day\n# specify columns to plot\ncols = [0,1,2,3,5,6]\n\ni = 1\ngroups = cols\nvalues = data.resample('D').mean().values\n# plot each column\nplt.figure(figsize=(15,10))\nfor group in groups:\n    plt.subplot(len(cols),1,i)\n    plt.plot(values[:, group])\n    plt.title(data.columns[group], y=0.75, loc='right')\n    i += 1\nplt.show()\n    ","d574cf1f":"# resampling over week and computing mean \ndata.Global_reactive_power.resample('W').mean().plot(color='Maroon',legend=True)\ndata.Global_active_power.resample('W').mean().plot(color='black', legend=True)\ndata.Sub_metering_1.resample('W').mean().plot(color='PaleGreen',legend=True)\ndata.Global_intensity.resample(\"W\").mean().plot(color='DarkGoldenrod',legend=True)\nplt.show()","f04515dd":"# hist plot of the mean of different feature resampled over month\ndata.Global_active_power.resample('M').mean().plot(kind='hist',color='Magenta',legend = True)\ndata.Global_reactive_power.resample(\"M\").mean().plot(kind='hist',color='Gold',legend=True)\ndata.Global_intensity.resample('M').mean().plot(kind='hist',color='Tomato',legend=True)\ndata.Sub_metering_1.resample(\"M\").mean().plot(kind='hist',color='Aquamarine',legend = True)\nplt.show()","f0c3fc22":"# the correlations between 'Global_intensity', 'Global_active_power'\ndata_returns = data.pct_change()\nsns.jointplot(x='Global_intensity', y='Global_active_power',data=data_returns)\nplt.show()","bcdee847":"# the correlation between 'voltage' and 'Global_active_power'\nsns.jointplot(x='Voltage', y='Global_active_power', data = data_returns)\nplt.show()","09570619":"# Correlations among features\nplt.matshow(data.corr(method='spearman'), vmax=1, vmin=-1, cmap='PRGn')\nplt.title(\"without resampling\",size=20)\nplt.colorbar()\nplt.show()","d1023307":"# Correlation of mean of feature resampled over months\n\nplt.matshow(data.resample(\"M\").mean().corr(method='spearman'),vmax=1,vmin=-1,cmap='PRGn')\nplt.title(\"resampled over month\",size=15)\nplt.colorbar()\nplt.margins(0.02)\nplt.matshow(data.resample('A').mean().corr(method='spearman'),vmax=1, vmin=-1,cmap='PRGn')\nplt.title(\"resampled over year\",size=15)\nplt.colorbar()\nplt.show()","f8199ccd":"data.head()","ee4ed75b":"def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    dff = pd.DataFrame(data)\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(dff.shift(i))\n        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    for i in range(0, n_out):\n        cols.append(dff.shift(-i))\n        if i == 0:\n            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg\n","634bafeb":"# resampling of data over hour\ndf_resample = data.resample('h').mean()\ndf_resample.shape","64daee52":"# scale all features in range of [0,1]\n\n# if you would like to train based on the resampled data (over hour), then used below\nvalues = df_resample.values\n\n# data without resampling\n# values = df.values\n# integer encode direction\n# ensure all data is float\n# values - values.astype('float32')\n# normalize features\n\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled = scaler.fit_transform(values)\n# frame as supervised learning\nreframed = series_to_supervised(scaled, 1, 1)","7bd8c636":"reframed.head()","cbaa70ce":"# drop columns we don't want to predict\nreframed.drop(reframed.columns[[8,9,10,11,12,13]], axis=1, inplace=True)\nreframed.head()","7aa0570b":"365*24","5a432c4e":"# split into train and test sets\nvalues = reframed.values\n\nn_train_time = 365*24\ntrain = values[:n_train_time,:]\ntest = values[n_train_time:,:]","f736ac97":"train.shape,test.shape","36ff740b":"train_x, train_y = train[:, :-1], train[:, -1]\ntest_x, test_y = test[:, :-1], test[:, -1]\n","d2d5f943":"# reshape input to be 3D [sample timesteps, features]\ntrain_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n\ntest_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))\n","c193ca14":"train_x.shape, test_x.shape, train_y.shape, test_y.shape","c67d49e9":"model = Sequential()\nmodel.add(LSTM(100, input_shape=(train_x.shape[1], train_x.shape[2])))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')","04efbd86":"history = model.fit(train_x, train_y, epochs=20, batch_size=70, \n                   validation_data = (test_x,test_y), verbose=2, shuffle=False)","83afac84":"# make a prediction \ny_ = model.predict(test_x)\ny_[0],test_y[0]","a298d4fe":"test_x = test_x.reshape((test_x.shape[0],7))\ntest_x.shape","2f185b1f":"inv_y_ = np.concatenate((y_, test_x[:, -6:]), axis=1)\ninv_y_ = scaler.inverse_transform(inv_y_)\ninv_y_ = inv_y_[:,0]","62ec61ba":"inv_y_.shape","85566a4d":"# invert scaling for actual\ntest_y = test_y.reshape((len(test_y), 1))\ninv_y = np.concatenate((test_y, test_x[:, -6:]), axis=1)\ninv_y = scaler.inverse_transform(inv_y)\ninv_y = inv_y[:,0]\n","bda8d921":"inv_y.shape","24dc300d":"inv_y[0], inv_y_[0]","d46fb033":"# calculate RMSE\nrmse = np.sqrt(mean_squared_error(inv_y, inv_y_))\nprint (rmse)","0417b719":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','test'], loc='upper right')\nplt.show()","804cd938":"# time steps, every step is one hour (you can easily convert the time step to the actual time index)\n# for a demonstration purpose, only compare the predictions i n 200 hours\n\na = [x for x in range(200)]\nplt.plot(a, inv_y[:200], marker='.', label='Actual')\nplt.plot(a, inv_y_[:200], 'y', label='Prediction')\nplt.ylabel('Global_active_power',size=15)\nplt.xlabel('Time step',size=15)\nplt.legend(fontsize=15)\nplt.show()","19edf3f7":"https:\/\/www.kaggle.com\/amirrezaeian\/time-series-data-analysis-using-lstm-tutorial","3dca077d":"supervised learning probleam as predicting the global_active_power at the current time (t) given the Global_active measurement and other fratures at the prior time step","575b863c":"### Above I showed 7 input variables (input series) and the 1 output variable for 'Global_active_power' at the current time in hour (depending on resampling).\n","2615353c":"### Context: Measurements of electric power consumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quantities and some sub-metering values are available.\n\n* Data Set Characteristics: Multivariate, Time-Series\n\n","c111b91c":"### Splitting the rest of data to train and validation sets\n","7536ec5b":"First, split the prepared dataset into train and test sets. To speed up the training of the model (for the sake of the demonstration), we will only train the model on the first year of data, then evaluate it on the next 3 years of data.","4b9c7e1f":"### Learn Time-Series analysis\n","dd0232d9":"# Data Visualization","e4295613":"### shift in py\n![image.png](attachment:e52f9c70-637e-4da7-8e1e-7f4bb7190792.png)","0615cdc2":"The resample() function is used to resample time-series data. Convenience method for frequency conversion and resampling of time series. Object must have a datetime-like index (DatetimeIndex, PeriodIndex, or TimedeltaIndex), or pass datetime-like values to the on or level keyword.\n","45a9ab2c":"Attribute Information: 1.date: Date in format dd\/mm\/yyyy\n\n2.time: time in format hh:mm:ss\n\n3.global_active_power: household global minute-averaged active power (in kilowatt)\n\n4.global_reactive_power: household global minute-averaged reactive power (in kilowatt)\n\n5.voltage: minute-averaged voltage (in volt)\n\n6.global_intensity: household global minute-averaged current intensity (in ampere)\n\n7.sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered).\n\n8.sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.\n\n9.sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner.\n\n","87af5dd6":"pct_change() function calculates the percentage change between the current and a prior element. This function by default calculates the percentage change from the immediately previous row. Note : This function is mostly useful in the time-series data. ... periods : Periods to shift for forming percent change.\n","65f6ac08":"xticks(rotation=45) rotate x-axis labels by 45 degrees.\nyticks(rotation=90) rotate y-axis labels by 90 degrees.\n","c9d4f85e":"### LSTM Data Preparation & Feature Engineering","137b8ba1":"Model architecture\n* LSTM with 100 neurons in the first visible layer\n* dropout 20%\n* 1 neuron in the output layer for predicting Global_active_power.\n* The input shape will be 1 time step with 7 features.\n* I use the Mean Absolute Error (MAE) loss function and the efficient Adam version of stochastic gradient descent.\n* The model will be fit for 20 training epochs with a batch size of 70.\u00b6\n","46475923":"![image.png](attachment:aad4ffe0-bb01-4bd0-bcfb-5d4b99341af5.png)"}}