{"cell_type":{"1dfee389":"code","8615822f":"code","cd508d44":"code","a268e0df":"code","8f2389a7":"code","a6b6f55c":"code","3755bbfe":"code","6d6266cb":"code","94712207":"code","2ddb2ecc":"code","90329d6d":"code","fcd75f5f":"code","53113071":"code","c3b04356":"code","f0379f95":"code","05e921ef":"code","f3d40a50":"code","a0689ed5":"code","a45d6240":"code","1dc423e1":"code","f232ca74":"code","3e01bce6":"code","93d442f2":"code","092de6ab":"code","abb0d3c5":"code","8e1e70b9":"code","9afbe21d":"code","bba57853":"code","383fd369":"code","0e4810d1":"markdown","33192788":"markdown","64690c3e":"markdown","1d32714e":"markdown","2aec321d":"markdown","5e5863b3":"markdown","77e00d13":"markdown","54fa9879":"markdown","ca279d02":"markdown","b0501c72":"markdown","de80c5c3":"markdown","019adaed":"markdown","62e2b90a":"markdown","adff594c":"markdown","6ddf902e":"markdown","8b68f269":"markdown","6971eb8e":"markdown","4bbbe5df":"markdown"},"source":{"1dfee389":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport time\nimport datetime\nimport pytz\nfrom itertools import combinations\nfrom scipy.sparse import hstack, csr_matrix\nimport os\n\n# Sklearn stuff\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer","8615822f":"PATH_TO_DATA = '..\/input\/'\nSEED = 17","cd508d44":"# Train dataset\ndf_train_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_features.csv'), \n                                    index_col='match_id_hash')\ndf_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_targets.csv'), \n                                   index_col='match_id_hash')\n\ny_train = df_train_targets['radiant_win'].map({True: 1, False: 0})\n\n# Test dataset\ndf_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), \n                                   index_col='match_id_hash')","a268e0df":"df_train_features.head()","8f2389a7":"df_full_features = pd.concat([df_train_features, df_test_features])\n\n# Index to split the training and test data sets\nidx_split = df_train_features.shape[0]\n\nheroes_df = df_full_features[[f'{t}{i}_hero_id' for t in ['r', 'd'] for i in range(1, 6)]]","a6b6f55c":"heroes_df.head()","3755bbfe":"heroes_df.shape","6d6266cb":"sns.countplot(x=y_train, palette=\"Set3\");","94712207":"def logit_cv(X_heroes_train, y_train, cv=5, random_state=SEED):\n    logit = LogisticRegression(random_state=SEED, solver='liblinear')\n\n    c_values = np.logspace(-2, 1, 20)\n\n    logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n                                       scoring='roc_auc',return_train_score=False, cv=cv,\n                                       n_jobs=-1, verbose=0)\n\n    logit_grid_searcher.fit(X_heroes_train, y_train)\n    \n    cv_scores = []\n    for i in range(logit_grid_searcher.n_splits_):\n        cv_scores.append(logit_grid_searcher.cv_results_[f'split{i}_test_score'][logit_grid_searcher.best_index_])\n    print(f'CV scores: {cv_scores}')\n    print(f'Mean: {np.mean(cv_scores)}, std: {np.std(cv_scores)}\\n')\n    \n    return logit_grid_searcher.best_estimator_, np.array(cv_scores) ","2ddb2ecc":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)","90329d6d":"heroes_df_ohe = heroes_df.copy()\nfor t in ['r', 'd']:\n    for i in range(1, 6):\n        heroes_df_ohe = pd.get_dummies(heroes_df_ohe, columns = [f'{t}{i}_hero_id'])\n        \nheroes_df_ohe.head()\n\nX_heroes_train = heroes_df_ohe[:idx_split]\nX_heroes_test  = heroes_df_ohe[idx_split:]","fcd75f5f":"print(f'Number of features: {heroes_df_ohe.shape[1]}')","53113071":"%%time\n\nlogit_0, cv_scores_0 = logit_cv(X_heroes_train, y_train, cv=skf, random_state=SEED)","c3b04356":"def bag_of_heroes(df, N=1, r_val=1, d_val=-1, r_d_val=0, return_as='csr'):\n    '''\n    Bag of Heroes. Returns a csr matrix (+ list of feature names) or dataframe where each column represents\n    a hero (ID) and each row represents a match.\n    \n    The value of a cell (i, j) in the returned matrix is:\n        cell[i, j] = 0, if the hero or combination of heroes of the j-th column is not present in the i-th match\n        cell[i, j] = r_val, if the hero (N = 1) or combination of heroes (N > 1, synergy) of the j-th column is within the Radiant team,\n        cell[i, j] = d_val, if the hero (N = 1) or combination of heroes (N > 1, synergy) of the j-th column is within the Dire team,\n        cell[i, j] = r_d_val, if the combination of heroes of the j-th column is between the Radiant and Dire teams (N>1, anti-synergy).\n    \n    Parameters:\n    -----------\n        df: dataframe with hero IDs, with columns ['r1_hero_id', ..., 'r5_hero_id', 'd1_hero_id', ..., 'd5_hero_id']\n        N: integer 1 <= N <= 10, for N heroes combinations\n        return_as: 'csr' for scipy csr sparse matrix, 'df' for pandas dataframe\n    '''\n    if N < 1 or N > df.shape[1]:\n        raise Exception(f'The number N of hero-combinations should be 1 <= N <= {df.shape[1]}')\n        \n    # Convert the integer IDs to strings of the form id{x}{x}{x}\n    df = df.astype(str).applymap(lambda x: 'id' + '0'*(3 - len(x)) + x)\n    \n    # Create a list of all hero IDs present in df\n    hero_ids = np.unique(df).tolist()\n\n    # Break df into teams Radiant (r) and Dire (d)\n    df_r = df[[col for col in df.columns if col[0] == 'r']]\n    df_d = df[[col for col in df.columns if col[0] == 'd']]\n    \n    # Create a list of all the hero IDs in df, df_r and df_d respectively\n    f = lambda x: ' '.join(['_'.join(c) for c in combinations(sorted(x), N)])\n    \n    df_list = df.apply(f, axis=1).tolist()\n    df_list.append(' '.join(['_'.join(c) for c in combinations(hero_ids, N)]))\n\n    df_r_list = df_r.apply(f, axis=1).tolist()\n    df_r_list.append(' '.join(['_'.join(c) for c in combinations(hero_ids, N)]))\n    \n    df_d_list = df_d.apply(f, axis=1).tolist()\n    df_d_list.append(' '.join(['_'.join(c) for c in combinations(hero_ids, N)]))\n    \n    # Create countvectorizers\n    vectorizer = CountVectorizer()\n    vectorizer_r = CountVectorizer()\n    vectorizer_d = CountVectorizer()\n    \n    X = vectorizer.fit_transform(df_list)[:-1]\n    X_r = vectorizer_r.fit_transform(df_r_list)[:-1]\n    X_d = vectorizer_d.fit_transform(df_d_list)[:-1]\n    X_r_d = (X - (X_r + X_d))  \n    X = (r_val * X_r + d_val * X_d + r_d_val * X_r_d)\n    \n    feature_names = vectorizer.get_feature_names()\n    \n    if return_as == 'csr':\n        return X, feature_names\n    elif return_as == 'df':\n        return pd.DataFrame(X.toarray(), columns=feature_names, index=df.index).to_sparse(0) ","f0379f95":"df = pd.DataFrame({'r1_hero_id': [1, 5, 2], 'r2_hero_id': [3, 4, 1],\n                   'd1_hero_id': [5, 3, 3], 'd2_hero_id': [4, 2, 5]},\n                 index=['match_1', 'match_2', 'match_3'])\n\ndf","05e921ef":"# bag_of_heroes(df, N=1, r_val=1, d_val=-1, return_as='csr')[0]\nbag_of_heroes(df, N=1, r_val=1, d_val=-1, return_as='df')","f3d40a50":"pd.concat([bag_of_heroes(df, N=1, r_val=1, d_val=-1, return_as='df'),\n           bag_of_heroes(df, N=2, r_val=1, d_val=-1, r_d_val=2, return_as='df')], axis=1)","a0689ed5":"boh = bag_of_heroes(heroes_df, N=1, r_val=1, d_val=-1, return_as='csr')[0]\n\nX_heroes_train = boh[:idx_split]\nX_heroes_test  = boh[idx_split:]","a45d6240":"print(f'Number of features: {boh.shape[1]}') ","1dc423e1":"%%time\n\nlogit_1, cv_scores_1 = logit_cv(X_heroes_train, y_train, cv=skf, random_state=SEED)","f232ca74":"cv_scores_1 > cv_scores_0","3e01bce6":"boh = hstack([bag_of_heroes(heroes_df, N=1, r_val=1, d_val=-1, r_d_val=0, return_as='csr')[0],\n              bag_of_heroes(heroes_df, N=2, r_val=0.2, d_val=-0.2, r_d_val=0, return_as='csr')[0]], format='csr')\n\nX_heroes_train = boh[:idx_split]\nX_heroes_test  = boh[idx_split:]","93d442f2":"print(f'Number of features: {boh.shape[1]}')","092de6ab":"%%time\n\nlogit_2, cv_scores_2 = logit_cv(X_heroes_train, y_train, cv=skf, random_state=SEED)","abb0d3c5":"cv_scores_2 > cv_scores_1","8e1e70b9":"boh = hstack([bag_of_heroes(heroes_df, N=1, r_val=1, d_val=-1, r_d_val=0, return_as='csr')[0],\n              bag_of_heroes(heroes_df, N=2, r_val=0.2, d_val=-0.2, r_d_val=0.1, return_as='csr')[0]], format='csr')\n\nX_heroes_train = boh[:idx_split]\nX_heroes_test  = boh[idx_split:]","9afbe21d":"print(f'Number of features: {boh.shape[1]}') ","bba57853":"%%time\n\nlogit_3, cv_scores_3 = logit_cv(X_heroes_train, y_train, cv=skf, random_state=SEED)","383fd369":"cv_scores_3 > cv_scores_2","0e4810d1":"With this naive one-hot-encoding we already get a score above the dummy baseline score of 0.5.\nLet's see if we can improve it with the bag-of-heroes representation.","33192788":"There are possibly better ways to deal with the hero IDs. Maybe a more clever bag-of-heroes encoding scheme or a different representation such as mapping hero IDs to hero win rates. Any suggestions are welcome!","64690c3e":"Let's consider a toy example of three 2v2 matches and 5 heroes to demonstrate the concept","1d32714e":"Let's compute the logit cv scores","2aec321d":"# Bag of heroes\nLet's write a function which will allow us to easily create different bag-of-heroes representations. It's a little bit hacky, but it works well (however I don't recomend using it for `N > 3` if you don't have enough memory). ","5e5863b3":"# Conclusion\nUsing bag-of-heroes for hero IDs with Logistic regression gives ROC AUC score around 0.6 which is quite good compared to score obtained from raw IDs or one-hot encoded IDs for each player. Unfortunately considering synergy and anti-synergy of heroes didn't help improving the score on the LB (although the CV scores slightly improved). My guess is that the dataset is too small for the synergy and anti-synergy of heroes to be seen by the model as a signal. Here are the results:","77e00d13":"I also will use stratified cross-validation with 5 folds","54fa9879":"Combine train and test datasets and create heroes dataframe","ca279d02":"# Logistic Regression\nIn the following I will use Logistic Regression for different bag-of-heroes representations and compare the CV scores. Let's create a helper function","b0501c72":"## Individual heroes\nNow let's use our real data and start with `N=1`, i.e. bag of individual heroes","de80c5c3":"## Synergy\nLet's take into account the hero pairings within each team (two-hero synergy). Assuming that the abilities of individual heroes are more important than the heroes synergy, smaller values `r_val`, `d_val` for `N=2` than for `N=1` are used. But these value choices are quite arbitrary and can be tuned.","019adaed":"## Anti-synergy","62e2b90a":"<img src='https:\/\/steamuserimages-a.akamaihd.net\/ugc\/1047377062453152758\/48CD2809864A478C11592F098A59F8B76C2A2D14\/'>\n\n# <center> Dota 2: Bag of Heroes\n\nIn this Kernel I show how to create a simple \"bag of heroes\", i.e. a sparse matrix (or dataframe) where each column represents a hero (his ID). The value of a cell (i, j) is zero\/non-zero if the hero at j-th column wasn't\/was present in the i-th match. For the non-zero values representing hero presense, I use `1` for the Radiant team hero and `-1` for the Dire team hero (distinguishing between teams helps!).\n\nNote that hero duplicates are not allowed in a match, so in a 5v5 match there are 10 unique heroes out of 115 existing heroes (keep in mind that hero IDs are `1, ... 23, 25, ..., 114, 119, 120`).\n\nSynergy and anti-synergy of heroes can be also considered, i.e. combinations of heroes within each team and between teams respectively. However I found that considering hero combinations doesn't help to improve the LB score -- perhaps because our dataset is too small. Also, as a side effect, it greatly increases the dimensionality of the feature space (e.g. there are $\\frac{115!}{3! \\cdot 112!} = 246905$ combinations of 3 heroes in the set of 115 heroes...).\n\nI use Logistic Regression to make predictions based (merely) on the bag-of-heroes and compare some of the encoding approaches. The best score on LB that I got with the bag-of-heroes is slightly above 0.6 which is better than the score of 0.5 obtained without encoding the hero IDs at all or with one-hot encoding them for each player.","adff594c":"We can also include pairs of heroes. For the sake of clarity the value `2` is used for the bpairs of heroes from opposing teams","6ddf902e":"# Load data","8b68f269":"# One-hot encoding each player\nLet's first try to one-hot encode heroes of each player (this is the approach I also used for Neural Network classifier, see the [Kernel](https:\/\/www.kaggle.com\/kuzand\/dota-2-winner-prediction-multilayer-nn-pytorch)). ","6971eb8e":"| |  CV_mean  | CV_std | LB |\n| :--- | :--- | :--- | \n|**1**\t|0.611003\t|0.003721\t|0.60127|\n|**2**\t|0.611519\t|0.004123\t|0.60062|\n|**3**\t|0.611673\t|0.004046\t|0.60020|","4bbbe5df":"Note that our train dataset is more or less balanced, so assuming that the test dataset has the same class distribution, we expect the baseline score to be close to 0.5."}}