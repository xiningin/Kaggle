{"cell_type":{"0c93c98c":"code","0d0f0831":"code","7f0d110d":"code","c6c9f678":"code","8f786b59":"code","c07fc58c":"code","fab5ecac":"code","2fbce891":"code","d2a1b5e0":"code","bc031047":"code","223dcfed":"code","d13845b0":"code","f8fb33f8":"code","022067b3":"code","7d3f77cf":"code","59fb5e9c":"code","44425c12":"code","c7223812":"code","dc73dd48":"code","53a3b37d":"code","c222bcfd":"code","cde3c6e3":"code","8c74f2dc":"code","01cc1c3b":"code","e15b8333":"code","a8a94837":"code","8042a0fb":"code","5ab13c5d":"code","f9f6f4d4":"code","8a19b023":"code","28b9227e":"code","de160732":"code","76260ea6":"code","82cc7f0e":"code","39178e41":"code","4e984249":"code","5d6683ed":"code","fe0e153f":"code","aa2c660f":"code","54869366":"code","d59c8a30":"code","89e1f5bd":"code","1f28d170":"code","f50fc694":"code","58fbd760":"code","c8000f0e":"code","40ae36fa":"code","72502c24":"code","80f581ce":"code","93306a04":"code","068d9505":"code","65dc366e":"code","8368c3a3":"code","c0331b35":"code","acfde202":"code","bc7fe7f8":"code","ea9faa0a":"code","2c7af542":"code","5c02304c":"code","145a5377":"code","64becc35":"code","653d9880":"code","e4c52932":"code","e59db647":"code","473054c9":"code","0c4747c4":"code","628a5b0f":"code","ead61aa9":"code","ca173ba8":"code","9e3305eb":"code","8ebbe482":"code","2c5d85a1":"code","826dfc00":"markdown","75ad77f3":"markdown","90b347eb":"markdown","3fe5492d":"markdown","70605407":"markdown","c588732a":"markdown","cf252ae5":"markdown","3611af23":"markdown","09011485":"markdown","7a3a1aae":"markdown","af6bfdee":"markdown","ae0489c1":"markdown","ba665bec":"markdown","2ac1afc9":"markdown","48103bb3":"markdown","d4421628":"markdown","b127c5d5":"markdown","fa9182b4":"markdown","0f1caad1":"markdown","e99b2069":"markdown","4acb0a2d":"markdown","0903a14d":"markdown","66203f71":"markdown","553924cd":"markdown","c8155c0f":"markdown","07351796":"markdown","55993ea7":"markdown","906b7d3f":"markdown","1b1c01e0":"markdown","1d416805":"markdown","a4d0150e":"markdown","10596328":"markdown","38baed58":"markdown","710cef79":"markdown","8da87efb":"markdown","be730e46":"markdown","937d6848":"markdown","8c1f4258":"markdown","4ce64299":"markdown","69360600":"markdown","b95f1866":"markdown","21cadf3f":"markdown","19f1204e":"markdown","52916d01":"markdown","51c4856c":"markdown","d76d2906":"markdown","c92af578":"markdown","d4d3e49b":"markdown","237b851f":"markdown","73094a74":"markdown","daefaba8":"markdown"},"source":{"0c93c98c":"#Importing the nescessary libraries:\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,BaggingClassifier,ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import power_transform\nimport scikitplot as skplt\nfrom yellowbrick.classifier.rocauc import roc_auc","0d0f0831":"data=pd.read_csv(\"\/kaggle\/input\/abalone-dataset\/abalone.csv\")\ndata","7f0d110d":"#checking the first 5 rows of the dataset\n\ndata.head()","c6c9f678":"#checking the last 5 rows of the dataset\n\ndata.tail()","8f786b59":"#checking the dimension of dataset\n\ndata.shape","c07fc58c":"# checking the column names\n\ndata.columns","fab5ecac":"# checking datatypes\n\ndata.info()","2fbce891":"#checking for null values\n\ndata.isnull().sum()","d2a1b5e0":"data.describe()","bc031047":"data.Rings.unique()","223dcfed":"data['Rings'].value_counts()","d13845b0":"# UNIVARIATE ANALYSIS\n# Visualizing null values with the help of heatmap\n\nsns.heatmap(data.isnull())\nplt.show()","f8fb33f8":"#UNIVARIATE ANALYSIS\n# checking sex count with countplot\n\nplt.figure(figsize=(10,7))\nsns.countplot(x='Sex',data=data)\nplt.title(\"Sex Count\",fontsize=20)","022067b3":"#Bivariate Analysis\n\nplt.figure(figsize=(10,7))\nsns.distplot(data.Rings)","7d3f77cf":"plt.figure(figsize=(20,15))\nplt.subplot(3,3,1)\nsns.distplot(data.Length,color='red')\nplt.subplot(3,3,2)\nsns.distplot(data.Diameter,color='y')\nplt.subplot(3,3,3)\nsns.distplot(data.Height,color='g')\nplt.subplot(3,3,4)\nsns.boxplot(data.Length,color='red')\nplt.subplot(3,3,5)\nsns.boxplot(data.Diameter,color='y')\nplt.subplot(3,3,6)\nsns.boxplot(data.Height,color='g')","59fb5e9c":"plt.figure(figsize=(20,25))\nplt.subplot(4,4,1)\nplt.title(\"Distribution Of Whole weight\")\nsns.distplot(data['Whole weight'],color='red')\nplt.subplot(4,4,2)\nplt.title(\"Distribution of Shucked Weight\")\nsns.distplot(data['Shucked weight'],color='y')\nplt.subplot(4,4,3)\nplt.title(\"Distribution of Viscera weight\")\nsns.distplot(data['Viscera weight'],color='b')\nplt.subplot(4,4,4)\nplt.title(\"Distribution of Shell weight\")\nsns.distplot(data['Shell weight'],color='g')\nplt.subplot(4,4,5)\nplt.title(\"Distribution of Whole weight\")\nsns.boxplot(data['Whole weight'],color='red')\nplt.subplot(4,4,6)\nplt.title(\"Distribution of Shucked weight\")\nsns.boxplot(data['Shucked weight'],color='y')\nplt.subplot(4,4,7)\nplt.title(\"Distribution of Viscera weight\")\nsns.boxplot(data['Viscera weight'],color='b')\nplt.subplot(4,4,8)\nplt.title(\"Distribution of Shell weight\")\nsns.boxplot(data['Shell weight'],color='g')","44425c12":"data.columns","c7223812":"col=['Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weight']\ndf=data[col]","dc73dd48":"#Bivariate analysis\n\nplt.figure(figsize=(12,25))\nfor i in range(0,len(col)):\n  plt.subplot(5,2,i+1)\n  sns.scatterplot(x=data.Rings,y=data[col[i]],hue=data.Sex)\n  plt.tight_layout()","53a3b37d":"data.columns","c222bcfd":"sns.lmplot(x='Rings',y='Length',data=data,hue='Sex')\nsns.lmplot(x='Rings',y='Diameter',data=data,hue='Sex')\nsns.lmplot(x='Rings',y='Height',data=data,hue='Sex')\nsns.lmplot(x='Rings',y='Whole weight',data=data,hue='Sex')\nsns.lmplot(x='Rings',y='Shucked weight',data=data,hue='Sex')\nsns.lmplot(x='Rings',y='Viscera weight',data=data,hue='Sex')\nsns.lmplot(x='Rings',y='Shell weight',data=data,hue='Sex')","cde3c6e3":"sns.pairplot(data)","8c74f2dc":"plt.rcParams['figure.figsize'] = (15,15)\ndata.hist(bins=30, color='maroon', density=True, label='Value', histtype='stepfilled', grid=False)\nplt.tight_layout()\nplt.show()","01cc1c3b":"#Exploring data variable\n\ndata['Sex'].value_counts()","e15b8333":"def labels(x):\n  if x<=10:\n    return 'young'\n  if x<=20:\n    return 'middle_age'\n  if x<=30:\n    return 'old'\ndata['Rings']=data['Rings'].apply(labels)","a8a94837":"# Encoding Categorical features into ordinal numerical value\n\noe=OrdinalEncoder()\ndef ordinal_encoder(df,column):\n  df[column]=oe.fit_transform(df[column])\n  return df","8042a0fb":"ordinal_column=['Sex','Rings']\ndata=ordinal_encoder(data,ordinal_column)","5ab13c5d":"# pre-processing the data\n\ndef preprocessing(df):\n  df=df.copy()\n  df=ordinal_encoder(df,['Sex'])\n  return df","f9f6f4d4":"df=preprocessing(data)","8a19b023":"df['Rings'].value_counts()","28b9227e":"df['Sex'].value_counts()","de160732":"df['Sex'].value_counts()","76260ea6":"X=df.drop(\"Rings\",axis=1)\ny=df['Rings']","82cc7f0e":"X['Sex'].value_counts()","39178e41":"X.dtypes","4e984249":"plt.figure(figsize=(18,7))\nsns.boxplot(x='variable',y='value',data=pd.melt(X))","5d6683ed":"#Removing the outliers\n\nfor col in X.columns:\n  percentile=X[col].quantile([0.01,0.98]).values\n  X[col][X[col] <=percentile[0]] = percentile[0]\n  X[col][X[col] >=percentile[1]] = percentile[1]","fe0e153f":"plt.figure(figsize=(18,7))\nsns.boxplot(x='variable',y='value',data=pd.melt(X))","aa2c660f":"X_corr=X.corr()\nX_corr","54869366":"#MULTIVARIATE ANALYSIS\n# Visualizing Correlation heatmap\n\n\nplt.figure(figsize=(15,8))\nX_corr=X.corr()\nsns.heatmap(X_corr,annot=True,linewidths=0.5,linecolor=\"red\", fmt= '.2f')","d59c8a30":"X.skew()","89e1f5bd":"X","1f28d170":"scaler=MinMaxScaler()\nX=scaler.fit_transform(X)","f50fc694":"x=data.drop(\"Rings\",axis=1)","58fbd760":"X=pd.DataFrame(X,columns=x.columns)\nX","c8000f0e":"X.skew()","40ae36fa":"smote=SMOTE(random_state=42)\nX_res,y_res=smote.fit_resample(X,y)\nX_new=pd.DataFrame(X_res,columns=X.columns)\ny_new=pd.DataFrame(y_res,columns=['Rings'])","72502c24":"plt.figure(figsize=(15,15))\nplt.subplot(2,2,1)\nplt.title(\"Imbalanced Data\")\nsns.countplot(data['Rings'])\nplt.subplot(2,2,2)\nplt.title(\"Balanced Data\")\nsns.countplot(y_new['Rings'])","80f581ce":"#Handling skewness of data\n\nX_new=power_transform(X_new,method='yeo-johnson')\nX_new=pd.DataFrame(X_new,columns=x.columns)","93306a04":"X_new.skew()","068d9505":"y_new","65dc366e":"X_train,X_test,y_train,y_test=train_test_split(X_new,y_new,test_size=0.3,random_state=42)","8368c3a3":"models={\n    \"ExtraTreesClassifier\":ExtraTreesClassifier(),\n    \"RandomForestClassifier\":RandomForestClassifier(),\n    \"XGBClassifier\":XGBClassifier(),\n    \"LGBMClassifier\":LGBMClassifier(),\n    \"BaggingClassifier\":BaggingClassifier(),\n    \"LogisticRegression\":LogisticRegression()\n}","c0331b35":"X_new.shape,y_new.shape","acfde202":"Model=[]\nScore=[]\nCVS=[]\ntrain=[]\nfor name,model in models.items():\n  print('***************************',name,'******************************')\n  print('\\n')\n  Model.append(name)\n  model.fit(X_train,y_train)\n  print(model)\n  print(\"\\n\")\n  train_hat=model.predict(X_train)\n  accs=accuracy_score(y_train,train_hat)\n  train.append(accs)\n  y_pred=model.predict(X_test)\n  As_test=accuracy_score(y_test,y_pred)\n  Score.append(As_test*100)\n  cv=cross_val_score(model,X_new,y_new,cv=5,scoring='accuracy').mean()\n  print(\"Cross_Val_Score==\",cv)\n  CVS.append(cv*100)\n  print(\"\\n\")\n  print(\"Test Score of is==\",As_test)\n  print(\"\\n\")\n  cm=confusion_matrix(y_test,y_pred)\n  print(\"Confusion Matrix:\\n\")\n  print(cm)\n  print(\"\\n\")\n  report=classification_report(y_test,y_pred)\n  print(\"Classification Report:\\n\")\n  print(report)\n  print(\"\\n\")\n  print(\"ROC_AUC CURVE\")\n  roc_auc(model,X_train,y_train,X_test=X_test,y_test=y_test,classes=['YOUNG','MIDDLE AGE','OLD'],micro=False,macro=False)\n  print(\"\\n\")\n  skplt.estimators.plot_learning_curve(model,X_new,y_new,\n                                       cv=5,shuffle=True,scoring='accuracy',\n                                       n_jobs=-1,figsize=(12,7),title_fontsize=\"large\",text_fontsize=\"large\",\n                                       title=name)","bc7fe7f8":"models_score=pd.DataFrame({\n    \"Model\":Model,\n    \"Accuracy_Score\":Score,\n    \"Cross_Val_Score\":CVS\n})","ea9faa0a":"models_score","2c7af542":"Etree=ExtraTreesClassifier()\nEtree.fit(X_train,y_train)","5c02304c":"y_pred=Etree.predict(X_test)","145a5377":"acc_score=accuracy_score(y_test,y_pred)\nacc_score","64becc35":"Tree={\n  \"criterion\":['gini','entropy'],\n  \"min_samples_leaf\":[1,2,3],\n  \"min_samples_split\":[1,2,3,4],\n  \"max_depth\":[1,2,3,4,5,None],\n  \"min_weight_fraction_leaf\":[0.0,0.1,0.2,0.3]\n}","653d9880":"RandomForest={\n    \"bootstrap\":[True,False],\n    \"criterion\":['gini','entropy'],\n    \"min_samples_leaf\":[1,2,3],\n    \"min_samples_split\":[1,2,3,4],\n}","e4c52932":"tree=ExtraTreesClassifier()\nrf=RandomForestClassifier()","e59db647":"Grid=GridSearchCV(estimator=tree,param_grid=Tree,cv=5,n_jobs=-1)","473054c9":"Grid.fit(X_train,y_train)","0c4747c4":"Grid.best_params_","628a5b0f":"Grid.best_score_","ead61aa9":"Grid_RandomForest=GridSearchCV(estimator=rf,param_grid=RandomForest,cv=5,n_jobs=-1)\nGrid_RandomForest.fit(X_train,y_train)","ca173ba8":"Grid_RandomForest.best_score_","9e3305eb":"import joblib\njoblib.dump(Etree,\"Abalone_Model.obj\")","8ebbe482":"model=joblib.load('Abalone_Model.obj')","2c5d85a1":"y_preds=model.predict(X_test)\npredicted=pd.DataFrame(y_pred,columns=['predicted'])\npredicted","826dfc00":"Remarks: The total number of rows present in our dataset is 4177 and there are 9 columns including the target label.","75ad77f3":"Observations: As object datatype cannot be viewed in the describe metod, we see 'sex' column being omitted automatically. \nBy looking at the other columns we can ignore the 'rings' column as that will be our label and does not need to be pre-processed. \nThe other columns show slight deviations between the quantile ranges and the min-max values. However We do not see any drastic gap except for the 'height' and 'shell weight' columns. We will check for skewness and outliers and treat them if required.","90b347eb":"Remarks: As we can see ExtraTreesClassifier And RandomForestClassifier is giving us high accuracy value.","3fe5492d":"Remarks: After labeling rings into young,middle age and old it will not effect our result and we can still predict it, if it comes in young we can say its age is less then 10 and if comes to middle age, we can say its age is less than 20 or greater than 10.","70605407":"# Summary Statistics of the Dataset:","c588732a":"# Conclusion:","cf252ae5":"Remarks: We are using the Grid Search CV method for hyper parameter tuning the best model.","3611af23":"Remarks: As we can see from the above analyis, We have imbalanced data so we have to balance it,and in order to do so, We are going to use smote for over-sampling because it over sample the data.","09011485":"# Pairplot","7a3a1aae":"Remarks: As we can see here, we removed lot of outliers without losing any data.","af6bfdee":"Remarks: Here the Grid Search CV has provided us with the best parameters list out of all the combinations it used to train the model","ae0489c1":"# Problem Statement:\n\nThe age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. Further information, such as weather patterns and location (hence food availability) may be required to solve the problem. We have to predict the rings of each abalone which will lead us to the age of that abalone.\n ","ba665bec":"# Checking Correlation\n\nPositive correlation - A correlation of +1 indicates a perfect positive correlation, meaning that both variables move in the same direction together.\n\nNegative correlation - A correlation of \u20131 indicates a perfect negative correlation, meaning that as one variable goes up, the other goes down.\n","2ac1afc9":"# Preparing Data for Analysis:","48103bb3":"Remarks: With the help of info method, we are able to see the column datatype bifurcation. There are 7 float datatype columns, 1 integer datatype column and 1 object datatype column.\n\nSince the object datatype is going to be one of the feature we will need to convert it later to numeric format using encoding techniques","d4421628":"# After Removing Outliers:","b127c5d5":"Remarks:\n\nTarget variable is discrete and categorical in nature.\n\nNumber of Rings ranges from 1 to 27.","fa9182b4":"Remarks: We have lots of columns that are correralted with each other. In real life, if two features are highly correlated to each other we can drop one of them but in this case we have less columns so we will not do anything","0f1caad1":"# Checking Outliers","e99b2069":"# Loading the Data:","4acb0a2d":"# Spliting train test data with best random_state","0903a14d":"Remarks: In the above dataset I see that there is only one object datatype column and rest are all numeric columns. Since we need to find or rather predict the number of rings it becomes our target label. Rest all other columns are then automatically our feature columns that we will be making use of in predicting the label values.","66203f71":"# Scatterplot:","553924cd":"Remarks: we can see most of the time male is having height value with all the features as respect to rings","c8155c0f":"Remarks: We have converted target column into bins because most of the values was having less then 10 count so it will be hard for model to predict those value.","07351796":"# Hyper parameter tuning","55993ea7":"Remarks: We see that there are no null values present in any column of the dataset, so we don't need to worry about missing data.","906b7d3f":"# Sampling the data","1b1c01e0":"# Exploring Data Variable","1d416805":"# Histogram:","a4d0150e":"Remarks: The pairplot gives us a visualization on scatter plot + histogram showing us the outliers as well as the skewness data","10596328":"Observations:\n\nRings has most values concentrated in the categories of 9,10,8 and 11.","38baed58":"Remarks: In the above distribution plots and boxplots, we see that there are skewness(right skewed) due to the outliers but still many of they are able to retain or rather showcase a bell shape curve indicating a normal distribution. So we can assume that not all outliers are to be removed and some might actually be genuine data therefore the outliers will need to be treated accordingly.","710cef79":"# Feature Scaling:","8da87efb":"Remarks: From above observation we can say Height dont have a good relationship with rings and another observation shows that sex male have the high values as compared to other like F,I on Rings.","be730e46":"# Finding Best Model","937d6848":"# Understanding the Dataset:\n    \nThere are 9 columns in the dataset.\n\nName \/ Data Type \/ Measurement Unit \/ Description:\n\n1.Sex \/ nominal \/ -- \/ M, F, and I (infant)\n\n2.Length \/ continuous \/ mm \/ Longest shell measurement\n\n3.Diameter \/ continuous \/ mm \/ perpendicular to length\n\n4.Height \/ continuous \/ mm \/ with meat in shell\n\n5.Whole weight \/ continuous \/ grams \/ whole abalone\n\n6.Shucked weight \/ continuous \/ grams \/ weight of meat\n\n7.Viscera weight \/ continuous \/ grams \/ gut weight (after bleeding)\n\n8.Shell weight \/ continuous \/ grams \/ after being dried\n\n9.Rings \/ integer \/ -- \/ +1.5 gives the age in years","8c1f4258":"Remarks: From upper observation we can say Length , Diameter both are left skewed and Height is Power law distributed.","4ce64299":"Remarks: It shows that number of rings is not normally distributed. It is right skewed.","69360600":"# Exploratory Data Analysis (EDA)","b95f1866":"Remarks:  we have trained the Grid Search CV with the list of parameters that we feel it should check for best possible outcomes","21cadf3f":"# Feature Engineering","19f1204e":"# Checking Skewness","52916d01":"# Saving the best model","51c4856c":"Observations: The above histogram shows us how the data is placed in our data set and if there are sections that have no entries for it. Like if I see in 'Rings' label the section near 15 is empty showing that possible there was not enough data collected that might fill in those number points too. Again in histogram we are confirming skewness that will need to be treated.","d76d2906":"# Distribution plot and Boxplot:","c92af578":"Remarks: After comparing both ExtraTreesClassifier and RandomForestClassifier, we saw that ExtraTreesClassifier is giving us 88% accuracy. Hence, we will us it only.","d4d3e49b":"Observations: In the above countplot we can see that list of categories that are present in the 'Sex' column and they are divided into 3 class namely M - Male, F - Female and I - Infant types. Looking at the plot we can see there are is not much of a class imbalance here but we do see the Male options being higher than the other two. If we were going to treat this as a classification problem then we have to apply an oversampling technique to get rid of the slighest of the imbalance.","237b851f":"Remarks: Dataset has no missing values. If there were any, we would have noticed in figure indicated by different colour shade","73094a74":"# Preparing Data for Model building","daefaba8":"Summary:\n\nThis was a classification problem where data was totally imbalanced and our target column also having a lot of values that were having only one count and some of the values were having less than 15 count so we converted them into bins,and we did lot of EDA to understand the impact of features on our target column,and if We talk about correlation, we were having high positive correlation. We have also applied PCA but in this case it was not working so we deleted that cells but we achieved 88% accuracy using EXTRATREESCLASSIFIER."}}