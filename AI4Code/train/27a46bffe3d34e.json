{"cell_type":{"ab199543":"code","fad1fc77":"code","991bd958":"code","2b98fd58":"code","f8b9cb2f":"code","fe265e7c":"code","fd741a18":"code","ee72f4ae":"code","d8ea90a0":"code","69e4f1ed":"code","12f0cde8":"code","d96e6bc4":"code","ea80dfd5":"code","f009ece6":"code","85f31d8c":"code","a35285bd":"code","7a12f97e":"code","81b0529e":"code","797b6ec7":"code","b8bf2e7b":"code","4a26a07a":"code","ba3618c8":"code","9934e0b2":"code","29fc8bef":"code","b5f8b410":"code","8a868c86":"code","97871fc8":"code","5eca4786":"code","dae5cac8":"code","4de24010":"code","a0493b09":"code","5a7c75ab":"code","c7fdf292":"code","bc2c97e0":"code","d78bd58f":"code","320ed02b":"code","71d43c93":"code","90f4fb2c":"code","6a7dfd09":"code","19ba24a9":"code","bed5b129":"code","bc85fca0":"code","1014a729":"code","d965bcc2":"code","df6f2754":"code","0a848d99":"code","c4c27ef2":"code","521a2ff4":"code","ce0f530b":"code","09f8f1b7":"code","14326719":"code","2bc62ac4":"code","0adead9d":"code","99b6591e":"code","41ca8cff":"code","7325e4fc":"code","7072decb":"code","20deeff2":"code","675d554c":"code","3dded0d0":"markdown","3a133ba1":"markdown","e3b0945b":"markdown","4002a2d5":"markdown","e7a4d8f5":"markdown","472a20bf":"markdown","0716a5c4":"markdown","0436bc44":"markdown","ab599a2d":"markdown","b2d7e4f5":"markdown","063c9b47":"markdown","e0be215d":"markdown","044ffc51":"markdown","75d214f6":"markdown","f600ff26":"markdown","5ca4f7bb":"markdown","cb6e7a99":"markdown"},"source":{"ab199543":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nimport time \nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import display, HTML\nimport plotly.graph_objects as go\nimport re\n# Natural Language Tool Kit \nimport nltk  \nnltk.download('stopwords') \nfrom nltk.corpus import stopwords \nfrom nltk.stem.porter import PorterStemmer \nfrom collections import Counter\nimport cufflinks as cf\ncf.go_offline()","fad1fc77":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nsubmission =  pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","991bd958":"train.head()","2b98fd58":"test.head()","f8b9cb2f":"display(HTML(f\"\"\"\n   \n        <ul class=\"list-group\">\n          <li class=\"list-group-item disabled\" aria-disabled=\"true\"><h4>Shape of Train and Test Dataset<\/h4><\/li>\n          <li class=\"list-group-item\"><h4>Number of rows in Train dataset is: <span class=\"label label-primary\">{ train.shape[0]:,}<\/span><\/h4><\/li>\n          <li class=\"list-group-item\"> <h4>Number of columns Train dataset is <span class=\"label label-primary\">{train.shape[1]}<\/span><\/h4><\/li>\n          <li class=\"list-group-item\"><h4>Number of rows in Test dataset is: <span class=\"label label-success\">{ test.shape[0]:,}<\/span><\/h4><\/li>\n          <li class=\"list-group-item\"><h4>Number of columns Test dataset is <span class=\"label label-success\">{test.shape[1]}<\/span><\/h4><\/li>\n        <\/ul>\n  \n    \"\"\"))","fe265e7c":"train.info()","fd741a18":"missing = train.isnull().sum()  \nmissing[missing>0].sort_values(ascending=False).iplot(kind='bar',title='Null values present in train Dataset', color=['red'])\n","ee72f4ae":"train.target.value_counts().iplot(kind='bar',text=['Fake', 'Real'], title='Comparing Tweet is a real disaster (1) or not (0)',color=['blue'])","d8ea90a0":"counts_train = train.target.value_counts(sort=False)\nlabels = counts_train.index\nvalues_train = counts_train.values\n\ndata = go.Pie(labels=labels, values=values_train ,pull=[0.03, 0])\nlayout = go.Layout(title='Comparing Tweet is a real disaster (1) or not (0) in %')\n\nfig = go.Figure(data=[data], layout=layout)\nfig.update_traces(hole=.3, hoverinfo=\"label+percent+value\")\nfig.update_layout(\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Train', x=0.5, y=0.5, font_size=20, showarrow=False)])\nfig.show()","69e4f1ed":"train['length'] = train['text'].apply(len)","12f0cde8":"data = [\n    go.Box(\n        y=train[train['target']==0]['length'],\n        name='Fake'\n    ),\n    go.Box(\n        y=train[train['target']==1]['length'],\n        name='Real'\n    )\n]\nlayout = go.Layout(\n    title = 'Comparison of text length in Tweets '\n)\nfig = go.Figure(data=data, layout=layout)\nfig.show()","d96e6bc4":"train.keyword.nunique()  # Total of 221 unique keywords","ea80dfd5":"\ntrain.keyword.value_counts()[:20].iplot(kind='bar', title='Top 20 keywords in text', color='red')","f009ece6":"train.location.value_counts()[:20].iplot(kind='bar', title='Top 20 location in tweet', color='blue')  # Check the top 15 locations ","85f31d8c":"STOPWORDS.add('https')  # remove htps to the world Cloud\n\ndef Plot_world(text):\n    \n    comment_words = ' '\n    stopwords = set(STOPWORDS) \n    \n    for val in text: \n\n        # typecaste each val to string \n        val = str(val) \n\n        # split the value \n        tokens = val.split() \n\n        # Converts each token into lowercase \n        for i in range(len(tokens)): \n            tokens[i] = tokens[i].lower() \n\n        for words in tokens: \n            comment_words = comment_words + words + ' '\n\n\n    wordcloud = WordCloud(width = 5000, height = 4000, \n                    background_color ='black', \n                    stopwords = stopwords, \n                    min_font_size = 10).generate(comment_words) \n\n    # plot the WordCloud image                        \n    plt.figure(figsize = (12, 12), facecolor = 'k', edgecolor = 'k' ) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n\n    plt.show() ","a35285bd":"text = train.text.values\n\nPlot_world(text)\n","7a12f97e":"#How many http words has this text?\ntrain.loc[train['text'].str.contains('http')].target.value_counts()","81b0529e":"pattern = re.compile('http[s]?:\/\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n\ndef remove_html(text):\n    no_html= pattern.sub('',text)\n    return no_html","797b6ec7":"# Remove all text that start with html\ntrain['text']=train['text'].apply(lambda x : remove_html(x))","b8bf2e7b":"# lets check if this clean works\ntrain.loc[train['text'].str.contains('http')].target.value_counts()","4a26a07a":"# Remove all text that start with html in test\ntest['text']=test['text'].apply(lambda x : remove_html(x))","ba3618c8":"def clean_text(text):\n \n    text = re.sub('[^a-zA-Z]', ' ', text)  \n\n    text = text.lower()  \n\n    # split to array(default delimiter is \" \") \n    text = text.split()  \n    \n    text = [w for w in text if not w in set(stopwords.words('english'))] \n\n    text = ' '.join(text)    \n            \n    return text","9934e0b2":"text = train.text[3]\nprint(text)\nclean_text(text)","29fc8bef":"# Apply clean text \ntrain['text'] = train['text'].apply(lambda x : clean_text(x))","b5f8b410":"# Apply clean text \ntest['text']=test['text'].apply(lambda x : clean_text(x))","8a868c86":"# How many unique words have this text\ndef counter_word (text):\n    count = Counter()\n    for i in text.values:\n        for word in i.split():\n            count[word] += 1\n    return count","97871fc8":"text_values = train[\"text\"]\n\ncounter = counter_word(text_values)","5eca4786":"print(f\"The len of unique words is: {len(counter)}\")\nlist(counter.items())[:10]","dae5cac8":"# The maximum number of words to be used. (most frequent)\n\nvocab_size = len(counter)\nembedding_dim = 32\n\n# Max number of words in each complaint.\nmax_length = 20\ntrunc_type='post'\npadding_type='post'\n\n# oov_took its set for words out our word index\noov_tok = \"<XXX>\"\ntraining_size = 6090\nseq_len = 12","4de24010":"# this is base in 80% of the data, an only text and targert at this moment\n\ntraining_sentences = train.text[0:training_size]\ntraining_labels = train.target[0:training_size]\n\ntesting_sentences = train.text[training_size:]\ntesting_labels = train.target[training_size:]","a0493b09":"\nprint('The Shape of training ',training_sentences.shape)\nprint('The Shape of testing',testing_sentences.shape)\n","5a7c75ab":"tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(training_sentences)\n","c7fdf292":"word_index = tokenizer.word_index","bc2c97e0":"# Lets see the first 10 elements\nprint(\"THe first word Index are: \")\nfor x in list(word_index)[0:15]:\n    print (\" {},  {} \".format(x,  word_index[x]))\n\n# If you want to see completed -> word_index","d78bd58f":"training_sequences = tokenizer.texts_to_sequences(training_sentences)\ntraining_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)","320ed02b":"print(train.text[1])\nprint(training_sequences[1])","71d43c93":"reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","90f4fb2c":"# Lets see the first 10 elements\nprint(\"THe first reverse word Index are: \")\nfor x in list(reverse_word_index)[0:15]:\n    print (\" {},  {} \".format(x,  reverse_word_index[x]))\n\n# If you want to see completed -> reverse_word_index","6a7dfd09":"def decode(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])","19ba24a9":"decode(training_sequences[1]) # this can be usefull for check predictions","bed5b129":"training_padded[1628]","bc85fca0":"\ntesting_sequences = tokenizer.texts_to_sequences(testing_sentences)\ntesting_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\n","1014a729":"# Model Definition with LSTM\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(14, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')  # remember this is a binary clasification\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","d965bcc2":"model.summary()\n","df6f2754":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)","0a848d99":"\nstart_time = time.time()\n\nnum_epochs = 10\nhistory = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels))\n\nfinal_time = (time.time()- start_time)\/60\nprint(f'The time in minutos: {final_time}')\n","c4c27ef2":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.head()","521a2ff4":"model_loss[['accuracy','val_accuracy']].plot(ylim=[0,1]);","ce0f530b":"predictions = model.predict_classes(testing_padded)   # predict_ clases because is classification problem with the split test","09f8f1b7":"predictions","14326719":"from sklearn.metrics import classification_report,confusion_matrix","2bc62ac4":"# Showing Confusion Matrix\ndef plot_cm(y_true, y_pred, title, figsize=(5,4)):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm \/ cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.title(title)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)","0adead9d":"# Showing Confusion Matrix\nplot_cm(testing_labels,predictions, 'Confution matrix of Tweets', figsize=(7,7))","99b6591e":"\ntesting_sequences2 = tokenizer.texts_to_sequences(test.text)\ntesting_padded2 = pad_sequences(testing_sequences2, maxlen=max_length, padding=padding_type, truncating=trunc_type)","41ca8cff":"predictions = model.predict(testing_padded2)","7325e4fc":"# sample of submission\nsubmission.head()","7072decb":"submission['target'] = (predictions > 0.5).astype(int)","20deeff2":"submission","675d554c":"submission.to_csv(\"submission.csv\", index=False, header=True)","3dded0d0":"## Competition Description\n* Twitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they\u2019re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).","3a133ba1":"<a href=\"#top\" class=\"btn btn-primary btn-lg active\" role=\"button\" aria-pressed=\"true\">Go to TOP<\/a>\n","e3b0945b":"<a id='libraries'><\/a>\n## 1. Import Libraries","4002a2d5":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content!<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#libraries\" role=\"tab\" aria-controls=\"profile\">Import Libraries<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#load\" role=\"tab\" aria-controls=\"messages\">Load Data<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#visual\" role=\"tab\" aria-controls=\"settings\">Visualization of data<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#word\" role=\"tab\" aria-controls=\"settings\">WordCloud<span class=\"badge badge-primary badge-pill\">4<\/span><\/a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#clean\" role=\"tab\" aria-controls=\"settings\">Cleaning the text<span class=\"badge badge-primary badge-pill\">5<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#split\" role=\"tab\" aria-controls=\"settings\">Train and test Split<span class=\"badge badge-primary badge-pill\">6<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#model\" role=\"tab\" aria-controls=\"settings\"> Creating the Model<span class=\"badge badge-primary badge-pill\">7<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#eval\" role=\"tab\" aria-controls=\"settings\">Model Evaluation<span class=\"badge badge-primary badge-pill\">8<\/span><\/a>  ","e7a4d8f5":"### Now remove stopwords, pass to lower add delimiter and more","472a20bf":" <a id='word'><\/a>\n#  4. WordCloud","0716a5c4":"<h2>I hope this notebook <span style=\"color:red\">Usefull<\/span> for you! <\/h3>","0436bc44":"<a id='clean'><\/a>\n# 5. Cleaning the text","ab599a2d":"<a id='load'><\/a>\n# 2. Load Data","b2d7e4f5":"<a id='model'><\/a>\n# 7. Creating the Model\n\n    # For a binary classification problem\n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n                                    ","063c9b47":"<a id='top'><\/a>\n<h1 style=\"text-align:center;font-size:200%;;\">Real or Not? NLP with Disaster Tweets<\/h1>\n<img src=\"https:\/\/dataxboost.files.wordpress.com\/2018\/03\/nlp.jpg\">","e0be215d":"## check Inverse for see how it works","044ffc51":"<ul style=\"list-style-type:square;\">\n  <li><span class=\"label label-default\">id<\/span> a unique identifier for each tweet<\/li>\n  <li><span class=\"label label-default\">text <\/span> the text of the tweet<\/li>\n  <li><span class=\"label label-default\">location<\/span>  the location the tweet was sent from (may be blank)<\/li>\n    <li><span class=\"label label-default\">keyword<\/span>  a particular keyword from the tweet (may be blank)<\/li>\n    <li><span class=\"label label-default\">target<\/span>  in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)<\/li>\n<\/ul>\n","75d214f6":"# Now working with test dataset","f600ff26":"<a id='visual'><\/a>\n# 3. Visualization of data","5ca4f7bb":"<a id='split'><\/a>\n# 6. Train Test Split","cb6e7a99":"<a id='eval'><\/a>\n# 8. Model Evaluation"}}