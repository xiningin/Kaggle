{"cell_type":{"668dd12a":"code","7f1578b5":"code","25ecf819":"code","0db8ef56":"code","354748ac":"code","fe7ad034":"code","28c8178e":"code","3cf42519":"code","5a824934":"code","0f2062ce":"code","5dcf9294":"code","a3091dfe":"code","76035f57":"code","2352bf31":"code","0e55d9bc":"code","be868458":"code","abd756bc":"code","0ce8b046":"code","cd991417":"code","e1bf6400":"code","ade4c2e6":"code","e05a1bb4":"code","d6a2b67f":"code","493eeafd":"code","b85ba02e":"code","343a5060":"code","d15d3bc0":"code","65ec55bf":"code","d6caf662":"code","26212aef":"code","6fe00741":"code","9afd7386":"code","7e981864":"markdown","cfbb941e":"markdown","b6a1460a":"markdown","78a9ad4d":"markdown","52c1d26d":"markdown","6f09a2d9":"markdown","74bb8f32":"markdown","202bde88":"markdown","3a7b6954":"markdown","56ee9d40":"markdown","30b69aed":"markdown","da457e7a":"markdown"},"source":{"668dd12a":"import os\nimport random\nimport numpy as np\nimport shutil\n\nimport torch.nn as nn\nimport torchvision\nfrom torchvision.transforms import ToTensor\n\nfrom kaggle_secrets import UserSecretsClient\n\nfrom PIL import Image\nimport torchvision.transforms.functional as TF\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n\nmpl.rcParams['figure.dpi']= 100\nmpl.rcParams[\"savefig.dpi\"] = 300","7f1578b5":"%%capture\n!pip install pynvml\nimport pynvml\nfrom pynvml.smi import nvidia_smi\npynvml.nvmlInit()","25ecf819":"deviceCount = pynvml.nvmlDeviceGetCount()\nfor i in range(deviceCount):\n    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n    print(f\"Device {i} {pynvml.nvmlDeviceGetName(handle).decode()}\")\nprint(f\"Free GPU memory - {nvidia_smi.getInstance().DeviceQuery('memory.total')}\")","0db8ef56":"random.seed(42)\nage_limits = [10,20,30,40,50,60,70,80,100,120]\ntest_split = 0.1\nvalid_split = 0.1\n\nEPOCHS = 10\nBATCH_SIZE = 10\nLEARNING_RATE = 2e-5\n\nfreezed = True","354748ac":"os.mkdir(\"\/kaggle\/utkface\/\")\nos.mkdir(\"\/kaggle\/utkface\/train\/\")\nos.mkdir(\"\/kaggle\/utkface\/test\/\")\nos.mkdir(\"\/kaggle\/utkface\/valid\/\")\nos.mkdir(\"\/kaggle\/workdir\/\")","fe7ad034":"all_classes = []\nl = 0\nfor x in range(len(age_limits)):\n    class_name = str(l)+\"-\"+str(age_limits[x]-1)\n    l=str(age_limits[x])\n    all_classes.append(class_name)\n    os.mkdir(\"\/kaggle\/utkface\/train\/\"+class_name+\"\/\")\n    os.mkdir(\"\/kaggle\/utkface\/test\/\"+class_name+\"\/\")\n    os.mkdir(\"\/kaggle\/utkface\/valid\/\"+class_name+\"\/\")","28c8178e":"path = \"..\/input\/utkface-new\/UTKFace\/\"\n\nfor filename in os.listdir(path):\n    age = int(filename.split(\"_\")[0])\n    bin_index = np.digitize(age, bins=age_limits)\n\n\n    class_name = all_classes[bin_index]\n\n    #copy files in correct folder\n    shutil.copy2(path+filename, \"\/kaggle\/utkface\/train\/\"+class_name+\"\/\"+filename)","3cf42519":"for class_filename in os.listdir(\"\/kaggle\/utkface\/train\"):\n    number_images = len(next(os.walk(\"\/kaggle\/utkface\/train\/\"+class_filename))[2])\n\n  \n    number_test_images = int(test_split * number_images)\n    number_valid_images = int(valid_split * number_images)\n\n    all_images_filenames = next(os.walk(\"\/kaggle\/utkface\/train\/\"+class_filename))[2]\n\n    #select random test images from all images\n    test_images_filenames = random.sample(all_images_filenames, number_test_images)\n    #remove test images from all images\n\n    all_images_filenames = [ img for img in all_images_filenames if img not in test_images_filenames]\n    #select random valid images from all images\n    valid_images_filenames = random.sample(all_images_filenames, number_valid_images)\n\n\n    for x in test_images_filenames:\n        shutil.move(\"\/kaggle\/utkface\/train\/\"+class_filename+\"\/\"+x, \"\/kaggle\/utkface\/test\/\"+class_filename+\"\/\"+x)\n\n    for x in valid_images_filenames:\n        shutil.move(\"\/kaggle\/utkface\/train\/\"+class_filename+\"\/\"+x, \"\/kaggle\/utkface\/valid\/\"+class_filename+\"\/\"+x)\n","5a824934":"train_ds = torchvision.datasets.ImageFolder('\/kaggle\/utkface\/train\/', transform=ToTensor())\nvalid_ds = torchvision.datasets.ImageFolder('\/kaggle\/utkface\/valid\/', transform=ToTensor())\ntest_ds = torchvision.datasets.ImageFolder('\/kaggle\/utkface\/test\/', transform=ToTensor())","0f2062ce":"%%capture\n!pip install transformers","5dcf9294":"from transformers import ViTForImageClassification","a3091dfe":"model = ViTForImageClassification.from_pretrained('google\/vit-large-patch16-224')\nclasses = len(train_ds.classes)\nmodel.classifier = nn.Linear(1024, classes)","76035f57":"pytorch_total_params = sum(p.numel() for p in model.parameters())\nprint(\"Model: {} Parameter\".format(pytorch_total_params))","2352bf31":"if freezed:\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.classifier.parameters():\n        param.requires_grad = True","0e55d9bc":"%%capture\n!pip install transformers datasets","be868458":"import torch.utils.data as data\nfrom transformers import ViTFeatureExtractor\nfrom transformers import AdamW\nfrom transformers import get_scheduler\nfrom datasets import load_metric\nimport torch\nfrom tqdm.auto import tqdm\nfrom torch.autograd import Variable","abd756bc":"feature_extractor = ViTFeatureExtractor.from_pretrained('google\/vit-large-patch16-224-in21k')","0ce8b046":"train_dataloader = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\ntest_dataloader  = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nvalid_dataloader = data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)","cd991417":"optimizer = AdamW(model.parameters(), lr=5e-5)\nloss_func = nn.CrossEntropyLoss()\nmetric = load_metric(\"accuracy\")\ntrain_metric = load_metric(\"accuracy\")\n\nnum_training_steps = EPOCHS * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps\n)","e1bf6400":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \nif torch.cuda.is_available():\n    model.cuda() ","ade4c2e6":"val_acc, train_acc, train_loss = [], [], []","e05a1bb4":"model.train()\nfor epoch in range(EPOCHS):\n    for (x, y) in train_dataloader:\n        x = np.split(np.squeeze(np.array(x)), np.array(x).shape[0])\n        for index, array in enumerate(x):\n            x[index] = np.squeeze(array)\n        x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n        x, y  = x.to(device), y.to(device)\n        b_x = Variable(x)\n        b_y = Variable(y)\n\n        optimizer.zero_grad()\n        #genereate predicitons\n        output = model(b_x, None)\n        train_metric.add_batch(predictions=torch.argmax(output.logits, dim=-1), references=b_y)\n        #compute loss\n        loss = loss_func(output.logits, b_y)  \n        \n        #back propagate and optimize\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        \n    #testing accuracy\n    for (x, y) in test_dataloader:\n        #prepare data\n        x = np.split(np.squeeze(np.array(x)), np.array(x).shape[0])\n        for index, array in enumerate(x):\n            x[index] = np.squeeze(array)\n        x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n        x, y  = x.to(device), y.to(device)\n\n        #get output without gradients\n        with torch.no_grad():\n            outputs = model(x, None)\n\n        #compare results\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        metric.add_batch(predictions=predictions, references=y)\n    \n    history = metric.compute()\n    train_history = train_metric.compute()\n    print(\"epoch:\", epoch)\n    print(\"accuracy: {:6.4f}\".format(history[\"accuracy\"]))\n    print(\"loss: {:6.4f}\".format(loss.data))\n    \n    val_acc.append(history[\"accuracy\"])\n    train_acc.append(train_history[\"accuracy\"])\n    train_loss.append(loss.data)","d6a2b67f":"torch.save(model.state_dict(), \"\/kaggle\/working\/model.pth\")","493eeafd":"eps = range(0, EPOCHS)\n\nplt.plot(eps, val_acc, 'g', label='Validation Accuracy')\nplt.plot(eps, train_acc, 'b', label='Training Accuracy')\nplt.title('Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","b85ba02e":"plt.plot(eps, train_loss, 'b', label='Loss')\nplt.title('Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","343a5060":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt ","d15d3bc0":"y_true = []\ny_pred = []\nmodel.eval()\nfor (x, y) in valid_dataloader:\n    x = np.split(np.squeeze(np.array(x)), np.array(x).shape[0])\n    for index, array in enumerate(x):\n        x[index] = np.squeeze(array)\n    x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n    x, y  = x.to(device), y.to(device)\n\n    #get output without gradients\n    with torch.no_grad():\n        outputs = model(x, None)\n\n    #compare results\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=y)\n    \n    y_true.append(y)\n    y_pred.append(predictions)\n    \nhistory = metric.compute()\nout = \"accuracy: {:6.2f}\".format(history[\"accuracy\"])\nprint(out)","65ec55bf":"# send to cpu if needed and construct one tensor out of list of tensors\ny_pred = torch.cat(y_pred).cpu()\ny_true = torch.cat(y_true).cpu()","d6caf662":"# Build confusion matrix\ncf_matrix = confusion_matrix(y_true, y_pred)\ndf_cm = pd.DataFrame(cf_matrix, index = [i for i in all_classes],columns = [i for i in all_classes])\nplt.figure(figsize = (12,7))\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.title(\"Confusion Matrix\")\nplt.savefig('\/kaggle\/working\/confusionMatrix.png')","26212aef":"def test_image(paths, number_columns=5):\n    \n    number_images = len(paths)    \n    a = int(np.ceil(number_images \/ number_columns))\n    \n    fig = plt.figure(figsize=(3*number_columns,a*3))\n\n    for i in range(number_images):\n        plt.subplot(a, number_columns, i+1)\n        plt.xlabel(i)\n        \n        \n        #prediciton\n        image = Image.open(paths[i])\n        x = TF.to_tensor(image)\n        x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n        x = x.to(device)\n        with torch.no_grad():\n            outputs = model(x, None)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        #send to cpu\n        predictions = predictions.cpu()\n        predicted_class = all_classes[predictions]\n        \n        #get real label\n        label = paths[i].split(\"\/\")[-1].split(\"_\")[0]\n        #set title\n        title = f\"predicted: {predicted_class}  real age:{label}\"\n        plt.title(title, fontsize= 8)\n        imgplot = plt.imshow(image)        \n        plt.axis('off')\n        \n    plt.show()","6fe00741":"#count is number of images per class\ndef get_random_images(count=2):\n    paths = []\n    for folder in os.listdir(\"\/kaggle\/utkface\/valid\/\"):\n        filenames = os.listdir(f\"\/kaggle\/utkface\/valid\/{folder}\/\")\n        filenames = [f\"\/kaggle\/utkface\/valid\/{folder}\/\"+x for x in filenames]\n        paths.extend(random.sample(filenames, count))\n    return paths","9afd7386":"images = get_random_images(3)\ntest_image(images,6)","7e981864":"test random images from valid folder","cfbb941e":"# imports","b6a1460a":"# Initialise Parameters","78a9ad4d":"training loop","52c1d26d":"# folders","6f09a2d9":"# training","74bb8f32":"get some informations about the GPU","202bde88":"freeze params","3a7b6954":"use GPU if possible","56ee9d40":"# ViT installation","30b69aed":"# Validation","da457e7a":"# show some test results"}}