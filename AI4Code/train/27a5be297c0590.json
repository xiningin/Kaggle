{"cell_type":{"49913051":"code","b77629c6":"code","1710c816":"code","eb853d56":"code","a79880fa":"code","3e4abcaf":"code","34ae97e5":"code","e3ce13d0":"code","177f19f3":"code","f64cc5d6":"code","c7e5056b":"code","3550c37b":"code","1004afb8":"code","06d12a3d":"code","e2c519e3":"code","30e0ffdd":"code","d4bccc23":"code","576d32a9":"code","877df215":"code","d14e75a5":"code","6cf7a47e":"code","97fa52a2":"code","4424d3a8":"code","5153fd63":"code","c09d5344":"code","54ecb666":"code","48a1308c":"code","57412be2":"code","a8beda55":"code","0cb90cc3":"code","dbe582f3":"code","65170d43":"code","2267416d":"code","2a3bf622":"code","0d0030a1":"code","c1cb8455":"code","9cf78076":"code","7586214e":"code","2472324f":"code","c8029190":"code","82ca0992":"code","bd8c5d61":"code","37fcb28b":"code","f570fbad":"code","c38bebd6":"code","a4a5a545":"code","a311d1ad":"code","6b594240":"markdown","a935bc24":"markdown","94bff66d":"markdown","a565b88a":"markdown","7fa03cd4":"markdown","560e3b34":"markdown","c57cc88d":"markdown","4a039b31":"markdown","6d7c5fa4":"markdown","cdc5784c":"markdown","426e3c49":"markdown","fae7c2ab":"markdown","9400498a":"markdown","3bea0355":"markdown","ba58a00d":"markdown","0b446b8e":"markdown","17202872":"markdown","fe69c795":"markdown","d99aab4f":"markdown","11795f3c":"markdown","2d74b377":"markdown","a7b7f4f7":"markdown","96edbb13":"markdown","8920e775":"markdown"},"source":{"49913051":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport scipy as sp\nimport warnings\nimport tensorflow as tf\nimport string\nimport datetime\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","b77629c6":"train = pd.read_csv('\/kaggle\/input\/handwriting-recognition\/written_name_train_v2.csv')\nvalid = pd.read_csv('\/kaggle\/input\/handwriting-recognition\/written_name_validation_v2.csv')","1710c816":"train.head()","eb853d56":"valid.head()","a79880fa":"train.describe()\n","3e4abcaf":"train.info()","34ae97e5":"train.shape","e3ce13d0":"valid.shape","177f19f3":"train.value_counts()","f64cc5d6":"train.dtypes","c7e5056b":"valid.dtypes","3550c37b":"valid.columns","1004afb8":"train.columns","06d12a3d":"train.isnull().sum()","e2c519e3":"valid.isnull().sum()","30e0ffdd":"train.isnull().any()","d4bccc23":"train=train.dropna()","576d32a9":"valid=valid.dropna()","877df215":"train.isnull().sum()\n","d14e75a5":"valid.isnull().sum()","6cf7a47e":"train.isnull().any()","97fa52a2":"#lets find the categorialfeatures\nlist_1=list(train.columns)\n","4424d3a8":"list_cate=[]\nfor i in list_1:\n    if train[i].dtype=='object':\n        list_cate.append(i)\n","5153fd63":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\n","c09d5344":"for i in list_cate:\n    train[i]=le.fit_transform(train[i])\n","54ecb666":"train","48a1308c":"X = train.drop('FILENAME',axis=1)\ny = train['FILENAME']\n","57412be2":"train.hist(figsize=(14,12))\nplt.show()\n","a8beda55":"train.corr()","0cb90cc3":"plt.figure(figsize = (12,10))\n\nsns.heatmap(train.corr(), annot =True)\n","dbe582f3":"plt.figure(figsize=(14,10))\nsns.set_style(style='whitegrid')\nplt.subplot(2,3,1)\nsns.boxplot(x='FILENAME',data=train)\nplt.subplot(2,3,2)\nsns.boxplot(x='IDENTITY',data=train)\n\n\n","65170d43":"\ntrain['IDENTITY'].plot(kind='hist')\n","2267416d":"plt.style.use(\"default\")\nsns.barplot(x=\"IDENTITY\", y=\"FILENAME\",data=train[180:190])\nplt.title(\"Identity vs Filename\",fontsize=15)\nplt.xlabel(\"Identity\")\nplt.ylabel(\"Filename\")\nplt.show()\n\n","2a3bf622":"plt.style.use(\"default\")\nsns.barplot(x=\"FILENAME\", y=\"IDENTITY\",data=train[180:190])\nplt.title(\"Filename vs Identity\",fontsize=15)\nplt.xlabel(\"Filename\")\nplt.ylabel(\"Identity\")\nplt.show()\n","0d0030a1":"plt.style.use(\"default\")\nplt.figure(figsize=(14,7))\nsns.lineplot(x = \"FILENAME\",y = \"IDENTITY\",data = train[190:400], color='g')\nplt.title(\"Filename vs Identity\")\nplt.xlabel(\"Filename\")\nplt.ylabel(\"Identity\")\nplt.show()\n","c1cb8455":"plt.style.use(\"default\")\nplt.figure(figsize=(14,8))\nplt.xlabel('Identity')\nplt.ylabel('Filename')\nsns.kdeplot(train['IDENTITY'],shade=True,color='g')\nplt.show()\n","9cf78076":"sns.scatterplot(x='FILENAME',y=\"IDENTITY\",data=train)","7586214e":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=12)\n","2472324f":"print(len(X_train))\nprint(len(X_test))\nprint(len(y_train))\nprint(len(y_test))","c8029190":"from tensorflow import keras\nfrom tensorflow.keras import layers\nmodel = tf.keras.Sequential([\n      tf.keras.layers.Dense(units=80,activation='relu',name = 'input_layer'),\n      tf.keras.layers.Dense(units=60,activation='relu',name = 'dense_layer1'),\n      tf.keras.layers.Dense(units=40,activation='relu',name = 'dense_layer2'),\n      tf.keras.layers.Dense(units=1,name='Output_layer')\n],name='Model')   # Dropout and Batch Normalization can also be used.\n\n\n        \nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',        # In loss mae can also be used.\n    metrics=['binary_accuracy'],\n)\n\n\nhistory = model.fit(X_train,y_train,batch_size=256,\n    epochs=150,\n)\n","82ca0992":"y_pred = model.predict(X_test)\ny_pred\n","bd8c5d61":"# convert the training history to a dataframe\nhistory_df = pd.DataFrame(history.history)\n# use Pandas native plot method\nhistory_df['loss'].plot()\n","37fcb28b":"model.summary()\n","f570fbad":"from tensorflow.keras.utils import plot_model\n\nplot_model(model, show_shapes = True)\n","c38bebd6":"history_df = pd.DataFrame(history.history)\n# Start the plot at epoch 5\nhistory_df.loc[5:, ['loss']].plot()\nhistory_df.loc[5:, ['binary_accuracy']].plot()\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['loss'].min(), \n              history_df['binary_accuracy'].max()))\n\n","a4a5a545":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n","a311d1ad":"model.evaluate(X_test,y_test)\n","6b594240":"**LINEPLOT**","a935bc24":"![](https:\/\/i.imgur.com\/eP0gppr.png)","94bff66d":"![](https:\/\/i.imgur.com\/tHiVFnM.png)","a565b88a":"**Activation Function other than relu we have are :**\n\n**Sigmoid**\n\n**Threshold**\n\n**Hyperbolic Tangent**","7fa03cd4":"# **Handwriting Recognition - TensorFlow**","560e3b34":"**Our dataset contains some null values we have to drop them.**","c57cc88d":"# **IMPORTING THE LIBRARIES**","4a039b31":"![](https:\/\/img.favpng.com\/8\/2\/22\/input-device-handwriting-recognition-digital-pen-png-favpng-rgu2P2MfvDMT0P5a85nXWjbFH.jpg)","6d7c5fa4":"**HEATMAP**","cdc5784c":"# EXPLORATORY DATA ANALYSIS","426e3c49":"**TENSORFLOW**","fae7c2ab":"**KDE PLOT**","9400498a":"**BARPLOT**","3bea0355":"# **If u like this notebook please appreciate it with a upvote !!**","ba58a00d":"**HISTOGRAM**","0b446b8e":"**SCATTER PLOT**","17202872":"**Dropping Null Values**","fe69c795":"**TRAINING AND TESTING DATA**","d99aab4f":"**Data Pre Processing**","11795f3c":"**Thus all the null values have been dropped.**","2d74b377":"**BOXPLOT**","a7b7f4f7":"![](https:\/\/i.imgur.com\/rFI1tIk.gif)","96edbb13":"**Checking Null Values**","8920e775":"# **LOADING THE DATASET**"}}