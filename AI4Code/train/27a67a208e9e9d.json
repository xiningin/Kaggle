{"cell_type":{"445aefaa":"code","74333ffa":"code","23a0954d":"code","d90a621f":"code","064df9e5":"code","b03dfcdf":"code","83444e5b":"code","7a5ae98a":"code","22d24c9f":"code","f0e8319f":"code","70e506f7":"code","6abb87e0":"code","288b39d9":"code","e03c8ab5":"code","107058f7":"code","d0959cf2":"code","70d1764b":"code","33e6920b":"code","340c483b":"code","fb7e1c37":"code","008ef09d":"code","02ae5c28":"code","8838104f":"code","574d5091":"code","23ade44c":"code","c07e9a98":"code","95e39faa":"code","7a90a0cc":"code","b3805b8a":"code","020f144d":"code","b9629f21":"code","a308c830":"code","e7195ea7":"code","5b2bf732":"code","6ee6093f":"code","2179b916":"code","7576c22c":"code","61723c87":"code","43224f5f":"code","01a52151":"code","addd97e5":"code","0b1767eb":"code","918870a2":"code","4e57b179":"code","630e0c8a":"code","546ce20d":"code","55f8b2f6":"code","b7bb9930":"code","423f87b2":"code","8a6a0f50":"markdown","882ab513":"markdown","69851159":"markdown","dd0587c6":"markdown","81bbcc90":"markdown","8b0349f5":"markdown","da5cb6f9":"markdown","641f90bc":"markdown","0048ecdc":"markdown"},"source":{"445aefaa":"from IPython.display import clear_output\n!pip install imutils\nclear_output()","74333ffa":"import cv2\nimport imutils\nimport numpy as np\nimport shutil\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils import shuffle\n\n%matplotlib inline","23a0954d":"def crop_brain_contour(image):\n    \n    # Convert the image to grayscale, and blur it slightly\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n    # Threshold the image, then perform a series of erosions +\n    # dilations to remove any small regions of noise\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    # Find contours in thresholded image, then grab the largest one\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)\n    \n    # Find the extreme points\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n    \n    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]] \n\n    return new_image","d90a621f":"# Function for Image preprocessing\ndef processDataset(dataset_src, dataset_dest):\n    # Making a Copy of Dataset\n    shutil.copytree(src, dest)\n    for folder in os.listdir(dest):\n        for (index, filen) in enumerate(os.listdir(os.path.join(dest, folder)), start = 1):\n            filename = f'{folder}_brain-tumor_{index}.jpg';\n            img_src = os.path.join(dest, folder, filen);\n            img_des = os.path.join(dest, folder, filename);\n            # Preprocess the Images\n            img = cv2.imread(img_src);\n            img = crop_brain_contour(img);\n            img = cv2.resize(img, (240, 240), interpolation=cv2.INTER_CUBIC);\n            cv2.imwrite(img_des ,img);\n            os.remove(img_src);\n\n# Source Location for Dataset\nsrc = '..\/input\/brain-mri-images-for-brain-tumor-detection\/brain_tumor_dataset';\n# Destination Location for Dataset\ndest = '.\/BrainTumorDataset';\n# Image preprocessing\nprocessDataset(src, dest);","064df9e5":"def GetDatasetSize(path):\n    num_of_image = {}\n    for folder in os.listdir(path):\n        # Counting the Number of Files in the Folder\n        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));\n    return num_of_image;\n    \npath = \".\/BrainTumorDataset\"\nDatasetSize = GetDatasetSize(path);\nprint(DatasetSize);","b03dfcdf":"# Function for Creating Train \/ Validation \/ Test folders (One time use Only)\n \ndef TrainValTestSplit(root_dir, classes_dir, val_ratio = 0.15, test_ratio = 0.10):\n    main_folder = '.\/BrainTumor_Splited_Data\/';\n\n    for cls in classes_dir:\n        # Creating Split Folders\n        os.makedirs(main_folder + 'train' + cls)\n        os.makedirs(main_folder + 'val' + cls)\n        os.makedirs(main_folder + 'test' + cls)\n\n        # Folder to copy images from\n        src = root_dir + cls\n        \n        # Storing the Filenames\n        allFileNames = os.listdir(src)\n        np.random.seed(123)\n        np.random.shuffle(allFileNames)\n        # Spliting the Files in the Given ratio\n        train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames), [int(len(allFileNames)* (1 - (val_ratio + test_ratio))), int(len(allFileNames)* (1 - test_ratio))])\n\n        train_FileNames = [src+'\/'+ name for name in train_FileNames.tolist()]\n        val_FileNames = [src+'\/' + name for name in val_FileNames.tolist()]\n        test_FileNames = [src+'\/' + name for name in test_FileNames.tolist()]\n\n        # Printing the Split Details\n        print(cls.upper(),':')\n        print('Total images: ', len(allFileNames))\n        print('Training: ', len(train_FileNames))\n        print('Validation: ', len(val_FileNames))\n        print('Testing: ', len(test_FileNames))\n\n        # Copy-pasting images\n        for name in train_FileNames:\n            shutil.copy(name, main_folder + 'train' + cls)\n\n        for name in val_FileNames:\n            shutil.copy(name, main_folder + 'val' + cls)\n\n        for name in test_FileNames:\n            shutil.copy(name, main_folder + 'test' + cls)\n        print();\n\n# Preforming Train \/ Validation \/ Test Split\nroot_dir = '.\/BrainTumorDataset'              # Dataset Root Folder\nclasses_dir = ['\/no', '\/yes']  # Classes\nTrainValTestSplit(root_dir, classes_dir);","83444e5b":"import zipfile \nimport tensorflow as tf \nimport keras\nfrom keras.layers import Dense,Conv2D, Flatten, MaxPool2D, Dropout\nfrom keras.models import Sequential\nfrom keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model ","7a5ae98a":"TRAIN_DIR = '.\/BrainTumor_Splited_Data\/train'\nVAL_DIR = '.\/BrainTumor_Splited_Data\/val'\nTEST_DIR = '.\/BrainTumor_Splited_Data\/test'","22d24c9f":"def GetDatasetSize(path):\n    num_of_image = {}\n    for folder in os.listdir(path):\n        # Counting the Number of Files in the Folder\n        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));\n    return num_of_image;\n    \ntrain_set = GetDatasetSize(TRAIN_DIR)\nval_set = GetDatasetSize(VAL_DIR)\ntest_set = GetDatasetSize(TEST_DIR)","f0e8319f":"labels = ['YES', 'NO']\ntrain_list = list(train_set.values())\nval_list = list(val_set.values())\ntest_list = list(test_set.values())\n\nx = np.arange(len(labels))  # the label locations\nwidth = 0.25  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x - width, train_list, width, label='Train')\nrects2 = ax.bar(x, val_list, width, label='Val')\nrects3 = ax.bar(x + width, test_list, width, label='Test')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Images Count')\nax.set_title('Dataset')\nax.set_xticks(x, labels)\nax.legend()\n\nax.bar_label(rects1)\nax.bar_label(rects2)\nax.bar_label(rects3)\n\nfig.tight_layout()\n\nplt.show()","70e506f7":"train_datagen = ImageDataGenerator( rotation_range=10,\n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1,\n                                    shear_range=0.1,\n                                    brightness_range=[0.5, 1.5],\n                                    horizontal_flip=True,\n                                    vertical_flip=True\n                                    )\n\ntrain_data = train_datagen.flow_from_directory(directory= TRAIN_DIR,\n                                               target_size=(240,240),\n                                               batch_size=64,\n                                               class_mode = 'binary')","6abb87e0":"val_datagen = image.ImageDataGenerator(rescale = 1.\/255)\n\nval_data = val_datagen.flow_from_directory(directory= VAL_DIR,\n                                               target_size=(240,240),\n                                               batch_size=16,\n                                               class_mode = 'binary')","288b39d9":"test_datagen = image.ImageDataGenerator(rescale = 1.\/255)\n\ntest_data = test_datagen.flow_from_directory(directory= TEST_DIR,\n                                               target_size=(240,240),\n                                               batch_size=32,\n                                               class_mode = 'binary')","e03c8ab5":"train_data.class_indices","107058f7":"# CNN Model \n\nmodel = Sequential() \n\n# Convolutional Layer with input shape (240,240,3)\nmodel.add(Conv2D(filters=32, kernel_size= (3,3), activation= 'relu', input_shape=(240,240,3)) )\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=1, activation='sigmoid'))\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),\n              loss='binary_crossentropy', \n              metrics=['accuracy']  )\n \nmodel.summary()","d0959cf2":"# Adding Model check point Callback\n\nmc = ModelCheckpoint(\n    filepath=\".\/bt_cnn_best_model.hdf5\",\n    monitor= 'val_accuracy', \n    verbose= 1,\n    save_best_only= True, \n    mode = 'auto'\n    );\n\ncall_back = [ mc ];","70d1764b":"# Fitting the Model\ncnn = model.fit(\n    train_data, \n    steps_per_epoch = train_data.samples\/\/train_data.batch_size, \n    epochs = 32, \n    validation_data = val_data, \n    validation_steps = val_data.samples\/\/val_data.batch_size,\n    callbacks = call_back \n    )","33e6920b":"# Loading the Best Fit Model \nmodel = load_model(\".\/bt_cnn_best_model.hdf5\")","340c483b":"# Checking the Accuracy of the Model \naccuracy_cnn = model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy_cnn*100} %\")","fb7e1c37":"cnn.history.keys()","008ef09d":"# Plot model performance\nacc = cnn.history['accuracy']\nval_acc = cnn.history['val_accuracy']\nloss = cnn.history['loss']\nval_loss = cnn.history['val_loss']\nepochs_range = range(1, len(cnn.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","02ae5c28":"from tensorflow.keras.applications.vgg16 import VGG16\n\nmodel_VGG = VGG16(\n    weights='imagenet',\n    input_shape = (240, 240, 3), # Shape of our images\n    include_top = False  # Leave out the last fully connected layer\n    )\n\nfor layer in model_VGG.layers:\n       layer.trainable = False\n        \nmodel_VGG.layers[-2].trainable = True;\nmodel_VGG.layers[-1].trainable = True;","8838104f":"vgg16 = Sequential()\nvgg16.add(model_VGG)\nvgg16.add(layers.Dropout(0.25))\nvgg16.add(layers.Flatten())\nvgg16.add(layers.Dropout(0.5))\nvgg16.add(layers.Dense(1, activation='sigmoid'))\n\nvgg16.compile(\n    loss='binary_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),\n    metrics=['accuracy']\n)\n\nvgg16.summary()","574d5091":"# Adding Model check point Callback\n\nmc = ModelCheckpoint(\n    filepath=\".\/bt_vgg_best_model.hdf5\",\n    monitor= 'val_accuracy',\n    verbose= 1, \n    save_best_only= True,\n    mode = 'auto'\n    );\n\ncall_back = [ mc ];","23ade44c":"vgg = vgg16.fit(\n    train_data,\n    steps_per_epoch = train_data.samples\/\/train_data.batch_size, \n    epochs = 32, \n    validation_data = val_data, \n    validation_steps = val_data.samples\/\/val_data.batch_size,\n    callbacks=call_back\n)","c07e9a98":"# Loading the Best Fit Model \nmodelVGG = load_model(\".\/bt_vgg_best_model.hdf5\")","95e39faa":"# Checking the Accuracy of the Model \naccuracy_vgg = modelVGG.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy_vgg*100} %\")","7a90a0cc":"vgg.history.keys()","b3805b8a":"# Plot model performance\nacc = vgg.history['accuracy']\nval_acc = vgg.history['val_accuracy']\nloss = vgg.history['loss']\nval_loss = vgg.history['val_loss']\nepochs_range = range(1, len(vgg.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","020f144d":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nbase_model = InceptionV3(input_shape = (240, 240, 3), \n                         include_top = False, \n                         weights = 'imagenet')\n\nfor layer in base_model.layers:\n       layer.trainable = False\n        \nbase_model.layers[-2].trainable = True;\nbase_model.layers[-1].trainable = True;","b9629f21":"x = layers.Flatten()(base_model.output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\n\n# Add a final sigmoid layer with 1 node for classification output\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel_incep = tf.keras.models.Model(base_model.input, x)\n\nmodel_incep.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.002), \n                    loss = 'binary_crossentropy', \n                    metrics = ['accuracy'])","a308c830":"# Adding Model check point Callback\n\nmc = ModelCheckpoint(\n    filepath=\".\/ct_incep_best_model.hdf5\",\n    monitor= 'val_accuracy', \n    verbose= 1,\n    save_best_only= True, \n    mode = 'auto'\n    );\n\ncall_back = [mc];","e7195ea7":"# Fitting the Model\nincep = model_incep.fit(\n    train_data, \n    steps_per_epoch = train_data.samples\/\/train_data.batch_size, \n    epochs = 32, \n    validation_data = val_data, \n    validation_steps = val_data.samples\/\/val_data.batch_size,\n    callbacks = call_back \n    )","5b2bf732":"# Loading the Best Fit Model \ninceptionv3_model = load_model(\".\/ct_incep_best_model.hdf5\")","6ee6093f":"# Checking the Accuracy of the Model \naccuracy_incep = inceptionv3_model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy_incep*100} %\")","2179b916":"incep.history.keys()","7576c22c":"# Plot model performance\nacc = incep.history['accuracy']\nval_acc = incep.history['val_accuracy']\nloss = incep.history['loss']\nval_loss = incep.history['val_loss']\nepochs_range = range(1, len(incep.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","61723c87":"from tensorflow.keras.applications import ResNet50\n\nbase_model = ResNet50(input_shape=(240, 240,3),\n                      include_top=False, \n                      weights=\"imagenet\")\n\nfor layer in base_model.layers:\n       layer.trainable = False\n\nbase_model.layers[-1].trainable = True;","43224f5f":"model_resnet = Sequential()\nmodel_resnet.add(base_model)\nmodel_resnet.add(layers.Dropout(0.3))\nmodel_resnet.add(layers.Flatten())\nmodel_resnet.add(layers.Dropout(0.5))\nmodel_resnet.add(layers.Dense(1, activation='sigmoid'))","01a52151":"model_resnet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.002), \n                     loss = 'binary_crossentropy', \n                     metrics = ['accuracy'])\n\nmodel_resnet.summary()","addd97e5":"# Adding Model check point Callback\n\nmc = ModelCheckpoint(\n    filepath=\".\/ct_resnet_best_model.hdf5\",\n    monitor= 'val_accuracy', \n    verbose= 1,\n    save_best_only= True, \n    mode = 'auto'\n    );\n\ncall_back = [mc];","0b1767eb":"# Fitting the Model\nresnet = model_resnet.fit(\n    train_data, \n    steps_per_epoch = train_data.samples\/\/train_data.batch_size, \n    epochs = 32, \n    validation_data = val_data, \n    validation_steps = val_data.samples\/\/val_data.batch_size,\n    callbacks = call_back \n    )","918870a2":"# Loading the Best Fit Model \nresnet_model = load_model(\".\/ct_resnet_best_model.hdf5\")","4e57b179":"# Checking the Accuracy of the Model \naccuracy_resnet = resnet_model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy_resnet*100} %\")","630e0c8a":"resnet.history.keys()","546ce20d":"# Plot model performance\nacc = resnet.history['accuracy']\nval_acc = resnet.history['val_accuracy']\nloss = resnet.history['loss']\nval_loss = resnet.history['val_loss']\nepochs_range = range(1, len(resnet.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","55f8b2f6":"algos = ['CNN', 'VGG16', 'InceptionV3', 'Resnet50']\naccuracy = [accuracy_cnn, accuracy_vgg, accuracy_incep, accuracy_resnet]\naccuracy = np.floor([i * 100 for i in accuracy])\n  \nfig = plt.figure(figsize = (10, 5))\n \n# creating the bar plot\nplt.bar(algos, accuracy, color ='orange', width = 0.3)\n \nplt.xlabel(\"Algorithms Applied\")\nplt.ylabel(\"Accuracy\")\nplt.show()","b7bb9930":"def brainTumorPrediction(path,Model):\n    # Loading Image\n    img = image.load_img(path, target_size=(240,240))\n    # Normalizing Image\n    norm_img = image.img_to_array(img)\/255\n    # Converting Image to Numpy Array\n    input_arr_img = np.array([norm_img])\n    # Getting Predictions\n    pred = (Model.predict(input_arr_img) > 0.5).astype(int)[0][0]\n    # Printing Model Prediction\n    if pred == 0:\n        print(\"No Brain tumor\")\n    else:\n        print(\"Brain Tumor\")","423f87b2":"path = \"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y10.jpg\"\nbrainTumorPrediction(path,modelVGG)","8a6a0f50":"### Predictions","882ab513":"## Split the Dataset \n\n#### Such that we have \n* 75% for Train Data\n* 15% for Validation Data\n* 10% for Testing Data","69851159":"## Comparison","dd0587c6":"## Importing Necessary Libraries","81bbcc90":"## CNN Model","8b0349f5":"## Inceptionv3 Model","da5cb6f9":"## VGG16 Model","641f90bc":"## RestNet50 Model","0048ecdc":"## Importing Keras for Image Classification"}}