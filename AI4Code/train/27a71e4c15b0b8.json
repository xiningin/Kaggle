{"cell_type":{"f5e7a32f":"code","9698b169":"code","ec5a8036":"code","97c3063f":"code","93273b6e":"code","50972b4e":"code","325d8df1":"code","a85e1aa0":"code","1dd49611":"code","7a6be4da":"markdown"},"source":{"f5e7a32f":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","9698b169":"import pandas as pd\n\nlocation = '..\/input\/iris\/Iris.csv'\niris_dataset = pd.read_csv(location)\niris_dataset.head(10)","ec5a8036":"iris_dataset.hist(alpha=0.5, figsize=(20, 20), color='red')\nplt.show()","97c3063f":"#separating elements\ncolumns = list(iris_dataset.columns)\nX = iris_dataset[[columns[1], columns[2], columns[3], columns[4]]]\ny = iris_dataset[columns[5]]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30)","93273b6e":"def machine_learning_algorithms(X, y):\n    train_X = X\n    train_y = y\n    \n    modelForest = RandomForestClassifier(n_estimators=100)\n    modelForest.fit( train_X , train_y)\n    \n    modelLogistic = LogisticRegression()\n    modelLogistic.fit(train_X , train_y)\n    \n    modeltrees = ExtraTreesClassifier(n_estimators=100)\n    modeltrees.fit(train_X , train_y)\n    \n    modelSVC = SVC()\n    modelSVC.fit(train_X , train_y)\n\n    modelgbc = GradientBoostingClassifier()\n    modelgbc.fit( train_X , train_y)\n    \n    modelKNN = KNeighborsClassifier(n_neighbors = 3)\n    modelKNN.fit( train_X , train_y)\n    \n    modelGaussian = GaussianNB()\n    modelGaussian.fit(train_X , train_y)\n\n    models = [modelForest, modelLogistic, modeltrees, modelSVC, modelgbc, modelKNN, modelGaussian]\n    \n    return models\n\nnp.random.seed(1000)\nalgorithm = machine_learning_algorithms(X_train, y_train)\n","50972b4e":"columns = ['RandomForest', 'Logistic Regression', 'Tree Classifier', 'SVC', 'GBC', 'KMeans', 'N. Bayes']\nscores_train = []\nscores_test = []\nfor k in range(0, 7):\n    scores_train.append(algorithm[k].score(X_train, y_train))\n    scores_test.append(algorithm[k].score(X_test, y_test))\n                \nRandomForest = 'Train:{}  Test:{}'.format(\"%.4f\" % scores_train[0], \"%.4f\" % scores_test[0])\nLogisticRegr = 'Train:{}  Test:{}'.format(\"%.4f\" % scores_train[1], \"%.4f\" % scores_test[1])\nTreeClassifier = 'Train:{}  Test:{}'.format(\"%.4f\" % scores_train[2], \"%.4f\" % scores_test[2])\nSVC = 'Train:{}  Test:{}'.format(\"%.4f\" % scores_train[3], \"%.4f\" % scores_test[3])\nGBC = 'Train:{}  Test:{}'.format(\"%.4f\" % scores_train[4], \"%.4f\" % scores_test[4])\nKmeans = 'Train:{}  Test:{}'.format(\"%.4f\" % scores_train[5], \"%.4f\" % scores_test[5])\nNBayes = 'Train:{}  Test:{}'.format(\"%.4f\" % scores_train[6], \"%.4f\" % scores_test[6])","325d8df1":"print(\"Random Forest                     :\", RandomForest) \nprint(\"Logistic Regression               :\", LogisticRegr)\nprint(\"Tree Classifier                   :\", TreeClassifier)\nprint(\"Support-Vector Machine(SVM)       :\", SVC)\nprint(\"Gradient Boosting Classifier (GBC):\", GBC)\nprint(\"KMeans                            :\", Kmeans)\nprint(\"Naive Bayes                       :\", NBayes)","a85e1aa0":"plt.figure(figsize=(15,6))\nplt.title(' Different model comparison: Train Score')\nplt.ylabel(' Score')\nbar = plt.bar(columns, scores_train)\nbar[0].set_color('red')\nbar[1].set_color('green')\nbar[2].set_color('blue')\nbar[3].set_color('pink')\nbar[4].set_color('orange')\nbar[5].set_color('gray')\nbar[6].set_color('black')","1dd49611":"plt.figure(figsize=(15,6))\nplt.title(' Different model comparison: Test Score')\nplt.ylabel(' Score')\nbar = plt.bar(columns, scores_test)\nbar[0].set_color('red')\nbar[1].set_color('green')\nbar[2].set_color('blue')\nbar[3].set_color('pink')\nbar[4].set_color('orange')\nbar[5].set_color('gray')\nbar[6].set_color('black')","7a6be4da":"# Machine Learning - Comparison Models \n- Random Forest                   \n- Logistic Regression              \n- Tree Classifier      \n- Support-Vector Machine(SVM)   \n- Gradient Boosting Classifier (GBC)\n- Kmeans\n- Naive Bayes    "}}