{"cell_type":{"8268fc9c":"code","89cd07a1":"code","88a5e72d":"code","536d28ba":"code","7f310496":"code","a8afafd1":"code","d10c9dbe":"code","9fc839ea":"code","3b6adc98":"code","b8e12488":"code","f08743fa":"code","9dab7407":"code","b2c56eab":"code","8331f88b":"code","75227972":"code","576ca650":"code","f95ffaaf":"code","db401997":"code","b54e77d4":"code","39a6b339":"code","85ef9e34":"code","c787f5d4":"code","94350ea1":"code","778971b0":"code","34874502":"code","81933c95":"code","80ad1818":"code","cd0ae695":"code","8ef27ed7":"code","fe1801ba":"code","d45123ce":"code","75f71021":"code","a7a7ac87":"code","2f897cd5":"code","7b789565":"code","0f7ed410":"code","2b54cd94":"code","62b1dba3":"code","bba744a8":"code","db9fca84":"code","b19b0f2e":"code","1e5c83b8":"code","08a97845":"code","26df34b5":"code","88795ebe":"code","8e9f35bf":"code","d393bfc7":"code","7a450499":"code","867295e8":"code","13f3d131":"code","52df0e53":"markdown","d89e3445":"markdown","eb4d5011":"markdown","206cd12f":"markdown"},"source":{"8268fc9c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\nimport os\nfiles = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        files.append(os.path.join(dirname, filename))","89cd07a1":"df = pd.read_csv('\/kaggle\/input\/top-cars-sales-20182020-fictitious\/topCarsSales.csv')","88a5e72d":"def edaFromData(dfA, allEDA=False, desc='Exploratory Data Analysis'):\n    print('Explorando os dados')\n    print(f'\\nShape:\\n{dfA.shape}')\n    print(f'\\nIs Null:\\n{dfA.isnull().mean().sort_values(ascending=False)}')\n    dup = dfA.duplicated()\n    print(f'\\nDuplicated: \\n{dfA[dup].shape}\\n')\n    try:\n        print(dfA[dfA.duplicated(keep=False)].sample(4))\n    except:\n        pass\n    if allEDA:  # here you put yours prefered analysis that detail more your dataset\n        \n        print(f'\\nDTypes - Numerics')\n        print(dfA.describe(include=[np.number]))\n        print(f'\\nDTypes - Categoricals')\n        print(dfA.describe(include=['object']))\n        \n        #print(df.loc[:, df.dtypes=='object'].columns)\n        print(f'\\nHead dos dados:\\n{dfA.head()}')\n        print(f'\\nSamples dos dados:\\n{dfA.sample(2)}')\n        print(f'\\nTail dos dados:\\n{dfA.tail()}')","536d28ba":"edaFromData(df)","7f310496":"df.head(3)","a8afafd1":"newdf = pd.DataFrame()\nnewdf['id']=df['id']\nnewdf['date']=pd.to_datetime(df['date'])\nnewdf['car']=df['car']\nnewdf['colorCar'] = df['car_color']\nnewdf['colorSeat'] = df['seat_color']\nnewdf['price']=df['value (US$ mi)']\nnewdf['priceOff'] = df['value off (US$ mi)']\nnewdf['discount']=df['discount (%)']\nnewdf['total']=df['total (US$ mi)']\nnewdf['salesperson']=df['salesperson']\nnewdf['city']=df['city']\nnewdf['country']=df['country']\nnewdf.head(3)","d10c9dbe":"def correlation(dfA, varT, minValue=0.5, showGraphic=True, title='Correlation between variables'):\n    corr = dfA.corr()\n    print(f'\\nAnalysing features:\\n'\n          f'Target: {varT}\\n'\n          f'minValue de ref.: {minValue}\\n'\n          f'\\nMain Features:')\n    corrs = corr[varT]\n    features = []\n    for i in range(0, len(corrs)):\n        if corrs[i] > minValue and corrs.index[i] != varT:\n            print(corrs.index[i], f'{corrs[i]:.2f}')\n            features.append(corrs.index[i])\n    if showGraphic:\n        plt.subplots()\n        sns.heatmap(corr,\n                    annot=True, fmt='.2f', vmin=-1, vmax=1, linewidth=0.01,\n                    linecolor='black', cmap='RdBu_r'\n                    )\n        plt.title(title)\n        plt.show()\n    \n    return features","9fc839ea":"varTarget = 'total'\nvarFeatures = correlation(dfA=newdf, varT=varTarget, minValue=0.1, showGraphic=True)","3b6adc98":"\nnewdf['year']=pd.DatetimeIndex(newdf['date']).year\nnewdf['month']=pd.DatetimeIndex(newdf['date']).month\nnewdf.sample(10)","b8e12488":"def sepColumns(dataset):\n    num = []\n    cat = []\n    for i in dataset.columns:\n        if dataset[i].dtype == 'object':\n            cat.append(i)\n        else:\n            num.append(i)\n    return num, cat","f08743fa":"num, cat = sepColumns(newdf)\nnum, cat","9dab7407":"# lower case for all\nfor x in cat:\n    newdf[x] = newdf[x].str.lower()","b2c56eab":"newdf.country.unique().tolist()\n","8331f88b":"newdf.sample(10)","75227972":"car = newdf.car.unique().tolist()\nseller = newdf.salesperson.unique().tolist()\ncity = newdf.city.unique().tolist()\ncountry = newdf.country.unique().tolist()\ncolorcar = newdf.colorCar.unique().tolist()\ncolorseat = newdf.colorSeat.unique().tolist()\n","576ca650":"car, city, country, seller, colorcar, colorseat","f95ffaaf":"# replace city newyouk to new york\nnewdf['city'] = newdf['city'].apply(lambda x: 'new york' if x == 'newyouk' else x)\ncity = newdf.city.unique().tolist()\ncity","db401997":"newdf['carNum'] = newdf['car'].apply(lambda x: car.index(x))\nnewdf['salespersonNum'] = newdf['salesperson'].apply(lambda x: seller.index(x))\nnewdf['cityNum'] = newdf['city'].apply(lambda x: city.index(x))\nnewdf['countryNum'] = newdf['country'].apply(lambda x: country.index(x))\nnewdf['colorCarNum'] = newdf['colorCar'].apply(lambda x: colorcar.index(x))\nnewdf['colorSeatNum'] = newdf['colorSeat'].apply(lambda x: colorseat.index(x))","b54e77d4":"newdf.sample(10)","39a6b339":"sns.pairplot(newdf[num])","85ef9e34":"varTarget = 'total'\nvarFeatures = correlation(dfA=newdf, varT=varTarget, minValue=0.1, showGraphic=True)","c787f5d4":"varFeatures = ['year','carNum']\nnewdf[['year','price', 'total']].describe()","94350ea1":"sns.set(style=\"ticks\")\nfig, ax = plt.subplots(ncols=2, sharey=True, figsize=(15,5))\ncol = 0\nfor var in varFeatures:\n    data = newdf.pivot_table(index=var, values=varTarget, aggfunc=\"mean\")\n    sns.barplot(x=data.index, y=data[varTarget], ax=ax[col]).set_title(f'Feature {var}')\n    col += 1\nplt.show()","778971b0":"# source image https:\/\/publiclab.org\/notes\/mimiss\/06-18-2019\/creating-a-boxplot-to-identify-outliers-using-codap\nfrom IPython.display import Image\nImage('https:\/\/publiclab.org\/system\/images\/photos\/000\/032\/980\/original\/Screen_Shot_2019-06-18_at_10.27.45_AM.png')","34874502":"def removeOutliers(out, varTarget):\n    print('\\nOutliers\\nRemoving ...', end='')\n    cidgrp = out[varTarget]\n    print('..', end='')\n    # quantiles\n    qtl1 = cidgrp.quantile(.25)  \n    qtl3 = cidgrp.quantile(.75)\n    print('..', end='')\n    # calculating iqr\n    iqr = qtl3 - qtl1\n    print('..', end='')\n\n    # creating limits\n    baixo = qtl1 - 1.5 * iqr\n    alto = qtl3 + 1.5 * iqr\n    print('..', end='')\n\n    # removing outliers\n    novodf = pd.DataFrame()\n    print('..', end='')\n\n    limites = out[varTarget].between(left=baixo, right=alto, inclusive=True)\n    novodf = pd.concat([novodf, out[limites]])\n\n    print('.....Done')\n\n    return novodf","81933c95":"noOut = removeOutliers(newdf, varTarget)\n# Is there outlier?\nsns.set(style=\"whitegrid\")\n# Two subplots\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True, figsize=(15,5))\nsns.boxplot(x=newdf[varTarget], ax=ax1).set_title('Original')\nsns.boxplot(x=noOut[varTarget], ax=ax2).set_title('Original No outliers')\n\n\n# yep... but..","80ad1818":"noOut = removeOutliers(noOut, varTarget)\n# Is there outlier?\nsns.set(style=\"whitegrid\")\n# Two subplots\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True, figsize=(15,5))\nsns.boxplot(x=newdf[varTarget], ax=ax1).set_title('Original')\nsns.boxplot(x=noOut[varTarget], ax=ax2).set_title('Original No outliers')","cd0ae695":"len(newdf.car.unique()), newdf.car.unique()","8ef27ed7":"len(noOut.car.unique()), noOut.car.unique()","fe1801ba":"newdf[newdf.car == 'bugatti la voiture noire']['total'].describe()","d45123ce":"newdf[newdf.car == 'rolls-royce sweptail']['total'].describe()","75f71021":"newdf.total.describe(), noOut.total.describe()","a7a7ac87":"sns.barplot(x=newdf.total.describe().index[1:], y=newdf.total.describe().values[1:])","2f897cd5":"sns.barplot(x=noOut.total.describe().index[1:], y=noOut.total.describe().values[1:])","7b789565":"# subplots varT x varFeatures\n# year\nsns.set(style=\"ticks\")\n\nfig, ax = plt.subplots(ncols=2, figsize=(15,6))\nfor varf in varFeatures:\n    sns.scatterplot(x=varTarget, y='year', data=newdf, ax=ax[0]).set_title('Original')\n    sns.scatterplot(x=varTarget, y='year', data=noOut, ax=ax[1]).set_title('Original no Outliers')","0f7ed410":"# subplots varT x varFeatures\n# discount\nsns.set(style=\"ticks\")\n\nfig, ax = plt.subplots(ncols=2, figsize=(15,6))\nfor varf in varFeatures:\n    sns.scatterplot(x=varTarget, y='discount', data=newdf, ax=ax[0]).set_title('Original')\n    sns.scatterplot(x=varTarget, y='discount', data=noOut, ax=ax[1]).set_title('Original no Outliers')","2b54cd94":"varFeatures = correlation(noOut, varT=varTarget, minValue=0.02, showGraphic=True)","62b1dba3":"# ML Algorithms sklearn\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, PoissonRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.dummy import DummyRegressor\n\n# ML selecao de dados de treino e teste\nfrom sklearn.model_selection import train_test_split\n# calcular o menor erro medio absoluto entre 2 dados apresentados\nfrom sklearn.metrics import mean_absolute_error","bba744a8":"# regressors list\nregressors = [\n        DecisionTreeRegressor(),\n        RandomForestRegressor(),\n        SVR(),\n        LinearRegression(),\n        GradientBoostingRegressor(),\n        PoissonRegressor(),\n        DummyRegressor(),\n        LogisticRegression(),\n        GaussianNB()\n    ]","db9fca84":"varFeatures","b19b0f2e":"X = noOut[varFeatures[2:]]\ny = noOut[varTarget]\nXtreino, Xteste, ytreino, yteste = train_test_split(X, y, test_size=0.3, random_state=123)","1e5c83b8":"reg = []\nmae = []\nsco = []\nfor regressor in regressors:\n    modelo = RandomForestRegressor()\n    modelo.fit(Xtreino, np.array(ytreino))\n    sco.append(modelo.score(Xtreino, ytreino))\n    previsao = modelo.predict(Xteste)\n    mae.append(round(mean_absolute_error(yteste, previsao), 2))\n    reg.append(regressor)\n","08a97845":"meuMae = pd.DataFrame(columns=['Regressor', 'mae', 'score'])\nmeuMae['Regressor'] = reg\nmeuMae['mae'] = mae\nmeuMae['score'] = sco","26df34b5":"meuMae = meuMae.sort_values(by='score', ascending=False)\nmeuMae","88795ebe":"car, varFeatures[2:], f'Best Regressor: {meuMae[\"Regressor\"].values[0]}'","8e9f35bf":"varFeatures = ['year', 'carNum']\nvalFeatures = [2020, car.index('mclaren p1 lm')]\nvarFeatures, valFeatures","d393bfc7":"model = meuMae[\"Regressor\"].values[0]\nx = noOut[varFeatures]\ny = noOut[varTarget]\nmodel.fit(x, y)","7a450499":"predict = float(model.predict([valFeatures]))","867295e8":"print(f'Summary:\\n'\n          f'Regs analyzed: {len(noOut)}\\n'\n          f'ML applied: {meuMae[\"Regressor\"].values[0]}\\n'\n          f'Features analyzed:')\n\nfor i in range(0, len(varFeatures)):\n    print(f' - {varFeatures[i]}: {valFeatures[i]}')\n\nprint(f\"Predicted value: US${predict:.2f} mi\")\n","13f3d131":"# cars with the same setup in the dataset \nnoOut.query(f'year == 2020 and carNum == 1')[['carNum', 'year', 'total']].describe()","52df0e53":"in noOut, we remove outliers but... we lose 2 cars: 'bugatti la voiture noire' and 'rolls-royce ","d89e3445":"# Predictions","eb4d5011":"**Predicting this sale**\n* Using best regressor \n* year = 2020\n* car = mclaren p1 lm - carNum is car.index('mclaren p1 lm')","206cd12f":"# Removing Outliers\n\nMore about outliers [here](https:\/\/en.wikipedia.org\/wiki\/Outlier)"}}