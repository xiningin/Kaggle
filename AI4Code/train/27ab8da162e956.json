{"cell_type":{"db431f76":"code","0cc84fe9":"code","6c6dcbbc":"code","a24e68e1":"code","577d809e":"code","5c184ac8":"code","d4cfd384":"code","982b7e12":"code","a3496212":"code","b852553a":"code","f2daf270":"code","ac1b5513":"code","85641232":"code","e4f61b60":"code","e340b926":"code","f94e9f36":"code","8b4afdba":"code","99354fe3":"code","fbcf3de2":"code","a331fd37":"code","aa0441ef":"code","fe161837":"code","e8adf5ff":"code","86dcd9a6":"code","0407540b":"code","b01c8982":"code","b70e306b":"code","ba7405cc":"code","1b888777":"code","3372be5f":"code","14fedd77":"code","535e96f4":"code","26319b11":"code","a4f2f19c":"code","1cd43785":"code","0fe35cb9":"code","0cbcf5e6":"code","ca88bd62":"code","f31809c5":"code","9529c254":"code","dc67decb":"code","dbf79d03":"code","813d6e2d":"code","4abe7edd":"code","1b8cd3bf":"code","b94224d0":"code","0424d08b":"code","198a1e91":"code","fe378ce0":"code","73e14670":"code","959dc274":"code","e8f82b41":"code","252f8fe6":"code","1c51331a":"code","283a0ee1":"code","5168a2e4":"code","d5923e57":"code","dc7752f7":"code","2c5d02b7":"code","775e9887":"code","773229a4":"code","0975c02d":"code","4e764fe9":"code","d0c12c47":"code","cb00f1af":"code","6557bcb2":"code","38635a26":"code","e1b5a478":"code","4db58d35":"code","a0ffc0a2":"code","9c5e4ca2":"code","93ea293b":"code","622e997d":"code","554474db":"code","69964074":"code","0009ba88":"code","9bc543b1":"code","2936706a":"markdown","2265b99a":"markdown","730c6cdc":"markdown","7b1042f7":"markdown","8a51a78b":"markdown","d3a11534":"markdown","2cc608ba":"markdown","10c84c82":"markdown","0d5745de":"markdown","8b9bd623":"markdown","b30215e5":"markdown","25ed948b":"markdown","f1b6c268":"markdown","55aba5e8":"markdown","e44ae344":"markdown","b734b50c":"markdown","c27837b8":"markdown","f7991625":"markdown","5a80d9e0":"markdown","654127b4":"markdown","f8adb28d":"markdown","23dd7644":"markdown","ee4da306":"markdown"},"source":{"db431f76":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0cc84fe9":"#Import data\ndata= pd.read_csv('..\/input\/amazon-prime-tv-shows\/Prime TV Shows Data set.csv', encoding = 'iso-8859-1')\ndata.head()","6c6dcbbc":"data.drop('S.no.',axis=1,inplace=True)     ## Dropping Serial Number column","a24e68e1":"data.isnull().sum()      ## Checking Null values","577d809e":"type(data)      ## type of data","5c184ac8":"data.nunique()       ## number of unique values in every column","d4cfd384":"data['Language'].unique()         ## Different languages in which movies are released on Amazon prime.","982b7e12":"data['Genre'].unique()         ### Type of MOvies released on Amazon Prime.","a3496212":"data['Age of viewers'].unique()      ## unique Age of viewers\/ The age group who used to watch Amazon Prime movies.","b852553a":"data['Name of the show'].nunique()    ","f2daf270":"data.shape","ac1b5513":"data.max()    ## Maximum number of movies released in 2020 and seasons available is 20 and maximum rating is 9.5 on AMAzon Prime","85641232":"data.min()    ## Maximum number of movies released in 1926 and seasons available is 1 and maximum rating is 3.7 on Amazon Prime","e4f61b60":"data.describe(include='all')        ##DEscribe data by including all categorical or nominal data and quantitative datatype.","e340b926":"data.describe()","f94e9f36":"data['Genre'].value_counts().head(2)    ## Drama is most frequent value   (showing the most frequenct(Mode)value)","8b4afdba":"data['Genre'].fillna(data['Genre'].value_counts().index[0],inplace=True)    ## filling the missing value","99354fe3":"data['Name of the show'].fillna(data['Name of the show'].value_counts().index[0],inplace=True)   ## filling the missing value","fbcf3de2":"data['No of seasons available'].fillna(data['No of seasons available'].value_counts().index[1],inplace=True)   ## filling the missing value","a331fd37":"data['Language'].fillna(data['Language'].value_counts().index[0],inplace=True)     ## filling the missing value","aa0441ef":"data['Age of viewers'].fillna(data['Age of viewers'].value_counts().index[0],inplace=True)    ## filling the missing value","fe161837":"data['Year of release'].fillna(data['Year of release'].value_counts().index[0],inplace=True)   ## filling the missing value","e8adf5ff":"data.isnull().sum()   ","86dcd9a6":"data['IMDb rating'].value_counts().head(2)","0407540b":"import matplotlib.pyplot as plt","b01c8982":"data.sample(2)","b70e306b":"data.corr(method='pearson')","ba7405cc":"import seaborn as sns\nplt.subplots(figsize=(12,6))\nsns.set(font_scale=1.2)\nsns.heatmap(data.corr(), annot=True)\nplt.show()","1b888777":"from plotnine import *\nimport warnings\nwarnings.filterwarnings('ignore')","3372be5f":"data.hist(bins=50,figsize=(20,15))\nplt.show()","14fedd77":"sns.boxplot(x ='Age of viewers',y = 'IMDb rating',data = data,palette ='rainbow')   ##Checking Outliers  ","535e96f4":"sns.boxplot(x ='IMDb rating',y = 'Age of viewers',data = data,palette ='rainbow')   ##Checking Outliers  ","26319b11":"sns.countplot(x = \"Age of viewers\", data =data)","a4f2f19c":"sns.countplot(y= \"Language\", data = data)","1cd43785":"figsize=(20,15)\nsns.distplot(data['IMDb rating'])        ## density plot","0fe35cb9":"sns.pairplot(data)","0cbcf5e6":"from wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\n#### Wordcloud showing the most frequent 'Genre released by Amazon prime'.\nwordcloudG=WordCloud(max_font_size=40, relative_scaling=.5,background_color='White',stopwords=stopwords).generate(data['Genre'].str.cat())\nplt.imshow(wordcloudG, interpolation=\"bilinear\")\nplt.axis('off')\nplt.margins(x=0, y=0) \nplt.show()\nplt.savefig(\"donaldwc.png\")","ca88bd62":"#### Wordcloud showing the most frequent 'Name of the show released by Amazon prime'.\nwordcloud2=WordCloud(max_font_size=40, relative_scaling=.5,background_color='White',stopwords=stopwords).generate(data['Name of the show'].str.cat())\nplt.imshow(wordcloud2, interpolation=\"bilinear\")\nplt.axis('off')\nplt.margins(x=0, y=0) \nplt.show()\nplt.savefig(\"donaldwc.png\")","f31809c5":"# Top 10 TV shows in the genre: 'Drama'\ntop_drama = data[data['Genre'] == 'Drama'].sort_values(by = 'IMDb rating',ascending = False)\n#Top 10 TV shows in drama\ntop_drama.head(10)","9529c254":"# Let us now take a look at 20 worst rated shows\ndata.sort_values(by = \"IMDb rating\", ascending = True).head(20)","dc67decb":"top_english = data[data['Language'] == 'English'].sort_values(by = 'IMDb rating',ascending = False)\n#Top 10 TV shows in english with the highest rating by viewers\ntop_english.head(10)","dbf79d03":"Q1=data['IMDb rating'].quantile(0.25)\nQ3=data['IMDb rating'].quantile(0.75)\nIQR=Q3-Q1\nprint(Q1)\nprint(Q3)\nprint(round(IQR,3))\nLower_Whisker = Q1-1.5*IQR\nUpper_Whisker = Q3+1.5*IQR\nprint(round(Lower_Whisker,3), round(Upper_Whisker,3))","813d6e2d":"data.head(1)","4abe7edd":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data.drop('Year of release', 1), data['Year of release'],\n                                                   test_size=0.2, random_state=5)","1b8cd3bf":"import math as m\nm.sqrt(len(data))    # Formula to decide the k-value in KNN","b94224d0":"num = [col for col in X_train.columns if X_train[col].dtypes != 'O']\nX_train[num].head()","0424d08b":"from sklearn.impute import KNNImputer\n\nimputer = KNNImputer(n_neighbors= 20,add_indicator=True)\n\nimputer1 = imputer.fit_transform(X_train[num])\n\nprint(\"\\nImpute with 20 Neighbour: \\n\", imputer1)","198a1e91":"imputer.transform(X_train[num])","fe378ce0":"data2=pd.DataFrame(imputer.transform(X_train[num]))  # Converting train array into dataframe","73e14670":"X_test[num].isna().sum()\n","959dc274":"imputer.transform(X_test[num])","e8f82b41":"data1=pd.DataFrame(imputer.transform(X_test[num]))     # Converting test array into dataframe","252f8fe6":"pd.DataFrame(imputer.transform(X_test[num])).isna().sum().sum()","1c51331a":"df = pd.concat([data2, data1])","283a0ee1":"df.head(2) ","5168a2e4":"df = df.rename({0:\"No of seasons available\",1:\"IMDb ratingss\"}, axis='columns')\ndf","d5923e57":"data.shape","dc7752f7":"df.drop(2, 1,inplace=True)   ","2c5d02b7":"df.head(2)","775e9887":"df.isnull().sum() ","773229a4":"Q1=df['IMDb ratingss'].quantile(0.25)\nQ3=df['IMDb ratingss'].quantile(0.75)\nIQR=Q3-Q1\nprint('First Quartile',Q1)\nprint('Thrid Quartile',Q3)\nprint('IQR-',round(IQR,3))\nLower_Whisker = Q1-1.5*IQR\nUpper_Whisker = Q3+1.5*IQR\nprint('\\n')\nprint('Lower Whisker value is -',round(Lower_Whisker,3))\nprint('Uower Whisker value is -', round(Upper_Whisker,3))","0975c02d":"print(df['IMDb ratingss'].min())\nprint(df['IMDb ratingss'].max())","4e764fe9":"sns.boxplot(df['IMDb ratingss'])","d0c12c47":"df.head(2)","cb00f1af":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n# the independent variables set\nX = df[['No of seasons available','IMDb ratingss']]\n  \n# VIF dataframe\nvif_data = pd.DataFrame()\nvif_data[\"feature\"] = X.columns\n  \n# calculating VIF for each feature\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n                          for i in range(len(X.columns))]\n  \nprint(vif_data)","6557bcb2":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(data2)\nX_test= sc.transform(data1)","38635a26":"from sklearn.decomposition import PCA\n\npca = PCA()\nX_train1 = pca.fit_transform(X_train)\nX_test1 = pca.transform(X_test)","e1b5a478":"explained_variance = pca.explained_variance_ratio_","4db58d35":"explained_variance","a0ffc0a2":"df1= pd.merge(data, df, right_index=True, left_index=True)   ###Merge the actual data and cleaned trained data.\ndf1","9c5e4ca2":"top_drama = df1[df1['Genre'] == 'Drama'].sort_values(by = 'IMDb ratingss',ascending = False)   \n#Top 10 TV shows in drama which has the highest rating\ntop_drama.head(10)","93ea293b":"crosstab1=pd.crosstab(df1['No of seasons available_y'], df1['IMDb ratingss'])\ncrosstab1","622e997d":"pd.crosstab(index=df1['Age of viewers'],columns=df1['Genre'],dropna=True)      ####Two Way Tables","554474db":"crosstab12=pd.crosstab(df1['Age of viewers'], df1['Language'])\ncrosstab12","69964074":"from scipy import stats\nfrom scipy.stats import chi2_contingency\nprint(\"Chi Square Test\")\nprint(\"\\n\")\n\nprint(\"Null Hypothesis : There is no correlation (independent relation) present between the two variables\")\nprint(\"Alternative Hypothesis : There is correlation(dependent relation) present between the two variables\")\nprint(\"\\n\")\n\nchi, pval, dof, exp = chi2_contingency(crosstab12)\nalpha=0.05\n\nprint(\"Chi Square Test statistic : %.3f, p value : %.6f\" % (chi, pval))\n\nif pval > alpha:\n    print('Variables are non correlated (fail to reject H0)')\nelse:\n    print('Variables are correlated (reject H0)') ","0009ba88":"df1.head(1)","9bc543b1":"print(\"One way ANOVA\")\nprint(\"\\n\")\n\nprint(\"Null Hypothesis : There is no significant difference in the means of the groups\")\nprint(\"Alternative Hypothesis : There is a significant difference between any one group in the means of the groups\")\nprint(\"\\n\")\n\ncol1 = list(df1.columns.values)[1]     #Year of release    \ncol2 = list(df1.columns.values)[7]     #Number of seasons available\ncol3 =  list(df1.columns.values)[8]    #IMDb ratings\n\ntest,p=stats.f_oneway(df1[col1], df1[col2],df1[col3])\n\nprint(\"One way ANOVA statistic : %.3f, p value : %.6f\" % (test, p))\n\nif p > alpha:\n    print('There is no significant difference among the groups (fail to reject H0)')\nelse:\n    print('There is a significant difference among the groups (reject H0)')","2936706a":"#### From the above graph we can say that 'data is not linearly related and also not normally distributed'.","2265b99a":"**Variables:**\nThe data set contains the \n1. name of the show or title, \n2. year of the release which is the year in which the show was released or went on-air, \n3. No.of seasons means the number of seasons of the show which are available on Prime, \n4. Language is for the audio language of the show and does not take into consideration the language of the subtitles, \n5. genre of the show like Kids, Drama, Action and so on, \n6. IMDB ratings of the show: though for many tv shows and kid shows the rating was not available,      \n7. Age of Viewers is to specify the age of the target audience- All in age means that the content is not restricted to any particular age group and all audiences can view it.","730c6cdc":"- if VIF=1 ; Not correlated   \n- If 1<VIF<5 ; Moderately correlated    \n- if VIF>=5,10; Highly correlated   \n\nso here our vif values lie between 1 and 5 so the data is moderately or less correlated, so we can say that there is a chances of less risk.","7b1042f7":"- Since,there numerous outliers present we can not remove this values because if we remove it then there is a loss of information will occur in large amount.","8a51a78b":"#### The mostly used amazon prime is by the viewers who is 16+ in age and 2nd is 18+ age of viewers.","d3a11534":"- The PCA class contains explained_variance_ratio_ which returns the variance caused by each of the principal components.\n- The explained_variance variable is now a float type array which contains variance ratios for each principal component.\n- We can see that first principal component is responsible for 43.33% variance and second principal component causes 36.16% variance in the dataset. Collectively we can say that (43.33 + 36.16)=79.49% percent of the classification information contained in the feature set is captured by the first two principal components, which is very less, so we will not go for pca because it will not give us a best accuracy and removing multicollinearity here in this case is not good.","2cc608ba":"K=20","10c84c82":"- This result shows that 'choosing language of movies has relation with the age'","0d5745de":"- IMDb Rating has higher number of missing value filling this value can be biased or misguide the model and also our interpretation.filling missing value by using mean or median could be cause of an outlier. and also  can affect the model badly i.e biasedness error could be high possibly.","8b9bd623":"### Statistical Tests","b30215e5":"- PCA is use to reduce the severe multicollinearity issue.Let's try either this method will give the best performance on this data or not.\n- PCA performs best with a normalized feature set. so we will perform standard scalar normalization to normalize our feature set.","25ed948b":"###### The year of release is positively distributed that is release is increased in amazon prime as the time goes i.e we can say that amazon prime has amazing growth with the time.","f1b6c268":"- This result shows that 'Significant difference among the groups means that the Year of movie release and number of seasons it is available and rating given by the viewers are all related with each other.'","55aba5e8":"**If you learnt something new Upvote the notebook**\n\n## Thank You","e44ae344":"### Analysis","b734b50c":"### Amazon Movie Prime Dataset","c27837b8":"### Data Visualization","f7991625":"### Data Preprocession and Cleaning","5a80d9e0":"### outlier treatment using knnimputer","654127b4":"#### English is the 1st language most prefered by the viewers and hindi is the 2nd language most prefered by the viewers","f8adb28d":"after imputing missing value we can see that there is a presence of an outlier in the rating,in data minimum rating is 3.7 and maximmu rating is 9.5 \\\nwhile Lower Whisker value is 6.625 and Upper whisker value is 8.345 which shows that  \\\n- Minimum value=3.7<<lower whisker=6.625, so there is a presence of lower outliers\n- Maximum value=9.5>>upper whisker=8.345, so there is a presence of upper outliers.\n\n-- let's visualize this by boxplot.","23dd7644":"#### KNN Imputer for imputing missing values in IMDB rating \n- As there are large number of missing values present in Imdb rating we can not fill this variable using mean,median or mode as this my cause the problem of biasedness in the data. So we are going to use Knn imputer.","ee4da306":"#### There is a very low or moderate positive and negative relationships between the variables which is somehow negligible. but we will test about this by using the concept of VIF."}}