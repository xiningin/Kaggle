{"cell_type":{"1ef4c1c7":"code","77dcba40":"code","6aca2a76":"code","4bc5b1fd":"code","36f1ad71":"code","bd08e998":"code","9499a949":"code","48903ae3":"code","1917fd71":"code","3b210834":"code","098395be":"code","ccbd8791":"code","9b8da89f":"code","e4369da7":"code","3e57b4ae":"code","de4bc6cd":"code","1a8d2ebe":"code","d5e3cf04":"code","9bc37f01":"code","6736011e":"code","2240dd94":"markdown","6ecb2fe5":"markdown","c16580be":"markdown","e08e5fba":"markdown"},"source":{"1ef4c1c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77dcba40":"from tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import GRU,SimpleRNN\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.preprocessing import sequence, text\nfrom keras.callbacks import EarlyStopping\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff","6aca2a76":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","4bc5b1fd":"#\u8b80\u53d6train,valid\u548ctest\u7684\u8cc7\u6599\ntrain = pd.read_csv('\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/jigsaw-toxic-comment-train.csv')\nvalidation = pd.read_csv('\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/validation.csv')\ntest = pd.read_csv('\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/test.csv')","36f1ad71":"validation.drop(['lang'],axis=1,inplace=True)","bd08e998":"validation","9499a949":"#\u5c07train\u4e2d\u4e0d\u5fc5\u8981\u7684\u6b04\u4f4ddrop\u6389\ntrain.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)","48903ae3":"#\u770b\u4e00\u4e0btrain\u7684\u6a23\u5b50\ntrain","1917fd71":"#\u53d625000\u7b46\u8cc7\u6599\u505a\u8a13\u7df4\u548c\u6e2c\u8a66\ntrain = train.loc[:19999,:]\ntrain.shape","3b210834":"train['comment_text'].apply(lambda x:len(str(x).split())).max()","098395be":"#AUC function,\u82e5AUC\u8d8a\u9ad8\uff0c\u8868\u793a\u6a21\u578b\u597d\ndef roc_auc(predictions,target):\n    '''\n    This methods returns the AUC Score when given the Predictions\n    and Labels\n    '''\n    \n    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n    roc_auc = metrics.auc(fpr, tpr)\n    return roc_auc","ccbd8791":"#\u53d6\u51fatrain\u548cvalid\u6240\u9700\u8cc7\u6599\nxtrain=train.comment_text.values\nytrain=train.toxic.values\nxvalid=validation.comment_text.values\nyvalid=validation.toxic.values\nxtest=test.content.values","9b8da89f":"# using keras tokenizer here\ntoken = text.Tokenizer(num_words=None)\nmax_len = 128 #\u53d6\u8a13\u7df4\u6587\u5b57\u6700\u5927\u9577\u5ea6128\n\ntoken.fit_on_texts(list(xtrain) ) #+ list(xvalid)+list(test)\nxtrain_seq = token.texts_to_sequences(xtrain)\nxvalid_seq = token.texts_to_sequences(xvalid)\nxtest_seq = token.texts_to_sequences(xtest)\n\n#zero pad the sequences\nxtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\nxvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\nxtest_pad = sequence.pad_sequences(xtest_seq, maxlen=max_len)\n\n\nword_index = token.word_index\nprint(xtrain_pad.shape,xvalid_pad.shape,xtest_pad.shape)","e4369da7":"#\u770b\u4e00\u4e0btrain\u505a\u5b8ctoken\u5f8c\u7684\u6a23\u5b50\nxvalid_seq[:1]","3e57b4ae":"# load the GloVe vectors in a dictionary:\n#\u4f7f\u7528Word Embedding\u4e2d\u7684GloVe\u5c07\u6587\u5b57\u8f49\u70ba\u5411\u91cf\nembeddings_index = {}\nf = open('\/kaggle\/input\/glove840b300dtxt\/glove.840B.300d.txt','r',encoding='utf-8')\nfor line in tqdm(f):\n    values = line.split(' ')\n    word = values[0]\n    coefs = np.asarray([float(val) for val in values[1:]])\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","de4bc6cd":"# create an embedding matrix for the words we have in the dataset\n#\u5c07\u6bcf\u4e00\u7b46\u8cc7\u6599\u8f49\u63db\u70ba300\u70ba\u7684\u5411\u91cf\nembedding_matrix = np.zeros((len(word_index) + 1, 300))\nfor word, i in tqdm(word_index.items()):\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","1a8d2ebe":"#GRU\u6a21\u578b\n%time\nwith strategy.scope():\n    # GRU with glove embeddings and two dense layers\n     model = Sequential()\n     model.add(Embedding(len(word_index) + 1,\n                     300,\n                     weights=[embedding_matrix],\n                     input_length=max_len,\n                     trainable=False))\n     model.add(SpatialDropout1D(0.3))\n     model.add(GRU(300,return_sequences=True))\n     model.add(Dropout(0.2))\n     model.add(GRU(300,return_sequences=False))\n     model.add(Dropout(0.3))\n     model.add(Dense(1, activation='sigmoid'))\n\n     model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n    \nmodel.summary()","d5e3cf04":"#GRU\u6a21\u578b\u8a13\u7df4\nmodel.fit(xtrain_pad, ytrain, nb_epoch=1, batch_size=64*strategy.num_replicas_in_sync)","9bc37f01":"#\u4f7f\u7528valid\u6e2c\u8a66\u8cc7\u6599\u7684AUC\u7d50\u679c\nscores = model.predict(xvalid_pad)\nprint(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))","6736011e":"sub = pd.read_csv(\"\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/sample_submission.csv\")\nsub['toxic'] = model.predict(xtest_pad, verbose=1)\nsub.to_csv('submission.csv', index=False)\nprint(\"finish\")","2240dd94":"# TPU","6ecb2fe5":"# GRU","c16580be":"# tokenizer","e08e5fba":"# Word Embeddings"}}