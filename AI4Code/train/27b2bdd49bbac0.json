{"cell_type":{"b4ebe032":"code","bb7edefe":"code","7b1aec3d":"code","db59b60c":"code","4b8b907a":"code","bcf5ba65":"code","ddbee231":"code","d72bd5d0":"code","6a814be3":"code","804df964":"code","f15608d8":"code","3854dd66":"code","fbea7fcd":"code","eff97bcf":"code","964d7e3a":"code","f2907fae":"code","c42954f4":"code","8da340e0":"code","85ebae54":"code","a256aa9b":"markdown","6222b759":"markdown","c8706bca":"markdown","7986e496":"markdown","b797a8bc":"markdown","265a6278":"markdown","94cb435b":"markdown","337d024c":"markdown","2d17c708":"markdown","d3645568":"markdown","ddc8b5bd":"markdown","f0e48fc3":"markdown"},"source":{"b4ebe032":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV","bb7edefe":"df = pd.read_csv('\/kaggle\/input\/housesalesprediction\/kc_house_data.csv')","7b1aec3d":"df.head()","db59b60c":"df.info()","4b8b907a":"df.describe()","bcf5ba65":"plt.figure(figsize=(10, 10))\ndf_corr = df.drop(['id', 'date', 'lat', 'long', 'zipcode'], axis=1)\ndf_corr = df_corr.corr()\nmask = np.triu(df_corr.corr())\nsns.heatmap(df_corr, annot=True, mask=mask, square=True, \n            fmt='.1g',  \n            vmin=-1, vmax=1, center= 0, cmap='coolwarm',\n            linewidths=3, linecolor='black',\n            cbar_kws= {'orientation': 'vertical'}) ","ddbee231":"list_ = []\nfor x in df['yr_renovated']:\n    if x!=0:\n        list_.append(1)\n    else:\n        list_.append(0)\ndf['renovated'] = list_","d72bd5d0":"figure = plt.figure()\naxes1 = figure.add_axes([0, 0, 1, 1]) \naxes2 = figure.add_axes([1.2, 0, 2.2, 1]) \naxes3 = figure.add_axes([0, -1.3, 1, 1]) \naxes4 = figure.add_axes([1.2, -1.3, 1, 1]) \naxes5 = figure.add_axes([2.4, -1.3, 1, 1]) \naxes6 = figure.add_axes([0, -2.6, 1, 1]) \naxes7 = figure.add_axes([1.2, -2.6, 1, 1]) \naxes8 = figure.add_axes([2.4, -2.6, 1, 1]) \naxes9 = figure.add_axes([0, -3.9, 1, 1]) \naxes10 = figure.add_axes([1.2, -3.9, 1, 1]) \naxes11 = figure.add_axes([2.4, -3.9, 1, 1])\naxes12 = figure.add_axes([0, -5.2, 2.2, 1]) \naxes13 = figure.add_axes([2.4, -5.2, 1, 1])\naxes14 = figure.add_axes([0, -6.5, 1.6, 1]) \naxes15 = figure.add_axes([1.8, -6.5, 1.6, 1]) \n\nsns.stripplot(x='bedrooms', y='price', data=df, palette='coolwarm', ax=axes1)\naxes1.set_title('Price depending of numbers of bedrooms', fontsize=17)\naxes1.set_xlabel('bedrooms', fontsize=14)\naxes1.set_ylabel('price', fontsize=14)\n\nsns.stripplot(x='bathrooms', y='price', data=df, palette='coolwarm', ax=axes2)\naxes2.set_title('Price depending of numbers of bathrooms', fontsize=17)\naxes2.set_xlabel('bathrooms', fontsize=14)\naxes2.set_ylabel('price', fontsize=14)\n\nsns.regplot(x='sqft_living', y='price', data=df, color='royalblue', ax=axes3, scatter_kws={'s' : 10}, line_kws={'color': 'crimson', 'lw': 5})\naxes3.set_title('Price depending of sqft_living', fontsize=17)\naxes3.set_xlabel('sqft_living', fontsize=14)\naxes3.set_ylabel('price', fontsize=14)\n\nsns.regplot(x='sqft_lot', y='price', data=df, color='royalblue', ax=axes4, scatter_kws={'s' : 10}, line_kws={'color': 'crimson', 'lw': 5})\naxes4.set_title('Price depending of sqft_lot', fontsize=17)\naxes4.set_xlabel('sqft_lot', fontsize=14)\naxes4.set_ylabel('price', fontsize=14)\n\nsns.stripplot(x='floors', y='price', data=df, palette='coolwarm', ax=axes5)\naxes5.set_title('Price depending of floors', fontsize=17)\naxes5.set_xlabel('floors', fontsize=14)\naxes5.set_ylabel('price', fontsize=14)\n\nsns.stripplot(x='waterfront', y='price', data=df, palette=['royalblue', 'crimson'], ax=axes6)\naxes6.set_title('Price depending of waterfront', fontsize=17)\naxes6.set_xlabel('waterfront', fontsize=14)\naxes6.set_ylabel('price', fontsize=14)\n\nsns.stripplot(x='view', y='price', data=df, palette='coolwarm', ax=axes7)\naxes7.set_title('Cost depending of view', fontsize=17)\naxes7.set_xlabel('view', fontsize=14)\naxes7.set_ylabel('price', fontsize=14)\n\nsns.stripplot(x='condition', y='price', data=df, palette='coolwarm', ax=axes8)\naxes8.set_title('Price depending of condition', fontsize=17)\naxes8.set_xlabel('condition', fontsize=14)\naxes8.set_ylabel('price', fontsize=14)\n\nsns.stripplot(x='grade', y='price', data=df, palette='coolwarm', ax=axes9)\naxes9.set_title('Price depending of grade', fontsize=17)\naxes9.set_xlabel('grade', fontsize=14)\naxes9.set_ylabel('price', fontsize=14)\n\nsns.regplot(x='sqft_above', y='price', data=df, color='royalblue', ax=axes10, scatter_kws={'s' : 10}, line_kws={'color': 'crimson', 'lw': 5})\naxes10.set_title('Price depending of sqft_above', fontsize=17)\naxes10.set_xlabel('sqft_above', fontsize=14)\naxes10.set_ylabel('price', fontsize=14)\n                         \nsns.regplot(x='sqft_basement', y='price', data=df, color='royalblue', ax=axes11, scatter_kws={'s' : 10}, line_kws={'color': 'crimson', 'lw': 5})\naxes11.set_title('Price depending of sqft_basement', fontsize=17)\naxes11.set_xlabel('sqft_basement', fontsize=14)\naxes11.set_ylabel('price', fontsize=14)\n\nsns.lineplot(x='yr_built', y='price', data=df, color='royalblue', ax=axes12, lw=5, marker='o', markerfacecolor='crimson')\naxes12.set_title('Price depending of yr_built', fontsize=17)\naxes12.set_xlabel('yr_built', fontsize=14)\naxes12.set_ylabel('price', fontsize=14)\n\nsns.stripplot(x='renovated', y='price', data=df, palette=['royalblue', 'crimson'], ax=axes13)\naxes13.set_title('Price depending of renovated', fontsize=17)\naxes13.set_xlabel('renovated', fontsize=14)\naxes13.set_ylabel('price', fontsize=14)\n\nsns.regplot(x='sqft_living15', y='price', data=df, color='royalblue', ax=axes14, scatter_kws={'s' : 10}, line_kws={'color': 'crimson', 'lw': 5})\naxes14.set_title('Price depending of sqft_living15', fontsize=17)\naxes14.set_xlabel('sqft_living15', fontsize=14)\naxes14.set_ylabel('price', fontsize=14)\n\nsns.regplot(x='sqft_lot15', y='price', data=df, color='royalblue', ax=axes15, scatter_kws={'s' : 10}, line_kws={'color': 'crimson', 'lw': 5})\naxes15.set_title('Price depending of sqft_lot15', fontsize=17)\naxes15.set_xlabel('sqft_lot15', fontsize=14)\naxes15.set_ylabel('price', fontsize=14)","6a814be3":"df['date'] = df['date'].replace('T000000', '', regex=True)\ndf['date'] = pd.to_datetime(df['date'])\ndf['year'] = df['date'].apply(lambda x: x.year)\ndf['month'] = df['date'].apply(lambda x: x.month)\ndf['weekday'] = df['date'].apply(lambda x: x.dayofweek)\nd = {0 : 'Monday', 1 : 'Tuesday', 2 : 'Wednesday', 3 : 'Thursday', 4 : 'Friday', 5 : 'Saturday', 6 : 'Sunday'}\ndf['weekday']=df['weekday'].map(d)","804df964":"df.head()","f15608d8":"df.info()","3854dd66":"figure = plt.figure()\naxes1 = figure.add_axes([0, 0, 1, 1])\naxes2 = figure.add_axes([1.2, 0, 1, 1])\naxes3 = figure.add_axes([2.4, 0, 1, 1])\n\nsns.stripplot(x='year', y='price', data=df, palette=['royalblue', 'crimson'], ax=axes1)\naxes1.set_title('Price depending of year', fontsize=17)\naxes1.set_xlabel('Year', fontsize=14)\naxes1.set_ylabel('Price', fontsize=14)\n\nsns.stripplot(x='month', y='price', data=df, palette='coolwarm', ax=axes2)\naxes2.set_title('Price depending of month', fontsize=17)\naxes2.set_xlabel('Month', fontsize=14)\naxes2.set_ylabel('Price', fontsize=14)\n\nsns.stripplot(x='weekday', y='price', data=df, palette='coolwarm', ax=axes3)\naxes3.set_title('Price depending of weekday', fontsize=17)\naxes3.set_xlabel('Weekday', fontsize=14)\naxes3.set_ylabel('Price', fontsize=14)","fbea7fcd":"df_pivot = df.pivot_table(index='weekday', columns='month', values='price')\ndf_group = df.groupby(['month', 'weekday'])['price'].count().reset_index() \ndf_pivot_count = df_group.pivot_table(index='weekday', columns='month', values='price')\n\nfigure = plt.figure()\naxes1 = figure.add_axes([0, 0, 1.6, 1.6]) \naxes2 = figure.add_axes([1.8, 0, 1.6, 1.6]) \n\n\nsns.heatmap(df_pivot, cmap='coolwarm', linecolor='white', linewidths=3, ax=axes1)\naxes1.set_title('Sales amount by weekdays and months', fontsize=17)\naxes1.set_xlabel('Month', fontsize=14)\naxes1.set_ylabel('Weekday', fontsize=14)\n\nsns.heatmap(df_pivot_count, cmap='coolwarm', linecolor='white', linewidths=3, ax=axes2)\naxes2.set_title('Number of sales by weekdays and months', fontsize=17)\naxes2.set_xlabel('Month', fontsize=14)\naxes2.set_ylabel('Weekday', fontsize=14)","eff97bcf":"df.columns","964d7e3a":"df.drop(['id', 'date', 'zipcode', 'lat', 'long', 'yr_renovated', 'year', 'month', 'weekday'], axis=1, inplace=True)\ndf.head()","f2907fae":"columns = list(df.columns)\nscaler = StandardScaler()\ndf_st = scaler.fit_transform(df)\ndf_st = pd.DataFrame(data=df_st, columns=columns)","c42954f4":"x = df_st.drop(['price'], axis=1)\ny = df_st['price']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\npoly = PolynomialFeatures(degree=2)\nx_train_poly = poly.fit_transform(x_train)\nx_test_poly = poly.fit_transform(x_test)","8da340e0":"# linear\nparams1 = {}\nlinear = GridSearchCV(LinearRegression(), params1, cv=5)\nlinear.fit(x_train, y_train)\ny_predict_linear = linear.predict(x_test)\nr_sq_linear = linear.score(x_test, y_test)\n\n# poly\npoly = GridSearchCV(LinearRegression(), params1, cv=5)\npoly.fit(x_train_poly, y_train)\ny_predict_poly = poly.predict(x_test_poly)\nr_sq_poly = poly.score(x_test_poly, y_test)\n\n# ridge\nparams2 = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100]}\nridge = GridSearchCV(Ridge(), params2, cv=5)\nridge.fit(x_train_poly, y_train)\ny_predict_ridge = ridge.predict(x_test_poly)\nr_sq_ridge = ridge.score(x_test_poly, y_test)\n\n# lasso\nparams2 = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100]}\nlasso = GridSearchCV(Lasso(), params2, cv=5)\nlasso.fit(x_train_poly, y_train)\ny_predict_lasso = lasso.predict(x_test_poly)\nr_sq_lasso = lasso.score(x_test_poly, y_test)\n\n# elastic\nparams3 = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100], 'l1_ratio':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\nelastic = GridSearchCV(ElasticNet(), params3, cv=5)\nelastic.fit(x_train_poly, y_train)\ny_predict_elastic = elastic.predict(x_test_poly)\nr_sq_elastic = elastic.score(x_test_poly, y_test)\n\n# knn\nparams4 = {'n_neighbors': list(range(3, 10, 2)),'weights':['uniform', 'distance'],\n          'metric':['euclidean', 'manhattan', 'chebyshev', 'minkowski']}\nknn = GridSearchCV(KNeighborsRegressor(), params4, cv=5)\nknn.fit(x_train, y_train)\ny_predict_knn = knn.predict(x_test)\nr_sq_knn = knn.score(x_test, y_test)\n\n# rf\nparams5 = {'criterion' : ['mse', 'mae'],'n_estimators': list(range(5, 10, 15)), 'min_samples_leaf': [5, 3]}\nrf = GridSearchCV(RandomForestRegressor(), params5, cv=5)\nrf.fit(x_train, y_train)\ny_predict_rf = rf.predict(x_test)\nr_sq_rf = rf.score(x_test, y_test)","85ebae54":"models = ['Linear', 'Poly', 'Ridge', 'Lasso', 'Elastic', 'KNN', 'RandomForest']\nr_sq = [r_sq_linear, r_sq_poly, r_sq_ridge, r_sq_lasso, r_sq_elastic, r_sq_knn, r_sq_rf]\nr_sq_table = pd.DataFrame({'Model':models, 'r^2':r_sq})\nr_sq_table.sort_values(by='r^2', axis=0, ascending=False)","a256aa9b":"**As the most part of the 'yr_renovated' values are 0s, we will perform the conversion, making a column that will reflect whether the repair was carried out or not.**","6222b759":"# Preparing","c8706bca":"* bedrooms - up to 5 bedrooms, we observe a proportional increase in the number of bedrooms and the cost. After 5, with the presence of some outliers, we can see the opposite situation ;\n* bathrooms - there is a proportional increase in bathrooms and cost. But after 5 bathrooms, the number of observations is too small, so it is difficult to draw a conclusion;\n* sqft_living - proportional increase in living space and cost;\n* sqft_lot - it is difficult to make an unambiguous conclusion, for some observations, with an increase in the area, the cost also increases, but at the same time a significant part of the observations shows the opposite situation. We can conclude about a bimodal data distribution;\n* floors - no obvious dependence of the cost on the number of floors is observed;\n* waterfront - any dependence of the cost on the presence of a view of the embankment on the watch. We can only conclude that most of the houses do not have a view of the embankment;\n* view - no clear dependence is observed;\n* condition - up to 3, there is a proportional increase in value, but after 3 there are no obvious changes;\n* grade - a proportional increase in quality and cost;\n* sqft_above - there is a proportional increase in area and value;\n* sqft_basement - there is a proportional increase in area and value;\n* yr_built - the cost of houses built during the Second World War is the least. At the same time, the highest cost is for houses built in 1905, 1934, 2001 and 2014.\n* renovated - I do not observe the dependence of the cost on the availability of repairs.\n* sqft_living15 is the same situation as with the sqft_living.\n* sqft_lot15 is a similar situation as with the sqft_lot15.","7986e496":"**I do not observe any obvious dependence, except that houses with a lower cost were sold over the weekend.**\n\n**Let's look at this data from a different angle, correlate the month and day of the week using pivot tables and visualize it.**","b797a8bc":"**Before that, the date column was not affected by me. I want to consider this data separately, but for this you need to perform the following transformations:**","265a6278":"* There is no relationship between price and the ratio of the month to the day of the week;\n* However, we can observe that the least number of houses were sold during the weekend. Also, the smallest number of houses were sold in the first and last 2 months.\n\n**The decrease in the number of sales in the first and last 2 months is associated with the period: 05.2014 - 05.2015. There is no need to comment on the decrease in the number of sales on weekends:)**","94cb435b":"# Results","337d024c":"**Let's try to find the relationship between year, month, day of the week and cost.**","2d17c708":"# EDA","d3645568":"**To wacth the corelation between variables,lets make a matrix:**","ddc8b5bd":"**From the presented data, it can be seen that Elastic has the best result.**","f0e48fc3":"**The highest correlation between the target and the independent variables:**\n\n* sqft_living;\n* sqft_above;\n* grade;\n* sqft_living15."}}