{"cell_type":{"53c15937":"code","73312036":"code","51c6bfa9":"code","9dd6ff2c":"code","d88de473":"code","0327fbd1":"markdown","05b228f9":"markdown","dfb0a6dc":"markdown"},"source":{"53c15937":"#!\/usr\/bin\/python\n# -*- coding: utf-8 -*-\n\nimport pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math as math\nimport time\nplt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = [14, 14]\n\ndf = pd.read_csv('..\/input\/disney-movies-and-tv-shows\/disney_plus_titles.csv')\n\ndf['date_added'] = pd.to_datetime(df['date_added'])\ndf['year'] = df['date_added'].dt.year\ndf['month'] = df['date_added'].dt.month\ndf['day'] = df['date_added'].dt.day\n\ndf['directors'] = df['director'].apply(lambda l: \\\n        ([] if pd.isna(l) else [i.strip() for i in l.split(',')]))\ndf['categories'] = df['listed_in'].apply(lambda l: \\\n        ([] if pd.isna(l) else [i.strip() for i in l.split(',')]))\ndf['actors'] = df['cast'].apply(lambda l: \\\n                                ([] if pd.isna(l) else [i.strip()\n                                for i in l.split(',')]))\ndf['countries'] = df['country'].apply(lambda l: \\\n        ([] if pd.isna(l) else [i.strip() for i in l.split(',')]))\n\ndf.head()\n","73312036":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom sklearn.cluster import MiniBatchKMeans\n\nstart_time = time.time()\ntext_content = df['description']\nvector = TfidfVectorizer(\n    max_df=0.4,\n    min_df=1,\n    stop_words='english',\n    lowercase=True,\n    use_idf=True,\n    norm=u'l2',\n    smooth_idf=True,\n    )\ntfidf = vector.fit_transform(text_content)\n\ndef find_similar(tfidf_matrix, index, top_n=5):\n    cosine_similarities = linear_kernel(tfidf_matrix[index:index + 1],\n            tfidf_matrix).flatten()\n    related_docs_indices = [i for i in cosine_similarities.argsort()[::\n                            -1] if i != index]\n    return [index for index in related_docs_indices][0:top_n]","51c6bfa9":"G = nx.Graph(label='MOVIE')\nstart_time = time.time()\nfor (i, rowi) in df.iterrows():\n    G.add_node(rowi['title'], key=rowi['show_id'], label='MOVIE',\n               mtype=rowi['type'], rating=rowi['rating'])\n    for element in rowi['actors']:\n        G.add_node(element, label='PERSON')\n        G.add_edge(rowi['title'], element, label='ACTED_IN')\n    for element in rowi['categories']:\n        G.add_node(element, label='CAT')\n        G.add_edge(rowi['title'], element, label='CAT_IN')\n    for element in rowi['directors']:\n        G.add_node(element, label='PERSON')\n        G.add_edge(rowi['title'], element, label='DIRECTED')\n    for element in rowi['countries']:\n        G.add_node(element, label='COU')\n        G.add_edge(rowi['title'], element, label='COU_IN')\n\n    indices = find_similar(tfidf, i, top_n=5)\n    snode = 'Sim(' + (rowi['title'])[:15].strip() + ')'\n    G.add_node(snode, label='SIMILAR')\n    G.add_edge(rowi['title'], snode, label='SIMILARITY')\n    for element in indices:\n        G.add_edge(snode, df['title'].loc[element], label='SIMILARITY')\n\n\ndef get_all_adj_nodes(list_in):\n    sub_graph = set()\n    for m in list_in:\n        sub_graph.add(m)\n        for e in G.neighbors(m):\n            sub_graph.add(e)\n    return list(sub_graph)\n\n\ndef draw_sub_graph(sub_graph, size='s'):\n    subgraph = G.subgraph(sub_graph)\n    colors = []\n    for e in subgraph.nodes():\n        if G.nodes[e]['label'] == 'MOVIE':\n            colors.append('#96cdeb')\n        elif G.nodes[e]['label'] == 'PERSON':\n            colors.append('#ed859d')\n        elif G.nodes[e]['label'] == 'CAT':\n            colors.append('#9ce087')\n        elif G.nodes[e]['label'] == 'COU':\n            colors.append('#edf283')\n        elif G.nodes[e]['label'] == 'SIMILAR':\n            colors.append('#edb672')\n        elif G.nodes[e]['label'] == 'CLUSTER':\n            colors.append('#edb672')\n\n    if size == 's':\n        plt.figure(figsize=(8, 8))\n    else:\n        plt.figure(figsize=(15, 15))\n    nx.draw(subgraph, with_labels=True, font_size=12,\n            node_color=colors, edge_color='#c4c2be')\n    plt.show()\n\n\ndef get_recommendation(root):\n    commons_dict = {}\n    for e in G.neighbors(root):\n        for e2 in G.neighbors(e):\n            if e2 == root:\n                continue\n            if G.nodes[e2]['label'] == 'MOVIE':\n                commons = commons_dict.get(e2)\n                if commons == None:\n                    commons_dict.update({e2: [e]})\n                else:\n                    commons.append(e)\n                    commons_dict.update({e2: commons})\n    movies = []\n    weight = []\n    for (key, values) in commons_dict.items():\n        w = 0.0\n        for e in values:\n            w = w + 1 \/ math.log(G.degree(e))\n        movies.append(key)\n        weight.append(w)\n\n    result = pd.Series(data=np.array(weight), index=movies)\n    result.sort_values(inplace=True, ascending=False)\n    return result\n\ndef recommend(input_movie):\n    print(\"*\"*40+\"\\n\\n Movie: \"+input_movie+\"\\n\\n\"+\"*\"*40)\n\n    list_in = [input_movie]\n    sub_graph = get_all_adj_nodes(list_in)\n    draw_sub_graph(sub_graph)\n\n    result = get_recommendation(input_movie)\n    print(result.head())\n\n    print (\"\\n\")\n    print(\"*\"*100+\"\\n\\n Extended Recommendation with Attributes\")\n    # print (\"\\n\")\n    print(\"*\"*100)\n\n    reco=list(result.index[:4].values)\n    reco.extend([input_movie])\n    sub_graph = get_all_adj_nodes(reco)\n    draw_sub_graph(sub_graph, size='w')","9dd6ff2c":"recommend(\"Marvel Studios' Iron Man 2\")","d88de473":"recommend(\"X-Men Origins: Wolverine\")","0327fbd1":"Create the graph using networkx","05b228f9":"## Disney+ Recommendation Engine with Graphs \n\nThis notebook is inspired from the work done by @yclaudel. @yclaudel shared a very nice notebook on the Netflix Movies and TV Shows data some time back. In this notebook, I have replicated his approach on the Disney+ dataset to generate recommendations for Disney+ content.\n\nOriginal Source: https:\/\/www.kaggle.com\/yclaudel\/recommendation-engine-with-networkx\/notebook\n\n**Brief Summary of the approach:**  \n\n1. Connect different tv shows \/ movies on Disney+ using a graph where each node represents a movie or a tv show. From the graph, measure the Adamic Adar Measure: higher this score for a node pair, closest the nodes are. The measures between all movies are NOT pre-calculated, in order to determine the list of recommendation films, we are going to explore the neighborhood of the target film\n2. In order to take in account the description, calculate the TF-IDF matrix and for each film, take the top 5 of similar descriptions and create a node Similar_to_this. This node will be taken in account in the Adamic Adar measure.\n3. In the graph, Nodes are : Movies, Person ( actor or director), Categories, Countries, Cluster (description), Sim(title) top 5 similar movies in the sense of the description\n4. Edges are : ACTED_IN : relation between an actor and a movie, CAT_IN : relation between a categrie and a movie, DIRECTED : relation between a director and a movie, COU_IN : relation between a country and a movie, DESCRIPTION : relation between a cluster and a movie, SIMILARITY in the sense of the description. so, two movies are not directly connected, but they share persons, categories,clusters and countries. \n5. To generate the recommendations, explore the neighborhood of the target film, this is a list of actor, director, country, categories. Explore the neighborhood of each neighbor \u2192 discover the movies that share a node with the target field. Calculate Adamic Adar measure to give the final results.\n\nLet's look at the dataset: ","dfb0a6dc":"As the next step, build the tfidf matrix with the descriptions and find similar - get the top_n movies with description similar to the target description. This is followed by creation of Graph using the approach described above. \n"}}