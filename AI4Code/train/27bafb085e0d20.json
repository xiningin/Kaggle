{"cell_type":{"ca182801":"code","0afec6ec":"code","0967cd30":"code","917b67ec":"code","97878d79":"code","020a6167":"code","0eed1689":"code","e5858e16":"code","f735a7b1":"code","b2ef30c5":"code","694b487b":"code","a5ba1437":"code","e49c2081":"code","d43237d9":"markdown","3088451c":"markdown","74450ceb":"markdown","e2b5b6a7":"markdown","e33f22f3":"markdown","f5d49225":"markdown","4f86e1ea":"markdown","cbd0f353":"markdown","ac506388":"markdown","aaa444c8":"markdown","a3467529":"markdown"},"source":{"ca182801":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.pipeline import make_pipeline","0afec6ec":"SEED = 42\nfrom tensorflow.random import set_seed\nfrom numpy.random import seed\nseed(SEED)\nset_seed(SEED)","0967cd30":"df = pd.read_csv('..\/input\/mines-vs-rocks\/sonar.all-data.csv', header = None)\ndf = df.values\nX = df[:,0:60].astype(float)\nY = df[:,60]\nprint ('X Shape :', X.shape)\nprint ('Y Shape :', Y.shape)\nprint ('Number of Unique Values in Y:', set(Y))","917b67ec":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nY_encoded = encoder.fit_transform(Y).astype(int)\nprint ('Shape of Y_encoded :', len(Y_encoded))\nprint ('Unique values in Y_encoded :', list(set(Y_encoded)))\nprint ('Inverse transforming : ', encoder.inverse_transform(list(set(Y_encoded))))","97878d79":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nX_transformed = ss.fit_transform(X)\nX_transformed.shape","020a6167":"def baseline_model():\n    \n    model = Sequential()\n    model.add(Dense(60, input_dim=(60), activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    \n    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n    \n    return model","0eed1689":"single_model = baseline_model()\n%time history = single_model.fit(X_transformed, Y_encoded, epochs = 200, batch_size = 8, verbose = 0, validation_split = 0.1)","e5858e16":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.show()","f735a7b1":"from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler","b2ef30c5":"EPOCHS     = 50\nBATCH_SIZE = 8\nVERBOSE    = 0\nFOLDS      = 10","694b487b":"kfold = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\nestimators = make_pipeline(StandardScaler(), KerasClassifier(build_fn = baseline_model, epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = VERBOSE))\nresults = cross_val_score(estimators, X, Y_encoded, cv = kfold)\nprint (f'Mean Accuracy : {round(results.mean()*100,2)} %, Std. dev : {round(results.std()*100,2)}%')","a5ba1437":"%%time \ndef small_model():\n    model = Sequential()\n    model.add(Dense(30, input_dim=(60), activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n    return model\n\nkfold = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\nestimators = make_pipeline(StandardScaler(), KerasClassifier(build_fn = small_model, epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = VERBOSE))\nresults = cross_val_score(estimators, X, Y_encoded, cv = kfold)\nprint (f'Mean Accuracy : {round(results.mean()*100,2)} %, Std. dev : {round(results.std()*100,2)}%')","e49c2081":"%%time \ndef large_model():\n    model = Sequential()\n    model.add(Dense(60, input_dim=(60), activation = 'relu'))\n    model.add(Dense(60, activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n    return model\n\nkfold = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\nestimators = make_pipeline(StandardScaler(), KerasClassifier(build_fn = large_model, epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = VERBOSE))\nresults = cross_val_score(estimators, X, Y_encoded, cv = kfold)\nprint (f'Mean Accuracy : {round(results.mean()*100,2)} %, Std. dev : {round(results.std()*100,2)}%')","d43237d9":"We got an equally good model with a smaller network","3088451c":"### Loading the dataset ","74450ceb":"### Building a single model","e2b5b6a7":"### Evaluating a larger network\n\nEvaluating a larger Network - A neural network topology with more layers offers more opportunity for the network to extract key features and combined them in useful non-linear ways","e33f22f3":"### Prepping Y","f5d49225":"# Predicting Mines or Rocks with Keras and TensorFlow\n\nUsing Keras library with TensorFlow backend, three Multilayer perceptron models were built and evaluated using KFold cross validation.\n```\n1. Model 1 - Input (60) - Hidden (60) - Output (1)\n2. Model 2 - Input (60) - Hidden (30) - Output (1)\n3. Model 3 - Input (60) - Hidden (60) - Hidden (60) - Output (1)\n```\n\nWhile training and evaluating models, standardization is being learned on each fold and applied to the validation fold. This is achieved using `StandardScaler()` function of `sklearn.preprocessing` and passing it to the sklearn's `make_pipeline` method","4f86e1ea":"### Trying out a small network\nReducing the number of hidden layer dimensions after the input dimension to 30 from 60 will put pressure on the network get the most important structure of the data.","cbd0f353":"### Prepping X","ac506388":"### Evaluating Model using K-Fold Crossvalidation","aaa444c8":"The accuracy improved with increased hidden layer ","a3467529":"### Importing Libraries"}}