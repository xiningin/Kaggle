{"cell_type":{"5d6f24f2":"code","8318af40":"code","67e7d181":"code","362ffb1e":"code","393ca35e":"code","85ee1242":"code","221a9d79":"code","9800c640":"code","a326db0c":"code","3f9acbf2":"code","7bd7cdba":"code","a288ed73":"code","54743ac4":"code","fc700a9a":"code","3ba79c52":"code","90e6115d":"code","13d80d4d":"code","114fc501":"code","35d55911":"code","7346bfa2":"code","435e18d8":"code","f6651b23":"code","7114d1e5":"code","1aa6f90d":"code","6c1e294d":"code","2265ccdf":"code","e79ce471":"code","9035d2ae":"code","2dba6262":"code","b8588e31":"code","ebc48309":"code","fe0bc18f":"code","daf65539":"code","fbb3f159":"code","7d949787":"code","b2941c6b":"code","06673c65":"code","fcd15541":"code","35d5e369":"code","ef5c9c6e":"markdown","6d3fbc92":"markdown","22921240":"markdown","0e9700b6":"markdown","eb61db73":"markdown","45681b7d":"markdown","ccc2f0f2":"markdown"},"source":{"5d6f24f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8318af40":"\n\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport string\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nfrom sklearn import metrics","67e7d181":"train_data = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/test.csv\")","362ffb1e":"print(train_data.shape)\nprint(test_data.shape)\n\nprint('Features : ', train_data.columns.values)\nprint('Features : ', test_data.columns.values)\ntrain_data.head()","393ca35e":"train_data.info()","85ee1242":"train_data.isnull().sum()","221a9d79":"test_data.isnull().sum()","9800c640":"train_data.nunique()","a326db0c":"train_data[\"Response\"].value_counts(normalize= True)","3f9acbf2":"import seaborn as sns\n\nsns.countplot(train_data[\"Response\"])","7bd7cdba":"sns.countplot(x ='Gender', hue='Response',data = train_data)","a288ed73":"sns.countplot(x=\"Gender\", data = train_data)","54743ac4":"sns.countplot(x=\"Driving_License\", data = train_data)","fc700a9a":"sns.countplot(x=\"Previously_Insured\", data = train_data)","3ba79c52":"sns.distplot(train_data.Age)","90e6115d":"sns.countplot(x=\"Vehicle_Damage\", data = train_data)","13d80d4d":"sns.countplot(x=\"Vehicle_Age\", data = train_data)","114fc501":"sns.countplot(x=\"Response\", data = train_data)","35d55911":"\ntrain = train_data.copy()\ntest = test_data.copy()","7346bfa2":"def preprocessing(data):\n    \n    #Dropping null values\n    data = data.dropna()\n    \n    #Dropping id\n    data = data.drop('id', axis = 1)\n    \n    #Columns to get dummies\n    cols = ['Gender', 'Vehicle_Damage', 'Vehicle_Age']\n    \n    #Changing categories into dummies\n    data_dum = pd.get_dummies(data = data , columns = cols, drop_first = True )\n    \n    #We don't need this column as it has almost no correlation with our dependent variable\n    data_dum = data_dum.drop('Vintage', axis = 1)\n    \n    return data_dum","435e18d8":"#Preprocessing training data\ntrain_dum = preprocessing(train)\n\n#Preprocessing test data\ntest_dum = preprocessing(test)\n","f6651b23":"x_test.info()","7114d1e5":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits = 10, random_state = 42)\n\nfor train_idx, val_idx in skf.split(inputs, targets):\n    x_train, x_val = inputs.iloc[train_idx], inputs.iloc[val_idx]\n    y_train, y_val = targets.iloc[train_idx], targets.iloc[val_idx]","1aa6f90d":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nx_train_scaled = scaler.fit_transform(x_train)\nx_val_scaled = scaler.transform(x_val)\nx_test_scaled = scaler.transform(x_test)","6c1e294d":"Results = pd.DataFrame(columns = ['Model', 'Validation Score'])","2265ccdf":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth=7, n_estimators = 500)\n\nrf.fit(x_train_scaled,y_train)\n\ny_val_pred = rf.predict_proba(x_val_scaled)[:,1]\n\nscore = roc_auc_score(y_val, y_val_pred)\nprint(score)","e79ce471":"\nResults = Results.append({'Model' : 'Random Forest', 'Validation Score': score}, ignore_index = True)","9035d2ae":"from xgboost import XGBClassifier\n\nxg = XGBClassifier(random_state = 42, learning_rate = 0.1)\n\nxg.fit(x_train_scaled, y_train)\n\ny_val_pred = xg.predict_proba(x_val_scaled)[:,1]\n\nscore = roc_auc_score(y_val, y_val_pred)\nprint(score)","2dba6262":"Results = Results.append({'Model' : 'XGBoost', 'Validation Score': score}, ignore_index = True)","b8588e31":"CatBoost","ebc48309":"from catboost import CatBoostClassifier\n\ncat = CatBoostClassifier()\n\ncat.fit(x_train_scaled, y_train, plot=True, early_stopping_rounds=30, verbose=100)\n\ny_val_pred = cat.predict_proba(x_val_scaled)[:,1]\n\nscore = roc_auc_score(y_val, y_val_pred)\nprint(score)","fe0bc18f":"Results = Results.append({'Model' : 'CatBoost', 'Validation Score': score}, ignore_index = True)","daf65539":"\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\nlgbm = LGBMClassifier(num_leaves = 30, max_depth = 5, n_estimators = 550, learning_rate = 0.05, objective = 'binary', \n                      lambda_l2 = 12,\n                      max_bin = 100, metric = 'auc', is_unbalance = True, random_state = None, n_jobs = -1)\n\nlgbm.fit(x_train_scaled,y_train)\n\ny_val_pred = lgbm.predict_proba(x_val_scaled)[:,1]\n\nscore = roc_auc_score(y_val, y_val_pred)\nprint(score)","fbb3f159":"Results = Results.append({'Model' : 'LGBM', 'Validation Score': score}, ignore_index = True)","7d949787":"Results","b2941c6b":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('whitegrid')","06673c65":"plt.figure(figsize = (10,6))\nsns.barplot(data = Results, y = 'Validation Score', x = 'Model')\nplt.ylim(0.84,0.86)\nplt.show()","fcd15541":"y_pred = lgbm.predict_proba(x_test_scaled)[:,1]","35d5e369":"Response = pd.DataFrame({'id': test.id, 'Response': y_pred})\nprint(Response)\n","ef5c9c6e":"Random forest","6d3fbc92":"# **Exploratory Data Analysis**","22921240":"XGBoost","0e9700b6":"# **Modelling**","eb61db73":"LGBMClassifier","45681b7d":"# DATA PREPROCESSING","ccc2f0f2":"# **Splitting data(Imbalanced data)**"}}