{"cell_type":{"37abd049":"code","059f8ba3":"code","a7a65f75":"code","fa6dded8":"code","27b04498":"code","cbc678de":"code","3a58f301":"markdown","6d12d93e":"markdown","cf73ed89":"markdown","3cf0283d":"markdown"},"source":{"37abd049":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom joblib import Parallel, delayed\nimport pickle\nfrom IPython.display import display","059f8ba3":"# Training data: extract targets to know the discrete values\ntrain_df = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntargets = train_df[['pressure']].to_numpy()\n\n# Find pressure sensor minimum and step\np_values = np.sort(np.unique(targets))\np_min = p_values[0]\np_step = p_values[1] - p_values[0]\n\n# Create 2d array uu from test data\ntest_df = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nrelevant = test_df[['u_out']].to_numpy() == 0\nuu = test_df[['u_in']].to_numpy().reshape(-1, 80)\nrr = relevant.reshape(-1, 80)\nt = test_df['time_step'].values.reshape(-1, 80)\ndt_ = t[:,1:] - t[:,:-1] # Only 79 columns - there is no dt for the final step\n\n# Sort the 950 pressure values by frequency in the first time step so that the search is fast\n# We only look for values <= 16\ntemp_df = pd.DataFrame(targets.reshape(-1, 80)[:,1], columns=['pressure'])\ntemp_df = temp_df.groupby('pressure').size().sort_values(ascending=False)\np_values_by_frequency = list(temp_df.index) + sorted(list(set(p_values[p_values <= 16]).difference(temp_df.index)))\nlen(p_values_by_frequency)\n","a7a65f75":"%%time\n# Find and optionally update all experiments which use a PI controller\n\n\ndef is_integer(discrete):\n    \"\"\"Test if discrete is an integer.\n    \n    The function can be called with a scalar or an array.\n    \"\"\"\n    tol = 1e-10 # must be small enough so that with millions of\n                # calls we don't get false positives\n    return (abs(discrete - np.round(discrete)) < tol)\n    \ndef find_pi_control(row, uu, rr, dt_, preds, pi_list, pp=None, update_preds=False):\n    \"\"\"Test if row has been generated by a perfect PI controller\n    \n    Parameters\n    ----------\n    row          : The row to be processed\n    uu           : 2d array of u_in\n    rr           : 2d array of (u_out == 0)\n    dt_          : 2d array of time differences\n    preds        : 2d array of predictions; will be updated if update_preds is True\n    pi_list      : list, the found parameters will be appended to this list\n    pp           : 2d array of true pressures for evaluation, optional\n    update_preds : bool, default False, controls if preds is updated\n    \n    Global variables\n    ----------------\n    count, count_bad, mae_gain : updated with evaluation results if pp is not None\n    updated                    : count of updated rows\n    \"\"\"\n    # Verify parameters and copy a slice [start:end] of the selected row into u, oof, p and dt\n    if uu.shape != preds.shape: raise ValueError(f\"Shapes of uu and preds must be equal: {uu.shape} {preds.shape}\")\n    if rr.shape != preds.shape: raise ValueError(f\"Shapes of rr and preds must be equal: {rr.shape} {preds.shape}\")\n    if dt_.shape[0] != preds.shape[0]: raise ValueError(f\"First dimension of dt_ and preds must be equal: {dt_.shape} {preds.shape}\")\n    global count, count_bad, ae_gain, updated\n    start, end = 1, rr[row].sum()\n    p_values_to_try = p_values_by_frequency\n    while start < end and (uu[row, start] == 0 or uu[row, start] == 100):\n        p_values_to_try = p_values\n        start += 1\n    if start == end: return # all u_in are 0 or 100\n    u = uu[row, rr[row]][start:]\n    oof = preds[row, rr[row]][start:]\n    if pp is not None: p = pp[row, rr[row]][start:]\n    dt = dt_[row, rr[row, 1:]][start:] # typically 1\/30\n    T = 0.5\n    \n    def find_pi_coefficients(u, dt, p_values_to_try):\n        # u has at least three elements, dt has at least two\n        # Determine p_0, p_coef, i_coef and p_star for the start of the slice by grid-search\n        # The possible p_0 are searched in order of descending frequency\n        # Determine q_0, p_1, q_1, p_2\n        # Accept the solution only if p_1 and p_2 are discrete p values\n        while len(u) >= 3 and (u[0] == 0 or u[0] == 100 or u[1] == 0 or u[1] == 100 or u[2] == 0 or u[2] == 100):\n            u = u[1:]\n        if len(u) < 3: return None, None, None, None, None\n        p_stars = np.array([10, 15, 20, 25, 30, 35])\n        found = False\n        s0 = dt[0] \/ (dt[0] + T)\n        s1 = dt[1] \/ (dt[1] + T)\n        for p_0 in p_values_to_try:\n            for p_coef in [0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n                for i_coef in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n                    if p_coef == 0 and i_coef == 0: continue\n                    # u[0] = p_coef * (p_star - p_0) + i_coef * q_0\n                    # dt[0] = t[1] - t[0]\n                    # s0 = dt[0] \/ (dt[0] + T)\n                    # q_1 = (1-s0) * q_0 + s0 * (p_star - p_1)\n                    # u[1] = p_coef * (p_star - p_1) + i_coef * q_1\n                    q_0 = (u[0] + p_coef * (p_0 - p_stars)) \/ i_coef\n                    pis = p_coef + i_coef * s0 # positive\n                    p_1 = (pis * p_stars + i_coef * (1-s0) * q_0 - u[1]) \/ pis # array of several possible p_1\n                    ii = is_integer((p_1 - p_min) \/ p_step)\n                    if not ii.any(): continue\n                    if ii.sum() > 1: print(\"More than one ***********\")\n                    p_star = p_stars[ii.argmax()]\n                    p_1 = p_1[ii.argmax()] # scalar p_1\n                    q_1 = (1-s0) * q_0[ii.argmax()] + s0 * (p_star - p_1) # scalar q_1\n                    pis = p_coef + i_coef * s1 # positive\n                    p_2 = (pis * p_star + i_coef * (1-s1) * q_1 - u[2]) \/ pis # scalar p_2\n                    if not is_integer((p_2 - p_min) \/ p_step): continue\n                    if np.abs(p_1 - p_2) < 1e-10: print('p_1 == p_2', p_0, p_1, p_2, p_coef, i_coef, p_star); return None, None, None, None, None\n                    found = True\n                    break\n                if found: break\n            if found: break\n        if not found: return None, None, None, None, None\n        return p_0, p_coef, i_coef, p_star, q_0[ii.argmax()]\n    \n    # Try to determine the coefficients twice: once at the beginning of the inhalation phase and once towards the end\n    p_0, p_coef, i_coef, p_star, q = find_pi_coefficients(u, dt, p_values_to_try)\n    q_is_valid = p_0 is not None\n    if p_0 is None:\n        p_0, p_coef, i_coef, p_star, q = find_pi_coefficients(u[-9:], dt[-8:], p_values) # last three elements of u; dt is one element shorter\n        q_is_valid = False\n        if p_0 is None: return\n\n    # At this point we have found parameters p_0, p_coef, i_coef and p_star which give discrete\n    # values for the first three time steps, and we may have q_0\n\n    # Compute the new predictions\n    update_list = [] # for plotting\n    pred_new = oof.copy()\n    if q_is_valid and p_coef != 0:\n        last_valid, last_delta = 0, p_0 - pred_new[0]\n        pred_new[0] = p_0\n        update_list.append((start, p_0))\n    for i in range(1, len(pred_new)):\n        # Invariant: pred_new[:i] has been computed\n        # Invariant: q is the state of the PI controller or not q_is_valid\n        # We want to determine pred_new[i]\n        if u[i] == 0 or u[i] == 100: \n            q_is_valid = False # u has been clipped; we cannot compute p here\n            continue\n        if q_is_valid:\n            s = dt[i-1] \/ (dt[i-1] + T) # ca. 1\/16\n            pis = p_coef + i_coef * s # positive\n            pni = (pis * p_star + i_coef * (1-s) * q - u[i]) \/ pis # candidate pred_new[i]\n            if is_integer((pni - p_min) \/ p_step):\n                last_valid, last_delta = i, pni - pred_new[i]\n                pred_new[i] = pni\n                update_list.append((start+i, pni))\n                q = (u[i] + p_coef * (pred_new[i] - p_star)) \/ i_coef\n            else:\n                #print(f\"Out of sync {start + i}\")\n                q_is_valid = False\n        else:\n            # Try to resynchronize the controller state after a phase which didn't use the PI controller\n            if i >= len(pred_new) - 2: break # we cannot resynchronize the last two\n            if u[i+1] == 0 or u[i+1] == 100 or u[i+2] == 0 or u[i+2] == 100: continue\n            s_i = dt[i] \/ (dt[i] + T)\n            s_i1 = dt[i+1] \/ (dt[i+1] + T)\n            pis = p_coef + i_coef * s_i # positive\n            for p_i in p_values:\n                q_i = (u[i] + p_coef * (p_i - p_star)) \/ i_coef\n                p_i1 = (pis * p_star + i_coef * (1-s_i) * q_i - u[i+1]) \/ pis\n                if not is_integer((p_i1 - p_min) \/ p_step): continue\n                q_i1 = (1-s_i) * q_i + s_i * (p_star - p_i1)\n                pis = p_coef + i_coef * s_i1\n                p_i2 = (pis * p_star + i_coef * (1-s_i1) * q_i1 - u[i+2]) \/ pis\n                if not is_integer((p_i2 - p_min) \/ p_step): continue\n                #print(f\"Resynchronized {i} {q_i:.3f}  {p_i:.3f}  {p_i1:.3f}  {(p_i1 - p_min) \/ p_step}\")\n                if p_coef != 0: # for p_coef == 0, q_i doesn't depend on p_i\n                    last_valid, last_delta = i, p_i - pred_new[i]\n                    pred_new[i] = p_i\n                    update_list.append((start+i, p_i))\n                q, q_is_valid = q_i, True\n                break\n\n    pred_new[(u < 1e-6) & (oof > pred_new)] = oof[(u < 1e-6) & (oof > pred_new)]\n    pred_new[(u > 99.9999) & (oof < pred_new)] = oof[(u > 99.9999) & (oof < pred_new)]\n    \n    # For training data (where we know the true pressure): verify that the error is getting smaller\n    if pp is not None and not update_preds:\n        mae_pred = mean_absolute_error(p, pred_new)\n        ae_gain_1 = np.abs(p - oof).sum() - np.abs(p - pred_new).sum() # should be nonnegative \n        print(f'Row {row:2}: Gain {ae_gain_1:6.3f}')\n        ae_gain += ae_gain_1\n        if ae_gain_1 < 0:\n            print(f\"Row: {row}\")\n            print(f\"MAE OOF:  {mean_absolute_error(p, oof):.3f}\")\n            print(f\"MAE Pred: {mae_pred:.3f}\")\n            print(f\"Start: {start}\")\n            plt.figure(figsize=(10, 4))\n            plt.title(f\"p_coef = {p_coef:.2f}, i_coef = {i_coef:.2f}, p_star = {p_star:.0f}\")\n            plt.plot(np.arange(start, end), u, label='u_in')\n            plt.scatter(*zip(*update_list), marker='o', label='updated pressure')\n            plt.scatter(np.arange(start, end)[u == 0], u[u == 0], marker='x') # clipped u_in which is useless for predictions\n            plt.plot(np.arange(start, end), oof, label='pressure_pred_oof')\n            plt.plot(np.arange(start, end), pp[row, rr[row]][start:end], label='pressure_true')\n            #plt.scatter(np.arange(start, end), pred_new, label='pressure_pred_new')\n            #plt.plot(np.arange(len(uu[row])), uu[row]) # 80 steps of u_in\n            #plt.plot(np.arange(len(pp[row])), pp[row]) # 80 steps of pressure_true\n            plt.legend()\n            plt.show()\n            count_bad += 1\n        else:\n            count += 1\n\n    # Keep the parameters for future reference\n    pi_list.append((row, p_coef, i_coef, p_star, np.abs(oof - pred_new).sum()))\n    \n    # For test data: update the predictions\n    if update_preds:\n        exhale = rr[row].argmin()\n        preds[row, start:exhale] = pred_new\n        updated += 1\n        \n# Test the function on a subset of the training data\n# if the training data is available and pp is defined\ntry:\n    pi_list, count, count_bad, ae_gain = [], 0, 0, 0\n    for row in range(len(pp) \/\/ 10, len(pp) \/\/ 5): # [79, 133, 219]: # [106, 171, 455]: # \n        find_pi_control(row, uu, rr, dt_, oof_pred, pi_list, pp)\n    if count > 0 or count_bad > 0:\n        print(\"Count:\", count, count_bad)\n        print(\"AE gain:\", ae_gain)\n    pi_df = pd.DataFrame(pi_list, columns=['row', 'p_coef', 'i_coef', 'p_star', 'difference'])\n    print(f\"Cumulated difference: {pi_df['difference'].sum():.3f}\")\n    display(pi_df)\nexcept NameError as e:\n    print(\"Warning: NameError caught\", e)\n","fa6dded8":"# Find and update all experiments which use a P-only controller\n\ndef find_p_control(row, uu, rr, preds, p_list, pp=None, update_preds=False):\n    \"\"\"Test if row has been generated by a perfect P controller\n    \n    Parameters\n    ----------\n    row          : The row to be processed\n    uu           : 2d array of u_in\n    rr           : 2d array of (u_out == 0)\n    preds        : 2d array of predictions; will be updated if update_preds is True\n    p_list       : list, the found parameters will be appended to this list\n    pp           : 2d array of true pressures for evaluation, optional\n    update_preds : bool, default False, controls if preds is updated\n    \n    Global variables\n    ----------------\n    row_set                    : set of row numbers with P controller\n    count, count_bad, mae_gain : updated with evaluation results if pp is not None\n    updated                    : count of updated rows\n    \"\"\"\n    # Verify parameters and copy the selected row into u, oof and p\n    if uu.shape != preds.shape: raise ValueError(f\"Shapes of uu and preds must be equal: {uu.shape} {preds.shape}\")\n    if rr.shape != preds.shape: raise ValueError(f\"Shapes of rr and preds must be equal: {rr.shape} {preds.shape}\")\n    global row_set, count, count_bad, ae_gain, updated\n    start, end = 1, rr[row].sum()\n    u = uu[row, rr[row]][start:]\n    oof = preds[row, rr[row]][start:]\n    if pp is not None: p = pp[row, rr[row]][start:]\n        \n    def find_p_coefficients(u):\n        \"\"\"Take four samples from the series and determine p_coef and p_star\n        \n        Return (p_coef, p_star) if the breath is using a P controller\n        Return (None, None) if it is not a P controller\"\"\"\n        for i in [0, len(u) \/\/ 3, len(u) * 2 \/\/ 3, len(u) - 1]:\n            if u[i] != 0 and u[i] != 100:\n                for p_coef in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n                    for p_star in [10, 15, 20, 25, 30, 35]:\n                        predicted_p_int = (p_star - u[i] \/ p_coef - p_min) \/ p_step\n                        if predicted_p_int >= 0 and predicted_p_int < len(p_values) and is_integer(predicted_p_int):\n                            return p_coef, p_star\n        return None, None\n\n    p_coef, p_star = find_p_coefficients(u)\n    if p_coef is None: return\n        \n    # Compute the new predictions\n    # If anything is strange about them, keep the original predictions\n    # If u_in is 0, the new prediction will be too low and not a discrete value\n    # -> we may round the prediction up\n    # -> we should keep the original prediction if it is higher\n    # If u_in is 100, the new prediction will be too high and not a discrete value\n    # -> we may round the prediction down\n    # we should keep the original prediction if it is lower\n    pred_new = p_star - u \/ p_coef\n    pred_new_int = (pred_new - p_min) \/ p_step\n    strange = ((pred_new_int < 0) | (pred_new_int >= len(p_values)) | (~is_integer(pred_new_int))) & (u != 0) & (u != 100)\n    if strange.any():\n        print('strange', row, strange)\n        return\n    pred_new[u == 0] = np.ceil(pred_new_int[u == 0]) * p_step + p_min\n    pred_new[(u == 0) & (oof > pred_new)] = oof[(u == 0) & (oof > pred_new)]\n    pred_new[u == 100] = np.floor(pred_new_int[u == 100]) * p_step + p_min\n    pred_new[(u == 100) & (oof < pred_new)] = oof[(u == 100) & (oof < pred_new)]\n    \n    \n    if pp is not None and not update_preds:\n        mae_pred = mean_absolute_error(p, pred_new)\n        ae_gain_1 = np.abs(p - oof).sum() - np.abs(p - pred_new).sum() # absolute error improvement should be positive \n        ae_gain += ae_gain_1\n        if ae_gain_1 < 0: # mae_pred > 0.00001: #\n            print(f\"Row: {row}\")\n            print(f\"Candidate p_coef: {p_coef:.6f}\")\n            print(f\"Candidate p_star: {p_star:.6f}\")\n            print(f\"MAE OOF:  {mean_absolute_error(p, oof):.3f}\")\n            print(f\"MAE Pred: {mae_pred:.3f}\")\n            plt.figure(figsize=(10, 4))\n            plt.title(f\"p_coef = {p_coef:.2f}, p_star = {p_star:.0f}\")\n            plt.plot(np.arange(start, end), u, label='u_in')\n            #plt.plot(np.arange(start, end), oof, label='pressure_pred_oof')\n            plt.plot(np.arange(start, end), pred_new, label='pressure_pred_new')\n            plt.plot(np.arange(end), pp[row, rr[row]], label='pressure_true')\n            #plt.plot(np.arange(len(uu[row])), uu[row]) # all 80 u_in\n            #plt.plot(np.arange(len(pp[row])), pp[row]) # all 80 true pressures\n            plt.scatter(np.arange(start, end)[u < 1e-6], u[u < 1e-6]) # mark zeros of u_in\n            plt.legend()\n            if row in [1, 537, 634, 1098, 3193, 9847, 10398, 13828]: plt.savefig(f\"p-control-{row}.png\")\n            plt.show()\n            count_bad += 1\n        else:\n            count += 1\n\n    # Keep the parameters for future reference\n    p_list.append((row, p_coef, p_star, np.abs(oof - pred_new).sum()))\n    \n    # For test data: update the predictions\n    if update_preds:\n        exhale = rr[row].argmin()\n        preds[row, 1:exhale] = pred_new\n        updated += 1\n        \n    try:\n        row_set.add(row)\n    except NameError:\n        pass\n\n# Test the function if the training data is available and pp is defined\np_list, row_set, count, count_bad, ae_gain = [], set(), 0, 0, 0\ntry:\n    for row in range(len(pp)):\n        find_p_control(row, uu, rr, oof_pred, p_list, pp)\n    if count > 0 or count_bad > 0:\n        print(\"Count:\", count, count_bad)\n        print(\"AE gain:\", ae_gain)\n        if ae_gain <= 0: raise ValueError(\"MAE gain is not positive\")\n    p_df = pd.DataFrame(p_list, columns=['row', 'p_coef', 'p_star', 'difference'])\n    print(f\"Cumulated difference: {p_df['difference'].sum():.3f}\")\n    display(p_df.head())\nexcept NameError as e:\n    print(\"Warning: NameError caught\", e)","27b04498":"try:\n    sub = pd.read_csv('..\/input\/notebook-output-cache\/submission_pi_20211101.csv')\n    p_df = pd.read_csv('..\/input\/notebook-output-cache\/p_parameters.csv')\n    pi_df = pd.read_csv('..\/input\/notebook-output-cache\/pi_parameters.csv')\n    use_shortcut = True\n    print(\"Using the shortcut to save CPU time\")\nexcept FileNotFoundError:\n    sub = pd.read_csv('..\/input\/vent-015a-pulp-fiction-inference\/submission_better_than_median.csv')\n    use_shortcut = False\n    print(\"Doing the full computation (no shortcut)\")\n","cbc678de":"%%time\ndef find_pi_control_slice(a, b):\n    \"\"\"Return the updated rows a:b of oof_copy.\n    \n    This function is meant to be run in a parallel job.\"\"\"\n    oof_copy2 = ss.copy() # make a writable copy for this job\n    pi_list = []\n    for row in range(a, b):\n        find_pi_control(row, uu, rr, dt_, oof_copy2, pi_list, pp=None, update_preds=True)\n    return oof_copy2[a:b], pi_list\n\nss = sub.pressure.values.reshape(-1, 80)\nss_copy = ss.copy()\nn_jobs = 8\nstop = 10 if use_shortcut else len(ss)\npi_list, updated = [], 0\n\na_list = [stop \/\/ n_jobs * i for i in range(n_jobs)]\nb_list = a_list[1:] + [stop]\nupdated_slices = Parallel(n_jobs=n_jobs)(delayed(find_pi_control_slice)(a, b)\n                                         for a, b in zip(a_list, b_list))\nfor (new_slice, slice_pi_list), a, b in zip(updated_slices, a_list, b_list):\n    ss[a:b] = new_slice\n    pi_list += slice_pi_list\n    \nprint(f\"Modified {(ss != ss_copy).any(axis=1).sum()} rows of {len(ss)} in parallel for the PI controllers.\")\nif not use_shortcut: pi_df = pd.DataFrame(pi_list, columns=['row', 'p_coef', 'i_coef', 'p_star', 'difference'])\nprint(f\"Cumulated difference: {pi_df['difference'].sum():.3f}\")\nwith open('pi_parameters.pickle', 'wb') as handle: pickle.dump(pi_df, handle)\npi_df.to_csv('pi_parameters.csv', index=False)\ndisplay(pi_df)\nprint()\n\np_list = []\nfor row in range(len(ss)):\n    find_p_control(row, uu, rr, ss, p_list, update_preds=True)\nprint(f\"Updated {updated} rows for the P controllers.\")\nif not use_shortcut: p_df = pd.DataFrame(p_list, columns=['row', 'p_coef', 'p_star', 'difference'])\nprint(f\"Cumulated difference: {p_df['difference'].sum():.3f}\")\nwith open('p_parameters.pickle', 'wb') as handle: pickle.dump(p_df, handle)\np_df.to_csv('p_parameters.csv', index=False)\ndisplay(p_df)\nprint()\n\nsub[\"pressure\"] = ss.ravel()\nsub.to_csv('submission_pi.csv', index=False)\nsub.head(5)","3a58f301":"# Predicting pressures by inverting the function of PID controllers\n\nThis notebook takes as input a submission file created by a neural network model and updates all pressures which can be determined by computing the inverse function of a P controller or a PI controller.\n\nIn addition to the submission file, the notebook saves all the controller parameters.","6d12d93e":"# Read training data and test data","cf73ed89":"# Inverse functions of P controller and PI controller","3cf0283d":"# Read the nn predictions, update them and write the final submission file\n\nThe full computation takes more than nine hours and cannot be run on Kaggle. I have run the exact same notebook locally and uploaded the result as a dataset. If the dataset is available, the notebook skips the full computation; if the dataset is unavailable, the notebook performs the full, lengthy computation."}}