{"cell_type":{"3b8625e9":"code","e19eda7f":"code","a1dfbb82":"code","07f42ccd":"code","0c9b853c":"code","2ec48e59":"code","60136495":"code","8dec94f3":"code","4f5e5740":"code","3f956cc5":"code","81998229":"code","88198331":"code","3d6b8015":"code","f435c9be":"code","e76cded8":"code","9f56c2f3":"code","250221d8":"code","fa8f00ab":"code","567cceb5":"code","24d85ae2":"code","6862b07b":"code","c4fb5d87":"code","52fc10b5":"code","74e96f79":"code","706102cd":"code","cb1be93b":"code","3aa7952c":"code","c878d985":"code","fe080c04":"code","16d9fe68":"code","0101690f":"markdown","e0b85274":"markdown","9bf22e9c":"markdown","a5ba9208":"markdown","7406cf54":"markdown","8c8366b9":"markdown","a620a00e":"markdown","ec1aa972":"markdown","7fbb295a":"markdown","ec82ae05":"markdown","f2c29431":"markdown","0e6212cc":"markdown","9562a597":"markdown","d221a2b0":"markdown","f49c207c":"markdown","2b2a8cfb":"markdown","373027a2":"markdown","249b6c02":"markdown","969c361f":"markdown","daf27649":"markdown"},"source":{"3b8625e9":"import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport random \nfrom itertools import cycle\nfrom ipywidgets import widgets, interactive\nfrom tqdm.autonotebook import tqdm\nimport datetime\nimport seaborn as sns\n\n\ntqdm.pandas()\npd.set_option('max_columns', 50)\nplt.style.use('bmh')\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n\nimport sys\nimport warnings\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")","e19eda7f":"!jupyter nbextension enable --py --sys-prefix widgetsnbextension","a1dfbb82":"df_calendar = pd.read_csv('..\/input\/m5-forecasting-accuracy\/calendar.csv')\ndf_calendar.head()","07f42ccd":"df_calendar.shape","0c9b853c":"df_sell_prices = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sell_prices.csv')\ndf_sell_prices.head()","2ec48e59":"df_sell_prices.shape","60136495":"print (\"Tehere are:\", len(df_sell_prices['item_id'].unique()) , \"unique items\")","8dec94f3":"print (\"Tehere are:\", len(df_sell_prices['store_id'].unique()) , \"unique stores\")","4f5e5740":"print (\"maximuim all items price is :\",max(df_sell_prices['sell_price']),\"$\")\nprint (\"minimum all items price is :\",min(df_sell_prices['sell_price']),\"$\")\nprint (\"average all item price is :\",round(sum(df_sell_prices['sell_price'])\/len(df_sell_prices['sell_price']),2),\"$\")","3f956cc5":"df_sales_train = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\ndf_sales_train.head()","81998229":"df_sales_train[df_sales_train['store_id']=='TX_1'].head()","88198331":"df_sales_train.shape","3d6b8015":"\nax = df_sales_train.groupby(['cat_id'])['item_id'].describe()['unique'].plot(kind='bar',\n                                    figsize=(14,4),\n                                    color=['r', 'g', 'b', 'r', 'g', 'b', 'r'])\n\nax.set_title(\"Items Per Categories\", fontsize= 18)\nplt.xticks(rotation=45)\nax.set_ylabel(\"Number Of Items\",fontsize = 14)\nax.set_xlabel(\"Category\",fontsize=14)\nplt.show()","f435c9be":"\nax = df_sales_train.groupby(['dept_id'])['item_id'].describe()['unique'].plot(kind='bar',\n                                    figsize=(14,4),\n                                    color=['r', 'g', 'b', 'r', 'g', 'b', 'r'])\n\nax.set_title(\"Items Per Department \", fontsize= 18)\nplt.xticks(rotation=45)\nax.set_ylabel(\"Number Of Items\",fontsize = 14)\nax.set_xlabel(\"Department\",fontsize=14)\nplt.show()","e76cded8":"#Create date index\ndate_index = df_calendar['date']\ndates = date_index[0:1913]\ndates_list = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in dates]","9f56c2f3":"# Create a data frame for items sales per day with item ids (with Store Id) as columns names  and dates as the index \ndf_sales_train['item_store_id'] = df_sales_train.apply(lambda x: x['item_id']+'_'+x['store_id'],axis=1)\nDF_Sales = df_sales_train.loc[:,'d_1':'d_1913'].T\nDF_Sales.columns = df_sales_train['item_store_id'].values\n\n#Set Dates as index \nDF_Sales = pd.DataFrame(DF_Sales).set_index([dates_list])\nDF_Sales.index = pd.to_datetime(DF_Sales.index)\n\nDF_Sales.head()","250221d8":"index = 17005\n#y = df_sales_train.loc[index,'d_1':'d_1913'].T\ny = pd.DataFrame(DF_Sales.iloc[:,index])\ny = pd.DataFrame(y).set_index([dates_list])\ny.index = pd.to_datetime(y.index)\n\nax = y.plot(figsize=(18, 5),color='black')\nax.set_facecolor('lightgrey')\nplt.show()\n\n ","fa8f00ab":"\n\n# Make a dropdown to select the Department\nDepartment = widgets.Dropdown(\n    options= list(df_sales_train['dept_id'].unique()),\n    value='FOODS_1',\n    style = {'description_width': 'initial'},\n    description='Select Department:', \n   \n      \n    \n)\n\n\n\n\n#Plot some examples from the selected category \ndef Plot_Rand_TS_From_Department(Department,Seed = 43):\n    col_index = DF_Sales.columns[DF_Sales.columns.str.contains(pat = Department)]\n    random.seed(Seed)\n    examples_index = random.sample(list(col_index),24)\n    ts_sample = DF_Sales[examples_index]\n\n\n\n\n    fig, axs = plt.subplots(8, 3, figsize=(18, 22))\n    axs = axs.flatten()\n    ax_idx = 0\n    for item in ts_sample.columns:\n        ax = ts_sample[item].plot(title=item,\n                                  fontsize = 14,\n                                  color=next(color_cycle),\n                                  ax=axs[ax_idx])\n        ax.set_xlabel(\"Date\",size=15)\n        ax.set_ylabel(\"Item Sold\",size = 15)\n        ax_idx += 1\n    plt.tight_layout()\n    plt.show()\n\n\nout = interactive(Plot_Rand_TS_From_Department,Department = Department,Seed = 43)\nout ","567cceb5":"#Plot some examples from specific category across all stores \n\n\n\n# Make a dropdown to select the Department\nDepartment = widgets.Dropdown(\n    options= list(df_sales_train['dept_id'].unique()),\n    value='FOODS_1',\n    style = {'description_width': 'initial'},\n    description='Select Department:', \n \n)\n\n# Make a dropdown to select the item\nitem = widgets.BoundedFloatText(\n    #department = Department.observe(on_value_change, names='value'),\n    #minmax = Calc_Min_Max_Item(department = Department.observe(on_value_change, names='value')),\n    value=55,\n    min=0,\n    max=1000,\n    style = {'description_width': 'initial'},\n    step=1,\n    description='Item Numberr:',\n    disabled=False,\n    color='black'\n)\n\n\ndef Plot_TS_Items_Across_Stores(Department,Item) : \n    Item = int(Item)\n    if Item < 10:\n        ItemS = '00'+str(Item)\n    if Item >9 and Item < 100:\n         ItemS = '0'+str(Item)\n    if Item > 99 :\n        ItemS = str(Item)\n    if Item == None:\n        ItemS = '001'\n    select_item =str(Department)+'_'+str(ItemS)\n     \n    examples_index = DF_Sales.columns[DF_Sales.columns.str.contains(pat = select_item)]\n    \n    if len(examples_index) ==0 : \n        select_item =str(Department)+'_'+str('001')\n        examples_index = DF_Sales.columns[DF_Sales.columns.str.contains(pat = select_item)]\n            \n    ts_sample = DF_Sales[examples_index]\n\n\n    fig, axs = plt.subplots(5, 2, figsize=(15, 10))\n    axs = axs.flatten()\n    ax_idx = 0\n    for item in ts_sample.columns:\n        ax = ts_sample[item].plot(title=item,\n                                  fontsize = 14,\n                                  color=next(color_cycle),\n                                  ax=axs[ax_idx])\n        ax_idx += 1\n        ax.set_xlabel(\"Date\",size=15)\n        ax.set_ylabel(\"Item Sold\",size = 15)\n    plt.tight_layout()\n    plt.show()\n    \n\ninteractive(Plot_TS_Items_Across_Stores,Department = Department,Item = item)","24d85ae2":" \n\n# Make a dropdown to select the Department\nDepartment = widgets.Dropdown(\n    options= list(df_sales_train['dept_id'].unique()),\n    value='FOODS_1',\n    style = {'description_width': 'initial'},\n    description='Select Department:', \n \n)\n\n# Make a dropdown to select the item\nitem = widgets.BoundedFloatText(\n    #department = Department.observe(on_value_change, names='value'),\n    #minmax = Calc_Min_Max_Item(department = Department.observe(on_value_change, names='value')),\n    value=55,\n    min=0,\n    max=1000,\n    style = {'description_width': 'initial'},\n    step=1,\n    description='Item Numberr:',\n    disabled=False,\n    color='black'\n)\n\n\n\ndef Plot_TS_Items_Aggr_Stata_All(Department,Item) : \n\n     \n    Item = int(Item)\n    if Item < 10:\n        ItemS = '00'+str(Item)\n    if Item >9 and Item < 100:\n         ItemS = '0'+str(Item)\n    if Item > 99 :\n        ItemS = str(Item)\n    if Item == None:\n        ItemS = '001'\n    Product =str(Department)+'_'+str(ItemS)\n    \n         \n    \n    df_product = DF_Sales.copy(deep=True)\n    df_product =  df_product[df_product.columns[df_product.columns.str.contains(pat = Product)]]\n    states = ['CA','TX','WI','All']\n    \n    \n    if df_product.shape[1] == 0:\n        Product =str(Department)+'_'+str('001')\n        df_product =  DF_Sales[DF_Sales.columns[DF_Sales.columns.str.contains(pat = Product)]]\n        \n\n    #Aggregate All \n    df_product.loc[:,'All'] = df_product.apply(lambda x:sum(x),axis=1)\n\n    #Aggregate across states \n    df_product.loc[:,'CA'] = df_product[df_product.columns[df_product.columns.str.contains(pat = 'CA')]].apply\\\n        (lambda x:sum(x),axis=1)\n    df_product.loc[:,'TX'] = df_product[df_product.columns[df_product.columns.str.contains(pat = 'TX')]].apply\\\n        (lambda x:sum(x),axis=1)\n    df_product.loc[:,'WI'] = df_product[df_product.columns[df_product.columns.str.contains(pat = 'WI')]].apply\\\n        (lambda x:sum(x),axis=1)\n\n\n\n    #fig, axs = plt.subplots(1, 1, figsize=(15, 10))\n    fig, axs = plt.subplots(2, 2, figsize=(14, 6))\n    axs = axs.flatten()\n\n    ax_idx = 0\n\n    for state in states:\n        ax = df_product[state].plot(title=Product+' '+state,\n                                      fontsize = 14,\n                                      color=next(color_cycle),\n                                      ax=axs[ax_idx])\n        ax_idx += 1\n        ax.set_xlabel(\"Date\",size=15)\n        ax.set_ylabel(\"Item Sold\",size = 15)\n    plt.tight_layout()\n    plt.show()\n\n\ninteractive(Plot_TS_Items_Aggr_Stata_All,Department = Department,Item = item)\n ","6862b07b":"\n\n# Make a dropdown to select the Department\nDepartment = widgets.Dropdown(\n    options= list(df_sales_train['dept_id'].unique()),\n    value='FOODS_1',\n    style = {'description_width': 'initial'},\n    description='Select Department:', \n \n)\n\n\ndef Plot_Department_Agg_By_Sate(Department):\n    df_department = DF_Sales.copy(deep = True)\n     \n    #Create Store List \n    Stores = pd.Series(df_department.columns).apply(lambda x: x[-4:]).unique()\n    df_department =  df_department[DF_Sales.columns[df_department.columns.str.contains(pat = Department)]]\n    for store in Stores :\n        df_department.loc[:,store] = df_department[df_department.columns[df_department.columns.str.contains(pat = store)]].apply\\\n            (lambda x:sum(x),axis=1)\n\n\n    fig, axs = plt.subplots(5, 2, figsize=(14, 12))\n    axs = axs.flatten()\n\n    ax_idx = 0\n\n    for store in Stores:\n            ax = df_department[store].plot(title=Department+' '+store,\n                                          fontsize = 14,\n                                          color=next(color_cycle),\n                                          #ax = axs.get_subplotspec().rowspan.start\n                                          ax=axs[ax_idx])\n            ax_idx += 1\n            ax.set_xlabel(\"Date\",size=15)\n            ax.set_ylabel(\"Item Sold\",size = 15)\n    plt.tight_layout()\n    plt.show()\n    \n    \ninteractive(Plot_Department_Agg_By_Sate,Department = Department)","c4fb5d87":"\n\n# Make a dropdown to select the Department\nCategory = widgets.Dropdown(\n    options= list(df_sales_train['cat_id'].unique()),\n    value='FOODS',\n    style = {'description_width': 'initial'},\n    description='Select Department:', \n \n)\n\n\ndef Plot_Category_Agg_By_Sate(Category):\n    df_Category = DF_Sales.copy(deep = True)\n     \n    #Create Store List \n    Stores = pd.Series(df_Category.columns).apply(lambda x: x[-4:]).unique()\n    df_Category =  df_Category[df_Category.columns[df_Category.columns.str.contains(pat = Category)]]\n    for store in Stores :\n        df_Category.loc[:,store] = df_Category[df_Category.columns[df_Category.columns.str.contains(pat = store)]].apply\\\n            (lambda x:sum(x),axis=1)\n\n\n    fig, axs = plt.subplots(5, 2, figsize=(14, 12))\n    axs = axs.flatten()\n\n    ax_idx = 0\n\n    for store in Stores:\n            ax = df_Category[store].plot(title=Category+' '+store,\n                                          fontsize = 14,\n                                          color=next(color_cycle),\n                                          ax=axs[ax_idx])\n            ax_idx += 1\n            ax.set_xlabel(\"Date\",size=15)\n            ax.set_ylabel(\"Item Sold\",size = 15)\n    plt.tight_layout()\n    plt.show()\n    \n    \ninteractive(Plot_Category_Agg_By_Sate,Category = Category)","52fc10b5":"\ndf_Department = DF_Sales.copy(deep = True)\n     \n#Create Store List \nStates = ['CA','TX','WI']\nDepartmants = pd.Series(df_Department.columns).apply(lambda x: x[:-9]).unique()\n\n\n#Create date index\ndate_index = df_calendar['date']\ndates = date_index[0:1913]\ndates_list = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\ndf = df_sales_train.groupby(['dept_id','state_id'])[df_sales_train.filter(regex='d_.*').columns].sum()\ndf = df.reset_index()\n\n\nfig, axs = plt.subplots(7, 3, figsize=(14, 16))\naxs = axs.flatten()\n\nax_idx = 0\n\nfor index, row in df.iterrows():\n    y = pd.DataFrame(row['d_1':'d_1913']).set_index([dates_list])\n    y.index = pd.to_datetime(y.index)\n     \n    \n    ax = y.plot(title=row.dept_id+' '+row.state_id,\n                                          fontsize = 14,\n                                          color=next(color_cycle),\n                                        ax=axs[ax_idx])\n     \n    ax_idx += 1\n    ax.set_xlabel(\"Date\",size=15)\n    ax.set_ylabel(\"Item Sold\",size = 15)\n     \n     \nplt.tight_layout()\nplt.show()\n","74e96f79":"#Create date index\ndate_index = df_calendar['date']\ndates = date_index[0:1913]\ndates_list = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\ndf = df_sales_train.groupby(['cat_id','state_id'])[df_sales_train.filter(regex='d_.*').columns].sum()\ndf = df.reset_index()\n\n\nfig, axs = plt.subplots(3, 3, figsize=(14, 16))\naxs = axs.flatten()\n\nax_idx = 0\n\nfor index, row in df.iterrows():\n    y = pd.DataFrame(row['d_1':'d_1913']).set_index([dates_list])\n    y.index = pd.to_datetime(y.index)\n     \n    \n    ax = y.plot(title=row.cat_id+' '+row.state_id,\n                                          fontsize = 14,\n                                          color=next(color_cycle),\n                                        ax=axs[ax_idx])\n     \n    ax_idx += 1\n    ax.set_xlabel(\"Date\",size=15)\n    ax.set_ylabel(\"Item Sold\",size = 15)\n     \n     \nplt.tight_layout()\nplt.show()","706102cd":"#Create date index\ndate_index = df_calendar['date']\ndates = date_index[0:1913]\ndates_list = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\ndf = df_sales_train.groupby(['dept_id'])[df_sales_train.filter(regex='d_.*').columns].sum()\ndf = df.reset_index()\n\n\nfig, axs = plt.subplots(4, 2, figsize=(14, 16))\naxs = axs.flatten()\n\nax_idx = 0\n\nfor index, row in df.iterrows():\n    y = pd.DataFrame(row['d_1':'d_1913']).set_index([dates_list])\n    y.index = pd.to_datetime(y.index)\n     \n    \n    ax = y.plot(title=row.dept_id,\n                                          fontsize = 14,\n                                          color=next(color_cycle),\n                                        ax=axs[ax_idx])\n     \n    ax_idx += 1\n    ax.set_xlabel(\"Date\",size=15)\n    ax.set_ylabel(\"Item Sold\",size = 15)\n     \n     \nplt.tight_layout()\nplt.show()","cb1be93b":"df_calendar.shape","3aa7952c":"#%%time\n# Add date column to sales price (use the calndat data)\ndf_calendar_weeks = df_calendar[df_calendar['weekday']=='Monday']\ndf_calendar_weeks = df_calendar[['date','wm_yr_wk']]\n(df_sell_prices['wm_yr_wk'].unique())\ncalendar_index = df_calendar_weeks.drop_duplicates(subset='wm_yr_wk').reset_index(drop=True)\n\ndf_sell_prices_dates = df_sell_prices.merge(calendar_index,on='wm_yr_wk',how='outer')\n","c878d985":"#combine item id and store id \ndf_sell_prices_dates['item_store_id'] = df_sell_prices_dates.progress_apply(lambda x: x['item_id']+'_'+x['store_id'],axis=1)","fe080c04":"# Make a dropdown to select the Department\nDepartment = widgets.Dropdown(\n    options= list(df_sales_train['dept_id'].unique()),\n    value='FOODS_1',\n    style = {'description_width': 'initial'},\n    description='Select Department:', \n   \n      \n    \n)\n\n#Plot some price examples from the selected category \ndef Plot_Rand_TS_From_Department(Department,Seed = 43):\n    df = df_sell_prices_dates[df_sell_prices_dates.item_store_id.str.contains(pat = Department)]\n    item_stores_list = df['item_store_id'].unique()\n    item_stores_list\n    examples_items = random.sample(list(item_stores_list),20)\n    ts_samples = pd.DataFrame()\n\n    fig, axs = plt.subplots(10, 2, figsize=(18, 24))\n    axs = axs.flatten()\n    \n    ax_idx = 0\n\n    for item in examples_items:\n        ts_samples = df[df.item_store_id.str.contains(pat = item)]\n        ts_samples = ts_samples.set_index(ts_samples['date'])\n        ax = ts_samples['sell_price'].plot(title=item,\n                                      fontsize = 14,\n                                      color=next(color_cycle),\n                                      ax=axs[ax_idx])\n       \n        ax.set_xlabel(\"Date\",size=14)\n        ax.set_ylabel(\"Price (in US$)\",size = 15)\n        ax_idx += 1\n    plt.tight_layout()\n    plt.show()\n\n\ninteractive(Plot_Rand_TS_From_Department,Department = Department,Seed = 43)\n\n","16d9fe68":"\n# Make a dropdown to select the Department\nDepartment = widgets.Dropdown(\n    options= list(df_sales_train['dept_id'].unique()),\n    value='FOODS_1',\n    style = {'description_width': 'initial'},\n    description='Select Department:', \n     \n    \n)\n\n\n# Make a dropdown to select the Department\nStore = widgets.Dropdown(\n    options= list(df_sales_train['store_id'].unique()),\n    value='CA_1',\n    style = {'description_width': 'initial'},\n    description='Select Store:', \n     \n    \n)\n\ndef Calc_Corr(Department,Store):\n\n    df_department = DF_Sales.copy(deep = True)\n    df_department =  df_department[df_department.columns[df_department.columns.str.contains(pat = Department)]]\n    df_department =  df_department[df_department.columns[df_department.columns.str.contains(pat = Store)]]\n\n    #Calculate the top Corrlated TS\n    corr_matrix = df_department.corr().abs()\n    #the matrix is symmetric so we need to extract upper triangle matrix without diagonal (k = 1)\n    sol = pd.DataFrame(corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n                     .stack()\n                     .sort_values(ascending=False)).reset_index()\n\n    Top_TS = np.concatenate([sol.iloc[0:10]['level_0'].unique(),sol.iloc[0:10]['level_1'].unique()])\n\n    df_department_top_corr = df_department[Top_TS]\n\n\n\n\n    corr = df_department_top_corr.corr()\n    matrix = np.triu(df_department_top_corr.corr())\n    plt.figure(figsize=(15,13))\n    # plot the heatmap\n\n\n    sns.heatmap(corr, annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm',mask=matrix,cbar=False,\n            xticklabels=corr.columns,\n            yticklabels=corr.columns)\n    plt.xticks(rotation=45) \n    print(sol.head(10))\n    \ninteractive(Calc_Corr,Department = Department,Store = Store)\n","0101690f":"# Time Series - One Selection\n  ","e0b85274":"# M5 Competition  - DataSet \nThe Diagram below illustrates the hierarchial data structure: \n* 3 States \n* 10 Stores \n* 3 categories \n* 3049 unique items \n\n\n![M5.JPG](attachment:M5.JPG)","9bf22e9c":"# Aggregiation  Level 5\n* Unit sales of all products, aggregated for each department","a5ba9208":"# Correlation ","7406cf54":"# M5 Competiotn - Data Exploratory \n\n \n\nThe first step in each data science is to explore the data \nThe kernel is my interpretation trying to do some exploratory data \nSome idea and code for this notebook were taken from :\nhttps:\/\/www.kaggle.com\/robikscube\/m5-forecasting-starter-data-exploration \n\nSince the data contains a lot of time series I tried to use the ipywidgets package \nThe idea is that you can select and slice the data and based on that see more data \nUnfortunately, Kaggle only support this kind of widgets on the on-line kerenl, \nafter committing the kernel lose the widgets' functionality - Hopefully this will be solved soon \n\nWhat next : \n* add some more data exploratory \n* write some conclusions \n* Create some models for predictions  \n\n## If you like it please upvote ","8c8366b9":"# Aggregiation  Level 7\n* Unit sales of all products, aggregated for each State and department\n","a620a00e":"# Items Per Department ","ec1aa972":"# Aggregiation  Level 6\n* Unit sales of all products, aggregated for each State and category","7fbb295a":"# Items Per Categories ","ec82ae05":"# Aggregation \n\n\n![M5_Agg.JPG](attachment:M5_Agg.JPG)\n","f2c29431":"# File 3: \u201csales_train.csv\u201d \nContains the historical daily unit sales data per product and store.\n* item_id: The id of the product.\n* dept_id: The id of the department the product belongs to.\n* cat_id: The id of the category the product belongs to.\n* store_id: The id of the store where the product is sold.\n* state_id: The State where the store is located.\n* d_1, d_2, \u2026, d_i, \u2026 d_1941: The number of units sold at day i, starting from 2011-01-29. \n","0e6212cc":"# Time Series - Same item in different stores \n\n\nNotes : \n* If an item out of the items range is selected - item 001 will be presented\n* Seed changes will change the selection ","9562a597":"# Item Prices ","d221a2b0":"# File 2: \u201csell_prices.csv\u201d\nContains information about the price of the products sold per store and date.\n* store_id: The id of the store where the product is sold. \n* item_id: The id of the product.\n* wm_yr_wk: The id of the week.\n* sell_price: The price of the product for the given week\/store. The price is provided per week (average across seven days). If not available, this means that the product was not sold during the examined week. Note that although prices are constant at weekly basis, they may change through time (both training and test set).  \n","f49c207c":"# Aggregiation  Level 9\n* Unit sales of all products, aggregated for each store and department\n","2b2a8cfb":"# Aggregiation  Level 11 & 10 \n* Unit sales of product x, aggregated for all stores\/states\n* Unit sales of product x, aggregated for each State\n","373027a2":"# Aggregiation  Level 8\n* Unit sales of all products, aggregated for each store and category\n","249b6c02":"# File 1: \u201ccalendar.csv\u201d \nContains information about the dates the products are sold.\n* date: The date in a \u201cy-m-d\u201d format.\n* wm_yr_wk: The id of the week the date belongs to.\n* weekday: The type of the day (Saturday, Sunday, \u2026, Friday).\n* wday: The id of the weekday, starting from Saturday.\n* month: The month of the date.\n* year: The year of the date.\n* event_name_1: If the date includes an event, the name of this event.\n* event_type_1: If the date includes an event, the type of this event.\n* event_name_2: If the date includes a second event, the name of this event.\n* event_type_2: If the date includes a second event, the type of this event.\n* snap_CA, snap_TX, and snap_WI: A binary variable (0 or 1) indicating whether the stores of CA, TX or WI allow SNAP  purchases on the examined date. 1 indicates that SNAP purchases are allowed.\n","969c361f":"# Time Series - By Department \n ","daf27649":"# Visualization \n1. Convert the dates from the calendar  data from strings to dates.\n2. Plot bars of items per categories and per Department.\n3. Use Transpose to move the unit sales data per day into rows."}}