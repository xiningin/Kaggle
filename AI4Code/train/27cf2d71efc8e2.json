{"cell_type":{"03fbe04a":"code","b3405000":"code","a402060b":"code","47b2aaad":"code","a648d374":"code","5369296e":"code","a007dd35":"code","0c74c14f":"code","b7f94a7b":"code","14bbe232":"code","26298e5a":"code","0ea4852c":"code","8217c29b":"code","e6bcb5c2":"code","f5d8380b":"code","9582d5cd":"code","bac00f9e":"code","3d816a55":"code","b0b2571d":"code","5e1e04cb":"code","6d06ca9f":"code","2ac70cf0":"code","e9cfa793":"code","a5d6eec3":"code","c9d13082":"code","95d5f1c4":"code","8486f0f9":"code","ea5c0fc7":"code","4dd6ddee":"code","ff2e9751":"code","04756d49":"code","c0579f72":"code","3b16c75c":"code","db40f3ec":"code","9a1bd18b":"code","4e7f561d":"code","0f39301c":"code","f7f4d208":"code","972fb00f":"code","6a9119fc":"code","7d64a865":"code","86f55b9e":"code","84d3ed7a":"code","7d7c666b":"code","10c852c9":"code","35b71dd2":"code","75d6f3f7":"code","a5064357":"markdown","1c8a5948":"markdown","62e659d7":"markdown","317c8c98":"markdown","a5326ed6":"markdown","216751c8":"markdown","1424bcca":"markdown","b4ccc894":"markdown","df43cef0":"markdown","647e6490":"markdown","5f2e9d58":"markdown","c33001e3":"markdown","7a9e9533":"markdown","0a929c91":"markdown","78134fa6":"markdown","80615097":"markdown","c3820b85":"markdown","81e97621":"markdown","02b1d4cb":"markdown","f03ec7a4":"markdown","a5d4748e":"markdown","5c3e7513":"markdown","b6be02df":"markdown","9a2bc732":"markdown","edffd99c":"markdown","7c13c9e3":"markdown","0fa8a661":"markdown","d9d538d4":"markdown","50427ed8":"markdown","5737d6e5":"markdown","31ffb398":"markdown","3e415b7a":"markdown","92351d29":"markdown","aa761974":"markdown","82435d51":"markdown","100fd0f7":"markdown","64bbb7dd":"markdown","f22678e0":"markdown","1763e199":"markdown","c7956120":"markdown","f6de5082":"markdown","a810ad9c":"markdown","c0617249":"markdown","9732ffa5":"markdown","f87cdc9c":"markdown","660d5df3":"markdown"},"source":{"03fbe04a":"# \u21a7\u21a7 some necessary imports\n\nimport os\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing \nfrom statsmodels.tsa.seasonal import STL, seasonal_decompose\nfrom statsmodels.tsa.stattools import pacf, adfuller,kpss\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima.model import ARIMA \nimport statsmodels.api as sm\nfrom datetime import date\nfrom pandas.tseries.offsets import DateOffset as dateoffset\nfrom tqdm.notebook import tqdm\n\n\n\nimport warnings\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\n    \nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()\n    \nwarnings.filterwarnings('ignore')\n","b3405000":"filepath='\/kaggle\/input\/acea-water-prediction\/Aquifer_Auser.csv'\nauser=pd.read_csv(filepath)\nauser.head()  ","a402060b":"auser.info()","47b2aaad":"auser.Date=pd.to_datetime(auser.Date,dayfirst=True)\n#auser.iloc[:,1:]=auser.iloc[:,1:].astype('float32')","a648d374":"missing_ratio=auser.isna().sum()*100\/len(auser)\ncritical=[]\nplt.figure(figsize=(20,7))\nplt.xticks(rotation=85)\nfor i,v in enumerate(missing_ratio):\n    plt.text(i-0.4,v+0.99,\"%.1f\" % v +'%')\n    if v>40:\n        critical.append(i)\nbarlist=plt.bar(auser.columns,missing_ratio,color='0.75')\nfor e in critical:\n    barlist[e].set_color('red')\nplt.title('percentage of missing values in each column',fontdict={'fontsize':20})\nplt.show()\n","5369296e":"import missingno as msno\nmiss=msno.matrix(auser,color=(0.25, 0.45, 0.6))\nmiss.axhline(y=auser.Rainfall_Gallicano.first_valid_index(),color=\"red\")\nplt.show()","a007dd35":"auser.plot(subplots=True,kind='box',layout=(10,4),legend=False,figsize=(25,25),patch_artist=True)\nplt.show()","0c74c14f":"for e in [\"Depth_to_Groundwater_LT2\",\"Depth_to_Groundwater_SAL\",\"Depth_to_Groundwater_CoS\"]:\n    print(auser[e][auser[e]==0].value_counts().item())\n","b7f94a7b":"#not too much so we can replace null value with nan value\nfor e in [\"Depth_to_Groundwater_LT2\",\"Depth_to_Groundwater_SAL\",\"Depth_to_Groundwater_CoS\"]:\n    auser[e].replace(0,np.nan,inplace=True)","14bbe232":"auser.plot(x='Date',y=['Volume_CSA','Volume_CSAL'],subplots=True,figsize=(20,7),legend=False)","26298e5a":"for e in ['Volume_CSAL','Volume_CSA']:\n    auser[e].replace(0,np.nan,inplace=True)\n    percent=auser[e].isna().sum()\/len(auser)\n    print( \"%.2f\" % (percent*100)  + \"% of data are missing in \"+e)\n","0ea4852c":"auser=auser.iloc[auser.Rainfall_Gallicano.first_valid_index():]\nauser.reset_index(drop=True,inplace=True)\nauser.drop(['Volume_CSA','Volume_CSAL'],inplace=True,axis=1)","8217c29b":"auser.set_index('Date',inplace=True)\n(pd.date_range(start=date(2006,1,1),end=date(2020,6,30))==auser.index).all()","e6bcb5c2":"auser.isna().any()","f5d8380b":"auser.Rainfall_Monte_Serra.isna().sum()","9582d5cd":"auser.Rainfall_Monte_Serra.plot(figsize=(12,3))","bac00f9e":"auser.Rainfall_Monte_Serra.fillna(0,inplace=True)","3d816a55":"auser.Rainfall_Piaggione.plot(figsize=(12,3),title='daily rainfall')","b0b2571d":"auser.Rainfall_Piaggione.isna().sum()","5e1e04cb":"#  check stationarity first\ndef isstationary(data):\n    adf=adfuller(data,regression='ct')\n    print('****** ADfuller test ****** ' )\n    if adf[1]>0.05:\n        print(f'pvalue = {adf[1]} , we can not reject H0, so the data has unit root and it\\'s not trend stationary')\n    else:\n        print(f'pvalue = {adf[1]} , we reject H0, data has no unit root')\n    print('\\n')\n\n    \n    kps=kpss(data, regression=\"ct\")\n    print('****** KPSS test ****** ' )\n    if kps[1]>0.05:\n        print(f'pvalue = {kps[1]} , we can not reject H0,  the data is trend stationary')\n    else:\n        print(f'pvalue = {kps[1]} , we reject H0, data is not trend stationary')","6d06ca9f":"lastnan = auser.query('Rainfall_Piaggione!=Rainfall_Piaggione').index.tolist()[-1]\nisstationary(auser.Rainfall_Piaggione.loc[lastnan+dateoffset(1):])","2ac70cf0":"fig1=plot_acf(auser.Rainfall_Piaggione.loc[lastnan+dateoffset(1):])\nfig2=plot_pacf(auser.Rainfall_Piaggione.loc[lastnan+dateoffset(1):])\n","e9cfa793":"fig1=plot_acf(auser.Rainfall_Piaggione.loc[lastnan+dateoffset(1):],lags=1300)\nfig2=plot_pacf(auser.Rainfall_Piaggione.loc[lastnan+dateoffset(1):],lags=1300)","a5d6eec3":"model=ARIMA(auser.Rainfall_Piaggione.loc[lastnan+dateoffset(1):],order=(1,0,0))\nresults=model.fit()\nresults.summary()","c9d13082":"fig1=plot_acf(results.resid)\nfig2=plot_pacf(results.resid)\nplt.show()\nresults.resid.plot(kind='kde')\nplt.show()\nresults.resid.plot()","95d5f1c4":"fig1=plot_acf((results.resid**2))\nfig2=plot_pacf((results.resid**2))","8486f0f9":"auser.Rainfall_Piaggione.loc[lastnan+dateoffset(1):].plot(figsize=(17,3))\nresults.fittedvalues.plot(figsize=(17,3))","ea5c0fc7":"from matplotlib import image\nimage=image.imread(\"..\/input\/villages-location\/piaggione.PNG\")\nplt.figure(figsize = (20,7))\nplt.imshow(image)\nplt.show()","4dd6ddee":"auser.plot(y=['Rainfall_Borgo_a_Mozzano','Rainfall_Piaggione'],figsize=(12,3),title='daily rainfall')\n\n# fillin missing values\nauser.Rainfall_Piaggione.loc[date(2009,1,1):date(2009,12,31)]=auser.Rainfall_Borgo_a_Mozzano.xs('2009').values","ff2e9751":"plt.figure(figsize=(16,4))\nplt.plot(auser.Depth_to_Groundwater_LT2)\n\nmisses=auser.query('Depth_to_Groundwater_LT2!=Depth_to_Groundwater_LT2')\nplt.vlines(misses.index,ymin=-16,ymax=-11,color='bisque')","04756d49":"# function that fit data \ndef frcast(data):\n    expsmooth=ExponentialSmoothing(data,trend='add' ,seasonal='add',freq='D',seasonal_periods=364)\n    model=expsmooth.fit()\n    return model.forecast(1)\n    \n\ndef fillin(featr,data):\n\n    for i in tqdm(pd.date_range(start=date(2011,2,10),end=date(2020,6,30))):\n        if pd.isnull(featr[str(i)]):\n            data=data.append(frcast(data))\n        else:\n            data=data.append(featr[str(i):str(i)])\n    return data","c0579f72":"\nVAR3=auser.Depth_to_Groundwater_LT2[:str(date(2011,2,9))].copy()\nVAR3.interpolate('slinear',inplace=True)\nVAR3=fillin(auser.Depth_to_Groundwater_LT2,VAR3)","3b16c75c":"plt.figure(figsize=(16,4))\nVAR3.plot()\nauser.Depth_to_Groundwater_LT2.plot()","db40f3ec":"auser.Depth_to_Groundwater_LT2.fillna(VAR3)","9a1bd18b":"plt.figure(figsize=(16,4))\nplt.plot(auser.Depth_to_Groundwater_SAL)\nmisses=auser.query('Depth_to_Groundwater_SAL!=Depth_to_Groundwater_SAL')\nplt.vlines(misses.index,ymin=-7,ymax=-3,color='bisque')","4e7f561d":"auser.Depth_to_Groundwater_SAL.interpolate('slinear',inplace=True)\nauser.Depth_to_Groundwater_SAL.fillna(auser.Depth_to_Groundwater_SAL.mean(),inplace=True)","0f39301c":"plt.figure(figsize=(16,4))\nplt.plot(auser.Depth_to_Groundwater_PAG)\nmisses=auser.query('Depth_to_Groundwater_PAG!=Depth_to_Groundwater_PAG')\nplt.vlines(misses.index,ymin=-3.5,ymax=0,color='bisque')","f7f4d208":"# aggregate the mean over the day of year \npagmean=auser.Depth_to_Groundwater_PAG.groupby(auser.index.dayofyear).mean()\n#set the same index of the mean to make the join\nauser.set_index(auser.index.dayofyear,append=True,inplace=True)","972fb00f":"#fillna with the mean and reser index\nauser.reset_index(level=0,inplace=True)\nauser.Depth_to_Groundwater_PAG.fillna(pagmean,inplace=True)\nauser.index.rename('dayofyear',inplace=True)\nauser.set_index('Date',drop=True,inplace=True)\nplt.figure(figsize=(16,4))\nauser.Depth_to_Groundwater_PAG.plot()","6a9119fc":"plt.figure(figsize=(16,4))\nplt.plot(auser.Depth_to_Groundwater_CoS)\nmisses=auser.query('Depth_to_Groundwater_CoS!=Depth_to_Groundwater_CoS')\nplt.vlines(misses.index,ymin=-10,ymax=-4,color='bisque')","7d64a865":"# aggregate the mean over the day of year \ncosmean=auser.Depth_to_Groundwater_CoS.groupby(auser.index.dayofyear).mean()\n\n#set the same index of the mean to make the join\nauser.set_index(auser.index.dayofyear,append=True,inplace=True)\n\n#fillna with the mean and reset index\nauser.reset_index(level=0,inplace=True)\nauser.Depth_to_Groundwater_CoS.fillna(cosmean,inplace=True)\nauser.index.rename('dayofyear',inplace=True)\nauser.set_index('Date',drop=True,inplace=True)\nplt.figure(figsize=(16,4))\nauser.Depth_to_Groundwater_CoS.plot()","86f55b9e":"plt.figure(figsize=(16,4))\nplt.plot(auser.Depth_to_Groundwater_DIEC)\nmisses=auser.query('Depth_to_Groundwater_DIEC!=Depth_to_Groundwater_DIEC')\nplt.vlines(misses.index,ymin=-5,ymax=-1,color='bisque')","84d3ed7a":"# aggregate the mean over the day of year \ndiecmean=auser.Depth_to_Groundwater_DIEC.groupby(auser.index.dayofyear).mean()\n\n#set the same index of the mean to make the join\nauser.set_index(auser.index.dayofyear,append=True,inplace=True)\n\n#fillna with the mean and reser index\nauser.reset_index(level=0,inplace=True)\nauser.Depth_to_Groundwater_DIEC.fillna(diecmean,inplace=True)\nauser.index.rename('dayofyear',inplace=True)\nauser.set_index('Date',drop=True,inplace=True)\nplt.figure(figsize=(16,4))\nauser.Depth_to_Groundwater_DIEC.plot()","7d7c666b":"plt.figure(figsize=(16,4))\nplt.plot(auser.Hydrometry_Monte_S_Quirico)\nmisses=auser.query('Hydrometry_Monte_S_Quirico!=Hydrometry_Monte_S_Quirico')\nplt.vlines(misses.index,ymin=0,ymax=2,color='bisque')","10c852c9":"# aggregate the mean over the day of year \nmontemean=auser.Hydrometry_Monte_S_Quirico.groupby(auser.index.dayofyear).mean()\n\n#set the same index of the mean to make the join\nauser.set_index(auser.index.dayofyear,append=True,inplace=True)\n\n#fillna with the mean and reser index\nauser.reset_index(level=0,inplace=True)\nauser.Hydrometry_Monte_S_Quirico.fillna(montemean,inplace=True)\nauser.index.rename('dayofyear',inplace=True)\nauser.set_index('Date',drop=True,inplace=True)\nplt.figure(figsize=(16,4))\nauser.Hydrometry_Monte_S_Quirico.plot()","35b71dd2":"plt.figure(figsize=(16,4))\nplt.plot(auser.Hydrometry_Piaggione)\nmisses=auser.query('Hydrometry_Piaggione!=Hydrometry_Piaggione')\nplt.vlines(misses.index,ymin=-2,ymax=3,color='bisque')","75d6f3f7":"# aggregate the mean over the day of year \nhydropiag=auser.Hydrometry_Piaggione.groupby(auser.index.dayofyear).mean()\n\n#set the same index of the mean to make the join\nauser.set_index(auser.index.dayofyear,append=True,inplace=True)\n\n#fillna with the mean and reser index\nauser.reset_index(level=0,inplace=True)\nauser.Hydrometry_Piaggione.fillna(hydropiag,inplace=True)\nauser.index.rename('dayofyear',inplace=True)\nauser.set_index('Date',drop=True,inplace=True)\nplt.figure(figsize=(16,5))\nauser.Hydrometry_Piaggione.plot()","a5064357":"<br>\n\n<br>\n\n<br> \n\n\n<img src= \"https:\/\/img.favpng.com\/18\/23\/16\/computer-icons-missing-data-ibm-data-science-experience-png-favpng-dKXSj5SMn0HT0tcGj9EvcZXsM.jpg\" \n     class=\"centerImage\" \n     alt =\"missindata\" \n     style=\"width: 900px; height: 300px\" >","1c8a5948":"<br>\n\n<br>\n\nNow that the dataset is cleaned and ready to use, you can start training !","62e659d7":"> We can use another interesting graph from missingno package, it converts the dataframe columns to uniformly stacked bars, and represents missing observations using white lines","317c8c98":"> ### **VAR4** : Depth_to_Groundwater_SAL","a5326ed6":"###  About dataset\n\nTo get the most out of this notebook, i have chosen the \"Aquifer_Auser dataset\" available in this [competition data page](https:\/\/www.kaggle.com\/c\/acea-water-prediction\/data), it suffers from several anomalies(outliers, non stationnarity, huge percentage of missing values... etc), which will allow the use of a multitude of statistical analysis techniques, including hypothesis tests, arima, exponential smoothing... .\n\n\n\n\nSo, Let's begin!","216751c8":"> What is the data type of each column?","1424bcca":"> ### **VAR7** : Depth_to_Groundwater_DIEC","b4ccc894":"\n> Fortunately, no date is missing, now we will go through columns with missing values one by one and try to use the best technique to fill in holes.","df43cef0":"these two variables suffer from severe missingness, the straight line showing null value for the same period for both of them indicates a systematic data entry error, the total percentage of missing values reaches 70%, and the data show no pattern to track, which make the use of these two variables for futur analysis impossible.","647e6490":">  What percentage of missing values do we have in each column ?","5f2e9d58":"Here you can see how poorly the model perform on train data :\/","c33001e3":"> ### **VAR1** : Rainfall_Monte_Serra ","7a9e9533":"> Check first if there are missing dates, if no date is missing the following code return True","0a929c91":"* we notice that \"Depth_to_Groundwater_LT2, Depth_to_Groundwater_SAL, Depth_to_Groundwater_CoS\" have some null values which are pretty far from the rest of observations and according to the data description in the competition webpage those variable should always be negative. let's see how many they are to make a safe judgement\n\n","78134fa6":"## 1.1 Missing values Detection \ud83d\udd0d","80615097":"> ### **VAR5** : Depth_to_Groundwater_DAG","c3820b85":"> ### **VAR2** : Rainfall_Piaggione","81e97621":"# 1. Exploratory Analysis \ud83d\udc40","02b1d4cb":"## 1.2 Missing values treatment \ud83e\ude79","f03ec7a4":"> ### **VAR8** : Hydrometry_Monte_S_Quirico","a5d4748e":"So these two villages should record almost the same precipitation data, by plotting the two series on the same figure, we hardly notice some differences on some spikes , but in general the series have the same behaviour. so this must be the best source to fill in with.","5c3e7513":"Hence we'll drop out these two variables as well as the first part of the dataset suffering from massive losses (before the red line in missingno plot), data after the red line will benefit from imputing\/prediction techniques.","b6be02df":"> First thing we should do is to convert \"Date\" column to datetime object, and (optionally) convert other columns to float32 to avoid any oom errors in case you intend to use the dataset as an entry of a prediction model.","9a2bc732":"<br>\n\n\n\n\n\n<br>\n","edffd99c":"one year of missing values=365 days, the first idea coming to mind here is to train an ARIMA model on the second part (2010-2020) and try to predict the missing values using the first part (2006-2008), but if you have worked with rainfall data before, you probably know that it's so hard to modelize and a simple ARIMA model won't find the real pattern behind because the processus is more prone to randomness and needs accurate explanatory variables to be well estimated.\n\nthat said, let's give it a try to be certain.\n","7c13c9e3":"> ### **VAR6** : Depth_to_Groundwater_CoS","0fa8a661":"<img src= \"https:\/\/miro.medium.com\/max\/18000\/1*2c21SkzJMf3frPXPAR_gZA.png\" alt =\"boxplot\" style='width: 900px;'>","d9d538d4":"An important question should come to mind here, is what's the mechanism of missingness ? is it random (MAR), completely at random (MCAR), or not at random (MNAR)?\n\nbrief explanation for those having no idea what it is:\n> **MCAR** : when each observation have the same chance to be lost, it's the case when data is deleted by error, or not recorded by error. In this situation we can delete these observations if the percentage is low enough, but generally it's preferable to proceed with imputation technique(with mode, mean...), or interpolation for time series. Another appreciated technique if the percentage is high is prediction using machine learning models, the challenge here is to find the right features to be used as predictors, but if data is already anonymized, just forget about it.\n\n> **MAR** : when the missingness is related to one or more observed variable in the data set, for example, \"salary\" variable has missing values for people having \"age\" variable <16 years. This mechanism share the same filling techniques with MCAR, except deleting, it's not allowed to delete any data here because it affect the data distribution and any further analysis based on that will be biased.\n\n> **MNAR** : when the missingness is related to the variable itself, for example when  \"weight\" variable has missing values because concerned people are too obese and don't want to reveale their real weight. \nThis is the hardest one and fortunately the rarest, cause here we can't use simple imputation techniques (imagine you want to impute using the mean, and the average of weights is 73kg, an obese person has clearly more than 100 kg,  this wrong estimation will generate biased and non consistent results), the best way to deal with is prediction techniques if possible.\n\nIn most cases and when we don't know how data have been collected, it's very hard to figure out the mechanism. But going back to literature, we can easily find tons of climate and hydrometeorological studies, in which the presence of missing data is almost a usual thing, and mostly caused by external factors (sensors defection, incorrect measurement, instrument malfunction...etc), thus, we assume that our missing data is MCAR.\n\n\nAnother probably missing data can come out from outliers or invalid values. Boxplot is a very good statistical graph that gives you a good indication of how the values are spread out, about distribution and especially the existence of invalid values.\n\nhere is how the box plot looks like:","50427ed8":"* the boxplots show that in \"Volume_CSA\" and \"Volume_CSAl\" variables, the half of valid observations are null which is not realistic, let's investigate more","5737d6e5":"6 missing values, given the nature of the variable, 0 is the most common value, and the best value to fill in with in this case.\n","31ffb398":"Now let's plot the autocorrelation graphs\n","3e415b7a":"* The quantile $Qi$ is the obsevation that splits dataset into  $(25 * i)\\% $ and $(100-25 * i)\\% $ . Median= $Q2$  and $IQR = Q3 - Q1$ \n\n* Outliers are the observations that came beyond the extremity=$Qj \\pm 1.5IQR$  $\\;\\;\\;\\;\\;\\;$  $j=1,3$\n\nLet's see what we'll get from our data","92351d29":"> ### **VAR3** : Depth_to_Groundwater_LT2","aa761974":"> ### **VAR9** : Hydrometry_Piaggione","82435d51":"this variable is strongly volatil , and unfortunately the beginning part is missing, we'll use linear interpolation and mean imputation","100fd0f7":"the PACF is showing an AR(1) model, but we know that precipitations are yearly seasonal so let's take more lags into account","64bbb7dd":"Now for this last variable we may think that there is a data entry error, but according to the [data description](https:\/\/www.kaggle.com\/c\/acea-water-prediction\/data?select=datasets_description.xlsx), this variable can take both positive and negative values.","f22678e0":"For the other variables, we can't really judge about the existence of invalid values just only from boxplots, we may need to take a close look at each ","1763e199":"The autocorrelation at the crucial lags--namely lags 1 has been eliminated, and there is no discernible pattern in higher-order lags, this gives the impression that the residual series looks to be white noise. But looking at the last graph , it clearly shows non constance of the variance which means the existance of volatility . one tool helps reducing the variance is the logarithmic or BoxCox transformation with adding a very small constant to the time series in order to avoid null values, but in our case, it does not help that much, because we obtain a bimodal distribution after the transformation (you can try it), which is not helpful at all.\n\nThe squared residuals series follows an ARMA pattern (see the ACF and PACF below ). This confirm what we've just said .\n","c7956120":"### Other solution \n\nWithout losing hope, we can take advantage of rainfall data of villages next to \"Piaggione\" , the  dataset contains 9 villages, using google map, we can see their locations in relation to \"Piaggione\", the nearest one is \"Borgo_a_mozzano\" with a distance of nearly 9Km. see the two encircled points in the photo","f6de5082":"it seems that seasonality has a very small effect and deseasonalizing won't make the task easier. An ARIMA(1,0,0) should work as well as a SARIMA with D=365","a810ad9c":"### Small Intro\n<br>\n\nMissing data, is probably the first horror movie that you can watch when exploring your dataset, depending on the volume of missingness, and nature of variables you can try some good techniques with no guarantee of getting bias-free results, but in general, time series are known to be way more hard to handle and not all methods are applicable on them. In this notebook, we'll try to discover together what are the best techniques to impute holes in time series and what are techniques that you should never use.","c0617249":"**Interpretation:**\n\u200b\n>by looking at the pvalue of the t-test (**P>|z|**), we deduce that the coefficients are significative and none should be removed\n\u200b\n\n>the pvalue (**Prob(Q)**) of portemeanteau test indicates that autocorrelations of residual at all lags are nuls\n\u200b\n\n>the pvalue (**Prob(H)**) of homoscedasticity test indicates that variance of residuals is not constant and changes severly over time, -we'll see this more clearly in the next graphs-\n\u200b\n\n>the pvalue (**Prob(JB)**) of Jarque Bera test indicates that the distribution of residuals doesn't satisfy  normality hypothesis\n\u200b","9732ffa5":"<br>\n<br>\n\n#### **We'll use the same technique for the rest of variables since they share the same properties**","f87cdc9c":"this variable has a clear yearly seasonality and low variance(no trend), but full of holes and the beginning part is missing, so we can not use holt-winter model,  the best way to impute is using seasonal average","660d5df3":"this variable looks having a trendy behaviour with a yearly seasonality, a simple but a very strong model that can perfectly fit our data is the holt-winter additive model, to obtain accurate estimates, we will train the model on a first small chunk \\[2006 to 2011\\], then forecast only 1 future value, add this later to the chunk and retrain the model again, before each training step we check if the next value is missing or not, if not so no need to forecast, add the data to the chunk until the next missing point."}}