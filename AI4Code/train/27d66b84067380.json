{"cell_type":{"81fc27a8":"code","f4ee1e90":"code","afb9f0b9":"code","d11252bc":"code","735770f6":"code","b9250101":"code","02401116":"code","e53a5365":"code","dd897955":"code","74cb9822":"code","38d4541c":"code","d8026856":"code","d9e711c1":"code","75a42f45":"code","adb2174b":"code","479b1453":"code","d4d5756f":"code","7e513aa3":"code","a49d8499":"code","1fe907fd":"code","cf5b5552":"code","2ea3b593":"code","3cf1db33":"code","a580f8d1":"code","786afee3":"code","2b4eca77":"code","75a05359":"code","a096a2c1":"markdown","0e7848f3":"markdown","9604fab8":"markdown","e9e239c0":"markdown","b3e09a70":"markdown"},"source":{"81fc27a8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport pandas as pd\nfrom datetime import datetime\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nprint(os.listdir(\"..\/input\"))\n","f4ee1e90":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint(\"Train set size:\", train.shape)\nprint(\"Test set size:\", test.shape)\nprint('START data processing', datetime.now(), )\n","afb9f0b9":"train_ID = train['Id']\ntest_ID = test['Id']\n# Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain.drop(['Id'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)\nprint(train.shape)","d11252bc":"# Deleting outliers\ntrain = train[train.GrLivArea < 4500]\ntrain.reset_index(drop=True, inplace=True)\n\n# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\ny = train.SalePrice.reset_index(drop=True)\ntrain_features = train.drop(['SalePrice'], axis=1)\ntest_features = test\n\nfeatures = pd.concat([train_features, test_features]).reset_index(drop=True)\nprint(features.shape)\n# Some of the non-numeric predictors are stored as numbers; we convert them into strings \n\nfeatures['MSSubClass'] = features['MSSubClass'].apply(str)\nfeatures['YrSold'] = features['YrSold'].astype(str)\nfeatures['MoSold'] = features['MoSold'].astype(str)\n\nfeatures['Functional'] = features['Functional'].fillna('Typ')\nfeatures['Electrical'] = features['Electrical'].fillna(\"SBrkr\")\nfeatures['KitchenQual'] = features['KitchenQual'].fillna(\"TA\")\nfeatures['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0])\nfeatures['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\nfeatures['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n\nfeatures[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    features[col] = features[col].fillna(0)\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    features[col] = features[col].fillna('None')\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    features[col] = features[col].fillna('None')\n\nfeatures['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n\nobjects = []\nfor i in features.columns:\n    if features[i].dtype == object:\n        objects.append(i)\n\nfeatures.update(features[objects].fillna('None'))\n\nfeatures['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\n# Filling in the rest of the NA's\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics = []\nfor i in features.columns:\n    if features[i].dtype in numeric_dtypes:\n        numerics.append(i)\nfeatures.update(features[numerics].fillna(0))\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics2 = []\nfor i in features.columns:\n    if features[i].dtype in numeric_dtypes:\n        numerics2.append(i)\n\nskew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nfor i in skew_index:\n    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))\n\nfeatures = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n\nfeatures['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\nfeatures['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n\nfeatures['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n                                 features['1stFlrSF'] + features['2ndFlrSF'])\n\nfeatures['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n\nfeatures['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n                              features['EnclosedPorch'] + features['ScreenPorch'] +\n                              features['WoodDeckSF'])\n\n# simplified features\nfeatures['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n\nprint(features.shape)\nfinal_features = pd.get_dummies(features).reset_index(drop=True)\nprint(final_features.shape)","735770f6":"X = final_features.iloc[:len(y), :]\nX_sub = final_features.iloc[len(X):, :]\nprint('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\noutliers = [30, 88, 462, 631, 1322]\nX = X.drop(X.index[outliers])\ny = y.drop(y.index[outliers])\noverfit = []\nfor i in X.columns:\n    counts = X[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros \/ len(X) * 100 > 99.94:\n        overfit.append(i)\n\noverfit = list(overfit)\noverfit.append('MSZoning_C (all)')\n\nX = X.drop(overfit, axis=1).copy()\nX_sub = X_sub.drop(overfit, axis=1).copy()\n\nprint('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n# ################## ML ########################################\nprint('START ML', datetime.now(), )","b9250101":"import plotly.graph_objs as go\nimport plotly.plotly as py\nimport plotly.offline as pyo\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly_express as px\ninit_notebook_mode(connected=True)\nfrom matplotlib import cm\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans","02401116":"X.head()","e53a5365":"pca = PCA(n_components=50).fit(X)\n#Plotting the Cumulative Summation of the Explained Variance\nexpvar=np.cumsum(pca.explained_variance_ratio_)\ndata = [go.Scatter(y=expvar)]\nlayout = {'title': 'Review PCA Explained Variance to determine number of components'}\niplot({'data':data,'layout':layout})","dd897955":"pca = PCA(n_components=4)\nXPCA = pca.fit_transform(X)","74cb9822":"Nc = range(1,20)\nkmeans = [KMeans(i) for i in Nc]\nscore = [kmeans[i].fit(XPCA).score(XPCA) for i in range(len(kmeans))]","38d4541c":"data = [go.Scatter(y=score,x=list(Nc))]\nlayout = {'title':'Review Elbow Curve to determine number of clusters for KMeans'}\niplot({'data':data,'layout':layout})","d8026856":"n_clusters=5\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nXkmeans = kmeans.fit_predict(XPCA)","d9e711c1":"from sklearn.manifold import TSNE\nXTSNE = TSNE(n_components=2).fit_transform(XPCA)","75a42f45":"y.shape","adb2174b":"XTSNEdf = pd.concat([pd.DataFrame(XTSNE),pd.DataFrame(Xkmeans),pd.DataFrame(y),pd.DataFrame(np.expm1(y))],axis=1)\nXTSNEdf.columns = ['x1','x2','cluster','logprice','price']\npx.scatter(XTSNEdf,x='x1',y='x2',color='cluster',color_continuous_scale=px.colors.qualitative.Plotly,title=\"TSNE visualization of House Clusters\",width=800,height=500)","479b1453":"XTSNEdf.head()","d4d5756f":"px.scatter(XTSNEdf,x='x1',y='x2',color='price',hover_data=['price'], color_continuous_scale=px.colors.colorbrewer.Greens,title=\"TSNE visualization to check relationship with price\",width=1000,height=600)","7e513aa3":"px.density_contour(XTSNEdf, x=\"x1\", y=\"x2\", title=\"Contour plot to see distribution of data\")","a49d8499":"px.scatter_3d(XTSNEdf, x=\"x1\", y=\"x2\", z=\"price\", color='cluster',color_continuous_scale=px.colors.qualitative.Plotly, title=\"3D plotting of price against x1 and x2\")","1fe907fd":"px.violin(XTSNEdf, x=\"cluster\", y=\"price\",box=True, points='all', title=\"Violin plot to compare price distribution between clusters\")","cf5b5552":"def outside_limit(df, label_col, label, feature_list):\n  \n  plot_list = []\n  mean_overall_list = []\n  mean_cluster_list = []\n  \n  for i,varname in enumerate(feature_list):\n    \n    #     get overall mean for a variable, set lower and upper limit\n    mean_overall = df[varname].mean()\n    lower_limit = mean_overall - (mean_overall*0.7)\n    upper_limit = mean_overall + (mean_overall*0.7)\n\n    #     get cluster mean for a variable\n    cluster_filter = df[label_col]==label\n    pd_cluster = df[cluster_filter]\n    mean_cluster = pd_cluster[varname].mean()\n    \n    #     create filter to display graph with 0.5 deviation from the mean\n    if (mean_cluster <= lower_limit or mean_cluster >= upper_limit) and mean_cluster != 0:\n      plot_list.append(varname)\n      mean_overall_std = mean_overall\/mean_overall\n      mean_cluster_std = mean_cluster\/mean_overall\n      mean_overall_list.append(mean_overall_std)\n      mean_cluster_list.append(mean_cluster_std)\n   \n  mean_df = pd.DataFrame({'feature_list':plot_list,\n                         'mean_overall_list':mean_overall_list,\n                         'mean_cluster_list':mean_cluster_list})\n  mean_df = mean_df.sort_values(by=['mean_cluster_list'], ascending=False)\n  \n  return mean_df\n\ndef plot_barchart_all_unique_features(df, label_col, feature_list, label, ax):\n  mean_df = outside_limit(df, label_col, label, feature_list)\n  mean_df_to_plot = mean_df.drop(['mean_overall_list'], axis=1)\n  \n  plot_list = list(mean_df_to_plot.feature_list)\n  char = df.groupby(label_col)[feature_list].mean().reset_index(level=0,drop=True).reset_index()\n#   char = char.loc[char[label_col] == label, plot_list]\n  \n  if len(mean_df.index) != 0:\n    sns.barplot(y='feature_list', x='mean_cluster_list', data=mean_df_to_plot, color=\"maroon\", \\\n                alpha=0.75, dodge=True, ax=ax)\n\n    for i,p in enumerate(ax.patches):\n      ax.annotate(\"{:.02f}\".format((p.get_width())), \n                  (0.925, p.get_y() + p.get_height() \/ 2.), xycoords=('axes fraction', 'data'),\n                  ha='right', va='top', fontsize=10, color='black', rotation=0, \n                  xytext=(0, 0),\n                  textcoords='offset pixels')\n      \n#       ax.annotate(\"({0}%)\".format(round(char.iloc[:,i],4)*100), \n#                   (1.02, p.get_y() + p.get_height() \/ 2.), xycoords=('axes fraction', 'data'),\n#                   ha='right', va='top', fontsize=10, color='black', rotation=0, \n#                   xytext=(0, 0),\n#                   textcoords='offset pixels')\n      \n  \n  ax.set_title('Unique Characteristics of Cluster ' + str(label))\n  ax.set_xlabel('Standardized Mean')\n  ax.axvline(x=1, color='k')","2ea3b593":"XTSNEall = pd.concat([pd.DataFrame(Xkmeans),pd.DataFrame(X),pd.DataFrame(y),pd.DataFrame(np.expm1(y))],axis=1)\nXTSNEall.columns = ['cluster'] + list(X.columns) + ['logprice','price']","3cf1db33":"sns.set_context(\"paper\", font_scale=2) \nnumclusters = 5\nlabel = list(range(numclusters))\nfig, ax = plt.subplots(numclusters,1,figsize=(8,20*numclusters))\nfor i in range(numclusters):\n    plot_barchart_all_unique_features(XTSNEall, 'cluster', list(XTSNEall.columns)[1:], i, ax[i])","a580f8d1":"def visualize_dimension_reduction_per_cluster(type, df_components, cluster_no, labels, ax, cluster_desc):\n  \n  color_list = sns.color_palette(\"Paired\")\n#   plt.clf()\n#   plt.cla()\n#   plt.close()\n\n#   f, ax = plt.subplots(1,1, figsize = (20,20))\n  \n\n  for l in set(labels):\n    \n    if l == cluster_no:\n      sns.scatterplot(df_components.loc[df_components['cluster'] == l, 'x1'], df_components.loc[df_components['cluster'] == l, 'x2'], color = color_list[l], ax = ax, label=str(cluster_no))\n      ax.set_title(\"Cluster \" + str(l) + \" : \" + cluster_desc[l])\n    else:\n      sns.scatterplot(df_components.loc[df_components['cluster'] == l, 'x1'], df_components.loc[df_components['cluster'] == l, 'x2'], color = \"grey\", ax = ax)\n#   L=plt.legend()\n#   if time_of_day == \"Morning\":\n#     L.get_texts()[0].set_text('Current date {}'.format(after_date))\n#     L.get_texts()[1].set_text('Previous date {}'.format(before_date))\n#   else:\n#     L.get_texts()[0].set_text('Current date {}'.format(after_time))\n#     L.get_texts()[1].set_text('Current date {}'.format(before_time))\n#   display(f)\n\ndef plot_features_all_cluster(df, label_col, feature_list, label, cluster_desc):\n  plt.clf()\n  plt.cla()\n  plt.close()\n  \n  fig, ax = plt.subplots(len(label), 2, figsize=(16,15*numclusters), sharex='col')\n#   ax= ax.ravel()\n  \n#   label = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n  for i in label:\n#   for l in set(label):\n#     j = l % 2\n#     i = (l - j)\/2\n    plot_barchart_all_unique_features(df, label_col, feature_list, label=i, ax=ax[i,1])\n    ax[i,1].xaxis.set_tick_params(labelbottom=True)\n    \n    \n    visualize_dimension_reduction_per_cluster(\"TSNE\", df, i, label, ax[i,0], cluster_desc)\n  \n    \n    \n  plt.tight_layout()\n  plt.subplots_adjust(hspace = 0.4)\n  display(fig)","786afee3":"feature_columns = list(X.columns)\nXTSNEall2 = pd.concat([pd.DataFrame(XTSNE),XTSNEall],axis=1)\nXTSNEall2.columns = ['x1','x2'] + list(XTSNEall.columns)\nsns.set_context(\"paper\", font_scale=1.5) \ncluster_desc = {0: \"Generic\", \n                1: \"So Warm\", \n                2: \"Some Road Condition?\", \n                3: \"RRNn\", \n                4: \"Exterior\"}\nplot_features_all_cluster(XTSNEall2, 'cluster', feature_columns, label, cluster_desc)","2b4eca77":"n_clusters=10\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nXkmeans = kmeans.fit_predict(XPCA)\nXTSNE = TSNE(n_components=2).fit_transform(XPCA)\nXTSNEdf = pd.concat([pd.DataFrame(XTSNE),pd.DataFrame(Xkmeans),pd.DataFrame(y),pd.DataFrame(np.expm1(y))],axis=1)\nXTSNEdf.columns = ['x1','x2','cluster','logprice','price']\npx.scatter(XTSNEdf,x='x1',y='x2',color='cluster',color_continuous_scale=px.colors.qualitative.Plotly,title=\"TSNE visualization of House Clusters\",width=800,height=500)","75a05359":"XTSNEall = pd.concat([pd.DataFrame(Xkmeans),pd.DataFrame(X),pd.DataFrame(y),pd.DataFrame(np.expm1(y))],axis=1)\nXTSNEall.columns = ['cluster'] + list(X.columns) + ['logprice','price']\n\nnumclusters = 10\nlabel = list(range(numclusters))\nfeature_columns = list(X.columns)\nXTSNEall2 = pd.concat([pd.DataFrame(XTSNE),XTSNEall],axis=1)\nXTSNEall2.columns = ['x1','x2'] + list(XTSNEall.columns)\nsns.set_context(\"paper\", font_scale=1.5) \ncluster_desc = {}\nfor i in range(numclusters):\n    cluster_desc[i] = str(i)\nplot_features_all_cluster(XTSNEall2, 'cluster', feature_columns, label, cluster_desc)","a096a2c1":"# Overview\n\nWe have lots of houses. Lets cluster them to find out different types of houses.\n\nI will also play around with Plotly Express to test its features\n\nFor the feature engineering, I quickly pulled from [here](https:\/\/www.kaggle.com\/itslek\/blend-stack-lr-gb-0-10649-house-prices-v57)","0e7848f3":"# Just curious about having 10 clusters","9604fab8":"# Cluster characteristics","e9e239c0":"The explained variance saturates very quickly, passing 99% with only 4 components. So we'll reduce the dimensionality into 4 variables using PCA","b3e09a70":"# Now we're ready for clustering"}}