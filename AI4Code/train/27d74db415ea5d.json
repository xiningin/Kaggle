{"cell_type":{"7d271486":"code","c03031ae":"code","a2a5acf3":"code","b34b1f4a":"code","53f335b0":"code","05e3012a":"code","2816977d":"code","af91aebf":"code","26c07f8e":"code","7b4b110a":"code","8d4fc952":"code","993d568a":"code","d28d64b7":"code","9fad7175":"code","3a8735b7":"code","b37f85a2":"code","6e538573":"code","be9e077e":"code","f4be4728":"code","a5b37e84":"code","4208eeda":"code","1e63ce6f":"code","c906292d":"code","3323c975":"code","cc7d0d45":"code","e3a6a250":"code","fd7e013f":"code","0949f265":"code","e73cfe57":"code","c10ac1bf":"code","c6a293ce":"code","4e80664f":"code","f20b132e":"code","9abec66c":"code","2ef7f241":"code","bb929062":"code","1ed4162c":"code","a4dad910":"code","a8eef76c":"code","03c38958":"code","824dd5c1":"code","3ac55119":"code","c6aeda7f":"code","4a1e7f39":"code","7c288838":"code","113bf9a4":"code","03ff4c38":"code","646d352c":"code","1ec0e30e":"code","5d1c96fa":"code","12e39932":"code","2ff897d6":"code","4d92e5e0":"code","a5d67c5a":"code","b02a78b6":"code","94f7a387":"code","c9863a4c":"code","fe5bff8e":"code","feaa288e":"code","8b7729f8":"code","94a1ce49":"code","7ba5b6d7":"code","7ad49ad6":"code","56536cae":"code","ccd56ee8":"code","c3d89533":"code","5aa38f42":"code","5ba3bccf":"code","c018a8af":"code","d4c7e766":"code","1d0e876d":"code","64c31690":"code","71bf2bdf":"code","6e372019":"code","0e2e578c":"code","b768c113":"code","4fffc2a5":"code","f9faa53e":"code","f25b1600":"code","b327e4aa":"code","fc84b0d0":"code","754930f5":"code","a2696eb2":"code","96a8a3aa":"code","c0cdf0d2":"code","9b59df91":"code","8292a7e3":"code","36d4d385":"code","0fffe4fb":"code","9d0d9360":"code","a7615163":"code","fe92ef8f":"code","895aef4f":"code","5089144f":"code","1f99a442":"code","a7fea719":"markdown","610c1db8":"markdown","0e6b7cc2":"markdown","80268488":"markdown","0860e4d4":"markdown","aa88a5e0":"markdown","dd473eb0":"markdown","24b1081d":"markdown","3ff3abee":"markdown","17dba59b":"markdown","a941e109":"markdown","876b28fe":"markdown","c8831b0c":"markdown","907e4c54":"markdown","942e19c4":"markdown","ec55425b":"markdown","8cbf1171":"markdown","213127eb":"markdown","2a425f02":"markdown","1fcc39e7":"markdown","8b4e6b76":"markdown","91e4d57f":"markdown","1905ec29":"markdown","2f797731":"markdown","7b854dce":"markdown","5815f619":"markdown","8d13f2df":"markdown","6c375ce4":"markdown","a146be8a":"markdown","032d1db0":"markdown","06d54da1":"markdown","a202b3a8":"markdown","5c2e488d":"markdown"},"source":{"7d271486":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing \nfrom category_encoders import *\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline\nfrom sklearn import datasets, linear_model, metrics\nfrom sklearn.metrics import  confusion_matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix","c03031ae":"df = pd.read_csv(\"..\/input\/the-world-of-pokemons\/pokemons dataset.csv\",encoding='latin-1')\ndf","a2a5acf3":"\n# Exploratory Data Analysis\ndef libraries():\n    global pd,np\n    import pandas as pd\n    import numpy as np\ndef load():\n    global df\n    df=pd.read_csv('..\/input\/the-world-of-pokemons\/pokemons dataset.csv',encoding='latin-1')\n    \ndef top_rows(value):\n    print('\\033[1m'+ 'displaying the', value, 'rows from top'+'\\033[0m')\n    a=df.head(value)\n    print(a,'\\n')\n    \ndef bottom_rows(value):\n    print('\\033[1m'+'displaying the', value, 'rows from bottom'+'\\033[0m')\n    b=df.tail(value)\n    print(b,'\\n')\n    \ndef rows_columns():\n    print('\\033[1m'+'Shape of the Data set'+'\\033[0m')\n    c=df.shape\n    print(c,'\\n')\n    \ndef col_names():\n    print('\\033[1m'+'Column Names in the Data set'+'\\033[0m')\n    d=df.columns\n    print(d,'\\n')\n    \ndef information():\n    print('\\033[1m'+'Quick Overview of DataSet(info)'+'\\033[0m')\n    e = df.info()\n    print(e,'\\n')\n\ndef sizee():\n    print('\\033[1m'+'No.of Elements in the DataSet'+'\\033[0m')\n    f = df.size\n    print(f,'\\n')\n\ndef ndimension():\n    print('\\033[1m'+'Dimensions in your dataframe'+'\\033[0m')\n    g = df.ndim\n    print(g,'\\n')\n    \ndef stats_summary():\n    print('\\033[1m'+'Staistical Summary of DataSet'+'\\033[0m')\n    h = df.describe()\n    print(h,'\\n')\n    \ndef null_values():\n    print('\\033[1m'+'Number of Missing values in each column'+'\\033[0m')\n    i = df.isnull().sum()\n    print(i,'\\n')\n    \ndef n_unique():\n    print('\\033[1m'+'Number of unique elements'+'\\033[0m')\n    j = df.nunique()\n    print(j,'\\n')\n    \ndef memory_use():\n    print('\\033[1m'+'Memory used by all colomns in bytes'+'\\033[0m')\n    k = df.memory_usage()\n    print(k,'\\n')\n    \ndef is_na(value):\n    print('\\033[1m'+'Dataframe filled with boolean values with true indicating missing values'+'\\033[0m')\n    l = df.isna().head(value)\n    print(l,'\\n')\n    \ndef duplicate():\n    print('\\033[1m'+'Boolean Series denoting duplicate rows'+'\\033[0m')\n    m = df.duplicated().sum()\n    print(m,'\\n')\n    \ndef valuecounts():\n    print('\\033[1m'+'Series containing count of unique values'+'\\033[0m')\n    n = df.value_counts()\n    print(n,'\\n')\n\ndef datatypes():\n    print('\\033[1m'+'Datatype of each column'+'\\033[0m')\n    o = df.dtypes\n    print(o,'\\n')\n    \ndef correlation():\n    print('\\033[1m'+'Correalation between all columns in DataFrame'+'\\033[0m')\n    p = df.corr()\n    print(p,'\\n')\n    \ndef nonnull_count():\n    print('\\033[1m'+'Count of non-null values'+'\\033[0m')\n    q = df.count()\n    print(q,'\\n')\n    \ndef eda():\n    load()\n    value= 5 \n    datatypes()\n    top_rows(value)\n    bottom_rows(value)\n    rows_columns()\n    col_names()\n    information()\n    sizee()\n    ndimension()\n    stats_summary()\n    null_values()\n    n_unique()\n    memory_use()\n    is_na(value)\n    nonnull_count()\n    duplicate()\n    valuecounts()\n    correlation()\n    \n    \n    \n        \ndef stats_u(data,col):\n    if data[col].dtype == \"float64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        max_value = data[col].max()\n        print('Maximum value of',col,'column',max_value)\n        min_value = data[col].min()\n        print('Minimum value of',col,'column',min_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n            \n    elif data[col].dtype == \"int64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(\"Outliers are:\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n    else:\n        print(col,'has Qualitative Data')\n        z = df[col].mode()\n        print('mode of',col,'column:\\n',z)\n        print('Count of mode is:\\n',df[col].value_counts())\n        print('Unique strings in',col,'are',data[col].nunique())\n        if(data[col].nunique() == 1):\n            print(col,'has same string')\n        elif(data[col].nunique() == 2):\n            print(col,'has binary strings')\n        else:\n            print(col,'has multi stings')\n\n\nlibraries()\neda()\n\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of DataSet'+'\\033[0m')\nprint('\\033[1m'+'DataTypes in the DataSet:\\n'+'\\033[0m',df.dtypes)\nprint('\\033[1m'+'Columns in DataSet:'+'\\033[0m',df.columns)\nprint('\\033[1m'+'Shape of DataSet:'+'\\033[0m',df.shape)\nprint('\\033[1m'+'Size of DataSet:'+'\\033[0m',df.size)\nprint('\\033[1m'+'Dimension of DataSet:'+'\\033[0m',df.ndim)\nprint('\\033[1m'+'Total Memory used in DataSet:'+'\\033[0m',df.memory_usage().sum())\nprint('\\033[1m'+'Total Number of missing values in DataSet:'+'\\033[0m',df.isnull().sum().sum())\nprint('\\033[1m'+'Total Number of Unique values in DataSet:'+'\\033[0m',df.nunique().sum())\nprint('\\033[1m'+'Total Number of non null values in DataSet:'+'\\033[0m',df.count().sum())\nprint('\\033[1m'+'Total Number of duplicate rows in DataSet:'+'\\033[0m',df.duplicated().sum())\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of Each Colomn'+'\\033[0m')\nprint(\"\\n\")\ncols=df.columns\ncols\nfor i in cols:\n    print('\\033[1m'+i+'\\033[0m')\n    stats_u(df,i)\n    print(\"\\n\")\n            ","b34b1f4a":"df.head()","53f335b0":"df.tail()","05e3012a":"df.dtypes","2816977d":"df.columns","af91aebf":"df.info()","26c07f8e":"df.describe()","7b4b110a":"df.isnull().sum()","8d4fc952":"df.duplicated().sum()","993d568a":"df.skew()","d28d64b7":"df.corr()","9fad7175":"df.shape","3a8735b7":"df.size","b37f85a2":"df.isnull().sum()","6e538573":"df.drop(['Name2','Secondary type'],axis = 1,inplace = True)","be9e077e":"df","f4be4728":"df.isnull().sum() # no null values","a5b37e84":"df.skew()","4208eeda":"df.corr()","1e63ce6f":"from IPython.core.display import HTML\n\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","c906292d":"df_nunique = {var: pd.DataFrame(df[var].value_counts()) \n              for var in {'Name','Primary Type'}}\nmulti_table([df_nunique['Name'], df_nunique['Primary Type']])","3323c975":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df.corr(),annot = True,cmap = 'viridis')\nplt.show()","cc7d0d45":"''' Plot a Shifted Correlation Matrix '''\n# Diagonal correlation is always unity & less relevant, shifted variant shows only relevant cases\ndef corrMat(df,id=False):\n    \n    corr_mat = df.corr().round(2)\n    f, ax = plt.subplots(figsize=(12,7))\n    mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n    mask = mask[1:,:-1]\n    corr = corr_mat.iloc[1:,:-1].copy()\n    sns.heatmap(corr,mask=mask,vmin=-0.3,vmax=0.3,center=0, \n                cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n#     bottom, top = ax.get_ylim() \n#     ax.set_ylim(bottom + 0.5, top - 0.5) \n    ax.set_title('Shifted Linear Correlation Matrix')\n    \ncorrMat(df.drop(['Name','Primary Type'],axis = 1))","e3a6a250":"'''Plot Correlation to Target Variable only'''\ndef corrMat2(df,target='Total',figsize=(9,0.5),ret_id=False):\n    \n    corr_mat = df.corr().round(2);shape = corr_mat.shape[0]\n    corr_mat = corr_mat.transpose()\n    corr = corr_mat.loc[:, df.columns == target].transpose().copy()\n    if(ret_id is False):\n        f, ax = plt.subplots(figsize=figsize)\n        sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, \n                     cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n        plt.title(f'Feature Correlation to {target}')\n    \n    if(ret_id):\n        return corr\ncorrMat2(df.drop(['Name','Primary Type'],axis = 1))","fd7e013f":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='Primary Type',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = df.columns[1:]\nsnsPairGrid(df[numvars_targ])","0949f265":"df.columns","e73cfe57":"df['Name'].value_counts()","c10ac1bf":"len(np.where(df['Name'].value_counts() == 1)[0])\n# 776 names not repeated ","c6a293ce":"# 104 names repeated 2 times\nlen(np.where(df['Name'].value_counts() == 2)[0])","4e80664f":"len(np.where(df['Name'].value_counts() == 3)[0])\n# 9 names repeated 3 times","f20b132e":"len(np.where(df['Name'].value_counts() == 4)[0])\n# 7 names repeated 4 times","9abec66c":"len(np.where(df['Name'].value_counts() == 6)[0])\n# 1 name repeated 6 times","2ef7f241":"sns.countplot(x = df['Name'].value_counts(),data = df)\nplt.show()","bb929062":"df['Primary Type'].value_counts()","1ed4162c":"sns.countplot(x = 'Primary Type',data = df)\nsns.set(rc={'figure.figsize':(17,17)})\nplt.show()","a4dad910":"obj = ['Name','Primary Type']\nnum = ['Attack', 'Defense', 'HP', 'Sp.Attack',\n       'Sp.Defense', 'Speed', 'Total']","a8eef76c":"data=df.copy()\ndata.groupby('Primary Type')['Attack'].mean().plot.bar()\nplt.xlabel('Primary Type')\nplt.ylabel('Attack')\nplt.title('Primary Type')\nplt.show()\n\n# primary type dragon has more attaking ability\n# primary type fairy as less attacking ability","03c38958":"data=df.copy()\ndata.groupby('Primary Type')['Defense'].mean().plot.bar()\nplt.xlabel('Primary Type')\nplt.ylabel('Defense')\nplt.title('Primary Type')\nplt.show()\n\n# primary type STEEL has high defense ability\n# primary type normal has less defense ability","824dd5c1":"data=df.copy()\ndata.groupby('Primary Type')['HP'].mean().plot.bar()\nplt.xlabel('Primary Type')\nplt.ylabel('HP')\nplt.title('HP')\nplt.show()\n\n# primary type DRAGON has high Hp\n# primary type BUG has less HP","3ac55119":"data=df.copy()\ndata.groupby('Primary Type')['Sp.Attack'].mean().plot.bar()\nplt.xlabel('Primary Type')\nplt.ylabel('Sp.Attack')\nplt.title('Primary Type')\nplt.show()\n\n# PSYCHIC has highest Sp.Attack\n# ground has lowest Sp.attack","c6aeda7f":"data=df.copy()\ndata.groupby('Primary Type')['Sp.Defense'].mean().plot.bar()\nplt.xlabel('Primary Type')\nplt.ylabel('Sp.Defense')\nplt.title('Primary Type')\nplt.show()\n\n# Fairy has highest Sp.defense\n# Ground has lowest Sp.Defense","4a1e7f39":"data=df.copy()\ndata.groupby('Primary Type')['Speed'].mean().plot.bar()\nplt.xlabel('Primary Type')\nplt.ylabel('Speed')\nplt.title('Primary Type')\nplt.show()\n\n# primary type flying has highest speed\n# primary type STEEL has lowest speed","7c288838":"data=df.copy()\ndata.groupby('Primary Type')['Total'].mean().plot.bar()\nplt.xlabel('Primary Type')\nplt.ylabel('Total')\nplt.title('Primary Type')\nplt.show()\n\n# Primary type electric has highest total\n# primary type bug has lowest total","113bf9a4":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'Attack':\n        sns.scatterplot(x= 'Attack',y=num[j],hue='Primary Type',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","03ff4c38":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'Defense':\n        sns.scatterplot(x= 'Defense',y=num[j],hue='Primary Type',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","646d352c":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'HP':\n        sns.scatterplot(x= 'HP',y=num[j],hue='Primary Type',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","1ec0e30e":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'Sp.Attack':\n        sns.scatterplot(x= 'Sp.Attack',y=num[j],hue='Primary Type',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","5d1c96fa":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'Sp.Defense':\n        sns.scatterplot(x= 'Sp.Defense',y=num[j],hue='Primary Type',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","12e39932":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'Total':\n        sns.scatterplot(x= 'Total',y=num[j],hue='Primary Type',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","2ff897d6":"plt.figure(figsize=(6,8))\nx = df.drop(obj,axis = 1)\nfor i in x.columns:\n    sns.histplot(x[i],kde = True)\n    plt.show()","4d92e5e0":"x = df.drop(obj,axis = 1)\nfor i in x.columns:\n    sns.boxplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","a5d67c5a":"x = df.drop(obj,axis = 1)\nfor i in x.columns:\n    sns.violinplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","b02a78b6":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'Speed':\n        sns.scatterplot(x= 'Speed',y=num[j],hue='Primary Type',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')\n        \n        \n# Speed is positively corelated with attack,sp.attack,total","94f7a387":"for j in range(len(num)):\n    if num[j] != 'Speed':\n        sns.scatterplot(x= 'Speed',y=num[j],data=df)\n        plt.show()","c9863a4c":"df1 = df.groupby('Primary Type').agg({'Attack' : 'mean', 'Defense' : 'mean', 'HP' : 'mean', 'Sp.Attack' : 'mean',\n       'Sp.Defense' : 'mean', 'Speed' : 'mean', 'Total' : 'mean'})\ndf1","fe5bff8e":"px.bar(data_frame=df1.drop('Total',axis = 1), barmode='group',\n       title = \"<b>Primary Type wise Analyzing<\/b>\",template=\"plotly_dark\")","feaa288e":"df2 = df.groupby('Primary Type').agg({'Attack' : 'max', 'Defense' : 'max', 'HP' : 'max', 'Sp.Attack' : 'max',\n       'Sp.Defense' : 'max', 'Speed' : 'max', 'Total' : 'max'})\ndf2# max value in respective type in each column","8b7729f8":"px.bar(data_frame=df2.drop('Total',axis = 1), barmode='group',\n       title = \"<b>Primary Type wise Analyzing<\/b>\",template=\"plotly_dark\")","94a1ce49":"df3 = df.groupby('Primary Type').agg({'Attack' : 'min', 'Defense' : 'min', 'HP' : 'min', 'Sp.Attack' : 'min',\n       'Sp.Defense' : 'min', 'Speed' : 'min', 'Total' : 'min'})\ndf3# min value in respective type in each column","7ba5b6d7":"px.bar(data_frame=df3.drop('Total',axis = 1), barmode='group',\n       title = \"<b>Primary Type wise Analyzing<\/b>\",template=\"plotly_dark\")","7ad49ad6":"px.bar(data_frame=df1['Total'], barmode='group',\n       title = \"<b>Primary Type wise Analyzing<\/b>\",template=\"plotly_dark\")\\\n# average total highest in dragon","56536cae":"px.bar(data_frame=df2['Total'], barmode='group',\n       title = \"<b>Primary Type wise Analyzing<\/b>\",template=\"plotly_dark\")\n# max value of total in poison","ccd56ee8":"px.bar(data_frame=df3['Total'], barmode='group',\n       title = \"<b>Primary Type wise Analyzing<\/b>\",template=\"plotly_dark\")\n# min value of total in water","c3d89533":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nfor i in x.columns:\n    count_outliers(x,i)\n    \n    \n# less outliers no need to rectify","5aa38f42":"df.columns","5ba3bccf":"Num_vars = ['Attack', 'Defense', 'HP', 'Sp.Attack','Sp.Defense', 'Speed', 'Total']","c018a8af":"Cat_vars = df.drop(Num_vars, axis = 1).columns.tolist()\nCat_vars","d4c7e766":"Cat_vars_low = list(df[Cat_vars].loc[:, (df[Cat_vars].nunique() < 10)].nunique().index)\nCat_vars_high = list(df[Cat_vars].loc[:, (df[Cat_vars].nunique() >= 10)].nunique().index)","1d0e876d":"sns.set_theme(rc = {'grid.linewidth': 0.5,\n                    'axes.linewidth': 0.75, 'axes.facecolor': '#fff3e9', 'axes.labelcolor': '#6b1000',\n                    'figure.facecolor': '#f7e7da'})\n                    #'xtick.labelcolor': '#6b1000', 'ytick.labelcolor': '#6b1000'","64c31690":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(2, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['Total']), \n                        hue =  np.log(df['Total']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","71bf2bdf":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(3, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['Attack']), \n                        hue =  np.log(df['Attack']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","6e372019":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(3, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['Defense']), \n                        hue =  np.log(df['Defense']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","0e2e578c":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(3, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['Sp.Attack']), \n                        hue =  np.log(df['Sp.Attack']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","b768c113":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(3, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['Sp.Defense']), \n                        hue =  np.log(df['Sp.Defense']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","4fffc2a5":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(3, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['Speed']), \n                        hue =  np.log(df['Speed']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","f9faa53e":"train_num_visual_0 = df.select_dtypes(include = ['int64']).columns.tolist()","f25b1600":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(2, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['Total'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","b327e4aa":"list(zip(Num_vars, ax_0.flatten()))","fc84b0d0":"list(enumerate(zip(Num_vars, ax_0.flatten())))","754930f5":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['Primary Type']].columns.tolist()","a2696eb2":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['Total'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['Total'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['Total'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","96a8a3aa":"df_groupby = {var: pd.DataFrame(df.groupby([var, 'Total']).size()) \n              for var in {'Primary Type'}}","c0cdf0d2":"multi_table([df_groupby['Primary Type']])","9b59df91":"df=pd.get_dummies(data=df,columns=['Primary Type'],drop_first=True)\ndf.drop('Name',axis = 1,inplace = True)\n# dropping name because it is not important","8292a7e3":"df","36d4d385":"df = df[['Attack', 'Defense', 'HP', 'Sp.Attack', 'Sp.Defense','Total',\n       'Primary Type_DARK', 'Primary Type_DRAGON', 'Primary Type_ELECTRIC',\n       'Primary Type_FAIRY', 'Primary Type_FIGHTING', 'Primary Type_FIRE',\n       'Primary Type_FLYING', 'Primary Type_GHOST', 'Primary Type_GRASS',\n       'Primary Type_GROUND', 'Primary Type_ICE', 'Primary Type_NORMAL',\n       'Primary Type_POISON', 'Primary Type_PSYCHIC', 'Primary Type_ROCK',\n       'Primary Type_STEEL', 'Primary Type_WATER','Speed']]","0fffe4fb":"df","9d0d9360":"X = df.drop(['Total'],axis = 1)\nY = df['Total']\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2,random_state=44)","a7615163":"from sklearn.ensemble import RandomForestRegressor\nforest= RandomForestRegressor(n_estimators =40, random_state = 0)\nforest.fit(X_train,Y_train)  \ny_pred = forest.predict(X_test)\nforest.score(X_test,Y_test)","fe92ef8f":"plt.scatter(Y_test,y_pred)\nplt.xlabel('Y Test (True Values)')\nplt.ylabel('Predicted values')\nplt.show()","895aef4f":"metrics.explained_variance_score(Y_test,y_pred)","5089144f":"print('MAE',metrics.mean_absolute_error(Y_test,y_pred))\nprint('MSE',metrics.mean_squared_error(Y_test,y_pred))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(Y_test,y_pred)))","1f99a442":"sns.displot(Y_test-y_pred,bins = 50,kde = True)","a7fea719":"# Feature Selection","610c1db8":"## Boxplot of numerical columns","0e6b7cc2":"# Count of Outliers","80268488":"## Encoding","0860e4d4":"# Prediction using RandomForest Regressor","aa88a5e0":"## Getting unique values of each category","dd473eb0":"## average Attacking for dragon is more \n## average defense for steel is more\n## average HP for dragon is more\n## average sp.Attack is more for PSYSIC\n## average sp.defense is more for fairy\n## average speed is more for flying","24b1081d":"## Now I will plot scatter plots between numerical columns with Primary Type as hue","3ff3abee":"## Scatterplot of target column(speed)","17dba59b":"## UPVOTE IF U LIKE","a941e109":"# Importing Libraries","876b28fe":"## Checking corelation and skewness again","c8831b0c":"## max value of attack is in bug\n## max value of defense in poison\n## max value of hp in normal,poison\n## max value of sp.attack in pyschic\n## max value of sp.defense in poison\n## max value of speed in felectric\n### from this we can say poison is most dangerous","907e4c54":"# (IMPORTANT) Analysis using groupby","942e19c4":"## Histolot of numerical column","ec55425b":"## since there are many null values in Name2 and secondary type we can drop those columns","8cbf1171":"## violin plot of numerical columns","213127eb":"## grouped tables for categorical variables","2a425f02":"## here we cant plot countplot for 827 names so we will plot for names greather than 2","1fcc39e7":"## We can easily visualse from above graphs","8b4e6b76":"# Loading DataSet","91e4d57f":"## checking null values again","1905ec29":"## ploting count plot for categorical column","2f797731":"## Scatterplots","7b854dce":"# Exploratory Data Analysis","5815f619":"## minimum value of attack in normal\n## minimun value of defense in normal\n## min value of hp in bug\n## min value of sp.attack in bug\n## min value od sp.defense in bug,normal,psychic,rock,water\n## min value of speed in bug,water,normal","8d13f2df":"## Now I will plot groupby of categorical column(Primary Type) with average values numerical columns ","6c375ce4":"# Advanced Data visualisation","a146be8a":"# Data Visualisation","032d1db0":"# Exploratory Data Analysis Using Userdefined Function","06d54da1":"## Rearranging Columns","a202b3a8":"# Basic Data Cleaning","5c2e488d":"# Data Preprocessing"}}