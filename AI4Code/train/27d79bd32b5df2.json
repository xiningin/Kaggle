{"cell_type":{"cdcb7be9":"code","fb84da69":"code","306220b4":"code","9c09a40f":"code","b5adf0b8":"code","76b2c4e0":"code","16792f72":"code","478faa48":"code","88609c92":"code","c4b0f030":"code","25de08fc":"code","c9493375":"code","054e3575":"code","0848c246":"code","c020703b":"code","096344c0":"code","3b342e82":"code","d122932a":"code","388f114e":"markdown","904fecd8":"markdown","219b843c":"markdown","05f3e059":"markdown","22bd14f1":"markdown","1aa0bf1a":"markdown"},"source":{"cdcb7be9":"# Call libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n# Check version of sklearn.\n# There should not be any assertion error\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"","fb84da69":"#Read dataset\nX = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\")","306220b4":"X.shape\nX.head()","9c09a40f":"#Copy the first column 'label' (target) to 'y' array and remove it\ny = X.pop('label')","b5adf0b8":"y.head()","76b2c4e0":"X.shape     \ny.shape     ","16792f72":"# Split dataset. Default split test-size is 0.25\nX_train, X_test, y_train, y_test = train_test_split(X, y)","478faa48":"X_train.shape\nX_test.shape\ny_train.shape\ny_test.shape","88609c92":"# Train PCA on dataset\npca = PCA()\npca.fit(X_train)","c4b0f030":"# Get statistics from pca\n# How much variance is explained by each principal component\npca.explained_variance_ratio_[:10]\n# Cumulative sum of variance of each principal component\ncumsum = np.cumsum(pca.explained_variance_ratio_)\ncumsum[:10]","25de08fc":"# Get the column (principal component) number \n# when cum explained variance threshold just exceeds 0.95\nd = np.argmax(cumsum >= 0.95) + 1\nd   ","c9493375":"#  Let us also plot cumsum - Saturation occurs are Elbow\nabc = plt.figure(figsize=(6,4))\nabc = plt.plot(cumsum, linewidth=3)\nabc = plt.axis([0, 400, 0, 1])\nabc = plt.xlabel(\"Dimensions\")\nabc = plt.ylabel(\"Explained Variance\")\n# Draw a (vertical) line from (d,0) to (d,0.95) - Should be black and dotted\nabc = plt.plot([d, d], [0, 0.95], \"k:\")\n# Draw another dotted (horizontal) line - from (0,0.95) to (d,0.95)\nabc = plt.plot([0, d], [0.95, 0.95], \"k:\")\n# Draw a point at (d,0.95)\nabc = plt.plot(d, 0.95, \"ko\")\n# Annotate graph\nabc = plt.annotate(\"Elbow\", xy=(40, 0.81), xytext=(60, 0.65), arrowprops=dict(arrowstyle=\"->\"), fontsize=16)\nplt.grid(True)\nplt.show()","054e3575":"# Get transformed dataset upto 95%\n# explained variance\npca = PCA(n_components=0.95)\nX_reduced = pca.fit_transform(X_train)","0848c246":"pca.n_components_\nX_reduced.shape","c020703b":"# Recheck sum of explained variance\nnp.sum(pca.explained_variance_ratio_)","096344c0":"# Use PCA's function inverse_transform() to get origianl\n# dimensions back from reduced dimesionality\nX_recovered = pca.inverse_transform(X_reduced)","3b342e82":"X_recovered.shape     ","d122932a":"# Plot few digits from original dataset\n# Digit shapes\nfig,axe = plt.subplots(2,5)\naxe = axe.flatten()\nfor i in range(10):\n    abc = axe[i].imshow(X_train.iloc[i,:].to_numpy().reshape(28,28))\n\n# And few digits from compressed dataset\n# And compare both\nfig,axe = plt.subplots(2,5)\naxe = axe.flatten()\nfor i in range(10):\n    abc = axe[i].imshow(X_recovered[i,:].reshape(28,28))\n","388f114e":"### Scope\nAny image contains lots of redundant data. For example, many adjoining pixels would have the same color. Therefore, there is a huge scope to reduce the number of columns in an image using PCA. This example shows how even by reducing dimensionality of any image in this dataset from 1 X 784 to 1 X 187, image is till preserved and when plotted is clearly recognizable.","904fecd8":"\n## Fashion MNIST Exercise to study how PCA can achieve data compression\n\n### By Ezhilarasan Kannaiyan ","219b843c":"## What is Fashion-MNIST Dataset?\nFashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.","05f3e059":"Our scope now is to apply reverse transform of pca to get from 187 to 784 (back to original shape) and check the quality of the image.","22bd14f1":"Shape is reduced from 784 to 187. ","1aa0bf1a":"## Conclusion: \n\nThere is not much difference between original images (first 10 images) and compressed (PCA applied) images (last 10 images).\n\nTherefore, \n- There is a huge scope to reduce the number of columns in an image using PCA. \n- Eventhough dimensionality of the image is reduced from 784 to 187 pixels, image is till preserved.\n- When the image is plotted, it is clearly recognizable.\n"}}