{"cell_type":{"c6c8a7c1":"code","59adc29a":"code","813e7257":"code","eec7bdd7":"code","7e5c0657":"code","a63362b8":"code","f3f4f2b7":"code","b346dd25":"code","abe595c5":"code","a7a6cca7":"code","6b8fb884":"code","174625a2":"code","5dbb639b":"code","423808e1":"code","8c73943b":"code","ad80b7bd":"code","f7de9b2d":"code","6e46cf93":"code","b0c6516b":"code","cecb9229":"code","938fbe87":"markdown"},"source":{"c6c8a7c1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","59adc29a":"import re\nimport nltk\nnltk.download(\"stopwords\")\nnltk.download('punkt')\nfrom nltk import word_tokenize,sent_tokenize\nnltk.download('wordnet')\nimport nltk as nlp","813e7257":"df = pd.read_csv('..\/input\/australian-election-2019-tweets\/auspol2019.csv',encoding='utf8')\ndf.head()","eec7bdd7":"cult_list=[]\n\nfor cult in df.full_text:\n    cult=re.sub(\"[^a-zA-z]\",\" \",cult)\n    cult=cult.lower()\n    cult=nltk.word_tokenize(cult)\n    lemma=nlp.WordNetLemmatizer()\n    cult=[lemma.lemmatize(word) for word in cult]\n    cult=\" \".join(cult)\n    cult_list.append(cult)","7e5c0657":"from sklearn.feature_extraction.text import CountVectorizer\n\nmax_features=800\ncount_vectorizer=CountVectorizer(max_features=max_features,stop_words=\"english\")\nsparce_matrix=count_vectorizer.fit_transform(cult_list).toarray()","a63362b8":"sparce_matrix.shape ","f3f4f2b7":"sparce_matrix","b346dd25":"print(\"Top {} the most used words: {}\".format(max_features,count_vectorizer.get_feature_names()))","abe595c5":"data = pd.DataFrame(count_vectorizer.get_feature_names(),columns=[\"Words\"])\ndata[0:10]","a7a6cca7":"from wordcloud import WordCloud \nimport matplotlib.pyplot as plt\n\nplt.subplots(figsize=(10,10))\nwordcloud=WordCloud(background_color=\"black\",width=1024,height=768).generate(\" \".join(data.Words[0:100]))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","6b8fb884":"X=sparce_matrix[0:20000]\ny0=df.favorite_count[0:20000]\n\ny1=[]\nfor item in y0:\n    y1+=[int(np.log1p(item))]\ny=pd.Series(y1)\n\nprint(X.shape)\nprint(y.shape)","174625a2":"X[0]","5dbb639b":"print(y.value_counts())","423808e1":"from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report,log_loss,precision_score\nfrom sklearn.metrics import roc_auc_score,roc_curve\n\nfrom lightgbm import LGBMClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8c73943b":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","ad80b7bd":"lgbm_model = LGBMClassifier()\nlgbm_model.fit(X_train,y_train)\ny_pred = lgbm_model.predict(X_test)","f7de9b2d":"print(\"Accuracy:\",accuracy_score(y_test,y_pred))","6e46cf93":"df1=df[['favorite_count','full_text']].copy()\ndf1","b0c6516b":"df2=df1.sort_values(by=['favorite_count'],ascending=False).reset_index()\ndf2","cecb9229":"for i in range(8):\n    print('['+str(i+1)+'] '+df2['full_text'][i])","938fbe87":"NLTK is a leading platform for building Python programs to work with human language data.\nhttps:\/\/www.nltk.org\/"}}