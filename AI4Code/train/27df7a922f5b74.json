{"cell_type":{"6fb74624":"code","b479f8f4":"code","f6ed3105":"code","ccb69c99":"code","c891d07f":"code","01644285":"code","3c7208b5":"code","b6c29d5c":"code","3bd635bd":"code","d07b2abe":"code","afcab73e":"code","994505ec":"code","ecc382b6":"code","c458efb8":"code","5e21ca61":"code","0e558ba3":"code","7f1aecc9":"code","4f220999":"code","0a13fd83":"code","2a393710":"code","1e48b900":"code","2623b70a":"code","42f76e25":"code","538afc55":"markdown","e0df1250":"markdown","f0c02c70":"markdown","1390a4b0":"markdown","021e2a52":"markdown","e6dbfb0a":"markdown","f07165e9":"markdown","3a960886":"markdown","7ce749fe":"markdown","72ef4e4e":"markdown","322ab293":"markdown","5a011180":"markdown","6ff2a9e0":"markdown","fa9715cf":"markdown","b4ac3a1d":"markdown","96e29016":"markdown","b518a2bd":"markdown","21c2fe0e":"markdown","6dd09171":"markdown","97268bf2":"markdown","076a4307":"markdown","ce875176":"markdown","7fa95aa7":"markdown","c6022727":"markdown"},"source":{"6fb74624":"# To do linear algebra\nimport numpy as np\n\n# To store data\nimport pandas as pd\n\n# To create interactive plots\nimport plotly.graph_objects as go","b479f8f4":"# Read the csv file\ndf = pd.read_csv('..\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv')\n\nprint('{} entries are in the file.'.format(df.shape[0]))\nprint('{} columns are in the file.'.format(df.shape[1]))\nprint('\\nThese are some sampled entries:')\ndf.sample(3)","f6ed3105":"def countUniqueAndNAN(df, column):\n    '''\n    Counts and prints the number of empty, filled and unique values for a column in a dataframe\n    \n    Input:\n    df - dataframe to use\n    column - column to inspect\n    \n    Output:\n    '''\n    \n    \n    # If there are empty values in the column\n    if df[column].isna().sum():\n    \n        # Count the filled and empty values in the column\n        tmp_dict = df[column].isna().value_counts().to_dict()\n\n    else:\n        tmp_dict = {False: len(df[column]), True: 0}\n        \n    print('The column \"{}\" has:\\n\\n{} filled and\\n{} empty values.'.format(column, tmp_dict[False], tmp_dict[True]))\n\n\n    # Count the unique values in the column\n    nunique = df[column].nunique()\n\n    print('\\n{} unique values are in the column.'.format(nunique))\n\n\n\n\ndef interactiveBarPlot(x, y, column, title):\n    '''\n    Creates interactive bar plot with x and y data\n    \n    Input:\n    x - data on x axis\n    y - data on y axis\n    column - column to inspect\n    title- title of the plot\n    n - number of most counted items to plot\n    \n    Output:\n    '''\n\n    bar = go.Bar(x=x, \n                 y=y, \n                 orientation='h')\n\n    layout = go.Layout(title=title, \n                       xaxis_title='Value Count', \n                       yaxis_title='{}'.format(column))\n\n    fig = go.Figure([bar], layout)\n    fig.show()","ccb69c99":"# Define the column to inspect\ncolumn = 'sha'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","c891d07f":"# Define the column to inspect\ncolumn = 'source_x'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","01644285":"# Define the column to inspect\ncolumn = 'title'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Shorten the y-axis labels\ny = [i[:30] for i in y]\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","3c7208b5":"# Define the column to inspect\ncolumn = 'doi'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","b6c29d5c":"# Define the column to inspect\ncolumn = 'pmcid'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","3bd635bd":"# Define the column to inspect\ncolumn = 'pubmed_id'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Shorten the y-axis labels\ny = ['ID: '+str(i)[:30] for i in y]\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","d07b2abe":"# Define the column to inspect\ncolumn = 'license'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","afcab73e":"# Define the column to inspect\ncolumn = 'abstract'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Shorten the y-axis labels\ny = [i[:30] for i in y]\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","994505ec":"# Define the column to inspect\ncolumn = 'publish_time'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Convert column to datetime\ndf_tmp = pd.to_datetime(df['publish_time'].dropna(), errors='coerce').to_frame()\n\n# Set and sort index\ndf_tmp.set_index('publish_time', inplace=True)\ndf_tmp.sort_index(inplace=True)\n\n# Resample the data on month basis\ndf_tmp = df_tmp.resample('M').size().to_frame()\n\n# Filter empty months out\ndf_tmp = df_tmp[df_tmp[0]!=0]\n\n# Create plot\nscatter = go.Scatter(x=df_tmp.index, \n                     y=df_tmp[0], \n                     mode='markers')\n\nlayout = go.Layout(title='Number of publications over time', \n                   xaxis_title='Month of publication', \n                   yaxis_title='Number of publications')\n\nfig = go.Figure([scatter], layout)\nfig.show()","ecc382b6":"# Define the column to inspect\ncolumn = 'authors'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Shorten the y-axis labels\ny = [i[:30] for i in y]\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","c458efb8":"# Define the column to inspect\ncolumn = 'journal'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","5e21ca61":"# Define the column to inspect\ncolumn = 'Microsoft Academic Paper ID'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Shorten the y-axis labels\ny = ['ID: '+ str(i)[:30] for i in y]\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","0e558ba3":"# Define the column to inspect\ncolumn = 'WHO #Covidence'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Shorten the y-axis labels\ny = ['WHO: '+ str(i)[:30] for i in y]\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","7f1aecc9":"# Define the column to inspect\ncolumn = 'has_full_text'\n\n\n# Count empty, filled and unique values for the column\ncountUniqueAndNAN(df, column)\n\n\n\n# Create mapper for empty and filled values\nmapper = {False:'Filled Values', True:'Empty Values'}\n\n# Count empty values\ntmp_dict = df[column].isna().value_counts().to_dict()\n\n# Split data to x- and y-axis\ny, x = zip(*tmp_dict.items())\n\n# Title of the plot\ntitle = 'Counted empty values for the column \"{}\"'.format(column)\n\n# Plot count of empty values\ninteractiveBarPlot(x, [mapper[i] for i in y], column, title)\n\n\n\n# Number of most common itemsto plot\nn = 20\n\n# Get value counts\ntmp_data = df[column].value_counts().head(n)\n\n# Get the data\nx = tmp_data.values\ny = tmp_data.index\n\n# Title of the plot\ntitle = 'Counted category values for the column \"{}\"'.format(column) + ('' if len(x)<n else ' (Top {})'.format(n))\n\n# Create the plot\ninteractiveBarPlot(x, y, column, title)","4f220999":"# Copy the dataframe\ndf_combine = df[['source_x', 'license', 'publish_time', 'journal', 'has_full_text']].copy()\n\n# Convert column to datetime\ndf_combine['publish_time'] = pd.to_datetime(df_combine['publish_time'], errors='coerce')\n\n# Set and sort index\ndf_combine.set_index('publish_time', inplace=True)\ndf_combine.sort_index(inplace=True)\n\n# Clean license column\ndf_combine['license'] = df_combine['license'].replace(np.nan, '', regex=True).apply(lambda x: x.replace('-', ' ').upper()).replace('', np.nan, regex=True)","0a13fd83":"scatter = []\n\ncolumn = 'source_x'\n\n# Iterate over all unique sources\nfor value in df_combine[column].unique():\n    \n    # Resample the data on month basis\n    df_tmp = df_combine[(df_combine[column]==value) & (df_combine.index.notnull())].resample('M').size().to_frame().loc['2000':]\n    \n    # Filter empty months out\n    df_tmp = df_tmp[df_tmp[0]!=0]\n    \n    # Create scatter\n    scatter.append(go.Scatter(x=df_tmp.index, \n                              y=df_tmp[0],\n                              name=value))\n\n\nlayout = go.Layout(title='Number of publications over time for the column \"{}\"'.format(column), \n                   xaxis_title='Month of publication', \n                   yaxis_title='Number of publications')\n\nfig = go.Figure(scatter, layout)\nfig.show()","2a393710":"scatter = []\n\ncolumn = 'license'\n\n# Iterate over all unique sources\nfor value in df_combine[column].unique():\n    \n    # Resample the data on month basis\n    df_tmp = df_combine[(df_combine[column]==value) & (df_combine.index.notnull())].resample('M').size().to_frame().loc['2000':]\n    \n    # Filter empty months out\n    df_tmp = df_tmp[df_tmp[0]!=0]\n    \n    # Create scatter\n    scatter.append(go.Scatter(x=df_tmp.index, \n                              y=df_tmp[0], \n                              name=value))\n\n\nlayout = go.Layout(title='Number of publications over time for the column \"{}\"'.format(column), \n                   xaxis_title='Month of publication', \n                   yaxis_title='Number of publications')\n\nfig = go.Figure(scatter, layout)\nfig.show()","1e48b900":"scatter = []\n\ncolumn = 'has_full_text'\n\n# Iterate over all unique sources\nfor value in df_combine[column].unique():\n    \n    # Resample the data on month basis\n    df_tmp = df_combine[(df_combine[column]==value) & (df_combine.index.notnull())].resample('M').size().to_frame().loc['2000':]\n    \n    # Filter empty months out\n    df_tmp = df_tmp[df_tmp[0]!=0]\n    \n    # Create scatter\n    scatter.append(go.Scatter(x=df_tmp.index, \n                              y=df_tmp[0], \n                              name=value))\n\n\nlayout = go.Layout(title='Number of publications over time for the column \"{}\"'.format(column), \n                   xaxis_title='Month of publication', \n                   yaxis_title='Number of publications')\n\nfig = go.Figure(scatter, layout)\nfig.show()","2623b70a":"# Create a pivot table to find the most used license by source_x\ndf_tmp = df_combine.pivot_table(values='has_full_text', index='license', columns='source_x', aggfunc='size', fill_value=0)\n\n# Compute percentages\ndf_tmp = df_tmp \/ df_tmp.sum(axis=0) * 100\n\ndf_tmp","42f76e25":"# Create a pivot table to find the most used license by journal\ndf_tmp = df_combine.pivot_table(values='license', index='has_full_text', columns='source_x', aggfunc='size', fill_value=0)\n\n# Compute percentages\ndf_tmp = df_tmp \/ df_tmp.sum(axis=0) * 100\n\ndf_tmp","538afc55":"# <a id=3>3. Inspect The Columns One By One<\/a>\n\nHere you can find a **short overview of each column** on its own.","e0df1250":"For more than 13k publications the full text is available.\n\n## <a id=3.15>3.15. Summary Of The Columns<\/a>\n\nThe most important insight is, there are **multiple entries for the same publication**. This is based on the fact that many abstracts occure mulitple times in the data. This also holds good for the columns \"authors\", \"title\" and the ID-columns (\"doi\", \"pmcid\", \"pubmed_id\", \"Microsoft Academic Paper ID\", and \"WHO #Covidence\").\n\nThese mentioned ID-columns can possibly be used to download additional information on the publications. Further analysis of these columns seems unnecsessary.\n\nThe **\"title\" and the \"abstract\" can be used to perform a short text-analysis** to get the basic relations between words and the most important words without touching the full text.\n\nThe **\"authors\" can be used to create a network of collaborations**. If it is possible to find the most important publications this can be used to attach weight to the network and as a result to find the most important clusters of scientists. \n\nSimilarly the \"journal\" can be used to find the most important journals with the highest value of information for the publications.\n\nThe **\"publish_time\" is important to order the publications** and to find subsequent conclusions based on older articles. \n\n# <a id=4>4. Interesting Combinations Of Columns<\/a>\n\nIn this paragraph multiple columns will be combined to get interesting insights.","f0c02c70":"## <a id=4.1>4.1. Combine \"publish_time\" And \"source_x\"<\/a>\n\nInspect when the sources have published their articles.","1390a4b0":"# 02 Exploring The Article-Metadata-CSV\n\nThis notebook explores the **basics of the metadata** of all articles.  \nIt focuses on the **\"all_sources_metadata_2020-03-13.csv\"-file**.\n\nThe notebook is a sequel to the [\"01 Exploring The Folder-Structure\"-notebook](https:\/\/www.kaggle.com\/morrisb\/01-exploring-the-folder-structure?scriptVersionId=30397035).\n\n# Table Of Content\n\n+ [1. Import Libraries](#1)<br>\n+ [2. Load The Data](#2)<br>\n+ [3. Inspect The Columns One By One](#3)<br>\n + [3.1. Column \"sha\"](#3.1)<br>\n + [3.2. Column \"source_x\"](#3.2)<br>\n + [3.3. Column \"title\"](#3.3)<br>\n + [3.4. Column \"doi\"](#3.4)<br>\n + [3.5. Column \"pmcid\"](#3.5)<br>\n + [3.6. Column \"pubmed_id\"](#3.6)<br>\n + [3.7. Column \"license\"](#3.7)<br>\n + [3.8. Column \"abstract\"](#3.8)<br>\n + [3.9. Column \"publish_time\"](#3.9)<br>\n + [3.10. Column \"authors\"](#3.10)<br>\n + [3.11. Column \"journal\"](#3.11)<br>\n + [3.12. Column \"Microsoft Academic Paper ID\"](#3.12)<br>\n + [3.13. Column \"WHO #Covidence\"](#3.13)<br>\n + [3.14. Column \"has_full_text\"](#3.14)<br>\n + [3.15. Summary Of The Columns](#3.15)<br>\n+ [4. Interesting Combinations Of Columns](#4)<br>\n + [4.1. Combine \"publish_time\" And \"source_x\"](#4.1)<br>\n + [4.2. Combine \"publish_time\" And \"license\"](#4.2)<br>\n + [4.3. Combine \"publish_time\" And \"has_full_text\"](#4.3)<br>\n + [4.4. Combine \"source_x\" And \"license\"](#4.4)<br>\n + [4.5. Combine \"source_x\" And \"has_full_text\"](#4.5)<br>\n+ [5. Conclusion](#5)<br>\n\n# <a id=1>1. Import Libraries<\/a>","021e2a52":"Since most of the values are empty and it is another ID the column is likely to have similar significance as the other ID columns.\n\n## <a id=3.13>3.13. Column \"WHO #Covidence\"<\/a>\n\nThe column contains an ID by the WHO.","e6dbfb0a":"The biorxiv and medrxiv have their own license. The most important license for the CZI and PMC is the \"CC BY\".\n\n## <a id=4.5>4.5. Combine \"source_x\" And \"has_full_text\"<\/a>\n\nCheck the percentage of the full text availability per source.","f07165e9":"## <a id=3.1>3.1. Column \"sha\"<\/a>\n\nThe column contains the sha-value (**Secure Hash Algorithm**) for the PDF document.  \nYou can use the value to check if you are using the right PDF by computing the sha-value of the file on your own.","3a960886":"**Most of the available articles are from the past few years** (only data after year 2000 will be displayed).  \n\nIt has to be noted that the **CZI seems very productive these days**. Whether they publish meaningful articles or only short notices has to be investigated. Furthermore the CZI only releases the year of their publication and no more exact information.  \nThe biorxiv clearly has an increase in publications, while the PMC stagnates.\n\n## <a id=4.2>4.2. Combine \"publish_time\" And \"license\"<\/a>\n\nInspect when the different licenses changed over time.","7ce749fe":"More than half of the entries have an associated PDF\/sha.\n\nWhether the **duplicated hashes** depict hash-collisions, multiple publications of the same PDF in different journals or something different is right now unclear.\n\n## <a id=3.2>3.2. Column \"source_x\"<\/a>\n\nThe column contains the source in which **online repository** the article can be found.","72ef4e4e":"The availability of the full text increases more rapidly than the missing of the text in the past few years.\n\n## <a id=4.4>4.4. Combine \"source_x\" And \"license\"<\/a>\n\nCheck the percentage of the different licenses per source.","322ab293":"Since **some titles of publications have many entries**, it is possible they have common or generic titles. Another possible explanation could be the articles have been published multiple times with only few or non changes.\n\n## <a id=3.4>3.4. Column \"doi\"<\/a>\n\nThe column represents a \"digital object identifier\" and seems to be an online link to the publication.","5a011180":"The distribution of the data implies another correlation with \"doi\" and \"abstract\" since the combinations of many authors should be quite unique.\n\n## <a id=3.11>3.11. Column \"journal\"<\/a>\n\nThe column contains the journal in which the article has been published.","6ff2a9e0":"The \"CC BY\" license increases over time and is the most important license in this dataset.\n\n## <a id=4.3>4.3. Combine \"publish_time\" And \"has_full_text\"<\/a>\n\nCheck if the full text availability changed over time. ","fa9715cf":"The distribution seems similar to the \"doi\", \"pmcid\" and \"pubmed_id\".  \nSince it is very **unlikely for different publications to have the same abstract**, it can be assumed some articles have multiple entries in the csv-file.\n\n## <a id=3.9>3.9. Column \"publish_time\"<\/a>\n\nThe column contains the date of the publication.","b4ac3a1d":"**Many entries reference the same digital object** on the web.  \nIt has to be investigated whether this leads to many almost duplicates in the articles.\n\n## <a id=3.5>3.5. Column \"pmcid\"<\/a>\n\nThe column contains an ID of the PMC.","96e29016":"The publications seem to include the first SARS outbreak in 2002\/2003 with rising numbers of publications in the following years.  \nThe **peak is right now with an explosion of articles** and publications.\n\n## <a id=3.10**>3.10. Column \"authors\"<\/a>\n\nThe column contains a list of all authors of the publication.","b518a2bd":"Since most of the values are empty and it is another ID the column is likely to have similar significance as the other ID columns.\n\n## <a id=3.14>3.14. Column \"has_full_text\"<\/a>\n\nThe column contains a bool variable whether the full text is available.","21c2fe0e":"Some licenses have **different notations but the same meaning**.  \nCleaning with lowering the letters and removing hyphens seems necessary.\n\n## <a id=3.8>3.8. Column \"abstract\"<\/a>\n\nThe column contains the abstracts of the publications.","6dd09171":"# <a id=2>2. Load The Data<\/a>","97268bf2":"The distribution seems similar to the \"doi\".  \nPossibly it is another variable for the same information.\n\n## <a id=3.6>3.6. Column \"pubmed_id\"<\/a>\n\nThe column contains the ID of the pubmed.","076a4307":"The PMC has most of the oldest publications and the lowest full text availability.  \nThe other and newer sources have a higher availabilty.\n\n# <a id=5>5. Conclusion<\/a>\n\nThe dataset contains **multiple entries for the same publications**. This could lead to a skewed view if not handled in the right way.  \n\nThe **time column should be useful to get an ordering**. Maybe it is possible to find articles building upon each other and to extract deeper insights.  \n\nThe **title and abstract can be used to perform a short text analysis** without having to tame the 2GB of json-data.\n\nThe **authors can be used to create a network of collaborations**. This could be helpful to find sources to expect reliable and meaningful new insights from. ","ce875176":"The distribution seems similar to the \"doi\" and the \"pmcid\".  \nPossibly it is another variable for the same information.\n\n## <a id=3.7>3.7. Column \"license\"<\/a>\n\nThe column contains the license under which article has been published.","7fa95aa7":"The articles have been published in many different journals.  \nIt could be interesting to investigate the articles regarding this information.\n\n## <a id=3.12>3.12. Column \"Microsoft Academic Paper ID\"<\/a>\n\nThis column contains an ID by Microsoft.","c6022727":"For each publication the source is known.  \nMost of the articles can be found at the PMC ([PubMed Central](https:\/\/en.wikipedia.org\/wiki\/PubMed_Central)). The other sources are the \"[Chan Zuckerberg Initiative](https:\/\/en.wikipedia.org\/wiki\/Chan_Zuckerberg_Initiative)\", \"[bioRxiv](https:\/\/en.wikipedia.org\/wiki\/BioRxiv)\" and the \"[medRxiv](https:\/\/en.wikipedia.org\/wiki\/MedRxiv)\".\n\n## <a id=3.3>3.3. Column \"title\"<\/a>\n\nThe column contains the title of the publication."}}