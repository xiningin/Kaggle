{"cell_type":{"a700be65":"code","e6162851":"code","398fa8b1":"code","a41dedb8":"code","996d159e":"code","911e9f31":"code","710a266b":"code","a779269d":"code","f756db49":"code","b24108d1":"code","4372849e":"code","e431743f":"code","ee550530":"code","d7f4cfb4":"code","a6fbad2d":"code","e670a694":"markdown","63b3a98b":"markdown","692b6f84":"markdown","22ba20bd":"markdown","820d929c":"markdown","80d03b8d":"markdown"},"source":{"a700be65":"%%capture\n\"\"\"\n!pip install pandarallel \n\nimport gc\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom pandarallel import pandarallel\npandarallel.initialize()\n\nBASE_DIR = Path('..\/input\/mlb-player-digital-engagement-forecasting')\ntrain = pd.read_csv(BASE_DIR \/ 'train.csv')\n\nnull = np.nan\ntrue = True\nfalse = False\n\nfor col in train.columns:\n\n    if col == 'date': continue\n\n    _index = train[col].notnull()\n    train.loc[_index, col] = train.loc[_index, col].parallel_apply(lambda x: eval(x))\n\n    outputs = []\n    for index, date, record in train.loc[_index, ['date', col]].itertuples():\n        _df = pd.DataFrame(record)\n        _df['index'] = index\n        _df['date'] = date\n        outputs.append(_df)\n\n    outputs = pd.concat(outputs).reset_index(drop=True)\n\n    outputs.to_csv(f'{col}_train.csv', index=False)\n    outputs.to_pickle(f'{col}_train.pkl')\n\n    del outputs\n    del train[col]\n    gc.collect()\n\"\"\"","e6162851":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.metrics import mean_absolute_error\nfrom datetime import timedelta\nfrom functools import reduce\nfrom tqdm import tqdm\nimport lightgbm as lgbm\nimport mlb\nimport gc","398fa8b1":"BASE_DIR = Path('..\/input\/mlb-player-digital-engagement-forecasting')\nTRAIN_DIR = Path('..\/input\/mlb-pdef-train-dataset')","a41dedb8":"players = pd.read_csv(BASE_DIR \/ 'players.csv')\n\nrosters = pd.read_pickle(TRAIN_DIR \/ 'rosters_train.pkl')\ntargets = pd.read_pickle(TRAIN_DIR \/ 'nextDayPlayerEngagement_train.pkl')\nscores = pd.read_pickle(TRAIN_DIR \/ 'playerBoxScores_train.pkl')\nscores = scores.groupby(['playerId', 'date']).sum().reset_index()","996d159e":"targets_id = ['playerId','date']\nTGTCOLS = ['target1', 'target2', 'target3', 'target4']\nrosters_id = ['playerId']\nrosters_cat = [\"statusCode\",\"status\"]\n\n\npscores_id = [\"playerId\", 'teamId'] #, \"gamePk\"\npscores_cat = [\"jerseyNum\",\"positionCode\",\"positionName\",\"positionType\"]\npscores_num = ['home', \n               'gamesPlayedBatting', 'flyOuts', 'groundOuts', 'runsScored', 'doubles', 'triples', \n               'homeRuns', 'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch', \n               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay', 'groundIntoTriplePlay', \n               'plateAppearances', 'totalBases', 'rbi', 'leftOnBase', 'sacBunts', 'sacFlies', \n               'catchersInterference', 'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching', \n               'completeGamesPitching', 'shutoutsPitching', 'winsPitching', 'lossesPitching', 'flyOutsPitching', \n               'airOutsPitching', 'groundOutsPitching', \n               'runsPitching', 'doublesPitching', 'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching', \n               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching', 'hitByPitchPitching', \n               'atBatsPitching', 'caughtStealingPitching', 'stolenBasesPitching', 'inningsPitched', \n               'saveOpportunities', 'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', \n               'balls', 'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching', 'rbiPitching', \n               'gamesFinishedPitching', 'inheritedRunners', 'inheritedRunnersScored', 'catchersInterferencePitching', \n               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves', 'assists', \n               'putOuts', 'errors', 'chances']\n\nstats_cols = ['target1_mean','target1_median','target1_std','target1_min','target1_max',\n              'target1_prob',\n              'target2_mean','target2_median','target2_std','target2_min','target2_max',\n              'target2_prob',\n              'target3_mean','target3_median','target3_std','target3_min',\n              'target3_max','target3_prob',\n              'target4_mean','target4_median','target4_std',\n              'target4_min','target4_max','target4_prob']\n#\nfeature_col = pscores_num + stats_cols","911e9f31":"player_target_stats = pd.read_csv(\"..\/input\/player-target-stats\/player_target_stats.csv\")\ndata_names=player_target_stats.columns.values.tolist()","710a266b":"# creat dataset\ntrain = targets[targets_id + TGTCOLS]\ntrain = train.merge(rosters[rosters_id + rosters_cat + [\"date\"]], \n                    on=['playerId', 'date'], how='left')\ntrain = train.merge(scores[pscores_id  + pscores_num  + [\"date\"]], \n                    on=['playerId', 'date'], how='left')\ntrain = train.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])","a779269d":"%%time\nX = train[feature_col].fillna(0.).values\ny = train[TGTCOLS].values","f756db49":"import tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping","b24108d1":"def make_model(n_in):\n    inp = L.Input(name=\"inputs\", shape=(n_in,))\n    nh = 50\n    x = L.Dense(nh, activation=\"relu\", name=\"d1\")(inp)\n    x = L.Dense(nh, activation=\"relu\", name=\"d2\")(x)\n    #x = L.Dense(nh, activation=\"relu\", name=\"d3\")(x)\n    preds = L.Dense(4, activation=\"linear\", name=\"preds\")(x)\n    \n    model = M.Model(inp, preds, name=\"ANN\")\n    model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n    return model","4372849e":"net = make_model(X.shape[1])\nprint(net.summary())","e431743f":"net.fit(X, y, batch_size=30_000, epochs=5)\ngc.collect()","ee550530":"null = np.nan\ntrue = True\nfalse = False\n\nenv = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set\n\nfor (test_df, sample_prediction_df) in iter_test: # make predictions here\n    \n    sample_prediction_df = sample_prediction_df.reset_index(drop=True)\n    \n    # creat dataset\n    sample_prediction_df['playerId'] = sample_prediction_df['date_playerId']\\\n                                        .map(lambda x: int(x.split('_')[1]))\n    # Dealing with missing values\n    if test_df['rosters'].iloc[0] == test_df['rosters'].iloc[0]:\n        test_rosters = pd.DataFrame(eval(test_df['rosters'].iloc[0]))\n    else:\n        test_rosters = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in rosters.columns:\n            if col == 'playerId': continue\n            test_rosters[col] = np.nan\n            \n    if test_df['playerBoxScores'].iloc[0] == test_df['playerBoxScores'].iloc[0]:\n        test_scores = pd.DataFrame(eval(test_df['playerBoxScores'].iloc[0]))\n    else:\n        test_scores = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in scores.columns:\n            if col == 'playerId': continue\n            test_scores[col] = np.nan\n    test_scores = test_scores.groupby('playerId').sum().reset_index()\n    test = sample_prediction_df[['playerId']].copy()\n    test = test.merge(test_rosters[rosters_id + rosters_cat], on='playerId', how='left')\n    test = test.merge(test_scores[pscores_id  + pscores_num], on='playerId', how='left')\n    test = test.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n    \n    Xe = test[feature_col].fillna(0.).values\n    pe = net.predict(Xe)\n    pe = np.clip(pe, 0, 100)\n    \n    # predict\n    # to come...\n    \n    # merge submission\n    sample_prediction_df[TGTCOLS] = pe\n    sample_prediction_df = sample_prediction_df.fillna(0.)\n    del sample_prediction_df['playerId']\n    \n    env.predict(sample_prediction_df)","d7f4cfb4":"sample_prediction_df.head()","a6fbad2d":"sample_prediction_df.max()","e670a694":"## MODEL","63b3a98b":"Credit to @columbia2131 - I started with his notebook and then added an external data set with descriptive statistics of the targets for each player.","692b6f84":"## About Dataset","22ba20bd":"generated by the code below","820d929c":"## DATA PREPARATION","80d03b8d":"## Inference"}}