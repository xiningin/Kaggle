{"cell_type":{"7f3839e6":"code","f3324c7c":"code","b18d93d2":"code","76a2fe28":"code","58f529b7":"code","c9ea2c06":"code","51a3517d":"code","99d13dbb":"code","88065c14":"code","50248b10":"code","9f67220f":"code","70520f51":"code","798dbbd9":"code","72e53bfd":"code","c511a9bb":"code","540ca0c2":"code","7327f25d":"code","d7ed1a1b":"code","ad20b23d":"code","2f0be6e3":"code","104c5a1c":"code","af02a663":"code","00c50d93":"code","a777286c":"code","7a1839fa":"code","9fe772fc":"code","e3fb62c9":"code","f8438818":"code","b51439d7":"code","b514d041":"code","a78e7df4":"code","f69a289e":"code","1b682662":"code","da132fda":"code","0cdf589d":"code","e79401b3":"code","b62c1b68":"code","858e16d7":"code","2dc00f76":"code","1c40d2d8":"code","5026c223":"code","65129e04":"code","581acdd3":"code","fb666e2d":"code","26b31eef":"code","2298e29e":"code","e1eaab54":"code","073a10e8":"code","04c2f84e":"code","9c6ba5b2":"code","e9a46129":"code","48cd9b57":"code","66f6f695":"code","be9d0153":"code","73d3a06e":"code","2bd1a75e":"code","49e18885":"code","c7808424":"code","1d7a66c0":"code","a6b4c135":"code","8cf4835a":"code","2a298b8d":"code","df239ef0":"code","7ad944a5":"code","e94c1229":"code","ca199b28":"code","fac2dc45":"code","69ecc19b":"code","85b050ff":"code","3a4026ee":"code","6167225f":"code","d6fcd5e2":"markdown","0df7ee6c":"markdown","e9233784":"markdown","b9ca12f9":"markdown","15f33d4b":"markdown","b69be74e":"markdown","9315309c":"markdown","3c32e549":"markdown","d246edc4":"markdown","ef048a50":"markdown","758ab239":"markdown","cedb0c12":"markdown","b91ae425":"markdown","f240b13b":"markdown","0656329b":"markdown","08a5a8ea":"markdown","f164fa74":"markdown","54d24e4a":"markdown","4b017380":"markdown","2db8f0cf":"markdown","0514157a":"markdown","79a6ffa0":"markdown","809e75b2":"markdown","d2b871ed":"markdown","321f6a2c":"markdown"},"source":{"7f3839e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f3324c7c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport missingno as msno # Ploting missng values\nimport plotly.graph_objects as go\n\nplt.style.use('fivethirtyeight')\n","b18d93d2":"df=pd.read_csv('..\/input\/ataljalyojana\/Atal Jal 31 March 2021 .xlsx - Sheet1.csv')\ndf.head()","76a2fe28":"df['State']=df['State'].str.lower()","58f529b7":"df.shape","c9ea2c06":"df.columns","51a3517d":"df.isnull().sum().sort_values(ascending=False)","99d13dbb":"df.info()","88065c14":"numeric_data=df.select_dtypes(include=[np.number])\ncate_data=df.select_dtypes(exclude=[np.number])","50248b10":"numeric_data.columns","9f67220f":"numeric_data.shape","70520f51":"cate_data.columns","798dbbd9":"cate_data.shape","72e53bfd":"plt.figure(figsize=(10,5))\nsns.kdeplot(df['Well Depth'], fill=True, hue=df['State'])\nplt.show()","c511a9bb":"df_guj=df[df['State']=='gujarat']\ndf_maha=df[df['State']=='maharashtra']\ndf_raj=df[df['State']=='rajasthan']\ndf_har=df[df['State']=='haryana']\ndf_up=df[df['State']=='uttar pradesh']\ndf_mp=df[df['State']=='madhya pradesh']\ndf_kar=df[df['State']=='karnataka']\n","540ca0c2":"plt.figure(figsize=(10,5))\nsns.kdeplot(df_guj['Well Depth'], fill=True)\nplt.title(\"Well Depth Across Gujrat\")\nplt.show()","7327f25d":"df_guj['Well Depth'].describe(percentiles=[0.25,0.5,0.75, 0.95]).T","d7ed1a1b":"df_guj['Well Depth'].value_counts()","ad20b23d":"# Confidence Interval\nimport numpy as np\nimport scipy.stats as st\n\nst.t.interval(alpha=0.95, df=len(df_guj['Well Depth'])-1, loc=np.mean(df_guj['Well Depth']), scale=st.sem(df_guj['Well Depth']) )\n","2f0be6e3":"x=df_guj['Well Depth'].notna","104c5a1c":"st.norm.interval(alpha=0.95, loc=np.mean(df_guj['Well Depth']), scale=st.sem(df_guj['Well Depth']))","af02a663":"from statsmodels.graphics.gofplots import qqplot\nfrom matplotlib import pyplot","00c50d93":"qqplot(df_guj['Well Depth'], line='s')\npyplot.show()","a777286c":"from scipy import stats","7a1839fa":"stats.probplot(df_guj['Well Depth'], dist=\"norm\", plot=plt)\nplt.show()","9fe772fc":"from scipy.stats import shapiro","e3fb62c9":"stat, p = shapiro(df_guj['Well Depth'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","f8438818":"print(\"Skewmess\", df_guj['Well Depth'].skew())\nprint(\"Kurtosis\", df_guj['Well Depth'].kurt())\n","b51439d7":"stat, p = shapiro(df_maha['Well Depth'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","b514d041":"stat, p = shapiro(df_raj['Well Depth'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","a78e7df4":"stat, p = shapiro(df_mp['Well Depth'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","f69a289e":"stat, p = shapiro(df_up['Well Depth'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","1b682662":"stat, p = shapiro(df_kar['Well Depth'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","da132fda":"numeric_data.head()","0cdf589d":"numeric_data.hist(bins=50, figsize=(30,20));\n","e79401b3":"numeric_data.columns","b62c1b68":"col=['Well Depth', 'Level Depth Ratio',\n       'Pre_2015', 'Pst_2015', 'Pre_2016', 'Pst_2016', 'Pre_2017', 'Pst_2017',\n       'Pre_2018', 'Pst_2018', 'Pre_2019', 'Pst_2019', 'Final Count',\n       'Pre Diff 19 15', 'Pst Diff 19 15', 'Diff 2015', 'Diff 2016',\n       'Diff 2017', 'Diff 2018', 'Diff 2019', 'Sign Diff 15', 'Sign Diff 16',\n       'Sign Diff 17', 'Sign Diff 18', 'Sign Diff 19', 'Sum Signed Diff']","858e16d7":"corrmat = numeric_data[col].corr(method='spearman')\nf, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(corrmat, ax=ax, cmap=\"YlGnBu\", linewidths=0.1)","2dc00f76":"corr = numeric_data[col].corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","1c40d2d8":"from statsmodels.stats.outliers_influence import variance_inflation_factor\ncols=['Well Depth']\nX=numeric_data[col].drop('Well Depth', axis=1)","5026c223":"X.columns","65129e04":"numeric_data[col].isna().sum()","581acdd3":"df.columns","fb666e2d":"col=[ 'State', \n        'Well Depth', 'Aquifier',\n       'Level Depth Ratio', 'Pre_2015', 'Pst_2015', 'Pre_2016', 'Pst_2016',\n       'Pre_2017', 'Pst_2017', 'Pre_2018', 'Pst_2018', 'Pre_2019', 'Pst_2019',\n       'Final Count', 'Pre Diff 19 15', 'Pst Diff 19 15', 'Diff 2015',\n       'Diff 2016', 'Diff 2017', 'Diff 2018', 'Diff 2019', 'Avg Diff',\n       'Avg Pre', 'Avg Post ', 'Avg Level', 'Sign Diff 15', 'Sign Diff 16',\n       'Sign Diff 17', 'Sign Diff 18', 'Sign Diff 19', 'Sum Signed Diff']","26b31eef":"df_guj[col].isna().sum()","2298e29e":"df_maha[col].isna().sum()","e1eaab54":"df_raj[col].isna().sum()","073a10e8":"df_kar[col].isna().sum()","04c2f84e":"df_mp[col].isna().sum()","9c6ba5b2":"df_up[col].isna().sum()","e9a46129":"df_har[col].isna().sum()","48cd9b57":"dff=df","66f6f695":"dff['State'].value_counts()","be9d0153":"dff.columns","73d3a06e":"# Initialize the Dice columns\ndff[\"well_missing\"] = dff['Well Depth']\n# The column is false\ndff[\"well_missing\"] = False\n# Replace where Height_missing with True where Height is missing\ndff.loc[dff[dff['Well Depth'].isnull()].index, \"well_missing\"] = True","2bd1a75e":"dff[dff[\"well_missing\"]==True].groupby(\"State\")[\"well_missing\"].count()","49e18885":"dff[dff[\"well_missing\"]==False].groupby(\"State\")[\"well_missing\"].count()","c7808424":"table=[[6, 266], [546, 68], [1, 298],[1, 186], [500, 199],\n      [101, 289],[0, 286]]","1d7a66c0":"print(table)","a6b4c135":"from scipy.stats import chi2_contingency\nchi2, p, dof, ex = chi2_contingency(table)","8cf4835a":"print(\"The p-value is esqual to {}\".format(p))\n","2a298b8d":"import missingno as msno","df239ef0":"msno.bar(dff)","7ad944a5":"msno.bar(numeric_data)","e94c1229":"msno.bar(cate_data)","ca199b28":"msno.matrix(numeric_data)","fac2dc45":"msno.heatmap(numeric_data)","69ecc19b":"msno.heatmap(cate_data)","85b050ff":"msno.dendrogram(numeric_data)","3a4026ee":"msno.dendrogram(cate_data)","6167225f":"msno.dendrogram(dff)","d6fcd5e2":"# Correlation among the Numerical features","0df7ee6c":"# Finding reason for missing data using a Heatmap","e9233784":"The first step is to detect if the missingness in the Height variable is relate to the Sex variable. The Chi2 contngency test from the scipy library will be used. This requires tge establishement of the contengeny table.","b9ca12f9":"# Normality Test\n1. QQ plot","15f33d4b":"Since the  p -value is less that 5%, not significant result, we reject null hypothesis (H0) and the two variables are not indepedent.","b69be74e":"# Bivariate analysis","9315309c":"# Shapiro Willki Test\n* Hypothesis Testing \n> H0: The distribution is gaussian\n> H1: The distribution is not gaussian","3c32e549":"# Correlation","d246edc4":"# Conclude\n1. The missingness in the columns well depth is MCAR- Missing Completly At Random.\n2. This has been proved with the help of the chi2 values.","ef048a50":"# State wise well depth varation","758ab239":"# Finding reason for missing data using Dendrogram\nA dendogram is a tree diagram of missingness. It groups the highly correlated variables together.","cedb0c12":"# Detect the MCAR pattern\n1. In order to detect an MCAR pattern, we can use statistical tests. One famous statistical test for this purpose is the  chi-square  test. The  chi square could be used to test goodness of fit, homogenity test and independence test. The latter will be used in this case to figure out if the missigness of data in the Height column is dependent (or not) on the other variables (columns).\n2. The test starts by stating a first hypothesis called (the null hypothesis) and calculates a measure of closness between the observed data and the expected data (in the case where the null hypothesis is satisfied).\n3. The null hypothesis in this case is the following:\n4. H0 : There is no association between the missingness in the Well Depth column and the other columns. The critical p-value associated to this test is equal to 0.05.\n\n5. Let us first define the columns \"Height_missing\" that equals to True if Height is missing and False otherwise.","b91ae425":"As a conclusion, the missingness in the Well Depth variable is dependent on the State variable.  This could be done in the same manner with a signle modification. Since the  chi2  test could not be performed between a continous and a categorical variable, the continous variables must be converted into categories by performing some binning techniques.","f240b13b":"# Multicollinearity","0656329b":"The associated  p -value to this observation is equal to:","08a5a8ea":"# Well Depth:\n1. Well depth is analysed with respect to the state that we have \n2. Perform  the chi square test in order to come up with the required hypothesis.\n3. The missing values will be imputed with the TRUE and non-missing with FALSE.\n4. Perform the chi square test\n5. If there is association betwwe the parameters i.e. the state and missng values of well depth we can say that if MCAR is this","f164fa74":"# Separating Numerical and Categorical features","54d24e4a":"* This table will be fed to the Chi2 contngency test from the scipy library. \n* We expect that the degree of freedom will be 1 ((nrows-1) * (nclos-1)). \n* This is also an information the scipy function returns.","4b017380":"# Maharastraskew","2db8f0cf":"The heatmap function shows that there are no strong correlations between missing values of different features. This is good; low correlations further indicate that the data are MAR.","0514157a":"# Response Variables","79a6ffa0":"# Missing Values","809e75b2":"# Obs\n* The heatmap shows that the correlation between the missing values of different features.\n* The higher correlation mean the missing values is not MAR.\n* We can see that Level depth ration, Pre_2015, Pst_2015, etc have higher correlation , hence the missing values in the features are not MAR\n* The heatmap function shows that there are no strong correlations between missing values of some other features. \n* This is good; low correlations further indicate that the data are MAR.","d2b871ed":"# Contigency table\n* State \tMissing\t   Non-missing\n* gujarat\t6\t       266\n* haryana\t546\t       68\n* karnataka\t1\t      298\n* madhya\t1\t      186\n* maharashtra\t500\t  199\n* rajasthan\t101\t       289\n* uttar\t0\t          286","321f6a2c":"# Rajasthan"}}