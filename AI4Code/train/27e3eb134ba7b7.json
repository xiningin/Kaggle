{"cell_type":{"61bb17fa":"code","2f3274ce":"code","b5ce6b6c":"code","d7aa0cc3":"code","5fe70cac":"code","08454c6c":"code","d062cc03":"code","bd2cb6e8":"code","da89b418":"code","e4ac1857":"code","f6dccbfe":"code","53f7e89f":"code","4928b48c":"code","5d7abe8d":"code","63273772":"code","c8cfab79":"code","0b71c521":"code","821e49ca":"code","1d8f7b31":"code","7e637385":"code","a3240bdc":"code","335a64e8":"code","84cf806f":"code","c61ba2f0":"code","6b835a51":"code","5f49d42a":"code","1f6fefc1":"code","e1544e71":"code","ff2e09c3":"code","10d594f5":"code","4871ba35":"code","b06119ae":"code","e51a777f":"code","da907231":"code","f5606126":"code","db2227ad":"code","5455c672":"code","78542ee7":"code","bb273549":"markdown","5fbe7771":"markdown","ffc70b40":"markdown","6b4d7837":"markdown","5acceefd":"markdown","71548559":"markdown","1cd6f5a7":"markdown","481635b1":"markdown","e48bea77":"markdown","8420c1cc":"markdown","7984f761":"markdown","9b30936d":"markdown","8378ebc2":"markdown","72cb5dac":"markdown","206f200a":"markdown","94916040":"markdown","9b31e262":"markdown","be477a63":"markdown","52cacc94":"markdown","69dd9c37":"markdown","a592f79a":"markdown","cdc7ce83":"markdown","976f1f4b":"markdown","80c6b51a":"markdown","70ce2294":"markdown","01db89dd":"markdown","fc796462":"markdown","91b615c6":"markdown","cad8bbeb":"markdown","f01e8efc":"markdown","7dc25904":"markdown","3ea4fdb4":"markdown"},"source":{"61bb17fa":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","2f3274ce":"print(os.listdir(\"..\/input\/dogs-vs-cats\/\"))","b5ce6b6c":"os.listdir(\"..\/input\/dogs-vs-cats\/\")[0]","d7aa0cc3":"from zipfile import ZipFile\nzf = ZipFile('..\/input\/dogs-vs-cats\/train.zip', 'r')\nzf.extractall('..\/kaggle\/working\/Temp')\nzf.close()","5fe70cac":"#Commented to reduce display...\n#print(os.listdir(\"..\/kaggle\/working\/Temp\/train\"))","08454c6c":"filenames = os.listdir(\"..\/kaggle\/working\/Temp\/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append('dog')\n    else:\n        categories.append('cat')\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","d062cc03":"df.head()","bd2cb6e8":"df['category'].value_counts()","da89b418":"sns.countplot(x='category', data=df)","e4ac1857":"filenames[0]","f6dccbfe":"from tensorflow.keras.preprocessing import image\nimg = image.load_img(\"..\/kaggle\/working\/Temp\/train\/\"+filenames[0])\nplt.imshow(img)","53f7e89f":"test_image = image.load_img(\"..\/kaggle\/working\/Temp\/train\/\"+filenames[0], \n                            target_size=(128, 128))\ntest_image = image.img_to_array(test_image)\nplt.imshow(test_image[:, :, 2])","4928b48c":"from sklearn.model_selection import train_test_split\n\ntrain_data, val_data = train_test_split(df, test_size=0.20, random_state=42)\ntrain_data = train_data.reset_index(drop=True)\nval_data   = val_data.reset_index(drop=True)","5d7abe8d":"train_data.head()","63273772":"val_data.head()","c8cfab79":"train_data['category'].value_counts()","0b71c521":"sns.countplot(x='category', data=train_data)","821e49ca":"val_data['category'].value_counts()","1d8f7b31":"sns.countplot(x='category', data=val_data)","7e637385":"from keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers import Dense, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator","a3240bdc":"classifier = Sequential([Convolution2D(filters=32, kernel_size=(3, 3), strides=(1, 1), input_shape=(128,128,3),\n                            padding='valid', activation='relu'),\n                         BatchNormalization(),\n                         MaxPooling2D(pool_size=(2, 2)),\n                         Dropout(0.2),\n                         Convolution2D(filters=32, kernel_size=(3, 3), strides=(1, 1),\n                            padding='valid', activation='relu'),\n                         BatchNormalization(),\n                         MaxPooling2D(pool_size=(2, 2)),\n                         Dropout(0.2),\n                         Flatten(),\n                         Dense(512, activation='relu'),\n                         BatchNormalization(),\n                         Dropout(0.25),\n                         Dense(2, activation='softmax')])\n\nclassifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nclassifier.summary()","335a64e8":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n        train_data,\n        \"..\/kaggle\/working\/Temp\/train\/\",\n        x_col='filename',\n        y_col='category',\n        target_size=(128, 128),\n        batch_size=32,\n        class_mode='categorical')","84cf806f":"val_datagen = ImageDataGenerator(rescale=1.\/255)\n\nval_generator = val_datagen.flow_from_dataframe(\n        val_data,\n        \"..\/kaggle\/working\/Temp\/train\/\",\n        x_col='filename',\n        y_col='category',\n        target_size=(128, 128),\n        batch_size=32,\n        class_mode='categorical')","c61ba2f0":"from keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)","6b835a51":"history=classifier.fit_generator(train_generator,\n                                steps_per_epoch=625,\n                                epochs=50,\n                                validation_data=val_generator,\n                                validation_steps=200,\n                                callbacks=[es, mc])","5f49d42a":"history.history","1f6fefc1":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'], '')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Accuracy')\nplt.title('Change of Accuracy over Epochs')\nplt.legend(['accuracy', 'val_accuracy'])\nplt.show()","e1544e71":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'], '')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Loss')\nplt.title('Change of Loss over Epochs')\nplt.legend(['loss', 'val_loss'])\nplt.show()","ff2e09c3":"train_generator.class_indices","10d594f5":"from zipfile import ZipFile\nzf = ZipFile('..\/input\/dogs-vs-cats\/test1.zip', 'r')\nzf.extractall('..\/kaggle\/working\/Temp')\nzf.close()","4871ba35":"#Commented to reduce display...\n#print(os.listdir(\"..\/kaggle\/working\/Temp\/test1\"))","b06119ae":"filenames = os.listdir(\"..\/kaggle\/working\/Temp\/test1\")\n\ntest_data = pd.DataFrame({\n    'filename': filenames\n})","e51a777f":"from keras.models import load_model\n\nsaved_model = load_model('best_model.h5')","da907231":"img = image.load_img(\"..\/kaggle\/working\/Temp\/test1\/\"+filenames[29])\n                            \ntest_image = image.load_img(\"..\/kaggle\/working\/Temp\/test1\/\"+filenames[29], \n                            target_size=(128, 128))\ntest_image = image.img_to_array(test_image)\nplt.imshow(img)\ntest_image = np.expand_dims(test_image, axis=0)\nresult = saved_model.predict(test_image)\nprint(np.argmax(result, axis=1))","f5606126":"img = image.load_img(\"..\/kaggle\/working\/Temp\/test1\/\"+filenames[39])\n                            \ntest_image = image.load_img(\"..\/kaggle\/working\/Temp\/test1\/\"+filenames[39], \n                            target_size=(128, 128))\ntest_image = image.img_to_array(test_image)\nplt.imshow(img)\ntest_image = np.expand_dims(test_image, axis=0)\nresult = saved_model.predict(test_image)\nprint(np.argmax(result, axis=1))","db2227ad":"test_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n        test_data,\n        \"..\/kaggle\/working\/Temp\/test1\/\",\n        x_col='filename',\n        y_col=None,\n        target_size=(128, 128),\n        batch_size=32,\n        class_mode=None)","5455c672":"predict = saved_model.predict_generator(test_generator)\nfinal_prediction = np.argmax(predict, axis=1)","78542ee7":"predict_df = pd.DataFrame(final_prediction, columns=['label'])\nsubmission_df = test_data.copy()\nsubmission_df['id'] = (submission_df['filename'].str.split('.').str[0]).astype(int)\nsubmission_df = pd.concat([submission_df, predict_df], axis=1)\nsubmission_df = submission_df.drop(['filename'], axis=1)\nsubmission_df = submission_df.sort_values(by=['id'])\nsubmission_df = submission_df.reset_index(drop=True)\nsubmission_df.to_csv('submission.csv', index=False)","bb273549":"#### Build the train_generator.","5fbe7771":"#### Check first few lines from train dataset.","ffc70b40":"#### Check whether the Unzip has worked.","6b4d7837":"#### Check the distibution of categories.","5acceefd":"#### First few rows of the dataframe.","71548559":"#### A CNN will have multiple layers of Convolution layers and then it will be fed into a fully connected network.\n\nIn our case we will have 2 layers of **Convolution Layers** and each will have below features -\n\n1. **Filters**: The number of output filters in the convolution\n2. **Kernel Size**: The height and width of the convolution window\n3. **Strides**: The stride of the convolution\n4. **Input Shape**: The first Convolution layer will have input shape of 128x128x3 (128x128 is the image size and 3 specifies the channel as 'RGB')\n\nThen we have **Batch Normalization** and **Dropout** as measure to prevent over-fitting and increase balance.\n\n**Max Pooling** reduces the dimension of the cluster from one layer to the next by using the maximum value.\n\n**Flatten** is used to change the dimension so that the output of Convolutional layer can be fed into a fully connected layer.\n\nWe are going to use **ImageDataGenerator** to preprocess the images.","1cd6f5a7":"#### Load the best model.","481635b1":"#### The filename of a cat's image will start with 'cat' and a dog's image will start with 'dog'. So using this feature create a dataframe with file names and their categories.\n#### I took help for the following code block from https:\/\/www.kaggle.com\/uysimty\/keras-cnn-dog-or-cat-classification.","e48bea77":"#### See the files in the input directory.","8420c1cc":"#### This is another well known dataset to do hands on *Image Classification * using Convolutional Neural Network (CNN).\n#### CNN as a subset of *Deep Learning* uses *Convolution* instead of linear matrix operation. *Convolution* is a mathematical operation between 2 functions f(x) and g(x) expressing how the shape of one is modified by the other as f *o* g(x).\n\n#### Import the libraries.","7984f761":"#### Early Stopping and Checkpoint","9b30936d":"#### Use one sample image from test set and predict its class.","8378ebc2":"#### We can see that there are same number of images of each category.\n#### We will now see a sample image from the 'train' set. Since each image has different dimension we will use a standard dimension of 128x128 which is a reduced version of the images' actual dimension.","72cb5dac":"#### Unzip the 'test' set.","206f200a":"#### We can see the class of the image is correctly predicted as '1' which means 'dog'.","94916040":"#### Check the distribution of category in validation dataset.","9b31e262":"#### Unzip the 'train' zip file into a 'Temp' folder in \/kaggle\/working directory.","be477a63":"#### Build the model.","52cacc94":"#### Check the distribution of category in train dataset.","69dd9c37":"#### Create the submission file.","a592f79a":"#### Plotting model accuracy.","cdc7ce83":"#### Fit the data into model.","976f1f4b":"#### Create a *validation set* with 20% images from the 'train' set.","80c6b51a":"#### Preprocess the images from test set.","70ce2294":"#### Check first few lines from validation dataset.","01db89dd":"#### Predict the classes of all the images from test set.","fc796462":"#### Create a dataframe for the test data.","91b615c6":"#### Plotting model loss.","cad8bbeb":"#### We can see the class of the image is correctly predicted as '0' which means 'cat'.","f01e8efc":"#### Check whether the Unzip has worked.","7dc25904":"#### Build the validation_generator.","3ea4fdb4":"#### We have specified y_col='category' and class_mode='categorical'. So the 'ImageDataGenerator' will convert the 'category' column into 2D one-hot-encoded matrix and we can see the value assigned to each class of the 'category' column through 'class_indices'."}}