{"cell_type":{"d50ce0a5":"code","6cafb713":"code","5cc23266":"code","d5d8f2b8":"code","b59c4715":"code","1ac120ce":"code","74153227":"code","e6a53ce3":"code","cf5335da":"code","baa6bd43":"code","6e13e101":"markdown","4b05935b":"markdown","2f96e286":"markdown","93a6f9b3":"markdown","11346741":"markdown"},"source":{"d50ce0a5":"# display some images for every different expression\n\nimport numpy as np\nimport seaborn as sns\nfrom keras.preprocessing.image import load_img, img_to_array\nimport matplotlib.pyplot as plt\nimport os\n\n# size of the image: 48*48 pixels\npic_size = 48\n\n# input path for the images\nbase_path = \"..\/input\/face-expression-recognition-dataset\/images\/\"\n\nplt.figure(0, figsize=(12,20))\ncpt = 0\n\nfor expression in os.listdir(base_path + \"train\"):\n    for i in range(1,6):\n        cpt = cpt + 1\n        plt.subplot(7,5,cpt)\n        img = load_img(base_path + \"train\/\" + expression + \"\/\" +os.listdir(base_path + \"train\/\" + expression)[i], target_size=(pic_size, pic_size))\n        plt.imshow(img, cmap=\"gray\")\n\nplt.tight_layout()\nplt.show()","6cafb713":"# building data generator \n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbatch_size = 128\nbase_path = \"..\/input\/face-expression-recognition-dataset\/images\/\"\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1.0\/255.0,\n                                  width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   rotation_range = 20,\n                                   horizontal_flip = True)\n\nvalidation_datagen = ImageDataGenerator(rescale= 1.0\/255)\n\ntrain_generator = train_datagen.flow_from_directory(base_path + \"train\",\n                                                    target_size=(56,56),\n                                                    color_mode=\"grayscale\",\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=True)\n\nvalidation_generator = validation_datagen.flow_from_directory(base_path + \"validation\",\n                                                    target_size=(56,56),\n                                                    color_mode=\"grayscale\",\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=False)","5cc23266":"from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\n\n# number of possible label values\nnb_classes = 7\n\n# Initialising the CNN\nmodel = Sequential()\n\n# 1 - Convolution\nmodel.add(Conv2D(64,(3,3), padding='same', input_shape=(56, 56,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel.add(Conv2D(128,(5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 3rd Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4th Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flattening\nmodel.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(nb_classes, activation='softmax'))\n\nprint(model.summary())\n\nopt = Adam(lr=0.0001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])","d5d8f2b8":"%%time\n\n# number of epochs to train the NN\nepochs = 50\n\n# checkpoint to save best model\nfrom keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit_generator(generator=train_generator,\n                                steps_per_epoch=train_generator.n\/\/train_generator.batch_size,\n                                epochs=epochs,\n                                validation_data = validation_generator,\n                                validation_steps = validation_generator.n\/\/validation_generator.batch_size,\n                                callbacks=callbacks_list\n                                )","b59c4715":"# visualise training and testing accuracy and loss\n\ndef plot_results(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(1, len(acc) + 1)\n\n    plt.figure(figsize = (24, 6))\n    plt.subplot(1,2,1)\n    plt.plot(epochs, acc, 'b', label = 'Training Accuracy')\n    plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n    plt.grid(True)\n    plt.legend()\n    plt.xlabel('Epoch')\n    \n\n\n    plt.subplot(1,2,2)\n    plt.plot(epochs, loss, 'b', label = 'Training Loss')\n    plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n    plt.grid(True)\n    plt.legend()\n    plt.xlabel('Epoch')\n    plt.show()\n \n# print best epoch with best accuracy on validation\n\ndef get_best_epcoh(history):\n    valid_acc = history.history['val_accuracy']\n    best_epoch = valid_acc.index(max(valid_acc)) + 1\n    best_acc =  max(valid_acc)\n    print('Best Validation Accuracy Score {:0.5f}, is for epoch {}'.format( best_acc, best_epoch))\n    return best_epoch","1ac120ce":"plot_results(history)\nbest_epoch =get_best_epcoh(history)","74153227":"import numpy as np\nimport cv2\nfrom tensorflow.keras.models import model_from_json","e6a53ce3":"model_json_file = '..\/input\/face-expression-model\/model.json'\nmodel_weights_file = '..\/input\/face-expression-model\/model_weights.h5'\nwith open(model_json_file, \"r\") as json_file:\n    loaded_model_json = json_file.read()\n    loaded_model = model_from_json(loaded_model_json)\n    loaded_model.load_weights(model_weights_file)\n    \n    ","cf5335da":"face_cascade = cv2.CascadeClassifier('..\/input\/face-expression-model\/haarcascade_frontalface_default.xml')","baa6bd43":"cap = cv2.VideoCapture(0)\nimport copy\n\nwhile True:\n    \n    ret, frame = cap.read()\n    img = copy.deepcopy(frame)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n    for (x,y,w,h) in faces:\n        fc = gray[y:y+h, x:x+w]\n        \n        roi = cv2.resize(fc, (48,48))\n        pred = loaded_model.predict(roi[np.newaxis, :, :, np.newaxis])\n        text_idx=np.argmax(pred)\n        text_list = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n        if text_idx == 0:\n            text= text_list[0]\n        if text_idx == 1:\n            text= text_list[1]\n        elif text_idx == 2:\n            text= text_list[2]\n        elif text_idx == 3:\n            text= text_list[3]\n        elif text_idx == 4:\n            text= text_list[4]\n        elif text_idx == 5:\n            text= text_list[5]\n        elif text_idx == 6:\n            text= text_list[6]\n        cv2.putText(img, text, (x, y-5),\n           cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 255), 2)\n        img = cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,255), 2)\n            \n    \n    cv2.imshow(\"frame\", img)\n    key = cv2.waitKey(1) & 0xFF\n    if key== ord('q'):\n        break\n    \ncap.release()\ncv2.destroyAllWindows()\n","6e13e101":"## Connecting with openCV","4b05935b":"# DoUpvote Please","2f96e286":"## Load our dataset\n#### Display some images from our dataset\n#### Dataset contain images from seven different Categories","93a6f9b3":"## Image augmentation using keras ImageDataGenerator","11346741":"# Defining our 4 Convolution and 2 Dense layers model"}}