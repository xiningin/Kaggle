{"cell_type":{"d1353435":"code","b0fd17a5":"code","f954e9bf":"code","a9657e31":"code","c144e2eb":"code","d7faa0e1":"code","cb2da55d":"code","81eea0a2":"code","9cfc7513":"code","68eddffe":"code","ed0e1ee1":"code","65de5d02":"code","0a60d0a7":"code","f5ef62a3":"code","fc84c76f":"code","138474b1":"code","be789620":"code","fcdec1d2":"code","373b3bad":"code","357c8d62":"code","883d0762":"code","376c109c":"code","d1b91528":"code","3077113e":"code","dd84d8f1":"code","80302e5b":"code","b4b0dbe1":"code","9410b0d5":"markdown","ccd8db85":"markdown","56cdf8bc":"markdown","f0c075a2":"markdown","b58d17d6":"markdown","0669448a":"markdown","237baf08":"markdown","9ac8ae4a":"markdown","6ed737c8":"markdown","de6830e4":"markdown","efd56b9e":"markdown","6e5cd21d":"markdown","7f5ac569":"markdown","c37e7029":"markdown","7cf79b68":"markdown","09a2bca8":"markdown","05813335":"markdown","9a48e118":"markdown","8059aad2":"markdown","30401c93":"markdown","0f95e1d4":"markdown","5839bc93":"markdown","5609479e":"markdown","e8de849f":"markdown","5c785ee9":"markdown","9a46624c":"markdown","5dd70964":"markdown","90b0817e":"markdown","31ef9052":"markdown","b495c423":"markdown","a42ec3fc":"markdown","1cf8af10":"markdown","16e2829e":"markdown","f8208fd2":"markdown","63740366":"markdown","a9c13873":"markdown","a3d18f63":"markdown","2298ed66":"markdown"},"source":{"d1353435":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b0fd17a5":"perform_data = pd.read_csv(r'..\/input\/body-performance-data\/bodyPerformance.csv')\nperform_data.head(10)","f954e9bf":"perform_data.info()","a9657e31":"np.sort(perform_data['class'].unique())","c144e2eb":"perform_data = perform_data.replace({'gender':{'M':0 , 'F':1}, \\\n                                    'class':{'A':1, 'B':2, 'C':3, 'D':4}})\nperform_data.head(10)","d7faa0e1":"fig, ax = plt.subplots(figsize=(8,8))\ncorr = sns.heatmap(perform_data.corr(), ax=ax, cmap='RdPu', annot=True)","cb2da55d":"sns.pairplot(perform_data)","81eea0a2":"sns.displot(perform_data, x='age', hue='class', multiple=\"stack\") #color='coral'","9cfc7513":"young_group = perform_data.loc[perform_data['age']<35, 'age']\nmidage_group = perform_data.loc[(perform_data['age']>=35) & (perform_data['age']<=50), 'age']\nadult_group = perform_data.loc[perform_data['age']>50, 'age']\n\nprint('Age 20-34 group size is {:.0f} and constitute {:.1f}% of our data'.format(len(young_group), (len(young_group))\/(len(perform_data))*100))\nprint('Age 35-50 group size is {:.0f} and constitute {:.1f}% of our data'.format(len(midage_group), len(midage_group)\/len(perform_data)*100))\nprint('Age 51+ group size is {:.0f} and constitute {:.1f}% of our data'.format(len(adult_group), len(adult_group)\/len(perform_data)*100))","68eddffe":"perform_by_decades = perform_data.groupby(perform_data['age']\/\/10*10)\nperform_by_decades['class'].value_counts(sort=True)","ed0e1ee1":"sns.barplot(x=perform_data['gender'].value_counts().index,\\\n            y=perform_data['gender'].value_counts().values, \\\n           color='plum')\n\nperform_data['gender'].value_counts()","65de5d02":"total_males, total_females = perform_data['gender'].value_counts()\nprint('Women precentage:{:.1f}%'.format(total_females\/len(perform_data)*100))\nprint('Men precentage:{:.1f}%'.format(total_males\/len(perform_data)*100))","0a60d0a7":"sns.displot(data=perform_data, x=\"age\", hue=\"class\", col=\"gender\", multiple=\"stack\")","f5ef62a3":"sns.displot(perform_data, x='height_cm', hue='class', multiple=\"stack\")\n\nprint('\\nAvarage heaight: {:.0f} cm\\n'.format(perform_data['height_cm'].mean()))","fc84c76f":"perform_by_decimetres = perform_data.groupby(perform_data['height_cm']\/\/10*10)\nperform_by_decimetres['class'].value_counts(sort=True)","138474b1":"sns.displot(perform_data, x='height_cm', y='age', color='plum')","be789620":"sns.displot(data=perform_data, x=\"weight_kg\", hue=\"class\", multiple=\"stack\")\nprint('\\nAvarage weight: {:.0f} kg\\n'.format(perform_data['weight_kg'].mean()))","fcdec1d2":"lean_people = perform_data.loc[perform_data['weight_kg']<45, :]\nsns.displot(data=lean_people, x=\"weight_kg\", hue=\"class\", multiple=\"stack\")","373b3bad":"overweight_people = perform_data.loc[perform_data['weight_kg']>95, :]\nsns.displot(data=overweight_people, x=\"weight_kg\", hue=\"class\", multiple=\"stack\")","357c8d62":"sns.displot(data=perform_data, x=\"weight_kg\", col=\"gender\", color='plum', multiple=\"stack\")\n\nfemale, male = perform_data.loc[perform_data['gender']==1,:], perform_data.loc[perform_data['gender']==0,:]\nprint('\\nFemales avarage weight: {:.1f} kg'.format(female['weight_kg'].mean()))\nprint('Males avarage weight: {:.1f} kg\\n'.format(male['weight_kg'].mean()))","883d0762":"sns.displot(data=perform_data, x=\"weight_kg\", y='age', color='plum')","376c109c":"sns.displot(data=perform_data, x=\"weight_kg\", y='height_cm', color='plum')","d1b91528":"sns.displot(data=perform_data, x=\"weight_kg\", y='body fat_%', color='plum')","3077113e":"def run_algo_on_data(X, y, algo_class, algo_name, **params):\n    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=42)\n    algo = algo_class(**params)\n    algo.fit(train_X, train_y)\n    r2_train = algo.score(train_X, train_y)\n    y_predicted = algo.predict(test_X)\n    accuracy = accuracy_score(test_y, y_predicted)\n    print('r^2 on training data for', algo_name, '{:.2f}'.format(r2_train))\n    print('Accuracy score for', algo_name, '{:.2f}'.format(accuracy))\n    print('---'*10)","dd84d8f1":"X0 = perform_data.iloc[:,:-1]\ny0 = perform_data['class']\n\nrun_algo_on_data(X0, y0, RandomForestClassifier, 'Random Forest Classifier')\nrun_algo_on_data(X0, y0, AdaBoostClassifier, 'AdaBoost Classifier')\nrun_algo_on_data(X0, y0, SVC, 'SVC')","80302e5b":"young = perform_data.loc[perform_data['age']<35, :]\ny1 = young['class']\nX1 = young.iloc[:,1:-1]\nprint('Random Forrest on young people:\\n')\nrun_algo_on_data(X1, y1, RandomForestClassifier, 'Random Forest Classifier', warm_start=True)\n\nmid = perform_data.loc[(perform_data['age']>=35) & (perform_data['age']<=50), :]\ny2 = mid['class']\nX2 = mid.iloc[:,1:-1]\nprint('\\nRandom Forrest on mid-age people:\\n')\nrun_algo_on_data(X2, y2, RandomForestClassifier, 'Random Forest Classifier', warm_start=True)\n\nadult = perform_data.loc[perform_data['age']>50, :]\ny3 = adult['class']\nX3 = adult.iloc[:,1:-1]\nprint('\\nRandom Forrest on adult people:\\n')\nrun_algo_on_data(X3, y3, RandomForestClassifier, 'Random Forest Classifier', warm_start=True)","b4b0dbe1":"adult20_25 = perform_data.loc[(perform_data['age']>=20) & (perform_data['age']<=25), :]\ny4 = adult20_25['class']\nX4 = adult20_25.iloc[:,1:-1]\nprint('\\n20 - 25:\\n')\nrun_algo_on_data(X4, y4, RandomForestClassifier, 'Random Forest Classifier', warm_start=True)\n\nadult26_30 = perform_data.loc[(perform_data['age']>25) & (perform_data['age']<=30), :]\ny5 = adult26_30['class']\nX5 = adult26_30.iloc[:,1:-1]\nprint('\\n25 - 30:\\n')\nrun_algo_on_data(X5, y5, RandomForestClassifier, 'Random Forest Classifier', warm_start=True)\n\nadult30_40 = perform_data.loc[(perform_data['age']>30) & (perform_data['age']<=40), :]\ny6 = adult30_40['class']\nX6 = adult30_40.iloc[:,1:-1]\nprint('\\n31 - 40:\\n')\nrun_algo_on_data(X6, y6, RandomForestClassifier, 'Random Forest Classifier', warm_start=True)\n\nadult41_58 = perform_data.loc[(perform_data['age']>40) & (perform_data['age']<=58), :]\ny7 = adult41_58['class']\nX7 = adult41_58.iloc[:,1:-1]\nprint('\\n41 - 58:\\n')\nrun_algo_on_data(X7, y7, RandomForestClassifier, 'Random Forest Classifier', warm_start=True)\n\nadult58_above = perform_data.loc[perform_data['age']>58, :]\ny8 = adult58_above['class']\nX8 = adult58_above.iloc[:,1:-1]\nprint('\\n59 and above:\\n')\nrun_algo_on_data(X8, y8, RandomForestClassifier, 'Random Forest Classifier', warm_start=True)","9410b0d5":"##### Weight - Age:","ccd8db85":"There are more people in their 20's than other group ages in our data. That might be the reason for our lack of correlation with body performance.\n\nIn order to analyse the distribution display, we should ignore the classes' boxes' size in each column and look at their proprpotions. We can see that in most age-groups there is no particular prominent grade box. Notably, there are some exceptions: for example, if you look closely, the groups between mid-40 and 60 have smaller '1' box (meaning, grade 'A' box). Nevertheless, I wouldn't say they are imbalanced, because they are not that significally small.\n\nWe might see it better if we group our data by decades (20's, 30's, 40's, etc.):","56cdf8bc":"## Age Factor\n\nAccording to several researches[1] aging impairs most physical capacities, which means that there is a correlation between age and body performance. Nevertheless, in our data it is not shown. Let's investigate why.\n\nBelow, we can see the distribution of number of people and their age:","f0c075a2":"## Weight Factor","b58d17d6":"Now we can check up for correlations between the parameters and the body performance:","0669448a":"##### Weight - Age:","237baf08":"## Gender Factor","9ac8ae4a":"##### Overweight people (>95 kg):","6ed737c8":"Transforming (A,B,C,D) into (1,2,3,4), and (M,F) into (0,1) correspondingly: ","de6830e4":"And indeed, Random Forest won.\n\nNow, let's split the data and use Random Forest, adding a slight improvement.","efd56b9e":"Interesting.\n\nThere are people with relatively low fat precentage and considered 'overweight'. I assume that those people are bodybuilders, since usually their weight is based on muscles and have a very low fat rate [4]. On the other hand, we can see 'lean' people with high fat precentage. Those people are known as 'skinny fat' (or 'thin fat obesity' phenomena [5]). Skinny fat people have low muscle mass and their fat percentage is high compared to it. The causes for this condition are usually sedentariness, lack of muscle, or poor diet.","6e5cd21d":"Let's see heights' distribution.","7f5ac569":"# References\n1. The age-performance relationship - https:\/\/archpublichealth.biomedcentral.com\/articles\/10.1186\/s13690-019-0375-8\n\n2. Women live longer than men - https:\/\/pubmed.ncbi.nlm.nih.gov\/23331196\/\n\n3. Weight-height relationships and body mass index - https:\/\/pubmed.ncbi.nlm.nih.gov\/15761809\/\n\n4. Muscle Mass and Body Fat in Bodybuilders - https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC6942464\/\n\n5. Thin Fat Obesity - https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK568563\/\n","c37e7029":"It looks better. I believe I could get even better results if I split even more, but in my opinion, it would be easier and efficient if I find more data.\n\nTo sum up, I believe that there *is* a relationship between age and body performance as other researches had found. However, unfotunately we cannot see it here, not as long as we don't add more data. I do believe that more data will give us a better prediction about someone's body performance by considering his age. But let's not throw in the towel; after all, by spliting the data into age groups, the ML model worked well.\n\nOverall, this project was fun. I hope you enjoyed it as well. Thank you :)","7cf79b68":"It doesn't look perfect, but it isn't bad either. I can be even more thorough and split the age range even more. ","09a2bca8":"We can see that there is a somewhat relationship between height and weight. But this is not surprising [3].","05813335":"There is no correlation.","9a48e118":"## Height Factor","8059aad2":"### Age and Height\n\nAs you can see above, in the correlation table, there is a seldom relationship between height and age. Nevertheless, it is still interesting to see how they relate with each other.","30401c93":"### Weight Relations - Age, Gender, Height and Body-Fat","0f95e1d4":"##### Lean people (<45 kg):","5839bc93":"# Exploring Factors\n\n","5609479e":"### Gender and Age\n\n","e8de849f":"We must take into account that there is lack of information for short people (120-140 cm) and for tall people (190+ cm). Except for the outliers (meaning, short and tall people), the proportions between classes in each height group are pretty much equal. Nevertheless, we can see that people around avarage height tend to perform better than the shorter or higher people. Yet, with this result we cannot say wether people with a certain height are in a good shape or not. \n","5c785ee9":"We can divide our height range into decimetres value.","9a46624c":"To sum up, it is not so surprising that more people in their 20's and 30's have a better body perofmance than the rest, as we can see in our result. And yet,it is surprising that people in their 60's tend to be in a better shape than those in their 40's and 50's. I assume that people in their 60's had probably retired from work, hance they have more time to do sports. Nevertheless, we must not forget to take into account that in our data there are less people in their 60's.","5dd70964":"There are more young people, hence it's not that surprising that they are shown mostly around the avarage height value.","90b0817e":"It's hard to tell what is happening in the tails, so let's take a better look.\n","31ef9052":"Since we have an imbalance in our age data, the best way to deal with it is to add more samples, especially for the groups mid-age and adult. But for now let's deal with what we have.\n\nAnother way to deal with the imbalance, is to split the data into three main groups: young, mid and adult, and do on each of them a ML model. Note that if we are not being careful, we might get an overfit.  \nBefore I start with this process, I want to see what model would work the best for our data. I will check Random Forest, AdaBoost and SVC. Since there is seldom-to-none relationship with the features and grades of body performance, I forsee that the best model would be the famous Random Forest.","b495c423":"There are more men than women in our dataset, and they constitute 63% of our data. There *is* a slight imbalance, yet, in my opinion it is not biased enough to influence a predction.","a42ec3fc":"Since there are more males than females, in order to analyse this display, we should ignore the classes' boxes' size in each column and look at their proprpotions. For instance, females at their early 20's tend to perform better than males in their age. On the other hand, when both males and females are about 60 years old, *men* tend to show better performance. In the range 30 - 60 they tend to behave pretty much the same, more or less, with seldom exceptions.\n\nThe reason for this behaviour, in my opinion is this: young women want to look better, probably to get a match, or other reasons, hence they would do more exercises then men. Then, as we all know, women live longer than men [2], and perhaps in terms to enlarge their life span, men would like to keep their body in a good estate. Hence is why I believe we see this distribution.","1cf8af10":"It is not unambiguous. Some are in a good shape, some are not.","16e2829e":"# Intro\n\nThe data that we are going to explore was taken from Korea Sports Promotion Foundation, and it shows the grade of performance concidering age, gender, weight, height and more factors that might influence one's body performence. In this project I will explore the possible features that can have an impact on our body performance, and see wether there is a Machine Learning model that can predict one's body performance's grade considering his age.\n\nLet's load our data and see how it looks:","f8208fd2":"# Muchine Learning Models and Making Predictions","63740366":"Cheers! There is no missing values!\n\nNow, after our little celebration, let's dig a little bit in.\n\nAs we can see, there are eleven factors in our data for the body performance grade that is shown in 'class'; seven of the features are physical body attributes and the rest are types of exercises. All features (except for 'gender' and 'class'), are 'float' type. As for 'gender' and 'class', the type is 'object'. Hence, before we begin, I shall transorm them into 'float' type. In this way we will be able to analyse our data.\n\nWe can see from the table above that 'gender' consist 'M' for male and 'F' for female. As for the body performance grade we have:","a9c13873":"It's interesting to see how little correlation there is between the features with the body performence. In addition, one would expect a clear correlation with age or body fat, yet, in both of them the correlation is low. The only feature that has somewhat correlation was 'sit and bend forward': the farther you bend, the better your body performance is. \n\nYet, let's not ignore other relationships. We can see a high correlation between grip force and broad jump, and between sit ups and (again) broad jumps. There are more relationships that mainly concern physical properties, such as height and weight, or weight and grip force, and more, but to me they are not interesting since they didn't surprise me.\n\nVisualising the correlations:","a3d18f63":"##### Weight - Height:","2298ed66":"Here it's clear that the heavier you are, the lower grade you have."}}