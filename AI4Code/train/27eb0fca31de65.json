{"cell_type":{"1a8503fb":"code","11571ae7":"code","82a51a6a":"code","1997fa5e":"code","dd4fa068":"code","c9d84637":"code","c971c1bd":"code","e0f87992":"code","5b1eeb09":"code","22bdf5fd":"code","cc7425f2":"code","bf11671d":"code","a2e25125":"code","e44545f6":"code","4d3e7c14":"code","5c5250f5":"code","51aeeff2":"code","20741f59":"code","e2151ea7":"code","f419798c":"code","56d5976c":"code","3ff4163b":"code","c2c40b02":"code","2abb3dcf":"code","ea8af2cb":"code","07c0ef03":"code","e8f9a3c3":"code","5be9522f":"code","5a694a08":"code","3f0e345c":"code","67e82380":"code","a38474b6":"code","74523a96":"code","d21290ed":"code","cec20abb":"code","903998f5":"code","34e27362":"code","6820832b":"code","4fb42dd6":"code","2b5c0e42":"code","a672464c":"code","5d635f0d":"code","9dbaad00":"code","e194d68f":"code","db295bf9":"code","38ad4a73":"code","a9451808":"code","d64e1b09":"code","7b69b857":"code","493506df":"code","3a1c5183":"code","76751b4c":"code","877dcb86":"code","18de77f6":"code","615065b2":"code","501a2488":"code","2a9e0382":"code","d5cf2124":"code","e98fc3e2":"code","21398c00":"code","54b44ba5":"code","2b75a043":"markdown","1b72dbd6":"markdown","e4361a72":"markdown","8587adb3":"markdown","a13c6f3c":"markdown","e7669c4f":"markdown","cfa54416":"markdown","06bf5b73":"markdown","6ff9abc5":"markdown","4ea27575":"markdown","fba2d331":"markdown","c82b7b51":"markdown"},"source":{"1a8503fb":"# ! conda install -c conda-forge gdcm -y\n\n# Net Off - Can't use this\n# Thanks to\n# https:\/\/www.kaggle.com\/c\/siim-covid19-detection\/discussion\/241582\n# Example:\n# Changed from: 'libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2'\n# Changed to: '..\/input\/GDCM-notebook\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2'\n\n!conda install '..\/input\/pydicom-gdcm\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '..\/input\/pydicom-gdcm\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '..\/input\/pydicom-gdcm\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '..\/input\/pydicom-gdcm\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '..\/input\/pydicom-gdcm\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '..\/input\/pydicom-gdcm\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","11571ae7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nUNIV_SEED = 2021\nfrom ast import literal_eval\nimport json","82a51a6a":"extract_path = \"\/kaggle\/input\/siim-covid-512-reshaped-corrected-bounded-box\/Extracted_Study_Series_Img.csv\"\ndf = pd.read_csv(extract_path)\ndf.head()","1997fa5e":"df.tail()","dd4fa068":"import os\ndata_dir = \"\/kaggle\/input\/siim-covid-512-reshaped-corrected-bounded-box\/resized_data\/resized_data\"\nNew_Image_Path = []\nfor index, row in df.iterrows():\n    img_path = row[\"Image_Name\"]\n    curr_set = row[\"Set_Name\"]\n    png_path = img_path.replace('.dcm','.png').zfill(16)\n    new_path = os.path.join(data_dir,curr_set,png_path)\n    New_Image_Path.append(new_path)\ndf[\"New_Image_Path\"] = New_Image_Path","c9d84637":"len(\"0026720152f5.png\")","c971c1bd":"n = 20\ntrain_df = df[df[\"Set_Name\"] == \"train\"]\nsample_train = train_df.sample(n)\nsample_train.reset_index(inplace = True)\n\ntest_df = df[df[\"Set_Name\"] == \"test\"]\nsample_test = test_df.sample(n)\nsample_test.reset_index(inplace = True)","e0f87992":"sample_train.head(2)","5b1eeb09":"import matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n%matplotlib inline\nimport cv2\nplt.style.use(\"dark_background\")","22bdf5fd":"import pydicom as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport PIL\nfrom PIL import Image\nfrom colorama import Fore, Back, Style\nviz_counter=0\n\ndef create_dir(dir, v=1):\n    \"\"\"\n    Creates a directory without throwing an error if directory already exists.\n    dir : The directory to be created.\n    v : Verbosity\n    \"\"\"\n    if not os.path.exists(dir):\n        os.makedirs(dir)\n        if v:\n            print(\"Created Directory : \", dir)\n        return 1\n    else:\n        if v:\n            print(\"Directory already existed : \", dir)\n        return 0\n\nvoi_lut=True\nfix_monochrome=True\n\ndef dicom_dataset_to_dict(filename):\n    \"\"\"Credit: https:\/\/github.com\/pydicom\/pydicom\/issues\/319\n               https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    \"\"\"\n    \n    dicom_header = dicom.dcmread(filename) \n    \n    #====== DICOM FILE DATA ======\n    dicom_dict = {}\n    repr(dicom_header)\n    for dicom_value in dicom_header.values():\n        if dicom_value.tag == (0x7fe0, 0x0010):\n            #discard pixel data\n            continue\n        if type(dicom_value.value) == dicom.dataset.Dataset:\n            dicom_dict[dicom_value.name] = dicom_dataset_to_dict(dicom_value.value)\n        else:\n            v = _convert_value(dicom_value.value)\n            dicom_dict[dicom_value.name] = v\n      \n    del dicom_dict['Pixel Representation']\n    \n    #====== DICOM IMAGE DATA ======\n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom_header.pixel_array, dicom_header)\n    else:\n        data = dicom_header.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom_header.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    modified_image_data = (data * 255).astype(np.uint8)\n    \n    return dicom_dict, modified_image_data\n\ndef _sanitise_unicode(s):\n    return s.replace(u\"\\u0000\", \"\").strip()\n\ndef _convert_value(v):\n    t = type(v)\n    if t in (list, int, float):\n        cv = v\n    elif t == str:\n        cv = _sanitise_unicode(v)\n    elif t == bytes:\n        s = v.decode('ascii', 'replace')\n        cv = _sanitise_unicode(s)\n    elif t == dicom.valuerep.DSfloat:\n        cv = float(v)\n    elif t == dicom.valuerep.IS:\n        cv = int(v)\n    else:\n        cv = repr(v)\n    return cv\n\"\"\"\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n\"\"\"\ndef view_data(sample_train,view=\"original\"):\n    if view==\"resized\":\n        fig, axs = plt.subplots(4, 5, figsize=(20,20))\n        fig.subplots_adjust(hspace=.2, wspace=.2)\n        axs = axs.ravel()\n        for i in range(n):\n            img = cv2.imread(sample_train['New_Image_Path'][i])\n            axs[i].imshow(img,cmap='gray')\n            if type(sample_train['corrected_boxes'][i])==str and (not sample_train['corrected_boxes'][i]==\"\") and (not sample_train['corrected_boxes'][i]==np.nan) :\n                boxes = literal_eval(sample_train['corrected_boxes'][i])\n                for box in boxes:\n                    axs[i].add_patch(Rectangle((box['x'], box['y']), box['width'], box['height'], fill=0, color='y', linewidth=2))\n                axs[i].set_title(sample_train['study_label'][i])\n            else:\n                axs[i].set_title(sample_train['study_label'][i])\n    if view==\"original\":\n        fig, axs = plt.subplots(4, 5, figsize=(20,20))\n        fig.subplots_adjust(hspace=.2, wspace=.2)\n        axs = axs.ravel()\n        for i in range(n):\n            fpath = sample_train['Image_Path'][i]\n            dicom_dict, modified_image_data = dicom_dataset_to_dict(fpath)\n            # print(modified_image_data.shape)\n            # rgb2gray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114])   \n            img = modified_image_data\n            axs[i].imshow(img,cmap='gray')\n            if type(sample_train['boxes'][i])==str and (not sample_train['boxes'][i]==\"\") and (not sample_train['boxes'][i]==np.nan):\n                boxes = literal_eval(sample_train['boxes'][i])\n                for box in boxes:\n                    axs[i].add_patch(Rectangle((box['x'], box['y']), box['width'], box['height'], fill=0, color='y', linewidth=2))\n                axs[i].set_title(sample_train['study_label'][i])\n            else:\n                axs[i].set_title(sample_train['study_label'][i])\n        ","cc7425f2":"view_data(sample_train,view=\"original\")","bf11671d":"view_data(sample_train,view=\"resized\")","a2e25125":"sample_test.head(2)","e44545f6":"view_data(sample_test,view=\"resized\")","4d3e7c14":"df.tail(2)","5c5250f5":"# !pip install openpyxl","51aeeff2":"df.to_csv('Resized_MetaData.csv',index=False)\n# df.to_excel('Resized_MetaData.xlsx',index=False)","20741f59":"def subtract_lists(x,y):\n    \"\"\"Subtract Two Lists (List Difference)\"\"\"\n    return [item for item in x if item not in y]\ndef merge_list_to_dict(test_keys,test_values):\n    \"\"\"Using dictionary comprehension to merge two lists to dictionary\"\"\"\n    merged_dict = {test_keys[i]: test_values[i] for i in range(len(test_keys))}\n    return merged_dict\n# CLASSES = subtract_lists(list(set(df[\"study_label\"])),[np.nan])\nCLASSES = ['negative','indeterminate', 'typical',  'atypical'] # keep negative at start","e2151ea7":"# IMAGE_LABELS = subtract_lists(list(set(df[\"image_label\"])),[np.nan])\nIMAGE_LABELS = ['none','opacity']","f419798c":"np.random.seed(UNIV_SEED)","56d5976c":"sub_pth = \"..\/input\/siim-covid19-detection\/sample_submission.csv\"\ndf_sub = pd.read_csv(sub_pth)\ndf_sub.head()","3ff4163b":"df_sub.tail()","c2c40b02":"idx_img = []\nidx_std = []\n\nfor index, row in df_sub.iterrows():\n    if row[\"id\"].endswith('_image'):\n        idx_img.append(int(index))\n    if row[\"id\"].endswith('_study'):\n        idx_std.append(int(index))","2abb3dcf":"len(idx_img)","ea8af2cb":"len(idx_std)","07c0ef03":"df_sub.shape","e8f9a3c3":"df_sub_img = df_sub.iloc[idx_img]\ndf_sub_std = df_sub.iloc[idx_std]","5be9522f":"df_sub_img.head()","5a694a08":"df.head(2)","3f0e345c":"df_sub_img[\"Image_ID\"] = df_sub_img[\"id\"].str.replace(\"_image\",\"\")","67e82380":"df_img = df_sub_img.merge(df,on=\"Image_ID\")\ndf_img.head()","a38474b6":"df_sub_img.shape","74523a96":"df_img.shape","d21290ed":"CLASSES","cec20abb":"CLASS_LABELLINGS = merge_list_to_dict(CLASSES,list(range(len(CLASSES))))\nCLASS_LABELLINGS","903998f5":"def get_preds(img = np.zeros((512,512))):\n    \"\"\"\n    Returns Classes and BBoxes\n    \"\"\"\n    Shape_X,Shape_Y = img.shape\n    Height_X = Shape_X\/4\n    Height_Y = Shape_Y\/4\n    num_preds = np.random.randint(low=0,high=4)\n    # print(num_preds4\n    CLASSES_IDX = []\n    CONFS = []\n    \n    BBOX = []\n    for i in range(num_preds):\n        CLS = np.random.randint(low=1,high=4) # 1,2,3\n        conf = np.random.randint(low=7,high=11)\/10 # Confidence > 7 - 7-10\n        x = np.random.randint(low=40,high=61) * Height_X\/100\n        y = np.random.randint(low=40,high=61) * Height_Y\/100\n\n        init_x = np.random.randint(low=Height_X,high=(Shape_X-Height_X))\n        init_y = np.random.randint(low=Height_Y,high=(Shape_Y-Height_Y))\n\n        data = {\"x\":init_x,\n                \"y\":init_y,\n                \"width\":x,\n                \"height\":y}\n        \n        BBOX.append(data)\n        CLASSES_IDX.append(CLS)\n        CONFS.append(conf)\n    \n    return CLASSES_IDX,BBOX,CONFS\n\n    \nget_preds()","34e27362":"df_img[\"confidences\"] = str([])\ndf_img.head(2)","6820832b":"std_value_cnts = df_img[\"Study_Name\"].value_counts()","4fb42dd6":"greater_than_one = std_value_cnts>1\ngreater_than_one.sum()","2b5c0e42":"CLASS_LABELLINGS","a672464c":"CLASS_VALS = {v: k for k, v in CLASS_LABELLINGS.items()}\nCLASS_VALS","5d635f0d":"\"\"\"\nIMG_PREDS = []\nSTUDY_PREDS = []\n\"\"\"\nfor index, row in df_img.iterrows():\n    img_path = row[\"New_Image_Path\"]\n    img = cv2.imread(img_path,0)\n    # print(img.shape)\n    CLASSES_IDX,BBOX,CONFS = get_preds(img)\n    \n    if CLASSES_IDX==[]:\n        df_img.loc[index, \"image_label\"] = \"none\"\n        df_img.loc[index, \"study_label\"] = \"negative\"\n        df_img.loc[index, \"confidences\"] = str([])\n        df_img.loc[index, \"corrected_boxes\"] = str([])\n    else:\n        PRED_CLASSES = []\n        for cls_idx in CLASSES_IDX:\n            e_cls = CLASS_VALS[cls_idx]\n            PRED_CLASSES.append(e_cls)\n        df_img.loc[index, \"image_label\"] = \"opacity\"\n        df_img.loc[index, \"study_label\"] = \",\".join(PRED_CLASSES)\n        df_img.loc[index, \"confidences\"] = str(CONFS)\n        df_img.loc[index, \"corrected_boxes\"] = str(BBOX)","9dbaad00":"pd.set_option('display.max_columns', None)","e194d68f":"df_img.head()","db295bf9":"df_sub.head()","38ad4a73":"df_img['ecfy'] = 1\/df_img['cfy']\ndf_img['ecfx'] = 1\/df_img['cfx']","a9451808":"from ast import literal_eval\nfor index, row in df_img.iterrows():\n    cbbox =  literal_eval(row[\"corrected_boxes\"])\n    OLD_BOXES = []\n    for each_box in cbbox:\n        data = {\"x\":each_box[\"x\"]*row[\"ecfy\"],\n                \"y\":each_box[\"y\"]*row[\"ecfx\"],\n                \"width\":each_box[\"width\"]*row[\"ecfy\"],\n                \"height\":each_box[\"height\"]*row[\"ecfx\"]}\n        OLD_BOXES.append(data)\n    df_img.loc[index, \"boxes\"] = str(OLD_BOXES)","d64e1b09":"df_img.head()","7b69b857":"view_data(df_img,view=\"resized\")","493506df":"view_data(df_img,view=\"original\")","3a1c5183":"df_img.head()","76751b4c":"df_img[\"Pred_Img\"] = \"\"\ndf_img[\"Pred_Std\"] = \"\"","877dcb86":"df_img.tail(2)","18de77f6":"for index, row in df_img.iterrows():\n    \n    Pred_Img = \"\"\n    Pred_Std = \"\"\n    study_label = row[\"study_label\"]\n    if study_label == \"negative\":\n        Pred_Img = \"negative 1 0 0 1 1\"\n        Pred_Std = \"none 1 0 0 1 1\"\n        # maybe insert confidences here (instead of the initial 1)!\n    else:\n        all_cls = study_label.split(\",\") if \",\" in study_label else [study_label]\n        bboxes =  literal_eval(row[\"boxes\"])\n        confs = literal_eval(row[\"confidences\"])\n        for each_class,each_box,each_conf in zip(all_cls,bboxes,confs):\n            # opacity 0.5 100 100 200 200 opacity 0.7 10 10 20 20\n            Pred_Img += \"opacity \"+str(round(each_conf,1))+\" \" + str(round(each_box[\"x\"],2))\n            Pred_Img +=  \" \"+ str(round(each_box[\"y\"],2))\n            Pred_Img +=  \" \" + str(round(each_box[\"width\"],2))+\" \" + str(round(each_box[\"height\"],2)) + \" \"\n            # indeterminate 1 0 0 1 1 atypical 1 0 0 1 1\n            Pred_Std += each_class + \" 1 0 0 1 1 \"\n    df_img.loc[index, \"Pred_Img\"] = str(Pred_Img)\n    df_img.loc[index, \"Pred_Std\"] = str(Pred_Std)","615065b2":"df_img[\"Pred_Img\"] = df_img[\"Pred_Img\"].str.strip()\ndf_img[\"Pred_Std\"] = df_img[\"Pred_Std\"].str.strip()","501a2488":"df_img.head(10)","2a9e0382":"df_img.to_csv('Prediction_Data.csv',index=False)\n# df_img.to_excel('Prediction_Data.xlsx',index=False)","d5cf2124":"for index, row in df_sub.iterrows():\n    img_id = row[\"id\"]\n    try:\n        if img_id.endswith('_study'):\n            idx = df_img.index[df_img['Study_Name'] == img_id.replace(\"_study\",\"\")].tolist()\n            p = df_img[\"Pred_Std\"][idx[0]]\n        elif img_id.endswith('_image'):\n            idx = df_img.index[df_img['Image_ID'] == img_id.replace(\"_image\",\"\")].tolist()\n            p = df_img[\"Pred_Img\"][idx[0]]\n        df_sub.loc[index, \"PredictionString\"] = str(p)\n    except:\n        continue","e98fc3e2":"df_sub.head()","21398c00":"df_sub.tail()","54b44ba5":"df_sub.to_csv('submission.csv',index=False)\n# df_sub.to_excel('submission.csv',index=False)","2b75a043":"# View Original Train Data","1b72dbd6":"# Get Dummy Predictions","e4361a72":"# Upscale the Predictions\n\nRemember that we have downscaled the image to a `(512,512)` shape before and we need to adjust the bounding boxes accordingly again.","8587adb3":"# Re-Verification of Scaling","a13c6f3c":"### Ignoring these for now.\nWill be clarified once the confusion is dealt with.\n\nSee Discussion : https:\/\/www.kaggle.com\/c\/siim-covid19-detection\/discussion\/244189 for more intricate details.","e7669c4f":"# View Resized Train Data","cfa54416":"# Now go ahead and build some awesome Object Detection Models!\n\nHurray! It displays the same data! Also let's try to build a mock submission file that takes in predictions from a random model and then create the `submission.csv` file. ","06bf5b73":"# Prepare Submission\n\n### Image Level","6ff9abc5":"Target:\n\n```\nId,PredictionString\n2b95d54e4be65_study,negative 1 0 0 1 1\n2b95d54e4be66_study,typical 1 0 0 1 1\n2b95d54e4be67_study,indeterminate 1 0 0 1 1 atypical 1 0 0 1 1\n2b95d54e4be68_image,none 1 0 0 1 1\n2b95d54e4be69_image,opacity 0.5 100 100 200 200 opacity 0.7 10 10 20 20\netc.\n```","4ea27575":"```\nId,PredictionString\n2b95d54e4be65_study,negative 1 0 0 1 1\n2b95d54e4be66_study,typical 1 0 0 1 1\n2b95d54e4be67_study,indeterminate 1 0 0 1 1 atypical 1 0 0 1 1\n2b95d54e4be68_image,none 1 0 0 1 1\n2b95d54e4be69_image,opacity 0.5 100 100 200 200 opacity 0.7 10 10 20 20\netc.\n```","fba2d331":"# Resized Data Paths","c82b7b51":"### Hooray! The Scaled Images have been brought back to the original size"}}