{"cell_type":{"ba8006e7":"code","bc92a8b4":"code","5f7d8fac":"code","ecee6447":"code","3e2d1e77":"code","2634943c":"code","0dde36c1":"code","a41f1ec3":"code","915f138a":"code","95e71b7a":"code","7ce0c479":"code","5dcfa1ca":"code","08591d18":"code","70efbd59":"code","2190d919":"code","86c4dd15":"code","76ab46f4":"code","410d40ff":"code","2d597f3f":"code","c1b554f8":"code","fc885b29":"code","c00120ea":"code","4070000d":"code","416f2e72":"code","07accead":"code","d7208693":"code","58377b7a":"code","c19b499d":"code","4d669853":"code","b82e13d7":"code","bf4acfc9":"code","9511d9b9":"code","2a9ce8c1":"code","f3e4c543":"code","3e5a104f":"code","a39b8ed0":"code","080b8b21":"code","7d2076cc":"code","7de306b5":"code","270cd137":"code","be364f2a":"code","c4578b3a":"code","5739c9a3":"code","fa4fc1bc":"code","f18fb45a":"code","78595275":"code","55734f64":"code","eff51ea5":"code","d40d0836":"code","46216080":"code","2c6c9266":"code","da5c97ef":"code","129fbbb2":"code","e21acf5e":"code","e2e6a875":"code","e8d50896":"code","2ddea13c":"code","d19a2c3e":"code","128f0a6d":"code","66e2bb89":"code","1cf0699a":"code","a22d2abd":"code","d318ede9":"code","3ac4c1be":"code","68db374a":"code","3ab0e898":"code","191c43e6":"code","daae09d2":"code","c45694f6":"code","fe4e93af":"code","c113ca0d":"code","76279d47":"code","b919c263":"code","97819ca0":"code","60b0c9c1":"code","a95a9b51":"code","64e6998f":"code","1f37dec1":"code","bb50b77d":"code","10396a47":"code","06a1e0f6":"code","8c573341":"code","e651c912":"code","8677866f":"code","89d82af6":"code","12e40b8d":"code","5f7b7085":"code","a3514aa6":"code","15c1427c":"code","1594e7f7":"code","0f19a3b0":"code","29a76873":"code","bbbfd553":"code","6baadfcb":"code","e65b60b3":"code","b8c27f79":"code","b0a249af":"code","2af49e45":"code","2c65dc8c":"code","ee62f428":"code","2b9d965c":"code","5dd8045b":"code","705b2a52":"code","ff49a15e":"code","996ef160":"code","9766ca79":"code","7b5013bf":"code","06f338b4":"code","1d0de16e":"code","6c50e954":"markdown","5899328d":"markdown","d5dcbdff":"markdown","2bc42a6f":"markdown","901953cb":"markdown","721d6fa3":"markdown","bee011c5":"markdown","ecd4504a":"markdown","bbac8a74":"markdown","cee43eb1":"markdown","03cd7832":"markdown","911608bb":"markdown","8f93c27a":"markdown","d07abcce":"markdown","bf45d3f3":"markdown","7e2bd475":"markdown","346e9f46":"markdown","cd1db07b":"markdown","13495ad4":"markdown","9d40d516":"markdown","08d1e5c2":"markdown","24c2c719":"markdown","5f6f23bd":"markdown","2c7740f9":"markdown","04dcdab1":"markdown","218841aa":"markdown","0f915864":"markdown","9a2591f1":"markdown","5cc6cc94":"markdown","b230f732":"markdown","5d420335":"markdown","7191ed8f":"markdown","3b4a554a":"markdown","42e9c088":"markdown","5c3bb845":"markdown","2128d3ac":"markdown","ea4ea682":"markdown","d8a33227":"markdown","b425c865":"markdown","51b94e1a":"markdown","16855add":"markdown","322f6fbb":"markdown","c8b6f4d4":"markdown","2a1a917e":"markdown","df87cd45":"markdown","7797d26a":"markdown","0d1cec37":"markdown","854dcd37":"markdown","37775c4d":"markdown","a06d74cf":"markdown"},"source":{"ba8006e7":"# import libraties\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom sklearn.model_selection import train_test_split\n\n# Data display coustomization\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 100)\n\n# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","bc92a8b4":"# Reading movies file\n\nmovies = pd.read_csv('\/kaggle\/input\/movielens-latest-small\/movies.csv', encoding='latin-1')\nmovies.head()","5f7d8fac":"print('Shape:', movies.shape)\nprint('Movie ids:', movies.movieId.nunique())\nprint('Titles:', movies.title.nunique())","ecee6447":"# Reading ratings file\n\nratings = pd.read_csv('\/kaggle\/input\/movielens-latest-small\/ratings.csv', encoding='latin-1')\nratings.head()","3e2d1e77":"print('Shape:', ratings.shape)\nprint('Movie ids:', ratings.movieId.nunique())\nprint('Number of users:', ratings.userId.nunique())","2634943c":"# These are the movies that have been stored with two different ids\n\nmovies.title.value_counts().sort_values(ascending=False).head(5)","0dde36c1":"# getting the ids of a movie\nmovies[movies['title'] == 'Saturn 3 (1980)']","a41f1ec3":"# checking those ids in 'rating' dataframe and count which id is most watched\nratings[(ratings['movieId'] == 2851) | (ratings['movieId'] == 168358)]['movieId'].value_counts()","915f138a":"# deleting the id who is less watched\nmovies = movies[movies['movieId'] != 168358]","95e71b7a":"# getting the ids of a movie\nmovies[movies['title'] == 'Confessions of a Dangerous Mind (2002)']","7ce0c479":"# checking those ids in 'rating' dataframe and count which id is most watched\nratings[(ratings['movieId'] == 6003) | (ratings['movieId'] == 144606)]['movieId'].value_counts()","5dcfa1ca":"# deleting the id who is less watched\nmovies = movies[movies['movieId'] != 144606]","08591d18":"# getting the ids of a movie\nmovies[movies['title'] == 'Emma (1996)']","70efbd59":"# checking those ids in 'rating' dataframe and count which id is most watched\nratings[(ratings['movieId'] == 838) | (ratings['movieId'] == 26958)]['movieId'].value_counts()","2190d919":"# deleting the id who is less watched\nmovies = movies[movies['movieId'] != 26958]","86c4dd15":"# getting the ids of a movie\nmovies[movies['title'] == 'War of the Worlds (2005)']","76ab46f4":"# checking those ids in 'rating' dataframe and count which id is most watched\nratings[(ratings['movieId'] == 34048) | (ratings['movieId'] == 64997)]['movieId'].value_counts()","410d40ff":"# deleting the id who is less watched\nmovies = movies[movies['movieId'] != 64997]","2d597f3f":"# getting the ids of a movie\nmovies[movies['title'] == 'Eros (2004)']","c1b554f8":"# checking those ids in 'rating' dataframe and count which id is most watched\nratings[(ratings['movieId'] == 32600) | (ratings['movieId'] == 147002)]['movieId'].value_counts()","fc885b29":"# deleting the id who is less watched\nmovies = movies[movies['movieId'] != 147002]","c00120ea":"movies_ratings = pd.merge(movies, ratings, on='movieId')\nmovies_ratings.head()","4070000d":"movies_ratings.shape","416f2e72":"# dropping 'timestamp' column\nmovies_ratings = movies_ratings[['userId','movieId', 'title', 'genres', 'rating']]\n\n# sort the dataframe according to 'userId' and then 'movieId'\nmovies_ratings.sort_values(['userId','movieId'], inplace=True)\n\n# resetting the index\nmovies_ratings.reset_index(drop=True, inplace=True)\n\n# top 10 rows\nmovies_ratings.head(10)","07accead":"# number of customer ids\nmovies_ratings.userId.nunique()","d7208693":"# number of movie ids\nmovies_ratings.movieId.nunique()","58377b7a":"# number of movie titles\nmovies_ratings.title.nunique()","c19b499d":"# removing the extra whitespaces(if any) from the column 'title' and 'genres'\nmovies_ratings['title'] = movies_ratings['title'].str.strip()\nmovies_ratings['genres'] = movies_ratings['genres'].str.strip()\n\n# extracting the 'year'\nmovies_ratings['year'] = movies_ratings['title'].str[-5:-1]","4d669853":"movies_ratings.year.unique()","b82e13d7":"movies_ratings['year'] = movies_ratings['year'].replace('irro',2011)\nmovies_ratings['year'] = movies_ratings['year'].replace('atso',2011)\nmovies_ratings['year'] = movies_ratings['year'].replace(' Bab',2017)\nmovies_ratings['year'] = movies_ratings['year'].replace('ron ',2017)\nmovies_ratings['year'] = movies_ratings['year'].replace('r On',2018)\nmovies_ratings['year'] = movies_ratings['year'].replace('lon ',1994)\nmovies_ratings['year'] = movies_ratings['year'].replace('imal',2016)\nmovies_ratings['year'] = movies_ratings['year'].replace('osmo',2019)\nmovies_ratings['year'] = movies_ratings['year'].replace('he O',2016)\nmovies_ratings['year'] = movies_ratings['year'].replace(' Roa',2015)\nmovies_ratings['year'] = movies_ratings['year'].replace('ligh',2016)\nmovies_ratings['year'] = movies_ratings['year'].replace('erso',2016)","bf4acfc9":"# movieIds where genre is missing\n\nmovies_ratings[movies_ratings['genres']=='(no genres listed)'].drop_duplicates('movieId')['movieId'].values","9511d9b9":"movies_ratings.loc[movies_ratings['movieId']==122896,\"genres\"] = 'Adventure|Action|Fantasy'\nmovies_ratings.loc[movies_ratings['movieId']==114335,\"genres\"] = 'Fantasy'\nmovies_ratings.loc[movies_ratings['movieId']==174403,\"genres\"] = 'Documentary|Biography'\nmovies_ratings.loc[movies_ratings['movieId']==172591,\"genres\"] = 'Crime|Drama|Thriller'\nmovies_ratings.loc[movies_ratings['movieId']==176601,\"genres\"] = 'Sci-Fi|Fantasy'\nmovies_ratings.loc[movies_ratings['movieId']==155589,\"genres\"] = 'Comedy'\nmovies_ratings.loc[movies_ratings['movieId']==147250,\"genres\"] = 'Crime|Mystery|Romance'\nmovies_ratings.loc[movies_ratings['movieId']==171749,\"genres\"] = 'Animation|Crime|Drama'\nmovies_ratings.loc[movies_ratings['movieId']==173535,\"genres\"] = 'Crime|Drama|Mystery'\nmovies_ratings.loc[movies_ratings['movieId']==134861,\"genres\"] = 'Comedy'\nmovies_ratings.loc[movies_ratings['movieId']==159161,\"genres\"] = 'Comedy'\nmovies_ratings.loc[movies_ratings['movieId']==171631,\"genres\"] = 'Documentary|Comedy'\nmovies_ratings.loc[movies_ratings['movieId']==171891,\"genres\"] = 'Documentary'\nmovies_ratings.loc[movies_ratings['movieId']==142456,\"genres\"] = 'Comedy|Fantasy'\nmovies_ratings.loc[movies_ratings['movieId']==181413,\"genres\"] = 'Documentary'\nmovies_ratings.loc[movies_ratings['movieId']==159779,\"genres\"] = 'Comedy|Fantasy'\nmovies_ratings.loc[movies_ratings['movieId']==169034,\"genres\"] = 'Musical'\nmovies_ratings.loc[movies_ratings['movieId']==171495,\"genres\"] = 'Sci-Fi'\nmovies_ratings.loc[movies_ratings['movieId']==172497,\"genres\"] = 'Action|Sci-Fi'\nmovies_ratings.loc[movies_ratings['movieId']==166024,\"genres\"] = 'Drama|Music'\nmovies_ratings.loc[movies_ratings['movieId']==167570,\"genres\"] = 'Drama|Fantasy|Mystery'\nmovies_ratings.loc[movies_ratings['movieId']==129250,\"genres\"] = 'Comedy'\nmovies_ratings.loc[movies_ratings['movieId']==143410,\"genres\"] = 'Action|Drama|War'\nmovies_ratings.loc[movies_ratings['movieId']==149330,\"genres\"] = 'Animation|Sci-Fi'\nmovies_ratings.loc[movies_ratings['movieId']==182727,\"genres\"] = 'Musical'\nmovies_ratings.loc[movies_ratings['movieId']==152037,\"genres\"] = 'Romance|Musical'\nmovies_ratings.loc[movies_ratings['movieId']==165489,\"genres\"] = 'Drama|Animation|History'\nmovies_ratings.loc[movies_ratings['movieId']==141866,\"genres\"] = 'Horror|Music|Thriller'\nmovies_ratings.loc[movies_ratings['movieId']==122888,\"genres\"] = 'Action|Adventure|Drama'\nmovies_ratings.loc[movies_ratings['movieId']==156605,\"genres\"] = 'Comedy|Drama|Romance'\nmovies_ratings.loc[movies_ratings['movieId']==141131,\"genres\"] = 'Action|Mystery|Sci-Fi'\nmovies_ratings.loc[movies_ratings['movieId']==181719,\"genres\"] = 'Biography|Drama'\nmovies_ratings.loc[movies_ratings['movieId']==132084,\"genres\"] = 'Drama|Romance'\nmovies_ratings.loc[movies_ratings['movieId']==161008,\"genres\"] = 'Drama|Music|Romance'","2a9ce8c1":"# replacing 'musical' with 'music' as both have same meaning\nmovies_ratings['genres'] = movies_ratings['genres'].str.replace('Musical','Music')","f3e4c543":"# converting string to int\nmovies_ratings['year'] = movies_ratings['year'].astype(int)","3e5a104f":"movies_ratings.info()","a39b8ed0":"movies_ratings.head()","080b8b21":"# store the column in different dataframe\ngenre_df = movies_ratings[['genres']]\n\n# splitting the columns\ngenre_df = genre_df['genres'].str.split('|', expand=True)\n\ngenre_df.head()","7d2076cc":"# changing the name of the columns\ngenre_df.rename(columns={0:'G1',1:'G2',2:'G3',3:'G4',4:'G5',5:'G6',6:'G7',7:'G8',8:'G9',9:'G10'}, inplace=True)","7de306b5":"# create a function that return distinct genres from whole dataframe\n\ndef genre_name(dataframe):\n    df = dataframe.copy()\n    col = df.columns\n    u = set()\n    for i in col:\n        s = set(df[i].value_counts().index)\n        u = u.union(s)\n    return(u)","270cd137":"# names of distinct genres (21 genres)\ng = genre_name(genre_df)\ng","be364f2a":"# making columns of each of the genes with value either 1 or 0 in original dataframe \n\nfor genre in g:\n    movies_ratings[genre] = movies_ratings['genres'].apply(lambda x: 1 if genre in x else 0)","c4578b3a":"movies_ratings.head()","5739c9a3":"plt.figure(figsize=(10,5))\nplt.hist(movies_ratings['rating'],bins=10, color='pink', alpha=0.7)\nplt.xlabel('rating',size=12)\nplt.xlim(0.5,5)\nplt.ylim(0,30000)\nplt.vlines(x=3.5, ymin=0, ymax=30000, color='red', label='Mean rating')\nplt.ylabel('')\nplt.title('count plot of ratings',size=18, color='red')\nplt.legend()\nplt.show()","fa4fc1bc":"genres_count = movies_ratings.iloc[:,6:].sum(axis=0).reset_index().rename(columns={'index':'genre',0:'count'})\ngenres_count.sort_values('count',ascending=False, inplace=True)\n\nplt.figure(figsize=(15,5))\nsns.barplot(x = genres_count['genre'], y=genres_count['count'], color='lightgreen')\nplt.xticks(rotation=45)\nplt.xlabel('Genres', size=12)\nplt.ylabel('')\nplt.title('Count plot of genres', size=18, color='green')\nplt.show()","f18fb45a":"mr = movies_ratings.groupby('title')['title'].count().sort_values(ascending=False).head(15)\n\nplt.figure(figsize=(10,5))\nsns.barplot(y = mr.index, x=mr.values, color='skyblue')\nplt.ylabel('')\nplt.title('15 Most watched Movies', size=18, color='blue')\nplt.show()","78595275":"user = movies_ratings.groupby('userId')['title'].count().sort_values(ascending=False).head(20)\n\nplt.figure(figsize=(15,5))\nuser.plot(kind=\"bar\", color=\"orange\", alpha=0.5)\nplt.title(\"Top 20 users according to watched history\", size=18, color='orange')\nplt.xlabel('User Id', size=12)\nplt.xticks(rotation=0)\nplt.show()","55734f64":"def best_movie(dataframe):\n    \"\"\"\n    This function will return a dataframe in which there are 3 columns. The first column is year.\n    The second column is number of movies released in that year. (according to data we have)\n    Third column is the most watched movie of that year. (in the given data)\n    It only takes one argument which is data.\n    \"\"\"\n    df = dataframe.copy()\n    movieid = df.year.unique()\n    year = list()\n    nMovies= list()\n    mostWatched = list()\n    for i in movieid:\n        year.append(i)\n        nMovies.append(df[df['year']==i]['title'].nunique())\n        mostWatched.append(df[df['year']==i]['title'].value_counts().index[0])\n    \n    df1 = pd.DataFrame({'year':year,'nMoviesReleased':nMovies, 'mostWatchedMovie':mostWatched})\n    df1.sort_values('year', inplace=True)\n    return(df1)","eff51ea5":"# calling the function and reading its top 10 rows\nyearWiseBestMovie = best_movie(movies_ratings)\nyearWiseBestMovie.head(10)","d40d0836":"train, test = train_test_split(ratings, test_size=0.30, random_state=31)","46216080":"print(train.shape)\nprint(test.shape)","2c6c9266":"dummy_train = train.copy()\ndummy_train['rating'] = dummy_train['rating'].apply(lambda x: 0 if x>=1 else 1)\n\ndummy_test = test.copy()\ndummy_test['rating'] = dummy_test['rating'].apply(lambda x: 1 if x>=1 else 0)","da5c97ef":"# The movies not rated by user is marked as 1 for prediction. \ndummy_train = dummy_train.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating'\n).fillna(1)\n\n# The movies not rated by user is marked as 0 for evaluation. \ndummy_test = dummy_test.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating'\n).fillna(0)","129fbbb2":"# 1 means not watched by user and 0 means watched by user\ndummy_train.head()","e21acf5e":"dummy_train.shape","e2e6a875":"# 0 means not watched by user and 1 means watched by user\ndummy_test.head()","e8d50896":"dummy_test.shape","2ddea13c":"# pivot ratings into movie features\ndf_movie_features = train.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating'\n).fillna(0)","d19a2c3e":"df_movie_features.head()","128f0a6d":"df_movie_features.shape","66e2bb89":"from sklearn.metrics.pairwise import pairwise_distances\n\n# User Similarity Matrix using 'cosine' measure\n\nuser_correlation = 1 - pairwise_distances(df_movie_features, metric='cosine')\nuser_correlation[np.isnan(user_correlation)] = 0\nprint(user_correlation)","1cf0699a":"user_correlation.shape","a22d2abd":"movie_features = train.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating')","d318ede9":"movie_features.head()","3ac4c1be":"movie_features.shape","68db374a":"mean = np.nanmean(movie_features, axis=1) # nanmean calculate the mean excluding NaN values\nprint(mean.shape)","3ab0e898":"# finally subtracting each user mean rating from its own values\n\ndf_subtracted = (movie_features.T - mean).T\ndf_subtracted.head()","191c43e6":"df_subtracted.shape","daae09d2":"from sklearn.metrics.pairwise import pairwise_distances\n\n# User Similarity Matrix\nuser_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')\nuser_correlation[np.isnan(user_correlation)] = 0\nprint(user_correlation)","c45694f6":"user_correlation.shape","fe4e93af":"user_correlation[user_correlation<0]=0\nuser_correlation","c113ca0d":"# These are the scores of all the movies by all users \n\nuser_predicted_ratings = np.dot(user_correlation, movie_features.fillna(0)) # 610x610 . 610x8536 = 610x8536\nuser_predicted_ratings","76279d47":"user_predicted_ratings.shape","b919c263":"user_final_rating = np.multiply(user_predicted_ratings, dummy_train)   # 610x8536 x 610x8536 = 610x8536\nuser_final_rating.head()","97819ca0":"def top_10_movies_for_user(i):\n    user_i = user_final_rating.iloc[i].to_frame()\n    user_i.reset_index(inplace=True)\n    user_i.rename(columns= {'movieId':'movieId', i+1:'ratings'}, inplace=True)\n    user_join_i = pd.merge(user_i, movies, on='movieId')\n    return user_join_i.sort_values(by=[\"ratings\"], ascending=False)[0:10]","60b0c9c1":"top_10_movies_for_user(540)","a95a9b51":"test_movie_features = test.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating')\n\ntest_movie_features.head()","64e6998f":"mean = np.nanmean(test_movie_features, axis=1)\ntest_df_subtracted = (test_movie_features.T-mean).T","1f37dec1":"# User Similarity Matrix\ntest_user_correlation = 1 - pairwise_distances(test_df_subtracted.fillna(0), metric='cosine')\ntest_user_correlation[np.isnan(test_user_correlation)] = 0\nprint(test_user_correlation)","bb50b77d":"test_user_correlation.shape","10396a47":"test_user_correlation[test_user_correlation<0]=0\ntest_user_predicted_ratings = np.dot(test_user_correlation, test_movie_features.fillna(0))\ntest_user_predicted_ratings","06a1e0f6":"test_user_predicted_ratings.shape","8c573341":"test_user_final_rating = np.multiply(test_user_predicted_ratings, dummy_test)","e651c912":"test_user_final_rating.head()","8677866f":"from sklearn.preprocessing import MinMaxScaler\nfrom numpy import *\n\nX  = test_user_final_rating.copy() \nX = X[X>0]\n\nscaler = MinMaxScaler(feature_range=(1, 5))\nprint(scaler.fit(X))\ny = (scaler.transform(X))\n\nprint(y)","89d82af6":"test_ = test.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating')","12e40b8d":"# Finding total non-NaN value\ntotal_non_nan = np.count_nonzero(~np.isnan(y))","5f7b7085":"rmse = (sum(sum((test_ - y )**2))\/total_non_nan)**0.5\nprint(rmse)","a3514aa6":"movie_features = train.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating'\n).T\n\nmovie_features.head()","15c1427c":"mean = np.nanmean(movie_features, axis=1) # nanmean calculate the mean excluding NaN values\nprint(mean.shape)","1594e7f7":"# finally subtracting each user mean rating from its own values\n\ndf_subtracted = (movie_features.T-mean).T\ndf_subtracted.head()","0f19a3b0":"df_subtracted.shape","29a76873":"from sklearn.metrics.pairwise import pairwise_distances\n\n# User Similarity Matrix\nitem_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')\nitem_correlation[np.isnan(item_correlation)] = 0\nprint(item_correlation)","bbbfd553":"item_correlation.shape","6baadfcb":"item_correlation[item_correlation<0]=0\nitem_correlation","e65b60b3":"item_predicted_ratings = np.dot((movie_features.fillna(0).T), item_correlation)\nitem_predicted_ratings","b8c27f79":"item_predicted_ratings.shape","b0a249af":"dummy_train.shape","2af49e45":"item_final_rating = np.multiply(item_predicted_ratings, dummy_train)\nitem_final_rating.head()","2c65dc8c":"def top_10_movies_for_user(i):\n    user_i = item_final_rating.iloc[i].to_frame()\n    user_i.reset_index(inplace=True)\n    user_i.rename(columns= {'movieId':'movieId', i+1:'ratings'},inplace=True)\n    user_join_i = pd.merge(user_i,movies,on='movieId')\n    return user_join_i.sort_values(by=[\"ratings\"],ascending=False)[0:10]","ee62f428":"top_10_movies_for_user(540)","2b9d965c":"test_movie_features = test.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating'\n).T","5dd8045b":"mean = np.nanmean(test_movie_features, axis=1)\ntest_df_subtracted = (test_movie_features.T-mean).T","705b2a52":"test_item_correlation = 1 - pairwise_distances(test_df_subtracted.fillna(0), metric='cosine')\ntest_item_correlation[np.isnan(test_item_correlation)] = 0\ntest_item_correlation[test_item_correlation<0]=0","ff49a15e":"test_item_correlation.shape","996ef160":"test_movie_features.shape","9766ca79":"test_item_predicted_ratings = (np.dot(test_item_correlation, test_movie_features.fillna(0))).T\ntest_item_final_rating = np.multiply(test_item_predicted_ratings,dummy_test)\ntest_item_final_rating.head()","7b5013bf":"test_ = test.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating')","06f338b4":"from sklearn.preprocessing import MinMaxScaler\nfrom numpy import *\n\nX  = test_item_final_rating.copy() \nX = X[X>0]\n\nscaler = MinMaxScaler(feature_range=(1, 5))\nprint(scaler.fit(X))\ny = (scaler.transform(X))\n\ntest_ = test.pivot(\n    index='userId',\n    columns='movieId',\n    values='rating')\n\n# Finding total non-NaN value\ntotal_non_nan = np.count_nonzero(~np.isnan(y))","1d0de16e":"rmse = (sum(sum((test_ - y )**2))\/total_non_nan)**0.5\nprint(rmse)","6c50e954":"---\n## <font color = 'orange'>Topics Covered in this notebook<\/font>\n1. User based recommendation\n    - Model development\n    - User based prediction\n    - Evaluation\n2. Item based recommendation\n    - Model development\n    - Item based prediction\n    - Evaluation","5899328d":"#### <font color = 'brown'>Replacing the missing genres of the movies","d5dcbdff":"#### <font color = 'brown'>Replacing strings with year","2bc42a6f":"---\n### Top 10 recommended movies to users<\/font>\nCreated a function in which you just need to give the user_id and it will return you the top 10 recommended movies for that user.","901953cb":"#### <font color = 'blue'>Using Adjusted Cosine<\/font>\n>Here, not removing the NaN values and calculating the mean only for the movies rated by the user","721d6fa3":"#### Normalising the movie rating for each movie\nWe are calculating the mean rating of each movie excluding the NaN value. So consider movie 1 who has beem watched by 215 users out of 610 users. So we are calculating sum of rating given by each user to this movie-1 divided by count of users i.e. 610. Similarly for all the movies we calculate the mean rating.","bee011c5":"`np.dot` is the dot product of two matrices.\n\n    |A B| . |E F|  =  |A*E+B*G  A*F+B*H|\n    |C D|   |G H|     |C*E+D*G  C*F+D*H|","ecd4504a":"#### <font color = 'brown'>Working on 'genres' column<\/font>\n1. Put that column in another dataframe and split the column on '|'\n2. Then we find the unique genres throughout the dataframe and store it as a set\n3. Finally making column of each of the genre in our main dataframe(movies_rating) and the values of each column is 1 or 0. 1 if that movie has that genre, 0 if not.","bbac8a74":"#### Normalising the rating of the movie for each user aroung 0 mean\nWe are calculating the mean rating by each user excluding the NaN value. So consider user 1 who has watched 232 movies out of 8536. So we are calculating sum of rating given by user to those 232 movies divided by count of movies i.e. 232. Similarly for all the user we calculate the mean rating.","cee43eb1":"## <font color = 'blue'>A. Model Development","03cd7832":"#### Finding cosine similarity","911608bb":"---\n# <font color = 'orange'>II. Item Based Recommendation","8f93c27a":"---\n# <font color = 'blue'>Graphs","d07abcce":"Doing the prediction for the users which are positively related with other users, and not the users which are negatively related as we are interested in the users which are more similar to the current users. So, ignoring the correlation for values less than 0. ","bf45d3f3":"### <font color = 'blue'>Copy train and test dataset<\/font>\nThese dataset will be used for prediction and evaluation. \n- Dummy train will be used later for prediction of the movies which has not been rated by the user. To ignore the movies rated by the user, we will mark it as 0 during prediction. The movies not rated by user is marked as 1 for prediction. \n- Dummy test will be used for evaluation. To evaluate, we will only make prediction on the movies rated by the user. So, this is marked as 1. This is just opposite of dummy_train","7e2bd475":"#### <font color = 'brown'>Merging 'movies' and 'rating' dataframe into one","346e9f46":"Evaluation will be same as you have seen above for the prediction. The only difference being, you will evaluate for the movie already rated by the user instead of predicting it for the movie not rated by the user. ","cd1db07b":"***Thank-you***","13495ad4":"#### <font color = 'red'>How to read the above output<\/font>\nwhat will happen in **pairwise_distances** is that it will do pairwise multiplication of elements between each user(or row of the *df_movie_features*) and divided by square root of summing of squaring of each value of both the rows. <br>\nHere we see how much a user is similar or dissimilar to all the other users.<br>\nex - \n\n                    userId1 . userId2(this is the dot product)\n                    -------------------------------------------\n                        sqrt(userId1^2) x sqrt(userId2^2)\n\n- The given output was 610x610 metrics (because there are 610 users) in which diagonal is 1 and the values above the diagonal and below the diagonal are same and represents the distance.\n- The first row of the metrics is of **user 1** and show the pairwise distance with all the other users. Similarly second row is of **user 2** and show the pairwise distance with all the other users and so on.","9d40d516":"Filtering the correlation only for which the value is greater than 0. (Positively correlated)","08d1e5c2":"`np.multiply` does an element-wise multiplication of two matrices\n\n        |A B|  \u2299 |E F| =  |A*E  B*F|\n        |C D|     |G H|    |C*G  D*H|","24c2c719":"![image.png](attachment:image.png)","5f6f23bd":"## <font color = 'blue'>C. Evaluation<\/font>\nEvaluation will be same as you have seen above for the prediction. The only difference being, you will evaluate for the movie already rated by the user instead of predicting it for the movie not rated by the user. ","2c7740f9":"#### Calculating the RMSE for only the movies rated by user. For  RMSE, normalising the rating to (1,5) range. ","04dcdab1":"## <font color = 'blue'>B. Prediction","218841aa":"#### <font color = 'blue'>Using Cosine Similarity<\/font>\n>Here, replacing the NaN values with 0","0f915864":"Since we are interested only in the movies not rated by the user, we will ignore the movies rated by the user by making it zero. ","9a2591f1":"---\n# <font color = 'orange'>I. User Based Recommendation","5cc6cc94":"## <font color = 'blue'>C. Evaluation","b230f732":"#### Finding the cosine similarity\nNote that since the data is normalised, both the cosine metric and correlation metric will give the same value. ","5d420335":"#### <font color = 'brown'>Finally the data is ready","7191ed8f":"## <font color = 'orange'>What is Recommendation System?<\/font>\n- **Recommender systems are the systems that are designed to recommend things to the user** based on many different factors. These systems predict the most likely product that the users are most likely to purchase and are of interest to. Companies like Netflix, Amazon, etc. use recommender systems to help their users to identify the correct product or movies for them. \n- Companies using recommender systems focus on increasing sales as a result of very personalized offers and an enhanced customer experience. Recommendations typically speed up searches and make it easier for users to access content they\u2019re interested in, and surprise them with offers they would have never searched for.","3b4a554a":"### <font color = 'orange'>Other type of Recommendation System<\/font>\n1. `Content-based recommendation system` : **Content** here refers to the content or attribute of the products you like. So the idea in this system is to tag the products with certain keywords, understand what the user like, look up to those keywords in database and recommend the products with same attribute. Also some features are more important then others. This suggest that the system should assign weights to the features. \n2. `Hybrid recommendation system` : Combining any of the two systems in a manner that suits a particular industry is known as Hybrid Recommender system. This is the most sought after Recommender system that many companies look after, as it combines the strengths of more than two Recommender system and also eliminates any weakness which exist when only one recommender system is used.","42e9c088":"## <font color = 'orange'>Collaborative Recommendation System<\/font>\n`Collaborative filtering based recommendation system` : The simple idea behind this system is that similar user tend to like similar items. It is based on the assumption that if some users have had similar interest in the past, they will have similar interest in the future. **This algorithm makes predictions about the interests of a user (filtering) by collecting preferences from many users (collaborating)**. The main advantage of this system is that you do not need to know the content in the detail. \n   1. `User based`: To summarise the algorithm of user-based filters:\n        1. Find users similar to the user 'x' (called the peer users) for whom predictions are to be made using any similarity measure like the correlation coefficient.\n        2. For each movie 'm' that the user has not seen, calculate the weighted average of the ratings given to 'm' by the peer users.\n        3. Recommend the top 'n' movies to the user 'x'.\n   2. `Item based` : To reiterate the item-based filtering procedure, the following steps are followed in sequence to predict the rating a user 'x' will give to a movie 'm':\n        1. Find items similar to the movie 'm' (often called peer group of items) using a similarity measure like cosine. \n        2. Calculate the rating that the user will give to the movie 'm' using the weighted average of the ratings given to the nearest movies by the user.\n        3. Recommend the top-n movies to the user.\n","5c3bb845":"#### <font color = 'brown'>Fixing the mismatch between 'movieId' and 'titles'","2128d3ac":"## <font color = 'blue'>A. Model Development","ea4ea682":"#### <font color = 'red'>How to read the above output<\/font>\nwhat will happen in **pairwise_distances** is that it will do pairwise multiplication of elements between each movie(or row of the *movie_features*) and divided by square root of summing of squaring of each value of both the rows. <br>\nHere we see how much a movie is similar or dissimilar to all the other movies.<br>\nex - \n\n                    movieId1 . movieId2(this is the dot product)\n                    -------------------------------------------\n                        sqrt(movieId1^2) x sqrt(movieId2^2)\n\n- The given output was 8536x8536 metrics (because there are 8536 movies) in which diagonal is 1 and the values above the diagonal and below the diagonal are same and represents the distance.\n- The first row of the metrics is of **movie 1** and show the pairwise distance with all the other movies. Similarly second row is of **movie 2** and show the pairwise distance with all the other movies and so on.","d8a33227":"Using Correlation","b425c865":"#### Filtering the rating only for the movies not rated by the user for recommendation","51b94e1a":"Rating predicted by the user (for movies rated as well as not rated) is the weighted sum of correlation with the movie rating (as present in the rating dataset). ","16855add":"---\n### Top 10 recommended movies to users<\/font>\nCreated a function in which you just need to give the user_id and it will return you the top 10 recommended movies for that user.","322f6fbb":"## <font color = 'blue'>B. Prediction","c8b6f4d4":"#### <font color = 'red'>What we have done above ?<\/font>\n- In *dummy_train*, what we had done previously is that we make all those movie ratings to 0 which the user already watched (or for which user provide rating already).\n- Now by multiplying *user_predicted_ratings* with *dummy_train*, what we do is we multiply each user ratings in user_predicted_ratings with that of its dummy_train ratings and hence those values becomes 0 which is already watched or rating is given by the user. \n- For which the rating is not given by user in dummy_train has set to 1 previously and hence when multiplied by user_predicted_ratings gives some value. ","2a1a917e":"### <font color = 'blue'>Dividing the dataset into train and test","df87cd45":"Taking the transpose of the rating matrix to normalize the rating around the mean for different movie ID. In the user based similarity, we had taken mean for each user intead of each movie. ","7797d26a":"- It is observed that in the last 4 rows, at some places there are string.\n- Looking at the data on those string, it has been found that those movies year are not mentioned. Also some of the movies genre is also not available.\n- Below I fill those missing year and genres of the movies\/shows by searching online.","0d1cec37":"#### Doing prediction for the movies rated by the user","854dcd37":"It is been oberved that there is a `mismatch between unique movieids and unique title`.<br>\nThere are 5 more ids than the movies i.e. **there is 5 such movies who has stored in this table with two different ids**.","37775c4d":"#### Further Readings\n- An introduction to recommendation engines [here](http:\/\/dataconomy.com\/2015\/03\/an-introduction-to-recommendation-engines\/)\n- Types of recommendation system [here](https:\/\/www.bluepiit.com\/blog\/classifying-recommender-systems\/)\n- How Netflix implements its recommendation engine in their two-part blog [here](https:\/\/netflixtechblog.com\/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)\n- What's difference between item-based and content-based collaborative filtering? [here](https:\/\/stackoverflow.com\/questions\/16372191\/whats-difference-between-item-based-and-content-based-collaborative-filtering)","a06d74cf":"#### Finding RMSE"}}