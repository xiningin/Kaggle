{"cell_type":{"41c77cd0":"code","bd8070d1":"code","6d36dd09":"code","9f8eb018":"code","1497c03c":"code","6e4433d8":"code","d213ec7e":"code","b451a833":"code","0744be8f":"code","8374e9c3":"code","3c0444a3":"code","5917dd2c":"code","1359fc01":"code","10ab8566":"code","94247ef3":"code","c2d978cd":"code","86ae254d":"code","2966381a":"code","f8edf69b":"markdown","e028a9b2":"markdown","51767e8e":"markdown","f4b274cb":"markdown","bf9edd1b":"markdown"},"source":{"41c77cd0":"import torch\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision.transforms as tt\nimport torch.nn as nn\nimport matplotlib.animation as animation\n\nfrom torchvision.datasets import ImageFolder\nfrom datetime import datetime\nfrom torchvision.transforms import ToTensor, Normalize\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data.dataloader import DataLoader\nfrom torchvision.utils import make_grid, save_image","bd8070d1":"data_path = \"..\/input\/manga-faces-dataset\/Manga-Faces-dataset\/\"\nclasses = os.listdir(data_path)\ntotal = 0\n\nfor clas in classes:\n    names = os.listdir(data_path+clas)\n    total += len(names)\n\nlen(classes), total","6d36dd09":"train_ds = ImageFolder(data_path, tt.Compose([tt.Resize((128, 128)), tt.ToTensor() ]))\n\nprint(len(train_ds))\n\ndata_helper = DataLoader(train_ds, batch_size=len(train_ds))\n\ndef mean_std(loader):\n    images, labels = next(iter(loader))\n    # shape of images = [b,c,w,h]\n    print(images.shape)\n    # print(torch.sum(torch.tensor(images))\/len(images))\n    mean, std = images.mean([0,2,3]), images.std([0,2,3])\n    return mean, std\n\nstats = mean_std(data_helper)\nstats","9f8eb018":"# Data transforms (normalization & data augmentation)\n# stats = ((0.7622, 0.7620, 0.7622), (0.3057, 0.3058, 0.3057))\n# stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )\nstats = ((0.5), (0.5))\n# degrees = (-90,90)\n# Means\nb_dim = 72 # 150\ndim = 64   # 128\ntrain_tfms = tt.Compose([tt.Resize((b_dim, b_dim)),\n                         tt.RandomCrop(dim),\n                         tt.RandomHorizontalFlip(), \n                         tt.Grayscale(num_output_channels=1), # Usar solo un canal pues son imagenes blanco y negro lol no ocupas mas\n                         # tt.RandomVerticalFlip(), \n                         # tt.RandomRotation(degrees),\n                         # tt.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n                         # tt.ColorJitter(brightness=0.5, hue=0.1),\n                         tt.ToTensor(), \n                         tt.Normalize(*stats,inplace=True)\n])\n\n# PyTorch datasets\n\ntrain_ds = ImageFolder(data_path, train_tfms)\nbatch_size = 5\ntrain_dl = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True, drop_last=True ,num_workers=0)\nbatch_size, len(train_dl), len(train_ds)","1497c03c":"%%time\n\ndef denormalize(images, means, stds):\n    means = torch.tensor(means).reshape(1, 1, 1, 1)\n    stds = torch.tensor(stds).reshape(1, 1, 1, 1)\n    return images * stds + means\n\ndef show_batch(dl):\n    for images, labels in dl:\n        print(torch.max(images), torch.min(images))\n        print(images[0].shape)\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        denorm_images = denormalize(images, *stats)\n        # denorm_images = images\n        row = 5\n        ax.imshow(make_grid(denorm_images, nrow=row).permute(1, 2, 0)) #.clamp(0,1))\n        print(make_grid(denorm_images, nrow=row).permute(1, 2, 0).shape)\n        break\n\nshow_batch(train_dl)","6e4433d8":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n\ndevice = get_default_device()\ntrain_dl = DeviceDataLoader(train_dl, device)\n\ndevice","d213ec7e":"n = nn.ConvTranspose2d(8,16,kernel_size=4, stride=1, padding=0,bias=False)\nm = nn.ConvTranspose2d(16,17,kernel_size=6, stride=2, padding=2,bias=False)\nh = nn.ConvTranspose2d(17,17,kernel_size=5, stride=2, padding=2,bias=False)\no = nn.ConvTranspose2d(17,17,kernel_size=5, stride=1, padding=0, bias=False)\nb = nn.BatchNorm2d(16)\n\nx = torch.rand([3,8,1,1])\nprint(x.shape)\nx = n(x)\nprint(x.shape)\nx = m(x)\nprint(x.shape)\nx = h(x)\nprint(x.shape)\nx = o(x)\nprint(x.shape)","b451a833":"class Generator(nn.Module):\n\n    def __init__(self, conv_size, input_G, device, channels=1):\n        super(Generator, self).__init__()\n        self.device = device\n        self.conv_size = conv_size\n        self.dim = input_G\n        self.channels = channels\n        conv = []\n        doble, same, ini = (4,2,1), (3,1,1), (4,1,0) # 1,1 to 4,4\n        conv.extend(self.ConvLayer(self.dim, conv_size[0], values=ini) )\n        for i in range(len(conv_size)-1):\n            conv.extend(self.ConvLayer( conv_size[i], conv_size[i+1], values=doble) )\n        conv.extend(self.ConvLayer( conv_size[-1], channels, values=same, output=True, batch=False) )\n        self.generator_conv   = nn.Sequential(*conv)\n        self.conv = conv\n        \n    def forward(self, x):\n        x = x.reshape(-1,self.dim,1,1)\n        x = self.generator_conv(x)\n        return x\n\n    def ConvLayer(self, in_size, out_size, values=(3,1,1), output=False, pool=False, batch=True):\n        kernel, stride, padding = values\n        layers = [ nn.ConvTranspose2d(in_size, out_size, kernel, stride=stride, padding=padding, bias=False, device=self.device) ]\n        if pool:\n            layers.append( nn.MaxUnpool2d(2, 2) )\n        if batch and not output:\n            layers.append( nn.BatchNorm2d(out_size) )\n        if output:  layers.append( nn.Tanh() )\n        else:       layers.append( nn.ReLU(inplace=True) )\n        return layers\n    ","0744be8f":"class Discriminator(nn.Module):\n\n    def __init__(self, conv_size, device, relu_lr=0.2, dim=128, channels=1):\n        super(Discriminator, self).__init__()\n        self.device = device\n        self.conv_size = conv_size\n        self.channels = channels\n        self.dim = dim\n        conv = []\n        doble, same, fin = (4,2,1), (3,1,1), (4,1,0)\n        conv.extend(self.ConvLayer(channels, conv_size[0], same) )\n        for i in range(len(conv_size)-1):\n            conv.extend(self.ConvLayer( conv_size[i], conv_size[i+1], values=doble) )\n        conv.extend(self.ConvLayer( conv_size[-1], 1, values=fin, output=True, batch=False) )\n        self.discriminator_conv = nn.Sequential(*conv)\n\n    def forward(self, x):\n        x = self.discriminator_conv(x)\n        return x.reshape(-1,1)\n\n    def ConvLayer(self, in_size, out_size, values=(3,1,1), pool=False, output=False, batch=False):\n        kernel, stride, padding = values\n        layers = [  nn.Conv2d(in_size, out_size, kernel_size=kernel, stride=stride, padding=padding, bias=True, device=self.device) ]\n        if batch and not output:\n            layers.append( nn.BatchNorm2d(out_size) )\n        if pool:\n            layers.append( nn.MaxPool2d(2, 2) )\n        if output:  layers.append( nn.Sigmoid() )\n        else:     layers.append( nn.LeakyReLU(negative_slope=relu_lr, inplace=True) )\n        return layers","8374e9c3":"class GAN():\n\n    def __init__(self, G, D, lr, train_dl, G_input_size, batch_size, device, rows, pxls, dim, channels, betas=[0.5, 0.999]):\n        self.dim = dim\n        self.pxls = pxls\n        self.channels = channels\n        self.device = device\n        self.rows = rows\n        self.batch_size = batch_size\n        self.samples_size = 25\n        self.train_dl = train_dl\n        self.train_dl_size = len(train_dl)\n        self.batch_show = 10\n        self.real_it = 0\n        self.G = G\n        self.D = D\n        self.G_input_size = G_input_size\n        self.lr = lr\n        self.D_optimizer = torch.optim.Adam(D.parameters(), lr = lr, betas=betas) \n        self.G_optimizer = torch.optim.Adam(G.parameters(), lr = lr, betas=betas)\n        self.G_loss = nn.BCELoss()\n        self.D_loss = nn.BCELoss()\n        self.samples = self.get_noise(samples=True)\n        self.G_loss_it, self.D_loss_it = [], []\n        self.real_pred_it, self.fake_pred_it = [], []\n\n    def grad_reset(self):\n        self.D_optimizer.zero_grad(set_to_none=True)\n        self.G_optimizer.zero_grad(set_to_none=True)\n\n    def G_train(self):\n        # Genera vectores random\n        noise = self.get_noise()\n        # Genera imagenes \n        out = self.G(noise)\n        # Label 0 para imagenes falsas\n        # Pero usamos 1 para confundir a la red\n        labels = torch.ones(batch_size, 1, device=self.device)\n        # Calcular loss\n        pred_labels = self.D(out)\n        loss = self.G_loss(pred_labels, labels)\n        # Reset gradientes\n        self.grad_reset()\n        # Calcular gradientes\n        loss.backward()\n        # Optimizar\n        self.G_optimizer.step()\n        return loss, out\n\n    def D_train(self, images):\n        # Genera vectores random\n        noise = self.get_noise()\n        # Label 1 para imagenes reales\n        real_labels = torch.ones(batch_size, 1, device=self.device)\n        # Label 0 para imagenes falsas\n        fake_labels = torch.zeros(batch_size, 1, device=self.device)\n\n        # Genera imagenes \n        out = self.G(noise)\n\n        # Prediccion imagenes reales\n        real_pred = self.D(images)\n        # Prediccion imagenes fake\n        fake_pred = self.D(out)\n\n        # Calcular loss\n        real_loss = self.D_loss(real_pred, real_labels)\n        fake_loss = self.D_loss(fake_pred, fake_labels)\n\n        # Sumar loss fn\n        loss = real_loss + fake_loss\n        # Reset gradientes\n        self.grad_reset()\n        # Calcular gradientes\n        loss.backward()\n        # Optimizar\n        self.D_optimizer.step()\n        return loss, real_pred, fake_pred\n        \n    def fit(self, its, folder=\"samples\", saveLoss=False):\n        torch.cuda.empty_cache()\n        begin_time = datetime.now()\n        for it in range(its):\n            batch_len = len(train_dl)\n            for i, (images, labels) in enumerate(self.train_dl):\n                \n                self.G.train()\n                self.D.train()\n\n                images = images.reshape(batch_size, self.channels, self.dim, self.dim)\n                \n                loss_d, real_pred, fake_pred = self.D_train(images)\n                loss_g, _ = self.G_train()\n                \n                if (i+1) % self.batch_show == 0:\n                    self.D_loss_it.append(loss_d.item())\n                    self.G_loss_it.append(loss_g.item())\n                    self.real_pred_it.append(real_pred.mean().item())\n                    self.fake_pred_it.append(fake_pred.mean().item())\n                    act_time = datetime.now()\n                    print('Epoch[{}\/{}]  Batch[{}\/{}]  D_loss:{:.5f}  G_loss:{:.5f}  D(x)_mean:{:.5f}  D(G(p))_mean:{:.5f}  Time:{}'.format(\n                        it+1, its, i+1, batch_len, loss_d.item(), loss_g.item(),\n                        real_pred.mean().item(), fake_pred.mean().item(), act_time - begin_time\n                    ))\n            \n            self.real_it+=1\n            if saveLoss: self.plot_loss(save=True, file_name='loss_log_{0:0=4d}'.format(self.real_it))\n            self.save_image('sample_{0:0=4d}'.format(self.real_it), folder=folder)\n            self.save_models()\n\n        return\n            \n    def random_generator(self):\n        random_vector = self.get_noise()\n        out = self.G(random_vector)\n        plt.imshow( out[0].detach().reshape(self.dim,self.dim,-1) )\n        return out[0], self.D(out)[0]\n\n    def show_samples(self, batch = False, show = True):\n        out = self.G(self.samples).detach().reshape(-1,self.channels,self.dim,self.dim) \n        if batch == True: out = self.take_random_batch()\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        grid = self.to_grid(out)\n        if show: ax.imshow(grid) \n        return fig, ax, out\n        \n    def save_models(self, folder='models'):\n        model_path = folder\n        if not os.path.exists(model_path):\n            os.makedirs(model_path)\n        torch.save({\n            'G_state_dict': self.G.state_dict(),\n            'D_state_dict': self.D.state_dict(),\n            'D_optimizer_state_dict': self.D_optimizer.state_dict(),\n            'G_optimizer_state_dict': self.G_optimizer.state_dict()\n            }, os.path.join(folder, 'model.pth'))\n        torch.save(self.G.state_dict(), model_path+'\/G.ckpt')\n        torch.save(self.D.state_dict(), model_path+'\/D.ckpt')\n\n    def save_image(self, file_name, folder=\"samples\", batch =False):\n        samples_path = folder\n        if not os.path.exists(samples_path):\n            os.makedirs(samples_path)\n        image = self.G(self.samples).detach().reshape(-1, self.channels, self.dim, self.dim)\n        if batch == True: image = self.take_random_batch()\n        save_image(image, os.path.join(samples_path, f'{file_name}.png'), nrow=self.rows)\n\n    def take_random_batch(self):\n        for images, labels in self.train_dl:\n            return images\n        return None\n\n    def to_grid(self, images):\n        return make_grid(images, nrow=self.rows).permute(1,2,0)\n\n    def get_noise(self, samples=False):\n        return torch.tensor(np.random.uniform( -1., 1., #self.pxls[0],self.pxls[1],\n            [ self.batch_size if not samples else self.samples_size, \n                self.G_input_size]), dtype=torch.float32, device=device)\n\n    def normalize(self, x):\n        return (x + 1) \/ 2\n\n    def plot_loss(self, save=False, file_name='loss-log', folder=\"loss\"):\n        plt.plot(self.D_loss_it, '-')\n        plt.plot(self.G_loss_it, '-')\n        plt.legend(['Discriminator', 'Generator'])\n        plt.xlabel('Iteraciones')\n        plt.ylabel('Loss')\n        plt.title('Loss')\n        if save:\n            if not os.path.exists(folder):\n                os.makedirs(folder)\n            plt.savefig(os.path.join(folder, f'{file_name}.png'))\n        else:\n            plt.show()\n        plt.close()\n    \n    def plot_score(self):\n        plt.plot(self.real_pred_it, '-')\n        plt.plot(self.fake_pred_it, '-')\n        plt.xlabel('Iteraciones')\n        plt.ylabel('Score')\n        plt.legend(['Real', 'Fake'])\n        plt.title('Scores')        \n        plt.close()","3c0444a3":"conv_size_G   = (256, 128, 64, 32, 16) # 4,8,16,32,64 -> 64\nconv_size_D   = (16, 32, 64, 128, 256) # 64,32,16,8,4\ninput_G = 256\nrelu_lr = 0.2\nchannels = 1\ndim = 64\n\nG = Generator(conv_size_G, input_G, device, channels=channels)\nD = Discriminator(conv_size_D, device, relu_lr=relu_lr, dim=dim, channels=channels)\n\nG.to(G.device)\nD.to(D.device)\n\nlr = 0.0002\nbetas = [0.5, 0.999]\n\npxls = (-1., 1.)\ngan = GAN(G, D, lr, train_dl, input_G, batch_size, device=device, rows=5, pxls=pxls, dim=dim,  channels=channels, betas=betas)\n\nout = gan.show_samples()\nout = gan.show_samples(batch=True)\n\n# gan.save_image('test')\n# gan.save_image('batch', batch=True)\n# gan.save_models()","5917dd2c":"%%time\ngan.fit(300, folder=\"samples\", saveLoss=True)","1359fc01":"gan.plot_loss()","10ab8566":"checkpoint = torch.load('..\/input\/manga-faces-model\/model.pth',map_location=torch.device('cpu'))\ngan.G.load_state_dict(checkpoint['G_state_dict'])\ngan.D.load_state_dict(checkpoint['D_state_dict'])\ngan.D_optimizer.load_state_dict(checkpoint['D_optimizer_state_dict'])\ngan.G_optimizer.load_state_dict(checkpoint['G_optimizer_state_dict'])","94247ef3":"out = gan.show_samples()\nout = gan.show_samples(batch=True)","c2d978cd":"imgs = []\npath = 'samples-2\/'\nlis = os.listdir(path)\n\nfig, ax = plt.subplots()\n\nax.set_xticks([]), ax.set_yticks([])\n\nfor i, x in enumerate(lis):\n    imgs.append([ax.imshow(plt.imread(path+x, format=\"png\"), animated=True)])\n    if i == 0: ax.imshow(plt.imread(path+x, format=\"png\"))\n\nani = animation.ArtistAnimation(fig, imgs, interval=50, blit=True, repeat_delay=1000)\n\nani.save(\"sample-2-video.mp4\")","86ae254d":"x = torch.tensor(np.random.uniform( -1., 1., #self.pxls[0],self.pxls[1],\n            [ gan.samples_size, \n                gan.G_input_size]), dtype=torch.float32, device=device)\nout = gan.G(x).detach().reshape(-1,gan.channels,gan.dim,gan.dim) \nfig, ax = plt.subplots(figsize=(12, 12))\nax.set_xticks([]); ax.set_yticks([])\ngrid = gan.to_grid(out)\nax.imshow(grid) \nplt.show()","2966381a":"conv_size_G   = (256, 128, 64, 32, 16) # 4,8,16,32,64 -> 64\nconv_size_D   = (16, 32, 64, 128, 256) # 64,32,16,8,4\ninput_G = 256\nrelu_lr = 0.2\nchannels = 1\ndim = 64\n\nG2 = Generator(conv_size_G, input_G, device, channels=channels)\nD2 = Discriminator(conv_size_D, device, relu_lr=relu_lr, dim=dim, channels=channels)\n\nG.to(G.device)\nD.to(D.device)\n\nlr = 0.0001\nbetas = [0.5, 0.999]\npxls = (-1., 1.)\n\ngan2 = GAN(G, D, lr, train_dl, input_G, batch_size, device=device, rows=5, pxls=pxls, dim=dim,  channels=channels, betas=betas)\n\ncheckpoint = torch.load('models\/model.pth')\ngan2.G.load_state_dict(checkpoint['G_state_dict'])\ngan2.D.load_state_dict(checkpoint['D_state_dict'])\ngan2.D_optimizer.load_state_dict(checkpoint['D_optimizer_state_dict'])\ngan2.G_optimizer.load_state_dict(checkpoint['G_optimizer_state_dict'])","f8edf69b":"# GAN Model","e028a9b2":"### Get mean and std\n* solo en caso de tomar los 3 canales RGB","51767e8e":"## Discriminator","f4b274cb":"## Load Models","bf9edd1b":"## Generator Model "}}