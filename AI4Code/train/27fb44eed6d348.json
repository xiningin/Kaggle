{"cell_type":{"136aa6b8":"code","fd320575":"code","057e1bc8":"code","36ef071d":"code","3b9da1f2":"code","d4781c36":"code","6bd8ec72":"code","7f87a2a7":"code","acd881bc":"code","505fff99":"code","400a0019":"code","8ba5219b":"markdown","40f73d1e":"markdown","55ca2bf0":"markdown","28657f54":"markdown","42fa701a":"markdown","7a7bd8c6":"markdown","7dbb8eb3":"markdown","e901acd1":"markdown","d929aa27":"markdown","27d671d7":"markdown","ac266c8c":"markdown"},"source":{"136aa6b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # data vizualisation\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","fd320575":"#Dataset overview\ndf = pd.read_csv('..\/input\/BreadBasket_DMS.csv')\nprint(df.info())\nprint(df.head(5))\ndf[df['Item'] == 'NONE'].count()","057e1bc8":"df['Year'] = df.Date.apply(lambda x: x.split('-')[0])\ndf['Month'] = df.Date.apply(lambda x: x.split('-')[1])\ndf['Day'] = df.Date.apply(lambda x: x.split('-')[2])\ndf['Hour'] = df.Time.apply(lambda x: int(x.split(':')[0]))\ndf.drop(columns = 'Time', inplace = True)\ndf = df[df['Item'] != 'NONE']\nunique_items = len(df['Item'].unique())\nprint('Unique items sold: ' + str(unique_items))","36ef071d":"sns.set(style = 'whitegrid')\nsales = df['Item'].value_counts()\nf = sales[:10].plot.bar(title = 'Top 10 sales')\nf.legend(['Number of items sold'])","3b9da1f2":"coffee_sales = df[df['Item'] == 'Coffee']\ncoffee_times = coffee_sales['Hour'].value_counts().sort_index()\nf = coffee_times.plot.bar(title = 'Coffee sales by hour')\nf.set_xlabel('Time of day')","d4781c36":"frequent_items = sales[1:10] #skip coffee\nfor item in frequent_items.index:\n    plt.figure()\n    curr_sales = df[df['Item'] == item]\n    curr_times = curr_sales['Hour'].value_counts().sort_index()\n    f = curr_times.plot.bar(title = (item + ' sales by hour'))\n    f.set_xlabel('Time of day')","6bd8ec72":"df['Day_of_week'] = pd.to_datetime(df['Date']).dt.weekday_name\nsales_by_day = df['Day_of_week'].value_counts()\nsales_by_day.plot.bar(title = 'Sales by day of week')","7f87a2a7":"weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ndf_coffee = df[df['Item'] == 'Coffee']\nfor day in weekdays:\n    plt.figure()\n    curr_sales = df_coffee[df_coffee['Day_of_week'] == day]\n    curr_times = curr_sales['Hour'].value_counts().sort_index()\n    curr_times.plot.bar(title = (day + ' coffee sales by hour'))","acd881bc":"transactions_by_month = pd.DataFrame(df.groupby(by = ['Year', 'Month'])['Transaction'].nunique().rename('N transactions')).reset_index()\ntransactions_by_month['Date'] = transactions_by_month['Year'] + '-' + transactions_by_month['Month']\ng = sns.barplot('Date', 'N transactions', data = transactions_by_month)\ng.set_xticklabels(g.get_xticklabels(), rotation = 30)","505fff99":"transactions_by_date = pd.DataFrame(df.groupby(by = ['Year', 'Month', 'Day'])['Transaction'].nunique().rename('Transactions a day')).reset_index()\ntransactions_by_date['Date'] = transactions_by_date['Year'] + '-' + transactions_by_date['Month']\ng = sns.barplot('Date', 'Transactions a day', data = transactions_by_date)\ng.set_xticklabels(g.get_xticklabels(), rotation = 30)","400a0019":"df_holidays = df[df['Month'] == '12']\ndf_holidays = df_holidays[df_holidays['Day'].isin(map(str, range(24, 32)))]\nprint(df_holidays.shape)\nholiday_by_date = pd.DataFrame(df_holidays.groupby(by = ['Month', 'Day'])['Transaction'].nunique().rename('Transactions a day')).reset_index()\nholiday_by_date['Date'] = holiday_by_date['Month'] + '-' + holiday_by_date['Day']\ng = sns.barplot('Date', 'Transactions a day', data = holiday_by_date)\ng.set_xticklabels(g.get_xticklabels(), rotation = 30)","8ba5219b":"Shop has only been open for about 6 months. How many transactions do we make each month? (Note, this is number of transactions, not items sold!)\nOctober 2016 bakery just opened, so let's ignore its little bar. November - it's popular! Probably people want to try it out. Then, December sales drop and sort of stay stable until March. Did people who try it out decide it was not that good? Or perhaps another shop opened nearby?\nA big drop in monthly sales from Nov to Dec can be explained by a large number of holidays in December. We'll look into those days in just a minute, but another way to see if number of sales dropped because of holidays or for other reasons is to look into average number of daily transactions for each month.","40f73d1e":"Let's nevertheless see whethere there were any sales on holidays at all. Let's pick up the dates from Christmas Eve to New Year from the dataset and find number of transactions on those days too. Looks like people prepare for Christmas, buying sweets, or probably just meeting for coffee with friends and family. Then we are closed for 2 days, and then sales slowly recover into the New Year.","55ca2bf0":"Actually, morning? Let's see! How is coffee sold during the day? Well, coffee consumption is certainly shifted to the morning hours, but some are not afraid to drink coffee well after lunchtime.","28657f54":"Let's clean it up a bit. Date in the existing form is somewhat cumbersome to work with; let's create separate columns for its parts - year, month, day, and hour of day. Minutes are probably not useful and we'll drop exact Time column. Also, let's remove the rows with 'NONE' items - not sure why does it appear? Cancelled purchase? Or some service sort of transaction? (This is entirely speculative)\nNumber of different items ever sold in the bakery - 94.","42fa701a":"Thanks for reading!","7a7bd8c6":"Let's see what time we drink coffee on different days. Not surprising, Friday is a bit of a lazy day. Saturday is even better. Most coffee sales occur at 11 on Saturday and Sunday. On Sunday shop is also probably only open 9-5.","7dbb8eb3":"Hmmm. Looks like the daily number of transactions dropped in December too, so a bunch of holidays is probably not the only thing responsible for sales drop!","e901acd1":"Let's add a weekday to our dataset for each date and see how sales differ by the weekday. I guess there is not much information there. Saturdays are good days for business.","d929aa27":"Many have already explored this dataset. Let's take a look anyways: it has about 21293 rows, corresponding to the number of items sold by the bakery; looks like the data is also very clean: no missing data. However, at the closer look we can see that number of items, namely 786, are listed as 'NONE'.","27d671d7":"This is pretty standard but here is the barplot of most selling items in the bakery. No surprses. Coffee wins by a large margin. Happy morning everyone!","ac266c8c":"What about other items? Let's look into time-dependent consumption of other frequently sold items in the bakery. Funny enough, tea consumption is shifted towards afternoon hours. Yes, you had your coffee in the morning, and too much may interfere with your sleep. Drink tea instead!\nCookies and brownies are showing a bimodal distribution. I can see why... I can eat cookies all day! Have one with your coffee in the morning, another one with your tea in the afternoon.\nUnsurprisingly, sandwiches are for lunch. Also unsurprisingly, pastries are for breakfast. Medialunas are also for breakfast. I don't know if that's surprising or not. No idea what those are."}}