{"cell_type":{"63aa6a7a":"code","6bba0bd8":"code","50e57bcb":"code","4642a33a":"code","0fe053ba":"code","051da851":"code","0a5f10b0":"code","3222ab76":"code","ebad032d":"code","424a40a4":"markdown"},"source":{"63aa6a7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6bba0bd8":"def produce_accuracy(list1,list2):\n    if len(list1)!=len(list2):\n        raise ValueError('lengths do not match')\n    else:\n        no_of_matches=0\n        for i in range(len(list1)):\n            if list1[i]==list2[i]:\n                no_of_matches+=1\n        percent=no_of_matches\/len(list1)\n        return percent","50e57bcb":"data=pd.read_csv('..\/input\/data.csv')\ncols=list(data.columns)\nprint(cols)\ndata=data.fillna(0)","4642a33a":"print(data.shape)\nprint(data.head())","0fe053ba":"print(data.diagnosis.unique().tolist())\nprint(len(data[data['diagnosis']=='M'].diagnosis))\ndef binarizer(x):\n    if x=='M':\n        return 0\n    else:\n        return 1\ndata['binary_class']=data['diagnosis'].apply(lambda x:binarizer(x))\ndata=data.drop(['diagnosis','Unnamed: 32'],axis=1)","051da851":"data=data.drop(['id'],axis=1)\nprint(data.shape)\nprint(data.columns)\n","0a5f10b0":"import sklearn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import precision_recall_fscore_support\n#create train,test,validation split with 20% fractions\ndata_train=data.sample(frac=0.8,random_state=200)\ndata_test=data.drop(data_train.index)\ndata_validation=data_train.sample(frac=0.1,random_state=210)\ndata_train_ultimate=data_train.drop(data_validation.index)\nX_train=data_train_ultimate.drop(['binary_class'],axis=1)\nX_test=data_test.drop(['binary_class'],axis=1)\nY_train=data_train_ultimate['binary_class']\nY_test=data_test['binary_class']\nvalidation_test=data_validation.drop(['binary_class'],axis=1)\nvalidation_actual=data_validation['binary_class']\n","3222ab76":"print(data.shape)\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)\nprint(validation_test.shape)\nprint(validation_actual.shape)","ebad032d":"#let's try logistic regression\n#first time with default 100 max_iter it didn't converge. So, increased to 1000.\nlogistic_model=LogisticRegression(solver='lbfgs',max_iter=1000,n_jobs=-1)\nlogistic_model.fit(X_train,Y_train)\npredictions=logistic_model.predict(X_test)\nprint('the naive prediction-accuracy is:',produce_accuracy(predictions,Y_test.tolist()))\nprint('the precision,recall and fscore results are: ',precision_recall_fscore_support(predictions,Y_test.tolist()))\nvalidation_prediction=logistic_model.predict(validation_test)\nprint('the accuracy in validation set is:',produce_accuracy(validation_actual.tolist(),validation_prediction))\nprint('the precision,recall and fscore results are: ',precision_recall_fscore_support(validation_prediction,validation_actual.tolist()))\n\n","424a40a4":"In this notebook, I want to explore some of the basic practices classification works. I have currently committed a basic logistic regression. I plan to explore \n(1) logistic regression\n(2) svm \n(3) effects of scaling vs current unscaled data\n(4) effects of introducing balance or weights\n(5) train some neural network later.\n"}}