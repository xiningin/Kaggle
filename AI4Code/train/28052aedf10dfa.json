{"cell_type":{"caa982d7":"code","daba959c":"code","e65f3556":"code","18c61358":"code","2739b5ff":"code","2b116cc5":"code","1aab38bc":"code","287b5983":"code","971b6bf0":"code","e0e4a507":"code","42a85003":"markdown"},"source":{"caa982d7":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom skimage import color\nfrom skimage import io\nfrom skimage.transform import rescale, resize\n\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.applications import Xception\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport keras.backend as K\nfrom keras.models import Sequential\nimport tensorflow as tf\nimport warnings\n\n#warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n\n#config = tf.ConfigProto()\n#config.gpu_options.allow_growth = True\n#sess = tf.Session(config=config)\n#K.set_session(sess)","daba959c":"img_size = 90\ntrain_df = pd.read_csv(r\"..\/input\/train.csv\")\ntrain_df.head()","e65f3556":"def prepareImages(data, m, dataset):\n    print(\"Preparing images\")\n    X_train = np.zeros((m, img_size, img_size, 1))\n    count = 0\n    \n    for fig in data['Image']:\n        img = image.load_img(r\"..\/input\/\"+dataset+\"\/\"+fig, target_size=(img_size, img_size, 3))\n        x = image.img_to_array(img)\n        #x = io.imread(r\"..\/input\/\"+dataset+\"\/\"+fig)\n        x = color.rgb2gray(x)\n        #x = resize(x, (img_size, img_size), anti_aliasing=True)\n        x = preprocess_input(x)\n        x = np.expand_dims(x, axis=2)\n\n        X_train[count] = x\n        #if (count%500 == 0):\n            #print(\"Processing image: \", count+1, \", \", fig)\n        count += 1\n    \n    return X_train\n\ndef prepareLabels(y):\n    values = np.array(y)\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(values)\n    # print(integer_encoded)\n\n    onehot_encoder = OneHotEncoder(sparse=False)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n    # print(onehot_encoded)\n\n    y = onehot_encoded\n    # print(y.shape)\n    return y, label_encoder","18c61358":"X = prepareImages(train_df, train_df.shape[0], \"train\")\nX \/= 255\ny,label_encoder=prepareLabels(train_df['Id'])","2739b5ff":"split = int(0.8*len(X))\nX_val = X[split-len(X):]\ny_val = y[split-len(X):]\nX = X[:split]\ny = y[:split]","2b116cc5":"INIT_LR = 0.0007\nEPOCHS = 50\nBS = 64\nnum_classes = y.shape[1]\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0', input_shape = (img_size, img_size, 1)))\n\nmodel.add(BatchNormalization(axis = 3, name = 'bn0'))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D((2, 2), name='max_pool'))\nmodel.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D((3, 3), name='avg_pool'))\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(500, activation=\"relu\", name='rl'))\nmodel.add(Dropout(0.8))\nmodel.add(Dense(y.shape[1], activation='softmax', name='sm'))\n\n#model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n\n\n\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.1, zoom_range=0.3, horizontal_flip=True, vertical_flip=False, fill_mode=\"nearest\")\n#model = Model(input = base_model.input, output = predictions)\n#model.summary()\n#file_path=r\"..\/happy_whale.hdf5\"\n#model.load_weights(file_path)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=20, verbose=2, mode='auto', baseline=0, restore_best_weights=True)\n#checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\ncallbacks_list = [early_stopping]","1aab38bc":"history=model.fit_generator(aug.flow(X, y, BS),epochs=EPOCHS,validation_data=aug.flow(X_val, y_val, BS),verbose=2)","287b5983":"test = os.listdir(r\"..\/input\/test\/\")\ncol = ['Image']\ntest_df = pd.DataFrame(test, columns=col)\ntest_df['Id'] = ''\nZ = prepareImages(test_df, test_df.shape[0], \"test\")\nZ \/= 255","971b6bf0":"predictions = model.predict(np.array(Z), verbose=1)\nfor i, pred in enumerate(predictions):\n    test_df.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))","e0e4a507":"test_df.head(10)\ntest_df.to_csv('submission.csv', index=False)","42a85003":"I have taken help to build the kernel from following link:\n> https:\/\/www.kaggle.com\/pestipeti\/keras-cnn-starter\n\nHere I am converting the images to gray scale befor training\/ testing."}}