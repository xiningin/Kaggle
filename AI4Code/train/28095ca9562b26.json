{"cell_type":{"1fe57dfe":"code","1e512c08":"code","1114bab7":"code","15ffa571":"code","3760e464":"code","d56488c1":"code","30ebaaf8":"code","3bc34fef":"code","d281be4a":"code","1244ba5b":"code","844b5e7d":"code","2287cde7":"code","d82a68be":"code","ce93950a":"code","1cf69c6b":"markdown","a3734a7e":"markdown","ab0bc8da":"markdown","cd78e5d9":"markdown","d1275972":"markdown","6fc6e8ed":"markdown"},"source":{"1fe57dfe":"# Put these at the top of every notebook, to get automatic reloading and inline plotting\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","1e512c08":"PATH_TO_IMAGES = \"..\/input\/imgs\/imgs\/\"\nsize=224","1114bab7":"from fastai.imports import *\nfrom fastai.transforms import *\nimport io\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nimport requests\nfrom torchvision import models, transforms\nfrom torch.autograd import Variable\nimport warnings\nwarnings.filterwarnings('ignore')","15ffa571":"torch.cuda.is_available(), torch.backends.cudnn.enabled","3760e464":"import numpy as np\nimport os","d56488c1":"fnames = np.array([f'{f}' for f in sorted(os.listdir(f'{PATH_TO_IMAGES}'))])\nLABELS_URL = 'https:\/\/s3.amazonaws.com\/outcome-blog\/imagenet\/labels.json'","30ebaaf8":"fnames","3bc34fef":"# Let's get our class labels.\nresponse = requests.get(LABELS_URL)  # Make an HTTP GET request and store the response.\nlabels = {int(key): value for key, value in response.json().items()}","d281be4a":"l = range(1,6)\n{key: labels[key] for key in labels.keys() & l}","1244ba5b":"# Initialize the pre-trained model\nmodel = models.resnet50(pretrained=True)\n#default is train mode we need to change it\nmodel.eval();","844b5e7d":"img = plt.imread(f'{PATH_TO_IMAGES}{fnames[1]}')\nplt.imshow(img);","2287cde7":"# Image pre-processing transforms\nnormalize = transforms.Normalize(\n    mean=[0.485, 0.456, 0.406],\n    std=[0.229, 0.224, 0.225]\n)\npreprocess = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize(size),\n    transforms.CenterCrop(size),\n    transforms.ToTensor(),\n    normalize\n])","d82a68be":"# Apply transforms\nimg_tensor = preprocess(img)\n# Add a batch dimension\nimg_tensor.unsqueeze_(0)\n# Forward pass without activation\nfc_out = model(Variable(img_tensor))","ce93950a":"from torch.nn import functional as f\n\nh_x = f.softmax(fc_out, dim=1).data.squeeze()\nprobs, idx = h_x.sort(0, True)\nidx = idx.tolist()\nfor i in range(0, 5):\n    print('{:.3f} -> {}'.format(probs[i], labels[idx[i]]))","1cf69c6b":"# Imagens?\n\nJ\u00e1 estamos acostumados em trabalhar com dados de texto, ou dados \"estruturados\". O que \u00e9 v\u00e1lidos saber \u00e9 que modelos de **Machine Learning** conseguem lidar com qualquer tipo de dado. Desde que sejamos capazes de tratar o dado de forma correta. No fim, \u00e9 sempre bom lembrar: os computadores *apenas enxergam n\u00fameros*.\n\n![](https:\/\/i.imgur.com\/yUcuZb9.png)\n\nAssim, imagens s\u00e3o apenas um conjunto de array de n\u00fameros. Uma imagem 256x256 com 3 canais (RGB) pode ser traduzida como um array \u00fanico de 256x256x3 = 196,608 n\u00fameros. Existem alguns \"truques\" para tratar imagens que n\u00e3o s\u00e3o quadradas ou n\u00e3o est\u00e3o na escala de cores padr\u00e3o, mas como essa aula n\u00e3o \u00e9 uma aula de vis\u00e3o computacional, n\u00e3o focaremos nisso hoje ):","a3734a7e":"Algumas classes","ab0bc8da":"# T\u00e1, mas o que \u00e9 Treinar uma Rede Neural?\n\n![](https:\/\/imgur.com\/UC4RdMm.jpg)\n\nPense que essa \"caixa preta\" que voc\u00eas viram tem uma s\u00e9rie de \"alavancas\" que precisam ser tunadas. Essas alavancas, em um jarg\u00e3o mais \"tecnico\" s\u00e3o chamadas de pesos. Quando os pesos est\u00e3o ajustados da maneira correta, a rede neural d\u00e1 a resposta para diferentes entradas.\n\n**Treinar uma rede neural significa ajustar essas alavancas para a forma ideal**\n\n![](https:\/\/imgur.com\/4cyLGL4.jpg)\n\n# Nossa primeira Rede Neural\n\nJ\u00e1 vamos entrar nos detalhes de como que podemos \"ajustar essas alavancas\" (chamamos isso de aprender os par\u00e2metros da rede). Mas n\u00e3o seria legal se pudessemos usar uma rede j\u00e1 treinada? E n\u00f3s **podemos**.\n\n# Conhecendo o ImageNet\n\nO ImageNet \u00e9 um projeto que visa fornecer um dataset de imagens para fins de pesquisa. Ele cont\u00e9m mais de 14 milh\u00f5es de imagens as quais pertencem a mais de 20 mil classes. Todo os anos eles promovem o ImageNet Large Scale Visual Recognition Challenge (ILSVRC), que \u00e9 basicamente uma competi\u00e7\u00e3o anual para que os times de pesquisa avaliem seus algoritmos de vis\u00e3o computacional. O termo Deep Learning voltou a ficar famoso em 2011 gra\u00e7as \u00e0 essa competi\u00e7\u00e3o, quando o Alex Krizhevsky e sua equipe de pesquisa venceram a competi\u00e7\u00e3o com uma vantagem absurda !\n![](https:\/\/imgur.com\/yMAyBgg.jpg)\n\n# Usando uma rede treinada?\n\nEntrando em um pouco mais de detalhes, se utilizassemos uma rede treinada nessas competi\u00e7\u00f5es, teriamos a vantagem de que alguns par\u00e2metros da rede j\u00e1 estariam de acordo com o nosso objetivo (no caso, classificar objetos). Isso nos d\u00e1 uma vantagem absurda do que se fossemos treinar uma rede do zero.\n","cd78e5d9":"# Agora \u00e9 a sua vez :)\n\n\nProcure por algumas imagens pela internet e tente descobrir algumas situa\u00e7\u00f5es em que o modelo \u00e9 bom e em que situa\u00e7\u00f5es ele n\u00e3o \u00e9 bom :) Ser\u00e1 que ele s\u00f3 \u00e9 ruim com frutas?","d1275972":"# O que s\u00e3o redes Neurais?\n\nRedes Neurais s\u00e3o algoritmos de aprendizado surpervisiodado (que podem ser utilizados de maneira n\u00e3o surpervisionada). Logo, ela recebe dados de treinamento e tenta \"aprender\" como que esses dados de treinamento se relacionam com a sa\u00edda esperada.\n\n![](https:\/\/i.imgur.com\/E6pT2n9.jpg)\n\nNo caso da imagem acima, n\u00f3s entramos com uma imagem e a rede d\u00e1 a probabilidade de ser cada uma das nossas classes. Uma rede neural perfeita retornaria (1, 0, 0) oara um gato (100% de chance de ser um gato; 0% de chance de ser um cachorro e 0% de chance de ser qualquer coisa que n\u00e3o seja nenhum gato e nem um cachorro). Na realidade, vai ser imposs\u00edvel de uma rede nos dar esses resultados, mas podemos conseguir algo como (0.97, 0.02, 0.01), como no exemplo da imagem.\n\n","6fc6e8ed":"Quando trabalhamos com imagens ou outros dados que envolvem algoritmos de Deep Learning, \u00e9 importante termos a GPU ativada. O framework de prgrama\u00e7\u00e3o utilizado pelas placas da NVidea \u00e9 conhecido como CUDA e, al\u00e9m disso, as placas da NVidea apresentam fun\u00e7\u00f5es especiais que auxiliam no treinamento de modelos de deep learning. Veremos se as duas coisas est\u00e3o ativadas:"}}