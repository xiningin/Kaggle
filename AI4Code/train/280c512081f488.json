{"cell_type":{"998e70a0":"code","5d66c268":"code","6a86a39a":"code","abb46282":"code","8ff93d50":"code","d9102772":"code","8f7a0d9f":"code","6a18dca4":"code","fec61dd5":"code","65e7a06b":"code","11a65b69":"code","559c0037":"code","10faa7c8":"code","a317a8f0":"code","3adcdf04":"code","d02fdac1":"code","5d1d176f":"code","9edfd349":"code","dd8f8c84":"code","92600617":"code","286b0c8e":"code","54395bbb":"code","9beb42a5":"code","e5b4b2ed":"code","5f5ae2e4":"code","a1ff955a":"markdown","6c8be345":"markdown","6bbfd4e4":"markdown","d2a8e6f2":"markdown","2fa1ffba":"markdown","0025d883":"markdown","d8f0656e":"markdown","dd7d780f":"markdown","49dbd375":"markdown","113d975f":"markdown","74b277a8":"markdown"},"source":{"998e70a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d66c268":"train = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/train_V2.csv')","6a86a39a":"# Display all columns\npd.options.display.max_columns = None","abb46282":"train.head()","8ff93d50":"# Import libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","d9102772":"plt.figure(figsize=(11, 11))\nsns.heatmap(\n    train.corr(),\n    linewidths=0.1,\n    cmap='RdBu',\n)","8f7a0d9f":"# Import libraries\nimport gc\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_absolute_error","6a18dca4":"# Ideas to experiment\n\ndef original(df):\n    return df\n\ndef items(df):\n    df['items'] = df['heals'] + df['boosts']\n    return df\n\ndef players_in_team(df):\n    agg = df.groupby('groupId').size().to_frame('players_in_team')\n    df = df.merge(agg, on='groupId')\n    return df\n\ndef total_distance(df):\n    df['total_distance'] = df['walkDistance'] + df['rideDistance'] + df['swimDistance']\n    return df\n\ndef headshots_over_kills(df):\n    df['headshots_over_kills'] = df['headshotKills'] \/ df['kills']\n    df['headshots_over_kills'] = df['headshots_over_kills'].fillna(0)\n    return df\n\ndef killPlace_over_maxPlace(df):\n    df['killPlace_over_maxPlace'] = df['killPlace'] \/ df['maxPlace']\n    return df\n\ndef walkDistance_over_heals(df):\n    df['walkDistance_over_heals'] = df['walkDistance'] \/ df['heals']\n    df['walkDistance_over_heals'] = df['walkDistance_over_heals'].replace(np.inf, 0)\n    return df\n\ndef walkDistance_over_kills(df):\n    df['workDistance_ove_kills'] = df['walkDistance'] \/ df['kills']\n    df['workDistance_ove_kills'] = df['workDistance_ove_kills'].fillna(0)\n    df['workDistance_ove_kills'] = df['workDistance_ove_kills'].replace(np.inf, 0)\n    return df\n\ndef teamwork(df):\n    df['teamwork'] = df['assists'] + df['revives']\n    return df\n    \ndef match_mode_classifier(mt):\n    if 'solo' in mt:\n        return 'solo'\n    elif 'duo' in mt:\n        return 'duo'\n    elif 'squad' in mt:\n        return 'squad'\n    else:\n        return 'others'","fec61dd5":"# My Idea to experiment\ndef match_mode(df):\n    df['match_mode'] = df['matchType'].map(lambda mt: match_mode_classifier(mt))\n    dummies = pd.get_dummies(df['match_mode'])\n    df = df.join(dummies)\n    df = df.drop('match_mode', axis=1)\n    return df","65e7a06b":"# Function to run experiments\ndef run_experiments(functions):\n    results = []\n    for function in functions:\n        start = time.time()\n        score = run_experiment(function)\n        execution_time = time.time() - start\n        result = {\n            'name': function.__name__,\n            'score': score,\n            'exection time': f'{round(execution_time, 2)}s'\n        }\n        print(result)\n        results.append(result)\n        gc.collect()\n    return pd.DataFrame(results, columns=['name', 'score', 'execution time']).sort_values(by='score')","11a65b69":"# Function to run a experiment\ndef run_experiment(function):\n    df = train.copy()\n    df = function(df)\n    \n    target = 'winPlacePerc'\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', target]\n    cols_to_fit = [\n        col\n        for col in df.columns\n        if col not in cols_to_drop\n    ]\n    \n    X = df[cols_to_fit]\n    y = df[target].fillna(df[target].mean())\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)\n    \n    model = LGBMRegressor(random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_valid)\n    return mean_absolute_error(y_pred, y_valid)","559c0037":"# # Run Experiments!\n# run_experiments([\n#     teamwork,\n#     match_mode,\n#     original,\n#     items,\n#     players_in_team,\n#     total_distance,\n#     headshots_over_kills,\n#     killPlace_over_maxPlace,\n#     walkDistance_over_heals,\n#     walkDistance_over_kills,\n# ])","10faa7c8":"# Ideas to experiment\ndef min_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId','groupId'])[features].min()\n    return df.merge(agg, suffixes=['', '_min'], how='left', on=['matchId', 'groupId'])\n\ndef max_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].max()\n    return df.merge(agg, suffixes=['', '_max'], how='left', on=['matchId', 'groupId'])\n\ndef sum_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].sum()\n    return df.merge(agg, suffixes=['', '_sum'], how='left', on=['matchId', 'groupId'])\n\ndef median_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].median()\n    return df.merge(agg, suffixes=['', '_median'], how='left', on=['matchId', 'groupId'])\n\ndef mean_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].mean()\n    return df.merge(agg, suffixes=['', '_mean'], how='left', on=['matchId', 'groupId'])\n\ndef rank_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].mean()\n    agg = agg.groupby('matchId')[features].rank(pct=True)\n    return df.merge(agg, suffixes=['', '_mean_rank'], how='left', on=['matchId', 'groupId'])","a317a8f0":"# My Idea to experiment","3adcdf04":"# # Run Experiments!\n# run_experiments([\n#     original,\n#     min_by_team,\n#     max_by_team,\n#     sum_by_team,\n#     median_by_team,\n#     mean_by_team,\n#     rank_by_team\n# ])","d02fdac1":"# import eli5\n# from eli5.sklearn import PermutationImportance\n\n# target = 'winPlacePerc'\n# cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', target]\n# cols_to_fit = [col for col in train.columns if col not in cols_to_drop]\n\n# X = train[cols_to_fit]\n# y = train[target].fillna(train[target].mean())\n\n# X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)\n\n# model = LGBMRegressor(random_state=0)\n# model.fit(X_train, y_train)\n\n# perm = PermutationImportance(model, random_state=42).fit(X_valid, y_valid)\n# eli5.show_weights(perm, feature_names=list(cols_to_fit))","5d1d176f":"def run_promising_preprocesses(df):\n    # Caution! There are dependencies to run.\n    df = run_promissing_aggregates(df)\n    df = run_promissing_conversions(df)\n    df = run_promissing_creations(df)\n    return df\n\ndef run_promissing_aggregates(df):\n    # Common\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    \n    # Aggregates\n#     agg_min = df.groupby(['matchId','groupId'])[features].min()\n#     agg_max = df.groupby(['matchId', 'groupId'])[features].max()\n#     agg_sum = df.groupby(['matchId', 'groupId'])[features].sum()\n#     agg_median = df.groupby(['matchId', 'groupId'])[features].median()\n    agg_mean = df.groupby(['matchId', 'groupId'])[features].mean()\n    agg_rank = agg_mean.groupby('matchId')[features].rank(pct=True)\n    \n    # Merge\n#     df = df.merge(agg_min, suffixes=['', '_min'], how='left', on=['matchId', 'groupId'])\n#     df = df.merge(agg_max, suffixes=['', '_max'], how='left', on=['matchId', 'groupId'])\n#     df = df.merge(agg_sum, suffixes=['', '_sum'], how='left', on=['matchId', 'groupId'])\n#     df = df.merge(agg_median, suffixes=['', '_median'], how='left', on=['matchId', 'groupId'])\n#     df = df.merge(agg_mean, suffixes=['', '_mean'], how='left', on=['matchId', 'groupId'])\n    df = df.merge(agg_rank, suffixes=['', '_rank'], how='left', on=['matchId', 'groupId'])\n    \n    return df\n\ndef run_promissing_conversions(df):\n    df = match_mode(df) # One-Hot encoding 'matchMode'\n    return df\n\ndef run_promissing_creations(df):\n    df = players_in_team(df) # Add 'players_in_team'\n    df = killPlace_over_maxPlace(df) # Add 'killPlace_over_maxPlace'\n    df = total_distance(df) # Add 'total_distance'\n    df = items(df) # Add 'total_distance'\n    return df","9edfd349":"# Run Promising Preprocesses\ntrain_preprocessed = run_promising_preprocesses(train.copy())\ntrain_preprocessed","dd8f8c84":"# Evaluate\ndef evaluate(df):\n    target = 'winPlacePerc'\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', target]\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    X = df[cols_to_fit]\n    y = df[target].fillna(df[target].mean())\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)\n\n    model = LGBMRegressor(random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_valid)\n    return mean_absolute_error(y_pred, y_valid)\n\nevaluate(train_preprocessed)","92600617":"# Output Memory Usage\nimport sys\n\nprint(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\"):\n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","286b0c8e":"# Fitting with promissing data\ntarget = 'winPlacePerc'\ncols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', target]\ncols_to_fit = [col for col in train_preprocessed.columns if col not in cols_to_drop]\n\nX = train_preprocessed[cols_to_fit]\ny = train_preprocessed[target].fillna(train_preprocessed[target].mean())\n\nmodel = LGBMRegressor(random_state=0)\nmodel.fit(X, y)","54395bbb":"# Import Test Data\ntest = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/test_V2.csv')","9beb42a5":"# Run Promising Preprocesses in Test\ntest_preprocessed = run_promising_preprocesses(test.copy())\ntest_preprocessed","e5b4b2ed":"# Predict\nX_test = test_preprocessed[cols_to_fit]\n\ny_pred = model.predict(X_test)\ny_pred","5f5ae2e4":"submission = pd.DataFrame({\n    'Id': test_preprocessed['Id'], # Caution!\n    'winPlacePerc': y_pred\n})\nsubmission.to_csv('submission.csv', index=False)","a1ff955a":"**We couldn't run all of promissing aggregates because of memory usage error..**","6c8be345":"## Promising Features","6bbfd4e4":"# Modeling","d2a8e6f2":"## Correlation","2fa1ffba":"# EDA","0025d883":"# Workflow\n1. Import datasets\n1. EDA\n1. Feature Engineering\n1. Modeling\n1. Submit","d8f0656e":"## Permutation Importance","dd7d780f":"# Submit","49dbd375":"# Special Thanks\n\nhttps:\/\/www.kaggle.com\/rejasupotaro\/effective-feature-engineering","113d975f":"# Import datasets","74b277a8":"# Feature Engineering"}}