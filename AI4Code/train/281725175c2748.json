{"cell_type":{"58a1a8bc":"code","d90b795b":"code","d293842e":"code","01bc8cd6":"code","55617187":"code","ddd56cde":"code","11121b84":"code","326bf334":"code","1f395fe6":"code","d6cf35be":"code","a571b365":"code","2e2d0ff6":"code","79c963ff":"code","a45a354b":"code","e5527984":"code","510d0c6d":"code","8a9126f8":"code","a60137ef":"code","c1ef41a4":"code","442a32ae":"code","24ff59cd":"code","46f1bcbd":"code","b2fd0ad4":"code","977776b1":"code","f36db3e7":"code","ac9f3e0c":"code","cf72eeca":"code","67fc1fb1":"code","5326964e":"code","7234eb93":"code","f016f372":"code","5c819824":"code","4d16e5c8":"code","ecb26741":"code","1ccdc571":"code","5855168d":"code","f3a45218":"code","af9653c1":"code","13a5f274":"code","458cc63a":"code","db6c2140":"code","4fe260ab":"code","c5a65d12":"code","499d99ad":"code","2fcda7d6":"code","213e3cd6":"code","c02003f8":"markdown","1ac37f6e":"markdown","a6792a49":"markdown","82d29bc2":"markdown","cc2cf949":"markdown","7d98337a":"markdown","38037d7c":"markdown","03c85e5b":"markdown","84df378d":"markdown","3c7c15bb":"markdown","09965c63":"markdown","f0710bed":"markdown","44f783d6":"markdown","64bd3839":"markdown","d2766263":"markdown","9fa1c821":"markdown","58a15cbd":"markdown","4ea7acf0":"markdown","4acc2aa7":"markdown","de947d25":"markdown"},"source":{"58a1a8bc":"from kaggle.competitions import nflrush\nimport pandas as pd\nimport numpy as np\nimport os\nimport datetime\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error\nimport optuna\nfrom scipy.stats import norm\nimport random\nfrom sklearn.model_selection import KFold, train_test_split\nimport gc\nfrom sklearn import preprocessing\nimport tqdm\nimport matplotlib.patches as patches\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport seaborn as sns\nsns.set_context(\"talk\")\nsns.set_style(\"white\")\nsns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(\"libraries imported!\")\npd.set_option('max_columns', 100)","d90b795b":"train_df = pd.read_csv('\/kaggle\/input\/nfl-big-data-bowl-2020\/train.csv', low_memory=False)\nprint(train_df.shape)\ntrain_df.head()","d293842e":"print(train_df.dtypes)","01bc8cd6":"# search for missing data\nimport missingno as msno\nmsno.matrix(df=train_df, figsize=(14,14), color=(0.5,0,0))","55617187":"# Which columns have nan?\nfor i in np.arange(train_df.shape[1]):\n    n = train_df.iloc[:,i].isnull().sum() \n    if n > 0:\n        print(list(train_df.columns.values)[i] + ': ' + str(n) + ' nans')","ddd56cde":"train_df.nunique()","11121b84":"train_df.describe()","326bf334":"df_numeric = train_df.select_dtypes(exclude=['object'])\nprint(df_numeric.shape)","1f395fe6":"fig, ax = plt.subplots(5, 5, figsize=(20, 20))\nax = ax.flatten()\n\nfor i, c in enumerate(df_numeric.columns.values):\n    sns.distplot(df_numeric[c].dropna(), ax=ax[i])\nplt.tight_layout()","d6cf35be":"del df_numeric\ngc.collect()","a571b365":"sns.distplot(train_df[\"Yards\"].values, bins=100)","2e2d0ff6":"train_df[\"Yards\"].value_counts()","79c963ff":"# Function to Create The Football Field \ndef create_football_field(linenumbers=True,\n                          endzones=True,\n                          highlight_line=False,\n                          highlight_line_number=50,\n                          highlighted_name='Line of Scrimmage',\n                          fifty_is_los=False,\n                          figsize=(12, 6.33)):\n    \"\"\"\n    Function that plots the football field for viewing plays.\n    Allows for showing or hiding endzones.\n    \"\"\"\n    rect = patches.Rectangle((0, 0), 120, 53.3, linewidth=0.1,\n                             edgecolor='r', facecolor='darkgreen', zorder=0)\n\n    fig, ax = plt.subplots(1, figsize=figsize)\n    ax.add_patch(rect)\n\n    plt.plot([10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n              80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n             [0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3,\n              53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n             color='white')\n    if fifty_is_los:\n        plt.plot([60, 60], [0, 53.3], color='gold')\n        plt.text(62, 50, '<- Player Yardline at Snap', color='gold')\n    # Endzones\n    if endzones:\n        ez1 = patches.Rectangle((0, 0), 10, 53.3,\n                                linewidth=0.1,\n                                edgecolor='r',\n                                facecolor='blue',\n                                alpha=0.2,\n                                zorder=0)\n        ez2 = patches.Rectangle((110, 0), 120, 53.3,\n                                linewidth=0.1,\n                                edgecolor='r',\n                                facecolor='blue',\n                                alpha=0.2,\n                                zorder=0)\n        ax.add_patch(ez1)\n        ax.add_patch(ez2)\n    plt.xlim(0, 120)\n    plt.ylim(-5, 58.3)\n    plt.axis('off')\n    if linenumbers:\n        for x in range(20, 110, 10):\n            numb = x\n            if x > 50:\n                numb = 120 - x\n            plt.text(x, 5, str(numb - 10),\n                     horizontalalignment='center',\n                     fontsize=20,  # fontname='Arial',\n                     color='white')\n            plt.text(x - 0.95, 53.3 - 5, str(numb - 10),\n                     horizontalalignment='center',\n                     fontsize=20,  # fontname='Arial',\n                     color='white', rotation=180)\n    if endzones:\n        hash_range = range(11, 110)\n    else:\n        hash_range = range(1, 120)\n\n    for x in hash_range:\n        ax.plot([x, x], [0.4, 0.7], color='white')\n        ax.plot([x, x], [53.0, 52.5], color='white')\n        ax.plot([x, x], [22.91, 23.57], color='white')\n        ax.plot([x, x], [29.73, 30.39], color='white')\n\n    if highlight_line:\n        hl = highlight_line_number + 10\n        plt.plot([hl, hl], [0, 53.3], color='yellow')\n        plt.text(hl + 2, 50, '<- {}'.format(highlighted_name),\n                 color='yellow')\n    return fig, ax","a45a354b":"# Adding Players For a Play (cyan = home, magenta = away), highlighting the line of scrimmage\nplayId = 20181230154157\nyl = train_df.query(\"PlayId == @playId\")['YardLine'].tolist()[0]\nfig, ax = create_football_field(highlight_line=True,\n                                highlight_line_number=yl+54)\ntrain_df.query(\"PlayId == @playId and Team == 'away'\") \\\n    .plot(x='X', y='Y', kind='scatter', ax=ax, color='magenta', s=30, legend='Away')\ntrain_df.query(\"PlayId == @playId and Team == 'home'\") \\\n    .plot(x='X', y='Y', kind='scatter', ax=ax, color='cyan', s=30, legend='Home')\nplt.title('Play # 20170907000118')\nplt.legend()\nplt.show()","e5527984":"train_df.head()","510d0c6d":"#from https:\/\/www.kaggle.com\/c\/nfl-big-data-bowl-2020\/discussion\/112681#latest-649087\nTurf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n        'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n        'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n        'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n        'SISGrass':'Artificial', 'Twenty-Four\/Seven Turf':'Artificial', 'natural grass':'Natural'} ","8a9126f8":"# from https:\/\/www.kaggle.com\/bgmello\/neural-networks-feature-engineering-for-the-win\nmap_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\nfor abb in train_df['PossessionTeam'].unique():\n    map_abbr[abb] = abb","a60137ef":"def uid_aggregation(comb, main_columns, uids, aggregations):\n    X = pd.DataFrame()\n    for main_column in main_columns:  \n        for col in uids:\n            for agg_type in aggregations:\n                new_col_name = col+'_'+main_column+'_'+agg_type\n                temp_df = comb[[col, main_column]]\n                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n                                                        columns={agg_type: new_col_name})\n\n                temp_df.index = list(temp_df[col])\n                temp_df = temp_df[new_col_name].to_dict()   \n\n                X[new_col_name] = comb[col].map(temp_df)\n                del temp_df\n                gc.collect()\n    return X","c1ef41a4":"def preprocess(df, labelEncoders=None):\n    X = df.select_dtypes(exclude=['object'])\n    def gameclock2min(x):\n        clock = x.split(\":\")\n        return 60 * int(clock[0]) + int(clock[1])\n    def height2inch(x):\n        height = x.split(\"-\")\n        return 12 * int(height[0]) + int(height[1])\n    def birthday2day(x):\n        days = x.split(\"\/\")\n        return 30 * int(days[0]) + int(days[1]) + 365 * int(days[2])\n    def timesnap2day(x):\n        days = x.split(\"-\")\n        return 365 * int(days[0]) + 30 * int(days[1]) + int(days[2][:2])\n    def utc2sec(x):\n        return int(x.split(\"-\")[2].split(\":\")[2].split(\".\")[0])\n    def group_stadium_types(stadium):\n        outdoor       = [\n            'Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field',\n            'Outdor', 'Ourdoor', 'Outside', 'Outddors',\n            'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl'\n        ]\n        indoor_closed = [\n            'Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed',\n            'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed',\n        ]\n        indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n        dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n        dome_open     = ['Domed, Open', 'Domed, open']\n\n        if stadium in outdoor:\n            return 0 #'outdoor'\n        elif stadium in indoor_closed:\n            return 3 # 'indoor closed'\n        elif stadium in indoor_open:\n            return 2 #'indoor open'\n        elif stadium in dome_closed:\n            return 4 #'dome closed'\n        elif stadium in dome_open:\n            return 1 #'dome open'\n        else:\n            return 5 #'unknown'\n\n    def group_game_weather(weather):\n        rain = [\n            'Rainy', 'Rain Chance 40%', 'Showers',\n            'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n            'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain'\n        ]\n        overcast = [\n            'Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n            'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n            'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n            'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n            'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n            'Partly Cloudy', 'Cloudy'\n        ]\n        clear = [\n            'Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n            'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n            'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n            'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n            'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n            'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny'\n        ]\n        snow  = ['Heavy lake effect snow', 'Snow']\n        none  = ['N\/A Indoor', 'Indoors', 'Indoor', 'N\/A (Indoors)', 'Controlled Climate']\n\n        if weather in rain:\n            return -1 #'rain'\n        elif weather in overcast:\n            return 1 #'overcast'\n        elif weather in clear:\n            return 2 #'clear'\n        elif weather in snow:\n            return -2 #snow'\n        elif weather in none:\n            return 0 #'none'\n\n    def clean_wind_speed(windspeed):\n        \"\"\"\n        This is not a very robust function,\n        but it should do the job for this dataset.\n        \"\"\"\n        ws = str(windspeed)\n        # if it's already a number just return an int value\n        if ws.isdigit():\n            return int(ws)\n        # if it's a range, take their mean\n        if '-' in ws:\n            return (int(ws.split('-')[0]) + int(ws.split('-')[1]))\/2\n        # if there's a space between the number and mph\n        if ws.split(' ')[0].isdigit():\n            return int(ws.split(' ')[0])\n        # if it looks like '10MPH' or '12mph' just take the first part\n        if 'mph' in ws.lower():\n            return int(ws.lower().split('mph')[0])\n        else:\n            return 0\n\n    def clean_wind_direction(wind_direction):\n        wd = str(wind_direction).upper()\n        if wd == 'N' or 'FROM S' in wd:\n            return 90 #'north'\n        if wd == 'S' or 'FROM N' in wd:\n            return 270 #'south'\n        if wd == 'W' or 'FROM E' in wd:\n            return 180 #'west'\n        if wd == 'E' or 'FROM W' in wd:\n            return 0 #'east'\n\n        if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n            return 45 #'north east'\n        if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n            return 135 #'north west'\n        if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n            return 315 #'south east'\n        if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n            return 225 #'south west'\n\n        if 'NW' in wd or 'NORTHWEST' in wd:\n            return 135 #'north west'\n        if 'NE' in wd or 'NORTH EAST' in wd:\n            return 45 #'north east'\n        if 'SW' in wd or 'SOUTHWEST' in wd:\n            return 225 #'south west'\n        if 'SE' in wd or 'SOUTHEAST' in wd:\n            return 315 #'south east'\n\n    def clean_offenceformation(of):\n        if of == \"SHOTGUN\":\n            return 9\n        elif of == \"SINGLEBACK\":\n            return 8\n        elif of == \"JUMBO\":\n            return 6\n        elif of == \"PISTOL\":\n            return 5\n        elif of == \"I_FORM\":\n            return 4\n        elif of == \"ACE\":\n            return 3\n        elif of ==  \"WILDCAT\":\n            return 2\n        elif of == \"EMPTY\":\n            return 1\n        else: \n            return 7\n    X[\"Dir\"] = np.mod(90 - df[\"Dir\"].values, 360)\n    X['Team'] = df['Team'].map({\"home\": 0, \"away\": 1})\n    X['Turf'] = df['Turf'].map(Turf)\n    X['Turf'] = X['Turf'].map({\"Natural\": 0,\"Artificial\": 1})\n    df[\"HomeTeamAbbr\"] = df[\"HomeTeamAbbr\"].map(map_abbr)\n    df[\"VisitorTeamAbbr\"] = df[\"VisitorTeamAbbr\"].map(map_abbr)\n    df[\"Possession\"] = df[\"PossessionTeam\"].map(map_abbr)\n    X['HomePossesion'] = 1 * (df['PossessionTeam'] == df['HomeTeamAbbr'])\n    X[\"OffenseFormation\"] = df['OffenseFormation'].apply(clean_offenceformation)\n    X['OffenseFormation'] = X['OffenseFormation'].fillna(7)\n    X['PassDuration'] = df['TimeHandoff'].apply(utc2sec) - df['TimeSnap'].apply(utc2sec)\n    # from https:\/\/www.kaggle.com\/zero92\/best-lbgm-new-features\n    X['Month'] = df['TimeHandoff'].apply(lambda x : int(x[5:7]))\n    X['Year'] = df['TimeHandoff'].apply(lambda x : int(x[0:4]))\n    X['Morning'] = df['TimeHandoff'].apply(lambda x : 1 if (int(x[11:13]) >=0 and int(x[11:13]) <12) else 0)\n    X['Afternoon'] = df['TimeHandoff'].apply(lambda x : 1 if (int(x[11:13]) <18 and int(x[11:13]) >=12) else 0)\n    X['Evening'] = df['TimeHandoff'].apply(lambda x : 1 if (int(x[11:13]) >= 18 and int(x[11:13]) < 24) else 0)\n    X['MatchDay'] = df['TimeSnap'].apply(timesnap2day)\n    X['PlayerBirthDate'] = df['PlayerBirthDate'].apply(birthday2day)\n    X['PlayerAge'] = X['MatchDay'] - X['PlayerBirthDate']\n    X['PlayDirection'] = df['PlayDirection'].map({'right': 1, 'left': -1})\n    X['PlayerWeight'] = df['PlayerWeight']\n    X['PlayerHeight'] = df['PlayerHeight'].apply(height2inch)\n    X['BMI'] = X['PlayerWeight'] \/ X['PlayerHeight']\n    X['GameClock'] = df['GameClock'].apply(gameclock2min)\n    X['StadiumType'] = df['StadiumType'].apply(group_stadium_types)\n    X['GameWeather'] = df['GameWeather'].apply(group_game_weather)\n    X['WindSpeed'] = df['WindSpeed'].apply(clean_wind_speed)\n    X['WindDirection'] = df['WindDirection'].apply(clean_wind_direction)\n    X['WindDirection'] = 2 * np.pi * (90 - X['WindDirection']) \/ 360\n    X['Humidity'] = df['Humidity'].fillna(df['Humidity'].median())\n    X['Temperature'] = df['Temperature'].fillna(df['Temperature'].median())\n    X['DefendersInTheBox'] = df['DefendersInTheBox'].fillna(df['DefendersInTheBox'].median())\n    \n    posts1 = [['0_DL','1_DL','2_DL','3_DL','4_DL','5_DL','6_DL','7_DL'],\n         ['0_LB','1_LB','2_LB','3_LB','4_LB','5_LB','6_LB'],['1_DB',\n         '2_DB','3_DB','4_DB','5_DB','6_DB','7_DB','8_DB']]\n    posts2 = [['1_RB','2_RB','3_RB','6_OL','7_OL','2_QB'],\n         ['1_TE','2_TE','3_TE','1_RB','2_RB','3_RB','0_TE','1_TE','2_TE','3_TE','4_TE'],['1_DB',\n         '1_WR','2_WR','3_WR','4_WR','5_WR','0_TE','1_TE','2_TE','3_TE','8_DB']]\n    for k in range(0,3) :\n        for col in posts1[k] :\n            X[col] = df['DefensePersonnel'].str.replace(' ','_').str.split(',_').apply(lambda x : 1 if (x[k] == col) else 0)\n            \n    for k in range(0,3) :\n        for col in posts2[k] :\n            X[col] = df['OffensePersonnel'].str.replace(' ','_').str.split(',_').apply(lambda x : 1 if (x[k] == col) else 0)\n    # from https:\/\/www.kaggle.com\/ryches\/model-free-benchmark\n    X['Field_eq_Possession'] = 1 * (df['FieldPosition'] == df['PossessionTeam'])    \n    X['is_rusher'] = 1 * (df['NflId'] == df['NflIdRusher'])\n    X['seconds_need_to_first_down'] = (df['Distance']*0.9144) \/ (df['Dis'].values + 0.01)\n    X['seconds_need_to_YardsLine'] = (df['YardLine']*0.9144) \/ (df['Dis'].values + 0.01)\n    X['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] \/ df['Distance']\n    \n    # based on https:\/\/www.kaggle.com\/sryo188558\/cox-proportional-hazard-model\n    X[\"Start\"] = X[\"YardLine\"]\n    X.loc[(X[\"Field_eq_Possession\"] == 1) & (X[\"PlayDirection\"] == 1), \"Start\"] = X.loc[(X[\"Field_eq_Possession\"] == 1) & (X[\"PlayDirection\"] == 1), \n                                                                                       \"YardLine\"] + 10\n    X.loc[(X[\"Field_eq_Possession\"] == 1) & (X[\"PlayDirection\"] == -1), \"Start\"] = 120 - X.loc[(X[\"Field_eq_Possession\"] == 1) & (X[\"PlayDirection\"] == -1), \n                                                                                       \"YardLine\"] - 10\n    X.loc[(X[\"Field_eq_Possession\"] == 0) & (X[\"PlayDirection\"] == 1), \"Start\"] = 120 - X.loc[(X[\"Field_eq_Possession\"] == 0) & (X[\"PlayDirection\"] == 1), \n                                                                                       \"YardLine\"] - 10\n    X.loc[(X[\"Field_eq_Possession\"] == 0) & (X[\"PlayDirection\"] == -1), \"Start\"] = X.loc[(X[\"Field_eq_Possession\"] == 0) & (X[\"PlayDirection\"] == -1), \n                                                                                       \"YardLine\"] + 10\n    X['Orientation'] = 2 * np.pi * (90 - X['Orientation']) \/ 360\n    X['locX'] = (X['X'].values - X['Start'].values) * X['PlayDirection'].values\n    X['locY'] = X['Y'].values - 53.3 \/ 2\n    X['velX'] = X['S'].values * np.cos(X['Orientation'].values) * X['PlayDirection'].values\n    X['velY'] = X['S'].values * np.sin(X['Orientation'].values)\n    X['accX'] = X['A'].values * np.cos(X['Orientation'].values) * X['PlayDirection'].values\n    X['accY'] = X['A'].values * np.sin(X['Orientation'].values)\n    \n    i_cols = ['VisitorScoreBeforePlay','HomeScoreBeforePlay','YardLine']\n    uids = ['DisplayName']\n    aggregations = ['mean','std','median', 'max', 'min']\n    X_agg = uid_aggregation(df, i_cols, uids, aggregations)\n    X = pd.concat([X, X_agg], axis=1)\n    \n    \n#     X['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n#     X['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\n#     X['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].map(map_abbr)\n#     X['FieldPosition'] = np.where(df['YardLine'] == 50, df['PossessionTeam'], df['FieldPosition'])\n#     for i in range(1,23) :\n#         for j in ['X','Y','S','A','YardLine'] :\n#             X[j+\"_\"+str(i)] = df[j].shift(i)\n\n#     categorical = df.select_dtypes(\"object\")\n#     if labelEncoders == None:\n#         labelEncoders = {}\n#         for c in categorical.columns:\n#             le = preprocessing.LabelEncoder()\n#             X[c] = le.fit(df[c].values).transform(df[c].values)\n#             labelEncoders[c] = le\n#     else:\n#         for c in categorical.columns:\n#             le = labelEncoders[c]\n#             X[c] = le.fit(df[c].values).transform(df[c].values)\n\n    return X","442a32ae":"# mydf = preprocess(train_df)\n# print(mydf.shape)\n# mydf.head()","24ff59cd":"train_df = preprocess(train_df)\nprint(train_df.shape)\ntrain_df.head()","46f1bcbd":"rm_cols = ['index','GameId','PlayId','NflId','FieldPosition', \n          'DisplayName','NflIdRusher']","b2fd0ad4":"features = [c for c in train_df.columns.values if c not in rm_cols]\ntrain_df = train_df[features]\nprint(train_df.shape)\ntrain_df.head()","977776b1":"# from https:\/\/www.kaggle.com\/hukuda222\/nfl-simple-model-using-lightgbm\n\ntrain_data=np.zeros((509762\/\/22, len(features)))\nfor i in tqdm.tqdm(range(0,509762,22)):\n    count=0\n    for c in features:\n        train_data[i\/\/22][count] = train_df[c][i]\n        count+=1","f36db3e7":"y_train_ = np.array([train_df[\"Yards\"][i] for i in range(0,509762,22)])","ac9f3e0c":"X_train = pd.DataFrame(data=train_data,columns=features)","cf72eeca":"features = [f for f in features if f not in [\"Yards\"]]\nX_train = X_train[features]\n\nprint(X_train.shape)\nX_train.head()","67fc1fb1":"y_train = np.zeros(len(y_train_),dtype=np.float)\nfor i in range(len(y_train)):\n    y_train[i]=(y_train_[i])\n\nscaler = preprocessing.StandardScaler()\nscaler.fit([[y] for y in y_train])\ny_train = np.array([y[0] for y in scaler.transform([[y] for y in y_train])])\ndata = [0 for i in range(199)]\nfor y in y_train:\n    data[int(y+99)]+=1\nplt.plot([i-99 for i in range(199)],data)","5326964e":"missing = train_df.isnull().sum() # Sum of missing values\nmissing = missing[missing > 0]  \nmissing.sort_values(inplace=True)\nmissing","7234eb93":"print(X_train.shape)\nprint(y_train.shape)","f016f372":"# from https:\/\/www.kaggle.com\/newbielch\/lgbm-regression-view\ndef get_cdf_df(yards_array):\n    pdf, edges = np.histogram(yards_array, bins=199,\n                 range=(-99,100), density=True)\n    cdf = pdf.cumsum().clip(0, 1)\n    cdf_df = pd.DataFrame(data=cdf.reshape(-1, 1).T, \n                            columns=['Yards'+str(i) for i in range(-99,100)])\n    return cdf_df\ncdf = get_cdf_df(y_train).values.reshape(-1,)\ndist_to_end_train = X_train.apply(lambda x:(100 - x.loc['YardLine']) if x.loc[\"Field_eq_Possession\"]==1 else x.loc['YardLine'],axis=1)","5c819824":"def get_score(y_pred,cdf,w,dist_to_end):\n    y_pred = int(y_pred)\n#     y_pred = y_pred.astype(int)\n    if y_pred ==w:\n        y_pred_array = cdf.copy()\n    elif y_pred - w >0:\n        y_pred_array = np.zeros(199)\n        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n    elif w - y_pred >0:\n        y_pred_array = np.ones(199)\n        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n    y_pred_array[-1]=1\n    y_pred_array[(dist_to_end+99):]=1\n    return y_pred_array    \n\ndef get_score_pingyi1(y_pred,y_true,cdf,w,dist_to_end):\n    y_pred = int(y_pred)\n    if y_pred ==w:\n        y_pred_array = cdf.copy()\n    elif y_pred - w >0:\n        y_pred_array = np.zeros(199)\n        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n    elif w - y_pred >0:\n        y_pred_array = np.ones(199)\n        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n    y_pred_array[-1]=1\n    y_pred_array[(dist_to_end+99):]=1\n    y_true_array = np.zeros(199)\n    y_true_array[(y_true+99):]=1\n    return np.mean((y_pred_array - y_true_array)**2)\n\n\ndef CRPS_pingyi1(y_preds,y_trues,w,cdf,dist_to_ends):\n    if len(y_preds) != len(y_trues):\n        print('length does not match')\n        return None\n    n = len(y_preds)\n    tmp = []\n    for a,b,c in zip(y_preds, y_trues, dist_to_ends):\n        tmp.append(get_score_pingyi1(a,b,cdf,w,c))\n    return np.mean(tmp)","4d16e5c8":"# Initial LGB parameters are ...\nlgbParams = {\n    'objective': 'regression',\n    'metric': 'mae',\n    'verbosity': -1,\n    'boosting_type': 'gbdt',\n    \"num_iterations\": 1000, \n    \"learning_rate\": 0.05,\n    \"lambda_l1\": 9,\n    \"lambda_l2\": 0.9,\n    \"num_leaves\": 42,\n    \"feature_fraction\": 0.4,\n    \"bagging_fraction\": 0.45,\n    \"bagging_freq\": 7,\n    \"min_child_samples\": 74,\n    \"random_state\": 42\n}","ecb26741":"## Visualize feature importance\n\n# make a LightGBM dataset\ntrainX, testX, trainY, testY = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\nd_train = lgb.Dataset(trainX, trainY)\nd_eval = lgb.Dataset(testX, testY, reference=d_train)\n\n# model training\nLGBmodel = lgb.train(lgbParams, d_train, valid_sets=d_eval, verbose_eval=1000)\n# LGBmodel = lgb.train(lgbParams, d_train, valid_sets=d_eval, early_stopping_rounds=500, verbose_eval=1000)\n\n# feature importance\nimportance = LGBmodel.feature_importance(importance_type=\"gain\")\nranking = np.argsort(-importance)\nfig, ax = plt.subplots(figsize=(20, 20))\nsns.barplot(x=importance[ranking], y=X_train.columns.values[ranking], orient='h')\nax.set_xlabel(\"feature importance\")\nplt.tight_layout()","1ccdc571":"features = X_train.columns.values[ranking][:30]\nprint(features)\nX_train = X_train[features]","5855168d":"# # FYI: Objective functions can take additional arguments\n# # (https:\/\/optuna.readthedocs.io\/en\/stable\/faq.html#objective-func-additional-args).\n# def objective(trial):\n    \n#     # make a LightGBM dataset\n#     trainX, testX, trainY, testY = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n#     d_train = lgb.Dataset(trainX, trainY)\n\n#     param = {\n#         'objective': 'regression',\n#         'metric': 'mae',\n#         'verbosity': -1,\n#         'boosting_type': 'gbdt',\n#         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n#         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n#         'num_leaves': trial.suggest_int('num_leaves', 40, 256),\n#         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n#         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n#     }\n\n#     gbm = lgb.train(param, d_train)\n#     preds = gbm.predict(testX)\n#     mae = mean_absolute_error(testY, preds)\n#     return mae","f3a45218":"# study = optuna.create_study(direction='minimize')\n# study.optimize(objective, n_trials=100)\n\n# print('Number of finished trials: {}'.format(len(study.trials)))\n\n# print('Best trial:')\n# trial = study.best_trial\n\n# print('  Value: {}'.format(trial.value))\n\n# print('  Params: ')\n# for key, value in trial.params.items():\n#     print('    {}: {}'.format(key, value))","af9653c1":"# lgbParams = trial.params\n# lgbParams['objective'] = 'regression'\n# lgbParams['metric'] = 'mae'\n# lgbParams['verbosity'] = -1\n# lgbParams['boosting_type'] = 'gbdt'\n# lgbParams[\"learning_rate\"] = 0.01\n# lgbParams[\"num_iterations\"] = 5000\n# lgbParams[\"random_state\"] = 1220\n# print(lgbParams)","13a5f274":"lgbParams = {'lambda_l1': 9.22654100630611, 'lambda_l2': 0.0014139850193561965, 'num_leaves': 64, 'feature_fraction': 0.5952892097040369,\n             'bagging_fraction': 0.45160449675869496, 'bagging_freq': 3, 'min_child_samples': 91, \n             'objective': 'regression', 'metric': 'mae', 'verbosity': -1, 'boosting_type': 'gbdt', \n             'learning_rate': 0.01, 'num_iterations': 5000, 'random_state': 1220}","458cc63a":"n_splits = 5\nseed = 1220\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\ny_valid = np.zeros(X_train.shape[0])\nmodels = []\n\nfor train_idx, valid_idx in kf.split(X_train, y_train):\n    trainX, trainY = X_train.iloc[train_idx, :], y_train[train_idx]\n    validX, validY = X_train.iloc[valid_idx, :], y_train[valid_idx]\n    \n    d_train = lgb.Dataset(trainX, trainY)\n    d_eval = lgb.Dataset(validX, validY, reference=d_train)\n    \n    LGBmodel = lgb.train(lgbParams, d_train, valid_sets=d_eval, \n                         early_stopping_rounds=500, \n                         learning_rates=lambda iter: 0.01 * (0.99 ** iter),\n                         verbose_eval=1000)\n    y_valid[valid_idx] += LGBmodel.predict(validX, num_iteration=LGBmodel.best_iteration)\n    models.append(LGBmodel)\ngc.collect()","db6c2140":"cprs = CRPS_pingyi1(y_valid, y_train.astype(int), 4, cdf, dist_to_end_train.astype(int))\nprint(\"cprs = {}\".format(cprs))","4fe260ab":"# y_pred = np.zeros((509762\/\/22,199))\n# y_ans = np.zeros((509762\/\/22,199))\n\n# for i,p in enumerate(np.round(scaler.inverse_transform(y_valid))):\n#     p+=99\n#     for j in range(199):\n#         if j>=p+10:\n#             y_pred[i][j]=1.0\n#         elif j>=p-10:\n#             y_pred[i][j]=(j+10-p)*0.05\n\n# for i,p in enumerate(y_train):\n#     p+=99\n#     for j in range(199):\n#         if j>=p:\n#             y_ans[i][j]=1.0\n\n# print(\"validation score:\",np.sum(np.power(y_pred-y_ans,2))\/(199*(509762\/\/22)))","c5a65d12":"# _EvalFunction(y_train, y_valid)[1]","499d99ad":"sns.distplot(y_valid)","2fcda7d6":"# You can only call make_env() once, so don't lose it!\nenv = nflrush.make_env()","213e3cd6":"index = 0\nfor (test_df, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n#     test, le = preprocess(test_df, labelEncoders=labelEncoders)\n    test = preprocess(test_df)\n    count=0\n    dist_to_end_test = test.apply(lambda x:(100 - x.loc['YardLine']) if x.loc[\"Field_eq_Possession\"]==1 else x.loc['YardLine'],axis=1)\n    test_data = np.zeros((1,len(features)))\n    for c in features:\n        try:\n            test_data[0][count] = test[c][index]\n        except:\n            test_data[0][count] = np.nan\n        count+=1\n        \n#     print(test_data)\n    y_pred = np.zeros(199)        \n    y_pred_p = np.sum(np.round(scaler.inverse_transform(\n        [model.predict(test_data) for model in models]))) \/ n_splits\n#     y_pred = list(get_score(y_pred_p, cdf, 4, dist_to_end_test.astype(int).values[0]))\n#     y_pred = np.array(y_pred).reshape(1,199)\n#     print(y_pred)\n    y_pred_p += 99\n    for j in range(199):\n        if j>=y_pred_p+10:\n            y_pred[j]=1.0\n        elif j>=y_pred_p-10:\n            y_pred[j]=(j+10-y_pred_p)*0.05\n#             y_pred[j]=norm_cumsum[max(min(j+10-y_pred_p),0)]\n#     pred_target = pd.DataFrame(index = sample_prediction_df.index, \\\n#                                columns = sample_prediction_df.columns, \\\n#                                data = y_pred)\n#     env.predict(pred_target)\n    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\n    index += 22\nenv.write_submission_file()","c02003f8":"So we use...","1ac37f6e":"### Training data is in the competition dataset as usual","a6792a49":"## In-depth Introduction\nFirst let's import the module and create an environment.","82d29bc2":"The amount of data is not crazy, which is good!\n\nLet's check what type of data are in the data.","cc2cf949":"Now ready for modeling!","7d98337a":"# Evaluation","38037d7c":"There are relatively a lot of object. We may need to convert them to numerical values somehow.\n\nnans?","03c85e5b":"# Make a submission\n## `iter_test` function\n\nGenerator which loops through each rushing play in the test set and provides the observations at `TimeHandoff` just like the training set.  Once you call **`predict`** to make your yardage prediction, you can continue on to the next play.\n\nYields:\n* While there are more rushing play(s) and `predict` was called successfully since the last yield, yields a tuple of:\n    * `test_df`: DataFrame with player and game observations for the next rushing play.\n    * `sample_prediction_df`: DataFrame with an example yardage prediction.  Intended to be filled in and passed back to the `predict` function.\n* If `predict` has not been called successfully since the last yield, prints an error and yields `None`.","84df378d":"## Feature importance","3c7c15bb":"Let's use the first X, for now...","09965c63":"There are relatively many nans for some columns such as \"WindSpeed\" and \"WindDirection\".\n\nnumber of uniques in each column?","f0710bed":"1, 2 and 3 yards are frequently observed.","44f783d6":"# Modeling\nHere we use lightGBM based on https:\/\/www.kaggle.com\/hukuda222\/nfl-simple-model-using-lightgbm. Please upvote his kernel!","64bd3839":"Note that yards are int64!","d2766263":"We are to predict \"Yards\". Let's close up.","9fa1c821":"Let's see how numerical columns look like for now.","58a15cbd":"# Field\nThanks to (https:\/\/www.kaggle.com\/robikscube\/nfl-big-data-bowl-plotting-player-position), we can draw players' positions on the field:D Please do upvote his kernel!","4ea7acf0":"# Making all-numeric data frame \nMany of the following functions are from https:\/\/www.kaggle.com\/marcovasquez\/nfl-basic-eda-data-visualization. Thanks a lot! Please do upvote his kernel:D The feature engineering is hard and needs more work.","4acc2aa7":"### lightGBM parameter tuning using Optuna\nUncomment the following two cells to run hyperparameter optimization using [Optuna](https:\/\/optuna.org).","de947d25":"# NFL Big Data Bowl 2020 (used to be Official) Starter Notebook\n## Introduction\nIn this competition you will predict how many yards a team will gain on a rushing play in an NFL regular season game.  You will loop through a series of rushing plays; for each play, you'll receive the position, velocity, orientation, and more for all 22 players on the field at the moment of handing the ball off to the rusher, along with many other features such as teams, stadium, weather conditions, etc.  You'll use this information to predict how many yards the team will gain on the play as a [cumulative probability distribution](https:\/\/en.wikipedia.org\/wiki\/Cumulative_distribution_function).  Once you make that prediction, you can move on to the next rushing play.\n\nThis competition is different from most Kaggle Competitions in that:\n* You can only submit from Kaggle Notebooks, and you may not use other data sources, GPU, or internet access.\n* This is a **two-stage competition**.  In Stage One you can edit your Notebooks and improve your model, where Public Leaderboard scores are based on your predictions on rushing plays from the first few weeks of the 2019 regular season.  At the beginning of Stage Two, your Notebooks are locked, and we will re-run your Notebooks over the following several weeks, scoring them based on their predictions relative to live data as the 2019 regular season unfolds.\n* You must use our custom **`kaggle.competitions.nflrush`** Python module.  The purpose of this module is to control the flow of information to ensure that you are not using future data to make predictions for the current rushing play.  If you do not use this module properly, your code may fail when it is re-run in Stage Two.\n\n## In this Starter Notebook, I will simply apply a lightGBM for this kind of a table data. "}}