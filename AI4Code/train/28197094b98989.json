{"cell_type":{"33b1a85d":"code","aa0b61b9":"code","d7917b8b":"code","4fe6c0cb":"code","1f2004ef":"code","6f88288c":"code","de5d7709":"code","0a657909":"code","8a7f58f0":"code","16a31a53":"code","2e2690b5":"code","88f4ead1":"code","99b64921":"code","170d1b5e":"code","b21b026e":"code","ea85d389":"code","74d74b09":"code","9531fe75":"code","4556da29":"code","d6d18106":"code","252ded75":"code","60d94e35":"code","a621b0cc":"code","3ff7b3c8":"code","604ff013":"code","5bd7c0ef":"code","7d77992c":"code","02aeebf6":"code","e428663d":"code","dbc6d5f6":"code","26cb3f50":"code","decb7596":"code","0ca27361":"code","9cd38ccc":"code","75e1a874":"code","a654f3d8":"code","5157608b":"code","dafeb195":"code","1fcc318c":"code","3e30cd2f":"code","16f6977e":"code","e9a6ef73":"code","c66789e4":"code","4c8502b1":"code","f6bb6968":"code","aee22b15":"code","322ee14d":"code","83e23fff":"code","83c6a2b4":"code","bc96255f":"code","0c23bed1":"code","bf8870d8":"code","4a6e0b33":"code","4afbed52":"markdown","b82ea1a5":"markdown","e2bf4dd3":"markdown","5afe7cab":"markdown","00de6320":"markdown","d7ff7cdd":"markdown","1c8002df":"markdown","42d7172f":"markdown","63f441a1":"markdown","b189b785":"markdown"},"source":{"33b1a85d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa0b61b9":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score,f1_score,classification_report,roc_curve,plot_roc_curve,auc,precision_recall_curve,plot_precision_recall_curve,average_precision_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom lightgbm import LGBMClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","d7917b8b":"df = pd.read_csv('..\/input\/churn-modelling\/Churn_Modelling.csv')","4fe6c0cb":"df.head()","1f2004ef":"df.info()","6f88288c":"df.describe()","de5d7709":"df.isnull().sum()","0a657909":"f, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(16,5))\n\nsns.heatmap(df.T.isna(), cmap='Blues')\nax.set_title('Missing Values')\n\nfor tick in ax.yaxis.get_major_ticks():\n    tick.label.set_fontsize(14)\nplt.show()","8a7f58f0":"# compute the correlation matrix\n\ncorr = df.corr()\n\n# generate a mask for the upper triangle\n\nmask = np.triu(np.ones_like(corr,dtype=bool))\n\n# set up matplotlib figure\nf, ax = plt.subplots(figsize=(11,9))\n\n#generate a custom diverging colormap\ncmap = sns.diverging_palette(230,20,as_cmap=True)\n\n#draw the heatpmap ith the mask and correct aspect ratio\nsns.heatmap(corr,mask=mask, cmap=cmap, vmax=.3,center=0,square=True,linewidths=.5,cbar_kws = {'shrink':.5})","16a31a53":"# Exited correlations\n\ncorr.sort_values(by=['Exited'],ascending=False).iloc[0].sort_values(ascending=False)","2e2690b5":"print(df.Gender.value_counts())\nsns.set_theme(style='darkgrid')\nax = sns.countplot(data=df, x='Gender')","88f4ead1":"print(df.Gender.value_counts())\nsns.set_theme(style='darkgrid')\nax = sns.countplot(data=df, x='Tenure')","99b64921":"print(df.NumOfProducts.value_counts())\nsns.set_theme(style='darkgrid')\nax = sns.countplot(data=df,x='NumOfProducts')","170d1b5e":"print(df.HasCrCard.value_counts())\nsns.set_theme(style='darkgrid')\nax = sns.countplot(data=df,x='HasCrCard')","b21b026e":"print(df.IsActiveMember.value_counts())\nsns.set_theme(style='darkgrid')\nax = sns.countplot(data=df,x='IsActiveMember')","ea85d389":"print(df.Exited.value_counts())\nsns.set_theme(style='darkgrid')\nax = sns.countplot(data=df,x='Exited')","74d74b09":"print(df.Geography.value_counts())\nsns.set_theme(style='darkgrid')\nax = sns.countplot(data=df,x='Geography')","9531fe75":"fig = plt.figure(figsize=(7,7))\nsns.displot(df.CreditScore, color='green',label='CreditScore', kde=True)\nplt.legend();","4556da29":"fig = plt.figure(figsize=(7,7))\nax = sns.displot(df.Age, color='blue',label='Age',kde='True')\nplt.legend();","d6d18106":"fig = plt.figure(figsize=(7,7))\nax = sns.displot(df.Balance, color='red', label='Balance',kde=True)\nplt.legend();","252ded75":"fig  = plt.figure(figsize=(7,7))\nax = sns.displot(df.EstimatedSalary,label='EstimatedSalary',color='green',kde=True)\nplt.legend();","60d94e35":"plt.figure(figsize=(13,13))\nsns.set_theme(style='darkgrid')\nplt.subplot(2,3,1)\nsns.violinplot(x='CreditScore',y='Exited',data=df)\nplt.subplot(2,3,2)\nsns.violinplot(x='Gender',y='Exited',data=df)\nplt.subplot(2,3,3)\nsns.violinplot(x='Age',y='Exited',data=df)\nplt.subplot(2,3,4)\nsns.violinplot(x='Tenure',y='Exited',data=df)\nplt.subplot(2,3,5)\nsns.violinplot(x='Balance',y='Exited',data=df)\nplt.subplot(2,3,6)\nsns.violinplot(x='NumOfProducts',y='Exited',data=df)\nplt.show()","a621b0cc":"df.head()","3ff7b3c8":"desc = df.describe().T\ndf1 = pd.DataFrame(index=['CreditScore', 'Age',\n                          'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', \n                           'EstimatedSalary', 'Exited'], \n                   columns= [\"count\",\"mean\",\"std\",\"min\",\n                             \"25%\",\"50%\",\"75%\",\"max\"], data= desc )\n\nf,ax = plt.subplots(figsize=(12,12))\n\nsns.heatmap(df1, annot=True,cmap = \"Blues\", fmt= '.0f',\n            ax=ax,linewidths = 5, cbar = False,\n            annot_kws={\"size\": 16})\n\nplt.xticks(size = 18)\nplt.yticks(size = 12, rotation = 0)\nplt.ylabel(\"Variables\")\nplt.title(\"Descriptive Statistics\", size = 16)\nplt.show()","604ff013":"df.drop(['CustomerId','Surname'],inplace=True,axis=1)","5bd7c0ef":"df.head()","7d77992c":"le = LabelEncoder()\ndf['Geography'] = le.fit_transform(df['Geography'])\ndf['Gender'] = le.fit_transform(df['Gender'])","02aeebf6":"df.head()","e428663d":"df['EstimatedSalaryBand'] = pd.cut(df['EstimatedSalary'], 5)\ndf[['EstimatedSalaryBand', 'Exited']].groupby(['EstimatedSalaryBand'], as_index=False).mean().sort_values(by='EstimatedSalaryBand', ascending=True)","dbc6d5f6":"df.head()","26cb3f50":"df.loc[df['EstimatedSalary'] <= 40007, 'EstimatedSalary'] = 0\ndf.loc[(df['EstimatedSalary'] > 40007) & (df['EstimatedSalary'] <= 80003), 'EstimatedSalary'] = 1\ndf.loc[(df['EstimatedSalary'] > 80003) & (df['EstimatedSalary'] <= 120000), 'EstimatedSalary'] = 2\ndf.loc[(df['EstimatedSalary'] > 120000) & (df['EstimatedSalary'] <= 159996), 'EstimatedSalary'] = 3\ndf.loc[df['EstimatedSalary'] > 159996, 'EstimatedSalary'] = 4\n\ndf.head()","decb7596":"df.EstimatedSalary.unique()","0ca27361":"df.drop('EstimatedSalaryBand',axis=1,inplace=True)","9cd38ccc":"df.head()","75e1a874":"df['BalanceBand'] = pd.cut(df['Balance'], 5)\ndf[['BalanceBand', 'Exited']].groupby(['BalanceBand'], as_index=False).mean().sort_values(by='BalanceBand', ascending=True)","a654f3d8":"df.head()","5157608b":"df.loc[df['Balance'] <= 0, 'Balance'] = 0\ndf.loc[(df['Balance'] > 0) & (df['Balance'] <= 251), 'Balance'] = 1\ndf.loc[(df['Balance'] > 251) & (df['Balance'] <= 50179), 'Balance'] = 2\ndf.loc[(df['Balance'] > 50179) & (df['Balance'] <= 100359), 'Balance'] = 3\ndf.loc[(df['Balance'] > 100359) & (df['Balance'] <= 150538), 'Balance'] = 4\ndf.loc[(df['Balance'] > 150538) & (df['Balance'] <= 200718), 'Balance'] = 5\ndf.loc[(df['Balance'] > 200718) & (df['Balance'] <= 250000), 'Balance'] = 6\ndf.head()","dafeb195":"df.drop(['BalanceBand'],axis=1,inplace=True)","1fcc318c":"df.head()","3e30cd2f":"df['CreditScoreBand'] = pd.cut(df['CreditScore'], 5)\ndf[['CreditScoreBand', 'Exited']].groupby(['CreditScoreBand'], as_index=False).mean().sort_values(by='CreditScoreBand', ascending=True)","16f6977e":"df.loc[df['CreditScore'] <= 450, 'CreditScore'] = 0\ndf.loc[(df['CreditScore'] > 450) & (df['CreditScore'] <= 550), 'CreditScore'] = 1\ndf.loc[(df['CreditScore'] > 550) & (df['CreditScore'] <= 650), 'CreditScore'] = 2\ndf.loc[(df['CreditScore'] > 650) & (df['CreditScore'] <= 750), 'CreditScore'] = 3\ndf.loc[(df['CreditScore'] > 750) & (df['CreditScore'] <= 850), 'CreditScore'] = 4\ndf.loc[(df['CreditScore'] > 850), 'CreditScore'] = 5","e9a6ef73":"df.drop('CreditScoreBand',axis=1,inplace=True)","c66789e4":"df.head()","4c8502b1":"X = df.drop('Exited',axis=1)\ny = df['Exited']","f6bb6968":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.33,random_state=42)","aee22b15":"print('DataFrame Shape:', df.shape)\nprint('*'*25)\nprint('X Train Shape:', X_train.shape)\nprint('*'*25)\nprint('X Test Shape:', X_test.shape)\nprint('*'*25)\nprint('Y Train Shape:', y_train.shape)\nprint('*'*25)\nprint('Y Test Shape:', y_test.shape)","322ee14d":"models = []\nmodels.append(['XGBClassifier',XGBClassifier(learning_rate=0.1,objective='binary:logistic',random_state=0,eval_metric='mlogloss')])\nmodels.append(['Logistic Regression',LogisticRegression(random_state=0)])\nmodels.append(['SVM',SVC(random_state=0)])\nmodels.append(['KNeigbors',KNeighborsClassifier()])\nmodels.append(['GaussianNB',GaussianNB()])\nmodels.append(['BernoulliNB',BernoulliNB()])\nmodels.append(['DecisionTree',DecisionTreeClassifier(random_state=0)])\nmodels.append(['RandomForest',RandomForestClassifier(random_state=0)])\nmodels.append(['AdaBoostClassifier',AdaBoostClassifier()])","83e23fff":"lst_1 = []\nfor m in range(len(models)):\n    lst_2 = []\n    model = models[m][1]\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    cm = confusion_matrix(y_test,y_pred)\n    accuracies = cross_val_score(estimator= model, X = X_train,y = y_train, cv=10)\n\n# k-fOLD Validation\n    roc = roc_auc_score(y_test,y_pred)\n    precision = precision_score(y_test,y_pred)\n    recall = recall_score(y_test,y_pred)\n    f1 = f1_score(y_test,y_pred)\n    print(models[m][0],':')\n    print(cm)\n    print('Accuracy Score: ',accuracy_score(y_test,y_pred))\n    print('')\n    print('K-Fold Validation Mean Accuracy: {:.2f} %'.format(accuracies.mean()*100))\n    print('')\n    print('Standard Deviation: {:.2f} %'.format(accuracies.std()*100))\n    print('')\n    print('ROC AUC Score: {:.2f} %'.format(roc))\n    print('')\n    print('Precision: {:.2f} %'.format(precision))\n    print('')\n    print('Recall: {:.2f} %'.format(recall))\n    print('')\n    print('F1 Score: {:.2f} %'.format(f1))\n    print('-'*40)\n    print('')\n    lst_2.append(models[m][0])\n    lst_2.append(accuracy_score(y_test,y_pred)*100)\n    lst_2.append(accuracies.mean()*100)\n    lst_2.append(accuracies.std()*100)\n    lst_2.append(roc)\n    lst_2.append(precision)\n    lst_2.append(recall)\n    lst_2.append(f1)\n    lst_1.append(lst_2)","83c6a2b4":"df2 = pd.DataFrame(lst_1,columns=['Model','Accuracy','K-Fold Mean Accuracy','Std.Deviation','ROC_AUC','Precision','Recall','F1 Score'])\n\ndf2.sort_values(by=['Accuracy','K-Fold Mean Accuracy'],inplace=True,ascending=False)\ndf2\n\n# COMPARE","bc96255f":"sns.barplot(x='Accuracy',y='Model',data=df2,color='b')\nplt.title('Model Compare Graphic');","0c23bed1":"grid_models = [(XGBClassifier(), [{'learning_rate': [0.01, 0.05, 0.1], 'eval_metric': ['error']}]),\n               (KNeighborsClassifier(),[{'n_neighbors':[5,7,8,10], 'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}]), \n               (DecisionTreeClassifier(),[{'criterion':['gini','entropy'],'random_state':[0]}]), \n               (RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'],'random_state':[0]}]),]","bf8870d8":"for i,j in grid_models:\n    grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'accuracy',cv = 10)\n    grid.fit(X_train,y_train)\n    best_accuracy = grid.best_score_\n    best_param = grid.best_params_\n    print(' {}: \\n Best Accuracy: {:.2f} %'.format(i,best_accuracy*100))\n    print('')\n    print('-'*25)\n    print('')","4a6e0b33":"classifier = XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,colsample_bynode=None, colsample_bytree=None, gamma=None,\n              gpu_id=None, importance_type='gain', interaction_constraints=None,\n              learning_rate=None, max_delta_step=None, max_depth=None,\n              min_child_weight=None,monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              random_state=None, reg_alpha=None, reg_lambda=None,\n              scale_pos_weight=None, subsample=None, tree_method=None,\n              validate_parameters=None, verbosity=None)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\ny_prob = classifier.predict_proba(X_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","4afbed52":"### 2.3 Distibution Plot","b82ea1a5":"### 2.2 CountPlot","e2bf4dd3":"## Data Preprocessing","5afe7cab":"### Data Describe","00de6320":"## Model Tuning","d7ff7cdd":"***Thank you for looking. Please provide your comments.***","1c8002df":"## Model Deployment","42d7172f":"## Data Visualization\n### 2.1 Corr Heat Map","63f441a1":"### Missing Values","b189b785":"### 2.4 Violin Plot"}}