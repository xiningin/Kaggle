{"cell_type":{"07fd287e":"code","c6201406":"code","e92cd7b6":"code","7c08c42f":"code","0e886a00":"code","5df6340d":"code","2e0629ae":"code","8bf4018b":"code","3e5df1c6":"code","31d0a6dd":"code","caf9fa35":"code","51f1c3c1":"code","dec1ad1f":"code","3cd97b79":"code","53f42a60":"code","bb8f175d":"code","027e3ad5":"code","7cbc7aed":"code","3a40f147":"code","0910f3de":"code","63bea078":"code","d114efb4":"code","c10c6173":"code","e618b1e4":"code","523ae1d8":"code","36f6a0d4":"code","75781d40":"code","cf700b8a":"code","8222dde4":"code","a9b426b7":"code","fbba668b":"code","1b62bf31":"code","94dbefd7":"code","2f22ac49":"code","3d4fb188":"code","2b57c8f1":"code","19eb5c2e":"code","6929fa92":"markdown","26e8d0eb":"markdown","1164ab1e":"markdown","de39d755":"markdown","31517a60":"markdown","d4f783bf":"markdown"},"source":{"07fd287e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c6201406":"#Importando as bibliotecas\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom  sklearn.model_selection import train_test_split  \n\nfrom sklearn.metrics import mean_squared_log_error\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport scikitplot as skplt \n\nfrom sklearn.model_selection import train_test_split","e92cd7b6":"#Importando a base de dados\n\nbase = pd.read_csv('\/kaggle\/input\/hmeq-data\/hmeq.csv')\n\nbase.head(10)","7c08c42f":"base.info()","0e886a00":"#Transformando REASON em Dummy\npd.get_dummies(base['REASON']).iloc[:4]","5df6340d":"#Transformando JOB em Dummy\npd.get_dummies(base['JOB']).iloc[:5]","2e0629ae":"base = pd.get_dummies(base, columns=['REASON', 'JOB'])","8bf4018b":"base.head().T","3e5df1c6":"#Confirmar a transforma\u00e7\u00e3o da vari\u00e1vel BAD\nbase.info()","31d0a6dd":"#An\u00e1lise estistica dos dados.\nbase[base['BAD']==0].drop('BAD', axis=1).describe().style.format(\"{:.2f}\")","caf9fa35":"#Correla\u00e7\u00e3o entre as vari\u00e1veis\nbase.corr()","51f1c3c1":"#Analise da variavel BAD\nsns.countplot(base['BAD'])","dec1ad1f":"# Histograma com a distribui\u00e7\u00e3o das vari\u00e1veis\nbase.hist()\nplt.show()","3cd97b79":"\nbase.iloc[:,[0]]","53f42a60":"#Retirar os valores nulos\n\nbase.dropna(inplace=True)","bb8f175d":"#Confirmando a retirada dos valores NaN\nbase.isnull().sum()","027e3ad5":"#Grafico das variaveis LOAN e BAD com a quantidade de emprestimos e os clientes inadimplente por empr\u00e9stimo e \n#emprestimos reembolsados, onde 0 = Cliente inadimplente por emprestimos | 1 = Empr\u00e9stimos reembolsados.\n\nplt.suptitle(\"Quantidade de emprestimos e tipos de emprestimos\")\nsns.stripplot(x='BAD', y='LOAN', data=base)","7cbc7aed":"# Definindo as features \nfeats = [c for c in base.columns if c not in ['LOAN', 'BAD']]\nfeats","3a40f147":"#Separando o dataframe \n\n#Importando o train_test_split\nfrom sklearn.model_selection import train_test_split\n\n#Primeiro treino e teste\ntrain, test = train_test_split(base, test_size=0.20, random_state=42)\n\n#Treino e valida\u00e7\u00e3o\ntrain, valid = train_test_split(train, test_size=0.20, random_state=42)\n\ntrain.shape, valid.shape, test.shape","0910f3de":"#Importando o RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Importando o modelo\nrf = RandomForestClassifier(n_estimators=200, random_state=42)","63bea078":"# Treinando o modelo\n\nrf.fit(train[feats], train['BAD'])","d114efb4":"#Primeiro treino e teste\ntrain, test = train_test_split(base, test_size=0.20, random_state=42)","c10c6173":"#Analisando o desempenho do modelo\n\n#Importando metricas\n\nfrom sklearn.metrics import accuracy_score","e618b1e4":"#Avaliando os dados de validacao\n\n#Obter as previs\u00f5es da base de valida\u00e7\u00e3o\npred = rf.predict(valid[feats])\n\n#Verificar acur\u00e1cia\naccuracy_score(valid['BAD'], pred)","523ae1d8":"#Avaliando os dados de teste\n\n# obter as previs\u00f5es dos dados de teste\npred_test = rf.predict(test[feats])\n\n#Verificar a acur\u00e1cia\naccuracy_score(test['BAD'], pred_test)","36f6a0d4":"# Olhar o dataFrame  completo\nbase['BAD'].value_counts(normalize=True)","75781d40":"base['BAD'].astype('category').cat.categories","cf700b8a":"# acessando os mapeamentos das categorias\nbase['BAD'].astype('category').cat.codes","8222dde4":"plt.figure(figsize=(10, 9))\n\n#Primeiro modelo criado\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","a9b426b7":"# matriz de confus\u00e3o\n#importar biblioteca de matriz de confus\u00e3o\n\nimport scikitplot as skplt ","fbba668b":"# Dados de valida\u00e7\u00e3o\n#comparar onde acertou ou n\u00e3o. Falsos positivos e falsos negativos\n\nskplt.metrics.plot_confusion_matrix(valid['BAD'], pred)","1b62bf31":"#Dados de teste | Matriz de confus\u00e3o\nskplt.metrics.plot_confusion_matrix(test['BAD'], pred_test)","94dbefd7":"# XGBoost\n\n# Importar o modelo\nfrom xgboost import XGBClassifier\n\n# Instanciar o modelo\nxgb = XGBClassifier(n_estimators=200, n_jobs=-1, random_state=42, learning_rate=0.05)","2f22ac49":"# Usando o cross validation\nscores = cross_val_score(xgb, train[feats], train['BAD'], n_jobs=-1, cv=5)\n\nscores, scores.mean()","3d4fb188":"# Usando o XGB para treinamento e predi\u00e7\u00e3o\nxgb.fit(train[feats], train['BAD'])","2b57c8f1":"# Fazendo predi\u00e7\u00f5es\npreds = xgb.predict(test[feats])","19eb5c2e":"# Medir o desempenho do modelo\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(test['BAD'], preds)","6929fa92":"Ap\u00f3s gerar a matriz de confus\u00e3o \u00e9 possivel identificar que o modelo classificou 638 instancias que foram previstas corretamente. \nPossivelmente devido a retirada dos valores missing.","26e8d0eb":"No gr\u00e1fico \u00e9 possivel identifica que 0 = empr\u00e9stimo reembolsado \u00e9 maior que os valores para 1 = cliente inadimplente no empr\u00e9stimo.","1164ab1e":"Ap\u00f3s gerar a matriz de confus\u00e3o \u00e9 possivel identificar que o modelo classificou 511 instancias que foram previstas corretamente. Possivelmente devido a retirada dos valores missing.","de39d755":"****INTRODU\u00c7\u00c3O****\n\n\n\nNo presente estudo, utilizamos a base HMEQ_Data, encontrada na plataforma Kaggle. \nA base traz dados sobre o departamento de cr\u00e9dito ao consumidor de um banco e foram usadas para auxiliar a decis\u00e3o da aprova\u00e7\u00e3o das linhas de cr\u00e9dito a partir de dados estatisticos.\n\nA vari\u00e1vel BAD foi utilizada como Target(alvo) e traz as informa\u00e7\u00f5es divididas em \"Dummies\" com os valores 1 = cliente inadimplente no empr\u00e9stimo e 0 = empr\u00e9stimo reembolsado.\n\nRealizado an\u00e1lise explorat\u00f3ria dos dados e aplicado modelo de predi\u00e7\u00e3o e tecnicas para melhorias dos parametros de estimativa. ","31517a60":"\n # *Data Mining e Machine Learning II*\n\n\n*Institui\u00e7\u00e3o:* Centro Universit\u00e1rio IESB\n\n*Curso:* P\u00f3s Gradua\u00e7\u00e3o Ci\u00eancia de Dados - Campus BSB\/Asa Sul\n\n*Disciplina:* Data Mining e Machine Learning II\n\n*Orientador:* Marcos Vinicius Guimar\u00e3es\n\n*Aluna:* Adriana Maria Santos Viana\n","d4f783bf":"Ap\u00f3s execu\u00e7\u00e3o dos dois modelos, o melhor modelo foi o XGBoost pois apresentou 0.94.\n"}}