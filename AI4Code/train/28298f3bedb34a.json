{"cell_type":{"cfe27ef7":"code","57841918":"code","066d2fb8":"code","eb9ef170":"code","c6d13bc0":"code","38da41f5":"code","6138dd2e":"code","3769de9f":"code","c04c9cd8":"markdown","efb9af1d":"markdown","fdc13e72":"markdown","985cb5e2":"markdown","66ef7290":"markdown","af69d120":"markdown"},"source":{"cfe27ef7":"# Import all necessary\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2 as cv\nimport re\nimport requests\n\nfrom sklearn.metrics import confusion_matrix,  multilabel_confusion_matrix\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\nfrom keras.layers import BatchNormalization, Activation, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint","57841918":"# Lists to store images data and labels\nX = []\nY = []\n\n# Input shape for ANN and also to resize images \ninput_shape = (96, 96, 3)\n\n# Merge train and test data into one dataset\n# Loop through train and test subsets\nfor subset in ('train', 'test'):\n    path_to_subset = f'..\/input\/apparel-images-dataset\/{subset}'\n    \n    # Loop through all classes in subset\n    for folder in os.listdir(path_to_subset):\n        \n        # Loop through all images in each class\n        for image in os.listdir(os.path.join(path_to_subset, folder)):\n            # Defining path to image\n            path_to_image = os.path.join(path_to_subset, folder, image)\n            # Reading image using cv2\n            image = cv.imread(path_to_image)\n            # Resizing image\n            image = cv.resize(image, (input_shape[1], input_shape[0]))\n            # Extracting labels from 'path_to_image' using regex\n            label = re.findall(r'\\w+\\_\\w+', path_to_image)[0].split('_')\n            \n            # Appending data and labels to X and Y lists\n            X.append(image)\n            Y.append(label)\n\n# Convert X to numpy array and scale values between 0 and 1\nX = np.array(X) \/ 255.0\nY = np.array(Y)\n\n# Binarize labels\nmlb = MultiLabelBinarizer()\nY = mlb.fit_transform(Y)","066d2fb8":"# mlb classes and example of binarized label\nprint(mlb.classes_)\nprint(Y[0])","eb9ef170":"# test_x and test_y will be used for final predictions\nx, test_x, y, test_y = train_test_split(X, Y, test_size = 0.1, stratify = Y, shuffle = True, random_state = 1)\n# train_x, val_x, train_y, val_y will be used to train model and validate results during training\ntrain_x, val_x, train_y, val_y = train_test_split(x, y, test_size = 0.2, stratify = y, shuffle = True, random_state = 1)\n\nprint(x.shape, test_x.shape, y.shape, test_y.shape)\nprint(train_x.shape, val_x.shape, train_y.shape, val_y.shape)\n\n# I'll use ImageDataGenerator to apply random transformations to images\ndatagen = ImageDataGenerator(rotation_range = 45,\n                            width_shift_range = 0.1,\n                            height_shift_range = 0.1,\n                            zoom_range = 0.2,\n                            horizontal_flip = True,\n                            validation_split = 0.2)","c6d13bc0":"# Creating model architecture\nmodel = Sequential()\n\nmodel.add(Conv2D(32, 3, padding = 'same', input_shape = input_shape, kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(3))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, 2, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation = 'relu', kernel_initializer = 'he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# model.summary()\n\n# use a *softmax* activation for single-label classification\n# and *sigmoid* activation for multi-label classification\nmodel.add(Dense(len(mlb.classes_), activation = 'sigmoid'))\n\n# Checkpoint to save best model\ncheckpoint = ModelCheckpoint('..\/working\/best_model.hdf5', save_best_only = True, monitor = 'val_loss', verbose = 1)\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nhistory = model.fit_generator(datagen.flow(train_x, train_y, batch_size = 64),\n                             validation_data = (val_x, val_y), epochs = 100, verbose = 1, callbacks = [checkpoint])","38da41f5":"# Plot training results\nH = history.history\nfig = plt.figure(figsize = (20, 7))\nplt.subplot(121)\nplt.plot(H['accuracy'], label = 'acc')\nplt.plot(H['val_accuracy'], label = 'val_acc')\nplt.grid()\nplt.legend()\n\nplt.subplot(122)\nplt.plot(H['loss'], label = 'loss')\nplt.plot(H['val_loss'], label = 'val_loss')\nplt.grid()\nplt.legend()","6138dd2e":"# Loading best weights\nmodel.load_weights('..\/working\/best_model.hdf5')\n# Save model for later usage\nmodel.save('..\/working\/model.hdf5')\n\n# Predicting test images\npreds = model.predict(test_x)\npreds = np.where(preds < 0.5, 0, 1)\n\n# Creating multilabel confusion matrix\nconfusion = multilabel_confusion_matrix(test_y, preds)\n\n# Plot confusion matrix \nfig = plt.figure(figsize = (14, 8))\nfor i, (label, matrix) in enumerate(zip(mlb.classes_, confusion)):\n    plt.subplot(f'23{i+1}')\n    labels = [f'not_{label}', label]\n    sns.heatmap(matrix, annot = True, square = True, fmt = 'd', cbar = False, cmap = 'Blues', \n                xticklabels = labels, yticklabels = labels, linecolor = 'black', linewidth = 1)\n    plt.title(labels[0])\n\nplt.tight_layout()\nplt.show()","3769de9f":"# URLs to images\nurls = [\n    'http:\/\/picture-cdn.wheretoget.it\/e07ql5-l-610x610-dress-little+black+dress-skater+dress-nastygal-deep+vneck-short-formal-short+formal+dress-prom-short+prom+dress-black-lbd-short+black+dress-prom+dress-black+dress-blackdress-short+.jpg',\n    'https:\/\/img.simplydresses.com\/_img\/SDPRODUCTS\/2103981\/500\/navy-dress-JU-TI-T0468-a.jpg',\n    'https:\/\/d2euz5hho4dp59.cloudfront.net\/images\/detailed\/40\/main_jean_419.jpg',\n    'https:\/\/sc02.alicdn.com\/kf\/HTB1QbZ_dzgy_uJjSZJnq6zuOXXaq\/Wholesale-scratch-pants-damaged-denim-women-s.jpg_350x350.jpg',\n    'https:\/\/i.ebayimg.com\/00\/s\/NjAwWDYwMA==\/z\/pakAAOSwVtta6SN8\/$_1.JPG?set_id=880000500F',\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcSFA1Q-O44dQWt1lvsnOQyoMcQ3myaxY-GscMHgmPtmyWT14ZJU',\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTJYyBOAy35RM7m0JzNGHo_-VTSf6bPMh9hACbhhqxsdoMXHQvD',\n    'https:\/\/cdn.shopify.com\/s\/files\/1\/1359\/6121\/products\/7481209_LF0A0919_1024x1024.jpg?v=1511982241',     \n]\n\nfig = plt.figure(figsize = (15, 15))\n\nfor i, url in enumerate(urls):\n    plt.subplot(f'33{i+1}')\n    \n    # Sending request to the URL\n    r = requests.get(url, stream = True).raw\n    \n    # Reading image, convert it to np array and decode\n    image = np.asarray(bytearray(r.read()), dtype=\"uint8\")\n    image = cv.imdecode(image, cv.IMREAD_COLOR)\n    \n    # Resize, scale and reshape image before making predictions\n    resized = cv.resize(image, (input_shape[1], input_shape[0]))\n    resized = (resized \/ 255.0).reshape(-1, input_shape[1], input_shape[0], input_shape[2])\n    \n    # Predict results\n    preds = model.predict(resized)\n    preds = zip(list(mlb.classes_), list(preds[0]))\n    preds = sorted(list(preds), key = lambda z: z[1], reverse = True)[:2]\n    \n    # Showing image\n    plt.imshow(image[:, :, ::-1])\n    plt.title(f'{preds[0][0]}: {round(preds[0][1] * 100, 2)}% \\n {preds[1][0]}: {round(preds[1][1] * 100, 2)}%')    \n        \nplt.tight_layout()   \n                        ","c04c9cd8":"# Creating train and test datasets\nThe dataset already divided  to train and test dataset, but in that case it will be easier to load all data in one array and then split it to train, validation and test datasets.","efb9af1d":"# Predicting random google search images","fdc13e72":"# Goal\nThis is experimental kernel in which I wanted to get some practice with multi-label classification.\n\nWe have 6 classes ['black' 'blue' 'dress' 'jeans' 'shirt' 'shorts'] and these classes grouped by 8 subclasses:\n\n- 'blue_dress',\n- 'black_shorts',\n- 'blue_jeans',\n- 'black_shirt',\n- 'black_dress',\n- 'blue_shorts',\n- 'black_jeans',\n- 'blue_shirt'\n\nI want to train model that can classify these subclasses.","985cb5e2":"# Model creation and training","66ef7290":"# Results","af69d120":"# Predicting test dataset images"}}