{"cell_type":{"7ea22753":"code","63769bc3":"code","7a46da56":"code","0882826c":"code","bf98e73e":"code","486a4ba8":"code","4f7b6015":"code","a5204305":"code","d44d6c24":"code","6aceab57":"code","20df63dc":"code","0276e398":"code","5a061fce":"code","20d96b1f":"code","73d323ae":"code","985ad5c2":"code","fdffcd9a":"code","55c49b66":"code","bd58621f":"code","4b772ebc":"code","1106e04d":"code","528906fe":"code","cd395b6a":"code","38b75777":"code","5a1bf2a0":"markdown","faaa5c30":"markdown","a1dc92ff":"markdown","601d3bed":"markdown"},"source":{"7ea22753":"DATASET_DIR = '..\/input\/severstal-steel-defect-detection\/'\nTEST_SIZE = 0.3\nRANDOM_STATE = 123\n\nNUM_TRAIN_SAMPLES = 20 # The number of train samples used for visualization\nNUM_VAL_SAMPLES = 20 # The number of val samples used for visualization\nCOLORS = ['b', 'g', 'r', 'm'] # Color of each class","63769bc3":"import pandas as pd\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom matplotlib.collections import PatchCollection\n\nfrom shutil import copyfile\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, iplot\nfrom plotly import subplots\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.graph_objs import *\nfrom plotly.graph_objs.layout import Margin, YAxis, XAxis","7a46da56":"df = pd.read_csv(os.path.join(DATASET_DIR, 'train.csv'))","0882826c":"df.head()","bf98e73e":"legacy_df = pd.DataFrame(columns=['ImageId_ClassId', 'EncodedPixels'])\n\nfor img_id, img_df in tqdm_notebook(df.groupby('ImageId')):\n    for i in range(1, 5):\n        avail_classes = list(img_df.ClassId)\n\n        row = dict()\n        row['ImageId_ClassId'] = img_id + '_' + str(i)\n\n        if i in avail_classes:\n            row['EncodedPixels'] = img_df.loc[img_df.ClassId == i].EncodedPixels.iloc[0]\n        else:\n            row['EncodedPixels'] = np.nan\n        \n        legacy_df = legacy_df.append(row, ignore_index=True)","486a4ba8":"legacy_df.head()","4f7b6015":"df = legacy_df","a5204305":"df['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['HavingDefection'] = df['EncodedPixels'].map(lambda x: 0 if x is np.nan else 1)\n\nimage_col = np.array(df['Image'])\nimage_files = image_col[::4]\nall_labels = np.array(df['HavingDefection']).reshape(-1, 4)","d44d6c24":"num_img_class_1 = np.sum(all_labels[:, 0])\nnum_img_class_2 = np.sum(all_labels[:, 1])\nnum_img_class_3 = np.sum(all_labels[:, 2])\nnum_img_class_4 = np.sum(all_labels[:, 3])\nprint('Class 1: {} images'.format(num_img_class_1))\nprint('Class 2: {} images'.format(num_img_class_2))\nprint('Class 3: {} images'.format(num_img_class_3))\nprint('Class 4: {} images'.format(num_img_class_4))","6aceab57":"def plot_figures(\n    sizes,\n    pie_title,\n    start_angle,\n    bar_title,\n    bar_ylabel,\n    labels=('Class 1', 'Class 2', 'Class 3', 'Class 4'),\n    colors=None,\n    explode=(0, 0, 0, 0.1),\n):\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\n    y_pos = np.arange(len(labels))\n    barlist = axes[0].bar(y_pos, sizes, align='center')\n    axes[0].set_xticks(y_pos, labels)\n    axes[0].set_ylabel(bar_ylabel)\n    axes[0].set_title(bar_title)\n    if colors is not None:\n        for idx, item in enumerate(barlist):\n            item.set_color(colors[idx])\n\n    def autolabel(rects):\n        \"\"\"\n        Attach a text label above each bar displaying its height\n        \"\"\"\n        for rect in rects:\n            height = rect.get_height()\n            axes[0].text(\n                rect.get_x() + rect.get_width()\/2., height,\n                '%d' % int(height),\n                ha='center', va='bottom', fontweight='bold'\n            )\n\n    autolabel(barlist)\n    \n    pielist = axes[1].pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=start_angle, counterclock=False)\n    axes[1].axis('equal')\n    axes[1].set_title(pie_title)\n    if colors is not None:\n        for idx, item in enumerate(pielist[0]):\n            item.set_color(colors[idx])\n\n    plt.show()","20df63dc":"print('[THE WHOLE DATASET]')\n\nsum_each_class = np.sum(all_labels, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\nsum_each_sample = np.sum(all_labels, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","0276e398":"X_train, X_val, y_train, y_val = train_test_split(image_files, all_labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)","5a061fce":"print('X_train:', X_train.shape)\nprint('y_train:', y_train.shape)\nprint('X_val:', X_val.shape)\nprint('y_val:', y_val.shape)","20d96b1f":"print('[TRAINING SET]')\n\nsum_each_class = np.sum(y_train, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\n\nsum_each_sample = np.sum(y_train, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","73d323ae":"print('[VALIDATION SET]')\n\nsum_each_class = np.sum(y_val, axis=0)\nplot_figures(\n    sum_each_class,\n    pie_title='The percentage of each class',\n    start_angle=90,\n    bar_title='The number of images for each class',\n    bar_ylabel='Images',\n    colors=COLORS,\n    explode=(0, 0, 0, 0.1)\n)\n\n\nsum_each_sample = np.sum(y_val, axis=1)\nunique, counts = np.unique(sum_each_sample, return_counts=True)\n\nplot_figures(\n    counts,\n    pie_title='The percentage of the number of classes appears in an image',\n    start_angle=120,\n    bar_title='The number of classes appears in an image',\n    bar_ylabel='Images',\n    labels=[' '.join((str(label), 'class(es)')) for label in unique],\n    explode=np.zeros(len(unique))\n)","985ad5c2":"def rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","fdffcd9a":"def show_samples(samples):\n    for sample in samples:\n        fig, ax = plt.subplots(figsize=(15, 10))\n        img_path = os.path.join(DATASET_DIR, 'train_images', sample[0])\n        img = cv2.imread(img_path)\n\n        # Get annotations\n        labels = df[df['ImageId_ClassId'].str.contains(sample[0])]['EncodedPixels']\n\n        patches = []\n        for idx, rle in enumerate(labels.values):\n            if rle is not np.nan:\n                mask = rle2mask(rle)\n                contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n                for contour in contours:\n                    poly_patch = Polygon(contour.reshape(-1, 2), closed=True, linewidth=1, edgecolor=COLORS[idx], fill=False)\n                    patches.append(poly_patch)\n        p = PatchCollection(patches, match_original=True, cmap=matplotlib.cm.jet)\n\n        ax.imshow(img\/255)\n        ax.set_title('{} - ({})'.format(sample[0], ', '.join(sample[1].astype(np.str))))\n        ax.add_collection(p)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        plt.show()","55c49b66":"train_pairs = np.array(list(zip(X_train, y_train)))\ntrain_samples = train_pairs[np.random.choice(train_pairs.shape[0], NUM_TRAIN_SAMPLES, replace=False), :]\n\nshow_samples(train_samples)","bd58621f":"val_pairs = np.array(list(zip(X_val, y_val)))\nval_samples = val_pairs[np.random.choice(val_pairs.shape[0], NUM_VAL_SAMPLES, replace=False), :]\n\nshow_samples(val_samples)","4b772ebc":"df_train=legacy_df\ndel df_train['Image']\ndel df_train['HavingDefection']\ntrain_df = df.fillna(-1)\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['ClassId_EncodedPixels'] = train_df.apply(lambda row: (row['ClassId'], row['EncodedPixels']), axis = 1)\ngrouped_EncodedPixels = train_df.groupby('ImageId')['ClassId_EncodedPixels'].apply(list)\ndef rle_to_mask(rle_string, height, width):  \n    rows, cols = height, width\n    if rle_string == -1:\n        return np.zeros((height, width))\n    else:\n        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n        img = np.zeros(rows*cols, dtype=np.uint8)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n        return img","1106e04d":"# calculate sum of the pixels for the mask per class id\ntrain_df['mask_pixel_sum'] = train_df.apply(lambda x: rle_to_mask(x['EncodedPixels'], width=1600, height=256).sum(), axis=1)","528906fe":"class_ids = ['1','2','3','4']\nmask_count_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0)]['mask_pixel_sum'].count() for class_id in class_ids]\npixel_sum_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0)]['mask_pixel_sum'].sum() for class_id in class_ids]","cd395b6a":"# Create subplots: use 'domain' type for Pie subplot\nfig = subplots.make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(Pie(labels=class_ids, values=mask_count_per_class, name=\"Mask Count\"), 1, 1)\nfig.add_trace(Pie(labels=class_ids, values=pixel_sum_per_class, name=\"Pixel Count\"), 1, 2)\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Steel Defect Mask & Pixel Count\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Mask', x=0.18, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Pixel', x=0.80, y=0.5, font_size=20, showarrow=False)])\nfig.show()","38b75777":"# plot a histogram and boxplot combined of the mask pixel sum per class Id\nfig = px.histogram(train_df[train_df['mask_pixel_sum']!=0][['ClassId','mask_pixel_sum']], \n                   x=\"mask_pixel_sum\", y=\"ClassId\", color=\"ClassId\", marginal=\"box\")\n\nfig['layout'].update(title='Histogram and Boxplot of Sum of Mask Pixels Per Class')\n\nfig.show()","5a1bf2a0":"##### Convert training data-frame to the legacy version","faaa5c30":"#### Observations\n\n* From the box plot we can reconfirm our previous observation of class 4 are generally larger in size than class 3, and of course class 1 and 2.\n* Defect class 3 has a lot of outliers. Even though class 4 is generally bigger in size, the outlier values in class 3 can be a lot larger than the ones in class 4!","a1dc92ff":"##### Continue the preprocessing process","601d3bed":"#### Observations\n\n* Obviously we have a lot of samples from class 3 and dataset is highly imbalanced. Almost 73% of the all defects are of class 3. \n* Although class 4 defect are 11.3% of the all defect, if you consider from the total area of defect perspective, they have almost 17% of real-estate. This means that typically defect of class 4 are larger in size.\n* As defect size for 2 is very small, and class 1 is very very small. Class 1 and 2 represents 12.6% and 3.48% of the total defects respectively. However, in terms of pixel count of the defect mask, they only make up 2.39% and 0.51% of the total mask respectively. In terms of sample and specially in terms of area, \n* *Our network may have a hard time finding class 1 and 2 two because of their small size*."}}