{"cell_type":{"43a4d5fa":"code","4e033380":"code","76006493":"code","42e30842":"code","543b6367":"code","6beadfad":"code","10fba1c5":"code","c8e3b5be":"code","c21adc93":"code","94fc8a79":"code","eeef4aba":"code","8e369173":"code","78ff9936":"code","a3e71e3e":"code","b0863d88":"code","39491e9b":"code","b880a0e5":"code","356553e8":"code","da74fa2f":"code","4c1604b3":"code","84001c53":"code","a006d60d":"markdown","4fdbac0b":"markdown","f7be9635":"markdown","adcb29b5":"markdown","cba6d470":"markdown","71e312a5":"markdown","6b679a8f":"markdown","0b4c6d08":"markdown","d80512de":"markdown","73e321e1":"markdown","265d66d2":"markdown","ae388493":"markdown","56a60673":"markdown","9a518def":"markdown"},"source":{"43a4d5fa":"!pip install alibi","4e033380":"import tensorflow as tf\ntf.get_logger().setLevel(40) \ntf.compat.v1.disable_v2_behavior() \nimport tensorflow.keras as keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Input, UpSampling2D\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import to_categorical\n\nimport matplotlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom alibi.explainers import CEM\n\nprint('TF version: ', tf.__version__)\nprint('Eager execution enabled: ', tf.executing_eagerly()) ","76006493":"(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\nprint('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)\nplt.gray()\nplt.imshow(x_test[4]);","42e30842":"x_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255\nx_train = np.reshape(x_train, x_train.shape + (1,))\nx_test = np.reshape(x_test, x_test.shape + (1,))\nprint('x_train shape:', x_train.shape, 'x_test shape:', x_test.shape)\ny_train = to_categorical(y_train) #one-hot encoding using to_categorical\ny_test = to_categorical(y_test)\nprint('y_train shape:', y_train.shape, 'y_test shape:', y_test.shape)","543b6367":"xmin, xmax = -.5, .5\nx_train = ((x_train - x_train.min()) \/ (x_train.max() - x_train.min())) * (xmax - xmin) + xmin\nx_test = ((x_test - x_test.min()) \/ (x_test.max() - x_test.min())) * (xmax - xmin) + xmin","6beadfad":"def cnn_model():\n    x_in = Input(shape=(28, 28, 1))\n    x = Conv2D(filters=64, kernel_size=2, padding='same', activation='relu')(x_in)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(0.3)(x)\n\n    x = Conv2D(filters=32, kernel_size=2, padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(0.3)(x)\n\n    x = Conv2D(filters=32, kernel_size=2, padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(0.3)(x)\n\n    x = Flatten()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x_out = Dense(10, activation='softmax')(x)\n\n    cnn = Model(inputs=x_in, outputs=x_out)\n    cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    return cnn","10fba1c5":"cnn = cnn_model()\ncnn.summary()\ncnn.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1)\ncnn.save('mnist_cnn.h5', save_format='h5')","c8e3b5be":"cnn = load_model('mnist_cnn.h5')\nscore = cnn.evaluate(x_test, y_test, verbose=0)\nprint('Test accuracy: ', score[1])","c21adc93":"def ae_model():\n    x_in = Input(shape=(28, 28, 1))\n    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x_in)\n    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    encoded = Conv2D(1, (3, 3), activation=None, padding='same')(x)\n\n    x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n    decoded = Conv2D(1, (3, 3), activation=None, padding='same')(x)\n\n    autoencoder = Model(x_in, decoded)\n    autoencoder.compile(optimizer='adam', loss='mse')\n\n    return autoencoder","94fc8a79":"ae = ae_model()\nae.summary()\nae.fit(x_train, x_train, batch_size=128, epochs=4, validation_data=(x_test, x_test), verbose=0)\nae.save('mnist_ae.h5', save_format='h5')","eeef4aba":"ae = load_model('mnist_ae.h5')\n\ndecoded_imgs = ae.predict(x_test)\nn = 5\nplt.figure(figsize=(20, 4))\nfor i in range(1, n+1):\n    # display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test[i].reshape(28, 28))\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    # display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","8e369173":"idx = 15\nX = x_test[idx].reshape((1,) + x_test[idx].shape) #(1,28,28,1)","78ff9936":"plt.imshow(X.reshape(28, 28));","a3e71e3e":"cnn.predict(X).argmax(), cnn.predict(X).max()","b0863d88":"mode = 'PN'  \nshape = (1,) + x_train.shape[1:]  \nkappa = 0. \nbeta = .1 \ngamma = 100  \nc_init = 1.  \n              \nc_steps = 10 \nmax_iterations = 1000  \nfeature_range = (x_train.min(),x_train.max())  \nclip = (-1000.,1000.)  \nlr = 1e-2  \nno_info_val = -1. ","39491e9b":"cem = CEM(cnn, mode, shape, kappa=kappa, beta=beta, feature_range=feature_range,\n          gamma=gamma, ae_model=ae, max_iterations=max_iterations,\n          c_init=c_init, c_steps=c_steps, learning_rate_init=lr, clip=clip, no_info_val=no_info_val)\n\nexplanation = cem.explain(X)","b880a0e5":"print('Pertinent negative prediction: {}'.format(explanation.PN_pred))\nplt.imshow(explanation.PN.reshape(28, 28))","356553e8":"mode = 'PP'","da74fa2f":"cem = CEM(cnn, mode, shape, kappa=kappa, beta=beta, feature_range=feature_range,\n          gamma=gamma, ae_model=ae, max_iterations=max_iterations,\n          c_init=c_init, c_steps=c_steps, learning_rate_init=lr, clip=clip, no_info_val=no_info_val)\n\nexplanation = cem.explain(X)","4c1604b3":"print('Pertinent positive prediction: {}'.format(explanation.PP_pred))\nplt.imshow(explanation.PP.reshape(28, 28));","84001c53":"os.remove('mnist_cnn.h5')\nos.remove('mnist_ae.h5')","a006d60d":"The first row depicts the original images while the second shows the decoded ones.","4fdbac0b":"## Contrastive Explaination with pertinent positive:\n\nPertinent positives (PP) are feature values obtained by changing the value of each feature towards its median such that the model prediction remains the same.","f7be9635":"Since this is a local explanation, we have considered a particular instance - index 15.","adcb29b5":"INTERPRETATION -\n\nFor a PP, the model prediction remains the same and thus it is 5 same as the original prediction.\n\nThe above image highlight the important pixels (which look like a 5) that should be present for it to be classified as a 5. In other words, these pixels should be minimally and necessarily present for the model prediction to be 5.","cba6d470":"Loading the MNIST data:","71e312a5":"Prepare data: scale, reshape and categorize","6b679a8f":"Now, training our CNN Model:","0b4c6d08":"### Application of such explanations in healthcare-\n\nA patient showing symptoms of fever, cough and cold but no chills will most likely be diagnosed as having flu rather than pneumonia. The presence of fever, cough and cold could indicate both flu or pneumonia. However, the absence of sputum or chills confirms the diagnosis of flu. ","d80512de":"## Contrastive Explaination with pertinent negative:\n\nPertinent negatives (PN) are changed feature values found by changing the value of each feature away from its median such that the model prediction changes.","73e321e1":"INTERPRETATION -\n\nThe pixels with values close to 1 define the number in the image while the background pixels have value 0. We assume that perturbations towards the background value 0 are equivalent to removing features, while perturbations towards 1 imply adding features. Adding features to get a PN means changing 0\u2019s into 1\u2019s until a different number is formed, in this case changing a 5 into an 8. \n\nThe pertinent negative prediction is 8. This means that on presence of some pixels(that are pertinent negative) , that should be absent, the prediction moves from 5 to 8(8 is close to and similar to 5).\n\nThe above image shows some PN pixels that should necessarily be absent from the image for model prediction to retain the prediction and not change to 8. ","265d66d2":"(Optional) An auto-encoder can be trained to reconstruct instances of the training set so that there is an L2 reconstruction error of the perturbed instance as an additional loss term. As a result, the perturbed instance lies close to the training data.","ae388493":"CEM parameters:\n\n*   mode : 'PN' (Pertinent Negative) or 'PP' (Pertinent Positive)\n*   shape : Shape of the current instance. As CEM is applicable for single explanations, we take 1 as the batch dimension which is added to the shape of data.\n*   kappa, beta, gamma, c_init, c_steps are all mathematical terms for calculating loss\n*   max_iterations : the total no. of loss optimization steps for each value of c\n*   feature_range : global or feature wise minimum and maximum values for the changed instance\n*   clip : minimum and maximum gradient values\n*   lr_init : initial learning rate \n\n","56a60673":"Training our Auto-encoder:","9a518def":"# CEM (Contrastive Explanation Method) on MNIST dataset :\n\nCEM generates local black box explanations for classification models in terms of Pertinent Positives (PP) and Pertinent Negatives (PN).  For a PP, the method finds the necessary features that should be present to predict the same class as on the original instance. For, PN identifies what features should be necessarily absent from the instance to be explained in order to maintain the original prediction class. "}}