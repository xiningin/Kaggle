{"cell_type":{"50a6e681":"code","5aecd134":"code","dff70653":"code","4b1521d9":"code","e6abd854":"code","4671c07d":"code","b5487221":"code","d6477716":"code","addf8dea":"code","67e1d319":"code","40a2833e":"code","f0dbd210":"code","90838a4e":"code","1afa8b48":"markdown","fe4139a3":"markdown","895582d6":"markdown","94c7ed67":"markdown","9bd7d569":"markdown","745119d8":"markdown","40b6bdfc":"markdown","ffbb3986":"markdown"},"source":{"50a6e681":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms, datasets\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm","5aecd134":"num_channels = 3\nlatent_size = 100\nbase_size, image_size, batch_size = 64, 64, 64\ntorch.cuda.set_device(\"cuda:0\")","dff70653":"transform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.CenterCrop(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # makes value in between [-1, 1]\n])\n\ndataset = datasets.ImageFolder('\/kaggle\/input\/', transform=transform)\nloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)","4b1521d9":"real_batch = next(iter(loader))\nplt.figure(figsize=(8, 8))\nplt.axis(\"off\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0][:32], padding=2, normalize=True).cpu(),(1,2,0)))","e6abd854":"class Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n\n    \nclass UnFlatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), 128, image_size\/\/4, image_size\/\/4)\n\ndef discriminator_block(in_filters, out_filters, bn=True):\n            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n                     nn.LeakyReLU(0.2, inplace=True),\n                     nn.Dropout2d(0.25)\n                    ]\n            if bn:\n                block.append(nn.BatchNorm2d(out_filters, 0.8))\n            return block","4671c07d":"G = nn.Sequential(\n    nn.Linear(100, 128 * (image_size\/\/4) ** 2),\n    UnFlatten(),\n    nn.BatchNorm2d(128),\n    nn.Upsample(scale_factor=2),\n    nn.Conv2d(128, 128, 3, stride=1, padding=1),\n    nn.BatchNorm2d(128, 0.8),\n    nn.LeakyReLU(0.2, inplace=True),\n    nn.Upsample(scale_factor=2),\n    nn.Conv2d(128, 64, 3, stride=1, padding=1),\n    nn.BatchNorm2d(64, 0.8),\n    nn.LeakyReLU(0.2, inplace=True),\n    nn.Conv2d(64, num_channels, 3, stride=1, padding=1),\n    nn.Tanh(),\n)","b5487221":"D = nn.Sequential(\n    *discriminator_block(num_channels, 16, bn=False),\n    *discriminator_block(16, 32),\n    *discriminator_block(32, 64),\n    *discriminator_block(64, 128),\n    Flatten(),\n    nn.Linear(128 * (image_size\/\/2**4) ** 2, 1), \n    nn.Sigmoid()\n)","d6477716":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n\n\n# recursively apply weights initialization on every submodule\nG.apply(weights_init)\nD.apply(weights_init)","addf8dea":"def draw_my_picture():\n    Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_size))))\n    img = G(z).cpu().data[0]\n    img = img.view((num_channels, image_size, image_size)).transpose(0, 1).transpose(1, 2).cpu().numpy()\n    plt.axis('off')\n    plt.imshow(img.reshape(image_size, image_size, num_channels))\n    plt.show()","67e1d319":"try:\n    D.load_state_dict(torch.load('D.pth'))\n    G.load_state_dict(torch.load('G.pth'))\nexcept:\n    print(\"Weights not found ):\")","40a2833e":"cuda = True if torch.cuda.is_available() else False\nadversarial_loss = torch.nn.BCELoss()\nif cuda:\n    G.cuda()\n    D.cuda()\n    adversarial_loss.cuda()\n    Tensor = torch.cuda.FloatTensor\nelse:\n    Tensor = torch.FloatTensor","f0dbd210":"num_epochs = 30\nlearning_rate = 1e-3\n\noptim_G = torch.optim.Adam(G.parameters(), lr=learning_rate)\noptim_D = torch.optim.Adam(D.parameters(), lr=learning_rate)\ncriterion_G = nn.BCELoss()\ncriterion_D = nn.BCELoss()\nfor epoch in tqdm(range(num_epochs)):\n    for imgs, _ in loader:\n        # Train Generator\n        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n\n        real_imgs = Variable(imgs.type(Tensor))\n\n        optim_G.zero_grad()\n\n        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_size)))) # Sample noise\n        gen_imgs = G(z)\n        G_loss = adversarial_loss(D(gen_imgs), valid)\n\n        G_loss.backward()\n        optim_G.step()\n\n        #  Train Discriminator\n        optim_D.zero_grad()\n        real_loss = adversarial_loss(D(real_imgs), valid)\n        fake_loss = adversarial_loss(D(gen_imgs.detach()), fake)\n        D_loss = (real_loss + fake_loss) \/ 2\n\n        D_loss.backward()\n        optim_D.step()\n    if epoch % 2 == 0:\n        D.eval()\n        G.eval()\n        draw_my_picture()        \n        print(f\"D_loss: {D_loss.item():.4f} G_loss: {G_loss.item():.4f}\")\n        torch.save(D.state_dict(), 'D.pth')\n        torch.save(G.state_dict(), 'G.pth')\n        D.train()\n        G.train()","90838a4e":"z = Variable(Tensor(np.random.normal(0, 1, (32, latent_size)))) # Sample noise\ngen_imgs = G(z).detach().cpu()\nplt.figure(figsize=(8, 8))\nplt.axis(\"off\")\nplt.imshow(np.transpose(vutils.make_grid(gen_imgs, padding=2, normalize=True).cpu(),(1,2,0)))","1afa8b48":"**Generator**","fe4139a3":"**Variables used**","895582d6":"## Training","94c7ed67":"## Imports","9bd7d569":"**Discriminator**","745119d8":"This code is insired by [Pytorch implementations of GANs repo](https:\/\/github.com\/eriklindernoren\/PyTorch-GAN)","40b6bdfc":"## Networks","ffbb3986":"## Data"}}