{"cell_type":{"068f4364":"code","70618ebe":"code","55636166":"code","acbc4a9b":"code","c1cc80f4":"code","1e44314c":"code","d5f463a3":"code","737b5df2":"code","1ca65a18":"code","aa93d46e":"code","ca67002e":"code","669d663e":"code","3568683a":"code","e24a4784":"code","92bf8031":"code","c5bf62a2":"code","3a0c4b48":"code","ad212b12":"code","5aea94d2":"code","77a8ee70":"code","88d8819c":"code","db8823dd":"code","1ef65383":"code","78684f1a":"code","b0861036":"code","b9d7e043":"code","dffba379":"code","370f7fd8":"code","d94b8771":"markdown","2042720e":"markdown","d12d4d62":"markdown","d5679c50":"markdown","ade9b177":"markdown","ab876d5b":"markdown","b9b56516":"markdown","01d08326":"markdown","c12b9246":"markdown","d55a3d6e":"markdown"},"source":{"068f4364":"import os, glob, pandas as pd","70618ebe":"# Paths\n\ninput_dir = os.path.abspath('\/kaggle\/input\/')\narticles_dir = input_dir + '\/cord19csv\/'","55636166":"%%time\n\nli_df = []\n\nfor jt in ['pdf','pmc']:\n    path = f'{articles_dir}\/{jt}*.csv'\n    files = glob.glob(path)\n    \n    for file in files:\n        if jt == \"pdf\":            \n            df_pdf = pd.read_csv(file, index_col=None, header=0)\n            li_df.append(df_pdf)\n        else:\n            df_pmc = pd.read_csv(file, index_col=None, header=0)        \n            li_df.append(df_pmc)\n\n# Combine all papers dataframes in one\ndf = pd.concat(li_df, axis=0, ignore_index=True, sort=False)","acbc4a9b":"df.shape","c1cc80f4":"df.head()","1e44314c":"# Drop duplicated documents by paper_id\ndf.drop_duplicates(subset=\"paper_id\", keep='first', inplace=True)","d5f463a3":"# Drop duplicated documents by text\ndf.drop_duplicates(subset=\"doc_text\", keep='first', inplace=True)\ndf.shape","737b5df2":"# Create the lists of key terms\n\nterms_group_id = \"medical_care\"\n\nterms1 = [\n    'medical care','surge capacity','nursing homes',\n    'efforts to inform allocation','scarce resources',\n    'personal protective equipment','ppe',\n    'alternative methods to advise','disease management',\n    'processes of care','clinical characterization','skilled nursing',\n    'management of the virus','resources to support skilled nursing',\n    'skilled nursing facilities','long term care facilities',\n    'nursing facilities'\n]\n\nterms2 = [\n    'mobilization of surge medical staff',\n    'mobilization','medical staff','address shortages',\n    'overwhelmed communities'\n]\n\nterms3 = [\n    'age-adjusted mortality','ards','viral etiologies',\n    'acute respiratory distress syndrome'\n]\n\nterms4 = [\n    'extracorporeal membrane oxygenation','ecmo'\n]\n\nterms5 = [\n    'outcomes data','ventilation adjusted for age'\n]\n\nterms6 = [\n    'extrapulmonary manifestations','cardiomyopathy',\n    'cardiac arrest'\n]\n\nterms7 = [\n    'application of regulatory standards',\n    'eua','clia','ability to adapt care','crisis standards',\n    'care level'\n]\n\nterms8 = [\n    'elastomeric respirators','n95 masks'\n]\n\nterms9 = [\n    'telemedicine practices','telemedicine',\n    'barriers','facilitators','specific actions',\n    'state boundaries'\n]\n\nterms10 = [\n    'safety recommendations','simple precautions',\n    'manage disease','brochoure','information brochure'\n]\n\nterms11 = [\n    'oral medication','remdesivir','hydroxychloroquine',\n    'chloroquine','azithromycin','z-pak','actemra',\n    'tocilizumab','kaletra','lopinavir','ritonavir',\n    'tamiflu','oseltamivir','avigan','favipiravir',\n    'ivermectin'\n]\n\nterms12 = [\n    'use of ai','real-time health care'\n]\n\nterms13 = [\n    'best practices','critical challenges','innovative solutions',\n    'technologies','hospital flow and organization',\n    'workforce protection','workforce allocation',\n    'community-based support resources','payment',\n    'supply chain management'\n]\n\nterms14 = [\n    'natural history',\n    'public health interventions','infection prevention control',\n    'clinical trials'\n]\n\nterms15 = [\n    'maximize usability of data','usability','usability of data',\n    'range of trials','trials'\n]\n\nterms16 = [\n    'supportive interventions','adjunctive interventions',\n    'adjunctive','supportive'\n]\n\nterms = terms1 + terms2 + terms3 + terms4 + terms5 \nterms += terms6 + terms7 + terms8 + terms9 + terms10 \nterms += terms11 + terms12 + terms13 + terms14 + terms14\nterms += terms15 + terms16","1ca65a18":"import spacy\n\n# Perform NLP operations on GPU, if available.\nspacy.prefer_gpu()\n\n# Load Spacy english model\nnlp = spacy.load('en', disable=['parser', 'ner', 'textcat'])\nnlp.max_length = 5000000","aa93d46e":"# Create matcher and patterns\n\nfrom spacy.matcher import PhraseMatcher\n\n# Create a Matcher to case insensitive text matching\nmatcher = PhraseMatcher(nlp.vocab, attr='LEMMA')    \n\n# Create patterns from terms\npatterns = [nlp(d) for d in terms]\nmatcher.add(terms_group_id, None, *patterns)","ca67002e":"# Defines the matcher\n\ndef cord_19_matcher(sample_pct):   \n    # variables to test: test_limt is the total of docs to test; \n    # 0 = test off\n    \n    test_limit = 0\n    counter = 0\n\n    docs = df.sample(frac = sample_pct\/100) if sample_pct < 100 else df\n    tdocs = str(len(docs))\n\n    print(f\"{tdocs} documents to proccess...\")\n        \n    # Maximun allowed length of string text document\n    max_tlen = 100000\n\n    # initialize array and total found variables\n    findings_arr = []\n\n    # loop all articles to match terms\n    for idx, row in docs.iterrows():\n        try:\n            paper_id = row['paper_id']\n            doc_text = row[\"doc_text\"]            \n            \n            doc = nlp(doc_text)\n\n            # get the matches\n            matches = matcher(doc)\n\n            # process all matches found in text\n            if matches:\n                for m in matches:\n                    m_id, start, end = m[0],m[1],m[2]\n                    term_group = nlp.vocab.strings[m_id]\n                    term = doc[start:end].text\n\n                    # put finding into json object\n                    finding = {\n                        \"paper_id\": paper_id,\n                        \"term_group\": term_group,\n                        \"term\": term\n                    }\n\n                    # append finding to findings array\n                    findings_arr.append(finding)                \n\n            counter += 1\n            if counter % 100 == 0:\n                print(f\"{counter} documents proccessed\")\n\n            # breake loop if test control present\n            if test_limit > 0:            \n                if counter == test_limit:\n                    print(test_limit, \"sample count reached\")\n                    break\n\n        except BaseException as e:\n            print(\"Oops!  Error occurred in document loop.\")\n            print(str(e))\n            print(\"Continuing...\")\n            continue\n    \n    return findings_arr","669d663e":"%%time\n\n# Set sample parameter = % of papers to proccess\nsample_pct = 100\n#sample_pct = 1.2\n#sample_pct = 10\n\nfindings_arr = cord_19_matcher(sample_pct)\n\ntfound = len(findings_arr)\nprint(tfound, \"matches found\\n\")","3568683a":"# Put findings array into a dataframe\n\nfindings = pd.DataFrame(findings_arr)\n\n# exclude the following terms originally taken in account\n#exc = ['term1','term2','term3']\n#findings.where(~findings.term.isin(exc), inplace = True)","e24a4784":"findings.info()","92bf8031":"findings.head()","c5bf62a2":"# Capitalize each term in findings\nfindings[\"term\"] = findings[\"term\"].str.capitalize()","3a0c4b48":"findings['count'] = ''\ncnt = findings.groupby('term').count()[['count']]\ncnt_s = cnt.sort_values(by='count', ascending=False).copy()","ad212b12":"# Show the bar chart\n\nax = cnt_s.plot(kind='barh', figsize=(12,40), \n                legend=False, color=\"coral\", \n                fontsize=16)\nax.set_alpha(0.8)\nax.set_title(\"What has been published about medical care?\",\n             fontsize=18)\nax.set_xlabel(\"Term Appearances\", fontsize=16);\nax.set_ylabel(\"Terms\", fontsize=14);\nax.set_xticks([0,100,200,300,400,500,600,700,800,900,1000])\n\n# Create a list to collect the plt.patches data\ntotals = []\n\n# Fill totals list\nfor i in ax.patches:\n    totals.append(i.get_width())\n\ntotal = sum(totals)\n\n# Set bar labels using the list\nfor i in ax.patches:\n    c = i.get_width()\n    cnt = f'{c:,} '\n    pct = str(round((c\/total)*100, 2)) + '%'\n    pct_f = \"(\" + pct + \")\"\n    ax.text(c+.3, i.get_y()+.4, cnt + pct_f, \n            fontsize=14, color='dimgrey')\n\n# Invert graph \nax.invert_yaxis()","5aea94d2":"from wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Fill the list of words to show\nterm_values = \"\"\nfor term in findings['term']:\n    term_val = str(term).title()\n    term_val = term_val.replace(' ','_')\n    term_val = term_val.replace('-','_')\n    term_values += term_val + ' '\n\n# Generates the wordcloud object\nwordcloud = WordCloud(background_color=\"white\",\n                      collocations=False).generate(term_values)\n\n# Display the generated image\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.figure(figsize=((10,8)))\nplt.show()","77a8ee70":"findings_sta = findings.groupby([\"term\", \"paper_id\"]).size().reset_index(name=\"count\")\nfindings_sta = findings_sta.sort_values(by=['term','count'], ascending=False)","88d8819c":"# Helper\n\ndef get_doc_text(paper_id):\n    doc = df.loc[df[\"paper_id\"]==paper_id].iloc[0]\n    return doc[\"doc_text\"]","db8823dd":"answers = []\n\nfor term in terms:    \n    term = term.capitalize()\n    try:\n        f = findings_sta[findings_sta[\"term\"]==term]\n        f = f.sort_values(\"count\",ascending=False)\n        for fc in f.iterrows():           \n            paper_id = fc[1][\"paper_id\"]                        \n            doc_text = get_doc_text(paper_id)\n            \n            answer = {\n                \"aspect\": terms_group_id,\n                \"factor\": term,\n                \"paper_id\": paper_id,\n                \"doc_text\": str(doc_text)\n            }\n\n            answers.append(answer)\n            \n            break\n        \n    except BaseException as e:\n        print(str(e))\n        continue\n\nlen(answers)","1ef65383":"import ipywidgets as widgets\nfrom ipywidgets import Layout, Button, Box, FloatText, Textarea, Dropdown, Label, IntSlider","78684f1a":"item_layout = Layout(\n    display='flex',\n    flex_flow='row',\n    justify_content='space-between',\n    width= '100%',\n    height= '200px'\n)","b0861036":"# Helpers\n\ndef get_text_area(text):\n    ta = widgets.Textarea(\n        value=str(text),\n        placeholder='',\n        description='',\n        layout=item_layout,\n        disabled=True\n    )\n    return ta\n\nimport json\n\ndef get_answer_text(factor):\n    try:\n        factor = factor.capitalize()\n        ans = next(x for x in answers if x[\"factor\"] == factor)\n        ans = json.dumps(ans[\"doc_text\"]).strip(\"'\").strip('\"')\n        ans = ans.replace('\\\\n', '\\n\\n')\n        return ans\n    except BaseException:\n        return \"\"\n    \ndef get_question_answer(t_params):\n    full_text = ''\n    for t_param in t_params:\n        try:\n            doc_text = get_answer_text(t_param)\n            if not doc_text in full_text:\n                if len(full_text) > 0:\n                    full_text += \"\\n\\n\"                \n                full_text += doc_text\n        except BaseException:\n            continue\n    \n    return full_text","b9d7e043":"td1 = 'Resources to support skilled nursing facilities and long term care facilities.'\ntext = get_question_answer(terms1)\nta1 = get_text_area(text)\n\ntd2 = 'Mobilization of surge medical staff to address shortages in overwhelmed communities'\ntext = get_question_answer(terms2)\nta2 = get_text_area(text)\n\ntd3 = 'Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with\/without other organ failure \u2013 particularly for viral etiologies'\ntext = get_question_answer(terms3)\nta3 = get_text_area(text)\n\ntd4 = 'Extracorporeal membrane oxygenation (ECMO) outcomes data of COVID-19 patients'\ntext = get_question_answer(terms4)\nta4 = get_text_area(text)\n\ntd5 = 'Outcomes data for COVID-19 after mechanical ventilation adjusted for age'\ntext = get_question_answer(terms5)\nta5 = get_text_area(text)\n\ntd6 = 'Knowledge of the frequency, manifestations, and course of extrapulmonary manifestations of COVID-19, including, but not limited to, possible cardiomyopathy and cardiac arrest'\ntext = get_question_answer(terms6)\nta6 = get_text_area(text)\n\ntd7 = 'Application of regulatory standards (e.g., EUA, CLIA) and ability to adapt care to crisis standards of care level.'\ntext = get_question_answer(terms7)\nta7 = get_text_area(text)\n\ntd8 = 'Approaches for encouraging and facilitating the production of elastomeric respirators, which can save thousands of N95 masks.'\ntext = get_question_answer(terms8)\nta8 = get_text_area(text)\n\ntd9 = 'Best telemedicine practices, barriers and faciitators, and specific actions to remove\/expand them within and across state boundaries.'\ntext = get_question_answer(terms9)\nta9 = get_text_area(text)\n\ntd10 = 'Guidance on the simple things people can do at home to take care of sick people and manage disease.'\ntext = get_question_answer(terms10)\nta10 = get_text_area(text)\n\ntd11 = 'Oral medications that might potentially work.'\ntext = get_question_answer(terms11)\nta11 = get_text_area(text)\n\ntd12 = 'Use of AI in real-time health care delivery to evaluate interventions, risk factors, and outcomes in a way that could not be done manually.'\ntext = get_question_answer(terms12)\nta12 = get_text_area(text)\n\ntd13 = 'Best practices and critical challenges and innovative solutions and technologies in hospital flow and organization, workforce protection, workforce allocation, community-based support resources, payment, and supply chain management to enhance capacity, efficiency, and outcomes.'\ntext = get_question_answer(terms13)\nta13 = get_text_area(text)\n\ntd14 = 'Efforts to define the natural history of disease to inform clinical care, public health interventions, infection prevention control, transmission, and clinical trials'\ntext = get_question_answer(terms14)\nta14 = get_text_area(text)\n\ntd15 = 'Efforts to develop a core clinical outcome set to maximize usability of data across a range of trials'\ntext = get_question_answer(terms15)\nta15 = get_text_area(text)\n\ntd16 = 'Efforts to determine adjunctive and supportive interventions that can improve the clinical outcomes of infected patients (e.g. steroids, high flow oxygen)'\ntext = get_question_answer(terms16)\nta16 = get_text_area(text)","dffba379":"ac1_tas = [ta1,ta2,ta3,ta4,ta5,ta6,ta7,ta8,ta9,\n          ta10,ta11,ta12,ta13,ta14,ta15,ta16]\nac1 = widgets.Accordion(children=ac1_tas)\nac1.set_title(0, td1)\nac1.set_title(1, td2)\nac1.set_title(2, td3)\nac1.set_title(3, td4)\nac1.set_title(4, td5)\nac1.set_title(5, td6)\nac1.set_title(6, td7)\nac1.set_title(7, td8)\nac1.set_title(8, td9)\nac1.set_title(9, td10)\nac1.set_title(10, td11)\nac1.set_title(11, td12)\nac1.set_title(12, td13)\nac1.set_title(13, td14)\nac1.set_title(14, td15)\nac1.set_title(15, td16)","370f7fd8":"ac1","d94b8771":"Display a bar graph and a word cloud with the totals of findings  by key term.","2042720e":"## Pattern Matching\nObjective: classify all articles according to key terms.","d12d4d62":"## Load Data","d5679c50":"## Get what the literature reports on the task topic","ade9b177":" # What has been published about medical care?\n \nThe answer to this question is distributed in each of the aspects listed at the beginning of this notebook.","ab876d5b":"# **INTRODUCTION**\n\nThis work is to help the medical community answer the posted question in Kaggle: [What has been published about medical care?](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge\/tasks) The resulting model enables to understand and keep up with the large amount of literature contained in the provided dataset, specifically:\n\n1. Resources to support skilled nursing facilities and long term care facilities.\n2. Mobilization of surge medical staff to address shortages in overwhelmed communities\n3. Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with\/without other organ failure \u2013 particularly for viral etiologies\n4. Extracorporeal membrane oxygenation (ECMO) outcomes data of COVID-19 patients\n5. Outcomes data for COVID-19 after mechanical ventilation adjusted for age.\n6. Knowledge of the frequency, manifestations, and course of extrapulmonary manifestations of COVID-19, including, but not limited to, possible cardiomyopathy and cardiac arrest.\n7. Application of regulatory standards (e.g., EUA, CLIA) and ability to adapt care to crisis standards of care level.\n8. Approaches for encouraging and facilitating the production of elastomeric respirators, which can save thousands of N95 masks.\n9. Best telemedicine practices, barriers and faciitators, and specific actions to remove\/expand them within and across state boundaries.\n10. Guidance on the simple things people can do at home to take care of sick people and manage disease.\n11. Oral medications that might potentially work.\n12. Use of AI in real-time health care delivery to evaluate interventions, risk factors, and outcomes in a way that could not be done manually.\n13. Best practices and critical challenges and innovative solutions and technologies in hospital flow and organization, workforce protection, workforce allocation, community-based support resources, payment, and supply chain management to enhance capacity, efficiency, and outcomes.\n14. Efforts to define the natural history of disease to inform clinical care, public health interventions, infection prevention control, transmission, and clinical trials\n15. Efforts to develop a core clinical outcome set to maximize usability of data across a range of trials\n16. Efforts to determine adjunctive and supportive interventions that can improve the clinical outcomes of infected patients (e.g. steroids, high flow oxygen)\n\nAt the end of this notebook, the question asked is answered by means of each of the aspects listed above. In each case, the original content of the article that most represents the processed aspect is shown.\n\nTo accomplish the goal, the selected approach was to perform text mining on input data, by applying the latest advances in natural language processing (NLP). This was realized by the following steps:\n\n    1. Obtain input data and pre-process it to facilitate analysis.\n    2. Extract the key terms from the task description.\n    3. Match key terms with text contents.\n    4. Group and quantify the findings.\n    5. Show the documents that answer the task questions.\n        \nThe advantage of using NLP to abord this problem is that it is based on language-specific models, saving time and resources for text analysis.\n\nThe key terms was extracted from the task description in the step 2, resulting in a set of rule-based patterns.\n\nThe matching of key terms (step 3) was applied through topic  classification with Spacy library. This work through large sets of the unstructured data to match the patterns obtained in step 2. It is a very fast and scalable process that preferably uses the GPU resource.\n\nThis approach presents the limitation of synonymy, where multiple words and phrases have the same or similar meaning. To counter this, great care was taken in selecting keywords to make up the vocabulary of terms (e.g. COVID-19, SARS-CoV-2, 2019-nCov, SARS Coronavirus 2, or 2019 Novel Coronavirus).\n\nIn other hand, since the [original input data](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge) it is stored in JSON single files, whose structure is likely too complex to directly perform the analysis, this notebook uses the pre-processed data from the dataset [CORD-19-CSV](https:\/\/www.kaggle.com\/huascarmendez1\/cord19csv), also of same authorship of this.\n\nThe preprocessing of the data further consisted of filtering the documents that specifically talk about the covid-19 disease and its other names, as well as that they dealt with related risk factors, among other general data review, counting and cleaning activities.\n\nFinally, as it is clear that the results presented here are not final, it is recommended to assume them as a starting point for a complete understanding of each of the aspects that it tries to address.","b9b56516":"Quantify documents by key terms","01d08326":"Group findings by key term and sort by key term and count. The first document in each group will be part of the response to the task question.","c12b9246":"Pre-process input data","d55a3d6e":"Run the matcher"}}