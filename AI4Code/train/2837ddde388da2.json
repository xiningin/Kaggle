{"cell_type":{"0c070022":"code","ecf5c03f":"code","5f1bfaa0":"code","6d2235dd":"code","7ad42afe":"code","8388850a":"code","232c6555":"code","aeb90e5a":"code","eeed799e":"code","fe004c1d":"code","b8936525":"code","e77d6abf":"code","4bf7753f":"code","2a489e6e":"code","3ebd351f":"code","008835cd":"code","5a45b0e1":"code","048eaea3":"code","3014afae":"code","8984a28c":"code","a1cfe11e":"code","a4a74970":"code","aa7be530":"code","86c44298":"code","3e33676c":"code","f2b23e83":"markdown","e6e8093d":"markdown","41f33225":"markdown","7102f99a":"markdown","b6721308":"markdown","be957428":"markdown","d560ef78":"markdown","2884a2f1":"markdown","aa5994a5":"markdown","9c4f3ab4":"markdown","7ec5f116":"markdown","3cac4edd":"markdown","71bf2960":"markdown","e3f69e94":"markdown","33fdba13":"markdown","51362cc7":"markdown","3f33b2e9":"markdown","0a347e14":"markdown","3a94fe45":"markdown","a46465f1":"markdown","589fc690":"markdown","30905c82":"markdown"},"source":{"0c070022":"import os\n\nimport numpy as np\nfrom numpy.random import choice\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport time\n\nimport PIL\n\nimport torch\nfrom torch import nn, Tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport torchvision\n\n\n# For AUC:\nfrom sklearn.metrics import roc_auc_score\n\n\nnp.random.seed(42)","ecf5c03f":"def function_timer(function):\n    \n    def wrapper(*args, **kwargs):\n        start    = time.time()\n        result   = function(*args, **kwargs)\n        duration = time.time() - start\n        \n        hours    = int(duration \/\/ 60**2)\n        minutes  = int((duration % 60**2) \/\/ 60)  \n        seconds  = int(duration % 60)\n        print(f'execution-time of function \"{function.__name__}\": {hours}h {minutes}m {seconds}s')\n        \n        return result\n        \n    return wrapper\n","5f1bfaa0":"def plot_error_curves(errors_over_time: list, error_name='error'):\n    \"\"\"\n    @ errors_over_time: list of tuples: (training-error, validation-error)\n    \"\"\"\n\n    if len(errors_over_time) <= 1:\n        print(f'Require at least two data-poits for plotting. Got {len(errors_over_time)}.')\n        return 0\n    \n    error_train, error_validation = zip(*errors_over_time)\n\n    plt.plot(range(len(error_train)), error_train)\n    plt.plot(range(len(error_validation)), error_validation)\n    plt.xticks(range(0, len(error_train) + 1, len(error_train) \/\/ 2))\n    plt.xlabel('epoch')\n    plt.ylabel(f'{error_name}')\n    plt.legend(('training', 'validation'))\n    plt.title(f'{error_name} over time')\n    plt.show();","6d2235dd":"DATA_DIR = '..\/input'\n\ntrain_dir = os.path.join(DATA_DIR, 'train')\ntest_dir  = os.path.join(DATA_DIR, 'test')\n\n\ndef train_validation_split(df, val_fraction=0.1):\n    val_ids  = np.random.choice(df.id, size=int(len(df) * val_fraction))\n    val_df   = df.query('id     in @val_ids')\n    train_df = df.query('id not in @val_ids')\n    return train_df, val_df\n\n\ntrain_label_df, val_label_df = train_validation_split(pd.read_csv(os.path.join(DATA_DIR, 'train_labels.csv')),\n                                                      val_fraction=0.1)","7ad42afe":"class HistoPatches(Dataset):\n    \n    def __init__(self,\n                 image_dir: str,\n                 label_df=None,\n                 transform=transforms.ToTensor(),\n                 sample_n=None,\n                 in_memory=False):\n        \"\"\"\n        @ image_dir:   path to directory with images\n        @ label_df:    df with image id (str) and label (0\/1) - only for labeled test-set\n        @ transforms:  image transformation; by default no transformation\n        @ sample_n:    if not None, only use that many observations\n        \"\"\"\n        self.image_dir = image_dir\n        self.img_files = os.listdir(image_dir)\n        self.label_df  = label_df\n        self.transform = transform\n        self.in_memory = in_memory\n        \n        if sample_n and label_df is None:\n            print('subsampling is currently only implemented when a label-dataframe is provided.')\n            print('(because training- and validation-set share the same image directory')\n            print('and the test-set does not need to be subsampled)')\n        elif sample_n:\n            self.label_df  = self.label_df.sample(n=sample_n)\n            ids            = set(self.label_df.id)\n            self.img_files = [f for f in self.img_files if f.split('.')[0] in ids]\n            \n        #self.label_df = self.label_df.reset_index(drop=True)\n            \n        if in_memory:\n            self.id2image = self._load_images()\n\n        print(f'Initialized datatset with {len(self.img_files)} images.\\n')\n        \n    @function_timer\n    def _load_images(self):\n        print('loading images in memory...')\n        id2image = {}\n        \n        for file_name in self.img_files:\n            img = PIL.Image.open(os.path.join(self.image_dir, file_name))\n            X   = self.transform(img)\n            id_ = file_name.split('.')[0]\n            id2image[id_] = X\n            \n        return id2image\n    \n    def __getitem__(self, idx):\n        file_name = self.img_files[idx]\n        id_ = file_name.split('.')[0]\n        \n        #row = self.label_df.iloc[idx]\n        #assert row.label == self.label_df.loc[idx].label\n        #y   = float(row.label)\n        \n        if self.in_memory:\n            X = self.id2image[id_]\n        else:\n            img = PIL.Image.open(os.path.join(self.image_dir, file_name))\n            X   = self.transform(img)\n            \n        if self.label_df is not None:\n            y = float(self.label_df.query('id == @id_').label)\n            return X, y\n        else:\n            return X, id_\n    \n    def __len__(self):\n        return len(self.img_files)\n    \n","8388850a":"image_trans = transforms.Compose([#transforms.CenterCrop(30),\n                                  transforms.ToTensor(),\n                                  transforms.Normalize(mean=[0.70017236, 0.5436771, 0.6961061], \n                                                       std=[0.22246036, 0.26757348, 0.19798167])\n                                 ])\nmemory      = True\nbatchsize   = 64\n\ntrain = HistoPatches(train_dir,\n                     train_label_df,\n                     transform=image_trans,\n                     sample_n=70000, #70k was best\n                     in_memory=memory)\n\nval   = HistoPatches(train_dir,\n                     val_label_df,\n                     transform=image_trans,\n                     sample_n=4000,\n                     in_memory=memory)\n\ntrain_loader = DataLoader(train, batch_size=batchsize, shuffle=True)\nval_loader   = DataLoader(val,   batch_size=batchsize, shuffle=False)\n\nprint('test and show batch-dimension:')\nfor i, (X, y) in enumerate(train_loader):\n    if i == 10:\n        print(X.shape, y.shape)\n        break","232c6555":"class CyclicLR(object):\n    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n                 step_size=2000, mode='triangular', gamma=1.,\n                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n\n        \n        self.optimizer = optimizer\n\n        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n            if len(base_lr) != len(optimizer.param_groups):\n                raise ValueError(\"expected {} base_lr, got {}\".format(\n                    len(optimizer.param_groups), len(base_lr)))\n            self.base_lrs = list(base_lr)\n        else:\n            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n\n        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n            if len(max_lr) != len(optimizer.param_groups):\n                raise ValueError(\"expected {} max_lr, got {}\".format(\n                    len(optimizer.param_groups), len(max_lr)))\n            self.max_lrs = list(max_lr)\n        else:\n            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n\n        self.step_size = step_size\n\n        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n                and scale_fn is None:\n            raise ValueError('mode is invalid and scale_fn is None')\n\n        self.mode = mode\n        self.gamma = gamma\n\n        if scale_fn is None:\n            if self.mode == 'triangular':\n                self.scale_fn = self._triangular_scale_fn\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = self._triangular2_scale_fn\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = self._exp_range_scale_fn\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n\n        self.step(batch_iteration = last_batch_iteration + 1)\n        self.last_batch_iteration = last_batch_iteration\n\n    def step(self, batch_iteration = None, ):\n        if batch_iteration is None:\n            batch_iteration = self.last_batch_iteration + 1\n        self.last_batch_iteration = batch_iteration\n        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n            param_group['lr'] = lr\n\n    def _triangular_scale_fn(self, x):\n        return 1.\n\n    def _triangular2_scale_fn(self, x):\n        return 1 \/ (2. ** (x - 1))\n\n    def _exp_range_scale_fn(self, x):\n        return self.gamma**(x)\n\n    def get_lr(self):\n        step_size = float(self.step_size)\n        cycle = np.floor(1 + self.last_batch_iteration \/ (2 * step_size))\n        x = np.abs(self.last_batch_iteration \/ step_size - 2 * cycle + 1)\n\n        lrs = []\n        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n        for param_group, base_lr, max_lr in param_lrs:\n            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n            if self.scale_mode == 'cycle':\n                lr = base_lr + base_height * self.scale_fn(cycle)\n            else:\n                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n            lrs.append(lr)\n        return lrs","aeb90e5a":"# Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = '1', '0'\nsizes = [np.mean(val_label_df.label), 1-np.mean(val_label_df.label)]\n#explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax1.set(title = \"Test Set Label Distribution\")\nplt.show()","eeed799e":"@function_timer\ndef train_model(net, train, validation, optimizer, device, scheduler = None, max_epoch=100, verbose=False):\n    \"\"\"\n    This function returns nothing. The parametes of @net are updated in-place\n    and the error statistics are written to a global variable. This allows to\n    stop the training at any point and still have the results.\n  \n    @ net: a defined model - can also be pretrained\n    @ train, test: DataLoaders of training- and test-set\n    @ max_epoch: stop training after this number of epochs\n    \"\"\"\n    global error_stats  # to track error log even when training aborted\n    error_stats = []\n  \n    criterion = nn.BCEWithLogitsLoss()\n    #scheduler = torch.optim.lr_scheduler.MultiStepLR(\n    #    optimizer,\n    #    milestones=[x for x in range(1, max_epoch) if x % 20 == 0],\n    #    gamma=0.5  # decrease learning rate by half each step\n    #)\n    net.to(device)\n    \n    print('epoch\\ttraining-CE\\ttraining-acc\\ttraining_auc\\tvalidation-CE\\tvalidation-acc\\tvalidation_auc')\n    for epoch in range(max_epoch):\n        net.train()\n        training_loss = 0\n        training_acc = 0\n        validation_loss = 0\n        validation_acc = 0\n        training_auc = 0\n        validation_auc = 0\n    \n        for batch_i, (X, y) in enumerate(train):\n            \n            if verbose and batch_i % (batchsize\/4) == 0:\n                print(f'\\t...batch {batch_i} \/ {len(train)}')\n            \n            X , y = X.to(device), y.to(device)\n            optimizer.zero_grad()\n            if scheduler is not None:\n                scheduler.step()\n            # prediction and error:\n            out  = net(X).squeeze()\n            loss = criterion(out.type(torch.DoubleTensor).cuda(), y)  # loss of current batch\n            training_loss += loss.item()\n            predictions = torch.sigmoid(out).round().detach().cpu().numpy()\n            training_acc += np.mean(y.detach().cpu().numpy() == predictions) * 100\n            training_auc += get_roc_score(out ,y)\n\n            # update parameters:\n            loss.backward()\n            optimizer.step()\n\n        with torch.no_grad():  # no backpropagation necessary\n            net.eval()\n\n            for X, y in validation:\n                X , y = X.to(device), y.to(device)\n\n                # prediction and error:\n                out  = net(X).squeeze()\n                loss = criterion(out.type(torch.DoubleTensor).cuda(), y)  # loss of current batch\n                validation_loss += loss.item()\n                predictions = torch.sigmoid(out).round().detach().cpu().numpy()\n                validation_acc += np.mean(y.detach().cpu().numpy() == predictions) * 100\n                validation_auc += get_roc_score(out ,y)\n    \n        # convert to batch loss:\n        training_acc    = training_acc    \/ len(train)\n        training_loss   = training_loss   \/ len(train)\n        training_auc    = training_auc    \/ len(train)\n        validation_acc  = validation_acc  \/ len(validation)\n        validation_loss = validation_loss \/ len(validation)\n        validation_auc  = validation_auc  \/ len(validation)\n        #scheduler.step()\n       \n        #torch.save(net.state_dict(), f'epoch{epoch}.pt')\n        error_stats.append( (training_loss, validation_loss, training_acc, validation_acc, training_auc, validation_auc) )\n\n        print('{}\\t{:.4f}\\t\\t{:.2f}\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.2f}\\t\\t{:.4f}'.format(\n            epoch, training_loss, training_acc, training_auc, validation_loss, validation_acc, validation_auc)\n             )\n        \n","fe004c1d":"def conv_dim(in_dim, k=3, s=1, p=0, p_left=None, p_right=None):\n    \n    if p is not None:\n        p_left = p_right = p\n    assert p_left is not None and p_right is not None\n        \n    tmp = (in_dim - k + p_left + p_right) \/ s\n    out_dim = int(np.floor(tmp) + 1)\n    \n    if tmp % 1 != 0:\n        print('no exact output-dim; using Gauss-brackets.')\n    print(f'out-dim: {out_dim}')\n\n\n# conv_dim(30, k=3, s=1, p=0)","b8936525":"#orig_net = models.densenet121()\n#print(orig_net.features[:4])\n\n#x = X.cpu()\n#h1 = orig_net.features[:4](x)\n#print(h1.shape)","e77d6abf":"from collections import OrderedDict\n\nnet_fullimage = models.densenet121(pretrained=False)\nnet_fullimage.features = nn.Sequential(\n    nn.Sequential(OrderedDict([\n            ('conv0', nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)),\n            ('norm0', nn.BatchNorm2d(64)),\n            ('relu0', nn.ReLU(inplace=True))\n        ])),  # 96**2 -> 48**2\n    net_fullimage.features[4:])\n\nnet_fullimage.classifier = nn.Sequential(\n    nn.Linear(1024, 512),\n    nn.Linear(512, 1)\n)\n# net_fullimage","4bf7753f":"net = net_fullimage  # choose net to train here\n\n# # just for testing\n# myloss = nn.BCEWithLogitsLoss()\n# net.cuda()\n# for i, (X, y) in enumerate(train_loader):\n#     if i == 10:\n#         X , y = X.cuda(), y.cuda()\n#         print(X.shape, y.shape)\n#         out = net(X).squeeze()\n#         print(f'loss: {myloss(y, out.type(torch.DoubleTensor).cuda()).item()}')\n#         break","2a489e6e":"def get_roc_score(net_output, y):\n    \"\"\"\n    @ net_output: output from neural network (cuda)tensor, with NO sigmoid applied yet!\n    @ y: label (cuda)tensor [0s, 1s]\n    \"\"\"\n    \n    # Apply sigmoid\n    net_out = nn.Sigmoid()(net_output)\n    # reshape from (batch_size, 1) to (batch_size, ) and convert to numpy\n    net_out_np = net_out.reshape(-1).detach().cpu().numpy()\n    # convert to numpy\n    y_np = y.detach().cpu().numpy()\n    return roc_auc_score(y_np,net_out_np)","3ebd351f":"nr_cycles = 10\nepochs = 20\ntotal_number_batches = epochs * len(train_loader)\nstepsize = int(.5*total_number_batches\/nr_cycles)\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=0)\nscheduler = CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01,\n                 step_size=stepsize, mode='triangular2')\nprint(f'Stepsize: {stepsize}')","008835cd":"train_model(net,\n            train_loader,\n            val_loader,\n            optimizer,\n            scheduler = scheduler,\n            device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n            max_epoch=epochs,\n            verbose=False)","5a45b0e1":"accuracy = [(x[2], x[3]) for x in error_stats]\nplot_error_curves(accuracy, error_name='accuracy')","048eaea3":"bce = [(x[0], x[1]) for x in error_stats]\nplot_error_curves(bce, error_name='binary cross-entropy')","3014afae":"auc_ = [(x[4], x[5]) for x in error_stats]\nplot_error_curves(auc_, error_name = \"Area Under the Curve (AUC))\")","8984a28c":"torch.save(net.state_dict(), 'swag_net2.pt')","a1cfe11e":"from sklearn.metrics import roc_curve\n\n# Predict all values\ny_pred = []\ny_true = []\nnet.eval()\nfor idx, (X, y) in enumerate(val_loader):\n    X, y = X.cuda(), y.cuda()\n    # save into y_pred and y_true (true)\n    y_pred.extend(list(net(X).reshape(-1).detach().cpu().numpy()))\n    y_true.extend(list(y.detach().cpu().numpy()))\n  \n\nfpr, tpr, _ = roc_curve(y_true, y_pred)\nauc_score = roc_auc_score(y_true, y_pred)\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='AUC: {0:.4f}'.format(auc_score))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='lower right')\nplt.show()\n","a4a74970":"# free up some RAM:\ntry:\n   del val, val_loader, train, train_loader\nexcept:\n   pass","aa7be530":"test = HistoPatches(image_dir=os.path.join(DATA_DIR, 'test'), transform = image_trans)\ntest_loader = DataLoader(test, batch_size=batchsize, shuffle = False)\nprediction_df = pd.DataFrame(columns=['id', 'label'])","86c44298":"net.eval()\nfor X, ids in test_loader:\n    out = net(X.cuda()).squeeze()\n    predictions = torch.sigmoid(out).detach().cpu().numpy()\n    df = pd.DataFrame({'id': ids, 'label': predictions.astype(float)})\n    prediction_df = prediction_df.append(df)","3e33676c":"display(prediction_df.head())\nprediction_df.to_csv('submission.csv', index=False)\nos.listdir('.')","f2b23e83":"# Display ROC Curve on Validation Data Set:","e6e8093d":"## Load Data into RAM","41f33225":"We see, the label distribution in our validation set is skewed towards label 0","7102f99a":"# Display Learning Curves of Training","b6721308":"## Loading Libraries","be957428":"## Save network parameters","d560ef78":"## Why Use AUC instead of Accuracy?","2884a2f1":"# Training Routine","aa5994a5":"## Hyperparameter settings","9c4f3ab4":"# Prepare for Training\n## AUC score calculation","7ec5f116":"# Predict for submission file","3cac4edd":"# Training the model","71bf2960":"## Helper functions\n### Timing","e3f69e94":"# Model\n## DenseNet121 Architecture\n\n![image.png](attachment:image.png)","33fdba13":"# Data preparation\n## Set directories and train\/validaton split","51362cc7":"<a href=\"submission.csv\"> Download submission-file <\/a>\n \n<a href=\"swag_net2.pt\"> Download net parameters<\/a>","3f33b2e9":"## Dataset Class","0a347e14":"## Alteration of the DenseNet121","3a94fe45":"Training- and validation error are always pretty close => regularization probably not necessary","a46465f1":"## Helper function to determine input shapes at the start of the network\nWe want to fit 96x96 images into a DenseNet, which expects a 224x224 image. Therefore we replace the first few layers of the DenseNet with a convolutional block that transforms the image accordingly.","589fc690":"# Cyclic Learning Rate Class","30905c82":"### Plot learning curves"}}