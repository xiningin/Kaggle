{"cell_type":{"36d28818":"code","80aac085":"code","6ee7203e":"code","3ca1766d":"code","4f47a3c2":"code","d82af7b7":"code","ec523220":"code","9b7055f6":"code","fa172462":"code","f967800c":"code","f405a845":"code","062ffd33":"code","83add805":"code","dc228c19":"code","e0805981":"code","aaaead4e":"code","1b564864":"code","5e2b6f0c":"code","a48b1d67":"code","2201950a":"code","460dd2a3":"code","e0b4ca9c":"code","1452e80e":"code","0051ae32":"code","86e137ae":"code","3f3cd376":"code","4c4d43f9":"code","48fe61c0":"code","619f869b":"code","c5bbac6e":"code","43802e89":"code","abd98152":"code","b280eb03":"code","3d1a4031":"code","490da0c4":"code","ed1d108c":"code","1c10f03d":"code","7e28132f":"code","5536c06d":"code","30447d9d":"code","1d1a34e1":"code","b40c3023":"code","e6f9e65a":"code","fcc7b76f":"code","c3fb1bb3":"code","d05ea171":"code","f413ebeb":"code","3b691efe":"code","b6c90513":"code","ab7949d3":"code","d3ab0878":"code","80224a01":"code","8b10d491":"code","6a644262":"code","d8a61476":"code","1c480dfc":"code","2f59fbf5":"code","6f810a7e":"code","4619909a":"code","c9843fca":"markdown","a771146a":"markdown","bac4bcb8":"markdown","a4d1aade":"markdown","dbc79e16":"markdown","0c70d424":"markdown","7801723c":"markdown","957cb78a":"markdown","43adf89f":"markdown","4233cc72":"markdown","3fb10d57":"markdown","1948b7d8":"markdown","bad1538e":"markdown","22c7c0ee":"markdown","a486f5ea":"markdown","926da6d6":"markdown","dcc45d85":"markdown","ac70488b":"markdown","87c869b0":"markdown","84773c48":"markdown","59ccebd0":"markdown","64a42663":"markdown","4e9ddbc6":"markdown","a1e32619":"markdown","6a589d35":"markdown","6ab69539":"markdown","12b048ca":"markdown","02fbf63c":"markdown","17a9d22f":"markdown","fd2d668b":"markdown","4d692353":"markdown","3a394da5":"markdown"},"source":{"36d28818":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","80aac085":"df = pd.read_csv(\"..\/input\/adult-census-income\/adult.csv\")\ndf.columns = df.columns.str.replace(\" \",\"\")","6ee7203e":"df.head()","3ca1766d":"df.info()","4f47a3c2":"df.describe().T","d82af7b7":"df.isna().values.any()","ec523220":"for sutun_adi in df.columns:\n    print(\"{} s\u00fctundaki benzersiz de\u011ferler\".format(sutun_adi))\n    print(\"{}\".format(df[sutun_adi].unique()),\"\\n\")","9b7055f6":"df[\"native.country\"] = df[\"native.country\"].apply(str.strip).replace(\"?\",np.nan)\nliste_1 =df[\"native.country\"]\n\nfor i in range(0,len(liste_1)):\n    if pd.isnull(liste_1[i]):\n        liste_1[i] = liste_1[i-1]\n        \ndf[\"native.country\"].unique()        \n                ","fa172462":"df[\"occupation\"] = df[\"occupation\"].apply(str.strip).replace(\"?\",np.nan)\n\nliste_2 =df[\"occupation\"]\n\nfor i in range(0,len(liste_2)):\n    if pd.isnull(liste_2[i]):\n        liste_2[i] = liste_2[i+1]\n        \ndf[\"occupation\"].unique() ","f967800c":"df[\"workclass\"] = df[\"workclass\"].apply(str.strip).replace(\"?\",np.nan)\nliste_3 =df[\"workclass\"]\n\nfor i in range(0,len(liste_3)):\n    if pd.isnull(liste_3[i]):\n        liste_3[i] = liste_3[i+1]\n        \ndf[\"workclass\"].unique() ","f405a845":"plt.figure(figsize=(19,12))\n\n\nnum_feat = df.select_dtypes(include=['int64']).columns\n\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.boxplot(df[num_feat[i]])\n    plt.title(num_feat[i],color=\"g\",fontsize=20)\n    plt.yticks(fontsize=14)\n    plt.xticks(fontsize=14)\n\n\nplt.show()","062ffd33":"from scipy.stats.mstats import winsorize\ndf[\"age\"]           = winsorize(df[\"age\"],(0,0.15))\ndf[\"fnlwgt\"]        = winsorize(df[\"fnlwgt\"],(0,0.15))\ndf[\"capital.gain\"]  = winsorize(df[\"capital.gain\"],(0,0.099))\ndf[\"capital.loss\"]  = winsorize(df[\"capital.loss\"],(0,0.099))\ndf[\"hours.per.week\"]= winsorize(df[\"hours.per.week\"],(0.12,0.18))","83add805":"plt.rcParams['figure.figsize'] = (25,7)\n\nbaslik_font = {'family':'arial','color':'purple','weight':'bold','size':25}\n\ncol_list=['age',\"fnlwgt\",'capital.gain', 'capital.loss', 'hours.per.week']\n\nfor i in range(5):\n    plt.subplot(1,5,i+1)\n    plt.boxplot(df[col_list[i]])\n    plt.title(col_list[i],fontdict=baslik_font)\n\nplt.show()","dc228c19":"con_var=['age', 'fnlwgt', 'education.num','hours.per.week']","e0805981":"plt.figure(figsize=(15,10))\nplt.subplot(221)\n\ni=0\nfor x in con_var:\n    plt.subplot(2, 2, i+1)\n    i += 1\n    ax1=sns.kdeplot(df[df['income'] == '<=50K'][x], shade=True,label=\"income <=50K\")\n    sns.kdeplot(df[df['income'] == '>50K'][x], shade=False,label=\"income   >50K\", ax=ax1)\n    plt.title(x,fontsize=15)\n\nplt.show()","aaaead4e":"plt.figure(figsize=(15,7))\n\ndeg=[\"race\",\"sex\"]\n\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    sns.countplot(x=deg[i],data=df,hue='income')\n    plt.xlabel(deg[i],color=\"darkorange\",fontsize=18)\n    plt.ylabel(\"Count\",color=\"darkorange\",fontsize=18)\n    plt.yticks(fontsize=13)\n    plt.xticks(rotation=90,fontsize=13)\n\nplt.show()","1b564864":"plt.figure(figsize=(15,7))\n\ndeg=[\"occupation\",\"hours.per.week\"]\n\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    sns.countplot(x=deg[i],data=df,hue=\"income\")\n    plt.xlabel(deg[i],color=\"darkorange\",fontsize=20)\n    plt.ylabel(\"Count\",color=\"darkorange\",fontsize=20)\n    plt.yticks(fontsize=13)\n    plt.xticks(rotation=90,fontsize=13)\n\nplt.show()","5e2b6f0c":"plt.figure(figsize=(16,7))\n\ndeg=[\"education\",\"education.num\"]\n\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    sns.countplot(x=deg[i],data=df,hue=\"income\")\n    plt.xlabel(deg[i],color=\"darkorange\",fontsize=20)\n    plt.ylabel(\"Count\",color=\"darkorange\",fontsize=20)\n    plt.yticks(fontsize=13)\n    plt.xticks(rotation=90,fontsize=13)\n\nplt.show()","a48b1d67":"plt.figure(figsize=(16,7))\n\ndeg = [\"relationship\",\"marital.status\"]\n\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    sns.countplot(x=deg[i],data=df,hue=\"income\")\n    plt.xlabel(deg[i],color=\"darkorange\",fontsize=18)\n    plt.ylabel(\"Count\",color=\"darkorange\",fontsize=18)\n    plt.xticks(rotation=90,fontsize=15)\n    plt.yticks(fontsize=15)\n\nplt.show()    ","2201950a":"plt.figure(figsize=(13,10))\nsns.countplot(x=df[\"native.country\"],data=df)\nplt.xlabel(\"native.country\",color=\"purple\",fontsize=20)\nplt.ylabel(\"Count\",color=\"purple\",fontsize=20)\nplt.xticks(rotation=90,fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","460dd2a3":"list=['age','education.num',\"hours.per.week\",\"fnlwgt\"]","e0b4ca9c":"plt.figure(figsize=(12,7))\nsns.heatmap(df[list].corr(),annot=True, fmt = \".2f\", cmap = \"YlGnBu\")\nplt.title(\"Correlation Matrix\",color=\"darkblue\",fontsize=20)\nplt.show()","1452e80e":"df[\"woman?\"]  = df.sex.replace({\"Female\":1,\"Male\":0})\ndf[\"income_\"] = df.income.replace({\"<=50K\":0,\">50K\":1})","0051ae32":"df1 = pd.get_dummies(df['workclass'])\ndf2 = pd.get_dummies(df[\"education\"])\ndf3 = pd.get_dummies(df[\"marital.status\"])\ndf4 = pd.get_dummies(df[\"occupation\"])\ndf5 = pd.get_dummies(df[\"relationship\"])\ndf6 = pd.get_dummies(df[\"race\"])\ndf7 = pd.get_dummies(df[\"native.country\"])\n\ndf  = pd.concat([df,df1,df2,df3,df4,df5,df6,df7],axis=1)","86e137ae":"df.head()","3f3cd376":"plt.figure(figsize=(7,5))\nsns.countplot(df[\"income_\"])\nplt.xlabel(\"\u0130ncome Case\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nprint(\">50K  rate : %{:.2f}\".format(sum(df[\"income_\"])\/len(df[\"income_\"])*100))\nprint(\"<=50K rate : %{:.2f}\".format((len(df[\"income_\"])-sum(df[\"income_\"]))\/len(df[\"income_\"])*100))","4c4d43f9":"y = df[\"income_\"]\nX = df[['age','hours.per.week',\"fnlwgt\",\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]","48fe61c0":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)","619f869b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\nmodel_1_predict_model = LogisticRegression(penalty='l2')\nmodel_1_predict_model.fit(X_train,y_train)\n\npredict_train_1 = model_1_predict_model.predict(X_train)\npredict_test_1  = model_1_predict_model.predict(X_test)","c5bbac6e":"from sklearn.metrics import classification_report,precision_recall_fscore_support\n\nprint(\"Model's Accuracy values       :\",model_1_predict_model.score(X_test,y_test))\nprint(\"Model's Train f1_score values :\",f1_score(y_train,predict_train_1))\nprint(\"Model's Test  f1_score values :\",f1_score(y_test,predict_test_1),\"\\n\")\n\nprint(classification_report(y_test,predict_test_1),\"\\n\")\n\nmetrics_1 =precision_recall_fscore_support(y_test,predict_test_1)\n\nprint(\"Precision:\",metrics_1[0])\nprint(\"Recall   :\",metrics_1[1])\nprint(\"F1 Skoru :\",metrics_1[2])","43802e89":"from sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns","abd98152":"model_1_predict_test_proba = model_1_predict_model.predict_proba(X_test)[:,1]\n\nfpr, tpr, thresholds  = roc_curve(y_test,model_1_predict_test_proba )\n\nconfusion_matrix_test = confusion_matrix(y_test,predict_test_1)\n\nplt.figure(figsize=(15,7))\nplt.subplot(1,2,1)\nsns.heatmap(confusion_matrix_test,annot=True,cmap=\"YlGnBu\")\nplt.title(\"Confusion Matrix\",fontsize=15)\nplt.xlabel(\"Predicted\",fontsize=14)\nplt.ylabel(\"Actual\",fontsize=14)\n\n\n# Plot ROC curve\nplt.subplot(1,2,2)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate',fontsize=14)\nplt.ylabel('True Positive Rate',fontsize=14)\nplt.title('ROC Curve',fontsize=15)\nplt.show()\nprint(\"\\n\",\"\\n\",'AUC De\u011feri : ', roc_auc_score(y_test,model_1_predict_test_proba ))","b280eb03":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\nmodel_2_predict_model = LogisticRegression(penalty='l1')\nmodel_2_predict_model.fit(X_train,y_train)\n\npredict_train_2 = model_2_predict_model.predict(X_train)\npredict_test_2  = model_2_predict_model.predict(X_test)","3d1a4031":"from sklearn.metrics import classification_report,precision_recall_fscore_support\n\nprint(\"Model's Accuracy values       :\",model_2_predict_model.score(X_test,y_test))\nprint(\"Model's Train f1_score values :\",f1_score(y_train,predict_train_2))\nprint(\"Model's Test  f1_score values :\",f1_score(y_test,predict_test_2),\"\\n\")\n\nprint(classification_report(y_test,predict_test_2),\"\\n\")\n\nmetrics_2 =precision_recall_fscore_support(y_test,predict_test_2)\n\nprint(\"Precision:\",metrics_2[0])\nprint(\"Racall   :\",metrics_2[1])\nprint(\"F1 Skoru :\",metrics_2[2])","490da0c4":"from sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ed1d108c":"model_2_predict_test_proba = model_2_predict_model.predict_proba(X_test)[:,1]\n\nfpr, tpr, thresholds  = roc_curve(y_test,model_2_predict_test_proba )\n\nconfusion_matrix_test_2 = confusion_matrix(y_test,predict_test_2)\n\nplt.figure(figsize=(15,7))\nplt.subplot(1,2,1)\nsns.heatmap(confusion_matrix_test,annot=True,cmap=\"YlGnBu\")\nplt.title(\"Confusion Matrix\",fontsize=15)\nplt.xlabel(\"Predicted\",fontsize=14)\nplt.ylabel(\"Actual\",fontsize=14)\n\n\n# Plot ROC curve\nplt.subplot(1,2,2)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\n\nprint('AUC Values : ', roc_auc_score(y_test,model_2_predict_test_proba ))","1c10f03d":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import f1_score","7e28132f":"def make_model(X,y):\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=111,stratify=y)\n    logistic_model = LogisticRegression()\n    logistic_model.fit(X_train,y_train)\n    \n    predict_train = logistic_model.predict(X_train)\n    predict_test = logistic_model.predict(X_test)\n    confusion_matrix_train = confusion_matrix(y_train,predict_train)\n    confusion_matrix_test  = confusion_matrix(y_test,predict_test)\n    \n    print(\"Model's Accuracy values       :\",logistic_model.score(X_test,y_test))\n    print(\"Model's Train f1_score values :\",f1_score(y_train,predict_train))\n    print(\"Model's Test  f1_score values :\",f1_score(y_test,predict_test),\"\\n\")\n    print(\"TEST DATA SET\")\n    print(classification_report(y_test,predict_test))\n    \n    metrics =precision_recall_fscore_support(y_test,predict_test)\n\n    print(\"Precision:\",metrics[0])\n    print(\"Racall   :\",metrics[1])\n    print(\"F1 Skoru :\",metrics[2])\n    \n    return None\n","5536c06d":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns","30447d9d":"def draw_graphic(X,y):\n    \n    \n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=111,stratify=y)\n    logistic_model = LogisticRegression()\n    logistic_model.fit(X_train,y_train)\n    \n    predict_train = logistic_model.predict(X_train)\n    predict_test = logistic_model.predict(X_test)\n    confusion_matrix_train = confusion_matrix(y_train,predict_train)\n    confusion_matrix_test  = confusion_matrix(y_test,predict_test)\n    \n    logistic_model_predict_test_proba = logistic_model.predict_proba(X_test)[:,1]\n\n    fpr, tpr, thresholds  = roc_curve(y_test,logistic_model_predict_test_proba )\n\n    confusion_matrix_test = confusion_matrix(y_test,predict_test)\n\n    plt.figure(figsize=(15,7))\n    plt.subplot(1,2,1)\n    sns.heatmap(confusion_matrix_test,annot=True,cmap=\"YlGnBu\")\n    plt.title(\"Confusion Matrix\",fontsize=15)\n    plt.xlabel(\"Predicted\",fontsize=14)\n    plt.ylabel(\"Actual\",fontsize=14)\n\n    plt.subplot(1,2,2)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fpr, tpr)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show()\n\n    print('AUC Values : ', roc_auc_score(y_test,logistic_model_predict_test_proba))","1d1a34e1":"from sklearn.utils import resample","b40c3023":"positive = df[df.income_==1]\nnegative = df[df.income_==0]\n\npositive_increase = resample(positive,\n                              replace = True,\n                              n_samples = len(negative),\n                              random_state = 111)\nincrease_df = pd.concat([negative,positive_increase])\nincrease_df.income.value_counts()","e6f9e65a":"X = increase_df[['age','fnlwgt','hours.per.week',\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]\n\ny = increase_df[\"income_\"]\n\nmake_model(X,y)","fcc7b76f":"draw_graphic(X,y)","c3fb1bb3":"from sklearn.utils import resample","d05ea171":"positive = df[df.income_==1]\nnegative = df[df.income_==0]\n\npositive_decrease = resample(negative,\n                              replace = True,\n                              n_samples = len(positive),\n                              random_state = 111)\ndecrease_df = pd.concat([positive,positive_decrease])\ndecrease_df.income.value_counts()","f413ebeb":"X = decrease_df[['age','fnlwgt', 'hours.per.week',\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]\n\ny = decrease_df[\"income_\"]\nmake_model(X,y)","3b691efe":"draw_graphic(X,y)","b6c90513":"from imblearn.over_sampling import SMOTE","ab7949d3":"y = df[\"income_\"]\nX = df[['age','fnlwgt','hours.per.week',\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]\n\nsm = SMOTE(random_state=27,ratio = 1.0)\nX_smote, y_smote = sm.fit_sample(X,y)","d3ab0878":"make_model(X_smote,y_smote)","80224a01":"draw_graphic(X_smote,y_smote)","8b10d491":"from imblearn.over_sampling import ADASYN","6a644262":"y = df[\"income_\"]\nX = df[['age','fnlwgt','hours.per.week',\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]\n\nad = ADASYN()\nX_adasyn,y_adasyn = ad.fit_sample(X,y)","d8a61476":"make_model(X_adasyn,y_adasyn)","1c480dfc":"draw_graphic(X_adasyn,y_adasyn)","2f59fbf5":"result = pd.DataFrame(columns = [\"Models\",\"Train f1 Score\",\"Test f1 Score\"])\nresult[\"Models\"]              = [\"Model 1\",\"Model 2\",\"Oversampling\",\"Undersampling\",\"Model Smote\",\"Model Adasyn\"]\nresult[\"Train f1 Score\"]      = [0.0,0.6369504535938589, 0.8191137970688263,0.8098272552783109,\n                                 0.88746921182266,0.8692412954234453]\nresult[\"Test f1 Score\"]       = [0.0,0.6122153957354536,0.8202595390276971,0.823673719717878,\n                                 0.881661041219188,0.8633108039947545]\nresult[\"Accuracy values\"]     = [0.7640104406571473,0.8352525717795178,0.8122977346278317,0.8167038571883966,\n                                 0.8829894822006472,0.8629790676509252]\nresult[\"AUC Values\"]          = [0.5008798249816425,0.8876067714489535,0.887471722122726,0.8921330123827734,\n                                 0.9574314032372933,0.9437558082270674]","6f810a7e":"result","4619909a":"result = pd.DataFrame(columns = [\"Models\",\"Train f1 Score\",\"Test f1 Score\"])\nresult[\"Models\"]              = [\"Model 1\",\"Model 2\",\"Oversampling\",\"Undersampling\",\"Model Smote\",\"Model Adasyn\"]\nresult[\"Train f1 Score\"]      = [0.0,0.6369504535938589, 0.8191137970688263,0.8098272552783109,\n                                 0.88746921182266,0.8692412954234453]\nresult[\"Test f1 Score\"]       = [0.0,0.6122153957354536,0.8202595390276971,0.823673719717878,\n                                 0.881661041219188,0.8633108039947545]\n\nplt.figure(figsize = (12,8))\n\nn_groups = 6\nindex = np.arange(n_groups)\nbar_width = 0.3\nopacity = 0.7\n \nrects1 = plt.bar(index,result[\"Train f1 Score\"], bar_width,\nalpha=opacity,\ncolor='bisque',\nlabel='Train F1 Score')\n \nrects2 = plt.bar(index + bar_width,result[\"Test f1 Score\"] , bar_width,\nalpha=opacity,\ncolor='navy',\nlabel='Test F1 Score')\n \nplt.xlabel('Models',color=\"navy\",fontsize =17)\nplt.ylabel('F1 Score Values',color=\"navy\",fontsize =17)\nplt.title('Train and Test F1 Score',color=\"navy\",fontsize =18)\nplt.xticks(index + bar_width\/2, (\"Model 1\",\"Model 2\",\"Oversampling\",\"Undersampling\",\"Model Smote\",\"Model Adasyn\"),\n           rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\nplt.legend(fontsize='large')\n\nplt.tight_layout()\nplt.show()","c9843fca":"### Correlation Matrix between Numerical Values","a771146a":"### Let's get rid of the outliers by winsorization","bac4bcb8":"### And last how abaout the outliers ?","a4d1aade":"## 6.Models","dbc79e16":"### Model Adasyn","0c70d424":"\n\n# Adult Income Classification","7801723c":"## 6.Conclusions","957cb78a":"### Is there problematic values ?","43adf89f":"Of course we are against racial and gender discrimination :) ","4233cc72":"## 4. Exploring the Data","3fb10d57":"### Contents\n\n### 1. Introduction\n\n### 2. General View of the Data\n\n### 3. Data Cleaning\n\n### 4. Exploring the Data\n\n### 5.Models\n\n### 6.Conclusions ","1948b7d8":"### Let's start by importing libraries","bad1538e":"__%24.08 of the data in the data set is classified as positive.Therefore we can say that the data set is not balanced.__","22c7c0ee":"### Oversampling","a486f5ea":" **Columns**\n* age \n* workclass \n* fnlwgt \n* education \n* education-num \n* marital-status \n* occupation\n* relationship \n* race \n* sex \n* capital-gain \n* capital-loss \n* hours-per-week \n* native-country \n* income ","926da6d6":"## 3. Data Cleaning","dcc45d85":"We prefer models's f1 score values instead of accuracy values because data set is not balanced.\nWhen sorting the models,we pay attention that the overfitting is low and the test f1 score is high.if we sort it \naccording to this,we get the following ranking:\n\n1.Model Smote\n\n2.Model Adasyn\n\n3.Undersampling\n\n4.Oversampling\n\n5.Model2\n\n6.Model1\n","ac70488b":"## 1. Introduction","87c869b0":"### Model Smote","84773c48":"## 5. Feature Engineering","59ccebd0":"## 2. General View of the Data","64a42663":"### Model 1","4e9ddbc6":"## Classification Project","a1e32619":" __Categorical Variables__\n \n \n * sex \n * race\n * income\n * workclass         \n * education\n * occupation\n * relationship \n * marital-status    \n * native-country          \n    \n  __Continuous Variables__\n  \n\n * age\n * fnlwgt \n * capital-loss\n * capital-gain\n * education-num \n * hours-per-week","6a589d35":"Our aim in this project is to predict classification by income.The prediction task is to determine whether a person makes over $50K a year.This data used was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker.A set of reasonably clean records was extracted using following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)).\n","6ab69539":"### Is there missing data ?","12b048ca":"### Continuous Variables's Distribution Graphs about Income","02fbf63c":"### Imbalanced Data","17a9d22f":"### Categorical Variables's Graphs by Count Plot about \u0130ncome","fd2d668b":"### Viewing Data","4d692353":"### Model 2","3a394da5":"### Undersampling"}}