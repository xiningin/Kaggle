{"cell_type":{"d12743cd":"code","a48f5f68":"code","01c31eca":"code","4e1c5cb5":"code","c4fc28cf":"code","fcf69c80":"code","2b75bf95":"code","83bec35e":"code","02a382d9":"code","7d97d6b4":"code","7e783f5a":"code","e2e9f431":"code","b984861a":"code","1f5e7f94":"code","59c0bace":"markdown","873a97a5":"markdown","8c48dde2":"markdown","fbee8576":"markdown","04102d78":"markdown","06766278":"markdown","5108144f":"markdown","4ebea055":"markdown","79fdc977":"markdown","26930d45":"markdown","0633fedc":"markdown"},"source":{"d12743cd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","a48f5f68":"train_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","01c31eca":"train_df[train_df[\"target\"] == 0][\"text\"].values[1]","4e1c5cb5":"train_df[train_df[\"target\"] == 1][\"text\"].values[1]","c4fc28cf":"from sklearn import feature_extraction, linear_model, model_selection, preprocessing","fcf69c80":"count_vectorizer = feature_extraction.text.CountVectorizer() # this is our Vectorizer model.","2b75bf95":"## In this cell, we get the counts for the first 5 tweets in our training data.\nexp_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])","83bec35e":"## We use .todense() to turn sparse into dense.\n## The reason for this is because sparse only keeps non-zero indexes to save space.\nprint(exp_train_vectors[0].todense().shape)\nprint(exp_train_vectors[0].todense())","02a382d9":"train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\ntest_vectors = count_vectorizer.transform(test_df[\"text\"])","7d97d6b4":"## Since our vectors are too big, we want to push our model weights\n## towards 0 without decreasing all different words.\n## Ridge Regression is an effective way for this.\nclf = linear_model.RidgeClassifier()","7e783f5a":"scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\nscores","e2e9f431":"clf.fit(train_vectors,train_df[\"target\"]) ## we fit our training data and vectors","b984861a":"test_pred = pd.Series(clf.predict(test_vectors),name=\"target\").astype(int)\nresults = pd.concat([test_df[\"id\"],test_pred],axis=1)\nresults.head()","1f5e7f94":"results.to_csv(\"submission.csv\",index=False)","59c0bace":"* That tuple tells us that there are 54 words in the first 5 words in our training data.\n* That list tells us the unique words in our first tweet.All indexes in that list are words in our first 5 tweets. The non-zero indexes are in our first tweet.\n* Since this was an example, we aren't going to use these vectors. Let's build the real one.","873a97a5":"* As we can see here, we read an example of the irrelevant tweets.\n* After this, we will get an example of relevant tweets.","8c48dde2":"## Understanding from words <a id=\"2\"><\/a>\n* Actually, the logic is too simple.\n* The words in our tweets are going to tell if a tweet is fake or not in substance.\n* After here, we are going to use the precious library of Python, which is named as sklearn.\n* We will get our words, and turn them into the data which our ML model can process.","fbee8576":"* As we can see here, this example is relevant to a forest fire,which is a disaster.","04102d78":"# Disaster in Tweets with NLP\nThese days, there are lots of **fake tweets** about disaster and alike subjects. <br>\nIn this competition, we will build a ML model which **predicts if a disaster announcement tweet is real or fake**. <br>\nWe will use a precious ML algorithm for these prediction, which is named as **NLP (Natural Language Processing).** <br>\n\n1. [Dataset import and preview](#1)\n2. [Understanding from words](#2)\n3. [Modeling](#3)\n4. [Prediction and submission](#4)","06766278":"## Modeling <a id=\"3\"><\/a>\n* As you can see above, we mentioned that the words in our tweets are going to tell if a tweet is real or not.\n* Particular words in our tweet might make a sign if that tweet is real or fake.\n* We suppose that we have a linear connection here, so we are going to build a linear model.","5108144f":"## Prediction and submission <a id=\"4\"><\/a>","4ebea055":"* Now, we will test our model's performance on training data.\n* For this test, we will be using Cross Validation.\n* Cross Validation is when we train a part of our data, and validate it with the left part of our data.\n* If we do cross validation more than one times, we will have a better view on how a particular model performs.","79fdc977":"## Dataset import and preview <a id=\"1\"><\/a>","26930d45":"* We select our model, we get our vectors, and we cross-validate it three times.\n* Our scores might seem terrible to you, but actually they are not.\n* This shows us that our model will score around 0.64 in the leaderboard.","0633fedc":"* Some of the tweets might be irrelevant to disasters.\n* We will check these tweets first."}}