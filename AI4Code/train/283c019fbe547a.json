{"cell_type":{"531b5819":"code","2c392f73":"code","0b552012":"code","6b70febe":"code","a03d3bb0":"code","86649113":"code","c5ace81a":"code","7c9fd257":"code","5620d102":"code","59da7663":"code","be99992c":"markdown"},"source":{"531b5819":"!python --version","2c392f73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report\nimport pickle\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b552012":"## loading datasets\ntrain_df = pd.read_csv('\/kaggle\/input\/quora-question-keyword-pairs\/train.tsv', sep='\\t')\ndev_df = pd.read_csv('\/kaggle\/input\/quora-question-keyword-pairs\/dev.tsv', sep='\\t')\ntest_df = pd.read_csv('\/kaggle\/input\/quora-question-keyword-pairs\/test.tsv', sep='\\t')\n\ntrain_df.shape, dev_df.shape, test_df.shape","6b70febe":"## inspect train set\ntrain_df.head()","a03d3bb0":"## sampling only first 10k train samples to bootstrap a quick test.\ntrain_text = train_df['query'].values[:10000]\ntest_text = test_df['query'].values\n\n## TF-IDF based features\nvectorizer = TfidfVectorizer(ngram_range=(1,3), \n                             min_df=0.001, \n                             max_df=0.7, \n                             analyzer='word')\n\nX_train = vectorizer.fit_transform(train_text)\nX_test = vectorizer.transform(test_text)\n\n\ny_train = train_df.target.values[:10000]\ny_test = test_df.target.values\n## TODO:\n## can be improved with cross validation to improve generalization\n##gb = GradientBoostingClassifier(n_estimators = 400, random_state=0)\n\n\n##gb.fit(X_train, y_train)","86649113":"predictions_rf = gb.predict(X_test)\n\n## f1 score of 99% comparative to attention based model\nprint(classification_report(y_test, predictions_rf))","c5ace81a":"\n\nwith open('query_classifier.pickle', 'wb') as handle:\n    pickle.dump(gb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","7c9fd257":"\nwith open('query_vectorizer.pickle', 'wb') as handle:\n    pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","5620d102":"import urllib\nquery_vectorizer_spaadia_squad = pickle.load(\n            urllib.request.urlopen(\n                \"https:\/\/raw.githubusercontent.com\/shahrukhx01\/ocr-test\/main\/query_vectorizer.pickle\"))\nquery_classifier_spaadia_squad = pickle.load(\n            urllib.request.urlopen(\n                \"https:\/\/raw.githubusercontent.com\/shahrukhx01\/ocr-test\/main\/query_classifier.pickle\"))","59da7663":"test_text = test_df['query'].values\nX_test = query_vectorizer_spaadia_squad.transform(test_text)\npredictions_rf = query_classifier_spaadia_squad.predict(X_test)\n\n## f1 score of 99% comparative to attention based model\nprint(classification_report(y_test, predictions_rf))","be99992c":"# Testing SPAADIA\/SQUAD BASED CLASSIFIER ON QUORA DATASET"}}