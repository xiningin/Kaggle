{"cell_type":{"704a82e9":"code","354aa2d2":"code","905d164a":"code","dd0e6681":"code","9aea658e":"code","b2043c38":"code","7b6d6167":"code","408b0786":"code","589e7e06":"code","218738de":"code","c653f65b":"code","8e74b97e":"code","dd633275":"code","4caa1cbc":"code","c192abac":"code","83ebeb9d":"code","4aa7c0f2":"code","93bd40d3":"code","0f3a7631":"code","22226641":"code","4342ec04":"code","ddf8b8d1":"code","2120f7ae":"code","98de2c6d":"code","26c2387c":"code","a96321d2":"code","b949c7d8":"code","8dd819b2":"code","b3ea0cc6":"code","e4e2e772":"code","37528128":"code","ccb88a46":"code","49cf127e":"markdown"},"source":{"704a82e9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nsns.set()","354aa2d2":"\ndf_train = pd.read_csv('\/kaggle\/input\/ods-mlclass-dubai-2019-03-lecture3-hw\/train.csv')\nprint(df_train.shape)\n\n\ndf_test = pd.read_csv('\/kaggle\/input\/ods-mlclass-dubai-2019-03-lecture3-hw\/test.csv')\nprint(df_test.shape)","905d164a":"df_train.head()","dd0e6681":"df_test['target'] = np.nan\ndf = pd.concat([df_train, df_test])","9aea658e":"#Data analyzing\nNumeric_features = [\n    'age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n    'hours-per-week', 'target'\n]\nCategorical_features = [\n    'workclass', 'education', 'marital-status', 'occupation', 'relationshop',\n    'race', 'sex', 'native-country'\n]","b2043c38":"sns.countplot(df['target'], label=\"Count\")","7b6d6167":"#Check correlation\nplt.figure(figsize=(12, 4))\nsns.heatmap(df[Numeric_features].corr(), annot=True, cmap='Greens')","408b0786":"graphs = sns.FacetGrid(df, col='target')\ngraphs = graphs.map(sns.distplot, 'age')","589e7e06":"df_tmp = df.loc[df['target'].notna()].groupby(['education'])['target'].agg(\n    ['mean', 'std']).rename(columns={\n        'mean': 'target_mean',\n        'std': 'target_std'\n    }).fillna(0.0).reset_index()","218738de":"df = pd.merge(df, df_tmp, how='left', on=['education'])","c653f65b":"#Feature Enginering\ndf.head()","8e74b97e":"df['sex'].unique()","dd633275":"df['race'].unique()","4caa1cbc":"df['sex'] = df['sex'].replace(' Male', 0)\ndf['sex'] = df['sex'].replace(' Female', 1)","c192abac":"married = [i for i in df['marital-status'].unique() if i[:8] == ' Married']\nalone = [i for i in df['marital-status'].unique() if i not in married]","83ebeb9d":"df['marital-status'] = df['marital-status'].replace(married, 1)\ndf['marital-status'] = df['marital-status'].replace(alone, 0)","4aa7c0f2":"df['marital-status'].unique()","93bd40d3":"df.head()","0f3a7631":"df.drop(columns=[\n    'uid', 'workclass', 'occupation','education', 'relationship', 'race', 'native-country'\n],\n        inplace=True)","22226641":"df.head()","4342ec04":"our_x_train = df.loc[df['target'].notna()].drop(columns=['target'])\nour_y_train = df.loc[df['target'].notna()]['target']\nour_x_test = df.loc[df['target'].isna()].drop(columns=['target'])\nour_y_test = df.loc[df['target'].isna()]['target']","ddf8b8d1":"X_train, X_test, y_train, y_test = train_test_split(our_x_train,\n                                                    our_y_train,\n                                                    test_size=0.33,\n                                                    random_state=17)","2120f7ae":"plt.figure(figsize=(15, 10))\n\n#critetion\nplt.subplot(3, 3, 1)\nfeature_param = ['gini', 'entropy']\nscores = []\nfor feature in feature_param:\n    clf = DecisionTreeClassifier(criterion=feature)\n    clf.fit(X_train, y_train)\n    scores.append(clf.score(X_test, y_test))\nplt.plot(feature_param, scores, '.-')\nplt.axis('tight')\nplt.title('Criterion')\nplt.grid()\n\n#max_depth\nplt.subplot(3, 3, 2)\nmax_depth_check = range(1, 30)\nscores = []\nfor depth in max_depth_check:\n    clf = DecisionTreeClassifier(max_depth=depth)\n    clf.fit(X_train, y_train)\n    scores.append(clf.score(X_test, y_test))\nplt.plot(max_depth_check, scores, '.-')\nplt.axis('tight')\nplt.title('Depth')\nplt.grid()\n\n#Splitter\nplt.subplot(3, 3, 3)\nfeature_param = ['best', 'random']\nscores = []\nfor feature in feature_param:\n    clf = DecisionTreeClassifier(splitter=feature)\n    clf.fit(X_train, y_train)\n    scores.append(clf.score(X_test, y_test))\nplt.plot(feature_param, scores, '.-')\nplt.axis('tight')\nplt.title('Splitter')\nplt.grid()\n\n#Min Samples Leaf\nplt.subplot(3, 3, 4)\nfeature_param = range(2, 21)\nscores = []\nfor feature in feature_param:\n    clf = DecisionTreeClassifier(min_samples_leaf=feature)\n    clf.fit(X_train, y_train)\n    scores.append(clf.score(X_test, y_test))\nplt.plot(feature_param, scores, '.-')\nplt.axis('tight')\nplt.title('Min Samples Leaf')\nplt.grid()\n\n#Min Samples Split\nplt.subplot(3, 3, 5)\nfeature_param = range(2, 21)\nscores = []\nfor feature in feature_param:\n    clf = DecisionTreeClassifier(min_samples_split=feature)\n    clf.fit(X_train, y_train)\n    scores.append(clf.score(X_test, y_test))\nplt.plot(feature_param, scores, '.-')\nplt.axis('tight')\nplt.title('Min Samples Split')\nplt.grid()\n\n#max_features\nplt.subplot(3, 3, 6)\nfeature_param = range(1, df.shape[1])\nscores = []\nfor feature in feature_param:\n    clf = DecisionTreeClassifier(max_features=feature)\n    clf.fit(X_train, y_train)\n    scores.append(clf.score(X_test, y_test))\nplt.plot(feature_param, scores, '.-')\nplt.axis('tight')\nplt.title('Max Features')\nplt.grid()","98de2c6d":"model = DecisionTreeClassifier(criterion='gini',\n                               splitter='best',\n                               max_depth=10,\n                               max_features=5,\n                               min_samples_split=40,\n                               min_samples_leaf=12)\nparameter_grid = {\n    'max_depth': range(5, 15),\n    'max_features': range(1, 9),\n    'min_samples_split': [35, 40, 45, 50],\n    'min_samples_leaf': [5, 10, 15, 20],\n}\ngrid_search = GridSearchCV(model, param_grid=parameter_grid, cv=5)\ngrid_search.fit(X_train, y_train)","26c2387c":"print(f'Best score: {grid_search.best_score_}')\nprint(f'Best parameters: {grid_search.best_params_}')\nprint(accuracy_score(y_test, grid_search.predict(X_test)))","a96321d2":"tree_cl = DecisionTreeClassifier(criterion='gini',\n                               splitter='best',\n                               max_depth=8,\n                               max_features=6,\n                               min_samples_split=45,\n                               min_samples_leaf=10)\ntree_cl.fit(X_train,y_train)\ntree_cl.score(X_test,y_test)","b949c7d8":"tree_cl.predict(our_x_test)","8dd819b2":"p = tree_cl.predict_proba(our_x_test)[:,1]","b3ea0cc6":"%matplotlib inline\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"dark\")","e4e2e772":"sns.distplot(p)","37528128":"df_submit = pd.DataFrame({\n    'uid': df_test['uid'],\n    'target': p\n})","ccb88a46":"df_submit.to_csv('submit.csv', index=False)","49cf127e":"Cross - Validation\n"}}