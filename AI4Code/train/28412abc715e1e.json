{"cell_type":{"0d89d234":"code","bd6f13ba":"code","f16d9a46":"code","ae2acb10":"code","6af5dca5":"code","3aff4b89":"code","b71a4b58":"code","ad244a78":"code","22c86d87":"code","631891ab":"code","2a945dc1":"code","8953041f":"code","445337c3":"code","03be9b48":"code","37ca2ed8":"code","50d7a2bc":"code","31aacc7a":"code","763f19b1":"markdown","3f5fca7e":"markdown","e146d487":"markdown","552a7c05":"markdown","1fdbd322":"markdown","9db2ff38":"markdown","5edf85c9":"markdown","4d76f1af":"markdown","54493ebb":"markdown","be0f18e8":"markdown","3b8321ad":"markdown"},"source":{"0d89d234":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nmainpath = '..\/input\/nih-chest-xrays-tfrecords\/'\ndatadir = os.path.join(mainpath,'data')\ncsvpath = os.path.join(mainpath,'preprocessed_data.csv')\n\nprint(f'Image Data : {datadir}')\nprint(f'CSV file : {csvpath}')\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd6f13ba":"import tensorflow as tf\nprint(f'TensorFlow Version : {tf.__version__}')","f16d9a46":"feature_map = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'image_id': tf.io.FixedLenFeature([], tf.string),\n    'No Finding': tf.io.FixedLenFeature([], tf.int64),\n    'Atelectasis': tf.io.FixedLenFeature([], tf.int64),\n    'Consolidation': tf.io.FixedLenFeature([], tf.int64),\n    'Infiltration': tf.io.FixedLenFeature([], tf.int64),\n    'Pneumothorax': tf.io.FixedLenFeature([], tf.int64),\n    'Edema': tf.io.FixedLenFeature([], tf.int64),\n    'Emphysema': tf.io.FixedLenFeature([], tf.int64),\n    'Fibrosis': tf.io.FixedLenFeature([], tf.int64),\n    'Effusion': tf.io.FixedLenFeature([], tf.int64),\n    'Pneumonia': tf.io.FixedLenFeature([], tf.int64),\n    'Pleural_Thickening': tf.io.FixedLenFeature([], tf.int64),\n    'Cardiomegaly': tf.io.FixedLenFeature([], tf.int64),\n    'Nodule': tf.io.FixedLenFeature([], tf.int64),\n    'Mass': tf.io.FixedLenFeature([], tf.int64),\n    'Hernia': tf.io.FixedLenFeature([], tf.int64)\n}","ae2acb10":"def tfr_decoder(path, shuffle=True):\n    def image_decoder(data):\n        example = tf.io.parse_single_example(data, feature_map) \n        image = example['image']\n        image = tf.io.decode_image(image, channels=3)\n        image = tf.image.convert_image_dtype(image, tf.float32)\n        image = tf.image.resize_with_pad(image, 150, 150)\n        image.set_shape([150,150,3])\n        image = image\/255.\n        \n        print([label for label in sorted(list(example.keys())) if label!='image' and label!='image_id'])\n        labels = [tf.cast(example[x], tf.float32) for x in sorted(list(example.keys())) if x!='image_id' and x!='image']\n        \n        return image, labels\n    \n    data_list = [os.path.join(datadir,x) for x in os.listdir(path)]\n    split = int(len(data_list)*0.8)\n    train_data, val_data = data_list[:split], data_list[split:]\n    \n    trainds = tf.data.TFRecordDataset(train_data)\n    trainds = trainds.map(image_decoder, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    \n    valds = tf.data.TFRecordDataset(val_data)\n    valds = valds.map(image_decoder, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\n    if shuffle:\n        trainds = trainds.shuffle(1024)\n        \n    trainds = trainds.batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n    valds = valds.batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n    return trainds, valds","6af5dca5":"trainds, valds = tfr_decoder(datadir)\nprint(trainds)","3aff4b89":"effic = tf.keras.applications.EfficientNetB2(\n    include_top=False, weights=None,input_shape=(150,150,3), pooling='avg')\n\nincep = tf.keras.applications.InceptionV3(\n    include_top=False, weights=None, input_shape=(150,150,3), pooling='avg')\n\nmodel = tf.keras.Sequential([\n            incep,\n            tf.keras.layers.Dense(512, activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dense(128, activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dense(32, activation='relu'),\n            tf.keras.layers.Dense(15, activation='sigmoid'),\n])\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer='Adam',\n             metrics=[tf.keras.metrics.AUC(multi_label=True),'binary_accuracy'])\n\nmodel.summary()","b71a4b58":"model.fit(trainds, epochs=3)\nmodel.evaluate(valds)","ad244a78":"forecast = model.predict(valds)","22c86d87":"label_list = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', \n              'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', \n              'Pneumothorax']\ncolumns = {}\nfor label in label_list:\n    columns[label] = []\n    \nfor element in valds.as_numpy_iterator():\n    for label in element[1]:\n        for n, data in enumerate(label):\n            columns[label_list[n]].append(data)\n    \nvaldf = pd.DataFrame(columns)\nvaldf","631891ab":"Example = list(valdf.loc[valdf['Atelectasis'] == 1].head(10).index)","2a945dc1":"val_image_data = []\nfor element in valds.as_numpy_iterator():\n    for img in element[0]:\n        img = img*255.0\n        val_image_data.append(img)","8953041f":"def interpolate_images(baseline,image,alphas):\n    alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n    baseline_x = tf.expand_dims(baseline, axis=0)\n    input_x = tf.expand_dims(image, axis=0)\n    delta = input_x - baseline_x\n    images = baseline_x +  alphas_x * delta\n    return images","445337c3":"def compute_gradients(images, target_class_idx):\n    with tf.GradientTape() as tape:\n        tape.watch(images)\n        logits = model(images)\n        probs = tf.nn.softmax(logits, axis=-1)[:,target_class_idx]\n        return tape.gradient(probs, images)","03be9b48":"def integral_approximation(gradients):\n    # riemann_trapezoidal\n    grads = (gradients[:-1] + gradients[1:]) \/ tf.constant(2.0)\n    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n    return integrated_gradients","37ca2ed8":"@tf.function\ndef integrated_gradients(baseline,image,target_class_idx, m_steps=150, batch_size=64):\n    # 1. Generate alphas\n    alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps)\n\n    # Accumulate gradients across batches\n    integrated_gradients = 0.0\n\n    # Batch alpha images\n    ds = tf.data.Dataset.from_tensor_slices(alphas).batch(batch_size)\n\n    for batch in ds:\n\n        # 2. Generate interpolated images\n        batch_interpolated_inputs = interpolate_images(baseline=baseline,\n                                                   image=image,\n                                                   alphas=batch)\n\n        # 3. Compute gradients between model outputs and interpolated inputs\n        batch_gradients = compute_gradients(images=batch_interpolated_inputs, \n                                            target_class_idx=target_class_idx)\n\n        # 4. Average integral approximation. Summing integrated gradients across batches.\n        integrated_gradients += integral_approximation(gradients=batch_gradients)\n\n    # 5. Scale integrated gradients with respect to input\n    scaled_integrated_gradients = (image - baseline) * integrated_gradients\n    return scaled_integrated_gradients","50d7a2bc":"def plot_img_attributions(baseline,image,target_class_idx, m_steps=tf.constant(50),cmap=None,\n                          overlay_alpha=0.4):\n\n    attributions = integrated_gradients(baseline=baseline,image=image,target_class_idx=target_class_idx,\n                                      m_steps=m_steps)\n\n    # Sum of the attributions across color channels for visualization.\n    # The attribution mask shape is a grayscale image with height and width\n    # equal to the original image.\n    attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n\n    fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n\n    axs[0, 0].set_title('Baseline image')\n    axs[0, 0].imshow(baseline)\n    axs[0, 0].axis('off')\n\n    axs[0, 1].set_title('Original image')\n    axs[0, 1].imshow(image)\n    axs[0, 1].axis('off')\n\n    axs[1, 0].set_title('Attribution mask')\n    axs[1, 0].imshow(attribution_mask, cmap=cmap)\n    axs[1, 0].axis('off')\n\n    axs[1, 1].set_title('Overlay')\n    axs[1, 1].imshow(attribution_mask, cmap=cmap)\n    axs[1, 1].imshow(image, alpha=overlay_alpha)\n    axs[1, 1].axis('off')\n\n    plt.tight_layout()\n    return fig","31aacc7a":"baseline = tf.zeros(shape=(150,150,3))\nfor num in Example:\n    _ = plot_img_attributions(image=val_image_data[num],baseline=baseline,target_class_idx=0, m_steps=2400,\n                              cmap=plt.cm.inferno, overlay_alpha=0.4)","763f19b1":"### Check First Data from Valds and get image data from that","3f5fca7e":"### Decode TFR datafiles and decode image fromg deocded data","e146d487":"### This feature_map is followed by Orginal Dataset Guide(https:\/\/www.kaggle.com\/nickuzmenkov\/nih-chest-xrays-tfrecords) ","552a7c05":"### **Check Label's order and shape of data**","1fdbd322":"##  **This notebook is using IG for Explainable. And Basic Model is Inception v3** ","9db2ff38":"### Load Model from Keras and set pooling='avg' for setting output shape to 2D","5edf85c9":"### From here, We are going to use IG. For more information about using IG, Please check official guideline(https:\/\/www.tensorflow.org\/tutorials\/interpretability\/integrated_gradients)\n\n- target_class_idx is Number of label. for example, if you want check which pixels point Atelectasis Area, just set target_class_idx to 0. ","4d76f1af":"### **Import TensorFlow**","54493ebb":"### **Let's check using Atelectasis Example**","be0f18e8":"### **Let check which pixels are important for Model to doing classifier**","3b8321ad":"#### **Model is not good for predict :(**"}}