{"cell_type":{"1194dd49":"code","cd1ed299":"code","24277716":"code","48535a6f":"code","b02eac05":"code","1dc94b0e":"code","64a457e9":"code","f1626644":"code","1b080938":"code","6af0e24b":"code","d4c5615b":"code","26729c18":"code","581b8f3f":"code","660d4c6e":"code","435f8f64":"code","e1ef46fd":"code","5ffa8243":"code","98ab4e3a":"code","59c2e3dd":"code","bb5ec02c":"code","ec8a7634":"code","80bcfca6":"code","5dcbd25b":"code","3ee13f05":"code","de9e6e7b":"code","e708ac9b":"code","2148f221":"code","e5a525a1":"code","a73475f9":"code","9e901b52":"code","6f36e211":"code","49188c24":"code","f4d2a2df":"code","c7ed6eaf":"code","23ca903f":"code","1f52132a":"code","ae053795":"code","b0aac87b":"code","5b3a1b2e":"code","aa9ca892":"code","9d767bf8":"code","171dd700":"code","17233a92":"code","3794772e":"code","2e2cf419":"code","d7e9d24f":"code","d10d4ea9":"code","e86b569d":"code","74cadccf":"code","a37d3f96":"code","58faf592":"code","773127be":"code","be19da05":"code","86dc6cbb":"code","7f276a97":"code","75fb2fdb":"code","869d4b72":"code","b04f4d62":"code","84cf50a5":"code","d12de02b":"code","e5f0397e":"code","55e89c75":"markdown","0f96d07b":"markdown","c36eb32b":"markdown","25b23285":"markdown"},"source":{"1194dd49":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cd1ed299":"import pandas as pd","24277716":"df=pd.read_csv('\/kaggle\/input\/fake-news\/train.csv')","48535a6f":"df.shape","b02eac05":"#Drop the NAN values\ndf=df.dropna()","1dc94b0e":"#drop the label from the dataset\nX=df.drop('label',axis=1)","64a457e9":"X.head()","f1626644":"y=df['label']","1b080938":"y","6af0e24b":"\nX.shape","d4c5615b":"# y.shape\nimport numpy as np\na=np.array(y)\n\n","26729c18":"import tensorflow as tf\n","581b8f3f":"tf.__version__","660d4c6e":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","435f8f64":"messages=X.copy()","e1ef46fd":"messages['title'][0]","5ffa8243":"messages.reset_index(inplace=True)","98ab4e3a":"import nltk\nimport re\nfrom nltk.corpus import stopwords","59c2e3dd":"nltk.download('stopwords')","bb5ec02c":"from nltk.stem import WordNetLemmatizer ","ec8a7634":"wordnet=WordNetLemmatizer ()","80bcfca6":"c=[]","5dcbd25b":"for i in range(0,len(messages)):\n    p=re.sub('[^A-Za-z]',' ',messages['title'][i])\n    p=p.lower()\n    p=p.split()\n    p=[wordnet.lemmatize(word) for word in p if not word in stopwords.words('english')]\n    p=' '.join(p)\n    c.append(p)","3ee13f05":"c[0]","de9e6e7b":"voc_size=10000","e708ac9b":"onehot=[one_hot(words,voc_size)for words in c]","2148f221":"onehot","e5a525a1":"total_len=25","a73475f9":"embedding=pad_sequences(onehot,padding='pre',maxlen=total_len)","9e901b52":"embedding","6f36e211":"# len(embedding)\nembedding[0]","49188c24":"Embedding_features=50\nmodel=Sequential()\nmodel.add(Embedding(voc_size,Embedding_features,input_length=total_len))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","f4d2a2df":"len(embedding),y.shape","c7ed6eaf":"rea=pd.read_csv('\/kaggle\/input\/fake-news\/submit.csv')\n","23ca903f":"rea['label']","1f52132a":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X_final,y_final,test_size=0.33,random_state=42)\nX_train=np.array('embedding')\n","ae053795":"dff=pd.read_csv('\/kaggle\/input\/fake-news\/test.csv')","b0aac87b":"dff.shape","5b3a1b2e":"dff.id\n# dff['id']","aa9ca892":"dff=dff.fillna(' ')","9d767bf8":"mess=dff.copy()\n","171dd700":"mess['title'][0]","17233a92":"len(mess)","3794772e":"d=[]\nfor i in range(0,len(mess)):\n    q=re.sub('[^A-Za-z]',' ',mess['title'][i])\n    q=q.lower()\n    q=q.split()\n    q=[wordnet.lemmatize(word) for word in q if not word in stopwords.words('english')]\n    q=' '.join(q)\n    d.append(q)","2e2cf419":"d[0]","d7e9d24f":"onhot=[one_hot(words,voc_size)for words in d]","d10d4ea9":"onhot","e86b569d":"embeding=pad_sequences(onhot,padding='pre',maxlen=total_len)","74cadccf":"len(embeding)","a37d3f96":"import numpy as np\nX_final=np.array(embeding)\ny_final=rea['label']","58faf592":"import numpy as np\nx_train=np.array(embedding)\ny_train=np.array(y)","773127be":"# X_final.shape,y_final.shape\n# x_train.shape,y_train.shape\n# y.isnull().sum()\n# embedding\n# x_train.shape\ny_train.shape","be19da05":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.1,random_state=42)","86dc6cbb":"model.fit(x_train,a,validation_data=(X_test,y_test),epochs=50,batch_size=64)","7f276a97":"y_pred=model.predict_classes(X_final)","75fb2fdb":"# y_pred\nresult = y_pred.flatten()","869d4b72":"result","b04f4d62":"submission = pd.DataFrame({'id':dff.id, 'label':result})\nsubmission.to_csv('submission.csv', index=False)\n","84cf50a5":"from sklearn.metrics import confusion_matrix","d12de02b":"confusion_matrix(y_final,y_pred)","e5f0397e":"from sklearn.metrics import accuracy_score\naccuracy_score(y_final,y_pred)","55e89c75":"# Creating Model","0f96d07b":"Performance ","c36eb32b":"# All the sentences are of different length,to make them all of same length ,use pad_sequences,and padding is added before or after depends on our choice,it adds the number of 0 at extra place****","25b23285":"# ****Embedding Representation****"}}