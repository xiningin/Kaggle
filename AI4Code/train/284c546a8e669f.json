{"cell_type":{"e5d3dc04":"code","26df8835":"code","842af923":"code","990ce98c":"code","4b8e4f85":"code","8867fbfc":"code","5f8ac5a2":"code","2394a83a":"code","a7b8f7c2":"code","c065c967":"code","2e95c78e":"code","c5f9cb65":"code","4ab03079":"code","8f60b62d":"code","1fdc406e":"code","b65cd91e":"code","3babc8d0":"code","2cbd9699":"code","fa40e0cb":"code","4ab95281":"code","7e113529":"code","24e55d16":"code","06a78b07":"code","09b8e985":"code","d2ad42c6":"code","cec1f1a8":"code","034a3822":"code","6fbf554c":"code","59961349":"code","1eca40da":"code","a47f3265":"code","b21e5fd4":"code","2b2967af":"code","ba94bab6":"code","867d48c2":"code","75f505a1":"code","e4c8d2b9":"code","6afdf894":"code","bce6b182":"code","71f03dc3":"code","d348d522":"code","2b75639f":"code","38712ac4":"markdown","523fbe94":"markdown","273439c6":"markdown","094db59d":"markdown","b612c4a6":"markdown","b865b108":"markdown","ca5ff3ed":"markdown","b92458aa":"markdown","74c4075e":"markdown","a20e91f1":"markdown","bb693af4":"markdown","fff66481":"markdown","9ddcb25e":"markdown","0198606e":"markdown","bac49cca":"markdown","690f3d4e":"markdown","d9295961":"markdown","d4c1e5cf":"markdown","2b009c16":"markdown","a639eecd":"markdown","ae55d9d5":"markdown","1e5d1ab1":"markdown","c0d4278c":"markdown","86b25433":"markdown","ed316514":"markdown","46ee5663":"markdown","5fa98e71":"markdown","2fba460c":"markdown","e7c4b1ae":"markdown","c400639d":"markdown","8f58ad51":"markdown","f1a40807":"markdown","e1e199f6":"markdown","2f89f3b5":"markdown","a5b6cfa5":"markdown","262da193":"markdown","91d6545c":"markdown","0a967c66":"markdown","d634e883":"markdown","f0349f38":"markdown","3fcb1119":"markdown","ef02ec37":"markdown","f6df08a8":"markdown","951ecedf":"markdown","adbccbd0":"markdown","3dcf4fdb":"markdown","7b50937e":"markdown","b7de0b79":"markdown","30113376":"markdown","a78a3088":"markdown","bca63d3a":"markdown","3bc76311":"markdown","0a8b5dd0":"markdown","99875306":"markdown","3dba363b":"markdown","434ac66f":"markdown","5d6d6ec3":"markdown","bd6e88a0":"markdown","75e70a96":"markdown","c9fa3e86":"markdown","0fedf2a6":"markdown","3377972b":"markdown","c35e0602":"markdown","cb994094":"markdown","d57a84d7":"markdown","61e2a373":"markdown","ceeaace6":"markdown","0f27d1ad":"markdown","997e1701":"markdown","f4400dc5":"markdown","3049b840":"markdown","7d0f4994":"markdown","d0cbbc55":"markdown","9453c6c8":"markdown","7745d6fd":"markdown","11bde534":"markdown","5f4813d0":"markdown","d8a2baa9":"markdown","6d43c207":"markdown","f542a12c":"markdown","f14e0f9e":"markdown","d62c0516":"markdown","2c1e84a6":"markdown","4c96dddc":"markdown"},"source":{"e5d3dc04":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib as pl\nfrom pylab import rcParams\nimport statsmodels.api as sm\nimport plotly.express as px\nfrom datetime import date\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_absolute_error\nimport warnings\nimport numpy\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport math\nimport tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pylab as pylab\nparams = {'legend.fontsize': 'x-large',\n          'figure.titlesize': 'x-large',\n         'axes.labelsize': 'large',\n         'axes.titlesize':'large',\n         'xtick.labelsize':'large',\n         'ytick.labelsize':'large'}\n\npylab.rcParams.update(params)\npl.rcParams.update({'font.size': 16})\n\nprint(tf.__version__)\n\nwarnings.filterwarnings(\"ignore\")\n \nplt.style.use('seaborn-whitegrid')","26df8835":"Aquifer_Auser = pd.read_csv('..\/input\/acea-water-prediction\/Aquifer_Auser.csv')\nAquifer_Doganella = pd.read_csv('..\/input\/acea-water-prediction\/Aquifer_Doganella.csv')\nAquifer_Luco = pd.read_csv('..\/input\/acea-water-prediction\/Aquifer_Luco.csv')\nAquifer_Petrignano = pd.read_csv('..\/input\/acea-water-prediction\/Aquifer_Petrignano.csv')\nLake_Bilancino = pd.read_csv('..\/input\/acea-water-prediction\/Lake_Bilancino.csv')\nRiver_Arno  = pd.read_csv('..\/input\/acea-water-prediction\/River_Arno.csv')\nWater_Spring_Amiata = pd.read_csv('..\/input\/acea-water-prediction\/Water_Spring_Amiata.csv')\nWater_Spring_Lupa = pd.read_csv('..\/input\/acea-water-prediction\/Water_Spring_Lupa.csv')\nWater_Spring_Madonna_di_Canneto = pd.read_csv('..\/input\/acea-water-prediction\/Water_Spring_Madonna_di_Canneto.csv')\n\nAquifer_Auser['Date'] = pd.to_datetime(Aquifer_Auser['Date'], dayfirst=True)\nAquifer_Doganella['Date'] = pd.to_datetime(Aquifer_Doganella['Date'], dayfirst=True)\nAquifer_Luco['Date'] = pd.to_datetime(Aquifer_Luco['Date'], dayfirst=True)\nAquifer_Petrignano['Date'] = pd.to_datetime(Aquifer_Petrignano['Date'], dayfirst=True)\nLake_Bilancino['Date'] = pd.to_datetime(Lake_Bilancino['Date'], dayfirst=True)\nRiver_Arno['Date'] = pd.to_datetime(River_Arno['Date'], dayfirst=True)\nWater_Spring_Amiata['Date'] = pd.to_datetime(Water_Spring_Amiata['Date'], dayfirst=True)\nWater_Spring_Lupa['Date'] = pd.to_datetime(Water_Spring_Lupa['Date'], dayfirst=True)\nWater_Spring_Madonna_di_Canneto['Date'] = pd.to_datetime(Water_Spring_Madonna_di_Canneto['Date'], dayfirst=True)\n\nAquifer_Auser_target = ['Depth_to_Groundwater_SAL', 'Depth_to_Groundwater_CoS', 'Depth_to_Groundwater_LT2']\nAquifer_Doganella_target = ['Depth_to_Groundwater_Pozzo_1', 'Depth_to_Groundwater_Pozzo_2','Depth_to_Groundwater_Pozzo_3', 'Depth_to_Groundwater_Pozzo_4','Depth_to_Groundwater_Pozzo_5', 'Depth_to_Groundwater_Pozzo_6','Depth_to_Groundwater_Pozzo_7', 'Depth_to_Groundwater_Pozzo_8','Depth_to_Groundwater_Pozzo_9']\nAquifer_Luco_target = ['Depth_to_Groundwater_Podere_Casetta']\nAquifer_Petrignano_target = ['Depth_to_Groundwater_P24', 'Depth_to_Groundwater_P25']\nLake_Bilancino_target = ['Lake_Level', 'Flow_Rate']\nRiver_Arno_target = ['Hydrometry_Nave_di_Rosano']\nWater_Spring_Amiata_target = ['Flow_Rate_Bugnano', 'Flow_Rate_Arbure', 'Flow_Rate_Ermicciolo', 'Flow_Rate_Galleria_Alta']\nWater_Spring_Lupa_target = ['Flow_Rate_Lupa']\nWater_Spring_Madonna_di_Canneto_target = ['Flow_Rate_Madonna_di_Canneto']\n\ndataset = ['Aquifer_Auser','Aquifer_Doganella','Aquifer_Luco','Aquifer_Petrignano','Lake_Bilancino','River_Arno','Water_Spring_Amiata','Water_Spring_Lupa','Water_Spring_Madonna_di_Canneto']\nall_data = [Aquifer_Auser,Aquifer_Doganella,Aquifer_Luco,Aquifer_Petrignano,Lake_Bilancino,River_Arno,Water_Spring_Amiata,Water_Spring_Lupa,Water_Spring_Madonna_di_Canneto]\nall_data_target = [Aquifer_Auser_target,Aquifer_Doganella_target,Aquifer_Luco_target,Aquifer_Petrignano_target,Lake_Bilancino_target,River_Arno_target,Water_Spring_Amiata_target,Water_Spring_Lupa_target,Water_Spring_Madonna_di_Canneto_target]","842af923":"import itertools\nab = itertools.chain(col for col in all_data_target)\nall = list(ab)\nall_targets = [item for sublist in all for item in sublist]\nall_targets","990ce98c":"Lake_Bilancino['Flow_Rate'] = Lake_Bilancino['Flow_Rate'].abs()\nWater_Spring_Amiata['Flow_Rate_Bugnano'] = Water_Spring_Amiata['Flow_Rate_Bugnano'].abs()\nWater_Spring_Amiata['Flow_Rate_Arbure'] = Water_Spring_Amiata['Flow_Rate_Arbure'].abs()\nWater_Spring_Amiata['Flow_Rate_Ermicciolo'] = Water_Spring_Amiata['Flow_Rate_Ermicciolo'].abs()\nWater_Spring_Amiata['Depth_to_Groundwater_David_Lazzaretti'] = Water_Spring_Amiata['Depth_to_Groundwater_David_Lazzaretti'].abs()\nWater_Spring_Amiata['Flow_Rate_Galleria_Alta'] = Water_Spring_Amiata['Flow_Rate_Galleria_Alta'].abs()\nWater_Spring_Lupa['Flow_Rate_Lupa'] = Water_Spring_Lupa['Flow_Rate_Lupa'].abs()\nWater_Spring_Madonna_di_Canneto['Flow_Rate_Madonna_di_Canneto'] = Water_Spring_Madonna_di_Canneto['Flow_Rate_Madonna_di_Canneto'].abs()","4b8e4f85":"def box_plot(acea_df,acea_df_target):\n  acea_df.replace(0, np.nan, inplace=True)\n  acea_df.dropna(subset=['Date'],inplace=True)\n  acea_df['year'] = [d.year for d in acea_df.Date]\n  acea_df['month'] = [d.strftime('%b') for d in acea_df.Date]\n  years = acea_df['year'].unique()\n  for target in acea_df_target:\n    fig, axes = plt.subplots(1, 2, figsize=(20,7), dpi= 80)\n    sns.boxplot(x='year', y=target, data=acea_df, ax=axes[0])\n    sns.boxplot(x='month', y=target, data=acea_df.loc[~acea_df.year.isin([1998, 2020]), :])\n    # Set Title\n    axes[0].set_title('Year-wise Box Plot\\n(The Trend)', fontsize=18); \n    axes[1].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize=18)\n    plt.show()\n  return acea_df\n\ndef nagraph(name,acea_df):\n    f, ax = plt.subplots(nrows=1, ncols=1, figsize=(40,20))\n    sns.heatmap(acea_df.T.isna(), cmap='Blues')\n    ax.set_title(\"Missing Values for \"+name, fontsize=20)\n    plt.show()","8867fbfc":"Aquifer_Auser = Aquifer_Auser.sort_values(by='Date')\n\n# Check time intervals\nAquifer_Auser['Time_Interval'] = Aquifer_Auser.Date - Aquifer_Auser.Date.shift(1)\n\nAquifer_Auser[['Date', 'Time_Interval']].head()","5f8ac5a2":"plt.figure(figsize=(40,100))\ni=0\nfor col in all_data[1].columns:\n  if col not in all_data_target[1]:\n      plt.subplot(15,2, i+1)\n      plt.plot(all_data[1].Date,all_data[1][col],'b.')\n      plt.title(col)\n      i=i+1\nplt.show()","2394a83a":"plt.figure(figsize=(40,100))\nfor i,col in enumerate(all_data_target[1]):\n  plt.subplot(15,2, i+1)\n  plt.plot(all_data[1].Date,all_data[1][col],'r.')\n  plt.title(col)\nplt.show()","a7b8f7c2":"for i in range(0,4):\n  print(\"Dataset Name - \",dataset[i])\n  print(\"Target Attributes - \",all_data_target[i])\n  print(all_data[i].describe())\n  print(all_data[i].info())\n  \n  #Correlation Matric\n  corrmat = all_data[i].corr()\n  top_corr_features = corrmat.index\n  plt.figure(figsize=(20,20))\n\n  #plot heat map\n  g=sns.heatmap(all_data[i][top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n  plt.plot()\n\n  #Box plot for Dependent Attributes\n  all_data[i] = box_plot(all_data[i],all_data_target[i])\n  plt.show()\n\n  ## Null Values\n  nagraph(dataset[i],all_data[i])","c065c967":"plt.figure(figsize=(40,100))\ni=0\nfor col in all_data[4].columns:\n  if col not in all_data_target[4]:\n      plt.subplot(15,2, i+1)\n      plt.plot(all_data[4].Date,all_data[4][col],'b.')\n      plt.title(col)\n      i=i+1\nplt.show()","2e95c78e":"plt.figure(figsize=(40,100))\nfor i,col in enumerate(all_data_target[4]):\n  plt.subplot(12,2, i+1)\n  plt.plot(all_data[4].Date,all_data[4][col],'r.')\n  plt.title(col)\nplt.show()","c5f9cb65":"for i in range(4,5):\n  print(\"Dataset Name - \",dataset[i])\n  print(\"Target Attributes - \",all_data_target[i])\n  print(all_data[0].describe())\n  print(all_data[0].info())\n  \n  corrmat = all_data[i].corr()\n  top_corr_features = corrmat.index\n  plt.figure(figsize=(20,20))\n  #plot heat map\n  g=sns.heatmap(all_data[i][top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n  plt.plot()\n  all_data[i] = box_plot(all_data[i],all_data_target[i])\n  plt.show()\n  nagraph(dataset[i],all_data[i])","4ab03079":"plt.figure(figsize=(40,100))\ni=0\nfor col in all_data[5].columns:\n  if col not in all_data_target[5]:\n      plt.subplot(12,2, i+1)\n      plt.plot(all_data[5].Date,all_data[5][col],'b.')\n      plt.title(col)\n      i=i+1\nplt.show()","8f60b62d":"plt.figure(figsize=(40,100))\nfor i,col in enumerate(all_data_target[5]):\n  plt.subplot(12,2, i+1)\n  plt.plot(all_data[5].Date,all_data[5][col],'r.')\n  plt.title(col)\nplt.show()","1fdc406e":"for i in range(5,6):\n  print(\"Dataset Name - \",dataset[i])\n  print(\"Target Attributes - \",all_data_target[i])\n  print(all_data[i].describe())\n  print(all_data[i].info())\n  \n  corrmat = all_data[i].corr()\n  top_corr_features = corrmat.index\n  plt.figure(figsize=(20,20))\n  #plot heat map\n  g=sns.heatmap(all_data[i][top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n  plt.plot()\n  all_data[i] = box_plot(all_data[i],all_data_target[i])\n  plt.show()\n  nagraph(dataset[i],all_data[i])","b65cd91e":"plt.figure(figsize=(40,100))\ni=0\nfor col in all_data[6].columns:\n  if col not in all_data_target[6]:\n      plt.subplot(12,2, i+1)\n      plt.plot(all_data[6].Date,all_data[6][col],'b.')\n      plt.title(col)\n      i=i+1\nplt.show()","3babc8d0":"plt.figure(figsize=(40,100))\nfor i,col in enumerate(all_data_target[6]):\n  plt.subplot(12,2, i+1)\n  plt.plot(all_data[6].Date,all_data[6][col],'r.')\n  plt.title(col)\nplt.show()","2cbd9699":"for i in range(6,9):\n  print(\"Dataset Name - \",dataset[i])\n  print(\"Target Attributes - \",all_data_target[i])\n  print(all_data[i].describe())\n  print(all_data[i].info())\n  \n  corrmat = all_data[i].corr()\n  top_corr_features = corrmat.index\n  plt.figure(figsize=(20,20))\n  #plot heat map\n  g=sns.heatmap(all_data[i][top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n  plt.plot()\n  all_data[i] = box_plot(all_data[i],all_data_target[i])\n  plt.show()\n  nagraph(dataset[i],all_data[i])","fa40e0cb":"year_to_select =  [2011,2017,2017,2009,2004,2004,2016,2011,2017]\ndef select_dates(acea_df,year):\n    acea_df['year'] = pd.DatetimeIndex(acea_df['Date']).year \n    acea_df = acea_df[acea_df.year>year-1]\n    acea_df.replace(0, np.nan,inplace=True) \n    return acea_df\n\nfor i,(acea_df,year) in enumerate(zip(all_data,year_to_select)):\n  all_data[i] = select_dates(acea_df,year)","4ab95281":"all_data[0].drop(['Volume_POL','Volume_CC1'],axis=1,inplace=True)\nall_data[1].drop(['Volume_Pozzo_1'],axis=1,inplace=True)\nall_data[6].drop(['Temperature_Abbadia_S_Salvatore','Temperature_S_Fiora','Temperature_Laghetto_Verde'],axis=1,inplace=True)","7e113529":"all_data[6].isnull().mean()","24e55d16":"for i in range(len(all_data)):\n  for cols in all_data[i].columns:\n    if cols not in all_data_target[i] and all_data[i][cols].isnull().mean() > 0.2:\n        all_data[i].drop([cols],axis=1,inplace=True)\n        \n  print(all_data[i].columns)","06a78b07":"def data_impute(acea_df,acea_df_target):\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_absolute_error\n    import lightgbm as lgb\n\n    features_to_fill = acea_df.columns[:-1]\n    temp_df = acea_df[features_to_fill].copy()\n\n    # Create time related features\n    temp_df['year'] = pd.DatetimeIndex(temp_df['Date']).year \n\n    temp_df['month'] = pd.DatetimeIndex(temp_df['Date']).month \n    month_in_year = 12\n    temp_df['month_sin'] = np.sin(2*np.pi*temp_df.month\/month_in_year)\n    temp_df['month_cos'] = np.cos(2*np.pi*temp_df.month\/month_in_year)\n\n    temp_df['season'] = temp_df.month%12 \/\/ 4 + 1\n\n    temp_df['day_of_year'] = pd.DatetimeIndex(temp_df['Date']).dayofyear\n    days_in_year = 365.25\n    temp_df['day_of_year_sin'] = np.sin(2*np.pi*temp_df.day_of_year\/days_in_year)\n    temp_df['day_of_year_cos'] = np.cos(2*np.pi*temp_df.day_of_year\/days_in_year)\n\n    temp_df['week_of_year'] = pd.DatetimeIndex(temp_df['Date']).weekofyear\n    weeks_in_year = 52.1429\n    temp_df['week_of_year_sin'] = np.sin(2*np.pi*temp_df.week_of_year\/weeks_in_year)\n    temp_df['week_of_year_cos'] = np.cos(2*np.pi*temp_df.week_of_year\/weeks_in_year)\n    \n    features = ['month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'week_of_year_sin', 'week_of_year_cos', 'year', 'season']\n    temp_df.drop(['month'],axis=1,inplace=True)\n    i=1\n    plt.figure(figsize=(40,200))\n    for attribute in features_to_fill[1:]:\n          if attribute in acea_df_target:\n            clr = 'black'\n          else:\n            clr = 'blue'\n          target = attribute\n          X = temp_df[temp_df[attribute].notna()][features]#.reset_index(drop=True)\n          y = temp_df[temp_df[attribute].notna()][target]#.reset_index(drop=True)\n          X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)\n\n          X_test = temp_df[features]#.reset_index(drop=True)\n          # Model\n          params = {'num_leaves': 32,\n                    'objective': 'regression_l1',\n                    'max_depth': 8,\n                    'learning_rate': 0.05,\n                    \"metric\": 'mae',\n                    'seed' : 42\n                  }\n\n          dtrain = lgb.Dataset(X_train, y_train)\n          dvalid = lgb.Dataset(X_valid, y_valid)\n\n          clf = lgb.train(params, dtrain, 5000, valid_sets = [dtrain, dvalid], verbose_eval=False,  early_stopping_rounds=100)\n\n          y_pred_valid = clf.predict(X_valid)\n          \n          old = temp_df[attribute].copy()\n          y_pred = clf.predict(X_test)\n          #replacing of actual null values here\n          acea_df[attribute] = np.where(acea_df[attribute].isna(), y_pred, acea_df[attribute])\n          \n          plt.subplot(20,2,i)\n          sns.scatterplot(x=acea_df.index, y=acea_df[attribute], color='red',label='predicted')\n          sns.scatterplot(x=acea_df.index, y=old.fillna(np.inf), color=clr, label = 'original')\n          i=i+1\n    plt.show()\n    return acea_df","09b8e985":"for i,(name,acea_df,acea_df_target) in enumerate(zip(dataset,all_data,all_data_target)):\n    print(\"Dataset for imputation - \" + str(name))\n    acea_df.reset_index(inplace = True, drop = True) \n    all_data[i] = data_impute(acea_df,acea_df_target)","d2ad42c6":"for i,(acea_df,year) in enumerate(zip(all_data,year_to_select)):\n  try:\n        all_data[i].drop(['Date','month'],axis=1,inplace=True)\n  except:\n        all_data[i].drop(['Date'],axis=1,inplace=True)","cec1f1a8":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[0].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[0][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\n    plt.show()","034a3822":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[1].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[1][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\nplt.show()","6fbf554c":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[2].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[2][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\n    plt.show()","59961349":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[3].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[3][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\n    plt.show()","1eca40da":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[4].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[4][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\n    plt.show()","a47f3265":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[5].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[5][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\n    plt.show()","b21e5fd4":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[6].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[6][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\n    plt.show()","2b2967af":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[7].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[7][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\n    plt.show()","ba94bab6":"from statsmodels.tsa.stattools import adfuller\n\nfor i,col in enumerate(all_data[8].columns):\n    plt.figure(figsize=(60,20))\n    if col=='Date':\n      continue\n    series = all_data[8][col].values\n    i=1\n    result = adfuller(series)\n    significance_level = 0.05\n    adf_stat = result[0]\n    p_val = result[1]\n    crit_val_1 = result[4]['1%']\n    crit_val_5 = result[4]['5%']\n    crit_val_10 = result[4]['10%']\n\n    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n        linecolor = 'forestgreen' \n    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n        linecolor = 'gold'\n    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n        linecolor = 'orange'\n    else:\n        linecolor = 'indianred'\n\n    plt.subplot(10,3,i)\n    plt.plot(series, color=linecolor)\n    i=i+1\n    plt.title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n    plt.ylabel(ylabel=str(col), fontsize=14)\n    plt.show()","867d48c2":"def add_feat(acea_df):\n  i=0\n  plt.figure(figsize=(40,100))\n  for cols in acea_df.columns:\n    acea_df[cols+'_roll'] = acea_df[cols].rolling(7).sum()\n    plt.subplot(20,2, i+1)\n    plt.plot(acea_df[cols+'_roll'])\n    plt.title(str(cols)+'_roll') \n    i=i+1\n  plt.show()\n  acea_df.dropna(axis=0,inplace=True)\n  return acea_df\n\nfor i,(name,acea_df,acea_df_target) in enumerate(zip(dataset,all_data,all_data_target)):\n    print(\"Dataset for Feature Engineering - \" + str(name))\n    all_data[i] = add_feat(acea_df)","75f505a1":"def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n\tn_vars = 1 if type(data) is list else data.shape[1]\n\tdf = pd.DataFrame(data)\n\tcols, names = list(), list()\n\t# input sequence (t-n, ... t-1)\n\tfor i in range(n_in, 0, -1):\n\t\tcols.append(df.shift(i))\n\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n\t# forecast sequence (t, t+1, ... t+n)\n\tfor i in range(0, n_out):\n\t\tcols.append(df.shift(-i))\n\t\tif i == 0:\n\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n\t\telse:\n\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n\t# put it all together\n\tagg = pd.concat(cols, axis=1)\n\tagg.columns = names\n\t# drop rows with NaN values\n\tif dropnan:\n\t\tagg.dropna(inplace=True)\n\treturn agg","e4c8d2b9":"def get_model(trainX):\n        model = Sequential()\n        model.add(LSTM(128, activation='relu',return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2])))\n        model.add(Dropout(0.4))\n        model.add(LSTM(64, activation='relu',return_sequences=True))\n        model.add(Dropout(0.3))\n        model.add(Dense(50))\n        model.add(LSTM(32, activation='relu'))\n        model.add(Dropout(0.3))\n        model.add(Dense(1))\n        model.compile(loss='mean_squared_error', optimizer='adam')\n        #print(model.summary())\n        return model","6afdf894":"def forecast(name,acea_df,acea_df_target):\n    dataset = acea_df.copy()\n    values = dataset.values\n    # ensure all data is float\n    values = values.astype('float32')\n    # normalize features\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    scaled = scaler.fit_transform(values)\n    \n    # frame as supervised learning\n    reframed = series_to_supervised(scaled, 1, 1)\n    # drop columns we don't want to predict\n    cols_to_drop = [len(acea_df.columns) + acea_df.columns.get_loc(c) for c in acea_df if c not in acea_df_target]\n    reframed.drop(reframed.columns[cols_to_drop], axis=1, inplace=True)\n    values = reframed.values\n\n\n    #Train Test Split\n    train_size = int(len(values) * 0.7)\n    test_size = len(values) - train_size\n\n    train, test = values[0:train_size,:], values[train_size:len(values),:]\n    scale = MinMaxScaler(feature_range=(0, 1))\n    scale.min_,scale.scale_ = scaler.min_[0],scaler.scale_[0]\n\n    for i in range(1,len(acea_df.columns)-len(cols_to_drop)+1):\n        trainX, trainY = train[:, :len(acea_df.columns)], train[:, -i]\n        testX, testY = test[:, :len(acea_df.columns)], test[:, -i]\n\n        trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n        testX = testX.reshape((testX.shape[0], 1, testX.shape[1]))\n\n        model = get_model(trainX)\n        grads = gradient_importance(trainX, model)\n        print('Mean:', np.mean(grads))\n        print('Standard Deviation:', np.std(grads))\n\n        plt.figure(figsize=(30,40))\n        plt.subplot(12,3,3)  \n        plt.bar(acea_df.columns,grads)\n        plt.xticks(acea_df.columns, rotation=90)\n        plt.legend()\n        \"\"\"       \n        #|\n        idx = np.nonzero((abs(grads) > 0.04))\n        print(\"Selected Features - \" + str(idx))\n\n        foo = trainX[:,:,idx]\n        trainX = np.squeeze(foo, axis=(1,))\n        foo = testX[:,:,idx]\n        testX = np.squeeze(foo, axis=(1,))\n        \"\"\"\n        history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0, shuffle=False)\n        \n        yhat = model.predict(testX)\n        testX = testX.reshape((testX.shape[0], testX.shape[2]))\n\n        inv_yhat = np.concatenate((yhat, testX[:, 1:]), axis=1)\n        inv_yhat = scale.inverse_transform(inv_yhat)\n        inv_yhat = inv_yhat[:,0]\n\n        testY = testY.reshape((len(testY), 1))\n        inv_y = np.concatenate((testY, testX[:, 1:]), axis=1)\n        inv_y = scale.inverse_transform(inv_y)\n        inv_y = inv_y[:,0]\n\n        rmse = math.sqrt(mean_squared_error(inv_y, inv_yhat))\n        mae = mean_absolute_error(inv_y, inv_yhat)\n        print('Test RMSE: %.3f' % rmse)\n        print('Test MAE: %.3f' % mae)\n      \n        plt.subplot(12,3,1)        \n        sns.scatterplot(x=np.linspace(0,len(inv_y),num=len(inv_y)), y=inv_y, color='black',label='Actual')\n        sns.scatterplot(x=np.linspace(0,len(inv_yhat),num=len(inv_yhat)), y=inv_yhat, color='green',label='predicted')\n        plt.title(acea_df_target[i-1])\n        plt.legend()\n       \n        plt.subplot(12,3,2)\n        plt.plot(history.history['loss'], label='train')\n        plt.plot(history.history['val_loss'], label='test')\n        plt.legend()\n        \n        actual.append(inv_y)\n        predicted.append(inv_yhat)\n        targets.append(acea_df_target[i-1])\n        rmses.append(rmse)\n        maes.append(mae)\n        \n    plt.show()\n    return actual,predicted,targets,history,rmses,maes","bce6b182":"def gradient_importance(seq, model):\n    seq = tf.Variable(seq, dtype=tf.float32)\n    with tf.GradientTape() as tape:\n        predictions = model(seq)\n    grads = tape.gradient(predictions, seq)\n    grads = tf.reduce_mean(grads, axis=1).numpy()[0]\n    return grads","71f03dc3":"actual = []\npredicted = []\ntargets = []\nrmses = []\nmaes = []\nmaes_train = []\nrmses_train = []\nfor name,acea_df,acea_df_target in zip(dataset,all_data,all_data_target):\n  actual,predicted,targets,history,rmses,maes= forecast(name,acea_df,acea_df_target)","d348d522":"errors = pd.DataFrame(list(zip(rmses, maes)), \n                      index=all_targets, columns=['Test RMSE','Test MAE'])\n#errors.to_csv('error.csv')\nerrors","2b75639f":"plt.figure(figsize=(40,200))\nfor i,(act,pred,name) in enumerate(zip(actual,predicted,targets)):\n  plt.subplot(20,2,i+1)\n  sns.scatterplot(x=np.linspace(0,len(act),num=len(act)), y=act, color='black',label='Actual')\n  sns.scatterplot(x=np.linspace(0,len(pred),num=len(pred)), y=pred, color='green',label='predicted')\n  plt.title(name)\n  plt.legend()\nplt.show()","38712ac4":"In this section, we are going to explore the datasets.\n\nLet's get a feeling about how many years of data we are looking at for each dataset. For the datasets for aquifer Auser, aquifer Luco, river Arno, and water spring Amiata, we have more than 20 years of data. On the other side, water spring Madonna only contains information about the past 8 years. We will be looking at indepentadant and target variables through visualizaition, correlation matrices for checking the extent of dependency of independent variables on target variables, total null values present in each dataset, statistical view for getting a good grasp of the type of data that exists in these columns. Additionally, we will be looking at boxplots in periods of years and months for checking trend and seasonality respectively if any.","523fbe94":"Independent Attributes","273439c6":"**Stationarity Test for Aquifer_doganella**","094db59d":"We are going to use a multi-layered LSTM recurrent neural network to predict the last value of a sequence of values.\n\nThe following data pre-processing and feature engineering need to be done before construct the LSTM model.\n\nCreate the dataset, ensure all data is float.\nNormalize the features.\nSplit into training and test sets.\nConvert an array of values into a dataset matrix.\nReshape into X=t and Y=t+1.\nReshape input to be 3D (num_samples, num_timesteps, num_features).","b612c4a6":"As a preprocessing step of the data, we will fill the NaN values and replace the implausible values as well. First, the implausible values consisting 0 will be replaced with NaN values. Then all NaN values will be filled through prediction. For this, we will build a small prediction model.\n\nWe will be using LightGBM for Null values Imputation. We will be creating additional time realated features for LightGBM model which will be then used along with feature to be imputed and perform train-test split for null values prediction.","b865b108":"The locus of our survey that arises out of the data available to us would put forward not one but multiple exploratory branches, the first of which would mean to overview dataset features affecting water bodies and target variables that have to be predicted. The second spear point of perception would be exploratory data analysis containing correlation matrix, Null values analysis and stationarity test as time-series are time-dependant and show specific characteristics, such as trend and seasonality. Right at the end of this particular train of thought we find ourselves in a space where data preprocessing which includes filling of Null values, feature selection and exterminating the old data is done efficiently. The method with which we will go forward in order to achieve and expand the implications of these objectives would be to create a model for prediction that will essentially enable a sub-model for future scope.","ca5ff3ed":"Can you build a story to predict the amount of water in each unique waterbody? The challenge is to determine how features influence the water availability of each presented waterbody. To be more straightforward, gaining a better understanding of volumes, they will be able to ensure water availability for each time interval of the year.\n\nThe time interval is defined as day\/month depending on the available measures for each waterbody. Models should capture volumes for each waterbody(for instance, for a model working on a monthly interval a forecast over the month is expected).\n\nThe goal is to create a mathematical model, for each category of waterbody (acquifers, water springs, river, lake) to predict the amount of water in each unique waterbody for a set time interval. The predictive power of the models shall be evaluated with both Mean Absolute Error (MAE) and Root Mean Square Error (RMSE).","b92458aa":"![image.png](attachment:image.png)","74c4075e":"<a id='8.1.3'><\/a>\n### <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">8.1.3. MAE and RMSE analysis<\/p>\n","a20e91f1":"In this section, we will fit an LSTM on the multivariate input data.\n\n* First, we must split the prepared dataset into train and test sets.\nwe will split the dataset into train and test sets, then splits the train and test sets into input and output variables. Finally, the inputs (X) are reshaped into the 3D format expected by LSTMs.\n\n* The model will be fit for 100 training epochs with a batch size of 64. Remember that the internal state of the LSTM in Keras is reset at the end of each batch, so an internal state that is a function of a number of days may be helpful (try testing this).\n\n* Finally, we keep track of both the training and test loss during training by setting the validation_data argument in the fit() function. At the end of the run both the training and test loss are plotted\n\nAfter the model is fit, we can forecast for the entire test dataset.\n\nWe combine the forecast with the test dataset and invert the scaling. We also invert scaling on the test dataset .\n\nWith forecasts and actual values in their original scale, we can then calculate an error score for the model. In this case, we calculate the Root Mean Squared Error (RMSE) that gives error in the same units as the variable itself.","bb693af4":"<a id='4'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">4. Dataset Overview<\/p>","fff66481":"**Stationarity Test for Water_spring_lupa**","9ddcb25e":"<a id='8'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">8. Time Series Forecasting Model<\/p>","0198606e":"Target Attributes","bac49cca":"\n<a id='5.4'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">5.4. Water Spring Waterbody<\/p>","690f3d4e":"Augmented Dickey-Fuller (ADF) test is a type of statistical test called a unit root test. Unit roots are a cause for non-stationarity.\n\nNull Hypothesis (H0): Time series has a unit root. (Time series is not stationary).\n\nAlternate Hypothesis (H1): Time series has no unit root (Time series is stationary).\n\nIf the null hypothesis can be rejected, we can conclude that the time series is stationary.\n\nThere are two ways to rejects the null hypothesis:\n\nOn the one hand, the null hypothesis can be rejected if the p-value is below a set significance level. The defaults significance level is 5%\n\n**p-value > significance level (default: 0.05)**: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n**p-value <= significance level (default: 0.05)**: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\nOn the other hand, the null hypothesis can be rejects if the test statistic is less than the critical value.\n\n**ADF statistic > critical value**: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n**ADF statistic < critical value**: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.","d9295961":"**Stationarity Test for Water_Spring_Amiata**","d4c1e5cf":"**Create feature importance plot**\n\nGenerally, importance provides a score that indicates how useful or valuable each feature was in the construction of the model.\n\nThe more an attribute is used to make key decisions, the higher its relative importance.\n\nThis importance is calculated explicitly for each attribute in the dataset, allowing attributes to be ranked and compared to each other.","2b009c16":"**Observations -**\n1.    Volumes of rainfall are quite volatile across all locations and at different times of the year. However, we cannot observe apparent seasonal patterns.\n2.    Temperatures for all locations seems mostly between 0\u00b0C and 30\u00b0C. In addition, the temperature shows quite a strong annual cycle.\n3.    Target attributes are also quite volatile across all locations and at different times of the year. However, we cannot observe apparent seasonal patterns.\n\n5. From Boxplots it is observed that Dependent attribute characterizes partial seasonality.\n\n6. From missing values graph it is observed that most of the values in columns have null values.\n","a639eecd":"<a id='6.2'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">6.2. Null Values Handling<\/p>","ae55d9d5":"**Stationarity Test for Aquifer_auser**","1e5d1ab1":"**Stationarity Test for Aquifer_patrignano**","c0d4278c":"Flow rate absolute value as per kaggle discussions\n\n[https:\/\/www.kaggle.com\/c\/acea-water-prediction\/discussion\/205071](https:\/\/www.kaggle.com\/c\/acea-water-prediction\/discussion\/205071)","86b25433":"<a id='8.1.4'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">8.1.4. Plot Predictions<\/p>\n","ed316514":"## Forecasting Function","46ee5663":"Independent Attributes","5fa98e71":"## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:120%; text-align:center\">Table of Content<\/p>\n\n* [1. Targeting Water Bodies - A reconstruction of Factors affecting water distribution](#2)\n* [2. Problem Definition](#2)\n* [3. Summary](#3)\n* [4. Dataset Overview](#4)\n* [5. Exploratory Data Analysis](#5)\n    * [5.1 Aquifer Waterbodies](#5.1)\n    * [5.2 Lake Waterbody](#5.2)\n    * [5.3 River Waterbody](#5.3)\n    * [5.4 Water Spring Waterbody](#5.4)     \n\n* [6. Data Preprocessing](#6)\n    * [6.1 Feature Selection](#6.1)\n    * [6.2 Null Values Handling](#6.2)\n    * [6.3 Null Values Imputation using LightGBM](#6.3)\n    * [6.4 Stationarity Test](#6.4) \n* [7. Feature Engineering](#7)\n* [8. Time-Series Forecasting](#8)\n    * [8.1 LSTM](#8.1)\n        * [8.1.1 Transforming Datasets for Multivariate LSTM Model](#8.1.1)\n        * [8.1.2 Create LSTM Model](#8.1.2)\n        * [8.1.3 Error Analysis](#8.1.3)\n        * [8.1.4 Prediction Plots](#8.1.4)\n* [9. Conclusion](#9)","2fba460c":"The Arno is a river in the Tuscany region of Italy. It is the most important river of central Italy after the Tiber. With a length of 241 kilometres (150 mi), it is the largest river in the region. It has many tributaries: Sieve at 60 kilometres (37 mi) long, Bisenzio at 49 kilometres (30 mi), Ombrone Pistoiese at 47 kilometres (29 mi), and the Era, Elsa, Pesa, and Pescia. The drainage basin amounts to more than 8,200 square kilometres (3,200 sq mi).\n\nThe main indicator that will be predicted for the river is hydrometry. The other two features in this dataset are rainfall and temperature. ","e7c4b1ae":"Remove date and month columns from all datasets because it is not needed for prediction.","c400639d":"<a id='8.1.2'><\/a>\n### <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">8.1.2. Create LSTM Model<\/p>\n\nWe have defined the LSTM with 128 neurons in the first hidden layer, 64 neurons in the second hidden layer, and 32 neurons in the third hidden layer and 1 neuron in the output layer for prediction.\nWe have also defined dropout function after all 3 layers in order to prevent our model from overfitting into a training dataset.\n\nWe will use the mean_squared_error(MSE) loss function and the efficient Adam version of stochastic gradient descent.\n\n\n![image.png](data:image\/png;base64,iVBORw0KGgoAAAANSUhEUgAAAogAAAIGCAYAAADX834SAAAgAElEQVR4Ae2dbZLjqNJG32V5VxW9kepddC3BS7jTUXNj7nSE1qM3ECSQkEjIlmzJPj86\/CEJksyTyQNSuf\/vcrmM\/MMHMAADMAADMAADMAADwsD\/yRtegQIGYAAGYAAGYAAGYMAxgEBkB5UdZBiAARiAARiAARhQDCAQAUIBwcqRlSMMwAAMwAAMwAACEYGIQIQBGIABGIABGIABxQACESAUEKwaWTXCAAzAAAzAAAwgEBGICEQYgAEYgAEYgAEYUAwgEAFCAcGqkVUjDMAADMAADMAAAhGBiECEARiAARiAARiAAcUAAhEgFBCsGlk1wgAMwAAMwAAMIBARiAhEGIABGIABGIABGFAMIBABQgHBqpFVIwzAAAzAAAzAwCEF4ud1GIffX+PHWvH28zoOw5D+XT\/3Fz\/S59TXx\/j12\/d\/\/QlcSwVmivMwjN+\/Pm6Pk\/hf4t6KuZxHnG739dp85Hx8DQMwAAOnZeC1BGIEMQi1lliI520g4pTwuIxe9HyPXz82aHtLOx\/W1ud47RR9mwjEOK6FmBOn0xappYUGx9+11jBu2IeBPRlYLRBlUtc7ZNvunE193LKD2CsW4nkbwPXja\/zOBBECsV8gbgv2gkAkTgjELfOetuAJBmDgxRm4WSAO+e5cmHzd7V0tHG8TYGcWiB+\/vsdhuI6fLw5OW9ydQyASp9tysx132sM3MAADMPBKDKwUiH6X5vvX13jNRJCbbP13hUDMhKN\/NtAWTn6yzp4ddM+TVTuIaZfStzV3G3dhNymIt0fv9vn+0jjtZ++8wErPUt7mM1sAtcTbQp9THL2\/1RiyGJkxlOcCsx1WlzyqjdlFRRnzuecV+2L+SsnLWJiMYAAGYAAG9mLgRoH4MU3yXuA4ceFEjJ+gRfSIYMh3FC1B5r\/TImj6LhMfl0sQMNmupW+\/JRJ7xEISRWLzXk527drjLOwvboO2r3Mic95n3QKxp89M6Cdf1THx\/vPfp\/Nmkje0mzOSx+DzWvgnPEdot90T8xlb3nbHF5\/kzPEeHmAABmDAM3CzQLy4ydqJOPea\/WWon7xbIqEQFQ2BUApEW+zMCYK5Ywl+L9oKEbKLUFhhjxLGztbCl3f5rGhLhGtnn+qxgt5r5\/zZGEs7OYMfK3udn\/p83G47ccE5+AIGYAAGYODdGVgpEL3A8Ds+bkL+Hr9\/y21lP0FPAjHs9Fg7Q7n4s4Vf2G2LIqA98edt6UC2r9HnPS4BvBgdgpi2+q3Fm7dVj6XPZ5fRPq\/so\/wsduk+Lw0hZ\/u\/1aa0nb022p2Lkd2na7OweU6YcoyHy2EABmAABmBgloE7BGIQIZaQmwSivTPnhZK\/PWqLmFIgesGRnslLz\/BN38X+M+FxULHgx5vsV7dKg1hqjjPcXu\/zWadA7OzzaQKxZd+JYj4ndjmW5yzv4QEGYAAGjsTAXQJRDyTbwVkSiGGC7xM7Wbvdav+Wax4JZrBP\/fFG385bn886BWJ5+7rl38ZOn72b1zeOiZ1Gu\/mxvtvaLnZHj\/kj+aIvXZvwB\/6AARiAgbUMrBOIcxO6mqBbIqH43hKSsmuU7RLZQmQu2H1iwe9m2judax25\/vzSxvJzY3ydPjOF5HRt\/pfAnX024m7HpbNNJ0Yb7Tpfevvr2Nh9Ol+t6LclhPl+9nbDesYbDONn\/AwDMAADh2dgQ4Gobw1bE7wXZPlf33rBmHaJgoD8\/a1\/5kZEY\/ZXzPOTVY9YCH2rXby9JrTP8ZoJ3sn2MCZ1m7kScJY9nT4LbcXnQMNndwt7dZ8NIdcSaz7OtbirYtZodzqv8kWIqfkTSAjEyrcU38MXX2Jm1Te+gwsYOAoDuwlEN0AvEtMzd\/VvG6ZdJP\/snRcV03WloJKfusl+W89dEwWQ\/FVtcVye6cvPE+d3C5ktJlsRuZl9lk2yqyZ2534Ru\/U53meWWNP+d8LciywlEN3YDNuGIRN4DSFn9eltzMRcGG\/qMwlzPcb6p3u0\/T7WZZ8+hhljS\/7dIpa0gfiCARiAARh4cQbWCcQXd0YUYCccZymczjwWbGcFDQMwAAMwAAPPZQCBeEIxaCUNAvG5iWTFhO+ICQzAAAzAwFkZQCAiELlN8CIMnLUIYTcTKAzAAAwcjwEE4ouIA3YQj5dcFDxiAgMwAAMwcFYGEIgvIhDPCiB2UzxhAAZgAAZg4HgMIBARiNxihgEYgAEYgAEYgAHFAAIRIBQQrOKOt4ojJsQEBmAABmDg0QwgEBGICEQYgAEYgAEYgAEYUAwgEAFCAfHoFQr9sSqGARiAARiAgeMxgEBEICIQYQAGYAAGYAAGYEAxgEAECAUEq7jjreKICTGBARiAARh4NAMIRAQiAhEGYAAGYAAGYAAGFAMIRIBQQDx6hUJ\/rIphAAZgAAZg4HgMIBARiAhEGIABGIABGIABGFAMIBABQgHBKu54qzhiQkxgAAZgAAYezQACEYGIQIQBGIABGIABGIABxQACESAUEI9eodAfq2IYgAEYgAEYOB4DCEQEIgIRBmAABmAABmAABhQDCESAUECwijveKo6YEBMYgAEYgIFHM4BARCAiEGEABmAABmAABmBAMYBABAgFxKNXKPTHqhgGYAAGYAAGjscAAhGBiECEARiAARiAARiAAcUAAhEgFBCs4o63iiMmxAQGYAAGYODRDCAQEYgIRBiAARiAARiAARhQDKwSiJ\/XYRyGpX9\/xj+L5wzj8Pe\/HW0N4z89bf33r77z\/lmy3R3\/3\/h3T5\/\/\/umy\/z9\/9fSJz3Ku8FnGDJxleUZu5nkydNUzakvuM2oLtSXnIb1\/k9ry+2v8WCGCVwnER29v0h9b6jAAAzAAAzAAAzDweAYQiCvUNIA+HlB8js9hAAZgAAZg4PEMIBARiOqZA5Lw8UmIz\/E5DMAADMDA0RhAICIQEYgwAAMwAAMwAAMwoBhAIHYD8TF+\/R7G718fyoFHU\/y5PdMfFV0\/T2NvbjvvWU3DQAcDP77G72EYrz87zu2udbQFezAAA5cRgdhZNP1fcF\/HT+P8j1\/f4zDYx54KWZg8ziRqn+ovI7bYc+6J4hm5+dA+EYgsgKlbMLATAzcJxDmx9IoTqi\/43+PXD3uyfOiEsBaEn9fpZ0LYYbBj94q8nn1M5c9p3bPAeUZubtpnyN\/0cxzFQhSBiDhYOyc8+\/zAbGI6\/PTOi97t0nfyPsfr0NYSR6vdCMTFZHEBnb+1vOmEsGjPeqHzboL+aEmGPb3M+lwb8t\/qksnkxsnjGbm5VZ++nfL28ed4NfzDArCXMc57ej2yFjWS50e8E3fnnOzm37jIncaJQPSrutnVr3+mz7w1G2CJTp0CJOfLD33WTk6FuTg3L6grg53aLAtLmMyaP6otK31j0hMbit29uNKIyeLHahb\/0rdzE6jpz3I8fH564RQu3vS1mWtFntjn5Qu53ty8jJesYPuFVKgvRc2YjhXf+WtFwK3osyu+ob25vHbthNx2NWLO\/ontsmZUk7Hv07XlfSy1VmpZXiOKGnuiXRHyPI\/jE95nzKpYBD7VvB\/OTbuN98z7JbOZcIu55NqXXPZ9xbwq878rj32fcQ6fxmjl0xPi0GH\/fjuILrCquElwMucUhV9g8cUpB6EulvU5uqglyOprpZ\/l12CzGkcdSHvCSudZtrq+PXjJHxHErNha19bfLY0xjOMmwNM4lv3FufjoVgbmGNbH7Hzz56S893bY52Y25hNQzHPdX8zVMn8aE91inx2F+XIJNpR9ltfO2K980VOPpU+36I39WrWj9k9dkzIflzbz+b1vizfyRhY7idtitzzOmbk26J\/3P6\/6ukspSCe7vsfv3+48z717P7i6MJ1bXD\/Lccib5gZSnmPHzZX9BKLlvEoQ1oXmcgmOjcVaAEhCyk\/CrfNkRZ+cPgmvWPDS94uTeQvkYmyLE0JoJ4HvbPBjz7\/zArGEsDyv\/BzGswDwoo3FmBZ9w\/nvXeS3jv9srulct1m288I+N6sBod9pEsjGVF5n1pCGzeW1t+aSb8fv4uV1QrXXsN+0Nxvf1EarHpe1sqgt9vh0jJSNZb98fu\/a0cgbEWxxt83iJFyb54PkSXndcg4EZoV3lUvhmOyyV7mS1RDLzvidq0tpTp9slf7iOb1tPf68xwpEAwwvijLxV53TLjwlAB6UFIy7i1RRGFvt2QUzD2YBogPDaLscj++vGL9x3XRe5be8f7u\/1nj4vvDdCRL59DGb5Vfnj51v9wnEcnIp89PMzYbNtn23MuXHFW+xlZNLwwbT3pLj6lrbh7Kz431U1KOsza4+s\/NPzyxjuU3oVtylRyXKhVrNSM3oPfO+YlbZpWtOl3i1eJjaTJpk6i\/b\/KrHd2ud2Oe6XQXi5Axji1UVYxWUsFuoimBRIMv2snPvAcUMVEuMFSB0TQhFWxYoCtbYhy7Ivi95Nqh+Vb6NbSAQzfjm\/uH9bcV+K78VdUDHy8qBbFE52VBPHK6Nxdxs9Wvla1ZrJvsa1y72eaPPUu6nCUeLtzRJWLVkuR7bPtR99NdjHcNkG9+\/uS9C3sRFT5jTrbkrMa\/nunoHMcuJVn41+o2PU6h83lIgplplzftHzofdBKIvRkXQVAAkSfLi79\/nwbduObcc6mEq+mzB0vN9MUnM95sgsM\/Li69\/XyaEVdSr8XfaVNlw63U9fuKc54qrl\/B\/nh9SG+RVH7MFmD5H+LfPlXbTzkWZi8fZQcxsdXGWSU52IcyaGp5vzgRtXz22fSh9eh\/l9bqw7SU4ZEySO7u9Npgt+xNxqHOzZrRr3i\/zJrCq5lxl150CcZpvtajtEcSlD579eSeB6INYbRerAGSJODnzOn5Ox2uBp4I4U4S6QJm5vgpGy96yjU7xNdnniraMt2jHHGdpQ\/m5aKMaQzjufbMkYrOYdLbb6o\/v8eVaBryIMRgt8stkeTqn+KtEx3BxbWVTI5\/KXCw\/u3a8HfUzz4t93pNbwd5YW7vs763H9eSbxpniYvmi8us9Y+Ta115wNpjVDBUCLTJRM+rzsNYNeXutcxTLyq6i\/1BftFhdrvFTv3Gh5m1f20Y+jke\/30kgBufKA54uuMHBTkXXDgoFzG01y8o4AmGsmvNj2fsWBLc7NYzDsinrV1bYpu3WeY3fVVSwTtcVkIa2pvOyB1+Xx2e3s3zdcgLQBj7ajIFS\/Djew3fqrkJZrLPaos7Lrm\/mppoUQizL9qMYTJOQrzV+h6CqZ9Y4Qu52+8q1YdSdKvct++WvPePE1FuP68nX9P8W41vrD85\/HdHYYLbMjRbrTkPked4174ecTtdJTmR\/TazsKuZMoyaU9lqfJ9tiHrv8SjXEOv9o390hEK3t07TKlL\/SjduqrlipAOiJ1cNgiUc5LxOR2XOIeXHuAmVlofFt5uMSe4rXbJLyY7auEShtSMQH0WctwRwnrCIGcUIobJvx+9GAxJ4idit5Pb\/\/6jzPc1zG5\/NS+He55nMrTQCZH+dyM+SGyrlGEVf5OeWat9WyL18Qt+tBZqMV58rubDKT8xu5Pdmq6kHhV7MeF+fMPBtW1ffZcxfGKWPh9XVE4FwsG8xKbqdXmS\/zPPeM5nneO+\/rmuG1hsoTZdc2AnFqXwTi1L4996cxHytXbhKIewzGF19LVD3bYaFoSpDnwF88VkBXnK9gLY7d4\/O92r3HJq59Ntf0PzGoJoV390k9+ZKn784E43\/nHDiIQDx2YZKVh7lTsEbILUxGuwi5G7fG3zkpGPsbTQoLOfleLBy7Dr9XLN4oB9fMoZz70F3mAwjE+V21oxQFv8N5z\/bw8k7k5gIxTH75dvxR\/IkdTACHYACBmE04CMRDMIkIypikTj6TyScKxCCY3LMr6lmZowLhhexqsRUmoOk5pIXb1FsLxKm9hT6fCR99H5X1N7ILgZhNxghEatIb5T5CPMt9O+5PFIi2QSQofoEBGIABGIABGICB5zKAQGQVsbiKIEmfm6T4H\/\/DAAzAAAw8mgEEIgIRgQgDMAADMAADMAADigEEIkAoIB69QqE\/VsUwAAMwAAMwcDwGEIgIRAQiDMAADMAADMAADCgGEIgAoYBgFXe8VRwxISYwAAMwAAOPZgCBiEBEIMIADMAADMAADMCAYgCBCBAKiEevUOiPVTEMwAAMwAAMHI8BBCICEYEIAzAAAzAAAzAAA4oBBCJAKCBYxR1vFUdMiAkMwAAMwMCjGVgtED9+fY\/Tfxvn\/ou86p\/8X8XZf6NXnTOMg\/z3bz+vRhup3etPB0T4v5qtdtx38b\/p6+uzz\/7OPrvsv4x9ffbZf+nqs9P+S1+fffZ39tllPz6bckvYxmfjMEhtgbP8v+3sy82+PKe2uLlHOMNnjjM\/B1OPX6se9wvt1QLx0QqW\/vqDia\/wFQzAAAzAAAzAwBYMIBC5xcwtZhiAARiAARiAARhQDKwWiNzSyG5rc+svuyXDrb\/1t\/7wGT5Lj9So21ibPv7B7VLnW26XZqzx+Er2eJs8VvAu9bh\/d3W1QNxi25I2+gOEr\/AVDMAADMAADMDAoxlAILKlrLaUHw0g\/VH0YAAGYAAGYOB4DCAQEYgIRBiAARiAARiAARhQDCAQAUIBwSrueKs4YkJMYAAGYAAGHs0AAhGBiECEARiAARiAARiAAcUAAhEgFBCPXqHQH6tiGIABGIABGDgeAwhEBCICEQZgAAZgAAZgAAYUAwhEgFBAsIo73iqOmBATGIABGICBRzOAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBcSjVyj0x6oYBmAABmAABo7HAAIRgYhAhAEYgAEYgAEYgAHFwA0Csfz\/CuX\/MTye+u1dkUz\/v7T835RnAOTH1\/g9nN\/vvfHhvPPm1r2xO11unqF+HM3G6f+0v46fR7MLe5RYuDeXuf58dfwGgZgNckrs+4XKNAkMTyoQ0xjSf+R+Fog\/r+4\/Xn+SzyicFM5HMHDS3DxLDTmOnWHT4UyL9EfwTx\/U2Scz8N4CcdqJG8bvXx8GiJ\/jdRjG4fppHMtE8uUyerHmBFv4p64J7cgx43XqP9gylEUyTJLV9xeK6nEmOM0Ddm3gj2Zupny6\/tT9THlY5s+TC+wmLEgNeOCCMNY0VcuSv\/2iPqt5Lb9H29O5Zdy8j\/rr7SY+fQUuTjqGip1iTlR8yLyYnVPO12Z7FbepbsR5evYuXHn+e27GvLVAnJ9QegqW3G4v4Pl5bYjOy9jcLY2JoHdkY6G2CnBzEk2FnGKKL87IQDs3Q17+\/h6\/i5xoX3NWBlIN8nWgqDN7CIS4a5v6LvmZapjyvcTka\/zIbPK1TtczmcyVCJBrYt9njRd2l6ys+VzNjRYP4btSJKp+ZC6tRKKOj88pzadrZ5ZRYfVNXvcViBKoqP7zAheKSjyWVphe4YdzpzZcEOV8H1Af3GGsd9Y0BAqcPKjBNrNQTee1C2Rs0wI478N4XyWBnDO1dR2\/fn1n4tLZ4L9rjfNhE4fYyevijnLkA1\/d5qvZ3JS8\/Bq\/fuviPuWCEi6p2Mddg3LSiPWluBNQtONjKjVIalVezzrrTjcTfvEp9ekheT75QsYkfl6+g+J84+taHo+weC79ffHt2hM8d0Xet3bUvFn5fJE7ZxVXOv\/sa\/U5F6vOWN9152zR\/gtct59ADI5WhcB9ZwS2KZqcg6d23G6BKz6+gLj3063fSVTlRak\/QLN9ToGtga2St2c1U0DS7DcIxM9pvL5Iu3Mn\/8mxoq3JnmCDTCSVjdY1fHebcMFvD\/FbM0cm\/6e8nM7L6omeFILYULdlw7W5+At1ygnIVKtSHzGfwnnpHBGUIqj6a09scwVPDxGIyh7DB+q4Hq+PWV6LG2Iv+LFVr+p2dD+3+I5rju9DK+42857LPA+t+Opa0Bi\/wWLXdTN5YNly5u\/2E4iTcMkLRiNIcfXZKLRSwKeJoCj6N4uj0E42udRB7CmQYo\/bUbhzrFEE+javP91raDMes3zYlzD1+Ky2+A4\/PZuBpdzM89K9T3VDFfdW\/SlrhqovaeyqLXnOOBeW0yTxuNyb7MnGuj+nuZ+TX1r9mvaJb8Vu+TxXd8M5LQHZ6p\/vl2N0XB+1WAvfx7k1fK7ysBh7meOmoAt1RrWVao\/nWe4U5IvHoi+z7dc5Zz+BKMUgBrftNL96SIVegawKRhHULhCsfj1o86uQFrRGe8EOuY01125rrNP3AqtrL3\/Gamq\/4Z\/OLXfl0xeHmrEajJ4m5ku5qfPS5Y3kWy7qTMEy+aBoX9WX5Le8rUvztmiaUPZmrj2eZPO2Nmg\/z7Yt9c8UfsFH4VEiiVW7vSI+p+F2rzi8frt+TmxvsHj2g1gzGbuMF2FwljPNYv0rIIH5ofhVk9D2MruvF6v9BGJWjEU41QHxDm2JpqmIqAJ+UIEYi1gGoIi9eGx+rEoghgkprqInQFsJFPpsJU7Rf7swvx7cjPWMMV0SCIVwmeqDXzzloi5\/rzmwri8mhHLHMNSgVMfSzsL03QNy77ACUSZmq96J3+SYnCs7imZtWor\/GZnGZp2DuT+KfFRMhGPCi\/C0uOkk83BrUyX0Xwm\/ti3tepKP5fXe7ywQM4fNFIfXEYh+vH489aTjkqQ1Vi0QM7+5hJl8h0BsF5nCX6rIcOxcflsSCHURd8XbLabyIp6\/1+Mv2g+TTlyMBXb09cU1T+Brskcmyof0X\/tZ+1GeD3di2ZqIw\/UiDsVmmeSbovr5vq7GKbbzuvkzyH4+tOa2lshrcFXGppHXZWx1nrc3W\/R57zOnPE4gugC2hE7re3eNCnQIoBSdIDrL4l5CUH9ug5DO7SiQJZTh8y0CcRbAOf80b3+9D8QpZoz5\/L5Yyk0jL11+XD+VQOyuNaq+JH50Pi7ZlK4T\/0\/Xqz98qc+Rc3tefXuWEJN2g43l7bFGjVru0\/Bz3pYIPVMcprpd\/47swgTfiMeyveIHXs\/jqznGWpwI53O5kPhb0gY6z\/UiM\/lxff6na8\/N424C0YmkMjjNIifFxlpVqoIRAnW3QGzv5KXAzsHrg26NUZ5Xav0sjRePNdwlqMmOBdhvFsnnBlf5J5+4eL\/5Kv\/Rvm7liLfDyktXF9wvHeQ\/e1XUiokL41pVX1JOVPkY8qzvOaTQ9\/Q8VJ3rt\/izWTsj72Fsrk+pj\/FYGld\/34avpD2p1y1xOJ0nPtC7Qz627Yf+\/XF9Tb\/Nt4yTa57l36VYe+aLO3EhD+uFRx7HwO5CHgiLSqcEtvM8X7LzWf57RL\/rBWIsDsVzOEZhkgDHZ3fmAiaBDw+ZxtsWqoAXRf8ecaTazeGS91nBjTbVD8pWY1zYNfCw1ZPG1E7LPzO2zl4nBZ3X04umRxSDw\/Qxw3tcgBWLSSn2WhyJSEm1Ki\/803gbfZl5Fc6N9WyqCw0xE+tZneu9frZqS+y7GL9r0\/aB1LOe15mal+1Mztqlaljtf2e\/mpBVbQrnG2Pr9Rnn9cT5COf0iTiLtTKHrXMqxqzcVaxmPqnOvT2Hz87jeoGoEjpz6gm\/92CdOPiNye3sUGL\/ufNqi\/idPjfDox9asO4cV5nYziqwJlHdENwnnF+2yAPa2Dln4Gp28+StBaI83zi\/XX1UQIvdVECfBZ1Ce1SOG3adXOx4gftIsSO7dWdd8IYdpbOKW+ov9fcFGXhvgegCGm4FldvWRxcU599haQiDF0yyo7N0WPvOmJsb3FpeG4\/7by0\/OxdZ7K6NOec\/m9n36B+BKM\/utJ5HOKJgmXZXHrk78R7JQNE9Xpwn8XOm3DxivTi6TZOoPuvO5\/FyhjpGTLZiAIF49OKJfdy6gAEYgAEYgAEYeDADCMQHO3wrZU87rBJhAAZgAAZgAAb2YgCBiEBkVQYDMAADMAADMAADigEEIkAoIPZaidAuq1wYgAEYgAEYOA8DCEQEIgIRBmAABmAABmAABhQDCESAUECwujvP6o5YESsYgAEYgIG9GEAgIhARiDAAAzAAAzAAAzCgGEAgAoQCYq+VCO2yyoUBGIABGICB8zCAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBQSru\/Os7ogVsYIBGIABGNiLAQQiAhGBCAMwAAMwAAMwAAOKAQQiQCgg9lqJ0C6rXBiAARiAARg4DwMIRAQiAhEGYAAGYAAGYAAGFAMIRIBQQLC6O8\/qjlgRKxiAARiAgb0YQCAiEBGIMAADMAADMAADMKAYQCAChAJir5UI7bLKhQEYgAEYgIHzMIBARCAiEGEABmAABmAABmBAMYBABAgFBKu786zuiBWxggEYgAEY2IsBBCICEYEIAzAAAzAAAzAAA4oBBCJAKCD2WonQLqtcGIABGIABGDgPA6sE4ud1GIdh6d+f8c\/iOcM4\/P1vR1vD+E9PW\/\/9q++8f5Zsd8f\/N\/7d0+e\/f7rs\/89fPX3is5wrfJYxA2dZnpGbeZ4MXfWM2pL7jNpCbcl5SO\/fpLb8\/ho\/VmyKrRKIKP\/zKH9iRaxgAAZgAAZgAAZuZQCBuEJN3+pkriNBYQAGYAAGYAAGzsQAAhGByDOIMAADMAADMAADMKAYQCAChALiTKsbbGU1DgMwAAMwAAP7MLCRQPwYv34P43D9RGx0Cs6PX9\/jsPKB0bdLgp\/XcRiu42enT9\/OP2\/gF\/Jkn8J\/qFwhz5k336CWHSrnOv2NQJx11Od4HYbx+9fHtgk8FcRhvP58g+Lf8O808S+Kv7DwQEhvy18jJocrYOTJm8SdPD9c7p2lRmDnrjUCgTgL2A4C8cfX+G2JzvB9+rP78HMEL7or2ycQnYD2MWB3+s0WE608ER6GeoE1\/QzXKy4mglB+5G56\/EmzRv3x+Zv9ZErL79H2dK69MCbP300kVgw1WHs3vxxpvAjEBwvE5iQWJkRdPEPRXNxpO5946BeIl\/HCTtKuq8QjFSSxpZknIhB\/f4\/fhShpX3O+\/PB+SKLJC7YHPG4Rcy31LTGR1yl3le\/Dueq7y+hz\/Hv8+pH8L6JA17lwPPadzpc+eX0tn3ieMzZkgwSReKhaf7NA9AFOq2GVFOwAACAASURBVMJp5ysLbhIA4faB\/Ph0UURc4kvRiLtnWTvx+HSdCCbfr3nrV0CT\/kpxZQqxy5hPLpU9sa2ZfmeFZkjuRt9T8Wsdk\/FEn2TPe8qxYF\/tD+2vYcgSMtg7jdu1XbRlFfAy5mV\/KeZ5MfM2+HNLewp+ylhFn3IL6q0myFYuTDwEhq5f49dvzXOew+KvKpdjHuU56dtRfBt1Ku5mx3qwp2DzzEseetv27O8SaoD0IX7ue67c+zmPR1anYh47n+f1IK8T7j15Lty+9Gsrv6cFQs5QyQefH83FDQLRSuK6GOSFOQmJsuiE65QwCOdkBTpvSwqmtask58VzLkH45cKoAac1ucwXs\/WwevukABfXN+xyQOjJQXzmxFWWTOXqO3xOvk9CvPaPbsvbmbUdd22yX2EP9ua3fu3x2ROCfW7hk2xiqW1qn\/voJKK\/bWMxz0aqIdN5meDTOSx5kudbXVvyhVHKldRHjG3gPZ1T5uW2Poj9hhzQNWDfvnzfhg+yfCztq\/Mz+D+r49M1M3XOHa\/becRY6aOM556f7fyWfN3hmf8Zbvcc5yu0vV4gmio\/BDcr1h6CheeEzLbqW4p2W2WfvqDlBdwHqCh0jQKlJxcpGK025fia19Le4tqGXW4MfnIQwSaJlE98rq3c1lZf4fusaOu2xaa8LSnaZX\/yvdgln8vzdFuSNHaRkP6N1xn\/SJu8Gn47XXFssStj8zz5hYl7n3hTOdxZW6JAzGpXzLkyT7LPnjWb7T049HmaxrpHH7rN3M\/i+\/araV\/I2fjspHwufK36Jc8PdYtRxWajWqLydGpT8uiTX0PZyMdbxW21QKyD64pGXdS9AEjiwTLYLCoKGP\/Xwy0xoWwJO2b57pj0qc5rFCB1TgySgLvFXzEvtNWwy41B+7IWeTLO+BraqsWytJUmGnvceTxn+itstuNkj9s+tz0BaQE8dx7HIgeR4zP5xOYljckfl51rx5FwnrM8vc\/EY3m9XCMCsawbeVtt9vI82dfH7fHs1a\/2c\/Kf0V+ovRITfW7wUfMxmLK9pfiX5\/NZ+\/v4\/lC5pRZyj8uns\/nsWfY+XyBWq3IHuC5OLTHRBk0niSquhagRx6u24sS6ZbFaaKthl7PP2y9ie0awid0zbXlfSluh7SoGeaLm77VfZXKVydaOkz1u+9yifRnP9Gq3I\/Hjdc53Zzq2FGd\/PIqRiXW\/4MlzOH+v2bCuX7jTEfIpPiMdn0EMz9DO7Ygphm+Pg68BaWGnx3R7u+12Cj+1xiHisKoh8kzjkH7vVc41hbuMYSn+ch6v7dgd2zeSm5\/ut4AVCzNzTYs\/vt91x\/nQAnFeeBTiRq1EdIIIkB8OpoZ4UudE6LYsVgttNeyKu7OxAG8hENNEY487T9T8vfZr6Utb9Nnjts8t2o9xcN\/b7Zy1SGJ3K9ZLcfbHo0AMCyi3A5iznL\/Xvi7ab+Sdvr64RnHZGse230\/2qMl02\/a1j1zbtZ+rc6JwTvUknROuj3Ur2CvXNEX1832dxrC3j9+zfV\/7s4VDzCdifzT2VgtEc2KXlWGW9P68tFNlDrwl6orvzT4rwdCCq\/jenBD8OfX\/bDIjjiLUvUm+0JZpV3oeU8RyLRit\/lt91d\/riTC0Vdhi+7++XW2eF9hI9oc+ihibfOQ+LmxaPD+\/lve7rjK3jUXNqG4\/5GpWa6Y\/WLt+KoHo\/4jNqD8ldw2udF4s2VTnoBd02z1wvywQg43G70Nq\/9W22scNP+d5FPymd4CytuV4Hqfp+latDdc24mHbmPWX28b7Y+d7K8ZlbhLHp8dxtUCUXaM44U\/Bdr9Jpv+rvS6BKM8uqlVmXZgs4WEVTKvP+ryy\/fDZ3TZSdvji4683Jpob4LXGEQuflTRBXGm7wkRg2BrbcraFa\/Nnq5r+UW1Z7Zc+SzuxkQOrT7F\/7ofBqwnELvqW7Wq8N8SD621fP9svs3li7mw5ZkMNiiyv4zjPEzf+Ke9jWymfFO9N5kLf061oa3dtvd\/rOla2MV\/H1sfUyHkZb6hVTXE4nSc+0LXTx7YtnMnzMq6v+bniOTDVl1+v6ZP1Obq\/H9YLRJf82cQvRWIKeDbZ9ye6FJL0m3glJFJU1DNAefGWwhX\/oCO1pcVVcGgscP48NzlMfZhtLtvXHVhLBIrthU1+rLq4+n6CPaatBTAqTm6s9WTlEzXzl5vUsjimsWUTUHgGq5xU3bk6Vq4\/b28Z06ndDvvUmE27ijGLP3l9+uozsbMyRnN5YgrEjDuVFx252+hrygvVVloUqTqU\/9RUzlxku865Xr+YuRlyz8rRmHul3blds+\/rHM\/HKvk+a5fqu\/a\/a0\/aqf0QzifPz5u7s3zpOlByZM4RK9qredL9cXy9P24TiA8Omi98txfaI4Hhk+I4Y5nsUUV9PUS7+3eabC2xfEBbH5wbu\/v+SeM5Wp6s93MQW4\/MLVlknlVgkedvIQzX5xJ1\/lk+QyA+egI8WBE\/vkCcudX16NjR3+MmsIPlydoC7QXuIxc1slt3nMXnOp+R5+v8hWjCX\/szgEB8xqQfbj8dYUv92AIxTHqP3IV5Bg\/0aQvPA+VJ92QUbLYe5+huYyUP999a3n+imR87eT7vn2fHh\/7fNT4IxJXFeCtQpqJ+AOFzaIE4TbZn3RGhqG6RK0fJky3GQhuNnCDP7QXSk+YmOG1w+obxOIVABFiAhQEYgAEYgAEYgIHHMYBAfMNVAQn2uATD1\/gaBmAABmDgjAwgEBGI3N6AARiAARiAARiAAcUAAhEgFBBnXOVgM6tzGIABGIABGNiWAQQiAhGBCAMwAAMwAAMwAAOKAQQiQCggWIFtuwLDn\/gTBmAABmDgjAwgEBGICEQYgAEYgAEYgAEYUAwgEAFCAXHGVQ42szqHARiAARiAgW0ZQCAiEBGIMAADMAADMAADMKAYQCAChAKCFdi2KzD8iT9hAAZgAAbOyAACEYGIQIQBGIABGIABGIABxQACESAUEGdc5WAzq3MYgAEYgAEY2JYBBCICEYEIAzAAAzAAAzAAA4oBBCJAKCBYgW27AsOf+BMGYAAGYOCMDCAQEYgIRBiAARiAARiAARhQDCAQAUIBccZVDjazOocBGIABGICBbRlAICIQEYgwAAMwAAMwAAMwoBhAIAKEAoIV2LYrMPyJP2EABmAABs7IAAIRgYhAhAEYgAEYgAEYgAHFAAIRIBQQZ1zlYDOrcxiAARiAARjYloFVAvHzOozDsPTvz\/hn8ZxhHP7+t6OtYfynp63\/\/tV33j9Ltrvj\/xv\/7unz3z9d9v\/nr54+8VnOFT7LmIGzLM\/IzTxPhq56Rm3JfUZtobbkPKT3b1Jbfn+NHys2xVYJRNT5tuocf+JPGIABGIABGICBIzKAQFyhpo8YQGyisMAADMAADMAADGzNAAIRgcgziDAAAzAAAzAAAzCgGEAgAoQCYusVCO2xqoUBGIABGICB8zFwg0D8GL9+Zw+6Dt\/j14\/zDXw3WH9ex2G4jp+nEZ4+nt+\/PhCKp4nZ++Tbx6\/vcVj5YPVuuQ0fK2sEtQUW36dWvWKsbxCIWcAnMXS\/QJwmgVOJqswH+aTx42v8HobxdGJriuMwXn82xpWPkfcrJ0l8enPhhMvzs0YMzx9Dav7bxvCNBWLaCd1G0H2OV\/fzONdPEyb\/E0EdO4uhoKY\/v8+vSTan4\/lurvQfbClFdxCw1g6nF+n3i\/2bxQBFyOTmbf3ZXGwJ2\/WCZsqxV9xtjDUhrwX7Ljx8PUi1pV0jUzxa51Bb9o3V2WtEYs3gO85ZgcWl\/M7OtzY8yp\/qM5nN2pB51jzvDeastxSIsWD93G7Hz7dpAB4g6hGIkiga7M\/x2kqKaeKwRF0q2nlb0r4lEC+XID5bfb1BMpy90L6S\/W2xF9j+\/T1+F6y2rznrBB3Gev0ce+rHNvEX\/\/b9Xpq3y0\/e7UmU2rJNbM7K8YzdSowV86ex+zyfB3oDJZ\/74vyWb5qE9hW3Rp8X67w3mQ\/3FYgq+K6I5AAkESMqXb+Gc6c2nAiS870gioWpmCQWE9EFW64J9ilAbgq8t22unXmwXQKF8TV2IM1xTeAaAlF89uua7Wi65Pkev9x3Kg5Z8lrJcZM\/sja5np3BtQyEvNQFXpiSPPnyPGfPP085Jrkd+kyLorADUeaX5MqPSxBhczsVUoPCOa08Wjte83w\/2YkPluuH+Oe+V8uHZu1xNsc4Ldc\/mWRlPM02TV\/cNyb6Oq7\/hLdP96yxyqcGU4E5c66V+TBs\/CjW5FhWLxwX5caO2KN\/TDoIz7J2vAGr+wlEK5DuO8PJZZBUQk\/tuN0CJ4R8oNz76VZuI+jq+rkgWjbOnd861mHHcoEPk08xwc2OpdVv8JkX1UFAunOd7+Mxq2gEG4wYzdrR8gvfIw5vYGC2HmQLqem8jFVd3ENRNyaduEB0toUa4BanadIx8sCoFcs5beXYbd89pK8wRjWxNuOXT5qNyVxda\/hUHb\/NL9SlE\/stm7+qnG+ymHOXjz1j0LhW1wa5LjA5pMdV7DzL2n4zZvcTiFnwl5K4giMPQgi2f7avKPpTHym4S\/1Ux0PbaWIQcNa92vDpNmzw9DneD353osumlo+ncaWdVteW638q\/Nmxyh+XsIuyRqTmseI9gvBuBloTgORKLjTc+3RXQuVhKzfKmqHqi\/RR54FqO47xcRNHT\/2w8nnVd+KzsAOT7ugkH0t7umb3+cH2YfK5tM3rO\/hEM6N5cuPXxxMToT4Uc5RiK+R0WugYNSWeU\/bjPw\/x11nC56K\/ZM9rx2o\/gSiFNzq67cgajuzcGEj3XQFHWexj4c6un\/sutN0lxprtGPAZ5\/YXeAF07lZXGJ8U9GLb3N\/OyW7Ru+e1ZCKdxmzclg42z8bCGNe7JArj7MypuxkpC3bZb8iPsHPoeJX8zSeJdr4V7av6kvrK21qcrLJdzL04aY8n2Xxv3z73h\/QIzhTLUN+kfkzfFT5sTubaNmqL9se98Trz9SUL5Wc3Ns+8nqtMRsscLj+LbshqRrqdXbLsY+T7DnPwA\/L7qLHcTyBmhWRuJeocY8ERHaaC\/Q4CMRWRmAwtkd0jEENyyCQqt9TS6ir1txiLuyd\/3VeMMe2y8xgZsAt2YsUfj78WMNUHvxjKRV3+Pl3r+LOur+9CqOtDDUp1TJ5BfNwE4ieseidPj+2+\/PL1Rk\/IU\/uqBte7q+LTWGNiLLU9s3W+cc2W46MtHY+n+aPgydnRYsNzn\/Lt+9en\/x3mKNqMDZqq\/XSOyuuJubLehPogC6KY+0ZevAGzOwvEDMiw25eUezrWgmMCWAX7vQRiPv44IeZQdgnE5Oe8PQRi4Zfcr7x\/omAtC3YZp0LghZ0Gx3Ne\/PP3E\/cxpkX7qr6kvvT1xTWxrXS+7mP77yd7ZNLaq\/9WPcl9ZJ7T55\/ZOr\/XmGj3ibls5UESa3nO9LOhWTOvy3kN8ff5Iz8Dl9mlzg22VXnm+1TPLr8JV48TiM6hZnGZ+d5dYwVQngeY2qtX\/zl4s+9D20sr39k2ZCtcbGqAc3OBDzauEYhm0ohdyp9ZooTjemKsjy\/5guP47D4G7AkktRmKddxBCPVDfgpG8rC31jTyQefBkk11zGVCure2yLiX64dMbvfXw2rxmPlSxtXcTVV\/7KP9on2qj8k4eX1xv8h85n4zuPlvZqd8YlGOJ+bbbYV8yBjOGdNzZUsISj\/S74vHSLTC5TLuJhCd48tC0yxyAk1e9MVIVcBDoNQkcH9BvLuIN+DLQWyOPR+nMX5\/XWN7u9Gvhr6EWa\/AchvlVpEpRsVOXg+2Ii\/je\/7PPfxqRl1dcL90kD8\/V9SKiVtDXKr6knxXiZkp1\/K\/dE7n6hxy38uE4ibBbSaVxfoht87dpCv18YZcrfsxfFa1O1dTxE897ci5vNZMvbZP5nPej312LsyZNHPaqAchp3Od4vsoNEU4T9ec146H8LdeIIqYs9R\/UZjE2VHdF8fFiOlVghDbDYVVBbsIshFg1WYOjbyfs7\/1rJ9c23xdLpCVL8pxurYrHywU++n8WjzOJ9uMrY32Fn3a9Mt7JBH+2TjOKufLtm2h4Zkv8yUXan7HoloMNvqa8rWsV2btqPNP17PbBWK7Zhi3yuJzXKUPSv8tfy77rXxW5ftMTZFzqS0sLIUF49Was2JOy1xpbKCYtbeR03rh5utBLg6lrZJ\/p1+Wc2A5r6T9M72uF4hGcM804L1s9TA3JotT+CxMpr1JeIoxvWbS7sXwkdr1Rfp2cfX8sQQhW4rMPfNGBOzhcpja8nweqYXEYD0DCMTNCvYTJoTNbJe\/IjuzwF0PPwXjwD47rNjp85kXuI\/MJ9ktPZ6oPv\/iuS\/m1BP89GoMIBA3FFnyBzWne1Yh3Nq2tttfDXjGc6IiHrg81e2dYPNWzx728BpvxT1yt7K3blJbuLXcywrnHY6V1xCIstsgzyq0Xh9x62UqiMdbxbcnGr\/zcKpJmEJyuELS5us+QTqJnyMKHxjsYJDaslde0O59dQX\/9fnvNQQixbqjWPcBQeLgJxiAARiAARiAAQQi4hJxCQMwAAMwAAMwAAOKAQQiQCggWDWyaoQBGIABGIABGEAgIhARiDAAAzAAAzAAAzCgGEAgAoQCglUjq0YYgAEYgAEYgAEEIgIRgQgDMAADMAADMAADigEEIkAoIFg1smqEARiAARiAARhAICIQEYgwAAMwAAMwAAMwoBhAIAKEAoJVI6tGGIABGIABGIABBCICEYEIAzAAAzAAAzAAA4oBBCJAKCBYNbJqhAEYgAEYgAEYQCAiEBGIMAADMAADMAADMKAYQCAChAKCVSOrRhiAARiAARiAAQQiAhGBCAMwAAMwAAMwAAOKAQQiQCggWDWyaoQBGIABGIABGEAgIhARiDAAAzAAAzAAAzCgGEAgAoQCglUjq0YYgAEYgAEYgAEEIgIRgQgDMAADMAADMAADigEEIkAoIFg1smqEARiAARiAARhAICIQEYgwAAMwAAMwAAMwoBhYJRA\/r8M4DEv\/\/ox\/Fs8ZxuHvfzvaGsZ\/etr671995\/2zZLs7\/r\/x754+\/\/3TZf9\/\/urpE5\/lXOGzjBk4y\/KM3MzzZOiqZ9SW3GfUFmpLzkN6\/ya15ffX+LFCBK8SiGw5s+UMAzAAAzAAAzAAA6\/PAAJxhZomIV4\/IYgxMYYBGIABGICBy4hARCCqZw5ICgojDMAADMAADMAAAhGBiECEARiAARiAARiAAcXARgLxY\/z6PYzD9VM1zgrkQSuQn9dxGK7jJ3C3+fvxNX4P3+PXjwfFhFi0Y7HCNx+\/vsdh5YPV1J2jMO7nhe9fH5uwQFyPElfseBcWEYizk9XneB2G8dAFbhI+B7dx1scbFJvgg+vP+bb8X+EjpE9T3KaFzzAuxfU049k7D47YPjFEHB+RS2zq4hKBOAvK1gIx7LRuJjq9ffXObfi+\/LmeV92J6RSIl0vw\/6v6YZblefF8OJHVXPgktkvhOC0AXjG2QWQ98i7BtHOb1Y\/2IjnFo3WOb4vd+8Pl2JPrRclYPY+drGY92Z978IVAnA2qL36twrcmILFI\/nS3OrfZ8fNtWjtilt0iTl+wUHcLxMt4aQoPitEanvc+ty32giD5\/T1+F2Kwfc1ZYxvGev0cH7f7Lf7t+700b5f\/bb12nWRhtne+nK19z002F4W6jEg8Vq26WSDmhSH+2GT2DGISLyJMwg90FkXdgb20kpiOT9eF4hVWtmZBEtDi6rcQUA0xMY0n2FbZE9taKoSN4LodABn3ZgLF+8L0waV1rC7+a+JUxrzse02cKh9n7EzFriNOpT2RwxCvcodJiqi\/ruBidqHQiCvXdN2mEL93vzZi768PDF+\/xq\/f2QRzuXgRJXkWYtPHmW9H8VS0o\/qO9WBPhnzdFIYfxezUjzl2IwdinFr1JruGW8375MoZa1DkJuPDjWNiROd0d804ox9OYPMNAtFaDYbvskk+L8xJSEhxlz9mEfGYF9qWiPHiTAqmh0k\/nyR9xnNk0sj\/OKEBp10YOwrf2iCH\/pNPiiTpbW82mdp2ex+lJBSfOXGVbCrjVMdEduLyFV\/eVoxBNTH0xVzaj+0Ev5hxasS0WVwqm26MQW+sOG\/V5Og5ymtCHp\/E5nReVnM0G+s4m+ff3nme+nvQH4c9pK9VeZTX\/Ha9STmY4pa+y+PK+3fxi53fkq\/5PAQTz2ZivUA0hUleLHxQRSzMTvBmW7KSSOLPbqvss1WkisLUKIJ6chEwW23K8RteNxKItr1iT9vu0pflZwEyb9+fU0\/Y\/vtabOqYF3HqjPmuArG5wyr+41U4ePxrwUslrvN8du8Tlzmzzd2IcnEQ8jFf6Lgxq7aMz94v7Tzb2m+TPdlYt25\/ak9yMzwGk3bkk4+lX10T+vxQ+lTa4vW96k3NgfDzya+hVPXuuWysFoh1cN0A6qJeigerCLSLngDjfx5BF6PkMGVLWfgzR6vzXkIg1v7W\/tX+U8cKPy3HKfRl3XYqfNkTp96Y7ysQl\/yXGFO+y5ji+718NMPu5H9\/XASdY052vvM835azlk2P46g9nu3i4PN3SI\/DTP4OY1TitPRH+dm2qVUfyCXbX6\/qlzxP9ULucfn0qr7delzPF4iW8Ag7PPkkYP0FXxs0nXCquBaiRhyq2opCoK\/wSRtdr6F\/mdS6ron2yLiWEqltt0wCssvnP6ddwNqemb6KsbQmgNy3+Xvdl7dZYo5AlFi\/22ubXc+LxYnf4crZyt\/fzVngPO2oheep5VnE7Da37mu72E3jUSJtu7bF5mYtKGpm7dulmHlbW\/VB+ud1+5ge0afCz6f7jVPF9MxcU82B7+GrZ8fv0AJRRFSrsAhoHw4euT1i\/BCyOq8odhIAdU6Esa\/wSRtdr4Wo6rom2iNJsZRIbbuncWZJ2ZwUYp8zfRW+7ImT7Wc3rsLmom3xk3l941y5pn6dGVMct\/ia19p\/e\/qk4KCKhz8eFxLh9q9b8ORs5O+1\/UX7DXb09cU1lU17+sO3PdmT5a0e00b9t2po7iPznD7\/tOrDLmN5QowYRx+HnoNyp9pd28cRfu7z8xZ+Wi0QzSQPty3zou3Pm9uZmhF1RREy+6xgasFVfJ8Xu1hE\/DnxL43j9zsIidC\/iN9bg6gnsBKYYswyntD32jjZ\/pe\/Pk\/PJ9nnFbYUsY3jL79fFaeiDxlv83Xt+aV\/+Rzj1vTxrT5ayjkfu5zhaXEoPwUjdyRKnsTO8nuTMy02rUdolsbvBd12D9wvC8TgtyE9u71kY3W84Yt88S3jau6mqj920wzM1yx9bmWbxI\/XVX\/wdUg\/dnB2SLvfkL3VAlFu\/UWBMwXb\/SaZ\/q\/2ugSiPLsoRX0KQD0BWMLDKphWn\/V5Zfvhs7tdpOzwBctfvyB014ATkiP6b821+bnlRJcfq8Rz+itMvaUvIm9pfKXPUnv5OPriFCYy5Wuj\/TCGJATm4iSTYxKrswVm8t0dE6nyNRPbrK9v8JXFUerDYsXFP9SgyFUnZ43JqhIzgZmc92RTyYDw6G5FdzK54Ke6jpV9zuVHeW77c92P5e\/yen\/OvG962inb5XObsXP7puJsq3lxIY9e1Z97jWu9QHQBCMXSryKz53+yZ3EssWYPIi+m9u8M+raK537iRKATpTrXOi\/AKKtgd3tqus46V0SsPG80s0K2x5fElPSnX5fEmR5f6mOuKIdinNns+pTnDlMbvQLR2VC3WbZX+b4huuOOTGafObmsitOyfTLuavKnqBxrV6Ih2nz8QpyzWuO+j+ypHF6uLbLgLVk2GSl49HncyN9YI28XiH4SLeqe5Ewx\/rYPWvWj\/X3Zr5mbKmd8TGbPm\/zR8JVqq22X5C+vr+Gj9Zy9xrjPxO9tAvHBCe2L\/+2F9kwBWWOr98txiu4p4jQrPihAa\/jb81w\/eZw554OQVYJ1Z75EwBricc9YLbcdhPrh7No5Hg+eJ5fjwHjx0ToGEIinTuInTEIz\/jq+QAwT1SMn7Rl\/UaxmitVhxc6MzVmsvcB95OJNdkuPJ6qPtpAl7\/oYxk\/4CYGYFfVTJsSBJtKjC8Tz70q9WcFa9dzfQXyzwa3ltXXI5539DPXatjY\/P\/ijvIW\/eT9nr+PYf6zHXIjHFA8E4o0gxKIszwQ1Xh9SGKci\/Pydg0MLxElIP3JH5yCC5Ua+jzKBT0yx43vSydPvas4+m3hyPo+SJ9hBvd2DgVMIxD0GTpskFAzAAAzAAAzAAAzYDCAQWcGedHfCBppExy8wAAMwAAMwcD8DCEQEIgIRBmAABmAABmAABhQDCESAUECw6rp\/1YUP8SEMwAAMwMDZGUAgIhARiDAAAzAAAzAAAzCgGEAgAoQC4uwrHuxn1Q4DMAADMAAD9zOAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBQSrrvtXXfgQH8IADMAADJydAQQiAhGBCAMwAAMwAAMwAAOKAQQiQCggzr7iwX5W7TAAAzAAAzBwPwMIRAQiAhEGYAAGYAAGYAAGFAMIRIBQQLDqun\/VhQ\/xIQzAAAzAwNkZQCAiEBGIMAADMAADMAADMKAYQCAChALi7Cse7GfVDgMwAAMwAAP3M4BARCAiEGEABmAABmAABmBAMYBABAgFBKuu+1dd+BAfwgAMwAAMnJ0BBCICEYEIAzAAAzAAAzAAA4oBBCJAKCDOvuLBflbtMAADMAADMHA\/AwhEBCICEQZgAAZgAAZgAAYUAwhEgFBAsOq6f9WFD\/EhDMAADMDA2RlYJRA\/r8M4DEv\/\/ox\/Fs8ZxuHvfzvaGsZ\/etr671995\/2zZLs7\/r\/x754+\/\/3TZf9\/\/urpE5\/lXOGzjBk4y\/KM3MzzZOiqZ9SW3GfUFmpLzkN6\/ya15ffX+LFiU2yVQDy7GsZ+VnQwAAMwAAMwAAMwsMwAAnGFmgaoZaDwET6CARiAARiAgfMzgEBEIPIMIgzAAAzAAAzAAAwoBhCIAKGAYNV3\/lUfMSSGMAADMAADcqXJegAAIABJREFU9zKwkUD8GL9+D+Nw\/XxhseHH+P3r48XG+KrjojjcWxyOcP3Hr+9xWPlg9RHsxgaXf9QWOKAOn5kBBGLnDqL\/C+7r+Nl5\/qmg+Hmd\/lL0+pNkPlXcXpHFfExwef7FKDE8fwzznOT9W8UTgdgB\/LSLMXyPXz+0gPLfZz8bEH4e54xCqzVGBJOOOf54kD9+fI3fwzDWO\/af47WRZ9Mi7hV3G4PIGoa9F6jhTpDxM19zcfA\/FVLXR8kVasuDcqZjLpOYPPfV5syaN6s51sjv6hzh1zi3\/Km+mmtilbOBQFxMKj8hWSB5MIuiLcX8dLfbQ9IaSZUDw3sKyCMYaIu9IBB\/f4\/fBavta84aszDW6+foJ7ai1izWrrXjDjVgqXYF8Z4\/UuTta4lEassjcubMfYjIy0Xi9J3Kccl9\/Vt+5jxc5YaI0iyHwlxtze1n9uWWtt8sEH1BKHbPqsISAiqKvloB++MOCgHEr0azIMZAl221ilF5ntVWf+Gcg691TMaSw+6CJt\/Lj3OWYE4+dT6UAtzYKbHayot1AkSSQuLU8lnwB7eD3ur2QeKkPx8eck3gv8wf33fI7+vX+PVb8zzlj5pQ6pyr8mTqy7ejalrRjuq7Wc+29KPPXfGBt+2+WrYcu1Avqjqux2X5WZ43rPwr9ZvaQm0RFsxXn9flnFgy6+dQnfeteVhdO\/Gnr3PHu6417dU5ofp6ofNvEIihiKgCahSWUOTzgNdFLhNzsShZ7cukkP8RzOd4VTZcorCa73NNYI1xZcFvw1XbW4296R8n5tJE0E4IDbs7TyYTD2ttg9WWBru+Rh9f4zvOxXe3MdDOK9deYnQ6L9aNi99lizUh5G6WS\/HaeE6qGW7RlupG6iPGsJmvKVfjuVmN2Oq7qn7s0MeiyJv69L5JvgoxDgIwr1167IZPdxnDbcxpW2nj8f5ocFUwYs1h8\/XCx9Je1AQmh6GYO4m\/xH+9QDSVeC2k5gKSiksIUF6wLVUfirMWQHUQ+\/qsrxNnVK8L\/bbBLMbVaKe83k8CWvjJbmI+dnucelxl235sdZzKMfe0XV7DZ+17\/HGPP5YYDbk1CUP3Pgk0xa5Zpy7jJQiZmE8hN8udL9XWpRSfMj5vS6pn8v32r5M92Vj3YUxEtdxx8K9qfEYti7Wm5fMwyZc+3WcM2\/seO\/f3aS\/f1nmeP82s\/uUDo6ZEjh+Xw2fkaLVAtJO8DEDL6X3nxYITVw++PbfKj4U9HhN4e\/uU8zteFwpebae0GcYZhG\/zvKJ907cRZGlbtsWHmZ\/\/KP2crjX7yHzZtDU754ygY3Ni4Ni+aOWx2B9qQdg5dLyKgMnZnt6bgqpo38gv55+8Ldl5lH6S\/9p5ls4Ru+97bY\/nvnYX7QyCOgpo5a9i\/EU9K9umtuwcq5PVaM+0CLtiY8QaS8midc70XagRMf81p5rDoh4023zP2O0jEEMRkWftqtd4W8gOjg6gBCYEOT7\/UwDV3ae01\/F6c8ELgAaBqBNBEkJe0zj0pBTsUwU5s1mSRfwRferOkQSRPorXYsc2L+S277N+SSCeJdqVAbsmJEYD28L7lB9+FzHPn\/x9ujbLDXV9vfBU1+9RW1b6cLInTniPzUfVd6xHRpxurpePHY\/mgb4P4Q\/JMcnLMj9kvpuZu9Q4wvl+QykJRJXXUx8Gx2Xfb\/x5H4EYBEq94i6T0Q7OokgRmNRPz9htKWjWBvrWghfsk\/EvjifYVcObnpFq75yG3Q4nFGNypYRYO\/5eW9e2y\/kl+3y2mVjKY388se75d\/mR50\/+XvdTtB8Fj46Hvr64Zm0d2eD8yZ4nCURfE2QhG\/xv3M1Zqh1Lx3WcdDw49vr+aPIR5\/v0OMkiD8Uc7PMnnyODPxv5v9j+Bjl9hj5WC0QziKLuVwsUu\/CafZQBqQJ7uyhqBqrqQydpy04PoxRUee4p+1yOJXzWk9I6gMtry8\/NMRa23Hpdb\/ucpxnCH6U\/lvI4CJRYa0J+yU\/ByA5Da3FXft\/IcZ0HSzaVY0iLNlkk3hvnyZ5ZgRhsNITbfX2HdsWv1e13Gfuyj7RP5Tpe74vP6\/jPnE9Dfrb\/+Mkev28rm3PLvA\/zntlnMSe+c3xWC0T5o4lY+KYAut8kK9R5EI3xPNPpnQLx5zU+ZyTBqgBw7Xf1aQMl7erX+aJnweULef4Xka4\/Kd7zKyCzgFYTmGurbMeYNCWx8onUjEHuD6OdxWvy63mv+cEft\/jDyqvUjsWoy4lQg6KQCTkXP7tYGNdW+eVjVuXiqtoi+e4e7Shz9TYmfF2ZayuMzd1JUGO+rT\/xt+83m2hdPQg+y2t7t32r6tF9tssYeD2BH638kjlsbQ5ZbckcnOdGOG\/u7ty7s7NeIGZCzD9b6IvWVCDK5I8Bzp+By4uNL2p5oXEBsSYI\/13eTqNYLva5LlksWwSa2qb54uyLaD4GLaqn4znAWTHWEGeTQXgGsfSht7E+b\/YPfaaEyeOzzlfiF17x210MhBzWzItPA9NFrYm5qPInF2o+76o8afQ1l4v6mepGvoTJ5x6BaNYL85lj7xvbB+K3nlejXih\/Zm1UdbZRj2WBSW3h2WVhQRZqwvL0WvMzy3\/GZX1eIydFJGb92jUm4zza\/J7f3SYQ38pp9oR01wR4SP+FybSYeF9vnO+Z6GeLoy\/69aRxnnGEupFNZLvbLqLtcDlMbdk99oecU6i1Z487ArEjsWRl\/sqrDT\/G1sqLRD97op\/O\/sOKnb5c8AL3kfkku6XHE9XUlj5mTpejHXMnYzp37BGInZA\/vuA\/ECyexeD2T2cePLTgBy6r28JHtFVs2uDW8lofywJ2y2cP19rQPJ\/aQm2R3OD1dCwgELuh9Sv0U01WXWN71XE9UGB3+Rl7miJixn+T+HnkbdoZW26x\/72voba8d\/ypeWePPwKRCeF0q5qzJx32M3HAAAzAAAwcnQEEIgIRgQgDMAADMAADMAADigEEIkAoII6+osE+Vt0wAAMwAAMwsD8DCEQEIgIRBmAABmAABmAABhQDCESAUECwKtt\/VYaP8TEMwAAMwMDRGUAgIhARiDAAAzAAAzAAAzCgGEAgAoQC4ugrGuxj1Q0DMAADMAAD+zOAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBQSrsv1XZfgYH8MADMAADBydAQQiAhGBCAMwAAMwAAMwAAOKAQQiQCggjr6iwT5W3TAAAzAAAzCwPwMIRAQiAhEGYAAGYAAGYAAGFAMIRIBQQLAq239Vho\/xMQzAAAzAwNEZQCAiEBGIMAADMAADMAADMKAYQCAChALi6Csa7GPVDQMwAAMwAAP7M4BARCAiEGEABmAABmAABmBAMYBABAgFBKuy\/Vdl+BgfwwAMwAAMHJ0BBCICEYEIAzAAAzAAAzAAA4oBBCJAKCCOvqLBPlbdMAADMAADMLA\/AwhEBCICEQZgAAZgAAZgAAYUA6sE4ud1GIdh6d+f8c\/iOcM4\/P1vR1vD+E9PW\/\/9q++8f5Zsd8f\/N\/7d0+e\/f7rs\/89fPX3is5wrfJYxA2dZnpGbeZ4MXfWM2pL7jNpCbcl5SO\/fpLb8\/ho\/VojgVQKRLd39t3TxMT6GARiAARiAARh4NgMIxBVq+tnBon8KBgzAAAzAAAzAwCMYQCAiENUzB4+Ajj4objAAAzAAAzBwbAYQiAhEBCIMwAAMwAAMwAAMKAZuEIgf49fv7EHX4Xv8+nFsFfzQVcrP6zgM1\/HzNKD5eH7\/+lBgPNRnp\/EVnD+ai49f3+Ow8sHqR9t4jv7I83PEiRpDnI7DwA0CMTN+EkP3C8RpEjiVqMp8kIubH1\/j9zCMpxNbUxyH8fqzMa58jLxHSD+KAbjcljX8ua0\/H5UH9EPcnsTAewrEIOTSn7jfL3Ivl8\/x6n4e5\/ppwux\/IqhjZzEU8WRbfk25e5vv5Ib3U\/\/BllJ0x3HnbXpR6EX6Fn5AZLIC3oCB5mJL2K4XNFOOvdBuo8\/JIset+hLzWs5t5zF5vgGbT5qsX7GuxJ\/Os7ie\/Jzy3c+JbbYvZR6UtaA8vnj3M\/V9uk2fjRh9P4E4QaIh85Dq79Ym49IuaI9AlAlB7+R9jtcSdAn+JCYtuxPYeVvSvn0LPIjPVl\/SJ6\/mAmAtL5w\/P1G3xV5g+\/f3+F2w2r5mvq\/TxEImuHwyXV3PyPPTxPuVa23czQ75nDMt4zZ4b83Vre9jrFfnyWX0bfpFFwJRgrLmtSlQQkGWAMcfns53rpKISbtlsgJ2r+HcGFg53wuiGLxikohArBlHsPN2CLxtc9d7e\/Pxl5PWTKK0xtLyv\/js1zXb0XQTw\/f45b4T35btxqQtbePzTVyV\/uVzn7gO+ZgvbpL\/JU++PM\/Z889TjhX1IC2KQm0pJyLJlR96QrCfe5QaJHVqLp\/3yRlrjMk3oc+lekae93FIvu7jp4lPyR3J5\/rOm816WODkedyaB5fiN5cn4dj1p7dvbm6v8m+p3xMd328H0XK++y4PbHDU7O7b1I7bLXDC0MPh3k+3cm8FowyQZWt5ztznDju6BWIxwc3C1+o3+Ozrh4M77DC6c53v4zFrAmsn66wdc77h2D5F9oX9OlsPskc5pvOyeqInlDCRqMVQ4DvPsZD7bpGaJgEjD4wasZzTVo7d950eY6Mtw1adv8b4XpgnPfaGzxj\/k+pUi0X\/fcrJELdpzss2kC6GYOyNZTNP8jYbdvT2cfLz9hOILfFiOGx2QpACPk0ERdEPsNg7DSsKwZ3t9BTtnsnE+8HvTlSJYfjt0vLx5LO00+racv1PfsqOWYWzZyzWdXy3gjcrlnwXJqi8OFs+zScU9152IsIOoIi\/Vm6Uua7qS+qvzIPys+f9wZNHaXuLmY7z7PGk8ZPP+OIxDOT5nPk85GU+t0edoHJbcvCz+HWV+hnlajyNPIn9TPkl7b\/nr3zsJxCl8MoOVquYXS6jDkgGibtGgRImDzUJdIAw03f845JsoqlAmr1+aULz45kKclcfIWHktryM1bJBJUrmt+n7MHE6\/7nntaTvyZ9hV9FoczYWxvnrfJXZSFtPWrEfPQZLBTnkR9g5dLzKYioXPe18K9pX9SX5Jm9LaoT0k5jvy\/10fmq\/+7swicljOLUNZZtSP5Jwtvoiz0u\/8dniZP\/vdD7H\/lReFnmWz3vhvKHQGZ7vOW3QypOiPoQ7Fst595r87CcQJwEgQZh\/Zme2WFmgiGgKxTNfZUTAugSI2NcWTMvtFfA2+m1PWG2wBPIS\/mhTnih5v9P3MkF4+yLgyp9137OxyPvgPQJvFwbKAl0yGnJWbi1PPHvWc1GXv4\/5MtlrXV9PJOr6OAlJHStexZZd\/JGPP9QaWexV\/fXXM\/I89yvvdY480h9FPgrTcZ7yx+P85Y7n8144Tx2f2pibl9t5ovJ+asfoX2x8g9edBWIGWhBz1h9IzBarCIprKwR9E4EoxbaeHNYlyxyIafwTeM3Cns6r+pbJyZqE8kTJYVUCsWhb+bM4trSbm\/fBewTiLgwsFeRQ3LN8cLnlFol5cc\/f65wq2m\/kg76+uGaXcde5qO0Oxxv2xto49NWz2Zr7zPHR95vVlTqfPffhe4NnzW4rN1vz8sy8b86nrfY78\/XkPD9OIDpHmQGY+d5dowpiCO7dAnEGkhsCqicTG5zpnAcJRJ1AhT3Kn8Wxi55kzQnqBv\/QTu1nfNLySauwy\/nGhOLqyvVTCcTuWtPIB53TSzaJbenV53v+hy\/p2F2xN+1dX8\/0+DayjdrwZuJuC26MfA4c2YyWuVh+FpssYTefJ5Kz8jiH9VrvVEp\/r\/m6m0B0IqW89esDILc+M4eGomf+yLQqiCHAdwnEeUhuKt4t4ZsVzObY5Rw3zmxXROzw1zVugTf6nRWIs89UtJNV7OE141Zix+umE2MPv7pWuJx2v3QwZP8tX1ErphgZfKv6kmI75Z3UGXftlGu9gi\/VGOuOye05FOzP7ZK7KsZOS7sfww8wvCnDbd8nxjjH+WKGxZCbuSgz59GQm7neqM9LOZmftxwDb19uw\/I1rxPj9QIxBM1S1+Vvh\/kgZc\/rqMJWODEEObUbhKQq4EXRN8BYDF7VT2Zf8aDrYluxqC5DVPlC\/ggl31W0bFv0WS0eeyZYE\/ip\/7q9fj8UMY3+4Xt8uIIBlfPldfaE4pnPBaK7Lk0KUlcq7ht9Tfla5p5Z+xr5EnPZWBB35oVVM6rJLfaT1zF5P2db41inbfBccsnnfiZCDsc5UHj1r4rxKuca+VTmQZm75XHV91wuLM\/t\/eM+HyPrBSIFxFxp+glqDrSjwxEmU2MX85UTgLEdk0svjhqTwSlqUJgEy4nq6baT5+T8MXOeuBwvLgjEzQr2USeEPujOL3D7xkkROomfZOfgpAsWL3CPt2Akz0\/C\/2bzEuOl5t\/OAAJxy0Q866QWtt\/V1v6WfqEtc9eZwrVQuAKX1W3hI\/MUb2UdcPeTPCcPj5w72HY4Pl9DIIowU88V6OcapmeQHrEbMRXhA04OzeTzt5xONQk3x7IgOLjucAVoSSRPO16Hu017Rs7I8yXWOH5GrrF5T25fQyAy8Z9u4t8TatqmaMIADMAADMDAfQwgEBGXiEsYgAEYgAEYgAEYUAwgEAFCAcGK674VF\/7DfzAAAzAAA6\/AAAIRgYhAhAEYgAEYgAEYgAHFAAIRIBQQr7DqYQys3mEABmAABmDgPgYQiAhEBCIMwAAMwAAMwAAMKAYQiAChgGDFdd+KC\/\/hPxiAARiAgVdgAIGIQEQgwgAMwAAMwAAMwIBiAIEIEAqIV1j1MAZW7zAAAzAAAzBwHwMIRAQiAhEGYAAGYAAGYAAGFAMIRIBQQLDium\/Fhf\/wHwzAAAzAwCswgEBEICIQYQAGYAAGYAAGYEAxgEAECAXEK6x6GAOrdxiAARiAARi4jwEEIgIRgQgDMAADMAADMAADigEEIkAoIFhx3bfiwn\/4DwZgAAZg4BUYQCAiEBGIMAADMAADMAADMKAYQCAChALiFVY9jIHVOwzAAAzAAAzcxwACEYGIQIQBGIABGIABGIABxQACESAUEKy47ltx4T\/8BwMwAAMw8AoMIBARiAhEGIABGIABGIABGFAMrBKIn9dhHIalf3\/GP4vnDOPw978dbQ3jPz1t\/fevvvP+WbLdHf\/f+HdPn\/\/+6bL\/P3\/19InPcq7wWcYMnGV5Rm7meTJ01TNqS+4zagu1JechvX+T2vL7a\/xYIYJXCcRX2DJlDGz9wwAMwAAMwAAMwMA8AwjEFWoamOZhwj\/4BwZgAAZgAAZegwEEIgJRPXNAYr9GYhNH4ggDMAADMHAPAwhEBCICEQZgAAZgAAZgAAYUAxsJxI\/x6\/cwDtdP1fg9ypVrV6x8fl7HYbiOn8Dd5u\/H1\/g9fI9fP1b4FX+2\/fkg33z8+h6HlQ9WUzssxn2N\/v718fSYEh8rPnwHF8djAIE4O9F9jtdhGA9dVCfhc3AbZ328QVIEH1x\/zrfl\/wofIX2aQjwtfIZxKa6nGc\/eebDUPv5EHC8xwnEYyRhAIGbOqCeaDQViEDHpz+q32M3y9tU7t+H78ud6XnUnplMgXi5hp\/tV\/TDL8rx4rtl\/8vnNhU9iuxSO0wLghWI77Z6WOWzdpVlRW3ybW9SeJ\/PxSqy\/6Vgqvi2239Q3R6nHCMRZADcSiFMB10XZ72bp79ZC4RPM2hGz7A7i6BVvs3YLxMt4aQoPJry1\/O15flvsBYH4+3v8LsRg+5oXia0IwXwiXV1bWCTtyS1t9+VaNf9ZbM\/OzX39EI\/7\/HSzQPQBzn500610s8KVxIsIk3BuUdRdAJdWEtPx6bq0e+B24sxbvwJaXHkXAiocn9t9qOyJbfkxmP2uhTnYcXtblggUGFrHZHJNP5a5Jk5lzEvb18Sp8nHGzpTUHXEq7Um7sz5OZYylWPjrCi7Wxo\/z97sV04i9j19g+Po1fv3WC6wprkV96ePMt6N4KtpRfcd68HiGrDEK1\/F1qbZwq3k\/dqkLy75t5ffEpc7pyDR+XfbrDj66QSBaK9DwXTbJ54U5CQkp7vLHLCIe80LbEjHFpG8UOekzFwa+6GfQNeC0C6+3JdkvAmyD16UivhTs2WRq2+19lPwhPtOCu4xTHRPZiasXBUtx6ou5tJ\/H0hULM06NmDaLi8FO89ylOHB888LlmcxrQp5vic3pvKzmaDbWcTbPv73z7GtLy87c5u3e6zE22l2sLcmHcN\/wIXm9eV4La3Z+S742Nn6Ix27xkLhYr+sFoilMQnCzYi3CY3aCN9u6jJdiArfbKvv0Ra8Wc0UxbIgJu\/C22tygqBRjtIIz951tr9jVtrv0ZflZ+szb9+fUE6H\/vhabOuZFnDpjvqtAvLT9I+PnVVh69GvBSzUx5Pns3icuc2Z9DUlsxniWeRfqQb7QceeqtozPvr0Hc1TaXvkmxKrjvHJ80T+tNvn+KRP0K8alZk\/y6JNfQzlYnq0WiHVwXVGqi3opHizQp7ayAp\/OEWD8TzK0BIqyZaYoqvMOIRD9+G7\/aZra38l3Lh7af+pY4aflOIW+rFtuhS974tQb830F4pL\/Hi2K6C8xOsPuVDxD7oTFqGNOFoV5nm\/LWcumB3AU8lUen5CxJn+V7AT\/mHU1ndvK1Xa76VrOwRf3MJDnqV7IPSCfDibA7vHjI659vkC0hEcQOLKqbxWzNmg6gdVkUYgacbJqK0LUmhh0+9JG36sUcGN3I\/a71P5SIrXt9r5MPx3iP8\/ZMtNX8KVMWj1xsv3sxhv8IrvQa+LUOLcdj5kxdcdgKUYcb\/t\/zjdtdn17Fid+FzFnK3+v7bCuT\/kg56rrA18i0qpXYXZ3dgK3TfEXxtbxh2itXJXx8zrHKMfu4UNy69P9xqlimbp8j1\/3uPbQAnGN8NArEZ3AAuSHK+ANMaHOiYV+abLS\/SwHSAp8PSEtX5v3tZRIbbuncWZJuYVAlFvKrUkn923+Xo+5sHlNnBrn6vbX+C8\/l\/dtP+7hm4KDmIvSlz8ui0dnm2PKMZizlb\/X9hftN9jR1xfXVDaJbQ94bdgb7+IMfbWllavaVw8YzzN9Sd9PuW3u2RuMH8A\/UJ7BxsTGaoFoFha5DZKtpP15cztT8qyhcc7UXvre7LO6jdqCq\/jeLLD+nPp\/bFgSYmsK6Fbi0PepJ7DSjmLMAnsYez659sTJ9r\/89Xl6Bsw+r7CliG2ckMrvV8Wp6EPG23xde37pXz7HuDV9fKuPlnLOxy5neFocXj+VQGwuGLs402Iziq+svi2Nf8rP1i8t3OMzMy\/W15b5+nFr7LhuiQuOtzdpmjl7T75w7V2LgNUCUXbgZHfPf3a\/SWb9zE0SeXZihMKmbjPXE4AlPHwBTuLEtW+Jnfq8sv3w2f10hbLDFzt\/\/dI4lgrj+gJu+yvrp5zoVCL4McUYuWMiDrPdw5bP6r5Ln6X28j764tQX8+qWs9yCNuMk\/tU81OMI\/pt817fT0mxD+TuLC9\/fVZASk61YGixOz0CHGhRzuJMzU3CVAlEWs71\/YSk8ur\/ob43jFmbC2OMYXRupL9nJX2bW8uEt9nDNsq\/xkeWjal4OeZjPJ9Z1fPdYntYLRDcBhgnWP4vjC+AU8GyFbYk1O7ipwMmzPSUkvi3\/8ylyjiXmXPvVuaqYBudGsZR+kmW6zjo3K8DSd2mfPa4skMpfxTg6nhey2\/dF3rYlTADx99rSOMu2+uNUt1lOSJXvTTHn\/LIc88nOVXFatk\/GPrFqxjqLGULvbqEn\/l792hBtvp0Q56zWuO8jeyquHZw1+jIZKXj09aCxeIw5f7tA9JOorhdlzularM8dWrVlsq1hN9w\/j\/s3833Jtz2XUZNX188NObpNIG5oQM\/gffG\/vdD29HHGc\/rF3WOS7BRxagiCM8b\/lW32k8eZcz4IWSVYH5OH81wE0VwI7PlrjmA3NhAjGHg0AwjEB4vdbQN8rEno+AIxTI6Hm7QpfFVeyG7dSYWMF7jH26U72qKyivup6zF5TDxfiwEE4tkL0oEm0qMLxPPvSr1W8VmcTMJt2lPdetrg1vKiX26tWcG26jb1re1xHbejYeClGUAg3gi4F0PlMz\/154cU46nwP\/923KEF4iSkj7ejs5sYuJHro9kzMcWO7waTkN89P5XYfhGGj5ZT2PNmC+078ugUAhGgARoGYAAGYAAGYAAGHscAAvEOdQ2ojwMVX+NrGIABGIABGHgcAwhEBOIGt68eByzFAV\/DAAzAAAzAwP4MIBARiAhEGIABGIABGIABGFAMIBABQgHBqmz\/VRk+xscwAAMwAANHZwCBiEBEIMIADMAADMAADMCAYgCBCBAKiKOvaLCPVTcMwAAMwAAM7M8AAhGBiECEARiAARiAARiAAcUAAhEgFBCsyvZfleFjfAwDMAADMHB0BhCICEQEIgzAAAzAAAzAAAwoBhCIAKGAOPqKBvtYdcMADMAADMDA\/gwgEBGICEQYgAEYgAEYgAEYUAwgEAFCAcGqbP9VGT7GxzAAAzAAA0dnAIGIQEQgwgAMwAAMwAAMwIBiAIEIEAqIo69osI9VNwzAAAzAAAzszwACEYGIQIQBGIABGIABGIABxQACESAUEKzK9l+V4WN8DAMwAAMwcHQGEIgIRAQiDMAADMAADMAADCgGEIgAoYA4+ooG+1h1wwAMwAAMwMD+DCAQEYgIRBiAARiAARiAARhQDKwSiJ\/XYRyGpX9\/xj+L5wzj8Pe\/HW0N4z89bf33r77z\/lmy3R3\/3\/h3T5\/\/\/umy\/z9\/9fSJz3Ku8FnGDJxleUZu5nkydNUzakvuM2oLtSXnIb1\/k9ry+2v8WCGCVwlEtnT339LFx\/gYBmAABmAABmDg2QwgEFeo6WcHi\/4pGDAAAzAAAzAAA49gAIGIQFTPHDwCOvqguMEADMAADMDAsRlAICIQEYgwAAMwAAMwAAMwoBjYSCB+jF+\/h3G4fqrGWR20Vwcfv77HYeUDo2fw5\/SHTHBAHmzd67ZdAAAf90lEQVRUaF81TzbN5Z\/XcRiu4+dGPt\/UNmyiFsDAaRlAID4D3qmgD+P1Z1tAnrZI\/\/gav4dh\/P71cdqkOK3vn8Hynn2+cp5s6rewQH\/BBSe5+IJzxKbs4589cwSBuARrEDzD8D1+\/dgAxpaAiv1kP0Pgfm7njLtxTOyI46W8WjreypPL53gNP0NVLrCm3etXFEkhn+Z3CYNfzlgvlljg+IvVk7CgKX5OrsznS+Q+mxNfMb8PzDcCsRmctCr\/dLeDNxKIzUksTIg6SWQyPN\/tI\/+bmeeze8\/VGG33L7CaeSIC8ff3+F1MFu1r+vs9VoyS6OvKJxZmLyakzsrterunR0mGpbtqIR+KvD9Wzq4f+5Htv1kg+oKVKXtzt0sEjpxXCgZ\/3IkiAcT\/cGV5nnN62VZrR688z2prOYhufHKb1NvW6m+5rQiAKQLD9a1j4ftqJ7FcXRU7B+nZLe0PGVO0yQlk6SOu6Gyf6Rgl\/6i2RHCHNs3+5BxemdAsBlq5MJ0beL5+jV+\/dU5aArFktsqjqS\/fjqpp5iSkc2l+R29FXbB8cPELVFkwetvsvEz5lxa1a34MN11\/r81cjy9vZcDn1tJ84fN5KQ9utYHrSn5vEIhWEQrf5SLFEAh1kcsKbrzWal8mhfyPYD7Ha1nEu\/pcD4GHUk9GpSN7Ps\/CPTMpln6r7an9489xwjyz29phMHw2CcYYD++v0gYRle2EtuK43vc9fuWc1\/LrbJ7IQvH66ReVGacTo7EmBP7UH2+EPInn6MVRYrnOJ4v3KidMobdNbHr7qmvDNv2TY\/hxXwZ8zqUctP09Xxvsa\/a1+7X7XC8QJ5GRiY6pKNYCURdrcWIJgVGwL7KbmK0SZsRTHvy+PsWW\/tdtim7to9x2mYBkxyA\/5icH8XnpwzCOIi7e5nLL3ri2uC7vN75v+H8pWZeOx\/Z3nFjpo5\/zY\/hqIU8ygejvKqQ6ofK\/xfX0fZYXge1yZ1G1dbmM5WfvKyOfdmLZ14A01masGrnaPH8ne+nvbHn3XHu7+A5sL4lI2NsulqsFol0oy6LeKpx959XCwrfnbj9bAsoD0dvneud5e0Sgrb9+3r7Q3kxhV\/23Jr7i+tqHrh\/DR+E6tdNYTBp2W5fRP0Q845eWrUX7JPStTL3idQajipdQC8LOoWNTJoy8NrUnnKL9Im+ExbwtM28mm8p6tl882uMp+yzGp3xXnstniTevj2fBMy2PnzXmkTg\/hfOyOwbEbP+Y7SMQy6DGZ9vKINvFzBYkoRjHtgqguvtc71RvT9Hf6sJrjzVC3pio3HGfSL5\/b4skVf0qAtr2YcsG\/336j8v1ToVO5LLPGb8gEHnGcOs8UTuIcovY8zpxGm4f5+9jjk22BNZlomnknbp+x9qibWvXJp+DOi\/ta1s53m7bbofz8csDGZAck7xs1A2fBzNzTuM6YnlbLPcRiNZOlRk4u5jZ4iYboMCUP1\/X3WfWjmlTffy5AjEIY3luqlN02T60\/a2SZ2rficA0Gdlt1X5S7TjfdtpaXdcZF67riMHpfLnEqD+e3xJ2k4ZbGOWiLn+vOSna7xGIO9YWbVs7nn5iTDnZvq4Y3+ni3\/ZBe8xc8wq+6Ztn4PuRsV4tEM0giqiI6r\/31osdbLOPstBVhb23z\/XFxNtz76plwb5qPMHO4Fu5jTb3rGIOju1D29\/5ddP7UtiVn8tYND7bNqz3f2Vfoz\/OewXfLuRJuYPoWHB8Xj+VQGwuTkqWG3mnBeaSTbXfvaBb+Ev\/FRx3C8TGeMiNOkb45Fg+6ZsvOuewFbkFB20OVgtEEShasLjfJCt+1HkqxEsF0g52BcrPa3zOSILpzylEW1efbWdI2+Wr2dcNAFbjytuwCnsYT\/lf8vnJohh73pb1hz7T8drfzia5LS3jriejMEFmu4pybvs1XCM7n4V97evWx4e2Xstns3liCcTpJ2FCDYq8Wfx5\/vPdR6lnZg7EtmQ3fKmeSRwkX\/RO\/D2c1jkpfenXrWrVPbZyrY4J\/ujwR9fcLXnVs5Pe0Sdz0uIjUOsFonOqCJfpeUAfrKmAxR3EEJwgetKzba5g5sKmFiwumawJwn+XP\/\/WgGSxzz5w6v6yvvOJYw1klgiU61fabdqX2WX5sPWwvZ98lsdXnefiX8a8GE858VIs+\/h7az\/N5YkpEKVmDMX\/by4TSmI7LmwXOJ1Yz\/JpiseaHI01slGnpP+ZVzPf5BlsM+\/CeM1jcPfWOTXD2eP9EhZqwnKmI3JbrDmuyt9Djev1cuw2gUhQFpV3Dnr+3hf92yeNvK0jvzcnWLi5mZsjx3oP286fJ2ESLEXmnjkwidJ8Af56E9YerNEmnMCAzQACcc+CbbUtuxCvvMoPuyfsHtpJRzHq8MvJ88QL3EeKNeP2uVV\/+I5FGgzAQCcDCMROR206qQcB9ZLb5WFif8mxPYOVd+7zjHkSbM5\/BWDT2mHyEG4tP3K30rSjQ\/hzHeIEBk7DwFsJRL+qT88j6Wcj5fvHrPqn5ytesKBPPn7l3VGK20OL26vmyaaicRKlr\/\/YyqY+I48fmsfE7pyLp7cSiEB6TkiJG3GDARiAARiAgccygEBkJclKEgZgAAZgAAZgAAYUAwhEgFBAsEJ77AoNf+NvGIABGICBIzKAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBcQRVzHYxOoaBmAABmAABh7LAAIRgYhAhAEYgAEYgAEYgAHFAAIRIBQQrNAeu0LD3\/gbBmAABmDgiAwgEBGICEQYgAEYgAEYgAEYUAwgEAFCAXHEVQw2sbqGARiAARiAgccygEBEICIQYQAGYAAGYAAGYEAxsFogTv\/11SD\/LV35Kv9NXfiP41vnyX\/FFv\/f0rId\/\/n606nl8P+MttqK\/11dX5999nf22WX\/Zezrs8\/+S1efnfZf+vrss7+zzy778dn030AK2\/hsHAapLXA2sRFqaF9u9uU5tcXNO8IZPnOc+TmYevxa9bh\/F3K1QGSLt9+5+ApfwQAMwAAMwAAMnJEBBCJbympL+YwQYzPFFwZgAAZgAAa2ZWC1QOSWxjAO3Pobpy336ba\/3JLh1t\/6W3\/4DJ8Vj9dIbdn08Q9ulzrOuF2asSac8fhK9ljBu9TjfhG5WiCi0Pudi6\/wFQzAAAzAAAzAwBkZQCByi5lbzDAAAzAAAzAAAzCgGEAgAoQC4oyrHGxmdQ4DMAADMAAD2zKAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBQQrsG1XYPgTf8IADMAADJyRAQQiAhGBCAMwAAMwAAMwAAOKAQQiQCggzrjKwWZW5zAAAzAAAzCwLQMIRAQiAhEGYAAGYAAGYAAGFAMIRIBQQLAC23YFhj\/xJwzAAAzAwBkZQCAiEBGIMAADMAADMAADMKAYQCAChALijKscbGZ1DgMwAAMwAAPbMvBaArH8fyWvn4gfBDAMwAAMwAAMwAAMrGTgEALx49f3OAzX8XOl8e3VQvhPtxGIJMRmTG27MmuzSz\/4BgZgAAZg4PkMrBSIn+N1GMZh5t\/3r4\/VogSB+HwQNk3GH1\/j98TI9\/j1Y35sPvaOqdYCIYj9YRhvYascV+rPc6zaLHegI+cN2+L5jeOI09W1oIwXn+fzB\/\/gHxiAgb0YWCkQdSC2EnZbtZOcxA5i8oWO2b7fB7\/\/\/ho\/p13hBYEYhaQtED0X3+PXTy84lZhbLb7C4ub31\/jRunYSfAs2T9eGtq6f4+fVtn1fPz8ypvRFLGEABmDgHRnYVyAqAVBOpEu7kcWuTNXW3ER+v0CcxMkkJrSdlkjxIsHvSE27q9Wtbd\/GdG3cdfLnX38WiVccL3fWpr6un6MXT8M4uL4y3+j2tO3DMOMzaaOyvbCvJa4ul0ksiX+iuJvZQZzGEsVkEW\/nBxFzwTZp+5ZElb6a4tCNq0sgerbEzz72he0zPrrFdq7pZxBf4SsYgAEY2IaB3QSiCBiZSF3A\/GRaixR\/7twk+zleRSyEybfVlgdjI4EYbjHGMQTxFj9fLpNQyz9HsaaEVi7U0jgrEeWEkLoujCO7\/eqFzrc\/Lwia79\/Op+WYQ5+qvdqPkkgSr1KQyvG1r9XYStGUibHF+N8rEMP1Kk6lPe5zZlPveBGI2xSiXn9zHv6GARiAgccwsJNAzHbM1ERsiRYvslYLk1nRUIql9c4UwaRFRV+7tWgI4y5ErohJ3UdhayFKlTAOx\/zOWrBN+ugVRRKfcP60Iynf3fE6LxA1H7sLRBF+4VZ1eoY2ifWp4AR\/puPlrncRm7joKdq5w28UvtrH+ASfwAAMwMDjGdhHIBaiJg+s3wHTz4EtCgRzwtUiI+\/jcukTcvoa7fyWTZb9ZTv1tbYwLq8zPxdCT\/Wv\/FwIxEvocxjGWQFq+lb7wrRr4Trvg3q32LVV+qf8XPU3uxhYttW3P6Rb1pPtwV\/Z7mzVr3A0c2veC3YEYu275bhwDT6CARiAgeMysKNAtMWBNaEuCoQoKrLn\/MLtX\/u5tEcKxCTE2jtP\/QLR+6cep4i8foHooBMRJO3ZMdkjQX1Mjf4Kwev6Xoz\/JgKxz5bKFwt9WzxXbSyIac4\/boEkNsQGBmDgXRl4jkCU26Bh4lwSCP54uRPmRddzBWIQfovj6ROIXmwUQqYQVOsEYpbYoZ3ZP1TZUMjYAtEW7kvxl1vxdqyzMbbsl1vM5R\/MFL61i8B87BCIHf5vxYXv+RkgGIABGDgsA\/sIxHB7s57QG6KuNYFP4ARRUYiwS7MPN2HZQsQWAPYEZ4uWwn51ize1U187LzK8XY1zChFzs0B0vizaUv4QAan+qCWNSZ3bkdCmQJQ+4u8Lys5m\/mrcrg3X1Txl9oVYxL98zm1sjXuWu9B2I8biDwRiFoPc57w\/bNEXdnmFXRiAgTkGdhKIcttQ74Y1J1MRDg1x4q\/L2pLzmz+evI9ArOwXOzK7\/TlO8ORCpyH+1CQabM6vE9GTPUc4tS9iWYmXQkj\/vFY\/LG2KtmCDP1bafXvyzPVVAunPzf1V9Bv8PCcQk\/3lTrNvq4qdPKOZxa60SwT13B\/u1O0WtqsYc6zyMf5BSMIADMDAIRnYTSC6iSCftKfn80TYWDBkYsg\/y5cLBhFPstPkjhW7efEvSuUc\/SrP8PVOUJXtbtfLsr+w24mYWvD0CEQnHsJ5ssPm+gviSOzvFoiW\/3PxWcbAELu9vpLzTJ\/lYyn7DJ9rf6XdTv1cp8Q0WyzENpPvxFdil7x6MSdt1P8zi2W\/1VbZjrJxTnBGWxGKEhNeYQEGYAAGjsnAXQLxlYNqihYm+EOucoRDL9ws8XjM5BO7eSU+MAADMAADR2MAgdgQfQjEkyVr2Mmduw19tOTDnpMx1qgVxJE4wgAMvCIDCMRG0UcgniXhl28tv2LiMqaz8ImdsAoDMHBOBhCICMRD3zamsJyzsBA34gYDMAAD52YAgdgQiIB9brCJH\/GDARiAARiAgdsZQCAiENlBhAEYgAEYgAEYgAHFAAIRIBQQrLZuX23hO3wHAzAAAzDwKgwgEBGICEQYgAEYgAEYgAEYUAycSyDKjznP\/eDzRgHu\/Svm8keTrR9WfpXVBONgZQwDMAADMAAD78EAArEhKHsFYkyU4n88id832uf4eyQYcSbOMAADMAADZ2RgpUBMvzmn\/nsx+e\/Umv838vngQCCeL2Y9CRh3fBf\/S7zEevPHt+N\/s5j\/t5C3+i31t\/xfTbb\/u0Dvg\/RfUzZtZ+GibqX0sMM5t7LNdbADA2dkYKVA1EFeLaJONCmtHhs7iMeecIOYu\/4MQmxBIEYhaS56Uhv+vPsEomdtGNuPJwTBt2CzK0C+re\/x6+fX+G3arnP4jEULm4khDMAADOzPwG4CMQmstJsx7Yz8\/ho\/CqGYT8bTOeVEGJ89DDsnRhsOlqkdd21xfj3xFjYZE2myX+\/sNHdkOgSiCAHZfW22VfhHJ4K3x41Jt2eIlMIPw1D\/P8VpnIVPKh8Xx0ufTX259sVfvq8Y26I9bfswDmXMMx\/4NmrbtV9mkmWyTfyTxF3z+hhLf66Ok\/eDMOVtk7ZnbMjGo\/qNfc1dG3w\/46OpTSeCxc+hXW37XB8cU3FpxYvvj70QJD7EBwY2Y2BngegFXZqk6snZCQWZbKcCHSa2lmCYJmSZBAsQohjJ\/ojFCxEtLj6v+vPF+H98p+t+f0+7MNG+uAtlTKYLE30lJG6ewEWADUkMXIKAUH75HK\/qcxDQhUjMhdpcnBZ9No3ne\/z+7Xzr7XHvpzhOfks+t2Livot+VnFN4032Gf5X18wdrxnUwiAXY\/7cuX6ruHbb4W2c4znZlds0N7bs2M18ZW2sHEuylzbwBQzAAAycnYHdBWI56fdMiHOT7tz1\/rokRKbgLAg3H8BaYIlw0vbX50UA5vppHPN9rN19CgKnEH9e5BZjLyd4QzTY4wxisuxDtVf4IrTthX04JkK9ENZzMYz+zPoy45odt65pfzcvEHVM9haIwU\/XT7\/73XyWV\/yZnj10u9BzwlV20WfPudmHFP42X\/gG38AADLwGAzsLxAXB0pig9CStHT0nLsxjDXFWAlxe27LBixVD1M3002qrS9RVPmqIlpn+01jra71tt8VJ+Uz1X4jHQiD6PvMdUB3jZO8e388JxNI\/5efaniYPVdzqay+XYMtQPH8Y\/DUr7sI5rZ12BKLlb77bN7fwL\/6FgVdi4AACMU2S8myefzVEmDxn2NjZUoJFJmglXAK84TvdnxYsLVHX+l4mZL3j6PvzIkLv\/qS+14qzhmgxxhmFWLYz5frNhYc\/p8OGJZ+p\/ucF4pRAInDEtqXn6ySed78G3oz+an4avs5s2EQgdtlSF97ZvkM88li\/UuFiLDUP+ASfwAAMbMnAkwVimKwLwdcUYVsIRBE6xaRcioOWDeV5MRhKIGlIW23FazPBsfxdQ7QU\/fs+i52psGOViwZ\/3oJA7PGZ6r9DIGZj9kJn\/g9Vlv2ifd4+vyEQJ8Fa+qHh68p2ezHTtkFsDX4qWHTXNTnL+p6NXYhHHutle8QuXvEVDMAADLw7A88ViGEXqdx1mxNUcxOneUwJF\/nL31II1BOybUNDXLhJu+hHgWWKj1uTzxYt2t5CoEVRUV87KzLCda1zlL\/V+Iv+G3HOfaTaivZ6H03Hij+uya9d996Ooe+jtctb\/rFVip2\/bk4gBl+Ut5HDGO1xt4VjGmvh48JnwiMCMcUq+Y7v8AUMwAAMLDHwXIEYREX+HFWaqO1J155QfaDNY0q4XMb6L5bTBB5\/IiT+npy2wdumv4sOLvtRE7b00bhWnbsEbS3yLDHgbc2EsPj6llvMQeAlsSHjyW7Lq\/EX4kUJRHes9IMt2rxvw7HC7uj3Vb5zvp3rq\/S94euiv1kmpnOT\/Tlf0f7gt+Tb9iImXiM7jHOi2Wg3v573Zaz5DBMwAAMwkDPwXIHoJtAgHuSZPDdR6t0wmTDt3Z18Yu0SiFH8pfbcDmZ1bSaoxLZ6gs8mf3mWLr6WIij0EY+H\/o3bi3mA6vd2n+Uu7EV++ib25+ypBU9rd7Ds158347NugegSsB5DHsey70rsFiKtPL\/+XPcXY9rY2fNt1P5y33t7ki\/ytvLFjtgRfVc8SiHHReCndkp2DPuttixmY\/yzxcJq\/1E0Y6zw3Wa\/sYZPySsYODYDdwlEgvuM4NqihVg8IxadfYpwW70Y6Gwf0YJogQEYgAEY2JgBBOLGDt1fqCEQ9\/fxlsJMbseXu4Jb9kFb52KCeBEvGICB4zOAQEQgsuraiYHFW8s79UvhPX7hJUbECAZg4OgMIBBPN0mzg3j0pMI+Cj8MwAAMwMDZGUAgnk4gknRnTzrsh2EYgAEYgIGjM4BARCByixkGYAAGYAAGYAAGFAMIRIBQQBx9RYN9rLphAAZgAAZgYH8GEIgIRAQiDMAADMAADMAADCgGEIgbASE\/njz3g8\/brHg6\/0hFfntPfijZ+mHljca+zbj2Xw1hJz6GARiAARiAgT4GXk8gqv\/Ro88JW8ByOIGYib\/JNgSiWhltEXPaeFx+4Wt8DQMwAAOPZWC1QBQhVP2XYtN\/mXeA\/87rSQLxceB27iAiEE8kCH1M03+1d4A8yvh5HNuPLX6MC3\/DAAzAQJuBGwXi9\/j9u5jEEIgPEiQIxJdKaHkUIPtv+PwirMgvBNuD8qtdLF+KO3iCJxiAgQUGbhSI1\/Hr1\/eonrezBKJMfvIc3FD+d2Ne7Fx\/Xsb4v05M55bnLRftuLMZ+xrGtCMzjK4PX+AzgTXZnM5L54RzK\/vrSbvst2rDBWBqx1+rzrdu+xY2DQ2fOd\/3+mzq0+orwlHuYK33v\/PtZM\/Uj25PcRL6VH5wMcsE0uo4Lfhs6uv6mfzl+spiq2OmbR+GOuZRKEgble3C2vKrHZvw3\/Pd0W60McZ42RauwUcwAAMwAAPCwM0C8XOaHDMhUQhEES\/55OtFQT7hZpNxnAzD5DgraGYCGCbtvF8ZrH\/N+szEl7e3sK2wobY\/s2OuXxESw5CJ6mBHHHcQkvnni\/X\/+Prr3A7uEO2b95ktQoLtwbZcxPlxZrHtFBkScyfMo\/+DeIufg5DMP0expsbeGSdnv7qu9pkf\/7c\/L3Dqd8DDufF6IyaXz\/Ea\/ZzFWwTxjQuanMXc99P3UfCuj4FmXdvLMfwBAzAAAzDQy8DtAvFyGd3EGyd6JRCDiPn1UWzhlhNw+FxMwF5o3Dg5zgm1SejYfYpIieOxRJEhpqKj5\/oNx8pdslnhJv1XAqthf3VeSoK5fuxjvo9KuIhNjVcRiNqHpQhLdkXfBZb0bmljnHN+FrsKX0xjlJ3AcMyPrRDWPW1LH+61Edd8XLPvjf4i+5Od+YLF9tts+7mtvC9qEf6EHRiAARiYY+AugThNkCLu8gmtmKBzA7QgsYVInCRvmdSMSTfv\/+J2hMxbmj2g2PZO7c\/12zimfdHov7q2YUM4zxJ17X4abcnOZdxZa9hWxKcVt3b\/qd362jviVPhM9a\/YLASisJHvgBZj1Cwl+2\/6XtlZCOk8n\/a0gbYRjjAAAzAAAwYD9wnEICSmHaN8QsvfF51Ok3W8tWsLlFos+N3K\/JlC994SQ7Kro3ex8om8X3h4O9IzitL\/6n6VEEi2KOES\/OT9U\/eZxmP7TISvZZvVTy5qZVzV624CMcSgel403zXuj9OSz9T4ZwWii00QatG2HXfxIhdGTGdy6CYxWuQhbaQ8xBf4AgZgAAZqBu4UiJfx4iYyJyTyCS1\/X0xMarIOOzalqLEEYnfw4qRbD9a30Sc8RBwmYebaMyZyGd9cv41j2hciggtBUl3bsKE6L42\/7Cf5stGWjGnlaytuuv\/gf9l5Dn3U14bzFkTq1LbcPhZ7C1+o\/ic25dGIcgcx+WzyUWhn9g9VpM+bXsMYjR3L2h+FbTf1RxuJfXyBL2AABmBgjoH7BeIkmq7jpxKFLeFRfl9+9sG6b3K020xO8MfL5wHTcWdDSzjMtF2IEtVe45gSLnJ7sxRE1bW2Dd5nhbgMIkL3kydEcVvzTtFhx62wVwm0ZEt9bU+cGucUPlPjV\/234pzsmt2RDv3Ms5S1ZfhX2RaPbxsXxWLsY94ursE\/MAADMPDeDGwgEP3Pm0x\/VZvt5FiCZZoM4+1l5\/hCPITJqxYLa4IUJlfVT359Q1QUE6e3NRNcIgZuubVdCBZJOi0ODLuDmHG3ftNOpuGz0H65E2v3k\/si7AC3xlT4RNprvVpxq2IufsyEsD\/H3VZfe4u5z2fKz3MC8ee1emzB4ljG74+Vdhf+XfKhEbvKZ0ttcJznh2AABmAABjZmYBOBKLss5a24NIGGZ+qK24r7CEQ3QQcRGJ8jqwXW8q6PiA95HtCJl1Kc1f2k5\/gysdMlEA27nb+Ma5OgEtvy8XmBUvk+80UlJEW0ZeeUsRRRNPdq9lnFPIlS8ZWzx1+b+UximAlJu+8iBobPugWi+uka8W1uUyH+xG+LNhbXlUks7UT\/z\/RZXstnJgUYgAEYgIEdGFgtEO1JemEC3MFw7Diez2uRdzwb4YaYwAAMwAAMwMAyAwhExOtmKy8E4nLCUZTwEQzAAAzAwBkYQCAiEBGIMLAZA2coetjI5AwDMAADywwgEBEHm4kDdhCXE46ihI9gAAZgAAbOwAACEYG4mUA8A\/DYSGGGARiAARiAgWUGEIgIRAQiDMAADMAADMAADCgGEIgAoYBgVbW8qsJH+AgGYAAGYODVGUAgIhARiDAAAzAAAzAAAzCgGEAgAoQC4tVXRIyPVT8MwAAMwAAMLDOAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBQSrquVVFT7CRzAAAzAAA6\/OAAIRgYhAhAEYgAEYgAEYgAHFAAIRIBQQr74iYnys+mEABmAABmBgmQEEIgIRgQgDMAADMAADMAADigEEIkAoIFhVLa+q8BE+ggEYgAEYeHUGEIgIRAQiDMAADMAADMAADCgGEIgAoYB49RUR42PVDwMwAAMwAAPLDCAQEYgIRBiAARiAARiAARhQDCAQAUIBwapqeVWFj\/ARDMAADMDAqzOAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBcSrr4gYH6t+GIABGIABGFhmAIGIQEQgwgAMwAAMwAAMwIBiAIEIEAoIVlXLqyp8hI9gAAZgAAZenQEEIgIRgQgDMAADMAADMAADioFVAvHzOozDsPTvz\/hn8ZxhHP7+t6OtYfynp63\/\/tV33j9Ltrvj\/xv\/7unz3z9d9v\/nr54+8VnOFT7LmIGzLM\/IzTxPhq56Rm3JfUZtobbkPKT3b1Jbfn+NHytE8CqB+OrbqYyPWwYwAAMwAAMwAAMwcBkRiCvUNMBQNGAABmAABmAABt6BAQQiAlE9c\/AO0DNGijsMwAAMwAAMzDOAQEQgIhBhAAZgAAZgAAZgQDGAQAQIBQQrqvkVFf7BPzAAAzAAA+\/AAAIRgYhAhAEYgAEYgAEYgAHFwP8DS5sjNOoK+wQAAAAASUVORK5CYII=)","8f58ad51":"An aquifer is an underground layer of water-bearing permeable rock, rock fractures or unconsolidated materials. Groundwater can be extracted using a water well. We are having 4 datasets for 4 different aquifers. We will be only looking at only 1 dataset varaibles visualization (i.e Aquifer Doganella) but all other visualizations for all datasets have been shown below for better understnding of data.","f1a40807":"We will also be removing Independent Attributes having Null values more than 20 percent of the remaining datasets even after the datasets were shortened because of the removal of old data which was achieved through year selection.","e1e199f6":"Boxplot and Null values graph functions","2f89f3b5":"\n<a id='5.2'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">5.2 Lake Waterbody<\/p>","a5b6cfa5":"Independent Attributes","262da193":"**Create Additional Features containing rolling averages**","91d6545c":"Before moving on to the individual dataset analysis lets check if our data is in Chronological Order and is having Equidistant Timestamps.\n\nThe data should be in chronological order and the timestamps should be equidistant in time series. The chronological order can be achieved by sorting the dataframe by the timestamps. Equidisant timestamps indicates constant time intervals. To check this, the difference between each timestamp can be taken. If this is not the case, you can decide on a constant time interval.\n\nThis is already the case in our data: The time interval is one day and the data is already in chronological order. Therefore, we do not have to do this additional data preparation step.","0a967c66":"The root mean square error (RMSE) criterion is being used here. It is defined by: \n![image.png](attachment:image.png)","d634e883":"Target Attributes","f0349f38":"A moving average, also called a rolling or running average, is used to analyze the time-series data by calculating averages of different subsets of the complete dataset. Since it involves taking the average of the dataset over time, it is also called a moving mean (MM) or rolling mean.\n\nFor calculating succeeding rolling average values, a new value will be added into the sum, and the previous time period value will be dropped out, since you have the average of previous time periods so full summation each time is not required:\n\n![image.png](attachment:image.png)\n\nAdding Features consiting of Rolling Average of 7 days for better model accuracy(smootherns dataset) whilst keeping original attributes.","3fcb1119":"\nBy observing above visualizations of null values of all datasets, we came to the conclusion that many of the datasets that had concentrated null values in past times are not healthy for our model, so, we selected specific years for each dataset, such that the dataset of the initial year would be the starting point of our analysis and all data before that will be expunged.\n","ef02ec37":"**List of All Target Attributes**\n\nThe target of a supervised model is a special kind of attribute. The target column in the training data contains the historical values used to train the model. The target column in the test data contains the historical values to which the predictions are compared.\nBelow is the  list of all target attributes which we will be using in future for predicting values of all datasets.","f6df08a8":"<a id='1'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">1. Targeting Water Bodies - A reconstruction of Factors affecting water distribution<\/p>","951ecedf":"**Observations** -\n\n1. Volumes of rainfall are quite volatile both across locations and at different times of the year. However, we cannot observe apparent seasonal patterns.\n\n2. Temperatures seems mostly between 0\u00b0C and 30\u00b0C. In addition, the temperature shows quite a strong annual cycle.\n\n3. The hydrometry shows quite a strong annual cycle. In addition, it seems that the river did stop flow between July 3, 2008 and December 31, 2008. Given the starting and ending dates, it seems either missing data or some man-made reasons had halted the river flow.\n\n4. From correlation matrix it is observed that Hydrometry is highly correlated with Temperature Attribute.\n\n5. From Boxplots it is observed that Dependent attribute characterizes seasonality.\n\n6. From missing values graph it is observed that most of the values related to rainfall columns have null values.\n","adbccbd0":"<a id='3'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">3. Summary<\/p>","3dcf4fdb":"**Observations - **\n1. Volumes of rainfall are quite volatile both across locations and at different times of the year. However, we cannot observe apparent seasonal patterns.\n\n2. Volume of most of the wells of Pozzo are mostly constant with some fluctuations. Volume of Pozzo_1 and Pozzo_2 are quite volatile at different times of the year.\n\n3. Temperatures seems mostly between 0\u00b0C and 30\u00b0C. In addition, the temperature shows a quite strong annual cycle.\n\n4. Most of the target attributes are not following a pattern and some of them have drastic drops in data which is either missing data or some man-made reasons.\n\n5. From Boxplots it is observed that Dependent attributes characterise partial seasonality.\n\n6. From the missing values graph it can be observed that half of the values related to Depth_to_groundwater columns are having null values.\n","7b50937e":"(Nans and inf not allowed)\nmore negative the value the more likely we are to reject null hypothesis(stationary)","b7de0b79":"LSTM has the advantage of capturing temporal information and is popular to be adopted in time series modeling. Detailed structure of the LSTM block is illustrated in Figure","30113376":"<a id='8.1'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">8.1 LSTM<\/p>","a78a3088":"Target Attributes","bca63d3a":"Independent Attributes","3bc76311":"Target Attributes","0a8b5dd0":"<a id='9'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">9. Conclusion<\/p>\n","99875306":"\n<a id=''><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">6. Data Preprocessing<\/p>","3dba363b":"Bilancino lake is an artificial lake located in the municipality of Barberino di Mugello (about 50 km from Florence). It is used to refill the Arno river during the summer months. Indeed, during the winter months, the lake is filled up and then, during the summer months, the water of the lake is poured into the Arno river.","434ac66f":"![image.png](attachment:image.png)","5d6d6ec3":"\n<a id='5.1'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">5.1 Aquifer Waterbody<\/p>","bd6e88a0":"The input of LSTM block is X(t). Then, the output of hidden layer, namely, the current hidden state h(t), is computed as follows:","75e70a96":"A spring is a place where water moving underground finds an opening to the land surface and emerges, sometimes as just a trickle, maybe only after a rain, and sometimes in a continuous flow.\nWe will be only looking at only 1 dataset varaibles visualization (i.e water spring spring amiata) but all other visualizations for all datasets have been shown below for better understnding of data.","c9fa3e86":"**Stationarity Test for Water_Spring_Madonna_di_Canneto**","0fedf2a6":"\n<a id='5.3'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">5.3 River Waterbody<\/p>","3377972b":"<a id='5'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">5. Exploratory Data Analysis<\/p>","c35e0602":"\n<a id='6.3'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">6.3. Null Values Imputation using LightGBM<\/p>","cb994094":"The Root Mean Square Error (RMSE) and Mean Absolute Error(MAE) re used to compare the performance of the model for predictions.\n\nThe mean square error (MSE) corresponds to the mean of the square of the prediction errors (L2\u2013 criterion method):\nwhere m represents the number of data from the test set. This criterion measures the mean square error of the mismatch between the predicted results and the test data. A low MSE value means that the predicted values match the real values.\n","d57a84d7":"![image.png](attachment:image.png)","61e2a373":"\n<a id='2'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">2. Problem definition<\/p>","ceeaace6":"We are dropping columns from all datasets having more than 20 percent null values.\nAlso we are dropping multiple columns for aquifer_auser, aquifer_dogenella and Water_Spring_Amiata because as we observed above in correlation matrix these columns have negligible to no effects on target values.","0f27d1ad":"Using non-stationary time series data in forecasting models produces unreliable and spurious results that leads to poor understanding and forecasting. The solution to the problem is to transform the time series data so that it becomes stationary. ADF and KPSS are quick stationary statistical tests to understand the data you are dealing with.\nMost statistical forecasting methods are based on the assumption that the time series are approximately stationary. A stationary series is relatively easy to predict: you simply forecast that its statistical properties will be the same in the future as they have been in the past. Analysis of time series patterns is the first step of converting non-stationary data in to stationary data (for example by trend removal), so that the statistical forecasting methods could be applied. There are three fundamental steps of building a quality forecasting time series model: making the data stationary, selecting the right model, and evaluating model accuracy.","997e1701":"![image.png](attachment:image.png)\n","f4400dc5":"<a id='6.1'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">6.1. Feature Selection<\/p>","3049b840":"<a id='8.1.1'><\/a>\n### <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">8.1.1. Transforming Data set for multivariate LSTM model<\/p>\n","7d0f4994":"![image.png](attachment:image.png)","d0cbbc55":"* As most of the target attributes of our datasets are non-stationary in nature ARIMA model is not feasible. So, Multivariate LSTM model was used.\n* LSTM outperforms the other models when we want our model to learn from long term dependencies. \n* LSTM's ability to forget, remember and update the information pushes it one step ahead of RNNs.\n* The system integrates the task of developing a LSTM model from data, with the technique of searching for logical conditions that enable a better fitting error by the model.\n* We think that the provided methodology is also applicable on new datasets belonging to another waterbody.","9453c6c8":"<a id='7'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">7. Feature Engineering<\/p>","7745d6fd":"![image.png](attachment:image.png)","11bde534":"**Observations -**\n1.    Volumes of rainfall are quite volatile across all locations and at different times of the year. However, we cannot observe apparent seasonal patterns.\n\n2.    Temperatures seems mostly between 0\u00b0C and 30\u00b0C. In addition, the temperature shows quite a strong annual cycle.\n\n3.    The Lake level shows quite a strong annual cycle. In addition, it seems the lake level dropped drastically (2012-2013). Given the starting and ending dates, it seems environmentally natural and unnatural processes affected the level of the lake.\n\n4. From Boxplots it is observed that Dependent attribute characterizes seasonality.\n\n5. From missing values graph it is observed that most of the values related to rainfall columns have null values.\n","5f4813d0":"**Stationarity Test for Lake_Bilancino**","d8a2baa9":"**Stationarity Test for River_arno**","6d43c207":"* The first step is to prepare the dataset for the LSTM.\n\n* This involves framing the dataset as a supervised learning problem and normalizing the input variables.\n\n* We will frame the supervised learning problem as predicting the target attributes at the current hour (t) given the target attributes measurement and independent attributes at the prior time step.\n\n* Next, all features are normalized, then the dataset is transformed into a supervised learning problem. The target attributes for the hour to be predicted (t) are then removed.\n","f542a12c":"**Stationarity Test for Aquifer_luco**","f14e0f9e":"\n<a id='6.4'><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center\">6.4. Stationarity Test<\/p>","d62c0516":"Water becomes not an essential commodity but one that is inextricably linked to the existence of basic life. Scarcity of water affects all life that exists in its vicinity. Because there have been efforts to even privatise water production and its availability, it is all the more important to address not only the environmental issues regaring water withdrawal but also the challenges faced by facetious corporations which treat water not as a basic human right but as a means of commerce. This analytical framework that we shall put forward will deal with water scarcity in a basin and its problematics. The emphasis would be to help Acea group to deal with the aforementioned problematics that arise in tandem with water preservation and the need for discourse surrounding the analyses of prediction as well as the groud realities reagarding the same.","2c1e84a6":"The mean absolute error (MAE) criterion (which corresponds to standard L1) is defined by:\n![image.png](attachment:image.png)\n\nThis criterion is similar to the RMSE coefficient. Nevertheless, it is more robust since it is less sensitive to extreme values than MSE.\n\nAll distance measurements (RMSE and MAE) are equivalent and make it possible to quantify how the approximated solutions match the simulated data. A small value for these criteria means that the estimated model is able to predict the values of the response of the more complex model.","4c96dddc":"\nNow, we are going to understand the deeper behaviour of our time series and how they depend and influence each other in order to establish the proper model.\n\nRemember, we want to create a robust model to predict target attributes of all datasets. A Multivariate Time Series will analyse how much the time series depend on each other. It will add information towards a more robust and precise Time-Series forecasting model.\n\nWe want to find the variables we will use in our future model. We don't want to use variables that are not significant in the forecasting because it can skew our model."}}