{"cell_type":{"7d5d617a":"code","f367ceae":"code","70cb08d8":"code","8d500d42":"code","9b8fade0":"code","0070b940":"code","b393ea25":"code","da2a7c12":"code","992150f4":"code","bb895f3c":"code","f114fd68":"code","f0a2506b":"code","30f76c45":"code","3fca1215":"code","d0f19ee5":"code","c1a565aa":"code","fbe23dbe":"code","8cfaea99":"code","65341f7c":"code","06248fda":"code","88c3a3a4":"code","fed80c9d":"code","6aff2eb3":"code","82563748":"code","45c66123":"code","c1485d7e":"code","3ec5acb2":"code","bf29d751":"code","7736934e":"code","a7121bd7":"code","3947fdf6":"code","f9974325":"code","1d6b6b60":"code","2484ef4f":"code","1358fe12":"code","d8684431":"code","ad07e9b2":"code","546c14a3":"code","acee2fa1":"code","33021cd9":"code","62dac455":"code","2227e6d0":"markdown","179f0d98":"markdown","5c03d58e":"markdown","97a19ca5":"markdown","db82457d":"markdown","6e502280":"markdown","ea92b623":"markdown","566fa9bc":"markdown","f782dc72":"markdown","4bb48dc1":"markdown","8e767479":"markdown","b26051c9":"markdown","ecd8b061":"markdown","e4fedd44":"markdown","d1921b3d":"markdown","6f4281ee":"markdown","b314d61c":"markdown","fe6e6621":"markdown","e4d64092":"markdown","b4432847":"markdown","1818002a":"markdown","4f344288":"markdown","082a2d7f":"markdown","a14a6db8":"markdown","114f7e13":"markdown","14e59df2":"markdown","b3cb17dc":"markdown","37ce1118":"markdown","c30d6e41":"markdown","1205a4dd":"markdown","07257c2e":"markdown","304f870a":"markdown","efbbc4be":"markdown","ffbbda5c":"markdown","7978ad00":"markdown","fc160e9c":"markdown","33796b87":"markdown","fa6e536e":"markdown","e144c40d":"markdown","2ecfb925":"markdown","3eb628cf":"markdown","9a2b6133":"markdown","73db9f64":"markdown","2e35a731":"markdown","201354fb":"markdown"},"source":{"7d5d617a":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","f367ceae":"# Load data\nrain_data = pd.read_csv('..\/input\/weatherAUS.csv')\nrain_data.head()","70cb08d8":"# Visualising missing data:\nsns.heatmap(rain_data.isnull(),yticklabels=False,cbar=False,cmap='Reds_r')","8d500d42":"# High percentage of missing data for Evaporation, Sunshine, Cloud9am and Cloud3pm features.\n# Date, Location and RISK_MM will be removed.\n# Lastly, remove any observations\/rows with missing data\nrain_data.drop(['Evaporation','Sunshine','Cloud9am','Cloud3pm','RISK_MM','Date','Location'],axis=1,inplace=True)\nrain_data.dropna(inplace=True)\nrain_data[['RainTomorrow','RainToday']] = rain_data[['RainTomorrow','RainToday']].replace({'No':0,'Yes':1})","9b8fade0":"# Frequency of Rainy and No Rain:\nmpl.style.use('ggplot')\nplt.figure(figsize=(6,4))\nplt.hist(rain_data['RainTomorrow'],bins=2,rwidth=0.8)\nplt.xticks([0.25,0.75],['No Rain','Rain'])\nplt.title('Frequency of No Rain and Rainy days\\n')\nprint(rain_data['RainTomorrow'].value_counts())","0070b940":"# Segregating our numerical features from the categorical\nrain_data_num = rain_data[['MinTemp','MaxTemp','Rainfall','WindSpeed9am','WindSpeed3pm',\n                           'Humidity9am','Humidity3pm','Pressure9am','Pressure3pm',\n                           'Temp9am','Temp3pm','RainToday','RainTomorrow']]\n\n# Histogram of each numerical feature\nmpl.rcParams['patch.force_edgecolor'] = True\nax_list = rain_data_num.drop(['RainTomorrow'],axis=1).hist(figsize=(20,15),bins=20)\nax_list[2,1].set_xlim((0,100))","b393ea25":"plt.figure(figsize=(12,8))\nsns.heatmap(rain_data_num.corr(),annot=True,cmap='bone',linewidths=0.25)","da2a7c12":"# Creating dummy variables for the categorical features:\nWindGustDir_data = pd.get_dummies(rain_data['WindGustDir'])\nWindDir9am_data = pd.get_dummies(rain_data['WindDir9am'])\nWindDir3pm_data = pd.get_dummies(rain_data['WindDir3pm'])\n\n# Dataframe of the categorical features\nrain_data_cat = pd.concat([WindGustDir_data,WindDir9am_data,WindDir3pm_data],\n                          axis=1,keys=['WindGustDir','WindDir9am','WindDir3pm'])\n\n# Combining the Numerical and Categorical\/Dummy Variables\nrain_data = pd.concat([rain_data_num,rain_data_cat],axis=1)","992150f4":"from sklearn.model_selection import train_test_split\n\nX = rain_data.drop(['RainTomorrow'],axis=1)\ny = rain_data['RainTomorrow']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=88)","bb895f3c":"from sklearn.ensemble import RandomForestClassifier\n# Out of Bag (oob) set to True. We will compare the oob_score with accuracy to see if they differ by much\n# n_estimators, or number of decision trees set to 100\nrf = RandomForestClassifier(n_estimators=100,oob_score=True,random_state=88)\nrf.fit(X_train,y_train)\ny_rf_pred = rf.predict(X_test)","f114fd68":"# No Rain and Rain frequency in test set\nprint(y_test.value_counts())\nnull_accuracy = float(y_test.value_counts().head(1) \/ len(y_test))\nprint('Null Accuracy Score: {:.2%}'.format(null_accuracy))","f0a2506b":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\nprint('Accuracy Score: {:.2%}'.format(accuracy_score(y_test,y_rf_pred),'\\n'))\nprint('Out of Bag Accuracy Score: {:.2%}'.format(rf.oob_score_),'\\n')\nprint('Confusion Matrix:\\n',confusion_matrix(y_test,y_rf_pred))","30f76c45":"# Using feature_importance_ for feature selection\nfeature_importance_rf = pd.DataFrame(rf.feature_importances_,index=X_train.columns,columns=['Importance']).sort_values(['Importance'],ascending=False)\nfeature_importance_rf.head(5)","3fca1215":"# Plot feature_importance\nfeature_importance_rf.plot(kind='bar',legend=False,figsize=(15,8))","d0f19ee5":"# Our Top 5 Features\nfeatures_top_5 = list(feature_importance_rf.index[0:6])\n\n# X dataframe - with only the top 5 features\nsubset_1 = [X.columns.get_loc(x) for x in features_top_5]\n\n# Split, Train, Predict\nX_train, X_test, y_train, y_test = train_test_split(X.iloc[:,subset_1], y, test_size=0.30, random_state=88)\nrf.fit(X_train,y_train)\ny_rf_pred = rf.predict(X_test)\n\nprint('Accuracy Score: {:.2%}'.format(accuracy_score(y_test,y_rf_pred)))\nprint('Out of Bag Score {:.2%}:'.format(rf.oob_score_),'\\n')\nprint('Confusion Matrix:\\n',confusion_matrix(y_test,y_rf_pred))","c1a565aa":"# X dataframe - with top 5 features and the categorical variables\nsubset_2 = subset_1 + list(range(12,len(X.columns)))\n\n# Split, Train, Predict\nX_train, X_test, y_train, y_test = train_test_split(X.iloc[:,subset_2], y, test_size=0.30, random_state=88)\nrf.fit(X_train,y_train)\ny_rf_pred = rf.predict(X_test)\n\nprint('Accuracy Score: {:.2%}'.format(accuracy_score(y_test,y_rf_pred)))\nprint('Out of Bag Score {:.2%}:'.format(rf.oob_score_),'\\n')\nprint('Confusion Matrix:\\n',confusion_matrix(y_test,y_rf_pred))","fbe23dbe":"%%time \n\n# Up to what number of features to plot\nindex = np.array(list(range(2,9)) + [15, 30, 60])\n\n# creating list of index location\nfeatures = list(feature_importance_rf.index)\nfeatures = [X.columns.get_loc(x) for x in features]\n\n# instantiate classifier\nrf = RandomForestClassifier(n_estimators=100,random_state=88)\n\naccuracy_rate = []\n\n# append the accuracy rate\nfor i in index:\n    X_train, X_test, y_train, y_test = train_test_split(X.iloc[:,features[0:i]], y, test_size=0.30, random_state=88)\n    rf.fit(X_train,y_train)\n    y_rf_pred = rf.predict(X_test)    \n    accuracy_rate.append(accuracy_score(y_test,y_rf_pred))","8cfaea99":"# Plot accuracy vs. number of features\nplt.figure(figsize=(7,5))\nplt.scatter(x=index-1,y=accuracy_rate)\nplt.ylabel('Accuracy Rate',fontsize=12)\nplt.xlabel('Number of Features',fontsize=12)\nplt.xlim(-0.2,60)\nplt.title('Random Forest \\nAccuracy Rate vs. Number of Features', fontsize = 14)","65341f7c":"# Split, Train, Predict on The 7 Features\nX_train, X_test, y_train, y_test = train_test_split(X[feature_importance_rf.head(7).index], y, test_size=0.30, random_state=88)\nrf.fit(X_train,y_train)\ny_rf_pred = rf.predict(X_test)\ncm = pd.DataFrame(confusion_matrix(y_test,y_rf_pred), index=['NO RAIN','RAIN'],columns=['NO RAIN','RAIN'])","06248fda":"print('Accuracy Score (Top 7 Features): {:.2%}'.format(accuracy_score(y_test,y_rf_pred)),'\\n')\n\n# plot confusion matrix\nfig = plt.figure(figsize=(8,6))\nax = sns.heatmap(cm,annot=True,cbar=False, cmap='CMRmap_r',linewidths=0.5,fmt='.0f')\nax.set_title('Random Forest Confusion Matrix',fontsize=16,y=1.25)\nax.set_ylabel('ACTUAL',fontsize=14)\nax.set_xlabel('PREDICTED',fontsize=14)\nax.xaxis.set_ticks_position('top')\nax.xaxis.set_label_position('top')\nax.tick_params(labelsize=12)","88c3a3a4":"TP = cm.iloc[1,1] # True Positive - Predicted Rain Correctly\nTN = cm.iloc[0,0] # True Negative - Predicted No Rain Incorrectly\nFP = cm.iloc[0,1] # False Positive - Predicted Rain when it didn't rain\nFN = cm.iloc[1,0] # False Negative - Predicted No Rain when it did rain","fed80c9d":"print('Sensitivity: {:.2%}'.format(TP\/(FN+TP)))\nprint('Specificity: {:.2%}'.format(TN\/(FP+TN)))","6aff2eb3":"# proves np.array of the probability scores\ny_prob_rain = rf.predict_proba(X_test)\n\n# To convert x-axis to a percentage\nfrom matplotlib.ticker import PercentFormatter\n\n# Plot histogram of predicted probabilities\nfig,ax = plt.subplots(figsize=(10,6))\nplt.hist(y_prob_rain[:,1],bins=50,alpha=0.5,color='teal',label='Rain')\nplt.hist(y_prob_rain[:,0],bins=50,alpha=0.5,color='orange',label='No Rain')\nplt.xlim(0,1)\nplt.title('Histogram of Predicted Probabilities')\nplt.xlabel('Predicted Probability (%)')\nplt.ylabel('Frequency')\n\nax.xaxis.set_major_formatter(PercentFormatter(1))\nax.text(0.025,0.83,'n = 33,878',transform=ax.transAxes)\n\nplt.legend()","82563748":"#ROC Curve\nfpr, tpr, thresholds = roc_curve(y_test,y_prob_rain[:,1])\n\nfig,ax1 = plt.subplots(figsize=(9,6))\nax1.plot(fpr, tpr,color='orange')\nax1.legend(['ROC Curve'],loc=1)\nax1.set_xlim([-0.005, 1.0])\nax1.set_ylim([0,1])\nax1.set_ylabel('True Positive Rate (Sensitivity)')\nax1.set_xlabel('False Positive Rate \\n(1 - Specificity)\\n FP \/ (TN + FP)')\nax1.set_title('ROC Curve for RainTomorrow Random Forest Classifier\\n')\n\nplt.plot([0,1],[0,1],linestyle='--',color='teal')\nplt.plot([0,1],[0.5,0.5],linestyle='--',color='red',linewidth=0.25)\n\n#Threshold Curve\nax2 = plt.gca().twinx()\nax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='black')\nax2.legend(['Threshold'],loc=4)\nax2.set_ylabel('Threshold',color='black')\nax2.set_ylim([0,1])\nax2.grid(False)","45c66123":"# Function to calc sensitivity and specificity rate for a given threshold\ndef evaluate_threshold(threshold):\n    print('Sensitivity: {:.2%}'.format(tpr[thresholds > threshold][-1]))\n    print('Specificity: {:.2%}'.format(1 - fpr[thresholds > threshold][-1]))\n    \nevaluate_threshold(0.25)","c1485d7e":"from sklearn.preprocessing import binarize\n# change the predicted class with 25% threshold\ny_pred_class = binarize(y_prob_rain,0.25)[:,1]\n\ncm = pd.DataFrame(confusion_matrix(y_test,y_pred_class), index=['NO RAIN','RAIN'],columns=['NO RAIN','RAIN'])\n\nprint('Accuracy Score (Top 7 Features with 25% Threshold): {:.2%}'.format(accuracy_score(y_test,y_pred_class)),'\\n')\n\n# Plot Confusion Matrix\nfig = plt.figure(figsize=(8,6))\nax = sns.heatmap(cm,annot=True,cbar=False, cmap='CMRmap_r',linewidths=0.5,fmt='.0f')\nax.set_title('Random Forest Confusion Matrix',fontsize=16,y=1.25)\nax.set_ylabel('ACTUAL',fontsize=14)\nax.set_xlabel('PREDICTED',fontsize=14)\nax.xaxis.set_ticks_position('top')\nax.xaxis.set_label_position('top')\nax.tick_params(labelsize=12)","3ec5acb2":"TP = cm.iloc[1,1] # True Positive - Predicted Rain Correctly\nTN = cm.iloc[0,0] # True Negative - Predicted No Rain Incorrectly\nFP = cm.iloc[0,1] # False Positive - Predicted Rain when it didn't rain\nFN = cm.iloc[1,0] # False Negative - Predicted No Rain when it did rain\n\nsens_rf = TP\/(FN+TP)\nspec_rf = TN\/(FP+TN)\n\nprint('Sensitivity: {:.2%}'.format(sens_rf))\nprint('Specificity: {:.2%}'.format(spec_rf))","bf29d751":"rf_auc = roc_auc_score(y_test,y_prob_rain[:,1])\nprint('AUC Score: {:.2%}'.format(rf_auc))","7736934e":"# Libraries for the Logistic Regression \nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\n\nX = rain_data.drop(['RainTomorrow'],axis=1)\ny = rain_data['RainTomorrow']\n# Remove the Categorical (Dummy) Variables, as we have identified earlier that they do not add much value\nX = X.iloc[:,0:12] \n\n\n# Train Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=88)\n\n# Logistic Regression train\nlr = LogisticRegression(random_state=88, solver='liblinear')\nlr.fit(X_train,y_train)\n\n# predict\ny_lr_pred = lr.predict(X_test)","a7121bd7":"# The 10-Fold Cross Validation method is used to calculate the accuracy score of the Logistic Regression model.\nprint('Accuracy Score with 10-KFolds: {:.2%}'.format(cross_val_score(lr,X,y,cv=10,scoring='accuracy').mean()),'\\n')\nprint('Confusion Matrix:\\n',confusion_matrix(y_test,y_lr_pred))","3947fdf6":"%%time\n#Feature Selection Method: Recursive Feature Elimination \nrfe = RFE(estimator=lr, n_features_to_select=7)\nrfe = rfe.fit(X_train,y_train)\n\nprint(\"Number of Features: {}\".format(rfe.n_features_)) \nprint(\"Selected Features: {}\".format(rfe.support_))\nprint(\"Feature Ranking: {}\".format(rfe.ranking_))","f9974325":"pd.DataFrame(X.iloc[:,rfe.support_].columns,columns=['Importance'])","1d6b6b60":"X_rfe = X.iloc[:,rfe.support_]\n# Train Test split with subset of X features\nX_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.30, random_state=88)\n# Train and Predict\nlr.fit(X_train,y_train)\ny_lr_pred = lr.predict(X_test)","2484ef4f":"#accuracy rate using 10-Fold CV\naccuracy_kfold = cross_val_score(lr,X_rfe,y,cv=10,scoring='accuracy').mean()\nprint('Accuracy Score with 7 Features and 10-KFolds: {:.2%}'.format(accuracy_kfold),'\\n')\nprint('Confusion Matrix:\\n',confusion_matrix(y_test,y_lr_pred))","1358fe12":"pd.concat([pd.DataFrame(lr.coef_,index=['coefficient'],columns=X_train.columns).T, \n                         X_train.aggregate([np.mean,np.std,np.min,np.max]).T],axis=1)","d8684431":"cm = pd.DataFrame(confusion_matrix(y_test,y_lr_pred), index=['NO RAIN','RAIN'],columns=['NO RAIN','RAIN'])\n\nprint('Accuracy Score with 7 Features and 10-KFolds: {:.2%}'.format(accuracy_kfold),'\\n')\n\n# Plot CM\nfig = plt.figure(figsize=(8,6))\nax = sns.heatmap(cm,annot=True,cbar=False, cmap='CMRmap_r',linewidths=0.5,fmt='.0f')\nax.set_title('Logistic Regression Confusion Matrix',fontsize=16,y=1.25)\nax.set_ylabel('ACTUAL',fontsize=14)\nax.set_xlabel('PREDICTED',fontsize=14)\nax.xaxis.set_ticks_position('top')\nax.xaxis.set_label_position('top')\nax.tick_params(labelsize=12)","ad07e9b2":"TP = cm.iloc[1,1] # True Positive - Predicted Rain Correctly\nTN = cm.iloc[0,0] # True Negative - Predicted No Rain Incorrectly\nFP = cm.iloc[0,1] # False Positive - Predicted Rain when it didn't rain\nFN = cm.iloc[1,0] # False Negative - Predicted No Rain when it did rain\n\nprint('Sensitivity: {:.2%}'.format(TP\/(FN+TP)))\nprint('Specificity: {:.2%}'.format(TN\/(FP+TN)))","546c14a3":"# Probability of Rain for X_test\ny_prob_rain = lr.predict_proba(X_test)\n\nfpr, tpr, thresholds = roc_curve(y_test,y_prob_rain[:,1])\n\n#ROC Curve\nfig,ax1 = plt.subplots(figsize=(9,6))\nax1.plot(fpr, tpr,color='orange')\nax1.legend(['ROC Curve'],loc=1)\nax1.set_xlim([-0.005, 1.0])\nax1.set_ylim([0,1])\nax1.set_ylabel('True Positive Rate (Sensitivity)')\nax1.set_xlabel('False Positive Rate \\n(1 - Specificity)\\n FP \/ (TN + FP)')\nax1.set_title('ROC Curve for RainTomorrow Logistic Regression Classifier\\n')\n\nplt.plot([0,1],[0,1],linestyle='--',color='teal')\nplt.plot([0,1],[0.5,0.5],linestyle='--',color='red',linewidth=0.25)\n\n#Threshold Curve\nax2 = plt.gca().twinx()\nax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='black')\nax2.legend(['Threshold'],loc=4)\nax2.set_ylabel('Threshold',color='black')\nax2.set_ylim([0,1])\nax2.grid(False)","acee2fa1":"# Changing predictions using threshold of 25%\ny_pred_class = binarize(y_prob_rain,0.25)[:,1]\n\ncm = pd.DataFrame(confusion_matrix(y_test,y_pred_class), index=['NO RAIN','RAIN'],columns=['NO RAIN','RAIN'])\n\nprint('Accuracy Score (Top 7 Features with 25% Threshold): {:.2%}'.format(accuracy_score(y_test,y_pred_class)),'\\n')\n\nfig = plt.figure(figsize=(8,6))\nax = sns.heatmap(cm,annot=True,cbar=False, cmap='CMRmap_r',linewidths=0.5,fmt='.0f')\nax.set_title('Logistic Regression Confusion Matrix',fontsize=16,y=1.25)\nax.set_ylabel('ACTUAL',fontsize=14)\nax.set_xlabel('PREDICTED',fontsize=14)\nax.xaxis.set_ticks_position('top')\nax.xaxis.set_label_position('top')\nax.tick_params(labelsize=12)","33021cd9":"TP = cm.iloc[1,1] # True Positive - Predicted Rain Correctly\nTN = cm.iloc[0,0] # True Negative - Predicted No Rain Incorrectly\nFP = cm.iloc[0,1] # False Positive - Predicted Rain when it didn't rain\nFN = cm.iloc[1,0] # False Negative - Predicted No Rain when it did rain\n\nsens_lr = TP\/(FN+TP)\nspec_lr = TN\/(FP+TN)\n\nprint('Sensitivity: {:.2%}'.format(sens_lr))\nprint('Specificity: {:.2%}'.format(spec_lr))","62dac455":"lr_auc = cross_val_score(lr,X,y,cv=10,scoring='roc_auc').mean()\n\nprint('Null Accuracy Score: {:.2%}\\n'.format(null_accuracy))\nprint('{:>30} {:>26}'.format('Random Forest','Logistic Regression'))\nprint('{} {:>17.2%} {:>22.2%}'.format('AUC Score',rf_auc,lr_auc))\nprint('{} {:>14.2%} {:>22.2%}'.format('Sensitivity*',sens_rf,sens_lr))\nprint('{} {:>14.2%} {:>22.2%}'.format('Specificity*',spec_rf,spec_lr))\nprint('\\n*25% Threshold')","2227e6d0":"Of the time it rained, we have correctly predicted Rain 47.76% of the time. Of the time it did not rain, we have correctly predicted No Rain 94.78% of the time. Considering it doesn't rain 77.6% of the time, you would expect the specificity rate to be higher.","179f0d98":"#### **ROC Curve and Threshold Curve for the Logistic Regression Model**","5c03d58e":"#### **Random Forest Top 5 Features with Categorical (Dummy) Variables Result:**","97a19ca5":"If we built a model that guesses 'No Rain' every time, then we would obtain the 'Null Accuracy' or 'Baseline Accuracy' of 77.6%. ","db82457d":"#### **Confusion Matrix with simplier Random Forest model (Top 7 Features)**","6e502280":"#### **How many features should we use?**\nThere's no one right answer to this. To help us choose what number of features to use, we will visualise the relationship between number of features used vs. accuracy rate.","ea92b623":"From here we can conclude that the categorical features do not add significant amount of value to the accuracy rate. Therefore we can remove the categorical features.","566fa9bc":"#### **Confusion Matrix with simplier Logistic Regression model (7 Features)**","f782dc72":"#### **Feature Selection - using Recursive Feature Elimination (RFE)**\n\n*\"Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\"*\n\nThe Final Random Forest model used 7 features. We will have the same number of features for the Logistic Regression Model. ","4bb48dc1":"#### **Which Features Add Value?**\nFeature selection (reducing the number of variables) will make our model simplier and reduce the chances of overfitting. We don't want to use variables that don't any or much value when it comes training our model to predict the out-of-sample data. ","8e767479":"As you can see, there is not much improvement to the accuracy rate when the number of features are at 5 or more. To keep our model simple, we will use 7 features instead of 59. The accuracy rate from 7 to 59 features differs by only 0.68%. ","b26051c9":"## **5. Conclusion**\n#### **The Random Forest model is the better performer as the AUC is 85.83% vs. 83.41% for the Logistic Regression model.**\n\nFrom comparing accuracy rates, the Categorical Features: WindGustDir,WindDir9am,WindDir3pm, offered little value. We saw the increase in the accuracy rates from having 1 feature to 59 and chose 7 features as that was the approximate point at which the increase in accuracy rate was very small. Having less features would simplify the model, reduce chances of overfitting, and provide better interpretability.\n\nBoth the Random Forest and Logistic Regression had a low sensitivity rate which often incorrectly predicted that it won't rain the next day when it actually did rain. \n\nThe ROC and Threshold Curve demonstrates the relationshp between sensitivity and specificity at each threshold. Assuming that the cost of a False Positive was greater than a False Negative, we have chosen to reduce the threshold from 50% to 25%. This resulted in the sensitivity rate for the Random Forest model increasing from 47.76% to 74.26% at the trade-off of decreasing the specificity rate from 94.78% to 81.16%. \n\nThe features used in the Random Forest and Logistic Regression differ. Features used in the final model were:\n\n    Random Forest                 Logistic Regression\n    1. Humidity3pm                1. Humidity3pm\n    2. Pressure3pm                2. Pressure3pm\n    3. Humidity9am                3. RainToday\n    4. Pressure9am                4. Pressure9am\n    5. Temp3pm                    5. Temp3pm\n    6. Rainfall                   6. MaxTemp\n    7. MinTemp                    7. MinTemp","ecd8b061":"#### **Null Accuracy**","e4fedd44":"#### **Probability Score of Rain and No Rain from the Random Forest**\nThe Random Forest algorithm produces a probability score (the proportion of votes of the trees in the ensemble) in order to make classification. Let's visualise the probability scores for Rain vs. No Rain.","d1921b3d":"Of the time it rained, we have correctly predicted Rain 70.05% of the time. Of the time it did not rain, we have correctly predicted No Rain 79.53% of the time.","6f4281ee":"#### **Rain vs. No Rain**","b314d61c":"#### **Random Forest result:**","fe6e6621":"#### **AUC for Random Forest**\nThe AUC is the Area Under the ROC Curve. If the model produces a high sensitivity and specificity rate (which is what you would want to achieve), then the ROC curve will be stretched towards the top left of the x-y axis.\nThe AUC provides in indication on how well the model had performed in comparison to another model.","e4d64092":"#### **Splitting Data by Train and Test Data**","b4432847":"## **2. Random  Forest**\n#### **Instantiate the Random Forest classifier, fit then predict**","1818002a":"### **3. Logistic Regression**\n#### **Train and Predict using the entire number of features**","4f344288":"Accuracy Rate is 84.98%, however the Baseline Accuracy is 77.6%. Still some improvement though. The False Positives (3,933) are greater than the True Positives (3,653). Let's try and make our model simplier through feature selection as there are 60 features. Then we will try and improve the True Positive Rate.","082a2d7f":"The default threshold is 50%, which had resulted in a low sensitivity rate of 47.76% and specificity of 94.78%. Now will change the threshold so that it provides a higher sensitivity rate at the cost of a lower specificity rate.","a14a6db8":"#### **Confusion Matrix with simplier Logistic Regression model (7 Features) and 25% threshold**","114f7e13":"#### **Train Random Forest with the subset of features. Then, predict.**\n#### **Random Forest Top 5 Features Result:**","14e59df2":"#### **Logistic Regression result using all the features:**","b3cb17dc":"#### **Logistic Regression result using the selected 7 features:**","37ce1118":"Of the time it rained, we have correctly predicted Rain 74.26% of the time. Of the time it did not rain, we have correctly predicted No Rain 81.16% of the time.","c30d6e41":"Of the time it rained, we have correctly predicted Rain 42.35% of the time. Of the time it did not rain, we have correctly predicted No Rain 95.20% of the time. Like what we did before, assuming the cost of False Positive is greater than False Negative, we will adjust the threshold level to 25%.","1205a4dd":"#### **The Selected 7 Features:**","07257c2e":"The Random Forest classication model uses 50% as the threshold for classification. Meaning that if probability of Rain is > 50%, it would predict Rain or assign a value of 1. Else if, the probability of Rain is < 50%, it would predict No Rain or assign a value of 0. \n\nBecause of the binary relationship between Rain and No Rain, the histogram has the highest frequency at 0% for Rain and 100% for No Rain.\n\nBut what if, the cost of a False Negative is greater than a False Positive? That is, the cost of it actually raining and predicting that it won't rain, is greater than the cost of when it does not rain when we have predicted that it will rain.\n\nThe 50% threshold can be reduced in order to increase the sensitivity rate. However this will reduce the specificity rate because there is an inverse relationship between sensitivity and specificity.","304f870a":"#### **ROC Curve (True Positive vs. False Positive Rate) and Threshold Curve for the Random Forest Model**","efbbc4be":"## 4. **Comparison Between Random Forest and Logistic Regression Model**\nWe will compare the results. The Area Under the ROC Curve is an indicator on which classifier model has the stronger performance.","ffbbda5c":"#### **Sensitivty vs. Specificity**\n**Sensitivity:** When it rains, how often are our predictions correct?\n**Specificity:** When it does not rain, how often are our predictions correct? ","7978ad00":"# **Will It Rain Tomorrow?**\n\nWe will predict if it will rain tomorrow in Australia. This is a classification problem as we are predicting whether it will Rain or Not Rain.\n### **Table of Contents**\n\n1. Data Preprocessing and Exploratory Data Analysis\n2. Random Forest\n3. Logistic Regression\n4. Comparison Between Random Forest and Logistic Regression\n5. Conclusion\n\n### **1. Data Preprocessing and Exploratory Data Analysis**\n#### **Import Libraries and Dataset**","fc160e9c":"#### **Missing Data:**","33796b87":"#### **Selecting The Threshold Rate**","fa6e536e":"#### **We will reduce the threshold from 50% to 25%.**\n\nIf the probability of Rain is > 25%, the model will predict Rain (for tomorrow). If the probability of Rain is < 25%, the model will predict No Rain (for tomorrow).","e144c40d":"Remember our Categorical Variables: WindGustDir,WindDir9am,WindDir3pm, were transformed into dummy variables to make the Random Forest algorithm perform better. Because they were transformed into dummy variables, then they would appear to rank low under the important features as plotted above.\n\nTo see whether the Categorical Variables: WindGustDir,WindDir9am,WindDir3pm, add much value to our model, we will compute the accuracy rate for the Random Forest using only the top 5 features, and compare it with the accuracy rate for the Random Forest using the top 5 features as well as the Categorical Variables.","2ecfb925":"#### **Train and Predict using the 7 chosen features**","3eb628cf":"#### **Histogram of the numerical features:**","9a2b6133":"#### **The coefficients and features in the Logistic Regression**","73db9f64":"#### **Correlation matrix between the numerical features:**","2e35a731":"#### **Categorical Features and Dummy Variables**","201354fb":"#### **Confusion Matrix with simplier Random Forest model (top 7 Features) and threshold rate set to 25%**"}}