{"cell_type":{"67b4d7f8":"code","b724a3f5":"code","a71b85e7":"code","ac35de97":"code","d12c7174":"code","fa2cd41f":"code","648652bc":"code","21f9628b":"code","cdec726c":"code","66e52e98":"code","11106080":"code","d7cceba7":"code","099554da":"code","136c39a3":"code","1bbaab82":"code","4c218693":"code","27e2f709":"markdown","f97de27b":"markdown","9a5f98ae":"markdown","16996b8c":"markdown","02157027":"markdown","6b7fc15f":"markdown","041e415f":"markdown"},"source":{"67b4d7f8":"# libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time \nimport tqdm\nfrom PIL import Image\ntrain_on_gpu = True\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n\nimport cv2\nimport albumentations\nfrom albumentations import pytorch as AT\nimport glob\nfrom sklearn.preprocessing import OneHotEncoder","b724a3f5":"class DigitDataset(Dataset):\n    def __init__(self, datafolder='\/kaggle\/input\/handwritten-digits',\n                 transform = transforms.Compose([transforms.ToTensor()])):\n        self.datafolder = datafolder\n        self.transform = transform\n        self.image_files_list = []\n        self.labels = []\n        self._load_images()\n    \n    def _load_images(self):\n        digit_folders = os.listdir(self.datafolder)\n        for folder in digit_folders:\n            for i, pic in enumerate(glob.glob(os.path.join(self.datafolder, folder, '*.jpg'))):\n\n                img = Image.open(pic).convert('RGB')\n                bbox = Image.eval(img, lambda px: 255-px).getbbox()\n                if img.crop(bbox) not in self.image_files_list:\n                    self.image_files_list.append(img.crop(bbox))\n                    if folder == 'other1':\n                        self.image_files_list.append(img.crop(bbox))\n                        self.image_files_list.append(img.crop(bbox))\n\n                    if folder != 'other1':\n                        # print(pic)\n                        if '__' in pic:\n                            self.labels.append(int(pic.split('\/')[-1].split('__')[0][-1]))\n                        else:\n                            self.labels.append(int(pic.split('\/')[-1].split('_')[1]))\n                    else:\n                        for _ in range(3):\n                            self.labels.append(10)\n    \n    def __len__(self):\n        return len(self.image_files_list)\n\n    def __getitem__(self, idx):\n        image = self.image_files_list[idx]\n        image = self.transform(image)\n        label = self.labels[idx]\n        weight = self.weights[idx]\n\n        return image, label, weight","a71b85e7":"train_transforms = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.RandomHorizontalFlip(p=0.2),\n    transforms.RandomRotation((-15, 15)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])","ac35de97":"dataset = DigitDataset(datafolder='\/kaggle\/input\/handwritten-digits', transform=train_transforms)","d12c7174":"len(dataset)","fa2cd41f":"fig = plt.figure(figsize=(25, 4))\n# display 20 images\nfor idx, img_id in enumerate(np.random.randint(0, len(dataset), 20)):\n    ax = fig.add_subplot(2, 20\/\/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(dataset.image_files_list[img_id])\n    lab = dataset.labels[img_id]\n    ax.set_title(f'Label: {lab}')","648652bc":"onehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoder.fit(np.arange(10).reshape(-1, 1))\nohe_labels = onehot_encoder.transform(np.array(dataset.labels).reshape(-1, 1))\ndataset.labels = ohe_labels","21f9628b":"weights = []\nfor i in np.unique(dataset.labels.argmax(1), return_counts=True)[1]:\n    weights.extend([len(dataset.labels) \/ i] * i)\n    \ndataset.weights = weights","cdec726c":"tr, val = train_test_split(range(len(dataset.labels)),\n                           stratify=dataset.labels, test_size=0.1)\n\ntrain_sampler = SubsetRandomSampler(list(tr))\nvalid_sampler = SubsetRandomSampler(list(val))\nbatch_size = 128\nnum_workers = 0\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                           sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                           sampler=valid_sampler, num_workers=num_workers)","66e52e98":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(16, 32, 3)\n        self.fc1 = nn.Linear(576 * 2, 512)\n        self.fc2 = nn.Linear(512, 10)\n        self.dropout = nn.Dropout(0.1)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 576 * 2)\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.fc2(x)\n        return x\n","11106080":"model_conv = Net()\nmodel_conv.cuda()\ncriterion = nn.BCEWithLogitsLoss()\n\noptimizer = optim.SGD(model_conv.parameters(), lr=0.1, momentum=0.85)\nmodel_scheduler = CosineAnnealingLR(optimizer, T_max=5)","d7cceba7":"valid_loss_min = np.Inf\nvalid_loss_hist = []\ntrain_loss_hist = []\nbest_epoch = 0\npatience = 15\n# current number of epochs, where validation loss didn't increase\np = 0\n# whether training should be stopped\nstop = False\n\n# number of epochs to train the model\nn_epochs = 100\ntrain_accuracy = []\nvalid_accuracy = []\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n\n    train_loss = []\n    train_acc = []\n\n    for batch_i, (data, target, weight) in enumerate(train_loader):\n\n        data, target, weight = data.cuda(), target.cuda(), weight.cuda()\n\n        optimizer.zero_grad()\n        output = model_conv(data)\n        criterion.weight = weight.view(-1, 1).double()\n        loss = criterion(output.double(), target.double())\n        train_loss.append(loss.item())\n        \n        a = target.data.cpu().numpy()\n        b = output[:,-1].detach().cpu().numpy()\n        train_acc.append(sum(np.argmax(a, axis=1) == output.argmax(1).cpu().numpy()) \/ len(a))\n        # train_auc.append(roc_auc_score(a, b))\n\n        loss.backward()\n        optimizer.step()\n    \n    model_conv.eval()\n    val_loss = []\n    val_acc = []\n    for batch_i, (data, target, weight) in enumerate(valid_loader):\n        data, target, weight = data.cuda(), target.cuda(), weight.cuda()\n        output = model_conv(data)\n        criterion.weight = weight.view(-1, 1).double()\n        loss = criterion(output.double(), target.double())\n\n        val_loss.append(loss.item()) \n        a = target.data.cpu().numpy()\n        b = output[:,-1].detach().cpu().numpy()\n        val_acc.append(sum(np.argmax(a, axis=1) == output.argmax(1).cpu().numpy()) \/ len(a))\n        # val_auc.append(roc_auc_score(a, b))\n\n    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, train acc: {np.mean(train_acc):.4f}, valid acc: {np.mean(val_acc):.4f}')\n    train_accuracy.append(np.mean(train_acc))\n    valid_accuracy.append(np.mean(val_acc))\n    valid_loss = np.mean(val_loss)\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        # torch.save(model_conv.state_dict(), 'model2____1.pt')\n        valid_loss_min = valid_loss\n        p = 0\n        best_epoch = epoch\n    valid_loss_hist.append(valid_loss)\n    train_loss_hist.append(np.mean(train_loss))\n\n    # check if validation loss didn't improve\n    if valid_loss > valid_loss_min:\n        p += 1\n        print(f'{p} epochs of increasing val loss')\n        if p > patience:\n            print('Stopping training')\n            stop = True\n            break        \n    \n    model_scheduler.step(epoch)\n    \n    if stop:\n        break\n        \nprint(f'Best train_accuracy: {max(train_accuracy)* 100:.4f}%. Best valid_accuracy: {max(valid_accuracy)* 100:.4f}%. Loss: {valid_loss_min:.4f}')","099554da":"targets = []\nall_output = []\nmodel_conv.eval()\nfor batch_i, (data, target, weight) in enumerate(valid_loader):\n\n    data, target = data.cuda(), target.cuda()\n\n    optimizer.zero_grad()\n    output = model_conv(data)\n    targets.extend(target.argmax(1).cpu().numpy())\n    all_output.extend(output.argmax(1).cpu().numpy())","136c39a3":"from sklearn import metrics\n# Show confusion table\nplt.rcParams['figure.figsize'] = (8.0, 8.0)\nconf_matrix = metrics.confusion_matrix(targets, all_output, labels=None)  # Get confustion matrix\n# Plot the confusion table\nclass_names = ['${:d}$'.format(x) for x in range(0, 11)]  # Digit class names\nfig = plt.figure()\nax = fig.add_subplot(111)\n# Show class labels on each axis\nax.xaxis.tick_top()\nmajor_ticks = range(0,11)\nminor_ticks = [x + 0.5 for x in range(0, 11)]\nax.xaxis.set_ticks(major_ticks, minor=False)\nax.yaxis.set_ticks(major_ticks, minor=False)\nax.xaxis.set_ticks(minor_ticks, minor=True)\nax.yaxis.set_ticks(minor_ticks, minor=True)\nax.xaxis.set_ticklabels(class_names, minor=False, fontsize=15)\nax.yaxis.set_ticklabels(class_names, minor=False, fontsize=15)\n# Set plot labels\nax.yaxis.set_label_position(\"right\")\nax.set_xlabel('Predicted label')\nax.set_ylabel('True label')\nfig.suptitle('Confusion table', y=1.03, fontsize=15)\n# Show a grid to seperate digits\nax.grid(b=True, which=u'minor')\n# Color each grid cell according to the number classes predicted\nax.imshow(conf_matrix, interpolation='nearest', cmap='binary')\n# Show the number of samples in each cell\nfor x in range(10):\n    for y in range(10):\n        color = 'w' if x == y else 'k'\n        ax.text(x, y, conf_matrix[y,x], ha=\"center\", va=\"center\", color=color)       \nplt.show()","1bbaab82":"stats_dict = {'train_acc': train_accuracy, 'valid_acc': valid_accuracy,\n              'train_loss': train_loss_hist, 'valid_loss': valid_loss_hist, 'best_epoch': best_epoch}\nplt.figure(figsize=(12, 8))\nplt.plot(stats_dict['train_acc'], label='train_accuracy');\nplt.plot(stats_dict['valid_acc'], label='valid_accuracy');\nplt.title('Accuracy while training');\nplt.axvline(x=stats_dict['best_epoch'], color='red', label='best epoch')\nplt.legend();\nplt.xlabel('Epoch');\nplt.ylabel('Accuracy');","4c218693":"plt.figure(figsize=(12, 8))\nplt.plot(stats_dict['train_loss'], label='train_loss');\nplt.plot(stats_dict['valid_loss'], label='valid_loss');\nplt.title('Loss while training');\nplt.axvline(x=stats_dict['best_epoch'], color='red', label='best epoch')\nplt.legend();\nplt.xlabel('Epoch');\nplt.ylabel('Loss');","27e2f709":"## Preparing data\n\nThe dataset is quite small, so we can load it into memory.\nSome of images are small, so I make crops using boxes from pillow","f97de27b":"Setting weights based on number of samples in classes.","9a5f98ae":"One hot encoding labels","16996b8c":"## Evaluation","02157027":"Defining dataloader","6b7fc15f":"## Importing libraries","041e415f":"## General information\n\nIn this kernel I work with my dataset: https:\/\/www.kaggle.com\/artgor\/handwritten-digits\n\nI show some images from this dataset and train a baseline model in pytorch.\n"}}