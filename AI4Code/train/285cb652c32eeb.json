{"cell_type":{"fbca6d3e":"code","97a0e575":"code","5f4cffd3":"code","adb99738":"code","c5544cbd":"code","01a2df55":"code","18f963c2":"code","f3df69b4":"code","4d588fe4":"code","56271267":"code","c338dfa4":"code","f6bdd189":"code","5415a124":"code","36e2a5dc":"code","70bbfc16":"code","0fd804fa":"code","7e64a555":"code","8810843f":"code","7cc289d8":"code","ed6eb843":"code","0f1d8551":"code","65c787f7":"markdown","6e807d4c":"markdown","4e4e9354":"markdown","0d5a9ffb":"markdown","d3a0be57":"markdown","6471c0af":"markdown","bf4249f9":"markdown","d9a0a77a":"markdown","8fd584fc":"markdown","53592391":"markdown","b1d64481":"markdown","c02c542d":"markdown","bf0c1602":"markdown"},"source":{"fbca6d3e":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import rcParams\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n%matplotlib inline\nrcParams['figure.figsize'] = 10,8\nsns.set(style='whitegrid', palette='muted',\n        rc={'figure.figsize': (12,8)})\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# print(os.listdir(\"..\/input\"))","97a0e575":"# Load data as Pandas dataframe\ntrain = pd.read_csv('..\/input\/train.csv', )\ntest = pd.read_csv('..\/input\/test.csv')\ndf = pd.concat([train, test], axis=0, sort=True)","5f4cffd3":"df.head()","adb99738":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)\n\n        \ndisplay_all(df.describe(include='all').T)","c5544cbd":"df['Survived'].value_counts()","01a2df55":"# create new Title column\ndf['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)","18f963c2":"df.head()","f3df69b4":"df['Title'].value_counts()","4d588fe4":"# replace rare titles with more common ones\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\n           'Don': 'Mr', 'Mme': 'Mrs', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\n           'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ndf.replace({'Title': mapping}, inplace=True)","56271267":"# confirm that we are left with just six values\ndf['Title'].value_counts()","c338dfa4":"# impute missing Age values using median of Title groups\ntitle_ages = dict(df.groupby('Title')['Age'].median())\n\n# create a column of the average ages\ndf['age_med'] = df['Title'].apply(lambda x: title_ages[x])\n\n# replace all missing ages with the value in this column\ndf['Age'].fillna(df['age_med'], inplace=True, )\ndel df['age_med']","f6bdd189":"sns.barplot(x='Title', y='Age', data=df, estimator=np.median, ci=None, palette='Blues_d')\nplt.xticks(rotation=45)\nplt.show()","5415a124":"sns.countplot(x='Title', data=df, palette='hls', hue='Survived')\nplt.xticks(rotation=45)\nplt.show()","36e2a5dc":"sns.swarmplot(x='Sex', y='Fare', hue='Survived', data=df)\nplt.show()","70bbfc16":"# impute missing Fare values using median of Pclass groups\nclass_fares = dict(df.groupby('Pclass')['Fare'].median())\n\n# create a column of the average fares\ndf['fare_med'] = df['Pclass'].apply(lambda x: class_fares[x])\n\n# replace all missing fares with the value in this column\ndf['Fare'].fillna(df['fare_med'], inplace=True, )\ndel df['fare_med']","0fd804fa":"sns.catplot(x='Embarked', y='Survived', data=df,\n            kind='bar', palette='muted', ci=None)\nplt.show()","7e64a555":"df['Embarked'].fillna(method='backfill', inplace=True)","8810843f":"# create Family_Size column (Parch +)\ndf['Family_Size'] = df['Parch'] + df['SibSp']","7cc289d8":"display_all(df.describe(include='all').T)","ed6eb843":"train = df[pd.notnull(df['Survived'])]\ntest = df[pd.isnull(df['Survived'])]","0f1d8551":"train.to_csv('train_clean.csv', index=False)\ntest.to_csv('test_clean.csv', index=False)","65c787f7":"### Extract title from name\nWe can use a regular expression to extract the title from the `Name` column. We will do this by finding the adjacent letters that are immediately followed by a full stop.\n","6e807d4c":"<a id=\"fare\"><\/a>\n## 2.2. Impute missing fare values\nFor the single missing fare value, I also use the median fare value for the passenger's class.   \n\n> Perhaps you could come up with a cooler way of visualising the relationship between the price a passenger paid for their ticket and their chances of survival?","4e4e9354":"As we can see above, there are quite a few different titles. However, many of these titles are just French versions of the more common English titles, e.g. Mme = Madame = Mrs.   \n\nWe will use the six most common titles, replacing all other titles with the most appropriate of these six.","0d5a9ffb":"# Table of Contents:\n\n- **1. [Load Packages and Data](#loading)**\n- **2. [Imputation](#impute-missing)**\n  - **2.1. [Age](#age)**\n  - **2.1. [Fare](#fare)**\n  - **2.1. [Embarked](#embarked)**\n- **3. [Feature engineering](#feature-engineering)**","d3a0be57":"<a id=\"feature-engineering\"><\/a>\n# 3. Add family size column\nWe can use the two variables of **Parch** and **SibSp** to create a new variable called **Family_Size**. This is simply done by adding `Parch` and `SibSp` together.","6471c0af":"<a id=\"loading\"><\/a>\n# 1. Load packages and data\nFirst step, as always, is to import the necessary Python packages and load the input data as a Pandas dataframe.\n\nI chose to combine the train and test set into one. Since we will have to impute some missing age and fare values, I prefer to do this across the entire dataset, rather than separately across train and test sets. ","bf4249f9":"<a id=\"impute-missing\"><\/a>\n# 2. Imputation \nWe can see above that there are a few columns with missing values. The `Cabin` column is missing over 1000 values, so we won't use that for predictions, but the `Age`, `Embarked` and `Fare` columns are all complete enough that we can fill in the missing values through imputation.   \n<a id=\"age\"><\/a>\n## 2.1. Impute missing age values\nA simple option for the missing age values is to use the median age value. Let's go a little further and use each passenger's *Title* to estimate their age. E.g. if a passenger has the title of *Dr*, I will give them the median age value for all other passengers with the same title.","d9a0a77a":"# 4. Save cleaned version\nFinally, let's save our cleaned data set so we can use it in other notebooks.","8fd584fc":"### Use median of title group\nNow, for each missing age value, we will impute the age using the median age for all people with the same title.","53592391":"### Use only the most common titles\nLet's take a look at the unique titles across all passengers:","b1d64481":"# Titanic challenge part 1\nIn this notebook, we will be covering all of the steps required to wrangle the Titanic data set into a format that is suitable for machine learning.   \nWe will do each of the following:\n  - impute missing values\n  - create new features (feature engineering)\n  \n[**Part 2**](https:\/\/www.kaggle.com\/jamesleslie\/titanic-random-forest-grid-search) of this challenge involves fitting and tuning a **random forest** to make predictions.","c02c542d":"We can visualize the median ages for each title group. Below, we see that each title has a distinctly different median age. \n> **Note**: There is no risk in doing this after imputation, as the median of an age group has not been affected by our actions.","bf0c1602":"<a id=\"embarked\"><\/a>\n## 2.3. Impute missing \"embarked\" value\nThere are also just two missing values in the `Embarked` column. Here we will just use the Pandas 'backfill' method.\n"}}