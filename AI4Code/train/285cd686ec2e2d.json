{"cell_type":{"ecf9b3ea":"code","b598b4cd":"code","4a7a696e":"code","30bec9dd":"code","e6e62923":"code","0bca950f":"code","a5a4ac94":"code","37a60ca5":"code","93178859":"code","d12523b9":"code","05925551":"code","526870a0":"code","f8af9496":"code","40dbc67d":"code","9f022ab5":"markdown","3eed7c48":"markdown","16d54651":"markdown","a2b40598":"markdown","df849205":"markdown","5d6f7c95":"markdown","43d342bb":"markdown","9e7bfbfd":"markdown","3d7d849a":"markdown","7d85777b":"markdown","b1604192":"markdown"},"source":{"ecf9b3ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in\/ the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b598b4cd":"import cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","4a7a696e":"Y = np.array(train_df['label'])\ntrain_df.drop(['label'], axis = 1)\nX = []\nfor i in range(len(train_df)):\n    img = np.array(list(train_df.loc[i]))\n    img = np.resize(img, (28,28,1))\n    X.append(img)\nX = np.array(X)\nprint('[INFO] All images read from training data.')\n\ntest_x = []\nfor i in range(len(test_df)):\n    img = np.array(list(test_df.loc[i]))\n    img = np.resize(img, (28,28,1))\n    test_x.append(img)\ntest_x = np.array(test_x)\nprint('[INFO] All images read from testing data.')","30bec9dd":"train_samples = [X[0], X[88], X[6857], X[1365]]\ntest_samples = [test_x[3556], test_x[410], test_x[17], test_x[87]]\n\nfig = plt.figure(figsize = (15,15))\nfor i in range(1,5):\n    ax = fig.add_subplot(1,4,i)\n    ax.imshow(train_samples[i-1], cmap = 'gray')\n    ax.set_title('Training sample '+ str(i))\n    ax.axis('off')\n\nfig = plt.figure(figsize = (15,15))\nfor i in range(1,5):\n    ax = fig.add_subplot(1,4,i)\n    ax.imshow(test_samples[i-1], cmap = 'gray')\n    ax.set_title('Testing sample '+ str(i))\n    ax.axis('off')","e6e62923":"model = keras.Sequential([\n    keras.layers.Conv2D(32, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', input_shape = (28,28,1)),\n    keras.layers.MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    keras.layers.Conv2D(32, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same'),\n    keras.layers.MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Conv2D(64, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same'),\n    keras.layers.MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    keras.layers.Conv2D(64, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same'),\n    keras.layers.MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Conv2D(128, kernel_size = (3,3), strides = 1, activation = 'relu',  padding = 'same'),\n    keras.layers.MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    keras.layers.Conv2D(128, kernel_size = (3,3), strides = 1, activation = 'relu',  padding = 'same'),\n    keras.layers.MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(256, activation = 'relu'),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(64, activation = 'relu'),\n    keras.layers.Dense(10, activation = 'softmax')\n])","0bca950f":"# To see the model architecture details\nmodel.summary()","a5a4ac94":"reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',\n                                             factor = 0.5,\n                                             patience = 3,\n                                             min_lr = 0.0001,\n                                             verbose = 1)","37a60ca5":"#Generator 1 with higher parameter values\ngen1 = ImageDataGenerator(width_shift_range = 0.3,\n                              height_shift_range = 0.3,\n                              zoom_range = 0.5,\n                              rotation_range = 180,\n                              shear_range = 0.5,\n                              fill_mode = 'nearest')\n\ngen2 = ImageDataGenerator(width_shift_range = 0.1,\n                              height_shift_range = 0.1,\n                              zoom_range = 0.15,\n                              rotation_range = 15,\n                              shear_range = 0.1,\n                              fill_mode = 'nearest')\n\n\nimg = np.expand_dims(X[45], axis=0)\nvisual = gen1.flow(img, batch_size=1)\nfig, ax = plt.subplots(nrows=1, ncols=5, figsize=(15,15))\nfor i in range(5):\n    # convert to unsigned integers\n    image = next(visual)[0].astype('uint8')\n\n    # plot image\n    ax[i].imshow(image)\n    ax[i].axis('off')\n    \nvisual2 = gen2.flow(img, batch_size=1)\nfig2, ax2 = plt.subplots(nrows=1, ncols=5, figsize=(15,15))\nfor i in range(5):\n    # convert to unsigned integers\n    image = next(visual2)[0].astype('uint8')\n\n    # plot image\n    ax2[i].imshow(image)\n    ax2[i].axis('off')","93178859":"train_datagen = ImageDataGenerator(width_shift_range = 0.1,\n                                    height_shift_range = 0.1,\n                                    zoom_range = 0.1,\n                                    shear_range = 0.1,\n                                    rotation_range = 15,\n                                    fill_mode = 'nearest'\n                                  )\nval_datagen = ImageDataGenerator()","d12523b9":"seed = 7\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\ni = 1\n\noptimizer = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\nmodel.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\nfor train, val in kfold.split(X,Y):\n    print('\\nSplit :',i)\n    i += 1\n    x_train = X[train]\n    y_train = keras.utils.to_categorical(Y[train], num_classes = 10)\n    x_val = X[val]\n    y_val = keras.utils.to_categorical(Y[val], num_classes = 10)\n    \n    train_gen = train_datagen.flow(x_train, y_train, batch_size = 128)\n    val_gen = val_datagen.flow(x_val, y_val, batch_size = 128)\n    model.fit(train_gen, epochs = 30, steps_per_epoch = len(x_train)\/128, validation_data = val_gen, callbacks = [reduce_lr], verbose = 2)","05925551":"test_y = model.predict(test_x)","526870a0":"# The argmax function fromthe numpy library is used to convert the predicted one-hot vectors into single-digit labels\ny_pred = np.argmax(test_y, axis = 1)","f8af9496":"#Build a data frame and convert it into a csv file\nId = list(range(len(test_df)))\nimageId = [(i+1) for i in Id]\nsubmission_dict =  {'ImageId':imageId, 'label':y_pred}\nsub = pd.DataFrame(submission_dict)","40dbc67d":"sub.head()\nsub.to_csv('submission.csv', index = False)","9f022ab5":"# Test Score\n\nThe model in this notebook is able to achieve a score of 0.995 on the leaderboard.","3eed7c48":"# 5.) Split the data into K-folds for cross validation\nNow it's time to split the data into k folds and train the model iteratively on k-1 folds while evaluating it the remaining k-th fold. \n\n**Important Note:**\nIf we plan to convert our labels into one-hot vector (which we do in this notebook), then the conversion must take place in each iteration after the data has been split into k -folds otherwise following error is raised: ```ValueError: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.``` This happens because stratified k-fold is not designed to work with one-hot vector labels, it expects the labels to be a 1-D array. \nTherefore, we will convert the true labels into categorical labels or one-hot vectors in each iteration using ```to_categorical``` function in keras.","16d54651":"**Data Augmentation**\nAugmenting the data by random rotations, horizontal and vertical shifts is a good way to get more data for training purpose. So, here we will use the ImageDataGenerator to augment the data. However, the augmentation must be carried out carefully for the problem at hand because if the image is modified significantly it might result in loss important information. For example rotating an image containing the digit 6 by 180 degrees will result in the digit 9 and this will confuse the model. Similarly if the image is shifted to a large extent on the vertical and horizontal axis then it might get cropped which will result in the loss of important pixel information. Let us visualize these things to get a better idea. We will instatiate two ImageDataGenerators with different parameters for this.\n","a2b40598":"It can be seen that in the top row images are rotated and shifted by a great margin when compared to the bottom row. Excessive rotation leads to misinterpration of number 6 as number 9. Excessive shift along the vertical or horizontal axis leads to loss of pixel values as well. The key takeaway here is to visualize the augmentations performed for any problem before using them for training. Finally we'll use the data generator specified below in this notebook for data augmentation.","df849205":"# Digit Recognizer with a CNN using Stratified K-Fold cross validation\n\n**The aim of my work in this notebook is to use Convolutional Neural Network model built from scratch (since we are dealing with images) alongwith Stratified K-fold cross-validation for better performance. The input data in the form of 784 pixel values can be reshaped into an image of size 28 X 28 X 1 (1 in the 3rd dimension because we have black and white images, not color images).**\n\nHere is a brief overview of the steps performed in the notebook:\n\n1. Import necessary libraries and load the train and test data by reading the csv files.\n\n2. Prepare the train and test data by reshaping the 784 pixel value array into 28X28 image \n\n3. Build the model using Keras Sequential API.\n\n4. Split the given training data into k folds and augment it.\n\n5. Compile and train the model on the train data on k-1 folds while evaluating on the remianing 1 fold\n\n6. Use the model to predict labels for test data.","5d6f7c95":"**What is K-Fold cross Validation and Stratified K-Fold Validation?**\n\nSplitting the given dataset into fixed train and dev set is the most common practice when training any ML model. In this case the model is repeatadly trained on the train set only and does not get to learn from the data in the dev set. For problems with large datasets this might mean that the model will miss out on a significant numbers of data from which it could have learned something. Consider the MNIST dataset at hand. Assuming we split 42,000 images into train and dev set with the dev set comprising 20-30% images of the total, it means that the model misses out on 8000-12000 images completely during the training process.\n\nA better way to make use of all the images in the dataset for training is to use K-Fold Cross Validation. If you don't know what K-fold cross validation is, here is a great tutorial on it: https:\/\/machinelearningmastery.com\/k-fold-cross-validation\/. \n\nHowever, there's a small problem that we might encounter when using k-fold cross validation. When the data is randomly split into k folds the distribution of classes might get highly uneven in which case the model may not learn as well as we'd like it to. Hence, to prevent this we use stratified k-fold which ensures that the distribution of classes in each fold is the same as the ditribution of the entire dataset. Stratified k-fold tutorial: https:\/\/machinelearningmastery.com\/cross-validation-for-imbalanced-classification\/.\n\nSo let's get started!!","43d342bb":"**What are Callbacks? Why use them?**\n\nA callback is an object that can perform actions at various stages of training (e.g. at the start or end of an epoch, before or after a single batch, etc). For more information refer: https:\/\/keras.io\/api\/callbacks\/\n\nCallbacks are usually used for various purposes, some of which are early stopping and learning rate adjustment. Here we will use a callback to reduce the learning rate of a model when the accuracy plateaus. \n\nReduce Learning Rate on Plateau: After each epoch of training, the callback function checks the metrics such as loss\/accuracy to see if it has plateaued, meaning it checks if the metric has changed significantly or not. If the metric is fairly stable for a certain number of epochs(specified as the parameter ```patience```, it reduces the learning rate by the provided factor. For example in the instance below the callback monitors ```validation accuracy``` and waits for  3 epochs to see a significant change. If it remains fairly stable then the learning rate is reduced by a factor of 1\/2. This is done until the training process ends or until the learning rate reaches the minimum learning rate specified by the parameter ```min_lr```.","9e7bfbfd":"# 1. Import necessary libraries and load the train and test data .","3d7d849a":"**Let us now visualize a few random images from the train and test data.**","7d85777b":"# 2. Prepare train and test data by reshaping the pixel array into 28X28X1 images","b1604192":"# 3.) Build the model using Keras Sequential API\n\nNow it is time to build a simple CNN that accepts an input of shape (28,28,1) and outputs a (10,1) one-hot vector to classify the input digit image. "}}