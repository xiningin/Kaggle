{"cell_type":{"337a504b":"code","41b3300a":"code","d9212668":"code","cdac0980":"code","4f7862a6":"code","c1a298c6":"code","8e414386":"code","59b5065a":"code","5f5bccc4":"code","f27fc478":"code","687f964c":"code","412a7a67":"code","b0c8a21c":"code","3b5dfb38":"code","5806c6df":"code","687cbfe6":"code","605754fd":"code","1d5a7f51":"code","bfe5cdbe":"code","276064ef":"code","39ad51a4":"code","611ea5af":"code","e659fe17":"code","97a637b3":"code","a42b7c17":"code","7f51520d":"markdown","d57106cd":"markdown","01c43ac7":"markdown","5b70ec03":"markdown","373efdeb":"markdown","e570450a":"markdown","28148c5d":"markdown","99fb570f":"markdown","684b7e17":"markdown","2c7ef357":"markdown","9e09a8db":"markdown","e2245ba9":"markdown","54c8cdd0":"markdown","f61dc825":"markdown","7db2ec36":"markdown","91efb8a0":"markdown","f1569d42":"markdown"},"source":{"337a504b":"import pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers import Dense, Dropout\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nimport keras","41b3300a":"def load_cifar10_data(batch_number):\n    with open('..\/input\/data_batch_'+ str(batch_number), 'rb') as file:\n        batch = pickle.load(file, encoding='latin1')\n\n    features = batch['data']\n    labels = batch['labels']\n    return features, labels","d9212668":"batch_1, labels_1 = load_cifar10_data(1)\nbatch_2, labels_2 = load_cifar10_data(2)\nbatch_3, labels_3 = load_cifar10_data(3)\nbatch_4, labels_4 = load_cifar10_data(4)\nbatch_5, labels_5 = load_cifar10_data(5)","cdac0980":"all_images = np.append(batch_1, batch_2, axis=0)\nall_images = all_images.reshape((len(all_images), 3, 32, 32)).transpose(0,2,3,1)\nall_labels = np.append(labels_1, labels_2, axis=0)","4f7862a6":"dict = {0:'Airplane', 1:'Automobile', 2:'Bird', 3:'Cat', 4:'Deer', 5:'Dog', 6:'Frog', 7:'Horse', 8:'Ship', 9:'Truck'}\ndef plot_image(number):\n    fig = plt.figure(figsize = (15,8))\n    plt.imshow(all_images[number])\n    plt.title(dict[all_labels[number]])","c1a298c6":"plot_image(321)","8e414386":"plot_image(2490)","59b5065a":"plot_image(4201)","5f5bccc4":"plot_image(3430)","f27fc478":"X_train = np.append(batch_1[0:8000], batch_2[0:8000], axis=0)\nX_train = np.append(X_train, batch_3[0:8000], axis=0)\nX_train = np.append(X_train, batch_4[0:8000], axis=0)\nX_train = np.append(X_train, batch_5[0:8000], axis=0)","687f964c":"Y_train = np.append(labels_1[0:8000], labels_2[0:8000], axis=0)\nY_train = np.append(Y_train, labels_3[0:8000], axis=0)\nY_train = np.append(Y_train, labels_4[0:8000], axis=0)\nY_train = np.append(Y_train, labels_5[0:8000], axis=0)","412a7a67":"X_validation = np.append(batch_1[8001:9000], batch_2[8001:9000], axis=0)\nX_validation = np.append(X_validation, batch_3[8001:9000], axis=0)\nX_validation = np.append(X_validation, batch_4[8001:9000], axis=0)\nX_validation = np.append(X_validation, batch_5[8001:9000], axis=0)","b0c8a21c":"Y_validation = np.append(labels_1[8001:9000], labels_2[8001:9000], axis=0)\nY_validation = np.append(Y_validation, labels_3[8001:9000], axis=0)\nY_validation = np.append(Y_validation, labels_4[8001:9000], axis=0)\nY_validation = np.append(Y_validation, labels_5[8001:9000], axis=0)","3b5dfb38":"X_test = np.append(batch_1[9001:10000], batch_2[9001:10000], axis=0)\nX_test = np.append(X_test, batch_3[9001:10000], axis=0)\nX_test = np.append(X_test, batch_4[9001:10000], axis=0)\nX_test = np.append(X_test, batch_5[9001:10000], axis=0)","5806c6df":"Y_test = np.append(labels_1[9001:10000], labels_2[9001:10000], axis=0)\nY_test = np.append(Y_test, labels_3[9001:10000], axis=0)\nY_test = np.append(Y_test, labels_4[9001:10000], axis=0)\nY_test = np.append(Y_test, labels_5[9001:10000], axis=0)","687cbfe6":"print(\"Length of X_train:\", len(X_train), \"Length of Y_train:\", len(Y_train))\nprint(\"Length of X_validation:\",len(X_validation), \"Length of Y_validation:\", len(Y_validation))\nprint(\"Length of X_test:\",len(X_test), \"Length of Y_test:\", len(Y_test))","605754fd":"Y_train_one_hot = np_utils.to_categorical(Y_train, 10)\nY_validation_one_hot = np_utils.to_categorical(Y_validation, 10)\nY_test_one_hot = np_utils.to_categorical(Y_test, 10)","1d5a7f51":"X_train = X_train.reshape((len(X_train), 3, 32, 32)).transpose(0,2,3,1)\nX_validation = X_validation.reshape((len(X_validation), 3, 32, 32)).transpose(0,2,3,1)\nX_test = X_test.reshape((len(X_test), 3, 32, 32)).transpose(0,2,3,1)","bfe5cdbe":"classifier = Sequential()\n\n# Convolution layer 1\nclassifier.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3), activation='relu', border_mode='same', bias=True))\n\n# Pooling layer 1\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Dropout(0.2))\n\n# Convolution and pooling layer 2\nclassifier.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same', bias=True))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Dropout(0.3))\n\n# Classifier and pooling layer 3.\nclassifier.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same', bias=True))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Dropout(0.3))\n\n# Classifier and pooling layer 4.\nclassifier.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same', bias=True))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Dropout(0.3))\n\n# Flattening\nclassifier.add(Flatten())\n\n# Full connection\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(output_dim = 128, activation='relu'))\nclassifier.add(Dense(output_dim = 10, activation='softmax'))\n\nclassifier.summary()\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\ntrain_set = train_datagen.flow(X_train, Y_train_one_hot, batch_size=32)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_set = validation_datagen.flow(X_validation, Y_validation_one_hot, batch_size=32)\n\n\nclassifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nclassifier.fit_generator(train_set,\n                    steps_per_epoch=40000,epochs=10,\n                    validation_data=(validation_set), validation_steps=4995, shuffle=True)","276064ef":"X_test = (X_test)*1.\/255 \nscores = classifier.evaluate(X_test, Y_test_one_hot, batch_size=32)\nprint('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))","39ad51a4":"labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\ndef show_test(number):\n    fig = plt.figure(figsize = (15,8))\n    test_image = np.expand_dims(X_test[number], axis=0)\n    test_result = classifier.predict_classes(test_image)\n    plt.imshow(X_test[number])\n    dict_key = test_result[0]\n    plt.title(\"Predicted: {}, Actual: {}\".format(labels[dict_key], labels[Y_test[number]]))","611ea5af":"show_test(123)","e659fe17":"show_test(9)","97a637b3":"show_test(490)","a42b7c17":"show_test(558)","7f51520d":"We give the labels to the neural network in one-hot-encoded format.\nKeras has the np_utils.to_categorical to help us do it.\nTo elaborate on one-hot encoding:\n* Label 5 is given as [ 0, 0, 0, 0, 0, 1, 0, 0, 0, 0 ] where the 5th digit is 1 and rest all are 0's.\n* Label 8 is given as [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 0 ] where the 8th digit is 1 and rest all are 0's.","d57106cd":"Plotting a few images.","01c43ac7":"Testing the model with the test images in the test set that is X_test.","5b70ec03":"For purpose of simplicity, I load different 1-D numpy arrays into one single batch of 40000 images.\nThe first 8000 arrays or images from each batch are appended to a single batch of X_train","373efdeb":"The labels between 8000 and 9000 are loaded to dataset which will be used for validation.\nY_validation contains 1000 labels of the corresponding X_validation images.","e570450a":"There are 5 batches of labeled data that can be used for training and validation and 1 batch that can be used for testing.\nEach batch contains 10000 random images and their corresponding labels. I load the data using the function load_cifar_data.","28148c5d":"This is a simple example of CIFAR-10 dataset.\nCIFAR-10 is a object dataset consisting of 10 objects namely Airplane, Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck. To know more about the dataset, check out the link here: https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html\n\nI start with importing the libraries which will be used.","99fb570f":"Loading the data:\nAs mentioned [here](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) the images are in the form of numpy arrays stored in a pickle file. We read the numpy image arrays and corresponding image labels.","684b7e17":"The dataset contains the labels in the form of digits from 0 to 9.\nI convert the numeric labels to words using the dictionary.\nSecondly, I plot the image just to inspect them visually.","2c7ef357":"I test the accuraccy of test dataset. It is scaled down to values between 0 to 1 as in the case of training and validation dataset.","9e09a8db":"Initially I used just 1 convolution layer.\nUpon increasing the convolution layers, the performance of the model increased.\nI increase the number of feature images from 32 in first convolution layer increasing with the multiple of 2 to 128 in the fourth layer.\nThe ImageDataGenerator scales down the color value by 255. The horizontal flip and vertical flip helps in flipping the training images so that model gets trained better for all possible images.\nFinally I add 2 hidden layers.\nI use the default 'adam optimizer'.\nCategorical crossentropy is used for categorical output as is the case with this dataset.","e2245ba9":"The images between 8000 and 9000 are loaded to dataset which will be used for validation.\nX_validation contains 1000 images.","54c8cdd0":"Similarly the training labels are appended to a single batch of Y_train containing 40000 labels of the corresponding training images.","f61dc825":"The labels between 9000 and 10000 are loaded to dataset which will be used for testing after the model has been trained.\nY_test contains 1000 labels of the corresponding X_test images.","7db2ec36":"This is where we convert the 1-D numpy arrays into 4-D numpy arrays.\nThe conversion is done on all the training, validation and test sets.","91efb8a0":"The images between 9000 and 10000 are loaded to dataset which will be used for testing after the model has been trained.\nX_test contains 1000 images.","f1569d42":"I just append numpy arrays of first two batch just to get the idea of how the images look like.\nThe images need to be reshaped from 1-Dimentional numpy array to 3-Dimentional numpy array as mentioned [here](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html).\nThe images are 3-Dimentional (32x32x3) as the first and the second dimention mention the length and width of the image. THe third dimention indicates r,g,b components i.e the image is a coloured image."}}