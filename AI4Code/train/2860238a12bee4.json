{"cell_type":{"9228116d":"code","31c581bb":"code","6e7c48d2":"code","0f606587":"code","f596f87e":"code","b9c2de5c":"code","658370ac":"code","0ef41c76":"code","bf34f4e1":"code","93accd69":"code","9c90efd7":"code","153df381":"code","1a674352":"code","45e24d82":"code","a5f3fe6b":"code","a610c855":"code","c32c8849":"code","21907c0a":"code","b240b9d8":"code","d0257017":"code","b25ce7f6":"code","7b363a0a":"code","debacaa1":"code","b6aa47af":"code","66e80057":"code","3b94f112":"code","ad652882":"code","a5d6875c":"code","40082e68":"code","85074daf":"code","37883e19":"code","01259cf0":"code","3612a13a":"code","c8c9fcc4":"code","34598915":"code","bb6db314":"code","053df4fe":"markdown","12d1d9c1":"markdown","c4964038":"markdown","1c0793c1":"markdown","00fe5066":"markdown","f87e0be7":"markdown"},"source":{"9228116d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","31c581bb":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf","6e7c48d2":"df.info()","0f606587":"df.isnull().sum()","f596f87e":"#Low variance filter\ndf['Age'].fillna(df['Age'].median(),inplace=True)\ndf['Cabin'].fillna(df['Cabin'].mode()[0], inplace=True)\ndf['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n","b9c2de5c":"df.isnull().sum()","658370ac":"df.corr()","0ef41c76":"from sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\ndf['Sex']=lb.fit_transform(df['Sex'])\ndf['Embarked']=lb.fit_transform(df['Embarked'])\ndf['Cabin']=lb.fit_transform(df['Cabin'])\n\n","bf34f4e1":"df=df.drop(['Name','Ticket','PassengerId'], axis=1)","93accd69":"df","9c90efd7":"X=df.drop(['Survived'],axis=1)\ny=df['Survived']","153df381":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 0)","1a674352":"X_train.shape,y_train.shape","45e24d82":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\nX_train","a5f3fe6b":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU, PReLU, ELU\nfrom keras.layers import Dropout\n\n#initialize the ANN\nclassifier = Sequential()\n\n# Add the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu',input_dim =8))\n\n# Add the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu'))\n\n# Add the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n\n# Compile the ANN\nclassifier.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nmodel_history=classifier.fit(X_train, y_train, batch_size = 64, epochs = 100)\n\n# list all data in history\nclassifier.summary()\n#total params are total number of weights and biases ","a610c855":"# Predict the Test set results\nY_pred = classifier.predict(X_test)\nY_pred","c32c8849":"Y_pred = (Y_pred > 0.5)","21907c0a":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, Y_pred)\nprint(cm)","b240b9d8":"#Calculate the Accuracy\nfrom sklearn.metrics import accuracy_score\nscore=accuracy_score(Y_pred,y_test)\nprint((score)*100,\"%\")","d0257017":"from sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(y_test, Y_pred))","b25ce7f6":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier(n_estimators=200, random_state=0)\nrf.fit(X_train, y_train)\nY_pred_rf=rf.predict(X_test)\nprint(\"Random Forest accuracy\", accuracy_score(Y_pred_rf, y_test)*100,\"%\")","7b363a0a":"import matplotlib.pyplot as plt\nfeatures = df.columns\nimportances = rf.feature_importances_\nindices = np.argsort(importances)[-9:]\nplt.title('Feature importance')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.show()","debacaa1":"from sklearn.metrics import confusion_matrix\ncm_rf = confusion_matrix(y_test,Y_pred_rf)","b6aa47af":"import seaborn as sns\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(cm_rf,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})","66e80057":"test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest.head()","3b94f112":"test.isnull().sum()","ad652882":"#Low variance filter\ntest['Age'].fillna(test['Age'].median(),inplace=True)\ntest['Cabin'].fillna(test['Cabin'].mode()[0], inplace=True)\ntest['Fare'].fillna(test['Fare'].median(),inplace=True)","a5d6875c":"test.isnull().sum()","40082e68":"test","85074daf":"test=test.drop(['Name','Ticket'], axis=1)","37883e19":"from sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\ntest['Sex']=lb.fit_transform(test['Sex'])\ntest['Embarked']=lb.fit_transform(test['Embarked'])\ntest['Cabin']=lb.fit_transform(test['Cabin'])\n","01259cf0":"testmodel=test.drop(['PassengerId'],axis=1)\n\n","3612a13a":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ntestmodel = sc.fit_transform(testmodel)","c8c9fcc4":"y_pred = classifier.predict(testmodel)","34598915":"y_pred = (y_pred > 0.5).astype(int).reshape(testmodel.shape[0])\ny_pred[:], len(y_pred)\n","bb6db314":"import csv\nSubmission = pd.DataFrame({ 'PassengerId': test['PassengerId'], 'Survived': y_pred})\nSubmission.to_csv(\"Titanic_Submission.csv\", index=False)\nSubmission.head()","053df4fe":"**Model Building**","12d1d9c1":"**Importing the Random Forest Model**","c4964038":"**Feature Selection**","1c0793c1":"**Label Encoding**\n\nIt refers to converting the labels into a numeric form so as to convert them into the machine-readable form.","00fe5066":"**Test Data**","f87e0be7":"**Feature Importance**\n\nFeature importance refers to techniques that assign a score to input features based on how useful they are at predicting a target variable.\n\nThe scores are useful and can be used in a range of situations in a predictive modeling problem, such as:\n* Better understanding the data.\n* Better understanding a model.\n* Reducing the number of input features."}}