{"cell_type":{"02a88327":"code","75a8bcc1":"code","d4651c6d":"code","aa6e4c8b":"code","9036fbe7":"code","81545479":"code","2f647750":"code","d6b3713e":"code","7e172200":"code","6b9aa8a8":"code","2b8305f5":"code","651a137d":"code","19ada124":"code","de8b358a":"code","45f8c23f":"code","d25ba19b":"code","a0e10777":"code","f82c48d5":"markdown","2b026d4b":"markdown","9b5cc129":"markdown","0827ad42":"markdown","bd8b7bc6":"markdown","7f2bf8f8":"markdown"},"source":{"02a88327":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","75a8bcc1":"import h5py","d4651c6d":"import matplotlib.pyplot as plt \nimport seaborn as sns\nimport time\n\n_t00 = time.time() # script start time ","aa6e4c8b":"if 1:\n    filename = '\/kaggle\/input\/multiple-single-cell-rna-expressions-archs4\/human_matrix.h5'\n    str_organism = 'human'\nelse:\n    filename = '\/kaggle\/input\/multiple-single-cell-rna-expressions-archs4\/mouse_matrix.h5'\n    str_organism = 'mouse'\nf = h5py.File(filename,'r')#, mode)\nfor key in f.keys():\n    print(key) #Names of the groups in HDF5 file.","9036fbe7":"key = 'data'\nkey2 = 'expression'\nX_full = f[key][key2]\nprint(X_full.shape)\nX_full","81545479":"X_full[:5,:8]","2f647750":"# Extract GSE and look how many unique we have:\nkey = 'meta'\ngroup = f[key]\nd = group['Sample_series_id']\nprint(  len(np.unique(d) ) )\nseries_GSE_for_each_row = pd.Series(d)\nv = series_GSE_for_each_row.value_counts()\nprint( (v > 2000).sum(), (v > 1000).sum(),  (v > 500).sum(),(v > 100).sum(), (v<=10).sum(), (v==1).sum(), )\nv","d6b3713e":"# Some statistics on number of cells corresponding to different GSE:\nseries_GSE_and_cell_count = series_GSE_for_each_row.value_counts()\nseries_GSE_and_cell_count.describe()","7e172200":"#mm = (1500 < series_GSE_and_cell_count ) &  ( series_GSE_and_cell_count < 2000 )\nmm = (100 < series_GSE_and_cell_count ) &  ( series_GSE_and_cell_count < 2000000 )\n\nt00 = time.time()\n\nprint( mm.sum() )\n#print( series_GSE_and_cell_count[mm] )\n\nkey = 'meta'\nkey2 = 'gene_name'\ngene_names = f[key][key2]\n\ndf_stat = pd.DataFrame()\nix4df_stat = 0\nfor GSE in series_GSE_and_cell_count[mm].index:\n    ix4df_stat += 1\n    print()\n    print(GSE)\n    df_stat.loc[ ix4df_stat, 'GSE'] = GSE.decode(encoding=\"ascii\", errors=\"ignore\" )\n    t0 = time.time()\n    mask = GSE == series_GSE_for_each_row\n    mask = mask.values\n    X = X_full[mask,:]\n    print(X.shape, 'count totally zero genes',  (X.sum(axis = 0) == 0 ).sum() ) \n    df_stat.loc[ ix4df_stat, 'Cell count'] = X.shape[0]\n    df_stat.loc[ ix4df_stat, 'Non zero genes count'] = X.shape[1] - (X.sum(axis = 0) == 0 ).sum()\n    m  = (X.sum(axis = 0) != 0 )\n    XX = X[:,m]\n    pcnt_zeros = np.round( (XX==0).sum().sum()\/(XX.shape[0]*XX.shape[1]) * 100  ,2 )\n    df_stat.loc[ ix4df_stat, '% of zeros in data'] = pcnt_zeros\n        \n    l = ['Sample_title', 'Sample_organism_ch1',  'Sample_source_name_ch1', 'Sample_status', 'Sample_instrument_model',\n        'Sample_data_processing',\n     'Sample_extract_protocol_ch1',\n      'Sample_library_selection',\n     'Sample_library_source',\n     'Sample_library_strategy',\n     'Sample_molecule_ch1',\n     'Sample_platform_id',\n     'Sample_source_name_ch1',\n     'Sample_status',\n     'Sample_submission_date',\n    'Sample_last_update_date']\n\n    \n    dt = f['meta']['Sample_submission_date']\n    value_loc = dt[mask][0]\n    value_loc = value_loc.decode(encoding=\"ascii\", errors=\"ignore\" )\n    df_stat.loc[ ix4df_stat, 'Year' ] = value_loc[-4:]# dt[mask][0]\n    \n    flag_single_in_text_info = False\n    flag_cell_in_text_info = False\n    flag_singlecell_in_text_info = False\n    for k in l:\n        dt = f['meta'][k]\n        #print(k,  dt[mask][0:2]     )\n        #print       \n        value_loc = dt[mask][0]\n        value_loc = value_loc.decode(encoding=\"ascii\", errors=\"ignore\" )\n        df_stat.loc[ ix4df_stat, k.replace('_',' ') ] = value_loc# dt[mask][0]\n        if isinstance(value_loc,str):\n            if 'single cell' in value_loc.lower().replace('-',' '):\n                flag_singlecell_in_text_info = True\n                print(value_loc)\n            if 'single' in value_loc.lower():\n                flag_single_in_text_info = True\n                print(value_loc)\n            if 'cell' in value_loc.lower():\n                flag_cell_in_text_info = True\n                print(value_loc)\n            \n    \n    df_stat.loc[ ix4df_stat, 'Single cell In Info' ] = flag_singlecell_in_text_info# dt[mask][0]\n    df_stat.loc[ ix4df_stat, 'Single In Info' ] = flag_single_in_text_info# dt[mask][0]\n    df_stat.loc[ ix4df_stat, 'Cell In Info' ] = flag_cell_in_text_info# dt[mask][0]\n    \n    print( np.round(time.time()-t0,2), 'seconds passed' )\n    df_stat.loc[ ix4df_stat,'Access Time (seconds)'] = np.round(time.time()-t0,2)\n       \nprint(np.round(time.time()-t00,1),np.round((time.time()-t00)\/60,1),'total seconds,minutes passed')\ndf_stat","6b9aa8a8":"df_stat.to_csv('df_stat_'+str_organism+'.csv')","2b8305f5":"pd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","651a137d":"df_scdat = pd.read_csv('\/kaggle\/input\/multiple-single-cell-rna-expressions-archs4\/Single cell studies database Valentine Svensson 20210725.csv')\nprint( df_scdat.columns )\ndf_scdat # 'Data location'\ndef f1(x):\n    if isinstance(x,str):\n        return x.replace(' ','')\n    else:\n        return x\n        \ndf_scdat['Data location'] = df_scdat['Data location'].apply( f1 )\ndf_stat['In Svensson SC list'] = df_stat['GSE'].isin( df_scdat['Data location'].values  ) # .sum()\nprint('Literally In Svensson SC list:', df_stat['In Svensson SC list'].sum())\n\ndf_stat = df_stat.merge( df_scdat, how = 'left', left_on='GSE' , right_on= 'Data location'  , )\n\ndf_stat.head(30)","19ada124":"# Merge for cases like GSE86894Xx-xXGSE86977\nprint('Before In Svensson list:',  df_stat['In Svensson SC list'].sum() )\nfor i in range(len(df_stat)):\n    idx = df_stat.index[i]\n    GSE = df_stat['GSE'].iat[i]\n    if 'Xx-xX' in GSE:\n        GSE1, GSE2 = GSE.split('Xx-xX')[0], GSE.split('Xx-xX')[1]\n        print(GSE1,GSE2, GSE)\n        if (GSE1 in df_scdat['Data location'].values) or ( GSE2 in df_scdat['Data location'].values ):\n            if (GSE1 in df_scdat['Data location'].values):\n                I = np.where(df_scdat['Data location'].values == GSE1)[0][0]\n            else:\n                I = np.where(df_scdat['Data location'].values == GSE2)[0][0]\n            print('In Svensson list. Index:', I )\n            df_stat.loc[idx, 'In Svensson SC list'] = 1\n            for col in df_stat.columns:\n                if col in df_scdat.columns:\n                    df_stat.loc[idx,col] = df_scdat[col].iat[I]\n                    \nprint('After In Svensson list:',  df_stat['In Svensson SC list'].sum() )\n                    ","de8b358a":"df_stat.to_csv('df_stat_'+str_organism+'_merged_Svensson.csv')","45f8c23f":"ll = ['Single cell In Info', 'Single In Info', 'Cell In Info', 'In Svensson SC list' ]\nfor col in ll : \n    print(col, df_stat[col].sum() )\n\nprint('\u00cdntersection single-cell and Svennson count:',np.sum( df_stat['Single cell In Info'] *  df_stat['In Svensson SC list'])  )","d25ba19b":"print('In Svensson SC list count:', df_stat['In Svensson SC list'].sum())\nprint()\n\nll = ['Sample instrument model', 'Sample platform id', 'Sample library selection', 'Sample library source', \n      'Sample library strategy', 'Sample molecule ch1'] \n\nfor k in ll:\n    display(df_stat[k].value_counts())\n    print(); print()","a0e10777":"print(np.round(time.time() - _t00,1),np.round((time.time() - _t00)\/60,1),np.round((time.time() - _t00)\/3600,1),'total seconds,minutes\/hours passed' ) ","f82c48d5":"# Look at different GSE present in data\n","2b026d4b":"## Some details on data\n\nThe file human_matrix.h5 - is version of 8 of the data file.\nIt contains expressions of 35238 genes for  238522 samples. Same file contains meta-information - gene names, sources of data etc \n\nExpression files for mouse and human in HDF5 format. All gene counts are on gene level (Entrez Gene Symbol). For compression purposes the Kallisto pseudocounts are rounded to integer values.\n\n\nSmall csv files like sample_human_tsne.csv may correspond to different version of the main file for example to version 2,\nand thus contains data corresponding to a subset of data relatively to .h5. \n","9b5cc129":"# Open file","0827ad42":"# What is about ?\n\n\nHere we show how to extract datasets by GSE id from the whole data matrix. \nAnd show info on them.  Consider file with human data. \n\nThere 7909 different GSE. \nMost of them contain only very few number of records (cells) - median is 8.\nThere are 8 datasets with more than 2000 records (cells); 27 with more than 1000, 75 with more than 500, 305 with more than 100. \nFor mouse: 17 38 93 345 - datasets with cells more than 2000,1000,500,100 respectively.  \n\nVersions: \n\nV11 - more clever merge with Svensson data - aware of GSE111894Xx-xXGSE111898\n\nV10 - added forgotten field 'Sample_title' - rerun (HUMAN). (FFQ part deleted)  \n\nV9 - tried to attach information from GEO using FFQ, but FFQ seems does not work on many GSENNN - cannot get result for hours - so failed to do that. May be try \"import GEOparse\" next. \n\nV8 - same as 7, corrections for flags calculations\n\nV7 - add info in \"single\/cell\" presence in information strings and merged with Svensson list info\n\nV6 - switch to HUMAN, do the same - show\/save statistics on datasets with more than 100 cells\n\nV5 - same as 4 - minor changes - added some statistics on value coints df_stat - last sections \n\nV4 - show\/save statistics on datasets with more than 100 cells for MOUSE\n\nV3 - show\/save statistics on datasets with more than 1000 cells for MOUSE\n\nV1,2: show statistics on datasets with more than 1000 cells for human \n\n\n============================\n\n## Context:\n\nDataset is downloaded from https:\/\/amp.pharm.mssm.edu\/archs4\/download.html\nThe methods are described in Nature Communications paper: https:\/\/www.nature.com\/articles\/s41467-018-03751-6\n\nThe ARCHS4 data provides user-friendly access to multiple gene expression data from the GEO database. (https:\/\/www.ncbi.nlm.nih.gov\/geo\/ ).  While in GEO database most of data is stored in raw formats,\nARCHS4 provides prepared count matrix expression data. While GEO contains data stored separately for each research paper,\nARCHS4 collects all the information in one single matrix. One may consult the main site for further information.  \n\n\nMain data files are in H5 (HD5, Hierarchical Data Format ) file format https:\/\/en.wikipedia.org\/wiki\/Hierarchical_Data_Format\nIt contains expression data, as well as annotation data and futher meta-information. There are several other auxilliary files like TSNE 3d projection (in CSV format) and correlation matrices for genes for human and mouse in feather format. \n\nThe notebook below gives examples how to work with such files. \n\nThe ARCHS4 project is by :\n\n'Alexander Lachmann', 'alexander.lachmann@mssm.edu', update: '2020-02-06'\n","bd8b7bc6":"# Generate statistics for datasets with more than 1000 cells","7f2bf8f8":"# Access full expression data  "}}