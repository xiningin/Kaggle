{"cell_type":{"a75dc961":"code","5ad33bc2":"code","9b4919b4":"code","43b9ef07":"code","2ac15fc6":"code","213178a2":"code","2b4b7d9c":"code","070da6af":"code","3e0ad32d":"code","71c43341":"code","608bff5c":"code","b4778a21":"code","3d61492e":"code","091b34bd":"code","ae0c130f":"code","4a8149de":"code","84b2ca75":"code","62389847":"code","cf5ae671":"code","5d2980bd":"code","bcac6730":"code","731fd91b":"code","466ee4db":"code","034e6fbb":"code","ffeec320":"code","92e8c73b":"code","f956ffb1":"code","06f9216b":"code","f735fe6b":"code","7d778dda":"code","0030c507":"code","0548616b":"code","65efe3a6":"code","4822dd9a":"code","55f7ce02":"code","339cf7b9":"code","fa4053cd":"code","e7d6b96e":"code","4042387d":"code","d7f53b4a":"code","555db6cd":"code","80d2552f":"code","12d5dca6":"code","8eaf59bd":"code","c9ffcefb":"code","18831c42":"code","7eebac38":"code","e86c37e6":"code","f9dda2ab":"code","15b59fab":"code","625ae610":"code","d930b4db":"code","ec196966":"code","7e09df69":"code","adadfe6a":"code","abfae289":"code","c83a993a":"code","c07ebd03":"code","5266385b":"code","75b97ebe":"code","64802f4a":"code","700cd843":"code","88318556":"code","25ca3994":"code","4776fb80":"code","27455497":"code","805397f1":"code","fff38a92":"code","f2c5b068":"code","9796edd4":"code","60855d1f":"code","0bd54f03":"code","0aa9a393":"code","651db407":"code","380c82e7":"code","68aa5da2":"code","9b649bfa":"code","4f03ff5d":"code","c8019b3f":"code","2b6f0ac0":"code","527a549e":"code","8f989106":"code","8dba928d":"code","0d6a960c":"code","2d669385":"markdown","ad409595":"markdown","1d905d58":"markdown","9b200628":"markdown","53370ed5":"markdown","6b0d0e80":"markdown","5505009c":"markdown","97b7cc8c":"markdown","39f409e2":"markdown","f88b2eaf":"markdown","4b791f59":"markdown","d6e2cbe3":"markdown","3a32df25":"markdown","cb76731d":"markdown","a8504d37":"markdown","d334099c":"markdown","7af7c2ec":"markdown","8591dfca":"markdown","7c53c9fc":"markdown","c87aa50f":"markdown","5f35b619":"markdown","30d0d44f":"markdown","179a04d4":"markdown","d29faac9":"markdown","8ccf879c":"markdown","01f78914":"markdown","993a7885":"markdown","6629b88d":"markdown","466efb7a":"markdown"},"source":{"a75dc961":"# import all libraries and dependencies for dataframe\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom datetime import datetime, timedelta\n\n# import all libraries and dependencies for data visualization\npd.options.display.float_format='{:.4f}'.format\nplt.rcParams['figure.figsize'] = [8,8]\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', -1) \nsns.set(style='darkgrid')\nimport matplotlib.ticker as ticker\nimport matplotlib.ticker as plticker\n\n# import all libraries and dependencies for machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.base import TransformerMixin\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport statsmodels.api as sm\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import r2_score","5ad33bc2":"import pandas as pd    \ndataset = pd.read_csv('..\/input\/fastract-wrist-watch-features-and-price\/dataset.csv')","9b4919b4":"df = pd.DataFrame(dataset)\ndf.head()","43b9ef07":"df['price'] = df['price'].astype(str)\ndf['price'] = df['price'].str.replace(',', '').str.replace('\u20b9', '').astype(int)\ndf['price'].dtype","2ac15fc6":"df['price'].describe()","213178a2":"import numpy as np\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nax = sns.boxplot(x=df[\"price\"])","2b4b7d9c":"Q1 =  df['price'].quantile(0.25)\nQ3 = df['price'].quantile(0.75)\nIQR = Q3 - Q1\n\n#removing outliers from data bsed on price\noutliers = []\nfor i in df.index :\n    if df['price'][i] > Q1+1.5*IQR or df['price'][i] < Q1 -  1.5*IQR:\n        outliers.append(i)\n        \ndf.drop(index = outliers,inplace = True)","070da6af":"sns.set(style=\"whitegrid\")\nax = sns.boxplot(x=df[\"price\"])","3e0ad32d":"df.dtypes","71c43341":"df['thickness'] = df['thickness'].astype(str)\ndf['thickness'] = df['thickness'].str.replace(' ', '').str.replace('mm', '').astype(float)\n\ndf['weight'] = df['weight'].astype(str)\ndf['weight'] = df['weight'].str.replace(' ', '').str.replace('g', '').astype(float)\n\ndf['width'] = df['width'].astype(str)\ndf['width'] = df['width'].str.replace(' ', '').str.replace('mm', '').str.replace('cm', '').astype(float)\n\ndf['Diameter'] = df['Diameter'].astype(str)\ndf['Diameter'] = df['Diameter'].str.replace(' ', '').str.replace('mm', '').astype(float)\n\ndf.dtypes","608bff5c":"df['water_resistant'].unique()","b4778a21":"Numeric = ['weight','width','thickness','Diameter','price']\ncategorical = ['water_resistant','Display_type','strap_material','box_material','occasion','series','strap_type']","3d61492e":"num_df = df.loc[: , Numeric]\ncat_df = df.loc[: , categorical]","091b34bd":"import matplotlib.pyplot as plt\nplt.title('wrist watch Price Distribution Plot')\nsns.distplot(df['price'])","ae0c130f":"ax = sns.pairplot(num_df)","4a8149de":"corr=num_df.corr()\ncorr.style.background_gradient(cmap=\"inferno\")","84b2ca75":"plt.figure(figsize=(20, 15))\nplt.subplot(3,3,1)\nsns.boxplot(x = 'water_resistant', y = 'price', data = df)\nplt.subplot(3,3,2)\nsns.boxplot(x = 'Display_type', y = 'price', data = df)","62389847":"plt.figure(figsize=(20, 10))\nsns.boxplot(x = 'strap_material', y = 'price', data = df)","cf5ae671":"df['strap_material'].unique()","5d2980bd":"full_cat = ['Silicone Strap', 'Stainless Steel Strap', 'Leather Strap',\n       'Metal Strap', 'Silicon Strap', 'Rubber Strap', 'Sillicone Strap',\n       'Resin Strap', 'Tan Strap', 'Genuine Leather Strap', 'metal Strap','Denim Strap', 'Plastic Strap',\n       'Polyurethane Strap', 'LEATHER Strap', 'Steel Strap',\n       'Fabric Strap']\nfor i in df.index:\n    if df['strap_material'][i] in full_cat:\n        df['strap_material'][i] = 'cat1'","bcac6730":"df['strap_material'].unique()","731fd91b":"plt.figure(figsize=(20, 10))\nsns.boxplot(x = 'strap_material', y = 'price', data = df)","466ee4db":"df['box_material'].unique()","034e6fbb":"plt.figure(figsize=(20, 10))\nsns.boxplot(x = 'box_material', y = 'price', data = df)","ffeec320":"df['box_material'].unique()","92e8c73b":"full_cat2 = ['Cardboard', 'Metal', 'Plastic', 'Brass Case','Plastic Box',]\nfor i in df.index:\n    if df['box_material'][i] in full_cat2:\n        df['box_material'][i] = 'cat1'","f956ffb1":"plt.figure(figsize=(20, 10))\nsns.boxplot(x = 'box_material', y = 'price', data = df)","06f9216b":"df['occasion'].unique()","f735fe6b":"plt.figure(figsize=(20, 10))\nsns.boxplot(x = 'occasion', y = 'price', data = df)","7d778dda":"df['occasion'].value_counts().plot(kind='bar')\nplt.xlabel('occasion')\nplt.ylabel('Frequency')\nplt.show()","0030c507":"df['series'].unique()","0548616b":"df['series'].value_counts().plot(kind = 'bar')","65efe3a6":"plt.figure(figsize=(20, 10))\nsns.boxplot(x = 'series', y = 'price', data = df)","4822dd9a":"df['strap_type'].unique()","55f7ce02":"plt.figure(figsize=(20, 10))\nsns.boxplot(x = 'strap_type', y = 'price', data = df)","339cf7b9":"df['strap_type'].value_counts().plot(kind = 'bar')","fa4053cd":"print(cat_df)\ndummy_cat = ['water_resistant','Display_type','strap_material','box_material','occasion','series','strap_type']","e7d6b96e":"dummies = pd.get_dummies(df[dummy_cat])\ndummies.shape","4042387d":"dummies = pd.get_dummies(df[dummy_cat], drop_first = True)\ndummies.shape","d7f53b4a":"# Drop the original cat variables as dummies are already created\n\ndf.drop( dummy_cat, axis = 1, inplace = True)\ndf.shape","555db6cd":"df = df.drop(columns = ['Diameter','width'])\ndf.head()","80d2552f":"corr=df.corr()\ncorr.style.background_gradient(cmap=\"inferno\")","12d5dca6":"df = pd.concat([df, dummies], axis = 1)\ndf.head()\ndf.shape\n","8eaf59bd":"df.head()","c9ffcefb":"# We specify this so that the train and test data set always have the same rows, respectively\n# We divide the df into 70\/30 ratio\n\nfrom sklearn.model_selection import train_test_split\nnp.random.seed(0)\ndf_train, df_test = train_test_split(df, train_size = 0.8, test_size = 0.2, random_state = 100)","18831c42":"scaler = preprocessing.StandardScaler()","7eebac38":"sig_num_col = ['price','thickness','weight']\n# Apply scaler() to all the columns except the 'dummy' variables\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndf_train[sig_num_col] = scaler.fit_transform(df_train[sig_num_col])","e86c37e6":"df = df.drop(columns = 'water_resistant')","f9dda2ab":"df_test.head()","15b59fab":"df_train.head()","625ae610":"# Let's check the correlation coefficients to see which variables are highly correlated\n\nplt.figure(figsize = (20, 20))\nsns.heatmap(df_train.corr(), cmap=\"RdYlGn\")\nplt.show()","d930b4db":"y_train = df_train.pop('price')\nX_train = df_train","ec196966":"y_train.shape","7e09df69":"X_train_1 = X_train['thickness']\n# Add a constant\nX_train_1c = sm.add_constant(X_train_1)\n\n# Create a first fitted model\nlr_1 = sm.OLS(y_train, X_train_1c).fit()","adadfe6a":"lr_1.params","abfae289":"# Let's visualise the data with a scatter plot and the fitted regression line\n\nplt.scatter(X_train_1c.iloc[:, 1], y_train)\nplt.plot(X_train_1c.iloc[:, 1], 0.8062*X_train_1c.iloc[:, 1], 'r')\nplt.show()","c83a993a":"# Print a summary of the linear regression model obtained\nprint(lr_1.summary())","c07ebd03":"X_train_2 = X_train[['thickness', 'weight']]","5266385b":"# Add a constant\nX_train_2c = sm.add_constant(X_train_2)\n\n# Create a second fitted model\nlr_2 = sm.OLS(y_train, X_train_2c).fit()\nlr_2.params","75b97ebe":"print(lr_2.summary())","64802f4a":"# Running RFE with the output number of the variable equal to 15\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)             \nrfe = rfe.fit(X_train, y_train)","700cd843":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","88318556":"# Selecting the variables which are in support\n\ncol_sup = X_train.columns[rfe.support_]\ncol_sup","25ca3994":"# Creating X_train dataframe with RFE selected variables\n\nX_train_rfe = X_train[col_sup]","4776fb80":"# Adding a constant variable and Build a first fitted model\nimport statsmodels.api as sm  \nX_train_rfec = sm.add_constant(X_train_rfe)\nlm_rfe = sm.OLS(y_train,X_train_rfec).fit()\n\n#Summary of linear model\nprint(lm_rfe.summary())","27455497":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","805397f1":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe1 = X_train_rfe.drop('strap_type_Genuine leather', 1,)\n\n# Adding a constant variable and Build a second fitted model\n\nX_train_rfe1c = sm.add_constant(X_train_rfe1)\nlm_rfe1 = sm.OLS(y_train, X_train_rfe1c).fit()\n\n#Summary of linear model\nprint(lm_rfe1.summary())","fff38a92":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe2 = X_train_rfe1.drop('series_loopholes', 1,)\n\n# Adding a constant variable and Build a third fitted model\n\nX_train_rfe2c = sm.add_constant(X_train_rfe2)\nlm_rfe2 = sm.OLS(y_train, X_train_rfe2c).fit()\n\n#Summary of linear model\nprint(lm_rfe2.summary())","f2c5b068":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe3 = X_train_rfe2.drop('series_Tattoo', 1,)\n\n# Adding a constant variable and Build a fourth fitted model\nX_train_rfe3c = sm.add_constant(X_train_rfe3)\nlm_rfe3 = sm.OLS(y_train, X_train_rfe3c).fit()\n\n#Summary of linear model\nprint(lm_rfe3.summary())","9796edd4":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe4 = X_train_rfe3.drop('series_Upgrades', 1,)\n\n# Adding a constant variable and Build a fifth fitted model\nX_train_rfe4c = sm.add_constant(X_train_rfe4)\nlm_rfe4 = sm.OLS(y_train, X_train_rfe4c).fit()\n\n#Summary of linear model\nprint(lm_rfe4.summary())","60855d1f":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe5 = X_train_rfe4.drop('series_Bikers', 1,)\n\n# Adding a constant variable and Build a sixth fitted model\nX_train_rfe5c = sm.add_constant(X_train_rfe5)\nlm_rfe5 = sm.OLS(y_train, X_train_rfe5c).fit()\n\n#Summary of linear model\nprint(lm_rfe5.summary())","0bd54f03":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe6 = X_train_rfe5.drop('series_Fundamentals', 1,)\n\n# Adding a constant variable and Build a sixth fitted model\nX_train_rfe6c = sm.add_constant(X_train_rfe6)\nlm_rfe6 = sm.OLS(y_train, X_train_rfe6c).fit()\n\n#Summary of linear model\nprint(lm_rfe6.summary())","0aa9a393":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe7 = X_train_rfe6.drop('series_Extreme Hybrid', 1,)\n\n# Adding a constant variable and Build a sixth fitted model\nX_train_rfe7c = sm.add_constant(X_train_rfe7)\nlm_rfe7 = sm.OLS(y_train, X_train_rfe7c).fit()\n\n#Summary of linear model\nprint(lm_rfe7.summary())","651db407":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe8 = X_train_rfe7.drop('series_Tees Valentines', 1,)\n\n# Adding a constant variable and Build a sixth fitted model\nX_train_rfe8c = sm.add_constant(X_train_rfe8)\nlm_rfe8 = sm.OLS(y_train, X_train_rfe8c).fit()\n\n#Summary of linear model\nprint(lm_rfe8.summary())","380c82e7":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe9 = X_train_rfe8.drop('series_Star Wars', 1,)\n\n# Adding a constant variable and Build a sixth fitted model\nX_train_rfe9c = sm.add_constant(X_train_rfe9)\nlm_rfe9 = sm.OLS(y_train, X_train_rfe9c).fit()\n\n#Summary of linear model\nprint(lm_rfe9.summary())","68aa5da2":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe10 = X_train_rfe9.drop('series_Trendies', 1,)\n\n# Adding a constant variable and Build a sixth fitted model\nX_train_rfe10c = sm.add_constant(X_train_rfe10)\nlm_rfe10 = sm.OLS(y_train, X_train_rfe10c).fit()\n\n#Summary of linear model\nprint(lm_rfe10.summary())","9b649bfa":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe11 = X_train_rfe10.drop('series_Party', 1,)\n\n# Adding a constant variable and Build a sixth fitted model\nX_train_rfe11c = sm.add_constant(X_train_rfe11)\nlm_rfe11 = sm.OLS(y_train, X_train_rfe11c).fit()\n\n#Summary of linear model\nprint(lm_rfe11.summary())","4f03ff5d":"# Predicting the price of training set.\ny_train_price = lm_rfe11.predict(X_train_rfe11c)","c8019b3f":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms Analysis', fontsize = 20)                   \nplt.xlabel('Errors', fontsize = 18)","2b6f0ac0":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ndf_test[sig_num_col] = scaler.transform(df_test[sig_num_col])\ndf_test.shape","527a549e":"y_test = df_test.pop('price')\nX_test = df_test","8f989106":"# Adding constant\nX_test_1 = sm.add_constant(X_test)\n\nX_test_new = X_test_1[X_train_rfe10c.columns]","8dba928d":"# Making predictions using the final model\ny_pred = lm_rfe10.predict(X_test_new)","0d6a960c":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)   \nplt.xlabel('y_test ', fontsize=18)                       \nplt.ylabel('y_pred', fontsize=16)  ","2d669385":"**strap material seems to affect price, all we need to do is join some of these categories together and this will help us to increase accuracy of our prediction**","ad409595":"**now this thing looks good ,and can be used ti predict price**\n","1d905d58":"**looking at price distribution of price**","9b200628":"**Visualising few more Categorical Variables**","53370ed5":"**Separating numerical and categorical data**","6b0d0e80":"Boxplot of all the categorical variables","5505009c":"**box material**\n* we can easily say that cardboard matal hav overall very small range of price\n* materials like Cardboard Metal Plastic have almost same price range thus it will be good to concatinate them\n* it will also be good to merge brass case and plastic box into same category as they have veryless values in dataset which may cause problem if all of those values go in test set.\n","97b7cc8c":"# converting dependent variable to suitable datatype and its analysis","39f409e2":"**Checking VIF**","f88b2eaf":"**water resistant**\n\n* there are very few watches with 10 and 60 values.\n* wrist watches with WR value of 100 have low celling for maximimum value.\n* no watches with price lower than \u20b9100 have WR value 3 or 10.\n\n*in the end water resistant dosen't seem to affect price at all*\n","4b791f59":"**series variablelooks to help in prediction**","d6e2cbe3":"**looking for correlation between numerical variables and price**","3a32df25":"* Looking at the p-values, it looks like some of the \nvariables aren't really significant (in the presence of other variables)and we need to drop it","cb76731d":"**Display Type**\n* analog only seems to have whole varity in price.\n* almost all of the watches with cost < \u20b9100 belongs to this only analog category\n\n*Display type seen to impact price*","a8504d37":"# Building a Linear Model","d334099c":"# Making a prediction model","7af7c2ec":"**water resistant is a discreate variable**","8591dfca":"1. **weight and thickness doesn't show any significant trend with price.** \n2. **Diameter and Width have negative correlation with price**","7c53c9fc":"**Converting Width , Weight , thickness and diameter from object into float datatype**","c87aa50f":"Variance Inflation Factor or VIF, gives a basic quantitative idea about how much the feature variables are correlated with each other. It is an extremely important parameter to test our linear model. The formula for calculating VIF is: VIF = 1\/(1 - R^2)","5f35b619":"# Checking for outliers ","30d0d44f":"**finding categorical and continues features**","179a04d4":"**Removing Outliers**","d29faac9":"**box material is now good to use**","8ccf879c":"**correlation matrix for better understanding of relation between numeric variables and price**","01f78914":"We generally want a VIF that is less than 5. So there are clearly some variables we need to drop.","993a7885":"**Encoding categorical variables**","6629b88d":"# Analysing independent variables","466efb7a":"**casual watches are prefered**"}}