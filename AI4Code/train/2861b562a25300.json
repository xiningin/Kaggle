{"cell_type":{"d293ee49":"code","ef7cae62":"code","68b4cd57":"code","b55cf519":"code","5345be36":"code","056efd93":"code","eeaf1077":"code","309844a9":"code","6c5e10b4":"code","6c5e2916":"code","23d7a31f":"code","997c9419":"code","08127d32":"code","1e0bcf04":"code","b0fa22c3":"code","c13e165f":"code","9e36a07c":"code","ece5c174":"code","6484ae2f":"code","f6f2b627":"code","4188b8b8":"code","b970d3f2":"code","e983ae5a":"code","2bd174a1":"code","9eb68500":"code","aea7168f":"markdown","c60f2abb":"markdown","499085c7":"markdown","7be9f0de":"markdown","18207558":"markdown"},"source":{"d293ee49":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nfrom pathlib import Path\nfrom torch.utils.data import Dataset, DataLoader, sampler\nfrom PIL import Image\nimport torch\nimport matplotlib.pyplot as plt\nimport time","ef7cae62":"if not os.path.exists(\"pytorch_unet.py\"):\n    if not os.path.exists(\"pytorch_unet\"):\n        !git clone https:\/\/github.com\/usuyama\/pytorch-unet.git\n\n    # %cd pytorch-unet","68b4cd57":"# check torch\nimport torch\n\nif not torch.cuda.is_available():\n  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n\nprint(\"device name\", torch.cuda.get_device_name(0))","b55cf519":"!ls -l","5345be36":"# reference to https:\/\/www.kaggle.com\/cordmaur\/38-cloud-simple-unet\n\nclass CloudDataset(Dataset):\n    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, pytorch=True):\n        super().__init__()\n        \n        # Loop through the files in red folder and combine, into a dictionary, the other bands\n        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]\n        self.pytorch = pytorch\n        \n    def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):\n        \n        files = {'red': r_file, \n                 'green':g_dir\/r_file.name.replace('red', 'green'),\n                 'blue': b_dir\/r_file.name.replace('red', 'blue'), \n                 'nir': nir_dir\/r_file.name.replace('red', 'nir'),\n                 'gt': gt_dir\/r_file.name.replace('red', 'gt')}\n\n        return files\n                                       \n    def __len__(self):\n        \n        return len(self.files)\n     \n    def open_as_array(self, idx, invert=False, include_nir=False):\n\n        raw_rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n                            np.array(Image.open(self.files[idx]['green'])),\n                            np.array(Image.open(self.files[idx]['blue'])),\n                           ], axis=2)\n    \n        if include_nir:\n            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n    \n        if invert:\n            raw_rgb = raw_rgb.transpose((2,0,1))\n    \n        # normalize\n        return (raw_rgb \/ np.iinfo(raw_rgb.dtype).max)\n    \n\n    def open_mask(self, idx, add_dims=False):\n        \n        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n    \n    def __getitem__(self, idx):\n        \n        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch, include_nir=True), dtype=torch.float32)\n        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)\n        \n        return x, y\n","056efd93":"# create torch dataset like defined in CloudDataset class\nbase_path = Path('..\/input\/38cloud-cloud-segmentation-in-satellite-images\/38-Cloud_training')\ndata = CloudDataset(base_path\/'train_red', \n                    base_path\/'train_green', \n                    base_path\/'train_blue', \n                    base_path\/'train_nir',\n                    base_path\/'train_gt')\nlen(data)","eeaf1077":"# returns features x and target feature y\nx, y = data[1000]\nx.shape, y.shape","309844a9":"# visualize raw image and ground truth\nimage_index = 800\n\nfig, ax = plt.subplots(1,2, figsize=(10,9))\nax[0].imshow(data.open_as_array(image_index))\nax[1].imshow(data.open_mask(image_index))\n\n# left -> raw image\n# right Ground-Truth Mask (as binary image)","6c5e10b4":"train_dataset, valid_dataset = torch.utils.data.random_split(data, (6000, 2400))","6c5e2916":"# Create dataloads sample from dataset\n\ntrain_dataload = DataLoader(train_dataset, batch_size=3, shuffle=True)\nvalid_dataload = DataLoader(valid_dataset, batch_size=3, shuffle=True)","23d7a31f":"# test dataload\nxb, yb = next(iter(train_dataload))\nxb.shape, yb.shape","997c9419":"from torch import nn\nclass UNET(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n\n        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n        self.conv2 = self.contract_block(32, 64, 3, 1)\n        self.conv3 = self.contract_block(64, 128, 3, 1)\n\n        self.upconv3 = self.expand_block(128, 64, 3, 1)\n        self.upconv2 = self.expand_block(64*2, 32, 3, 1)\n        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)\n\n    def __call__(self, x):\n\n        # downsampling part\n        conv1 = self.conv1(x)\n        conv2 = self.conv2(conv1)\n        conv3 = self.conv3(conv2)\n\n        upconv3 = self.upconv3(conv3)\n\n        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n\n        return upconv1\n\n    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n\n        contract = nn.Sequential(\n            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            torch.nn.BatchNorm2d(out_channels),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            torch.nn.BatchNorm2d(out_channels),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n                                 )\n\n        return contract\n\n    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n\n        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n                            torch.nn.BatchNorm2d(out_channels),\n                            torch.nn.ReLU(),\n                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n                            torch.nn.BatchNorm2d(out_channels),\n                            torch.nn.ReLU(),\n                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n                            )\n        return expand","08127d32":"unet = UNET(4,2)","1e0bcf04":"! pip install hiddenlayer","b0fa22c3":"import hiddenlayer as hl\n\ntransforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n\ngraph = hl.build_graph(unet, torch.zeros([12, 4, 384, 384]), transforms=transforms)\ngraph.theme = hl.graph.THEMES['blue'].copy()\ngraph.save('rnn_hiddenlayer', format='png')","c13e165f":"graph\n\n# visualize Unet Layers","9e36a07c":"# testing one pass\nxb, yb = next(iter(train_dataload))\nxb.shape, yb.shape\n\npred = unet(xb)\npred.shape","ece5c174":"import time\nfrom IPython.display import clear_output\n\ndef train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=1):\n    start = time.time()\n    model.cuda()\n\n    train_loss, valid_loss = [], []\n\n    best_acc = 0.0\n\n    for epoch in range(epochs):\n        print('Epoch {}\/{}'.format(epoch, epochs - 1))\n        print('-' * 10)\n\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train(True)  # Set trainind mode = true\n                dataloader = train_dataload\n            else:\n                model.train(False)  # Set model to evaluate mode\n                dataloader = valid_dataload\n\n            running_loss = 0.0\n            running_acc = 0.0\n\n            step = 0\n\n            # iterate over data\n            for x, y in dataloader:\n                x = x.cuda()\n                y = y.cuda()\n                step += 1\n\n                # forward pass\n                if phase == 'train':\n                    # zero the gradients\n                    optimizer.zero_grad()\n                    outputs = model(x)\n                    loss = loss_fn(outputs, y)\n\n                    # the backward pass frees the graph memory, so there is no \n                    # need for torch.no_grad in this training pass\n                    loss.backward()\n                    optimizer.step()\n                    # scheduler.step()\n\n                else:\n                    with torch.no_grad():\n                        outputs = model(x)\n                        loss = loss_fn(outputs, y.long())\n\n                # stats - whatever is the phase\n                acc = acc_fn(outputs, y)\n\n                running_acc  += acc*dataloader.batch_size\n                running_loss += loss*dataloader.batch_size \n\n                if step % 100 == 0:\n                    # clear_output(wait=True)\n                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()\/1024\/1024))\n                    # print(torch.cuda.memory_summary())\n\n            epoch_loss = running_loss \/ len(dataloader.dataset)\n            epoch_acc = running_acc \/ len(dataloader.dataset)\n\n            clear_output(wait=True)\n            print('Epoch {}\/{}'.format(epoch, epochs - 1))\n            print('-' * 10)\n            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n            print('-' * 10)\n\n            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n\n    time_elapsed = time.time() - start\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))    \n    \n    return train_loss, valid_loss    \n\ndef acc_metric(predb, yb):\n    return (predb.argmax(dim=1) == yb.cuda()).float().mean()","6484ae2f":"loss_fn = nn.CrossEntropyLoss() # choose loss function\nopt = torch.optim.Adam(unet.parameters(), lr=0.01) # choose gradient function\n\n# start training\ntrain_loss, valid_loss = train(unet, train_dataload, valid_dataload, loss_fn, opt, acc_metric, epochs=2)\n\n","f6f2b627":"train_loss","4188b8b8":"valid_loss","b970d3f2":"# visualize Result\nplt.figure(figsize=(10,8))\nplt.plot(train_loss, label='Train loss')\nplt.plot(valid_loss, label='Valid loss')\nplt.legend()","e983ae5a":"def batch_to_img(xb, idx):\n    img = np.array(xb[idx,0:3])\n    return img.transpose((1,2,0))\n\ndef predb_to_mask(predb, idx):\n    p = torch.functional.F.softmax(predb[idx], 0)\n    return p.argmax(0).cpu()","2bd174a1":"xb, yb = next(iter(train_dataload))\n\nwith torch.no_grad():\n    predb = unet(xb.cuda())\n\npredb.shape","9eb68500":"bs = 12\nfig, ax = plt.subplots(bs,3, figsize=(15,bs*5))\nfor i in range(bs):\n    ax[i,0].imshow(batch_to_img(xb,i))\n    ax[i,1].imshow(yb[i])\n    ax[i,2].imshow(predb_to_mask(predb, i))","aea7168f":"## Model","c60f2abb":"## Use the UNET without Training","499085c7":"# Cloud Segmentation with U-Net","7be9f0de":"## Preparation & Exploration","18207558":"## Init & Prepare"}}