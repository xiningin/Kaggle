{"cell_type":{"193c58c5":"code","281a3b0e":"code","775e2e90":"code","94790784":"code","a5680dd5":"code","6318a585":"code","a3c55ab5":"code","a8d0d3db":"code","1a327b0e":"code","26b2958d":"code","7bbd0401":"code","3eab7d3f":"code","495f5c1e":"code","b733e886":"code","90a186ad":"code","310c8d7e":"code","4d0f2378":"code","169975ef":"code","eb3677e3":"code","6811e565":"code","33f3e6a2":"code","47d1222d":"code","ce763970":"code","ef60e5b3":"code","4662ba07":"code","8bee9d8e":"code","20f1fdfd":"code","43a48b19":"code","5c45cfe5":"code","f5e72e64":"code","a87e851c":"code","46e211df":"code","1bac6eeb":"code","bd3d758d":"code","7fae47e9":"code","8e799cf0":"code","e50c0200":"code","f1d3bb7f":"code","a5c52351":"code","fc995002":"code","2bdea144":"code","7ff3434b":"code","c608e8c7":"code","68002d63":"code","a9b66947":"code","ea214c68":"code","8f646ffb":"code","23bb0f8d":"code","b0b90a46":"code","c423f4fc":"code","fd0258c6":"code","8d1e83f4":"code","37058ddb":"code","10804c5d":"code","80647606":"code","bf68b66f":"code","d7d0b2c0":"code","30df8353":"code","df5ba568":"code","7059b4d2":"code","23d4fef0":"code","8e3d35b1":"code","e72abbe5":"code","41f60399":"code","da5b936c":"code","1484f834":"code","098f7d16":"code","05eb613e":"code","2378bb95":"code","e80d70fd":"code","402bcfd2":"code","c1632ea7":"code","cef6d354":"code","5c83978e":"markdown","8c2509de":"markdown","98effd51":"markdown","69e0c9d9":"markdown","ab1f0b90":"markdown","0e699e02":"markdown","f2874a05":"markdown","1a566ce1":"markdown","39b7adf3":"markdown","68660792":"markdown","5bb34b6b":"markdown","37ba975d":"markdown","81ea10b2":"markdown","4ce7d90a":"markdown","ae394d2d":"markdown","2250e43e":"markdown","c1cec5b7":"markdown","d997abea":"markdown","4231d496":"markdown","5073e7d5":"markdown","385a421c":"markdown","fbd4b522":"markdown","7ea45e9c":"markdown","01beb10c":"markdown","7e2c7472":"markdown","ea46b193":"markdown","026cb81e":"markdown","84c0a466":"markdown","1c933b28":"markdown","5d779b41":"markdown","d8b3968d":"markdown","30ad782f":"markdown","6adb2293":"markdown","84c00bd3":"markdown","6016720b":"markdown","a762a7eb":"markdown","56a37e7e":"markdown","e44e177d":"markdown","fb413752":"markdown","c9c9b7ef":"markdown","934a9076":"markdown","e94c4871":"markdown","f31b6603":"markdown"},"source":{"193c58c5":"# Data analysis tools\nimport pandas as pd\nimport numpy as np\n\n# Data Visualization Tools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Data Pre-Processing Libraries\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\n\n# For Train-Test Split\nfrom sklearn.model_selection import train_test_split\n\n# Libraries for various Algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Metrics Tools\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, f1_score\n\n#For Receiver Operating Characteristic (ROC)\nfrom sklearn.metrics import roc_curve ,roc_auc_score, auc\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","281a3b0e":"df = pd.read_csv('\/kaggle\/input\/people-charm\/People Charm case.csv')","775e2e90":"df.head(10)","94790784":"df.info()","a5680dd5":"df.isnull().sum()","6318a585":"len(df[df.duplicated()])","a3c55ab5":"# Removing all duplicates\ndf=df.drop_duplicates(subset=None, keep='first', inplace=False)\nlen(df[df.duplicated()])","a8d0d3db":"sns.countplot(df[\"left\"])\nplt.xlabel(\"Class\")\nplt.ylabel(\"frequency\")\nplt.title(\"Checking imbalance\")","1a327b0e":"sns.distplot(df.skew(),hist=False)\nplt.show()","26b2958d":"# Printing interquartile range (IQR) for each column\nQ1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","7bbd0401":"# Boxplot visualization for columns with high IQR\n\nplt.boxplot([df[\"numberOfProjects\"]])\nplt.xticks([1],[\"numberOfProjects\"])\nplt.show()\nplt.boxplot([df[\"timeSpent.company\"]])\nplt.xticks([1],[\"timeSpent.company\"])\nplt.show()\nplt.boxplot([df[\"avgMonthlyHours\"]])\nplt.xticks([1],[\"avgMonthlyHours\"])\nplt.show()","3eab7d3f":"# Identifying the Ideal min and maximum value\n\nprint(df['timeSpent.company'].quantile(0.10))\nprint(df['timeSpent.company'].quantile(0.90))","495f5c1e":"# Capping and Flooring of Outliers\n\ndf[\"timeSpent.company\"] = np.where(df[\"timeSpent.company\"] <2.0, 2.0,df['timeSpent.company'])\ndf[\"timeSpent.company\"] = np.where(df[\"timeSpent.company\"] >5.0, 5.0,df['timeSpent.company'])\n\ndf.head()","b733e886":"cols=['dept', 'salary']\nfor label in cols:\n    df[label]=LabelEncoder().fit_transform(df[label])\ndf.head()","90a186ad":"# Correlation \ndf.corr()[\"left\"]","310c8d7e":"plt.figure(figsize = (10,5))\nsns.heatmap(df.corr(), cmap = \"RdYlGn\", annot = True)","4d0f2378":"# satisfactoryLevel vs left\nfig, ax = plt.subplots(3,3,figsize = (15,15))\nsatisfactoryLevel = pd.crosstab(df['satisfactoryLevel'],df['left'])\nsatisfactoryLevel.div(satisfactoryLevel.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, ax=ax[0,0])\n\n# lastEvaluation vs left\nlastEvaluation = pd.crosstab(df['lastEvaluation'],df['left'])\nlastEvaluation.div(lastEvaluation.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True, ax=ax[0,1])\n\n# numberOfProjects vs left\nnumberOfProjects = pd.crosstab(df['numberOfProjects'],df['left'])\nnumberOfProjects.div(numberOfProjects.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True, ax=ax[0,2])\n\n# avgMonthlyHours vs left\navgMonthlyHours = pd.crosstab(df['avgMonthlyHours'],df['left'])\navgMonthlyHours.div(avgMonthlyHours.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True,ax=ax[1,0])\n\n# timeSpent vs left\ntimeSpent = pd.crosstab(df['timeSpent.company'],df['left'])\ntimeSpent.div(timeSpent.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True, ax=ax[1,1])\n\n# workAccident vs left\nworkAccident = pd.crosstab(df['workAccident'],df['left'])\nworkAccident.div(workAccident.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True, ax=ax[1,2])\n\n# promotionInLast5years vs left\npromotionInLast5years= pd.crosstab(df['promotionInLast5years'],df['left'])\npromotionInLast5years.div(promotionInLast5years.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True,ax=ax[2,0])\n\n# dept vs left\ndept= pd.crosstab(df['dept'],df['left'])\ndept.div(dept.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True,ax=ax[2,1])\n\n# salary vs left\nsalary= pd.crosstab(df['salary'],df['left'])\nsalary.div(salary.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True,ax=ax[2,2])","169975ef":"scaler=StandardScaler()","eb3677e3":"X=df.drop([\"left\"],axis=1)\ny=df[\"left\"]\n\nX =scaler.fit_transform(X)","6811e565":"# Train-Test Split\nx_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)","33f3e6a2":"#Fitting the model\n\nlogistic_Regression = LogisticRegression(max_iter=3000,random_state=0,class_weight=\"balanced\",solver = \"saga\")\nlogistic_Regression.fit(x_train,y_train)","47d1222d":"# Applying the model to the x_test\n\ny_pred = logistic_Regression.predict(x_test)\ny_pred","ce763970":"# Finding Accuracy\n\nlog = accuracy_score(y_pred,y_test)*100","ef60e5b3":"# Confusion Matrix\n\ncmlr=confusion_matrix(y_pred,y_test)\nprint(cmlr)","4662ba07":"# Classification Report that computes various\n# metrics like Precision, Recall and F1 Score\n\nprint(classification_report(y_pred,y_test))","8bee9d8e":"# Plotting the ROC Curve\n\nprob_lr=logistic_Regression.predict_proba(x_test)\nauc_lr = roc_auc_score(y_test,prob_lr[:,1])\nfprlr,tprlr,_ = roc_curve(y_test,prob_lr[:,1])\nroc_auc=auc(fprlr,tprlr)\nplt.plot(fprlr,tprlr,label = \"AUC = %.2f\" % auc_lr)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for Logistic Regression\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","20f1fdfd":"#Fitting the model\n\nknn = KNeighborsClassifier(n_neighbors=35)\nknn.fit(x_train,y_train)","43a48b19":"# Applying the model to the x_test\n\npred_knn = knn.predict(x_test)\npred_knn","5c45cfe5":"# Finding Accuracy\n\nKNN = accuracy_score(pred_knn,y_test)*100","f5e72e64":"# Confusion Matrix\n\ncm_knn=confusion_matrix(pred_knn,y_test)\nprint(cm_knn)","a87e851c":"# Classification Report that computes various\n# metrics like Precision, Recall and F1 Score\n\nprint(classification_report(pred_knn,y_test))","46e211df":"# Plotting the ROC Curve\n\nprob_knn= knn.predict_proba(x_test)\nauc_knn = roc_auc_score(y_test,prob_knn[:,1])\nfprknn,tprknn,_= roc_curve(y_test,prob_knn[:,1])\nroc_auc_knn=auc(fprknn,tprknn)\nplt.plot(fprknn,tprknn,label = \"AUC = %.2f\" % auc_knn)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for KNN\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","1bac6eeb":"#Fitting the model\n\ngnb=GaussianNB()\ngnb.fit(x_train,y_train)","bd3d758d":"# Applying the model to the x_test\n\npred_gnb = gnb.predict(x_test)\npred_gnb","7fae47e9":"# Finding Accuracy\n\nGNB = accuracy_score(pred_gnb,y_test)*100","8e799cf0":"# Confusion Matrix\n\ncm_gnb=confusion_matrix(pred_gnb,y_test)\nprint(cm_gnb)","e50c0200":"# Classification Report that computes various \n# metrics like Precision, Recall and F1 Score\n\nprint(classification_report(pred_gnb,y_test))","f1d3bb7f":"# Plotting the ROC Curve\n\nprob_gnb= gnb.predict_proba(x_test)\nauc_gnb = roc_auc_score(y_test,prob_gnb[:,1])\nfprgnb,tprgnb,_= roc_curve(y_test,prob_gnb[:,1])\nroc_auc_gnb=auc(fprgnb,tprgnb)\nplt.plot(fprgnb,tprgnb,label = \"AUC = %.2f\" % auc_gnb)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for Naive-Bayes\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","a5c52351":"#Fitting the model\n\nsvc = SVC(probability=True)\nsvc.fit(x_train,y_train)\n\n# Applying the model to the x_test\npred_svc = svc.predict(x_test)\npred_svc","fc995002":"# Finding Accuracy\n\nSVC = accuracy_score(pred_svc,y_test)*100","2bdea144":"# Confusion Matrix\n\ncm_svc=confusion_matrix(pred_svc,y_test)\nprint(cm_svc)","7ff3434b":"# Classification Report that computes various \n#metrics like Precision, Recall and F1 Score\n\nprint(classification_report(pred_svc,y_test))","c608e8c7":"# Plotting the ROC Curve\n\nprob_svc= svc.predict_proba(x_test)\nauc_svc = roc_auc_score(y_test,prob_svc[:,1])\nfprsvc,tprsvc,_= roc_curve(y_test,prob_svc[:,1])\nroc_auc_svc=auc(fprsvc,tprsvc)\nplt.plot(fprsvc,tprsvc,label = \"AUC = %.2f\" % auc_svc)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for SVM\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","68002d63":"#Fitting the model\n\ndtree_en = DecisionTreeClassifier()\nclf = dtree_en.fit(x_train,y_train)","a9b66947":"# Applying the model to the x_test\n\npred_dt = clf.predict(x_test)\npred_dt","ea214c68":"# Finding Accuracy\n\nDTREE = accuracy_score(pred_dt,y_test)*100","8f646ffb":"# Confusion Matrix\n\ncm_dt=confusion_matrix(y_test,pred_dt)\nprint(cm_dt)\n\n# Classification Report that computes various \n# metrics like Precision, Recall and F1 Score\n\nprint(classification_report(y_test,pred_dt))","23bb0f8d":"# Plotting the ROC Curve\n\nprob_dt= dtree_en.predict_proba(x_test)\nauc_dt = roc_auc_score(y_test,prob_dt[:,1])\nfprdt,tprdt,_= roc_curve(y_test,prob_dt[:,1])\nroc_auc_dt=auc(fprdt,tprdt)\nplt.plot(fprdt,tprdt,label = \"AUC = %.2f\" % auc_dt)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for Decision Tree\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","b0b90a46":"#Fitting the model\n\nGBC=GradientBoostingClassifier(n_estimators=150)\nGBC.fit(x_train,y_train)","c423f4fc":"# Applying the model to the x_test\n\nY_predict=GBC.predict(x_test)\nY_predict","fd0258c6":"# Finding Accuracy\n\ngbc = accuracy_score(y_test,Y_predict)*100","8d1e83f4":"# Confusion Matrix\n\ncm_gbc=confusion_matrix(y_test,Y_predict)\nprint(cm_gbc)\n\n# Classification Report that computes various \n# metrics like Precision, Recall and F1 Score\n\nprint(classification_report(y_test,Y_predict))","37058ddb":"# Plotting the ROC Curve\n\nprob_GBC= GBC.predict_proba(x_test)\nauc_GBC = roc_auc_score(y_test,prob_GBC[:,1])\nfprGBC,tprGBC,_= roc_curve(y_test,prob_GBC[:,1])\nroc_auc_GBC=auc(fprGBC,tprGBC)\nplt.plot(fprGBC,tprGBC,label = \"AUC = %.2f\" % auc_GBC)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for Gradient Boosting\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","10804c5d":"#Fitting the model\n\nrfc = RandomForestClassifier(n_estimators=30,criterion='gini',random_state=1,max_depth=10)\nrfc.fit(x_train, y_train)","80647606":"# Applying the model to the x_test\n\npred_rf= rfc.predict(x_test)\npred_rf","bf68b66f":"# Finding Accuracy\n\nRFC = accuracy_score(y_test,pred_rf)*100","d7d0b2c0":"# Confusion Matrix\n\ncm_rf=confusion_matrix(pred_rf,y_test)\nprint(cm_rf)","30df8353":"# Classification Report that computes various \n# metrics like Precision, Recall and F1 Score\n\nprint(classification_report(pred_rf,y_test))","df5ba568":"# Plotting the ROC Curve\n\nprob_rfc= rfc.predict_proba(x_test)\nauc_rfc = roc_auc_score(y_test,prob_rfc[:,1])\nfprrfc,tprrfc,_= roc_curve(y_test,prob_rfc[:,1])\nroc_auc_rfc=auc(fprrfc,tprrfc)\nplt.plot(fprrfc,tprrfc,label = \"AUC = %.2f\" % auc_rfc)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for Random Forest\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","7059b4d2":"#Fitting the model. Base model is chosen to be Decision Tree\n\nmodel = DecisionTreeClassifier(criterion='entropy',max_depth=1,random_state=0)\nadaboost = AdaBoostClassifier(n_estimators=80, base_estimator=model,random_state=0)\nadaboost.fit(x_train,y_train)","23d4fef0":"# Applying the model to the x_test\n\npred = adaboost.predict(x_test)\npred","8e3d35b1":"# Finding Accuracy\n\nada = accuracy_score(y_test,pred)*100","e72abbe5":"# Confusion Matrix\n\ncm_ada=confusion_matrix(pred,y_test)\nprint(cm_ada)\n\n# Classification Report that computes various \n# metrics like Precision, Recall and F1 Score\n\nprint(classification_report(pred,y_test))","41f60399":"# Plotting the ROC Curve\n\nprob_adaboost= adaboost.predict_proba(x_test)\nauc_adaboost = roc_auc_score(y_test,prob_adaboost[:,1])\nfpradaboost,tpradaboost,_= roc_curve(y_test,prob_adaboost[:,1])\nroc_auc_adaboost=auc(fpradaboost,tpradaboost)\nplt.plot(fpradaboost,tpradaboost,label = \"AUC = %.2f\" % auc_adaboost)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for AdaBoost (Entropy-Decision Tree)\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","da5b936c":"#Fitting the model\n\nxgb =  XGBClassifier(learning_rate =0.000001,n_estimators=1000,max_depth=5,min_child_weight=1,\n                     subsample=0.8,colsample_bytree=0.8,nthread=4,scale_pos_weight=1,seed=27)\nxgb.fit(x_train, y_train)","1484f834":"# Applying the model to the x_test\n\n\npredxg = xgb.predict(x_test)\n\n# Finding Accuracy\nxg = accuracy_score(y_test,predxg)*100\n","098f7d16":"# Confusion Matrix\n\ncm_xg=confusion_matrix(predxg,y_test)\nprint(cm_xg)\n\n# Classification Report that computes various \n# metrics like Precision, Recall and F1 Score\n\nprint(classification_report(predxg,y_test))","05eb613e":"# Plotting the ROC Curve\n\nprob_xgb= xgb.predict_proba(x_test)\nauc_xgb = roc_auc_score(y_test,prob_xgb[:,1])\nfprxgb,tprxgb,_= roc_curve(y_test,prob_xgb[:,1])\nroc_auc_xgb=auc(fprxgb,tprxgb)\nplt.plot(fprxgb,tprxgb,label = \"AUC = %.2f\" % auc_xgb)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for XGBoost\")\nplt.plot([0,1],[0,1],\"--\")\nplt.legend()\nplt.show()","2378bb95":"# Accuracy values for all the models\nprint(\"1)  Logistic Regression    :\",round(log, 2))\nprint(\"2)  KNN                    :\",round(KNN, 2))\nprint(\"3)  Naive-Bayes            :\",round(GNB, 2))\nprint(\"4)  SVM                    :\",round(SVC, 2))\nprint(\"5)  Decision Tree          :\",round(DTREE, 2))\nprint(\"6)  Gradient Boosting      :\",round(gbc, 2))\nprint(\"7)  Random Forest          :\",round(RFC, 2))\nprint(\"8)  AdaBoost               :\",round(ada, 2))\nprint(\"9)  XGBoost                :\",round(xg, 2))","e80d70fd":"# Area Under the Curve(AUC) of all the models\nprint('Area under the curve for Logistic Regression :',round(roc_auc, 2))\nprint('Area under the curve for KNN                 :',round(roc_auc_knn, 2))\nprint('Area under the curve for Naive-Bayes         :',round(roc_auc_gnb, 2))\nprint('Area under the curve for SVM                 :',round(roc_auc_svc, 2))\nprint('Area under the curve for Decision Tree       :',round(roc_auc_dt, 2))\nprint('Area under the curve for Gradient Boosting   :',round(roc_auc_GBC, 2))\nprint('Area under the curve for Random Forest       :',round(roc_auc_rfc, 2))\nprint('Area under the curve for AdaBoost            :',round(roc_auc_adaboost, 2))\nprint('Area under the curve for XGBoost             :',round(roc_auc_xgb, 2))","402bcfd2":"#ROC Curve for all models\nplt.figure(figsize = (20,10))\nplt.plot(fprlr,tprlr,label = \"Logistic Regression\")\nplt.plot(fprknn,tprknn,label = \"KNN\")\nplt.plot(fprgnb,tprgnb,label = \"Naive-Bayes\")\nplt.plot(fprsvc,tprsvc,label = \"SVM\")\nplt.plot(fprdt,tprdt,label = \"Decision Tree\")\nplt.plot(fprGBC,tprGBC,label = \"Gradient Boosting\",color='black')\nplt.plot(fprrfc,tprrfc,label = \"Random Forest\",color='yellow')\nplt.plot(fpradaboost,tpradaboost,label = \" AdaBoost\")\nplt.plot(fprxgb,tprxgb,label = \"XGBoost\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True)","c1632ea7":"# f1_score of all models\nprint(\"1)  Logistic Regression    :\",round(f1_score(y_pred,y_test), 2))\nprint(\"2)  KNN                    :\",round(f1_score(pred_knn,y_test), 2))\nprint(\"3)  Naive-Bayes            :\",round(f1_score(pred_gnb,y_test), 2))\nprint(\"4)  SVM                    :\",round(f1_score(pred_svc,y_test), 2))\nprint(\"5)  Decision Tree          :\",round(f1_score(pred_dt,y_test), 2))\nprint(\"6)  Gradient Boosting      :\",round(f1_score(Y_predict,y_test), 2))\nprint(\"7)  Random Forest          :\",round(f1_score(pred_rf,y_test), 2))\nprint(\"8)  AdaBoost               :\",round(f1_score(pred,y_test), 2))\nprint(\"9)  XGBoost                :\",round(f1_score(predxg,y_test), 2))","cef6d354":"#Accessing the False Positives of all models from their confusion Matrix\nprint(\"1)  Logistic Regression    :\",cmlr[0][1])\nprint(\"2)  KNN                    :\",cm_knn[0][1])\nprint(\"3)  Naive-Bayes            :\",cm_gnb[0][1])\nprint(\"4)  SVM                    :\",cm_svc[0][1])\nprint(\"5)  Decision Tree          :\",cm_dt[0][1])\nprint(\"6)  Gradient Boosting      :\",cm_gbc[0][1])\nprint(\"7)  Random Forest          :\",cm_rf[0][1])\nprint(\"8)  AdaBoost               :\",cm_ada[0][1])\nprint(\"9)  XGBoost                :\",cm_xg[0][1])","5c83978e":"Skewness refers to distortion or asymmetry in a symmetrical bell curve, or normal distribution, in a set of data. If the curve is shifted to the left or to the right, it is said to be skewed. If there is too much skewness in the data, then the statistical model don\u2019t work properly. This is because, in skewed data, the tail region may act as an outlier for the statistical model and we know that outliers adversely affect the model\u2019s performance. Hence, we need to check for outliers.","8c2509de":"Arranging the accuracy values in order:\n\n1)  Random Forest          : 98.29 %\n\n2)  Gradient Boosting      : 98.04 %\n\n3)  XGBoost                : 97.96 %\n\n4)  SVM                    : 96.58 %\n\n5)  Decision Tree          : 96.54 %\n\n6)  AdaBoost               : 96.08 %\n\n7)  KNN                    : 94.87 %\n\n8)  Naive-Bayes            : 85.74 %\n\n9)  Logistic Regression    : 79.78 % \n\n\n\n\n\nHere, <b>Random Forest Classifier has the highest accuracy rate.<\/b> But during Data visualization step, we observed that the <b>class distribution is Imbalanced<\/b>. The dataset has 80% samples of class 0 (the employee is not leaving their job) and 20% samples of class 1(The employee has decided to leave their job). This is the reason why most of the models are getting accuracy above 90% by simply predicting every training sample belonging to class 0. But, when we apply this model to a new test-set, then the <b>test accuracy would drop to less than 60%.<\/b>\n\n<b>In this case, Accuracy metric proves to be a poor indicator of model performance. Therefore, we need to consider other metrics before deciding the best model.<\/b>","98effd51":"<b>Here we can see that there are outliers in the timespent.company column in the dataset. There are two options here:\n    \n    \n1) We can drop the entire column from the dataset\n\n2) We can treat the outliers\n\nThe best option is to treat the outliers rather than removing the entire column. This way we will not lose more data.\n\nI am using Capping method in order to treat the outliers<\/b>","69e0c9d9":"* The dataset \u2018People Charm Case.csv\u2019  contains 10 columns.\n* Target Variable: \u201cLeft\u201d\n* Predictor Variables: 'satisfactoryLevel', 'lastEvaluation', 'numberOfProjects', 'avgMonthlyHours', 'timeSpent.company', 'workAccident', 'promotionInLast5years', 'dept', 'salary\u2019.","ab1f0b90":"<h1><center><u>Employee Attrition Prediction<\/u><\/center><\/h1>\n\n<b>\u2018People Charm\u2019, a growing company is facing a high attrition rate among their employees which in turn affects their business due to lack of expertise and experience. Their HR department is assigned the task to reduce the attrition rate by retaining employees who are about to churn out. They need to recommend special plans or strategies which will help them to retain their employees which in turn will help them to grow bigger as a company.\n\nThe file \u2018People Charm Case.csv\u2019 has several attributes. <\/b>\n\n![image.png](attachment:image.png)","0e699e02":"# Step 6: Defining the Tatget and Predictor Variables and Standard Scaling\n\n<b> \n* We know that our target variable is \u201cleft\u201d. Hence, we define X (Predictor variables) and Y (Target Variable).\n    \n* If a feature\u2019s variance is more than the variance of other features, that particular feature might dominate other features in the dataset. This could affect the accuracy of predictions. Hence, we need to scale all the features to a standard centered scale. For this purpose, we use StandardScaler() method.\n    \n* After Feature scaling, I am dividing the dataset into Train and test set at a ratio 80:20.<\/b>","f2874a05":"# Step 3: Understanding the Structure of the Dataset","1a566ce1":"The <b>Receiver Operating Characteristic (ROC)<\/b> curve is plot which shows the performance of a binary classifier as function of its cut-off threshold. ROC curve is one of the most effective evaluation metrics because it visualizes the accuracy of predictions for a whole range of cutoff values. It essentially shows the true positive rate (TPR) against the false positive rate (FPR) for all possible threshold values. <b>A model is said to be the best model when the ROC is close to the upper left corner.<\/b>\n\nLooking at the ROC curve plot above, the <b>black curve (Gradient Boosting), is the curve that is closest to the upper left corner. Hence, based on the ROC plot, Gradient Boosting is the best fit model.<\/b>","39b7adf3":"# 4) F1-Score","68660792":"# Step 8: Choosing the Best model\n\nThere are various ways to evaluate a classification model. Some of them are:\n \n1) Accuracy\n    \n2) AUC\n    \n3) ROC\n    \n4) f1 Score\n    \n5) Type I Error\n\nI am evaluating with all these metrics in order to find the best fit model\n\n# Confusion Matrix\n\nA confusion matrix is an N X N matrix, where N is the number of classes being predicted. Confusion Matrix gives us a matrix as output and describes the complete performance of the model.\n\nThe correct predictions falls on the diagonal line of the matrix.\n\n4 important terms in Confusion Matrix:\n\n<b>True Positives<\/b>  : We predict YES and the actual output is also YES.\n\n<b>True Negatives<\/b>  : We predict NO and the actual output is NO.\n\n<b>False Positives(Type I Error)<\/b> : We predict YES but the actual output is NO.\n\n<b>False Negatives(Type II error)<\/b> : We predict NO but the actual output is YES.\n\n<b>The Confusion matrix in itself is not a performance measure, but almost all of the performance metrics are based on Confusion Matrix.\n","5bb34b6b":"The dataset had 3008 duplicate values. Retaining these values could lead to Over-fitting of data. Therefore, we need to remove these values before proceeding further.\n\nPandas has a method called drop_duplicates() that allows us to drop all the duplicate values. Using this method, we have removed all duplicate values.","37ba975d":"# f) Converting the categorical data into numerical data appropriately\n\nscikit-learn only accepts numerical variables. Hence, we need to convert all categorical variables into numeric types.","81ea10b2":"The area under the curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values. AUC calculates the area under the ROC curve, and therefore it is between 0 and 1.<b> For any classifier, the higher the AUC of a model the better it is.<\/b> The AUC values of all the models are listed below:\n\n1)  Gradient Boosting      : 0.99\n\n2)  Random Forest          : 0.98\n\n3)  XGBoost                : 0.98\n\n4)  AdaBoost               : 0.98\n\n5)  SVM                    : 0.97\n\n6)  KNN                    : 0.96\n\n7)  Decision Tree          : 0.95\n\n8)  Naive-Bayes            : 0.87\n\n9)  Logistic Regression    : 0.86\n\nHere, <b>Gradient Boosting<\/b> has the highest AUC value. Hence, based on the AUC values, Gradient Boosting is the best fit model.","4ce7d90a":"# 7) Random Forest","ae394d2d":"# 5)Type I Error","2250e43e":"# 5) Decision Tree","c1cec5b7":"# 6) Gradient Boosting","d997abea":"We will do the flooring (10th percentile) for the lower values and capping (the 90th percentile) for the higher values. These values will be used for quantile-based flooring and capping.\n\n* For capping, the code below replaces all values greater than 5.0 with 5.0\n\n* Similarly, for Flooring, the code replaces all values lesser than 2.0 with 2.0","4231d496":"# 2) KNN","5073e7d5":"# d) Checking Skewness of data","385a421c":"From the graph, it is clear that the class distribution is Imbalanced. The dataset has :\n\n* 80% samples of class 0 - the employee is not leaving their job\n\n* 20% samples of class 1 - The employee has decided to leave their job\n\nEffect of Data imbalance:\n\nBecause the class distribution is not balanced, most machine learning algorithms will perform very well with very high accuracy (Sometimes more than 90%)on training data. But when applied to a new test dataset, the same model performs very poorly(having less than 60% accuracy). \nThis is because, during training, the model simply predicts the majority class in all cases leading to very high accuracy. \nIn this type of situations, Accuracy cannot be taken as a reliable metric to decide the best fit model.","fbd4b522":"# Correlation between each predictor and the target variable. \n<b>This can be done using the corr() method and we can visualize using seabors plotting method heatmap().<\/b>","7ea45e9c":"# Step 4: Data Pre-Processing\n\nThe dataset contains 14999 Entries, with a total of 10 columns. Out of the 10 columns, 2 columns have float64 type values, 6 columns have int64 type values and we have 2 columns with Categorical values.\n\nThe various steps for data Pre-Processing are:\n\na) Treating Missing Values\n\nb) Finding and removing all the duplicated values\n\nc) Checking for Imbalance\n\nd) Checking Skewness of data\n\ne) Identifying Outliers with Interquartile Range (IQR) and Boxplot Visualization\n\nf) Converting the categorical data into numerical data appropriately\n\n   # a) Treating Missing Values (Imputation)","01beb10c":"# 2) Area Under Curve (AUC)","7e2c7472":"# 3) ROC Curve","ea46b193":"<b>Precision<\/b>           - It is the number of True Positive divided by the number of positive results predicted by the classifier.\n\n<b>Recall\/ Sensitivity<\/b> - It is the number of True Positives divided by the number of all relevant samples\n\n<b>F1 Score<\/b>            - F1 Score is the Harmonic Mean between precision and recall.\n\nF1 Score tells how precise the classifier is (how many values it classifies correctly).\n\n<b>The greater the F1 Score, the better is the performance of our model.<\/b>\n\nf1_Scores for all the models are:\n\n1)  Random Forest          : 0.95\n\n2)  Gradient Boosting      : 0.94\n\n3)  XGBoost                : 0.94\n\n4)  Decision Tree          : 0.9\n\n5)  SVM                    : 0.89\n\n6)  AdaBoost               : 0.88\n\n7)  KNN                    : 0.84\n\n8)  Naive-Bayes            : 0.64\n\n9)  Logistic Regression    : 0.59\n\nHere, <b>Random Forest<\/b> has the highest f1_score. Hence, based on the f1_score, Random Forest is the best fit model.","026cb81e":"# Step 9: Finalizing the Best Model\n\nAfter all the comparison using 5 different metrics:\n\nwhen considering the metrics AUC, ROC and Type I error, Gradient Boosting is found to be the best model.\n\nwhen considering the metrics Accuracy and F1 Score, Random Forest is found to be the best model.\n\n# Finally, <u><b>Gradient Boosting<\/b><\/u> algorithm proves to be the best model for the Employee Attrition dataset (People Charm case.csv).\n","84c0a466":"# 3) Naive-Bayes","1c933b28":"# c) Checking for Imbalance","5d779b41":"The dataset does not have any null values. Hence no treatment for missing values required.\nWe can move on to the next step of Data Pre-Processing\u2026","d8b3968d":"# Step 2: Loading the Dataset","30ad782f":"# Step 5: Data Visualization\n# Independent Variables vs Target Variable\n\nThe crosstab() function is used to compute a simple\u00a0cross tabulation of two\u00a0(or more) factors.\nThe pandas\u00a0crosstab\u00a0function builds a cross-tabulation table that can show the frequency with which certain groups of data appear.","6adb2293":"# Step 7: Fitting the dataset to various models\n\n<b>We will fit the dataset to various models and find out the best fit model among these.\n\nVarious models used in this notebook are:\n    \n\n1)  Logistic Regression\n\n2)  KNN                \n\n3)  Naive-Bayes       \n\n4)  SVM                   \n\n5)  Decision Tree         \n\n6)  Gradient Boosting     \n\n7)  Random Forest         \n\n8)  AdaBoost             \n\n9)  XGBoost    \n\n<\/b>           \n\n# 1) Logistic Regression","84c00bd3":"False Positives(Type I Error) occurs when we incorrectly reject a true hypothesis.<b>Lower the value of False Positives, better is the model<\/b>. This is because, while predicting, <b>if we predict that an employee is not going to leave the job, but later he\/she actually leaves the job, then this kind of wrong prediction could further increase Attrition Rate to an alarming range.<\/b>\n\nThe False Positives(Type I Error) for all the models can be accessed from the confusion matrix. The values for various models are:\n\n\n1)  Naive-Bayes            : 88\n\n2)  KNN                    : 57\n\n3)  Decision Tree          : 53\n\n4)  AdaBoost               : 39\n\n5)  SVM                    : 43\n\n6)  Logistic Regression    : 41\n\n7)  XGBoost                : 37\n\n8)  Random Forest          : 30\n\n9)  Gradient Boosting      : 19\n\n<b>Gradient Boosting algorithm has the least number of False Positives(Type I Error). Hence, based on the False Positives(Type I Error), Gradient Boosting is the best fit model.<\/b>","6016720b":"# b) Finding and removing all the duplicated values","a762a7eb":"# 9) XGBoost ","56a37e7e":"# e) Identifying Outliers with Interquartile Range (IQR) and Boxplot Visualization\n\n<b>Outliers are observations that are significantly different from other data points. Outliers can adversely affect the training process of a machine learning algorithm, resulting in very low accuracy.\n\nOutliers in input data can skew and mislead the training process of machine learning algorithms resulting in longer training time, less accurate models and ultimately poorer results.\n\nThe interquartile range (IQR) is a measure of statistical dispersion and is calculated as the difference between the 75th and 25th percentiles. It is represented by the formula IQR = Q3 \u2212 Q1.<\/b>","e44e177d":"# 4) SVM","fb413752":"* An\u00a0attrition rate\u00a0is a metric used to measure employees or customers lost over a period of time who are not replaced.\n* \u201cPeople Charm, a growing company is facing a high attrition rate among their employees \u201d- means the company is losing lots of their employees over the years and they want to reduce this rate by finding strategies that can help them retain their employees which in turn will help them to grow bigger as a company.\n* In order to plan strategies, they have provided a dataset  containing various attributes. \n* We need to find the best fit model which can predict if a certain employee will work in the company for a longer period, or if he\/she is planning to leave the company. \n* Using these predictions, the company can make their plans to avoid attrition.\n* This is a Binary Classification Problem","c9c9b7ef":"# Step 1: Importing Libraries","934a9076":"# 8) AdaBoost (Entropy-Decision Tree)","e94c4871":"# Understanding the problem","f31b6603":"# 1) Accuracy"}}