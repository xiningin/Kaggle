{"cell_type":{"9a357e0c":"code","eccc9588":"code","c9945080":"code","ecd04895":"code","908813d4":"code","22a79b0c":"code","8d036d16":"code","1efed7ba":"code","d0cc06cf":"code","3b938657":"code","188204c9":"code","c1c2901b":"code","f3692315":"code","5be37a39":"code","328473b9":"code","539a1478":"code","c95c542f":"code","97cddd4f":"code","b53e7b62":"code","7f2f4f90":"code","49472ef4":"code","c0440fc4":"code","ec1dd76c":"code","2aa953f3":"code","ccde5aa9":"code","1114d003":"code","65b8b267":"code","bf5645ae":"markdown","143a1bbb":"markdown","5a40f3b1":"markdown","dcb8310c":"markdown","9d56078b":"markdown","f54b1324":"markdown"},"source":{"9a357e0c":"import keras\nimport tensorflow as tf\nfrom keras.layers import Input, Dense\nfrom keras.utils.vis_utils import plot_model\nfrom keras.models import Model\nfrom keras.datasets import fashion_mnist,mnist\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline","eccc9588":"(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()","c9945080":"def show_images(data,number_of_images):\n    n = number_of_images\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        # display original\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(data[i].reshape(28, 28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n    plt.show()\nshow_images(X_train,20)","ecd04895":"X_train = X_train.astype('float32') \/ 255.\nX_test = X_test.astype('float32') \/ 255.","908813d4":"X_train.shape","22a79b0c":"X_train_ = X_train[1].reshape(1, 784)\nX_train_.shape","8d036d16":"X_train = X_train.reshape((len(X_train), 784))\nX_test = X_test.reshape((len(X_test), 784))\nX_train.shape","1efed7ba":"X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\nX_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\nprint (X_train.shape)\nprint (X_test.shape)","d0cc06cf":"X_train = np.reshape(X_train, (len(X_train), 28, 28, 1))  \nX_test = np.reshape(X_test, (len(X_test), 28, 28, 1))  ","3b938657":"X_train.shape","188204c9":"X_test.shape","c1c2901b":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras import backend as K\ninput_img = Input(shape=(28, 28, 1))  \n\nx = Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D(pool_size = (2, 2), padding='same')(x)\nx = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D(pool_size = (2, 2), padding='same')(x) \nx = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D(pool_size = (2, 2), padding='same')(x)","f3692315":"x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nmodel = Model(input_img, decoded)\nmodel.compile(optimizer='adam', loss='binary_crossentropy')","5be37a39":"model.summary()\nplot_model(model, show_shapes=True, show_layer_names=True)","328473b9":"history = model.fit(X_train, X_train,epochs=50,batch_size=128,shuffle=True,validation_data=(X_test, X_test))","539a1478":"plt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.ylabel('Loss')\nplt.xlabel('No. epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","c95c542f":"pred_img = model.predict(X_test)","97cddd4f":"show_images(X_test,10)\nshow_images(pred_img,10)","b53e7b62":"noise_factor = 0.5\nX_train_noise = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \nX_test_noise = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n\nX_train_noise = np.clip(X_train_noise, 0., 1.)\nX_test_noise = np.clip(X_test_noise, 0., 1.)\n","7f2f4f90":"show_images(X_test_noise,10)","49472ef4":"history_ = model.fit(X_train_noise, X_train,epochs=100,batch_size=128,shuffle=True,validation_data=(X_test_noise, X_test))","c0440fc4":"plt.plot(history_.history['loss'], label='Loss')\nplt.plot(history_.history['val_loss'], label='Val Loss')\nplt.ylabel('Loss')\nplt.xlabel('No. epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","ec1dd76c":"decoded_imgs = model.predict(X_test)","2aa953f3":"n = 10 \nplt.figure(figsize=(20, 7))\nplt.gray()\nfor i in range(n):  \n  bx = plt.subplot(3, n, i + 1) \n  plt.title(\"Noise Images\") \n  plt.imshow(tf.squeeze(X_test_noise[i])) \n  bx.get_xaxis().set_visible(False) \n  bx.get_yaxis().set_visible(False) \n  \n  cx = plt.subplot(3, n, i + n + 1) \n  plt.title(\"reconstructed\") \n  plt.imshow(tf.squeeze(decoded_imgs[i])) \n  bx.get_xaxis().set_visible(False) \n  bx.get_yaxis().set_visible(False) \n  \n  ax = plt.subplot(3, n, i + 2*n + 1) \n  plt.title(\"original\") \n  plt.imshow(tf.squeeze(X_test[i])) \n  ax.get_xaxis().set_visible(False) \n  ax.get_yaxis().set_visible(False) \n\nplt.show()","ccde5aa9":"random_img = np.random.choice(10)","1114d003":"psnr1 = tf.image.psnr(X_test[random_img],decoded_imgs[random_img], max_val=255)","65b8b267":"plt.figure(1)\nplt.subplot(211)\nplt.imshow(X_test[random_img])\n\nplt.subplot(212)\nplt.imshow(decoded_imgs[random_img])\nplt.show()\nprint('PSNR Value' ,psnr1.numpy())","bf5645ae":"### Generating Results- Reconstruted Images,Noisy Images,Original Images","143a1bbb":"## Dataset Used-\n* <b> Fashion MNIST <\/b>\n\n## CNN Architecuture used -\n\n* <b> Autoencoder <\/b>\n>Autoencoder is a type of neural network that can be used to learn a compressed representation of raw data.\nAn autoencoder is composed of an encoder and a decoder sub-models. The encoder compresses the input and the decoder attempts to recreate the input from the compressed version provided by the encoder. After training, the encoder model is saved and the decoder is discarded.The encoder can then be used as a data preparation technique to perform feature extraction on raw data that can be used to train a different machine learning model.","5a40f3b1":"## Inducting Noise to Train and Test Data","dcb8310c":"### The Decoder","9d56078b":"## Calculating PSNR Values for Random Image","f54b1324":"## Autoencoders CNN Architecture\n### The Encoder"}}