{"cell_type":{"fdd666a3":"code","fb10fb10":"code","4a9b39dd":"code","e4e64368":"code","48911463":"code","af8d1364":"code","f4269652":"code","761d465a":"code","27bb663e":"code","02be1cb6":"code","4070d59a":"code","97cba4a6":"code","a800519b":"code","27264b3b":"code","bb1f2b4f":"code","f48f1c51":"code","63744325":"code","fb87d70b":"markdown","e5199234":"markdown","a2205d86":"markdown","a60a5e5c":"markdown","c046b37e":"markdown","9eb910a4":"markdown","c9422af3":"markdown","9b6c7b22":"markdown","a931323f":"markdown","4ef33dce":"markdown","37f3a841":"markdown"},"source":{"fdd666a3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fb10fb10":"import pandas as pd\nimport numpy as np\n%matplotlib inline","4a9b39dd":"df = pd.read_csv(r'\/kaggle\/input\/iris.txt')\ndf.head()\n\ndf = df.iloc[:,:-1]\ndf.dtypes","e4e64368":"from sklearn.preprocessing import MinMaxScaler\nfeature_scaler = MinMaxScaler(feature_range=(0, 1))\ndf_scaled = feature_scaler.fit_transform(df)\ndf_scaled = pd.DataFrame(data=df_scaled)\ndf_scaled.head()","48911463":"som_width = 8\nsom_length = 8\nepochs = 10000\ninitial_learning_rate=0.01\nnp.random.seed(10)","af8d1364":"raws,cols = df_scaled.shape\nprint(\"Data set raw count=%d column count=%d\" %(raws, cols))","f4269652":"initial_radius = max(som_width, som_length)\/2\ntime_constant =  epochs\/np.log(initial_radius)","761d465a":"som_net = np.random.random((som_width, som_length, cols))\nprint(\"Initial weights set to SOM network:\")\nprint(som_net)","27bb663e":"def update_radius(initial_radius, i, time_constant):\n    return initial_radius * np.exp(-i \/ time_constant)\n\ndef update_learning_rate(initial_learning_rate, i, n_iterations):\n    return initial_learning_rate * np.exp(-i \/ n_iterations)\n\ndef calculate_euclidian_dis(point1, point2):\n    return np.sqrt(np.sum((point1 - point2) ** 2))","02be1cb6":"def find_best_matching_Unit(data_point):\n    bmu_pos = np.array([0, 0])\n    min_dist = np.iinfo(np.int).max\n    input_dim = len(data_point)\n    \n    for x in range(som_width):\n        for y in range(som_length):\n            som_weight_vector = som_net[x, y, :].reshape(1, 4)\n            euclidian_dist = calculate_euclidian_dis(som_weight_vector, data_point)\n            if euclidian_dist < min_dist:\n                min_dist = euclidian_dist\n                bmu_pos = np.array([x, y])\n    \n    bmu = som_net[bmu_pos[0], bmu_pos[1], :].reshape(1, 4)\n    return (bmu, bmu_pos)","4070d59a":"def neighbourhood_function(bmu_location, selected_node_location, radius):\n    euclidien_dist_to_bmu = calculate_euclidian_dis(bmu_location, selected_node_location)\n    return np.exp(-euclidien_dist_to_bmu \/ (2* (radius**2)))","97cba4a6":"#shuffle data set\ndf_scaled = df_scaled.sample(frac=1)\n\nrad_values = list()\nlearn_rates_values = list()\nrad_values.append(initial_radius)\nlearn_rates_values.append(initial_learning_rate)\n\nfor i in range(epochs):\n    data_point = np.array(df_scaled.sample())\n    bmu, bmu_idx = find_best_matching_Unit(data_point)\n\n    r_new = update_radius(initial_radius, i, time_constant)\n    new_learning_rate = update_learning_rate(initial_learning_rate, i, epochs)\n    \n    rad_values.append(r_new)\n    learn_rates_values.append(new_learning_rate)\n    \n    for x in range(som_width):\n        for y in range(som_length):\n            w = som_net[x, y, :].reshape(1, 4)\n            w_dist = calculate_euclidian_dis(np.array([x, y]), bmu_idx)\n            \n            if w_dist <= r_new:\n                influence = neighbourhood_function(bmu, w, r_new)\n                new_w = w + (new_learning_rate * influence * (data_point - w))\n                som_net[x, y, :] = new_w.reshape(1, 4)          ","a800519b":"from matplotlib import pyplot as plt\nplt.plot(rad_values)\nplt.title('Radius values')","27264b3b":"plt.plot(learn_rates_values)\nplt.title('Learning Rates values')","bb1f2b4f":"from matplotlib import patches as patches\n\nfig = plt.figure(figsize=(7,7))\nax = fig.add_subplot(1,1,1, aspect='equal')\nax.set_xlim((0, som_width+1))\nax.set_ylim((0, som_length+1))\nax.set_title('Self-Organising Map after %d iterations' % epochs)\n\nfor x in range(1, som_width + 1):\n    for y in range(1, som_length + 1):\n        ax.add_patch(patches.Circle((x, y), 0.5, facecolor=som_net[x-1,y-1,:], edgecolor='black'))\nplt.show()\n\nfig.savefig('SOM_iris_data.png')","f48f1c51":"u_matrix = np.zeros((som_width-1, som_length-1))\n\nfor x in range(1, som_width):\n    for y in range(1, som_length):\n        neighbour_list = list()\n        print(\"-\"* 100)\n        print(\"neighbour cordinates of x=%d, y=%d\" %(x,y))\n        for u in range(x-1, x+2):\n            if (u < 0 or u > (som_width-1)):\n                continue\n            for v in range(y-1, y+2):\n                if(v < 0 or v > (som_length-1)):\n                    continue\n                if (u == x and v == y):\n                    continue\n                neighbour_list.append(np.array([u,v]))\n                print(u,v)\n        sum=0\n        for idx in neighbour_list:\n            sum += calculate_euclidian_dis(som_net[x,y,:], som_net[idx[0],idx[1],:])\n        \n        avg = sum\/len(neighbour_list)\n        print(\"Sum of distance to neighbour weights=%f, average=%f\" % (sum, avg))     \n        u_matrix[x-1,y-1] = avg","63744325":"fig = plt.figure(figsize=(7,7))\nplt.title(\"U Matrix visualization of Iris data using SOM\")\nplt.imshow(u_matrix, cmap=\"gray\")\nplt.show()\nfig.savefig('U_Matrix_iris.png')","fb87d70b":"**In above grayscale image, light colors depict closely spaced node codebook vectors and darker colors indicate more widely separated node codebook vectors. Therefore groups of light colors can be considered as clusters, and the dark parts as the boundaries between the clusters.**","e5199234":"### Logic to calculcate best matching unit","a2205d86":"### Train SOM network with Iris data set","a60a5e5c":"### Neighbourhood function to calculate influence from best matching unit and selected node","c046b37e":"## Define parameters for SOM network","9eb910a4":"### Reading the data file","c9422af3":"### U Matrix Calculation from above SOM","9b6c7b22":"### Define basic functions needed to decay learning rate, radius and calculate Euclidian distance","a931323f":"### From above graph, a clear clustering of data can be seen such that same colors in the neighbourhood in a cluster and different cluseters with different colors","4ef33dce":"### Visualize the weights of the SOM after number of epoch times","37f3a841":"### Min max Scaling the data set to vary between [0,1]"}}