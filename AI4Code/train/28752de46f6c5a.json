{"cell_type":{"1a6b3c27":"code","20b675f6":"code","0492d6dd":"code","3601283b":"code","e524d79a":"code","f5a039e7":"code","4cee4752":"code","5d685b00":"code","be45525c":"code","f9cecd70":"code","ce378d72":"code","e8354a17":"code","dea80b8b":"code","2347a5fa":"code","efeb403e":"code","3c7c0557":"code","0e8e29fa":"code","5a38ad4d":"markdown","fe2878e7":"markdown","98b81321":"markdown","cd4adb83":"markdown","859270fc":"markdown","8b653b7f":"markdown","1d00ba3c":"markdown","29939b27":"markdown","f4f20d9f":"markdown","75f8c41d":"markdown","7adaed73":"markdown","5ba15b63":"markdown","31e1438e":"markdown","75c61924":"markdown","57ae72bd":"markdown","2a191eb7":"markdown","b0f70e58":"markdown","d8dd1369":"markdown","f92dfdd4":"markdown"},"source":{"1a6b3c27":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20b675f6":"data=pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\ndata.head()","0492d6dd":"data=data.drop(['CLIENTNUM'],axis=1)\ndata = data.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'], axis=1)\ndata = data.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1)\ndata.head()","3601283b":"import matplotlib.pyplot as plt\ncount=pd.value_counts(data['Attrition_Flag']).tolist()\nplt.figure(figsize=(11,11))\nplt.title(\"Percentage of Attrited Customer and Existing Customer\")\nplt.pie(x=count,labels=[\"Attrited Customer\",\"Existing Customers\"],autopct='%.2f%%')\n","e524d79a":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,15))\n\nattrited_gender = data.loc[data[\"Attrition_Flag\"] == \"Attrited Customer\", [\"Gender\"]].value_counts().tolist()\nax1.pie(x=attrited_gender,labels=[\"Male\",\"Female\"],autopct='%.2f%%')\nax1.set_title('Gender vs Attrited Customer')\n\nexisting_gender=data.loc[data[\"Attrition_Flag\"] == \"Existing Customer\", [\"Gender\"]].value_counts().tolist()\nax2.pie(x=existing_gender,labels=[\"Male\",\"Female\"],autopct='%.2f%%')\nax2.set_title('Gender vs Existing Customer')","f5a039e7":"import seaborn as sns\nplt.figure(figsize=(28,11))\nplt.title(\"Distribution of Age with respect to Churned or not\")\nsns.countplot(data=data,x=data[\"Customer_Age\"],hue=\"Attrition_Flag\")","4cee4752":"fig, axes = plt.subplots(2, 2, figsize=(15, 15), sharey=True)\nfig.suptitle('Group by Attrition Flag')\nsns.countplot(x=\"Gender\", hue = \"Attrition_Flag\",  data=data, ax=axes[0,0], palette=\"Set2\")\naxes[0,0].set_title(\"GENDER & ATTRITION FLAG\")\n\nsns.countplot(x=\"Income_Category\", hue = \"Attrition_Flag\",  data=data, ax=axes[0,1], palette=\"Set2\",order=data[\"Income_Category\"].value_counts().index)\naxes[0,1].set_title(\"INCOME CATEGORY & ATTRITION FLAG\")\n\nsns.countplot(x=\"Education_Level\", hue = \"Attrition_Flag\",  data=data, ax=axes[1,0], palette=\"Set1\",order=data[\"Education_Level\"].value_counts().index)\naxes[1,0].set_title(\"EDUCATION LEVEL & ATTRITION FLAG\")\n\nsns.countplot(x=\"Card_Category\", hue = \"Attrition_Flag\",  data=data, ax=axes[1,1], palette=\"Set1\",order=data[\"Card_Category\"].value_counts().index)\naxes[1,1].set_title(\"CARD CATEGORY & ATTRITION FLAG\")","5d685b00":"fig,ax=plt.subplots(figsize=(10,10))\nsns.heatmap(data.corr(),annot=True)","be45525c":"data.isnull().any()","f9cecd70":"import seaborn as sns\nsns.boxplot(x=data['Total_Ct_Chng_Q4_Q1'])","ce378d72":"#outlier cleanup\nfrom scipy import stats\nimport numpy as np\ncolumns = [\"Customer_Age\", 'Dependent_count', 'Months_on_book',\n       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']\nprint(data.shape)\nfor column in columns : \n    z = np.abs(stats.zscore(data[column]))\n    data=data[(z < 3)]\nprint(data.shape)\n    \n    ","e8354a17":"#boxplot after removing outlier\nimport seaborn as sns\nsns.boxplot(x=data['Total_Ct_Chng_Q4_Q1'],palette=[sns.xkcd_rgb[\"pale red\"]])\n","dea80b8b":"X=data.drop(\"Attrition_Flag\",axis=1)\nY=data[\"Attrition_Flag\"]\nY.shape","2347a5fa":"from sklearn.preprocessing import LabelEncoder\ncategorical_col =['Gender','Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\nfor cols in categorical_col :\n    le=LabelEncoder()\n    X[cols]=le.fit_transform(X[cols])\nY=le.fit_transform(Y)\ndata.info()","efeb403e":"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)","3c7c0557":"from sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, make_scorer, recall_score\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC, SVC\n\nclassifiers = [[XGBClassifier(),'XGB Classifier'], [RandomForestClassifier(),'Random Forest'], \n    [KNeighborsClassifier(), 'K-Nearest Neighbours'], [SGDClassifier(),'SGD Classifier'], [SVC(),'SVC']]\nscore_list=[]\nroc_auc_list=[]\ncross_val_list=[]\n\nfor classifier in classifiers :\n    model=classifier[0]\n    model.fit(X_train,Y_train)\n    model_name=classifier[1]\n    prediction=model.predict(X_test)\n    \n    scores=model.score(X_test,Y_test)\n    cross_val=cross_val_score(model,X_test,Y_test).mean()\n    roc_auc = roc_auc_score(Y_test, prediction)\n    \n    score_list.append(scores)\n    cross_val_list.append(cross_val)\n    roc_auc_list.append(roc_auc)\n    \n    print(model_name,\"Score :\"+str(round(scores*100,2))+'%')\n    print(model_name,\"Cross Validation Score :\"+str(round(cross_val*100,2))+'%')\n    print(model_name,\"ROC AUC score:\"+str(round(roc_auc*100,2))+'%')","0e8e29fa":"from sklearn.metrics import plot_confusion_matrix\n\nmodel = XGBClassifier()\nmodel.fit(X_train, Y_train)\npred = model.predict(X_test)\nplot_confusion_matrix(model, X_test, Y_test)","5a38ad4d":"I hope this notebook was useful for Kaggle learners. I appreciate every feedback and if you think my code can be improved better please suggest me so in the comment. ","fe2878e7":"After removing outliers the size of the data frame is **(9317,20)** ie reduced from (10127,20) of the original data.","98b81321":"First,let's look at the top 5 rows of the data.","cd4adb83":"It turns out that the **ratio is highly imbalanced**.Attrited customers account to much higher percentage of the total data. \n\nLet's check with respect to the **genders- male and female** .","859270fc":"The distribution of age is clearly a **Gaussian distribution** meaning that most of the data are clustered around the mean value. \n","8b653b7f":"# Correlation using heatmap \n\nIn a visually appealing way,correlation heatmaps show which variables are correlated, to what degree and in which direction. ","1d00ba3c":"We notice we do not require the column that has client id (CLIENTNUM)in our analysis and prediction so let's drop it.The last two columns are also unnecessary so dropping it.","29939b27":"From the heatmap,it can be seen that the columns **'Avg_Open_To_Buy' and 'Credit_Limit','Total_Revolving_Bal' and 'Avg_Utilization_Ratio', 'Months_on_book' and 'Customer_Age**'are highly correlated**(value of 1)**.","f4f20d9f":"# Prediction Part \n\nWe split the data into train and test data.The predictive models are then applied and checked which one has the best model score. Consequently,we choose the model with the best score. The **model score**,the **cross validation score** and the **ROC-AUC** scores are calculated.","75f8c41d":"# Predict whether a customer will churn or not :\nCustomer churning or attrition in banking is when the customer no longer using the bank's credit cards. In this notebook the tasks covered are:\n\n1. Data Visualisation of features\n2. Data Cleaning and Preprocessing\n3. Applying models(KNN,Random Forest,SVC,RandomForest etc) and choosing the model with best model score\n","7adaed73":"Since the target column for prediction is \"Attrition_Flag\" we can drop that from the dataframe and seperate it. ","5ba15b63":"It can be seen from the plot that the values above 3 are much farther than the mean and we consider them as outliers. ","31e1438e":"# Removing Outlier\n\nUsing the **concept of z-score** it is possible to check for outliers in the columns. We set a particular threshold(3 in this case) and then remove those values which have a z-score less than 3.","75c61924":"In both the cases,the male to female ratio is **almost same and comparable.** ","57ae72bd":"# Data Preprocessing \n\nSince we require **numerical values** for the predictive model ,the categorical columns need to be transformed. Hence **label encoding** is done.","2a191eb7":"# Data Visualisation\n \nSince our target column is 'Attrition_Flag',we will firstly see the percentage of Existing and attrited Customer.","b0f70e58":"# Checking for Outliers and removing them\n\nUsing a **boxplot** it is easy to visualize whether there are any outliers in the data or not.The outliers for the column\"Total_Ct_Chng_Q4_Q1\" can seen for example. \n","d8dd1369":"We check if there are any null values in the dataframe.","f92dfdd4":"# Best Score :\n\nFrom the above output,it can be seen that **XGBoost** performs the best with a model score of **97.48%**. The **Random Forest classifier** also performs comparably well with a score of **96.41**. \n\nSo we use XGBoost and plot the confusion matrix for this model's prediction."}}