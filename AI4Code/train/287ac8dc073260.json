{"cell_type":{"365cb100":"code","9a5a48bb":"code","48ad0ca4":"code","780eb6ce":"code","38673801":"code","c56b3657":"code","28838085":"code","dd62f7e5":"code","432f2155":"code","9c2809b5":"code","19e88514":"code","c8e21447":"code","14ccc848":"code","75e74971":"code","6b3196de":"code","caa2a961":"code","9d385fc6":"code","b0f4599c":"code","ff913e1a":"code","338d13e0":"code","449f9d8f":"code","3a67cf04":"code","619d257d":"code","f672b8e2":"markdown","03ce9e34":"markdown","4dd59936":"markdown","096e7290":"markdown","4b90b1f5":"markdown","230272e5":"markdown","486c22ad":"markdown","fa449bb3":"markdown","0783aaf6":"markdown","ca6b24ec":"markdown"},"source":{"365cb100":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a5a48bb":"audi_cars_file_path = '\/kaggle\/input\/audi-used-car-listings\/audi.csv'\naudi_data = pd.read_csv(audi_cars_file_path) \naudi_data.head()","48ad0ca4":"# print a summary of the numerical Audi used car data\naudi_data.describe()","780eb6ce":"categorical_columns = ['model', 'transmission', 'fuelType']\naudi_data[categorical_columns].describe()","38673801":"# see what the distinct values are for each of the categorical columns\naudi_data['model'].unique()","c56b3657":"audi_data['transmission'].unique()","28838085":"audi_data['fuelType'].unique()","dd62f7e5":"numeric_columns = ['year', 'price', 'mileage', 'tax', 'mpg', 'engineSize']\naudi_num_data = audi_data[numeric_columns]\naudi_num_data.head()","432f2155":"corr = audi_num_data.corr()\ncorr","9c2809b5":"# Set the width and height of the figure\nplt.figure(figsize=(10, 8))\n\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)","19e88514":"model_price = audi_data.groupby('model')['price'].mean().sort_values()\n\nplt.figure(figsize=(14, 8))\nplt.title(\"Audi Average Price for each Model\")\npal = sns.color_palette(\"Greens_d\", len(model_price))\n\nsns.barplot(x=model_price.index, y=model_price.values, palette=pal)\n\nplt.xlabel(\"Model\")\nplt.ylabel(\"Price (Euros)\")\nplt.tight_layout()","c8e21447":"year_price = audi_data.groupby('year')['price'].mean().sort_values()\n\nplt.figure(figsize=(14, 8))\nplt.title(\"Audi Average Price by Year\")\npal = sns.color_palette(\"Greens_d\", len(year_price))\n\nsns.barplot(x=year_price.index, y=year_price.values, palette=pal)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Price (Euros)\")\nplt.tight_layout()","14ccc848":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=audi_num_data['year'], y=audi_num_data['price'])","75e74971":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=audi_num_data['engineSize'], y=audi_num_data['price'])","6b3196de":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=audi_num_data['mileage'], y=audi_num_data['price'])","caa2a961":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=audi_num_data['mpg'], y=audi_num_data['price'])","9d385fc6":"plt.figure(figsize=(14,4))\naudi_data.groupby('fuelType')['mpg'].mean().plot.barh()","b0f4599c":"engine_0 = audi_data[audi_data['engineSize'] == 0.0]\nengine_0","ff913e1a":"plt.figure(figsize=(14,4))\naudi_data.groupby('transmission')['mpg'].mean().plot.barh()","338d13e0":"from sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Apply ordinal encoder to the model category feature\nordinal_encoder = OrdinalEncoder()\naudi_data['model'] = ordinal_encoder.fit_transform(audi_data[['model']])","449f9d8f":"# Apply one-hot encoder to transmission and fuelType features\nOH_encoder = OneHotEncoder(sparse=False)\noh_cols = pd.DataFrame(OH_encoder.fit_transform(audi_data[['transmission', 'fuelType']]))\noh_cols.columns = ['trans_0', 'trans_1', 'trans_2', 'fuel_0', 'fuel_1', 'fuel_2']\n\n# drop the original columns and add the encoded ones\naudi_data = audi_data.drop(['transmission', 'fuelType'], axis=1)\naudi_data = pd.concat([audi_data, oh_cols], axis=1)\naudi_data","3a67cf04":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Select the target variable and predictors\ny = audi_data['price']\nX = audi_data.drop(['price'], axis=1)\n\n# Divide data into training and validation subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n\nmodel = RandomForestRegressor(n_estimators=10, random_state=0)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_valid)\nmae = mean_absolute_error(y_valid, preds)\nmae","619d257d":"plt.figure(figsize=(14,8))\nplot = sns.scatterplot(x=y_valid, y=preds).set(title='Price vs. Prediction', \n                                               xlabel=\"Price\", \n                                               ylabel=\"Predicted Price\")","f672b8e2":"### Initial data exploration","03ce9e34":"Maybe those mpg data points aren't outliers after all. It looks like all Audis get very good mpg, but the Hybrid models are particularly good. Now let's take a closer look at the cars whose engine size is 0.","4dd59936":"The year and engine size both look positively correlated with price, while the mileage and mpg are both fairly negatively correlated to price. This makes sense, but let's look at a few plots with these features and price, starting with model and year.","096e7290":"Those plots all aggree with the correlations to price we saw. There are a few price outliers, and at least one extreme mileage outlier. There appear to be several mpg outliers, and I'm not sure what engine size 0 means, so let's take a closer look at the data for those features. We'll start by looking at the average mpg for each fuel type (a categorical variable, so we'll go back to the original data set).","4b90b1f5":"There are many different models, years, and fuel types in this subset. There's also no fully electric model, so it looks like 0.0 was the fill value for missing values in the engine size column. That's a potential source of error in a machine learning model, but we'll leave it alone for now. One last thing I want to look at is the mpg for different types of transmissions.","230272e5":"For an initial model, a mean absolute error of 1,618 Euros is not bad considering the average price is nearly 23,000 Euros. I can see from the plot of the actual prices vs. the predictions that a few very high-priced data points are off by quite a bit, which is going to throw off the average error. Other than that, the prices vs. predictions scatterplot forms a fairly straight line, although it does have a little bit of spread.\n\nThere's a lot of room for improvement, but I'll leave it there for this notebook.","486c22ad":"### Training a simple Random Forest model\nFinally, let's train a simple model to see how good this data set is for predicting the price of a used Audi.","fa449bb3":"It looks like there are no missing values in this data set. If we want to build a model using categorical features, we'll have to encode them. The `transmission` and `fuelType` features only have a few unique values, so we can use one-hot encoding. The `model` has 26 unique values though. It will probably have a lot of predictive value though, so we'll want to keep it. For that feature we'll use ordinal encoding. Before we start building models, let's see how some of the features correlate to each other, and to the price (the ultimate target variable).","0783aaf6":"There's a lot less variation in mpg here than by fuel type, but I did expect manual transmission cars to get better mpg than the other two groups. That checks out. Now let's move on to encoding the categorical features before training a simple model.\n\n### Encoding categorical features","ca6b24ec":"### Audi Used Car Analysis\n\nAnalyze and predict prices for used Audi automobiles.\n\nAlso see my related notebooks:\n- [BMW Used Car Analysis](https:\/\/www.kaggle.com\/bcruise\/bmw-used-car-analysis)\n- [Mercedes Used Car Analysis](https:\/\/www.kaggle.com\/bcruise\/mercedes-used-car-analysis)\n- [Hyundai Used Car Analysis](https:\/\/www.kaggle.com\/bcruise\/hyundai-used-car-analysis)"}}