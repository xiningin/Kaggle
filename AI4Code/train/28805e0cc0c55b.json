{"cell_type":{"c78eb894":"code","c85d371f":"code","66710b06":"code","7cdfdff9":"code","6dfde82e":"code","dc1d6611":"code","41c80f77":"code","33f472e4":"code","b0a94b05":"code","499baab2":"code","fdd0f73b":"code","f98dce5c":"markdown","1f7a5f70":"markdown","a321718f":"markdown","65544319":"markdown","f9c2f4ef":"markdown","d7b29949":"markdown","d5670889":"markdown","dcb762ec":"markdown","d0aba264":"markdown","28dbb3c8":"markdown","8370d1cd":"markdown","7ab0f533":"markdown","897cebbf":"markdown","82361c50":"markdown","1b3758cf":"markdown","d26ee2df":"markdown","2ebb3f8a":"markdown","1674830a":"markdown","bb770fdd":"markdown","a085cde8":"markdown","263fbb2a":"markdown","5fe6fb59":"markdown","5c0151ed":"markdown","2c574f6d":"markdown"},"source":{"c78eb894":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\nfrom PIL import Image\nfrom keras.preprocessing import image","c85d371f":"from keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))\n\n","66710b06":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1\/255,validation_split=0.1, zoom_range=(0.5,1.5), rotation_range=60, brightness_range=(0.5,1.5))\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/sarscov2-ctscan-dataset\/',  \n        target_size=(256, 256),  \n        batch_size=128,\n        class_mode='binary',\n        subset='training')\n    \nvalidation_generator  = train_datagen.flow_from_directory(\n        '..\/input\/sarscov2-ctscan-dataset\/',  \n        target_size=(256, 256),  \n        batch_size=128,\n        class_mode='binary',\n        subset='validation')\n","7cdfdff9":"validation_generator.batch_size = 247\nX,y = validation_generator.next()\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)","6dfde82e":"noncovid_datas_train = train_generator.labels.sum()\ncovid_datas_train = train_generator.labels.size-noncovid_datas_train\nnoncovid_datas_valid = y_train.sum()\ncovid_datas_valid = y_train.size - y_train.sum()\nnoncovid_datas_test = y_test.sum()\ncovid_datas_test = y_test.size - y_test.sum()\n\nx = ['NTrain', 'CTrain', 'NV', 'CV', 'NTest', 'Ctest']\nsizes = [noncovid_datas_train, covid_datas_train, noncovid_datas_valid, covid_datas_valid, noncovid_datas_test, covid_datas_test]\nx_pos = [i for i, _ in enumerate(x)]\nplt.bar(x_pos, sizes, color=('green', \"red\"))\nplt.xlabel(\"Dataset\")\nplt.ylabel(\"Total number of datas that we have in the dataset\")\nplt.title(\"Values of Covid and Noncovid datas in the datasets\")\nplt.xticks(x_pos, x)\nplt.show()\n","dc1d6611":"for i in range (1,9):\n    a=np.random.randint(0,120)\n    plt.imshow(X_test[a])\n    plt.axis('Off')\n    plt.show()\n    if y_test[a] ==1:\n        print(\"Noncovid\")\n    else:\n        print(\"Covid\")","41c80f77":"import tensorflow as tf\ninception=tf.keras.applications.inception_v3.InceptionV3(include_top=False,input_shape=(256,256,3),weights='imagenet')\n#pretrain_model_path = '\/content\/drive\/My Drive\/v3.h5'\nlayer=inception.get_layer('mixed7')\n#x.load_weights(pretrain_model_path)\nx=tf.keras.layers.Flatten()(layer.output)\nx=tf.keras.layers.Dense(units=1024,activation='relu')(x)\nx=tf.keras.layers.Dense(units=512,activation='relu')(x)\nx=tf.keras.layers.Dense(1)(x)\nout=tf.keras.layers.Activation(activation='sigmoid')(x)\n\nmodel=tf.keras.Model(inputs=inception.input,outputs=out)\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),loss='binary_crossentropy',metrics=['acc',f1_m,precision_m, recall_m])\n\nperformance_scheduler = keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 2)\n\nmodel.summary()","33f472e4":"train_generator.batch_size = 32\nhistory = model.fit(train_generator, epochs = 8,validation_data=(X_train, y_train))","b0a94b05":"model.evaluate(X_test, y_test)","499baab2":"predictions = model.predict(X_test)\nprdcs = []\nfor i in predictions:\n    if i>=0.5:\n        prdcs.append(1)\n    else:\n        prdcs.append(0)","fdd0f73b":"for i in range(0,20):    \n    plt.imshow(X_test[i])\n    plt.show()\n    print(\"prediction: \", prdcs[i])\n    print(\"covid status: \", y_test[i])\n","f98dce5c":"*Like as I mentioned above, I am splitting the validation and test sets fifty fifty.*","1f7a5f70":"# *Veri setlerini olu\u015fturmak*\n*Tensorflow k\u00fct\u00fcphanesinin bize sa\u011flad\u0131\u011f\u0131 ImageDataGenerator'u kullanarak verilerimi \"Covid\" ve \"Normal\" \u015feklinde etiketlenmi\u015f bir bi\u00e7imde 256 piksele 256 piksel olarak al\u0131yorum, daha sonra verilerime rastgele bir \u015fekilde yak\u0131nla\u015ft\u0131rma, ayd\u0131nlatma, d\u00f6nd\u00fcrme uyguluyorum. Bunu yapma sebebim program\u0131n farkl\u0131 veri \u015fekillerini \u00f6\u011frenmesini sa\u011flamak. daha sonra bu verilerin y\u00fczde 90'\u0131n\u0131 e\u011fitim veri setime kaydediyorum. Kalan k\u0131sm\u0131n\u0131 ise \u015fimdilik \"Validation\" veri setine koyuyorum ama ilerleyen kod bloklar\u0131nda onu da \"test\" ve \"validation\" olarak tekrar ay\u0131raca\u011f\u0131m.*","a321718f":"*I am adding the libraries we need.*","65544319":"*Elimizdeki verilerin nas\u0131l da\u011f\u0131ld\u0131\u011f\u0131na bakal\u0131m \u015fimdi de. A\u015fa\u011f\u0131da \"train\", \"validation\" ve \"test\" veri setlerimiz i\u00e7in covid ve noncovid veri say\u0131lar\u0131m\u0131z\u0131 g\u00f6rebilece\u011fimiz bir grafik \u00e7iziyorum.*\nNot:\n* C Covid,\n* N Normal,\n* V ise Validation anlam\u0131na gelmektedir.","f9c2f4ef":"*\u015eimdi de \"test\" setindeki g\u00f6rseller, onlar\u0131n ger\u00e7ek etiketleri ve modelimizin tahmin etti\u011fi de\u011ferleri kar\u015f\u0131la\u015ft\u0131ral\u0131m.*","d7b29949":"# *Fitting and testing*\n*It's time for fitting, I am setting the batch size to 32 and epochs to 8. These are the most optimal numbers according to my tests.*","d5670889":"*I showed some of the datas we have with the covid statuses of them below. If we examine the covid ones carefully we can determine peripheral subpleural ground glass opacities which is the most common symptom of COVID-19 pneumonia. It is easy to detemine this areas due to the their light color tones compared to their surroundings.*","dcb762ec":"*Yukar\u0131da bahsetti\u011fim gibi \"validation\" veri setini yar\u0131 yar\u0131ya \"test\" ve \"validation\" olarak ay\u0131r\u0131yorum.*","d0aba264":"*As you can see there is a confusion matrix above. I want to take attention to a question. We can identify how much of the actually covid datas predicted as covid. This is a very important question we should pay attention to. Because we don't want to diagnose a covid positive person as covid negative. Recall metric is answering this question. You can see the values of the recall metric and other usefull metrices above. A value of 1 equals to hundred percent.*","28dbb3c8":"*E\u011fitim bitti \u015fimdi modelimizi \"test\" seti \u00fczerinde test edelim, bakal\u0131m do\u011fruluk oran\u0131 ka\u00e7?*","8370d1cd":"# *Creating datasets*\n*With the help of Tensorflow's ImageDataGenerator I am creating train and validation sets, getting all the images(labeled) 256 pixels by 256 pixels and using some augmantation techiques(zoom, rotation and brightness) to the images randomly. With all of these our model will learn how to deal with different kinds of data forms. Lastly validation set contains ten percent of all the datas we have. I will split this validation set to test and validation set later.*","7ab0f533":"# *Creating the model*\n*Time for creating the model. I decided to use the Transfer learning model InceptionV3. But before the last layer, I added 2 more layers one with 1024 nourons and other with 512 nourons.*","897cebbf":"*Now lets compare our data's in the test dataset, their labels and models predictions for them.*","82361c50":"*I am adding functions of some metricies for future use.*","1b3758cf":"*Elimizdeki verilerin baz\u0131lar\u0131n\u0131 a\u015fa\u011f\u0131da covid durumlar\u0131yla birlikte g\u00f6sterdim. Bu g\u00f6r\u00fcnt\u00fclerden covid olanlar\u0131 inceledi\u011fimizde COVID-19 pn\u00f6monisinde en yayg\u0131n bulgu olarak kar\u015f\u0131m\u0131za \u00e7\u0131kan periferal subplevral buzlu cam dansitelerinin varl\u0131\u011f\u0131n\u0131 saptayabiliriz. Bu kondisyonu g\u00f6steren alanlar etraf\u0131na g\u00f6re daha a\u00e7\u0131k bir renk tonunda oldu\u011fundan saptamak olduk\u00e7a kolayd\u0131r.*","d26ee2df":"![](https:\/\/static.packt-cdn.com\/products\/9781838555078\/graphics\/C13314_06_05.jpg)\n\n*Yukar\u0131da g\u00f6rebildi\u011finiz tablo bizim tahmin etti\u011fimiz de\u011ferlerin ve ger\u00e7ek de\u011ferlerin sonu\u00e7lar\u0131n\u0131 g\u00f6steren \u00f6rnek bir tablodur. De\u011finmek istedi\u011fim k\u0131s\u0131m ger\u00e7ekten hasta olan ki\u015filerin ne kadar\u0131na hasta diyebiliyoruz? Kesinlikle hasta olan birine hasta de\u011fil demek istemeyiz ve bu sorumuzun yan\u0131t\u0131n\u0131 yaz\u0131n\u0131n ba\u015f\u0131nda ekledi\u011fim metriklerden \"recall\" adl\u0131 metrik bizim i\u00e7in hesapl\u0131yor. Bu metri\u011fin test setinde ald\u0131\u011f\u0131 de\u011feri yukar\u0131da \"recall_m\" yazan k\u0131s\u0131m\u0131n yan\u0131ndan g\u00f6rebilirsiniz. Metri\u011fin 1 olmas\u0131 y\u00fczde y\u00fcz anlam\u0131na gelmektedir.*","2ebb3f8a":"# *Modeli e\u011fitmek ve test etmek*\n*Modelimizi e\u011fitme zaman\u0131, 32'\u015fer veriden olu\u015fan setler halinde e\u011fitim veri setini toplam 8 kere y\u00fcr\u00fctecek bir \u015fekilde ayarl\u0131yorum modelimi. Bu de\u011ferler yapt\u0131\u011f\u0131m testler sonucunda buldu\u011fum en optimal de\u011ferler.*","1674830a":"*K\u00fct\u00fcphanelerimizi ekleyelim.*","bb770fdd":"*\u0130leride kullanmak i\u00e7in baz\u0131 metriklerin fonksiyonlar\u0131n\u0131 ekliyorum.*","a085cde8":"*Fitting is done, Let's evaluate the model with the test set.*","263fbb2a":"*Let's see how many covid and noncovid datas we have in our datasets. We can see that in the chart below.*\nNote:\n* C is for Covid,\n* N is for Normal,\n* V is for Validation.","5fe6fb59":"# *Giri\u015f*\n*G\u00fcn\u00fcm\u00fczde art\u0131k hepimiz her g\u00fcn Korona'y\u0131 ve vaka say\u0131lar\u0131n\u0131 duyuyoruz. Korona ger\u00e7e\u011finin fark\u0131nday\u0131z. Semptomlar\u0131n\u0131 da hemen hemen hepimiz ya ara\u015ft\u0131rarak ya da bir arkada\u015f\u0131m\u0131z vas\u0131tas\u0131 ile biliyoruz. Bu vir\u00fcs akci\u011ferlerimizde bir tak\u0131m patalojik durumlara yol a\u00e7makta ve okumakta oldu\u011funuz \u00e7al\u0131\u015fmada amac\u0131m bilgisayarl\u0131 tomografi g\u00f6r\u00fcnt\u00fclerinden yararlanarak bir g\u00f6r\u00fcnt\u00fc i\u015fleme tekni\u011fi ile derin \u00f6\u011frenme tekni\u011fi kullanarak bu patalojik durumlar\u0131 saptamak ve akci\u011fer BT g\u00f6r\u00fcnt\u00fclerine bakarak covid te\u015fhisi koyan bir yapay zeka programlamak.*\n","5c0151ed":"# *Preface*\n*Nowadays we all know about corona and hearing news about corona everyday. We even know the symptoms and it is a sign of how much it is in our lives. This virus causes some pathological conditions in our lungs and we can monitorize them with computed tomography of the lungs. My aim is programing a deep learning model that uses images of computed tomography of the lungs and some image processing to diagnose covid.*","2c574f6d":"# *Modeli olu\u015fturmak*\n*\u015eimdi derin \u00f6\u011frenmeyi uygulayaca\u011f\u0131m modeli olu\u015fturmaya geldi s\u0131ra. E\u011fitim i\u00e7in \"Transfer learning\" kullanmaya karar verdim. Transfer Learning \u00f6nceden olu\u015fturulmu\u015f ve e\u011fitilmi\u015f bir modeli farkl\u0131 bir konuda e\u011fitmek i\u00e7in kullanmak demektir ve bu bize b\u00fcy\u00fck bir fayda sa\u011flar. Ben \"Transfer learning\" i\u00e7in \"InceptionV3\" kulland\u0131m ve 1024 ve 512 n\u00f6rondan olu\u015fan 2 katman daha ekledim.*\n"}}