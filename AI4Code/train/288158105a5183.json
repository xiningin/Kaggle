{"cell_type":{"8604b7c0":"code","653cb1ab":"code","0ee87041":"code","ee0a45ce":"code","02c4e534":"code","d55797ac":"code","25c467b1":"code","0d02b90f":"code","5fbf6426":"code","9343e65a":"code","104de738":"code","ca0d7e77":"code","58486620":"code","972441c1":"code","73008d3c":"code","9e66293e":"code","711ede95":"code","1a54fc59":"code","f9cdd9e3":"code","81e874b4":"code","f1c21ee3":"code","de0981f7":"code","2af2ca4f":"code","c1a75f3e":"code","261d6a71":"code","992dc12e":"code","442accbb":"code","9b81bd70":"code","6945706b":"code","abe45146":"code","b0acd20a":"code","01b1c376":"code","919d247c":"code","5c786715":"code","6ace602a":"code","84ceaf2e":"code","81c33109":"code","4d9ef6a0":"code","0d457008":"code","99dfda56":"code","76753fb9":"code","585fd759":"code","192c658d":"code","b336c410":"code","caa3913d":"code","8be1872f":"code","c4cd6767":"code","2023ed16":"markdown","c10b5c84":"markdown","2897bbe7":"markdown","937d5ff4":"markdown","5eadb0f1":"markdown","02f50ab7":"markdown","91d7fe52":"markdown","661fd1b2":"markdown","0638f87b":"markdown","825f5222":"markdown"},"source":{"8604b7c0":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/clusterimages\/CoverPage.PNG\")","653cb1ab":"# Loading Libraries\nimport pandas as pd # for data analysis\nimport numpy as np # for scientific calculation\nimport seaborn as sns # for statistical plotting\nimport matplotlib.pyplot as plt # for plotting\n%matplotlib inline","0ee87041":"#Reading market segment data set.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/marketsegment-sns\/marketsegment.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ee0a45ce":"marketsegment_eda=pd.read_csv('\/kaggle\/input\/marketsegment-sns\/marketsegment.csv')","02c4e534":"marketsegment_eda.describe()","d55797ac":"marketsegment_eda.shape","25c467b1":"marketsegment_eda.info()","0d02b90f":"marketsegment_eda.head()","5fbf6426":"marketsegment_eda.isnull().sum()","9343e65a":"# Identify Duplicate Records\nduplicate_records = marketsegment_eda[marketsegment_eda.duplicated()]\nprint(\"Duplicate Rows except first occurrence based on all columns are :\")\nprint(len(duplicate_records))\nprint(marketsegment_eda.shape)\nprint(duplicate_records.head(2))","104de738":"# dropping duplicate values \nmarketsegment_eda.drop_duplicates(keep=False,inplace=True) ","ca0d7e77":"#Validate duplicate records after dropping duplicate record rows.\nduplicate_records = marketsegment_eda[marketsegment_eda.duplicated()]\nprint(\"Duplicate Rows except first occurrence based on all columns are :\")\nprint(len(duplicate_records))\nprint(marketsegment_eda.shape)\nprint(marketsegment_eda.head(2))","58486620":"# https:\/\/www.kaggle.com\/pavansanagapati\/comprehensive-feature-engineering-tutorial\n# Missing Data Percentage\ntotal = marketsegment_eda.isnull().sum().sort_values(ascending=False)\npercent = (marketsegment_eda.isnull().sum()\/marketsegment_eda.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nf, ax = plt.subplots(figsize=(15, 6))\nplt.xticks(rotation='90')\nsns.barplot(x=missing_data.index, y=missing_data['Percent'])\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of Missing Values', fontsize=15)\nplt.title('Percentage of Missing Data by Feature', fontsize=15)\nmissing_data.head()","972441c1":"# https:\/\/thispointer.com\/pandas-drop-rows-from-a-dataframe-with-missing-values-or-nan-in-columns\/\n# Drop rows with any NaN in the selected columns only\nprint(marketsegment_eda.shape)\nmarketsegment_eda = marketsegment_eda.dropna(how='any', subset=['gender'])\nprint(marketsegment_eda.shape)\nprint(\"Contents of the Modified Dataframe : \")\nprint(marketsegment_eda.head(2))\ntotal = marketsegment_eda.isnull().sum().sort_values(ascending=False)\npercent = (marketsegment_eda.isnull().sum()\/marketsegment_eda.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nprint(missing_data.head(3))","73008d3c":"# Verify Age count based on gradyear.\nmarketsegment_eda.groupby(by=['gradyear', 'gender'])['age'].mean()","9e66293e":"# Below apply_age function is used to assign missing age value calculate w.r.t to mean age value based on gradyear and Sex.\n# To maintain accuracy of missing Age value. In real time it is very difficult to calculate missing Age value in case of\n# DateOfBirth value column details were missing in the given dataset. To maintain consistency written below function.\ndef apply_age(gradyear,sex):\n    if(gradyear==2006):\n        age=19\n    elif (gradyear==2007):\n        age=18\n    elif (gradyear==2008 and sex=='F'):\n        age=17\n    elif (gradyear==2008 and sex=='M'):\n        age=18\n    elif (gradyear==2007):\n        age=17\n    else:\n        age=18 # mean age considered from describe()\n    return age\n\n#print(apply_age(1,'male'))","711ede95":"# Filling missing values of age column.\nage_nulldata=marketsegment_eda[marketsegment_eda['age'].isnull()]\nage_nulldata['age'] = age_nulldata.apply(lambda row : apply_age(row['gradyear'],row['sex']), axis = 1) \nmarketsegment_eda['age'].fillna(value=age_nulldata['age'],inplace=True)","1a54fc59":"# total number of missing Age value count is 263.\nmarketsegment_eda['age'].isnull().sum()","f9cdd9e3":"# https:\/\/www.kaggle.com\/viratkothari\/eda-worldwide-meat-consumption-analysis\n# Learnt it from @Virat Kothari article\n# Analysis of Non-numerical columns\nmarketsegment_eda.describe(include=['O'])","81e874b4":"# Gender Types\nprint(marketsegment_eda['gender'].unique())\nprint(\"Type of Gender: %s\" % (marketsegment_eda['gender'].nunique()))\nprint(marketsegment_eda['gender'].value_counts())","f1c21ee3":"# Generated HeatMap.\n# Observation: From the below heatmap it is difficult to do correlation analysis between the variables.\n# Let's see next observation after EDA and feature engineering.\ncorr = marketsegment_eda.corr()\nax = sns.heatmap( corr,vmin=-1, vmax=1, center=0,  cmap=sns.diverging_palette(20, 220, n=200),square=True)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right');\n\n\n","de0981f7":"marketsegment_eda.head(2)","2af2ca4f":"#https:\/\/www.geeksforgeeks.org\/combining-multiple-columns-in-pandas-groupby-with-dictionary\/\n#Sports\ngroupby_dict_sports = {\"basketball\":\"Sports\",\"football\":\"Sports\",\"soccer\":\"Sports\",\"softball\":\"Sports\",\n \"volleyball\":\"Sports\",\"swimming\":\"Sports\",\"cheerleading\":\"Sports\",\"baseball\":\"Sports\",\"tennis\":\"Sports\",\"sports\":\"Sports\"}\nmarketsegment_eda['Sports'] = marketsegment_eda.groupby(groupby_dict_sports, axis = 1).sum() \n#Religion\ngroupby_dict_religion = {\"god\":\"Religion\",\"church\":\"Religion\",\"jesus\":\"Religion\",\"bible\":\"Religion\",\"hollister\":\"Religion\"}\nmarketsegment_eda['Religion'] = marketsegment_eda.groupby(groupby_dict_religion, axis = 1).sum() \n#Music\ngroupby_dict_music = {\"dance\":\"Music\",\"band\":\"Music\",\"music\":\"Music\",\"rock\":\"Music\"}\nmarketsegment_eda['Music'] = marketsegment_eda.groupby(groupby_dict_music, axis = 1).sum() \n#Others\ngroupby_dict_others = {\"cute\":\"Others\",\"sexy\":\"Others\",\"hot\":\"Others\",\"kissed\":\"Others\",\"marching\":\"Others\",\"hair\":\"Others\",\n                       \"dress\":\"Others\",\"blonde\":\"Others\",\"mall\":\"Others\",\"shopping\":\"Others\",\"clothes\":\"Others\",\n                       \"abercrombie\":\"Others\",\"die\":\"Others\",\"death\":\"Others\",\"drunk\":\"Others\",\"drugs\":\"Others\"}\nmarketsegment_eda['Others'] = marketsegment_eda.groupby(groupby_dict_others, axis = 1).sum() ","c1a75f3e":"print(marketsegment_eda.groupby('gender')['Sports'].sum())\nprint(marketsegment_eda.groupby('gender')['Religion'].sum())\nprint(marketsegment_eda.groupby('gender')['Music'].sum())\nprint(marketsegment_eda.groupby('gender')['Others'].sum())\n\n","261d6a71":"marketsegment_eda_final = marketsegment_eda.copy()\nmarketsegment_eda_final = marketsegment_eda_final.drop(['basketball','football','soccer','softball','volleyball','swimming','cheerleading','baseball','tennis','sports','cute','sex','sexy','hot','kissed','dance','band','marching','music','rock','god','church','jesus','bible','hair','dress','blonde','mall','shopping','clothes','hollister','abercrombie','die','death','drunk','drugs'],axis = 1) \n","992dc12e":"print(marketsegment_eda_final.head(2))\nprint(marketsegment_eda_final.shape)","442accbb":"# displaying the datatypes \ndisplay(marketsegment_eda_final.dtypes) \n  \n# converting 'age' from float to int \nmarketsegment_eda_final['age'] = marketsegment_eda_final['age'].astype(int) \n  \n# displaying the datatypes \ndisplay(marketsegment_eda_final.dtypes) \n","9b81bd70":"# Correlation Heat Map\nfigsize=[10,8]\nplt.figure(figsize=figsize)\nsns.heatmap(marketsegment_eda_final.corr(),annot=True)\nplt.show()","6945706b":"# Analyzing data points using pairplot\nsns.pairplot(marketsegment_eda_final, hue='gender')","abe45146":"# Label Encoding for gender\n# Returns dictionary having key as category and values as number\ndef find_category_mappings(marketsegment_eda_final, variable):\n    return {k: i for i, k in enumerate(marketsegment_eda_final[variable].unique())}\n\n# Returns the column after mapping with dictionary\ndef integer_encode(marketsegment_eda_final,variable, ordinal_mapping):\n    marketsegment_eda_final[variable] = marketsegment_eda_final[variable].map(ordinal_mapping)\n\nfor variable in ['gender']:\n    mappings = find_category_mappings(marketsegment_eda_final,variable)\n    integer_encode(marketsegment_eda_final, variable, mappings)\n    \nmarketsegment_eda_final.head()","b0acd20a":"knn_data = marketsegment_eda_final.drop(['gradyear', 'friends','age'], axis =1)","01b1c376":"knn_data.describe()","919d247c":"# Removing (statistical) outliers for Sports\nQ1 = knn_data.Sports.quantile(0.05)\nQ3 = knn_data.Sports.quantile(0.95)\nIQR = Q3 - Q1\nknn_data = knn_data[(knn_data.Sports >= Q1 - 1.5*IQR) & (knn_data.Sports <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Religion\nQ1 = knn_data.Religion.quantile(0.05)\nQ3 = knn_data.Religion.quantile(0.95)\nIQR = Q3 - Q1\nknn_data = knn_data[(knn_data.Religion >= Q1 - 1.5*IQR) & (knn_data.Religion <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Music\nQ1 = knn_data.Music.quantile(0.05)\nQ3 = knn_data.Music.quantile(0.95)\nIQR = Q3 - Q1\nknn_data = knn_data[(knn_data.Music >= Q1 - 1.5*IQR) & (knn_data.Music <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Others\nQ1 = knn_data.Others.quantile(0.05)\nQ3 = knn_data.Others.quantile(0.95)\nIQR = Q3 - Q1\nknn_data = knn_data[(knn_data.Others >= Q1 - 1.5*IQR) & (knn_data.Others <= Q3 + 1.5*IQR)]","5c786715":"print(knn_data.describe())\nprint(knn_data.shape)\n      ","6ace602a":"print(knn_data.head(2))\nprint(knn_data.shape)","84ceaf2e":"from sklearn.cluster import KMeans\n\nssw=[]\ncluster_range=range(1,10)\nfor i in cluster_range:\n    model=KMeans(n_clusters=i,init=\"k-means++\",n_init=10, max_iter=300, random_state=0)\n    model.fit(knn_data)\n    ssw.append(model.inertia_)","81c33109":"ssw_df=pd.DataFrame({\"no. of clusters\":cluster_range,\"SSW\":ssw})\nprint(ssw_df)","4d9ef6a0":"plt.figure(figsize=(12,7))\nplt.plot(cluster_range, ssw, marker = \"o\",color=\"cyan\")\nplt.xlabel(\"Number of clusters\")\nplt.ylabel(\"sum squared within\")\nplt.title(\"Elbow method to find optimal number of clusters\")\nplt.show()","0d457008":"# We'll continue our analysis with n_clusters=5\nkmeans=KMeans(n_clusters=5, init=\"k-means++\", n_init=10, random_state = 42)\n# Fit the model\nk_model=kmeans.fit(knn_data)","99dfda56":"## It returns the cluster vectors i.e. showing observations belonging which clusters \nclusters=k_model.labels_\nclusters","76753fb9":"knn_data['clusters'] = clusters","585fd759":"knn_data['clusters'].value_counts()","192c658d":"knn_data.head(2)","b336c410":"knn_data = knn_data.drop(['gender'], axis =1)","caa3913d":"### Visualizing the cluster based on each pair of columns\nsns.pairplot(knn_data, hue=\"clusters\", diag_kind=\"kde\")","8be1872f":"# Complete linkage\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nmergings = linkage(knn_data, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","c4cd6767":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/clusterimages\/DecisionandConclusion.PNG\")","2023ed16":"<a id=\"Tableofcontents\"><\/a>\n# Table of Contents\n\n* [Introduction](#Introduction)\n* [Exploratory Data Analysis](#ExploratoryDataAnalysis)\n* [Feature Engineering](#FeatureEngineering)\n* [Finding Clusters with Elbow Method](#FindingClusterswithElbowMethod)\n* [Building KMeans Model](#BuildingKMeansModel)\n* [Conclusion](#Conclusion)\n* [References](#References)","c10b5c84":"* [Table of Contents](#Tableofcontents)\n<a id=\"Introduction\"><\/a>\n### Introduction\n\n### Project Name: Clustering the Market Segments\n\nOne way to gain an edge in segmented marketing to identify segments of people who share similar tastes, so that they can avoid targeting advertisements to people with no interest in the product being sold. For instance, an alcoholic beverage is likely to be difficult to sell to people who do not drink.\n\nGiven the text of Social Networking Service (SNS) pages of people, we can identify groups that share common interests such as sports, religion, or music. Clustering can automate the process of discovering the natural segments in this population.","2897bbe7":"### Importing the dataset and packages ","937d5ff4":"* [Table of Contents](#Tableofcontents)\n<a id=\"FindingClusterswithElbowMethod\"><\/a>\n### Finding Clusters with Elbow Method","5eadb0f1":"* [Table of Contents](#Tableofcontents)\n<a id=\"BuildingKMeansModel\"><\/a>\n### Building KMeans Model \n\nK-Means History\n\nThe term \"k-means\" was first used by James MacQueen in 1967 as part of his paper on \"Some methods for classification and analysis of multivariate observations\". The standard algorithm was also used in Bell Labs as part of a technique in pulse code modulation in 1957. It was also published by In 1965 by E. W. Forgy and typically is also known as the Lloyd-Forgy method.\n\nWhat Is K-Means?\n\nClustering is the task of dividing the population or data points into a number of groups such that data points in the same groups are more similar to other data points in the same group than those in other groups. In simple words, the aim is to segregate groups with similar traits and assign them into clusters. The goal of the k-means algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. In the reference image below, K=5, and there are five clusters identified from the source dataset.\n\nK-Means Clustering algorithm used for unsupervised learning for clustering problem. K- variable value easily decide based on the number of clusters business is looking for.Popular Distance measures to use: Euclidean distance.\n\n\n* Specify number of clusters K.\n* Initialize centroids by first shuffling the dataset and then randomly selecting K data points for the centroids without replacement.\n* Keep iterating until there is no change to the centroids. i.e assignment of data points to clusters isn\u2019t changing. ","02f50ab7":"## Main intension of developing this project is to understand the Clustering Concepts.\nHappy Learning!!!","91d7fe52":"* [Table of Contents](#Tableofcontents)\n<a id=\"Conclusion\"><\/a>\n### Conclusion\n\nBased on K-means clusters, Now, Marketing group can easily identify to segment people based on their interest to target only those segments for advertising their products. \n","661fd1b2":"* [Table of Contents](#Tableofcontents)\n<a id=\"ExploratoryDataAnalysis\"><\/a>\n### Exploratory Data Analysis ","0638f87b":"* [Table of Contents](#Tableofcontents)\n<a id=\"References\"><\/a>\n### References\n* https:\/\/www.analyticsvidhya.com\/blog\/2019\/08\/comprehensive-guide-k-means-clustering\/\n* https:\/\/machinelearningmastery.com\/clustering-algorithms-with-python\/\n* https:\/\/towardsdatascience.com\/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68\n* https:\/\/www.digitalvidya.com\/blog\/the-top-5-clustering-algorithms-data-scientists-should-know\/\n* https:\/\/dzone.com\/articles\/10-interesting-use-cases-for-the-k-means-algorithm\n* https:\/\/www.kdnuggets.com\/2019\/11\/customer-segmentation-using-k-means-clustering.html\n* http:\/\/rstudio-pubs-static.s3.amazonaws.com\/192257_031d558dcbfa4b5db65d8ff5c2e6e2da.html\n* https:\/\/www.kaggle.com\/viratkothari\/eda-worldwide-meat-consumption-analysis\n* https:\/\/www.kaggle.com\/pavansanagapati\/comprehensive-feature-engineering-tutorial\n","825f5222":"* [Table of Contents](#Tableofcontents)\n<a id=\"FeatureEngineering\"><\/a>\n### Feature Engineering"}}