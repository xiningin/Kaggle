{"cell_type":{"c2d8971f":"code","a16b086e":"code","95b06597":"code","61a3d10d":"code","7698723d":"code","d16ffbc6":"code","609dbfb5":"code","8515a823":"code","1a458b4a":"code","87838101":"code","aaab4c06":"code","5b6f9408":"code","4ad56531":"code","69211b8f":"code","95961a52":"code","e660030d":"code","2086c528":"code","47cfec82":"code","e80330c7":"code","647f1933":"code","bba10b39":"code","890ea85d":"code","d5a5a167":"code","8dcfa16d":"code","2848ce44":"code","a86812f6":"code","d4f04f1f":"code","190cb74c":"code","0321fb24":"code","ec94d577":"code","94b93831":"code","5057fa34":"markdown","be41ad9e":"markdown","848bbb7b":"markdown","f62f3a63":"markdown","57697df2":"markdown","e3731d50":"markdown","cef87c94":"markdown"},"source":{"c2d8971f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O","a16b086e":"dataset=pd.read_csv('..\/input\/sentiment140\/training.1600000.processed.noemoticon.csv',encoding = 'latin',header=None)\ndataset.head()","95b06597":"dataset=dataset[[0,5]] #Removing unwanted columns\ndataset.head()","61a3d10d":"sentences=dataset[5] #Dividing Labels and texts\nlabel=dataset[0]\nsentences.head()","7698723d":"sentences = sentences[700000:900000]\nlabel = label[700000:900000]","d16ffbc6":"from sklearn.utils import shuffle\nsentences, label = shuffle(sentences, label, random_state=0) # shuffle data","609dbfb5":"label[label==4]=1 # Assigning 1 to Positive(4) ","8515a823":"import nltk #Natural Language processing toolkit\nimport re  # Regular expression operations\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords \nfrom nltk.stem import SnowballStemmer","1a458b4a":"stop_words = stopwords.words('english')\nstemmer = SnowballStemmer('english')\n\ntext_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\" # To remove URL's","87838101":"def preprocess(text):  # Cleaning sentences\n    text = re.sub(text_cleaning_re, ' ', text).strip()\n    words=[]    \n    for word in text.split():              \n        if word not in stop_words:                \n            words.append(stemmer.stem(word))\n                               \n    return \" \".join(words)","aaab4c06":"processed_text=sentences.apply(lambda text: preprocess(text))","5b6f9408":"processed_text","4ad56531":"from sklearn.model_selection import train_test_split","69211b8f":"#splitting data into train and test sets\ntrain_text,test_text,train_labels,test_labels=train_test_split(processed_text,np.array(label),test_size=0.1,random_state=4)","95961a52":"#vectorizing data\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_model=TfidfVectorizer(ngram_range=(1,2),min_df=10, max_features=160000)\ntfidf_model.fit(train_text,train_labels)\ntrain_text_tfidf=tfidf_model.transform(train_text)\ntest_text_tfidf=tfidf_model.transform(test_text)","e660030d":"#Applying Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\nlr=LogisticRegression(max_iter=1000)\nlr.fit(train_text_tfidf,train_labels)\nlr_predict=lr.predict(test_text_tfidf)\nlr_f1=f1_score(test_labels,lr_predict,average=\"weighted\")\nlr_f1 # performance of logistic regression","2086c528":"from sklearn.metrics import plot_confusion_matrix\nfrom matplotlib import pyplot as plt\n\ndisp = plot_confusion_matrix(lr, test_text_tfidf, test_labels, cmap=plt.cm.Blues, normalize='true')\ndisp.ax_.set_title(\"Logistic regression Confusion matrix\")\nprint(\"Logistic regression Confusion matrix\")\nprint(disp.confusion_matrix)\nplt.show()","47cfec82":"#Applying Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(random_state=0)\ndtc.fit(train_text_tfidf, train_labels)\ndt_predict=dtc.predict(test_text_tfidf)\ndt_f1=f1_score(test_labels,dt_predict,average=\"weighted\")","e80330c7":"dt_f1 # performance of decision tree","647f1933":"disp1 = plot_confusion_matrix(dtc, test_text_tfidf, test_labels, cmap=plt.cm.Blues, normalize='true')\ndisp1.ax_.set_title(\"Decision Tree Confusion matrix\")\nprint(\"Decision Tree Confusion matrix\")\nprint(disp1.confusion_matrix)\nplt.show()","bba10b39":"#Applying Naive Bayes\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(train_text_tfidf, train_labels)\nnb_predict=nb.predict(test_text_tfidf)\nnb_f1 = f1_score(test_labels,nb_predict,average=\"weighted\")\nnb_f1 # performance of naive bayes","890ea85d":"disp2 = plot_confusion_matrix(nb, test_text_tfidf, test_labels, cmap=plt.cm.Blues, normalize='true')\ndisp2.ax_.set_title(\"Naive Bayes Confusion matrix\")\nprint(\"Naive Bayes Confusion matrix\")\nprint(disp2.confusion_matrix)\nplt.show()","d5a5a167":"#Applying KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(train_text_tfidf, train_labels)\nknn_predict=knn.predict(test_text_tfidf)\nknn_f1 = f1_score(test_labels,knn_predict,average=\"weighted\")\nknn_f1 # performance of artificial neural network","8dcfa16d":"disp3 = plot_confusion_matrix(knn, test_text_tfidf, test_labels, cmap=plt.cm.Blues, normalize='true')\ndisp3.ax_.set_title(\"KNN Confusion matrix\")\nprint(\"KNN Confusion matrix\")\nprint(disp3.confusion_matrix)\nplt.show()","2848ce44":"models=[\"LogisticRegression\",\"DecisionTrees\",\"NaiveBayes\", \"KNN\"]\nf1_scores=[lr_f1, dt_f1, nb_f1, knn_f1]\n","a86812f6":"plt.figure(figsize=(6,5)),\nplt.barh(models,f1_scores)\nplt.title(\"F1 Scores of all models\",size=20)\nfor index, value in enumerate(f1_scores):\n    plt.text(0.9,index,str(round(value,2)))\nplt.xlabel('F1_Scores',size=15)\nplt.ylabel(\"Models\",size=15)\nplt.savefig(\"f1_scores.png\")\nplt.show()","d4f04f1f":"# Saving model\nimport pickle\nfilename = 'final_model.sav'\npickle.dump(lr, open(filename, 'wb')) #wb = write binary","190cb74c":"#Loading model\nloaded_model = pickle.load(open(filename, 'rb')) #rb = read binary","0321fb24":"#function to predict sentiment of a single tweet\ndef predict_sentiment(tweet):\n    input = [tweet]\n    input = tfidf_model.transform(input)\n    result = loaded_model.predict(input)\n    if result == 0:\n        print(\"Negative sentiment detected :(\")\n    else:\n        print(\"Positive sentiment detected :)\")","ec94d577":"predict_sentiment(\"what an amazing day\")","94b93831":"predict_sentiment(\"I wanna sleep and I still can't\")","5057fa34":"### 3. Model Tuning\nWe train the following classifiers on our training data\n1. Logistic Regression\n2. Decision Tree\n3. Naive Bayes\n4. Neural Network\n\nEach classifier's accuracy is measured through their F1 score (a metric to measure efficiency provided as a function in sklearn).\nConfusion Matrix of each model is displayed to represent how good the model performed","be41ad9e":"### 4. Evaluation\nComparison between the performances of all the classifiers we trained.","848bbb7b":"### 2. Data Preprocessing\n1. We first shuffle the dataset to avoid any biases.\n2. Stopwords (a, an, the, etc) are to be removed\n3. The data is cleaned using Stemmer utility in sci-kit learn library\n4. The cleaned data is split into Training Set (90%) and Test Set (10%)\n5. Finally, we use TFIDF Vectorizer to convert our tweets from string to vector format so that Machine Learning models can be applied to them.","f62f3a63":"Examples:","57697df2":"### Final Model\nSince Logistic Regression outperforms the rest we select it as our final model and will use it to predict the sentiments depicted by tweets.","e3731d50":"### 1. Data Input\nInput the dataset and separate the tweets and positive\/negative labels","cef87c94":"# TWITTER SENTIMENT ANALYSIS\n\nThis project aims to perform sentiment analysis on data consisting of 200K tweets and compare the performance of various classifiers when used for sentiment analysis."}}