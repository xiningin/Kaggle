{"cell_type":{"6e8401c9":"code","d8b311e6":"code","79f3f542":"code","de3b0447":"code","99c12dc7":"code","7f8b1fff":"code","35bd8df3":"code","421a4950":"code","3dbf689d":"code","27e54ee9":"code","e8efee44":"code","d6d3d1a7":"code","08c0b29b":"code","17b43c1d":"code","757e0cb4":"code","596e9d4c":"code","94189441":"code","d312fdcf":"code","f4a0907b":"code","1b986a21":"code","6cb20a4f":"code","0b40b3bf":"code","0a13fa9c":"code","ec401771":"code","21b0327a":"code","5b4490bb":"code","d41657e0":"code","1bc4919a":"code","7ddef5b5":"code","cdb4a3de":"code","564898ea":"code","a1c2b12f":"code","8d4b9cfa":"code","fbd87828":"code","63201435":"code","edb2beac":"code","e7459b82":"code","78b8af3a":"code","adf4d671":"code","65ee6805":"code","f8a315a3":"code","0e1ea4a0":"code","e426b82c":"code","c86b72e4":"code","107b9463":"code","e45d4eb9":"code","bb7cc30d":"code","99cf728e":"code","1841f1e3":"code","20c51b21":"markdown","420d4f3f":"markdown","23196c51":"markdown","78c3f9cd":"markdown","781ecb4f":"markdown","4bbd9b3f":"markdown","277e36b5":"markdown","c7381bf9":"markdown","065257a3":"markdown","32a9c2d8":"markdown"},"source":{"6e8401c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8b311e6":"# Importing the libraries\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')","79f3f542":"train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","de3b0447":"test.head()","99c12dc7":"train.head()","7f8b1fff":"train.describe()","35bd8df3":"train.isnull().sum()","421a4950":"train.dtypes","3dbf689d":"def Missing_val(data):\n    Total_val=train.isnull().sum()\n    Percent_val=100*train.isnull().sum()\/len(train)\n    Total_val=pd.DataFrame(Total_val[Total_val>0])\n    Percent_val=pd.DataFrame(Percent_val[Percent_val>0])\n    Missing_val=pd.concat([Total_val, Percent_val], axis=1)\n    Missing_val.columns=['Total_val', 'Percent_val']\n    Missing_Value=Missing_val.sort_values(by='Percent_val', ascending=False)\n    return Missing_Value","27e54ee9":"Missing_val(train)","e8efee44":"plt.figure(figsize=(10,4))\nsns.barplot(x=Missing_val(train).index, y='Percent_val', data=Missing_val(train))\nplt.xticks(rotation=90)\nplt.show()","d6d3d1a7":"Missing_val(train)[Missing_val(train)['Percent_val']>80]","08c0b29b":"train=train.drop(['PoolQC','MiscFeature','Alley','Fence'], axis=1)","17b43c1d":"# Remaining Missing Values\nMissing_val(train)","757e0cb4":"# Filling missing values\nLotFrontage_median=train.LotFrontage.median()\ntrain['LotFrontage']=train.LotFrontage.fillna(LotFrontage_median)\ntrain[\"Electrical\"] = train[\"Electrical\"].fillna(\"FuseA\")\ntrain[\"Utilities\"] = train[\"Utilities\"].fillna(\"AllPub\")\ntrain[\"Exterior1st\"] = train[\"Exterior1st\"].fillna(\"VinylSd\")\ntrain[\"Exterior2nd\"] = train[\"Exterior2nd\"].fillna(\"VinylSd\")\ntrain[\"MSZoning\"] = train[\"MSZoning\"].fillna(\"RL\")\ntrain[\"SaleType\"] = train[\"SaleType\"].fillna(\"WD\")\ntrain[\"GarageCars\"] = train[\"GarageCars\"].fillna(2)\ntrain[\"KitchenQual\"] = train[\"KitchenQual\"].fillna(\"TA\")\ntrain['GarageType']= train['GarageType'].fillna('Attchd')    \ntrain['GarageQual']= train['GarageQual'].fillna('TA') \ntrain['GarageFinish']= train['GarageFinish'].fillna('Unf') \ntrain['GarageCond']=train['GarageCond'].fillna('TA')\ntrain['MasVnrArea']= train['MasVnrArea'].fillna(0)\ntrain['MasVnrType']= train['MasVnrType'].fillna('None')\n\n# Filling numeric values of garage with mean \ntrain['GarageYrBlt']= train['GarageYrBlt'].fillna(train.GarageYrBlt.mean()) \n\n\n# Filling basement string features with none\nbasement_str =  ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\ntrain[basement_str] = train[basement_str].fillna('None')\n\n# Filling basement other numeric variables with 0\nbasement_num = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\ntrain[basement_num]=train[basement_num].fillna(0)\n\n# Filling Fireplace Qu with None\ntrain['FireplaceQu']= train['FireplaceQu'].fillna('None')  ","596e9d4c":"Missing_val(train) # 0 missing values","94189441":"train['SalePrice'].describe()","d312fdcf":"# Heat Map\ncorrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True)","f4a0907b":"corrmat","1b986a21":"corrmat.nlargest(5, 'SalePrice')","6cb20a4f":"# Sale Price Correlation Matrix\nx=10 \ncols=corrmat.nlargest(x,'SalePrice')['SalePrice'].index\nsns.set(font_scale=1)\nhm = sns.heatmap(train[cols].corr(), cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","0b40b3bf":"sns.scatterplot(data=train, x='OverallQual', y='SalePrice')","0a13fa9c":"sns.scatterplot(data=train, x='GrLivArea', y='SalePrice')","ec401771":"sns.scatterplot(data=train, x='GarageCars', y='SalePrice')","21b0327a":"sns.scatterplot(data=train, x='GarageArea', y='SalePrice')","5b4490bb":"# Visulize Datetime Variable\ntrain.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title('House Price vs Year Sold')","d41657e0":"# Distribution plot of Sale Price\nsns.distplot(train['SalePrice'])","1bc4919a":"print('Skewness:',train['SalePrice'].skew())\nprint('Kurtosis:',train['SalePrice'].kurt())","7ddef5b5":"# Log Transformation\nnum_var=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n\nfor col in num_var:\n    train[col]=np.log(train[col])\nsns.distplot(train['SalePrice'])","cdb4a3de":"sns.distplot(train['LotFrontage'])","564898ea":"probility= stats.probplot(train['SalePrice'], plot= plt)","a1c2b12f":"train_object = train.select_dtypes(include = \"object\")\ntrain_numeric = train.select_dtypes(exclude = \"object\")\ntrain_object.shape , train_numeric.shape","8d4b9cfa":"# list of variables that contain year information\nyear_var = [var for var in train_numeric if 'Yr' in var or 'Year' in var]\nprint(\"Temporial feature Count : {}\".format(len(year_var)))\nyear_var","fbd87828":"# Discrete Variables\ndiscrete_var=[var for var in train_numeric if len(train[var].unique())<25 and var not in year_var+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_var)))","63201435":"#Continous Variables\ncontinuous_var=[var for var in train_numeric if var not in discrete_var+year_var+['Id']]\nprint(\"Continuous var Count: {}\".format(len(continuous_var)))","edb2beac":"for var in train.select_dtypes(include = \"object\"):\n    labels_ordered=train.groupby([var])['SalePrice'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    train[var]=train[var].map(labels_ordered)","e7459b82":"X = train.drop(['SalePrice'],axis=1)\nY = train['SalePrice']","78b8af3a":"# Train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)","adf4d671":"# Standard scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train) \nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n","65ee6805":"# Model\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nclf=RidgeCV(alphas=[0.1,1.0,10.0]) #Choosing the best alpha \nclf.fit(X_train, Y_train)\nRidge","f8a315a3":"y_pred_Ridge=clf.predict(X_test)","0e1ea4a0":"clf.alpha_","e426b82c":"# Accuracy Check\n\nfrom sklearn.metrics import r2_score, mean_absolute_error\nprint(\"Mean_Absolute_Error_Ridge\", mean_absolute_error(Y_test, y_pred_Ridge))\nprint(\"R2_Score_Ridge\", r2_score(Y_test, y_pred_Ridge))","c86b72e4":"sns.regplot(y_pred_Ridge, Y_test)","107b9463":"# Model \nfrom sklearn.linear_model import Lasso, LassoCV\nclf_lasso=LassoCV(alphas=[0.01,0.1, 0.05, 0.5, 1])\nclf_lasso.fit(X_train, Y_train)","e45d4eb9":"clf_lasso.alpha_","bb7cc30d":"clf_pred_lasso=clf_lasso.predict(X_test)","99cf728e":"# Accuracy Check\nfrom sklearn.metrics import mean_absolute_error\nprint(\"Mean_Absolute_Error_LassoReg\", mean_absolute_error(Y_test, clf_pred_lasso))\nfrom sklearn.model_selection import cross_val_score\nprint('R2_SCORE_LassoReg',r2_score(Y_test, clf_pred_lasso))","1841f1e3":"sns.regplot(clf_pred_lasso, Y_test)","20c51b21":"The variables having more than 80% of the missing values needs to be deleted. As these can not used \nto derive significant information.","420d4f3f":"**Data Description**","23196c51":"**Normality Check**","78c3f9cd":"**Handling Missing Values**","781ecb4f":"**Regression Models:**","4bbd9b3f":"**EDA:**","277e36b5":"Exploring Highly corelated variables","c7381bf9":"**Post log transformation the data now looks similar to normal distribution. Thus, it can be used for performing further anlaysis.**","065257a3":"**From the above models we can observe that application of Ridge Regression will give us better predictions.**","32a9c2d8":"**To predict house prices in Boston using advanced regression techniques.**"}}