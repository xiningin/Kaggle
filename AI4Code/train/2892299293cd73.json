{"cell_type":{"3deb2fce":"code","4d5cd83c":"code","e01ade25":"code","c70259b9":"code","b14aab49":"code","aad36c08":"code","b7fe0285":"code","b3919f83":"code","6c81935a":"code","5637ee2e":"code","98928f6e":"code","7c45869b":"code","0ddbd06d":"code","4a9140e7":"code","952067ce":"code","fa45fda4":"code","6a999e6e":"code","42769155":"code","390cc395":"code","13e81bb5":"markdown","38fadbf5":"markdown","82459168":"markdown","7a182e8c":"markdown","acf642e2":"markdown","e5f66d17":"markdown","c4576971":"markdown","f03eacc2":"markdown","9c68fe06":"markdown","79ec5483":"markdown","dd92fa52":"markdown","7421da29":"markdown","2879ed46":"markdown"},"source":{"3deb2fce":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4d5cd83c":"import numpy as np   \nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd    \nimport matplotlib.pyplot as plt \n%matplotlib inline \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split  #(Sklearn package's randomized data splitting function)","e01ade25":"df = pd.read_csv(\"\/kaggle\/input\/autompg-dataset\/auto-mpg.csv\")  \ndf.head()","c70259b9":"df.shape","b14aab49":"df = df.drop('car name', axis=1)\n\n# Also replacing the categorical var with actual values\n\ndf['origin'] = df['origin'].replace({1: 'america', 2: 'europe', 3: 'asia'})\ndf.head()","aad36c08":"df = pd.get_dummies(df, columns=['origin'])\ndf.head()","b7fe0285":"# quick summary of data columns\n\ndf.describe()","b3919f83":"# We can see horsepower is missing, cause it does not seem to be reqcognized as a numerical column!\n# lets check the types of data\n\ndf.dtypes","6c81935a":"# horsepower is showing as object type but as we see the data, it's a numeric value\n# so it is possible that horsepower is missing some data in it\n# lets check it by using 'isdigit()'. If the string is made of digits, it will store True else False\n \nmissing_value = pd.DataFrame(df.horsepower.str.isdigit())  \n\n#print missing_value = False!\n\ndf[missing_value['horsepower'] == False]   # prints only those rows where hosepower is false","5637ee2e":"# Missing values have a'?''\n# Replace missing values with NaN\n\ndf = df.replace('?', np.nan)\ndf[missing_value['horsepower'] == False] ","98928f6e":"df.median()","7c45869b":"median_fill = lambda x: x.fillna(x.median())\ndf = df.apply(median_fill,axis=0)\n\n# converting the hp column from object \/ string type to float\n\ndf['horsepower'] = df['horsepower'].astype('float64')  \n","0ddbd06d":"df_plot = df.iloc[:, 0:7]\nsns.pairplot(df_plot, diag_kind='kde')   \n\n# kde -> to plot density curve instead of histogram on the diag","4a9140e7":"# lets build our linear model\n\n# independant variables\nX = df.drop(['mpg','origin_europe'], axis=1)\n\n# the dependent variable\ny = df[['mpg']]\n\n# Split X and y into training and test set in 70:30 ratio\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)","952067ce":"regression_model = LinearRegression()\nregression_model.fit(X_train, y_train)\n\n# Here are the coefficients for each variable and the intercept\n\nfor idx, col_name in enumerate(X_train.columns):\n    print(f\"The coefficient for {col_name} is {regression_model.coef_[0][idx]}\")","fa45fda4":"intercept = regression_model.intercept_[0]\nprint(f\"The intercept for our model is {regression_model.intercept_}\")","6a999e6e":"in_sampleScore = regression_model.score(X_train, y_train)\nprint(f'In-Sample score = {in_sampleScore}')\n\nout_sampleScore = regression_model.score(X_test, y_test)\nprint(f'Out-Sample Score = {out_sampleScore}')","42769155":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\n\npoly = PolynomialFeatures(degree=2, interaction_only=True)\nX_train2 = poly.fit_transform(X_train)\nX_test2 = poly.fit_transform(X_test)\n\npoly_regr = linear_model.LinearRegression()\n\npoly_regr.fit(X_train2, y_train)\n\ny_pred = poly_regr.predict(X_test2)\n\n#print(y_pred)\n\n#In sample (training) R^2 will always improve with the number of variables!\n\nprint(poly_regr.score(X_train2, y_train))","390cc395":"# number of extra variables used in Polynomial Regression\n\nprint(X_train.shape)\nprint(X_train2.shape)","13e81bb5":"## Drope\/Ignore Car Name","38fadbf5":"### Split Data","82459168":"### Adding Interaction Terms\n* Polynomial Regression (with only interaction terms) to check if it improves the Out of sample accuracy, R^2.","7a182e8c":"## Import Libraries ","acf642e2":"## Dealing With Missing Values","e5f66d17":"### The score (R^2) for in-sample and out of sample","c4576971":"### Polynomial Features (with only interaction terms) have improved the Out of sample R^2 score. But this improves at the cost of 29 extra variables! ","f03eacc2":"## Create Dummy Variables\n\n* Values like 'america' cannot be read into an equation. Using substitutes like 1 for america, 2 for europe and 3 for asia would end up implying that european cars fall exactly half way between american and asian cars! we dont want to impose such an baseless assumption!\n\n* So we create 3 simple true or false columns with titles equivalent to \"Is this car America?\", \"Is this care European?\" and \"Is this car Asian?\". These will be used as independent variables without imposing any kind of ordering between the three regions.","9c68fe06":"There are various ways to handle missing values. Drop the rows, replace missing values with median values etc. of the 398 rows 6 have NAN in the hp column. We could drop those 6 rows - which might not be a good idea under all situations. So Replacing NaN values with Median.\n\n#### Note : - Note, we do not need to specify the column names below as every column's missing value is replaced with that column's median respectively  (axis =0 means columnwise)\ndf = df.fillna(df.median())\n\n","79ec5483":"### Fit Linear Model","dd92fa52":"# We will construct a linear model that explains the relationship, a car's mileage (mpg) has with its other attributes.","7421da29":"### BiVariate Plots\n* A bivariate analysis among the different variables can be done using scatter matrix plot. Seaborn libs create a dashboard reflecting useful information about the dimensions. The result can be stored as a .png file.\n* Observation between 'mpg' and other attributes indicate the relationship is not really linear. However, the plots also indicate that linearity would still capture quite a bit of useful information\/pattern. Several assumptions of classical linear regression seem to be violated, including the assumption of no Heteroscedasticity","2879ed46":"## Load and Review Data"}}