{"cell_type":{"28cb4075":"code","8c3c16d8":"code","5eb75f63":"code","aef9c64b":"code","f6f55de1":"code","f340d7f5":"markdown"},"source":{"28cb4075":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MaxAbsScaler ","8c3c16d8":"D0 = pd.read_csv(\"\/kaggle\/input\/data-ml\/D_train.csv\", index_col=\"index\")\nD0","5eb75f63":"cat_cols = D0.select_dtypes(\"object\").columns.difference([\"y\"]).to_list()\n\nmodel = make_pipeline(\n    make_column_transformer((OneHotEncoder(handle_unknown=\"ignore\"), cat_cols), remainder=\"passthrough\"),\n    MaxAbsScaler(),  # is able to keep the sparse data format sparse; doesn't matter which scaler to use exactly\n    LogisticRegression(max_iter=1000, n_jobs=-1),\n)\n\nX_train = D0.drop(columns=\"y\")\ny_train = D0[\"y\"]","aef9c64b":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    \"logisticregression__C\": np.logspace(np.log10(1e-5), np.log10(1e5), num=20),\n    \"logisticregression__solver\": [\"liblinear\", \"lbfgs\"],  # we are not actually interested in the solver, but rather that LR will use multi_class=\"multinomial\" when solver!=\"liblinear\"\n    \"logisticregression__penalty\": [\"l1\", \"l2\"],   # L1 only with liblinear\n    #\"logisticregression__class_weight\": [None, \"balanced\"],\n}\n\ngrid = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1)\ngrid.fit(X_train, y_train)\n\ngrid.best_score_, grid.best_params_","f6f55de1":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nmodel = make_pipeline(\n    make_column_transformer((OneHotEncoder(handle_unknown=\"ignore\"), cat_cols), remainder=\"passthrough\"),\n    MaxAbsScaler(),  # is able to keep the sparse data format sparse; doesn't matter which scaler to use exactly\n    SVC(probability=True),\n)\n\nparam_grid = {\n    \"svc__C\": np.logspace(np.log10(1e-5), np.log10(1e5), num=20),\n}\n\ngrid = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1)\n\n# was not any better\n#grid.fit(X_train, y_train)\n#grid.best_score_, grid.best_params_","f340d7f5":"(-0.8170142700336853,\n {'logisticregression__C': 0.2782559402207126})"}}