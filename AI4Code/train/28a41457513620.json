{"cell_type":{"7d466d57":"code","fed5eedb":"code","9dcaa065":"code","e99b2861":"code","1ad65dd3":"code","68979d46":"code","af6324fa":"code","ef8072cf":"code","13667a9c":"code","f46f91a8":"code","11dbd331":"code","133efcf5":"code","b518f6d5":"code","708483c2":"code","66774084":"code","57b8e408":"code","09d0071d":"code","c15e357e":"code","c4a2795a":"code","6a84a364":"code","c9e4b012":"code","5e303115":"code","01cb5471":"code","5bfc5d58":"code","deeb102e":"code","9659515a":"code","56f0e156":"code","6ad5cabd":"code","b0e3d022":"code","e7b3024d":"code","00f243ed":"code","ac44e59d":"code","9ebdd5a2":"code","681c8f04":"code","d9bc43ce":"code","c2bd3405":"code","a1a1ca9e":"markdown"},"source":{"7d466d57":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fed5eedb":"# reading the CSV file into pandas dataframe\ndf = pd.read_csv(\"\/kaggle\/input\/dl-intro-to-nn\/car-mpg.csv\")  \nprint(df.shape)\ndf.head()","9dcaa065":"df.isnull().sum()","e99b2861":"df  = df.drop(\"car_name\" , axis=1)","1ad65dd3":"df.describe()","68979d46":"df.info()","af6324fa":"# print(df['hp']).value_counts()","ef8072cf":"# df.isna().sum()","13667a9c":"# temp  = pd.DataFrame(df.hp.str.isdigit()) \n# temp","f46f91a8":"# temp.sum()","11dbd331":"# temp[temp['hp'] == False] ","133efcf5":"# On inspecting records number 32, 126 etc, we find \"?\" in the columns. Replace them with \"nan\"\n#Replace them with nan and remove the records from the data frame that have \"nan\"\ndf = df.replace('?', np.nan)","b518f6d5":"df.isna().sum()","708483c2":"# Since the question marks appear only in the \"hp\" columns, replace them with the median of the same column\n#df = df.apply(lambda x: x.fillna(x.median()),axis=0)\ndf.dropna(inplace=True)","66774084":"# df.isna().sum()","57b8e408":"df.shape","09d0071d":"# While reading the data into dataframe, Pandas assigned the data type as object to column \"hp\" because of the question marks\n# The column type continues to be same even after replacing the question marks with the median\n# Convert the column type to float64\n\n\ndf['hp'] = df['hp'].astype('float64')  # converting the hp column from object \/ string type to float","c15e357e":"df","c4a2795a":"import seaborn as sns\n\nsns.pairplot(data=df);","6a84a364":"# convert origin to numric values (but that will introduce an order in that column)\n\ndf['Origin'] = df['origin'].map(lambda x: {1: 'USA', 2: 'Europe', 3: 'Japan'}.get(x))","c9e4b012":"# convert the numeric values to one-hot code to remove the order\n\ndf = pd.get_dummies(df, columns=['origin'],drop_first=True)","5e303115":"df.head()","01cb5471":"df.drop(['Origin'],axis=1,inplace=True)\nprint(df.shape)\ndf.head()","5bfc5d58":"# Import `train_test_split` from `sklearn.model_selection`\nfrom sklearn.model_selection import train_test_split\n\n# Specify the data \nX=df.iloc[:,1:]\n\n# Specify the target labels and flatten array\ny= df.mpg\n\n\n# Split the data up in train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n\ny_train =  np.array(y_train)\ny_test =  np.array(y_test)","deeb102e":"from sklearn.preprocessing import StandardScaler\n\n# Define the scaler \nscaler = StandardScaler().fit(X_train)\n\n# Scale the train set\nX_train = scaler.transform(X_train)\n\n# Scale the test set\nX_test = scaler.transform(X_test)","9659515a":"X_train.shape","56f0e156":"# Using Tensorflow Keras instead of the original Keras\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\n\n\nncols = X_train.shape[1]\n\n# Initialize the constructor\nmodel = Sequential()\n\n# Add an first hidden layer \nmodel.add(Dense(20, input_shape=(ncols,),activation='sigmoid'))\n\n# second hidden layer\n#model.add(Dense(10, activation='relu', kernel_initializer='normal'))\n\n\n# Add an output layer with one neuron and no activation specified\nmodel.add(Dense(1))\n\nmodel.summary()","6ad5cabd":"optimizer = tf.keras.optimizers.Adam(0.01)\nmodel.compile(loss='mean_squared_error',optimizer=optimizer , metrics = ['mae' , 'mse'])","b0e3d022":"epochs = 50\nhistory = model.fit(X_train, y_train, epochs=epochs, validation_split = 0.2, verbose = True)\nhist  = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch","e7b3024d":"hist.head()","00f243ed":"model.summary()","ac44e59d":"import matplotlib.pyplot as plt\n\nplt.plot(hist['mse'])\nplt.plot(hist['val_mse'])\nplt.legend((\"train\" , \"valid\") , loc =0)","9ebdd5a2":"plt.plot(hist['mae'])\nplt.plot(hist['val_mae'])\nplt.legend((\"train\" , \"valid\") , loc =0)","681c8f04":"loss = model.evaluate(X_test, y_test, verbose=False)","d9bc43ce":"y_pred = np.round(model.predict(X_test))","c2bd3405":"import matplotlib.pyplot as plt\nplt.scatter(y_test, y_pred)","a1a1ca9e":"# <center> Build Deep Neural Network"}}