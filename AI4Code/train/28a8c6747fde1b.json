{"cell_type":{"e7458944":"code","b53cd1bd":"code","2fb83890":"code","086cb0e8":"code","1a676a93":"code","40d6d278":"code","148d469f":"code","7fa67f0a":"code","aad09fd3":"code","93e4495f":"code","529d16e8":"code","e947c39e":"code","fd8b0fc4":"code","18895940":"code","d54e231d":"code","7f8ab743":"code","aeb9974c":"code","71a068bd":"code","8a48f5b2":"code","96a38fa6":"code","01e4992c":"code","2e0dfef6":"markdown","5f464720":"markdown","f5f2917d":"markdown","fc2b3f1a":"markdown","b3a40a50":"markdown","b75be755":"markdown","f8675d01":"markdown","fba25191":"markdown","524d5d16":"markdown","cc3c4b4f":"markdown","61ed1379":"markdown","92d3e485":"markdown","e0eabe9c":"markdown","e00062f5":"markdown","4d6744a7":"markdown","4382633f":"markdown","55e685b0":"markdown","08e1d460":"markdown","c5836931":"markdown","9958e732":"markdown","03303253":"markdown","5a776d5c":"markdown","16506718":"markdown"},"source":{"e7458944":"import os\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, layers\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","b53cd1bd":"root_path = \"\/kaggle\/input\/digit-recognizer\/\"\n\n# Read train data\ntrain_df = pd.read_csv(os.path.join(root_path, 'train.csv'))\n\n# Read test data\ntest_df = pd.read_csv(os.path.join(root_path, 'test.csv'))","2fb83890":"train_df.head()","086cb0e8":"test_df.head()","1a676a93":"train_df.isnull().any().describe()","40d6d278":"# split into feature and label\nfeatures = train_df.values[:, 1:]\nlabels    = train_df.values[:, 0]","148d469f":"# information about data\nm = features.shape[0] # Number of training example\nn = features.shape[1] # Number of features\nunq_labels = np.unique(labels) # Unique label\nnum_label  = len(unq_labels) # Number of label\/class\n\nprint('Number of training examples: ', m)\nprint('Number of features: ', n)\nprint('Number of class\/label: ', num_label)","7fa67f0a":"print('Maximum pixel value ', np.max(features))\nprint('Minimum pixel value ', np.min(features))","aad09fd3":"# Normalize taining examples\nnorm_features = features\/255.0\n\n# Normalize test examples\ntest = test_df.values\/255.0","93e4495f":"# Reshape training example\nreshaped_features = norm_features.reshape(-1, 28, 28, 1)\n\n# Resahpe test examples\ntest = test.reshape(-1, 28, 28, 1)","529d16e8":"fig, axes = plt.subplots(8, 8, figsize=(10,10))\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(reshaped_features[np.random.randint(0,m)], cmap='gray')\n    ax.set(xticks=[], yticks=[])\nplt.show()","e947c39e":"# visualize labels\nplt.figure(figsize=(10,7))\nsns.countplot(labels, palette='icefire')\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.title('Count vs. Label')\nplt.show()","fd8b0fc4":"# convert to one hot encoding\none_hot_labels = tf.one_hot(labels, depth=num_label).numpy()","18895940":"x_train, x_val, y_train, y_val = train_test_split(reshaped_features, one_hot_labels, test_size=0.1, random_state=1)","d54e231d":"model = Sequential()\nmodel.add( \n    layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(28, 28, 1)) )\nmodel.add(\n    layers.MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(\n    layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(\n    layers.MaxPool2D(pool_size=(2,2)))\n\nmodel.add(\n    layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(\n    layers.MaxPool2D(pool_size=(2,2)))\n\nmodel.add( layers.Flatten() )\n\nmodel.add( layers.Dense(128, activation='relu') )\nmodel.add( layers.Dense(num_label, activation='softmax'))","7f8ab743":"model.compile(optimizer='adam', \n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy']\n             )","aeb9974c":"# Model Summary\nmodel.summary()","71a068bd":"# Fit and evaluation\nhistory = model.fit(x=x_train, y=y_train, validation_data=(x_val, y_val), batch_size=128, epochs=20, shuffle=True)","8a48f5b2":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(20)\n\nplt.figure(figsize=(10,6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","96a38fa6":"predicted = model.predict(test)\n","01e4992c":"pred_y = np.argmax(predicted, axis=1)\n\noutput_df = pd.DataFrame()\noutput_df['ImageId'] = pd.Series(range(1, pred_y.shape[0]+1))\noutput_df['Label'] = pd.Series(pred_y)\n\noutput_df.to_csv('submission.csv', index=False)","2e0dfef6":"#### Train data information","5f464720":"#### Label Encoding","f5f2917d":"#### Data visualization\n\nVisualize few training examples","fc2b3f1a":"### Compile the model\n\nCompiling the model requires the following \n- select a loss function that we want to optimize, such as mean squared error or cross-entropy.\n- select an algorithm to perform the optimization procedure, typically stochastic gradient descent, or a modern variation, such as Adam.\n- select a performance metrics to keep track of during the model training process.\n","b3a40a50":"#### Reshaping\nAs per dataset description we can understand that each row contain pixel values of an binary image which size is $28\\times 28$\nSo lets reshape them $28 \\times 28 \\times 1$; Where, \nheight=28, width=28 and channel=1 (1 for binary image and 3 for RGB image).","b75be755":"### Define the model\nWe are going to use Keras Sequentila API for defining the model.","f8675d01":"The range of pixel value is 0 to 255 which is not ideal for a neural network Neural network; CNN converge faster on [0...1] data over [0...255] So we will **standarize\/normalize** the data both train and test dividing by **255**.","fba25191":"#### Checking and removing null and missing values ","524d5d16":"Train dataset contains image pixels values and label of the image. Each image size is $28\\times28$ and they are binary images which means single chanel. Each row coressponding to one image pixles.","cc3c4b4f":"Since there is no null value or missing value, no need of removing operation.\n","61ed1379":"# Digit Recognition\nWe build a classfier with Convolution Neural Network which classify digit images.\n`Keras` of `TnesorFlow` is used in this notebook.\n\n### Main contents of this notebook\n- Data Processing\n    - Read dataset\n    - Checking and removing null and missing values\n    - Data Standarization\/Normalization\n    - Data visualization\n    - Split tarin data into train and validation set\n- Define the model.\n- Compile the model.\n- Fit the model.\n- Evaluate the model.\n- Make predictions.\n- Create submission file","92d3e485":"### Data Processing\n#### Read dataset\nRead train and test dataset with pandas as DataFrame","e0eabe9c":"#### Split tarin data into train and validation set","e00062f5":"Visulaize Labels\/Classes","4d6744a7":"#### Visualize the training results","4382633f":"Test dataset contains only image pixel values. Each row coressponding to one image pixles.","55e685b0":"#### Data Standarization\/Normalization","08e1d460":"#### Import required packages","c5836931":"### Fit the Model\n\nSelect the training configuration, such as the number of **epochs** (loops through the training dataset) and the **batch size** (number of samples in an epoch used to estimate model error).\n\nTrainig will be done through the chosen optimization to minimize the loss and update the model through backpropagation.\n\nThis is the slow part of the whole process.\n\n### Evaluate the Model\nRequires a holdout dataset or validation dataset from training data which is not used in training.\n\n**Note:** We will do both training and validation (evaluation) through `model.fit()`.","9958e732":"#### Create submission file","03303253":"### Make a Prediction\nPredict with test data\n","5a776d5c":"## Model: CNN\nWe will use CNN to classify our digit images\n\n### CNN:\nCNN comes with few terms like \n- filter\/weight matrix\n- Striding\n- Padding\n- Polling\n\n#### A basic CNN requires 2 additional layers.\n- Convolution and pooling layers before feedforward neural network\/ fully connected layer\n\n#### Structure of CNN\nOur CNN model has following structure\n\n`CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED`\n\nFrameworks makes our work so easy. We will use `keras` of `TensorFlow` to build and evaluate our model.\n\nA model has following steps\n1. Define the model.\n2. Compile the model.\n3. Fit the model.\n4. Evaluate the model.\n5. Make predictions.\n","16506718":"#### Split Train Dataset into feature and label"}}