{"cell_type":{"ca60a92e":"code","000112b3":"code","3d604342":"code","1af5b4ae":"code","aac9e1de":"code","3890d9de":"code","69629fac":"code","94d7cd95":"code","6f1c4ab2":"code","c5877c55":"code","53f74d02":"code","ad107d4d":"code","086a6832":"code","4dedacf2":"markdown","0d9132c0":"markdown","53fa7716":"markdown","b79f9515":"markdown","d76810d1":"markdown","ea114720":"markdown","ef552d52":"markdown","2f07e45d":"markdown"},"source":{"ca60a92e":"import pandas as pd","000112b3":"file = pd.read_csv('data1.csv', usecols=['full_text','location'])\ndf = file.rename({'full_text': 'body_text'},axis =1)\nfile = pd.read_csv('dataset.csv', usecols=['content'])\ndf = df.append(file.rename({'content': 'body_text'}, axis=1))\nfile = pd.read_csv('Final Paper - Part a[M.Sohail(24721)].csv', usecols=['full_text','location'])\ndf = df.append(file.rename({'full_text': 'body_text'}, axis=1))\nfile = pd.read_csv('Final paper -part a(21785).csv', usecols=['tweet'])\ndf = df.append(file.rename({'tweet': 'body_text'}, axis=1))\nwith open('Paper Part 1 24714.csv',errors = 'ignore',) as document:\n    file= pd.read_csv(document, usecols=['text','location'],)\ndf = df.append(file.rename({'text': 'body_text'}, axis=1))\nfile= pd.read_csv('SAP21786-tweets.csv', usecols=['content'])\ndf = df.append(file.rename({'content': 'body_text'}, axis=1))\nwith open('tweets.csv',errors = 'ignore',) as document:\n    file= pd.read_csv(document, usecols=['full_text','location'], )\ndf = df.append(file.rename({'full_text': 'body_text'}, axis=1))\nfile= pd.read_csv('Tweets_by_Faizan_Hussain_21409.csv', usecols=['TweetText','City'])\ndf = df.append(file.rename({'TweetText':'body_text','City':'location'}, axis=1))\nwith open('tweets_data.csv',errors = 'ignore',) as document:\n    file= pd.read_csv(document, usecols=['full_text','location'], )\ndf = df.append(file.rename({'full_text':'body_text'}, axis=1))\nfile= pd.read_csv('tweets_new.csv', usecols=['content'])\ndf = df.append(file.rename({'content':'body_text'}, axis=1))\nfile= pd.read_csv('tweets_pakistan-AhmedAdnan-11177.csv', usecols=['tweet'])\ndf = df.append(file.rename({'tweet':'body_text'}, axis=1))\nwith open('tweets_pakistan.csv',errors = 'ignore',) as document:  \n    file= pd.read_csv(document, usecols=['full_text','location'], )\ndf = df.append(file.rename({'full_text':'body_text'}, axis=1))\nwith open('twitter dataset.csv',errors = 'ignore',) as document:    \n    file= pd.read_csv(document, usecols=['full_text','location'], encoding ='uft-8')\ndf = df.append(file.rename({'full_text':'body_text'}, axis=1))\nfile= pd.read_excel('AmmarKhalil_19689_DeepLearning_finalPaper_part1.xlsx', usecols=['Text','Location'])\ndf = df.append(file.rename({'Text':'body_text',\"Location\":'location'}, axis=1))\nfile= pd.read_excel('FinalExam_Part1_deeplearning_Komalbatool_30342_4July21.xlsx', usecols=['Tweet','Location'])\ndf = df.append(file.rename({'Tweet':'body_text',\"Location\":'location'}, axis=1))\nfile= pd.read_excel('tweets_datasete.xlsx', usecols=['Tweet','Location'])\ndf = df.append(file.rename({'Tweet':'body_text',\"Location\":'location'}, axis=1))\nfile= pd.read_excel('Twitter Dataset (Mohsin Suleman 25752).xlsx', usecols=['Tweet'])\ndf = df.append(file.rename({'Tweet':'body_text'}, axis=1))\nfile= pd.read_excel('Zeshan Masood SAP_ID 21709.xlsx', sheet_name=1,usecols=['tweet'])\ndf = df.append(file.rename({'tweet':'body_text'}, axis=1))","3d604342":"df = df.dropna(subset = ['body_text'])\ndf = df.drop_duplicates(subset = ['body_text'])\ndf","1af5b4ae":"len(df)","aac9e1de":"location = df.groupby('location').count()\nlocation.sort_values(by='body_text', ascending=False).iloc[0]","3890d9de":"df.groupby('location').count().sort_values(by='body_text').iloc[-1]","69629fac":"\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport emoji\n\nbody_text = \" \".join(df['body_text'].values)","94d7cd95":"c = WordCloud(width =2000,height =1600).generate(body_text)\n\nplt.figure(figsize=(20, 16))\nplt.imshow(c)\n","6f1c4ab2":"e = WordCloud(font_path='Symbola.ttf', regexp=emoji.get_emoji_regexp('en'), width=2000, \n               height=1500).generate(body_text)\nplt.figure(figsize=(20, 16))\nfig = plt.imshow(e)","c5877c55":"# files gathered from\n# https:\/\/github.com\/shekhargulati\/sentiment-analysis-python\/tree\/master\/opinion-lexicon-English\n\nwith open('positive-words.txt', 'r') as document:\n    positive = document.readlines()\n    positive = [x.strip() for x in positive]\nwith open('negative-words.txt', 'r') as document:\n    negative = document.readlines()\n    negative = [x.strip() for x in negative]\n\n\n\ncount_positive = 0\ncount_negative = 0\nfor x in body_text.split():\n    if x in positive:\n        count_positive +=1\n    \n    if x in negative:\n        count_negative +=1\n\nplt.bar(height=[count_positive, count_negative], x=['positive', 'negative'])","53f74d02":"with open('abusive.csv') as f:\n    abusive = f.readlines()\nabusive = [x.strip()  for x in abusive]\nabusive_c={}\nfor x in abusive:\n    for y in body_text.split():\n        if x == y:\n            if not x in abusive_c.keys():\n                abusive_c[x] = 1\n            else:\n                abusive_c[x] += 1","ad107d4d":"abuse =pd.DataFrame({'abuseive_words':abusive_c.keys(),'counts':abusive_c.values()})","086a6832":"abuse.sort_values(by = 'counts').iloc[-13:-2]","4dedacf2":"# Emoji\n","0d9132c0":"# Abusive\n","53fa7716":"# duplicate records\n","b79f9515":"# cloud\n","d76810d1":"# location\n","ea114720":"# Positive\/negative words\n","ef552d52":"# Merge dataset \n","2f07e45d":"# tweets in the dataset\n"}}