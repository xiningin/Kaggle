{"cell_type":{"d2cd162f":"code","012cbf90":"code","21dacf8c":"code","14ba6651":"code","b49e20b3":"code","cd2db389":"code","6aa1b49c":"code","e525c9f1":"code","66120c73":"code","82c5b2f2":"code","e394eb51":"code","d555ba95":"code","972ee0fe":"code","bac4acb7":"code","5cc99a4a":"code","5b185d70":"code","fa95fcf8":"code","0032b2a0":"markdown","b7e9c5c9":"markdown","86f1fc78":"markdown","146096b0":"markdown","69521687":"markdown","e7deb995":"markdown","007be32d":"markdown","77dd6085":"markdown","014e3018":"markdown","84675c53":"markdown","dcbe81b9":"markdown","a1f985b1":"markdown"},"source":{"d2cd162f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","012cbf90":"train_df = pd.read_csv(\"\/kaggle\/input\/ag-news-classification-dataset\/train.csv\")\nprint(train_df.shape)\n\ntest_df = pd.read_csv(\"\/kaggle\/input\/ag-news-classification-dataset\/test.csv\")\nprint(test_df.shape)","21dacf8c":"train_df.info()","14ba6651":"test_df.info()","b49e20b3":"train_df['Class Index'].value_counts()","cd2db389":"df = pd.DataFrame()\ndf['text'] = train_df['Description']\ndf['label'] = train_df['Class Index']","6aa1b49c":"df['label'] = df['label'].apply(lambda x : x -1)\ndf['label'].value_counts()","e525c9f1":"pip install simpletransformers","66120c73":"from simpletransformers.classification import ClassificationModel\n\nmodel = ClassificationModel('bert', 'bert-base-cased', num_labels=4,\nargs={'reprocess_input_data': True, 'overwrite_output_dir': True},use_cuda=True)","82c5b2f2":"# 20 % of original dataset\nsmall_df = df.sample(frac =0.5)","e394eb51":"%%time\nmodel.train_model(small_df)","d555ba95":"eval_df = pd.DataFrame()\neval_df['text'] = test_df['Description']\neval_df['label'] = test_df['Class Index']\n\neval_df['label'] = eval_df['label'].apply(lambda x : x -1)\neval_df['label'].value_counts()","972ee0fe":"result, model_outputs, wrong_predictions = model.eval_model(eval_df)","bac4acb7":"print(result)\nprint(model_outputs)","5cc99a4a":"lst = []\nfor arr in model_outputs:\n    lst.append(np.argmax(arr))\ntrue = eval_df['label'].tolist()\npredicted = lst","5b185d70":"import sklearn\nprint(sklearn.metrics.classification_report(true,predicted,target_names=['World','Sports','Business','Sci\/Tech']))\n","fa95fcf8":"sklearn.metrics.accuracy_score(true,predicted)","0032b2a0":"# Reading the train and test files","b7e9c5c9":"### Evaluate the model","86f1fc78":"## Missing values analysis","146096b0":"### Since this is a balanced dataset  - Accuracy is a good measure of model performance","69521687":"## preparing training data\n\n### Please note - we are doing a baseline using PyTorch and BERT and hence we are not doing any text preprocessing","e7deb995":"### Target variable \n\n### There are 4 types of news \n\n### The class ids are numbered 1-4 where \n#### 1 represents World, 2 represents Sports, 3 represents Business and 4 represents Sci\/Tech.","007be32d":"## Install simple transformers","77dd6085":"### Since the labels are starting from 1 to N - we need to map it to 0 to N-1 , so that we dont get \"CUDA error: device-side assert triggered\"","014e3018":"### Great nothing is missing!!!\n","84675c53":"## Configure the simple transformer for classificating the text\n\n### select the bert model you want to train\n### Hardware Accelerator \n### No of labels  - in our case it is 4 ","dcbe81b9":"### Lets begin our training of the model on a smaller dataset","a1f985b1":"### Lets prepare our evalution data set"}}