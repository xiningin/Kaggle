{"cell_type":{"d84cb87d":"code","4cb6ac6c":"code","b49c424a":"code","1aa8d283":"code","1a100594":"code","bee7f65e":"code","417499a4":"code","6528ff4f":"code","6e3b1714":"code","b244bdcc":"code","993cedd5":"code","baba368a":"code","6a45fb29":"code","fa098f8c":"code","3874a5e5":"code","c05fcf9f":"code","ac023b14":"code","e041bdf9":"code","4310f3f3":"markdown","50a5add5":"markdown","96949925":"markdown","96cff167":"markdown","b5a04fbd":"markdown","53ec4bbc":"markdown","07570924":"markdown","b0ad9727":"markdown","d1af3f9c":"markdown","5b3453be":"markdown","869f4660":"markdown","f7195cf1":"markdown"},"source":{"d84cb87d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4cb6ac6c":"train_data = pd.read_csv('\/kaggle\/input\/birds-songs-numeric-dataset\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/birds-songs-numeric-dataset\/test.csv')\nprint(\"train data shape is:\",train_data.shape)\nprint(\"test data shape is:\",test_data.shape)\nprint(\"columns are:\")\nprint(train_data.columns)","b49c424a":"#from pandas_profiling import ProfileReport\n#profile = ProfileReport(df = train_data,\n#                        title = \"Pandas Profiling Report\",\n#                        interactions = None)\n#r = ProfileReport(df = train_data,samples=None, correlations=[], missing_diagrams=None, interactions=None)\n#print(profile)","1aa8d283":"profile = ProfileReport(df = train_data,minimal = True)","1a100594":"profile.to_file(\"output.html\")","bee7f65e":"from IPython.core.display import HTML,display\ndisplay(HTML(filename=\"output.html\"))","417499a4":"from IPython.display import IFrame,display\ndisplay(IFrame(src='output.html', width=700, height=600))","6528ff4f":"!pip install lazypredict","6e3b1714":"from sklearn.utils import shuffle\ntrain_data = shuffle(train_data)\ntest_data = shuffle(test_data)\nY_train = train_data['species']\nY_test = test_data['species']\ntrain_data = train_data.drop(['id','species','genus'],axis = 1)\ntest_data = test_data.drop(['id','species','genus'],axis = 1)","b244bdcc":"from lazypredict.Supervised import LazyClassifier\nclf = LazyClassifier(verbose = 0, ignore_warnings = True,custom_metric = None)\nmodels,predictions = clf.fit(train_data,test_data,Y_train,Y_test)\nprint(models)","993cedd5":"bird_names = list(Y_train.unique())\nprint(bird_names)\nprint(len(bird_names))","baba368a":"Y_train_encoded = []\nfor el in Y_train:\n    Y_train_encoded.append(bird_names.index(el))","6a45fb29":"print(Y_train_encoded)","fa098f8c":"Y_test_encoded = []\nfor el in Y_test:\n    Y_test_encoded.append(bird_names.index(el))","3874a5e5":"print(Y_test_encoded[-200:-100])","c05fcf9f":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=128, criterion='gini', max_depth=14, min_samples_split=2, \n                             min_samples_leaf=2, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n                             min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=True, n_jobs=None, \n                             random_state=None, verbose=0, warm_start=False, class_weight='balanced', ccp_alpha=0.0, max_samples=None)\n\nrfc.fit(train_data,Y_train_encoded)","ac023b14":"print(rfc.oob_score_)","e041bdf9":"from sklearn.metrics import classification_report\nY_pred_test = rfc.predict(test_data)\nprint(classification_report(Y_test_encoded,Y_pred_test))","4310f3f3":"Trying to check what ways work for showing the output.","50a5add5":"well it works. But we will try another method too, given sometimes the first one doesn't work in some notebook environments according to stackoverflow.","96949925":"This also creates same result. Now we move on to lazypredict for now.","96cff167":"This doesn't work.","b5a04fbd":"## Automl classification exercise with lazypredict:\nIn this notebook, I will be using the automl library lazypredict, to explore and classify the birds song dataset. We will check the different model outputs and then finally build one model which gets best result in the lazypredict model.\n### tech stack used:\npandas profiling for data visualization and exploration<br\/>\n[lazypredict](https:\/\/github.com\/shankarpandala\/lazypredict) for automl and model choosing<br\/>\nsklearn for final modeling<br\/>","53ec4bbc":"#### (1) trying Ipython.core.display's display, HTML methods","07570924":"### let's visualize the data using pandas profiling","b0ad9727":"Let's see if minimal works.","d1af3f9c":"So in minimal version, we can't see the output. But you can download the output.html and open to see the output.","5b3453be":"So we successfully achieved 98% F1-score in classifying the birds with chromogram data and we reached the fast model selection using lazypredict's cool use. I will try to derive how chromogram is calculated and spec_ratio is determined; and if we can derive them from the picture itself; so that we can build an app for bird classification. But that's for another day! for now ciao!","869f4660":"So clearly RandomForestClassifier is the correct model to go with. But before doing that, we need to turn the Y_train into codes as the names will not be processed by sklearn library.","f7195cf1":"Also,let's change Y_test as well."}}