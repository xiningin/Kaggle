{"cell_type":{"3d74ea00":"code","527b5841":"code","2d9a0117":"code","24a50e35":"code","0ffd6cd7":"code","82569a3c":"code","c5fe145b":"code","cfddcdef":"code","c7ed5d38":"code","eea451a9":"code","0c6ac14b":"code","21a9090c":"code","33ef07c9":"code","d76d3d04":"code","a5e47ca6":"code","6ee3765a":"code","f3a5d591":"code","35706b18":"code","3a8aa6a7":"code","ecc3de7c":"code","28186c9a":"code","6fcf2139":"code","6fbac1f5":"code","2feb1d3b":"code","486f2ba8":"code","e77db2c8":"code","fdef3028":"code","198303d5":"code","27363d54":"code","8d9e92dc":"code","2e119733":"code","1a222ea0":"code","3c63a1e2":"markdown","44a2b068":"markdown","54a3c81b":"markdown","d9718f8d":"markdown","a2cf1201":"markdown","62675210":"markdown","5c4c8b17":"markdown","c3f90b04":"markdown","3eb88ca4":"markdown","7124877f":"markdown","5c2a2b6a":"markdown"},"source":{"3d74ea00":"import tensorflow as tf \nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport glob\nimport pydot\nimport datetime\nimport pandas as pd","527b5841":"imgs_path = glob.glob('..\/input\/csicdataset\/train\/image\/*.bmp')\nlabels_path = glob.glob('..\/input\/csicdataset\/train\/label\/*.bmp')\nimgs_path.sort(key=lambda imgs_path:int(imgs_path.split('image\/')[-1].split('.bmp')[0]))\nlabels_path.sort(key=lambda labels_path:int(labels_path.split('label\/')[-1].split('.bmp')[0]))\n\n\nval_imgs_path = glob.glob('..\/input\/csicdataset\/val\/image\/*.bmp')\nval_labels_path =glob.glob('..\/input\/csicdataset\/val\/label\/*.bmp')\nval_imgs_path.sort(key=lambda val_imgs_path:int(val_imgs_path.split('image\/')[-1].split('.bmp')[0]))\nval_labels_path.sort(key=lambda val_labels_path:int(val_labels_path.split('label\/')[-1].split('.bmp')[0]))\nimgs_path,labels_path,val_imgs_path,val_labels_path","2d9a0117":"index= np.random.permutation(len(imgs_path))\nimgs_path =np.array(imgs_path)[index]\nlabels_path =np.array(labels_path)[index]\nimgs_path","24a50e35":"train_dataset_path = tf.data.Dataset.from_tensor_slices((imgs_path,labels_path))\nval_dataset_path = tf.data.Dataset.from_tensor_slices((val_imgs_path,val_labels_path))","0ffd6cd7":"def process_img(img_path,label_path):\n    \n    img = tf.io.read_file(img_path)\n    mask = tf.io.read_file(label_path)\n    img = tf.image.decode_bmp(img,channels=1)\n    mask = tf.image.decode_bmp(mask,channels=1)\n    img = tf.cast(img,tf.float32)\n    mask = tf.cast(mask,tf.int32)\n    \n    return img,mask\n","82569a3c":"train_count = len(imgs_path)\nval_count = len(val_imgs_path)\nbat_size = 8\nbuf_size = 300\nstps_per_epoch = train_count\/\/bat_size\nval_stps = val_count\/\/6","c5fe145b":"auto = tf.data.experimental.AUTOTUNE","cfddcdef":"train_dataset = train_dataset_path.map(process_img,num_parallel_calls=auto)\nval_dataset = val_dataset_path.map(process_img,num_parallel_calls=auto)","c7ed5d38":"train_dataset = train_dataset.shuffle(buf_size).batch(bat_size).repeat()\nval_dataset = val_dataset.batch(6)","eea451a9":"for img ,label in train_dataset.take(1):   \n    plt.figure()\n    plt.subplot(1,2,1)\n    plt.imshow(tf.squeeze(img[0]),cmap='gray')\n    plt.axis('off')\n    plt.subplot(1,2,2)\n    plt.imshow(tf.squeeze(label[0]),cmap='gray')\n    plt.axis('off')","0c6ac14b":"#\u7f16\u7801\u6a21\u5757\ninput = tf.keras.layers.Input(shape=(512,512,1))\n\nen1 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu')(input)\nen1 = tf.keras.layers.BatchNormalization()(en1)\nen1 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu')(en1)\nen1 = tf.keras.layers.BatchNormalization()(en1) #512*512*16\n\nen2= tf.keras.layers.MaxPool2D()(en1) #256*256*16\n\nen2 = tf.keras.layers.Conv2D(64,3,padding='same',activation='relu')(en2)\nen2 = tf.keras.layers.BatchNormalization()(en2)\nen2 = tf.keras.layers.Conv2D(64,3,padding='same',activation='relu')(en2)\nen2 = tf.keras.layers.BatchNormalization()(en2) #256*256*32\n\nen3 = tf.keras.layers.MaxPool2D()(en2) #128*128*32\n\nen3 = tf.keras.layers.Conv2D(128,3,padding='same',activation='relu')(en3)\nen3 = tf.keras.layers.BatchNormalization()(en3)\nen3 = tf.keras.layers.Conv2D(128,3,padding='same',activation='relu')(en3)\nen3 = tf.keras.layers.BatchNormalization()(en3) #128*128*64\n\nen4= tf.keras.layers.MaxPool2D()(en3) #64*64*64\n\nen4 = tf.keras.layers.Conv2D(256,3,padding='same',activation='relu')(en4)\nen4 = tf.keras.layers.BatchNormalization()(en4)\nen4 = tf.keras.layers.Conv2D(256,3,padding='same',activation='relu')(en4)\nen4 = tf.keras.layers.BatchNormalization()(en4) #64*64*128\n\nen5 = tf.keras.layers.MaxPool2D()(en4) #32*32*128\n\nen5 = tf.keras.layers.Conv2D(512,3,padding='same',activation='relu')(en5)\nen5 = tf.keras.layers.BatchNormalization()(en5)\nen5 = tf.keras.layers.Conv2D(512,3,padding='same',activation='relu')(en5)\nen5 = tf.keras.layers.BatchNormalization()(en5) #32*32*256 \n\n\n#\u89e3\u7801\u6a21\u5757\nde4 = tf.keras.layers.Conv2DTranspose(256,2,strides=2, \n                                    padding='same',activation='relu')(en5)\nde4 = tf.keras.layers.BatchNormalization()(de4)\n \nde4 = tf.concat([en4,de4],axis=-1)\n\nde4 = tf.keras.layers.Conv2D(256,3,padding='same',activation='relu')(de4)\nde4 = tf.keras.layers.BatchNormalization()(de4)\nde4 = tf.keras.layers.Conv2D(256,3,padding='same',activation='relu')(de4)\nde4 = tf.keras.layers.BatchNormalization()(de4) #64*64*128\n\nde3 = tf.keras.layers.Conv2DTranspose(128,2,strides=2, \n                                    padding='same',activation='relu')(de4)\nde3 = tf.keras.layers.BatchNormalization()(de3)\n\nde3 = tf.concat([en3,de3],axis=-1)\n\nde3 = tf.keras.layers.Conv2D(128,3,padding='same',activation='relu')(de3)\nde3 = tf.keras.layers.BatchNormalization()(de3)\nde3 = tf.keras.layers.Conv2D(128,3,padding='same',activation='relu')(de3)\nde3 = tf.keras.layers.BatchNormalization()(de3) #128*128*64\n\n\nde2 = tf.keras.layers.Conv2DTranspose(64,2,strides=2, \n                                    padding='same',activation='relu')(de3)\nde2 = tf.keras.layers.BatchNormalization()(de2)\n\nde2 = tf.concat([en2,de2],axis=-1)\n\nde2 = tf.keras.layers.Conv2D(64,3,padding='same',activation='relu')(de2)\nde2 = tf.keras.layers.BatchNormalization()(de2)\nde2 = tf.keras.layers.Conv2D(64,3,padding='same',activation='relu')(de2)\nde2 = tf.keras.layers.BatchNormalization()(de2) #256*256*32\n\nde1 = tf.keras.layers.Conv2DTranspose(32,2,strides=2, \n                                    padding='same',activation='relu')(de2)#512*512*16\nde1 = tf.keras.layers.BatchNormalization()(de1)\n\nde1 = tf.concat([en1,de1],axis=-1)#512*512*32\n\nde1 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu')(de1)\nde1 = tf.keras.layers.BatchNormalization()(de1)\nde1 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu')(de1)\nde1 = tf.keras.layers.BatchNormalization()(de1) #512*512*16\n\nde1 = tf.keras.layers.Conv2D(2,3,padding='same',activation='relu')(de1)\noutput = tf.keras.layers.Conv2D(1,1,padding='same',activation='sigmoid')(de1)","21a9090c":"model = tf.keras.Model(inputs=input,outputs=output)","33ef07c9":"model.summary()","d76d3d04":"class MeanIoU(tf.keras.metrics.MeanIoU):\n    def __call__(self,y_true,y_pred,sample_weight=None):\n        y_pred = tf.where(y_pred <= 0.5,x = 0,y = 1)\n        return super().__call__(y_true,y_pred,sample_weight=sample_weight)\n    \n    ","a5e47ca6":"model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n          loss='binary_crossentropy',\n          metrics=['acc']\n)","6ee3765a":"def scheduler(epoch, lr):\n  if (epoch+1)%5 ==0:\n    return lr*0.95\n  else:\n    return lr \n\n","f3a5d591":"# earlystopcallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,mode='min')\nlearnratecallback = tf.keras.callbacks.LearningRateScheduler(scheduler)","35706b18":"epchs = 40","3a8aa6a7":"history =model.fit(train_dataset,\n                   epochs = epchs,\n                   steps_per_epoch = stps_per_epoch,\n                   validation_steps = val_stps,\n                   validation_data = val_dataset,\n                   callbacks = [learnratecallback]\n                  )","ecc3de7c":"round(model.optimizer.lr.numpy(), 10)","28186c9a":"def preprocess_label(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.io.decode_bmp(img,channels=1)\n    img = tf.cast(img,tf.int32)\n    img = tf.expand_dims(img,axis=0)\n    img = img.numpy()    \n    return img","6fcf2139":"def preprocess_img(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.io.decode_bmp(img,channels=1)\n    img = tf.cast(img,tf.float32)\n    return img","6fbac1f5":"test_img_dataset = tf.data.Dataset.from_tensor_slices(val_imgs_path).map(preprocess_img,num_parallel_calls=auto).batch(6)\n\ntest_pred_dataset = model.predict(test_img_dataset)\n\nlabels = np.concatenate([preprocess_label(img_path) for img_path in val_labels_path],axis=0)\n\nm = MeanIoU(num_classes=2)\nm(labels, test_pred_dataset)","2feb1d3b":"save_filename = 'Unet5-Case1'\ntf.io.gfile.mkdir('.\/{}'.format(save_filename))","486f2ba8":"model.save('{}\/{}.h5'.format(save_filename,save_filename))\npf = pd.DataFrame(history.history)\npf.to_excel('{}\/{}.xlsx'.format(save_filename,save_filename))","e77db2c8":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nplt.figure()\nplt.plot(history.epoch,loss,'r',label='Training loss')\nplt.plot(history.epoch,val_loss,'bo',label='Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss Value')\nplt.legend()\nplt.savefig('{}\/{}_Loss.png'.format(save_filename,save_filename))","fdef3028":"loss = history.history['acc']\nval_loss = history.history['val_acc']\nplt.figure()\nplt.plot(history.epoch,loss,'r',label='Training Accuracy')\nplt.plot(history.epoch,val_loss,'bo',label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy Value')\nplt.legend()\nplt.savefig('{}\/{}_Accuracy.png'.format(save_filename,save_filename))","198303d5":"# loss = history.history['mean_io_u']\n# val_loss = history.history['val_mean_io_u']\n# plt.figure()\n# plt.plot(history.epoch,loss,'r',label='Training MeanIoU')\n# plt.plot(history.epoch,val_loss,'bo',label='Validation MeanIoU')\n# plt.title('Training and Validation MeanIoU')\n# plt.xlabel('Epoch')\n# plt.ylabel('MeanIoU Value')\n# plt.legend()\n# plt.savefig('{}\/{}_MeanIoU.png'.format(save_filename\uff0csave_filename))","27363d54":"jishu = 1\nfor val_img_path ,val_label_path in zip(val_imgs_path[0:60:10], val_labels_path[0:60:10]):\n    \n    val_img = tf.io.read_file(val_img_path)\n    val_img = tf.io.decode_bmp(val_img)\n    \n    val_img = tf.cast(val_img,tf.float32)\n\n#     print(np.max(np.array(val_img1)))\n#     print(np.max(np.array(val_img2)))\n    \n    val_label = tf.io.read_file(val_label_path)\n    val_label = tf.io.decode_bmp(val_label)\n    val_label = tf.cast(val_label,tf.int32)\n    \n    val_img_pred = model.predict(tf.expand_dims(val_img,0))\n\n\n    plt.figure(figsize=(3,3),dpi=300)\n    \n\n    plt.subplot(1,3,1)\n    plt.imshow(tf.squeeze(val_img),vmin=0,vmax=255,cmap='gray')\n    plt.axis('off')\n    \n    plt.subplot(1,3,2)\n    plt.imshow(tf.squeeze(val_label))\n    plt.axis('off')\n    \n    plt.subplot(1,3,3)\n    plt.imshow(tf.squeeze(val_img_pred > 0.5))\n    plt.axis('off')\n    \n    \n  \n    plt.savefig('{}\/{}_{}.png'.format(save_filename,save_filename,jishu))\n    jishu =jishu +1\n","8d9e92dc":"# import time\n# img0 = tf.io.read_file(val_imgs_path[10])\n# img0 = tf.io.decode_bmp(img0)\n# img0 = tf.cast(img0\/255,tf.float32)\n# img_pred = model.predict(tf.expand_dims(img0,0))\n# time = time.process_time()","2e119733":"# test_imgs_path = tf.io.gfile.glob(r'C:\\Users\\chenyh\\Desktop\\dataset\\test\\image\\*.bmp')\n# test_imgs_path.sort(key=lambda imgs_path:int(imgs_path.split('image\\\\')[-1].split('.bmp')[0]))","1a222ea0":"# jishu = 1\n# for test_img_path in test_imgs_path :\n#     img = tf.io.read_file(test_img_path)\n#     img = tf.io.decode_bmp(img)\n#     img = tf.cast(img,tf.float32)\n#     img_pred = model.predict(tf.expand_dims(img,0))\n#     img_pred_path = os.path.join(r\"C:\\Users\\chenyh\\Desktop\\dataset\\unet3_test_label\",'%d.jpeg'%jishu)\n#     plt.imsave(img_pred_path,tf.squeeze(img_pred>0.5))\n#     jishu = jishu+1\n\n# #     img_pred = tf.where(img_pred < 0.5,x = 0,y =1)\n# #     img_pred = tf.squeeze(img_pred,0)    \n# #     img_pred = tf.cast(255*img_pred,tf.uint8)\n# #     img_pred = tf.io.encode_jpeg(img_pred)    \n# #     tf.io.write_file(img_pred_path,img_pred)","3c63a1e2":"import math\nbce = tf.keras.losses.BinaryCrossentropy()\nloss = bce([0, 1], [0.1, 0.8])\nif groundtruth = 1:\n(1)*math.log(0.8) (1)*log(0.8)\nif groundtruth = 0:\n(1-0)*math.log(0.9) (1-0)*log(1-0.1)\nloss = ((1-0)*math.log(0.9)+(1)*math.log(0.8))\/2\nloss = plog(q)+(1-p)log(1-q)","44a2b068":"def preprocess_label(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.io.decode_bmp(img,channels=1)\n    img = tf.cast(img,tf.int32)\n    img = tf.expand_dims(img,axis=0)\n    img = img.numpy()    \n    return img","54a3c81b":"test_pred_dataset = new_model.predict(test_img_dataset)","d9718f8d":"l =tf.keras.losses.BinaryCrossentropy()(labels, test_pred_dataset)\nl","a2cf1201":"labels = np.concatenate([preprocess_label(img_path) for img_path in val_labels_path],axis=0)\nlabels.shape,test_pred_dataset.shape","62675210":"new_model = tf.keras.models.load_model('.\/Unet3-Case2.h5')","5c4c8b17":"test_img_dataset = tf.data.Dataset.from_tensor_slices(val_imgs_path).map(preprocess_img,num_parallel_calls=auto).batch(6)","c3f90b04":"n = MeanIoU(num_classes=2)\nn(labels, test_pred_dataset)","3eb88ca4":"m = tf.keras.metrics.MeanIoU(num_classes=2)\nm(labels, test_pred_dataset)","7124877f":"def preprocess_img(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.io.decode_bmp(img,channels=1)\n    img = tf.cast(img,tf.float32)\n    return img","5c2a2b6a":"acc =tf.keras.metrics.BinaryAccuracy()(labels, test_pred_dataset)\nacc"}}