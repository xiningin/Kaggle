{"cell_type":{"b47e383c":"code","ef5030ae":"code","41dfa083":"code","edeacde3":"code","a734515c":"code","5d0baa96":"code","355e5c3a":"code","58e1c19d":"code","33e138a0":"code","ba7209ab":"code","89ab4684":"code","1759e57c":"code","609e893d":"code","41e3de02":"code","40e84ac0":"code","72e98dc0":"code","4d85d22b":"code","176de33f":"code","c61ff633":"code","382873b3":"code","74587fd5":"code","05075919":"code","c714fd38":"code","900a2b0f":"code","8e1c74ae":"code","eff31369":"code","a4158f31":"code","62ba4fc6":"code","b547f905":"code","7a653278":"code","cf67b922":"code","bf70e7d9":"code","ff67e69d":"code","c5ff5fd7":"code","5e9839d9":"code","89f00195":"code","218e439b":"code","79e1b475":"code","cd1def43":"code","0d544a86":"markdown"},"source":{"b47e383c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef5030ae":"FILEPATH = '\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv'","41dfa083":"df = pd.read_csv(FILEPATH, encoding='iso-8859-1', engine = 'c') # engine 'c' used instead of 'python' for higher performance\ndf.head(10)","edeacde3":"# delete unnecessary cols\ncols = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n\ndf.drop(cols, axis = 1, inplace = True)","a734515c":"df.head()","5d0baa96":"# Title change v1 = result, v2 = input\n\ndf.rename(columns={'v1':'Classification','v2':'Sms content'},inplace=True)\n\n# we can also use df.rename() option here","355e5c3a":"df.head()","58e1c19d":"# reorder options - must be applicable for all cols\ndf = df[['Sms content','Classification']]\n ","33e138a0":"df.head()","ba7209ab":"df.head()","89ab4684":"df.count()\n","1759e57c":"df.describe()","609e893d":"# print first string\n\ndf.iloc[0][0]","41e3de02":"df.iloc[2][0]","40e84ac0":"def message_length(msg):\n    \n    msg_words = msg.split(' ')\n    \n    msg_len = len(msg_words)\n    \n    return msg_len","72e98dc0":"print(message_length(df.iloc[1][0]))","4d85d22b":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['words_count'] = df['Sms content'].apply(message_length)\ndf.head()\n\n\n# ref: https:\/\/rajacsp.github.io\/mlnotes\/python\/data-wrangling\/advanced-custom-lambda\/","176de33f":"# show the unique labels\n\ndf['Classification'].unique()","c61ff633":"print(find_length(df.iloc[0][0]))","382873b3":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['msg_length'] = df['Sms content'].apply(lambda x:len(x))\ndf.head()","74587fd5":"# History words count\n\nimport matplotlib.pyplot as plt\n\n# to avoid popups use inline\n%matplotlib inline ","05075919":"# plt.hist(data['label'], bins=3, weights=np.ones(len(data['label'])) \/ len(data['label']))\n\nimport numpy as np\n\nplt.hist(df['words_count'], bins = 50, alpha=0.5)\nplt.hist(df['msg_length'], bins=50 ,alpha=0.3)\nplt.xlabel('Word Length')\nplt.ylabel('Group Count')\nplt.title('Word Length Histogram')","c714fd38":"# Find more than 80 words\ndf['words_count']","900a2b0f":"df1 = df[(df['words_count'] > 80) & (df['msg_length'] > 100)]\n","8e1c74ae":"df1","eff31369":"# encode\nfrom sklearn import preprocessing\n\nencode = preprocessing.LabelEncoder()\ndf['find spam'] = encode.fit_transform(df['Classification'])\ndf","a4158f31":"import string\nstring.punctuation","62ba4fc6":"def remove_punctuation(text):\n    new_text=''.join([char for char in text if char not in string.punctuation])\n    return new_text","b547f905":"df['new_sms']=df['Sms content'].apply(lambda row : remove_punctuation(row))\ndf","7a653278":"import re\ndef tokenize(text):\n    tokens=re.split('\\W+',text)\n    return tokens ","cf67b922":"df['tokenized_text']=df['new_sms'].apply(lambda row : tokenize(row.lower()))\ndf.head()","bf70e7d9":"import nltk\nstopwords=nltk.corpus.stopwords.words('english')\nstopwords[:5]","ff67e69d":"def remove_stopwords(text):\n    clean_text=[word for word in text if word not in stopwords]\n    return clean_text ","c5ff5fd7":"df['clean_text'] = df['tokenized_text'].apply(lambda row : remove_stopwords(row))\ndf.head()","5e9839d9":"ps = nltk.PorterStemmer()\ndir(ps)","89f00195":"\nfrom nltk.stem import PorterStemmer\ndef stemming(tokenized_text):\n    stemmed_text=[ps.stem(word) for word in tokenized_text]\n    return stemmed_text","218e439b":"df['stemmed_text']=df['clean_text'].apply(lambda row : stemming(row))\ndf[['Sms content','stemmed_text']].head()","79e1b475":"def get_final_text(stemmed_text):\n    final_text=\" \".join([word for word in stemmed_text])\n    return final_text","cd1def43":"df['final_text']=df['stemmed_text'].apply(lambda row : get_final_text(row))\ndf.head()","0d544a86":"Source:\n\nhttps:\/\/docs.python.org\/3\/library\/codecs.html#standard-encodings\n\nhttps:\/\/www.kaggle.com\/devghiles\/step-by-step-solution-with-f1-score-as-a-metric\n\nhttps:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_csv.html\n\nTo rename:\nhttps:\/\/stackoverflow.com\/questions\/11346283\/renaming-columns-in-pandas\n\nTo change cols:\nhttps:\/\/stackoverflow.com\/questions\/12329853\/how-to-rearrange-pandas-column-sequence\/23741704\n\nhttps:\/\/rajacsp.github.io\/mlnotes\/python\/data-wrangling\/advanced-custom-lambda\/\n"}}