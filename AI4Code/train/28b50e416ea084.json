{"cell_type":{"f63dc9a7":"code","72eec3cf":"code","502c73d0":"code","bbcfaac7":"code","ef0693c3":"code","3783fa00":"code","74216864":"code","70d5e423":"code","101e1007":"code","3030c6b6":"code","55b00e92":"code","d2c0e4ae":"code","9d8ab183":"code","4f9ef59c":"code","c5bc83a2":"code","2e4f66c9":"code","85cf9067":"code","85f5d3f2":"code","77026db0":"code","9c6b8552":"code","1e25ee6f":"code","377aa3a4":"code","76c00723":"code","f368ec98":"code","be78ae58":"code","40384dd0":"code","2b74c43b":"markdown","31fff478":"markdown","085c261e":"markdown","6f56c257":"markdown","42dacb50":"markdown","f9c885fd":"markdown","a8fa98f4":"markdown","f656d836":"markdown","d5250444":"markdown","dfd07c79":"markdown","1090ae62":"markdown","f5db0734":"markdown","36971319":"markdown","3b02472c":"markdown","cf056107":"markdown","832cf4e3":"markdown","337a9127":"markdown","848e9acb":"markdown","1dd74282":"markdown","766a1ab4":"markdown","4e267383":"markdown","1c68738f":"markdown","76ffd460":"markdown","8644a4a4":"markdown","88650a9d":"markdown","03850db4":"markdown","d97d7228":"markdown","9e1e98e3":"markdown","10a82b96":"markdown","e50b1a63":"markdown","a4cee08b":"markdown","3badb1bb":"markdown","e89bf418":"markdown","85cd9a8a":"markdown","c6a3bf8a":"markdown"},"source":{"f63dc9a7":"### Import libraries\nimport numpy as np\nimport pandas as pd","72eec3cf":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","502c73d0":"print(train.shape)\nntrain = train.shape[0]\n\nprint(test.shape)\nntest = test.shape[0]\n\ntrain.head()","bbcfaac7":"# Check data type\nprint(train.dtypes[:5])       # all int64, other wise do train =  train.astype('int64')\nprint(test.dtypes[:5])        # all int64, other wise do test =  test.astype('int64')","ef0693c3":"# array containing labels of each image\nytrain = train['label']\nprint(\"Shape of ytrain: \", ytrain.shape)\n\n# dataframe containing all pixels ( the label column is dropped)\nxtrain = train.drop(\"label\", axis=1)\n\n# the images are in square from, so dim*dim =784\nfrom math import sqrt\ndim = int(sqrt(xtrain.shape[1]))\nprint(\"The images are {}x{} square.\".format(dim, dim))\n\nprint(\"Shape of xtrain: \", xtrain.shape)","3783fa00":"ytrain.head()","74216864":"import seaborn as sns\nsns.set(style='white', context='notebook', palette='deep')\n\n#plot how many images are there in each class\nsns.countplot(ytrain)\n\nprint(ytrain.shape)\nprint(type(ytrain))\n\n#array with each class and its number of images\nvals_class = ytrain.value_counts()\nprint(vals_class)\n\n#mean and std\ncls_mean = np.mean(vals_class)\ncls_std = np.std(vals_class, ddof=1)\n\nprint(\"The mean amount of elements per class is\", cls_mean)\nprint(\"The standard deviation on the element per class distribution is\", cls_std)\n\n\n# 68% - 95% - 99% rule, the 68% of the data should be cls_std away from the mean and so on\nif cls_std > cls_mean * (0.6827 \/ 2):\n    print(\"The standard deviation is high\")","70d5e423":"def check_nan(df):\n    print(df.isnull().any().describe())\n    print(\"There are missing values\" if df.isnull().any().any() else \"There are no missing values\")\n\n    if df.isnull().any().any():\n        print(df.isnull().sum(axis=0))\n        \n    print()\n        \ncheck_nan(xtrain)\ncheck_nan(test)","101e1007":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\n# convert train dataset to (num_images, img_rows, img_cols) format in order to plot it\nxtrain_vis = xtrain.values.reshape(ntrain, dim, dim)\n\n# https:\/\/matplotlib.org\/api\/_as_gen\/matplotlib.pyplot.subplot.html\n# subplot(2,3,3) = subplot(233)\n# a grid of 3x3 is created, then plots are inserted in some of these slots\nfor i in range(0,9): # how many imgs will show from the 3x3 grid\n    plt.subplot(330 + (i+1)) # open next subplot\n    plt.imshow(xtrain_vis[i], cmap=plt.get_cmap('gray'))\n    plt.title(ytrain[i]);","3030c6b6":"xtrain = xtrain \/ 255.0                                                   # Normalize the data\ntest = test \/ 255.0","55b00e92":"def df_reshape(df):                                                       # reshape of image data to (nimg, img_rows, img_cols, 1)\n    print(\"Previous shape, pixels are in 1D vector:\", df.shape)\n    df = df.values.reshape(-1, dim, dim, 1)                               # -1 means the dimension doesn't change, so 42000 in the case of xtrain and 28000 in the case of test\n    print(\"After reshape, pixels are a 28x28x1 3D matrix:\", df.shape)\n    return df\n\nxtrain = df_reshape(xtrain)                                               # numpy.ndarray type\ntest = df_reshape(test)                                                   # numpy.ndarray type","d2c0e4ae":"from keras.utils.np_utils import to_categorical\n\nprint(type(ytrain))\n# number of classes, in this case 10\nnclasses = ytrain.max() - ytrain.min() + 1\n\nprint(\"Shape of ytrain before: \", ytrain.shape) # (42000,)\n\nytrain = to_categorical(ytrain, num_classes = nclasses)\n\nprint(\"Shape of ytrain after: \", ytrain.shape) # (42000, 10), also numpy.ndarray type\nprint(type(ytrain))","9d8ab183":"from sklearn.model_selection import train_test_split\n\n# fix random seed for reproducibility\nseed = 2\nnp.random.seed(seed)\n\n# percentage of xtrain which will be xval\nsplit_pct = 0.1\n\n# Split the train and the validation set\nxtrain, xval, ytrain, yval = train_test_split(xtrain,\n                                              ytrain, \n                                              test_size=split_pct,\n                                              random_state=seed,\n                                              shuffle=True,\n                                              stratify=ytrain\n                                             )\n\nprint(xtrain.shape, ytrain.shape, xval.shape, yval.shape)","4f9ef59c":"from keras import backend as K\n\n# for the architecture\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPool2D, AvgPool2D\n\n# optimizer, data generator and learning rate reductor\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n","c5bc83a2":"model = Sequential()\n\ndim = 28\nnclasses = 10\n\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(dim,dim,1)))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu',))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(120, activation='relu'))\nmodel.add(Dense(84, activation='relu'))\nmodel.add(Dense(nclasses, activation='softmax'))","2e4f66c9":"model.summary()","85cf9067":"model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","85f5d3f2":"lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                 patience=3, \n                                 verbose=1, \n                                 factor=0.5, \n                                 min_lr=0.00001)","77026db0":"datagen = ImageDataGenerator(\n          featurewise_center=False,            # set input mean to 0 over the dataset\n          samplewise_center=False,             # set each sample mean to 0\n          featurewise_std_normalization=False, # divide inputs by std of the dataset\n          samplewise_std_normalization=False,  # divide each input by its std\n          zca_whitening=False,                 # apply ZCA whitening\n          rotation_range=30,                   # randomly rotate images in the range (degrees, 0 to 180)\n          zoom_range = 0.1,                    # Randomly zoom image \n          width_shift_range=0.1,               # randomly shift images horizontally (fraction of total width)\n          height_shift_range=0.1,              # randomly shift images vertically (fraction of total height)\n          horizontal_flip=False,               # randomly flip images\n          vertical_flip=False)                 # randomly flip images\n\ndatagen.fit(xtrain)","9c6b8552":"epochs = 15\nbatch_size = 64","1e25ee6f":"history = model.fit_generator(datagen.flow(xtrain,ytrain, batch_size=batch_size),\n                              epochs=epochs, \n                              validation_data=(xval,yval),\n                              verbose=1, \n                              steps_per_epoch=xtrain.shape[0] \/\/ batch_size, \n                              callbacks=[lr_reduction])","377aa3a4":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\nax[0].grid(color='black', linestyle='-', linewidth=0.25)\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nax[1].grid(color='black', linestyle='-', linewidth=0.25)\nlegend = ax[1].legend(loc='best', shadow=True)","76c00723":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nypred_onehot = model.predict(xval)\n# Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\nypred = np.argmax(ypred_onehot,axis=1)\n# Convert validation observations from one hot vectors to labels\nytrue = np.argmax(yval,axis=1)\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(ytrue, ypred)\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes=range(nclasses))","f368ec98":"errors = (ypred - ytrue != 0) # array of bools with true when there is an error or false when the image is cor\n\nypred_er = ypred_onehot[errors]\nypred_classes_er = ypred[errors]\nytrue_er = ytrue[errors]\nxval_er = xval[errors]\n\ndef display_errors(errors_index, img_errors, pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n            \n# Probabilities of the wrong predicted numbers\nypred_er_prob = np.max(ypred_er,axis=1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_er = np.diagonal(np.take(ypred_er, ytrue_er, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_er = ypred_er_prob - true_prob_er\n\n# Sorted list of the delta prob errors\nsorted_delta_er = np.argsort(delta_pred_true_er)\n\n# Top 6 errors. You can change the range to see other images\nmost_important_er = sorted_delta_er[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_er, xval_er, ypred_classes_er, ytrue_er)","be78ae58":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","40384dd0":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_predictions.csv\",index=False)","2b74c43b":"<a id=section201><\/a>\n#### 2.1 Load Data\n- __Train__:\n    - Used to __train__ the CNN\n    - __Image data and corresponding class__ is provided\n    - CNN __learns the weights__ to create the mapping from the image data to their corresponding class.\n    \n- Test:\n    - Used to __test__ the CNN\n    - Only __image data__ is provided    ","31fff478":"**Observation**<br><br>\nIn __real world problems__, the dimensions of images could diverge from this particular 28x28x1 set in two ways:\n\n- Images are usually __much bigger__\n\n- In MNIST dataset there is no such problem since the dimensions are already __small__.\n\n- Images __don't__ usually have the __same__ dimensions\n\n- Different dimension images are a problem since dense layers at the end of the __CNN have a fixed number of neurons__, which cannot be dynamically changed. \n- The layer expects __fixed image dimensions__, which means all images must be __resized__ to the same dimensions before training. \n\n- There is another option, namely, using a __FCN (fully convoluted network)__ which consits solely of convolutional layers and a very big pooling in the end, so each image can be of any size, but this architecture isn't as popular as the CNN + FC (fully connected) layers.\n\nThere are __various methods__ to make images have the same dimensions:\n\n- __Resize__ to a fixed dimension\n- __Add padding__ to some images and resize\n","085c261e":"<a id=section207><\/a>\n#### 2.7 Normalization\n- Pixels are represented in the range [0-255].\n- The __NN converges faster__ with smaller values, in the range [0-1] so they are normalized to this range.","6f56c257":"#### Observation\n- __Train__:\n    - Contains data from __42K images__.\n    - Data from each image is stretched out in 1D with __28*28 = 784 pixels__\n    - First columns is the __label\/class__ it belongs, the digit it represnts\n    \n- __Test__:\n    - Contains data from __28k images__.\n    - Data shall be fed to the CNN so that it's new data, that the CNN has never seen before.\n    - There is __no label information__, that is the goal of the notebook, predicting lables as well as possible.\n","42dacb50":"- This is a useful tool which __reduces the learning rate__ when there is a __plateau on a certain value__.\n- In this case the monitoring value is __val_acc__. \n- When there is no change in val_acc in __3 epochs (patience)__, the learning rate is multiplied by __0.5 (factor)__. \n- If the learning rate has the __value of min_lr, it stops decreasing__.","f9c885fd":"<a id=section203><\/a>\n#### 2.3 Extract xtrain, ytrain\n\nThe CNN will be fed xtrain and it will learn the weights to map xtrain to ytrain.","a8fa98f4":"<a id=section3><\/a>\n## 3. CNN\nIn this section the CNN is defined, including \n- Architecture, \n- Optimizers, \n- Metrics, \n- Learning rate reductions, \n- Data augmentation <br>\n\n\nThen it is compiled and fit to the training set.","f656d836":"<a id=section210><\/a>\n#### 2.10 Splitting training and validation datasets","d5250444":"### Table of Content\n- 1. [Introduction](#section1)<br>\n- 2. [Data Pre Processing](#section2)<br>\n    - 2.1 [Load Data](#section201)<br>\n    - 2.2 [Check shape, data type](#section202)<br>\n    - 2.3 [Extract xtrain, ytrain](#section203)<br>\n    - 2.4 [Mean and std of classes](#section204)<br>\n    - 2.5 [Check nulls and missing values](#section205)<br>\n    - 2.6 [Visualization](#section206)<br>\n    - 2.7 [Normalization](#section207)<br>\n    - 2.8 [Reshape](#section208)<br>\n    - 2.9 [One Hot Encoding of label](#section209)<br>\n    - 2.10 [Split training and validation sets](#section210)<br>\n- 3. [Convolutional Neural Network](#section3)<br>\n    - 3.1 [Define model architecture](#section301)<br>\n    - 3.2 [Compile the model](#section302)<br>\n    - 3.3 [Set other parameters](#section303)<br>\n    - 3.4 [Fit model](#section304)<br>\n    - 3.5 [Plot loss and accuracy](#section305)<br>\n    - 3.6 [Plot confusion matrix](#section306)<br>\n    - 3.7 [Plot errors](#section307)<br>","dfd07c79":"```\ndf.isnull().any()\n```\nReturns a df with 1 col and n rows where each row says if there is a NaN value present in that col.","1090ae62":"### Prediction","f5db0734":"```\ndf.isnull()\n```\nReturns a boolean df with true if value is NaN and false otherwise.","36971319":"<a id=section208><\/a>\n#### 2.8 Reshape","3b02472c":"- __Conv2D__<br><br>\n\n    - __filters__: \n        - Usually on the first convolutional layers there are __less filters, and more deeper down the CNN__. \n        - A __power of 2__ is set, and in this case 16 offered poorer performance big CNN was not required for digit recognition.<br><br>\n\n    - __kernel_size__: \n        - The filter size, usually __(3,3) or (5,5)__ is set. \n        - Ii is advised setting one, building the architecture and changing it to __see if it affects the performance__ though it usually doesn't.<br><br>\n\n    - __padding__: Two options\n\n        - _valid padding_: __No__ padding, the image __shrinks__ after convolution.\n        - _same padding_ : Padding of __2__, the image __doesn't shrink__ after convolution.<br><br>\n    - __activation__:\n        - ReLU is represented mathematically by __max(0,X)__ and offers __good performance in CNNs__.<br><br>\n\n- __MaxPool2D__: <br><br>\n    - The goal is to __reduce variance\/overfitting__ and __reduce computational complexity__ since it makes the image smaller. two pooling options\n\n        - MaxPool2D: Extracts the most important features like __edges__\n        - AvgPool2D: Extracts __smooth features__<br><br>\n\n__Conclusion__ is that for binarized images, with noticeable edge differences, __MaxPool performs better__.<br><br>\n\n- __Dropout__:<br><br>\n\n     - It's a useful tool to __reduce overfitting__. \n     - The net becomes __less sensitive__ to the specific weights of __neurons__ and is more capable of better generalization and __less likely to overfit__ to the train data. \n     - The __optimal dropout value in Conv layers is 0.2__, and if you want to implement it in the __dense layers, its optimal value is 0.5__.","cf056107":"#### Epochs and batch size\n- __Epochs__: \n    - Based on experiments, the loss and accuracy get into a plateau at __around the 10th epoch__, so we should usually __set it to 15__.\n- __Batch_size__: \n    - It is recommended to try __changing it and check the change in the loss and accuracy__.\n    - In this case a batch_size of 16 turned out to be disastrous and the __best case__ occurred when it was __set to 64__.","832cf4e3":"**Observation**\n- Shape of __xtrain__ is: (42000, 784)\n- Shape of __ytrain__ is: (42000, )\n- Shape of __test__ is: (28000, 784)\n\n- __Number of classes = 10__, the distribution of the pictures per class has a __mean of 4200 images__ and a __std of 237 images__.\n- The digit 1 has the __most representation (4684 images)__ and the digit 5 __the least (3795 images)__. This data can be seen by printing __vals_class__.\n- This corresponds to a __small standard deviation (5.64%)__ so there is __no class imbalance__.","337a9127":"<a id=section204><\/a>\n#### 2.4 Mean and std of the classes","848e9acb":"<a id=section205><\/a>\n#### 2.5 Check nulls and missing value","1dd74282":"<a id=section304><\/a>\n#### 3.4 Data Augmentation\n- Data augmentation is a technique used to __artificially make the training set bigger__.\n- There are a number of options for this, the __most common ones include__ :\n    - Rotating images, \n    - Zooming in a small range and \n    - Shifting images horizontally and vertically.","766a1ab4":"<a id=section303><\/a>\n#### 3.3 Learning rate annealer","4e267383":"<a id=section307><\/a>\n#### 3.7 Plot errors","1c68738f":"<a id=section2><\/a>\n### 2. Data Pre processing","76ffd460":"<a id=section206><\/a>\n#### 2.6 Visualization","8644a4a4":"<a id=section305><\/a>\n#### 3.5 Plot loss and accuracy","88650a9d":"1. The first nine images in the dataset (which are not ordered by digit) are plotted, just for visualization. \n2. There is only one color channel __(grayscale)__ and moreover the pixels are __binarized__, meaning that they are either __black (0)__ or __white (255)__. \n3. This makes the classification problem __easier__. \n4. Imagine that the CNN received __colored digits__, either solid, gradient, or digits with __many colors__. \n5. Probably __some part of the neural network__ would focus on learning to tell the digits apart by __looking at the colors__, when the __actual difference__ between the digits is in their shape.","03850db4":"# CNN implementation on MNIST dataset using Keras.<br>\n<img src = \"https:\/\/raw.githubusercontent.com\/insaid2018\/DeepLearning\/master\/images\/mnist.gif\">","d97d7228":"<a id=section209><\/a>\n#### 2.9 One Hot Encoding of label","9e1e98e3":"<a id=section302><\/a>\n#### 3.2 Compile the model","10a82b96":"<a id=section306><\/a>\n#### 3.6 Plotting confusion matrix","e50b1a63":"<a id=section304><\/a>\n### 3.4 Fit the model","a4cee08b":"```\ndf.isnull().any().any()\n```\nReturns a bool with True if any of the df.isnull().any() rows is True","3badb1bb":"<a id=section1><\/a>\n### Introduction\n> MNIST digit recognition is the Computer Vision Hello World\n\n\nThe Digit recognizer dataset is a very suitable set of images for CNN, considering the __image size is homogenous__ across all images(not common in real-world problems), that the size is small (28*28) so no resizing required.\nThey are in greyscale and also in csv which can be easily read into dataframe.![image.png](attachment:image.png)\n\nThe notebook consists of __3 main parts__:\n- __Data preparation__: \n    - Even if the data is already quite clean as mentioned before, it still needs some preparation and pre-processing in order to be in appropriate format for performing CNN. It includes\n        - Data seperation\n        - Reshaping\n        - Visualization<br><br>\n- __CNN__: \n    - After NN is defined, \n        - The Convolutional step gets added up, \n        - NN parameters initialized and \n        - The model is trained.<br><br>\n- __Evaluation__: \n    - Once model is trained, \n        - Evaluate the model performance by \n        - Seeing the progress of the loss and\n        - Extract some conclusions.","e89bf418":"**Observation**\nThe available data is now divided as follows:\n\n- __Train data__     : Images (xtrain) and labels (ytrain), __90% of the available data__\n- __Validation data__: Images (xval) and labels (yval), __10% of the available data__","85cd9a8a":"<a id=section301><\/a>\n### 3.1 Define Model Architecture","c6a3bf8a":"<a id=section201><\/a>\n#### 2.2 Check shape, data type"}}