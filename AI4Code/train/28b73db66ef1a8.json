{"cell_type":{"72116746":"code","32231022":"code","3ef19d75":"code","7e52e7de":"code","68e5e133":"code","a8c69b3d":"code","319d9909":"code","353612bd":"code","d2c62d91":"code","224f80d7":"code","75c73aad":"code","3513da04":"code","a4438f0b":"code","9f8e2b0f":"code","8b8a1699":"code","3d9232f0":"code","9f531691":"code","37817534":"code","3b7a2303":"code","ed5dd8b2":"code","d52b7f2d":"code","e148fde2":"code","1541e882":"code","afbcdde1":"code","37e676db":"code","b42b6d69":"code","31228eca":"code","b60584a1":"code","18966b9f":"code","2e402a47":"code","37a2a54b":"code","272b82c5":"code","03dd0665":"code","c2b10c15":"code","209e927f":"code","af08833d":"code","392cc6cf":"code","4a84f217":"code","b82f7f61":"code","598de9c7":"code","b5ac31af":"code","220d3175":"code","b9a968e3":"code","15f985a1":"code","edaaac8c":"code","8346c303":"code","5c6ad216":"code","ec5f80c5":"code","a37564ab":"code","63e30a20":"code","1bca11ab":"code","86fd3e71":"code","1e76f01f":"code","7fbf2f9f":"markdown","89135040":"markdown","c67b1ec3":"markdown","e76ce5dd":"markdown","375b04ed":"markdown","dfdc678e":"markdown","00494ccd":"markdown","c3e157ce":"markdown","4c851d51":"markdown","f496d77a":"markdown","8bb51c59":"markdown","dda611d9":"markdown","7e7f4c55":"markdown","9af23a16":"markdown","25921466":"markdown","e3410b7b":"markdown"},"source":{"72116746":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\nimport math\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\nimport PIL\nfrom IPython import display\nfrom skimage.morphology import convex_hull_image, erosion\nfrom skimage.morphology import square\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom skimage import data, io, filters\nimport skimage\nfrom scipy.ndimage.interpolation import zoom\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU, ReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","32231022":"JPG_PATH = Path(\"..\/input\/galaxydat\/train\")","3ef19d75":"JPG_LIST = list(JPG_PATH.glob(r\"*.jpg\"))","7e52e7de":"print(len(JPG_LIST))","68e5e133":"JPG_LIST = sorted(JPG_LIST)","a8c69b3d":"COLOR_SERIES = pd.Series(JPG_LIST[:2000],name=\"COLOR\").astype(str)","319d9909":"print(len(COLOR_SERIES))","353612bd":"EXAMPLE_COLOR = cv2.cvtColor(cv2.imread(COLOR_SERIES[0]),cv2.COLOR_BGR2RGB)\nEXAMPLE_GRAY = cv2.imread(COLOR_SERIES[0],0)\n\n\nfigure,axis = plt.subplots(1,2,figsize=(14,14))\n\naxis[0].set_xlabel(EXAMPLE_COLOR.shape)\naxis[0].set_title(\"COLOR\")\naxis[0].imshow(EXAMPLE_COLOR)\n\naxis[1].set_xlabel(EXAMPLE_GRAY.shape)\naxis[1].set_title(\"GRAY\")\naxis[1].imshow(EXAMPLE_GRAY,cmap=\"gray\")\n\nplt.tight_layout()\nplt.show()","d2c62d91":"os.mkdir(\".\/GRAY_IMG\/\")","224f80d7":"index_count = 0\nOUTPUT_GRAY_LIST = []\nINPUT_COLOR_LIST = []\n\nfor x_3D_image in COLOR_SERIES.values:\n    \n    COLOR_IMAGE = cv2.cvtColor(cv2.imread(x_3D_image),cv2.COLOR_BGR2RGB)\n    COLOR_RESIZE = cv2.resize(COLOR_IMAGE,(180,180))\n    \n    TARGET_IMG_TRANS_GRAY = cv2.imread(x_3D_image,0)\n    RESIZED_IMG_TRANS_GRAY = cv2.resize(TARGET_IMG_TRANS_GRAY,(180,180))\n    \n    index_count = index_count + 1\n    cv2.imwrite(f'.\/GRAY_IMG\/GRAY_{index_count}.jpg', RESIZED_IMG_TRANS_GRAY)\n    TARGET_GRAY = cv2.cvtColor(cv2.imread(f'.\/GRAY_IMG\/GRAY_{index_count}.jpg'),cv2.COLOR_BGR2RGB)\n    \n    INPUT_COLOR_LIST.append(COLOR_RESIZE)\n    OUTPUT_GRAY_LIST.append(TARGET_GRAY)","75c73aad":"COLOR_ARRAY = np.array(INPUT_COLOR_LIST,dtype=\"float32\")\nGRAY_ARRAY = np.array(OUTPUT_GRAY_LIST,dtype=\"float32\")","3513da04":"print(COLOR_ARRAY.shape)\nprint(GRAY_ARRAY.shape)","a4438f0b":"COLOR_ARRAY = COLOR_ARRAY \/ 255.\nGRAY_ARRAY = GRAY_ARRAY \/ 255.","9f8e2b0f":"EXAMPLE_COLOR = COLOR_ARRAY[0]\nEXAMPLE_GRAY = GRAY_ARRAY[0]\n\n\nfigure,axis = plt.subplots(1,2,figsize=(14,14))\n\naxis[0].set_xlabel(EXAMPLE_COLOR.shape)\naxis[0].set_title(\"COLOR\")\naxis[0].imshow(EXAMPLE_COLOR)\n\naxis[1].set_xlabel(EXAMPLE_GRAY.shape)\naxis[1].set_title(\"GRAY\")\naxis[1].imshow(EXAMPLE_GRAY,cmap=\"gray\")\n\nplt.tight_layout()\nplt.show()","8b8a1699":"EXAMPLE_COLOR = COLOR_ARRAY[10]\nEXAMPLE_GRAY = GRAY_ARRAY[10]\n\n\nfigure,axis = plt.subplots(1,2,figsize=(14,14))\n\naxis[0].set_xlabel(EXAMPLE_COLOR.shape)\naxis[0].set_title(\"COLOR\")\naxis[0].imshow(EXAMPLE_COLOR)\n\naxis[1].set_xlabel(EXAMPLE_GRAY.shape)\naxis[1].set_title(\"GRAY\")\naxis[1].imshow(EXAMPLE_GRAY,cmap=\"gray\")\n\nplt.tight_layout()\nplt.show()","3d9232f0":"EXAMPLE_COLOR = COLOR_ARRAY[100]\nEXAMPLE_GRAY = GRAY_ARRAY[100]\n\n\nfigure,axis = plt.subplots(1,2,figsize=(14,14))\n\naxis[0].set_xlabel(EXAMPLE_COLOR.shape)\naxis[0].set_title(\"COLOR\")\naxis[0].imshow(EXAMPLE_COLOR)\n\naxis[1].set_xlabel(EXAMPLE_GRAY.shape)\naxis[1].set_title(\"GRAY\")\naxis[1].imshow(EXAMPLE_GRAY,cmap=\"gray\")\n\nplt.tight_layout()\nplt.show()","9f531691":"EXAMPLE_COLOR = COLOR_ARRAY[1000]\nEXAMPLE_GRAY = GRAY_ARRAY[1000]\n\n\nfigure,axis = plt.subplots(1,2,figsize=(14,14))\n\naxis[0].set_xlabel(EXAMPLE_COLOR.shape)\naxis[0].set_title(\"COLOR\")\naxis[0].imshow(EXAMPLE_COLOR)\n\naxis[1].set_xlabel(EXAMPLE_GRAY.shape)\naxis[1].set_title(\"GRAY\")\naxis[1].imshow(EXAMPLE_GRAY,cmap=\"gray\")\n\nplt.tight_layout()\nplt.show()","37817534":"ITERATIONS = 60\nVECTOR_NOISE_SHAPE = 180\nCOUNT_EXAMPLE= 20\nBATCH_SIZE = 6\nCOUNT_BUFFER = 60000","3b7a2303":"seed = tf.random.normal([COUNT_EXAMPLE,VECTOR_NOISE_SHAPE])","ed5dd8b2":"TRAIN_COLOR = tf.data.Dataset.from_tensor_slices(COLOR_ARRAY).shuffle(COUNT_BUFFER).batch(BATCH_SIZE)\nTRAIN_GRAY = tf.data.Dataset.from_tensor_slices(GRAY_ARRAY).shuffle(COUNT_BUFFER).batch(BATCH_SIZE)","d52b7f2d":"print(TRAIN_COLOR.element_spec)\nprint(TRAIN_GRAY.element_spec)","e148fde2":"def Generator_Model():\n    \n    \n    Model = Sequential()\n    #\n    Model.add(Dense(90*90*128,use_bias=False,input_shape=(180,)))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Reshape((90,90,128)))\n    #\n    Model.add(Conv2DTranspose(128,(3,3),padding=\"same\",use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Conv2DTranspose(3,(3,3),padding=\"same\",use_bias=False,activation=\"tanh\"))\n    \n    \n    return Model","1541e882":"Generator = Generator_Model()","afbcdde1":"print(Generator.summary())","37e676db":"def Discriminator_Model():\n    \n    Model = Sequential()\n    \n    Model.add(Conv2D(64,(3,3),padding=\"same\",input_shape=[180,180,3]))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n    \n    \n    Model.add(Conv2D(128,(3,3),padding=\"same\"))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n    \n    Model.add(layers.Flatten())\n    Model.add(layers.Dense(1))\n    \n    return Model","b42b6d69":"Discriminator = Discriminator_Model()","31228eca":"print(Discriminator.summary())","b60584a1":"Generator_Optimizer = RMSprop(lr=0.0003,clipvalue=1.0,decay=1e-8)\nDiscriminator_Optimizer = RMSprop(lr=0.0003,clipvalue=1.0,decay=1e-8)","18966b9f":"Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)","2e402a47":"def Discriminator_Loss(real_out,fake_out):\n    \n    Real_Loss_Func = Loss_Function(tf.ones_like(real_out),real_out)\n    Fake_Loss_Func = Loss_Function(tf.zeros_like(fake_out),fake_out)\n    Total_Loss = Real_Loss_Func + Fake_Loss_Func\n    \n    return Total_Loss","37a2a54b":"def Generator_Loss(fake_out):\n    \n    return Loss_Function(tf.ones_like(fake_out),fake_out)\n\n","272b82c5":"def display_and_save_images(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(12, 12))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(5, 4, i+1)\n        plt.imshow(predictions[i, :, :, 0])\n        plt.axis('off')\n\n    plt.savefig('output_image{:04d}.png'.format(epoch))\n    plt.show()","03dd0665":"def display_and_save_images_II(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(12, 12))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(5, 4, i+1)\n        plt.imshow(predictions[i, :, :, 0])\n        plt.axis('off')\n\n    plt.savefig('output_image_gray{:04d}.png'.format(epoch))\n    plt.show()","c2b10c15":"def display_and_save_images_III(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(12, 12))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(5, 4, i+1)\n        plt.imshow(predictions[i, :, :, 0])\n        plt.axis('off')\n\n    plt.savefig('HUBBLE{:04d}.png'.format(epoch))\n    plt.show()","209e927f":"def Train_Step(images):\n    \n    random_noise_vector = tf.random.normal([BATCH_SIZE,VECTOR_NOISE_SHAPE])\n    \n    with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n        \n        Generator_Fake_Image = Generator(random_noise_vector,training=False)\n        \n        real_output = Discriminator(images,training=True)\n        fake_output = Discriminator(Generator_Fake_Image,training=True)\n        \n        Generator_Loss_Output = Generator_Loss(fake_output)\n        Discriminator_Loss_Output = Discriminator_Loss(real_output,fake_output)\n        \n    Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Output,Generator.trainable_variables)\n    Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Output,Discriminator.trainable_variables)\n    \n    Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))","af08833d":"def Training(dataset,iterations):\n    \n    for epoch in range(iterations):\n        start = time.time()\n        \n        for image_batch in dataset:\n            Train_Step(image_batch)\n            \n        display.clear_output(wait=True)\n        display_and_save_images_III(Generator,epoch+1,seed)\n    \n    display.clear_output(wait=True)\n    display_and_save_images_III(Generator,epoch,seed)  ","392cc6cf":"iter_count_stop = 0\n\nwhile iter_count_stop < ITERATIONS:\n    \n    iter_count_stop = iter_count_stop + 1\n    \n    if 1 <= iter_count_stop <= 30:\n        \n        for epoch in range(30):\n            \n            start = time.time()\n        \n            for image_batch in TRAIN_COLOR:\n                \n                random_noise_vector = tf.random.normal([BATCH_SIZE,VECTOR_NOISE_SHAPE])\n\n            with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n\n                Generator_Fake_Image = Generator(random_noise_vector,training=False)\n\n                real_output = Discriminator(image_batch,training=True)\n                fake_output = Discriminator(Generator_Fake_Image,training=True)\n\n                Generator_Loss_Output = Generator_Loss(fake_output)\n                Discriminator_Loss_Output = Discriminator_Loss(real_output,fake_output)\n\n            Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Output,Generator.trainable_variables)\n            Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Output,Discriminator.trainable_variables)\n\n            Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n            Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))\n\n            display.clear_output(wait=True)\n            display_and_save_images(Generator,epoch+1,seed)\n    \n        display.clear_output(wait=True)\n        display_and_save_images(Generator,epoch,seed)\n        \n        \n    else:\n        \n        for epoch in range(30):\n            \n            start = time.time()\n        \n            for image_batch in TRAIN_GRAY:\n                \n                random_noise_vector = tf.random.normal([BATCH_SIZE,VECTOR_NOISE_SHAPE])\n\n            with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n\n                Generator_Fake_Image = Generator(random_noise_vector,training=False)\n\n                real_output = Discriminator(image_batch,training=True)\n                fake_output = Discriminator(Generator_Fake_Image,training=True)\n\n                Generator_Loss_Output = Generator_Loss(fake_output)\n                Discriminator_Loss_Output = Discriminator_Loss(real_output,fake_output)\n\n            Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Output,Generator.trainable_variables)\n            Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Output,Discriminator.trainable_variables)\n\n            Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n            Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))\n\n            display.clear_output(wait=True)\n            display_and_save_images_II(Generator,epoch+1,seed)\n    \n        display.clear_output(wait=True)\n        display_and_save_images_II(Generator,epoch,seed)\n        \n        ","4a84f217":"Predict_Generator_Noise = tf.random.normal(shape=[50,VECTOR_NOISE_SHAPE])","b82f7f61":"print(Predict_Generator_Noise[0].shape)","598de9c7":"Generator_Predict_Noise = Generator(Predict_Generator_Noise)","b5ac31af":"figure, axes = plt.subplots(nrows=7,ncols=7,figsize=(14,14))\n\nfor i,ax in enumerate(axes.flat):\n    Prediction_Output = Generator_Predict_Noise[i]\n    ax.imshow(Prediction_Output[:,:,0],cmap=\"hot\")\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","220d3175":"NEW_GRAY_PATH = \".\/output_image_gray0020.png\"\nNEW_COLOR_PATH = \".\/output_image0025.png\"\n\nGRAY_NEW = cv2.cvtColor(cv2.imread(NEW_GRAY_PATH),cv2.COLOR_BGR2RGB)\nCOLOR_NEW = cv2.cvtColor(cv2.imread(NEW_COLOR_PATH),cv2.COLOR_BGR2RGB)\n\n\nfigure,axis = plt.subplots(1,2,figsize=(22,22))\n\n\naxis[0].set_title(\"COLOR\")\naxis[0].axis(\"off\")\naxis[0].imshow(COLOR_NEW[:,:,0],cmap=\"hot\")\n\naxis[1].set_title(\"GRAY\")\naxis[1].axis(\"off\")\naxis[1].imshow(GRAY_NEW[:,:,0],cmap=\"hot\")\n\nplt.tight_layout()\nplt.show()","b9a968e3":"Hubble_Pick_Path = Path(\"..\/input\/top-100-hubble-telescope-images\")\nHubble_IMG_Path = list(Hubble_Pick_Path.glob(r\"*.tif\"))\nHubble_Series = pd.Series(Hubble_IMG_Path,name=\"HUBBLE\").astype(str)\n\nHubble_Transformation = []\nfor x_hubble in Hubble_Series.values:\n    \n    Hubble_Pick_Read = cv2.cvtColor(cv2.imread(x_hubble),cv2.COLOR_BGR2RGB)\n    Hubble_Pick_Resize = cv2.resize(Hubble_Pick_Read,(180,180))\n    \n    Hubble_Transformation.append(Hubble_Pick_Resize)","15f985a1":"plt.figure(figsize=(15,7))\n\nplt.imshow(Hubble_Transformation[0])\nplt.axis(\"off\")\nplt.show()","edaaac8c":"plt.figure(figsize=(15,7))\n\nplt.imshow(Hubble_Transformation[90])\nplt.axis(\"off\")\nplt.show()","8346c303":"Hubble_Array = np.array(Hubble_Transformation,dtype=\"float32\")\nHubble_Array = Hubble_Array \/ 255.","5c6ad216":"Hubble_Array_Slice = tf.data.Dataset.from_tensor_slices(Hubble_Array).shuffle(COUNT_BUFFER).batch(BATCH_SIZE)","ec5f80c5":"print(Hubble_Array_Slice.element_spec)","a37564ab":"Training(Hubble_Array_Slice,30)","63e30a20":"Predict_H_Noise = tf.random.normal(shape=[50,VECTOR_NOISE_SHAPE])","1bca11ab":"Generator_H_Predict = Generator(Predict_Generator_Noise)","86fd3e71":"figure, axes = plt.subplots(nrows=7,ncols=7,figsize=(14,14))\n\nfor i,ax in enumerate(axes.flat):\n    Prediction_Output = Generator_H_Predict[i]\n    ax.imshow(Prediction_Output)\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","1e76f01f":"for indexing in range(random.randint(0,22)):\n    figure = plt.figure(figsize=(8,8))\n\n    Saving_Count = indexing\n    plt.axis(\"off\")\n    plt.imshow(Generator_H_Predict[Saving_Count])\n    plt.savefig(f\"Ex{Saving_Count}_Output.png\")","7fbf2f9f":"### TRANSFORMATION","89135040":"### GENERATING AND SAVING IMAGE","c67b1ec3":"### DISCRIMINATOR PROCESS","e76ce5dd":"### PREDICTION PROCESS","375b04ed":"### LOSS FUNCTIONS","dfdc678e":"### HUBBLE TRAINING","00494ccd":"# PACKAGES AND LIBRARIES","c3e157ce":"### CONTROL","4c851d51":"### TRAINING STEP","f496d77a":"# DC-GAN PROCESS","8bb51c59":"### TENSOR SLICES","dda611d9":"# DATA PROCESS","7e7f4c55":"### PARAMETERS","9af23a16":"### GENERATOR STRUCTURE","25921466":"### CREATING NEW 3-D GRAY","e3410b7b":"### COMPARING IMAGES"}}