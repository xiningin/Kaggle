{"cell_type":{"2deebe44":"code","3e85ec56":"code","552e3ac4":"code","38373f97":"code","3db34094":"code","aef28049":"code","aa36af45":"code","f0337ba7":"code","7e9833ef":"code","8761c08a":"code","f79aedbb":"code","d0e0f22a":"code","ad39001c":"code","d8f987de":"code","ba0ab574":"code","2ab8ab9b":"code","8174691c":"code","2ce31adc":"code","8095cf10":"code","1d38966e":"code","eae3e5cf":"code","b081f2ad":"markdown","2e492399":"markdown","807b1857":"markdown","f10c759d":"markdown","81b0a9ee":"markdown","a7cb1a62":"markdown","d9476391":"markdown","9f98d8a1":"markdown","5909e2ad":"markdown","24b0d4d4":"markdown","fa8d1646":"markdown","72eb0bc6":"markdown","336d1e27":"markdown","30ec6e18":"markdown"},"source":{"2deebe44":"%cd \/opt\/conda\/bin\/\n!python3.7 -m pip install --upgrade pip","3e85ec56":"! conda install -y gdown","552e3ac4":"# install dependencies: (use cu101 because colab has CUDA 10.1)\n!pip install --use-feature=2020-resolver -U torch==1.5 torchvision==0.6 -f https:\/\/download.pytorch.org\/whl\/cu101\/torch_stable.html \n!pip install cython pyyaml==5.1\n!pip install -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n!gcc --version\n!pip install google-colab","38373f97":"# opencv is pre-installed on colab\n# install detectron2:\n!pip install detectron2==0.1.3 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu101\/torch1.5\/index.html","3db34094":"# You may need to restart your runtime prior to this, to let your installation take effect\n# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport cv2\nimport random\nfrom google.colab.patches import cv2_imshow\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\nfrom detectron2.data.catalog import DatasetCatalog","aef28049":"import os\noutput=\"\/kaggle\/working\/detectron2\"\nif not os.path.exists(output):\n    os.makedirs(output)\n\n%cd  \/kaggle\/working\/detectron2\/\n# download ataset dataset_21_2825_1\n#!gdown --id  1-2uin6c7rTqGoygEZMPvAsLwz18sfPHp\n#!tar xvzf dataset_21_2825_1.tar.gz\n#!rm -rf dataset_21_2825_1.tar.gz\n\n\n# download ataset dataset_21_6426\n!gdown --id  12V7svOlQRNk88ahJ-mqUP3buuX_rr-J-\n!tar xzf dataset_21_6426.tar.gz\n!rm -rf dataset_21_6426.tar.gz","aa36af45":"import os\noutput=\"\/kaggle\/working\/detectron2\/output\"\nif not os.path.exists(output):\n    os.makedirs(output)\n    \n%cd  \/kaggle\/working\/detectron2\/output\n# download ataset model_final.pt (less accuracy)\n!gdown --id  1-XGlG6XKDJCZJyRyJoaB6hQAUZIPXkoP\n\n\n# download ataset model_final.pt (more accuracy)\n# %cp -arvf \/kaggle\/input\/lastpretrainedmodel\/model_final.pth \/kaggle\/working\/detectron2\/output\/model_final.pth","f0337ba7":"\"\"\"\nimport os\noutput=\"\/kaggle\/working\/detectron2\"\nif not os.path.exists(output):\n    os.makedirs(output)\n    \n%cd \/kaggle\/working\/detectron2\n\n\nimport os\noutput=\"dataset_21_2825_1\"\nif not os.path.exists(output):\n    os.makedirs(output)\n    \n%cd dataset_21_2825_1\/\n!curl -L \"https:\/\/app.roboflow.ai\/ds\/ypwjrTOS9q?key=DD9xOpsn13\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n\"\"\"","7e9833ef":"\"\"\"\nimport fileinput\nimport os\nfrom shutil import copyfile\ndef convert_list_to_string(org_list, seperator=' '):\n  #Convert list to string, by joining all item in list with given separator.\n  #Returns the concatenated string \n  return seperator.join(org_list)\n\nlistOfFiles=[\"test\",\"train\",\"valid\"]\ninput_dir=\"\/kaggle\/working\/detectron2\/dataset_21_2825_1\"\nfor folderName in listOfFiles:\n  output=os.path.join(\"\/content\",folderName)\n  if not os.path.exists(output):\n    os.makedirs(output)\n\n  input_file=os.path.join(input_dir,folderName,\"_annotations.coco.json\")\n  \n  copyfile(input_file, os.path.join(output,\"_annotations.coco.json\"))\n  for i in range(0,21):\n    text_to_search='\"category_id\": {},'.format(i+1)\n    # print(text_to_search)\n    replacement_text='\"category_id\": {},'.format(i)\n    #read input file\n    fin = open(input_file, \"rt\")\n    #read file contents to string\n    data = fin.read()\n    #replace all occurrences of the required string\n    data = data.replace(text_to_search, replacement_text)\n    #close the input file\n    fin.close()\n    #open the input file in write mode\n    fin = open(input_file, \"wt\")\n    #overrite the input file with the resulting data\n    fin.write(data)\n    #close the file\n    fin.close()\n    print(\"\\rpercent {:.2f}%\".format(100*i\/20), end='')\n\n\"\"\"\n\n","8761c08a":"%cd \/kaggle\/working\/detectron2\/\n\nfrom detectron2.data.datasets import register_coco_instances\nregister_coco_instances(\"my_dataset_train\", {}, \"dataset_21_6426\/train\/_annotations.coco.json\", \"dataset_21_6426\/train\")\nregister_coco_instances(\"my_dataset_val\", {}, \"dataset_21_6426\/valid\/_annotations.coco.json\", \"dataset_21_6426\/valid\")\nregister_coco_instances(\"my_dataset_test\", {}, \"dataset_21_6426\/test\/_annotations.coco.json\", \"dataset_21_6426\/test\")\n","f79aedbb":"print(\"visualize training data\")\n# #visualize training data\n# my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n# dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n\n# import random\n# from detectron2.utils.visualizer import Visualizer\n\n# for d in random.sample(dataset_dicts, 5):\n#     img = cv2.imread(d[\"file_name\"])\n\n#     print(d[\"file_name\"].split(\"\/\")[-1].split(\"_jpg\")[0])\n#     visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.7)\n#     vis = visualizer.draw_dataset_dict(d)\n#     cv2_imshow(vis.get_image()[:, :, ::-1])\n","d0e0f22a":"#We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.evaluation import COCOEvaluator\n\nclass CocoTrainer(DefaultTrainer):\n\n  @classmethod\n  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n\n    if output_folder is None:\n        os.makedirs(\"coco_eval\", exist_ok=True)\n        output_folder = \"coco_eval\"\n\n    return COCOEvaluator(dataset_name, cfg, False, output_folder)","ad39001c":"%cd \/kaggle\/working\/detectron2\/\n#from .detectron2.tools.train_net import Trainer\n#from detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg\n#from detectron2.evaluation.coco_evaluation import COCOEvaluator\nimport os\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection\/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"my_dataset_train\",)\ncfg.DATASETS.TEST = (\"my_dataset_val\",)\n\ncfg.DATALOADER.NUM_WORKERS = 4\n\n# use coco pre-trained model\n#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection\/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n\n# use my pre-trained model\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n\ncfg.SOLVER.IMS_PER_BATCH =   1\n\ncfg.SOLVER.BASE_LR = 0.001\n\n\n#cfg.SOLVER.WARMUP_ITERS = 10000\ncfg.SOLVER.MAX_ITER = 460000 #adjust up if val mAP is still rising, adjust down if overfit\n#cfg.SOLVER.STEPS = (10000, 10500)\ncfg.SOLVER.GAMMA = 0.05\n\n\n\n\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 7\n#             batch_size_per_image (int): number of proposals to sample for training\n#             positive_fraction (float): fraction of positive (foreground) proposals\n#                 to sample for training.\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 21 #your number of classes + 1\n# num_classes (int): number of classes. Used to label background proposals.\n\ncfg.TEST.EVAL_PERIOD = 1000\n\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = CocoTrainer(cfg)\ntrainer.resume_or_load(resume=True)\n    # resume_or_load(resume=True)[source]\n    # If resume==True, and last checkpoint exists, resume from it, load all checkpointables (eg. optimizer and scheduler) and update iteration counter from it. cfg.MODEL.WEIGHTS will not be used.\n\n    # Otherwise, load the model specified by the config (skip all checkpointables) and start from the first iteration.\ntrainer.train()","d8f987de":"#%cp -arvf \/kaggle\/working\/detectron2\/output\/model_final.pth \/kaggle\/working\/","ba0ab574":"# Look at training curves in tensorboard:\n# !kill 669\n%load_ext tensorboard\n%tensorboard --logdir output","2ab8ab9b":"#test evaluation\nimport os\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.001 # set the testing threshold for this model\npredictor = DefaultPredictor(cfg)\nevaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\".\/output\/\")\nval_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\ninference_on_dataset(trainer.model, val_loader, evaluator)","8174691c":"%ls -l \/kaggle\/working\/detectron2\/output\/","2ce31adc":"%cd \/kaggle\/working\/detectron2\/\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.DATASETS.TEST = (\"my_dataset_test\", )\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.001   # set the testing threshold for this model\npredictor = DefaultPredictor(cfg)\ntest_metadata = MetadataCatalog.get(\"my_dataset_test\")","8095cf10":"%cd \/kaggle\/working\/detectron2\/\n\nfrom detectron2.utils.visualizer import ColorMode\nimport glob\n\nlistOfImages=glob.glob('dataset_21_6426\/test\/*jpg')\nfor i in range(0,5):\n  im = cv2.imread(listOfImages[i])\n  outputs = predictor(im)\n  v = Visualizer(im[:, :, ::-1],\n                metadata=test_metadata, \n                scale=1\n                 )\n  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n  cv2_imshow(out.get_image()[:, :, ::-1])\n","1d38966e":"%cd \/kaggle\/working\/\n# download the test image\n!gdown --id 1-UxNH8cM0km391pO7-JAo2qX8TNKWmJV","eae3e5cf":"%cd \/kaggle\/working\/detectron2\/\n\nfrom detectron2.utils.visualizer import ColorMode\nimport glob\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.DATASETS.TEST = (\"my_dataset_test\", )\n\nfor x in [0.0001,0.001,0.0015,0.009,0.01,0.1]:\n  print(\"\\n\\t\\tSCORE_THRESH_TEST={}\\n\".format(x))\n  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = x\n  # set the testing threshold for this model\n  predictor = DefaultPredictor(cfg)\n  W=1024\n  imageName=\"\/kaggle\/working\/0.jpg\"\n  im = cv2.imread(imageName)\n  im=cv2.resize(im,(W,W))\n  outputs = predictor(im)\n  v = Visualizer(im[:, :, ::-1],\n                metadata=test_metadata, \n                scale=1\n                 )\n  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n  cv2_imshow(out.get_image()[:, :, ::-1])","b081f2ad":"# download the test image","2e492399":"# **import dataset**","807b1857":"# Train Custom Detectron2 Detector","f10c759d":"## install detectron2:","81b0a9ee":"# Inference with Detectron2 Saved Weights\n\n","a7cb1a62":"### upgrade pip","d9476391":"# Install Detectron2 Dependencies","9f98d8a1":"## **Check classes**","5909e2ad":"**install gdown**","24b0d4d4":"# **download dataset from Roboflow**","fa8d1646":"# **download pre-trained model**","72eb0bc6":"# **visualize training data**","336d1e27":"# **Register_coco_instances**","30ec6e18":"# How to Train Detectron2 on Custom Objects\n\nThis tutorial implements the new [Detectron2 Library](https:\/\/ai.facebook.com\/blog\/-detectron2-a-pytorch-based-modular-object-detection-library-\/) by facebook. This notebook shows training on **your own custom objects** for object detection.\n\nIt is worth noting that the Detectron2 library goes far beyond object detection, supporting semantic segmentation, keypoint detection, mask, and densepose.\n\n\n### Accompanying Blog Post\n\nWe recommend that you follow along in this notebook while reading the blog post on [how to train Detectron2](https:\/\/blog.roboflow.ai\/how-to-train-detectron2\/), concurrently.\n\n### Steps Covered in this Tutorial\n\nIn this tutorial, we will walk through the steps required to train Detectron2 on your custom objects. We use a [public blood cell detection dataset](https:\/\/public.roboflow.ai\/object-detection\/bccd), which is open source and free to use. You can also use this notebook on your own data.\n\nTo train our detector we take the following steps:\n\n* Install Detectron2 dependencies\n* Download custom Detectron2 object detection data\n* Visualize Detectron2 training data\n* Write our Detectron2 Training configuration\n* Run Detectron2 training\n* Evaluate Detectron2 performance\n* Run Detectron2 inference on test images\n\n\n\n### **About**\n\n[Roboflow](https:\/\/roboflow.ai) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n\n#### ![Roboflow Workmark](https:\/\/i.imgur.com\/WHFqYSJ.png)"}}