{"cell_type":{"b90c46ad":"code","962712c3":"code","f4712f6f":"code","8312600c":"code","9907a21f":"code","ddaa1402":"code","bc99d97b":"code","3a497f1c":"code","129dfcc9":"code","0e8a4eae":"code","1dd0e174":"code","0c200f75":"code","23ed9e5b":"code","49be0650":"code","7f48b050":"code","ba52fd55":"code","2845ef87":"code","68d8d900":"code","319aa8d6":"code","99a26f45":"code","e9bc8ba6":"code","e19ebe99":"code","2b56ad22":"code","7d31d8a8":"code","1237a20e":"code","37b668cc":"code","04681e45":"code","3fa88150":"code","e9cdc09a":"code","1fcdfd21":"code","387dbece":"code","cc54dc9c":"code","882b8898":"code","1c02a37d":"code","dcc32d74":"code","6e5f7c95":"code","b8e7f1ee":"code","843489e0":"code","510cf6c2":"code","cdf0c7c6":"code","8efc3a61":"code","4c23dcde":"code","ef0b16ac":"code","df405058":"code","c3698fc6":"code","d57a948a":"code","08da2326":"code","6d2fb68c":"code","d7ff68f2":"code","1aa721d0":"markdown","23c821ab":"markdown","00c593ef":"markdown","4da6f533":"markdown","99df3d5b":"markdown","8f2211d5":"markdown","dd6128fc":"markdown","d3db65fc":"markdown","15b80b17":"markdown","0be08a99":"markdown","018a9ebf":"markdown","76687d96":"markdown","ea549cf8":"markdown","0b861ad7":"markdown","20025bb0":"markdown","857ea72b":"markdown","bda856f3":"markdown","6057b08b":"markdown","7cc9f4eb":"markdown","6a742942":"markdown","beeb4321":"markdown","b2ea639b":"markdown","4814ec98":"markdown","e4b72942":"markdown","c95fc682":"markdown","5aa52850":"markdown","d4f95a76":"markdown"},"source":{"b90c46ad":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom wordcloud import WordCloud\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n!pip install chart-studio\nimport chart_studio.plotly as py \nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom collections import defaultdict\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nnltk.download('stopwords')\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","962712c3":"# reading .csv file\ndf=pd.read_csv('..\/input\/data-analyst-jobs\/DataAnalyst.csv')\ndf.drop('Unnamed: 0',axis=1,inplace=True)\ndf.shape","f4712f6f":"df.head()","8312600c":"df.describe(include='all')","9907a21f":"def miss_val(df):\n    #number of missing values\n    miss_val = df.isnull().sum()\n    \n    #percent missing values\n    miss_val_per = miss_val\/ len(df)*100\n    \n    #creating df with the results\n    miss_val_df = pd.concat([miss_val, miss_val_per], axis=1)\n    \n    #renaming the columns\n    miss_val_df = miss_val_df.rename(columns = {0 : 'missing_values', 1 : '%_of_total_values'})\n    \n    #sorting the table\n    miss_val_df=miss_val_df[miss_val_df['missing_values']!=0]\n    miss_val_df = miss_val_df.sort_values('%_of_total_values', ascending=False)\n    return miss_val_df","ddaa1402":"miss_val(df)","bc99d97b":"df['Job Title'].value_counts()","3a497f1c":"#1 is given as max split i.e split only once\ndf['Job Title'],df['Department']=df['Job Title'].str.split(',', 1).str\ndf.head()","129dfcc9":"df['Industry'].value_counts().head(10)","0e8a4eae":"df['Sector'].value_counts().head(10)","1dd0e174":"df['Competitors'].value_counts().head(10)","0c200f75":"df['Easy Apply'].value_counts().head(10)","23ed9e5b":"df['Revenue'].value_counts().head(10)","49be0650":"num_lst=[-1,-1.0,'-1']\nfor num in num_lst:\n    df=df.replace(num,np.nan)","7f48b050":"df['Salary Estimate'].value_counts().head(10)","ba52fd55":"df['Salary Estimate'],_=df['Salary Estimate'].str.split('(', 1).str\ndf['salary_min'],df['salary_max']=df['Salary Estimate'].str.split('-').str\ndf['salary_max']=df['salary_max'].str.strip(' ').str.lstrip('$').str.rstrip('K').fillna(0).astype('int')\ndf['salary_min']=df['salary_min'].str.strip(' ').str.lstrip('$').str.rstrip('K').fillna(0).astype('int')\ndf.drop('Salary Estimate',axis=1,inplace=True)","2845ef87":"df['Size'].value_counts()","68d8d900":"df['Size'],_=df['Size'].str.split(\" e\").str","319aa8d6":"df['Company Name'].value_counts().head(5)","99a26f45":"df['Company Name'],_=df['Company Name'].str.split('\\n', 1).str","e9bc8ba6":"df['City'],df['State']=df['Location'].str.split(', ', 1).str\ndf['State']=df['State'].replace(\"Arapahoe, CO\",\"CO\")\ndf.drop('Location',axis=1,inplace=True)\ndf.head()","e19ebe99":"df['Size'].fillna('Unknown',inplace=True)\n\ndf['Founded']=df['Founded'].fillna(\"0\").astype(int)\n\ndf['Type of ownership'].fillna('Unknown',inplace=True)\n\ndf['Sector'].fillna('Unknown',inplace=True)\n\ndf['Easy Apply']=df['Easy Apply'].fillna(\"False\").astype(\"bool\")","2b56ad22":"def filter_revenue(x):\n    revenue=0\n    if(x== 'Unknown \/ Non-Applicable' or type(x)==float):\n        revenue=0\n    elif(('million' in x) and ('billion' not in x)):\n        maxRev = x.replace('(USD)','').replace(\"million\",'').replace('$','').strip().split('to')\n        if('Less than' in maxRev[0]):\n            revenue = float(maxRev[0].replace('Less than','').strip())\n        else:\n            if(len(maxRev)==2):\n                revenue = float(maxRev[1])\n            elif(len(maxRev)<2):\n                revenue = float(maxRev[0])\n    elif(('billion'in x)):\n        maxRev = x.replace('(USD)','').replace(\"billion\",'').replace('$','').strip().split('to')\n        if('+' in maxRev[0]):\n            revenue = float(maxRev[0].replace('+','').strip())*1000\n        else:\n            if(len(maxRev)==2):\n                revenue = float(maxRev[1])*1000\n            elif(len(maxRev)<2):\n                revenue = float(maxRev[0])*1000\n    return revenue","7d31d8a8":"df['Max_revenue']=df['Revenue'].apply(lambda x: filter_revenue(x))\ndf.head()","1237a20e":"job_title=df['Job Title'][~pd.isnull(df['Job Title'])]\nwordCloud = WordCloud(background_color='white',width=500,height= 200).generate(' '.join(job_title))\nplt.figure(figsize=(20,7))\nplt.axis('off')\nplt.title(df['Job Title'].name,fontsize=20)\nplt.imshow(wordCloud)\nplt.show()","37b668cc":"# Removing stopwords\ndef removing_stopwords(text):\n   #removing some important stopwords from stopwords\n    Stopwords=set(stopwords.words('english'))\n    return \" \".join([word for word in str(text).split() if word not in Stopwords])","04681e45":"#removing stopwords\ndf['Job Description']=df['Job Description'].apply(lambda text:removing_stopwords(text))","3fa88150":"Job_Description=df['Job Description'][~pd.isnull(df['Job Description'])]\nwordCloud = WordCloud(background_color='white',width=500,height= 200).generate(' '.join(Job_Description))\nplt.figure(figsize=(20,7))\nplt.axis('off')\nplt.title(df['Job Description'].name,fontsize=20)\nplt.imshow(wordCloud)\nplt.show()","e9cdc09a":"pg_lan = [\"python\",\"c++\",\"java\",\"matlab\",\".net\",\"c#\",\"javascript\",\"html\",\"bash\"]\nbig_data = [\"big data\",\"hadoop\",\"spark\",\"impala\",\"cassandra\",\"kafka\",\"hdfs\",\"hbase\",\"hive\"]\njob = df[\"Job Description\"].tolist()\njob = [x.lower() for x in job]","1fcdfd21":"pg_lan_required = defaultdict()\nfor item in pg_lan:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    pg_lan_required[item] = counter\n\npg_lan_df = pd.DataFrame(list(pg_lan_required.items()),columns = ['Programming Langauge','count']) \npg_lan_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","387dbece":"plt.figure(figsize = (20,7))\nx = pg_lan_df[\"Programming Langauge\"]\ny = pg_lan_df[\"count\"]\nplt.bar(x,y,color= \"#4090c5\")\nplt.title(\"Top programming languages required\",fontsize=17)\nplt.xlabel(\"Programming Languages\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)","cc54dc9c":"counter = 0\nbig_data_required = defaultdict()\nfor item in big_data:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    big_data_required[item] = counter\n\nbig_data_df = pd.DataFrame(list(big_data_required.items()),columns = ['Big Data Technologies','count']) \nbig_data_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","882b8898":"plt.figure(figsize = (20,7))\nx = big_data_df[\"Big Data Technologies\"]\ny = big_data_df[\"count\"]\nplt.bar(x,y,color= \"#4090c5\")\nplt.title(\"Top Big Data Technologies requrired \",fontsize=17)\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)","1c02a37d":"plt.figure(figsize=(20,7))\nsns.countplot(df['Rating'],color='#4090c5')\nplt.xlabel(\"Rating\",fontsize=15)\nplt.ylabel(\"# of companies\",fontsize=15)\nplt.title(\"Rating v\/s number of companies\",fontsize=17)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)","dcc32d74":"statewise_count=pd.DataFrame(df.groupby('State').count().iloc[:,1]).reset_index()\n\n\ndata = dict(type='choropleth',\n            locations = statewise_count['State'],\n            locationmode = 'USA-states',\n            colorscale='blues',\n            z = statewise_count['Job Description'],\n            colorbar = {'title':\"number of jobs\"}\n            )\n\nlayout = dict(title = 'Data Analyst jobs per state',geo = dict(scope='usa'))\n\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","6e5f7c95":"salary_df=df.copy()\nsalary_df['mean_salary']=(df['salary_max']+df['salary_min'])\/2\nstate_salary=pd.DataFrame(salary_df.groupby('State')['mean_salary'].mean()).reset_index()\nstate_salary\n\ndata = dict(type='choropleth',\n            locations = state_salary['State'],\n            locationmode = 'USA-states',\n            colorscale = 'blues',\n            z = state_salary['mean_salary'],\n            colorbar = {'title':\"salary\"}\n            )\n\nlayout = dict(title = 'mean salary based on state',geo = dict(scope='usa'))\n\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","b8e7f1ee":"plt.figure(figsize=(20,7))\nsns.distplot(salary_df.loc[salary_df['mean_salary']!=0,'mean_salary'],color=\"#4090c5\")\nplt.xlabel('mean_salary',fontsize=15)\nplt.ylabel('probability density',fontsize=15)\nplt.title('distribution of mean salary',fontsize=17)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)","843489e0":"temp_df=salary_df[salary_df['Max_revenue']!=0]\nsize_revenue=pd.DataFrame(temp_df.groupby('Size')['mean_salary'].mean().sort_values()).reset_index()","510cf6c2":"plt.figure(figsize=(20,7))\norder=['Unknown','51 to 200','201 to 500','501 to 1000','1001 to 5000','5001 to 10000','10000+']\nsns.barplot(x='Size',y='mean_salary',data=size_revenue,order=order,color='#4090c5')\nplt.title(\"company size v\/s salary\",fontsize=17)\nplt.ylabel('mean salary in thousands of $',fontsize=15)\nplt.xlabel('Size of the Company',fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)","cdf0c7c6":"ownership_df=pd.DataFrame(temp_df['Type of ownership'].value_counts()).reset_index()\nownership_df.rename(columns={'index':'Type of ownership','Type of ownership':'value_counts'},inplace=True)\nownership_salary=pd.DataFrame(temp_df.groupby('Type of ownership')['mean_salary'].mean()).reset_index()\nownership_df=pd.merge(ownership_df,ownership_salary,how='left',left_on=\"Type of ownership\",right_on='Type of ownership')","8efc3a61":"plt.figure(figsize=(20,7))\nplt.xticks(rotation=60,horizontalalignment='right')\nsns.barplot(x=ownership_df['Type of ownership'],y=ownership_df['mean_salary'],color='#4090c5')\nplt.title('mean salary for different types of ownership', fontsize=17)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.xlabel('Type of ownership',fontsize=15)\nplt.ylabel('mean salary',fontsize=15)","4c23dcde":"ownership_df_2=ownership_df.set_index('Type of ownership')\nfig = plt.figure(figsize=(20,7)) # Create matplotlib figure\n\nax = fig.add_subplot(111) # Create matplotlib axes\nax2 = ax.twinx() # Create another axes that shares the same x-axis as ax.\n\nwidth = 0.4\n\nownership_df_2['mean_salary'].plot(kind='bar', color='#ee854a', ax=ax, width=width, position=1)\nownership_df_2['value_counts'].plot(kind='bar', color='#4090c5', ax=ax2, width=width, position=0)\n\nax.set_ylabel('mean salary in thousands of $',fontsize=15)\nax.legend(['mean_salary'],bbox_to_anchor=(0.45, 1))\nax2.set_ylabel('number of companies',fontsize=15)\nax2.legend(['number of companies'],bbox_to_anchor=(0.65, 1))\nplt.title(\"Type of ownership v\/s mean salary v\/s number of companies\",fontsize=17)\nplt.xlabel('Type of ownership',fontsize=15)\nplt.yticks(fontsize=13)","ef0b16ac":"sector_df=pd.DataFrame(temp_df['Sector'].value_counts()).reset_index()\nsector_df.rename(columns={'index':'Sector','Sector':'value_counts'},inplace=True)\nsector_salary=pd.DataFrame(temp_df.groupby('Sector')['mean_salary'].mean()).reset_index()\nsector_df=pd.merge(sector_df,sector_salary,how='left',left_on=\"Sector\",right_on='Sector')\nsector_df_2=sector_df.set_index('Sector')","df405058":"fig = plt.figure(figsize=(20,7)) # Create matplotlib figure\n\nax = fig.add_subplot(111) # Create matplotlib axes\nax2 = ax.twinx() # Create another axes that shares the same x-axis as ax.\n\nwidth = 0.4\n\nsector_df_2['mean_salary'].plot(kind='bar', color='#ee854a', ax=ax, width=width, position=1)\nsector_df_2['value_counts'].plot(kind='bar', color='#4090c5', ax=ax2, width=width, position=0)\n\nax.set_ylabel('mean salary in thousands of $',fontsize=15)\nax.legend(['mean_salary'],bbox_to_anchor=(0.45, 1))\nax2.set_ylabel('number of companies',fontsize=15)\nax2.legend(['number of companies'],bbox_to_anchor=(0.65, 1))\nplt.xlabel('Sector',fontsize=15)\nplt.title(\"sector v\/s mean salary v\/s number of companies\",fontsize=17)","c3698fc6":"plt.figure(figsize=(20,7))\nsns.countplot(df.loc[df['Max_revenue']!=0,'Max_revenue'],color='#4090c5')\nplt.ylabel('number of companies',fontsize=15)\nplt.xlabel(\"Revenue in millions of $\",fontsize=15)\nplt.title('Number of companies with given revenue',fontsize=17)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)","d57a948a":"city_salary=pd.DataFrame(temp_df.groupby('City')['mean_salary'].mean()).reset_index()","08da2326":"top_city_df=pd.DataFrame(df['City'].value_counts()).reset_index()\ntop_city_df.rename(columns={'City':'count','index':'city'},inplace=True)\ntop_city_df=pd.merge(top_city_df,city_salary,how='left',left_on='city',right_on='City')\ntop_city_df.drop('City',axis=1,inplace=True)\ntop_city_df=top_city_df[top_city_df['count']>=5]\ntop_city_df=top_city_df.sort_values(by='mean_salary',ascending=False)\n\ntop_city_df=top_city_df.head(20)\nplt.figure(figsize=(20,7))\nsns.barplot(x=top_city_df['city'],y=top_city_df['mean_salary'],color='#4090c5')\nplt.xticks(rotation=60,horizontalalignment='right')\nplt.ylabel('mean salary in thousands of $',fontsize=15)\nplt.xlabel(\"city\",fontsize=15)\nplt.title('top 20 cities with highest salaries',fontsize=17)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)","6d2fb68c":"Title_salary=pd.DataFrame(temp_df.groupby('Job Title')['mean_salary'].mean()).reset_index().sort_values('mean_salary',ascending=False)\nplt.figure(figsize=(20,7))\nsns.barplot(x=Title_salary['Job Title'].head(20),y=Title_salary['mean_salary'].head(20),color='#4090c5')\nplt.xticks(rotation=60,horizontalalignment='right')\nplt.ylabel('mean salary in thousands of $',fontsize=15)\nplt.xlabel(\"Job Title\",fontsize=15)\nplt.title('top 20 Job Titles with highest salaries',fontsize=17)\nplt.xticks(fontsize=11)\nplt.yticks(fontsize=13)","d7ff68f2":"sector_revenue=pd.DataFrame(temp_df.groupby('Sector')['Max_revenue'].sum()).reset_index().sort_values('Max_revenue',ascending=False)\nsector_revenue.rename(columns={'Max_revenue':\"Total_revenue\"},inplace=True)\nplt.figure(figsize=(20,7))\nsns.barplot(x=sector_revenue['Sector'],y=sector_revenue['Total_revenue'],color='#4090c5')\nplt.xticks(rotation=60,horizontalalignment='right')\nplt.ylabel('Total revenue in millions of $',fontsize=15)\nplt.xlabel(\"Sector\",fontsize=15)\nplt.title('Sector wise total revenue generated',fontsize=17)\nplt.xticks(fontsize=11)\nplt.yticks(fontsize=13)","1aa721d0":"# Data Analyst Job EDA","23c821ab":"### If you like my work, please upvote this kernel since it will keep me motivated to perform more in-depth research on other datasets....","00c593ef":"Removing \"employees\" from the \"Size\".","4da6f533":"### Observations\n\"Company Name\" has its rating after \"\\n\", which is not required as we already have a Rating column\n\nRemoving excess text and only recover company information. ","99df3d5b":"How the companies stand on the rating scale\n","8f2211d5":"### Observations\nCalifornia, Illinois, Colorado are the top 3 states with highest mean salary for Data Analyst.","dd6128fc":"### Observations\n-1 Indicates null values.\n\nlets explore other columns as well to see if there are such null values(in disguise).","d3db65fc":"## Loading the data\n","15b80b17":"![achievement-analysis-brainstorming-business.jpg](attachment:achievement-analysis-brainstorming-business.jpg)","0be08a99":"Removing stop words from the description as when the Wordcloud is created, because of high frequency of stop words like(from,the,a,and,an,on), they will be given higher priority(which has no importance)\n","018a9ebf":"## Importing required libraries","76687d96":"### Observations\n\"Real Estate\",\"Arts, Entertainment & Recreation\", and \"Biotech & Pharma\" has the highest mean salary based on sector ","ea549cf8":"Creating a function which will output the maximum Revenue of the company from column \"Revenue\".","0b861ad7":"Creating a WordCloud of JobTitle. It gives us a high level view of current trend of Data Analyst jobs","20025bb0":"Python, java, javascript are the top programming languages in the Industry. ","857ea72b":"\"Location\" has city and state information.\n\nSplitting it into two individual columns(\"State\", \"City\")","bda856f3":"### Observations\nThere is not much difference in mean salary of Data Analyst when compared with the Size of the company.\n\ni.e even a small company with less than 200 employees, and MNC with greater than 10,000 employees have similar mean salary for Data Analyst","6057b08b":"### Observations\nFinance and IT sectors have the highest total revenues.","7cc9f4eb":"### Observations\nSimilar to the column \"Industry\", all these columns (\"Sector\",\"Competitor\",\"Easy Apply\",\"Revenue\") has -1 as the null value.\n\nreplacing -1 with null values","6a742942":"## Imputing\n\nfilling na's.\n\nas model building is not the motive of this Kernel, na's are filled with \"Unknown\" or 0.","beeb4321":"Dataframe.describe(include='all'), gives us all the required descriptive stats\nwhich include\n1. the total number of non NULL values.\n2. If it is a categorical variable, the number of unique values in it.\n3. Most frequent value in the categorical variable.\n4. Descriptive statistics like minimum, maximum, mean, standard deviation, (25-50-75) quantiles.","b2ea639b":"few Job Title got two sections,(The job title and the department) which is separated by \",\".\n\ncreating two columns by splitting the \"Job Title\"","4814ec98":"### Observations\nCalifornia, Texas and NewYork are the top 3 states which have highest Data Analyst requirement.","e4b72942":"Lets take a look at the Data","c95fc682":"### Observations\n\"Salary Estimate\" has a lot of special characters and text, we only need the estimated number(in integer format).\n\nRemoving text(Glassdoor est. ,$, K, -) from the column and splitting it into two columns max and min salary.","5aa52850":"Finding out important programming languages and Big data technologies that companies seek from the applicants","d4f95a76":"### Observations\nSelf employeed, School,and Government ownership has the least mean salary for a Data Analyst"}}