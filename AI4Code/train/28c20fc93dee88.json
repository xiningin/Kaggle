{"cell_type":{"05fa61f9":"code","8b76d0f9":"code","01a297b4":"code","47e16548":"code","e59ed420":"code","ece011b2":"code","61b2119a":"code","2d8838ec":"code","b9c51698":"code","8ca8b277":"code","e927851d":"code","6c3decc3":"markdown","af63bb70":"markdown","8f1c4809":"markdown","c5f4ae73":"markdown","06b3c863":"markdown","58e8d846":"markdown","6863b85e":"markdown","3d9f37ab":"markdown","e9a0e360":"markdown","3eb461f0":"markdown","b70e47ad":"markdown","c8fb1e44":"markdown","60e36140":"markdown","8501a318":"markdown","23865139":"markdown"},"source":{"05fa61f9":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\n\nsns.set_style(\"dark\")\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)","8b76d0f9":"bank_data = pd.read_csv('\/kaggle\/input\/bank-marketing-data-set\/bank-additional-full.csv', sep = ';', header = 0)","01a297b4":"sns.set_style(\"dark\")\nplt.figure(figsize=(10, 10))\n\nfig_pallete = {'no' : '#EF3627' , 'yes' : '#1CDD25'}\n\nplot = sns.catplot(x=\"y\", kind = 'count', data=bank_data, palette = fig_pallete)\n\nplt.title('Client subscribe to a term deposit?', size = 14, fontweight = 'bold', pad = 14)\nplot.set(ylabel = None)\nplot.set(yticklabels=[])\nplot.set(xlabel = None)\nplot.set_xticklabels(size = 10, fontweight = 'bold')\n\nfor i, bar in enumerate(plot.ax.patches):\n    h = bar.get_height()\n    plot.ax.text(\n        i, # bar index\n        h+1000, # y coordinate of text\n        '{}'.format(int(h)),  # y label\n        ha='center', \n        va='center', \n        fontweight='bold', \n        size=10)","47e16548":"features = pd.get_dummies(bank_data.drop('y', axis = 1)).values\nlabels = bank_data['y'].replace({'no': 0, 'yes': 1}).values","e59ed420":"rf = RandomForestClassifier(n_estimators = 100, random_state = 202)","ece011b2":"def cross_val_with_metrics(X, y, model, kfold_splits, model_name):\n\n    class0_precisions = []\n    class0_recalls = []\n    class1_precisions = []\n    class1_recalls = []\n    tprs = []\n    tnrs = []\n    ppvs = []\n    fprs = []\n    fnrs = []\n    fdrs = []\n    accs = []\n    result = {}\n\n    cv = StratifiedKFold(n_splits = kfold_splits)\n\n    for train_index, test_index in cv.split(X, y):\n\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        trained_model = model.fit(X_train, y_train)\n\n        model_predictions = trained_model.predict(X_test)\n\n        model_confusion_matrix = confusion_matrix(y_test, model_predictions)\n\n        #Metrics by class\n\n        precision_class_0 = model_confusion_matrix[0][0] \/ np.sum(model_confusion_matrix[0])\n        precision_class_1 = model_confusion_matrix[1][1] \/ np.sum(model_confusion_matrix[1])\n\n        recall_class_0 = model_confusion_matrix[0][0] \/ np.sum([row[0] for row in model_confusion_matrix])\n        recall_class_1 = model_confusion_matrix[1][1] \/ np.sum([row[1] for row in model_confusion_matrix])\n\n        class0_precisions.append(precision_class_0)\n        class1_precisions.append(precision_class_1)\n        class0_recalls.append(recall_class_0)\n        class1_recalls.append(recall_class_1)\n\n        #Overall Metrics\n\n        false_positives = model_confusion_matrix.sum(axis=0) - np.diag(model_confusion_matrix) \n        false_negatives = model_confusion_matrix.sum(axis=1) - np.diag(model_confusion_matrix)\n        true_positives = np.diag(model_confusion_matrix)\n        true_negatives = model_confusion_matrix.sum() - (false_positives + false_negatives + true_positives)\n\n        FP = false_positives.astype(float)\n        FN = false_negatives.astype(float)\n        TP = true_positives.astype(float)\n        TN = true_negatives.astype(float)\n\n        # Sensitivity, hit rate, recall, or true positive rate\n        TPR = TP\/(TP+FN)\n        tprs.append(TPR)\n\n        # Specificity or true negative rate\n        TNR = TN\/(TN+FP) \n        tnrs.append(TNR)\n\n        # Precision or positive predictive value\n        PPV = TP\/(TP+FP)\n        ppvs.append(PPV)\n\n        # Fall out or false positive rate\n        FPR = FP\/(FP+TN)\n        fprs.append(FPR)\n\n        # False negative rate\n        FNR = FN\/(TP+FN)\n        fnrs.append(FNR)\n\n        # False discovery rate\n        FDR = FP\/(TP+FP)\n        fdrs.append(FDR)\n\n        # Overall accuracy\n        ACC = (TP+TN)\/(TP+FP+FN+TN)\n        accs.append(ACC)\n\n    result['model_name'] = model_name\n    result['class0_precision'] = round(np.mean(class0_precisions), 2)\n    result['class0_recall'] = round(np.mean(class0_recalls), 2)\n    result['class1_precision'] = round(np.mean(class1_precisions), 2)\n    result['class1_recall'] = round(np.mean(class1_recalls), 2)\n    result['true_positive_rate'] = round(np.mean(tprs), 2)\n    result['true_negative_rate'] = round(np.mean(tnrs), 2)\n    result['false_positive_rate'] = round(np.mean(fprs), 2)\n    result['false_negative_rate'] = round(np.mean(fnrs), 2)\n    result['false_discovery_rate'] = round(np.mean(fdrs), 2)\n    result['overall_precision'] = round(np.mean(ppvs), 2)\n    result['overall_accuracy'] = round(np.mean(accs), 2)\n\n    return result","61b2119a":"sm = SMOTE(sampling_strategy = 'not majority', k_neighbors = 50, random_state = 202)\n\nfeatures_res, labels_res = sm.fit_resample(features, labels)","2d8838ec":"sns.set_style(\"dark\")\nsns.set(rc={\"figure.figsize\":(10, 10)}) \n\nlabels_res_df = pd.DataFrame(labels_res, columns = ['y'])\n\nfig_pallete = {0 : '#EF3627' , 1 : '#1CDD25'}\n\nplot = sns.catplot(x = 'y', kind = 'count', data=labels_res_df, palette = fig_pallete)\n\nplt.title('Client subscribe to a term deposit?', size = 14, fontweight = 'bold', pad = 14)\nplot.set(ylabel = None)\nplot.set(yticklabels=[])\nplot.set(xlabel = None)\nplot.set_xticklabels(size = 10, fontweight = 'bold')\n\nfor i, bar in enumerate(plot.ax.patches):\n    h = bar.get_height()\n    plot.ax.text(\n        i, # bar index\n        h+1000, # y coordinate of text\n        '{}'.format(int(h)),  # y label\n        ha='center', \n        va='center', \n        fontweight='bold', \n        size=10)","b9c51698":"unbalanced_model_results = cross_val_with_metrics(X = features, y = labels, model = rf, kfold_splits = 10, model_name = 'unbalanced_model')\nbalanced_model_results = cross_val_with_metrics(X = features_res, y = labels_res, model = rf, kfold_splits = 10, model_name = 'balanced_model')","8ca8b277":"results_df = pd.DataFrame([unbalanced_model_results, balanced_model_results])","e927851d":"sns.set_style(\"dark\")\nsns.set(rc={\"figure.figsize\":(30, 30)}) \nfig, axes = plt.subplots(3, 4)\n\nmetrics = results_df.drop('model_name', axis = 1).columns\n\nfig_pallete = {'unbalanced_model' : '#14A9E5' , 'balanced_model' : '#B214E5'}\n\nfig.suptitle('Comparing SMOTE data balancing effect on model\\'s performance', size = 20, fontweight = 'bold', va = 'center', ha = 'center')\n\nfig.subplots_adjust(wspace=0.05)\n\nfor metric, ax in zip(metrics, axes.flatten()):\n\n    plot = sns.barplot(x = 'model_name', y = metric, data = results_df, palette = fig_pallete, ax = ax)\n    plot.set(ylabel = None)\n    plot.set(yticklabels=[])\n    plot.set(xlabel = None)\n    \n    plot.set_title(metric, size = 12, fontweight = 'bold', pad = 14)\n    \n    for bar in plot.patches:\n   \n        plot.annotate(format(bar.get_height(), '.2f'),\n                       (bar.get_x() + bar.get_width() \/ 2,\n                        bar.get_height()), ha='center', va='center',\n                       size=10, xytext=(0, 8),\n                       textcoords='offset points')\n    \naxes[2][3].set_axis_off()\n\nfig.tight_layout(pad = 3)","6c3decc3":"## Creating our RandomForest base model","af63bb70":"## Comparing results","8f1c4809":"## Data","c5f4ae73":"## Checking unbalanced data","06b3c863":"## Importing stuffs","58e8d846":"### Lets check the difference now","6863b85e":"### SMOTE is an resampling algorithm that includes K neighbors data points given a existing data point on our resampled data. On our example, the sampling_strategy is 'not majority', soo it will only resample the minority class and for each data point on our resampled data we want to include 50 neighbors data point's of the minority class too.","3d9f37ab":"## Resampling data with SMOTE","e9a0e360":"## Creating a function to run a cross validation on our model and return some metrics about it","3eb461f0":"### Using our 'built-in' cross validation fuction to return some metrics about each class performance too","b70e47ad":"## As we can see, it's not balanced. At this cenario, is common to models predict better the clients that will not subscribe to a term deposit, but when our model says that the client will subscribe, the probability that we actually takes that subscription (jargon alert! the model \"recall \/ hit hate \/ sensitivity\"  at class \"yes\" or \"1\") is small.","c8fb1e44":"## Soo lets run a model on that unbalanced data and in a balanced data using SMOTE and compare the results","60e36140":"## Amazing difference! 400% improvement on recall at class 1, it means that now when our model says that a client WILL get a term deposit, we have a probability of 84% that our model is correct, on our unbalanced model our probability was only 14%.","8501a318":"## Spliting our data in features and labels","23865139":"## Running models"}}