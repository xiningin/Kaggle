{"cell_type":{"2edc362d":"code","faaf789e":"code","1d64874d":"code","16c243ee":"code","497f0848":"code","5ec6c852":"code","118edd3f":"code","5463348b":"code","38796bde":"code","064fae74":"code","2b7a744e":"code","244dc109":"code","f4f4b008":"code","dc5de56b":"code","8b93a8f5":"code","94e9fae2":"markdown","0665c5d5":"markdown","da51f99b":"markdown","180c3775":"markdown","1b9f1f0a":"markdown","c0eae83b":"markdown","9d269a33":"markdown","363c89a9":"markdown","28c2a736":"markdown"},"source":{"2edc362d":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom typing import Optional\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch import nn, optim\nfrom torchvision.io import read_image\nfrom torchvision.transforms import ConvertImageDtype, Resize, Normalize\nfrom torchvision.transforms import RandomHorizontalFlip, Compose\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\npd.set_option(\"display.max_rows\", None)\nplt.style.use('ggplot')","faaf789e":"# Duplicate images, credit to https:\/\/www.kaggle.com\/valleyzw\/petfinder-duplicate-images\n\nSIMILAR_IDS = [\n    '13d215b4c71c3dc603cd13fc3ec80181_373c763f5218610e9b3f82b12ada8ae5',\n    '5ef7ba98fc97917aec56ded5d5c2b099_67e97de8ec7ddcda59a58b027263cdcc',\n    '839087a28fa67bf97cdcaf4c8db458ef_a8f044478dba8040cc410e3ec7514da1',\n    '1feb99c2a4cac3f3c4f8a4510421d6f5_264845a4236bc9b95123dde3fb809a88',\n    '3c50a7050df30197e47865d08762f041_def7b2f2685468751f711cc63611e65b',\n    '37ae1a5164cd9ab4007427b08ea2c5a3_3f0222f5310e4184a60a7030da8dc84b',\n    '5a642ecc14e9c57a05b8e010414011f2_c504568822c53675a4f425c8e5800a36',\n    '2a8409a5f82061e823d06e913dee591c_86a71a412f662212fe8dcd40fdaee8e6',\n    '3c602cbcb19db7a0998e1411082c487d_a8bb509cd1bd09b27ff5343e3f36bf9e',\n    '0422cd506773b78a6f19416c98952407_0b04f9560a1f429b7c48e049bcaffcca',\n    '68e55574e523cf1cdc17b60ce6cc2f60_9b3267c1652691240d78b7b3d072baf3',\n    '1059231cf2948216fcc2ac6afb4f8db8_bca6811ee0a78bdcc41b659624608125',\n    '5da97b511389a1b62ef7a55b0a19a532_8ffde3ae7ab3726cff7ca28697687a42',\n    '78a02b3cb6ed38b2772215c0c0a7f78e_c25384f6d93ca6b802925da84dfa453e',\n    '08440f8c2c040cf2941687de6dc5462f_bf8501acaeeedc2a421bac3d9af58bb7',\n    '0c4d454d8f09c90c655bd0e2af6eb2e5_fe47539e989df047507eaa60a16bc3fd',\n    '5a5c229e1340c0da7798b26edf86d180_dd042410dc7f02e648162d7764b50900',\n    '871bb3cbdf48bd3bfd5a6779e752613e_988b31dd48a1bc867dbc9e14d21b05f6',\n    'dbf25ce0b2a5d3cb43af95b2bd855718_e359704524fa26d6a3dcd8bfeeaedd2e',\n    '43bd09ca68b3bcdc2b0c549fd309d1ba_6ae42b731c00756ddd291fa615c822a1',\n    '43ab682adde9c14adb7c05435e5f2e0e_9a0238499efb15551f06ad583a6fa951',\n    'a9513f7f0c93e179b87c01be847b3e4c_b86589c3e85f784a5278e377b726a4d4',\n    '38426ba3cbf5484555f2b5e9504a6b03_6cb18e0936faa730077732a25c3dfb94',\n    '589286d5bfdc1b26ad0bf7d4b7f74816_cd909abf8f425d7e646eebe4d3bf4769',\n    '9f5a457ce7e22eecd0992f4ea17b6107_b967656eb7e648a524ca4ffbbc172c06',\n    'b148cbea87c3dcc65a05b15f78910715_e09a818b7534422fb4c688f12566e38f',\n    '3877f2981e502fe1812af38d4f511fd2_902786862cbae94e890a090e5700298b',\n    '8f20c67f8b1230d1488138e2adbb0e64_b190f25b33bd52a8aae8fd81bd069888',\n    '221b2b852e65fe407ad5fd2c8e9965ef_94c823294d542af6e660423f0348bf31',\n    '2b737750362ef6b31068c4a4194909ed_41c85c2c974cc15ca77f5ababb652f84',\n    '01430d6ae02e79774b651175edd40842_6dc1ae625a3bfb50571efedc0afc297c',\n    '72b33c9c368d86648b756143ab19baeb_763d66b9cf01069602a968e573feb334',\n    '03d82e64d1b4d99f457259f03ebe604d_dbc47155644aeb3edd1bd39dba9b6953',\n    '851c7427071afd2eaf38af0def360987_b49ad3aac4296376d7520445a27726de',\n    '54563ff51aa70ea8c6a9325c15f55399_b956edfd0677dd6d95de6cb29a85db9c',\n    '87c6a8f85af93b84594a36f8ffd5d6b8_d050e78384bd8b20e7291b3efedf6a5b',\n    '04201c5191c3b980ae307b20113c8853_16d8e12207ede187e65ab45d7def117b'\n]\n\nSIMILAR_PAIRS = pd.Series(SIMILAR_IDS).str.extract(r\"(?P<first>\\w+)_(?P<second>\\w+)\")","1d64874d":"# Remove duplicate images with lower Pawpularity scores\n# following https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/285140\n\ndef drop_duplicates(meta, pairs):\n    \"\"\"\n    Return metadata where only the duplicate with the highest Pawpularity score\n    is kept.\n    \"\"\"\n    # Find duplicates\n    meta = meta.set_index('Id')\n    duplicates = pairs.apply(\n        lambda row: (\n            row['first']\n            if meta.at[row['first'], 'Pawpularity'] < meta.at[row['second'], 'Pawpularity']\n            else row['second']\n        ),\n        axis=1\n    )\n    # Query non-duplicate metadata\n    meta.query('Id not in @duplicates', inplace=True)\n    meta.reset_index(inplace=True)\n    return meta","16c243ee":"class PetfinderDataset(Dataset):\n    \"\"\"Training\/Testing dataset of Petfinder profiles.\"\"\"\n    \n    def __init__(\n        self,\n        train: bool = True,\n        img_transform = None,\n        meta_transform = None,\n        score_transform = None\n    ):\n        \"\"\"\n        Arguments\n        ---------\n            train: Whether the training dataset or the testing dataset\n            img_transform: Transformation of images\n            meta_transform: Transformation of metadata\n            socre_transform: Transformation of pawpularity scores\n        \n        Note\n        ----\n        `score_transform` is not supported if `train` is `False`.\n        \"\"\"\n        self.dirpath = '..\/input\/petfinder-pawpularity-score'\n        self.img_dir = 'train' if train else 'test'\n        self.meta = pd.read_csv(\n            os.path.join(self.dirpath, 'train.csv' if train else 'test.csv')\n        )\n        if train: self.meta = drop_duplicates(self.meta, SIMILAR_PAIRS)\n        self.metacols = self.meta.columns.drop(\n            ['Id', 'Pawpularity'] if train else 'Id'\n        )\n        self.train = train\n        self.img_transform = img_transform\n        self.meta_transform = meta_transform\n        self.score_transform = score_transform\n    \n    def __len__(self):\n        return len(self.meta.index)\n    \n    def __getitem__(self, idx):\n        \"\"\"\n        Return the image, metadata and score given the index of a sample.\n        \n        Note\n        ----\n        If `self.train` is `False`, the returned score will be -1.\n        \"\"\"\n        # Obtain image, metadata and score\n        ind = self.meta.index[idx]  # index in metadata\n        img_path = os.path.join(\n            self.dirpath, self.img_dir,\n            f\"{self.meta.loc[ind, 'Id']}.jpg\"\n        )\n        img = read_image(img_path)\n        meta = self.meta.loc[ind, self.metacols]\n        meta = meta.values.astype(np.float32)  # convert data type\n        score = self.meta.loc[ind, 'Pawpularity'] if self.train else -1.0\n        score = np.float32(score)  # convert data type\n        # Apply transformations\n        if self.img_transform is not None:\n            img = self.img_transform(img)\n        if self.meta_transform is not None:\n            meta = self.meta_transform(meta)\n        if self.train and self.score_transform is not None:\n            score = self.score_transform(score)\n        return img, meta, score","497f0848":"class PetfinderDataModule(pl.LightningDataModule):\n    \"\"\"Data module of Petfinder profiles.\"\"\"\n    \n    def __init__(\n        self,\n        image_size: int = 224,\n        batch_size: int = 64,\n        num_validation: int = 128\n    ):\n        \"\"\"\n        Arguments\n        ---------\n            image_size: Size of square images after transformations\n            batch_size: Batch size loading training\/validation dataset\n            num_validataion: Number of observations in validataion dataset\n        \"\"\"\n        super().__init__()\n        self.image_size = image_size\n        self.batch_size = batch_size\n        self.num_validation = num_validation\n    \n    def setup(self, stage: Optional[str] = None):\n        # Transformations\n        prerequisite = [  # required transformations for pretrained model\n            ConvertImageDtype(torch.float32),\n            Resize((self.image_size, self.image_size)),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]\n        augmentation = [RandomHorizontalFlip(),]  # data augmentation1\n        transforms = {'img_transform': Compose(prerequisite+augmentation)}\n        # Split training set and validation set\n        if stage in (None, 'fit'):\n            self.dataset = PetfinderDataset(train=True, **transforms)\n            self.trainset, self.valset = random_split(\n                self.dataset,\n                [len(self.dataset)-self.num_validation, self.num_validation]\n            )\n        # Load dataset for prediction\n        if stage == 'predict':\n            self.predictset = PetfinderDataset(train=False, **transforms)\n    \n    def train_dataloader(self):\n        return DataLoader(self.trainset, batch_size=BATCH_SIZE, shuffle=True)\n    \n    def val_dataloader(self):\n        return DataLoader(self.valset, batch_size=BATCH_SIZE)\n    \n    def predict_dataloader(self):\n        return DataLoader(self.predictset, batch_size=len(self.predictset))\n    \n    def num_meta(self):\n        \"\"\"\n        Return number of features in the metadata.\n        \n        Note\n        ----\n        Must be called after running self.setup().\n        \"\"\"\n        return len(self.dataset.metacols)\n    \n    def meta_odds(self):\n        \"\"\"\n        Return the odds against features in the metadata.\n        \n        Note\n        ----\n        Must be called after running self.setup().\n        \"\"\"\n        pos_rate = self.dataset.meta.loc[:, self.dataset.metacols].mean()\n        pos_rate = torch.from_numpy(pos_rate.values).float()\n        return (1 - pos_rate) \/ pos_rate","5ec6c852":"class Regressor(nn.Module):\n    \"\"\"Custom regressor to predict Pawpularity score from latent features.\"\"\"\n    \n    def __init__(\n        self,\n        num_feats: int,\n        dropout: float = 0.5,\n        scale: float = 100.0\n    ):\n        \"\"\"\n        Arguments\n        ---------\n            num_feats: Input feature dimension\n            dropout: Dropout rate\n            scale: Scale of predicted scores; scores are in range of `[0, scale]`.\n        \"\"\"\n        super().__init__()\n        dim_intermediate = int(num_feats ** 0.5)\n        self.dropout = nn.Dropout(dropout)\n        self.layer1 = nn.Sequential(\n            nn.Linear(num_feats, dim_intermediate),\n            nn.BatchNorm1d(dim_intermediate),\n            nn.Dropout(dropout),\n            nn.Sigmoid()\n        )\n        self.layer2 = nn.Sequential(\n            nn.Linear(dim_intermediate, 1),\n            nn.Sigmoid()\n        )\n        self.scale = scale\n    \n    def forward(self, feats):\n        feats = self.dropout(feats)\n        feats = self.layer1(feats)\n        preds = self.layer2(feats)\n        preds = self.scale * preds\n        return preds","118edd3f":"class PawpularityPredictor(pl.LightningModule):\n    \"\"\"Transfer learning model with two-stage finetuning.\"\"\"\n    \n    def __init__(\n        self,\n        backbone: str ='resnet_18',\n        training_phase: str = 'regression',\n        num_meta: int = 12,\n        pos_weight: torch.Tensor = torch.ones(12),\n        classification_threshold: float = 0.5,\n        regressor_kwargs: Optional[dict] = None\n    ):\n        \"\"\"\n        Arguments\n        ---------\n            backbone: Backbone model to fine tune\n            training_phase: Indicator of classification or regression\n            num_meta: Number of features in metadata\n            pos_weight: Weight of positive samples passed to classification loss\n            classification_threshold: Threshold for binary classification\n            regressor_kwargs: Keyword arguments passed to regressor\n        \"\"\"\n        super().__init__()\n        if training_phase not in ('classification', 'regression'):\n            raise ValueError('phase must be either classification or regression')\n        if backbone == 'resnet_18':\n            self.backbone = torchvision.models.resnet18(pretrained=True)\n            num_feats = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        else:\n            raise ValueError('backbone model not supported')\n        self.classifier = nn.Linear(num_feats, num_meta)\n        if regressor_kwargs is None: regressor_kwargs = {}\n        self.regressor = Regressor(num_feats, **regressor_kwargs)\n        self.lossfn_classification = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n        self.lossfn_regression = nn.MSELoss()\n        self.classification_threshold = classification_threshold\n        self.training_phase = training_phase\n        self.freeze_part_by_training_phase()\n    \n    def freeze_part_by_training_phase(self):\n        \"\"\"Freeze part of model according to the internal training phase.\"\"\"\n        if self.training_phase == 'classification':\n            self.classifier.requires_grad_(True)\n            self.regressor.requires_grad_(False)  # freeze regressor\n        else:\n            self.regressor.requires_grad_(True)\n            self.classifier.requires_grad_(False)  # freeze classifier\n    \n    def forward(self, imgs):\n        return self.regressor(self.backbone(imgs))\n    \n    def training_step(self, batch, batch_idx):\n        imgs, meta, scores = batch\n        if self.training_phase == 'classification':\n            logits = self.classifier(self.backbone(imgs))\n            loss = self.lossfn_classification(logits, meta)\n            self.log('Loss:classification\/train', loss)\n            preds = torch.sigmoid(logits) > self.classification_threshold\n            acc = (preds == meta).float().mean().item()  # batch accuracy\n            self.log('Accuracy\/train', acc)\n        else:\n            preds = self.regressor(self.backbone(imgs))\n            loss = self.lossfn_regression(preds, scores.unsqueeze(-1))\n            self.log('Loss:regression\/train', loss)\n            rmse = torch.sqrt(loss)\n            self.log('RMSE\/train', rmse)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        imgs, meta, scores = batch\n        if self.training_phase == 'classification':\n            logits = self.classifier(self.backbone(imgs))\n            loss = self.lossfn_classification(logits, meta)\n            self.log('Loss:classification\/validation', loss)\n            preds = torch.sigmoid(logits) > self.classification_threshold\n            acc = (preds == meta).float().mean().item()  # batch accuracy\n            self.log('Accuracy\/validation', acc)\n        else:\n            preds = self.regressor(self.backbone(imgs))\n            loss = self.lossfn_regression(preds, scores.unsqueeze(-1))\n            self.log('Loss:regression\/validation', loss)\n            rmse = torch.sqrt(loss)\n            self.log('RMSE\/validation', rmse)\n    \n    def configure_optimizers(self):\n        if self.training_phase == 'classification':\n            optimizer = optim.AdamW(self.parameters(), lr=1e-3)\n            return optimizer\n        else:\n            optimizer = optim.AdamW(self.parameters(), lr=1e-3)\n            return optimizer\n    \n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        imgs, _, _ = batch\n        return self(imgs)","5463348b":"IMAGE_SIZE = 224\nBATCH_SIZE = 64\nNUM_VALIDATION = 128\n\nCLASSIFICATION_THRESHOLD = 0.5\nREGRESSOR_KWARGS = {'dropout': 0.1}\n\nNUM_EPOCHS_CLASSIFICATION = 15\nNUM_EPOCHS_REGRESSION = 60\nREGRESSOR_CHECKPOINT_PERIOD = 15","38796bde":"datamodule = PetfinderDataModule(\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    num_validation=NUM_VALIDATION\n)\ndatamodule.setup()","064fae74":"model = PawpularityPredictor(\n    backbone='resnet_18',\n    training_phase='classification',\n    num_meta=datamodule.num_meta(),\n    pos_weight=datamodule.meta_odds(),\n    classification_threshold=CLASSIFICATION_THRESHOLD,\n    regressor_kwargs=REGRESSOR_KWARGS\n)\ncheckpoint_callback_classifier = ModelCheckpoint(\n    monitor='Accuracy\/validation',\n    mode='max',\n    filename='classifier-{epoch}'\n)\nlogger_classification = pl.loggers.CSVLogger('.\/logs_classification')\ntrainer = pl.Trainer(\n    gpus=1,\n    max_epochs=NUM_EPOCHS_CLASSIFICATION,\n    callbacks=[checkpoint_callback_classifier],\n    logger=logger_classification\n)\n\ntrainer.fit(model, datamodule=datamodule)","2b7a744e":"model = PawpularityPredictor.load_from_checkpoint(\n    checkpoint_callback_classifier.best_model_path,\n    training_phase='regression'\n)\ncheckpoint_callback_regressor = ModelCheckpoint(\n    filename='regressor-{epoch}',\n    every_n_epochs=REGRESSOR_CHECKPOINT_PERIOD,\n    save_top_k=-1\n)\nlogger_regression = pl.loggers.CSVLogger('.\/logs_regression')\ntrainer = pl.Trainer(\n    gpus=1,\n    max_epochs=NUM_EPOCHS_REGRESSION,\n    callbacks=[checkpoint_callback_regressor],\n    logger=logger_regression\n)\n\ntrainer.fit(model, datamodule=datamodule)","244dc109":"def diagnose_predictions(model, datamodule, num_epochs):\n    \"\"\"Output a scatter plot of the actual\/predicted Pawpularity scores.\"\"\"\n    # Setup figure\n    fig, axes = plt.subplots(ncols=2, figsize=(12,6))\n    lims = (-2, 102)\n    for ax in axes:\n        ax.set_xlabel('Actual Pawpularity Score')\n        ax.set_ylabel('Predicted Pawpularity Score')\n        ax.set_xlim(*lims)\n        ax.set_ylim(*lims)\n    axes[0].set_title('Training Samples')\n    axes[1].set_title('Validation Set')\n    fig.suptitle(f'Regressor Trained after {num_epochs} Epochs', fontsize=16)\n    \n    # Plot diagonal line\n    for ax in axes:\n        ax.plot(lims, lims, color='C3')\n    \n    # Visualize training\/validation set\n    dataloaders = (\n        DataLoader(datamodule.trainset, batch_size=NUM_VALIDATION, shuffle=True),\n        DataLoader(datamodule.valset, batch_size=NUM_VALIDATION)\n    )\n    for ax, dataloader in zip(axes, dataloaders):\n        # Plot actual\/predicted scores\n        imgs, _, scores = next(iter(dataloader))\n        with torch.no_grad():\n            preds = model(imgs)\n        ax.scatter(scores.cpu().numpy(), preds.squeeze().cpu().numpy(), c='C1')\n        # Add text of RMSE\n        rmse = torch.sqrt(model.lossfn_regression(preds, scores.unsqueeze(-1))).item()\n        textstr = f'RMSE = {rmse:.2f}'\n        props = dict(boxstyle='round', facecolor='C4', alpha=0.5)\n        ax.text(0.05, 0.95, textstr, transform=ax.transAxes, verticalalignment='top', bbox=props)\n    \n    # Output\n    os.makedirs('.\/diagnostics', exist_ok=True)\n    fig.savefig(f'.\/diagnostics\/regressor-epoch={num_epochs}.png')\n    plt.show(fig)","f4f4b008":"num_checkpoints = NUM_EPOCHS_REGRESSION \/\/ REGRESSOR_CHECKPOINT_PERIOD\ncheckpoint_epochs = [\n    REGRESSOR_CHECKPOINT_PERIOD * i for i in range(num_checkpoints+1)\n]\n\n# Diagnose predictions during regressor training\nfor epoch in checkpoint_epochs:\n    if epoch == 0:\n        ckptpath = checkpoint_callback_classifier.best_model_path\n    else:\n        ckptpath = os.path.join(\n            logger_regression.log_dir,\n            f'checkpoints\/regressor-epoch={epoch-1}.ckpt'\n        )\n    model = PawpularityPredictor.load_from_checkpoint(ckptpath)\n    diagnose_predictions(model, datamodule, epoch)","dc5de56b":"preds, = trainer.predict(model, datamodule=datamodule)","8b93a8f5":"# Output predictions\npredictions = pd.DataFrame({\n    'Id': datamodule.predictset.meta['Id'],\n    'Pawpularity': preds.squeeze().cpu().numpy()\n})\npredictions.to_csv('.\/submission.csv', index=False)","94e9fae2":"# Inference","0665c5d5":"## Finetune Backbone & Classifier","da51f99b":"# Diagnostics","180c3775":"## Finetune Backbone & Regressor","1b9f1f0a":"# Two-stage Finetuning","c0eae83b":"# Training with Two-stage Finetuning","9d269a33":"# Dataset & Datamodule","363c89a9":"Two stages of finetuning:\n1. Finetune the pretrained model to capture the metadata.\n2. Finetune the pretrained model (tuned after step 1.) along with a regressor to predict Pawpularity score.","28c2a736":"# Model & Training\/Validation Step"}}