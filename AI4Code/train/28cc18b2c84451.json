{"cell_type":{"965bd07d":"code","4d95e864":"code","ff6f83c7":"code","9947ebb8":"code","05db4abe":"code","858d24a3":"code","e5a9bb80":"code","cd87de9a":"code","04cb0469":"code","206bae97":"code","61c47d9b":"code","fb20356c":"code","78cc3ad2":"code","e1f2590d":"code","b6e84ad4":"code","7343687a":"code","c5e6b7da":"code","5102e500":"code","646ab038":"code","a22f7795":"code","335b6c8d":"code","da2a7975":"code","2ad18c7c":"code","d7ac3e2f":"markdown","39dcf8ea":"markdown","b130e034":"markdown","b592b9ae":"markdown","0b5f7d30":"markdown","f43f86bd":"markdown","147f0b5e":"markdown","a014bedb":"markdown","e38ad1e1":"markdown","7c4e5b86":"markdown","7e9e3670":"markdown","6d9d6f63":"markdown","a651d3c0":"markdown","de82e257":"markdown","839f6252":"markdown","8b6472f1":"markdown","22f6a3df":"markdown","73d2ba80":"markdown","fc6ac726":"markdown","7941611f":"markdown","5b7d4b8b":"markdown","a5cbaf49":"markdown","94cb988e":"markdown","f9034c6a":"markdown","a7e6c1d4":"markdown","4bac833d":"markdown","74591e5b":"markdown","e844ac4f":"markdown","0b01236a":"markdown","99139c21":"markdown","c61a3cbd":"markdown","d570d623":"markdown"},"source":{"965bd07d":"import numpy as np\nimport pandas as pd\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import RobustScaler\nimport warnings","4d95e864":"df = pd.read_csv(\"..\/input\/credit-card-customers\/BankChurners.csv\")\n# First droping all features unnecessary. \ndf = df.drop(['CLIENTNUM', 'Customer_Age',\n                 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n                 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1)","ff6f83c7":"# To prevent any Dimensional Data Curse I don't work with onehot to duplicate Columns.\n# I prefer to make some routine codes to prevents alot of calcules beeing cause by the features numbers.\n\ndef Attrition_Flag2num(x):\n    if x == 'Attrited Customer':\n        return 1\n    if x == \"Existing Customer\":\n        return 0\ndf['Attrition_Flag'] = df['Attrition_Flag'].apply(Attrition_Flag2num)\n\n\n        \n# Secondly I begin to transform every feature needed to number.\ndef Gender2num(x):\n    if x == 'M':\n        return 1\n    if x == \"F\":\n        return 0\ndf['Gender'] = df['Gender'].apply(Gender2num)\n                              \n\ndef Education_Level2num(x):\n    if x == 'Uneducated':\n        return 0\n    if x == 'Unknown':\n        return 0\n    if x == 'College':\n        return 1\n    if x == 'Post-Graduate':\n        return 1\n    if x == 'Graduate':\n        return 2\n    if x == 'High School':\n        return 3\n    if x == 'Doctorate':\n        return 4\ndf['Education_Level'] = df['Education_Level'].apply(Education_Level2num)\n                   \n\ndef Marital_Status2num(x):\n    if x == 'Unknown':\n        return 0\n    if x == 'Single':\n        return 1\n    if x == 'Divorced':\n        return 1\n    if x == 'Married':\n        return 2\ndf['Marital_Status'] = df['Marital_Status'].apply(Marital_Status2num)\n\ndef Card_Category2num(x):\n    if x == 'Blue':\n        return 0\n    if x == 'Silver':\n        return 1\n    if x == 'Gold':\n        return 2\n    if x == 'Platinum':\n        return 3\ndf['Card_Category'] = df['Card_Category'].apply(Card_Category2num)\n                      \n\n# Inwuery of 'Income_Category' category feature :    \nprint(df['Income_Category'])\n# To prevent Linkage I work with small nubers.\ndef Income_Category2income_int(x):\n    if x == '$120K +':\n        return 13\n    if x == '$80K - $120K':\n        return 10\n    if x == '$60K - $80K':\n        return 7\n    if x == '$40K - $60K':\n        return 5\n    if x == 'Less than $40K':\n        return 2\n    if x == 'Unknown':\n        return 0\ndf['Income_Category'] = df['Income_Category'].apply(Income_Category2income_int)\n\n\ndf.dtypes\ndf.info()\n\n\n\nX = df.drop('Attrition_Flag', axis=1)\ny = df['Attrition_Flag']       \n","9947ebb8":"#  Ignore warnings\nwarnings.filterwarnings(\"ignore\")","05db4abe":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)","858d24a3":"svclassifier = SVC(kernel='linear')\nsvclassifier.fit(X_train, y_train)","e5a9bb80":"y_pred = svclassifier.predict(X_test)","cd87de9a":"print('Simple SVM')\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","04cb0469":"X = df.drop('Attrition_Flag', axis=1)\ny = df['Attrition_Flag']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)       \n\n","206bae97":"svclassifier = SVC(kernel ='poly', degree = 4)","61c47d9b":"svclassifier.fit(X_train, y_train)","fb20356c":"y_pred = svclassifier.predict(X_test)","78cc3ad2":"print('Poly karnel')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n","e1f2590d":"X = df.drop('Attrition_Flag', axis=1)\ny = df['Attrition_Flag']","b6e84ad4":"y[y == 0] = -1\nX = RobustScaler().fit_transform(X)","7343687a":"# For `zero_division` control I need to RobustScalar and change label '0' to '1'\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)  ","c5e6b7da":"svclassifier = SVC(kernel='rbf')\n\nsvclassifier.fit(X_train, y_train)","5102e500":"y_pred = svclassifier.predict(X_test)","646ab038":"# precision_score(y_true, y_pred, average=None, zero_division=1)","a22f7795":"print('Gaussian karnel')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","335b6c8d":"svclassifier = SVC(kernel='sigmoid')\nsvclassifier.fit(X_train, y_train)","da2a7975":"y_pred = svclassifier.predict(X_test)","2ad18c7c":"print('Sigmoid karnel')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","d7ac3e2f":"0. Introduction ","39dcf8ea":"Here I take an aneconomic data tabular clients bank to be inqueried as classification\nby some types SVM models.I'm Implamenting-econommic-dataset-via-SVM-s-models-comparisonable-preventing-Dimensional-Data-Curse by using some routines, and not onehot. Onehot could made an inflation features and some clculating inflation.\nI try to compare both simple and kernel SVMs. I studied the intuition behind the\nSVM algorithm and how it can be implemented with Python's Scikit-Learn library. \nI also studied different types of kernels that can be used to implement \nkernel SVM.\nAll that were done via small data of customers bank as classification.\nI try to prevent any Dimensional Data Curse - no onehot. \nI take some comparison on model's SVM'","b130e034":"6. Making Predictions.","b592b9ae":"Gaussian Kernel\n---------------","0b5f7d30":"5. Fitting method of SVC class.","f43f86bd":"7. Evaluating the Algorithm","147f0b5e":"1.-4. All the steps are the same.","a014bedb":"4. Dividing data into training and test sets.  ","e38ad1e1":"7. Evaluating the Algorithm","7c4e5b86":"Implementing Kernel SVM with Scikit-Learn.\n------------------------------------------","7e9e3670":"This kind of reduces columns cause some warnings since my way to reduce them cause some miss understandings. Even that calculating was done good and seem to be simpler than one hot.","6d9d6f63":"5. Fitting method of SVC class with Polynomial Kernel.","a651d3c0":"5. Fitting method of SVC class with Gaussian Kernel.","de82e257":"Gamma is used when we use the Gaussian RBF kernel. if you use linear or\npolynomial kernel then you do not need gamma only you need C hypermeter. \nGamma is a hyperparameter which we have to set before training model.\nGamma decides that how much curvature we want in a decision boundary.","839f6252":"This Scaler removes the median and scales the data according to the quantile \nrange (defaults to IQR: Interquartile Range). The IQR is the range between \nthe 1st quartile (25th quantile) and the 3rd quartile (75th quantile).","8b6472f1":"For this data:\nIf we compare the performance of the different types of kernels\nwe can clearly see that the Gaussian kernel performs the worst. \nThis is due to the reason that Gaussian function returns two \nvalues, 0 and 1, therefore it is more suitable for binary classification \nproblems sincewe forced it to be 0 and 1.However, in our case we had two output classes.","22f6a3df":"In machine learning, the polynomial kernel is a kernel function commonly used with support vector machines (SVMs) and other kernel models. It represents the similarity of vectors (training samples) in a space of polynomial degree greater than that of the original variables, which allows training of non-linear models. \n\nExplication en francais:\n    En apprentissage automatique, le noyau polynomial est une fonction\n    noyau couramment utilis\u00e9e avec les machines \u00e0 vecteurs de support (SVMs)\n    et d'autres mod\u00e8les \u00e0 noyaux. Il repr\u00e9sente la similarit\u00e9 des vecteurs\n    (\u00e9chantillons d'apprentissage) dans un espace de degr\u00e9 polynomial plus\n    grand que celui des variables d'origine, ce qui permet un apprentissage\n    de mod\u00e8les non-lin\u00e9aires. ","73d2ba80":"All the first steps are the same as simple SVM, so\nI jump directly to Polynomial Kernel.","fc6ac726":"7. Evaluating the Algorithm","7941611f":"8. Comparison of Kernel Performance.","5b7d4b8b":"6. Making Predictions.","a5cbaf49":"Polynomial Kernel:\n------------------\nThe characteristic (implicit) space of a polynomial kernel is equivalent to\nthat of polynomial regression, but without the combinatorial explosion\nof the number of parameters to be learned","94cb988e":"6. Making Predictions.","f9034c6a":"Sigmoid Kernel\n--------------","a7e6c1d4":"3. Inquery data.","4bac833d":"5. Fitting method of SVC class with Sigmoid Kernel.","74591e5b":"2. Data louded.","e844ac4f":"Adding polynomial features is simple to implement and can work with all sorts of\nMachine Learning Algorithms.\n\u2022However at a low polynomial degree it cannot deal with very complex datasets,\n\u2022With a high polynomial degree it creates a huge number of features, making the\nmodel too slow.","0b01236a":"Implementing SVM with Scikit-Learn\n-----------------------------------","99139c21":"1. Libraries to import.","c61a3cbd":"7. Evaluating the Algorithm.","d570d623":"6. Making Predictions."}}