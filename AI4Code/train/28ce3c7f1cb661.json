{"cell_type":{"1dbbf97f":"code","0066f839":"code","bed6604e":"code","df9c31d7":"code","c6d506fa":"code","24cf4db0":"code","dd060e91":"code","796362cf":"code","0acc4ddf":"code","b7c6f8df":"code","33b011ce":"code","0ea70aa1":"code","6b2bc526":"code","0d746e69":"code","654c20b5":"code","d5283306":"code","27e667d9":"code","7bea573e":"code","9ac6b519":"code","ccb6d759":"code","162eda64":"code","566e0aa2":"code","258e2f58":"code","8bcbe99b":"code","f14947fc":"code","d06c15ba":"code","5ef250c8":"code","daf7dc2a":"code","bc5f85c0":"code","02801951":"code","584b714f":"code","516392e3":"code","a90123db":"code","1b4ee102":"code","b3713dd0":"markdown","4064c0c6":"markdown","63cf2398":"markdown","3279a556":"markdown","8916e39e":"markdown","12d4734d":"markdown","8e3fc18c":"markdown","a2e39853":"markdown","84f6ec48":"markdown","9f0134c7":"markdown","ea32f227":"markdown","4b90b16a":"markdown","6967be87":"markdown","36fc58a1":"markdown","d73000d4":"markdown","d8b8514a":"markdown","8e0f4e1f":"markdown","bce37bc7":"markdown","89cedfce":"markdown","ca674704":"markdown","7061266f":"markdown","bd363a34":"markdown","fc4dda55":"markdown","bf904740":"markdown"},"source":{"1dbbf97f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # For Plotting and Visualization\nimport seaborn as sns # For Plotting and Visualization\nfrom sklearn.model_selection import train_test_split # For Splitting the Dataset into Training and Test Dataset\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as metrics # Metrics Calculation\nimport statsmodels.api as sm # For Building Logistic Regression Model\nimport os\nprint(os.listdir(\"..\/input\"))","0066f839":"class CalculateMetrics():\n        def __init__(self,x,y):\n            self.actualvalue=x\n            self.predictedvalue=y\n            \n# Calculate the Accuracy of the Model\n        def accuracy(self):\n            return metrics.accuracy_score(self.actualvalue,self.predictedvalue)\n\n# Calculate the Other Performance Evaluation Metrics \n        def eval_metrics(self):\n            confusionmatrix=metrics.confusion_matrix(self.actualvalue,self.predictedvalue)\n            # Created a Dictionary which will hold the values of Evaluation Metrics as Key-Value Pairs\n            metrics_dict={ \"ConfusionMatrix\":confusionmatrix\n                          ,\"TruePositiveRate\":confusionmatrix[1,1]\n                          ,\"FalsePositiveRate\":confusionmatrix[0,1]\n                          ,\"TrueNegativeRate\":confusionmatrix[0,0]\n                          ,\"FalseNegativeRate\":confusionmatrix[1,0]\n                          ,\"Sensitivity\":(confusionmatrix[1,1]\/float(confusionmatrix[1,1]+confusionmatrix[1,0]))\n                          ,\"Specificity\":(confusionmatrix[0,0]\/float(confusionmatrix[0,0]+confusionmatrix[0,1]))\n                         }   \n            return metrics_dict","bed6604e":"def print_evalmetrics(metrics_obj):\n    items=(('Accuracy of the Model:',metrics_obj.accuracy()),('Sensitivity:',metrics_obj.eval_metrics().get(\"Sensitivity\")),('Specificity:',metrics_obj.eval_metrics().get(\"Specificity\")),('TruePositiveRate:',metrics_obj.eval_metrics().get(\"TruePositiveRate\")),('FalsePositiveRate:',metrics_obj.eval_metrics().get(\"FalsePositiveRate\")),('TrueNegativeRate:',metrics_obj.eval_metrics().get(\"TrueNegativeRate\")),('FalseNegativeRate:',metrics_obj.eval_metrics().get(\"FalseNegativeRate\")))\n    for item in items:\n        print(item[0],item[1])","df9c31d7":"def plot_roc(actualvalue,probabilityvalue):\n    fpr,tpr,thresholds=metrics.roc_curve(actualvalue,probabilityvalue,drop_intermediate=False)\n    #Calculate the Area Under Curve Score\n    auc_score=metrics.roc_auc_score(actualvalue,probabilityvalue)\n    plt.figure(figsize=(5,5))\n    plt.plot(fpr,tpr,label='ROC Curve (area=%0.2f)'% auc_score)\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return None\n    ","c6d506fa":"# Read the input dataset\n\ndf_input=pd.read_csv(\"..\/input\/Admission_Predict_Ver1.1.csv\")\ndf_input.head()","24cf4db0":"# Read the input dataset\n\ndf_input=pd.read_csv(\"..\/input\/Admission_Predict_Ver1.1.csv\")\ndf_input.head()","dd060e91":"# Column Information of the Dataset\n\ndf_input.info()","796362cf":"# Convert Chance of Admit Column into 0 and 1 as this will be considered as response variable\ndf_input.loc[df_input['Chance of Admit ']>0.75,'Chance of Admit ']=1\ndf_input.loc[df_input['Chance of Admit ']<0.75,'Chance of Admit ']=0\ndf_input['Chance of Admit ']=df_input['Chance of Admit '].astype(np.int64)\ndf_input.head()\n","0acc4ddf":"# Understand the Correlation between the Columns in the dataset\nsns.set(style='ticks',color_codes=True)\nsns.pairplot(df_input)\nplt.show()","b7c6f8df":"# Check for Missing Values in any of the Columns in the dataset\n\ndf_input.isnull().sum()","33b011ce":"# Drop Unnecessary Columns from the Dataset\n\ndf_input=df_input.drop(['Serial No.'],axis=1)","0ea70aa1":"# Divide the input dataset into train and test dataset\n\n# Putting Feature Variable into X\n\nX=df_input.drop(['Chance of Admit '],axis=1)\nX.head()","6b2bc526":"# Putting Response Variable into Y\n\nY=df_input['Chance of Admit ']\nY.head()","0d746e69":"# Splitting the data into train and test \n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.7,test_size=0.3,random_state=100)","654c20b5":"X_train_sm=sm.add_constant(X_train)\nlogm1=sm.GLM(Y_train,X_train_sm,family=sm.families.Binomial())\nres=logm1.fit()\nres.summary()","d5283306":"# Drop the SOP variable which has high p-value\n\nX_train=X_train.drop(['SOP'],axis=1)\nX_train_sm=sm.add_constant(X_train)\nlogm2=sm.GLM(Y_train,X_train_sm,family=sm.families.Binomial())\nres2=logm2.fit()\nres2.summary()","27e667d9":"# Drop the Research Variable which has high p-value\n\nX_train=X_train.drop(['Research'],axis=1)\nX_train_sm=sm.add_constant(X_train)\nlogm3=sm.GLM(Y_train,X_train_sm,family=sm.families.Binomial())\nres3=logm3.fit()\nres3.summary()","7bea573e":"# Get the Predicted Values from the training set\n\nY_train_pred=res3.predict(X_train_sm)\nY_train_pred[:10]","9ac6b519":"Y_train_pred=Y_train_pred.values.reshape(-1)\nY_train_pred[:10]","ccb6d759":"# Creating a data frame with response variable and predicted probabilities\n\nY_train_pred_final=pd.DataFrame({'Admission':Y_train.values,'Admission_Probability':Y_train_pred})\nY_train_pred_final['StudentID']=Y_train.index\nY_train_pred_final.head()","162eda64":"# Let us create columns with different ranges of probabilities\n\nnumbers=[float(x)\/10 for x in range(10)]\nfor i in numbers:\n    Y_train_pred_final[i]=Y_train_pred_final.Admission_Probability.map(lambda x:1 if x>i else 0)\nY_train_pred_final.head()","566e0aa2":"# let us identify accuracy,sensitivity and specificity for different proability cut-off\n\ncutoff_df=pd.DataFrame(columns=['prob','accuracy','sensitivity','specificity'])\n\n# Confusion Matrix metrics are derived below\n\nnum=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n\nfor i in num:\n    cm1=confusion_matrix(Y_train_pred_final.Admission,Y_train_pred_final[i])\n    total1=sum(sum(cm1))\n    #Accuracy of the Model\n    accuracy=(cm1[0,0]+cm1[1,1])\/total1\n    #Sensitivity of the Model\n    sensitivity=cm1[1,1]\/(cm1[1,1]+cm1[1,0])\n    #Specificity of the Model\n    specificity=cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    cutoff_df.loc[i]=[i,accuracy,sensitivity,specificity]\nprint(cutoff_df)\n","258e2f58":"## Plotting Accuracy,Sensitivity and Specificity for Various Probabilities\ncutoff_df.plot.line(x='prob',y=['accuracy','sensitivity','specificity'])\nplt.show()","8bcbe99b":"# Create the Predicted Column which will be assigned a value 1 if the Probability of Admission is greater than ideal probability cut off point\n\nY_train_pred_final['Predicted']=Y_train_pred_final.Admission_Probability.map(lambda x:1 if x>0.4 else 0)\nY_train_pred_final.head()","f14947fc":"metrics_results=CalculateMetrics(Y_train_pred_final.Admission,Y_train_pred_final.Predicted)\nprint_evalmetrics(metrics_results)","d06c15ba":"## Plotting the ROC Curve for the train set\nplot_roc(Y_train_pred_final.Admission,Y_train_pred_final.Admission_Probability)","5ef250c8":"# Select Columns Necessary for Prediction\n\nX_test=X_test.drop(['SOP','Research'],axis=1)\nX_test.info()","daf7dc2a":"X_test_sm=sm.add_constant(X_test)","bc5f85c0":"Y_test_pred=res3.predict(X_test_sm)","02801951":"Y_test_pred=Y_test_pred.values.reshape(-1)\nY_test_pred[:10]","584b714f":"# Creating a data frame with response variable and predicted probabilities\n\nY_test_pred_final=pd.DataFrame({'Admission':Y_test.values,'Admission_Probability':Y_test_pred})\nY_test_pred_final['StudentID']=Y_test.index\nY_test_pred_final.head()","516392e3":"# Create the Predicted Column which will be assigned a value 1 if the Probability of Admission is greater than ideal probability cut off point\n\nY_test_pred_final['Predicted']=Y_test_pred_final.Admission_Probability.map(lambda x:1 if x>0.4 else 0)\nY_test_pred_final.head()","a90123db":"## Metrics Results of the test set\nmetrics_results=CalculateMetrics(Y_test_pred_final.Admission,Y_test_pred_final.Predicted)\nprint_evalmetrics(metrics_results)","1b4ee102":"# Plotting the ROC Curve for the test set\nplot_roc(Y_test_pred_final.Admission,Y_test_pred_final.Admission_Probability)","b3713dd0":"## Model Building","4064c0c6":"**Function to Print Evaluation Metrics**","63cf2398":"## Conclusion","3279a556":"## Assumption","8916e39e":"- There is no missing values in any of the columns in the dataset.\n- we have necessary data to build the Logistic Regression Model.","12d4734d":"- From the results, predictor variables like `SOP`,`LOR`,`Research` has high p-values\n- Let us drop this predictor variables one by one and notice the behaviour of the Model","8e3fc18c":"## Finding Optimal Cut-Off Point","a2e39853":"## Classes and Functions Used","84f6ec48":"## Packages Used in Project","9f0134c7":"**Function to Plot ROC Curve**","ea32f227":"- In order to build a Logistic Regression Model ,we need a output variable which is said to be binary in nature i.e having a value of either 0 or 1\n- Currently Chance of Admit has a Probability Value of Student getting an Admission\n- I will set a threshold of value of 0.75 i.e Students whose Chance of Admit value is greater than 0.75 will get an admission (i.e value will be 1) and value less than 0.75 will be treated as 0","4b90b16a":"- We have to find an optimal cut-off probability which decide whether a student gets an admission into Graduate School.\n- Once we find the optimal cut-off value ,then if the Admission_Probability is greater than optimal cut-off value it is highly possible the Student gets an admission","6967be87":"![](http:\/\/)- `LOR` and `TOEFL Score` Predictor variables has moderate p-value and can still be considered as predictor varaibles for Model Prediction","36fc58a1":"## Accuracy,Sensitivity and Specificity","d73000d4":"## Predictions on the Test Set","d8b8514a":"## Model Prediction","8e0f4e1f":"`GRE Score` is said to be highly correlated with `TOEFL Score`, `CGPA`","bce37bc7":"## Logistic Regression Model 2","89cedfce":"- Model built predicted the results of the test data with an `Accuracy` of `90.6%` and a `high sensitivity` of `90.1%`\n- Moreover the more the ROC plot follows the left hand border i.e with high Sensitivity which says the Model built is accurate.","ca674704":"It is eveident from the plot that `0.4 is the ideal proability cut off point` which balances the sensitivity,specifciity and accuracy.","7061266f":"## Logistic Regression Model 1","bd363a34":"Created a Class which contains reusable functions used for Calculating `Performance Evaluation Metrics` from the `Built Logistic Regression Model`","fc4dda55":"## Dataset Train - Test Split","bf904740":"## Logistic Regression Model 3"}}