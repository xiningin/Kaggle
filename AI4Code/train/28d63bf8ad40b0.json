{"cell_type":{"466940ba":"code","5b82b9f7":"code","da1f5e5f":"code","59087359":"code","525881da":"code","4c9b7df8":"code","cf113af9":"code","a8c24d64":"code","1cfc4d02":"code","3be19f53":"code","5f9aaad5":"code","97769d8d":"code","ab9f24d1":"code","c80b0f2c":"code","3a97aa62":"code","fec5a5d6":"code","07f446d8":"code","f767db59":"code","409a1d15":"code","51b3378b":"code","9a39663b":"code","3c74357c":"code","aaf9e54c":"code","c092af2e":"code","265a317c":"code","a310af8c":"code","d00b76a8":"code","79e04408":"code","e484d984":"code","085f2f01":"code","d16dcdba":"code","40b157bd":"code","3c1b1fdf":"code","351a384d":"code","df626f7c":"code","8a9344ef":"code","5360cf93":"code","742291f8":"code","d943201f":"code","938176b2":"code","3121ed89":"code","fa24559b":"code","309ec0ad":"code","88071c30":"code","afdce155":"code","62327666":"code","47796d64":"code","cbe6cb54":"code","6c9aefa3":"code","ef0a3ca6":"code","dd9c9638":"code","dad0c599":"code","43a6f1af":"code","606cbc42":"code","35b056cd":"code","0f072fb6":"code","7eb6d07a":"code","8540b56d":"code","474e0899":"code","abe0b4e3":"code","981871d7":"code","c10b3f67":"code","288eb693":"code","45e25466":"code","c0907eb3":"code","d9fa8350":"code","1d94aa5b":"code","e36da405":"code","82458a02":"code","3ac1f15f":"markdown","47d33ff9":"markdown","ede44839":"markdown","81318c37":"markdown","cf5f26bd":"markdown","4ad522ef":"markdown","bc81db43":"markdown","a1b10b92":"markdown","d99e33ed":"markdown","92bb4442":"markdown","3b3ce986":"markdown","ab15d3ba":"markdown","2efcca91":"markdown","4ad7c4fa":"markdown","70aee330":"markdown","f9ab50e5":"markdown","65b9d518":"markdown","7f258ad8":"markdown","749852cb":"markdown","0f14226e":"markdown","e9429f80":"markdown","83ab949d":"markdown","9d677cab":"markdown","27aee526":"markdown","10a7de1f":"markdown","e03755d0":"markdown","c7db2bca":"markdown","c4f4e59e":"markdown","91964550":"markdown","5c778f2d":"markdown","9b1d3f21":"markdown","7a4aebfb":"markdown","1a2c9fe3":"markdown","b0b937e1":"markdown","dec72896":"markdown","6ca81b3b":"markdown","e5e2ab3a":"markdown","5ee63f3f":"markdown","b104bfba":"markdown","b0eb58b6":"markdown","773890ae":"markdown","c895ea35":"markdown","15627e5d":"markdown","7d5b512b":"markdown","3bd767d9":"markdown","40f5bcb5":"markdown","a53857d6":"markdown","27ec60b2":"markdown","dfe135e1":"markdown","151fa01d":"markdown","75a1d34a":"markdown","e6025b41":"markdown","e3df5818":"markdown","07f61661":"markdown","2feb0950":"markdown","81e49909":"markdown","ac75ea88":"markdown","41416f10":"markdown","e9b83ed5":"markdown","cfffc0a0":"markdown","6c212115":"markdown","803eab26":"markdown","25941c89":"markdown","7f543fb7":"markdown","f486f136":"markdown","851a72ea":"markdown","7151aecb":"markdown","f820c65b":"markdown","1c0d5622":"markdown","49455d0c":"markdown","198b8e94":"markdown","d9f1b484":"markdown","f488a347":"markdown","700e21e6":"markdown","fafdb270":"markdown"},"source":{"466940ba":"# Any results you write to the current directory are saved as output.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Ignore all warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n        \n# Importing Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas_profiling import ProfileReport\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nfrom sklearn.model_selection import train_test_split # for spliting dataset\nfrom sklearn.feature_extraction.text import CountVectorizer # bow-->1gram and 2 gram\nfrom sklearn.feature_extraction.text import TfidfVectorizer # tf-idf\nfrom gensim.models import Word2Vec  # w2v\nfrom gensim.models import KeyedVectors # to understanding w2v using google pre trained model\nfrom sklearn.metrics import accuracy_score # to check the accuracy of model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score # k-fold cv\nfrom sklearn.metrics import classification_report\nimport pickle\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom tqdm import tqdm\nimport re\nimport nltk\nfrom nltk.probability import FreqDist\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\neng_stopwords = stopwords.words('english')\nfrom nltk.stem import PorterStemmer\nfrom sklearn.metrics import confusion_matrix,log_loss\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import FunctionTransformer\nfrom imblearn.pipeline import Pipeline\nfrom lime import lime_text\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\nfrom imblearn.over_sampling import SMOTE\n","5b82b9f7":"# Loading CSV file\ndata = pd.read_csv(\"..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv\",index_col=0)\n\n# Using only 'Review text' and 'Rating' and descarding other columns\ndata = data[['Review Text','Rating']] \n\n# Converting into binary classification problem\ndata = data[data['Rating']!=3]\ndata['Rating'] = data['Rating'].apply(lambda x: 0 if x<3 else 1)\n\n# Shape of dataset\nprint(\"Shape of the dataset:\",data.shape)\n\n# Overview of data\nprint(\"\\nOverview of data: \")\ndata.info","da1f5e5f":"# Pandas Profiling : Really good library to get the overview EDA.\nprofile = ProfileReport(data, title='Pandas Profiling Report',minimal=False, html={'style':{'full_width':True}})\nprofile.to_widgets()","59087359":"# Finding missing values\nprint(f\"Number of Missing values: \\n{data.isnull().sum()}\\n\")\n\nprint(f\"number of duplicated reviews: {sum(data[data['Review Text'].notnull()].duplicated(['Review Text'],keep='first'))}\")","525881da":"# Duplicate Review text example\ndata[data['Review Text'].notnull()][data[data['Review Text'].notnull()].duplicated(['Review Text'],keep=False)]","4c9b7df8":"# Removing datapoints having missing values and duplicate Review text\ndata_after_drop = data[data['Review Text'].notnull()]\ndata_after_drop = data_after_drop.drop_duplicates(['Review Text'],keep='first')\n\nprint(f\"percentage of data remaing after dopping missing values and duplicate reviews: { round((data_after_drop.shape[0]\/data.shape[0])*100,3)} %\")","cf113af9":"# Classlabel value counts\n\ntemp  = data_after_drop['Rating'].value_counts()\nprint(pd.DataFrame({'Class label(sentiment)':temp.index, \"values_counts\":temp.values,\"distribution percentage\":temp.values\/sum(temp.values) }))\n\n# Ploting distribution of classlabel\nsn.countplot(data_after_drop['Rating'])\nplt.show()","a8c24d64":"# Preprocessing Functions\n# credit : https:\/\/www.kaggle.com\/urvishp80\/quest-encoding-ensemble\n\n#======================================================================================================================================\n# Return the number of links and text without html tags \n# Also return the counts of 'number of lines'  and remove it\ndef strip_html(text):\n    \"\"\" Return theclean text (without html tags) \"\"\"\n    \n    # Removing HTML tags\n    text = re.sub(r'http[s]?:\/\/\\S+',\" \",text)\n    \n    # finding number of lines using regex and counting it and remove it\n    text = re.sub(r'\\n', \" \",text)\n    \n    return  text\n\n\n#======================================================================================================================================\nmispell_dict = {\"aren't\" : \"are not\",\"can't\" : \"cannot\",\"couldn't\" : \"could not\",\"couldnt\" : \"could not\",\"didn't\" : \"did not\",\"doesn't\" : \"does not\",\n                \"doesnt\" : \"does not\",\"don't\" : \"do not\",\"hadn't\" : \"had not\",\"hasn't\" : \"has not\",\"haven't\" : \"have not\",\"havent\" : \"have not\",\n                \"he'd\" : \"he would\",\"he'll\" : \"he will\",\"he's\" : \"he is\",\"i'd\" : \"i would\",\"i'd\" : \"i had\",\"i'll\" : \"i will\",\"i'm\" : \"i am\",\n                \"isn't\" : \"is not\",\"it's\" : \"it is\",\"it'll\":\"it will\",\"i've\" : \"I have\",\"let's\" : \"let us\",\"mightn't\" : \"might not\",\n                \"mustn't\" : \"must not\",\"shan't\" : \"shall not\",\"she'd\" : \"she would\",\"she'll\" : \"she will\",\"she's\" : \"she is\",\"shouldn't\" : \"should not\",\n                \"shouldnt\" : \"should not\",\"that's\" : \"that is\",\"thats\" : \"that is\",\"there's\" : \"there is\",\"theres\" : \"there is\",\"they'd\" : \"they would\",\n                \"they'll\" : \"they will\",\"they're\" : \"they are\",\"theyre\":  \"they are\",\"they've\" : \"they have\",\"we'd\" : \"we would\",\"we're\" : \"we are\",\n                \"weren't\" : \"were not\",\"we've\" : \"we have\",\"what'll\" : \"what will\",\"what're\" : \"what are\",\"what's\" : \"what is\",\"what've\" : \"what have\",\n                \"where's\" : \"where is\",\"who'd\" : \"who would\",\"who'll\" : \"who will\",\"who're\" : \"who are\",\"who's\" : \"who is\",\"who've\" : \"who have\",\n                \"won't\" : \"will not\",\"wouldn't\" : \"would not\",\"you'd\" : \"you would\",\"you'll\" : \"you will\",\"you're\" : \"you are\",\"you've\" : \"you have\",\n                \"'re\": \" are\",\"wasn't\": \"was not\",\"we'll\":\" will\",\"didn't\": \"did not\",\"tryin'\":\"trying\"}\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\ndef replace_typical_misspell(text):\n    \n    text = text.lower()\n    \n    \n    \"\"\"De-Concatenation of words and correction of misspelled words\"\"\"\n    mispellings, mispellings_re = _get_mispell(mispell_dict)\n\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)\n\n\n#======================================================================================================================================\n# removing non_alpha_numeric character and removing all the special character words\ndef non_alpha_numeric_remove(text):  \n    \n    # removing all non alpha char \n    text = re.sub(r\"[^A-Za-z]\", \" \",text)\n    \n    return text \n\n#======================================================================================================================================\n\n# function to remove all the stopwords and words having lengths less than 3\ndef remove_stop_words_and_punc(text) :\n    \n    \"\"\" \n    Remove all the stopwords \n    \n    \"\"\"\n    # removing the words from the stop words list: 'no', 'nor', 'not'\n    stops = set(stopwords.words(\"english\"))\n    stops.remove('no')\n    stops.remove('nor')\n    stops.remove('not')\n    \n    clean_text = []\n    for word in text.split():\n        if word not in stops and len(word)>3:        \n            clean_text.append(word)\n        \n    clean_text = \" \".join(clean_text)\n    \n    return(clean_text)\n\n#======================================================================================================================================\n# function for stemming of words in text\ndef stem(text):\n    stemmer = PorterStemmer()\n    result = \" \".join([ stemmer.stem(word) for word in text.split(\" \")])\n    return result\n\n#======================================================================================================================================\n#======================================================================================================================================\n# Final text cleaning funtion  \ndef clean_text(text):\n    \"\"\"\n    This function sequentially execute all the cleaning and preprocessing function and finaly gives cleaned text.\n    Input: Boolean values of extra_features, strip_html, count_all_cap_words_and_lower_it, replace_typical_misspell, count_non_alpha_numeric_and_remove, remove_stop_words_and_punc, stem\n            (by default all the input values = True)\n    \n    return: clean text\n    \n    \"\"\"\n    \n    # remove html tags\n    clean_text = strip_html(text)  \n    \n    # de-concatenation of words\n    clean_text = replace_typical_misspell(clean_text)\n     \n    # Count the number of non alpha numeric character and remove it\n    clean_text = non_alpha_numeric_remove(clean_text)\n    \n    # removing Stopwords and the words length less than 3(As these words mostly tend to redundant words) excpect 'C' and 'R'and 'OS' <-- programing keywords\n    clean_text = remove_stop_words_and_punc(clean_text)\n    \n    # stemming ( use only for BOW or TFIDF represention. Not effective for word embedding like w2v or glove)\n    clean_text = stem(clean_text)\n\n    return clean_text","1cfc4d02":"# Preprocessing \ncleaned_review_text = data_after_drop['Review Text'].apply(lambda x: clean_text(x))\n\n# Sample\ni=15\nprint(f\"\\nBefore Preprocessing\\n{'='*20}\")\nprint(data_after_drop['Review Text'].iloc[i])\n\nprint(f\"\\nAfter Preprocessing\\n{'='*20}\")\nprint(cleaned_review_text.iloc[i])","3be19f53":"# Calculating the length of text before and after preprocessing\nlen_after_cleaning = cleaned_review_text.apply(lambda x : len(x.split()))\nlen_before_cleaning = data_after_drop['Review Text'].apply(lambda x : len(x.split()))\n    \n# ploting\nplt.figure(figsize=(9,6))\nsn.distplot(len_before_cleaning, label=f'Review text before cleaning')\nsn.distplot(len_after_cleaning, label=f'Review text after cleaning')\nplt.title(f\" Distribution of number of words of Review text before v\/s after preprocessing\\n\",fontsize=15)\nplt.ylabel(\"distribtion\")\nplt.xlabel(f\"number of words in Review text\")\nplt.legend()\nplt.grid()\nplt.show()","5f9aaad5":"# train test split\n\nX = data_after_drop['Review Text']\ny = data_after_drop['Rating']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n\nprint(f\"Shape of X_train: {X_train.shape}\")\nprint(f\"Shape of y_train: {y_train.shape}\")\nprint(f\"Shape of X_val: {X_val.shape}\")\nprint(f\"Shape of y_val: {y_val.shape}\")","97769d8d":"# Preprocessing for BOW and TFIDF\nX_train_clean_text = X_train.apply(lambda x: clean_text(x))\nX_val_clean_text = X_val.apply(lambda x: clean_text(x))","ab9f24d1":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None)\nx_train_bow_unigram = count_vect.fit_transform(X_train_clean_text)\nx_val_bow_unigram = count_vect.transform(X_val_clean_text)\n\nprint(f\"shape of features after BOW Feture extraction: {x_train_bow_unigram.shape}\")\n\n# Sparsity of BOW-unigram\nsparsiry_bow = (len(x_train_bow_unigram.toarray().nonzero()[0]) \/ len(np.nonzero(x_train_bow_unigram.toarray()==0)[0]))*100\nprint(f\"Sparsity of BOW: {round(sparsiry_bow,5)}%\")","c80b0f2c":"# BOW feature representaiona\nbow_unigram_feature_representation = pd.DataFrame(data = x_train_bow_unigram.toarray(), columns = count_vect.get_feature_names())\nbow_unigram_feature_representation.head()","3a97aa62":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vect = TfidfVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None)\nx_train_tfidf_unigram = tfidf_vect.fit_transform(X_train_clean_text)\nx_val_tfidf_unigram = tfidf_vect.transform(X_val_clean_text)\n\nprint(f\"shape of features after BOW Feture extraction: {x_train_tfidf_unigram.shape}\")\n\n# Sparsity of TFIDF-unigram\nsparsiry_tfidf = (len(x_train_tfidf_unigram.toarray().nonzero()[0]) \/ len(np.nonzero(x_train_tfidf_unigram.toarray()==0)[0]))*100\nprint(f\"Sparsity of TFIDF: {round(sparsiry_tfidf,5)}%\")","fec5a5d6":"# Tf-IDF feature representaion\ntfidf_unigram_feature_representation = pd.DataFrame(data = x_train_tfidf_unigram.toarray(), columns = tfidf_vect.get_feature_names())\ntfidf_unigram_feature_representation.head()","07f446d8":"# Text Preprocessing funtion for word2vec\ndef clean_text_for_embedding(text):\n    \"\"\"\n    This function sequentially execute all the cleaning and preprocessing function and finaly gives cleaned text.\n    Input: Boolean values of extra_features, strip_html, count_all_cap_words_and_lower_it, replace_typical_misspell, count_non_alpha_numeric_and_remove, remove_stop_words_and_punc, stem\n            (by default all the input values = True)\n    \n    return: clean text \"\"\"\n    \n    # remove html tags\n    clean_text = strip_html(text)  \n    \n    # de-concatenation of words\n    clean_text = replace_typical_misspell(clean_text)\n     \n    # Count the number of non alpha numeric character and remove it\n    clean_text = non_alpha_numeric_remove(clean_text)\n    \n    # removing Stopwords and the words length less than 3(As these words mostly tend to redundant words) excpect 'C' and 'R'and 'OS' <-- programing keywords\n    clean_text = remove_stop_words_and_punc(clean_text)\n\n    return clean_text","f767db59":"# Preprocessing for word2vec embedding for train and test review text\nX_train_review_text_for_embedding = X_train.apply(lambda x: clean_text_for_embedding(x))\nX_val_review_text_for_embedding = X_val.apply(lambda x: clean_text_for_embedding(x))\n\n\n# Sample\ni=15\nprint(f\"\\nBefore Preprocessing\\n{'='*20}\")\nprint(X_train.iloc[i])\n\nprint(f\"\\nAfter Preprocessing\\n{'='*20}\")\nprint(X_train_review_text_for_embedding.iloc[i])","409a1d15":"import operator \nimport gensim\nfrom gensim.models import KeyedVectors\n\n# Train the genisim word2vec model with our own custom corpus\n# CBOW -> sg = 0\n\n# Convering text in list of list of train reviews text\nlist_of_sent_train = X_train_review_text_for_embedding.apply(lambda x: x.split()).values\n\n# Convering text in list of list of val reviews text\nlist_of_sent_val = X_val_review_text_for_embedding.apply(lambda x: x.split()).values\n\n# Traing W2V\nmodel_cbow = Word2Vec(sentences= list_of_sent_train, min_count=3, sg=0, workers= 3,size=100) # Default setting","51b3378b":"# Vocab after training\nwords = model_cbow.wv.vocab.keys()\nprint(\"Number of words in vocab\",len(words),\"\\n\\n\")\nprint(words,sep='\\n')","9a39663b":"# Top similar word\nmodel_cbow.similar_by_word(\"good\")","3c74357c":"'''\n    -->procedure to make avg w2v of each reviews\n    \n    1. find the w2v of each word\n    2. sum-up w2v of each word in a sentence\n    3. divide the total w2v of sentence by total no. of words in the sentence\n'''\n\n# vocablary of w2v model of e-commerce dataset\nvocab=model_cbow.wv.vocab\n\n\n#------------------------------------------------------------------------------------------------------------\n## average Word2Vec for train reviews\n# compute average word2vec for each review.\ntrain_w2v_cbow = [] # the avg-w2v for each sentence\/review in train dataset is stored in this list\n\nlist_of_sent_train = X_train_review_text_for_embedding.apply(lambda x: x.split()).values\n\nfor sent in list_of_sent_train: # for each review\/sentence\n    sent_vec = np.zeros(100) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in vocab:\n            vec = model_cbow.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    train_w2v_cbow.append(sent_vec)\n\nprint(\"Number of datapoints in train: \",len(train_w2v_cbow))\n\n\n#------------------------------------------------------------------------------------------------------------\n\n## average Word2Vec for val reviews\n# compute average word2vec for each review.\nval_w2v_cbow = [] # the avg-w2v for each sentence\/review in train dataset is stored in this list\n\nlist_of_sent_train = X_val_review_text_for_embedding.apply(lambda x: x.split()).values\n\nfor sent in list_of_sent_val: # for each review\/sentence\n    sent_vec = np.zeros(100) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in vocab:\n            vec = model_cbow.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    val_w2v_cbow.append(sent_vec)\n\nprint(\"Number of datapoints in val: \",len(val_w2v_cbow))","aaf9e54c":"# Standard scaling of W2V\nsc = StandardScaler()\ntrain_w2v_sc = sc.fit_transform(train_w2v_cbow)\nval_w2v_sc = sc.transform(val_w2v_cbow)\n\n\n## Example : Review text is encoded into 100 dim vector space\nprint(f\"\\n Before encoding: \\n{'='*20}\\n {X_train_review_text_for_embedding.iloc[0]}\")\nprint(f\"\\n After encoding: \\n{'='*20}\\n {train_w2v_sc[0]}\")","c092af2e":"# Loading Glove(pretrained) model\nGLOVE_EMBEDDING_PATH = '..\/input\/glove840b300dtxt\/glove.840B.300d.txt'\n\n\"\"\"\nWorking:\n\n1. Embedding has word and corresponding word vector\n2. get_coefs function retuen the word and array of word vector\n3. load_embeddings split the word and word vector and send it to get_coef function and convert the returned values into dict\n4. Final dict has 'word' as key as 'word embeddings' as values e.g {'word(key)': [array(word embedding)]} \n\"\"\"\n\ndef get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\ndef load_embeddings(path):\n    with open(path) as f:\n        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n    \nembeddings_index = load_embeddings(GLOVE_EMBEDDING_PATH)","265a317c":"## Building vocubulary from our Quest Data\ndef build_vocab(sentences, verbose =  True):\n    \"\"\"\n    :param sentences: list of list of words\n    :return: dictionary of words and their count\n    \"\"\"\n    vocab = {}\n    for sentence in tqdm(sentences, disable = (not verbose)):\n        for word in sentence:\n            try:\n                vocab[word] += 1\n            except KeyError:\n                vocab[word] = 1\n    return vocab\n\n#=========================================================================================================\nimport operator \n## This is a common function to check coverage between our quest data and the word embedding\ndef check_coverage(vocab,embeddings_index):\n    a = {}\n    oov = {}\n    k = 0\n    i = 0\n    for word in tqdm(vocab):\n        try:\n            a[word] = embeddings_index[word]\n            k += vocab[word]\n        except:\n\n            oov[word] = vocab[word]\n            i += vocab[word]\n            pass\n\n    print('Found embeddings for {:.2%} of vocab'.format(len(a) \/ len(vocab)))\n    print('Found embeddings for  {:.2%} of all text'.format(k \/ (k + i)))\n    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n\n    return sorted_x","a310af8c":"##Apply the vocab function to get the words and the corresponding counts\nsentences = X_train_review_text_for_embedding.apply(lambda x: x.split()).values\nvocab = build_vocab(sentences)\n\nprint(f\"\\nFor cleaned_question_body_for_embedding: \\n{'-'*40}\")\noov = check_coverage(vocab,embeddings_index)\n\n## List 10 out of vocabulary word\nprint(f\"\\nTop 10 out of vocabulary word: \\n{'-'*30}\")\noov[:10]","d00b76a8":"#------------------------------------------------------------------------------------------------------------\n## average Word2Vec usnig pretrained model(GLOVE) for train reviews\n# compute average word2vec for each review.\ntrain_w2v_pretrained = [] # the avg-w2v for each sentence\/review in train dataset is stored in this list\n\nlist_of_sent_train = X_train_review_text_for_embedding.apply(lambda x: x.split()).values\n\nfor sent in list_of_sent_train: # for each review\/sentence\n    sent_vec = np.zeros(300) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in vocab:\n            try:\n                vec = embeddings_index[word]\n                sent_vec += vec\n                cnt_words += 1\n            \n            except:\n                pass\n            \n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    train_w2v_pretrained.append(sent_vec)\n\nprint(\"Number of datapoints in train: \",len(train_w2v_pretrained))\n\n\n#------------------------------------------------------------------------------------------------------------\n\n## average Word2Vec for val reviews\n# compute average word2vec for each review.\nval_w2v_pretrained = [] # the avg-w2v for each sentence\/review in train dataset is stored in this list\n\nlist_of_sent_train = X_val_review_text_for_embedding.apply(lambda x: x.split()).values\n\nfor sent in list_of_sent_val: # for each review\/sentence\n    sent_vec = np.zeros(300) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in vocab:\n            try:     \n                vec = embeddings_index[word]\n                sent_vec += vec\n                cnt_words += 1\n                \n            except:\n                pass\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    val_w2v_pretrained.append(sent_vec)\n\nprint(\"Number of datapoints in val: \",len(val_w2v_pretrained))","79e04408":"# Standard scaling of W2V\nsc = StandardScaler()\ntrain_w2v_pretrained_sc = sc.fit_transform(train_w2v_pretrained)\nval_w2v_pretrained_sc = sc.transform(val_w2v_pretrained)\n\n\n## Example : Review text is encoded into 100 dim vector space\nprint(f\"\\n Before encoding: \\n{'='*20}\\n {X_train_review_text_for_embedding.iloc[0]}\")\nprint(f\"\\n After encoding: \\n{'='*20}\\n {train_w2v_pretrained_sc[0]}\")","e484d984":"import operator \nimport gensim\nfrom gensim.models import KeyedVectors\n\n# Train the genisim word2vec model with our own custom corpus\n# Skip gram -> sg = 1\n\n# Convering text in list of list of train reviews text\nlist_of_sent_train = X_train_review_text_for_embedding.apply(lambda x: x.split()).values\n\n# Convering text in list of list of val reviews text\nlist_of_sent_val = X_val_review_text_for_embedding.apply(lambda x: x.split()).values\n\n# Traing W2V\nmodel_skip = Word2Vec(sentences= list_of_sent_train, min_count=3, sg=1, workers= 3,size=100) # Default setting","085f2f01":"# Top similar word by W2V Skip gram\nprint(\"Top similar word by W2V Skip gram:\\n\")\nprint(pd.Series(model_skip.similar_by_word(\"good\")))\n\n# Top similar word by W2V CBOW\nprint(\"\\n\\nTop similar word by W2V CBOW:\\n\")\nprint(pd.Series(model_cbow.similar_by_word(\"good\")))","d16dcdba":"'''\n    -->procedure to make avg w2v of each reviews\n    \n    1. find the w2v of each word\n    2. sum-up w2v of each word in a sentence\n    3. divide the total w2v of sentence by total no. of words in the sentence\n'''\n\n# vocablary of w2v model of e-commerce dataset\nvocab = model_skip.wv.vocab\n\n\n#------------------------------------------------------------------------------------------------------------\n## average Word2Vec for train reviews\n# compute average word2vec for each review.\ntrain_w2v_skip = [] # the avg-w2v for each sentence\/review in train dataset is stored in this list\n\nlist_of_sent_train = X_train_review_text_for_embedding.apply(lambda x: x.split()).values\n\nfor sent in list_of_sent_train: # for each review\/sentence\n    sent_vec = np.zeros(100) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in vocab:\n            vec = model_skip.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    train_w2v_skip.append(sent_vec)\n\nprint(\"Number of datapoints in train: \",len(train_w2v_skip))\n\n\n#------------------------------------------------------------------------------------------------------------\n\n## average Word2Vec for val reviews\n# compute average word2vec for each review.\nval_w2v_skip = [] # the avg-w2v for each sentence\/review in train dataset is stored in this list\n\nlist_of_sent_train = X_val_review_text_for_embedding.apply(lambda x: x.split()).values\n\nfor sent in list_of_sent_val: # for each review\/sentence\n    sent_vec = np.zeros(100) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in vocab:\n            vec = model_skip.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    val_w2v_skip.append(sent_vec)\n\nprint(\"Number of datapoints in val: \",len(val_w2v_skip))\n#------------------------------------------------------------------------------------------------------------\n\n# Standard scaling of W2V\nsc = StandardScaler()\ntrain_w2v_skip_sc = sc.fit_transform(train_w2v_skip)\nval_w2v_skip_sc = sc.transform(val_w2v_skip)\n\n\n## Example : Review text is encoded into 100 dim vector space\nprint(f\"\\n Before encoding: \\n{'='*20}\\n {X_train_review_text_for_embedding.iloc[0]}\")\nprint(f\"\\n After encoding: \\n{'='*20}\\n {train_w2v_skip_sc[0]}\")","40b157bd":"# PCA for visualisation of W2V skipram\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\n\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(train_w2v_skip)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\n\n# Ploting\nsns.scatterplot(x='principal component 1', y='principal component 2', hue=y_train.values, style=None, size=None, data=principalDf)\nplt.show()","3c1b1fdf":"from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\n# Doc2Vec traing\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train_review_text_for_embedding.apply(lambda x: x.split()).values)]\ndoc2vec_model = Doc2Vec(documents, vector_size=100, window=3, min_count=2, workers=-1)\n\ntrain_doc2vec = [doc2vec_model.infer_vector(sent) for sent in X_train_review_text_for_embedding.apply(lambda x: x.split()).values]\nval_doc2vec = [doc2vec_model.infer_vector(sent) for sent in X_val_review_text_for_embedding.apply(lambda x: x.split()).values]\n\n# Standard scaling of W2V\nsc = StandardScaler()\ntrain_doc2vec_sc = sc.fit_transform(train_doc2vec)\nval_doc2vec_sc = sc.transform(val_doc2vec)\n\n## Example : Review text is encoded into 100 dim vector space\nprint(f\"\\n Before encoding: \\n{'='*20}\\n {X_train_review_text_for_embedding.iloc[0]}\")\nprint(f\"\\n After encoding: \\n{'='*20}\\n {train_doc2vec_sc[0]}\")","351a384d":"# PCA for visualisation of W2V skipram\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\n\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(train_doc2vec_sc)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\n\n# Ploting\nsns.scatterplot(x='principal component 1', y='principal component 2', hue=y_train.values, style=None, size=None, data=principalDf)\nplt.show()","df626f7c":"from sklearn.tree import DecisionTreeClassifier\n\n# BOW feature extraction\ncount_vect = CountVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None)\nx_train_bow_unigram = count_vect.fit_transform(X_train_clean_text)\nx_val_bow_unigram = count_vect.transform(X_val_clean_text)\n\n\n# Applying SMOTE to balance the dataset\n# transform the dataset\nsmote_oversample = SMOTE(sampling_strategy='auto',random_state=None,k_neighbors=5,n_jobs=None)\nX_res_bow, y_res = smote_oversample.fit_resample(x_train_bow_unigram, y_train)\n\n# Decision Tree Estimator\nclf = DecisionTreeClassifier(criterion='gini',class_weight='balanced')\n\n# Gris search for hyper tuining\nparam={'max_depth':[1, 5, 10, 50, 100, 500, 1000],'min_samples_split':[5, 10, 100, 500]}\n\ngrid = GridSearchCV(estimator = clf, param_grid = param, return_train_score=True,scoring='accuracy',n_jobs=-1, verbose=0)\ngrid.fit(X_res_bow,y_res)\n\ngrid.best_estimator_","8a9344ef":"## sentiment classification Pipeline\n# refer: https:\/\/ryan-cranfill.github.io\/sentiment-pipeline-sklearn-5\/\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 1.clean text preprocessing pipeline\n\n## clean_text(text) <-- Preprocessing function for embedding (initialised in starting of notebook)\n\ndef pipelinize(function, active=True):\n    def list_comprehend_a_function(list_or_series, active=True):\n        if active:\n            return [function(i) for i in list_or_series]\n        else: # if it's not active, just pass it right back\n            return list_or_series\n    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 2.BOW feature extractionpipeline\ncount_vect = CountVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None)\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 3.SMOTE to balance the dataset\nsmote_oversample = SMOTE(sampling_strategy='auto',random_state=123,k_neighbors=5,n_jobs=None)\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 4.Model \nclf = DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n                             max_depth=10, min_samples_split=500,random_state=123, splitter='best')\n\n# Creating pipeline object\ndt_model_pipeline = Pipeline([\n        (\"clean_text\", pipelinize(clean_text)),\n        ('BOW', count_vect),\n        ('classifier', clf)\n    ],verbose=True)\n\ndt_model_pipeline.fit(X_train,y_train)","5360cf93":"# Result track\n\ny_pred = dt_model_pipeline.predict(X_val)\ny_pred_proba = dt_model_pipeline.predict_proba(X_val)\n\naccuracy = accuracy_score(y_val,y_pred)\nbal_accuracy = balanced_accuracy_score(y_val,y_pred)\nlogloss = log_loss(y_val,y_pred_proba)\nprint(f'\\nGenearalisation log_loss: {logloss:.3f}')\nprint(f\"\\nGeneralisation Accuracy: {(round(accuracy,2))*100}%\")\nprint(f\"\\nGeneralisation Balance accuracy: {(round(bal_accuracy,2))*100}%\")\nprint(f'\\nmisclassification percentage: {(1-accuracy)*100:.2f}%')\n\n\n#ploting confusion matrix\nsn.heatmap(confusion_matrix(y_pred,y_val),annot=True, fmt=\"d\",linewidths=.5)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.show()\n# Classification Report\nprint(\"\\n\\nclassification report:\\n\",classification_report(y_val,y_pred)) ","742291f8":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 115\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","d943201f":"# Index of random 15 incorrectly classified pt\nnp.random.choice(np.where(y_val!=y_pred)[0],size=15)","938176b2":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 3199\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","3121ed89":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 4612\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","fa24559b":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 3221\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","309ec0ad":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 4822\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","88071c30":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 742\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","afdce155":"from sklearn.tree import DecisionTreeClassifier\n\n# BOW feature extraction\ntfidf_vect = TfidfVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None)\nx_train_tfidf_unigram = tfidf_vect.fit_transform(X_train_clean_text)\nx_val_tfidf_unigram = tfidf_vect.transform(X_val_clean_text)\n\n\n# Applying SMOTE to balance the dataset\n# transform the dataset\nsmote_oversample = SMOTE(sampling_strategy='auto',random_state=None,k_neighbors=5,n_jobs=None)\nX_res_tfidf, y_res = smote_oversample.fit_resample(x_train_tfidf_unigram, y_train)\n\n# Decision Tree Estimator\nclf = DecisionTreeClassifier(criterion='gini',class_weight='balanced')\n\n# Gris search for hyper tuining\nparam={'max_depth':[1, 5, 10, 50, 100, 500, 1000],'min_samples_split':[5, 10, 100, 500]}\n\ngrid = GridSearchCV(estimator = clf, param_grid = param, return_train_score=True,scoring='accuracy',n_jobs=-1, verbose=0)\ngrid.fit(X_res_tfidf,y_res)\n\ngrid.best_estimator_","62327666":"## sentiment classification Pipeline\n# refer: https:\/\/ryan-cranfill.github.io\/sentiment-pipeline-sklearn-5\/\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 1.clean text preprocessing pipeline\n\n## clean_text(text) <-- Preprocessing function for embedding (initialised in starting of notebook)\n\ndef pipelinize(function, active=True):\n    def list_comprehend_a_function(list_or_series, active=True):\n        if active:\n            return [function(i) for i in list_or_series]\n        else: # if it's not active, just pass it right back\n            return list_or_series\n    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 2.BOW feature extractionpipeline\ntfidf_vect = TfidfVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None)\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 3.SMOTE to balance the dataset\nsmote_oversample = SMOTE(sampling_strategy='auto',random_state=123,k_neighbors=5,n_jobs=None)\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 4.Model \nclf = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n                       max_depth=100, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=5,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')\n\n# Creating pipeline object\ndt_model_pipeline = Pipeline([\n        (\"clean_text\", pipelinize(clean_text)),\n        ('BOW', tfidf_vect),\n        ('SMOTE', SMOTE()),\n        ('classifier', clf)\n    ],verbose=True)\n\ndt_model_pipeline.fit(X_train,y_train)","47796d64":"# Result track\n\ny_pred = dt_model_pipeline.predict(X_val)\ny_pred_proba = dt_model_pipeline.predict_proba(X_val)\n\naccuracy = accuracy_score(y_val,y_pred)\nbal_accuracy = balanced_accuracy_score(y_val,y_pred)\nlogloss = log_loss(y_val,y_pred_proba)\nprint(f'\\nGenearalisation log_loss: {logloss:.3f}')\nprint(f\"\\nGeneralisation Accuracy: {(round(accuracy,2))*100}%\")\nprint(f\"\\nGeneralisation Balance accuracy: {(round(bal_accuracy,2))*100}%\")\nprint(f'\\nmisclassification percentage: {(1-accuracy)*100:.2f}%')\n\n\n#ploting confusion matrix\nsn.heatmap(confusion_matrix(y_pred,y_val),annot=True, fmt=\"d\",linewidths=.5)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.show()\n# Classification Report\nprint(\"\\n\\nclassification report:\\n\",classification_report(y_val,y_pred)) ","cbe6cb54":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 115\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","6c9aefa3":"# Index of random 15 incorrectly classified pt\nnp.random.choice(np.where(y_val!=y_pred)[0],size=15)","ef0a3ca6":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 330\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","dd9c9638":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 3171\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","dad0c599":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 3900\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","43a6f1af":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 500\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","606cbc42":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 3844\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","35b056cd":"from sklearn.tree import DecisionTreeClassifier\n\n\n# Applying SMOTE to balance the dataset\n# transform the dataset\nsmote_oversample = SMOTE(sampling_strategy='auto',random_state=None,k_neighbors=5,n_jobs=None)\nX_res_w2v_skipgram, y_res = smote_oversample.fit_resample(train_w2v_skip_sc, y_train)\n\n# Decision Tree Estimator\nclf = DecisionTreeClassifier(criterion='gini',class_weight='balanced')\n\n# Gris search for hyper tuining\nparam={'max_depth':[1, 5, 10, 50, 100, 500, 1000],'min_samples_split':[5, 10, 100, 500]}\n\ngrid = GridSearchCV(estimator = clf, param_grid = param, return_train_score=True,scoring='accuracy',n_jobs=-1, verbose=0)\ngrid.fit(X_res_w2v_skipgram,y_res)\n\ngrid.best_estimator_","0f072fb6":"## sentiment classification Pipeline\n# refer: https:\/\/ryan-cranfill.github.io\/sentiment-pipeline-sklearn-5\/\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 1.clean text preprocessing pipeline\n\n## clean_text(text) <-- Preprocessing function for embedding (initialised in starting of notebook)\n\ndef pipelinize(function, active=True):\n    def list_comprehend_a_function(list_or_series, active=True):\n        if active:\n            return [function(i) for i in list_or_series]\n        else: # if it's not active, just pass it right back\n            return list_or_series\n    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 2.W2V embedding pipeline\ndef embed(series):\n    list_of_sent = pd.Series(series).apply(lambda x: x.split()).values\n    w2v_embeding = [] # the avg-w2v for each sentence\/review in train dataset is stored in this list\n    \n    for sent in list_of_sent: # for each review\/sentence\n        sent_vec = np.zeros(300) # as word vectors are of zero length\n        cnt_words =0; # num of words with a valid vector in the sentence\/review\n        for word in sent: # for each word in a review\/sentence\n            if word in vocab:\n                try:     \n                    vec = model_skip.wv[word]\n                    sent_vec += vec\n                    cnt_words += 1\n\n                except:\n                    pass\n        if cnt_words != 0:\n            sent_vec \/= cnt_words        \n        w2v_embeding.append(sent_vec)\n    return w2v_embeding\n\n\ndef w2v_pipeline(function, active=True):\n    def list_comprehend_a_function(list_or_series, active=True):\n        if active:\n            return embed(list_or_series)\n        \n        else: # if it's not active, just pass it right back\n            return list_or_series\n    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 3.Model \nclf = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n                       max_depth=500, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=5,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')\n\n# Creating pipeline object\ndt_model_pipeline = Pipeline([\n        (\"clean_text\", pipelinize(clean_text_for_embedding)),\n        ('embed', w2v_pipeline(embed)),\n        ('smote',SMOTE()),\n        ('classifier', clf)\n    ],verbose=True)\n\ndt_model_pipeline.fit(X_train,y_train)","7eb6d07a":"# Result track\n\ny_pred = dt_model_pipeline.predict(X_val)\ny_pred_proba = dt_model_pipeline.predict_proba(X_val)\n\naccuracy = accuracy_score(y_val,y_pred)\nbal_accuracy = balanced_accuracy_score(y_val,y_pred)\nlogloss = log_loss(y_val,y_pred_proba)\nprint(f'\\nGenearalisation log_loss: {logloss:.3f}')\nprint(f\"\\nGeneralisation Accuracy: {(round(accuracy,2))*100}%\")\nprint(f\"\\nGeneralisation Balance accuracy: {(round(bal_accuracy,2))*100}%\")\nprint(f'\\nmisclassification percentage: {(1-accuracy)*100:.2f}%')\n\n\n#ploting confusion matrix\nsn.heatmap(confusion_matrix(y_val,y_pred),annot=True, fmt=\"d\",linewidths=.5)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.show()\n# Classification Report\nprint(\"\\n\\nclassification report:\\n\",classification_report(y_val,y_pred)) ","8540b56d":"## sentiment classification Pipeline\n# refer: https:\/\/ryan-cranfill.github.io\/sentiment-pipeline-sklearn-5\/\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 1.clean text preprocessing pipeline\n\n## clean_text(text) <-- Preprocessing function for embedding (initialised in starting of notebook)\n\ndef pipelinize(function, active=True):\n    def list_comprehend_a_function(list_or_series, active=True):\n        if active:\n            return [function(i) for i in list_or_series]\n        else: # if it's not active, just pass it right back\n            return list_or_series\n    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 2.W2V embedding pipeline\ndef embed(series):\n    list_of_sent = pd.Series(series).apply(lambda x: x.split()).values\n    w2v_embeding = [] # the avg-w2v for each sentence\/review in train dataset is stored in this list\n    \n    for sent in list_of_sent: # for each review\/sentence\n        sent_vec = np.zeros(300) # as word vectors are of zero length\n        cnt_words =0; # num of words with a valid vector in the sentence\/review\n        for word in sent: # for each word in a review\/sentence\n            if word in vocab:\n                try:     \n                    vec = model_skip.wv[word]\n                    sent_vec += vec\n                    cnt_words += 1\n\n                except:\n                    pass\n        if cnt_words != 0:\n            sent_vec \/= cnt_words        \n        w2v_embeding.append(sent_vec)\n    return w2v_embeding\n\n\ndef w2v_pipeline(function, active=True):\n    def list_comprehend_a_function(list_or_series, active=True):\n        if active:\n            return embed(list_or_series)\n        \n        else: # if it's not active, just pass it right back\n            return list_or_series\n    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 3.Model \nclf = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n                       max_depth=500, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=5,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')\n\n# Creating pipeline object\ndt_model_pipeline = Pipeline([\n        (\"clean_text\", pipelinize(clean_text_for_embedding)),\n        ('embed', w2v_pipeline(embed)),\n        (\"standard_scalar\",StandardScaler()),\n        ('classifier', clf)\n    ],verbose=True)\n\ndt_model_pipeline.fit(X_train,y_train)","474e0899":"# Result track\n\ny_pred = dt_model_pipeline.predict(X_val)\ny_pred_proba = dt_model_pipeline.predict_proba(X_val)\n\naccuracy = accuracy_score(y_val,y_pred)\nbal_accuracy = balanced_accuracy_score(y_val,y_pred)\nlogloss = log_loss(y_val,y_pred_proba)\nprint(f'\\nGenearalisation log_loss: {logloss:.3f}')\nprint(f\"\\nGeneralisation Accuracy: {(round(accuracy,2))*100}%\")\nprint(f\"\\nGeneralisation Balance accuracy: {(round(bal_accuracy,2))*100}%\")\nprint(f'\\nmisclassification percentage: {(1-accuracy)*100:.2f}%')\n\n\n#ploting confusion matrix\nsn.heatmap(confusion_matrix(y_val,y_pred),annot=True, fmt=\"d\",linewidths=.5)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.show()\n# Classification Report\nprint(\"\\n\\nclassification report:\\n\",classification_report(y_val,y_pred)) ","abe0b4e3":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 116\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","981871d7":"# Index of random 15 incorrectly classified pt\nnp.random.choice(np.where(y_val!=y_pred)[0],size=15)","c10b3f67":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 4154\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","288eb693":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 556\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_val.iloc[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()\nexp.show_in_notebook(text=True)","45e25466":"from sklearn.tree import DecisionTreeClassifier\n\n\n# Applying SMOTE to balance the dataset\n# transform the dataset\nsmote_oversample = SMOTE(sampling_strategy='auto',random_state=None,k_neighbors=5,n_jobs=None)\nX_res_doc2vec, y_res = smote_oversample.fit_resample(train_doc2vec_sc,y_train)\n\n# Decision Tree Estimator\nclf = DecisionTreeClassifier(criterion='gini',class_weight='balanced')\n\n# Gris search for hyper tuining\nparam={'max_depth':[1, 5, 10, 50, 100, 500, 1000],'min_samples_split':[5, 10, 100, 500]}\n\ngrid = GridSearchCV(estimator = clf, param_grid = param, return_train_score=True,scoring='accuracy',n_jobs=-1, verbose=0)\ngrid.fit(X_res_doc2vec,y_res)\n\ngrid.best_estimator_","c0907eb3":"## sentiment classification Pipeline\n# refer: https:\/\/ryan-cranfill.github.io\/sentiment-pipeline-sklearn-5\/\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 1.clean text preprocessing pipeline\n\n## clean_text_for_embedding(text) <-- Preprocessing function for embedding (initialised in starting of notebook)\n\ndef pipelinize(function, active=True):\n    def list_comprehend_a_function(list_or_series, active=True):\n        if active:\n            return [function(i) for i in list_or_series]\n        else: # if it's not active, just pass it right back\n            return list_or_series\n    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})\n\n#--------------------------------------------------------------------------------------------------------------------------------\n\n# Doc2Vec traing\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train_review_text_for_embedding.apply(lambda x: x.split()).values)]\ndoc2vec_model = Doc2Vec(documents, vector_size=100, window=3, min_count=2, workers=-1)\n\n# 2. doc2vec embedding pipeline\ndef doc2vec_pipeline(active=True):\n    def list_comprehend_a_function(list_or_series, active=True):\n        if active:\n            return [doc2vec_model.infer_vector(sent) for sent in pd.Series(list_or_series).apply(lambda x: x.split()).values]\n        \n        else: # if it's not active, just pass it right back\n            return list_or_series\n    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# 3.Model \nclf = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n                       max_depth=500, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=5,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')\n\n# Creating pipeline object\ndt_model_pipeline = Pipeline([\n        (\"clean_text\", pipelinize(clean_text_for_embedding)),\n        ('embed', doc2vec_pipeline()),\n        (\"standard_scalar\" ,StandardScaler()),\n        ('smote',SMOTE()),\n        ('classifier', clf)\n    ],verbose=True)\n\ndt_model_pipeline.fit(X_train,y_train)","d9fa8350":"# Result track\n\ny_pred = dt_model_pipeline.predict(X_val)\ny_pred_proba = dt_model_pipeline.predict_proba(X_val)\n\naccuracy = accuracy_score(y_val,y_pred)\nbal_accuracy = balanced_accuracy_score(y_val,y_pred)\nlogloss = log_loss(y_val,y_pred_proba)\nprint(f'\\nGenearalisation log_loss: {logloss:.3f}')\nprint(f\"\\nGeneralisation Accuracy: {(round(accuracy,2))*100}%\")\nprint(f\"\\nGeneralisation Balance accuracy: {(round(bal_accuracy,2))*100}%\")\nprint(f'\\nmisclassification percentage: {(1-accuracy)*100:.2f}%')\n\n\n#ploting confusion matrix\nsn.heatmap(confusion_matrix(y_pred,y_val),annot=True, fmt=\"d\",linewidths=.5)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.show()\n# Classification Report\nprint(\"\\n\\nclassification report:\\n\",classification_report(y_val,y_pred)) ","1d94aa5b":"# LimeTextExplainer \nclass_names = ['Negative sentiment','Positive Sentiment']\nexplainer = LimeTextExplainer(class_names=class_names, kernel_width=25, verbose=True, feature_selection='auto', bow=True)\n\n# Prediction\nidx = 115\nexp = explainer.explain_instance(text_instance = X_val.iloc[idx], classifier_fn = dt_model_pipeline.predict_proba, num_features=10,num_samples=5000,distance_metric='cosine')\nprint('\\nDocument id: %d' % idx)\nprint(f\"Before Preprocessing\\n{'-'*20}\\n{X_val.iloc[idx]}\\n\")\nprint(f\"After Preprocessing\\n{'-'*20}\\n{X_val_clean_text.iloc[idx]}\\n\")\n\nprint('Probability(Negative sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,0])\nprint('Probability(Positive sentiment) =',dt_model_pipeline.predict_proba([X_val.iloc[idx]])[0,1])\nprint('True class: %s' % class_names[y_train[idx]])\n\n# Local Explanability\n%matplotlib inline\nfig = exp.as_pyplot_figure()","e36da405":"exp.show_in_notebook(text=True)","82458a02":"np.where(y_val!=y_pred)[0]","3ac1f15f":"#### Preprocessing for Embeddings","47d33ff9":"### Decision Tree BOW Pipeline ","ede44839":"#### Example 5 (Incorrectly classified)","81318c37":"### 4.4. Decision Tree on Doc2Vec","cf5f26bd":"## ** Debug (todo)","4ad522ef":"#### AVG W2V Skip gram empbedding","bc81db43":"#### Example 6 (Incorrectly classified)","a1b10b92":"#### PCA for visualisation of Doc2Vec","d99e33ed":"#### Example 3  (Incorrectly classified)","92bb4442":"#### Example 3  (Incorrectly classified)","3b3ce986":"#### Prediction Result","ab15d3ba":"### Decision Tree TFIDF Pipeline ","2efcca91":"#### Building vocubulary from our Dataset\nRefer: https:\/\/www.kaggle.com\/phoenix9032\/quest-preprocessing-data-for-embedding","4ad7c4fa":"#### Example 4 (Incorrectly classified)","70aee330":"## 1.1 About Dataset\n\n\n#### Dataset Source: https:\/\/www.kaggle.com\/nicapotato\/womens-ecommerce-clothing-reviews\n\n\n### Context:\nWelcome. This is a Women\u2019s Clothing E-Commerce dataset revolving around the reviews written by customers. Its nine supportive features offer a great environment to parse out the text through its multiple dimensions. Because this is real commercial data, it has been anonymized, and references to the company in the review text and body have been replaced with \u201cretailer\u201d.\n\n\n### Content:\n\n#### This dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n\n**Clothing ID:** Integer Categorical variable that refers to the specific piece being reviewed.\n\n**Age:** Positive Integer variable of the reviewers age.\n\n**Title:** String variable for the title of the review.\n\n**Review Text:** String variable for the review body.\n\n**Rating:** Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n\n**Recommended IND:** Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n\n**Positive Feedback Count:** Positive Integer documenting the number of other customers who found this review positive.\n\n**Division Name:** Categorical name of the product high level division.\n\n**Department Name:** Categorical name of the product department name.\n\n**Class Name:** Categorical name of the product class name.\n\n\n### Note: Iam only using *'Review Text'* as features and *'Rating'* as class labels and converting into binary classification problem.\n#### {1: positive sentiment, 0: Negative sentiment}","f9ab50e5":"#### Prediction Result (Not showing right result)","65b9d518":"## 1.3. Overview EDA\n\n* Dataset Overview\n* Distribution of classlabel\n* Missing Values and Duplicate values","7f258ad8":"#### Example 1 (correctly classified)","749852cb":"#### Prediction Result ","0f14226e":"Dataset: https:\/\/www.kaggle.com\/nicapotato\/womens-ecommerce-clothing-reviews\n\nGlove: https:\/\/www.kaggle.com\/takuok\/glove840b300dtxt","e9429f80":"----","83ab949d":"#### Example 3  (Incorrectly classified)","9d677cab":"### 3.2. TF-IDF\n","27aee526":"### 3.6. Doc2Vec(PV-DM) - training on own corpus\n\nRefer foe learning: https:\/\/towardsdatascience.com\/understand-how-to-transfer-your-paragraph-to-vector-by-doc2vec-1e225ccf102","10a7de1f":"### Decision Tree W2V Skip gram Pipeline (with smote problem)","e03755d0":"### Lime Explainability (DT + W2V Skip)","c7db2bca":"### 4.3. Decision Tree on W2V Skipgram","c4f4e59e":"### Decision Tree Doc2Vec Pipeline","91964550":"### 3.5. Word2Vec Skip gram trained on own corpus","5c778f2d":"#### 3.1.2. BOW - bigram","9b1d3f21":"#### Standard scaling of Avg W2V (Trained on own corpus)","7a4aebfb":"### 3.3. Word2vec trained on our own corpus","1a2c9fe3":"#### Example 2 (Incorrectly classified)","b0b937e1":"## 2. Preprocessing\n\n1. tokenize and lowering words\n2. Decontraction (mis spelled words)\n3. Cleaning(html tags remove, punctuation remove etc)\n4. stopwords remove\n5. lemmatization or stemming\n5. Unnecessary words remove(word_len<3)\n","dec72896":"#### 3.1.1. BOW - unigram ","6ca81b3b":"### 2.1. Distribution  number of word in text (before and after preprocessing)","e5e2ab3a":"### Lime Explainability (DT + TFIDF)","5ee63f3f":"### 3.1. Bag of Words (BOW)\n","b104bfba":"## 1.2. Machine Learning Formulation\n\n#### Its a simple Binary Classification \n![image.png](attachment:image.png)\n\n### 1.2.1. Evaluation Metric\n\n#### 1. Logloss ass primary metric. (want to penalise based on probability score of each class and also for better interpretability of model for both of the class)\n#### 2. Classification Report as secondary metric (include accuracy, precision, recall, f1_score)  ","b0eb58b6":"#### Example 5 (Incorrectly classified)","773890ae":"# Sentiment classification on E-commerce dataset\n----\n----\n\n## Workflow\n-----\n\n### 1. About Data, Machine Learning Formulation and EDA\n\n### 2. Preprocessing\n\n### 3. Feature Engineering\n\n### 4. Modeling and hypertuining\n\n### 5. Result and deploying prediction pipeline\n","c895ea35":"## 4.1. Decision Tree on BOW","15627e5d":"#### Example 4 (Incorrectly classified)","7d5b512b":"### Lime Explainability (DT + BOW)","3bd767d9":"#### Example 6 (Incorrectly classified)","40f5bcb5":"## 1.1.1. Loading the dataset and dataset Overview\n","a53857d6":"### Lime Explainability (DT + Doc2Vec)","27ec60b2":"#### Prediction Result ","dfe135e1":"#### Example 1 (correctly classified)","151fa01d":"#### Prediction Result","75a1d34a":"#### Example 2 (Incorrectly classified)","e6025b41":"#### Visualizing Reviews text using Avg W2V CBOW","e3df5818":"# 4. Modeling","07f61661":"## 3. Feature Engineering or Feature Extraction\n\n#### 3.1. Bag of Words (countvectoriser)\n#### 3.2. TF-IDF\n#### 3.3. Word2Vec CBOW on own corpus\n#### 3.4. Word2Vec Skipgram on own corpus\n#### 3.5. Word2Vec pretrained \n#### 3.6. Doc2Vec trained on own corpus \n#### 3.7. Doc2Vec pretrained ","2feb0950":"### Explanation . . .. ","81e49909":"### Train Test Split","ac75ea88":"![](http:\/\/)![image.png](attachment:image.png)","41416f10":"#### W2V Embeddings using CBOW","e9b83ed5":"#### AVG W2V using pretrained model","cfffc0a0":"# 1. About Data, Machine Learning Formulation and EDA","6c212115":"### 1.3.2 Distribution of class labels(sentiments)","803eab26":"#### Check Coverage for review_text_for_embedding","25941c89":"### Decision Tree W2V Skip gram Pipeline (without smote problem)","7f543fb7":"#### AVG W2V CBOW Feature Exraction","f486f136":"### 3.4. Word2vec - pretrained (Glove)","851a72ea":"#### Example 1 (correctly classified)","7151aecb":"###  Importing llibraries","f820c65b":"#### PCA for visualisation of W2V skipram","1c0d5622":"### 1.3.2 Missing Values and Duplicate values","49455d0c":"#### Example 2 (Incorrectly classified)","198b8e94":"Observation:\n* Class labels are high imbalance. Using accuracy as metric is really not a good idea to check the performance of model.","d9f1b484":"### 1.3.1. Pandas Profiling\n\nLearning Resource for pandas profiling:\n\n1. https:\/\/towardsdatascience.com\/a-better-eda-with-pandas-profiling-e842a00e1136\n\n2. https:\/\/github.com\/pandas-profiling\/pandas-profiling\n","f488a347":"### 4.2. Decision Tree on TFIDF","700e21e6":"### 3.3 Word2vec ","fafdb270":"#### Preprocessing for BOW and TFIDF"}}