{"cell_type":{"d525abf3":"code","af8a3ea7":"code","86f368be":"code","a2bccd53":"code","e0176cf4":"code","f25310b1":"code","b50cd70d":"code","5cf61e1e":"code","15aae767":"code","e4319ef6":"code","4b7185cb":"code","9aabab04":"markdown","2b948679":"markdown","1b776b6a":"markdown","6b067ab2":"markdown","35b452f2":"markdown","7cc14f2f":"markdown"},"source":{"d525abf3":"import os\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\ntf.get_logger().setLevel(\"ERROR\")","af8a3ea7":"# Helper method to load an image\n\ndef load_image_into_numpy_array(path):\n    image = None\n    image_data = tf.io.gfile.GFile(path, \"rb\").read()\n    image = Image.open(BytesIO(image_data))\n    (im_width, im_height) = image.size\n    \n    return np.array(image.getdata()).reshape(\n        (1, im_height, im_width, 3)).astype(np.uint8)\n\n# Map of all models in TFHub\n\nALL_MODELS = {\n'CenterNet HourGlass104 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/hourglass_512x512\/1', 'CenterNet HourGlass104 Keypoints 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/hourglass_512x512_kpts\/1',\n'CenterNet HourGlass104 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/hourglass_1024x1024\/1', 'CenterNet HourGlass104 Keypoints 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/hourglass_1024x1024_kpts\/1',\n'CenterNet Resnet50 V1 FPN 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet50v1_fpn_512x512\/1', 'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet50v1_fpn_512x512_kpts\/1',\n'CenterNet Resnet101 V1 FPN 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet101v1_fpn_512x512\/1', 'CenterNet Resnet50 V2 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet50v2_512x512\/1',\n'CenterNet Resnet50 V2 Keypoints 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet50v2_512x512_kpts\/1', 'EfficientDet D0 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d0\/1',\n'EfficientDet D1 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d1\/1', 'EfficientDet D2 768x768' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d2\/1',\n'EfficientDet D3 896x896' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d3\/1', 'EfficientDet D4 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d4\/1',\n'EfficientDet D5 1280x1280' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d5\/1', 'EfficientDet D6 1280x1280' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d6\/1',\n'EfficientDet D7 1536x1536' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d7\/1', 'SSD MobileNet v2 320x320' : 'https:\/\/tfhub.dev\/tensorflow\/ssd_mobilenet_v2\/2',\n'SSD MobileNet V1 FPN 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/ssd_mobilenet_v1\/fpn_640x640\/1', 'SSD MobileNet V2 FPNLite 320x320' : 'https:\/\/tfhub.dev\/tensorflow\/ssd_mobilenet_v2\/fpnlite_320x320\/1',\n'SSD MobileNet V2 FPNLite 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/ssd_mobilenet_v2\/fpnlite_640x640\/1', 'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet50_v1_fpn_640x640\/1',\n'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet50_v1_fpn_1024x1024\/1', 'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet101_v1_fpn_640x640\/1',\n'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet101_v1_fpn_1024x1024\/1', 'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet152_v1_fpn_640x640\/1',\n'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet152_v1_fpn_1024x1024\/1', 'Faster R-CNN ResNet50 V1 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet50_v1_640x640\/1',\n'Faster R-CNN ResNet50 V1 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet50_v1_1024x1024\/1', 'Faster R-CNN ResNet50 V1 800x1333' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet50_v1_800x1333\/1',\n'Faster R-CNN ResNet101 V1 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet101_v1_640x640\/1', 'Faster R-CNN ResNet101 V1 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet101_v1_1024x1024\/1',\n'Faster R-CNN ResNet101 V1 800x1333' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet101_v1_800x1333\/1', 'Faster R-CNN ResNet152 V1 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet152_v1_640x640\/1',\n'Faster R-CNN ResNet152 V1 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet152_v1_1024x1024\/1', 'Faster R-CNN ResNet152 V1 800x1333' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet152_v1_800x1333\/1',\n'Faster R-CNN Inception ResNet V2 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/inception_resnet_v2_640x640\/1', 'Faster R-CNN Inception ResNet V2 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/inception_resnet_v2_1024x1024\/1',\n'Mask R-CNN Inception ResNet V2 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/mask_rcnn\/inception_resnet_v2_1024x1024\/1'\n}\n\n# List of tuples with Human Keypoints needed for models with keypoints\n\nCOCO17_HUMAN_POSE_KEYPOINTS = [\n    (0, 1), (0, 2), (1, 3), (2, 4), (0, 5), (0, 6), (5, 7), (7, 9), (6, 8), (8, 10), (5, 6), \n    (5, 11), (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)\n]","86f368be":"# Use TensorFlow Object Detection API\n\n# Clone the TensorFlow models repository\n\n!git clone --depth 1 https:\/\/github.com\/tensorflow\/models","a2bccd53":"# Install the TensorFlow Object Detection API","e0176cf4":"%%bash\nsudo apt install -y protobuf-compiler\ncd models\/research\/\nprotoc object_detection\/protos\/*.proto --python_out=.\ncp object_detection\/packages\/tf2\/setup.py .\npython -m pip install .","f25310b1":"# Import dependencies for object detection\n\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils\nfrom object_detection.utils import ops\n\n%matplotlib inline","b50cd70d":"# Let's try a version of RetinaNet: SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)\n\nmodel_name = \"SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)\"\nmodel_handle = ALL_MODELS[model_name]\n\n# Load the model from TensorFlow Hub\n\nprint(\"loading model...\")\nhub_model = hub.load(model_handle)\nprint(\"model loaded !\")","5cf61e1e":"# Get the data\n\npath = \"..\/input\/tensorflow-great-barrier-reef\/\"\ntrain = pd.read_csv(path+\"train.csv\")\ntest = pd.read_csv(path+\"test.csv\")\n\n# Add images path to data\n\ntrain[\"image_path\"] = \"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_\"+train[\"video_id\"].astype(str)+\"\/\"+train[\"image_id\"].apply(lambda x: x.split(\"-\")[1])+\".jpg\"\n\n# Reorganise columns\n\ncols = train.columns[:-2].tolist()+[\"image_path\"]+[train.columns[-2]]\ntrain = train[cols]\n\nprint(\"First rows of training data:\\n\")\nprint(train.head(), \"\\n\")\n\nprint(\"Training data types:\\n\")\nprint(train.dtypes)","15aae767":"# Pick an image randomly from the training set\n\nimage_path = pd.DataFrame.sample(train[\"image_path\"], n=1).tolist()[0]\nimage_np = load_image_into_numpy_array(image_path)\n\nplt.figure(figsize=(10, 8))\nplt.imshow(image_np[0])\nplt.show()","e4319ef6":"# Run inference with our model\nresult = hub_model(image_np)","4b7185cb":"PATH_TO_LABELS = '.\/models\/research\/object_detection\/data\/mscoco_label_map.pbtxt'\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n\nlabel_id_offset = 0\nimage_np_with_detections = image_np.copy()\n\n# Use keypoints if available in detections\nkeypoints, keypoint_scores = None, None\nif 'detection_keypoints' in results:\n    keypoints = result['detection_keypoints'][0]\n    keypoint_scores = result['detection_keypoint_scores'][0]\n\nvisualization_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_detections[0],\n      result['detection_boxes'][0],\n      (result['detection_classes'][0] + label_id_offset),\n      result['detection_scores'][0],\n      category_index,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=200,\n      min_score_thresh=.1,\n      agnostic_mode=False,\n      keypoints=keypoints,\n      keypoint_scores=keypoint_scores,\n      keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np_with_detections[0])\nplt.show()","9aabab04":"## Build an Object Detection Model","2b948679":"# TensorFlow Object Detection API Experiment","1b776b6a":"## Model trials on training images","6b067ab2":"**Objectives**\n\n1. ETL on competition data for TensorFlow Object Detection API\n2. Train and evaluate a model with competition data\n3. Make a first submission (if everything goes well)","35b452f2":"## Utilities","7cc14f2f":"## Visualisation Tools"}}