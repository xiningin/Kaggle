{"cell_type":{"e9204854":"code","ddcaa2ea":"code","b3c2ebb3":"code","9f8ce61d":"code","9b47127d":"code","8deb147b":"code","8ea64aa0":"code","bc4d4f3d":"code","a1cfae56":"code","79494cf0":"code","f392bfbd":"code","064a6875":"code","d339096c":"code","67b9fc54":"code","c86510be":"code","fe840181":"code","71cbbab7":"code","2ccc2208":"code","8cfa8171":"code","a026c5ae":"code","6995cbb8":"code","fded65ed":"code","998954f2":"code","7a46c7d0":"code","436d4d5b":"code","76896dec":"code","f04dfb2c":"code","95f79386":"code","967625df":"code","56500d92":"code","fcff16dd":"code","5efc6263":"code","81f8f6ce":"code","c030d955":"code","5220f964":"code","be1a0e56":"code","42d5e352":"code","0aa263dc":"code","e9209fcc":"markdown","a08d3f42":"markdown","2853c1e2":"markdown","64f68ae4":"markdown","10d336d0":"markdown","d900c11f":"markdown","26ee9bda":"markdown","77b95da5":"markdown","45b59e7a":"markdown","2685266a":"markdown","3f71cd1d":"markdown","5e85af28":"markdown","733d562a":"markdown","f143d078":"markdown","c34db2a0":"markdown","ff1fc770":"markdown","372b8ecd":"markdown","aa5eae91":"markdown","2636a7ff":"markdown"},"source":{"e9204854":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os, math\nfrom datetime import datetime\nimport seaborn as sns\nimport matplotlib.cm as cm\n\nfrom sklearn import neighbors, linear_model, svm, tree, ensemble\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix,roc_auc_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split","ddcaa2ea":"dat = pd.read_csv(\"..\/input\/ATP.csv\")","b3c2ebb3":"dat['date'] = dat.tourney_date.apply(lambda t: datetime.strptime(str(t), '%Y%m%d'))","9f8ce61d":"colnames = dict()\ncolnames['type1'] = ['1stIn', '1stWon', '2ndWon', 'SvGms', 'ace', 'bpFaced', 'bpSaved', 'df', 'svpt']\ncolnames['type2'] = ['age', 'entry', 'hand', 'ht', 'id', 'ioc', 'name', 'rank', 'rank_points', 'seed']\ncolnames['type3'] = ['best_of', 'draw_size', 'match_num', 'minutes', 'round', 'score', 'surface', 'tourney_date',\n                     'tourney_id', 'tourney_level', 'tourney_name', 'date']","9b47127d":"df = pd.DataFrame()\nmat = []\nfor i in dat.index:\n    row = []\n    for col in colnames['type3']:\n        row.append(dat[col][i])\n    if i % 2 == 0: #j0\n        # j0=loser, j1=winner\n        for col in colnames['type1']:\n            row.append(dat['l_'+col][i])\n        for col in colnames['type2']:\n            row.append(dat['loser_'+col][i])\n        for col in colnames['type1']:\n            row.append(dat['w_'+col][i])\n        for col in colnames['type2']:\n            row.append(dat['winner_'+col][i])\n        row.append(1) #target winner --> j1\n    else: #j1\n        # j0=winner, j1=loser\n        for col in colnames['type1']:\n            row.append(dat['w_'+col][i])\n        for col in colnames['type2']:\n            row.append(dat['winner_'+col][i])\n        for col in colnames['type1']:\n            row.append(dat['l_'+col][i])\n        for col in colnames['type2']:\n            row.append(dat['loser_'+col][i])\n        row.append(0) #target winner --> j0\n    mat.append(row)","8deb147b":"colDataFrame = colnames['type3']\nfor col in colnames['type1']:\n    colDataFrame.append('j0_'+col)\nfor col in colnames['type2']:\n    colDataFrame.append('j0_'+col)\nfor col in colnames['type1']:\n    colDataFrame.append('j1_'+col)\nfor col in colnames['type2']:\n    colDataFrame.append('j1_'+col)\ncolDataFrame.append(\"target\")","8ea64aa0":"df = pd.DataFrame(columns=colDataFrame, data=mat)","bc4d4f3d":"df.head()","a1cfae56":"print(\"nRows : {}, nCols : {}\".format(df.shape[0], df.shape[1]))","79494cf0":"dfe = df.copy()","f392bfbd":"dfe = dfe.loc[np.invert(dfe.j0_rank.isna()) & np.invert(dfe.j1_rank.isna())]\ndfe = dfe.loc[np.invert(dfe.j0_rank_points.isna()) & np.invert(dfe.j1_rank_points.isna())]","064a6875":"dfe = dfe.loc[np.invert(dfe.surface.isna())]\ndfe = dfe.loc[dfe.surface != \"None\"]","d339096c":"print(\"nRows : {}, nCols : {}\".format(dfe.shape[0], dfe.shape[1]))","67b9fc54":"print(\"There are {} matches.\".format(dfe.shape[0]))\nprint(\"There are {} different players.\".format(len(list(set(dfe.j0_name + dfe.j1_name)))))","c86510be":"# pie chart of surface\ncount_surface = dfe[[\"tourney_id\", \"surface\"]]\ncount_surface = count_surface.groupby([\"surface\"]).agg('count')\ncount_surface.reset_index(inplace=True)\ncount_surface.columns=[\"surface\",\"Count\"]\ncount_surface.sort_values(\"Count\", inplace=True)\n\nx = np.arange(count_surface.shape[0])\nys = [i+x+(i*x)**2 for i in range(count_surface.shape[0])]\ncolors = cm.rainbow(np.linspace(0, 1, len(ys)))\n\nplt.rc('font', weight='bold')\nf, ax = plt.subplots(figsize=(5,5), dpi=120)\nlabels=count_surface.surface.values\n\nsizes=count_surface.Count.values\n\nexplode = [0.9 if sizes[i] < 1000 else 0.0 for i in range(len(sizes))]\nax.pie(sizes, explode = explode, labels=labels, colors = colors,\n       autopct = lambda x:'{:1.0f}%'.format(x) if x > 1 else '',\n       shadow = False, startangle=0, textprops={'fontsize': 7})\nax.axis('equal')\nax.set_title('Surface', bbox={'facecolor':'blue', 'pad':3}, color = 'w', fontsize=10)\n_ = ax","fe840181":"# bpFaced barplot\ndfe_bpFaced = dfe.groupby([\"target\"])[\"j0_bpFaced\",\"j1_bpFaced\"].agg('mean')\ndfe_bpFaced.reset_index(inplace=True)\n\nplayers=['player 0', 'player 1']\nlw=[0,1]\npos = np.arange(len(players))\nbar_width = 0.35\nindex_loser=dfe_bpFaced.iloc[0,1:].values\nindex_winner=dfe_bpFaced.iloc[1,1:].values\n\nplt.bar(pos,index_loser,bar_width,color='red',edgecolor='black')\nplt.bar(pos+bar_width,index_winner,bar_width,color='green',edgecolor='black')\nplt.xticks(pos+0.1, players)\nplt.xlabel('', fontsize=16)\nplt.ylabel('Breakpoints faced', fontsize=15)\nplt.title('Barchart',fontsize=18)\nplt.legend(lw,loc=2)\nplt.show()","71cbbab7":"# Binarize surface\ndf_surface = dfe.surface.str.get_dummies()\ndf_surface.head()","2ccc2208":"ax = sns.boxplot(x=\"surface\", y=\"j1_rank_points\", hue=\"target\", data=dfe, palette=['blue','red'])\nax.set_ylim([0, 5000])\nax.set_ylabel(\"rank points\")\n_ = ax","8cfa8171":"ax = sns.boxplot(x=\"target\", y=\"j1_rank_points\", data=dfe, palette=[\"blue\",\"red\"])\nax.set_ylim([0,4000])\nax.set_ylabel('rank points')\n_ = ax","a026c5ae":"class Model:\n    def __init__(self,data,seed,random_sample):\n        self.random_sample = random_sample\n        self.seed = seed\n        \n        self.data = data.sample(frac=self.random_sample, replace=False, random_state=self.seed)\n        \n        self.lr=None\n        self.pred_train=None\n        self.pred_test=None\n    def split(self, test_size):\n        self.test_size = test_size\n        train_X, test_X, train_y, test_y = train_test_split(self.data,self.data['target'], test_size = test_size, random_state=self.seed)\n        self.train_X = train_X.drop(columns=['target'])\n        self.test_X = test_X.drop(columns=['target'])\n        self.train_y = train_y\n        self.test_y = test_y\n    def model_LR(self,n_jobs,cv,regul):\n        self.regul = regul\n        if regul=='none':\n            n_iters = np.array([50, 200])\n            model = linear_model.SGDClassifier(loss='log', random_state=0, penalty=self.regul)\n            grid = GridSearchCV(estimator=model, param_grid=dict(n_iter_no_change=n_iters), scoring='roc_auc', n_jobs=n_jobs, cv=cv, verbose=1)\n            grid.fit(self.train_X,self.train_y)\n            self.grid = grid\n        elif regul=='elasticnet':\n            n_iters = np.array([50, 200])\n            alphas = np.logspace(-5, 1, 5)\n            l1_ratios = np.array([0, 0.15, 0.3, 0.4, 0.5, 0.6, 0.85, 1])\n            model = linear_model.SGDClassifier(loss='log', random_state=0, penalty=self.regul,n_iter_no_change=100,max_iter=100)\n            grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas,l1_ratio=l1_ratios), scoring='roc_auc', n_jobs=n_jobs, cv=cv, verbose=1)\n            grid.fit(self.train_X,self.train_y)\n            self.grid = grid\n        return self.lr\n    def model_GB(self,n_jobs,cv):\n        param_grid = {'n_estimators' : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,150,200],\n                      'learning_rate':[0.1,0.2,0.5,0.7,0.9,1]}\n        model = ensemble.GradientBoostingClassifier()\n        grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', n_jobs=n_jobs, cv=cv, verbose=1)\n        grid.fit(self.train_X,self.train_y)\n        self.grid = grid\n    def model_KNN(self,n_jobs,cv):\n        param_grid = {'n_neighbors': np.arange(1,310,10)}\n        model = neighbors.KNeighborsClassifier()\n        grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', n_jobs=n_jobs, cv=cv, verbose=1)\n        grid.fit(self.train_X,self.train_y)\n        self.grid = grid\n    def model_RF(self,n_jobs,cv):\n        param_grid = {'criterion' : ['entropy', 'gini'],\n                      'n_estimators' : [20, 40, 60, 80, 100, 120, 160, 200, 250, 300],\n                      'max_features' :['sqrt', 'log2']}\n        model = ensemble.RandomForestClassifier()\n        grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', n_jobs=n_jobs, cv=cv, verbose=1)\n        grid.fit(self.train_X,self.train_y)\n        self.grid = grid\n    def predict(self):\n        self.pred_train = self.grid.best_estimator_.predict_proba(X=self.train_X)\n        self.pred_test = self.grid.best_estimator_.predict_proba(X=self.test_X)\n    def get_AUC(self):\n        self.train_auc=metrics.roc_auc_score(y_score=self.grid.best_estimator_.predict_proba(X=self.train_X)[:,1], y_true=self.train_y)\n        self.test_auc=metrics.roc_auc_score(y_score=self.grid.best_estimator_.predict_proba(X=self.test_X)[:,1], y_true=self.test_y)\n        return (self.train_auc,self.test_auc)\n    ### get contingency table + recall precision + roc curve !!!\n    def boxplot(self):\n        plt.figure()\n        plt.subplot(1,2,1)\n        sns.boxplot(x=self.train_y.values, y=self.grid.best_estimator_.predict_proba(X=self.train_X.values)[:,1])\n        plt.title('Train')\n        plt.subplot(1,2,2)\n        sns.boxplot(x=self.test_y.values, y=self.grid.best_estimator_.predict_proba(X=self.test_X.values)[:,1])\n        plt.title('Test')\n        return plt\n    def rocCurve(self):\n        plt.figure()\n        plt.subplot(1,2,1)\n        fpr, tpr, thresholds = metrics.roc_curve(y_score=self.grid.best_estimator_.predict_proba(X=self.train_X)[:,1], y_true=self.train_y)\n        plt.plot(fpr, tpr,'r')\n        plt.plot([0,1],[0,1],'b')\n        plt.title('Train, AUC: {}'.format(round(metrics.auc(fpr,tpr),3)))\n        \n        plt.subplot(1,2,2)\n        fpr, tpr, thresholds = metrics.roc_curve(y_score=self.grid.best_estimator_.predict_proba(X=self.test_X)[:,1], y_true=self.test_y)\n        plt.plot(fpr, tpr,'r')\n        plt.plot([0,1],[0,1],'b')\n        plt.title('Test, AUC: {}'.format(round(metrics.auc(fpr,tpr),3)))\n        return plt\n    def confusion(self,set_):\n        if set_ == \"train\":\n            res = metrics.confusion_matrix(y_true=self.train_y,y_pred=self.pred_train)\n        elif set_ == \"test\":\n            res = metrics.confusion_matrix(y_true=self.test_y,y_pred=self.pred_test)\n        return res\n    def getAccuracy(self):\n        res=(metrics.accuracy_score(y_true=self.train_y,y_pred=self.pred_train),\n            metrics.accuracy_score(y_true=self.test_y,y_pred=self.pred_test))\n        return res\n    def getClassificationReport(self,set_):\n        if set_ == \"train\":\n            res = metrics.classification_report(self.train_y, self.pred_train)\n        elif set_ == \"test\":\n            res = metrics.classification_report(self.test_y, self.pred_test)\n        return res","6995cbb8":"dfm = dfe[[\"target\",\"j0_rank_points\",\"j1_rank_points\",\"j0_bpFaced\",\"j1_bpFaced\"]]\ndfm[df_surface.columns] = df_surface\ndfm.dropna(inplace=True)\n\ndfm.j0_rank_points = dfm.j0_rank_points.apply(lambda x: math.log(x))\ndfm.j1_rank_points = dfm.j1_rank_points.apply(lambda x: math.log(x))","fded65ed":"dfm.head()","998954f2":"lr = Model(data=dfm,seed=123,random_sample=1)\nlr.split(0.35)\nlr.model_LR(cv=4,n_jobs=8,regul=\"elasticnet\")\nlr.predict()","7a46c7d0":"_ = lr.rocCurve()","436d4d5b":"_ = lr.boxplot()","76896dec":"lr.grid.best_params_","f04dfb2c":"gb = Model(data=dfm,seed=123,random_sample=1)\ngb.split(0.35)\ngb.model_GB(cv=4,n_jobs=8)\ngb.predict()","95f79386":"_ = gb.rocCurve()","967625df":"_ = gb.boxplot()","56500d92":"gb.grid.best_params_","fcff16dd":"knn = Model(data=dfm,seed=123,random_sample=1)\nknn.split(0.35)\nknn.model_KNN(cv=4,n_jobs=8)\nknn.predict()","5efc6263":"_ = knn.rocCurve()","81f8f6ce":"_ = knn.boxplot()","c030d955":"knn.grid.best_params_","5220f964":"rf = Model(data=dfm,seed=123,random_sample=1)\nrf.split(0.35)\nrf.model_RF(cv=4,n_jobs=4)\nrf.predict()","be1a0e56":"_ = rf.rocCurve()","42d5e352":"_ = rf.boxplot()","0aa263dc":"rf.grid.best_params_","e9209fcc":"There is overfitting of data using the random forest algorithm.","a08d3f42":"Converting the date of tourney as datatime","2853c1e2":"Rows with 'None' or NaN for the surface will be removed as it is a pertinent variable for the prediction.","64f68ae4":"## Logistic regression (lr)","10d336d0":"# Conclusion\/Discussion","d900c11f":"## K nearest neighbors (knn)","26ee9bda":"## Random forest (rf)","77b95da5":"# Exploration of data","45b59e7a":"The rank points is an important data because it allows to justify the level of the player. So, if the player has a huge rank, he could win the match very easily.","2685266a":"There are 4 types of surface in the Tennis : Hard, Grass, Carpet, Clay.","3f71cd1d":"## Gradient boosting (gb)","5e85af28":"# Loading modules","733d562a":"# Prediction\nIn this section, I would suggest 4 different algorithms (supervised): Logistic regression (lr), Gradient boosting (gb), k-nearest neighbors (knn), Random forest (rf). For each model, the metric will be the AUC (ROC Curve) using a gridsearchcv to determine the best estimator for the prediction.\n## Class implementation","f143d078":"The model contains the rank points (rank_points) and the breakpoints faced (bpFaced) for each player as predictors, the surface (binarized).<br>\nThe rank points will be replaced by its log-transformation.","c34db2a0":"The breakpoints faced is an important variable to predict a win of a match.<br>\nAs I said before, the surface seems to be naturally a good predictor.<br>\nFor example, Raphael Nadal may win Roger Federer in clay surface (Roland Garros) with a high probability.<br>\nThat is why we binarize the surface variable.","ff1fc770":"The first rankings were published in August, 23rd 1973, so we can delete all row without rank as this value seems to be important for the bookmakers !","372b8ecd":"# Cleaning of data","aa5eae91":"As a conclusion, all models developped have a good diagnostic performance in train\/test set (AUC = 0.90) except for the random forest because of the overfitting. Nevertheless, if I had to choose one model, I choose the one based on the gradient boosting because there are a few outliers compared to the others.<br>\n\nNote that is not easy to collect some data like the breakpoints faced for further predictions. As a matter of fact, if we want to create an api which is going to give the probability of the winner. We have to collect the rank points and surface used which are very easy. But the breakpoints faced will be missed. To pass this obstacle, the solution will be to develop a knn model based on rank points and surface in order to predict the breakpoints faced (as a continuous variable), for each player. Then, after predicting the value of breakpoints faced, the prediction of the winner can be done.<br>\n\nAnother suggestion : use the module \"VotingClassifier\" which can combine multiple different models into a single model (which is stronger than any of the individual models alone).","2636a7ff":"Changing the format of initial dataframe.<br>\nI would like to create a binary target which means the win of the player j0 or j1.<br>\nFor example, target = 0 means that the player j0 won, otherwise target = 1 means that the player j1 won.<br>\nObjective : Predict this target based on several variables from this dataset."}}