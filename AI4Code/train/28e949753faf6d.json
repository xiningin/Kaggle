{"cell_type":{"f8d8f04f":"code","fb30b1a2":"code","65561d23":"code","52877a38":"code","34580b72":"code","676aef82":"code","6c762b5a":"code","20802370":"code","ecd69564":"code","c0479247":"code","3c999579":"code","17e2141f":"code","d0533450":"code","91a7f37f":"code","bb370851":"code","62e06299":"code","6270281f":"code","f0b433e6":"code","ae5be2de":"code","082ee6a7":"code","0a9baa82":"code","ee20bfde":"code","7bf5e10c":"code","05a709aa":"code","947f297e":"code","29570ab7":"code","cb8f6db9":"code","a4bba77f":"code","1296d626":"code","47eb43b7":"code","bbf2870e":"markdown","637b16fc":"markdown","d1512e7f":"markdown","a167dcaf":"markdown","f40e9c3d":"markdown","9448831f":"markdown","cd3fb112":"markdown","d22c8537":"markdown","63106664":"markdown","03f24d48":"markdown","e25cde6d":"markdown","113a5ce2":"markdown","8ea7ff58":"markdown","c6c14b52":"markdown","23fc1743":"markdown","0690fa8a":"markdown","73520fda":"markdown","59afb51b":"markdown","0c3bec7f":"markdown","96a31a04":"markdown","26b4103a":"markdown","d1e4921d":"markdown","31cc5ab9":"markdown","9c1ea65c":"markdown","08a64bac":"markdown","cb3db3aa":"markdown","e45f7187":"markdown","c34c349c":"markdown","3d2ebcc2":"markdown","30bdf679":"markdown","5d8e96f5":"markdown","8f9ad032":"markdown","7833b85d":"markdown","ec47567e":"markdown","66973da0":"markdown","1b333abd":"markdown"},"source":{"f8d8f04f":"name = 'Brian Keegan'\nprint(name)","fb30b1a2":"from IPython.display import Image\n\nImage('https:\/\/pbs.twimg.com\/media\/C4otUykWcAIbSy1.jpg')","65561d23":"import requests\n\n# Pretend to be a web browser and make a get request of a webpage\noscars90_request = requests.get('https:\/\/www.oscars.org\/oscars\/ceremonies\/2018')\n\n# The .text returns the text from the request\noscars90_html = oscars90_request.text\n\n# The oscars90_html is a string, we can use the common len function to ask how long the string is (in characters)\nlen(oscars90_html)","52877a38":"# The [0:1000] is a slicing notation \n# It gets the first (position 0 in Python) character until the 1000th character\n\nprint(oscars90_html[0:1000])","34580b72":"# You can slice any ranges you'd like up, as long as it's not beyond the length of the string\n# oscars90_html[144588:] would return an error\n\nprint(oscars90_html[50000:51000])","676aef82":"house_raw = requests.get('http:\/\/clerk.house.gov\/xml\/lists\/MemberData.xml').text\n\nsenate_raw = requests.get('https:\/\/www.senate.gov\/legislative\/LIS_MEMBER\/cvc_member_data.xml').text","6c762b5a":"# First import the library\nfrom bs4 import BeautifulSoup\n\n# Then make the soup, specifying the \"lxml\" parser\nhouse_soup = BeautifulSoup(house_raw,'lxml')","20802370":"# Make an empty list to store data\nchildren = []\n\n# Start a loop to go through all the children tags in house_soup\nfor tag in house_soup.findChildren():\n    \n    # If the name of the tag (tag.name) is not already in the children list\n    if tag.name not in children:\n        \n        # Add the name of the tag to the children list\n        children.append(tag.name)\n\n# Look at the list members\nchildren","ecd69564":"len(house_soup.html.body.memberdata.members)","c0479247":"len(house_soup.members)","3c999579":"house_soup.members.contents[0]","17e2141f":"house_soup.members.contents[0].bioguideid","d0533450":"house_soup.members.contents[0].state-fullname","91a7f37f":"house_soup.members.contents[0].find('state-fullname')","bb370851":"house_soup.members.contents[0].find('state-fullname').text","62e06299":"house_soup.find_all('party')[:10]","6270281f":"# Initialize a counter\ndemocrats = 0\nrepublicans = 0\nother = 0\n\n# Loop through each element of the caucus tags\nfor p in house_soup.find_all('party'):\n    \n    # Check if it's D, R, or something else\n    if p.text == \"D\":\n        \n        # Increment the appropriate counter\n        democrats += 1\n    \n    elif p.text == \"R\":\n        republicans += 1\n    else:\n        other += 1\n        \nprint(\"There are {0} Democrats, {1} Republicans, and {2} others in the 116th Congress.\".format(democrats,republicans,other))\n","f0b433e6":"# Make classrooms as lists with student names as strings\nclassroom0 = ['Alice','Bob','Carol','Dave']\nclassroom1 = ['Eve','Frank','Grace','Harold']\nclassroom2 = ['Isabel','Jack','Katy','Lloyd']\nclassroom3 = ['Maria','Nate','Olivia','Philip']\nclassroom4 = ['Quinn','Rachel','Steve','Terry','Ursula']\nclassroom5 = ['Violet','Walter','Xavier','Yves','Zoe']\n\n# Make schools that contain classrooms\nschool0 = [classroom0,classroom1]\nschool1 = [classroom2,classroom3]\nschool2 = [classroom4,classroom5]\n\n# Make a school district that contains schools\nschool_district = [school0,school1,school2]\n\n# Inspect one school's enrollments\nschool_district","ae5be2de":"classroom0[0]","082ee6a7":"# Make a dictionary of states containing dictionaries\nmountain_west = {'Colorado': {'Abbreviation': 'CO',\n                              'Area': 269601,\n                              'Capital': 'Denver',\n                              'Established': '1876-08-01',\n                              'Largest city': 'Denver',\n                              'Population': 5540545,\n                              'Representatives': 7},\n                 'Idaho': {'Abbreviation': 'ID',\n                              'Area': 216443,\n                              'Capital': 'Boise',\n                              'Established': '1890-07-03',\n                              'Largest city': 'Boise',\n                              'Population': 1683140,\n                              'Representatives': 2},\n                 'Montana': {'Abbreviation': 'MT',\n                              'Area': 380831,\n                              'Capital': 'Helena',\n                              'Established': '1889-11-08',\n                              'Largest city': 'Billings',\n                              'Population': 1042520,\n                              'Representatives': 1},\n                 'Utah': {'Abbreviation': 'UT',\n                              'Area': 219882,\n                              'Capital': 'Salt Lake City',\n                              'Established': '1896-01-04',\n                              'Largest city': 'Salt Lake City',\n                              'Population': 3051217,\n                              'Representatives': 4},\n                 'Wyoming': {'Abbreviation': 'WY',\n                              'Area': 253335,\n                              'Capital': 'Cheyenne',\n                              'Established': '1890-07-10',\n                              'Largest city': 'Cheyenne',\n                              'Population': 585501,\n                              'Representatives': 1}}","0a9baa82":"mountain_west.keys()","ee20bfde":"mountain_west.values()","7bf5e10c":"# Statistics about Colorado\nmountain_west['Colorado']","05a709aa":"mountain_west['Colorado']['Population']","947f297e":"school_district_dict = {'School 1':{'Classroom A':['Alice','Bob','Carol','Dave'],\n                                    'Classroom B':['Eve','Frank','Grace','Harold']\n                                   },\n                        'School 2':{'Classroom A':['Isabel','Jack','Katy','Lloyd'],\n                                    'Classroom B':['Maria','Nate','Olivia','Philip']\n                                   },\n                        'School 3':{'Classroom A':['Quinn','Rachel','Steve','Terry','Ursula'],\n                                    'Classroom B':['Violet','Walter','Xavier','Yves','Zoe']\n                                   }\n                        }","29570ab7":"school_district_dict['School 2']['Classroom B'][2]","cb8f6db9":"state_population = [ {'Population': 4338785, 'State': 'Colorado', 'Year': 2000},\n                     {'Population': 4444513, 'State': 'Colorado', 'Year': 2001},\n                     {'Population': 4504709, 'State': 'Colorado', 'Year': 2002},\n                     {'Population': 4555084, 'State': 'Colorado', 'Year': 2003},\n                     {'Population': 4608811, 'State': 'Colorado', 'Year': 2004},\n                     {'Population': 4662534, 'State': 'Colorado', 'Year': 2005},\n                     {'Population': 4745660, 'State': 'Colorado', 'Year': 2006},\n                     {'Population': 4821784, 'State': 'Colorado', 'Year': 2007},\n                     {'Population': 4901938, 'State': 'Colorado', 'Year': 2008},\n                     {'Population': 4976853, 'State': 'Colorado', 'Year': 2009},\n                     {'Population': 5049935, 'State': 'Colorado', 'Year': 2010},\n                     {'Population': 5119538, 'State': 'Colorado', 'Year': 2011},\n                     {'Population': 5191086, 'State': 'Colorado', 'Year': 2012},\n                     {'Population': 5268413, 'State': 'Colorado', 'Year': 2013},\n                     {'Population': 5350118, 'State': 'Colorado', 'Year': 2014},\n                     {'Population': 5448055, 'State': 'Colorado', 'Year': 2015},\n                     {'Population': 5538180, 'State': 'Colorado', 'Year': 2016}\n                   ]","a4bba77f":"# Loop through each dictionary in the list\nfor year_data in state_population:\n    \n    # If the inner dictionary's value for \"Year\" is 2008, do something, otherwise skip\n    if year_data['Year'] == 2008:\n        \n        # Print our the inner dictionary's value for \"Population\"\n        print(year_data['Population'])","1296d626":"# Year 2000 is at index 0, so year 2008 should be at index 8\n# Passing only the index 8 returns a dictionary\n# Include the key whose value you want from this dictionary: \"Population\"\nstate_population[8]['Population']","47eb43b7":"obama_tweet = {'created_at': 'Tue Feb 14 15:34:47 +0000 2017',\n               'favorite_count': 1023379,\n               'hashtags': [],\n               'id': 831527113211645959,\n               'id_str': '831527113211645959',\n               'lang': 'en',\n               'media': [{'display_url': 'pic.twitter.com\/O0UhJWoqGN',\n                          'expanded_url': 'https:\/\/twitter.com\/BarackObama\/status\/831527113211645959\/photo\/1',\n                          'id': 831526916398149634,\n                          'media_url': 'http:\/\/pbs.twimg.com\/media\/C4otUykWcAIbSy1.jpg',\n                          'media_url_https': 'https:\/\/pbs.twimg.com\/media\/C4otUykWcAIbSy1.jpg',\n                          'sizes': {'large': {'h': 800, 'resize': 'fit', 'w': 1200},\n                                    'medium': {'h': 800, 'resize': 'fit', 'w': 1200},\n                                    'small': {'h': 453, 'resize': 'fit', 'w': 680},\n                                    'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n                          'type': 'photo',\n                          'url': 'https:\/\/t.co\/O0UhJWoqGN'}],\n               'retweet_count': 252266,\n               'source': '<a href=\"http:\/\/twitter.com\" rel=\"nofollow\">Twitter Web Client<\/a>',\n               'text': 'Happy Valentine\u2019s Day, @michelleobama! Almost 28 years with you, but it always feels new. https:\/\/t.co\/O0UhJWoqGN',\n               'urls': [],\n               'user': {'created_at': 'Mon Mar 05 22:08:25 +0000 2007',\n                        'description': 'Dad, husband, President, citizen.',\n                        'favourites_count': 10,\n                        'followers_count': 84814791,\n                        'following': True,\n                        'friends_count': 631357,\n                        'id': 813286,\n                        'lang': 'en',\n                        'listed_count': 221906,\n                        'location': 'Washington, DC',\n                        'name': 'Barack Obama',\n                        'profile_background_color': '77B0DC',\n                        'profile_background_image_url': 'http:\/\/pbs.twimg.com\/profile_background_images\/451819093436268544\/kLbRvwBg.png',\n                        'profile_banner_url': 'https:\/\/pbs.twimg.com\/profile_banners\/813286\/1484945688',\n                        'profile_image_url': 'http:\/\/pbs.twimg.com\/profile_images\/822547732376207360\/5g0FC8XX_normal.jpg',\n                        'profile_link_color': '2574AD',\n                        'profile_sidebar_fill_color': 'C2E0F6',\n                        'profile_text_color': '333333',\n                        'screen_name': 'BarackObama',\n                        'statuses_count': 15436,\n                        'time_zone': 'Eastern Time (US & Canada)',\n                        'url': 'https:\/\/t.co\/93Y27HEnnX',\n                        'utc_offset': -18000,\n                        'verified': True},\n               'user_mentions': [{'id': 409486555,\n                                  'name': 'Michelle Obama',\n                                  'screen_name': 'MichelleObama'}]}","bbf2870e":"1. What are the top-most keys in the `obama_tweet` object?\n2. When was this tweet sent?\n3. Does this tweet mention anyone?\n4. How many retweets did this tweet receive (at the time I collected it)?\n5. How many followers does the \"user\" who wrote this tweet have?\n6. What's the \"media_url\" for the image in this tweet?","637b16fc":"Instead you can use the `.find()` method to handle these hyphenated cases.","d1512e7f":"We're not actually going to be slicing the text to get this structured data out, we'll use a wonderful tool call [BeautifulSoup](https:\/\/www.crummy.com\/software\/BeautifulSoup\/) to do the heavy lifting for us.","a167dcaf":"## Forms of structured data\n\nThere are three primary forms of structured data you will encounter on the web: HTML, XML, and JSON.\n\n### HTML\nThe Oscars example from above is an example of [HyperText Markup Language](https:\/\/www.w3.org\/html\/) (HTML), a markup standard that allows web browsers to render documents transmitted by a web server into webpages. HTML is distinct from\u2014but depends strongly on\u2014the [HyperText Transfer Protocol](https:\/\/en.wikipedia.org\/wiki\/Hypertext_Transfer_Protocol) (HTTP) to move data from servers to clients. HTML works with other standards like Cascading Style Sheets (CSS) and JavaScript to create the dynamic and interactive websites. \n\nHTML has a tree-like structure with the \"root\" node being an `<html>` element with other elements like `<body>`s and `<head>`s as children, and those children having other children live the `<div>`, `<a>`, and [other elements](https:\/\/en.wikipedia.org\/wiki\/HTML_element). See the visualization below for a simple example of an HTML tree.\n\n<img src=\"https:\/\/raw.githubusercontent.com\/compsocialscience\/summer-institute\/master\/2018\/materials\/day2-digital-trace-data\/screenscraping\/rmarkdown\/html_tree.png\"><\/img>\n<em>From Chris Bail's \"Screen-Scraping in R\": <a href=\"https:\/\/cbail.github.io\/SICSS_Screenscraping_in_R.html\">https:\/\/cbail.github.io\/SICSS_Screenscraping_in_R.html<\/a><\/em>\n\nIt's beyond the scope of this mini-course to cover what all these elements do or how they interact\u2014I'll leave it to you to develop some folk theories of these tags' functionality based on exploring pages with the \"Inspect\" tool above.\n\nWe can use Python's `requests` library to make a valid HTTP \"get\" request to the Oscars' web server for the 90 Academy Awards which will return the raw HTML. There are more than 144,000 characters in the document!","f40e9c3d":"You can also short-cut to the members tag directly rather than navigating down the parent elements.","9448831f":"There [should be](https:\/\/en.wikipedia.org\/wiki\/116th_United_States_Congress#Party_summary) 235 Democrats and 199 Republicans, plus the other non-voting members from territories.","cd3fb112":"Let's look at the first thousand characters. Mostly declarations to handle Internet Explorer's notorious refusal to follow standards\u2014stuff you don't need to worry about.","d22c8537":"### Exercises\n\n1. How many members serve in \"At Large\" districts? (There's at least two ways to do this)\n2. How many members are women?\n3. How many members are not incumbents? (They were not in the prior Congress)","63106664":"### Exercises\n\nBelow is an example of a [tweet status](https:\/\/dev.twitter.com\/overview\/api\/tweets) object that Twitter's [API returns](https:\/\/dev.twitter.com\/rest\/reference\/get\/statuses\/show\/id). This `obama_tweet` dictionary corresponds to [this tweet](https:\/\/twitter.com\/BarackObama\/status\/831527113211645959). This is a classic example of a JSON object containing a mixture of dictionaries, lists, lists of dictionaries, dictionaries of lists, *etc*.","03f24d48":"### JSON\n\nHTML in the wild can be incredibly complicated (which is why we'll dedicate two whole class sessions to it) and XML is verbose and has other ideosyncracies (which is probably why we won't see it after this class). [JavaScript Object Notation](https:\/\/www.json.org\/) (JSON) is probably the most popular data markup language and is especially ubiquitous when retreiving data from the application programming interfaces (APIs) of popular platforms like Twitter, Reddit, Wikipedia, *etc*.\n\nJSON is attractive for programmers using JavaScript and Python because it can represent a mix of different data types. We need to make a brief digression into Python's fundamental data stuctures in order to understand the contemporary attraction to JSON. Python has a few fundamental data types for representing collections of information:\n\n* **Lists**: This is a basic ordered data structure that can contain strings, ints, and floats.\n* **Dictionaries**: This is an unordered data structure containing key-value pairs, like a phonebook.\n\nHere are some basic examples of lists. Note that lists can contain other lists, and lists of lists of lists, and so on. In this case `school_district` is a list of schools, where each school is a list of classrooms, where each classroom is a list of names.","e25cde6d":"We can access the text inside the tag with `.text`","113a5ce2":"What's the population of Colorado in 2008?\n\nIt's actually a small pain to get it out in this list of dictionaries format. You could loop through each dictionary in the list and ask if its \"Year\" in 2008 and only then print out its \"Population\". You could discover the min and max years (assuming the data is reliably chronological) and then calculate the index where 2008 should occur. This format probably starts to remind you of some of the limitations of XML, but it has strengths in some situations.","8ea7ff58":"### Additional resources\n\nJupyter Notebooks are very powerful tools that are increasingly pervasive throughout the computer, information, and data science communities. I am an [unapologetic evangelist](https:\/\/github.com\/brianckeegan\/Bechdel\/blob\/master\/Bechdel_test.ipynb) for them to be used by researchers, journalists, and activists to improve documentation practices and openness in data analysis, but notebooks also have their critics: [Joel Grus](https:\/\/twitter.com\/joelgrus?lang=en)'s hilarious but important presentation, [I Don't Like Notebooks](https:\/\/docs.google.com\/presentation\/d\/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI\/edit). \n\nHere is some helpful documentation, tutorials, and examples; there are many others out there on the web!\n\n* [DataCamp \u2014 The Definitive Jupyter Notebook Tutorial](https:\/\/www.datacamp.com\/community\/tutorials\/tutorial-jupyter-notebook)\n* [Jupyter Notebook documentation](https:\/\/jupyter.readthedocs.io\/en\/latest\/)\n* [Gallery of interesting Jupyter Notebooks](https:\/\/github.com\/jupyter\/jupyter\/wiki\/A-gallery-of-interesting-Jupyter-Notebooks)","c6c14b52":"This data is still in a string format (`type(house_raw)`), so it's difficult to search and navigate. Let's make our first soup together using [BeautifulSoup](https:\/\/www.crummy.com\/software\/BeautifulSoup\/bs4\/doc\/).","23fc1743":"You can access list elements by their position. In this case, we could access the first name in `classroom0` by requesting the item at the 0th index.","0690fa8a":"## Ethical considerations\n\nThe phrase \"data scraping\" is colloquial and popular but has pejorative connotations. Data is valuable: other people invested time in collecting, organizing, and sharing it. When you show up with a scraper you built after maybe a dozen hours demanding data, you rarely pay the costs of labor, hosting, *etc*. that went into making the data available. There are *very* good rationales for making many kinds of data more availabile: reproducibility of scientific results, sharing publicly-funded and\/or close-to-zero marginal cost resources, transparency and accountability in democratic institutions, remixing for innovative new analyses, *etc*. \n\nBut data breaches have become eponymous (Target in 2013, Equifax in 2017, Facebook in 2018, *etc*.) because they violate other values like privacy. Ethics is concerned with managing these conflicting values and in the West, we've largely converged around two frameworks: utilitarianism and deonotologicalism.\n\n| *Type* | *Pros* | *Cons* |\n| :--- | :----: | :----: |\n| **Consequence** (utilitarian) | \"Greatest good for greatest number\" | Concerns of justice for minority |\n| **Duty** (deontological) | Respect for all persons | Does not maximize utility\/happiness |\n| **Contract** (rights) | Consenual morality | Overly permissive\/asymmetrical morality |\n| **Character** (virtue) | Moral developmen and education | Assumes homogenous morality |\n\nThese manifest most clearly in principles outlined in the 1978 [Belmont Report](https:\/\/en.wikipedia.org\/wiki\/Belmont_Report):\n* **Respect for persons**: protecting the autonomy of all people and treating them with courtesy and respect and allowing for informed consent. Researchers must be truthful and conduct no deception;\n* **Beneficence**: The philosophy of \"Do no harm\" while maximizing benefits for the research project and minimizing risks to the research subjects; and\n* **Justice**: ensuring reasonable, non-exploitative, and well-considered procedures are administered fairly \u2014 the fair distribution of costs and benefits to potential research participants \u2014 and equally.\n\n(A fourth principle \"Respect for Public\" emphasizes compliance, accountability, and transparency in the conduct of research.)\n\nIn the context of data scraping, there are four \"areas of difficulty\":\n\n* **Informed consent**: does the data scraper obtain consent from every person whose data is being retrieved?\n* **Informational risk**: can the data scraper inflict economic, social, *etc*. harm on individuals by disclosing data?\n* **Privacy**: does the data scraper know which information a person intended to be private or public? \n* **Decision-making under uncertainty**: does the data scraper know all the ways the data could be (mis)used? \n\nEthical and legal risks involved with scraping:\n\n* **[Copyright infringement](https:\/\/en.wikipedia.org\/wiki\/Copyright_infringement)**: compiling data that someone else can claim ownership over\n* **[Trespass](https:\/\/en.wikipedia.org\/wiki\/Trespass_to_chattels#In_the_electronic_age)**: over-aggressive scraping shuts down someone else's property\n* **[Computer Fraud & Abuse Act](https:\/\/en.wikipedia.org\/wiki\/Computer_Fraud_and_Abuse_Act)**: misrepresenting yourself to access a system is \"hacking\"\n\nWhile I cannot provide legal advice, we will revisit these concerns throughout the course through best practices for avoiding infringement, staggering data collection, simulating human requests, securing data, and protecting privacy.","73520fda":"### XML\n\nThe HTML from the example above is too obtuse to start working with BeautifulSoup. The [Extensible Markup Language](https:\/\/www.w3.org\/XML\/) (XML) is a related markup language for representing data structures. XML was all the rage at the turn of the century: \"many software designers can barely contain their excitement over its potential to establish a real Internet lingua franca\" (*The New York Times* in 2000: \"[The Next Big Step? It's Called XML](https:\/\/www.nytimes.com\/2000\/06\/07\/business\/the-next-big-leap-it-s-called-xml.html)\"). That obviously did not come to pass. But XML remains a robust and open\u2014though verbose\u2014standard for representing structured data.\n\nXML has taken on something of an afterlife as the official data standard for the U.S. Congress. The [House](http:\/\/clerk.house.gov\/index.aspx) and [Senate](https:\/\/www.senate.gov\/general\/XML.htm) both release information about members, committees, schedules, legislation, and votes in XML. These are immaculately formatted and documented and remarkably up-to-date: the data for members of the 116th Congress are already posted.\n\nUse the `requests` library to make a HTTP get request to the House's webserver and get the list of current member data.","59afb51b":"What's so great about this soup-ified string? We now have a suite of new functions and methods that let us navigate the tree. First, let's inspect the different tags\/elements in this tree of House member data. This is the full tree of data.","0c3bec7f":"Note that this navigation method breaks when the tag has a hyphen in it.","96a31a04":"Here are some basic examples of dictionaries. Note that dictionaries can contain other dictionaries, and so on. In this example `mountain_west` is a dictionary of dictionaries where the outer dictionary is keyed by the name of the state and the inner dictionary has different statistical information.","26b4103a":"Nested data structures do not need to be the same type. A dictionary can have a list as a value for example. This would probably make the `school_district` example easier to understand.","d1e4921d":"## Using Chrome's \"Inspect\" tool\n\nThe official list of nominees and winners of the 90th Academy Awards (in 2018) is available on [the Academy of Motion Picture Arts and Sciences' website](https:\/\/www.oscars.org\/oscars\/ceremonies\/2018). By ocular inspection, this data is at least semi-structured: there are groups of nominees, each group has a title, each nominee has the name of the movie. But this is not structured in the way that we typically analyze data, a table with rows (observations) and columns (features).\n\nThis exercise assumes you're using Chrome, if you're using Safari ([instructions](https:\/\/support.apple.com\/guide\/safari-developer\/inspecting-overview-dev1a8227029\/mac)) or Mozilla ([instructions](https:\/\/developer.mozilla.org\/en-US\/docs\/Tools\/View_source)), there are slightly different workflows. If you right click on the \"Actor in a Leading Role\" and select \"Inspect\", a new window should appear on the side of your browser window. Make sure you have the \"Elements\" tab clicked.\n\nYou should see a nested list of collapsable elements. This is a very complex webpage, like many are these days, with many layers of tags. However if you mouse over the elements, things highlight in the primary browser window. You can see how this is really useful for matching specific HTML codes with what they produce. You can expand an element to see its sub-elements, sub-sub-elements, and so on.\n\nYou should discover that the `<div class=\"view-grouping\">` elements correspond to the nominee categories. The `\"view-grouping\"` is an attribute for the `div` tag. Expanding this element reveals a `<div class=\"view-grouping-content\">` element, which then has seven \"children\": an `<h3>` (heading 3) tag for the name of the category, an obtuse `<div>` class for the winner, another `<h3>` tag for the nominees, and then four (or more) of the same obtuse `<div>` classes for the other nominees. \n\n<img src=\"https:\/\/github.com\/CARTSS\/Web-Data-Scraping-S2019\/blob\/master\/Notebooks\/Images\/oscars-tags-1.png?raw=true\"><\/img>\n\nExpanding any one of the obtuse `<div>` elements reveals still more child tags that ultimately end with the name of the actor `<h4 class=\"field-content\">Gary Oldman<\/h4>` and movie `<span class=\"field-content\">Darkest Hour<\/span>`.\n\n<img src=\"https:\/\/github.com\/CARTSS\/Web-Data-Scraping-S2019\/blob\/master\/Notebooks\/Images\/oscars-tags-2.png?raw=true\"><\/img>\n\nWe will use Chrome's \"Inspect\" tool throughout the rest of the course to find out where our data lives.\n\n### Exercises\n\n1. Use the inspect tool to find the HTML element that makes the triangular logo at the top of the page.\n2. Use the inspect tool to find the `<li>` tags linking to other years's awards pages.\n3. How does the HTML change under the `\"social-drawer-content\"` element when you click between Twitter, Instagram, *etc*.?","31cc5ab9":"You access dictionary values by their keys.","9c1ea65c":"# Web Data Scraping\n\n[Spring 2019 ITSS Mini-Course](https:\/\/www.colorado.edu\/cartss\/programs\/interdisciplinary-training-social-sciences-itss\/mini-course-web-data-scraping) \u2014 ARSC 5040  \n[Brian C. Keegan, Ph.D.](http:\/\/brianckeegan.com\/)  \n[Assistant Professor, Department of Information Science](https:\/\/www.colorado.edu\/cmci\/people\/information-science\/brian-c-keegan)  \nUniversity of Colorado Boulder  \n\nCopyright and distributed under an [MIT License](https:\/\/opensource.org\/licenses\/MIT)\n\n## Course description\n\nThis is a five-week one-credit \"mini-course\" on retrieving (\"scraping\") data from the web. The course is intended for researchers in the social sciences and humanities with computational instincts but limited or no prior programming experience. Each class will be 2.5 hours long: we'll take a break mid-way for biological input and output. Lectures will use a combination of lecture-by-notebook as well as hands-on exercises. The end of each class will have links to resources and additional take-home exercises. Students will have the option of presenting their solutions to the take-home exercises at the beginning of the next class.\n\nAlthough many programming languages offer libraries for web information retrieval and analysis, we will be focusing on the Python data analysis ecosystem given its popularity and capabilities. I would strongly recommend that students download the latest Python 3.7 or above version of the [Anaconda distribution](https:\/\/www.anaconda.com\/download\/) which includes the Jupyter Notebook environment we're currently in, most of the data libraries we will use, and other conveniences.\n\n## Learning objectives\n\nStudents will:\n* Be able to navigate and access structured web data like HTML, XML, and JSON\n* Develop strategies for identifying relevant structures in semi-structed data using browser console tools\n* Utilize Python-based libraries to make request and parse web data\n* Retrieve data from platforms' application programming interfaces (APIs)\n* Critically reflect about the technological and ethical constraints on web scraping\n\n## Class outline\n\n* **Week 1**: Introduction to Jupyter, browser console, structured data, ethical considerations\n* **Week 2**: Scraping HTML with `requests` and `BeautifulSoup`\n* **Week 3**: Scraping web data with Selenium, other tools for automated scraping\n* **Week 4**: Scraping an API with `requests` and `json`, Wikipedia\n* **Week 5**: Authenticating through an API, Twitter & Reddit\n\n## Evaluation\n\nTo be determined based on enrollments, distribution of skills, *etc*. but will primarily involve regular attendance, participation, and upwards trajectory in skill and confidence.\n\n## Acknowledgements\n\nThis course will draw on resources built by myself and [Allison Morgan](https:\/\/allisonmorgan.github.io\/) for the [2018 Summer Institute for Computational Social Science](https:\/\/github.com\/allisonmorgan\/sicss_boulder), which were in turn derived from [other resources](https:\/\/github.com\/simonmunzert\/web-scraping-with-r-extended-edition) developed by [Simon Munzert](http:\/\/simonmunzert.github.io\/) and [Chris Bail](http:\/\/www.chrisbail.net\/). \n\nThank you also to Professors [Bhuvana Narasimhan](https:\/\/www.colorado.edu\/linguistics\/bhuvana-narasimhan) and [Stefanie Mollborn](https:\/\/behavioralscience.colorado.edu\/person\/stefanie-mollborn) for coordinating the ITSS seminars.","08a64bac":"### Exercises\n\n1. Create at least two new cells below (before the **Additional resources** cell) and write your name and 1+1 in them.\n2. Experiment with running a code cell versus a markdown cell. How does the cell change formatting for each?\n3. Move cells around (look at the arrows in the toolbar or use the keyboard shortcuts under Help).\n4. Create a third cell and add another image from the web (use the \"Copy Image Address\" on a right click) into the notebook using the `Image` function.","cb3db3aa":"We can access the 3rd member (remember Python indexes start at 0, so we ask for 2) of \"Classroom B\" in \"School 2\" by working our way outside inward.","e45f7187":"What is the population of Colorado? In a dictionary of dictionaries, you can access the inner dictionary with another key.","c34c349c":"Looking at 1,000 lines about a third of the way through the document, we can see some of the structure we found with the \"Inspect\" tool above corresponding to the closing lines of the \"Actor in a Supporting Role\" grouping and the opening lines of the \"Acress in a Leading Role\" grouping.","3d2ebcc2":"The `.find_all()` method will be your primary tool when working with structured data. The `<party>` tag codes party membership (D=Democratic, R=Republican) for each representative. ","30bdf679":"What are the keys and what are the values?","5d8e96f5":"The `.contents` method is great for getting a list of the children below the tag as a list. We can use the `[0]` slice to get the first member and their data in the list. Interestingly, the `<committee-assignments>` tags are currently empty since these have not yet been allocated, but will in the next few weeks.","8f9ad032":"We can navigate through the tree. You won't do this in practice, but it's helpful for debugging. In this case, we navigated from the root node (`html`) into the `body` tag, then the `memberdata` tag, then the `members` tag. There are 441 descendents at this level, corresponding to the 435 voting seats and the 6 seats for territories.","7833b85d":"## Introduction to Jupyter Notebooks\n\nJupyter Notebooks (previously called IPython Notebooks) are interactive programming environments that are great for writing, executing, and documenting code. The notebooks we'll be using launch in your web browser but are \"talking\" to a local background kernel (hence the \"localhost\" in the URL) rather than an external server. Put another way: the data you're analyzing in Jupyter Notebook isn't leaving your computer.\n\nJupyter Notebooks are composed of \"cells\" which you can create, move, and delete. These cells can be different formats like \"Markdown\" (what this pretty cell is), \"code\" (what you'll spend most of your time in), or \"raw\" (useful for preserving code but avoiding accidentally running it). All the cells up until now have been [Markdown](https:\/\/daringfireball.net\/projects\/markdown\/syntax), which is a lightweight standard for formatting text. You can double click on these Markdown cells to edit them.\n\nThis is an example of a code cell below. You type the code into the cell and run the cell with the \"Run\" button in the toolbar or pressing Shift+Enter.","ec47567e":"A list can take just about any other data structure as a value. Dictionaries are great because they label your data for you but don't preserve order and need unique keys, so they're bad at storing repeated data like a time series. Here's a list where the values are dictionaries and each dictionary is information about the population, state, and year of a location.","66973da0":"Jupyter Notebooks are great because they can keep your code, documentation, and results all in one file. Here I'll import a helper library that lets Jupyter Notebook embed images from the web (from [this tweet](https:\/\/twitter.com\/barackobama\/status\/831527113211645959), which we'll return to in a bit). When you save this notebook, this image will be saved with it.","1b333abd":"You could keep navigating down the tree from here."}}