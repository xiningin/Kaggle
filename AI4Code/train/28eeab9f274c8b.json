{"cell_type":{"3d7fc762":"code","9528521c":"code","03dedf81":"code","904f33cf":"code","f46921d1":"code","1fa9f6cf":"code","76b4abfe":"code","9cd29bc4":"code","ace7c038":"code","c6b87c22":"code","6f04ebe0":"code","ef6704e9":"code","27c32173":"code","aad0fd86":"code","608522d3":"code","f41c93ae":"code","c1799a12":"code","4737c1e7":"code","23c5ea3f":"code","aa1423c9":"code","f61475ea":"code","4b1dea7b":"code","d574fbf0":"code","b48c3c22":"code","ecb95c7d":"code","3eed1ec7":"code","44ea29c3":"code","91870ee5":"code","dc60a49e":"code","9a92fb79":"code","6d44e6f0":"code","61d42427":"code","c1bb95f5":"code","f723f0e3":"code","3ff362dc":"code","e93e3d2b":"code","a4f342fa":"code","2245110c":"markdown","559c3f84":"markdown","4f42213b":"markdown","5da77742":"markdown","e51cfd0c":"markdown","32820fcc":"markdown","48939e7c":"markdown","84412da5":"markdown","84af6f73":"markdown","d2b4a5e3":"markdown","d628a63c":"markdown","489b54af":"markdown","fc5c9701":"markdown","1ffa33cf":"markdown","ac01891c":"markdown","cc94ec4a":"markdown","888bdd6b":"markdown","bdcd5c23":"markdown","a4e6d6ea":"markdown","e580c4b5":"markdown","6e10057f":"markdown","a14552d5":"markdown"},"source":{"3d7fc762":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9528521c":"import matplotlib.pyplot as plt\nimport seaborn as sns","03dedf81":"%%time\ntrain_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv\")","904f33cf":"# mengatur maksimum kolom yang dapat ditampilkan.\npd.set_option(\"display.max_columns\", 103)","f46921d1":"train_df.shape","1fa9f6cf":"train_df.info()","76b4abfe":"%%time\ntrain_df.describe()","9cd29bc4":"%%time\ntrain_df['target'].value_counts()","ace7c038":"train_df['target'].value_counts().plot(kind='pie', autopct='%.1f')","c6b87c22":"# import vaex","6f04ebe0":"# %%time\n# train_vdf = vaex.open(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv\")","ef6704e9":"# train_vdf.info(description=False)","27c32173":"# %%time\n# train_vdf.describe()","aad0fd86":"# %%time\n# train_vdf.target.value_counts()","608522d3":"# %%time\n# train_vdf.f1.countmissing()","f41c93ae":"sns.displot(data=train_df, x=\"f0\", hue=\"target\", kind=\"kde\", fill=True)","c1799a12":"cols = [c for c in train_df.columns if 'f' in c]","4737c1e7":"plt.figure(figsize=(20, 15))\nfor i, feature in enumerate(cols[:16]):\n    plt.subplot(4, 4, i+1)\n    sns.kdeplot(data=train_df, x=feature, hue=\"target\", fill=True)","23c5ea3f":"plt.figure(figsize=(20, 15))\nfor i, feature in enumerate(cols[16:32]):\n    plt.subplot(4, 4, i+1)\n    sns.kdeplot(data=train_df, x=feature, hue=\"target\", fill=True)","aa1423c9":"plt.figure(figsize=(20, 15))\nfor i, feature in enumerate(cols[32:48]):\n    plt.subplot(4, 4, i+1)\n    sns.kdeplot(data=train_df, x=feature, hue=\"target\", fill=True)","f61475ea":"plt.figure(figsize=(20, 15))\nfor i, feature in enumerate(cols[48:64]):\n    plt.subplot(4, 4, i+1)\n    sns.kdeplot(data=train_df, x=feature, hue=\"target\", fill=True)","4b1dea7b":"plt.figure(figsize=(20, 15))\nfor i, feature in enumerate(cols[64:80]):\n    plt.subplot(4, 4, i+1)\n    sns.kdeplot(data=train_df, x=feature, hue=\"target\", fill=True)","d574fbf0":"plt.figure(figsize=(20, 15))\nfor i, feature in enumerate(cols[80:96]):\n    plt.subplot(4, 4, i+1)\n    sns.kdeplot(data=train_df, x=feature, hue=\"target\", fill=True)","b48c3c22":"plt.figure(figsize=(12, 8))\nfor i, feature in enumerate(cols[96:100]):\n    plt.subplot(2, 2, i+1)\n    sns.kdeplot(data=train_df, x=feature, hue=\"target\", fill=True)","ecb95c7d":"%%time\ntrain_df.isnull().sum().sort_values(ascending=False)","3eed1ec7":"# cek duplikasi baris\ntrain_df.drop(columns=['id']).duplicated().sum()","44ea29c3":"def get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=10):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\ndf = train_df\nprint(\"Top Absolute Correlations\")\nprint(get_top_abs_correlations(df, 10))","91870ee5":"# from sklearn.model_selection import train_test_split","dc60a49e":"# X = train_df.drop(columns=['id', 'target'])\n# y = train_df['target']","9a92fb79":"# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=101)","6d44e6f0":"# install FLAML\n!pip install FLAML[notebook] -q","61d42427":"# from flaml import AutoML\n# automl =  AutoML()","c1bb95f5":"import pickle\n\nmodel = pickle.load(open(\"..\/input\/automl1-lgbm\/automl1_lgbm.pkl\", \"rb\"))","f723f0e3":"test_df = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")","3ff362dc":"sample_submission","e93e3d2b":"test_df","a4f342fa":"predictions_proba = model.predict_proba(test_df.drop(columns=['id']))[:, 1]\n\noutput = pd.DataFrame({'id': test_df['id'], 'target': predictions_proba})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","2245110c":"Proporsi jumlah label target **1** dan **0** terlihat seimbang. label **1** sekitar 50.6% dan label **0** sekitar 49.4% dari seluruh baris(?).","559c3f84":"Model didapatkan dari proses training dan *model selection* menggunakan FLAML pada platform [Deepnote](https:\/\/deepnote.com\/project\/AutoML-with-FLAML-_u3I3ayRRPWBj4XF8V4iOA\/%2Fnotebook.ipynb).","4f42213b":"#### Mencoba menggunakan Vaex daripada Pandas  \ntentang [Vaex](https:\/\/vaex.io\/docs\/index.html)","5da77742":"Terjadi *error* dikarenakan perbedaan versi scikit-learn dengan *dependencies package*nya. Namun tetap digunakan untuk memuat model hasil FLAML (dikerjakan di luar Kaggle notebook).","e51cfd0c":"Melihat distribusi dari kolom `target`, apakah label yang kita miliki *balance* atau *imbalance*?","32820fcc":"## Memuat Dataset test.csv dan sample_submission.csv","48939e7c":"## Memuat Dataset (train) ","84412da5":"Kesimpulan awal dari *summary statistics*:  \n1. Kemungkinan terdapat *outlier*, akan diamati lebih dengan visualisasi data.\n2. Apakah akan diperlukan *normalization* atau *standarization*, kita melihat terdapat kolom yang memiliki rentang nilai berbeda misalkan beberapa kolom memiliki nilai maksimum \/ minimum ratusan (*hundreds*) bahkan ribuan (*thousands*) dengan sebagian besar pada satuan (*ones*).","84af6f73":"Rencana *splitting* dataset:\n1. train test split 90:10\n2. 10-fold cross vallidation","d2b4a5e3":"Di dalam dataset **train** kita memiliki 600000 baris dengan jumlah kolom total 102; 100 kolom fitur, 1 kolom `id` , dan 1 kolom `target`.  \n\nDilanjutkan dengan melihat *summary statistics* dari dataset.","d628a63c":"Baik korelasi antar fitur ataupun dengan target, memiliki korelasi yang lemah.","489b54af":"[List Highest Correlation Pairs from a Large Correlation Matrix in Pandas?](https:\/\/stackoverflow.com\/questions\/17778394\/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas)","fc5c9701":"---","1ffa33cf":"Dalam membuat *multiple subplots* untuk plot dari *library* `seaborn` perhatikan level dari *function* yang digunakan. Contoh `seaborn.displot()` merupakan *figure-level*, sedangkan untuk *axes-level* dapat berupa `seaborn.histplot()` atau `seaborn.kdeplot()`.  \n\n[seaborn is not plotting within defined subplots](https:\/\/stackoverflow.com\/questions\/63895392\/seaborn-is-not-plotting-within-defined-subplots)","ac01891c":"Tidak terdapat *missing values* dan duplikasi.","cc94ec4a":"---","888bdd6b":"## Exploratory Data Analysis  - EDA","bdcd5c23":"---","a4e6d6ea":"Kesimpulan dari visualisasi distribusi:\n* **dalam diskusi**:\n- Keberadaan outlier\n- Bimodality (Multimodal Distribution)\n- Langkah selanjutnya","e580c4b5":"Mari kita lihat distribusi untuk setiap kolom fitur.","6e10057f":"Gunakan Pandas, untuk *single machine* di sini masih memiliki performa yang baik.","a14552d5":"Gunakan [FLAML](https:\/\/github.com\/microsoft\/FLAML) untuk *hyperparameter tuning* dan menggunakan [LightGBM](https:\/\/lightgbm.readthedocs.io\/en\/latest\/index.html) untuk *training* model."}}