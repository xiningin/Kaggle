{"cell_type":{"7cee6a3a":"code","7f9d06b4":"code","2d3f4041":"code","1b1a80cf":"code","e7e6a32b":"code","e239e93c":"code","57a619f0":"code","665c9f5f":"code","1c8403b9":"code","e200dd66":"code","9562a9c3":"code","423130f6":"code","8fe2e124":"code","e15dd791":"code","d9bc273d":"code","ec1d5026":"code","ce56820b":"code","a0f53994":"markdown","fffca828":"markdown","f0692a61":"markdown","ab2f49c6":"markdown","a1316bf3":"markdown","7a698a4c":"markdown","7e06bbd6":"markdown","7f7c9b2b":"markdown","dc0fb622":"markdown","c3717aa7":"markdown"},"source":{"7cee6a3a":"# Usually Tensorflow is Installed on Kaggle, or else type this to install\n\n#!pip install -U tensorflow==2.0","7f9d06b4":"# importing tensorflow libraries\n\nimport tensorflow as tf    ","2d3f4041":"# Printing Version of Tensorflow\n\nprint(tf.__version__)","1b1a80cf":"hello = tf.constant(\"Hello TensorFlow !!\")  \nprint(hello.numpy())                ","e7e6a32b":"# creating nodes in computation graph \nnode1 = tf.constant(3, dtype=tf.int32)   # creates a data node \nnode2 = tf.constant(5, dtype=tf.int32)   # creates a data node\nnode3 = tf.add(node1, node2)             # creates a function node\n\n\n# evaluating node3 and printing the result \nprint(\"Sum of node1 and node2 is:\",node3.numpy()) \n","e239e93c":"A  = tf.Variable(initial_value = ([[0,1,2,3],[5,6,7,8]]), shape=(2,4) , dtype = 'int32', name = 'A' )\nprint(A.numpy())\nprint(A.shape)\nprint(tf.rank(A))","57a619f0":"b = tf.Variable([[1],[2],[3],[4]])\nprint(b.shape)\nprint(tf.rank(b))","665c9f5f":"C = tf.Variable([[1,2],[3,4]])\nprint(C.shape)\nprint(tf.rank(C))\nprint(C)","1c8403b9":"D = tf.constant(50, shape=[6,2])\nprint(\"rank of D :\", tf.rank(D))\nprint(\"shape of D :\" , D.shape)\nprint(\"content of D :\",  D)","e200dd66":"tf_t = tf.convert_to_tensor(5.0, dtype=tf.float64)   #converting a scalar value (5.0) into a tensor of rank 0 ","9562a9c3":"print(tf.rank(tf_t))\nprint(tf.shape(tf_t))   # pl. note, the number after Rank_ and Shape_ are internal indices. \n\nprint(tf.rank(tf_t))    #Note: if we do not use tfs.run(), the tf.rank will only describe the node\nprint(tf.shape(tf_t) )  # pl. note, the number after Rank_ and Shape_ are internal indices. ","423130f6":"import numpy as np\n\none_dim_array = ([1], [2], [3], [4], [5])\nprint(\"one_dim_array Shape : \", one_dim_array)\n\ntf_t = tf.convert_to_tensor(one_dim_array, dtype=tf.float64)\nprint('\\n')\nprint(tf_t)\nprint('rank of tf_t : ', tf.rank(tf_t))     #Note: if we do not use tfs.run(), the tf.rank will only describe the node\nprint('shape of tf_t: ', tf.shape(tf_t))\nprint('\\n')\nprint('tf_t[0] : ', tf_t[0])\nprint('tf_t[0] : ', tf_t[2])\nprint('\\n')\nprint('run(tf_t) : \\n', tf_t)","8fe2e124":"# Assume Linear Model y = w * x + b\n# Define model parameters\nw = tf.Variable([.3], tf.float32)\nb = tf.Variable([-.3], tf.float32)\n\n\n# Define model input and output\nx = tf.Variable([5.0],tf.float32)\ny = w * x + b\n\nprint(\"w:\", w)\nprint(\"x:\", x)\nprint(\"b:\", b)\nprint(\"y:\", y)\n\n","e15dd791":"train_X = [3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 9.779, 6.182, 7.59, 2.167,\n           7.042, 10.791, 5.313, 7.997, 5.654, 9.27, 3.1]\ntrain_Y = [1.7, 2.76, 2.09, 3.19, 1.694, 1.573, 3.366, 2.596, 2.53, 1.221,\n           2.827, 3.465, 1.65, 2.904, 2.42, 2.94, 1.3]\nNUM_EXAMPLES = len(train_X)\n\n\n#create model paramters with initial values \nW = tf.Variable(0.)\nb = tf.Variable(0.)\n\n#training info\ntrain_steps = 100\nlearning_rate = 0.01\n\nfor i in range(train_steps):\n  \n  #watch the gradient flow \n  with tf.GradientTape() as tape:\n    \n    #forward pass \n    yhat = train_X * W + b\n    \n    #calcuate the loss (difference squared error)\n    error = yhat - train_Y\n    loss = tf.reduce_mean(tf.square(error))\n  \n  #evalute the gradient with the respect to the paramters\n  dW, db = tape.gradient(loss, [W, b])\n\n  #update the paramters using Gradient Descent  \n  W.assign_sub(dW * learning_rate)\n  b.assign_sub(db* learning_rate)\n\n  #print the loss every 20 iterations \n  if i % 20 == 0:\n    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss))\n      \nprint(f'W : {W.numpy()} , b  = {b.numpy()} ')","d9bc273d":"%matplotlib inline\nimport matplotlib.pyplot as plt\n# Graphic display\nplt.plot(train_X, train_Y, 'ro', label='Original data')\nplt.plot(train_X, np.array(W * train_X + b), label='Fitted line')\nplt.legend()\nplt.show()","ec1d5026":"def linear_model(X_val):\n  print((W*X_val + b).numpy())","ce56820b":"linear_model(8)","a0f53994":"# Define tensorflow variables ","fffca828":"[Click Here to know more](https:\/\/www.tensorflow.org\/)","f0692a61":"Turn on GPU of Kaggle before starting","ab2f49c6":"# Creating tensors from Existing Objects","a1316bf3":"# Creating tensors from an array","7a698a4c":"# Linear model in tensorflow","7e06bbd6":" # Creating tensors through operations\n> Tensors are a type of data structure used in linear algebra, and like vectors and matrices, you can calculate arithmetic operations with tensors. After completing this tutorial, you will know: That tensors are a generalization of matrices and are represented using n-dimensional arrays.","7f7c9b2b":"# Creating tensors through constants\n> A constant has the following arguments which can be tweaked as required to get the desired function. \n> value : A constant value (or list) of output type dtype . \n> dtype : The type of the elements of the resulting tensor. \n> shape : Optional dimensions of resulting tensor","dc0fb622":"![](https:\/\/www.tensorflow.org\/images\/tf_logo_social.png)","c3717aa7":"Ignore Warning "}}