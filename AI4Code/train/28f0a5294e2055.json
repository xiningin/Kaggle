{"cell_type":{"81fb4262":"code","f0d692e1":"code","24f6c19b":"code","cad3581e":"code","968265d3":"code","d39c969a":"code","aad9e5d6":"code","194828fc":"code","b96b9c4a":"code","daa04ad2":"code","50e4a063":"code","b0fca5fd":"code","dcc1d766":"code","fb568b73":"code","bb55fdc4":"code","1827f370":"code","fc4cda35":"code","b6a4ab89":"code","d9877572":"code","04ff8726":"code","140add20":"code","e8462dc2":"code","b634f328":"code","be97fe1b":"code","0e326924":"code","6d1aad6e":"code","d1213658":"code","89d3a70a":"code","b0d9444e":"code","ba1b5741":"code","29f46f8e":"code","50d1da30":"code","15e13c9b":"code","adf76072":"code","b753ce63":"code","f2b2d314":"code","53d7473e":"code","6ad0b576":"code","ef760e4c":"code","54bd72af":"markdown","c35d9e65":"markdown","828963e4":"markdown","4b165338":"markdown","3b7e9251":"markdown","0e9e813c":"markdown","baba0c1b":"markdown","572a8c1b":"markdown","e09f583b":"markdown","b8c04a63":"markdown","d138ac2d":"markdown","11f84de5":"markdown","bdab8744":"markdown","ff69da77":"markdown","2cc3670d":"markdown","e2afa4ae":"markdown","30decd2e":"markdown","0aa9a10c":"markdown","cbd2e38f":"markdown","0bcf6600":"markdown","9f0cf5ad":"markdown","f8c96fab":"markdown","f9aa04e1":"markdown"},"source":{"81fb4262":"import tensorflow as tf\nimport pandas_profiling \nimport datetime as dt\nimport pandas as pd\nimport numpy as np\nimport graphviz\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow import keras\nfrom sklearn import tree\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\n%matplotlib inline","f0d692e1":"df = pd.read_csv('..\/input\/lsvt-voice-rehabilation-dataset\/data.csv')","24f6c19b":"df['Class']","cad3581e":"df.head()","968265d3":"#plt.figure(figsize=(7,5))\ncor = df.corr()\ncor\n#heat_map = sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n#plt.show()","d39c969a":"cor_target = abs(cor[\"Class\"])","aad9e5d6":"relevant_features = cor_target[cor_target>0.48]\nrelevant_features","194828fc":"data = [df['V80'],df['V82'],df['V84'],df['V85'],df['V86'],df['V153'],df['Class']]","b96b9c4a":"head = ['V80','V82','V84','V85','V86','V153','Class']","daa04ad2":"new_df = pd.concat(data,axis=1,keys=head)","50e4a063":"new_df.head()","b0fca5fd":"new_df.describe","dcc1d766":"new_df.isna().sum() #no missing values","fb568b73":"new_df.info()","bb55fdc4":"plt.figure(figsize=(18,9))\nnew_df[['V80','V82','V84','V85','V86','V153','Class']].boxplot()\nplt.title(\"Numerical variables in Our Dataset\", fontsize=20)\nplt.show()","1827f370":"new_df.head()","fc4cda35":"new_df['V86'] = (new_df['V86']- new_df['V86'].min())\/(new_df['V86'].max() - new_df['V86'].min())","b6a4ab89":"new_df['V85'] = (new_df['V85']- new_df['V85'].min())\/(new_df['V85'].max() - new_df['V85'].min())","d9877572":"new_df['V84'] = (new_df['V84']- new_df['V84'].min())\/(new_df['V84'].max() - new_df['V84'].min())","04ff8726":"new_df['V82'] = (new_df['V82']- new_df['V82'].min())\/(new_df['V82'].max() - new_df['V82'].min())","140add20":"new_df['V80'] = (new_df['V80']- new_df['V80'].min())\/(new_df['V80'].max() - new_df['V80'].min())","e8462dc2":"new_df['V153'] = (new_df['V153']- new_df['V153'].min())\/(new_df['V153'].max() - new_df['V153'].min())","b634f328":"new_df['Class'] = new_df['Class'].factorize()[0]","be97fe1b":"new_df","0e326924":"plt.figure(figsize=(18,9))\nnew_df[['V80','V82','V84','V85','V86','V153','Class']].boxplot()\nplt.title(\"Numerical variables in Our Dataset\", fontsize=20)\nplt.show()","6d1aad6e":"start_time = dt.datetime.now()\nprint(\"Started at \", start_time)\nreport = pandas_profiling.ProfileReport(new_df)\nreport","d1213658":"X= new_df.drop(['Class'],axis=1)","89d3a70a":"y = new_df['Class']","b0d9444e":"model_params = {\n    'svm': {\n        'model': svm.SVC(gamma='auto'),\n        'params' : {\n            'C': [1,5,20],\n            'kernel': ['rbf','linear'],\n        }  \n    },\n    'random_forest': {\n        'model': RandomForestClassifier(),\n        'params' : {\n            'max_depth':[1,5,9],\n            'n_estimators': [1,5,20,100],\n        }\n    },\n    'logistic_regression' : {\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params': {\n            'C': [1,2,5,10,15]\n        }\n    }\n}\n","ba1b5741":"scores = []\n\nfor model_name, mp in model_params.items():\n    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n    clf.fit(X, y)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_,\n    })\n    \ndf = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf","29f46f8e":"scores = cross_val_score(RandomForestClassifier(max_depth=9,n_estimators=100),X, y,cv=5)\nprint(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))","50d1da30":"scores = cross_val_score(LogisticRegression(solver='liblinear',multi_class='auto',C=1),X, y,cv=5)\nprint(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))","15e13c9b":"scores = cross_val_score(svm.SVC(gamma='auto',kernel='linear',C=20),X, y,cv=5)\nprint(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))","adf76072":"x_train,x_test,y_train,y_test=train_test_split( X, y, test_size=0.3, random_state=42)","b753ce63":"model = RandomForestClassifier(max_depth=9,n_estimators=100)","f2b2d314":"model.fit(x_train,y_train)","53d7473e":"y_pred = model.predict(x_test)","6ad0b576":"accuracy_score(y_test, y_pred)*100","ef760e4c":"cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\nimport seaborn as sns\nplt.figure(figsize =(5,4))\nsns.heatmap(cm,annot=True,fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","54bd72af":"### SVM performance using cross_val_score","c35d9e65":"# Model Training(as it is a classification problem) :- <br>\n### 1.) Using Random forest classifier <br>\n### 2.) Using Logistic Regression<br>\n### 3.) Using SVM <br>","828963e4":"### Create a new dataframe from the selected features","4b165338":"## Using pandas profiling :-\n**Pandas profiling can be used for expolration data analysis, It plot correlation matrix, gives you the valuable information about the feature and all**<br>\n**For more info read this blog :- https:\/\/towardsdatascience.com\/exploratory-data-analysis-with-pandas-profiling-de3aae2ddff3**","3b7e9251":"**Our label is our target class ie 'Class'.**","0e9e813c":"### Lets import our dataset data.csv\n**Link:-** <a>https:\/\/www.openml.org\/d\/1484 <\/a><br>\n**I have used dataset from openml because is has a classification column so that we can train and test our model, The testing on this dataset will also work for the original raw dataset from UCI Machine Learning LSVT dataset.**<br>","baba0c1b":"### Lets Start with importing our neccessary libraries\n**That includes:**:-<br>\n    *1.) Tensorflow*<br>\n    *2.) Pandas*<br>\n    *3.) Numpy*<br>\n    *4.) Matplotlib*<br>\n    *5.) Seaborn*<br>\n    *6.) Svm classifier*<br>\n    *7.) Decision tree cassifier*<br> \n    *8.) Random Forest classifier.*<br>\n    *9.) Pandas profiling*<br>\n    etc","572a8c1b":"### Random Forest model performance using cross_val_score :-","e09f583b":"### The Relevant Features of our Target colums are:-\n**V80**<br>\n**V82**<br>\n**V84**<br>\n**V85**<br>\n**V86**<br>\n**V153**<br>\n***Note :- The feature Class is itself only thats why correlation is 1.***<br>","b8c04a63":"## Lets see the box plot after Normalization :-\n**Now the Values are Betweeen 0 and 1.**","d138ac2d":"#### Create a Correlation matrix with our target feature to see on which feature our target feature is dependent","11f84de5":"**I am here performing min-max Normalization**<br>\n**For more info:- <a>https:\/\/www.geeksforgeeks.org\/ml-feature-scaling-part-2\/<\/a>**","bdab8744":"**As it is clearly visivle that Random Forest is best classifier for our prediction**","ff69da77":"### Lets plot a box plot to see how the values in our dataset is distributed<br>\n**As we can see the values are not evenly distributed some have very large number of negative values like v153 where as some has values between 0 and 1. So we need to scale them up so that we can train our model efficiently**","2cc3670d":"#### Lets looks at our Target feature","e2afa4ae":"# LSVT Voice Rehabilitation\n**Abstract: 126 samples from 14 participants, 309 features. Aim: assess whether voice rehabilitation treatment lead to phonations considered 'acceptable' or 'unacceptable' (binary class classification problem).**<br>\n**Original dataset :- https:\/\/archive.ics.uci.edu\/ml\/datasets\/LSVT+Voice+Rehabilitation**<br>","30decd2e":"### Logistic Regression model performance using cross_val_score :-","0aa9a10c":"**There are no missing value in our dataset**","cbd2e38f":"## The Optimal Parameters are(I have used gridsearcv as datset has only 126 instances if dataset is large one can use randomizedsearchcv):-","0bcf6600":"## Hyperparameter Tuning (hpt is done to get the optimal parameters so that our model can work efficiently as in sklearn you have so many parameter so it become difficult to get the optimal parameter below code can also be used as a template for hpt):-","9f0cf5ad":"**Now lets extract our feature which are :- 'V80', 'V82', 'V84', 'V85', 'V86', 'V153'.**","f8c96fab":"**For our Target class we need to make it in binary form ie in term of 0 and 1. 0 for false and 1 for true.**","f9aa04e1":"# Conclusion:-\n**Random Forest Classifier is the best fitted classifier for our prediction.It has cross_val_score greater than svm and logistic regression.<br>On training and testing on our dataset, Our model gave a accuracy of greater than 90%.**<br>\n#### Key learning :-\n**Learnt about confusion matrix,classifiers,feature extraction techniques,how to process raw data,feature scaling,how to make model with better accuracy using data preprocessing and pandas profiling.**"}}