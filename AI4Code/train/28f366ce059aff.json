{"cell_type":{"2e9354db":"code","eedd4bb3":"code","4b3a7d58":"code","4fcf2e1a":"code","f72f2456":"code","12ffca79":"code","52150c8c":"code","abd66049":"code","11bae585":"code","026a9c37":"code","a8445f7b":"code","e52d0a57":"code","1d8fb325":"code","7566a4f6":"code","1e623c5d":"code","30a2aed8":"code","f06ef523":"code","58b467ca":"code","8488930e":"code","537fec08":"code","97eea638":"code","4b8d58c6":"code","caea8a2d":"code","9b0b386c":"code","1d048e57":"code","137c00b3":"code","e5726c46":"code","015e24cd":"code","3f62dbad":"code","736fff73":"code","2e51db82":"code","9e5e78f6":"code","718ccbe8":"code","dfe54b2f":"code","e3a93bae":"code","de379b04":"code","7072c1a5":"code","7d039b80":"code","3799be7c":"code","79177f90":"code","e9a9556a":"code","f62f6f48":"code","7c1711c5":"code","e3eaa704":"code","88e46ff8":"code","c27880a5":"code","1f997f8b":"code","c8a65ad8":"code","a29e5824":"code","9012b2ce":"code","57d34a7a":"code","ed99abdf":"code","c0585e30":"code","2a3a0533":"code","8e40c86c":"code","f406ce10":"code","f1c53827":"code","1a50af59":"code","ac42942a":"code","bdb9ac73":"code","baae9dcb":"code","224e4cc9":"code","ef4cf0e2":"code","b3ae70d7":"code","161ee634":"code","cb39f4a4":"code","3d07ece8":"code","357f4c63":"code","7fa81135":"code","3be9935b":"code","61b6cbf1":"code","d43d8051":"code","acdd82a8":"code","87f891b6":"code","b220762e":"code","aa1b7aea":"code","743a9dad":"code","3e274d1f":"markdown","5bf20ea9":"markdown","ca4fec1c":"markdown","be73554c":"markdown","0de738a5":"markdown","40e94ede":"markdown","81d63e18":"markdown","7308bac2":"markdown","0bbdeced":"markdown","84e37997":"markdown","3276a552":"markdown","2279df45":"markdown","acef1927":"markdown","1d0301ac":"markdown","b327b79b":"markdown","5b2001d7":"markdown","211f1b43":"markdown"},"source":{"2e9354db":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.efficientnet  import EfficientNetB4 \n\n%matplotlib inline\ntf.__version__","eedd4bb3":"train_datagen= tf.keras.preprocessing.image.ImageDataGenerator(\n    # DEFAULT PARAMS \n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    brightness_range=None,\n    shear_range=0.0,\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=False,\n    vertical_flip=False,\n    rescale=None,\n    data_format=None,\n    dtype=None,\n\n    # PARAMS TO EXPLORE\n    validation_split=0.3,\n    zoom_range=0.0,\n    preprocessing_function=None\n)","4b3a7d58":"train_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","4fcf2e1a":"train_ds.class_indices","f72f2456":"X, y = next(train_ds)","12ffca79":"(X[:5]).shape","52150c8c":"import os\nimport random\nfrom tensorflow.keras.preprocessing.image import load_img","abd66049":"dataset_dir = r\"C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset\"\nall_classes = os.listdir(dataset_dir)\n\ndataset_num_ofall_classes = {}\nfor XX in range(len(all_classes)): \n    dataset_num_ofall_classes[all_classes[XX]] = len(os.listdir(dataset_dir+ \"\\\\\"+ all_classes[XX]))","11bae585":"dataset_num_ofall_classes","026a9c37":"plt.figure(figsize=(12, 5))\nplt.bar(dataset_num_ofall_classes.keys(), dataset_num_ofall_classes.values(), width= .7)\n\n#As we can see rainbow and lightning are significantly lower than the other classes, \n#   fortunately, image of these 2 classes can be find easily on the itnernet.. \n#   I will add around 400 images for rainbow, and 300 images for ligtning\n#   i will also downsample ","a8445f7b":"### LOAD DATASET \nload_added_img_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\Add',\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data","e52d0a57":"add_classes = load_added_img_ds.class_indices\nadd_classes","1d8fb325":"add_dir = r\"C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\Add\"","7566a4f6":"# Only added 50 and 100 to class `lightning` and `rainbow` \nfig, axs = plt.subplots (nrows = 4, ncols = 4, figsize=(16,24))\n\nclass_num = 0 \nfor XX, ax in enumerate(fig.axes): #32\n    class_num = ( 1 if class_num==1 else 0 ) #set a condition so it wont go bigger than class size\n    random_img = random.choice(os.listdir(add_dir+ \"\\\\\"+ list(add_classes)[class_num]))\n    random_img_path = os.path.join(add_dir+ \"\\\\\" + list(add_classes)[class_num] + \"\\\\\" + random_img)\n    ax.imshow(plt.imread(random_img_path))\n    ax.set_title(list(add_classes)[class_num])\n    class_num+=1","1e623c5d":"random_img = random.choice(os.listdir(dataset_dir+ \"\\\\\"+ all_classes[0]))\nrandom_img_path = os.path.join(dataset_dir+ \"\\\\\" + all_classes[0] + \"\\\\\" + random_img)\nload_img(random_img_path, target_size=(128,128))","30a2aed8":"all_classes","f06ef523":"fig, axs = plt.subplots (nrows = 8, ncols = 4, figsize=(16,24))\n\nclass_num = 0 \nfor XX, ax in enumerate(fig.axes): #32\n    class_num = ( 0 if class_num>7 else class_num ) #set a condition so it wont go bigger than class size\n    random_img = random.choice(os.listdir(dataset_dir+ \"\\\\\"+ all_classes[class_num]))\n    random_img_path = os.path.join(dataset_dir+ \"\\\\\" + all_classes[class_num] + \"\\\\\" + random_img)\n    ax.imshow(plt.imread(random_img_path))\n    ax.set_title(all_classes[class_num])\n    class_num+=1","58b467ca":"from tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.xception import preprocess_input\nfrom tensorflow.keras.applications.xception import decode_predictions","8488930e":"### LOAD DATASET \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","537fec08":"### Build model \nbase_model = Xception(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(150, 150, 3)\n)\n\nbase_model.trainable = False\ninputs = keras.Input(shape=(150, 150, 3))\nbase = base_model(inputs, training=False)\nvectors = keras.layers.GlobalAveragePooling2D()(base)\noutputs = keras.layers.Dense(8,  activation='softmax')(vectors)\nmodel = keras.Model(inputs, outputs)","97eea638":"### Compile model \noptimizer = keras.optimizers.Adam()\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(optimizer = optimizer, loss = loss, metrics=['accuracy'])","4b8d58c6":"### Train and fit the model \nhistory = model.fit(train_ds, epochs=10, validation_data=val_ds)","caea8a2d":"### Plot model performance \nplt.plot(history.history['val_accuracy'], label=('val'))\nplt.plot(history.history['accuracy'], label=('acc'))\nplt.legend()\nplt.title('Training acc vs Validation acc')\n\n#This model seems good, the train accuracy is quite near to validation accuracy. ","9b0b386c":"### ADD MORE LAYERS to the model \nbase_model = Xception(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(150, 150, 3)\n)\n\nbase_model.trainable = False\ninputs = keras.Input(shape=(150, 150, 3))\nbase = base_model(inputs, training=False)\nvectors = keras.layers.GlobalAveragePooling2D()(base)\ninner = keras.layers.Dense(500, activation='relu')(vectors)\ninner2 = keras.layers.Dense(250, activation='relu')(inner)\noutputs = keras.layers.Dense(8,  activation='softmax')(inner2)\nmodel = keras.Model(inputs, outputs)","1d048e57":"### Compile the model \noptimizer = keras.optimizers.Adam()\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(optimizer = optimizer, loss = loss, metrics=['accuracy'])","137c00b3":"### Train and fit the model \nhistory = model.fit(train_ds, epochs=10, validation_data=val_ds)\n#We can see obvious overfitting from Epoch 8 onwards ","e5726c46":"### PLOT the model performance \nplt.plot(history.history['val_accuracy'], label=('val'))\nplt.plot(history.history['accuracy'], label=('acc'))\nplt.legend()\nplt.title('Training acc vs Validation acc')","015e24cd":"### IMPORT MODULE\nfrom tensorflow.keras.applications.vgg16 import VGG16","3f62dbad":"### LOAD DATA \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","736fff73":"### BUILD and COMPILE MODEL\nbase_model= VGG16(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n\n##################################################\ninputs = keras.Input(shape=(224, 224, 3))   \nbase = base_model(inputs, training= False)\nvectors = keras.layers.GlobalAveragePooling2D()(base)\ninner = keras.layers.Dense(100, activation= 'relu')(vectors) \noutputs = keras.layers.Dense(8, activation='softmax')(inner) \nmodel = keras.Model(inputs, outputs)\n##################################################\n\noptimizer = keras.optimizers.Adam()\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(\n    optimizer=optimizer, \n    loss = loss, \n    metrics=['accuracy']\n)","2e51db82":"history = model.fit(train_ds, epochs=10, validation_data = val_ds)","9e5e78f6":"### PLOT THE MODEL EVALUATION \nplt.plot(history.history['accuracy'], label='Train acc')\nplt.plot(history.history['val_accuracy'], label='Val acc')\nplt.legend()\nplt.title('Train accuracy vs Val accuracy')\n\n# This model outperformed previous model, though there's overfitting issue. ","718ccbe8":"### IMPORT MODULE\nfrom tensorflow.keras.applications.efficientnet  import EfficientNetB4 ","dfe54b2f":"### LOAD DATA \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","e3a93bae":"### BUILD AND COMPILE MODEL \nbase_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n\n##################################################\ninputs = keras.Input(shape=(224, 224, 3))   \nbase = base_model(inputs, training= False)\nvectors = keras.layers.GlobalAveragePooling2D()(base)\ninner = keras.layers.Dense(100, activation= 'relu')(vectors) \noutputs = keras.layers.Dense(8, activation='softmax')(inner) \nmodel = keras.Model(inputs, outputs)\n##################################################\n\noptimizer = keras.optimizers.Adam()\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(\n    optimizer=optimizer, \n    loss = loss, \n    metrics=['accuracy']\n)","de379b04":"model.summary()","7072c1a5":"history = model.fit(train_ds, epochs=10, validation_data = val_ds)","7d039b80":"### PLOT THE MODEL EVALUATION \nplt.plot(history.history['accuracy'], label='Train acc')\nplt.plot(history.history['val_accuracy'], label='Val acc')\nplt.legend()\nplt.title('Train accuracy vs Val accuracy')\n\n#This model performed really well but it clrealy overfits! ","3799be7c":"### IMPORT MODULE\nfrom tensorflow.keras.applications  import InceptionResNetV2 ","79177f90":"### LOAD DATA \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","e9a9556a":"### BUILD AND COMPILE MODEL \nbase_model= InceptionResNetV2(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n\n##################################################\ninputs = keras.Input(shape=(224, 224, 3))   \nbase = base_model(inputs, training= False)\nvectors = keras.layers.GlobalAveragePooling2D()(base)\ninner = keras.layers.Dense(100, activation= 'relu')(vectors) \noutputs = keras.layers.Dense(8, activation='softmax')(inner) \nmodel = keras.Model(inputs, outputs)\n##################################################\n\noptimizer = keras.optimizers.Adam()\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(\n    optimizer=optimizer, \n    loss = loss, \n    metrics=['accuracy']\n)","f62f6f48":"history = model.fit(train_ds, epochs=10, validation_data = val_ds)","7c1711c5":"### PLOT THE MODEL EVALUATION \nplt.plot(history.history['accuracy'], label='Train acc')\nplt.plot(history.history['val_accuracy'], label='Val acc')\nplt.legend()\nplt.title('Train accuracy vs Val accuracy')\n\n#Seems like the model is not configured properly, the accuracy is exceptionally low..","e3eaa704":"### LOAD DATA \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","88e46ff8":"def make_model(learning_rate = 0) :\n    base_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n    ##################################################\n    inputs = keras.Input(shape=(224, 224, 3))   \n    base = base_model(inputs, training= False)\n    vectors = keras.layers.GlobalAveragePooling2D()(base)\n    inner = keras.layers.Dense(100, activation= 'relu')(vectors) \n    outputs = keras.layers.Dense(8, activation='softmax')(inner) \n    model = keras.Model(inputs, outputs)\n    ##################################################\n    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n    loss = keras.losses.CategoricalCrossentropy()\n    model.compile(\n        optimizer=optimizer, \n        loss = loss, \n        metrics=['accuracy']\n    )\n    \n    return model ","c27880a5":"scores = {}\n\nfor lr in [0.0001, 0.001, 0.005, 0.01, 0.1]:\n    print(lr)\n    model = make_model(learning_rate=lr)\n    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n    scores[lr] = history.history\n    print()\n    print()","1f997f8b":"fig, axs = plt.subplots(2, figsize=(15,15))\n\nfor lr,hist in scores.items():\n    if (lr!= 0.1): \n        axs[0].plot(hist['accuracy'], label = (f\"val={lr}\"))\n        axs[1].plot(hist['val_accuracy'], label = (f\"val={lr}\"))\n\naxs[0].title.set_text(\"Model Training Accuracy\")\naxs[0].legend()\n#axs[0].set_xticks(np.arange(10)) \naxs[1].title.set_text(\"Model Validation Accuracy\")\naxs[1].legend()\naxs[1].axhline(y=0.88, color='b', linestyle='--')\naxs[1].set_xticks(np.arange(10)) \nplt.ylim(0.8, 1.0)\n\n# 0.001 will be selected since most epochs performed greather than 0.88 ","c8a65ad8":"### LOAD DATA \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","a29e5824":"### ADD MORE LAYERS to the model \nbase_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n##################################################\ninputs = keras.Input(shape=(224, 224, 3))\nbase = base_model(inputs, training=False)\nvectors = keras.layers.GlobalAveragePooling2D()(base)\ninner = keras.layers.Dense(500, activation='relu')(vectors)\ninner2 = keras.layers.Dense(250, activation='relu')(inner)\noutputs = keras.layers.Dense(8,  activation='softmax')(inner2)\nmodel = keras.Model(inputs, outputs)\n##################################################\noptimizer = keras.optimizers.Adam()\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(\n    optimizer=optimizer, \n    loss = loss, \n    metrics=['accuracy']\n)","9012b2ce":"history = model.fit(train_ds, epochs=10, validation_data=val_ds)","57d34a7a":"# Add one layer of drop out 0.2\nbase_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n##################################################\ninputs = keras.Input(shape=(224, 224, 3))   \nbase = base_model(inputs, training= False)\nvectors = keras.layers.GlobalAveragePooling2D()(base)\ninner = keras.layers.Dense(100, activation= 'relu')(vectors) \ndrop = keras.layers.Dropout(0.2)(inner)\noutputs = keras.layers.Dense(8, activation='softmax')(drop) \nmodel = keras.Model(inputs, outputs)\n##################################################\noptimizer = keras.optimizers.Adam(learning_rate=0.001)\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(\n    optimizer=optimizer, \n    loss = loss, \n    metrics=['accuracy']\n)  ","ed99abdf":"history = model.fit(train_ds, epochs=10, validation_data=val_ds)","c0585e30":"plt.plot(history.history['accuracy'], label = \"Train_acc\")\nplt.plot(history.history['val_accuracy'], label = \"Val_acc\")\nplt.legend()","2a3a0533":"# Add two layers of drop out 0.2\nbase_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n##################################################\ninputs = keras.Input(shape=(224, 224, 3))   \nbase = base_model(inputs, training= False)\nvectors = keras.layers.GlobalAveragePooling2D()(base)\ndrop1 = keras.layers.Dropout(0.2)(vectors)\ninner = keras.layers.Dense(100, activation= 'relu')(drop1) \ndrop2 = keras.layers.Dropout(0.2)(inner)\noutputs = keras.layers.Dense(8, activation='softmax')(drop2) \nmodel = keras.Model(inputs, outputs)\n##################################################\noptimizer = keras.optimizers.Adam(learning_rate=0.001)\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(\n    optimizer=optimizer, \n    loss = loss, \n    metrics=['accuracy']\n)  ","8e40c86c":"history = model.fit(train_ds, epochs=10, validation_data=val_ds)","f406ce10":"plt.plot(history.history['accuracy'], label = \"Train_acc\")\nplt.plot(history.history['val_accuracy'], label = \"Val_acc\")\nplt.legend()","f1c53827":"# Tune dropout \ndef make_model(dropout=0.1) :\n    base_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n    ##################################################\n    inputs = keras.Input(shape=(224, 224, 3))   \n    base = base_model(inputs, training= False)\n    vectors = keras.layers.GlobalAveragePooling2D()(base)\n    drop1 = keras.layers.Dropout(dropout)(vectors)\n    inner = keras.layers.Dense(100, activation= 'relu')(drop1) \n    drop2 = keras.layers.Dropout(dropout)(inner)\n    outputs = keras.layers.Dense(8, activation='softmax')(drop2) \n    model = keras.Model(inputs, outputs)\n    ##################################################\n    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n    loss = keras.losses.CategoricalCrossentropy()\n    model.compile(\n        optimizer=optimizer, \n        loss = loss, \n        metrics=['accuracy']\n    ) \n    return model ","1a50af59":"scores = {}\n\nfor do in [0.3,0.5, 0.6]:\n    print(do)\n    model = make_model(dropout=do)\n    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n    scores[do] = history.history\n    print(\"=========================================================\")\n    print()","ac42942a":"fig, axs = plt.subplots(3, figsize=(15,15))\n\nfor lr,hist in scores.items():\n    axs[0].plot(hist['accuracy'], label = (f\"acc={lr}\"))\n    axs[1].plot(hist['val_accuracy'], label = (f\"val={lr}\"))\n    axs[2].plot(hist['accuracy'],label = (f\"acc={lr}\") )\n    axs[2].plot(hist['val_accuracy'], label = (f\"val={lr}\"))\n\naxs[0].title.set_text(\"Dropout tuning- Model Training Accuracy\")\naxs[0].legend()\n#axs[0].set_xticks(np.arange(10)) \naxs[1].title.set_text(\"Dropout tuning- Model Validation Accuracy\")\naxs[1].legend()\naxs[1].axhline(y=0.88, color='b', linestyle='--')\naxs[1].set_xticks(np.arange(10)) \nplt.ylim(0.8, 1.0)\n\naxs[1].title.set_text(\"Dropout tuning- Training and Validation Accuracy\")\naxs[2].legend()\n\n# 0.5 dropout seems good, the model didnt really overfit much in this case, and converged well with val_accuracy","bdb9ac73":"# Adding regularizer to the network! \n# Reference: https:\/\/sthalles.github.io\/keras-regularizer\/ \ndef make_model() :\n    base_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n    base_model.trainable = True\n    # adding regularization\n    regularizer = tf.keras.regularizers.l2(0.1)\n\n    for layer in base_model.layers:\n        for attr in ['kernel_regularizer']:\n            if hasattr(layer, attr):\n                setattr(layer, attr, regularizer)\n    ##################################################\n    inputs = keras.Input(shape=(224, 224, 3))   \n    base = base_model(inputs, training= False)\n    vectors = keras.layers.GlobalAveragePooling2D()(base)\n    inner = keras.layers.Dense(100, activation= 'relu')(vectors) \n    outputs = keras.layers.Dense(8, activation='softmax')(inner) \n    model = keras.Model(inputs, outputs)\n    ##################################################\n    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n    loss = keras.losses.CategoricalCrossentropy()\n    model.compile(\n        optimizer=optimizer, \n        loss = loss, \n        metrics=['accuracy']\n    )\n\n\n    return model ","baae9dcb":"model = make_model()\nhistory = model.fit(train_ds, epochs=10, validation_data=val_ds)","224e4cc9":"### LOAD DATA \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","ef4cf0e2":"# Tune dense layer size  \ndef make_model(size=10) :\n    base_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n    ##################################################\n    inputs = keras.Input(shape=(224, 224, 3))   \n    base = base_model(inputs, training= False)\n    vectors = keras.layers.GlobalAveragePooling2D()(base)\n    drop1 = keras.layers.Dropout(0.5)(vectors)\n    inner = keras.layers.Dense(size, activation= 'relu')(drop1) \n    drop2 = keras.layers.Dropout(0.5)(inner)\n    outputs = keras.layers.Dense(8, activation='softmax')(drop2) \n    model = keras.Model(inputs, outputs)\n    ##################################################\n    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n    loss = keras.losses.CategoricalCrossentropy()\n    model.compile(\n        optimizer=optimizer, \n        loss = loss, \n        metrics=['accuracy']\n    ) \n    return model ","b3ae70d7":"scores = {}\n\nfor size in [50,100, 150, 300, 500]:\n    print(size)\n    model = make_model(size=size)\n    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n    scores[size] = history.history\n    print()\n    print()","161ee634":"fig, axs = plt.subplots(2, figsize=(15,15))\n\nfor lr,hist in scores.items():\n    axs[0].plot(hist['accuracy'], label = (f\"acc={lr}\"))\n    axs[1].plot(hist['val_accuracy'], label = (f\"val={lr}\"))\n\n\naxs[0].title.set_text(\"Tune dense layer size- Training accuracy\")\naxs[0].legend()\naxs[0].set_xticks(np.arange(10)) \n\naxs[1].title.set_text(\"Tune dense layer size-Validation Accuracy\")\naxs[1].legend()\naxs[1].set_xticks(np.arange(10)) \naxs[1].axhline(y=0.895, color='b', linestyle='--')\n# Dense layer size 100 will be used for the final model","cb39f4a4":"train_datagen= tf.keras.preprocessing.image.ImageDataGenerator(\n    # DEFAULT PARAMS \n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False, \n    zca_epsilon=1e-06,\n    brightness_range=None,\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    vertical_flip=False,\n    rescale=None,\n    data_format=None,\n    dtype=None,\n\n    # PARAMS TO EXPLORE\n    horizontal_flip=True,\n    shear_range=0.15,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.3,\n    zoom_range=0.2,\n    preprocessing_function=None\n)","3d07ece8":"### LOAD DATA \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","357f4c63":"# Final model  \ndef make_model() :\n    base_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n    ##################################################\n    inputs = keras.Input(shape=(224, 224, 3))   \n    base = base_model(inputs, training= False)\n    vectors = keras.layers.GlobalAveragePooling2D()(base)\n    drop1 = keras.layers.Dropout(0.5)(vectors)\n    inner = keras.layers.Dense(100, activation= 'relu')(drop1) \n    drop2 = keras.layers.Dropout(0.5)(inner)\n    outputs = keras.layers.Dense(8, activation='softmax')(drop2) \n    model = keras.Model(inputs, outputs)\n    ##################################################\n    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n    loss = keras.losses.CategoricalCrossentropy()\n    model.compile(\n        optimizer=optimizer, \n        loss = loss, \n        metrics=['accuracy']\n    ) \n    return model ","7fa81135":"model = make_model()\nhistory = model.fit(train_ds, epochs=10, validation_data = val_ds)","3be9935b":" train_datagen= tf.keras.preprocessing.image.ImageDataGenerator(\n    # DEFAULT PARAMS \n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False, \n    zca_epsilon=1e-06,\n    brightness_range=None,\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    vertical_flip=False,\n    rescale=None,\n    data_format=None,\n    dtype=None,\n\n    # PARAMS TO EXPLORE\n    horizontal_flip=True,\n    shear_range=0.15,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.3,\n    zoom_range=0.2,\n    preprocessing_function=None\n)","61b6cbf1":"### LOAD DATA \ntrain_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_ds = train_datagen.flow_from_directory(\n    r'C:\\Users\\User\\@Code-ML\\Zoom-camp Capstone Project\\Data\\dataset', # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data","d43d8051":"# Final model  \ndef make_model() :\n    base_model= EfficientNetB4(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n    ##################################################\n    inputs = keras.Input(shape=(224, 224, 3))   \n    base = base_model(inputs, training= False)\n    vectors = keras.layers.GlobalAveragePooling2D()(base)\n    drop1 = keras.layers.Dropout(0.5)(vectors)\n    inner = keras.layers.Dense(100, activation= 'relu')(drop1) \n    drop2 = keras.layers.Dropout(0.5)(inner)\n    outputs = keras.layers.Dense(8, activation='softmax')(drop2) \n    model = keras.Model(inputs, outputs)\n    ##################################################\n    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n    loss = keras.losses.CategoricalCrossentropy()\n    model.compile(\n        optimizer=optimizer, \n        loss = loss, \n        metrics=['accuracy']\n    ) \n    return model ","acdd82a8":"chechpoint = keras.callbacks.ModelCheckpoint(\n    'EfficientNetB4_Epoch-{epoch:02d}_Val-acc-{val_accuracy:.3f}.h5',\n    save_best_only=True,\n    monitor='val_accuracy',\n    mode='max'\n)","87f891b6":"# Latest model (with augmentation)\nmodel = make_model()\n\nhistory = model.fit(\n    train_ds,\n    epochs=50,\n    validation_data=val_ds,\n    callbacks=[chechpoint]\n)","b220762e":"hist = history.history\nplt.plot(hist['val_accuracy'], label='val')\nplt.plot(hist['accuracy'], label='train')\n\nplt.legend()","aa1b7aea":"# FIRST MODEL (without augmentation)\nmodel = make_model()\n\nhistory = model.fit(\n    train_ds,\n    epochs=30,\n    validation_data=val_ds,\n    callbacks=[chechpoint]\n)","743a9dad":"hist = history.history\nplt.plot(hist['val_accuracy'], label='val')\nplt.plot(hist['accuracy'], label='train')\n\nplt.legend()","3e274d1f":"### EDA-1. Checking class balance <a class=\"anchor\" id=\"EDA1\"><\/a>","5bf20ea9":"# EDA <a class=\"anchor\" id=\"EDA\"><\/a>\n\nReference: https:\/\/medium.com\/geekculture\/eda-for-image-classification-dcada9f2567a\nhttps:\/\/towardsdatascience.com\/deep-learning-unbalanced-training-data-solve-it-like-this-6c528e9efea6","ca4fec1c":"# B.Hypeparameter tuning<a class=\"anchor\" id=\"B\"><\/a>","be73554c":"# A. Model Selection <a class=\"anchor\" id=\"A\"><\/a>\n\n## A1. Xception Model <a class=\"anchor\" id=\"A1\"><\/a>\n","0de738a5":"## A3. EfficientNetB4 Model <a class=\"anchor\" id=\"A3\"><\/a>","40e94ede":"### EDA-2. Viewing sample of the Weather dataset <a class=\"anchor\" id=\"EDA2\"><\/a>","81d63e18":"## A4. InceptionResNetV2 Model <a class=\"anchor\" id=\"A4\"><\/a>","7308bac2":"### Test run and view the added dataset: <a class=\"anchor\" id=\"EDA1Z\"><\/a>\nOnly added 50 for `lightning` and 100 for `rainbow`. \n\nDownloaded 300 images for rainbow, and 200 images for ligtning, after manual filtering only about 150 images are usable (some cannot be used due to picture format, so the actual usable images are even lesser). ","0bbdeced":"## B2. Number of layers and dropout <a class=\"anchor\" id=\"B2\"><\/a>","84e37997":"# D. Final model checkpointing <a class=\"anchor\" id=\"D\"><\/a>","3276a552":"# Weather classification project  \n<br>\n\n## Table of content: \n* [EDA](#EDA)\n    1. <a href=\"#EDA1\">Check Class Balance <\/a>\n      * <a href=\"#EDA1Z\">Test run and view added dataset <\/a>\n    2. <a href=\"#EDA2\">Viewing sample of the Weather dataset  <\/a>\n    \n\nOverview: There's class imbalance issue, I will add around 400 images for rainbow, and 300 images for ligtning to make the data more balance. Class `rime` is downsampled. \n<br><br>\n* [A. Model Selection](#A)\n    1. <a href=\"#A1\">Xception Model <\/a>\n    2. <a href=\"#A2\">VGG16 Model <\/a>\n    3. <a href=\"#A3\">EfficientNetB4  <\/a>\n    4. <a href=\"#A4\">InceptionResNetV2  <\/a>\n\n\nOverview: `EfficientNetB4` performed exceptionally well among all the models, it is selected as the pretrained model for this study. \n<br><br>\n* [B. Hyperparameter Tuning](#B)\n    1. <a href=\"#B1\">Learning Rate <\/a>\n    2. <a href=\"#B2\">Number of layers and dropout <\/a>\n    3. <a href=\"#B3\">Dense layer size <\/a>\n\n\nOverview: Hyperparamters decision: `0.001` for learning rate. `0.5` for dropout. `100` for Dense layer size\n<br><br>\n* [C. Data Augmentation](#C)\n\nOverview: Image augmentation lead to better convergence of training accuracy and validation accuracy. \n<br><br>\n* [D. Final model Checkpointing](#D)\n    ","2279df45":"Adding regularizer (code below) didnt work, due to `ResourceExhaustedError:  OOM ` prob casued by my environment, it's worth exploring tho.","acef1927":"# C. Data augmentation  <a class=\"anchor\" id=\"C\"><\/a>\n\nRef: https:\/\/www.pyimagesearch.com\/2019\/07\/08\/keras-imagedatagenerator-and-data-augmentation\/ \n\nKeras actually replace the orginal batch of images with the new, randomly transformed batch. ","1d0301ac":"# B3. Tune dense layer size  <a class=\"anchor\" id=\"B3\"><\/a>","b327b79b":"## A2. VGG16 Model <a class=\"anchor\" id=\"A2\"><\/a>","5b2001d7":"There isnt much difference when second dense layer is added, thus I will stick to the previous model with one dense layer. ","211f1b43":"## B1. Learning rate<a class=\"anchor\" id=\"B1\"><\/a>"}}