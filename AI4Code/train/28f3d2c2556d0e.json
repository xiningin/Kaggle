{"cell_type":{"683930f2":"code","e02d19dc":"code","e0a0570b":"code","a6576b58":"code","f5eff3d1":"code","6e0eabf7":"code","8cf6b689":"code","24bc6607":"code","0af0df4a":"code","51f8ea80":"code","4f3a3b75":"code","b22a6f75":"markdown","b857a33b":"markdown","efeb50e5":"markdown","f5dce74c":"markdown","7176596e":"markdown","04d532c6":"markdown","6d75e815":"markdown","e1b21a9c":"markdown","ab870925":"markdown","c6135ada":"markdown","ccf3abd5":"markdown","81eac182":"markdown","df1005f6":"markdown","94927b8a":"markdown"},"source":{"683930f2":"# Important library imports\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam","e02d19dc":"# Read the labels.csv file and checking shape and records\nlabels_all = pd.read_csv(\"\/kaggle\/input\/dogbreedidfromcomp\/labels.csv\")\nprint(labels_all.shape)\nlabels_all.head()","e0a0570b":"# Visualize the number of each breeds\nbreeds_all = labels_all[\"breed\"]\nbreed_counts = breeds_all.value_counts()\nbreed_counts.head()","a6576b58":"# Selecting first 3 breeds (Limitation due to computation power)\nCLASS_NAMES = ['scottish_deerhound','maltese_dog','bernese_mountain_dog']\nlabels = labels_all[(labels_all['breed'].isin(CLASS_NAMES))]\nlabels = labels.reset_index()\nlabels.head()","f5eff3d1":"# Creating numpy matrix with zeros\nX_data = np.zeros((len(labels), 224, 224, 3), dtype='float32')\n# One hot encoding\nY_data = label_binarize(labels['breed'], classes = CLASS_NAMES)\n\n# Reading and converting image to numpy array and normalizing dataset\nfor i in tqdm(range(len(labels))):\n    img = image.load_img('\/kaggle\/input\/dogbreedidfromcomp\/train\/%s.jpg' % labels['id'][i], target_size=(224, 224))\n    img = image.img_to_array(img)\n    x = np.expand_dims(img.copy(), axis=0)\n    X_data[i] = x \/ 255.0\n    \n# Printing train image and one hot encode shape & size\nprint('\\nTrain Images shape: ',X_data.shape,' size: {:,}'.format(X_data.size))\nprint('One-hot encoded output shape: ',Y_data.shape,' size: {:,}'.format(Y_data.size))","6e0eabf7":"# Building the Model\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5), activation ='relu', input_shape = (224,224,3)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), activation ='relu', kernel_regularizer = 'l2'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (7,7), activation ='relu', kernel_regularizer = 'l2'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', kernel_regularizer = 'l2'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = \"relu\", kernel_regularizer = 'l2'))\nmodel.add(Dense(64, activation = \"relu\", kernel_regularizer = 'l2'))\nmodel.add(Dense(len(CLASS_NAMES), activation = \"softmax\"))\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.0001),metrics=['accuracy'])\n\nmodel.summary()","8cf6b689":"# Splitting the data set into training and testing data sets\nX_train_and_val, X_test, Y_train_and_val, Y_test = train_test_split(X_data, Y_data, test_size = 0.1)\n# Splitting the training data set into training and validation data sets\nX_train, X_val, Y_train, Y_val = train_test_split(X_train_and_val, Y_train_and_val, test_size = 0.2)","24bc6607":"# Training the model\nepochs = 100\nbatch_size = 128\n\nhistory = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n                    validation_data = (X_val, Y_val))","0af0df4a":"# Plot the training history\nplt.figure(figsize=(12, 5))\nplt.plot(history.history['accuracy'], color='r')\nplt.plot(history.history['val_accuracy'], color='b')\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'val'])\n\nplt.show()","51f8ea80":"Y_pred = model.predict(X_test)\nscore = model.evaluate(X_test, Y_test)\nprint('Accuracy over the test set: \\n ', round((score[1]*100), 2), '%')","4f3a3b75":"# Plotting image to compare\nplt.imshow(X_test[2,:,:,:])\nplt.show()\n\n# Finding max value from predition list and comaparing original value vs predicted\nprint(\"Originally : \",labels['breed'][np.argmax(Y_test[2])])\nprint(\"Predicted : \",labels['breed'][np.argmax(Y_pred[2])])","b22a6f75":"## Dog Breed Prediction","b857a33b":"Now we will train our model on 100 epochs and a batch size of 128. You can try using more number of epochs to increase accuracy. During each epochs we can see how the model is performing by viewing the training and validation accuracy.","efeb50e5":"Loading the labels data into dataframe and viewing it. Here we analysed that labels contains 10222 rows and 2 columns.  ","f5dce74c":"As we are working with the classification dataset first we need to one hot encode the target value i.e. the classes. After that we will read images and convert them into numpy array and finally normalizing the array.","7176596e":"We will use predict function to make predictions using this model also we are finding out the accuracy on the test set.","04d532c6":"We will work on only 3 breeds due to limited computational power. You can consider more classes as per your system computational power.","6d75e815":"In this project, we will see how to use Keras and TensorFlow to build, train, and test a Convolutional Neural Network capable of identifying the breed of a dog in a supplied image. This is a supervised learning problem, specifically a multiclass classification problem.","e1b21a9c":"Here you can see image with its original and predicted label.","ab870925":"After defining the network architecture we will start with splitting the test and train data then dividing train data in train and validation data. ","c6135ada":"## Conclusion:\n\nWe started with importing dataset, creating the model and finding out the predictions using the model. We can optimize different hyper parameters in order to tune this model for a higher accuracy. This model can be used to predict different breeds of dogs which can be further used by different NGO's working on saving animals and for educational purposes also.","ccf3abd5":"Next we will create a network architecture for the model. We have used different types of layers according to their features namely Conv_2d (It is used to create a convolutional kernel that is convolved with the input layer to produce the output tensor), max_pooling2d (It is a downsampling technique which takes out the maximum value over the window defined by poolsize), flatten (It flattens the input and creates a 1D output), Dense (Dense layer produce the output as the dot product of input and kernel).\n\n\nAfter defining the network architecture we found out the total parameters as 162,619.","81eac182":"Importing required libraries.","df1005f6":"Here we analyse how the model is learning with each epoch in terms of accuracy.","94927b8a":"Here we are finding out the count per class i.e. total data in each class using value_counts() function."}}