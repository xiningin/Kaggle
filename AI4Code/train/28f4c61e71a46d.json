{"cell_type":{"a24cdd49":"code","7b0303c6":"code","802a9b77":"code","8e7638c3":"code","4c2a1e63":"code","931fe133":"code","23de2c5a":"code","5ca7c58f":"code","6f883a59":"code","067958fe":"code","371629bc":"code","58a93244":"code","411d8842":"code","bb043de5":"code","f4dec913":"code","d15b9b81":"code","b8d78874":"code","635e7c81":"code","2cd267ad":"code","f9031855":"code","82c7d70a":"code","5a73a5d4":"code","03ca59c2":"code","c1b74a49":"code","09e445bc":"code","dcc4a74c":"code","f4bddaf4":"code","076df221":"code","edd7df5a":"code","319115eb":"code","241313b8":"code","6760c79b":"code","b1612519":"code","8545d4fa":"code","de36f66e":"code","aa201be1":"code","9d578626":"markdown","3d5ab025":"markdown","c1da89b3":"markdown","38cbc003":"markdown","022814a9":"markdown","0fa98ca8":"markdown"},"source":{"a24cdd49":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7b0303c6":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sn\nfrom sklearn.feature_selection import SelectKBest,chi2\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split","802a9b77":"train_data = pd.read_csv(\"\/kaggle\/input\/mobile-price-classification\/train.csv\")","8e7638c3":"train_data.head()","4c2a1e63":"train_data.tail()","931fe133":"train_data.isnull().any()","23de2c5a":"train_data['price_range'].value_counts()","5ca7c58f":"x = train_data.iloc[:,0:20]\ny = train_data.iloc[:,20:]","6f883a59":"x","067958fe":"print(x.shape)\nprint(y.shape)","371629bc":"best_feat = SelectKBest(chi2,k=10)\nfit = best_feat.fit(x,y)","58a93244":"dfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(x.columns)","411d8842":"# concat both dataframes for comparing best scores\n\nscore_list = pd.concat([dfcolumns,dfscores],axis=1)\nscore_list.columns = [\"features\",\"scores\"]","bb043de5":"score_list","f4dec913":"print(score_list.nlargest(10,\"scores\"))","d15b9b81":"train_data.drop(train_data.columns[[1,2,3,5,7,9,10,17,18,19]],axis=1,inplace=True)","b8d78874":"train_data.head()","635e7c81":"train_data.tail()","2cd267ad":"x = train_data.iloc[:,0:10].values\ny = train_data.iloc[:,10:].values","f9031855":"x","82c7d70a":"y","5a73a5d4":"# Random Forest Classifier\n\nskfold = StratifiedKFold(n_splits=3,random_state=0)\nmodel_c = RandomForestClassifier(criterion='entropy',n_estimators=10,random_state=0,n_jobs=-1)\nresults_skfold = model_selection.cross_val_score(model_c, x, y.ravel(), cv=skfold)\nprint(\"Accuracy: %.2f%%\" % (results_skfold.mean()*100.0))","03ca59c2":"# KNN Classifier\n\nskfold = StratifiedKFold(n_splits=3,random_state=0)\nmodel_knn = KNeighborsClassifier(n_neighbors=10)\nresults_skfold = model_selection.cross_val_score(model_c, x, y.ravel(), cv=skfold)\nprint(\"Accuracy: %.2f%%\" % (results_skfold.mean()*100.0))","c1b74a49":"# Decision Tree Classifier\n\nskfold = StratifiedKFold(n_splits=3,random_state=0)\nmodel_c = DecisionTreeClassifier()\nresults_skfold = model_selection.cross_val_score(model_c, x, y.ravel(), cv=skfold)\nprint(\"Accuracy: %.2f%%\" % (results_skfold.mean()*100.0))","09e445bc":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)","dcc4a74c":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","f4bddaf4":"knn = KNeighborsClassifier(n_neighbors=10)","076df221":"knn.fit(x_train,y_train.ravel())","edd7df5a":"test_data = pd.read_csv(\"\/kaggle\/input\/mobile-price-classification\/test.csv\")","319115eb":"test_data.head()","241313b8":"test_data_1 = test_data","6760c79b":"test_data_1 = test_data_1.drop(test_data_1.columns[[0,2,3,4,6,8,10,11,18,19,20]],axis=1)","b1612519":"predicted_val = knn.predict(test_data_1)","8545d4fa":"predicted_val","de36f66e":"test_data['price_range']=predicted_val","aa201be1":"test_data","9d578626":"## Model","3d5ab025":"## Separating dependent and independent variable","c1da89b3":"## Univariate Feature Selection\n\nUses staistical test to select those features that have strongest relationship with target variable.","38cbc003":"## Applying cross validation technique on various models","022814a9":"Selecting the best features","0fa98ca8":"This notebook mainly focuses on feature selection aspect of the dataset"}}