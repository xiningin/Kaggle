{"cell_type":{"6a94b647":"code","d56dfe8c":"code","563d553d":"code","71ded6c3":"code","6bbdfde5":"code","db64d251":"code","80f8d76e":"code","28abcee6":"code","aad81d0a":"code","03d5de91":"code","f667b3b1":"code","061bd0a3":"code","7143c984":"code","c1f827ae":"code","71f15b97":"code","584ec87d":"code","04757fd3":"code","92864f6f":"code","67d82bf9":"code","8d42615d":"code","8405b71c":"code","5ebe4f89":"code","021670a5":"code","9664fbbb":"code","853ad0e1":"code","f0fd113f":"code","6163b9cd":"code","95dea80a":"code","38048a89":"code","35c69a66":"code","ba06fa2f":"code","93269327":"code","d50d079c":"code","12fd9f8c":"code","23fbf3fa":"code","9615cd5d":"code","05ae654f":"code","afaf54d8":"code","50daf43b":"code","1d910e2e":"code","d7d89cc5":"code","f01c22e1":"code","74a9757e":"code","fff1506c":"code","603dfd88":"code","3ea9ab4b":"code","f670a1c3":"code","c5fdcc97":"code","051b7af9":"code","62269f64":"code","d81fb076":"code","8f7712b7":"markdown","d16a0da6":"markdown","2dd12fba":"markdown","8a4eba20":"markdown","8d679b51":"markdown","c9694d99":"markdown","bc98964b":"markdown","73c209e0":"markdown","7a58333c":"markdown","4528f68c":"markdown","73a59620":"markdown","e19c934f":"markdown","39dfa50f":"markdown","89ba218b":"markdown","8195511a":"markdown","770b05cf":"markdown","12a827ed":"markdown"},"source":{"6a94b647":"# Operating system dependent\nimport os\n\n# linear algebra\nimport numpy as np\n\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\n\n#Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Display HTML\nfrom IPython.core.display import display, HTML\n\n#collection of machine learning algorithms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n#Common Model Helpers\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nfrom sklearn import model_selection\nimport pylab as pl\nfrom sklearn.metrics import roc_curve\nfrom sklearn.preprocessing import Imputer\n\nimport plotly.graph_objects as go\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport cufflinks as cf\ncf.go_offline()\n\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline","d56dfe8c":"train = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat-ii\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat-ii\/test.csv\")\nsubmission =  pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat-ii\/sample_submission.csv\")","563d553d":"train_size = str(round(os.path.getsize('\/kaggle\/input\/cat-in-the-dat-ii\/train.csv') \/ 1000000, 2)) + 'MB'\ntest_size = str(round(os.path.getsize('\/kaggle\/input\/cat-in-the-dat-ii\/test.csv') \/ 1000000, 2)) + 'MB'\nsample_submission_size = str(round(os.path.getsize('\/kaggle\/input\/cat-in-the-dat-ii\/sample_submission.csv') \/ 1000000, 2)) + 'MB'","71ded6c3":"display(HTML(f\"\"\"\n\n    \n    <table style=\"width:40%;font-size:100%;\">\n      <tr>\n        <th>Filename<\/th>\n        <th>size<\/th>\n      <\/tr>\n      <tr>\n        <td>Train<\/td>\n        <td>{train_size}<\/td>\n      <\/tr>\n      <tr>\n        <td>Test<\/td>\n        <td>{test_size}<\/td>\n      <\/tr>\n       <tr>\n        <td>Sample_Submission<\/td>\n        <td>{sample_submission_size}<\/td>\n      <\/tr>\n    <\/table>\n    \n  \n\"\"\"))","6bbdfde5":"train.head()","db64d251":"train.columns","80f8d76e":"display(HTML(f\"\"\"\n   \n        <ul class=\"list-group\">\n          <li class=\"list-group-item disabled\" aria-disabled=\"true\"><h4>Shape of Train and Test Dataset<\/h4><\/li>\n          <li class=\"list-group-item\"><h4>Number of rows in Train dataset is: <span class=\"label label-primary\">{ train.shape[0]:,}<\/span><\/h4><\/li>\n          <li class=\"list-group-item\"> <h4>Number of columns Train dataset is <span class=\"label label-primary\">{train.shape[1]}<\/span><\/h4><\/li>\n          <li class=\"list-group-item\"><h4>Number of rows in Test dataset is: <span class=\"label label-success\">{ test.shape[0]:,}<\/span><\/h4><\/li>\n          <li class=\"list-group-item\"><h4>Number of columns Test dataset is <span class=\"label label-success\">{test.shape[1]}<\/span><\/h4><\/li>\n        <\/ul>\n  \n    \"\"\"))","28abcee6":"train.info()","aad81d0a":"train.target.value_counts().iplot(kind='bar',text=['0', '1'], title='Distribution Binary target column',color=['blue'])","03d5de91":"counts_train = train.target.value_counts(sort=False)\nlabels = counts_train.index\nvalues_train = counts_train.values\n\ndata = go.Pie(labels=labels, values=values_train ,pull=[0.03, 0])\nlayout = go.Layout(title='Comparing Target is binary (1) or not (0) in %')\n\nfig = go.Figure(data=[data], layout=layout)\nfig.update_traces(hole=.3, hoverinfo=\"label+percent+value\")\nfig.update_layout(\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Train', x=0.5, y=0.5, font_size=20, showarrow=False)])\nfig.show()","f667b3b1":"missing = train.isnull().sum()  \nmissing[missing>0].sort_values().iplot(kind='bar',title='Null values present in train Dataset', color=['red'])","061bd0a3":"bin_ = [col for col in train.columns if 'bin_' in col]\nprint(bin_ )\nnom_ = [col for col in train.columns if 'nom_' in col]\nprint(nom_)\nord_ = [col for col in train.columns if 'ord_' in col]\nprint(ord_)","7143c984":"fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12,10))\n\nfor ax, column in zip(axes.flatten(), bin_):\n    sns.countplot(x = column, ax = ax, data = train)\n\nplt.show()","c1f827ae":"fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12,10))\n\nfor ax, column in zip(axes.flatten(), ord_):\n    sns.countplot(x = column, ax = ax, data = train)\n\nplt.show()","71f15b97":"fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(14,12))\n\nfor ax, column in zip(axes.flatten(), nom_):\n    sns.countplot(x = column, ax = ax, data = train)\n\nplt.show()","584ec87d":"cat_cols = [ col  for col, dt in train.dtypes.items() if dt == object]\ny_col = ['target']\ncont_cols = [col for col in train.columns if col not in cat_cols + y_col]\n\n\nprint(f'cat_cols  has {len(cat_cols)} columns')  \nprint(f'cont_cols has {len(cont_cols)} columns')   ","04757fd3":"# Taking care of missing data in continous\nfrom sklearn.preprocessing import Imputer\n\nimputer = Imputer(strategy = 'most_frequent')\nimputer = imputer.fit(train[cont_cols])\ntrain[cont_cols] = imputer.transform(train[cont_cols])","92864f6f":"#now for test\nimputer = imputer.fit(test[cont_cols])\ntest[cont_cols] = imputer.transform(test[cont_cols])","67d82bf9":"for cat in cat_cols:\n    if train[cat].isnull().sum() > 0:\n        train[cat] = train[cat].fillna(train[cat].mode()[0])\n    if test[cat].isnull().sum() > 0:\n        test[cat] = test[cat].fillna(test[cat].mode()[0])","8d42615d":"# check again for Null values\nmissing = train.isnull().sum()  \nmissing[missing>0].sort_values()","8405b71c":"# Convert our categorical columns to category dtypes.\nfor cat in cat_cols:\n    train[cat] = train[cat].astype('category')\n","5ebe4f89":"train.info()","021670a5":"for cat in cat_cols:\n    test[cat] = test[cat].astype('category')","9664fbbb":"train.nom_3.unique()","853ad0e1":"# this is how cat.codes work, assign a numeric value to each categorie.\ntrain.nom_3.cat.codes.unique()","f0fd113f":"pd.DataFrame(train.nom_3.cat.codes.unique(), train.nom_3.unique())\n# Check here Russia is change for 5 values and so on","6163b9cd":"# lets make as encoder this train columns\nfor col in cat_cols:\n    train[col] = train[col].cat.codes\n    ","95dea80a":"for col in cat_cols:\n    test[col] = test[col].cat.codes","38048a89":"train.head()","35c69a66":"# Number of unique itemns by colum\ntrain.nunique()","ba06fa2f":"#check correlation in train dataset\ntrain.corr()['target'][:-1].sort_values().plot.bar(figsize=(10,10))","93269327":"\nX = train.drop(['id', 'target'],axis=1).values\ny = train['target'].values","d50d079c":"from sklearn.model_selection import train_test_split","12fd9f8c":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=42)","23fbf3fa":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n","9615cd5d":"scaler.fit(X_train)\n","05ae654f":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n","afaf54d8":"X_train.max()","50daf43b":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression","1d910e2e":"#Grid Search\nlogreg = LogisticRegression(class_weight='balanced')\nparameters = {'C':[0.1,5,10]}\nclf_grid = GridSearchCV(logreg,parameters,scoring='roc_auc',refit=True,cv=5, n_jobs=-1)\nclf_grid.fit(X_train, y_train)\nprint('Best roc_auc: {:.4}, with best C: {}'.format(clf_grid.best_score_, clf_grid.best_params_))","d7d89cc5":"# Fitting LogisticRegression Classification to the Training set with paramns\n\nclassifier = LogisticRegression(C=5, solver='lbfgs', class_weight='balanced')\nclassifier.fit(X_train, y_train)","f01c22e1":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)","74a9757e":"from sklearn.metrics import confusion_matrix\nprint( confusion_matrix(y_test, y_pred))","fff1506c":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test,y_pred))","603dfd88":"# Showing Confusion Matrix\ndef plot_cm(y_true, y_pred, title, figsize=(5,4)):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm \/ cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.title(title)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)","3ea9ab4b":"# Showing Confusion Matrix\nplot_cm(y_test,y_pred, 'Confution matrix of Tweets', figsize=(5,5))","f670a1c3":"test = test.drop(['id'],axis=1).values\nscalert = MinMaxScaler()\nscalert.fit(test)\nr_test = scalert.transform(test)\n","c5fdcc97":"predictions = classifier.predict(r_test)\npredictions","051b7af9":"# sample of submission\nsubmission.head()","62269f64":"submission['target'] = predictions ","d81fb076":"submission.to_csv(\"submission.csv\", index=False, header=True)","8f7712b7":"\n# Scaling Data","d16a0da6":"<a id='split'><\/a>\n# 5. Train Test Split","2dd12fba":"<a id='reference'><\/a>\n# 8. References","8a4eba20":" <a id='separate'><\/a>\n#  4. Separate continuous, categorical and label column names","8d679b51":"<a id='libraries'><\/a>\n## 1. Import Libraries","c9694d99":"## Competition Description\nThis follow-up competition offers an even more challenging dataset so that you can continue to build your skills with the common machine learning task of encoding categorical variables. This challenge adds the additional complexity of feature interactions, as well as missing data.\n\nThis Playground competition will give you the opportunity to try different encoding schemes for different algorithms to compare how they perform. We encourage you to share what you find with the community.","bc98964b":"<a id='top'><\/a>\n<h1 style=\"text-align:center;font-size:200%;;\">Categorical Feature Encoding Challenge II<\/h1>\n<img src=\"https:\/\/miro.medium.com\/max\/1200\/1*TBSV23ud8tae3E4szI5EDA.jpeg\">","73c209e0":"<h2>I hope this notebook <span style=\"color:red\">Usefull<\/span> for you! <\/h3>","7a58333c":"[Competition](https:\/\/www.kaggle.com\/c\/cat-in-the-dat-ii\/overview)","4528f68c":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content!<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#libraries\" role=\"tab\" aria-controls=\"profile\">Import Libraries<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#load\" role=\"tab\" aria-controls=\"messages\">Load Data<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#visual\" role=\"tab\" aria-controls=\"settings\">Visualization of data<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#separate\" role=\"tab\" aria-controls=\"settings\">Separate continuous, categorical and label column names<span class=\"badge badge-primary badge-pill\">4<\/span><\/a> \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#split\" role=\"tab\" aria-controls=\"settings\">Train and test Split<span class=\"badge badge-primary badge-pill\">5<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#model\" role=\"tab\" aria-controls=\"settings\"> Creating the Model<span class=\"badge badge-primary badge-pill\">6<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#eval\" role=\"tab\" aria-controls=\"settings\">Model Evaluation<span class=\"badge badge-primary badge-pill\">7<\/span><\/a>\n     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#reference\" role=\"tab\" aria-controls=\"settings\">References<span class=\"badge badge-primary badge-pill\">8<\/span><\/a>  ","73a59620":"\n<a href=\"#top\" class=\"btn btn-primary btn-lg active\" role=\"button\" aria-pressed=\"true\">Go to TOP<\/a>","e19c934f":"<a id='load'><\/a>\n# 2. Load Data","39dfa50f":"<a id='eval'><\/a>\n# 7. Model evaluation","89ba218b":"<a id='model'><\/a>\n# 6. Creating the Model    ","8195511a":"<a id='visual'><\/a>\n# 3. Visualization of data","770b05cf":"\n## Categorify\nRemember that Pandas offers a <a href='https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/categorical.html'><strong>category dtype<\/strong><\/a> for converting categorical values to numerical codes.  Pandas replaces the column values with codes, and retains an index list of category values. In the steps ahead we'll call the categorical values \"names\" and the encodings \"codes\".","12a827ed":"<ul style=\"list-style-type:square;\">\n   <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Data Colums Description!<\/h3>\n  <li><span class=\"label label-default\">id<\/span> a unique identifier for each tweet<\/li>\n  <li><span class=\"label label-default\">bin_* <\/span> The data contains binary features <\/li>\n  <li><span class=\"label label-default\">nom_*<\/span>  Nominal features <\/li>\n    <li><span class=\"label label-default\">ord_*<\/span>  Ordinal features<\/li>\n    <li><span class=\"label label-default\">ord_{3-5}<\/span>  String ordinal features,  are lexically ordered according to string.ascii_letters.<\/li>\n    <li><span class=\"label label-default\">day<\/span>  Day of the week features<\/li>\n    <li><span class=\"label label-default\">month<\/span>  Month Feachures<\/li>\n    <li><span class=\"label label-default\">target<\/span> you will be predicting the probability [0, 1] of a binary target column.<\/li>\n<\/ul>\n"}}