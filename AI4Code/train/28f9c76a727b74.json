{"cell_type":{"4766a5de":"code","ed96f652":"code","c809ec96":"code","dcc89660":"code","9241c1d3":"code","293da3db":"code","6e4f1415":"code","9039030e":"code","b4e4092c":"code","5d78e4b1":"code","8b9743f5":"code","9084e3dd":"code","8e0b19e9":"code","cfd99074":"code","2dee4b09":"code","2532886e":"code","376a73c2":"code","997436f6":"code","98f720c4":"code","0df29127":"code","2ba92b6b":"code","9d32106e":"code","fd3cba77":"code","c6ee6b73":"code","fe0238ed":"code","cd399eca":"code","db9461ed":"code","c8c18308":"code","b48dc939":"code","a1a01afe":"code","ba96ae3f":"code","242ce958":"code","89272126":"code","0bbe6547":"code","a6353745":"code","cafeafa5":"code","50082196":"code","0643deb5":"code","357e1bae":"code","1efbdf52":"code","92ce60eb":"code","9169d4b6":"code","22d15b45":"code","bf7db96e":"code","1195e3b6":"code","90b79e93":"code","28b3f36a":"code","03480b79":"code","9eef28f4":"code","e8901d0b":"code","cd113c42":"code","6194eff9":"code","cb4def4e":"code","e0a2f434":"code","8b773cd6":"code","a400e07f":"code","f81eb449":"code","d1a5d56f":"code","3acfd014":"code","826d6fd6":"code","8ce17ec2":"code","784ca7db":"code","1751989e":"code","0aea70c6":"code","0a09a6d3":"code","fc982faa":"code","8c97a874":"code","f5fbf29d":"code","cc7f8d81":"code","108d5a4e":"markdown","4d17da65":"markdown","aa56b069":"markdown","9d595722":"markdown","de044137":"markdown","c5705115":"markdown","fd06843d":"markdown","910f8aee":"markdown","b3ff8c25":"markdown","482b2d39":"markdown","13d30d2d":"markdown","ca31df5b":"markdown","613ab76a":"markdown","59be8910":"markdown","d60d25c7":"markdown","24e19aba":"markdown","d1491f5f":"markdown","cfbeb0e5":"markdown","dd0536d2":"markdown","0d5d93dc":"markdown","6eb4232f":"markdown","9fcac0ee":"markdown","20c8839d":"markdown","a4475c56":"markdown","045016b5":"markdown","64b616dc":"markdown","7be82291":"markdown","4dae355a":"markdown","8862befc":"markdown","2078a5de":"markdown","08dec5ef":"markdown","ed87de74":"markdown","e466b71d":"markdown","f8c557da":"markdown","4be708d0":"markdown","b4727bbc":"markdown","f81b4049":"markdown","f6661949":"markdown","f06e7184":"markdown","8a42811f":"markdown","b7f5b16b":"markdown","347aaf6a":"markdown","0c608ba7":"markdown","da7b20d9":"markdown","03f27bea":"markdown","04c346f0":"markdown"},"source":{"4766a5de":"%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline","ed96f652":"import numpy as np\nimport pandas as pd\n\nfrom fastai.imports import *\n#from fastai.structured import *\n#from structured import *\nfrom fastai.tabular import *\nfrom fastai import *\n#from fastai_structured import *\n\n\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV\n\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nfrom scipy.cluster import hierarchy as hc\n\nfrom fastai_structured import *","c809ec96":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)","dcc89660":"def display_small(df):\n    with pd.option_context(\"display.max_rows\", 10, \"display.max_columns\", 5): \n        display(df)","9241c1d3":"PATH = \"..\/input\/house-prices-advanced-regression-techniques\/\"\n!ls {PATH}","293da3db":"## Training dataset\ndf_raw = pd.read_csv(f'{PATH}train.csv', low_memory=False,\n                     index_col='Id')\n## Test dataset\ndf_test_raw = pd.read_csv(f'{PATH}test.csv', low_memory=False,\n                          index_col='Id')","6e4f1415":"display_small(df_raw.tail().T)","9039030e":"display_small(df_test_raw.tail().T)","b4e4092c":"display_small(df_raw.describe(include='all').T)","5d78e4b1":"train_cats(df_raw)\napply_cats(df_test_raw,df_raw)","8b9743f5":"#df_raw.head()","9084e3dd":"#df_raw.MSZoning.cat.set_categories(['FV', 'RL', 'RM', 'RH', 'C (all)'], ordered=True, inplace=True)\n#df_raw.LotShape.cat.set_categories(['Reg', 'R1', 'R2', 'R3'], ordered=True, inplace=True)\n#df_raw.Utilities.cat.set_categories(['AllPub', 'NoSewr', 'NoSeWa', 'ELO'], ordered=True, inplace=True)\n#df_raw.LandSlope.cat.set_categories(['Gtl', 'Mod', 'Sev'], ordered=True, inplace=True)\n#df_raw.ExterQual.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po'], ordered=True, inplace=True)\n#df_raw.ExterCond.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po'], ordered=True, inplace=True)\n#df_raw.BsmtQual.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA'], ordered=True, inplace=True)\n#df_raw.BsmtExposure.cat.set_categories(['Gd', 'Av', 'Mn', 'No', 'NA'], ordered=True, inplace=True)\n#df_raw.BsmtFinType1.cat.set_categories(['GLD', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'NA'], ordered=True, inplace=True)\n#df_raw.HeatingQC.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA'], ordered=True, inplace=True)\n#df_raw.Electrical.cat.set_categories(['SBrkr', 'FuseA', 'FuseF', 'FuseP', 'Mix', 'NA'], ordered=True, inplace=True)\n#df_raw.KitchenQual.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA'], ordered=True, inplace=True)\n#df_raw.BsmtFinType1.cat.set_categories(['Typ', 'Min1', 'Min2', 'Mod', 'Maj1', 'Maj2', 'Sev', 'Sal'], ordered=True, inplace=True)\n#df_raw.FireplaceQu.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA'], ordered=True, inplace=True)\n#df_raw.GarageFinish.cat.set_categories(['Fin', 'RFn', 'Unf', 'NA'], ordered=True, inplace=True)\n#df_raw.GarageQual.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA'], ordered=True, inplace=True)\n#df_raw.GarageCond.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA'], ordered=True, inplace=True)\n#df_raw.PavedDrive.cat.set_categories(['Y', 'P', 'N'], ordered=True, inplace=True)\n#df_raw.PoolQC.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA'], ordered=True, inplace=True)\n#df_raw.Fence.cat.set_categories(['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA'], ordered=True, inplace=True)","8e0b19e9":"## train set\n(df_raw.isnull().sum().sort_values(ascending=False)\/len(df_raw)).head(10)","cfd99074":"df_raw['SalePrice'].head()","2dee4b09":"df_raw['SalePrice'] = np.log(df_raw['SalePrice']); df_raw['SalePrice'].head()","2532886e":"df, y, nas = proc_df(df_raw, 'SalePrice')","376a73c2":"## train set\n(df.isnull().sum().sort_values(ascending=False)\/len(df)).head(5)","997436f6":"X_train,X_valid,y_train,y_valid = train_test_split(df,y,test_size=0.25, random_state=42)","98f720c4":"def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n\ndef print_score(m):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","0df29127":"m = RandomForestRegressor(n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","2ba92b6b":"m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\nm.fit(X_train, y_train)\nprint_score(m)","9d32106e":"import IPython\nimport graphviz\n\ndef mydraw_tree(t, df, size=10, ratio=0.6, precision=0):\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub('Tree {',\n       f'Tree {{ size={size}; ratio={ratio}', s)))","fd3cba77":"## Draw tree is fastai\nmydraw_tree(m.estimators_[0], X_train, precision=3)","c6ee6b73":"m = RandomForestRegressor(n_estimators=300,n_jobs=-1,oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","fe0238ed":"## Each tree is found in m.estimators_\n\npreds = np.stack([t.predict(X_valid) for t in m.estimators_])\npreds[:,0], np.mean(preds[:,0]), y_valid[0]","cd399eca":"preds.shape","db9461ed":"plt.plot([metrics.r2_score(y_valid, np.mean(preds[:i+1], axis=0)) for i in range(300)]);","c8c18308":"param_grid = {\n    'min_samples_leaf': [1, 5, 10, 15, 20, 25],\n    'max_features': ['sqrt', 'log2', 0.2, 0.4, 0.6],\n    'n_estimators': [300],\n    'n_jobs': [-1],\n    'random_state': [42]\n}\n\nm = RandomForestRegressor(n_estimators=300)\n\ngrid_search = GridSearchCV(m, param_grid=param_grid, cv=5, iid=False,\n                           verbose=0, scoring='neg_mean_squared_error');\ngrid_search.fit(X_train, y_train);\n#print(grid_search.cv_results_)","b48dc939":"print(grid_search.best_score_)","a1a01afe":"print(grid_search.best_params_)","ba96ae3f":"myscoredf = pd.DataFrame(grid_search.cv_results_)[['param_min_samples_leaf','param_max_features','mean_test_score']]; myscoredf.head(10)","242ce958":"myscoredf = myscoredf.pivot('param_min_samples_leaf','param_max_features','mean_test_score')","89272126":"ax = sns.heatmap(myscoredf, annot=True, fmt=\".5g\", cmap=cm.coolwarm)","0bbe6547":"#set_rf_samples(800)\n#reset_rf_samples()","a6353745":"m = RandomForestRegressor(n_estimators=300,\n                          min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n                          max_features=grid_search.best_params_['max_features'],\n                          n_jobs=-1)\nm.fit(X_train, y_train);\nprint_score(m)","cafeafa5":"fi = rf_feat_importance(m, df); fi[:10]","50082196":"fi.plot('cols', 'imp', figsize=(10,6), legend=False);","0643deb5":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\nplot_fi(fi[:30]);","357e1bae":"len(fi.cols)","1efbdf52":"to_keep = fi[fi.imp>0.005].cols; len(to_keep)","92ce60eb":"df_keep = df[to_keep].copy()\n#X_train, X_valid = split_vals(df_keep, n_trn)\nX_train,X_valid,_ ,_ = train_test_split(df_keep,y,test_size=0.25, random_state=42)","9169d4b6":"m = RandomForestRegressor(n_estimators=300,\n                          min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n                          max_features=grid_search.best_params_['max_features'],\n                          n_jobs=-1)\nm.fit(X_train, y_train);","22d15b45":"fi = rf_feat_importance(m, df_keep)\nplot_fi(fi);","bf7db96e":"df_raw2 = df_raw.copy(); df_raw2.head()","1195e3b6":"#df_raw2['TotalArea']   = (df_raw2['TotalBsmtSF'] + df_raw2['GrLivArea']\n#                       + df_raw2['GarageArea'] + df_raw2['PoolArea'])\ndf_raw2['GoodLivArea'] = (df_raw2['TotalBsmtSF'] + df_raw2['GrLivArea']\n                       - df_raw2['LowQualFinSF'])\ndf_raw2['BuildingAge'] = (df_raw2['YrSold'] - df_raw2['YearBuilt'])\ndf_raw2['RemodAge']    = (df_raw2['YrSold'] - df_raw2['YearRemodAdd'])\ndf_raw2.head()","90b79e93":"df2,_ , nas = proc_df(df_raw2, 'SalePrice')\nX_train,X_valid,_ ,_ = train_test_split(df2,y,test_size=0.25, random_state=42)","28b3f36a":"m = RandomForestRegressor(n_estimators=300,\n                          min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n                          max_features=grid_search.best_params_['max_features'],\n                          n_jobs=-1)\nm.fit(X_train, y_train);\nprint_score(m)","03480b79":"fi2 = rf_feat_importance(m, df2); fi2[:10]","9eef28f4":"to_keep2 = fi2[fi2.imp>0.002].cols\ndf_keep2 = df2[to_keep2].copy()\nX_train,X_valid,_ ,_ = train_test_split(df_keep2,y,test_size=0.25, random_state=42)","e8901d0b":"print(len(fi2), len(to_keep2))","cd113c42":"plot_fi(fi2[:25]);","6194eff9":"m = RandomForestRegressor(n_estimators=300,\n                          min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n                          max_features=grid_search.best_params_['max_features'],\n                          n_jobs=-1)\nm.fit(X_train, y_train);\nprint_score(m)","cb4def4e":"## We use spearman's correlation\ncorr = np.round(scipy.stats.spearmanr(df_keep2).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(16,10))\ndendrogram = hc.dendrogram(z, labels=df_keep2.columns, orientation='left', leaf_font_size=16)\nplt.show()","e0a2f434":"def get_oob(df):\n    m = RandomForestRegressor(n_estimators=300,\n                          min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n                          max_features=grid_search.best_params_['max_features'],\n                          n_jobs=-1, oob_score=True)\n    x,_ ,_ ,_ = train_test_split(df_keep2,y,test_size=0.25,\n                                       random_state=42)\n\n    m.fit(x, y_train)\n    return m.oob_score_","8b773cd6":"get_oob(df_keep2)","a400e07f":"df_keep2.columns","f81eb449":"for c in ('GrLivArea', 'GoodLivArea', 'FireplaceQu', 'Fireplaces',\n          '1stFlrSF', 'TotalBsmtSF', 'GarageArea', 'GarageCars',\n          'Exterior2nd', 'Exterior1st'):\n    print(c, get_oob(df_keep2.drop(c, axis=1)))","d1a5d56f":"to_drop = ['GrLivArea', 'FireplaceQu', 'TotalBsmtSF', 'GarageArea', 'Exterior1st']\nget_oob(df_keep2.drop(to_drop, axis=1))","3acfd014":"df_hot,_ ,_ = proc_df(df_raw2, 'SalePrice', max_n_cat=5)\nX_train,X_valid,_ ,_ = train_test_split(df_hot,y,test_size=0.25, random_state=42)\n\nm = RandomForestRegressor(n_estimators=300,\n                          min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n                          max_features=grid_search.best_params_['max_features'],\n                          n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train);\nprint_score(m)","826d6fd6":"fi = rf_feat_importance(m, df_hot)\nplot_fi(fi[:25]);","8ce17ec2":"## We bootstrap from a different 20000 everytime\n#set_rf_samples(1460)","784ca7db":"df_test_raw2 = df_test_raw.copy()","1751989e":"#df_test_raw2['TotalArea']   = (df_test_raw2['TotalBsmtSF'] + df_test_raw2['GrLivArea']\n#                       + df_test_raw2['GarageArea'] + df_test_raw2['PoolArea'])\ndf_test_raw2['GoodLivArea'] = (df_test_raw2['TotalBsmtSF'] + df_test_raw2['GrLivArea']\n                       - df_test_raw2['LowQualFinSF'])\ndf_test_raw2['BuildingAge'] = (df_test_raw2['YrSold'] - df_test_raw2['YearBuilt'])\ndf_test_raw2['RemodAge']    = (df_test_raw2['YrSold'] - df_test_raw2['YearRemodAdd'])\ndf_test_raw2.head()","0aea70c6":"df_test, _, _ = proc_df(df_test_raw2, na_dict=nas)\ndf_test_keep = df_test[to_keep2].copy()\n\n\nX_train,X_valid ,y_train,y_valid = train_test_split(df_keep2,y,test_size=0.01, random_state=42)\nprint(len(X_train), len(X_valid))","0a09a6d3":"np.shape(X_train)","fc982faa":"m = RandomForestRegressor(n_estimators=300,\n                          min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n                          max_features=grid_search.best_params_['max_features'],\n                          n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train);","8c97a874":"y_test = np.exp(pd.Series(m.predict(df_test_keep))); y_test.head()","f5fbf29d":"mysubmission = pd.DataFrame({'SalePrice': y_test.values}, index=df_test.index.values)\nmysubmission.index.name = 'Id'\nmysubmission.head(10)","cc7f8d81":"pd.DataFrame.to_csv(mysubmission,'mysubmission.csv')","108d5a4e":"## Checking data and preprocessing","4d17da65":"Below, we are displaying the training and test data. This is just to spot any obvious problems. I used the display_all instead of display_small during the first run through.","aa56b069":"Note: Currently the RMSE is at 0.139 (r2 at 0.888); which places us approximately a bit below the middle of the pack (July 2019) in Kaggle (assuming the test data gives the same number).","9d595722":"From the description of the data on top, we know there are nans. We want to quickly see how much nans are in our data","de044137":"A small improvement.","c5705115":"## Using 1-hot encoding to find important features","fd06843d":"We then turn the categorical data into categorical values using the train_cats and apply_cats function","910f8aee":"As expected, TotalArea, GoodLivArea, Building Age and Remod Age are all very important.","b3ff8c25":"Note that after trial and error, it seems that TotalArea only makes the predictions worse. Therefore we only go with three of the new features.","482b2d39":"Will set limit to appoximately >0.005. This pushes the features from 82 to 27","13d30d2d":"We now redo the n_estimators=100 to see if we have any changes to the RMSE and r2_score ","ca31df5b":"We try different min_samples_leaf, max_features and set_rf_samples(1460) to see what gives a good result. Note we should really have used a grid search instead of manually searching","613ab76a":"It looks like the majority of the improvements are before 20 trees. However, there still seems to be visible (albeit small) improvements up to 100 trees or so.","59be8910":"## Running some preliminary trees and diagrams","d60d25c7":"Now we will go through the data and order the categorical variables. Actually, we don't: for some reason, this increased RMSE.","24e19aba":"We are going to run 500 estimators and look at the diminishing returns to get a feel of the number of estimators we should use","d1491f5f":"## Removing redundant features","cfbeb0e5":"The df dataframe now needs to be split into a training and validation set. We have set n_valid to be approximately 25% of the whole dataset.\n","dd0536d2":"## Loading packages and data","0d5d93dc":"#### I would greatly appreciate any help, comments and suggestions that any can give me! :)\n\n#### Note this Kernel gives 0.14022. If I am not wrong, this is not too bad for a random forest (not boosted) and with minimal feature engineering. ","6eb4232f":"Below is a function draw_tree taken from the package draw_tree. However, it wasn't working in the kaggle Kernel as it needed the imports to make it work. I just copied the source code from draw_tree","9fcac0ee":"We now use proc_df to remove the nans and split the data into the input variables (df) and the dependent variables (y). Firstly, we log our SalePrice","20c8839d":"## Improved model","a4475c56":"RMSE at 0.136 (r2 at 0.894). No change.","045016b5":"In this Kernel, I am trying to tackle the \n'House Prices: Advanced Regression Techniques problem' using a random forest. My code is based on the fastai machine learning course code (https:\/\/course18.fast.ai\/ml.html) with some edits.","64b616dc":"We plot the changes in the r2_score as we increase number of trees","7be82291":"We now check the nans again to make sure they are all zeros (no nans left).","4dae355a":"\"Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price\"","8862befc":"Looks like OverallQual gives the biggest mse difference followed Living space. That makes sense to me intuitively.","2078a5de":"Below, we are going to get the predictions of every tree in our 300 trees","08dec5ef":"Now we have a RMSE of 0.138 (r2 of 0.871).","ed87de74":"We use a dendrogram which is part of hierarchical clustering.\n\nThis is where we look at every pair of objects and see which is the closest. We then delete them and replace with the midpoint of the pair.","e466b71d":"This is an improvement.","f8c557da":"## Adding the our extra interaction features","4be708d0":"Similar. So ignore this for final model","b4727bbc":"## Looking at feature importance","f81b4049":"## Base model","f6661949":"## Testing number of estimators needed","f06e7184":"Here we want to look at feature importance and remove some useless\/redundant features ","8a42811f":"#### To do list:\n1. Total area = TotalBsmtSF + GrLivArea + GarageArea + PoolArea\n2. GoodLivArea = TotalBsmtSF + GrLivArea - LowQualFinSF\n(Got this idea from https:\/\/towardsdatascience.com\/my-first-kaggle-competition-using-random-forests-to-predict-housing-prices-76efee28d42f)\n2. Building age = YrSold - YearBuilt\n3. Remod age = YrSold - YearRemodAdd","b7f5b16b":"This is important if one class in a categorical feature is especially important. We use all features again (instead of df_keep) to check the low contribution features as well.","347aaf6a":"The only one that stands out is ExterQual_TA. Will not use one hot encoding.","0c608ba7":"Now we display the description of the data. Again, I used the display_all instead of display_small during the first run through.","da7b20d9":"1. OverallQual: Rates the overall material and finish of the house\n2. GrLiveArea: Above grade (ground) living area square feet\n3. YearBuilt: Year garage was built\n4. ExterQual: Evaluates the quality of the material on the exterior. **(We should make sure this is sorted by quality) (Perhaps also make a overall quality average - difficult to judge though)**\n5. GarageCars: Size of garage in car capacity **(We should probably make a total area feature)**\n6. GarageArea: Size of garage in square feet **(We should probably make a total area feature)**\n7. TotalBsmtSF: Total square feet of basement area **(We should probably make a total area feature)**\n8. 1stFlrSF: First Floor square feet\n9. GarageYrBlt: Year garage was built\n10. LotArea: Lot size in square feet","03f27bea":"## Final model","04c346f0":"# Predicting house prices"}}