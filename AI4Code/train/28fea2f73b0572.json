{"cell_type":{"193b0b5e":"code","b2cecb63":"code","282be674":"code","00fab4cc":"code","4579d2a8":"code","58a3ada9":"code","ae887ff9":"code","9f84fb27":"code","05961b33":"code","619928f7":"code","f93e7d95":"code","6a64439e":"code","ae35c1c0":"code","04147dac":"code","a33de06c":"code","422cd88c":"code","53a9a9b7":"code","8cd5dba9":"code","b2388b1d":"code","f84ffc8c":"code","01464f66":"code","736fdd70":"code","56027b2d":"code","194926cb":"code","34ddf844":"code","613ac51c":"code","0896de4f":"code","8fa36de2":"code","994429cc":"code","c7187638":"code","baebfc09":"code","2da172f4":"code","b93575fd":"code","c88d1bfc":"code","eeadbcf1":"code","566fb240":"markdown","9829b2eb":"markdown","dc4216ab":"markdown","650d9b87":"markdown","51bf555c":"markdown","5a1e991b":"markdown","4eb22bc2":"markdown","3ad756a5":"markdown","85d26e11":"markdown","116a5ccb":"markdown","b328ab59":"markdown","c7199891":"markdown","8c55786e":"markdown","1cf88d37":"markdown","5c2f012c":"markdown","dbb7b42d":"markdown","cf783d65":"markdown","7a1ea5c6":"markdown","985e0584":"markdown","e43874ca":"markdown","872e3fce":"markdown","8e8c0fc3":"markdown","bb6a58ba":"markdown","37012902":"markdown","7f705307":"markdown","f170d4bf":"markdown","b8b4909a":"markdown","ff9066e0":"markdown","ae014dbf":"markdown","2eba39f3":"markdown","d2429515":"markdown","b737e426":"markdown","4f5c8dac":"markdown","378b0897":"markdown","f53951db":"markdown","e6bc3a2a":"markdown","f45d3b04":"markdown","d9d7c657":"markdown"},"source":{"193b0b5e":"import numpy as np\nimport pandas as pd\nimport holoviews as hv\nfrom holoviews import opts\nhv.extension('bokeh')\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport os\nimport scipy.stats as stats\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\n!pip install changefinder\nimport changefinder\nfrom sklearn.metrics import f1_score\nimport shap\nshap.initjs()\nfrom tabulate import tabulate\nfrom IPython.display import HTML, display","b2cecb63":"for dirname, _, filenames in os.walk('\/kaggle\/input\/nab\/realKnownCause\/realKnownCause'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","282be674":"df = pd.read_csv(\"\/kaggle\/input\/nab\/realKnownCause\/realKnownCause\/machine_temperature_system_failure.csv\",low_memory=False)\nprint(f'machine_temperature_system_failure.csv : {df.shape}')\ndf.head(3)","00fab4cc":"anomaly_points = [\n        [\"2013-12-10 06:25:00.000000\",\"2013-12-12 05:35:00.000000\"],\n        [\"2013-12-15 17:50:00.000000\",\"2013-12-17 17:00:00.000000\"],\n        [\"2014-01-27 14:20:00.000000\",\"2014-01-29 13:30:00.000000\"],\n        [\"2014-02-07 14:55:00.000000\",\"2014-02-09 14:05:00.000000\"]\n]","4579d2a8":"df['timestamp'] = pd.to_datetime(df['timestamp'])\n#is anomaly? : True => 1, False => 0\ndf['anomaly'] = 0\nfor start, end in anomaly_points:\n    df.loc[((df['timestamp'] >= start) & (df['timestamp'] <= end)), 'anomaly'] = 1","58a3ada9":"df['year'] = df['timestamp'].apply(lambda x : x.year)\ndf['month'] = df['timestamp'].apply(lambda x : x.month)\ndf['day'] = df['timestamp'].apply(lambda x : x.day)\ndf['hour'] = df['timestamp'].apply(lambda x : x.hour)\ndf['minute'] = df['timestamp'].apply(lambda x : x.minute)","ae887ff9":"df.index = df['timestamp']\ndf.drop(['timestamp'], axis=1, inplace=True)\ndf.head(3)","9f84fb27":"count = hv.Bars(df.groupby(['year','month'])['value'].count()).opts(ylabel=\"Count\", title='Year\/Month Count')\nmean = hv.Bars(df.groupby(['year','month']).agg({'value': ['mean']})['value']).opts(ylabel=\"Temperature\", title='Year\/Month Mean Temperature')\n(count + mean).opts(opts.Bars(width=380, height=300,tools=['hover'],show_grid=True, stacked=True, legend_position='bottom'))","05961b33":"year_maxmin = df.groupby(['year','month']).agg({'value': ['min', 'max']})\n(hv.Bars(year_maxmin['value']['max']).opts(ylabel=\"Temperature\", title='Year\/Month Max Temperature') \\\n+ hv.Bars(year_maxmin['value']['min']).opts(ylabel=\"Temperature\", title='Year\/Month Min Temperature'))\\\n    .opts(opts.Bars(width=380, height=300,tools=['hover'],show_grid=True, stacked=True, legend_position='bottom'))","619928f7":"hv.Distribution(df['value']).opts(opts.Distribution(title=\"Temperature Distribution\", xlabel=\"Temperature\", ylabel=\"Density\", width=700, height=300,tools=['hover'],show_grid=True))","f93e7d95":"((hv.Distribution(df.loc[df['year']==2013,'value'], label='2013') * hv.Distribution(df.loc[df['year']==2014,'value'], label='2014')).opts(title=\"Temperature by Year Distribution\", legend_position='bottom') + \\\n(hv.Distribution(df.loc[df['month']==12,'value'], label='12') * hv.Distribution(df.loc[df['month']==1,'value'], label='1') \\\n     * hv.Distribution(df.loc[df['month']==2,'value'], label='2')).opts(title=\"Temperature by Month Distribution\", legend_position='bottom')) \\\n     .opts(opts.Distribution(xlabel=\"Temperature\", ylabel=\"Density\", width=380, height=300,tools=['hover'],show_grid=True))","6a64439e":"anomalies = [[ind, value] for ind, value in zip(df[df['anomaly']==1].index, df.loc[df['anomaly']==1,'value'])]\n(hv.Curve(df['value'], label=\"Temperature\") * hv.Points(anomalies, label=\"Anomaly Points\").opts(color='red', legend_position='bottom', size=2, title=\"Temperature & Given Anomaly Points\"))\\\n    .opts(opts.Curve(xlabel=\"Time\", ylabel=\"Temperature\", width=700, height=400,tools=['hover'],show_grid=True))","ae35c1c0":"hv.Curve(df['value'].resample('D').mean()).opts(opts.Curve(title=\"Temperature Mean by Day\", xlabel=\"Time\", ylabel=\"Temperature\", width=700, height=300,tools=['hover'],show_grid=True))","04147dac":"hotelling_df = pd.DataFrame()\nhotelling_df['value'] = df['value']\nmean = hotelling_df['value'].mean()\nstd = hotelling_df['value'].std()\nhotelling_df['anomaly_score'] = [((x - mean)\/std) ** 2 for x in hotelling_df['value']]\nhotelling_df['anomaly_threshold'] = stats.chi2.ppf(q=0.95, df=1)\nhotelling_df['anomaly']  = hotelling_df.apply(lambda x : 1 if x['anomaly_score'] > x['anomaly_threshold'] else 0, axis=1)","a33de06c":"(hv.Curve(hotelling_df['anomaly_score'], label='Anomaly Score') * hv.Curve(hotelling_df['anomaly_threshold'], label='Threshold').opts(color='red', line_dash=\"dotdash\")) \\\n  .opts(title=\"Hotelling's T2 - Anomaly Score & Threshold\", xlabel=\"Time\", ylabel=\"Anomaly Score\", legend_position='bottom').opts(opts.Curve(width=700, height=400, show_grid=True, tools=['hover']))","422cd88c":"anomalies = [[ind, value] for ind, value in zip(hotelling_df[hotelling_df['anomaly']==1].index, hotelling_df.loc[hotelling_df['anomaly']==1,'value'])]\n(hv.Curve(hotelling_df['value'], label=\"Temperature\") * hv.Points(anomalies, label=\"Detected Points\").opts(color='red', legend_position='bottom', size=2, title=\"Hotelling's T2 - Detected Points\"))\\\n    .opts(opts.Curve(xlabel=\"Time\", ylabel=\"Temperature\", width=700, height=400,tools=['hover'],show_grid=True))","53a9a9b7":"hotelling_f1 = f1_score(df['anomaly'], hotelling_df['anomaly'])\nprint(f'Hotelling\\'s T2 F1 Score : {hotelling_f1}')","8cd5dba9":"ocsvm_model = OneClassSVM(nu=0.2, gamma=0.001, kernel='rbf')\nocsvm_ret = ocsvm_model.fit_predict(df['value'].values.reshape(-1, 1))\nocsvm_df = pd.DataFrame()\nocsvm_df['value'] = df['value']\nocsvm_df['anomaly']  = [1 if i==-1 else 0 for i in ocsvm_ret]","b2388b1d":"anomalies = [[ind, value] for ind, value in zip(ocsvm_df[ocsvm_df['anomaly']==1].index, ocsvm_df.loc[ocsvm_df['anomaly']==1,'value'])]\n(hv.Curve(ocsvm_df['value'], label=\"Temperature\") * hv.Points(anomalies, label=\"Detected Points\").opts(color='red', legend_position='bottom', size=2, title=\"One-Class SVM - Detected Points\"))\\\n    .opts(opts.Curve(xlabel=\"Time\", ylabel=\"Temperature\", width=700, height=400,tools=['hover'],show_grid=True))","f84ffc8c":"ocsvm_f1 = f1_score(df['anomaly'], ocsvm_df['anomaly'])\nprint(f'One-Class SVM F1 Score : {ocsvm_f1}')","01464f66":"iforest_model = IsolationForest(n_estimators=300, contamination=0.1, max_samples=700)\niforest_ret = iforest_model.fit_predict(df['value'].values.reshape(-1, 1))\niforest_df = pd.DataFrame()\niforest_df['value'] = df['value']\niforest_df['anomaly']  = [1 if i==-1 else 0 for i in iforest_ret]","736fdd70":"anomalies = [[ind, value] for ind, value in zip(iforest_df[iforest_df['anomaly']==1].index, iforest_df.loc[iforest_df['anomaly']==1,'value'])]\n(hv.Curve(iforest_df['value'], label=\"Temperature\") * hv.Points(anomalies, label=\"Detected Points\").opts(color='red', legend_position='bottom', size=2, title=\"Isolation Forest - Detected Points\"))\\\n    .opts(opts.Curve(xlabel=\"Time\", ylabel=\"Temperature\", width=700, height=400,tools=['hover'],show_grid=True))","56027b2d":"sample_train = df['value'].values[np.random.randint(0, len(df['value']), (100))].reshape(-1, 1)\nexplainer = shap.TreeExplainer(model=iforest_model, feature_perturbation=\"interventional\", data=sample_train)\nshap_values = explainer.shap_values(X=sample_train)\nshap.summary_plot(shap_values=shap_values, features=sample_train, feature_names=['value'], plot_type=\"violin\")","194926cb":"iforest_f1 = f1_score(df['anomaly'], iforest_df['anomaly'])\nprint(f'Isolation Forest F1 Score : {iforest_f1}')","34ddf844":"lof_model = LocalOutlierFactor(n_neighbors=500, contamination=0.07)\nlof_ret = lof_model.fit_predict(df['value'].values.reshape(-1, 1))\nlof_df = pd.DataFrame()\nlof_df['value'] = df['value']\nlof_df['anomaly']  = [1 if i==-1 else 0 for i in lof_ret]","613ac51c":"anomalies = [[ind, value] for ind, value in zip(lof_df[lof_df['anomaly']==1].index, lof_df.loc[lof_df['anomaly']==1,'value'])]\n(hv.Curve(lof_df['value'], label=\"Temperature\") * hv.Points(anomalies, label=\"Detected Points\").opts(color='red', legend_position='bottom', size=2, title=\"LOF - Detected Points\"))\\\n    .opts(opts.Curve(xlabel=\"Time\", ylabel=\"Temperature\", width=700, height=400,tools=['hover'],show_grid=True))","0896de4f":"lof_f1 = f1_score(df['anomaly'], lof_df['anomaly'])\nprint(f'LOF F1 Score : {lof_f1}')","8fa36de2":"cf_model = changefinder.ChangeFinder(r=0.002, order=1, smooth=250)\nch_df = pd.DataFrame()\nch_df['value'] = df['value']\nch_df['anomaly_score'] = [cf_model.update(i) for i in ch_df['value']]\nch_score_q1 = stats.scoreatpercentile(ch_df['anomaly_score'], 25) \nch_score_q3 = stats.scoreatpercentile(ch_df['anomaly_score'], 75) \nch_df['anomaly_threshold'] = ch_score_q3 + (ch_score_q3 - ch_score_q1) * 3\nch_df['anomaly']  = ch_df.apply(lambda x : 1 if x['anomaly_score'] > x['anomaly_threshold'] else 0, axis=1)","994429cc":"(hv.Curve(ch_df['anomaly_score'], label='Anomaly Score') * hv.Curve(ch_df['anomaly_threshold'], label='Threshold').opts(color='red', line_dash=\"dotdash\")) \\\n  .opts(title=\"ChangeFinder - Anomaly Score & Threshold\", xlabel=\"Time\", ylabel=\"Anomaly Score\", legend_position='bottom').opts(opts.Curve(width=700, height=400, show_grid=True, tools=['hover']))","c7187638":"anomalies = [[ind, value] for ind, value in zip(ch_df[ch_df['anomaly']==1].index, ch_df.loc[ch_df['anomaly']==1,'value'])]\n(hv.Curve(ch_df['value'], label=\"Temperature\") * hv.Points(anomalies, label=\"Detected Points\").opts(color='red', legend_position='bottom', size=2, title=\"ChangeFinder - Detected Points\"))\\\n    .opts(opts.Curve(xlabel=\"Time\", ylabel=\"Temperature\", width=700, height=400,tools=['hover'],show_grid=True))","baebfc09":"ch_f1 = f1_score(df['anomaly'], ch_df['anomaly'])\nprint(f'ChangeFinder F1 Score : {ch_f1}')","2da172f4":"sigma_df = pd.DataFrame()\nsigma_df['value'] = df['value']\nstd = sigma_df['value'].std()\nsigma_df['anomaly_threshold_3r'] = mean + 1.5*std\nsigma_df['anomaly_threshold_3l'] = mean - 1.5*std\nsigma_df['anomaly']  = sigma_df.apply(lambda x : 1 if (x['value'] > x['anomaly_threshold_3r']) or (x['value'] < x['anomaly_threshold_3l']) else 0, axis=1)","b93575fd":"anomalies = [[ind, value] for ind, value in zip(sigma_df[sigma_df['anomaly']==1].index, sigma_df.loc[sigma_df['anomaly']==1,'value'])]\n(hv.Curve(sigma_df['value'], label=\"Temperature\") * hv.Points(anomalies, label=\"Detected Points\").opts(color='red', legend_position='bottom', size=2, title=\"Variance Based Method - Detected Points\"))\\\n    .opts(opts.Curve(xlabel=\"Time\", ylabel=\"Temperature\", width=700, height=400,tools=['hover'],show_grid=True))","c88d1bfc":"sigma_f1 = f1_score(df['anomaly'], sigma_df['anomaly'])\nprint(f'Variance Based Method F1 Score : {sigma_f1}')","eeadbcf1":"display(HTML('<h3>Evaluation - F1 Score<\/h3>'+tabulate([['F1 Score', hotelling_f1, ocsvm_f1, iforest_f1, lof_f1, ch_f1, sigma_f1]],\\\n                      [\"\", \"Hotelling's T2\", \"One-Class SVM\", 'Isolation Forest', 'LOF', 'ChangeFinder', 'Variance Based Method'], tablefmt=\"html\")))","566fb240":"# 2. Import libraries","9829b2eb":"# 8. References\n> * **NAB Anomaly Points References**  \n> https:\/\/github.com\/numenta\/NAB\/blob\/master\/labels\/combined_windows.json  \n> * **Anomaly Detection Learning Resources**  \n> https:\/\/github.com\/yzhao062\/anomaly-detection-resources  \n> * **PyOD documentation**  \n> https:\/\/pyod.readthedocs.io\/en\/latest\/  \n> * **Anomaly Detection Toolkit documentation**  \n> https:\/\/arundo-adtk.readthedocs-hosted.com\/en\/latest\/  ","dc4216ab":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","650d9b87":"## Model2. One-Class SVM\n><div class=\"alert alert-info\" role=\"alert\">\n><ul>\n><li>Unsupervised kernel-based anomaly detection method.<\/li>\n><\/ul>\n><\/div>","51bf555c":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","5a1e991b":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","4eb22bc2":"## Datetime Information","3ad756a5":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","85d26e11":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","116a5ccb":"# 3. Load the dataset\n>As above, we use 'machine_temperature_system_failure.csv' for our analysis.  \n>According to dataset information, it has the following features : \n>* Temperature sensor data of an internal component of a large, industrial mahcine.\n>* The first anomaly is a planned shutdown of the machine. \n>* The second anomaly is difficult to detect and directly led to the third anomaly, a catastrophic failure of the machine.","b328ab59":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","c7199891":"# 1. Overview\n## Project Detail\n>In this project, we use [NAB-dataset](https:\/\/www.kaggle.com\/boltzmannbrain\/nab), which is a novel benchmark for evaluating algorithms for anomaly detection in several fields.  \n>There are 58 timeseries data from various kind of sources.\n>* **Real data**\n>    * realAWSCloudwatch\n>    * realAdExchange\n>    * realKnownCause\n>    * realTraffic\n>    * realTweets\n>* **Artificial data**\n>    * artificialNoAnomaly\n>    * artificialWithAnomaly\n>\n>In these dataset above, I picked up and analyzed **'machine_temperature_system_failure'** from realKnownCause dataset based on my buissiness interests.  \n>This dataset does not include acutual anomaly point, so we need to refer to the [NAB github page](https:\/\/github.com\/numenta\/NAB\/blob\/master\/labels\/combined_windows.json).\n\n## Goal of this notebook\n>* Practice data pre-processing technique\n>* Practice EDA technique to deal with time-series data\n>* Practice visualising technique\n>* Practice anomaly detection modeling technique\n>    * from simple techniques to complex techniques\n>* Practice improving model interpretability technique\n>    * SHAP","8c55786e":"# Table of Contents<a id='top'><\/a>\n>1. [Overview](#1.-Overview)  \n>    * [Project Detail](#Project-Detail)\n>    * [Goal of this notebook](#Goal-of-this-notebook)\n>1. [Import libraries](#2.-Import-libraries)\n>1. [Load the dataset](#3.-Load-the-dataset)\n>1. [Pre-processing](#4.-Pre-processing)\n>    * [Anomaly Points](#Anomaly-Points)\n>    * [Datetime Information](#Datetime-Information)\n>1. [EDA](#5.-EDA)  \n>    * [Basic Analysis](#Basic-Analysis)\n>    * [Time Series Analysis](#Time-Series-Analysis)\n>1. [Modeling](#6.-Modeling)\n>    * [Model1. Hotelling's T2](#Model1.-Hotelling's-T2)\n>    * [Model2. One-Class SVM](#Model2.-One\\-Class-SVM)\n>    * [Model3. Isolation Forest](#Model3.-Isolation-Forest)\n>    * [Model4. LOF](#Model4.-LOF)\n>    * [Model5. ChangeFinder](#Model5.-ChangeFinder)\n>    * [Model6. Variance Based Method](#Model6.-Variance-Based-Method)\n>    * [Model Comparison](#Model-Comparison)\n>1. [Conclusion](#7.-Conclusion)\n>1. [References](#8.-References)","1cf88d37":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","5c2f012c":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","dbb7b42d":"## Model1. Hotelling's T2\n><div class=\"alert alert-info\" role=\"alert\">\n><ul>\n><li>Basic anomaly detection method based on statustics.<\/li>\n><\/ul>\n><\/div>","cf783d65":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","7a1ea5c6":"<h2 style=\"text-align:center;font-size:200%;;\">Industrial  Machine Anomaly Detection<\/h2>\n<h3  style=\"text-align:center;\">Keywords : <span class=\"label label-success\">IoT<\/span> <span class=\"label label-success\">Anomaly Detection<\/span> <span class=\"label label-success\">Model Interpretability<\/span> <span class=\"label label-success\">Model Comparison<\/span><\/h3>","985e0584":"# 4. Pre-processing","e43874ca":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","872e3fce":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","8e8c0fc3":"## Model4. LOF\n><div class=\"alert alert-info\" role=\"alert\">\n><ul>\n><li>Unsupervised density-based anomaly detection method, which measures the local deviation of density of a given sample with respect to its neighbors.<\/li>\n><\/ul>\n><\/div>","bb6a58ba":"## Anomaly Points\n>We can get anomaly points information [here](https:\/\/github.com\/numenta\/NAB\/blob\/master\/labels\/combined_windows.json)","37012902":"## Model6. Variance Based Method\n><div class=\"alert alert-info\" role=\"alert\">\n><ul>\n><li>This is variance based method with assumption of the normal distribution against the data.<\/li>\n><\/ul>\n><\/div>","7f705307":"## Model Comparison","f170d4bf":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","b8b4909a":"# 5. EDA","ff9066e0":"## Model3. Isolation Forest\n><div class=\"alert alert-info\" role=\"alert\">\n><ul>\n><li>Unsupervised tree-based anomaly detection method.<\/li>\n><\/ul>\n><\/div>","ae014dbf":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","2eba39f3":">plot temperature & its given anomaly points.","d2429515":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","b737e426":"# 6. Modeling\n>We will build several anomaly detection models and compare them each other.","4f5c8dac":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","378b0897":"# 7. Conclusion\n><div class=\"alert alert-success\" role=\"alert\">\n><ul>\n><li>The model built with <b>simple algorithms<\/b> resulted in high accuracy.<\/li>\n><li>It is considered that a simple algorithm is effective in many cases <u>for time-series data having a simple structure<\/u> such as a constant mean and variance over time.<\/li>\n><li>Complex and robust algorithms are considered to be effective <u>when time-series has complicated patterns or when there are various anomolous patterns<\/u>.<\/li>\n><\/ul>\n>In this analysis, the model was evaluated based on the F1 score, but if you want to make <b>a more business-oriented evaluation<\/b>, the following viewpoints should be added to the evaluation.\n><ul>\n><li>Detection of signs of anomalies<\/li>\n><li>Balance of importance of false positive and false negative<\/li>\n><li>Model interpretability<\/li>\n><\/ul>\n><\/div>","f53951db":"## Time Series Analysis","e6bc3a2a":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents<\/a>","f45d3b04":"## Basic Analysis","d9d7c657":"## Model5. ChangeFinder\n><div class=\"alert alert-info\" role=\"alert\">\n><ul>\n><li>Change detection method based on SDAR model.<\/li>\n><\/ul>\n><\/div>"}}