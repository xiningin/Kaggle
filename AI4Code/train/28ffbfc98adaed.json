{"cell_type":{"10655cfc":"code","0c181fe7":"code","74c32c0c":"code","0cbb2ddc":"code","6f634f0d":"code","723ed616":"code","16a2c261":"code","22275132":"code","459fc486":"code","c9171e51":"code","edfc7f6b":"code","4991e5b9":"code","ff07b6bb":"code","60907879":"code","6283e152":"code","0a5c3c3b":"code","28eafdd7":"code","75b7178e":"code","601085ee":"code","cab9aa52":"code","d4828ea5":"code","c93e4ea9":"code","ffade093":"code","20c57a81":"code","9436d0ce":"code","a5a9d6b9":"code","730f330e":"code","0ec2e5ac":"code","7f93d452":"code","845252b9":"code","9498fdb3":"code","270c3c19":"code","45f8d8db":"code","b6ee13aa":"markdown","1dc110cb":"markdown","b238d35d":"markdown","568e6ff1":"markdown","8f697387":"markdown","ebbf2965":"markdown","0e99ab2f":"markdown","f4dcaef9":"markdown","9080e540":"markdown","b73f8bcb":"markdown","ff3e806d":"markdown","7d5386b5":"markdown","47b7cae2":"markdown","9d3a394b":"markdown","95efc984":"markdown"},"source":{"10655cfc":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\n\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom plotly import graph_objs as go\nimport requests\n\nfrom plotly import __version__\nprint(__version__) # need 1.9.0 or greater\ninit_notebook_mode(connected = True)\n\n\ndef plotly_df(df, title = ''):\n    data = []\n    \n    for column in df.columns:\n        trace = go.Scatter(\n            x = df.index,\n            y = df[column],\n            mode = 'lines',\n            name = column\n        )\n        data.append(trace)\n    \n    layout = dict(title = title)\n    fig = dict(data = data, layout = layout)\n    iplot(fig, show_link=False)","0c181fe7":"df = pd.read_csv('..\/input\/wiki_machine_learning.csv', sep = ' ')\ndf = df[df['count'] != 0]\ndf.head()","74c32c0c":"df.shape","0cbb2ddc":"df.date = pd.to_datetime(df.date)","6f634f0d":"plotly_df(df.set_index('date')[['count']])","723ed616":"from fbprophet import Prophet","16a2c261":"predictions = 30\n\ndf = df[['date', 'count']]\ndf.columns = ['ds', 'y']\ndf.tail()","22275132":"train_df = df[:-predictions].copy()","459fc486":"m = Prophet()\nm.fit(train_df);","c9171e51":"future = m.make_future_dataframe(periods=predictions)\nfuture.tail()","edfc7f6b":"forecast = m.predict(future)\nforecast.tail()","4991e5b9":"m.plot(forecast)","ff07b6bb":"m.plot_components(forecast)","60907879":"cmp_df = forecast.set_index('ds')[['yhat', 'yhat_lower', 'yhat_upper']].join(df.set_index('ds'))","6283e152":"import numpy as np\ncmp_df['e'] = cmp_df['y'] - cmp_df['yhat']\ncmp_df['p'] = 100 * cmp_df['e'] \/ cmp_df['y']\nprint('MAPE = ', round(np.mean(abs(cmp_df[-predictions:]['p'])), 2))\nprint('MAE = ', round(np.mean(abs(cmp_df[-predictions:]['e'])), 2))","0a5c3c3b":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport statsmodels.api as sm\nplt.rcParams['figure.figsize'] = (15, 10)","28eafdd7":"sm.tsa.seasonal_decompose(train_df['y'].values, freq=7).plot();\nprint(\"Dickey-Fuller test: p=%f\" % sm.tsa.stattools.adfuller(train_df['y'])[1])","75b7178e":"train_df.set_index('ds', inplace=True)","601085ee":"train_df['y_diff'] = train_df.y - train_df.y.shift(7)\nsm.tsa.seasonal_decompose(train_df.y_diff[7:].values, freq=7).plot();\nprint(\"Dickey-Fuller test: p=%f\" % sm.tsa.stattools.adfuller(train_df.y_diff[8:])[1])","cab9aa52":"ax = plt.subplot(211)\nsm.graphics.tsa.plot_acf(train_df.y_diff[13:].values.squeeze(), lags=48, ax=ax)\n\nax = plt.subplot(212)\nsm.graphics.tsa.plot_pacf(train_df.y_diff[13:].values.squeeze(), lags=48, ax=ax)","d4828ea5":"ps = range(0, 2)\nds = range(0, 2)\nqs = range(0, 4)\nPs = range(0, 4)\nDs = range(0, 3)\nQs = range(0, 2)","c93e4ea9":"from itertools import product\n\nparameters = product(ps, ds, qs, Ps, Ds, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)","ffade093":"%%time\nimport warnings\nfrom tqdm import tqdm\nresults1 = []\nbest_aic = float(\"inf\")\nwarnings.filterwarnings('ignore')\n\nfor param in tqdm(parameters_list):\n    #try except is necessary, because on some sets of parameters the model can not be trained\n    try:\n        model=sm.tsa.statespace.SARIMAX(train_df['y'], order=(param[0], param[1], param[2]), \n                                        seasonal_order=(param[3], param[4], param[5], 7)).fit(disp=-1)\n    #print parameters on which the model is not trained and proceed to the next set\n    except (ValueError, np.linalg.LinAlgError):\n        continue\n    aic = model.aic\n    #save the best model, aic, parameters\n    if aic < best_aic:\n        best_model = model\n        best_aic = aic\n        best_param = param\n    results1.append([param, model.aic])","20c57a81":"result_table1 = pd.DataFrame(results1)\nresult_table1.columns = ['parameters', 'aic']\nprint(result_table1.sort_values(by = 'aic', ascending=True).head())","9436d0ce":"result_table1[result_table1['parameters'].isin([(1, 0, 2, 3, 1, 0),\n                                                (1, 1, 2, 3, 2, 1),\n                                                (1, 1, 2, 3, 1, 1),\n                                                (1, 0, 2, 3, 0, 0)])]","a5a9d6b9":"import scipy.stats\ntrain_df['y_box'], lmbda = scipy.stats.boxcox(train_df['y']) \nprint(\"The optimal Box-Cox transformation parameter: %f\" % lmbda)","730f330e":"results2 = []\nbest_aic = float(\"inf\")\n\nfor param in tqdm(parameters_list):\n    #try except is necessary, because on some sets of parameters the model can not be trained\n    try:\n        model=sm.tsa.statespace.SARIMAX(train_df['y_box'], order=(param[0], param[1], param[2]), \n                                        seasonal_order=(param[3], param[4], param[5], 7)).fit(disp=-1)\n    #print parameters on which the model is not trained and proceed to the next set\n    except (ValueError, np.linalg.LinAlgError):\n        continue\n    aic = model.aic\n    #save the best model, aic, parameters\n    if aic < best_aic:\n        best_model = model\n        best_aic = aic\n        best_param = param\n    results2.append([param, model.aic])\n    \nwarnings.filterwarnings('default')","0ec2e5ac":"result_table2 = pd.DataFrame(results2)\nresult_table2.columns = ['parameters', 'aic']\nprint(result_table2.sort_values(by = 'aic', ascending=True).head())","7f93d452":"result_table2[result_table2['parameters'].isin([(1, 0, 2, 3, 1, 0),\n                                                (1, 1, 2, 3, 2, 1),\n                                                (1, 1, 2, 3, 1, 1),\n                                                (1, 0, 2, 3, 0, 0)])].sort_values(by='aic')","845252b9":"print(best_model.summary())","9498fdb3":"plt.subplot(211)\nbest_model.resid[13:].plot()\nplt.ylabel(u'Residuals')\n\nax = plt.subplot(212)\nsm.graphics.tsa.plot_acf(best_model.resid[13:].values.squeeze(), lags=48, ax=ax)\n\nprint(\"Student's test: p=%f\" % stats.ttest_1samp(best_model.resid[13:], 0)[1])\nprint(\"Dickey-Fuller test: p=%f\" % sm.tsa.stattools.adfuller(best_model.resid[13:])[1])","270c3c19":"def invboxcox(y,lmbda):\n    # reverse Box Cox transformation\n    if lmbda == 0:\n        return(np.exp(y))\n    else:\n        return(np.exp(np.log(lmbda * y + 1) \/ lmbda))","45f8d8db":"train_df['arima_model'] = invboxcox(best_model.fittedvalues, lmbda)\n\ntrain_df.y.tail(200).plot()\ntrain_df.arima_model[13:].tail(200).plot(color='r')\nplt.ylabel('wiki pageviews');","b6ee13aa":"<center>\n<img src=\"https:\/\/habrastorage.org\/files\/fd4\/502\/43d\/fd450243dd604b81b9713213a247aa20.jpg\">\n## [mlcourse.ai](https:\/\/mlcourse.ai) \u2013 Open Machine Learning Course \n<center>Author: [Mariya Mansurova](https:\/\/www.linkedin.com\/in\/mariya-mansurova-04070982\/), analyst & developer in Yandex.Metrics team. <br>Translated by [Ivan Zakharov](https:\/\/www.linkedin.com\/in\/ivan-zakharov\/), ML enthusiast.\n<br>All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/) license.","1dc110cb":"Initial values:\n* Q = 1\n* q = 3\n* P = 3\n* p = 1","b238d35d":"If we consider the variants proposed in the form:","568e6ff1":"## Data preparation","8f697387":"**<font color='red'>Question 1:<\/font>** What is the prediction of the number of views of the wiki page on January 20? Round to the nearest integer.\n\n- 4947\n- 3426 **[+]**\n- 5229\n- 2744","ebbf2965":"But the seasonally differentiated series will already be stationary.","0e99ab2f":"Now do the same, but for the series with Box-Cox transformation.","f4dcaef9":"Estimate the quality of the prediction with the last 30 points.\n\n**<font color='red'>Question 2:<\/font> What is MAPE equal to?**\n\n- 34.5 **[+]**\n- 42.42\n- 5.39\n- 65.91\n\n**<font color='red'>Question 3:<\/font> What is MAE equal to?**\n\n- 355\n- 4007\n- 600 **[+]**\n- 903","9080e540":"**Next, we turn to the construction of the SARIMAX model (`sm.tsa.statespace.SARIMAX`).<br> <font color='red'>Question 5:<\/font> What parameters are the best for the model according to the `AIC` criterion?**\n\n- D = 1, d = 0, Q = 0, q = 2, P = 3, p = 1\n- D = 2, d = 1, Q = 1, q = 2, P = 3, p = 1 **[+]**\n- D = 1, d = 1, Q = 1, q = 2, P = 3, p = 1\n- D = 0, d = 0, Q = 0, q = 2, P = 3, p = 1","b73f8bcb":"**<font color='red'>Question 4:<\/font> Let's verify the stationarity of the series using the Dickey-Fuller test. Is the series stationary? What is the p-value?**\n\n- Series is stationary, p_value = 0.107\n- Series is not stationary, p_value = 0.107 **[+]**\n- Series is stationary, p_value = 0.001\n- Series is not stationary, p_value = 0.001","ff3e806d":"## Predicting with ARIMA","7d5386b5":"If we consider the variants proposed in the form:","47b7cae2":"Let's look at the forecast of the best AIC model.","9d3a394b":"## Predicting with FB Prophet\nWe will train at first 5 months and predict the number of trips for June.","95efc984":"# <center> Assignment #9 (demo). Solution\n## <center> Time series analysis\n\n**Fill cells marked with \"Your code here\" and submit your answers to the questions through the [web form](https:\/\/docs.google.com\/forms\/d\/1UYQ_WYSpsV3VSlZAzhSN_YXmyjV7YlTP8EYMg8M8SoM\/edit).**"}}