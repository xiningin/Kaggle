{"cell_type":{"8bbb53ed":"code","b0bfa161":"code","23a65a8c":"code","23482e84":"code","0ba29d35":"code","2b36d825":"code","62ca9737":"code","00b60fca":"code","f1079c9a":"code","5d51f38b":"code","510561aa":"code","23ccd05a":"code","49c2e50f":"code","dcc0476d":"code","a2223be5":"code","5192d0df":"code","aeda4c38":"code","b8e496bc":"code","08fcc6bf":"code","1622995c":"code","c53c2021":"code","4a17fe70":"code","c83eb61c":"code","d2dcd850":"code","bd748597":"code","944fa74d":"code","1cb11acf":"code","f70584be":"code","c21f77f4":"code","8c7e8ba7":"code","ed4d43a6":"code","bd521491":"code","d585c0bd":"code","2129bfa5":"code","79845db0":"code","9f50abe5":"code","31a3ca43":"code","a09126a0":"code","98f045b9":"code","9c981caa":"code","b7235f14":"code","3cce68c0":"code","58779fe9":"code","8d18bf15":"code","bbe6c446":"code","692df11d":"code","23acc4ba":"code","b8d090ec":"code","4fedff01":"code","39419c85":"code","948182ed":"code","e77ceee7":"code","faeac606":"code","db90de47":"code","2a2aa8af":"code","48ae0849":"code","b32144cd":"code","3b4886bc":"code","181468e2":"code","866ccbd0":"code","9bd3de2f":"code","f5da6a9f":"code","efe2270b":"code","1b66572c":"code","aec6d475":"code","054d593f":"code","41bd3afc":"markdown","9579511d":"markdown","fb53d26a":"markdown","82bf83c5":"markdown","d4a0215c":"markdown","3be2e23d":"markdown","f18bec4d":"markdown","e33393ff":"markdown","941ccc72":"markdown","d5107b0c":"markdown","09830d9a":"markdown","443b4707":"markdown","f7c62f96":"markdown","8f2c6893":"markdown","da0b47e4":"markdown","bd9efd88":"markdown","2e502f09":"markdown","c33063f5":"markdown","261bb117":"markdown","ef3582a1":"markdown","e03f58fe":"markdown","1214c073":"markdown","476c9f70":"markdown","01e6d7a3":"markdown","9adf7bc9":"markdown","4e2e827a":"markdown","80e82dfb":"markdown"},"source":{"8bbb53ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b0bfa161":"!pip install seaborn --upgrade","23a65a8c":"#import libraries\n\nimport datetime as dt\nimport matplotlib.pyplot as plt\n%matplotlib inline","23482e84":"import seaborn as sns","0ba29d35":"sns.__version__","2b36d825":"train = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/train.csv.zip\",index_col=\"Id\")\ntest = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/test.csv.zip\",index_col=\"Id\")","62ca9737":"print(\"train set shape : \",train.shape)\nprint(\"test set shape : \",test.shape)","00b60fca":"print(\"train set number of null value : \",train.isnull().sum().sum())\nprint(\"test set number of null value : \",test.isnull().sum().sum())\nprint(\"No missing value in both dataset\")","f1079c9a":"train.describe()","5d51f38b":"test.describe()","510561aa":"train.columns","23ccd05a":"train.select_dtypes(exclude=\"number\")","49c2e50f":"train[\"City\"].unique()","dcc0476d":"train.City.nunique()","a2223be5":"train[\"Type\"].unique()","5192d0df":"train[\"City Group\"].unique()","aeda4c38":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(10, 6))\nplt.title(\"Restaurant Type and Revenue\")\nsns.boxplot(y=\"revenue\",x=\"Type\",data=train)","b8e496bc":"train.groupby(by=\"Type\").revenue.median()","08fcc6bf":"train.groupby(by=\"Type\").revenue.mean()","1622995c":"train.Type.value_counts()","c53c2021":"test.Type.value_counts()","4a17fe70":"plt.figure(figsize=(15, 10))\nplt.subplot(2, 2, 1)\nplt.title(label=\"Test Set City Group Count\")\nsns.countplot(x=\"Type\", data=test)\nplt.subplot(2,2,2)\nplt.title(label=\"Train Set City Group Count\")\nsns.countplot(x=\"Type\", data=train)","c83eb61c":"print(\"Train Set Type Inline Percentage : \",100*len(train.loc[train.Type==\"IL\"])\/len(train),\"%\")\nprint(\"Train Set Type Food Court Percentage : \",100*len(train.loc[train.Type==\"FC\"])\/len(train),\"%\")\nprint(\"Train Set Type Drive Thru Percentage : \",100*len(train.loc[train.Type==\"DT\"])\/len(train),\"%\")\nprint(\"Test Set Type Inline Percentage : \",100*len(test.loc[test.Type==\"IL\"])\/len(test),\"%\")\nprint(\"Test Set Type Food Court Percentage : \",100*len(test.loc[test.Type==\"FC\"])\/len(test),\"%\")\nprint(\"Test Set Type Drive Thru Percentage : \",100*len(test.loc[test.Type==\"DT\"])\/len(test),\"%\")\nprint(\"Test Set Type Mobile Percentage : \",100*len(test.loc[test.Type==\"MB\"])\/len(test),\"%\")","d2dcd850":"#move to bivariate later\n# sns.set_style(\"whitegrid\")\n# plt.figure(figsize=(16, 6))\n# plt.title(\"City Group and Revenue\")\n# sns.boxplot(y=\"revenue\",x=\"City Group\",data=train)","bd748597":"train.groupby(by=\"City Group\").revenue.median()","944fa74d":"train.groupby(by=\"City Group\").revenue.mean()","1cb11acf":"plt.figure(figsize=(15, 10))\nplt.subplot(2, 2, 1)\nplt.title(label=\"Test Set City Group Count\")\nsns.countplot(x=\"City Group\", data=test)\nplt.subplot(2,2,2)\nplt.title(label=\"Train Set City Group Count\")\nsns.countplot(x=\"City Group\", data=train)","f70584be":"print(\"Train Set Big Cities Percentage : \",100*len(train.loc[train[\"City Group\"]==\"Big Cities\"])\/len(train),\"%\")\nprint(\"Train Set Other Percentage : \",100*len(train.loc[train[\"City Group\"]==\"Other\"])\/len(train),\"%\")\nprint(\"Test Set Big Cities Percentage : \",100*len(test.loc[test[\"City Group\"]==\"Big Cities\"])\/len(test),\"%\")\nprint(\"Test Set Other Percentage : \",100*len(test.loc[test[\"City Group\"]==\"Other\"])\/len(test),\"%\")","c21f77f4":"#move to bivariate later\n# plt.figure(figsize=(40, 6))\n# plt.title(label=\"City and Revenue\")\n# sns.boxplot(y=\"revenue\",x=\"City\",data=train)","8c7e8ba7":"train.groupby(by=\"City\").revenue.median()","ed4d43a6":"train.City.unique()\nprint(len(train.City.unique()))","bd521491":"print(test.City.unique())\nprint(len(test.City.unique()))","d585c0bd":"solo_set_city=[]\nfor i in test.City.unique().tolist()+train.City.unique().tolist():\n    if i not in train.City.unique() or i not in test.City.unique():\n         solo_set_city.append(i)\nprint(solo_set_city)\nprint(len(solo_set_city))","2129bfa5":"plt.figure(figsize=(40, 6))\nplt.title(label=\"Train Set City Count\")\nsns.countplot(x=\"City\", data=train)","79845db0":"for city in train.City.unique():\n    print(\"Train Set \"+str(city)+\" Percentage : \",100*len(train.loc[train[\"City\"]==city])\/len(train),\"%\")","9f50abe5":"plt.figure(figsize=(40, 6))\nplt.title(label=\"Test Set City Count\")\nsns.countplot(x=\"City\", data=test)","31a3ca43":"for city in test.City.unique():\n    print(\"Test Set \"+str(city)+\" Percentage : \",100*len(test.loc[test[\"City\"]==city])\/len(test),\"%\")","a09126a0":"num_cols = train.select_dtypes(include=\"number\").drop('revenue',axis=1).columns\nlen(num_cols)","98f045b9":"train.P1.describe()","9c981caa":"# f, axes = plt.subplots(13, 6,figsize=(40,40))\n\n# for j in range(len(axes)):\n#     count=0\n#     for i in range(0,3):\n#         if j*3+i >=37:\n#             break\n#         sns.violinplot(  y=num_cols[j*3+i], data=train ,ax=axes[j,i+count],cut=0)\n#         axes[j,i+count].set_title(num_cols[j*3+i]+\"Train\")\n#         axes[j,i+count].set_ylim(min(test[num_cols[j*3+i]].min(),train[num_cols[j*3+i]].min()), max(test[num_cols[j*3+i]].max(),train[num_cols[j*3+i]].max()))\n#         count+=1\n#         sns.violinplot(  y=num_cols[j*3+i], data=test,ax=axes[j,i+count],cut=0)\n#         axes[j,i+count].set_title(num_cols[j*3+i]+\"Test\")\n#         axes[j,i+count].set_ylim(min(test[num_cols[j*3+i]].min(),train[num_cols[j*3+i]].min()), max(test[num_cols[j*3+i]].max(),train[num_cols[j*3+i]].max()))\n    ","b7235f14":"#checking\nsns.violinplot(y=\"P25\",data=train,cut=0)","3cce68c0":"test.P3.unique()","58779fe9":"for i in num_cols:\n    print(train[i].value_counts())","8d18bf15":"for i in num_cols:\n    print(test[i].value_counts())","bbe6c446":"#plotting histogram of same features with train and test set back to back\n# f, axes = plt.subplots(13, 6,figsize=(60,80))\n# for j in range(len(axes)):\n#     count=0\n#     for i in range(0,3):\n#         if j*3+i >= 37:\n#             break\n#         sns.histplot(  x=num_cols[j*3+i], data=train ,ax=axes[j,i+count], discrete=True)\n#         axes[j,i+count].set_title(num_cols[j*3+i]+\"Train\")\n#         axes[j,i+count].set_xlim(min(test[num_cols[j*3+i]].min(),train[num_cols[j*3+i]].min()), max(test[num_cols[j*3+i]].max(),train[num_cols[j*3+i]].max()))\n#         count+=1\n#         sns.histplot(  x=num_cols[j*3+i], data=test,ax=axes[j,i+count] ,discrete=True)\n#         axes[j,i+count].set_title(num_cols[j*3+i]+\"Test\")\n#         axes[j,i+count].set_xlim(min(test[num_cols[j*3+i]].min(),train[num_cols[j*3+i]].min()), max(test[num_cols[j*3+i]].max(),train[num_cols[j*3+i]].max()))\n# plt.tight_layout()\n# plt.show()","692df11d":"train[\"open_dt\"]=pd.to_datetime(train['Open Date'])\ntest[\"open_dt\"]=pd.to_datetime(test['Open Date'])\ntrain.drop('Open Date',axis=1,inplace=True)\ntest.drop('Open Date',axis=1,inplace=True)","23acc4ba":"f, axes = plt.subplots(1, 2,figsize=(12,5))\nsns.histplot(x=\"open_dt\",data=train,ax=axes[0],bins=12)\nsns.histplot(x=\"open_dt\",data=test,ax=axes[1],bins=12)","b8d090ec":"train['year']=pd.DatetimeIndex(train['open_dt']).year\ntest['year']=pd.DatetimeIndex(test['open_dt']).year\nf, axes = plt.subplots(1, 2,figsize=(40,10))\nsns.histplot(x=\"year\",data=train,ax=axes[0],discrete=True)\naxes[0].set_xlim(1995,2014)\naxes[0].set_xticks(range(1995,2015))\n\nsns.histplot(x=\"year\",data=test,ax=axes[1],discrete=True)\naxes[1].set_xlim(1995,2014)\naxes[1].set_xticks(range(1995,2015))","4fedff01":"#train set distribution\nfor year in sorted(train.year.unique(),reverse=True):\n    print(\"Train Set \"+str(year)+\" Percentage : \",100*len(train.loc[train[\"year\"]==year])\/len(train),\"%\")\n    check+=100*len(train.loc[train[\"year\"]==year])\/len(train)","39419c85":"#test set distribution\nfor year in sorted(test.year.unique(),reverse=True):\n    print(\"Test Set \"+str(year)+\" Percentage : \",100*len(test.loc[test[\"year\"]==year])\/len(test),\"%\")\n    summa+=100*len(test.loc[test[\"year\"]==year])\/len(test)","948182ed":"train['day']=pd.DatetimeIndex(train['open_dt']).day\ntest['day']=pd.DatetimeIndex(test['open_dt']).day\nf, axes = plt.subplots(1, 2,figsize=(40,10))\nsns.histplot(x=\"day\",data=train,ax=axes[0],discrete=True)\naxes[0].set_xlim(1,31)\naxes[0].set_xticks(range(0,33))\n\nsns.histplot(x=\"day\",data=test,ax=axes[1],discrete=True)\naxes[1].set_xlim(1,31)\naxes[1].set_xticks(range(0,33))","e77ceee7":"for day in sorted(test.day.unique(),reverse=True):\n    print(\"Train Set \"+str(day)+\" Percentage : \",100*len(train.loc[train[\"day\"]==day])\/len(train),\"%\")\n    print(\"Test Set \"+str(day)+\" Percentage : \",100*len(test.loc[test[\"day\"]==day])\/len(test),\"%\")","faeac606":"train[\"month\"]=pd.DatetimeIndex(train['open_dt']).month\ntest['month']=pd.DatetimeIndex(test['open_dt']).month\nf, axes = plt.subplots(1, 2,figsize=(40,10))\nsns.histplot(x=\"month\",data=train,ax=axes[0],discrete=True)\naxes[0].set_xlim(1,12)\naxes[0].set_xticks(range(0,14))\n\nsns.histplot(x=\"month\",data=test,ax=axes[1],discrete=True)\naxes[1].set_xlim(1,12)\naxes[1].set_xticks(range(0,14))","db90de47":"for month in sorted(test.month.unique(),reverse=True):\n    print(\"Train Set \"+str(month)+\" Percentage : \",100*len(train.loc[train[\"month\"]==month])\/len(train),\"%\")\n    print(\"Test Set \"+str(month)+\" Percentage : \",100*len(test.loc[test[\"month\"]==month])\/len(test),\"%\")","2a2aa8af":"train.columns","48ae0849":"cols=list(train.columns)\ncols.remove('revenue')\ncols=cols[3:]+cols[0:3]\ncols.append('revenue')\ncols","b32144cd":"train","3b4886bc":"train=train[cols]","181468e2":"train.columns","866ccbd0":"corr=train.corr()\nplt.figure(figsize=(40,20))\nsns.heatmap(corr,annot=True)","9bd3de2f":"test.columns","f5da6a9f":"test.columns\ntest_cols=list(test.columns)[3:]+list(test.columns)[0:3]\nlen(test_cols)","efe2270b":"test=test[test_cols]","1b66572c":"corr=test.corr()\nplt.figure(figsize=(40,20))\nsns.heatmap(corr,annot=True)","aec6d475":"ax = sns.barplot(x=\"City Group\", y=\"revenue\", hue=\"Type\", data=train)","054d593f":"train.select_dtypes(exclude='number')","41bd3afc":"Could possibly merge this feature with City Group","9579511d":"Relationship: Investigate Relationship between type and revenue","fb53d26a":"Proportion are similar but with a +-6 % difference on both variable","82bf83c5":"Analysis date later","d4a0215c":"Restaurant in Big Cities has more revenue than those in Other as expected","3be2e23d":"Seems like data in test set are a lot more discrete than train. Lets dig deeper","f18bec4d":"Correlation in train set are much more significant than in test set in simmilar regions on the heatmap","e33393ff":"Test and Train Set Count","941ccc72":"# Univariate Analysis for Categorical Variable","d5107b0c":"Investigate City in both test and train set","09830d9a":"All these numerical columns are discrete","443b4707":"Distribution a bit off but could due to different bins location\nWe will come back to this later","f7c62f96":"Outlier Detection","8f2c6893":"Inline has the highest median but Food Court has the highest mean","da0b47e4":"# Dataset Basic Info","bd9efd88":"Comment: We could merge cities and city group feature later","2e502f09":"Test Set has a lot of more cities than train set","c33063f5":"*Categorical Columns*","261bb117":"It is fairly obvious that all features in both sets follow similar distribution (or we could do chi-squared test later)","ef3582a1":"Assign year column","e03f58fe":"Tha Above cities only present in either train or test set once","1214c073":"https:\/\/radiant-brushlands-42789.herokuapp.com\/towardsdatascience.com\/walking-through-a-linear-regression-dca9942111e4","476c9f70":"# Bivarate Analysis","01e6d7a3":"train and test set have pretty much the same proportion but test set has on more label[](http:\/\/)","9adf7bc9":"It is hard to say whether month or day in test set follows similar distribution.","4e2e827a":"# Univariate Analysis for continuous variable","80e82dfb":"test set has one more element than train set. Be careful when apply encoding"}}