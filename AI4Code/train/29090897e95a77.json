{"cell_type":{"914a4c31":"code","1d789c2e":"code","d8d25b37":"code","fde885ad":"code","8062175e":"code","c90227c0":"code","01e81b7f":"code","06ec4528":"code","847bb3b9":"code","4c886983":"code","5b209626":"code","5f55478c":"code","abe48ae6":"code","8db92581":"code","1717dc45":"code","ac2bfdf1":"code","0910df20":"code","7923aa76":"code","266df662":"code","4d64ecda":"code","8320151f":"markdown","2430e1dc":"markdown","c725e0e5":"markdown","75818b4b":"markdown","2d879675":"markdown","6bef92c9":"markdown","8b4c36f7":"markdown","56bdd6c2":"markdown","b84d5858":"markdown","7be2f9c8":"markdown","bb3ce3c9":"markdown"},"source":{"914a4c31":"pip install -U keras-tuner","1d789c2e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout,LSTM\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom kerastuner.engine.hyperparameters import HyperParameters\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kerastuner.tuners import RandomSearch","d8d25b37":"df_train = pd.read_csv(\"..\/input\/gooogle-stock-price\/Google_Stock_Price_Train.csv\")\ndf_train","fde885ad":"df_closing = df_train['Close'].apply(lambda x : x.replace(',', '')).astype('float')\ndf_closing.head()","8062175e":"plt.plot(df_closing.values);\nplt.title(\"Closing prices for the data\");","c90227c0":"scaler=MinMaxScaler(feature_range=(0,1))\ndf_closing=scaler.fit_transform(np.array(df_closing).reshape(-1,1))","01e81b7f":"def create_dataset(dataset, time_step=1):\n    x_data, y_data = [], []\n    \n    for i in range(len(dataset)-time_step-1):\n        x_data.append(dataset[i:(i+time_step), 0])\n        y_data.append(dataset[i + time_step, 0])\n    return np.array(x_data), np.array(y_data)","06ec4528":"training_size=int(len(df_closing)*0.65)\ntest_size=len(df_closing)-training_size\ntrain_data,test_data=df_closing[0:training_size,:],df_closing[training_size:len(df_closing),:1]","847bb3b9":"time_step = 100\n\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, ytest = create_dataset(test_data, time_step)","4c886983":"X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)","5b209626":"def build_model(hp):\n    model = Sequential()\n    model.add(layers.LSTM(units = hp.Choice('layer1_units', [10,20,30,40,50,60,70,80,90,100]),return_sequences=True,input_shape=(100,1)))\n    \n    for i in range(hp.Int('num_layers', 2, 15)):                        \n        model.add(layers.LSTM(units =  hp.Int('units' + str(i), min_value=10, max_value=150, step=10), return_sequences=True))\n    \n    model.add(LSTM(units = hp.Choice('last_lstm_units', [50, 100, 150])))\n    model.add(Dropout(rate = hp.Choice('rate', [0.3, 0.4, 0.5, 0.6, 0.7])))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error',optimizer='adam' )\n    return model\n\n\ntuner = RandomSearch(\n    build_model,\n    objective='val_loss',\n    max_trials= 5,\n    executions_per_trial=3,\n    directory='project', project_name = 'Stacked_LSTM_Stock_Prediction')\n\ntuner.search_space_summary()\n\ntuner.search(X_train, y_train,\n             epochs= 5,\n             validation_data=(X_test, ytest))","5f55478c":"tuner.results_summary()","abe48ae6":"model=tuner.get_best_models(num_models=1)[0]\nmodel.summary()","8db92581":"model_history = model.fit(X_train,y_train, epochs=100, validation_data=(X_test,ytest))","1717dc45":"loss = model_history.history['loss']\nvalidation_loss = model_history.history['val_loss']\n\n\n\nplt.figure(figsize=(17, 7));\nplt.plot(range(100), loss, label='Training Loss');\nplt.plot(range(100), validation_loss, label='Validation Loss');\nplt.legend(loc='upper left');\nplt.title('Loss : Training Vs Validation ');","ac2bfdf1":"train_predict=model.predict(X_train)\ntest_predict=model.predict(X_test)","0910df20":"train_predict=scaler.inverse_transform(train_predict)\ntest_predict=scaler.inverse_transform(test_predict)","7923aa76":"look_back=100\ntrainPredictPlot = np.empty_like(df_closing)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(df_closing)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(df_closing)-1, :] = test_predict\n\nplt.plot(scaler.inverse_transform(df_closing))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.title('Train Vs Test predictions');\nplt.show()","266df662":"future_predictions = test_data.copy()\nfor i in range(100):\n    new_prediction = model.predict(((future_predictions[341+i:])).reshape(1,100,1))\n    future_predictions = np.append(future_predictions, new_prediction)\n    \nplt.plot(scaler.inverse_transform(future_predictions[441:].reshape(-1, 1)));\nplt.title('Predictions for the next 10 days');\nplt.xlabel('Days');\nplt.ylabel('Closing stocks');","4d64ecda":"print(\"Train RMSE: \", math.sqrt(mean_squared_error(y_train,train_predict)))\nprint(\"Test RMSE: \", math.sqrt(mean_squared_error(ytest,test_predict)))","8320151f":"## Scaling Data","2430e1dc":"# Scaling Data","c725e0e5":"# Preparing Train and Test data","75818b4b":"# Data Preprocessing","2d879675":"# Taking Past 50 days data","6bef92c9":"# Result and Conclusion","8b4c36f7":"# Importing Modules","56bdd6c2":"# Modeling with LSTM and Tuning the HyperParameters","b84d5858":"* The model is performing pretty well, train and test MSE are close.","7be2f9c8":"# Table of Content\n* 1. Importing Modules\n\n* 2. Loading Data\n\n* 3. Data PreProcessing\n\n* 4. Modelling With LSTM And Tuning The Hyperparameters\n\n* 5. Results And Conclusion","bb3ce3c9":"# Predecting Model"}}