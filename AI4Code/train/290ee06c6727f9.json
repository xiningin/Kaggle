{"cell_type":{"bbfe2846":"code","b41d0219":"code","b419fc7d":"code","e18f6ca3":"code","38f508b0":"code","86e4063c":"code","cae2ff81":"code","9da72fbd":"code","1bf4badd":"code","b04cc3f2":"code","c7ca1705":"markdown","f5029c49":"markdown","adefb967":"markdown","3d7548c6":"markdown","0152535b":"markdown","ede6a77b":"markdown","a7a166a8":"markdown","51c93b23":"markdown","43955cc0":"markdown","26c9275f":"markdown","2e848585":"markdown","de8b6444":"markdown"},"source":{"bbfe2846":"with open('..\/input\/humpback-whale-identification-fluke-location\/cropping.txt', 'rt') as f: data = f.read().split('\\n')[:-1]\nlen(data) # Number of rows in the dataset","b41d0219":"for line in data[:5]: print(line)","b419fc7d":"data = [line.split(',') for line in data]\ndata = [(p,[(int(coord[i]),int(coord[i+1])) for i in range(0,len(coord),2)]) for p,*coord in data]\ndata[0] # First row of the dataset","e18f6ca3":"from PIL import Image as pil_image\nfrom PIL.ImageDraw import Draw\n\ndef read_raw_image(p):\n    return pil_image.open('..\/input\/whale-categorization-playground\/train\/' + p)\n\ndef draw_dot(draw, x, y):\n    draw.ellipse(((x-5,y-5),(x+5,y+5)), fill='red', outline='red')\n\ndef draw_dots(draw, coordinates):\n    for x,y in coordinates: draw_dot(draw, x, y)\n\nfilename,coordinates = data[0]\nimg = read_raw_image(filename)\ndraw = Draw(img)\ndraw_dots(draw, coordinates)\nimg","38f508b0":"def bounding_rectangle(list):\n    x0, y0 = list[0]\n    x1, y1 = x0, y0\n    for x,y in list[1:]:\n        x0 = min(x0, x)\n        y0 = min(y0, y)\n        x1 = max(x1, x)\n        y1 = max(y1, y)\n    return x0,y0,x1,y1\n\nbox = bounding_rectangle(coordinates)\nbox","86e4063c":"draw.rectangle(box, outline='red')\nimg","cae2ff81":"# Suppress annoying stderr output when importing keras.\nimport sys\nold_stderr = sys.stderr\nsys.stderr = open('\/dev\/null', 'w')\nfrom keras.preprocessing.image import img_to_array,array_to_img\nsys.stderr = old_stderr\n\nimport numpy as np\nfrom numpy.linalg import inv\nfrom scipy.ndimage import affine_transform\n\ndef transform_img(x, affine):\n    matrix   = affine[:2,:2]\n    offset   = affine[:2,2]\n    x        = np.moveaxis(img_to_array(x), -1, 0) # Change to channel first\n    channels = [affine_transform(channel, matrix, offset, order=1, mode='constant', cval=np.average(channel)) for channel in x]\n    return array_to_img(np.moveaxis(np.stack(channels, axis=0), 0, -1)) # Back to channel last, and image format\n\nwidth, height = img.size\nrotation = np.deg2rad(10)\n# Place the origin at the center of the image\ncenter = np.array([[1, 0, -height\/2], [0, 1, -width\/2], [0, 0, 1]]) \n# Rotate\nrotate = np.array([[np.cos(rotation), np.sin(rotation), 0], [-np.sin(rotation), np.cos(rotation), 0], [0, 0, 1]])\n# Restaure the origin\ndecenter = inv(center)\n# Combine the transformations into one\nm   = np.dot(decenter, np.dot(rotate, center))\nimg = transform_img(img, m)\nimg","9da72fbd":"def coord_transform(coordinates, m):\n    result = []\n    for x,y in coordinates:\n        y,x,_ = m.dot([y,x,1]).astype(np.int)\n        result.append((x,y))\n    return result\n\ntransformed_coordinates = coord_transform(coordinates, inv(m))\ntransformed_coordinates","1bf4badd":"transformed_box = bounding_rectangle(transformed_coordinates)\ntransformed_box","b04cc3f2":"draw = Draw(img)\ndraw.rectangle(transformed_box, outline='yellow')\nimg","c7ca1705":"The idea here is to use the computed bounding boxes to train a bounding box model for the whale flukes.<br\/>\nWhen using image affine transformations as a form of data augmentation, the individual points make it possible to compute the bounding box of the transformed image.","f5029c49":"# Read the data","adefb967":"The list of coordinates can be used to determine a bounding box around the fluke.","3d7548c6":"Convert data to a list of tuples. Each tuple contains the picture filename and a list of coordinates.","0152535b":"A new bounding box can be computed for the rotated image:<br\/>\nEach point on the perimeter is transformed, and a new bounding box is computed on the transformed coordinates.<br\/>\nNotice how different points are selected when constructing the bounding box.","ede6a77b":"Show the first 5 lines.","a7a166a8":"From my experiments, it appears that building an image cropping model is useful but not critical in achieving good model accuracy.<br\/>\nTo determine this, I trained essentially identical versions of the identification model with and without image cropping:\n\n* 0.714 : score without image cropping\n* 0.766 : score with image cropping\n\nWhile image cropping provides a substantial improvement, good accuracy is still possible without it.<br\/>\n*N.B.: I don't have a \"no cropping\" equivalent for my final submission, so I am using older submissions for comparison.*","51c93b23":"# Affine transformation\nUsing affine transformation is a basic data augmentation technique used when training deep convolution network.<br\/>\nThe example below shows a 10-degree rotation.","43955cc0":"# How valuable is image cropping?","26c9275f":"# Java program to record boundary points\nI used the following small Java programme to record the points in the dataset.\n```java\nimport java.io.*;\nimport java.util.*;\nimport javafx.application.*;\nimport javafx.event.*;\nimport javafx.scene.*;\nimport javafx.scene.canvas.*;\nimport javafx.scene.image.*;\nimport javafx.scene.input.*;\nimport javafx.scene.layout.*;\nimport javafx.stage.*;\n\npublic class WhaleTagger extends Application\n{\n  private List<String>  list   = new ArrayList<>();\n  private int           index  = 0;\n  private StringBuilder buffer = new StringBuilder();\n  private int           tagged;\n\n  public static void main(String[] args)\n  {\n    Application.launch(args);\n  }\n\n  @Override\n  public void start(Stage primaryStage) throws Exception\n  {\n    initfiles();\n    Image     image     = getNextImage();\n    int       width     = (int)image.getWidth();\n    int       height    = (int)image.getHeight();\n\n    Canvas          canvas = new Canvas(width, height);\n    GraphicsContext gc     = canvas.getGraphicsContext2D();\n    gc.drawImage(image, 0, 0, canvas.getWidth(), canvas.getHeight());\n\n    \/\/ Reset the Canvas when the user double-clicks\n    canvas.addEventHandler(MouseEvent.MOUSE_CLICKED, new EventHandler<MouseEvent>()\n    {\n      @Override\n      public void handle(MouseEvent e)\n      {\n        if (e.getClickCount() == 1)\n        {\n          int x = (int)e.getX();\n          int y = (int)e.getY();\n          gc.clearRect(x - 2, y - 2, 5, 5);\n          buffer.append(\",\");\n          buffer.append(x);\n          buffer.append(\",\");\n          buffer.append(y);\n          System.out.println(buffer);\n        }\n      }\n    });\n\n\n    canvas.setFocusTraversable(true);\n    canvas.requestFocus();\n    canvas.setOnKeyPressed(new EventHandler<KeyEvent>()\n    {\n      @Override\n      public void handle(KeyEvent event)\n      {\n        if (event.getCode() == KeyCode.SPACE || event.getCode() == KeyCode.ENTER)\n        {\n          if (buffer.length() > 0)\n          {\n            ++tagged;\n            list.set(index, list.get(index) + buffer.toString());\n            System.out.println(list.get(index));\n          }\n          Image image = getNextImage();\n          canvas.setWidth(image.getWidth());\n          canvas.setHeight(image.getHeight());\n          canvas.getGraphicsContext2D().drawImage(image, 0, 0, canvas.getWidth(), canvas.getHeight());\n          primaryStage.sizeToScene();\n        }\n        else if (event.getCode() == KeyCode.BACK_SPACE)\n        {\n          System.out.println(\"Resetting\");\n          Image image = getNextImage();\n          canvas.getGraphicsContext2D().drawImage(image, 0, 0, canvas.getWidth(), canvas.getHeight());\n        }\n        else if (event.getCode() == KeyCode.ESCAPE)\n        {\n          done();\n        }\n      }\n    });\n\n    \/\/ Add the Canvas to the Scene, and show the Stage\n    Pane root = new Pane();\n    root.getChildren().add(canvas);\n    Scene scene = new Scene(root);\n    primaryStage.setTitle(\"Whale tagging\");\n    primaryStage.sizeToScene();\n    primaryStage.setScene(scene);\n    primaryStage.show();\n  }\n\n  private Image getNextImage()\n  {\n    try\n    {\n      for (;;)\n      {\n        if (index == list.size()) done();\n        if (!list.get(index).contains(\",\")) break;\n        ++index;\n      }\n      File file = new File(\"humpback-whale-identification\\\\train\\\\\" + list.get(index));\n      Image image = new Image(file.toURI().toURL().toString());\n      buffer.setLength(0);\n      System.out.println();\n      System.out.println(tagged + 1 + \") \" + list.get(index) + \" \" + (int)image.getWidth() + \" x \" + (int)image.getHeight());\n      return image;\n    }\n    catch (Exception e)\n    {\n      e.printStackTrace();\n    }\n    return null;\n  }\n\n  private void done()\n  {\n    try\n    {\n      System.out.println(\"Writing filelist.txt\");\n      PrintStream stream = new PrintStream(new FileOutputStream(\"filelist.txt\"));\n      for (String s : list) stream.println(s);\n      stream.close();\n      System.out.println(\"Exiting\");\n      System.exit(0);\n    }\n    catch (Exception e)\n    {\n      e.printStackTrace();\n    }\n  }\n\n  private void initfiles() throws Exception\n  {\n    tagged = 0;\n    int untagged = 0;\n    BufferedReader reader = new BufferedReader(new FileReader(\"filelist.txt\"));\n    for (;;)\n    {\n      String line = reader.readLine();\n      if (line == null || line.length() == 0) break;\n      list.add(line);\n      if (line.contains(\",\"))\n        ++tagged;\n      else\n        ++untagged;\n    }\n    reader.close();\n    System.out.println(\"Read \" + tagged + \" tagged and \" + untagged + \" untagged entries\");\n  }\n}\n```","2e848585":"We can show the coordinates on the original image","de8b6444":"# Bounding box data for the whale flukes\n<p>This notebook explores the Humpback Whale Identification - Fluke Location dataset.<p>\n<p>This dataset is associated with the Humpback Whale Identification Challenge dataset. It contains the location of points on the edge of the fluke for 1200 pictures randomly selected from the Humpback Whale Identification Challenge training set. Points are selected to capture the leftmost and rightmost points, as well as the highest and lowest points. Additional points are added to help determine the fluke bounding box following an affine transformation on the image.<\/p>\n<p>The intent of this dataset is to build a model for locating the whale fluke inside the image. In the context of the Humpback Whale Identification Challenge, such a model can then be used to crop images around the region of interest.<\/p>"}}