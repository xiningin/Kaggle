{"cell_type":{"cd386505":"code","3039358c":"code","92bbe728":"code","597f4e3d":"code","34b3c14b":"code","6707f832":"code","6c26fc3b":"code","29f87dbe":"code","014b6ac2":"code","2d3fa155":"code","b3635b25":"code","ae89ab63":"code","930413ee":"code","6cdc7502":"code","fac20069":"code","280786f8":"code","54b15ae9":"code","646881de":"code","40c4adbd":"code","f9e0031d":"code","e812f444":"code","a6e923ef":"code","ee2a6b6d":"code","7db2c69c":"code","e0bc5e14":"code","c70c79f5":"code","7f360fe7":"code","1cf0173a":"code","b399fd46":"code","d541624c":"code","ae38dce8":"code","868da689":"code","0bc765cc":"code","0bb8dc5d":"code","3f37d2cb":"code","f958bf0f":"code","53493e2f":"code","875b44e7":"code","89fd0645":"code","938c22d6":"code","8db78d44":"code","ca637715":"code","d1cce60d":"code","8491d624":"code","94682513":"code","61ce12d4":"code","3dbe5dc4":"code","246a22ea":"code","80e92701":"code","2b9445ac":"code","f8bf9d1c":"code","a43a6eca":"code","f62b7952":"code","0b79fdb8":"code","088dc349":"code","f7942cba":"code","b2aa6e70":"code","f090ee95":"code","7a217cd5":"code","a5f1b4f2":"code","de434e61":"code","a58a598b":"code","b60d52d5":"code","f4c67828":"code","946c2b9e":"code","0aff55cb":"code","4c81aaa1":"markdown","fee583b9":"markdown","93f9b4de":"markdown","d8387873":"markdown","c6a71e77":"markdown","929015b0":"markdown","1b5e943a":"markdown","c18700da":"markdown","7af7da64":"markdown","0c2d33e1":"markdown","dea8d4ea":"markdown","9178d7d8":"markdown","9957c31f":"markdown","03e4dd52":"markdown","e3be9502":"markdown","e126561b":"markdown","b8d9ac00":"markdown","1002f990":"markdown","108287a7":"markdown","2f450bba":"markdown","302e38a6":"markdown","8697dcf6":"markdown","2dd3511d":"markdown","84982e44":"markdown","a5849bee":"markdown"},"source":{"cd386505":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3039358c":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn import linear_model, ensemble\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nimport tensorflow as tf\n\nfrom tqdm.notebook import tqdm\n\nimport os\nfrom PIL import Image","92bbe728":"train = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntest = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/test.csv')\nsubmission = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/sample_submission.csv')","597f4e3d":"train.head()","34b3c14b":"train.info()","6707f832":"test.head()","6c26fc3b":"test.info()","29f87dbe":"train.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])","014b6ac2":"submission['Patient'] = (\n    submission['Patient_Week']\n    .apply(\n        lambda x:x.split('_')[0]\n    )\n)\n\nsubmission['Weeks'] = (\n    submission['Patient_Week']\n    .apply(\n        lambda x: int(x.split('_')[-1])\n    )\n)\n\nsubmission =  submission[['Patient','Weeks', 'Confidence','Patient_Week']]\n\nsubmission = submission.merge(test.drop('Weeks', axis=1), on=\"Patient\")","2d3fa155":"submission.head()","b3635b25":"train['Dataset'] = 'train'\ntest['Dataset'] = 'test'\nsubmission['Dataset'] = 'submission'","ae89ab63":"all_data = train.append([test, submission])\n\nall_data = all_data.reset_index()\nall_data = all_data.drop(columns=['index'])\n","930413ee":"all_data.head()\n\n","6cdc7502":"train_patients = train.Patient.unique()","fac20069":"fig, ax = plt.subplots(5, 1, figsize=(10, 20))\n\nfor i in range(5):\n    patient_log = train[train['Patient'] == train_patients[i]]\n\n    ax[i].set_title(train_patients[i])\n    ax[i].plot(patient_log['Weeks'], patient_log['FVC'])","280786f8":"all_data['FirstWeek'] = all_data['Weeks']\nall_data.loc[all_data.Dataset=='submission','FirstWeek'] = np.nan\nall_data['FirstWeek'] = all_data.groupby('Patient')['FirstWeek'].transform('min')","54b15ae9":"first_fvc = (\n    all_data\n    .loc[all_data.Weeks == all_data.FirstWeek][['Patient','FVC']]\n    .rename({'FVC': 'FirstFVC'}, axis=1)\n    .groupby('Patient')\n    .first()\n    .reset_index()\n)\n\nall_data = all_data.merge(first_fvc, on='Patient', how='left')","646881de":"all_data.head()","40c4adbd":"all_data['WeeksPassed'] = all_data['Weeks'] - all_data['FirstWeek']","f9e0031d":"all_data.head()","e812f444":"\"\"\"def calculate_height(row):\n    if row['Sex'] == 'Male':\n        return row['FirstFVC'] \/ (27.63 - 0.112 * row['Age'])\n    else:\n        return row['FirstFVC'] \/ (21.78 - 0.101 * row['Age'])\n\nall_data['Height'] = all_data.apply(calculate_height, axis=1)\n\"\"\"\n\ndef calculate_height(row):\n    height = 0\n    if row['Sex'] == 'Male' or 'Female':\n        height = (((row['FirstFVC']\/933.33) + 0.026*row['Age'] + 2.89)\/0.0443)\n        return int(height) \n\nall_data['Height'] = all_data.apply(calculate_height, axis=1)\n\n\ndef FEV1(row):\n    FEV = 0\n    if row['Sex'] == 'Male':\n        FEV = (0.84 * row['FirstFVC'] - 0.23)\n    else:\n        FEV = (0.84 * row['FirstFVC'] - 0.36)\n    return FEV\nall_data['FEV'] = all_data.apply(FEV1, axis = 1)","a6e923ef":"all_data.head()","ee2a6b6d":"all_data = pd.concat([\n    all_data,\n    pd.get_dummies(all_data.Sex),\n    pd.get_dummies(all_data.SmokingStatus)\n], axis=1)\n\nall_data = all_data.drop(columns=['Sex', 'SmokingStatus'])","7db2c69c":"all_data.head()","e0bc5e14":"def scale_feature(series):\n    return (series - series.min()) \/ (series.max() - series.min())\n\nall_data['Weeks'] = scale_feature(all_data['Weeks'])\nall_data['Percent'] = scale_feature(all_data['Percent'])\nall_data['Age'] = scale_feature(all_data['Age'])\nall_data['FirstWeek'] = scale_feature(all_data['FirstWeek'])\nall_data['FirstFVC'] = scale_feature(all_data['FirstFVC'])\nall_data['WeeksPassed'] = scale_feature(all_data['WeeksPassed'])\nall_data['Height'] = scale_feature(all_data['Height'])\nall_data['FEV'] = scale_feature(all_data['FEV'])","c70c79f5":"feature_columns = [\n    'Percent',\n    'Age',\n    'FirstWeek',\n    'FirstFVC',\n    'WeeksPassed',\n    'Female',\n    'Male', \n    'Currently smokes',\n    'Ex-smoker',\n    'Never smoked',\n    'FEV'\n]","7f360fe7":"train = all_data.loc[all_data.Dataset == 'train']\ntest = all_data.loc[all_data.Dataset == 'test']\nsubmission = all_data.loc[all_data.Dataset == 'submission']","1cf0173a":"train[feature_columns].head()","b399fd46":"from sklearn.model_selection import KFold \nfrom sklearn.model_selection import cross_val_score\n\ndef qloss(y_true, y_pred):\n    # Pinball loss for multiple quantiles\n    qs = [0.2, 0.50, 0.8]\n    q = tf.constant(np.array([qs]), dtype=tf.float32)\n    e = y_true - y_pred\n    v = tf.maximum(q*e, (q-1)*e)\n    return K.mean(v)\nn_folds = 10\n\ndef rmse_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=1234).get_n_splits(train[feature_columns])\n    rmse= np.sqrt(-cross_val_score(model, train[feature_columns], train['FVC'], scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","d541624c":"from sklearn.linear_model import Lasso\nfrom sklearn.pipeline import make_pipeline \nfrom sklearn.linear_model import Lasso\nlasso = Lasso()\n\nlasso.fit(train[feature_columns], train['FVC'])","ae38dce8":"lasso_preds = lasso.predict(train[feature_columns])\nsub = pd.DataFrame()\nsub['lasso_FVC'] = lasso_preds\nsub.head()","868da689":"from sklearn.linear_model import Ridge\nridge = Ridge()\nridge.fit(train[feature_columns], train['FVC'])","0bc765cc":"!pip install ngboost","0bb8dc5d":"from ngboost import NGBRegressor\nngb = NGBRegressor()\nngb.fit(train[feature_columns], train['FVC'])","3f37d2cb":"ngb_preds = ngb.predict(train[feature_columns])\nsub = pd.DataFrame()\nsub['ngb_FVC'] = ngb_preds\nsub.head()","f958bf0f":"ridge_preds = lasso.predict(train[feature_columns])\nsub = pd.DataFrame()\nsub['ridge_FVC'] = ridge_preds\nsub.head()","53493e2f":"from sklearn.linear_model import BayesianRidge\nbayesian_ridge = BayesianRidge()\nbayesian_ridge.fit(train[feature_columns], train['FVC'])","875b44e7":"bayesian_ridge_preds = bayesian_ridge.predict(train[feature_columns])\nsub = pd.DataFrame()\nsub['bay_ridge_FVC'] = bayesian_ridge_preds\nsub.head()","89fd0645":"from sklearn.linear_model import HuberRegressor\nHuber = HuberRegressor()\nHuber.fit(train[feature_columns], train['FVC'])","938c22d6":"Huber_preds = Huber.predict(train[feature_columns])\nsub = pd.DataFrame()\nsub['huber_FVC'] = Huber_preds\nsub.head()","8db78d44":"from catboost import CatBoostRegressor\ncat = CatBoostRegressor()\ncat.fit(train[feature_columns], train['FVC'])","ca637715":"cat_preds = cat.predict(train[feature_columns])\nsub = pd.DataFrame()\nsub['cat_FVC'] = cat_preds\nsub.head()","d1cce60d":"ridge_weight = 0.2\nlasso_weight = 0.2\n#cat_weight = 0.3\nhuber_weight = 0.40 \nbayesian_ridge_weight = 0.20 ","8491d624":"prediction1 = 0\nsub = pd.DataFrame()\nsub['ensembled_FVC'] = (ridge_preds*ridge_weight) + (lasso_preds*lasso_weight)  + (Huber_preds*huber_weight ) + (bayesian_ridge_preds*bayesian_ridge_weight)\npredictions = sub['ensembled_FVC'].values","94682513":"mse = mean_squared_error(\n    train['FVC'],\n    predictions,\n    squared=False\n)\n\nmae = mean_absolute_error(\n    train['FVC'],\n    predictions\n)\n\nprint('MSE Loss: {0:.2f}'.format(mse))\nprint('MAE Loss: {0:.2f}'.format(mae))","61ce12d4":"def competition_metric(trueFVC, predFVC, predSTD):\n    clipSTD = np.clip(predSTD, 70 , 9e9)  \n    deltaFVC = np.clip(np.abs(trueFVC - predFVC), 0 , 1000)  \n    return np.mean(-1 * (np.sqrt(2) * deltaFVC \/ clipSTD) - np.log(np.sqrt(2) * clipSTD))\n    \n\nprint(\n    'Competition metric: ', \n    competition_metric(train['FVC'].values, predictions, 285) \n)","3dbe5dc4":"train['prediction'] = predictions","246a22ea":"plt.scatter(predictions, train['FVC'])\n\nplt.xlabel('predictions')\nplt.ylabel('FVC (labels)')\nplt.show()","80e92701":"delta = predictions - train['FVC']\nplt.hist(delta, bins=20)\nplt.show()","2b9445ac":"fig, ax = plt.subplots(5, 1, figsize=(10, 20))\n\nfor i in range(5):\n    patient_log = train[train['Patient'] == train_patients[i]]\n\n    ax[i].set_title(train_patients[i])\n    ax[i].plot(patient_log['WeeksPassed'], patient_log['FVC'], label='truth')\n    ax[i].plot(patient_log['WeeksPassed'], patient_log['prediction'], label='prediction')\n    ax[i].legend()","f8bf9d1c":"submission[feature_columns].head()","a43a6eca":"lasso_preds1 = lasso.predict(submission[feature_columns])\nsubmission1 = pd.DataFrame()\nsubmission1['lasso_FVC'] = lasso_preds1\nsubmission1.head()","f62b7952":"ridge_preds1 = lasso.predict(submission[feature_columns])\nsubmission2 = pd.DataFrame()\nsubmission2['ridge_FVC'] = ridge_preds1\nsubmission2.head()\n","0b79fdb8":"bayesian_ridge_preds1 = bayesian_ridge.predict(submission[feature_columns])\nsubmission3 = pd.DataFrame()\nsubmission3['bay_ridge_FVC'] = bayesian_ridge_preds1\nsubmission3.head()","088dc349":"Huber_preds1 = Huber.predict(submission[feature_columns])\nsubmission4 = pd.DataFrame()\nsubmission4['huber_FVC'] = Huber_preds1\nsubmission4.head()","f7942cba":"cat_preds1 = cat.predict(submission[feature_columns])\nsubmission5 = pd.DataFrame()\nsubmission5['cat_FVC'] = cat_preds1\nsubmission5.head()","b2aa6e70":"submission_ensemble = pd.DataFrame()\nsubmission_ensemble['pred_FVC'] = (submission2['ridge_FVC'].values*ridge_weight) + (submission1['lasso_FVC']*lasso_weight)  + (submission4['huber_FVC'].values*huber_weight ) + (submission3['bay_ridge_FVC'].values*bayesian_ridge_weight)\n\nfinal_prediction = submission_ensemble['pred_FVC'].values","f090ee95":"submission_ensemble.shape \n","7a217cd5":"submission['FVC'] = final_prediction","a5f1b4f2":"submission.head()","de434e61":"test_patients = list(submission.Patient.unique())\nfig, ax = plt.subplots(5, 1, figsize=(10, 20))\n\nfor i in range(5):\n    patient_log = submission[submission['Patient'] == test_patients[i]]\n\n    ax[i].set_title(test_patients[i])\n    ax[i].plot(patient_log['WeeksPassed'], patient_log['FVC'])","a58a598b":"submission = submission[['Patient_Week', 'FVC']]\n\nsubmission['Confidence'] = 275","b60d52d5":"print(len(submission['FVC'].unique()))","f4c67828":"submission.to_csv('submission.csv', index=False)","946c2b9e":"submission.head()","0aff55cb":"def competition_metric(trueFVC, predFVC, predSTD):\n    clipSTD = np.clip(predSTD, 70 , 9e9)  \n    deltaFVC = np.clip(np.abs(trueFVC - predFVC), 0 , 1000)  \n    return np.mean(-1 * (np.sqrt(2) * deltaFVC \/ clipSTD) - np.log(np.sqrt(2) * clipSTD))\n    \n\nprint(\n    'Competition metric: ', \n    competition_metric(submission['FVC'].values, final_prediction, 275) \n)","4c81aaa1":"# Bayesian predictions ","fee583b9":"### Feature scaling ","93f9b4de":"# Model","d8387873":"# Huber","c6a71e77":"## Categorical column","929015b0":"# Ridge ","1b5e943a":"# weights ","c18700da":"# Ridge Predictions ","7af7da64":"# Lasso","0c2d33e1":"# plot for the first five test sets ","dea8d4ea":"# Huber predictions ","9178d7d8":"# Libararies ","9957c31f":"# Ensemble ","03e4dd52":"feature engineering ","e3be9502":"# NG boost","e126561b":"# Cat predictions ","b8d9ac00":"# Bayesian Ridge","1002f990":"# loading data sets ","108287a7":"# MAE and MSE","2f450bba":"# Submission","302e38a6":"# A quick data analysis ","8697dcf6":"# Lasso predictions ","2dd3511d":"# Cat boost","84982e44":"## Patient height and FEV ","a5849bee":"# Ensemble technique in machine learning \n\n### please upvote if you like the approach simple but effective approach ! this will motivate me to make more such notebooks, and also i didnt apply grid search you can do it to tune the hyper parametrs !  This is just an approach if you like mahcine leanring ! \n"}}