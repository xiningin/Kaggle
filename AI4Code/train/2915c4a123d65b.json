{"cell_type":{"425f88bc":"code","57036e76":"code","bcdb5122":"code","844cf1ed":"code","44908c67":"code","2f231342":"code","4a903724":"code","81e7d84a":"code","8877e448":"code","ed6aa9ae":"code","b133d2b4":"code","b2f7f67f":"code","ef370c6f":"code","4e1aa973":"code","3ef593fe":"code","0bc67008":"code","f3a46d00":"code","292f4a65":"code","8e867110":"code","abb4cbf4":"code","365f03d2":"code","b9acadb8":"code","f279c950":"code","506b19fb":"code","5e815fa6":"code","8026ee66":"code","9fc7ca4b":"code","8a80b11d":"code","70d1efca":"code","8fd47ebd":"code","f66de5ea":"code","1468f1f4":"code","3e5e89a4":"code","ddb34410":"markdown","76ff48a6":"markdown","d27f0db7":"markdown","55331753":"markdown"},"source":{"425f88bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","57036e76":"!pip install praw","bcdb5122":"import praw\nfrom IPython import display\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.tokenize import word_tokenize\nimport re","844cf1ed":"# Mengisi reddit API auth\nclient_id = \"BIOoZ_fWqSm2CA\"\nclient_secret = \"wJLDG8brQ-tnd6GGAFDUqcdGiYu9JQ\"\nuser_agent = \"scrap-redit-data\"\nreddit = praw.Reddit(\n    client_id=client_id, \n    client_secret=client_secret, \n    user_agent=user_agent)\n","44908c67":"# Mencari topik forum dengan keyword JoeBiden\nposts = []\npost_topic = reddit.subreddit('JoeBiden')\nfor post in post_topic.new(limit=100):\n    posts.append([post.title, \n                  post.score, \n                  post.id, \n                  post.subreddit, \n                  post.url, \n                  post.num_comments, \n                  post.selftext, \n                  post.created])\n# membuat data set\nposts = pd.DataFrame(posts, columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\nposts.head()","2f231342":"# menggunakan kolom title dan score\ntop_post_reddit = posts.iloc[:, 0:2]\ntop_post_reddit.head()","4a903724":"# instansiasi library analisis sentimen dari NLTK\nsia = SIA()\n\n# membuat kolom sentimen kemudian menerapkan polarity score\ntop_post_reddit['sentiment'] = top_post_reddit.title.apply(lambda x: sia.polarity_scores(x)['compound'])\ntop_post_reddit","81e7d84a":"# menggunakan kolom title\ntop_post_reddit = top_post_reddit['title']\ntop_post_reddit","8877e448":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\n\n# TFIDF vectorizer dengan stopword bahasa inggris\nvectorizer = TfidfVectorizer(stop_words='english')\n# menerapkan vektorizer pada data set top_post_reddit\nX = vectorizer.fit_transform(top_post_reddit)\n\n# train model dengan cluster 5 dan iterasi sebanyak 100, kemudian train dengan fit()\nmodel = KMeans(n_clusters=5, init='k-means++', max_iter=100, n_init=1)\nmodel.fit(X)","ed6aa9ae":"copy_data = top_post_reddit.reset_index()\ncopy_data","b133d2b4":"print(model.labels_)\ncopy_data['kluster'] = model.labels_","b2f7f67f":"print(model.cluster_centers_)","ef370c6f":"# analisis sentimen dari topik terbaru dengan keyword joe bidden\nheadlines = set()\n# iterasi dengan batas 100 data\nfor submission in post_topic.new(limit=100):\n    headlines.add(submission.title)\n    display.clear_output()\n    print(headlines)","4e1aa973":"# melakukan analisis sentimen dengan SIA dari library nltk\nsia = SIA()\nresults = []\n\nfor line in headlines:\n    pol_score = sia.polarity_scores(line)\n    pol_score['headline'] = line\n    results.append(pol_score)\nresult_df = pd.DataFrame.from_records(results)\nresult_df","3ef593fe":"print(\"0: neutral\\n1: positive\\n-1: negative\\n\")","0bc67008":"# labeling our data compound\nresult_df['label'] = 0\nresult_df.loc[result_df['compound'] > 0.2, 'label'] = 1\nresult_df.loc[result_df['compound'] < -0.2, 'label'] = -1\n\n# Result data  \nresult_df","f3a46d00":"result_df.info()","292f4a65":"print(\"Positive headlines:\\n\")\nprint(list(result_df[result_df['label'] == 1].headline[:5]))\n\nprint(\"\\nNegative headlines:\\n\")\nprint(list(result_df[result_df['label'] == -1].headline[:5]))","8e867110":"# value total positives and negatives\nprint(result_df.label.value_counts(), \"\\n\")\nprint(result_df.label.value_counts(normalize=True) * 100)","abb4cbf4":"# plotting pie chart\nlabels = 'Positive', 'Negative', 'Neutral'\nsizes = result_df.label.value_counts()\ncolors = ['green', 'red', 'lightblue']\nexplode = (0.1, 0, 0)  # explode 1st slice\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')\nplt.show()","365f03d2":"# memisahkan data train dan test\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    result_df['headline'], \n    result_df['label'], \n    test_size = 0.3,random_state=0)","b9acadb8":"# menerapkan countVectorizer pada data train dan test\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(analyzer='word', stop_words='english')\n\nX_train_cv = cv.fit_transform(X_train)\nX_test_cv = cv.transform(X_test)","f279c950":"from sklearn.preprocessing import StandardScaler \nscaler = StandardScaler(with_mean=False) \nscaler.fit(X_train_cv)\nX_train_cv = scaler.transform(X_train_cv) \nX_test_cv = scaler.transform(X_test_cv)","506b19fb":"word_freq = pd.DataFrame(X_train_cv.toarray(), columns=cv.get_feature_names())\ntop_words_df = pd.DataFrame(word_freq.sum()).sort_values(0, ascending=False)\n\nword_freq, top_words_df","5e815fa6":"from sklearn.naive_bayes import MultinomialNB\nnaive_bayes = MultinomialNB()\nnaive_bayes.fit(X_train_cv, y_train)\nMNBpredictions = naive_bayes.predict(X_test_cv)","8026ee66":"from sklearn.metrics import accuracy_score, precision_score, recall_score\nprint('Accuracy score: ', accuracy_score(y_test, MNBpredictions))\nprint('Precision score: ', precision_score(y_test, MNBpredictions, average='micro'))\nprint('Recall score: ', recall_score(y_test, MNBpredictions, average='micro'))","9fc7ca4b":"# visualisasi data dengan confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, MNBpredictions)\nsns.heatmap(cm, square=True, annot=True, cmap='RdBu', cbar=False,\nxticklabels=['positive', 'neutral', 'negative'], yticklabels=['positive', 'neutral', 'negative'])\nplt.xlabel('Actual label')\nplt.ylabel('Predicted label')","8a80b11d":"# klasifikasi dengan KNN clasifier\nfrom sklearn.neighbors import KNeighborsClassifier \nKNNclassifier = KNeighborsClassifier(n_neighbors=5) \nKNNclassifier.fit(X_train_cv, y_train)","70d1efca":"# Menghitung akurasi model\nKNNpred = KNNclassifier.predict(X_test_cv)\nprint('Accuracy score: ', accuracy_score(y_test, KNNpred))","8fd47ebd":"# Klasifikasi data dengan Logistic regression\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\n\nlr.fit(X_train_cv,y_train)\n\nLR_Pred = lr.predict(X_test_cv)","f66de5ea":"score_lr = round(accuracy_score(y_test,LR_Pred)*100, 2)\n\nprint(\"The accuracy score achieved using Logistic Regression is: \"+str(score_lr)+\" %\")","1468f1f4":"from sklearn import svm\n\nsv = svm.SVC(kernel='linear')\n\nsv.fit(X_train_cv, y_train)","3e5e89a4":"\nY_pred_svm = sv.predict(X_test_cv)\nscore_svm = round(accuracy_score(Y_pred_svm,y_test)*100,2)\n\nprint(\"The accuracy score achieved using Linear SVM is: \"+str(score_svm)+\" %\")","ddb34410":"# **Reddit Sentiment Analysis**","76ff48a6":"# Headlines Sentiment Analysis","d27f0db7":"# New Post Clustering","55331753":"# Labeling data"}}