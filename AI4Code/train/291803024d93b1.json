{"cell_type":{"b6fd4772":"code","1295dc1c":"code","76212147":"code","14a105fe":"code","f16a991b":"code","fc9bc625":"code","e632a318":"code","4004f4a9":"code","147fbf5d":"code","d2797cda":"code","595aa2e7":"code","0f1ff6f8":"markdown","2df98100":"markdown","282e8513":"markdown","b042f036":"markdown","ec31903d":"markdown","bf55a3b2":"markdown","88b8a6b2":"markdown","2ed9a2e0":"markdown","0b75155a":"markdown","30a8d28c":"markdown","aac8285e":"markdown"},"source":{"b6fd4772":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot as plt\nfrom keras import Input, Model, optimizers\nfrom keras.layers import Dense, regularizers, Dropout, GlobalAveragePooling2D\nfrom keras.applications import InceptionV3, inception_v3\nfrom sklearn.metrics import classification_report\n\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\nimage_root = '\/kaggle\/input\/marvel\/marvel'\n# Any results you write to the current directory are saved as output.","1295dc1c":"def normalize_image(images):\n    return images \/ 127.5 - 1\n\n\ndef restore_image(images):\n    return (images + 1) \/ 2","76212147":"def get_image_loader(image_size, batch_size, color_mode='rgb', shuffle=True):\n    data_gen = ImageDataGenerator(\n        preprocessing_function=normalize_image\n    )\n    train_loader = data_gen.flow_from_directory(\n        os.path.join(image_root, 'train'),\n        color_mode=color_mode,\n        target_size=(image_size, image_size),\n        batch_size=batch_size,\n        shuffle=shuffle\n    )\n    valid_loader = data_gen.flow_from_directory(\n        os.path.join(image_root, 'valid'),\n        color_mode=color_mode,\n        target_size=(image_size, image_size),\n        batch_size=batch_size,\n        shuffle=shuffle\n    )\n    return train_loader, valid_loader\n\n\ntrain, valid = get_image_loader(image_size=224, batch_size=64, shuffle=True)\nprint(\"There are {} batches in training set, {} batches in validation set\".format(len(train), len(valid)))","14a105fe":"def display_image(*images, col=None, width=20):\n    from matplotlib import pyplot as plt\n\n    if col is None:\n        col = len(images)\n    row = np.math.ceil(len(images) \/ col)\n    plt.figure(figsize=(width, (width + 1) * row \/ col))\n    for i, image in enumerate(images):\n        plt.subplot(row, col, i + 1)\n        plt.axis('off')\n        plt.imshow(image, cmap='gray')\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.show()\n\n\nbatch_x, _ = train[0]\nrestored = restore_image(batch_x)[:16]\ndisplay_image(*restored, col=8)","f16a991b":"def get_feature_extractor():\n    base = InceptionV3(include_top=False, input_shape=(224, 224, 3), pooling='avg')\n    btnk = base.get_layer('mixed8').output\n    features = GlobalAveragePooling2D()(btnk)\n    return Model(base.input, features)\n\nfeature_extractor = get_feature_extractor()\nfeatures = feature_extractor.predict(batch_x)\nprint(features.shape)","fc9bc625":"def extract_features(extractor, dataset):\n    x, y = None, None\n    n = len(dataset)\n    for i in range(n):\n        print(\"\\r[info] extracting features: batch #{}\/{}...\".format(i + 1, n), end='')\n        batch_x, batch_y = dataset[i]\n        features = extractor.predict(batch_x)\n        if x is None:\n            x = features\n            y = batch_y\n        else:\n            x = np.vstack([x, features])\n            y = np.vstack([y, batch_y])\n    return x, y\n\nprint(\"\\n[info] extracting training set image features:\")\nx_train, y_train = extract_features(feature_extractor, train)\nprint(\"\\n[info] training set complete!\\n\")\n\nprint(\"\\n[info] extracting validation set image features:\")\nx_valid, y_valid = extract_features(feature_extractor, valid)\nprint(\"\\n[info] validation set complete!\\n\")\n\nprint(\"training set input shape = {}, output shape = {}\".format(x_train.shape, y_train.shape))\nprint(\"validation set input shape = {}, output shape = {}\".format(x_valid.shape, y_valid.shape))","e632a318":"def create_nn(input_size, num_classes):\n    \"\"\"this function creates a neural network model that \n    accepts vectors of 'input_size' dimensions and outputs \n    `num_classes` dimensional one-hot vectors to represent\n    the corresponding class label\"\"\"\n    inputs = Input(shape=(input_size,))\n    x = Dropout(.5)(inputs)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(.5)(x)\n    out = Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(.1))(x)\n    return Model(inputs, out)\n\nmodel = create_nn(x_train.shape[1], y_train.shape[1])\nopt = optimizers.Adam(lr=.0001, beta_1=.99, beta_2=.999, epsilon=1e-8)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n\nprint(\"\\n[info] start training...\")\nH = model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_valid, y_valid), verbose=2)\nplt.plot(H.history['loss'], label='train loss')\nplt.plot(H.history['val_loss'], label='valid loss')\nplt.legend()\n\nplt.figure()\nplt.plot(H.history['acc'], label='train acc')\nplt.plot(H.history['val_acc'], label='valid acc')\nplt.legend()","4004f4a9":"test_results = model.predict(x_valid)\n\nid2label = {val: key for key, val in valid.class_indices.items()}\n\nprint(classification_report(\n    y_valid.argmax(axis=1),\n    test_results.argmax(axis=1),\n    target_names=id2label.values()\n))\n\nsample_images, sample_labels = valid[0]\nsample_images = sample_images[:16]\nsample_images = (sample_images + 1) \/ 2\nplt.figure(figsize=(20, 25))\ncol = 4\nrow = np.math.ceil(len(sample_images) \/ col)\nfor i, image in enumerate(sample_images):\n    plt.subplot(row, col, (i+1))\n    plt.title(id2label[sample_labels[i].argmax()], fontsize=30)\n    plt.text(0, 256, id2label[test_results[i].argmax()], color='red', fontsize=30)\n    plt.axis('off')\n    plt.imshow(image)","147fbf5d":"bottleneck = feature_extractor.output\nout = model(bottleneck)\nhero_recognizer = Model(feature_extractor.input, out)\nhero_recognizer.save(\"hero_recognizer.h5\")","d2797cda":"import cv2\nfrom keras.engine.saving import load_model\n\nhero_recognizer = load_model('hero_recognizer.h5')","595aa2e7":"import requests\nfrom io import BytesIO\nfrom PIL import Image\n\nurl = 'https:\/\/i.ytimg.com\/vi\/bPTZ43nM688\/maxresdefault.jpg'\nresponse = requests.get(url)\ntest_image = Image.open(BytesIO(response.content))\ntest_image = np.array(test_image)[:, :, :3]\n\ninput_image = cv2.resize(test_image, (224, 224))\ninput_image = normalize_image(input_image)\n\npred = hero_recognizer.predict(np.array([input_image]))\n\npredicted_hero = id2label[pred.argmax()]\nprint(\"The model thinks this image is of [{}].\".format(predicted_hero))\ndisplay_image(test_image)","0f1ff6f8":"Visualize a few sample images from the dataset.","2df98100":"# Import everything & find data","282e8513":"# Extract important features from images\n\nThis function creates a pre-trained deep learning model based on Google's work named [Inception v3](https:\/\/arxiv.org\/abs\/1512.00567) used to extract image features. In other words, each image will be fed into the deep learning model in the format of 3-dimensional tensors (3 224x224 matrices stacking together), and the model will extract 1280 features from that image represented as a 1280-dimensional vector.","b042f036":"# Loading data in batches\n\nThis function will create 2 generators responsible for loading training and testing datasets in batches. Since many times we deal with image data that's too large to fit into memory space, usually we read images in batches.","ec31903d":"We load the model like this in any other python programs","bf55a3b2":"extract features from both datasets","88b8a6b2":"Now that we have the images represented as 1280 features, we create a fully connected neural network to try to find the mapping between the feature vectors and the images' labels.","2ed9a2e0":"And use the model to recognize Marvel heroes like a pro!","0b75155a":"Helper functions to rescale image pixel values from [0, 255] to [-1, 1] and restore them back.","30a8d28c":"evaluate the trained performance and visualize some of them ","aac8285e":"Now that we have the trained models, how do we use them for later without retraining the models? Let's combine the 2 models and save it on disk"}}