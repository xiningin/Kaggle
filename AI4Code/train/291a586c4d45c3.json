{"cell_type":{"50bba292":"code","5b161501":"code","d6e60060":"code","ce5c1adc":"code","461b63f7":"code","5344b3fe":"code","f8212bd4":"code","4125541d":"code","53abe4a4":"code","cc21d608":"code","3e3d38ce":"code","4b7fa1fa":"code","d113c9e5":"code","1db01f56":"code","11a611d5":"code","bb65e25d":"code","1aed1379":"code","3fb18f97":"code","71568d2c":"code","e23784c3":"code","c256fcfa":"code","e4a4c42c":"code","2b064619":"code","2fa636ed":"code","2c0322f6":"code","4752c61c":"code","7a6b8849":"code","7b663721":"code","f9d0b59f":"code","635c42f0":"code","399af0cc":"code","b4961bdc":"code","2b2d8bc4":"code","99c72bdf":"code","998a03ce":"code","330b989d":"code","91218187":"code","0048431a":"code","b41f960c":"markdown","45bbdab2":"markdown","efc3f0e4":"markdown","c2cfa473":"markdown","f20151dd":"markdown","9ef49f35":"markdown","aa0d94cc":"markdown","e94bcf56":"markdown","0649b395":"markdown","e4c40681":"markdown","fc4f4fe5":"markdown"},"source":{"50bba292":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5b161501":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","d6e60060":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","ce5c1adc":"#print(test_data.loc[test_data.Fare.isnull()])\ntest_data.Fare = test_data.Fare.replace(np.NaN, test_data.Fare.mean())\n#print(test_data.loc[test_data.Fare.isnull()])","461b63f7":"train_data.Age.plot.hist(), train_data.Age.mean(),train_data.Age.median()","5344b3fe":"train_data.Fare.plot.hist(), train_data.Fare.mean(),train_data.Fare.median()","f8212bd4":"test_data.Fare.plot.hist(), test_data.Fare.mean(),test_data.Fare.median()","4125541d":"train_data.loc[train_data.Name.str.contains(\"Master\") & train_data.Age.isnull()]","53abe4a4":"train_data.Age = np.where((train_data.Name.str.contains(\"Master\") & train_data.Age.isnull()), train_data.loc[train_data.Name.str.contains(\"Master\")].Age.mean(), train_data.Age )","cc21d608":"#train_data.loc[train_data.Name.str.contains(\"Master\") & train_data.Age.isnull()]","3e3d38ce":"#train_data.loc[train_data.Age.isnull()]","4b7fa1fa":"train_data.Age = train_data.Age.replace(np.NaN, train_data.Age.mean())","d113c9e5":"test_data.Age.plot.hist(), test_data.Age.mean(),test_data.Age.median()","1db01f56":"test_data.loc[test_data.Name.str.contains(\"Master\") & test_data.Age.isnull()]","11a611d5":"test_data.Age = np.where((test_data.Name.str.contains(\"Master\") & test_data.Age.isnull()), test_data.loc[test_data.Name.str.contains(\"Master\")].Age.mean(), test_data.Age )","bb65e25d":"#test_data.loc[test_data.Name.str.contains(\"Master\") & test_data.Age.isnull()]","1aed1379":"test_data.Age = test_data.Age.replace(np.NaN, test_data.Age.mean())","3fb18f97":"#train_data.plot.scatter('Fare','Survived')","71568d2c":"#train_data.plot.scatter('Age','Fare')","e23784c3":"train_data.isnull().sum()","c256fcfa":"test_data.isnull().sum()","e4a4c42c":"train_data.Embarked.value_counts()","2b064619":"train_data.Embarked = train_data.Embarked.replace(np.NaN, 'S')","2fa636ed":"train_data['WithoutFamily'] = np.where(((train_data.Parch == 0) & (train_data.SibSp == 0)) ,1,0 )\n#train_data","2c0322f6":"#For Test\ntest_data['WithoutFamily'] = np.where(((test_data.Parch == 0) & (test_data.SibSp == 0)) ,1,0 )\n#test_data","4752c61c":"train_data[\"CabStatus\"] = np.where(train_data.Cabin.isnull(),0,1)\ntest_data[\"CabStatus\"] = np.where(test_data.Cabin.isnull(),0,1)","7a6b8849":"train_data","7b663721":"def split_cabin(cabin_no):\n  return cabin_no[0]\n\ntrain_data[\"Cabin\"] = np.where(train_data.Cabin.isnull(),'Z',train_data.Cabin)\ntrain_data[\"Cabin\"] = np.where(train_data.Cabin == 'G6','Z',train_data.Cabin)\ntrain_data[\"Cabin\"] = np.where(train_data.Cabin == 'T','Z',train_data.Cabin)\ntest_data[\"Cabin\"] = np.where(test_data.Cabin.isnull(),'Z',test_data.Cabin)\ntest_data[\"Cabin\"] = np.where(test_data.Cabin == 'G6','Z',test_data.Cabin)\ntest_data[\"Cabin\"] = np.where(test_data.Cabin == 'T','Z',test_data.Cabin)\n\ntrain_data['cabin_no'] = train_data.apply(lambda row: split_cabin(row.Cabin), axis=1)\ntest_data['cabin_no'] = test_data.apply(lambda row: split_cabin(row.Cabin), axis=1)","f9d0b59f":"train_data['sex_class']=train_data.Pclass.astype(str)+train_data.Sex","635c42f0":"train_data.sex_class.value_counts()","399af0cc":"test_data['sex_class']=test_data.Pclass.astype(str)+test_data.Sex","b4961bdc":"train_data.columns","2b2d8bc4":"from sklearn.model_selection import train_test_split\nX_training, X_val, Y_training, Y_val = train_test_split(train_data[[\"PassengerId\",\"Pclass\",\"Name\",\"Sex\",\"Age\",\"sex_class\",\n                                                                    \"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\",\n                                                                    'WithoutFamily','CabStatus', 'cabin_no']], \n                                                        train_data.Survived,\n                                                    stratify=train_data.Survived, random_state=1,\n                                                    test_size=0.20)\n\n\nprint(\"Shape of train split :\",X_training.shape,Y_training.shape)\nprint(\"Shape of test split :\",X_val.shape,Y_val.shape)","99c72bdf":"train_data.describe()","998a03ce":"from sklearn.ensemble import RandomForestClassifier\n\ny = Y_training\n\nfeatures = [\"sex_class\",\"Fare\", \"Age\", \"SibSp\",\"Parch\",\"CabStatus\",\"WithoutFamily\"] #\"Embarked\", , \"Pclass\", \"Sex\",\"cabin_no\"\nX = pd.get_dummies(X_training[features])\nX_validation = pd.get_dummies(X_val[features])\n\nmodel = RandomForestClassifier(n_estimators=350, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_validation)\n\noutput = pd.DataFrame({'PassengerId': X_val.PassengerId, 'Survived_orgnl': Y_val, 'Survived_pred': predictions})\noutput['final'] = np.where(output.Survived_orgnl == output.Survived_pred, 1,0)\naccuracy = sum(output.final)\/len(output.final)\nprint(\"Accuracy is : \",accuracy)\n","330b989d":"candidate_max_depths = [3,4,5,6,7,8,9,10]\ncandidate_estimators = [200,250,300,350,400,450,500,550,600]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\naccuracy_dict,estimators_dicts = {},{}\n\nfor val1 in candidate_max_depths:\n    for val2 in candidate_estimators:\n        y = Y_training\n        features = [\"sex_class\",\"Fare\", \"Age\", \"SibSp\",\"Parch\",\"CabStatus\",\"WithoutFamily\"]\n        X = pd.get_dummies(X_training[features])\n        X_validation = pd.get_dummies(X_val[features])\n\n        model = RandomForestClassifier(n_estimators=val2, max_depth=val1, random_state=1)\n        model.fit(X, y)\n        predictions = model.predict(X_validation)\n\n        output = pd.DataFrame({'PassengerId': X_val.PassengerId, 'Survived_orgnl': Y_val, 'Survived_pred': predictions})\n        output['final'] = np.where(output.Survived_orgnl == output.Survived_pred, 1,0)\n        accuracy = sum(output.final)\/len(output.final)\n        print(\"Accuracy of {} depth & {} Estimators : {}\".format(val1,val2,accuracy))\n        \n        estimators_dicts[val2] = accuracy\n    accuracy_dict[val1] = estimators_dicts\n    print(\"For {} Max depth the Accuracies are: {}\".format(val1,accuracy_dict[val1]))\n\nprint(\"Matrix of depths and estimators and accuracies is : \\n{}\".format(accuracy_dict))\n# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n#best_tree_size = mae_list[min(mae_list.keys())]","91218187":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\n#features = [\"Pclass\", \"Sex\",\"Fare\", \"Age\",\"cabin_no\",\"SibSp\"] #\"Embarked\",\"CabStatus\",\"WithFamily\", \"Parch\"\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=200, max_depth=7, random_state=1)\n#model = RandomForestClassifier(random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0048431a":"X","b41f960c":"#### Handling null values in categorical column - Embarked ","45bbdab2":"### Creating new column using sex and passenger class","efc3f0e4":"### Scatter between Age and Price of ticket","c2cfa473":"#### Understaning few columns","f20151dd":"### For testing submission","9ef49f35":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","aa0d94cc":"### Introducing Validation set","e94bcf56":"### **Test data, fixing Age column**","0649b395":"### creating new column in place of Parch and Sibsp as 'WithFamily'","e4c40681":"#### Creating new column for Cabin - Where Cabin is missing 0","fc4f4fe5":"### **Train data, fixing Age column**"}}