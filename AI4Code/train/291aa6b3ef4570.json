{"cell_type":{"55d2254d":"code","b7a81666":"code","b7807a17":"code","56b14bc0":"code","f00c498b":"code","dc0a903d":"code","dbcbdce8":"code","a8ddcdc1":"code","096c775e":"code","f47d529d":"code","cd7e2bc3":"code","d1333814":"code","cbc120d9":"code","0044149e":"code","997ef1f6":"code","c36d0b45":"code","0c4e6cfb":"code","d6f2467d":"code","40c584d6":"code","693b4838":"code","6fa935e7":"code","b5cd8318":"code","47fb2b17":"code","a916c6ed":"markdown","b14a2b28":"markdown","81dca97c":"markdown","e1d98f16":"markdown","0a2bcfbb":"markdown","b051c504":"markdown","6641940a":"markdown","97798ceb":"markdown","78e157e2":"markdown","6cfe615b":"markdown","51f754ac":"markdown","50ba617c":"markdown"},"source":{"55d2254d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import mode\n        \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras import models, optimizers\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, SpatialDropout2D\nfrom keras.layers.normalization import BatchNormalization\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nnp.random.seed(42)\ntf.random.set_seed(42)","b7a81666":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\ntrain.head()","b7807a17":"train.describe().loc['max',].max()","56b14bc0":"train.shape, test.shape","f00c498b":"Y_train = to_categorical(train['label'].values, 10)\nX_train = (train.loc[:, 'pixel0':] \/ 255).values\n\nX_train.shape, Y_train.shape","dc0a903d":"X_test = (test \/ 255).values","dbcbdce8":"X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\nX_test = X_test.reshape((X_test.shape[0], 28, 28, 1))","a8ddcdc1":"X_train.shape, X_test.shape","096c775e":"datagener = ImageDataGenerator(\n    rotation_range=15,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n)","f47d529d":"example = X_train[6].reshape((1, 28, 28, 1))\nlabel = Y_train[6]","cd7e2bc3":"label = label.reshape((1, 10))\nlabel","d1333814":"plt.figure(figsize=(12, 12))\nfor i in range(20):\n    plt.subplot(1, 20, i + 1)\n    img, lb = datagener.flow(example, label).next()\n    plt.imshow(img[0].squeeze(), cmap=plt.cm.binary)\n    plt.axis('off')","cbc120d9":"# from sklearn.utils import class_weight\n\n# weight = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\n# weight = {i : weight[i] for i in np.unique(Y_train)}\n# weight","0044149e":"# X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.2)","997ef1f6":"count_network = 5\nsize_for_network = X_train.shape[0] \/\/ count_network\nX_train_list = []\nX_valid_list = []\n\nY_train_list = []\nY_valid_list = []\n\nfor i in range(count_network):\n    X_train_list.append(X_train[i * size_for_network : (i + 1) * size_for_network])\n    Y_train_list.append(Y_train[i * size_for_network : (i + 1) * size_for_network])\n    \n    X_valid_list.append(\n        np.concatenate((X_train[0 * size_for_network : i * size_for_network], \n                        X_train[(i + 1) * size_for_network : count_network * size_for_network]))\n    )\n    \n    Y_valid_list.append(\n        np.concatenate((Y_train[0 * size_for_network : i * size_for_network], \n                        Y_train[(i + 1) * size_for_network : count_network * size_for_network]))\n    )","c36d0b45":"def build_model(lr):\n    model = models.Sequential()\n    model.add(Conv2D(96, 3, activation='relu', padding='same', input_shape=(28, 28, 1)))\n    model.add(BatchNormalization())\n    model.add(SpatialDropout2D(0.4))\n\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(160, 3, activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(SpatialDropout2D(0.4))\n\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(256, 3, activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(SpatialDropout2D(0.4))\n    \n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(128, 3, activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(SpatialDropout2D(0.4))\n    \n#     model.add(MaxPooling2D((2, 2)))\n#     model.add(Conv2D(96, 3, activation='relu', padding='same'))\n#     model.add(BatchNormalization())\n#     model.add(SpatialDropout2D(0.4))\n\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, 3, activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(SpatialDropout2D(0.4))\n\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(96, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(optimizer=optimizers.Adam(lr=lr), \n                  loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n    \n    return model","0c4e6cfb":"list_models = [build_model(lr=1e-2) for _ in range(count_network)]\nlist_history = []\n\nfor i in range(count_network):\n    checkpoint_path = f'bestmodel{i + 1}.hdf5'\n    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_categorical_accuracy', \n                                 verbose=0, save_best_only=True, mode='max')\n\n    scheduler = LearningRateScheduler(lambda epoch, lr: lr * 0.99, verbose=0)\n\n    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=50, mode='min', verbose=0)\n\n    tqdm_callback = tfa.callbacks.TQDMProgressBar(leave_epoch_progress=False, \n                                                  leave_overall_progress=True, \n                                                  show_epoch_progress=False,\n                                                  show_overall_progress=True)\n\n    callbacks_list = [\n        checkpoint, \n        scheduler, \n        tqdm_callback, \n       early_stop\n    ]\n    \n    print(f'Training {i + 1} network' + '\\n' + '-' * 80)\n    \n    history = list_models[i].fit_generator(datagener.flow(X_train_list[i], Y_train_list[i], batch_size=50), \n                                           epochs=350, steps_per_epoch=X_train_list[i].shape[0] \/\/ 50,\n                                           callbacks=callbacks_list, \n                                           # class_weight=weight,\n                                           verbose=0, validation_data=(X_valid_list[i], Y_valid_list[i]))\n    \n    list_history.append(history)","d6f2467d":"for i in range(count_network):\n    list_models[i].load_weights(f'bestmodel{i + 1}.hdf5')\n    print(f'Model \u2116{i + 1}')\n    _, acc = list_models[i].evaluate(X_train_list[i], Y_train_list[i])\n    _, acc2 = list_models[i].evaluate(X_valid_list[i], Y_valid_list[i])\n    print()","40c584d6":"def graph_plot(history, typ=False):\n    fig = plt.figure(figsize=(30, 5))\n    if typ:\n        for i in history.history.keys():\n            print(f'{i} = [{min(history.history[i])}; {max(history.history[i])}]\\n')\n    \n    epoch = len(history.history['loss'])\n    # \u043d\u0430 \u043a\u0430\u0436\u0434\u0443\u044e: (train, val) + lr\n    size = len(history.history.keys()) \/\/ 2 + 1\n    \n    i = 1\n    for k in list(history.history.keys()):\n        if 'val' not in k:\n            fig.add_subplot(1, size, i)\n            plt.plot(history.history[k], marker='o', markersize=5)\n            if k != 'lr':\n                plt.plot(history.history['val_' + k], marker='o', markersize=5)\n            if k == 'loss':\n                plt.yscale('log')\n\n            plt.title(k, fontsize=10)\n\n            plt.ylabel(k)\n            plt.xlabel('epoch')\n            plt.grid()\n\n            plt.yticks(fontsize=10, rotation=30)\n            plt.xticks(fontsize=10, rotation=30)\n            plt.legend(['train', 'valid'], loc='upper left', fontsize=10, title_fontsize=15)\n            i += 1\n#         plt.show()","693b4838":"for i in range(count_network):\n    graph_plot(list_history[i])","6fa935e7":"def get_predict(models, data, method_voting='soft', count_classes=10):\n    if method_voting == 'soft':\n        for_test = np.zeros((data.shape[0], count_classes))\n        \n        for i in range(len(models)):\n            for_test += models[i].predict(data)\n\n        return np.argmax(for_test, axis=1)\n        \n    elif method_voting == 'hard':\n        for_test = np.zeros((data.shape[0], len(models)))\n\n        for i in range(len(models)):\n            for_test[:, i] += models[i].predict_classes(data)\n        \n        return np.int32(mode(for_test, axis=1)[0].T.flatten())","b5cd8318":"submit = pd.DataFrame(get_predict(list_models, X_test), columns=['Label'], index=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')['ImageId'])\nsubmit2 = pd.DataFrame(get_predict(list_models, X_test, method_voting='hard'), columns=['Label'], \n                       index=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')['ImageId'])\n\nsubmit.index.name = 'ImageId'\nsubmit.to_csv('submittion.csv')\nsubmit2.index.name = 'ImageId'\nsubmit2.to_csv('submittion2.csv')","47fb2b17":"comparison = submit.join(submit2, lsuffix='_1', rsuffix='_2')\ncomparison.loc[~(comparison['Label_1'] == comparison['Label_2'])]","a916c6ed":"## RGB format","b14a2b28":"## Comparison predict","81dca97c":"## Vizualize ImageGenerator","e1d98f16":"## Loading data","0a2bcfbb":"## Ensemble CNN","b051c504":"## Predict: soft and hard voting","6641940a":"## Import Libraries","97798ceb":"## Loss graphs","78e157e2":"8.4k images will be used for each neural network and checked on the remaining (42 - 8.4)k","6cfe615b":"## Normalize","51f754ac":"## Load model and evaluate","50ba617c":"## Train and Validation"}}