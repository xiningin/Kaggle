{"cell_type":{"df765150":"code","3632f473":"code","0e5d482a":"code","77acf9a8":"code","c5b73d45":"code","d1c9b155":"code","f61d0ef6":"code","b4878e2c":"code","93a8b2d4":"code","15f69faa":"code","c369a425":"code","e882d14f":"code","da7d0f47":"code","d63a0f93":"code","c81ed813":"code","340c0dde":"code","c9e91fe0":"code","d249d25a":"code","0b364cdb":"code","840a25ad":"code","482a049b":"code","33de9340":"code","b37f3e8f":"code","766965b2":"code","b2b871d8":"code","917954f1":"code","6aacf3bd":"code","be2d3e54":"code","38290085":"code","b1c64688":"code","7a1dfbdb":"code","d0659cf1":"code","c2c0e698":"code","d495df0c":"code","c49f4503":"code","66f5cfb6":"code","c9637df5":"code","64eb4a22":"code","9bdf8f93":"code","dc779e18":"code","3682fbc0":"code","fa8454d7":"code","debad883":"code","7e45730d":"code","a6577d6a":"code","9debc62e":"code","e776a8a2":"code","de333726":"code","3466a3ec":"code","b1330a18":"code","34681ac6":"code","51c7185f":"code","8f2bc152":"code","1900befb":"code","0588582e":"code","26d857e6":"code","9b5f7034":"code","191352d1":"code","fa82af8f":"code","1ea25074":"code","85dffbc2":"code","485a4c2b":"code","8557d427":"code","7a523b5c":"code","e1b5a133":"code","9851dc1c":"code","1b838c71":"code","e4689f36":"code","b2c66640":"code","6601d947":"code","063051e4":"code","599e014f":"code","422e2188":"code","1369721b":"code","50e8e8a8":"code","bd06f590":"code","861e375c":"code","12a2aa8d":"code","8c14d1af":"code","5dadb365":"code","ff34e567":"code","8c8d412f":"code","7b12a1cd":"code","850ebac5":"code","07f04bc1":"code","1788d813":"code","1b276f6b":"code","9ada4e62":"code","c426352b":"code","15af5023":"code","7dad33b0":"code","188263f9":"code","c5525114":"code","e631854a":"code","6ff0d4e2":"code","ae73f53f":"code","c5dba9a5":"code","7bcb9ff4":"code","635cbde1":"code","c0a470fe":"code","1a893ba9":"code","bb3d4374":"code","925b1805":"code","519de9b0":"code","99a6b2eb":"code","13adc746":"code","ea13d39b":"code","f4c606a9":"code","8dd792fd":"code","2bee69e7":"code","92a2f68b":"code","e9ccc87c":"code","bb232761":"code","3552ec02":"code","d571b189":"code","6023ca93":"code","0e406ac3":"code","c6777316":"code","d36fbf95":"code","531b7397":"code","47ff82ff":"code","eb8a529c":"code","a50ebb51":"code","bc01bef0":"code","36cd4748":"code","f6d99c3a":"code","fafe6863":"code","ef0c8ced":"code","2a7cbaa3":"code","cb03c4ab":"code","6731f750":"code","e0a66d22":"code","b2af80a6":"code","d8ccc580":"code","aca457bd":"code","5f3a2496":"code","46ff4c27":"code","838ca41d":"code","e7749e51":"code","d4212f48":"code","fadfd85e":"code","e79f0bc7":"code","9458b973":"code","bb4e3f2a":"code","bd43af7b":"code","711a3adb":"code","0508bdf3":"code","cc9adf32":"code","70d33cb7":"code","27b4d293":"code","64e0317a":"code","bb05d45c":"code","39f4e5aa":"code","c9870e71":"code","a166d65d":"code","92e9e0d6":"code","e139c4d9":"code","09652462":"code","61814195":"code","337f2202":"code","ce0cd7e1":"code","9b5c714c":"code","447ed32b":"code","7de6d61c":"code","84b1c259":"code","291a3ba1":"code","37fa2541":"code","3beb5db8":"code","41b688dc":"code","0d9974f9":"code","c9cb8a6e":"code","abc55147":"code","6dec0e1d":"code","76889d58":"code","89cd09a1":"code","d1dada48":"code","ee933630":"code","43d0d3a8":"code","b9e5dc6f":"code","985da625":"code","f3af51c6":"code","1497fdde":"markdown","174d0fb9":"markdown","452f964c":"markdown","848f5204":"markdown","b47dc2c3":"markdown","f0c08340":"markdown","5fa2bd88":"markdown","4b66d479":"markdown","fb9d8a27":"markdown","970ad37c":"markdown","cb9c44b9":"markdown","9ad6b213":"markdown","ed86dbca":"markdown","2ad9001a":"markdown","cac6e0f9":"markdown","8011b44f":"markdown","1b0d188d":"markdown","fb878090":"markdown","7bc259a6":"markdown","ea9a3652":"markdown","6195cfda":"markdown","47b69cc0":"markdown","3c1c3b17":"markdown","2855a2f4":"markdown","792cd966":"markdown","9211ab46":"markdown","43022cbb":"markdown","b12b268d":"markdown","bf604a68":"markdown","213e6304":"markdown","39834f6a":"markdown","22f9c8b2":"markdown","52975f8a":"markdown","42164b9e":"markdown","dbd89c64":"markdown","3b5fa645":"markdown","72b06680":"markdown","28a1e23d":"markdown","1f7a0493":"markdown","35d123b3":"markdown","c8b9dc1d":"markdown","6cbfca07":"markdown","93614cfe":"markdown","b9dc71cd":"markdown","82a38d4f":"markdown","c75d374e":"markdown","3f6bb4b7":"markdown","b6b9d23b":"markdown","71613854":"markdown","3bbb4943":"markdown","d744c99d":"markdown","726c9c63":"markdown","262dde9d":"markdown","d17796c9":"markdown","724113cd":"markdown","7961043e":"markdown","3343a09d":"markdown","50c0f34a":"markdown","463a3e4b":"markdown","b2a34881":"markdown","dc9edcbf":"markdown","e3d736d2":"markdown","461b289b":"markdown","eea206db":"markdown","588964fa":"markdown","b456f756":"markdown"},"source":{"df765150":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3632f473":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0e5d482a":"df_train = pd.read_csv('..\/input\/housing-data\/train.csv')\ndf_train.head()","77acf9a8":"df_train['SalePrice'].describe()","c5b73d45":"df_train['Id'].nunique() ","d1c9b155":"sns.distplot(df_train['SalePrice'])","f61d0ef6":"print(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","b4878e2c":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum())\/(df_train.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","93a8b2d4":"delete_features = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage']","15f69faa":"df_train = df_train.drop(delete_features, axis = 1)","c369a425":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum())\/(df_train.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","e882d14f":"df_train.loc[:, 'GarageType'].fillna('None') # for no garage","da7d0f47":"garageyrblt_mask = df_train['GarageYrBlt'].isnull()","d63a0f93":"df_train.loc[garageyrblt_mask,'GarageYrBlt'] = df_train.loc[garageyrblt_mask, 'YearBuilt']","c81ed813":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum())\/(df_train.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)\n# Now our garageyrblt is filled","340c0dde":"df_train.loc[:, 'GarageType'] = df_train.loc[:, 'GarageType'].fillna('None') # for no garage\ndf_train.loc[:, 'GarageFinish'] = df_train.loc[:, 'GarageFinish'].fillna('None') # for no garage\ndf_train.loc[:, 'GarageQual'] = df_train.loc[:, 'GarageQual'].fillna('None') # for no garage\ndf_train.loc[:, 'GarageCond'] = df_train.loc[:, 'GarageCond'].fillna('None') # for no gagage","c9e91fe0":"df_train.loc[:, 'BsmtQual'] = df_train.loc[:, 'BsmtQual'].fillna('None') # for no basement\ndf_train.loc[:, 'BsmtCond'] = df_train.loc[:, 'BsmtCond'].fillna('None') # for no basement\ndf_train.loc[:, 'BsmtExposure'] = df_train.loc[:, 'BsmtExposure'].fillna('None') # for no basement\ndf_train.loc[:, 'BsmtFinType1'] = df_train.loc[:, 'BsmtFinType1'].fillna('None') # for no basement\ndf_train.loc[:, 'BsmtFinType2'] = df_train.loc[:, 'BsmtFinType2'].fillna('None') # for no basement","d249d25a":"df_train['MasVnrType'].value_counts()","0b364cdb":"df_train['MasVnrArea'].value_counts","840a25ad":"df_train.loc[:, 'MasVnrType'] = df_train.loc[:, 'MasVnrType'].fillna('None')\ndf_train.loc[:, 'MasVnrArea'] = df_train.loc[:, 'MasVnrArea'].fillna(0)","482a049b":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum())\/(df_train.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","33de9340":"df_train['Electrical'].value_counts()","b37f3e8f":"df_train.loc[:, 'Electrical'] = df_train.loc[:, 'Electrical'].fillna('None')","766965b2":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum())\/(df_train.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","b2b871d8":"df_train['MoSold'].value_counts()","917954f1":"df_train = df_train.replace({'MSSubClass': {20: 'SC20', 30: 'SC30', 40: 'SC40', 50: 'SC50', 60: 'SC60',\n70: 'SC70', 80: 'SC80', 85: 'SC85', 90: 'SC90', 120: 'SC120', 150: 'SC150', 160: 'SC160', 180: 'SC180', 190: 'SC190'},\n'MoSold': {1: 'January', 2: 'Feburary', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August',\n          9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n                 })","6aacf3bd":"df_train['MoSold'].value_counts()","be2d3e54":"df_train = df_train.replace({'LotShape': {'IR3': 1, 'IR2': 2, 'IR1': 3, 'Reg': 4},\n                             'LandSlope': {'Gtl': 1, 'Mod': 2, 'Sev': 3},\n                            'ExterQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'ExterCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtQual': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtCond': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtExposure': {'None': 0, 'No': 0, 'Mn': '1', 'Av': 2, 'Gd': 3},\n                            'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n                            'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n                            'HeatingQC': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'Functional': {'Sal': 0,'Sev': 1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2': 5, 'Min1': 6, 'Typ': 7},\n                            'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3},\n                            'GarageQual': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'GarageCond': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            })","38290085":"df_train_ordinal_dict = ({'LotShape': {'IR3': 1, 'IR2': 2, 'IR1': 3, 'Reg': 4},\n                             'LandSlope': {'Gtl': 1, 'Mod': 2, 'Sev': 3},\n                            'ExterQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'ExterCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtQual': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtCond': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtExposure': {'None': 0, 'No': 0, 'Mn': '1', 'Av': 2, 'Gd': 3},\n                            'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n                            'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n                            'HeatingQC': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'Functional': {'Sal': 0,'Sev': 1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2': 5, 'Min1': 6, 'Typ': 7},\n                            'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3},\n                            'GarageQual': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'GarageCond': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            })","b1c64688":"df_train_ordinal_dict.keys()","7a1dfbdb":"corrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","d0659cf1":"corr = df_train.corr()\ncorr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\ncorr['SalePrice'][:20]","c2c0e698":"# much closer to normal distribution\nfrom scipy.stats import norm\ndf_train['log_SalePrice'] = np.log(df_train['SalePrice'])\nsns.distplot(df_train['log_SalePrice'], fit = norm)\nplt.title('Log SalePrice Histogram\\n')","d495df0c":"from sklearn.feature_selection import f_classif","c49f4503":"X = df_train.loc[:, df_train.corr().index.tolist()[1:-2]].values\nY = df_train.iloc[:,-1].values","66f5cfb6":"[f_stat, f_p_value] = f_classif(X,Y)","c9637df5":"f_test_df = pd.DataFrame({'feature':df_train.corr().index.tolist()[1:-2],\n                         'f_statistic':f_stat,\n                         'p_value':f_p_value})","64eb4a22":"f_test_df.sort_values('p_value')[:20]","9bdf8f93":"ftest_features = f_test_df.sort_values('p_value')['feature'][:20].tolist()","dc779e18":"corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\ncorr_features = corr['SalePrice'].index.tolist()[1:21]","3682fbc0":"features = [value for value in corr_features if value in ftest_features] + ['SalePrice']","fa8454d7":"mpl.rcParams['figure.dpi'] = 150 ","debad883":"#saleprice correlation matrix\ncm = np.corrcoef(df_train[features].values.T)\nsns.set(font_scale = .35)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, yticklabels=features, \n                 xticklabels=features)\nplt.show()","7e45730d":"features.remove('2ndFlrSF')\nfeatures.remove('BsmtFinSF1')\nfeatures.remove('Fireplaces')\nfeatures.remove('MasVnrArea')","a6577d6a":"features","9debc62e":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'OverallQual', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('OverallQual')","e776a8a2":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'ExterQual', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('ExterQual Boxplot')","de333726":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'KitchenQual', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('KitchenQual Boxplot')","3466a3ec":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'GarageCars', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('GarageCars Boxplot')","b1330a18":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'FullBath', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('FullBath Boxplot')","34681ac6":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'TotRmsAbvGrd', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('TotRmsAbvGrd Boxplot')","51c7185f":"features","8f2bc152":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'YearBuilt', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('YearBuilt Boxplot')\nplt.xticks(rotation = 90);","1900befb":"df_train['GarageYrBlt'] = df_train['GarageYrBlt'].astype('int64')","0588582e":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'GarageYrBlt', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('GarageYrBlt Boxplot')\nplt.xticks(rotation = 90);","26d857e6":"f, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x = 'YearRemodAdd', y=\"SalePrice\", data = df_train)\nfig.axis(ymin=0, ymax=800000)\nplt.title('YearRemodAdd Boxplot')\nplt.xticks(rotation = 90);","9b5f7034":"from scipy import stats","191352d1":"plt.scatter(df_train['GrLivArea'], df_train['SalePrice'])\nplt.title('GrLivArea vs SalePrice')\nplt.xlabel('GrLivArea')\nplt.ylabel('SalePrice')","fa82af8f":"sns.distplot(df_train['GrLivArea'], fit=norm);","1ea25074":"res = stats.probplot(df_train['GrLivArea'], plot=plt)","85dffbc2":"df_train['GrLivArea'] =  np.log(df_train['GrLivArea'])\nsns.distplot(df_train['GrLivArea'], fit=norm)","485a4c2b":"plt.scatter(df_train['GrLivArea'], df_train['log_SalePrice'])\nplt.title('GrLivArea vs SalePrice')\nplt.xlabel('GrLivArea')\nplt.ylabel('SalePrice')","8557d427":"res = stats.probplot(df_train['GrLivArea'], plot=plt)","7a523b5c":"df_train[df_train['GrLivArea'] > 8.3][['GrLivArea', 'log_SalePrice']]\n# So we will take out 523 and 1298","e1b5a133":"df_train = df_train.drop([523,1298])","9851dc1c":"plt.scatter(df_train['GrLivArea'], df_train['log_SalePrice'])\nplt.title('GrLivArea vs SalePrice')\nplt.xlabel('GrLivArea')\nplt.ylabel('SalePrice')","1b838c71":"df_train['GrLivAreaSq'] = df_train['GrLivArea']**2\ndf_train['GrLivAreaCu'] = df_train['GrLivArea']**3","e4689f36":"plt.scatter(df_train['GarageArea'], df_train['log_SalePrice'])\nplt.xlabel('GarageArea')\nplt.ylabel('SalePrice')\nplt.title('GarageArea vs SalePrice')","b2c66640":"df_train[df_train['GarageArea'] > 1200][['GarageArea', 'log_SalePrice']]","6601d947":"df_train = df_train.drop([581, 1061, 1190])","063051e4":"sns.distplot(df_train['GarageArea'], fit=norm)","599e014f":"print(\"Skewness: %f\" % df_train['GarageArea'].skew())\nprint(\"Kurtosis: %f\" % df_train['GarageArea'].kurt())","422e2188":"res = stats.probplot(df_train['GarageArea'], plot=plt)","1369721b":"df_train['GarageAreaSq'] = df_train['GarageArea']**2\ndf_train['GarageAreaCu'] = df_train['GarageArea']**3","50e8e8a8":"plt.scatter(df_train['TotalBsmtSF'], df_train['log_SalePrice'])\nplt.title('TotalBsmtSF vs LogSalePrice')\nplt.xlabel('TotalBsmtSF')\nplt.ylabel('LogSalePrice')","bd06f590":"df_train[df_train['TotalBsmtSF'] > 3000][['TotalBsmtSF', 'log_SalePrice']]","861e375c":"df_train = df_train.drop([440,332])","12a2aa8d":"sns.distplot(df_train['TotalBsmtSF'], fit=norm)","8c14d1af":"df_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\ndf_train['HasBsmt'] = 0 \ndf_train.loc[df_train['TotalBsmtSF'] > 0,'HasBsmt'] = 1\ndf_train.loc[df_train['HasBsmt'] == 1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])","5dadb365":"sns.distplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);","ff34e567":"res = stats.probplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","8c8d412f":"df_train['TotalBsmtSFSq'] = df_train['TotalBsmtSF']**2\ndf_train['TotalBsmtSFCu'] = df_train['TotalBsmtSF']**3","7b12a1cd":"plt.scatter(df_train['1stFlrSF'], df_train['log_SalePrice'])\nplt.title('1stFlrSF vs log_SalePrice')\nplt.xlabel('1stFlrSF')\nplt.ylabel('log_SalePrice')","850ebac5":"sns.distplot(df_train['1stFlrSF'], fit=norm)\nplt.title('1stFlrSF Histogram')","07f04bc1":"res = stats.probplot(df_train['1stFlrSF'], plot=plt)","1788d813":"df_train['1stFlrSF'] = np.log(df_train['1stFlrSF'])","1b276f6b":"sns.distplot(df_train['1stFlrSF'], fit=norm)\nplt.title('1stFlrSF Histogram')","9ada4e62":"plt.scatter(df_train['1stFlrSF'], df_train['log_SalePrice'])\nplt.title('1stFlrSF vs log_SalePrice')\nplt.xlabel('1stFlrSF')\nplt.ylabel('log_SalePrice')","c426352b":"res = stats.probplot(df_train['1stFlrSF'], plot=plt)","15af5023":"df_train['1stFlrSFSq'] = df_train['1stFlrSF']**2\ndf_train['1stFlrSFCu'] = df_train['1stFlrSF']**3","7dad33b0":"features = features +['GrLivAreaSq', 'GrLivAreaCu', 'GarageAreaSq', 'GarageAreaCu', 'TotalBsmtSFSq', 'TotalBsmtSFCu', '1stFlrSFSq', '1stFlrSFCu'] #add new features                          #our featurs so far","188263f9":"corr['SalePrice'].index.tolist()","c5525114":"cat_features = [x for x in df_train.columns.tolist() if x not in corr['SalePrice'].index.tolist() ]\ncat_features = ['Id'] + cat_features\n","e631854a":"cat_features.remove('log_SalePrice')","6ff0d4e2":"features = cat_features + features","ae73f53f":"features.sort()","c5dba9a5":"features = set(features)","7bcb9ff4":"df_train['SalePrice'] = df_train['log_SalePrice']","635cbde1":"df_train = df_train.drop(['log_SalePrice'], axis = 1)","c0a470fe":"original_features = df_train.columns.tolist()","1a893ba9":"df_train_clean = pd.get_dummies(df_train[features])","bb3d4374":"# Now we have the dataset we will use for our model\ndf_train_clean.head()","925b1805":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.linear_model import LinearRegression","519de9b0":"columns = df_train_clean.columns.tolist()","99a6b2eb":"columns.remove('SalePrice')","13adc746":"X_train, X_val, y_train, y_val = train_test_split(df_train_clean[columns], df_train_clean['SalePrice'], test_size = .3, random_state = 19)","ea13d39b":"lin_model = LinearRegression(fit_intercept = True)\nlin_model.fit(X_train, y_train)","f4c606a9":"print(lin_model.coef_) # Many of our coefficents are close to zero and this regression could benefit from a cost function regression \nprint(lin_model.intercept_)","8dd792fd":"housing_predict = lin_model.predict(X_val)\nlin_rmse = np.sqrt(mean_squared_error(y_val, housing_predict)) # Linear Regression MSE\nlin_rmse","2bee69e7":"lin_r2 = r2_score(y_val, housing_predict) \nlin_r2","92a2f68b":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV","e9ccc87c":"ridge_model = Ridge(fit_intercept = True, solver = 'cholesky')\nparams = {'alpha': [0, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 1, 10**1, 10**2,10**3, 10**4, 10**5]}","bb232761":"cv_ridge = GridSearchCV(ridge_model, param_grid = params, scoring = ['neg_root_mean_squared_error', 'r2'],\n                 n_jobs = None, iid = False, refit = 'r2', cv = 4, verbose = 1, \n                 pre_dispatch = None, error_score = np.nan, return_train_score = True)","3552ec02":"ridge_model.get_params().keys()","d571b189":"cv_ridge.fit(df_train_clean[columns], df_train_clean['SalePrice']) \n# use the whole dataset the data will be split for us in GridSearchCV","6023ca93":"cv_ridge_df = pd.DataFrame(cv_ridge.cv_results_)\ncv_ridge_df","0e406ac3":"cv_ridge_df[['param_alpha', 'mean_train_neg_root_mean_squared_error',\n             'mean_test_neg_root_mean_squared_error', 'mean_test_r2', 'mean_train_r2']]","c6777316":"cv_ridge.best_params_ ","d36fbf95":"ridge_model = Ridge(alpha = 10, fit_intercept = True, solver = 'cholesky', max_iter = 10000000)","531b7397":"ridge_model.fit(X_train, y_train)","47ff82ff":"y_pred_ridge = ridge_model.predict(X_val)","eb8a529c":"ridge_rmse = np.sqrt(mean_squared_error(y_val, y_pred_ridge))\nridge_rmse","a50ebb51":"ridge_r2 = r2_score(y_val, y_pred_ridge)\nridge_r2","bc01bef0":"from sklearn.linear_model import Lasso","36cd4748":"lasso_model = Lasso(fit_intercept = True)","f6d99c3a":"cv_lasso = GridSearchCV(lasso_model, param_grid = params, scoring = ['neg_root_mean_squared_error', 'r2'],\n                 n_jobs = None, iid = False, refit = 'r2', cv = 4, verbose = 1, \n                 pre_dispatch = None, error_score = np.nan, return_train_score = True)","fafe6863":"cv_lasso.fit(df_train_clean[columns], df_train_clean['SalePrice'])","ef0c8ced":"cv_lasso_df = pd.DataFrame(cv_lasso.cv_results_)\ncv_lasso_df","2a7cbaa3":"cv_lasso_df[['param_alpha', 'mean_train_neg_root_mean_squared_error',\n             'mean_test_neg_root_mean_squared_error', 'mean_test_r2', 'mean_train_r2']]","cb03c4ab":"cv_lasso.best_params_","6731f750":"lasso_model = Lasso(alpha = 0.001, fit_intercept = True, max_iter = 10000000)","e0a66d22":"lasso_model.fit(X_train, y_train)","b2af80a6":"y_pred_lasso = lasso_model.predict(X_val)","d8ccc580":"lasso_rmse = np.sqrt(mean_squared_error(y_val, y_pred_lasso))\nlasso_rmse","aca457bd":"lasso_r2 = r2_score(y_val, y_pred_lasso)\nlasso_r2","5f3a2496":"from sklearn.linear_model import ElasticNet","46ff4c27":"elastic_model = ElasticNet(fit_intercept = True)","838ca41d":"elastic_model.get_params().keys()","e7749e51":"params = {'alpha': [0, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 1, 10**1, 10**2,10**3, 10**4, 10**5],\n         'l1_ratio': [0, 0.001, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}","d4212f48":"cv_elastic = GridSearchCV(elastic_model, param_grid = params, scoring = ['neg_root_mean_squared_error', 'r2'],\n                 n_jobs = None, iid = False, refit = 'r2', cv = 4, verbose = 1, \n                 pre_dispatch = None, error_score = np.nan, return_train_score = True)","fadfd85e":"cv_elastic.fit(df_train_clean[columns], df_train_clean['SalePrice'])","e79f0bc7":"cv_elastic_df = pd.DataFrame(cv_elastic.cv_results_)\ncv_elastic_df.head()","9458b973":"cv_elastic_df[['params', 'mean_train_neg_root_mean_squared_error',\n             'mean_test_neg_root_mean_squared_error', 'mean_test_r2', 'mean_train_r2']].head()","bb4e3f2a":"cv_elastic.best_params_","bd43af7b":"elastic_model = ElasticNet(fit_intercept = True, alpha = .001, l1_ratio = .5, max_iter = 10000000)","711a3adb":"elastic_model.fit(X_train, y_train)","0508bdf3":"y_pred_elastic = elastic_model.predict(X_val)","cc9adf32":"elastic_rmse = np.sqrt(mean_squared_error(y_val, y_pred_elastic))\nelastic_rmse","70d33cb7":"elastic_r2 = r2_score(y_val, y_pred_elastic)\nelastic_r2","27b4d293":"elastic_r2","64e0317a":"model = ['Linear Model', 'Ridge Model', 'Lasso Model', 'Elastic Net Model']\nr2_score = [lin_r2, ridge_r2, lasso_r2, elastic_r2],\nrmse = [lin_rmse, ridge_rmse, lasso_rmse, elastic_rmse]","bb05d45c":"model_score = pd.DataFrame({'R^2 Score': [lin_r2, ridge_r2, lasso_r2, elastic_r2],\n                            'Root Mean Squared Error': rmse},\n                           index = model)\nmodel_score.head()","39f4e5aa":"model = np.array(['Linear Model', 'Ridge Model', 'Lasso Model', 'Elastic Net Model'])\nr2_score = np.array([lin_r2, ridge_r2, lasso_r2, elastic_r2])\nrmse = np.array([lin_rmse, ridge_rmse, lasso_rmse, elastic_rmse])","c9870e71":"plt.plot(model, r2_score)\nplt.title('Linear Model R^2 Value Validation Data')\nplt.ylabel('R^2 Score')\nplt.scatter(model, r2_score)","a166d65d":"plt.plot(model, rmse, color = 'red')\nplt.title('Linear Model R^2 Value Validation Data')\nplt.ylabel('Root Mean Squared Error')\nplt.scatter(model, rmse, color = 'red')","92e9e0d6":"import numpy as np \nimport pandas as pd","e139c4d9":"df_test = pd.read_csv('..\/input\/housing-data\/test.csv')\ndf_test.head()","09652462":"total = df_test.isnull().sum().sort_values(ascending = False)\npercent = (df_test.isnull().sum())\/(df_test.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","61814195":"delete_features = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage']","337f2202":"df_test = df_test.drop(delete_features, axis = 1)","ce0cd7e1":"total = df_test.isnull().sum().sort_values(ascending = False)\npercent = (df_test.isnull().sum())\/(df_test.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","9b5c714c":"df_test.loc[:, 'GarageType'].fillna('None') # for no garage\ngarageyrblt_mask = df_test['GarageYrBlt'].isnull()\ndf_test.loc[garageyrblt_mask,'GarageYrBlt'] = df_test.loc[garageyrblt_mask, 'YearBuilt']\ndf_test.loc[:, 'GarageType'] = df_test.loc[:, 'GarageType'].fillna('None') # for no garage\ndf_test.loc[:, 'GarageFinish'] = df_test.loc[:, 'GarageFinish'].fillna('None') # for no garage\ndf_test.loc[:, 'GarageQual'] = df_test.loc[:, 'GarageQual'].fillna('None') # for no garage\ndf_test.loc[:, 'GarageCond'] = df_test.loc[:, 'GarageCond'].fillna('None') # for no gagage\ndf_test.loc[:, 'BsmtQual'] = df_test.loc[:, 'BsmtQual'].fillna('None') # for no basement\ndf_test.loc[:, 'BsmtCond'] = df_test.loc[:, 'BsmtCond'].fillna('None') # for no basement\ndf_test.loc[:, 'BsmtExposure'] = df_test.loc[:, 'BsmtExposure'].fillna('None') # for no basement\ndf_test.loc[:, 'BsmtFinType1'] = df_test.loc[:, 'BsmtFinType1'].fillna('None') # for no basement\ndf_test.loc[:, 'BsmtFinType2'] = df_test.loc[:, 'BsmtFinType2'].fillna('None') # for no basement\ndf_test.loc[:, 'MasVnrType'] = df_test.loc[:, 'MasVnrType'].fillna('None')\ndf_test.loc[:, 'MasVnrArea'] = df_test.loc[:, 'MasVnrArea'].fillna(0)\ndf_test.loc[:, 'Electrical'] = df_test.loc[:, 'Electrical'].fillna('None')\ndf_test.loc[:, 'MSZoning'] = df_test.loc[:, 'MSZoning'].fillna('None')\ndf_test.loc[:, 'BsmtFinType2'] = df_test.loc[:, 'BsmtFinType2'].fillna('None')","447ed32b":"df_test = df_test.replace({'MSSubClass': {20: 'SC20', 30: 'SC30', 40: 'SC40', 50: 'SC50', 60: 'SC60',\n70: 'SC70', 80: 'SC80', 85: 'SC85', 90: 'SC90', 120: 'SC120', 150: 'SC150', 160: 'SC160', 180: 'SC180', 190: 'SC190'},\n'MoSold': {1: 'January', 2: 'Feburary', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August',\n          9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n                 })\n\n\ndf_test = df_test.replace({'LotShape': {'IR3': 1, 'IR2': 2, 'IR1': 3, 'Reg': 4},\n                             'LandSlope': {'Gtl': 1, 'Mod': 2, 'Sev': 3},\n                            'ExterQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'ExterCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtQual': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtCond': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'BsmtExposure': {'None': 0, 'No': 0, 'Mn': '1', 'Av': 2, 'Gd': 3},\n                            'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n                            'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n                            'HeatingQC': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n                            'Functional': {'Sal': 0,'Sev': 1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2': 5, 'Min1': 6, 'Typ': 7},\n                            'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3},\n                            'GarageQual': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            'GarageCond': {'None': 0, 'Po': 1, 'Fa': 2, 'Ta': 3, 'Gd': 4, 'Ex': 5},\n                            })","7de6d61c":"total = df_test.isnull().sum().sort_values(ascending = False)\npercent = (df_test.isnull().sum())\/(df_test.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","84b1c259":"bsmtfullbath_mask = df_test['BsmtFullBath'].isnull()\nbsmthalfbath_mask = df_test['BsmtHalfBath'].isnull()\nutilities_mask = df_test['Utilities'].isnull()\nfunctional_mask = df_test['Functional'].isnull()\ntotalbsmtsf_mask = df_test['TotalBsmtSF'].isnull()\ngaragearea_mask = df_test['GarageArea'].isnull()\nbsmtfinsf2_mask = df_test['BsmtFinSF2'].isnull()\nbsmtunfsf_mask = df_test['BsmtUnfSF'].isnull()\nsaletype_mask = df_test['SaleType'].isnull()\nexterior2nd_mask = df_test['Exterior2nd'].isnull()\nexterior1st_mask = df_test['Exterior1st'].isnull()\nkitchenqual_mask = df_test['KitchenQual'].isnull()\ngaragecars_mask = df_test['GarageCars'].isnull()\nbsmtfinsf1_mask = df_test['BsmtFinSF1'].isnull()","291a3ba1":"df_test.loc[bsmtfullbath_mask,'BsmtFullBath'] = 0\ndf_test.loc[bsmthalfbath_mask,'BsmtHalfBath'] = 0\ndf_test.loc[utilities_mask, 'Utilities'] = 'AllPub'\ndf_test.loc[totalbsmtsf_mask, 'TotalBsmtSF'] = 0\ndf_test.loc[functional_mask, 'Functional'] = 4\ndf_test.loc[garagearea_mask, 'GarageArea'] = 0\ndf_test.loc[bsmtfinsf2_mask, 'BsmtFinSF2'] = 0\ndf_test.loc[bsmtunfsf_mask, 'BsmtUnfSF'] = 0\ndf_test.loc[saletype_mask, 'SaleType'] = 'Oth'\ndf_test.loc[exterior2nd_mask, 'Exterior2nd'] = 'Other'\ndf_test.loc[exterior1st_mask, 'Exterior1st'] = 'Other'\ndf_test.loc[kitchenqual_mask, 'KitchenQual'] = 3\ndf_test.loc[garagecars_mask, 'GarageCars'] = 0\ndf_test.loc[bsmtfinsf1_mask, 'BsmtFinSF1'] = 0","37fa2541":"total = df_test.isnull().sum().sort_values(ascending = False)\npercent = (df_test.isnull().sum())\/(df_test.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","3beb5db8":"df_test['GrLivArea'] =  np.log(df_test['GrLivArea'])\ndf_test['GrLivAreaSq'] = df_test['GrLivArea']**2\ndf_test['GrLivAreaCu'] = df_test['GrLivArea']**3\n\ndf_test['GarageAreaSq'] = df_test['GarageArea']**2\ndf_test['GarageAreaCu'] = df_test['GarageArea']**3\n\ndf_test['HasBsmt'] = pd.Series(len(df_test['TotalBsmtSF']), index=df_train.index)\ndf_test['HasBsmt'] = 0 \ndf_test.loc[df_test['TotalBsmtSF'] > 0,'HasBsmt'] = 1\ndf_test.loc[df_test['HasBsmt'] == 1,'TotalBsmtSF'] = np.log(df_test['TotalBsmtSF'])\ndf_test['TotalBsmtSFSq'] = df_test['TotalBsmtSF']**2\ndf_test['TotalBsmtSFCu'] = df_test['TotalBsmtSF']**3\n\ndf_test['1stFlrSF'] = np.log(df_test['1stFlrSF'])\ndf_test['1stFlrSFSq'] = df_test['1stFlrSF']**2\ndf_test['1stFlrSFCu'] = df_test['1stFlrSF']**3","41b688dc":"features.remove('SalePrice')","0d9974f9":"df_test_clean = pd.get_dummies(df_test[features])","c9cb8a6e":"columns = [x for x in df_test_clean.columns.tolist() if x in columns]","abc55147":"final_elastic_model = ElasticNet(alpha = 0.001, l1_ratio = .5, max_iter = 10000000)","6dec0e1d":"final_elastic_model.fit(df_train_clean[columns], df_train_clean['SalePrice'])","76889d58":"print(len(df_test_clean.columns.tolist()))\nprint(len(columns))","89cd09a1":"elastic_pred_final = final_elastic_model.predict(df_test_clean[columns])","d1dada48":"df_test_clean['SalePrice_Pred'] = elastic_pred_final","ee933630":"df_test_clean['SalePrice'] = np.exp(df_test_clean['SalePrice_Pred'])","43d0d3a8":"submission = df_test_clean[['Id', 'SalePrice']] ","b9e5dc6f":"submission.shape","985da625":"submission.to_csv('submission.csv',\n                 index = False)","f3af51c6":"submission.shape","1497fdde":"# We use Regularized Linear Models to reduce overfitting the first one we will use is the Ridge Regression","174d0fb9":"# We have the best parameters for our elastic model with alpha of 0.001 and a l1_ratio of 0.5","452f964c":"# We see a linear relationship between Sale Price and our strongest Correlated Ordinal Variables","848f5204":"# GarageArea","b47dc2c3":"# TotRmsAbvGrd","f0c08340":"# We will get rid of features that have less than a 50 percent correlation score","5fa2bd88":"# Total Basement Surface Area","4b66d479":"# YearBuilt","fb9d8a27":"# Now lets take a look at some of our numerical variables","970ad37c":"# We have a unique identifier for every sale. A good sign. ","cb9c44b9":"# Now we clean our dataset by trying to replace the remaining missing values","9ad6b213":"# lambda = 0.001 gives us the best root mean squared error for our Lasso model. With our RMSE on our testing data = .126829 and a R^2 score of .898 <br\/>\n# Now Let us update our model","ed86dbca":"# Our SalePrice variable appears to deviate from the normal distribuation and our ANOVA test assumes a normal distribution","2ad9001a":"# Polynomial Features","cac6e0f9":"# We should take out the outliers from our data","8011b44f":"# We can account for 86 percent of the variation in the data with our current model. We will test Ridge, Lasso, and Elastic Net Regression to improve our model.","1b0d188d":"# We need to change our log prices back to the house prices","fb878090":"# Now our data is normally distributed","7bc259a6":"# KitchenQual ","ea9a3652":"# We will assume that the missing values means that there is no vaneer","6195cfda":"# Polynomial Features","47b69cc0":"# There are some columns that are numbered at are actually categorical values and we have alot of features that are categorical that can be made ordinal","3c1c3b17":"# First lets at a look at the variable we are trying to predict salesprice","2855a2f4":"# The data from GrLivArea is not normal and is right skewed a log transformation will help with this","792cd966":"# Polynomial Features","9211ab46":"# We are missing one value for electrical we can assume that there is no electricity","43022cbb":"# Data Visualizations. Now I will get a heat map to show features that are correlated with the SalesPrice","b12b268d":"# Our Lasso Model with an alpha value of 0.001 improves on the regular Linear Regression Model and slightly improves on the Ridge Model <br\/>\n# Now lets see how our data does with a Elastic Net Model","bf604a68":"# We will also conduct a One - Way ANOVA F-test to check for factors that could be useful to our model","213e6304":"# Numerical features that should be categorical features","39834f6a":"# Now lets look at filling the basement features","22f9c8b2":"# No missing values","52975f8a":"# The next thing that I want to do is check the dataset for columns with a large number of missing values any columns with a large number of missing values...15 percent or more will be deleted from the model","42164b9e":"# GarageCars","dbd89c64":"# Let's visualize how our highest correlated features work with our response variable. We may need to change some data to work with our models to predict the SalePrice","3b5fa645":"# Since the garage would have most likely have been built when the house was built we will fill it with the year built value in the same index","72b06680":"# We have a right skewedness to our data a log transformation should fix this","28a1e23d":"# The relationship between GrLivArea and SalePrice appears to be linear. Let's get a histogram to how the data is distributed","1f7a0493":"# We have slight skewedness and kurtosis but a log transformation may be too much here. So we will leave it as is.","35d123b3":"# Our Ridge Model with an alpha value of 10 slightly improves on the regular Linear Regression Model. <br\/>\n# Now lets see how our data does with a Lasso Model","c8b9dc1d":"# 1stFlrSF","6cbfca07":"# Get dummy variables for our categorical features","93614cfe":"# We will take PoolQC, MiscFeature, Alley, Fence, FireplaceQu and LotFrontage out of the model since they have more than 15 percent of their data missing","b9dc71cd":"# It looks as though our data deviates from a normal distribution, may have a right skewness, and some kurtosis as well. We might be able to fix the skewness with a log transformation","82a38d4f":"# lambda = 10 gives us the best root mean squared error for our Ridge model. With our RMSE on our testing data = .127054 and a R^2 score of .897 <br\/>\n# Now Let us update our model","c75d374e":"# Ridge Regression","3f6bb4b7":"# OverallQual","b6b9d23b":"# CREATE CSV FILE FOR SUBMISSION","71613854":"# We still have the features that we want to use as part of the feature selection. Now we need to get the features that are purely categorical and make dummy variables for them be part of the analysis","3bbb4943":"# Polynomial Features","d744c99d":"# This data will benefit from a log transformation because of right skewedness","726c9c63":"# FullBath","262dde9d":"# Now we have some categorical features that we want to turn to ordinal","d17796c9":"# Make lin graph with results from different linear models","724113cd":"# We are trying to maximize our R^2 value and minimize our Root Mean Sqaured Error Value. Therefore the Elastic Net Model is the best model for this. Now lets import our testing data and clean it to get our final model","7961043e":"# Delete Features with too many missing values","3343a09d":"# Now lets look at filling the vaner features","50c0f34a":"# Now it is normally distributed. We should take out the two outliers that don't fit with our model","463a3e4b":"# We will use the linear, ridge, lasso and elastic net regression to find the best model with the lowest RMSE","b2a34881":"# Split data into training and validation data. Out testing data is in another spreadsheet","dc9edcbf":"# Fit our Elastic Net model to the test data","e3d736d2":"# Our mean sale price in ames is 180k with standard deviation of 80k, and we have 1460 different saleprices. Lets see if they are all unique. The id column keeps track of this","461b289b":"# Features that are strong indictators for both the Pearson Correlation Test and ANOVA F - Test","eea206db":"# ExterQual ","588964fa":"# GrLivArea","b456f756":"# YearRemodAdd"}}