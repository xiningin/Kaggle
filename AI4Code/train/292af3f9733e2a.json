{"cell_type":{"59433110":"code","c117bac1":"code","1f8fb843":"code","6cdeb5c0":"code","892d4b78":"code","e7c8f805":"code","1d925140":"code","591098eb":"code","eb62321a":"code","4d1130e8":"code","9de20dc4":"code","f9f899f6":"code","ce0fd3c3":"code","6c91879d":"code","d00d6eb8":"code","ecdcfb80":"code","047f0e16":"code","015e0af4":"code","52545d58":"code","f7a875ae":"code","a5ca6f34":"code","b23d5078":"code","4e6e79b6":"code","819998dc":"markdown","1e4e3bf5":"markdown","2fa76e54":"markdown","acbac550":"markdown","ab7950d0":"markdown","e4b97185":"markdown","9cbcc245":"markdown","fab19a5d":"markdown","1f7fdd9f":"markdown","3b710cc2":"markdown","af5aecbf":"markdown","32401f9c":"markdown","5940b6eb":"markdown","f4220b86":"markdown","da71ad27":"markdown","e9914c7c":"markdown","d3618016":"markdown","10f3d991":"markdown","434502d3":"markdown","c1ffa63a":"markdown","3522b237":"markdown"},"source":{"59433110":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c117bac1":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_actuals = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","1f8fb843":"train.info()","6cdeb5c0":"train_corr = train.corr().unstack().reset_index()\ntrain_corr[train_corr['level_0'] == 'Age']","892d4b78":"import matplotlib.pyplot as plt\n\ntrain_sibsp = train.groupby('Age').SibSp.median()\nplt.plot(train_sibsp)\nplt.show()","e7c8f805":"train_parch = train.groupby('Age').Parch.median()\nplt.plot(train_parch)\nplt.show()","1d925140":"train_sex = train.groupby('Sex').Age.median()\nplt.plot(train_sex)\nplt.show()","591098eb":"train_emb = train.groupby('Embarked').Age.median()\nplt.plot(train_emb)\nplt.show()","eb62321a":"train['Age'] = train.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","4d1130e8":"import seaborn as sns\n\ngrid = sns.FacetGrid(data = train, col = 'Sex', hue = 'Survived')\ngrid.map(sns.histplot, 'Age', bins = 10)","9de20dc4":"grid = sns.FacetGrid(data = train, col = 'Pclass', hue = 'Survived')\ngrid.map(sns.histplot, 'Age', bins = 10)","f9f899f6":"X = train.drop(['Survived', 'Name', 'Cabin', 'Embarked', 'Ticket', 'PassengerId'], axis = 1)\nX = pd.get_dummies(X[X.columns])\ny = train['Survived']","ce0fd3c3":"test.info()","6c91879d":"test['Age'] = test.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\ntest['Fare'] = test.groupby(['Sex', 'Pclass'])['Fare'].apply(lambda x: x.fillna(x.median()))\n\nX_test = test.drop(['Name', 'Cabin', 'Embarked', 'Ticket', 'PassengerId'], axis = 1)\nX_test = pd.get_dummies(X_test[X_test.columns])\n\ny_test = test_actuals['Survived']","d00d6eb8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\nlr = LogisticRegression(random_state = 21)\n# Fit the data to standard range\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nlr.fit(X_scaled, y)","ecdcfb80":"y_pred = lr.predict(X_scaled)","047f0e16":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\ncm = confusion_matrix(y, y_pred)\nprint(cm)\n\nprint(accuracy_score(y, y_pred))\n\nprint(classification_report(y, y_pred))","015e0af4":"X_test_scaled = scaler.transform(X_test)\n\ny_test_pred = lr.predict(X_test_scaled)\n\ncm = confusion_matrix(y_test, y_test_pred)\nprint(cm)\n\nprint(accuracy_score(y_test, y_test_pred))\n\nprint(classification_report(y_test, y_test_pred))","52545d58":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X, y)\n\ny_pred = rfc.predict(X)\n\ncm = confusion_matrix(y, y_pred)\nprint(cm)\n\nprint(accuracy_score(y, y_pred))\n\nprint(classification_report(y, y_pred))","f7a875ae":"feature_imp = pd.DataFrame(data = {'Features': X.columns, 'Importance': rfc.feature_importances_})\nfeature_imp","a5ca6f34":"from sklearn.inspection import permutation_importance\n\nresult = permutation_importance(rfc, X, y, n_repeats = 10, random_state = 21)\npermutation_imp = pd.DataFrame(data = {'Features': X.columns, \n                                       'Mean': result.importances_mean, \n                                       'Std. Dev': result.importances_std})\npermutation_imp","b23d5078":"y_test_pred = rfc.predict(X_test)\n\ncm = confusion_matrix(y_test, y_test_pred)\nprint(cm)\n\nscore = accuracy_score(y_test, y_test_pred)\nprint(score)\n\nprint(classification_report(y_test, y_test_pred))","4e6e79b6":"rfc_output = pd.DataFrame(data = {'PassengerId': test.PassengerId, 'Survived': y_test_pred})\nrfc_output.to_csv('\/kaggle\/working\/titanic_rfc_submission.csv', index = False)","819998dc":"There is also a strong correction with Parch. Lower the age, they are likely to be travelling with one or two parents. Higher the age, they are likely to be travelling with none, one or more children. A plot does not show a definitive trend (ie., age is not influenced by the number of parents\/children travelling with the passenger) and hence this feature can be ignored.","1e4e3bf5":"For a given age, people travelling in 1st class are more likely to survive than the other classes.","2fa76e54":"Now, check the variation with the categorical variables (Sex, Ticket, Embarked, Cabin). Ticket and Cabin has too many values and will not be representative of the variation in age by these variables.","acbac550":"hmmm... Random forest seems to overfit on the training dataset and hence has a lower test accuracy","ab7950d0":"Age, Fare (which is dependent on Pclass) and Sex are features that influence the outcome the most. The impurity-based importances can be inaccurate with high cardinality features (not applicable in this case though). Run a permutation importance just to make sure that these features are the most important. ","e4b97185":"But provides a good enough accuracy on the test dataset. ","9cbcc245":"The Random Forest classifies the training data much more accurately even without the feature scaling. It can also help determine the features that are important for predicting the outcome.","fab19a5d":"### Visualize the data\n\nVisualize the data to get an intuition on what impacts the outcome. \n\nHow does age influence the survival chance?","1f7fdd9f":"Let us try a more elaborate model for this classification.","3b710cc2":"Strong correlation with Pclass (ie., age is influenced by Pclass. Very young passengers were mostly found in higher class numbers)\n\nThere is also a strong correlation with SibSp. Lower the age, they are likely to be travelling with more than one sibling. Higher the age, they are likely to be travelling with one(?) spouse. A plot does not show a definitive trend and hence there is no influence.","af5aecbf":"Age and fare have missing values. Use Median imputation within the test data set for those. Cabin will anyway be dropped as it has too many values to provide a meaningful interpretation","32401f9c":"### Inspect and clean the data","5940b6eb":"There are missing values in both the Age and Cabin columns. Use a correlation matrix to find out how other variables influence the age. ","f4220b86":"Now validate and clean up the test dataset as well.","da71ad27":"### Load the data","e9914c7c":"Sex definitely has an influence on median age, but point of embarkation does not. Now interpolate the missing values with the median grouped by Pclass and Sex.","d3618016":"For a given age, Females are much more likely to survive than Males.","10f3d991":"Now, we are ready to train a model on the training data set. ","434502d3":"This clearly flags the Pclass, Age, Fare (which is dependent on Pclass) and Sex are the features important for the determination of the outcome. ","c1ffa63a":"Name, Ticket # or PassengerId are features that do not have much influence on determining whether the passenger survived or not. ","3522b237":"The baseline logistic regression did not provide a high accuracy on the training dataset. "}}