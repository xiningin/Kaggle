{"cell_type":{"188925b5":"code","bda02f32":"code","8e8641d7":"code","ad2ed513":"code","6f836ddb":"code","3ec226b5":"code","96cc6791":"code","214fa627":"code","4eac57df":"code","e2a85e50":"code","76f2997c":"code","252d28ed":"code","9291db59":"code","2ec2795d":"code","81ca8d09":"code","418370b5":"code","76c2db5d":"code","bc113594":"code","4632748a":"code","7c922c1e":"code","2cd7ace7":"code","6f44cf6f":"code","8d115650":"code","ac45177e":"code","ef396be5":"code","94185354":"code","681bac4d":"code","ebed6477":"code","9a869940":"code","6d794d8b":"code","04d90614":"code","8b9bf4f6":"code","b052868a":"code","35b830bb":"code","ff9cdf2f":"code","858bc957":"code","582f8e43":"code","4a8f96b7":"code","104d1c73":"code","51d22cb1":"code","cee51e5a":"code","084977be":"code","17943022":"code","1ebc7d6f":"code","b71827c4":"code","71385943":"code","69ee26d6":"code","c91dcc86":"code","c279217b":"code","8732bca9":"code","cc873805":"markdown","047b9c3d":"markdown","c0717984":"markdown","c40aa2c8":"markdown","2a9b7456":"markdown","dcdb62dc":"markdown","1ee0a1f9":"markdown","11511694":"markdown","fc8830cc":"markdown","2ba2e53c":"markdown","44773895":"markdown","441f236e":"markdown","93abad28":"markdown","2bd993be":"markdown","4519228c":"markdown","86a6647d":"markdown","8baa636b":"markdown"},"source":{"188925b5":"import numpy as np\nimport pandas as pd\nimport os\n\nimport cv2\nimport PIL\nimport gc\nimport psutil\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import set_random_seed\nfrom tqdm import tqdm\nfrom math import ceil\nimport math\nimport sys\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.activations import softmax, relu, elu\nfrom keras.optimizers import Adam, rmsprop, RMSprop,SGD\nfrom keras.layers import BatchNormalization\nfrom tqdm import tqdm\ngc.enable()\n\nprint(os.listdir(\"..\/input\/\"))","bda02f32":"SEED = 7\nnp.random.seed(SEED)\nset_random_seed(SEED)\ndir_path = \"..\/input\/aptos2019-blindness-detection\/\"\nIMG_DIM = 299  # 224\nBATCH_SIZE = 12\nCHANNEL_SIZE = 3\nNUM_EPOCHS = 60\nTRAIN_DIR = 'train_images'\nTEST_DIR = 'test_images'\nFREEZE_LAYERS = 2  # freeze the first this many layers for training\nCLASSS = {0: \"No DR\", 1: \"Mild\", 2: \"Moderate\", 3: \"Severe\", 4: \"Proliferative DR\"}","8e8641d7":"df_train = pd.read_csv(os.path.join(dir_path, \"train.csv\"))\ndf_test = pd.read_csv(os.path.join(dir_path, \"test.csv\"))\nNUM_CLASSES = df_train['diagnosis'].nunique()","ad2ed513":"print(\"Training set has {} samples and {} classes.\".format(df_train.shape[0], df_train.shape[1]))\nprint(\"Testing set has {} samples and {} classes.\".format(df_test.shape[0], df_test.shape[1]))","6f836ddb":"chat_data = df_train.diagnosis.value_counts()\nchat_data.plot(kind='bar');\nplt.title('Samples Per Class');\nplt.show()\nplt.pie(chat_data, autopct='%1.1f%%', shadow=True, labels=[\"No DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferative DR\"])\nplt.title('Per class sample Percentage');\nplt.show()","3ec226b5":"# Train & Test samples ratio\n# Plot Data\nlabels = 'Train', 'Test'\nsizes = df_train.shape[0], df_test.shape[0]\ncolors = 'lightskyblue', 'lightcoral'\n# Plot\nplt.figure(figsize=(7, 5))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\nplt.axis('equal')\nplt.show()","96cc6791":"x_train, x_test, y_train, y_test = train_test_split(df_train.id_code, df_train.diagnosis, test_size=0.2,\n                                                    random_state=SEED, stratify=df_train.diagnosis)","214fa627":"def draw_img(imgs, target_dir, class_label='0'):\n    fig, axis = plt.subplots(2, 6, figsize=(15, 6))\n    for idnx, (idx, row) in enumerate(imgs.iterrows()):\n        imgPath = os.path.join(dir_path, f\"{target_dir}\/{row['id_code']}.png\")\n        img = cv2.imread(imgPath)\n        row = idnx \/\/ 6\n        col = idnx % 6\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axis[row, col].imshow(img)\n    plt.suptitle(class_label)\n    plt.show()","4eac57df":"CLASS_ID = 0\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","e2a85e50":"CLASS_ID = 1\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","76f2997c":"CLASS_ID = 2\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","252d28ed":"CLASS_ID = 3\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","9291db59":"CLASS_ID = 4\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","2ec2795d":"CLASS_ID = 'Test DataSet'\ndraw_img(df_test.sample(12, random_state=SEED), 'test_images', CLASS_ID)","81ca8d09":"def check_max_min_img_height_width(df, img_dir):\n    max_Height , max_Width =0 ,0\n    min_Height , min_Width =sys.maxsize ,sys.maxsize \n    for idx, row in df.iterrows():\n        imgPath=os.path.join(dir_path,f\"{img_dir}\/{row['id_code']}.png\") \n        img=cv2.imread(imgPath)\n        H,W=img.shape[:2]\n        max_Height=max(H,max_Height)\n        max_Width =max(W,max_Width)\n        min_Height=min(H,min_Height)\n        min_Width =min(W,min_Width)\n    return max_Height, max_Width, min_Height, min_Width","418370b5":"check_max_min_img_height_width(df_train, TRAIN_DIR)","76c2db5d":"check_max_min_img_height_width(df_test, TEST_DIR)","bc113594":"# Display some random images from Data Set with class categories ing gray\nfigure = plt.figure(figsize=(20, 16))\nfor target_class in (y_train.unique()):\n    for i, (idx, row) in enumerate(\n            df_train.loc[df_train.diagnosis == target_class].sample(5, random_state=SEED).iterrows()):\n        ax = figure.add_subplot(5, 5, target_class * 5 + i + 1)\n        imagefile = f\"..\/input\/aptos2019-blindness-detection\/train_images\/{row['id_code']}.png\"\n        img = cv2.imread(imagefile)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n        plt.imshow(img, cmap='gray')\n        ax.set_title(CLASSS[target_class])","4632748a":"# Add Lighting to the images for improving the visibility \n\ndef draw_img_light(imgs, target_dir, class_label='0'):\n    fig, axis = plt.subplots(2, 6, figsize=(15, 6))\n    for idnx, (idx, row) in enumerate(imgs.iterrows()):\n        imgPath = os.path.join(dir_path, f\"{target_dir}\/{row['id_code']}.png\")\n        img = cv2.imread(imgPath)\n        row = idnx \/\/ 6\n        col = idnx % 6\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n        img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , IMG_DIM\/10) ,-4 ,128) # the trick is to add this line\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        axis[row, col].imshow(img, cmap='gray')\n    plt.suptitle(class_label)\n    plt.show()","7c922c1e":"CLASS_ID = 3\ndraw_img_light(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","2cd7ace7":"# Image Croping\ndef crop_image1(img, tol=7) :\n    # img is image data\n    # tol is tolerance\n    mask = img>tol\n    return img[np.ix_(mask.any(1,),mask.any(0))]","6f44cf6f":"def crop_image_from_gray(img,tol=7):\n    if img.ndim== 2:\n        mask=img>tol\n    elif img.ndim==3:\n        gray_img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n        mask=gray_img>tol\n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n#         check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if check_shape ==0: # Image was full dark and may be cropout everything.\n            return img # Return original Image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            print(img1.shape,img2.shape,img3.shape)            \n            img=np.stack([img1,img2,img3],axis=1)\n            print(img.shape)\n            return img","8d115650":"def load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)S\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_DIM, IMG_DIM))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","ac45177e":"def crop_image(img,tol=7):\n    w, h = img.shape[1],img.shape[0]\n    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray_img = cv2.blur(gray_img,(5,5))\n    shape = gray_img.shape \n    gray_img = gray_img.reshape(-1,1)\n    quant = quantile_transform(gray_img, n_quantiles=256, random_state=0, copy=True)\n    quant = (quant*256).astype(int)\n    gray_img = quant.reshape(shape)\n    xp = (gray_img.mean(axis=0)>tol)\n    yp = (gray_img.mean(axis=1)>tol)\n    x1, x2 = np.argmax(xp), w-np.argmax(np.flip(xp))\n    y1, y2 = np.argmax(yp), h-np.argmax(np.flip(yp))\n    if x1 >= x2 or y1 >= y2 : # something wrong with the crop\n        return img # return original image\n    else:\n        img1=img[y1:y2,x1:x2,0]\n        img2=img[y1:y2,x1:x2,1]\n        img3=img[y1:y2,x1:x2,2]\n        img = np.stack([img1,img2,img3],axis=-1)\n    return img\n\ndef process_image(image, size=512):\n    image = cv2.resize(image, (size,int(size*image.shape[0]\/image.shape[1])))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    try:\n        image = crop_image(image, tol=15)\n    except Exception as e:\n        image = image\n        print( str(e) )\n    return image","ef396be5":"# Display some random images from Data Set with class categories. showig Gray image removing other channel and adding lighting to image.\nfigure = plt.figure(figsize=(20, 16))\nfor target_class in (y_train.unique()):\n    #     print(CLASSS[target_class],target_class)\n    for i, (idx, row) in enumerate(\n            df_train.loc[df_train.diagnosis == target_class].sample(5, random_state=SEED).iterrows()):\n        ax = figure.add_subplot(5, 5, target_class * 5 + i + 1)\n        imagefile = f\"..\/input\/aptos2019-blindness-detection\/train_images\/{row['id_code']}.png\"\n        img = cv2.imread(imagefile)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n        img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), IMG_DIM \/ 10), -4, 128)\n        plt.imshow(img, cmap='gray')\n        ax.set_title('%s-%d-%s' % (CLASSS[target_class], idx, row['id_code']))\n#         print(row['id_code'])\n#     plt.show()","94185354":"imgPath = f\"..\/input\/aptos2019-blindness-detection\/train_images\/cd54d022e37d.png\"\nimg = cv2.imread(imgPath)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n_, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\ncontours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnt = contours[0]\nx, y, w, h = cv2.boundingRect(cnt)\nimg = img[y:y + h, x:x + w]\nplt.imshow(img)","681bac4d":"def random_crop(img, random_crop_size):\n    # Note: image_data_format is 'channel_last'\n    assert img.shape[2] == 3\n    height, width = img.shape[0], img.shape[1]\n    dy, dx = random_crop_size\n    x = np.random.randint(0, width - dx + 1)\n    y = np.random.randint(0, height - dy + 1)\n    img = img[y:(y + dy), x:(x + dx), :]\n    return img\n\n\n\"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n    crops from the image batches generated by the original iterator.\n    \"\"\"\n\n\ndef crop_generator(batches, crop_length):\n    while True:\n        batch_x, batch_y = next(batches)\n        batch_crops = np.zeros((batch_x.shape[0], crop_length, 3))\n        for i in range(batch_x.shape[0]):\n            batch_crops[0] = random_crop(batch_x[i], (crop_length, crop_length))\n        yield (batch_crops, batch_y)","ebed6477":"#print(\"available RAM:\", psutil.virtual_memory())\ngc.collect()\n#print(\"available RAM:\", psutil.virtual_memory())\n\ndf_train.id_code = df_train.id_code.apply(lambda x: x + \".png\")\ndf_test.id_code = df_test.id_code.apply(lambda x: x + \".png\")\ndf_train['diagnosis'] = df_train['diagnosis'].astype('str')","9a869940":"# Creating the imageDatagenerator Instance \ndatagenerator=ImageDataGenerator(#rescale=1.\/255,\n#                                       validation_split=0.15, \n                                         horizontal_flip=True,\n                                         vertical_flip=True, \n                                         rotation_range=40, \n                                         zoom_range=0.2, \n                                         shear_range=0.1,\n                                        fill_mode='nearest')","6d794d8b":"imgPath = f\"..\/input\/aptos2019-blindness-detection\/train_images\/cd54d022e37d.png\"\n# Loading image\nimg = load_img(imgPath)\ndata = img_to_array(img)\nsamples =np.expand_dims(data, 0)\ni=5\nit=datagenerator.flow(samples , batch_size=1)\nfor i in range(5):\n    plt.subplot(230 + 1 + i)\n    batch = it.next()\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","04d90614":"train_datagen = ImageDataGenerator(rescale=1. \/ 255, validation_split=0.15, horizontal_flip=True,\n                                         vertical_flip=True, rotation_range=40, zoom_range=0.2, shear_range=0.1, fill_mode='nearest')","8b9bf4f6":"train_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    directory=\"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n                                                    x_col=\"id_code\",\n                                                    y_col=\"diagnosis\",\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode=\"categorical\",\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='training',\n                                                    shaffle=True,\n                                                    seed=SEED,\n                                                    )\nvalid_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    directory=\"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n                                                    x_col=\"id_code\",\n                                                    y_col=\"diagnosis\",\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode=\"categorical\",\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='validation',\n                                                    shaffle=True,\n                                                    seed=SEED\n                                                    )\ndel x_train\n# # del x_test\ndel y_train\n# del y_test\ngc.collect()\n#  color_mode= \"grayscale\",","b052868a":"def design_model():\n    model = Sequential()\n    model.add(Conv2D(filters=16, kernel_size=(2, 2), input_shape=[IMG_DIM, IMG_DIM, CHANNEL_SIZE], activation='elu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(filters=32, kernel_size=(2, 2), activation='elu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(filters=64, kernel_size=(2, 2), activation='elu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(units=1000, activation=elu))\n    model.add(Dropout(rate=0.2))\n    model.add(Dense(units=1000, activation=elu))\n    model.add(Dropout(rate=0.2))\n    model.add(Dense(5, activation='softmax'))\n    return model\n\n\nmodel = design_model()\n# model.summary()","35b830bb":"model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])","ff9cdf2f":"eraly_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n# Reducing the Learning Rate if result is not improving. \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',\n                              verbose=1)","858bc957":"NUB_TRAIN_STEPS = train_generator.n \/\/ train_generator.batch_size\nNUB_VALID_STEPS = valid_generator.n \/\/ valid_generator.batch_size\n\nNUB_TRAIN_STEPS, NUB_VALID_STEPS","582f8e43":"!pip install -U '..\/input\/install\/efficientnet-0.0.3-py2.py3-none-any.whl'\nfrom efficientnet import EfficientNetB5","4a8f96b7":"def create_resnet(img_dim, CHANNEL, n_class):\n    input_tensor = Input(shape=(img_dim, img_dim, CHANNEL))\n\n    base_model = EfficientNetB5(weights=None,\n    input_shape=(IMG_DIM, IMG_DIM, CHANNEL_SIZE),\n    include_top=False\n                   )\n    base_model.load_weights(\"..\/input\/efficientnet-keras-weights-b0b5\/efficientnet-b5_imagenet_1000_notop.h5\")\n    #base_model = ResNet50(weights=None, include_top=False, input_tensor=input_tensor)\n    #base_model.load_weights('..\/input\/resnet50weightsfile\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    \n    #x = GlobalAveragePooling2D()(base_model.output)\n    #x = Dropout(0.3)(x)\n    #x = Dense(1024, activation=elu)(x)\n    #x = Dropout(0.3)(x)\n    #x = Dense(1024, activation=elu)(x)\n    #x = Dropout(0.3)(x)\n    #x = Dense(512, activation=elu)(x)\n    #x = Dropout(0.3)(x)\n    #x = BatchNormalization()(x)\n    #output_layer = Dense(n_class, activation='softmax', name=\"Output_Layer\")(x)\n    #model_resnet = Model(input_tensor, output_layer)\n    \n    x = base_model.output\n    x = Flatten()(x)\n    x = Dense(1024, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(n_class, activation=\"softmax\")(x)\n    model_resnet = Model(input = base_model.input, output = predictions)\n    \n    return model_resnet\n\n\nmodel_resnet = create_resnet(IMG_DIM, CHANNEL_SIZE, NUM_CLASSES)","104d1c73":"for layers in model_resnet.layers:\n    layers.trainable = True","51d22cb1":"lr = 1e-3\noptimizer =SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)# Adam(lr=lr, decay=0.1)\nmodel_resnet.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n# model.summary()\ngc.collect()","cee51e5a":"history = model_resnet.fit_generator(generator=train_generator,\n                                     steps_per_epoch=NUB_TRAIN_STEPS,\n                                     validation_data=valid_generator,\n                                     validation_steps=NUB_VALID_STEPS,\n                                     epochs=NUM_EPOCHS,\n                                     callbacks=[eraly_stop, reduce_lr])\ngc.collect()","084977be":"history.history.keys()","17943022":"accu = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(accu, label=\"Accuracy\")\nplt.plot(val_acc)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(['Acc', 'val_acc'])\nplt.plot(np.argmax(history.history[\"val_acc\"]), np.max(history.history[\"val_acc\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.show()","1ebc7d6f":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(history.history[\"loss\"], label=\"loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","b71827c4":"(eval_loss, eval_accuracy) = tqdm(\n    model_resnet.evaluate_generator(generator=valid_generator, steps=NUB_VALID_STEPS, pickle_safe=False))\nprint(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\nprint(\"[INFO] Loss: {}\".format(eval_loss))","71385943":"test_datagen = ImageDataGenerator(rescale=1. \/ 255, validation_split=0.2, horizontal_flip=True)\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n                                                  directory=\"..\/input\/aptos2019-blindness-detection\/test_images\/\",\n                                                  x_col=\"id_code\",\n                                                  target_size=(IMG_DIM, IMG_DIM),\n                                                  batch_size=1,\n                                                  shuffle=False,\n                                                  class_mode=None,\n                                                  seed=SEED)\n# del df_test\nprint(df_test.shape[0])\n# del train_datagen\n# del traabsin_generator\ngc.collect()","69ee26d6":"tta_steps = 5\npreds_tta = []\nfor i in tqdm(range(tta_steps)):\n    test_generator.reset()\n    preds = model_resnet.predict_generator(generator=test_generator, steps=ceil(df_test.shape[0]))\n    #     print('Before ', preds.shape)\n    preds_tta.append(preds)\n#     print(i,  len(preds_tta))","c91dcc86":"final_pred = np.mean(preds_tta, axis=0)\npredicted_class_indices = np.argmax(final_pred, axis=1)\nlen(predicted_class_indices)","c279217b":"results = pd.DataFrame({\"id_code\": test_generator.filenames, \"diagnosis\": predicted_class_indices})\nresults.id_code = results.id_code.apply(lambda x: x[:-4])  # results.head()\nresults.to_csv(\"submission.csv\", index=False)","8732bca9":"results['diagnosis'].value_counts().plot(kind='bar')\nplt.title('Test Samples Per Class')","cc873805":"**\ub370\uc774\ud130 \uac00\uc838\uc624\uae30**","047b9c3d":"**\ubcc0\uc218 \uc124\uc815**","c0717984":"**\ub77c\uc774\ube0c\ub7ec\ub9ac \uc784\ud3ec\ud2b8**\n\nStages Of Diabetic Retinopathy\n\nNO DR\nMild\nModerate\nServere\nProliferative DR","c40aa2c8":"**RestNet50\uc744 \uc0ac\uc6a9\ud55c \uc804\uc1a1 \ud559\uc2b5 \uc0ac\uc6a9**","2a9b7456":"\ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98 \uc124\uacc4","dcdb62dc":"'regin'\uc744 \uacac\ub514\uae30 \uc704\ud574 GrayScale \uc801\uc6a9(??)","1ee0a1f9":"\ub208 \uc8fc\uc704\uc758 \uac80\uc740 \ubd80\ubd84\uc744 \uc81c\uac70 \ud574\uc918\uc57c\ud568.","11511694":"**Test-Time Augmentation**\n\n\uc544\ub798 \uc139\uc158\uc5d0\uc11c \uc6b0\ub9ac\ub294 TTA\uc5d0 \uc608\uce21 \uc815\ud655\ub3c4\ub97c \ubd80\uc5ec\ud569\ub2c8\ub2e4. \uadf8\uac83\uc740 \uc774\ubbf8\uc9c0\ub97c \ubcc0\ud615\uc2dc\ud0a4\uace0 \uc608\uce21\ud560 \uac83\uc774\ub2e4.","fc8830cc":"**\uc99d\uc0c1\ubcc4\ub85c \ub370\uc774\ud130 \ubd84\uc0b0**\n\n\ub370\uc774\ud130 \uc14b\uc774 \uc0c1\ub2f9\ud788 \ubd88\uade0\ud615\ud55c\uac78\ub85c \ubcf4\uc784.","2ba2e53c":"**\ub370\uc774\ud130 \uc0dd\uc131\uae30**\nKeras \ubaa8\ub378\uc5d0 \ub300\ud55c \ub370\uc774\ud130 \uc0dd\uc131\uc744 \uc704\ud55c Keras ImageDataGenerator \ud074\ub798\uc2a4 \uc0ac\uc6a9 shear_range, zoom_range \ucd94\uac00","44773895":"train \/ test \uc14b \uc774\ubbf8\uc9c0 \ub192\uc774\/\ub108\ube44 \uac00\uc838\uc624\uae30","441f236e":"\uc99d\uc0c1\ubcc4\ub85c \uc790\ub8cc \ud45c\uc2dc\n\ub370\uc774\ud130 \uc14b\uc758 \uc0d8\ud50c \uc774\ubbf8\uc9c0\n\n\uc774\ubbf8\uc9c0 \ud06c\uae30 \uc870\uc815 \ud544\uc694\n\ud45c\uc900 \uc774\ubbf8\uc9c0 \ud06c\uae30 \uc815\ud558\uae30\n\uc774\ubbf8\uc9c0 \ubc1d\uae30 \uc870\uc815 \ud544\uc694","93abad28":"\ub370\uc774\ud130 \ud504\ub808\uc784\uc5d0 \uc774\ubbf8\uc9c0\uc640 \ud568\uaed8 \uc774\ubbf8\uc9c0 \uc720\ud615 \ucd94\uac00","2bd993be":"\ucf5c\ubc31 \uae30\ub2a5(?)\nEraly Stoping and Learning Rate Reducing","4519228c":"\ud06c\uae30\ub97c \uc870\uc815\ud558\uae30 \uc704\ud574 \uc784\uc758\ub85c \uc774\ubbf8\uc9c0\ub97c \uc790\ub984.","86a6647d":"No DR\uc5d0 \ube44\ud574 Severe\uc758 \uc218\uac00 \uc0c1\ub2f9\ud788 \ucc28\uc774\ub098\ub294\uac83\uc744 \ubcfc\uc218 \uc788\ub2e4.\n\ub370\uc774\ud130 \uc9d1\ud569\uc758 \uade0\ud615\uc744 \ub9de\ucd94\uae30 \uc704\ud574 \ub370\uc774\ud130\ub97c \uc99d\uac00\uc2dc\ud0ac \ud544\uc694\uac00 \uc788\ub2e4.","8baa636b":"\ub370\uc774\ud130 \uc14b\uc758 \ud06c\uae30\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud30c\uc774 \ucc28\ud2b8"}}