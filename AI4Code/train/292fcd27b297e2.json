{"cell_type":{"5c38b25f":"code","faefcde6":"code","6a299578":"code","1a51a61c":"code","40c830c9":"code","5de91889":"code","b6c482e1":"code","25c4a70b":"code","77bc1f77":"code","303a0605":"code","73bc53de":"code","6016b1bb":"code","02a58841":"code","c6b9c3a4":"code","82e2c361":"code","e3101ab8":"code","ed24a79c":"code","e889a050":"markdown","362855d6":"markdown","386bfec8":"markdown"},"source":{"5c38b25f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","faefcde6":"df = pd.read_csv(\"\/kaggle\/input\/dogecoin-historical-data\/DOGE-USD.csv\")\ndf.head()","6a299578":"df.corr()","1a51a61c":"df['Date'] =  pd.to_datetime(df['Date'], infer_datetime_format=True)\ndf.set_index('Date',inplace=True)\ndf.head()","40c830c9":"df.dropna(inplace=True)\ndf.info()","5de91889":"# Close column is our y feature (predicted feature). So we should make feature engineering to get higher corr values with y \n# We will take corr values between 0.8-0.2 due to Pearson Correlation Matrix but we can take Volume because its at the borderline\ndf[\"gap\"] = (df[\"High\"] - df[\"Low\"]) * df[\"Volume\"]\ndf[\"y\"] = df[\"High\"] \/ df[\"Volume\"]\ndf[\"z\"] = df[\"Low\"] \/ df[\"Volume\"]\ndf[\"a\"] = df[\"High\"] \/ df[\"Low\"]\ndf[\"b\"] = (df[\"High\"] \/ df[\"Low\"]) * df[\"Volume\"]\nabs(df.corr()[\"Close\"].sort_values(ascending=False))","b6c482e1":"df = df[[\"Close\",\"Volume\",\"gap\",\"a\",\"b\"]]\ndf.head()","25c4a70b":"#!pip install pycaret \nfrom pycaret.regression import *\nexp_name = setup(data=df,target=\"Close\")\nbest_model = compare_models()","77bc1f77":"model1 = create_model(\"gbr\")","303a0605":"tuned_model = tune_model(model1)","73bc53de":"## I'm gonna analyze last 30 days because significant changes have occured in these 30 days \ndf2 = df.tail(30)\ndf2","6016b1bb":"#!pip install pmdarima\nfrom pmdarima.arima import auto_arima\n\nmodel = auto_arima(df2[\"Close\"],df2.drop(\"Close\",axis=1),\n                      seasonal=True, m=1,\n                      start_d=0, D=None, \n                      start_q=0, start_p=0,\n                      trace=True,\n                      error_action='ignore',test=\"adf\",\n                      suppress_warnings=True)\n\nprint(model.summary())\n","02a58841":"df2.info()","c6b9c3a4":"train= df2[:11]\ntest= df2[-19:]\n\nprint(train.shape, test.shape)\ntrain","82e2c361":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nmodel= SARIMAX(endog=train[\"Close\"],exog = train.drop(\"Close\",axis=1), order=(2,1,1))\nresults=model.fit()\nprint(results.summary())","e3101ab8":"start= 11\nend= 29\npredictions= results.predict(start=start, end=end,exog = test.drop(\"Close\",axis=1))\npredictions","ed24a79c":"test[\"Close\"].plot(legend=True,figsize=(12,6))\npredictions.plot(label='TimeSeries',legend=True);","e889a050":"## Let's make Time Series Analysis too!","362855d6":"## Well trends looks like same so I think there are similar speculations on the market compared to last month.","386bfec8":"## Thanks for reviewing, feel free to comment!"}}