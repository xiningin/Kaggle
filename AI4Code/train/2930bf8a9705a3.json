{"cell_type":{"0d459fee":"code","16d9ecc5":"code","ed8f989a":"code","216e53d6":"code","b6655e58":"code","032bc51f":"code","b60ed296":"code","39c0e02e":"code","e4ff0e63":"code","5e62862b":"code","84aa9de6":"code","566094a4":"code","f87ce6f3":"code","db593323":"code","83760a78":"code","0e466b70":"code","31a70712":"code","31817f0d":"code","da78119e":"code","517a60ca":"code","138f4c7f":"code","2fab1d65":"code","3f32be57":"code","8fbce89f":"code","f8040168":"code","c74fa8f2":"code","3e00627b":"code","7386ceb3":"code","89a8e267":"code","d1689a9b":"code","0fb070eb":"markdown"},"source":{"0d459fee":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# # for dirname, _, filenames in os.walk('\/kaggle\/input'):\n# #     for filename in filenames:\n# #         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","16d9ecc5":"!apt update\n!apt install --yes python-opencv\n!apt install --yes libopencv-dev\n!\/bin\/bash -c 'echo \"\/opt\/conda\/lib\/\" > \/etc\/ld.so.conf.d\/opencv.conf'\n!ldconfig\n!pip install imagesize","ed8f989a":"import pandas as pd\nimport os\nimport pickle\nimport matplotlib.pyplot as plt\nimport ast\nimport glob\nimport shutil\nimport sys\nimport numpy as np\nimport imagesize\nimport cv2\nfrom tqdm.notebook import tqdm","216e53d6":"#Install Darknet\n!git clone https:\/\/github.com\/AlexeyAB\/darknet.git","b6655e58":"#Build Darknet with GPU enable settings\n%cd darknet\n\n!cp '..\/..\/input\/libcuda\/libcuda.so' .\n\n!sed -i 's\/OPENCV=0\/OPENCV=1\/g' Makefile\n!sed -i 's\/GPU=0\/GPU=1\/g' Makefile\n!sed -i 's\/CUDNN=0\/CUDNN=1\/g' Makefile\n!sed -i 's\/CUDNN_HALF=0\/CUDNN_HALF=1\/g' Makefile\n!sed -i 's\/LIBSO=0\/LIBSO=1\/' Makefile\n!sed -i \"s\/ARCH= -gencode arch=compute_60,code=sm_60\/ARCH= ${ARCH_VALUE}\/g\" Makefile\n\n!sed -i 's\/LDFLAGS+= -L\\\/usr\\\/local\\\/cuda\\\/lib64 -lcuda -lcudart -lcublas -lcurand\/LDFLAGS+= -L\\\/usr\\\/local\\\/cuda\\\/lib64 -lcudart -lcublas -lcurand -L\\\/kaggle\\\/working\\\/darknet -lcuda\/' Makefile\n!make &> compile.log","032bc51f":"#Verify build\n!.\/darknet detector train","b60ed296":"#Define image\/label path\nROOT_DIR  = '\/kaggle\/input'\nWORKING_DIR  = '\/kaggle\/working'\ndef get_path(row):\n    row['image_path'] = f'{ROOT_DIR}\/tensorflow-great-barrier-reef\/train_images\/video_{row.video_id}\/{row.video_frame}.jpg'\n    row['label_path'] = f'{WORKING_DIR}\/darknet\/data\/obj\/video_{row.video_id}_{row.video_frame}.txt'\n    return row","39c0e02e":"#Load annotations in dataframe\ndf = pd.read_csv(f'{ROOT_DIR}\/tensorflow-great-barrier-reef\/train.csv')\ndf = df.apply(get_path, axis=1)\ndf['annotations'] = df['annotations'].apply(lambda x: ast.literal_eval(x))\ndisplay(df.head(2))","e4ff0e63":"# Check negative samples also\ndf['num_bbox'] = df['annotations'].apply(lambda x: len(x))\ndata = (df.num_bbox>0).value_counts()\/len(df)*100\nprint('% images without annotations: {}'.format(data[0]))\nprint('% images with annotations: {} '.format(data[1]))","5e62862b":"#Filter out negative samples\ndf = df.query(\"num_bbox>0\")","84aa9de6":"#Convert given annotations to YOLO format\ndef coco2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normalizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]\/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]\/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\/2\n    \n    return bboxes\n\ndef yolo2coco(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    \n    return bboxes\n\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None):\n    # Plots one bounding box on image\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) \/ 2) + 1  # line\/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl \/ 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl \/ 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n     \n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n    \n    if bbox_format == 'yolo':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:\n            \n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]\/2) #w\/2 \n                h  = round(float(bbox[3])*image.shape[0]\/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row['image_path'])\n    return row\n\n\ndf['bboxes'] = df.annotations.apply(get_bbox)\ndf = df.apply(get_imgsize,axis=1)\ndisplay(df.width.unique(), df.height.unique())\ndisplay(df.head(2))","566094a4":"#Maintain the Darknet's YOLO required directory structure\n%cd data\/\n!mkdir obj test\n\ncnt = 0\nfor row_idx in tqdm(range(df.shape[0])):\n    row = df.iloc[row_idx]\n    image_height = row.height\n    image_width = row.width\n    bboxes_coco = np.asarray(row.bboxes).astype(np.float32).copy()\n    num_bbox = len(bboxes_coco)\n    labels = [0]*num_bbox\n  \n    f = open(row.label_path, 'w')\n\n    if num_bbox < 1:\n        annot = ''\n        f.write(annot)\n        f.close()\n        cnt += 1\n        continue\n  \n    bboxes_yolo  = coco2yolo(image_height, image_width, bboxes_coco)\n\n    for i in range(len(bboxes_yolo)):\n        annot = [str(labels[i])] + list(bboxes_yolo[i].astype(str)) + (['\\n'] if num_bbox!=(i+1) else [''])\n        annot = ' '.join(annot)\n        annot = annot.strip(' ')\n        f.write(annot)\n    f.close()\n\nprint('Missing boxes ', cnt)","f87ce6f3":"!cat obj\/video_0_1000.txt","db593323":"#Split the dataset into train-val\nfrom sklearn.model_selection import GroupKFold\nkf = GroupKFold(n_splits = 5) \ndf = df.reset_index(drop=True)\ndf['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(kf.split(df, y = df.video_id.tolist(), groups=df.sequence)):\n    df.loc[val_idx, 'fold'] = fold\ndisplay(df.fold.value_counts())","83760a78":"val_df = df[df['fold']==2]\ntrain_df = df[df['fold']!=2]\nprint(train_df.shape)\nprint(val_df.shape)","0e466b70":"# Move labels from obj to test directory\ndef mv_labels (row):\n    old_path = row.label_path\n    filename = row.label_path.split('\/')[-1]\n    new_path = '\/'.join(row.label_path.split('\/')[:-2]) + '\/test\/' + filename\n    row['label_path'] = new_path\n    shutil.move(old_path, new_path)\n    return row\n\nval_df = val_df.apply(lambda x: mv_labels(x), axis=1)\nval_df.head(2)","31a70712":"# Copy images to working directory\n'''\nLabels and images must have the same name:\nImages: obj\/image_XX.jpg\nLabels: obj\/image_XX.txt\n'''\ndef copy_images (row):\n    old_path = row.image_path\n    filename = row.label_path.split('\/')[-1][:-4] + '.jpg'\n    new_path = '\/'.join(row.label_path.split('\/')[:-1]) + '\/' + filename\n    shutil.copy(old_path, new_path)\nval_df.apply(lambda x: copy_images(x), axis=1)\ntrain_df.apply(lambda x: copy_images(x), axis=1)","31817f0d":"#Verify\n!ls obj\/*.jpg | wc -l\n!ls obj\/*.txt | wc -l\n!ls test\/*.jpg | wc -l\n!ls test\/*.txt | wc -l","da78119e":"# Generate train.txt and test.txt files\n%cd ..\/\ntrain_images = glob.glob('data\/obj\/*.jpg')\nf = open('.\/data\/train.txt', 'w')\nannot = [os.path.join(os.getcwd(),t) + ('\\n' if i<len(train_images)-1 else '') for i, t in enumerate(train_images)]\nannot = ''.join(annot)\nannot = annot.strip()\nf.write(annot)\n\nval_images = glob.glob('data\/test\/*.jpg')\nf = open('.\/data\/test.txt', 'w')  \nannot = [os.path.join(os.getcwd(),t) + ('\\n' if i<len(val_images)-1 else '') for i, t in enumerate(val_images)]\nannot = ''.join(annot)\nannot = annot.strip()\nf.write(annot)","517a60ca":"#Verify\n!cat data\/train.txt | wc -l\n!cat data\/test.txt | wc -l","138f4c7f":"#Visualization\nnp.random.seed(1)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]\n\ndf2 = train_df[(train_df.num_bbox>0)].sample(100) # takes samples with bbox\n\nfor idx in range(10):\n    row = df2.iloc[idx]\n    img           = load_image(row.image_path)\n    image_height  = row.height\n    image_width   = row.width\n    f = open(row.label_path)\n    bboxes_yolo = np.asarray([[float(a) for a in l[1:].strip().split(' ')] for l in f.readlines()])\n\n    names         = ['starfish']*len(bboxes_yolo)\n    labels        = [0]*len(bboxes_yolo)\n\n    plt.figure(figsize = (12, 8))\n    plt.imshow(draw_bboxes(img = img,\n                           bboxes = bboxes_yolo, \n                           classes = names,\n                           class_ids = labels,\n                           class_name = True, \n                           colors = colors, \n                           bbox_format = 'yolo',\n                           line_thickness = 2))\n    plt.axis('OFF')\n    plt.show()","2fab1d65":"# #Modify YOLO's configuration file as per our data\n# !sed -i 's\/subdivisions=8\/subdivisions=64\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed -i 's\/max_batches = 500500\/max_batches = 8000\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed -i 's\/steps=400000,450000\/steps=6400,7200\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed -i 's\/classes=80\/classes=1\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed -i 's\/filters=255\/filters=18\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed -i 's\/objectness_smooth=1\/objectness_smooth=0\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed -i 's\/scale_x_y=2.0\/scale_x_y=1.05\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed -i 's\/activation=logistic\/activation=linear\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed -i 's\/iou_thresh=0.2\/iou_thresh=1.0\/g' .\/cfg\/yolov4x-mish.cfg\n# !sed 'iou_loss=ciou d' .\/cfg\/yolov4x-mish.cfg\n# !sed 'iou_normalizer=0.05 d' .\/cfg\/yolov4x-mish.cfg\n# !sed 'new_coords=1 d' .\/cfg\/yolov4x-mish.cfg","3f32be57":"!sed -i 's\/subdivisions=16\/subdivisions=16\/g' .\/cfg\/yolov4-custom.cfg \n!sed -i 's\/width=608\/width=416\/g' .\/cfg\/yolov4-custom.cfg\n!sed -i 's\/height=608\/height=416\/g' .\/cfg\/yolov4-custom.cfg\n!sed -i 's\/max_batches = 500500\/max_batches =4000\/g' .\/cfg\/yolov4-custom.cfg\n!sed -i 's\/steps=400000,450000\/steps=3200,3600\/g' .\/cfg\/yolov4-custom.cfg\n!sed -i 's\/classes=80\/classes=1\/g' .\/cfg\/yolov4-custom.cfg\n!sed -i 's\/filters=255\/filters=18\/g' .\/cfg\/yolov4-custom.cfg","8fbce89f":"# Build obj.data and obj.names files\nf = open('.\/data\/obj.data', 'w')\nf.write('classes = 1\\ntrain = data\/train.txt\\nvalid = data\/test.txt\\nnames = data\/obj.names\\nbackup = backup\\n')\nf.close()\nf = open('.\/data\/obj.names', 'w')\nf.write('starfish')\nf.close()","f8040168":"# # Download YOLOv4x-MISH pre-trained model\n# !wget https:\/\/github.com\/AlexeyAB\/darknet\/releases\/download\/darknet_yolo_v4_pre\/yolov4x-mish.conv.166","c74fa8f2":" !wget https:\/\/github.com\/AlexeyAB\/darknet\/releases\/download\/darknet_yolo_v3_optimal\/yolov4.conv.137","3e00627b":"# # Start the training\n# !.\/darknet detector train data\/obj.data cfg\/yolov4x-mish.cfg yolov4x-mish.conv.166 -dont_show -map","7386ceb3":"from distutils.dir_util import copy_tree\n#copy_tree('..\/input\/cots-last-weight-yolo','\/kaggle\/working\/darknet\/backup')\nimport shutil\nsrc='..\/input\/cots-last-weight-yolo\/yolov4-custom_last.weights'\ndst = '\/kaggle\/working\/darknet\/yolov4-custom_last.weights'\ntry:\n    #if path already exists, remove it before copying with copytree()\n    if os.path.exists(dst):\n        shutil.rmtree(dst)\n        shutil.copyfile(src, dst)\n        print(\"Copy File 1\")\n    elif not os.path.isdir('\/kaggle\/working\/darknet\/backup'):\n        os.makedirs('\/kaggle\/working\/darknet\/backup')\n        print(\"folder is created!\")\n    else:\n        shutil.copyfile(src, dst)\n        print(\"Copy File 2\")\nexcept OSError as e:\n        #shutil.copy(source_dir_prompt, destination_dir_prompt)\n        print(\"No Copy due to: \", e)","89a8e267":"!.\/darknet detector train data\/obj.data cfg\/yolov4-custom.cfg yolov4.conv.137 -dont_show -map\n#resume training\n#!.\/darknet detector train data\/obj.data cfg\/yolov4-custom.cfg {ROOT_DIR}\/cots-yolov4-last-weight\/yolov4-custom_last.weights -dont_show -map","d1689a9b":"os.listdir()","0fb070eb":"<a href=\"\/kaggle\/working\/darknet\/backup\"> Download File <\/a>\n"}}