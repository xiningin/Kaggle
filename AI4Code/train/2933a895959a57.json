{"cell_type":{"f58c74f4":"code","b1c0ed4e":"code","69351762":"code","89e26c12":"code","4d310d8d":"code","81c8b16d":"code","c576310b":"code","aa24f3f0":"code","9db1bc28":"code","71e22740":"code","51d0ab2f":"code","a1143dea":"code","7cb3d4bc":"code","cf16173f":"code","c0f38a10":"code","84978454":"code","9e2ab785":"code","08e8ecb3":"code","10969793":"code","1c0a9320":"code","e9a62c00":"code","2f7ad8d9":"code","5e7c5447":"code","2077e9a4":"code","feb2ed43":"code","91df7377":"code","e0da0043":"code","4c8b4bac":"code","cf70b18b":"code","741b9038":"code","0defcaaf":"code","8546ddc4":"code","7df75aa6":"code","3dde8f8b":"code","6bd14042":"code","db5ac0bc":"code","a0deaf50":"code","502b5f77":"code","94879ec8":"code","280cd8d8":"markdown","5a0bdbeb":"markdown","d1f88123":"markdown","b75b7fd6":"markdown","21ef7cc0":"markdown","5d5d94ef":"markdown","a36bf226":"markdown","459257bc":"markdown","d67804c0":"markdown","a95d051a":"markdown","f36061b2":"markdown","778ab870":"markdown","dd34664e":"markdown","9f58a4f6":"markdown"},"source":{"f58c74f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b1c0ed4e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt,matplotlib.image as mping\nimport seaborn as sns","69351762":"df_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_test =  pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","89e26c12":"df_train.info()","4d310d8d":"df_test.info()","81c8b16d":"df_train.iloc[:,0].unique()","c576310b":"sns.countplot(df_train.iloc[:,0])","aa24f3f0":"y = df_train.iloc[:,0]\nX = df_train.iloc[:,1:]","9db1bc28":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2 , random_state = 42)","71e22740":"y_train.value_counts(normalize=True)","51d0ab2f":"y_test.value_counts(normalize=True)","a1143dea":"from sklearn.tree import DecisionTreeClassifier","7cb3d4bc":"tree = DecisionTreeClassifier().fit(X_train,y_train)\ny_pred = tree.predict(X_test)","cf16173f":"from sklearn.metrics import accuracy_score,classification_report,plot_confusion_matrix,confusion_matrix","c0f38a10":"accuracy_score(y_test,y_pred)","84978454":"from sklearn.ensemble import RandomForestClassifier\nrandom_classifier =  RandomForestClassifier(random_state=42).fit(X_train,y_train)","9e2ab785":"random_classifier.score(X_test,y_test)","08e8ecb3":"from sklearn.ensemble import BaggingClassifier\nbagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100,oob_score=True,random_state=42).fit(X_train,y_train)","10969793":"bagging_clf.score(X_test,y_test)","1c0a9320":"from sklearn.neighbors import KNeighborsClassifier\nk_neighbors_clf = KNeighborsClassifier().fit(X_train,y_train)","e9a62c00":"y_pred = k_neighbors_clf.predict(X_test)\naccuracy_score(y_test,y_pred)","2f7ad8d9":"from sklearn.svm import SVC","5e7c5447":"svm_parameter = SVC(C= 10,degree = 3,gamma = 'scale',random_state=42).fit(X_train,y_train)","2077e9a4":"y_pred = svm_parameter.predict(X_test)","feb2ed43":"accuracy_score(y_test,y_pred)","91df7377":"confusion_matrix(y_test,y_pred)","e0da0043":"cm = confusion_matrix(y_test,y_pred)\nsns.heatmap(cm, annot=True)","4c8b4bac":"print(classification_report(y_test,y_pred))","cf70b18b":"## here we can see that the svm has get most accuracy\n## we are going to use svm model for predication","741b9038":"df_test","0defcaaf":"X_test_data = df_test.iloc[:,:]","8546ddc4":"y_pred_data = svm_parameter.predict(X_test_data)","7df75aa6":"y_pred_data = y_pred_data.reshape(-1,1)","3dde8f8b":"df_sample_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')","6bd14042":"df_pred = pd.DataFrame(y_pred_data,columns=['Label'])","db5ac0bc":"df_sample_data = df_sample_data.drop(columns=['Label'])","a0deaf50":"submit_data = pd.concat([df_sample_data,df_pred],axis=1)","502b5f77":"submitt_data.info()","94879ec8":"submit_data.to_csv('submission.csv',index = False)","280cd8d8":"## Support Vector Machine","5a0bdbeb":"### Accuracy Score","d1f88123":"## Training the Random Forest Classifier on the Training set","b75b7fd6":"## Importing the libraries","21ef7cc0":"## Splitting the dataset into the Training set and Test set","5d5d94ef":"## Training Decision Tree Classifier on the Training set","a36bf226":"## Importing the dataset","459257bc":"### Accuracy Score","d67804c0":"### Algorithm Use\n       1. Decision Tree Classifier\n       2. Random Forest Classifier\n       3. Bagging Classifier\n       4. K Neighbors Classifier\n       5. Supoort Vector Classifier\n       \n       \n Support Vector Classifier given Good Accuracy Score","a95d051a":"### Accuracy Score","f36061b2":"### Accuracy Score","778ab870":"## Training Baggingclassifier on the Training set","dd34664e":"# Digit Recognizer","9f58a4f6":"## K Neighbors Classifier"}}