{"cell_type":{"879923de":"code","30419138":"code","4c30f12b":"code","00fab564":"code","dd656e40":"code","c79ce7f7":"code","943a0c93":"code","aaf28edb":"code","144d21e5":"code","e2decdc3":"code","62d78c21":"code","f2cf8fd5":"code","63033a94":"code","c8917c3d":"code","0e7374e6":"markdown","85a5fd7a":"markdown","c0d91b8a":"markdown","6b4349ab":"markdown","3a0e1a25":"markdown"},"source":{"879923de":"import numpy as np\nimport cupy as cp\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nfrom IPython.display import display, clear_output\nfrom itertools import product\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","30419138":"fpath = '\/kaggle\/input\/santa-2019-workshop-scheduling\/family_data.csv'\ndata = pd.read_csv(fpath, index_col='family_id')\nfpath = '\/kaggle\/input\/santa-2019-workshop-scheduling\/sample_submission.csv'\nsubmission = pd.read_csv(fpath, index_col='family_id')","4c30f12b":"N_DAYS = 100\nMAX_OCCUPANCY = 300\nMIN_OCCUPANCY = 125\nN_FAMILY = 5000\n","00fab564":"class CostFunction(object):\n    \n    '''\n    B ... BATCH\n    F ... N_FAMILY\n    D ... N_DAYS\n    \n    '''\n    def __init__(self, data, np=np):\n        self.np = np\n        family_size_array = np.array(data['n_people'], dtype=np.int32)\n        penalty_table = np.ones((N_FAMILY, N_DAYS+1), dtype=np.int32)*500\n        family_penalty_table = np.ones((N_FAMILY, N_DAYS+1), dtype=np.int32)*(36+398)\n\n        for i, x in enumerate(data['choice_0']):\n            penalty_table[i, x] = 0\n            family_penalty_table[i, x] = 0\n\n        for i, x in enumerate(data['choice_1']):\n            penalty_table[i, x] = 50\n            family_penalty_table[i, x] = 0\n\n        for i, x in enumerate(data['choice_2']):\n            penalty_table[i, x] = 50\n            family_penalty_table[i, x] = 9\n\n        for i, x in enumerate(data['choice_3']):\n            penalty_table[i, x] = 100\n            family_penalty_table[i, x] = 9\n\n        for i, x in enumerate(data['choice_4']):\n            penalty_table[i, x] = 200\n            family_penalty_table[i, x] = 9\n\n        for i, x in enumerate(data['choice_5']):\n            penalty_table[i, x] = 200\n            family_penalty_table[i, x] = 18\n\n        for i, x in enumerate(data['choice_6']):\n            penalty_table[i, x] = 300\n            family_penalty_table[i, x] = 18\n\n        for i, x in enumerate(data['choice_7']):\n            penalty_table[i, x] = 300\n            family_penalty_table[i, x] = 36\n\n        for i, x in enumerate(data['choice_8']):\n            penalty_table[i, x] = 400\n            family_penalty_table[i, x] = 36\n\n        for i, x in enumerate(data['choice_9']):\n            penalty_table[i, x] = 500\n            family_penalty_table[i, x] = 36+199\n\n        self.family_size_array = family_size_array.copy()\n        self.penalty_array = penalty_table.reshape((-1,))\n        self.family_penalty_array = family_penalty_table.reshape((-1, ))\n        self.index_shift = np.arange(0, 5000, dtype=np.int32)*(N_DAYS+1)\n        self.day_shift = None\n        \n    def cost_function(self, prediction):\n        np = self.np\n        prediction_index = prediction + self.index_shift\n        penalty = self.penalty_array[prediction_index].sum()\n        family_penalty = (self.family_penalty_array[prediction_index]*self.family_size_array).sum()\n        n = np.bincount(prediction, self.family_size_array)\n        n[0] = n[100]\n        accounting_penalty = np.maximum(0, n-125)\/400.*(n**(0.5+np.abs(n-np.roll(n,-1))\/50.))\n        accounting_penalty[0] = 0\n        lower_penalty = np.maximum(0, 125-n)\n        upper_penalty = np.maximum(0, n-300)\n        lower_penalty[0] = 0\n        upper_penalty[0] = 0\n        loss = penalty+family_penalty+accounting_penalty.sum()+(lower_penalty.sum()+upper_penalty.sum())*1000000000\n        return loss\n    \n    def cost_function_batch(self, predictions):\n        np = self.np\n        # B, F\n        predictions_index = predictions + self.index_shift[None]\n        # B, F\n        penalty = np.sum(self.penalty_array[predictions_index], axis=1)\n        # B, \n        family_penalty = np.sum(self.family_penalty_array[predictions_index]*self.family_size_array[None], axis=1)\n        # B,\n        days = predictions + self.day_shift[:, None]\n        family_size_arrays = np.broadcast_to(self.family_size_array[None], days.shape)\n        # B, F\n        days = days.reshape((-1, ))\n        family_size_arrays = family_size_arrays.reshape((-1, ))\n        # B*F\n        ns = np.bincount(days, family_size_arrays)\n        ns = np.reshape(ns, (-1, N_DAYS+1))\n        # B, D\n        ns[:, 0] = ns[:, 100]\n        accounting_penalty = np.maximum(0, ns-125)\/400.*(ns**(0.5+np.abs(ns-np.roll(ns,-1, axis=1))\/50.))\n        accounting_penalty[:, 0] = 0\n        accounting_penalty = np.sum(accounting_penalty, axis=1)\n        lower_penalty = np.maximum(0, 125-ns)\n        upper_penalty = np.maximum(0, ns-300)\n        lower_penalty[:, 0] = 0\n        upper_penalty[:, 0] = 0\n        lower_penalty = np.sum(lower_penalty, axis=1)\n        upper_penalty = np.sum(upper_penalty, axis=1)\n        loss = penalty+family_penalty+accounting_penalty+(lower_penalty+upper_penalty)*1000000000\n        return loss\n\n    def set_batch_size(self, bs):\n        np = self.np\n        self.day_shift = np.arange(0, bs, dtype=np.int32)*(N_DAYS+1)","dd656e40":"family_size_dict = data[['n_people']].to_dict()['n_people']\n\ncols = [f'choice_{i}' for i in range(10)]\nchoice_list = [data[x].tolist() for x in cols]\nchoice_array = np.array(choice_list, dtype=np.int32)\nchoice_matrix = choice_array.T\ncost_function = CostFunction(data, np=cp)\n\n","c79ce7f7":"idx = np.arange(5000, dtype=np.int32)\nn = np.zeros((101, ), dtype=np.int32)\ninit_ans = np.zeros((5000,), dtype=np.int32)\nfamily_size_array = np.array(data['n_people'], dtype=np.int32)\nborder = 300\nmaximum_choice = 4\n\nfor border in range(120, 310, 10):\n    for t in range(maximum_choice+1):\n        for i in range(t):\n            choices = np.array(data['choice_{}'.format(i)].tolist())\n            now = np.bincount(choices[idx], family_size_array[idx], 101)\n            nxt = n + now\n            next_idx = []\n            for x in idx:\n                if nxt[choices[x]] <= border:\n                    init_ans[x] = choices[x]\n                else:\n                    next_idx.append(x)\n\n            idx = np.array(next_idx, dtype=np.int32)\n            for i in range(101):\n                if nxt[i] <= border:\n                    n[i] = nxt[i]\n","943a0c93":"init_ans = cp.array(init_ans)\ncost = cost_function.cost_function(init_ans)\nprint(cost)\ncost_function.set_batch_size(1)\ncosts = cost_function.cost_function_batch(init_ans[None])\nprint(costs)\nbest = init_ans.copy()","aaf28edb":"def stochastic_product_search(top_k, fam_size, original, choice_matrix, \n                              cost_function, disable_tqdm=False, verbose=10000,\n                              n_iter=500, random_state=2019, np=np, tnp=np):\n    \"\"\"\n    original (np.array): The original day assignments.\n    \n    At every iterations, randomly sample fam_size families. Then, given their top_k\n    choices, compute the Cartesian product of the families' choices, and compute the\n    score for each of those top_k^fam_size products.\n    \"\"\"\n    \n    best = original.copy()\n    best_score = cost_function.cost_function(best)\n    \n    np.random.seed(random_state)\n    cost_function.set_batch_size(top_k**fam_size)\n\n\n    for i in tqdm(range(n_iter), disable=disable_tqdm):\n        fam_indices = tnp.random.choice(range(choice_matrix.shape[0]), size=fam_size)\n        changes = np.array(list(product(*choice_matrix[fam_indices, :top_k].tolist())))\n\n        fam_indices = np.array(fam_indices)\n        new = best.copy()\n        news = np.tile(new, len(changes))\n        fam_indices = fam_indices[None]\n        shift = (np.arange(0, len(changes), dtype=np.int32)*5000)[:, None]\n        fam_indices = fam_indices+shift\n        news[fam_indices] = changes\n        news = news.reshape((-1, N_FAMILY))\n        costs = cost_function.cost_function_batch(news)\n        if best_score > np.min(costs):\n            best = news[np.argmin(costs)].copy()\n            best_score = np.min(costs)\n\n    \n        if verbose and i % verbose == 0:\n            tnp_best_score = float(best_score)\n            print(f\"Iteration #{i}: Best score is {tnp_best_score:.2f}\")\n    \n    tnp_best_score = float(best_score)\n    print(f\"Final best score is {tnp_best_score:.2f}\")\n    return best","144d21e5":"best = cp.array(init_ans)","e2decdc3":"best = stochastic_product_search(\n    choice_matrix=choice_matrix, \n    top_k=2,\n    fam_size=8, \n    original=best, \n    n_iter=1000000,\n    disable_tqdm=True,\n    verbose=50000,\n    np=cp,\n    cost_function=cost_function\n)","62d78c21":"best = stochastic_product_search(\n    choice_matrix=choice_matrix, \n    top_k=2,\n    fam_size=12, \n    original=best, \n    n_iter=50000,\n    disable_tqdm=True,\n    verbose=5000,\n    np=cp,\n    cost_function=cost_function\n)","f2cf8fd5":"best = stochastic_product_search(\n    choice_matrix=choice_matrix, \n    top_k=4,\n    fam_size=6, \n    original=best, \n    n_iter=50000,\n    disable_tqdm=True,\n    verbose=5000,\n    np=cp,\n    cost_function=cost_function\n)","63033a94":"best = stochastic_product_search(\n    choice_matrix=choice_matrix, \n    top_k=8,\n    fam_size=4, \n    original=best, \n    n_iter=100000,\n    disable_tqdm=True,\n    verbose=5000,\n    np=cp,\n    cost_function=cost_function\n)","c8917c3d":"submission['assigned_day'] = cp.asnumpy(best)\nfinal_score = cost_function.cost_function(best)\nsubmission.to_csv(f'submission_{final_score}.csv')","0e7374e6":"## Initialization\n\n","85a5fd7a":"## Cost Function (Using GPU Code)\n\n","c0d91b8a":"## About this kernel\n\nIn this kernel I implemented \"Cost function accelerated by GPU\".\nMy cost function and Stochastic Product Search algorigthm performs in 22 \u00b5s per iter.\nTo improve parallel efficiency, my cost function uses batches where bigger batch size enable more performance.\nThe maximum performance is 12 \u00b5s per iter when batch size is 4096(8^4).\n\nRunning this code on GPU will lead to a 5x speed improvement compared to the CPU.\n\n### Reference\n* Simple but nice optimization algorithm: https:\/\/www.kaggle.com\/xhlulu\/santa-s-2019-stochastic-product-search\n\n\n\n\n","6b4349ab":"## Read in the family information and sample submission","3a0e1a25":"## Optimization"}}