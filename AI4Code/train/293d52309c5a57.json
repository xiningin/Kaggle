{"cell_type":{"068d2cf1":"code","47a2f513":"code","07e57de0":"code","7404abfc":"code","5f5ef02d":"code","75624e3d":"code","fe030e79":"code","ed1e7526":"code","dc1214d2":"code","cfc77634":"code","6e8dc887":"code","486a5123":"code","829fb0fa":"code","50d5adab":"code","473d9525":"code","d561287a":"code","7b5abaa1":"code","482fdaf9":"code","f9dc0757":"code","eee405d2":"code","cbc7cb27":"code","5a374f8b":"markdown","286564e7":"markdown","261f0e38":"markdown","3c459c33":"markdown","da98705e":"markdown","1de54f3c":"markdown","e9ab1743":"markdown","c0446112":"markdown","ad75d8af":"markdown","f89d06af":"markdown","ff35826b":"markdown","967f38d5":"markdown"},"source":{"068d2cf1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB0\nfrom keras.optimizers import Adam\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os, cv2, json\nfrom PIL import Image","47a2f513":"WORK_DIR = '..\/input\/cassava-leaf-disease-classification'\nos.listdir(WORK_DIR)","07e57de0":"print('Train images: %d' %len(os.listdir(\n    os.path.join(WORK_DIR, \"train_images\"))))","7404abfc":"with open(os.path.join(WORK_DIR, \"label_num_to_disease_map.json\")) as file:\n    print(json.dumps(json.loads(file.read()), indent=4))","5f5ef02d":"train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\ntrain_labels.head()","75624e3d":"sns.countplot(train_labels.label, edgecolor = 'black',\n              palette = sns.color_palette(\"viridis\", 5))\nplt.show()","fe030e79":"sample = train_labels[train_labels.label == 3].sample(6)\nplt.figure(figsize=(16, 8))\nfor ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n    plt.subplot(2, 3, ind + 1)\n    image = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    \nplt.show()","ed1e7526":"sample = train_labels[train_labels.label == 4].sample(6)\nplt.figure(figsize=(16, 8))\nfor ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n    plt.subplot(2, 3, ind + 1)\n    image = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    \nplt.show()","dc1214d2":"y_pred = [3] * len(train_labels.label)\nprint('The baseline accuracy: %.3f' \n      %accuracy_score(y_pred, train_labels.label))","cfc77634":"# The TRAIN\/VALID split is performing in the generator directly.\n\n#train, valid = train_test_split(train_labels, train_size = 0.8, shuffle = True,\n#                                random_state = 0)","6e8dc887":"#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n#sns.set_style(\"white\")\n#plt.suptitle('Train vs Valid labels', size = 15)\n#\n#sns.countplot(train.label, edgecolor = 'black', ax = ax1,\n#              palette = sns.color_palette(\"viridis\", 5))\n#sns.countplot(valid.label, edgecolor = 'black', ax = ax2,\n#              palette = sns.color_palette(\"viridis\", 5))\n#plt.show()","486a5123":"BATCH_SIZE = 16\nSTEPS_PER_EPOCH = len(train_labels)*0.8 \/ BATCH_SIZE\nVALIDATION_STEPS = len(train_labels)*0.2 \/ BATCH_SIZE\nEPOCHS = 20\nTARGET_SIZE = 224","829fb0fa":"train_labels.label = train_labels.label.astype('str')\n\ntrain_generator = ImageDataGenerator(validation_split = 0.2,\n                                     preprocessing_function = None,\n                                     zoom_range = 0.2,\n                                     cval = 0.2,\n                                     horizontal_flip = True,\n                                     vertical_flip = True,\n                                     fill_mode = 'nearest',\n                                     shear_range = 0.2,\n                                     height_shift_range = 0.2,\n                                     width_shift_range = 0.2) \\\n    .flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n\nvalidation_generator = ImageDataGenerator(validation_split = 0.2) \\\n    .flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"validation\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")","50d5adab":"def create_model():\n    model = models.Sequential()\n\n    model.add(EfficientNetB0(include_top = False, weights = 'imagenet',\n                             input_shape = (TARGET_SIZE, TARGET_SIZE, 3)))\n    \n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(5, activation = \"softmax\"))\n\n    model.compile(optimizer = Adam(lr = 0.001),\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"acc\"])\n    return model","473d9525":"model = create_model()\nmodel.summary()","d561287a":"model_save = ModelCheckpoint('.\/best_baseline_model.h5', \n                             save_best_only = True, \n                             save_weights_only = True,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 5, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)\n\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    callbacks = [model_save, early_stop, reduce_lr]\n)","7b5abaa1":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.set_style(\"white\")\nplt.suptitle('Train history', size = 15)\n\nax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\nax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\nax1.set_title(\"Training and validation acc\")\nax1.legend()\n\nax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\nax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\nax2.set_title(\"Training and validation loss\")\nax2.legend()\n\nplt.show()","482fdaf9":"model.save('.\/baseline_model.h5')","f9dc0757":"ss = pd.read_csv(os.path.join(WORK_DIR, \"sample_submission.csv\"))\nss","eee405d2":"preds = []\n\nfor image_id in ss.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n\nss['label'] = preds\nss","cbc7cb27":"ss.to_csv('submission.csv', index = False)","5a374f8b":"After some experiments with various pre-trained networks, I've stopped on [EfficientNetB0](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications\/EfficientNetB0). It will be my baseline NN for future improvements.","286564e7":"## Some photos of dominant class (with CMD)","261f0e38":"We have imbalanced data with domination of third class: \"Cassava Mosaic Disease (CMD)\"","3c459c33":"Our future model must have accuracy better than 0.615.","da98705e":"## SEE [PREDICTION VERSION OF THIS NOTEBOOK](https:\/\/www.kaggle.com\/maksymshkliarevskyi\/cassava-leaf-disease-keras-cnn-prediction)\n\n## AND NOTEBOOK WITH MY BEST CNN: [Cassava Leaf Disease: Best Keras CNN](https:\/\/www.kaggle.com\/maksymshkliarevskyi\/cassava-leaf-disease-best-keras-cnn)","1de54f3c":"## Some photos of healthy plants","e9ab1743":"<a id=\"section-four\"><\/a>\n# Prediction","c0446112":"<a id=\"section-one\"><\/a>\n# First look at the data","ad75d8af":"## Work directory","f89d06af":"# **Cassava Leaf Disease Classification: CNN Keras Baseline**\n![Cassava](https:\/\/scx2.b-cdn.net\/gfx\/news\/2019\/3-geneeditingt.jpg)\n\nAs the second-largest provider of carbohydrates in Africa, cassava is a key food security crop grown by smallholder farmers because it can withstand harsh conditions. At least 80% of household farms in Sub-Saharan Africa grow this starchy root, but viral diseases are major sources of poor yields. With the help of data science, it may be possible to identify common diseases so they can be treated.\n\nExisting methods of disease detection require farmers to solicit the help of government-funded agricultural experts to visually inspect and diagnose the plants. This suffers from being labor-intensive, low-supply and costly. As an added challenge, effective solutions for farmers must perform well under significant constraints, since African farmers may only have access to mobile-quality cameras with low-bandwidth.\n\n### Table of contents:\n1. [**First look at the data**](#section-one)\n2. [**The baseline level of accuracy**](#section-two)\n3. [**Modeling**](#section-three)\n4. [**Prediction**](#section-four)\n\n\n### History of changes:\n\n**Ver.4:** Changed strategy for train\/valid splitting; EfficientNetB0 was chosen as a baseline network for future work.\n\n**Ver.5:** Changed some parameters of ImageDataGenerator.\n\n**Ver.6:** Changed some parameters of ImageDataGenerator.\n\n**Ver.7-8:** Changed batch size.\n\n**Ver.9:** Changed batch size and 'factor' parameter (ReduceLROnPlateau callback).\n\n\n## Notebook with prediction: [Cassava Leaf Disease: Keras CNN prediction](https:\/\/www.kaggle.com\/maksymshkliarevskyi\/cassava-leaf-disease-keras-cnn-prediction)\n\n## See also the last part of this work with my best CNN: [Cassava Leaf Disease: Best Keras CNN](https:\/\/www.kaggle.com\/maksymshkliarevskyi\/cassava-leaf-disease-best-keras-cnn)","ff35826b":"<a id=\"section-three\"><\/a>\n# Modeling","967f38d5":"<a id=\"section-two\"><\/a>\n# The baseline level of accuracy"}}