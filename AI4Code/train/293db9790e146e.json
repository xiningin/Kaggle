{"cell_type":{"1c7ae926":"code","b345f244":"code","f4ddba53":"code","e4594aef":"code","e177b7de":"code","2e458c28":"code","a89e0b13":"code","66497f2e":"code","d2619c8d":"code","e54e9fe0":"code","9edb78dd":"code","9a90d043":"code","ec594251":"code","8cb5f1d3":"code","23cc9795":"code","eef2ad3b":"code","b0ce05e6":"code","eca1a3cb":"code","ae2698bf":"code","1cbb1a51":"markdown","1f9f4c44":"markdown"},"source":{"1c7ae926":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/all-dogs\/\"))\n\n# Any results you write to the current directory are saved as output.","b345f244":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Reshape\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers import Flatten, Dropout\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.optimizers import Adam\nimport math\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom keras.preprocessing import image","f4ddba53":"img_list =os.listdir(\"..\/input\/all-dogs\/all-dogs\/\")","e4594aef":"print(os.listdir(\"..\/working\"))","e177b7de":"len(img_list)","2e458c28":"temp_img = load_img('..\/input\/all-dogs\/all-dogs\/n02085620_10074.jpg')\ntemp_img_array  = img_to_array(temp_img)","a89e0b13":"temp_img","66497f2e":"temp_img_array.shape","d2619c8d":"def generator_model():\n    model = Sequential()\n    model.add(Dense(input_dim=100, units=1024))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dense(32 * 32 * 128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Reshape((32, 32, 128), input_shape=(32 * 32 * 128,)))\n    model.add(UpSampling2D((2, 2)))\n    model.add(Conv2D(64, (5, 5), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(UpSampling2D((2, 2)))\n    model.add(Conv2D(3, (5, 5), padding=\"same\"))\n    model.add(Activation('tanh'))\n    return model","e54e9fe0":"def discriminator_model():\n    model = Sequential()\n    model.add(Conv2D(64, (5,5), strides=(2, 2), input_shape=(128, 128, 3), padding=\"same\"))\n    model.add(LeakyReLU(0.2))\n    model.add(Conv2D(128, (5,5), strides=(2, 2)))\n    model.add(LeakyReLU(0.2))\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.5))\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n    return model","9edb78dd":"def combine_images(generated_images):\n    total = generated_images.shape[0]\n    cols = int(math.sqrt(total))\n    rows = math.ceil(float(total)\/cols)\n    width, height, ch= generated_images.shape[1:]\n    output_shape = (\n        height * rows,\n        width * cols,\n        ch\n    )\n    combined_image = np.zeros(output_shape)\n\n    for index, image in enumerate(generated_images):\n        i = int(index\/cols)\n        j = index % cols\n        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[:, :, :]\n    return combined_image","9a90d043":"TRAIN_IMAGE_PATH = '..\/input\/all-dogs\/all-dogs\/'\n#GENERATED_IMAGE_PATH = '..\/images\/'\nGENERATED_IMAGE_PATH = '..\/working\/images\/'\nGEN_GENERATED_IMAGE_PATH = '..\/gen_images\/'","ec594251":"# \u8a13\u7df4\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\nimg_list = os.listdir(TRAIN_IMAGE_PATH)\nX_train = []\nfor img in img_list:\n    img = img_to_array(load_img(TRAIN_IMAGE_PATH+img, target_size=(128,128,3)))\n    # -1\u304b\u30891\u306e\u7bc4\u56f2\u306b\u6b63\u898f\u5316\n    img = (img.astype(np.float32) - 127.5)\/127.5\n    X_train.append(img)","8cb5f1d3":"len(X_train)","23cc9795":"# 4D\u30c6\u30f3\u30bd\u30eb\u306b\u5909\u63db(\u30c7\u30fc\u30bf\u306e\u500b\u6570, 128, 128, 3)\nX_train = np.array(X_train)","eef2ad3b":"# generator\u3068discriminator\u3092\u4f5c\u6210\ndiscriminator = discriminator_model()\nd_opt = Adam(lr=1e-5, beta_1=0.1)\ndiscriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n# discriminator\u306e\u91cd\u307f\u3092\u56fa\u5b9a(dcgan\u306e\u4e2d\u306e\u307f)\ndiscriminator.trainable = False\ngenerator = generator_model()\n\ndcgan = Sequential([generator, discriminator])\ng_opt = Adam(lr=2e-4, beta_1=0.5)\ndcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\nBATCH_SIZE = 128\nNUM_EPOCH  = 200\n\nnum_batches = int(X_train.shape[0] \/ BATCH_SIZE)\nprint('Number of batches:', num_batches)\n","b0ce05e6":"for epoch in tqdm(range(NUM_EPOCH)):\n    for index in range(num_batches):\n        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n        image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n        generated_images = generator.predict(noise, verbose=0, batch_size=BATCH_SIZE)\n\n#         # \u751f\u6210\u753b\u50cf\u3092\u51fa\u529b\n#         if (index+1) % (num_batches) == 0:\n#             image = combine_images(generated_images)\n#             image = image*127.5 + 127.5\n#             if not os.path.exists(GENERATED_IMAGE_PATH):\n#                 os.mkdir(GENERATED_IMAGE_PATH)\n#             Image.fromarray(image.astype(np.uint8)).save(GENERATED_IMAGE_PATH+\"%04d_%04d.png\" % (epoch, index))\n            \n        if not os.path.exists(GEN_GENERATED_IMAGE_PATH):\n            os.mkdir(GEN_GENERATED_IMAGE_PATH)\n        \n        if epoch == 200 and index > 59:\n            generated_images_v = generated_images*127.5 + 127.5    \n            for j in range(100):\n                Image.fromarray((generated_images_v[j]*127.5 + 127.5).astype(np.uint8)).save(GEN_GENERATED_IMAGE_PATH+\"%04d_%04d_%04d.png\" % (epoch, index,j))\n\n        # discriminator\u3092\u66f4\u65b0\n        X = np.concatenate((image_batch, generated_images))\n        # \u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u30e9\u30d9\u30eb\u304c1\u3001\u751f\u6210\u753b\u50cf\u306e\u30e9\u30d9\u30eb\u304c0\u306b\u306a\u308b\u3088\u3046\u5b66\u7fd2\u3059\u308b\n        y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n        d_loss = discriminator.train_on_batch(X, y)\n\n        # generator\u66f4\u65b0\n        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n        # \u751f\u6210\u753b\u50cf\u3092discriminator\u306b\u3044\u308c\u305f\u3068\u304d\u306b\n        # \u51fa\u529b\u304c1\u306b\u8fd1\u304f\u306a\u308b(\u8a13\u7df4\u753b\u50cf\u3068\u8b58\u5225\u3055\u308c\u308b\u78ba\u7387\u304c\u9ad8\u304f\u306a\u308b)\u3088\u3046\u306b\u5b66\u7fd2\u3059\u308b\n        g_loss = dcgan.train_on_batch(noise, [1]*BATCH_SIZE)\n\n        print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))","eca1a3cb":"print(os.listdir(GENERATED_IMAGE_PATH))","ae2698bf":"import shutil\n#shutil.make_archive('images', 'zip', '..\/images\/')\nshutil.make_archive('images', 'zip', '..\/gen_images\/')","1cbb1a51":"### show sample images","1f9f4c44":"### Beginer DCGAN LESSON"}}