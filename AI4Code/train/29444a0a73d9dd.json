{"cell_type":{"00d68549":"code","3e463c8a":"code","f16427f6":"code","71bd2a6f":"code","7b932e38":"code","24a58bc7":"code","d4da2939":"code","9a8ebdba":"code","ac8efb2d":"code","a0c4f3ef":"code","820f355d":"code","0d5ab065":"code","6f418dc8":"code","b7b63589":"code","81064ff0":"code","7ef7a349":"code","cc96bc79":"markdown"},"source":{"00d68549":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3e463c8a":"train = pd.read_csv(\"..\/input\/train.tsv\", sep=\"\\t\")\ntest = pd.read_csv(\"..\/input\/test.tsv\", sep=\"\\t\")\nsampleSub = pd.read_csv(\"..\/input\/sampleSubmission.csv\")","f16427f6":"train=train.set_index('PhraseId')\ntrain.head()","71bd2a6f":"train.isnull().any()","7b932e38":"train['Sentiment'].value_counts()","24a58bc7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train['Phrase'], train.Sentiment, random_state=0)","d4da2939":"from sklearn.feature_extraction.text import CountVectorizer\nvect = CountVectorizer(min_df=5, ngram_range=(1, 10)).fit(X_train)\nX_train_vectorized = vect.transform(X_train)\nlen(vect.get_feature_names())","9a8ebdba":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nfrom sklearn.metrics import f1_score\nprint('f1 score: ', f1_score(y_test, predictions, average=\"micro\"))","ac8efb2d":"feature_names = np.array(vect.get_feature_names())\n\nsorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","a0c4f3ef":"test = test.set_index('PhraseId')","820f355d":"result = model.predict(vect.transform(test.Phrase))\nresult = pd.Series(result)","0d5ab065":"test = test.reset_index()\ntest.head()","6f418dc8":"result","b7b63589":"test['Sentiment'] = result","81064ff0":"test.head()","7ef7a349":"test[['PhraseId', 'Sentiment']].to_csv('submission.csv',encoding=\"utf-8\", index=False)","cc96bc79":"So we have mostly average or neutral reviews and a few movies have total negative and total positive reviews"}}