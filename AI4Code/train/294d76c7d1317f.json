{"cell_type":{"0edd5dd7":"code","a9b0f3e5":"code","09d2e000":"code","0fde9275":"code","ccb473b3":"code","0be964d0":"code","9a46aacd":"code","eb15006b":"code","9512719c":"code","a5c0b94f":"code","9ea07e7a":"code","694d4cb9":"code","f3fe0536":"code","3eb22e5a":"code","f2e81b42":"code","2385f3ba":"code","9431e182":"code","d0ab1257":"code","d06d036b":"code","a37cca10":"code","19403408":"code","44bcbde9":"code","e8f7fc83":"code","69416f59":"code","b8ad57d7":"code","b7e5ec00":"code","a84f63bc":"code","fd6a9182":"code","c873d27f":"markdown","acd7418d":"markdown","ce66eeea":"markdown","01209d50":"markdown","64995586":"markdown","45323df9":"markdown","6d80021f":"markdown","0ba380ab":"markdown","6c86267f":"markdown"},"source":{"0edd5dd7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a9b0f3e5":"# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avanc\u00e9s\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","09d2e000":"df = pd.read_csv(\"\/kaggle\/input\/voicegender\/voice.csv\")","0fde9275":"df.head().T","ccb473b3":"df.columns","0be964d0":"from IPython.core.display import HTML # permet d'afficher du code html dans jupyter\ndisplay(HTML(df.head(10).to_html()))","9a46aacd":"df.shape","eb15006b":"df.describe()","9512719c":"sns.pairplot(df, hue = \"label\")","a5c0b94f":"data_train = df.sample(frac=0.8, random_state=1)   # 80% des donn\u00e9es avec frac=0.8\ndata_test = df.drop(data_train.index)              # le reste des donn\u00e9es pour le test","9ea07e7a":"X_train = data_train.drop(['label'], axis=1)\ny_train = data_train['label']\nX_test = data_test.drop(['label'], axis=1)\ny_test = data_test['label']","694d4cb9":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn import tree\ndtc = tree.DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ny_dtc = dtc.predict(X_test)\nprint(accuracy_score(y_test, y_dtc))","f3fe0536":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc, feature_names=X_train.columns, class_names=['benin','malin'], fontsize=14, filled=True)  ","3eb22e5a":"dtc1 = tree.DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 20)\ndtc1.fit(X_train,y_train)","f2e81b42":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc1, feature_names=X_train.columns, class_names=['benin','malin'], fontsize=14, filled=True)  ","2385f3ba":"y_dtc1 = dtc1.predict(X_test)\nprint(accuracy_score(y_test, y_dtc1))","9431e182":"pd.crosstab(y_test, y_dtc1, rownames=['Reel'], colnames=['Prediction'], margins=True)","d0ab1257":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","d06d036b":"rf_score = accuracy_score(y_test, y_rf)\nprint(rf_score)","a37cca10":"pd.crosstab(y_test, y_rf, rownames=['Reel'], colnames=['Prediction'], margins=True)","19403408":"importances = rf.feature_importances_\nindices = np.argsort(importances)","44bcbde9":"plt.figure(figsize=(12,8))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), df.columns[indices])\nplt.title('Importance des caracteristiques')","e8f7fc83":"# All imports\nimport xgboost as XGB\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score","69416f59":"xgb = XGB.XGBClassifier()","b8ad57d7":"# Fit the regressor to the training set and make predictions on the test set\nxgb.fit(X_train, y_train)\ny_xgb = xgb.predict(X_test)","b7e5ec00":"pd.crosstab(y_test, y_xgb, rownames=['Reel'], colnames=['Prediction'], margins=True)","a84f63bc":"print(classification_report(y_test, y_xgb))","fd6a9182":"y_pred = xgb.predict(X_test)\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)","c873d27f":"## Random Forest","acd7418d":"***Matrice de confusion***","ce66eeea":"***Matrice de confusion***","01209d50":"## XGboost","64995586":"# Machine Learning","45323df9":"***Niveau d'importance des caracteristiques***","6d80021f":"***Preparing data to be used***","0ba380ab":"# Visualisations","6c86267f":"## Arbres de d\u00e9cision"}}