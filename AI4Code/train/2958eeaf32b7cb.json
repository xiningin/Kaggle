{"cell_type":{"4ef736a9":"code","ec77a46d":"code","a4dbfacc":"code","2a4568e6":"code","80fb789f":"code","948a609f":"code","e0b1af30":"code","5e12be5f":"code","46dee9e4":"code","b6ceb431":"code","f945b60d":"code","e7648f42":"code","e08fc165":"code","1ced8458":"code","4d55b0f6":"code","e47f5e27":"code","bd131759":"code","66d0c4b4":"code","2f38f17a":"code","a03c1563":"code","cf4bcc52":"code","ce138dd2":"code","c4faa21e":"code","7e34bb8f":"code","a5ebcbd1":"code","60dd20e5":"code","cdb32672":"code","ba4c9fcf":"code","4e0ba711":"code","f8cca728":"code","230adc25":"code","170d5b0e":"code","117924c6":"code","5cd3897c":"code","83eee6b3":"code","91cbcbbc":"code","da3d9125":"code","75b2c15d":"code","4e36ccc0":"markdown","1f5fc6f5":"markdown","06efc682":"markdown","b84a17e4":"markdown","0c8906ee":"markdown","e77c9493":"markdown","e76510ac":"markdown","660844d8":"markdown","d5d7dd71":"markdown","88a8e42e":"markdown","ff581f69":"markdown","345fc3a1":"markdown","f84ebf6c":"markdown","9f280a06":"markdown","dd73a2b6":"markdown","f8f4575c":"markdown","4e541f5c":"markdown","5abbd1a7":"markdown","a0bdd5d9":"markdown"},"source":{"4ef736a9":"# import required packages\n\nimport pandas as pd \nimport numpy as np\nimport os, gc, time, warnings\n\nfrom scipy.misc import imread\nfrom scipy import sparse\nimport scipy.stats as ss\nfrom scipy.sparse import csr_matrix, hstack, vstack\n\nimport matplotlib.pyplot as plt, matplotlib.gridspec as gridspec \nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom PIL import Image\nimport matplotlib_venn as venn\nimport pydot, graphviz\nfrom IPython.display import Image\n\nimport string, re, nltk, collections\nfrom nltk.util import ngrams\nfrom nltk.corpus import stopwords\nimport spacy\nfrom nltk import pos_tag\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer \nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import TweetTokenizer   \n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_is_fitted\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.models import Model, Sequential\nfrom keras.utils import plot_model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, BatchNormalization\nfrom keras.layers import GRU, LSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import Callback","ec77a46d":"# settings\n\nos.environ['OMP_NUM_THREADS'] = '4'\nstart_time = time.time()\ncolor = sns.color_palette()\nsns.set_style(\"dark\")\nwarnings.filterwarnings(\"ignore\")\n\neng_stopwords = set(stopwords.words(\"english\"))\nlem = WordNetLemmatizer()\nps = PorterStemmer()\ntokenizer = TweetTokenizer()\n\n%matplotlib inline","a4dbfacc":"# import the dataset\n\ntrain = pd.read_csv(\"..\/input\/midasiiitd\/V1.4_Training.csv\", encoding = 'latin-1')\ndev = pd.read_csv(\"..\/input\/midasiiitd\/SubtaskA_Trial_Test_Labeled.csv\", encoding = 'latin-1')\ntest = pd.read_csv(\"..\/input\/midasiiitd\/SubtaskA_EvaluationData.csv\", encoding = 'latin-1')","2a4568e6":"# quick look at a few training examples\n\ntrain.head(10)","80fb789f":"print(\"Training data...\")\ntrain.info()","948a609f":"# class-imbalance in training data\n\nsuggestion_count = (train['label'].values == 1).astype(int).sum()\nnon_suggestion_count = (train['label'].values == 0).astype(int).sum()\nprint(\"Total sentences : \" + str(train.shape[0]))\nprint(\"Total suggestions : \" + str(suggestion_count))\nprint(\"Total non_suggestions : \" + str(non_suggestion_count))","e0b1af30":"# oversampling to balance the training data\n\nsuggestions = train[train['label'].values == 1]\n\nwhile suggestion_count < non_suggestion_count:\n    random_suggestion = suggestions.sample()\n    train = train.append(random_suggestion, ignore_index = True)\n    suggestion_count = suggestion_count + 1\n\ntrain.info()","5e12be5f":"# exploring the development\/validation data\n\nprint(\"Development Set...\")\ndev.info()","46dee9e4":"# class-imbalance in development data\n\nsuggestion_count = (dev['label'].values == 1).astype(int).sum()\nnon_suggestion_count = (dev['label'].values == 0).astype(int).sum()\nprint(\"Total sentences : \" + str(dev.shape[0]))\nprint(\"Total suggestions : \" + str(suggestion_count))\nprint(\"Total non_suggestions : \" + str(non_suggestion_count))","b6ceb431":"stopword = set(STOPWORDS)\n\n# wordcloud for sentences with 'suggestion' label\nsubset = train[train.label == 1]\ncontent = subset.sentence.values\nwc = WordCloud(background_color = \"black\", max_words = 2000, stopwords = stopword)\nwc.generate(\" \".join(content))\nplt.figure(figsize = (20,20))\nplt.subplot(221)\nplt.axis(\"off\")\nplt.title(\"Words frequented in 'suggestion' sentences\", fontsize = 20)\nplt.imshow(wc.recolor(colormap = 'viridis', random_state = 17), alpha = 0.98)\n\n# wordcloud for sentences with 'non-suggestion' label\nsubset = train[train.label == 0]\ncontent = subset.sentence.values\nwc = WordCloud(background_color = \"black\", max_words = 2000, stopwords = stopword)\nwc.generate(\" \".join(content))\nplt.subplot(222)\nplt.axis(\"off\")\nplt.title(\"Words frequented in 'non-suggestion' sentences\", fontsize = 20)\nplt.imshow(wc.recolor(colormap = 'viridis', random_state = 17), alpha = 0.98)\n\nplt.show()","f945b60d":"# Aphost lookup dict\n\nAPPO = {\n    \"aren't\" : \"are not\",\n    \"can't\" : \"cannot\",\n    \"couldn't\" : \"could not\",\n    \"didn't\" : \"did not\",\n    \"doesn't\" : \"does not\",\n    \"don't\" : \"do not\",\n    \"hadn't\" : \"had not\",\n    \"hasn't\" : \"has not\",\n    \"haven't\" : \"have not\",\n    \"he'd\" : \"he would\",\n    \"he'll\" : \"he will\",\n    \"he's\" : \"he is\",\n    \"i'd\" : \"I would\",\n    \"i'd\" : \"I had\",\n    \"i'll\" : \"I will\",\n    \"i'm\" : \"I am\",\n    \"isn't\" : \"is not\",\n    \"it's\" : \"it is\",\n    \"it'll\":\"it will\",\n    \"i've\" : \"I have\",\n    \"let's\" : \"let us\",\n    \"mightn't\" : \"might not\",\n    \"mustn't\" : \"must not\",\n    \"shan't\" : \"shall not\",\n    \"she'd\" : \"she would\",\n    \"she'll\" : \"she will\",\n    \"she's\" : \"she is\",\n    \"shouldn't\" : \"should not\",\n    \"that's\" : \"that is\",\n    \"there's\" : \"there is\",\n    \"they'd\" : \"they would\",\n    \"they'll\" : \"they will\",\n    \"they're\" : \"they are\",\n    \"they've\" : \"they have\",\n    \"we'd\" : \"we would\",\n    \"we're\" : \"we are\",\n    \"weren't\" : \"were not\",\n    \"we've\" : \"we have\",\n    \"what'll\" : \"what will\",\n    \"what're\" : \"what are\",\n    \"what's\" : \"what is\",\n    \"what've\" : \"what have\",\n    \"where's\" : \"where is\",\n    \"who'd\" : \"who would\",\n    \"who'll\" : \"who will\",\n    \"who're\" : \"who are\",\n    \"who's\" : \"who is\",\n    \"who've\" : \"who have\",\n    \"won't\" : \"will not\",\n    \"wouldn't\" : \"would not\",\n    \"you'd\" : \"you would\",\n    \"you'll\" : \"you will\",\n    \"you're\" : \"you are\",\n    \"you've\" : \"you have\",\n    \"'re\": \" are\",\n    \"wasn't\": \"was not\",\n    \"we'll\":\" will\",\n    \"didn't\": \"did not\",\n    \"tryin'\":\"trying\"\n}","e7648f42":"def clean(sentence):\n    sentence = sentence.lower()\n    sentence = re.sub('<.*>', '', sentence)\n    sentence = re.sub(\"\\\\n\", \"\", sentence)\n    sentence = re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", sentence)\n    sentence = re.sub(\"\\[\\[.*\\]\", \"\", sentence)\n    sentence = re.sub(\"[\" + re.sub(\"\\.\",\"\",string.punctuation) + \"]\", \"\", sentence)\n    \n    words = tokenizer.tokenize(sentence)\n    \n    words = [APPO[word] if word in APPO else word for word in words]\n    words = [ps.stem(word) for word in words]\n    words = [lem.lemmatize(word, \"v\") for word in words]\n    words = [w for w in words if not w in eng_stopwords]\n    \n    clean_sent = \" \".join(words)\n    \n    return(clean_sent)","e08fc165":"# obtaining separate clean corpora for suggestion and non-suggestion classes\n\nsuggestion_corpus = train[train['label'].values == 1].sentence\nsuggestion_corpus = suggestion_corpus.append(dev[dev['label'].values == 1].sentence)\nclean_suggestion_corpus = \"\"\nfor sentence in suggestion_corpus:\n    clean_suggestion_corpus += clean(sentence)\n\nnon_suggestion_corpus = train[train['label'].values == 0].sentence\nnon_suggestion_corpus = non_suggestion_corpus.append(dev[dev['label'].values == 0].sentence)\nclean_non_suggestion_corpus = \"\"\nfor sentence in non_suggestion_corpus:\n    clean_non_suggestion_corpus += clean(sentence)","1ced8458":"# top 20 bigrams in suggestion sentences\n\nsuggestion_bigrams = ngrams(clean_suggestion_corpus.split(), 2)\nsuggestion_bigrams_freq = collections.Counter(suggestion_bigrams)\nsuggestion_bigrams_freq.most_common(20)","4d55b0f6":"# top 20 bigrams in non-suggestion sentences\n\nnon_suggestion_bigrams = ngrams(clean_non_suggestion_corpus.split(), 2)\nnon_suggestion_bigrams_freq = collections.Counter(non_suggestion_bigrams)\nnon_suggestion_bigrams_freq.most_common(20)","e47f5e27":"del(suggestions)\ndel(subset)\ndel(content)\ndel(stopword)\ndel(wc)\ndel(suggestion_corpus)\ndel(clean_suggestion_corpus)\ndel(non_suggestion_corpus)\ndel(clean_non_suggestion_corpus)\ngc.collect()","bd131759":"# plot of sentence length against label\n\ndf = pd.concat([train, dev])\ndf['count_word'] = df['sentence'].apply(lambda x : len(x.split()))\n\nplt.figure(figsize = (12, 6))\nplt.suptitle(\"How is sentence length related to its label?\", fontsize = 15)\ncount_word = df['count_word'].astype(int)\ndf['count_word'].loc[df['count_word'] > 100] = 100\nplt.plot()\nsns.violinplot(y = 'count_word', x = 'label', data = df, split = True, inner = \"quart\")\nplt.xlabel('Suggestion?', fontsize = 12)\nplt.ylabel('Number of words in a sentence', fontsize = 12)\nplt.title(\"Number of sentences with a given word length\", fontsize = 12)\nplt.show()\n\ndel(df)\ngc.collect()","66d0c4b4":"# plot of mean word length against label\n\ndf = pd.concat([train, dev])\ndf['mean_word_len'] = df['sentence'].apply(lambda x : np.mean([len(word) for word in x.split()]))\n\nplt.figure(figsize = (12, 6))\nplt.suptitle(\"How is mean word length in a sentence related to its label?\", fontsize = 15)\nmean_word_len = df['mean_word_len'].astype(int)\ndf['mean_word_len'].loc[df['mean_word_len'] > 10] = 10\nplt.plot()\nsns.violinplot(y = 'mean_word_len', x = 'label', data = df, split = True, inner = \"quart\")\nplt.xlabel('Suggestion?', fontsize = 12)\nplt.ylabel('Mean word length in sentence', fontsize = 12)\nplt.title(\"Number of sentences with a given mean word length\", fontsize = 12)\nplt.show()\n\ndel(df)\ngc.collect()","2f38f17a":"# corpus containing all the sentences in train, development and test data\n\ncorpus = (pd.concat([train.iloc[:, 0:2], dev.iloc[:, 0:2], test.iloc[:, 0:2]])).sentence\nclean_corpus = corpus.apply(lambda x : clean(x))","a03c1563":"# tf-idf vectors with unigram features\n\nunigram_tfv = TfidfVectorizer(strip_accents = 'unicode', analyzer = 'word', ngram_range = (1,1),\n                              sublinear_tf = 1, stop_words = 'english')\nunigram_tfv.fit(clean_corpus)\n\ntrain_unigrams = unigram_tfv.transform(clean_corpus.iloc[:train.shape[0]])\ndev_unigrams = unigram_tfv.transform(clean_corpus.iloc[train.shape[0]:train.shape[0]+dev.shape[0]])\ntest_unigrams = unigram_tfv.transform(clean_corpus.iloc[train.shape[0]+dev.shape[0]:])","cf4bcc52":"# tf-idf vectors with bigram and trigram features\n\nbtgram_tfv = TfidfVectorizer(strip_accents = 'unicode', analyzer = 'word', ngram_range = (2,3),\n            sublinear_tf = 1, stop_words = 'english')\nbtgram_tfv.fit(clean_corpus)\n\ntrain_btgrams = btgram_tfv.transform(clean_corpus.iloc[:train.shape[0]])\ndev_btgrams = btgram_tfv.transform(clean_corpus.iloc[train.shape[0]:train.shape[0]+dev.shape[0]])\ntest_btgrams = btgram_tfv.transform(clean_corpus.iloc[train.shape[0]+dev.shape[0]:])","ce138dd2":"# tf-idf vectors with char n-gram features\n\ncharngram_tfv = TfidfVectorizer(strip_accents = 'unicode', analyzer = 'char', ngram_range = (1,5),\n                sublinear_tf = 1, stop_words = 'english')\ncharngram_tfv.fit(clean_corpus)\n\ntrain_charngrams =  charngram_tfv.transform(clean_corpus.iloc[:train.shape[0]])\ndev_charngrams = charngram_tfv.transform(clean_corpus.iloc[train.shape[0]:train.shape[0]+dev.shape[0]])\ntest_charngrams = charngram_tfv.transform(clean_corpus.iloc[train.shape[0]+dev.shape[0]:])","c4faa21e":"# evaluation functions for different models\n\ndef lgb_f1_score(preds, train_data):\n    y_train = train_data.get_label()\n    preds = (preds >= 0.5).astype(int)\n    return 'f1_score', f1_score(y_train, preds), True\n\ndef xgb_f1_score(preds, train_data):\n    y_train = train_data.get_label()\n    preds = (preds >= 0.5).astype(int)\n    return 'f1_score', f1_score(y_train, preds)\n\ndef nn_f1_score(y_true, y_pred):\n    y_pred = tf.cast((y_pred >= 0.5), tf.float32)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis = 0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis = 0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis = 0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis = 0)\n\n    p = tp \/ (tp + fp + K.epsilon())\n    r = tp \/ (tp + fn + K.epsilon())\n\n    f1 = 2*p*r \/ (p+r+K.epsilon())\n    f1_score = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1_score)","7e34bb8f":"# dataframes for blending\n\ntrain_labels = pd.DataFrame()\ndev_labels = pd.DataFrame()","a5ebcbd1":"# preparing data for statistical and GBDT models\n\nx_train = hstack((train_unigrams, train_btgrams, train_charngrams)).tocsr()\ny_train = train['label'].values\nx_dev = hstack((dev_unigrams, dev_btgrams, dev_charngrams)).tocsr()\ny_dev = dev['label'].values\nx_test = hstack((test_unigrams, test_btgrams, test_charngrams)).tocsr()","60dd20e5":"# logistic regression classifier\n\nclf = LogisticRegression(C = 0.1, solver = 'liblinear')\nclf.fit(x_train, y_train)\n\nlr_dev_pred = clf.predict_proba(x_dev)[:, 1]\nlr_test_pred = clf.predict_proba(x_test)[:, 1]\n\ntrain_labels['lr'] = (clf.predict_proba(x_train)[:, 1] >= 0.5).astype(int)\ndev_labels['lr'] = (clf.predict_proba(x_dev)[:, 1] >= 0.5).astype(int)\n\ny_pred = (lr_dev_pred >= 0.5).astype(int)\nlr_precision = precision_score(y_dev, y_pred)\nlr_recall = recall_score(y_dev, y_pred)\nlr_f1 = f1_score(y_dev, y_pred)\n\nprint(\"Logistic Regression...\")\nprint(\"Precision score : \" + str(lr_precision))\nprint(\"Recall score : \" + str(lr_recall))\nprint(\"F1 score : \" + str(lr_f1))","cdb32672":"# SVM classifier\n\n# reducing the number of features using Singular Value Decomposition\nsvd = TruncatedSVD(n_components = 15)\nsvd.fit(vstack((x_train, x_dev, x_test)).tocsr())\nx_train_svd = svd.transform(x_train)\nx_dev_svd = svd.transform(x_dev)\nx_test_svd = svd.transform(x_test)\n\n# scaling the data obtained from SVD\nscaler = StandardScaler()\nscaler.fit(np.concatenate((x_train_svd, x_dev_svd, x_test_svd)))\nx_train_svd = scaler.transform(x_train_svd)\nx_dev_svd = scaler.transform(x_dev_svd)\nx_test_svd = scaler.transform(x_test_svd)\n\nclf = SVC(C = 0.1, probability = True)\nclf.fit(x_train_svd, y_train)\n\nsvm_dev_pred = clf.predict_proba(x_dev_svd)[:, 1]\nsvm_test_pred = clf.predict_proba(x_test_svd)[:, 1]\n\ntrain_labels['svm'] = (clf.predict_proba(x_train_svd)[:, 1] >= 0.5).astype(int)\ndev_labels['svm'] = (clf.predict_proba(x_dev_svd)[:, 1] >= 0.5).astype(int)\n\ny_pred = (svm_dev_pred >= 0.5).astype(int)\nsvm_precision = precision_score(y_dev, y_pred)\nsvm_recall = recall_score(y_dev, y_pred)\nsvm_f1 = f1_score(y_dev, y_pred)\n\nprint(\"SVM Classifier...\")\nprint(\"Precision score : \" + str(svm_precision))\nprint(\"Recall score : \" + str(svm_recall))\nprint(\"F1 score : \" + str(svm_f1))","ba4c9fcf":"# lgbm classifier\n\nimport lightgbm as lgb\n\nd_train = lgb.Dataset(x_train, label = y_train)\nd_dev = lgb.Dataset(x_dev, label = y_dev)\nvalid_sets = [d_train, d_dev]\n\nparams = {'learning_rate': 0.2,\n          'application': 'binary',\n          'num_leaves': 31,\n          'verbosity': -1,\n          'bagging_fraction': 0.8,\n          'feature_fraction': 0.6,\n          'nthread': 4,\n          'lambda_l1': 1,\n          'lambda_l2': 1}\n\nmodel = lgb.train(params,\n                  train_set = d_train,\n                  num_boost_round = 25,\n                  valid_sets = valid_sets,\n                  feval = lgb_f1_score,\n                  verbose_eval = False)\n\nlgb_dev_pred = model.predict(x_dev)\nlgb_test_pred = model.predict(x_test)\n\ntrain_labels['lgb'] = (model.predict(x_train) >= 0.5).astype(int)\ndev_labels['lgb'] = (model.predict(x_dev) >= 0.5).astype(int)\n\ny_pred = (lgb_dev_pred >= 0.5).astype(int)\nlgb_precision = precision_score(y_dev, y_pred)\nlgb_recall = recall_score(y_dev, y_pred)\nlgb_f1 = f1_score(y_dev, y_pred)\n\nprint(\"LGBM Classifier...\")\nprint(\"Precision score : \" + str(lgb_precision))\nprint(\"Recall score : \" + str(lgb_recall))\nprint(\"F1 score : \" + str(lgb_f1))","4e0ba711":"del(d_train)\ndel(d_dev)\ndel(model)\ngc.collect()","f8cca728":"# XGBoost classifier\n\nimport xgboost as xgb\n\nd_train = xgb.DMatrix(x_train, label = y_train)\nd_dev = xgb.DMatrix(x_dev, label = y_dev)\nd_test = xgb.DMatrix(x_test)\nevallist = [(d_train, 'train'), (d_dev, 'valid')]\n\nparams = {'booster' : 'gbtree',\n          'nthread' : 4,\n          'eta' : 0.2,\n          'max_depth' : 6,\n          'min_child_weight' : 4,\n          'subsample' : 0.7,\n          'colsample_bytree' : 0.7,\n          'objective' : 'binary:logistic'}\n\nmodel = xgb.train(params, \n                  d_train, \n                  num_boost_round = 21,\n                  evals = evallist,\n                  feval = xgb_f1_score,\n                  verbose_eval = False)\n\nxgb_dev_pred = model.predict(d_dev, ntree_limit = 21)\nxgb_test_pred = model.predict(d_test, ntree_limit = 21)\n\ntrain_labels['xgb'] = (model.predict(d_train, ntree_limit = 21) >= 0.5).astype(int)\ndev_labels['xgb'] = (model.predict(d_dev, ntree_limit = 21) >= 0.5).astype(int)\n\ny_pred = (xgb_dev_pred >= 0.5).astype(int)\nxgb_precision = precision_score(y_dev, y_pred)\nxgb_recall = recall_score(y_dev, y_pred)\nxgb_f1 = f1_score(y_dev, y_pred)\n\nprint(\"XGBoost Classifier...\")\nprint(\"Precision score : \" + str(xgb_precision))\nprint(\"Recall score : \" + str(xgb_recall))\nprint(\"F1 score : \" + str(xgb_f1))","230adc25":"del(x_train)\ndel(y_train)\ndel(x_dev)\ndel(y_dev)\ndel(d_train)\ndel(d_dev)\ndel(model)\ngc.collect()","170d5b0e":"# preparing data for Neural Network\n\nEMBEDDING_FILE = '..\/input\/fasttext\/crawl-300d-2M.vec'\n\nmax_features = 10760\nmaxlen = 600\nembed_size = 300\n\npos_tags_train = train['sentence'].apply(lambda x : \" \".join(item[1] for item in pos_tag(word_tokenize(x)))).values\npos_tags_dev = dev['sentence'].apply(lambda x : \" \".join(item[1] for item in pos_tag(word_tokenize(x)))).values\npos_tags_test = test['sentence'].apply(lambda x : \" \".join(item[1] for item in pos_tag(word_tokenize(x)))).values\n\nx_train = train['sentence'].values + \" \" + pos_tags_train\ny_train = train['label'].values\nx_dev = dev['sentence'].values + \" \" + pos_tags_dev\ny_dev = dev['label'].values\nx_test = test['sentence'].values + \" \" + pos_tags_test\n\ntokenizer = text.Tokenizer(num_words = max_features)\ntokenizer.fit_on_texts(list(x_train) + list(x_dev) + list(x_test))\nx_train = tokenizer.texts_to_sequences(x_train)\nx_dev = tokenizer.texts_to_sequences(x_dev)\nx_test = tokenizer.texts_to_sequences(x_test)\nx_train = sequence.pad_sequences(x_train, maxlen = maxlen)\nx_dev = sequence.pad_sequences(x_dev, maxlen = maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n\ndef get_coefs(word, *arr): \n    return word, np.asarray(arr, dtype = 'float32')\n\nembeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n\nword_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.zeros((nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","117924c6":"# Hybrid Neural Network classifier\n\ninp = Input(shape = (maxlen, ))\nx = Embedding(max_features, embed_size, weights = [embedding_matrix])(inp)\nx = SpatialDropout1D(0.2)(x)\nx = Bidirectional(GRU(100, return_sequences = True))(x)\nx = Conv1D(50, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\navg_pool = GlobalAveragePooling1D()(x)\nmax_pool = GlobalMaxPooling1D()(x)\nconc = concatenate([avg_pool, max_pool])\noutp = Dense(1, activation = \"sigmoid\")(conc)\n    \nmodel = Model(inputs = inp, outputs = outp)\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = [nn_f1_score])\nmodel.fit(x_train, y_train, batch_size = 128, epochs = 1, validation_data = (x_dev, y_dev), verbose = 1)","5cd3897c":"nn_dev_pred = model.predict(x_dev, batch_size = 128, verbose = 1)\nnn_test_pred = model.predict(x_test, batch_size = 128, verbose = 1)\n\ntrain_labels['nn'] = (model.predict(x_train, batch_size = 128, verbose = 1) >= 0.5).astype(int)\ndev_labels['nn'] = (model.predict(x_dev, batch_size = 128, verbose = 1) >= 0.5).astype(int)\n\ny_pred = (nn_dev_pred >= 0.5).astype(int)\nnn_precision = precision_score(y_dev, y_pred)\nnn_recall = recall_score(y_dev, y_pred)\nnn_f1 = f1_score(y_dev, y_pred)\n\nprint(\"Hybrid Neural Network Classifier...\")\nprint(\"Precision score : \" + str(nn_precision))\nprint(\"Recall score : \" + str(nn_recall))\nprint(\"F1 score : \" + str(nn_f1))","83eee6b3":"plot_model(model, to_file = 'model.png')","91cbcbbc":"def getmodel():\n    model = Sequential()\n    model.add(Dense(256, input_dim = 5, activation = 'relu'))\n    model.add(Dense(64, activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = [nn_f1_score])\n    return model","da3d9125":"# Stacking all the models\n\nstacked_model = getmodel()\n\nstacked_model.fit(train_labels, y_train, batch_size = 128, epochs = 2, validation_data = (dev_labels, y_dev), \n          verbose = 1)\n\nstacked_dev_pred = stacked_model.predict(dev_labels, batch_size = 128, verbose = 1)\n\ny_pred = (stacked_dev_pred >= 0.5).astype(int)\nstack_precision = precision_score(y_dev, y_pred)\nstack_recall = recall_score(y_dev, y_pred)\nstack_f1 = f1_score(y_dev, y_pred)\n\nprint(\"Stacked Models Classifier...\")\nprint(\"Precision score : \" + str(stack_precision))\nprint(\"Recall score : \" + str(stack_recall))\nprint(\"F1 score : \" + str(stack_f1))","75b2c15d":"# saving the test labels to output csv file\n\ny_test = (nn_test_pred[:, 0] >= 0.5).astype(int)\nsubmission = pd.read_csv(\"..\/input\/midasiiitd\/SubtaskA_EvaluationData.csv\")\nsubmission.drop(['label'], axis = 1)\nsubmission['label'] = y_test\nsubmission.to_csv(\"sanket_rai.csv\", index = False)","4e36ccc0":"<div>\n<p> Since blending does not seem to improve on the prediction performance of our deep learning model, we will use the predictions of the hybrid neural network on the test data for submission.  \n<\/p>\n<\/div>","1f5fc6f5":"<div><p>\n    Mean word length analysis too does not yield any significant difference between the sentences in the two classes.\n    <\/p>\n<\/div>","06efc682":"<div>\n<h3>Suggestion Mining<\/h3>\n<p>It can be defined as the automatic extraction of suggestions from unstructured text, where the term <i>suggestion<\/i> refers to the expression of tips, advice, recommendations etc. As proposed by Negi et. al. <a href = \"#paper1\"> [1] <\/a>, the scope of suggestions is limited to explicit suggestions only. These are the sentences for which the surface structure as well as the context conform to a suggestion.<\/p>\n\n<h4> Problem Statement <\/h4>\n<p>Given a sentence <i>s<\/i>. If <i>s<\/i> is an explicit suggestion, assign the label <i>'suggestion'<\/i>. Otherwise, assign the label <i>'non-suggestion'<\/i>.<\/p>\n\n<h4> Data <\/h4>\n<p>This notebook uses the <a href = \"https:\/\/github.com\/Semeval2019Task9\/Subtask-A\"> Semeval 2019 Subtask-A<\/a> dataset, which contains sentences from Microsoft Windows App Studio discussion forum.<\/p>\n\n<h4> Contents <\/h4>\n<ol>\n    <li> <a href = \"#eda\"> Exploratory Data Analysis <\/a> <\/li>\n    <li> <a href = \"#fe\"> Feature Engineering <\/a> <\/li>\n    <li> <a href = \"#statmod\"> Statistical Models <\/a> <\/li>\n    <li> <a href = \"#gbdtmod\"> Gradient Boosting Decision Tree Ensemble Models <\/a> <\/li>\n    <li> <a href = \"#dlmod\"> Deep Learning Model <\/a> <\/li>\n    <li> <a href = \"#stackmod\"> Stacking Models <\/a> <\/li>\n<\/ol>\n\n<h4> References<\/h4>\nThis notebook contains theoretic and implementation ideas from the following research papers:<br\/>\n<ol>\n    <li><a href = \"https:\/\/arxiv.org\/abs\/1806.02179\" id = \"paper1\"> Open Domain Suggestion Mining: Problem Definition and Datasets<\/a>. Sapna Negi, Maarten de Rijke, and Paul Buitelaar. arXiv preprint arXiv:1806.02179 (2018).<\/li>\n    <li><a href = \"https:\/\/aclweb.org\/anthology\/S\/S16\/S16-2022.pdf\" id = \"paper2\"> A Study of Suggestions in Opinionated Texts and their automatic Detection <\/a>. Sapna Negi, Kartik Asooja, Shubham Mehrotra, Paul Buitelaar. *SEM 2016, Co-located with ACL 2016, Berlin, Germany.<\/li>\n<li><a href = \"https:\/\/arxiv.org\/pdf\/1709.07403.pdf\" id = \"paper3\"> Inducing Distant Supervision in Suggestion Mining through Part-of-Speech Embeddings <\/a>. Sapna Negi, and Paul Buitelaar. arXiv preprint arXiv:1709.07403 (2017).<\/li>\n<li><a href = \"https:\/\/www.kaggle.com\/jagangupta\/stop-the-s-toxic-comments-eda\"> Toxic Comments EDA <\/a><\/li>\n<\/ol>\n<\/div>","b84a17e4":"<div>\n    <p> Finally, let's see how the length of sentences are related to their labels.\n    <\/p>\n<\/div>","0c8906ee":"<div>\n<h3 id=\"fe\"> Feature Engineering <\/h3>\n<p> We extract certain useful features from the data which may improve the prediction performance of our statistical models.<br\/>\n    As is evident from the above analysis, the features related to the frequency of words may not be useful in this particular case. This may be very domain specific, since users on developers' forums are often very concise, less verbose and use more technical terms while writing all kind of sentences.<br\/>\n    Although, the ngram features too do not seem to differentiate between the sentences in the two classes very well, using these to learn syntactic structure of sentences may improve performances of our statistical models.<br\/>\n    We need not use these additional features, other than the word embeddings for sequence representation, with deep learning models since the neural networks can learn better feature representations on their own.\n<\/div>","e77c9493":"<div>\n    <h3>Evaluation Metrics<\/h3>\n    <p> We will use three different evaluation metrics : Precision score, Recall score and F1 score. The F1 score can be interpreted as a weighted average of the Precision and Recall. These three metrics have been used in paper <a href = \"#paper2\"> [2] <\/a>.  <\/p>\n<\/div>","e76510ac":"<div>\n    <h3 id = \"stackmod\"> Stacking Models <\/h3>\n    <p> In the recent years, stacked models or model ensembles have been able to outperform all the base learners by a significant margin. Top solutions in most of the Kaggle competitions mostly use blends of several models. Here, we will create an ensemble of all the models we have trained till now, by performing weighted average of their outputs.<\/p>\n<\/div>","660844d8":"<div><p>\nAnother measure that can be checked for is the mean word length. The writers may choose more elegant and longer words for expressing suggestions. \n    <\/p><\/div>","d5d7dd71":"<div>\n    <h3 id = \"gbdtmod\"> Gradient Boosting Decision Tree Ensemble Models <\/h3>\n    <p>We will train two high performing GBDT models : LGBM and XGBoost.<\/p>\n<\/div>","88a8e42e":"<div>\n    <p> There are three columns in the training data. The first column is 'id' which is a unique identifier for each sentence. The second column 'sentence' contains exactly one sentence as a string of characters. The third column is the target variable 'label', which is an integer that has value 1 if the corresponding sentence is a suggestion, and 0 otherwise. <b>There are no missing values in the entire training set.<\/b><\/p><\/div>","ff581f69":"<div>\n<p>\nThe word clouds do not render any significant difference between the type of words occuring frequently in the two classes.  The top unigrams in the 'suggestion' class like 'Window', 'app', 'user', 'developer', 'Windows Phone', 'use', 'need' and 'new' also occur frequently in the 'non-suggestion' class.<br\/>\n    Refering to the description of linguistic observations in explicit suggestions in paper <a href = \"#paper1\"> [1] <\/a>, in this dataset, the suggestion sentences do not contain frequent occurence of keywords and pharases directly expressing suggestions, like 'suggest', 'suggestion', 'recommendation', 'advice', 'I suggest', 'I recommend', etc. <br\/> \n    Let's take a look at the top bigrams in the two classes to further see the difference.\n<\/p>\n<\/div>","345fc3a1":"<div>\n<h4> Word Clouds for the two target classes <\/h4>\n<p> Word clouds are a visual representation of the frequency of occurence of several words and phrases in a corpus. The font size of a word or a phrase appearning in a word cloud is directly proportional to its number of occurences in the corpus.<\/p>     \n<\/div>","f84ebf6c":"<div>\n    <h3 id = \"statmod\"> Statistical Models <\/h3>\n    <p> We will train two statistical models : Logistic Regression and Support Vector Machine (SVM).<\/p>\n<\/div>","9f280a06":"<div>\n<p> The suggestion bigrams have more frequent occurences of indirect suggestion expressing phrases like 'would like', 'would nice', 'would great'. These phrases contain an auxiliary verb followed by a verb or an adjective. We may think of extracting some useful feature based on these patterns. However, such constructs also appear in the non-suggestion sentences, as is apparent from the non-suggestion bigrams. Also, given the fact that we have oversampled the positive class to balance the data, it will not be a great idea to extract features based on these bigram patterns. \n<br\/>\n    The statistical models cannot learn the syntactic structure of sentences on their own. But, neural networks can. As suggested in paper <a href = \"#paper3\"> [3] <\/a>, we will use Part Of Speech (POS) embeddings to improve the syntactic structure learning by the deep learning models.\n<\/p>\n<\/div>","dd73a2b6":"<div>\n    <p> There exists a significant class imbalance in the training data. Paper <a href = \"#paper3\"> [3] <\/a> addresses the issue of class imbalance in data. It suggests oversampling to achieve class balance. In oversampling, multiple copies of instances of the minority class are created till a balance is achieved. The results show that balanced data is better for both domain specific and domain independent training.<\/p>\n    <\/div>","f8f4575c":"<div>\n    <h3 id = \"dlmod\"> Deep Learning Model <\/h3>\n    <p> Paper <a href = \"#paper2\"> [2] <\/a> uses two different Neural Network models namely Long Short-Term Memory (LSTM), which is a variant of Recurrent Neural Network (RNN), and Convolutional Neural Network (CNN). For learning sequences, they have used word embeddings generated from three different pre-trained models - COMPOSES7, Glove and DEPS. Paper <a href = \"#paper3\"> [3] <\/a> introduced additional Part Of Speech (POS) embeddings, and an increase in prediction performace was observed on using these.<br\/><br\/>\n        We will develop a hybrid Deep Neural Network architecture containing Gated Recurrent Unit (GRU) units as well as Convolutional layers. The reason we use GRU and not LSTM is that the lengths of word sequences in our dataset are quite small, average length being 19 words. GRU is faster than LSTM and known to perform better with smaller length sequences. In the recent years, Facebook's <a href = \"https:\/\/www.kaggle.com\/facebook\/fasttext-wikinews\"> fastText <\/a> library has shown better performance at learning word representation than other pre-trained models. So, we will use this library for generating word embeddings and POS embeddings. \n        \n    <\/p>\n<\/div>","4e541f5c":"<div><p>There is no class imbalance in the development set.<\/p><\/div>","5abbd1a7":"<div><h3 id = \"eda\"> Exploratory Data Analysis <\/h3><\/div>","a0bdd5d9":"<div>\n    <p> It can be seen from the above plot that both suggestion and non-suggestion classes have similar frequency distribution of sentences having a given number of words, so it will be unwise to label a sentence as suggestion or non-suggestion based on the number of words in it.\n    <\/p>\n<\/div>"}}