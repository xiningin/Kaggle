{"cell_type":{"4b7c5caa":"code","9fdd0d65":"code","9e6ba15e":"code","e6409d40":"code","e9858b94":"code","eb62b39a":"code","14d8816d":"code","dce9ef78":"code","3bc8117e":"code","b61bb367":"code","f657a06e":"markdown","9598b8c9":"markdown","02e0b81d":"markdown"},"source":{"4b7c5caa":"import torch\n\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset\nfrom torch.nn import functional as F\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms, models\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np","9fdd0d65":"DEVICE = 'cpu'\n\nif torch.cuda.is_available():\n    DEVICE = 'cuda'","9e6ba15e":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # 224, 224\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.pool1 = nn.MaxPool2d(2)\n\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(2)\n\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.pool3 = nn.MaxPool2d(2)\n\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 28 * 28, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 1)\n    \n    def forward(self, x):\n        out = self.pool1(F.relu(self.conv1(x)))\n        out = self.pool2(F.relu(self.conv2(out)))\n        out = self.pool3(F.relu(self.conv3(out)))\n        \n        out = self.flatten(out)\n        out = F.relu(self.fc1(out))\n        out = F.relu(self.fc2(out))\n        \n        return torch.sigmoid(self.fc3(out))","e6409d40":"class DataSet(Dataset):\n    def __init__(self, path, transformations=None):\n        self.train_data = ImageFolder(f'{path}\/train', transform=transformations)\n        self.test_data = ImageFolder(f'{path}\/test', transform=transformations)\n    \n    def __len__(self):\n        return len(self.train_data) + len(self.test_data)\n    \n    def __getitem__(self, index):\n        # return the features and target separated\n        return self.dataset[index, :-1], self.dataset[index, -1]","e9858b94":"class DataLoader():\n    def __init__(self, train, test, batch_size, shuffle=True):\n        self.train_data = train\n        self.test_data = test\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n    \n    def load(self):\n        loaders = (torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size, shuffle=self.shuffle),\n                   torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size, shuffle=self.shuffle))\n        \n        return loaders","eb62b39a":"def training_loop(model, train, test, n_epochs, optimizer, loss_fn, print_plot=True):\n    train_accuracy = torch.zeros(n_epochs)\n    test_accuracy = torch.zeros(n_epochs)\n\n    for epoch in range(n_epochs):\n        for example, label in train:\n            example = example.to(DEVICE)\n            label = label.to(DEVICE)\n\n            # return a list instead of a list of one element lists\n            label = label.unsqueeze(1)\n\n            # predict and compute loss\n            output = model(example.float())\n            loss = loss_fn(output, label.float())\n\n            optimizer.zero_grad() # zero gradient (make errors to 0)\n            loss.backward()\n            optimizer.step() # change weights\n\n        with torch.no_grad():\n            for loader, accuracy in [(train, train_accuracy), (test, test_accuracy)]:\n                correct = 0\n                total = 0\n\n                for examples, labels in loader:\n                    examples = examples.to(device=DEVICE)\n                    labels = labels.to(device=DEVICE).view(-1, 1)\n\n                    outputs = model(examples.float())\n                    predicted = torch.round(outputs)\n\n                    total += labels.shape[0]\n                    correct += (predicted == labels).sum()\n\n                accuracy[epoch] = correct \/ total\n        \n        # print the accuracy of every tenth epoch\n        if (epoch+1) % 10 ==0:\n            print(f'Epoch {epoch+1})', \n                  f'Train Accuracy: {train_accuracy[epoch]}',\n                  f'Test Accuracy: {test_accuracy[epoch]}') \n        \n    if print_plot:\n        epochs = range(n_epochs)\n\n        #Ploting both curves, train and val \n        plt.plot(epochs, train_accuracy, 'g', label='Training accuracy')\n        plt.plot(epochs, test_accuracy, 'b', label='Test accuracy')\n        plt.title('Training and Test loss')\n        plt.xlabel('Epochs')\n        plt.ylabel('Accuracy')\n        plt.legend()\n        plt.show()","14d8816d":"transformations = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\ndata = DataSet('..\/input\/skin-cancer-malignant-vs-benign', transformations)\ntrain_loader, test_loader = DataLoader(data.train_data, data.test_data, batch_size=32).load()","dce9ef78":"model = CNN().to(DEVICE)\nn_epochs = 24\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nloss_fn = nn.BCELoss()\n\ntraining_loop(\n    model,\n    train_loader,\n    test_loader,\n    n_epochs,\n    optimizer,\n    loss_fn\n)","3bc8117e":"from collections import OrderedDict\n\nmodel = models.resnet50(pretrained=True)\n\n# we want the layers to be pretrained\nfor param in model.parameters():\n    param.requires_grad = False\n\nn_features = model.fc.in_features\nmodel.fc = nn.Sequential(OrderedDict([\n    ('fc', nn.Linear(n_features, 1)),\n    ('sigmoid', nn.Sigmoid())\n]))","b61bb367":"lr = 0.001\nmodel = model.to(DEVICE)\noptimizer = optim.Adam(model.parameters(), lr = lr)\nloss_fn = nn.BCELoss()\nn_epochs = 16\n\ntraining_loop(\n    model,\n    train_loader,\n    test_loader,\n    n_epochs,\n    optimizer,\n    loss_fn\n)","f657a06e":"## Training on ResNet","9598b8c9":"The model we created has overfit. We have 100% train accuracy and 81% test accuracy. Note that at the 10th epoch the train accuracy was higher than at the end. So we should decrease the number of epochs. We have 100% accuracy because we have a small number of samples and the dataset is balanced.\n\nThe pretrained ResNet50 trained 10 epochs has a smaller accuracy than our model. It has 50 layers. But our cnn has a smaller number of layers. Perhaps, the fact that the images on which we predict are not complex, they don't have complicated shapes, a smaller number of layers is better.","02e0b81d":"## Training"}}