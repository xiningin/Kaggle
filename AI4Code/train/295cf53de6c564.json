{"cell_type":{"2f935a93":"code","b361ca81":"code","3326b926":"code","34c13808":"code","d6a3139a":"code","14d1750e":"code","508ead86":"code","8e51a6d0":"code","5e4934ef":"code","80ba9e39":"markdown","bf2b9f16":"markdown"},"source":{"2f935a93":"import tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, UpSampling2D, Reshape, Dense, Dropout, concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import ResNet50\n\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport os\nimport random\n\nfrom tqdm import tqdm\n\nfrom skimage import io\nfrom matplotlib import pyplot as plt\nimport cv2\n\nimport math\nimport scipy \nfrom scipy.stats import multivariate_normal","b361ca81":"class CustomDataGen(tf.keras.utils.Sequence):\n    \n    def __init__(self, path,\n                 batch_size = 3,\n                 input_size=(512, 512, 3),\n                 shuffle=True, seed = 1, subset = 'training',\n                 data_augmentation = False):\n        self.subset = subset\n        self.path = path\n        self.batch_size = batch_size\n        self.input_size = input_size\n        self.data_augmentation = data_augmentation\n        \n        self.var = input_size[0]\/\/75\n        self.gaussian_kernel = self.gkern(31, self.var)\n        \n        self.imageGenerator = ImageDataGenerator(\n            #horizontal_flip = True,\n            #vertical_flip = True,\n            fill_mode = 'reflect',\n            zoom_range = (1, 1.1),\n            #width_shift_range = 0.2,\n            #height_shift_range = 0.2\n        )\n        \n        self.X_paths = []\n        self.y = []\n        \n        for dirname, _, filenames in tqdm(list(os.walk(self.path))):\n            for filename in sorted(filenames):\n                if filename.endswith('.jpg'):\n                    self.X_paths.append(os.path.join(dirname, filename))\n                    y_filename = os.path.join(dirname, filename)+'.cat'\n                    self.y.append([int(num) for num in open(y_filename).read().split(' ')[1:-1]])\n        \n        self.y = np.array(self.y)\n        self.y = self.y.reshape((self.y.shape[0], self.y.shape[1] \/\/ 2, 2))\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X_paths, self.y, test_size=0.2, random_state = seed)\n        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(self.X_train, self.y_train, test_size=0.2, random_state = seed)\n        \n        if subset == 'training':\n            self.X, self.y = self.X_train, self.y_train\n                \n        elif subset == 'validation':\n            self.X, self.y = self.X_val, self.y_val\n        else:\n            self.X, self.y = self.X_test, self.y_test\n            \n        self.n = len(self.X)\n    \n    def update_var(self, diff):\n        self.var += diff\n        print(f\"Var diffs {self.subset}: {diff}\")    \n    \n\n    def create_hotmap(self, shape, coordinates):\n        image = np.zeros((*shape[:-1], 9), np.float32)\n        coordinates = np.hstack((coordinates, np.arange(9).reshape(9, -1)))\n        \n        coordinates = np.where(coordinates > image.shape[0] - 1, image.shape[0] - 1, coordinates)\n        \n        rows = coordinates[:, 1]\n        cols = coordinates[:, 0]\n        ch = coordinates[:, 2]\n        \n        image[rows, cols, ch] = 1.\n        return image\n    \n    def gkern(self, l=5, sig=1.):\n        \"\"\"\\\n        creates gaussian kernel with side length `l` and a sigma of `sig`\n        \"\"\"\n        ax = np.linspace(-(l - 1) \/ 2., (l - 1) \/ 2., l)\n        gauss = np.exp(-0.5 * np.square(ax) \/ np.square(sig))\n        kernel = np.outer(gauss, gauss)\n        kernel = kernel \/ np.max(kernel)\n        gaussian_kernel = np.zeros((*kernel.shape, 9,9), dtype = np.float32)\n        for i in range(9):\n            gaussian_kernel[:, :, i, i] = kernel \n        return gaussian_kernel\n\n    def __getitem__(self, index):\n        \n        data_x, data_y = [], []\n        \n        for i in range(self.batch_size):\n            x = cv2.imread(self.X[self.batch_size * index + i])[:,:,::-1] \/ 255        \n            y = self.y[self.batch_size * index + i]  \n            \n            \n            x_resized = tf.image.resize(tf.convert_to_tensor(x), self.input_size[:-1], method=tf.image.ResizeMethod.BILINEAR)\n            \n            ratio = np.array([x_resized.shape[0] \/ x.shape[0], x_resized.shape[1] \/ x.shape[1]])[::-1]\n            \n            y = self.create_hotmap(x_resized.shape, (y * ratio).astype(np.int32))\n            y = tf.image.resize(tf.convert_to_tensor(y), self.input_size[:-1], method=tf.image.ResizeMethod.BILINEAR)\n        \n            if self.data_augmentation:\n                seed = random.randint(0, 2**32)\n                x_resized, y = self.imageGenerator.random_transform(x_resized.numpy(), seed), self.imageGenerator.random_transform(y.numpy(), seed) \n           \n            data_x.append(x_resized)\n            data_y.append(y)\n        \n        data_y = np.array(data_y)\n        \n        \n        \n        data_y = tf.nn.conv2d(\n        data_y, self.gaussian_kernel, 1, 'SAME')\n        #maxs = tf.reduce_max(image, axis = (0,1))\n        #maxs = np.where(maxs == 0, 1, maxs)\n        #image = image\/maxs\n        \n        \n        return np.array(data_x), data_y \n    \n    def __len__(self):\n            \n        return self.n \/\/ self.batch_size","3326b926":"train_datagen = CustomDataGen('..\/input\/cat-dataset', data_augmentation = False)\nval_datagen = CustomDataGen('..\/input\/cat-dataset', subset = 'validation', data_augmentation = False)","34c13808":"#Adaloss Callback\nclass AdaLossCallback(tf.keras.callbacks.Callback):\n    \n    def __init__(self):\n        super(AdaLossCallback, self).__init__()\n        self.loss_list = []\n        self.epoch_loss = []#(n_batches, n_samples\/batch, landmarks)\n        self.window_size = 3\n        self.p = 0.9\n    \n    def set_datasets(self, train_datagen, val_datagen):        \n        self.previous_loss_var = None\n        self.train_datagen = train_datagen\n        self.val_datagen = val_datagen\n        \n    def loss(self, y_true, y_pred):\n        \n        loss = tf.reduce_mean((y_true - y_pred) ** 2, axis = (1,2)) #mse, (samples, landmarks)\n        \n        self.epoch_loss.append(loss)\n        \n        return tf.reduce_mean(loss)\n\n    def on_epoch_end(self, epoch, logs=None):\n        \n        epoch_loss_list = np.array(self.epoch_loss)\n        self.epoch_loss.clear()\n        loss_mean = epoch_loss_list.mean(axis = (0, 1)) #list n_landmarks\n        self.loss_list.append(loss_mean) #list (epochs, n_landmarks)     \n        \n        \n        #Compute new vars\n        if len(self.loss_list) > self.window_size:\n            del self.loss_list[0] #remove oldest from window\n        if len(self.loss_list) == self.window_size:\n            loss_list = np.array(self.loss_list)\n            loss_var = ((loss_list - loss_list.mean(axis = 0)) ** 2).mean(axis = 0) #calculate loss var in each landmark.\n            \n            if self.previous_loss_var is not None:\n                diff = self.p * (1 - self.previous_loss_var \/ loss_var )\n                self.train_datagen.update_var(diff)\n                self.val_datagen.update_var(diff)\n            self.previous_loss_var = loss_var\n            \n            batch = 0\n            cat = 0\n            x, y = train_datagen[batch]\n            plt.imshow(x[cat])\n            plt.imshow(y[cat].max(axis = -1), alpha = 0.5)\n            plt.show()\n        \n","d6a3139a":"plt.imshow(train_datagen.gaussian_kernel[:,:,0,0])\nplt.show()","14d1750e":"batch = 10\ncat = 0\nx, y = train_datagen[batch]\nplt.imshow(x[cat])\nplt.imshow(tf.reduce_max(y[cat],axis = -1), alpha = 0.5)\nplt.show()\nprint(x.shape, y.shape)\nprint(tf.reduce_max(y[cat],axis = (0,1)))","508ead86":"from tensorflow.keras.regularizers import L2\n\ndef unet(input_size = (512,512, 3), n_classes = 9, l2=1e-7):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv1)\n    pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n    \n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(pool1)\n    conv2 = Dropout(0.1)(conv2)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv2)\n    pool2 = MaxPool2D(pool_size=(2, 2))(conv2)\n    \n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv3)\n    pool3 = MaxPool2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPool2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(pool4)    \n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=L2(l2))(conv9)\n    conv10 = Conv2D(n_classes, 1, activation = 'sigmoid', kernel_regularizer=L2(l2))(conv9)\n\n    model = Model(inputs, conv10)\n\n    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mse')\n    return model\n\ndef deeplab_plus(input_size = (512,512, 3), n_classes = 9):\n    def SqueezeAndExcite(inputs, ratio=8):\n        init = inputs\n        filters = init.shape[-1]\n        se_shape = (1, 1, filters)\n\n        se = GlobalAveragePooling2D()(init)\n        se = Reshape(se_shape)(se)\n        se = Dense(filters \/\/ ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n        se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n        x = init * se\n        return x\n\n    def ASPP(inputs):\n        \"\"\" Image Pooling \"\"\"\n        shape = inputs.shape\n        y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(inputs)\n        y1 = Conv2D(256, 1, padding=\"same\", use_bias=False)(y1)\n        y1 = BatchNormalization()(y1)\n        y1 = Activation(\"relu\")(y1)\n        y1 = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y1)\n\n        \"\"\" 1x1 conv \"\"\"\n        y2 = Conv2D(256, 1, padding=\"same\", use_bias=False)(inputs)\n        y2 = BatchNormalization()(y2)\n        y2 = Activation(\"relu\")(y2)\n\n        \"\"\" 3x3 conv rate=6 \"\"\"\n        y3 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=6)(inputs)\n        y3 = BatchNormalization()(y3)\n        y3 = Activation(\"relu\")(y3)\n\n        \"\"\" 3x3 conv rate=12 \"\"\"\n        y4 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=12)(inputs)\n        y4 = BatchNormalization()(y4)\n        y4 = Activation(\"relu\")(y4)\n\n        \"\"\" 3x3 conv rate=18 \"\"\"\n        y5 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=18)(inputs)\n        y5 = BatchNormalization()(y5)\n        y5 = Activation(\"relu\")(y5)\n\n        y = Concatenate()([y1, y2, y3, y4, y5])\n        y = Conv2D(256, 1, padding=\"same\", use_bias=False)(y)\n        y = BatchNormalization()(y)\n        y = Activation(\"relu\")(y)\n\n        return y\n        \n    \n    \"\"\" Input \"\"\"\n    inputs = Input(input_size)\n\n    \"\"\" Encoder \"\"\"\n    encoder = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n\n    image_features = encoder.get_layer(\"conv4_block6_out\").output\n    x_a = ASPP(image_features)\n    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n\n    x_b = encoder.get_layer(\"conv2_block2_out\").output\n    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n    x_b = BatchNormalization()(x_b)\n    x_b = Activation('relu')(x_b)\n\n    x = Concatenate()([x_a, x_b])\n    x = SqueezeAndExcite(x)\n\n    x = Conv2D(filters=256, kernel_size=3, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=256, kernel_size=3, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SqueezeAndExcite(x)\n\n    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n    x = Conv2D(n_classes, 1, activation = \"sigmoid\")(x)\n\n    model = Model(inputs, x)\n    return model","8e51a6d0":"model = deeplab_plus()\nif True:\n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n                                       patience=3)  # Early stopping (stops training when validation doesn't improve for {patience} epochs)\n    save_best = tf.keras.callbacks.ModelCheckpoint('deeplab.h5', monitor='val_loss', save_best_only=True,\n                                                    mode='min')  # Saves the best version of the model to disk (as measured on the validation data set)\n    learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss',patience = 2,verbose = 1,factor = 0.1)\n    remote_monitor_callback = tf.keras.callbacks.RemoteMonitor(\n        root='https:\/\/dweet.io', path='\/dweet\/for\/semantic-segmentation-training',\n        send_as_json=False, field = 'data'\n    )\n    adaloss_callback = AdaLossCallback()\n    adaloss_callback.set_datasets(train_datagen, val_datagen)\n\n    #Warming up\n    model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'mse')\n    history = model.fit(train_datagen ,\n            steps_per_epoch = len(train_datagen),\n            validation_steps = len(val_datagen),\n            epochs=15,\n            validation_data=val_datagen,\n            shuffle=True,\n             callbacks = [es, save_best, learning_rate_reduction, remote_monitor_callback])\n    \n    #model.compile(optimizer = Adam(learning_rate = 1e-4), loss = adaloss_callback.loss, run_eagerly = True) \n    \"\"\"history = model.fit(train_datagen ,\n            epochs=100,\n            steps_per_epoch = 200,                        \n            validation_steps = 10,\n            validation_data=val_datagen,\n            shuffle=True,\n             callbacks = [es, save_best, learning_rate_reduction, remote_monitor_callback, adaloss_callback])\"\"\"\n    \n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.savefig('loss.jpg')\n    plt.show()\n    model.load_weights('.\/deeplab.h5')\nelse:    \n    model.load_weights('..\/input\/catkeypointlocationweights\/deeplab.h5')\n    #model.evaluate(val_datagen, verbose = 1)\n    ","5e4934ef":"x, y = val_datagen[7]\npred = model(x).numpy()\n\ncolours = ['b', 'b', 'r', 'y', 'y', 'y', 'y', 'y', 'y']\n\nfor x_sample, p, y_sample in zip(x, pred, y):\n    plt.imshow(x_sample)\n    for i in range(p.shape[-1]):\n        coord = np.unravel_index(p[:,:,i].argmax(), p[:,:,i].shape)[::-1]\n        circle = plt.Circle(coord, 10, color=colours[i])\n        plt.gca().add_patch(circle)\n    #plt.imshow(y_sample[:,:,6], alpha = 0.8)\n    plt.show()\n\n","80ba9e39":"CatKeypoint Location\n\nWe use a pretrained Deeplabv3+ and the technique of regresion keypoint heatmap with AdaLoss(https:\/\/arxiv.org\/pdf\/1908.01070.pdf) to train the network.\nThe network was not fully trained (exceeds 9h limit) but it shows promising results.\n\n![cat3.png](attachment:05076dbf-557a-452a-a02b-84173d696244.png)\n\n![cat2.png](attachment:435194d7-e6e8-40b9-9977-d9db4029371f.png)\n\n![cat1.png](attachment:84da1c11-3c56-4743-9ebe-0af4c40d7ddb.png)","bf2b9f16":"### AdaLoss Callback"}}