{"cell_type":{"3dae30ec":"code","5aba6920":"code","b9a278a3":"code","788abcbd":"code","1b7efc43":"code","a64a5585":"code","cebb583f":"code","03f5b0fc":"code","166d7e5d":"code","009c868a":"code","7ccf584a":"code","ffa525bf":"code","3af49b59":"code","70488f56":"code","c1c06091":"code","0ea2e60f":"code","7be03e4f":"code","a5581aac":"code","c20196a9":"code","69451d75":"code","0bb84616":"code","3317cebf":"code","762c1165":"code","fd8d4c2a":"code","8290bc6c":"code","7f19b2a5":"code","a96c74fe":"code","16162e8a":"code","22cdfec8":"code","e2fefa42":"code","415738a0":"code","4f6e9733":"code","2adabf59":"code","c27c097d":"code","6940afe2":"code","c2417bab":"code","c1af2ec9":"code","9ac44952":"code","6f0e3069":"code","15d884e9":"code","d2315809":"code","7c489b58":"code","20342a10":"code","5b5cdd3c":"code","f2df3bc0":"code","678b234a":"code","06c1a5f1":"code","cc4804ca":"code","77ff1035":"code","157661a1":"code","5bae1f31":"code","5f218f7e":"code","f054f2d6":"code","01cfc30a":"markdown","ece912b2":"markdown","26839541":"markdown","42e66f23":"markdown","0e8a1f01":"markdown","f8886fa8":"markdown","9a7d4f36":"markdown","0d7bfa98":"markdown","0159a3c3":"markdown","49011f24":"markdown","95319349":"markdown","c30f3efc":"markdown","cf491e29":"markdown","d10dd583":"markdown","d15120a3":"markdown"},"source":{"3dae30ec":"# imports\nimport numpy as np\nimport pandas as pd\nimport glob\nfrom pydicom.data import get_testdata_file\nfrom pydicom import dcmread\nimport matplotlib.pyplot as plt\nfrom tqdm import trange","5aba6920":"# read in data\ntrain_df = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/test.csv')","b9a278a3":"# find total number of unique patients\ntrain_df['Patient'].nunique()","788abcbd":"# finding number of patients that are male and female\nprint(test_df['Sex'].unique())\nprint(train_df[train_df['Sex'] == 'Female'].shape)\nprint(train_df[train_df['Sex'] == 'Male'].shape)","1b7efc43":"# getting list of paths to all subjects folders\nsubject_paths = glob.glob('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train\/*')","a64a5585":"# getting list of all dicom paths\ndicom_paths = []\nfor subject in subject_paths:\n    subject_dicoms = glob.glob(subject + '\/*')\n    dicom_paths.append(subject_dicoms)","cebb583f":"# reading in a particular dicom path\nds = dcmread(dicom_paths[100][13])","03f5b0fc":"# displaying the pixel array in the dicom\nplt.figure(figsize = (7, 7))\nplt.imshow(ds.pixel_array, cmap=\"plasma\")\nplt.axis('off');","166d7e5d":"# find max value in the pixel array\nds.pixel_array.max()","009c868a":"# checking which GPU was allocated\n!nvidia-smi","7ccf584a":"!pip install rich efficientnet_pytorch","ffa525bf":"# imports\nimport math\nimport numpy as np\nimport pandas as pd\nimport glob\nimport matplotlib.pyplot as plt\nfrom pydicom import dcmread\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom rich.progress import track","3af49b59":"# Torch-specific imports\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom efficientnet_pytorch import EfficientNet","70488f56":"# Function to read in dicom pixel values from file, and to reshape and resize to smaller size - 224x224\ndef get_img(path):\n    # read in file with pydicom\n    d = dcmread(path)\n    # rescale pixel intensities to match actual values\n    pxls = (d.pixel_array - d.RescaleIntercept) \/ (d.RescaleSlope * 1000)\n    # resize pixel intensities to a 224 by 224 array\n    return cv2.resize(pxls, (224, 224))","c1c06091":"class OsicDataset(Dataset):\n    def __init__(self, df, mode = 'train'):\n        self.mode = mode\n        self.df = df\n        self.transforms = transforms.Compose([\n            transforms.ToTensor(),\n#             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        # particular row of dataset\n        row = self.df.iloc[idx,:]\n        # patient id for certain row\n        pid = row['Patient']\n        # fvc measurement for particular patient\n        label = row['FVC']\n        # list of all dicom file paths within patient directory is obtained with ```glob.glob```\n        img_ids = glob.glob('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/' + self.mode + '\/' + pid + '\/*')\n        # random dicom file path is selected and transformed through the ```get_img``` function\n        img = get_img(np.random.choice(img_ids))\n        # Image is converted to PyTorch tensor\n        img = self.transforms(img)\n        \n        # Tensors are changed to ```torch.double``` datatype\n        # returns dictionary of image and target\n        return {\n            'img': img.type(torch.DoubleTensor),\n            'target': torch.tensor(label, dtype=torch.double),\n        }","0ea2e60f":"class CustomModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1,32,kernel_size=(4,4),padding=1,stride=2)\n        self.max_pool = nn.MaxPool2d(kernel_size=(2, 2))\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=(4, 4), padding=1, stride=2)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.dropout = nn.Dropout(0.15)\n        self.conv3 = nn.Conv2d(64, 4, kernel_size=(4, 4))\n        self.bn2 = nn.BatchNorm2d(4)\n        self.ada_pool = nn.AdaptiveMaxPool2d((28, 28))\n        self.fc1 = nn.Linear(28 * 28 * 4, 16)\n        self.fc2 = nn.Linear(16, 8)\n        self.fc3 = nn.Linear(8, 1)\n        \n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        # first convolutional layer with convs of size 4 and 32 channels\n        x = self.conv1(x)\n        # thresholded with relu\n        x = self.relu(x)\n        # max pooling to reduce image size\n        x = self.max_pool(x)\n        # second convolutional layer with convs of size 4 and 64 channels\n        x = self.conv2(x)\n        x = self.relu(x)\n        # batch normalization used to normalize outputs so far\n        x = self.bn1(x)\n        # max pooling to reduce image size\n        x = self.max_pool(x)\n        # dropout to reduce model overfitting\n        x = self.dropout(x)\n        # third convolutional layer with convs of size 4 and 4 channels\n        x = self.conv3(x)\n        x = self.relu(x)\n        x = self.bn2(x)\n        # adaptive pooling to resize images to 228 by 228\n        x = self.ada_pool(x)\n        \n        # flatten image to be passed through fully connected layers\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.fc3(x)\n        \n        return x","7be03e4f":"class EffModel(nn.Module):\n    def __init__(self, eff_name='b0'):\n        super().__init__()\n        self.conv = nn.Conv2d(1, 3, kernel_size=3, padding=1, stride=2)\n        self.bn = nn.BatchNorm2d(3)\n        self.model = EfficientNet.from_pretrained(f'efficientnet-{eff_name}')\n        self.fc1 = nn.Linear(1000, 128)\n        self.fc2 = nn.Linear(128, 1)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        # one initial convolution layer with convs of size 3 and 3 channels\n        x = self.conv(x)\n        # batch normalization\n        x = self.bn(x)\n        x = self.relu(x)\n        \n        # pass through pretrained model\n        x = self.model(x)\n        # image passed through two additional fully connected layers\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        \n        return x","a5581aac":"# b1 model is being used\nnet = EffModel(eff_name='b1')\n# model set to type torch.double\nnet.double();","c20196a9":"def train(model, train_dataloader, valid_dataloader, test_dataloader, epochs):\n    # have torch recognize GPU if it exists, otherwise use CPU\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    # load model onto the device\n    model.to(device)\n    \n    # set loss to MSELoss and optimizer to Adam\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.MSELoss()\n    \n    print(\"start of training loop\")\n    \n    # creating lists to store training and validation losses\n    train_losses = []\n    val_losses = []\n    \n    # iterating model training for each epoch\n    for epoch in track(range(epochs), description='Training...'):\n        model.train()\n        train_loss = 0\n        train_rmse = 0\n        train_rsq = 0\n        count = 0\n        \n        for batch in train_dataloader:\n            # set to zero so gradients are not accumulated\n            optimizer.zero_grad()\n            \n            # load images and targets onto device\n            imgs = batch['img'].to(device)\n            targets = batch['target'].to(device)\n            \n            # pass images through model\n            out = model(imgs)\n            \n            # calculate loss and backpropagate through network\n            loss = criterion(out, targets.view(-1, 1))\n            loss.backward()\n            optimizer.step()\n            \n            # add train_loss for particular training step to epoch training loss\n            train_loss += loss.item() * targets.size(0)\n            \n            # get predicted and actual values for targets\n            predicted = out.cpu().detach().numpy()\n            actual = targets.cpu().detach().numpy()\n            \n            # use predicted and actual values for target to calculate rmse and r^2 score\n            train_rmse += mean_squared_error(actual, predicted, squared=False)\n            train_rsq  += r2_score(actual, predicted)\n            count += 1\n        \n        # divide train_loss by number of training steps in order to get epoch train_loss\n        train_loss \/= len(train_dataloader.sampler)\n        train_losses.append(train_loss)\n        \n        # divide rmse and r^2 to get epoch rmse and r^2 score\n        train_rmse \/= count\n        train_rsq \/= count\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        val_rmse = 0\n        val_rsq = 0\n        count = 0\n        \n        for batch in val_dataloader:\n            optimizer.zero_grad()\n            \n            imgs = batch['img'].to(device)\n            targets = batch['target'].to(device)\n            \n            out = model(imgs)\n            loss = criterion(out, targets.view(-1, 1))\n            \n            val_loss += loss.item() * targets.size(0)\n            \n            predicted = out.cpu().detach().numpy()\n            actual = targets.cpu().detach().numpy()\n            \n            val_rmse += mean_squared_error(actual, predicted, squared=False)\n            val_rsq  += r2_score(actual, predicted)\n            count += 1\n        \n        val_loss \/= len(val_dataloader.sampler)\n        val_losses.append(val_loss)\n        \n        val_rmse \/= count\n        val_rsq \/= count\n        \n        # print metrics\n        print(\n            \"\\n\",\n            \"\\n\",\n            f\"Epoch {epoch+1}\/{epochs}:\\n\",\n            f\"Train loss: {train_loss:.3f}...\\n\",\n            f\"Valid loss: {val_loss:.3f}...\\n\",\n            \"\\n\",\n            f\"Train RMSE: {train_rmse:.3f}...\\n\",\n            f\"Valid RMSE: {val_rmse:.3f}...\\n\",\n            \"\\n\",\n            f\"Train R^2: {train_rsq}...\\n\",\n            f\"Valid R^2: {val_rsq}...\\n\",\n        )\n    \n    \n    # Test\n    model.eval()\n    \n    test_rmse = 0\n    test_rsq = 0\n    count = 0\n\n    for batch in test_dataloader:\n\n        imgs = batch['img'].to(device)\n        targets = batch['target'].to(device)\n\n        out = model(imgs)\n    \n        predicted = out.cpu().detach().numpy()\n        actual = targets.cpu().detach().numpy()\n        \n        test_rmse += mean_squared_error(actual, predicted, squared=False)\n        test_rsq  += r2_score(actual, predicted)\n        count += 1\n\n    test_rmse \/= count\n    test_rsq \/= count\n\n    print(\n        \"\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"Training Finished!\\n\",\n        f\"Test RMSE: {test_rmse:.3f}...\\n\",\n        f\"Test R^2: {test_rsq:.3f}...\\n\\n\",\n        f\"Predictions: {predicted}\\n\",\n        f\"Actual: {actual} \\n\\n\",\n    )\n    \n    # display loss curves\n    print('Loss Curves: ')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    # plot train losses per epoch\n    plt.plot(list(range(epochs)), train_losses, label='train')\n    # plot validation losses per epoch\n    plt.plot(list(range(epochs)), val_losses, label='valid')\n    plt.legend()\n    plt.show()","69451d75":"train_df = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train.csv') \ntest_df  = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/test.csv')","0bb84616":"train_df = train_df.drop(np.nonzero(np.array(train_df['Patient'] == 'ID00011637202177653955184',dtype=float))[0], axis=0).reset_index(drop=True)\ntrain_df = train_df.drop(np.nonzero(np.array(train_df['Patient'] == 'ID00052637202186188008618',dtype=float))[0], axis=0).reset_index(drop=True)","3317cebf":"train_df, val_df = train_test_split(train_df, test_size=0.3)","762c1165":"train_dataset = OsicDataset(train_df)\nval_dataset = OsicDataset(val_df)\ntest_dataset = OsicDataset(test_df, mode='test')","fd8d4c2a":"train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)","8290bc6c":"train(\n    net,\n    train_dataloader,\n    val_dataloader,\n    test_dataloader,\n    epochs=10\n)","7f19b2a5":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","a96c74fe":"# read in data\ntrain_df = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/test.csv')","16162e8a":"# dropping patients who have dicoms that raise errors when trying to open with pydicom\ntrain_df = train_df.drop(np.nonzero(np.array(train_df['Patient'] == 'ID00011637202177653955184',dtype=float))[0], axis=0).reset_index(drop=True)\ntrain_df = train_df.drop(np.nonzero(np.array(train_df['Patient'] == 'ID00052637202186188008618',dtype=float))[0], axis=0).reset_index(drop=True)","22cdfec8":"print(train_df.columns)\nprint(train_df['SmokingStatus'].unique())","e2fefa42":"# dropping Percent and rearranging columns\ncols = ['Patient', 'Age', 'Sex', 'SmokingStatus', 'Weeks', 'FVC']\ntrain_df = train_df[cols]\ntest_df = test_df[cols]","415738a0":"test_df","4f6e9733":"# label encoding Sex and SmokingStatus\ntrain_df['Sex'] = train_df['Sex'].astype('category').cat.codes\ntrain_df['SmokingStatus'] = train_df['SmokingStatus'].astype('category').cat.codes\n\ntest_df['Sex'] = test_df['Sex'].astype('category').cat.codes\ntest_df['SmokingStatus'] = test_df['SmokingStatus'].astype('category').cat.codes","2adabf59":"print(train_df.info())\nprint(test_df.info())","c27c097d":"# taken from https:\/\/machinelearningmastery.com\/multivariate-time-series-forecasting-lstms-keras\/\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    # get number of variables to shift\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols, names = list(), list()\n    \n    # shift feature data backward in order to use past n_in time points to predict next fvc values\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    \n    # create target column(s) - n_out time points to be predicted\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n        if i == 0:\n            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    \n    # concatenating all shift columns together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    \n    # drop nan values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg","6940afe2":"# get dfs for each patient\ntrain_split = [subj_data for _, subj_data in train_df.groupby('Patient', as_index=False)]\n# get values of each df in train_split\ntrain_vals = [df.values for df in train_split]\n# apply series to supervised function on the values\ntrain_time_series = [series_to_supervised(val) for val in train_vals]\n# sort values in time series by week just in case measurements in the original dataset are not in order\ntrain_time_series = [ts.sort_values(by='var5(t-1)') for ts in train_time_series]","c2417bab":"# concatenate list of time series for each patient\ntrain_ts = pd.concat(train_time_series)","c1af2ec9":"# only predicting next fvc measurement, not other variables\ndrop_idxs = list(range(6, train_ts.shape[1] - 1))\ntrain_ts = train_ts.drop(train_ts.columns[drop_idxs], axis=1)\ntest_ts = test_df","9ac44952":"train_ts","6f0e3069":"# label encoding the patient column\ntrain_ts['Patient'] = train_ts['var1(t-1)'].astype('category').cat.codes","15d884e9":"# rearrange columns to make the df look nicer\ntrain_ts = train_ts[['var1(t-1)', 'Patient', 'var2(t-1)', 'var3(t-1)', 'var4(t-1)', 'var5(t-1)', 'var6(t-1)', 'var6(t)']]","d2315809":"train_ts","7c489b58":"test_ts","20342a10":"submission = pd.read_csv('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/sample_submission.csv')\nsubmission = pd.DataFrame(submission.Patient_Week.str.split('_',1).tolist(),\n                                 columns = ['Patient','Weeks'])","5b5cdd3c":"submission","f2df3bc0":"class CombinedDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.transforms = transforms.Compose([\n            transforms.ToTensor(),\n#             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        # particular row of dataset\n        row = self.df.iloc[idx,:]\n\n        # patient id for certain row\n        pid = row['var1(t-1)']\n        # fvc measurement for particular patient\n        label = row['var6(t)']\n        \n        ## Image Processing\n        \n        # list of all dicom file paths within patient directory is obtained with ```glob.glob```\n        img_ids = glob.glob('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train\/' + pid + '\/*')\n        # random dicom file path is selected and transformed through the ```get_img``` function\n        img = get_img(np.random.choice(img_ids))\n        # Image is converted to PyTorch tensor\n        img = self.transforms(img)\n        \n        ## Time Series Processing\n        # don't include pid char string or label at the end\n        ts_data = np.array(list(row[1:-1].values))\n        ts_data = ts_data.reshape(1, 6)\n        # Tensors are changed to ```torch.double``` datatype\n        # returns dictionary of image and target\n        return {\n            'img': img.type(torch.DoubleTensor),\n            'ts': torch.tensor(ts_data, dtype=torch.double),\n            'target': torch.tensor(label, dtype=torch.double),\n        }","678b234a":"class CombinedModel(nn.Module):\n    def __init__(self, hidden_size, eff_name='b1'):\n        super().__init__()\n        \n        ## img layers\n        self.conv = nn.Conv2d(1, 3, kernel_size=3, padding=1, stride=2)\n        self.bn = nn.BatchNorm2d(3)\n        self.model = EfficientNet.from_pretrained(f'efficientnet-{eff_name}')\n        self.fc1 = nn.Linear(1000, 500)\n        \n        ## ts layer\n        self.hidden_size = hidden_size\n        self.rnn = nn.LSTM(input_size=6,hidden_size=self.hidden_size, num_layers=2, dropout=0.4, batch_first=True)\n        \n        self.output = nn.Linear(500 + hidden_size, 1)\n        self.relu = nn.ReLU()\n        \n    def forward(self, img, ts):\n        # apply conv to increase channels to 3\n        img = self.conv(img)\n        # batch norm to \n        img = self.bn(img)\n        img = self.relu(img)\n        # pass through efficientnet model\n        img = self.model(img)\n        # fc layer to condense outputs down to 500\n        img = self.fc1(img)\n        img = self.relu(img)\n        \n        # run rnn on time series data\n        ts, _ = self.rnn(ts)\n        \n        # concatenate image features with time series features\n        x = torch.cat([img, ts.view(-1,self.hidden_size)], dim=1)\n        # pass through last fc layer\n        return self.output(x)","06c1a5f1":"def train_loop(model, train_dataloader, val_dataloader, epochs):\n    \n    # have torch recognize GPU if it exists, otherwise use CPU\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    # load model onto the device\n    model.to(device)\n    \n    # set loss to MSELoss and optimizer to Adam\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.L1Loss()\n    \n    print(\"start of training loop\")\n    \n    # creating lists to store training and validation losses\n    train_losses = []\n    val_losses = []\n    \n    # iterating model training for each epoch\n    for epoch in track(range(epochs), description='Training...'):\n        model.train()\n        train_loss = 0\n        train_rmse = 0\n        train_rsq = 0\n        count = 0\n        \n        for batch in train_dataloader:\n            # set to zero so gradients are not accumulated\n            optimizer.zero_grad()\n            \n            # load images, time series data, and targets onto device\n            imgs = batch['img'].to(device)\n            ts = batch['ts'].to(device)\n            targets = batch['target'].to(device)\n            \n            # pass images and time series data through model\n            out = model(imgs, ts)\n            \n            # calculate loss and backpropagate through network\n            loss = criterion(out, targets.view(-1, 1))\n            loss.backward()\n            optimizer.step()\n            \n            # add train_loss for particular training step to epoch training loss\n            train_loss += loss.item() * targets.size(0)\n            \n            # get predicted and actual values for targets\n            predicted = out.cpu().detach().numpy()\n            actual = targets.cpu().detach().numpy()\n            \n            # use predicted and actual values for target to calculate rmse and r^2 score\n            train_rmse += mean_squared_error(actual, predicted, squared=False)\n            train_rsq  += r2_score(actual, predicted)\n            count += 1\n        \n        # divide train_loss by number of training steps in order to get epoch train_loss\n        train_loss \/= len(train_dataloader.sampler)\n        train_losses.append(train_loss)\n        \n        # divide rmse and r^2 to get epoch rmse and r^2 score\n        train_rmse \/= count\n        train_rsq \/= count\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        val_rmse = 0\n        val_rsq = 0\n        count = 0\n        \n        for batch in val_dataloader:\n            optimizer.zero_grad()\n            \n            imgs = batch['img'].to(device)\n            ts = batch['ts'].to(device)\n            targets = batch['target'].to(device)\n            \n            out = model(imgs, ts)\n            loss = criterion(out, targets.view(-1, 1))\n            \n            val_loss += loss.item() * targets.size(0)\n            \n            predicted = out.cpu().detach().numpy()\n            actual = targets.cpu().detach().numpy()\n            \n            val_rmse += mean_squared_error(actual, predicted, squared=False)\n            val_rsq  += r2_score(actual, predicted)\n            count += 1\n        \n        val_loss \/= len(val_dataloader.sampler)\n        val_losses.append(val_loss)\n        \n        val_rmse \/= count\n        val_rsq \/= count\n        \n        # print metrics\n        print(\n            \"\\n\",\n            \"\\n\",\n            f\"Epoch {epoch+1}\/{epochs}:\\n\",\n            f\"Train loss: {train_loss:.3f}...\\n\",\n            f\"Valid loss: {val_loss:.3f}...\\n\",\n            \"\\n\",\n            f\"Train RMSE: {train_rmse:.3f}...\\n\",\n            f\"Valid RMSE: {val_rmse:.3f}...\\n\",\n            \"\\n\",\n            f\"Train R^2: {train_rsq}...\\n\",\n            f\"Valid R^2: {val_rsq}...\\n\",\n        )\n    \n    \n    # Test\n    model.eval()\n    \n    test_rmse = 0\n    test_rsq = 0\n    count = 0\n\n#     for batch in test_dataloader:\n\n#         imgs = batch['img'].to(device)\n#         targets = batch['target'].to(device)\n\n#         out = model(imgs, targets)\n    \n#         predicted = out.cpu().detach().numpy()\n#         actual = targets.cpu().detach().numpy()\n        \n#         test_rmse += mean_squared_error(actual, predicted, squared=False)\n#         test_rsq  += r2_score(actual, predicted)\n#         count += 1\n\n#     test_rmse \/= count\n#     test_rsq \/= count\n\n    print(\n        \"\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"Training Finished!\\n\",\n#         f\"Predictions vs Actual: {submission}\",\n    )\n    \n    # display loss curves\n    print('Loss Curves: ')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    # plot train losses per epoch\n    plt.plot(list(range(epochs)), train_losses, label='train')\n    # plot validation losses per epoch\n    plt.plot(list(range(epochs)), val_losses, label='valid')\n    plt.legend()\n    plt.show()","cc4804ca":"# randomly sample certain patients to be in the train set and others to be in validation\nrng = np.random.default_rng()\nnum_patients = train_ts['Patient'].nunique()\nval_idxs = rng.choice(num_patients, size=math.floor(num_patients * 0.3), replace=False)\ntrain = train_ts.loc[~train_ts['Patient'].isin(val_idxs)].copy()\nvalid = train_ts.loc[train_ts['Patient'].isin(val_idxs)].copy()","77ff1035":"print(train.shape)\nprint(valid.shape)","157661a1":"# instantiate datasets and dataloaders with a batch size of 64\ntrain_dataset = CombinedDataset(train)\nvalid_dataset = CombinedDataset(valid)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=64)\nvalid_dataloader = DataLoader(train_dataset, batch_size=64)","5bae1f31":"# create new efficientnet b3 model and convert model to work with double tensors\nnet = CombinedModel(32, eff_name='b3')\nnet.double();","5f218f7e":"# run training loop\ntrain_loop(net, train_dataloader, valid_dataloader, epochs=30)","f054f2d6":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","01cfc30a":"#  Model Training","ece912b2":"## Training Loop\n* ```net``` (convolutional neural network chosen) is passed into train function\n* train, validation, and test dataloaders are passed into train function\n* 10 epochs of training are specified","26839541":"# Cleanup","42e66f23":"## Preprocessing","0e8a1f01":"# CombinedDataset Class\n* Relatively similar to the ```OsicDataset``` but includes other feature data to be used in time series prediction (smoking status, gender, etc.)","f8886fa8":"# EDA","9a7d4f36":"## Train Function\n* Created with use of previous mimic_bert code\n* Allows GPU training\n* Mean Squared Error used as loss function\n* Adam used as optimizer function\n* MSE loss, RMSE, and R^2 calculated during training and validation\n* RMSE and R^2 calculated during train validation, and test\n* Loss curve of training and validation loss is plotted","0d7bfa98":"## Preprocessing\n\n* provided csv files are read into ```train_df``` and ```test_df``` respectively\n* subjects with dicom files that cause errors due to being stored in a different compressed format were not included\n* Provided train dataframe was partitioned into train and validation with in a ratio of 0.7:0.3","0159a3c3":"# Combining both a CNN and RNN to include Tabular Data","49011f24":"## PyTorch Dataset Class\n### ```__init__``` function:\n* Variables:\n    * ```self.mode``` to tell function where to find dicom images for particular subject (train or test folder)\n    * ```self.df``` specifies the dataframe containing train, validation, or test patients\/FVC measurements\n    * ```self.transforms``` specifies particular transforms applied on image - here, the image is only converted to a pytorch tensor\n\n### ```__len__``` function:\n * Function that tells PyTorch the size of the dataset being used\n * set to ```len(self.df)``` because the dataframe contains the total number of pids and each image\/target is selected once per patient\n\n### ```__getitem__``` function:\n* particular data point at specified idx selected\n* ```pid``` stores Patient ID for the particular datapoint\n* ```label``` stores FVC measurement for a particular Patient ID\n* ```img``` contains a random image chosen from all patient dicoms after being transformed\n* Tensors of type double are returned (model requires double data type)","95319349":"## Data Loading\n* ```train_df```,```val_df```, and ```test_df``` are passed into train, validation, and test instances of the ```OsicDataset``` class\n* PyTorch DataLoaders are created that prepare data in batches of 32 and randomly shuffle data","c30f3efc":"# CombinedModel Class\n* similar to ```EffModel``` but includes the time series data through the use of an LSTM\n* hidden_size of the LSTM can be changed\n* output tensors from RNN and CNN are concatenated and passed through a last fully connected layer to create output","cf491e29":"## Cleanup\n* gc package used for garbage collection to free RAM memory\n* ```torch.cuda.empty_cache()``` used to free GPU VRAM memory","d10dd583":"## Model Specification\nTwo models are created:\n* CustomModel\n    * custom model created using prior code\n* EffModel\n    * model that makes use of pretrained neural networks: created with help from https:\/\/www.kaggle.com\/noelmat\/pytorch-efficientnet-with-better-dataloaders\n    * ```eff_name``` specifies which model (from b0-b7) is to be used as the pretrained model - here, ```b1``` is used","d15120a3":"## Libraries Utilized\n* numpy - used for arrays and fast random selection\n* pandas - used for reading in csv file and accessing row data for generating model inputs and targets\n* glob - used for finding all dicom files belonging to a particular patient (finds dicom files in patient folder)\n* matplotlib - used for visualizing training and validation loss curves\n* pydicom - used as an interface to read in dicom information and pixel values\n* cv2 - used to resize images to a smaller and consistent shape\n* scikit-learn - used for ```train_test_split``` and for r^2 and RMSE calculation\n* rich - used for a progress bar to visualize model training runtime\n* pytorch - used for model creation, training, and data preparation\n* efficientnet_pytorch - used for pretrained EfficientNet models for use in transfer learning"}}