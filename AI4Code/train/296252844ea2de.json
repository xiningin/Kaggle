{"cell_type":{"c007da68":"code","76270106":"code","6236081f":"code","398d307c":"code","16fe6ed0":"code","6f2c9128":"code","901cdd45":"code","b299d778":"code","35c4391d":"code","88d5491b":"code","681739e0":"code","b0ceae14":"code","c76fed26":"code","d992214d":"code","10ac3573":"code","3ee7981f":"code","5a51fe66":"code","90318883":"code","62e6f75a":"code","0f690df9":"code","adb12bdd":"code","36c62cd7":"code","cfd286e3":"code","4a7dbd63":"code","91367a69":"code","1c07354f":"code","7f097f37":"code","db425faa":"code","cae3856d":"code","bbeb616b":"code","711001eb":"markdown","98513eda":"markdown","51bd47c1":"markdown","4e73b93a":"markdown","8a18daf1":"markdown","2750e441":"markdown","4f41fda3":"markdown","c0d18745":"markdown","dae5549e":"markdown","7538e478":"markdown","000ec29f":"markdown","7d2eca5a":"markdown","badc0f84":"markdown","f72caaf5":"markdown","6acb36a2":"markdown","d70282ac":"markdown","2de16bc3":"markdown","392b72b3":"markdown","a8d64989":"markdown","6c7581b8":"markdown","bb15c8ab":"markdown","a390ad77":"markdown","64c97b60":"markdown","25756f96":"markdown","049cf5c9":"markdown","54246918":"markdown","8acd4925":"markdown","9b2e13b7":"markdown","300e16ee":"markdown","0073fcb7":"markdown","fb60f036":"markdown","36433434":"markdown"},"source":{"c007da68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nplt.rcParams['figure.dpi'] = 300\nimport matplotlib.dates as mdates\nimport missingno as msno\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfiles = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n        if '.csv' in filename:\n            files +=list([filename])\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\naq_auser = pd.read_csv(\"..\/input\/acea-water-prediction\/Aquifer_Auser.csv\", index_col = 'Date')\naq_doganella = pd.read_csv(\"..\/input\/acea-water-prediction\/Aquifer_Doganella.csv\", index_col = 'Date')\naq_luco = pd.read_csv(\"..\/input\/acea-water-prediction\/Aquifer_Luco.csv\", index_col = 'Date')\naq_petrignano = pd.read_csv(\"..\/input\/acea-water-prediction\/Aquifer_Petrignano.csv\", index_col = 'Date')\nlk_bilancino = pd.read_csv(\"..\/input\/acea-water-prediction\/Lake_Bilancino.csv\", index_col = 'Date')\nrv_arno = pd.read_csv(\"..\/input\/acea-water-prediction\/River_Arno.csv\", index_col = 'Date')\nws_amiata = pd.read_csv(\"..\/input\/acea-water-prediction\/Water_Spring_Amiata.csv\", index_col = 'Date')\nws_lupa = pd.read_csv(\"..\/input\/acea-water-prediction\/Water_Spring_Lupa.csv\", index_col = 'Date')\nws_madonna = pd.read_csv(\"..\/input\/acea-water-prediction\/Water_Spring_Madonna_di_Canneto.csv\", index_col = 'Date')\n\ndatasets=[aq_auser,aq_doganella,aq_luco,aq_petrignano,lk_bilancino,rv_arno,ws_amiata,ws_lupa,ws_madonna]","76270106":"# Creating a brief dataframe to compare the qty of rows and cols of each file.\ndatasets_df = pd.DataFrame(columns=['File_Name'], data=files)\ndatasets_df['Waterbody_type'] = datasets_df.File_Name.apply(lambda x: x.split('_')[0])\ndatasets_df['Qty_Rows'] = datasets_df.File_Name.apply(lambda x: pd.read_csv(f'..\/input\/acea-water-prediction\/{x}').shape[0])\ndatasets_df['Qty_Cols'] = datasets_df.File_Name.apply(lambda x: pd.read_csv(f'..\/input\/acea-water-prediction\/{x}').shape[1])\ndatasets_df = datasets_df.replace('Water','Water_Spring')\ndatasets_df = datasets_df.sort_values(by=['Waterbody_type','Qty_Rows'], ascending=[True,False]).reset_index(drop=True)\n#datasets_df.style.bar(subset=['Qty_Rows','Qty_Cols'], color='#118DFF')\ndatasets_df","6236081f":"#Stating each waterbody target\nauser_targets = ['Depth_to_Groundwater_LT2', 'Depth_to_Groundwater_SAL', 'Depth_to_Groundwater_CoS']\ndoganella_targets = ['Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_2','Depth_to_Groundwater_Pozzo_3',\n                     'Depth_to_Groundwater_Pozzo_4','Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6',\n                     'Depth_to_Groundwater_Pozzo_7','Depth_to_Groundwater_Pozzo_8','Depth_to_Groundwater_Pozzo_9']\nluco_targets = ['Depth_to_Groundwater_Podere_Casetta']\npetrignano_targets = ['Depth_to_Groundwater_P24', 'Depth_to_Groundwater_P25']\nbilancino_targets = ['Lake_Level', 'Flow_Rate']\narno_targets = ['Hydrometry_Nave_di_Rosano']\namiata_targets = ['Flow_Rate_Bugnano','Flow_Rate_Arbure', \n                  'Flow_Rate_Ermicciolo','Flow_Rate_Galleria_Alta']\nlupa_targets = ['Flow_Rate_Lupa']\nmadonna_targets = ['Flow_Rate_Madonna_di_Canneto']","398d307c":"#Defining some functions\ndef df_relinfo(df, target_var=[]):\n    x = pd.DataFrame(df.isna().sum().apply(lambda x: x\/df.shape[0])).reset_index().rename(columns={'index':'Feature',0:'%Na'})\n    x['Na_qty'] = df.isna().sum().tolist()\n    x['Variable'] = x.Feature.apply(lambda x: 'Target' if x in target_var else 'Predictor')\n    return x.sort_values(by='%Na', ascending = False).reset_index(drop=True).style.bar(subset = ['%Na'], color = '#118DFF')\n\ndef corr_plot(data, top_visible=False, right_visible=False, bottom_visible=True, left_visible=False, ylabel=None, figsize=(15,11), axis_grid='y'):\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.title('Correlations (Pearson)', size=15, fontweight='bold')\n    mask = np.triu(np.ones_like(data.corr(), dtype=bool))\n    sns.heatmap(round(data.corr(), 2), mask=mask, cmap='viridis', annot=True)\n    plt.show()\n    \ndef line_plot(data, y, title, color, top_visible=False, right_visible=False, bottom_visible=True, left_visible=False,\n             ylabel=None, figsize=(10,4), axis_grid='y'):\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.title(title, size=15, fontweight='bold')\n    \n    for i in ['top','right','bottom','left']:\n        ax.spines[i].set_color('black')\n    #    ax.spines[i].set_visible(i+'_visible')\n    \n    ax.spines['top'].set_visible(top_visible)\n    ax.spines['right'].set_visible(right_visible)\n    ax.spines['bottom'].set_visible(bottom_visible)\n    ax.spines['left'].set_visible(left_visible)\n    \n    sns.lineplot(x=range(len(data[y])), y=data[y], dashes=False, color=color, linewidth=.5)\n    ax.xaxis.set_major_locator(plt.MaxNLocator(20))\n    \n    ax.set_xticks([])\n    plt.xticks(rotation=90)\n    plt.xlabel('')\n    plt.ylabel(ylabel)\n    ax.grid(axis=axis_grid, alpha=0.9, linestyle='--')\n    plt.show()\n\ndef columns_viz(data, color):\n    for i in range(len(data.columns)):\n        line_plot(data=data, y=data.columns[i], color=color, \n                 title='{} dynamics'.format(data.columns[i]),\n                  bottom_visible=False, figsize=(10,2))\n        \n# some more helper functions\ndef add_month(df):\n    \"\"\"\n    Convert date to a date object, then create the month column\n    \"\"\"\n    df = df.reset_index()\n    df['Date'] = pd.to_datetime(df['Date'])\n    df = df.sort_values(by = 'Date')\n    \n    df['Month'] = pd.DatetimeIndex(df['Date']).month\n    return df\n\ndef add_year(df):\n    \"\"\"\n    add a column for the year\n    \"\"\"\n    df['Year'] = pd.DatetimeIndex(df['Date']).year\n    return df\n\ndef add_seasons(df):\n    \"\"\"\n    This function will add the season (winter, spring, summer, autumn) based on the month\n    Spring: March, April, May\n    Summer: June, July, August\n    Autumn: September, October, November\n    Winter: December, January, February\n    \"\"\"\n    months = df['Month'].unique()\n    df['Season'] = df['Month']\n    for month in months:\n        if month in [12,1,2]:\n            df.loc[lambda df: df['Month'] == month, 'Season'] = '1_Winter'\n        elif month in [3,4,5]:\n            df.loc[lambda df: df['Month'] == month, 'Season'] = '2_Spring'\n        elif month in [6,7,8]:\n            df.loc[lambda df: df['Month'] == month, 'Season'] = '3_Summer'\n        else:\n            df.loc[lambda df: df['Month'] == month, 'Season'] = '4_Autumn'\n    return df\n\ndef do_dates(df):\n    df = add_month(df)\n    df = add_year(df)\n    df = add_seasons(df)\n    return df","16fe6ed0":"print('The earliest date is: \\t', datasets[5].index[0])\nprint('The latest date is: \\t', datasets[5].index[-1])","6f2c9128":"df_relinfo(rv_arno,arno_targets)","901cdd45":"corr_plot(datasets[5])","b299d778":"columns_viz(datasets[5], '#FF5733')","35c4391d":"#Adding rainfall Sum, year, month, month_year\ndf = rv_arno[['Hydrometry_Nave_di_Rosano', 'Temperature_Firenze']].reset_index()\ndf['rainfall'] = rv_arno.iloc[:, 0:-2].sum(axis = 1).values\ndf['year'] = pd.to_datetime(df.Date).dt.year\ndf['month'] = pd.to_datetime(df.Date).dt.month\ndf['month_year'] = pd.to_datetime(df.Date).apply(lambda x: x.strftime('%Y\/%m'))","88d5491b":"# Monthly dynamics\nr_means = np.log(df.groupby('month_year').Hydrometry_Nave_di_Rosano.mean() * 10).reset_index()\nr_means['month_year'] = pd.to_datetime(r_means['month_year'])\n\nr_rain = np.log(df.groupby('month_year').rainfall.mean()).reset_index()\nr_rain['month_year'] = pd.to_datetime(r_rain['month_year'])\n\nr_temp = np.log(df.groupby('month_year').Temperature_Firenze.mean()).reset_index()\nr_temp['month_year'] = pd.to_datetime(r_temp['month_year'])\n\nfig, ax = plt.subplots(figsize = (15, 5))\nplt.title('Monthly dynamics (Arno River)', size = 15, fontweight = 'bold')\n          \nsns.lineplot(data = r_rain, x = 'month_year', y = 'rainfall',  \n             color = 'gray', label = 'Rainfall', alpha = 0.4)\nplt.xticks(rotation = 45)\nsns.lineplot(data = r_temp, x = 'month_year', y = 'Temperature_Firenze', \n             color = 'green', label = 'Temperature_Firenze', alpha = 0.6)\nplt.xticks(rotation = 45)\nsns.lineplot(data = r_means, x = 'month_year', y = 'Hydrometry_Nave_di_Rosano', \n             color = 'blue', label = 'Hydrometry')\nplt.xticks(rotation = 45)\n    \nfor i in ['top', 'right', 'bottom', 'left']:\n        ax.spines[i].set_visible(False)\n\nax.set_xticks(r_means.month_year[::12])\nax.set_xticklabels(range(1998, 2021, 1))\nax.set_xlabel('')\nax.set_ylabel('')\nax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\nplt.show()","681739e0":"# Yearly dynamics\nr_means_y = np.log(df.groupby('year').Hydrometry_Nave_di_Rosano.mean() * 10).reset_index()\nr_rain_y = np.log(df.groupby('year').rainfall.mean()).reset_index()\nr_temp_y = np.log(df.groupby('year').Temperature_Firenze.mean()).reset_index()\n\nfig, ax = plt.subplots(figsize = (15, 5))\nplt.title('Yearly dynamics (Arno River)', size = 15, fontweight = 'bold')\n          \nsns.lineplot(data = r_rain_y, x = 'year', y = 'rainfall',  \n             color = 'gray', label = 'Rainfall', alpha = 0.4)\nplt.xticks(rotation = 45)\nsns.lineplot(data = r_temp_y, x = 'year', y = 'Temperature_Firenze', \n             color = 'green', label = 'Temperature_Firenze', alpha = 0.6)\nplt.xticks(rotation = 45)\nsns.lineplot(data = r_means_y, x = 'year', y = 'Hydrometry_Nave_di_Rosano', \n             color = 'blue', label = 'Hydrometry')\nplt.xticks(rotation = 45)\n    \nfor i in ['top', 'right', 'bottom', 'left']:\n        ax.spines[i].set_visible(False)\n\nax.set_xticks(r_means_y.year)\nax.set_xlabel('')\nax.set_ylabel('')\nax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\nplt.show()","b0ceae14":"msno.matrix(rv_arno)","c76fed26":"rv_arno_wrk = do_dates(rv_arno).drop(columns=['Rainfall_Vernio','Rainfall_Stia','Rainfall_Consuma', \\\n    'Rainfall_Incisa', 'Rainfall_Montevarchi', 'Rainfall_S_Savino', 'Rainfall_Laterina', 'Rainfall_Bibbiena', 'Rainfall_Camaldoli'])\nrv_arno_wrk['Rainfall_Mean'] = rv_arno_wrk.iloc[:, 1:6].mean(axis = 1).values\nrv_arno_wrk","d992214d":"test = rv_arno_wrk.groupby('Season').mean().drop(columns=['Year','Month','Temperature_Firenze','Hydrometry_Nave_di_Rosano'])\n\nfig, ax = plt.subplots(figsize = (15, 5))\nsns.lineplot(data=test, dashes=False)","10ac3573":"# I will delete data before 2004 because its having all missing values on the Rainfall variables.\n# I will fill the NaN values in Target with ffill. Affecting only 3 rows.\n# I will replace 0 values in Target with ffill as well. Affecting 187 rows, but mainly not consecutive.\nrv_arno_wrk = rv_arno_wrk[rv_arno_wrk.Date>'2004-01-01']\nrv_arno_wrk['Hydrometry_Nave_di_Rosano'].fillna(method='ffill', inplace=True)\nrv_arno_wrk['Hydrometry_Nave_di_Rosano'].replace(to_replace=0, method='ffill', inplace=True)","3ee7981f":"rv_arno_wrk['Temperature_Firenze'].isnull().sum()","5a51fe66":"rv_arno_tmp = rv_arno_wrk.groupby(['Year','Month']).mean().drop(columns=['Hydrometry_Nave_di_Rosano','Rainfall_Le_Croci', 'Rainfall_Cavallina', 'Rainfall_S_Agata',\n       'Rainfall_Mangona', 'Rainfall_S_Piero','Rainfall_Mean']).reset_index()\nrv_arno_tmp =rv_arno_tmp.pivot('Month','Year','Temperature_Firenze')\nfig, ax = plt.subplots(figsize = (15, 5))\nplt.title('Average Temperature per Month and Year', size = 15, fontweight = 'bold')\nsns.lineplot(data=rv_arno_tmp);","90318883":"rv_arno_tmp_mean = rv_arno_wrk.groupby('Month').mean().drop(columns=['Year','Hydrometry_Nave_di_Rosano','Rainfall_Le_Croci', 'Rainfall_Cavallina', 'Rainfall_S_Agata',\n       'Rainfall_Mangona', 'Rainfall_S_Piero','Rainfall_Mean'])\nrv_arno_tmp_mean","62e6f75a":"for month in range(1,13):\n    rv_arno_wrk.loc[lambda x: (x['Month']==month) & (x['Temperature_Firenze'].isnull()), 'Temperature_Firenze'] = rv_arno_tmp_mean.loc[month,'Temperature_Firenze']","0f690df9":"msno.matrix(rv_arno_wrk)","adb12bdd":"#Adding rainfall Sum, year, month, month_year\ndf = rv_arno_wrk[['Date','Rainfall_Mean','Hydrometry_Nave_di_Rosano', 'Temperature_Firenze']]#.reset_index()\n#df['rainfall'] = rv_arno.iloc[:, 0:-2].sum(axis = 1).values\ndf['year'] = pd.to_datetime(df.Date).dt.year\ndf['month'] = pd.to_datetime(df.Date).dt.month\ndf['month_year'] = pd.to_datetime(df.Date).apply(lambda x: x.strftime('%Y\/%m'))\n\n# Monthly dynamics\nr_means = np.log(df.groupby('month_year').Hydrometry_Nave_di_Rosano.mean() * 10).reset_index()\nr_means['month_year'] = pd.to_datetime(r_means['month_year'])\n\nr_rain = np.log(df.groupby('month_year').Rainfall_Mean.mean() *10).reset_index()\nr_rain['month_year'] = pd.to_datetime(r_rain['month_year'])\n\nr_temp = np.log(df.groupby('month_year').Temperature_Firenze.mean()).reset_index()\nr_temp['month_year'] = pd.to_datetime(r_temp['month_year'])\n\nfig, ax = plt.subplots(figsize = (15, 5))\nplt.title('Monthly dynamics (Arno River)', size = 15, fontweight = 'bold')\n          \nsns.lineplot(data = r_rain, x = 'month_year', y = 'Rainfall_Mean',  \n             color = 'gray', label = 'Rainfall', alpha = 0.4)\nplt.xticks(rotation = 45)\nsns.lineplot(data = r_temp, x = 'month_year', y = 'Temperature_Firenze', \n             color = 'green', label = 'Temperature_Firenze', alpha = 0.6)\nplt.xticks(rotation = 45)\nsns.lineplot(data = r_means, x = 'month_year', y = 'Hydrometry_Nave_di_Rosano', \n             color = 'blue', label = 'Hydrometry')\nplt.xticks(rotation = 45)\n    \nfor i in ['top', 'right', 'bottom', 'left']:\n        ax.spines[i].set_visible(False)\n\nax.set_xlabel('')\nax.set_ylabel('')\nax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\nplt.show()","36c62cd7":"rv_arno_wrk_model = rv_arno_wrk.set_index('Date')","cfd286e3":"corr_plot(rv_arno_wrk_model.drop(columns=['Year','Month']))","4a7dbd63":"y = rv_arno_wrk_model['Hydrometry_Nave_di_Rosano']\nX = rv_arno_wrk_model.drop(['Hydrometry_Nave_di_Rosano','Season','Month','Year'], axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, shuffle = False)\n\nparams = {'n_estimators': 100,\n          'max_depth': 4,\n          'subsample': 0.7,\n          'learning_rate': 0.04,\n          'random_state': 0}\n\nmodel = XGBRegressor(**params)\n\nmodel.fit(X_train, y_train,)\n\ny_pred = model.predict(X_test)\nprint('MAE value: %.4f'%mean_absolute_error(y_test, y_pred))","91367a69":"def model_imp_viz(model, train_data, bias = 0.01):\n    imp = pd.DataFrame({'importance': model.feature_importances_,\n                        'features': train_data.columns}).sort_values('importance', \n                                                                     ascending = False)\n    fig, ax = plt.subplots(figsize = (10, 4))\n    plt.title('Feature importances', size = 15, fontweight = 'bold')\n\n    sns.barplot(x = imp.importance, y = imp.features, edgecolor = 'black',\n                palette = reversed(sns.color_palette(\"viridis\", len(imp.features))))\n\n    for i in ['top', 'right']:\n            ax.spines[i].set_visible(None)\n\n    rects = ax.patches\n    labels = imp.importance\n    for rect, label in zip(rects, labels):\n        x_value = rect.get_width() + bias\n        y_value = rect.get_y() + rect.get_height() \/ 2\n\n        ax.text(x_value, y_value, round(label, 3), fontsize = 9, color = 'black',\n                 ha = 'center', va = 'center')\n    ax.set_xlabel('Importance', fontweight = 'bold')\n    ax.set_ylabel('Features', fontweight = 'bold')\n    plt.show()","1c07354f":"model_imp_viz(model, X_train)","7f097f37":"def predicted_viz(y_test, y_pred, param, name):\n    rm = y_test.reset_index()\n    rm['month_year'] = pd.to_datetime(rm.Date).apply(lambda x: x.strftime('%Y\/%m'))\n    rm_means = rm.groupby('month_year')[param].mean().reset_index()\n    rm_means['month_year'] = pd.to_datetime(rm_means['month_year'])\n\n    pm = pd.DataFrame({'Date': y_test.index, param: y_pred})\n    pm['month_year'] = pd.to_datetime(pm.Date).apply(lambda x: x.strftime('%Y\/%m'))\n    pm_means = pm.groupby('month_year')[param].mean().reset_index()\n    pm_means['month_year'] = pd.to_datetime(pm_means['month_year'])\n\n    fig, ax = plt.subplots(figsize = (15, 5))\n    plt.title('{} prediction ({})'.format(param, name), size = 15, \n              fontweight = 'bold')\n\n    sns.lineplot(data = rm_means, x = 'month_year', y = param, \n                 color = 'blue', label = 'Real {}'.format(param), alpha = 1)\n    sns.lineplot(data = pm_means, x = 'month_year', y = param, \n                 color = 'red', label = 'Pred {}'.format(param), alpha = 0.5)\n\n    for i in ['top', 'right', 'bottom', 'left']:\n            ax.spines[i].set_visible(False)\n\n    ax.set_xticks(rm_means.month_year[::12])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\n    plt.show()","db425faa":"predicted_viz(y_test, y_pred, 'Hydrometry_Nave_di_Rosano', 'Arno River')","cae3856d":"def resid_viz(y_test, y_pred):\n    resid = abs(y_test - y_pred)\n    fig, ax = plt.subplots(figsize = (10, 5))\n    plt.title('Residuals', size = 15, fontweight = 'bold')\n\n    sns.scatterplot(x = y_test, y = resid, color = 'red', \n                    edgecolor = 'black', alpha = 0.7)\n\n    for i in ['top', 'right']:\n            ax.spines[i].set_visible(False)\n\n    ax.set_xlabel('Real values', fontweight = 'bold')\n    ax.set_ylabel('Resiaduals', fontweight = 'bold')\n    plt.show()","bbeb616b":"resid_viz(y_test, y_pred)","711001eb":"Residual distribution is a powerful tool for assessing the quality of a model. The linear dependence, which is most pronounced for high hydrometry values, proves that our model does not consider all the dependencies. Perhaps if all predictors were used (this is not possible due to missing values), the model would do much better.","98513eda":"# Further steps","51bd47c1":"# Datasets overview","4e73b93a":"Let's now plot the Hydrometry Real vs Predicted.","8a18daf1":"Now, I'll plot the Monthly Dynamics again just to see how it looks after the Featuring Engineering.","2750e441":"Let's now plot the monthly dynamics. Scales will be tweaked to make it more visual (log and *10).\nNote how rainfall data is starting in around 2003-2004 and temperature data is until 2017.","4f41fda3":"Let's now dive into Temperature's missing values. There are 1082 missing values.","c0d18745":"From the plot below, we can see a high correlation between the temperature and the month (as we can intuitively expect). Based on this, I will replace all missing values in the temperatures with the mean of temperatures of that month, across all years. ","dae5549e":"# Inspiration\/Credits\/Sources\nhttps:\/\/www.kaggle.com\/tomwarrens\/intro-to-time-series-analysis \\\nhttps:\/\/www.kaggle.com\/marcomarchetti\/acea-smart-water-eda#7-Conclusions \\\nhttps:\/\/www.kaggle.com\/maksymshkliarevskyi\/acea-smart-water-eda-prediction\/execution \\\nhttps:\/\/www.kaggle.com\/iamleonie\/intro-to-time-series-forecasting \\\nhttps:\/\/www.kaggle.com\/lucena1990\/acea-smater-water-water-availability-data#Exploratory-Data-Analysis \\\nhttps:\/\/www.kaggle.com\/kevinnolasco\/random-forests-and-early-stopping-to-predict-water \\\nKirill Eremenko, Hadelin de Ponteves, Super Data Science","7538e478":"# Challenge overview\n\nThe Acea Group is one of the leading Italian multiutility operators. Listed on the Italian Stock Exchange since 1999, the company manages and develops water and electricity networks and environmental services. Acea is the foremost Italian operator in the water services sector supplying 9 million inhabitants in Lazio, Tuscany, Umbria, Molise, Campania.\n\nThis competition uses nine different datasets, completely independent and not linked to each other. Each dataset can represent a different kind of waterbody. As each waterbody is different from the other, the related features as well are different from each other. So, if for instance we consider a water spring we notice that its features are different from the lake\u2019s one. This is correct and reflects the behavior and characteristics of each waterbody. The Acea Group deals with four different type of waterbodies: water spring (for which three datasets are provided), lake (for which a dataset is provided), river (for which a dataset is provided) and aquifers (for which four datasets are provided).\n\nThe desired outcome of this challenge is a notebook that can generate four mathematical models, one for each category of waterbody (acquifers, water springs, river, lake) that might be applicable to each single waterbody.\n\n![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F6195295%2Fcca952eecc1e49c54317daf97ca2cca7%2FAcea-Input.png?generation=1606932492951317&alt=media)\n\nEach waterbody has its own different features to be predicted. The table below shows the expected feature to forecast for each waterbody.\n\n![](https:\/\/storage.cloud.google.com\/kaggle-media\/competitions\/Acea\/Screen%20Shot%202020-12-02%20at%2012.40.17%20PM.png)","000ec29f":"# Reading files","7d2eca5a":"Let's take a quick look at the features, missing values and types of variables.\nWe can see 9 predictors with over 44% of missing values.","badc0f84":"Let's now plot missing values from Missingno which allow us to see also the distribution of the missing values.\nWe can see that all Rainfalls started to be recorded at the same time, which was later than Temperature and Hydrometry.\nWe can also see that Temperature was not recorded until last day.","f72caaf5":"Now plotting the yearly dynamics","6acb36a2":"The Mean Absolute Error of the predicted values is 0.3607, meaning that on average the model have an error of 36cm.","d70282ac":"Below table is just to show all the datasets, waterbody types, rows, and columns of the tables. As stated before, I'll only focus on **River Arno**.","2de16bc3":"From this plot we can see that Rainfalls varies considerably through seasons.","392b72b3":"## EDA","a8d64989":"## Feature Engineering","6c7581b8":"Let's now plot the daily dynamics for a glimpse","bb15c8ab":"Let's now plot the Correlations matrix again to see how it looks.","a390ad77":"# Model prediction","64c97b60":"I decided to drop all values before 2004 because of the quantity of missing values (might not be the best approach but I prefer this one rather than replace NaNs in each rainfall before 2003 with data from after 2004).\\\nI will also replace few missing values in Hydrometry with ffill since they are only three and not consecutive. Also the type of variable suggest me that extending the measure for one more day might be better than using some average. Quantity of records impacted: 3.\\\nI found 187 rows with Hydrometry = 0 which sounds like a data collection issue for me. I will also replace this values with the ffill method.","25756f96":"Due to high number of missing values in values (over 44%), I will drop the following 9 Rainfalls: 'Rainfall_Vernio','Rainfall_Stia', 'Rainfall_Consuma', 'Rainfall_Incisa', 'Rainfall_Montevarchi', 'Rainfall_S_Savino', 'Rainfall_Laterina', 'Rainfall_Bibbiena', 'Rainfall_Camaldoli'.\n\nDo not forget that these Rainfalls have a higher correlation that the ones that will remain.\n\nI will now group create Seasonal columns particularly to group each of the rainfalls and try to fill the missing values with the mean within the season. I believe this approach is better than the mean of the year. The same approach can be used for the temperature. \nMoreover, a column Rainfall_Mean.","049cf5c9":"Let's now plot the correlations matrix.\nWe can see high negative correlation in Hydrometry with Temperature, meaning the higher the temperature, the lower the target.\nWe can also see a set of rainfalls with lower correlation than others. Coincidentally, the ones with higher correlation are the ones with higher quantity of missing values. This may lead into problems afterwards.","54246918":"# Important note\nThis notebook will only cover **River Arno**, leaving the other 8 waterbodies (datasets) out of scope.","8acd4925":"Let's check if we still have to work some feature.","9b2e13b7":"# Defining functions","300e16ee":"# River Arno Analysis","0073fcb7":"* Try differnt algorithms,\n* Analyze the remainig 8 waterbodies,\n* Try new parameters for XGB,\n* Improve data selection and preprocessing.","fb60f036":"I will split the data on 70% for training and 30% for testing and apply XGB because it's powerful and popular but other models could also be applied.\nSince I'm applying XGB, I'm not normalizing the data (not required). Parameters chosen after some experimentation","36433434":"I will now plot the Feature Importances. Where we can see that Temperature is the most important."}}