{"cell_type":{"ededf89c":"code","f84fdd22":"code","aa167750":"code","d8b4919f":"code","b7d9d19a":"code","e718f1a6":"code","3d7af517":"code","bc98ce29":"code","e13a285e":"code","a3f4880c":"code","4bbf77a8":"code","c160b173":"code","b7d2434f":"code","978ccc8d":"code","280b10d2":"code","da8e31bf":"code","77078b18":"code","3e60d2ae":"code","6ab1e591":"code","1e11e7b8":"code","335b7ded":"code","181fd62c":"code","7e6b4982":"markdown","4516966d":"markdown","2cc97476":"markdown","83b25348":"markdown","f19acef6":"markdown"},"source":{"ededf89c":"import numpy as np \nimport pandas as pd \nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(2019)\n\nmain_dir = '..\/input\/digit-recognizer\/'\nos.listdir(main_dir)\n","f84fdd22":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras\nimport keras.layers as klayers\nimport tensorflow as tf\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score","aa167750":"#Some hyper-parameters\n\nembedding_dims = 32\nbatch_size = 128\nepochs = 30","d8b4919f":"\ntrain_df = pd.read_csv(main_dir + 'train.csv')\ntest_df = pd.read_csv(main_dir + 'test.csv')\n\nprint(\"Shape of train dataframe : \", train_df.shape)\nprint(\"Shape of test dataframe : \", test_df.shape)\n\n#Check the data\ntrain_df.head(5)","b7d9d19a":"train_label = train_df['label']\ntrain_df = train_df.drop(['label'], axis = 1)","e718f1a6":"#Check some images in training dataset\nimgs = np.asarray( train_df.iloc[:10], dtype = np.uint8)\nlabels = np.asarray( train_label.iloc[:10], dtype = int)\nncols = 5\nnrows = 2\n\nplt.suptitle(\"Digits in training dataset\")\nplt.figure(figsize = (12,8))\nfor i,(img,label) in enumerate(zip(imgs,labels)):\n    plt.subplot(nrows, ncols, i+1)\n    plt.imshow(img.reshape(28,28), cmap = 'binary')\n    plt.title(\"label : \" + str(label))\n    plt.axis(\"off\")\nplt.show()","3d7af517":"#Split the training and validation dataset\n\ntrain_x, valid_x, train_y, valid_y = train_test_split(train_df, train_label, test_size = 0.25, random_state = 2019)\nprint(\"train_x shape : \", train_x.shape)\nprint(\"train_y shape : \", train_y.shape)\nprint(\"valid_x shape : \", valid_x.shape)\nprint(\"valid_y shape : \", valid_y.shape)","bc98ce29":"train_x = np.asarray(train_x).reshape(-1,28,28,1)\nvalid_x = np.asarray(valid_x).reshape(-1,28,28,1)\ntrain_y = np.asarray(train_y)\nvalid_y = np.asarray(valid_y)\nnum_classes = len(np.unique(train_y))\n\nprint(\"train_x shape : \", train_x.shape)\nprint(\"valid_x shape : \", valid_x.shape)","e13a285e":"def input_generator(x,y,batch_size):\n    \n    out_imgs = []\n    out_labels = []\n    \n    data_len = len(x)\n    \n    while True:\n        \n        idx = np.random.choice(range(data_len))\n        out_imgs.append(x[idx])\n        out_labels.append(y[idx])\n        \n        if len(out_imgs) >= batch_size:\n            yield np.stack(out_imgs), np.stack(out_labels)\n            out_imgs = []\n            out_labels = []\n            \ndef augmentation_generator(input_gen, data_gen, batch_size, embedding_dims):\n    \n    \n    dummy_y = np.zeros((batch_size, embedding_dims + 1))\n    for data, label in input_gen:    \n        x = data_gen.flow(data, batch_size = batch_size, shuffle = False)\n        \n        yield [next(x),label], dummy_y","a3f4880c":"train_data_generator = ImageDataGenerator(\n                                    rescale = 1.0 \/ 255.0,\n                                    rotation_range = 40,\n                                    width_shift_range = 0.15,\n                                    height_shift_range = 0.15,\n                                    shear_range = 0.1,\n                                    zoom_range = 0.1,\n                                    )\nvalid_data_generator = ImageDataGenerator(rescale = 1.0\/255.0)\ntrain_input_gen = input_generator(train_x,train_y,batch_size)\nvalid_input_gen = input_generator(valid_x,valid_y,batch_size)\n\ntrain_aug = augmentation_generator(train_input_gen, train_data_generator, batch_size, embedding_dims)\nvalid_aug = augmentation_generator(valid_input_gen, valid_data_generator, batch_size, embedding_dims)","4bbf77a8":"#Check the images after augmentation\n\n(imgs, labels),dummy = next(train_aug)\nncols = 5\nnrows = 2\n\nplt.suptitle(\"Digits in training dataset\")\nplt.figure(figsize = (12,8))\nfor i,(img,label) in enumerate(zip(imgs,labels)):\n    if i > 9 :\n        break\n    plt.subplot(nrows, ncols, i+1)\n    plt.imshow(img.reshape(28,28), cmap = 'binary')\n    plt.title(\"label : \" + str(label))\n    plt.axis(\"off\")\nplt.show()","c160b173":"def _cn_bn_relu(filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"same\"):\n    \n    def f(input_x):\n        \n        x = input_x\n        x = klayers.Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding,\n                          kernel_initializer = \"he_normal\")(x)\n        x = klayers.BatchNormalization()(x)\n        x = klayers.Activation(\"relu\")(x)\n        \n        return x\n    return f\n\ndef _dn_bn_relu(units = 256):\n    def f(input_x):\n        \n        x = input_x\n        x = klayers.Dense(units = units)(x)\n        x = klayers.BatchNormalization()(x)\n        x = klayers.Activation(\"relu\")(x)\n        \n        return x\n    return f\n    \ndef build_model(image_input, embedding_dims):\n    \n    x = _cn_bn_relu(filters = 64, kernel_size = (3,3))(image_input)\n    x = klayers.MaxPooling2D(pool_size = (2,2))(x)\n    x = _cn_bn_relu(filters = 64, kernel_size = (3,3))(x)\n    x = klayers.MaxPooling2D(pool_size = (2,2))(x)\n    x = klayers.Dropout(0.35)(x)\n    x = klayers.Flatten()(x)\n    x = _dn_bn_relu(units = 256)(x)\n    x = _dn_bn_relu(units = 128)(x)\n    x = klayers.Dropout(0.25)(x)\n    x = _dn_bn_relu(units = 64)(x)\n    x = klayers.Dense(units = embedding_dims, name = \"embedding_layer\")(x)\n    \n    return x\n\nimage_input = klayers.Input(shape = train_x.shape[1:], name = \"image_input\")\nlabel_input = klayers.Input(shape = (1,), name = \"label_input\")\n\nbase_model = build_model(image_input, embedding_dims)\noutput = klayers.concatenate([label_input, base_model])\n\nmodel = keras.models.Model(inputs = [image_input, label_input], outputs = [output])\nmodel.summary()","b7d2434f":"def triplet_loss(y_true, y_pred, margin = 1.2):\n    \n    del y_true\n    \n    labels = y_pred[:,:1]\n    labels = tf.dtypes.cast(labels, tf.int32)\n    labels = tf.reshape(labels, (tf.shape(labels)[0],))\n    \n    embeddings = y_pred[:,1:]\n    return tf.contrib.losses.metric_learning.triplet_semihard_loss(labels = labels,\n                                                                 embeddings = embeddings,\n                                                                 margin = margin)","978ccc8d":"optimizer = keras.optimizers.Adam(lr = 1e-3, decay = 1e-6)\nmodel.compile(optimizer = optimizer, loss = triplet_loss)\n\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 3, factor = 0.5, mode = 'min', verbose = 1, min_lr = 1e-6)\nes = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min')\n\nsteps_per_epoch = len(train_x) \/\/ batch_size\nvalidation_steps = len(valid_x) \/\/ batch_size","280b10d2":"history = model.fit_generator(train_aug, steps_per_epoch = steps_per_epoch,\n                              epochs = epochs, verbose = 1,\n                              validation_data = valid_aug, validation_steps = validation_steps,\n                              shuffle = True, callbacks = [reduce_lr,es])","da8e31bf":"plt.figure(figsize = (12,8))\nplt.plot(history.history['loss'], '-', label = 'train_loss', color = 'g')\nplt.plot(history.history['val_loss'], '-', label = 'valid_loss', color = 'r')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.title('triple loss of embedding model')\nplt.legend()\nplt.show()","77078b18":"#Check the layers\nmodel.layers","3e60d2ae":"#Transfer the weights from original model to embedding model\n\nimage_input = klayers.Input(shape = train_x.shape[1:])\nembedding_output = build_model(image_input, embedding_dims = embedding_dims)\nembedding_model = keras.models.Model(inputs = [image_input], outputs = [embedding_output])\n\nfor idx in range(1,18):\n    target_layer = embedding_model.layers[idx]\n    source_layer = model.layers[idx]\n    target_layer.set_weights(source_layer.get_weights())\n    \nembedding_model.layers[-1].set_weights(model.layers[-2].get_weights())\n\nembedding_model.summary()","6ab1e591":"#Use PCA to check the effect of embedding model\n\ndef plot_2d_distribution(embedding_data, num_classes, y, steps = 10, title = \"\"):\n    pca = PCA(n_components = 2)\n    decomposed_data = pca.fit_transform(embedding_data)\n    plt.figure(figsize = (8,8))\n    for label in range(num_classes):\n        \n        decomposed_class = decomposed_data[label == y]\n        plt.scatter(decomposed_class[::steps, 1], decomposed_class[::steps,0], label = str(label))\n    plt.legend()\n    plt.title(title)\n    plt.show()\n    \n\ntrain_x_embeddings = embedding_model.predict(train_x\/255.0)\nvalid_x_embeddings = embedding_model.predict(valid_x\/255.0)\n\nplot_2d_distribution(train_x_embeddings, num_classes, train_y, title = 'training embeddings distribution in 2 dimensions')\nplot_2d_distribution(valid_x_embeddings, num_classes, valid_y, title = 'validation embeddings distribution in 2 dimensions')","1e11e7b8":"#Use SVC to predict the final label of embedding data\n\nsvc = SVC()\nsvc.fit(train_x_embeddings, train_y)\nvalid_prediction = svc.predict(valid_x_embeddings)\nprint(\"validation accuracy : \", accuracy_score(valid_y, valid_prediction))","335b7ded":"test_x = np.asarray(test_df.values)\ntest_x = test_x.reshape(-1,28,28,1) \/ 255.0\n\ntest_embeddings = embedding_model.predict([test_x])\ntest_prediction = svc.predict(test_embeddings)","181fd62c":"submission = pd.read_csv(main_dir + 'sample_submission.csv')\nsubmission['Label'] = test_prediction\n\nsubmission.to_csv('v3.csv', index = False)\nsubmission.head(10)","7e6b4982":"## data generator for training and validation","4516966d":"# Data prepare","2cc97476":"# Build the model","83b25348":"## Define triplet loss function","f19acef6":"# Training embedding model"}}