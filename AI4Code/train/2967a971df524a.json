{"cell_type":{"53420e38":"code","1d818f23":"code","06da7644":"code","e02f4794":"code","25de65e9":"code","dcffc351":"code","295edeab":"code","9b513810":"code","75b11902":"code","1b7b1b2d":"code","f49490e2":"markdown","a815ec8c":"markdown","fabcbc54":"markdown","3568e946":"markdown","2a6f95c6":"markdown","78a5935e":"markdown","d8203027":"markdown","b958263b":"markdown","13146dcd":"markdown","ecd17221":"markdown","82747a8b":"markdown"},"source":{"53420e38":"import gc\nimport cv2\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport tensorflow as tf\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import class_weight\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom sklearn.metrics import confusion_matrix,precision_score,recall_score\n\nsns.set(font_scale=1.4)\n#base image path in kaggle env\nBASE_IMAGE_PATH = Path('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/')\n#Reshape input images to 200x200, free to be changed\nIMG_SIZE=200","1d818f23":"#returns image path of a set of data, train, test and val\ndef get_imgs_path(cat):\n    PATH = BASE_IMAGE_PATH \/ cat\n    normal_path = PATH \/ 'NORMAL'\n    pneumonia_path = PATH \/ 'PNEUMONIA'\n    normal_imgs_path = normal_path.glob('*.jpeg')\n    pneumonia_imgs_path = pneumonia_path.glob('*.jpeg')\n    normal_imgs = [path for path in normal_imgs_path]\n    pneumonia_imgs = [path for path in pneumonia_imgs_path]\n    print('\\n{} normal images in {} directory'.format(len(normal_imgs),cat))\n    print('{} pneumonia images in {} directory\\n'.format(len(pneumonia_imgs),cat))\n    return normal_imgs,pneumonia_imgs\n\n#return images and labels from given path\ndef get_images(normal_imgs,pneumonia_imgs):\n    normal_images=[]\n    normal_labels=[]\n    for image_path in normal_imgs:\n        img = cv2.imread(str(image_path))\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        if img.shape[2]==1:\n            img = np.dstack([img, img, img])\n        else:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img\/255.0\n        img  = img.astype(np.float32)\n        normal_images.append(img)\n        normal_labels.append(0)\n\n    for image_path in pneumonia_imgs:\n        img = cv2.imread(str(image_path))\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        if img.shape[2]==1:\n            img = np.dstack([img, img, img])\n        else:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img\/255.0\n        img  = img.astype(np.float32)\n        normal_images.append(img)\n        normal_labels.append(1)\n    return np.array(normal_images),np.array(normal_labels)\n\n#Function for garbage collection\ndef clean(x):\n    x=0\n    gs.collect()","06da7644":"#Ready all 3 sets of data\nnormal_train_path,pneumonia_train_path = get_imgs_path('train')\ntrain_images,train_labels=get_images(normal_train_path,pneumonia_train_path)\nprint(\"Shape of train_images is {}\".format(train_images.shape))\nprint(\"Shape of train_labels is {}\".format(train_labels.shape))\n\nnormal_val_path,pneumonia_val_path = get_imgs_path('val')\nval_images,val_labels=get_images(normal_val_path,pneumonia_val_path)\nprint(\"Shape of val_images is {}\".format(val_images.shape))\nprint(\"Shape of val_labels is {}\".format(val_labels.shape))\n\n\nnormal_test_path,pneumonia_test_path = get_imgs_path('test')\ntest_images,test_labels=get_images(normal_test_path,pneumonia_test_path)\nprint(\"Shape of test_images is {}\".format(test_images.shape))\nprint(\"Shape of test_labels is {}\".format(test_labels.shape))","e02f4794":"f = plt.figure(figsize=(20,20))\nfor i in range(1,17):\n    ax = f.add_subplot(4,4,i)\n    if i>=9:\n        i += 1341\n        ax.set_title('Pneumonia')\n    else:\n        ax.set_title('Normal')\n    plt.imshow(train_images[i,:,:,:])\n    ax.axis('off')","25de65e9":"#define focal loss function which works best for imbalanced classification\n#Refer to original paper here https:\/\/arxiv.org\/pdf\/1708.02002.pdf\nfrom keras import backend as K\ndef focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","dcffc351":"#opt = tf.keras.optimizers.Adadelta(lr=0.0001)\n#es = EarlyStopping(patience=5)\n#ckpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)","295edeab":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=16,activation='relu',kernel_size=(3,3),padding='same',input_shape=(IMG_SIZE,IMG_SIZE,3)),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n\n    tf.keras.layers.Conv2D(filters=32,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n\n    tf.keras.layers.Conv2D(filters=64,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    \n    tf.keras.layers.Conv2D(filters=128,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n\n    tf.keras.layers.Conv2D(filters=256,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256,activation='relu'),\n    tf.keras.layers.Dropout(0.6),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.compile(loss=focal_loss(),optimizer='adadelta',metrics=['accuracy'])","9b513810":"class_weights = class_weight.compute_class_weight('balanced',np.unique(train_labels),train_labels)\nclass_weights = dict(enumerate(class_weights))\nhistory1 =  model.fit(train_images, train_labels.astype(np.float32), batch_size=16, epochs=50,\n                      validation_data=(val_images,val_labels.astype(np.float32)),class_weight=class_weights, \n                      verbose=1)","75b11902":"# plot the model loss and accuracy\ntrain_loss = history1.history['loss']\ntrain_acc = history1.history['accuracy']\n\nvalid_loss = history1.history['val_loss']\nvalid_acc = history1.history['val_accuracy']\n\nx = [(i+1) for i in range(len(train_loss))]\n\nf,ax = plt.subplots(1,2, figsize=(12,5))\nax[0].plot(x, train_loss)\nax[0].plot(x, valid_loss)\nax[0].set_title(\"Loss plot\")\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"loss\")\nax[0].legend(['train', 'valid'])\n\n\nax[1].plot(x, train_acc)\nax[1].plot(x, valid_acc)\nax[1].set_title(\"Accuracy plot\")\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"acc\")\nax[1].legend(['train', 'valid'])\n\nplt.show()","1b7b1b2d":"pred = np.round(model.predict(test_images,steps=test_steps))\nprint(\"Precision:{:.4f}\\nRecall score:{:.4f}\\n\".format(precision_score(test_labels,pred),recall_score(test_labels,pred)))\nprint(\"Confusion Matrix:\\n\",sns.heatmap(confusion_matrix(test_labels,pred), annot=True, annot_kws={\"size\": 16}, cmap='YlGnBu', fmt='d'))","f49490e2":"# Acknowledgement\nFind the dataset here https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia\n## Dataset Content\nThe dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia\/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia\/Normal).\n\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\u2019s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients\u2019 routine clinical care.\n\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n\nDataset has more pneumonia images than normal imgaes and therefore focus must be on precision","a815ec8c":"# Helper functions","fabcbc54":"### Classifying these images would be a difficult task because even I can't tell the difference in some cases!!! Let's see how our model performs.","3568e946":"## That's quite good performance, fork and make this even better!","2a6f95c6":"# Define CNN model","78a5935e":"# Train and Evaluate","d8203027":"### Training data is imbalanced with almost 3 times more images for pneumonia, it can be tackled by\n* Define class_weights for both classes(implemented below)\n![](https:\/\/ibb.co\/p28tKGQ)\n* Undersample or Oversample\n![](https:\/\/www.researchgate.net\/profile\/Peter_Andrews\/publication\/47349648\/figure\/fig1\/AS:601708375834630@1520469864800\/Demonstration-of-the-over-sample-and-under-sample-method-for-covariate-adjustment.png)\n* Use ensemble techniques\n![](https:\/\/miro.medium.com\/max\/3064\/0*XJx4UK_LVNTx0aaI.)","b958263b":"# Plotting images","13146dcd":"# Importing packages","ecd17221":"![](https:\/\/www.researchgate.net\/profile\/Takio_Kurita\/publication\/320748406\/figure\/download\/fig1\/AS:555719381274624@1509505233044\/An-example-of-CNN-architecture.png)\n### The architecture will be simple because after trying more complex architectures results are more biased towards classifying image as pneumonia.\n* Conv(16)\n* MaxPool()\n* Conv(32)\n* MaxPool()\n* Conv(64)\n* MaxPool()\n* Conv(128)\n* MaxPool()\n* Conv(256)\n* MaxPool()\n* Dense(256)\n* Dropout(0.6)\n* Dense(1)","82747a8b":"# Preprocess data"}}