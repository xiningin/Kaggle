{"cell_type":{"45b266b1":"code","21f3941d":"code","6a86b4a6":"code","2e5689d7":"code","37c5008f":"code","eb00352e":"code","6a9041ed":"code","c6fd7f08":"code","453b2c2c":"code","b3525204":"code","9a8067c8":"code","3d34272f":"code","40d6951d":"code","b92d5d18":"code","d1e762c5":"code","ef1ff0e2":"code","38633b19":"code","1be97bc3":"code","4faf96b8":"code","d689da8e":"code","f9f108ac":"code","bf2e14f4":"code","9834e386":"code","bb58ee3d":"markdown","7a723249":"markdown","e5fe6518":"markdown","8606c1f5":"markdown","68eaf3f4":"markdown","108c2027":"markdown","495c1a3a":"markdown","eb249650":"markdown","b5d26f13":"markdown","9c4b271a":"markdown","b3a4050f":"markdown","fa51b093":"markdown","34745d2e":"markdown","83783a66":"markdown","cc9988bb":"markdown","0919e765":"markdown","d8ea994a":"markdown","bc6c255a":"markdown","92d08679":"markdown","504e9154":"markdown","c229f91d":"markdown","a0024ba0":"markdown","33a5f2f2":"markdown"},"source":{"45b266b1":"# Install\n!pip install prince -q","21f3941d":"#Setup\nimport pandas as pd\nimport numpy as np\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\n\nimport itertools\nimport re\nimport unidecode\nimport math\nfrom IPython.display import display\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom prince import MFA\n\npd.set_option('max_columns', None)\npd.set_option('max_rows', None)\npd.set_option('display.max_colwidth', None)","6a86b4a6":"# General functions\ndef select_columns(dataset, app_dict_cols, to_dummy=True):\n    \n    questions = app_dict_cols.keys()\n    \n    multiple_choice = {k: v for k, v in app_dict_cols.items() if all_questions_dict[k]['type'] == 'multiple'}\n    unique_choice = {k: v for k, v in app_dict_cols.items() if all_questions_dict[k]['type'] == 'unique'}\n    \n    # Multiple choice questions\n    cols_per_question = {name: list(all_questions_dict[question]['columns'].keys()) for question, name in multiple_choice.items()}\n    question_names = {item: name for name, sublist in cols_per_question.items() for item in sublist}\n\n    names_per_question = [all_questions_dict[a]['columns'] for a in multiple_choice.keys()]\n    question_options = {}\n    for option_dict in names_per_question:\n        question_options.update(option_dict)\n\n    renamer = {}\n    for k, v in question_names.items():\n        new_name = v\n        if k in question_options and question_options[k]:\n            new_name += '__' + question_options[k].lower().strip().title().replace(' ', '').split('(')[0]\n        renamer[k] = new_name\n\n    multiple_df = dataset.loc[:, renamer.keys()].rename(columns=renamer)\n    multiple_df.index = dataset.index\n    for c in multiple_df.columns.tolist():\n        multiple_df.loc[:, c] = (~multiple_df[c].isnull()).astype(int)\n        \n    \n    # Single choice questions\n    \n    df = dataset.loc[:,unique_choice.keys()].rename(columns=unique_choice)\n    \n    for c in df.columns.tolist():\n        df.loc[:, c] = df[c].str.split('(', expand=True).iloc[:, 0].str.lower().str.strip().str.title().str.replace(' ', '')\n    single_df = pd.get_dummies(df, prefix_sep='__')\n    single_df.index = survey_df.index\n    \n    final_df = pd.concat([multiple_df, single_df], axis=1)\n        \n    return final_df\n\n\ndef complete_nones(original_df):\n    # To users who didn't signup all questions, lead them to None option\n    # for any of the questions in this subset, didn't signaled any of the options\n\n    cols_map = {}\n    for c in original_df.columns.tolist():\n        dim = c.split('__')[0]\n        if dim in cols_map:\n            cols_map[dim].append(c)\n        else:\n            cols_map[dim] = [c]\n\n    new_df = original_df.copy()\n\n    skippers_index = []\n    for dim, cols in cols_map.items():\n        df = original_df.loc[:, cols].sum(axis=1).to_frame()\n        df.loc[:, 'empty'] = (df.iloc[:,0] == 0)    \n        none_indexes = df.loc[df['empty']].index.tolist()\n\n        none_col =  dim + '__None'\n        if none_col in new_df.columns.tolist():\n            new_df.loc[new_df.index.isin(none_indexes), none_col] = 1\n\n    return new_df\n\n\ndef test_cluster_size(dataset, to_print=False):\n    inertias = {}\n    for k in range(1, 25):\n        if to_print:\n            if k % 5 == 0:\n                print(k)\n        model = KMeans(n_clusters=k, random_state=42)\n        model.fit(dataset)\n        inertias[k] = model.inertia_\n\n    inertia_df = pd.DataFrame.from_dict(inertias, orient='index').reset_index()\n    inertia_df.columns = ['cluster_size', 'inertia']\n    \n    return inertia_df\n    \n    \ndef mfa_method(n_components, dataset, groups):\n    mfa = MFA(groups = groups, n_components = n_components, n_iter = 5, random_state = 42)\n    return mfa.fit_transform(dataset)\n    \n\ndef str_normalize(x):\n    return unidecode.unidecode(x).lower().replace(' ', '_').split(',')[0].strip()","2e5689d7":"# Data Load and Prep\n\n## Survey Info\n\n### Load raw data and dump it without question names\nsurvey_raw_df = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\nsurvey_raw_df.iloc[1:, 1:].to_csv('\/kaggle\/working\/kaggle_survey_2020_responses_no_header.csv', index=False)\n\n### Load data with question reference\nsurvey_df = pd.read_csv('\/kaggle\/working\/kaggle_survey_2020_responses_no_header.csv')\n\n### Generate dataframe with main informations of each question\nquestions_dict = {k:v[0] for k, v in survey_raw_df.head(1).to_dict().items()}\n\nselect_choice = []\nfor k, v in questions_dict.items():\n    if 'Part' in k or 'OTHER' in k:\n        select_choice.append(k)\n\n#### Questions with multiple choices\nselect_choice_dict = {}\nfor k in select_choice:\n    if '_Part' in k:     \n        question_key = k.split('_Part')[0]\n    elif '_OTHER' in k:     \n        question_key = k.split('_OTHER')[0]\n    question = questions_dict[k].split(' - ')[0]\n    value = questions_dict[k].split(' - ')[-1]\n    if question_key in select_choice_dict:\n        select_choice_dict[question_key]['columns'][k] = value\n    else:\n        select_choice_dict[question_key] = {'question':question, 'columns':{k:value}, 'type':'multiple'}\n\n#### Questions with only one choice\nmultiple_choice_dict={}\nmultiple_choice = [a for a in questions_dict.keys() if a not in select_choice][1:]\nfor k in multiple_choice:\n    multiple_choice_dict[k] = {'question':questions_dict[k], 'columns':{k:survey_df[k].unique().tolist()}, 'type':'unique'}\n    \n\nall_questions_dict = multiple_choice_dict.copy()\nall_questions_dict.update(select_choice_dict)\n\nall_questions_df = pd.DataFrame.from_dict(all_questions_dict, orient='index').reset_index()\nall_questions_df.loc[:, 'order'] = all_questions_df['index'].apply(lambda x: int(str(x).split('_')[0][1:]))\nall_questions_df.sort_values(by='order', inplace=True)\n\n## Identity Info\nidentity_questions = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5']\n\nidentity_raw_df = survey_df.loc[:, identity_questions]\nidentity_raw_df.columns = ['age', 'gender', 'country', 'schooling', 'profession']\n\nidentity_raw_df.loc[:, 'country_key'] = identity_raw_df['country'].apply(lambda x: str_normalize(x))\n\ncountry_rematch = {'IR': 'Iran', 'TW': 'Taiwan', 'KR':'South Korea', 'KP':'Republic of Korea', 'RU': 'Russia'}\n\ncountries_infos = pd.read_csv('\/kaggle\/input\/countries-infos\/countries_info.csv')\n\ncountries_infos.loc[:, 'name_adj'] = countries_infos.apply(lambda x: country_rematch[x['alpha-2']] if x['alpha-2'] in country_rematch else x['name'], axis=1)\n\ncountries_infos.loc[:, 'country_key'] = countries_infos['name_adj'].apply(lambda x: str_normalize(x))\n\nidentity_df = pd.merge(left=identity_raw_df, \n                       right=countries_infos.loc[:, ['region', 'sub-region', 'country_key']],\n                       on='country_key',\n                       how='left'\n                      )\n\nall_ages = identity_df['age'].sort_values().unique().tolist()\nall_ages_dict = {all_ages[i]:i for i in range(0, len(all_ages))}\n\nidentity_df.loc[:, 'age_adj'] = identity_df['age'].apply(lambda x: all_ages_dict[x])\n\n\n## Apparatus Info\n\napp_dict_cols = {\n 'Q7': 'lang',\n 'Q9': 'ide',\n 'Q10': 'notebook',\n 'Q11': 'platform',\n 'Q12': 'hardware',\n 'Q14': 'viz',\n 'Q36': 'deploy'\n}\n\n### Get dataset ready to clustering\napparatus_raw_df = select_columns(survey_df, app_dict_cols)\n\n### To users who didn't answer a question, attribute them to None option of question    \napparatus_df = complete_nones(apparatus_raw_df)\n\n### \napp_groups = {}\nfor c in apparatus_df.columns.tolist():\n    group = c.split('__')[0] \n    if group in app_groups:\n        app_groups[group].append(c)\n    else:\n         app_groups[group] = [c]","37c5008f":"# Clustering\n\n# ## Finding cluster size, with different component sizes\n# size = apparatus_df.shape[1]\n# pace = math.floor(size\/5)\n# inertias = []\n# for s in range(pace, size, pace):\n#     if s <= size:\n#         dataset = mfa_method(s, apparatus_df, app_groups)\n# #         print('{} colunas - {:.0f}%'.format(s, 100*s\/size))\n#         df = test_cluster_size(dataset)\n#         df.loc[:, 'num_cols'] = s\n#         inertias.append(df)\n        \n# inertia_df = pd.concat(inertias, axis=0)\n\n# fig = px.line(inertia_df, x='cluster_size', y='inertia', facet_col='num_cols')\n# fig.update_yaxes(matches=None)\n# fig.show()\n\n## Given results, choose cluster size = 9\ndataset = mfa_method(14, apparatus_df, app_groups)\nmodel = KMeans(n_clusters=9, random_state=42)\nmodel.fit(dataset)\n\nlabels = model.labels_\n\n\n## Create dataframe with cluster features information\ncluster_df = apparatus_df.copy()\n\ncols = cluster_df.columns.tolist()\nop_dict = {c:['mean', 'median'] for c in cols}\n\ncluster_df.loc[:, 'cluster_num'] = labels\ncluster_df.loc[:, 'counter'] = 1\n\nop_dict['counter'] = 'sum'\n\ngrouped = cluster_df.groupby('cluster_num').agg(op_dict)\ngrouped.columns = ['{}={}'.format(c[0], c[1]) for c in grouped.columns.tolist()]\nmelt = pd.melt(grouped.reset_index(), id_vars=['cluster_num'], value_vars=grouped.columns.tolist())\nmelt.loc[:, 'var_type'] = melt['variable'].str.split('=', expand=True).iloc[:, 1]\nmelt.loc[:, 'var'] = melt['variable'].str.split('=', expand=True).iloc[:, 0]\nmelt.loc[:, 'dim'] = melt['var'].str.split('__', expand=True).iloc[:, 0]\nmelt.loc[:, 'dim_value'] = melt['var'].str.split('__', expand=True).iloc[:, 1]\n\ncluster_infos = melt.loc[melt['var_type'] == 'mean'].drop(columns=['variable'])\ncluster_infos.loc[:, 'rank'] = cluster_infos.groupby(['var'])['value'].rank(ascending=False)\ncluster_infos.loc[:, 'rank_var'] = cluster_infos.groupby(['cluster_num', 'dim'])['value'].rank(ascending=False)\ncluster_infos.head()\n\n## Cluster main informations undestanding, to define names\nclusters = cluster_infos['cluster_num'].unique().tolist()\n\nall_clusters_summary = []\nall_clusters_detail = []\n\nfor c in clusters:\n    df = cluster_infos.loc[cluster_infos['cluster_num'] == c].sort_values(by='value', ascending=False)\n    df.loc[:, 'rank_presence'] = df['value'].rank(ascending=False)\n    top = df.loc[(((df['rank_presence'] <= 5) | (df['rank'] == 1)) & (df['value'] >= 0.1)) | (df['rank_var'] == 1)]\n    \n    group = top.groupby(['dim'])['dim_value'].agg(lambda x: list(x)).to_frame().sort_index()\n    \n    group.columns = [c]\n    all_clusters_summary.append(group)\n    all_clusters_detail.append(top)\n    \nall_clusters_df = pd.concat(all_clusters_summary, axis=1).sort_index()\n# all_clusters_df.head(7)\n\n## Find conditions to define name, despite order\ncluster_map = {}\nfor cluster, infos in all_clusters_df.to_dict().items():\n    if 'R' in infos['lang']:\n        cluster_map[cluster] = 'pirate'\n    elif 'ADeepLearningWorkstation' in infos['platform']:\n        cluster_map[cluster] = 'brainy'\n    elif 'ACloudComputingPlatform' in infos['platform']:\n        cluster_map[cluster] = 'cloudy'\n    elif 'Matlab' in infos['lang']:\n        cluster_map[cluster] = 'mathy'        \n    elif 'Bash' in infos['lang']:\n        cluster_map[cluster] = 'root'     \n    elif 'Tpus' in infos['hardware']:\n        cluster_map[cluster] = 'pro'\n    elif 'None' in infos['lang']:\n        cluster_map[cluster] = 'fresh'\n    elif 'Notepad++' in infos['ide']:\n        cluster_map[cluster] = 'dev'  \n    else:\n        cluster_map[cluster] = 'core'\n\n\n## Aggregate information back to users\ncluster_df.loc[:, 'cluster'] = cluster_df['cluster_num'].apply(lambda x: cluster_map[x])\n\n## Bring other information to generate insights and remove users with no complete answers of identity questions\nother_info = survey_df.loc[:, ['Q6', 'Q20', 'Q21', 'Q24']]\nother_info.columns = ['experience', 'company_size', 'team_size', 'salary']\n\nidentity_info = identity_df.loc[:, ['age', 'age_adj', 'gender', 'country', 'schooling', 'profession', 'region', 'sub-region']]\n\nall_cluster_infos = pd.concat([identity_info, other_info, cluster_df], axis=1)\nall_cluster_infos.index.name='user_id'\n\nall_cluster_infos['has_empy_answer'] = all_cluster_infos.apply(lambda x: np.nan in [x['experience'], x['schooling'], x['profession']], axis=1)\n\ncluster_infos = all_cluster_infos.loc[~all_cluster_infos['has_empy_answer']].copy()\n\n## Create dict to define order of some categories\nexperience_dict = {'I have never written code':0, '< 1 years': 1, '1-2 years':2, '3-5 years':3, \n                   '5-10 years': 4, '10-20 years':5, '20+ years':6}\n\ncompany_size_dict = {'0-49 employees': 0, '50-249 employees': 1, '250-999 employees':2, '1000-9,999 employees':3,\n                     '10,000 or more employees':4, 'Not Answered':-1}\n\ncluster_infos.loc[:, 'region'] =  cluster_infos['region'].fillna('Not Disclosed')\ncluster_infos.loc[:, 'sub-region'] =  cluster_infos['sub-region'].fillna('Not Disclosed')\n\ncluster_infos.loc[:, 'team_size'] =  cluster_infos['team_size'].fillna('Not Answered')\ncluster_infos.loc[:, 'company_size'] =  cluster_infos['company_size'].fillna('Not Answered')\ncluster_infos.loc[:, 'salary'] =  cluster_infos['salary'].fillna('Not Answered')\n\ncluster_infos.loc[:, 'exp_order'] = cluster_infos['experience'].apply(lambda x: experience_dict[x])\ncluster_infos.loc[:, 'company_order'] = cluster_infos['company_size'].apply(lambda x: company_size_dict[x])\ncluster_infos.loc[:, 'team_order'] = cluster_infos['team_size'].apply(lambda x: int(re.split('[-+]', x)[0]) if x != 'Not Answered' else -1)\ncluster_infos.loc[:, 'salary_order'] = cluster_infos['salary'].apply(lambda x: int([f for f in re.split('[$-\/>]', x) if f.strip()][0].replace(',', '')) if x != 'Not Answered' else -1)\n\ncluster_infos.to_csv('\/kaggle\/working\/cluster_infos.csv', index=True)","eb00352e":"# Analysis\n\n## Data Load\ncluster_infos = pd.read_csv('\/kaggle\/working\/cluster_infos.csv')#.set_index('user_id')\n\ncluster_infos.loc[:, 'Cluster'] = cluster_infos['cluster'].str.title()\n\n\n## Color Definitions\ncluster_colors = [\"ffcad4\",\"17bebb\",\"f0cf65\",\"d62246\",\"2B3A64\",\"647BA6\",\"f3663f\",\"6c0e23\",\"6A449C\"]\ncluster_key = cluster_infos['cluster'].unique().tolist()\ncluster_name = cluster_infos['Cluster'].unique().tolist()\n\ncolor_dict_key = {cluster_key[i]:'#' + cluster_colors[i] for i in range(0, len(cluster_colors))}\ncolor_dict_key[''] = '#A9A9A9'\ncolor_dict_name = {cluster_name[i]:'#' + cluster_colors[i] for i in range(0, len(cluster_colors))}\ncolor_dict_name[''] = '#A9A9A9'\n\ncolor_map = {'cluster':color_dict_key, 'Cluster':color_dict_name}\n\npalette = px.colors.qualitative.T10\n\n## Data Prep\ncluster_melt = pd.melt(cluster_infos, id_vars=['user_id', 'age', 'age_adj', 'gender', 'country', 'schooling', \n                                               'profession', 'region', 'sub-region', 'experience', 'exp_order', \n                                               'company_size', 'company_order', 'team_size', 'team_order', \n                                               'salary', 'salary_order', 'cluster_num', 'cluster'\n                                              ], value_vars = [c for c in cluster_infos.columns.tolist() if '__' in c])\n\n\ncluster_melt.loc[:, 'dim'] = cluster_melt['variable'].str.split('__', expand=True).iloc[:, 0]\ncluster_melt.loc[:, 'dim_value'] = cluster_melt['variable'].str.split('__', expand=True).iloc[:, 1]","6a9041ed":"def plot(fig):\n    fig.update_layout(font_family='Avenir', template='plotly_white', titlefont_size=22)\n    fig.update_yaxes(tickfont_size=14)\n    fig.show()\n    \n\ndef fmt_cluster_name(cluster_list, bold=False, italic=False):\n    \n    new_list = ['{}'.format(f.title().replace('_', ' ')) for f in cluster_list]\n    \n    if bold and italic:\n        new_list = ['<i><b>{}<\/b><\/i>'.format(f) for f in new_list]\n    elif bold:\n        new_list = ['<b>{}<\/b>'.format(f) for f in new_list]\n    elif italic:\n        new_list = ['<i>{}<\/i>'.format(f) for f in new_list]\n\n    return new_list\n\n\ndef split_break(name, upper=True, size=15):\n    if upper:\n        words = re.split('(?=[A-Z])', name)\n    else:\n        words = name.split(' ')\n    new_text = ''\n    for s in words:\n        if len(new_text.split('<br>')[-1]) > size:\n            new_text += '<br>' + s\n        else:\n            new_text += ' ' + s\n        \n    return new_text.strip()","c6fd7f08":"df = cluster_infos\\\n        .groupby(['Cluster'], as_index=False)\\\n        .agg({'counter':'sum'})\n\ndf.loc[:, 'percentage'] = 100*df['counter']\/df['counter'].sum()\n \nfig = px.bar(df, y='Cluster', text='percentage', color='Cluster', color_discrete_map=color_map['Cluster'],\n            x='counter')\nfig.update_layout(\n    showlegend=False, \n    yaxis_title='', \n    xaxis_title='Total of users',\n    title='Distribution of 9 clusters among all users',\n    xaxis_range=[0, 7000]\n\n)\nfig.update_yaxes(categoryorder='total ascending')\nfig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n\n\nplot(fig)","453b2c2c":"all_langs = cluster_melt.loc[cluster_melt['dim'] == 'lang']\\\n        .groupby(['dim_value'], as_index=False)\\\n        .agg({'value':'mean'})\n\n# all_langs.sort_values(by='value', ascending=False)","b3525204":"## Language\n\nlang = cluster_melt.loc[cluster_melt['dim'] == 'lang']\\\n        .groupby(['cluster', 'dim_value'], as_index=False)\\\n        .agg({'value':['sum', 'mean'], 'user_id':'count'})\n\nlang.columns = ['cluster', 'dim_value', 'users', 'value', 'total_users']\n\nlang.loc[:, 'name'] = lang['dim_value'].str.title()\nlang.loc[:, 'cluster_name'] = lang['cluster'].str.replace('_', '<br>').str.title()\n\nlang.loc[:, 'predominance'] = 100*lang['value']\nlang.loc[:, 'rank_cluster'] = lang.groupby(['cluster'])['value'].rank(ascending=False)\nlang.loc[:, 'rank_lang'] = lang.groupby(['name'])['value'].rank(ascending=False)\n\n# Option 1\ndf = lang\\\n        .loc[lang['rank_cluster'] <= 3]\\\n        .sort_values(by='rank_cluster')\n\ndf.loc[:, 'Language'] = df['name']\n# df.loc[:, 'text'] = df.apply(lambda x: '{} - {:.0f}%'.format(x['name'], x['predominance']), axis=1)\n\ncluster_order = {'cluster':['fresh', 'pirate', 'mathy', 'brainy', 'core', 'cloudy', 'root', 'dev', 'pro']}\n\nfig = px.bar(df, x='predominance', y='cluster', facet_col='rank_cluster', color='Language', \n             text='name', facet_col_spacing=0.1,\n             category_orders=cluster_order,\n             color_discrete_sequence=palette\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Top 3 languages of each cluster',\n    height=600,\n    margin_t=120\n)\n\nfig.update_yaxes(title='', tickvals=cluster_order['cluster'], ticktext=fmt_cluster_name(cluster_order['cluster'], True))\n\nfig.update_xaxes(\n    tickvals=[0, 25, 50, 75, 100],\n    title='Share of users<br>who know it (%)'\n)\n\nfig.update_traces(textposition='auto')\n\nfig.for_each_annotation(lambda a: a.update(text = '<i>Top {:.0f}<\/i>'.format(float(a.text.split('=')[1]))))              \n                \nplot(fig)","9a8067c8":"# Lang x Cluster\ntop = lang\\\n        .loc[lang['rank_lang'] <= 1].copy()\n\n# others = lang\\\n#             .loc[lang['rank_lang'] > 1]\\\n#             .groupby(['dim_value'])\\\n#             .agg({'users':'sum', 'total_users':'sum'})\n\n# others.loc[:, 'total'] = others.groupby(['dim_value'])['users'].transform('sum')\n# others.loc[:, 'value'] = others['users']\/others['total']\n\n# df = pd.concat([top, others], axis=0)\ndf = top.copy()\n\ndf.loc[:, 'Cluster'] = df['cluster'].str.title()\ndf.loc[:, 'Language'] = df['name'].str.title()\n\norder = df.sort_values(by='predominance', ascending=False)['Language'].tolist()\n\nfig = px.bar(df.sort_values(by='cluster'), y='predominance', x='Cluster', color='Cluster', color_discrete_sequence=palette\n#              text='name', \n             ,facet_col='name', color_discrete_map=color_map['Cluster']\n#              ,category_orders={'Cluster':['Core', 'Pirate', 'Fresh','Mathy', 'Pro', 'Root', 'Dev']}\n             ,category_orders={'name':['Python', 'R', 'Matlab','C++', 'C','None', 'Sql', 'Javascript','Swift', 'Java', 'Other', 'Bash', 'Julia']}\n#              facet_col_wrap=3, facet_col_spacing=0.1\n            )\n\nfig.update_layout(\n    showlegend=False, title='Group most skilled in each language (proportionally)',\n    yaxis_title='Percentage of group<br>that uses it (%)',\n    margin_t=100,\n#     height=700\n    )\nfig.update_xaxes(matches=None, \n                 showticklabels=True, \n#                  categoryorder='total descending', \n                 title='')\n# fig.update_xaxes(\n#     tickvals=[0, 50, 100], \n#     range=[0, 120])\n\n# fig.update_traces(textposition='outside', texttemplate='%{x:.0f}%')\nfig.for_each_annotation(lambda a: a.update(text = '<i>{}<\/i>'.format(a.text.split('=')[1].title())))\nplot(fig)","3d34272f":"melt = cluster_melt.copy()\n\nmelt.loc[:, 'count'] = 1\nmelt.loc[melt['value'] == 0, 'count'] = 0\nmelt.loc[melt['dim_value'].isin(['None', 'I do not share my work publicly']) , 'count'] = 0\n\ndim_user = melt.copy()\\\n            .groupby(['user_id', 'cluster', 'dim'], as_index=False)\\\n            .agg({'count': 'sum'})\n\ndim_cluster = dim_user\\\n                .groupby(['cluster', 'dim'], as_index=False)\\\n                .agg({'count':['mean', 'median'], 'user_id':'nunique'})\n\ndim_cluster.columns = ['cluster', 'dim', 'avg_value', 'med_value', 'users']\n\ndf = dim_cluster\\\n        .loc[dim_cluster['dim'].isin(['deploy', 'lang', 'notebook', 'viz'])].copy()\n\ndf.loc[:, 'Cluster'] = df['cluster'].str.title()\ndf.loc[:, 'rank'] = df.groupby(['dim'])['avg_value'].rank(ascending=False)\n\ndf.loc[:, 'main'] = ''\ndf.loc[df['rank'] <= 2, 'main'] = df['Cluster']\n\n\nfig = px.bar(df, x='avg_value', y='Cluster', facet_col='dim', \n             color='main', color_discrete_map=color_map['Cluster'])\n\nrenamer = {'deploy': 'Deploy tools<br>(9 options)', 'lang':'Programming languages<br>(12 options)', 'notebook':'Notebook solutions<br>(13 options)',\n            'viz':'Visualization libraries<br>(11 options)'\n           }\n\n# lang = 12\n# ide = 11\n# notebook = 13\n# viz = 11\n# deploy = 9\n\nfig.update_layout(\n    title='Average of user tools, per Cluster - Top 2 highlighted',\n    yaxis_title='',\n    showlegend=False,\n    margin_t=120\n)\n\nfig.update_xaxes(title='Average<br>per user')\n\nfig.update_traces(texttemplate='%{x:.1f}')\n\nfig.for_each_annotation(lambda x: x.update(text=renamer[x.text.split('=')[1]]))\nplot(fig)","40d6951d":"## Platform\n\ndim_df = cluster_melt.loc[cluster_melt['dim'] == 'viz']\\\n        .groupby(['cluster', 'dim_value'], as_index=False)\\\n        .agg({'value':'mean'})\n\ndim_df.loc[:, 'name'] = dim_df['dim_value']\ndim_df.loc[:, 'cluster_name'] = dim_df['cluster'].str.replace('_', '<br>').str.title()\n\ndim_df.loc[:, 'predominance'] = 100*dim_df['value']\ndim_df.loc[:, 'rank_cluster'] = dim_df.groupby(['cluster'])['value'].rank(ascending=False)\ndim_df.loc[:, 'rank_dim'] = dim_df.groupby(['name'])['value'].rank(ascending=False)\n\n\n# Option 1\ndf = dim_df\\\n        .loc[dim_df['rank_cluster'] <= 3]\\\n        .sort_values(by='name')\n\ndf.loc[:, 'Cluster'] = df['cluster'].str.title()\ndf.loc[:, 'Lib'] = df['name'].str.title()\n\n# df.loc[:, 'text'] = df.apply(lambda x: '{:.0f}%'.format(x['predominance']), axis=1)\n\ncluster_order = {'Cluster':['Fresh', 'Dev', 'Pirate', 'Core', 'Pro', 'Cloudy', 'Brainy', 'Mathy', 'Root']}\n\nfig = px.bar(df, x='predominance', y='Cluster', color='name', \n             text='Lib', facet_col_spacing=0.05, facet_col='rank_cluster',\n             category_orders=cluster_order, color_discrete_sequence=palette\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Top 3 Visualization Libraries of each cluster', \n    yaxis_title='',\n    margin=dict(t=120),\n    height=600)\n\nfig.update_xaxes(\n    range=[0,130], matches=None, tickvals=[0, 25, 50, 75, 100], \n    title='Share of cluster<br>that uses it (%)'\n)\n\nfig.update_traces(textposition='outside')\n\nfig.for_each_annotation(lambda a: a.update(text = \"Top {:.0f}\".format(float(a.text.split('=')[1]))))\n\nplot(fig)","b92d5d18":"## Platform\n\ndim_df = cluster_melt.loc[cluster_melt['dim'] == 'platform']\\\n        .groupby(['cluster', 'dim_value'], as_index=False)\\\n        .agg({'value':'mean'})\n\ndim_df.loc[:, 'name'] = dim_df['dim_value']\ndim_df.loc[:, 'cluster_name'] = dim_df['cluster'].str.replace('_', '<br>').str.title()\n\ndim_df.loc[:, 'predominance'] = 100*dim_df['value']\ndim_df.loc[:, 'rank_cluster'] = dim_df.groupby(['cluster'])['value'].rank(ascending=False)\ndim_df.loc[:, 'rank_dim'] = dim_df.groupby(['name'])['value'].rank(ascending=False)\n\n\n# Option 1\ndf = dim_df\\\n        .loc[dim_df['rank_cluster'] == 1]\\\n        .sort_values(by='name')\n\ndf.loc[:, 'Platform'] = df['name']\ndf.loc[:, 'text'] = df.apply(lambda x: '{:.0f}%'.format(x['predominance']), axis=1)\n\ncluster_order = {'cluster':df.sort_values(by=['value'])['cluster'].tolist()}\n\nfig = px.bar(df, y='predominance', x='cluster', color='Platform', \n             text='text', facet_col_spacing=0.05, facet_col='Platform',\n             category_orders=cluster_order, color_discrete_sequence=palette\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Main computing platform used by each cluster', \n    yaxis_title='Share of cluster<br>that uses it (%)',\n    margin=dict(t=120),\n    yaxis_range=[0,110],\n    height=600)\n\nfig.update_xaxes(title='', tickvals=cluster_order['cluster'], ticktext=fmt_cluster_name(cluster_order['cluster'], True))\nfig.update_xaxes(matches=None, tickangle=45, categoryorder='total descending', tickfont_size=14)\n\nfig.update_traces(textposition='outside')\n\n# fig.for_each_annotation(lambda a: a.update(text = split_break(a.text.split('=')[1])))\nfig.for_each_annotation(lambda a: a.update(text = f\"<b>{split_break(a.text.split('=')[1])}<\/b>\"))\n\nplot(fig)","d1e762c5":"## Dimensions\n\ndim_df = cluster_melt.loc[cluster_melt['dim'] == 'hardware']\\\n        .groupby(['cluster', 'dim_value'], as_index=False)\\\n        .agg({'value':'mean'})\n\ndim_df.loc[:, 'name'] = dim_df['dim_value']\ndim_df.loc[:, 'Cluster'] = dim_df['cluster'].str.title()\n\ndim_df.loc[:, 'predominance'] = 100*dim_df['value']\ndim_df.loc[:, 'rank_cluster'] = dim_df.groupby(['Cluster'])['value'].rank(ascending=False)\ndim_df.loc[:, 'rank_dim'] = dim_df.groupby(['name'])['value'].rank(ascending=False)\n\n# Option 1\ndf = dim_df\\\n#         .loc[dim_df['rank_cluster'] == 1]\\\n#         .sort_values(by='rank_cluster')\n\ndf.loc[:, 'IDE'] = df['name']\n\ndf.loc[:, 'main'] = ''\ndf.loc[df['rank_dim'] == 1, 'main'] = df['Cluster']\n\n# df.loc[:, 'text'] = ''\n# df.apply(lambda x: '{} - {:.0f}%'.format(x['name'], x['predominance']), axis=1)\n\ncluster_order = {'IDE':['Gpus', 'Tpus', 'Other', 'None']}\n\nfig = px.bar(df, x='predominance', y='Cluster', color='main', \n             facet_col_spacing=0.1, facet_col='IDE',\n             category_orders=cluster_order, color_discrete_map=color_map['Cluster'],\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Hardware usage of each cluster, main group highlight', \n    height=500\n)\n\nfig.update_yaxes(title='', categoryorder='total ascending')\n\nfig.update_xaxes(\n#     matches=None,\n#     tickvals=[0, 25, 50, 75, 100], \n    title='Share of cluster<br>that uses it (%)'\n)\n\n\nfig.update_traces(texttemplate='%{x:.0f}%', textposition='auto')\nfig.for_each_annotation(lambda a: a.update(text = '<b>{}<\/b>'.format(a.text.split('=')[1])))\nplot(fig)","ef1ff0e2":"## Dimensions\n\ndim_df = cluster_melt.loc[cluster_melt['dim'] == 'ide']\\\n        .groupby(['cluster', 'dim_value'], as_index=False)\\\n        .agg({'value':'mean'})\n\ndim_df.loc[:, 'name'] = dim_df['dim_value']\ndim_df.loc[:, 'cluster_name'] = dim_df['cluster'].str.replace('_', '<br>').str.title()\n\ndim_df.loc[:, 'predominance'] = 100*dim_df['value']\ndim_df.loc[:, 'rank_cluster'] = dim_df.groupby(['cluster'])['value'].rank(ascending=False)\ndim_df.loc[:, 'rank_dim'] = dim_df.groupby(['name'])['value'].rank(ascending=False)\n\n# Option 1\ndf = dim_df\\\n        .loc[dim_df['rank_cluster'] == 1]\\\n        .sort_values(by='rank_cluster')\n\ndf.loc[:, 'IDE'] = df['name']\n# df.loc[:, 'text'] = df.apply(lambda x: '{} - {:.0f}%'.format(x['name'], x['predominance']), axis=1)\n\ncluster_order = {'cluster':df.sort_values(by='value')['cluster'].tolist()}\n\nfig = px.bar(df, x='predominance', y='cluster', color='IDE', \n             text='IDE', facet_col_spacing=0.1,\n             category_orders=cluster_order, color_discrete_sequence=palette\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Main IDE used by each group', \n    height=500\n)\n\nfig.update_yaxes(title='', tickvals=cluster_order['cluster'], ticktext=fmt_cluster_name(cluster_order['cluster'], True))\n\nfig.update_xaxes(\n    tickvals=[0, 25, 50, 75, 100], \n    range=[0, 130],\n    title='Share of cluster<br>that uses it (%)'\n)\n\n   \nfig.update_layout(margin_r=100)\n\ntext = '''\n<b>Jupyter<\/b> is the most common choice,<br>\nbut <b>Devs<\/b> prefer others IDE's.<br>\nOthers groups opt for<br>\ntheir respective language IDE's.\n'''\nfig.add_annotation(\n                text=text,\n                align='right',\n                showarrow=False,\n                xref='paper',\n                yref='paper',\n                x=1.1,\n                y=1,\n                font_size=13\n            )\n\n\nfig.update_traces(textposition='outside')\n# fig.for_each_annotation(lambda a: a.update(text = '<i>Top {:.0f}<\/i>'.format(float(a.text.split('=')[1]))))\nplot(fig)","38633b19":"\ndf = cluster_infos\\\n        .groupby(['Cluster', 'age'], as_index=False)\\\n        .agg({'user_id':'nunique', 'age_adj':'mean'})\n\ndf.columns = ['Cluster', 'age_group', 'num_users', 'age_order']\n\ndf.loc[:, 'total_users'] = df.groupby(['Cluster'])['num_users'].transform('sum')\n\ndf.loc[:, 'percentage'] = 100*df['num_users']\/df['total_users']\n\ndf.loc[:, 'rank'] = df.groupby(['age_group'])['percentage'].rank(ascending=False)\n\ndf.loc[:, 'text'] = ''\ndf.loc[df['rank'] == 1, 'text'] = df['Cluster']\n\ntop = df.loc[df['rank'] <= 1]\n\nfig = px.bar(top.sort_values(by='age_order'), x='age_group', y='percentage', color='Cluster', \n            color_discrete_map=color_map['Cluster'], text='Cluster')\n\nfig.update_layout(\n    title='Cluster with largest proportion on age group',\n    xaxis_title='Age group',\n    yaxis_title='Share of users of cluster (%)'\n)\n\nfig.update_traces(textposition='outside')\n\nplot(fig)\n\n# fig = px.bar(df, y='Cluster', x='percentage', color='text', facet_col='age_group', \n#             color_discrete_map=color_map['Cluster'])\n\n# fig.update_layout(showlegend=False)\n# fig.for_each_annotation(lambda a: a.update(text = '<b>{}<\/b>'.format(a.text.split('=')[1])))\n# fig.\n\n# fig = px.bar(top.sort_values(by='age_order'), y='cluster', x='percentage', facet_col='age_group')\n# plot(fig)","1be97bc3":"df = cluster_infos\\\n        .groupby(['Cluster', 'experience'], as_index=False)\\\n        .agg({'user_id':'nunique', 'exp_order':'mean'})\\\n        .sort_values(by='exp_order')\n\ndf.columns = ['Cluster', 'dim', 'num_users', 'order']\n\ndf.loc[:, 'total_users'] = df.groupby(['Cluster'])['num_users'].transform('sum')\n\ndf.loc[:, 'percentage'] = 100*df['num_users']\/df['total_users']\n\ndf.loc[:, 'rank'] = df.groupby(['dim'])['percentage'].rank(ascending=False)\n\ntop = df.loc[df['rank'] <= 1]\n\nfig = px.bar(top, y='dim', x='percentage', color='Cluster', text='Cluster', \n             facet_col='rank', color_discrete_map=color_map['Cluster'])\nfig.update_yaxes(showticklabels=True)\nfig.update_xaxes(ticksuffix='%')\n\nfig.update_traces(texttemplate='<b>%{text}<\/b>', textposition='outside')\nfig.update_layout(\n    yaxis_title='',\n    xaxis_title='Share of users on cluster',\n    xaxis_range=[0,70],\n    title='Top cluster of each coding experience level',\n    showlegend=False\n)\n\nfig.for_each_annotation(lambda a: a.update(text=''))\nplot(fig)","4faf96b8":"# Gender x cluster \ndf = cluster_infos\\\n        .groupby(['Cluster', 'gender'], as_index=False)\\\n        .agg({'user_id':'nunique'})\n\ndf.columns = ['Cluster', 'gender', 'num_users']\n\ndf.loc[:, 'total_users'] = df.groupby(['Cluster'])['num_users'].transform('sum')\n\ndf.loc[:, 'percentage'] = 100*df['num_users']\/df['total_users']\n\ndf.loc[:, 'rank'] = df.groupby(['gender'])['percentage'].rank(ascending=False)\n\ndf.loc[:, 'text'] = ''\ndf.loc[df['rank'] <= 1, 'text'] = df['Cluster']\n\n\nfig = px.bar(df.sort_values(by=['gender','percentage']), y='Cluster', x='percentage', facet_col='gender',\n             color='text', color_discrete_map=color_map['Cluster'], \n             color_discrete_sequence=palette, text='text',\n             category_orders={'gender':['Man', 'Woman', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']}\n            )\nfig.update_xaxes(matches=None, ticksuffix='%', title='Share of users<br>on cluster')\nfig.for_each_annotation(lambda a: a.update(text=f\"<b>{a.text.split('=')[1]}<\/b>\"))\nfig.update_layout(\n    title='Gender distribution highlights - Top cluster',\n    yaxis_title='',\n    showlegend=False)\n\nplot(fig)","d689da8e":"## Education background\ndim_df = cluster_infos\\\n        .groupby(['cluster', 'schooling'], as_index=False)\\\n        .agg({'user_id':'nunique'})\n\ndim_df.columns = ['cluster', 'dim', 'num_users']\n\ndim_df.loc[:, 'total_users_dim'] = dim_df.groupby(['dim'])['num_users'].transform('sum')\ndim_df.loc[:, 'total_users'] = dim_df['num_users'].sum()\n\n\ndim_df.loc[:, 'percentage_dim'] = 100*dim_df['num_users']\/dim_df['total_users_dim']\ndim_df.loc[:, 'percentage_gen'] = 100*dim_df['total_users_dim']\/dim_df['total_users']\n\ndim_df.loc[:, 'rank_cluster'] = dim_df.groupby(['cluster'])['percentage_dim'].rank(ascending=False, method='first')\ndim_df.loc[:, 'rank_dim'] = dim_df.groupby(['dim'])['percentage_dim'].rank(ascending=False, method='first')\n\ndf = dim_df\\\n        .loc[dim_df['rank_dim'] <= 2]\\\n        .sort_values(by=['rank_dim', 'percentage_dim'])\n\ndf.loc[:, 'Cluster'] = fmt_cluster_name(df['cluster'].tolist())\ndf.loc[:, 'text'] = df.apply(lambda x: '<b>{}<\/b> ({:.0f}%)'.format(x['Cluster'], x['percentage_dim']), axis=1)\n\ndf.loc[:, 'dim_adj'] = df['dim'].apply(lambda x: split_break(x, False))\n\nfig = px.bar(df, x='percentage_dim', y='dim_adj', facet_col='rank_dim', color='Cluster'\n             ,text='text', facet_col_spacing=0.1, color_discrete_map=color_map['Cluster']\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Top 2 groups of each educational background', \n    margin_t=120,\n    height=700)\n\nfig.update_yaxes(categoryorder='total descending', row=1, col=1, title='')\n                 \nfig.update_xaxes(\n    showticklabels=False,\n    showgrid=False,\n#     range=[0, 75],\n    title='Share of users<br>on cluster (%)'\n)\n\nfig.update_traces(textposition='auto')\nfig.for_each_annotation(lambda a: a.update(text = '<i>Top {:.0f}<\/i>'.format(float(a.text.split('=')[1]))))\nplot(fig)","f9f108ac":"## Professional background\ndim_df = cluster_infos\\\n        .groupby(['cluster', 'profession'], as_index=False)\\\n        .agg({'user_id':'nunique'})\n\ndim_df.columns = ['cluster', 'dim', 'num_users']\n\ndim_df.loc[:, 'total_users_dim'] = dim_df.groupby(['dim'])['num_users'].transform('sum')\ndim_df.loc[:, 'total_users'] = dim_df['num_users'].sum()\n\n\ndim_df.loc[:, 'percentage_dim'] = 100*dim_df['num_users']\/dim_df['total_users_dim']\ndim_df.loc[:, 'percentage_gen'] = 100*dim_df['total_users_dim']\/dim_df['total_users']\n\ndim_df.loc[:, 'rank_cluster'] = dim_df.groupby(['cluster'])['percentage_dim'].rank(ascending=False, method='first')\ndim_df.loc[:, 'rank_dim'] = dim_df.groupby(['dim'])['percentage_dim'].rank(ascending=False, method='first')\n\ndf = dim_df\\\n        .loc[dim_df['rank_dim'] <= 2]\\\n        .sort_values(by=['rank_dim', 'percentage_dim'])\n\ndf.loc[:, 'Cluster'] = fmt_cluster_name(df['cluster'].tolist())\ndf.loc[:, 'text'] = df.apply(lambda x: '<b>{}<\/b> ({:.0f}%)'.format(x['Cluster'], x['percentage_dim']), axis=1)\n\ndf.loc[:, 'dim_adj'] = df['dim'].apply(lambda x: split_break(x, False))\n\nfig = px.bar(df, x='percentage_dim', \n             y='dim_adj', facet_col='rank_dim', color='Cluster'\n             ,text='text', facet_col_spacing=0.1, \n             color_discrete_map=color_map['Cluster'],\n             category_orders={'dim_adj':['Statistician','Currently not employed', \n                                         'Data Analyst', 'Business Analyst','Data Scientist',\n                                        'Research Scientist', 'Data Engineer', 'Machine Learning<br>Engineer',\n                                         'Product\/Project<br>Manager', 'Other', 'Student', 'Software Engineer',\n                                         'DBA\/Database Engineer']}\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Top 2 groups of each profession', \n    margin_t=120,\n    height=800,\n    yaxis_title='Profession'\n)\n\nfig.update_yaxes(\n    tickvals=[\n        'Statistician','Currently not employed', \n                                         'Data Analyst', 'Business Analyst','Data Scientist',\n                                        'Research Scientist', 'Data Engineer', 'Machine Learning<br>Engineer',\n                                         'Product\/Project<br>Manager', 'Student', 'Other', 'Software Engineer',\n                                         'DBA\/Database Engineer'   \n    ]\n#     categoryorder='total descending', row=1, col=1, title='')\n)\n\nfig.update_xaxes(\n    showticklabels=False,\n    showgrid=False,\n#     range=[0, 75],\n    title='Share of professionals<br>on cluster (%)'\n)\n\nfig.update_traces(textposition='auto')\nfig.for_each_annotation(lambda a: a.update(text = '<i>Top {:.0f}<\/i>'.format(float(a.text.split('=')[1]))))\nplot(fig)\n","bf2e14f4":"## Continent\ndim_df = cluster_infos\\\n        .groupby(['cluster', 'region'], as_index=False)\\\n        .agg({'user_id':'nunique'})\n\ndim_df.columns = ['cluster', 'dim', 'num_users']\n\ndim_df.loc[:, 'total_users_dim'] = dim_df.groupby(['dim'])['num_users'].transform('sum')\ndim_df.loc[:, 'total_users_cluster'] = dim_df.groupby(['cluster'])['num_users'].transform('sum')\n\ndim_df.loc[:, 'total_users'] = dim_df['num_users'].sum()\n\n\ndim_df.loc[:, 'percentage_dim'] = 100*dim_df['num_users']\/dim_df['total_users_dim']\ndim_df.loc[:, 'percentage_gen'] = 100*dim_df['total_users_dim']\/dim_df['total_users']\n\ndim_df.loc[:, 'rank_cluster'] = dim_df.groupby(['cluster'])['percentage_dim'].rank(ascending=False, method='first')\ndim_df.loc[:, 'rank_dim'] = dim_df.groupby(['dim'])['percentage_dim'].rank(ascending=False, method='first')\n\ndf = dim_df.copy()\\\n        .loc[dim_df['rank_cluster'] <= 1]\n#         .sort_values(by=['rank_dim', 'percentage_dim'])\n\ndf.loc[:, 'Cluster'] = fmt_cluster_name(df['cluster'].tolist())\n\ndf.loc[:, 'main'] = ''\ndf.loc[df['rank_cluster'] == 1, 'main'] = df['Cluster']\n\ndf.loc[:, 'dim_adj'] = df['dim'].apply(lambda x: split_break(x, False))\n\ncategory_orders={'dim_adj':['Africa', 'Oceania', 'Europe', 'Not Disclosed']}\n\nfig = px.bar(df, y='percentage_dim', \n             x='Cluster', color='main', facet_col='dim_adj'\n             ,text='num_users',\n             category_orders=category_orders,\n             color_discrete_map=color_map['Cluster']\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Continent with the largest proportion of each cluster', \n    margin_t=120,\n    yaxis_title='Proportion of cluster<br> on region (%)'\n)\n\nfig.update_yaxes(showgrid=False, showticklabels=False)\n\nfig.update_xaxes(\n    matches=None,\n    title=''\n)\n\nfig.update_traces(texttemplate='%{y:.0f}%', textposition='outside')\nfig.for_each_annotation(lambda a: a.update(text = '<b>{}<\/b>'.format(a.text.split('=')[1])))\nplot(fig)","9834e386":"## Professional background\ndim_df = cluster_infos\\\n        .groupby(['cluster', 'sub-region'], as_index=False)\\\n        .agg({'user_id':'nunique'})\n\ndim_df.columns = ['cluster', 'dim', 'num_users']\n\ndim_df.loc[:, 'total_users_dim'] = dim_df.groupby(['dim'])['num_users'].transform('sum')\ndim_df.loc[:, 'total_users_cluster'] = dim_df.groupby(['cluster'])['num_users'].transform('sum')\n\ndim_df.loc[:, 'total_users'] = dim_df['num_users'].sum()\n\n\ndim_df.loc[:, 'percentage_dim'] = 100*dim_df['num_users']\/dim_df['total_users_dim']\ndim_df.loc[:, 'percentage_gen'] = 100*dim_df['total_users_dim']\/dim_df['total_users']\n\ndim_df.loc[:, 'rank_cluster'] = dim_df.groupby(['cluster'])['percentage_dim'].rank(ascending=False, method='first')\ndim_df.loc[:, 'rank_dim'] = dim_df.groupby(['dim'])['percentage_dim'].rank(ascending=False, method='first')\n\ndf = dim_df.copy()\\\n        .loc[dim_df['rank_cluster'] <= 1]\n#         .sort_values(by=['rank_dim', 'percentage_dim'])\n\ndf.loc[:, 'Cluster'] = fmt_cluster_name(df['cluster'].tolist())\n\ndf.loc[:, 'main'] = ''\ndf.loc[df['rank_cluster'] == 1, 'main'] = df['Cluster']\n\ndf.loc[:, 'dim_adj'] = df['dim'].apply(lambda x: split_break(x, False))\n\ncategory_orders={'dim_adj':['Sub-Saharian Africa','Northern Africa', 'Australia and New Zealand', \n                            'Western Europe', 'Eastern Asia', 'South-eastern Asia', 'Latin America and the Caribbean',\n                            'Disclosed']}\n\nfig = px.bar(df, y='percentage_dim', \n             x='Cluster', color='main', facet_col='dim_adj'\n             ,text='num_users',\n             category_orders=category_orders,\n             color_discrete_map=color_map['Cluster']\n            )\n\nfig.update_layout(\n    showlegend=False, \n    title='Sub-region with the largest proportion of each cluster', \n    margin_t=150,\n    yaxis_title='Proportion of cluster<br> on sub-region(%)'\n)\n\nfig.update_yaxes(showgrid=False, showticklabels=False, range=[0,50])\n\nfig.update_xaxes(\n    matches=None,\n    title=''\n)    \n    \n\nfig.update_traces(texttemplate='%{y:.0f}%', textposition='outside')\nfig.for_each_annotation(lambda a: a.update(text = '<b>{}<\/b>'.format(split_break(a.text.split('=')[1], False, 5))))\nplot(fig)\n","bb58ee3d":"##  Intro\nWhen we take a closer look at the Kaggle Survey data, there's a lot of hidden patterns to uncover.  \nIn this Notebook, I've decided to focus on the apparatus different kagglers use all over the world, what are the common groups that exist and how they are related to other very interesting dimensions such as gender, professional experience and world region.\n\nLet's take a look?","7a723249":"# Who are you at the Toolset Zoo?","e5fe6518":"### How do theses clusters relate to the users personal information?","8606c1f5":"When we investigate sub-regions inside each continent, the picture shifts:\n* Asia is ruling the Deep Learning and newcomer game **(Brainy and Fresh)**;\n* Africa is a highlight to **Core** and **Mathy**; \n* **Cloudy** and **Root** focus on Western Europe;\n* Latin America land of the **Pro** users","68eaf3f4":"When considering hardware usage, we see that:\n* **Brainy** users are the biggest fans of GPUs (which are great for running Deep Learning)\n* **Pro** users are the heaviest users of TPU\n* **Root** go wild again with other hardware choices","108c2027":"## There are 9 main groups of users on Kaggle \n\nIn order of proportion among users: **Core, Dev, Pirate, Fresh, Cloudy, Mathy, Pro, Brainy and Root.**","495c1a3a":"Looking at each cluster computing platform preferences we see that:\n* Nearly 100% of **Brainy** uses a Deep Learning Workstation \n* Almost 100% of **Cloudy** uses a Cloud Computing Platform\n* Other groups rely on their own computers **(Core, Pirate, Mathy, Dev and Pro)**, other type of platform **(Root)** or really just didn't start to code **(Fresh).**","eb249650":"* Among all clusters, the gender gap is the highest on Deep Learning (**Brainy**)\n* Women are coming on strong to the field, with the **Fresh** cluster (27%) having the largest proportion of them among all clusters\n* **Root** users have the largest participation of non-binary respondants","b5d26f13":"* Africa is coming strong, ruling the **Core** and **Pro** game\n* Oceania is wild, with the largest proportion of **Devs** and **Pirates**\n* Europe goes beyond its laptop, with lots of **Brainys** and **Cloudys**\n* **Fresh, Mathy and Root** coming from little places everywhere (so little that their location data is not disclosed)","9c4b271a":"* Statisticias are mainly **Pirates**\n* Not employed users are rocking that **Core** skills\n* The most Analytics and Data Science oriented jobs (Data Analyst, Business Analyst, Data Scientist and Research Scientists) are really rocking that **Core** and **Pirate** toolset\n* The most DataOps jobs (Data Engineer and Machine Learning Engineering) are really keen on the **Cloudy** toolset\n* Software Engineers and DBA's are mainly fond of the **Dev** toolset\n* When in doubt of how to enter the market, PMs and Students are going mainly to the **Core** and **Dev** toolsets.","b3a4050f":"* **Devs** don't need a degree (They are the top 1 group among those who didn't have formal education past high school and top 2 among those who didn't finish college.)\n* Academia is apparently a **Pirate** training, with this cluster being the second most common among users with Master's or Doctoral degrees.","fa51b093":"When we look multiple apparatus dimensions at the same time, we see that **Pro** are the users with the most tools under their belt, from deploy to visualization libraries.","34745d2e":"# TL; DR\n\n## Wanna know what is the toolset closest to yours?\n## To make it easy for you to find it, here's a quick recap on the main findings!\n\n* Has never written code? **Fresh**\n* Loves R? **Pirate**\n* Uses a lot of Matlab and C\/C++? **Mathy**\n* Python running in the Cloud? **Cloudy**\n* Python to Deep Learning? **Brainy**\n* Focusing on that Python + Jupyter + Matplotlib combo? **Core**\n* Jack of all trades, uses a lot of Python and SQL and knows a lot of tools to visualization and deploy? **Pro**\n* Knows Python and other language like Javascript or Java, picky with IDEs and don't usually work with visualizations? **Dev**\n* Not running things locally, but also not in the cloud? (and probably with some Bash?) **Root**","83783a66":"## Defining apparatus and Clustering\n\nFirst and foremost, let's define what is the Data Apparatus. Considering apparatus the main tools needed to every data application in order to deliver value, the dimensions we'll analyze to each user are:\n* Programming Languages (Q7)\n* IDE's (Q9)\n* Computing Platform (Q11)\n* Notebook products (Q10)\n* Hardware (Q12)\n* Visualization Libraries (Q14)\n* Deploy (Q36)\n\nAfter selecting this data to all users and removing users who didn't answer the questions about coding experience, educational background and profession, we can use Multi Factor Analysis (with Prince) to transform our Categorical variables in Continuous features, and then cluster them with the K-Means algorithm. The details of the clustering step are defined on a cell hidden above.","cc9988bb":"When we investigate coding experience:\n* **Root** users have been working for very long (10-20+ years)\n* Again, Deep Learning is most commmon among users with greater experience (5-10 years)\n* Cloud is popular with the more recent crowd (3-5 years)\n* **Core** users are fairly new, but as the name says, are good at the basics\n* **Fresh** users are the ones with least coding experience\n","0919e765":"When we dive into each cluster Visualization Tool, we see that:\n* **Devs** don't use them as much\n* More than half of **Pro** users use at least 3 different vizualiation libraries\n* **Core** users really focus on Matplotlib\n* **Pirates** know their Ggplot","d8ea994a":"As we look to age distribution, we can see that, considering the distribution inside the cluster:\n* **Mathy**s have the youngest users\n* **Core** and **Pro** users have more 20-somethings\n* **Brainy**s predominance from 30-34 shows that Deep Learning takes experience\n* **Root** users were here before everyone (with largest proportion from 35 to 59 years old) ","bc6c255a":"There are three clusters that standout due to their programming language choices:\n* 68% of users from the **Fresh** cluster aren't used to any programming language, or know a little Python\n* **Pirates** love R. (95% use it frequently)\n* Beyond Python, Matlab is very used by **Mathy** users (more than 86% of users)\n* All others have Python and SQL as their two most used languages. \n* Javascript is a relevant language to **Devs** and **Pros** ","92d08679":"Here, we see that:\n* As expected, **Mathy** and **Pirates** use Matlab and RStudio, respectively as their main IDE's\n* **Devs** really like their own choices of IDE\n* The other groups, apart from the **Fresh** one, opt for the Jupyter Suite","504e9154":"## Where does each cluster thrives?","c229f91d":"When we look to each language's largest group (proportionally), some other patters emerge:\n* The **Core** group is the most Python-skilled\n* **Mathy** users are also the most skilled on C and C++, languages known for their speed and scientific usage\n* **Root** users are the ones who love Bash the most\n* **Pros** are the heaviest users of SQL and Javascript\n* **Devs** were the ones who used Java and non-mapped languages the most","a0024ba0":"# Analysis","33a5f2f2":"## What each of these clusters mean?\n\nTo define these clusters attributes, let's analyze their Programming Languages preferences."}}