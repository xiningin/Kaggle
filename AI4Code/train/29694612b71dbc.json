{"cell_type":{"c6287d16":"code","9c62addc":"code","eabc0860":"code","e3900e0c":"code","efed9847":"code","1d03de75":"code","d6c15b26":"code","06121c08":"code","c30d5160":"code","4deff241":"code","d0f2e7c3":"code","9ac9cfc0":"code","3cf1df65":"code","dcb92717":"code","73488fb9":"code","49e882ca":"code","1f493d5c":"markdown","41e913c6":"markdown","08804f50":"markdown"},"source":{"c6287d16":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom glob import glob\nimport cv2 \nimport numpy as np\nimport pandas as pd","9c62addc":"train_dir = '..\/input\/aia-dt4-who-is-she\/training_set\/training_set'\ntest_dir = '..\/input\/aia-dt4-who-is-she\/testing_set'\n\n# print traing data and testing data\n## len of the glob's returned list\nprint(\"training data number\uff1a\", len(glob(train_dir + '\/*\/*')))\nprint(\"testing data nummber\uff1a\"  , len(glob(test_dir + '\/testing_set\/*')))\n\n# check the images\nimg = cv2.imread(train_dir+\"\/akane\/000.png\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nprint(type(img), img.shape, img.min(), img.max())","eabc0860":"image_size = 244 # same as the resnet50 \nbatch_size = 16\nseed = 248\n\n# Data augmentation and split the data into valid and training into batches \n\n# create a image generator object\n## to rescale, train_test_split, rotate, shift, flip, ...\n## Q: how many of the augmented data could be generated?\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale= 1.\/255,\n    featurewise_center=False,\n    samplewise_center=True,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=True,\n    zca_whitening=True,\n    validation_split=0.2,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    vertical_flip=False,\n    horizontal_flip=True)\n\n# feed the data to the image generator object\n## set the image to read data, convert to rgb, resize, shuffle with a seed, pack into batch size \n### return batches of the input data with augemntation\ntrain_generator = train_datagen.flow_from_directory(\n    directory = train_dir,\n    target_size = (image_size,image_size),\n    color_mode='rgb',\n    batch_size = batch_size,\n    class_mode = 'categorical', # 2D one-hot encode \n    seed=seed,\n    subset = 'training'\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    directory = train_dir,\n    target_size=(image_size,image_size),\n    batch_size=batch_size,\n    class_mode='categorical',\n    seed=seed,\n    subset = 'validation'\n)\n\n\n# return a Directory Iterator object \n# print(type(train_generator))\n\n# print the labels \nprint(train_generator.class_indices)","e3900e0c":"from tensorflow.keras import Input, layers, models, optimizers, Model, Sequential, regularizers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.applications import VGG16 \nfrom tensorflow.keras.applications import ResNet50, ResNet152V2, Xception","efed9847":"## define the customized VGG16\ndef vgg16CNN(input_shape, outclass, sigma='sigmoid'):\n    \n    # create a model framework\n    model = Sequential()\n    \n    # base_model: VGG16\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n    # reserve the last five as trainable layers \n    #for layer in base_model.layers[:-5]:\n        #layer.trainable=False\n    model.add(base_model)\n    \n    # add the fully-connected layers\n    model.add(layers.Flatten())\n    model.add(layers.Dense(256, activation='relu', kernel_regularizer='l1')) # Lasso for feature selection\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(128, activation='relu', kernel_regularizer='l1'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(outclass, activation=sigma))\n    \n    return model","1d03de75":"## define the customized resnet50\ndef CNN(input_shape, outclass, sigma='sigmoid'):\n    \n    # create a model framework\n    model = Sequential()\n    \n    # base_model\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n    # reserve the last five as trainable layers \n    for layer in base_model.layers[:-20]:\n        layer.trainable=False\n    model.add(base_model)\n    print(base_model.output_shape)\n    \n    # add the fully-connected layers\n    model.add(layers.Flatten())\n    model.add(layers.Dense(100, activation='relu', kernel_regularizer=regularizers.L1L2(l1=0.001, l2=0.1))) # Lasso for feature selection\n    model.add(layers.Dropout(0.5))\n    #model.add(layers.Dense(50, activation='relu', kernel_regularizer=regularizers.L1L2(l1=0.001, l2=0.1)))\n    #model.add(layers.Dropout(0.5))\n    #model.add(layers.Dense(256,kernel_regularizer='l2', activation='relu'))\n    #model.add(layers.Dropout(0.5))\n    #model.add(layers.Dense(256, activation='relu', kernel_regularizer='l1')) # Lasso for feature selection\n    #model.add(layers.Dropout(0.5))\n    #model.add(layers.Dense(128, activation='relu', kernel_regularizer='l1'))\n    #model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(outclass, activation=sigma))\n    \n    return model","d6c15b26":"network = CNN(input_shape=(image_size, image_size, 3),\n                  outclass=5, # the number of output labels \n                  sigma='softmax')\n\nprint(network.input_shape, network.output_shape)\n#network.summary()\n\n'''for layer in network.layers[0].layers:\n    print(layer.trainable)'''","06121c08":"# network.load_weights(mcp_fpath)","c30d5160":"epochs=20\n\n# optimizer\nopt = optimizers.Adam(learning_rate=1e-3)\n\n# checkpoint\n## 0_temp.h5, 1_temp.h5, ...\nmcp_fpath ='.\/3_temp.h5'\n# or each best and store as \n## mcp_fpath = '.\/weights\/baseline\/weights.{epoch:02d}-{val_loss:.2f}.hdf5'\nmcp = ModelCheckpoint(filepath=mcp_fpath, \n                      save_best_only=True,\n                      save_weights_only=False, # for load model\n                      monitor='val_loss', \n                      mode='auto')\n\n# compile \nnetwork.compile(loss='categorical_crossentropy', \n                optimizer=opt, \n                metrics=['accuracy'])","4deff241":"# training and history\n## pass the DirectoryIterator as the args\n## then no need to specify y, and batch_size (already in the Iterator)\ntraining = network.fit(x=train_generator, \n                      epochs=epochs,\n                      steps_per_epoch=train_generator.samples\/train_generator.batch_size, \n                      validation_data=validation_generator,\n                      validation_steps=validation_generator.samples\/validation_generator.batch_size,\n                      verbose=2,\n                      callbacks=[mcp]) # list of the CallBack instances","d0f2e7c3":"import matplotlib.pyplot as plt\n\nprint(training.history.keys())\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.title('model '+ 'loss')\nplt.plot(np.arange(1, len(training.history['loss'])+1), training.history['loss'], label='loss')\nplt.plot(np.arange(1, len(training.history['loss'])+1), training.history['val_loss'], label='val_loss')\nplt.legend(loc='best')\n\nplt.subplot(1, 2, 2)\nplt.title('model '+ 'acc')\nplt.plot(np.arange(1, len(training.history['loss'])+1), training.history['accuracy'], label='accuracy')\nplt.plot(np.arange(1, len(training.history['loss'])+1), training.history['val_accuracy'], label='val_accuracy')\nplt.legend(loc='best')\n\nplt.show()","9ac9cfc0":"# initialize the model weights with the callbacks \nnetwork.load_weights(mcp_fpath)","3cf1df65":"# load the test data\n## normalize it before input the data to save space\ntest_datagen = ImageDataGenerator(\n    rescale= 1.\/255,\n    preprocessing_function=preprocess_input)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory = test_dir,\n    target_size=(image_size,image_size),\n    batch_size=batch_size,\n    class_mode=None, # only for load the data, no y\n    shuffle=False)","dcb92717":"# predict\n## with steps=None, it will run till the data is exhausted\npred = network.predict(x=test_generator, verbose=1, steps=None)\n\n## with the categorical pred after softmax, \n## the max will be the best prediction\npred = np.argmax(pred,axis=1)\nprint(pred.shape)\nprint(pred)","73488fb9":"# map to the required classmap\nclassmap = pd.read_csv('..\/input\/aia-dt4-who-is-she\/classmap.csv',header=None)\nclassmap = dict(classmap.values)\npred_class = list(train_generator.class_indices.keys())\nprint(classmap, end='\\n\\n')\nprint(pred_class)\n\npred_classmap = np.array([classmap[pred_class[i]] for i in pred])\nprint(pred_classmap)","49e882ca":"# save the prediction to a csv file\nfname = [f[12:22] for f in test_generator.filenames]\n\nprint(type(fname), type(pred_classmap))\n\nresult = pd.DataFrame({\"id\": fname,\n                      \"class\":pred_classmap})\nprint(result.head(10))\n\nresult.to_csv('.\/result.csv',index=None)","1f493d5c":"Build Model","41e913c6":"Predict","08804f50":"Load Data"}}