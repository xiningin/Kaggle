{"cell_type":{"82d53ba1":"code","9beb682f":"code","97769d89":"code","cc25e863":"code","689d677c":"code","0c0156f3":"code","e9840eea":"code","87e39b30":"code","353727c8":"code","3145d93b":"markdown","c00f21bb":"markdown","ab115ebd":"markdown","d71e329d":"markdown"},"source":{"82d53ba1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9beb682f":"import pickle\nimport numpy as np\nimport pandas as pd","97769d89":"train_pickle_file = '..\/input\/pickling\/train.csv.pandas.pickle'\ntrain = pickle.load(open(train_pickle_file, 'rb'))\n\nfeatures = [c for c in train.columns if \"feature\" in c]\ntrain = train[train['weight'] != 0]\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain.fillna(train.mean(),inplace=True)\n\nf_mean = np.mean(train[features[1:]].values,axis=0)\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\ngroups = train['date'].values\n\ny = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T #Multitarget","cc25e863":"valid = train.loc[(train.date >= 450) & (train.date < 500)].reset_index(drop=True)\ntrain = train.loc[train.date < 450].reset_index(drop=True)\n\nX_train = train.loc[:, train.columns.str.contains('feature')].values\ny_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n\nX_valid = valid.loc[:, valid.columns.str.contains('feature')].values\ny_valid = np.stack([(valid[c] > 0).astype('int') for c in resp_cols]).T","689d677c":"import xgboost as xgb\nfrom tqdm import tqdm\n\n\nparams_1 = {'n_estimators': 494, 'max_depth': 8, 'min_child_weight': 6, 'learning_rate': 0.009624384025871735, \n            'subsample': 0.8328412036014541, 'gamma': 0, 'colsample_bytree': 0.715303237773365,\n           'objective':'binary:logistic', 'eval_metric': 'auc','tree_method': 'hist', 'random_state': 42,}\n","0c0156f3":"TRAINING= False\n\nif TRAINING:\n    model = xgb.XGBClassifier(**params_1,n_jobs=-1)\n    model.fit(X_train, y_train[:,3], eval_set=[(X_valid, y_valid[:,3])], eval_metric='auc',verbose=100, callbacks = [xgb.callback.EarlyStopping(rounds=300,save_best=True)])\n    pickle.dump(model,open(\".\/simple-xgb.dat\",\"rb\"))\nelse:\n    model = pickle.load(open(\"..\/input\/jsxgb\/simple-xgb.dat\",\"rb\"))","e9840eea":"from tqdm import tqdm\nimport janestreet\nfrom numba import njit\nenv = janestreet.make_env()\nenv_iter = env.iter_test()","87e39b30":"@njit\ndef fillna_npwhere_njit(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array\ntest_df_columns = ['weight'] + [f'feature_{i}' for i in range(130)] + ['date']\nindex_features = [n for n,col in enumerate(test_df_columns) if col in features]","353727c8":"for (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].values[0]>0:\n        x_tt = test_df.values[0][index_features].reshape(1,-1)\n        x_tt[:, 1:] = fillna_npwhere_njit(x_tt[:, 1:][0], f_mean)\n        y_pred = model.predict(x_tt)\n        pred_df.action = int(y_pred)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","3145d93b":"# Train test split","c00f21bb":"# prediction","ab115ebd":"# Train Model","d71e329d":"# load data"}}