{"cell_type":{"5de6856f":"code","2e3d879f":"code","d4a153fb":"code","c5027715":"code","afe77d70":"code","05010b14":"code","c1742930":"code","5a56c887":"code","2d4b113f":"code","278568b7":"code","fe3aa0d3":"code","55180d7e":"code","4fdb98e8":"code","62fac409":"code","02aa7c24":"code","b86f4d60":"markdown","e1d5443e":"markdown","9a7565b7":"markdown"},"source":{"5de6856f":"import numpy as np\nimport tensorflow as tf\nimport os.path\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path","2e3d879f":"x_train_path= Path('..\/input\/famous-iconic-women\/output\/train')\nx_test_path= Path('..\/input\/famous-iconic-women\/output\/valid')\n\nfilepaths_train = list(x_train_path.glob(r'**\/*.jpg'))\nfilepaths_test = list(x_test_path.glob(r'**\/*.jpg'))","d4a153fb":"def proc_img(filepath):\n    \n\n    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepath))\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df\n\n\ntrain_df = proc_img(filepaths_train)\ntest_df = proc_img(filepaths_test)\n\n\n# Show the result\ntrain_df.head(5)","c5027715":"print(f'Number of training pictures: {train_df.shape[0]}')\nprint(f'Number of test pictures: {test_df.shape[0]}')\nprint(f'Number of labels: {train_df.shape[1]}')","afe77d70":"from PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","05010b14":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","c1742930":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    subset='training',\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    subset='validation',\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","5a56c887":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","2d4b113f":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(64, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=20,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","278568b7":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","fe3aa0d3":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","55180d7e":"pred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n","4fdb98e8":"from sklearn.metrics import classification_report\ny_test = list(test_df.Label)\nprint(classification_report(y_test, pred))","62fac409":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (20,15))\nsns.heatmap(cf_matrix, annot=False, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\nplt.title('Normalized Confusion Matrix')\nplt.show()","02aa7c24":"fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\nplt.tight_layout()\nplt.show()","b86f4d60":"making model\/ using pre-trained model","e1d5443e":"Train model","9a7565b7":"data processing and data augmentation "}}