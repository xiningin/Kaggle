{"cell_type":{"b374848d":"code","cd32066e":"code","f47a9199":"code","ef4eecab":"code","a3382fb7":"code","aa8ed6e1":"code","1250bff7":"code","d7bd339d":"code","90a7ceb5":"code","b666d01c":"code","369ab53d":"code","09bc304d":"code","ee2ca21c":"code","a894a870":"code","a88a65c5":"code","646c9bb8":"code","27178cc8":"markdown","e4c06c90":"markdown","7942ea60":"markdown","56d3f56e":"markdown","8d029cf3":"markdown","82e4750b":"markdown","8f00ad3d":"markdown","883901f7":"markdown","67a36075":"markdown","79179e23":"markdown","27fea09f":"markdown","9ebf2d1a":"markdown","d4d40cf5":"markdown","e89e9103":"markdown"},"source":{"b374848d":"import os\nimport joblib\nimport tqdm\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Sequential","cd32066e":"INPUT_POINTS = '..\/input\/soybean_2019_2020_samples.gpkg'\nINPUT_DATA = '..\/input\/soybean_southamerica_mod13q1_evi_2000_2019.csv'\n\nFIELD_ID = 'fid'\nFIELD_TIMESTAMP = 'timestamp'\n\n\nTRAIN_FEATURES = ['evi']\nTRAIN_VALUES = 500\n\nPREDICT_FEATURE = 'evi'\nPREDICT_START_DATE = '2019-01-01'\nPREDICT_END_DATE = '2019-12-31'\nPREDICT_VALUES = 23\n\nSCALER_PATH = '\/kaggle\/working\/lstm_scaler.save'\nMODEL_PATH = '\/kaggle\/working\/lstm_trained_model.h5'","f47a9199":"gdf = gpd.read_file(INPUT_POINTS)","ef4eecab":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\n# We restrict to South America.\nax = world[world.continent == 'South America'].plot(color='white', edgecolor='black', figsize=(20, 15))\n\n# We can now plot our ``GeoDataFrame``.\ngdf.plot(ax=ax, color='orange')\nplt.title('Soybean South America: 50k samples', fontsize=16)\nplt.show()","a3382fb7":"df = pd.read_csv(INPUT_DATA)\ndf.tail()","aa8ed6e1":"all_series = df[FIELD_ID].dropna().unique()\nlen(all_series)","1250bff7":"trainining_ids, test_ids = train_test_split(all_series, test_size=0.10, random_state=101)\nlen(trainining_ids), len(test_ids)","d7bd339d":"def load_dataset(ids, dataset, train_values=500, predict_values=23):\n    x = []\n    y = []\n\n    for id in tqdm.tqdm(ids):\n        data = dataset[(dataset[FIELD_ID] == id)]\n        index = pd.DatetimeIndex(pd.to_datetime(data[FIELD_TIMESTAMP],  unit='ms'))\n        data.index = index\n\n        x_data = data.loc[:PREDICT_START_DATE][TRAIN_FEATURES].dropna()\n        y_data = data.loc[PREDICT_START_DATE:PREDICT_END_DATE][PREDICT_FEATURE].dropna()\n\n        if len(y_data) != predict_values:\n            continue\n\n        x_data = tf.keras.preprocessing.sequence.pad_sequences([x_data], maxlen=train_values, dtype='float32')[0]\n\n        x.append(x_data)\n        y.append(y_data.values)\n\n    return np.array(x), np.array(y)\n\ntrain_x_data, train_y_data  = load_dataset(ids=trainining_ids, \n                             dataset=df, \n                             train_values=TRAIN_VALUES, \n                             predict_values=PREDICT_VALUES)\n\ntrain_x_data.shape, train_y_data.shape","90a7ceb5":"lstm_model = Sequential()\n\ninput_shape = (train_x_data.shape[1], 1)\n\nlstm_model.add(LSTM(128, return_sequences=True, input_shape=input_shape))\n\nlstm_model.add(LSTM(128))\n\nlstm_model.add(Dense(train_y_data.shape[1]))\n\nlstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n\ntf.keras.utils.plot_model(lstm_model, show_shapes=True, to_file='\/kaggle\/working\/model.png')","b666d01c":"if os.path.exists(SCALER_PATH):\n    print(\"Loading saved scaler...\")\n    scaler = joblib.load(SCALER_PATH) \nelse: \n    scaler = MinMaxScaler()\n    scaler.fit(train_x_data.reshape(-1, train_x_data.shape[-1]))\n    joblib.dump(scaler, SCALER_PATH)","369ab53d":"for i, value in enumerate(train_x_data):\n    value = value[~np.isnan(value).any(axis=1)]\n    train_x_data[i] = scaler.transform(value)\n\nfor i, value in enumerate(train_y_data):\n    value = value[~np.isnan(value).any()]\n    train_y_data[i] = scaler.transform(value)","09bc304d":"callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=True\n)\n\nif os.path.exists(MODEL_PATH):\n    print(\"Loading trained model...\")\n    lstm_model = tf.keras.models.load_model(MODEL_PATH)\nelse:\n    history = lstm_model.fit(train_x_data, train_y_data, \n                        epochs=100, \n                        batch_size=32, \n                        validation_split=0.25, \n                        verbose=1, \n                        callbacks=[callback]) \n\n    # plot history\n    plt.figure(figsize=(20,8))\n    plt.plot(history.history['loss'], label='Train loss')\n    plt.plot(history.history['val_loss'], label='Validation loss')\n    plt.legend()\n    plt.ylabel('Model loss')\n    plt.xlabel('Epochs')\n    plt.show()\n    plt.savefig('\/kaggle\/working\/model_loss.png', dpi=300, bbox_inches='tight')","ee2ca21c":"test_x_data, test_y_data  = load_dataset(ids=test_ids, \n                             dataset=df, \n                             train_values=TRAIN_VALUES, \n                             predict_values=PREDICT_VALUES)\n\ntest_x_data.shape, test_y_data.shape\n\nfor i, value in enumerate(test_x_data):\n    value = value[~np.isnan(value).any(axis=1)]\n    test_x_data[i] = scaler.transform(value)\n\nfor i, value in enumerate(test_y_data):\n    value = value[~np.isnan(value).any()]\n    test_y_data[i] = scaler.transform(value)","a894a870":"lstm_model.evaluate(x=test_x_data, y=test_y_data)","a88a65c5":"def expected_vs_predicted(input, expected, predicted):\n    expected_values = expected.copy()\n    \n    index = expected.index.to_pydatetime()\n\n    expected_values.index = index\n    \n    fitted_series = pd.Series(predicted)\n    fitted_series.index=index\n\n    plt.figure(figsize=(20,15))\n    plt.subplot(211)\n\n    # plotar gr\u00e1fico\n    plt.plot(input, color='green')\n    plt.plot(fitted_series, linestyle='--', color='orange')\n    plt.ylim(0, 1)\n    plt.legend(['real', 'previsto'], loc='upper left')\n\n    rmse = np.sqrt(mean_squared_error(expected_values, predicted))\n\n    return rmse","646c9bb8":"for id in test_ids[:50]:\n    data = df[(df[FIELD_ID] == id)]\n    index = pd.DatetimeIndex(pd.to_datetime(data[FIELD_TIMESTAMP],  unit='ms'))\n    data.index = index\n\n    input = data.loc[:PREDICT_START_DATE][TRAIN_FEATURES].dropna()\n    input = tf.keras.preprocessing.sequence.pad_sequences([input], maxlen=TRAIN_VALUES, dtype='float32')[0]\n\n    expected = data.loc[PREDICT_START_DATE:PREDICT_END_DATE][PREDICT_FEATURE]\n    expected = expected.dropna()\n\n    if len(expected) != PREDICT_VALUES:\n        continue\n        \n    predicted = lstm_model.predict(np.array([input]))[0]\n\n    # inverse transform\n    reescaled_expected = scaler.inverse_transform(expected.values.reshape(expected.values.shape[0], 1)).flatten()\n    reescaled_predicted = scaler.inverse_transform(predicted.reshape(predicted.shape[0], 1)).flatten()\n\n    reescaled_expected = pd.Series(reescaled_expected, index=expected.index)\n\n    rmse = expected_vs_predicted(data[TRAIN_FEATURES].loc['2015-01-01':].dropna(), reescaled_expected, reescaled_predicted)\n    plt.title(\"Actual vs Predicted Vegetation Index | Sample ID: %s. RMSE: %.3f\" % (str(id), rmse, ), fontsize=20)\n    plt.ylabel('Vegetation Index (EVI)', fontsize=16)\n    plt.xlabel(None)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.legend(['Actual', 'Predicted'], fontsize=16)\n    plt.show()","27178cc8":"# Introduction\n\nThe goal of this work is to predict the vegetation index behavior of soybean areas located in south america region.\n\nFor this work, we used 50k soybean samples collected from thematic maps produced by the [Global Land Analysis & Discovery group](https:\/\/glad.umd.edu\/) (GLAD) and vegetation index time series obtained from the [MOD13Q1](https:\/\/lpdaac.usgs.gov\/products\/mod13q1v006\/) product of the [Moderate-Resolution Imaging Spectroradiometer](https:\/\/modis.gsfc.nasa.gov\/about\/).","e4c06c90":"# Plot all 50k soybean points","7942ea60":"# Load training dataset","56d3f56e":"# Split time series in train and test","8d029cf3":"# Train model","82e4750b":"# Imports","8f00ad3d":"# Results","883901f7":"# Normalize data","67a36075":"# Settings","79179e23":"# Evaluate model","27fea09f":"# Load time series","9ebf2d1a":"# LSTM Model","d4d40cf5":"# Load soybean samples","e89e9103":"# All time series ids"}}