{"cell_type":{"cf908635":"code","48a598a7":"code","9bded359":"code","7cde3373":"code","b0c8a0c7":"code","6933504c":"code","29edaa2d":"code","a6cc023f":"code","18867d58":"code","4f79ea7d":"code","8caca674":"code","31e8fdca":"code","6b19bd33":"code","626f8e76":"code","7abd39c2":"code","3bf650bd":"code","40a2bf3d":"code","56074fe2":"code","528ed221":"code","aa4e5f79":"code","75d501ff":"code","a91b4141":"code","56a99500":"code","5fc9aaaf":"code","6ff04775":"code","2b686c51":"code","63ab961b":"code","1d5ce1e7":"code","b54312bc":"code","3ef9ce51":"code","29f2541b":"code","98bb5b12":"code","156160b3":"code","a5abdd52":"code","b23cf8ca":"code","f966bb28":"markdown","8dd5164f":"markdown","bb302f01":"markdown","33527b45":"markdown","7084ff11":"markdown","8e99f35d":"markdown","dc9e960e":"markdown","b7ef9a6f":"markdown","7b052f4a":"markdown","f156f367":"markdown","09489a91":"markdown"},"source":{"cf908635":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","48a598a7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsns.set(style=\"whitegrid\")","9bded359":"df=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","7cde3373":"df.shape","b0c8a0c7":"df.columns","6933504c":"df.dtypes","29edaa2d":"df.isnull().sum()","a6cc023f":"df=df.drop('Unnamed: 32', axis=1)","18867d58":"df.columns","4f79ea7d":"from scipy.stats import pearsonr\ncorr, _ = pearsonr(df['radius_mean'], df['texture_mean'])\nprint('Pearsons correlation: %.3f' % corr)\n\n","8caca674":"cols=['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","31e8fdca":"sns.kdeplot(df['radius_mean'])\n","6b19bd33":"sns.kdeplot(df['texture_mean'])","626f8e76":"sns.kdeplot(df['perimeter_mean'])","7abd39c2":"sns.kdeplot(df['area_mean'])","3bf650bd":"sns.kdeplot(df['fractal_dimension_mean'])","40a2bf3d":"from scipy.stats import spearmanr\nfrom scipy.stats import pearsonr\n","56074fe2":"coef, p = spearmanr(df['radius_mean'], df['texture_mean'])\nprint('Spearmans correlation coefficient: %.3f' % coef)\n# interpret the significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","528ed221":"coef, p = pearsonr(df['radius_mean'], df['texture_mean'])\nprint('Pearson correlation coefficient: %.3f' % coef)\n# interpret the significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","aa4e5f79":"df[['radius_mean', 'texture_mean']].corr()","75d501ff":"from scipy.stats import kendalltau","a91b4141":"coef, p = kendalltau(df['radius_mean'], df['texture_mean'])\nprint('Kendall correlation coefficient: %.3f' % coef)\n# interpret the significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","56a99500":"def pearson_r(x, y):\n    x_bar, y_bar = np.mean(x), np.mean(y)\n    cov_est = np.sum((x - x_bar) * (y - y_bar))\n    std_x_est = np.sqrt(np.sum((x - x_bar)**2))\n    std_y_est = np.sqrt(np.sum((y - y_bar)**2))\n    return cov_est \/ (std_x_est * std_y_est)","5fc9aaaf":"pearson_r(df['radius_mean'], df['texture_mean'])","6ff04775":"from scipy.stats import rankdata\ndef spearmans_correlation_coefficient(X, Y):\n    rX, rY = rankdata(X), rankdata(Y)\n    return pearson_r(rX, rY)","2b686c51":"spearmans_correlation_coefficient(df['radius_mean'], df['texture_mean'])","63ab961b":"plt.style.use('fivethirtyeight')\n\nsns.jointplot(x=df['radius_mean'], y=df['texture_mean'], hue=df['diagnosis'])","1d5ce1e7":"g = sns.jointplot(data=df, x=df['radius_mean'], y=df['texture_mean'])\ng.plot_joint(sns.kdeplot, color=\"r\", zorder=0, levels=6)\ng.plot_marginals(sns.rugplot, color=\"r\", height=-.15, clip_on=False)","b54312bc":"sns.jointplot(x=rankdata(df['radius_mean']), y=rankdata(df['texture_mean']), hue=df['diagnosis'])","3ef9ce51":"def joint_plot(X, Y, z):\n    sns.jointplot(x=X, y=Y, hue=z)\n    print(\"Pearson's correlation:-\",pearson_r(X,Y))\n    print(\"Spearman coefficient:-\",spearmans_correlation_coefficient(X,Y))","29f2541b":"joint_plot(df['radius_mean'], df['texture_mean'], df['diagnosis'])","98bb5b12":"df.columns","156160b3":"joint_plot(df['radius_mean'], df['perimeter_mean'], df['diagnosis'])","a5abdd52":"joint_plot(df['radius_mean'], df['area_mean'], df['diagnosis'])","b23cf8ca":"corr = df.corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","f966bb28":"from scipy.stats import pearsonr\n","8dd5164f":"# Spearman\u2019s Rank Correlation\n* t may also be called Spearman\u2019s correlation coefficient and is denoted by the lowercase greek letter rho (p)\n* This statistical method quantifies the degree to which ranked variables are associated by a monotonic function, meaning an increasing or decreasing relationship\n* As a statistical hypothesis test, the method assumes that the samples are uncorrelated (fail to reject H0)\n*","bb302f01":"# Checking the missing values\n* As we can see there is no missing value excepet the one feature i.e. \"Unnamed: 32\". In this column all the row value are missing","33527b45":"* Similarly we plot for all the features and come out of the best analysis.\n* Like wwise we ll find out the correlation coeffiecient value \n","7084ff11":"# Kendall\u2019s Rank Correlation\n* coefficient is often referred to by the lowercase Greek letter tau (t)\n* The intuition for the test is that it calculates a normalized score for the number of matching or concordant rankings between the two samples\n* the test is also referred to as Kendall\u2019s concordance test.","8e99f35d":"# Jointplot-  \n* Great way to visualize the individuals distributions and joint distribution as well","dc9e960e":"# Conclusion\n* The features in dataset are almost normaly distributed \n* Now as per the assumption we can se the pearson's correlation coefficient and other correlation coeffiecient ","b7ef9a6f":"# Dropping the columns \n* Unnecessary feature is going to be dropped \n* As it can be seen that \"Unnamed: 32\" is unwanted columns which is dropped","7b052f4a":"# Import Library","f156f367":"# Pearson's Correlation Coefficient \n* Correlation refers to the association between the observed values of two variables\n* Correlation quantifies this association, often as a measure between the values -1 to 1 for perfectly negatively correlated and perfectly positively correlated. The calculated correlation is referred to as the \u201ccorrelation coefficient.\n* The correlation between two variables that each have a Gaussian distribution can be calculated using standard methods such as the Pearson\u2019s correlation\n* This procedure cannot be used for data that does not have a Gaussian distribution. Instead, rank correlation methods must be used.","09489a91":"# Data type of the features\n* Diagnosis- it is Nominal Scale\n* Rest are the ratio scales "}}