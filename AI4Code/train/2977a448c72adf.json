{"cell_type":{"c44c6f48":"code","79240fae":"code","d6595178":"code","0521fcd8":"code","f8b57d96":"code","f0b23f7a":"code","5fe142b9":"code","038ac880":"code","091d03b7":"code","e8e548a7":"code","02241d65":"code","8052d8e0":"code","68529590":"code","2e75aaf9":"code","26c288c9":"code","a14cb135":"code","5d4934ce":"code","1111c8de":"code","213188f0":"code","b88be9a9":"code","ab73093b":"code","68cc13e9":"code","ab5ffef5":"code","adedf6ef":"code","f8f31720":"markdown"},"source":{"c44c6f48":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","79240fae":"data = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ndata.info()","d6595178":"data.head()","0521fcd8":"cols =  data.columns\ncols","f8b57d96":"X = data[cols[1:]].values\nY = data['label']","f0b23f7a":"Y.value_counts().plot('bar');","5fe142b9":"Y = pd.get_dummies(Y).values.tolist()\ntest = pd.read_csv('..\/input\/fashion-mnist_test.csv')\ntest = test[cols[1:]].values","038ac880":"image_size = 28\nlabel_size = 10\nhidden_size =1024\nlearning_rate =0.001\nbatch_size =256\nsplit = 0.2","091d03b7":"trainX, validationX, trainY, validationY = train_test_split(X,Y,test_size=split,random_state=42)\nvalidationX.shape","e8e548a7":"x_input = tf.placeholder(tf.float32, shape=(None,image_size*image_size))\ny_labels = tf.placeholder(tf.float32, shape=(None,label_size))\ndropout = tf.placeholder(tf.bool)","02241d65":"x_image = tf.reshape(x_input,[-1,image_size,image_size,1])\n\nconv1 = tf.layers.conv2d(inputs=x_image, kernel_size=[5,5], filters=32, padding='same',activation= tf.nn.elu)\npool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],strides=2)\n\nconv2 = tf.layers.conv2d(inputs=pool1, kernel_size= [5,5], filters= 64, padding='same',activation= tf.nn.elu)\npool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2)\nflatten = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\nhidden = tf.layers.dense(inputs=flatten,units=hidden_size,activation=tf.nn.elu)\ndropouts = tf.layers.dropout(inputs=hidden,rate= 0.65,training= dropout)\n\ny_output = tf.layers.dense(inputs=dropouts,units=label_size)","8052d8e0":"loss = tf.reduce_min(tf.losses.softmax_cross_entropy(logits=y_output,onehot_labels=y_labels))\noptimizer = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(loss)\n#optimizer = tf.train.AdamOptimizer(0.03).minimize(loss),global_step=tf.train.get_global_step()\nprediction=tf.argmax(y_output,1)","68529590":"correct_prediction = tf.equal(prediction, tf.argmax(y_labels,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    ","2e75aaf9":"sess =  tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())","26c288c9":"l = len(trainX) - len(trainX)%batch_size","a14cb135":"for n in range(5):\n    print(\"Epoch:\", n+1)\n    for i in range(0,l,batch_size):\n        #input_batch, labels_batch = sess.run(data.repeat().batch(512).make_one_shot_iterator().get_next())\n        #print(input_batch.shape,labels_batch.shape,type(input_batch),type(labels_batch),input_batch[0])\n        #print(labels_batch.dtype,labels_batch[0])\n        feed_dict = {x_input: trainX[i:i+batch_size], y_labels:trainY[i:i+batch_size], dropout: True}\n        feed_dict_test = {x_input: trainX[i:i+batch_size], y_labels: trainY[i:i+batch_size], dropout: False}\n\n        #plt.imshow(np.reshape(input_batch[5],(28,28)),cmap='gray');\n        if (i\/\/batch_size)%50 == 0:\n            train_accuracy = accuracy.eval(feed_dict=feed_dict_test)\n            print(\"Step %d, training batch accuracy %.3f\"%(i\/\/batch_size, train_accuracy))\n        sess.run(optimizer,feed_dict=feed_dict)\n    \nprint(\"The end of training!\")","5d4934ce":"print(\"Validation accuracy: %.3f\"%accuracy.eval(feed_dict={x_input: validationX[:200], y_labels: validationY[:200], dropout: False}))","1111c8de":"predictions = sess.run(prediction, feed_dict={x_input:validationX[:512] ,dropout: False})","213188f0":"classes = ['T-shirt\/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\nclasses","b88be9a9":"n = 32\nfig = plt.figure(figsize=(10,10))\nfor i,p in enumerate(predictions[:n]):\n    ax = fig.add_subplot(8,8,i+1)\n    plt.title(f'''\\n\\n {classes[p]}''')\n    plt.axis(\"off\")\n    ax.imshow(np.reshape(validationX[:512][i],(28,28)),cmap='gray');","ab73093b":"v = pd.Series([validationY[i].index(1) for i in range(512)])\n#p = pd.Series([classes[predictions[i]] for i in range(512)])","68cc13e9":"# Create a confusion matrix on training data.\nplt.figure(figsize=(10,10))\ncm = tf.confusion_matrix(v.values,predictions)\ncm_out = sess.run(cm)\n\n# Normalize the confusion matrix so that each row sums to 1.\ncm_out = cm_out.astype(float) \/ cm_out.sum(axis=1)[:, np.newaxis]\n\nsns.heatmap(cm_out, annot=True, xticklabels=classes, yticklabels=classes);\nplt.xlabel(\"Predicted\");\nplt.ylabel(\"True\");\nplt.title('Confusion Matrix Fashion Dress');","ab5ffef5":"test_preds = []\ntest_preds.extend(sess.run(prediction, feed_dict={x_input:test,dropout: False}))\nprint(len(test_preds))\nsess.close()\ntest_preds[:10]","adedf6ef":"fig = plt.figure(figsize=(10,10))\ntv = test[100:116]\nfor i,p in enumerate(test_preds[100:116]):\n    ax = fig.add_subplot(4,4,i+1)\n    plt.title(f''' \\n Prediction:{classes[p]}''')\n    plt.axis('off')\n    ax.tick_params(axis='both', which='both')\n    ax.imshow(np.reshape(tv[i],(28,28)),cmap='gray');","f8f31720":"## Define Placeholders conv2d"}}