{"cell_type":{"af5b93c4":"code","333b87ef":"code","b4425d46":"code","0dc24bd3":"code","48b2f92a":"code","bba86697":"code","d4eb2a18":"code","3f0c157d":"code","61c35c66":"code","300862fd":"code","80e26bdf":"code","08608d94":"code","9193bdd5":"code","6ede78f3":"code","e923ca3b":"code","16cd7b28":"code","ddfd1eea":"code","9f506ce3":"markdown","bacc22df":"markdown","49ee2c0b":"markdown"},"source":{"af5b93c4":"a = input('Put your enrollment no. over here:- ')","333b87ef":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report \nfrom sklearn.datasets import load_iris","b4425d46":"#Plotting Function\ndef visualize_classifier(classifier, X, y):\n    # Define the minimum and maximum values for X and Y\n    # that will be used in the mesh grid\n    min_x, max_x = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0\n    min_y, max_y = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0\n\n    # Define the step size to use in plotting the mesh grid \n    mesh_step_size = 0.01\n\n    # Define the mesh grid of X and Y values\n    x_vals, y_vals = np.meshgrid(np.arange(min_x, max_x, mesh_step_size), np.arange(min_y, max_y, mesh_step_size))\n\n    # Run the classifier on the mesh grid\n    output = classifier.predict(np.c_[x_vals.ravel(), y_vals.ravel()])\n\n    # Reshape the output array\n    output = output.reshape(x_vals.shape)\n\n    # Create a plot\n    plt.figure()\n\n    # Choose a color scheme for the plot \n    plt.pcolormesh(x_vals, y_vals, output, cmap=plt.cm.gray)\n\n    # Overlay the training points on the plot \n    plt.scatter(X[:, 0], X[:, 1], c=y, s=75, edgecolors='black', linewidth=1, cmap=plt.cm.Paired)\n\n    # Specify the boundaries of the plot\n    plt.xlim(x_vals.min(), x_vals.max())\n    plt.ylim(y_vals.min(), y_vals.max())\n\n    # Specify the ticks on the X and Y axes\n    plt.xticks((np.arange(int(X[:, 0].min() - 1), int(X[:, 0].max() + 1), 1.0)))\n    plt.yticks((np.arange(int(X[:, 1].min() - 1), int(X[:, 1].max() + 1), 1.0)))\n    \n    plt.title(f'{a}')\n    plt.show()","0dc24bd3":"load_iris = load_iris()\ndf_data= load_iris.data[:,:2]\ndf_target = load_iris.target","48b2f92a":"X_train, X_test, y_train , y_test = train_test_split(df_data,\n                                                    df_target,\n                                                    test_size = 0.25,\n                                                    random_state = 5)","bba86697":"classifier = SVC(kernel = 'poly',gamma = 'auto' ,degree = 3, C = 10)\nclassifier.fit(X_train, y_train)","d4eb2a18":"visualize_classifier(classifier, X_train, y_train)","3f0c157d":"y_test_pred = classifier.predict(X_test)\nvisualize_classifier(classifier, X_test, y_test)","61c35c66":"target_names = ['Class-' + str(int(i)) for i in set(df_target)]\nprint (\"\\n\" + \"#\"*30)\nprint (\"\\nClassifier performance on training dataset\\n\")\nprint(classification_report(y_train,classifier.predict(X_train\n), target_names=target_names))\nprint (\"#\"*30 + \"\\n\") ","300862fd":"df_1 = pd.read_csv('..\/input\/crab-dataset\/crab.csv')\ndf_1.head()","80e26bdf":"df_data = df_1[['FL', 'RW']].to_numpy()\ndf_1['sex'].replace(['F','M'],[0,1],inplace=True)\ndf_target = df_1['sex'].to_numpy()","08608d94":"x_train, x_test, y_train , y_test = train_test_split(df_data,\n                                                    df_target,\n                                                    test_size = 0.25,\n                                                    random_state = 5)","9193bdd5":"classifier = SVC(kernel = 'poly',gamma = 'auto' ,degree = 3, C = 10)\nclassifier.fit(x_train, y_train)","6ede78f3":"visualize_classifier(classifier, x_train, y_train)\n#target_names = ['Class-' + str(int(i)) for i in set(df_target)]\nprint (\"\\n\" + \"#\"*30)\nprint (\"\\nClassifier performance on training dataset\\n\")\nprint(classification_report(y_train,classifier.predict(x_train)))\nprint (\"#\"*30 + \"\\n\") ","e923ca3b":"kernel = k = 'poly'\ngamma = g = 'auto'\nC = 10","16cd7b28":"classifier = SVC(kernel = k,gamma = g ,degree = 3, C = C)\nclassifier.fit(x_train, y_train)\nvisualize_classifier(classifier, x_train, y_train)\nprint (\"\\n\" + \"#\"*30)\nprint (\"\\nClassifier performance on training dataset\\n\")\nprint(classification_report(y_train,classifier.predict(x_train)))\nprint (\"#\"*30 + \"\\n\") ","ddfd1eea":"kernel = k = 'poly'\ngamma = g = 'scale'\nC = 100\nclassifier = SVC(kernel = k,gamma = g ,degree = 3, C = C)\nclassifier.fit(x_train, y_train)\nvisualize_classifier(classifier, x_train, y_train)\nprint (\"\\n\" + \"#\"*30)\nprint (\"\\nClassifier performance on training dataset\\n\")\nprint(classification_report(y_train,classifier.predict(x_train)))\nprint (\"#\"*30 + \"\\n\") ","9f506ce3":"### Q2. Check the effect of penalty function using C values and gamma for nonlinear kernal based method. ","bacc22df":"# Non Linear SVM","49ee2c0b":"## Q_1). Use Non-linear SVM method for carb data."}}