{"cell_type":{"69d238ce":"code","470c815b":"code","562e842f":"code","f73878c9":"code","ccc3d5b7":"code","cc49a6a1":"code","d7550c5b":"code","219106a5":"code","da9ecfcb":"code","52d88fbb":"code","18ccbcb2":"code","96f05a5b":"code","67b8c1e4":"code","6b343006":"code","dae50226":"code","6f78211c":"code","f25290fc":"code","ccd397e1":"code","8f0cecde":"code","5b01af86":"code","d4cbfae0":"code","e8203e8c":"code","9bea533c":"code","cce6f9c3":"code","c0ff71bd":"code","be649853":"code","208ed7b8":"code","21adf16b":"code","dcfaf583":"code","9b8deebc":"code","bfc18acb":"code","0ced372e":"code","ec48970e":"code","69468f88":"code","ac1b3d87":"code","e014de77":"code","d3771fd5":"code","9d7088cf":"code","1f61bebc":"code","7b790c24":"code","7fdd0408":"code","220e7630":"code","2c256577":"code","a378c13c":"code","70f6df36":"code","3d1263f1":"code","aa085acd":"code","a2574974":"code","ad5c6cde":"code","fc7fbef9":"code","f0b95f6d":"code","459376c3":"code","92744601":"markdown","6c36c44d":"markdown","51b5757b":"markdown","4f0fda8d":"markdown","6fcb055c":"markdown","7197c8e2":"markdown","2f3a8795":"markdown","fbd696bd":"markdown","edde6f98":"markdown","545e18a9":"markdown"},"source":{"69d238ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","470c815b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns\nimport datetime as dt\nimport matplotlib.image as pltimg\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport folium.plugins\nfrom geopy.geocoders import Nominatim\nfrom matplotlib import pyplot\n","562e842f":"world_data=pd.read_csv('\/kaggle\/input\/corona-virus-report\/covid_19_clean_complete.csv')\n\nworld_data.head()\nworld_data.dtypes\nworld_data['Date'] = pd.to_datetime(world_data['Date'])\nworld_data['Date'].max()\nworld_grouped=world_data.loc[world_data['Date']=='2020-05-10']\nworld_grouped=world_grouped.sort_values(['Confirmed'],ascending=False)\nworld_grouped[\"Death Rate (per 100)\"] = np.round(100*world_grouped[\"Deaths\"]\/world_grouped[\"Confirmed\"],2)\nworld_grouped[\"Cure Rate (per 100)\"] = np.round(100*world_grouped[\"Recovered\"]\/world_grouped[\"Confirmed\"],2)\ndisplay(world_grouped.head())\nprint('Confirmed cases worlwide : ',world_grouped['Confirmed'].sum())\nprint('Confirmed deaths worlwide : ',world_grouped['Deaths'].sum())\nprint('Confirmed recovered cases worlwide : ',world_grouped['Recovered'].sum())","f73878c9":"world_grouped.drop(['Lat','Long'],axis=1).groupby(['Country\/Region'],as_index=False).sum().sort_values(['Confirmed'],ascending=False).head(26).style.background_gradient(cmap='Blues',subset=[\"Confirmed\"])\\\n                        .background_gradient(cmap='Reds',subset=[\"Deaths\"])\\\n                        .background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n                        .background_gradient(cmap='Reds',subset=[\"Death Rate (per 100)\"])\\\n                        .background_gradient(cmap='Greens',subset=[\"Cure Rate (per 100)\"])\\\n                        ","ccc3d5b7":"world_confirmed = world_grouped['Confirmed'].sum()\nworld_recovered = world_grouped['Recovered'].sum()\nworld_deaths = world_grouped['Deaths'].sum()\nworld_active = world_confirmed - (world_recovered - world_deaths)\n\nlabels = ['Active','Recovered','Deceased']\nsizes = [world_active,world_recovered,world_deaths]\ncolor= ['#66b3ff','green','red']\nexplode = []\n\nfor i in labels:\n    explode.append(0.05)\n    \nplt.figure(figsize= (15,10))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=9, explode =explode,colors = color)\ncentre_circle = plt.Circle((0,0),0.70,fc='white')\n\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.title('World COVID-19 Cases',fontsize = 20)\nplt.axis('equal')  \nplt.tight_layout()","cc49a6a1":"fig = px.choropleth(world_grouped, locations=\"Country\/Region\", \n                    locationmode='country names', color=\"Confirmed\", \n                    hover_name=\"Country\/Region\", range_color=[1,7000], \n                    color_continuous_scale=\"aggrnyl\", \n                    title='Countries with Confirmed Cases as of today')\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","d7550c5b":"world_data.groupby(['Date'],as_index=False)[['Confirmed']].sum()","219106a5":"fig = px.line(world_data.groupby(['Date'],as_index=False)[['Confirmed']].sum(), \n             x=\"Date\", y=\"Confirmed\", \n             title='Number of cases worldwide from start COVID-19', \n             width=800, height=700)\nfig.update_traces(marker_color='#008000', opacity=0.8)\n\nfig.update_layout(template = 'plotly_dark')\nfig.show()","da9ecfcb":"import matplotlib.dates as mdates","52d88fbb":"hotspots = ['China','Germany','Iran','Italy','Spain','US','Korea, South','France','Turkey','United Kingdom','India']\ndates = list(confirmed_df.columns[4:])\ndates = list(pd.to_datetime(dates))\ndates_india = dates[8:]\n\ndf1 = confirmed_df.groupby('Country\/Region').sum().reset_index()\ndf2 = deaths_df.groupby('Country\/Region').sum().reset_index()\ndf3 = recovered_df.groupby('Country\/Region').sum().reset_index()\n\nglobal_confirmed = {}\nglobal_deaths = {}\nglobal_recovered = {}\nglobal_active= {}\n\nfor country in hotspots:\n    k =df1[df1['Country\/Region'] == country].loc[:,'1\/30\/20':]\n    global_confirmed[country] = k.values.tolist()[0]\n\n    k =df2[df2['Country\/Region'] == country].loc[:,'1\/30\/20':]\n    global_deaths[country] = k.values.tolist()[0]\n\n    k =df3[df3['Country\/Region'] == country].loc[:,'1\/30\/20':]\n    global_recovered[country] = k.values.tolist()[0]\n    \nfor country in hotspots:\n    k = list(map(int.__sub__, global_confirmed[country], global_deaths[country]))\n    global_active[country] = list(map(int.__sub__, k, global_recovered[country]))\n    \nfig = plt.figure(figsize= (15,15))\nplt.suptitle('Active, Recovered, Deaths in Hotspot Countries and India as of April 20',fontsize = 20,y=1.0)\n#plt.legend()\nk=0\nfor i in range(1,12):\n    ax = fig.add_subplot(6,2,i)\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%b'))\n    ax.bar(dates_india,global_active[hotspots[k]],color = 'green',label = 'Active');\n    ax.bar(dates_india,global_recovered[hotspots[k]],color='grey',label = 'Recovered',alpha=0.6);\n    ax.bar(dates_india,global_deaths[hotspots[k]],color='red',label = 'Death');   \n    plt.title(hotspots[k])\n    handles, labels = ax.get_legend_handles_labels()\n    fig.legend(handles, labels, loc='upper left')\n    k=k+1\n\nplt.tight_layout(pad=3.0)","18ccbcb2":"cases=pd.read_csv('\/kaggle\/input\/covid19-corona-virus-india-dataset\/complete.csv')\ncases.dtypes\n\ncases['Date'] = pd.to_datetime(cases['Date'])\ncases.dtypes\ncases.tail()","96f05a5b":"current_status=cases.loc[cases['Date']=='2020-05-10']\ncurrent_status['active']=current_status['Total Confirmed cases']-(current_status['Cured\/Discharged\/Migrated']+current_status['Death'])\ncurrent_status['mortality']=(current_status['Death']\/current_status['Total Confirmed cases'])*100\n\ntoday=current_status['Total Confirmed cases'].sum()\n\n#cases.loc[cases['Date']=='20-04-2020']\n#yesterday_cases=cases.loc[cases['Date']=='23-04-2020']['Total Confirmed cases'].sum()\n#today-yesterday_cases","67b8c1e4":"population=pd.read_csv('\/kaggle\/input\/covid19-in-india\/population_india_census2011.csv')\npopulation=population.drop(['Rural population','Urban population','Area','Gender Ratio'],axis=1)\ncurrent_status_pop=pd.merge(population,current_status,left_on='State \/ Union Territory',right_on='Name of State \/ UT')","6b343006":"current_status_pop['percentage of population affected']=(current_status_pop['Total Confirmed cases']\/current_status_pop['Population'])*100\ncurrent_status_pop[\"Death Rate (per 100)\"] = np.round(100*current_status_pop[\"Death\"]\/current_status_pop[\"Total Confirmed cases\"],2)\ncurrent_status_pop[\"Cure Rate (per 100)\"] = np.round(100*current_status_pop[\"Cured\/Discharged\/Migrated\"]\/current_status_pop[\"Total Confirmed cases\"],2)","dae50226":"fig = px.line(cases.groupby(['Date'],as_index=False)[['Total Confirmed cases']].sum(), \n             x=\"Date\", y=\"Total Confirmed cases\", \n             title='Number of cases from start COVID-19 ie 30 JAN', \n             width=800, height=700)\nfig.update_traces(marker_color='#008000', opacity=0.8)\n\nfig.update_layout(template = 'plotly_dark')\nfig.show()","6f78211c":"current_status_pop.drop(['Total Confirmed cases (Indian National)','Total Confirmed cases ( Foreign National )','Latitude', 'Longitude','Population','Density','Sno','Name of State \/ UT','Date'],axis=1).sort_values(['Total Confirmed cases'],ascending=False).head(26).style.background_gradient(cmap='Blues',subset=[\"Total Confirmed cases\"])\\\n                        .background_gradient(cmap='Reds',subset=[\"Death\"])\\\n                        .background_gradient(cmap='Greens',subset=[\"Cured\/Discharged\/Migrated\"])\\\n                        .background_gradient(cmap='Purples',subset=[\"active\"])\\\n                        .background_gradient(cmap='YlOrBr',subset=[\"mortality\"])\\\n                        .background_gradient(cmap='Reds',subset=[\"percentage of population affected\"])\\\n                        .background_gradient(cmap='Reds',subset=[\"Death Rate (per 100)\"])\\\n                        .background_gradient(cmap='Greens',subset=[\"Cure Rate (per 100)\"])\\","f25290fc":"current_status['Total Confirmed cases'].sum()","ccd397e1":"india_covid_19 = pd.read_csv('\/kaggle\/input\/covid19-in-india\/covid_19_india.csv')","8f0cecde":"india_covid_19['Date'] = pd.to_datetime(india_covid_19['Date'],dayfirst = True)","5b01af86":"import matplotlib.dates as mdates","d4cbfae0":"all_state = list(india_covid_19['State\/UnionTerritory'].unique())\nall_state.remove('Unassigned')\n#all_state.remove('Nagaland#')\n#all_state.remove('Nagaland')\nlatest = india_covid_19[india_covid_19['Date'] > '24-03-20']\nstate_cases = latest.groupby('State\/UnionTerritory')['Confirmed','Deaths','Cured'].max().reset_index()\nlatest['Active'] = latest['Confirmed'] - (latest['Deaths']- latest['Cured'])\nstate_cases = state_cases.sort_values('Confirmed', ascending= False).fillna(0)\nstates =list(state_cases['State\/UnionTerritory'][0:15])\n\nstates_confirmed = {}\nstates_deaths = {}\nstates_recovered = {}\nstates_active = {}\nstates_dates = {}\n\nfor state in states:\n    df = latest[latest['State\/UnionTerritory'] == state].reset_index()\n    k = []\n    l = []\n    m = []\n    n = []\n    for i in range(1,len(df)):\n        k.append(df['Confirmed'][i]-df['Confirmed'][i-1])\n        l.append(df['Deaths'][i]-df['Deaths'][i-1])\n        m.append(df['Cured'][i]-df['Cured'][i-1])\n        n.append(df['Active'][i]-df['Active'][i-1])\n    states_confirmed[state] = k\n    states_deaths[state] = l\n    states_recovered[state] = m\n    states_active[state] = n\n    date = list(df['Date'])\n    states_dates[state] = date[1:]\n    \ndef calc_movingaverage(values ,N):    \n    cumsum, moving_aves = [0], [0,0]\n    for i, x in enumerate(values, 1):\n        cumsum.append(cumsum[i-1] + x)\n        if i>=N:\n            moving_ave = (cumsum[i] - cumsum[i-N])\/N\n            moving_aves.append(moving_ave)\n    return moving_aves\n\nfig = plt.figure(figsize= (25,17))\nplt.suptitle('5-Day Moving Average of Confirmed Cases in Top 15 States',fontsize = 20,y=1.0)\nk=0\nfor i in range(1,15):\n    ax = fig.add_subplot(5,3,i)\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%b'))\n    ax.bar(states_dates[states[k]],states_confirmed[states[k]],label = 'Day wise Confirmed Cases ') \n    moving_aves = calc_movingaverage(states_confirmed[states[k]],5)\n    ax.plot(states_dates[states[k]][:-2],moving_aves,color='red',label = 'Moving Average',linewidth =3)  \n    plt.title(states[k],fontsize = 20)\n    handles, labels = ax.get_legend_handles_labels()\n    fig.legend(handles, labels, loc='upper left')\n    k=k+1\nplt.tight_layout(pad=3.0)","e8203e8c":"state_cases = india_covid_19.groupby('State\/UnionTerritory')['Confirmed','Deaths','Cured'].max().reset_index()\nstate_cases['Active'] = state_cases['Confirmed'] - (state_cases['Deaths']- state_cases['Cured'])\n","9bea533c":"fig = px.bar(current_status, \n             x=\"Name of State \/ UT\", y=\"Total Confirmed cases\", \n             title='Number of cases per state', \n             text='Total Confirmed cases', \n             orientation='v', \n             width=1400, height=700)\nfig.update_traces(marker_color='#008000', opacity=0.8, textposition='outside')\n\nfig.update_layout(template = 'plotly_dark')\nfig.show()","cce6f9c3":"fig = px.treemap(current_status, path=['Name of State \/ UT'], values='Total Confirmed cases',\n                  color='Total Confirmed cases', hover_data=['Name of State \/ UT'],\n                  color_continuous_scale='dense', title='Current number of cases in India by state')\nfig.show()","c0ff71bd":"import IPython\nIPython.display.HTML('<div class=\"flourish-embed flourish-bar-chart-race\" data-src=\"visualisation\/1977187\" data-url=\"https:\/\/flo.uri.sh\/visualisation\/1977187\/embed\"><script src=\"https:\/\/public.flourish.studio\/resources\/embed.js\"><\/script><\/div>')","be649853":"fig = px.treemap(current_status_pop, path=['Name of State \/ UT'], values='percentage of population affected',\n                  color='percentage of population affected', hover_data=['Name of State \/ UT'],\n                  color_continuous_scale='dense', title='Current percentage of population affected by the virus in India by state')\nfig.show()","208ed7b8":"age_groups=pd.read_csv('\/kaggle\/input\/covid19-in-india\/AgeGroupDetails.csv')\nage_groups.head()\n\nfig = px.bar(age_groups, \n             x=\"AgeGroup\", y=\"TotalCases\", \n             title='Number of cases per Age group', \n             text='TotalCases', \n             orientation='v', \n             width=800, height=700)\nfig.update_traces(marker_color='#008000', opacity=0.8, textposition='outside')\n\nfig.update_layout(template = 'plotly_dark')\nfig.show()\n\n","21adf16b":"state_testing = pd.read_csv('..\/input\/covid19-in-india\/StatewiseTestingDetails.csv')\nstate_testing.sort_values(['TotalSamples'],ascending=False).head(20).style.background_gradient(cmap='Reds')","dcfaf583":"testing=state_testing.groupby('State').sum().reset_index()\nfig = px.bar(testing, \n             x=\"TotalSamples\",y=\"State\", \n             orientation='h',\n             text='TotalSamples',\n             height=800,\n             title='Testing statewise insight')\nfig.update_traces(marker_color='#008000', opacity=0.8, textposition='outside')\n\nfig.update_layout(template = 'plotly_dark')\nfig.show()","9b8deebc":"patients=pd.read_csv('\/kaggle\/input\/covid19-in-india\/IndividualDetails.csv')\npatients.head()\n\ngender_patients=patients.groupby(['gender'],as_index=False)[['notes']].count()\ngender_patients\n\n","bfc18acb":"sizes=[]\nlabels = ['Male', 'Female']\nsizes.append(list(patients['gender'].value_counts())[0])\nsizes.append(list(patients['gender'].value_counts())[1])\nexplode = (0.1, 0)\ncolors = ['#66b3ff','#ff9999']\n\nplt.figure(figsize= (8,8))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n        shadow=True, startangle=90)\n\nplt.title('Percentage of Gender (Ignoring the Missing Values)',fontsize = 20)\nplt.axis('equal')\nplt.tight_layout()","0ced372e":"f,axes = plt.subplots(2, 2, figsize=(15,10))\nsns.distplot( current_status[\"Total Confirmed cases\"] , color=\"blue\", ax=axes[0, 0])\nsns.distplot( current_status[\"Death\"] , color=\"violet\", ax=axes[0, 1])\nsns.distplot( current_status[\"Cured\/Discharged\/Migrated\"] , color=\"olive\", ax=axes[1, 0])\nsns.distplot( current_status[\"active\"] , color=\"orange\", ax=axes[1, 1])\nf.subplots_adjust(hspace=.3,wspace=0.03) ","ec48970e":"ts=cases.groupby(['Date'],as_index=False)[['Total Confirmed cases']].sum()\nts.set_index('Date')\nts.dtypes","69468f88":"from statsmodels.tsa.arima_model import ARIMA\n\nmodel = ARIMA(ts['Total Confirmed cases'], order=(5,2,0))\nmodel_fit = model.fit()\nmodel_fit.summary()","ac1b3d87":"residuals = pd.DataFrame(model_fit.resid)\nresiduals.plot()\npyplot.show()\nresiduals.plot(kind='kde')\npyplot.show()","e014de77":"next_20_day=pd.DataFrame(model_fit.forecast(20))\nmodel_fit.forecast(20)","d3771fd5":"next_20_day","9d7088cf":"next_20_day=next_20_day.reset_index()","1f61bebc":"\nlister=next_20_day.iloc[2].to_list()\nminimum_case=[]\nmaximum_case=[]\nfor i in range(1,21,1):\n    minimum_case.append(lister[i][0])\n    maximum_case.append(lister[i][1])\nminimum_case\n\nimport datetime\ndate_list=[]\nbase = datetime.datetime.today()\ndate_day=[]\ndate_list = [base + datetime.timedelta(days=x) for x in range(20)]\ndate_list\nfor i in range(20):\n    date_day.append(date_list[i].day)\nprint(len(minimum_case))\nprint(len(date_list))\nprint(len(maximum_case))\n\nprint(lister[20])","7b790c24":"predictions=pd.DataFrame(columns=['Date','Best Case scenario','Worst case scenario'])\npredictions['Date'] = date_list\npredictions['Best Case scenario'] = minimum_case\npredictions['Worst case scenario'] = maximum_case\npredictions['Date'] = pd.to_datetime(predictions['Date']).dt.date\npredictions","7fdd0408":"prev_cases=cases.groupby(['Date'],as_index=False)[['Total Confirmed cases']].sum()\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=predictions['Date'], y=predictions['Best Case scenario'],\n                    mode='lines+markers',\n                    name='Predicted Best case scenario'))\nfig.add_trace(go.Scatter(x=predictions['Date'], y=predictions['Worst case scenario'],\n                    mode='lines+markers',\n                    name='Predicted worst case scenario'))\nfig.add_trace(go.Scatter(y= prev_cases['Total Confirmed cases'],x= prev_cases['Date'],\n                    mode='markers', name='markers'))\n\nfig.show()","220e7630":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n# Any results you write to the current directory are saved as output.\ntrain=pd.read_csv('\/kaggle\/input\/coronavirus-2019ncov\/covid-19-all.csv')\n\n#print(\"Number of Country_Region -\", train['Country\/Region'].nunique())\n#print(\"Dates from\", min(train['Date']), \"to day\", max(train['Date']), \"- total of\", train['Date'].nunique(), \"days\")\n#print(\"Countries with Province: \", train[train['Province\/State'].isna()==False]['Country\/Region'].unique())\ntrain.head(5)","2c256577":"country_df = train[train['Country\/Region']=='India'].groupby('Date')['Confirmed','Deaths'].sum()\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\nydata = country_df.Confirmed\nxdata = country_df.day_count\ncountry_df['rate'] = (country_df.Confirmed-country_df.Confirmed.shift(1))\/country_df.Confirmed\ncountry_df['increase'] = (country_df.Confirmed-country_df.Confirmed.shift(1))\n\nplt.plot(xdata, ydata, 'o')\nplt.title(\"India\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()","a378c13c":"from scipy.optimize import curve_fit\nimport pylab\n\n\ndef sigmoid(x,c,a,b):\n     y = c*1 \/ (1 + np.exp(-a*(x-b)))\n     return y\n#country_df.ConfirmedCases\n#country_df.day_count\nxdata = np.array([1, 2, 3,4, 5, 6, 7])\nydata = np.array([0, 0, 13, 35, 75, 89, 91])\n\n#([low_a,low_b],[high_a,high_b])\n#low x --> low b\n#high y --> high c\n#a is the sigmoidal shape.\npopt, pcov = curve_fit(sigmoid, xdata, ydata, method='dogbox',bounds=([0.,0., 0.],[100,2, 10.]))\nprint(popt)\n\nx = np.linspace(-1, 10, 50)\ny = sigmoid(x, *popt)\n\npylab.plot(xdata, ydata, 'o', label='data')\npylab.plot(x,y, label='fit')\npylab.ylim(-0.05, 105)\npylab.legend(loc='best')\npylab.show()","70f6df36":"in_df = train[train['Country\/Region']=='India'].groupby('Date')['Confirmed','Deaths'].sum()\nin_df = in_df[in_df.Confirmed>=100]\n\nfrom scipy.optimize import curve_fit\nimport pylab\nfrom datetime import timedelta\n\nin_df['day_count'] = list(range(1,len(in_df)+1))\nin_df['increase'] = (in_df.Confirmed-in_df.Confirmed.shift(1))\nin_df['rate'] = (in_df.Confirmed-in_df.Confirmed.shift(1))\/in_df.Confirmed\n\n\ndef sigmoid(x,c,a,b):\n     y = c*1 \/ (1 + np.exp(-a*(x-b)))\n     return y\n\nxdata = np.array(list(in_df.day_count)[::2])\nydata = np.array(list(in_df.Confirmed)[::2])\n\npopulation=1.332*10**9\npopt, pcov = curve_fit(sigmoid, xdata, ydata, method='dogbox',bounds=([0.,0., 0.],[population,6, 100.]))\nprint(popt)","3d1263f1":"est_a = 22500\nest_b = 0.18\nest_c = 32\nx = np.linspace(-1, in_df.day_count.max()+50, 50)\ny = sigmoid(x,est_a,est_b,est_c)\npylab.plot(xdata, ydata, 'o', label='data')\npylab.plot(x,y, label='fit',alpha = 0.6)\npylab.ylim(-0.05, est_a*1.05)\npylab.xlim(-0.05, est_c*2.05)\npylab.legend(loc='best')\nplt.xlabel('days from day 1')\nplt.ylabel('confirmed cases')\nplt.title('India')\npylab.show()\n\n\nprint('model start date:',in_df[in_df.day_count==1].index[0])\nprint('model start infection:',int(in_df[in_df.day_count==1].Confirmed[0]))\nprint('model fitted max infection at:',int(est_a))\nprint('model sigmoidal coefficient is:',round(est_b,3))\nprint('model curve stop steepening, start flattening by day:',int(est_c))\nprint('model curve flattens by day:',int(est_c)*2)\ndisplay(in_df.head(3))\ndisplay(in_df.tail(3))","aa085acd":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os\nfrom tqdm.notebook import tqdm\nfrom scipy.integrate import solve_ivp\nimport numpy\nimport datetime\nfrom datetime import timedelta\n\n# Susceptible equation\ndef dS_dt(S, I, R_t, T_inf):\n    return -(R_t \/ T_inf) * I * S\n\n# Exposed equation\ndef dE_dt(S, E, I, R_t, T_inf, T_inc):\n    return (R_t \/ T_inf) * I * S - (T_inc**-1) * E\n\n# Infected equation\ndef dI_dt(I, E, T_inc, T_inf):\n    return (T_inc**-1) * E - (T_inf**-1) * I\n\n# Recovered\/Remove\/deceased equation\ndef dR_dt(I, T_inf):\n    return (T_inf**-1) * I\n\ndef SEIR_model(t, y, R_t, T_inf, T_inc):\n    \n    if callable(R_t):\n        reproduction = R_t(t)\n    else:\n        reproduction = R_t\n        \n    S, E, I, R = y\n    \n    S_out = dS_dt(S, I, reproduction, T_inf)\n    E_out = dE_dt(S, E, I, reproduction, T_inf, T_inc)\n    I_out = dI_dt(I, E, T_inc, T_inf)\n    R_out = dR_dt(I, T_inf)\n    \n    return [S_out, E_out, I_out, R_out]","a2574974":"import datetime\ntrain = pd.read_csv('\/kaggle\/input\/adeconvid19\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/adeconvid19\/test.csv')\ntrain['Date_datetime'] = train['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))\n\npop_info = pd.read_csv('\/kaggle\/input\/covid19-population-data\/population_data.csv')\ncountry_pop = pop_info.query('Type == \"Country\/Region\"')\nprovince_pop = pop_info.query('Type == \"Province\/State\"')\ncountry_lookup = dict(zip(country_pop['Name'], country_pop['Population']))\nprovince_lookup = dict(zip(province_pop['Name'], province_pop['Population']))\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom scipy.integrate import odeint\n\nfrom plotly.offline import iplot, init_notebook_mode\nimport math\nimport bokeh \nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom urllib.request import urlopen\nimport json\nfrom dateutil import parser\nfrom bokeh.layouts import gridplot\nfrom bokeh.plotting import figure, show, output_file\nfrom bokeh.layouts import row, column\nfrom bokeh.resources import INLINE\nfrom bokeh.io import output_notebook\nfrom bokeh.models import Span\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","ad5c6cde":"def plot_model_and_predict(data, pop, solution, title='SEIR model'):\n    sus, exp, inf, rec = solution.y\n    \n    f = plt.figure(figsize=(16,5))\n    ax = f.add_subplot(1,2,1)\n    #ax.plot(sus, 'b', label='Susceptible');\n    ax.plot(exp, 'y', label='Exposed');\n    ax.plot(inf, 'r', label='Infected');\n    ax.plot(rec, 'c', label='Recovered\/deceased');\n    plt.title(title)\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.ylabel(\"Fraction of population\", fontsize=10);\n    plt.legend(loc='best');\n    \n    ax2 = f.add_subplot(1,2,2)\n    preds = np.clip((inf + rec) * pop ,0,np.inf)\n    ax2.plot(range(len(data)),preds[:len(data)],label = 'Predict ConfirmedCases')\n    ax2.plot(range(len(data)),data['ConfirmedCases'])\n    plt.title('Model predict and data')\n    plt.ylabel(\"Population\", fontsize=10);\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.legend(loc='best');\n\nCountry = 'India'\nN = pop_info[pop_info['Name']==Country]['Population'].tolist()[0] # India Population \n\n# Load dataset of Hubei\ntrain_loc = train[train['Country_Region']==Country].query('ConfirmedCases > 0')\nif len(train_loc)==0:\n    train_loc = train[train['Province_State']==Country].query('ConfirmedCases > 0')\n\nn_infected = train_loc['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\nmax_days = len(train_loc)# how many days want to predict\n\n# Initial stat for SEIR model\ns = (N - n_infected)\/ N\ne = 0.\ni = n_infected \/ N\nr = 0.\n\n# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9 # average infectious period\nR_0 = 3.954 # reproduction number\n\n## Solve the SEIR model \nsol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(R_0, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\n## Plot result\nplot_model_and_predict(train_loc, N, sol, title = 'SEIR Model (without intervention)')","fc7fbef9":"from scipy.optimize import minimize\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\n\ndef cumsum_signal(vec):\n    temp_val = 0\n    vec_new = []\n    for i in vec:\n        if i > temp_val:\n            vec_new.append(i)\n            temp_val = i\n        else:\n            vec_new.append(temp_val)\n    return vec_new\n\n# Use a constant reproduction number\ndef eval_model_const(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # R0 become half after intervention days\n    def time_varying_reproduction(t):\n        if t > 80: # we set intervention days = 80\n            return R_0 * 0.5\n        else:\n            return R_0\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['ConfirmedCases'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final\n\n# Use a Hill decayed reproduction number\ndef eval_model_decay(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr, k, L = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions   \n    # Hill decay. Initial values: R_0=2.2, k=2, L=50\n    def time_varying_reproduction(t): \n        return R_0 \/ (1 + (t\/L)**k)\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['ConfirmedCases'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final\n\nlen(train[-7:]),len(train[:-7]),len(train)","f0b95f6d":"import plotly.express as px\nfrom matplotlib import dates\nimport plotly.graph_objects as go\n\ndef fit_model_new(data, area_name, initial_guess=[2.2, 0.02, 2, 50], \n              bounds=((1, 20), (0, 0.15), (1, 3), (1, 100)), make_plot=True, decay_mode = None):\n    \n    if area_name in ['France']:# France last data looks weird, remove it\n        train = data.query('ConfirmedCases > 0').copy()[:-1]\n    #elif area_name in ['Virgin Islands']:\n    #    train = data[:-3].query('ConfirmedCases > 0').copy()\n    else:\n        train = data.query('ConfirmedCases > 0').copy()\n    \n    ####### Split Train & Valid #######\n    #valid_data = train[-1:]\n    train_data = train\n    \n    ####### If this country have no ConfirmedCase, return 0 #######\n    if len(train_data) == 0:\n        result_zero = np.zeros((43))\n        return pd.DataFrame({'ConfirmedCases':result_zero,'Fatalities':result_zero}), 0 \n    \n    ####### Load the population of area #######\n    try:\n        #population = province_lookup[area_name]\n        population = pop_info[pop_info['Name']==area_name]['Population'].tolist()[0]\n    except IndexError:\n        print ('country not in population set, '+str(area_name))\n        population = 1000000 \n    \n    \n    if area_name == 'US':\n        population = 327200000\n    if area_name == 'Global':\n        population = 7744240900\n        \n    cases_per_million = train_data['ConfirmedCases'].max() * 10**6 \/ population\n    n_infected = train_data['ConfirmedCases'].iloc[0]\n    \n    ####### Total case\/popuplation below 1, reduce country population #######\n    if cases_per_million < 1:\n        #print ('reduce pop divide by 100')\n        population = population\/100\n        \n    ####### Fit the real data by minimize the MSLE #######\n    res_const = minimize(eval_model_const, [2.2, 0.02], bounds=((1, 20), (0, 0.15)),\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n\n    res_decay = minimize(eval_model_decay, initial_guess, bounds=bounds,\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    ####### Align the date information #######\n    test_end = datetime.datetime.strptime('2020-05-07','%Y-%m-%d')\n    test_start = datetime.datetime.strptime('2020-03-26','%Y-%m-%d')\n    train_test = data[data.Date_datetime>=test_start]\n    test_period = (test_end - test_start).days\n    train_max = train_data.Date_datetime.max()\n    train_min = train_data.Date_datetime.min()\n    add_date = 0\n    delta_days =(test_end - train_max).days\n    train_add_time=[]\n\n    if train_min > test_start:\n        add_date = (train_min-test_start).days\n        last = train_min-timedelta(add_date)\n        train_add_time = np.arange(last, train_min, dtype='datetime64[D]').tolist()\n        train_add_time = pd.to_datetime(train_add_time)\n        dates_all = train_add_time.append(pd.to_datetime(np.arange(train_min, test_end+timedelta(1), dtype='datetime64[D]')))\n    else:\n        dates_all = pd.to_datetime(np.arange(train_min, test_end+timedelta(1), dtype='datetime64[D]'))\n\n\n    ####### Auto find the best decay function ####### \n    if decay_mode is None:\n        if res_const.fun < res_decay.fun :\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n    else:\n        if decay_mode =='day_decay':\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n\n    ####### Predict the result by using best fit paramater of SEIR model ####### \n    sus, exp, inf, rec = sol.y\n    \n    y_pred = pd.DataFrame({\n        'ConfirmedCases': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum()),\n       # 'ConfirmedCases': [inf[0]*population for i in range(add_date)]+(np.clip((inf + rec) * population,0,np.inf)).tolist(),\n       # 'Fatalities': [rec[0]*population for i in range(add_date)]+(np.clip(rec, 0, np.inf) * population * res.x[1]).tolist()\n        'Fatalities': cumsum_signal((np.clip(rec * population * res.x[1], 0, np.inf)).tolist())\n    })\n\n    #y_pred_valid = y_pred.iloc[len(train_data):len(train_data)+len(valid_data)]\n    y_pred_valid = y_pred.iloc[:len(train_data)]\n    y_pred_test = pd.concat([train_test[['ConfirmedCases', 'Fatalities']],y_pred.iloc[-(delta_days):]], ignore_index=True)\n    y_true_valid = train_data[['ConfirmedCases', 'Fatalities']]\n    #y_true_valid = valid_data[['ConfirmedCases', 'Fatalities']]\n    #print (len(y_pred),train_min)\n    \n    ####### Calculate MSLE ####### \n    valid_msle_cases = mean_squared_log_error(y_true_valid['ConfirmedCases'], y_pred_valid['ConfirmedCases'])\n    valid_msle_fat = mean_squared_log_error(y_true_valid['Fatalities'], y_pred_valid['Fatalities'])\n    valid_msle = np.mean([valid_msle_cases, valid_msle_fat])\n    \n    ####### Plot the fit result of train data and forecast after 300 days ####### \n    if make_plot:\n        if len(res.x)<=2:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using intervention days decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}')\n        else:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using Hill decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}, K : {res.x[2]:0.5f}, L: {res.x[3]:0.5f}')\n        \n        ####### Plot the fit result of train data dna SEIR model trends #######\n\n        f = plt.figure(figsize=(16,5))\n        ax = f.add_subplot(1,2,1)\n        ax.plot(exp, 'y', label='Exposed');\n        ax.plot(inf, 'r', label='Infected');\n        ax.plot(rec, 'c', label='Recovered\/deceased');\n        plt.title('SEIR Model Trends')\n        plt.xlabel(\"Days\", fontsize=10);\n        plt.ylabel(\"Fraction of population\", fontsize=10);\n        plt.legend(loc='best');\n        #train_date_remove_year = train_data['Date_datetime'].apply(lambda date:'{:%m-%d}'.format(date))\n        ax2 = f.add_subplot(1,2,2)\n        xaxis = train_data['Date_datetime'].tolist()\n        xaxis = dates.date2num(xaxis)\n        hfmt = dates.DateFormatter('%m\\n%d')\n        ax2.xaxis.set_major_formatter(hfmt)\n        ax2.plot(np.array(train_data['Date_datetime'], dtype='datetime64[D]'),train_data['ConfirmedCases'],label='Confirmed Cases (train)', c='g')\n        ax2.plot(np.array(train_data['Date_datetime'], dtype='datetime64[D]'), y_pred['ConfirmedCases'][:len(train_data)],label='Cumulative modeled infections', c='r')\n        #ax2.plot(np.array(valid_data['Date_datetime'], dtype='datetime64[D]'), y_true_valid['ConfirmedCases'],label='Confirmed Cases (valid)', c='b')\n        #ax2.plot(np.array(valid_data['Date_datetime'], dtype='datetime64[D]'),y_pred_valid['ConfirmedCases'],label='Cumulative modeled infections (valid)', c='y')\n        plt.title('Real ConfirmedCase and Predict ConfirmedCase')\n        plt.legend(loc='best');\n        plt.show()\n            \n        ####### Forecast 300 days after by using the best paramater of train data #######\n        if len(res.x)>2:\n            msle, sol = eval_model_decay(res.x, train_data, population, True, 300)\n        else:\n            msle, sol = eval_model_const(res.x, train_data, population, True, 300)\n        \n        sus, exp, inf, rec = sol.y\n        \n        y_pred = pd.DataFrame({\n            'ConfirmedCases': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum()),\n            'Fatalities': cumsum_signal(np.clip(rec, 0, np.inf) * population * res.x[1])\n        })\n        \n        ####### Plot 300 days after of each country #######\n        start = train_min\n        end = start + timedelta(len(y_pred))\n        time_array = np.arange(start, end, dtype='datetime64[D]')\n\n        max_day = numpy.where(inf == numpy.amax(inf))[0][0]\n        where_time = time_array[max_day]\n        pred_max_day = y_pred['ConfirmedCases'][max_day]\n        xy_show_max_estimation = (where_time, max_day)\n        \n        con = y_pred['ConfirmedCases']\n        fat = y_pred['Fatalities']\n        max_day_con = numpy.where(con == numpy.amax(con))[0][0] # Find the max confimed case of each country\n        max_day_fat = numpy.where(fat == numpy.amax(fat))[0][0]\n        max_con = numpy.amax(con)\n        max_fat = numpy.amax(fat)\n        where_time_con = time_array[len(time_array)-50]\n        xy_show_max_estimation_confirmed = (where_time_con, max_con)\n        \n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=time_array, y=y_pred['ConfirmedCases'].astype(int),\n                            mode='lines',\n                            line = dict(color='red'),\n                            name='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date())))\n        fig.add_trace(go.Scatter(x=time_array, y=y_pred['Fatalities'].astype(int),\n                            mode='lines',\n                            line = dict(color='yellow'),\n                            name='Estimation Fatalities Start from '+ str(start.date())+ ' to ' +str(end.date())))\n        fig.add_trace(go.Scatter(x=time_array[:len(train)], y=train['ConfirmedCases'],\n                            mode='lines',\n                            name='Confirmed case until '+ str(train_max.date()),line = dict(color='green', width=4)))\n        fig.add_trace(go.Scatter(x=time_array[:len(train)], y=train['Fatalities'],\n                            mode='lines',\n                            name='Fatalities case until '+ str(train_max.date()),line = dict(color='blue', width=4)))\n        fig.add_annotation(\n            x=where_time_con,\n            y=max_con-(max_con\/30),\n            showarrow=False,\n            text=\"Estimate Max Case around:\" +str(int(max_con)),\n            font=dict(\n                color=\"Blue\",\n                size=15\n            ))\n        fig.add_annotation(\n            x=where_time_con,\n            y=max_fat-(max_fat\/30),\n            showarrow=False,\n            text=\"Estimate Max death around:\" +str(int(max_fat)),\n            font=dict(\n                color=\"Blue\",\n                size=15\n            ))\n        fig.add_annotation(\n            x=time_array[len(train)-1],\n            y=train['ConfirmedCases'].tolist()[-1],\n            showarrow=True,\n            text=f\"Real Max ConfirmedCase: \" +str(int(train['ConfirmedCases'].tolist()[-1]))) \n        \n        fig.add_annotation(\n            x=time_array[len(train)-1],\n            y=train['Fatalities'].tolist()[-1],\n            showarrow=True,\n            text=f\"Real Max Fatalities: \" +str(int(train['Fatalities'].tolist()[-1]))) \n        \n        fig.add_annotation(\n            x=where_time,\n            y=pred_max_day,\n            text='Infect start decrease from: ' + str(where_time))   \n        fig.update_layout(title='Estimate Confirmed Case ,'+area_name+' Total population ='+ str(int(population)), legend_orientation=\"h\")\n        fig.show()\n        ###\n        df = pd.DataFrame({'Values': train_data['ConfirmedCases'].tolist()+y_pred['ConfirmedCases'].tolist(),'Date_datatime':time_array[:len(train_data)].tolist()+time_array.tolist(),\n                   'Real\/Predict': ['ConfirmedCase' for i in range(len(train_data))]+['PredictCase' for i in range(len(y_pred))]})\n        fig = px.line(df, x=\"Date_datatime\", y=\"Values\",color = 'Real\/Predict')\n        fig.show()\n        plt.figure(figsize = (16,7))\n        plt.plot(time_array[:len(train_data)],train_data['ConfirmedCases'],label='Confirmed case until '+ str(train_max.date()),color='g', linewidth=3.0)\n        plt.plot(time_array,y_pred['ConfirmedCases'],label='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date()),color='r', linewidth=1.0)\n        plt.annotate('Infect start decrease from: ' + str(where_time), xy=xy_show_max_estimation, size=15, color=\"black\")\n        plt.annotate('max Confirmedcase: ' + str(int(max_con)), xy=xy_show_max_estimation_confirmed, size=15, color=\"black\")\n        plt.title('Estimate Confirmed Case '+area_name+' Total population ='+ str(int(population)))\n        plt.legend(loc='lower right')\n        plt.show()\n\n\n    return y_pred_test, valid_msle","459376c3":"country = 'India'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","92744601":"# ARIMA modelling with parameters as 5,2,0\n\nAutoregressive Integrated Moving Average Model\n\nAn ARIMA model is a class of statistical models for analyzing and forecasting time series data.\n\nIt explicitly caters to a suite of standard structures in time series data, and as such provides a simple yet powerful method for making skillful time series forecasts.\n\nARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a generalization of the simpler AutoRegressive Moving Average and adds the notion of integration.\n\nThis acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n\nAR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n<br><br>I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n<br><br>MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n\nEach of these components are explicitly specified in the model as a parameter. A standard notation is used of ARIMA(p,d,q) where the parameters are substituted with integer values to quickly indicate the specific ARIMA model being used.\n\nThe parameters of the ARIMA model are defined as follows:\n\n   <br>p: The number of lag observations included in the model, also called the lag order.\n   <br>d: The number of times that the raw observations are differenced, also called the degree of differencing.\n   <br>q: The size of the moving average window, also called the order of moving average.\n\nA linear regression model is constructed including the specified number and type of terms, and the data is prepared by a degree of differencing in order to make it stationary, i.e. to remove trend and seasonal structures that negatively affect the regression model.\n\n","6c36c44d":"# India analysis","51b5757b":"I have used few notebooks as reference so a huge thanks to the authors of those notebooks","4f0fda8d":"If you like the notebook please do upvote","6fcb055c":"<h1><center>Introduction<\/center><\/h1>\n\n![image.png](attachment:image.png)\n    \n\n<br>\n<center>The first case of the 2019\u201320 coronavirus pandemic in India was reported on 30 January 2020, originating from China. Experts suggest the number of infections could be much higher as India's testing rates are among the lowest in the world. The infection rate of COVID-19 in India is reported to be 1.7, significantly lower than in the worst affected countries.<br>\n\n\n<br>The outbreak has been declared an epidemic in more than a dozen states and union territories, where provisions of the Epidemic Diseases Act, 1897 have been invoked, and educational institutions and many commercial establishments have been shut down. India has suspended all tourist visas, as a majority of the confirmed cases were linked to other countries.<br>\n\n<br>On 22 March 2020, India observed a 14-hour voluntary public curfew at the instance of the prime minister Narendra Modi. The government followed it up with lockdowns in 75 districts where COVID cases had occurred as well as all major cities. Further, on 24 March, the prime minister ordered a nationwide lockdown for 21 days, affecting the entire 1.3 billion population of India.<br>\n\n<br>The World Health Organisation chief executive director of health emergencies programme Michael Ryan said that India had \"tremendous capacity\" to deal with the coronavirus outbreak and, as the second most populous country, will have enormous impact on the world's ability to deal with it.Other commentators worried about the economic devastation caused by the lockdown, which has huge effects on informal workers, micro and small enterprises, farmers and the self-employed, who are left with no livelihood in the absence of transportation and access to markets. The lockdown was justified by the government and other agencies for being preemptive to prevent India from entering a higher stage which could make handling very difficult and cause even more losses thereafter.<br>\n\n<br>According to a study at Shiv Nadar University, India could have witnessed a surge of 31,000 cases of disease between March 24 and April 14 without lockdown.<\/center>","7197c8e2":"\n\n# SEIR Model\n\nThe SEIR models the flows of people between four states: susceptible (S), exposed (E), infected (I), and resistant (R).\n\nEach of those variables represents the number of people in those groups. The parameters alpha and beta partially control how fast people move from being susceptible to exposed (beta), from exposed to infected (sigma), and from infected to resistant (gamma). This model has two additional parameters; one is the background mortality (mu) which is unaffected by disease-state, while the other is vaccination (nu). The vaccination moves people from the susceptible to resistant directly, without becoming exposed or infected.\n\nThe SEIR differs from the SIR model in the addition of a latency period. Individuals who are exposed (E) have had contact with an infected person, but are not themselves infectious.\n\nInstructions: The boxes on the right side of the page control the parameters of the model. The page should load with some parameters already in the box. Click \"submit\" to run the model. The parameters can all be modified and the model re-run. The parameters are Beta The parameter controlling how often a susceptible-infected contact results in a new exposure. Gamma The rate an infected recovers and moves into the resistant phase. Sigma The rate at which an exposed person becomes infective. Mu The natural mortality rate (this is unrelated to disease). This models a population of a constant size, Initial susceptible The number of susceptible individuals at the beginning of the model run. Initial exposed The number of exposed individuals at the beginning of the model run. Initial infected The number of infected individuals at the beginning of the model run. Initial recovered The number of recovered individuals at the beginning of the model run. Days Controls how long the model will run. This program runs on your computer, so some computers may run faster than others. It is probably a good idea not to set the number iterations or the initial populations too high, since it will take longer to run. Note that cookies must be enabled for the algorithm to function.\n\n![image.png](attachment:image.png)\n\nimage.png Details: This is an ordinary differential equation model, described by the following equation: derivative of S with respect to t equals The simulation uses the fourth-order Runge-Kutta algorithm to solve it numerically, with a step size fixed at 0.01, written in JavaScript. The plotting methods are from the flot module. Both the ode simulation and the script in this page calling it are new, so there may still be some unanticipated bugs (I am also fairly new to the language, so my code may be inefficient or bizarre in places). Internet Explorer may not work since it has not yet adopted the canvas element, which is used in plotting.\n","2f3a8795":"According to the ARIMA model we can see that by the end of the next 20 days the total number of cases may rise upto 64,700 (model fitting done based on the data available as of 21st.","fbd696bd":"![image.png](attachment:image.png)","edde6f98":"## Active Cases : 1,684,951\n## Currently Infected Patients : \n\n### 1,627,669 (97%) in Mild Condition\n\n### 57,282 (3%) Serious or Critical\n\nData Source : https:\/\/www.worldometers.info\/coronavirus\/#countries\n","545e18a9":"# Predictions"}}