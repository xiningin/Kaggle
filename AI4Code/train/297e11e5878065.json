{"cell_type":{"fd2db2e9":"code","38799967":"code","c1d4d8c7":"code","bfb8be75":"code","b46c7f87":"code","ea11890c":"code","bb598b39":"code","724efec8":"code","77f06ddb":"code","81e60127":"code","ca512edc":"code","44fb5193":"code","9b33c1e4":"markdown","50c58a81":"markdown","91e8c4c5":"markdown","d35f9a32":"markdown","79744d0b":"markdown","c3a2715b":"markdown","6ffda232":"markdown","cd6df206":"markdown","c7a71c1f":"markdown","16d819d3":"markdown"},"source":{"fd2db2e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38799967":"import tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import image_dataset_from_directory\n\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Rescaling\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom keras.utils.vis_utils import plot_model\n\nimport numpy\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom numpy.random import randn\nfrom numpy import asarray\n\nimport matplotlib.pyplot as plt\nfrom os import listdir\nfrom PIL import Image\n\n\n","c1d4d8c7":"image_path = \"\/kaggle\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/\"\n# Load an image from the file\ndef load_image(filename):\n    temp_image = Image.open(filename)\n    temp_image = temp_image.convert('RGB')\n    image = temp_image.resize((80,80))\n    pixels = asarray(image)\n    return pixels\n\n# loading images and extract faces for all images in a directory\n# For DEBUG Purpose only\ndef load_faces(directory,n_faces):\n    faces = list()\n    for filename in listdir(directory):\n        pixels = load_image(directory+filename)\n        faces.append(pixels)\n        if len(faces)>=n_faces:\n            break\n    return asarray(faces)\ndef load_images(directory):\n    images = list()\n    for filename in listdir(directory):\n        pixels = load_image(directory+filename)\n        images.append(pixels)\n    return asarray(images)\n\nfaces = load_faces(image_path,25)\nprint('Loaded: ',faces.shape)","bfb8be75":"def plot_faces(images,n):\n    plt.figure(figsize=(10, 10))\n    for i in range(n*n):\n        plt.subplot(n,n,i+1)\n        plt.axis('off')\n        plt.imshow(faces[i])\n    plt.show()\n    \nplot_faces(faces,5)","b46c7f87":"#normalization_layer = tf.keras.layers.Rescaling(1.\/127.5)\nshape = 0\ndef load_real_samples(data_path):\n    # convert from unsigned ints to floats\n    print(\"Loading the input Images\")\n    X = load_faces(data_path,100)\n    X = X.astype('float32')\n    # Scaling the data from [0,255] to [-1,1]\n    X = (X-127.5)\/127.5\n    print(\"Converting numpy array to tensorflow data\")\n    # Converting numpy array to tensorflow data\n    shape = X.shape[0]\n    data = tf.data.Dataset.from_tensor_slices(X)\n    for element in data:\n        print(element.shape)\n        break\n    return X, shape\n\ndef generate_real_samples(dataset,shape,n_samples):\n    # choosing random instances\n    ix = randint(0,shape,n_samples)\n    # retriece selected images\n    X = dataset[ix]\n    # generate 'real' class labels(1)\n    y = ones((n_samples,1))\n    return X, y\n\ndef generate_latent_points(latent_dim,n_samples):\n    # generate points in the latent space\n    x_input = randn(latent_dim*n_samples)\n    # reshape nto a batch of inputs for the network\n    x_input = x_input.reshape(n_samples,latent_dim)\n    return x_input\n\ndef generate_fake_samples(g_model,latent_dim,n_samples):\n    # generate points in the latent space\n    x_input = generate_latent_points(latent_dim,n_samples)\n    # predict_outputs\n    X = g_model.predict(x_input)\n    # create 'fake' class labels\n    y = zeros((n_samples,1))\n    return X,y","ea11890c":"def define_discriminator(in_shape =(80,80,3)):\n    dis_model = Sequential()\n    dis_model.add(Conv2D(128,(5,5),padding='same',input_shape = in_shape))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    # downsample to 40x40\n    dis_model.add(Conv2D(128,(5,5),strides=(2,2),padding='same'))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    # downsample to 20x20\n    dis_model.add(Conv2D(128,(5,5),strides=(2,2),padding='same'))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    # downsample to 10x10\n    dis_model.add(Conv2D(128,(5,5),strides=(2,2),padding='same'))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    # downsample to 5x5\n    dis_model.add(Conv2D(128,(5,5),strides=(2,2),padding='same'))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    # classifier\n    dis_model.add(Flatten())\n    dis_model.add(Dropout(0.4))\n    dis_model.add(Dense(1,activation='sigmoid'))\n    \n    # compile model\n    opt = Adam(learning_rate = 0.0002, beta_1=0.5)\n    print(\"Compiling the discriminator model\")\n    dis_model.compile(loss='binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n    return dis_model\n \ndismodel = define_discriminator()\ndismodel.summary()\nplot_model(dismodel,show_shapes = True, show_layer_names = True, to_file='Discriminator_Model.png')","bb598b39":"def define_generator(latent_dim):\n    gen_model=Sequential()\n    n_nodes = 128*5*5\n    # Foundation for 5x5 feature map \n    gen_model.add(Dense(n_nodes,input_dim=latent_dim))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    gen_model.add(Reshape((5,5,128)))\n    # upsampling the image to 10x10\n    gen_model.add(Conv2DTranspose(128,(4,4), padding='same',strides = (2,2)))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    # upsampling the image to 20x20\n    gen_model.add(Conv2DTranspose(128,(4,4), strides = (2,2), padding='same'))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    # upsampling the image to 40x40\n    gen_model.add(Conv2DTranspose(128,(4,4), padding='same',strides = (2,2)))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    # upsampling the image to 80x80\n    gen_model.add(Conv2DTranspose(128,(4,4), padding='same',strides = (2,2)))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    # output layer -> 80x80x3\n    gen_model.add(Conv2D(3,(5,5),activation ='tanh',padding = 'same'))\n    print(\"Generator model is created.\")\n    return gen_model\n\ngenmodel = define_generator(100)\ngenmodel.summary()\nplot_model(genmodel, to_file='generator_model.png',show_layer_names = True,show_shapes = True)\n","724efec8":"def define_gan(gen_model,dis_model):\n    gan_model = Sequential()\n    \n    gan_model.add(gen_model)\n    gan_model.add(dis_model)\n    \n    opt = Adam(learning_rate = 0.0002, beta_1 = 0.5)\n    print(\"Compiling the GAN model\")\n    gan_model.compile(loss=\"binary_crossentropy\",optimizer=opt)\n    \n    return gan_model\nganmodel = define_gan(genmodel,dismodel)\nganmodel.summary()\nplot_model(ganmodel,show_shapes=True, show_layer_names = True, to_file = 'ganmodel.png')\n    ","77f06ddb":"def save_plot(examples,epoch,n=10):\n    # scale from [-1,1] to [0,1]\n    examples = (examples+1)\/2.0\n    #plot images \n    for i in range(n*n):\n        plt.subplot(n,n,i+1)\n        plt.axis(\"off\")\n        plt.imshow(examples[i])\n    file_name = 'generated_plot_e%03d.png'%(epoch+1)\n    plt.savefig(file_name)\n    plt.close()\n\n# evaluating the discriminator and plot generated images, save generator model\ndef summarize_performance(epoch,gen_model,dis_model,dataset,latent_dim,shape,n_samples=100):\n    # prepare real samples\n    X_real,y_real = generate_real_samples(dataset,shape,n_samples)\n    # evaluate discriminator on real examples\n    _, acc_real = dis_model.evaluate(X_real,y_real,verbose=0)\n    # Prepare fake samples\n    x_fake, y_fake = generate_fake_samples(g_model,latent_dim,n_samples)\n    # evaluate discriminator on fake examples\n    _, acc_fake = dis_model.evaluate(x_fake,y_fake,verbose=0)\n    print('--> Accuracy real: %.0f%%, fake: %.0f%%' %(acc_real*100, acc_fake*100))\n    save_plot(x_fake,epoch)\n    file_name = 'generator_model-%03d.h5'%(epoch+1)\n    gen_model.save(file_name)\n    ","81e60127":"def plot_history(dreal_hist,dfake_hist,g_hist,a1_hist,a2_hist):\n    # Plotting the loss \n    plt.subplot(2,1,1)\n    plt.plot(dreal_hist,label='d_real')\n    plt.plot(dfake_hist,label='d_fake')\n    plt.plot(g_hist,label='gen')\n    plt.legend()\n    \n    # Plotting the model accuracy\n    plt.subplot(2,1,2)\n    plt.plot(a1_hist,label='acc_real')\n    plt.plot(a2_hist,label='acc_real')\n    plt.legend()\n    plt.show()\n    plt.close()","ca512edc":"def train(gen_model,dis_model,gan_model,shape,dataset,latent_dim,bat_per_epo = 500,n_epochs=25,n_batch=128):\n    #bat_per_epo = int(dataset.shape[0]\/n_batch)\n    half_batch = int(n_batch\/2)\n    dreal_hist, dfake_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n    for i in range(n_epochs):\n        for j in range(bat_per_epo):\n            X_real,y_real = generate_real_samples(dataset,shape,half_batch)\n            d_loss_real,d_acc_real = dis_model.train_on_batch(X_real,y_real)\n            \n            X_fake,y_fake = generate_fake_samples(gen_model,latent_dim,half_batch)\n            d_loss_fake,d_acc_fake = dis_model.train_on_batch(X_fake,y_fake)\n            \n            X_gan = generate_latent_points(latent_dim,n_batch)\n            y_gan = ones((n_batch,1))\n            \n            gan_loss = gan_model.train_on_batch(X_gan,y_gan)\n            \n            print('--> %d, %d%d, d_real=%.3f, d_fake=%.3f , g=%.3f' % (i+1,j+1, bat_per_epo, d_loss_real,d_loss_fake,gan_loss))\n            # Recording the model history\n            dreal_hist.append(d_loss_real)\n            dfake_hist.append(d_loss_fake)\n            g_hist.append(gan_loss)\n            a1_hist.append(d_acc_real)\n            a2_hist.append(d_acc_fake)\n        if(i+1)%10==0:\n            summarize_performance(i,gen_model,dis_model,dataset,latent_dim,shape)\n    plot_history(dreal_hist,dfake_hist,g_hist,a1_hist,a2_hist)","44fb5193":"latent_dim = 1\nd_model = define_discriminator()\ng_model = define_generator(latent_dim)\ngan_model = define_gan(g_model,d_model)\n\ndataset, shape = load_real_samples(image_path)\nprint(\"shape ----->>>>>\", shape)\n#bat_per_epo = int(dataset.shape[0]\/100)\ntrain(g_model,d_model,gan_model,shape,dataset,latent_dim)","9b33c1e4":"## Data Import using Tensorflow","50c58a81":"##  Defining the Generator","91e8c4c5":"## Training the GAN","d35f9a32":"## Mode Collapse Replication","79744d0b":"## Plotting the sample images","c3a2715b":"## Generating the data","6ffda232":"## Defining the GAN","cd6df206":"## Performance Summary","c7a71c1f":"## Plotting the history of the models","16d819d3":"## Defining the discriminator"}}