{"cell_type":{"aae668f1":"code","83e92701":"code","f1b780d6":"code","2d702310":"code","555fb6ca":"code","480fd904":"code","37dd1944":"code","959f942f":"code","0ba16aa1":"code","80080f86":"code","ee51b1b4":"code","a1e31006":"code","97628eaf":"code","1a46f435":"code","965aaf76":"code","60952f77":"code","77cdc0ce":"code","385ed92f":"code","43b50193":"code","77391827":"code","0fe16b80":"code","3575db77":"code","1879000f":"code","71635c64":"code","80f0ea1c":"code","6115dbb4":"code","ff7ca115":"code","452b4b48":"code","0ab87099":"code","f4b1f1a5":"code","ae91c968":"markdown","1690aeae":"markdown","ec3d650f":"markdown","69fd1a35":"markdown","456bcd33":"markdown","b84abde1":"markdown","9301d298":"markdown","830c0e1e":"markdown"},"source":{"aae668f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","83e92701":"data = pd.read_csv(\"\/kaggle\/input\/tmnist-glyphs-1812-characters\/Glyphs_TMNIST_updated.csv\")","f1b780d6":"data.head()","2d702310":"# Shape of the Dataframe\n\nprint(f\"The Shape of the Dataframe is: {data.shape}\")\nprint(f\"Number of Samples: {data.shape[0]}\")","555fb6ca":"# Alphanumeric and Symbols List\n\nsymbols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n           'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \n           'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', \n           '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '\/', ':', ';', '<', '=', '>', '?', '@','[',']','\\\\','^','_','`','{','}',\"|\",'~']\n\nlen(symbols)","480fd904":"# Get all the sample hows label are present in the list \"symbols\"\n\ndata = data[data.label.isin(symbols)]","37dd1944":"# DataFrame Description\n\ndata.describe().T","959f942f":"# DataFrame feature's Datatype\n\ndata.info(verbose=True)","0ba16aa1":"# Number of Fonts in the Dataframe\nprint(f\"Number of unique fonts present in the Dataset: {len(data.font_name.unique())}\")","80080f86":"# Number of unique character in the Dataframe\nprint(f\"Number of unique character present in the Dataset: {len(data.label.unique())}\")","ee51b1b4":"# Spliting the Labels and the features\n\nX = data.drop(columns=['font_name','glyph_name','label']).values\ny = data[['label']].values\ndel data","a1e31006":"X = X.astype('u1')\nX.dtype","97628eaf":"X.shape, y.shape","1a46f435":"# Display few of the characters\n\nimport matplotlib.pyplot as plt\n\nX_images = X.reshape(-1,28,28)\nfig,axs = plt.subplots(3,3,figsize=(9,9))\nfor i in range(9):\n    r=i\/\/3\n    c=i%3\n    axs[r][c].set_xticks([])\n    axs[r][c].set_yticks([])\n    axs[r][c].imshow(X_images[i])\nplt.show()\ndel X_images","965aaf76":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\ny_train = y_train.reshape((-1,))\ny_test = y_test.reshape((-1,))","60952f77":"X_train.shape, X_test.shape","77cdc0ce":"y_train.shape, y_test.shape","385ed92f":"from sklearn.preprocessing import LabelBinarizer\n\nlb = LabelBinarizer()\ny_train_label = lb.fit_transform(y_train)\ny_test_label = lb.transform(y_test)\nprint('Train labels dimension:');print(y_train.shape)\nprint('Test labels dimension:');print(y_test.shape)","43b50193":"# Normalizing the Dataset for the Neural Network\n\nX_train, X_test = np.true_divide(X_train, 255), np.true_divide(X_test, 255)","77391827":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import roc_auc_score, accuracy_score","0fe16b80":"# Create Model\n\nmodel = Sequential()\nmodel.add(Dense(500, input_shape=(X_train.shape[1],), activation='relu'))\nmodel.add(Dense(250, activation='relu'))\nmodel.add(Dense(125, activation='relu'))\nmodel.add(Dense(y_train_label.shape[1], activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","3575db77":"# Model Summary\n\nmodel.summary()","1879000f":"# Configure the model and start training\nmodel.fit(X_train, y_train_label, epochs=50, batch_size=150, verbose=1, validation_split=0.1)","71635c64":"# Test the model after training\ntest_results = model.evaluate(X_test, y_test_label, verbose=1)\nprint(f'Test results - Accuracy: {test_results[1]}%')","80f0ea1c":"# Reshape X_train and X_test for CNN\n\nX_train = X_train.reshape(-1,28,28,1).astype('float32')\nX_test = X_test.reshape(-1,28,28,1).astype('float32')","6115dbb4":"X_train.shape","ff7ca115":"#CNN Model\n\ncnnmodel = Sequential()\ncnnmodel.add(Conv2D(64,(4,4),input_shape = (28,28,1),activation = 'relu'))\ncnnmodel.add(MaxPooling2D(pool_size=(2,2)))\ncnnmodel.add(Conv2D(32,(3,3),activation = 'relu'))\ncnnmodel.add(MaxPooling2D(pool_size=(2,2)))\ncnnmodel.add(Dropout(0.2))\ncnnmodel.add(Flatten())\ncnnmodel.add(Dense(128,activation='relu'))\ncnnmodel.add(Dense(y_train_label.shape[1], activation='softmax'))\ncnnmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])","452b4b48":"# CNN Model Summary\n\ncnnmodel.summary()","0ab87099":"# Train the CNN Model\n\nresult = cnnmodel.fit(X_train, y_train_label, validation_split=0.1, epochs=50, batch_size=100, verbose=1)","f4b1f1a5":"# Test the CNN model after training\ntest_results = cnnmodel.evaluate(X_test, y_test_label, verbose=1)\nprint(f'Test results - Accuracy: {test_results[1]}%')","ae91c968":"# Split the Dataframe into Training and Test Dataframe","1690aeae":"# Binarize labels","ec3d650f":"# Normalize the Training and Testing Dataset","69fd1a35":"# Read the TMNIST Glyphs CSV File","456bcd33":"# Dense Neural Network","b84abde1":"# Exploratory Data Analysis (EDA)","9301d298":"# About Dataset\n\n* TMNIST (Typography MNIST) Glyphs: A database of over 500,000 MNIST style images made from 1,812 unique glyphs and 2,990 font-styles\n* This repository contains a single csv file.\n* **The structure of the csv file is:**\n\n    * The first row contains column headers ['fontname','glyphname', 'label','1','2',\u2026..'784']\n    * The 'font_name' column contains font file names such as 'Acme-Regular' and 'ZillaSlab-Bold'\n    * The 'glyph_name' column contains the unicodedata name for the glyph such as 'LATIN CAPITAL LETTER A' and 'DEVANAGARI LETTER AA'\n    * For glyphs that are represented by more than 1 unicode character, the 'glyphname' column contains the the individual names of both the characters concatenated with a '+' sign. For ex: '\u0905\u0902' has the 'glyphname' = 'DEVANAGARI LETTER A + DEVANAGARI SIGN ANUSVARA'\n    * The 'label' column contains characters such as '\u0634','E' or '\u091b'\n    * The remaining 784 columns contain the grayscale pixel values for the image of the corresponding character in the 'font_name' font-style\n    * This dataset contains over 500,000 images and is part of the Warhol.ai Computational Creativity and Congnitive Type projects.","830c0e1e":"# Convolution Neural Network"}}