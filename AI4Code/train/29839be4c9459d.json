{"cell_type":{"5609f114":"code","110b938b":"code","243a8af0":"code","670e5b35":"code","710d0552":"code","46cb741f":"code","a289a7ee":"code","a21a461a":"code","ff205a1f":"code","5ae33eab":"code","73685c17":"code","9ce2cb79":"code","108ccf1f":"code","ea9f2a01":"markdown","8558a82a":"markdown"},"source":{"5609f114":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","110b938b":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split","243a8af0":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","670e5b35":"device","710d0552":"def to_categorical(y, num_classes=10):\n    \"\"\" 1-hot encodes a tensor \"\"\"\n    return np.eye(num_classes, dtype='uint8')[y]","46cb741f":"class MNISTDataset(Dataset):\n    def __init__(self, root):\n        super(MNISTDataset, self).__init__()\n        self.df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/\" + root)\n        self.data = self.df.to_numpy()\n        self.x , self.y = self.data[:, 1:] \/ 255., self.data[:, 0]\n        self.x = torch.from_numpy(self.x.reshape((-1, 1, 28, 28))).float()\n        self.y = torch.from_numpy(to_categorical(self.y)).float()\n\n    def __getitem__(self, idx):\n        return self.x[idx, :], self.y[idx,:]\n    \n    def __len__(self):\n        return len(self.data)","a289a7ee":"VAL_SPLIT = 0.1\ntrain_dataset = MNISTDataset(\"train.csv\")\ntrain_dataset_len = len(train_dataset)\ntrain_size = int((1 - VAL_SPLIT)*train_dataset_len)\nval_size = int(0.1*train_dataset_len)\n\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\ntrain_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_data_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n\nprint(\"Train dataset size: %d\" % (len(train_dataset)))\nprint(\"Validation dataset size: %d\" % (len(val_dataset)))","a21a461a":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef show_image(im, label=None):\n    plt.imshow(im.reshape(28, 28), cmap='gray', vmin=0, vmax=1)\n    if label is not None:\n        plt.title(label)\n    plt.show()","ff205a1f":"# for x, y in train_data_loader:\n#     show_image(x[0], np.argmax(y.tolist()))\n#     break","5ae33eab":"import albumentations as A\n\ntransformA = A.Compose([\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5)\n#     A.RandomBrightnessContrast(p=0.5)\n])\n\ns = None\nfor x, y in train_data_loader:\n    s = transformA(image=np.array(x[0].tolist()))['image']\n    show_image(x[0], np.argmax(y.tolist()))\n    break\n","73685c17":"class Flatten(torch.nn.Module):\n    def forward(self, x):\n        batch_size = x.shape[0]\n        return x.view(batch_size, -1)\n\nclass Print(nn.Module):\n    def forward(self, x):\n        print(x.size())\n        return x\n\nclass ConvNeuralNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ConvNeuralNet, self).__init__()\n        self.classifier = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=2),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 32, kernel_size=3, padding=2),\n            nn.MaxPool2d(kernel_size=(2, 2)),\n            nn.Dropout(0.2),\n            \n            nn.Conv2d(32, 128, kernel_size=3, padding=2),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(128, 128, kernel_size=3, padding=2),\n            nn.MaxPool2d(kernel_size=(2, 2)),\n            nn.Dropout(0.2),\n            \n            nn.Conv2d(128, 256, kernel_size=3),\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(kernel_size=(2, 2)),\n            nn.Dropout(0.2),\n            \n            nn.Flatten(),\n            #Print(),\n            nn.Linear(4096, 128),\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.3),\n\n            nn.Linear(128, 32),\n            nn.ReLU(),\n            nn.BatchNorm1d(32),\n            nn.Dropout(0.5),\n            \n            nn.Linear(32, num_classes),\n            nn.Softmax()\n        ) \n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        out = self.classifier(x)\n        return out\n","9ce2cb79":"model = ConvNeuralNet(10).cuda()\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n","108ccf1f":"num_epochs = 50\ntotal_step = len(train_data_loader)\nloss_list = []\nacc_list = []\n\nval_total_step = len(val_data_loader)\nval_loss_list = []\nval_acc_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_data_loader):\n        # Run the forward pass\n        labels = torch.max(labels, 1)[1].cuda()\n        outputs = model(images.cuda()).cuda()\n        loss = criterion(outputs, labels)\n        loss_list.append(loss.item())\n\n        # Backprop and perform Adam optimisation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Track the accuracy\n        total = labels.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        correct = (predicted == labels).sum().item()\n        acc_list.append(correct \/ total)\n\n        if (i + 1) % 1000 == 0:\n            print('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct * 100.\/ total)))\n    for i, (images, labels) in enumerate(val_data_loader):\n        # Run the forward pass\n        labels = torch.max(labels, 1)[1].cuda()\n        outputs = model(images.cuda()).cuda()\n        loss = criterion(outputs, labels)\n        val_loss_list.append(loss.item())\n\n        # Track the accuracy\n        total = labels.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        correct = (predicted == labels).sum().item()\n        val_acc_list.append(correct * 100.\/ total)\n\n    print('Val Loss: {:.4f}, Val Accuracy: {:.2f}% \\n\\n\\n'\n          .format(np.mean(val_loss_list), np.mean(val_acc_list)))","ea9f2a01":"## CNN Model","8558a82a":"## Data Preparation and Exploration"}}