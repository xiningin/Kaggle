{"cell_type":{"3ab8b102":"code","8088ee2a":"code","20259ffe":"code","4974347a":"code","3cb73e6c":"code","5512122d":"code","ba3ea984":"code","8448e92f":"code","f712c7e6":"code","0c53fffc":"code","045a6259":"code","a4ba4084":"code","c2b3f714":"code","d6197b5f":"code","c7dca9c3":"code","f77639ad":"code","2ef3adaa":"code","06e6117b":"code","50a7f266":"code","83eba348":"code","a79ec6fa":"code","08592603":"code","4084ee3c":"code","7efadf72":"code","c5b79375":"code","79d879d2":"code","eb485a3c":"code","b66c62f3":"code","3a2bc1a1":"code","1fb30503":"code","1b9b4688":"code","8eb90583":"code","7c1199c7":"code","40f5b758":"code","3cb5dd9a":"code","8b309362":"code","cfae4665":"code","8d2d107d":"code","a4c5c6cf":"code","67946d66":"code","289986a7":"code","64ccefd0":"code","1aa25504":"code","fdca6135":"code","a1d3caa1":"code","cef85864":"code","92bbd137":"code","b539d4e1":"code","3fe69692":"code","278daf64":"code","9b42c7f9":"code","ed8c82d8":"code","6cffe032":"code","1e62583e":"code","f4d5957e":"code","688599a5":"code","6894aebb":"code","0c3f87c4":"code","7cdd2720":"code","5fc0b380":"code","665491fb":"code","c809bd58":"code","6e8cd9b8":"code","b1aacbc1":"code","f2d6bc89":"code","bc3dfff4":"code","c1123892":"code","12685f4f":"code","bc4e48fa":"code","fb67aff1":"code","24ce82ad":"code","dd4c5e62":"code","b2502d82":"code","290de51b":"code","a48a328e":"code","545d618b":"code","819f908f":"code","45c49ce0":"code","92a21cd7":"code","8915c9ae":"code","7f0b4804":"code","72853162":"code","b5d1c3e6":"code","f9585718":"code","1cc97aa8":"code","53ec6a9a":"code","15d7bec2":"code","76ba6778":"code","79c6ef43":"code","c0a9e4aa":"code","69d9c634":"code","f0e80207":"code","c9bd04e9":"code","081062c0":"markdown","6b5d23d3":"markdown","eb50f660":"markdown","b4d88f9d":"markdown","41f347a3":"markdown","4a7cc752":"markdown","ad367fbd":"markdown","3ae18169":"markdown","e18382e3":"markdown","fc92ba4c":"markdown","b175707c":"markdown","281c067c":"markdown","e99a5d08":"markdown","275652cd":"markdown","bd2111b5":"markdown","de9215b5":"markdown","bd5f264a":"markdown","63be637f":"markdown","58469231":"markdown","88828413":"markdown","d8e36f7b":"markdown","a3c937c1":"markdown","9835d29b":"markdown","89ea78f7":"markdown","52f88d61":"markdown","0f0eb7ad":"markdown","2060c654":"markdown","2be8a7c0":"markdown","89957410":"markdown","91055ea7":"markdown","923c61a2":"markdown","b2ad66e3":"markdown","89deccbd":"markdown","0ffa2fc8":"markdown","080de4a3":"markdown","1ea4b0bc":"markdown","211b1fd8":"markdown","02f3420c":"markdown"},"source":{"3ab8b102":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(style='whitegrid')\nfrom sklearn.preprocessing import LabelEncoder","8088ee2a":"df = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","20259ffe":"df.info()","4974347a":"df.isna().sum()","3cb73e6c":"df.drop(['Unnamed: 32'], axis = 1 , inplace=True)","5512122d":"df.dtypes","ba3ea984":"labelencoder_Y = LabelEncoder()\ndf.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)","8448e92f":"df.iloc[:,1]","f712c7e6":"df.head()","0c53fffc":"df['diagnosis'].value_counts()","045a6259":"sns.countplot(df['diagnosis'], label = 'Count')","a4ba4084":"plt.figure(figsize=(20,15))\nsns.heatmap(df.corr(), annot=True, cmap='viridis')","c2b3f714":"plt.figure(figsize=(10,6))\nsns.heatmap(df[[df.columns[1],df.columns[2], df.columns[3],df.columns[4],df.columns[5],\n                     df.columns[6], df.columns[7], df.columns[8],df.columns[9],df.columns[10],df.columns[11]]].corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True)\nplt.yticks(rotation=0);\nplt.suptitle('Correlation Map')","d6197b5f":"sns.pairplot(df[['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean']], hue = 'diagnosis')","c7dca9c3":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.cluster import KMeans\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import svm\nfrom keras.models import Sequential \nfrom keras.layers import Dense\nfrom sklearn.metrics import confusion_matrix","f77639ad":"df.drop(columns=\"id\", inplace=True, errors=\"ignore\")","2ef3adaa":"X = df.iloc[:,1:31].values\ny = df.iloc[:,0].values","06e6117b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","50a7f266":"lr_model = LogisticRegression()\nlr_model.fit(X_train, y_train)","83eba348":"lr_prediction = lr_model.predict(X_test)\nlr_prediction","a79ec6fa":"lr_acc = accuracy_score(y_test,lr_prediction)\nlr_re = recall_score(y_test,lr_prediction)\nlr_pr = precision_score(y_test,lr_prediction)\nlr_f1 = f1_score(y_test,lr_prediction)\nprint(\"Accuracy score:\",lr_acc)\nprint(\"Recall score:\",lr_re)\nprint(\"Precision score:\",lr_pr)\nprint(\"f1 score:\",lr_f1)","08592603":"plot_confusion_matrix(lr_model,X_test, y_test,cmap= plt.cm.Blues)","4084ee3c":"KNN = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN.fit(X_train, y_train)","7efadf72":"KNN_predictions = KNN.predict(X_test)\nKNN_predictions","c5b79375":"KNN_acc = accuracy_score(y_test,KNN_predictions)\nKNN_re = recall_score(y_test,KNN_predictions)\nKNN_pr = precision_score(y_test,KNN_predictions)\nKNN_f1 = f1_score(y_test,KNN_predictions)\nprint(\"Accuracy score:\",KNN_acc)\nprint(\"Recall score:\",KNN_re)\nprint(\"Precision score:\",KNN_pr)\nprint(\"f1 score:\",KNN_f1)","79d879d2":"plot_confusion_matrix(KNN,X_test, y_test,cmap= plt.cm.Blues)","eb485a3c":"dt_classifier = DecisionTreeClassifier(random_state=42)\ndt_classifier.fit(X_train, y_train)","b66c62f3":"dt_predictions = dt_classifier.predict(X_test)\ndt_predictions","3a2bc1a1":"dt_acc = accuracy_score(y_test,dt_predictions)\ndt_re = recall_score(y_test,dt_predictions)\ndt_pr = precision_score(y_test,dt_predictions)\ndt_f1 = f1_score(y_test,dt_predictions)\nprint(\"Accuracy score:\",dt_acc)\nprint(\"Recall score:\",dt_re)\nprint(\"Precision score:\",dt_pr)\nprint(\"f1 score:\",dt_f1)","1fb30503":"plot_confusion_matrix(dt_classifier,X_test, y_test,cmap= plt.cm.Blues)","1b9b4688":"rf_classifier = RandomForestClassifier(random_state=42)\nrf_classifier.fit(X_train, y_train)","8eb90583":"rf_predictions = rf_classifier.predict(X_test)\nrf_predictions","7c1199c7":"rf_acc = accuracy_score(y_test,rf_predictions)\nrf_re = recall_score(y_test,rf_predictions)\nrf_pr = precision_score(y_test,rf_predictions)\nrf_f1 = f1_score(y_test,rf_predictions)\nprint(\"Accuracy score:\",rf_acc)\nprint(\"Recall score:\",rf_re)\nprint(\"Precision score:\",rf_pr)\nprint(\"f1 score:\",rf_f1)","40f5b758":"plot_confusion_matrix(rf_classifier,X_test, y_test,cmap= plt.cm.Blues)","3cb5dd9a":"Gnb = GaussianNB() \nGnb.fit(X_train, y_train) ","8b309362":"Gnb_predictions = Gnb.predict(X_test)\nGnb_predictions","cfae4665":"Gnb_acc = accuracy_score(y_test,Gnb_predictions)\nGnb_re = recall_score(y_test,Gnb_predictions)\nGnb_pr = precision_score(y_test,Gnb_predictions)\nGnb_f1 = f1_score(y_test,Gnb_predictions)\nprint(\"Accuracy score:\",Gnb_acc)\nprint(\"Recall score:\",Gnb_re)\nprint(\"Precision score:\",Gnb_pr)\nprint(\"f1 score:\",Gnb_f1)","8d2d107d":"plot_confusion_matrix(Gnb,X_test, y_test,cmap= plt.cm.Blues)","a4c5c6cf":"svm_model = svm.SVC(random_state=42)\nsvm_model.fit(X_train, y_train)","67946d66":"svm_prediction = svm_model.predict(X_test)\nsvm_prediction","289986a7":"svm_acc = accuracy_score(y_test,svm_prediction)\nsvm_re = recall_score(y_test,svm_prediction)\nsvm_pr = precision_score(y_test,svm_prediction)\nsvm_f1 = f1_score(y_test,svm_prediction)\nprint(\"Accuracy score:\",svm_acc)\nprint(\"Recall score:\",svm_re)\nprint(\"Precision score:\",svm_pr)\nprint(\"f1 score:\",svm_f1)","64ccefd0":"plot_confusion_matrix(svm_model,X_test, y_test,cmap= plt.cm.Blues)","1aa25504":"ANN_model = Sequential() \nANN_model.add(Dense(activation = \"relu\", input_dim = 30,  \n                     units = 8, kernel_initializer = \"uniform\")) \nANN_model.add(Dense(activation = \"relu\", units = 14,  \n                     kernel_initializer = \"uniform\")) \nANN_model.add(Dense(activation = \"sigmoid\", units = 1,  \n                     kernel_initializer = \"uniform\")) \nANN_model.compile(optimizer = 'adam' , loss = 'binary_crossentropy',  \n                   metrics = ['accuracy'] ) ","fdca6135":"ANN_model.summary()","a1d3caa1":"ANN_model.fit(X_train , y_train , batch_size = 8 ,epochs = 400 )","cef85864":"ANN_prediction = ANN_model.predict(X_test) \nANN_prediction = (ANN_prediction > 0.5) ","92bbd137":"ANN_acc = accuracy_score(y_test,ANN_prediction)\nANN_re = recall_score(y_test,ANN_prediction)\nANN_pr = precision_score(y_test,ANN_prediction)\nANN_f1 = f1_score(y_test,ANN_prediction)\nprint(\"Accuracy score:\",ANN_acc)\nprint(\"Recall score:\",ANN_re )\nprint(\"Precision score:\",ANN_pr)\nprint(\"f1 score:\",ANN_f1)","b539d4e1":"cmann = confusion_matrix(y_test,ANN_prediction) \nprint(cmann)","3fe69692":"models = [('Logistic Regression',lr_acc,lr_pr,lr_re,lr_f1),\n          ('K-Nearest Neighbors (KNN)',KNN_acc,KNN_pr,KNN_re,KNN_f1),\n          ('Decision Tree Classifier',dt_acc,dt_pr,dt_re,dt_f1),\n          ('Random Forest Classifier',rf_acc,rf_pr,rf_re,rf_f1),\n          ('Gaussian Naive Bayes',Gnb_acc,Gnb_pr,Gnb_re,Gnb_f1),\n          ('Support Vector Machine (SVM)',svm_acc,svm_pr,svm_re,svm_f1),\n          ('Artificial Neural Network (ANN)',ANN_acc,ANN_pr,ANN_re,ANN_f1)]\n\nComp_models = pd.DataFrame(data = models, columns=['Model','Accuracy Score','Precision Score','Recall Score','F1 Score'])\nComp_models","278daf64":"sns.catplot(x='Model',y='Accuracy Score',data=Comp_models,kind='point',height=4,aspect=4.5)","9b42c7f9":"standard_scaler = StandardScaler()\nstandard_scaler.fit(df)\n\nscaled_features = standard_scaler.transform(df)\n\nscaled_features","ed8c82d8":"from sklearn.decomposition import PCA\npca_model = PCA(n_components=3)\npca_model.fit(scaled_features)\n\nX_pca = pca_model.transform(scaled_features)\n\nprint('Shape of the dataset after PCA transformation is {}'.format(X_pca.shape))","6cffe032":"pca_df = pd.DataFrame(X_pca, columns=['pca0', 'pca1', 'pca2'])          \npca_df['diagnosis'] = df['diagnosis']\nprint('Shape of PCA dataset is {}'.format(pca_df.shape))\npca_df.head()","1e62583e":"df_target  = df['diagnosis']\nX = pca_df.drop(['diagnosis'], axis=1)\ny = df_target \n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)","f4d5957e":"nb_model_pca = GaussianNB()\nnb_model_pca.fit(X_train, y_train)\nnb_predict_pca = nb_model_pca.predict(X_test)\nnb_accuracy_pca = accuracy_score(y_test, nb_predict_pca)\n\nprint('The accuracy score after PCA using Naive bayes : ',nb_accuracy_pca)","688599a5":"rf_pca = RandomForestClassifier(random_state=42)\nrf_pca.fit(X_train, y_train)\nrf_pca_predict = rf_pca.predict(X_test)\nrf_acc_pca = accuracy_score(y_test,rf_pca_predict) \n\nprint('The accuracy score after PCA using Random Forest : ',rf_acc_pca)","6894aebb":"KNN_pca = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN_pca.fit(X_train, y_train)\nKNN_pca_predict = KNN_pca.predict(X_test)\nKNN_acc_pca = accuracy_score(y_test,KNN_pca_predict)\n\nprint('The accuracy score after PCA using KNN : ',KNN_acc_pca)","0c3f87c4":"dt_pca = DecisionTreeClassifier(random_state=42)\ndt_pca.fit(X_train, y_train)\ndt_pca_predict = dt_pca.predict(X_test)\ndt_acc_pca = accuracy_score(y_test,dt_pca_predict) \n\nprint('The accuracy score after PCA using Decision Tree : ',dt_acc_pca)","7cdd2720":"svm_model_pca = svm.SVC(random_state=42)\nsvm_model_pca.fit(X_train, y_train)\nsvm_predict_pca = svm_model_pca.predict(X_test)\nsvm_accuracy_pca = accuracy_score(y_test, svm_predict_pca)\n\nprint('The accuracy score after PCA using Suppoer Vector Machine : ',svm_accuracy_pca)","5fc0b380":"lr_model_pca = LogisticRegression()\nlr_model_pca.fit(X_train, y_train)\nlr_predict_pca = lr_model_pca.predict(X_test)\nlr_accuracy_pca = accuracy_score(y_test, lr_predict_pca)\n\nprint('The accuracy score after PCA using Logistic Regression : ',lr_accuracy_pca)","665491fb":"models = [('K-Nearest Neighbors (KNN)',KNN_acc,KNN_acc_pca),\n         ('Random Forest Classifier',rf_acc,rf_acc_pca),\n         ('Gaussian Naive Bayes',Gnb_acc,nb_accuracy_pca),\n          ('Decision Tree Classifier',dt_acc,dt_acc_pca),\n         ('Suppoer Vector Machine',svm_acc,svm_accuracy_pca),\n         ('Logistic Regression',lr_acc,lr_accuracy_pca)]\n\nComp_models = pd.DataFrame(data = models, columns=['Model','Accuracy without PCA','Accuracy with PCA'])\nComp_models","c809bd58":"X25_train, X25_test, y25_train, y25_test = train_test_split(X, y, test_size=0.25, random_state=42)","6e8cd9b8":"#Logistic Regression\nlr_model_25=LogisticRegression()\nlr_model_25.fit(X25_train, y25_train)\nlr_prediction_25 = lr_model_25.predict(X25_test)\nlr_acc_25 = accuracy_score(y25_test,lr_prediction_25)\n\n#KNeighborsClassifier\nKNN_25 = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN_25.fit(X25_train, y25_train)\nKNN_predictions_25 = KNN_25.predict(X25_test)\nKNN_acc_25 = accuracy_score(y25_test,KNN_predictions_25)\n\n#Decision Tree\ndt_classifier_25 = DecisionTreeClassifier(random_state=42)\ndt_classifier_25.fit(X25_train, y25_train)\ndt_predictions_25 = dt_classifier_25.predict(X25_test)\ndt_acc_25 = accuracy_score(y25_test,dt_predictions_25)\n\n#Random Forest Classifier\nrf_classifier_25 = RandomForestClassifier(random_state=42)\nrf_classifier_25.fit(X25_train, y25_train)\nrf_predictions_25 = rf_classifier_25.predict(X25_test)\nrf_acc_25 = accuracy_score(y25_test,rf_predictions_25)\n\n#Gaussian Naive Bayes\nGnb_25 = GaussianNB() \nGnb_25.fit(X25_train, y25_train) \nGnb_predictions_25 = Gnb_25.predict(X25_test)\nGnb_acc_25 = accuracy_score(y25_test,Gnb_predictions_25)\n\n#Support Vector Machine\nsvm_model_25 = svm.SVC(random_state=42)\nsvm_model_25.fit(X25_train, y25_train)\nsvm_prediction_25 = svm_model_25.predict(X25_test)\nsvm_acc_25 = accuracy_score(y25_test,svm_prediction_25)\n\n#Artificial Neural Network (ANN)\n#ANN_model_25 = Sequential() \n#ANN_model_25.add(Dense(activation = \"relu\", input_dim = 30,  \n#                     units = 8, kernel_initializer = \"uniform\")) \n#ANN_model_25.add(Dense(activation = \"relu\", units = 14,  \n#                     kernel_initializer = \"uniform\")) \n#ANN_model_25.add(Dense(activation = \"sigmoid\", units = 1,  \n#                     kernel_initializer = \"uniform\")) \n#ANN_model_25.compile(optimizer = 'adam' , loss = 'binary_crossentropy',  \n#                   metrics = ['accuracy'] ) \n#ANN_model_25.fit(X25_train , y25_train , batch_size = 8 ,epochs = 400 )\n#ANN_prediction_25 = ANN_model_25.predict(X25_test) \n#ANN_prediction_25 = (ANN_prediction_25 > 0.5) \n#ANN_acc_25 = accuracy_score(y25_test,ANN_prediction_25)\n","b1aacbc1":"X30_train, X30_test, y30_train, y30_test = train_test_split(X, y, test_size=0.30, random_state=42)","f2d6bc89":"#Logistic Regression\nlr_model_30=LogisticRegression()\nlr_model_30.fit(X30_train, y30_train)\nlr_prediction_30 = lr_model_30.predict(X30_test)\nlr_acc_30 = accuracy_score(y30_test,lr_prediction_30)\n\n#KNeighborsClassifier\nKNN_30 = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN_30.fit(X30_train, y30_train)\nKNN_predictions_30 = KNN_30.predict(X30_test)\nKNN_acc_30 = accuracy_score(y30_test,KNN_predictions_30)\n\n#Decision Tree\ndt_classifier_30 = DecisionTreeClassifier(random_state=42)\ndt_classifier_30.fit(X30_train, y30_train)\ndt_predictions_30 = dt_classifier_30.predict(X30_test)\ndt_acc_30 = accuracy_score(y30_test,dt_predictions_30)\n\n#Random Forest Classifier\nrf_classifier_30 = RandomForestClassifier(random_state=42)\nrf_classifier_30.fit(X30_train, y30_train)\nrf_predictions_30 = rf_classifier_30.predict(X30_test)\nrf_acc_30 = accuracy_score(y30_test,rf_predictions_30)\n\n#Gaussian Naive Bayes\nGnb_30 = GaussianNB() \nGnb_30.fit(X30_train, y30_train) \nGnb_predictions_30 = Gnb_30.predict(X30_test)\nGnb_acc_30 = accuracy_score(y30_test,Gnb_predictions_30)\n\n#Support Vector Machine\nsvm_model_30 = svm.SVC(random_state=42)\nsvm_model_30.fit(X30_train, y30_train)\nsvm_prediction_30 = svm_model_30.predict(X30_test)\nsvm_acc_30 = accuracy_score(y30_test,svm_prediction_30)\n","bc3dfff4":"X35_train, X35_test, y35_train, y35_test = train_test_split(X, y, test_size=0.35, random_state=42)","c1123892":"#Logistic Regression\nlr_model_35= LogisticRegression()\nlr_model_35.fit(X35_train, y35_train)\nlr_prediction_35 = lr_model_35.predict(X35_test)\nlr_acc_35 = accuracy_score(y35_test,lr_prediction_35)\n\n#KNeighborsClassifier\nKNN_35 = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN_35.fit(X35_train, y35_train)\nKNN_predictions_35 = KNN_35.predict(X35_test)\nKNN_acc_35 = accuracy_score(y35_test,KNN_predictions_35)\n\n#Decision Tree\ndt_classifier_35 = DecisionTreeClassifier(random_state=42)\ndt_classifier_35.fit(X35_train, y35_train)\ndt_predictions_35 = dt_classifier_35.predict(X35_test)\ndt_acc_35 = accuracy_score(y35_test,dt_predictions_35)\n\n#Random Forest Classifier\nrf_classifier_35 = RandomForestClassifier(random_state=42)\nrf_classifier_35.fit(X35_train, y35_train)\nrf_predictions_35 = rf_classifier_35.predict(X35_test)\nrf_acc_35 = accuracy_score(y35_test,rf_predictions_35)\n\n#Gaussian Naive Bayes\nGnb_35 = GaussianNB() \nGnb_35.fit(X35_train, y35_train) \nGnb_predictions_35 = Gnb_35.predict(X35_test)\nGnb_acc_35 = accuracy_score(y35_test,Gnb_predictions_35)\n\n#Support Vector Machine\nsvm_model_35 = svm.SVC(random_state=42)\nsvm_model_35.fit(X35_train, y35_train)\nsvm_prediction_35 = svm_model_35.predict(X35_test)\nsvm_acc_35 = accuracy_score(y35_test,svm_prediction_35)\n","12685f4f":"models_total = [('Logistic Regression',lr_acc,lr_acc_25,lr_acc_30,lr_acc_35 ),\n          ('K-Nearest Neighbors (KNN)',KNN_acc,KNN_acc_25,KNN_acc_30,KNN_acc_35 ),\n          ('Decision Tree Classifier',dt_acc,dt_acc_25,dt_acc_30,dt_acc_35 ),\n          ('Random Forest Classifier',rf_acc,rf_acc_25,rf_acc_30,rf_acc_35 ),\n          ('Gaussian Naive Bayes',Gnb_acc,Gnb_acc_25,Gnb_acc_30,Gnb_acc_35 ),\n          ('Support Vector Machine (SVM)',svm_acc,svm_acc_25,svm_acc_30,svm_acc_35 )]\n\nComp_models_total = pd.DataFrame(data = models_total, columns=['Model','Accuracy Score-20%','Accuracy Score-25%','Accuracy Score-30%','Accuracy Score-35%'])\nComp_models_total","bc4e48fa":"lr_gs = LogisticRegression()\nlr_params = {\n    'penalty' : ['l2','elasticnet','none'],\n    'class_weight' : ['dict','balanced','None'],\n    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n    'multi_class' : ['auto', 'ovr', 'multinomial']\n}\ngs_lr = GridSearchCV(estimator = lr_gs, param_grid = lr_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_lr.fit(X_train,y_train)","fb67aff1":"gs_lr.best_params_","24ce82ad":"Grid_lr = LogisticRegression(class_weight='dict',multi_class='auto',penalty='l2',solver='newton-cg')\nGrid_lr.fit(X_train, y_train)\nGrid_lr_predictions = Grid_lr.predict(X_test)\nGrid_lr_acc = accuracy_score(y_test,Grid_lr_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_lr_acc)\nprint(\"Accuracy score without Grid Search:\",lr_acc)","dd4c5e62":"plot_confusion_matrix(Grid_lr,X_test, y_test,cmap= plt.cm.Blues)","b2502d82":"KNN_gs = KNeighborsClassifier()\nKNN_params = {\n    'n_neighbors' : [5,7,9,11,13,15,19,23],\n    'algorithm': ['auto','ball_tree', 'kd_tree', 'brute'],\n    'p' : [1,2]\n}\ngs_knn = GridSearchCV(estimator = KNN_gs, param_grid = KNN_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_knn.fit(X_train,y_train)","290de51b":"gs_knn.best_params_","a48a328e":"Grid_KNN = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2 ,algorithm='auto')\nGrid_KNN.fit(X_train, y_train)\nGrid_KNN_predictions = Grid_KNN.predict(X_test)\nGrid_KNN_acc = accuracy_score(y_test,Grid_KNN_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_KNN_acc)\nprint(\"Accuracy score without Grid Search:\",KNN_acc)","545d618b":"plot_confusion_matrix(Grid_KNN,X_test, y_test,cmap= plt.cm.Blues)","819f908f":"dt_classifier_gs = DecisionTreeClassifier()\ndt_classifier_params = {\n    'criterion': ['gini', 'entropy'],\n    'splitter' : ['best', 'random'],\n    'max_features' : ['auto','sqrt','log2',None],\n    'class_weight' : ['dict', 'balanced', None]\n\n}\ngs_dt_classifier = GridSearchCV(estimator = dt_classifier_gs, param_grid = dt_classifier_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_dt_classifier.fit(X_train,y_train)","45c49ce0":"gs_dt_classifier.best_params_","92a21cd7":"Grid_dt = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_features=None, splitter='random',random_state=42)\nGrid_dt.fit(X_train, y_train)\nGrid_dt_predictions = Grid_dt.predict(X_test)\nGrid_dt_acc = accuracy_score(y_test,Grid_dt_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_dt_acc)\nprint(\"Accuracy score without Grid Search:\",dt_acc)","8915c9ae":"plot_confusion_matrix(Grid_dt,X_test, y_test,cmap= plt.cm.Blues)","7f0b4804":"rf_classifier_gs = RandomForestClassifier()\nrf_classifier_params = {\n    'criterion': ['gini', 'entropy'],\n    'max_features' : ['auto','sqrt','log2',None]\n\n}\ngs_rf_classifier = GridSearchCV(estimator = rf_classifier_gs, param_grid = rf_classifier_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_rf_classifier.fit(X_train,y_train)","72853162":"gs_rf_classifier.best_params_","b5d1c3e6":"Grid_rf = RandomForestClassifier(criterion='entropy', max_features=None,random_state=42)\nGrid_rf.fit(X_train, y_train)\nGrid_rf_predictions = Grid_rf.predict(X_test)\nGrid_rf_acc = accuracy_score(y_test,Grid_rf_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_rf_acc)\nprint(\"Accuracy score without Grid Search:\",rf_acc)","f9585718":"plot_confusion_matrix(Grid_rf,X_test, y_test,cmap= plt.cm.Blues)","1cc97aa8":"Gnb_gs = GaussianNB() \nGnb_params = {\n    'var_smoothing': np.logspace(0,-9, num=100)\n}\ngs_Gnb = GridSearchCV(estimator = Gnb_gs, param_grid = Gnb_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_Gnb.fit(X_train,y_train)","53ec6a9a":"gs_Gnb.best_params_","15d7bec2":"Grid_Gnb = GaussianNB(var_smoothing= 0.15199110829529336 )\nGrid_Gnb.fit(X_train, y_train)\nGrid_Gnb_predictions = Grid_Gnb.predict(X_test)\nGrid_Gnb_acc = accuracy_score(y_test,Grid_Gnb_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_Gnb_acc)\nprint(\"Accuracy score without Grid Search:\",Gnb_acc)","76ba6778":"plot_confusion_matrix(Grid_Gnb,X_test, y_test,cmap= plt.cm.Blues)","79c6ef43":"svm_model_gs = svm.SVC()\nsvm_model_params = {\n    'degree' : [2,3,4,5,6],\n    'gamma' : ['scale','auto'],\n    'shrinking' : [True,False],\n    'probability' : [True, False],\n    'class_weight' : ['dict', 'balanced', None],\n    'verbose' : [True, False],\n    'decision_function_shape' : ['ovo', 'ovr']\n}\ngs_svm_model = GridSearchCV(estimator = svm_model_gs, param_grid = svm_model_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_svm_model.fit(X_train,y_train)","c0a9e4aa":"gs_svm_model.best_params_","69d9c634":"Grid_svm = svm.SVC(class_weight = None, decision_function_shape='ovo',degree=2,gamma='scale',probability=True,\n                   shrinking=True, verbose= True ,random_state=42)\nGrid_svm.fit(X_train, y_train)\nGrid_svm_predictions = Grid_svm.predict(X_test)\nGrid_svm_acc = accuracy_score(y_test,Grid_svm_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_svm_acc)\nprint(\"Accuracy score without Grid Search:\",svm_acc)","f0e80207":"plot_confusion_matrix(Grid_svm,X_test, y_test,cmap= plt.cm.Blues)","c9bd04e9":"models_total = [('Logistic Regression',lr_acc,Grid_lr_acc ),\n          ('K-Nearest Neighbors (KNN)',KNN_acc,Grid_KNN_acc ),\n          ('Decision Tree Classifier',dt_acc,Grid_dt_acc ),\n          ('Random Forest Classifier',rf_acc,Grid_rf_acc ),\n          ('Gaussian Naive Bayes',Gnb_acc,Grid_Gnb_acc),\n          ('Support Vector Machine (SVM)',svm_acc,Grid_svm_acc )]\n\nComp_models_total = pd.DataFrame(data = models_total, columns=['Model','Accuracy Score  without Grid Search','Accuracy Score with Grid Search'])\nComp_models_total","081062c0":"## 7.6.Support Vector Machine","6b5d23d3":"We converted the diagnosis values to numerical values. B=0 and M=1","eb50f660":"## 7.1.Logistic Regression ","b4d88f9d":"## 1.2.Importing Data","41f347a3":"## 3.2.KNeighborsClassifier","4a7cc752":"## 3.6. Support Vector Machine","ad367fbd":"# 4.Comparison of Models","3ae18169":"## 7.2.KNeighborsClassifier ","e18382e3":"We will divide our data into 4 variables; The x_train and y_train variables for training, x_test and y_test variables to test the model at the end of the training.\n\nThe test_size parameter specifies what percentage of the data set should be reserved for testing","fc92ba4c":"# 5.PCA: Principal Component Analysis","b175707c":"## 3.1. Logistic Regression","281c067c":"## 7.5.Gaussian Naive Bayes","e99a5d08":"## 7.4.Random Forest Classifier","275652cd":"We delete the column 'Unnamed: 32' because it does not affect the data set.","bd2111b5":"## 2.3.Distribution Charts","de9215b5":"## Comparison of Accuracy Scores","bd5f264a":"## Comparison of Accuracy Scores","63be637f":"## 2.1.Diagnosis Values","58469231":"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\nn the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\n\nAttribute Information:\n1. ID number\n1. Diagnosis (M = malignant, B = benign)\n\nTen real-valued features are computed for each cell nucleus:\n\n1. radius (mean of distances from center to points on the perimeter)\n1. texture (standard deviation of gray-scale values)\n1. perimeter\n1. area\n1. smoothness (local variation in radius lengths)\n1. compactness (perimeter^2 \/ area - 1.0)\n1. concavity (severity of concave portions of the contour)\n1. concave points (number of concave portions of the contour)\n1. symmetry\n1. fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. All feature values are recoded with four significant digits.","88828413":"## 25% rate for testing","d8e36f7b":"# 3.Model Building","a3c937c1":"# 2.Data Visualization","9835d29b":"## 3.4.Random Forest Classifier","89ea78f7":"## 3.7.Artificial Neural Network (ANN)","52f88d61":"## 30% rate for testing","0f0eb7ad":"## 2.2.Correlation Map","2060c654":"We define the \"diagnosis\" column to y and the other columns to X.","2be8a7c0":"## 35% rate for testing","89957410":"# 6.Comparison of Test&Train Percentage","91055ea7":"## 3.5.Gaussian Naive Bayes ","923c61a2":"# 7.Grid Search Application on Models","b2ad66e3":"First, We delete the \"id\" column as it will not contribute to model training.","89deccbd":"## 1.1.Importing Libraries","0ffa2fc8":"## 1.3.Data Analysis","080de4a3":"Count the number of empty values in each column:\n","1ea4b0bc":"## 3.3.Decision Tree","211b1fd8":"## 7.3.Decision Tree","02f3420c":"While training the previous models, we allocated 20% of the model for testing. Now, let's compare the accuracy results of models with different ratios."}}