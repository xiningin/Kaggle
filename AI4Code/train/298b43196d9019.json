{"cell_type":{"ce844d02":"code","7fccaac1":"code","f750231d":"code","7f54833c":"code","b79a8418":"code","57e6995b":"code","a074f143":"code","00ecc0cc":"code","e0d61ea6":"code","c3a6f14a":"code","2e29aad8":"code","10b51244":"code","74e25002":"code","f89d1bb1":"code","3d33ca57":"code","e10f68bf":"code","28b358ba":"code","afb1084f":"code","6dd937ce":"code","2a61e788":"code","066630d5":"code","cbd34313":"code","958fd846":"code","dd36dbab":"code","9480996b":"code","6a143efa":"code","b5e1ea11":"code","0b9e0526":"code","780f0626":"code","819c5085":"code","9f08db00":"code","78a09c69":"code","edf44a0a":"code","e19f36ae":"code","daa7181a":"code","37720e99":"code","0d4e01b5":"code","503ef2ee":"code","7e6daa57":"code","a2539da2":"code","66639bbf":"code","52329ae6":"code","74136954":"code","fce9ebf3":"code","40adf708":"code","0d677e8d":"code","6d177e9f":"code","2564a99f":"code","a35c2bf4":"code","07ec5037":"code","d733ee11":"code","10c7635d":"code","e22d9197":"code","84567e19":"code","a9d9b62b":"code","fc4e0e1a":"code","adffd5af":"code","770e6e95":"code","d8ec9076":"code","609215fb":"code","70113b39":"code","66aaee69":"code","4043e209":"code","caf50647":"code","5101680e":"code","eea8fdd4":"code","f2b07f65":"code","d3577be0":"code","b808518a":"code","d4b36704":"code","fd8364ef":"code","209645e0":"code","42b21d47":"code","3d16a9a7":"code","be681ac4":"code","1194153c":"code","7c038ef1":"code","5b19447a":"code","6b942f15":"code","7aaf2639":"code","9bc540b0":"code","33fd1434":"code","663899fc":"markdown","62ec0903":"markdown","423c7f99":"markdown","96308ed2":"markdown","1ddcf01d":"markdown","4f45f157":"markdown","a8d79810":"markdown","55096ad1":"markdown","a7007a1b":"markdown"},"source":{"ce844d02":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import OrderedDict\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","7fccaac1":"train = pd.read_csv(\"..\/input\/tmdb-box-office-prediction\/train.csv\")\ntest=pd.read_csv(\"..\/input\/tmdb-box-office-prediction\/test.csv\")","f750231d":"# shows the data shape\ntrain.shape","7f54833c":"#check top n rows\ntrain.head(2)","b79a8418":"# shows the data column info\ntrain.info()","57e6995b":"data.loc[data['id'] == 16,'revenue'] = 192864         \ndata.loc[data['id'] == 90,'budget'] = 30000000                  \ndata.loc[data['id'] == 118,'budget'] = 60000000       \ndata.loc[data['id'] == 149,'budget'] = 18000000       \ndata.loc[data['id'] == 313,'revenue'] = 12000000       \ndata.loc[data['id'] == 451,'revenue'] = 12000000      \ndata.loc[data['id'] == 464,'budget'] = 20000000       \ndata.loc[data['id'] == 470,'budget'] = 13000000       \ndata.loc[data['id'] == 513,'budget'] = 930000         \ndata.loc[data['id'] == 797,'budget'] = 8000000        \ndata.loc[data['id'] == 819,'budget'] = 90000000       \ndata.loc[data['id'] == 850,'budget'] = 90000000       \ndata.loc[data['id'] == 1007,'budget'] = 2              \ndata.loc[data['id'] == 1112,'budget'] = 7500000       \ndata.loc[data['id'] == 1131,'budget'] = 4300000        \ndata.loc[data['id'] == 1359,'budget'] = 10000000       \ndata.loc[data['id'] == 1542,'budget'] = 1             \ndata.loc[data['id'] == 1570,'budget'] = 15800000       \ndata.loc[data['id'] == 1571,'budget'] = 4000000        \ndata.loc[data['id'] == 1714,'budget'] = 46000000       \ndata.loc[data['id'] == 1721,'budget'] = 17500000       \ndata.loc[data['id'] == 1865,'revenue'] = 25000000      \ndata.loc[data['id'] == 1885,'budget'] = 12             \ndata.loc[data['id'] == 2091,'budget'] = 10             \ndata.loc[data['id'] == 2268,'budget'] = 17500000       \ndata.loc[data['id'] == 2491,'budget'] = 6              \ndata.loc[data['id'] == 2602,'budget'] = 31000000       \ndata.loc[data['id'] == 2612,'budget'] = 15000000       \ndata.loc[data['id'] == 2696,'budget'] = 10000000      \ndata.loc[data['id'] == 2801,'budget'] = 10000000       \ndata.loc[data['id'] == 335,'budget'] = 2 \ndata.loc[data['id'] == 348,'budget'] = 12\ndata.loc[data['id'] == 470,'budget'] = 13000000 \ndata.loc[data['id'] == 513,'budget'] = 1100000\ndata.loc[data['id'] == 640,'budget'] = 6 \ndata.loc[data['id'] == 696,'budget'] = 1\ndata.loc[data['id'] == 797,'budget'] = 8000000 \ndata.loc[data['id'] == 850,'budget'] = 1500000\ndata.loc[data['id'] == 1199,'budget'] = 5 \ndata.loc[data['id'] == 1282,'budget'] = 9              \ndata.loc[data['id'] == 1347,'budget'] = 1\ndata.loc[data['id'] == 1755,'budget'] = 2\ndata.loc[data['id'] == 1801,'budget'] = 5\ndata.loc[data['id'] == 1918,'budget'] = 592 \ndata.loc[data['id'] == 2033,'budget'] = 4\ndata.loc[data['id'] == 2118,'budget'] = 344 \ndata.loc[data['id'] == 2252,'budget'] = 130\ndata.loc[data['id'] == 2256,'budget'] = 1 \ndata.loc[data['id'] == 2696,'budget'] = 10000000","a074f143":"test.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30","00ecc0cc":"trainAdditionalFeatures = pd.read_csv('..\/input\/tmdb-competition-additional-features\/TrainAdditionalFeatures.csv')\ntestAdditionalFeatures = pd.read_csv('..\/input\/tmdb-competition-additional-features\/TestAdditionalFeatures.csv')\ntrain = pd.merge(train, trainAdditionalFeatures, how='left', on=['imdb_id'])\ntest = pd.merge(test, testAdditionalFeatures, how='left', on=['imdb_id'])","e0d61ea6":"print(\"Missing rating in Train set\", train['rating'].isna().sum())\nprint(\"Missing total Votes in Train set\", train['totalVotes'].isna().sum())\nprint(\"\")\nprint(\"Missing rating in Test set\", test['rating'].isna().sum())\nprint(\"Missing total Votes in Test set\", test['totalVotes'].isna().sum())","c3a6f14a":"#first removing features which are irrelevant for our prediction\ndata.drop(['imdb_id','poster_path'],axis=1,inplace=True)\ntest.drop(['imdb_id','poster_path'],axis=1,inplace=True)","2e29aad8":"data.isnull().sum()","10b51244":"#we have a lot of null values for homepage\n#Converting homepage as binary\ndata['has_homepage'] = 0\ndata.loc[data['homepage'].isnull() == False, 'has_homepage'] = 1\ntest['has_homepage'] = 0\ntest.loc[test['homepage'].isnull() == False, 'has_homepage'] = 1\n\n#Homepage v\/s Revenue\nsns.catplot(x='has_homepage', y='revenue', data=data);\nplt.title('Revenue for film with and without homepage');","74e25002":"# dropping the 'homepage' feature which is now irrelevant for our prediction\ndata=data.drop(['homepage'],axis =1)\ntest=test.drop(['homepage'],axis =1)","f89d1bb1":"#Converting collections as binary\ndata['collection'] = 0\ndata.loc[data['belongs_to_collection'].isnull() == False, 'collection'] = 1\ntest['collection'] = 0\ntest.loc[test['belongs_to_collection'].isnull() == False, 'collection'] = 1\n\n#collections v\/s Revenue\nsns.catplot(x='collection', y='revenue', data=data);\nplt.title('Revenue for film with and without collection');","3d33ca57":"# dropping the 'belongs_to_collection' feature which is now irrelevant for our prediction\ndata=data.drop(['belongs_to_collection'],axis =1)\ntest=test.drop(['belongs_to_collection'],axis =1)","e10f68bf":"#Exploring Genres\ngenres = {}\nfor i in data['genres']:\n    if(not(pd.isnull(i))):\n        if (eval(i)[0]['name']) not in genres:\n            genres[eval(i)[0]['name']]=1\n        else:\n            genres[eval(i)[0]['name']]+=1","28b358ba":"#Exploring Genres\nplt.figure(figsize = (12, 8))\n#text = ' '.join([i for j in genres for i in j])\nwordcloud = WordCloud(background_color=\"white\",width=1000,height=1000, max_words=10,relative_scaling=0.5,normalize_plurals=False).generate_from_frequencies(genres)\n\nplt.imshow(wordcloud)\nplt.title('Top genres')\nplt.axis(\"off\")\nplt.show()\ngenres = OrderedDict(genres)\n#Drama, Comedy and Thriller are popular genres\nOrderedDict(sorted(genres.items(), key=lambda t: t[1]))","afb1084f":"#adding number of genres for each movie\ngenres_count=[]\nfor i in data['genres']:\n    if(not(pd.isnull(i))):\n        genres_count.append(len(eval(i)))\n    else:\n        genres_count.append(0)\ndata['num_genres'] = genres_count","6dd937ce":"#Genres v\/s revenue\nsns.catplot(x='num_genres', y='revenue', data=data);\nplt.title('Revenue for different number of genres in the film');","2a61e788":"#Adding genres count for test data\ngenres_count_test=[]\nfor i in test['genres']:\n    if(not(pd.isnull(i))): \n        genres_count_test.append(len(eval(i)))\n    else:\n        genres_count_test.append(0)\ntest['num_genres'] = genres_count_test","066630d5":"#Dropping genres\ndata.drop(['genres'],axis=1, inplace = True)\ntest.drop(['genres'],axis=1, inplace = True)","cbd34313":"#Production companies\n#Adding production_companies count for  data\nprod_comp_count=[]\nfor i in data['production_companies']:\n    if(not(pd.isnull(i))):\n        prod_comp_count.append(len(eval(i)))\n    else:\n        prod_comp_count.append(0)\ndata['num_prod_companies'] = prod_comp_count","958fd846":"#number of prod companies vs revenue\nsns.catplot(x='num_prod_companies', y='revenue', data=data);\nplt.title('Revenue for different number of production companies in the film');","dd36dbab":"#Adding production_companies count for  test data\nprod_comp_count_test=[]\nfor i in test['production_companies']:\n    if(not(pd.isnull(i))):\n        prod_comp_count_test.append(len(eval(i)))\n    else:\n        prod_comp_count_test.append(0)\ntest['num_prod_companies'] = prod_comp_count_test","9480996b":"#Dropping production_companies\ndata.drop(['production_companies'],axis=1, inplace = True)\ntest.drop(['production_companies'],axis=1, inplace = True)","6a143efa":"#production_countries\n#Adding production_countries count for  data\nprod_coun_count=[]\nfor i in data['production_countries']:\n    if(not(pd.isnull(i))):\n        prod_coun_count.append(len(eval(i)))\n    else:\n        prod_coun_count.append(0)\ndata['num_prod_countries'] = prod_coun_count","b5e1ea11":"#number of prod countries vs revenue\nsns.catplot(x='num_prod_countries', y='revenue', data=data);\nplt.title('Revenue for different number of production countries in the film');","0b9e0526":"#Adding production_countries count for  test data\nprod_coun_count_test=[]\nfor i in test['production_countries']:\n    if(not(pd.isnull(i))):\n        prod_coun_count_test.append(len(eval(i)))\n    else:\n        prod_coun_count_test.append(0)\ntest['num_prod_countries'] = prod_coun_count_test","780f0626":"#Dropping production_countries\ndata.drop(['production_countries'],axis=1, inplace = True)\ntest.drop(['production_countries'],axis=1, inplace = True)","819c5085":"#handling overview\n#mapping overview present to 1 and nulls to 0\ndata['overview']=data['overview'].apply(lambda x: 0 if pd.isnull(x) else 1)\ntest['overview']=test['overview'].apply(lambda x: 0 if pd.isnull(x) else 1)\nsns.catplot(x='overview', y='revenue', data=data);\nplt.title('Revenue for film with and without overview');","9f08db00":"#cast\n#Adding cast count for  data\ntotal_cast=[]\nfor i in data['cast']:\n    if(not(pd.isnull(i))):\n        total_cast.append(len(eval(i)))\n    else:\n        total_cast.append(0)\ndata['cast_count'] = total_cast","78a09c69":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.scatter(data['cast_count'], data['revenue'])\nplt.title('Number of cast members vs revenue');","edf44a0a":"#cast\n#Adding cast count for  test data\ntotal_cast=[]\nfor i in test['cast']:\n    if(not(pd.isnull(i))):\n        total_cast.append(len(eval(i)))\n    else:\n        total_cast.append(0)\ntest['cast_count'] = total_cast","e19f36ae":"#Dropping cast\ndata= data.drop(['cast'],axis=1)\ntest= test.drop(['cast'],axis=1)","daa7181a":"#crew\ntotal_crew=[]\nfor i in data['crew']:\n    if(not(pd.isnull(i))): \n        total_crew.append(len(eval(i)))\n    else:\n        total_crew.append(0)\ndata['crew_count'] = total_crew","37720e99":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.scatter(data['crew_count'], data['revenue'])\nplt.title('Number of crew members vs revenue');","0d4e01b5":"#Adding crew count for  test data\ntotal_crew=[]\nfor i in test['crew']:\n    if(not(pd.isnull(i))):\n        total_crew.append(len(eval(i)))\n    else:\n        total_crew.append(0)\ntest['crew_count'] = total_crew","503ef2ee":"#Dropping crew\ndata= data.drop(['crew'],axis=1)\ntest= test.drop(['crew'],axis=1)","7e6daa57":"#Dropping original_title\ndata= data.drop(['original_title'],axis=1)\ntest= test.drop(['original_title'],axis=1)","a2539da2":"#How language contributes to revenue\nplt.figure(figsize=(15,11)) #figure size\n\n#It's another way to plot our data. using a variable that contains the plot parameters\ng1 = sns.boxenplot(x='original_language', y='revenue', \n                   data=data[(data['original_language'].isin((data['original_language'].sort_values().value_counts()[:10].index.values)))])\ng1.set_title(\"Revenue by language\", fontsize=20) # title and fontsize\ng1.set_xticklabels(g1.get_xticklabels(),rotation=45) # It's the way to rotate the xticks when we use variable to our graphs\ng1.set_xlabel('Language', fontsize=18) # Xlabel\ng1.set_ylabel('Revenue', fontsize=18) #Ylabel\n\nplt.show()","66639bbf":"#Taking only en and zh into consideration as they are the highest grossing\ndata['original_language'] =data['original_language'].apply(lambda x: 1 if x=='en' else(2 if x=='zh' else 0))\ntest['original_language'] =test['original_language'].apply(lambda x: 1 if x=='en' else(2 if x=='zh' else 0))","52329ae6":"#check correlation between variables\ncol = ['revenue','budget','popularity','runtime']\nplt.subplots(figsize=(10, 8))\ncorr = data[col].corr()\nsns.heatmap(corr, xticklabels=col,yticklabels=col, linewidths=.5, cmap=\"Reds\")","74136954":"#budget and revenue are highly correlated\nsns.regplot(x=\"budget\", y=\"revenue\", data=data)","fce9ebf3":"#Check how revenue depends of day\ndata['release_date']=pd.to_datetime(data['release_date'])\ntest['release_date']=pd.to_datetime(data['release_date'])","40adf708":"release_day = data['release_date'].value_counts().sort_index()\nrelease_day_revenue= data.groupby(['release_date'])['revenue'].sum()\nrelease_day_revenue.index=release_day_revenue.index.dayofweek\nsns.barplot(release_day_revenue.index,release_day_revenue, data = data,ci=None)\nplt.show()","0d677e8d":"#adding day feature to the data\ndata['release_day']=data['release_date'].dt.dayofweek \ntest['release_day']=test['release_date'].dt.dayofweek ","6d177e9f":"#filling nulls in test\ntest['release_day']=test['release_day'].fillna(0)","2564a99f":"data.drop(['release_date'],axis=1,inplace=True)\ntest.drop(['release_date'],axis=1,inplace=True)","a35c2bf4":"#status\nprint(\"train data\")\nprint(data['status'].value_counts())\nprint(\"test data\")\ntest['status'].value_counts()","07ec5037":"#Feature is irrelevant hence dropping\ndata.drop(['status'],axis=1,inplace =True)\ntest.drop(['status'],axis=1,inplace =True)","d733ee11":"#keywords\nKeywords_count=[]\nfor i in data['Keywords']:\n    if(not(pd.isnull(i))):\n        Keywords_count.append(len(eval(i)))\n    else:\n        Keywords_count.append(0)\ndata['Keywords_count'] = Keywords_count","10c7635d":"#number of prod countries vs revenue\nsns.catplot(x='Keywords_count', y='revenue', data=data);\nplt.title('Revenue for different number of Keywords in the film');","e22d9197":"Keywords_count=[]\nfor i in test['Keywords']:\n    if(not(pd.isnull(i))):\n        Keywords_count.append(len(eval(i)))\n    else:\n        Keywords_count.append(0)\ntest['Keywords_count'] = Keywords_count","84567e19":"#Dropping title and keywords\ndata=data.drop(['Keywords'],axis=1)\ndata=data.drop(['title'],axis=1)\ntest=test.drop(['Keywords'],axis=1)\ntest=test.drop(['title'],axis=1)","a9d9b62b":"#tagline\ndata['isTaglineNA'] = 0\ndata.loc[data['tagline'].isnull() == False, 'isTaglineNA'] = 1\ntest['isTaglineNA'] = 0\ntest.loc[test['tagline'].isnull() == False, 'isTaglineNA'] = 1\n\n#Tagline v\/s Revenue\nsns.catplot(x='isTaglineNA', y='revenue', data=data);\nplt.title('Revenue for film with and without tagline');","fc4e0e1a":"data.drop(['tagline'],axis=1,inplace =True)\ntest.drop(['tagline'],axis=1,inplace =True)","adffd5af":"#runtime has 2 nulls; setting it to the mean\n#filling nulls in test\ndata['runtime']=data['runtime'].fillna(data['runtime'].mean())\ntest['runtime']=test['runtime'].fillna(test['runtime'].mean())","770e6e95":"#spoken languages\n#adding number of spoken languages for each movie\nspoken_count=[]\nfor i in data['spoken_languages']:\n    if(not(pd.isnull(i))):\n        spoken_count.append(len(eval(i)))\n    else:\n        spoken_count.append(0)\ndata['spoken_count'] = spoken_count\n\nspoken_count_test=[]\nfor i in test['spoken_languages']:\n    if(not(pd.isnull(i))):\n        spoken_count_test.append(len(eval(i)))\n    else:\n        spoken_count_test.append(0)\ntest['spoken_count'] = spoken_count_test","d8ec9076":"#dropping spoken_languages\ndata.drop(['spoken_languages'],axis=1,inplace=True)\ntest.drop(['spoken_languages'],axis=1,inplace=True)","609215fb":"data.info()","70113b39":"data.head()","66aaee69":"data['budget'] = np.log1p(data['budget'])\ntest['budget'] = np.log1p(test['budget'])","4043e209":"data.head()","caf50647":"#normalizing budget\n#a, b = 1, 100\n#m, n = data.budget.min(), data.budget.max()\n#data['budget'] = (data.budget - m) \/ (n - m) * (b - a) + a","5101680e":"y= data['revenue'].values\ncols = [col for col in data.columns if col not in ['revenue', 'id']]\nX= data[cols].values\ny = np.log1p(y)","eea8fdd4":"from sklearn.linear_model import LinearRegression\nclf = LinearRegression()\nscores = cross_val_score(clf, X, y, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores.mean())","f2b07f65":"from sklearn.ensemble import RandomForestRegressor\nregr = RandomForestRegressor(max_depth=10, min_samples_split=5, random_state=0,\n                             n_estimators=500)\nscores = cross_val_score(regr, X, y, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores.mean())","d3577be0":"cols = [col for col in test.columns if col not in ['id']]\nX_test= test[cols].values","b808518a":"regr.fit(X,y)\ny_pred = regr.predict(X_test)","d4b36704":"y_pred=np.expm1(y_pred)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission_RF.csv', index=False)","fd8364ef":"import xgboost as xgb\nimport lightgbm as lgb","209645e0":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)","42b21d47":"params = {'num_leaves': 30,\n         'min_data_in_leaf': 20,\n         'objective': 'regression',\n         'max_depth': 5,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.2,\n         \"verbosity\": -1}\n\nlgb_model = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\nlgb_model.fit(X_train, y_train, \n        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)","3d16a9a7":"data.head()","be681ac4":"lgb_model.fit(X, y, \n        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)\ny_pred=lgb_model.predict(X_test)","1194153c":"y_pred=np.expm1(y_pred)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission_LGB.csv', index=False)","7c038ef1":"xgb_params = {'eta': 0.01,\n              'objective': 'reg:linear',\n              'max_depth': 7,\n              'subsample': 0.8,\n              'colsample_bytree': 0.8,\n              'eval_metric': 'rmse',\n              'seed': 11,\n              'silent': True}\nxgb_model = xgb.XGBRegressor(**xgb_params, n_estimators = 20000, \n                             nthread = 4, n_jobs = -1)","5b19447a":"xgb_model.fit(X, y, \n        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)","6b942f15":"y_pred = xgb_model.predict(X_test)","7aaf2639":"y_pred=np.expm1(y_pred)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission_XGB.csv', index=False)","9bc540b0":"from sklearn.ensemble import GradientBoostingRegressor\n\nmodel_gboost = GradientBoostingRegressor()\n\nmodel_gboost.fit(X_train, y_train)\ny_pred = model_gboost.predict(X_test)","33fd1434":"y_pred=np.expm1(y_pred)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission_GradientBoosting.csv', index=False)","663899fc":"model 1 - linear Regression","62ec0903":"Traing with XGboost and LGB","423c7f99":"**Data Cleaning**","96308ed2":"Traning the model\n","1ddcf01d":"The data below comes from the kernel EDA, Feature Engineering, LGB+XGB+CAT of Kamal Chhirang","4f45f157":"**Let's Explore External Data**","a8d79810":"Testing the model","55096ad1":"XGB ","a7007a1b":"Model 2 - Random forest regression"}}