{"cell_type":{"01aa99d7":"code","2df99074":"code","7bde9136":"code","6e06716e":"code","78d2ca0f":"code","4ec7a0a1":"code","5bb167b2":"code","98855457":"code","26a60ef5":"code","9f1e745e":"code","3f5e74e0":"code","698ad524":"code","9b2f1015":"code","015338b3":"code","9416c68d":"code","135da1a9":"code","db0fd201":"code","e375fb3d":"code","3965b2ad":"code","ed081857":"code","00d2a408":"code","af6ea2b0":"code","b372de75":"code","7676021b":"code","a475c747":"code","c669c1c0":"code","ee4138bb":"code","1050393b":"code","536c15a9":"code","f2f3aa7b":"code","e4913cc9":"code","e89f5ee8":"code","54675dc7":"code","b9e8dc26":"code","64c6ab06":"code","daabba08":"code","e20e0eb5":"code","d1c89045":"markdown","94f855a9":"markdown","daf74422":"markdown","d895b9b4":"markdown","1619d960":"markdown","384111e1":"markdown","93da4b2c":"markdown"},"source":{"01aa99d7":"import pandas as pd\nimport numpy as np\n# insert train_split data as Pandas Dataframe Object and remove the df* variable\n\ntrain_df = pd.read_csv('..\/input\/train_split.csv')\ntrain_df.head()","2df99074":"train_df.shape","7bde9136":"from sklearn import preprocessing\nimport numpy as np\n\ndef prep_data(WORKING_DF):\n    encoded = pd.DataFrame()\n    \n    WORKING_DF.drop(columns=['batch_enrolled', 'desc', 'zip_code'], axis=1)\n    # Mapping and encoding emp_length values\n    scale_mapper = {np.nan:0, '< 1 year':1, '1 year':2, '2 years':3, '3 years':4, '4 years':5, '5 years':6, '6 years':7, '7 years':8, '8 years':9, '9 years':10, '10+ years':11}\n    encoded['emp_length_encoded'] = WORKING_DF['emp_length'].replace(scale_mapper)\n\n    # Encoding remaining ordinal variables\n    grouped = WORKING_DF[['delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'pub_rec', 'total_acc', 'open_acc', 'collections_12_mths_ex_med', 'acc_now_delinq', 'last_week_pay']]\n    grouped = grouped.apply(preprocessing.LabelEncoder().fit_transform)\n    encoded = pd.concat([encoded, grouped], axis=1)\n\n\n    # One-hot encode nominal variables\n    grouped = WORKING_DF[['term', 'grade', 'sub_grade', 'home_ownership', 'verification_status', 'pymnt_plan', 'purpose', 'addr_state', 'initial_list_status', 'application_type', 'verification_status_joint', 'member_id']]\n    grouped = pd.get_dummies(grouped)\n    encoded = pd.concat([encoded, grouped], axis=1)\n\n    # Append float columns to encoded df\n    grouped = WORKING_DF[['annual_inc', 'dti', 'revol_bal', 'revol_util', 'total_acc', 'total_rec_int', 'total_rec_late_fee', 'recoveries',\n                          'collection_recovery_fee', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim', 'open_acc', 'mths_since_last_major_derog']]\n\n    # Fill NaN values with mean of each column\n    fill_NaN = preprocessing.Imputer(missing_values=np.nan, strategy='mean', axis=0)\n    imputed_df = pd.DataFrame(fill_NaN.fit_transform(grouped))\n    imputed_df.columns = grouped.columns\n    imputed_df.index = grouped.index\n\n    encoded = pd.concat([encoded, imputed_df], axis=1)\n    return encoded","6e06716e":"encoded = prep_data(train_df)\nencoded_test_df = prep_data(train_df)\nencoded = encoded.drop(columns=['home_ownership_ANY'], axis=1)","78d2ca0f":"encoded_test_df.head()","4ec7a0a1":"from sklearn.model_selection import train_test_split\n\nX = encoded\ny = train_df['loan_status']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","5bb167b2":"from sklearn.linear_model import LinearRegression\n\nlr_clf = LinearRegression()\nlr_clf.fit(X_train, y_train)","98855457":"lr_clf.predict([X_test.iloc[1,:]])","26a60ef5":"lr_clf.predict(X_test)","9f1e745e":"lr_clf.score(X_test, y_test)","3f5e74e0":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(n_estimators=1500, max_depth=200, random_state=0)\nrf_clf.fit(X_train, y_train) ","698ad524":"rf_clf.score(X_test, y_test)","9b2f1015":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\npipeline = make_pipeline(StandardScaler(),RandomForestClassifier(n_estimators=1000, max_depth=2, random_state=0) )","015338b3":"model = pipeline.fit(X_train, y_train)","9416c68d":"predicted = model.predict(X_test)","135da1a9":"print(predicted)","db0fd201":"from sklearn import svm, metrics\nmetrics.classification_report(y_test, predicted)","e375fb3d":"! pip install watson_machine_learning_client","3965b2ad":"from watson_machine_learning_client import WatsonMachineLearningAPIClient","ed081857":"#get wml credentials from your service credentials tab under your ML Service\nwml_credentials={\n  \n  \"username\": \"55826a0d-f7c7-4980-a509-5c291ba63134\",\n  \"password\": \"bdff31f5-063f-44ae-b38d-743fdd8c14b7\",\n  \"instance_id\": \"5e8dd26f-9800-4ffe-a971-46c6225530e1\",\n  \"url\": \"https:\/\/eu-gb.ml.cloud.ibm.com\"\n}","00d2a408":"#get wml credentials from your service credentials tab under your ML Service\n# wml_credentials={\n  \n#   \"username\": \"******\",\n#   \"password\": \"******\",\n#   \"instance_id\": \"******\",\n#   \"url\": \"******\"\n# }","af6ea2b0":"client = WatsonMachineLearningAPIClient(wml_credentials)","b372de75":"import json\n\ninstance_details = client.service_instance.get_details()\nprint(json.dumps(instance_details, indent=2))","7676021b":"model_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"Shadab\", \n               client.repository.ModelMetaNames.AUTHOR_EMAIL: \"shadab.cs0058@gmail.com\",\n               client.repository.ModelMetaNames.NAME: \"Loan eligibility model created on notebook\"}","a475c747":"published_model = client.repository.store_model(model=model, meta_props=model_props, \\\n                                                training_data=X_train, training_target=y_train)","c669c1c0":"published_model_uid = client.repository.get_model_uid(published_model)\nmodel_details = client.repository.get_details(published_model_uid)\n\nprint(json.dumps(model_details, indent=2))","ee4138bb":"models_details = client.repository.list_models()","1050393b":"loaded_model = client.repository.load(published_model_uid)\nprint(loaded_model)","536c15a9":"test_predictions = loaded_model.predict(X_test[:10])","f2f3aa7b":"print(test_predictions)","e4913cc9":"created_deployment = client.deployments.create(published_model_uid, \"Deployment of locally created scikit model\")","e89f5ee8":"scoring_endpoint = client.deployments.get_scoring_url(created_deployment)\n\nprint(scoring_endpoint)","54675dc7":"\n\ndeployments = client.deployments.get_details()\n\nprint(json.dumps(deployments, indent=2))\n\n","b9e8dc26":"deployment_url = client.deployments.get_url(created_deployment)\n\nprint(deployment_url)","64c6ab06":"scoring_payload = {\"values\": [list(X_test.iloc[1,:])]}","daabba08":"predictions = client.deployments.score(scoring_endpoint, scoring_payload)","e20e0eb5":"print(json.dumps(predictions, indent=2))","d1c89045":"## 3.Split data into test and train datasets","94f855a9":"## 7.Deploying as a webservice","daf74422":"## 6.Publishing the model to Watson ML","d895b9b4":"## 4.Create your first ML Model","1619d960":"## 5.Creating a ML Pipeline","384111e1":"## 2.Take the necessary pre processing steps","93da4b2c":"## 1.Import data train_split as a pandas dataframe "}}