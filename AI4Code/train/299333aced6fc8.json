{"cell_type":{"a0f12a3c":"code","9d2bf59a":"code","a97af072":"code","889da48d":"code","079d4ad8":"code","05778a81":"code","54a957b8":"code","ec2a529d":"code","68bf370e":"code","ee4bf36a":"code","6716f500":"code","189e1d97":"markdown"},"source":{"a0f12a3c":"import os\nimport sys\nsys.path.append('..\/input\/pytorch-images-seresnet')\nimport math\nimport time\nimport random\nimport numpy as np \nimport cv2\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport albumentations\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensorV2\nimport timm\nfrom torch.cuda.amp import autocast, GradScaler\nimport glob as glob\nimport pandas as pd\nfrom contextlib import contextmanager","9d2bf59a":"class CFG:\n    device='GPU'\n    nprocs=1\n    print_freq=100\n    num_workers=4\n    model_name='resnet200d'\n    teacher='..\/input\/resnet200d-public\/resnet200d_320_CV9632.pth'\n    startpoint = '..\/input\/resnet200d-pretrained-weight\/resnet200d_ra2-bdba9bf9.pth'\n    size=512\n    scheduler='CosineAnnealingLR'\n    epochs=1\n    T_max=1\n    lr=5e-4 \n    min_lr=1e-6\n    batch_size=16 \n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=416\n    target_size=11\n    n_fold=5\n    trn_fold=[0]\n    train=True\n    ","a97af072":"train_files = glob.glob('..\/input\/data\/*\/*\/*.png')\ndata={'image_path':train_files}\nfolds = pd.DataFrame(data,columns=['image_path'])\nfolds","889da48d":"@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file='train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","079d4ad8":"class TrainDataset(Dataset):\n    def __init__(self, df, use_annot=False, annot_size=50, transform=None):\n        self.df = df\n        self.file_names = df['image_path'].values\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = file_name\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","05778a81":"def get_transforms(*, data):\n    \n    if data == 'train':\n            return Compose([\n            Resize(CFG.size, CFG.size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","54a957b8":"class CustomResNet200D(nn.Module):\n    def __init__(self, model_name='resnet200d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return features","ec2a529d":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(train_loader, teacher_model, model, criterion, optimizer, epoch, scheduler, device):\n    scaler = GradScaler()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images) in enumerate(train_loader):\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        with torch.no_grad():\n            teacher_features = teacher_model(images)\n        \n        batch_size = images.size(0)\n        with autocast():\n            features = model(images)\n            loss = criterion(teacher_features, features)\n\n            losses.update(loss.item(), batch_size)\n            if CFG.gradient_accumulation_steps > 1:\n                loss = loss \/ CFG.gradient_accumulation_steps\n            scaler.scale(loss).backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                global_step += 1\n\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}\/{2}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  .format(\n                   epoch+1, step, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)\/len(train_loader)),\n                   grad_norm=grad_norm,\n                   ))\n    return losses.avg","68bf370e":"def train_loop(folds, fold):\n    \n    train_folds = folds.reset_index(drop=True)\n\n\n    train_dataset = TrainDataset(train_folds, use_annot=True,\n                                 transform=get_transforms(data='train'))\n    \n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n    teacher_model = CustomResNet200D(CFG.model_name, pretrained=False)\n    teacher_model.load_state_dict(torch.load(CFG.teacher)['model'])\n    for param in teacher_model.parameters():\n        param.requires_grad = False\n    teacher_model.eval()\n    teacher_model.to(device)\n    \n    model = CustomResNet200D(CFG.model_name, pretrained=True)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n\n    train_criterion = nn.MSELoss()\n\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        start_time = time.time()\n\n        avg_loss = train_fn(train_loader, teacher_model, model, train_criterion, optimizer, epoch, scheduler, device)\n\n        scheduler.step()\n\n\n        elapsed = time.time() - start_time\n\n        if CFG.device == 'GPU':\n            LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}   time: {elapsed:.0f}s')\n        \n           \n        if avg_loss < best_loss:\n            best_loss = avg_loss      \n            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict()},\n                       f'{CFG.model_name}_fold{fold}_best_loss.pth')","ee4bf36a":"def main():\n    if CFG.train:\n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                train_loop(folds, fold)","6716f500":"# if __name__ == '__main__':\n#     main()","189e1d97":"Credit: https:\/\/www.kaggle.com\/yasufuminakama\/ranzcr-resnet200d-3-stage-training-step2 \n"}}