{"cell_type":{"ac3ef87f":"code","46603677":"code","5019b7b7":"code","f9ab80c5":"code","1ed7aafd":"code","662c6cb9":"code","d7d014e9":"code","9c72e821":"code","f0b9ffb8":"code","47fe814c":"code","55179151":"code","f927d2aa":"code","c6e48f9e":"code","1f8ec449":"code","3ae488c7":"code","2c39df62":"code","bbfb716f":"code","651ab260":"code","5085ffaf":"code","db73b91a":"code","293d0946":"code","6427905d":"code","dd9b18ae":"code","8229809a":"code","7649cc28":"code","820ec7af":"code","7d260dd4":"code","a8a0d3cb":"code","c4788704":"code","337cbb77":"code","687a997c":"code","7b7adaae":"code","d7acf23d":"code","77a51087":"code","df070f92":"code","7c7e8868":"code","051489e2":"code","2bc71125":"code","dee0d346":"code","7db8fd1e":"code","127ccecf":"code","b03bfc21":"code","5bbe02a1":"code","f587d4b8":"code","97a3d07f":"code","16a77399":"code","80915ac1":"code","517c65b7":"code","5ba4c6d0":"code","26503f3d":"code","1197c3a1":"code","a9c8eb7b":"code","e0bb2914":"code","2ccc147c":"code","1abc0188":"code","c1c10e43":"code","2fd9da76":"code","73c95320":"code","bb95f114":"code","229c1191":"code","64764fa0":"code","08522d8c":"code","514e457b":"code","be02147d":"code","c153986a":"code","36465a98":"code","389627c6":"code","4e477d16":"code","a663db29":"code","b67c88f9":"code","845f7fc7":"code","3eebe2a1":"code","8007621d":"code","abb0271f":"code","98d53bfb":"code","faaf2b77":"markdown","c86dd189":"markdown","2aa5a3ed":"markdown","ff77af15":"markdown","2a757905":"markdown","b9451a0a":"markdown","6fad61c3":"markdown","3e9f8673":"markdown","3e919754":"markdown","cfae672f":"markdown","ad763a82":"markdown","fb14c25c":"markdown","26946c00":"markdown","b51d73e4":"markdown","6c7f4b8a":"markdown","42e029c0":"markdown","c0278b31":"markdown","777626ca":"markdown","a3b3c887":"markdown","759cb6c7":"markdown","e825346c":"markdown","b4f6a964":"markdown","b71245b3":"markdown","beb18733":"markdown","3fc0bed5":"markdown","b5094a53":"markdown","eb21cb37":"markdown","fea827ed":"markdown","83b7115a":"markdown","e8a46fd1":"markdown","4aa985b6":"markdown","b0bf5bc9":"markdown","7de0d7bd":"markdown","9daa48e6":"markdown","73aa6e99":"markdown","167b34f0":"markdown","62f59c9e":"markdown","9c156c6c":"markdown"},"source":{"ac3ef87f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46603677":"# Import necessary library\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\nsns.set()","5019b7b7":"# Load three availabl dataframe\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest  = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","f9ab80c5":"# Quick overview of train data\ntrain.info()","1ed7aafd":"train.describe()","662c6cb9":"# Visualize missing values on train data\nmsno.matrix(train, figsize=(15, 5))","d7d014e9":"# New dataframe to store columns of train\/test data with numerical values\ntrain_num = pd.DataFrame()\ntest_num = pd.DataFrame()","9c72e821":"print('All columns name in train:\\n', train.columns.values)","f0b9ffb8":"# Check the correlation between passengerID and survived\ntrain[['PassengerId', 'Survived']].corr()","47fe814c":"# Check number of people survived\n_ = plt.figure(figsize=(16, 2))\nsns.countplot(y='Survived', data=train)\ntrain.Survived.value_counts()","55179151":"# Include target column into train_num\ntrain_num['Survived'] = train['Survived']","f927d2aa":"# Check how many kinds of ticket\n_ = plt.figure(figsize=(5, 3))\nsns.countplot(x='Pclass', data=train)\ntrain.Pclass.value_counts()","c6e48f9e":"# Showing distribution of Pclass over survival rate might be interesting\nfig, ax = plt.subplots()\nsns.kdeplot(x='Pclass', shade=True, data=train, hue='Survived', ax=ax)\nax.legend(labels=['Not Survived', 'Survived'], loc=2)","1f8ec449":"train['Pclass'].isna().sum()","3ae488c7":"train_num['Pclass'] = train['Pclass']","2c39df62":"train['Name']","bbfb716f":"_ = plt.figure(figsize=(15, 3))\nsns.countplot(y='Sex', data=train)","651ab260":"sns.histplot(x = 'Sex', data=train, multiple=\"dodge\", shrink=.8, hue='Survived')","5085ffaf":"# Check null values\ntrain['Sex'].isna().sum()","db73b91a":"# Insert sex into train_num\ntrain_num['Sex'] = train['Sex']","293d0946":"fig, ax = plt.subplots()\nsns.kdeplot(x='SibSp', shade=True, data=train, hue='Survived', ax=ax)\n# sns.histplot(x='SibSp', data=train, hue='Survived', ax=ax)","6427905d":"# Check null values \ntrain['SibSp'].isna().sum()","dd9b18ae":"# Since no null values we can directly include them into train_num\ntrain_num['SibSp'] = train['SibSp']","8229809a":"sns.kdeplot(x='Parch', data=train, shade=True, hue='Survived')","7649cc28":"# Check for null values\ntrain['Parch'].isna().sum()","820ec7af":"# Add to train_num\ntrain_num['Parch'] = train['Parch']","7d260dd4":"# Let's see how many kinds of tickets are there\nprint(train['Ticket'].value_counts())\n\nnum_tickets = len(train['Ticket'].unique()) \nprint(f'There are {num_tickets} kinds of tickets')","a8a0d3cb":"# Check for null values\ntrain['Ticket'].isna().sum()","c4788704":"# Ignore this column for now, revisit later","337cbb77":"# Check how many kinds of ticket price\ntrain['Fare'].value_counts()","687a997c":"# Let's see if ticket price relates to survival rate\nsns.kdeplot(x='Fare', shade=True, hue='Survived', data=train)","7b7adaae":"# Check for null values\ntrain['Fare'].isna().sum()","d7acf23d":"bin_fare = pd.cut(train['Fare'], bins=5)\nbin_fare","77a51087":"train_num['Fare'] = bin_fare","df070f92":"train_num","7c7e8868":"# Check kinds of cabin\ntrain['Cabin'].value_counts()","051489e2":"# Check null values\ntrain['Cabin'].isna().sum()","2bc71125":"train['Embarked'].value_counts()","dee0d346":"sns.countplot(x='Embarked', data=train, hue='Survived')","7db8fd1e":"# Check null values\ntrain['Embarked'].isna().sum()","127ccecf":"# Adding and dropping null values\ntrain_num['Embarked'] = train['Embarked']\ntrain_num.dropna(axis=0, how='any', subset=['Embarked'], inplace=True)","b03bfc21":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder","5bbe02a1":"train_num.head()","f587d4b8":"# Perform one-hot encode on categorical variables, Pclass, Sex, Fare, and Embarked\ndf_pclass_enc = pd.get_dummies(train_num['Pclass'], prefix='pclass')\n# display(df_pclass_enc.head())\n\ndf_sex_enc = pd.get_dummies(train_num['Sex'], prefix='sex')\n# display(df_sex_enc.head())\n\ndf_fare_enc = pd.get_dummies(train_num['Fare'], prefix='fare')\n# display(df_fare_enc.head())\n\ndf_embarked_enc = pd.get_dummies(train_num['Embarked'], prefix='embarked')\n# display(df_embarked_enc.head())","97a3d07f":"# Combine encoded variable to train_num\ntrain_enc = pd.concat([train_num, df_pclass_enc, df_sex_enc, df_fare_enc, df_embarked_enc], axis=1)\ntrain_enc.head()","16a77399":"# Drop the original column\ntrain_enc = train_enc.drop(columns=['Pclass', 'Sex', 'Fare', 'Embarked'])\ntrain_enc.head()","80915ac1":"X_train = train_enc.drop(['Survived'], axis=1)\ny_train = train_enc['Survived']\n\n# Making sure they have same length\nassert X_train.shape[0] == y_train.shape[0]","517c65b7":"from sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score","5ba4c6d0":"# Declare number of fold for cv\ncv_num = 10\n\n\ndef eval_model(model, X_train, y_train, cv=cv_num):\n    # Train accuracy\n    model.fit(X_train, y_train)\n    train_acc = round(model.score(X_train, y_train) * 100, 2)\n    \n    # CV score\n    cv_acc = cross_val_score(model, X_train, y_train, cv=cv)\n    cv_acc = round(cv_acc.mean() * 100, 2)\n    \n    return train_acc, cv_acc","26503f3d":"# Array to store each algorithm's train and cv scores\ntr_score = []\ncv_score = []\nalgo = []","1197c3a1":"lda = LDA()\n\ntrain_acc, cv_acc = eval_model(lda, X_train, y_train, cv=cv_num)\nprint(f'Train accuracy: ', train_acc)\nprint(f'{cv_num}-fold CV accuracy: ', cv_acc)\n\n# Storing results\ntr_score.append(train_acc)\ncv_score.append(cv_acc)\nalgo.append(\"LDA\")","a9c8eb7b":"logreg = LogisticRegression()\n\ntrain_acc, cv_acc = eval_model(logreg, X_train, y_train, cv=cv_num)\nprint(f'Train accuracy: ', train_acc)\nprint(f'{cv_num}-fold CV accuracy: ', cv_acc)\n\n# Storing results\ntr_score.append(train_acc)\ncv_score.append(cv_acc)\nalgo.append(\"Logistic Regression\")","e0bb2914":"knn = KNeighborsClassifier()\n\ntrain_acc, cs_acc = eval_model(knn, X_train, y_train, cv=cv_num)\nprint(f'Train accuracy: ', train_acc)\nprint(f'{cv_num}-fold CV accuracy: ', cv_acc)\n\n\n# Storing results\ntr_score.append(train_acc)\ncv_score.append(cv_acc)\nalgo.append(\"KNN\")","2ccc147c":"sgd = SGDClassifier()\n\n\ntrain_acc, cs_acc = eval_model(sgd, X_train, y_train, cv=cv_num)\nprint(f'Train accuracy: ', train_acc)\nprint(f'{cv_num}-fold CV accuracy: ', cv_acc)\n\n\n# Storing results\ntr_score.append(train_acc)\ncv_score.append(cv_acc)\nalgo.append(\"SGDClassifier\")","1abc0188":"gauss = GaussianNB()\n\ntrain_acc, cs_acc = eval_model(gauss, X_train, y_train, cv=cv_num)\nprint(f'Train accuracy: ', train_acc)\nprint(f'{cv_num}-fold CV accuracy: ', cv_acc)\n\n\n# Storing results\ntr_score.append(train_acc)\ncv_score.append(cv_acc)\nalgo.append(\"Gaussian Naive Bayes\")","c1c10e43":"tree = DecisionTreeClassifier()\n\ntrain_acc, cs_acc = eval_model(tree, X_train, y_train, cv=cv_num)\nprint(f'Train accuracy: ', train_acc)\nprint(f'{cv_num}-fold CV accuracy: ', cv_acc)\n\n\n# Storing results\ntr_score.append(train_acc)\ncv_score.append(cv_acc)\nalgo.append(\"Decision Tree\")","2fd9da76":"gboost = GradientBoostingClassifier()\n\ntrain_acc, cs_acc = eval_model(gboost, X_train, y_train, cv=cv_num)\nprint(f'Train accuracy: ', train_acc)\nprint(f'{cv_num}-fold CV accuracy: ', cv_acc)\n\n# Storing results\ntr_score.append(train_acc)\ncv_score.append(cv_acc)\nalgo.append(\"Gradient Boosting Classifier\")","73c95320":"all_scores = pd.DataFrame({\n    \"Model\": algo,\n    \"Train score\": tr_score,\n    \"CV score\": cv_score\n})","bb95f114":"all_scores.sort_values(by=[\"CV score\"], ascending=False)","229c1191":"# Prepare for modified version of test\ntest_enc = pd.DataFrame()\n\ntest.head()","64764fa0":"# First remove check for null values\ntest.isna().sum()","08522d8c":"# Column in train_enc\ntrain_enc.columns","514e457b":"# Copy test into test_enc\ntest_enc = test\nprint(test_enc.shape)\n\n# Drop Age, Cabin\ntest_enc = test_enc.drop(labels = [\"Age\", \"Cabin\"], axis=1)\nprint(test_enc.shape)","be02147d":"# Fill missing data in Fare with average\ntest_enc['Fare'] = test_enc['Fare'].fillna(test_enc['Fare'].mean())","c153986a":"# Save passengerId\npassengerId = test_enc['PassengerId']\npassengerId","36465a98":"# Binning fare columns to similar number of bins in train_enc \nn_bin = []\n\nn_bin = [1 for i in train_enc.columns if 'fare' in i]\nn_bin = len(n_bin)\n\ntest_enc['Fare'] = pd.cut(test_enc['Fare'], bins=n_bin)","389627c6":"# Perform one-hot encode on categorical variables, Pclass, Sex, Fare, and Embarked\ndf_pclass_enc = pd.get_dummies(test_enc['Pclass'], prefix='pclass')\n\ndf_sex_enc = pd.get_dummies(test_enc['Sex'], prefix='sex')\n\ndf_fare_enc = pd.get_dummies(test_enc['Fare'], prefix='fare')\n\ndf_embarked_enc = pd.get_dummies(test_enc['Embarked'], prefix='embarked')","4e477d16":"# Substitute corresponding columns with one-hot encoded version\ntest_enc = pd.concat([test_enc, df_pclass_enc, df_sex_enc, df_fare_enc, df_embarked_enc], axis=1)","a663db29":"# Only grab columns that are in the X_train before\ntest_enc = test_enc[X_train.columns]","b67c88f9":"# Check that test_enc and train_enc (without Survived) has same columns\nwrong = False\nfor col in test_enc.columns:\n    if not col in train_enc.drop(['Survived'], axis=1).columns:\n        print(f\"Column {col} shouldn't be in test data\")\n        wrong = True\n        \nif not wrong:\n    print(\"All match!\")","845f7fc7":"all_scores","3eebe2a1":"# Predict test_enc\npredict = lda.predict(test_enc)\npredict[:20]","8007621d":"test_enc","abb0271f":"# Create file for submission\nsubmission = pd.DataFrame()\n\nsubmission['PassengerId'] = passengerId\nsubmission['Survived'] = predict\n\nprint(submission.shape)\nsubmission.head()","98d53bfb":"# Output to csv\nsubmission.to_csv(\"20210625-submission.csv\", index=False)","faaf2b77":"# Implementing different ML algorithms","c86dd189":"The histogram above implies that male are more likely to survived than female, but note that even originally there are more male than femal in the ship. But this variable clearly relates to survival rate, thus we can insert it into `train_num`","2aa5a3ed":"## Embarked\nDescription: point of departure for passenger  \nC = Cherbourg, Q = Queenstown, S=Southampton","ff77af15":"## K Nearest Neighbors","2a757905":"## Clean test data","b9451a0a":"## Name\nDescription: contains name of each passanger","6fad61c3":"## GaussianNB","3e9f8673":"## Survived\n0 = No, 1 = Yes  \nDescription: the label and is required to train classifier, copy this colum to `train_num`","3e919754":"## LDA","cfae672f":"## SGDClassifier","ad763a82":"## Ticket\nDescription: ticket number of each passenger","fb14c25c":"## Logistic Regression","26946c00":"## Fare\nDescription: how much ticket cost","b51d73e4":"## Sex\nDescription: contains the gender\/sex of each passanger","6c7f4b8a":"## PassengerId\nIntuitively there should be no correlation between the passenger id and the survived, we can skip this column","42e029c0":"## Run highest score CV-score model to `test_enc`","c0278b31":"It turns out that the lower one ticket price, the less likely one will survive. Let's include this into `train_num`","777626ca":"## Gradient Boosting Classifier","a3b3c887":"## Creating train and test set","759cb6c7":"Most passenger depart from Southampton, and most of those passengers are less likely to survive. Let's include this variable to `train_num`","e825346c":"# Submission\nWe will use the classifier with highest cv score on test data. \nTest data need to contain the same columns as train data.","b4f6a964":"## SibSp\nDescription: number of siblings or spouse a passenger has on board","b71245b3":"## Parch\nDescription: number of parents\/children the passenger has, this feature is similar to SibSp","beb18733":"## Cabin\nDescription: The cabin number where passenger stayed","3fc0bed5":"Since there are 2 missing values in `Embarked`, we can add it to `train_num` and drop the corresponding rows for now.","b5094a53":"## Function to train and cross validation accuracy","eb21cb37":"# EDA\nPerform EDA on train data, will inspect each column in the train data ","fea827ed":"Since fare is originally a continuous numerical variable, let's group them into several range","83b7115a":"# Build Machine Learning Model","e8a46fd1":"# Feature Encoding\nHere we will any categorical\/ordinal variables and transform it into numerical variables","4aa985b6":"## Summary","b0bf5bc9":"## Binning `fare` & one-hot encode `pclass` and `embarked`","7de0d7bd":"for now, this column will be ignored","9daa48e6":"## Pclass\nDescription: defines the ticket class","73aa6e99":"From the result above we can see that ticket class correlates with survival rate, those in class 3 are more likely not survived, while those in class 1 are more likely to survived, add this data to `train_num`, moreover there isn't null data in `Pclass`, so we can move it directly.","167b34f0":"Since there are too many cabin values, and too many missing values, we'll skip this variable for now","62f59c9e":"From the kde plot above, especially when `SibSp` values are greater than 2, we can see more of them are not likely to survived, this means, the more siblings or spouses you ahve on board, the less likely the passenger will survive. This says that `SibSp` correlates with survival rate, thus we can include this variable to `train_num`","9c156c6c":"## Decision Tree"}}