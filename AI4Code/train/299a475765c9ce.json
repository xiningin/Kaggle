{"cell_type":{"1768c034":"code","89f214f4":"code","fcc4284a":"code","1237827e":"code","bbc3d319":"code","2cd2dbcb":"code","1414bceb":"code","dc59a5f7":"code","386c0e50":"code","e9468138":"code","399c2e9e":"code","15b91994":"code","5f7b2a18":"code","9122d43b":"code","058ee4a3":"code","52a6c1ac":"code","c6544663":"code","45da6750":"code","3f244a01":"code","f121e651":"code","4eaed5e4":"code","6295dfba":"code","1865dcc8":"code","18310997":"code","8f8ddaa0":"code","f5118c95":"code","61c45ee0":"code","1362486e":"code","80d6195b":"code","47ac931b":"code","b769259b":"code","6c66629d":"code","34f8922c":"code","343a0ced":"code","89ec3100":"code","869e8ecb":"code","a31581f8":"code","aac2c6c3":"code","621ac501":"code","6a5e33b8":"code","32607912":"code","01aa6cb4":"code","265ef953":"code","1a18753d":"markdown","1e8d9d02":"markdown","1175ba9c":"markdown","a8740afa":"markdown","e0438efa":"markdown","2b624ead":"markdown","11a5e3a8":"markdown","65b6d75e":"markdown","52f2adc4":"markdown","69b7ecba":"markdown","5a92b56a":"markdown","19348300":"markdown","1c2561a4":"markdown","ab0143a3":"markdown","a82647b9":"markdown","6f69e481":"markdown","bd9bdd7e":"markdown","86f580ea":"markdown","93693ef9":"markdown","c2cf3bb8":"markdown","82160e57":"markdown","1499812e":"markdown","6b8f832d":"markdown"},"source":{"1768c034":"import pandas as pd\nimport numpy as np","89f214f4":"dftr = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndfte = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")","fcc4284a":"#first 5 rows\ndftr.head()","1237827e":"#info about dataset\ndftr.info()","bbc3d319":"#filling with '0' on N\/A\ndftr=dftr.fillna(0)","2cd2dbcb":"#filling with '0' on N\/A\ndfte=dfte.fillna(0)","1414bceb":"dftr.info()","dc59a5f7":"pip install pycaret==2.0","386c0e50":"from pycaret.regression import *","e9468138":"#setting up PyCaret\nreg1 = setup(dftr, target='SalePrice', train_size=0.8, session_id=117, log_experiment=True, \n             transformation=True, pca=True, pca_method='linear',pca_components=0.8,\n             experiment_name='hpareg1')","399c2e9e":"#lets see how this evolve\nbest_model = compare_models(fold=4)\n","15b91994":"#with a little differnt strategy this time\nreg2 = setup(dftr, target='SalePrice', train_size=0.8, session_id=118, log_experiment=True, \n             transformation=True, pca=True, pca_method='linear',pca_components=0.9, transform_target=True,\n             polynomial_features=True, polynomial_degree=3, trigonometry_features=True,\n             remove_multicollinearity=True, multicollinearity_threshold=0.93, experiment_name='hpareg2')","5f7b2a18":"best_model1 = compare_models(fold=4)","9122d43b":"df1 = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf1.drop(['MiscFeature', 'Fence', 'PoolQC', 'Alley'], axis=1, inplace=True)","058ee4a3":"df_corr = df1.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\ndf_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\ndf_corr[df_corr['Feature 1'] == 'LotFrontage']","52a6c1ac":"df1['LotFrontage'] = df1.groupby(['1stFlrSF', 'LotArea'])['LotFrontage'].apply(lambda x: x.fillna(x.median()))","c6544663":"df_corr[df_corr['Feature 1'] == 'GarageYrBlt']","45da6750":"df1['GarageYrBlt'] = df1.groupby(['YearBuilt', 'YearRemodAdd'])['GarageYrBlt'].apply(lambda x: x.fillna(x.median()))","3f244a01":"FireplaceQu_mean = df1.groupby(['FireplaceQu','LotShape', 'LandContour','Neighborhood'])['SalePrice'].mean()\nFireplaceQu_mean","f121e651":"mis_cat = ['GarageQual', 'GarageCond', 'GarageFinish','GarageYrBlt', 'GarageType', 'BsmtFinType2', 'MasVnrType', \n       'BsmtExposure']","4eaed5e4":"from sklearn_pandas import CategoricalImputer\nimputer = CategoricalImputer()\n","6295dfba":"df1['GarageQual'] = imputer.fit_transform(df1['GarageQual'])","1865dcc8":"df1['GarageCond'] = imputer.fit_transform(df1['GarageCond'])\ndf1['GarageFinish'] = imputer.fit_transform(df1['GarageFinish'])\ndf1['GarageYrBlt'] = imputer.fit_transform(df1['GarageYrBlt'])\ndf1['GarageType'] = imputer.fit_transform(df1['GarageType'])\ndf1['BsmtFinType2'] = imputer.fit_transform(df1['BsmtFinType2'])\ndf1['MasVnrType'] = imputer.fit_transform(df1['MasVnrType'])\ndf1['BsmtExposure'] = imputer.fit_transform(df1['BsmtExposure'])\n","18310997":"reg3 = setup(df1, target='SalePrice', train_size=0.8, session_id=119, log_experiment=True, \n             transformation=True, pca=True, pca_method='linear',pca_components=0.87, transform_target=True,\n             polynomial_features=True, polynomial_degree=4, trigonometry_features=True,\n             remove_multicollinearity=True, multicollinearity_threshold=0.93, experiment_name='hpareg3')","8f8ddaa0":"best_model2 = compare_models(fold=4)","f5118c95":"svm = create_model('svm', fold=4)","61c45ee0":"catboost = create_model('catboost', fold=4)","1362486e":"gbr = create_model('gbr', fold=4)","80d6195b":"tuned_svm = tune_model(svm, n_iter=5, optimize = 'R2')","47ac931b":"blender = blend_models(estimator_list = [svm, catboost, gbr], fold=4)","b769259b":"stacked_svm = stack_models(estimator_list = [svm, catboost, gbr],\n                           meta_model=svm)","6c66629d":"plot_model(svm)","34f8922c":"plot_model(tuned_svm)","343a0ced":"plot_model(blender)","89ec3100":"plot_model(svm, plot = 'error')","869e8ecb":"plot_model(svm, plot = 'residuals')","a31581f8":"plot_model(blender, plot = 'error')","aac2c6c3":"plot_model(gbr, plot = 'feature')","621ac501":"plot_model(svm, plot = 'learning')","6a5e33b8":"plot_model(svm, plot = 'manifold')","32607912":"interpret_model(gbr)","01aa6cb4":"interpret_model(gbr, plot = 'correlation' , feature = 'Component_1')","265ef953":"interpret_model(gbr, plot='reason')","1a18753d":"A Learning curve of Training and cross validations","1e8d9d02":"## Thankyou for having a look, Hope this helps. You can contact me here or at LinkedIn for any query : [LinkedIn](http:\/\/https:\/\/www.linkedin.com\/in\/muhammad-saad-31740060\/)","1175ba9c":"#### Tuned SVM performed very poorly, lets try blending and stacking","a8740afa":"* ## For Further Analysis, based on below output we can impute categorical features as well using the power of stats which can further improve our model","e0438efa":"## <span style=\"color:blue\">If you like my work and able to grasp some knowledge, pls upvote<\/span>","2b624ead":"* ## Now lets create some polynomial features and remove some multi-collinearity and check for improvements in R2","11a5e3a8":"* ## Comparing a variety of regression models, i am measureing score based on R2","65b6d75e":"**Feel free to play with the reason plot & do share if you like my work**","52f2adc4":"## <span style=\"color:green\">Here i have used the newly released PyCaret 2.0 to present how a low code machine learning library can reduce our insights cycle time and improve model efficiency in  no time. Having a strong understanding of data science and ML can covert this tool to a super power for ML practioneer as it open infinite new possibilites to test and choose from given a firm concepts of models and their underlying concepts<\/span>","69b7ecba":"* # Visuals (interpreting and story telling is one of the core KPI's of any DS or ML practioneer). I'll leave it to you all for interpreting ;)","5a92b56a":"* ## You can see with some transformation and tuning we have now a different model with better R2","19348300":"#  <span style=\"color:green\"> Advance Regression Techniques Via AutoML (PyCaret 2.0) <\/span>","1c2561a4":"* ## Creating models","ab0143a3":"* ## filling N\/A of Features based on most correlated features median","a82647b9":"* ## Now Lets use some power of stats and fill N\/A with it","6f69e481":"## A javascript plot to interpret all the features","bd9bdd7e":"* ### Basic Approach, Fill all NA\/missing data with Zero","86f580ea":"Resolved some errors occured in last run","93693ef9":"* ### Setting up AutoML with Transformation and PCA with 0.8. See how a single line of code has taken most of the hectic work","c2cf3bb8":"#### See how creating new features has worked on their interpretation ","82160e57":"### So we have 87 features, which is quite good for a good solution","1499812e":"### Version 7: Added Some new features of SHAP Library ","6b8f832d":"### <span style=\"color:green\">Lets Begin, i am going to compare 3 different setups while doing some wranging and feature engineering and will compare there outputs and visualize the the best one "}}