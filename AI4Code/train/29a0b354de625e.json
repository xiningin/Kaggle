{"cell_type":{"1fa69077":"code","99b3c9f4":"code","e71db9fa":"code","9b6e239c":"code","0d2a7273":"code","853ebd62":"code","f98fe378":"code","eca36562":"code","8896836a":"code","29148123":"code","a1297b9d":"code","d044bb27":"code","3a20a05b":"code","c3aeff7d":"code","3ff70ee3":"code","25577837":"code","fcd434ae":"code","bca15c94":"code","0dbba493":"code","950c5bd6":"code","eee140fc":"code","8fbea82d":"code","77851169":"code","2d9fb1db":"code","61ccc471":"code","8d589513":"code","715fa00f":"code","c8afacbe":"code","8a1ad727":"code","7cf01a5c":"code","e28591cf":"code","39da5ced":"code","973998e9":"code","0ec6ee50":"code","6b2d0f03":"code","8dad0de3":"code","93455b0e":"code","cefc2022":"code","edcc7f3c":"markdown","54beddb0":"markdown","9691809c":"markdown","dbac393f":"markdown","68768b8d":"markdown","cceb7299":"markdown","cf4ccae4":"markdown","f5099a0e":"markdown","656cf28d":"markdown","42388591":"markdown","e7c4cbaa":"markdown","38e83e78":"markdown","6a9df8a4":"markdown","c3a8c6b0":"markdown","46be2e6e":"markdown","adcd0d2e":"markdown"},"source":{"1fa69077":"# import training dataset\nimport pandas as pd\ndf = pd.read_csv(\"..\/input\/feedback-prize-2021\/train.csv\")\ndf.head()","99b3c9f4":"df.shape","e71db9fa":"# load other datasets (this is mainly used for validation purpose)\ntrain_text_path = \"..\/input\/feedback-prize-2021\/train\"\ntest_text_path = \"..\/input\/feedback-prize-2021\/test\"","9b6e239c":"# read .txt file \npath = '..\/input\/feedback-prize-2021\/train\/423A1CA112E2.txt'\nwith open(path, \"r\") as fp:\n    txt = fp.read()\nprint(txt)","0d2a7273":"text_id = df['id'][0]\ntext_id","853ebd62":"def get_text(file_id):\n    # creating a file path\n    a_file = f\"{train_text_path}\/{file_id}.txt\"\n    \n    # read .txt file \n    with open(a_file, \"r\") as fp:\n        txt = fp.read()\n    return txt\n\ntxt = get_text(text_id)\nprint(txt)","f98fe378":"df_example = df[df['id'] == text_id]\ndf_example","eca36562":"# Creadits for this part of visualisation _> https:\/\/www.kaggle.com\/thedrcat\nimport spacy\nfrom spacy import displacy\nfrom pylab import cm, matplotlib\n\ncolors = {\n            'Lead': '#8000ff',\n            'Position': '#2b7ff6',\n            'Evidence': '#2adddd',\n            'Claim': '#80ffb4',\n            'Concluding Statement': 'd4dd80',\n            'Counterclaim': '#ff8042',\n            'Rebuttal': '#ff0000'\n         }\n\ndef visualize(example, df):\n    ents = []\n    for i, row in df[df['id'] == example].iterrows():\n        ents.append({\n                        'start': int(row['discourse_start']), \n                         'end': int(row['discourse_end']), \n                         'label': row['discourse_type']\n                    })\n        \n    with open(f'{train_text_path}\/{example}.txt', 'r') as file: data = file.read()\n    doc2 = {\n                \"text\": data,\n                \"ents\": ents,\n                \"title\": example\n            }\n\n    options = {\"ents\": df.discourse_type.unique().tolist(), \"colors\": colors}\n    displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True)","8896836a":"examples = df['id'].sample(n=1, random_state=42).values.tolist()\nfor ex in examples:\n    visualize(ex,df)\n    print('\\n')","29148123":"# No nulls\ndf.isnull().sum()","a1297b9d":"# check value count of response variable\ndf.discourse_type.value_counts()\n\n# optional way\ndf['discourse_type'].value_counts()","d044bb27":"new_df = pd.DataFrame(columns=['text', 'label'])\nnew_df['text'] =  df['discourse_text'] \nnew_df['label'] = df['discourse_type']\nnew_df.head()","3a20a05b":"new_df.shape","c3aeff7d":"# select first 5000 obs for fast run on colab\nnew_df = new_df[:5000]\nnew_df.shape","3ff70ee3":"from nltk.stem import PorterStemmer \nfrom nltk.tokenize import word_tokenize \nimport re\nfrom nltk.corpus import stopwords\n\nps = PorterStemmer() \ndef text_process(text):\n    # lower case\n    text = text.lower()\n    # remove emails\n    text= ' '.join([i for i in text.split() if '@' not in i])\n    # remove urls\n    text = re.sub(r'http\\S+|www\\S+', '', text)\n    # remove irrelevant characters other than numbers and space\n    text = re.sub('[^A-Za-z\\s]+', ' ', text)\n    # remove numbers\n    text =  re.sub(r'\\d+', '', text)\n    #remove white spaces\n    text = re.sub(r'\\s+', ' ', text)\n    #remove unwanted words with string\n    text=re.sub(r'\\d+\\W','',text)\n    # Remove HTML Tag\n    text=re.sub(r'<[^>]+>','',text)\n    \n    \n    # Use tokenizer\n    words = word_tokenize(text)\n    # remove Stop words from text\n    stop = stopwords.words('english')\n    words=[x for x in words if x not in stop]\n    text=' '.join(words)\n    return text.strip()","25577837":"text = \"Hello\ud83d\ude42... x@xwy.in my s@gmail.com \u201cname\u201d (is) #Sanket!!!!  7$  ] 100%  } ] http\/\/:vision.com https:\/\/vision.com and your???,,,,, ???? name \\ is \/ www.fb.com \"\ntext_process(text)","fcd434ae":"#apply text processing\n# colum in pandas data\n#1. new_df['text']\n#2. new_df.text\nnew_df = new_df[new_df.text.str.split().str.len() >= 3]\n\nnew_df['text'] = new_df['text'].apply(lambda x: text_process(x))\nnew_df.head(1)","bca15c94":"new_df['category_id'] = new_df['label'].factorize()[0]\nnew_df.head(1)","0dbba493":"new_df['category_id'].unique().tolist()","950c5bd6":"# create a dictionary of id and class (this will help in prediction purpose)\nid_to_category = dict(enumerate(new_df['label'].unique().tolist()))\ncategory_to_id = {v: k for k, v in id_to_category.items()}\nprint(id_to_category)\nprint(category_to_id)","eee140fc":"# model evaluation\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import cohen_kappa_score","8fbea82d":"X = new_df['text'] # features\ny = new_df['category_id'] # labels","77851169":"# maths calculation\nimport numpy as np\n\n# word embeddings \/ feature extraction\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\n\n# Create sample set of documents\ndocs = np.array(['Mirabai has won a silver medal in weight lifting in Tokyo olympics 2021',\n                 'Sindhu has won a bronze medal in badminton in Tokyo olympics'])\n\n# Fit the bag-of-words model df.text\nbag = vectorizer.fit_transform(docs)\n\n# Associate the indices with each unique word\nprint(vectorizer.vocabulary_)\n\nprint(\"---------------------------------\")\n# Print the numerical feature vector\nprint(bag.toarray())","2d9fb1db":"from sklearn.feature_extraction.text import TfidfVectorizer\n# create object\ntfidf = TfidfVectorizer()\n\n# assign documents\nd0 = 'VisionNLP for nlp'\nd1 = 'VisionNLP'\nd2 = 'VisionNLP vision nlp'\n# merge documents into a single corpus\nstring = [d0, d1, d2]\n\n# get tf-df values \nresult = tfidf.fit_transform(string)\n\n# get idf values\nprint('\\nidf values:')\nfor ele1, ele2 in zip(tfidf.get_feature_names(), tfidf.idf_):\n    print(ele1, ':', ele2)","61ccc471":"# get indexing\nprint('\\nWord indexes:')\nprint(tfidf.vocabulary_)\n  \n# display tf-idf values\nprint('\\ntf-idf value:')\nprint(result)\n  \n# in matrix form\nprint('\\ntf-idf values in matrix form:')\nprint(result.toarray())","8d589513":"# word embeddings \/ feature extraction\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer()\nfeatures = tfidf.fit_transform(X).toarray()\nlabels = y","715fa00f":"# train and test spliiting\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.33, random_state=42)\nX_train.shape","c8afacbe":"y_train.shape","8a1ad727":"X_test","7cf01a5c":"# model building\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)","e28591cf":"y_pred = lr.predict( X_test )\ny_pred","39da5ced":"y_test","973998e9":"print(classification_report(y_test, y_pred))","0ec6ee50":"accuracy_score(y_test, y_pred)","6b2d0f03":"cohen_kappa_score(y_test,y_pred)","8dad0de3":"from sklearn.svm import SVC # SVM\nmodel=SVC(C=1, gamma=1, kernel='linear',probability=True)\n#Train Algorithm\nmodel.fit(X_train, y_train)","93455b0e":"# model evaluation\ny_pred = model.predict( X_test )\nprint('Accuracy: ', accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","cefc2022":"# save the model to disk\nimport pickle\nfilename = 'finalized_model.pickle'\npickle.dump(clf, open(filename, 'wb'))","edcc7f3c":"#### Understanding dataset with simple Amazon product reviews Ex.mobile \n\nReview - amazon product\n- \/ train\n- - review1.txt\n- - review2.txt\n- review1.txt: camera is not good. battery is working good.\n\n-\/ train.csv\n| discourse_text      | discourse_type |\n| camera is not good  | camera |\n| battery is working good | battery |\n\n-----\n- train - model building\n- test - validation --> calculate accuracy\n- test - submission\n\n![image.png](attachment:2e5baebe-200c-48b7-85c7-5c2b04224fb3.png)","54beddb0":"# \ud83d\udcd6 Feedback Prize - Sentence Classifier using Machine learning","9691809c":"# load Data","dbac393f":"# 2. Data processing \n\n## Check For Null Values \nwe can see that there are no null values in the dataset","68768b8d":"## For performance and visualization reasons, we'll only use 5,000 sentences from the dataset\n\n### lets learn Text classification zero to BERT","cceb7299":"# 4. Word Emeddings \n\n**In classification of text, for the text we can call sentence, row or document.**\n\n**generate numbers from raw texts**\n\n### context free\n1. Bag of words - simple method\n2. tf-idf - statistical\n\n### context free\n3. word2vec - statistical + deep learning(newural networks)\n4. glove \n\n### contextual\n5. EMLo\n6. bert","cf4ccae4":"# 1. EDA","f5099a0e":"# 3. Text processing\n\n- I've given better version of text clearning and procesing(mainly used in quite messy and unclean data like twitter).\n- This data is clean, you can ignore few steps of clearning process.","656cf28d":"## From the [Data tab](https:\/\/www.kaggle.com\/c\/feedback-prize-2021\/data):\n\n> *  id -                 ID code for essay response\n> *  discourse_id -       ID code for discourse element\n> *  discourse_start -    character position where discourse element begins in the essay response\n> *  discourse_end -      character position where discourse element ends in the essay response\n> *  discourse_text -     text of discourse element\n> *  discourse_type -     classification of discourse element\n> *  discourse_type_num - enumerated class label of discourse element\n> *  predictionstring -   the word indices of the training sample, as required for predictions","42388591":"tf-idf values: \n- first value in tuple is document index\n- second value in tuple is word index\n","e7c4cbaa":"- tf-idf is used in the fields of information retrieval (IR) and machine learning text classification.\n- The tf\u2013idf value increases proportionally to the:-\n- - number of times  a word appears in the document and the number of documents in the corpus that contain the word\n- which helps to adjust for the fact that some words appear more frequently in general. \n\n**inverse document frequency: This means, how common or rare a word is in the entire document set. The closer it is to 0, the more common a word is.**\n\n**tf-idf: The higher the score, the more relevant that word is in that particular document.**","38e83e78":"## 1. Bag of words\n- In this algorithm we basically calculates frequecy of each word means how frequent each word appears in different documents\n- Here we will implement Bag of words (BoW) model\n- Bag of words model helps convert the text into numerical representation (numerical feature vectors) , later this feature vector will be used to train ML models\n- The below picture explains the above concepts:\n\nFor example, for the first document, \u201cbird\u201d occured for 5 times, \u201cthe\u201d occured for two times and \u201cabout\u201d occured for 1 time.\n\n![image.png](attachment:64e41225-06b6-4d03-9224-7126b03263bb.png)\n\nIn python we use **CountVectorizer** class from scikit-learn ","6a9df8a4":"## categorical variable to numerical for model building","c3a8c6b0":"## 2. tf-idf\n\n![image.png](attachment:10ca2f72-1451-45ca-b2a2-74882d6a0097.png)","46be2e6e":"## Let's see the first example in some more detail","adcd0d2e":"![image.png](attachment:a082d528-9e97-4e07-bc83-dcd5ca9d02c9.png)"}}