{"cell_type":{"66dafd35":"code","79c45914":"code","e7606b07":"code","3b960c36":"code","d3d0a683":"code","14cc3dac":"code","b82f3b01":"code","0752ddfd":"code","e681684c":"code","c8fa2d92":"code","73ba7d2b":"code","3541a3d9":"code","9d34dfb6":"code","82452f36":"code","2b5e00f6":"code","87315213":"code","800462b9":"code","706c1f3b":"code","9d4ebef6":"code","0fcb9450":"code","d398b504":"code","b28ff7ba":"markdown","74f005cb":"markdown","d966142b":"markdown"},"source":{"66dafd35":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint('Input file:')\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","79c45914":"train = pd.read_csv(\"..\/input\/train.csv\", \n                    #nrows=6000000, \n                    usecols=['date','store_nbr','item_nbr','unit_sales','onpromotion'],\n                    parse_dates=['date']\n                   )","e7606b07":"print('There are',str(len(train)),'rows in train.csv')\nprint('Columns:',str(list(train.columns)))","3b960c36":"storeAccount=len(train.store_nbr.value_counts())\nprint('There are '+str(storeAccount)+' supermarket of all.')\n\nitemAccount=len(train.item_nbr.value_counts())\nprint('There are '+str(itemAccount)+' items are selling.')\n\nprint('Data record from',\n      str(train.date.head(1)).split( )[1],\n      'to',\n      str(train.date.tail(1)).split( )[1],\n      '.'\n     )","d3d0a683":"storeSalesVolumn=train[['store_nbr','unit_sales']].groupby('store_nbr').sum().sort_values(by='unit_sales',ascending=False)\nstoreSalesVolumn.unit_sales=storeSalesVolumn.unit_sales.astype('int32')\n\ntopStoreId=storeSalesVolumn.head(1).index[0]\n\nprint('Top store ID: '+str(topStoreId) )\nprint('sales volumn: '+str(storeSalesVolumn.head(1).values[0][0]))","14cc3dac":"itemSalesVolumn=train[['item_nbr','unit_sales']].groupby('item_nbr').sum().sort_values(by='unit_sales',ascending=False)\nitemSalesVolumn.unit_sales=itemSalesVolumn.unit_sales.astype('int32')\n\ntopItemId=itemSalesVolumn.head(1).index[0]\n\nprint('Top item ID: '+str(topItemId) )\nprint('sales volumn: '+str(itemSalesVolumn.head(1).values[0][0]))","b82f3b01":"topStoreData=train[train['store_nbr']==topStoreId]\ntopStoreTopItem=topStoreData[topStoreData['item_nbr']==topItemId]\n\ntopStoreTopItem.head(70).unit_sales.plot(kind='bar',\n                                          figsize=(20,5),\n                                          use_index=False,\n                                          xticks=list(range(0,121,7))                                        \n                                        )","0752ddfd":"unWrapDate=topStoreTopItem.copy()\nunWrapDate['weekday']=unWrapDate.date.dt.weekday_name\nunWrapDate['month']=unWrapDate.date.dt.month\nunWrapDate['year']=unWrapDate.date.dt.year\npivotWeek=unWrapDate[['year','month','weekday','unit_sales']]\npivotWeek=pivotWeek.set_index(['year','month'])\npivotWeeked=pivotWeek.pivot_table(index=['year','month'],columns='weekday',values='unit_sales')\npivotWeeked=pivotWeeked.astype('int32')\npivotWeeked=pivotWeeked[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']]\npivotWeeked","e681684c":"import matplotlib.pyplot as plt\nimport seaborn as sns\nstep=len(pivotWeeked.index.levels[0])\nplt.figure(figsize=(15,9))\n\nfor i,year in enumerate(pivotWeeked.index.levels[0]):\n    plt.subplot(4, 1, i+1)\n    ax = sns.heatmap(pivotWeeked.loc[year],linewidths=.5,cmap=\"YlGnBu\")\n    plt.ylabel(str(year))","c8fa2d92":"transactions=pd.read_csv(\"..\/input\/transactions.csv\")\ntransactions.head()","73ba7d2b":"stores=pd.read_csv(\"..\/input\/stores.csv\")\nstores.head()","3541a3d9":"items=pd.read_csv(\"..\/input\/items.csv\")\nitems.head()","9d34dfb6":"oil=pd.read_csv(\"..\/input\/oil.csv\")\noil.head()","82452f36":"holiday=pd.read_csv(\"..\/input\/holidays_events.csv\")\nholiday.head()","2b5e00f6":"from keras import layers\nfrom keras import Input\nfrom keras.models import Model \n\n#input_tensor = Input(shape=(7,))\n#line = layers.Dense(32)(input_tensor) \n#line = layers.Dense(32)(line) \n#output_tensor = layers.Dense(1)(line)\n#model = Model(input_tensor, output_tensor)\n#model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n\nweekday_input = Input(shape=(7,),  name='weekday')\ntempWeekday = layers.Dense(32)(weekday_input)\n\nmonth_input = Input(shape=(13,),  name='month')\ntempMonth = layers.Dense(32)(month_input)\n\nconcatenated = layers.concatenate([tempWeekday, tempMonth], axis=-1)\noutput = layers.Dense(1)(concatenated)\n\nmyModel = Model([weekday_input, month_input], output)\n\nmyModel.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n\nmyModel.summary()","87315213":"weekday=topStoreTopItem.date.dt.dayofweek.values\nmonth=topStoreTopItem.date.dt.month.values\ny=topStoreTopItem.unit_sales.values","800462b9":"from keras.utils import to_categorical\nweekday=to_categorical(weekday)\nmonth=to_categorical(month)","706c1f3b":"myModel.fit({'weekday': weekday, 'month': month},y,epochs=100, batch_size=1, verbose=1 )","9d4ebef6":"[weekday[1],month[1]]","0fcb9450":"temp={'weekday': weekday, 'month': month}","d398b504":"predict=myModel.predict(temp)\npredict[:7]","b28ff7ba":"**Chapter 1** :\noverviews","74f005cb":"**Chapter2** :  bypass input","d966142b":"**Chapter3** :\nmodel fit"}}