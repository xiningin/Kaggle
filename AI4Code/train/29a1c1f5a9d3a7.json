{"cell_type":{"158a9902":"code","d1e35eed":"code","71f42f05":"code","948b1783":"code","6ce61e2f":"code","35b169f9":"code","5e837532":"code","5cf550da":"code","6bcb31b0":"code","cfb85a25":"code","67be6eb5":"code","2ffc5aae":"code","ed05fce7":"code","d0c001a9":"code","c1c804dd":"code","13c1b6e7":"code","49240941":"code","66c0d2c0":"code","76ddd5b4":"code","cae67620":"code","20cd5a0d":"code","9d5cef02":"code","74f6bc17":"code","e3fa72d3":"code","e1a984be":"code","7fa413c5":"code","19ad85e9":"code","332d51ff":"code","6230815d":"code","4ecd8bdf":"code","f99b2e97":"code","cc0c82bd":"code","b57fb75f":"code","652c13d9":"code","ac59a10c":"code","8f3d52e3":"code","10971c74":"code","af3a3eac":"code","f9700a59":"code","4c0006d1":"code","93c6c1db":"code","9f927893":"code","3d1eb289":"code","40acef20":"code","1fb99956":"code","dd1b76ea":"code","0491dc09":"code","f8d56969":"code","c026fc27":"code","24eed6da":"code","aa695e3e":"code","d52c85a2":"code","a21e8340":"code","0052f0ca":"code","32c271bf":"code","b87613e0":"markdown","220fda08":"markdown","740da287":"markdown","4e951628":"markdown","d277619d":"markdown","92a0d0b5":"markdown","57ebb768":"markdown","3ea85d65":"markdown","daa66574":"markdown"},"source":{"158a9902":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim","d1e35eed":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","71f42f05":"transform_train = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),\n    ])\n# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#                                  std=[0.229, 0.224, 0.225])\ntransform_test = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),\n    ])","948b1783":"trainset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n                                       download=True,\n                                       transform=transform_train)\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False,\n                                     download=True,\n                                     transform=transform_test)","6ce61e2f":"num_classes = 10","35b169f9":"batch_size = 4","5e837532":"trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)","5cf550da":"dataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\nprint(images.shape)\n\nprint(images[1].shape)\nprint(labels[1].item())","6bcb31b0":"def imshow(img, title):\n    npimg = img.numpy() \/ 2 + 0.5\n    plt.figure(figsize=(batch_size,1))\n    plt.axis('off')\n    plt.imshow(np.transpose(npimg,(1, 2, 0)))\n    plt.title(title)\n    plt.show()","cfb85a25":"def imshow(img, title):\n    npimg = img.numpy() \/ 2 + 0.5\n    plt.figure(figsize=(batch_size,1))\n    plt.axis('off')\n    plt.imshow(np.transpose(npimg,(1, 2, 0)))\n    plt.title(title)\n    plt.show()","67be6eb5":"def show_batch_images(dataloader):\n    images, labels = next(iter(dataloader))\n    img = torchvision.utils.make_grid(images)\n    imshow(img, title = [str(x.item()) for x in labels])","2ffc5aae":"for i in range(4):\n    show_batch_images(trainloader)","ed05fce7":"from torchvision import models","d0c001a9":"vgg = models.vgg16_bn()","c1c804dd":"print(vgg)","13c1b6e7":"print(vgg.features[0])","49240941":"print(vgg.classifier[6])","66c0d2c0":"final_in_features = vgg.classifier[6].in_features\nmod_classifier = list(vgg.classifier.children())[:-1]\nmod_classifier.extend([nn.Linear(final_in_features, num_classes)])\nprint(mod_classifier)","76ddd5b4":"vgg.classifier = nn.Sequential(*mod_classifier)\nprint(vgg)","cae67620":"batch_size = 16\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)","20cd5a0d":"def evaluation(dataloader, model):\n    total, correct = 0,0\n    for data in dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (pred == labels).sum().item()\n    return 100 * correct \/ total","9d5cef02":"vgg = vgg.to(device)\nloss_fn = nn.CrossEntropyLoss()\nopt = optim.SGD(vgg.parameters(), lr=0.05)","74f6bc17":"loss_epoch_arr = []\nmax_epochs = 1\n\nn_iters = np.ceil(50000\/batch_size)\n\nfor epoch in range(max_epochs):\n    \n    for i, data in enumerate(trainloader, 0):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        opt.zero_grad()\n        \n        outputs = vgg(inputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        opt.step()\n        \n        del inputs, labels, outputs\n        torch.cuda.empty_cache()\n        \n        if i % 100 == 0:\n            print('Iteration: %d\/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n    \n    loss_epoch_arr.append(loss.item())\n    \n    print('Epoch: %d\/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch,max_epochs,evaluation(testloader,vgg),evaluation(trainloader, vgg)))\n\nplt.plot(loss_epoch_arr)\nplt.show()\n","e3fa72d3":"batch_size = 16\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)","e1a984be":"vgg = models.vgg16_bn(pretrained=True)","7fa413c5":"for param in vgg.parameters():\n    param.requires_grad = False","19ad85e9":"final_in_features = vgg.classifier[6].in_features\nvgg.classifier[6] = nn.Linear(final_in_features, num_classes)","332d51ff":"for param in vgg.parameters():\n    if param.requires_grad:\n        print(param.shape)","6230815d":"vgg = vgg.to(device)\nloss_fn = nn.CrossEntropyLoss()\nopt = optim.SGD(vgg.parameters(),lr=0.05)","4ecd8bdf":"loss_epoch_arr= []\nmax_epochs = 1\n\nn_iters = np.ceil(50000\/batch_size)\n\nfor epoch in range(max_epochs):\n    \n    for i, data in enumerate(trainloader, 0):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        opt.zero_grad()\n        \n        outputs = vgg(inputs)\n        loss = loss_fn(outputs,labels)\n        loss.backward()\n        opt.step()\n        \n        if i % 100 == 0:\n            print(\"Iteration: %d\/%d, Loss: %0.2f \" % (i, n_iters, loss.item()))\n        \n        del inputs, labels, outputs\n        torch.cuda.empty_cache()\n    \n    loss_epoch_arr.append(loss.item())\n    \n    print('Epoch: %d\/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n        epoch, max_epochs,\n        evaluation(testloader, vgg), evaluation(trainloader, vgg)))\n\nplt.plot(loss_epoch_arr)\nplt.show()","f99b2e97":"import copy","cc0c82bd":"loss_epoch_arr = []\nmax_epochs = 1\n\nmin_loss = 1000\n\nn_iters = np.ceil(50000\/batch_size)\n\nfor epoch in range(max_epochs):\n\n    for i, data in enumerate(trainloader, 0):\n\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        opt.zero_grad()\n\n        outputs = vgg(inputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        opt.step()\n        \n        if min_loss > loss.item():\n            min_loss = loss.item()\n            best_model = copy.deepcopy(vgg.state_dict())\n            print('Min loss %0.2f' % min_loss)\n        \n        if i % 100 == 0:\n            print('Iteration: %d\/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n            \n        del inputs, labels, outputs\n        torch.cuda.empty_cache()\n        \n    loss_epoch_arr.append(loss.item())","b57fb75f":"vgg.load_state_dict(best_model)\nprint(evaluation(trainloader, vgg), evaluation(testloader, vgg))","652c13d9":"resnet = models.resnet18(pretrained=True)","ac59a10c":"print(resnet)","8f3d52e3":"for param in resnet.parameters():\n    param.requires_grad = False","10971c74":"in_features = resnet.fc.in_features\nresnet.fc = nn.Linear(in_features, num_classes)","af3a3eac":"for param in resnet.parameters():\n    if param.requires_grad:\n        print(param.shape)","f9700a59":"resnet = resnet.to(device)\nloss_fn = nn.CrossEntropyLoss()\nopt = optim.SGD(resnet.parameters(), lr=0.01)","4c0006d1":"loss_epoch_arr = []\nmax_epochs = 4\n\nmin_loss = 1000\n\nn_iters = np.ceil(50000\/batch_size)\n\nfor epoch in range(max_epochs):\n\n    for i, data in enumerate(trainloader, 0):\n\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        opt.zero_grad()\n\n        outputs = resnet(inputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        opt.step()\n        \n        if min_loss > loss.item():\n            min_loss = loss.item()\n            best_model = copy.deepcopy(resnet.state_dict())\n            print('Min loss %0.2f' % min_loss)\n        \n        if i % 100 == 0:\n            print('Iteration: %d\/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n            \n        del inputs, labels, outputs\n        torch.cuda.empty_cache()\n        \n    loss_epoch_arr.append(loss.item())\n        \n    print('Epoch: %d\/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n        epoch, max_epochs, \n        evaluation(testloader, resnet), evaluation(trainloader, resnet)))\n    \n    \nplt.plot(loss_epoch_arr)\nplt.show()","93c6c1db":"resnet.load_state_dict(best_model)\nprint(evaluation(trainloader, resnet),evaluation(testloader, resnet))","9f927893":"inception = models.inception_v3(pretrained=True)","3d1eb289":"print(inception)","40acef20":"for param in inception.parameters():\n    param.requires_grad = False","1fb99956":"aux_in_features = inception.AuxLogits.fc.in_features\ninception.AuxLogits.fc =nn.Linear(aux_in_features, num_classes)","dd1b76ea":"for param in inception.parameters():\n    if param.requires_grad:\n        print(param.shape)","0491dc09":"in_features = inception.fc.in_features\ninception.fc = nn.Linear(in_features, num_classes)","f8d56969":"for param in inception.parameters():\n    if param.requires_grad:\n        print(param.shape)","c026fc27":"transform_train = transforms.Compose([\n    transforms.RandomResizedCrop(299),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),\n    ])\n# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#                                  std=[0.229, 0.224, 0.225])\ntransform_test = transforms.Compose([\n    transforms.RandomResizedCrop(299),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),\n    ])","24eed6da":"trainset = torchvision.datasets.CIFAR10(root='.\/data', train=True, \n                                        download=True, \n                                        transform=transform_train)\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False, \n                                        download=True, \n                                        transform=transform_test)","aa695e3e":"batch_size=16\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)","d52c85a2":"inception = inception.to(device)\nloss_fn = nn.CrossEntropyLoss()\nopt = optim.SGD(inception.parameters(), lr=0.01)","a21e8340":"def evaluation_inception(dataloader, model):\n    total, correct = 0,0\n    for data in dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs, aux_output = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        total += (pred == labels).sum().item()\n        correct += (pred == labels).sum().item()\n    return 100 * correct \/ total","0052f0ca":"loss_epoch_arr = []\nmax_epochs = 1\n\nmin_loss = 1000\n\nn_iters = np.ceil(50000\/batch_size)\n\nfor epoch in range(max_epochs):\n    \n    for i, data in enumerate(trainloader, 0):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        opt.zero_grad()\n        \n        outputs, aux_outputs = inception(inputs)\n        loss = loss_fn(outputs, labels) + 0.3 * loss_fn(aux_outputs, labels)\n        loss.backward()\n        opt.step()\n        \n        if min_loss > loss.item():\n            min_loss = loss.item()\n            best_model = copy.deepcopy(inception.state_dict())\n            print('Min loss %0.2f' % min_loss)\n            \n        if i % 100 == 0:\n            print('Iteration: %d\/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n        \n        del inputs, labels, outputs\n        torch.cuda.empty_cache()\n    \n    loss_epoch_arr.append(loss.item())\n    \n    print('Epoch: %d\/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n        epoch, max_epochs, \n        evaluation_inception(testloader, inception), \n        evaluation_inception(trainloader, inception)))\n    \nplt.plot(loss_epoch_arr)\nplt.show()","32c271bf":"inception.load_state_dict(best_model)\nprint(evaluation_inception(trainloader, inception), evaluation_inception(testloader, inception))","b87613e0":"### CNNs Architectures\nRead more [link](https:\/\/towardsdatascience.com\/illustrated-10-cnn-architectures-95d78ace614d)","220fda08":"### ResNet Model\n#### [Link](https:\/\/pytorch.org\/hub\/pytorch_vision_resnet\/)","740da287":"### Creating VGG-16\n \n#### [link](https:\/\/pytorch.org\/hub\/pytorch_vision_vgg\/)","4e951628":"### Dataset, transforms, and visualisation","d277619d":"### Freeze layers of Convolutional Operations","92a0d0b5":"### Outline\n1. Loading datasets - Transforming images\n2. VGG-16 with modification to network head\n3. Using pre-trained models\n4. Storing intermediate models\n5. ResNet\n6. Inception v3","57ebb768":"### Inception Model\n#### [Link](https:\/\/pytorch.org\/hub\/pytorch_vision_inception_v3\/)","3ea85d65":"### Train CIFAR10","daa66574":"### With Model Copies"}}