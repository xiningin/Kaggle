{"cell_type":{"3282bceb":"code","32f3bae0":"code","987f9bb1":"code","f94736b3":"code","b6b77772":"code","ec833727":"code","d1c6b2b2":"markdown","038d54ae":"markdown","224a527d":"markdown","8f820958":"markdown","6ed8b41c":"markdown"},"source":{"3282bceb":"import numpy as np\nimport lightgbm as lgb\nimport pandas as pd\nfrom kaggle.competitions import twosigmanews\nimport matplotlib.pyplot as plt\nimport random\nfrom datetime import datetime, date\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time","32f3bae0":"env = twosigmanews.make_env()\n\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train, news_train = market_train_df.copy(), news_train_df.copy()","987f9bb1":"def mis_impute(data):\n    for i in data.columns:\n        if data[i].dtype == \"object\":\n            data[i] = data[i].fillna(\"other\")\n        elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(data[i].mean())\n        else:\n            pass\n    return data\n\nmarket_train_df = mis_impute(market_train_df)\n\ndef data_prep(market_train):\n    market_train.time = market_train.time.dt.date\n    lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n    market_train['assetCodeT'] = market_train['assetCode'].map(lbl)\n    \n    market_train = market_train.dropna(axis=0)\n    \n    return market_train\n\nmarket_train = data_prep(market_train_df)\n\n# check the shape\nprint(market_train.shape)","f94736b3":"market_train = market_train.loc[market_train['time']>=date(2009, 1, 1)]\nup = market_train.returnsOpenNextMktres10 >= 0\nfcol = [c for c in market_train if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n\nX = market_train[fcol].values\nup = up.values\nr = market_train.returnsOpenNextMktres10.values\n\n# Scaling of X values\n# It is good to keep these scaling values for later\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) \/ rng)\n\n# Sanity check\nassert X.shape[0] == up.shape[0] == r.shape[0]\n\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time\n\nX_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.25, random_state=99)\n\ntrain_data = lgb.Dataset(X_train, label=up_train.astype(int))\ntest_data = lgb.Dataset(X_test, label=up_test.astype(int))","b6b77772":"'''\n# use this section if you want to customize optimization\n\n# define blackbox function\ndef f(x):\n    print(x)\n    params = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x[0],\n        'num_leaves': x[1],\n        'min_data_in_leaf': x[2],\n        'num_iteration': x[3],\n        'max_bin': x[4],\n        'verbose': 1\n    }\n    \n    gbm = lgb.train(params,\n            train_data,\n            num_boost_round=100,\n            valid_sets=test_data,\n            early_stopping_rounds=5)\n            \n    print(type(gbm.predict(X_test, num_iteration=gbm.best_iteration)[0]),type(up_test.astype(int)[0]))\n    \n    print('score: ', mean_squared_error(gbm.predict(X_test, num_iteration=gbm.best_iteration), up_test.astype(float)))\n    \n    return mean_squared_error(gbm.predict(X_test, num_iteration=gbm.best_iteration), up_test.astype(float))\n\n# optimize params in these ranges\nspaces = [\n    (0.19, 0.20), #learning_rate\n    (2450, 2600), #num_leaves\n    (210, 230), #min_data_in_leaf\n    (310, 330), #num_iteration\n    (200, 220) #max_bin\n    ]\n\n# run optimization\nfrom skopt import gp_minimize\nres = gp_minimize(\n    f, spaces,\n    acq_func=\"EI\",\n    n_calls=10) # increase n_calls for more performance\n\n# print tuned params\nprint(res.x)\n\n# plot tuning process\nfrom skopt.plots import plot_convergence\nplot_convergence(res)\n'''","ec833727":"# these are tuned params I found\nx_1 = [0.19000424246380565, 2452, 212, 328, 202]\nx_2 = [0.19016805202090095, 2583, 213, 312, 220]\n\nparams_1 = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x_1[0],\n        'num_leaves': x_1[1],\n        'min_data_in_leaf': x_1[2],\n        'num_iteration': x_1[3],\n        'max_bin': x_1[4],\n        'verbose': 1\n    }\n\nparams_2 = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x_2[0],\n        'num_leaves': x_2[1],\n        'min_data_in_leaf': x_2[2],\n        'num_iteration': x_2[3],\n        'max_bin': x_2[4],\n        'verbose': 1\n    }\n\n\ngbm_1 = lgb.train(params_1,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5)\n        \ngbm_2 = lgb.train(params_2,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5)\n        \n\n#prediction\ndays = env.get_prediction_days()\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if (n_days%50==0):\n        print(n_days,end=' ')\n    t = time.time()\n    market_obs_df = data_prep(market_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = market_obs_df[fcol].values\n    X_live = 1 - ((maxs - X_live) \/ rng)\n    prep_time += time.time() - t\n    \n    t = time.time()\n    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))\/2\n    prediction_time += time.time() -t\n    \n    t = time.time()\n\n    confidence = lp\n    confidence = (confidence-confidence.min())\/(confidence.max()-confidence.min())\n    confidence = confidence * 2 - 1\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n    \nenv.write_submission_file()\nsub  = pd.read_csv(\"submission.csv\")","d1c6b2b2":"# Tuning hyper-params with skopt","038d54ae":"# Import packages","224a527d":"# Data prep","8f820958":"# Training with tuned params","6ed8b41c":"# Load Data"}}