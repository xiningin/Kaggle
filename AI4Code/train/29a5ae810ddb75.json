{"cell_type":{"bd6bd557":"code","97d3cd5d":"code","913b421d":"code","248b8349":"code","1a0b736a":"code","9934028f":"code","bff3d86e":"code","93b3a998":"code","e945b733":"code","a4a21848":"code","08113f7a":"code","9aa309b0":"code","4db298cd":"code","779f05f4":"markdown"},"source":{"bd6bd557":"import sys\nsys.path.append('..\/input\/autoaugment')\nfrom autoaugment import ImageNetPolicy\n\nimport PIL\n\nimport pandas as pd\nimport numpy as np\n\nimport keras\nfrom keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Dense\nfrom keras.optimizers import SGD\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm import tqdm","97d3cd5d":"IMG_SIZE = 224\nBATCH_SIZE = 128","913b421d":"train = pd.read_csv('..\/input\/2019-3rd-ml-month-with-kakr\/train.csv')\ntest = pd.read_csv('..\/input\/2019-3rd-ml-month-with-kakr\/test.csv')","248b8349":"folds = list(StratifiedKFold(5, random_state=0, shuffle=False).split(train, train['class']))","1a0b736a":"def make_dataset(df, augment=True, test=False):\n    x = []\n    for i, image_path in tqdm(enumerate(df['img_file'].values)):\n        if test:\n            image_path = '..\/input\/3rd-ml-month-car-image-cropping-dataset\/test_crop\/' + image_path\n        else:\n            image_path = '..\/input\/3rd-ml-month-car-image-cropping-dataset\/train_crop\/' + image_path\n        image = PIL.Image.open(image_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n        x.append(image)\n    if test:\n        y = None\n    else:\n        y = keras.utils.to_categorical(df['class'].astype(int)-1, num_classes=196)\n    return x, y\n\nx_train, y_train = make_dataset(train.iloc[folds[0][0]])\nx_val, y_val = make_dataset(train.iloc[folds[0][1]])","9934028f":"print(len(x_train))\nx_train[:5]","bff3d86e":"print(y_train.shape)\ny_train","93b3a998":"class SlowGenerator(keras.utils.Sequence):\n    \n    def __init__(self, x, y=None, augment=True):\n        self.x = x\n        self.y = y\n        self.augment = augment\n        self.policy = ImageNetPolicy()\n        \n    def __len__(self):\n        return int(np.ceil(len(self.x)\/BATCH_SIZE))\n    \n    def _transform(self, image):\n        image = self.policy(image)\n        image = preprocess_input(np.array(image))\n        return image\n    \n    def __getitem__(self, index):\n        if self.y is None:\n            images = [PIL.Image.open('..\/input\/3rd-ml-month-car-image-cropping-dataset\/test_crop\/'+_x).convert('RGB').resize((IMG_SIZE, IMG_SIZE)) for _x in self.x[index*BATCH_SIZE:(index+1)*BATCH_SIZE]]\n            if self.augment:\n                x = list(map(self._transform, images))\n            else:\n                x = [preprocess_input(np.array(x_)) for x_ in images]\n            return np.array(x)\n        \n        images = [PIL.Image.open('..\/input\/3rd-ml-month-car-image-cropping-dataset\/train_crop\/'+_x).convert('RGB').resize((IMG_SIZE, IMG_SIZE)) for _x in self.x[index*BATCH_SIZE:(index+1)*BATCH_SIZE]]\n        if self.augment:\n            x = np.array(list(map(self._transform, images)))\n            y = self.y[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n            y = keras.utils.to_categorical(y-1, num_classes=196)\n            return x, y\n        \n        x = np.array([preprocess_input(np.array(x_)) for x_ in images])\n        y = self.y[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n        y = keras.utils.to_categorical(y-1, num_classes=196)\n        return x, y\n\nclass FastGenerator(keras.utils.Sequence):\n    \n    def __init__(self, x, y=None, augment=True):\n        self.x = x\n        self.y = y\n        self.augment = augment\n        self.policy = ImageNetPolicy()\n        \n    def __len__(self):\n        return int(np.ceil(len(self.x)\/BATCH_SIZE))\n    \n    def _transform(self, image):\n        image = self.policy(image)\n        image = preprocess_input(np.array(image))\n        return image\n    \n    def __getitem__(self, index):\n        \n        if self.y is None:\n            if self.augment:\n                x = list(map(self._transform, self.x[index*BATCH_SIZE:(index+1)*BATCH_SIZE]))\n            else:\n                x = [preprocess_input(np.array(x_)) for x_ in self.x[index*BATCH_SIZE:(index+1)*BATCH_SIZE]]\n            return np.array(x)\n        \n        if self.augment:\n            x = np.array([preprocess_input(np.array(x_)) for x_ in self.x[index*BATCH_SIZE:(index+1)*BATCH_SIZE]])\n            y = self.y[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n            return x, y\n        \n        x = np.array([preprocess_input(np.array(x_)) for x_ in self.x[index*BATCH_SIZE:(index+1)*BATCH_SIZE]])\n        y = self.y[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n        return x, y","e945b733":"fast_train_generator = FastGenerator(x_train, y_train)\nfast_val_generator = FastGenerator(x_val, y_val, augment=False)\nslow_train_generator = SlowGenerator(train.iloc[folds[0][0]]['img_file'].values, train.iloc[folds[0][0]]['class'].values)\nslow_val_generator = SlowGenerator(train.iloc[folds[0][1]]['img_file'].values, train.iloc[folds[0][1]]['class'].values, augment=False)","a4a21848":"def get_model():\n    \n    base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')\n    base_model.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    output = Dense(196, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=output)\n    model.compile(loss='categorical_crossentropy', optimizer=SGD(momentum=0.9))\n\n    return model","08113f7a":"model = get_model()\nhistory = model.fit_generator(\n    slow_train_generator,\n    validation_data=slow_val_generator,\n    epochs=2,\n    verbose=1\n)","9aa309b0":"model = get_model()\nhistory = model.fit_generator(\n    fast_train_generator,\n    validation_data=fast_val_generator,\n    epochs=2,\n    verbose=1\n)","4db298cd":"model = get_model()\nhistory = model.fit_generator(\n    fast_train_generator,\n    validation_data=fast_val_generator,\n    epochs=2,\n    verbose=1,\n    use_multiprocessing=True,\n    workers=2\n)","779f05f4":"\uc9c0\uae08\uae4c\uc9c0 \uc62c\ub77c\uc628 \ucee4\ub110\ub4e4\uc744 \ubcf4\uba74 \ubc30\uce58\ub9c8\ub2e4 \ud558\ub4dc\uc5d0\uc11c \uc774\ubbf8\uc9c0\ub97c \uc77d\uc5b4\uc640\uc11c \ud559\uc2b5\uc744 \uc2dc\ucf30\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \uc774\ubc88 \ub300\ud68c\ub294 \ub370\uc774\ud130 \uc6a9\ub7c9\uc774 \ud06c\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 \uba54\ubaa8\ub9ac\uc5d0 \uc800\uc7a5\ud574\ub450\uc5b4\uc11c \ubc30\uce58\ub9c8\ub2e4 \ud559\uc2b5\ub370\uc774\ud130\ub97c \ub354 \ube60\ub974\uac8c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ub610\ud55c keras\uc758 `fit_generator` \uba54\uc11c\ub4dc\uc5d0\uc11c `use_multiprocessing=True`, `workers=n`\uc73c\ub85c \ub46c\uc11c \uc804\ucc98\ub9ac \uacfc\uc815\uc744 \uc5ec\ub7ec cpu \ucf54\uc5b4\uc5d0 \ub098\ub204\uc5b4 \ucc98\ub9ac\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. (\ub2e4\ub9cc \uc774 \uae30\ub2a5\uc744 \uc708\ub3c4\uc6b0\uc758 \uc8fc\ud53c\ud130\ub178\ud2b8\ubd81 \ud658\uacbd\uc5d0\uc11c\ub294 \uc4f8 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.)\n\n\uc18d\ub3c4 \ud14c\uc2a4\ud2b8\uac00 \ubaa9\uc801\uc774\ubbc0\ub85c \uc5d0\ud3ed\uc740 2\ubc88\ub9cc \ub3cc\ub838\uc2b5\ub2c8\ub2e4.\n\n---\n\n*\ucc38\uace0*\n1. Cropped image dataset: \ud0dc\uba85\ub2d8\uc758 https:\/\/www.kaggle.com\/tmheo74\/3rd-ml-month-car-image-cropping-dataset\n2. Augmentation: https:\/\/github.com\/DeepVoltaire\/AutoAugment \uc758 ImagenetPolicy\n3. Train-val-split: StratifiedKFold(5)\uc758 \uccab \ubc88\uc9f8 fold\n4. Optimizer: \uc138\uc6d0\ub2d8\uc774 https:\/\/www.kaggle.com\/yangsaewon\/ka-kr-sillim-pytorch-baseline-updated-7-01 \uc5d0\uc11c \uc4f0\uc2e0 SGD(momentum=0.9)"}}