{"cell_type":{"03cbaaa9":"code","135d6011":"code","4fe80ee8":"code","7bbb0143":"code","898e29d9":"code","ad2d5711":"code","39bc10c3":"code","395be83a":"code","381642f5":"code","4a180991":"code","a48bc83d":"code","1f8fd174":"code","f9352e43":"code","e110caf2":"code","d806375d":"code","c1e045a2":"code","c6a42ce3":"code","39448d3e":"markdown","7cdc460c":"markdown","86ed4623":"markdown","ad8aa63a":"markdown","d74e8e90":"markdown","7f3eeb2b":"markdown","272f4ad0":"markdown","02a6045f":"markdown","490640ad":"markdown","7fa5719c":"markdown","fe59f7fd":"markdown","cabcc99a":"markdown","8ad9211a":"markdown"},"source":{"03cbaaa9":"import matplotlib.pyplot as plt \nplt.style.use('ggplot')\n%matplotlib inline","135d6011":"import numpy as np\nimport pandas as pd  \nimport seaborn as sns \nplt.rcParams['figure.figsize'] = (12, 8)","4fe80ee8":"data=pd.read_csv('..\/input\/bike-sharing-data\/bike_sharing_data.txt')\ndata.head()","7bbb0143":"data.info()","898e29d9":"ax=sns.scatterplot(x='Population',y='Profit',data=data)\nax.set_title(\"profit in 10000 dollars  vs  city population in 10000 dollars\")\n","ad2d5711":"def cost_function(X,y,theta):\n    m=len(y)\n    y_pred=X.dot(theta)\n    error = (y_pred -y) **2\n    return 1\/(2*m) * np.sum(error)","39bc10c3":"m=data.Population.values.size\nX=np.append(np.ones((m,1)),data.Population.values.reshape(m,1),axis=1)\ny=data.Profit.values.reshape(m,1)\ntheta=np.zeros((2,1))\ncost_function(X,y,theta)","395be83a":"def gradient_descent(X,y,theta,alpha,iterations):\n    m=len(y)\n    costs=[]\n    for i in range(iterations):\n        y_pred=X.dot(theta)\n        error=np.dot(X.transpose(),(y_pred-y))\n        theta -=alpha* 1\/m *error\n        costs.append(cost_function(X,y,theta))\n    return theta,costs\n\n\n    ","381642f5":"theta, costs=gradient_descent(X,y,theta,alpha=0.01,iterations=2000)\nprint(\"h(x)={} +{}x1\".format(str(round(theta[0,0],2)),str(round(theta[1,0],2))))","4a180991":"from mpl_toolkits.mplot3d import Axes3D","a48bc83d":"theta_0=np.linspace(-10,10,100)\ntheta_1=np.linspace(-1,4,100)\ncost_values=np.zeros((len(theta_0),len(theta_1)))\n\nfor i in range(len(theta_0)):\n    for j in range(len(theta_1)):\n        t=np.array([theta_0[i],theta_1[j]])\n        cost_values[i,j]=cost_function(X,y,t)","1f8fd174":"fig=plt.figure(figsize=(12,8))\nax=fig.gca(projection='3d')\nsurf=ax.plot_surface(theta_0,theta_1,cost_values,cmap='viridis')\nfig.colorbar(surf,shrink=0.5,aspect=5)\nplt.xlabel(\"$\\theta_0$\")\nplt.ylabel(\"$\\theta_1$\")\nax.set_zlabel(\"$(\\theta)$\")\nax.view_init(30,330)\nplt.show()\n","f9352e43":"plt.plot(costs)\nplt.xlabel(\"iterations\")\nplt.ylabel(\"theta\")\nplt.title(\"values of the cost function over iterations of gradient descent\")","e110caf2":"theta=np.squeeze(theta)\nsns.scatterplot(x=\"Population\",y=\"Profit\",data=data)\n\nx_value=[x for x in range(5,25)]\ny_value=[(x*theta[1]+theta[0]) for x in x_value]\nsns.lineplot(x_value,y_value)\n\nplt.xlabel(\"population in 10000s\")\nplt.ylabel(\"profit in $10000s\")\nplt.title(\"linear regression fit\")\n","d806375d":"def predict(x,theta):\n    y_pred=np.dot(theta.transpose(),x)\n    return y_pred","c1e045a2":"y_pred_1=predict(np.array([1,4]),theta)*10000\nprint(\"for population of 40000, model predicts profit of \"+str(round(y_pred_1,0)))","c6a42ce3":"y_pred_1=predict(np.array([1,8.3]),theta)*10000\nprint(\"for population of 83000, model predicts profit of \"+str(round(y_pred_1,0)))","39448d3e":"### Task 5: Gradient Descent\n---","7cdc460c":"### Task 9: Inference using the optimized $\\theta$ values\n---","86ed4623":"### Task 4: Compute the Cost $J(\\theta)$\n---","ad8aa63a":"### Task 8: Training Data with Linear Regression Fit\n---","d74e8e90":"### Task 6: Visualising the Cost Function $J(\\theta)$\n---","7f3eeb2b":"<h2 align=\"center\"> Univariate Linear Regression <\/h2>","272f4ad0":"### Task 3: Visualize the Data\n---","02a6045f":"$h_\\theta(x) = \\theta^Tx$","490640ad":"Minimize the cost function $J(\\theta)$ by updating the below equation and repeat unitil convergence\n        \n$\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$ (simultaneously update $\\theta_j$ for all $j$).","7fa5719c":"The objective of linear regression is to minimize the cost function\n\n$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)} )^2$$\n\nwhere $h_{\\theta}(x)$ is the hypothesis and given by the linear model\n\n$$h_{\\theta}(x) = \\theta^Tx = \\theta_0 + \\theta_1x_1$$","fe59f7fd":"### Task 7: Plotting the Convergence\n---","cabcc99a":"### Task 2: Load the Data and Libraries\n---","8ad9211a":"Plot $J(\\theta)$ against the number of iterations of gradient descent:"}}