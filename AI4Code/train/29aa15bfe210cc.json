{"cell_type":{"150278ad":"code","77a8d140":"code","f54617b5":"code","87398c8d":"code","4eb67ed3":"code","97850bc4":"code","35e28c50":"code","85139d34":"code","313ef5d6":"code","95f6d045":"code","87f64967":"code","25a044ab":"code","abc4d3b6":"code","3248c283":"code","3d251186":"code","8d19a779":"code","a7a80914":"code","a26be688":"code","c2748e3e":"code","a00239e7":"code","88d24929":"code","d592150e":"code","170c2786":"code","98ce3c18":"code","ca1862e6":"code","6330a76f":"code","b076910e":"code","d13758e0":"code","bac4d951":"code","fc53f49f":"code","4033ff39":"code","0881f152":"code","3ec51548":"code","1620721b":"code","36212902":"code","8269a5f1":"code","b91310bb":"markdown","1a35188a":"markdown","f7b2b745":"markdown","77a74119":"markdown","64cf4cba":"markdown","668b362b":"markdown","d5db2122":"markdown","44e7a371":"markdown","d5768829":"markdown","2ab86f14":"markdown","42cc3b50":"markdown"},"source":{"150278ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","77a8d140":"import zipfile\n\nfiles=['\/kaggle\/input\/word2vec-nlp-tutorial\/labeledTrainData.tsv.zip',\n       '\/kaggle\/input\/word2vec-nlp-tutorial\/testData.tsv.zip',\n       '\/kaggle\/input\/word2vec-nlp-tutorial\/unlabeledTrainData.tsv.zip']\n\nfor file in files :\n    zip = zipfile.ZipFile(file,'r')\n    zip.extractall()\n    zip.close()","f54617b5":"train=pd.read_csv('\/kaggle\/working\/labeledTrainData.tsv', delimiter=\"\\t\")\ntest=pd.read_csv('\/kaggle\/working\/testData.tsv', delimiter=\"\\t\")","87398c8d":"sub=pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/sampleSubmission.csv')","4eb67ed3":"train.head()","97850bc4":"print('the train data is : {} line'.format(len(train)))\nprint('the test data is : {} line'.format(len(test)))","35e28c50":"train_len=train['review'].apply(len)\ntest_len=test['review'].apply(len)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot((train_len),color='red')\n\nfig.add_subplot(1,2,2)\nsns.distplot((test_len),color='blue')","85139d34":"train['word_n'] = train['review'].apply(lambda x : len(x.split(' ')))\ntest['word_n'] = test['review'].apply(lambda x : len(x.split(' ')))\n\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot(train['word_n'],color='red')\n\nfig.add_subplot(1,2,2)\nsns.distplot(test['word_n'],color='blue')\n","313ef5d6":"train['length']=train['review'].apply(len)\ntrain['length'].describe()","95f6d045":"train['word_n'].describe()","87f64967":"from wordcloud import WordCloud\ncloud=WordCloud(width=800, height=600).generate(\" \".join(train['review'])) # join function can help merge all words into one string. \" \" means space can be a sep between words.\nplt.figure(figsize=(15,10))\nplt.imshow(cloud)\nplt.axis('off')","25a044ab":"fig, axe = plt.subplots(1,3, figsize=(23,5))\nsns.countplot(train['sentiment'], ax=axe[0])\nsns.boxenplot(x=train['sentiment'], y=train['length'], data=train, ax=axe[1])\nsns.boxenplot(x=train['sentiment'], y=train['word_n'], data=train, ax=axe[2])","abc4d3b6":"print('the review with question mark is {}'.format(np.mean(train['review'].apply(lambda x : '?' in x))))\nprint('the review with fullstop mark is {}'.format(np.mean(train['review'].apply(lambda x : '.' in x))))\nprint('the ratio of the first capital letter is {}'.format(np.mean(train['review'].apply(lambda x : x[0].isupper()))))\nprint('the ratio with the capital letter is {}'.format(np.mean(train['review'].apply(lambda x : max(y.isupper() for y in x)))))\nprint('the ratio with the number is {}'.format(np.mean(train['review'].apply(lambda x : max(y.isdigit() for y in x)))))","3248c283":"import re\nimport json\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer","3d251186":"train['review']=train['review'].apply(lambda x: BeautifulSoup(x,\"html5lib\").get_text())\ntest['review']=test['review'].apply(lambda x: BeautifulSoup(x,\"html5lib\").get_text())","8d19a779":"train['review']=train['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",x))\ntest['review']=test['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",x))","a7a80914":"train.head(3)","a26be688":"stops = set(stopwords.words(\"english\"))\n\nfor i in range(0,25000) : \n    review = train.iloc[i,2] # review column : 2 \n    review = review.lower().split()\n    words = [r for r in review if not r in stops]\n    clean_review = ' '.join(words)\n    train.iloc[i,2] = clean_review","c2748e3e":"for i in range(0,25000) : \n    review = test.iloc[i,1] # review column : 1\n    review = review.lower().split()\n    words = [r for r in review if not r in stops]\n    clean_review = ' '.join(words)\n    test.iloc[i,1] = clean_review","a00239e7":"train['word_n_2'] = train['review'].apply(lambda x : len(x.split(' ')))\ntest['word_n_2'] = test['review'].apply(lambda x : len(x.split(' ')))\n\nfig, axe = plt.subplots(1,1, figsize=(7,5))\nsns.boxenplot(x=train['sentiment'], y=train['word_n_2'], data=train)","88d24929":"from keras.preprocessing.text import Tokenizer\ntk = Tokenizer()\ntk.fit_on_texts(list(train['review'])+list(test['review']))\ntext_seq_tr=tk.texts_to_sequences(train['review'])\ntext_seq_te=tk.texts_to_sequences(test['review'])\nword_ind=tk.word_index","d592150e":"print('Total word count is :',len(word_ind))","170c2786":"data_info={}\ndata_info['word_ind']=word_ind\ndata_info['word_len']=len(word_ind)+1","98ce3c18":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot(pd.Series(text_seq_tr).apply(lambda x : len(x)))\nfig.add_subplot(1,2,2)\nsns.distplot(pd.Series(text_seq_te).apply(lambda x : len(x)))","ca1862e6":"from keras.preprocessing.sequence import pad_sequences\npad_train=pad_sequences(text_seq_tr, maxlen=400) \npad_test=pad_sequences(text_seq_te, maxlen=400) ","6330a76f":"from sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(pad_train, train['sentiment'], random_state=77, test_size=0.07, stratify=train['sentiment'])","b076910e":"len(tk.word_index)","d13758e0":"from keras import Sequential\nfrom keras.layers import Dense, Embedding, Flatten\n\nmodel=Sequential()\nmodel.add(Embedding(101247,65, input_length=400))\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'] )","bac4d951":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes=EarlyStopping(patience=4) \nmc=ModelCheckpoint('best.h5',save_best_only=True)\nmodel.fit(x_train,y_train, batch_size=128, epochs=10, validation_data=[x_valid,y_valid], callbacks=[es,mc]) ","fc53f49f":"model.load_weights('best.h5')","4033ff39":"res=model.predict(pad_test, batch_size=128)","0881f152":"res","3ec51548":"sub['sentiment_pro']=res[:,1]","1620721b":"sub.loc[sub['sentiment_pro']>=0.5,\"sentiment\"]=1\nsub.loc[sub['sentiment_pro']<0.5,\"sentiment\"]=0","36212902":"sub=sub[['id','sentiment']]","8269a5f1":"sub.to_csv('result.csv',index=False)","b91310bb":"- Usiung keras, tokenization and mapping to numbers are done\n- When fitting, `use all data from train and text data set`, which prevents model from errors","1a35188a":"## 3. Modeling\n1. *`sequential model`* using adam optimizer\n1. set `early stopping` and `model checkpoint` (patient option)","f7b2b745":"- `max length` is set, if length more than max length, `zero value` will replace that place","77a74119":"- `Distribution of words in one review` is similar both in train and test set\n- The `mean words` count is 233 and `std` is 173 words\n- The character count seems to show similar distribution with word count","64cf4cba":"## 1. EDA of review texts\n1. `Character distriubtion` of each review\n1. `Word distriubtion` of each review\n1. `Word cloud` of each word\n1. Distribution by `Sentiment class`\n1. Ratio with `special characters`","668b362b":"- `br` is the most frequent one. But br is a sort of HTML tag, Thus it should be removed.\n- `movie` or `film` is the theme which all reviews share. Thus I suppose `idf(inverse document frequency)` shoul be close to zero","d5db2122":"- Use *`0.5 as thereshold`* to specify one or zero","44e7a371":"## 2. Preprocessing\n1. Remove `HTML tags` such as `<br>` using BeautifulSoup\n1. Only `english character` will remain using regular expression\n1. By NLTK, `stopwords` will be eliminated","d5768829":"- After preprocessing, the distribution by sentiment in train data is `not so different` from previous state `except total counts`","2ab86f14":"- The distribution of sentiment is `half and half` between zero and one\n- The review length distribution by sentiment is similar but if somebody feels harshly dissatisfied, the reveiw tends to be wordy (more outliers)","42cc3b50":"- use validation set, when we make a model. test_size is set in between 5% to 10%, to use more data"}}