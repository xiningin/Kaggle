{"cell_type":{"83a698b0":"code","1a97ae18":"code","e909c23f":"code","18dcfdb0":"code","c5f08d72":"code","c288b524":"code","20576fc4":"code","3a7bea77":"code","472e832d":"code","d787992c":"code","816b7e27":"code","42882e36":"code","734030c5":"code","ea1e912d":"code","591ba254":"code","009493f1":"code","25f7b1f4":"code","575314a8":"code","a33a21c1":"code","20fe1977":"code","d1c835b5":"code","b0744ec5":"code","67fda873":"code","80efb0c3":"code","6c426333":"code","f1dfd685":"code","bf1bf8f6":"code","0648a604":"markdown","4d22eb3b":"markdown","48e0b4f1":"markdown","07bb1b64":"markdown","895ce9ce":"markdown","55aae82d":"markdown","7b2e37a4":"markdown","bbfe68fc":"markdown","c643fc6a":"markdown","5c428e9b":"markdown","c3a9512c":"markdown","7384debe":"markdown","8d8517b8":"markdown","2b796044":"markdown","b8963df8":"markdown","b6bb23cd":"markdown","5375505b":"markdown","71ee85e5":"markdown","91c8cab7":"markdown","ed73d31d":"markdown","49d4afa3":"markdown","29fa674e":"markdown","11e08b2f":"markdown","172c8a8b":"markdown","8b835f5b":"markdown","a8402aa4":"markdown","3a8a8fcb":"markdown","3f87fa81":"markdown","537e59d3":"markdown","edec6d2d":"markdown","09c77c41":"markdown","101897a1":"markdown","8f6ed35e":"markdown","b0853e34":"markdown","519b727c":"markdown","93120722":"markdown","26cc30ba":"markdown","840c27c8":"markdown","9cddd681":"markdown","e8b8b5dc":"markdown","8c8d1936":"markdown","84b7529b":"markdown","7732e1e9":"markdown","d162320d":"markdown","98e1cd5b":"markdown","100e4d27":"markdown"},"source":{"83a698b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a97ae18":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport matplotlib.gridspec as gridspec \nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action='ignore')\nplt.rcParams['figure.dpi'] = 200 #high resolution\nfrom matplotlib.colors import ListedColormap\ndf=pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')","e909c23f":"df.head()","18dcfdb0":"data_q35 = df[[i for i in df.columns if 'Q35' in i]]\ndata_q35_count = pd.Series(dtype='int')\nfor i in data_q35.columns:\n        #print(data_q14_count[data_q14[i].value_counts().index[0]])\n        data_q35_count[data_q35[i].value_counts().index[0]] = data_q35[i].count()\nfor i in data_q35_count.index:\n percentage_values=(data_q35_count[i]\/data_q35_count.sum())*100\n print(i,percentage_values)","c5f08d72":"pivot_tools = df[[\"Q5\",'Q35_A_Part_1','Q35_A_Part_2','Q35_A_Part_3','Q35_A_Part_4','Q35_A_Part_5','Q35_A_Part_6','Q35_A_Part_7','Q35_A_Part_8','Q35_A_Part_9','Q35_A_Part_10','Q35_A_OTHER']].groupby(\"Q5\")\ntools_data = pivot_tools['Q35_A_Part_1'].count()\ntools_data = pd.DataFrame(tools_data)\ntools_data.rename(columns = {'Q35_A_Part_1' : ' Neptune.ai '},inplace=True)\ntools_data['Weights & Biases '] = pivot_tools ['Q35_A_Part_2'].count()\ntools_data['Comet.ml  '] = pivot_tools ['Q35_A_Part_3'].count()\ntools_data['Sacred + Omniboard '] = pivot_tools ['Q35_A_Part_4'].count()\ntools_data['Tensorboardd '] = pivot_tools ['Q35_A_Part_5'].count()\ntools_data['Guild.ai '] = pivot_tools ['Q35_A_Part_6'].count()\ntools_data['Polyaxon '] = pivot_tools ['Q35_A_Part_7'].count()\ntools_data['Trains '] = pivot_tools ['Q35_A_Part_8'].count()\ntools_data[' Domino Model Monitor'] = pivot_tools ['Q35_A_Part_9'].count()\ntools_data[' None '] =( pivot_tools ['Q35_A_Part_10'].count())\n\ntools_data['Other'] = pivot_tools ['Q35_A_OTHER'].count()\ntools_data=tools_data.T\ntools_data=tools_data.drop(tools_data.columns[[1,10,13]],axis=1)\n\ntools_data","c288b524":"ax=tools_data.transpose().apply(lambda x: x*100\/sum(x), axis=1).plot(kind=\"barh\", stacked=True,fontsize=18 ,figsize=(28,22))\nplt.legend(loc='upper right', ncol=1, title=\"Tools\",fontsize=24,bbox_to_anchor=(-0.17, .859))\n   \nplt.title(\"ML Experiment Tools\/Role\",fontfamily='serif', fontsize=38)\nplt.xlabel(\" Usage\",fontfamily='serif', fontsize=34)\nplt.ylabel(\"Current Work\",fontfamily='serif', fontsize=34,rotation=90)","20576fc4":"pivot_tools_edu = df[[\"Q4\",'Q35_A_Part_1','Q35_A_Part_2','Q35_A_Part_3','Q35_A_Part_4','Q35_A_Part_5','Q35_A_Part_6','Q35_A_Part_7','Q35_A_Part_8','Q35_A_Part_9','Q35_A_Part_10','Q35_A_OTHER']].groupby(\"Q4\")\ntools_data_edu = pivot_tools_edu['Q35_A_Part_1'].count()\ntools_data_edu = pd.DataFrame(tools_data_edu)\ntools_data_edu.rename(columns = {'Q35_A_Part_1' : ' Neptune.ai '},inplace=True)\ntools_data_edu['Weights & Biases '] = pivot_tools_edu ['Q35_A_Part_2'].count()\ntools_data_edu['Comet.ml  '] = pivot_tools_edu ['Q35_A_Part_3'].count()\ntools_data_edu['Sacred + Omniboard '] = pivot_tools_edu ['Q35_A_Part_4'].count()\ntools_data_edu['Tensorboard '] = pivot_tools_edu ['Q35_A_Part_5'].count()\ntools_data_edu['Guild.ai '] = pivot_tools_edu ['Q35_A_Part_6'].count()\ntools_data_edu['Polyaxon '] = pivot_tools_edu ['Q35_A_Part_7'].count()\ntools_data_edu['Trains '] = pivot_tools_edu ['Q35_A_Part_8'].count()\ntools_data_edu[' Domino Model Monitor'] = pivot_tools_edu ['Q35_A_Part_9'].count()\ntools_data_edu[' None '] =( pivot_tools_edu ['Q35_A_Part_10'].count())\n\ntools_data_edu['Other'] = pivot_tools_edu ['Q35_A_OTHER'].count()\ntools_data_edu=tools_data_edu.T\ntools_data_edu=tools_data_edu.drop(tools_data_edu.columns[[2,7]],axis=1)\ntools_data_edu","3a7bea77":"ax=tools_data_edu.transpose().apply(lambda x: x*100\/sum(x), axis=1).plot(kind=\"barh\", stacked=True,fontsize=18 ,figsize=(28,22))\nplt.legend(loc='upper right', ncol=1, title=\"Tools\",fontsize=24,bbox_to_anchor=(-0.37, 1.00959))\n\nplt.title(\"ML Experiment Tools\/Education\",fontfamily='serif', fontsize=38)\nplt.xlabel(\"Usage\",fontfamily='serif', fontsize=34)\nplt.ylabel(\"Educational Qualification\",fontfamily='serif', fontsize=34,rotation=90)","472e832d":"pivot_tools_exp = df[[\"Q15\",'Q35_A_Part_1','Q35_A_Part_2','Q35_A_Part_3','Q35_A_Part_4','Q35_A_Part_5','Q35_A_Part_6','Q35_A_Part_7','Q35_A_Part_8','Q35_A_Part_9','Q35_A_Part_10','Q35_A_OTHER']].groupby(\"Q15\")\ntools_data_exp = pivot_tools_exp['Q35_A_Part_1'].count()\ntools_data_exp = pd.DataFrame(tools_data_exp)\ntools_data_exp.rename(columns = {'Q35_A_Part_1' : ' Neptune.ai '},inplace=True)\ntools_data_exp['Weights & Biases '] = pivot_tools_exp ['Q35_A_Part_2'].count()\ntools_data_exp['Comet.ml  '] = pivot_tools_exp ['Q35_A_Part_3'].count()\ntools_data_exp['Sacred + Omniboard '] = pivot_tools_exp ['Q35_A_Part_4'].count()\ntools_data_exp['Tensorboard '] = pivot_tools_exp ['Q35_A_Part_5'].count()\ntools_data_exp['Guild.ai '] = pivot_tools_exp ['Q35_A_Part_6'].count()\ntools_data_exp['Polyaxon '] = pivot_tools_exp ['Q35_A_Part_7'].count()\ntools_data_exp['Trains '] = pivot_tools_exp ['Q35_A_Part_8'].count()\ntools_data_exp[' Domino Model Monitor'] = pivot_tools_exp ['Q35_A_Part_9'].count()\ntools_data_exp[' None '] =( pivot_tools_exp ['Q35_A_Part_10'].count())\n\ntools_data_exp['Other'] = pivot_tools_exp ['Q35_A_OTHER'].count()\ntools_data_exp=tools_data_exp.T\ntools_data_exp=tools_data_exp.drop(tools_data_exp.columns[7],axis=1)\ntools_data_exp","d787992c":"ax=tools_data_exp.transpose().apply(lambda x: x*100\/sum(x), axis=1).plot(kind=\"barh\", stacked=True,fontsize=18 ,figsize=(28,22))\nplt.legend(loc='upper right', ncol=1, title=\"Tools\",fontsize=24,bbox_to_anchor=(-0.27, .959))\n\n   \nplt.title(\"ML Experiment Tools\/ML Experience\",fontfamily='serif', fontsize=38)\nplt.xlabel(\" Usage\",fontfamily='serif', fontsize=34)\nplt.ylabel(\"ML Experience in years\",fontfamily='serif', fontsize=34,rotation=90)","816b7e27":"data_q10_ans= df[[i for i in df.columns if 'Q10' in i]]\ndata_q10_count_ans = pd.Series(dtype='int')\nfor i in data_q10_ans.columns:\n        \n        #print(data_q35_ans[i].value_counts().index[0])\n        data_q10_count_ans[data_q10_ans[i].value_counts().index[0]] = data_q10_ans[i].count()\nprint(data_q10_count_ans)\nplt.figure(figsize=(15,12))\nsns.set(style='whitegrid',font_scale=1.5)\nsns.barplot(y=data_q10_count_ans.index,x=data_q10_count_ans,data=df)\nax=plt.gca()\n\nplt.title('Hosted Notebook Products Used',size=20)","42882e36":"pivot_exp= df[[\"Q15\",'Q10_Part_1','Q10_Part_2','Q10_Part_3','Q10_Part_4','Q10_Part_5','Q10_Part_6','Q10_Part_7','Q10_Part_8','Q10_Part_9','Q10_Part_10','Q10_Part_11','Q10_Part_12','Q10_OTHER']].groupby(\"Q15\")\nnotebooks_data_exp = pivot_exp['Q10_Part_1'].count()\nnotebooks_data_exp = pd.DataFrame(notebooks_data_exp)\nnotebooks_data_exp.rename(columns = {'Q10_Part_1' : 'Kaggle Notebooks'},inplace=True)\nnotebooks_data_exp['Colab Notebooks'] = pivot_exp['Q10_Part_2'].count()\nnotebooks_data_exp['Azure Notebooks'] = pivot_exp['Q10_Part_3'].count()\nnotebooks_data_exp['Paperspace \/ Gradient'] = pivot_exp['Q10_Part_4'].count()\nnotebooks_data_exp['Code Ocean'] = pivot_exp['Q10_Part_6'].count()\nnotebooks_data_exp['Jupyter Hub'] = pivot_exp['Q10_Part_5'].count()\nnotebooks_data_exp['IBM Watson Studio'] = pivot_exp['Q10_Part_7'].count()\nnotebooks_data_exp['Amazon Sagemaker Studio'] = pivot_exp['Q10_Part_8'].count()\nnotebooks_data_exp['Amazon EMR Notebooks'] = pivot_exp['Q10_Part_9'].count()\nnotebooks_data_exp['Google Cloud AI Platform Notebooks'] = pivot_exp['Q10_Part_10'].count()\nnotebooks_data_exp['Google Cloud Datalab Notebooks'] = pivot_exp['Q10_Part_11'].count()\nnotebooks_data_exp['Databricks Collaborative Notebooks'] = pivot_exp['Q10_Part_12'].count()\nnotebooks_data_exp['Other'] = pivot_exp['Q10_OTHER'].count()\nnotebooks_data_exp=notebooks_data_exp.T\nnotebooks_data_exp=notebooks_data_exp.drop(notebooks_data_exp.columns[7],axis=1)\nnotebooks_data_exp","734030c5":"fig, ax = plt.subplots(1,1, figsize=(3,3))\nsns.heatmap(notebooks_data_exp.T, \n            cmap=\"PiYG\",\n            square=True, \n            linewidth=0.1, \n            cbar=False, \n            ax=ax,\n            annot=True,\n            annot_kws={\"fontsize\":'4'},\n            xticklabels=True, \n            yticklabels=True,\n            \n                fmt=\"d\"\n           )\n\nax.spines['top'].set_visible(True)\n\n  \n\nax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=4)\nax.set_xticklabels (ax.get_xticklabels(),fontfamily='serif', rotation=90, fontsize=4)\nplt.title(\"Notebooks Used vs ML Experience\",fontfamily='serif', fontsize=8)\nplt.xlabel(\"Notebooks\",fontfamily='serif', fontsize=6)\nplt.ylabel(\"ML Experience in years\",fontfamily='serif', fontsize=6,rotation=90)\nplt.show()\n","ea1e912d":"pivot_job= df[[\"Q5\",'Q10_Part_1','Q10_Part_2','Q10_Part_3','Q10_Part_4','Q10_Part_5','Q10_Part_6','Q10_Part_7','Q10_Part_8','Q10_Part_9','Q10_Part_10','Q10_Part_11','Q10_Part_12','Q10_OTHER']].groupby(\"Q5\")\nnotebooks_data_job = pivot_job['Q10_Part_1'].count()\nnotebooks_data_job = pd.DataFrame(notebooks_data_job)\nnotebooks_data_job.rename(columns = {'Q10_Part_1' : 'Kaggle Notebooks'},inplace=True)\nnotebooks_data_job['Colab Notebooks'] = pivot_job['Q10_Part_2'].count()\nnotebooks_data_job['Azure Notebooks'] = pivot_job['Q10_Part_3'].count()\nnotebooks_data_job['Paperspace \/ Gradient'] = pivot_job['Q10_Part_4'].count()\nnotebooks_data_job['Code Ocean'] = pivot_job['Q10_Part_6'].count()\nnotebooks_data_job['Jupyter Hub'] = pivot_job['Q10_Part_5'].count()\nnotebooks_data_job['IBM Watson Studio'] = pivot_job['Q10_Part_7'].count()\nnotebooks_data_job['Amazon Sagemaker Studio'] = pivot_job['Q10_Part_8'].count()\nnotebooks_data_job['Amazon EMR Notebooks'] = pivot_job['Q10_Part_9'].count()\nnotebooks_data_job['Google Cloud AI Platform Notebooks'] = pivot_job['Q10_Part_10'].count()\nnotebooks_data_job['Google Cloud Datalab Notebooks'] = pivot_job['Q10_Part_11'].count()\nnotebooks_data_job['Databricks Collaborative Notebooks'] = pivot_job['Q10_Part_12'].count()\nnotebooks_data_job['Other'] = pivot_job['Q10_OTHER'].count()\nnotebooks_data_job=notebooks_data_job.T\nnotebooks_data_job=notebooks_data_job.drop(notebooks_data_job.columns[10],axis=1)\nnotebooks_data_job","591ba254":"\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nsns.heatmap(notebooks_data_job.T, \n            \n            square=True, \n            linewidth=0.1, \n            cbar=False, \n            ax=ax,\n            annot=True,\n            annot_kws={\"fontsize\":'4'},\n            xticklabels=True, \n            yticklabels=True,\n            \n                fmt=\"d\"\n           )\n\nax.spines['top'].set_visible(True)\n\nax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=4)\nax.set_xticklabels (ax.get_xticklabels(),fontfamily='serif', rotation=90, fontsize=4)\nplt.title(\"Notebooks Used vs Current Work\",fontfamily='serif', fontsize=12)\nplt.xlabel(\"Notebooks\",fontfamily='serif', fontsize=10)\nplt.ylabel(\"Current Work\",fontfamily='serif', fontsize=10,rotation=90)\n\nplt.show()\n","009493f1":"pivot = df[[\"Q4\",'Q10_Part_1','Q10_Part_2','Q10_Part_3','Q10_Part_4','Q10_Part_5','Q10_Part_6','Q10_Part_7','Q10_Part_8','Q10_Part_9','Q10_Part_10','Q10_Part_11','Q10_Part_12','Q10_OTHER']].groupby(\"Q4\")\nnotebooks_data = pivot['Q10_Part_1'].count()\nnotebooks_data = pd.DataFrame(notebooks_data)\nnotebooks_data.rename(columns = {'Q10_Part_1' : 'Kaggle Notebooks'},inplace=True)\nnotebooks_data['Colab Notebooks'] = pivot['Q10_Part_2'].count()\nnotebooks_data['Azure Notebooks'] = pivot['Q10_Part_3'].count()\nnotebooks_data['Paperspace \/ Gradient'] = pivot['Q10_Part_4'].count()\nnotebooks_data['Code Ocean'] = pivot['Q10_Part_6'].count()\nnotebooks_data['Jupyter Hub'] = pivot['Q10_Part_5'].count()\nnotebooks_data['IBM Watson Studio'] = pivot['Q10_Part_7'].count()\nnotebooks_data['Amazon Sagemaker Studio'] = pivot['Q10_Part_8'].count()\nnotebooks_data['Amazon EMR Notebooks'] = pivot['Q10_Part_9'].count()\nnotebooks_data['Google Cloud AI Platform Notebooks'] = pivot['Q10_Part_10'].count()\nnotebooks_data['Google Cloud Datalab Notebooks'] = pivot['Q10_Part_11'].count()\nnotebooks_data['Databricks Collaborative Notebooks'] = pivot['Q10_Part_12'].count()\nnotebooks_data['Other'] = pivot['Q10_OTHER'].count()\nnotebooks_data=(notebooks_data.T)\nnotebooks_data=notebooks_data.drop(notebooks_data.columns[7],axis=1)\nnotebooks_data","25f7b1f4":"\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nsns.heatmap(notebooks_data.T, \n            cmap=\"YlGnBu\",\n            square=True, \n            linewidth=0.1, \n            cbar=False, \n            ax=ax,\n            annot=True,\n            annot_kws={\"fontsize\":'4'},\n            xticklabels=True, \n            yticklabels=True,\n            \n                fmt=\"d\"\n           )\n\nax.spines['top'].set_visible(True)\n\nax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=4)\nax.set_xticklabels (ax.get_xticklabels(),fontfamily='serif', rotation=90, fontsize=4)\nplt.title(\"Notebooks Used vs Educational Qualification\",fontfamily='serif', fontsize=12)\nplt.xlabel(\"Notebooks\",fontfamily='serif', fontsize=10)\nplt.ylabel(\" Educational Qualification\",fontfamily='serif', fontsize=10,rotation=90)\n\nplt.show()\n","575314a8":"pivot_auto_exp= df[[\"Q15\",'Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10','Q34_A_Part_11','Q34_A_OTHER']].groupby(\"Q15\")\nauto_data_exp = pivot_auto_exp['Q34_A_Part_1'].count()\nauto_data_exp = pd.DataFrame(auto_data_exp)\nauto_data_exp.rename(columns = {'Q34_A_Part_1' : 'Google Cloud AutoML'},inplace=True)\nauto_data_exp['H20 Driverless AI'] = pivot_auto_exp['Q34_A_Part_2'].count()\nauto_data_exp['Databricks AutoML'] = pivot_auto_exp['Q34_A_Part_3'].count()\nauto_data_exp['DataRobot AutoML'] = pivot_auto_exp['Q34_A_Part_4'].count()\n\nauto_data_exp['Tpot'] = pivot_auto_exp['Q34_A_Part_5'].count()\nauto_data_exp['Auto-Keras'] = pivot_auto_exp['Q34_A_Part_6'].count()\nauto_data_exp['Auto-Sklearn'] = pivot_auto_exp['Q34_A_Part_7'].count()\nauto_data_exp['Auto_ml'] = pivot_auto_exp['Q34_A_Part_8'].count()\nauto_data_exp['Xcessiv'] = pivot_auto_exp['Q34_A_Part_9'].count()\nauto_data_exp['MLbox'] = pivot_auto_exp['Q34_A_Part_10'].count()\nauto_data_exp['None'] = pivot_auto_exp['Q34_A_Part_11'].count()\n\nauto_data_exp['Other'] = pivot_auto_exp['Q34_A_OTHER'].count()\nauto_data_exp=auto_data_exp.T\nauto_data_exp=auto_data_exp.drop(auto_data_exp.columns[7],axis=1)\nauto_data_exp","a33a21c1":"ax=auto_data_exp.transpose().apply(lambda x: x*100\/sum(x), axis=1).plot(kind=\"bar\", stacked=True,fontsize=18 ,figsize=(28,22))\nplt.legend(loc='upper right', ncol=1, title=\"Tools\",fontsize=24,bbox_to_anchor=(-0.17, .859))\n\n   \nplt.title(\"Auto ML Tools\/ML Experience in Years\",fontfamily='serif', fontsize=38)\nplt.xlabel(\"ML Experience in years\",fontfamily='serif', fontsize=34)\nplt.ylabel(\"% Usage\",fontfamily='serif', fontsize=34,rotation=90)","20fe1977":"pivot_auto_job= df[[\"Q5\",'Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10','Q34_A_Part_11','Q34_A_OTHER']].groupby(\"Q5\")\nauto_data_job = pivot_auto_job['Q34_A_Part_1'].count()\nauto_data_job = pd.DataFrame(auto_data_job)\nauto_data_job.rename(columns = {'Q34_A_Part_1' : 'Google Cloud AutoML'},inplace=True)\nauto_data_job['H20 Driverless AI'] = pivot_auto_job['Q34_A_Part_2'].count()\nauto_data_job['Databricks AutoML'] = pivot_auto_job['Q34_A_Part_3'].count()\nauto_data_job['DataRobot AutoML'] = pivot_auto_job['Q34_A_Part_4'].count()\n\nauto_data_job['Tpot'] = pivot_auto_exp['Q34_A_Part_5'].count()\nauto_data_job['Auto-Keras'] = pivot_auto_job['Q34_A_Part_6'].count()\nauto_data_job['Auto-Sklearn'] = pivot_auto_job['Q34_A_Part_7'].count()\nauto_data_job['Auto_ml'] = pivot_auto_job['Q34_A_Part_8'].count()\nauto_data_job['Xcessiv'] = pivot_auto_job['Q34_A_Part_9'].count()\nauto_data_job['MLbox'] = pivot_auto_job['Q34_A_Part_10'].count()\nauto_data_job['None'] = pivot_auto_job['Q34_A_Part_11'].count()\n\nauto_data_job['Other'] = pivot_auto_job['Q34_A_OTHER'].count()\nauto_data_job=auto_data_job.fillna(0)\n\nauto_data_job=auto_data_job.T\nauto_data_job=auto_data_job.drop(auto_data_job.columns[[1,10,13]],axis=1)\nauto_data_job","d1c835b5":"ax=auto_data_job.transpose().apply(lambda x: x*100\/sum(x), axis=1).plot(kind=\"barh\", stacked=True,fontsize=18 ,figsize=(28,22))\nplt.legend(loc='upper right', ncol=1, title=\"Tools\",fontsize=24,bbox_to_anchor=(-0.17, .859))\n\n   \nplt.title(\"Auto ML Tools\/Role in Industry\",fontfamily='serif', fontsize=38)\nplt.xlabel(\" Usage\",fontfamily='serif', fontsize=34)\nplt.ylabel(\"Role in Industry\",fontfamily='serif', fontsize=34,rotation=90)","b0744ec5":"pivot_bi_job= df[[\"Q5\",'Q31_A_Part_1','Q31_A_Part_2','Q31_A_Part_3','Q31_A_Part_4','Q31_A_Part_5','Q31_A_Part_6','Q31_A_Part_7','Q31_A_Part_8','Q31_A_Part_9','Q31_A_Part_10','Q31_A_Part_11','Q31_A_Part_12','Q31_A_Part_13','Q31_A_OTHER']].groupby(\"Q5\")\nbi_data_job = pivot_bi_job['Q31_A_Part_1'].count()\nbi_data_job = pd.DataFrame(bi_data_job)\nbi_data_job.rename(columns = {'Q31_A_Part_1' : 'Amazon QuickSight'},inplace=True)\nbi_data_job['Microsoft Power BI'] = pivot_bi_job['Q31_A_Part_2'].count()\nbi_data_job['Google Data Studio'] = pivot_bi_job['Q31_A_Part_3'].count()\nbi_data_job['Tableau'] = pivot_bi_job['Q31_A_Part_4'].count()\n\nbi_data_job['Salesforce'] = pivot_bi_job['Q31_A_Part_5'].count()\nbi_data_job['Einstein Analytics'] = pivot_bi_job['Q31_A_Part_6'].count()\nbi_data_job['Qlik'] = pivot_bi_job['Q31_A_Part_7'].count()\nbi_data_job['Domo'] = pivot_bi_job['Q31_A_Part_8'].count()\nbi_data_job['TIBCO Spotfire'] = pivot_bi_job['Q31_A_Part_9'].count()\nbi_data_job[' Alteryx'] =pivot_bi_job['Q31_A_Part_10'].count()\nbi_data_job['TIBCO Spotfire'] = pivot_bi_job['Q31_A_Part_11'].count()\nbi_data_job[' Sisense'] = pivot_bi_job['Q31_A_Part_12'].count()\nbi_data_job['SAP Analytics Cloud'] = pivot_bi_job['Q31_A_Part_13'].count()\n\nbi_data_job['Other'] =pivot_bi_job['Q31_A_OTHER'].count()\nbi_data_job=bi_data_job.T\nbi_data_job=bi_data_job.drop(bi_data_job.columns[[10,13]],axis=1)\nbi_data_job","67fda873":"bi_data_job.T.apply(lambda x: x*100\/sum(x), axis=1).plot(kind='barh', stacked=True,colormap=ListedColormap(sns.color_palette(\"colorblind\",13)), \n          figsize=(12,10))\nplt.legend(loc='upper right', ncol=1, title=\"Tools\",fontsize=14,bbox_to_anchor=(-0.47, 1.0859))\nplt.title(\"Business Intelligence Tools\/Role in Industry\",fontfamily='serif', fontsize=24)\nplt.xlabel(\"Usage \",fontfamily='serif', fontsize=18)\nplt.ylabel(\"Role in Industry\",fontfamily='serif', fontsize=18,rotation=90)","80efb0c3":"pivot_bi_exp= df[[\"Q15\",'Q31_A_Part_1','Q31_A_Part_2','Q31_A_Part_3','Q31_A_Part_4','Q31_A_Part_5','Q31_A_Part_6','Q31_A_Part_7','Q31_A_Part_8','Q31_A_Part_9','Q31_A_Part_10','Q31_A_Part_11','Q31_A_Part_12','Q31_A_Part_13','Q31_A_OTHER']].groupby(\"Q15\")\nbi_data_exp = pivot_bi_exp['Q31_A_Part_1'].count()\nbi_data_exp = pd.DataFrame(bi_data_exp)\nbi_data_exp.rename(columns = {'Q31_A_Part_1' : 'Amazon QuickSight'},inplace=True)\nbi_data_exp['Microsoft Power BI'] = pivot_bi_exp['Q31_A_Part_2'].count()\nbi_data_exp['Google Data Studio'] = pivot_bi_exp['Q31_A_Part_3'].count()\nbi_data_exp['Tableau'] = pivot_bi_exp['Q31_A_Part_4'].count()\n\nbi_data_exp['Salesforce'] = pivot_bi_exp['Q31_A_Part_5'].count()\nbi_data_exp['Einstein Analytics'] = pivot_bi_exp['Q31_A_Part_6'].count()\nbi_data_exp['Qlik'] = pivot_bi_exp['Q31_A_Part_7'].count()\nbi_data_exp['Domo'] = pivot_bi_exp['Q31_A_Part_8'].count()\nbi_data_exp['TIBCO Spotfire'] = pivot_bi_exp['Q31_A_Part_9'].count()\nbi_data_exp[' Alteryx'] =pivot_bi_exp['Q31_A_Part_10'].count()\nbi_data_exp['TIBCO Spotfire'] = pivot_bi_exp['Q31_A_Part_11'].count()\nbi_data_exp[' Sisense'] = pivot_bi_exp['Q31_A_Part_12'].count()\nbi_data_exp['SAP Analytics Cloud'] = pivot_bi_exp['Q31_A_Part_13'].count()\n\nbi_data_exp['Other'] =pivot_bi_exp['Q31_A_OTHER'].count()\nbi_data_exp=bi_data_exp.T\nbi_data_exp=bi_data_exp.drop(bi_data_exp.columns[7],axis=1)\nbi_data_exp","6c426333":"\nbi_data_exp.T.apply(lambda x: x*100\/sum(x), axis=1).plot(kind='barh', stacked=True,colormap=ListedColormap(sns.color_palette(\"dark\",13)), \n          figsize=(12,10))\nplt.legend(loc='upper right', ncol=1, title=\"Tools\",fontsize=14,bbox_to_anchor=(-0.47, 1.0859))\nplt.title(\"Business Intelligence Tools\/ML Experience\",fontfamily='serif', fontsize=24)\nplt.xlabel(\"Usage \",fontfamily='serif', fontsize=18)\nplt.ylabel(\"ML Experience\",fontfamily='serif', fontsize=18,rotation=90)\n","f1dfd685":"pivot_bi_edu= df[[\"Q4\",'Q31_A_Part_1','Q31_A_Part_2','Q31_A_Part_3','Q31_A_Part_4','Q31_A_Part_5','Q31_A_Part_6','Q31_A_Part_7','Q31_A_Part_8','Q31_A_Part_9','Q31_A_Part_10','Q31_A_Part_11','Q31_A_Part_12','Q31_A_Part_13','Q31_A_OTHER']].groupby(\"Q4\")\nbi_data_edu = pivot_bi_edu['Q31_A_Part_1'].count()\nbi_data_edu = pd.DataFrame(bi_data_edu)\nbi_data_edu.rename(columns = {'Q31_A_Part_1' : 'Amazon QuickSight'},inplace=True)\nbi_data_edu['Microsoft Power BI'] = pivot_bi_edu['Q31_A_Part_2'].count()\nbi_data_edu['Google Data Studio'] = pivot_bi_edu['Q31_A_Part_3'].count()\nbi_data_edu['Tableau'] = pivot_bi_edu['Q31_A_Part_4'].count()\n\nbi_data_edu['Salesforce'] = pivot_bi_edu['Q31_A_Part_5'].count()\nbi_data_edu['Einstein Analytics'] = pivot_bi_edu['Q31_A_Part_6'].count()\nbi_data_edu['Qlik'] = pivot_bi_edu['Q31_A_Part_7'].count()\nbi_data_edu['Domo'] = pivot_bi_edu['Q31_A_Part_8'].count()\nbi_data_edu['TIBCO Spotfire'] = pivot_bi_edu['Q31_A_Part_9'].count()\nbi_data_edu[' Alteryx'] =pivot_bi_edu['Q31_A_Part_10'].count()\nbi_data_edu['TIBCO Spotfire'] = pivot_bi_edu['Q31_A_Part_11'].count()\nbi_data_edu[' Sisense'] = pivot_bi_edu['Q31_A_Part_12'].count()\nbi_data_edu['SAP Analytics Cloud'] = pivot_bi_edu['Q31_A_Part_13'].count()\n\nbi_data_edu['Other'] =pivot_bi_edu['Q31_A_OTHER'].count()\nbi_data_edu=bi_data_edu.T\nbi_data_edu=bi_data_edu.drop(bi_data_edu.columns[7],axis=1)\nbi_data_edu","bf1bf8f6":"bi_data_edu.T.apply(lambda x: x*100\/sum(x), axis=1).plot(kind='bar', stacked=True, colormap=ListedColormap(sns.color_palette(\"Paired\",13)),\n          figsize=(12,6))\n\nplt.legend(loc='upper right', ncol=1, title=\"Tools\",fontsize=14,bbox_to_anchor=(-0.17, .859))\nplt.title(\"Business Intelligence Tools\/Educational Qualification\",fontfamily='serif', fontsize=24)\nplt.xlabel(\"Role in Industry \",fontfamily='serif', fontsize=18)\nplt.ylabel(\"Usage\",fontfamily='serif', fontsize=18,rotation=90)","0648a604":"###  With respect to Machine Learning Experience","4d22eb3b":"### Overall Usage","48e0b4f1":" ### Q31 Business Intelligence Tools ","07bb1b64":"Its is seen that Auto Sklearn is the clear winner among all the categories followed by Auto Keras and Google Cloud ML. As the experience increases people tend to use less AutoML\/Partial Auto ML features. The experts tend to use less Automl tools comapred to others(they tend to build complex models). The advantage of Automl trickles down here since experts produce better models than Automated ML\n\nThe tides are in favour of people with less experience AutoML produce a base model which can help beginners to tune or grasp quickly how things work!","895ce9ce":"### Conclusion\n\n\nIn this study, I have presented the findings related to the  usage of the most commonly used Tools as per the data available. These results are based only the perception of the survey.The summary of useful insights found:\n\n* Almost 70% of the people dont use tools to support their training. Among those who use Tesnsorboard is the most commonly used tool\n\n* People with lower educational qualification tend to depend on these tools more\n\n* Adaptation of tools for taining is more and quick in ML newbies comapred to experts\n\n* Both Colab and Kaggle are the clear winners in Notebook preferneces in almost all categories\n\n* Maximum adoption of AutoML is by Data Scientists. Multiple years of experience increases the likelihood of AutoML adoption.\n\n* The propotion of Business intelligence tools is highest among Bachelors and Masters people compared to other degree holders.\n\nOverall the adpation to new tools is little less compared to the emergence of new tools. This may also be due to any external factors like cost. I hope this been an interesting study","55aae82d":"Its clear from the chart that from 2 to 10 years the uses of ML managemnet tools remains constant with TensorBoard being the one with highest followed by Neptune.ai and Weights&Biases\nFor people with more than 10+ years experince the use of tools decreases which may be due to the fact that they move to more of managemnet positions.People with ML Experience of 1-2years and less than 1 year  have used almost all tools which shows that beginners are ready to get their hands dirty to learn anything new and get a good grasp of what will be useful. ","7b2e37a4":"Sales Force  and Microsoft Power BI are the top two choices of the professionals. Its evident that Data Scientist, Business analyst and Data Analyst tend to use a lot these Business Intelligence tools.\n\nData Scientist is the highest user of Business Intelligence tools among all other professions followed by Data Analyst. Statistician and Database Engineer are the ones who least use Business Intelligence tools","bbfe68fc":"#### Quick overview of the AutoMl tools that are mentioned in the survey:","c643fc6a":"#####         Key Takeaways:\n                1. Always there is an neck to neck tie beween Kaggle and Colab Notebooks across all domains. \n                \n                2.Colab seems to more beginner friendly than Kaggle since it wins by a huge difference in ML Practionres with less than 3years\n                \n                3.Jupyterlab and Google Cloud Data Lab Notebook other commonly used apart from Kaggle and Colab but they are far behind in competition\n                \n                4.DataBricks Collabrative Notebook and Code Ocean are the two least popular notebooks across various domains mentioned ","5c428e9b":"###  With respect to Educational Qualification","c3a9512c":" ### Q10 Hosted Notebook products","7384debe":"### With respect to Educational Qualification","8d8517b8":"### **Annual Kaggle survey**\n\n\nIt's a quadrennial festival for Kaggle's annual Machine Learning and Data Science Survey.The 2020 Survey will be the dataset that will be used for this notebook. Since ML tools are an evoloving technology and some new tools were added to this years survey compared to the previous years survyes I decided to pick the best from the lot using 2020 survey.","2b796044":"**Amazon QuickSight**- Amazon QuickSight is a fast, cloud-powered business intelligence service that makes it easy to deliver insights to everyone in your organization. As a fully managed service, it helps to create and publish interactive dashboards that include ML Insights.\n\n**Microsoft Power BI**- Power BI is a business analytics service by Microsoft. It aims to provide interactive visualizations and business intelligence capabilities with an interface simple enough for end users to create their own reports and dashboards\n\n**Google Data Studio**- Data Studio is a free tool that turns your data into informative, easy to read, easy to share, and fully customizable dashboards and reports.\n\n**Looker**- Looker is a cloud-based business intelligence (BI) platform designed to explore and analyze data. The solution helps businesses to capture and analyze data from multiple sources and make data-driven decisions.\n\n**Tableau**- Tableau software is used to translate queries into visualization. It is also used for managing metadata. Tableau software imports data of all sizes and ranges. it offers the facility to create 'no-code' data queries.\n\n**Salesforce**- Salesforce is a customer relationship management solution that brings companies and customers together. It's one integrated CRM platform that gives all your departments \u2014 including marketing, sales, commerce, and service \u2014 a single, shared view of every customer.\n\n**Einstein Analytics**-  Einstein Analytics delivers a portfolio of contextually relevant, self-service analytics apps that empower every CRM user to explore data and uncover insights\u2014from a simple sales pipeline dashboard to the most advanced complex forecasting decision.\n\n**Qlik**- Qlik provides an end-to-end platform which includes data integration, user-driven business intelligence and conversational analytics.Qlik Sense Desktop is a Windows application that allows users to create visualizations, charts, interactive dashboards and analytics apps for local and offline usage.\n\n**Domo**-Domo is a cloud-native platform that combines iPaaS capabilities for data integration, visualizations for real-time and predictive insights, and a foundation for building own apps to take immediate action on those insights. \n\n**TIBCO Spotfire**-It is a software that is most complete analytics solution on the market, enabling everyone to explore and visualize new discoveries in data through immersive dashboards and advanced analytics \n\n**Alteryx**- Alteryx is a business intelligence platform for data analysts that offers data mining and predictive analytics. It allows users to blend data from disparate sources, including Microsoft Excel, Hadoop, and Salesforce, with built-in drag-and-drop features to prepare raw data for analytics.\n\n**Sisense**- Sisense is a  business intelligence software that offers a host of benefits to its users. It can  be used to collect information from all the sources and unify them into a single repository. The app's powerful visual reports can be used to generate smart analysis. \n\n**SAP Analytics Cloud**- SAP Analytics Cloud is a new tool in the SAP portfolio to meet the needs of data visualization in the cloud. It is delivered as an all-in-one, SaaS-based product. It covers the needs of data visualization, budget planning, and predictive analytics. Its main function is the creation of data reports\n","b8963df8":"**Kaggle Notebooks**-  Kaggle, a subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners which  proivides a cloud computational environment that enables reproducible and collaborative analysis.\n\n**Colab Notebooks**- Colaboratory, or \u201cColab\u201d for short, is a product from Google Research. Colab allows anybody to write and execute arbitrary python code through the browser, and is especially well suited to machine learning, data analysis and education.\n\n**Azure Notebooks**- Azure is a product of Microsoft and  is a free hosted service to develop and run Jupyter notebooks in the cloud with no installation.\n\n**Paperspace \/ Gradient**- Gradient is Paperspace's platform for building machine learning  and deep learning  projects. It helps you through the entire pipeline of building and deploying ML\/DL models. \n\n**Binder \/ JupyterHub**-J upyterHub brings the power of notebooks to groups of users. It gives users access to computational environments and resources without burdening the users with installation and maintenance tasks.\n\n**Code Ocean**- Code Ocean brings together leading tools, languages, and environments to give researchers an end-to-end workflow geared towards reproducibility.\n\n**IBM Watson Studio**-It is a part of IBM.It helps to run and manage AI models, and optimize decisions at scale across any cloud. IBM Watson\u00ae Studio empowers you to operationalize AI anywhere as part of IBM Cloud Pak\u00ae for Data, the IBM data and AI platform.\n\n**Amazon EMR Notebooks**-It is a product of Amazon and is a managed environment based on Jupyter and Jupyter-lab notebooks, enables users to interactively analyze and visualize data, collaborate with peers, and build applications using EMR clusters. \n\n**Google Cloud Datalab Notebooks**- Cloud Datalab Notebbok is an interactive data analysis and machine learning environment designed for GCP. You can use it to explore, analyze, transform, and visualize your data interactively and to build machine learning models from your data.\n\n**Databricks Collaborative Notebooks**- It is a shared and interactive notebooks, experiments, and extended files support allow data scientists teams to organize, share, and manage complex data science projects more effectively throughout the lifecycle. ","b6bb23cd":"### Q35 Tools to help manage machine learning experiments:","5375505b":"Both Colab and kaggle are the superstars for Master Degree and Bachelor Degree people comapred to Doctoral Degree people. People with Phd's use less Notebooks comapred to Master Degree and Bachelor Degree counterparts.\n\nPeople with Master's Degree is seen to use all the notebooks mentioned considerably in a high margin than other Degree holders. Professional Degree holders tend to use less notebooks.\n\nColab is the sureshot winner since they have a little edge in all the Categories compared to Kaggle. DataBricks Collabrative Notebook and Code Ocean seems to be the note book which are least used","71ee85e5":"It is observed that many professionals dont use AutoMl tool. This may be due the fact that they are paid tools and it is used as part of organization mostly.\n\nAmong them AutoSklearn is the preferred tool among all the professionals with highest usage from DataScientist with least usage from Statistician. DataBase Engineer and Statistician tends to use less number of these tools which is due to the fact that these tools are used for Machine Lerning Applications.\n\nMachine Learning Engineer and Data Scientist use most of these Automated ML tools compared to other professionals. The least used tools are MLbox and Xcessiv","91c8cab7":"1.https:\/\/www.kaggle.com\/subinium\/kaggle-2020-visualization-analysis\n\n2.https:\/\/neptune.ai\/blog\/top-12-on-prem-tracking-tools-in-machine-learning\n\n3.https:\/\/www.kaggle.com\/parulpandey\/the-emergence-of-automl\n\n4.https:\/\/analyticsindiamag.com\/10-popular-automl-tools-developers-can-use\/","ed73d31d":"#### Quick overview of the top notebooks that are mentioned in the survey:","49d4afa3":"Let's start from the novice category,Salesforce and Microsoft PowerBI are two BI tools who are in constant race where Salesforce seems to a high edge among this category of ML Practioners than Microsoft PowerBI. Though the different between them is not huge but it is not negligible.The novice Practioners have a say in all the BI tools in a considerable amount compared to other categories.\n\nAs the years of Experince increases the tides are still in favour of Salesforce but the overall percentage of Usage of BI tools in general shrinks gradually.The least used tool among all the categories are  Qlik and Sisense","29fa674e":"#####         Key Takeaways:\n                1. SalesForce and Microsoft PowerBI are the two commonly used Business Intelligence tools \n                \n                2.SalesForce is the topper among all categories across all domains\n                                               \n                3.Qlik and Sisense are the two least popular notebooks across various domains mentioned ","11e08b2f":"Why do we need tools to manage experiments when all that can be done in an IDE? \n\n> ###  **_Those who don't track training are doomed to repeat it._**\n\nTracking the experiments is a key to successful outcome. The tools listed below help in versioning,tracking hyperparameters, data versioning, tracking metrics. They play a major role in model organization process.\n\nThese tools helps to provide a monitoring solution and helps to know thw status of the project to the Team members, Project manager and Stake holders.\n\nLogging the loss and accuracy curves has never been an easy job. We often save these values in arrays or lists and then plot them at the end of the training. Sharing these graphs is even harder where sending screenshots of these graphs seems the only choice\n\n A specialized tool for tracking ML experiments is even more useful for the whole team of data scientists. It allows them to see what others are doing, share the ideas and insights, store experiment metadata, retrieve it at any time and analyze it whenever they need to. It makes the teamwork much more efficient, prevents situations where several people work on the same task, and makes onboarding of new members way easier.","172c8a8b":"Well its observed that approximately on an average 70% of the professionals dont use any of these tools. It is observed that every category of people in the work use Tensorbaord for visualization even DBA Engineers. ML Engineers uses Tensorboard highest (on an of avergae 35 %) followed by Resarch Scientist. Every professional also seems to use Weigths&Biases on average of 8%.\n\nDomino Model Monitor is quite popular among DataAnalyst and Statistician since they provide better dashboard control.\n\nTrains is quite popular among DataScientist,Research Scientist and ML Engineers which is quite obvious as they used the software to store the weights to the server.\n\nApart from Tensorbaord the top two tools used are Weights&Biases and Neptune.ai.\nBusinest Analyst ,Data Analyst,DataEngineer,Statistician and Data Scientist use more of Weights&Biases and Neptune.ai(approximately 4%) where as ML Engineer use Trains and Weights&baises more.\nSoftware Engineers use all three Trains, Weights&Biases and Neptne.ai\nThe least used tools are Polyaxon,Guild.ai,Comet.ml\n","8b835f5b":"###  With respect to Machine Learning Experience","a8402aa4":"An interesting observation to be noted here is persons with some college university without earning a bachelors degree tend to use more Machine learning tools  comapred to Bachelors ,Masters or Doctoral Degree holders.\n\nIts also observed that as the educational qualification increases the more tools are being used with Tensorboard being the highest followed by Weights & Biases and Trains.\n\nThe least used tools are Guild.ai ,Polyaxon and Sacred+OmniBoard","3a8a8fcb":"### References and Acknowledgements","3f87fa81":"As the number of years of education increases the usage of BI tools increases attaining its peak in masters degree while there is a sudden drop in Doctrol Degree. Again SalesForce seems to be the clear winner here followed by Microsoft Power BI,both seems to have highest users in Master's Degree followed by Bachelor's. The least tools are Qlik and Sisense followed by Alteryx","537e59d3":"###  With respect to Machine Learning Experience","edec6d2d":"Intrestingly, the vice-versa of whats seen in the above heatmap Notebook vs ML Experiance is observed here.First lets talk about the professions where Kaggle is the clear winner,it seems that Kaggle is the first choice for Data Analyst, Business Analyst,Statistician,Software Engineer,DataBase Engineer,Project manager  use a lot more Kaggle comapred to Colab (not by a huge margin though and not a nascent one).But this advantage goes down in case of Data Engineer, Data Scientist , Machine Learning Engineer,Resarch Scientist and Students where Colab is the first choice for these professionals.\n\nThe Currently not employed Category also seems to use Kaggle more than Colab which may be due to the fact that they participate in Competitions more but nothing can be said firmly.(Just an hinch!!! :p)\n\n\nStudents  and Beginners are in favour of  Colab  which implies that Colab is beginner friendly and has a upper hand in this category clearly\n\nThough both are owned by Google Inc there seems to be head on head competition and the trends take turn in a couple of years ","09c77c41":"Its clear that both Colab and Kaggle occupy the top spots comapred to Other notebooks available in the Industry. The closest that can compete with them is the Jupyernotebook but both kaggle and Colab are 3times higher in usage compared to Jupyter. Both Colab and Kaggle have conquired this domain with Colab having an upperhand.","101897a1":"**Google Cloud AutoML**- Google's AutoML lets you create customized deep learning models without any knowledge of data science or programming.\n\n**H20 Driverless AI**-. H2O is a fully open-source, distributed in-memory machine learning platform with linear scalability. H2O supports the most widely used statistical & machine learning algorithms, including gradient boosted machines, generalized linear models, deep learning, and many more.\n\n**Databricks AutoML**- Databricks automates various steps of the data science workflow including augmented data preparation, visualization, feature engineering, hyperparameter tuning, model search, and finally automatic model tracking, reproducibility, and deployment, through a combination of native product offerings, partnerships, and custom solutions for a fully controlled and transparent AutoML experience\n\n**DataRobot AutoML**- DataRobot\u2019s Automated Machine Learning product accelerates the productivity of your data science team.It automates the entire data science lifecycle from raw data to value.\n\n**Tpot**- TPOT is an open-source library for performing AutoML in Python. It makes use of the popular Scikit-Learn machine learning library for data transforms and machine learning algorithms and uses a Genetic Programming stochastic global search procedure to efficiently discover a top-performing model pipeline for a given dataset.\n\n**Auto-Keras**- AutoKeras is an open-source library for performing AutoML for deep learning models. The search is performed using so-called Keras models via the TensorFlow tf.keras API.\nIt provides a simple and effective approach for automatically finding top-performing models for a wide range of predictive modeling tasks, including tabular or so-called structured classification and regression datasets.\n\n**Auto-Sklearn**- Auto-Sklearn is an open-source library for performing AutoML in Python. It makes use of the popular Scikit-Learn machine learning library for data transforms and machine learning algorithms and uses a Bayesian Optimization search procedure to efficiently discover a top-performing model pipeline for a given dataset\n\n**Auto_ml**- Auto_ml is designed for production.It automates the whole machine learning process, making it super easy to use for both analytics, and getting real-time predictions in production.\n\n**Xcessiv**- Xcessiv is a web-based application for quick and scalable hyperparameter tuning and stacked ensembling in Python.It effortlessly chooses the base learners and create stacked ensembles.\n\n**MLbox**-MLBox is a  Automated Machine Learning python library. It provides fast reading and distributed data preprocessing\/cleaning\/formatting.It has highly robust feature selection and leak detection methods.\n\n","8f6ed35e":"### Overall Usage  ","b0853e34":"###  With respect to Role in the Indstry","519b727c":" ### Q34 Auto ML Tools ","93120722":"### With respect to Current Role in the Industry","26cc30ba":"\n![tools4.jpg](attachment:tools4.jpg)\n\n\n###  **_You cannot mandate productivity, you must provide the tools to let people become their best\"-Steve Jobs_**\n\n\nIn the last few years the adoption of AI especially Deep Learning and Machine Learning has marked a significant growth in all business domains and all aspects of human life. To make it easier for beginners and non tech people and business to adapt to AI enormous number of tools have been developed to manage machine learning experiments. Knowing which software application to use can mean the difference between creating a racist, sexist bot with a one syllable name and building a fully functioning AI algorithm.\n\nMastering machine learning tools will let you play with the data, train your models, discover new methods, and create your own algorithms.\nMoreover these tools make it easy for any organization to managae workflow. They also help to explain,optimise experiments and models.\n\nSo lets dive in and check which are the tools that rule the AI world!!!\n\n\n\n\n\n","840c27c8":"Though Kaggle and Colab are data science centric platforms,It's observed that for people who have experience less than 1 year in Machine Learning  Kaggle is more popular tha itsr under 1 year seem to use kaggle  competitor Colab .As the experince increase Colab seems to be more popular than Kaggle but a little margin.\n\nPeople with more 10 years of ML Experience too seem to have colab as their favourite notebook comapred to Kaggle. Kaggle seems to have an upper hand with people who dont use machine learning methods which seems to be an peculiar observation.\n \n\nColab seems to the first choice for most people and to be friendly comapred to Kaggle .\nCode Ocean and Amazon EMR notebooks seems to be the less popular notebooks comapred to the rest","9cddd681":"#####         Key Takeaways:\n                1. Though  AutoML tools help developers build scalable models with great ease and minimal domain expertise they are not widely used. \n                \n                2.Auto Keras is the top choice of people across all domains followed by Auto Sklearn\n                \n                3.Beginners and people with less than 3 years of experince tends to use AutoMl tools more\n                \n                4.MLBox and Xcessiv are the two least popular AutoMl tools used across variuos domains mentioned ","e8b8b5dc":"###  With respect to Role in the Indstry","8c8d1936":"#####         Key Takeaways:\n                1. On an average 40% of the people across all domains dont use any Machine Learning Managenent Tools\n                \n                2.Tensorbaord is widely being used across all the domains and by various categories of ML Practioners\n                \n                3.Weights&Biases ,Neptune.ai and Trains are three tools commonly used apart from Tesnorboard\n                \n                4.Guild.ai and Sacred+Omniboard are the two least popular tools across various domains mentioned ","84b7529b":"###  With respect to Role in the Indstry","7732e1e9":"### **Purpose**\n\nThe main objective of this notebook is to give a view of various tools used in the field of Machine Learning and which are the tools widely used. This notebooks provides comparision of the most popular tools used for Machine Learning and Deep Learning experiments based soley on the Eductional Qualification and the role of a person in the  Industry and the Years of Machine Learning experience . These metrcis have been chosen since they help to quantify the popularity of a tool \/ the tool frequently used comapred to other metrics provided. Both these metrics helps in understanding the current business scenario and will help us know where these tools are widely used","d162320d":"#### Quick overview of the top tools that are mentioned in the survey:\n\n**Neptune.ai**- Neptune is the most lightweight experiment management tool for efficient team collaboration and project supervision. It offers a wide range of tracking faetures that can be intergated with most of the frameworks available. They are highly scalabel with highly flexibility.\n\n**Weights & Biases**- Created for Deep learning experiments tracking with good User Interface. They help share the work through major  cloud platforms\n\n**Comet.ml**- It is a self-hosted and cloud-based meta machine learning platform allowing data scientists and teams to track, compare, explain and optimize experiments and models.It works well with existing ML libraries and safeguards IP\n \n**Sacred + Omniboard**- Sacred is open-source software and allows machine learning engineers to configure, organize, log and reproduce experiments.It supports extensive experiment parameters customization options and is easyily integratable\n\n**TensorBoard**- It\u2019s open-source and offers a suite of tools for visualization and debugging of machine learning models.It has a large library of pre-built tracking tools\n \n**Guild.ai**- It\u2019s lightweight and equipped with many useful features that make it easier to run, analyze, optimize and recreate machine learning experiments. Remote training and backup possibility feature is available\n\n**Polyaxon**- It is  a platform that focuses on both, the whole life cycle management of machine learning projects as well as the facilitation of the ML team collaboration.\n \n**Trains**- Trains is designed to track the experiment process and save data to one centralized server.It's an open-source platform that is still in the beta stage, however, it is being constantly developed and upgraded. \n\n**Domino Model Monitor**- DMM creates a \u201csingle pane of glass\u201d to monitor the performance of all models across the entire organization.It establishs a standard for model health metrics across your organization with an interactive dashboard\n \n \n  \n","98e1cd5b":"###  With respect to Machine Learning Experience","100e4d27":"###  With respect to Educational Qualification"}}