{"cell_type":{"ccf712bb":"code","41e56042":"code","3fffe55a":"code","616f8f62":"code","41371241":"code","6d534714":"code","d3210c8d":"code","dc370c0e":"code","96a9b972":"code","1f703a63":"code","58a237e8":"code","4b38cc2c":"code","3e68134b":"code","bd9d450b":"code","197b7ab7":"code","e5ca884a":"code","c9f7ceae":"code","e9608436":"code","39bf5f0e":"code","83c2fe2b":"code","0e2b0199":"code","15bc9265":"code","42ec3c86":"code","7b6845bf":"code","95893682":"code","17cc3c13":"code","213e74c5":"code","0c9b0183":"code","7315bfd6":"code","ec4dc03e":"code","770b0813":"code","30d97193":"code","23be16e2":"code","eb5a43ac":"code","dd973c3b":"code","ac3bd124":"code","765cefad":"code","bdc47050":"code","c141ad4e":"code","a1506af1":"code","fd0f7f9a":"code","002d214d":"code","da332396":"code","d2912b96":"code","ab6aa5db":"code","6cfdc6b6":"code","1cc5f4d0":"code","06d3fbec":"code","1ec1dba9":"code","5f2d95fc":"code","ec144308":"code","6d7531ed":"code","7353c7ea":"markdown","3cee34b7":"markdown","d12fa482":"markdown","994bcf7d":"markdown","8558cae3":"markdown","11563adf":"markdown","a7d872de":"markdown","1865cdc0":"markdown","8eca9555":"markdown","a1ee56f2":"markdown","dddc04ea":"markdown","f6eee1ca":"markdown","639c5ffe":"markdown","47694579":"markdown","50faf954":"markdown","b69b8b09":"markdown","95f74ea1":"markdown","61129b97":"markdown","a1aaef9b":"markdown","55310ae0":"markdown","3f6c9746":"markdown","9135eb92":"markdown","71cdade0":"markdown","f0031eda":"markdown","10aacbdd":"markdown","59a10434":"markdown","d8ce10bf":"markdown","e5917cfd":"markdown","ce268431":"markdown","ef9aa637":"markdown","48ffd210":"markdown","1e11f94b":"markdown","a1ab6061":"markdown","e0ecb389":"markdown","ba7af6b3":"markdown","c66abd77":"markdown","d5ea1bc0":"markdown","147f6389":"markdown","de7ad626":"markdown","64c41c8d":"markdown","eb17f20c":"markdown","580dce52":"markdown","8f090151":"markdown","e3e874d7":"markdown","dd6f11e6":"markdown","63259451":"markdown","778bc1ca":"markdown","30b4d358":"markdown","85364f5d":"markdown","c7964c33":"markdown"},"source":{"ccf712bb":"# standard libaries\nimport os\n\n# sklearn\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\n\n# other\nimport itertools as it\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set()\nfrom IPython.display import display\nfrom xgboost import XGBClassifier\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","41e56042":"X_train_full = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\", index_col='PassengerId')\nX_test_full = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\", index_col='PassengerId')","3fffe55a":"X_train_full.shape","616f8f62":"X_train_full.head()","41371241":"X_train_full.info()","6d534714":"X_train_full.describe()","d3210c8d":"X_train_full.select_dtypes('object').describe()","dc370c0e":"numerical_features = X_train_full.select_dtypes(['int64', 'float64']) \\\n    .drop(['Survived'], axis='columns')\nprint('Numerical cols: %s' % numerical_features.columns.tolist())\n\ncategorical_features = X_train_full.select_dtypes(['object'])\nprint('Categorical cols: %s' % categorical_features.columns.tolist())","96a9b972":"# Check missing values\nmissing = X_train_full.isnull().sum()\nmissing[missing > 0].sort_values(ascending=False)","1f703a63":"print('<Missing values>', end='\\n\\n')\ncagegory_nulls = categorical_features.isnull().sum().sort_values(ascending=False)\nprint(cagegory_nulls)\n\nprint('_' * 40, end='\\n\\n')\n\nprint('<Unique values>', end='\\n\\n')\ncategory_uniques = categorical_features.nunique().sort_values(ascending=False)\nprint(category_uniques)","58a237e8":"X_train_processed = X_train_full.copy()\nX_test_processed = X_test_full.copy()","4b38cc2c":"fig = plt.figure(figsize=(12, 6))\nncols = 3\nnrows = numerical_features.columns.size % ncols\nfor i, cname in enumerate(numerical_features):\n    fig.add_subplot(nrows, ncols, i + 1)\n    sns.distplot(numerical_features[cname].dropna(),\n                 rug=True,\n                 hist=False,\n                 label='UW',\n                 kde_kws={'bw': 0.1})\n    plt.xlabel(cname)\nplt.tight_layout()\nplt.show()","3e68134b":"fig = plt.figure(figsize=(12, 6))\nncols = 3\nnrows = numerical_features.columns.size % ncols\nfor i, cname in enumerate(numerical_features):\n    fig.add_subplot(nrows, ncols, i + 1)\n    sns.boxplot(y=cname,\n                data=numerical_features)\nplt.tight_layout()\nplt.show()","bd9d450b":"fig = plt.figure(figsize=(12, 6))\nncols = 3\nnrows = numerical_features.columns.size % ncols\nfor i, cname in enumerate(numerical_features):\n    fig.add_subplot(nrows, ncols, i + 1)\n    sns.regplot(x=cname,\n                y='Survived',\n                data=X_train_full)\nplt.tight_layout()\nplt.show()","197b7ab7":"plt.figure(figsize=(9, 6))\nplt.title('Correlation among numerical features')\nsns.heatmap(numerical_features.corr(),\n            annot=True,\n            square=True)","e5ca884a":"X_train_full.query('Age > 70').sort_values(by=['Survived', 'Age'], ascending=False)","c9f7ceae":"X_train_processed.drop(X_train_processed.query('Age > 70 and Survived == 1').index, inplace=True)","e9608436":"sns.regplot(x='Fare',\n            y='Survived',\n            data=X_train_full.query('Fare < 500'))","39bf5f0e":"X_train_processed.drop(X_train_processed.query('Fare > 500').index, inplace=True)","83c2fe2b":"fig = plt.figure(figsize=(12, 4.5))\nfor i, threshold in enumerate([9, 5]):\n    fig.add_subplot(1, 2, i + 1)\n    ax = sns.regplot(x='SibSp',\n                     y='Survived',\n                     data=X_train_full.query('SibSp < @threshold'))\n    ax.set_title('SibSp < %d' % threshold)\nplt.tight_layout()\nplt.show()","0e2b0199":"X_train_parch_sibsp = X_train_full.filter(['Survived', 'Parch', 'SibSp'])\nX_train_parch_sibsp['ParchAndSibSp'] = X_train_full['Parch'] + X_train_full['SibSp']\nsns.regplot(x='ParchAndSibSp',\n            y='Survived',\n            data=X_train_parch_sibsp)","15bc9265":"X_train_processed['ParchAndSibSp'] = X_train_processed['Parch'] + X_train_processed['SibSp']\nX_test_processed['ParchAndSibSp'] = X_test_processed['Parch'] + X_test_processed['SibSp']","42ec3c86":"fig = plt.figure(figsize=(12, 3))\nfor i, cname in enumerate(category_uniques[category_uniques < 10].index):\n    fig.add_subplot(1, 3, i + 1)\n    sns.countplot(x=cname,\n                  data=X_train_full,\n                  hue='Survived')\nplt.tight_layout()\nplt.show()","7b6845bf":"X_train_cabin = X_train_full.filter(['Survived', 'Cabin', 'Sex'])\nX_train_cabin['CabinClass'] = X_train_cabin['Cabin'].str.slice(0, 1)\nX_train_cabin.sort_values(by='CabinClass', inplace=True)\n\ndisplay(X_train_cabin['CabinClass'].value_counts())\nsns.countplot(x='CabinClass',\n              data=X_train_cabin.sort_values(by='CabinClass'),\n              hue='Survived')","95893682":"fig = plt.figure(figsize=(9, 3))\nfor i, sex in enumerate(['male', 'female']):\n    fig.add_subplot(1, 2, i + 1)\n    ax = sns.countplot(x='CabinClass',\n                       data=X_train_cabin.query('Sex == @sex').sort_values('CabinClass'),\n                       hue='Survived')\n    ax.set_title(sex)\nplt.show()","17cc3c13":"# def add_cabin_class(df):\n#     df['CabinClass'] = df['Cabin'].str.slice(0, 1)\n#     male = df['Sex'] == 'male'\n#     df.loc[male, 'CabinClass'] = df.loc[male, 'CabinClass'].fillna('C')\n#     female = df['Sex'] == 'female'\n#     df.loc[female, 'CabinClass'] = df.loc[female, 'CabinClass'].fillna('C')\n\n# for df in [X_train_processed, X_test_processed]:\n#     add_cabin_class(df)","213e74c5":"titles = [\n    'Mr.',\n    'Mrs.',\n    'Miss.',\n    'Master.',\n#     'Dr.',\n#     'Rev.'\n]\nX_train_full[~X_train_full['Name'].str.contains('|'.join(titles))]","0c9b0183":"def name_to_title(name):\n    for title in titles:\n        if title in name:\n            return title\n    return np.nan\n\nX_train_title = X_train_full.filter(['Survived', 'Name'])\nX_train_title['Title'] = X_train_title['Name'].apply(name_to_title)\n\nsns.countplot(x='Title',\n              data=X_train_title,\n              hue='Survived')","7315bfd6":"X_train_processed['Title'] = X_train_processed['Name'].apply(name_to_title)\nX_test_processed['Title'] = X_test_processed['Name'].apply(name_to_title)","ec4dc03e":"X_train_processed.groupby(['Sex', 'Title'])['Age'].mean().round()","770b0813":"def fill_nan_age(df):\n    for _index, entry in df.groupby(['Sex', 'Title'])['Age'].mean().round().reset_index().iterrows():\n        sex = entry['Sex']\n        title = entry['Title']\n        avg_age = entry['Age']\n        query = df.query('Sex == @sex and Title == @title')\n        df.loc[query.index, 'Age'] = df.loc[query.index, 'Age'].fillna(avg_age)\n\nfill_nan_age(X_train_processed)\nfill_nan_age(X_test_processed)","30d97193":"# def extract_last_name(name):\n#     if ' (' in name:\n#         return name.split(' (')[0].split(' ')[-1]\n#     if ' \"' in name:\n#         return name.split(' \"')[0].split(' ')[-1]\n#     return name.split(' ')[-1]\n\n# X_train_processed['LastName'] = X_train_processed['Name'].apply(extract_last_name)","23be16e2":"X_train_full['Ticket'].head()","eb5a43ac":"def ticket_to_number(ticket):\n    last = ticket.split(' ')[-1]\n    return int(last) if last.isnumeric() else np.nan\n\nX_train_ticket = X_train_full.filter(['Survived', 'Ticket'])\nX_train_ticket['TicketNum'] = X_train_full['Ticket'].apply(ticket_to_number)\nX_train_ticket.describe()","dd973c3b":"sns.regplot(x='TicketNum',\n            y='Survived',\n            data=X_train_ticket)","ac3bd124":"sns.regplot(x='TicketNum',\n            y='Survived',\n            data=X_train_ticket.query('TicketNum < 3_000_000'))","765cefad":"X_train_processed['TicketNum'] = X_train_processed['Ticket'].apply(ticket_to_number)\nX_test_processed['TicketNum'] = X_test_processed['Ticket'].apply(ticket_to_number)","bdc47050":"def ticket_to_class(ticket):\n    elems = ticket.split(' ')\n    return elems[0] if len(elems) > 1 else np.nan\n\nX_train_ticket_class = X_train_full.filter(['Survived', 'Ticket'])\nX_train_ticket_class['TicketClass'] = X_train_ticket_class['Ticket'].apply(ticket_to_class)","c141ad4e":"plt.figure(figsize=(20, 12))\nplt.xticks(rotation=45)\nsns.countplot(x='TicketClass',\n              data=X_train_ticket_class,\n              hue='Survived')","a1506af1":"# X_train_processed['TicketClass'] = X_train_processed['Ticket'].apply(ticket_to_class)\n# X_test_processed['TicketClass'] = X_test_processed['Ticket'].apply(ticket_to_class)","fd0f7f9a":"numerical_cols = [cname for cname in X_train_processed.select_dtypes(exclude='object') if\n                  cname not in ['Survived', 'Parch', 'SibSp']]\ncategorical_cols = [cname for cname in X_train_processed.select_dtypes('object') if\n                    cname not in ['Name', 'Cabin', 'Ticket', 'Embarked']]\n\ncolumns = numerical_cols + categorical_cols\ncolumns","002d214d":"X_train = X_train_processed[columns]\ny = X_train_processed['Survived']\nX_test = X_test_processed[columns]","da332396":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, numerical_cols),\n    ('cat', categorical_transformer, categorical_cols)\n])","d2912b96":"class Debug(BaseEstimator, TransformerMixin):\n\n    def transform(self, X):\n        print(pd.DataFrame(X).head())\n        print(X.shape)\n        return X\n\n    def fit(self, X, y=None, **fit_params):\n        return self","ab6aa5db":"model = RandomForestClassifier(n_estimators=250,\n                               max_depth=8,\n                               random_state=42)\n\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('selection', SelectKBest(k='all')),\n#     ('debug', Debug()),\n    ('model', model)\n])","6cfdc6b6":"# param_grid = {\n#     'selection__k': [7, 9, 11, 'all'],\n#     'model__n_estimators': [100, 150, 200, 250, 300],\n#     'model__max_depth': [5, 6, 7, 8, 9]\n# }\n# search = GridSearchCV(pipeline, param_grid=param_grid)\n# search.fit(X_train, y)\n\n# display(search.best_score_)\n# display(search.best_params_)","1cc5f4d0":"scores = cross_val_score(pipeline, X_train, y, cv=4, n_jobs=-1)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","06d3fbec":"# X_train_, X_valid, y_train, y_valid = train_test_split(X_train, y,\n#                                                        test_size=0.25,\n#                                                        random_state=42)\n# pipeline.fit(X_train_, y_train)\n# preds_valid = pipeline.predict(X_valid)\n# print('Mean absolute_error: {:.4f}'.format(mean_absolute_error(y_valid, preds_valid)))\n#\n# df_preds_valid = pd.DataFrame(data=preds_valid,\n#                               index=y_valid.index,\n#                               columns=['Survived_Pred'])\n# X_valid.join(y_valid).join(df_preds_valid).query('Survived != Survived_Pred')","1ec1dba9":"pipeline.fit(X_train, y)","5f2d95fc":"encoded_category_cols = (pipeline['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names())\nall_features = numerical_cols + encoded_category_cols.tolist()\nselected_features = list(it.compress(all_features, pipeline['selection'].get_support()))\nimportances = pipeline['model'].feature_importances_\n\nassert len(selected_features) == len(importances), 'Lengths do not match. Got {:d} and{:d}'.format(len(selected_features), len(importances))\n\nfor feature, importance in zip(selected_features, pipeline['model'].feature_importances_):\n    print('{}: {:.2%}'.format(feature, importance))","ec144308":"preds = pipeline.predict(X_test)","6d7531ed":"output = pd.DataFrame({'PassengerId': X_test_processed.index,\n                       'Survived': preds})\noutput.to_csv('submission.csv', index=False)","7353c7ea":"## Name","3cee34b7":"# Predict","d12fa482":"This is the time we fill missing age features with Sex and Title.","994bcf7d":"For `n_estimators` and `max_depth`, I used `GridSearchCV` and found that they generated best score. I also tried to select features with several `k` parameter patterns but they didn't improve score.","8558cae3":"## Ticket Number","11563adf":"Check missing values on numerical features.","a7d872de":"### Correlation between numerical features and Survived","1865cdc0":"For ticket we see two patterns. One is just a number and the another one has something else before number. Either way we can extract numbers so see if they have relation to Survived.","8eca9555":"# Data Visualization and Feature Engineering","a1ee56f2":"From above, we can see Fare and Survived has negative correlation. But seems there are some samples whose fare is quite high. Try to filter out them and see there is any changes.","dddc04ea":"We confirmed that they still have positive correlation. But let's exclude those high fare data so that we can reduce variance.","f6eee1ca":"### Distribution","639c5ffe":"Maybe CabinClass doesn't matter a lot... I tried to add the feature but it didn't improve score. Since Cabin have so many missing values, I didn't find how I should fill them.\nIf you want to try it, active \u2193 code.","47694579":"### Correlation between categorical features and Survived\n\nObviously Sex has significant correlation with Survived.","50faf954":"# Load data","b69b8b09":"As we saw above, Parch and SibSp have positive correlations. But it looks like Parch has positive relation with Survived and SibSp has negative one. When SibSp is greater than four, seems no one survived. So let's see two graphs, one contains all rows and the another one only has SibSp which are less than five.","95f74ea1":"From above, we can see Age and Survived has negative correlation. But seems there are some samples Age are old but they're Survived. Let's look into that.","61129b97":"## Build model","a1aaef9b":"Partition numerical features and categorical features. We will visualize them later.","55310ae0":"Check missing values and number of distinct observations on categorical features.","3f6c9746":"## Numerical Features","9135eb92":"# Submission","71cdade0":"See importance for each feature.","f0031eda":"## Build pre-processor","10aacbdd":"## Age","59a10434":"### Correlation among numerical features\n\nLooks like Parch and SibSp has positive correlation.","d8ce10bf":"## Parch, SibSp","e5917cfd":"`Name` features contain Title. Let's extract it and see if there is any relation with `Survived`. (I didn't come up with the idea. I got it from other Kernels).\n\nAs searching titles with regex, realized that they're mostly `Mr.`, `Mrs.`, `Miiss.` and `Master.`. I also found there are other patterns like `Dr.` or `Rev.`, but they have small numbers and actually they increated variance, I just excluded them from list.","ce268431":"Most features have already filled NaN values so just impute with constant here. I changed strategy to `mean`, `median` and `most_frequent` but didn't see any improvement.","ef9aa637":"It turned out there is only one sample whose age is greater than 70 and survived. Seems that is an outlier. Let's exclude it from training data.","48ffd210":"## Ticket Class\n\nFollowing above, I tried to extract something looking like ticket class but they have many missing values and I didn't figure out how I should handle them, didn't use them as a feature after all.","1e11f94b":"See cross validation score.","a1ab6061":"# Explore data","e0ecb389":"## Fare","ba7af6b3":"Confirmed that actually ticket number have negative relation to Survived. Add them as a new feature.","c66abd77":"## Last Name\n\nI found that some kernels extract last name and use them for training but I didn't quite understand how I use do them effectively so gave up after all...","d5ea1bc0":"## Cabin","147f6389":"If you want to see false positives and false negatives, activate code below.","de7ad626":"The result is quite interesting. Actually SibSp and Survived have positive correlation until SibSp is four, but later they get negative correlation.\nAt least we see positive correlation between Parch and SibSp, let's combine them and create a new feature named `ParchAndSipSp`.","64c41c8d":"# Import libraries","eb17f20c":"## Categorical Features","580dce52":"If you want to try search by yourself, use \u2193 code.","8f090151":"Define a class to debug Pipeline. Refered this page: https:\/\/stackoverflow.com\/questions\/34802465\/sklearn-is-there-any-way-to-debug-pipelines","e3e874d7":"# Run Training and Validation Step","dd6f11e6":"Looks like they have relations. Let's split graph by Sex because, as we saw before, it has big relation with Survived.","63259451":"### Univariate Analysis","778bc1ca":"Seems ticket numbers have negative relation to Survived for some reason. They're some ticket which have extremely big number so try to exclude them and see if any changes.","30b4d358":"This Kernel follows Kaggle's nice micro courses:\n- [Intro to Machine Learning](https:\/\/www.kaggle.com\/learn\/intro-to-machine-learning)\n- [Intermediate Machine Learning](https:\/\/www.kaggle.com\/learn\/intermediate-machine-learning)\n- [Data Visualization](https:\/\/www.kaggle.com\/learn\/data-visualization)\n- [Feature Engineering](https:\/\/www.kaggle.com\/learn\/feature-engineering)\n\nSo I think this helps Data Science beginner somehow :) After all I couldn't reach out 0.8 score but if you have any idea, please leave comments. Any advice will be appreciated!","85364f5d":"Since titles are highly related to Sex, apparently they have relation with Survived as well.","c7964c33":"`Cabin` is composed by `a capital letter + number` so try to extract first letter and see if they have any relation with Survived."}}