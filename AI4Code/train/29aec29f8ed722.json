{"cell_type":{"0f997a3a":"code","eaa5f354":"code","0d3fe897":"code","58a83883":"code","d020cc16":"code","ec89021b":"code","3dbdd3a8":"code","4b71b486":"code","f229e588":"code","033927e6":"code","7770ae45":"code","1c9f5a01":"code","7653195b":"code","56a6cf6d":"code","79ff81df":"code","7eafa802":"code","4b19bb68":"code","09941b2a":"code","2be87a73":"code","32229438":"code","7339d39b":"markdown","d7fb6e31":"markdown","f1f8d349":"markdown","783cdae7":"markdown","05c383a2":"markdown","ec323b34":"markdown","8cf65d92":"markdown","728b7055":"markdown","66b33635":"markdown"},"source":{"0f997a3a":"import pandas as pd \nimport glob\nimport os\nprint(os.listdir(\"..\/input\"))\n\nPATH = \"..\/input\"","eaa5f354":"filenames = glob.glob(os.path.join(PATH, \"*.csv\"))\nprint(filenames)\ndf = pd.concat((pd.read_csv(f) for f in filenames))\nprint(df.shape)\ndf.head()","0d3fe897":"## I'll keep the external id for now. We drop the harvested ID. \ndf.drop(\"harvested_date\",axis=1,inplace=True)","58a83883":"# print(df.external_author_id.nunique()) # 2489\n# df.external_author_id = pd.Categorical(df.external_author_id).codes\n# print(df.external_author_id.nunique())  # # 2490\n\n# # There's a mismatch - unknown where my bug is. Commenting out for now!","d020cc16":"df.shape","ec89021b":"df.dtypes","3dbdd3a8":"df.describe(include=\"all\")","4b71b486":"df.shape[0] - df.drop_duplicates(subset=\"content\").shape[0]","f229e588":"df.drop_duplicates(subset=\"content\",inplace=True)\nprint(\"df without duplicated content:\",df.shape[0])","033927e6":"# how many unique authors?\n# df.author.value_counts().shape[0]\ndf.author.nunique()","7770ae45":"df.author.value_counts().head() # Top authors have tens of thousands of tweets\n# df.author.value_counts(normalize=True).head() # top author are 1-2 % of all tweets ","1c9f5a01":"(df.author.value_counts()<5).sum() # a few hundred with only a few posts","7653195b":"df.language.value_counts()","56a6cf6d":"df_en = df.loc[df.language==\"English\"]\nprint(df_en.shape[0])","79ff81df":"df_en.describe(include=\"all\")","7eafa802":"df = df.loc[df.account_category != \"Unknown\" ]\ndf.account_category.value_counts(normalize=True)","4b19bb68":"df_en.account_category.value_counts()\nprint(\"original Unknown counts (for english only tweets)\")\ndf_en = df_en.loc[df.account_category != \"Unknown\" ]\ndf_en.account_category.value_counts(normalize=True)","09941b2a":"## Model building & text features can go here:","2be87a73":"df.to_csv(\"russianTweet538Election.csv.gz\",index=False,compression=\"gzip\")","32229438":"df_en.sample(frac=0.25).to_csv(\"russianTweet538Election_eng_sample.csv.gz\",index=False,compression=\"gzip\")","7339d39b":"*  Replace the existing external author id number with a shorter one, using pandas categoricals (not  really needed, but it's a tiny bit more mem.efficient, and can save data corruption if opened in excel. Also, I like this minor code snippet).\n    * https:\/\/stackoverflow.com\/questions\/38088652\/pandas-convert-categories-to-numbers : Get categoricals mapping (str_id to int) \n\n* **BUG** - mismatch in # entities, disabling for now. ","d7fb6e31":"## Concatenate the dataframes\n* https:\/\/stackoverflow.com\/questions\/20906474\/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\ndf = pd.concat((pd.read_csv(f) for f in all_files))\n\n> os.path.join(path, \"*.csv\")\n","f1f8d349":"# Export the data","783cdae7":"## Initial EDA on the Russian tweets\n* Data from https:\/\/fivethirtyeight.com\/features\/why-were-sharing-3-million-russian-troll-tweets\/\n    * 538 and the center did a great job at getting, sharing and analyzing the initial data, so this will be just the basic for getting the data into a more amenable form. \n    \n    * In future - I'll add an additional sample of tweets from the same period or in English, to see if we can seperate  the distributions (not just between the groups\/hashtags)","05c383a2":"## Peek at the authors:\n* 2,848 authors\n* Relatively imbalanced (range from tens of thousands to a handful of tweets).\n* Unknown yet if there are  reallymultiple \"writers\" per authors or whether the same writers create content for multiple author.  (beyond the \"external id\" which doesn't necessarily capture the truth).\n    * Would be an interesting problem to practice *author identification* on! ","ec323b34":"### minor EDA\n","8cf65d92":"## 538 defined clusters\/Categories:\n\n* We'll drop the 8th, *\"Unknown\"* cluster (it's also the smallest).\n* we'll run a model (Externally?) to classify between the clusters.\n    * Presumably, 538 made the clusters based on simple word clusters\/topics\/LDA or similar, so this won't be very informative, but it's an easy thing to start with. ","728b7055":"## Let's look at (English) language\n* We may want to keep only English language tweets. (As detected by Twitter's algo presumably)  = A bit of noise. (Note the many tweets that are in very rare languages. More likely they were'nt identified correctly)\n*  Makes it much more relevant for any future \"Identify foreign propaganda\/russian spy\" type models\n\n* Interestingly, Russian is the second most common language! \n    * Would be interesting to leave the Russian tweets in , in future\n* We leave geography alone.","66b33635":"### 20%  duplicated posts!\n\n* A lot of duplicated posts (may be due to retweets or lazyness)\n* Let's drop these for now - it makes author identification\/resharing easier, but it's less interesting to us for some other purposes + makes it to oeasy"}}