{"cell_type":{"4f0532aa":"code","256d0fe2":"code","cbfe261e":"code","5210f615":"code","3fe6de85":"code","1bc4c262":"code","9995c0e8":"code","d5357e6a":"code","9c94d8be":"code","02ea68d2":"code","6ac613ee":"code","e950acdc":"code","a15a9c5c":"code","dd48104c":"code","a4f06588":"code","59aac716":"code","7d2b62ad":"code","b7819ac0":"code","1acb3137":"markdown","ef2b2876":"markdown","cbc8cca6":"markdown","2e10bedc":"markdown","88f93ad2":"markdown","073377a6":"markdown","ffac1a6e":"markdown","1c177470":"markdown","24bb8d85":"markdown","985e62be":"markdown","8c23a0da":"markdown","5d1d7bdd":"markdown","a5c9e575":"markdown","d3dc99f8":"markdown","e71296d2":"markdown","afde8dd9":"markdown"},"source":{"4f0532aa":"import pandas as pd\nimport numpy as np\n\nurl = '..\/input\/habermans-survival-data-set\/haberman.csv'\nlist_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\ndf = pd.read_csv(url, names=list_cols)","256d0fe2":"df.head()","cbfe261e":"df['survival_status'].value_counts()","5210f615":"X = df.drop(['survival_status'], axis=1)\ny = df['survival_status']\n\n# spliting daa\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=21, stratify=y)","3fe6de85":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score,cross_validate\nfrom sklearn.metrics import confusion_matrix, classification_report\nmodel_knn =  KNeighborsClassifier()\nparam_grid = {'n_neighbors':np.arange(5,50), 'weights':['distance','uniform']}\ngscv= GridSearchCV(model_knn,param_grid=param_grid, scoring='roc_auc', cv=5)\n#latih model\ngscv.fit(X,y)","1bc4c262":"gscv.best_params_","9995c0e8":"gscv.best_score_","d5357e6a":"gscv.predict_proba(X_test)","9c94d8be":"gscv.classes_\ngscv.predict_proba(X_test)[:,1]","02ea68d2":"cv_score_1 = cross_validate(model_knn, X,y, scoring='roc_auc', cv=5, return_train_score=True)\ncv_score_2 = cross_val_score(model_knn, X,y, scoring='roc_auc')\ncv_score_1","6ac613ee":"def knn_pred(k):\n  model = KNeighborsClassifier(n_neighbors=k)\n  score = cross_validate(model, X,y, cv=10, return_train_score=True)\n  train_score = score['train_score'].mean()\n  test_score = score['test_score'].mean()\n  return train_score, test_score","e950acdc":"train_scores = []\ntest_scores = []\n\nfor k in range(2,100):\n  train_score, test_score = knn_pred(k)\n  train_scores.append(train_score)\n  test_scores.append(test_score)","a15a9c5c":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(12,8))\n\nax.plot(range(2,100), train_scores, marker='x', label='Train Score', color='g')\nax.plot(range(2,100), test_scores, marker='o', label='Test Score', c='b')\n\nax.set_xlabel('K')\nax.set_ylabel('score')\n\nplt.legend()\nplt.show()","dd48104c":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nmodel_dt = DecisionTreeClassifier()\nparam_grid = {'splitter':['best','random'], 'criterion':['gini','entropy']}\nrscv= RandomizedSearchCV(model_dt,param_distributions=param_grid,n_iter=100,scoring='roc_auc')\n#latih model\nrscv.fit(X,y)","a4f06588":"rscv.best_params_","59aac716":"rscv.predict_proba(X_test)","7d2b62ad":"rscv.classes_\nrscv.predict_proba(X_test)[:,1]","b7819ac0":"cv_score_1_ = cross_validate(model_dt, X,y, scoring='roc_auc', cv=5, return_train_score=True)\ncv_score_2_ = cross_val_score(model_dt, X,y, scoring='roc_auc')\ncv_score_1_","1acb3137":"Prediksi probabilitasi output","ef2b2876":"Mendapatkan hyperparameter terbaik untuk kombinasi hyperparameterMendapatkan","cbc8cca6":"dari visualisasi diatas didapatkan model ini memberikan performa\/skor baik dengan k = 40","2e10bedc":"Menggunakan GridSearchCV untuk hyperparameter tuning dan model selection dan model algoritma KNN sebagai model classifier.\n\nMenggunakan gscv untuk tuning hyperparameter model algoritma KNN dengan n array 5-50 dan weights 'distance' dan 'uniform'.","88f93ad2":"Menampilkan hasil prediksi dimana masing2 adalah nilai probabilitas untuk setiap class label dan urutan label dari hasil prediksi probabilitas.","073377a6":"**Visualisasi score dari K data train dan data test**","ffac1a6e":"**Praktis Model Selection**\n\n1. Bagi kedua data ini menjadi data training dan data test dengan test_size=0.25.\n2. Gunakan algoritma KNN sebagai model classifier.\n3. Gunakan fungsi GridSearchCV untuk hyperparameter tuning dan model selection.\n4. jumlah fold bebas!, gunakan scoring 'roc_auc'\n5. Definisikan kombinasi hyperparameter untuk model selection dengan GridSearchCV. kombinasi Hyperparameter bebas, baca lagi dokumentasi KNN di link berikut https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html untuk memahami lagi jenis2 hyperparameter di algorithma KNN.\n6. Latih model terhadap data training.\n7. Apa hyperparameter terbaik untuk kombinasi hyperparameter kalian?\n8. Berapa score validasi terbaik dari model tersebut?\n9. Prediksi probabilitasi output dari model yang telah di buat terhadap data test. note : gunakan method .predict_proba() untuk menghasilkan output probabilitas\n10. Perhatikan bahwa hasil prediksi ada 2, dimana masing2 adalah nilai probabilitas untuk setiap class label. Ambil nilai probabilitas pasien phositive meninggal dalam waktu kurang dari 5 tahun. note : gunakan bantuan attirubte .classes_ untuk mengetahui urutan label dari hasil prediksi probabilitas.\n11. Berapa nilai score roc_auc untuk data test?\n12. Apakah model anda termasuk baik atau overtting atau underfitting?\n13. Ulangi tahap di atas namun kali ini menggunakan algoritma DecisionTreeClassifier dan kalian bisa menggunakan RandomizedSearchCV apabila process training lama. pelajari algoritma DecisionTreeClassifier di linkberikut : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier\n14. Bandingkan scorenya dengan Algoritma KNN, mana yang lebih baik?","1c177470":"Import dataset","24bb8d85":"Score validasi terbaik","985e62be":"Prediksi probabilitasi output","8c23a0da":"**Model Decision Tree**","5d1d7bdd":"Hyperparameter terbaik untuk kombinasi hyperparameter","a5c9e575":"Menampilkan 5 data teratas","d3dc99f8":"Menghitung value dari kolom 'survival_status'","e71296d2":"Menentukan label dan fitur serta membagi data menjadi data train dan data test","afde8dd9":"Menampilkan hasil prediksi dimana masing2 adalah nilai probabilitas untuk setiap class label dan urutan label dari hasil prediksi probabilitas."}}