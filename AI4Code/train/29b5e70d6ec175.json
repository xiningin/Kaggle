{"cell_type":{"ce5e905d":"code","70f374b6":"code","80518602":"code","f1b1596a":"code","baa82bda":"code","87a46174":"code","f642d603":"code","e5d5a932":"code","3e2242b2":"code","727c2646":"code","003d6cc0":"code","9abca73e":"code","86299d64":"markdown"},"source":{"ce5e905d":"from glob import glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\nfrom sklearn.model_selection import train_test_split","70f374b6":"train_files = sorted(glob(\"\/kaggle\/input\/denoising-dirty-documents-in-32x32-chunks\/new_dataset\/train\/*\")) \ntrain_cleaned_files = sorted(glob(\"\/kaggle\/input\/denoising-dirty-documents-in-32x32-chunks\/new_dataset\/train_cleaned\/*\"))\ntest_files = sorted(glob(\"\/kaggle\/input\/test-pages\/test\/*\"))\nlen(train_files),len(train_cleaned_files), len(test_files)","80518602":"# build the autoencoder\ndef get_model():\n    In = Input(shape=(32,32,1))\n    x = Conv2D(64,(3,3),activation=\"relu\", padding=\"same\")(In)\n    x = MaxPooling2D((2,2), padding=\"same\")(x)\n    x = Conv2D(32,(3,3),activation=\"relu\", padding=\"same\")(x)\n    x = MaxPooling2D((2,2), padding=\"same\")(x)\n    \n    x = Conv2D(32,(3,3),activation=\"relu\", padding=\"same\")(x)\n    x = UpSampling2D((2,2))(x)\n    x = Conv2D(64,(3,3),activation=\"relu\", padding=\"same\")(x)\n    x = UpSampling2D((2,2))(x)\n    Out = Conv2D(1,(3,3),activation=\"sigmoid\", padding=\"same\")(x)\n    \n    model = Model(In,Out)\n    model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")\n    return model\n    ","f1b1596a":"model = get_model()\nmodel.summary()","baa82bda":"X = []\nY = []\n\nfor files in zip(train_files,train_cleaned_files):\n    img = cv2.imread(files[0],cv2.IMREAD_GRAYSCALE)\/255.\n    X.append(img)\n    img = cv2.imread(files[1],cv2.IMREAD_GRAYSCALE)\/255.\n    Y.append(img)\n\nX = np.array(X)\nY = np.array(Y)\n\nprint(X.shape, Y.shape)","87a46174":"X = X.reshape(-1,32,32,1)\nY = Y.reshape(-1,32,32,1)","f642d603":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n","e5d5a932":"model.fit(x_train,y_train, epochs=10, batch_size=16, validation_data=(x_test,y_test))","3e2242b2":"# first we have to load the image in chunks of 32x32\n# for now I just crop the image to fit in 32x32\ndef get_chunks(file):\n    page = cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n    \n    # getting the hight and width of the image, old_page_height and old_page_width\n    oph, opw=page.shape[:2]  \n    \n    # getting new height and width\n    # to fit the chunks in the image use max - (max%32) to get rid of the remaining.\n    # it is a fast solution we can use for now\n    nph, npw = oph-(oph%32),opw-(opw%32) \n    \n    row_chunks=nph\/\/32 # numober of rows\n    col_chunks=npw\/\/32 # number of chunks\n    rc=0 # row counter \n    cc=0 # column counter \n    \n    # the structure is convertible between chunks and the initial image\n    img_chunks = np.ones((row_chunks,col_chunks,32,32,1),dtype=\"float32\")\n    \n    # the paper shredder\n    for row in range(0,nph,32):\n        cc=0\n        for col in range(0,npw,32):\n            nimg = page[row:row+32,col:col+32]\/255.\n            nimg =np.array(nimg).reshape(32,32,1)\n            try:\n                img_chunks[rc,cc]=nimg\n            except:\n                print(rc,cc)\n            cc+=1\n        rc+=1\n    return img_chunks\n\n\ndef show_chunks(chunks):\n    for row in chunks:\n        plt.figure(figsize=(10,10))\n        for i,chunk in enumerate(row):\n            plt.subplot(1,len(row),i+1)\n            plt.imshow(chunk.reshape(32,32),\"gray\")\n            plt.axis(\"OFF\")\n        plt.show()\n\n\n# puting chunks together again \ndef reassemble_chunks(chunks):\n    # getting the page size\n    oph, opw=chunks.shape[0]*32,chunks.shape[1]*32    \n    \n    the_page = np.ones((oph,opw),dtype=\"float32\")\n    \n    for r, row in enumerate(chunks):\n        r=r*32\n        for c, chunk in enumerate(row):\n            c=c*32\n            the_page[r:r+32,c:c+32]=chunk.reshape(32,32)\n            \n    return the_page","727c2646":"img = get_chunks(test_files[1])\npred_chunks = model.predict(img.reshape(-1,32,32,1))\npred_chunks = pred_chunks.reshape(img.shape)\nshow_chunks(pred_chunks)","003d6cc0":"the_page = reassemble_chunks(pred_chunks)\nplt.figure(figsize=(20,20))\nplt.imshow(the_page,\"gray\")\nplt.show()","9abca73e":"for file in test_files[:5]:\n    test_img = cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n    test_chunks = get_chunks(file)\n    \n    plt.figure(figsize=(20,20))\n    plt.subplot(1,2,1)\n    plt.imshow(test_img,\"gray\")\n    \n    pred_chunks = model.predict(test_chunks.reshape(-1,32,32,1))\n    pred_chunks = pred_chunks.reshape(test_chunks.shape)\n    \n    the_page = reassemble_chunks(pred_chunks)\n    \n    plt.subplot(1,2,2)\n    plt.imshow(the_page,\"gray\")\n    plt.show()\n    ","86299d64":"# Denoising dirty Documents in 32x32 chunks\nI tried to use a paper shredder to tear the images into smaller chunks! \nI tore the images into 32x32 images, but now after I trained it and saw the results, I think 64x64 will be much better.\nhere we will have a larger dataset. I used <a href=\"https:\/\/www.kaggle.com\/c\/denoising-dirty-documents\">Denosing dirty documents<\/a> dataset which has 144 half-pages for training. by using the paper shredder I got 26,112 chunks of images for training, which is a larger dataset and your model can be focused on the details.\n<img src=\"https:\/\/media.giphy.com\/media\/l0IyjK57IEerH0xMc\/giphy.gif\">\n"}}