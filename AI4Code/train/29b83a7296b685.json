{"cell_type":{"43940cca":"code","f243aaba":"code","5ce45215":"code","ec6aea57":"code","27dd51f2":"code","fd583b09":"code","0445018a":"code","50a2d345":"code","c02e2f0f":"code","1f1b84ac":"code","2165df16":"code","a3cd4aae":"code","1eeebe02":"code","72eba160":"code","3fa07d18":"code","165b707d":"code","d6b4cc17":"code","421de850":"code","69d65669":"code","995e8533":"code","373c0c95":"code","300b39c6":"code","fe838ffe":"code","e53cd2e6":"code","d32a0f88":"code","fcd4df49":"code","12a578fe":"code","91976087":"code","568ca16e":"code","ba054178":"code","0a18d067":"code","ca6a0b32":"code","54a46fb8":"code","8b8d73db":"markdown","56df1457":"markdown","99d8bea7":"markdown","72f24479":"markdown","ec6db5af":"markdown","4048d6f9":"markdown","f7fb4093":"markdown","c8f16252":"markdown","724216a7":"markdown","842ee733":"markdown","d16cf3a6":"markdown","0b4b8cdc":"markdown","ce9e115d":"markdown","d891337d":"markdown","217a953f":"markdown","6f9c0961":"markdown","24c5d72b":"markdown","99bedde2":"markdown","7c180f4b":"markdown","ebf9e537":"markdown"},"source":{"43940cca":"# importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","f243aaba":"# importing dataset \n\ntrain_df = pd.DataFrame(pd.read_csv('..\/input\/titanic\/train.csv'))\ntest_df = pd.DataFrame(pd.read_csv('..\/input\/titanic\/test.csv'))\nclass_df =  pd.DataFrame(pd.read_csv('..\/input\/titanic\/gender_submission.csv'))","5ce45215":"train_df.head()","ec6aea57":"# showing column wise %ge of NaN values they contains \n\nfor i in train_df.columns:\n  print(i,\"\\t-\\t\", train_df[i].isna().mean()*100)\n","27dd51f2":"train_df = train_df.drop([\"Cabin\"], axis=1)","fd583b09":"train_df['Age'].fillna(train_df['Age'].median(), inplace=True)#filling Nan values of Age\ntrain_df['Embarked'].fillna(train_df['Embarked'].mode(), inplace=True)","0445018a":"train_df.info()","50a2d345":"train_df = train_df.drop([\"PassengerId\", \"Fare\", \"Ticket\", \"Name\"], axis = 1)   #Since PassengerId, Fare, Name, Ticket does not has any role in price prediction","c02e2f0f":"from sklearn.preprocessing import LabelEncoder\n\ncat_col= train_df.drop(train_df.select_dtypes(exclude=['object']), axis=1).columns\nprint(cat_col)\n\nenc1 = LabelEncoder()\ntrain_df[cat_col[0]] = enc1.fit_transform(train_df[cat_col[0]].astype('str'))\n\nenc2 = LabelEncoder()\ntrain_df[cat_col[1]] = enc2.fit_transform(train_df[cat_col[1]].astype('str'))","1f1b84ac":"train_df.head()","2165df16":"train_df.info()","a3cd4aae":"# Pclass\n\nsns.FacetGrid(train_df, col='Survived').map(plt.hist, 'Pclass')","1eeebe02":"# Sex\n\nsns.FacetGrid(train_df, col='Survived').map(plt.hist, 'Sex')","72eba160":"# Age\n\nsns.FacetGrid(train_df, col='Survived').map(plt.hist, 'Age')","3fa07d18":"# SibSp\n\nsns.FacetGrid(train_df, col='Survived').map(plt.hist, 'SibSp')","165b707d":"# Parch\n\nsns.FacetGrid(train_df, col='Survived').map(plt.hist, 'Parch')","d6b4cc17":"# Embarked\n\nsns.FacetGrid(train_df, col='Survived').map(plt.hist, 'Embarked')","421de850":"X = train_df.drop(['Survived'], axis=1)\ny = train_df['Survived']","69d65669":"#now lets split data in test train pairs\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","995e8533":"# model training \n\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()   # Here kernel used is RBF (Radial Basis Function)\nmodel.fit(X_train, y_train)","373c0c95":"y_pred = model.predict(X_test)\n\npred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\npred_df.head()","300b39c6":"#plot\n\nplt.scatter([i for i in range(len(X_test[\"Age\"]))], y_test, color='black')\nplt.plot([i for i in range(len(X_test[\"Age\"]))], y_pred, color='red')\n\nplt.ylabel('Survived')\nplt.xlabel('Passenger')\n\nplt.show()","fe838ffe":"# To check Accuracy\n\nfrom sklearn import metrics\n\n# Generate the roc curve using scikit-learn.\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\nplt.plot(fpr, tpr)\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.show()\n\n# Measure the area under the curve.  The closer to 1, the \"better\" the predictions.\nprint(\"AUC of the predictions: {0}\".format(metrics.auc(fpr, tpr)))\n\n# Measure the Accuracy Score\nprint(\"Accuracy score of the predictions: {0}\".format(metrics.accuracy_score(y_pred, y_test)))","e53cd2e6":"test_df.head()","d32a0f88":"# showing column wise %ge of NaN values they contains \n\nfor i in train_df.columns:\n  print(i,\"\\t-\\t\", train_df[i].isna().mean()*100)\n","fcd4df49":"test_df = test_df.drop([\"Cabin\"], axis=1)\n\ntest_df['Age'].fillna(test_df['Age'].median(), inplace=True) #filling Nan values of Age\ntrain_df['Embarked'].fillna(train_df['Embarked'].mode(), inplace=True)","12a578fe":"test_df.info()","91976087":"PassengerId = test_df[\"PassengerId\"]\n\ntest_df = test_df.drop([\"PassengerId\", \"Fare\", \"Ticket\", \"Name\"], axis = 1)   #Since PassengerId, Fare, Name, Ticket does not has any role in price prediction","568ca16e":"test_df[cat_col[0]] = enc1.transform(test_df[cat_col[0]].astype('str'))\n\ntest_df[cat_col[1]] = enc2.transform(test_df[cat_col[1]].astype('str'))","ba054178":"test_df.head()","0a18d067":"y_test_pred = model.predict(test_df)","ca6a0b32":"#plot\n\nplt.scatter([i for i in range(len(test_df[\"Age\"]))], y_test_pred, color='black')\n\nplt.ylabel('Survived')\nplt.xlabel('Passenger')\n\nplt.show()","54a46fb8":"submission = pd.DataFrame({\n        \"PassengerId\": PassengerId,\n        \"Survived\": y_test_pred\n    })\n\nsubmission.to_csv('.\/submission.csv', index=False)","8b8d73db":"> From above graph we can also infer that :\n   + Most of Pclass 3 were not able to survive.","56df1457":"> From above graph we can also infer that :\n   + Most of passengers travelling from Southampton were not able to survive.","99d8bea7":"> Now let's make predictions for test dataset ","72f24479":"## Titanic Survival Classification","ec6db5af":"> Now lets visualise the relation of columns to our target in order to decide weather to add during classification or not.","4048d6f9":"***","f7fb4093":"> Since we got an AUC score of 0.79 we can say that our classifier is not too good but acceptable. Since accuracy score is 0.81, we can say aour model is 81% accurate.","c8f16252":"> From above gapph we can infer that Parch is  well co-related with our target.Most of passengers are  with either 0, 1 or 2 parents. ","724216a7":"> We can say tha Sex has a fine co-realtion with our target class.","842ee733":"> From above graph we can also infer that :\n   + Most of infants were not survived.\n   + Most of passengers who were not able to survive was of age grp 20-40.\n   + Oldest passenger to survive was in 80's (or of 90) .","d16cf3a6":"> From above gapph we can infer that SibSp is  well co-related with our target. Most of passengers are  with either 0 or 1 sibling\/spouse. ","0b4b8cdc":"> We can say tha age has a fine co-realtion with our target class as its histogram against no of passager as it is not skewd in both the classes. ","ce9e115d":"> Now we can move towards prediction","d891337d":"> We can say tha Pclass has a fine co-realtion with our target class as its histogram against no of passager as it is shows an nice dirtibution of Target class in 3 classes of Pclass.","217a953f":"> From above graph we can also infer that :\n   + Most of passengers travelling alone were survived.","6f9c0961":"> From above graph we can also infer that :\n   + Most of Males were not able to survive\n   + No of Males travelling on ship was greater than that of females\n   + Most of Females were survived as compared to males","24c5d72b":"> We can say tha Embarked has a fine co-realtion with our target class as its histogram against no of passager as it is shows an nice dirtibution of Target class in 3 classes.","99bedde2":"> Let's first encode the categorical data into numerical for futher analysis","7c180f4b":"> From above graph we can also infer that :\n   + Most of passengers travelling alone were survived.","ebf9e537":"> Since Cabin  has very significant no of Nan values , so we can drop it for better results"}}