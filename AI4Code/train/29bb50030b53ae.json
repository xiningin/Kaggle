{"cell_type":{"54c1bb83":"code","e00d684b":"code","672a32d5":"code","e8eabc85":"code","85732250":"code","68214c84":"code","eb63ebd1":"code","297fd792":"code","faf74a51":"code","b6a2b08c":"code","5df12998":"code","5d2469ae":"code","4685432e":"code","555db740":"code","a3a141df":"code","7c2531cc":"code","54c4f384":"code","1aaf45e4":"code","fc383771":"code","8b6e5480":"code","aa8a9b17":"code","3de00754":"code","a10b217b":"code","7a888cd6":"code","ee46acf7":"code","6e0069df":"code","e9040292":"code","253672dc":"code","86e9be00":"code","a80f285c":"code","ca4b9f43":"code","a34a2eda":"code","198fcf8e":"code","e5b7ec29":"code","21e3df06":"code","e73b3748":"code","bae78895":"code","9ac5d26d":"code","6c850290":"code","a0391a2e":"code","38441d68":"code","99d4a04b":"code","24556208":"code","164fc248":"code","66a8ad7b":"code","ff7246ff":"code","f8a8040d":"code","4852986e":"code","46c79baf":"code","6809a757":"code","b80490f9":"code","7ff025d5":"code","e54aea6b":"code","8ee04e4a":"code","add7dc3a":"code","57da54bb":"code","6d7dc4a5":"code","98257c5b":"code","eea97628":"code","06dd94a3":"code","13f02efd":"code","8a22eee9":"code","7c5e6784":"code","36745454":"code","4d882b44":"code","854f09ee":"code","b7a7446c":"markdown","70774b97":"markdown","b15e0d3e":"markdown","051a3eae":"markdown","2f030e73":"markdown","00af4536":"markdown","9f7f37b9":"markdown","93edc8b8":"markdown","83308955":"markdown","321b2f42":"markdown","b2849e0f":"markdown","dd85bdf9":"markdown","afba0c12":"markdown","a4f65bef":"markdown","c0594b17":"markdown","6b416e32":"markdown","9dd0d0ec":"markdown"},"source":{"54c1bb83":"# Set your own project id here\nPROJECT_ID = 'msds498'\nfrom google.cloud import storage\nstorage_client = storage.Client(project=PROJECT_ID)\nfrom google.cloud import bigquery\nclient = bigquery.Client(project=PROJECT_ID)","e00d684b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path, PurePath\nimport pandas as pd\nimport requests\nfrom requests.exceptions import HTTPError, ConnectionError\nfrom ipywidgets import interact\nimport ipywidgets as widgets\nimport re\nfrom ipywidgets import interact\nimport ipywidgets as widgets\nimport pandas as pd\nfrom IPython.display import display\nimport os\nimport json\nimport glob\nfrom tqdm import tqdm\n\n!pip install nltk\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer ","672a32d5":"# upload data and list contents\ninput_dir = '\/kaggle\/input\/CORD-19-research-challenge\/'\nmetadata_path = f'{input_dir}\/metadata.csv'\nmetadata = pd.read_csv(metadata_path,\n                               dtype={'pubmed_id': str,'title': str,'abstract': str})\nmetadata.head()","e8eabc85":"metadata.info()","85732250":"metadata.isnull().sum()\n# sha is the unique id for papers contained in pdf_json folder. There are over 10000 missing values. Likely because \n# they make be referencing to papers contained in pmc_json folder. pmcid is the unique identifier for papers kept in\n# pmc_json folder.","68214c84":"# So how many papers in the metadataset have abstract.\nlen(metadata) - metadata.abstract.isnull().sum()","eb63ebd1":"# Unique paper ids of research papers contained in pdf_json folder\nmetadata.sha.nunique()","297fd792":"# Title of research papers\nmetadata.title.nunique()","faf74a51":"# Number of research papers in pdf json folder \nall_json_pdf = glob.glob(f'{input_dir}\/**\/pdf_json\/*.json',recursive=True)\nlen(all_json_pdf)","b6a2b08c":"# Number of research papers in pmc json folder \nall_json_pmc = glob.glob(f'{input_dir}\/**\/pmc_json\/*.json',recursive=True)\nlen(all_json_pmc)","5df12998":"# Read a file from PMC_JSON FOLDER\n#with open(all_json_pmc[0]) as file:\n#    first_entry = json.load(file)\n#    print(json.dumps(first_entry[:200],indent=4))\n","5d2469ae":"# Read a file from PDF_JSON FOLDER\n#with open(all_json_pdf[0]) as file:\n#    first_entry = json.load(file)\n#    print(json.dumps(first_entry,indent=4))","4685432e":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            self.paper_id = content['paper_id']\n            self.abstract = []\n            self.body_text = []\n            self.abstract = []\n            #Abstract\n            for entry in content['abstract']:\n                self.abstract.append(entry['text'])\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            self.body_text = '\\n'.join(self.body_text)\n    def __repr__(self):\n        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\nfirst_row = FileReader(all_json_pdf[0])\nprint(first_row)","555db740":"dict_ = {'paper_id': [], 'abstract': [],'body_text': []}\nfor idx, entry in enumerate(all_json_pdf):\n    if idx % (len(all_json_pdf) \/\/ 10) == 0:\n        print(f'Processing index: {idx} of {len(all_json_pdf)}')\n    \n    content = FileReader(entry)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['abstract'].append(content.abstract)\n    dict_['body_text'].append(content.body_text)\n\n    \ndf_json_pdf = pd.DataFrame(dict_, columns=['paper_id', 'abstract','body_text'])\ndf_json_pdf.head()","a3a141df":"metadata.columns","7c2531cc":"df_json_pdf.columns","54c4f384":"df = pd.merge(metadata,df_json_pdf,left_on='sha',right_on='paper_id',how='left').drop('paper_id',axis=1)","1aaf45e4":"df.isnull().sum()","fc383771":"# Body text updated to df table from json\n# Total research papers in json folder is around 80744\n# 72000 from 80744 papers have body text from pdf_json folder\ndf.body_text.notnull().sum()","8b6e5480":"len(df)","aa8a9b17":"df.columns","3de00754":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            self.paper_id = content['paper_id']\n            self.body_text = []\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            self.body_text = '\\n'.join(self.body_text)\n    def __repr__(self):\n        return f'{self.paper_id}: ... {self.body_text[:200]}...'\nfirst_row = FileReader(all_json_pmc[0])\nprint(first_row)","a10b217b":"dict_ = {'paper_id': [],'body_text': []}\nfor idx, entry in enumerate(all_json_pmc):\n    if idx % (len(all_json_pmc) \/\/ 10) == 0:\n        print(f'Processing index: {idx} of {len(all_json_pmc)}')\n    \n    content = FileReader(entry)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['body_text'].append(content.body_text)\n\n    \ndf_json_pmc = pd.DataFrame(dict_, columns=['paper_id','body_text'])\ndf_json_pmc.head()","7a888cd6":"# we do not see rows with empty body text. This is good.\ndf_json_pmc[df_json_pmc.body_text == '']","ee46acf7":"# All 58950 papers have body text\ndf_json_pmc.body_text.isnull().sum()","6e0069df":"df_json_pdf.columns","e9040292":"len(df_json_pdf)","253672dc":"df_json_pmc.columns","86e9be00":"len(df_json_pmc)","a80f285c":"metadata.columns","ca4b9f43":"len(metadata)","a34a2eda":"# Merge the original merged dataset with the df_json_pmc dataset\n# left means left outer join\ndf = pd.merge(df,df_json_pmc,left_on='pmcid',right_on='paper_id',how='left').drop('paper_id',axis=1)\nlen(df)","198fcf8e":"# Body text updated to df table from json\n# Total research papers in json folder is around 80744\n# 72000 from 80744 papers have body text from pdf_json folder\ndf.body_text_x.notnull().sum()","e5b7ec29":"# All 58950 papers have body text. Hence \n# 181778 - 58950 = 122828 papers do not have body_text_y\ndf.body_text_y.isnull().sum()","21e3df06":"df.columns","e73b3748":"#Lets compare abstracts from json folder and metadata\n# abstract_x from metadata and abstract_y from pdf_json\ndf[df.abstract_x != df.abstract_y].shape","bae78895":"df[df.abstract_x != df.abstract_y][['abstract_x','abstract_y','url']].tail(20)","9ac5d26d":"# check metadata abstract column to see if null values exist\ndf.abstract_x.isnull().sum(),(df.abstract_x == '').sum()","6c850290":"# Check pdf_json abstract to see if null values exist\ndf.abstract_y.isnull().sum(),(df.abstract_y == '').sum()","a0391a2e":"df.iloc[13:16,18:22]","38441d68":"# Convert all columns to string and then replace abstract_y values to test\n#df = df.astype(str)\ndf[\"abstract_y\"] = df[\"abstract_y\"].astype(str) \ndf['abstract_y'] = np.where(df['abstract_y'].map(len) > 50, df['abstract_y'], \"na\")","99d4a04b":"df[df['abstract_y'].apply(lambda x: len(str(x)) <= 10)]","24556208":"# check metadata abstract column to see if null values exist\ndf.abstract_x.isnull().sum(),(df.abstract_x == '').sum()","164fc248":"# abstract_y values are all filled now. This is what we had expected after the \"na\" treatment\ndf.isnull().sum()","66a8ad7b":"# Over 2000 rows where abstract_x value is null but abstract_y value has data\ndf.loc[df.abstract_x.isnull() & (df.abstract_y != 'na')]","ff7246ff":"# replace abstract_x (metadata column) with abstract_y (pdf_json) value where abstract_x is null\ndf.loc[df.abstract_x.isnull() & (df.abstract_y != 'na'),'abstract_x'] = df[df.abstract_x.isnull() & (df.abstract_y != 'na')].abstract_y","f8a8040d":"# Do we have any remaining null abstract values. Not anymore. This is good.\n# The null values have reduced which is what we had expected.\ndf.abstract_x.isnull().sum()","4852986e":"# the remaining missing values are also empty in json folder\n(df.abstract_x.isnull() & ((df.abstract_y != 'na') | (df.abstract_y != 'na'))).sum()","46c79baf":"# Lets get rid of the pdf_json abstract column and rename the metadata abstract column\ndf.rename(columns = {'abstract_x' : 'abstract'}, inplace = True)\ndf.drop('abstract_y',axis=1,inplace = True)\ndf.columns","6809a757":"# This is expected because body text comes from pdf and pmc folders\n(df.body_text_x != df.body_text_y).sum()","b80490f9":"# check pdf_json body text to see if null values exist\n# # 72000 from 80744 papers have body text from pdf_json folder\n# 181778 - 72000 = 109778 records have null value of body_text_x\ndf.body_text_x.isnull().sum(),(df.body_text_y == '').sum()","7ff025d5":"# This is expected because there are only ~50000 papers in json_pmc\ndf.body_text_y.isnull().sum()","e54aea6b":"# body_text_x is pdf_json. body_text_y comes from pmc_json\n# Where available we use the text from pmc file trusting the statement quality\ndf.body_text_x.isnull().sum(),(df.body_text_y.isnull()).sum()","8ee04e4a":"df.shape","add7dc3a":"(df.body_text_x != df.body_text_y).sum()","57da54bb":"# There are 7000 rows where body_text_x is null but body_text_y is not null\ndf.loc[df.body_text_x.isnull() & df.body_text_y.notnull()]","6d7dc4a5":"df.iloc[1337].body_text_x[:500]","98257c5b":"df.iloc[1337].body_text_y[:500]","eea97628":"df.body_text_x.isnull().sum(),df.body_text_y.isnull().sum()","06dd94a3":"# We are trusting the text from pmc folder to be of higher quality as it contains full text. \n# Hence we will replace with body_text_x with body_text_y where body_text_y exists\ndf.loc[df.body_text_y.notnull(),'body_text_x'] = df.loc[df.body_text_y.notnull(), 'body_text_y']","13f02efd":"# Lets get rid of the pdf_pmc body text column and rename the body text column\ndf.rename(columns = {'body_text_x' : 'body_text'}, inplace = True)\ndf.drop('body_text_y',axis=1,inplace = True)\ndf.columns","8a22eee9":"# Body text null values have now decreased.\ndf.body_text.isnull().sum()","7c5e6784":"df.isnull().sum()","36745454":"df_processed = pd.DataFrame(df)\n# Drop records where title is Null\ndf_processed = df_processed.dropna(axis=0,subset=['title'])\ndf_processed.drop(df_processed.columns[[0,1,2,4,5,6,7,9,10,11,12,13,14,15,16,17,18]],axis=1,inplace=True)\ndf_processed.columns","4d882b44":"df_processed.isnull().sum()","854f09ee":"%env JOBLIB_TEMP_FOLDER=\/tmp\n#df.to_csv('cord19_df_merged.csv',index=False)\ndf_processed.to_csv('cord19_processed.csv',index=False)\ndf_subset = df_processed.sample(frac = 0.05).reset_index(drop=True)\ndf_subset.to_csv('cord19_processed_subset.csv',index=False)","b7a7446c":"**4. Load research data into dataframe**","70774b97":"Since the abstract_x from metadata is more reliable , we will use it but only fill by abstract_y text when abstract_x value is null","b15e0d3e":"**Export to a file**","051a3eae":"PMC_JSON Data table clean up\nThis folder only contains full texts and no abstracts","2f030e73":"**Lets check for duplicates**","00af4536":"**EXPLORATION AND FURTHER CLEAN UP**","9f7f37b9":"pdf_json files contain abstract. pmc_json folder files does not abstract. They contain full texts","93edc8b8":"**Project COVID-19 (498) By Sambit Das:**\nThe goal is to generate meaningful summaries for the COVID-19 research papers.\nPreprocessing steps taken as follows\nData Collection\nResearch paper extraction\nBM25 Search Engine\nQ&A Answer Tool","83308955":"****3. Fetch all JSON Files****\nLets also take a look at the data contained in the JSON Files","321b2f42":"**PDF_JSON Data table clean up**","b2849e0f":"**Compare body text columns**","dd85bdf9":"**Merge metadata and json folder data**","afba0c12":"**2. Download the DataSet**","a4f65bef":"**Compare abstract column and clean**","c0594b17":"Merge df_json_pmc and pdf_json","6b416e32":"**1. **Environment Setup****","9dd0d0ec":"**Merge Metadata , pdf_json and pmc_json data**"}}