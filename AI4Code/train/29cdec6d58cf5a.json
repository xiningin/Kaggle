{"cell_type":{"d93f19fc":"code","435aa400":"code","05ef4bfc":"code","cf614e20":"code","819c9e2b":"code","0c9968b9":"code","fee583eb":"code","5cdd1b50":"code","e95ee48a":"code","6fcb0a85":"code","0d67508b":"code","a95ef21c":"code","9332b3dc":"code","7f96f249":"code","ffa0b4f3":"code","09b7fa78":"code","86feaadb":"code","c474c290":"code","3cb76810":"code","250e751b":"code","6ae285fe":"code","0ca833fe":"code","97a596aa":"code","e3995820":"code","2f27e369":"code","59ef11ab":"code","7410cea6":"code","c4d47546":"code","aa8624a4":"code","c15c1234":"code","3461bc89":"code","1992a562":"code","02adc998":"code","566c0564":"code","e6edd88e":"code","63cb1d33":"code","908f42f5":"code","6e3cfd66":"code","40a6ef70":"code","0ee0b149":"code","4063488f":"code","9b6554a5":"code","51e088f2":"code","b645c67c":"code","66d9c0fa":"code","256e2bcc":"code","d8256f8c":"code","9bce894d":"code","4a433604":"code","0b5a328e":"code","2f25fa05":"code","16c8bdb1":"markdown","de01ed6a":"markdown","fa5f869b":"markdown","fab78621":"markdown","b2710637":"markdown","a1d86634":"markdown","5d2e5475":"markdown","5e1d2ffa":"markdown","477c7fe1":"markdown","b622a627":"markdown","3c0a646a":"markdown","8222ab89":"markdown","2ebf452b":"markdown","d0a08ae6":"markdown","9b56b198":"markdown","198910d8":"markdown","65ce31ea":"markdown","1b1b00db":"markdown","0e089737":"markdown","fefe79ab":"markdown","dc5bbc06":"markdown","93d805a2":"markdown","ba16699f":"markdown"},"source":{"d93f19fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","435aa400":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.metrics import plot_confusion_matrix,classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import KNNImputer\nfrom sklearn.tree import DecisionTreeClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom wordcloud import WordCloud\nfrom matplotlib.colors import ListedColormap","05ef4bfc":"df = pd.read_csv('\/kaggle\/input\/twitter-airline-sentiment\/Tweets.csv')","cf614e20":"def resizeplot(x,y,d):\n    plt.figure(figsize=(x,y),dpi=d)","819c9e2b":"df.head()","0c9968b9":"df.isnull().sum()","fee583eb":"df.info()","5cdd1b50":"imputer = KNNImputer(missing_values=float ,n_neighbors=5,metric='nan_euclidian',weights='uniform')","e95ee48a":"df.columns","6fcb0a85":"df['negativereason'].fillna('unknown',inplace=True)","0d67508b":"df['negativereason_confidence'].mean()","a95ef21c":"df['negativereason_confidence'].unique()","9332b3dc":"df['negativereason_confidence'].fillna(0,inplace=True)","7f96f249":"df['negativereason_confidence'] = imputer.fit_transform(df[['negativereason_confidence']])","ffa0b4f3":"df['airline_sentiment_gold'].unique()","09b7fa78":"df['negativereason_gold'].fillna('unknown',inplace=True)","86feaadb":"df['airline_sentiment_gold'].fillna('unknown',inplace=True)","c474c290":"df['tweet_location'].fillna('unknown',inplace=True)","3cb76810":"df['tweet_coord'].fillna('unknown',inplace=True)","250e751b":"df['user_timezone'].fillna('unknown',inplace=True)","6ae285fe":"df['negativereason_gold'].value_counts()","0ca833fe":"df['airline_sentiment_gold'].value_counts()","97a596aa":"df.isnull().sum()","e3995820":"resizeplot(10,6,90)\nplt.xticks(rotation=70);\nsns.countplot(x='negativereason',data=df)","2f27e369":"resizeplot(10,6,90)\nsns.heatmap(df.corr(),cmap='viridis',annot=True)","59ef11ab":"df.drop('tweet_id',axis=1,inplace=True)","7410cea6":"df.groupby('airline_sentiment').describe().transpose()","c4d47546":"pd.DataFrame(df[['airline_sentiment','airline']].value_counts(),columns=['rated'])","aa8624a4":"resizeplot(10,6,90)\nsns.countplot(x='airline',hue='airline_sentiment',data=df)","c15c1234":"pd.DataFrame(df[['airline_sentiment','tweet_location','airline']].value_counts(),columns=['Rated']).head(30)","3461bc89":"df['tweet_location'].unique()","1992a562":"color_map = ListedColormap(['orange','green','red','magenta'])\ncloud = WordCloud(background_color='black',max_words = 100,colormap=color_map)\nreview = df['negativereason']\ncloud = cloud.generate(str(review))\nplt.figure(figsize=(15,15))\nplt.imshow(cloud)\nplt.axis('off')","02adc998":"data = df[['airline_sentiment','text']]","566c0564":"data","e6edd88e":"X = data['text']\ny = data['airline_sentiment']","63cb1d33":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)","908f42f5":"tfid = TfidfVectorizer(stop_words='english')\n\ntfid.fit(X_train)\n\nX_train_tfid = tfid.transform(X_train)\nX_test_tfid = tfid.transform(X_test)","6e3cfd66":"X_train_tfid","40a6ef70":"#MULTINOMIAL NB\n\nnb = MultinomialNB()\n\nnb.fit(X_train_tfid,y_train)","0ee0b149":"#LOGISTIC REGRESSION\n\n#lr = LogisticRegression(solver='saga',multi_class='ovr',max_iter = 1000)\nlr = LogisticRegression(max_iter = 1000)\nlr.fit(X_train_tfid,y_train)\n\n#penalty = ['l1','l2']\n#l1_ratio = np.linspace(0,10)\n#C = np.logspace(0,10)\n\n#param_grid_lr = {'penalty':penalty,'l1_ratio':l1_ratio,'C':C}\n\n#grid_model = GridSearchCV(lr,param_grid=param_grid_lr,cv=2,verbose=2,n_jobs=-1)","4063488f":"#grid_model.fit(X_train_tfid,y_train)\nlr.fit(X_train_tfid,y_train)","9b6554a5":"#SVC\n\nsvc = SVC()\n\nsvc.fit(X_train_tfid,y_train)\n\n#penalty_svc = ['l1','l2']\n#C_svc = np.logspace(0,10)\n#param_grid_svc = {'penalty':penalty_svc,'loss':['hinge', 'squared_hinge'],\n                  #'C'=C_svc,'multi_class':['ovr'],\n                  #'max_iter':[1000] }\n\n#grid_model_svc = GridSearchCV(rbf_svc,param_grid=param_grid_svc,cv=2,verbose=2,n_jobs=-1)","51e088f2":"#DECISION TREE\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train_tfid,y_train)","b645c67c":"#METRICS FUNCTION\n\ndef report(model):\n    preds =model.predict(X_test_tfid)\n    print(classification_report(y_test,preds))\n    plot_confusion_matrix(model,X_test_tfid,y_test)","66d9c0fa":"#MULTINOMIALNB\n\nreport(nb)","256e2bcc":"#LOGISTIC_REGRESSION_MODEL\n\nreport(lr)","d8256f8c":"#SVC MODEL\n\nreport(svc)","9bce894d":"# DECISION TREE MODEL\n\nreport(dt)","4a433604":"pipe = Pipeline([('tfid',TfidfVectorizer()),('LR',LogisticRegression())])","0b5a328e":"pipe.fit(X,y)","2f25fa05":"pipe.predict(['ok flight'])","16c8bdb1":"**Just a curiosity, let's check the correlation between the features.**","de01ed6a":"**There are other categorical features that has many 'nan' data.**\n**I'll perform a feature engineering filling with 'unknown' data for the best visualization of our analisys.**\n**Check this out.**","fa5f869b":"**Down bellow I did a counting of the airline sentiment based on each airline, let's see how it works.**","fab78621":"**Now the predictions based on the airline sentiment and the text. I used the 4 basics(could used more of course) algorithms of machine learning to do this. For the better results I could use GridSeachCV to take the maximum possibility of the results but will take too long, but the code is commented if you want to test, please be my guest.**","b2710637":"**As we can see, the Logistic Regression was our winner. Let's check the pipeline brings us the prediction of whole data.**","a1d86634":"**Where this tweets came from?**","5d2e5475":"**Let's check statistics of the airline_sentiment.**","5e1d2ffa":"**Good, the 'ok flight' it's on the 'neutral' sentiment.**","477c7fe1":"![three-major-us-airlines-switching-to-sustainable-fuel.jpg](attachment:b9849127-9317-4680-82ad-ab80c603aa00.jpg)","b622a627":"**Bellow, it's a little function to resize the plots.**","3c0a646a":"**Well, as we can see, there is a bunch of nan data. Let's check.**","8222ab89":"**Ok, now we gonna create a imputer to fill the nan data from the float columns.**\n**Remember: Imputation for completing missing values using k-Nearest Neighbors.\nEach sample\u2019s missing values are imputed using the mean value from n_neighbors nearest neighbors found in the training set. Two samples are close if the features that neither is missing are close.**","2ebf452b":"**Well, most of them it's about a negative sentiment. That's worrisome. Let's go on.**","d0a08ae6":"**Good, above none of null data. Let's go on.**","9b56b198":"# Ok guys, that's it for now, if you liked please smash a upvote and if you don't, make a comment. Be safe!","198910d8":"# **Ok, the analisys today will be the sentiment about the airlines tweets all over the America. We know that it's a important rated indicator of the quality service the company is providing to their costumers. And now we gonna find out over a bunch of analisys and predictions how eficient they are according with the tweets of costumers.**","65ce31ea":"**Well, United, Airways and American, the top of 3 worst.But we have Southwest as one of the best.\nLet's visualize this the other way.**","1b1b00db":"**Let's drop the 'tweet_id.**","0e089737":"**I personally don't like the word clouds but let's check anyway. Maybe give us a bad luck if I don't.**","fefe79ab":"**As we can see above, the negative kind of service its a Customer Service Issue in general.**","dc5bbc06":"**Testing the metrics.**","93d805a2":"**Let's see if works.**","ba16699f":" **First, let's import the main libraries.**"}}