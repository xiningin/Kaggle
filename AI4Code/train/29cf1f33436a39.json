{"cell_type":{"873acae5":"code","c50bf2d2":"code","eea6616b":"code","ae33af3f":"code","40c204da":"code","2b7d79a9":"code","134e830b":"code","78e1d564":"code","1f852146":"code","675ab534":"code","c808bce4":"code","63d8cd0c":"code","9de46964":"code","720868bf":"code","9a16c957":"code","eb59687e":"code","2ba0c4ef":"code","f9ccec90":"code","ed91dff7":"code","022f1773":"code","cc4b2eb3":"code","75ba662b":"code","88c58345":"code","a21df9cd":"code","2d7dcc5f":"code","b2fd3c8e":"code","7ee2a0af":"code","c61c7325":"code","d54a759d":"code","d5405b30":"code","12c97339":"code","f0d8cd3e":"code","511b4f19":"code","c54b4d71":"code","18c33430":"code","65755204":"code","cc844549":"code","448801e1":"code","95f5547f":"code","a78a4e25":"code","388cb936":"markdown","119483d8":"markdown","c8d35039":"markdown","ba9e4bb7":"markdown","9f672fed":"markdown","87399ef5":"markdown","eb070ab0":"markdown","6032cf2e":"markdown","6cf654bf":"markdown","20aec24b":"markdown","d18a89ea":"markdown","1512f843":"markdown","b548a659":"markdown"},"source":{"873acae5":"import warnings\nwarnings.filterwarnings(\"ignore\")","c50bf2d2":"from glob import glob\nimport pandas as pd\nfrom pathlib import Path\nimport numpy as np\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn import metrics\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom torchmetrics.functional import accuracy, auroc\nfrom torchmetrics.functional import mean_absolute_error, mean_squared_error\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder","eea6616b":"RANDOM_STATE = 42\nNUM_CLASSES = 98\nMAX_HOURS = 90\nBATCH_SIZE = 128","ae33af3f":"pl.seed_everything(RANDOM_STATE)","40c204da":"class CountBoxes(Dataset):\n    def __init__(self, df, transform=None):\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.num_workers = 2\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        img_id, label = self.df.iloc[index][\"image_id\"], self.df.iloc[index][\"count\"]\n        img_path = f\"..\/input\/count-the-blue-boxes\/train\/train\/{label}\/{label}_{img_id}.png\"\n        image = Image.open(img_path)\n        image = image.convert(\"RGB\")\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","2b7d79a9":"class CountBoxesDataModule(pl.LightningDataModule):\n    def __init__(self, path, batch_size=64, num_workers=4):\n        super().__init__()\n        self.path = Path(path)\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.transform = transforms.Compose(\n            [\n                transforms.Resize(size=(250, 500)),\n                transforms.ToTensor()\n            ]\n        )\n\n    def prepare_data(self):\n        df = pd.read_csv(self.path \/ \"train.csv\")\n        df = df.loc[df[\"count\"] < MAX_HOURS]\n        # making sure it's a stratified split\n        X_train, X_valid, y_train, y_valid = train_test_split(df[\"image_id\"], df[\"count\"], \n                                                              stratify=df[\"count\"], test_size=0.2)\n        train_df = pd.concat([X_train, y_train], axis=1)\n        valid_df = pd.concat([X_valid, y_valid], axis=1)\n        train_df.to_pickle(\"train_df.pkl\")\n        valid_df.to_pickle(\"valid_df.pkl\")\n\n    def setup(self):\n        self.train_df = pd.read_pickle(\"train_df.pkl\")\n        self.valid_df = pd.read_pickle(\"valid_df.pkl\")\n        self.train_transform = self.transform\n        self.valid_transform = self.transform\n\n    def train_dataloader(self):\n        train_dataset = CountBoxes(df=self.train_df, transform=self.train_transform)\n        return DataLoader(train_dataset, batch_size=self.batch_size, \n                          num_workers=self.num_workers, shuffle=True, pin_memory=True)\n\n    def val_dataloader(self):\n        valid_dataset = CountBoxes(df=self.valid_df, transform=self.valid_transform)\n        return DataLoader(valid_dataset, batch_size=self.batch_size, num_workers=self.num_workers,\n                          shuffle=False, pin_memory=True)","134e830b":"datamodule = CountBoxesDataModule(path=\"..\/input\/count-the-blue-boxes\/\", batch_size=BATCH_SIZE)\ndatamodule.prepare_data()\ndatamodule.setup()","78e1d564":"train_dataloader = datamodule.train_dataloader()","1f852146":"images, labels = iter(train_dataloader).next()\nf, ax = plt.subplots(5, 5, figsize=(30, 30))\nfor i in range(5*5):\n    ax[i \/\/ 5, i % 5].imshow(images[i].permute(1, 2, 0))\n    ax[i \/\/ 5, i % 5].axis(\"off\")\n    ax[i \/\/ 5, i % 5].set_title(labels[i], fontdict={\"fontsize\": 20})\nplt.tight_layout()\nplt.show()","675ab534":"valid_dataloader = datamodule.val_dataloader()","c808bce4":"for data in valid_dataloader:\n    images, labels = data\n    f, ax = plt.subplots(5, 5, figsize=(30, 30))\n    for i in range(5*5):\n        ax[i \/\/ 5, i % 5].imshow(images[i].permute(1, 2, 0))\n        ax[i \/\/ 5, i % 5].axis(\"off\")\n        ax[i \/\/ 5, i % 5].set_title(labels[i], fontdict={\"fontsize\": 20})\n    plt.tight_layout()\n    plt.show()\n    break","63d8cd0c":"class CountModel(pl.LightningModule):\n    def __init__(self, input_shape, num_classes, learning_rate=2e-4):\n        super().__init__()\n        \n        # log hyperparameters\n        self.save_hyperparameters()\n        self.num_classes = num_classes\n        self.learning_rate = learning_rate\n        \n        self.conv1 = nn.Conv2d(3, 16, 5, 1)\n        self.conv2 = nn.Conv2d(16, 32, 5, 1)\n        self.conv3 = nn.Conv2d(32, 64, 5, 1)\n        self.conv4 = nn.Conv2d(64, 128, 5, 1)\n\n        self.pool1 = torch.nn.MaxPool2d(2)\n        self.pool2 = torch.nn.MaxPool2d(2)\n        self.pool3 = torch.nn.MaxPool2d(2)\n        \n        n_sizes = self._get_conv_output(input_shape)\n\n        self.fc1 = nn.Linear(n_sizes, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, self.num_classes)\n\n    # returns the size of the output tensor going into Linear layer from the conv block\n    def _get_conv_output(self, shape):\n        batch_size = 1\n        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n\n        output_feat = self._forward_features(input) \n        n_size = output_feat.data.view(batch_size, -1).size(1)\n        return n_size\n        \n    # returns the feature tensor from the conv block\n    def _forward_features(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.pool1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.pool2(x))\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.pool3(x))\n        x = F.relu(self.conv4(x))\n        return x\n\n    # will be used during inference\n    def forward(self, x):\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)    # Flatten in TF\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.log_softmax(self.fc3(x), dim=1)\n        return x\n\n    # logic for a single training step\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.nll_loss(logits, y)\n        \n        # training metrics\n        preds = torch.argmax(logits, dim=1)\n        acc = accuracy(preds, y)\n        mae = mean_absolute_error(preds, y)\n        mse = mean_squared_error(preds, y)\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, logger=True)\n        self.log(\"train_mae\", mae, on_step=True, on_epoch=True, logger=True)\n        self.log(\"train_mse\", mse, on_step=True, on_epoch=True, logger=True)\n        return loss\n\n    # logic for a single validation step\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.nll_loss(logits, y)\n        \n        # training metrics\n        preds = torch.argmax(logits, dim=1)\n        acc = accuracy(preds, y)\n        mae = mean_absolute_error(preds, y)\n        mse = mean_squared_error(preds, y)\n        self.log(\"val_loss\", loss, on_step=True, on_epoch=True)\n        self.log(\"val_acc\", acc, on_step=True, on_epoch=True)\n        self.log(\"val_mae\", mae, on_step=True, on_epoch=True)\n        self.log(\"val_mse\", mse, on_step=True, on_epoch=True)\n        return loss\n\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer","9de46964":"checkpoint_callback = ModelCheckpoint(\n    monitor=\"val_loss\",\n    filename=\"model-{epoch:02d}-{val_loss:.2f}\",\n    save_top_k=1,\n    mode=\"min\",\n)\n\nearly_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=3, verbose=False, mode=\"min\")","720868bf":"model = CountModel((3, 250, 500), NUM_CLASSES)\ntrainer = pl.Trainer(\n    max_epochs=3,\n    progress_bar_refresh_rate=5,\n    gpus=1,\n    callbacks=[checkpoint_callback, early_stop_callback]\n)","9a16c957":"trainer.fit(model, datamodule)","eb59687e":"print(f\"Best Model: {checkpoint_callback.best_model_path}\")\ninference_model = CountModel.load_from_checkpoint(checkpoint_callback.best_model_path)","2ba0c4ef":"inference_model = inference_model.to(\"cuda\")\ninference_model.eval()\ninference_model.freeze()","f9ccec90":"def get_predictions(dataloader):\n    y_preds, y_actuals = [], []\n    for imgs, labels in tqdm(dataloader):\n        logits = inference_model(imgs.to(\"cuda\"))\n        preds = torch.argmax(logits, dim=1)\n        y_actuals.extend(labels.numpy().tolist())\n        y_preds.extend(preds.cpu().detach().numpy().tolist())\n    return y_preds, y_actuals","ed91dff7":"def get_roc_auc_score(y_true, y_pred):\n    classes = np.unique(np.array(y_true))\n    y_true = label_binarize(y_true, classes=classes)\n    y_pred = label_binarize(y_pred, classes=classes)\n    print(y_true.shape ,y_pred.shape)\n    return metrics.roc_auc_score(y_true, y_pred, average=\"macro\", multi_class=\"ovr\")","022f1773":"def print_metrics(stage, y_true, y_pred):\n    auc = get_roc_auc_score(y_true, y_pred)\n    acc = metrics.accuracy_score(y_true, y_pred)\n    mae = metrics.mean_absolute_error(y_true, y_pred)\n    mse = metrics.mean_squared_error(y_true, y_pred)\n    print(f\"{stage} ROC-AUC Score: {auc:.2f}\")\n    print(f\"{stage} Accuracy: {acc:.2f}\")\n    print(f\"{stage} Mean Absolute Error: {mae:.2f}\")\n    print(f\"{stage} Mean Squared Error: {mse:.2f}\")","cc4b2eb3":"valid_dataloader = datamodule.val_dataloader()\ntrain_dataloader = datamodule.train_dataloader()","75ba662b":"valid_pred, valid_act = get_predictions(valid_dataloader)","88c58345":"print_metrics(\"Validation\", valid_pred, valid_act)","a21df9cd":"train_pred, train_act = get_predictions(train_dataloader)","2d7dcc5f":"print_metrics(\"Training\", train_pred, train_act)","b2fd3c8e":"class TestDataset(torch.utils.data.Dataset):\n    def __init__(self, image_paths):\n        self.image_paths = image_paths\n        self.transform = transforms.Compose([\n              transforms.Resize(size=(250, 500)),\n              transforms.ToTensor()\n        ])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_loc = self.image_paths[idx]\n        image = Image.open(img_loc)\n        image = image.convert(\"RGB\")\n        image = self.transform(image)\n        return image","7ee2a0af":"submission = pd.read_csv(\"..\/input\/count-the-blue-boxes\/sample_submission.csv\")\nsubmission[\"image_path\"] = submission[\"image_id\"].apply(lambda x: f\"..\/input\/count-the-blue-boxes\/test\/test\/{x}.png\")","c61c7325":"test_dataset = TestDataset(submission[\"image_path\"].tolist())\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)\nprint(f\"Test Dataset: {len(test_dataset)}\\tTest DataLoader: {len(test_dataloader)}\")","d54a759d":"y_preds = []\nfor imgs in tqdm(test_dataloader):\n    logits = inference_model(imgs.to(\"cuda\"))\n    preds = torch.argmax(logits, dim=1)\n    y_preds.extend(preds.cpu().detach().numpy().tolist())","d5405b30":"submission[\"count\"] = y_preds\nsubmission = submission[[\"image_id\", \"count\"]]\nprint(submission.shape)\nsubmission.head()","12c97339":"submission[\"count\"].describe()","f0d8cd3e":"submission.to_csv(\"submission.csv\", index=False)","511b4f19":"import cv2","c54b4d71":"def plot_random(paths, labels, h=4, w=4, title=\"\"):\n    f, ax = plt.subplots(h, w, figsize=(30, 30))\n    for i in range(h*w):\n        img = cv2.imread(paths[i])\n        ax[i \/\/ h, i % w].imshow(img)\n        ax[i \/\/ h, i % w].axis(\"off\")\n        ax[i \/\/ h, i % w].set_title(labels[i], fontdict={\"fontsize\": 20})\n    plt.tight_layout()\n    f.suptitle(title, fontsize=\"large\", fontweight=\"extra bold\")\n    plt.show()","18c33430":"submission[\"image_path\"] = submission[\"image_id\"].apply(lambda x: f\"..\/input\/count-the-blue-boxes\/test\/test\/{x}.png\")","65755204":"sample = submission.sample(30)\nplot_random(sample[\"image_path\"].tolist(), sample[\"count\"].tolist())","cc844549":"sample = submission.sample(30)\nplot_random(sample[\"image_path\"].tolist(), sample[\"count\"].tolist())","448801e1":"sample = submission.sample(30)\nplot_random(sample[\"image_path\"].tolist(), sample[\"count\"].tolist())","95f5547f":"sample = submission.sample(30)\nplot_random(sample[\"image_path\"].tolist(), sample[\"count\"].tolist())","a78a4e25":"sample = submission.sample(30)\nplot_random(sample[\"image_path\"].tolist(), sample[\"count\"].tolist())","388cb936":"This code occasionally throws multiprocessing-related errors which here is atleast non-fatal","119483d8":"## Submission","c8d35039":"**Training DataLoader Samples**","ba9e4bb7":"## Import Libraries","9f672fed":"## DataModule","87399ef5":"## Callbacks","eb070ab0":"## Inference","6032cf2e":"**Seed Everything**","6cf654bf":"## Random Test Plots","20aec24b":"**Validation DataLoader Plots**","d18a89ea":"## Load the best model\nModel with lowest validation loss","1512f843":"## Model","b548a659":"## Training"}}