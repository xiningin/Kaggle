{"cell_type":{"4030c557":"code","e664b032":"code","5db6d31e":"code","1839fa27":"code","2198ce68":"code","9527927a":"code","68f56b24":"code","0ccb6c2b":"code","ab82c46d":"code","3c2e8a26":"code","7cc15f22":"code","804cfb00":"code","f086791a":"code","982dc20f":"code","0895c255":"markdown","2216d795":"markdown","8f9f3fb1":"markdown","ffd15f49":"markdown","b1ea3a82":"markdown","3eefd70e":"markdown","422f6991":"markdown","4b80c8ff":"markdown","ca734976":"markdown"},"source":{"4030c557":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e664b032":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","5db6d31e":"data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndata.head()","1839fa27":"sns.distplot(data['Time'])","2198ce68":"sns.countplot('Class', data=data)","9527927a":"data.sample(frac=1)\n\nfraud_data = data.loc[data['Class'] == 1]\nnonfraud_data = data.loc[data['Class'] == 0][0: 492]\n\nnormal_distributed = pd.concat([fraud_data, nonfraud_data])","68f56b24":"normal_distributed.head()","0ccb6c2b":"sns.countplot('Class', data=normal_distributed)","ab82c46d":"# Dropping the Class in order it as our labels:\ny = normal_distributed['Class']\nnormal_distributed.drop(['Class'], axis=1, inplace=True)","3c2e8a26":"# Dividing the data into training and test sets:\n\ntrain, test, ytrain, ytest = train_test_split(normal_distributed, y, train_size=0.7, test_size=0.3)\n\ntrain = train.values\ntest = test.values\nytrain = ytrain.values\nytest = ytest.values","7cc15f22":"Model = SVC(random_state=0)","804cfb00":"Model.fit(train, ytrain)","f086791a":"Preds = Model.predict(test)","982dc20f":"print('The accuracy of the Model is:', accuracy_score(ytest, Preds))","0895c255":"I took help of this [notebook](https:\/\/www.kaggle.com\/janiobachmann\/credit-fraud-dealing-with-imbalanced-datasets) by [Janio Martinez](https:\/\/www.kaggle.com\/janiobachmann). I really suggest you to check his out too! \nThank You :)","2216d795":"Prediciting or running the model on data that it has not seen before:\n","8f9f3fb1":"Fitting the model:","ffd15f49":"Lets try to plot the distribution again:","b1ea3a82":"Defining the model:\n","3eefd70e":"As seen above the data is highly imbalalnced so in order to balance it out I'll basically concatenate all the fraudulent transactions\nand equal number of non fraudulent transactions:","422f6991":"Finally the distribution is equal, if we simply used the distribution as it was, it would have been problematic since the algorithms that w euse on it will conclude that there are next to no fraudulent transactions as the fraudulent transactions make up for a very tiny percentage of the data as a whole.","4b80c8ff":"To find its accuracy lets use the accuracy_score:","ca734976":"Thank you for going through my notebook! I hope it helps you :)"}}