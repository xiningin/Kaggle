{"cell_type":{"84b43328":"code","f00ac926":"code","a9e2c292":"code","21ff86e6":"code","73f3a31e":"code","fb2d5b0f":"code","c8f158eb":"code","b523df77":"code","ff19082d":"code","2c5fd04e":"code","8d83601b":"code","681b1b2a":"code","edf59cba":"code","2cd74fe0":"code","d695467c":"code","f01aa8d6":"code","ea324464":"markdown","6678f811":"markdown","10ac528b":"markdown","b218eeda":"markdown","9f8b7682":"markdown"},"source":{"84b43328":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # to plot the images\n\nfrom sklearn.metrics import accuracy_score\n\nimport keras \nfrom keras.callbacks import EarlyStopping, ModelCheckpoint \nfrom keras.layers import Input, Dense, Flatten,Dropout\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.applications.vgg16 import VGG16\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#ici on a import\u00e9 les bibliotheques necessaires","f00ac926":"from keras.datasets import cifar10\n\n(X_train,y_train),(X_test,y_test) = cifar10.load_data()","a9e2c292":"print(X_train.shape)\nprint(y_train.shape)","21ff86e6":"print(X_test.shape)\nprint(y_test.shape)","73f3a31e":"X_train[0]","fb2d5b0f":"y_train","c8f158eb":"# pour voir le nombre des classes ou des categories\nno_of_classes = len(np.unique(y_train))\nno_of_classes","b523df77":"y_train_ohe=keras.utils.to_categorical(y_train,no_of_classes)\ny_test_ohe=keras.utils.to_categorical(y_test,no_of_classes)","ff19082d":"#temps de redimensionner de sorte que toutes les valeurs de pixels se situent entre 0 et 1\nX_test = X_test.astype('float32')\n\nX_train=(X_train\/255)\nX_test=(X_test\/255)","2c5fd04e":"X_train[0]","8d83601b":"Input_shape = X_train.shape[1:]\nInput_shape","681b1b2a":"# maintenant on va visualiser les 25 premi\u00e8res images de l'ensemble d'entra\u00eenement\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(25,5))\nfor i in range(25):\n    ax = fig.add_subplot(5,10,i+1)\n    ax.imshow(np.squeeze(X_train[i]))","edf59cba":"def create_cnn_model():\n    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n    \n    #Create your own input format\n    keras_input = Input(shape = Input_shape, name = 'image_input')\n    \n   #Utilisez le mod\u00e8le g\u00e9n\u00e9r\u00e9 #Utilisez le mod\u00e8le g\u00e9n\u00e9r\u00e9\n    output_vgg16_conv = model_vgg16_conv(keras_input)\n    \n    #Ajoutez les couches enti\u00e8rement connect\u00e9es \n    x = Flatten(name='flatten')(output_vgg16_conv)\n    x = Dropout(0.3)(x)\n    x = Dense(128, activation=\"relu\", name='fc1')(x)\n    x = Dense(64, activation=\"relu\", name='fc2')(x)\n    x = Dense(10, activation='softmax', name='predictions')(x) \n    model = Model( keras_input, x )\n    return model\n\nmodel = create_cnn_model()\nmodel.summary()","2cd74fe0":"datagen = ImageDataGenerator(\n    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","d695467c":"model.compile( loss='categorical_crossentropy' , optimizer=Adam(), metrics=['accuracy']) #Configuration du mod\u00e8le pour la formation \u00e0 l'aide de la compilation\n    \nes = EarlyStopping(patience=10, monitor='val_accuracy', mode='max') #Arr\u00eatez l'entra\u00eenement lorsqu'une quantit\u00e9 surveill\u00e9e a cess\u00e9 de s'am\u00e9liorer.\n#Enregistrez le mod\u00e8le apr\u00e8s chaque \u00e9poque.\n#le dernier meilleur mod\u00e8le en fonction de la quantit\u00e9 surveill\u00e9e ne sera pas \u00e9cras\u00e9.\nmc = ModelCheckpoint('.\/weights.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n    \n#Forme le mod\u00e8le sur les donn\u00e9es g\u00e9n\u00e9r\u00e9es lot par lot par un g\u00e9n\u00e9rateur Python (ou une instance de Sequence).  \nmodel.fit_generator(datagen.flow(X_train, y_train_ohe), steps_per_epoch=50000\/32, validation_data=[X_test, y_test_ohe], callbacks = [es,mc], epochs=1000)\n    \nmodel.load_weights('.\/weights.h5')#nous chargeons les meilleurs poids enregistr\u00e9s par le ModelCheckpoint\n#On charge les meilleurs poids sauvegard\u00e9s par le ModelCheckpoint\n\n#pr\u00e9dire le test\npreds = model.predict(X_test)\ntest = model.evaluate(X_test,y_test_ohe)\nscore_test = accuracy_score( y_test, np.argmax(preds, axis=1) )\nprint (' LE SCORE DE TEST : ', score_test)\n\n","f01aa8d6":"preds_classes = np.argmax(preds,axis=-1)\nL=7\nW=7\nfig,axes=plt.subplots(L,W,figsize=(12,12))\naxes=axes.ravel()\n\nfor i in np.arange(0,L*W):\n    axes[i].imshow(X_test[i])\n    axes[i].set_title('Prediction= {}\\nTrue={}'.format(preds_classes[i],y_test[i]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","ea324464":"donc on va cr\u00e9er maintenant le modele vgg.","6678f811":"visualisation des donn\u00e9es de test","10ac528b":"On va charger la bibliotheque de Cifar10 qui se trouve dans Keras\n","b218eeda":"1. lancer les donn\u00e9es pour qu'elles deviennent float\n2. normaliser les donn\u00e9es","9f8b7682":"Conversion du vecteur de classe (entiers) en matrice de classe binaire. (Un encodage \u00e0 chaud)"}}