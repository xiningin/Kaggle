{"cell_type":{"ea0ae61d":"code","9940fe46":"code","006c5da0":"code","78e0073c":"code","38e3c77b":"code","e98f3ff6":"code","47116697":"code","1723f2aa":"code","56560cda":"code","49ea8663":"code","7ed6c78d":"code","1e292495":"code","265f5040":"code","cf04a9fb":"code","8f8015fa":"code","1c66e623":"code","195f9c67":"code","a5e4bd1c":"code","050874c2":"code","abebdd30":"code","84ddc44b":"code","c010fe9c":"code","377b9c0f":"code","fce67a13":"markdown","4fce1fe9":"markdown"},"source":{"ea0ae61d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport spacy\nnlp = spacy.load('en')\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","9940fe46":"# Read data out into pandas dataframes\nraw_data_df = pd.read_csv('\/kaggle\/input\/goodreads-10k-dataset-integrated\/books_updated.csv')\n# we will take only the original tite, and tags column\ncolumns = ['original_title', 'tag_name']\ndf = raw_data_df[columns].copy()\n# we will remove any rows which have nan values or empty strings in the original title or tag names\ndf['original_title'].replace('', np.nan, inplace=True)\ndf['tag_name'].replace('', np.nan, inplace=True)\ndf.dropna(inplace=True) \ndf.head()","006c5da0":"# Get unique tag values\nunique_tags = [val.strip() for sublist in df['tag_name'].dropna().str.split(\",\").tolist() for val in sublist]\nprint(f'No. of unique tags {len(unique_tags)}, first 10 entries {unique_tags[0:10]}')\n# print count for each unique tag\ntags_summary = pd.DataFrame(unique_tags,columns=['tag_name']).value_counts().reset_index().rename(columns={0:'count'})","78e0073c":"tags_summary[0:5]","38e3c77b":"# test = pd.DataFrame(unique_tags,columns=['tag_name'])\n# sns.countplot(x='tag_name',data=test[0:50])\n","e98f3ff6":"# We need to remove those that are not genres such as audio, toread etc 'fiction', 'fantasy', 'nonfiction',\nto_remove = ['library','audio', 'books', 'audiobook', 'read', 'tobuy', 'ebook', 'ya', 'ownedbooks', 'default', 'readin', 'kindle', 'bookclub', 'series', 'booksiown', 'owned', 'currentlyreading', 'favourites', 'favorites', 'ebooks', 'childrens', 'toread', 'audiobooks']\n# ya here I will assume is young adult and merge, same for childrens and children\nindex_names = []\nfor tag in to_remove:\n    indexes = (tags_summary[tags_summary['tag_name'] == tag ].index)\n    for index in indexes:\n        index_names.append(index)\n\ntags_summary.drop(index_names, inplace = True)\ngenres_as_list = tags_summary['tag_name'][0:30].tolist()\nprint(genres_as_list)","47116697":"plt.figure(figsize=(30,4))\nplt.bar('tag_name', 'count', data=tags_summary[50:150])\nplt.xticks(rotation=90)\nplt.show()","1723f2aa":"# Now we can create a column for each genre and then assign a value if the book has been tagged as that genre\nfor genre in genres_as_list:\n    \n    df[genre] = df['tag_name'].map(lambda x: 1 if (genre in x) else 0)","56560cda":"# great now we can remove the tag name column\ndf.drop(['tag_name'], axis=1, inplace=True)\n\ndf.head()","49ea8663":"def load_data(df, split=0.9):\n    \n    # Shuffle data\n    train_data = df.sample(frac=1, random_state=7)\n    \n    texts = train_data['original_title']\n    y = train_data.drop(['original_title'], axis=1) # this leaves us with all the other columns\n    labels = y.to_dict('records')\n    split = int(len(train_data) * split)\n    \n    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n    \n    return texts[:split], train_labels, texts[split:], val_labels","7ed6c78d":"train_texts, train_labels, val_texts, val_labels = load_data(df)","1e292495":"print('Texts from training data\\n------')\nprint(train_texts[:2])\nprint('\\nLabels from training data\\n------')\nprint(train_labels[:2])","265f5040":"# Create the TextCategorizer with exclusive classes and \"bow\" architecture\ntextcat = nlp.create_pipe(\n              \"textcat\",\n              config={\n                \"architecture\": \"bow\"})\n\n# Add the TextCategorizer to the empty model\nnlp.add_pipe(textcat)","cf04a9fb":"# Add labels to text classifier\nfor genre in genres_as_list:\n    textcat.add_label(genre)","8f8015fa":"from spacy.util import minibatch\nimport random\n\ndef train(model, train_data, optimizer):\n    losses = {}\n    random.seed(1)\n    random.shuffle(train_data)\n    \n    batches = minibatch(train_data, size=8)\n    for batch in batches:\n        # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n        # Split batch into texts and labels\n        texts, labels = zip(*batch)\n        \n        # Update model with texts and labels\n        model.update(texts, labels, sgd=optimizer, losses=losses)\n        \n    return losses","1c66e623":"# Fix seed for reproducibility\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\n\n# This may take a while to run!\noptimizer = nlp.begin_training()\ntrain_data = list(zip(train_texts, train_labels))\nlosses = train(nlp, train_data, optimizer)\nprint(losses['textcat'])","195f9c67":"text = \"The girl with the dragon tattoo\"\ndoc = nlp(text)\nprint(doc.cats)","a5e4bd1c":"def predict(nlp, texts): \n    # Use the model's tokenizer to tokenize each input text\n    docs = [nlp.tokenizer(text) for text in texts]\n    \n    # Use textcat to get the scores for each doc\n    textcat = nlp.get_pipe('textcat')\n    scores, _ = textcat.predict(docs)\n    # From the scores, find the class with the highest score\/probability\n    predicted_class = scores.argmax(axis=1)\n    \n    return predicted_class","050874c2":"texts = val_texts[34:38]\npredictions = predict(nlp, texts)\n\nfor p, t in zip(predictions, texts):\n    print(f\"{textcat.labels[p]}: {t} \\n\")","abebdd30":"texts = val_texts\npredictions = predict(nlp, texts)\n\ntrue_classes = [max(each['cats'], key=each['cats'].get) for each in val_labels] # this only takes one of the genres (the first on with 1)\n\ndef get_accuracry(predictions, true_classes):\n    correct_predictions = []\n\n    for p, c in zip(predictions, true_classes):\n        if textcat.labels[p] == c:\n            correct_predictions.append(1)\n        else:\n            correct_predictions.append(0)\n    \n    return sum(correct_predictions) \/ len(correct_predictions)\n\n\nprint(f'Accuracy: {get_accuracry(predictions, true_classes)}')","84ddc44b":"def evaluate(model, texts, labels):\n    \"\"\" Returns the accuracy of a TextCategorizer model. \n    \n        Arguments\n        ---------\n        model: ScaPy model with a TextCategorizer\n        texts: Text samples, from load_data function\n        labels: True labels, from load_data function\n    \n    \"\"\"\n    # Get predictions from textcat model (using your predict method)\n    predicted_class = predict(model, texts)\n    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n    # true_class = [max(each['cats'], key=each['cats'].get) for each in labels]\n    true_class = []\n    for label in labels:\n        true_classes_per_label = []\n        for cat in label['cats']:\n            if label['cats'][cat] == 1:\n                true_classes_per_label.append(cat)\n        true_class.append(true_classes_per_label)\n            \n    # A boolean or int array indicating correct predictions\n    correct_predictions = []\n    for p, c in zip(predicted_class, true_class):\n        correct_predictions.append(textcat.labels[p] in c)\n        \n    # The accuracy, number of correct predictions divided by all predictions\n    accuracy = sum(correct_predictions) \/ len(correct_predictions)\n    \n    return accuracy","c010fe9c":"accuracy = evaluate(nlp, val_texts, val_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")","377b9c0f":"# doc = nlp(train_texts[0])\n\n# print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\n# print(\"-\"*40)\n# for token in doc:\n#     print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")","fce67a13":"Can we with some degree of acuracy predict which category or genre a book is from the title alone?","4fce1fe9":"TODO: clean rows that do not match**** any of the categories"}}