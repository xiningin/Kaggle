{"cell_type":{"a2e789f6":"code","8e7f26aa":"code","c8a031c5":"code","6a9b59b5":"code","09958f74":"code","a04b51b8":"code","6b4068eb":"code","6417f103":"code","07e3f1cc":"code","d3035d46":"code","d3d8a58b":"markdown"},"source":{"a2e789f6":"! pip install -U tokenizers","8e7f26aa":"!pip install tensorflow==1.15","c8a031c5":"import tokenizers","6a9b59b5":"bwpt = tokenizers.BertWordPieceTokenizer(\n    vocab_file=None,\n    add_special_tokens=True,\n    unk_token='[UNK]',\n    sep_token='[SEP]',\n    cls_token='[CLS]',\n    clean_text=True,\n    handle_chinese_chars=True,\n    strip_accents=True,\n    lowercase=True,\n    wordpieces_prefix='##'\n)","09958f74":"bwpt.train(\n    files=[\"..\/input\/hindi-oscar-corpus\/hi_dedup_1000.txt\"],\n    vocab_size=30000,\n    min_frequency=3,\n    limit_alphabet=1000,\n    special_tokens=['[PAD]', '[UNK]', '[CLS]', '[MASK]', '[SEP]']\n)","a04b51b8":"bwpt.save(\"\/kaggle\/working\/\", \"hindi\")","6b4068eb":"cd ..\/input\/bertsrc\/","6417f103":"!ls","07e3f1cc":"!python create_pretraining_data.py \\\n    --input_file=\/kaggle\/input\/hindi-oscar-corpus\/hi_dedup_1000.txt \\\n    --output_file=\/kaggle\/working\/tf_examples.tfrecord \\\n    --vocab_file=\/kaggle\/working\/hindi-vocab.txt \\\n    --do_lower_case=True \\\n    --max_seq_length=128 \\\n    --max_predictions_per_seq=20 \\\n    --masked_lm_prob=0.15 \\\n    --random_seed=42 \\\n    --dupe_factor=5","d3035d46":"!python run_pretraining.py \\\n    --input_file=gs:\/\/tf-lang-model\/*.tfrecord \\\n    --output_dir=gs:\/\/tf-lang-model\/model\/ \\\n    --do_train=True \\\n    --do_eval=True \\\n    --bert_config_file=\/kaggle\/input\/bert-base-uncased\/config.json \\\n    --train_batch_size=32 \\\n    --max_seq_length=128 \\\n    --max_predictions_per_seq=20 \\\n    --num_train_steps=20 \\\n    --num_warmup_steps=10 \\\n    --learning_rate=2e-5 \\\n    --use_tpu=True \\\n    --tpu_name=$TPU_NAME","d3d8a58b":"#### In this kernel, I will show you how to train language models, such as BERT, from scratch on TPUs!\n\n#### If you like this kernel, consider upvoting it and the associated datasets:\n\n- https:\/\/www.kaggle.com\/abhishek\/bert-master\n- https:\/\/www.kaggle.com\/abhishek\/hindi-oscar-corpus\n- https:\/\/www.kaggle.com\/abhishek\/bert-base-uncased"}}