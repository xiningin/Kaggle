{"cell_type":{"7295fe9e":"code","38f7f4f2":"code","439411ea":"code","2ef3f6df":"code","82cda2ab":"code","38426127":"code","d2d6aaa9":"code","b385fe3e":"code","8ba81df7":"code","c41b1e37":"code","3da079ef":"code","4d907543":"code","6628b41d":"code","c9c1ddc2":"code","8296f0d3":"code","9205019a":"code","eb245689":"code","acfd452c":"code","fc7fa639":"code","4b417e26":"code","762485c0":"code","1866fa88":"code","9da0ebda":"code","5a64975e":"code","a7276605":"code","53b3f133":"code","2ca2b9b2":"code","5e18f016":"code","335a16bb":"code","c35e9e11":"code","faafd459":"code","139a5265":"code","f362d2ff":"code","727cab6b":"code","be74fb27":"code","36144da4":"code","cfa39c68":"code","89db11c4":"code","7796c532":"code","03d947d7":"markdown","76c0fe76":"markdown","b0266d79":"markdown","b7c7b1cb":"markdown"},"source":{"7295fe9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","38f7f4f2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nsns.set()","439411ea":"train = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","2ef3f6df":"train.head()","82cda2ab":"test.head()","38426127":"train.shape","d2d6aaa9":"test.shape","b385fe3e":"training_array = np.array(train,dtype='float32')","8ba81df7":"testing_array = np.array(test,dtype = 'float32')","c41b1e37":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","3da079ef":"i = random.randint(1,60000)\nplt.figure()\nplt.imshow(training_array[i,1:].reshape(28,28))\nplt.grid(False)\nplt.show()\nlabel = int(training_array[i,0])\nprint(f'The image is for : {class_names[label]}')","4d907543":"W_grid = 15\nL_grid = 15\n\n# subplot return the figure and axes object\n# And by using axes object we can plot specific figure at various location\nfig , axes = plt.subplots(L_grid,W_grid,figsize=(17,17))  \naxes = axes.ravel()          #Flaten the 15 * 15 matrix into 255 array \n\n\nn_training = len(training_array)  #get the length of training dataset\n\n\nfor i in np.arange(0,L_grid*W_grid):\n    \n    index = np.random.randint(0,n_training)\n    axes[i].imshow(training_array[index,1:].reshape(28,28))\n    axes[i].set_title(class_names[int(training_array[index,0])],fontsize=8)\n    axes[i].axis('off')\n    \n    \nplt.subplots_adjust(hspace=0.4)","6628b41d":"X_train = training_array[:,1:]\/255\ny_train = training_array[:,0]","c9c1ddc2":"X_test = testing_array[:,1:]\/255\ny_test = testing_array[:,0]","8296f0d3":"from sklearn.model_selection import train_test_split","9205019a":"X_train ,X_validate , y_train,y_validate = train_test_split(X_train,y_train,test_size = 0.2,random_state = 12345)","eb245689":"X_train = X_train.reshape(X_train.shape[0],28,28,1)\nX_test = X_test.reshape(X_test.shape[0],28,28,1)\nX_validate = X_validate.reshape(X_validate.shape[0],28,28,1)","acfd452c":"print(f'shape of X train : {X_train.shape}')\nprint(f'shape of X test : {X_test.shape}')\nprint(f'shape of X validate : {X_validate.shape}')","fc7fa639":"print(f'shape of y train : {y_train.shape}')\nprint(f'shape of y test : {y_test.shape}')\nprint(f'shape of y validate : {y_validate.shape}')","4b417e26":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import MaxPool2D,Flatten,Dense\nfrom tensorflow.keras.callbacks import EarlyStopping,TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical","762485c0":"y_cat_train = to_categorical(y_train,num_classes=10)\ny_cat_test = to_categorical(y_test,num_classes=10)\ny_cat_validate = to_categorical(y_validate,num_classes=10)","1866fa88":"print(f'shape of y train : {y_cat_train.shape}')\nprint(f'shape of y test : {y_cat_test.shape}')\nprint(f'shape of y validate : {y_cat_validate.shape}')","9da0ebda":"model = Sequential()\n\n# CONVOLUTIONAL LAYER\nmodel.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(28, 28, 1), activation='relu',))\n# POOLING LAYER\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# FLATTEN IMAGES FROM 28 by 28 to 764 BEFORE FINAL LAYER\nmodel.add(Flatten())\n\n# 128 NEURONS IN DENSE HIDDEN LAYER (YOU CAN CHANGE THIS NUMBER OF NEURONS)\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dropout(0.5))\n\n# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES\nmodel.add(Dense(10, activation='softmax'))\n\n# https:\/\/keras.io\/metrics\/\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy']) # we can add in additional metrics https:\/\/keras.io\/metrics\/","5a64975e":"model.summary()","a7276605":"early_stopping = EarlyStopping(monitor='val_loss',patience=1)","53b3f133":"model.fit(X_train,\n         y_cat_train,\n         epochs=50,\n          verbose=1,\n         validation_data=(X_validate,y_cat_validate),\n         callbacks=[early_stopping])","2ca2b9b2":"model_history = pd.DataFrame(model.history.history)","5e18f016":"model_history","335a16bb":"model_history[['accuracy','val_accuracy']].plot()","c35e9e11":"model_history[['loss','val_loss']].plot()","faafd459":"evalution = model.evaluate(X_test,y_cat_test)\nprint(f'Test Accuracy : {evalution[1]}')","139a5265":"predict_class = model.predict_classes(X_test)","f362d2ff":"predict_class.shape","727cab6b":"i = random.randint(0,predict_class.shape[0])\nprint(class_names[predict_class[i]])\nprint(class_names[int(y_test[i])])","be74fb27":"w_gird = 5\nl_gird = 5\n\nfig,axes = plt.subplots(l_gird,w_gird,figsize=(12,12))\n\naxes = axes.ravel()\n\nfor i in np.arange(0,l_gird*w_gird):\n    axes[i].imshow(X_test[i].reshape(28,28))\n    axes[i].set_title(f'{i}.Predict Class : {class_names[predict_class[i]]} \\n True Class : {class_names[int(y_test[i])]}')\n    axes[i].axis('off')\n    \nplt.subplots_adjust(wspace=0.9,hspace=0.7)","36144da4":"from sklearn.metrics import confusion_matrix","cfa39c68":"cm = confusion_matrix(y_test,predict_class)","89db11c4":"fig = plt.figure(figsize=(12,12))\nsns.heatmap(cm,annot=True,cmap='viridis',fmt='d')","7796c532":"from sklearn.metrics import classification_report\n\nnum_classes = 10\ntarget_names = ['Class {}'.format(i) for i in range(num_classes)]\n\nprint(classification_report(y_test,predict_class,target_names=target_names))","03d947d7":"Loading the dataset returns four NumPy arrays:\n\n* The `train_images` and `train_labels` arrays are the *training set*\u2014the data the model uses to learn.\n* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n\nThe images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n\n<table>\n  <tr>\n    <th>Label<\/th>\n    <th>Class<\/th> \n  <\/tr>\n  <tr>\n    <td>0<\/td>\n    <td>T-shirt\/top<\/td> \n  <\/tr>\n  <tr>\n    <td>1<\/td>\n    <td>Trouser<\/td> \n  <\/tr>\n    <tr>\n    <td>2<\/td>\n    <td>Pullover<\/td> \n  <\/tr>\n    <tr>\n    <td>3<\/td>\n    <td>Dress<\/td> \n  <\/tr>\n    <tr>\n    <td>4<\/td>\n    <td>Coat<\/td> \n  <\/tr>\n    <tr>\n    <td>5<\/td>\n    <td>Sandal<\/td> \n  <\/tr>\n    <tr>\n    <td>6<\/td>\n    <td>Shirt<\/td> \n  <\/tr>\n    <tr>\n    <td>7<\/td>\n    <td>Sneaker<\/td> \n  <\/tr>\n    <tr>\n    <td>8<\/td>\n    <td>Bag<\/td> \n  <\/tr>\n    <tr>\n    <td>9<\/td>\n    <td>Ankle boot<\/td> \n  <\/tr>\n<\/table>\n\nEach image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:","76c0fe76":"* We scale these values to a range of 0 to 1 before feeding to the neural network model. For this, we divide the values by 255. It's important that the *training set* and the *testing set* are preprocessed in the same way:","b0266d79":"# **Start Building CNN Models**","b7c7b1cb":"## Import the Fashion MNIST dataset\n\nThis guide uses the [Fashion MNIST](https:\/\/github.com\/zalandoresearch\/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n\n<table>\n  <tr><td>\n    <img src=\"https:\/\/tensorflow.org\/images\/fashion-mnist-sprite.png\"\n         alt=\"Fashion MNIST sprite\"  width=\"600\">\n  <\/td><\/tr>\n  <tr><td align=\"center\">\n    <b>Figure 1.<\/b> <a href=\"https:\/\/github.com\/zalandoresearch\/fashion-mnist\">Fashion-MNIST samples<\/a> (by Zalando, MIT License).<br\/>&nbsp;\n  <\/td><\/tr>\n<\/table>\n\nFashion MNIST is intended as a drop-in replacement for the classic [MNIST](http:\/\/yann.lecun.com\/exdb\/mnist\/) dataset\u2014often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc) in an identical format to the articles of clothing we'll use here.\n\nThis guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code. \n\nWe will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow, just import and load the data:"}}