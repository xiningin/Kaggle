{"cell_type":{"9ea5ec72":"code","8beaa3f5":"code","92123dd6":"code","89dde038":"code","42f165a6":"code","85ae0ad7":"code","cb1984da":"code","23671808":"code","8f1acb6b":"markdown","3bca97d8":"markdown","615c7688":"markdown","b61d5f6d":"markdown","3b32e465":"markdown"},"source":{"9ea5ec72":"import pandas as pd\nimport numpy as np\nimport transformers\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport torch\nfrom sklearn import model_selection\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom transformers import RobertaConfig","8beaa3f5":"df=pd.read_csv(\"..\/input\/commonlitreadabilityprize\/train.csv\")","92123dd6":"MAX_LEN=256\nTEST_BATCH_SIZE=4\nTOKENIZER=transformers.RobertaTokenizerFast.from_pretrained(\"..\/input\/roberta-new\")\nRoberta_PATH = \"..\/input\/roberta-full-training\/model.bin\"\nTRAINING_FILE=\"..\/input\/commonlitreadabilityprize\/train.csv\"","89dde038":"class RobertaDataset:\n    def __init__(self,excerpt,target):\n        self.excerpt=excerpt\n        self.target=target\n\n        \n    def __len__(self):\n        return len(self.excerpt)\n    \n    def __getitem__(self,item):\n        excerpt=str(self.excerpt[item])\n        excerpt=\" \".join(excerpt.split())\n        \n        inputs =TOKENIZER(excerpt,add_special_tokens=True,max_length=MAX_LEN,padding=True,truncation=True)\n        \n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        \n        padding_len=MAX_LEN-len(ids)\n        ids=ids+([0]*padding_len)\n        mask=mask+([0]*padding_len)\n \n        return {\"ids\": torch.tensor(ids, dtype=torch.long),\n            \"mask\": torch.tensor(mask, dtype=torch.long),\n            \"targets\": torch.tensor(self.target[item], dtype=torch.float)}","42f165a6":"class RobertaModel(nn.Module):\n    \n    def __init__(self, conf):\n        super(RobertaModel,self).__init__()\n        self.roberta=transformers.RobertaModel.from_pretrained(Roberta_PATH,config=conf)\n        self.dropout=nn.Dropout(0.3)\n        self.linear=nn.Linear(768,1)\n        \n    def freeze(self):\n        for child in self.roberta.children():\n            for param in child.parameters():\n                param.requires_grad = False\n\n    def unfreeze(self):\n        for child in self.roberta.children():\n            for param in child.parameters():\n                param.requires_grad = True\n        \n    def forward(self,ids,mask):\n        \n        output1=self.roberta(ids,attention_mask=mask)\n        output1 = output1.hidden_states\n        output1 = output1[-1]\n        xlnet_output=self.dropout(output1)\n        \n        out = torch.mean(xlnet_output, 1, False)\n        final_output=self.linear(out)\n        final_outputs = final_output.squeeze(-1).squeeze(-1)\n        \n        return final_outputs","85ae0ad7":"def inference(data_loader, model, device):\n    model.eval()\n    final_loss=0\n    i=0\n    \n    with torch.no_grad():\n        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n            ids = d[\"ids\"]\n            mask = d[\"mask\"]\n            targets = d[\"targets\"]\n\n            ids = ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            targets = targets.to(device, dtype=torch.float)\n\n            predictions = model(ids=ids, mask=mask)\n            predictions = predictions.cpu().detach().numpy()\n            \n            if i==0:\n                preds_test = predictions\n            else:\n                preds_test = np.concatenate((preds_test,predictions), axis=None)\n                \n            i+=1\n\n            \n    return preds_test","cb1984da":"model_config = RobertaConfig.from_pretrained(\"..\/input\/roberta-new\")\n\ndevice = torch.device(\"cuda\")\nmodel_config.output_hidden_states = True\nmodel = RobertaModel(model_config)\n\nmodel.load_state_dict(torch.load(Roberta_PATH))\n\nmodel.to(device)\n\ntest=pd.read_csv(\"..\/input\/commonlitreadabilityprize\/test.csv\")\ntest[\"target\"]=0\ntest_dataset = RobertaDataset(excerpt=test.excerpt.values, target=test.target.values)\n\ntest_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, num_workers=1)\n\npreds_test=inference(test_data_loader, model, device)","23671808":"test.target=preds_test\ntest=test[[\"id\",\"target\"]]\ntest.to_csv(\"submission.csv\",index=False)\ntest.head()","8f1acb6b":"# Imports","3bca97d8":"# Inference","615c7688":"# Create the Dataset","b61d5f6d":"# Configuration","3b32e465":"# Model"}}