{"cell_type":{"c5c58640":"code","b03419e8":"code","c98808cb":"code","1ed66eb0":"code","c7bd1dda":"code","e53d0149":"code","8ec09e5e":"code","04383d2a":"code","e8434711":"code","ade18ba1":"code","f35af229":"code","ce21df67":"code","b8ccdde5":"code","2b8dd62c":"code","bdbef3ac":"code","9dd16825":"code","318dc17c":"code","539a06a9":"code","2082626e":"code","5e909672":"code","edb6dd6b":"code","a2c1e0e4":"code","4598da6c":"code","d9e8df2a":"code","e374e2df":"code","981a3639":"code","0a8b21c8":"code","0cc2bf57":"markdown","2e34fcd1":"markdown","500f584e":"markdown","bd13d8ae":"markdown","966274a7":"markdown","e6659972":"markdown"},"source":{"c5c58640":"import numpy as np # linear algebra\nimport gc\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nimport os\nimport seaborn as sns\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","b03419e8":"root_path = '\/kaggle\/input\/pokemon-generation-one\/dataset\/dataset'\nclasses = os.listdir(root_path)\ncount=0\ncount_dict = {}\nprint(f'Total number of pokemons: {len(classes)}')\nfor pokemon in classes:\n    dir_path = os.path.join(root_path, pokemon)\n    count+=len(os.listdir(dir_path))\n    count_dict[pokemon] = len(os.listdir(dir_path))\nprint(f'Total number of images: {count}')\nfig = plt.figure(figsize = (25, 5))\nsns.lineplot(x = list(count_dict.keys()), y = list(count_dict.values())).set_title('Number of images for each pokemon')\nplt.xticks(rotation = 90)\nplt.margins(x=0)\nplt.show()","c98808cb":"# sorted the list of pokemons with respect to number of their appearances in the datasett\nsorted_list =  sorted(count_dict.items(), key=lambda item: item[1], reverse=True)\nsorted_list","1ed66eb0":"# pick the 50 most frequently appears\nchosen_pokemon = sorted_list[0:50]\nchosen_pokemon","c7bd1dda":"#functions to augment more images\ndef generate_extra_two(img):\n    return img[0:96, 0:96,:], img[4:100, 4:100, :]\ndef generate_extra_three(img):\n    return generate_extra_two(img)[0], generate_extra_two(img)[1], img[2:98,2:98,:]","e53d0149":"#generate data and labels\nX = []\ny= []\npoke_label_dict = {}\ni=0\nfor pokemon in chosen_pokemon:\n    name = pokemon[0]\n    poke_label_dict[i] = name\n    print(name+ ': ' + str(i))\n    dir_path = os.path.join(root_path, name)\n    j=0\n    if pokemon[1] < 70:\n        for filename in os.listdir(dir_path):   \n            try:\n                file_path = os.path.join(dir_path, filename)\n                img = cv.imread(file_path, 1)\n                img = cv.resize(img, (100, 100))\n                extra = generate_extra_three(img)\n                for e in range(3):\n                    X.append(extra[e])\n                    y.append(i)\n                gc.collect()\n            except:\n                j+=1\n                print(str(j)+ \" Broken file(s)\")\n\n    elif pokemon[1] < 100:\n        for filename in os.listdir(dir_path):   \n            try:\n                file_path = os.path.join(dir_path, filename)\n                img = cv.imread(file_path, 1)\n                img = cv.resize(img, (100, 100))\n                extra = generate_extra_two(img)\n                for e in range(2):\n                    X.append(extra[e])\n                    y.append(i)\n                gc.collect()\n            except:\n                j+=1\n                print(str(j)+ \" Broken file(s)\")    \n    else:\n        for filename in os.listdir(dir_path):   \n            try:\n                file_path = os.path.join(dir_path, filename)\n                img = cv.imread(file_path, 1)\n                img = cv.resize(img, (96, 96))\n                X.append(img)\n                y.append(i)\n                gc.collect()\n            except:\n                j+=1\n                print(str(j)+ \" Broken file(s)\")\n    i+=1    \n    ","8ec09e5e":"#convert X to 4-dimensional tensor\nX = np.array(X).reshape(-1, 96, 96, 3)\n#normalize X\nX = X\/255.0\n#convert y to one-hot-encoded form\ny = to_categorical(np.array(y))","04383d2a":"#check shape of X and Y\nX.shape, y.shape","e8434711":"#check if X has been normailized\nX.max(),X.min()","ade18ba1":"#split data into training and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=500,test_size=0.2)","f35af229":"#check shape of training and test data\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","ce21df67":"#split data into training and validation data\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True, random_state=500,test_size=0.4)","b8ccdde5":"#check shape of training and validation data\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","2b8dd62c":"#check length of label dictionary\nlen(poke_label_dict)","bdbef3ac":"#visulaize some example in training set and some example in validation set\nimport random\ndef vis_ex(X,y):\n    plt.figure(1,figsize=(15, 10))\n    for i in range(1,9):\n        c = random.randint(0, 2000)\n        img = X[c]\n        plt.subplot(5,8,i)\n        plt.imshow(img)\n        plt.title(poke_label_dict[np.argmax(y[c])])","9dd16825":"vis_ex(X_train, y_train)","318dc17c":"vis_ex(X_val, y_val)","539a06a9":"model= Sequential()\n#Phase 1: 2 Conv-> Pooling block\nmodel.add(layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), \n                       padding='valid' , input_shape=(96,96,3),activation='relu'))\nmodel.add(layers.BatchNormalization(axis=-1))\nmodel.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\nmodel.add(layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization(axis=-1))\nmodel.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n#Phase 2: Convol Phase\nmodel.add(layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization(axis=-1))\nmodel.add(layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization(axis=-1))\nmodel.add(layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization(axis=-1))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))) #modified from pool(3,3) to fit the input\n#Phase 3: Fully-connected Phase: #modify the second FC layer from original paper due to low number of training examples \nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(units=1024, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(units=512, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(units=y_train.shape[1], activation='softmax'))","2082626e":"model.summary()","5e909672":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","edb6dd6b":"#create datagen during training and validation\ntrain_datagen = ImageDataGenerator(horizontal_flip=True,\n                                   rotation_range = 45, \n                                   width_shift_range = 0.15,  \n                                   height_shift_range = 0.15)\ntest_datagen = ImageDataGenerator(horizontal_flip=True)\ntrain_generator =  train_datagen.flow(X_train, y_train, batch_size=256, shuffle=True)\nval_generator = test_datagen.flow(X_val, y_val, batch_size=256, shuffle=True)","a2c1e0e4":"history = model.fit_generator(train_generator, validation_data=val_generator, epochs=100, \n                              steps_per_epoch=len(train_generator),validation_steps= len(val_generator))","4598da6c":"y_pred = model.predict(X_test)","d9e8df2a":"print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))","e374e2df":"#plot some predictions:\ndef vis_pred(X):\n    plt.figure(1,figsize=(15, 10))\n    for i in range(1,9):\n        c = random.randint(0, 1000)\n        img = X[c]\n        plt.subplot(5,8,i)\n        plt.imshow(img)\n        plt.title(poke_label_dict[np.argmax(model.predict(img.reshape(1,96,96,3)))])\n","981a3639":"vis_pred(X_test)","0a8b21c8":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model_pkm.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model_pkm.h5\")\nprint(\"Saved model to disk\")","0cc2bf57":"Step 1: Import necessary libraries","2e34fcd1":"Step 3: Generate data and preprocessing","500f584e":"Step 7: Save  model","bd13d8ae":"Step 4 : Build a CNN-model based on Alex","966274a7":"Step 4: Evaluation","e6659972":"Step 2: Analyze and Visualize data"}}