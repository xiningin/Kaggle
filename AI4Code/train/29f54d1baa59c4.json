{"cell_type":{"4b014c97":"code","4736526a":"code","1fd006ee":"code","43bb1a43":"code","ce5eea93":"code","c7343dc2":"code","44029ab3":"code","1018acee":"code","c93e2803":"code","cb00fd6d":"code","cb2b54d9":"code","796b6952":"code","074f3d72":"code","367065ba":"code","1e1bb990":"code","a6ffb3f4":"code","f35628ff":"code","899a01c7":"code","3e63c09b":"code","b245e3cb":"code","8ac16671":"code","72eee7d2":"code","5b5b5bee":"code","60542b74":"code","6ed6f741":"code","3dcef2fa":"markdown","95b411a9":"markdown","5f563154":"markdown","1fcbc4e2":"markdown","f4ce8ffa":"markdown","6f721b23":"markdown","d8d8029a":"markdown","f3c0d029":"markdown","989f9c7d":"markdown","2c7055e7":"markdown","525127e8":"markdown","fb2e8c95":"markdown","8bcb91bf":"markdown","219a1acf":"markdown","a4703597":"markdown","27d1c1c3":"markdown","98532eb7":"markdown","ed2e2860":"markdown","105e5d87":"markdown","27b6b464":"markdown","cc896d02":"markdown","e9995e8b":"markdown","bc849d83":"markdown","a53d70f4":"markdown","0692553a":"markdown","ef2ced0b":"markdown","b9bf88c6":"markdown"},"source":{"4b014c97":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nrawdf = pd.read_csv('\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv', low_memory=False)\n\n# Clear Question description row\ndf = rawdf.iloc[1:]\n\n# drop students and unemployed respondents\ndf = df[~df['Q5'].isin(['Student','Currently not employed'])]","4736526a":"# create info df with desired info\neducation_job = df[[\"Q4\", \"Q5\"]]\neducation_job = education_job.rename(columns={\"Q4\":\"Education\", \"Q5\":\"Job Title\"})\n\ngrouped_education = pd.DataFrame(education_job.groupby([\"Job Title\", \"Education\"], as_index=True).size())\n\n# build data frame with desired output (binary vector representation of each response with 1 indicating education response)\neducation_options = education_job[\"Education\"].to_list()\nunique_education_options = set(education_options)\neducation_data = pd.DataFrame(columns=unique_education_options, index=[\"Business Analyst\", \"Data Analyst\", \"Data Engineer\", \"Data Scientist\", \"DBA\/Database Engineer\", \"Machine Learning Engineer\", \"Product Manager\", \"Program\/Project Manager\", \"Research Scientist\", \"Software Engineer\", \"Statistician\", \"Other\"])\n\n# build education_data df and fill in using values from grouped_education\nfor i in range(0, (grouped_education.shape[0])):\n  # get Series for each row in grouped_education data\n  series = grouped_education.iloc[i]\n  # series.name has data @ index 0 = job title and 1 = education\n  # series[0] is the count of that job\/education pairing\n  education_data.at[series.name[0], series.name[1]] = series[0]\n\n# fill in total count for each job title\neducation_data[\"Total\"] = education_data.sum(axis=1)\neducation_data.fillna(value=0, inplace=True)\n\n#get list of columns and remove total\ncols = education_data.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total to get proportion\nproportion_education_data = education_data[cols].div(education_data.Total, axis=0)\n\n# stacked bar chart - x-axis is job title, y-axis is the count and the stacked barchart makes up the education levels (modified from https:\/\/towardsdatascience.com\/stacked-bar-charts-with-pythons-matplotlib-f4020e4eb4a7 tutorial)\n# build chart data, filter out Total column for graphing\nfields = proportion_education_data.columns\n# 7 colours required\ncolors = ['#1D2F6F', '#8390FA', '#6EAF46', '#FAC748', '#FF5733', '#FFA533', '#33DDFF']\n\n# figure and axis\nfig, ax = plt.subplots(1, figsize=(12, 10))\n# plot bars\nleft = len(proportion_education_data) * [0]\nfor idx, name in enumerate(fields):\n    plt.barh(proportion_education_data.index, proportion_education_data[name], left = left, color=colors[idx])\n    left = left + proportion_education_data[name]\n# title, legend, labels\nplt.title('Education for each job title\\n', loc='left', fontsize=20, pad=20)\nplt.xlabel('Proportion of education for job title', fontsize=16, labelpad=20)\nplt.ylabel('Job Title', fontsize=16, labelpad=20)\n# remove spines\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\n# adjust limits and draw grid lines\nplt.ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nplt.legend(fields, ncol=2, frameon=False, bbox_to_anchor=(1.0, 1.0))\nax.set_axisbelow(True)\nax.xaxis.grid(color='gray', linestyle='dashed')\nplt.gca().invert_yaxis()\nplt.show()","1fd006ee":"salary_data = df[[\"Q3\", \"Q5\", \"Q25\"]]\nsalary_data = salary_data.rename(columns={\"Q3\":\"Country\", \"Q5\":\"Job Title\", \"Q25\":\"Yearly Comp USD\"})\nsalary_data = salary_data.replace(to_replace={\"$0-999\":499.5, \"1,000-1,999\":1499.5, \"10,000-14,999\":12499.5, \"30,000-39,999\":34999.5, \"100,000-124,999\":112499.5, \"5,000-7,499\":6249.5, \"50,000-59,999\":54999.5, \"40,000-49,999\":44999.5, \"20,000-24,999\":22499.5, \"2,000-2,999\":2499.5, \"15,000-19,999\":17499.5, \"7,500-9,999\":8749.5, \"60,000-69,999\":64999.5, \"25,000-29,999\":27499.5, \"70,000-79,999\":74999.5, \"4,000-4,999\":4499.5, \"150,000-199,999\":174999.5, \"80,000-89,999\":84999.5, \"3,000-3,999\":3499.5, \"125,000-149,999\":137499.5, \"90,000-99,999\":94999.5, \"200,000-249,999\":224999.5, \"300,000-499,999\":399999.5, \"250,000-299,999\":274999.5, \">$1,000,000\":1000000,\"$500,000-999,999\":749999.5})\n\ntotal_results = salary_data.groupby([\"Country\", \"Job Title\"]).mean()\n# heatmap of the total results with all data included\npivot_total = pd.pivot_table(total_results, values=[\"Yearly Comp USD\"], index=[\"Country\"], columns=[\"Job Title\"], fill_value=0)\nplt.figure(figsize=(12,12))\nax = sns.heatmap(data=pivot_total, robust=True, linewidth=.015, xticklabels=True, yticklabels=True, cmap=\"Greens\")\nplt.setp(ax.xaxis.get_majorticklabels(), rotation=45, rotation_mode=\"anchor\", ha=\"right\")\nplt.title(\"Salary by Country vs Job Title\", fontsize=20, pad=20)\nplt.xlabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.ylabel(\"Country\", fontsize=16, labelpad=20)\nplt.show()","43bb1a43":"## remove country\/job title combinations with less than 50 responses\nlarge_sample_salary = salary_data.groupby([\"Country\", \"Job Title\"]).mean()\nlarge_sample_salary['Total'] = salary_data.groupby([\"Country\", \"Job Title\"]).size()\nlarge_sample_salary = large_sample_salary[large_sample_salary['Total'] > 29]\n\n# heatmap of the large sample results with >= 30 data point pairs included\npivot_total = pd.pivot_table(large_sample_salary, values=[\"Yearly Comp USD\"], index=[\"Country\"], columns=[\"Job Title\"], fill_value=0)\nplt.figure(figsize=(12,12))\nax = sns.heatmap(data=pivot_total, robust=True, linewidth=.015, xticklabels=True, yticklabels=True, cmap=\"Greens\")\nplt.setp(ax.xaxis.get_majorticklabels(), rotation=45, rotation_mode=\"anchor\", ha=\"right\")\nplt.title(\"Large Sample Country\/Job Pairings\", fontsize=20, pad=20)\nplt.xlabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.ylabel(\"Country\", fontsize=16, labelpad=20)\nplt.show()","ce5eea93":"# df for job titles and industry\nindustry_data = df[[\"Q5\", \"Q20\"]]\nindustry_data = industry_data.rename(columns={\"Q5\":\"Job Title\", \"Q20\":\"Industry\"})\nindustry_grouped = industry_data.groupby([\"Job Title\", \"Industry\"]).size().reset_index()\n\n# build the heatmap of industry to job titles\npivot_total = pd.pivot_table(industry_grouped, index=[\"Job Title\"], columns=[\"Industry\"], fill_value=0)\nplt.figure(figsize=(12,12))\nax = sns.heatmap(data=pivot_total, robust=True, linewidth=.015, xticklabels=True, yticklabels=True, cmap=\"Greens\")\nax.set(xticklabels=['Academics\/Education','Accounting\/Finance','Broadcasting\/Communications','Computers\/Technology','Energy\/Mining',\n               'Government\/Public Service', 'Hospitality\/Entertainment\/Sports','Insuarance\/Risk Assessment','Manufacturing\/Fabrication',\n              'Marketing\/CRM','Medical\/Pharmaceutical','Military\/Security\/Defense','Non-profit\/Service','Online Business\/Internet-based Sales',\n              'Online Service\/Internet-based Services','Other','Retail\/Sales','Shipping\/Transportation'])\nplt.setp(ax.xaxis.get_majorticklabels(), rotation=45, rotation_mode=\"anchor\", ha=\"right\")\nplt.title(\"Industry Breakdown for Job Titles\", fontsize=20, pad=20)\nplt.xlabel(\"Industry\", fontsize=16, labelpad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.show()","c7343dc2":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,119:127]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,119:127]].groupby(['Q5']).size()\ntdf\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title',\n'Analyze and understand data to \\n influence product or business decisions',\n'Build and\/or run the data infrastructure \\n that my business uses for storing, \\n analyzing, and operationalizing data',\n'Build prototypes to explore\\n applying machine learning to new areas',\n'Build and\/or run a machine \\n learning service that operationally \\n improves my product or workflows',\n'Experimentation and iteration \\n to improve existing ML models',\n'Do research that advances the \\n state of the art of machine learning',\n'None of these activities are an \\n important part of my role at work',\n'Other'\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Job Activities by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Activity\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","44029ab3":"# columns for answers to question 40, all parts\ntdf = df.iloc[:,np.r_[243:255]]\n\n# transpose data so that rows become learning tools\ntdf = tdf.transpose()\n\n# rename index to learning tool\ntdf.rename(index={\"Q40_Part_1\":\"Coursera\", \"Q40_Part_2\":\"edX\", \"Q40_Part_3\":\"Kaggle Learn Courses\", \"Q40_Part_4\":\"DataCamp\", \"Q40_Part_5\":\"Fast.ai\", \"Q40_Part_6\":\"Udacity\", \"Q40_Part_7\":\"Udemy\", \n                  \"Q40_Part_8\":\"LinkedIn Learning\", \"Q40_Part_9\":\"Cloud-certification programs \\n (direct from AWS, \\n Azure, GCP, or similar)\", \"Q40_Part_10\":\"University Courses \\n resulting in a university degree)\", \n                  \"Q40_Part_11\":\"None\", \"Q40_OTHER\":\"Other\"}, inplace=True)\n\n# convert responses to a binary vector like system, 1 means a response and 0 for no response\ndef response_to_binary(x):\n  if x is not np.nan:\n    return 1\n  else:\n    return 0\nbinary_tdf = tdf.applymap(response_to_binary)\n\n# sum the total of all rows and get a total \nbinary_tdf[\"Total\"] = binary_tdf.apply(np.sum, axis = 1)\n\n# convert to percentages\n# get total count for responses of tools used - multiple education tools maybe used by one respondent\ntotal_responses = binary_tdf[\"Total\"].sum()\n# divide all values by \nbinary_tdf[\"Percentage\"] = binary_tdf[\"Total\"].div(total_responses, axis=0)\nbinary_tdf[\"Percentage\"] = pd.Series([val*100 for val in binary_tdf[\"Percentage\"]], index = binary_tdf.index)\n\n# plot in descending from most used to least used \nbinary_tdf.sort_values(\"Percentage\", ascending=False).plot.bar(y=\"Percentage\", color=['C2', 'C2', 'C2', 'C7', 'C7', 'C7', 'C7', 'C7', 'C7', 'C7', 'C7', 'C7'], figsize=(15,10))\n\nplt.title(\"Learning Tool Usage\", fontsize=20, pad=20)\nplt.ylabel(\"Percentage of Responses that used each Learning Tool\", fontsize=16, labelpad=20)\nplt.xlabel(\"Learning Tool\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.show()","1018acee":"# columns for Q7_Part_1 to Q7_Other\ntdf = df.iloc[:,np.r_[5,7:20]].groupby(['Q5']).count()\ntdf[\"Total\"] = df.iloc[:,np.r_[5,7:20]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title','Python', 'R', 'SQL', 'C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None','Other']\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Programming Languages by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Programming Language\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\n# plt.legend(loc='best', bbox_to_anchor=(1.7,1), labelspacing=2, fontsize=14, frameon=False, markerscale=1)\n\nplt.tight_layout()\nplt.show()","c93e2803":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,21:34]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,21:34]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title',\"JupyterLab\", \"RStudio\", \"Visual Studio\",\"Visual Studio Code\\n (VSCode)\", \"PyCharm\",\"Spyder\",\"Notepad++\", \"Sublime Text\", \"Vim \/ Emacs\", \"MATLAB\", \"Jupyter Notebook\",\"None\",\"Other\" ]\ntdf.set_index('Job_Title',inplace=True)\n\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"IDEs by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"IDE\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","cb00fd6d":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,34:51]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,34:51]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', \"Kaggle Notebooks\",\"Colab Notebooks\", \"Azure Notebooks\", \"Paperspace \/ Gradient\", \"Binder \/ JupyterHub\", \"Code Ocean\",\n               \"IBM Watson Studio\", \"Amazon Sagemaker \\n Studio Notebooks\", \"Amazon EMR Notebooks\", \"Google Cloud Notebooks \\n (AI Platform \/ Vertex AI)\",\n               \"Google Cloud Datalab\", \"Databricks Collaborative \\n Notebooks\", \"Zeppelin \/ Zepl Notebooks\", \"Deepnote Notebooks\", \"Observable Notebooks\",\n               \"None\", \"Other\"]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Hosted Notebooks by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Hosted Notebook\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","cb2b54d9":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,59:71]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,59:71]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Matplotlib', 'Seaborn', \"Plotly \/ Plotly Express\", \"Ggplot \/ ggplot2\", 'Shiny',' D3 js', 'Altair', 'Bokeh', 'Geoplotlib', 'Leaflet \/ Folium', 'None', 'Other']\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Data Visualisation Libraries \/ Tools by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Library \/ Tool\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","796b6952":"# create info df with desired info\nprimary_tool = df[[\"Q5\", \"Q41\"]]\nprimary_tool = primary_tool.rename(columns={\"Q5\":\"Job Title\", \"Q41\":\"Primary Tool\"})\n\ngrouped_tool = pd.DataFrame(primary_tool.groupby([\"Job Title\", \"Primary Tool\"], as_index=True).size())\n\n# build data frame with desired output (binary vector representation of each response with 1 indicating education response)\njob_options = primary_tool[\"Job Title\"].to_list()\nunique_job_options = set(job_options)\ntool_options = primary_tool[\"Primary Tool\"].to_list()\nunique_tool_options = set(tool_options)\ntool_data = pd.DataFrame(index=unique_job_options, columns=unique_tool_options)\n\n# build country_data df and fill in using values from grouped_country\nfor i in range(0, (grouped_tool.shape[0])):\n  # get Series for each row in grouped_education data\n  series = grouped_tool.iloc[i]\n  # series.name has data @ index 0 = job title and 1 = primary tool\n  # series[0] is the count of that job\/tool pairing\n  tool_data.at[series.name[0], series.name[1]] = series[0]\n\ntool_data.drop(np.NaN, axis=1, inplace=True)\n\n# fill in total count for each job title\ntool_data[\"Total\"] = tool_data.sum(axis=1)\ntool_data.fillna(value=0, inplace=True)\ntool_data\n# get list of columns and remove total\ncols = tool_data.columns.tolist()\ncols.remove('Total')\n\n# # divide all values by row total to get proportion\nproportion_tool_data = tool_data[cols].div(tool_data.Total, axis=0)\n\n# stacked bar chart - x-axis is job title, y-axis is the count and the stacked barchart makes up the education levels (modified from https:\/\/towardsdatascience.com\/stacked-bar-charts-with-pythons-matplotlib-f4020e4eb4a7 tutorial)\n# build chart data, filter out Total column for graphing\nfields = proportion_tool_data.columns\n# 7 colours required\ncolors = ['#1D2F6F', '#8390FA', '#6EAF46', '#FAC748', '#FF5733', '#FFA533']\n\n# figure and axis\nfig, ax = plt.subplots(1, figsize=(12, 10))\n# plot bars\nleft = len(proportion_tool_data) * [0]\nfor idx, name in enumerate(fields):\n    plt.barh(proportion_tool_data.index, proportion_tool_data[name], left = left, color=colors[idx])\n    left = left + proportion_tool_data[name]\n# title, legend, labels\nplt.xlabel('Proportion of primary tool by job title', fontsize=16, labelpad=20)\nplt.title('Primary tool usage by job title\\n', loc='left', fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\n# remove spines\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\n# adjust limits and draw grid lines\nplt.ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nplt.legend(fields, ncol=2, frameon=False, bbox_to_anchor=(1.0, 1.0))\nax.set_axisbelow(True)\nax.xaxis.grid(color='gray', linestyle='dashed')\nplt.gca().invert_yaxis()\nplt.show()","074f3d72":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,72:90]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,72:90]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Scikit-learn', 'TensorFlow', 'Keras', 'PyTorch', 'Fast.ai', 'MXNet', 'Xgboost', 'LightGBM', 'CatBoost', 'Prophet', 'H2O 3', 'Caret', 'Tidymodels', 'JAX', 'PyTorch Lightning', 'Huggingface', 'None', 'Other']\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Machine Learning Frameworks by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Framework\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","367065ba":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,90:102]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,90:102]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Linear or Logistic \\n Regression', 'Decision Trees or \\n Random Forests',' Gradient Boosting Machines \\n (xgboost, lightgbm, etc)', 'Bayesian Approaches', 'Evolutionary Approaches', \n               'Dense Neural Networks \\n (MLPs, etc)', 'Convolutional \\n Neural Networks', 'Generative Adversarial \\n Networks', 'Recurrent Neural \\n Networks',' Transformer Networks \\n (BERT, gpt-3, etc)', 'None', 'Other'\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Machine Learning Algorithms by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Algorithm\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","1e1bb990":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,102:109]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,102:109]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title','General purpose image \/ video \\n tools (PIL, cv2, skimage, etc)', 'Image segmentation methods \\n (U-Net, Mask R-CNN, etc)', 'Object detection methods \\n (YOLOv3, RetinaNet, etc)', \n               'Image classification and \\n other general purpose networks \\n (VGG, Inception, ResNet, ResNeXt,\\n NASNet, EfficientNet, etc)', 'Generative Networks \\n (GAN, VAE, etc)', 'None', 'Other'\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Computer Vision Methods by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Method\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","a6ffb3f4":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,109:115]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,109:115]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Word embeddings\/vectors \\n (GLoVe, fastText, word2vec)', 'Encoder-decoder models \\n (seq2seq, vanilla transformers)', \n               'Contextualized embeddings \\n (ELMo, CoVe)', 'Transformer language models \\n (GPT-3, BERT, XLnet, etc)', 'None', 'Other'\n\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"NLP Methods by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Method\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","f35628ff":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,205:213]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,205:213]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Automated data augmentation \\n (e.g. imgaug, albumentations)', 'Automated feature \\n engineering \/ selection \\n (e.g. tpot, boruta_py)', \n               'Automated model selection \\n (e.g. auto-sklearn, xcessiv)', 'Automated model architecture \\n searches (e.g. darts, enas)',' Automated hyperparameter tuning \\n (e.g. hyperopt, ray.tune, Vizier)', \n               'Automation of full ML pipelines \\n (e.g. Google AutoML, H20 Driverless AI)', 'No \/ None', 'Other'\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Automated Machine Learning Techniques by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Technique\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","899a01c7":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,213:221]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,213:221]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Google Cloud AutoML', 'H20 Driverless AI', 'Databricks AutoML', 'DataRobot AutoML', 'Amazon Sagemaker Autopilot', 'Azure Automated \\n Machine Learning', 'No \/ None', 'Other'\n\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Automated Machine Learning Tools by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Tool\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","3e63c09b":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,155:165]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,155:165]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Amazon SageMaker', 'Azure Machine \\n Learning Studio', 'Google Cloud \\n Vertex AI', 'DataRobot', 'Databricks', 'Dataiku', 'Alteryx', 'Rapidminer', 'No \/ None', 'Other'\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Managed Machine Learning Products by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Product\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","b245e3cb":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,221:233]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,221:233]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Neptune.ai', 'Weights & Biases', 'Comet.ml', 'Sacred + Omniboard', 'TensorBoard', 'Guild.ai', 'Polyaxon', 'Trains', 'Domino Model Monitor', 'MLflow', 'No \/ None', 'Other'\n\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Machine Learning Management Tools by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Tool\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","8ac16671":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,129:141]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,129:141]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Amazon Web Services (AWS)', 'Microsoft Azure', 'Google Cloud Platform (GCP)', 'IBM Cloud \/ Red Hat', \n               'Oracle Cloud', 'SAP Cloud', 'Salesforce Cloud', 'VMware Cloud', 'Alibaba Cloud', 'Tencent Cloud', 'None', 'Other'\n\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Cloud Computing Platforms by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Platform\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","72eee7d2":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,142:147]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,142:147]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Amazon Elastic \\n Compute Cloud (EC2)', 'Microsoft Azure \\n Virtual Machines', 'Google Cloud \\n Compute Engine', 'No \/ None', 'Other'\n\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Cloud Computing Products by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Product\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","5b5b5bee":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,147:155]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,147:155]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Microsoft Azure \\n Data Lake Storage', 'Microsoft Azure \\n Disk Storage', 'Amazon Simple \\n Storage Service (S3)',\n               'Amazon Elastic \\n File System (EFS)', 'Google Cloud \\n Storage (GCS)', 'Google Cloud Filestore', 'No \/ None', 'Other'\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Data Storage Products by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Product\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","60542b74":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,165:186]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,165:186]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'MySQL', 'PostgreSQL', 'SQLite', 'Oracle Database', 'MongoDB', 'Snowflake', 'IBM Db2', 'Microsoft SQL Server', 'Microsoft Azure SQL Database', 'Microsoft Azure Cosmos DB', \n               'Amazon Redshift', 'Amazon Aurora', 'Amazon RDS', 'Amazon DynamoDB', 'Google Cloud BigQuery', 'Google Cloud SQL', 'Google Cloud Firestore', 'Google Cloud BigTable', 'Google Cloud Spanner', 'None', 'Other'\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Big Data Products by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Product\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","6ed6f741":"# columns for answers to question\ntdf = df.iloc[:,np.r_[5,187:204]].groupby(['Q5']).count()\n\n# total number of entries in relevant job titles\ntdf[\"Total\"] = df.iloc[:,np.r_[5,187:204]].groupby(['Q5']).size()\n\n#get list of columns and remove total\ncols = tdf.columns.tolist()\ncols.remove('Total')\n\n# divide all values by row total\ntdf = tdf[cols].div(tdf.Total, axis=0)\n\n# resets index and assigns column names which will serve as x axis labels\ntdf.reset_index(inplace=True)\ntdf.columns = ['Job_Title', 'Amazon QuickSight', 'Microsoft Power BI', 'Google Data Studio', 'Looker', 'Tableau', 'Salesforce', 'Einstein Analytics', \n               'Qlik', 'Domo', 'TIBCO Spotfire', 'Alteryx', 'Sisense', 'SAP Analytics Cloud', 'Microsoft Azure Synapse', 'Thoughtspot', 'None', 'Other'\n]\ntdf.set_index('Job_Title',inplace=True)\n\n# unstacks temporary dataframe and builds a cartesian product for our bubble chart\ndfu = tdf.unstack().reset_index()\ndfu.columns = ['x_axis','y_axis','proportion']\n\n# Create bubble plot with grid\nfig = plt.figure()\nplt.scatter(dfu.x_axis, dfu.y_axis, s = dfu.proportion*1000, edgecolors=\"black\", c = dfu['proportion'], zorder = 2, cmap=\"viridis\")\nplt.grid(ls = \"--\", zorder = 1)\nfig.set_size_inches(18.5, 10.5)\n\n# Set Titles and Labels\nplt.title(\"Business Intelligence Tools by Job Title\", fontsize=20, pad=20)\nplt.ylabel(\"Job Title\", fontsize=16, labelpad=20)\nplt.xlabel(\"Tool\", fontsize=16, labelpad=20)\nplt.xticks(rotation=45, rotation_mode='anchor', ha='right')\nplt.gca().invert_yaxis()\n\n#Legend with colour bar and circle sizes\nplt.colorbar(ticks=np.linspace(0,1,11))\n\nplt.tight_layout()\nplt.show()","3dcef2fa":"As we can see from the above bar graph, there is a wide variety of tools to choose from. We have coloured the graph for you to clearly see the 3 most popular tools, which are Coursera, Kaggle Learn Courses and Udemy. \n[Coursera](https:\/\/www.coursera.org\/) was the most popular, with just under 20% of respondents having used this tool.\n\n## 5.2 Basic Tools\nBasic Tools encompasses the fundamental tools for a practitioner, this consists of a Programming Language, an IDE, a Hosted Notebook and a Data Visualisation Tool.\n\n### 5.2.1 Programming Languages\nA programming language is essentially a written language that tells computers what to do.\n","95b411a9":"Here we can see that Collab Notebooks is the most used hosted notebook with Kaggle notebooks being a close second.\n\n### 5.2.4 Data Visualisation Libraries \/ Tools\nData Visualisation Libraries refer to the libraries used to create charts, graphs and other methods of visualisation. Think of these like a toolbox for visualising data, rather than program everything from scratch you can build a visualisation with a few simple lines of code. For example, to create the bubble charts you see here, we used Matplotlib.","5f563154":"Here we can see that across most professions Matplotlib is the most widely used visualisation tool, the exception to this being statisticians where it is a close second to ggplot\/ggplot2.\n\n### 5.2.5 Primary Tools\nThis relates to what category of software is used and can be factored into prioritising your list of items to learn.","1fcbc4e2":"As before, the white cells represent an average of 0\/missing data as every country\/job title combination is included in the heatmap. This is due to not having sufficient data for those specific combinations. These values still appear as the nature of the heatmap includes a cell for every country\/job title pairing.\n\nDue to the large samples principle, this heatmap contains the data that is best representative of its population.\n\nAfter examining these heatmaps Israel, United States of America and Australia seem to have the highest compensation in USD. It should be noted that this does not necessarily mean that other countries are not similar in compensation as smaller countries may have a lower cost of living\/median wage and \"low\" compensation may actually be \"high\" compensation. \n\nData Scientist and Other seem to be the job titles associated with the highest compensation levels.\n\n## 4.4 Industry Breakdown\nWithin the survey, respondents were able to enter their industry. We have put together a heatmap to demonstrate the spread of Kaggler's job titles across various industries.","f4ce8ffa":" \n# 4. Information on Job Titles: Helping you Select a Career Path\nThe purpose of this section is to help familiarise you with some of the available career paths in the data science and machine learning space and help find which will best suit you. To achieve this goal, for each job title provided we will look at a brief description of the job, the expected salary in each country, a breakdown of jobs in different industries and the day-to-day activities of each job title.\n\n## 4.1 Job Descriptions\nBelow descriptions are modified and extended from [Seek Australia](https:\/\/www.seek.com.au\/career-advice\/)\n### Business Analyst\nBusiness Analysts are responsible for reviewing and analysing business decisions and processes, as well as communicating technical information back to the business and shareholders. Analysts work across a large range of departments and industries.\n\n### DBA \/ Database Engineer\nDatabase engineers are responsible for an organisation\u2019s database management. They assess business and user requirements and plan, configure and maintain custom databases and their accompanying documentation and protocols for the business.\n\n### Data Analyst\nData Analysts help organisations identify ways to reduce costs and find opportunities for improving business revenue. Data Analysts collect and analyse data from within the business. Analysts are responsible for taking data and their findings and transferring this to actionable plans for the business.\n\n### Data Engineer\nData Engineers develop ways to store and access large amounts of data. Data engineers design and maintain data architectures that enable easier access and interpretation of data for the business and shareholders.\n\n### Data Scientist\nData Scientists look for patterns in the raw business data and use this to find trends and patterns to generate insights into real-world problems and to find possible solutions for these problems.\n\n### Developer Relations\/Advocacy\nDeveloper Relations involves working with business shareholders and developers to assist in planning and setting expectations for projects. Advocates are typically experts in their field\/company and promote their product.\n\n### Machine Learning Engineer\nMachine Learning Engineers are experts in AI and machine learning models. ML engineers design, build and test models. Also, verifying data quality is part of their job as it is important that the ML models are being trained with quality and accurate data.\n\n### Product Manager\nProduct Manager's identify the needs of the business or shareholder and ensure products designed will meet these needs and requirements. The manager also ensures their team is working in line with the business\u2019s goals.\n\n### Program\/Project Manager\nLike product managers, this position involves ensuring that the program\/project output of the team they lead, is matching the needs and expectations of the business or customer. \n\n### Research Scientist\nResearch Scientist's design and undertake experiments and trials. This is a broad position and the options are endless as to what you can do. \n\n### Software Engineer\nSoftware Engineer's design, develop, maintain and test software. Engineer's work with businesses and shareholders to determine the requirements for the program.\n\n### Statistician\nStatisticians utilise statistical theories and knowledge to analyse and interpret findings related to data. Statisticians\u2019 validation and ensure quality data and report their findings to their businesses\/customers.\n\n### Other\nOther is referred to within this notebook under job titles and refers to any survey respondent who did not feel that their current job title was reflected in any of the options as above.\n\n## 4.2 Education by Job Title\nEducation level varies according to job title. The purpose of this section is to give you an idea about what level of education you should aim for, given a career decision.\u2003\n","6f721b23":"From the above graph, it can clearly be seen that most positions require a bachelor\u2019s degree or a master's degree.\nInteresting to note, is that research scientists seem to hold or be undertaking doctoral degrees, suggesting that this position requires a higher level of study.","d8d8029a":"Out of the Business Intelligence Tools most respondents said they do not use any. Of the ones that do use a tool, Microsoft Power BI and Tableau were the most popular.\n\n# 6. Closing Remarks\n\nReturning to our original question of \"What do I study?\", hopefully this notebook has provided you with the necessary information to begin your self-directed learning journey, to ensure your time spent learning is best utilised.\n\nWhilst what you choose to study will vary depending on career path, if the goal is to maintain employability by ensuring flexibility, then it may be wise to focus on areas that are used across multiple careers (such as Python programming language).\n\nOtherwise, if learning from the beginning and wishing to break into an industry it is wise to focus on what the data tells us, by looking at what are the most used tools\/skills for your respective career. As you continue to learn you can return to this notebook to determine what area of study in which to challenge yourself next.\n\n# References\nCornerstone 2021, *What today's self-directed learning trends tell us about the value of modern learning content*, published 12 May 2021, <https:\/\/www.cornerstoneondemand.com\/resources\/article\/what-todays-self-directed-learning-trends-tell-us-about-the-value-of-modern-learning-content\/>\n\nKen Phillips 2016, 'How Much is Scrap Learning Costing Your Organisation', *Association for Talent Development*, blog, published 10 August 2016,<https:\/\/www.td.org\/insights\/how-much-is-scrap-learning-costing-your-organization>","f3c0d029":"In the heatmap, darker colours correspond to greater average compensation for the job title. Each cell in the heatmap is made up of the corresponding country\/job title pair. \n\nNot all country\/job titles had respondents and the white cells represent these missing data points.\n\nA point to keep in mind is that these compensations are all in USD and may not be a useful comparison tool between countries, as the lower band of compensation for a country may in fact be the same quality of compensation in a high compensated country. Instead, using the interpretation that darker colours are greater compensated positions can be used to determine ideal positions within the rows. \n\nWe can see that not many cells contain data. After examining the number respondents, we also found quite a few entries with data from a low number of individuals.\n\nAs stated [in this cyberlecture](http:\/\/web.pdx.edu\/~newsomj\/pa551\/lecture4.htm ), larger samples better represent the population. For another analysis, we recreated the above heatmap with only data with greater than 30 data points, as this follows the [central limit theorem](https:\/\/www.investopedia.com\/terms\/c\/central_limit_theorem.asp) that 30 is a large enough sample to ensure a fairly representative sample of the population.","989f9c7d":"On a similar thread to automated machine learning models, we see that most respondents use none of the listed options. However following this there appear to be a few respondents that use Google Cloud AutoML\n\n### 5.3.6 Managed Machine Learning Products\nManaged Machine Learning Products refers to the available products to support building and deploying your own machine learning model.","2c7055e7":"Amazon Elastic Compute Cloud (EC2) turned out to be the most used Cloud Computing Product.\n\n## 5.5 Data Storage and Big Data\n\n### 5.5.1 Data Storage Products\nRefers to the different tools available for storing data in the cloud.\n","525127e8":"From the above heatmap, the darker green represents a higher concentration of survey respondents reporting that job title\/industry pairing. \n\nAs expected, the industries that are most popular among respondents include computers\/technology and academics\/education. \nAccounting\/finance seems to also be popular. \n\nData Scientist and Research Scientist positions are popular in the academics\/education industry. Data Scientist, Machine Learning Engineer and Software Engineering are popular responses for respondents from the computers\/technology industry.\nAccounting\/finance seem to have Data Analyst, Data Scientist as well as Software Engineers. \n\n## 4.5 Job Activities\nWhen selecting a career, it is important to consider the day-to-day activities you will be performing along with your personal preference. The following plot shows the proportions of different job activities by job title.","fb2e8c95":"## 4.3 Salaries\nSalaries were included in the Kaggle survey and respondents were able to select ranges for their responses. As numerical data is easier to visualise, the middle value for each range was taken as the response and then averages were able to be taken based off this data. This is not an accurate representation of compensation you may receive, but instead a tool for you to use to compare positions and countries that may be associated with higher compensations. As there were many different countries represented, as well as job titles, first let's look at the average salaries based of all available data from the survey.","8bcb91bf":"As we can see the most used Machine Learning Frameworks across professions is Scikit-learn. It is worth noting that for Developer Relations\/Advocacy Scikit-learn appears to be tied closely with TensorFlow as the most used package framework for the profession.\n\n### 5.3.2 Machine Learning Algorithms\nWithin the ML Frameworks there are different algorithm types. If ML Frameworks are the toolboxes, then ML Algorithms are the tools in the box.","219a1acf":"As we can see above, the most common activity across all job titles is \"Analyse and understand data to influence product or business decisions\". However, in some roles such as Software Engineer, it is not as prevalent.\n\n## 4.6 Concluding Notes for Section 4\nHopefully the above section has provided you with sufficient information to help decide on a career path or at least serve as a starting point. Keep in mind your choice for section 5 as you can tailor your self-directed learning towards the career you wish to pursue.\n\n# 5. Breakdown of Skills\/Tools\/Methods by Job Title\nThe purpose of this section is to help identify where to focus your self-directed learning based on your career path.\n\nMost of the information for this section is presented as bubble charts, with the colour of the bubble showing the use of a specific item proportionate to other items for each Job Title, and the size of the bubble showing the use of an item relative to the number of respondents for each job title. If that's a little confusing this example of how to use it might help.\n\nSay you want to be a Machine Learning Engineer; we can see in terms of programming languages (section 5.2.1) that Python is the most used as it is coloured yellow and comparatively the circle is quite large. Note that the size of the circle and the scale on the right of the chart give us an indication of how many respondents answered the question. Now let's look at computer vision methods (section 5.3.3), we can see that for the Machine Learning Engineer, most respondents who answered the question said they use \"Image classification and other general-purpose networks\", but the bubble is smaller and the scale on the right doesn't go as high. So, what does this mean? It means that less respondents that said they were Machine Learning Engineers selected the image classification option (based on the scale we can assume less than 50%) when compared to the number that selected the Python option.\n\nSo how do we use this information? Remembering the goal is to identify what to learn and in what order. If you already have experience with tools, you'll need to factor that in (as well as current demand in your workplace). To make it simple we recommend:\n1. Creating a list of 1 tool\/method\/skill from each section\/chart, based on your career path.\n2. Order the list by the size of the bubble\/scale, with Programming Language first (5.2.1) and Integrated Development Environment (IDE) second (5.2.2). \n\nFor example, if your career path is data scientist you might start with Python --> Jupyter Notebook --> Matplotlib --> Scikit-Learn --> Linear\/Logistic Regression --> etc.\n\nEssentially, you're making a list of what's relevant to you and learning the most used first (larger bubbles).\n\nThis section categorises items into Learning Tools, Basic Tools, Machine Learning, Cloud Computing, Data Storage and Big Data, and Business Intelligence\n\n\n\n## 5.1 Learning Tools\nThere are many tools available to you online that provide you with the opportunity to learn\/refine your data science skills. Kaggler's listed platforms that they have used, and we aim to investigate which platforms are the most popular.\n","a4703597":"As we can see Python is the most used programming language across the programming languages for the relevant careers with SQL being second most common.\n### 5.2.2 Integrated Development Environments (IDEs)\nAn IDE is a software tool that combines different developer tools. Think of it as the platform on which you will be writing your code.","27d1c1c3":"Big Data Products had quite a wide dispersion, indicating the professionals aren\u2019t gravitating, entirely to 1 or 2 platforms. MySQL however appeared to be the most used followed by both Microsoft SQL Server and PostgreSQL.\n\n## 5.6 Business Intelligence Tools\nBusiness Intelligence Tools refer to the tools\/products used to generate useful insights\/information from raw data.","98532eb7":"Out of the Data Storage Products, Amazon Simple Storage Service appeared to be the most used.\n\n### 5.5.2 Big Data Products\nBig data products refer to the products available for handling large datasets that would struggle on conventional applications.","ed2e2860":"As we can see the most used Machine Learning Framework across professions is Linear or Logistic Regression. It is worth noting that for Machine Learning Engineers, Convolutional Neural Networks come a very close second.\n\n### 5.3.3 Computer Vision Methods\nComputer vision methods refer to methods for computers to gain meaningful information from digital images or videos. Similar to ML algorithms, computer vision methods are another type of tool in the box, so if ML algorithms are the different types of screwdrivers, then computer vision methods would be the hammers.","105e5d87":"# 1. Introduction\nSelf-directed learning has always been a cornerstone of the data science and machine learning industry (as anyone who has spent hours crawling through documentation on APIs, packages and SDKs can testify!). \n\nThis has become even more critical since the advent of COVID-19 as employees, job hunters and students scramble to develop skills to increase adaptability and flexibility in the workplace and job market. Between Q1 2020 and Q1 2021, online self-directed learning has seen a 3x increase globally, with certain regions like Asia seeing a 5x increase (Cornerstone on Demand 2021).\n\nSo we can agree that self-directed learning is key, but for any would-be learner this now begs the question of \"What do I learn?\".\n\nA 2014 white paper by CEB revealed that in the average organisation, 45% of all learning delivered ends up not being applied, with a 2004 study putting that number closer to 80-85% (Ken Phillips 2016). That's astronomical!\n\nThere is no doubt that the question of **\"What** do I learn?\" in an age where information is so abundant, is the most important question of all.\n\n# 2. Our Goal\nThis notebook will serve as a practical guide for self-directed learners, to help them identify the areas of study relevant to them by utilising a data driven approach.\n\nSection 4 \"Information on Job Titles\" has been designed for individuals looking to select or switch career paths. By examining the various attributes (such as salary and job activities) of different careers within the data science and machine learning industry, individuals can identify which may best suit them to begin their self-learning journey.\n\nSection 5 \"Breakdown of Skills\/Tools\/Methods by Job Title\" has been designed to help individuals select areas of study that will be relevant to them based on the career path they are pursuing (or if they don't know what career yet then they can see what areas of study will be useful across the different careers).\n\n# 3. The Dataset\n\n## 3.1 Description\nThe dataset used comes from an industry wide survey for data science and machine learning held from 09\/01\/2021 to 10\/04\/2021 with 25,973 valid responses from 171 countries and territories.\n\nQuestions were asked as a multichoice with many allowing for multiple selection.\nGo to https:\/\/www.kaggle.com\/c\/kaggle-survey-2021\/data for a full breakdown of the survey and the raw data.\n\n## 3.2 Managing Bias\nAs the data is collected via survey rather than random sample, we must be aware of the inherent bias with this method. \n\nOne major concern was the bias in the countries in which respondents were based. As such we have avoided making sum-based comparisons between countries such as \"number of respondents from India with a master\u2019s degree compared to number of respondents from Australia with a master\u2019s degree\" and instead have looked at these as a proportion relative to the country, for example \"Of the respondents from India, what proportion have a master\u2019s degree\". \n\nAnother concern was a difference in respondents from each job title, once again we have used proportions rather than sum comparisons. For example, rather than asking \"How many data scientists use Python\" we ask \"What proportion of data scientists use Python\".\n\nThe exception to this is section 4.3 \"Industry Breakdown\". This is as job titles with lower respondents would skew the visualisation when comparing across industry, additionally it is useful to see the respondents broken down by industry and job title.\n\n## 3.3 Processing The Data Set\nAs the data was already pre-processed (see \"kaggle_survey_2021_methodology.pdf\" in the \"supplementary data\" folder of the dataset), we only needed to pre-process the data relative to our objective. Given that the objective of the notebook was to look at areas of study based on what is used by industry professionals, respondents who answered \"Student\" or \"Currently Not Employed\" to Question 5 \"Select the title most similar to your current role (or most recent title if retired)\", were removed from the dataset, leaving us with 17,182 valid respondents.\n\nAn additional note on data quality is the presence of null values for some multiple select answers, whilst one option was to potentially impute the option of \"None\" where a question was not answered, this runs the risk of skewing the data as we cannot guarantee that \"None\" was the intended answer, as such the null values have not been changed. On the bubble charts in section 5, the size of the bubble and the scale on the right of the graph gives and rough indication of what proportion of survey respondents provided used any specific item.\n","27b6b464":"As we can see, Jupyter Notebook is the most used IDE across the relevant professions followed by Visual Studio Code. It is worth noting that the statistician career path stands apart with RStudio being the most used IDE.\n\n### 5.2.3 Hosted Notebooks\nA Notebook is a type of IDE that also supports text elements. A Hosted Notebook is simply a notebook hosted online, often used for working collaboratively with others.","cc896d02":"As we can see the most used NLP Method is Word Embedding\/Vectors which is most used by Machine Learning Engineers, however only about 20-30% answered that they use these methods.\n\n### 5.3.5 Automated Machine Learning\nAutomated Machine Learning (AutoML) refers to automating the steps involved in applying machine learning solutions. If ML Algorithms are the screw drivers than AutoML are the power drills.\n\n#### 5.3.5.1 AutoML Techniques\nWithin the machine learning process there are several different steps, AutoML techniques refers to the different steps for machine learning that can be automated. If delivering a presentation to your manager is the machine learning process, then having a computer make the presentation slides for you would be one of the AutoML techniques.","e9995e8b":"As visibile above the majority of primary tools used across professions are local development environments and basic statistical software. However as to which of those 2 are prioritised in your self-directed learning will be dependent on your selected career path.\n\n## 5.3 Machine Learning (ML)\nMachine Learning refers to algorithms that improve an analytical model automatically as they look over more data.\n\n### 5.3.1 Machine Learning Frameworks\nRefers to the frameworks and libraries used in machine learning. Think of these like the toolbox for machine learning, like our data visualisation libraries, rather than having to program everything from scratch, you can use these frameworks to run ML algorithms with only a few lines of code.","bc849d83":"As we can see the most used Cloud computing platforms were Amazon Web Services, followed by Google Cloud Platform, although only a little over 30% of Data Engineers and Data Scientists from the pool of respondents answered that they use AWS.\n\n### 5.4.2 Cloud Computing Products\nCloud Computing Products refers to the products available on each platform. To stick with our car example if the platform is the make, the product is the model.","a53d70f4":"As we can see, Image classification and other general-purpose networks are the most used computer vision methods. There are 2 points of interest here, first is that Machine Learning Engineers appear to use comparatively more computer vision methods, second is that only approximately 40% of ML Engineers answered that they use Image classification, this makes it less of a priority for self-directed learning than say Python as a programming language in which over 90% of Machine Learning Engineers answered that they use.\n\n### 5.3.4 Natural Language Processing (NLP) Methods\nNLP methods refers to the methods in which computers gain meaningful information from natural language such as speech and text. Once again, as with ML algorithms and computer vision methods these are a completely different type of tool in the toolbox.","0692553a":"As we can see most respondents do not use automated machine learning models at this time. However, there are still a small number of respondents in each profession that do. Whilst this means that it may not be an initial point of self-directed learning, it could also be a skill that once developed would provide an individual with a competitive edge in the job market (provided there is demand for the skill). The most viable selection in this case would be based on chosen career path.\n\n#### 5.3.5.2 AutoML Tools\nAutoML Tools refers to the tools are used to carry out the techniques in the previous section. If automatically building presentation slides is an AutoML technique then Microsoft PowerPoint would be an AutoML tool.","ef2ced0b":"As we can see most respondents do not use a machine learning management tool, the exception here is Machine Learning Engineers which use TensorBoard more than any other ML management tool.\n\n## 5.4 Cloud Computing\nCloud computing is essentially performing computing tasks but, on the cloud, rather than on your local device.\n\n### 5.4.1 Cloud Computing Platforms\nCloud computing platforms simply refer to the platforms\/providers that can facilitate cloud computing. If we consider cloud computing to be a car, cloud computing platforms are simply the different makes.","b9bf88c6":"As we can see most respondents do not use any of the managed machine learning products listed. Out of the remaining options the most viable to study will be dependent on chosen career path.\n\n### 5.3.7 Machine Learning Management Tools\nMachine Learning Management Tools refers to the tools\/products for managing your machine learning experiments."}}