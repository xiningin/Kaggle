{"cell_type":{"d7abd541":"code","c26cc0d6":"code","93a90ff8":"code","66a7cb51":"code","ac77a117":"code","36a90f6b":"code","50a08db8":"code","1e394c51":"code","d604ab1d":"code","3a0b5a2e":"code","0822bf05":"code","c48add30":"code","344d76a1":"code","38df9a99":"code","a2bb64d6":"code","fe6d879a":"code","2de2c389":"code","bc3f5f53":"code","27d350d0":"code","f1c40ae6":"code","62973451":"code","92405f4a":"code","7d696822":"code","645ba1db":"code","9a968b6e":"code","d2275e3f":"code","e9c7537d":"code","bbc5984a":"code","f84d8886":"code","c5a7cfbc":"code","8cb3a154":"code","4618b2f3":"code","d96e1099":"markdown","1062cbb2":"markdown","e7fb2d16":"markdown","3dbe20c8":"markdown","abe9d933":"markdown","d0018ca5":"markdown","24e88244":"markdown","620257d8":"markdown","b89b9f15":"markdown","ee0599f8":"markdown","4ba7b053":"markdown","575223a5":"markdown","a8189b31":"markdown","b0e01a49":"markdown","b64ecaa7":"markdown","c42e3b24":"markdown","fc55e939":"markdown","1d9702b4":"markdown","c8e1c8ba":"markdown","bbe68e51":"markdown","333d8c03":"markdown","33ed07d1":"markdown","16002e7d":"markdown","fc20c8ad":"markdown"},"source":{"d7abd541":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom functools import reduce\nfrom sklearn.preprocessing import FunctionTransformer, StandardScaler, PowerTransformer, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, cross_validate, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_log_error\nimport holoviews as hv\nhv.extension('bokeh')\n\nfrom xgboost import XGBRegressor\n\nfrom sklearn.linear_model import LinearRegression, ElasticNetCV\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n%matplotlib inline\nprint(os.listdir(\"..\/input\"))\n\n","c26cc0d6":"relu = np.vectorize(lambda x: x if x>0.0 else 0.0)\n\ndef create_feat_len(df, feat_name):\n    _df = df.copy()\n    _df[f\"{feat_name}_count\"] = _df[feat_name].str.count(\"name\")\n    return _df\n\ndef split_x_y(df, target=\"revenue\"):\n    return df.drop(columns=[target]), df[target]\n\ndef cross_val_pipeline(pipe, X, y):\n    res = cross_val_score(pipe, X, y, scoring=\"neg_mean_squared_error\", cv=5, n_jobs=2)\n    res = np.sqrt(-res)\n    mean_res, std_res = np.mean(res), np.std(res)\n    print(f\"RMSLE: {mean_res:2.3} +- {std_res:3.2}\")","93a90ff8":"df_train = pd.read_csv(\"..\/input\/tmdb-box-office-prediction\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/tmdb-box-office-prediction\/test.csv\")\n\ndf_train.head()","66a7cb51":"df_train.isna().mean()","ac77a117":"df_aux = df_train.copy()\ndf_aux['release_date'] = pd.to_datetime(df_aux.release_date)\ndf_dates_to_correct = df_aux['release_date'] > pd.datetime(2019, 2, 1)\ndf_aux.loc[df_dates_to_correct, 'release_date'] = df_aux.loc[df_dates_to_correct, 'release_date']\\\n                                                            .apply(lambda t: pd.datetime(t.year-100, t.month, t.day))\ndf_aux = df_aux.set_index(\"release_date\").sort_index()\n# df_aux.resample(\"Y\").mean().revenue.plot()\ndf_aux[\"is_american\"] = df_aux.production_countries.str.contains(\"United States of America\")","36a90f6b":"plt.figure(figsize=(18,5))\ndf_aux.revenue.rolling('180d').mean().plot(label='90 rolling mean')\ndf_aux.revenue.rolling('180d').quantile(0.9).plot(label='90 rolling quantile 90')\nplt.grid()\nplt.legend()\nplt.show()\n\ndf_aux2 = df_aux[~df_aux.is_american.isna()]\ndf_aux2[\"is_american\"]=df_aux2[\"is_american\"].astype(np.bool)\nplt.figure(figsize=(18,5))\ndf_aux2[df_aux2.is_american].resample(\"y\").mean().revenue.dropna().plot(label=\"American movie\")\ndf_aux2[~df_aux2.is_american].resample(\"y\").mean().revenue.dropna().plot(label='Non American movie')\nplt.ylabel(\"Revenue\", fontsize=14)\nplt.xlabel(\"Release date\", fontsize=14)\nplt.title(\"Average revenue per year of American and Non-american movies\", fontsize=14)\nplt.legend(fontsize=14)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","50a08db8":"df_train_clean = pd.read_csv('..\/input\/moviestmdb-datapreparation\/train_prep.csv')","1e394c51":"best_movies = df_train.sort_values(by='revenue', ascending=False).iloc[:10]","d604ab1d":"best_movies[[\"original_title\", \"popularity\", \"budget\", \"release_date\",\"revenue\"]].set_index(np.arange(1,11))","3a0b5a2e":"## 5 best actors","0822bf05":"l_actors = [c for c in df_train_clean.columns if \"cast_name\" in c]\nl_series_of_actors=[]\nfor c in l_actors:\n    asd =df_train_clean[df_train_clean[c]==1].agg({\"revenue\":\"mean\",\"budget\":\"mean\",\"popularity\":\"mean\"})\n    asd.name=c.replace(\"cast_name_\",\"\")\n    l_series_of_actors.append(asd)\ndf_actors = pd.DataFrame(l_series_of_actors).reset_index()\ndf_actors.sort_values(by='revenue', ascending=False).iloc[:10].set_index(np.arange(1,11)).rename(columns={\"index\":\"Actor\"})","c48add30":"plt.scatter(df_actors.popularity, \n            df_actors.budget)\n# plt.scatter(df_actors.popularity, \n#             df_actors.revenue)","344d76a1":"asd =df_train_clean[df_train_clean[l_actors[0]]==1].agg({\"revenue\":\"mean\",\"budget\":\"mean\",\"popularity\":\"mean\"})\nasd.name=l_actors[0].replace(\"cast_name_\",\"\")\npd.DataFrame([asd])","38df9a99":"df_aux = df_train.copy()\ndf_aux[\"is_american\"] = df_aux.production_countries.str.contains(\"United States of America\")\ndf_aux[\"revenue\"]=df_aux.revenue.apply(np.log1p)\ndf_aux = df_aux.dropna(subset=[\"is_american\"])\ndf_aux[\"is_american\"] = df_aux[\"is_american\"].astype(np.bool)\n\nplt.figure(figsize=(7,4))\nsns.distplot(df_aux[df_aux['is_american']].revenue, label='American')\nsns.distplot(df_aux[~df_aux['is_american']].revenue, label='Non American')\nplt.legend()\nplt.show()","a2bb64d6":"\nplt.hist(df_aux[df_aux['is_american']].revenue, label='Non American', alpha=0.5)\nplt.hist(df_aux[~df_aux['is_american']].revenue, label='Non American', alpha=0.5)","fe6d879a":"df_aux2 = df_aux[~df_aux.is_american.isna()]\ndf_aux2[\"is_american\"]=df_aux2[\"is_american\"].astype(np.bool)\nplt.figure(figsize=(18,5))\ndf_aux2[df_aux2.is_american].resample(\"y\").mean().revenue.dropna().plot(label=\"american movie\")\ndf_aux2[~df_aux2.is_american].resample(\"y\").mean().revenue.dropna().plot(label='non american movie')\nplt.ylabel(\"Revenue\", fontsize=14)\nplt.xlabel(\"Release Date\", fontsize=14)\nplt.title(\"Revenue for American vs Non-american movies\", fontsize=14)\nplt.legend(fontsize=14)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\n# plt.ylim(0,2)\nplt.show()","2de2c389":"plt.figure(figsize=(18,5))\ndf_aux[df_aux.original_language=='en'].revenue.rolling('30d').mean().plot(label='90 rolling mean revenue of english movies')\ndf_aux[df_aux.original_language!='en'].revenue.rolling('30d').mean().plot(label='90 rolling mean revenue of non-english movies')\nplt.grid()\nplt.legend()\nplt.show()","bc3f5f53":"df_train.status.value_counts()","27d350d0":"df_train[\"has_homepage\"] = (~df_train.homepage.isna()).astype(int)","f1c40ae6":"sns.distplot(df_train[1==df_train.has_homepage].revenue, kde=False)\nsns.distplot(df_train[0==df_train.has_homepage].revenue, kde=False)\nplt.yscale(\"log\")","62973451":"df_aux = df_train.copy().dropna(subset=[\"production_countries\"])\ndf_aux[\"is_american\"] = df_aux.production_countries.str.contains(\"United States of America\")\n\nsns.distplot(df_aux[df_aux.is_american].revenue, kde=False, label=\"Yes\")\nsns.distplot(df_aux[~df_aux.is_american].revenue, kde=False, label=\"No\")\nplt.title(\"Is the film american?\")\nplt.yscale(\"log\")\nplt.legend()\nplt.show()","92405f4a":"df_aux = df_train.copy().dropna(subset=[\"original_language\"])\ndf_aux[\"is_english\"] = df_aux.original_language==\"en\"\n\nsns.distplot(df_aux[df_aux.is_english].revenue, kde=False, label=\"Yes\")\nsns.distplot(df_aux[~df_aux.is_english].revenue, kde=False, label=\"No\")\nplt.title(\"Is the film english?\")\nplt.yscale(\"log\")\nplt.legend()\nplt.show()","7d696822":"df_aux = df_train.copy()\ndf_aux[\"belongs_to_a_collection\"] = ~df_aux.belongs_to_collection.isna()\n\nsns.distplot(df_aux[df_aux.belongs_to_a_collection].revenue, kde=False, label=\"Yes\")\nsns.distplot(df_aux[~df_aux.belongs_to_a_collection].revenue, kde=False, label=\"No\")\nplt.title(\"Is the film english?\")\nplt.yscale(\"log\")\nplt.legend()\nplt.show()","645ba1db":"ref_date = pd.datetime(2019, 2, 1)\nl_complex_feats = [\"production_companies\", \"production_countries\", \"spoken_languages\", \"cast\", \"crew\"]\ndef apply_custom_transformations(df):\n    df_res = reduce(create_feat_len, l_complex_feats, df.copy())\n    df_res[\"has_homepage\"] = (~df_res.homepage.isna()).astype(np.float)\n    df_res[\"is_english\"] = (df_res.original_language==\"en\").astype(np.float)\n    df_res[\"is_american\"] = df_res.production_countries.str.contains(\"United States of America\").astype(np.float)\n    df_res[\"belongs_to_a_collection\"] = (~df_res.belongs_to_collection.isna()).astype(np.float)\n    df_res['release_date'] = pd.to_datetime(df_res.release_date)\n    df_dates_to_correct = df_res['release_date'] > ref_date\n    df_res.loc[df_dates_to_correct, 'release_date'] = df_res.loc[df_dates_to_correct, 'release_date']\\\n                                                                .apply(lambda t: pd.datetime(t.year-100, t.month, t.day))\n    df_res['days_since_release'] = (df_res.release_date - ref_date).dt.days\n    df_res = df_res.select_dtypes(np.number).set_index(\"id\")\n    \n    # if train move target column to last\n    if 'revenue' in df_res.columns:\n        df_res = df_res[df_res.columns.drop(\"revenue\").tolist() + [\"revenue\"]]\n        df_res['revenue'] = np.log(df_res['revenue'])\n    return df_res\n\ncustom_transformer = FunctionTransformer(apply_custom_transformations, validate=False)\ndf_FE=custom_transformer.fit_transform(df_train)","9a968b6e":"# sns.pairplot(df_FE, diag_kind='kde', markers = '+')\n# plt.show()","d2275e3f":"sns.heatmap(df_FE.corr())","e9c7537d":"X, y = split_x_y(df_train)\nlogy = np.log(y)","bbc5984a":"pipe = make_pipeline(custom_transformer, SimpleImputer(strategy='median'), StandardScaler(), \n                    ElasticNetCV(cv = 5, n_jobs=2))\ncross_val_pipeline(pipe, X, logy)","f84d8886":"pipe = make_pipeline(custom_transformer, SimpleImputer(strategy='median'), StandardScaler(), \n                    XGBRegressor(booster='gblinear', n_estimators=500, n_jobs=2))\ncross_val_pipeline(pipe, X, logy)","c5a7cfbc":"model = XGBRegressor(max_depth=5, n_estimators=50)\npipe = make_pipeline(custom_transformer, SimpleImputer(strategy='median'), StandardScaler(), model)\ncross_val_pipeline(pipe, X, logy)","8cb3a154":"# points = hv.Points(pd.DataFrame([y_pred, np.log(y_val)], index=[\"y_pred\",\"y_true\"]).T)\n# points","4618b2f3":"pipe.fit(X, logy)\nlogy_pred_test = pipe.predict(df_test)\ny_pred_test = np.exp(logy_pred_test)\n\ndf_pred = df_test[['id']].copy()\ndf_pred['revenue']=y_pred_test\ndf_pred.to_csv(\"submission_1.csv\", index=False)","d96e1099":"Nope...","1062cbb2":"## What about being in english?","e7fb2d16":"## Homepage exists is relevant?","3dbe20c8":"# Released feature - is it useful?","abe9d933":"# top 5 movies in rev and ","d0018ca5":"## 0. Data extraction: import and show data","24e88244":"# 1. Data exploration: Hypothesis validation","620257d8":"Yes!","b89b9f15":"## Does it matter if belongs to collection?","ee0599f8":"Yes!","4ba7b053":"### utils","575223a5":"## Missing values","a8189b31":"# Is the date of release relevant?","b0e01a49":"Yes!!","b64ecaa7":"### Linear regression","c42e3b24":"## Adding count of complex features (crew, cast, etc)","fc55e939":"## Does it matter if the film is american or not?","1d9702b4":"### imports","c8e1c8ba":"# TMDB Revenue prediction - simple baseline using only numeric features + length of complex ones","bbe68e51":"### XGB with linear regressor booster","333d8c03":"Yes!!","33ed07d1":"# American vs non american movies","16002e7d":"### XGB with regressor trees","fc20c8ad":"# 2. Training: Time to start predicting"}}