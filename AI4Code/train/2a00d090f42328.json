{"cell_type":{"1c8f0326":"code","135c485c":"code","b2c82314":"code","bb431a63":"code","928493d4":"code","a157db31":"code","437f21ec":"code","167d0d7d":"code","f8d2ae33":"code","9cd920a3":"code","116e5b35":"code","b5a44695":"code","6f2d8cee":"code","43c60907":"code","dd6ca3de":"code","646e8341":"code","ce55e4d2":"code","abb00dc9":"code","ca83fbeb":"code","1a218321":"code","ce470faa":"code","a3bdb0d3":"code","50a0b0ac":"code","448b8c97":"code","d5547b3c":"code","fcc00098":"code","08343e34":"code","1b23de8d":"code","f7c14d02":"code","5a7c83cc":"code","4982bece":"code","a0166797":"code","932d4bb7":"markdown","84627618":"markdown","482da497":"markdown","bd585860":"markdown","340cce87":"markdown","e2c06b00":"markdown","81c75722":"markdown","23b9f9db":"markdown","9f3a272d":"markdown","d6b1a25b":"markdown","3b0e9d90":"markdown","f3b7c51e":"markdown"},"source":{"1c8f0326":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","135c485c":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns; sns.set()\nfrom sklearn.externals import joblib\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\n\nfrom xgboost import XGBRegressor\n\nimport gc\nfrom itertools import product\nimport time\n\nfrom bayes_opt import BayesianOptimization\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom bayes_opt.logger import JSONLogger\nfrom bayes_opt.event import Events","b2c82314":"all_data = pd.read_pickle(\"\/kaggle\/input\/eda-with-feature-engineering\/all_data.pkl\")\nall_data.head()","bb431a63":"test_items = all_data.loc[all_data['date_block_num']==34,'item_id'].unique()\ntrain_items = all_data.loc[all_data['date_block_num']<34,'item_id'].unique()\nitems_in_test_and_not_in_train = set(test_items).difference(set(train_items))\nprint('Items in test and not in train: {0}'.format(len(items_in_test_and_not_in_train)))\nitems_in_train_and_not_in_test = set(train_items).difference(set(test_items))\nprint('Items in train and not in test: {0}'.format(len(items_in_train_and_not_in_test)))\n\ntest_shops = all_data.loc[all_data['date_block_num']==34,'shop_id'].unique()\nprint('Number of unique shops: {0}'.format(len(test_shops)))\n","928493d4":"missing_shop_item_count = 378 * 42 # all missing item per shop ===> 15876\nindex_cols = ['shop_id', 'item_id', 'date_block_num']\n\ngrid = []\nfor block_num in all_data.loc[all_data['date_block_num']<34, 'date_block_num'].unique():\n    print(block_num)\n    \n    zero_target_df = all_data[(all_data['date_block_num'] == block_num) & (all_data['target']==0) & \n                              (all_data['item_id'].isin(items_in_train_and_not_in_test))]\n    \n    idx_to_delete = zero_target_df.sample(missing_shop_item_count, random_state=block_num).index\n    all_data.drop(idx_to_delete, inplace=True)\n    temp = np.array(list(product(*[test_shops, items_in_test_and_not_in_train, [block_num]])),dtype='int32')\n    grid.append(temp)\n    \n    del zero_target_df\n    del idx_to_delete\n    del temp\n    gc.collect()\n\n#     I think grid is all items that a specific shop(in train data) didn't have in each month\n# \u06cc\u0639\u0646\u06cc \u0627\u062c\u0646\u0627\u0633\u06cc \u06a9\u0647 \u0647\u0631 \u0645\u063a\u0627\u0632\u0647 \u062f\u0631 \u0645\u0627\u0647 \u0647\u0627\u06cc \u0642\u0628\u0644 \u06f3\u06f4 \u0646\u0641\u0631\u0648\u062e\u062a\u0647 (\u06cc\u0627 \u0647\u0645\u0648\u0646 \u0646\u062f\u0627\u0634\u062a\u0647 \u06a9\u0647 \u0628\u0641\u0631\u0648\u0634\u0647 )\n#  non of grid rows are in all_data\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n    \n    ","a157db31":"grid['shop_id'] = grid['shop_id'].astype(np.int16)\ngrid['item_id'] = grid['item_id'].astype(np.int32)\ngrid['date_block_num'] = grid['date_block_num'].astype(np.int8)","437f21ec":"all_data = pd.concat([all_data, grid], ignore_index=True, sort=False, keys=index_cols)\nall_data[['item_shop_last_sale', 'item_last_sale']].fillna(-1, inplace=True) #-1 is default value in this columns\nall_data.fillna(0, inplace=True)\n\ndel grid\ndel test_items\ndel test_shops\ndel train_items\ndel items_in_test_and_not_in_train\ndel items_in_train_and_not_in_test\ngc.collect()","167d0d7d":"all_data","f8d2ae33":"all_data['is_december'] = all_data['is_december'].astype(np.int8)\nall_data['item_category_id'] = all_data['item_category_id'].astype(np.int8)\nall_data['type_code'] = all_data['type_code'].astype(np.int8)\nall_data['subtype_code'] = all_data['subtype_code'].astype(np.int8)\nall_data['city_code'] = all_data['city_code'].astype(np.int16)\n\nall_data['month'] = all_data['month'].astype(np.int8)\nall_data['days'] = all_data['days'].astype(np.int8)\nall_data['item_shop_last_sale'] = all_data['item_shop_last_sale'].astype(np.int8)\nall_data['item_last_sale'] = all_data['item_last_sale'].astype(np.int8)\nall_data['item_shop_first_sale'] = all_data['item_shop_first_sale'].astype(np.int8)\nall_data['item_first_sale'] = all_data['item_first_sale'].astype(np.int8)","9cd920a3":"# we added some rows to balance ditribution of our dataset so we need put those new rows in right position\n# put added rows in right position\nall_test_data = all_data[all_data['date_block_num'] == 34]\nall_data = all_data[all_data['date_block_num'] < 34]\nall_data.sort_values(['date_block_num'], inplace=True)\nall_data = pd.concat([all_data, all_test_data], ignore_index=True, sort=False, keys=index_cols)\n\ndel all_test_data\ngc.collect()\n","116e5b35":"dates = all_data['date_block_num']\n\nlast_block = dates.max()\nprint('Test `date_block_num` is {0}'.format(last_block))\n\nX_train = all_data.loc[dates <  last_block]\nX_test =  all_data.loc[dates == last_block]\n\ny_train = all_data.loc[dates <  last_block, 'target'].values\ny_test =  all_data.loc[dates == last_block, 'target'].values\n\nX_valid_train = all_data.loc[dates <  last_block-1]\nX_valid_test =  all_data.loc[dates == last_block-1]\n\ny_valid_train = all_data.loc[dates <  last_block-1, 'target'].values\ny_valid_test =  all_data.loc[dates == last_block-1, 'target'].values\n\nall_data.to_pickle('all_data.pkl') # will use it later. Now free RAM\n\ndel dates\ndel all_data\ngc.collect()","b5a44695":"# delete some rows from test\ncolumns_to_delete = ['date_block_num', 'target']\nX_valid_train = X_valid_train.drop(columns_to_delete, axis=1)\nX_valid_test = X_valid_test.drop(columns_to_delete, axis=1)\n\nX_train = X_train.drop(columns_to_delete, axis=1)\nX_test = X_test.drop(columns_to_delete, axis=1)","6f2d8cee":"#  we need list of column_names in lgb.Dataset()\npredictors = X_valid_train.columns.tolist()","43c60907":"bayesian_tr_index, bayesian_val_index = list(StratifiedKFold(2, random_state=12, shuffle=True).split(X_valid_train, y_valid_train))[0]","dd6ca3de":"# in bayesian optimization we need to have a black box. this black box is our algorithm which we want to optimize\ndef lgb_black_box(\n    num_leaves,  # int\n    min_data_in_leaf,  # int\n    learning_rate,\n    min_sum_hessian_in_leaf,    # int  \n    feature_fraction,\n    lambda_l1,\n    lambda_l2,\n    min_gain_to_split,\n    max_depth):\n    \n    # lgb need some inputs as int but BayesianOptimization library send continuous values values. so we change type.\n\n    num_leaves = int(num_leaves)\n    min_data_in_leaf = int(min_data_in_leaf)\n    max_depth = int(max_depth)\n    \n    # all this hyperparameter values are just for test. our goal in this kernel is how to use bayesian optimization\n    # you can see lgb documentation for more info about hyperparameters\n    params = {\n        'num_leaves': num_leaves,\n        'max_bin': 63,\n        'min_data_in_leaf': min_data_in_leaf,\n        'learning_rate': learning_rate,\n        'min_sum_hessian_in_leaf': min_sum_hessian_in_leaf,\n        'bagging_fraction': 1.0,\n        'bagging_freq': 5,\n        'feature_fraction': feature_fraction,\n        'lambda_l1': lambda_l1,\n        'lambda_l2': lambda_l2,\n        'min_gain_to_split': min_gain_to_split,\n        'max_depth': max_depth,\n        'save_binary': True, \n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'rmse',\n        'is_unbalance': True,\n        'boost_from_average': False, \n    }\n    \n    train_data = lgb.Dataset(X_valid_train.iloc[bayesian_tr_index].values,\n                            label = y_valid_train[bayesian_tr_index],\n                            feature_name=predictors,\n                            free_raw_data = False)\n    \n    \n    validation_data = lgb.Dataset(X_valid_train.iloc[bayesian_val_index].values,\n                                 label= y_valid_train[bayesian_val_index],\n                                 feature_name=predictors,\n                                 free_raw_data=False)\n    \n    num_round = 5000\n    clf = lgb.train(params, train_data, num_round, valid_sets = [validation_data], verbose_eval=250,\n                 early_stopping_rounds = 50)\n    \n    predictions = clf.predict(X_valid_train.iloc[bayesian_val_index].values,\n                              num_iteration = clf.best_iteration)\n    \n#      we need to compute a regression score. roc_auc_score is a classification score. we can't use it\n#     score = metrics.roc_auc_score(y_valid_train[bayesian_val_index], predictions)\n    mse = mean_squared_error(y_valid_train[bayesian_val_index], predictions)\n    rmse = np.sqrt(mse)\n#     our bayesian optimization expect us to give him increasing number to understand this is getting better\n    return -rmse","646e8341":"# these ranges are not best range for this competition, I just use these base ranges\nLGB_bound = {\n    \"num_leaves\" : (5, 20),\n    \"min_data_in_leaf\" : (5, 20),\n    \"learning_rate\" : (0.01, 0.3),\n    \"min_sum_hessian_in_leaf\" : (0.00001, 0.01),\n    \"feature_fraction\" : (0.05, 0.5),\n    \"lambda_l1\" : (0, 5.0),\n    \"lambda_l2\" : (0, 5.0),\n    'min_gain_to_split': (0, 1.0),\n    'max_depth':(3,15)\n}","ce55e4d2":"from bayes_opt import BayesianOptimization\n\n#  we have 3 parameters for this object. first is function. second is ranges. third is random_state (no matter)\noptimizer = BayesianOptimization(\n    f=lgb_black_box,\n    pbounds = LGB_bound,\n    random_state = 13\n)\nprint(optimizer.space.keys)","abb00dc9":"init_points = 3\nn_iter = 3\n\noptimizer.maximize(init_points = init_points, n_iter = n_iter)","ca83fbeb":"optimizer.max[\"params\"]","1a218321":"# here i say hey optimizer! search for this new parameter to see if they are really better or not.\n# probe = \u06a9\u0627\u0648\u0634\n#  tmp code\n#  feature fraction = 0.3064, l1=  2.659,  l2 =   0.3892, learning =  0.1054,\n# max_depth = 14.76, min_da  19.7,   min_ga = 0.6548,   min_su = 0.000626, num_lea 19.06\n\noptimizer.probe(\n    params = {\n        'feature_fraction': 0.3064, \n            'lambda_l1': 2.659, \n            'lambda_l2': 0.3892, \n            'learning_rate': 0.1054, \n            'max_depth': 14.76, \n            'min_data_in_leaf': 19.7, \n            'min_gain_to_split': 0.6548, \n            'min_sum_hessian_in_leaf': 0.000626, \n            'num_leaves': 19.06\n    },\n    lazy = False\n)\n# if lazy= True  it will run next time I say .maximize\n# if lazy = False it will run the optimizing right now.","ce470faa":"optimizer.max[\"params\"]","a3bdb0d3":"\noptimized_lgb_params = {\n        'num_leaves': int(optimizer.max[\"params\"][\"num_leaves\"]),\n        'max_bin': 63,\n        'min_data_in_leaf': int(optimizer.max[\"params\"][\"min_data_in_leaf\"]),\n        'learning_rate': optimizer.max[\"params\"][\"learning_rate\"],\n        'min_sum_hessian_in_leaf': optimizer.max[\"params\"][\"min_sum_hessian_in_leaf\"],\n        'bagging_fraction': 1.0,\n        'bagging_freq': 5,\n        'feature_fraction': optimizer.max[\"params\"][\"feature_fraction\"],\n        'lambda_l1': optimizer.max[\"params\"][\"lambda_l1\"],\n        'lambda_l2': optimizer.max[\"params\"][\"lambda_l2\"],\n        'min_gain_to_split': optimizer.max[\"params\"][\"min_gain_to_split\"],\n        'max_depth': int(optimizer.max[\"params\"][\"max_depth\"]),\n        'save_binary': True, \n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'rmse',\n        'is_unbalance': True,\n        'boost_from_average': False, \n    }\n    ","50a0b0ac":"nfold = 5\nimport gc\ngc.collect()\nskf2 = StratifiedKFold(n_splits = nfold, shuffle = True, random_state=68)","448b8c97":"predictions1 = np.zeros((len(y_test), nfold))\ni = 1\nfor train_index, val_index in skf2.split(X_train, y_train):\n    train_set_lgb = lgb.Dataset(X_train.iloc[train_index][predictors].values,\n                                label= y_train[train_index],\n                                feature_name= predictors,\n                                free_raw_data=False)\n    \n    val_set_lgb = lgb.Dataset(X_train.iloc[val_index][predictors].values,\n                                label= y_train[val_index],\n                                feature_name= predictors,\n                                free_raw_data=False)\n    clf = lgb.train(optimized_lgb_params, train_set_lgb, 5000, valid_sets = [val_set_lgb],\n                   verbose_eval=250, early_stopping_rounds = 50)\n    \n    predictions1[:,i-1] += clf.predict(X_test[predictors], num_iteration=clf.best_iteration)\n    i = i + 1\n\n\n","d5547b3c":"su=[sum(i) for i in predictions1]\nnewList = [ x \/ 5 for x in su]\nnewList","fcc00098":"clipedList = [20 if x > 20 else x  for x in newList ]","08343e34":"submit3 = pd.DataFrame({'ID':range(214200), 'item_cnt_month': clipedList})\nsubmit3.to_csv('submit3.csv', index=False)\n","1b23de8d":"train_index2, val_index2 = list(StratifiedKFold(2, random_state=12, shuffle=True).split(X_train, y_train))[0]","f7c14d02":"# prediction with 1 time of prediction.\npredictions = np.zeros((len(y_test), nfold))\n\n\ntrain_set_lgb = lgb.Dataset(X_train.iloc[train_index2][predictors].values,\n                            label= y_train[train_index2],\n                            feature_name= predictors,\n                            free_raw_data=False)\n    \nval_set_lgb = lgb.Dataset(X_train.iloc[val_index2][predictors].values,\n                            label= y_train[val_index2],\n                            feature_name= predictors,\n                            free_raw_data=False)\nclf = lgb.train(optimized_lgb_params, train_set_lgb, 5000, valid_sets = [val_set_lgb],\n                verbose_eval=250, early_stopping_rounds = 50)\n    \npredictions = clf.predict(X_test[predictors], num_iteration=clf.best_iteration)","5a7c83cc":"final = predictions.clip(0,20)","4982bece":"predictions\n\nsubmit = pd.DataFrame({'ID':range(len(predictions)), 'item_cnt_month': final})\nsubmit.to_csv('submit.csv', index=False)","a0166797":"submit","932d4bb7":"assume you find some kernel with different hyperparameters, then you want to check if those values are better than yours or not?\n\nI used bayesian optimization another time and found different hyperparameter values.\nnow we can check which one is better.","84627618":"ok, let's create our test and train data.\nas you may know 34th month is our test set and all before months are train.","482da497":"important to us are : \n* X_valid_train\n* X_valid_test\n* y_valid_train\n* y_valid_test","bd585860":"# bayesian optimization part\n\n\nso let's go inside the real part of kernel","340cce87":"# Bayesian optimization\n\nin this kernel we want to make prediction for this competition. but we will find our hyperparameters by bayesian optimization.\n\nwe will use pre engineered data from this [kernel](https:\/\/www.kaggle.com\/emaksone\/eda-with-feature-engineering)\n![bayesian optimization](https:\/\/github.com\/fmfn\/BayesianOptimization\/raw\/master\/examples\/func.png)","e2c06b00":"set range for hyperparams, and library will select best choice for these hyperparams in this range.\n<br>\nto understand these params you can visit [lgbm documentation](https:\/\/lightgbm.readthedocs.io\/en\/latest\/Parameters.html)","81c75722":"we need a black box function to use bayesian optimization.\n\nthe library will use this function oo gain best result.","23b9f9db":"data loading","9f3a272d":"# a little data prepration\n\na little data prepration .( if  you want, you can Expand cells).this part heavilly inspired by [Manizuk notebook](https:\/\/www.kaggle.com\/emaksone\/linear-model-xgboost-and-stacking\/comments)","d6b1a25b":"# prediction with 5 time prediciting.\n\nlet's create prediction.\n\nthis way of predicting will output 202 rank better than predicting with one time predicting.","3b0e9d90":"If you want to read more about this Bayesian library, read [Lib documentation](https:\/\/github.com\/fmfn\/BayesianOptimization)","f3b7c51e":"# prediction with 1 time of prediction\n\nnext cell is prediction without ranked averaging "}}