{"cell_type":{"7fd46f3f":"code","1c335e3b":"code","92d2e46c":"code","c1721231":"code","b367f2e1":"code","18b94bd0":"code","a15ec1ae":"code","c850ba4c":"code","b616b81f":"code","c380e235":"code","e8121b9c":"code","d4cda9a6":"code","536c211c":"code","73286641":"code","affaa7c7":"markdown","c67c550b":"markdown","289630d5":"markdown","7e57922b":"markdown","a70cc41b":"markdown","26be0b95":"markdown","d7278839":"markdown","0dc953a0":"markdown","93e63cd1":"markdown","84aacd54":"markdown","65129b5f":"markdown","6bc96a2c":"markdown","4feef4c0":"markdown"},"source":{"7fd46f3f":"\nimport tensorflow as tf\nimport matplotlib.pyplot as plt \nimport numpy as np\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential,load_model ,Model\nfrom keras.layers import Conv2D,Activation, MaxPooling2D,Dense,Flatten, Input, ZeroPadding2D, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import accuracy_score,roc_curve,confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt_False_Positive_vs_True_Positive\n\nfrom keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\nimport time\nimport os\n\n%matplotlib inline\n\n","1c335e3b":"\n\ndata=[]\nfor dirname, _, filenames in os.walk('..\/input\/brain-mri-images-for-brain-tumor-detection'):\n    for filename in filenames:\n        img=cv2.imread(os.path.join(dirname, filename))\n        if img is not None:\n                data.append(img)\n        \ndata=np.array(data)","92d2e46c":"#smallest size in the data set\nM=[]\nfor i in range(253):\n    M.append(data[i].shape[0])\nprint(f\" The smallest image-width is {np.min(M)} which is {np.argmin(M)}-th image \" )   \nMh=[]\nfor i in range(253):\n    Mh.append(data[i].shape[1])\nprint(f\" The smallest image-heigt is {np.min(Mh)} which is {np.argmin(Mh)}-th image \" ) ","c1721231":"M=[]\nfor i in range(253):\n    M.append(data[i].shape[0])\nprint(f\" The largest image-width is {np.max(M)} which is {np.argmax(M)}-th image \" )   \nMh=[]\nfor i in range(253):\n    Mh.append(data[i].shape[1])\nprint(f\" The largest image-heigt is {np.max(Mh)} which is {np.argmax(Mh)}-th image \" ) ","b367f2e1":"fig = plt.figure()\nax = fig.add_subplot(1, 2, 1)\nimgplot = plt.imshow(data[213])\nax.set_title('smallest-width')\nax = fig.add_subplot(1, 2, 2)\nimgplot = plt.imshow(data[45])\nax.set_title('largest-width')\nplt.show()","18b94bd0":"fig = plt.figure()\nax = fig.add_subplot(1, 2, 1)\nimgplot = plt.imshow(data[224])\nax.set_title('smallest-heigt')\nax = fig.add_subplot(1, 2, 2)\nimgplot = plt.imshow(data[222])\nax.set_title('largest-heigt')\nplt.show()","a15ec1ae":"m=[]\nfor i in range(253):\n    m.append(data[i].shape[0])\n    \nplt.hist(m)\nax.set_title('distribution of width of images')\nplt.show()","c850ba4c":"higth=[]\nfor i in range(253):\n    higth.append(data[i].shape[1])\nplt.hist(higth) \nax.set_title('distribution of heigh of images')\nplt.show()","b616b81f":"def Build_CNN_Model():\n    \n    # -------------------------------------------------------------------------\n    #                        Transfer InceptionV3 Model \n    # -------------------------------------------------------------------------\n    # load Inception model\n    Inception = InceptionV3(include_top=True, input_shape=(299, 299, 3))\n\n    # mark loaded layers as trainable\n    for layer in Inception.layers:\n\t    layer.trainable = True   \n        \n  \n    #  Softmax Classifier\n    Class_layer = Dense(2)(Inception.layers[-2].output)\n    \n    Softmax_layer = Activation('softmax')(Class_layer)\n    \n    \n\t# define new model    \n    model = Model(inputs=Inception.inputs, outputs=Softmax_layer)\n    \n        \n    #  Display model\n    model.summary()\n    \n\t# compile model\n\n    opt = Adam(learning_rate=0.00005, beta_1=0.9, beta_2=0.999)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model \n            ","c380e235":"def Train_CNN_Model(model):\n    \n    # -------------------------------------------------------------------------\n    #                        Train CNN Model \n    # -------------------------------------------------------------------------\n    \n    # create data generators    \n    train_datagen = ImageDataGenerator(\n                                     rescale=1.0\/255.0,\n                                     featurewise_center= True,\n                                     featurewise_std_normalization = True,\n                                     rotation_range=10,\n                                     width_shift_range=0.1,\n                                     height_shift_range=0.1,\n                                     zoom_range=0.2,                                     \n                                     brightness_range=[0.2,1.0],\n                                     )\n    \n    valid_datagen = ImageDataGenerator(\n                                     rescale=1.0\/255.0,\n                                     featurewise_center= True,\n                                     featurewise_std_normalization = True)\n    \n   \n   \n    # prepare iterators\n    batch_size=32\n    path_train= '..\/input\/cleandata1\/train'\n    path_valid= '..\/input\/cleandata1\/valid'\n    train_it = train_datagen.flow_from_directory(path_train,classes =('yes','no'),batch_size=batch_size, target_size=(299, 299))\n    valid_it = valid_datagen.flow_from_directory(path_valid,classes =('yes','no'),batch_size=batch_size, target_size=(299, 299))\n\n\n    epochs=10;\n    \n    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n\t\tvalidation_data=valid_it, validation_steps=len(valid_it), epochs=epochs, verbose=2)\n    \n    \n    #  \"Accuracy\"\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    \n    # \"Loss\"\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n\n\t# save model\n    model.save('medical.h5')\n\n\n\n\n\n","e8121b9c":"def Evaluate_CNN_Model():\n    # -------------------------------------------------------------------------\n    #                        Evaluate CNN Model \n    # -------------------------------------------------------------------------\n    \n    # load model\n    model = load_model('medical.h5')\n    \n    # load test data\n    batch_size=32\n    test_datagen = ImageDataGenerator(\n                                     rescale=1.0\/255.0,\n                                     featurewise_center= True,\n                                     featurewise_std_normalization = True)\n    path_test='..\/input\/cleandata1\/test'\n    test_it = test_datagen.flow_from_directory(path_test,classes =('yes','no'), \n                                               shuffle=False,batch_size=batch_size, target_size=(299, 299))\n    \n    y_true = test_it.classes;\n\n    y_pred = model.predict_generator(test_it, steps=len(test_it), verbose=1)\n\n    \n    y_pred_prob = y_pred[:,1]\n\n     \n    y_pred_binary =  y_pred_prob > 0.5\n   \n    #Confution Matrix    \n    print('\\nConfusion Matrix\\n -------------------------')    \n    print(confusion_matrix(y_true,y_pred_binary));\n    \n    # accuracy: (tp + tn) \/ (p + n)\n    accuracy = accuracy_score(y_true, y_pred_binary)\n    print('Accuracy: %f' % accuracy)\n    \n    \n    # precision tp \/ (tp + fp)\n    precision = precision_score(y_true, y_pred_binary)\n    print('Precision: %f' % precision)\n    \n    # recall: tp \/ (tp + fn)\n    recall = recall_score(y_true, y_pred_binary)\n    print('Recall: %f' % recall)\n    \n    # f1: 2 tp \/ (2 tp + fp + fn)\n    f1 = f1_score(y_true, y_pred_binary)\n    print('F1 score: %f' % f1)    \n       \n    # ROC AUC\n    auc = roc_auc_score(y_true, y_pred_prob)\n    print('ROC AUC: %f' % auc)\n    \n    \n    # calculate roc curves\n    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n        \n    # plot the roc curve for the model\n    plt.figure()\n    plt_False_Positive_vs_True_Positive.plot(fpr, tpr, linestyle='--', label='')\n    \n    # axis labels\n    plt_False_Positive_vs_True_Positive.xlabel('False Positive Rate')\n    plt_False_Positive_vs_True_Positive.ylabel('True Positive Rate')\n       \n    # show the legend\n    plt_False_Positive_vs_True_Positive.legend()\n    # show the plot\n    plt_False_Positive_vs_True_Positive.show()\n    \n\n\n\n\n","d4cda9a6":"model = Build_CNN_Model()","536c211c":"Train_CNN_Model(model)","73286641":"Evaluate_CNN_Model()","affaa7c7":"#  MODEL","c67c550b":"# \n# Image Classification with InceptionV3 transfer","289630d5":"a)- I seprated the data into 3 parts: 1-train, 2-test, 3-validation (I uppluded files in the Kaggle Data input). Images has been clean by crop_brain_contour function and resized to (299,299). \n\nb)- I used ImageDataGenerator just on the training data. Not on the test and the validation sets\n.\n\nc)- Hyperarameter tunning  has been done fine and the model has the following parameters:\n\n1-batch size=32.\n\n2-epoch size= 10. This migth be strange. I started from 100 epochs but  in all models, by looking at  the graph of loss and accuracy, it was the best size.  \n, \n3-Optimization Adam: The important key about this project was to play with the learning rate  of optimizer. \n\n-learn rate: I started with 0.01, but the accuracy of the training set was jumping (for example from 80% to 70% and then again to 82% then 65% and ...). In other words it couldn't find the minimum. I decreased it to 0.0005 and the problem of jumping was solved. \n\n-betta_1= 0.9\n\n-betta_2= 0.999\n\nd) I used accuracy as a metric wich is the number of (correct prediction\/ total number of predictions)\n\ne) The model is simple. I started with a more complicated model. I retrain some of the lower layers to increase performance but the result was not better than a simple model. \n\n\nNote that one of the reasons that I choosed this transfer was the size of its input. In the Note book I drew the distribution of the widths and heigts of the images. And seems 299 is a better choice than 254 (which other notebooks used). ","7e57922b":"# Training of the model","a70cc41b":"InceptionV3 is the third edition of Google's Inception Convolutional Neural Network, originally introduced. \nThe following picture shows the architecture of this model.","26be0b95":"Let's compare the largest and smallest widths and heigts","d7278839":"![1]( https:\/\/i.stack.imgur.com\/yU9iD.png)","0dc953a0":"I checked the results of other Notebooks and decided to build a different model with a better accuracy. \n\nThe summary of the model is as follows:","93e63cd1":"First I am gonna look at the whole data to check the distribution of images","84aacd54":"conclusion\n\nAs the confution matrix shows the final result is very good.","65129b5f":"# Evaluation of the model","6bc96a2c":"These two graphs show 299 is a better choice. ","4feef4c0":"So the difference is huge. Let's plot them out."}}