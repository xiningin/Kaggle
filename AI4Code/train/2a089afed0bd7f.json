{"cell_type":{"b7e3134f":"code","a506da1d":"code","ead23bf9":"code","cc8eca58":"code","5b37e50e":"code","3a0ad27b":"code","468ee832":"code","54acf526":"code","376c3e42":"code","d71f2c70":"code","9f77b672":"code","6435e3e9":"code","2e760e48":"code","a83194f6":"code","a0c11629":"code","9a235371":"code","a71f57af":"code","5d8baf50":"code","aecfd4ff":"code","9a7b8bd0":"code","dbc442ef":"code","18ba1cf2":"code","09d64a98":"code","3184375a":"code","774c1546":"code","7f42c9de":"code","6002ae9c":"code","a6cedc55":"code","fd4859bd":"code","7bee2e25":"code","a7a159fe":"code","dbae04b9":"code","8871a552":"code","f0efaad4":"code","409286d9":"code","08cbe12d":"code","974cfcf6":"code","b7f57d56":"code","81795f93":"code","be551e63":"code","55c6211a":"code","f602084d":"code","5de0f24f":"code","0b553138":"code","58eee42e":"code","fcef029d":"code","0b1ef967":"code","cea1812e":"code","f02f8c01":"code","bb5a31d0":"code","6d0b1979":"code","cdbcc13a":"code","57bfe53c":"code","163c878e":"code","aa476245":"code","5775b1c0":"code","ffe42118":"code","72b52f96":"code","f7216b67":"code","4f9ad0fb":"code","8a88bcde":"code","f2361f2e":"code","75ad717b":"code","111177c1":"code","2a054012":"markdown","74f7d7c5":"markdown","ddc455a4":"markdown","6dc43936":"markdown","ad0beb40":"markdown","2a706bf8":"markdown","6e55609d":"markdown","710712c1":"markdown","32003c7d":"markdown","12ebd5e9":"markdown","0ac1748a":"markdown","4e74a4d6":"markdown","e54bdfb1":"markdown","7ad833f9":"markdown","76ad6290":"markdown","52c425da":"markdown","15507bbf":"markdown","d7833dc6":"markdown","90fd97de":"markdown","bc41b93a":"markdown","c7f47076":"markdown","3f10ef79":"markdown","b1649473":"markdown","1f31ee16":"markdown","668b7585":"markdown","58ac7f25":"markdown","309f397c":"markdown","666c03c3":"markdown","85094fb9":"markdown","57084555":"markdown","fae69ad3":"markdown","8ad70d99":"markdown","8c898b30":"markdown","9eb1403b":"markdown","985d1175":"markdown","a231eab3":"markdown","029f5cda":"markdown","25a7a25e":"markdown","24ff100e":"markdown","09ee27e0":"markdown","cc1564e2":"markdown","991113e0":"markdown","7b333825":"markdown","aabafda7":"markdown","c256842b":"markdown","4e0fd0e6":"markdown","6c9af503":"markdown","1bed3fb9":"markdown","f73b9d5a":"markdown","959515da":"markdown","afadc406":"markdown","a47859c8":"markdown","1983c15c":"markdown","e3b39c10":"markdown"},"source":{"b7e3134f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a506da1d":"\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport matplotlib.dates as mdates\nimport matplotlib.colors as mcolors\nfrom matplotlib import style\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use(\"fivethirtyeight\")\n%matplotlib inline\n\n# For reading stock data from yahoo\nfrom pandas_datareader.data import DataReader\n\n# For time stamps\nfrom datetime import datetime\nfrom math import sqrt\n\n#ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ntry:\n    import mplfinance as mpf\n    import mpl_finance as mplf\n    from mpl_finance import candlestick_ohlc\nexcept:\n    !pip install mplfinance mpl_finance\n    import mplfinance as mpf\n    import mpl_finance as mplf\n    from mpl_finance import candlestick_ohlc","ead23bf9":"#tcs = pd.read_csv('..\/input\/tcs-stock-data-live-and-latest\/TCS_stock_history.csv')\n\ntcs = pd.read_csv('..\/input\/tcs-stock-data-live-and-latest\/TCS_stock_history.csv')\nprint(tcs.head())","cc8eca58":"#Closing Price PLot\ntcs[[\"Close\"]].plot()\n#Volume Plot\ntcs[[\"Volume\"]].plot()","5b37e50e":"tcs2 = pd.read_csv('..\/input\/tcs-stock-data-live-and-latest\/TCS_stock_history.csv', header=0, \n                  index_col= 0, names=['Date','Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Splits'], parse_dates=True)\n# Get the number of days in `tcs`\ndays = (tcs2.index[-1] - tcs2.index[0]).days\n\n# Calculate the CAGR \ncagr = ((((tcs2['Close'][-1]) \/ tcs2['Close'][1])) ** (365.0\/days)) - 1\n\n\n# Print CAGR\nprint(\"The CAGR (Compound Annual Growth Rate) of TCS since IPO is \" , round((cagr*100),2), \"% per year\")","3a0ad27b":"# Isolate the adjusted closing prices \nadj_close_px = tcs2['Close']\n\n# Calculate the moving average\nmoving_avg = adj_close_px.rolling(window=40).mean()\n\n# Inspect the result\nmoving_avg[-10:]","468ee832":"# Short moving window rolling mean\ntcs2['42'] = adj_close_px.rolling(window=40).mean()\n\n# Long moving window rolling mean\ntcs2['252'] = adj_close_px.rolling(window=252).mean()\n\n# Plot the adjusted closing price, the short and long windows of rolling means\ntcs2[['Close', '42', '252']].plot()\n\nplt.show()","54acf526":"#OHLC Plot using Plotly\nimport plotly.graph_objects as go\n\nfig = go.Figure(data=go.Ohlc(x=tcs['Date'],\n        open=tcs['Open'],\n        high=tcs['High'],\n        low=tcs['Low'],\n        close=tcs['Close']))\nfig.show()","376c3e42":"daily_close_px = tcs2[['Close']]\n# Calculate the daily percentage change for `daily_close_px`\ndaily_pct_change = daily_close_px.pct_change()\n\n# Plot the distributions\ndaily_pct_change.hist(bins=50, sharex=True, figsize=(12,8))\n\n# Show the resulting plot\nplt.show()","d71f2c70":"# Define the minumum of periods to consider \nmin_periods = 75 \n\n# Calculate the volatility\nvol = daily_pct_change.rolling(min_periods).std() * np.sqrt(min_periods) \n\n# Plot the volatility\nvol.plot(figsize=(10, 8))\n\n# Show the plot\nplt.show()","9f77b672":"# Plot a scatter matrix with the `daily_pct_change` data \npd.plotting.scatter_matrix(daily_pct_change, diagonal='kde', alpha=0.1,figsize=(12,12))\n\n# Show the plot\nplt.show()","6435e3e9":"tcs['SMA5'] = tcs.Close.rolling(5).mean()\ntcs['SMA20'] = tcs.Close.rolling(20).mean()\ntcs['SMA50'] = tcs.Close.rolling(50).mean()\ntcs['SMA200'] = tcs.Close.rolling(200).mean()\ntcs['SMA500'] = tcs.Close.rolling(500).mean()\n\nfig = go.Figure(data=[go.Ohlc(x=tcs['Date'],\n                              open=tcs['Open'],\n                              high=tcs['High'],\n                              low=tcs['Low'],\n                              close=tcs['Close'], name = \"OHLC\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA5, line=dict(color='orange', width=1), name=\"SMA5\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA20, line=dict(color='green', width=1), name=\"SMA20\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA50, line=dict(color='blue', width=1), name=\"SMA50\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA200, line=dict(color='violet', width=1), name=\"SMA200\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA500, line=dict(color='purple', width=1), name=\"SMA500\")])\nfig.show()","2e760e48":"\ntcs['EMA5'] = tcs.Close.ewm(span=5, adjust=False).mean()\ntcs['EMA20'] = tcs.Close.ewm(span=20, adjust=False).mean()\ntcs['EMA50'] = tcs.Close.ewm(span=50, adjust=False).mean()\ntcs['EMA200'] = tcs.Close.ewm(span=200, adjust=False).mean()\ntcs['EMA500'] = tcs.Close.ewm(span=500, adjust=False).mean()\n\nfig = go.Figure(data=[go.Ohlc(x=tcs['Date'],\n                              open=tcs['Open'],\n                              high=tcs['High'],\n                              low=tcs['Low'],\n                              close=tcs['Close'], name = \"OHLC\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA5, line=dict(color='orange', width=1), name=\"EMA5\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA20, line=dict(color='green', width=1), name=\"EMA20\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA50, line=dict(color='blue', width=1), name=\"EMA50\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA200, line=dict(color='violet', width=1), name=\"EMA200\"),\n                      go.Scatter(x=tcs.Date, y=tcs.SMA500, line=dict(color='purple', width=1), name=\"EMA500\")])\nfig.show()","a83194f6":"tcs.set_index('Date')","a0c11629":"tcs['daily_change_pct'] = tcs['Close'].pct_change()*100\ntcs['returns'] = tcs['daily_change_pct'] \/ tcs['Close']  \ntcs.head()","9a235371":"tcs['daily_change_pct'].fillna(0)\ntcs['daily_change_pct'].hist(bins = 50, figsize = (10,5)) \nplt.xlabel('Daily Change Percentage')\nplt.ylabel('Frequency')\nplt.show()\n#print the statistics on daily change percentage\ntcs.daily_change_pct.describe()","a71f57af":"tcs_vol = tcs['Volume'].rolling(7).std()*np.sqrt(7)\ntcs_vol.plot(figsize = (15, 7))","5d8baf50":"def daily_trend(x):\n    if x > -0.5 and x <= 0.5:\n        return 'No change'\n    elif x > 0.5 and x <= 2:\n        return 'Upto 2% Increase'\n    elif x > -2 and x <= -0.5:\n        return 'Upto 2% Decrease'\n    elif x > 2 and x <= 5:\n        return '2-5% Increase'\n    elif x > -5 and x <= -2:\n        return '2-5% Decrease'\n    elif x > 5 and x <= 10:\n        return '5-10% Increase'\n    elif x > -10 and x <= -5:\n        return '5-10% Decrease'\n    elif x > 10:\n        return '>10% Increase'\n    elif x <= -10:\n        return '>10% Decrease'","aecfd4ff":"tcs['Trend']= np.zeros(tcs['daily_change_pct'].count()+1)\ntcs['Trend']= tcs['daily_change_pct'].apply(lambda x:daily_trend(x))\ntcs['Trend'].replace('None','No change')\ntcs.head()","9a7b8bd0":"\ntcs_pie_data = tcs.groupby('Trend')\n#pie_label = tcs_pie_data['Trend'].unique()\nplt.pie(tcs_pie_data['Trend'].count(), #labels = pie_label, \n        autopct = '%1.1f%%', radius = 2 )\nplt.show()\nax=tcs_pie_data['Trend'].count().sort_values(ascending=False).plot.bar(rot=90)\nplt.show()","dbc442ef":"tcs.index = pd.DatetimeIndex(tcs['Date'])\nmpf.plot(tcs)","18ba1cf2":"mpf.plot(tcs, type='candle', mav = (7, 30, 90, 180, 365), volume = True)","09d64a98":"mpf.plot(tcs, type='candle', mav = (7, 30, 90, 180, 365), volume = True , show_nontrading = True)","3184375a":"tcs.head()","774c1546":"tcs['Shares'] = [1 if tcs.loc[ei, 'SMA20']>tcs.loc[ei, 'SMA50'] else 0 for ei in tcs.index]","7f42c9de":"tcs['Close1'] = tcs['Close'].shift(-1)\ntcs['Profit'] = [tcs.loc[ei, 'Close1'] - tcs.loc[ei, 'Close'] if tcs.loc[ei, 'Shares']==1 else 0 for ei in tcs.index]\ntcs['Profit'].plot()\nplt.axhline(y=0, color='red')","6002ae9c":"tcs['wealth'] = tcs['Profit'].cumsum()\ntcs.tail()","a6cedc55":"tcs['wealth'].plot()\nplt.title('Total money made by TCS Stock (number of times ): {}'.format(round((tcs.loc[tcs.index[-2], 'wealth']),1)))","fd4859bd":"tcs['LogReturn'] = np.log(tcs['Close']).shift(-1) - np.log(tcs['Close'])\nprint(tcs['LogReturn'])","7bee2e25":"from scipy.stats import norm\nmu = tcs['LogReturn'].mean()\nsigma = tcs['LogReturn'].std(ddof=1)\n\ndensity = pd.DataFrame()\ndensity['x'] = np.arange(tcs['LogReturn'].min()-0.01, tcs['LogReturn'].max()+0.01, 0.001)\ndensity['pdf'] = norm.pdf(density['x'], mu, sigma)\n\ntcs['LogReturn'].hist(bins=50, figsize=(15, 8))\nplt.plot(density['x'], density['pdf'], color='red')\nplt.show()","a7a159fe":"mu220 = 365*mu\nsigma220 = (365**0.5) * sigma\nfor i in range(-5, 6, 1):\n    drop = norm.cdf((-i)*0.05, mu220, sigma220)\n    jump = norm.cdf(i*0.05, mu220, sigma220)\n    print('The probability of %d percent drop is = %f & The probability of %d percent jump is = %f' % (i*5, round(drop,2), -i*5, round(jump,2)))","dbae04b9":"VaR = norm.ppf(0.05, mu, sigma)\nprint('Single day value at risk is: ', VaR)","8871a552":"# Quantile \n# 5% quantile\nprint('5% quantile ', norm.ppf(0.05, mu, sigma))\n# 95% quantile\nprint('95% quantile ', norm.ppf(0.95, mu, sigma))","f0efaad4":"tcs['logReturn'] = np.log(tcs['Close'].shift(-1)) - np.log(tcs['Close'])\nsample_size = tcs['logReturn'].shape[0]\nsample_mean = tcs['logReturn'].mean()\nsample_std = tcs['logReturn'].std(ddof=1) \/ sample_size**0.5\n# left and right quantile\nfor i in range(1,10):\n    z_left = norm.ppf(0.05*i)\n    z_right = norm.ppf((1-0.05*i))\n    interval_left = sample_mean+z_left*sample_std\n    interval_right = sample_mean+z_right*sample_std\n    print('%d percent confidence interval is ' % (100-i*2*5), ( round(interval_left,6), round(interval_right,6)))","409286d9":"\n# Get the 26-day EMA of the closing price\nk = tcs['Close'].ewm(span=12, adjust=False, min_periods=12).mean()\n# Get the 12-day EMA of the closing price\nd = tcs['Close'].ewm(span=26, adjust=False, min_periods=26).mean()\n# Subtract the 26-day EMA from the 12-Day EMA to get the MACD\nmacd = k - d\n# Get the 9-Day EMA of the MACD for the Trigger line\nmacd_s = macd.ewm(span=9, adjust=False, min_periods=9).mean()\n# Calculate the difference between the MACD - Trigger for the Convergence\/Divergence value\nmacd_h = macd - macd_s\n# Add all of our new values for the MACD to the dataframe\ntcs['macd'] = tcs.index.map(macd)\ntcs['macd_h'] = tcs.index.map(macd_h)\ntcs['macd_s'] = tcs.index.map(macd_s)\n# View our data\npd.set_option(\"display.max_columns\", None)\nprint(tcs)","08cbe12d":"try: \n    import pandas_ta as ta\nexcept:\n    !pip install pandas_ta\n    import pandas_ta as ta\n\n","974cfcf6":"\n# Calculate MACD values using the pandas_ta library\ntcs2.ta.macd(close='close', fast=12, slow=26, signal=9, append=True)\n# View result\npd.set_option(\"display.max_columns\", None)  # show all columns\nprint(tcs2)","b7f57d56":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n# calculate MACD values\ntcs2.ta.macd(close='close', fast=12, slow=26, append=True)\n# Force lowercase (optional)\ntcs2.columns = [x.lower() for x in tcs2.columns]\n# Construct a 2 x 1 Plotly figure\nfig = make_subplots(rows=2, cols=1)\n# price Line\nfig.append_trace(\n    go.Scatter(\n        x=tcs2.index,\n        y=tcs2['open'],\n        line=dict(color='lawngreen', width=1),\n        name='open',\n        # showlegend=False,\n        legendgroup='1',\n    ), row=1, col=1\n)\n# Candlestick chart for pricing\nfig.append_trace(\n    go.Candlestick(\n        x=tcs2.index,\n        open=tcs2['open'],\n        high=tcs2['high'],\n        low=tcs2['low'],\n        close=tcs2['close'],\n        increasing_line_color='lawngreen',\n        decreasing_line_color='black',\n        showlegend=False\n    ), row=1, col=1\n)\n# Fast Signal (%k)\nfig.append_trace(\n    go.Scatter(\n        x=tcs2.index,\n        y=tcs2['macd_12_26_9'],\n        line=dict(color='lawngreen', width=2),\n        name='macd',\n        # showlegend=False,\n        legendgroup='2',\n    ), row=2, col=1\n)\n# Slow signal (%d)\nfig.append_trace(\n    go.Scatter(\n        x=tcs2.index,\n        y=tcs2['macds_12_26_9'],\n        line=dict(color='mediumblue', width=2),\n        # showlegend=False,\n        legendgroup='2',\n        name='signal'\n    ), row=2, col=1\n)\n# Colorize the histogram values\ncolors = np.where(tcs2['macdh_12_26_9'] < 0, '#000', 'lawngreen')\n# Plot the histogram\nfig.append_trace(\n    go.Bar(\n        x=tcs2.index,\n        y=tcs2['macdh_12_26_9'],\n        name='histogram',\n        marker_color=colors,\n    ), row=2, col=1\n)\n# Make it pretty\nlayout = go.Layout(\n    plot_bgcolor='linen',\n    # Font Families\n    font_family='Monospace',\n    font_color='mediumblue',\n    font_size=20,\n    xaxis=dict(\n        rangeslider=dict(\n            visible=False\n        )\n    )\n)\n# Update options and show plot\nfig.update_layout(layout)\nfig.update_layout(height=800,width=1200,dragmode='lasso')\nfig.show()","81795f93":"try:\n    from finta import TA\n    from backtesting import Backtest, Strategy\n    from backtesting.lib import crossover\nexcept:\n    !pip install finta backtesting\n    from finta import TA\n    from backtesting import Backtest, Strategy\n    from backtesting.lib import crossover\n","be551e63":"fin_tcs = pd.read_csv('..\/input\/tcs-stock-data-live-and-latest\/TCS_stock_history.csv', index_col=\"Date\", parse_dates=True)\nprint(fin_tcs.head())\nohlc=fin_tcs\nprint(TA.SMA(ohlc, 42))\n#will return Pandas Series object with \"Awesome oscillator\" values\nTA.AO(ohlc)\n#expects [\"volume\"] column as input\nprint(TA.OBV(ohlc))\n#will return Series with Bollinger Bands columns [BB_UPPER, BB_LOWER]\nprint(TA.BBANDS(ohlc))\n#will return Series with calculated BBANDS values but will use KAMA instead of MA for calculation, other types of Moving Averages are allowed as well.\nprint(TA.BBANDS(ohlc, MA=TA.KAMA(ohlc, 20)))","55c6211a":"\n# calc bol band\nbbands = TA.BBANDS(fin_tcs, 30)\n\n# cherry pick what to show on the chart\nbands_plot = pd.concat([bbands.BB_UPPER, bbands.BB_LOWER], axis=1)\n\napd = mpf.make_addplot(bands_plot.tail(300))\n\nmpf.plot(fin_tcs.tail(300), type='candle', style='charles',\n        title='tcs BBANDS(30)',\n        ylabel='Price (USD)',\n        ylabel_lower='Volume',\n        volume=True,\n        figscale=1.5,\n        addplot=apd\n        )\n\napd = mpf.make_addplot(bands_plot.head(300))\n\nmpf.plot(fin_tcs.head(300), type='candle', style='charles',\n        title='tcs BBANDS(30)',\n        ylabel='Price (USD)',\n        ylabel_lower='Volume',\n        volume=True,\n        figscale=1.5,\n        addplot=apd\n        )","f602084d":"\nfunction_dict = {' Simple Moving Average ' : 'SMA',\n                 ' Simple Moving Median ' : 'SMM',\n                 ' Smoothed Simple Moving Average ' : 'SSMA',\n                 ' Exponential Moving Average ' : 'EMA',\n                 ' Double Exponential Moving Average ' : 'DEMA',\n                 ' Triple Exponential Moving Average ' : 'TEMA',\n                 ' Triangular Moving Average ' : 'TRIMA',\n                 ' Triple Exponential Moving Average Oscillator ' : 'TRIX',\n                 ' Volume Adjusted Moving Average ' : 'VAMA',\n                 ' Kaufman Efficiency Indicator ' : 'ER',\n                 ' Kaufmans Adaptive Moving Average ' : 'KAMA',\n                 ' Zero Lag Exponential Moving Average ' : 'ZLEMA',\n                 ' Weighted Moving Average ' : 'WMA',\n                 ' Hull Moving Average ' : 'HMA',\n                 ' Elastic Volume Moving Average ' : 'EVWMA',\n                 ' Volume Weighted Average Price ' : 'VWAP',\n                 ' Smoothed Moving Average ' : 'SMMA',\n                 ' Fractal Adaptive Moving Average ' : 'FRAMA',\n                 ' Moving Average Convergence Divergence ' : 'MACD',\n                 ' Percentage Price Oscillator ' : 'PPO',\n                 ' Volume-Weighted MACD ' : 'VW_MACD',\n                 ' Elastic-Volume weighted MACD ' : 'EV_MACD',\n                 ' Market Momentum ' : 'MOM',\n                 ' Rate-of-Change ' : 'ROC',\n                 ' Relative Strength Index ' : 'RSI',\n                 ' Inverse Fisher Transform RSI ' : 'IFT_RSI',\n                 ' True Range ' : 'TR',\n                 ' Average True Range ' : 'ATR',\n                 ' Stop-and-Reverse ' : 'SAR',\n                 ' Bollinger Bands ' : 'BBANDS',\n                 ' Bollinger Bands Width ' : 'BBWIDTH',\n                 ' Momentum Breakout Bands ' : 'MOBO',\n                 ' Percent B ' : 'PERCENT_B',\n                 ' Keltner Channels ' : 'KC',\n                 ' Donchian Channel ' : 'DO',\n                 ' Directional Movement Indicator ' : 'DMI',\n                 ' Average Directional Index ' : 'ADX',\n                 ' Pivot Points ' : 'PIVOT',\n                 ' Fibonacci Pivot Points ' : 'PIVOT_FIB',\n                 ' Stochastic Oscillator Percent K ' : 'STOCH',\n                 ' Stochastic oscillator Percent D ' : 'STOCHD',\n                 ' Stochastic RSI ' : 'STOCHRSI',\n                 ' Williams Percent R ' : 'WILLIAMS',\n                 ' Ultimate Oscillator ' : 'UO',\n                 ' Awesome Oscillator ' : 'AO',\n                 ' Mass Index ' : 'MI',\n                 ' Vortex Indicator ' : 'VORTEX',\n                 ' Know Sure Thing ' : 'KST',\n                 ' True Strength Index ' : 'TSI',\n                 ' Typical Price ' : 'TP',\n                 ' Accumulation-Distribution Line ' : 'ADL',\n                 ' Chaikin Oscillator ' : 'CHAIKIN',\n                 ' Money Flow Index ' : 'MFI',\n                 ' On Balance Volume ' : 'OBV',\n                 ' Weighter OBV ' : 'WOBV',\n                 ' Volume Zone Oscillator ' : 'VZO',\n                 ' Price Zone Oscillator ' : 'PZO',\n                 ' Elders Force Index ' : 'EFI',\n                 ' Cummulative Force Index ' : 'CFI',\n                 ' Bull power and Bear Power ' : 'EBBP',\n                 ' Ease of Movement ' : 'EMV',\n                 ' Commodity Channel Index ' : 'CCI',\n                 ' Coppock Curve ' : 'COPP',\n                 ' Buy and Sell Pressure ' : 'BASP',\n                 ' Normalized BASP ' : 'BASPN',\n                 ' Chande Momentum Oscillator ' : 'CMO',\n                 ' Chandelier Exit ' : 'CHANDELIER',\n                 ' Qstick ' : 'QSTICK',\n                 #' Twiggs Money Index ' : 'TMF',\n                 ' Wave Trend Oscillator ' : 'WTO',\n                 ' Fisher Transform ' : 'FISH',\n                 ' Ichimoku Cloud ' : 'ICHIMOKU',\n                 ' Adaptive Price Zone ' : 'APZ',\n                 #' Squeeze Momentum Indicator ' : 'SQZMI',\n                 ' Volume Price Trend ' : 'VPT',\n                 ' Finite Volume Element ' : 'FVE',\n                 ' Volume Flow Indicator ' : 'VFI',\n                 ' Moving Standard deviation ' : 'MSD',\n                 ' Schaff Trend Cycle ' : 'STC'}\n\nfor key, value in function_dict .items():\n    function_name = \"TA.\" + value + \"(ohlc).plot(title='\" + key + \"')\"\n    result = eval(function_name)\n","5de0f24f":"# Defining DEMA cross strategy\nclass DemaCross(Strategy):\n\n    def init(self):\n\n        self.ma1 = self.I(TA.DEMA, ohlc, 10)\n        self.ma2 = self.I(TA.DEMA, ohlc, 20)\n\n    def next(self):\n        if crossover(self.ma1, self.ma2):\n            self.buy()\n        elif crossover(self.ma2, self.ma1):\n            self.sell()","0b553138":"bt = Backtest(ohlc, DemaCross,\n              cash=10000, commission=0.025)","58eee42e":"bt.run()","fcef029d":"bt.plot()","0b1ef967":"def sharpe_ratio(return_series, N, rf):\n    mean = return_series.mean() * N -rf\n    sigma = return_series.std() * np.sqrt(N)\n    return mean \/ sigma\n\nN = 255 #255 trading days in a year\nrf =0.018 #1.8% risk free rate\ntcs.columns\ntemp_df=tcs[['Close']]\nsharpes = temp_df.apply(sharpe_ratio, args=(N,rf,))#,axis=0)\nprint(\"The Sharpe Ratio for the stock i =\" , round(sharpes[0],2))","cea1812e":"def calculate_sortino(series,N, rf):\n    expected_return = np.mean(series)\n    below_avg = [i for i in series if i < expected_return]\n    risk_free = rf\n    sortino = (expected_return - risk_free) \/ np.std(below_avg)\n    return round(sortino, 2)\n\nsortinos = temp_df.apply(calculate_sortino, args=(N,rf,))\nprint(\"The Sortino Ratio for the stock is =\" , round(sortinos[0],2))","f02f8c01":"def max_drawdown(return_series):\n    comp_ret = (return_series+1).cumprod()\n    peak = comp_ret.expanding(min_periods=1).max()\n    dd = (comp_ret\/peak)-1\n    return dd.min()\n\n\nmax_drawdowns = temp_df.apply(max_drawdown,axis=0)\nprint(\"The max_drawdowns Ratio for the stock is =\" , round(max_drawdowns[0],2))","bb5a31d0":"def bollinger_bands_price(price):\n    up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n    bollinger_bands_price = (price['Close'] - low) \/ (up - low)\n    return bollinger_bands_price","6d0b1979":"# Histogram of the daily price change percent of 'Close' price\ntcs['Close'].pct_change().plot.hist(bins=50)\nplt.title('Daily Price: 1-Day Percent Change')\nplt.show() ","cdbcc13a":"# Create 5-day % changes of Last for the current day, and 5 days in the future\ntcs['5d_future_close'] = tcs['Close'].shift(-5)\ntcs['5d_close_future_pct'] = tcs['5d_future_close'].pct_change(5)\ntcs['5d_close_pct'] = tcs['Close'].pct_change(5)","57bfe53c":"# Calculate the correlation matrix between the 5d close pecentage changes (current and future)\ncorr = tcs[['5d_close_pct', '5d_close_future_pct']].corr()","163c878e":"# Scatter the current 5-day percent change vs the future 5-day percent change\nplt.scatter(tcs['5d_close_pct'], tcs['5d_close_future_pct'])\nplt.title('Current vs. Future 5-Day % Change')\nplt.show()","aa476245":"# a list of the feature names for later\nfeature_names = ['5d_close_pct']  ","5775b1c0":"# Drop all na values\ntcs = tcs.dropna()\n\n# Create features and targets\n# use feature_names for features; 5d_close_future_pct for targets\nfeatures = tcs[feature_names]\ntargets = tcs['5d_close_future_pct']\n\n# Create DataFrame from target column and feature columns\nfeat_targ_df = tcs[['5d_close_future_pct'] + feature_names]\n\n# Calculate correlation matrix\ncorr = feat_targ_df.corr()\nprint(corr)","ffe42118":"import seaborn as sns\n# Plot heatmap of correlation matrix\nsns.heatmap(corr, annot=True)\nplt.yticks(rotation=0); plt.xticks(rotation=90) # fix ticklabel directions\nplt.show() # show the plot","72b52f96":"import statsmodels.api as sm\n\n# Add a constant to the features\nlinear_features = sm.add_constant(features)\n\n# Create a size for the training set that is 80% of the total number of rows\n#.shape gives us the number of rows in our data, and convert to an int\ntrain_size = int(0.8 * features.shape[0])\n\n# split features and targets using python indexing\ntrain_features = linear_features[:train_size]\ntrain_targets = targets[:train_size]\ntest_features = linear_features[train_size:]\ntest_targets = targets[train_size:]\nprint(linear_features.shape, train_features.shape, test_features.shape)","f7216b67":"# Create the linear model and complete the least squares fit\nmodel = sm.OLS(train_targets, train_features)\nresults = model.fit()  # fit the model\nprint(results.summary())\n\n# examine pvalues\n# Features with p <= 0.05 are typically considered significantly different from 0\nprint(results.pvalues)\n\n# Make predictions from our model for train and test sets\ntrain_predictions = results.predict(train_features)\ntest_predictions = results.predict(test_features)","4f9ad0fb":"try:\n    from fbprophet.plot import plot_plotly\n    from fbprophet import Prophet\nexcept:\n    !pip install fbprophet    # install Faceboo Prophet\n    from fbprophet.plot import plot_plotly\n    from fbprophet import Prophet\n    ","8a88bcde":"from fbprophet.plot import plot_plotly\nfrom fbprophet import Prophet","f2361f2e":"def plot_close_val(data_frame, column, stock):\n    plt.figure(figsize=(16,6))\n    plt.title(column + ' Price History for ' + stock )\n    plt.plot(data_frame[column])\n    plt.xlabel('Date', fontsize=18)\n    plt.ylabel(column + ' Price USD ($) for ' + stock, fontsize=18)\n    plt.show()","75ad717b":"def fb_prophet_plot(df, param, stock):\n    # Check the dataset\n    #df.head()\n    # Create Dataset based on the FB Prophet standard ds\/y\n    df2 = pd.DataFrame([], columns = ['ds', 'y'])\n    df2.columns=['ds','y']\n    df2['ds']=pd.to_datetime(df.index,format='%Y-%m')\n    #Assign the Parameter\n    df2['y']=df[param].values\n    #check the new DS\n    #df2.head()\n    \n    #create a new Prophet Model\n    model=Prophet(interval_width=0.95,yearly_seasonality=True)\n    \n    #Fit the Model\n    model.fit(df2)\n    #Predict the future\n    future=model.make_future_dataframe(periods=50, freq='MS')\n    forecast=model.predict(future)\n    #Save the predicted model\n    preds= forecast['yhat'][:-50]\n    #plot the graph\n    title = 'FB Prophet predictions for ==> ' + stock\n    plt.figure(figsize=(16,8))\n    plt.plot(df2.ds,preds,color='#555555',label=' Predictions')\n    plt.plot(df2.ds,df2.y,color='#1155FF',label='Actual')\n    plt.title(title)\n    plt.legend()\n    plt.show()\n    figure=model.plot(forecast,xlabel='Date',ylabel='Price')\n    figure.set_size_inches(16,8)\n    plt.title(title)\n    model.plot_components(forecast)\n    plt.show()","111177c1":"plot_close_val(tcs, 'Close', 'tcs') # Plot the Closing Price\nfb_prophet_plot(tcs, 'Close', 'tcs')\n\nprint(\"All forecasting done!\")","2a054012":"### Let us try Sharpe Ratio","74f7d7c5":"#### Simple Pandas plots for the price and volume of TCS Stock","ddc455a4":"## Try Bollinger Bands Price","6dc43936":"#### What is the Value At Risk for the Stock?","ad0beb40":"#### General MPLFinance Plot","2a706bf8":"## It is very evidend that albeit some volatility, it is a pretty solid long term stock with outstanding run over last 5 years.","6e55609d":"#### Another Candle Stick Plot with Moving Averages and show of non trading days","710712c1":"#### Calculate the cumulated wealth on the stock","32003c7d":"#### EMA chart plotting for 5, 20, 50, 200, 500 day moving averages","12ebd5e9":"###### Following is a reuse from the kernel https:\/\/www.kaggle.com\/datapple\/eda-tesla-stock-price-financial-analysis and modified for the analysis","0ac1748a":"### Tag the dates as profit when the closing price is greater than the preceding date \n\n#### Plot the dates of wealth generation over the years","4e74a4d6":"### Let us check the Backtesting summary","e54bdfb1":"#### Define a daily trend function for usage in aggregation","7ad833f9":"#### OHLC Chart","76ad6290":"#### CandleStick MPLFinance plot with Moving Averages for (7, 30, 90, 180, 365) days ","52c425da":"# Use of Facebook Prophet for Stock Forecasting\n## TCS Stock forecast \n* This kernel uses Facebook Prophet (which uses SKLEARN) and Neural Prophet (which uses PyTorch) libaries to predict stocks. This kernel splits the NASDAQ stocks into ten folds and creates 10 output files each for the stocks in a PDF Format\n\n###  Yahoo! DataReader Download\n<div class=\"alert alert-block alert-info\">\n<b>Step-1:<\/b> Download data using Yahoo! Finance Data Reader<\/div>\n\n###  Facebook Prophet Models\n<div class=\"alert alert-block alert-info\">\n<b>Step-2:<\/b> Build Facebook Prophet Input dataset<\/div>\n<div class=\"alert alert-block alert-info\">\n<b>Step-3:<\/b> Run Prophet Model<\/div>\n<div class=\"alert alert-block alert-info\">\n<b>Step-4:<\/b> Generate Model Visualization <\/div>\n<div class=\"alert alert-block alert-info\">\n<b>Step-5:<\/b> Generate the Image Files <\/div>\n<div class=\"alert alert-block alert-info\">\n<b>Step-6:<\/b> Consolidate Image Files for Facebook Prophet Model <\/div>\n\n###  Neural Prophet Models\n<div class=\"alert alert-block alert-warning\">\n<b>Step-7-11:<\/b> Repeat Steps 2-6 for Neural Prophet Model <\/div>\n\n","15507bbf":"# [2\ufe0f\u20e3. Dataset Visualization Using Simple Plots](#2)\n\n\n## Initial simple plots using \n* *Pandas Plotting for opening and closing prices*\n* *Plotly OHLC (Open-High-Low-Close) Charts*\n* *Statistical Moving Average (SMA) Charts*\n* *Exponential Moving Average (EMA) Charts*\n","d7833dc6":"#### Reset the index on to the Date column","90fd97de":"* Simple Moving Average 'SMA'\n* Simple Moving Median 'SMM'\n* Smoothed Simple Moving Average 'SSMA'\n* Exponential Moving Average 'EMA'\n* Double Exponential Moving Average 'DEMA'\n* Triple Exponential Moving Average 'TEMA'\n* Triangular Moving Average 'TRIMA'\n* Triple Exponential Moving Average Oscillator 'TRIX'\n* Volume Adjusted Moving Average 'VAMA'\n* Kaufman Efficiency Indicator 'ER'\n* Kaufman's Adaptive Moving Average 'KAMA'\n* Zero Lag Exponential Moving Average 'ZLEMA'\n* Weighted Moving Average 'WMA'\n* Hull Moving Average 'HMA'\n* Elastic Volume Moving Average 'EVWMA'\n* Volume Weighted Average Price 'VWAP'\n* Smoothed Moving Average 'SMMA'\n* Fractal Adaptive Moving Average 'FRAMA'\n* Moving Average Convergence Divergence 'MACD'\n* Percentage Price Oscillator 'PPO'\n* Volume-Weighted MACD 'VW_MACD'\n* Elastic-Volume weighted MACD 'EV_MACD'\n* Market Momentum 'MOM'\n* Rate-of-Change 'ROC'\n* Relative Strenght Index 'RSI'\n* Inverse Fisher Transform RSI 'IFT_RSI'\n* True Range 'TR'\n* Average True Range 'ATR'\n* Stop-and-Reverse 'SAR'\n* Bollinger Bands 'BBANDS'\n* Bollinger Bands Width 'BBWIDTH'\n* Momentum Breakout Bands 'MOBO'\n* Percent B 'PERCENT_B'\n* Keltner Channels 'KC'\n* Donchian Channel 'DO'\n* Directional Movement Indicator 'DMI'\n* Average Directional Index 'ADX'\n* Pivot Points 'PIVOT'\n* Fibonacci Pivot Points 'PIVOT_FIB'\n* Stochastic Oscillator %K 'STOCH'\n* Stochastic oscillator %D 'STOCHD'\n* Stochastic RSI 'STOCHRSI'\n* Williams %R 'WILLIAMS'\n* Ultimate Oscillator 'UO'\n* Awesome Oscillator 'AO'\n* Mass Index 'MI'\n* Vortex Indicator 'VORTEX'\n* Know Sure Thing 'KST'\n* True Strength Index 'TSI'\n* Typical Price 'TP'\n* Accumulation-Distribution Line 'ADL'\n* Chaikin Oscillator 'CHAIKIN'\n* Money Flow Index 'MFI'\n* On Balance Volume 'OBV'\n* Weighter OBV 'WOBV'\n* Volume Zone Oscillator 'VZO'\n* Price Zone Oscillator 'PZO'\n* Elder's Force Index 'EFI'\n* Cummulative Force Index 'CFI'\n* Bull power and Bear Power 'EBBP'\n* Ease of Movement 'EMV'\n* Commodity Channel Index 'CCI'\n* Coppock Curve 'COPP'\n* Buy and Sell Pressure 'BASP'\n* Normalized BASP 'BASPN'\n* Chande Momentum Oscillator 'CMO'\n* Chandelier Exit 'CHANDELIER'\n* Qstick 'QSTICK'\n* Twiggs Money Index 'TMF'\n* Wave Trend Oscillator 'WTO'\n* Fisher Transform 'FISH'\n* Ichimoku Cloud 'ICHIMOKU'\n* Adaptive Price Zone 'APZ'\n* Squeeze Momentum Indicator 'SQZMI'\n* Volume Price Trend 'VPT'\n* Finite Volume Element 'FVE'\n* Volume Flow Indicator 'VFI'\n* Moving Standard deviation 'MSD'\n* Schaff Trend Cycle 'STC'\n","bc41b93a":"#### Create a histogram on the daily changes \/ percentage","c7f47076":"## Click on Zoom button to vied the performance","3f10ef79":"# [6\ufe0f\u20e3 Let us do a financial ratios calculation](#6)\n","b1649473":"### Moving Windows\n","1f31ee16":"# [8\ufe0f\u20e3 Let us do a Forecasting using FB Prophet ](#8)\n","668b7585":"# [3\ufe0f\u20e3. Dataset Visualization Using MPLFinance Plots](#3)\n","58ac7f25":"#### A Pie & Bar Chart of Daily Percentage change categories","309f397c":" *  Task-1 Dataset Load  \n *  Task-2 Data Visualization Charts  \n *  Task-3 Statistical Analysis and Inference  \n *  Task-4 Linear Regression and Forecasting \n","666c03c3":"# [5\ufe0f\u20e3 Let us do a financial ratios calculation using FINTA library](#5)","85094fb9":"# [1\ufe0f\u20e3. Dataset Loading](#1)\r>","57084555":"# [7\ufe0f\u20e3 Let us do a bit of forecasting using Regression ](#7)\n\n Some inspiration from the following post as well\n*  [MLQ.AI](https:\/\/www.mlq.ai\/price-prediction-with-linear-regression\/)\n","fae69ad3":"#### Check for the probability od drops and jumps for a range","8ad70d99":"#### Plot a histogram on logarithm of returns","8c898b30":"#### Build a probability distribution function plot using scipy stats package","9eb1403b":"> ","985d1175":"# [4\ufe0f\u20e3. Stock Data Analysis using standard techniques](#4)\n","a231eab3":"### CAGR Compound Annual Growth Rate (CAGR)","029f5cda":"#### Created MACD Values","25a7a25e":"### Let us do a bit of MACD based Trading indicators\n\n\n##### Inspiration from Alpharithms -  https:\/\/www.alpharithms.com\/calculate-macd-python-272222\/","24ff100e":"#### Plot 7-day rolling averages for volume of stocks traded","09ee27e0":"### Let us do some plotting","cc1564e2":"#### Calculate MACD through Pandas Technical Analysis Library","991113e0":"#### SMA chart plotting for 5, 20, 50, 200, 500 day moving averages","7b333825":"# [4\ufe0f\u20e3.1\ufe0f\u20e3 MACD Forecasting of data using Pandas TA](#4.1)","aabafda7":"#### Create a column on daily change percentages for the Stock","c256842b":"## Use backtesting library to do a simple data backtesting","4e0fd0e6":"#### What is the confidence level at various levels?","6c9af503":"#### Calculate the probability of better investment","1bed3fb9":"<a id=1><h3 >1\ufe0f\u20e3 Dataset Loading<br><\/h3><\/a>\n<a id=2><h3 >2\ufe0f\u20e3 Dataset Visualization Using Simple Plots<br><\/h3><\/a>\n<a id=3><h3 >3\ufe0f\u20e3 Dataset Visualization Using MPLFinance Plots<br><\/h3><\/a>\n<a id=4><h3 >4\ufe0f\u20e3 Stock Analysis of the data<br><\/h3><\/a>\n<a id=4.1><h4 >4\ufe0f\u20e3.1\ufe0f\u20e3 MACD Forecasting of data using Pandas TA<br><\/h4><\/a>\n<a id=5><h3 >5\ufe0f\u20e3 Let us do a financial ratios calculation using FINTA library <br><\/h3><\/a>\n<a id=6><h3 >6\ufe0f\u20e3 Let us do a financial ratios calculation<br><\/h3><\/a>\n<a id=7><h3 >7\ufe0f\u20e3 Let us do a bit of forecasting using Facebook Prophet Regression <br><\/h3><\/a>\n<a id=8><h3 >8\ufe0f\u20e3 Let us do a Facebook Prophet library<br><\/h3><\/a>\n","f73b9d5a":"#### Identify the days where the SMA20 is greater than SMA50 and tag the dates.These are target investment dates","959515da":"# [\ud83d\udd2e\ud83c\udfaf\ud83d\udcca TCS Stock Price Performance Analysis and Data Visualization \ud83d\udcca\ud83c\udfaf\ud83d\udd2e](#0)\n","afadc406":"#### SMA chart plotting for 5, 20, 50, 200, 500 day moving averages","a47859c8":"#### What is the Mu and Sigma for the stock at 5 and 95 percentile?","1983c15c":"# THIS IS A WORK IN PROGRESS ","e3b39c10":"### Volatility Calculation"}}