{"cell_type":{"6971f3e4":"code","f723b5ae":"code","e422cd3a":"code","e7dd06f0":"code","c868b540":"code","23afcf3e":"code","4fb1218e":"code","929a8abb":"code","968ae05d":"markdown","2eb45a12":"markdown","78bfeadf":"markdown","c5bf147c":"markdown","6e3d9d2e":"markdown","58a4c262":"markdown"},"source":{"6971f3e4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport time\nimport os\nimport glob\nimport PIL\nfrom PIL import Image\nimport itertools\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom torchvision.utils import save_image, make_grid\n\ncuda = torch.cuda.is_available()\n\nif cuda:\n    print(\"Cuda ON\")\nelse:\n    print(\"No GPU...\")","f723b5ae":"def to_rgb(image):\n    rgb_image = Image.new(\"RGB\", image.size)\n    rgb_image.paste(image)\n    return rgb_image\n\nclass ImageDataset(Dataset):\n    def __init__(self, root, transform_, aligned, mode='train'):\n        self.transform = transforms.Compose(transform_)\n        self.aligned = aligned\n        self.files_A = sorted(glob.glob(os.path.join(root, \"{}A\".format(mode)) + \"\/*.*\"))\n        self.files_B = sorted(glob.glob(os.path.join(root, \"{}B\".format(mode)) + \"\/*.*\"))\n        \n    def __getitem__(self, index):\n        image_A = Image.open(self.files_A[index % len(self.files_A)])\n        \n        if self.aligned:\n            image_B = Image.open(self.files_B[index % len(self.files_B)])\n        else:\n            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B)-1)])\n            \n        if image_A.mode != \"RGB\":\n            image_A = to_rgb(image_A)\n        if image_B.mode != \"RGB\":\n            image_B = to_rgb(image_B)\n            \n        item_A = self.transform(image_A)\n        item_B = self.transform(image_B)\n        \n        return {\"A\": item_A, \"B\": item_B}\n    \n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))","e422cd3a":"def weight_init(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n        if hasattr(m, 'bias') and m.bias is not None:\n            torch.nn.init.constant_(m.bias.data, 0.0)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)\n        \nclass residual_block(nn.Module):\n    def __init__(self, in_features):\n        super(residual_block, self).__init__()\n        \n        self.block = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features)\n        )\n        \n    def forward(self, x):\n        return x + self.block(x)\n    \nclass GeneratorResnet(nn.Module):\n    def __init__(self, input_shape, num_residual_blocks):\n        super(GeneratorResnet, self).__init__()\n        \n        channels = input_shape[0]\n        out_features = 64\n        \n        model = [\n            nn.ReflectionPad2d(channels),\n            nn.Conv2d(channels, out_features, 7),\n            nn.InstanceNorm2d(out_features),\n            nn.ReLU(inplace=True)\n        ]\n        \n        # DownSample\n        for _ in range(2):\n            in_features = out_features\n            out_features *= 2\n            model += [\n                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            \n        # Residual Blocks for 128 x 128 \/\/ for 256x256 or higher, use 9 such blocks\n        for _ in range(num_residual_blocks):\n            model += [residual_block(out_features)]\n            \n        # Upsample\n        for _ in range(2):\n            in_features = out_features\n            out_features \/\/= 2\n            model += [\n                nn.Upsample(scale_factor=2),\n                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            \n        # Output Layer\n        model += [\n            nn.ReflectionPad2d(channels),\n            nn.Conv2d(out_features, channels, 7),\n            nn.InstanceNorm2d(channels),\n            nn.Tanh()\n        ]\n        \n        self.model = nn.Sequential(*model)\n        \n    def forward(self, x):\n        return self.model(x)\n    \nclass Discriminator(nn.Module):\n    def __init__(self, input_shape):\n        super(Discriminator, self).__init__()\n        out_features, (channels, height, width) = 64, input_shape\n        self.output_shape = (1, height \/\/ 2**4, width \/\/ 2**4)\n        model = [\n            nn.Conv2d(channels, out_features, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n        \n        for _ in range(3):\n            in_features = out_features\n            out_features *= 2\n            model += [\n                nn.Conv2d(in_features, out_features, 4, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.LeakyReLU(0.2, inplace=True)\n            ]\n            \n        model += [nn.ZeroPad2d((1,0,1,0))]\n        model += [nn.Conv2d(out_features, 1, 4, padding=1)]\n        \n        self.model = nn.Sequential(*model)\n        \n    def forward(self, x):\n        return self.model(x)","e7dd06f0":"class LambdaLR:\n    def __init__(self, n_epochs, offset, decay_start_epoch):\n        self.n_epochs = n_epochs\n        self.offset = offset\n        self.decay_start_epoch = decay_start_epoch\n    \n    def step(self, epoch):\n        return 1.0 - max(0, epoch+self.offset-self.decay_start_epoch) \/ (self.n_epochs - self.decay_start_epoch)","c868b540":"class ReplayBuffer:\n    def __init__(self, max_size=50):\n        assert max_size > 0, \"Empty Buffer Not Allowed\"\n        self.max_size = max_size\n        self.data = []\n        \n    def push_pop(self, data):\n        to_return = []\n        for element in data.data:\n            element = torch.unsqueeze(element, 0)\n            if len(self.data) < self.max_size:\n                self.data.append(element)\n                to_return.append(element)\n            else:\n                if random.uniform(0,1) > 0.5:\n                    i = random.randint(0, self.max_size-1)\n                    to_return.append(self.data[i].clone())\n                    self.data[i] = element\n                else:\n                    to_return.append(element)\n        return Variable(torch.cat(to_return))","23afcf3e":"# Compile Loss Functions\ncriterion_GAN = nn.MSELoss()\ncriterion_cycle = nn.L1Loss()\ncriterion_identity = nn.L1Loss()\n\nimg = np.asarray(Image.open('\/kaggle\/input\/monet2photo\/monet2photo\/trainA\/0.jpg')) # Hardcoded for Kaggle Kernel\ninput_shape = (img.shape[2], img.shape[0], img.shape[1])\n\nG_AB = GeneratorResnet(input_shape, num_residual_blocks=9)\nG_BA = GeneratorResnet(input_shape, num_residual_blocks=9)\nD_A = Discriminator(input_shape)\nD_B = Discriminator(input_shape)\n\nif cuda:\n    G_AB, G_BA, D_A, D_B = G_AB.cuda(), G_BA.cuda(), D_A.cuda(), D_B.cuda()\n    criterion_GAN, criterion_cycle, criterion_identity = criterion_GAN.cuda(), criterion_cycle.cuda(), criterion_identity.cuda()\n    \nG_AB.apply(weight_init)\nG_BA.apply(weight_init)\nD_A.apply(weight_init)\nD_B.apply(weight_init)\n\n# ------------ #\n#  Hyperparams\n# ------------ #\n\nlr = 0.0002\nbeta1, beta2 = 0.5, 0.999\nn_epochs = 200\nepoch = 0\ndecay_epoch = 100\n\noptimizer_G = optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(beta1, beta2))\noptimizer_DA = optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, beta2))\noptimizer_DB = optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, beta2))\n\nlr_scheduler_G = optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\nlr_scheduler_DA = optim.lr_scheduler.LambdaLR(optimizer_DA, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\nlr_scheduler_DB = optim.lr_scheduler.LambdaLR(optimizer_DB, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n\nTensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n\nfakeA_buffer = ReplayBuffer()\nfakeB_buffer = ReplayBuffer()\n\ntransform_ = [\n    transforms.Resize(int(input_shape[1]*1.12), Image.BICUBIC),\n    transforms.RandomCrop((input_shape[1], input_shape[2])),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n]\n\ntrainloader = DataLoader(\n    ImageDataset(\"\/kaggle\/input\/monet2photo\/monet2photo\/\", transform_=transform_, aligned=False, mode='train'),\n    batch_size = 1,\n    shuffle=True\n)\n\n# validloader = DataLoader(\n#     ImageDataset(\"\/kaggle\/input\/monet2photo\/monet2photo\/\", transform_=transform_, aligned=False, mode='test'),\n#     batch_size=1,\n#     shuffle=True\n# )","4fb1218e":"def sample_image(finished_batch):\n    imgs = next(iter(validloader))\n    G_AB.eval()\n    G_BA.eval()\n    real_A = Variable(imgs['A'].type(Tensor))\n    real_B = Variable(imgs['B'].type(Tensor))\n    fake_A = G_BA(real_B)\n    fake_B = G_AB(real_A)\n    real_A = make_grid(real_A, nrow=5, normalize=True)\n    real_B = make_grid(real_B, nrow=5, normalize=True)\n    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n    save_image(image_grid, \"images\/%s.png\" % finished_batch, normalize=False)\n","929a8abb":"from collections import defaultdict\nt0 = time.time()\noutput = defaultdict(list)\n\nfor epoch in range(n_epochs):\n    for i, batch in enumerate(trainloader):\n        \n        real_A = Variable(batch['A'].type(Tensor))\n        real_B = Variable(batch['B'].type(Tensor))\n        \n        t = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n        f = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n        \n        # --------------- #\n        # Train Generator\n        # --------------- #\n        \n        optimizer_G.zero_grad()\n        G_AB.train()\n        G_BA.train()\n        \n        # Identity Loss\n        loss_id_A = criterion_identity(G_BA(real_A), real_A)\n        loss_id_B = criterion_identity(G_AB(real_B), real_B)\n        \n        loss_identity = (loss_id_A + loss_id_B) \/ 2\n        \n        fake_A, fake_B = G_BA(real_B), G_AB(real_A)\n        \n        # GAN Loss\n        loss_GAN_AB = criterion_GAN(D_B(fake_B), t)\n        loss_GAN_BA = criterion_GAN(D_A(fake_A), t)\n        \n        loss_GAN = (loss_GAN_AB + loss_GAN_BA) \/ 2\n        \n        # Cycle-consistency Loss\n        loss_cycle_A = criterion_cycle(G_BA(fake_B), real_A)\n        loss_cycle_B = criterion_cycle(G_AB(fake_A), real_B)\n        \n        loss_cycle = (loss_cycle_A + loss_cycle_B) \/ 2\n        \n        # Hyperparameters in the literature\n        loss_G = 5*loss_identity + 10*loss_cycle + loss_GAN\n        \n        loss_G.backward()\n        optimizer_G.step()\n        \n        # ------------------- #\n        # Train Discriminator\n        # ------------------- #\n        \n        G_AB.eval()\n        G_BA.eval()\n        \n        optimizer_DA.zero_grad()\n        \n        loss_real_DA = criterion_GAN(D_A(real_A), t)\n        fake_A = fakeA_buffer.push_pop(fake_A)\n        loss_fake_DA = criterion_GAN(D_A(fake_A), f)\n        loss_DA = (loss_real_DA + loss_fake_DA) \/ 2\n        loss_DA.backward()\n        optimizer_DA.step()\n        \n        optimizer_DB.zero_grad()\n        \n        loss_real_DB = criterion_GAN(D_B(real_B), t)\n        fake_B = fakeB_buffer.push_pop(fake_B)\n        loss_fake_DB = criterion_GAN(D_B(fake_B), f)\n        loss_DB = (loss_real_DB + loss_fake_DB) \/ 2\n        loss_DB.backward()\n        optimizer_DB.step()\n        \n        loss_D = (loss_DA + loss_DB) \/ 2\n        \n    t1 = time.time()\n    \n    output['epoch'].append(epoch+1)\n    output['Loss_G'].append(loss_G.item())\n    output['Loss_D'].append(loss_D.item())\n    output['Loss_id'].append(loss_identity.item())\n    output['Loss_GAN'].append(loss_GAN.item())\n    output['Loss_cycle'].append(loss_cycle.item())\n    \n    print(\"Epoch: {}\".format(epoch+1))\n    print(\"Time per Epoch: {:.1f}m\".format((t1-t0)\/60))\n    print(\"Generator Loss: {:.3f}\".format(loss_G.item()))\n    print(\"Discriminator Loss: {:.3f}\".format(loss_D.item()))\n    print(\"Identity Loss: {:.3f}\".format(loss_identity.item()))\n    print(\"GAN Loss: {:.3f}\".format(loss_GAN.item()))\n    print(\"Cycle Loss: {:.3f}\".format(loss_cycle.item()))\n    print('-'*50)","968ae05d":"# 6. Train","2eb45a12":"# 1. Module Import","78bfeadf":"# 4. Helper Functions","c5bf147c":"# 5. Compile Models","6e3d9d2e":"# 3. Baseline Model","58a4c262":"# 2. Dataset"}}