{"cell_type":{"61ba75c4":"code","ce924024":"code","258cdbe3":"code","15d23db0":"code","49ea68c6":"code","5cef4faa":"code","46d66f66":"code","fbcd2cec":"code","81499534":"code","48077787":"code","da405019":"code","9083d55d":"code","38d5efc8":"code","ec6ea6f9":"code","ebbbdc76":"code","fc3ce72c":"code","115f9277":"code","c5da00c2":"code","8d58953e":"code","b02eb5c7":"code","8cc21376":"code","bc079715":"code","c7b48a75":"code","7b318b0c":"code","3e582c58":"code","56833690":"code","e2add53a":"code","3288e8dd":"code","b0d330a4":"code","e2790910":"markdown","7c80c454":"markdown","aa70490e":"markdown","608de3d4":"markdown","bb516c67":"markdown","ce388ed7":"markdown","bb94ba65":"markdown","86d7e83f":"markdown","827910a8":"markdown","25950a68":"markdown","53f76bf4":"markdown","426b1e8f":"markdown","53bfff01":"markdown","f9b74ea5":"markdown","e309c338":"markdown","cf5133c5":"markdown","09ac639f":"markdown","38ac8833":"markdown","84f86bb5":"markdown","6bd85884":"markdown","5cc61ece":"markdown","f366bc2f":"markdown","6bc8e0e7":"markdown","24a07459":"markdown"},"source":{"61ba75c4":"!pip install pycaret\nimport numpy as np \nimport pandas as pd \nimport datetime as dt\n","ce924024":"car_prices = pd.read_csv('..\/input\/used-car-auction-prices\/car_prices.csv', nrows=10000) #nrows=400000\n#car_prices['Date']= pd.to_datetime(car_prices['saledate']).apply(lambda x: x.date())\n#car_prices[\"Date\"] = pd.to_datetime(car_prices[\"Date\"], format = '%Y-%m-%d')\ncar_prices.head()","258cdbe3":"#check the shape of data\ncar_prices.shape","15d23db0":"data = car_prices.sample(frac=0.9, random_state=786).reset_index(drop=True)\ndata_unseen = car_prices.drop(data.index).reset_index(drop=True)\n\nprint('Data for Modeling: ' + str(data.shape))\nprint('Unseen Data For Predictions: ' + str(data_unseen.shape))","49ea68c6":"from pycaret.regression import *\n","5cef4faa":"exp_reg101 = setup(data = data, \n             target = 'sellingprice',\n             numeric_imputation = 'mean',\n             categorical_features = ['make','model','trim','body','transmission','vin','state','color','interior','seller','saledate'], \n             silent = True,\n             session_id=123)","46d66f66":"compare_models()","fbcd2cec":"ada = create_model('ada')\n","81499534":"#trained model object is stored in the variable 'dt'. \nprint(ada)","48077787":"lightgbm = create_model('lightgbm')\n","da405019":"dt = create_model('dt')\n","9083d55d":"tuned_ada = tune_model(ada)\n","38d5efc8":"#tuned model object is stored in the variable 'tuned_dt'. \nprint(tuned_ada)","ec6ea6f9":"tuned_lightgbm = tune_model(lightgbm)\n","ebbbdc76":"tuned_dt = tune_model(dt)\n","fc3ce72c":"plot_model(tuned_lightgbm)\n","115f9277":"plot_model(tuned_lightgbm, plot = 'error')\n","c5da00c2":"plot_model(tuned_lightgbm, plot='feature')\n","8d58953e":"evaluate_model(tuned_lightgbm)\n","b02eb5c7":"predict_model(tuned_lightgbm);\n","8cc21376":"final_lightgbm = finalize_model(tuned_lightgbm)\n","bc079715":"#Final Light Gradient Boosting Machine parameters for deployment\nprint(final_lightgbm)","c7b48a75":"predict_model(final_lightgbm);","7b318b0c":"unseen_predictions = predict_model(final_lightgbm, data=data_unseen)\nunseen_predictions.to_csv('predicted.csv',index = False)\nunseen_predictions.head()","3e582c58":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\nplt.rcParams[\"figure.figsize\"] = [18, 6]\n\nunseen_predictions.sellingprice.plot(linewidth = 3, label = 'Actual', color = 'red')\nunseen_predictions.Label.plot(linewidth = 2, label = 'Predicted', color = 'blue', linestyle = '--')\nplt.legend(fontsize = 'large')","56833690":"save_model(final_lightgbm,'Final Lightgbm Model 30June2021')\n","e2add53a":"saved_final_lightgbm = load_model('Final Lightgbm Model 30June2021')\n","3288e8dd":"new_prediction = predict_model(saved_final_lightgbm, data=data_unseen)\n","b0d330a4":"new_prediction.head()\n","e2790910":"<h3>Step #9. Predict on unseen data<\/h3>\n\nThe predict_model() function is also used to predict on the unseen dataset.","7c80c454":"<h3>Step #3. Comparing All Models<\/h3>\n\nComparing all models to evaluate performance is the recommended starting point for modeling once the setup is completed. This function trains all models in the model library and scores them using kfold cross validation for metric evaluation. The output prints a score grid that shows average MAE, MSE, RMSE, R2, RMSLE and MAPE accross the folds (10 by default) of all the available models in the model library.","aa70490e":"<h3>Step #12. References<\/h3>\n\nThis section provides more resources on the topic if you are looking to go deeper.\n\n* https:\/\/pycaret.org\/\n* https:\/\/www.pycaret.org\/tutorials\/html\/REG101.html","608de3d4":"<h3>Step #10. Saving the model<\/h3>","bb516c67":"<h3>Step #0. Installing PyCaret + Import Library<\/h3>","ce388ed7":"<h4>Step #4.2. Light Gradient Boosting Machine<\/h4>","bb94ba65":"\n<center>\n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20200524202456\/pycaret-300x184.PNG\" width='400'>\n    <\/center>\n\n\n<center> PyCaret is an open source, low-code machine learning library in Python that allows you to go from preparing your data to deploying your model within minutes in your choice of notebook environment.<\/center>\n\n<br>\n<br>\n\n\n\n\n\n* Step #0. Installing PyCaret + Import Library\n* Step #1. Getting the Data\n* Step #2. Setting up Environment in PyCaret\n* Step #3. Comparing All Models\n* Step #4. Create a Model\n  * Step #4.1. AdaBoost Regressor\n  * Step #4.2. Light Gradient Boosting Machine\n  * Step #4.3. Decision Tree\n* Step #5. Tune a Model\n  * Step #5.1. AdaBoost Regressor\n  * Step #5.2. Light Gradient Boosting Machine\n  * Step #5.3. Decision Tree\n* Step #6. Plot a Model\n  * Step #6.1. Residual Plot\n  * Step #6.2. Prediction Error Plot\n  * Step #6.3. Feature Importance Plot\n* Step #7. Predict on test \/ hold-out Sample\n* Step #8. Finalize Model for Deployment\n* Step #9. Predict on unseen data\n* Step #10. Saving the model\n* Step #11. Loading the saved model\n* Step #12. References","86d7e83f":"<h3>Step #2. Setting up Environment in PyCaret<\/h3>\n\nThe setup() function initializes the environment in pycaret and creates the transformation pipeline to prepare the data for modeling and deployment. setup() must be called before executing any other function in pycaret. It takes two mandatory parameters: a pandas dataframe and the name of the target column.","827910a8":"<h4>Step #5.3. Decision Tree<\/h4>","25950a68":"<h4>Step #6.2. Prediction Error Plot<\/h4>","53f76bf4":"<h4>Step #6.1. Residual Plot<\/h4>","426b1e8f":"<h4>Step #4.1. AdaBoost Regressor<\/h4>","53bfff01":"<h3>Step #7. Predict on test \/ hold-out Sample<\/h3>\n\nBefore finalizing the model, it is advisable to perform one final check by predicting the test\/hold-out set and reviewing the evaluation metrics.","f9b74ea5":"<h3>Step #4. Create a Model<\/h3>\n\nWhile compare_models() is a powerful function and often a starting point in any experiment, it does not return any trained models. PyCaret's recommended experiment workflow is to use compare_models() right after setup to evaluate top performing models and finalize a few candidates for continued experimentation. As such, the function that actually allows to you create a model is unimaginatively called create_model(). This function creates a model and scores it using stratified cross validation. Similar to compare_models(), the output prints a score grid that shows MAE, MSE, RMSE, R2, RMSLE and MAPE by fold.","e309c338":"<h4>Step #5.2. Light Gradient Boosting Machine<\/h4>","cf5133c5":"<h3>Step #6.  Plot a Model<\/h3>\n\nBefore model finalization, the plot_model() function can be used to analyze the performance across different aspects such as Residuals Plot, Prediction Error, feature importance etc. This function takes a trained model object and returns a plot based on the test \/ hold-out set.","09ac639f":"<h3>Step #11. Loading the saved model<\/h3>","38ac8833":"The Label column is added onto the data_unseen set. Label is the predicted value using the final_lightgbm model. If you want predictions to be rounded, you can use round parameter inside predict_model().","84f86bb5":"<h4>Step #5.1. AdaBoost Regressor<\/h4>","6bd85884":"<h4>Step #4.3. Decision Tree<\/h4>","5cc61ece":"<h3>Step #8. Finalize Model for Deployment<\/h3>\n\nModel finalization is the last step in the experiment. A normal machine learning workflow in PyCaret starts with setup(), followed by comparing all models using compare_models() and shortlisting a few candidate models (based on the metric of interest) to perform several modeling techniques such as hyperparameter tuning, ensembling, stacking etc.","f366bc2f":"<h4>Step #6.3. Feature Importance Plot<\/h4>","6bc8e0e7":"<h3>Step #1. Getting the Data<\/h3>","24a07459":"<h3>Step #5. Tune a Model<\/h3>\n\nWhen a model is created using the create_model() function it uses the default hyperparameters. In order to tune hyperparameters, the tune_model() function is used. This function automatically tunes the hyperparameters of a model on a pre-defined search space and scores it using kfold cross validation. The output prints a score grid that shows MAE, MSE, RMSE, R2, RMSLE and MAPE by fold."}}