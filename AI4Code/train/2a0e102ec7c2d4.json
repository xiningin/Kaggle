{"cell_type":{"c5a1c453":"code","e68f8013":"code","8f8fe700":"code","c66e4564":"code","be1897c4":"code","1750e664":"code","d217ac6b":"code","9ae1958c":"code","c4802f83":"code","65579207":"code","201a9dfc":"code","5861a516":"code","e6c8442f":"code","671818c5":"code","06d4e5fa":"code","47cc8a2b":"markdown","ef2c9d6a":"markdown","eaab3625":"markdown","a582ed80":"markdown","f7e70b92":"markdown","db0981a3":"markdown","124f9f61":"markdown","4ae50e41":"markdown","7d9a4aec":"markdown","68bcabd0":"markdown","fdcc2100":"markdown","f44d5f40":"markdown"},"source":{"c5a1c453":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n","e68f8013":"# Introductory data\ndf=pd.read_csv('..\/input\/suicide-rates-overview-1985-to-2016\/master.csv')\ndf.head()\nimport pandasql as ps\ncountry = \"Spain\" # we can change the country \n\nSQL=f\"\"\"\n    SELECT year , \n            sum(\"suicides\/100k pop\")\/12 as suicides_{country} \n    FROM df \n    WHERE country = '{country}' group by year order by year\"\"\"  \ndf_es =  ps.sqldf( SQL, locals())\ndf_es.set_index('year', inplace=True)\n\n\n\ndf_es[f'suicides_{country}'].plot( figsize=(15,4), title=f\"Suicides {country}, rate \/100k pop\")","8f8fe700":"df_es.head()\n","c66e4564":"kk = pd.DataFrame()\ngroups = df.age.unique()\n\nfor sex in ['male','female'] :\n    for age_group in groups :\n        kk[ age_group.replace('5-14','05-14' )+'_'+sex] = df.loc[ (df['country']==country) & (df['age'] == age_group) & ( df['sex'] == sex) ]['suicides\/100k pop'].values\n\nkk.index = df.loc[ (df['country']==country) & (df['age'] == age_group) & ( df['sex'] == sex) ]['year'].values\n\ndf_es_gender_age = kk\n\ndf_es_gender_age.head()","be1897c4":"df_female= pd.DataFrame()\ndf_male= pd.DataFrame()\n\nfor c in df_es_gender_age.columns.values :\n    if \"female\" in c : \n        df_female[c] = df_es_gender_age[c]\n    else : \n        df_male[c] = df_es_gender_age[c]\n        \n\ndf_male.plot(   figsize=(15,4), title=f\"Male suicide rates in {country}, per age\")\n\ndf_female.plot( figsize=(15,4), title=f\"Female suicide rates in {country}, per age\")","1750e664":"import matplotlib.pyplot as plt\ncompare=[]\nplt.style.use('ggplot')\n\nfor age in groups :\n    compare_male_female = pd.DataFrame()\n    compare_male_female[age+'_male']   = df_male  [age.replace('5-14','05-14' )+'_male']\n    compare_male_female[age+'_female'] = df_female[age.replace('5-14','05-14' )+'_female']\n    compare_male_female.plot(   figsize=(15,4), title=f\"Male\/Female suicide rates in {country}, per age, {age}\")","d217ac6b":"import matplotlib.pyplot as plt\n\n    \nfor age in groups :\n    compare_male_female = pd.DataFrame()\n    compare=[]\n    compare_male_female[age+'_male']   = df_male  [age.replace('5-14','05-14' )+'_male']\n    compare_male_female[age+'_female'] = df_female[age.replace('5-14','05-14' )+'_female']\n    compare.insert(0,compare_male_female[age+'_male'  ].mean())\n    compare.insert(1,compare_male_female[age+'_female'].mean())\n    male_percentage = str(compare[0]\/(compare[0]+compare[1])*100)[0:5]\n    plt.title(f\"Suicide rated in {country}, mean values, {age}, {male_percentage}% male\")\n    plt.bar([\"male\",\"female\"],compare , color='green',)\n    plt.show()","9ae1958c":"headlines = pd.read_csv('..\/input\/million-headlines\/abcnews-date-text.csv')\nheadlines.head() \n\n\n\nSQL=f\"SELECT publish_date  , headline_text FROM headlines WHERE headline_text LIKE '%{country}%'\"  \nhds =  ps.sqldf( SQL, locals())\n\ncountry_lwr=country.lower()\nhds['year'] = hds['publish_date'].astype(str).str[:4]\nhds['headline_text_new'] = hds['headline_text'].astype(str).str.replace(f\"in {country}\",\"\").replace(f\"{country_lwr}\",\"\").replace(\";\",\"\").replace(\",\",\"\")\nhds['headline_text'] = hds['headline_text_new']\n\nhds.drop(\"headline_text_new\", axis=1, inplace=True)\nhds.drop(\"publish_date\", axis=1, inplace=True)\n\nhds.head()\n\n","c4802f83":"from stop_words import get_stop_words\nstop  =  get_stop_words('english') + [country.lower(),country.lower()+'s',\",\",\";\"]\n# That would be the line to remove stop word, but we use the vectorizer to remote it, so we do not need next line\n# hds['headline_text'] = hds['headline_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n\nprint(stop)","65579207":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nimport numpy as np\n\nMAX_FEATURES=10\ndef get_topics_year( year ):\n    \"\"\"Get the most frecuent topic for a given year.\n    Args:\n        yeat: Year of the news to be considered.\n    Returns:\n        Array with the news\n\n    \"\"\"\n\n    corpus = hds.loc[ hds['year'] == year ]\n    corpus.drop(\"year\", axis=1, inplace=True)\n\n    tf = TfidfVectorizer(analyzer='word',\n                         ngram_range=(2,2),\n                         max_features=MAX_FEATURES,\n                         min_df = 0, \n                         stop_words = stop, \n                         sublinear_tf=True)\n    X = tf.fit_transform(corpus['headline_text'].values)\n    feature_names = tf.get_feature_names()\n    tf.get_feature_names()\n    return tf.get_feature_names()\n\ntopics = pd.DataFrame()\nrows = []\nfor i in range(2003,2016):\n    topic_this_year = {'year' : str(i) , 'topics' : get_topics_year(str(i)   ) }\n    rows.append(topic_this_year)\n    \ntopics=pd.DataFrame.from_dict(rows, orient='columns')\ntopics.set_index('year', inplace=True)\n\ntopics","201a9dfc":"for i in range(2003,2016):\n    this_year_suicide = df_es.loc[i,f'suicides_{country}'] -  df_es.loc[i-1,f'suicides_{country}']\n    topics.loc[str(i),'this_year_suicide'] = this_year_suicide","5861a516":"print(\"year\",\"this_year_suicide variation\", \"topics\")\nmy_rows=[]\nfor i, row in topics.iterrows():\n    print( i,row['this_year_suicide'],row['topics']) \n    \n    my_rows.append ({ \"year\" : i ,\n                     \"this_year_suicide\" : row['this_year_suicide'] ,\n                     \"topics\" : row['topics'] })\n\nsummary_country =pd.DataFrame.from_dict(my_rows, orient='columns')\nsummary_country['headlines']= summary_country['topics'].apply(', '.join)\n\nsummary_country[['year', 'this_year_suicide','headlines']]","e6c8442f":"from IPython.core.display import HTML \n\ns = f\"\"\"<iframe width=\"900\" height=\"800\" frameborder=\"0\" scrolling=\"no\" src=\"\/\/plot.ly\/~jaimevalero78\/48.embed\"><\/iframe>\"\"\"\ndisplay(HTML(s))\n","671818c5":"def accumulate_frecuency_terms(df,d):\n    for i, row in df.iterrows():\n        for term in row['topics'] :\n            if term not in d : \n                d[term] =           row['this_year_suicide']\n            else :             \n                d[term] = d[term] + row['this_year_suicide']\n            \nfrom collections import defaultdict\nd = defaultdict(float)\n\n#d={}\naccumulate_frecuency_terms(topics,d)\n#print(d)\ntext=\"\"\n\n\nfrom IPython.display import Image\nfrom IPython.core.display import HTML \n\n\narray=[]\nresults_contry = pd.DataFrame()\nfor w in sorted(d, key=d.get, reverse=True):\n    array.append( { \"term\" : w , \"suicide_impact\" :  d[w]})\n    \n\nresults_country=pd.DataFrame.from_dict(array, orient='columns')\n\ns = f\"\"\"<h3>Top headlines in years with increases in suicide rates, for {country}: <\/h3>\"\"\"\ns = s + f\"\"\"Aka: Bad news for {country}  :-(\"\"\"\ndisplay(HTML(s))\nresults_country.head(20)\n\n\n","06d4e5fa":"s = f\"\"\"<h3>Top headlines in years with decreases in suicide rates, for {country}: <\/h3>\"\"\"\ns = s + f\"\"\"Aka: Good news for  {country} :-) \"\"\"\ndisplay(HTML(s))\nresults_country.sort_values(by=['suicide_impact'],ascending = True ).head(15)","47cc8a2b":"#\u00a0Headlines topic extraction using TF-IDF Vectorizer.#\n\nFirst we do some data exploration.\n\nI use SQL syntax, because it is just faster than remember all those  dataframe commands to group data.\n","ef2c9d6a":"We list the news for each year, with the increase in suicides, for each year that we have headlines.","eaab3625":"We compare the male \/ female data.\n\nIn Spain, male casualties are aproximately 80%.","a582ed80":"# Relation between headlines and suicides\n\n##\u00a0Analyzing which headlines news have a bigger impact in the suicide rates.\n\nI am going to use two datasets.\n- [Suicide Rates Overview 1985 to 2016\n](https:\/\/www.kaggle.com\/russellyates88\/suicide-rates-overview-1985-to-2016) \n\n- [A Million News Headlines](https:\/\/www.kaggle.com\/therohk\/million-headlines) \n\n\nCase of use : \n - Spain\n \n### Index\n  - Exploratory data : suicide rates.\n  - Exploratory data : Male vs Female suicide rates.\n  - Headlines topic extraction using TF-IDF Vectorizer.\n  - Relation between news and change in suicide rates.\n  - Conclusions\n  ","f7e70b92":"We calculate the increase in the suicide rate, respect the previous year.\n\n - this_year_suicide > 0 .  There has been an increase in the suicide rate, from the previous year.\n \n - this_year_suicide < 0 .  There has been a decrease in the suicide rate, from the former year.","db0981a3":"We try to get the new that have a greater impact on the suicide rates.\n\nTo do this, we accumulate each news, changes over the year, and store it into a DataFrame.","124f9f61":"We create a function that return the topics for a giver year, and we call it sequentially.\n","4ae50e41":"<iframe width=\"900\" height=\"800\" frameborder=\"0\" scrolling=\"no\" src=\"\/\/plot.ly\/~jaimevalero78\/48.embed\"><\/iframe>","7d9a4aec":" # Conclussions\n\n - There is a correlation between certain news and important variations in the suicide rate, given two consecutive years.\n \n \n - The event with the highest positive impact seems to be the winning of the football world cup in 2010. \n This euphoria climate brought by this news, possibly saved the life of about 400 people, if we compare with the numbers of the previous year.\n \n \n - By contrast, the event with the worst impacts seems to be the financial crisis in 2012, when Spain faced a default in national debt. \n It is difficult to ponder how many lives has been lost due to economic difficulties. Considering that this event affected several countries over a span of years, we can affirm that it is a higher order of magnitude in suicides due to economical crisis worldwide.\n\n\n- Other news seems to have a lesser impact - War on terror, government crisis.\n\n\n- I would like to have had more recent data, to ponder the weight of spanish recents events in suicide rates. Specifically, catalonian crisis and special laws against genre violence.\n\n\n- Finally, many headlines does not seem to have specific impact - some news have seen both in 'good' and 'bad' years. \nThis would point that many of the messages the media send to us does not have an impact on people lifes, and contains only anecdotical value.\n\n\n\n ","68bcabd0":"We create a dataframe, to group for age interval and sex. ","fdcc2100":"Group and create chart for suicide rating based on sex and age\n\nWe will see the oldest men have the greatest risk, with a big difference.","f44d5f40":"Analyzing which news have a bigger impact in the suicide rates.\n\n"}}