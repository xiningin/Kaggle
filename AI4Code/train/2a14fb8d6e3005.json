{"cell_type":{"78ede487":"code","4146876a":"code","c254fafa":"code","9540d955":"code","e6ed352e":"code","d81bc584":"code","f3e4d732":"code","e6fc4f3f":"code","c7878186":"code","06754aeb":"code","ffe3f8f8":"code","de740b3c":"code","78efea54":"code","5820ad83":"code","cd80fb75":"code","6a6466c1":"code","6e67a6b0":"code","34a445cb":"code","fa2e96e7":"code","1242cb06":"code","bc80b302":"code","7e11e042":"code","6ac7cfbf":"code","12e0727f":"code","d7cbd6b9":"code","2df42bbb":"code","0a759d39":"code","fbc65682":"code","3de01679":"code","a9eab3d7":"code","d0b13421":"code","4c2908e5":"code","f4b22a11":"code","aa7dda96":"code","27705e7b":"code","1dd8c0b4":"code","0b3c217f":"code","d50c9d48":"code","63ba6123":"code","15132a69":"code","14753f45":"code","65884951":"code","f1392eba":"code","1c8dda0a":"code","baf42880":"code","3de49396":"code","8ed717c4":"code","16ea6939":"code","d273d8c9":"code","4a1916c5":"code","304151e6":"code","bd84bcc1":"code","2b266eae":"code","791776e5":"code","67385520":"code","bf80bbe7":"code","c677b117":"code","3aef3dba":"code","0738cac2":"code","dbf75e4a":"code","c6f629ff":"code","76c4575f":"code","3ddb0ca8":"code","af17f15d":"code","924013d0":"code","4456289d":"code","4cf4fdc0":"code","33d46c44":"code","fb53fcc8":"code","e3b89e6c":"code","d4f40ccf":"code","e1c5bc79":"code","787390e2":"code","f9248f13":"code","c068c3a0":"code","199b6df2":"code","0c7338a5":"code","ac05eaf4":"code","0f42905a":"code","3e55907f":"code","f4ecd9c8":"code","4e32b7a7":"code","910533b8":"markdown","a8d5500c":"markdown"},"source":{"78ede487":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4146876a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Plotting\n%matplotlib inline\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (10,10) #Make the plots bigger by default\nplt.rcParams[\"lines.linewidth\"] = 2 #Setting the default line width\nplt.style.use(\"ggplot\")\n\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose #Describes the time data\nfrom statsmodels.tsa.stattools import adfuller #Check if data is stationary\nfrom statsmodels.graphics.tsaplots import plot_acf #Compute lag for ARIMA\nfrom statsmodels.graphics.tsaplots import plot_pacf #Compute partial lag for ARIMA\nfrom statsmodels.tsa.arima_model import ARIMA #Predictions and Forecasting\n\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom datetime import datetime\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping , ReduceLROnPlateau\nfrom sklearn.metrics import mean_absolute_error","c254fafa":"df=pd.read_csv(\"\/kaggle\/input\/ethereum-historical-dataset\/ETHUSD.csv\")\ndf.head()","9540d955":"df[\"Date\"]=pd.to_datetime(df.Date,dayfirst=True)\ndf.set_index(\"Date\",inplace=True)\ndf","e6ed352e":"df.isnull().sum()\n","d81bc584":"df=df.fillna(method=\"bfill\")\n","f3e4d732":"df.isnull().sum()\n","e6fc4f3f":"df['Open'].plot(figsize=(12,8))\nplt.ylabel(\"open price\")","c7878186":"df['Volume'].plot(figsize=(12,8))\nplt.ylabel(\"Volume price\")","06754aeb":"df['Total Pos'] = df.sum(axis=1)\n","ffe3f8f8":"df['Total Pos'].plot(figsize=(10,8))\nplt.title('Total Portfolio Value')","de740b3c":"df['Daily Return'] = df['Total Pos'].pct_change(1)\n","78efea54":"df['Daily Return'].mean()\n","5820ad83":"df['Daily Return'].plot(kind='kde')\n","cd80fb75":"SR = df['Daily Return'].mean()\/df['Daily Return'].std()\n","6a6466c1":"all_plot = df\/df.iloc[0]\nall_plot.plot(figsize=(24,16))","6e67a6b0":"df.hist(bins=100,figsize=(12,6));\nplt.tight_layout()","34a445cb":"df.resample(rule='A').mean()","fa2e96e7":"title = 'Yearly Mean Closing Price'\ndf['Open'].resample('A').mean().plot.bar(title=title,color=['#b41f7d']);","1242cb06":"df['Open'].resample('M').max().plot.bar(figsize=(18,12),color='#1f77b4');\n","bc80b302":"ax = df['Open'].plot(figsize=(24,6),title=title)\n","7e11e042":"df['6-month-SMA'] = df['Open'].rolling(window=6).mean()\ndf['12-month-SMA'] = df['Open'].rolling(window=12).mean()\ndf['2-month-SMA'] = df['Open'].rolling(window=2).mean()","6ac7cfbf":"df.head(15)\n","12e0727f":"df[[\"Open\",\"6-month-SMA\",\"12-month-SMA\",\"2-month-SMA\"]].plot(figsize=(24,10));\n","d7cbd6b9":"df[[\"Open\",\"6-month-SMA\"]].plot(figsize=(18,10));\n","2df42bbb":"df[['Open','6-month-SMA']].iloc[:50].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","0a759d39":"df['EWMA12'] = df['Open'].ewm(span=14,adjust=True).mean()\n","fbc65682":"df[['Open','EWMA12']].plot(figsize=(24,12));","3de01679":"df[['Open','EWMA12']].iloc[:100].plot(figsize=(12,6)).autoscale(axis='x',tight=True);","a9eab3d7":"df[['Open','EWMA12','12-month-SMA']].plot(figsize=(30,15)).autoscale(axis='x',tight=True);\n","d0b13421":"span = 12\nalpha = 2\/(span+1)","4c2908e5":"df['EWMA12'] = df['Open'].ewm(alpha=alpha,adjust=False).mean()","f4b22a11":"model=SimpleExpSmoothing(df[\"Open\"])","aa7dda96":"model.fit(smoothing_level=alpha,optimized=False)","27705e7b":"fitted_model=model.fit(smoothing_level=alpha,optimized=False)","1dd8c0b4":"fitted_model.fittedvalues","0b3c217f":"fitted_model.fittedvalues.shift(-1)","d50c9d48":"df[\"SES12\"]=fitted_model.fittedvalues.shift(-1)","63ba6123":"df[['Close',\"SES12\"]].plot(figsize=(30,15)).autoscale(axis='x',tight=True);","15132a69":"df['DESadd12'] = ExponentialSmoothing(df['Open'], trend='add').fit().fittedvalues.shift(-1);\ndf.head()","14753f45":"df[['Open',  'SES12', 'DESadd12']].plot(figsize=(24,12))","65884951":"df[['Open','EWMA12','DESadd12']].iloc[:12].plot(figsize=(12,6)).autoscale(axis='x',tight=True);","f1392eba":"df['DESmul12'] = ExponentialSmoothing(df['Open'], trend='mul').fit().fittedvalues.shift(-1)\ndf.head()","1c8dda0a":"df[['Open','DESadd12','DESmul12']].iloc[:24].plot(figsize=(12,6)).autoscale(axis='x',tight=True);","baf42880":"df['TESadd12'] = ExponentialSmoothing(df['Open'],trend='add',seasonal='add',seasonal_periods=12).fit().fittedvalues\ndf.head()","3de49396":"df['TESmul12'] = ExponentialSmoothing(df['Open'],trend='mul',seasonal='mul',seasonal_periods=12).fit().fittedvalues\ndf.head()","8ed717c4":"df[['Open','TESadd12','TESmul12']].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","16ea6939":"df[['Open','TESadd12','TESmul12']].iloc[:24].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","d273d8c9":"plt.figure(figsize=(16,6))\nplt.title('Open Price History')\nplt.plot(df['Open'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Open Price USD ($)', fontsize=18)\nplt.show()\n","4a1916c5":"data = df.filter(['Open'])\n\ndataset = data.values\n\ntraining_data_len = int(np.ceil( len(dataset) * .95 ))\n\ntraining_data_len","304151e6":"scaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","bd84bcc1":"train_data = scaled_data[0:int(training_data_len), :]\n\nx_train = []\ny_train = []\n\nfor i in range(50, len(train_data)):\n    x_train.append(train_data[i-50:i, 0])\n    y_train.append(train_data[i, 0])\n    if i<= 51:\n        print(x_train)\n        print(y_train)\n        print()\n        \n\nx_train, y_train = np.array(x_train), np.array(y_train)\n\n\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))","2b266eae":"model = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(32))\nmodel.add(Dense(16))\nmodel.add(Dense(1))","791776e5":"model.compile(optimizer='adam', loss='mean_squared_error')\n","67385520":"callbacks = [EarlyStopping(patience=4, monitor='val_loss', mode='min'), \n             ReduceLROnPlateau(patience=2, verbose=1)]  ","bf80bbe7":"history =model.fit(x_train, y_train, \n                        epochs=20,\n                        batch_size=1,\n                        callbacks=[callbacks],\n                        )","c677b117":"# Create the testing data set\n# Create a new array containing scaled values from index 1543 to 2002 \ntest_data = scaled_data[training_data_len - 50: , :]\n# Create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(50, len(test_data)):\n    x_test.append(test_data[i-50:i, 0])\n    \n\nx_test = np.array(x_test)\n\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n\npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\n\n\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\nrmse","3aef3dba":"mean_absolute_error(y_test, predictions)\n","0738cac2":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n# Visualize the data\nplt.figure(figsize=(16,6))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Open Price USD ($)', fontsize=18)\nplt.plot(train['Open'])\nplt.plot(valid[['Open', 'Predictions']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\nplt.show()","dbf75e4a":"predictions = model.predict(x_test)\n","c6f629ff":"valid[['Open','Predictions']].iloc[:100].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","76c4575f":"df=pd.read_csv(\"\/kaggle\/input\/ethereum-historical-dataset\/ETHUSD.csv\")\ndf.head()","3ddb0ca8":"close_df=df[[\"Date\", \"Close\"]].copy()\n","af17f15d":"close_df[\"Date\"] = pd.to_datetime(close_df[\"Date\"])\nclose_df.set_index(\"Date\", inplace = True) ","924013d0":"close_df = close_df.asfreq(\"d\")\n","4456289d":"close_df = close_df.fillna(method  = \"bfill\")","4cf4fdc0":"decomp = seasonal_decompose(close_df, model = \"multiplicative\") #Decompose the data\nx = decomp.plot()","33d46c44":"adf = adfuller(close_df[\"Close\"])\nadf","fb53fcc8":"closeLog = np.log(close_df) \ncloseStationary = closeLog -closeLog.shift() \ncloseStationary = closeStationary.dropna() \ncloseStationary.plot()","e3b89e6c":"adf = adfuller(closeStationary[\"Close\"])\nadf","d4f40ccf":"decomp = seasonal_decompose(closeStationary)\nx = decomp.plot()","e1c5bc79":"fig,axes = plt.subplots(2,2) \n\na = axes[0,0].plot(close_df[\"Close\"]) \na = axes[0,0].set_title(\"Original Data\") \nb = plot_acf(close_df[\"Close\"],ax=axes[0,1]) \n\nx = axes[1,0].plot(closeStationary[\"Close\"])\nx = axes[1,0].set_title(\"Stationary Data\") \ny = plot_acf(closeStationary[\"Close\"],ax=axes[1,1]) ","787390e2":"fig,axes = plt.subplots(1,2) \n\na = axes[0].plot(close_df[\"Close\"]) \na = axes[0].set_title(\"Stationary\") \nb = plot_pacf(close_df[\"Close\"], ax = axes[1], method = \"ols\") ","f9248f13":"fig,axes = plt.subplots(1,2) \n\na = axes[0].plot(close_df[\"Close\"])\na = axes[0].set_title(\"Stationary\") \nb = plot_acf(close_df[\"Close\"], ax = axes[1]) ","c068c3a0":"model = ARIMA(close_df, order = (6, 1, 6)) \nfitModel = model.fit(disp = 1)","199b6df2":"plt.rcParams.update({\"figure.figsize\" : (12,6), \"lines.linewidth\" : 0.05, \"figure.dpi\" : 100}) \n\nx = fitModel.plot_predict(dynamic = False) \nx = plt.title(\"Forecast Fitting\")\nplt.show() ","0c7338a5":"plt.rcParams.update({\"figure.figsize\" : (12,5), \"lines.linewidth\": 2}) \nlength = int((len(close_df)*9)\/10) \nprint(length)","ac05eaf4":"train = close_df[:length] \ntest = close_df[length:] \nmodelValid = ARIMA(train,order=(5,1,5)) \nfitModelValid = modelValid.fit(disp= -1) ","0f42905a":"fc,se,conf = fitModelValid.forecast(len(close_df) - length) \nforecast = pd.Series(fc, index = test.index)","3e55907f":"plt.plot(train,label = \"Training Data\") \nplt.plot(test,label = \"Actual Continuation\")\nplt.plot(forecast,label = \"Forecasted Continuation\", color = \"g\")\n\nplt.title(\"ARIMA Forecast\")\nplt.legend(loc = \"upper left\") \nplt.xlabel(\"Year\") \nplt.ylabel(\"close Price\")","f4ecd9c8":"modelPred = ARIMA(close_df,order=(5,1,5)) \nfitModelPred = modelPred.fit(disp= -1) ","4e32b7a7":"fitModelPred.plot_predict(1,len(close_df) + 1000) \nx = fitModelPred.forecast(1000) \nx = plt.title(\"Amazon Stock Forecast\") \nx = plt.xlabel(\"Year\") \nx = plt.ylabel(\"close Price\") ","910533b8":"# MA Lag","a8d5500c":"# ARIMA"}}