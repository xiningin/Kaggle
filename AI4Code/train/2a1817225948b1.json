{"cell_type":{"ed2ff164":"code","505b82c0":"code","ea20b511":"code","5d51299f":"code","26d2325a":"code","8767000a":"code","49bdb98a":"code","633a8a5a":"code","e27d759e":"code","9968add5":"code","d0a6c8ff":"markdown","716f25b2":"markdown","e1107d6d":"markdown","312e94d8":"markdown","4ed4688c":"markdown","102ba63e":"markdown","9cfb5f44":"markdown","cdec31c4":"markdown","aacbd21e":"markdown","fe7c843e":"markdown"},"source":{"ed2ff164":"import pandas as pd\nimport numpy as np\nimport os\nimport math\nimport itertools\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport keras\nfrom keras.optimizers import Adam\nfrom keras.layers import GlobalAveragePooling2D, Dense\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras_applications.densenet import DenseNet201\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import compute_sample_weight, compute_class_weight\nfrom sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix\n\ninput_path = '.\/..\/input'\nmetadata_path = os.path.join(input_path, 'HAM10000_metadata.csv')\npart1_path = os.path.join(input_path, 'ham10000_images_part_1')\npart2_path = os.path.join(input_path, 'ham10000_images_part_2')","505b82c0":"label_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\ndata = pd.read_csv(metadata_path)\nnum_examples = data.values.shape[0]\ninputs = np.empty(shape=(num_examples, 224, 224, 3), dtype=np.float32)\nlabels = np.empty(shape=(num_examples), dtype=np.uint8)\n\nfor i, row in enumerate(data.values):\n    img_id = row[1]\n    label = row[2]\n    im_path = ''\n    im_path1 = os.path.join(part1_path, img_id) + '.jpg'\n    im_path2 = os.path.join(part2_path, img_id) + '.jpg'\n    if (os.path.isfile(im_path1)):\n        im_path = im_path1\n    elif (os.path.isfile(im_path2)):\n        im_path = im_path2\n    else:\n        raise Exception ('File not found \\'%s\\'' %img_id)\n    img = Image.open(im_path).resize((224, 224), Image.LANCZOS)\n    inputs[i] = np.array(img)\/255\n    labels[i] = label_names.index(label)\n","ea20b511":"x_train, x_test, y_train, y_test = train_test_split(\n    inputs, labels, test_size=0.2, random_state=2019)\ndel inputs\ndel labels\nx_train, x_val, y_train, y_val = train_test_split(\n    x_train, y_train, test_size=0.25, random_state=2019)","5d51299f":"import keras.backend as K\nfrom keras.legacy import interfaces\nfrom keras.optimizers import Optimizer\n\nclass AdamAccumulate(Optimizer):\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., amsgrad=False, accum_iters=1, **kwargs):\n        if accum_iters < 1:\n            raise ValueError('accum_iters must be >= 1')\n        super(AdamAccumulate, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.amsgrad = amsgrad\n        self.accum_iters = K.variable(accum_iters, K.dtype(self.iterations))\n        self.accum_iters_float = K.cast(self.accum_iters, K.floatx())\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n\n        completed_updates = K.cast(K.tf.floordiv(self.iterations, self.accum_iters), K.floatx())\n\n        if self.initial_decay > 0:\n            lr = lr * (1. \/ (1. + self.decay * completed_updates))\n\n        t = completed_updates + 1\n\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) \/ (1. - K.pow(self.beta_1, t)))\n\n        # self.iterations incremented after processing a batch\n        # batch:              1 2 3 4 5 6 7 8 9\n        # self.iterations:    0 1 2 3 4 5 6 7 8\n        # update_switch = 1:        x       x    (if accum_iters=4)  \n        update_switch = K.equal((self.iterations + 1) % self.accum_iters, 0)\n        update_switch = K.cast(update_switch, K.floatx())\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        gs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        else:\n            vhats = [K.zeros(1) for _ in params]\n\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        for p, g, m, v, vhat, tg in zip(params, grads, ms, vs, vhats, gs):\n\n            sum_grad = tg + g\n            avg_grad = sum_grad \/ self.accum_iters_float\n\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * avg_grad\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(avg_grad)\n\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                p_t = p - lr_t * m_t \/ (K.sqrt(vhat_t) + self.epsilon)\n                self.updates.append(K.update(vhat, (1 - update_switch) * vhat + update_switch * vhat_t))\n            else:\n                p_t = p - lr_t * m_t \/ (K.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(K.update(m, (1 - update_switch) * m + update_switch * m_t))\n            self.updates.append(K.update(v, (1 - update_switch) * v + update_switch * v_t))\n            self.updates.append(K.update(tg, (1 - update_switch) * sum_grad))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, (1 - update_switch) * p + update_switch * new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon,\n                  'amsgrad': self.amsgrad}\n        base_config = super(AdamAccumulate, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","26d2325a":"base_model = DenseNet201(include_top=False, weights='imagenet', input_shape=(224,224,3),\n                         backend=keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n\nbase_model.trainable = False\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\npreds = Dense(7,activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input,outputs=preds)\n\nmodel.compile(optimizer=AdamAccumulate(lr=0.001, accum_iters=16), \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n\n","8767000a":"datagen = ImageDataGenerator(\n        rotation_range=180,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest')\n\ndatagen.fit(x_train)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\ncheckpoint_saving = ModelCheckpoint('model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\nreduce_lr_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.3, min_lr=0.00001 , patience=10, verbose=1, min_delta=1e-4, mode='min')\n","49bdb98a":"%%time\n\nhistory = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n                              validation_data=(x_val, y_val, compute_sample_weight('balanced', y_val)),\n                              class_weight=compute_class_weight('balanced', np.unique(y_train), y_train),\n                              steps_per_epoch=math.ceil(x_train.shape[0]\/16),\n                              epochs=150,\n                              callbacks=[early_stopping, checkpoint_saving, reduce_lr_rate])","633a8a5a":"model.load_weights('model.hdf5')\ny_pred = np.argmax(model.predict(x_val), axis=1)\nprint('balanced acc on validation set:', balanced_accuracy_score(y_true=y_val, y_pred=y_pred))\ny_pred = np.argmax(model.predict(x_test), axis=1)\nprint('balanced acc on test set:', balanced_accuracy_score(y_true=y_test, y_pred=y_pred))","e27d759e":"def plot_confusion_matrix(matrix, labels,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        matrix = matrix.astype('float') \/ matrix.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    #print(matrix)\n\n    plt.imshow(matrix, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(labels))\n    plt.xticks(tick_marks, labels) #, rotation=45)\n    plt.yticks(tick_marks, labels)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = matrix.max() \/ 2.\n    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n        plt.text(j, i, format(matrix[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n    \nconf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\nplot_confusion_matrix(conf_matrix, labels=label_names, normalize=True)","9968add5":"report = classification_report(y_true=y_test, y_pred=y_pred, target_names=label_names)\nprint(report)","d0a6c8ff":"**EVALUATE ON TEST SET**","716f25b2":"**SET UP CUSTOM ADAM OPTIMIZER**\n\nOur dataset is highly imbalanced.\nThe df class is about 1% of the dataset.\n\nThe memory limit on kaggle kernel only allows batch size of 16.\nIf we only choose 16 images for each step then it is not likely to have the examples from minor classes.\n\nTherefore, I use accumulate batch size. For each step, I calculate the loss for the given batch and store it. Then I update the weights only after a certain amount of batches. In my code, I update weights after every 16 batches. It is equivalent to a virtual batch size of 16x16=256\n\nThe adam accumulate optimizer implementation can be found [here](https:\/\/github.com\/keras-team\/keras\/issues\/3556#issuecomment-440638517)","e1107d6d":"**SPLIT INTO TRAINING, VALIDATION, AND TESTING SET**\n\n60% for training, 20% for validation and 20% for testing","312e94d8":"**SET UP MODEL**\n\nI use DenseNet201 pretrained on ImageNet as my base model and add an average pooling layer follwed by a dense layer for predictions.","4ed4688c":"**DATA AUGMENTATION AND CALLBACKS**","102ba63e":"**TRAIN MODEL**","9cfb5f44":"Load the best model base on validation loss\n\nBalanced accuracy is the macro-average recall of all classes.\n\nThe balanced accuracy on test set is from 75 to 81% (you can check other versions for that)","cdec31c4":"**LOAD LIBRARIES**","aacbd21e":"Plot confusion matrix\n\nThe code I'm using can be found [here](https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)","fe7c843e":"**LOAD DATASET**"}}