{"cell_type":{"5ebaacea":"code","07de3afb":"code","79acbbff":"code","a39165ab":"code","74b3aa0e":"code","4c55264a":"code","a4b35397":"code","eb80c5f3":"code","534ab749":"code","574fd5b2":"code","8a2c5258":"code","59f262f0":"code","67031076":"code","994e21c1":"code","fa958126":"code","8008ae00":"code","d765c830":"code","e73a1b8a":"code","a85f2f0f":"code","2934c702":"code","3bbfc7be":"code","a88c630a":"code","1d4e83ad":"code","2f523e42":"code","2014817f":"code","71230ce7":"code","13b18d51":"code","91366b39":"code","4107e98c":"code","8de50f2a":"code","9fed58f1":"code","4ae9988d":"code","0973b9f8":"code","94bf25c1":"code","f276fb72":"code","030fd7f0":"code","16b8b1ba":"code","b18be92c":"code","8d52061d":"code","cb1fd16a":"code","94978154":"code","517ccca3":"code","43971938":"code","28b24a9f":"code","a6c99b7a":"code","c4693dce":"code","dc011e50":"code","2da01943":"code","7cb18dd3":"code","dc43728c":"code","38226e55":"code","3a41a89c":"code","5c957789":"code","2c663266":"code","f8233215":"code","05213c71":"code","adca2c29":"code","d8a8ee2d":"code","a4046ae3":"code","043b976a":"code","051a570e":"code","7fa67ee2":"code","17737c1f":"code","1cc6cf30":"code","94e4dbe5":"code","2a0b3a3d":"code","5ce09f68":"code","638a2629":"code","d41f5380":"code","bb67e9d0":"code","0db5459d":"code","5971a684":"code","90b5055b":"code","9e9ef1a7":"code","83002d87":"code","9e230df0":"code","8380977c":"code","f1e0a46a":"code","31701412":"code","06a6f1d0":"markdown","56855d33":"markdown","785748e4":"markdown","ae4f8593":"markdown","10647f6e":"markdown","d0bfd6a9":"markdown","2f94e72b":"markdown","37633068":"markdown","cbad5606":"markdown","12247c18":"markdown","6a4770e8":"markdown","7ec30553":"markdown","08db76d0":"markdown","64895ed4":"markdown","4d735b7d":"markdown","faed5505":"markdown","7b07353d":"markdown","d915d5e3":"markdown","4d2e80a7":"markdown","79e5b9b6":"markdown","bd878848":"markdown","2b25e45a":"markdown","82ad5ed5":"markdown","a84227c3":"markdown","945df61f":"markdown","4f07f602":"markdown"},"source":{"5ebaacea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","07de3afb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default='notebook'\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as matplot\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFE\n\n\nimport re\nimport sklearn\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n","79acbbff":"#Merging 2013-14 datsets\ndf1 = pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/labs.csv')\ndf2 = pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/examination.csv')\ndf3 = pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/demographic.csv')\ndf4a = pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/diet.csv')\ndf5 = pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/questionnaire.csv')\n\ndf2.drop(['SEQN'], axis = 1, inplace=True)\ndf3.drop(['SEQN'], axis = 1, inplace=True)\ndf4a.drop(['SEQN'], axis = 1, inplace=True)\ndf5.drop(['SEQN'], axis = 1, inplace=True)\n\ndfa = pd.concat([df1, df2], axis=1, join='inner')\ndfa = pd.concat([dfa, df3], axis=1, join='inner')\ndfa = pd.concat([dfa, df4a], axis=1, join='inner')\ndfa = pd.concat([dfa, df5], axis=1, join='inner')\n","a39165ab":"#reading 2015-16 healthdata\nd56 = pd.read_csv('..\/input\/merged\/merged_2015_2016.csv')\nd56.describe()","74b3aa0e":"#reading 2017-18 healthdata\nd78 = pd.read_csv('..\/input\/merged\/merged_2017_2018.csv')\nd78.describe()\n","4c55264a":"a=d56.columns\n\nb=d78.columns\n","a4b35397":"#merging 2015,2016,2017,2018 data\ndf_m = pd.concat([d56,d78],ignore_index=True,axis=0)\n\ndf_m.describe()\n","eb80c5f3":"#merged 2015,16,17,18\n#Dropiing non common rows across different datasets\n#\ndf_md=df_m.drop(['DR1TWS', 'DMDHRMAR', 'DMDHRBR4', 'DMDHREDU', 'DMDHRAGE', 'DMDHSEDU','DMDHRAGZ', 'DMDHREDZ', 'DMDHRMAZ', 'DMDHSEDZ', 'DR1TWSZ','DR1_330Z', 'DR1_320Z', 'DR1MRESP', 'DR1_300', 'DR1HELP'],axis=1)\n\n","534ab749":"df_mdc=df_md.columns\n#dfa-2013-14dataframe\nprint(dfa[df_mdc])","574fd5b2":"#Merging 2013,14,15,16,17,18 data\ndf_x = pd.concat([dfa[df_mdc],df_md],ignore_index=True,axis=0)\ndf_x.dropna(axis=1, how='all')\ndf_x.dropna(axis=0, how='all')\ndf_x","8a2c5258":"#Renaming required columns\ndf_x = df_x.rename(columns = {'SEQN' : 'ID',\n                          'RIDAGEYR': 'Age',\n                          'RIAGENDR' : 'Gender',\n                          'WTINT2YR' : 'Weight',\n                          'INDFMIN2' : 'Tot_family_income',\n                          'DMDFMSIZ'  :'Tot_no_fam_members',\n                          'DMDYRSUS' : 'Years_in_US', # Nan -> american i guess\n                          'INDFMPIR' : 'Family_income',\n                          'LBXGH' : 'GlycoHemoglobin',\n                          'BMXARMC' : 'ArmCircum',\n                          'BMDAVSAD' : 'SaggitalAbdominal',\n                          'MGDCGSZ' : 'GripStrength',\n                          'DRABF' : 'Breast_fed',\n                           'MCQ053':'Anemia_treatment',\n                            'LBXHGB': 'Hemoglobin',\n                            'MCQ220': 'Cancer',\n                            'BMXBMI': 'BMI',\n                            'DMDEDUC2':'Educationlevel',\n                            'INDHHINC': 'annualincome',\n                            'RIDRETH1':'Ethinicity',\n                            \n                           })\n\ndf_x.describe()","59f262f0":"#Filling continous and categorical missing values\ndf_x['Tot_family_income'] = df_x['Tot_family_income'].interpolate(limit_direction ='both')\ndf_x['Hemoglobin'] = df_x['Hemoglobin'].interpolate(limit_direction ='both')\ndf_x['Age'] = df_x['Age'].interpolate(limit_direction ='both')\ndf_x['Weight'] = df_x['Weight'].interpolate(limit_direction ='both')\ndf_x['Tot_no_fam_members'] = df_x['Tot_no_fam_members'].interpolate(limit_direction ='both')\n    \ndf_x = df_x.fillna(df_x['Gender'].value_counts().index[0])\ndf_x = df_x.fillna(df_x['Anemia_treatment'].value_counts().index[0])\n\n    \n\n    ","67031076":"#Filling rest of missing values\nimport pandas as pd\nimport numpy as np\nfrom sklearn.base import TransformerMixin\nclass DataFrameImputer(TransformerMixin):\n    def __init__(self):\n        \"\"\"Impute missing values.\n        Columns of dtype object are imputed with the most frequent value\n        in column.\n        Columns of other types are imputed with mean of column.\n        \"\"\"\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n            index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\n\n\nX = df_x\nprint('before...')\nprint(X)\ndf_x = DataFrameImputer().fit_transform(X)\nprint('after...')\nprint(df_x)","994e21c1":"df_x.loc[(df_x['Gender']==1) & (df_x['Hemoglobin'] < 13), 'Anemia'] = 1\ndf_x.loc[(df_x['Gender']==1) & (df_x['Hemoglobin'] > 13), 'Anemia'] = 0\n\ndf_x.loc[(df_x['Gender']==2) & (df_x['Hemoglobin'] < 12), 'Anemia'] = 1\ndf_x.loc[(df_x['Gender']==2) & (df_x['Hemoglobin'] > 12), 'Anemia'] = 0\n\n","fa958126":"df_x['Anemia']=df_x['Anemia'].fillna(0)\n#Distribution of ANEMIA values\ndf_x['Anemia'].value_counts(normalize=True)","8008ae00":"null=100*(df_x.isnull().sum())\/(df_x.shape[0])\n\ndf4ad_null=pd.DataFrame({'percentage':null})\n\ndf4ad_null.describe()","d765c830":"df_m1 = df_x.loc[:,['DR1DRSTZ',\n 'DRD350A',\n 'DRD350C',\n 'DRD350D',\n 'DRD350E',\n 'DRD350G',\n 'DRD350I',\n 'DRD350J',\n 'DRD350K',\n 'DRD360',\n 'DRD370C',\n 'DRD370G',\n 'DRD370H',\n 'DRD370I',\n 'DRD370J',\n 'DRD370K',\n 'DRD370L',\n 'DRD370N',\n 'DRD370O',\n 'DRD370P',\n 'DRD370Q',\n 'DRD370R',\n 'DRD370S',\n 'DRD370T',\n 'DRD370U',\n 'DRD370V',\n 'ID',\n 'Gender',\n 'Age',\n 'Weight',\n 'Tot_family_income',\n 'Tot_no_fam_members',\n 'Hemoglobin',\n 'Anemia_treatment',\n 'Cancer',\n 'BMI',\n 'Educationlevel',\n 'Ethinicity',\n 'Breast_fed',\n 'GlycoHemoglobin',\n 'Anemia'\n    ] ]\ndf_m1.describe()\n#removed drsthepd,drespnd,drabf","e73a1b8a":"nullv=100*(df_m1.isnull().sum())\/(df_m1.shape[0])\n\nvar_allnull=pd.DataFrame({'percentage':nullv})\nprint(var_allnull)","a85f2f0f":"#Dropping ID column\ndf_m1.drop('ID',\n  axis='columns', inplace=True)\n","2934c702":"#Renaming diet variables\n#Renaming required columns\ndf_m1 = df_m1.rename(columns = {\n                            'DRD360':'Fisheaten',\n                            'DR1DRSTZ':'Dietrecalsts',\n                             'DRD370T':'Othefisheaten',\n                             'DRD350G':'Scallopeaten',\n                            'DRD350A':'Clameaten',\n                            'DRD350E':'Musseleaten',\n    'DRD370U':'Othunknfish',\n    'DRD350D':'Lobsteaten',\n    'DRD370C':'Basseaten',\n    'DRD370G':'Haddockeaten',\n    'DRD350C':'Crayfish',\n    'DRD350I':'Shellfish',\n    'DRD350J':'Othshelfis',\n    'DRD350K':'Refshelfdat'\n    \n    \n                           })\n\ndf_m1.head()","3bbfc7be":"df_m1.describe()","a88c630a":"#deopping hemoglobin\nX = df_m1.drop(['Anemia','Hemoglobin'],axis=1)\ny = df_m1[['Anemia']]","1d4e83ad":"#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","2f523e42":"\n# Init the transformer\nrfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=30)\n\n# Fit to the training data\n_ = rfe.fit(X, y)\nnewvar=X.loc[:, rfe.support_]\n\nnewvar.describe()","2014817f":"#Adding anemia to top 30 variables\nnewvar[\"Anemia\"] = df_m1[[\"Anemia\"]]\nnewvar.describe()","71230ce7":"colormap = plt.cm.viridis\nplt.figure(figsize=(20,20))\nsns.heatmap(newvar.astype(float).corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, annot=True)","13b18d51":"#deopping hemoglobin\nX = newvar.drop(['Anemia','Weight','Anemia_treatment'],axis=1)\ny = newvar[['Anemia']]","91366b39":"#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","4107e98c":"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n                            precision_recall_curve, roc_curve, accuracy_score\nfrom sklearn.exceptions import NotFittedError\n\n# instantiate the model (using the default parameters)\nlogreg = LogisticRegression()\n\n# fit the model with data\nlogreg.fit(X_train,y_train)\n\n#\ny_pred=logreg.predict(X_test)","8de50f2a":"# Classification Report-Test dataset\nprint(classification_report(y_test, y_pred\n                                ))","9fed58f1":"#Classification Report-Train dataset\n\nprint(classification_report(y_train, logreg.predict(X_train)))","4ae9988d":"# import the metrics class\nfrom sklearn import metrics\n\n#Confusion matrix\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix\n\n#Plotting heatmap for cm\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\n\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.rcParams['figure.figsize'] = [5,3]\nplt.show()\n","0973b9f8":"#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","94bf25c1":"#scaled_pos_weight-calculation for XGbclassifier for tackling classimbalance\nratio= float(np.sum(y_train == 0)) \/ np.sum(y_train == 1)\nratio\n","f276fb72":"import xgboost as xgb\nfrom optuna import create_study, logging\nfrom optuna.pruners import MedianPruner\nfrom optuna.integration import XGBoostPruningCallback\n","030fd7f0":"import timeit\nimport pickle\nimport sys\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n                            precision_recall_curve, roc_curve, accuracy_score\nfrom sklearn.exceptions import NotFittedError","16b8b1ba":"def confusion_plot(matrix, labels=None):\n    \"\"\" Display binary confusion matrix as a Seaborn heatmap \"\"\"\n    \n    labels = labels if labels else ['Negative (0)', 'Positive (1)']\n    \n    fig, ax = plt.subplots(nrows=1, ncols=1)\n    sns.heatmap(data=matrix, cmap='Blues', annot=True, fmt='d',\n                xticklabels=labels, yticklabels=labels, ax=ax)\n    ax.set_xlabel('PREDICTED')\n    ax.set_ylabel('ACTUAL')\n    ax.set_title('Confusion Matrix')\n    plt.close()\n    \n    return fig","b18be92c":"def roc_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Receiver Operating Characteristic (ROC) curve \n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    fpr, tpr, thresh = roc_curve(y_true, y_probs,\n                                 drop_intermediate=False)\n    auc = round(roc_auc_score(y_true, y_probs), 2)\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    label = ' '.join([label, f'({auc})']) if compare else None\n    sns.lineplot(x=fpr, y=tpr, ax=axis, label=label)\n    \n    if compare:\n        axis.legend(title='Classifier (AUC)', loc='lower right')\n    else:\n        axis.text(0.72, 0.05, f'AUC = { auc }', fontsize=12,\n                  bbox=dict(facecolor='green', alpha=0.4, pad=5))\n            \n        # Plot No-Info classifier\n        axis.fill_between(fpr, fpr, tpr, alpha=0.3, edgecolor='g',\n                          linestyle='--', linewidth=2)\n        \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('ROC Curve')\n    axis.set_xlabel('False Positive Rate [FPR]\\n(1 - Specificity)')\n    axis.set_ylabel('True Positive Rate [TPR]\\n(Sensitivity or Recall)')\n    \n    plt.close()\n    \n    return axis if ax else fig","8d52061d":"def precision_recall_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Precision-Recall curve.\n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    p, r, thresh = precision_recall_curve(y_true, y_probs)\n    p, r, thresh = list(p), list(r), list(thresh)\n    p.pop()\n    r.pop()\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    \n    if compare:\n        sns.lineplot(r, p, ax=axis, label=label)\n        axis.set_xlabel('Recall')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n    else:\n        sns.lineplot(thresh, p, label='Precision', ax=axis)\n        axis.set_xlabel('Threshold')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n\n        axis_twin = axis.twinx()\n        sns.lineplot(thresh, r, color='limegreen', label='Recall', ax=axis_twin)\n        axis_twin.set_ylabel('Recall')\n        axis_twin.set_ylim(0, 1)\n        axis_twin.legend(bbox_to_anchor=(0.24, 0.18))\n    \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('Precision Vs Recall')\n    \n    plt.close()\n    return axis if ax else fig    ","cb1fd16a":"def train_clf(clf, x_train, y_train, sample_weight=None, refit=False):\n    train_time = 0\n    \n    try:\n        if refit:\n            raise NotFittedError\n        y_pred_train = clf.predict(x_train)\n    except NotFittedError:\n        start = timeit.default_timer()\n        \n        if sample_weight is not None:\n            clf.fit(x_train, y_train, sample_weight=sample_weight)\n        else:\n            clf.fit(x_train, y_train)\n        \n        end = timeit.default_timer()\n        train_time = end - start\n        \n        y_pred_train = clf.predict(x_train)\n    \n    train_acc = accuracy_score(y_train, y_pred_train)\n    return clf, y_pred_train, train_acc, train_time","94978154":"def feature_importance_plot(importances, feature_labels, ax=None):\n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n    sns.barplot(x=importances, y=feature_labels, ax=axis)\n    axis.set_title('Feature Importance Measures')\n    \n    plt.close()\n    \n    return axis if ax else fig\n","517ccca3":"def model_memory_size(clf):\n    return sys.getsizeof(pickle.dumps(clf))\ndef report(clf, x_train, y_train, x_test, y_test, display_scores=[],\n           sample_weight=None, refit=False, importance_plot=False,\n           confusion_labels=None, feature_labels=None, verbose=True):\n    \"\"\" Trains the passed classifier if not already trained and reports\n        various metrics of the trained classifier \"\"\"\n    \n    dump = dict()\n    \n    ## Train if not already trained\n    clf, train_predictions, \\\n    train_acc, train_time = train_clf(clf, x_train, y_train,\n                                      sample_weight=sample_weight,\n                                      refit=refit)\n    ## Testing\n    start = timeit.default_timer()\n    test_predictions = clf.predict(x_test)\n    end = timeit.default_timer()\n    test_time = end - start\n    \n    test_acc = accuracy_score(y_test, test_predictions)\n    y_probs = clf.predict_proba(x_test)[:, 1]\n    \n    roc_auc = roc_auc_score(y_test, y_probs)\n    ## Additional scores\n    scores_dict = dict()\n    for func in display_scores:\n        scores_dict[func.__name__] = [func(y_train, train_predictions),\n                                      func(y_test, test_predictions)]\n        \n    ## Model Memory\n    model_mem = round(model_memory_size(clf) \/ 1024, 2)\n    \n    print(clf)\n    print(\"\\n=============================> TRAIN-TEST DETAILS <======================================\")\n    \n    ## Metrics\n    print(f\"Train Size: {x_train.shape[0]} samples\")\n    print(f\" Test Size: {x_test.shape[0]} samples\")\n    print(\"---------------------------------------------\")\n    print(f\"Training Time: {round(train_time, 3)} seconds\")\n    print(f\" Testing Time: {round(test_time, 3)} seconds\")\n    print(\"---------------------------------------------\")\n    print(\"Train Accuracy: \", train_acc)\n    print(\" Test Accuracy: \", test_acc)\n    print(\"---------------------------------------------\")\n    \n    if display_scores:\n        for k, v in scores_dict.items():\n            score_name = ' '.join(map(lambda x: x.title(), k.split('_')))\n            print(f'Train {score_name}: ', v[0])\n            print(f' Test {score_name}: ', v[1])\n            print()\n        print(\"---------------------------------------------\") \n    print(\" Area Under ROC (test): \", roc_auc)\n    print(\"---------------------------------------------\")\n    print(f\"Model Memory Size: {model_mem} kB\")\n    print(\"\\n=============================> CLASSIFICATION REPORT <===================================\")\n    \n    ## Classification Report\n    clf_rep = classification_report(y_test, test_predictions, output_dict=True)\n    \n    print(classification_report(y_test, test_predictions,\n                                target_names=confusion_labels))\n    \n    \n    if verbose:\n        print(\"\\n================================> CONFUSION MATRIX <=====================================\")\n    \n        ## Confusion Matrix HeatMap\n        display(confusion_plot(confusion_matrix(y_test, test_predictions),\n                               labels=confusion_labels))\n        print(\"\\n=======================================> PLOTS <=========================================\")\n\n\n        ## Variable importance plot\n        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n        roc_axes = axes[0, 0]\n        pr_axes = axes[0, 1]\n        importances = None\n\n        if importance_plot:\n            if not feature_labels:\n                raise RuntimeError(\"'feature_labels' argument not passed \"\n                                   \"when 'importance_plot' is True\")\n\n            try:\n                importances = pd.Series(clf.feature_importances_,\n                                        index=feature_labels) \\\n                                .sort_values(ascending=False)\n            except AttributeError:\n                try:\n                    importances = pd.Series(clf.coef_.ravel(),\n                                            index=feature_labels) \\\n                                    .sort_values(ascending=False)\n                except AttributeError:\n                    pass\n\n            if importances is not None:\n                # Modifying grid\n                grid_spec = axes[0, 0].get_gridspec()\n                for ax in axes[:, 0]:\n                    ax.remove()   # remove first column axes\n                large_axs = fig.add_subplot(grid_spec[0:, 0])\n\n                # Plot importance curve\n                feature_importance_plot(importances=importances.values,\n                                        feature_labels=importances.index,\n                                        ax=large_axs)\n                large_axs.axvline(x=0)\n\n                # Axis for ROC and PR curve\n                roc_axes = axes[0, 1]\n                pr_axes = axes[1, 1]\n            else:\n                # remove second row axes\n                for ax in axes[1, :]:\n                    ax.remove()\n        else:\n            # remove second row axes\n            for ax in axes[1, :]:\n                ax.remove()\n\n\n        ## ROC and Precision-Recall curves\n        clf_name = clf.__class__.__name__\n        roc_plot(y_test, y_probs, clf_name, ax=roc_axes)\n        precision_recall_plot(y_test, y_probs, clf_name, ax=pr_axes)\n\n        fig.subplots_adjust(wspace=5)\n        fig.tight_layout()\n        display(fig)\n    \n    ## Dump to report_dict\n    dump = dict(clf=clf, accuracy=[train_acc, test_acc], **scores_dict,\n                train_time=train_time, train_predictions=train_predictions,\n                test_time=test_time, test_predictions=test_predictions,\n                test_probs=y_probs, report=clf_rep, roc_auc=roc_auc,\n                model_memory=model_mem)\n    \n    return clf, dump","43971938":"#Dropping features not useful for analysis\nX = newvar.drop(['Anemia','Weight','Anemia_treatment'],axis=1)\ny = newvar[['Anemia']]","28b24a9f":"\nimport xgboost as xgb\nfrom optuna import create_study, logging\nfrom optuna.pruners import MedianPruner\nfrom optuna.integration import XGBoostPruningCallback\nfrom xgboost import XGBClassifier\nfrom sklearn.utils import class_weight\nfrom sklearn import metrics\n\nfrom sklearn.model_selection import train_test_split\n#deopping hemoglobin\n\ndata_splits = train_test_split(X, y, test_size=0.3, random_state=123,\n                               shuffle=True, stratify=y)\nx_train, x_test, y_train, y_test = data_splits\ndef objective(trial, X, y, group, score, params=dict()):\n    dtrain = xgb.DMatrix(X, label=y)\n    class_weight = (y.shape[0] - np.sum(y)) \/ np.sum(y)\n    \n    ## Initial Learning Parameters\n    params['learning_rate'] = 0.1\n    params['num_boost_round'] = 1000\n\n    if group == '1':\n        params['max_depth'] = trial.suggest_int('max_depth', 2, 15)\n        params['min_child_weight'] = trial.suggest_loguniform('min_child_weight',\n                                                              1e-10, 1e10)\n        params['n_estimators']=trial.suggest_int('n_estimators',500,1000)\n        params['scale_pos_weight']=trial.suggest_float('scale_pos_weight',3.5,5)\n    \n    if group == '2':\n        params['min_samples_split']=trial.suggest_int('min_samples_split',5,10)\n        params['subsample'] = trial.suggest_uniform('subsample', 0, 1)\n        params['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0, 1)\n    \n    if group == '3':\n        params['learning_rate'] = trial.suggest_uniform('learning_rate', 0, 0.1)\n        params['num_boost_round'] = trial.suggest_int('num_boost_round', 100, 1000)\n\n    pruning_callback = XGBoostPruningCallback(trial, \"test-\" + score.__name__)\n    cv_scores = xgb.cv(params, dtrain, nfold=5,\n                       stratified=True,\n                       feval=score,\n                       early_stopping_rounds=10,\n                       callbacks=[pruning_callback],\n                       seed=0)\n\n    return cv_scores['test-' + score.__name__ + '-mean'].values[-1]\ndef execute_optimization(study_name, group, score, trials,\n                         params=dict(), direction='maximize'):\n    logging.set_verbosity(logging.ERROR)\n    \n    ## We use pruner to skip trials that are NOT fruitful\n    pruner = MedianPruner(n_warmup_steps=5)\n    \n    study = create_study(direction=direction,\n                         study_name=study_name,\n                         storage='sqlite:\/\/\/optuna.db',\n                         load_if_exists=True,\n                         pruner=pruner)\n\n    study.optimize(lambda trial: objective(trial, x_train, y_train,\n                                           group, score, params),\n                   n_trials=trials,\n                   n_jobs=-1)\n    \n    \n    print(\"STUDY NAME: \", study_name)\n    print('------------------------------------------------')\n    print(\"EVALUATION METRIC: \", score.__name__)\n    print('------------------------------------------------')\n    print(\"BEST CV SCORE\", study.best_value)\n    print('------------------------------------------------')\n    print(f\"OPTIMAL GROUP - {group} PARAMS: \", study.best_params)\n    print('------------------------------------------------')\n    print(\"BEST TRIAL\", study.best_trial)\n    print('------------------------------------------------')\n    \n    \n    return study.best_params\n","a6c99b7a":"score_func = metrics.f1_score\ndef score_function(y_pred, dtrain):\n    y_pred = (y_pred > 0.5).astype(int)\n    y_true = (dtrain.get_label() > 0.5).astype(int)\n    return score_func.__name__, score_func(y_true, y_pred)\n\nscore_function.__name__ = score_func.__name__","c4693dce":"params1={'learning_rate': 0.02578297296713958,\n 'num_boost_round': 585,\n 'objective': 'binary:logistic',\n 'max_depth': 7,\n 'min_child_weight': 18.93704847111416,\n 'n_estimators': 754,\n         'min_samples_split': 9,\n 'scale_pos_weight': 3.425510435559797,\n 'subsample': 0.505407237617943,\n 'colsample_bytree': 0.5538227649946694}","dc011e50":"primary_eval_metric = metrics.f1_score\nn=list(x_train.columns)","2da01943":"#Tuning model with parameters\nxgb_clf_tuned_1 = XGBClassifier(**params1, \n                                random_state=45, n_jobs=-1)\nxgb_clf_tuned_1.fit(x_train, y_train);\nxgb_clf_tuned_1, xgb_report_tuned_1 = report(xgb_clf_tuned_1, x_train, y_train,\n                                             x_test, y_test,\n                                             display_scores=[primary_eval_metric],\n                                             importance_plot=True,\n                                             feature_labels=n\n                                             )","7cb18dd3":"    ## Classification Report-Test dataset\n    c=xgb_clf_tuned_1.fit(x_train, y_train);\n    test_predictions = c.predict(x_test)\n    print(classification_report(y_test, test_predictions\n                                ))","dc43728c":"\nprint(classification_report(y_train, c.predict(x_train)))","38226e55":"import shap\nimport xgboost\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pylab as pl","3a41a89c":"#deopping hemoglobin\nX = df_m1.drop(['Anemia','Hemoglobin','Anemia_treatment'],axis=1)\ny = df_m1[['Anemia']]","5c957789":"shap_values = shap.TreeExplainer(xgb_clf_tuned_1).shap_values(x_train)","2c663266":"shap.summary_plot(shap_values, x_train)","f8233215":"shap.dependence_plot(\"GlycoHemoglobin\", shap_values, x_train,interaction_index=None)","05213c71":"shap.dependence_plot(\"Gender\", shap_values, x_train,interaction_index=None)","adca2c29":"shap.dependence_plot(\"Age\", shap_values, x_train,interaction_index=None)","d8a8ee2d":"shap.dependence_plot(\"BMI\", shap_values, x_train,interaction_index=None)","a4046ae3":"shap.dependence_plot(\"Fisheaten\", shap_values, x_train,interaction_index=None)","043b976a":"shap.dependence_plot(\"Dietrecalsts\", shap_values, x_train,interaction_index=None)","051a570e":"import scipy\nimport scipy.stats\nfrom scipy import stats","7fa67ee2":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nimport gc\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\nevals = {}\nevals['lgb'] = {}\nlparams = {}\nseeds = [0, 1]\nnfold = [5, 5]\nstratified=[False, False]\nshuffle=[True, True]\nn_estimators = 30000\nearly_stopping_rounds = 300\nverbose_eval = 0\nlearning_rate = 0.01\nreg_alpha = [0.4, 1]\nreg_lambda = [0.7, 1]\nsubsample = [0.45, 1]\ncolsample_bytree = [0.3, 0.225]\nmax_depth = -1\nverbose = -1\nn_jobs = 4\nlparams[0] = dict(boosting_type='gbdt',\n               objective='binary',\n               metric='auc',\n               learning_rate= learning_rate,\n               num_leaves= 200,\n               max_bin=500,\n               min_child_weight= 0.035,\n               subsample= subsample[0],\n               colsample_bytree= colsample_bytree[0],\n               min_data_in_leaf= 150,\n               max_depth= max_depth,\n               bagging_seed= seeds[0],\n               reg_alpha= reg_alpha[0],\n               reg_lambda= reg_lambda[0],\n               verbose= verbose,\n               seed= seeds[0],\n               n_jobs= n_jobs,)\nlparams[1] = dict(boosting_type='gbdt',\n               objective='binary',\n               metric='auc',\n               learning_rate= learning_rate,\n               n_estimators= n_estimators,\n               subsample= subsample[1],\n               colsample_bytree= colsample_bytree[1],\n               max_depth= max_depth,\n               bagging_seed= seeds[1],\n               reg_alpha= reg_alpha[1],\n               reg_lambda= reg_lambda[1],\n               verbose= verbose,\n               seed= seeds[1],\n               n_jobs= n_jobs,)\ntest_preds = np.zeros(len(X_test))    \ndtrain = lgb.Dataset(X_train, y_train)\ndtest = X_test.copy()\ntestlen = X_test.shape[0]\n\ngc.collect()\nfor i, seed in enumerate(seeds):\n    print(f'Training Model with SEED : {seed}')\n    evals['lgb'][i] = lgb.cv(lparams[i],\n                             dtrain,\n                             nfold=nfold[i], \n                             stratified=stratified[i],\n                             shuffle=shuffle[i],\n                             num_boost_round=n_estimators,\n                             early_stopping_rounds=early_stopping_rounds,\n                             verbose_eval=verbose_eval,\n                             return_cvbooster=True,\n                             seed = seed,\n                             show_stdv=True)\n    \n                  \n#     filename = 'lgb_'+ i+'_.sav'\n#     pickle.dump(evals['lgb'][i], open(filename, 'wb'))\n    print(f'SEED {i} Average fold  AUC {np.round(max(evals[\"lgb\"][i][\"auc-mean\"]),5)}')\n    \n    \n    test_preds += stats.rankdata(np.mean(evals['lgb'][i]['cvbooster'].predict(dtest, num_iteration=evals['lgb'][i]['cvbooster'].best_iteration), axis=0)) \/ (testlen * len(seeds))\n    ","17737c1f":"Model= lgb.train(params=lparams[1],train_set=dtrain)\n\n#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred = Model.predict(X_test)\npred_labels = np.rint(pred)\n   \nmean_accuracy=sklearn.metrics.accuracy_score(y_test, pred_labels),\n\nprint( (classification_report(y_test, pred_labels)))","1cc6cf30":"from sklearn.metrics import roc_auc_score\nauc_score1 = roc_auc_score(y_test, pred_labels)\nauc_score1","94e4dbe5":"model1=xgb.XGBClassifier(\n learning_rate =0.1,\n n_estimators=500,\n max_depth=6,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n scale_pos_weight=4.747735,\n seed=27,eval_metric=\"error\")\ntrain_model = model1.fit(X_train, y_train,eval_metric=\"error\",verbose=True)","2a0b3a3d":"# stratified k-fold cross validation evaluation of xgboost model\nfrom numpy import loadtxt\nimport xgboost\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\n# CV model\nkfold = StratifiedKFold(n_splits=5)\nresults = cross_val_score(model1, X, y, cv=kfold)\nprint(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","5ce09f68":"# import XGBoost\nimport xgboost as xgb\n\n\n# define data_dmatrix\ndata_dmatrix = xgb.DMatrix(data=X,label=y)\nfrom xgboost import cv\n\nparams = {'learning_rate':0.1,\n 'n_estimators':500,\n 'max_depth':6,\n 'min_child_weight':1,\n 'gamma':0,\n 'subsample':0.8,\n 'colsample_bytree':0.8,\n 'objective': 'binary:logistic',\n 'scale_pos_weight':4.747735,\n 'seed':27}\n\nxgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=5,num_boost_round=5,\n                     metrics=\"error\", as_pandas=True, seed=123)","638a2629":"print(((1-xgb_cv[\"test-error-mean\"]).iloc[-1]))\n","d41f5380":"xgb_cv.head()","bb67e9d0":"model1=xgb.XGBClassifier(\n learning_rate =0.1,\n n_estimators=500,\n max_depth=6,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n scale_pos_weight=4.747735,\n seed=27,eval_metric=\"error\")\ntrain_model = model1.fit(X_train, y_train,eval_metric=\"error\",verbose=True)","0db5459d":"#prediction and Classification Report-On test dataset\nfrom sklearn.metrics import classification_report\n\npred = train_model.predict(X_test)\n\nprint( (classification_report(y_test, pred)))","5971a684":"#prediction and Classification Report-On train dataset\nprint(classification_report(y_train, train_model.predict(X_train)))","90b5055b":"from sklearn.metrics import accuracy_score\nprint('Accuracy: {0:.2f}'.format(accuracy_score(y_test, pred)))\n#print('Precision: {0:.2f}'.format(precision_score(y_test, pred)))\n#print('Recall: {0:.2f}'.format(recall_score(y_test, pred)))\n#print('AUC ROC: {0:.2f}'.format(roc_auc_score(y_test, pred)))","9e9ef1a7":"xgb.plot_importance(train_model)\nplt.rcParams['figure.figsize'] = [15,9]\nplt.show()","83002d87":"#Random forest classifier-To select parameters,curves are plotted\n# import Random Forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc\n\n\nn_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200,500,1000]\ntrain_results = []\ntest_results = []\nfor estimator in n_estimators:\n   rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\n    \nfrom matplotlib.legend_handler import HandlerLine2D\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nline1, = plt.plot(n_estimators, train_results, \"b\", label=\"Train AUC\")\nline2, = plt.plot(n_estimators, test_results, \"r\", label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"n_estimators\")\nplt.show()","9e230df0":"max_depths = np.linspace(1, 32, 32, endpoint=True)\ntrain_results = []\ntest_results = []\nfor max_depth in max_depths:\n   rf = RandomForestClassifier(max_depth=max_depth, n_jobs=-1)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(max_depths, train_results, \"b\", label=\"Train AUC\")\nline2, = plt.plot(max_depths, test_results, \"r\", label=\"Test AUC\" )\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"Tree depth\")\nplt.show()","8380977c":"min_samples_leafs = np.linspace(0.1,  0.5,50 ,endpoint=True)\ntrain_results = []\ntest_results = []\nfor min_samples_leaf in min_samples_leafs:\n   rf = RandomForestClassifier(min_samples_leaf=min_samples_leaf)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(min_samples_leafs, train_results,\"b\",label=\"Train AUC\")\nline2, = plt.plot(min_samples_leafs, test_results, \"r\", label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"min samples leaf\")\nplt.show()","f1e0a46a":"# Model\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n\n\n# instantiate the classifier \n\nrfc = RandomForestClassifier(class_weight=\"balanced\", n_estimators=500, min_samples_leaf=50, max_depth=7)\n\n\n\n# fit the model\n\nrfc.fit(X_train, y_train)\n\n\n\n# Predict the Test set results\n\ny_pred = rfc.predict(X_test)\n\n\n\n# Check accuracy score \n\nfrom sklearn.metrics import accuracy_score\n\nprint('Model accuracy score with  decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n","31701412":"#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred = rfc.predict(X_test)\n\nprint( (classification_report(y_test, y_pred)))","06a6f1d0":"**Percentage of null values**","56855d33":"# SHAP","785748e4":"# ANEMIA PREDICTION USING NHANES DATA FROM 2013-2018 ","ae4f8593":"### Main code-model tuning using optuna","10647f6e":"**Random forest classifier results**","d0bfd6a9":"**LIGHTGBM RESULTS**","2f94e72b":"**Merged data frame**","37633068":"## Dependence plot -Top features","cbad5606":"**Classification Report-Train dataset**","12247c18":"**Extracting important values from dataframe**","6a4770e8":"# XGBClassifier-Optuna","7ec30553":"# LIGHTGBM","08db76d0":"**Heat map-Top 30 features**","64895ed4":"# RFE using Random Forest regressor-Top 30 features","4d735b7d":"# DATA","faed5505":"# RANDOM FOREST CLASSIFIER","7b07353d":"# LOGISTIC REGRESSION (Baseline model)","d915d5e3":"**Confusion matrix**","4d2e80a7":"**UTILITY FUNCTIONS**","79e5b9b6":"**Anemia calculation**","bd878848":"**FEATURE IMPORTANCE PLOT**","2b25e45a":"**Merging data**","82ad5ed5":"**Cleaning data**","a84227c3":"## Summary Plot","945df61f":"# XGBClassifier","4f07f602":"# XGBClassifier with K-fold cross validation"}}