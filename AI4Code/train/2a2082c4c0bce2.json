{"cell_type":{"27b51818":"code","f17127c8":"code","5ec5da67":"code","21536414":"code","be8c48c3":"code","7e2b3d15":"code","a024c024":"code","58241a25":"code","091800a9":"code","8b0ea640":"code","ebce4432":"code","255d5cba":"code","7210108b":"code","87d15db3":"markdown","82550802":"markdown","e377bf44":"markdown","1989cf1f":"markdown"},"source":{"27b51818":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f17127c8":"df = pd.read_csv('..\/input\/job-classification-dataset\/jobclassinfo2.csv')\ndf.info()","5ec5da67":"df.head(3)","21536414":"df.isnull().sum()","be8c48c3":"object_type_features = df.select_dtypes(\"object\").columns\nobject_type_features","7e2b3d15":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor feat_name in object_type_features: \n    df[feat_name] = le.fit_transform(df[feat_name])\ndf.info()","a024c024":"df.head()","58241a25":"X = df.drop(['PG'], axis = 1)\ny = df['PG']","091800a9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n","8b0ea640":"from sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression()\n\nclf_lr.fit(X_train, y_train)\ny_pred_lr = clf_lr.predict(X_test)\nprint(\"Train Score LR-\", clf_lr.score(X_train, y_train)*100 , \"%\")\nprint(\"Test Score LR-\", clf_lr.score(X_test, y_test)*100, \"%\")","ebce4432":"from sklearn.metrics import recall_score, precision_score, confusion_matrix\n\nprint(\"Recall score\", recall_score(y_test, y_pred_lr, average='macro'))\nprint(\"Precision score\", precision_score(y_test, y_pred_lr, average='macro'))\nprint (\"CONFUSION MATRIX\", confusion_matrix(y_test, y_pred_lr))","255d5cba":"from sklearn.tree import DecisionTreeClassifier\nclf_dt = DecisionTreeClassifier()\n\nclf_dt.fit(X_train, y_train)\ny_pred_dt = clf_dt.predict(X_test)\nprint(\"Train Score LR-\", clf_dt.score(X_train, y_train)*100 , \"%\")\nprint(\"Test Score LR-\", clf_dt.score(X_test, y_test)*100, \"%\")","7210108b":"print(\"Recall score\", recall_score(y_test, y_pred_dt, average='macro'))\nprint(\"Precision score\", precision_score(y_test, y_pred_dt, average='macro'))\nprint (\"CONFUSION MATRIX\", confusion_matrix(y_test, y_pred_dt))","87d15db3":"Out of the two Decision Tree gives me the best result.","82550802":"**Confusion Matrix, Recall Score and Precision Score**","e377bf44":"**2)DECISION TREE**","1989cf1f":"**1)LOGISTIC REGRESSION**"}}