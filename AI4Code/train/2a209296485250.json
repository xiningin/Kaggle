{"cell_type":{"9f10cc1f":"code","256f50a3":"code","3d74d672":"code","b0aea261":"code","70c45452":"code","2fc2cddd":"code","7af67aef":"code","18599d0d":"code","8da5c265":"code","0fefac17":"code","c8d174b8":"code","da07cec5":"code","e80de1b4":"code","b1091f19":"code","6f984b0a":"code","2df7daf6":"code","ea9cf72f":"code","44239f50":"code","7b2a1f43":"code","3013bd0f":"code","2227d4ca":"code","d9d56a4d":"code","3c38c2e7":"code","b8675c5b":"code","1682d1ff":"code","2d438862":"code","e7576ba9":"code","60323a94":"code","7b4aef39":"code","41658cb0":"code","236f756a":"code","d8688ac5":"code","f82f5f18":"code","57971c5a":"code","0bc62ae4":"code","7147c66f":"code","8ab002c3":"code","b3a02d0e":"code","49b528ce":"code","8dde5cc1":"code","8ba11b8f":"code","f9215426":"code","18ff5a87":"code","98a2c38c":"code","48b60d17":"code","ca57b944":"code","8f563ca6":"code","e60b0087":"code","7ff9add1":"code","cfa6e56d":"code","d913952d":"code","dbe8c9b1":"code","442211a2":"code","16852320":"code","3daada4a":"code","b78fbddc":"code","aa8ee2d7":"code","7101c75b":"code","dde42b9f":"code","cf1d1bf7":"code","e84e7123":"code","c1f77a7f":"code","a779ab11":"code","ed282f9d":"code","9d4da3d1":"code","338d097a":"code","350fed7e":"code","e9ecf6a1":"code","a40c53af":"code","01dbd709":"code","8bd0238d":"code","ecf21f52":"code","29969bb4":"code","7c7950ed":"code","c528d65b":"code","aa26c0df":"code","7dcf7742":"markdown","66fd8efc":"markdown","1a6e868d":"markdown","21b1d949":"markdown","f77baaca":"markdown","a7c06653":"markdown","732de5b0":"markdown","5f20baf3":"markdown","b6a17bd5":"markdown","b3855b3f":"markdown","f17614f5":"markdown","f1dc5687":"markdown","651cdc5c":"markdown"},"source":{"9f10cc1f":"!nvidia-smi","256f50a3":"!pip install imagecodecs","3d74d672":"!pip install iterative-stratification","b0aea261":"import os\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import KFold\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport skimage.io\nimport matplotlib.pylab as plt\nimport tensorflow as tf\n\nimport torch\nimport random\n\nRANDOM_STATE = 42\n\nimport ast\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nprint(tf.__version__)","70c45452":"def seed_everything(seed):\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['PYTHONSEED'] = str(seed)\n\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","2fc2cddd":"train = pd.read_csv('..\/input\/lacuna2021\/train-unique.csv')","7af67aef":"\nbands = '..\/input\/lacuna2021\/ImageBands.docx'\n\nimage_size = 80","18599d0d":"print(\"Train meta-data shape:\", train.shape)\ntrain.head(5)","8da5c265":"train.Year.value_counts()","0fefac17":"train.Quality.value_counts()","c8d174b8":"train.drop('Quality', 1).groupby(\"Year\").describe(percentiles=[])","da07cec5":"fig, ax = plt.subplots(len(train.Year.unique()), 3, figsize=(12,14))\nfor i, year in enumerate(train.Year.unique()):\n    ax[i][0].hist(train[train.Year == year].PlotSize_acres)\n    ax[i][0].set_title('PlotSize_acres')\n    ax[i][1].hist(train[train.Year == year].x)\n    ax[i][1].set_title('x')\n\n    ax[i][2].hist(train[train.Year == year].y)\n    ax[i][2].set_title('y')\nplt.show()","e80de1b4":"CONST_X = 10.986328125 \/ 2\nCONST_Y = 10.985731758 \/ 2","b1091f19":"def read_image(path):\n    image = cv2.imread(path)[:, :, ::-1]\n    return image","6f984b0a":"def load_gray_images(ID, load_extra=False):\n    # e.g id_0b242e06 -> 0b242e06\n    if load_extra:\n        extra = 'extra_train-'\n    else:\n        extra = ''\n    name = ID.split('_')[1]\n\n    img_jun17 = read_image(f'..\/input\/lacuna2021\/{extra}planet-jun17\/{extra}planet-jun17\/{name}.png')\n    img_dec17 = read_image(f'..\/input\/lacuna2021\/{extra}planet-dec17\/{extra}planet-dec17\/{name}.png')\n    img_jun18 = read_image(f'..\/input\/lacuna2021\/{extra}planet-jun18\/{extra}planet-jun18\/{name}.png')\n    img_dec18 = read_image(f'..\/input\/lacuna2021\/{extra}planet-dec18\/{extra}planet-dec18\/{name}.png')\n\n    img_jun17 = cv2.resize(img_jun17, (image_size, image_size))\n    img_jun18 = cv2.resize(img_jun18, (image_size, image_size))\n    img_dec17 = cv2.resize(img_dec17, (image_size, image_size))\n    img_dec18 = cv2.resize(img_dec18, (image_size, image_size))\n\n    img_jun17 = cv2.cvtColor(img_jun17, cv2.COLOR_BGR2GRAY)\n    img_jun18 = cv2.cvtColor(img_jun18, cv2.COLOR_BGR2GRAY)\n    img_dec17 = cv2.cvtColor(img_dec17, cv2.COLOR_BGR2GRAY)\n    img_dec18 = cv2.cvtColor(img_dec18, cv2.COLOR_BGR2GRAY)\n\n    return [img_jun17 , img_dec17, img_jun18,  img_dec18]","2df7daf6":"def load_RGB_images(ID, load_extra=False):\n    # e.g id_0b242e06 -> 0b242e06\n    if load_extra:\n        extra = 'extra_train-'\n    else:\n        extra = ''\n    name = ID.split('_')[1]\n\n    img_jun17 = read_image(f'..\/input\/lacuna2021\/{extra}planet-jun17\/{extra}planet-jun17\/{name}.png')\n    img_dec17 = read_image(f'..\/input\/lacuna2021\/{extra}planet-dec17\/{extra}planet-dec17\/{name}.png')\n    img_jun18 = read_image(f'..\/input\/lacuna2021\/{extra}planet-jun18\/{extra}planet-jun18\/{name}.png')\n    img_dec18 = read_image(f'..\/input\/lacuna2021\/{extra}planet-dec18\/{extra}planet-dec18\/{name}.png')\n\n    img_jun17 = cv2.resize(img_jun17, (image_size, image_size))\n    img_jun18 = cv2.resize(img_jun18, (image_size, image_size))\n    img_dec17 = cv2.resize(img_dec17, (image_size, image_size))\n    img_dec18 = cv2.resize(img_dec18, (image_size, image_size))\n\n    return [img_jun17 , img_dec17, img_jun18,  img_dec18]","ea9cf72f":"from skimage.transform import resize\n\ndef load_Spectral_image(ID, load_extra=False, year_2015=False):\n    # e.g id_0b242e06 -> 0b242e06\n    if load_extra:\n        extra = 'extra_train-'\n    else:\n        extra = ''\n    \n    name = ID.split('_')[1]\n    if year_2015:\n        root_dir = 'sentinel_for_points_collected_in_2015\/sentinel_for_points_collected_in_2015'\n    elif not load_extra:\n        if os.path.isfile(f'..\/input\/lacuna2021\/sentinel-2-part1\/sentinel\/{name}.tif'):\n            root_dir = 'sentinel-2-part1\/sentinel'\n        elif os.path.isfile(f'..\/input\/lacuna2021\/sentinel-2-part2\/sentinel\/{name}.tif'):\n            root_dir = 'sentinel-2-part2\/sentinel'\n    else:\n        root_dir = extra + 'sentinel' + '\/extra_train-sentinel'\n            \n    img_sentinel = skimage.io.imread(f'..\/input\/lacuna2021\/{root_dir}\/{name}.tif')\n    \n    img_sentinel = resize(img_sentinel, (40, 40))\n\n    return img_sentinel","44239f50":"def load_test_Spectral_image(ID, load_extra=False, year_2015=False):\n    # e.g id_0b242e06 -> 0b242e06\n    if load_extra:\n        extra = 'extra_train-'\n    else:\n        extra = ''\n    \n    name = ID.split('_')[1]\n    if year_2015:\n        if os.path.isfile(f'..\/input\/lacuna2021\/sentinel_for_points_collected_in_2015\/sentinel_for_points_collected_in_2015\/sentinel_for_points_collected_in_2015\/sentinel_for_points_collected_in_2015\/{name}.tif'):\n            root_dir = 'sentinel_for_points_collected_in_2015\/sentinel_for_points_collected_in_2015'\n        elif os.path.isfile(f'..\/input\/lacuna2021\/sentinel-2-part1\/sentinel\/{name}.tif'):\n            root_dir = 'sentinel-2-part1\/sentinel'\n        elif os.path.isfile(f'..\/input\/lacuna2021\/sentinel-2-part2\/sentinel\/{name}.tif'):\n            root_dir = 'sentinel-2-part2\/sentinel'            \n    else:\n        if not load_extra:\n            if os.path.isfile(f'..\/input\/lacuna2021\/sentinel-2-part1\/sentinel\/{name}.tif'):\n                root_dir = 'sentinel-2-part1\/sentinel'\n            else:\n                root_dir = 'sentinel-2-part2\/sentinel'\n                \n        else:\n            root_dir = extra + 'sentinel' + '\/extra_train-sentinel'\n\n    img_sentinel = skimage.io.imread(f'..\/input\/lacuna2021\/{root_dir}\/{name}.tif')\n    \n    img_sentinel = resize(img_sentinel, (40, 40))\n\n    return img_sentinel\n\n","7b2a1f43":"train.shape","3013bd0f":"aux = pd.read_csv('..\/input\/lacuna2021\/auxilary_data-unique.csv')\naux.head(5)","2227d4ca":"# print(get_features_fromBands(ex, bands=band_names, Band_Names = names))","d9d56a4d":"# train_Features = pd.DataFrame([get_features_fromBands(train['Field_ID'].values[fid_idx],bands=bands,Band_Names=names) for fid_idx in tqdm(range(len(train['Field_ID'].values))) ])\n# train_Features['Field_ID'] = train['Field_ID'].values","3c38c2e7":"print(aux.shape)\naux.isna().sum()","b8675c5b":"aux.Year.value_counts()","1682d1ff":"aux.Quality.value_counts()","2d438862":"aux.drop('Quality', 1).groupby(\"Year\").describe(percentiles=[])","e7576ba9":"def compute_distance(x0, y0, x1, y1):\n\n    a = np.array([x0, y0])\n    b = np.array([x1, y1])\n\n    dist = np.linalg.norm(b - a)\n\n    return dist\n  ","60323a94":"extra = pd.read_csv('..\/input\/lacuna2021\/extra_train.csv')\nextra.head(5)","7b4aef39":"extra.loc[:, 'is_extra'] = True\naux.loc[:,   'is_extra'] = False\ntrain.loc[:, 'is_extra'] = False","41658cb0":"test = pd.read_csv('..\/input\/lacuna2021\/test.csv')\ntest.head(5)","236f756a":"print(test.shape)\ntest.isna().sum()","d8688ac5":"# test = test[test['ID'].isin(sample_submission.ID.values)]","f82f5f18":"print(test.shape)","57971c5a":"test['Quality'] = 3","0bc62ae4":"test","7147c66f":"train_extra = pd.concat([train, aux, extra], axis=0).reset_index(drop=True)","8ab002c3":"train_extra.shape","b3a02d0e":"df = pd.concat([train_extra,test], axis=0).reset_index(drop=True)","49b528ce":"df.shape, train.shape","8dde5cc1":"df.isna().sum()","8ba11b8f":"df","f9215426":"df.Year.value_counts()","18ff5a87":"df.Yield.fillna(value = df.groupby(['PlotSize_acres','Quality'])['Yield'].transform('mean'), inplace=True)\ndf.Yield.fillna(value = df.groupby(['Year'])['Yield'].transform('mean'), inplace=True)","98a2c38c":"df","48b60d17":"df.Quality.value_counts()","ca57b944":"df.drop('Quality', 1).groupby(\"Year\").describe(percentiles=[])","8f563ca6":"df.isna().sum()","e60b0087":"fig, ax = plt.subplots(len(extra.Year.unique()), 3, figsize=(12,12))\nfor i, year in enumerate(extra.Year.unique()):\n    ax[i][0].hist(extra[extra.Year == year].PlotSize_acres)\n    ax[i][0].set_title('PlotSize_acres')\n    ax[i][1].hist(extra[extra.Year == year].x)\n    ax[i][1].set_title('x')\n    ax[i][2].hist(extra[extra.Year == year].y)\n    ax[i][2].set_title('y')\nplt.show()","7ff9add1":"train_df = df[df['ID'].isin(train_extra['ID'].values)]\ntest_df =  df[~df['ID'].isin(train_extra['ID'].values)]","cfa6e56d":"test_df.Year.value_counts()","d913952d":"test_df","dbe8c9b1":"train_df","442211a2":"# train_idx = train_df[train_df['Quality'] != 3].index\n# valid_idx = train_df[train_df['Quality'] == 3].index\n\n# train = train_df.loc[train_idx].reset_index(drop=True)\n# valid = train_df.loc[valid_idx].reset_index(drop=True)\n\n# train.shape, valid.shape","16852320":"predictors =  ['Yield','PlotSize_acres','Year']","3daada4a":"sentinel_feature_cols =['BANDS_FEATURES_Median_FEATURES_B7_B5_0',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_1',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_10',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_11',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_2',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_3',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_4',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_5',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_6',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_7',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_8',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_9',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_0',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_1',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_10',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_11',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_2',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_3',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_4',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_5',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_6',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_7',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_8',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_9',\n 'EVI_Max_10',\n 'EVI_Max_11',\n 'EVI_Max_2',\n 'EVI_Max_3',\n 'EVI_Max_4',\n 'EVI_Max_5',\n 'EVI_Max_6',\n 'EVI_Max_7',\n 'EVI_Max_8',\n 'EVI_Max_9',\n 'EVI_Median_0',\n 'EVI_Median_1',\n 'EVI_Median_10',\n 'EVI_Median_11',\n 'EVI_Median_2',\n 'EVI_Median_3',\n 'EVI_Median_4',\n 'EVI_Median_5',\n 'EVI_Median_6',\n 'EVI_Median_7',\n 'EVI_Median_8',\n 'EVI_Median_9',\n 'NDVI_Max_0',\n 'NDVI_Max_10',\n 'NDVI_Max_3',\n 'NDVI_Max_4',\n 'NDVI_Max_5',\n 'NDVI_Max_6',\n 'NDVI_Max_7',\n 'NDVI_Max_8',\n 'NDVI_Max_9',\n 'NDVI_Median_0',\n 'NDVI_Median_1',\n 'NDVI_Median_10',\n 'NDVI_Median_11',\n 'NDVI_Median_2',\n 'NDVI_Median_3',\n 'NDVI_Median_4',\n 'NDVI_Median_5',\n 'NDVI_Median_6',\n 'NDVI_Median_7',\n 'NDVI_Median_8',\n 'NDVI_Median_9',\n 'NDVI_Min_0',\n 'NDVI_Min_10',\n 'NDVI_Min_3',\n 'NDVI_Min_4',\n 'NDVI_Min_5',\n 'NDVI_Min_6',\n 'NDVI_Min_7',\n 'NDVI_Min_8',\n 'NDVI_Min_9']","b78fbddc":"sentinel_train_df= pd.read_csv('..\/input\/sentinel-features\/train_features.csv')\nsentinel_test_df = pd.read_csv('..\/input\/sentinel-features\/test_features.csv')","aa8ee2d7":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\nall_images = []\ntrain_dists = []\nsentinel_features = []\n\n# loop over the input house paths\nfor i,row in enumerate(train_df['ID']):\n    \n    row_df = train_df.loc[i]\n    \n    sent_row = sentinel_train_df[sentinel_train_df['ID'] == str(row)][sentinel_feature_cols].values[0]\n    sentinel_features.append(sent_row)\n\n    if row_df['is_extra']:\n        images = load_RGB_images(row, load_extra=True)\n\n        if row_df['Year'] == 2017:\n            idx = random.randint(0,1)\n            img = images[:2][idx]\n\n            x0, y0 = img.shape[1]\/\/2, img.shape[0]\/\/2\n            x1 = x0 - np.round(row_df['x'] \/ CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']\/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n            \n        elif row_df['Year']  == 2018:\n\n            idx = random.randint(0,1)\n\n            img = images[2:][idx]\n\n            x0, y0 = img.shape[1]\/\/2, img.shape[0]\/\/2\n            x1 = x0 - np.round(row_df['x'] \/ CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']\/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n            \n\n        else:\n            idx = random.randint(0,3)\n\n            img = images[idx]\n\n            x0, y0 = img.shape[1]\/\/2, img.shape[0]\/\/2\n            x1 = x0 - np.round(row_df['x'] \/ CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']\/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n\n        train_dists.append(d)\n        all_images.append(img)\n\n\n    else:\n        images = load_RGB_images(row, load_extra=False)\n\n        if row_df['Year'] == 2017:\n\n            idx = random.randint(0,1)\n\n            img = images[:2][idx]\n            x0, y0 = img.shape[1]\/\/2, img.shape[0]\/\/2\n            x1 = x0 - np.round(row_df['x'] \/ CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']\/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n\n                    \n        elif row_df['Year'] == 2018:\n            idx = random.randint(0,1)\n\n            img = images[2:][idx]\n            x0, y0 = img.shape[1]\/\/2, img.shape[0]\/\/2\n            x1 = x0 - np.round(row_df['x'] \/ CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']\/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n\n        else:\n            idx = random.randint(0,3)\n\n            img = images[idx]\n\n            x0, y0 = img.shape[1]\/\/2, img.shape[0]\/\/2\n            x1 = x0 - np.round(row_df['x'] \/ CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']\/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n\n\n        train_dists.append(d)\n        all_images.append(img)\n\n        del img\n        _ = gc.collect()","7101c75b":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nX_train = np.array(all_images)\ntrain_sentinel_features = np.array(sentinel_features)\ntrain_ds = np.array(train_dists)\n\nX_train.shape, train_ds.shape,train_sentinel_features.shape","dde42b9f":"# Tile all images into a single image\nimport gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nall_images = []\ntest_sentinel_features = []\n\n# loop over the input house paths\nfor i,row in enumerate(test_df['ID']):\n\n    row_df = test_df.iloc[i]\n\n    sent_row = sentinel_test_df[sentinel_test_df['ID'] == str(row)][sentinel_feature_cols].values[0]\n    test_sentinel_features.append(sent_row)\n    \n    images = load_RGB_images(row, load_extra=False)\n\n    if row_df['Year'] == 2017:\n\n        idx = random.randint(0,1)\n\n        img = images[:2][idx]\n\n\n    elif row_df['Year'] == 2018:\n        idx = random.randint(0,1)\n\n        img = images[2:][idx]\n\n\n    else:\n        idx = random.randint(0,3)\n        img = images[idx]\n            \n    all_images.append(img)\n\n    del img\n    _ = gc.collect()","cf1d1bf7":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nX_test = np.array(all_images)\ntest_sentinel_features = np.array(test_sentinel_features)\n\nX_test.shape, test_sentinel_features.shape","e84e7123":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nX_test_aux =  np.concatenate([test_df[predictors].values,test_sentinel_features], axis=1)\nX_train_aux = np.concatenate([train_df[predictors].values,train_sentinel_features], axis=1)","c1f77a7f":"X_test_aux.shape, X_train_aux.shape","a779ab11":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nytrain = train_df[['x', 'y']].values\n\nytrain = np.array(ytrain.tolist()).reshape((ytrain.shape[0], 2))\n\nytrain.shape","ed282f9d":"import keras\nfrom keras.layers import *\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.initializers import glorot_normal\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.applications import ResNet50,ResNet152\n\nfrom keras.regularizers import l2\nimport tensorflow as tf\nimport random\n","9d4da3d1":"kf = MultilabelStratifiedKFold(n_splits=20, shuffle=True, random_state=42)","338d097a":"def build_model():\n\n    img_inp = keras.Input(shape=(image_size, image_size,3), name=\"img_inputs\")    \n    aux_inp = keras.Input(shape=(79), name=\"auxillary_inputs\")\n    \n    inp_proj = ResNet50(include_top=False, weights='imagenet')(img_inp)\n\n    x_avg = tf.keras.layers.GlobalAveragePooling2D()(inp_proj)\n\n    out1 = Dropout(0.5)(x_avg)\n\n    out2 = Dense(64, activation='relu')(aux_inp)\n\n    concat = keras.layers.Concatenate(name=\"concat_layer\")([out1, out2])\n\n    prediction = keras.layers.Dense(2, name=\"prediction\")(concat)\n    predict_dist =  keras.layers.Dense(1, name=\"predict_dist\")(concat)\n    \n    # Model\n    model = keras.Model(inputs=[img_inp, aux_inp], outputs=[prediction, predict_dist])\n    \n    opt = keras.optimizers.Adam(learning_rate=0.001)\n    \n    model.compile(\n        loss= {\"prediction\":\"huber\",\"predict_dist\": \"huber\"},\n        loss_weights = { \"prediction\": 0.8,\"predict_dist\": 0.2 },\n        optimizer=opt,\n        metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae')]\n\n    )\n    \n    return model","350fed7e":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nmodel_predictions = []\n\nfor i,(tr_index,test_index) in enumerate(kf.split(X_train, ytrain)):\n  \n    X_train_,y_train, Xtrain_aux = X_train[tr_index],ytrain[tr_index], X_train_aux[tr_index]\n\n    X_valid_,y_valid ,Xvalid_aux = X_train[test_index],ytrain[test_index], X_train_aux[test_index]\n\n    y_train_2 , y_valid_2 = train_ds[tr_index], train_ds[test_index]\n\n    model = build_model()\n    \n    checkpoint_filepath = '\/tmp\/efnetb5_checkpoint'\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                                filepath= checkpoint_filepath,\n                                save_weights_only=True,\n                                monitor='val_prediction_mae',\n                                mode='min',\n                                save_best_only=True)\n    \n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50,\n                                 mode='min',restore_best_weights=False)\n    sch_cb = ReduceLROnPlateau(\n        monitor='val_prediction_mae',\n        factor= 0.7,\n        patience= 2,\n        min_lr=1e-5,\n        verbose=1,\n        mode='min')\n        \n    print()\n    print(f'######### FOLD {i+1} \/ {kf.n_splits} ')\n\n    model.fit([X_train_, Xtrain_aux], \n        [y_train, y_train_2],\n        epochs = 300, \n        batch_size = 128,\n        validation_data = ([X_valid_ , Xvalid_aux], [y_valid, y_valid_2]),\n        callbacks = [es, model_checkpoint_callback, sch_cb]\n        )\n    model.load_weights(checkpoint_filepath)\n\n    preds,_ = model.predict([X_test, X_test_aux])\n\n    del model, X_train_, X_valid_, Xvalid_aux, Xtrain_aux\n\n    model_predictions.append(preds)","e9ecf6a1":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\npreds = np.mean(model_predictions, axis=0)\n\ntest_df[['x', 'y']] = preds\n\nsub_df = test_df[['ID','x', 'y']]\n\nsub_df.to_csv('sub_resnet50_final.csv', index=False)","a40c53af":"def build_resnetmodel():\n\n    img_inp = keras.Input(shape=(image_size, image_size,3), name=\"img_inputs\")    \n    aux_inp = keras.Input(shape=(79), name=\"auxillary_inputs\")\n    \n    inp_proj = ResNet152(include_top=False, weights='imagenet')(img_inp)\n\n    x_avg = tf.keras.layers.GlobalAveragePooling2D()(inp_proj)\n\n    out1 = Dropout(0.5)(x_avg)\n\n    out2 = Dense(64, activation='relu')(aux_inp)\n    \n    concat = keras.layers.Concatenate(name=\"concat_layer\")([out1, out2])\n\n    prediction = keras.layers.Dense(2, name=\"prediction\")(concat)\n    predict_dist =  keras.layers.Dense(1, name=\"predict_dist\")(concat)\n    \n    # Model\n    model = keras.Model(inputs=[img_inp, aux_inp], outputs=[prediction, predict_dist])\n    \n    opt = keras.optimizers.Adam(learning_rate=0.001)\n    \n    model.compile(\n        loss= {\"prediction\":\"huber\",\"predict_dist\": \"huber\"},\n        loss_weights = { \"prediction\": 0.8,\"predict_dist\": 0.2 },\n        optimizer=opt,\n        metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae')]\n\n    )\n    \n    return model","01dbd709":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nresnetmodel_predictions = []\n\nfor i,(tr_index,test_index) in enumerate(kf.split(X_train, ytrain)):\n  \n    X_train_,y_train, Xtrain_aux = X_train[tr_index],ytrain[tr_index], X_train_aux[tr_index]\n\n    X_valid_,y_valid ,Xvalid_aux = X_train[test_index],ytrain[test_index], X_train_aux[test_index]\n\n    y_train_2 , y_valid_2 = train_ds[tr_index], train_ds[test_index]\n\n    model = build_resnetmodel()\n    \n    checkpoint_filepath = '\/tmp\/resnet152_checkpoint'\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                                filepath= checkpoint_filepath,\n                                save_weights_only=True,\n                                monitor='val_prediction_mae',\n                                mode='min',\n                                save_best_only=True)\n    \n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50,\n                                  mode='min',restore_best_weights=False)\n    sch_cb = ReduceLROnPlateau(\n        monitor='val_prediction_mae',\n        factor= 0.7,\n        patience= 2,\n        min_lr=1e-5,\n        verbose=1,\n        mode='min')\n    \n    print()\n    print(f'######### FOLD {i+1} \/ {kf.n_splits} ')\n\n    model.fit([X_train_, Xtrain_aux], \n        [y_train, y_train_2],\n        epochs = 300, \n        batch_size = 128,\n        validation_data = ([X_valid_ , Xvalid_aux], [y_valid, y_valid_2]),\n        callbacks = [model_checkpoint_callback, es,sch_cb]\n        )\n    \n    model.load_weights(checkpoint_filepath)\n    \n    preds,_ = model.predict([X_test, X_test_aux])\n\n    del model, X_train_, X_valid_, Xvalid_aux, Xtrain_aux\n\n    resnetmodel_predictions.append(preds)","8bd0238d":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nrespreds = np.mean(resnetmodel_predictions, axis=0)\n\ntest_df[['x', 'y']] = respreds\n\nsub_df = test_df[['ID','x', 'y']]\n\nsub_df.to_csv('sub_resnet152_final_20cv_folds.csv', index=False)","ecf21f52":"def build_model_2():\n\n    inp = keras.Input(shape=(76), name=\"inputs\")\n    \n    x = Dense(64,  activation='relu')(inp)\n    x = Dense(128, activation='relu')(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dense(512, activation='relu')(x)\n    \n    out = Dropout(0.5)(x)\n\n    prediction = keras.layers.Dense(2, name=\"predictions\")(out)\n    \n    # Model\n    model = keras.Model(inputs=[inp], outputs=[prediction])\n    \n    opt = keras.optimizers.Adam(learning_rate=0.001)\n    \n    model.compile(\n        loss= \"mae\",\n        optimizer=opt,\n        metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae')]\n\n    )\n    \n    return model","29969bb4":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n                              \nX_test =   test_sentinel_features\nX_train =  train_sentinel_features\n\nprint(X_test.shape,X_train.shape)","7c7950ed":"gc.collect()","c528d65b":"import gc\n\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nnn_preds = []\n\nfor i,(tr_index,test_index) in enumerate(kf.split(X_train, ytrain)):\n    \n    X_train_,y_train = X_train[tr_index],ytrain[tr_index]\n    X_valid_,y_valid = X_train[test_index],ytrain[test_index]\n\n    model = build_model_2()\n    \n    checkpoint_filepath = '\/tmp\/mlp_ckpt'\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                                filepath= checkpoint_filepath,\n                                save_weights_only=True,\n                                monitor='val_mae',\n                                mode='min',\n                                save_best_only=True)\n    \n    es = EarlyStopping(monitor='val_loss', patience=20,\n                                      mode='min',restore_best_weights=False)\n    sch_cb = ReduceLROnPlateau(\n        monitor='val_prediction_mae',\n        factor= 0.7,\n        patience= 2,\n        min_lr=1e-5,\n        verbose=1,\n        mode='min')\n    print()\n    print(f'######### FOLD {i+1} \/ {kf.n_splits} ')\n\n    model.fit(X_train_, \n            y_train,\n            epochs = 300, \n            batch_size = 64,\n            validation_data = (X_valid_, y_valid),\n            callbacks = [es, model_checkpoint_callback, sch_cb]\n            )\n    model.load_weights(checkpoint_filepath)\n\n    preds = model.predict(X_test)\n\n    del model, X_train_, X_valid_\n\n    nn_preds.append(preds)","aa26c0df":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\nmlp_preds = np.mean(nn_preds, axis=0)\n\ntest_df[['x', 'y']] = mlp_preds\n\nsub_df = test_df[['ID','x', 'y']]\n\nsub_df.to_csv('sub_mlp_final_20cv_folds.csv', index=False)","7dcf7742":"**TEST SET**\n\nNow let's inspect the test data in *test.csv*. We will also visualize a sample but with out the markers.\n\nThe target columns (x, y) are not provided in *test.csv*. Note that the *Quality* column is also not provided.","66fd8efc":"We can sample a random row from the data.","1a6e868d":"There are 2 types of satellite images provided in this competition:\n\n\n*   RGB color images taken at June'17, December'17, June'18, and December'18\n*   Spectral band images from the Sentinel-2 satellite taken monthly over the entire year of the data point acquisition i.e. the *Year* column in the meta-data.\n\nMore details of these images can be found in the data description page. \n\n","21b1d949":"We now read the RGB images for each of the 4 image dates June'17, December'17, June'18, and December'18.","f77baaca":"**DATA EXPLORATION**\n\nWe now try to do understand our data.\n\nLet's start with the meta-data.","a7c06653":"Let's inspect one of these images.\n\nWe can visualize it.","732de5b0":"We can now start loading the data. The data consists of satellite images of agricultural fields along with meta-data files.\n\n**Update:** The data files are now updated to include only unique (Location, PlotSize) pairs and the files are named accordingly *-unique.csv\n\nThe main meta-data files are *train-unique.csv* for the training images and *test-unique.csv* for the test images.\n\nLet's start with the training data.","5f20baf3":"Let's also visualize a sample from the auxilary data.","b6a17bd5":"**AUXLIARY DATA**\n\nIn addition to the main training data, we also have additional data points in *auxilary_data-unique.csv*.\n\nThese points can be used to improve the training of the model.\n\n**Update:** The number of auxilary data points has decreased after removing duplicate data points. The extra training data compensates this shortage.","b3855b3f":"We can see that we have data points from 2015 to 2018. We have the most data points from 2018 and the least from 2016.\n\nThe Quality column describes the confidence of the annotator in the label, with *1* being least confident and *3* being most confident.\n\nLet's statistically summarize the remaining columns grouped by each year.","f17614f5":"Now let's visualize the images.\n\nWe need two constant value to map the (x,y) values into the pixel-space of the image.","f1dc5687":"Note that the image size can slightly vary e.g. 84x84 or 83x83.\n\nIt is important to account for this difference in your preprocessing code when training a model e.g. padding with zeros.","651cdc5c":"**EXTRA DATA**\n\nIn addition to the main training data and auxilary data, we have annotated an extra 1000 unique data points to be used also for training in *extra_train.csv*.\n"}}