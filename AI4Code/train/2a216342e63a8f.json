{"cell_type":{"343141fe":"code","27bc9b50":"code","2cec9f6f":"code","e4cd566d":"code","7767e521":"code","83e3b461":"code","2e91f3bc":"code","1e43af60":"code","2fbf4e7a":"code","3e415640":"code","89104b91":"code","c3e87f24":"code","7734b2db":"code","55f7f94d":"code","e4609942":"code","13f8daeb":"code","16d0b50c":"code","e07e035e":"code","b1568eb7":"code","5e067de1":"code","0ca8ade4":"code","e884daf1":"code","13c851b6":"code","535b4c9b":"code","a45e7940":"code","28f935d6":"code","b033077f":"code","55333594":"code","83f76c27":"code","1b41fb53":"code","6b6cef83":"code","ad752176":"code","ee4a52eb":"code","c110d1f6":"code","b930ab67":"markdown","c7415d91":"markdown","0c948f71":"markdown","684b5acb":"markdown","42709ea9":"markdown","5cfdb840":"markdown"},"source":{"343141fe":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV","27bc9b50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2cec9f6f":"my_file = pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')\nmy_file.head(10)","e4cd566d":"dataset = my_file.sort_values(by=['Date_of_Journey'])\ndataset.head(3)","7767e521":"dataset.isna().any()","83e3b461":"#Checking for null values in Route and Total_Stops column\nnull_in_route = dataset[dataset['Route'].isnull()]\nnull_in_total_stops = dataset[dataset['Total_Stops'].isnull()]\nnull_in_route","2e91f3bc":"null_in_total_stops","1e43af60":"#Delete the above row by using the index value\ndelete_row = dataset[dataset['Total_Stops'].isnull()].index\nprint(delete_row)\ndataset = dataset.drop(delete_row)","2fbf4e7a":"#Checking for null values\nprint(dataset.isnull().values.any())","3e415640":"#Get the total rows and column in the dataset\nprint(\"Train file shape\", dataset.shape)\n#Checking the types of column\nprint(dataset.dtypes)","89104b91":"#Convert Date_of_Journey, Arrival_Time to datetime format\ndataset['Date_of_Journey'] = pd.to_datetime(dataset['Date_of_Journey'])\ndataset['Arrival_Time'] = pd.to_datetime(dataset['Arrival_Time'])","c3e87f24":"#Checking the 'Duration' column to see if there is any row which takes only minutes to travel. This may be an outlier\ndef check_duration_col(row):\n    if 'h' not in row:\n        print(row)\ndataset['Duration'].apply(check_duration_col)","7734b2db":"#Since duration of travel cannot be 5 mins hence removing the row.\ndataset = dataset.drop(dataset[dataset['Duration'] == '5m'].index)","55f7f94d":"#Converting Duration column from hours and minutes to minutes only\nimport re\ndef convert_hours_to_mins(row):\n    row = row.split(' ')\n    match_hr = re.match(r\"([0-9]+)([a-z]+)\", row[0], re.I)\n    if len(row) > 1:\n        match_min = re.match(r\"([0-9]+)([a-z]+)\", row[1], re.I)\n        mins = match_min.groups()\n    else:\n        mins = [0]\n    if match_hr:\n        hr = match_hr.groups()\n    hr_to_min = int(hr[0]) * 60\n    return int(hr_to_min) + int(mins[0])","e4609942":"dataset['Duration'] = dataset['Duration'].apply(convert_hours_to_mins)","13f8daeb":"dataset.head(3)","16d0b50c":"#Remove stops from Total_stops\ndef remove_stops(row):\n    if row == 'non-stop':\n        row = 0\n    else:\n        row = row.split(' ')[0]\n    return row\ndataset['Total_Stops'] = dataset['Total_Stops'].apply(remove_stops)","e07e035e":"dataset['Additional_Info'] = dataset['Additional_Info'].str.lower()\ndataset['Additional_Info'].value_counts()","b1568eb7":"#Remove colon from Departure Time\ndef remove_colon(row):\n    if ':' in str(row):\n        row = row.replace(':', '')\n    return int(row)\n\ndataset['Dep_Time'] = dataset['Dep_Time'].apply(remove_colon)","5e067de1":"#Selecting features from dataframe to prepare data for training\ndataframe_x = dataset[['Airline', 'Source', 'Destination', 'Dep_Time', 'Duration', 'Total_Stops', 'Additional_Info']]\ndataframe_y = dataset[['Price']]","0ca8ade4":"#Converting categorical columns to one-hot encoding \ndataframe_x = pd.get_dummies(dataframe_x, columns=['Source', 'Additional_Info', 'Airline', 'Destination'])","e884daf1":"dataframe_x.head(5)","13c851b6":"#Splitting the data into train, validation and test \ntrain_dataframe_x = dataframe_x[:7000]\ntrain_dataframe_y = dataframe_y[:7000]\nval_dataframe_x = dataframe_x[7000:8500]\nval_dataframe_y = dataframe_y[7000:8500]\ntest_dataframe_x = dataframe_x[8500:]\ntest_dataframe_y = dataframe_y[8500:]\nprint(train_dataframe_x.shape, val_dataframe_x.shape, test_dataframe_x.shape)\nprint(train_dataframe_y.shape, val_dataframe_y.shape, test_dataframe_y.shape)","535b4c9b":"#Standardizing the datasets\nscaler = preprocessing.StandardScaler()\ntrain_dataframe_x = scaler.fit_transform(train_dataframe_x)\nval_dataframe_x = scaler.transform(val_dataframe_x)\ntest_dataframe_x = scaler.transform(test_dataframe_x)","a45e7940":"#Finding the best hyperparameters to train the Random Forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nimport datetime\nparam_grid = {\n 'max_depth': [4, 8, 16, 32],\n 'n_estimators': [1, 2, 5, 10, 50, 100, 200]\n}\nt1 = datetime.datetime.now()\nrf = RandomForestRegressor(n_jobs=-1)\nclf = GridSearchCV(estimator = rf, param_grid = param_grid)\nclf.fit(val_dataframe_x,val_dataframe_y)\nprint(\"time required = \", datetime.datetime.now() - t1)","28f935d6":"clf.best_params_","b033077f":"rf_model = RandomForestRegressor(max_depth = clf.best_params_['max_depth'], n_estimators=clf.best_params_['n_estimators'])\nrf_model.fit(train_dataframe_x, train_dataframe_y)","55333594":"#Getting scores\nprint(\"Train Score\", rf_model.score(train_dataframe_x, train_dataframe_y))\nprint(\"Test Score\", rf_model.score(test_dataframe_x, test_dataframe_y))","83f76c27":"#making prediction on test data\ny_pred = rf_model.predict(test_dataframe_x)","1b41fb53":"#Calculating the metrics\nfrom sklearn import metrics\nprint('MAE:', metrics.mean_absolute_error(test_dataframe_y, y_pred))\nprint('MSE:', metrics.mean_squared_error(test_dataframe_y, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(test_dataframe_y, y_pred)))\nprint(\"R-squared score:\", metrics.r2_score(test_dataframe_y, y_pred))","6b6cef83":"#Using XGBoost Regressor\n#Finding best parameters\nparams = {'max_depth': [1, 2, 3, 4, 5], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [20, 50, 100, 200, 300, 400, 500], 'reg_lambda': [0.001, 0.1, 1.0, 10.0, 100.0]}\nxgb_model = RandomizedSearchCV(XGBRegressor(), params, n_iter=20, cv=10, n_jobs=-1)\nxgb_model.fit(train_dataframe_x, train_dataframe_y)","ad752176":"#Getting scores\nprint(\"Train Score\", xgb_model.score(train_dataframe_x, train_dataframe_y))\nprint(\"Test Score\", xgb_model.score(test_dataframe_x, test_dataframe_y))","ee4a52eb":"#making prediction on test data\ny_pred_xgb = xgb_model.predict(test_dataframe_x)","c110d1f6":"#Calculating the metrics\nprint('MAE:', metrics.mean_absolute_error(test_dataframe_y, y_pred_xgb))\nprint('MSE:', metrics.mean_squared_error(test_dataframe_y, y_pred_xgb))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(test_dataframe_y, y_pred_xgb)))\nprint(\"R-squared score:\", metrics.r2_score(test_dataframe_y, y_pred_xgb))","b930ab67":"## Random Forest Model","c7415d91":"### Sort by Date_of_Journey","0c948f71":"So both the column with missing value was the same row.","684b5acb":"Since there is no much difference between the train and test score. This incdicates the model is not overfitted or underfitted","42709ea9":"## XGBoost Model","5cfdb840":"### Check for Null values"}}