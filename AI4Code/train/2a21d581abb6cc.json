{"cell_type":{"73867bba":"code","52afd53b":"code","3bf3b208":"code","b35b93b9":"code","47fe01e1":"code","cd0681a8":"code","e0732c04":"code","0993a153":"code","3ce3f29a":"code","f7b3cb4c":"code","3825b962":"code","cb9bf126":"code","e09e73e8":"code","38fd7c89":"code","46dd211b":"code","64b079c1":"code","8fccb2b7":"code","2f0a5621":"code","623c2426":"code","607e06e2":"code","a668b97e":"code","a60cac9a":"code","86660a21":"code","accd6118":"code","59ecd8b2":"code","8f9732f6":"code","38493e7d":"code","6b172156":"code","fef18dc1":"markdown","698bb5e4":"markdown","113e0a86":"markdown","8231ba50":"markdown","52e0b233":"markdown","0f79509a":"markdown","b7cf31ff":"markdown","baf8ce6a":"markdown","954273ca":"markdown","f68a4769":"markdown","04d4d9c5":"markdown"},"source":{"73867bba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","52afd53b":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as ttf\nimport PIL.Image as imgs\nfrom PIL import ImageDraw","3bf3b208":"class RacoonsDataSet(Dataset):\n    def __init__(self,p):\n#         super(self).__init__()\n        self.df=pd.read_csv(p)\n        self.transform=ttf.Compose([ttf.Resize([64,64]),ttf.ToTensor(),ttf.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n        \n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,i):\n        image=imgs.open('..\/input\/racoon-detection\/Racoon Images\/images\/{}'.format(self.df['filename'][i])).convert('RGB')\n        X=image.size[0]\n        Y=image.size[1]\n        try:\n            image=self.transform(image)\n        except Exception as e:\n            print(X,\"   \",Y)\n            print(e)\n            return\n        box=torch.from_numpy(np.array([[(64\/X)*self.df[x][i],(64\/Y)*self.df[y][i]] for [x,y] in zip(['xmin','xmax'],['ymin','ymax'])]).ravel()).float()\n        return [image,box]\n    def drawBox(self,img,box):\n        draw=ImageDraw.Draw(img)\n        draw.rectangle([int(x) for x in box], outline=(255, 0, 0),width=1)\n        return img\n    def getImage(self,i):\n        image=imgs.open('..\/input\/racoon-detection\/Racoon Images\/images\/{}'.format(self.df['filename'][i])).convert('RGB')\n        \n        X=image.size[0]\n        Y=image.size[1]\n        image=image.resize((64,64))\n        return image,np.array([[(64\/X)*self.df[x][i],(64\/Y)*self.df[y][i]] for [x,y] in zip(['xmin','xmax'],['ymin','ymax'])])\n","b35b93b9":"p=RacoonsDataSet('..\/input\/racoon-detection\/train_labels_.csv')\np[3]","47fe01e1":"k=p.getImage(23)\nk[1].ravel()\np.drawBox(k[0],k[1].ravel())\n    \n    ","cd0681a8":"class Network(nn.Module):\n    def __init__(self):\n        super(Network,self).__init__()\n        model = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet18', pretrained=True)        \n        self.fc1=nn.Sequential(*self.get_req_features(model))\n        self.fc_classifier=nn.Sequential(nn.Linear(64*16*16,2),nn.ReLU())\n        self.boundingBox=nn.Sequential(nn.Linear(64*16*16,4),nn.ReLU())\n    def forward(self,X):\n        X=self.fc1(X)\n        X=X.reshape(-1,64*16*16)\n        class_preds=self.fc_classifier(X)\n        bound_box=self.boundingBox(X)\n        \n        return class_preds,bound_box\n    def get_req_features(self,model):\n        fc=list(model.children())\n        req_features=[]\n        k=torch.zeros([1,3,64,64]).float()\n        for i in fc:\n            k=i(k)\n            if k.size()[2] <800\/\/80:\n                break\n            req_features.append(i)\n        print(\"++++++++++++++++++++Processing To Extract Features++++++++++++++++++++++++\")\n        print(len(req_features))\n        print(k.size())\n        return req_features","e0732c04":"model2=Network()","0993a153":"model2","3ce3f29a":"p[2][0].shape","f7b3cb4c":"loss_boundingBox=nn.MSELoss()","3825b962":"optimizer = torch.optim.Adam(model2.parameters(), lr=1e-4, weight_decay=1e-5)","cb9bf126":"optimizer.zero_grad()","e09e73e8":"# c,bb=model2(p[2][0].unsqueeze(0))\n# l2=loss_boundingBox(bb,p[2][1])\n# print(l2)\n# l2.backward()\n# optimizer.step()","38fd7c89":"dataloader=DataLoader(p,batch_size=64,shuffle=True)","46dd211b":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel2.to(device)","64b079c1":"model2","8fccb2b7":"!pip install tensorboard\n","2f0a5621":"from torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()","623c2426":"from matplotlib.pyplot import imshow,show","607e06e2":"batch_size=64\ntolerance=0.01","a668b97e":"def getSample(i):    \n    img,_=p.getImage(i)\n    k=model2.forward(p[i][0].unsqueeze(0).to(device))\n    k=k[1].to('cpu').detach().numpy()\n#     k=k*128\/64\n    p.drawBox(img,k.ravel())\n    show(img)\n    return img","a60cac9a":"from tqdm import tqdm\nfor j in tqdm(range(1000)):\n    for D,B in dataloader:\n        optimizer.zero_grad()\n        D,B=D.to(device),B.to(device)\n        \n        c,bb=model2(D)\n        l2=loss_boundingBox(bb,B)+tolerance*torch.sum((bb[2]-bb[0])**2+(bb[3]-bb[1]))\/(2*batch_size)\n        l2.backward()\n        optimizer.step()\n        writer.add_scalar('Loss\/train',l2.item())\n        \n    if j%100==0:\n        print(l2.item())\n        with torch.no_grad():\n            k=model2.forward(p[1][0].unsqueeze(0).to(device))        \n            k=k[1].cpu().detach().numpy()\n            img=p.drawBox(p.getImage(1)[0],k.ravel())\n            imshow(img)\n            show()","86660a21":"p[0][1]","accd6118":"%load_ext tensorboard","59ecd8b2":"%tensorboard --logdir=runs","8f9732f6":"a=ttf.ToPILImage()","38493e7d":"for i in range(10):\n\n    imshow(getSample(i+3))","6b172156":"torch.save(model2,'Model.pt')","fef18dc1":"Lets create network. We are using a pretrained network (resnet) to get basic features of image","698bb5e4":"Loss For bounding box is MSE loss as it is a regression problem","113e0a86":"Create the Custom Dataset\n\nDataset returns the racoon image with bounding box with proper scalling\nOur class also have a function to directly get pil images implemented seprately\n\nLets Test the outputs","8231ba50":"Seems fine, Next target is to make a racoon detection and localization project","52e0b233":"Bounding Box Scalling seems fine","0f79509a":"Let the training began","b7cf31ff":"This Notebook contains very basic implementation to search and put a object in a bounding box (localization) with deep learning using pytorch.","baf8ce6a":"get sample can be used to see the results","954273ca":"Import modules ","f68a4769":"So we will train in batch of 64\nAlso We use a custom loss function where we also try to minimize size of bounding box. it is controlled by tolerance factor\n","04d4d9c5":"Lets Test with first 10 images\n"}}