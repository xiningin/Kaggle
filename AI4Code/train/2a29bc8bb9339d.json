{"cell_type":{"18693a95":"code","ebed09c4":"code","a886949c":"code","39a64a35":"code","36749b69":"code","b10451e9":"code","1ca87194":"code","886c4db1":"code","4d2a1416":"code","36992da9":"code","095d8906":"code","e92e2fbd":"code","24ec51f1":"code","c73430e3":"code","3600fa67":"code","1bdf6a0b":"code","90c3e7bc":"code","e018e045":"code","0fd5c332":"code","d417e354":"code","0a984f2a":"code","1db47d57":"code","d87447fd":"code","ccad4b71":"code","c0467b43":"code","cd964c3d":"code","b9b75210":"code","7a3350eb":"code","c96a8c39":"code","c9be5cc1":"code","acf28671":"code","9c0c6cc5":"code","b75a61cf":"code","9a7e88d6":"code","093e02f6":"code","89495500":"markdown","7cc0e5f7":"markdown","7a6c9d39":"markdown"},"source":{"18693a95":"from fastai.vision.all import *","ebed09c4":"pd.options.display.max_columns = 100","a886949c":"datapath = Path(\"\/kaggle\/input\/rsna-str-pulmonary-embolism-detection\/\")\ntrain_df = pd.read_csv(datapath\/'train.csv')\ntest_df = pd.read_csv(datapath\/'test.csv')\nimagepath = Path(\"\/kaggle\/input\/rsna-str-pe-detection-jpeg-256\/\")","39a64a35":"train_df.head(2)","36749b69":"train_qi = train_df.groupby(['StudyInstanceUID'])['pe_present_on_image'].agg('mean')","b10451e9":"train_df.pe_present_on_image.mean()","1ca87194":"labels_dict = dict(zip(train_df['SOPInstanceUID'], train_df['pe_present_on_image']))","886c4db1":"len(labels_dict)","4d2a1416":"unique_pids = train_df.StudyInstanceUID.unique()","36992da9":"n = len(unique_pids)\nnvalid = int(n*0.05); nvalid, n","095d8906":"unique_pids = np.random.permutation(unique_pids)\ntrain_pids = unique_pids[nvalid:]\nvalid_pids = unique_pids[:nvalid]\nlen(train_pids), len(valid_pids)","e92e2fbd":"os.makedirs(\"pids\", exist_ok=True)\npd.to_pickle(valid_pids, \"pids\/train_pids.pkl\")\npd.to_pickle(valid_pids, \"pids\/valid_pids.pkl\")","24ec51f1":"files = get_image_files(imagepath)","c73430e3":"from fastai.medical.imaging import *","3600fa67":"files_dict = defaultdict(list)\nfor o in files:\n    files_dict[o.parent.parent.name].append(o)","1bdf6a0b":"for k in files_dict:\n    files_dict[k] = sorted(files_dict[k], key=lambda o: int(o.name.split('_')[0]))","90c3e7bc":"plt.hist([len(files_dict[k]) for k in files_dict]);","e018e045":"def sample_patient_slices(pid, num_slice_samples):\n    \"Use a fixed number of samples per patient for training speed up\"\n    files = array(files_dict[pid])\n    n = len(files)\n    if n > num_slice_samples:\n        idxs = [np.clip(int(i), 0, n-1) for i in np.linspace(0, n, num_slice_samples)]\n        return files[idxs]\n    else: return files","0fd5c332":"train_sampled_files = parallel(partial(sample_patient_slices, num_slice_samples=120), train_pids)","d417e354":"train_files = []\nfor o in train_sampled_files: train_files += list(o)","0a984f2a":"valid_files = []\nfor o in valid_pids: valid_files += files_dict[o]","1db47d57":"len(train_files), len(valid_files)","d87447fd":"def aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10., min_zoom=1., max_zoom=1.1,\n                   max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=None,\n                   mode='bilinear', pad_mode=PadMode.Reflection, align_corners=True, batch=False, min_scale=1.):\n    \"Utility func to easily create a list of flip, rotate, zoom, warp, lighting transforms.\"\n    res,tkw = [],dict(size=size if min_scale==1. else None, mode=mode, pad_mode=pad_mode, batch=batch, align_corners=align_corners)\n    max_rotate,max_lighting,max_warp = array([max_rotate,max_lighting,max_warp])*mult\n    if do_flip: res.append(Dihedral(p=0.5, **tkw) if flip_vert else Flip(p=0.5, **tkw))\n    if max_warp:   res.append(Warp(magnitude=max_warp, p=p_affine, **tkw))\n    if max_rotate: res.append(Rotate(max_deg=max_rotate, p=p_affine, **tkw))\n    if min_zoom<1 or max_zoom>1: res.append(Zoom(min_zoom=min_zoom, max_zoom=max_zoom, p=p_affine, **tkw))\n    if max_lighting:\n        res.append(Brightness(max_lighting=max_lighting, p=p_lighting, batch=batch))\n        res.append(Contrast(max_lighting=max_lighting, p=p_lighting, batch=batch))\n    xtra_tfms = [RandomResizedCropGPU(size, min_scale=min_scale, ratio=(1,1))] + xtra_tfms\n    return res + L(xtra_tfms)","ccad4b71":"wgtdict = {0:1, 1:10}","c0467b43":"def get_label(o): return labels_dict[o.stem.split(\"_\")[1]]","cd964c3d":"class FlipUD(RandTransform):\n    def __init__(self, p=0.5): super().__init__(p=p)\n    def encodes(self, x:TensorImage): return x.flip(-2)","b9b75210":"from time import time\ndef get_dls(train_files, valid_files, resize=256, size=224, bs=128):\n    \n    files = train_files + valid_files\n    trn_idxs = list(range(0, len(train_files)))\n    val_idxs = list(range(len(train_files), len(files)))\n    trn_wgts = [wgtdict[get_label(o)] for o in train_files]\n    print(f\"Collected idxs\")\n\n    tfms = [[PILImage.create, ToTensor, RandomResizedCrop(resize, min_scale=0.9)], \n            [get_label, Categorize()]]\n    dsets = Datasets(files, tfms=tfms, splits=(trn_idxs, val_idxs))\n    print(f\"Created dset\")\n\n    aug_tfms = aug_transforms(size=size, max_lighting=False, max_warp=False, flip_vert=False, min_scale=0.85,\n                              xtra_tfms=[RandomErasing(sh=0.2, min_aspect=0.15), FlipUD(p=0.3)])    \n    batch_tfms = [IntToFloatTensor] + aug_tfms\n    dls = dsets.dataloaders(bs=bs, after_batch=batch_tfms, dl_type=WeightedDL, dl_kwargs=[{\"wgts\":trn_wgts}, {}])\n    print(f\"DLs ready\")\n    return dls","7a3350eb":"dls = get_dls(train_files, valid_files, resize=256, bs=128)","c96a8c39":"len(dls.train.dataset), len(dls.valid.dataset)","c9be5cc1":"dls.show_batch(max_n=16)","acf28671":"opt_func = partial(ranger, **dict(sqrmom=0.99, mom=0.95, beta=0., eps=1e-4))","9c0c6cc5":"loss_func = LabelSmoothingCrossEntropyFlat(eps=0.05)\nlearn = cnn_learner(dls, xresnet34, opt_func=opt_func, pretrained=True, loss_func=loss_func,\n                    metrics=[accuracy], cbs=[SaveModelCallback(\"accuracy\", fname=\"xresnet34-256\", every_epoch=True)])\nlearn.to_fp16();","b75a61cf":"# learn.lr_find()","9a7e88d6":"learn.path = Path(\".\")","093e02f6":"base_lr = 2e-3\nlr_mult = 100\nlearn.freeze()\nlearn.fit_flat_cos(1, slice(base_lr))\nbase_lr \/= 2\nlearn.unfreeze()\nlearn.fit_flat_cos(4, slice(base_lr\/lr_mult, base_lr))","89495500":"### Smart Sample\n\nWe don't have to use all the slices as input data per patient. We can simply sample every nth slice for each patient so that we have good enough variability within that patient and use that data for CNN feature training.","7cc0e5f7":"[Next notebook](https:\/\/www.kaggle.com\/keremt\/04-generate-sequences)","7a6c9d39":"### Data"}}