{"cell_type":{"5ba20f9b":"code","02ad3c41":"code","3dcab597":"code","3731dcf9":"code","229f7d96":"code","23682d9c":"code","bc12479a":"code","e06d033c":"code","53c92331":"code","9552c163":"code","5ed2340a":"code","b27f4828":"code","cbe76c89":"code","56a41558":"code","fc0faab6":"code","10d68ec0":"code","02898dfa":"code","026381d2":"code","a3085bd1":"code","8db339f9":"code","b9f5355b":"code","f6bf6f6e":"code","9d483d5c":"code","426bd281":"code","c644ca62":"code","c80bc6ea":"code","5e4eff7e":"code","be7f313b":"code","a57b72f4":"code","49678d95":"code","3eef0c27":"code","ff4a54ca":"code","b447d67b":"code","a480c813":"code","8659ff3a":"code","6391b7c0":"code","548d3f00":"code","98457a74":"code","bc07dfe5":"code","7d20e51d":"code","36b9f326":"code","4f86a8b5":"code","5bd12c42":"code","7a65cb75":"code","ffaa7576":"code","5034ce99":"code","ced4e3c3":"code","488629d6":"code","919b44d8":"code","e50b95b6":"code","d05f5c4e":"code","55f9a33d":"code","11e09314":"code","f09ef116":"code","84b01176":"code","6ca4e209":"code","cedc248e":"code","854e775f":"code","81221f4a":"code","705f0f46":"code","fa265986":"code","4743e354":"code","a9d66f7f":"code","bd347d18":"code","f3b443f3":"code","11f31b3e":"code","92b146a1":"code","088b140c":"code","88eb8965":"markdown","fce43340":"markdown","33ae73c6":"markdown","6a576d6f":"markdown","23248260":"markdown","cf75644b":"markdown","1ffa0bf5":"markdown","7be03aca":"markdown","be75fe07":"markdown","2ac4e7bd":"markdown","4620283a":"markdown","906101d8":"markdown","354594e7":"markdown","beab2575":"markdown","ec22bde0":"markdown","912dca67":"markdown","e42806ce":"markdown","041b2ae2":"markdown","fb44762e":"markdown","9b024010":"markdown","7daa1555":"markdown","9f0199a8":"markdown","863d7187":"markdown","ffc2dec2":"markdown","c37b7eb7":"markdown"},"source":{"5ba20f9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","02ad3c41":"# basic libraries - musts\nimport numpy as np\nimport pandas as pd\n#visuals\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport plotly.express as px # remember to use px.choropleth to plot depression on map\nimport plotly.graph_objects as go\nsns.set()\n\n#set the number of columns and rows given in each table\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',100)\n\n#ignore warnings caused by version errors\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#impute missings with KNN\nfrom sklearn.impute import KNNImputer\n\n#to convert country codes to alpha 3\n!pip install pycountry_convert\nfrom pycountry_convert import country_alpha2_to_country_name, country_name_to_country_alpha3 ","3dcab597":"data = pd.read_csv('..\/input\/depression-anxiety-stress-scales\/DASS_data_21.02.19\/data.csv', delimiter='\\t')","3731dcf9":"data.head()","229f7d96":"data.shape","23682d9c":"#\u00a0Calculating DASS scores\ndf = data.copy() # to preserve the data\ndf.iloc[:,0:126]\nquestions = [i for i in df.iloc[:,0:126] if  'A' in i]\ntime = [i for i in df.iloc[:,0:126] if  'E' in i] # should be equal to testelapse\nposition = [i for i in df.iloc[:,0:126] if  'I' in i]\n\n# save items in another dataframe\nitem_positions = df[position] # if we ever need these\ndass = df[questions]\ntestelapse = df[time]\n\ndf.drop(position, axis=1, inplace=True)","bc12479a":"# DASS score calculation\n## Q2, Q4, Q7, Q15, Q19, Q23, Q25, Q41 questions are including physical symptoms\n# other questions are including mental symptoms\n##  _t = total, _ps = physical symptom, _ms = mental_symptom\n\ndf['depression_t'] = np.sum(dass.iloc[:,0:14],axis=1)\ndf['depression_ps'] = np.sum(dass.loc[:,['Q2A','Q4A','Q7A']],axis=1)\ndf['depression_ms'] = df['depression_t'] - df['depression_ps']\ndf['anxiety_t'] = np.sum(dass.iloc[:,15:28],axis=1)\ndf['anxiety_ps'] = np.sum(dass.loc[:,['Q15A','Q19A','Q23A','Q25A']],axis=1)\ndf['anxiety_ms'] = df['anxiety_t'] - df['anxiety_ps']\ndf['stress_t'] = np.sum(dass.iloc[:,29:42],axis=1)\ndf['stress_ps'] = np.sum(dass.loc[:,['Q41A']],axis=1)\ndf['stress_ms'] = df['stress_t'] - df['stress_ps']\ndf['total'] = np.sum(dass.iloc[:,0:42], axis=1)","e06d033c":"df['testelapse'] = np.sum(df[time],axis=1) \/ 1000\n# total time is not equal to testelapse. Calculated elapsed time seems much more \n# reliable than testElapse. I changed testelapse with calculated time.","53c92331":"# now drop time related features\ndf.drop(df[time],axis=1, inplace=True)\ndf.drop(df[questions],axis=1, inplace= True)","9552c163":"# TIPI\nconversion = {1: 7,\n              2: 6,\n              3: 5,\n              4: 4,\n              5: 3,\n              6: 2,\n              7: 1}\n\n#negative items are 2 ,4, 6, 8, 10\nnegative_items = ['TIPI2', 'TIPI4', 'TIPI6', 'TIPI8', 'TIPI10']","5ed2340a":"for x in negative_items:\n  df[x] = df[x].map(conversion)","b27f4828":"tipi = df[[i for i in df.columns if 'TIPI' in i]]\n\ndf['TIPI_extraversion'] = (df['TIPI1'] + df['TIPI6']) \/ 2\ndf['TIPI_agreeableness'] = (df['TIPI2'] + df['TIPI7']) \/ 2\ndf['TIPI_conscientiousness'] = (df['TIPI3'] + df['TIPI8']) \/ 2\ndf['TIPI_emotional_stability'] = (df['TIPI4'] + df['TIPI9']) \/ 2\ndf['TIPI_openness_exp'] = (df['TIPI5'] + df['TIPI10']) \/ 2","cbe76c89":"# drop tipi\ndf.drop(tipi, axis=1, inplace=True)","56a41558":"VCL_questions = df[[i for i in df.columns if 'VCL' in i]]","fc0faab6":"# renaming VCL's with words\nnames = ['boat',\n         'incoherent', \n         'pallid',\n         'robot',\n         'audible', \n         'reliability_q1', \n         'paucity',\n         'epistemology',\n         'reliability_q2',\n         'decide',\n         'pastiche',\n         'reliability_q3',\n         'abysmal',\n         'lucid',\n         'betray',\n         'funny']\n\nfor x,y in enumerate(names):\n  df.rename(columns = {'VCL'+str(x+1) : y}, inplace = True)\n\n\nfor x in names:\n  df[x] = df[x].astype('object')\n","10d68ec0":"df.info()","02898dfa":"# change categorics to category \/ object type\ncategorics = ['source', 'uniquenetworklocation', 'screensize', 'country',\n'major', 'familysize', 'married', 'voted', 'race',  'orientation', 'religion',\n'religion', 'hand', 'gender','engnat', 'urban', 'education']\n\nfor column in categorics:\n  df[column] = df[column].astype('object')","026381d2":"df['major'] = df['major'].str.lower()\ndf['major'].value_counts().nlargest(n=50)","a3085bd1":"#function for cleaning 'major' column\n#'na' values changed with 'other' value\ndef simplifier(title):\n    if 'business management' in str(title).lower():\n        return 'management'\n    elif 'information technology' in str(title).lower():\n        return 'it'\n    elif 'math' in str(title).lower():\n        return 'mathematics'\n    elif 'computer' in str(title).lower():\n        return 'it'\n    elif 'bio' in str(title).lower():\n        return 'biology'\n    elif 'tesl' in str(title).lower():\n        return 'english'\n    elif 'medic' in str(title).lower():\n        return 'medicine'\n    elif 'account' in str(title).lower():\n        return 'accountacy'\n    elif 'none' in str(title).lower():\n        return np.nan\n    elif 'nurs' in str(title).lower():\n        return 'nursing'\n    elif '-' in str(title).lower():\n        return np.nan\n    elif 'teach' in str(title).lower():\n        return 'teaching'\n    elif 'pharma' in str(title).lower():\n        return 'pharmacy'\n    elif 'no' in str(title).lower():\n        return np.nan\n    elif 'film' in str(title).lower():\n        return 'media'\n    elif 'international' in str(title).lower():\n        return 'international relations'\n    elif 'human' in str(title).lower():\n        return 'human resources'\n    elif 'art' in str(title).lower():\n        return 'arts'\n    elif 'islam' in str(title).lower():\n        return 'islamic studies'\n    elif 'physio' in str(title).lower():\n        return 'physiotherapy'\n    elif 'socio' in str(title).lower() or 'social' in str(title).lower():\n        return 'sociology'\n    elif 'bank' in str(title).lower():\n        return 'banking'\n    elif 'agri' in str(title).lower():\n        return 'agriculture'\n    elif 'commerce' in str(title).lower() or 'real estate' in str(title).lower():\n        return 'marketing'\n    elif 'counsel' in str(title).lower():\n        return 'counselling'\n    elif 'programming' in str(title).lower():\n        return 'it'\n    elif 'civil' in str(title).lower():\n        return 'engineering'\n    elif 'ict' in str(title).lower():\n        return 'it'\n    elif 'communication' in str(title).lower():\n        return 'communication'\n    elif 'administration' in str(title).lower():\n        return 'administration'\n    elif 'psycho' in str(title).lower():\n        return 'psychology'\n    elif 'english' in str(title).lower():\n        return 'english'\n    elif 'law' in str(title).lower():\n        return 'laws'\n    elif 'engineering' in str(title).lower():\n        return 'engineering'\n    elif 'architecture' in str(title).lower():\n        return 'architecture'\n    elif 'design' in str(title).lower():\n        return 'designer'\n    else:\n        return title","8db339f9":"df['major'] = df['major'].apply(simplifier)\n","b9f5355b":"df['education'].value_counts()","f6bf6f6e":"df[df['education']==0]['major'].notnull().sum()","9d483d5c":"# change 0's to 3 \nedu_zero = df[(df['major'].notnull()) & ((df['education'] == 0))]\nedu_zero['education'] = 3\ndf.loc[edu_zero.index, 'education'] = edu_zero['education']\n\n#change 0's major to 'no degree', and 0 to 1\nmajor_zero = df[(df['major'].isnull()) & ((df['education'] == 0))]\nmajor_zero['major'] = 'without a degree'\nmajor_zero['education'] = 1\ndf.loc[major_zero.index, 'major'] = major_zero['major']\ndf.loc[major_zero.index, 'education'] = major_zero['education']","426bd281":"# change 1's to 3 \nedu_one = df[(df['major'].notnull()) & ((df['education'] == 1))]\nedu_one['education'] = 3\ndf.loc[edu_one.index, 'education'] = edu_one['education']\n\n#change 1's major to 'without a degree'\nmajor_one = df[(df['major'].isnull()) & ((df['education'] == 1))]\nmajor_one['major'] = 'without a degree'\ndf.loc[major_one.index, 'major'] = major_one['major']","c644ca62":"# change 2's to 3 \nedu_two = df[(df['major'].notnull()) & ((df['education'] == 2))]\nedu_two['education'] = 3\ndf.loc[edu_two.index, 'education'] = edu_two['education']\n\n#change 2's major to 'no degree'\nmajor_two = df[(df['major'].isnull()) & ((df['education'] == 2))]\nmajor_two['major'] = 'without a degree'\ndf.loc[major_two.index, 'major'] = major_two['major']","c80bc6ea":"df['education'].value_counts()","5e4eff7e":"df['education'] = df['education'].astype('object')","be7f313b":"df['major'].isna().sum()","a57b72f4":"df['major'] = df.groupby('education')['major'].apply(lambda x: x.fillna(x.mode()[0]))","49678d95":"df['major'].value_counts()","3eef0c27":"## changing major names to 'other' if less than 60\ns = df['major'].value_counts()\ndf['major'] = np.where(df['major'].isin(s.index[s < 60]), 'Other', df['major'])","ff4a54ca":"##there were 'no' values which i cant change with simplifier function\ndf['major'] = df['major'].apply(lambda x: x.replace('no','without a degree'))\ndf['major'] = df['major'].apply(lambda x: x.replace('without a degree','no degree'))","b447d67b":"#Some inputs are based on birth year so we are changing those inputs to age\n#There is also couple of unrealistic birth years\ndf['age'] = df['age'].apply(lambda x: 2019-x if x > 1798 else x)","a480c813":"df.drop(df[df['age'] > 100].index, inplace = True)","8659ff3a":"df['gender'].replace({0:3},inplace=True)","6391b7c0":"df['orientation'].replace({0:5}, inplace=True)","548d3f00":"df['religion'].replace({0:2}, inplace=True)","98457a74":"#Changing zeros to 3 as no \ndf['married'].replace({0:3}, inplace=True)","bc07dfe5":"df['hand'].replace({0:3}, inplace = True)","7d20e51d":"#Changing zeros to four as a other\ndf['urban'].replace({0:4}, inplace=True)","36b9f326":"df.drop(df[df['familysize'] > 14].index, inplace=True)","4f86a8b5":"#They might misunderstood question\ndf['familysize'].replace({0:1}, inplace=True)","5bd12c42":"df['voted'].replace({0:2}, inplace=True)","7a65cb75":"# Impute missings in TIPI\nimputer = KNNImputer()","ffaa7576":"##KNNimputer for missing values\ndf.loc[:,['TIPI_agreeableness','TIPI_extraversion',\n          'TIPI_conscientiousness','TIPI_openness_exp','TIPI_emotional_stability']] = imputer.fit_transform(df.loc[:,['TIPI_agreeableness','TIPI_extraversion',\n          'TIPI_conscientiousness','TIPI_openness_exp','TIPI_emotional_stability']]) \n","5034ce99":"##filling null values in country column with mode\ndf['country'] = df['country'].fillna(df['country'].mode()[0])\ndf['country'] = df['country'].apply(lambda x: x.replace('NONE','MY'))\n## Changing 'XK' code to 'RS' code because 'XK' code not in 'country_alpha2_to_country_name'\ndf['country'] = df['country'].apply(lambda x: x.replace('XK','RS'))","ced4e3c3":"##Converting ISO 2 code to ISO 3 code\ndf['country_alpha_3'] = df['country'].apply(lambda x: country_name_to_country_alpha3(country_alpha2_to_country_name(x)))\ndf.drop(['country'], axis = 1, inplace=True)","488629d6":"df['country_alpha_3'].value_counts().nlargest(n=20)","919b44d8":"VCL_questions.columns\nVCL_positives = ['VCL1', 'VCL2', 'VCL3', 'VCL4', 'VCL5','VCL7', 'VCL8', 'VCL10', 'VCL11', \n                 'VCL13', 'VCL14', 'VCL15', 'VCL16']\nVCL_negatives = ['VCL6', 'VCL9', 'VCL12']","e50b95b6":"df['total_vocabulary'] = np.sum(VCL_questions[VCL_positives], axis=1) - np.sum(VCL_questions[VCL_negatives],axis=1)\n                                 ","d05f5c4e":"plt.figure(figsize=(20,12))\ndf['major'].value_counts().sort_values(ascending= True).plot(kind='barh', \n                                                             width = 0.9,\n                                                             color=list('bgc'))\n\nfor i, v in enumerate(df['major'].value_counts().sort_values(ascending= True)):\n    plt.text(v + 10, i - 0.45, str(v), color='blue', fontweight='bold')\n\n_ = plt.xlabel(\"Number of Examinees\")\n_ = plt.ylabel(\"Major Names\")\n_ = plt.title('Total Number of Examinees by Each Major')","55f9a33d":"plt.figure(figsize=(20,12))\ndf['country_alpha_3'].value_counts()[:25].sort_values(ascending= True).plot(kind='barh', \n                                                             width = 0.9,\n                                                             color=list('bgc'))\n\nfor i, v in enumerate(df['country_alpha_3'].value_counts()[:25].sort_values(ascending= True)):\n    plt.text(v + 10, i - 0.15, str(v), color='blue', fontweight='bold')\n\n_ = plt.xlabel(\"Number of Examinees\")\n_ = plt.ylabel(\"Countries\")\n_ = plt.title('Total Number of Examinees by Each Country')","11e09314":"# TO PLOT STACKING BARH for DASS ITEMS\n\n# first create a DF with value_counts of each item\ncounts = []\nfor col in dass.columns:\n  counts.append([dass[col].value_counts()[1], \n                dass[col].value_counts()[2],\n                dass[col].value_counts()[3],\n                dass[col].value_counts()[4]])\n  \n#convert list to DF\ncount = pd.DataFrame(counts, columns =['Did not apply to me at all',\n                                       'Applied to me some degree',\n                                       'Applied to me considerable degree',\n                                       'Applied to me very much'])\n\ncount['item'] = dass.columns\n# extract numbers in Items column\ncount['item'] = count.item.str.extract(('(\\d+)'))\n#save item as INT\ncount['item'] = count['item'].astype('int32') \n\n\n\n# Now plot\n#create a plot object\n_ = plt.style.use('ggplot')\n\n_ = count.sort_values('item', ascending=False).plot(x='item', \n           kind='barh',\n           stacked=True,\n           width = 0.85, \n           legend = True,\n           colormap='Spectral',\n           figsize= (12,10)\n           )\nplt.xlabel(\"Count\")\nplt.ylabel(\"Questions\")\n\nplt.legend( bbox_to_anchor = (1.1, -0.1), ncol=len(count.columns))\n\n# add count of each response\nfor p in _.patches:\n    left, bottom, width, height = p.get_bbox().bounds\n    if width > 0:\n         _.annotate(f'{width:0.0f}', xy=(left+width\/2, bottom+height\/2), ha='center', va='center',)","f09ef116":"selected_questions = ['Q2E','Q4E','Q7E','Q15E','Q19E','Q23E','Q25E','Q41E']\nps_questions = dict(testelapse[selected_questions])\nall_questions = dict(testelapse)\n\ncolors = []\nfor i in all_questions.keys():\n    if i in ps_questions.keys():\n      colors.append('g')\n    else:\n      colors.append('b')\n    \n","84b01176":"plt.figure(figsize=(20,12))\ntestelapse[[x for x in testelapse.columns if 'E' in x]].mean().plot(kind='barh', \n                                                                    width = 0.9,\n                                                                    color=colors,\n                                                                  )\n_ = plt.xlabel(\"Spent Time\")\n_ = plt.ylabel(\"Questions\")\n_ = plt.title(\"Distribution of Spent Time per Question\")\n","6ca4e209":"# scores amongst gender, race, religion and orientation\nfig, (ax1,ax2) = plt.subplots(1,2, figsize=(25,10))\n\n#ax1 : gender and total score means\n_ = sns.barplot( y = df['total'], x = df['gender'], ax= ax1)\n\nax1.set_title('DASS Mean Scores by Gender')\n\nfor i, v in enumerate(df['gender'].value_counts()):\n  ax1.text(s = f\"n : {v:}\", x = i - 0.1, y = 80 , fontsize= 12)\nax1.set_xticklabels(['male','female','other'])   \n\n\n_ = sns.barplot( y = df['total'], x = df['race'], ax= ax2)\n\nfor i, v in enumerate(df['race'].value_counts()):\n  ax2.text(s = f\"n : \\n{v:}\", x = i - 0.25, y = 80, fontsize=12)\n\nax2.set_title('DASS Mean Scores by Race')\n\n#labels for race\nlabels_race = ['Asian', \n               'Arab',\n               'Black', \n               'Indigenous', \n               'Native American', \n               'White', \n               'Other']\n_ = ax2.set_xticklabels(labels_race)\n\n_ = plt.figtext(0.5, 0.01,'n defines the total number of participants in each category',\n           ha='center', fontsize=12)\n","cedc248e":"fig, ax = plt.subplots(1,1, figsize=(12,6))\n_ = sns.barplot( y = df['total'], x = df['religion'])\n\nreligion_labels = ['Agnostic', \n                   'Atheist', \n                   'Buddhist',\n                   'Christian (Catholic)',\n                   'Christian (Mormon)',\n                   'Christian (Protestant)',\n                   'Christian (Other)',\n                   'Hindu', \n                   'Jewish', \n                   'Muslim', \n                   'Sikh',\n                   'Other',\n                   ]\nplt.title('Total DASS Scores by Religion')\n_ = ax.set_xticklabels(religion_labels, rotation= 60)\n\n\nfor i, v in enumerate(df['religion'].value_counts()):\n  ax.text(s = f\"n : \\n{v:}\", x = i - 0.30, y = 80, fontsize=12)","854e775f":"fig, ax = plt.subplots(figsize=(12,6))\n_ = sns.barplot( y = df['total'], x = df['orientation'])\n\norientation_labels = ['Heterosexual',\n                      'Bisexual',\n                      'Homosexual',\n                      'Asexual',\n                      'Other'\n                   ]\nplt.title('Total DASS Scores by Orientation')\n_ = ax.set_xticklabels(orientation_labels)\n\n\nfor i, v in enumerate(df['orientation'].value_counts()):\n  ax.text(s = f\"n : {v:}\", x = i - 0.30, y = 80, fontsize=12)","81221f4a":"bins = [13, 18, 30, 40, 50, 60, 70, 120]\nlabels = ['13-17','18-29', '30-39', '40-49', '50-59', '60-69', '70+']\ndf['age_range'] = pd.cut(df.age, bins, labels = labels,include_lowest = True)\n\ndf[[x for x in df.columns if '_t' in x] + ['age_range']].groupby('age_range').mean().plot(kind=\"bar\",\n                                                                              rot=45,\n                                                                              figsize=(20,10),\n                                                                              width=0.9,\n                                                                              color=list('bgc'))\n_ = plt.xlabel(\"Range of Age\")\n_ = plt.ylabel(\"Score\")\n_ = plt.title(\"Total Anxiety, Depression, Stress Scores by Age\")","705f0f46":"df[[x for x in df.columns if '_ps' in x] + ['age_range']].groupby('age_range').mean().plot(kind=\"bar\",\n                                                                              rot=45,\n                                                                              figsize=(20,10),\n                                                                              width=0.9,\n                                                                              color=list('bgc'))\n_ = plt.xlabel(\"Range of Age\")\n_ = plt.ylabel(\"Score\")\n_ = plt.title(\"Distribution of Physical Symptoms by Age\")","fa265986":"df[[x for x in df.columns if '_ms' in x] + ['age_range']].groupby('age_range').mean().plot(kind=\"bar\",\n                                                                              rot=45,\n                                                                              figsize=(20,10),\n                                                                              width=0.9,\n                                                                              color=list('bgc'))\n_ = plt.xlabel(\"Range of Age\")\n_ = plt.ylabel(\"Score\")\n_ = plt.title(\"Distribution of Mental Symptoms by Age\")","4743e354":"tipi_values = df[[i for i in df.columns if 'TIPI' in i]]\n\nfig, ax = plt.subplots(2,3, figsize=(12,8))\n_ = plt.style.use('ggplot')\n\n\n_ = ax[0,0].text(s='TIPI \\nSubscale \\nScores',\n             x= 0.5, y= 0.5,  \n             fontsize= 32,\n             ha='center', va='center', wrap=True,color = 'darkblue')\n#plots\n\n_ = sns.boxplot( y = tipi_values['TIPI_extraversion'], color = 'red',\n               ax = ax[0,1])\n\n_ = sns.boxplot( y = tipi_values['TIPI_agreeableness'], color = 'blue',\n               ax = ax[0,2])\n\n_ = sns.boxplot( y = tipi_values['TIPI_conscientiousness'], color = 'cyan',\n               ax = ax[1,0])\n\n_ = sns.boxplot( y = tipi_values['TIPI_emotional_stability'], color = 'green',\n               ax = ax[1,1])\n\n_ = sns.boxplot( y = tipi_values['TIPI_openness_exp'], color = 'yellow',\n               ax = ax[1,2])\n\n#titles\n_ = ax[0,1].set_title('Extraversion')\n_ = ax[0,2].set_title('Agreeableness')\n_ = ax[1,0].set_title('Conscientiousness')\n_ = ax[1,1].set_title('Emotional Stability')\n_ = ax[1,2].set_title('Openness Exp')\n","a9d66f7f":"tipi_and_age = df[[x for x in df.columns if 'TIPI' in x] + ['age']]\nbins = [13, 18, 30, 40, 50, 60, 70, 120]\nlabels = ['13-17','18-29', '30-39', '40-49', '50-59', '60-69', '70+']\ntipi_and_age['age_range'] = pd.cut(tipi_and_age.age, bins, labels = labels,include_lowest = True)","bd347d18":"fig, ax = plt.subplots(3,2, figsize=(18,16))\n\n_ = ax[0,0].text(s='TIPI \\nScores by \\nAge',\n             x= 0.5, y= 0.5,  \n             fontsize= 32,\n             ha='center', va='center', wrap=True,color = 'darkblue')\n\n_ = sns.barplot(x = 'age_range', y = 'TIPI_extraversion', data = tipi_and_age, ax= ax[0,1])\n_ = sns.barplot(x = 'age_range', y = 'TIPI_agreeableness', data = tipi_and_age, ax= ax[1,0])\n_ = sns.barplot(x = 'age_range', y = 'TIPI_conscientiousness', data = tipi_and_age, ax= ax[1,1])\n_ = sns.barplot(x = 'age_range', y = 'TIPI_emotional_stability', data = tipi_and_age, ax= ax[2,0])\n_ = sns.barplot(x = 'age_range', y = 'TIPI_openness_exp', data = tipi_and_age, ax= ax[2,1])","f3b443f3":"def correlation_plot(df, cmap='RdBu_r'):\n    fig, ax = plt.subplots(figsize=(12,12))\n    corr = df.corr()\n\n    matshow = ax.matshow(corr, cmap=cmap)\n    for (x, y), z in np.ndenumerate(corr):\n        ax.text(y, x, '{:0.2f}'.format(z), ha='center', va='center',\n                bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n\n    plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=90)\n    plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)\n    cb = plt.colorbar(matshow, orientation=\"horizontal\")\n    ax.tick_params(labelsize=12)\n    plt.show()","11f31b3e":"personality_values = [x for x in df.columns if 'TIPI' in x]\npersonalities = df[personality_values]","92b146a1":"dass_headers = ['depression_t','anxiety_t','stress_t']\ndass_values = df[dass_headers]","088b140c":"character = pd.concat([dass_values, personalities], axis=1)\ncorrelation_plot(character, cmap='inferno')","88eb8965":"# Conclusion\n\nIn this notebook, we tried to understand the factors laying behind Depression, Anxiety and Stress. There are various options; personality type,  gender, sexual orientation and where you live! \n\nTo see more visuals about this dataset, please see our Tableau Public page:\n\nhttps:\/\/public.tableau.com\/app\/profile\/orkun.tahir.aran\/viz\/DepressionAnxietyandStressLevels\/Dashboard1\n\nIf you liked our approach, please consider giving an upvote.\n\nStay healthy and safe everyone.","fce43340":"### Major","33ae73c6":"##\u00a0Education Column\nThe education column has some errors. It should have 1,2,3 and 4; however it has 0's as well as 0's,1's and 2's have filled Major column. \n\nWe changed as follows; ","6a576d6f":"Emotional stability is negatively correlated with DASS items. Emotionally unstable (or less stable) individuals suffer more from depression, anxiety and stress. ","23248260":"## TIPI","cf75644b":"# Reading and Investigation of the Data","1ffa0bf5":"First, we changed Education to 3 where major is not null. \nAfter, changed major to 'no degree' where Education is equal to 0.\n\n\non the next cell, changed education to 3 where major is is not null and education is equal to 1. Did the same thing for education == 2. \nAlso, changed major to 'no degree' where education is equal to 1 and 2","7be03aca":"Minorities and disadventagenous groups have higher DASS scores. However, group participant distributions in this study are way too much unbalanced. Therefore, it is really hard to make general assumptions rather than having a general idea what is going on. \n\nMale gender obviously have lower DASS scores.\n\nIt is also hard to make assumptions about race, however we can have a better idea of asian, arab and black participants. Arabs have the highest DASS score among three groups. Apart from groups; all race groups have DASS scores higher than 100.","be75fe07":"Majority of the participants are agreeable and conscientious. Also, each personality type score is increasing by age except extraversion.","2ac4e7bd":"## Data Cleaning","4620283a":"The highest time spent on Question 9, followed by 35 and 25. \n\n    Q9 I found myself in situations that made me so anxious I was most relieved when they ended.\n\n    Q25 I was aware of the action of my heart in the absence of physical exertion (eg, sense of heart rate increase, heart missing a beat).\n\n    Q35 I was intolerant of anything that kept me from getting on with what I was doing.\n\n","906101d8":"# Predicting Depression, Anxiety and Stress - EDA\n\n![image](https:\/\/www-assets.perkbox.com\/media\/7058\/i960\/22a5cdad3b473bc9ff2a.jpg)\n\n[image source](https:\/\/www-assets.perkbox.com\/media\/7058\/i960\/22a5cdad3b473bc9ff2a.jpg)\n\nThe data is from: \nhttps:\/\/openpsychometrics.org\/tests\/TMAS\/ \n\nDepression, Anxiety and Stress; three horse-man of pschological disorders of our era. They effect how we live, how we work and other aspects of our daily lives. Many studies proved the negative effects of these three; however we are still not sure about how we got these disorders, what drives us to get the DAS. There are more studies and analysis needed to discuss and make assumptions about that. \n\nOne of the studies conducted to determine the reasons \/ drivers of DAS is the Taylor study, and the data is available at Kagge and openpsychometrics web page.\n\nLet's have a look at the data information:\n\n\n    This data was collected with an on-line version of the Depression Anxiety Stress\n    Scales (DASS), see http:\/\/www2.psy.unsw.edu.au\/dass\/\n\n    The survey was open to anyone and people were motivated to take it to get \n    personalized results. At the end of the test they also were given the option to \n    complete a short research survey. \n    This datatset comes from those who agreed to complete the research survey and answered \n    yes to the question \"Have you given accurate answers and may they be used for research?\" \n    at the end.\n\n    This data was collected 2017 - 2019.\n\n    Each item was presented one at a time in a random order for each new participant \n    along with a 4 point rating scale asking the user to indicate how often that had \n    been true of them in the past week.\n\n    This response is stored in variable A (e.g. Q1A). \n    Also recorded was the time taken in milliseconds to answer that question (E)\n    and that question's position in the survey (I).\n\n    These other durations were also recorded (measured on the server's side):\n\n    introelapse\t\tThe time spent on the introduction\/landing page (in seconds)\n    testelapse\t\tThe time spent on all the DASS questions (should be equivalent to the time elapsed on all the indiviudal questions combined)\n    surveyelapse\tThe time spent answering the rest of the demographic and survey questions\n\n    On the next page was a generic demographics survey with many different questions.\n\n    The Ten Item Personality Inventory was administered \n    (see Gosling, S. D., Rentfrow, P. J., & Swann, W. B., Jr. (2003). \n    A Very Brief Measure of the Big Five Personality Domains. Journal of Research in Personality, 37, 504-528.):\n\n    TIPI1\tExtraverted, enthusiastic.\n    TIPI2\tCritical, quarrelsome.\n    TIPI3\tDependable, self-disciplined.\n    TIPI4\tAnxious, easily upset.\n    TIPI5\tOpen to new experiences, complex.\n    TIPI6\tReserved, quiet.\n    TIPI7\tSympathetic, warm.\n    TIPI8\tDisorganized, careless.\n    TIPI9\tCalm, emotionally stable.\n    TIPI10\tConventional, uncreative.\n\n    The TIPI items were rated \"I see myself as:\" _____ such that\n\n    1 = Disagree strongly\n    2 = Disagree moderately\n    3 = Disagree a little\n    4 = Neither agree nor disagree\n    5 = Agree a little\n    6 = Agree moderately\n    7 = Agree strongly\n\n    TIPI scale scoring (\u2018\u2018R\u2019\u2019 denotes reverse-scored items): Extraversion: 1, 6R; Agreeableness: 2R, 7;\n    Conscientiousness; 3, 8R; Emotional Stability: 4R, 9; Openness to Experiences: 5, 10R\n\n    The following items were presented as a check-list and subjects were instructed \"In the grid below, check all the words whose definitions you are sure you know\":\n\n    VCL1\tboat\n    VCL2\tincoherent\n    VCL3\tpallid\n    VCL4\trobot\n    VCL5\taudible\n    VCL6\tcuivocal\n    VCL7\tpaucity\n    VCL8\tepistemology\n    VCL9\tflorted\n    VCL10\tdecide\n    VCL11\tpastiche\n    VCL12\tverdid\n    VCL13\tabysmal\n    VCL14\tlucid\n    VCL15\tbetray\n    VCL16\tfunny\n\n    A value of 1 is checked, 0 means unchecked. The words at VCL6, VCL9, and VCL12\n    are not real words and can be used as a validity check.\n\n    A bunch more questions were then asked:\n\n\n    education    \"How much education have you completed?\", 1=Less than high school, 2=High school, 3=University degree, 4=Graduate degree\n    urban        \"What type of area did you live when you were a child?\", 1=Rural  (country side), 2=Suburban, 3=Urban (town, city)\n    gender       \"What is your gender?\", 1=Male, 2=Female, 3=Other\n    engnat       \"Is English your native language?\", 1=Yes, 2=No\n    age          \"How many years old are you?\"\n    hand\t\t \"What hand do you use to write with?\", 1=Right, 2=Left, 3=Both\n    religion     \"What is your religion?\", 1=Agnostic, 2=Atheist, 3=Buddhist, 4=Christian (Catholic), 5=Christian (Mormon), 6=Christian (Protestant),  7=Christian (Other), 8=Hindu, 9=Jewish, 10=Muslim, 11=Sikh, 12=Other\n    orientation  \"What is your sexual orientation?\", 1=Heterosexual, 2=Bisexual, 3=Homosexual, 4=Asexual, 5=Other\n    race        \"What is your race?\", 10=Asian, 20=Arab, 30=Black, 40=Indigenous Australian, 50=Native American, 60=White, 70=Other\n    voted       \"Have you voted in a national election in the past year?\", 1=Yes, 2=No\n    married     \"What is your marital status?\", 1=Never married, 2=Currently married, 3=Previously married\n    familysize  \"Including you, how many children did  your mother have?\"\t\t\n    major       \"If you attended a university, what was your major (e.g. \"psychology\",  \"English\", \"civil engineering\")?\"\n\n    The following values were derived from technical information:\n\n    country      ISO country code of where the user connected from\n    screensize   1=device with small screen (phone, etc), 2=device with big screen (laptop, desktop, etc)\n    uniquenetworklocation :\t 1=only one survey from user's specific network in dataset,  \n    2=multiple surveys submitted from the network of this user (2 does not necessarily imply \n    duplicate records for an individual, as it could be different students at a single school \n    or different memebers of the same household and even if 1 there still could be duplicate records \n    from a single individual e.g. if they took it once  on their wifi and once on their phone)\n\n    source       how the user found the test, 1=from the front page of the site hosting\n    the survey, 2=from google, 0=other or unknown\n\n\n\n\nWe have plenty of information about the data; however let's try to wrap up:\n\n1. The main outcome of this study is the DASS scale - Depression , Anxiety and Stress Scale\n2. The 10 item personality inventory; this is a brief version of Big 5 Personality assessments which is commonly used to determine personality types among examinees. \n3. Vocabulary knowledge assessment assessed with 16 different words. It evaluates wheter the examinee knows the given word or not. \n4. Demographic outcomes : A bunch of questions that gathers information about examinees such as age, gender, sexuality, religion and etc. \n\n\nOur approach for this dataset includes the following:\n\n1. Data Cleaning \n2. EDA\n3. Visualization - in two parts\n\n    3a. Visuals in the notebook\n    \n    3b. Visuals in tableau public  \n\n\n\n","354594e7":"## Observations about data\n\nThe data has nearly 40k rows and 172 features. However, most of the data is about DASS - item, response time, estimated random number of item-. It would be better to calculate total and sub-domain scores of DASS and other questionnaires. ","beab2575":"### The Ten Item Personality Inventory (TIPI)\n\nlink = https:\/\/gosling.psy.utexas.edu\/scales-weve-developed\/ten-item-personality-measure-tipi\/\n\nThe Ten-Item Personality Inventory (TIPI) is a brief assessment of the Big Five personality dimensions: (1) Extraversion, (2) Agreeableness, (3) Conscientiousness, (4) Emotional Stability, and (5) Openness to Experience. Items are rated on a scale from 1, disagree strongly, to 7, agree strongly.\n\nTIPI scale scoring (\u2018\u2018R\u2019\u2019 denotes reverse-scored items): \n\n    Extraversion: 1, 6R; \n\n    Agreeableness: 2R, 7;\n\n    Conscientiousness; 3, 8R; \n\n    Emotional Stability: 4R, 9; \n\n    Openness to Experiences: 5, 10R\n\n","ec22bde0":"Majority of the participants are from Malesia, and the sample is not equally distributed; therefore we cannot assume this sample size reflect the entire population. The same is present for major.","912dca67":"The Mormon's have the highest DASS scores among all other religions. Same as other categories, religion is also skewed. ","e42806ce":"# Importing Libraries","041b2ae2":"Bisexuals have the highest DASS score, and all others apart from Hetero's have higher scores than hetero's. ","fb44762e":"# Visuals\n\n## Visuals for Descriptives","9b024010":"The following items were answered as the examinee's felt that way most of the time:\n\n- Question 11: I found myself getting upset rather easily.\n- Question 13: I felt sad and depressed.\n- Question 18: I felt that I was rather touchy.\n- Question 34: I felt I was pretty worthless.\n- Question 40: I was worried about situations in which I might panic and make a fool of myself.\n\nOn the other hand, following items were answered as the examinee's felt that way nearly never:\n\n- Question 15: I had a feeling of faintness.\n- Question 23: I had difficulty in swallowing.\n\nIt is obvious that most of the participants had mental \/ emotional symptoms of ADS; and do not have physical symptoms.\n","7daa1555":"###\u00a0DASS \n\n","9f0199a8":"Depression, anxiety and stress levels are getting lower by age. \nWhile anxiety causes physical symptoms, stress causes mental symptoms on all ages. Apart from that, depression causes both symptoms.","863d7187":"### DASS\n\nThe DASS is a 42-item self-administered questionnaire\ndesigned to measure the magnitude of three negative\nemotional states: depression, anxiety, and stress. \nThe DASSDepression focuses on reports of low mood, motivation,\nand self-esteem, DASS-anxiety on physiological arousal,\nperceived panic, and fear, and DASS-stress on tension and\nirritability.\nInstructions to client and scoring: A respondent indicates\non a 4-point scale the extent to which each of 42 statements\napplied over the past week. A printed overlay is used to\nobtain total scores for each subscale. Higher scores on each\nsubscale indicate increasing severity of depression, anxiety, or stress\n\n\nThe DASS has 3 parts;\n\n* 0 - 14 : Depression\n* 15 - 28 : Anxiety\n* 29 - 42 : Stress\n\nAnd these three parts were evaluated in 3 parts also; \n- Physical Symptoms\n- Mental Symptoms\n- Total Score ","ffc2dec2":"## Vocabulary Assesment (VCL)\n\nThere were 16 items in VCL, it was asked examinee's whether they know or don't know given vocabulary. 3 given words are not actual words which are used as reliability items. \n\nWe created a sumation of VCL; each correct word is +1, and reliability items are -1 each. ","c37b7eb7":"### VCL"}}