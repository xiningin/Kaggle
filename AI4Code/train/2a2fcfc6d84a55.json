{"cell_type":{"578ca5e3":"code","eb5e23b9":"code","0b65cbdd":"code","580e44b7":"code","d3a1e13a":"code","ad0c4a81":"code","374c8328":"code","f03b1653":"code","5173a809":"code","c4b638c7":"code","aad394a2":"code","dd326cb0":"code","9b9a2b2e":"code","48d29a45":"code","851daff0":"code","a7268f5f":"code","940a1dd2":"code","f5edc76f":"code","e13c8135":"code","d83c09fd":"code","058a8e97":"code","081e3967":"code","a8326bfc":"code","7db198bb":"code","358e1368":"code","ff6cb631":"code","e271415c":"code","d8364e58":"code","2666ee44":"code","980acf0a":"code","b42e4e1e":"code","013829c4":"code","6a9e8e4a":"markdown","2dc8cfd1":"markdown","31cd58a7":"markdown","fc85e777":"markdown","743b8aff":"markdown","ad63ff03":"markdown"},"source":{"578ca5e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eb5e23b9":"#importing the required librarys to install the data\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","0b65cbdd":"# reading the dataset\ndf1 = pd.read_csv(\"..\/input\/carpriceprediction\/CarPrice_Assignment.csv\")\ndf1.head()","580e44b7":"# checking how each column is corelated with target variable\ncor=df1.corr()['price'].sort_values()\ncor","d3a1e13a":"# lets see the correlation between eachother by using heatmap\n\ndf1=df1.drop(columns=['car_ID','peakrpm','symboling','compressionratio','stroke','carheight'])\n\nfig, ax = plt.subplots(figsize=(10,10))\nmask = np.triu(np.ones_like(df1.corr(),dtype=np.bool))\nsns.heatmap(df1.corr(), annot=True, cmap=\"Reds\", mask=mask, linewidth=0.5)","ad0c4a81":"# Checking data missing values\nmissing = pd.DataFrame(df1.isnull().sum(),columns = ['No.of missing values'])\n\nmissing['% missing_values']= (missing\/len(df1)).round(2)*100\nmissing","374c8328":"df1.shape","f03b1653":"from sklearn.preprocessing import LabelEncoder","5173a809":"# exrtact categorical features\ncat_col=df1.select_dtypes(object).columns.tolist()\nlen(cat_col)","c4b638c7":"# Convert categorized values to numerical values\nle = LabelEncoder()\ndf1[cat_col] =df1[cat_col].astype('str').apply(le.fit_transform)\ndf1","aad394a2":"#Checking and highliting the variables which has high correletion\nDF=df1.corr()\ndef highlight(s):\n    return ['background-color: yellow' if (v>0.9) or (v<-0.9) else 'background-color: white' for v in s]\nDF.style.apply(highlight, axis=0)","dd326cb0":"# importing packages for checking VIF values\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant","9b9a2b2e":"#Checking the High VIF values of columns\ndata = df1.drop(columns=['highwaympg'])\nX = add_constant(data)\nvif = pd.DataFrame()\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range (X.shape[1])]\nvif['features'] = X.columns\nvif","48d29a45":"#Droping the column which has high VIF value\ndf1.drop('highwaympg',inplace=True,axis=1)\ndf1","851daff0":"#Declaring independent variable \ny = df1['price']\n\n#Declaring Target variable \nx = df1.drop(['price'], axis = 1)","a7268f5f":"# importing package \nfrom sklearn.preprocessing import StandardScaler\n\n#fitting the model to standardlize the data\nscaler = StandardScaler()\nscaler.fit(x)","940a1dd2":"#Transforming the data\nscaled_x = scaler.transform(x)","f5edc76f":"#importing the package\nfrom sklearn.model_selection import train_test_split\n\n# splitting the data into train and test\nx_train,x_test, y_train, y_test = train_test_split(scaled_x, y , test_size = 0.2, random_state = 47)","e13c8135":"#importing the model package\nfrom sklearn.linear_model import LinearRegression\n\n#loading and fitting the model\nreg = LinearRegression()\nreg.fit(x_train,y_train)","d83c09fd":"#predicting using x_train\ny_hat = reg.predict(x_train)","058a8e97":"#Plotting y_train vs our predicted value(y_hat)\nfig, ax = plt.subplots()\nax.scatter(y_train, y_hat)","081e3967":"#R2\nreg.score(x_train, y_train)","a8326bfc":"#importing the EGD packages\nfrom xgboost import XGBRegressor\nfrom sklearn import metrics","7db198bb":"# loading the model\nmodel = XGBRegressor()","358e1368":"# training the model with X_train\nmodel.fit(x_train, y_train)","ff6cb631":"# accuracy for prediction on training data\ntraining_data_prediction = model.predict(x_train)","e271415c":"# R squared error\nscore_1 = metrics.r2_score(y_train, training_data_prediction)\nprint(\"R squared error : \", score_1)","d8364e58":"# Mean Absolute Error\nscore_2 = metrics.mean_absolute_error(y_train, training_data_prediction)\nprint('Mean Absolute Error : ', score_2)","2666ee44":"#Plotting actual vs predcited\nplt.scatter(y_train, training_data_prediction)\nplt.xlabel(\"Actual Prices\")\nplt.ylabel(\"Predicted Prices\")\nplt.title(\"Actual Price vs Predicted Price\")\nplt.show()","980acf0a":"# accuracy for prediction on test data\ntest_data_prediction = model.predict(x_test)","b42e4e1e":"# R squared error\nscore_1 = metrics.r2_score(y_test, test_data_prediction)\nprint(\"R squared error : \", score_1)","013829c4":"# Mean Absolute Error\nscore_2 = metrics.mean_absolute_error(y_test, test_data_prediction)\n\nprint('Mean Absolute Error : ', score_2)","6a9e8e4a":"# Data Scaling","2dc8cfd1":"# Extreme  Gradient Decent","31cd58a7":"## _Multicollinearity_","fc85e777":"# Splitting the data","743b8aff":"# Model : Linear regression","ad63ff03":"# Label encoding"}}