{"cell_type":{"43ccac25":"code","51aff0e1":"code","1a0f20d6":"code","9b22dc61":"code","7ce6a5fd":"code","165ab454":"code","282f2441":"code","7e4f4cae":"code","1e86bccd":"code","d4532d1b":"code","04df22e6":"code","86c74cfe":"code","b08f2344":"code","1d9facc1":"code","0724b7c8":"code","de7bddc9":"code","c78f26a1":"code","7d635cc4":"code","1b195a8e":"code","7489b607":"code","2081a62d":"code","b7ea289c":"markdown","fe2888bd":"markdown","179a9832":"markdown","5efbc3f9":"markdown","278fb592":"markdown","c5ca164a":"markdown","1a9829d3":"markdown","b187fdcd":"markdown","3fd1240f":"markdown","5a762648":"markdown","88a40c3b":"markdown","ab4c386c":"markdown","69d273da":"markdown","b697e4b8":"markdown","1da5f5b4":"markdown","46114f38":"markdown"},"source":{"43ccac25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51aff0e1":"import nltk\nimport re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport warnings\nwarnings.filterwarnings('ignore')","1a0f20d6":"data=pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\")","9b22dc61":"df=data.copy()\ndf.head()","7ce6a5fd":"#shape of the dataset\ndf.shape","165ab454":"#check duplicates\ndf['show_id'].duplicated().sum()","282f2441":"#check missing values\ndf.isna().sum()","7e4f4cae":"#remove all the missing values\ndf.dropna(inplace=True)","1e86bccd":"#reset the index values\ndf.reset_index(inplace=True)","d4532d1b":"df1=df[df['type']=='Movie']","04df22e6":"#reset index\ndf1.reset_index(inplace=True)","86c74cfe":"newdf=df1[['title','director','country','description']]\nnewdf.head()","b08f2344":"features=[]\n\nfor i in range(newdf.shape[0]):\n    features.append(\" \".join(list(newdf.iloc[i].values)))","1d9facc1":"lem=nltk.WordNetLemmatizer()\ncorpus=[]\n\nfor i in range(len(features)):\n    review=re.sub('[^a-zA-Z]',' ',features[i])\n    review=review.lower()\n    review=review.split()\n    review=[lem.lemmatize(w) for w in review if w not in set(stopwords.words('english'))]\n    review=' '.join(review)\n    corpus.append(review)","0724b7c8":"newdf['features']=corpus\nnewdf.head()","de7bddc9":"cv=CountVectorizer()\ncvdf=cv.fit_transform(newdf['features'])","c78f26a1":"#since cvdf is sparse matrix, we need to put toarray() part to show our matrix\ncvdf.toarray()","7d635cc4":"cs=cosine_similarity(cvdf)","1b195a8e":"cs","7489b607":"#let's write a function to get recommendations for given movie\ndef movie_rec(title):\n    \n    #extract movie index of given movie title\n    movie_index=newdf[[title in name for name in newdf[\"title\"]]].index[0]\n    \n    #get similarity score and its index for given movie title\n    similarity_score=list(enumerate(cs[movie_index]))\n    \n    #sorted similarity scores for given movie title (Descending order)\n    similarity_score=sorted(similarity_score,key=lambda x:x[1],reverse=True)\n    \n    #extract top 10 similarity scores for given movie\n    similarity_score=similarity_score[1:11]\n    \n    #extract index values of top 10 movies\n    movie_indices=[idx[0] for idx in similarity_score]\n    \n    #return recommended movies with their index values\n    return newdf['title'][movie_indices]","2081a62d":"movie_rec('Jeans')","b7ea289c":"<h2>Cleaning Text Data<\/h2>","fe2888bd":"<h2>Let's import needful libraries<\/h2>","179a9832":"<h2>Feature Count Matrix<\/h2>","5efbc3f9":"<h4>Since we have removed missing values, index values are not in order. So as a good practice it's better to reset our index values.<\/h4>","278fb592":"<h4>As a good practice, it's better to remove all unnecessary notations, remove stop words, use lemmatization (Lemmatization helps us to achieve the root forms (sometimes called synonyms in search context) of inflected (derived) words), and convert all letters to lower cases (Since I'm going to apply count vectorizer, if there exist a word with both upper and lower cases, then count vectorizer identify that word as two words).<\/h4>  ","c5ca164a":"<h2>According to above results, we can recommend above 10 movies to people who have watched 'Jeans' movie.<\/h2>","1a9829d3":"<h4>Six columns have some missing values. Since all these six columns consists of text data, it is really hard to impute those values. Therefore, it's better to remove all the missing values.<\/h4>","b187fdcd":"<h4>Let's check our functions!<\/h4>","3fd1240f":"<h4>As I told, Let's extract only movie data<\/h4>","5a762648":"<h4>I'm going to use count vectorizer for this task. However, you can use TF-IDF as well.<\/h4> ","88a40c3b":"<h2>Needful Columns<\/h2>","ab4c386c":"<h2>Data Wrangling<\/h2>","69d273da":"**Recommendation system is one of interesting applications in Data Science. Even though we have so many libraries including scikit-learn to implement machine learning models, there is no any direct library for build recommendations. Hence, we have to create this system by our own way. In this notebook, I'm going to create recommendation system only for netflix movies based on title, director, country and description.**    ","b697e4b8":"<h2>Recommendations<\/h2>","1da5f5b4":"<h2>Let's Calculate Cosine Similarity<\/h2>","46114f38":"<h4>We use cosine similarity to calculate similarity between movies (we can use linear kernal as well).<\/h4>"}}