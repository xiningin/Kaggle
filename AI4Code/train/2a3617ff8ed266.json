{"cell_type":{"283b3181":"code","61d13665":"code","41d8812d":"code","595edbb6":"code","c233f6e1":"code","23b1e338":"code","daec342e":"code","343372a5":"code","dec05769":"code","d30f63e4":"code","9153b2b6":"code","72ed7808":"code","422632b6":"code","7814d50e":"code","61186273":"markdown","7fe972e7":"markdown","7d48f066":"markdown","2860e044":"markdown","f579b7ba":"markdown","611c954f":"markdown","b695690c":"markdown","829acb7f":"markdown","b35d12f8":"markdown","62e5e61f":"markdown","fc4e9111":"markdown"},"source":{"283b3181":"#import libraries \nimport numpy as np #computing\nimport pandas as pd #calculations\/Data wrangling\nimport bq_helper\nfrom bq_helper import BigQueryHelper\nimport seaborn as sns #visualization package\nimport matplotlib.pyplot as plt","61d13665":"#Get Data\nnyc = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                   dataset_name=\"new_york\") #Set up connection\nbq_assistant = BigQueryHelper(\"bigquery-public-data\", \"new_york\") #Set up helper\nbq_assistant.list_tables() #Show list of available tables ","41d8812d":"#Preview of Dataset \nnyc.head('citibike_trips') #Sneak a peek at data ","595edbb6":"#Query Data, eliminate nulls for total_amount\nquery = \"\"\"select *\n          from `bigquery-public-data.new_york.citibike_trips`  \n          limit 10000\n          \"\"\"","c233f6e1":"\ndata = nyc.query_to_pandas_safe(query, max_gb_scanned=10) ","23b1e338":"data.head(5) #See head of data \n","daec342e":"data.shape  #(1000 rows,23 columns)\n","343372a5":"data.describe() #See summary of quant data \n","dec05769":"data.columns #See list of columns \n","d30f63e4":"data.info() #Check out structure of each column (if integer, string,etc)\n","9153b2b6":"\npd.isna(data).sum() #See number of NAs by column. We see that birth_year has a sizeable amount of nulls- will need to investigate and handle \n\n","72ed7808":"sns.countplot(data['gender'])","422632b6":"g = sns.countplot(data['start_station_name']) #Create basic plot \n","7814d50e":"ax = sns.countplot(x=data['start_station_name']) #Store labels \n\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\") #Rotate x-axis\nplt.show() #Show visual","61186273":"**We all know NYC is the best city in the world, right???\n   Here, we get started with pulling the data through BigQuery and SQL, and then getting a sense for the structure of the data. [](http:\/\/)\n**","7fe972e7":"The first thing we have to do is load our packages. Packages are complex compilation of functions created by other users,and open to the community to use. You can technically recreate them yourself in the code, but who has time for that?! Not New Yorkers, I promise you that.\n\nBelow we import some of the required packages for the project. Note: Pandas\/Numpy are essential for data science, and I strongly encourage you to check out seperate tutorials for those packages. ","7d48f066":"So we have a good, general sense of the data now. It also helps to visualize the data, to see certain trends\/stories that we might have otherwise misseed. Let's do a few quick visuals to get us started here. We'll develop more sophisticated visuals later on in the series! ","2860e044":"Now let's see the distribution of the start stations. ","f579b7ba":"Males dominate the demographic- it's interesting to note how unknown is almost equal to female in the data.","611c954f":"The next step is actually loading our data. We're using a public dataset on BigQuery, and will be pulling using basic SQL. Nothing terribly complex here, we could devote an entire series into SQL! ","b695690c":"Let's look at what the gender split is. ","829acb7f":"Awesome. Now that we've pulled our data through our first SQL Query, we're going to proceed to storing it for easy usage. ","b35d12f8":"Yikes. X-axis is looking very cluttered, can't make any sense of the data. Let's tweak that. ","62e5e61f":"That's much better! Looks like Barrow & Hudson has the most trip starts. Ew. \n\nThis is a good stopping point for the first stage of our project. Next time, we'll perform some more in-depth analysis of the data, do some grouping\/staistical analysis, perform some data cleansing\/wrangling, and then perform a bit more in-depth visuals. \n\nIn the inteirm, feel free to play around with the code, write some of your own,or explore other tutorials.","fc4e9111":"It's time to explore the data! Let's get a sense for what the data looks like, how many rows\/columns are present,and other simple explorations. "}}