{"cell_type":{"12512524":"code","bf26e037":"code","73925e77":"code","62aafb05":"code","94cd0a99":"code","4f4883e9":"code","a4116557":"code","a843a30d":"code","b996049c":"code","ee7f0335":"code","a91f9ebd":"code","48ca32e4":"code","28211af8":"code","14aada1e":"code","0872511f":"code","431955e5":"code","6731e7d0":"code","a8368421":"code","52c987d7":"code","3567e0a6":"code","14ec19e2":"code","a05cbf49":"code","5e2da25b":"code","9f37866a":"code","d2d8c9d3":"code","dbb6e926":"code","a3f5c9ff":"code","a2cb2590":"code","9b1f5039":"code","fdfd1eb8":"code","17b58ed9":"code","72373f68":"code","5caad322":"code","9e20a41b":"code","c401f910":"code","d9efea01":"code","7fd595dc":"markdown","42f268a0":"markdown","c6a2b386":"markdown","aef5baea":"markdown","3d45818e":"markdown","b8ddccd2":"markdown","f4dfa103":"markdown","ccd36907":"markdown","9a066beb":"markdown","1e155c7c":"markdown","d666679c":"markdown","69bf870f":"markdown"},"source":{"12512524":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB3\nfrom keras.optimizers import Adam\nfrom keras.losses import CategoricalCrossentropy\nimport os, cv2, json\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")","bf26e037":"# For easy acces to files\nWORK_DIR = \"..\/input\/cassava-leaf-disease-classification\/\"\nos.listdir(WORK_DIR)","73925e77":"with open('..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json', 'r') as file:\n    labels = json.load(file)\n    \nlabels","62aafb05":"data = pd.read_csv(WORK_DIR + \"train.csv\")","94cd0a99":"data.head()","4f4883e9":"data.dtypes","a4116557":"#change for the ImageDatagen and flow_from_dataframe\ndata.label = data.label.astype(\"str\")","a843a30d":"data.dtypes","b996049c":"data.shape[0]","ee7f0335":"data.label.value_counts()","a91f9ebd":"IMG_SIZE = 300","48ca32e4":"plt.figure(figsize=(15,12))\ndata_sample = data.sample(9).reset_index(drop=True)\n\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","28211af8":"labels.get(\"0\")","14aada1e":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"0\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","0872511f":"labels.get(\"1\")","431955e5":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"1\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","6731e7d0":"labels.get(\"2\")","a8368421":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"2\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","52c987d7":"labels.get(\"3\")","3567e0a6":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"3\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","14ec19e2":"labels.get(\"4\")","a05cbf49":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"4\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","5e2da25b":"\n\ntrain_generator = ImageDataGenerator(\n                                    featurewise_center=True,                                    \n                                    samplewise_center=True,\n                                    featurewise_std_normalization=True,\n                                    samplewise_std_normalization=True, \n                                    zca_whitening=False,\n                                    zca_epsilon=1e-06,\n                                    rotation_range=180,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    brightness_range=[-0.1,0.1],\n                                    shear_range=25,\n                                    zoom_range=0.3,\n                                    channel_shift_range=0.2,\n                                    #fill_mode=\"nearest\",\n                                    #cval=0.0,\n                                    horizontal_flip=True,\n                                    vertical_flip=True,\n                                    #rescale=None,\n                                    #preprocessing_function=None,\n                                    #data_format=None,\n                                    validation_split=0.2,\n                                    #dtype=None,\n) \\\n        .flow_from_dataframe(\n                            data,\n                            directory = WORK_DIR + \"train_images\",\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            #weight_col = None,\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            #color_mode = \"rgb\",\n                            #classes = None,\n                            class_mode = \"categorical\",\n                            batch_size = 32,\n                            shuffle = True,\n                            #seed = 34,\n                            #save_to_dir = None,\n                            #save_prefix = \"\",\n                            #save_format = \"png\",\n                            subset = \"training\",\n                            #interpolation = \"nearest\",\n                            #validate_filenames = True\n)\n","9f37866a":"valid_generator = ImageDataGenerator(\n                                    validation_split = 0.2\n) \\\n        .flow_from_dataframe(\n                            data,\n                            directory = WORK_DIR + \"train_images\",\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            class_mode = \"categorical\",\n                            batch_size = 32,\n                            shuffle = True,\n                            #seed = 34,\n                            subset = \"validation\")","d2d8c9d3":"valid_generator.class_indices","dbb6e926":"def modelEfficientNetB3():\n    \n    model = models.Sequential()\n    model.add(EfficientNetB3(include_top = False, weights = \"imagenet\",\n                            input_shape=(IMG_SIZE,IMG_SIZE, 3)))\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(256, activation = 'relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(5, activation = \"softmax\"))\n    \n    return model ","a3f5c9ff":"model = modelEfficientNetB3()","a2cb2590":"model.summary()","9b1f5039":"from tensorflow.keras import utils\n\nutils.plot_model(model)","fdfd1eb8":"model_check = ModelCheckpoint(\n                            \".\/firstTry.h5\",\n                            monitor = \"val_loss\",\n                            verbose = 1,\n                            save_best_only = True,\n                            save_weights_only = False,\n                            mode = \"min\")","17b58ed9":"early_stop= EarlyStopping(\n                                monitor = \"val_loss\",\n                                min_delta=0.001,\n                                patience=5,\n                                verbose=1,\n                                mode=\"min\",\n                                #baseline=None,\n                                restore_best_weights=False)","72373f68":"reduce_lr = ReduceLROnPlateau(\n                                monitor=\"val_loss\",\n                                factor=0.1,\n                                patience=2,\n                                verbose=1,\n                                mode=\"min\",\n                                min_delta=0.0001,\n                                #cooldown=0,\n                                #min_lr=0\n)","5caad322":"model.compile(optimizer = \"adam\",\n            loss = CategoricalCrossentropy(label_smoothing=0.3,reduction=\"auto\",name=\"categorical_crossentropy\"),\n            metrics = [\"accuracy\"])","9e20a41b":"history = model.fit_generator(train_generator,\n                            epochs = 30,\n                            validation_data = valid_generator,\n                            callbacks = [model_check,early_stop,reduce_lr])\n","c401f910":"plt.figure(figsize=(15, 5))\nplt.plot(history.history['accuracy'], 'b*-', label=\"train_acc\")\nplt.plot(history.history['val_accuracy'], 'r*-', label=\"val_acc\")\nplt.grid()\nplt.title(\"train_acc vs val_acc\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend()\nplt.show()","d9efea01":"plt.figure(figsize=(15, 5))\nplt.plot(history.history['loss'], 'b*-', label=\"train_loss\")\nplt.plot(history.history['val_loss'], 'r*-', label=\"val_loss\")\nplt.grid()\nplt.title(\"train_loss - val_loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend()\nplt.show()","7fd595dc":"# Image Visualization\n\n\n#### Let's first visualize the general data set. \n#### Visualize by class later","42f268a0":"## Callbacks\n\n**ModelCheckpoint**: Callback to save the Keras model or model weights at some frequency.\n\n**EarlyStopping**: Stop training when a monitored metric has stopped improving.\n\n**ReduceLROnPlateau**: Reduce learning rate when a metric has stopped improving.\n\n\nhttps:\/\/keras.io\/api\/callbacks\/","c6a2b386":"**Cassava Mosaic Disease (CMD)**","aef5baea":"### **We have 21397 images for training and don't have an equal number of photos for each class.** \n\n I don't know how to deal with the unbalanced image dataset so I'll leave it to the next version.","3d45818e":"# STARTER: keras EfficientNet\n\nHello, this is my first computer vision competition notebook. \n\nPlease don't be afraid to ask questions. I hope this notebook helps you. \n\n","b8ddccd2":"**Cassava Bacterial Blight (CBB)**","f4dfa103":"**Any suggestions are very valuable to me. please share with me**","ccd36907":"**Cassava Green Mottle (CGM)**","9a066beb":"**Healthy**","1e155c7c":"**Cassava Brown Streak Disease (CBSD)**","d666679c":"# Model\n\nActually I can say that this is my first experience in transfer learning. I found a good repo on GitHub for benchmarking. Thats why I used EfficientNet.\n\nhttps:\/\/github.com\/weiaicunzai\/awesome-image-classification","69bf870f":"# Image Preprocessing, Data Augmentetion\n\n\n**ImageDataGenerator:** Generate batches of tensor image data with real-time data augmentation.\n\n**flow_from_dataframe:** Takes the dataframe and the path to a directory + generates batches.\nThe generated batches contain augmented\/normalized data.\n\n\nhttps:\/\/keras.io\/api\/preprocessing\/image\/"}}