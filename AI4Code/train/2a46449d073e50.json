{"cell_type":{"a8d0afb7":"code","8cb6b3b1":"code","273db6f2":"code","6b4a9b77":"code","d7f2085f":"code","66495d94":"code","5e87ebf8":"code","712a23f2":"code","28799fec":"code","d0208472":"code","7d37f16f":"code","afa45f34":"code","a5f9eab9":"code","5b5b0c5a":"code","1caa76d2":"code","7aac673c":"code","b75858c2":"code","0b0b0105":"code","175534a1":"code","723ffca3":"code","572996cf":"code","93af9ee3":"code","0df9c867":"code","91272c41":"code","6f67e92c":"code","1cefa931":"code","0c86ee58":"code","112d043b":"code","61db855d":"code","f7eaa18f":"code","6ce7bb21":"code","322b2339":"code","98e7f2bd":"code","4b873b41":"code","870fd5fb":"code","11d4bee7":"code","6bf73895":"code","a2a400b5":"code","9cd10077":"code","3feed8ae":"code","a2fda462":"code","4c1ce11b":"code","eef3406c":"code","92ff99b8":"code","a2ef2e9d":"code","ce6ca496":"code","33df4008":"code","79097d73":"code","8d629c9c":"code","8258271c":"code","fd6e33a3":"code","b41cb43d":"code","b1c7fc20":"code","684613e3":"code","ca97f438":"code","3c0334a7":"code","7fb67296":"code","e6e4f7ee":"code","72534e54":"code","fa8a974e":"code","d64ebec9":"markdown","ed37c275":"markdown","e7a0eb3f":"markdown","54d41eb4":"markdown","9129c71c":"markdown","9f9270d2":"markdown","068569e0":"markdown","f74f548c":"markdown","caf9cb76":"markdown","a38f5a69":"markdown","433e12a6":"markdown","cb33b64c":"markdown","349d6064":"markdown","32e1d074":"markdown","939ac789":"markdown","0c83671a":"markdown","c5b08b28":"markdown","4a43c259":"markdown","a01da839":"markdown","f9cd3005":"markdown","2cc38083":"markdown","76aab37c":"markdown","daa5996d":"markdown","e72cd879":"markdown","f953dc7c":"markdown","63e5057f":"markdown","46047af4":"markdown"},"source":{"a8d0afb7":"!pip install pytorch-ignite==0.2.* tensorboardX==1.6.*\nimport os\nimport numpy as np\nimport random\nimport torch\nimport ignite\n\nseed = 17\nrandom.seed(seed)\n_ = torch.manual_seed(seed)","8cb6b3b1":"torch.__version__, ignite.__version__","273db6f2":"import torch\nimport torch.nn as nn\n\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.reshape(x.shape[0], -1)","6b4a9b77":"import matplotlib.pylab as plt\n%matplotlib inline\n\nd = torch.linspace(-10.0, 10.0)\ns = Swish()\nres = s(d)\nres2 = torch.relu(d)\n\nplt.title(\"Swish transformation\")\nplt.plot(d.numpy(), res.numpy(), label='Swish')\nplt.plot(d.numpy(), res2.numpy(), label='ReLU')\nplt.legend()","d7f2085f":"class SqueezeExcitation(nn.Module):\n    \n    def __init__(self, inplanes, se_planes):\n        super(SqueezeExcitation, self).__init__()\n        self.reduce_expand = nn.Sequential(\n            nn.Conv2d(inplanes, se_planes, \n                      kernel_size=1, stride=1, padding=0, bias=True),\n            Swish(),\n            nn.Conv2d(se_planes, inplanes, \n                      kernel_size=1, stride=1, padding=0, bias=True),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x_se = torch.mean(x, dim=(-2, -1), keepdim=True)\n        x_se = self.reduce_expand(x_se)\n        return x_se * x\n","66495d94":"from torch.nn import functional as F\n\nclass MBConv(nn.Module):\n    def __init__(self, inplanes, planes, kernel_size, stride, \n                 expand_rate=1.0, se_rate=0.25, \n                 drop_connect_rate=0.2):\n        super(MBConv, self).__init__()\n\n        expand_planes = int(inplanes * expand_rate)\n        se_planes = max(1, int(inplanes * se_rate))\n\n        self.expansion_conv = None        \n        if expand_rate > 1.0:\n            self.expansion_conv = nn.Sequential(\n                nn.Conv2d(inplanes, expand_planes, \n                          kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3),\n                Swish()\n            )\n            inplanes = expand_planes\n\n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(inplanes, expand_planes,\n                      kernel_size=kernel_size, stride=stride, \n                      padding=kernel_size \/\/ 2, groups=expand_planes,\n                      bias=False),\n            nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3),\n            Swish()\n        )\n\n        self.squeeze_excitation = SqueezeExcitation(expand_planes, se_planes)\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(expand_planes, planes, \n                      kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(planes, momentum=0.01, eps=1e-3),\n        )\n\n        self.with_skip = stride == 1\n        self.drop_connect_rate = torch.tensor(drop_connect_rate, requires_grad=False)\n    \n    def _drop_connect(self, x):        \n        keep_prob = 1.0 - self.drop_connect_rate\n        drop_mask = torch.rand(x.shape[0], 1, 1, 1) + keep_prob\n        drop_mask = drop_mask.type_as(x)\n        drop_mask.floor_()\n        return drop_mask * x \/ keep_prob\n        \n    def forward(self, x):\n        z = x\n        if self.expansion_conv is not None:\n            x = self.expansion_conv(x)\n\n        x = self.depthwise_conv(x)\n        x = self.squeeze_excitation(x)\n        x = self.project_conv(x)\n        \n        # Add identity skip\n        if x.shape == z.shape and self.with_skip:            \n            if self.training and self.drop_connect_rate is not None:\n                self._drop_connect(x)\n            x += z\n        return x","5e87ebf8":"from collections import OrderedDict\nimport math\n\n\ndef init_weights(module):    \n    if isinstance(module, nn.Conv2d):    \n        nn.init.kaiming_normal_(module.weight, a=0, mode='fan_out')\n    elif isinstance(module, nn.Linear):\n        init_range = 1.0 \/ math.sqrt(module.weight.shape[1])\n        nn.init.uniform_(module.weight, a=-init_range, b=init_range)\n        \n        \nclass EfficientNet(nn.Module):\n        \n    def _setup_repeats(self, num_repeats):\n        return int(math.ceil(self.depth_coefficient * num_repeats))\n    \n    def _setup_channels(self, num_channels):\n        num_channels *= self.width_coefficient\n        new_num_channels = math.floor(num_channels \/ self.divisor + 0.5) * self.divisor\n        new_num_channels = max(self.divisor, new_num_channels)\n        if new_num_channels < 0.9 * num_channels:\n            new_num_channels += self.divisor\n        return new_num_channels\n\n    def __init__(self, num_classes=10, \n                 width_coefficient=1.0,\n                 depth_coefficient=1.0,\n                 se_rate=0.25,\n                 dropout_rate=0.2,\n                 drop_connect_rate=0.2):\n        super(EfficientNet, self).__init__()\n        \n        self.width_coefficient = width_coefficient\n        self.depth_coefficient = depth_coefficient\n        self.divisor = 8\n                \n        list_channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n        list_channels = [self._setup_channels(c) for c in list_channels]\n                \n        list_num_repeats = [1, 2, 2, 3, 3, 4, 1]\n        list_num_repeats = [self._setup_repeats(r) for r in list_num_repeats]        \n        \n        expand_rates = [1, 6, 6, 6, 6, 6, 6]\n        strides = [1, 2, 2, 2, 1, 2, 1]\n        kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n\n        # Define stem:\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, list_channels[0], kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(list_channels[0], momentum=0.01, eps=1e-3),\n            Swish()\n        )\n        \n        # Define MBConv blocks\n        blocks = []\n        counter = 0\n        num_blocks = sum(list_num_repeats)\n        for idx in range(7):\n            \n            num_channels = list_channels[idx]\n            next_num_channels = list_channels[idx + 1]\n            num_repeats = list_num_repeats[idx]\n            expand_rate = expand_rates[idx]\n            kernel_size = kernel_sizes[idx]\n            stride = strides[idx]\n            drop_rate = drop_connect_rate * counter \/ num_blocks\n            \n            name = \"MBConv{}_{}\".format(expand_rate, counter)\n            blocks.append((\n                name,\n                MBConv(num_channels, next_num_channels, \n                       kernel_size=kernel_size, stride=stride, expand_rate=expand_rate, \n                       se_rate=se_rate, drop_connect_rate=drop_rate)\n            ))\n            counter += 1\n            for i in range(1, num_repeats):                \n                name = \"MBConv{}_{}\".format(expand_rate, counter)\n                drop_rate = drop_connect_rate * counter \/ num_blocks                \n                blocks.append((\n                    name,\n                    MBConv(next_num_channels, next_num_channels, \n                           kernel_size=kernel_size, stride=1, expand_rate=expand_rate, \n                           se_rate=se_rate, drop_connect_rate=drop_rate)                                    \n                ))\n                counter += 1\n        \n        self.blocks = nn.Sequential(OrderedDict(blocks))\n        \n        # Define head\n        self.head = nn.Sequential(\n            nn.Conv2d(list_channels[-2], list_channels[-1], \n                      kernel_size=1, bias=False),\n            nn.BatchNorm2d(list_channels[-1], momentum=0.01, eps=1e-3),\n            Swish(),\n            nn.AdaptiveAvgPool2d(1),\n            Flatten(),\n            nn.Dropout(p=dropout_rate),\n            nn.Linear(list_channels[-1], num_classes)\n        )\n\n        self.apply(init_weights)\n        \n    def forward(self, x):\n        f = self.stem(x)\n        f = self.blocks(f)\n        y = self.head(f)\n        return y","712a23f2":"model = EfficientNet(num_classes=1000, \n                     width_coefficient=1.0, depth_coefficient=1.0, \n                     dropout_rate=0.2)","28799fec":"def print_num_params(model, display_all_modules=False):\n    total_num_params = 0\n    for n, p in model.named_parameters():\n        num_params = 1\n        for s in p.shape:\n            num_params *= s\n        if display_all_modules: print(\"{}: {}\".format(n, num_params))\n        total_num_params += num_params\n    print(\"-\" * 50)\n    print(\"Total number of parameters: {:.2e}\".format(total_num_params))\n    \n\nprint_num_params(model)","d0208472":"from torchvision.models.resnet import resnet18, resnet34, resnet50","7d37f16f":"print_num_params(resnet18(pretrained=False, num_classes=10))\nprint_num_params(resnet34(pretrained=False, num_classes=10))\nprint_num_params(resnet50(pretrained=False, num_classes=10))","afa45f34":"from tensorboardX.pytorch_graph import graph\n\nimport random\nfrom IPython.display import clear_output, Image, display, HTML\n\n\ndef show_graph(graph_def):\n    \"\"\"Visualize TensorFlow graph.\"\"\"\n    if hasattr(graph_def, 'as_graph_def'):\n        graph_def = graph_def.as_graph_def()\n    strip_def = graph_def\n    code = \"\"\"\n        <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/polymer\/0.3.3\/platform.js\"><\/script>\n        <script>\n          function load() {{\n            document.getElementById(\"{id}\").pbtxt = {data};\n          }}\n        <\/script>\n        <link rel=\"import\" href=\"https:\/\/tensorboard.appspot.com\/tf-graph-basic.build.html\" onload=load()>\n        <div style=\"height:600px\">\n          <tf-graph-basic id=\"{id}\"><\/tf-graph-basic>\n        <\/div>\n    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(random.randint(0, 1000)))\n\n    iframe = \"\"\"\n        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"><\/iframe>\n    \"\"\".format(code.replace('\"', '&quot;'))\n    display(HTML(iframe))","a5f9eab9":"# x = torch.rand(4, 3, 224, 224)\n# graph_def = graph(model, x, operator_export_type='RAW')","5b5b0c5a":"# Display in Firefox may not work properly. Use Chrome.\n# show_graph(graph_def[0])","1caa76d2":"!wget http:\/\/storage.googleapis.com\/public-models\/efficientnet-b0-08094119.pth","7aac673c":"from collections import OrderedDict\n\nmodel_state = torch.load(\"efficientnet-b0-08094119.pth\")\n\n# A basic remapping is required\nmapping = {\n    k: v for k, v in zip(model_state.keys(), model.state_dict().keys())\n}\nmapped_model_state = OrderedDict([\n    (mapping[k], v) for k, v in model_state.items()\n])\n\nmodel.load_state_dict(mapped_model_state, strict=False)","b75858c2":"!wget https:\/\/raw.githubusercontent.com\/lukemelas\/EfficientNet-PyTorch\/master\/examples\/simple\/img.jpg -O\/tmp\/giant_panda.jpg\n!wget https:\/\/raw.githubusercontent.com\/lukemelas\/EfficientNet-PyTorch\/master\/examples\/simple\/labels_map.txt -O\/tmp\/labels_map.txt","0b0b0105":"import json\n\nwith open(\"\/tmp\/labels_map.txt\", \"r\") as h:\n    labels = json.load(h)\n\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n\nimg = Image.open(\"\/tmp\/giant_panda.jpg\")\n# Preprocess image\ntfms = transforms.Compose([transforms.Resize(224),\n                           transforms.ToTensor(),\n                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\nx = tfms(img).unsqueeze(0)\n_ = plt.imshow(img)","175534a1":"# Classify\nmodel.eval()\nwith torch.no_grad():\n    y_pred = model(x)\n\n# Print predictions\nprint('-----')\nfor idx in torch.topk(y_pred, k=5)[1].squeeze(0).tolist():\n    prob = torch.softmax(y_pred, dim=1)[0, idx].item()\n    print('{label:<75} ({p:.2f}%)'.format(label=labels[str(idx)], p=prob*100))","723ffca3":"from torchvision.datasets.cifar import CIFAR100, CIFAR10\nfrom torchvision.transforms import Compose, RandomCrop, Pad, RandomHorizontalFlip, Resize, RandomAffine\nfrom torchvision.transforms import ToTensor, Normalize\n\nfrom torch.utils.data import Subset\nimport torchvision.utils as vutils","572996cf":"!ls ..\/input\n!tar -zxvf ..\/input\/cifar-10-python.tar.gz","93af9ee3":"from PIL.Image import BICUBIC\n\npath = \".\"\nimage_size = 224\n\ntrain_transform = Compose([\n    Resize(image_size, BICUBIC),\n    RandomAffine(degrees=2, translate=(0.02, 0.02), scale=(0.98, 1.02), shear=2, fillcolor=(124,117,104)),\n    RandomHorizontalFlip(),\n    ToTensor(),\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = Compose([\n    Resize(image_size, BICUBIC),    \n    ToTensor(),\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = CIFAR10(root=path, train=True, transform=train_transform, download=False)\ntest_dataset = CIFAR10(root=path, train=False, transform=test_transform, download=False)\n\ntrain_eval_indices = [random.randint(0, len(train_dataset) - 1) for i in range(len(test_dataset))]\ntrain_eval_dataset = Subset(train_dataset, train_eval_indices)\n\nlen(train_dataset), len(test_dataset), len(train_eval_dataset)","0df9c867":"from torch.utils.data import DataLoader\n\nbatch_size = 125\nnum_workers = 2\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, \n                          shuffle=True, drop_last=True, pin_memory=True)\n\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, \n                         shuffle=False, drop_last=False, pin_memory=True)\n\neval_train_loader = DataLoader(train_eval_dataset, batch_size=batch_size, num_workers=num_workers, \n                               shuffle=False, drop_last=False, pin_memory=True)","91272c41":"# Plot some training images\nbatch = next(iter(train_loader))\n\nplt.figure(figsize=(16, 8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\n_ = plt.imshow( \n    vutils.make_grid(batch[0][:16], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0))\n)","6f67e92c":"# Classify prior to fine tunning\nmodel.eval()\nwith torch.no_grad():\n    y_pred = model(batch[0][:1])\n\n# Print predictions\nprint('-----')\nfor idx in torch.topk(y_pred, k=9)[1].squeeze(0).tolist():\n    prob = torch.softmax(y_pred, dim=1)[0, idx].item()\n    print('{label:<75} ({p:.2f}%)'.format(label=labels[str(idx)], p=prob*100))","1cefa931":"batch = None\ntorch.cuda.empty_cache()","0c86ee58":"model.head[6].in_features, model.head[6].out_features","112d043b":"model.head[6] = nn.Linear(1280, 10)\nc10classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","61db855d":"model.head[6].in_features, model.head[6].out_features","f7eaa18f":"assert torch.cuda.is_available()\nassert torch.backends.cudnn.enabled, \"NVIDIA\/Apex:Amp requires cudnn backend to be enabled.\"\ntorch.backends.cudnn.benchmark = True\n\ndevice = \"cuda\"","6ce7bb21":"model = model.to(device)","322b2339":"from itertools import chain\n\nimport torch.optim as optim\nimport torch.nn.functional as F\n\ncriterion = nn.CrossEntropyLoss()\nlr = 0.006\n\noptimizer = optim.SGD([\n    {\n        \"params\": chain(model.stem.parameters(), model.blocks.parameters()),\n        \"lr\": lr * 0.1,\n    },\n    {\n        \"params\": model.head[:6].parameters(),\n        \"lr\": lr * 0.2,\n    },    \n    {\n        \"params\": model.head[6].parameters(), \n        \"lr\": lr\n    }], \n    momentum=0.9, weight_decay=1e-3, nesterov=True)","98e7f2bd":"from torch.optim.lr_scheduler import ExponentialLR\nlr_scheduler = ExponentialLR(optimizer, gamma=0.985)","4b873b41":"use_amp = True\n\nif use_amp:\n    try:\n        from apex import amp\n    except ImportError:\n        !git clone https:\/\/github.com\/NVIDIA\/apex\n        !pip install --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" apex\/\n        from apex import amp\n\n\n    # Initialize Amp\n    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O2\", num_losses=1)","870fd5fb":"from ignite.utils import convert_tensor\n\n\ndef update_fn(engine, batch):\n    model.train()\n\n    x = convert_tensor(batch[0], device=device, non_blocking=True)\n    y = convert_tensor(batch[1], device=device, non_blocking=True)\n    \n    y_pred = model(x)\n    \n    # Compute loss \n    loss = criterion(y_pred, y)    \n\n    optimizer.zero_grad()\n    if use_amp:\n        with amp.scale_loss(loss, optimizer, loss_id=0) as scaled_loss:\n            scaled_loss.backward()\n    else:\n        loss.backward()\n    optimizer.step()\n    \n    return {\n        \"batchloss\": loss.item(),\n    }    ","11d4bee7":"batch = next(iter(train_loader))\n\nres = update_fn(engine=None, batch=batch)\n\nbatch = None\ntorch.cuda.empty_cache()\n\nres","6bf73895":"from ignite.engine import Engine, Events, create_supervised_evaluator\nfrom ignite.metrics import RunningAverage, Accuracy, Precision, Recall, Loss, TopKCategoricalAccuracy\n\nfrom ignite.contrib.handlers import TensorboardLogger\nfrom ignite.contrib.handlers.tensorboard_logger import OutputHandler, OptimizerParamsHandler","a2a400b5":"trainer = Engine(update_fn)\n\ndef output_transform(out):\n    return out['batchloss']\n\nRunningAverage(output_transform=output_transform).attach(trainer, \"batchloss\")","9cd10077":"from datetime import datetime\n\nexp_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlog_path = f\"\/tmp\/finetune_efficientnet_cifar10\/{exp_name}\"\ntb_logger = TensorboardLogger(log_dir=log_path)\n\ntb_logger.attach(trainer, \n                 log_handler=OutputHandler('training', ['batchloss', ]), \n                 event_name=Events.ITERATION_COMPLETED)\n\nprint(\"Experiment name: \", exp_name)","3feed8ae":"trainer.add_event_handler(Events.EPOCH_COMPLETED, lambda engine: lr_scheduler.step())\n\n# Log optimizer parameters\ntb_logger.attach(trainer,\n                 log_handler=OptimizerParamsHandler(optimizer, \"lr\"), \n                 event_name=Events.EPOCH_STARTED)","a2fda462":"from ignite.contrib.handlers import ProgressBar\n\n# Iteration-wise progress bar\nProgressBar(bar_format=\"\").attach(trainer, metric_names=['batchloss',])\n\n# Epoch-wise progress bar with display of training losses\nProgressBar(persist=True, bar_format=\"\").attach(trainer, metric_names=['batchloss',],\n                                                event_name=Events.EPOCH_STARTED,\n                                                closing_event_name=Events.COMPLETED)","4c1ce11b":"metrics = {\n    'Loss': Loss(criterion),\n    'Accuracy': Accuracy(),\n    'Precision': Precision(average=True),\n    'Recall': Recall(average=True),\n    'Top-5 Accuracy': TopKCategoricalAccuracy(k=5)\n}\n\nevaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)\ntrain_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)","eef3406c":"from ignite.contrib.handlers import CustomPeriodicEvent\n\ncpe = CustomPeriodicEvent(n_epochs=3)\ncpe.attach(trainer)\n\n\ndef run_evaluation(engine):\n    train_evaluator.run(eval_train_loader)\n    evaluator.run(test_loader)\n\n\ntrainer.add_event_handler(cpe.Events.EPOCHS_3_STARTED, run_evaluation)\ntrainer.add_event_handler(Events.COMPLETED, run_evaluation)\n\n\n# Log train eval metrics:\ntb_logger.attach(train_evaluator,\n                 log_handler=OutputHandler(tag=\"training\",\n                                           metric_names=list(metrics.keys()),\n                                           another_engine=trainer),\n                 event_name=Events.EPOCH_COMPLETED)\n\n# Log val metrics:\ntb_logger.attach(evaluator,\n                 log_handler=OutputHandler(tag=\"test\",\n                                           metric_names=list(metrics.keys()),\n                                           another_engine=trainer),\n                 event_name=Events.EPOCH_COMPLETED)","92ff99b8":"import logging\n\n# Setup engine &  logger\ndef setup_logger(logger):\n    handler = logging.StreamHandler()\n    formatter = logging.Formatter(\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    logger.setLevel(logging.INFO)","a2ef2e9d":"from ignite.handlers import ModelCheckpoint, EarlyStopping, TerminateOnNan\n\ntrainer.add_event_handler(Events.ITERATION_COMPLETED, TerminateOnNan())\n\n# Store the best model\ndef default_score_fn(engine):\n    score = engine.state.metrics['Accuracy']\n    return score\n\nbest_model_handler = ModelCheckpoint(dirname=log_path,\n                                     filename_prefix=\"best\",\n                                     n_saved=3,\n                                     score_name=\"test_acc\",\n                                     score_function=default_score_fn)\nevaluator.add_event_handler(Events.COMPLETED, best_model_handler, {'model': model, })\n\n# Add early stopping\nes_patience = 10\nes_handler = EarlyStopping(patience=es_patience, score_function=default_score_fn, trainer=trainer)\nevaluator.add_event_handler(Events.COMPLETED, es_handler)\nsetup_logger(es_handler._logger)\n\n# Clear cuda cache between training\/testing\ndef empty_cuda_cache(engine):\n    torch.cuda.empty_cache()\n    import gc\n    gc.collect()\n\ntrainer.add_event_handler(Events.EPOCH_COMPLETED, empty_cuda_cache)\nevaluator.add_event_handler(Events.COMPLETED, empty_cuda_cache)\ntrain_evaluator.add_event_handler(Events.COMPLETED, empty_cuda_cache)","ce6ca496":"num_epochs = 50\n\ntrainer.run(train_loader, max_epochs=num_epochs)","33df4008":"evaluator.state.metrics","79097d73":"train_evaluator.state.metrics","8d629c9c":"# Find the last checkpoint\n!ls {log_path}\ncheckpoints = next(os.walk(log_path))[2]\ncheckpoints = sorted(filter(lambda f: f.endswith(\".pth\"), checkpoints))\nscores = [c[22:28] for c in checkpoints]\nbest_epoch = np.argmax(scores)\nprint(best_epoch, scores)\nif not checkpoints:\n    print('No weight files in {}'.format(log_path))\nelse:\n    model_path = f'efficientNet_cifar10_{scores[best_epoch]}.pth'\n    !cp {os.path.join(log_path, checkpoints[best_epoch])} {model_path}\n\n    \nprint(model_path)\n!rm {log_path}\/*","8258271c":"best_model = EfficientNet()\nbest_model.load_state_dict(torch.load(model_path))","fd6e33a3":"metrics = {\n    'Accuracy': Accuracy(),\n    'Precision': Precision(average=True),\n    'Recall': Recall(average=True),\n}\n\nall_pred = np.empty((0, 10), float)","b41cb43d":"def inference_update_with_tta(engine, batch):\n    global all_pred\n    best_model.eval()\n    with torch.no_grad():\n        x, y = batch        \n        # Let's compute final prediction as a mean of predictions on x and flipped x\n        y_pred1 = best_model(x)\n        y_pred2 = best_model(x.flip(dims=(-1, )))\n        y_pred = 0.5 * (y_pred1 + y_pred2)\n        # calc softmax for submission\n        curr_pred = (0.5 * (F.softmax(y_pred1, dim=-1) + F.softmax(y_pred1, dim=-1))).data.cpu().numpy()\n        all_pred = np.vstack([all_pred, curr_pred])\n\n        return y_pred, y\n\ninferencer = Engine(inference_update_with_tta)","b1c7fc20":"for name, metric in metrics.items():\n    metric.attach(inferencer, name)","684613e3":"ProgressBar(desc=\"Inference\").attach(inferencer)","ca97f438":"result_state = inferencer.run(test_loader, max_epochs=1)","3c0334a7":"result_state.metrics","7fb67296":"# Plot some training images\nbatch = next(iter(test_loader))\n\nplt.figure(figsize=(16, 8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\n_ = plt.imshow( \n    vutils.make_grid(batch[0][:16], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0))\n)","e6e4f7ee":"# Classify\nbest_model.eval()\nwith torch.no_grad():\n    y_pred = best_model(batch[0][:1])\n\n# Print predictions\nprint('-----')\nfor idx in torch.topk(y_pred, k=9)[1].squeeze(0).tolist():\n    prob = torch.softmax(y_pred, dim=1)[0, idx].item()\n    print('{label:<75} ({p:.2f}%)'.format(label=c10classes[idx], p=prob*100))","72534e54":"print(all_pred.shape)\nimport pandas as pd\nsub = pd.DataFrame(all_pred, columns=c10classes)\nsub.to_csv('efficientNetB0.csv', index_label='id')\nsub.head()","fa8a974e":"# clean up folders\n!rm -rf cifar* apex \/tmp\/*\n!ls *","d64ebec9":"Finally, we obtain similar scores:","ed37c275":"Let's setup learning rate scheduling:","e7a0eb3f":"And finally, we can implement generic `EfficientNet`:","54d41eb4":"Now let's define `SqueezeExcitation` module","9129c71c":"We will finetune the model on GPU with AMP fp32\/fp16 using nvidia\/apex package.","9f9270d2":"Let's compare the number of parameters with some of ResNets:","068569e0":"Obviously, our training settings is not the optimal one and the delta between our result and the paper's one is about 5%.","f74f548c":"## Finetunning model","caf9cb76":"### Load pretrained weights\n\nLet's load pretrained weights and check the model on a single image.","a38f5a69":"All EfficientNet models can be defined using the following parametrization:\n```\n# (width_coefficient, depth_coefficient, resolution, dropout_rate)\n'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n```    \nLet's define and train the third one: `EfficientNet-B0`","433e12a6":"## Dataflow\n\nLet's setup the dataflow:\n- load CIFAR10 train and test datasets\n- setup train\/test image transforms\n- setup train\/test data loaders\n\nAccording to the paper authors borrowed training settings from other publications and the dataflow for CIFAR10 is the following:\n\n- input images to the network during training are resized to 224x224\n- horizontally flipped randomly and augmented using cutout.\n- each mini-batch contained 256 examples\n","cb33b64c":"Next, we can define `MBConv`.\n\n**Note on implementation**: in Tensorflow (and PyTorch ports) convolutions use `SAME` padding option which in PyTorch requires\na specific padding computation and additional operation to apply. We will use built-in padding argument of the convolution.","349d6064":"- Training subset:","32e1d074":"## Model\n\n\nLet's define some helpful modules:\n- Flatten \n- Swish \n\nThe reason why Swish is not implemented in `torch.nn` can be found [here](https:\/\/github.com\/pytorch\/pytorch\/pull\/3182).\n","939ac789":"Let's create two evaluators to compute metrics on train\/test images and log them to Tensorboard:","0c83671a":"## Inference\n\nLet's load the best model and recompute evaluation metrics on test dataset with a very basic Test-Time-Augmentation to boost the performances.\n","c5b08b28":"Let's setup cross-entropy as criterion and SGD as optimizer.\n\nWe will split model parameters into 2 groups: \n\n    1) feature extractor (pretrained weights)\n    2) classifier (random weights)\n\nand define different learning rates for these groups (via learning rate scheduler).","4a43c259":"Let's check `update_fn`","a01da839":"Now let's setup the best model checkpointing, early stopping:","f9cd3005":"### Model's graph with Tensorboard\n\nWe can optionally inspect model's graph with the code below. For that we need to install\n`tensorboardX` package.\nOtherwise go directly to the next section.","2cc38083":"Let's visualize Swish transform vs ReLU:","76aab37c":"Number of parameters:","daa5996d":"Next, let's define a single iteration function `update_fn`. This function is then used by `ignite.engine.Engine` to update model while running over the input data.","e72cd879":"As we are interested to finetune the model to CIFAR-10, we will replace the classification fully-connected layer (ImageNet-1000 vs CIFAR-10).","f953dc7c":"Finetunning results:\n\n- Test dataset:","63e5057f":"# Finetuning of ImageNet pretrained EfficientNet-B0 on CIFAR-10 with PyTorch Ignite\n\nThis kernel is based on the official [PyTorch Ignite examples](https:\/\/github.com\/pytorch\/ignite\/tree\/master\/examples\/notebooks).\n\nRecently new ConvNets architectures have been proposed in [\"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\"](https:\/\/arxiv.org\/pdf\/1905.11946.pdf) paper. According to the paper, model's compound scaling starting from a 'good' baseline provides an network that achieves  state-of-the-art on  ImageNet,  while  being 8.4x  smaller and 6.1x faster on inference than the best existing ConvNet.\n\n![efficientnets](https:\/\/raw.githubusercontent.com\/pytorch\/ignite\/c22609796031f5831f054036895696c7e4df07ce\/examples\/notebooks\/assets\/efficientnets.png)\n\nFollowing the paper, EfficientNet-B0 model pretrained on ImageNet and finetuned on CIFAR10 dataset gives 98% test accuracy. Let's reproduce this result with Ignite. [Official implementation](https:\/\/github.com\/tensorflow\/tpu\/tree\/master\/models\/official\/efficientnet) of EfficientNet uses Tensorflow, \nfor our case we will borrow the code from [katsura-jp\/efficientnet-pytorch](https:\/\/github.com\/katsura-jp\/efficientnet-pytorch), \n[rwightman\/pytorch-image-models](https:\/\/github.com\/rwightman\/pytorch-image-models) and [lukemelas\/EfficientNet-PyTorch](https:\/\/github.com\/lukemelas\/EfficientNet-PyTorch\/) repositories (kudos to authors!). We will download pretrained weights from [lukemelas\/EfficientNet-PyTorch](https:\/\/github.com\/lukemelas\/EfficientNet-PyTorch\/) repository.\n\n## Network architecture review\nThe architecture of EfficientNet-B0 is the following:\n```\n1 - Stem    - Conv3x3|BN|Swish\n\n2 - Blocks  - MBConv1, k3x3 \n            - MBConv6, k3x3 repeated 2 times\n            - MBConv6, k5x5 repeated 2 times\n            - MBConv6, k3x3 repeated 3 times\n            - MBConv6, k5x5 repeated 3 times\n            - MBConv6, k5x5 repeated 4 times\n            - MBConv6, k3x3\n                            totally 16 blocks\n\n3 - Head    - Conv1x1|BN|Swish \n            - Pooling\n            - Dropout\n            - FC\n```\n\nwhere \n```\nSwish(x) = x * sigmoid(x)\n```\nand `MBConvX` stands for mobile inverted bottleneck convolution, X - denotes expansion ratio:\n``` \nMBConv1 : \n  -> DepthwiseConv|BN|Swish -> SqueezeExcitation -> Conv|BN\n\nMBConv6 : \n  -> Conv|BN|Swish -> DepthwiseConv|BN|Swish -> SqueezeExcitation -> Conv|BN\n\nMBConv6+IdentitySkip : \n  -.-> Conv|BN|Swish -> DepthwiseConv|BN|Swish -> SqueezeExcitation -> Conv|BN-(+)->\n   \\___________________________________________________________________________\/\n```","46047af4":"Now let's define a trainer and add some practical handlers:\n- log to tensorboard: losses, metrics, lr\n- progress bar\n- models\/optimizers checkpointing"}}