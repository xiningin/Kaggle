{"cell_type":{"84b18e55":"code","e6945ea0":"code","dd1565f3":"code","aceda90e":"code","8e19a166":"code","8057fadb":"code","25af2b7c":"code","4fbcc8e5":"code","8e7e85da":"code","873fc9d0":"code","144dda79":"code","2a2081d6":"code","ef9d4d10":"code","e87e425a":"code","bd50fa35":"code","d49a9279":"code","be10a32a":"code","1d6a99b1":"code","a3e11474":"code","f3356d53":"code","feadcf95":"code","f6888b2f":"code","b83e95c5":"code","802dce59":"code","ec94b494":"code","d8a9958c":"code","2e597ca4":"code","b5d69da2":"code","2827982a":"code","d2512cf0":"code","740ec426":"code","a785557f":"code","cc673845":"code","fc00c310":"code","0d4bd880":"code","8ceadaab":"code","b3b9c806":"code","0ca318ce":"code","1609bdb9":"code","ccce2c6f":"code","c71f0306":"code","2350503b":"code","9d75be3b":"code","4182e49c":"code","fac8d10f":"code","8442b377":"code","f78c7b80":"code","1a8a272f":"code","49e75820":"code","8be21273":"code","a14ce500":"code","e605bcd1":"code","572e1214":"code","0acf995c":"code","69c51746":"code","53457f4b":"code","62d2c841":"code","aa602398":"code","2683f8f8":"code","d4cd2561":"code","6f2cb75d":"code","43d776d9":"markdown","112b17ff":"markdown","b1afb60e":"markdown","8fefaa52":"markdown","2fd04019":"markdown","f73f3c40":"markdown","8eaef325":"markdown","5441d3ec":"markdown","b775703d":"markdown","c441ed48":"markdown","57fab225":"markdown","4816d8a9":"markdown"},"source":{"84b18e55":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\n# Filter out warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# To style plots\nplt.style.use('fivethirtyeight')\n\nfrom itertools import cycle\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e6945ea0":"# Import Dataset\nX_sample = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nX_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nX_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","dd1565f3":"# X_sample\nX_train.head()\n# X_train.shape\n# (1460, 81)","aceda90e":"# Configuring plot dimension\nplt.figure(figsize=(15, 5))\n\n# Plotting and labelling\nplt.plot(X_train.SalePrice, linewidth=1, color=next(color_cycle))\nplt.title('Distribution for Sale Prices')\nplt.ylabel('Sale Prices')","8e19a166":"plt.figure(figsize=(15,5))\nplt.plot(X_train.SalePrice.sort_values().reset_index(drop=True), color=next(color_cycle))\nplt.title('Distribution for Sorted Sale Prices')\nplt.ylabel('Sale Price')","8057fadb":"# Visualize locations of null values using the heatmap trick\nsns.heatmap(X_train.isnull(), yticklabels=False, cmap='plasma')","25af2b7c":"# Check out number of null values in the training set\nX_train.isnull().sum().sort_values(ascending=False)[0:19]","4fbcc8e5":"# Check out number of null values in the testing set\nX_test.isnull().sum().sort_values(ascending=False)[0:33]","8e7e85da":"X_train.LotFrontage.head()","873fc9d0":"# Number of missing values in training set\nX_train.LotFrontage.isnull().sum()","144dda79":"# Number of missing values in testing set\nX_test.LotFrontage.isnull().sum()","2a2081d6":"# Filling null values with mean\nX_train['LotFrontage'] = X_train['LotFrontage'].fillna(X_train.LotFrontage.mean())\nX_test['LotFrontage'] = X_test['LotFrontage'].fillna(X_test.LotFrontage.mean())","ef9d4d10":"X_train.Alley.value_counts(dropna=False)","e87e425a":"X_test.Alley.value_counts(dropna=False)","bd50fa35":"# Dropping columns\nif 'Alley' in X_train:\n    X_train.drop(columns=['Alley'], inplace=True)\n\nif 'Alley' in X_test:\n    X_test.drop(columns=['Alley'], inplace=True)","d49a9279":"# Performing same actions for other columns\ncol_replace = ['BsmtCond', 'BsmtQual', 'FireplaceQu', 'GarageType', \n               'GarageCond', 'GarageFinish', 'GarageQual', 'MasVnrType', \n               'MasVnrArea', 'BsmtExposure', 'BsmtFinType2']\ncol_drop = ['PoolQC', 'Fence', 'MiscFeature', 'GarageYrBlt']\n\nfor col in col_replace:\n    X_train[col] = X_train[col].fillna(X_train[col].mode()[0])\n    X_test[col] = X_test[col].fillna(X_test[col].mode()[0])\n    \nfor col in col_drop:\n    if col in X_train:\n        X_train.drop(columns=col, inplace=True)\n    if col in X_test:\n        X_test.drop(columns=col, inplace=True)","be10a32a":"X_train.isnull().sum().sort_values(ascending=False)","1d6a99b1":"# Handling remaining null values\nX_train.dropna(inplace=True)\n\nif 'Id' in X_train:\n    X_train.drop(columns=['Id'], inplace=True)","a3e11474":"X_train.shape","f3356d53":"X_test.isnull().sum().sort_values(ascending=False)[0:17]","feadcf95":"X_test['MSZoning'] = X_test['MSZoning'].fillna(X_test['MSZoning'].mode()[0])","f6888b2f":"columns_1 = ['BsmtFinType1', 'Utilities','BsmtFullBath', 'BsmtHalfBath', 'Functional', 'SaleType', 'Exterior2nd', \n           'Exterior1st', 'KitchenQual']\ncolumns_2 = ['GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',  'TotalBsmtSF', 'GarageArea']\n\nfor col in columns_1:\n    X_test[col] = X_test[col].fillna(X_test[col].mode()[0])\nfor col in columns_2:\n    X_test[col] = X_test[col].fillna(X_test[col].mean())","b83e95c5":"if 'Id' in X_test:\n    X_test.drop(columns=['Id'], inplace=True)","802dce59":"X_test.shape","ec94b494":"X_train.isnull().any().any()","d8a9958c":"X_test.isnull().any().any()","2e597ca4":"mszoning_dist = px.scatter(X_train, x=X_train.index, y='SalePrice', labels={'x': 'Index'}, \n                           color=X_train.MSZoning, template=\"seaborn\", \n                           title=\"Sale Price Distribution based on MSZoning\")\nmszoning_dist.show()","b5d69da2":"street_dist = px.scatter(X_train, x=X_train.index, y='SalePrice', labels={'x': 'Index'}, \n                           color=X_train.Street, template=\"seaborn\", \n                           title=\"Sale Price Distribution based on Street\")\nstreet_dist.show()","2827982a":"X_train.LotConfig.unique()","d2512cf0":"# Configuring plot size for compact view\nplt.figure(figsize=(20, 10))\n\n# Plots with respect to each value of LotConfig\nplt.subplot(2, 3, 1)\nplt.scatter(x=X_train[X_train.LotConfig == 'Inside'].index,\n           y=X_train[X_train.LotConfig == 'Inside'].SalePrice,\n            color=next(color_cycle))\nplt.title('Sale Price Distribution based on Inside Value')\n\nplt.subplot(2, 3, 2)\nplt.scatter(x=X_train[X_train.LotConfig == 'FR2'].index,\n           y=X_train[X_train.LotConfig == 'FR2'].SalePrice,\n            color=next(color_cycle))\nplt.title('Sale Price Distribution based on FR2 Value')\n\nplt.subplot(2, 3, 3)\nplt.scatter(x=X_train[X_train.LotConfig == 'Corner'].index,\n           y=X_train[X_train.LotConfig == 'Corner'].SalePrice,\n            color=next(color_cycle))\nplt.title('Sale Price Distribution based on Corner Value')\n\nplt.subplot(2, 3, 4)\nplt.scatter(x=X_train[X_train.LotConfig == 'CulDSac'].index,\n           y=X_train[X_train.LotConfig == 'CulDSac'].SalePrice,\n            color=next(color_cycle))\nplt.title('Sale Price Distribution based on CulDSac Value')\n\nplt.subplot(2, 3, 5)\nplt.scatter(x=X_train[X_train.LotConfig == 'FR3'].index,\n           y=X_train[X_train.LotConfig == 'FR3'].SalePrice,\n            color=next(color_cycle))\nplt.title('Sale Price Distribution based on FR3 Value')\n","740ec426":"cols = ['MSZoning', 'Street',\n       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', \n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n       'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',\n       'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']","a785557f":"len(cols)","cc673845":"# Clean dataframe\nfinal_df = pd.concat([X_train, X_test], axis=0)","fc00c310":"final_df.shape","0d4bd880":"def HotEncoding(cols):\n    df = final_df\n    i = 0\n    for col in cols:\n        dummy = pd.get_dummies(final_df[col], drop_first=True)\n        final_df.drop([col], axis=1, inplace=True)\n        \n        if i >= 1:\n            df = pd.concat([df, dummy], axis=1)\n        else:\n            df = dummy.copy()\n        \n        i += 1\n    \n    df = pd.concat([final_df, df], axis=1)\n    \n    return df","8ceadaab":"final_df = HotEncoding(cols)","b3b9c806":"final_df.shape","0ca318ce":"final_df = final_df.loc[:, ~final_df.columns.duplicated()]","1609bdb9":"final_df.shape","ccce2c6f":"# Splitting data as the original one\ndf_train = final_df.iloc[:1422, :]\ndf_test = final_df.iloc[1422:, :]","c71f0306":"df_test.drop(['SalePrice'], axis=1, inplace=True)","2350503b":"X_train_final = df_train.drop(['SalePrice'], axis=1)\ny_train_final = df_train['SalePrice']","9d75be3b":"# Importing required libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","4182e49c":"X_std = StandardScaler().fit_transform(X_train_final)\n\nmy_columns = X_train_final.columns\nnew_df = pd.DataFrame(X_std, columns=my_columns)","fac8d10f":"pca = PCA(n_components=2)\ndf_pca = pca.fit_transform(new_df)","8442b377":"# Plotting\nplt.figure(figsize = (10, 8))\nplt.scatter(df_pca[:, 0], df_pca[:, 1], c=y_train_final, cmap='plasma')\n\n# Labeling\nplt.xlabel('First Principle Component')\nplt.ylabel('Second Principle Component')","f78c7b80":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX_train_linear, X_test_linear, y_train_linear, y_test_linear = train_test_split(X_train_final, y_train_final)","1a8a272f":"# Fitting the Linear Regression model\nlinreg = LinearRegression()\nlinreg.fit(X_train_linear, y_train_linear)","49e75820":"# Checking model accuracy\nprint(\"R_Squared Value for Training Set: {}\".format(linreg.score(X_train_linear, y_train_linear)))\nprint(\"R_Squared Value for Testing Set: {}\".format(linreg.score(X_test_linear, y_test_linear)))","8be21273":"from sklearn.model_selection import RandomizedSearchCV\nimport xgboost","a14ce500":"xgb = xgboost.XGBRegressor()","e605bcd1":"# Hyperparameter tuning\nn_estimators = [100, 500, 900, 1100, 1500, 2000]\nmax_depth = [2, 3, 5, 10, 15]\nbooster = ['gbtree', 'gblinear']\nlearning_rate = [0.05, 0.1, 0.15, 0.20]\nmin_child_weight = [1, 2, 3, 4]\nbase_score = [0.25, 0.5, 0.75, 1]\n\n# Define the grid of hyperparamers for searching purposes\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth': max_depth,\n    'booster': booster,\n    'learning_rate': learning_rate,\n    'min_child_weight': min_child_weight,\n    'base_score': base_score,\n}\n\nrandom_cv = RandomizedSearchCV(estimator=xgb, param_distributions=hyperparameter_grid,\n                              cv=5, n_iter=50,\n                              scoring='neg_mean_absolute_error', n_jobs=4,\n                              verbose=5, return_train_score=True,\n                              random_state=42)","572e1214":"# Fitting randomcv model\nrandom_cv.fit(X_train_final, y_train_final)","0acf995c":"# Finding best estimator\nrandom_cv.best_estimator_","69c51746":"# Initialize model using best estimators\nxgb = xgboost.XGBRegressor(base_score=0.75, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=3,\n             min_child_weight=1, missing=None, monotone_constraints='()',\n             n_estimators=900, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)","53457f4b":"# Fitting model\nxgb.fit(X_train_final, y_train_final)","62d2c841":"y_pred = xgb.predict(df_test)","aa602398":"y_pred","2683f8f8":"# Finalize data to submit\npred = pd.DataFrame(y_pred)\nsamp = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsubmission = pd.concat([samp['Id'], pred], axis=1)\nsubmission.columns = ['Id', 'SalePrice']","d4cd2561":"submission","6f2cb75d":"# Submitting\nsubmission.to_csv('submission-1.csv', index=False)","43d776d9":"# Hyperparameter Tuning and XGBoost Classifier\n\n* We build a extreme gradient boost regression model","112b17ff":"## Handling Null Values","b1afb60e":"**Handling Missing Values by Column**","8fefaa52":"# Linear Regression","2fd04019":"## Feature Engineering by HotCoding","f73f3c40":"Note: neither of `Street` and `MSZoning` presents a strong correlation to Sales Price. Let's move on and discover the correlations with respect to other columns.","8eaef325":"## Plotting distribution for sale prices","5441d3ec":"At this moment, our dataset is ready.\n\n---\n\n# Exploratory Data Analysis","b775703d":"**Check if null values exist**","c441ed48":"**The plot illustrates the distribution of sale price, ordered by id. \nWe sort the values based on sale prices, and make another plot.**","57fab225":"## Principle Component Analysis\n\nWe implement PCA and visualize the data set.","4816d8a9":"# Predicting House Prices using XGBoost Classifier"}}