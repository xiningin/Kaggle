{"cell_type":{"1870b3e5":"code","c55ddbde":"code","80efcc49":"code","e0290590":"code","84e95904":"code","4e06c3eb":"code","b4b58693":"code","366e5d05":"code","96847dd8":"code","a7f4cbaa":"code","401b4f42":"code","c51d50eb":"code","cb353260":"code","3db8165c":"code","6604b4ba":"code","fbaf8893":"code","f8478f6f":"code","b0c82781":"code","36d56906":"code","769a1593":"code","31a329fd":"code","25c2bff5":"code","a6298d3a":"code","6e2379a7":"code","25c8e721":"code","da76d752":"code","f95fc590":"code","3c6d1516":"code","6d4df209":"code","553633df":"code","5cf3cb47":"code","772e3cd4":"code","8858df00":"code","41b9a4f8":"code","36274676":"code","024ecb94":"code","358b5566":"code","b1b5f1c6":"code","cf1cd9ad":"code","2b9cc8aa":"code","1227fe6a":"code","772a44dc":"code","01ad7fe2":"code","72ca2868":"code","cfc274d5":"code","76428656":"code","d71c83af":"code","5c8c8108":"code","33a3bef4":"code","33246295":"code","4f2a946e":"code","a82233b6":"code","e65153b0":"code","6ae565b0":"code","5182c62d":"markdown","36c9472f":"markdown","baf4b917":"markdown","88bb15c1":"markdown","1edfadd5":"markdown","9ec277a2":"markdown","1c947fe9":"markdown","82e0bc4b":"markdown","903ed855":"markdown","3c82aa26":"markdown","b18827a6":"markdown","cf792736":"markdown","c9186213":"markdown","af31d9fa":"markdown","a2fca1f0":"markdown","35912c5f":"markdown","5aae1f8d":"markdown"},"source":{"1870b3e5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport os, gc, pickle, copy, datetime, warnings\nimport pycountry\n\npd.set_option('max_columns', 500)\npd.set_option('max_rows', 500)\npd.options.display.float_format = '{:.2f}'.format","c55ddbde":"!ls -l ..\/input\/covid19-global-forecasting-week-2\/","80efcc49":"# Read in data\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/train.csv\")\ntest = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/test.csv\")\n\ntt = pd.concat([train, test], sort=False)\ntt = train.merge(test, on=['Province_State','Country_Region','Date'], how='outer')\n\n# concat Country\/Region and Province\/State\ndef name_place(x):\n    try:\n        x_new = x['Country_Region'] + \"_\" + x['Province_State']\n    except:\n        x_new = x['Country_Region']\n    return x_new\ntt['Place'] = tt.apply(lambda x: name_place(x), axis=1)\n# tt = tt.drop(['Province_State','Country_Region'], axis=1)\ntt['Date'] = pd.to_datetime(tt['Date'])\ntt['doy'] = tt['Date'].dt.dayofyear\ntt['dow'] = tt['Date'].dt.dayofweek\ntt['hasProvidence'] = ~tt['Province_State'].isna()\n\n\ncountry_meta = pd.read_csv('..\/input\/covid19-forecasting-metadata\/region_metadata.csv')\ntt = tt.merge(country_meta, how='left')\n\ncountry_date_meta = pd.read_csv('..\/input\/covid19-forecasting-metadata\/region_date_metadata.csv')\n#tt = tt.merge(country_meta, how='left')\n\ntt['HasFatality'] = tt.groupby('Place')['Fatalities'].transform(lambda x: x.max() > 0)\ntt['HasCases'] = tt.groupby('Place')['ConfirmedCases'].transform(lambda x: x.max() > 0)\n\nfirst_case_date = tt.query('ConfirmedCases >= 1').groupby('Place')['Date'].min().to_dict()\nten_case_date = tt.query('ConfirmedCases >= 10').groupby('Place')['Date'].min().to_dict()\nhundred_case_date = tt.query('ConfirmedCases >= 100').groupby('Place')['Date'].min().to_dict()\nfirst_fatal_date = tt.query('Fatalities >= 1').groupby('Place')['Date'].min().to_dict()\nten_fatal_date = tt.query('Fatalities >= 10').groupby('Place')['Date'].min().to_dict()\nhundred_fatal_date = tt.query('Fatalities >= 100').groupby('Place')['Date'].min().to_dict()\n\ntt['First_Case_Date'] = tt['Place'].map(first_case_date)\ntt['Ten_Case_Date'] = tt['Place'].map(ten_case_date)\ntt['Hundred_Case_Date'] = tt['Place'].map(hundred_case_date)\ntt['First_Fatal_Date'] = tt['Place'].map(first_fatal_date)\ntt['Ten_Fatal_Date'] = tt['Place'].map(ten_fatal_date)\ntt['Hundred_Fatal_Date'] = tt['Place'].map(hundred_fatal_date)\n\ntt['Days_Since_First_Case'] = (tt['Date'] - tt['First_Case_Date']).dt.days\ntt['Days_Since_Ten_Cases'] = (tt['Date'] - tt['Ten_Case_Date']).dt.days\ntt['Days_Since_Hundred_Cases'] = (tt['Date'] - tt['Hundred_Case_Date']).dt.days\ntt['Days_Since_First_Fatal'] = (tt['Date'] - tt['First_Fatal_Date']).dt.days\ntt['Days_Since_Ten_Fatal'] = (tt['Date'] - tt['Ten_Fatal_Date']).dt.days\ntt['Days_Since_Hundred_Fatal'] = (tt['Date'] - tt['Hundred_Fatal_Date']).dt.days\n\n# Merge smoking data\nsmoking = pd.read_csv(\"..\/input\/smokingstats\/share-of-adults-who-smoke.csv\")\nsmoking = smoking.rename(columns={'Smoking prevalence, total (ages 15+) (% of adults)': 'Smoking_Rate'})\nsmoking_dict = smoking.groupby('Entity')['Year'].max().to_dict()\nsmoking['LastYear'] = smoking['Entity'].map(smoking_dict)\nsmoking = smoking.query('Year == LastYear').reset_index()\nsmoking['Entity'] = smoking['Entity'].str.replace('United States', 'US')\n\ntt = tt.merge(smoking[['Entity','Smoking_Rate']],\n         left_on='Country_Region',\n         right_on='Entity',\n         how='left',\n         validate='m:1') \\\n    .drop('Entity', axis=1)\n\n# Country data\ncountry_info = pd.read_csv('..\/input\/countryinfo\/covid19countryinfo.csv')\n\n\ntt = tt.merge(country_info, left_on=['Country_Region','Province_State'],\n              right_on=['country','region'],\n              how='left',\n              validate='m:1')\n\n# State info from wikipedia\nus_state_info = pd.read_html('https:\/\/simple.wikipedia.org\/wiki\/List_of_U.S._states_by_population')[0] \\\n    [['State','Population estimate, July 1, 2019[2]']] \\\n    .rename(columns={'Population estimate, July 1, 2019[2]' : 'Population'})\n#us_state_info['2019 population'] = pd.to_numeric(us_state_info['2019 population'].str.replace('[note 1]','').replace('[]',''))\n\ntt = tt.merge(us_state_info[['State','Population']],\n         left_on='Province_State',\n         right_on='State',\n         how='left')\n\ntt['pop'] = pd.to_numeric(tt['pop'].str.replace(',',''))\ntt['pop'] = tt['pop'].fillna(tt['Population'])\ntt['pop'] = pd.to_numeric(tt['pop'])\n\ntt['pop_diff'] = tt['pop'] - tt['Population']\ntt['Population_final'] = tt['Population']\ntt.loc[~tt['hasProvidence'], 'Population_final'] = tt.loc[~tt['hasProvidence']]['pop']\n\ntt['Confirmed_Cases_Diff'] = tt.groupby('Place')['ConfirmedCases'].diff()\ntt['Fatailities_Diff'] = tt.groupby('Place')['Fatalities'].diff()\nmax_date = tt.dropna(subset=['ConfirmedCases'])['Date'].max()\ntt['gdp2019'] = pd.to_numeric(tt['gdp2019'].str.replace(',',''))","e0290590":"# Correcting population for missing countries\n# Googled their names and copied the numbers here\npop_dict = {'Angola': int(29.78 * 10**6),\n            'Australia_Australian Capital Territory': 423_800,\n            'Australia_New South Wales': int(7.544 * 10**6),\n            'Australia_Northern Territory': 244_300,\n            'Australia_Queensland' : int(5.071 * 10**6),\n            'Australia_South Australia' : int(1.677 * 10**6),\n            'Australia_Tasmania': 515_000,\n            'Australia_Victoria': int(6.359 * 10**6),\n            'Australia_Western Australia': int(2.589 * 10**6),\n            'Brazil': int(209.3 * 10**6),\n            'Canada_Alberta' : int(4.371 * 10**6),\n            'Canada_British Columbia' : int(5.071 * 10**6),\n            'Canada_Manitoba' : int(1.369 * 10**6),\n            'Canada_New Brunswick' : 776_827,\n            'Canada_Newfoundland and Labrador' : 521_542,\n            'Canada_Nova Scotia' : 971_395,\n            'Canada_Ontario' : int(14.57 * 10**6),\n            'Canada_Prince Edward Island' : 156_947,\n            'Canada_Quebec' : int(8.485 * 10**6),\n            'Canada_Saskatchewan': int(1.174 * 10**6),\n            'China_Anhui': int(62 * 10**6),\n            'China_Beijing': int(21.54 * 10**6),\n            'China_Chongqing': int(30.48 * 10**6),\n            'China_Fujian' :  int(38.56 * 10**6),\n            'China_Gansu' : int(25.58 * 10**6),\n            'China_Guangdong' : int(113.46 * 10**6),\n            'China_Guangxi' : int(48.38 * 10**6),\n            'China_Guizhou' : int(34.75 * 10**6),\n            'China_Hainan' : int(9.258 * 10**6),\n            'China_Hebei' : int(74.7 * 10**6),\n            'China_Heilongjiang' : int(38.31 * 10**6),\n            'China_Henan' : int(94 * 10**6),\n            'China_Hong Kong' : int(7.392 * 10**6),\n            'China_Hubei' : int(58.5 * 10**6),\n            'China_Hunan' : int(67.37 * 10**6),\n            'China_Inner Mongolia' :  int(24.71 * 10**6),\n            'China_Jiangsu' : int(80.4 * 10**6),\n            'China_Jiangxi' : int(45.2 * 10**6),\n            'China_Jilin' : int(27.3 * 10**6),\n            'China_Liaoning' : int(43.9 * 10**6),\n            'China_Macau' : 622_567,\n            'China_Ningxia' : int(6.301 * 10**6),\n            'China_Qinghai' : int(5.627 * 10**6),\n            'China_Shaanxi' : int(37.33 * 10**6),\n            'China_Shandong' : int(92.48 * 10**6),\n            'China_Shanghai' : int(24.28 * 10**6),\n            'China_Shanxi' : int(36.5 * 10**6),\n            'China_Sichuan' : int(81.1 * 10**6),\n            'China_Tianjin' : int(15 * 10**6),\n            'China_Tibet' : int(3.18 * 10**6),\n            'China_Xinjiang' : int(21.81 * 10**6),\n            'China_Yunnan' : int(45.97 * 10**6),\n            'China_Zhejiang' : int(57.37 * 10**6),\n            'Denmark_Faroe Islands' : 51_783,\n            'Denmark_Greenland' : 56_171,\n            'France_French Guiana' : 290_691,\n            'France_French Polynesia' : 283_007,\n            'France_Guadeloupe' : 395_700,\n            'France_Martinique' : 376_480,\n            'France_Mayotte' : 270_372,\n            'France_New Caledonia' : 99_926,\n            'France_Reunion' : 859_959,\n            'France_Saint Barthelemy' : 9_131,\n            'France_St Martin' : 32_125,\n            'Netherlands_Aruba' : 105_264,\n            'Netherlands_Curacao' : 161_014,\n            'Netherlands_Sint Maarten' : 41_109,\n            'Papua New Guinea' : int(8.251 * 10**6),\n            'US_Guam' : 164_229,\n            'US_Virgin Islands' : 107_268,\n            'United Kingdom_Bermuda' : 65_441,\n            'United Kingdom_Cayman Islands' : 61_559,\n            'United Kingdom_Channel Islands' : 170_499,\n            'United Kingdom_Gibraltar' : 34_571,\n            'United Kingdom_Isle of Man' : 84_287,\n            'United Kingdom_Montserrat' : 4_922\n           }\n\ntt['Population_final'] = tt['Population_final'].fillna(tt['Place'].map(pop_dict))","84e95904":"tt.loc[tt['Place'] == 'Diamond Princess', 'Population final'] = 2_670","4e06c3eb":"tt['ConfirmedCases_Log'] = tt['ConfirmedCases'].apply(np.log1p)\ntt['Fatalities_Log'] = tt['Fatalities'].apply(np.log1p)","b4b58693":"tt['Population_final'] = tt['Population_final'].astype('int')\ntt['Cases_Per_100kPop'] = (tt['ConfirmedCases'] \/ tt['Population_final']) * 100000\ntt['Fatalities_Per_100kPop'] = (tt['Fatalities'] \/ tt['Population_final']) * 100000\n\ntt['Cases_Percent_Pop'] = ((tt['ConfirmedCases'] \/ tt['Population_final']) * 100)\ntt['Fatalities_Percent_Pop'] = ((tt['Fatalities'] \/ tt['Population_final']) * 100)\n\ntt['Cases_Log_Percent_Pop'] = ((tt['ConfirmedCases'] \/ tt['Population_final']) * 100).apply(np.log1p)\ntt['Fatalities_Log_Percent_Pop'] = ((tt['Fatalities'] \/ tt['Population_final']) * 100).apply(np.log1p)\n\n\ntt['Max_Confirmed_Cases'] = tt.groupby('Place')['ConfirmedCases'].transform(max)\ntt['Max_Fatalities'] = tt.groupby('Place')['Fatalities'].transform(max)\n\ntt['Max_Cases_Per_100kPop'] = tt.groupby('Place')['Cases_Per_100kPop'].transform(max)\ntt['Max_Fatalities_Per_100kPop'] = tt.groupby('Place')['Fatalities_Per_100kPop'].transform(max)","366e5d05":"tt.query('Date == @max_date') \\\n    .query('Place != \"Diamond Princess\"') \\\n    .query('Cases_Log_Percent_Pop > -10000') \\\n    ['Cases_Log_Percent_Pop'].plot(kind='hist', bins=500)\nplt.show()","96847dd8":"tt.query('Days_Since_Ten_Cases > 0') \\\n    .query('Place != \"Diamond Princess\"') \\\n    .dropna(subset=['Cases_Percent_Pop']) \\\n    .query('Days_Since_Ten_Cases < 40') \\\n    .plot(x='Days_Since_Ten_Cases', y='Cases_Log_Percent_Pop', style='.', figsize=(15, 5), alpha=0.2)\nplt.show()","a7f4cbaa":"PLOT = False\nif PLOT:\n    for x in tt['Place'].unique():\n        try:\n            fig, ax = plt.subplots(1, 4, figsize=(15, 2))\n            tt.query('Place == @x') \\\n                .query('ConfirmedCases > 0') \\\n                .set_index('Date')['Cases_Log_Percent_Pop'] \\\n                .plot(title=f'{x} confirmed log pct pop', ax=ax[0])\n            tt.query('Place == @x') \\\n                .query('ConfirmedCases > 0') \\\n                .set_index('Date')['Cases_Percent_Pop'] \\\n                .plot(title=f'{x} confirmed cases', ax=ax[1])\n            tt.query('Place == @x') \\\n                .query('Fatalities > 0') \\\n                .set_index('Date')['Fatalities_Log_Percent_Pop'] \\\n                .plot(title=f'{x} confirmed log pct pop', ax=ax[2])\n            tt.query('Place == @x') \\\n                .query('Fatalities > 0') \\\n                .set_index('Date')['Fatalities_Percent_Pop'] \\\n                .plot(title=f'{x} confirmed cases', ax=ax[3])\n        except:\n            pass\n        plt.show()","401b4f42":"tt.query('Date == @max_date')[['Place','Max_Cases_Per_100kPop',\n                               'Max_Fatalities_Per_100kPop','Max_Confirmed_Cases',\n                               'Population_final',\n                              'Days_Since_First_Case',\n                              'Confirmed_Cases_Diff']] \\\n    .drop_duplicates() \\\n    .sort_values('Max_Cases_Per_100kPop', ascending=False)","c51d50eb":"tt['Past_7Days_ConfirmedCases_Std'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200324').groupby('Place')['ConfirmedCases'].std().to_dict())\ntt['Past_7Days_Fatalities_Std'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200324').groupby('Place')['Fatalities'].std().to_dict())\n\ntt['Past_7Days_ConfirmedCases_Min'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200324').groupby('Place')['ConfirmedCases'].min().to_dict())\ntt['Past_7Days_Fatalities_Min'] = tt['Place'].map(tt.dropna(subset=['Fatalities']).query('Date >= 20200324').groupby('Place')['Fatalities'].min().to_dict())\n\ntt['Past_7Days_ConfirmedCases_Max'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200324').groupby('Place')['ConfirmedCases'].max().to_dict())\ntt['Past_7Days_Fatalities_Max'] = tt['Place'].map(tt.dropna(subset=['Fatalities']).query('Date >= 20200324').groupby('Place')['Fatalities'].max().to_dict())\n\ntt['Past_7Days_Confirmed_Change_of_Total'] = (tt['Past_7Days_ConfirmedCases_Max'] - tt['Past_7Days_ConfirmedCases_Min']) \/ (tt['Past_7Days_ConfirmedCases_Max'])\ntt['Past_7Days_Fatalities_Change_of_Total'] = (tt['Past_7Days_Fatalities_Max'] - tt['Past_7Days_Fatalities_Min']) \/ (tt['Past_7Days_Fatalities_Max'])","cb353260":"tt['Past_21Days_ConfirmedCases_Std'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200310').groupby('Place')['ConfirmedCases'].std().to_dict())\ntt['Past_21Days_Fatalities_Std'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200310').groupby('Place')['Fatalities'].std().to_dict())\n\ntt['Past_21Days_ConfirmedCases_Min'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200310').groupby('Place')['ConfirmedCases'].min().to_dict())\ntt['Past_21Days_Fatalities_Min'] = tt['Place'].map(tt.dropna(subset=['Fatalities']).query('Date >= 20200324').groupby('Place')['Fatalities'].min().to_dict())\n\ntt['Past_21Days_ConfirmedCases_Max'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200310').groupby('Place')['ConfirmedCases'].max().to_dict())\ntt['Past_21Days_Fatalities_Max'] = tt['Place'].map(tt.dropna(subset=['Fatalities']).query('Date >= 20200310').groupby('Place')['Fatalities'].max().to_dict())\n\ntt['Past_21Days_Confirmed_Change_of_Total'] = (tt['Past_21Days_ConfirmedCases_Max'] - tt['Past_21Days_ConfirmedCases_Min']) \/ (tt['Past_21Days_ConfirmedCases_Max'])\ntt['Past_21Days_Fatalities_Change_of_Total'] = (tt['Past_21Days_Fatalities_Max'] - tt['Past_21Days_Fatalities_Min']) \/ (tt['Past_21Days_Fatalities_Max'])\n\ntt['Past_7Days_Fatalities_Change_of_Total'] = tt['Past_7Days_Fatalities_Change_of_Total'].fillna(0)\ntt['Past_21Days_Fatalities_Change_of_Total'] = tt['Past_21Days_Fatalities_Change_of_Total'].fillna(0)","3db8165c":"tt['Date_7Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 7] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_14Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 14] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_21Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 21] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_28Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 28] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_35Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 35] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_60Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 60] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\n\ntt['Date_7Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 7] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_14Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 14] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_21Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 21] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_28Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 28] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_35Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 35] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_60Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 60] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\n\n\ntt['Date_7Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 7] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_14Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 14] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_21Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 21] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_28Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 28] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_35Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 35] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_60Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 60] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())","6604b4ba":"tt['CC_7D_1stCase'] = tt.loc[tt['Date_7Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_14D_1stCase'] = tt.loc[tt['Date_14Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_21D_1stCase'] = tt.loc[tt['Date_21Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_28D_1stCase'] = tt.loc[tt['Date_28Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_35D_1stCase'] = tt.loc[tt['Date_35Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_60D_1stCase'] = tt.loc[tt['Date_60Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\n\ntt['F_7D_1stCase'] = tt.loc[tt['Date_7Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_14D_1stCase'] = tt.loc[tt['Date_14Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_21D_1stCase'] = tt.loc[tt['Date_21Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_28D_1stCase'] = tt.loc[tt['Date_28Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_35D_1stCase'] = tt.loc[tt['Date_35Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_60D_1stCase'] = tt.loc[tt['Date_60Days_Since_First_Case'] == tt['Date']]['Fatalities']\n\ntt['CC_7D_10Case'] = tt.loc[tt['Date_7Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_14D_10Case'] = tt.loc[tt['Date_14Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_21D_10Case'] = tt.loc[tt['Date_21Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_28D_10Case'] = tt.loc[tt['Date_28Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_35D_10Case'] = tt.loc[tt['Date_35Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_60D_10Case'] = tt.loc[tt['Date_60Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\n\ntt['F_7D_10Case'] = tt.loc[tt['Date_7Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_14D_10Case'] = tt.loc[tt['Date_14Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_21D_10Case'] = tt.loc[tt['Date_21Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_28D_10Case'] = tt.loc[tt['Date_28Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_35D_10Case'] = tt.loc[tt['Date_35Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_60D_10Case'] = tt.loc[tt['Date_60Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\n\ntt['CC_7D_1Fatal'] = tt.loc[tt['Date_7Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_14D_1Fatal'] = tt.loc[tt['Date_14Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_21D_1Fatal'] = tt.loc[tt['Date_21Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_28D_1Fatal'] = tt.loc[tt['Date_28Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_35D_1Fatal'] = tt.loc[tt['Date_35Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_60D_1Fatal'] = tt.loc[tt['Date_60Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\n\ntt['F_7D_1Fatal'] = tt.loc[tt['Date_7Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_14D_1Fatal'] = tt.loc[tt['Date_14Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_21D_1Fatal'] = tt.loc[tt['Date_21Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_28D_1Fatal'] = tt.loc[tt['Date_28Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_35D_1Fatal'] = tt.loc[tt['Date_35Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_60D_1Fatal'] = tt.loc[tt['Date_60Days_Since_First_Fatal'] == tt['Date']]['Fatalities']","fbaf8893":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\ntt[['Place','Past_7Days_Confirmed_Change_of_Total','Past_7Days_Fatalities_Change_of_Total',\n    'Past_7Days_ConfirmedCases_Max','Past_7Days_ConfirmedCases_Min',\n   'Past_7Days_Fatalities_Max','Past_7Days_Fatalities_Min']] \\\n    .drop_duplicates() \\\n    .sort_values('Past_7Days_Confirmed_Change_of_Total')['Past_7Days_Confirmed_Change_of_Total'] \\\n    .plot(kind='hist', bins=50, title='Distribution of Pct change confirmed past 7 days', ax=axs[0])\ntt[['Place','Past_21Days_Confirmed_Change_of_Total','Past_21Days_Fatalities_Change_of_Total',\n    'Past_21Days_ConfirmedCases_Max','Past_21Days_ConfirmedCases_Min',\n   'Past_21Days_Fatalities_Max','Past_21Days_Fatalities_Min']] \\\n    .drop_duplicates() \\\n    .sort_values('Past_21Days_Confirmed_Change_of_Total')['Past_21Days_Confirmed_Change_of_Total'] \\\n    .plot(kind='hist', bins=50, title='Distribution of Pct change confirmed past 21 days', ax=axs[1])\nplt.show()\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 5))\ntt[['Place','Past_7Days_Fatalities_Change_of_Total']] \\\n    .drop_duplicates()['Past_7Days_Fatalities_Change_of_Total'] \\\n    .plot(kind='hist', bins=50, title='Distribution of Pct change confirmed past 7 days', ax=axs[0])\ntt[['Place', 'Past_21Days_Fatalities_Change_of_Total']] \\\n    .drop_duplicates()['Past_21Days_Fatalities_Change_of_Total'] \\\n    .plot(kind='hist', bins=50, title='Distribution of Pct change confirmed past 21 days', ax=axs[1])\nplt.show()","f8478f6f":"# Example of flat prop\ntt.query(\"Place == 'China_Chongqing'\").set_index('Date')['ConfirmedCases'].dropna().plot(figsize=(15, 5))\nplt.show()","b0c82781":"# Assume the places with small rate of change will continue slow down of virus spread\nconstant_case_places = tt.loc[(tt['Past_21Days_Confirmed_Change_of_Total'] < 0.01) & (tt['ConfirmedCases'] > 10)]['Place'].unique()\nconstant_case_places","36d56906":"# Assume the places with small rate of change will continue slow down of virus spread\nconstant_fatal_places = tt.loc[(tt['Past_21Days_Fatalities_Change_of_Total'] < 0.01) & (tt['Fatalities'] > 1)]['Place'].unique()\nconstant_fatal_places","769a1593":"# Example of flat prop\ntt.query(\"Place == 'Italy'\").set_index('Date')[['ConfirmedCases']].dropna().plot(figsize=(15, 5))\nplt.show()\ntt.query(\"Place == 'Italy'\").set_index('Date')[['ConfirmedCases_Log']].dropna().plot(figsize=(15, 5))\nplt.show()","31a329fd":"latest_summary_stats = tt.query('Date == @max_date') \\\n    [['Country_Region',\n      'Place',\n      'Max_Cases_Per_100kPop',\n      'Max_Fatalities_Per_100kPop',\n      'Max_Confirmed_Cases',\n      'Population_final',\n      'Days_Since_First_Case',\n      'Days_Since_Ten_Cases']] \\\n    .drop_duplicates()","25c2bff5":"latest_summary_stats.query('Place != \"Diamond Princess\"') \\\n    .query('Country_Region != \"China\"') \\\n    .plot(y='Max_Cases_Per_100kPop',\n          x='Days_Since_Ten_Cases',\n          style='.',\n          figsize=(15, 5))","a6298d3a":"tt.query('Province_State == \"Maryland\"')[['ConfirmedCases','Confirmed_Cases_Diff']]","6e2379a7":"# train model to predict fatalities\/day\n# params\nSEED = 42\nparams = {'num_leaves': 8,\n          'min_data_in_leaf': 5,  # 42,\n          'objective': 'regression',\n          'max_depth': 8,\n          'learning_rate': 0.02,\n      #    'boosting': 'gbdt',\n          'bagging_freq': 5,  # 5\n          'bagging_fraction': 0.8,  # 0.5,\n          'feature_fraction': 0.8201,\n          'bagging_seed': SEED,\n          'reg_alpha': 1,  # 1.728910519108444,\n          'reg_lambda': 4.9847051755586085,\n          'random_state': SEED,\n          'metric': 'mse',\n          'verbosity': 100,\n         'n_estimators' : 500,\n          'min_gain_to_split': 0.02,  # 0.01077313523861969,\n          'min_child_weight': 5,  # 19.428902804238373,\n          'num_threads': 6,\n          }","25c8e721":"import lightgbm as lgb\npd.set_option('max_columns', 500)\ntry:\n    tt['healthexp'] = pd.to_numeric(tt['healthexp'].str.replace(',',''))\nexcept:\n    pass\ntrain = tt.loc[tt['Date'] < '25-March-2020']\ntest = tt.loc[tt['Date'] >= '25-March-2020']","da76d752":"# [c for c in tt.columns]","f95fc590":"FEATURES = ['doy', 'dow', 'hasProvidence',\n       'lat', 'lon', 'Days_Since_First_Case', 'Days_Since_Ten_Cases',\n       'Days_Since_Hundred_Cases', 'Days_Since_First_Fatal',\n       'Days_Since_Ten_Fatal', 'Days_Since_Hundred_Fatal', 'Smoking_Rate',\n            'Population_final',\n#             'tests',\n#        'testpop', 'density', 'medianage', 'urbanpop',\n#             'quarantine', 'schools',\n#        'publicplace',\n            #'gatheringlimit', 'gathering', 'nonessential',\n       'hospibed', 'smokers', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64',\n       'sex65plus', 'sexratio', 'lung', 'femalelung', 'malelung', 'gdp2019',\n       'healthexp', 'healthperpop', 'fertility', \n            #'firstcase', 'totalcases',\n       #'activecases', 'newcases', 'deaths', 'newdeaths', 'recovered',\n       #'critical', 'casediv1m', 'deathdiv1m',\n             'CC_7D_1stCase',\n 'CC_14D_1stCase',\n 'CC_21D_1stCase',\n 'CC_28D_1stCase',\n 'CC_35D_1stCase',\n 'CC_60D_1stCase',\n 'F_7D_1stCase',\n 'F_14D_1stCase',\n 'F_21D_1stCase',\n 'F_28D_1stCase',\n 'F_35D_1stCase',\n 'F_60D_1stCase',\n 'CC_7D_10Case',\n 'CC_14D_10Case',\n 'CC_21D_10Case',\n 'CC_28D_10Case',\n 'CC_35D_10Case',\n 'CC_60D_10Case',\n 'F_7D_10Case',\n 'F_14D_10Case',\n 'F_21D_10Case',\n 'F_28D_10Case',\n 'F_35D_10Case',\n 'F_60D_10Case',\n 'CC_7D_1Fatal',\n 'CC_14D_1Fatal',\n 'CC_21D_1Fatal',\n 'CC_28D_1Fatal',\n 'CC_35D_1Fatal',\n 'CC_60D_1Fatal',\n 'F_7D_1Fatal',\n 'F_14D_1Fatal',\n 'F_21D_1Fatal',\n 'F_28D_1Fatal',\n 'F_35D_1Fatal',\n 'F_60D_1Fatal'\n           ]\nTARGET = ['ConfirmedCases_Log']","3c6d1516":"reg = lgb.LGBMRegressor(**params)\nreg.fit(train[FEATURES], train[TARGET])","6d4df209":"test['ConfirmedCases_Log_Pred'] = reg.predict(test[FEATURES])\ntest['ConfirmedCases_pred'] = test['ConfirmedCases_Log_Pred'].apply(np.expm1)","553633df":"test.set_index('Date')[['Place','ConfirmedCases_pred','ConfirmedCases']].query('Place == \"US_Maryland\"').plot(figsize=(15, 5))\nplt.show()\n\ntest.set_index('Date')[['Place','ConfirmedCases_pred','ConfirmedCases']].query('Place == \"Bhutan\"').plot(figsize=(15, 5))\nplt.show()","5cf3cb47":"from sklearn.linear_model import LinearRegression, ElasticNet","772e3cd4":"us_states = tt.query('Country_Region == \"US\"')['Place'].unique()\nus_states","8858df00":"myplace = \"US_Florida\"\ntt.query('Place == @myplace and Days_Since_First_Fatal >= 0')[['Days_Since_First_Fatal','Fatalities_Log']]","41b9a4f8":"for myplace in us_states:\n    try:\n        # Confirmed Cases\n        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n        dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases_Log']].dropna()\n        X = dat['Days_Since_Ten_Cases']\n        y = dat['ConfirmedCases_Log']\n        y = y.cummax()\n        dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases_Log']]\n        X_pred = dat_all['Days_Since_Ten_Cases']\n        en = ElasticNet()\n        en.fit(X.values.reshape(-1, 1), y.values)\n        preds = en.predict(X_pred.values.reshape(-1, 1))\n        tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'ConfirmedCases_Log_Pred1'] = preds\n        tt.loc[(tt['Place'] == myplace), 'ConfirmedCases_Pred1'] = tt['ConfirmedCases_Log_Pred1'].apply(np.expm1)\n        # Cap at 10 % Population\n        pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n        tt.loc[(tt['Place'] == myplace) & (tt['ConfirmedCases_Pred1'] > (0.1 * pop_myplace)), 'ConfirmedCases_Pred1'] = (0.1 * pop_myplace)\n        ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n        # Fatalities\n        # If low count then do percent of confirmed:\n        dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities_Log']].dropna()\n        if len(dat) < 5:\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.001\n        elif tt.query('Place == @myplace')['Fatalities'].max() < 5:\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.001\n        else:\n            X = dat['Days_Since_Ten_Cases']\n            y = dat['Fatalities_Log']\n            y = y.cummax()\n            dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities_Log']]\n            X_pred = dat_all['Days_Since_Ten_Cases']\n            en = ElasticNet()\n            en.fit(X.values.reshape(-1, 1), y.values)\n            preds = en.predict(X_pred.values.reshape(-1, 1))\n            tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'Fatalities_Log_Pred1'] = preds\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt['Fatalities_Log_Pred1'].apply(np.expm1)\n\n            # Cap at 0.0001 Population\n            pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n            tt.loc[(tt['Place'] == myplace) & (tt['Fatalities_Pred1'] > (0.0005 * pop_myplace)), 'Fatalities_Pred1'] = (0.0005 * pop_myplace)\n\n        ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])\n        plt.show()\n    except:\n        print(f'============= FAILED FOR {myplace} =============')\n","36274676":"myplace = 'US_Virgin Islands'\ndat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Place','Days_Since_Ten_Cases','ConfirmedCases']].dropna()","024ecb94":"tt.loc[tt['Place'].isin(us_states)].groupby('Place')['Fatalities_Pred1'].max().sum()","358b5566":"constant_fatal_places","b1b5f1c6":"tt.loc[tt['Place'].isin(constant_fatal_places), 'ConfirmedCases_Pred1'] = tt.loc[tt['Place'].isin(constant_fatal_places)]['Place'].map(tt.loc[tt['Place'].isin(constant_fatal_places)].groupby('Place')['ConfirmedCases'].max())\ntt.loc[tt['Place'].isin(constant_fatal_places), 'Fatalities_Pred1'] = tt.loc[tt['Place'].isin(constant_fatal_places)]['Place'].map(tt.loc[tt['Place'].isin(constant_fatal_places)].groupby('Place')['Fatalities'].max())","cf1cd9ad":"for myplace in constant_fatal_places:\n    fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n    ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n    ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])\n    plt.show()","2b9cc8aa":"remaining_places = pd.DataFrame(tt.groupby('Place')['ConfirmedCases_Pred1'].max().isna()).query('ConfirmedCases_Pred1').index.values\nprint(remaining_places)\nprint(len(remaining_places))","1227fe6a":"for myplace in remaining_places:\n    try:\n        # Confirmed Cases\n        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n        dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases_Log']].dropna()\n        X = dat['Days_Since_Ten_Cases']\n        y = dat['ConfirmedCases_Log']\n        y = y.cummax()\n        dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases_Log']]\n        X_pred = dat_all['Days_Since_Ten_Cases']\n        en = ElasticNet()\n        en.fit(X.values.reshape(-1, 1), y.values)\n        preds = en.predict(X_pred.values.reshape(-1, 1))\n        tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'ConfirmedCases_Log_Pred1'] = preds\n        tt.loc[(tt['Place'] == myplace), 'ConfirmedCases_Pred1'] = tt['ConfirmedCases_Log_Pred1'].apply(np.expm1)\n        # Cap at 10 % Population\n        pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n        tt.loc[(tt['Place'] == myplace) & (tt['ConfirmedCases_Pred1'] > (0.1 * pop_myplace)), 'ConfirmedCases_Pred1'] = (0.1 * pop_myplace)\n        ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n        # Fatalities\n        # If low count then do percent of confirmed:\n        dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities_Log']].dropna()\n        if len(dat) < 5:\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.001\n        elif tt.query('Place == @myplace')['Fatalities'].max() < 5:\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.001\n        else:\n            X = dat['Days_Since_Ten_Cases']\n            y = dat['Fatalities_Log']\n            y = y.cummax()\n            dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities_Log']]\n            X_pred = dat_all['Days_Since_Ten_Cases']\n            en = ElasticNet()\n            en.fit(X.values.reshape(-1, 1), y.values)\n            preds = en.predict(X_pred.values.reshape(-1, 1))\n            tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'Fatalities_Log_Pred1'] = preds\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt['Fatalities_Log_Pred1'].apply(np.expm1)\n\n            # Cap at 0.0001 Population\n            pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n            tt.loc[(tt['Place'] == myplace) & (tt['Fatalities_Pred1'] > (0.0005 * pop_myplace)), 'Fatalities_Pred1'] = (0.0005 * pop_myplace)\n\n        ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])\n        plt.show()\n    except:\n        print(f'============= FAILED FOR {myplace} =============')\n        ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n        ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])","772a44dc":"# Estimated total\ntt.groupby('Place')['Fatalities_Pred1'].max().sum()","01ad7fe2":"# Clean Up any time the actual is less than the real\ntt['ConfirmedCases_Pred1'] = tt[['ConfirmedCases','ConfirmedCases_Pred1']].max(axis=1)\ntt['Fatalities_Pred1'] = tt[['Fatalities','Fatalities_Pred1']].max(axis=1)\n\ntt['ConfirmedCases_Pred1'] = tt['ConfirmedCases_Pred1'].fillna(0)\ntt['Fatalities_Pred1'] = tt['Fatalities_Pred1'].fillna(0)\n\n# Fill pred with\ntt.loc[~tt['ConfirmedCases'].isna(), 'ConfirmedCases_Pred1'] = tt.loc[~tt['ConfirmedCases'].isna()]['ConfirmedCases']\ntt.loc[~tt['Fatalities'].isna(), 'Fatalities_Pred1'] = tt.loc[~tt['Fatalities'].isna()]['Fatalities']\n\ntt['ConfirmedCases_Pred1'] = tt.groupby('Place')['ConfirmedCases_Pred1'].transform('cummax')\ntt['Fatalities_Pred1'] = tt.groupby('Place')['Fatalities_Pred1'].transform('cummax')","72ca2868":"for myplace in tt['Place'].unique():\n    try:\n        # Confirmed Cases\n        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n        ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(title=myplace, ax=axs[0])\n        ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(title=myplace, ax=axs[1])\n        plt.show()\n    except:\n        print(f'============= FAILED FOR {myplace} =============')","cfc274d5":"tt.groupby('Place')['Fatalities_Pred1'].max().sort_values()","76428656":"# Questionable numbers\ntt.query('Place == \"Iran\"').set_index('Date')[['ConfirmedCases',\n                                               'ConfirmedCases_Pred1',]].plot(figsize=(15, 5))\n# Make Iran's Predictions Linear\n\ntt.query('Place == \"Iran\"').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5))","d71c83af":"dat.iloc[-10:]","5c8c8108":"for myplace in ['Iran']:\n\n    # Confirmed Cases\n    fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n    dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases']].dropna()\n    dat = dat.iloc[-10:]\n    X = dat['Days_Since_Ten_Cases']\n    y = dat['ConfirmedCases']\n    y = y.cummax()\n    dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases']]\n    X_pred = dat_all['Days_Since_Ten_Cases']\n    en = ElasticNet()\n    en.fit(X.values.reshape(-1, 1), y.values)\n    preds = en.predict(X_pred.values.reshape(-1, 1))\n    tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'ConfirmedCases_Pred1'] = preds\n    # Cap at 10 % Population\n    pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n    tt.loc[(tt['Place'] == myplace) & (tt['ConfirmedCases_Pred1'] > (0.1 * pop_myplace)), 'ConfirmedCases_Pred1'] = (0.1 * pop_myplace)\n    ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n    # Fatalities\n    # If low count then do percent of confirmed:\n    dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities']].dropna()\n    dat = dat.iloc[-10:]\n    if len(dat) < 5:\n        tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.001\n    elif tt.query('Place == @myplace')['Fatalities'].max() < 5:\n        tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.001\n    else:\n        X = dat['Days_Since_Ten_Cases']\n        y = dat['Fatalities']\n        y = y.cummax()\n        dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities']]\n        X_pred = dat_all['Days_Since_Ten_Cases']\n        en = ElasticNet()\n        en.fit(X.values.reshape(-1, 1), y.values)\n        preds = en.predict(X_pred.values.reshape(-1, 1))\n        tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'Fatalities_Pred1'] = preds\n\n        # Cap at 0.0001 Population\n        pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n        tt.loc[(tt['Place'] == myplace) & (tt['Fatalities_Pred1'] > (0.0005 * pop_myplace)), 'Fatalities_Pred1'] = (0.0005 * pop_myplace)\n\n    ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])\n    plt.show()","33a3bef4":"# Clean Up any time the actual is less than the real\ntt['ConfirmedCases_Pred1'] = tt[['ConfirmedCases','ConfirmedCases_Pred1']].max(axis=1)\ntt['Fatalities_Pred1'] = tt[['Fatalities','Fatalities_Pred1']].max(axis=1)\n\ntt['ConfirmedCases_Pred1'] = tt['ConfirmedCases_Pred1'].fillna(0)\ntt['Fatalities_Pred1'] = tt['Fatalities_Pred1'].fillna(0)\n\n# Fill pred with\ntt.loc[~tt['ConfirmedCases'].isna(), 'ConfirmedCases_Pred1'] = tt.loc[~tt['ConfirmedCases'].isna()]['ConfirmedCases']\ntt.loc[~tt['Fatalities'].isna(), 'Fatalities_Pred1'] = tt.loc[~tt['Fatalities'].isna()]['Fatalities']\n\ntt['ConfirmedCases_Pred1'] = tt.groupby('Place')['ConfirmedCases_Pred1'].transform('cummax')\ntt['Fatalities_Pred1'] = tt.groupby('Place')['Fatalities_Pred1'].transform('cummax')","33246295":"# Questionable numbers\ntt.query('Place == \"Iran\"').set_index('Date')[['ConfirmedCases',\n                                               'ConfirmedCases_Pred1',]].plot(figsize=(15, 5))\n# Make Iran's Predictions Linear\n\ntt.query('Place == \"Iran\"').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5))","4f2a946e":"ss = pd.read_csv('..\/input\/covid19-global-forecasting-week-2\/submission.csv')","a82233b6":"print(ss.shape)\nss.head()","e65153b0":"mysub = tt.dropna(subset=['ForecastId'])[['ForecastId','ConfirmedCases_Pred1','Fatalities_Pred1']]\nmysub['ForecastId'] = mysub['ForecastId'].astype('int')\nmysub = mysub.rename(columns={'ConfirmedCases_Pred1':'ConfirmedCases',\n                      'Fatalities_Pred1': 'Fatalities'})\nmysub.to_csv('submission.csv', index=False)","6ae565b0":"# Questionable numbers\ntt.groupby('Date').sum()[['ConfirmedCases',\n                          'ConfirmedCases_Pred1',]].plot(figsize=(15, 5))\n# Make Iran's Predictions Linear\n\ntt.groupby('Date').sum()[['Fatalities',\n                          'Fatalities_Pred1']].plot(figsize=(15, 5))","5182c62d":"# List of Places to keep fatailities constant","36c9472f":"# Make Submission","baf4b917":"# US States","88bb15c1":"# Deal with Flattened location","1edfadd5":"# Create Models","9ec277a2":"# Linear Regression","1c947fe9":"# Other Data Prep","82e0bc4b":"# Make Iran's Predictions Linear","903ed855":"# Data Preprocessing\nhttps:\/\/www.kaggle.com\/osciiart\/covid19-lightgbm","3c82aa26":"# Results dont look good","b18827a6":"# Falalities per day","cf792736":"# Remaining Locations\n## 217 left","c9186213":"# List of Places to keep cases constant","af31d9fa":"# Features about cases since first case\/ fatality","a2fca1f0":"# Plot them all!!","35912c5f":"# Summary Stats","5aae1f8d":"# Rob's Baseline Model"}}