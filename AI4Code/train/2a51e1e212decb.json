{"cell_type":{"7878382c":"code","b04c3fa5":"code","feb98a17":"code","27d7ca2c":"code","76840faa":"code","b0bf712f":"code","2dba9b30":"markdown"},"source":{"7878382c":"from sklearn import *\nimport numpy as np\nimport pandas as pd\nimport glob\n\ndata = {k.split('\/')[-1][:-4]:k for k in glob.glob('\/kaggle\/input\/**\/**.csv')}\ntrain = pd.read_csv(data['jigsaw-toxic-comment-train'], usecols=['id', 'comment_text', 'toxic'])\nval = pd.read_csv(data['validation'], usecols=['comment_text', 'toxic'])\ntest = pd.read_csv(data['test'], usecols=['id', 'content'])\ntest.columns = ['id', 'comment_text']\ntest['toxic'] = 0.5\n\n#https:\/\/www.kaggle.com\/hamditarek\/ensemble\nsub2 = pd.read_csv('..\/input\/ensemble\/submission.csv')","b04c3fa5":"%%time\ndef f_experience(c, s):\n    it = {'memory':10,\n        'influence':0.5,\n        'inference':0.5,\n        'interest':0.9,\n        'sentiment':1e-10,\n        'harmony':0.5}\n    \n    exp = {}\n    \n    for i in range(len(c)):\n        words = set([w for w in str(c[i]).lower().split(' ')])\n        for w in words:\n            try:\n                exp[w]['influence'] = exp[w]['influence'][1:] + [s[i]] #need to normalize\n                exp[w]['inference'] += 1\n                exp[w]['interest'] = exp[w]['interest'][1:] + [(exp[w]['interest'][it['memory']-1] + (s[i] * it['interest']))\/2]\n                exp[w]['sentiment'] += s[i]\n                #exp[w]['harmony']\n            except:\n                m = [0. for m_ in range(it['memory'])]\n                exp[w] = {}\n                exp[w]['influence'] = m[1:] + [s[i]]\n                exp[w]['inference'] = 1\n                exp[w]['interest'] = m[1:] + [s[i] * it['interest'] \/ 2]\n                exp[w]['sentiment'] = s[i]\n                #exp[w]['harmony'] = 0\n                \n    for w in exp:\n        exp[w]['sentiment'] \/= exp[w]['inference'] + it['sentiment']\n        exp[w]['inference'] \/= len(c) * it['inference']\n\n    return exp\n\nexp = f_experience(train['comment_text'].values, train['toxic'].values)","feb98a17":"%%time\ndef features(df):\n    df['len'] = df['comment_text'].map(len)\n    df['wlen'] = df['comment_text'].map(lambda x: len(str(x).split(' ')))\n    \n    df['influence_sum'] = df['comment_text'].map(lambda x: np.sum([np.mean(exp[w]['influence']) if w in exp else 0 for w in str(x).lower().split(' ')]))\n    df['influence_mean'] = df['comment_text'].map(lambda x: np.mean([np.mean(exp[w]['influence']) if w in exp else 0 for w in str(x).lower().split(' ')]))\n    \n    df['inference_sum'] = df['comment_text'].map(lambda x: np.sum([exp[w]['inference'] if w in exp else 0 for w in str(x).lower().split(' ')]))\n    df['inference_mean'] = df['comment_text'].map(lambda x: np.mean([exp[w]['inference'] if w in exp else 0 for w in str(x).lower().split(' ')]))\n    \n    df['interest_sum'] = df['comment_text'].map(lambda x: np.sum([np.mean(exp[w]['interest']) if w in exp else 0 for w in str(x).lower().split(' ')]))\n    df['interest_mean'] = df['comment_text'].map(lambda x: np.mean([np.mean(exp[w]['interest']) if w in exp else 0 for w in str(x).lower().split(' ')]))\n    \n    df['sentiment_sum'] = df['comment_text'].map(lambda x: np.sum([exp[w]['sentiment'] if w in exp else 0.5 for w in str(x).lower().split(' ')]))\n    df['sentiment_mean'] = df['comment_text'].map(lambda x: np.mean([exp[w]['sentiment'] if w in exp else 0.5 for w in str(x).lower().split(' ')]))\n    return df\n\nval = features(val)\ntest= features(test)","27d7ca2c":"col = [c for c in val if c not in ['id', 'comment_text', 'toxic']]\nx1, x2, y1, y2 = model_selection.train_test_split(val[col], val['toxic'], test_size=0.3, random_state=20)\n\nmodel = ensemble.ExtraTreesClassifier(n_estimators=1000, max_depth=7, n_jobs=-1, random_state=20)\nmodel.fit(x1, y1)\nprint(metrics.roc_auc_score(y2, model.predict_proba(x2)[:,1].clip(0.,1.)))\n\nmodel.fit(val[col], val['toxic'])\ntest['toxic'] = model.predict_proba(test[col])[:,1].clip(0.,1.)\nsub1 = test[['id', 'toxic']]","76840faa":"sub1.rename(columns={'toxic':'toxic1'}, inplace=True)\nsub2.rename(columns={'toxic':'toxic2'}, inplace=True)\nsub3 = pd.merge(sub1, sub2, how='left', on='id')\n\nsub3['toxic'] = (sub3['toxic1'] * 0.1) + (sub3['toxic2'] * 0.9) #blend 1\nsub3['toxic'] = (sub3['toxic2'] * 0.51) + (sub3['toxic'] * 0.49) #blend 2\n\nsub3[['id', 'toxic']].to_csv('submission.csv', index=False)","b0bf712f":"#Is it toxic :)\ntest = pd.DataFrame(['Howling with Wolf on L\u00fcgenpresse'], columns=['comment_text'])\ntest['id'] = test.index\ntest= features(test)\ntest['toxic'] = model.predict_proba(test[col])[:,1].clip(0.,1.)\ntest[['id', 'comment_text', 'toxic']].head()","2dba9b30":"\uff28\ud835\udc00\ud835\udc77\ud835\udc77\ud835\udcce \ud83c\uddf0\ud835\uddee\ud835\ude28\ud835\ude28\ud83c\uddf1\ud835\udd8e\uff2e\u0262 \ud83d\udcaf\n========"}}