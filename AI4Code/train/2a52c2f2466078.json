{"cell_type":{"feb49683":"code","f13ab680":"code","5b527f90":"code","175a87c8":"code","087a4568":"code","9525c47f":"code","ddf56d85":"code","bbc5b7d5":"code","4aa20e82":"code","933f2773":"code","55e9ccbc":"code","5e057b54":"code","f551de6c":"code","629bb977":"code","87a3a097":"code","b271b3c0":"code","5ef9835a":"code","b7a25b15":"code","fc4651f6":"code","56be8bf5":"code","a1e18aaa":"code","48799f1a":"code","f7b084ea":"code","0a83f5fb":"code","183b9aa3":"code","14d79824":"code","9983b72d":"code","09ec4b94":"code","b282b127":"markdown","2ea6d441":"markdown","8d754272":"markdown","675f642c":"markdown","266229e5":"markdown","10306dd5":"markdown","0960c206":"markdown"},"source":{"feb49683":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","f13ab680":"data = pd.read_csv('..\/input\/adult-census-income\/adult.csv')","5b527f90":"data","175a87c8":"data.drop('education', axis=1, inplace=True)","087a4568":"data.isna().sum()","9525c47f":"data.isin(['?']).sum()","ddf56d85":"data = data.replace('?', np.NaN)","bbc5b7d5":"data.isna().sum()","4aa20e82":"data","933f2773":"categorical_features = ['workclass', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']","55e9ccbc":"def get_uniques(df, columns):\n    uniques = dict()\n    for column in columns:\n        uniques[column] = list(df[column].unique())\n    return uniques","5e057b54":"get_uniques(data, categorical_features)","f551de6c":"binary_features = ['sex']\n\nnominal_features = ['workclass', 'marital.status', 'occupation', 'relationship', 'race', 'native.country']","629bb977":"def binary_encode(df, columns):\n    label_encoder = LabelEncoder()\n    for column in columns:\n        df[column] = label_encoder.fit_transform(df[column])\n    return df\n\ndef onehot_encode(df, columns):\n    for column in columns:\n        dummies = pd.get_dummies(df[column])\n        df = pd.concat([df, dummies], axis=1)\n        df.drop(column, axis=1, inplace=True)\n    return df","87a3a097":"data = binary_encode(data, binary_features)\ndata = onehot_encode(data, nominal_features)","b271b3c0":"(data.dtypes == 'object').sum()","5ef9835a":"data","b7a25b15":"y = data['income']\nX = data.drop('income', axis=1)","fc4651f6":"label_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\ny_mappings = {index: label for index, label in enumerate(label_encoder.classes_)}\ny_mappings","56be8bf5":"y","a1e18aaa":"scaler = MinMaxScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)","48799f1a":"X","f7b084ea":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)","0a83f5fb":"inputs = tf.keras.Input(shape=(88,))\nx = tf.keras.layers.Dense(16, activation='relu')(inputs)\nx = tf.keras.layers.Dense(16, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmetrics = [\n    tf.keras.metrics.BinaryAccuracy(name='acc'),\n    tf.keras.metrics.AUC(name='auc')\n]\n\nmodel.compile(\n    optimizer=optimizer,\n    loss='binary_crossentropy',\n    metrics=metrics\n)\n\n\nbatch_size = 32\nepochs = 26\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=0\n)","183b9aa3":"plt.figure(figsize=(14, 10))\n\nepochs_range = range(1, epochs + 1)\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs_range, train_loss, label=\"Training Loss\")\nplt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.show()","14d79824":"np.argmin(val_loss)","9983b72d":"model.evaluate(X_test, y_test)","09ec4b94":"y.sum() \/ len(y)","b282b127":"## Missing Values","2ea6d441":"# Preprocessing","8d754272":"## Scaling","675f642c":"## Encoding","266229e5":"# Getting Started","10306dd5":"# Training","0960c206":"# Results"}}