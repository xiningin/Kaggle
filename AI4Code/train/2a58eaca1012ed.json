{"cell_type":{"7d7be290":"code","e678d2f0":"code","c58ba6ed":"code","c1b33c82":"code","1696e1bc":"code","22b58eae":"code","f977a817":"code","c311bcc1":"code","9c61c910":"code","1c1b0e43":"code","7cd04d6a":"code","06c2a75d":"code","bcbcfcf3":"code","0f88d00c":"code","ae6ab2ef":"code","cdab3daf":"code","08900fd7":"code","c8aeb6bf":"code","f44f2724":"code","eb52aca3":"code","e6799b9f":"code","7eadb536":"code","65ad2566":"code","e0f83381":"code","236fe0fc":"code","846cf7b6":"code","225ea1db":"code","9280cf14":"code","c8306e94":"code","7f7f7476":"code","9cee3acb":"code","b5ab8e4e":"code","8f30287b":"code","638de519":"code","f043579c":"code","820a07c4":"code","e106222d":"code","9b98998c":"markdown","e851abf6":"markdown","7f6b40fb":"markdown","81c1be98":"markdown","2988d974":"markdown","94ae57d1":"markdown","b69aabf2":"markdown","f91eb54a":"markdown","559ded3f":"markdown","a329046b":"markdown","9dc3d0fc":"markdown"},"source":{"7d7be290":"import os\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torchvision.utils import save_image","e678d2f0":"DATA_DIR = \"..\/input\/abstract-art-gallery\"","c58ba6ed":"stats = (.5, .5, .5), (.5, .5, .5)","c1b33c82":"transform_ds = T.Compose([\n    T.Resize((128, 128)),\n    T.CenterCrop(128),\n    T.RandomHorizontalFlip(),\n    T.RandomVerticalFlip(),\n    T.ToTensor(),\n    T.Normalize(*stats)\n])\nds = torchvision.datasets.ImageFolder(root=DATA_DIR, transform=transform_ds)","1696e1bc":"def denorm(img_tensor):\n    return img_tensor * stats[1][0] + stats[0][0]","22b58eae":"batch_size=128","f977a817":"train_dl = DataLoader(ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)","c311bcc1":"def show_image(train_dl):\n    for images,_ in train_dl:\n        fig, ax = plt.subplots(figsize=(8,8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(denorm(images.detach()[:32]), nrow=8).permute(1,2,0))\n        break\n        \nshow_image(train_dl)","9c61c910":"project_name = 'abstract-art'","1c1b0e43":"def get_device():\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    else:\n        return torch.device(\"cpu\")\n    \ndef to_device(data, device):\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for x in self.dl:\n            yield to_device(x, self.device)\n            \n    def __len__(self):\n        return len(self.dl)\n    \ndevice = get_device()\ndevice","7cd04d6a":"train_dl = DeviceDataLoader(train_dl, device)","06c2a75d":"discriminator = nn.Sequential(\n    #in: 128 x 3 x 128 x 128\n    \n    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    #128 x 64 x 64 x 64\n    \n    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    #128 x 128 x 32 x 32\n    \n    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.2, inplace=True),\n    #128 x 256 x 16 x 16\n    \n    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.2, inplace=True),\n    #128 x 512 x 8 x 8\n    \n    nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(1024),\n    nn.LeakyReLU(0.2, inplace=True),\n    #128 x 1024 x 4 x 4\n    \n    nn.Conv2d(1024, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    #128 x 1 x 1 x 1\n    \n    nn.Flatten(),\n    nn.Sigmoid()\n\n)","bcbcfcf3":"discriminator = to_device(discriminator, device)","0f88d00c":"latent_size=128","ae6ab2ef":"generator = nn.Sequential(\n    #in: 128 x 1 x 1\n    \n    nn.ConvTranspose2d(latent_size, 1024, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.BatchNorm2d(1024),\n    nn.ReLU(True),\n    #128 x 1024 x 4 x 4\n    \n    nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    #128 x 512 x 8 x 8\n    \n    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    #128 x 256 x 16 x 16\n    \n    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    #128 x 128 x 32 x 32\n    \n    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    #128 x 64 x 64 x 64\n    \n    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n    #128 x 3 x 128 x 128\n    nn.Tanh()\n    \n    \n)","cdab3daf":"generator = to_device(generator, device)","08900fd7":"def train_discriminator(real_images, opt_d):\n    opt_d.zero_grad()\n    \n    real_preds= discriminator(real_images)\n    real_targets = torch.ones(real_images.size(0), 1, device=device)\n    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n    real_score = torch.mean(real_preds).item()\n    \n    latent = torch.randn(latent_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n    \n    fake_preds= discriminator(fake_images)\n    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n    fake_score = torch.mean(fake_preds).item()\n    \n    loss = real_loss + fake_loss\n    loss.backward(),\n    opt_d.step()\n    \n    return loss.item(), real_score, fake_score","c8aeb6bf":"def train_generator(opt_g):\n    opt_g.zero_grad()\n    \n    latent = torch.randn(latent_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n    \n    preds = discriminator(fake_images)\n    targets = torch.ones(fake_images.size(0), 1, device=device)\n    loss = F.binary_cross_entropy(preds, targets)\n    \n    loss.backward(),\n    opt_g.step()\n    \n    return loss.item()","f44f2724":"sample_dir = \"generated\"\nos.makedirs(sample_dir, exist_ok=True)","eb52aca3":"def save_sample(index, fixed_latent, show=True):\n    fake_images = generator(fixed_latent)\n    fake_fname = \"generated-images-{0:0=4d}.png\".format(index)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n    if show:\n        fig, ax = plt.subplots(figsize=(8,8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach()[:32], nrow=8).permute(1,2,0))","e6799b9f":"fixed_latent = torch.randn(128, latent_size, 1, 1, device=device)\nsave_sample(0, fixed_latent, show=True)","7eadb536":"def fit(epochs, lr_d, lr_g, start_idx=1):\n    torch.cuda.empty_cache()\n    \n    losses_d = []\n    losses_g = []\n    real_scores = []\n    fake_scores = []\n    \n    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n    opt_g = torch.optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n    \n    for epoch in range(epochs):\n        for real_images,_ in tqdm(train_dl):\n            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n            loss_g = train_generator(opt_g)\n            \n        losses_d.append(loss_d)\n        losses_g.append(loss_g)\n        real_scores.append(real_score)\n        fake_scores.append(fake_score)\n        \n        print(\"Epoch: [{}\/{}], loss_d: {:.4f}, loss_g: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n        epoch+1, epochs, loss_d, loss_g, real_score, fake_score))\n        \n        save_sample(epoch+start_idx, fixed_latent, show=False)\n        \n    return losses_d, losses_g, real_scores, fake_scores","65ad2566":"epochs = 420\nlr_d = 10e-5\nlr_g = 10e-4","e0f83381":"history = [fit(epochs, lr_d, lr_g, start_idx=1)]","236fe0fc":"losses_g, losses_d, real_scores, fake_scores = history","846cf7b6":"jovian.log_metrics(loss_g=losses_g[-1], \n                   loss_d=losses_d[-1], \n                   real_score=real_scores[-1], \n                   fake_score=fake_scores[-1])","225ea1db":"# Save the model checkpoints \ntorch.save(generator.state_dict(), 'G.pth')\ntorch.save(discriminator.state_dict(), 'D.pth')","9280cf14":"from IPython.display import Image","c8306e94":"Image(\".\/generated\/generated-images-0001.png\")","7f7f7476":"Image('.\/generated\/generated-images-0050.png')","9cee3acb":"Image('.\/generated\/generated-images-0100.png')","b5ab8e4e":"Image('.\/generated\/generated-images-0150.png')","8f30287b":"Image('.\/generated\/generated-images-0200.png')","638de519":"Image('.\/generated\/generated-images-0250.png')","f043579c":"import cv2\nimport os\n\nvid_fname = 'gans_training.avi'\n\nfiles = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]\nfiles.sort()\n\nout = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n[out.write(cv2.imread(fname)) for fname in files]\nout.release()","820a07c4":"plt.plot(losses_d, '-')\nplt.plot(losses_g, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","e106222d":"plt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real', 'Fake'])\nplt.title('Scores');","9b98998c":"#### The input to the generator is typically a vector or a matrix of random numbers (referred to as a latent tensor) which is used as a seed for generating an image. The generator will convert a latent tensor of shape (128, 1, 1) into an image tensor of shape 3 x 28 x 28. To achive this, we'll use the ConvTranspose2d layer from PyTorch, which is performs to as a transposed convolution (also referred to as a deconvolution). ","e851abf6":"## Importing the modules","7f6b40fb":"### We make the discriminator network which helps us classify real and fake images using CNN ","81c1be98":"### We train the discriminator and the generator for a given number of epochs and learning rates.","2988d974":"## Moving to the GPU","94ae57d1":"#### Different from the regular ReLU function, Leaky ReLU allows the pass of a small gradient signal for negative values. As a result, it makes the gradients from the discriminator flows stronger into the generator. Instead of passing a gradient (slope) of 0 in the back-prop pass, it passes a small negative gradient","b69aabf2":"### We move the data to the GPU using device dl in order to do the calculations faster","f91eb54a":"### We specify the batch size and prepare the train_dataloader ","559ded3f":"### We prepare the data by adding the data and specifying the 'DATA_DIR' and then we apply some transformations to the data.","a329046b":"### We can see the outputs of our generator in the generated folder.","9dc3d0fc":"## Preparing the data"}}