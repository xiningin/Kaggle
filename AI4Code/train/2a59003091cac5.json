{"cell_type":{"ebb357a4":"code","1a6e93ef":"code","546ef182":"code","120d9f7b":"code","0b038451":"code","71ffe7d9":"code","859037f5":"code","57f55afd":"code","d7c127a9":"code","eadcfafa":"code","698b6516":"code","2d39ecd3":"code","978a22ce":"code","d60048da":"code","72847b49":"code","fed5fe91":"markdown","117b24ee":"markdown","36dc3706":"markdown","0d0015c3":"markdown","72022378":"markdown"},"source":{"ebb357a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a6e93ef":"#importing all the necessary libraries to be used in our code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score,cross_validate\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom xgboost import XGBClassifier","546ef182":"#importing the parkinsons data downloaded from UCI machine learning repository\npath = 'parkinsons.data'\ndf = pd.read_csv(\"\/kaggle\/input\/parkinsons-data-set\/parkinsons.data\")\ndf.head()","120d9f7b":"df.info() #checking the information of the columns","0b038451":"df.shape #Cecking th shape of of data i.e rows and column","71ffe7d9":"df.describe() #Getting the statistical summary of features in our dataset","859037f5":"sns.countplot(df['status']) #ploting a count of the target variable with seaborn\nplt.show()","57f55afd":"#Visualization is always the best way to explain figures.\n#Using seaborn heatmap for plotting the correlation of the features \nplt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True,fmt=\".2f\",linewidths=\"1.2\")\nplt.show()","d7c127a9":"#Using pair plot to showing the relationship between variables that are highly correlected (+ve and -ve) with the target (status)\nplt.figure(figsize = (15,10))\nsns.pairplot(df, vars=['MDVP:Fo(Hz)','MDVP:Flo(Hz)','HNR','PPE','spread1','spread2'],hue='status',palette='Dark2')\nplt.savefig('Relationship')\nplt.show()","eadcfafa":"#Dividing our dataset into X (features) and y (Target)\nX = np.array(df.drop(['name','status'], axis = 1))\ny = np.array(df['status'])\nprint(f'X shape: {X.shape} Y Shape: {y.shape}')","698b6516":"#scaling the features so they are of the same scale. The target doesnt need to be scaled\nscaler = MinMaxScaler()\nscaled_X = scaler.fit_transform(X)","2d39ecd3":"#writting a function for performing cross validation \ndef crossValidate(model):\n    #Using StratifiedKFold to ensure that the divided folds are shuffled\n    strat_k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n    \n    #Getting just specific scores for perfromance evualation.\n    scoring = [\"accuracy\",\"precision\",\"recall\",\"f1\",\"roc_auc\"]\n    cv = cross_validate(model, scaled_X, y, cv = strat_k_fold, scoring = scoring)\n    \n    '''\n    for score in cv:\n        print(f'{score}: {round(cv[score].mean(),3)}')\n    '''\n    \n    result = [round(cv[score].mean(),3) for score in cv]\n    return result\n    ","978a22ce":"model = XGBClassifier()\nresult = crossValidate(model)#passing the model to the cross validate function","d60048da":"result[2:]","72847b49":"#Giving a plot of the performance metrics used\nplt.figure(figsize = (6,2))\nmodel_preformance = pd.Series(data=result[2:], \n        index=['Accuracy','Precision','Recall','F1-Score','AUC (ROC)'])\nmodel_preformance.sort_values().plot.barh()\nplt.title('Model Performance')","fed5fe91":"<h2>Selecting Features and Scaling Them<\/h2>","117b24ee":"<h2>Perfroming Cross Validation<\/h2>\nCross validation helps to ensure that our model is not over fitting the data","36dc3706":"<h2>Instantiate The Model To Be Used<\/h2>","0d0015c3":"<h2>Parkinson's Disease Detection For Begineers Using XGBoost<\/h2>\n\nXGBoost is a machine learning algorithm that has been used  by many winner of machine learning competions because of its speed. It is based on the concept of decision trees.","72022378":"<h2>EDA (Exploratory Data Analysis)<\/h2>\n"}}