{"cell_type":{"adc4303f":"code","20ab2b23":"code","85b6f676":"code","51f75c7d":"code","230da621":"code","a3cf4e3c":"code","9d0238fc":"code","dc1b3ce4":"code","823fae40":"code","62658228":"code","fedb4ff1":"code","b463fab7":"code","601b71bc":"code","cc4f6a96":"code","da3a1424":"code","60c34296":"code","6fe68a05":"code","f52d6881":"code","53f46243":"code","760ab38f":"code","92bf4e2a":"code","e4337ea3":"code","5115d5bd":"code","00f3fdfc":"code","90045d01":"code","a293335a":"code","d42cf7c4":"code","bc076fc5":"code","515ac851":"code","173ea3a2":"code","ff3ad128":"code","aee9f379":"code","301d6fed":"code","1a6f60e2":"code","53c59c9f":"code","7821d244":"code","865460ef":"code","d5c70961":"code","762e26b6":"code","92cc6566":"code","7b7609b2":"code","f3bcba7d":"code","5eb42334":"code","529a4b12":"code","52468294":"code","c4a56153":"code","25339583":"code","a6d4d208":"code","66a651ca":"code","dd8fbbd2":"code","ed9cd154":"code","9009a1a5":"code","deb49e1f":"code","20e34ed7":"code","e1f7c0f0":"code","8df2edd0":"code","a1a13c0e":"markdown","f71406da":"markdown","cc8db4cc":"markdown","7c694c97":"markdown","0b726eac":"markdown","1f48607a":"markdown","ae738b53":"markdown","03919cc0":"markdown","27995929":"markdown","3f8d51c1":"markdown"},"source":{"adc4303f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20ab2b23":"flights=pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')","85b6f676":"flights.head()","51f75c7d":"flights.info()","230da621":"#clearing the missing data\nflights.dropna(inplace=True)\nflights.info()","a3cf4e3c":"#Now lets check the count of the airlines in the visual graph\nplot=plt.figure()\nsns.countplot('Airline',data=flights)\nplt.xticks(rotation=90)","9d0238fc":"#Now lets check the count of the Source in the visual graph\nplot=plt.figure()\nsns.countplot('Source',data=flights)\nplt.xticks(rotation=90)","dc1b3ce4":"#Now lets check the count of the Destination in the visual graph\nplot=plt.figure()\nsns.countplot('Destination',data=flights)\nplt.xticks(rotation=90)","823fae40":"#Now lets check the count of the Total_Stops in the visual graph\nplot=plt.figure()\nsns.countplot('Total_Stops',data=flights)\nplt.xticks(rotation=90)","62658228":"#Now lets check the count of the Additional_info in the visual graph\nplot=plt.figure()\nsns.countplot('Additional_Info',data=flights)\nplt.xticks(rotation=90)","fedb4ff1":"flights['Date_of_Journey']=pd.to_datetime(flights['Date_of_Journey'])\nflights['Dep_Time']=pd.to_datetime(flights['Dep_Time'],format='%H:%M').dt.time","b463fab7":"flights['Date_of_Journey']","601b71bc":"flights['Dep_Time']","cc4f6a96":"#As we can see that there are two 'no_info' columns we combine them\nflights['Additional_Info']=flights['Additional_Info'].str.replace('No info','No Info')","da3a1424":"#For the duration column which is in a hour and min format lets convert it into minutes using a equation \nflights['Duration']=flights['Duration'].str.replace('h','*60').str.replace(' ','+').str.replace('m','*1').apply(eval)\n#now lets convert this column into a numeric\nflights['Duration']=pd.to_numeric(flights['Duration'])","60c34296":"#we are converting the flights day to find which day it is in the week and storing it in the weekday column\nflights['weekday']=flights[['Date_of_Journey']].apply(lambda x:x.dt.day_name())","6fe68a05":"#now lets check the day of the journey relation with the output price column\nsns.barplot('weekday','Price',data=flights)","f52d6881":"#we are converting the flights date to find which month it is and storing it in the month column\nflights[\"month\"] = flights['Date_of_Journey'].map(lambda x: x.month_name())","53f46243":"#now lets check the month of journey relation with the output price column\nsns.barplot('month','Price',data=flights)","760ab38f":"#we are taking the departure time hour column and converting it into a numeric\nflights['Dep_Time']=flights['Dep_Time'].apply(lambda x:x.hour)\nflights['Dep_Time']=pd.to_numeric(flights['Dep_Time'])","92bf4e2a":"#now lets check the departure time relation with the output price column\nsns.barplot('Dep_Time','Price',data=flights)","e4337ea3":"#Now lets check this Duration column in a histogram\nplot=plt.figure()\nsns.distplot(flights['Duration'],bins=40)\nplt.xticks(rotation=90)","5115d5bd":"flights.head()","00f3fdfc":"#Now lets remove the irrelevant features\nflights.drop(['Route','Arrival_Time','Date_of_Journey'],axis=1,inplace=True)","90045d01":"flights.head()","a293335a":"#Now lets encode the inputs using label encoder\nfrom sklearn.preprocessing import LabelEncoder\nvar_mod = ['Airline','Source','Destination','Additional_Info','Total_Stops','weekday','month','Dep_Time']\nle = LabelEncoder()\nfor i in var_mod:\n    flights[i] = le.fit_transform(flights[i])","d42cf7c4":"flights.head()","bc076fc5":"flights.corr()","515ac851":"def outlier(df):\n    for i in df.describe().columns:\n        Q1=df.describe().at['25%',i]\n        Q3=df.describe().at['75%',i]\n        IQR= Q3-Q1\n        LE=Q1-1.5*IQR\n        UE=Q3+1.5*IQR\n        df[i]=df[i].mask(df[i]<LE,LE)\n        df[i]=df[i].mask(df[i]>UE,UE)\n    return df","173ea3a2":"flights=outlier(flights)","ff3ad128":"x=flights.drop('Price',axis=1)#taking all the other columns except price \ny=flights['Price']","aee9f379":"from sklearn.model_selection import train_test_split","301d6fed":"#We are splitting the data in to two parts one is used to train the model and another is used to evaluate the model\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)","1a6f60e2":"from sklearn.ensemble import RandomForestRegressor","53c59c9f":"# Defining the RandomForestRegressor\nrfr=RandomForestRegressor(n_estimators=100)","7821d244":"# Training the model\nrfr.fit(x_train,y_train)","865460ef":"# In random forest we have a method to determine the feature importance in accordance with the relevance of the data\n# lets check that once\nfeatures=x.columns\nimportances = rfr.feature_importances_\nindices = np.argsort(importances)\nplt.figure(1)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), features[indices])\nplt.xlabel('Relative Importance')","d5c70961":"predictions=rfr.predict(x_test)","762e26b6":"predictions=rfr.predict(x_test)","92cc6566":"plt.scatter(y_test,predictions)","7b7609b2":"from sklearn import metrics","f3bcba7d":"print('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('r2_score:', (metrics.r2_score(y_test, predictions)))","5eb42334":"sns.distplot((y_test-predictions),bins=50)","529a4b12":"from sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor","52468294":"from sklearn.metrics import r2_score,make_scorer","c4a56153":"from sklearn.model_selection import cross_val_score","25339583":"regg=[LinearRegression(),RandomForestRegressor(),SVR(),DecisionTreeRegressor()]","a6d4d208":"mean=[]\nstd=[]\nfor i in regg:\n    cvs=cross_val_score(i,x,y,cv=5,scoring=make_scorer(r2_score))\n    mean.append(np.mean(cvs))\n    std.append(np.std(cvs))","66a651ca":"for i in range(4):\n    print(regg[i].__class__.__name__,':',mean[i])","dd8fbbd2":"test_file=pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Test_set.xlsx')","ed9cd154":"test_file.head()","9009a1a5":"test_file.info()","deb49e1f":"test_file['Date_of_Journey']=pd.to_datetime(test_file['Date_of_Journey'])\ntest_file['Dep_Time']=pd.to_datetime(test_file['Dep_Time'],format='%H:%M').dt.time\ntest_file['Duration']=test_file['Duration'].str.replace('h','*60').str.replace(' ','+').str.replace('m','*1').apply(eval)\ntest_file['Duration']=pd.to_numeric(test_file['Duration'])\ntest_file['Dep_Time']=test_file['Dep_Time'].apply(lambda x:x.hour)\ntest_file['Dep_Time']=pd.to_numeric(test_file['Dep_Time'])\ntest_file[\"month\"] = test_file['Date_of_Journey'].map(lambda x: x.month_name())\ntest_file['weekday']=test_file[['Date_of_Journey']].apply(lambda x:x.dt.day_name())\ntest_file['Additional_Info']=test_file['Additional_Info'].str.replace('No info','No Info')\ntest_file.drop(['Date_of_Journey','Route','Arrival_Time'],axis=1,inplace=True)\nfor i in var_mod:\n    test_file[i]=le.fit_transform(test_file[i])","20e34ed7":"test_price_predictions=rfr.predict(test_file)","e1f7c0f0":"# predicted price\ntest_price_predictions  ","8df2edd0":"plot=plt.figure()\nsns.distplot(test_price_predictions,bins=40)\nplt.xticks(rotation=90);","a1a13c0e":"**Assigning Input and output variables**","f71406da":"# Applying the regressions on a new test data file","cc8db4cc":"![image.png](attachment:image.png)","7c694c97":"# Build Model","0b726eac":"# Regression Evaluation Metrics","1f48607a":"The flight ticket price in India is based on demand and supply model with few restrictions on pricing from regulatory bodies. It is often perceived as unpredictable and , recent dynamic pricing scheme added to the confusion. The objective is to create a machine learning model for predicting the flight price, based on historical data, which can be used for reference price for customers as well as airline service providers","ae738b53":"# Exploratory Data Analysis","03919cc0":"**Now we can predict the data**","27995929":"**Residual Histogram**","3f8d51c1":"**Train Test Split**"}}