{"cell_type":{"b60ae22f":"code","6dfc527d":"code","f88f76cf":"code","a3870614":"code","df7c559e":"code","f86458db":"code","d1e5428b":"code","e194e9e3":"code","74ac4408":"code","22c772ca":"code","81e7a707":"code","4612885a":"code","a23bfe75":"code","6320b21f":"code","7bb8520a":"markdown","7f3bb594":"markdown","74645e6a":"markdown","eff3f9af":"markdown","496acda9":"markdown","be5e67da":"markdown","7b0ce148":"markdown","b6b2f19e":"markdown","11e1fbc4":"markdown","9449ff65":"markdown"},"source":{"b60ae22f":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import imagenet_utils\nimport os\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline","6dfc527d":"trainpath = os.listdir(\"..\/input\/fingers\/train\")\ntestpath = os.listdir(\"..\/input\/fingers\/test\")","f88f76cf":"traindata = ['..\/input\/fingers\/train\/' + i for i in trainpath]\ntestdata = [\"..\/input\/fingers\/test\/\" + i for i in testpath]","a3870614":"traindata = pd.DataFrame(traindata, columns=['Filepath'])\ntestdata = pd.DataFrame(testdata, columns=['Filepath'])","df7c559e":"traindata['target'] = traindata['Filepath'].apply(lambda a: a[-6:-5])\ntestdata['target'] = testdata['Filepath'].apply(lambda a: a[-6:-5])","f86458db":"from IPython.display import Image\nImage(filename=traindata.Filepath[0], width=300,height=300) ","d1e5428b":"ds_generator = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,validation_split=0.1)","e194e9e3":"train_ds = ds_generator.flow_from_dataframe(dataframe=traindata,x_col='Filepath',y_col='target',target_size=(224, 224),color_mode='rgb',class_mode='categorical',batch_size=16,subset='training')\nval_ds = ds_generator.flow_from_dataframe(dataframe=traindata,x_col='Filepath',y_col='target',target_size=(224, 224),color_mode='rgb',class_mode='categorical',batch_size=16,subset='validation')\ntest_ds = ds_generator.flow_from_dataframe(dataframe=testdata,x_col='Filepath',y_col='target',target_size=(224, 224),color_mode='rgb',class_mode='categorical',batch_size=16)","74ac4408":"mobile = tf.keras.applications.mobilenet.MobileNet()\n\nmobile.summary()","22c772ca":"x = mobile.layers[-6].output #Removing last 5 layers of mobilenet and addding softmax layer\n\noutput = Dense(units=6, activation='softmax')(x)\nmodel = Model(inputs=mobile.input, outputs=output)\n\nmodel = Model(inputs=mobile.input, outputs=output)\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","81e7a707":"model.fit(train_ds, validation_data=val_ds, verbose=1, epochs=2)","4612885a":"model.summary()","a23bfe75":"model.evaluate(test_ds)","6320b21f":"model.save('.\/CountFinger1.h5')","7bb8520a":"**MobileNet Model and Summary**","7f3bb594":"**Saving Model**","74645e6a":"**Creating List with Image Filemname**","eff3f9af":"**Data PreProcesing Using MobileNet**","496acda9":"**Image**","be5e67da":"**Dataset for Training Testing Validation**","7b0ce148":"**Converting List to Dataframe**","b6b2f19e":"**Seperating Target Value from Filename**","11e1fbc4":"**Model Evaluation with Test Data**","9449ff65":"**Trained Model Summary**"}}