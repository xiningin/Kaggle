{"cell_type":{"238a1d65":"code","e1995391":"code","71e5b9b2":"code","598b5ea6":"code","adf0ad58":"code","6460add1":"code","0223d1f6":"code","343f4f1e":"code","165986b5":"code","10806ea1":"code","71cbb8fd":"code","0b073a21":"code","9b1e978c":"code","824eb787":"code","ce6f49d2":"code","1d3d050a":"code","6bf0245c":"code","d44e7c0c":"code","3510e8c2":"code","b2c951ce":"code","d1c817fe":"code","72708283":"code","470fb8ab":"code","2095a124":"code","075d5ecb":"code","4b68451f":"code","4780b289":"code","1b50eaaf":"code","b1649e28":"code","271b7ffc":"code","aefa5375":"code","99391f4d":"code","920842d7":"markdown","d04a4e42":"markdown","89020c07":"markdown","e3d3b295":"markdown","07b20b8c":"markdown","4e122c6e":"markdown","e52854e6":"markdown","be78ec2c":"markdown","68852f9f":"markdown","1635ead3":"markdown","6bea9a02":"markdown","14a7cc3b":"markdown","25c73499":"markdown","864d13f3":"markdown","043b9a6c":"markdown","573d4730":"markdown","d937435e":"markdown"},"source":{"238a1d65":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nseed = 7\n\n%matplotlib inline\n\ndataset = pd.read_csv('..\/input\/creditcard.csv')\n\nprint('This dataset contains ',dataset.shape[0],'rows')\nprint('This dataset contains ',dataset.shape[1],'columns')","e1995391":"dataset.head()","71e5b9b2":"dataset.info()","598b5ea6":"# Check if NA values are present\ndataset.isnull().sum().sum()","adf0ad58":"# Change the type of the Class column\ndataset.Class = dataset.Class.astype('bool')\n\n# Get the count of each Class\ndataset.groupby('Class').size()","6460add1":"dataset.describe()","0223d1f6":"import seaborn as sns\n\nfrauds = dataset[dataset.Class==True]\ngenuines = dataset[dataset.Class==False]","343f4f1e":"# 'Time' visualization\nsns.distplot(dataset.Time,\n             bins=80, color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 2})\nplt.title('Density plot and Histogram of Time (in seconds)')\nplt.show()","165986b5":"# 'Time' visualization for frauds\nsns.distplot(frauds.Time,\n             bins=80, color = 'darkgreen', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 2})\nplt.title('Density plot and Histogram of Time for Frauds (in seconds)')\nplt.show()","10806ea1":"# 'Amount' visualization\n# According to the Introduction, we assume the currency is Euro\nsns.distplot(dataset.Amount, \n             bins=80, color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 2})\nplt.title('Density plot and Histogram of Amount (in \u20ac)')\nplt.show()","71cbb8fd":"# Ratio of Frauds vs. Amount\namounts = np.linspace(0,5000,1001)\nratios = np.array([])\n\nfor amount in amounts:\n    \n    nbGenuine = len(genuines[genuines.Amount > amount])\n    nbFrauds = len(frauds[frauds.Amount > amount])\n    ratio = 100*nbFrauds\/nbGenuine\n    \n    ratios = np.append(ratios,ratio)\n\nplt.plot(amounts,ratios,'r-')\nplt.title('Ratio #Fraud\/#Genuine vs. Amount')\nplt.xlabel('Amount (in \u20ac)')\nplt.ylabel('Ratio (in %)')\nplt.show()","0b073a21":"from pandas.plotting import scatter_matrix\n\nfig = plt.figure(figsize=(6,6))\nax = fig.add_subplot(111)\ncax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none')\nfig.colorbar(cax)\nplt.show()","9b1e978c":"# We randomly select 492 genuine transactions\ngenuines_sub = genuines.sample(492, random_state=seed)\n\n# dataset_sub is the dataset composed of 492 frauds and of 492 genuine transactions\ndataset_sub = frauds.append(genuines_sub, ignore_index=True)\n\n# We drop the 'Time' column\ndataset_sub = dataset_sub.drop('Time',axis=1)\n\nprint('This sub dataset contains ',dataset_sub.shape[0],'rows')\nprint('This sub dataset contains ',dataset_sub.shape[1],'columns')","824eb787":"dataset_sub.groupby('Class').size()","ce6f49d2":"from sklearn.model_selection import train_test_split\n\n# Predictors\nX = dataset_sub.drop('Class',axis=1)\n\n# Response\ny = dataset_sub.Class\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state = seed)\n\n# Proportion of fraud in train set and test set\nprint('Proportion of fraud in train:',y_train[y_train == True].shape[0]\/X_train.shape[0])\nprint('Proportion of fraud in test:',y_test[y_test == True].shape[0]\/X_test.shape[0])","1d3d050a":"from sklearn.metrics import recall_score, precision_recall_curve, average_precision_score, confusion_matrix, precision_score\n\nscoring = 'average_precision'","6bf0245c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nimport xgboost\n\nmodels = []\nmodels.append(('LR',LogisticRegression(random_state=seed)))\nmodels.append(('LDA',LinearDiscriminantAnalysis()))\nmodels.append(('QDA',QuadraticDiscriminantAnalysis()))\nmodels.append(('SVM',SVC(random_state=seed,gamma='scale')))\n\nensembles = []\nensembles.append(('RF', RandomForestClassifier(random_state=seed,n_estimators=100)))\nensembles.append(('ADA', AdaBoostClassifier(random_state=seed)))\nensembles.append(('GBM', GradientBoostingClassifier(random_state=seed)))\nensembles.append(('XGB', XGBClassifier(random_state=seed)))","d44e7c0c":"# Models evaluation function\ndef get_score_models(model,X_train,X_test,y_train,y_test):\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    \n    # All our models implement the 'decision_function' method\n    # It is not the case of all our ensembles\n    y_score = model.decision_function(X_test)\n    \n    compare(y_test,y_pred,y_score)\n    \n# Ensembles evaluation function\ndef get_score_ensembles(ensemble,X_train,X_test,y_train,y_test):\n    ensemble.fit(X_train,y_train)\n    y_pred = ensemble.predict(X_test)\n    \n    # All our ensembles implement the 'predict_proba' method\n    # It is not the case of all our models\n    y_score = ensemble.predict_proba(X_test)[:,1]\n    \n    compare(y_test,y_pred,y_score)\n\n# Print metrics and graph function\ndef compare(y_test,y_pred,y_score):\n    print('Confusion matrix:')\n    print(confusion_matrix(y_test,y_pred))\n    \n    print('Recall:',recall_score(y_test,y_pred))\n    print('Precision:',precision_score(y_test,y_pred))\n    print('Area under the curve:',average_precision_score(y_test,y_score))\n    \n    precision, recall, _ = precision_recall_curve(y_test, y_score)\n    plt.step(recall, precision, alpha=0.4, color='b', where='post')\n    plt.fill_between(recall, precision, alpha=0.2, color='b', step='post')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0, 1.05])\n    plt.xlim([0, 1])\n    plt.title('Precision-Recall curve')\n    plt.show()","3510e8c2":"# Evaluation of each model\nfor name,model in models:\n    print('----------',name,'----------')\n    get_score_models(model,X_train,X_test,y_train,y_test)","b2c951ce":"# Evaluation of each ensemble method\nfor name,ensemble in ensembles:\n    print('----------',name,'----------')\n    get_score_ensembles(ensemble,X_train,X_test,y_train,y_test)","d1c817fe":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nnum_folds = 10\nkfold = KFold(n_splits=num_folds,random_state=seed)\n\nnames = []\nresults_recall = []\nresults_aupcr = []\nmodels_score = {}\nensembles_score = {}\n\n# Function cross validating and printing Recall and AUPRC results\ndef cross_validation(name,classifier,classifiers_score,results_recall,results_aupcr):\n    cv_results_recall = cross_val_score(model,X_train,y_train,cv=kfold,scoring='recall')\n    cv_results_auprc = cross_val_score(model,X_train,y_train,cv=kfold,scoring=scoring)\n\n    models_score[name] = [cv_results_recall.mean()]\n    models_score[name].append(cv_results_recall.std())\n    models_score[name].append(cv_results_auprc.mean())\n    models_score[name].append(cv_results_auprc.std())\n    \n    results_recall.append(cv_results_recall)\n    results_aupcr.append(cv_results_auprc)\n    names.append(name)\n\n    print('----------',name,'----------')\n    print('Recall:',models_score[name][0],'(',models_score[name][1],')')\n    print('AUPRC:',models_score[name][2],'(',models_score[name][3],')\\n')","72708283":"# 10-Fold cross validation on our models\nfor name,model in models:\n    cross_validation(name,model,models_score,results_recall,results_aupcr)","470fb8ab":"# 10-Fold cross validation on ensembles\nfor name,ensemble in ensembles:\n    cross_validation(name,ensemble,ensembles_score,results_recall,results_aupcr)","2095a124":"# Compare Classifiers regarding Recall\nfig = plt.figure()\nfig.suptitle('Classifiers Recall Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results_recall)\nax.set_xticklabels(names)\nplt.show()","075d5ecb":"# Compare Classifiers regarding the Precision\nfig = plt.figure()\nfig.suptitle('Classifiers AUPRC Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results_aupcr)\nax.set_xticklabels(names)\nplt.show()","4b68451f":"from sklearn.model_selection import GridSearchCV\n\n# Function executing the Grid Search and printing the result\ndef search_param(model,X_train,y_train,param_grid,scoring,kfold):\n    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n    grid_result = grid.fit(X_train, y_train)\n    \n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    means = grid_result.cv_results_['mean_test_score']\n    stds = grid_result.cv_results_['std_test_score']\n    params = grid_result.cv_results_['params']\n    for mean, stdev, param in zip(means, stds, params):\n        print(\"%f (%f) with: %r\" % (mean, stdev, param))","4780b289":"# \/!\\ May take some time\n# SVC Parameters values that will be tested:\nC = [0.001,0.01,0.1,1]\nkernel_values = ['rbf', 'sigmoid', 'linear']\n\nparam_grid = dict(C=C,kernel=kernel_values)\n\nmodel = SVC(random_state=seed,gamma='scale')\n\nsearch_param(model,X_train,y_train,param_grid,scoring,kfold)","1b50eaaf":"# kernel = 'linear'\n# C contained in [0.001;0.01]\nC = np.linspace(0.001,0.01,10)\nparam_grid = dict(C=C)\n\nmodel = SVC(kernel='linear',random_state=seed)\n\nsearch_param(model,X_train,y_train,param_grid,scoring,kfold)","b1649e28":"# Check the Recall for the tuned SVM\nmodel = SVC(kernel='linear',C=0.002,random_state=seed)\ncv_results = cross_val_score(model,X_train,y_train,cv=kfold,scoring='recall')\n\nprint('Recall:',cv_results.mean(),'(',cv_results.std(),')')","271b7ffc":"# \/!\\ Take some time\n# XGBoost Parameters values that will be tested:\nlearning_rate = [0.01,0.1,1]\nn_estimators = [10,100,1000]\nmax_depth = np.linspace(2,5,4).astype('int')\n\nparam_grid = dict(learning_rate=learning_rate,n_estimators=n_estimators,max_depth=max_depth)\n\nmodel = XGBClassifier(random_state=seed)\n\nsearch_param(model,X_train,y_train,param_grid,scoring,kfold)","aefa5375":"# \/!\\ Take some time\n# max_depth = 2\n\nlearning_rate = np.linspace(0.1,1,10)\nn_estimators = np.linspace(10,100,10).astype('int')\n\nparam_grid = dict(learning_rate=learning_rate,n_estimators=n_estimators)\n\nmodel = XGBClassifier(max_depth=2,random_state=seed)\n\nsearch_param(model,X_train,y_train,param_grid,scoring,kfold)","99391f4d":"# Check the Recall for the tuned XGB\nmodel = XGBClassifier(max_depth=2, learning_rate=0.2,n_estimators=60,random_state=seed)\ncv_results = cross_val_score(model,X_train,y_train,cv=kfold,scoring='recall')\n\nprint('Recall:',cv_results.mean(),'(',cv_results.std(),')')","920842d7":"### 2.2.1. When does frauds happen?\n<a id=\"time\"><\/a>\n\n>Hypothesis: Frauds happen at night.","d04a4e42":"**10-Fold cross validation conclusion**\n\n>Classifiers results:\n\n>| Model          | Mean Recall (in %) | Std Recall (in %) | Mean AUPCR (in %) | Std AUPCR (in %) |\n>| :------------  | :-------------:    |   :-------------: | :---------------: | ---------------: |\n>| LR             | 91.3               |              5.74 |              98.3 |             1.14 |\n>| LDA            | 85.3               |              5.15 |              97.3 |             1.72 |\n>| QDA            | 89.8               |              5.34 |              97.9 |             1.21 |\n>| **SVM**        | **92.2**           |              3.94 |              96.4 |             2.61 |\n>| RF             | 88.7               |              4.34 |              97.1 |             1.60 |\n>| ADA            | 91.7               |              5.48 |              98.3 |             1.33 |\n>| GBM            | 90.2               |              5.84 |              98.3 |             1.03 |\n>| **XGB**        | 91.6               |              5.71 |          **98.5** |             1.03 |\n\n>- Again, focused on recall, the SVM classifier get the best score _(on this particular genuine subsample)_. But in the same time, the SVM classifier has the poorest AUPCR.\n\n>- Regarding Area under the Precision-Recall curve, **XGBoost** get the best score _(Note that the Random Forest get poorer results by cross validation)_.\n\n\n## 4.4. Classifiers Tuning\n<a id=\"tuning\"><\/a>\n\n>Before switching to a new configuration of our dataset, let's try to get a better AUPCR for the Support Vector Classifier and the XGBoost by tuning their parameter.\n\n### 4.4.1. SVM Tuning\n<a id=\"svm tuning\"><\/a>\n\n>For the SVM Classifier, the following parameters will be explored:\n- _C_: the penalty of the error term\n- _kernel_: the kernel type used by the algorithm.","89020c07":"## 4.3. Spot Check Algorithms\n<a id=\"50\/50 spot check\"><\/a>\n\n>First, the following classifier would be tested:\n- Logistic Regression\n- Linear Discriminant Analysis\n- Quadratic Discriminant Analysis\n- Support Vector Machine\n\n>Then the following Ensemble methods would be tested:\n- Random Forest\n- Ada Boost\n- Stochastic Gradient Boosting\n- XGBoost","e3d3b295":"### 4.3.1. Train and Test Sets\n<a id=\"50\/50 train test\"><\/a>\n\n>First, we evaluate the performance of our classifier with a direct train-test stragtegy.","07b20b8c":">Proportion should be 50\/50\n\n## 4.2. Set metrics\n<a id=\"50\/50 metrics\"><\/a>\n\n>As evoked in the Introduction, we will use the following metrics:\n- Precision\n- Recall\n- Area under the Precision-Recall Curve\n\n>Confusion matrix will also be used\n\n>**We have to take into account those metrics to find the best compromise in the Recall-Precision trade-off. Here are some extrem cases we want to avoid:**\n- Recall = 1, Precision = 0: the Naive classifier that classify all transactions as Frauds\n- Recall = 0, Precision = 1: the Naive classifier that classify all transactions as Genuines\n- Recall = 0.5, Precision = 0.5: the Random classifier that classify randomly all transactions\n\n>**The Area Under the Precision-Recall Curve (AUPCR) will be our standard metric ([average_precision](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.average_precision_score.html)).**","4e122c6e":"## 4.1. Split-out validation Dataset\n<a id=\"50\/50 split-out\"><\/a>","e52854e6":"**Train-Test Split conclusion**\n\n>Classifiers results:\n\n>| Model          | Recall (in %)  | _AUPRC (in %)_ | _Precision (in %)_ |\n>| :------------  | :------------: | :------------: |   ---------------: |\n>| LR             | 92.2           |           96.7 |             _94.3_ |\n>| LDA            | 85.6           |           92.6 |             _95.1_ |\n>| QDA            | 94.4           |           98.0 |             _92.4_ |\n>| SVM            | **97.8**       |           94.7 |             _84.6_ |\n>| **RF**         | 94.4           |       **98.4** |             _95.5_ |\n>| ADA            | 95.6           |           98.1 |             _91.5_ |\n>| GBM            | 92.2           |           94.5 |             _95.4_ |\n>| **XGB**        | 94.4           |       **98.4** |             _94.4_ |\n\n>- Focused on Recall, the SVM classifier get the best score _(on this particular Train-Test split)_. But in the same time, the SVM classifier has one of the poorest precision rate.\n\n>- Regarding the Area under the Precision-Recall curve, **Random Forest** and **XGBoost** get the best score.\n\n### 4.3.2. K-Fold cross validation\n<a id=\"50\/50 kfold\"><\/a>\n\n>Now, we evaluate the performance of our classifiers with a 10-Fold cross validation.","be78ec2c":">'V' predictors are not correlated to each other. Indeed, as Principal Components, there are orthogonal to each other.\n\n>The 'blurred' border is due to column 'Time', 'Amount' and 'Class': there are no significant correlation between the variables.\n\n# 3. Prepare Dataset\n<a id=\"prepare dataset\"><\/a>\n\n## 3.1. Feature Selection\n<a id=\"feature selection\"><\/a>\n\n>'V1' to 'V28' have already been preprocessed. We will use them as predictors. We have to decide if we use 'Time' and 'Amount' as predictors:\n- As it is, 'Time' does not seem very relevant.\n- As it is, 'Amount' should already brings information.\n\n## 3.2. Data Transforms\n<a id=\"data transforms\"><\/a>\n\n>We will not apply any transformation to variables 'V1', 'V2', ... , 'V28'.\n>'Time' and 'Amount' could be transformed:\n- 'Time' could be use to set a new boolean variable called 'Day' (_True_ for Day, _False_ for Night, cf.[previousely](#time)). So regarding the 'Time' variable, we could either:\n    1. Not use it\n    2. Or replace it by 'Day' \n- 'Amount' could be use:\n    1. As it is\n    2. Normalized\n    3. Standardized\n    \n## 3.3. Subsampling\n<a id=\"subsampling\"><\/a>\n\n>To continue our analysis of the dataset, we could:\n1. Use the whole dataset as it is: so no sampling\n2. Create a new dataset composed of the 492 frauds and of 492 random genuine transactions (50\/50 sampling). If so, we would have to ensure that the 492 random genuine transactions are representative of the genuine transactions...\n3. A way to manage this  would be to resample 492 genuine transactions randomly N times and to compare results.\n\n>So different configurations for our dataset are possible regarding 'Time', 'Amount' and subsampling:\n\n>| 'Time'               | 'Amount'        |      Subsampling |\n>| :------------        | :-------------: | -------------:   |\n>| Not use it           | As it is        |               No |\n>| Replace it by 'Day'  | Normalized      |            50\/50 |\n>|                      | Standardized    |    N times 50\/50 |\n\n>If you are curious about which configuration brings the best results, go for it!\n\n>Next in this notebook, we will explore one of those configuration.\n\n# 4. 50\/50 Dataset\n<a id=\"50\/50 dataset\"><\/a>\n\n>As a first step in this analysis, we will use the following highlighted configuration for our dataset:\n\n>| 'Time'               | 'Amount'        |      Subsampling |\n>| :------------        | :-------------: | -------------:   |\n>| _**Not use it**_     | _**As it is**_  |             No   |\n>| Replace it by 'Day'  | Normalized      |      _**50\/50**_ |\n>|                      | Standardized    |  N times 50\/50   |\n\n>Let's create the new dataset.","68852f9f":"# Credit Card Fraud Detection\n\n# Introduction\n\nThe dataset contains 284,807 transactions made by credit cards during two days of September 2013 by european cardholders.<br>\nCredit card companies need to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n\n**Goal**<br>\nBuild a predictive model to identify fraudulent credit card transactions (supervised binary classification problem).\n\n**Data**<br>\nAccording to the Kaggle 'Overview' tab:\n- Features V1, V2, ... V28 are the principal components obtained by PCA\n- Feature 'Time' contains the seconds elapsed between a transaction and the first transaction in the dataset\n- Feature 'Amount' is the transaction Amount\n- Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n\n**Metric**<br>\nThe dataset is highly unbalanced:\n- 492 fraudulent transactions vs. 284,315 genuines\n- So the positive class (Frauds) account for 0.172% of all transactions.\n\n1. First, we want to catch frauds. It means: minimizing the False Negative rate\n> Recall\n2. Then we want to minimize the False Positive rate\n> Precision\n\n    **The Area under the Precision-Recall curve is the compromise metrics in this Precision-Recall trade-off.**<br>\n   \n<br>\n\n**Outline**<br>\n\n1. [Load Dataset](#load dataset)<br>\n\n2. [Summarize Dataset](#summarize dataset)<br>\n2.1. [Descriptive Statistics](#descriptive statistics)<br>\n2.2. [Data Visualization](#data visualization)<br>\n2.2.1. [When does frauds happen?](#time)<br>\n2.2.2. [What is the amount of a fraud transaction?](#amount)<br>\n2.2.3. [Correlations](#correlations)<br>\n\n3. [Prepare Dataset](#prepare dataset)<br>\n3.1. [Feature selection](#feature selection)<br>\n3.2. [Data Transform](#data transforms)<br>\n3.3. [Subsampling](#subsampling)<br>\n\n4. [50\/50 Dataset](#50\/50 dataset)<br>\n4.1. [Split-out validation Dataset](#50\/50 split-out)<br>\n4.2. [Set Metrics](#50\/50 metrics)<br>\n4.3. [Spot Check Algorithms](#50\/50 spot check)<br>\n4.3.1. [Train and Test Sets](#50\/50 train test)<br>\n4.3.2. [K-Fold cross validation](#50\/50 kfold)<br>\n4.4. [Classifiers Tuning](#tuning)<br>\n4.4.1. [SVM Tuning](#svm tuning)<br>\n4.4.2. [XGBoost Tuning](#xgb tuning)<br>\n4.5 [Conclusion](#50\/50 conclusion)<br>\n\n# 1. Load dataset\n<a id=\"load dataset\"><\/a>","1635ead3":">Density is more flat for frauds. So the proportion of frauds may be higher at night.\n\n### 2.2.2. What is the amount of a fraud transaction?\n<a id=\"amount\"><\/a>\n\n>Hypothesis: the higher an amount is, the more likely the transaction is fraudulent.","6bea9a02":"> A day is 86,400 seconds so we can recongnize the 2 days of transactions. Each top of slope correspond to a day and each valley correspond to a night.","14a7cc3b":"> With (kernel='linear', C = 0.002), SVM Classifier get 98.6% AUPRC.","25c73499":">Contrary to what we could believe, a large amount in a transaction does not involve that it is a fraud.\n\n### 2.2.3. Correlations\n<a id=\"correlations\"><\/a>","864d13f3":"## 2.2. Data Visualization\n<a id=\"data visualization\"><\/a>","043b9a6c":"> Default SVM Classifier scores (C = 1.0, kernel = 'rbf'):\n- AUPCR: 96.4 % (_2.61_ %)\n- Recall: **92.2** % (_3.94_ %)\n\n> Tuned SVM Classifier scores (C = 0.002, kernel = 'linear'):\n- AUPCR: **98.6** % (_1.03_ %)\n- Recall: 85.9 % (_4.75_ %)\n\n### 4.4.2. XGBoost Tuning\n<a id=\"xgb tuning\"><\/a>\n\n>For the XGBoost Classifier, the following parameters will be explored:\n- *learning_rate*: the Boosting learning rate (xgb\u2019s 'eta')\n- *n_estimators*: the Number of boosted trees to fit\n- *max_depth*: the maximum tree depth for base learners.","573d4730":"> Default XGB Classifier scores (max_depth = 3, learning_rate = 0.1, n_estimators = 100):\n- AUPCR: 98.5 % (_1.03_ %)\n- Recall: **91.6** % (_5.71_ %)\n\n> Tuned XGB Classifier scores (max_depth = 2, learning_rate = 0.2, n_estimators = 60):\n- AUPCR: **98.7** % (_0.93_ %)\n- Recall: 91.1 % (_5.95_ %)\n\n** Part 4 (50\/50 Dataset) Conclusion:**\n<a id=\"50\/50 conclusion\"><\/a>\n\nIn this part, we randomly selected half of the dataset as genuine transactions, the other half being frauds.\n\nWe were aware of the importance of the Recall, to identify fraudulent transactions and minimize False Negative rate.\n\nBut we also were aware of the Area under the Precision-Recall curve, to avoid the False Positive rate to skyrocket.\n\n(_False Positive: Genuine transactions classify as Frauds_)\n(_False Negative: Frauds classify as enuine transactions_)\n\nEight classifiers have been trained, by direct Train-Test split and then by cross-validation, to get more reliable results.\n\nWe shortlisted the one with the best mean Recall (Support Vector Classifier with 92.2 %) and the one with the best mean Area under the Precision-Recall curve (XGBoost Classifier with 91.6 %).\n\nBy tuning their parameters, we were able to increase the AUPRC metric, often at the expense of the Recall:\n- Standard SVM: Lowest AUPRC (96.4%) but best Recall (92.2%)\n- Tuned XGBoost: Best AUPRC (98.7%) with a high Recall (91.1%)\n- Standard XGBoost: Both high AUPRC (98.5%) and Recall (91.6%)\n- Tuned SVM: Very high AUPRC (98.6%) but lowest Recall (85.9%)\n\nNote: On my side, I also tuned SVM and XGB with the Recall as the scoring metric. This leads to a very high Recall (~98%) but the AUPRC drops (~50%).\n\nThank you for reading this notebook. Part 5 will come later.","d937435e":"> There is no 'NA' values.\n\n> The dataset is unbalanced.\n\n# 2. Summarize Data\n<a id=\"summarize dataset\"><\/a>\n\n## 2.1. Descriptive Statistics\n<a id=\"descriptive statistics\"><\/a>"}}