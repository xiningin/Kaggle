{"cell_type":{"1528afe3":"code","48995447":"code","3fc7d459":"code","aeb7ed67":"code","f9a79269":"code","4726abd9":"code","f7806caa":"code","6d2a4772":"code","e2c11cfe":"code","2b584baf":"code","dbba9599":"code","3a4c2592":"code","8a50836f":"code","d8b2219e":"code","2bd8cf2c":"code","2cdc6b03":"code","24be8646":"code","0d4d8615":"code","3b946dbd":"code","840e2580":"code","fbe4d709":"code","df1963d1":"code","8a7b458e":"code","91d7d6b0":"markdown","4e76b73c":"markdown","6bec0e67":"markdown","73defdf3":"markdown","15c664a4":"markdown"},"source":{"1528afe3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","48995447":"# To enable the autocomplete\n%config Completer.use_jedi = False","3fc7d459":"train_ds_path = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ntest_ds_path  = \"\/kaggle\/input\/digit-recognizer\/test.csv\"","aeb7ed67":"# Load the dataset\ndf_train = pd.read_csv(train_ds_path)\ny = df_train.iloc[:,0]\nx = df_train.iloc[:,1:]","f9a79269":"y.hist()","4726abd9":"def view_images(flat_images, labels, show_n_imgs = 10):\n    images = np.array(flat_images, dtype=\"uint8\").reshape(-1, 28, 28,1)\n    \n    plt.figure(figsize=(20,20))\n    plt.subplots_adjust(hspace=1)\n    for i, img in enumerate(images[:show_n_imgs]):\n        plt.subplot(10,5,i+1)\n#         plt.axis('off')\n        plt.imshow(img, cmap = 'gray')\n        plt.title(labels[i])","f7806caa":"x.head()","6d2a4772":"view_images(x, y, 20)","e2c11cfe":"x = x \/ 255.0","2b584baf":"x_train , x_valid ,y_train , y_valid = train_test_split(x,y,test_size = 0.25)","dbba9599":"import tensorflow as tf\nfrom tensorflow import keras","3a4c2592":"def fcModel(input_shape):\n    \n    X_input = keras.layers.Input(shape = input_shape, name='input')\n    \n    X = keras.layers.Dense(units=64, name='layer-1')(X_input)\n    X = keras.layers.BatchNormalization(name='b-1')(X)\n    X = keras.layers.Activation('relu')(X)\n    \n    X = keras.layers.Dropout(0.2)(X)\n    X = keras.layers.Dense(units=64, name='layer-2')(X)\n    X = keras.layers.BatchNormalization(name='b-2')(X)\n    X = keras.layers.Activation('relu')(X)\n    \n    X = keras.layers.Dropout(0.1)(X)\n    X = keras.layers.Dense(units=128, name='layer-3')(X)\n    X = keras.layers.BatchNormalization(name='b-3')(X)\n    X = keras.layers.Activation('relu')(X)\n    \n    X = keras.layers.Dropout(0.1)(X)\n    X = keras.layers.Dense(units=32, name='layer-4')(X)\n    X = keras.layers.BatchNormalization(name='b-4')(X)\n    X = keras.layers.Activation('relu')(X)\n    \n    X = keras.layers.Dense(units=10, activation='softmax', name='output')(X)\n    \n    model = keras.Model(inputs = X_input, outputs = X, name = \"Simple_Model\")\n    \n    return model","8a50836f":"model = fcModel(x_train.values.shape[1])\nmodel.summary()","d8b2219e":"model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","2bd8cf2c":"history = model.fit(x_train, y_train, epochs=30, batch_size= 128, validation_data=(x_valid, y_valid))","2cdc6b03":"history_dic = history.history\nhistory_dic.keys()","24be8646":"loss_values = history_dic['loss']\nval_loss_values = history_dic['val_loss']\nepochs = range(1, len(loss_values)+1)\n\nplt.plot(epochs, loss_values, 'b-', label='Train')\nplt.plot(epochs, val_loss_values, 'y-', label='Validation')\n\nplt.ylim([-0.01, 0.5])\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","0d4d8615":"accuracy_values = history_dic['accuracy']\nval_accuracy_values = history_dic['val_accuracy']\nepochs = range(1, len(accuracy_values)+1)\n\nplt.plot(epochs, accuracy_values, 'b-', label='Train')\nplt.plot(epochs, val_accuracy_values, 'y-', label='Validation')\n\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","3b946dbd":"preds = model.evaluate(x = x_valid, y = y_valid)\nprint(\"Loss\", preds[0])\nprint(\"Accuracy\", preds[1])","840e2580":"y_pred = model.predict(x_valid)\ny_pred = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_true = y_valid, y_pred = y_pred))","fbe4d709":"df_test = pd.read_csv(test_ds_path)\nx_test = df_test.iloc[:,:] \/ 255.0","df1963d1":"y_pred = model.predict(x_test)\ny_pred = np.argmax(y_pred, axis=1)\nsubmit = pd.DataFrame({\"Label\":y_pred}, index=np.arange(1,len(y_pred)+1))\nsubmit.index.name = \"ImageId\"\n\nsubmit.to_csv('submission.csv')\n\nsubmit.head()","8a7b458e":"start = 30\nview_images((x_test*255.0)[start:], y_pred[start:], 10)","91d7d6b0":"# Splitting the dataset into train and validation","4e76b73c":"## Training","6bec0e67":"# About the dataset\n\n- The images are organized in line vectors and each sample (image) of the dataset occupies one line of the set. Each line of the dataset has 784 columns(28*28) in order to represent each pixel value of the image.\n- The image's pixels are value in [0,255]","73defdf3":"# Submit","15c664a4":"# The model"}}