{"cell_type":{"499ebb4d":"code","d37de53d":"code","0fadd842":"code","e073ddc7":"code","3388eb5c":"code","8eb08ee4":"code","3c0de90e":"code","90dbc2b2":"code","23b8ea03":"code","872da790":"code","4a995c9d":"code","684c49f2":"code","3c371f72":"code","07682045":"code","530a2179":"code","4dc7d9d1":"code","f4c02d94":"code","e336fedd":"code","bec22668":"code","4ada0c86":"code","07c0412c":"code","eb4078cd":"code","c8de51ce":"code","e65063d5":"code","0514ab6e":"code","d4f7ff5b":"code","e0f75630":"code","420e20eb":"code","e37677fa":"code","308def6e":"code","559c8b3d":"code","a4287ad9":"code","3131d683":"code","b960b8ec":"code","7ff52e25":"code","8b00f8ca":"code","d5420eb8":"code","7eb425ac":"code","6cad71d4":"code","3bea508b":"code","02a6918a":"code","7c2b8aa5":"code","a8087dbc":"code","b43d7981":"code","b30e2ed8":"code","0d0e8e52":"markdown","4b8e4460":"markdown","33426886":"markdown","a3a7f4d8":"markdown","51b0635f":"markdown","6b0fa3ee":"markdown","5c3e77be":"markdown","d6623324":"markdown","2cb880e6":"markdown","1f138a9f":"markdown","2d65186d":"markdown","0d8b1f52":"markdown","e38237e8":"markdown","7bdaff89":"markdown","d6863293":"markdown","f28fc621":"markdown","9cbc884a":"markdown","17f51a2b":"markdown","cf925e29":"markdown","c0593e4d":"markdown","7d795885":"markdown","9c7a007f":"markdown","b6bc85dc":"markdown","a2f8b5b5":"markdown","4c905213":"markdown","8fe2379d":"markdown","f5cc278c":"markdown","9159b6ed":"markdown","e144108c":"markdown"},"source":{"499ebb4d":"# 786\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objs as go\n\nimport plotly as py\nfrom plotly import tools\nfrom plotly.offline import iplot\npy.offline.init_notebook_mode(connected = True)\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d37de53d":"dt = pd.read_csv(\"..\/input\/pakistans-largest-ecommerce-dataset\/Pakistan Largest Ecommerce Dataset.csv\", parse_dates=[\"created_at\", \"Working Date\"], low_memory=False)\nprint(\"Data Dimensions are: \", dt.shape)\nprint(\"Columns: \", dt.columns)","0fadd842":"print(dt.info())","e073ddc7":"dt = dt.iloc[:, :-5]\ndt = dt.dropna(how = 'all') ","3388eb5c":"dt.rename(columns = {' MV ':'MV'}, inplace = True)\ndt.columns","8eb08ee4":"dt['Customer ID'] = dt['Customer ID'].astype(str)\ndt['item_id'] = dt['item_id'].astype(str)\ndt['qty_ordered'] = dt['qty_ordered'].astype(int)  \ndt['Year'] = dt['Year'].astype(int)  \ndt['Month'] = dt['Month'].astype(int)  \n# dt['MV'] = dt['MV'].astype(float, errors = 'raise')","3c0de90e":"dt.tail()","90dbc2b2":"dt.describe()","23b8ea03":"dt.describe(include=['object', 'bool'])","872da790":"dt = dt.sort_values('created_at')","4a995c9d":"dtg = dt.groupby('created_at')['grand_total'].sum().reset_index()\ndtq = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\ndtd = dt.groupby('created_at')['discount_amount'].sum().reset_index()\n# comput count for non numeric values\ndts = dt.groupby('created_at')['sku'].count().reset_index() \ndtst = dt.groupby('created_at')['status'].count().reset_index()","684c49f2":"# new data set\np = pd.DataFrame(dtg) \np['qty_ordered'] = dtq['qty_ordered']\np['discount_amount'] = dtd['discount_amount']\np['sku'] = dts['sku']\np['status'] = dtst['status']\n#Cumulative Sum\np['cum_grand_total'] = p['grand_total'].cumsum()\np['cum_qty_ordered'] = p['qty_ordered'].cumsum()\np['cum_discount_amount'] = p['discount_amount'].cumsum()\np['cum_sku_cnt'] = p['sku'].cumsum()\np['cum_status_cnt'] = p['status'].cumsum()\n","3c371f72":"# Date features\np['Dateofmonth'] = p['created_at'].dt.day\np['Month'] = p['created_at'].dt.month\np['Week'] = p['created_at'].dt.week\np['Dayofweek'] = p['created_at'].dt.dayofweek # 0 = monday.\np['Weekdayflg'] = (p['Dayofweek'] \/\/ 5 != 1).astype(float)\np['Month'] = p['created_at'].dt.month\np['Quarter'] = p['created_at'].dt.quarter\np['Dayofyear'] = p['created_at'].dt.dayofyear","07682045":"p.head()","530a2179":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['grand_total'],\n                    mode='lines+markers',\n                    name='grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['discount_amount'],\n                    mode='lines+markers',\n                    name='discount_amount'))\nfig.show()","4dc7d9d1":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['cum_grand_total'],\n                    mode='lines+markers',\n                    name='xcum_grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['cum_discount_amount'],\n                    mode='lines+markers',\n                    name='cum_discount_amount'))\nfig.show()","f4c02d94":"n = dt.groupby(['Year' ,'status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"Year\", y=\"grand_total\", color=\"status\", title=\"Long-Form Input\")\nfig.show()","e336fedd":"n = dt.groupby(['Year' ,'payment_method'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"Year\", y=\"grand_total\", color=\"payment_method\", title=\"Long-Form Input\")\nfig.show()","bec22668":"n = dt.groupby(['status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, y='grand_total', x='status', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","4ada0c86":"n = dt.groupby(['created_at' ,'status'])['grand_total'].sum().reset_index()\npx.box(n, y=\"grand_total\", color = \"status\")","07c0412c":"n = dt.groupby(['category_name_1'])['grand_total'].sum().reset_index()\nfig = px.bar(n, y='grand_total', x='category_name_1', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","eb4078cd":"n = dt.groupby(['category_name_1','status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"category_name_1\", y=\"grand_total\",\n             color='status', barmode='group')\nfig.show()","c8de51ce":"n = dt.groupby(['payment_method'])['grand_total'].sum().reset_index()\n\nfig = px.bar(n, y='grand_total', x='payment_method', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","e65063d5":"ord_cncl_ind = dt[dt['status'] == 'canceled' ].index\ndt.drop(ord_cncl_ind , inplace=True)\ndt.shape","0514ab6e":"dtg = dt.groupby('created_at')['grand_total'].sum().reset_index()\ndtq = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\ndtd = dt.groupby('created_at')['discount_amount'].sum().reset_index()\n# comput count for non numeric values\ndts = dt.groupby('created_at')['sku'].count().reset_index() \ndtst = dt.groupby('created_at')['status'].count().reset_index()\n\n# new data set\np = pd.DataFrame(dtg) \np['qty_ordered'] = dtq['qty_ordered']\np['discount_amount'] = dtd['discount_amount']\np['sku'] = dts['sku']\np['status'] = dtst['status']\n#Cumulative Sum\np['cum_grand_total'] = p['grand_total'].cumsum()\np['cum_qty_ordered'] = p['qty_ordered'].cumsum()\np['cum_discount_amount'] = p['discount_amount'].cumsum()\np['cum_sku_cnt'] = p['sku'].cumsum()\np['cum_status_cnt'] = p['status'].cumsum()\n","d4f7ff5b":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['grand_total'],\n                    mode='lines+markers',\n                    name='grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['discount_amount'],\n                    mode='lines+markers',\n                    name='discount_amount'))\nfig.show()","e0f75630":"fig = px.scatter(p, x= 'created_at', y = 'grand_total', trendline = \"ols\")\nfig.show()\nresults = px.get_trendline_results(fig)\nresults","420e20eb":"n = dt.groupby('created_at')['grand_total'].sum().reset_index()\npx.density_contour(n,x=\"created_at\",y=\"grand_total\",marginal_x=\"histogram\",marginal_y=\"histogram\")","e37677fa":"# Graph for quantity\nn = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\npx.density_contour(n,x=\"created_at\",y=\"qty_ordered\",marginal_x=\"histogram\",marginal_y=\"histogram\", title=\"no of orders\")","308def6e":"n = dt.groupby(['created_at' ,'category_name_1', 'status'])['qty_ordered'].sum().reset_index()\npx.scatter(n, x=\"created_at\", y=\"qty_ordered\", color=\"status\", size=\"qty_ordered\", hover_data=['category_name_1','status'])\n","559c8b3d":"n = dt.groupby(['created_at' ,'status'])['qty_ordered'].sum().reset_index()\npx.line(n, x=\"created_at\", y=\"qty_ordered\", color=\"status\", )","a4287ad9":"pa = pd.DataFrame(dt)\n# pa.reset_index(inplace=True)\npa.drop(pa[pa.status==\"canceled\"].index,inplace=True) #dropping cancelled orders\ndf = pd.DataFrame(pa)\n#adding few more date features\ndf[\"month_name\"] = df[\"created_at\"].dt.month_name()\ndf[\"week_day_name\"] = df[\"created_at\"].dt.day_name()\ndf[\"week_day\"] = df[\"created_at\"].dt.weekday\ndf[\"week\"] = df[\"created_at\"].dt.isocalendar().week\ndf[\"month_start\"] = df[\"created_at\"].dt.is_month_start\ndf[\"month_end\"]= df[\"created_at\"].dt.is_month_end\ndf[\"quarter\"] = df[\"created_at\"].dt.quarter\ndf[\"quarter_start\"] = df[\"created_at\"].dt.is_quarter_end\ndf[\"quarter_end\"]= df[\"created_at\"].dt.is_quarter_start\n\ndf[\"year_start\"] = df[\"created_at\"].dt.is_year_start\ndf[\"year_end\"] = df[\"created_at\"].dt.is_year_end\ndf[\"month\"] = df[\"created_at\"].dt.month\ndf.columns = df.columns.str.lower()","3131d683":"quarterly = df[[\"grand_total\",\"discount_amount\"]].groupby(df.quarter).sum() # Extracting quarterly turnover \nfig = px.bar(quarterly,x=quarterly.index,y=[\"grand_total\",\"discount_amount\"], title=\"Quaterly Turnover\")\nfig.show()","b960b8ec":"monthly = df[[\"grand_total\",\"discount_amount\"]].groupby(df.month_name).sum() #Extracting monthly turnover \nfig = px.bar(monthly,x=monthly.index,y=[\"grand_total\",\"discount_amount\"], title=\"Monthly Turnover\")\nfig.show()","7ff52e25":"weekday = df[[\"grand_total\",\"discount_amount\"]].groupby(df.week_day_name).sum() # Extracting day wise \nfig = px.bar(weekday,x=weekday.index,y=[\"grand_total\",\"discount_amount\"], title=\"Day-wise Turnover\")\nfig.show()","8b00f8ca":"month_end = df[[\"grand_total\",\"discount_amount\"]].groupby(df.month_end).sum() \nfig = px.bar(month_end,x=month_end.index,y=[\"grand_total\",\"discount_amount\"], title=\"Month end days vs otherdays\")\nfig.show()","d5420eb8":"year = df[[\"grand_total\",\"discount_amount\"]].groupby(df.year).sum() # Extracting year wise \nfig = px.bar(year,x=year.index,y=[\"grand_total\",\"discount_amount\"], title=\"Yearly Turnover\")\nfig.show()","7eb425ac":"y_2016 = df.groupby([df.year,df.category_name_1]).grand_total.sum().loc[2016].nlargest(10)\ny_2017 = df.groupby([df.year,df.category_name_1]).grand_total.sum().loc[2017].nlargest(10)\ny_2018 = df.groupby([df.year,df.category_name_1]).grand_total.sum().loc[2018].nlargest(10)","6cad71d4":"from plotly.subplots import make_subplots\n\n# Create subplots, using 'domain' type for pie charts\nspecs = [[{'type':'domain'}, {'type':'domain'}], [{'type':'domain'}, {'type':'domain'}]] #adopted from https:\/\/plotly.com\/python\/pie-charts\/\nfig = make_subplots(rows=2, cols=2, specs=specs) \n# Define pie charts\nfig.add_trace(go.Pie(labels=y_2016.index, values=y_2016, title='2016'), 1, 1)\nfig.add_trace(go.Pie(labels=y_2017.index, values=y_2017, title='2017'), 1, 2)\nfig.add_trace(go.Pie(labels=y_2018.index, values=y_2018, title='2018'), 2, 1)\n# Tune layout and hover info\n# fig.update_traces(hoverinfo='label+percent+name', textinfo='none')\nfig.update(layout_title_text= \"Yearly share of Top Ten Categories by Grand Total\",\n           layout_showlegend=True)\nfig.show()","3bea508b":"df.payment_method =  df.payment_method.str.lower()\ny_2016pm = df.groupby([df.year,df.payment_method]).grand_total.sum().loc[2016].nlargest(10)\ny_2017pm = df.groupby([df.year,df.payment_method]).grand_total.sum().loc[2017].nlargest(10)\ny_2018pm = df.groupby([df.year,df.payment_method]).grand_total.sum().loc[2018].nlargest(10)","02a6918a":"# Create subplots, using 'domain' type for pie charts\nspecs = [[{'type':'domain'}, {'type':'domain'}], [{'type':'domain'}, {'type':'domain'}]] #adopted from https:\/\/plotly.com\/python\/pie-charts\/\nfig = make_subplots(rows=2, cols=2, specs=specs) \n# Define pie charts\n\nfig.add_trace(go.Pie(labels=y_2016pm.index, values=y_2016pm, title='2016'), 1, 1)\nfig.add_trace(go.Pie(labels=y_2017pm.index, values=y_2017pm, title='2017'), 1, 2)\nfig.add_trace(go.Pie(labels=y_2018pm.index, values=y_2018pm, title='2018'), 2, 1)\n# Tune layout and hover info\nfig.update_traces(hole=.4, hoverinfo='label+percent+name',)\nfig.update(layout_title_text= \"Most used payments methods for each year\",\n           layout_showlegend=True)\nfig.show()","7c2b8aa5":"dto = df.groupby(\"created_at\").sum()[[\"grand_total\",\"discount_amount\"]] # aggregating sum day-wise\ndto[\"opd\"] = df.groupby(\"created_at\").size() # extracting daily count for orders\n# Simple Moving Average for Grand total \ndto[\"3 Days Moving Average\"] = dto.opd.rolling(3).mean() # Window = 3 days\ndto[\"7 Days Moving Average\"] = dto.opd.rolling(7).mean() # Window = 3 days\ndto[\"twenty_1_sma\"] = dto.opd.rolling(window=21).mean() # Window = 3 days\n# Exponentialy weighted moving avg\nalpha=0.2\ndto[\"EWM_Avg\"] = dto.opd.ewm(alpha=alpha).mean()","a8087dbc":"from plotly.subplots import make_subplots\nsubplot_titles = [\"3 days Simple Moving Average\",\"7 days Simple Moving Average\", \n                  \"21 days Simple Moving Average\",\n                 f\"Exponential weighted moving average with Alpha = {alpha}\"]\nfig = make_subplots(rows=4, cols=1,shared_yaxes=False,shared_xaxes=True,vertical_spacing=0.1,\n                    subplot_titles=subplot_titles)\nfig.add_scatter(x=dto.index, y=dto.opd, row=1, col=1, name=\"Orders Per Day\")\nfig.add_scatter(x=dto.index, y=dto[\"3 Days Moving Average\"], name=\"3 Days MA\",row=1, col=1)\nfig.add_scatter(x=dto.index, y=dto.opd, row=2, col=1, name=\"Orders Per Day\")\nfig.add_scatter(x=dto.index, y=dto[\"7 Days Moving Average\"], name=\"7 Days MA\",row=2, col=1)\nfig.add_scatter(x=dto.index, y=dto.opd,name=\"Orders Per Day\", row=3, col=1)\nfig.add_scatter(x=dto.index, y=dto.twenty_1_sma,name=\"21 Days MA\", row=3, col=1)\nfig.add_scatter(x=dto.index, y=dto.opd,name=\"Orders Per Day\", row=4, col=1)\nfig.add_scatter(x=dto.index, y=dto.EWM_Avg,name=\"EMW Average\", row=4, col=1)\nfig.update_layout(height=900,width=850, showlegend=True,\n                  title_text=\"Moving Average Analysis for Order Count\",\n                 legend=dict( orientation=\"v\"))\nfig.show()","b43d7981":"# Simple Moving Average for Grand total \ndto[\"tdayma_gt\"] = dto.grand_total.rolling(window=3).mean()  # window = 3 days\ndto[\"sdayma_gt\"] = dto.grand_total.rolling(window=7).mean() # window = 7 days\ndto[\"twenty_1_sma_gt\"] = dto.grand_total.rolling(window=21).mean() # Window = 21 days\n# Exponentialy weighted moving avg\nalpha=0.2 # setting aplha equal to 0.2 \ndto[\"EWM_Grand_Total\"] = dto.grand_total.ewm(alpha=alpha).mean() ","b30e2ed8":"fig = make_subplots(rows=4, cols=1,shared_yaxes=False,shared_xaxes=True,vertical_spacing=0.1,\n                   subplot_titles=subplot_titles)\nfig.add_scatter(x=dto.index, y=dto.grand_total, row=1, col=1, name=\"Daily Grand Total\")\nfig.add_scatter(x=dto.index, y=dto.tdayma_gt, name=\"3 Days MA for Grand Total\",row=1, col=1)\nfig.add_scatter(x=dto.index, y=dto.grand_total, row=2, col=1, name=\"Daily Grand Total\")\nfig.add_scatter(x=dto.index, y=dto.sdayma_gt, name=\"7 Days MA for Grand Total\",row=2, col=1)\nfig.add_scatter(x=dto.index, y=dto.grand_total,name=\"Daily Grand Total\", row=3, col=1)\nfig.add_scatter(x=dto.index, y=dto.twenty_1_sma_gt,name=\"21 Days Moving Average\", row=3, col=1)\nfig.add_scatter(x=dto.index, y=dto.grand_total,name=\"Daily Grand Total\", row=4, col=1)\nfig.add_scatter(x=dto.index, y=dto.EWM_Grand_Total,name=\"EMW Average\", row=4, col=1)\nfig.update_layout(height=900,width=850, showlegend=True,\n                  title_text=\"Moving Average Analysis for Grand Total\",\n                 legend=dict( orientation=\"v\",yanchor='top',xanchor=\"left\"))\nfig.show()","0d0e8e52":"### Let's look into summary of data\nData Summary of non-numeric data","4b8e4460":"**In each year order cancellation is high. We need to drop Cancelled items and recheck sales growth**\n\nNote: We will do this after looking into other data points. ","33426886":"# Exploratory Analysis to Understand Data","a3a7f4d8":"Data Summary of non-numeric data","51b0635f":"As we can see above, few columns are not in correct data type. We need to perform casting.","6b0fa3ee":"# Quarterly, Monthly, Weekday and Weekend Analysis","5c3e77be":"### Category Type","d6623324":"# Top Ten Categories in each Year","2cb880e6":"#  Unveiling Mean reverting behaviour \n\nThe Growth analysis unravel some interesting patterns in daily order count.However, one may ask does \norder count keep on growing persistently. Mainly, is there any mean reverting behavior. In simple words,if a time series exibhit mean reversion it plunges to its long-run or shor run average value. \nThe average value act as a magnetic force, pulling the series towards it. In order to unveil mean reverting behaviour we will carry on some moving average analysis.","1f138a9f":"**In above graphs we can observe that sales boosted when discount offer initiated.**\n\nBut this can we tempting without looking into item status.","2d65186d":"# Moving Average Analysis for daily orders count","0d8b1f52":"The column MV contains leading and trailing space that might cause problem. We will rename it first.","e38237e8":"## Payment Methods\n","7bdaff89":"As we analysed above, we need to drop cancelled orders\n","d6863293":"## A quick view of Regession model (OLS)","f28fc621":"## Growth Analysis","9cbc884a":"To be Continue...\n\n**You can fork this kernel and continue your analysis.**\n\n**Way Forward**\n* Data Cleansing at SKU and Status columns\n* Segregate analysis by dropping Cancel status orders. \n* Quarterly, Monthly, Weekday and Weekend Analysis\n* Seasonality Analysis\n* What are the Trends in Top 10 Categories\n* Weekly Moving Average Analysis","17f51a2b":"Data contains 1048574 rows but maximum columns contain 584524 records. \n\nHalf of row are completely empty, so we will drop them. The tricky part is we can't drop all na rows as actual data set  also contain few NA entries. We need to keep them.\nWe will drop NA values where all entries are Null. \n\nAlso, we will drop last 5 empty columns.","cf925e29":"# Work in progress..... more to come","c0593e4d":"### Few new features extracted","7d795885":"# Recomputing daily figures","9c7a007f":"### Cumulative Sums of Grand_Total and discount_amount","b6bc85dc":"# Moving Average analysis clearly indicates that both series  daily order counts  and daily grand total kept on hovering around average value hence exbiting mean reversion. ","a2f8b5b5":"# Moving Average Analysis for daily Grand total (Turnover)","4c905213":"## Daily Sales vs. Discount","8fe2379d":"### Order Status","f5cc278c":"# Top (10)  most preferable payment methods","9159b6ed":"### Density Graph","e144108c":"# Data Loading & Preparation"}}