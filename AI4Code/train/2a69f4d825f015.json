{"cell_type":{"70b035df":"code","ded5b8a1":"code","6d51d4c3":"code","c7ef84ad":"code","ceed3b8f":"code","b5365fe3":"code","0b848fc6":"code","c111ad77":"code","02c75560":"code","b4aa1c4d":"code","63ff7423":"code","7b01af59":"code","a6440eaa":"code","95a8b473":"code","5a34d9b3":"code","37d32a2f":"code","55911ab8":"code","88e2f38e":"code","5170d738":"code","43638a1d":"code","a15a8f8a":"code","647448c3":"code","a1f19533":"code","91a6c21b":"code","53569c0e":"code","d40f2843":"code","fd312b6d":"code","8550ed9d":"code","48817e68":"code","e4fd35c3":"code","4640cc63":"code","4b2c2ff7":"code","4997e736":"code","714d9729":"code","a4b9467b":"code","49c9977a":"code","9f98b301":"code","ce3f6f9c":"code","8d1cf102":"code","2e00344e":"code","85c78b5e":"code","d6085c6c":"code","92dc5f61":"code","64d89f5c":"code","9a97687a":"code","934312c0":"code","3bd36c0e":"code","e1c9fb4f":"code","2af1d621":"code","038bee5c":"code","22fcff3d":"code","ba32c121":"code","d1edbb46":"code","da3807a9":"code","2ebac373":"code","c94a660c":"code","4d5e45ac":"code","fa37ff74":"code","c58aa00a":"code","583817bd":"code","c107982b":"code","3ff61a96":"code","b9d9d4a0":"code","62b354cb":"code","0a536d8a":"code","0dacafdc":"code","5c92f595":"code","27e8445e":"code","099dd4b3":"code","42f03f08":"code","13f0c129":"code","19eabebc":"code","b363e283":"code","055489bd":"code","27ad4722":"code","24250041":"code","2c793334":"code","b7c150da":"code","c74c6e8d":"code","4dd6b15c":"code","e5308225":"code","58486933":"code","b1c7e332":"code","6426dc33":"code","b9fce481":"code","59bb4227":"code","921e37b7":"code","5625907f":"code","4efb0fad":"code","2c5e8854":"markdown","19fa42e5":"markdown","484f1286":"markdown","fcbb03ad":"markdown","e5fc320c":"markdown","16ee491f":"markdown","434cc640":"markdown","73e39d98":"markdown","b553beda":"markdown","6bac2b68":"markdown","caeccbbf":"markdown","834496b3":"markdown","b64ebf4c":"markdown","88f402ed":"markdown","325cad6f":"markdown","a92ccb2c":"markdown","5ec4d3a0":"markdown","58c9aaf8":"markdown","8c087a2b":"markdown","c2a1178c":"markdown","b18fdbd6":"markdown","a70312ce":"markdown","de3d6ec7":"markdown","82248b9a":"markdown","392fbb8c":"markdown","7c3244f4":"markdown"},"source":{"70b035df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport sklearn.linear_model as linear_model\nimport matplotlib.style as style\nimport seaborn as sns\nimport matplotlib.gridspec as gridspec\nimport missingno as msno\nimport seaborn as sns\nfrom lightgbm import LGBMRegressor\nfrom mlxtend.regressor import StackingCVRegressor\nfrom scipy.stats import skew  \nfrom scipy import stats\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom IPython.display import display, HTML\n%matplotlib inline\nfrom xgboost import XGBRegressor\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","ded5b8a1":"# Import Training Data and Test data\n\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","6d51d4c3":"print (\"Size of the train data : {}\" .format(train.shape))","c7ef84ad":"print (\"Size of the test data : {}\" .format(test.shape))","ceed3b8f":"# Information about the features\n\ntest.info()","b5365fe3":"#Save the 'Id' column\ntrain_ID = train['Id']\ntest_ID = test['Id']\n\n#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)","0b848fc6":"\nprint (\"Size of train data after dropping Id: {}\" .format(train.shape))\nprint (\"Size of test data after dropping Id: {}\" .format(test.shape))\n","c111ad77":"# Statistical about the numerical variables in training data\n\ntrain.describe().T","02c75560":"# Statistical about the numerical variables in testing data\n\ntest.describe().T","b4aa1c4d":"# Missing values in training dataset**\n\ndef missing_percentage(df):\n   \n    total = df.isnull().sum().sort_values(ascending = False)[df.isnull().sum().sort_values(ascending = False) != 0]\n    percent = round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100,2)[round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100,2) != 0]\n    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])\n\nmissing_percentage(train)","63ff7423":"# **Missing values in testing dataset**\n\nmissing_percentage(test)","7b01af59":"#For the PoolQC, 99.52% training data and 99.79% testing data is NA. \n#All the NA in PoolQC is due to no swimming pool.\n\n#\"NA\" is replaced by \"None\".  \n\ntrain[\"PoolQC\"] = train[\"PoolQC\"].fillna('None')\ntest[\"PoolQC\"] = test[\"PoolQC\"].fillna('None')","a6440eaa":"# For the MiscFeature, 96.3% training data and 96.5% testing data is NA.  \n#As NA referes to no miscellaneous feature, \"NA\" is replaced by \"None\".\n\ntrain[\"MiscFeature\"] = train[\"MiscFeature\"].fillna('None')\ntest[\"MiscFeature\"] = test[\"MiscFeature\"].fillna('None')","95a8b473":"# For the Alley, 93.77% training data and 92.67% testing data is NA.  \n#As NA referes to alley access to property , \"NA\" is replaced by \"None\".\n\ntrain[\"Alley\"] = train[\"Alley\"].fillna('None')\ntest[\"Alley\"] = test[\"Alley\"].fillna('None')","5a34d9b3":"# For the Fence, 80.75% training data and 80.12% testing data is NA.  \n#As NA referes to No fence, \"NA\" is replaced by \"None\".\n\ntrain[\"Fence\"] = train[\"Fence\"].fillna('None')\ntest[\"Fence\"] = test[\"Fence\"].fillna('None')","37d32a2f":"# For the FireplaceQu, 47.26% training data and 50.03% testing data is NA. \n#As NA referes to No fireplace, \"NA\" is replaced by \"None\".\n\ntrain[\"FireplaceQu\"] = train[\"FireplaceQu\"].fillna('None')\ntest[\"FireplaceQu\"] = test[\"FireplaceQu\"].fillna('None')","55911ab8":"### For the LotFrontage, 17.74% training data and 15.56% testing data is missing. \n#The feature cannot be dropped as the correlation is 0.33 to SalePrice.\n# We can fill the missing value with median if outliers exist, otherwise fill it with mean.\n\n# Distribution of training data of Feature LotFrontage \n\ntrain.boxplot(column=\"LotFrontage\")","88e2f38e":"# Distribution of testing data of Feature LotFrontage \n\ntest.boxplot(column=\"LotFrontage\")","5170d738":"#Calculation of mean and median of LotFrontage in training dataset\n\ntrain['LotFrontage'].mean(),train['LotFrontage'].median()\n","43638a1d":"#Calculation of mean and median of LotFrontage in training dataset\n\ntest['LotFrontage'].mean(),test['LotFrontage'].median()","a15a8f8a":"#Fill the missing LotFrontage value with median\n\ntrain[\"LotFrontage\"] = train[\"LotFrontage\"].fillna(train['LotFrontage'].median())\ntest[\"LotFrontage\"] = test[\"LotFrontage\"].fillna(test['LotFrontage'].median())","647448c3":"# For the GarageType, GarageCond, GarageFinish, GarageQual 5.55% training data and 5.35% testing data is NA. \n# As NA referes to No garage, \"NA\" is replaced by \"None\".\n\n# For the GarageYrBlt, GarageArea and GarageCars, \"0\" should be filled as there is no garage included\n\ntrain[\"GarageType\"] = train[\"GarageType\"].fillna('None')\ntest[\"GarageType\"] = test[\"GarageType\"].fillna('None')\ntrain[\"GarageFinish\"] = train[\"GarageFinish\"].fillna('None')\ntest[\"GarageFinish\"] = test[\"GarageFinish\"].fillna('None')\ntrain[\"GarageQual\"] = train[\"GarageQual\"].fillna('None')\ntest[\"GarageQual\"] = test[\"GarageQual\"].fillna('None')\ntrain[\"GarageCond\"] = train[\"GarageCond\"].fillna('None')\ntest[\"GarageCond\"] = test[\"GarageCond\"].fillna('None')\ntrain[\"GarageYrBlt\"] = train[\"GarageYrBlt\"].fillna('0')\ntest[\"GarageYrBlt\"] = test[\"GarageYrBlt\"].fillna('0')\ntrain[\"GarageArea\"] = train[\"GarageArea\"].fillna('0')\ntest[\"GarageArea\"] = test[\"GarageArea\"].fillna('0')\ntrain[\"GarageCars\"] = train[\"GarageCars\"].fillna('0')\ntest[\"GarageCars\"] = test[\"GarageCars\"].fillna('0')","a1f19533":"# For the BsmtFinSF1, BsmtFinSF2, TotalBsmtSF, BsmtFullBath and BsmtHalfBath, The missing values is due to no basement in the house, missing value is filled with \"0\"\n\n# For BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1 and BsmtFinType2, \"none\" should be filled as there is no basement\n\ntrain[\"BsmtFinSF1\"] = train[\"BsmtFinSF1\"].fillna('0')\ntest[\"BsmtFinSF1\"] = test[\"BsmtFinSF1\"].fillna('0')\ntrain[\"BsmtFinSF2\"] = train[\"BsmtFinSF2\"].fillna('0')\ntest[\"BsmtFinSF2\"] = test[\"BsmtFinSF2\"].fillna('0')\ntrain[\"BsmtUnfSF\"] = train[\"BsmtUnfSF\"].fillna('0')\ntest[\"BsmtUnfSF\"] = test[\"BsmtUnfSF\"].fillna('0')\ntrain[\"TotalBsmtSF\"] = train[\"TotalBsmtSF\"].fillna('0')\ntest[\"TotalBsmtSF\"] = test[\"TotalBsmtSF\"].fillna('0')\ntrain[\"BsmtFullBath\"] = train[\"BsmtFullBath\"].fillna('0')\ntest[\"BsmtFullBath\"] = test[\"BsmtFullBath\"].fillna('0')\ntrain[\"BsmtHalfBath\"] = train[\"BsmtHalfBath\"].fillna('0')\ntest[\"BsmtHalfBath\"] = test[\"BsmtHalfBath\"].fillna('0')\ntrain[\"BsmtQual\"] = train[\"BsmtQual\"].fillna('None')\ntest[\"BsmtQual\"] = test[\"BsmtQual\"].fillna('None')\ntrain[\"BsmtCond\"] = train[\"BsmtCond\"].fillna('None')\ntest[\"BsmtCond\"] = test[\"BsmtCond\"].fillna('None')\ntrain[\"BsmtExposure\"] = train[\"BsmtExposure\"].fillna('None')\ntest[\"BsmtExposure\"] = test[\"BsmtExposure\"].fillna('None')\ntrain[\"BsmtFinType1\"] = train[\"BsmtFinType1\"].fillna('None')\ntest[\"BsmtFinType1\"] = test[\"BsmtFinType1\"].fillna('None')\ntrain[\"BsmtFinType2\"] = train[\"BsmtFinType2\"].fillna('None')\ntest[\"BsmtFinType2\"] = test[\"BsmtFinType2\"].fillna('None')\n","91a6c21b":"# For the MasVnrArea, 0.55% training data and 1.03% testing data is missing value. It should fill by \"0\" as most likely refer to no masonry veneer.\n\n# For the MasVnrType, 0.55% training data and 1.10% testing data is missing, It should fill by \"None\" as most likely the house does not include masonry veneer.\n\ntrain[\"MasVnrArea\"] = train[\"MasVnrArea\"].fillna('0')\ntest[\"MasVnrArea\"] = test[\"MasVnrArea\"].fillna('0')\ntrain[\"MasVnrType\"] = train[\"MasVnrType\"].fillna('None')\ntest[\"MasVnrType\"] = test[\"MasVnrType\"].fillna('None')\n","53569c0e":"## For the Electrical, Functional, Utilities, Exterior1st, KitchenQual, Exterior2nd, SaleType Less than 0.2% data is missing. The missing value is filled with the most common value.\n\ntrain[\"Electrical\"] = train[\"Electrical\"].fillna('sBrKr')\ntest[\"Functional\"] = test[\"Functional\"].fillna('Typ')\ntest[\"Utilities\"] = test[\"Utilities\"].fillna('AllPub')\ntest[\"Exterior1st\"] = test[\"Exterior1st\"].fillna('VinylSd')\ntest[\"KitchenQual\"] = test[\"KitchenQual\"].fillna('TA')\ntest[\"Exterior2nd\"] = test[\"Exterior2nd\"].fillna('VinylSd')\ntest[\"SaleType\"] = test[\"SaleType\"].fillna('Normal')","d40f2843":"# For MSZoning, 0.27% testing data with missing value. The value is filled with most common values.\n\ntest[\"MSZoning\"] = test[\"MSZoning\"].fillna('RL')","fd312b6d":"# Double Check missing value in both training and testing data\n\nmissing_percentage(train), missing_percentage(test)","8550ed9d":"train['SalePrice'].describe()","48817e68":"train.hist(column=\"SalePrice\", figsize=(5,5), color=\"green\", bins=100 )","e4fd35c3":"# Distribution of testing data of Target Feature SalePrice \n\ntrain.boxplot(column=\"SalePrice\")","4640cc63":"#Correct right-skewedness of SalePrice\n\ntrain.SalePrice = np.log1p(train.SalePrice)","4b2c2ff7":"# Plot log SalePrice to check skewedness again\n\ntrain.hist(column=\"SalePrice\", figsize=(5,5), color=\"green\", bins=100 )","4997e736":"#Find the most correlated features with SalePrice\n\ncorrmat = train.corr()\ntop_correlated_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.3]\nplt.figure(figsize=(20,20))\nx = sns.heatmap(train[top_correlated_features].corr(),annot=True,cmap=\"viridis\")","714d9729":"# define plot function, and in this function, we will calculate the skew of X and take the log1p of y\ndef plot_outlier(x,y):\n    tmp=x.dropna()\n    skew_value=skew(tmp)\n    y=np.log1p(y)\n    print('sample lengh: %s   and skew: %s'%(len(x),skew_value))\n    fig,axs=plt.subplots(1,2,figsize=(8,3))\n    sns.boxplot(x,orient='v',ax=axs[0])\n    sns.regplot(x,y,ax=axs[1])\n    plt.tight_layout()","a4b9467b":"# LotFrontage\nplot_outlier(train.LotFrontage,train.SalePrice)","49c9977a":"# it seems that there are two outlier about LotFrontage, let's remove them and replot \ntrain=train[train.LotFrontage<300]\nplot_outlier(train.LotFrontage,train.SalePrice)","9f98b301":"# LotArea\nplot_outlier(train.LotArea,train.SalePrice)","ce3f6f9c":"# the same thing we do for LotArea, I select threshold from 7000->5000->3000\ntrain=train[train.LotArea<30000]\nplot_outlier(train.LotArea,train.SalePrice)","8d1cf102":"train=train[train.GrLivArea<4500]\nplot_outlier(train.GrLivArea,train.SalePrice)","2e00344e":"# OverallQual, \nplot_outlier(train.OverallQual,train.SalePrice)","85c78b5e":"# YearBuilt, newer of the house the higher of the price\nplot_outlier(train.YearBuilt,train.SalePrice)","d6085c6c":"# YearRemodAdd, same as YearBuilt\nplot_outlier(train.YearRemodAdd,train.SalePrice)","92dc5f61":"# BsmtFinSF1, \nplot_outlier(train.BsmtFinSF1,train.SalePrice)","64d89f5c":"# BsmtUnfSF\nplot_outlier(train.BsmtUnfSF,train.SalePrice)","9a97687a":"# TotalBsmtSF\nplot_outlier(train.TotalBsmtSF,train.SalePrice)","934312c0":"#Outlier at TotalBsmtSF<3000\ntrain=train[train.TotalBsmtSF<3000]\nplot_outlier(train.TotalBsmtSF,train.SalePrice)","3bd36c0e":"# finished square feet\nBsmtFSF=train.TotalBsmtSF-train.BsmtUnfSF\nplot_outlier(BsmtFSF,train.SalePrice)","e1c9fb4f":"# 1stFlrSF\nplot_outlier(train.loc[:,'1stFlrSF'],train.SalePrice)","2af1d621":"# 2ndFlrSF\nplot_outlier(train.loc[:,'2ndFlrSF'],train.SalePrice)","038bee5c":"# GrLivArea\nplot_outlier(train.GrLivArea,train.SalePrice)","22fcff3d":"#Outlier at GrLivArea < 4000\ntrain=train[train.GrLivArea<4000]\nplot_outlier(train.GrLivArea,train.SalePrice)","ba32c121":"#BsmtFullBath\nplot_outlier(train.BsmtFullBath,train.SalePrice)","d1edbb46":"#BsmtHalfBath\nplot_outlier(train.BsmtHalfBath,train.SalePrice)","da3807a9":"#FullBath\nplot_outlier(train.FullBath,train.SalePrice)","2ebac373":"#HalfBath\nplot_outlier(train.HalfBath,train.SalePrice)","c94a660c":"#BedroomAbvGr\nplot_outlier(train.BedroomAbvGr,train.SalePrice)","4d5e45ac":"#TotRmsAbvGrd\nplot_outlier(train.TotRmsAbvGrd,train.SalePrice)","fa37ff74":"#Fireplaces\nplot_outlier(train.Fireplaces,train.SalePrice)","c58aa00a":"#GarageCars\nplot_outlier(train.GarageCars,train.SalePrice)","583817bd":"#GarageArea\nplot_outlier(train.GarageArea,train.SalePrice)","c107982b":"#WoodDeckSF\nplot_outlier(train.WoodDeckSF,train.SalePrice)","3ff61a96":"#OpenPorchSF\nplot_outlier(train.OpenPorchSF,train.SalePrice)","b9d9d4a0":"#EnclosePorch\nplot_outlier(train.EnclosedPorch,train.SalePrice)","62b354cb":"#3SsnPorch\nplot_outlier(train.loc[:,'3SsnPorch'],train.SalePrice)","0a536d8a":"#ScreenPorch\nplot_outlier(train.ScreenPorch,train.SalePrice)","0dacafdc":"#MoSold\nplot_outlier(train.MoSold ,train.SalePrice)","5c92f595":"#YrSold\nplot_outlier(train.YrSold ,train.SalePrice)","27e8445e":"#Deleting outliers in SalePrice\n\n#train=train[(train['GrLivArea'] > 4500) & (train['SalePrice'] < 300000)]\n#train=train[(train['1stFlrSF'] > 4000) & (train['SalePrice'] < 300000)]\n#train=train[(train['TotalBsmtSF'] >6000) & (train['SalePrice'] < 200000)]","099dd4b3":"categorial_features = [feature for feature in train.columns if train[feature].dtypes == 'O']\nprint(categorial_features)","42f03f08":"\ntrain[categorial_features].head()","13f0c129":"\nfor feature in categorial_features:\n    print(\"Feature {} has {} unique values\".format(feature, len(train[feature].unique())))\n","19eabebc":"for feature in categorial_features:\n    data = train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('Sale Price')\n    plt.title(feature)\n    plt.show()\n","b363e283":"ntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))\n","055489bd":"all_data['OverallCond'].value_counts()","27ad4722":"#Converting some numerical variables that are really categorical type.\n\n#MSSubClass=The building class\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","24250041":"from sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(all_data.shape))","2c793334":"#highly skewed features\n\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(15)\n","b7c150da":"#Box Cox Transformation of (highly) skewed features\n\nskewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    #all_data[feat] += 1\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n","c74c6e8d":"all_data = pd.get_dummies(all_data)\nall_data.shape\n","4dd6b15c":"train = all_data[:ntrain]\ntest = all_data[ntrain:]\ntrain.shape","e5308225":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","58486933":"#Validation function\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","b1c7e332":"#KRR = KernelRidge(alpha=0.014, kernel='polynomial', degree=2, coef0=2.5)#\n#score = rmsle_cv(KRR)\n#print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","6426dc33":"#lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0004, random_state=1))\n#score = rmsle_cv(lasso)\n#print(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n","b9fce481":"ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0004, l1_ratio=.9, random_state=3))\nscore = rmsle_cv(ENet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","59bb4227":"#LassoMd = lasso.fit(train.values,y_train)\nENetMd = ENet.fit(train.values,y_train)\n#KRRMd = KRR.fit(train.values,y_train)","921e37b7":"finalMd = (np.expm1(ENetMd.predict(test.values))) ","5625907f":"#finalMd = (np.expm1(LassoMd.predict(test.values)) + np.expm1(ENetMd.predict(test.values)) + np.expm1(KRRMd.predict(test.values))) ","4efb0fad":"sub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = finalMd\nsub.to_csv('submission.csv',index=False)","2c5e8854":"Outliers found!\nSalePrice < 300000 & GrLivArea > 4000","19fa42e5":"Observation \n\n1. Sale Price has a right skewed Distribution \n2. Outlier found in Sale Price","484f1286":"# Submission","fcbb03ad":"# Imputing missing data","e5fc320c":"# Handling of Missing Values","16ee491f":"# Concatenate both train and test values.\n","434cc640":"# Cross Validation\n\n#KFold( ) splits the train\/test data into k consecutive folds, we also have made shuffle attrib to True.\n\ncross_val_score ( ) evaluate a score by cross-validation.\n","73e39d98":"# Observation about dataset","b553beda":"# Modelling","6bac2b68":"# Mean of all model's prediction.\n\n","caeccbbf":"# Lasso Regression\n ","834496b3":"# Check for Missing Values","b64ebf4c":"# Label Encoding\n\n","88f402ed":"Drop and save the ID column for furture use","325cad6f":"# - 3 different types of features, float64(11), int64(26), object(43)\n# - Missing values in some features, especially in PoolQC, MiscFeature, Alley, Fence, FireplaceQu, LotFrontage","a92ccb2c":"Rank of numerical features correlation with SalePrice observed from the corrlation plot :\n1. OverallQual (0.79)\n2. GrLivArea (0.71)\n3. GarageCars (0.64)\n4. GarageArea (0.62)\n5. 1stFlrSF(0.61)\n6. TotalBsmtSF (0.61)\n7. FullBath (0.56)\n8. TotRmsAbvGrd (0.53)\n9. YearBuilt (0.52)\n10. YearRemodAdd (0.51)\n","5ec4d3a0":"# Analysis of Target Feature - Sale Price","58c9aaf8":"# Getting dummy categorical features\n","8c087a2b":"not correlate with SalePrice","c2a1178c":"# Create Train and test data","b18fdbd6":"# Import Libraries","a70312ce":"# Elastic Net Regression","de3d6ec7":"# Ridge Regression","82248b9a":"Fit the training dataset on every model\n","392fbb8c":"# Categorical Data\n\n","7c3244f4":"# Creating features"}}