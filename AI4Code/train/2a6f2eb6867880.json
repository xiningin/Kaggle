{"cell_type":{"cbba8025":"code","50627b94":"code","9b5222e9":"code","18ea8058":"code","3fcf7c94":"code","57f7a1a0":"markdown","89b8d354":"markdown","4a16d060":"markdown","cc0e8919":"markdown","97b75bd9":"markdown","f396a112":"markdown","b51ee977":"markdown","999fdd61":"markdown","9d34267f":"markdown"},"source":{"cbba8025":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","50627b94":"train_file = \"..\/input\/digit-recognizer\/train.csv\"\ntest_file = \"..\/input\/digit-recognizer\/test.csv\"\nraw_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)\n\nraw_data.shape","9b5222e9":"test_data.shape","18ea8058":"from sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimg_rows, img_cols = 28, 28\nnum_classes = 10\n\n#prepare data format as required by the model\ndef data_prep(raw):    \n    out_y = keras.utils.to_categorical(raw.label, num_classes)\n    num_images = raw.shape[0]\n    x_as_array = raw.values[:,1:]\n    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n    out_x = x_shaped_array \/ 255\n    return out_x, out_y\n\ndef data_prep_test(raw):        \n    num_images = raw.shape[0]\n    x_as_array = raw.values[:,:]\n    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n    out_x = x_shaped_array \/ 255\n    return out_x\n\nx, y = data_prep(raw_data)\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\nx_test = data_prep_test(test_data)\n\n#Data augmentation for better prediction using ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range = 0.1, \n                                   height_shift_range = 0.1)\ntrain_datagen.fit(x_train)\n\n#Create the model and add the layers\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(5, 5),\n                 activation='relu', padding='Same',\n                 input_shape=(img_rows, img_cols, 1)))\nmodel.add(Conv2D(32, kernel_size=(5, 5), padding='Same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.fit(train_datagen.flow(x, y, batch_size=64),\n          steps_per_epoch=len(x) \/ 64,\n          epochs=100, validation_data=(x_val, y_val))","3fcf7c94":"predictions = model.predict(x_test)\n#Save the predictions to a pandas data frame and assign it to digits as column names\nresults = pd.DataFrame(predictions, index=list(range(28000)), columns=[0,1,2,3,4,5,6,7,8,9])\n#Since the column with highest value is the prediction of the model, add a new column for the prediction result.\nresults.loc[:,10] = results.idxmax(axis=1)\n#Save the new column into a new dataframe with modified index starting with 1 and rename column as Label\ntest_predictions = pd.DataFrame(results.loc[:,10])\ntest_predictions = test_predictions.rename(columns={10: 'Label'})\ntest_predictions.index.name = 'ImageId'\ntest_predictions.index += 1\ntest_predictions.to_csv('my_submission_digits.csv')\nprint('File saved')","57f7a1a0":"# **Import Libraries and Data**","89b8d354":"# Import deep learning model and libraries","4a16d060":"This notebook is derived from deep learning class by Den Becker. I have modified the model and added pre and post processing steps necessary for test dataset.\nThis is an introductory notebook for simple image recognition modeling.\n\nVersion 15: Added data augmentation methods using TensorFlow","cc0e8919":"Since the model outputs probabilities for the digit in the picture, we have to modify the output before submitting to the competition.\nSo I have created a new dataframe and added the digit with max probability as a new column. This columns is our result, which can be submitted.","97b75bd9":"# Make the predictions and save as csv file","f396a112":"Let's import the train and test datasets. Check the shapes.","b51ee977":"I have reached an accuracy of around 0.995. Data augmentation increased the accuracy around 0.15.\nNext one can try to tune the hyperparameters of the CNN, it will slightly improve the accuracy but the accuracy is already high (>0.994) and close to 1. The accuracy is already in the top 10% of the competition.","999fdd61":"In this notebook; I have used a sequential model including convolutional (conv2D) layers.\nI have changed values of number of kernels, Conv2D number of filters and number of units in the first dense layer.\nIn addition; I have added maxpool2D and dropout layers to further imporve the model.\nEpoch number is set to 100 for good accuracy","9d34267f":"As can be seen, test data has one less column since the labels are missing.\nThere are 42000 rows of training data and 28000 rows of test data."}}