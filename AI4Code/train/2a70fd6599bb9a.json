{"cell_type":{"b74aca5f":"code","5455a09a":"code","3333f22b":"code","1980f40f":"code","905e7042":"code","685c6c81":"code","278a39b7":"code","19e49e59":"code","f896a658":"code","ad1b647a":"code","c254e1d8":"code","51a9a659":"code","389542ff":"code","af977d68":"code","1c48b40b":"code","a9f0a994":"markdown","95ea6aad":"markdown","136a19ed":"markdown","03a47065":"markdown","d599602d":"markdown","6432abba":"markdown","f3550e4d":"markdown","156ae5d0":"markdown","6a43799e":"markdown"},"source":{"b74aca5f":"import pandas as pd\n\n# You need scikit-learn 0.24 to run this notebook, you can install it with the code below if your account has been verified\n# and you have the \"Internet\" toggle switched on in the right pannel of Kaggle\n\n# pip install scikit-learn==0.24","5455a09a":"df = pd.read_csv(\"..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv\")\ndf_test = pd.read_csv(\"..\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv\")\nsample = pd.read_csv(\"..\/input\/hr-analytics-job-change-of-data-scientists\/sample_submission.csv\")","3333f22b":"def get_df_infos(df_):\n\n    df_info = pd.DataFrame(columns={\"column\", \"NaN\", \"NaN %\"})\n\n    for index, value in df_.isna().sum().iteritems():\n        df_temp = pd.DataFrame({\"column\" : index, \"NaN\" : [value], \"NaN %\" : round(value*100 \/len(df_), 2)})\n        df_info = pd.concat([df_info, df_temp], ignore_index=True)\n        df_info.sort_values(by=\"NaN\", ascending=False, inplace=True)\n\n    int_ = df_.select_dtypes(include=['int64']).columns.to_list()\n    float_ = df_.select_dtypes(include=['float64']).columns.to_list()\n    object_ = df_.select_dtypes(include=['object']).columns.to_list()\n\n    print(f\"Int64 : {', '.join(int_)}\")\n    print(f\"\\nFloat64 : {', '.join(float_)}\")\n    print(f\"\\nObject : {', '.join(object_)}\\n\") \n    \n    print(\"Total detected columns =\",len(int_) + len(float_) + len(object_))\n    print(\"\\nshape =\", df_.shape)\n    print(\"\\nshape without NaNs =\", df_.dropna().shape)\n\n    print(\"\\n\\n\", df_info)\n","1980f40f":"get_df_infos(df)","905e7042":"def df_cleaner(df_):\n    under_3 = []\n    for index, value in df_.isna().sum().iteritems():\n        if 0 <  value*100 \/len(df_) < 3:\n            under_3.append(index)\n    df_.dropna(subset=under_3, axis=0, inplace=True)\n    return df_\n\ndf = df_cleaner(df)\n\ndf.shape","685c6c81":"columns_to_fill = ['gender','company_size','major_discipline','company_type','relevent_experience']\n\nfor col in columns_to_fill:\n    df[col].fillna(df[col].mode()[0], inplace=True)\n\ndf.isna().sum()","278a39b7":"round(df[\"target\"].value_counts(normalize=True)*100, 3)","19e49e59":"from sklearn.utils import resample\n\ndf_majority = df[df[\"target\"] == 0]\ndf_minority = df[df[\"target\"] == 1]\n \n\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     \n                                 n_samples=len(df_majority),    \n                                 random_state=123) \n \ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \ndf_upsampled[\"target\"].value_counts()","f896a658":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(1, 2, figsize=(17, 6))\nfig.suptitle('Before | After')\n\nsns.set_style(\"darkgrid\")\n\nsns.countplot(df['target'], ax=axs[0]).set_title(\"1. Original\")\nsns.countplot(df_upsampled['target'], ax=axs[1]).set_title(\"2. Upsampled\")\n\nfig.show()","ad1b647a":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# !!! \"handle_unknown\" for OrdinalEncoder ONLY works with sklearn 0.24 and above\n\nX = df_upsampled.drop([\"target\", \"enrollee_id\"], axis=1)\ny = df_upsampled[\"target\"]\n\ncategorical_features = df_upsampled.select_dtypes(include=['object']).columns.to_list()\n\nordinal_features = [\"training_hours\", \"city_development_index\"]\n\npreprocessor = ColumnTransformer(\n               transformers=[\n               ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n               ('ord', OrdinalEncoder(handle_unknown='ignore'), ordinal_features),         \n               ],\n               remainder = \"drop\"\n               )\n\nclassifier_pipeline = Pipeline(\n                      steps=[\n                      ('preprocessor', preprocessor),\n                      ('SVD', TruncatedSVD()),\n                      ('classifier', ExtraTreesClassifier())             \n                      ]\n                      )\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25)\n\nclassifier_pipeline.fit(X_train, y_train)","c254e1d8":"sorted(classifier_pipeline.get_params().keys())","51a9a659":"from sklearn.model_selection import GridSearchCV\n\nparameters = [                           \n              {\n                'SVD__n_components': range(5, 9),\n                'classifier__max_depth': range(25, 40, 2),\n                'classifier__min_samples_leaf' : range(3, 10),\n                'classifier__criterion' : [\"gini\", \"entropy\"]\n                }\n              ]\n\ngrid_search = GridSearchCV(classifier_pipeline, param_grid=parameters, scoring=\"accuracy\")\n\ngrid_search.fit(X_train, y_train)\n\nprint(f\"Best parameters : \\n\\n{grid_search.best_params_}\")","389542ff":"X = df_upsampled.drop([\"target\", \"enrollee_id\"], axis=1)\ny = df_upsampled[\"target\"]\n\ncategorical_features = df_upsampled.select_dtypes(include=['object']).columns.to_list()\n\nordinal_features = [\"training_hours\", \"city_development_index\"]\n\npreprocessor = ColumnTransformer(\n               transformers=[\n               ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n               ('ord', OrdinalEncoder(handle_unknown='ignore'), ordinal_features),         \n               ],\n               remainder = \"drop\"\n               )\n\nclassifier_pipeline = Pipeline(\n                      steps=[\n                      ('preprocessor', preprocessor),\n                      ('SVD', TruncatedSVD(n_components=5)),\n                      ('classifier', ExtraTreesClassifier(criterion='entropy', max_depth=37, min_samples_leaf=3))             \n                      ]\n                      )\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25)\n\nclassifier_pipeline.fit(X_train, y_train)","af977d68":"print(f\"Train score = {round(classifier_pipeline.score(X_train, y_train), 4)}\")\nprint(f\"Test score = {round(classifier_pipeline.score(X_test, y_test), 4)}\")","1c48b40b":"from sklearn import metrics\nfrom sklearn.metrics import plot_roc_curve\n\nsns.set(rc={'figure.figsize':(10, 5)})\nsns.set_style(\"darkgrid\")\n\nmetrics.plot_roc_curve(classifier_pipeline, X_test, y_test)\n\nplt.show()","a9f0a994":"### Let's get some infos about this Dataset, i have a rapid function for that","95ea6aad":"###  Let's list all available parameters for my pipeline","136a19ed":"### Let's apply those parameters to our pipeline","03a47065":"### Very well, we no longer have any NaNs, let's move onto the next problem to deal with.\n### As stated in the description, the \"target\" is unbalanced, resampling could be the way to go about it\n","d599602d":"### There are a lot of them! I'll choose a few, it takes a long time to execute a Grid Search","6432abba":"### The Dataset isn't that big, i can't afford to drop all the NaNs i'll end up with too little Data to play with, i'll fill the rest of the NaN with the mode value of each column","f3550e4d":"### Let's initiate a Pipeline with no specific parameters yet\n### ColumnTransformer will transform our data according to our needs (categorical, ordinal)\n","156ae5d0":"### Too many NaNs, gotta clean that up\n### I will drop the NaNs from the columns with <3% of NaNs","6a43799e":"### We now have equally populated \"target\" classes"}}