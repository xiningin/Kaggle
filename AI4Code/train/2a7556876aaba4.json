{"cell_type":{"887107fc":"code","27e1e41f":"code","ef0a2c6a":"code","8d257f27":"code","0ca126be":"code","c0109321":"code","cbbc4bce":"code","d08320aa":"code","96a16319":"code","7380924c":"code","5a5f6891":"code","63629b89":"code","6f5ede45":"code","4cbfb0b3":"code","9ab090e1":"code","b11c4e8d":"code","cf4dfc96":"code","bd37f95e":"code","885fd3df":"code","96eb7c2e":"code","2c34343a":"code","df3aeed5":"code","ddd9d352":"code","46493d9a":"code","2a2360f3":"code","3134f857":"code","6b14f485":"code","93814ad2":"code","157e04c1":"code","f60eaf48":"code","46c4c101":"code","00964f8e":"code","6c100afb":"code","f27f2a17":"code","1eefa0a0":"code","742e435f":"code","e1b17c1c":"code","432d62cb":"code","7d0f51d2":"code","efb498a7":"code","417c6333":"markdown","955a8905":"markdown","3c2a37f2":"markdown","a73806ef":"markdown","06c744c7":"markdown","83c86552":"markdown","220daae7":"markdown","5dabf203":"markdown","daceb86b":"markdown","289a8c0e":"markdown","bd962979":"markdown","07ec0c95":"markdown","defa02b6":"markdown","cb27c94e":"markdown","6f26f501":"markdown","9be91253":"markdown","1c20a0f0":"markdown","1c16f90e":"markdown","17d22135":"markdown","3f8ad071":"markdown","7b44664c":"markdown","c82f9620":"markdown","cc04ae3a":"markdown","ebb80c9e":"markdown","85692ce5":"markdown","d6c12669":"markdown"},"source":{"887107fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27e1e41f":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings('ignore')","ef0a2c6a":"train_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nconcat_df = pd.concat([train_df, test_df])","8d257f27":"pd.set_option('max_columns', 81)\npd.set_option('max_rows', 50)","0ca126be":"concat_df.reset_index(drop=True, inplace=True)","c0109321":"concat_df","cbbc4bce":"f'concat_df dimension: {concat_df.shape}'","d08320aa":"missing_df = pd.DataFrame({'Missing Count':concat_df.isna().sum()[concat_df.isna().any() == True]})\nmissing_df","96a16319":"fig = px.imshow(concat_df.isna())\nfig.show()","7380924c":"f'Total duplicated data: {concat_df.duplicated().sum()}'","5a5f6891":"cat_cols = concat_df.select_dtypes(object).columns.tolist()\nnum_cols = concat_df.select_dtypes(exclude = object).columns.tolist()\n\nprint(f'Categorical Features --- ({len(cat_cols)})\\n{cat_cols}\\n')\nprint(f'Numeric Features --- ({len(num_cols)})\\n{num_cols}')","63629b89":"concat_df.info()","6f5ede45":"concat_df.describe()","4cbfb0b3":"corr = concat_df.corr()\n\nfig = px.imshow(corr)\nfig.show()","9ab090e1":"fig = px.histogram(concat_df.SalePrice, title='House Price Distribution')\nfig.show()","b11c4e8d":"fig = px.box(x=concat_df.SalePrice, title='House Price Distribution')\nfig.show()","cf4dfc96":"from sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import LabelEncoder","bd37f95e":"class FE:\n    def __init__(self, df):\n        self.df = df\n        \n        \n    # Drop any column whose na value is over 50% of the total data\n    def drop_columns(self):\n        columns = list()\n        for column, value in zip(self.df.isna().sum().index.tolist(), self.df.isna().sum().values.tolist()):\n            if value > (len(self.df) \/ 2):\n                columns.append(column)\n        \n        self.df.drop(columns, axis=1, inplace=True)\n        return self.df\n    \n    \n    # Fill na rows with the mode value (data that appears the most)\n    def fill_na_cat(self):\n        for column in self.df.select_dtypes(object):\n            self.df[column].fillna(self.df[column].mode()[0], inplace=True)\n        \n        return self.df\n    \n    \n    # Fill na rows with imputer\n    def impute(self):\n        imputer = KNNImputer(n_neighbors=2)\n        \n        try:\n            impute_df = self.df.select_dtypes(exclude=object).drop('SalePrice', axis=1)\n            imputed_numeric = imputer.fit_transform(impute_df)\n            \n            numeric_df = pd.DataFrame(imputed_numeric, columns=impute_df.columns)\n            categorical_df = self.df.select_dtypes(object)\n            sale_price_df = self.df['SalePrice']\n            self.df = pd.concat([numeric_df, categorical_df, sale_price_df], axis=1)\n        except:\n            impute_df = self.df.select_dtypes(exclude=object)\n            imputed_numeric = imputer.fit_transform(impute_df)\n            \n            numeric_df = pd.DataFrame(imputed_numeric, columns=impute_df.columns)\n            categorical_df = self.df.select_dtypes(object)\n            self.df = pd.concat([numeric_df, categorical_df], axis=1)\n            \n        return self.df\n    \n    \n    # Convert categorical values into numeric\n    def convert_values(self):\n        encoder = LabelEncoder()\n        for column in self.df.select_dtypes(object).columns:\n            self.df[column] = encoder.fit_transform(self.df[column])\n            \n        return self.df\n        \n    \nfe = FE(concat_df.copy())\nfe.drop_columns()\nfe.fill_na_cat()\nfe.impute()\ncleaned_df = fe.convert_values()","885fd3df":"cleaned_df.head()","96eb7c2e":"fig = px.imshow(cleaned_df.isna(), title='Missing Values')\nfig.show()","2c34343a":"from sklearn.model_selection import train_test_split","df3aeed5":"X = cleaned_df[~cleaned_df.SalePrice.isna()][cleaned_df.columns[1:-1]]\ny = cleaned_df[~cleaned_df.SalePrice.isna()][cleaned_df.columns[-1]]\n\ntrain_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.25, random_state=1)","ddd9d352":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_log_error","46493d9a":"class Models:\n    r2_scores = list()\n    rmsle_scores = list()\n    rmse_scores = list()\n    mae_scores = list()\n    model_names = list()\n    \n    def __init__(self, model, model_name):\n        self.model = model\n        self.model_name = model_name\n        Models.model_names.append(self.model_name)\n        \n    def predict(self):\n        model = self.model\n        model.fit(train_x, train_y)\n        prediction = model.predict(test_x)\n        \n        r2 = r2_score(test_y, prediction)\n        rmse = np.sqrt(mean_squared_error(test_y, prediction))\n        mae = mean_absolute_error(test_y, prediction)\n        rmsle = np.sqrt(mean_squared_log_error(test_y, prediction))\n        \n        Models.r2_scores.append(r2)\n        Models.rmse_scores.append(rmse)\n        Models.mae_scores.append(mae)\n        Models.rmsle_scores.append(rmsle)\n\n        self.print_result(r2, rmse, mae, rmsle)\n        \n    def print_result(self, r2, rmse, mae, rmsle):\n        print(f'R2: {r2}')\n        print(f'RMSE: {rmse}')\n        print(f'MAE: {mae}')\n        print(f'RMSLE: {rmsle}')","2a2360f3":"from sklearn.linear_model import LinearRegression\n\nmodel = Models(LinearRegression(), 'Linear Regression')\nmodel.predict()","3134f857":"from sklearn.linear_model import Ridge\n\nmodel = Models(Ridge(), 'Ridge Regression')\nmodel.predict()","6b14f485":"from sklearn.linear_model import Lasso\n\nmodel = Models(Lasso(), 'Lasso Regression')\nmodel.predict()","93814ad2":"from sklearn.svm import SVR\n\nmodel = Models(SVR(), 'Support Vector Regressor')\nmodel.predict()","157e04c1":"from xgboost import XGBRegressor\n\nmodel = Models(XGBRegressor(), 'XGB Regressor')\nmodel.predict()","f60eaf48":"performance_df = pd.DataFrame({'Model':Models.model_names, 'R2':Models.r2_scores, 'RMSE':Models.rmse_scores, 'MAE':Models.mae_scores, 'RMSLE':Models.rmsle_scores})\nperformance_df = performance_df.sort_values(by='RMSE').reset_index(drop=True)\nperformance_df","46c4c101":"fig = make_subplots(rows=2, cols=2, vertical_spacing=0.3, subplot_titles=('RMSE', 'R2', 'MAE', 'RMSLE'))\n\nfig.add_trace(\n    go.Bar(y=performance_df.RMSE, x=performance_df.Model),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Bar(y=performance_df.R2, x=performance_df.Model),\n    row=1, col=2\n)\n\nfig.add_trace(\n    go.Bar(y=performance_df.MAE, x=performance_df.Model),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Bar(y=performance_df.RMSLE, x=performance_df.Model),\n    row=2, col=2\n)\n\nfig.update_layout(height=700, title_text=\"Models Performances\")","00964f8e":"xgb = XGBRegressor()\nxgb.fit(train_x, train_y)\n\nfeatures = train_x.columns.tolist()\nimportances = xgb.feature_importances_.tolist()\n\nfi_df = pd.DataFrame({'Feature':features, 'Importance':importances}).sort_values(by='Importance')\nfi_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)","6c100afb":"fig = px.bar(fi_df, x='Importance', y='Feature', title='Feature Importances', height=800)\nfig.show()","f27f2a17":"from sklearn.preprocessing import StandardScaler","1eefa0a0":"fe = FE(test_df.copy())\nfe.drop_columns()\nfe.fill_na_cat()\nfe.impute()\ntest_df2 = fe.convert_values()\ntest_df2.Id = test_df.Id.apply(lambda x : int(x))","742e435f":"fe = FE(train_df.copy())\nfe.drop_columns()\nfe.fill_na_cat()\nfe.impute()\ntrain_df2 = fe.convert_values()\ntrain_df2.Id = train_df2.Id.apply(lambda x : int(x))","e1b17c1c":"train_x = train_df2[train_df2.columns[1:-1]].drop('FireplaceQu', axis=1)\ntrain_y = train_df2.SalePrice\ntest_x = test_df2.copy().drop('Id', axis=1)","432d62cb":"xgb = XGBRegressor()\nxgb.fit(train_x, train_y)\nprediction = xgb.predict(test_x)","7d0f51d2":"result_df = pd.DataFrame({'Id':test_df2.Id.values, 'SalePrice':prediction})\nresult_df","efb498a7":"result_df.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","417c6333":"#### General information about the data","955a8905":"# **Models Creation**","3c2a37f2":"# **Feature Engineering**","a73806ef":"### Support Vector Regressor","06c744c7":"### Columns Correlation","83c86552":"#### Set the max_columns to 81 so that all the columns are visible","220daae7":"# **Visualization**","5dabf203":"# **Feature Importance**\nSince XGB Regressor has the best performace, we're going to check the feature importances from the XGB Regressor model","daceb86b":"#### Print all categorical and numeric columns","289a8c0e":"### Lasso Regression","bd962979":"#### Train and test data","07ec0c95":"# **Predicting Test Data**","defa02b6":"# **Exploratory Data Analysis**","cb27c94e":"#### Check duplicated data","6f26f501":"#### Creating model","9be91253":"# **Models Performace**","1c20a0f0":"#### Visualize the na values","1c16f90e":"#### Clean test data","17d22135":"#### Result df","3f8ad071":"#### Count the na values","7b44664c":"### XGB Regressor","c82f9620":"#### Submission","cc04ae3a":"# **Data Preprocessing**","ebb80c9e":"### Linear Regression","85692ce5":"### Ridge Regression","d6c12669":"#### Clean train data"}}