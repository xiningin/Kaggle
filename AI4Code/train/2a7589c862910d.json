{"cell_type":{"99d616fc":"code","57398079":"code","dfb09412":"code","bd8abe97":"code","d0d5b8ca":"code","8cb161f9":"code","e59ebe3f":"code","2f1e2b31":"code","a20700c0":"code","17f569f7":"code","136852a7":"code","891ad12c":"code","f9e4e882":"code","27c22287":"code","6b728cb5":"code","5e247ea5":"code","a218b422":"code","4f4e9c59":"code","9fa48a9d":"code","10aa4e68":"code","bc35f68b":"code","9535bd18":"code","e5d4a86a":"markdown","aa13f8c8":"markdown","212061f8":"markdown","d4032b92":"markdown","446d7a06":"markdown","95e4f2c1":"markdown","475a325c":"markdown","6b27a714":"markdown","f09d667e":"markdown","c6a52996":"markdown","4d340bae":"markdown"},"source":{"99d616fc":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport xgboost","57398079":"df=pd.read_csv('..\/input\/heart-attack\/Heart Attack Data Set.csv')","dfb09412":"df.dtypes","bd8abe97":"df.info()","d0d5b8ca":"df.describe()","8cb161f9":"sns.set(rc={'figure.figsize':(13,13)})\nsns.heatmap(df.corr(),annot=True)","e59ebe3f":"df.columns","2f1e2b31":"#pairwise plot of 6 random features and which is \n# visually divided by the patient's gender\n\ndf1=df[['age', 'sex','oldpeak', 'thal', 'chol', 'fbs']]\n\nsns.pairplot(df1,hue='sex')","a20700c0":"#target variable countplot to show the number of instances of each class\n\nprint(df.target.value_counts())\nsns.set(rc={'figure.figsize':(8,8)})\nsns.countplot(df.target)\nplt.xlabel('Patients who suffered a heart attack(1) or not(0):')\nplt.ylabel('Count:')\nplt.title(\"0's count=\"+str(df.target.value_counts()[0])+\", 1's count=\" + str(df.target.value_counts()[1]))\nplt.show()","17f569f7":"\n# 30% for testing the data \n\ntraining_features=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal']\ntarget=['target']\n\nX_train, X_test, Y_train, Y_test= train_test_split(df[training_features],df[target],\n                                                   test_size=0.2, random_state=100)","136852a7":"#pre processing\n\nsc=StandardScaler()\n\nX_train=sc.fit_transform(X_train)\nX_test=sc.fit_transform(X_test)","891ad12c":"#define the model\n\nboost=GradientBoostingClassifier(n_estimators=200,learning_rate=0.01,max_depth=3,max_leaf_nodes=10)","f9e4e882":"#train the model\n\nboost.fit(X_train,Y_train)","27c22287":"#train accuracy\n\nboost.score(X_train,Y_train)","6b728cb5":"#predict on test data\n\ny_pred=boost.predict(X_test)","5e247ea5":"#metrics\n\n\nsns.set(rc={'figure.figsize':(8,6)})\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\ncm=confusion_matrix(y_pred,Y_test)\nprint('Accuracy score:',accuracy_score(y_pred,Y_test))\nprint('F1-Score:',f1_score(y_pred,Y_test))\nsns.heatmap(cm,annot=True)\nplt.title('Confusion Matrix for GradientBoostClassifier:')\nplt.show()","a218b422":"#classification report\n\nprint(classification_report(y_pred,Y_test))","4f4e9c59":"#define the model\n\nxboost=xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.01, max_delta_step=0, max_depth=3,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=300, n_jobs=4, num_parallel_tree=1, random_state=100,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=2)","9fa48a9d":"#train the model\n\n\nxboost.fit(X_train,Y_train)","10aa4e68":"# Predict on the test data\n\ny_pred=xboost.predict(X_test)","bc35f68b":"#metrics\n\nsns.set(rc={'figure.figsize':(8,6)})\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\ncm=confusion_matrix(y_pred,Y_test)\nprint('Accuracy score:',accuracy_score(y_pred,Y_test))\nprint('F1-Score:',f1_score(y_pred,Y_test))\nsns.heatmap(cm,annot=True)\nplt.title('Confusion Matrix for XGBClassifier:')\nplt.show()","9535bd18":"#classification report\n\nprint(classification_report(y_pred,Y_test))","e5d4a86a":"# Step 3: Visualizations and EDA","aa13f8c8":"## Correlations","212061f8":"## PLEASE UPVOTE IF YOU FOUND THIS USEFUL THANKS!","d4032b92":"## Pairwise plots","446d7a06":"# Step 1: Import Necessary Libraries","95e4f2c1":"# Learnings:\n\n### So for this particular dataset, we have seen gradient boost and xgboost classification and found that xgboost outperforms the gradientboosting model with an weighted average accuracy of around 0.89 where as gradient boosting model scores a weighted average accuracy of around 0.86.","475a325c":"##  Analyzing target variable","6b27a714":"# Step 6: XGBoost Model","f09d667e":"# Step 4: Train-test split and pre-processing","c6a52996":"# Step 2: Read the data","4d340bae":"# Step 5: Gradient Boost model"}}