{"cell_type":{"7506d464":"code","4cdf16de":"code","b55ff189":"code","3d7881a3":"code","2c66d4c5":"code","987ca30f":"code","17883345":"code","c5ab8f10":"code","a3d59b0c":"code","9cda0826":"code","3249b805":"code","0d8304d8":"code","7da3e935":"code","1ba18e25":"code","c61f4e6a":"code","d49f74e0":"code","bebe77ae":"code","3ab974ef":"code","445d9133":"code","d378882e":"code","f8086248":"code","d5603195":"code","c939c338":"code","1fa2dd76":"code","c1f4e0a8":"code","54a1d965":"code","6b0739b6":"code","1464011c":"code","64566760":"code","945c3763":"code","a81b04b3":"code","74cd5061":"code","82af493d":"code","e2b3734a":"code","edba1e24":"markdown","137a11d8":"markdown","44da3fb2":"markdown","3974b2bb":"markdown","990b62a2":"markdown","36830574":"markdown","f0d80733":"markdown","ea93738d":"markdown","2a2e27f1":"markdown","87e3d84c":"markdown","805cfcb2":"markdown"},"source":{"7506d464":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math \n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport seaborn as sns\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current sessio\ndata_Test=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndata_Train=pd.read_csv(\"..\/input\/titanic\/train.csv\")\nTest=data_Test.copy()\nTrain=data_Train.copy()\nTest\nTrain\nTrain.head()","4cdf16de":"tb=[Train,Test]\nData=pd.concat(tb)","b55ff189":"sns.barplot(x=\"Sex\",y=\"Survived\",data=Data)","3d7881a3":"Data.isnull().sum()","2c66d4c5":"Test","987ca30f":"Data[\"Title\"]=Data[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\nData","17883345":"Data[[\"Title\",\"Age\"]].groupby(\"Title\").sum()","c5ab8f10":"Data[\"Title\"].value_counts()","a3d59b0c":"Data[[\"Age\",\"Title\"]].groupby(\"Title\").mean()","9cda0826":"Data[\"Title\"]=Data[\"Title\"].replace([\"Mme\"],\"Mrs\")\nData[\"Title\"]=Data[\"Title\"].replace([\"Ms\",\"Mlle\"],\"Miss\")\nData[\"Title\"]=Data[\"Title\"].replace([\"Countess\",\"Lady\",\"Sir\"],\"Royal\")\nData[\"Title\"]=Data[\"Title\"].replace([\"Don\",\"Dona\",\"Jonkheer\",\"Major\",\"Rev\",\"Col\",\"Capt\",\"Dr\"],\"Rare\")","3249b805":"Data[[\"Age\",\"Title\"]].groupby(\"Title\").mean()","0d8304d8":"\nfor i in Data[\"Title\"]:\n    if i==\"Master\":\n        Data[\"Age\"]=Data[\"Age\"].fillna(5)\n    elif i==\"Miss\":\n        Data[\"Age\"]=Data[\"Age\"].fillna(22)\n    elif i==\"Mr\":\n        Data[\"Age\"]=Data[\"Age\"].fillna(32)\n    elif i==\"Mrs\":\n        Data[\"Age\"]=Data[\"Age\"].fillna(40)\n    elif i==\"Rare\":\n        Data[\"Age\"]=Data[\"Age\"].fillna(40)\n    else:\n        Data[\"Age\"]=Data[\"Age\"].fillna(43)\nData[\"Title\"].value_counts()","7da3e935":"Data[\"Fare\"]=Data[\"Fare\"].fillna(12)\nData.isnull().sum()","1ba18e25":"sns.barplot(x=\"Embarked\",y=\"Fare\",data=Data)","c61f4e6a":"Data[\"Embarked\"]=Data[\"Embarked\"].fillna('C')\nData.isnull().sum()","d49f74e0":"Data=Data.drop(\"Ticket\",axis=1)\nData=Data.drop(\"Cabin\",axis=1)\nData=Data.drop(\"Name\",axis=1)\nData.head()","bebe77ae":"#Tr=dict(tuple(Data.groupby(\"Survived\")))\n#NorTrain=pd.concat(Tr)\n#NorTrain=NorTrain.sort_values(by=[\"PassengerId\"])\n#NorTrain\nNorTrain=Data.loc[lambda Data:~(Data[\"Survived\"].isnull())]\nNorTrain","3ab974ef":"NorTest=Data.loc[lambda Data: Data[\"Survived\"].isnull()]\nNorTest","445d9133":"from sklearn import model_selection\nfrom sklearn import svm\nhelp(model_selection)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","d378882e":"ySurvived=NorTrain[\"Survived\"]\nNorTrain=NorTrain.drop([\"Survived\"],axis=1)\npidTrain=NorTrain[\"PassengerId\"]\nNorTrain=NorTrain.drop([\"PassengerId\"],axis=1)\npidFinal=NorTest[\"PassengerId\"]","f8086248":"NorTrain.dtypes\nenTrain=pd.get_dummies(NorTrain)\nenTest=pd.get_dummies(NorTest)\nFinalTrain,Final=enTrain.align(enTest,join='left',axis=1)\nFinal[\"Title_Royal\"]=Final[\"Title_Royal\"].fillna(FinalTrain[\"Title_Royal\"])\nFinal","d5603195":"rfc=RandomForestClassifier(n_estimators=150,\n    criterion='gini',\n    max_depth=5,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    min_weight_fraction_leaf=0.0,\n    max_features='auto')\nf=np.mean(cross_val_score(rfc, FinalTrain, ySurvived, cv=10))\nprint(f)","c939c338":"from sklearn.model_selection import RandomizedSearchCV","1fa2dd76":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","c1f4e0a8":"rfc_ran=RandomizedSearchCV(RandomForestClassifier(),param_distributions = random_grid, n_iter = 100, \n                           cv = 3, verbose=2, random_state=42, n_jobs = -1)\nrfc_ran.fit(FinalTrain,ySurvived)","54a1d965":"rfc_ran.best_params_","6b0739b6":"rfc_ran=RandomForestClassifier(n_estimators=600,min_samples_split=10,min_samples_leaf=1,\n                               max_features='sqrt',max_depth=110,bootstrap='True')\nf=np.mean(cross_val_score(rfc_ran, FinalTrain, ySurvived, cv=10))\nprint(f)","1464011c":"from sklearn.model_selection import GridSearchCV","64566760":"param_grid = {\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [2, 3, \"sqrt\"],\n    'min_samples_leaf': [1, 3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [200, 300, 600, 1000]\n}","945c3763":"rfc_grid = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)\nrfc_grid.fit(FinalTrain,ySurvived)","a81b04b3":"rfc_grid.best_params_","74cd5061":"rfc_final=RandomForestClassifier(n_estimators=300,min_samples_split=10,min_samples_leaf=1,\n                               max_features=3,max_depth=80,bootstrap='True')\nf=np.mean(cross_val_score(rfc_final, FinalTrain, ySurvived, cv=10))\nprint(f)","82af493d":"rfc_final.fit(FinalTrain,ySurvived)\nPredictions=rfc_final.predict(Final)","e2b3734a":"ID=pidFinal.array\nSubmission = pd.DataFrame({\n    'PassengerId':ID,\n    'Survived':Predictions\n})\nSubmission.to_csv('Submission.csv', index = False)","edba1e24":"**Hyperparameter Optimization: Random Search**","137a11d8":"**Combining all the data**","44da3fb2":"**Splitting the training and validation data**","3974b2bb":"**Fitting the Data: Random Forest Classifier**","990b62a2":"**Fitting the model with the best parameters found**","36830574":"**Combining the Titles and Age assignment**","f0d80733":"**Finding which predictors have missing data**","ea93738d":"**HyperParameter Optimization: Grid Search**","2a2e27f1":"**Extracting TITLE from the name. For filling the missing values in Age**","87e3d84c":"**Filling missing data for 'Embarked' by checking the 'Fares'**","805cfcb2":"**Dropping the useless variables**"}}