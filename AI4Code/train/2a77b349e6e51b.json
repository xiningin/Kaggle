{"cell_type":{"9b172d83":"code","471b53f6":"code","f845733f":"code","26a9fba8":"code","c5eaf83a":"code","7c4939df":"code","be1e183f":"code","63132841":"code","07109ab8":"code","6750f85c":"code","7290c4d5":"code","f6680f4a":"code","8a602432":"code","f1008302":"code","533b5cd3":"code","6862d969":"code","9b7235d9":"code","807f2e81":"code","b6c311ef":"code","05d02df5":"code","31928c2b":"code","922f5d0e":"code","d13dd51f":"code","eb1eff84":"code","331dc6c1":"code","9c1f9b0b":"code","2022e892":"code","0637ec00":"code","6c330d30":"code","194354d5":"code","19daa376":"code","d11ed7d5":"code","25572573":"code","cded8f85":"code","ed112d3a":"code","5a006133":"code","ca9dfcda":"code","1f1c8116":"code","d5626b5d":"code","8a9b4287":"code","c81c15bb":"code","0bd76051":"code","df3ac422":"code","de7a0f74":"markdown","ca56e60d":"markdown","988b2b14":"markdown","bc067265":"markdown","53d95f71":"markdown","7d32cbe9":"markdown","fd4f3b7e":"markdown","a7916c40":"markdown","7497db9d":"markdown","b1a4a77b":"markdown","869071ac":"markdown","0b235807":"markdown","8cfcaa09":"markdown"},"source":{"9b172d83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","471b53f6":"test = pd.read_csv('..\/input\/test.csv')\ntrain = df = pd.read_csv('..\/input\/train.csv')","f845733f":"test.shape, train.shape","26a9fba8":"df = pd.concat([train, test])","c5eaf83a":"df.shape, train.shape, test.shape","7c4939df":"texto = df.select_dtypes(include='object').columns","be1e183f":"numero = [c for c in df.columns if c not in texto]\nnumero = [c for c in numero if c not in ['nota_mat', 'codigo_mun', 'Unnamed: 0']]","63132841":"df.info()","07109ab8":"def outliers_iqr(ys):\n    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n    iqr = quartile_3 - quartile_1\n    lower_bound = quartile_1 - (iqr * 1.5)\n    upper_bound = quartile_3 + (iqr * 1.5)\n    return np.where((ys > upper_bound) | (ys < lower_bound))","6750f85c":"for a in numero:\n    quartile_1, quartile_3 = np.percentile(df[a], [25, 75])\n    iqr = quartile_3 - quartile_1\n    lower_bound = quartile_1 - (iqr * 1.5)\n    upper_bound = quartile_3 + (iqr * 1.5)\n    df[a][df[a] < lower_bound] = None\n    df[a][df[a] > upper_bound] = None    ","7290c4d5":"df.shape","f6680f4a":"texto = [c for c in texto if c not in ['codigo_mun']]","8a602432":"for c in texto:\n    df[c]=df[c].astype('category').cat.codes","f1008302":"feats = [c for c in df.columns if c not in ['nota_mat','codigo_mun', 'Unnamed: 0']]","533b5cd3":"# nme: nota m\u00e9dia por estado\nnme = df.groupby(['estado'], as_index=False).mean()\nfor c in nme.columns:\n    nme[c].fillna(nme[c].mean(), inplace=True)","6862d969":"df2 = pd.merge(df, nme, left_on='estado', right_on='estado', how='left', suffixes=('', '_mean'))\ndf2['estado_mean']=df2['estado']","9b7235d9":"df.shape, df2.shape, nme.shape","807f2e81":"feats2 = [c for c in feats if c not in ['codigo_mun']]","b6c311ef":"for c in feats2:\n    #df[c].fillna(1, inplace=True)\n    df[c].fillna(df2[c+'_mean'], inplace=True)","05d02df5":"df.sample(10)","31928c2b":"df['nota_mat'] = np.log(df['nota_mat'])","922f5d0e":"import  matplotlib.pyplot  as plt\nimport matplotlib.gridspec as gridspec\n","d13dd51f":"df.columns\ngraf = ['anos_estudo_empreendedor', 'area',\n       'comissionados', 'comissionados_por_servidor',\n       'densidade_dem', 'exp_anos_estudo', 'exp_vida',\n       'gasto_pc_educacao', 'gasto_pc_saude', 'hab_p_medico', 'idhm',\n       'indice_governanca', 'jornada_trabalho',\n       'participacao_transf_receita', 'perc_pop_econ_ativa', 'pib', 'pib_pc',\n       'populacao', 'ranking_igm', 'servidores',\n       'taxa_empreendedorismo']","eb1eff84":"plt.rcParams['figure.figsize'] = (20,30)","331dc6c1":"ncol = 3\nf, ax = plt.subplots((len(graf)\/\/ncol),ncol)\ncol=0\nrow=0\nfor i in graf: \n    ax[col,row].boxplot(df[i])\n    ax[col,row].set_title(df[i].name.upper())\n    row=row+1\n    if row % ncol == 0:\n        col=col+1\n        row=0\nplt.show()","9c1f9b0b":"test = df[df['nota_mat'].isnull()]\ntrain = df[df['nota_mat'].notnull()]","2022e892":"test.shape, train.shape","0637ec00":"from sklearn.model_selection import train_test_split","6c330d30":"train, valid = train_test_split(train, random_state = 42)","194354d5":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(random_state = 42)\nfrom pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rf.get_params())","19daa376":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)","d11ed7d5":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\n#rf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\n#rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\n#rf_random.fit(train[feats], train['nota_mat'])","25572573":"best = rf_random.best_params_\nbest2 = {'n_estimators': 800,\n 'min_samples_split': 2,\n 'min_samples_leaf': 2,\n 'max_features': 'sqrt',\n 'max_depth': 50,\n 'bootstrap': False}\nbest","cded8f85":"best_random = RandomForestRegressor(n_estimators= 800, min_samples_split = 2, min_samples_leaf= 2, max_features = 'sqrt', max_depth =50, bootstrap= False)","ed112d3a":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors \/ test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy","5a006133":"base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\nbase_model.fit(train[feats], train['nota_mat'])\nbase_accuracy = evaluate(base_model, valid[feats], valid['nota_mat'])","ca9dfcda":"best_random.fit(train[feats], train['nota_mat'])\nrandom_accuracy = evaluate(best_random, valid[feats], valid['nota_mat'])","1f1c8116":"print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) \/ base_accuracy))","d5626b5d":"plt.rcParams['figure.figsize'] = (11,7)\npd.Series(best_random.feature_importances_, index=feats).sort_values().plot.barh()","8a9b4287":"test['nota_mat'] = best_random.predict(test[feats])","c81c15bb":"test['nota_mat'] = np.exp(test['nota_mat'])\ntest['codigo_mun'] = test['codigo_mun'].apply(lambda x: x.replace('ID_ID_', ''))\n#test['codigo_mun'] = test['codigo_mun'].values.astype('int64')","0bd76051":"test[['codigo_mun','nota_mat']].to_csv('rf.csv', index=False)","df3ac422":"test.info()","de7a0f74":"### Identifica\u00e7\u00e3o das colunas a serem utilizadas no modelo","ca56e60d":"### Uni\u00e3o dos datasets para tratamento dos dados","988b2b14":"### Normaliza\u00e7\u00e3o da coluna da nota de matem\u00e1tica","bc067265":"### Transforma\u00e7\u00e3o das colunas textuais em categorias num\u00e9ricas","53d95f71":"### Buscando melhores par\u00e2metros","7d32cbe9":"### Separa\u00e7\u00e3o dos datasets de teste e treino","fd4f3b7e":"### Vari\u00e1veis do modelo","a7916c40":"### Prepara\u00e7\u00e3o dos resultados","7497db9d":"### Transforma\u00e7\u00e3o do campo de c\u00f3digo do mun\u00edcipio","b1a4a77b":"### Utiliza\u00e7\u00e3o do modelo de regress\u00e3o","869071ac":"### Visualisa\u00e7\u00e3o dos dados","0b235807":"### Prenchimento dos valores nulos pela m\u00e9dia da vari\u00e1vel no Estado","8cfcaa09":"### Importa\u00e7\u00e3o dos dados"}}