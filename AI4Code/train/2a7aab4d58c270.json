{"cell_type":{"8f94eaaa":"code","4594fdeb":"code","297521f6":"code","cb6c17c9":"code","cee248b5":"code","96f04067":"code","23a0da69":"code","df866901":"code","a59e22fd":"code","7d85d735":"code","6a46938d":"code","53f50155":"code","b5f6589e":"code","790a7221":"code","be0324bb":"code","f32b4008":"code","d6dab8c1":"code","53aa56f5":"code","c1dcc3e9":"code","eeb98627":"code","e305b05e":"code","fc481544":"code","bacfaf1f":"markdown","b3b1549f":"markdown","b8f549d0":"markdown","e332dddc":"markdown","2d96f452":"markdown","8dbc1746":"markdown","024f84c1":"markdown","39ea5e28":"markdown","555a7e52":"markdown","bcc3de16":"markdown","244f1e52":"markdown","32a241bc":"markdown","16de0463":"markdown"},"source":{"8f94eaaa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4594fdeb":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","297521f6":"train.sample(10)","cb6c17c9":"train.info()","cee248b5":"print ('Survives percentage -', train.Survived.mean()) ","96f04067":"print(pd.DataFrame(train.groupby('Sex').mean().Survived))\nprint('------------------------------')\nprint(pd.DataFrame(train.groupby('Pclass').mean().Survived))","23a0da69":"print(train.groupby(['Pclass','Sex']).mean().Survived.unstack()), \nsns.catplot(x='Survived', kind='count', hue='Sex', col = 'Pclass', data=train)","df866901":"print(train.groupby(['Embarked','Sex']).mean().Survived.unstack()), \nsns.catplot(x='Sex', y='Survived', kind='bar', col='Embarked', data=train)","a59e22fd":"fig, (ax0,ax1) = plt.subplots (1, 2, figsize=(15, 5))\nsns.catplot(x='Survived', y='Age', kind=\"violin\", hue = 'Pclass', data=train, ax = ax0)\nplt.close(2)\nsns.catplot(x='Survived', y='Fare',  kind=\"violin\", hue = 'Sex', split = True, data=train, ax = ax1)\nplt.close(2)","7d85d735":"train[train.Fare > 300][['Fare','Survived']]","6a46938d":"train.isnull().mean()","53f50155":"print(train.groupby(['Sex','Pclass']).Age.median().unstack()),\nsns.boxplot(x=\"Pclass\", y=\"Age\",hue=\"Sex\",data=train)","b5f6589e":"for data in [train, test]:\n    # Delete useless columns\n    data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1, inplace = True)\n    \n    # Fill missing data\n    # Use median in groups of Sex and Class for Age\n    data.Age = data.groupby(['Sex','Pclass']).Age.transform(lambda x: x.fillna(np.nanmedian(x)))\n    # Use mode for Embarked and median for Fare\n    data.Embarked.fillna(data.Embarked.mode()[0], inplace = True)\n    data.Fare.fillna(np.nanmedian(data.Fare), inplace = True)\n    \n    # Convert categorical features to numeric\n    data['Sex_num'] = data.Sex.map({'female': 0, 'male':1})\n    data['Embarked_num'] = data.Embarked.map({'S': 0, 'C':1, 'Q': 2})\n    \n    # Create a feature Isalone where 1 means a person without family on boart, 0 means a person with family members on Titanic\n    data['Family_size'] = data.SibSp + data.Parch + 1\n    data['Isalone'] = 0\n    data.loc[data.Family_size == 1, ['Isalone']] = 1\n    \n    # Delete useless columns\n    data.drop(['Sex', 'Embarked', 'SibSp', 'Parch'], axis = 1, inplace = True)\n    \n    # Divide Age and Fare into categorical groups\n    data['Age_num'] = pd.cut(data.Age, 5, labels = [0,1,2,3,4]).astype(int)\n    data['Fare_num'] = pd.qcut(data.Fare, 5, labels = [0,1,2,3,4]).astype(int)\n    data.drop(['Age', 'Fare'], axis = 1, inplace = True)","790a7221":"train.sample(10)","be0324bb":"print(train.corr()['Survived'])\nsns.heatmap(train.corr())","f32b4008":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb","d6dab8c1":"# Divide train data to independent and target variables\ndata_y = train.Survived\ntrain.drop (['Survived'], axis = 1, inplace = True)","53aa56f5":"# Create a model variable\nclf = xgb.XGBClassifier ()\n# Create a dictionary with model parameters\nparams = {\n    \"colsample_bytree\": [0.1, 0.2, 0.3, 0.4, 0.5],\n    \"learning_rate\": [0.2, 0.3, 0.4], \n    \"max_depth\": range (5, 15),\n    \"n_estimators\": [50, 70, 100, 150],\n    \"subsample\": [0.4, 0.5, 0.6, 1],\n    'min_child_weight': [1, 5, 10],\n    'gamma': [0.5, 1, 1.5, 2, 5]}","c1dcc3e9":"# Select the best params from dictionary\nsearch = GridSearchCV(clf, params, n_jobs=5, scoring='accuracy')\nsearch.fit(train, data_y)\nsearch.best_score_","eeb98627":"# Get best parameters\nsearch.best_params_","e305b05e":"# Apply model with selected parameters\nmodel = xgb.XGBClassifier(colsample_bytree = 0.5, gamma = 5, learning_rate = 0.4, max_depth = 5, n_estimators = 50, subsample = 1, min_child_weight= 1)\nmodel.fit (train, data_y)\nresult = model.predict(test)","fc481544":"# Save final file\nsubmission = pd.DataFrame({\n        'PassengerId': pd.read_csv(\"..\/input\/titanic\/test.csv\")['PassengerId'],\n        'Survived': result})\nsubmission.to_csv('submission.csv', index = False)","bacfaf1f":"There are only 3 passengers who paid high price - 512. These outliners leads to such peak at the graphic before.","b3b1549f":"As we can see below, other cathegorical feature 'Embarked' has high influence on the target feature - C embarked passengers have 87% and 30% survavial rate for female and male respectively.","b8f549d0":"Check our new data look.","e332dddc":"Let`s move to data cleaning. There are some missing data. Get the list of missing values percentage.","2d96f452":"After transformation we can see that Sex, Class, Fare and relatives absence have impact on survival rate. Sex = 1 (Male), relatives absence ('Isalone' = 1), higher class decrease chances to survive. On the contarary, high Fare leads to higher survival rate. ","8dbc1746":"38% of passengers from the dataset were survived. Let`s see which factors increase survavial rate.","024f84c1":"Move to numeric features. Based on violin graphic  we see that children had higher probability to survive. The right graph descibes Fare correlation with survival rate, but I would like to check  observation larger than 300.","39ea5e28":"If we combine these 2 features we discover that females from 1 and 2 classes have 96% and 92% of survived. At the same time women from 3 class have 50\/50 chances to survive.","555a7e52":"As we can see median age is lower in lower class, so we can use this pattern later.","bcc3de16":"As it was pointed out earleir the majority of men could not survived, but we need to pay atttention that they have better chances if they were at the 1 class - 36% survived (only 15% and 13% in 2 and 3 classes).","244f1e52":"* Little missing data of 'Embarked', probably we can use the top frequent category. \n* 77% of 'Cabin' is NaN value. It is too much to handle it. Moreover, it`s a random meaning, so let drop this column. \n* Almost fifth part of Age feature is missing. At the same time it is one of crucial feature in the model. So it is better to fill it by using median meaning. Let`s check how the median differs in Sex\/Class groups.","32a241bc":"Group our data by sex and class - here we can see that female have better chances to survive than male. Additionally, higher clas means that passenger has higher chances to survive.","16de0463":"Let`s make some data transformation:\n* Drop passenger's ID, name, ticket and cabin number, because they are mostly random and we can't extract any benifit.\n* Convert categorical features 'Sex' and 'Emberked' to numeric data.\n* Create a new feature showed if a person was alone or with family on the board.\n* Divide 'Age' and 'Fare' into groups, so we can solve problem with outliners. "}}