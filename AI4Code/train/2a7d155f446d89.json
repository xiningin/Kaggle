{"cell_type":{"b7b51e8c":"code","06a2e99f":"code","dd2a4646":"code","e43a8fce":"code","53e54836":"code","e5982e5a":"code","c5a278e7":"code","fee5ac87":"code","5da76d6c":"code","ce0cfc22":"markdown","1bfe0010":"markdown","87191183":"markdown","da6cd4f7":"markdown","c1430064":"markdown","55972b66":"markdown","ec2b10c8":"markdown","96ff69da":"markdown"},"source":{"b7b51e8c":"# # First prediction\n# # The results are saved in the file submission_old.csv, fields: id, label_old, pred_old\n\n# submission_old = pd.DataFrame.from_dict({'id': test_img_paths, 'label_old': test_predictions, 'pred_old': test_predictions})\n\n# submission_old['label_old'] = submission_old['label_old'].map(lambda pred: 'dirty' if pred > 0.5 else 'cleaned')\n# submission_old['id'] = submission_old['id'].str.replace('\/kaggle\/working\/test\/unknown\/', '')\n# submission_old['id'] = submission_old['id'].str.replace('.jpg', '')\n# submission_old.set_index('id', inplace=True)\n\n# submission_old.to_csv('submission_old.csv')\n# submission_old.head()","06a2e99f":"# # Second prediction\n# # For example, we change the learning speed from 0.0001 to 0.00015. Run all the code in the first block again. \n# # We skip the block with the first prediction (we do not start it), otherwise the previous result in the submission_old.csv file will be erased.\n# # The new results will be saved in the file submission_new.csv, fields: id, label_new, pred_new\n\n# submission_new = pd.DataFrame.from_dict({'id': test_img_paths, 'label_new': test_predictions, 'pred_new': test_predictions})\n\n# submission_new['label_new'] = submission_new['label_new'].map(lambda pred: 'dirty' if pred > 0.5 else 'cleaned')\n# submission_new['id'] = submission_new['id'].str.replace('\/kaggle\/working\/test\/unknown\/', '')\n# submission_new['id'] = submission_new['id'].str.replace('.jpg', '')\n# submission_new.set_index('id', inplace=True)\n\n# submission_new.to_csv('submission_new.csv')\n# submission_new.head()","dd2a4646":"import pandas as pd\n\ndf_old = pd.read_csv(\"..\/input\/submission\/submission_new.csv\")\ndf_new = pd.read_csv(\"..\/input\/submission\/submission_old.csv\")","e43a8fce":"df_test = df_old.merge(df_new, on='id')\nsubset = df_test.query(\"label_old != label_new\")\nsubset.head(100)","53e54836":"import os\nprint(os.listdir(\"..\/input\"))","e5982e5a":"import zipfile\nwith zipfile.ZipFile('..\/input\/platesv2\/plates.zip', 'r') as zip_obj:\n    zip_obj.extractall('\/kaggle\/working\/')\n\nprint(os.listdir('\/kaggle\/working\/'))\nprint(os.listdir('\/kaggle\/working\/plates\/'))","c5a278e7":"from PIL import Image\nimport matplotlib.pyplot as plt\n\nn = len(subset)+1\ns = 0\nplt.figure(figsize=(20, round(n*3)))\nfor i, l in zip(subset['id'], subset['label_new']):\n    i = str(i).zfill(4)\n    img = Image.open(f'\/kaggle\/working\/plates\/test\/{i}.jpg')\n    plt.subplot(round(n\/2), 3, s + 1)\n    s += 1\n    plt.imshow(img)\n    plt.title(f'{i} {l}')\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","fee5ac87":"midlle_pred = 0.5\nstep = 0.05\n\ndirty_old = df_test.query(\"label_old == 'dirty' & pred_old < @midlle_pred + @step\")\ncleaned_old = df_test.query(\"label_old == 'cleaned' & pred_old > @midlle_pred - @step\")\n\ndirty_new = df_test.query(\"label_new == 'dirty' & pred_new < @midlle_pred + @step\")\ncleaned_new = df_test.query(\"label_new == 'cleaned' & pred_new > @midlle_pred - @step\")\n\nfig, ax = plt.subplots()\n\n# colors: 'b', 'g', 'r', 'c', 'm', 'y', 'k', 'w'\n\nax.scatter(dirty_old.pred_old, dirty_old.id, c = 'm', alpha = 0.5)\nax.scatter(cleaned_old.pred_old, cleaned_old.id, c = 'y', alpha = 0.5)\n\nax.scatter(dirty_new.pred_new, dirty_new.id, c = 'r')\nax.scatter(cleaned_new.pred_new, cleaned_new.id, c = 'g')\n\nax.plot([midlle_pred, midlle_pred], [0, 744], c = 'b')\n#ax.plot([0.795, 0.795], [0, 744], c = 'b')\n\nax.minorticks_on()\nax.grid(which='major', color = 'k', linewidth = 0.5)\nax.grid(which='minor', color = 'k', linestyle = ':')\n\nfig.set_figwidth(16)\nfig.set_figheight(12)\n\n# for x, y in zip(dirty_old.pred, dirty_old.id):\n#     plt.text(x, y, y)\n# for x, y in zip(cleaned_old.pred, cleaned_old.id):\n#     plt.text(x, y, y)\n    \nfor x, y in zip(dirty_new.pred_new, dirty_new.id):\n    plt.text(x, y, y)\nfor x, y in zip(cleaned_new.pred_new, cleaned_new.id):\n    plt.text(x, y, y)\n\nplt.show()","5da76d6c":"!rm -rf train val test plates __MACOSX","ce0cfc22":"## Prediction analysis\nWe have two files with predictions (old and new): submission_old.csv, submission_new.csv. We will carry out a small analysis of the predictions. Purpose: to visually determine whether our model began to predict better or worse.\n\n\n\u0423 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u0434\u0432\u0430 \u0444\u0430\u0439\u043b\u0430 \u0441 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 (\u0441\u0442\u0430\u0440\u044b\u0439 \u0438 \u043d\u043e\u0432\u044b\u0439): submission_old.csv, submission_new.csv. \u041f\u0440\u043e\u0432\u0435\u0434\u0451\u043c \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0430\u043d\u0430\u043b\u0438\u0437 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439. \u0426\u0435\u043b\u044c: \u0432\u0438\u0437\u0443\u0430\u043b\u044c\u043d\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u043b\u0443\u0447\u0448\u0435 \u0438\u043b\u0438 \u0445\u0443\u0436\u0435 \u0441\u0442\u0430\u043b\u0430 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0442\u044c \u043d\u0430\u0448\u0430 \u043c\u043e\u0434\u0435\u043b\u044c.","1bfe0010":"This method helped me to increase the result on LB by about 5%, I hope it will be useful to you. The method is based on a comparison of the last two submission, it helps to determine how good the new model is, how and what parameters and hyperparameters change the predictions. Based on [notebook](https:\/\/www.kaggle.com\/yellowduck\/baseline-in-pytorch) Igor.Slinko, the analysis of predictions comes after it.\n\nFor example, you need two submission.\n* The first submission_old file I received with: optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=0.0001, weight_decay=0.20)\n* Second submission_new file, with:  optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=0.00015, weight_decay=0.20)","87191183":"\u0414\u0430\u043d\u043d\u044b\u0439 \u0441\u043f\u043e\u0441\u043e\u0431 \u043f\u043e\u043c\u043e\u0433 \u043c\u043d\u0435 \u043f\u043e\u0434\u043d\u044f\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043d\u0430 LB \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u043d\u0430 5%, \u043d\u0430\u0434\u0435\u044e\u0441\u044c \u043e\u043d \u0431\u0443\u0434\u0435\u0442 \u043f\u043e\u043b\u0435\u0437\u0435\u043d \u0432\u0430\u043c. \u041c\u0435\u0442\u043e\u0434 \u043e\u0441\u043d\u043e\u0432\u0430\u043d \u043d\u0430 \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0438 \u0434\u0432\u0443\u0445 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0445 submission, \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u043d\u0430 \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0445\u043e\u0440\u043e\u0448\u0430 \u043d\u043e\u0432\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c, \u043a\u0430\u043a \u0438 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0438 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0438\u0437\u043c\u0435\u043d\u044f\u044e\u0442 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f. \u0417\u0434\u0435\u0441\u044c \u0437\u0430 \u043e\u0441\u043d\u043e\u0432\u0443 \u0432\u0437\u044f\u0442 [notebook](https:\/\/www.kaggle.com\/yellowduck\/baseline-in-pytorch) Igor.Slinko. \n\n\u0414\u043b\u044f \u043f\u0440\u0438\u043c\u0435\u0440\u0430 \u043d\u0443\u0436\u043d\u043e \u0434\u0432\u0430 submission. \n* \u041f\u0435\u0440\u0432\u044b\u0439 \u0444\u0430\u0439\u043b submission_old \u044f \u043f\u043e\u043b\u0443\u0447\u0438\u043b \u043f\u0440\u0438: optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=0.0001, weight_decay=0.20)\n* \u0412\u0442\u043e\u0440\u043e\u0439 \u0444\u0430\u0439\u043b submission_new, \u043f\u0440\u0438:  optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=0.00015, weight_decay=0.20)","da6cd4f7":"Well, almost all of the plates (out of 83) have changed correctly. \u0425\u043e\u0440\u043e\u0448\u043e, \u043f\u043e\u0447\u0442\u0438 \u0432\u0441\u0435 \u0442\u0430\u0440\u0435\u043b\u043a\u0438 (\u0438\u0437 83) \u0438\u0437\u043c\u0435\u043d\u0438\u043b\u0438\u0441\u044c \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e. ","c1430064":"You can also improve the result by shifting midlle_pred, for example, between 0.49 and 0.50 midlle_pred there are more dirty dishes, then it makes sense to move midlle_pred to 0.49, where midlle_pred is the threshold for dividing plates into clean and dirty.\n\n\u0415\u0449\u0451, \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \"\u043d\u0430\u0442\u044f\u043d\u0443\u0442\u044c\" \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043c\u0435\u0436\u0434\u0443 0,49 \u0438 0,50 midlle_pred \u0431\u043e\u043b\u044c\u0448\u0435 \u0433\u0440\u044f\u0437\u043d\u044b\u0445 \u0442\u0430\u0440\u0435\u043b\u043e\u043a, \u0442\u043e\u0433\u0434\u0430 \u0438\u043c\u0435\u0435\u0442 \u0441\u043c\u044b\u0441\u043b \u043f\u0435\u0440\u0435\u043c\u0435\u0441\u0442\u0438\u0442\u044c midlle_pred \u0432 0.49, \u0433\u0434\u0435 midlle_pred - \u043f\u043e\u0440\u043e\u0433 \u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0442\u0430\u0440\u0435\u043b\u043e\u043a \u043d\u0430 \u0447\u0438\u0441\u0442\u044b\u0435 \u0438 \u0433\u0440\u044f\u0437\u043d\u044b\u0435.\n\nIf you have questions, write. Good luck on LB!","55972b66":"On LB, these files have very low prediction, but enough for an example. submission_old ~ 0.71, submission_new ~ 0.74","ec2b10c8":"Below are two blocks for an example of how to create files for analysis. \u041d\u0438\u0436\u0435 \u0434\u0432\u0430 \u0431\u043b\u043e\u043a\u0430 \u0434\u043b\u044f \u043f\u0440\u0438\u043c\u0435\u0440\u0430, \u043a\u0430\u043a \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0444\u0430\u0439\u043b\u044b \u0434\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430.","96ff69da":"There are more dirty plates (+83), look at them. \u0413\u0440\u044f\u0437\u043d\u044b\u0445 \u0442\u0430\u0440\u0435\u043b\u043e\u043a \u0441\u0442\u0430\u043b\u043e \u0431\u043e\u043b\u044c\u0448\u0435 (+83), \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043d\u0438\u0445."}}