{"cell_type":{"e3548a4c":"code","98719131":"code","5f8eae48":"code","e0514b51":"code","e659afca":"code","6502caa8":"code","227ff290":"code","d0330f45":"code","7e6bab20":"code","37cc75dc":"code","63512cb9":"markdown","92669fee":"markdown","96f9696c":"markdown","01010459":"markdown","e5c7c1ef":"markdown","4b839877":"markdown","6b0f7fc1":"markdown","f6499227":"markdown","a4ffcef4":"markdown","67362df3":"markdown","e86316d0":"markdown","306b7926":"markdown","b67bc982":"markdown","40118611":"markdown","f5865f94":"markdown","70ed28b0":"markdown","2e78e526":"markdown","34aebe84":"markdown","1a84d750":"markdown","18bac397":"markdown"},"source":{"e3548a4c":"import os\nimport io\nimport json\nimport tarfile\nimport glob\nimport time\nimport logging\nimport boto3\nimport requests\nimport PIL\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nfrom torchvision import models, transforms","98719131":"def load_and_process_image(url, size):\n    # Notice the unsqueeze part in the last line,this is for having a batch size of 1.\n    img_request = requests.get(url, stream=True)\n    img = PIL.Image.open(io.BytesIO(img_request.content))\n    img = img.convert('RGB')\n    img = img.resize((size, size),PIL.Image.BILINEAR)\n    res = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n    res = res.view(size, size, -1).permute(2,0,1).float().div_(255)\n    return(res.unsqueeze(0))","5f8eae48":"url = \"https:\/\/drive.google.com\/uc?export=download&id=1W-3GLMoKv00i_w1niGqEdcZjDDDjbFmw\" # 00028173_003.png\nload_and_process_image(url, size = 128)","e0514b51":"def predict(input_object, model):\n    \"\"\"Predicts the class from an input image.\n    Parameters\n    ----------\n    input_object: Tensor, required\n        The tensor object containing the image pixels reshaped and normalized.\n    Returns\n    ------\n    Response object: dict\n        Returns the predicted class and confidence score.\n    \n    \"\"\"        \n    predict_values = model(input_object)\n    predict_values = F.softmax(predict_values)\n    response = prediction_one_label(predict_values)\n    response_str = prediction_multi_labels(predict_values)\n    response['multi_label'] = response_str\n    return response","e659afca":"def prediction_one_label(predict_values):\n    preds = F.softmax(predict_values, dim=1)\n    conf_score, indx = torch.max(preds, dim=1)\n    predict_class = classes[indx]\n    response = {}\n    response['single_class'] = str(predict_class)\n    response['single_confidence'] = conf_score.item()\n    response['predict_values'] = predict_values\n    return response","6502caa8":"def prediction_multi_labels(predict_values):\n    indxx = (predict_values > threshholds)\n    indxx = np.array(indxx).reshape(-1)\n    output = [classes[x]  for x in range (len(classes))  if  (indxx[x]==1)] \n    output = [x.decode('utf-8') for x in output ] \n    if (len(output) > 1):\n        output = [x for x in output if str(x) != 'No Finding']\n    retval = ';'.join(output); retval\n    return retval","227ff290":"bucket_url = 'https:\/\/tfg-models.s3.us-east-2.amazonaws.com\/chestxray.tar.gz' \nACCESS_ID = 'AKIARM4DEL66FTOYP72M'\nACCESS_KEY = '4+5UlbGmbl48wZY2rKyaGR4RVXW7OF\/oDe+dO4k2'\nMODEL_BUCKET = \"test-model-bucket\"\nMODEL_KEY = \"chestxray.tar.gz\"\nTHRESHOLD_VALUES = torch.tensor([.20,.20,.20,.20,.20,.20,.20,.20,.20,.20,.20,.20,.20,.20,.20]) ","d0330f45":"def load_model():\n    \"\"\"Loads the PyTorch model into memory from a file on S3.\n    Returns\n    ------\n    Vision model: Module\n        Returns the vision PyTorch model to use for inference.\n    The developer needs to replace print call to logger.info before uploading to aws lambda.    \n    \n    \"\"\"      \n    global classes\n    global threshholds\n    threshholds = THRESHOLD_VALUES # Multilabel Thresholds\n    s3 = boto3.client('s3', aws_access_key_id=ACCESS_ID, aws_secret_access_key= ACCESS_KEY)\n    print('Loading model from S3')\n    obj = s3.get_object(Bucket=MODEL_BUCKET, Key=MODEL_KEY)\n    bytestream = io.BytesIO(obj['Body'].read())\n    tar = tarfile.open(fileobj=bytestream, mode=\"r:gz\")\n    for member in tar.getmembers():\n        if member.name.endswith(\".txt\"):\n            print(\"Classes file is :\", member.name)\n            f=tar.extractfile(member)\n            classes = f.read().splitlines()\n            print(classes)\n        if member.name.endswith(\".pth\"):\n            print(\"Model file is :\", member.name)\n            f=tar.extractfile(member)\n            print(\"Loading PyTorch model\")\n            model = torch.jit.load(io.BytesIO(f.read()), map_location=torch.device('cpu')).eval()\n    return model","7e6bab20":"model = load_model()","37cc75dc":"img_url = \"https:\/\/drive.google.com\/uc?export=download&id=1W-3GLMoKv00i_w1niGqEdcZjDDDjbFmw\"\ninput_object = load_and_process_image(img_url, size = 128)\nstart_time = time.time()\nprint(\"--- Object loading time: %s seconds ---\" % (time.time() - start_time))\nprint(input_object.size())\nprint(\"Calling prediction\")\nstart_time = time.time()\nresponse = predict(input_object, model)\nprint(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))\nprint(response)","63512cb9":"# Background & Motivation\n\nChest X-ray exam is one of the most frequent and cost-effective medical imaging examination. However clinical diagnosis of chest X-ray can be challenging, and sometimes believed to be harder than diagnosis via chest CT imaging. Even some promising work have been reported in the past, and especially in recent deep learning work on Tuberculosis (TB) classification. NIH Chest X Ray Dataset (https:\/\/nihcc.app.box.com\/v\/ChestXray-NIHCC) provides a comprehensive dataset of X Rays which may be used for developing machine learning models which can predict diseases related to chest region. This dataset comprises of 14 labels of data, listed below:\n\n(1, Atelectasis; 2, Cardiomegaly; 3, Effusion; 4, Infiltration; 5, Mass; 6, Nodule; 7, Pneumonia; 8, Pneumothorax; 9, Consolidation; 10, Edema; 11, Emphysema; 12, Fibrosis; 13, Pleural_Thickening; 14 Hernia)\n\n![image.png](attachment:image.png)\n\nSource(http:\/\/academictorrents.com\/details\/557481faacd824c83fbf57dcf7b6da9383b3235a)\n\nAs challenging is to train an efficient and accurate ML model, equally challenging is to provide this model for consumption. Also, we are looking to create the experience closer to reality. i.e. when an examiner looks at the X-Ray, (s)he is able to tell about a number of diseases, similarly, our model hosting also achieves this, i.e. it can output a number of labels (symptoms in an X-Ray) (**multi-label classification**).\n\nHere in this article, we will focus on How to host a pretrained Deep Learning model on a cloud platform.","92669fee":"Above code execution eastablishes that the model loading, image processing and getting inference are working as per the expectations. We have also observed how an image tensor looks like. Now it is the time to thread the pieces together and so that they are made available in a AWS Lambda function.\n\nWhile deploying the model at Lambda layer, we need to do certain changes, instead of putting the various keys and values in a script, they would be passed dynamically. Following will make this clear.\n\n![image.png](attachment:image.png)\n\nNow, its time to stitch the input_fn and predict functions together. Once various pieces are done, input_fn and predict become very easy.\n\n![image.png](attachment:image.png)","96f9696c":"# Loading model\nThis is done once so there is no overhead to loading the model every time. Please note that threshold values are important for multi-label classification which are obtained from statistical considerations, and applicable for the use case we are trying to solve.","01010459":"![image.png](attachment:image.png)","e5c7c1ef":"# predict_multi_labels","4b839877":"* Notice that predict function is used as a wrapper, which calls rwo functions , `predict_one_label` and `predict_multi_labels`. This is an important addition where we can handle the use case of how to handle multi label prediction at inference stage.","6b0f7fc1":"**IMPORTANT**\n\nBefore calling the model, the important thing is to load the image, resize this and do transformations, if applicable. Sometimes, if there is a mismatch in the methodology how a image has been loaded, resized at the training time and inference time, we may get random results.\n\nNo matter, how good our model is, if this step is not right, we may not expect our model to behave rightly. There may be some loss of pixel values, because of randomness produced due to resizing of images, but generally tensors should match. Hence this is recommended to match the pixel values of the image at train time and inference time and ensure that these agree.\n\nTo facilitate this, `load_and_process_image` function is written, whose input is url to an image which needs to be examined. Lets look at the function and examine the output.","f6499227":"# Objective:\n\nObjective of this notebook is how to host Deep Learning Models on AWS Lambda layer. The emphasis is to follow a structured approach which could help in following a template when it comes to hosting Deep Learning models. Contrary to the belief that we need a GPU based environment for model serving, I would like to highlight that CPU based model serving does well. \n\nA structured approach helps in testing a model before depoying on AWS Lambda. This also saves on  debugging time. The Deep Learning model is written using python's FastAI and Pytorch libraries. \n\nThese libraries enable to quickly write Deep Learning models. Pytorch has become quite popular in just two years after its release and FastAI is further helping by providing a framework which makes it an appropriate choice in applying deep learning techniques to industry problems.\n\nThis article also describes about how to test pieces of code in a Jupyter Notebook, before deploying to AWS Lambda.\n","a4ffcef4":"# Conclusion\n\nThats it! You can see that how a deep learning model built in Pytorch can be successfully wrapped inside a AWS lambda layer. This is useful, as deep learning models can be succesfully served on a cloud platform and this is also cost efficient and less maintenance centric. \n\nAnother advantage is that hosting on AWS enables this to scale when loads go up and user only pays for compute time.\n\nWe have also discovered a strategy where multi-label classification can be approached. This model hosting can also be tried at other cloud platforms like Azure.\n\nPlease send your feedback through the comments section. Happy Model Hosting!","67362df3":"# Calling Model","e86316d0":"# lambda_handler\nThe starting point of Lambda execution is **lambda_handler** function.","306b7926":"# Prerequisites\n\nYou will need a pretrained model in trained in Pytorch framework. Alongwith the model, output labels are also required. The trained model and output classes are included in a tar file.\n\nFor this case, the trained model is named as `chestxray_resnet50_jit.pth` and prediction classes are available in `classes.txt`. At the inference time, above two files are used to respond to a query sent in form of an image.\n\nThe name of the tarfile is `chestxray.tar.gz`\n\nAlso, the language for building models, productionizing on AWS lambda is python.\n\n**Note** : As this is an exercise on hosting a model, not much emphasis has been given to accuracy of the model, but the model is expected to do well as it is using resnet50 architecture with an optimal learning rate applied.","b67bc982":"# predict\nThe predict function does a few things. To help in aligning with business demands, helper functions like predict_one_label and predict_multi_labels are created and output is then sent back to caller. Following is the structure of the predict function. This returns a dictionary back to the caller.","40118611":"# Setting up AWS Access Parameters\n\nBefore accessing AWS resources, we need to set up some parameters which will tell the program where to take the resources (model and labels).\n\nNote: Following parameters will not work for you, you need to supply your own AWS account details. ","f5865f94":"# Prediction Service Hosted on AWS\nPrediction service is hosted on AWS lambda and the model is kept in a S3 bucket. The S3 bucket holds the tar file which houses model and label information and the execution is done at Lambda layer.\n\n![image.png](attachment:image.png)\n\nAbove gives a view of various AWS components required for model hosting. Please notice that how simple this architecture is.\n","70ed28b0":"Once the Lambda layer is invoked, the execution is done with two primary functions: **input_fn** and **predict**.\n\n- **input_fn** - This function internally calls load_and_process_image which takes an url and returns a image tensor. With the help of url, this input_fn_core can be tested in a jupyter notebook environment. Let us see this here. Here, in order to test the functionality in a notebook, `input_fn` is used as a wrapper function, which actually calls the `load_and_process_image` which takes a parameter called url as an input.\n\n- **predict** - This function encapsulates the call to model and applies logic for inferencing. In this article, we will also talk about a strategy to do multi-label classification, by using thresholds in a function `predict_multi_labels`.\n","2e78e526":"# predict_one_label","34aebe84":"![image.png](attachment:image.png)","1a84d750":"# Deploy on AWS Lambda\n\nYou will need aws and sam utilities to do the same. \nwith `aws configure` command, you can set up `ACCESS_ID` and `ACCESS_KEY` among other parameters.\nThen execute the following command:\n\n`sam package --output-template-file packaged.yaml --s3-bucket \"YOUR_BUCKET_NAME\"`\n\n`sam deploy --template-file packaged.yaml --stack-name \"YOUR_STACL_NAME\" --capabilities CAPABILITY_IAM --parameter-overrides BucketName=\"YOUR_BUCKET_NAME\" ObjectKey=chestxray.tar.gz`\n","18bac397":"## Testing the model from Command Line\n\nThis can be done using Curl Command. Some of the urls are masked and they will be changed as per your implementation.\n\n![image.png](attachment:image.png)\n\nNote: An example github project is available to you at https:\/\/github.com\/sinharitesh\/aws-lambda-starter . This is an uncustomized version, you need to implement various functions described above to fit to your needs."}}