{"cell_type":{"f486238f":"code","bb11b9be":"code","0add15c7":"code","2f018921":"code","ef2191af":"code","5b42da2f":"code","6b3d9224":"code","21bb6ed6":"code","18025860":"code","2e7b1bb3":"code","2d0ae42b":"code","9007c1ed":"code","2cba1a32":"code","8e282679":"code","290e926f":"code","c15a2914":"code","29bab712":"code","c2852cc8":"code","4919f7e4":"code","0e43d1bc":"code","2c900803":"code","b1303c8c":"code","da019284":"code","4d648f4f":"code","186cc5ab":"code","56d24ed8":"markdown","ee18ba5d":"markdown","e56ab796":"markdown","02677a76":"markdown","08119b6c":"markdown","b1f5cffe":"markdown","b8975582":"markdown","dee91d7e":"markdown","c454a665":"markdown","3fd2d287":"markdown","95c7eec1":"markdown","3e8fcb57":"markdown","e1f20711":"markdown","36c29eab":"markdown","7767f920":"markdown","60f4a2f2":"markdown"},"source":{"f486238f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim \nimport torchvision\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.utils.data as utils\nfrom torchvision import transforms\nimport torch.nn.functional as F","bb11b9be":"path = '..\/input\/severstal-steel-defect-detection\/'","0add15c7":"tr = pd.read_csv(path + 'train.csv')\nprint(len(tr))\ntr.head(6)","2f018921":"df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\ndf_train = df_train[df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\nprint(len(df_train))\ndf_train.head()","ef2191af":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","5b42da2f":"columns = 1\nrows = 4\nfig = plt.figure(figsize=(20,columns*rows+6))\nfor i in range(1,columns*rows+1):\n    fn = df_train['ImageId_ClassId'].str[:-2].iloc[i]\n    fig.add_subplot(rows, columns, i).set_title(fn)\n    img = cv2.imread( path + 'train_images\/'+fn )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n    img[mask==1,0] = 255\n    plt.imshow(img)\nplt.show()","6b3d9224":"class ImageData(Dataset):\n    def __init__(self, df, transform, subset=\"train\"):\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.subset = subset\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images\/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images\/'\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):                      \n        fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n        img = Image.open(self.data_path + fn)\n        img = self.transform(img)\n\n        if self.subset == 'train': \n            mask = rle2mask(self.df['EncodedPixels'].iloc[index], (256, 1600))\n            mask = transforms.ToPILImage()(mask)            \n            mask = self.transform(mask)\n            return img, mask\n        else: \n            mask = None\n            return img       ","21bb6ed6":"data_transf = transforms.Compose([\n                                  transforms.Scale((256, 256)),\n                                  transforms.ToTensor()])\ntrain_data = ImageData(df = df_train, transform = data_transf)\ntrain_loader = DataLoader(dataset = train_data, batch_size=4)","18025860":"plt.imshow(train_data[3][0].permute(1, 2, 0))","2e7b1bb3":"plt.imshow(np.squeeze(train_data[3][1].permute(1, 2, 0)))","2d0ae42b":"def convrelu(in_channels, out_channels, kernel, padding):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n# copied from 682\n# model = nn.Sequential(\n#     nn.Conv2d(3, 64, 3, padding=1, stride=1),\n#     nn.BatchNorm2d(64),\n#     nn.ELU(),\n#     nn.Conv2d(64, 64, 3, padding=1, stride=1),\n#     nn.BatchNorm2d(64),\n#     nn.ELU(),\n#     nn.MaxPool2d(2), #32\/2\n        nn.ReLU(inplace=True),\n    )\n\nclass UNet(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        \n        self.base_model = models.resnet18()\n        self.base_model.load_state_dict(torch.load(\"..\/input\/resnet18\/resnet18.pth\"))\n        self.base_layers = list(self.base_model.children())\n\n        self.layer0 = nn.Sequential(*self.base_layers[:3])\n        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n        self.layer1 = nn.Sequential(*self.base_layers[3:5])\n        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n        self.layer2 = self.base_layers[5]\n        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n        self.layer3 = self.base_layers[6]\n        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n        self.layer4 = self.base_layers[7]\n        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n\n        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n\n        self.conv_last = nn.Conv2d(64, n_class, 1)\n\n    def forward(self, input):\n        x_original = self.conv_original_size0(input)\n        x_original = self.conv_original_size1(x_original)\n\n        layer0 = self.layer0(input)\n        layer1 = self.layer1(layer0)\n        layer2 = self.layer2(layer1)\n        layer3 = self.layer3(layer2)\n        layer4 = self.layer4(layer3)\n\n        layer4 = self.layer4_1x1(layer4)\n        x = self.upsample(layer4)\n        layer3 = self.layer3_1x1(layer3)\n        x = torch.cat([x, layer3], dim=1)\n        x = self.conv_up3(x)\n\n        x = self.upsample(x)\n        layer2 = self.layer2_1x1(layer2)\n        x = torch.cat([x, layer2], dim=1)\n        x = self.conv_up2(x)\n\n        x = self.upsample(x)\n        layer1 = self.layer1_1x1(layer1)\n        x = torch.cat([x, layer1], dim=1)\n        x = self.conv_up1(x)\n\n        x = self.upsample(x)\n        layer0 = self.layer0_1x1(layer0)\n        x = torch.cat([x, layer0], dim=1)\n        x = self.conv_up0(x)\n\n        x = self.upsample(x)\n        x = torch.cat([x, x_original], dim=1)\n        x = self.conv_original_size2(x)\n\n        out = self.conv_last(x)\n\n        return out","9007c1ed":"model = UNet(n_class=1).cuda()\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.SGD(model.parameters(), weight_decay=1e-4, lr = 0.001, momentum=0.9)","2cba1a32":"%%time\nfor epoch in range(5):      \n    model.train()         \n    for ii, (data, target) in enumerate(train_loader):                         \n        data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)  \n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()          \n    print('Epoch: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))","8e282679":"plt.imshow(train_data[6][0].permute(1, 2, 0))","290e926f":"x = train_data[6][0].unsqueeze(0)\no = model(x.cuda())  \no = o.cpu().detach().numpy() * (-1)\ntmp = np.copy(o)\nmn = np.mean(o)*1.2\ntmp[tmp<mn] = 0\ntmp[tmp>mn] = 1\nplt.imshow(np.squeeze(tmp))","c15a2914":"submit = pd.read_csv(path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '})\nprint(len(submit))\nsub4 = submit[submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')]\nprint(len(sub4))\nsub4.head()","29bab712":"test_data = ImageData(df = sub4, transform = data_transf, subset=\"test\")\ntest_loader = DataLoader(dataset = test_data, shuffle=False)","c2852cc8":"%%time\npredict = []\nmodel.eval()\nfor data in test_loader:\n    data = data.cuda()\n    output = model(data)  \n    output = output.cpu().detach().numpy() * (-1)    \n    predict.append(abs(output[0]))","4919f7e4":"def mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,1)   \n    for i in range( len(tmp) ):\n        if (lastColor==0) and tmp[i]>0:\n            startpos = i\n            lastColor = 1\n        elif (lastColor==1)and(tmp[i]==0):\n            endpos = i-1\n            lastColor = 0\n            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n    return \" \".join(rle)","0e43d1bc":"%%time\npred_rle = []\n  \nfor p in predict:        \n    img = np.copy(p)\n    mn = np.mean(img)*1.2\n    img[img<=mn] = 0\n    img[img>mn] = 1\n    img = cv2.resize(img[0], (1600, 256))\n    \n    pred_rle.append(mask2rle(img))","2c900803":"submit['EncodedPixels'][submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')] = pred_rle\nsubmit.head()","b1303c8c":"img_s = cv2.imread( path + 'test_images\/'+ submit['ImageId_ClassId'][47].split('_')[0])\nplt.imshow(img_s)","da019284":"mask_s = rle2mask(submit['EncodedPixels'][47], (256, 1600))\nplt.imshow(mask_s)","4d648f4f":"submit.head(10)","186cc5ab":"submit.to_csv('submission.csv', index=False)","56d24ed8":"### Create train Dataset and DataLoader","ee18ba5d":"#### To simplify and speed up process, n this kernel I use only images with ClassId=4","e56ab796":"### Read train dataframe","02677a76":"### Create test Dataset and DataLoader","08119b6c":"### Show prediction on image from train dataset","b1f5cffe":"### Import necessary libraries","b8975582":"### Prediction","dee91d7e":"### Create U-Net Model","c454a665":"### Read submit file","3fd2d287":"### Display some images","95c7eec1":"### Resize images","3e8fcb57":"### Encode mask ","e1f20711":"### Decode mask","36c29eab":"### Training","7767f920":"### Show some image and mask","60f4a2f2":"### Prepare submission file"}}