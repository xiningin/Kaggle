{"cell_type":{"877f34c9":"code","832cf434":"code","ddc6f3f1":"code","dfb9b968":"code","be44fd12":"code","6183cf35":"code","3a15cbef":"code","dcd9d962":"code","0573c57a":"code","74620440":"code","0d3173e4":"code","5c0df352":"code","09995e3c":"code","86687579":"code","5e0d0597":"code","073b658e":"code","b5dc0355":"code","e9f78ccc":"code","c7204f16":"code","7fcce0a6":"code","a6ae09c1":"code","f05435b3":"code","9f0ba509":"code","1192dfa1":"code","6f64d140":"code","fb7d1128":"code","ce4cefdb":"markdown","2300f22b":"markdown","f3afe88f":"markdown","ad8048f8":"markdown","16bfc6f5":"markdown","821450e4":"markdown"},"source":{"877f34c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","832cf434":"df=pd.read_csv('..\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv')\ndf.head()","ddc6f3f1":"df.drop(['RowNumber','CustomerId','Surname'],axis=1,inplace=True)","dfb9b968":"df.Geography.unique()","be44fd12":"df[df.Exited==1]","6183cf35":"from matplotlib import pyplot as plt\nplt.hist([df[df.Exited==1].Balance,df[df.Exited==0].Balance])","3a15cbef":"plt.hist([df[df.Exited==1].CreditScore,df[df.Exited==0].CreditScore])","dcd9d962":"df['Gender'].replace({'Male':1,'Female':0},inplace=True)","0573c57a":"df['Geography'].replace({'France':1,'Spain':0,'Germany':2},inplace=True)","74620440":"df.head()","0d3173e4":"import seaborn as sn\nsn.boxenplot(data=df,y=df.Balance)","5c0df352":"df1=df.Balance>200000\ndf1.value_counts()","09995e3c":"df = df.loc[df[\"Balance\"] < 200000]","86687579":"df.shape","5e0d0597":"sn.boxenplot(data=df,y=df.EstimatedSalary)","073b658e":"df.dtypes","b5dc0355":"df.Balance = df.Balance.astype(int)\ndf.EstimatedSalary = df.EstimatedSalary.astype(int)","e9f78ccc":"cols_to_scale = ['CreditScore','Geography','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])","c7204f16":"x=df.drop('Exited',axis=1)\n\ny=df.Exited","7fcce0a6":"from sklearn.model_selection import train_test_split,cross_val_score\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=None)","a6ae09c1":"import tensorflow as tf\nfrom tensorflow import keras","f05435b3":"x_train.shape","9f0ba509":"model=keras.Sequential([\n    keras.layers.Dense(10, input_shape=(10,),activation='relu'),\n    keras.layers.Dense(5,activation='sigmoid'),\n    keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.compile(optimizer='SGD',\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","1192dfa1":"model.fit(x_train,y_train,epochs=5)","6f64d140":"model.evaluate(x_test,y_test)","fb7d1128":"from sklearn.linear_model import LogisticRegression\ncross_val_score(LogisticRegression(),x,y).mean()","ce4cefdb":"we understood that where the balance is zero there is high number of people are there","2300f22b":"But we have to go with the data that's why we removed outlier's in data","f3afe88f":"as per data no outlier's\nand start building the model","ad8048f8":"and check estimated salary outlier's in it","16bfc6f5":"we cannot assume that above 200000 is outlier because in bank deposit above 2 lakh is common but this \ndata is imbalanced i think so","821450e4":"some type of visualisation is over let's do the feature engineering"}}