{"cell_type":{"92bd7026":"code","f0525ae2":"code","db7d589e":"code","74d44433":"code","4ce7f31e":"code","77b99bcb":"code","03023d91":"code","8c6a8766":"code","641fbc90":"code","fb7dc9a1":"code","390ec380":"code","7409553b":"code","dd64838e":"code","408738b5":"code","747f67d9":"code","ac5ad034":"code","0573bb89":"code","63e5d8a2":"code","b3895662":"code","1b9ad39e":"code","b891a9e3":"code","010a1cff":"markdown","eeff3881":"markdown","7f51f28e":"markdown","cf8bf52e":"markdown","1455dda5":"markdown","929126e7":"markdown","c81b28cb":"markdown","16a301f9":"markdown","bc33c527":"markdown","e227aafd":"markdown","ef6e2b4d":"markdown","fd797e9a":"markdown","c039f2c2":"markdown","7df6b8c8":"markdown","63e51d6c":"markdown","cd37a631":"markdown","33b2b329":"markdown","ef086468":"markdown","fb642f54":"markdown"},"source":{"92bd7026":"%matplotlib inline\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\"]).decode(\"utf8\"))","f0525ae2":"import pandas as pd\n\npath = r'..\/input\/\/d_e_f_e_v_s\/D_E_f_E_V_S\/walking' \ndf = pd.read_csv(path + \"\/1\/1 vic.csv\")\ndf.head()","db7d589e":"df.info()","74d44433":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#to read multiple CSVs automatically\npath = r'..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\/frame_test.csv' \n\nlabels_dfs = pd.read_csv(path)\nplt.figure(figsize = (15,6))\nlegendTitles = []\n\nlabels_dfs.drop(['Source' , 'Destination' , 'Protocol' , 'Info' , 'No.'], axis=1, inplace=True)\n\ndf = labels_dfs\ndf['key'] = np.array(df['Time']).astype(int)\ndf = df.groupby('key',axis=0).sum()\n\ndf['bytes'] = df['Length'].cumsum()  \navg_bps = \"{:.1f}\".format(df['Length'].sum() \/ (len(df['Length'])*1000))\nprint(\"average bitrate:\" ,avg_bps)\ndf['rollLen'] = df['Length'].rolling(20).mean() #in bytes\ndf['rollLen'] = df['rollLen']\/1000 #KBPS\n\nplt.plot(range(len(df['rollLen'])), df['rollLen'])\ntitle = \"Bitrate (KBPS) vs time - average: \" + avg_bps + \" KB\/S\"\nplt.title(title, fontsize=18)\nplt.xlabel('Time (sec)', fontsize=18); plt.ylabel('KB', fontsize=16)\nplt.show()","4ce7f31e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#to read multiple CSVs automatically\npath = r'..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\/motion increase test.csv' \n\n\nlabels_dfs = pd.read_csv(path)\nplt.figure(figsize=(15,6))\n#plt.ylim((0,250))\nlegendTitles = []\n\nlabels_dfs.drop(['Source' , 'Destination' , 'Protocol' , 'Info' , 'No.'], axis=1, inplace=True)\n\ndf = labels_dfs\ndf['key'] = np.array(df['Time']).astype(int)\ndf = df.groupby('key',axis=0).sum()\n\ndf['bytes'] = df['Length'].cumsum()  \navg_bps = \"{:.1f}\".format(df['Length'].sum() \/ (len(df['Length'])*1000))\nprint(\"average bitrate:\" ,avg_bps)\ndf['rollLen'] = df['Length'].rolling(20).mean() #in bytes\ndf['rollLen'] = df['rollLen']\/1000 #KBPS\nplt.plot(range(len(df['rollLen'])), df['rollLen'])\ntitle = \"Bitrate (KBPS) vs time - average: \" + avg_bps + \" KB\/S\"\nplt.title(title, fontsize=18)\nplt.xlabel('Time (sec)', fontsize=18); plt.ylabel('KB', fontsize=16)\n    \nplt.show()","77b99bcb":"num_dfs_tot = 0\nsec_to_cut = 15\n\n#to read multiple CSVs automatically\nimport glob\npath = r'..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\/walking' \nallFolderPaths = glob.glob(path + \"\/*\")\ntime_sliced = pd.DataFrame()\nnum_labels = len(allFolderPaths)\nlabels_dfs = [0]*num_labels\n\n#read all CSVs for label i, and cut 15 sec of start and end of each video.\nfor i in range(num_labels) :\n    labels_dfs[i] = [pd.read_csv(f) for f in glob.glob(allFolderPaths[i] + \"\/*.csv\")]\n    num_dfs_tot += len(labels_dfs[i])\n    \n    for j in range(len(labels_dfs[i])) :\n        labels_dfs[i][j].drop(['Source' , 'Destination' , 'Protocol' , 'Info' , 'No.'], axis=1, inplace=True)\n        labels_dfs[i][j] = labels_dfs[i][j][labels_dfs[i][j].Time > sec_to_cut]\n        labels_dfs[i][j] = labels_dfs[i][j][labels_dfs[i][j].Time < labels_dfs[i][j][\"Time\"].iloc[-1] - sec_to_cut]\n        labels_dfs[i][j]['Time'] -= sec_to_cut\n        labels_dfs[i][j]['Label'] = i\n        labels_dfs[i][j]['location'] = j\n        \nlabels_dfs[2][1][:10]","03023d91":"labels_dfs[2][1].info()","8c6a8766":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\nfrom math import ceil\nimport timeit\n\nstart = timeit.default_timer() #to measure runtime\ntime_slice = 2; #in seconds\ntime_sliced = pd.DataFrame()\n\n#read all CSVs for label i, and cut 15 sec of start and end of each video.\nfor i in range(num_labels) :\n    for j in range(len(labels_dfs[i])) :\n        \n        df = labels_dfs[i][j] \n        df['TimeSlice'] = (np.array(labels_dfs[i][j]['Time'])\/time_slice).astype(int)\n        df = df.groupby('TimeSlice',axis=0 ,sort = 'False').agg(\n        {'Time'     : ['count', 'std', 'mean'],\n         'Length'   : ['mean', 'sum', 'std'],\n         'Label'    : 'first',\n         'location'    : 'first'}).fillna(0) \n        time_sliced = time_sliced.append(df)\n\ntime_sliced.columns = [\"_\".join(x) for x in df.columns.ravel()]\n\ntime_sliced.rename(columns={'Time_count':'pack_count',\n                          'Label_first':'Label',\n                          'location_first':'location'}, inplace=True)\ntime_sliced.head()","641fbc90":"time_sliced['Label'].value_counts(normalize=True)","fb7dc9a1":"time_sliced.info()","390ec380":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom statistics import mean \n\nnum_labels = 5;\n#labels_dfs = [0]*num_labels\nfileNames = [0]*num_labels\n\nLAB = 0\nTSUR = 1\nVIC = 2\n\ncategories_or_singles = \"cat\"\n\n#to read multiple CSVs automatically\nimport glob\npath = r'..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\/walking' \nallFolderPaths = glob.glob(path + \"\/*\")\n\nplt.figure(figsize=(20, 13))\nlegendTitles = []\nax = plt.gca() \n#max_spec_bitrate = [512]*1200\nmax_observed_bitrate = [458]*1200\navgs = [0]*num_labels\n\nfor i in range(num_labels) :\n    #labels_dfs[i] = [pd.read_csv(f) for f in glob.glob(allFolderPaths[i] + \"\/*.csv\")]\n    fileNames[i] = [f for f in glob.glob(allFolderPaths[i] + \"\/*.csv\")]\n    plt.xlim((0,1200))\n    color = next(ax._get_lines.prop_cycler)['color']\n    avgs[i] = []\n\n    for j in range(len(labels_dfs[i])) :\n        #labels_dfs[i][j].drop(['Source' , 'Destination' , 'Protocol' , 'Info' , 'No.'], axis=1, inplace=True)\n        #labels_dfs[i][j] = labels_dfs[i][j][labels_dfs[i][j].Time > 15]\n        #labels_dfs[i][j] = labels_dfs[i][j][labels_dfs[i][j].Time < labels_dfs[i][j][\"Time\"].iloc[-1] - 15]\n        #labels_dfs[i][j]['Time'] -= 15\n        #labels_dfs[i][j]['Label'] = i\n        #labels_dfs[i][j]['location'] = j\n        \n        short_fileName = fileNames[i][j].replace('..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\/walking\/', '')\n        short_fileName = short_fileName.replace('.csv', '')\n        legendTitles.append(short_fileName) #'vid ' + str(i) + '.' + str(j+1))\n        df = labels_dfs[i][j]\n        df['key'] = np.array(df['Time']).astype(int)\n        df = df.groupby('key',axis=0).sum()\n        \n        df['bytes'] = df['Length'].cumsum()  \n        df['BPS'] = df['bytes']\/df['Time']\n        bps = float(\"{:.1f}\".format(df['Length'].sum() \/ (len(df['Length'])*1000)))\n        avgs[i].append(bps)\n        \n        df['rollLen'] = df['Length'].rolling(20).mean()\n        df['rollLen'] = df['rollLen']\/1000\n        \n        if(categories_or_singles == \"cat\"):\n            if j == VIC: #outlier room\n                plt.plot(range(len(df['Length'])), df['rollLen'] , linestyle = '-', color = color, linewidth=4.0)\n            else:    \n                plt.plot(range(len(df['Length'])), df['rollLen'] , color = color)\n        else:\n            if j == VIC:\n                plt.plot(range(len(df['Length'])), df['rollLen'], linestyle = '-', linewidth=4.0)\n            else:  \n                plt.plot(range(len(df['Length'])), df['rollLen'])\n#            plt.ylim((0,350))\n        \n        plt.xlabel('Time (sec)', fontsize=16); plt.ylabel('KB', fontsize=16)\n        \n\n    avgs[i] = int(mean(avgs[i]))\n    avgLine = [avgs[i]]*1200\n    legendTitles.append(\"avg, label = \" + str(i))\n    plt.plot(range(len(avgLine)), avgLine)\n#legendTitles.append(\"max_spec_bitrate\") #'vid ' + str(i) + '.' + str(j+1))    \n#plt.plot(range(len(max_spec_bitrate)), max_spec_bitrate)\n#legendTitles.append(\"max_observed_bitrate\") #'vid ' + str(i) + '.' + str(j+1))    \n#plt.plot(range(len(max_observed_bitrate)), max_observed_bitrate)\nplt.title(\"Videos' bitrates\", fontsize=18)\nplt.legend(legendTitles)\nplt.show()\n","7409553b":"import itertools\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(true_class, prediction,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.YlOrRd):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    cm = confusion_matrix(true_class, prediction)\n    classes = (np.sort(np.unique(true_class)))\n    \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n   # print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    #plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    plt.show()\n    \n    return","dd64838e":"train_data = []\ntest_data = []\n    \ntrain_data.append(time_sliced[time_sliced['location'] == LAB]) \ntrain_data.append(time_sliced[time_sliced['location'] == TSUR])\ntest_data.append(time_sliced[time_sliced['location'] == VIC])\n\ntrain_data  = pd.concat(train_data, axis=0) #first 80% of data for label i\ntest_data   = pd.concat(test_data, axis=0)   #last 20% of data for label i\ntrain_data.drop('location', axis=1, inplace=True)\ntest_data.drop('location', axis=1, inplace=True)\n\n#train_data = train_data.sample(frac=1).reset_index(drop=True) #mix the data!!!\n#test_data  = test_data.sample(frac=1).reset_index(drop=True) #mix the data!!!\n\ntrain_labels = train_data['Label'] #get labels\ntest_labels = test_data['Label'] #get labels\ntrain_data = train_data.drop('Label',axis=1) #remove labels from data\ntest_data = test_data.drop('Label',axis=1) #remove labels from data    \n    \n\n#fit classifier\nclf = RandomForestClassifier(n_estimators = 100, max_depth= 4)\nclf.fit(train_data ,train_labels)\npred = clf.predict(test_data)\n\n\nfeatures = list(train_data.columns.values)\nimportances = clf.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(1,figsize = (10, 6))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\n\nplt.figure(2, figsize = (7, 7))\nplot_confusion_matrix(test_labels, pred)\n\nacc_score = \"{:.2f}\".format(accuracy_score(test_labels , pred))\nmean_absolute_err = \"{:.3f}\".format(mean_absolute_error(test_labels , pred))\nprint('time_slice:', time_slice, 'sec')\nprint ('accuracy_score:',acc_score)\nprint ('mean_absolute_error:', mean_absolute_err)","408738b5":"features","747f67d9":"# Extract single tree\nestimator = clf.estimators_[5]\n\nfrom sklearn.tree import export_graphviz\n# Export as dot file\nexport_graphviz(estimator, out_file='tree.dot',\n                feature_names = features,\n                class_names = list(map(str, range(0,5))),\n                rounded = True, proportion = True,leaves_parallel = True,label = False, filled = True)\n\n# Convert to png using system command (requires Graphviz)\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\n# Display in jupyter notebook\nfrom IPython.display import Image\nImage(filename = 'tree.png')","ac5ad034":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\nfrom math import ceil\nimport timeit\n\nstart = timeit.default_timer() #to measure runtime\n\ntime_slices = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]; #in seconds\nnum_labels = 5;\n'''\nnum_dfs_tot = 0\nlabels_dfs = [0]*num_labels\n'''\nsec_to_cut = 15\nacc_scores = []\nmaes = []\n\n#to read multiple CSVs automatically\nimport glob\npath = r'..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\/sitting' \nallFolderPaths = glob.glob(path + \"\/*\")\n\n'''\n#read all CSVs for label i, and cut 15 sec of start and end of each video.\nfor i in range(num_labels) :\n    labels_dfs[i] = [pd.read_csv(f) for f in glob.glob(allFolderPaths[i] + \"\/*.csv\")]\n    for j in range(len(labels_dfs[i])) :\n        labels_dfs[i][j].drop(['Source' , 'Destination' , 'Protocol' , 'Info' , 'No.'], axis=1, inplace=True)\n        labels_dfs[i][j] = labels_dfs[i][j][labels_dfs[i][j].Time > sec_to_cut]\n        labels_dfs[i][j] = labels_dfs[i][j][labels_dfs[i][j].Time < labels_dfs[i][j][\"Time\"].iloc[-1] - sec_to_cut]\n        labels_dfs[i][j]['Time'] -= sec_to_cut\n        labels_dfs[i][j]['Label'] = i\n        labels_dfs[i][j]['location'] = j\n'''\n        \nfor s in range(len(time_slices)) :\n    time_sliced = pd.DataFrame()\n    for i in range(num_labels) :\n        for j in range(len(labels_dfs[i])) :\n            df = labels_dfs[i][j] \n            df['TimeSlice'] = (np.array(labels_dfs[i][j]['Time'])\/time_slices[s]).astype(int)\n            df = df.groupby('TimeSlice',axis=0 ,sort = 'False').agg(\n            {'Time'     : ['count', 'std', 'mean'],\n             'Length'   : ['mean', 'sum', 'std'],\n             'Label'    : 'first',\n             'location'    : 'first'}).fillna(0)\n            time_sliced = time_sliced.append(df)\n    \n    time_sliced.columns = [\"_\".join(x) for x in df.columns.ravel()]\n    time_sliced.rename(columns={'Time_count':'pack_count',\n                          'Label_first':'Label',\n                          'location_first':'location'}, inplace=True)\n    \n    train_data = []; test_data = []\n        \n    train_data.append(time_sliced[time_sliced['location'] == LAB])  #lab\n    train_data.append(time_sliced[time_sliced['location'] == TSUR])  #tsur\n    test_data.append(time_sliced[time_sliced['location'] == VIC])   #vic\n    \n    train_data  = pd.concat(train_data, axis=0) \n    test_data   = pd.concat(test_data, axis=0)   \n    train_data.drop('location', axis=1, inplace=True)\n    test_data.drop('location', axis=1, inplace=True)\n    \n    train_labels = train_data['Label'] #get labels\n    test_labels = test_data['Label'] #get labels\n    train_data = train_data.drop('Label',axis=1) #remove labels from data\n    test_data = test_data.drop('Label',axis=1) #remove labels from data    \n        \n    \n    clf = RandomForestClassifier(n_estimators = 100)\n    clf.fit(train_data ,train_labels)\n    pred = clf.predict(test_data)\n    \n    acc_score = \"{:.2f}\".format(accuracy_score(test_labels , pred))\n    mean_absolute_err = \"{:.3f}\".format(mean_absolute_error(test_labels , pred))\n    acc_scores.append(int(float(acc_score)*100))\n    maes.append(float(float(mean_absolute_err)*100))\n    #print ('slice size:', time_slices[s], 's,', 'acc_score:',int(float(acc_score)*100), '%, mean_abs_err:', mean_absolute_err, '\\n')\n\nstop = timeit.default_timer() #to measure runtime\nprint('RunTime:', \"{:.1f}\".format(stop - start), 'sec.')\n\n\nplt.figure(3,figsize=(15,6))\nplt.title('Mean abs. error(time slice size)',fontsize=16)\nplt.xlabel('time slice size'); plt.ylabel('Mean abs. error * 100')\nplt.xticks(np.arange(0,20), np.arange(0,20).astype(int))\nplt.ylim([0,100])\nplt.grid()\nplt.scatter(time_slices,maes)\n#plt.plot(time_slices,maes)\n\nplt.figure(4,figsize=(15,6))\nplt.title('accuracy score(time slice size)',fontsize=16)\nplt.xlabel('time slice size'); plt.ylabel('accuracy score (%)')\nplt.xticks(np.arange(0,20), np.arange(0,20).astype(int))\nplt.grid()\nplt.ylim([0,100])\nplt.scatter(time_slices,acc_scores)\n","0573bb89":"num_dfs_tot","63e5d8a2":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom math import ceil\nimport timeit\n\ntime_slice = 10; #in seconds\nnum_labels = 5;\n'''\nnum_dfs_tot = 0\nlabels_dfs = [0]*num_labels\n'''\n\n# Find the Time diff that shows when a frame ends\n\ncombined = pd.DataFrame()\n\nseconds_in_DFs_list = [0]*num_dfs_tot #in a every single video dataframe\ntime_slice_list     = [0]*num_dfs_tot #initiallization\nindexes_to_split_frame_by_list = [0]*num_dfs_tot #initiallization\ntime_sliced_df_list = []\n\n\nstart = timeit.default_timer() #to measure runtime\n\nfor k in range(num_labels) : #slice data frames by time slice seconds\n    for i in list(range(len(labels_dfs[k]))) : #slice data frames by time slice seconds\n        #\"lose\" non essential data\n       #labels_dfs[k][i].drop(['Source' , 'Destination' , 'Protocol' , 'Info' , 'No.'], axis=1, inplace=True)\n       #labels_dfs[k][i]['Time']  = labels_dfs[k][i]['Time'].astype('float') #change Time column data to int type \n       combined = combined.append(labels_dfs[k][i])\n       \n       seconds_in_DFs_list[i] = int(ceil(labels_dfs[k][i].at[len(labels_dfs[k][i])-1,'Time'])) #number of seconds in current df\n       time_slice_list[i] = list(range(0,seconds_in_DFs_list[i],time_slice)) #list of times to slice by\n       indexes_to_split_frame_by_list[i] = list(range(0,seconds_in_DFs_list[i],time_slice)) #initialization\n       \n       for j in list(range(len(time_slice_list[i]))): #calc indexes to slice by\n           #find first index of labels_dfs[k][i]['Time'] the exceeds time_slice_list[i][j]\n           indexes_to_split_frame_by_list[i][j] = np.argmax(labels_dfs[k][i]['Time'] > time_slice_list[i][j]) -1 #TODO: moved below.\n                \n       df_slice = pd.DataFrame() \n       \n       for j in list(range(len(time_slice_list[i]))): #TODO: change for efficiency.\n           #print(len(time_slice_list[i]))\n           #indexes_to_split_frame_by_list[i][j] = np.argmax(labels_dfs[k][i]['Time'] > time_slice_list[i][j]) -1 TODO: doesnt work because we need j+1.\n           if (j != len(time_slice_list[i])-1 and j != 0):  #not first or last index\n               ind_start = indexes_to_split_frame_by_list[i][j] + 1\n               ind_end = indexes_to_split_frame_by_list[i][j+1] + 1\n           elif j == len(time_slice_list[i])-1:             #last index\n               ind_start = indexes_to_split_frame_by_list[i][j] + 1\n               ind_end = len(labels_dfs[k][i])\n           else:                                            # j==0, first index\n               ind_start = 0\n               ind_end = indexes_to_split_frame_by_list[i][j+1]+1\n           \n           df_slice = labels_dfs[k][i][ind_start:ind_end]\n           df_slice.loc[:,'Time'] = df_slice['Time'].diff().fillna(0) #calc time diffs, not time since begining of recording packets.\n           time_sliced_df_list.append(df_slice)\n         \n\ncombined.to_csv('combined.csv',index=False)\n\n\ntimeDiffCol = labels_dfs[1][1]['Time']\nimport matplotlib.pyplot as plt\nplt.figure(1,figsize=(15,6))\nplt.hist(timeDiffCol, bins = 30)\n#plt.xlim(0,0.1)\nplt.xlabel('TimeDiff', fontsize=16); plt.ylabel('Count', fontsize=16)\nplt.title(\"Histogram of time diffs between two packets\", fontsize = 20)\n\n#%% Distinguish between the frames\n\nlabels_dfs[1][1]['frameNum'] = 0\nj=0\ntimeDiffCol.reset_index(drop = True , inplace = True)\nlabels_dfs[1][1].reset_index(drop = True ,inplace = True)\n\nimport time\nt0 = time.time()\nfor idx,row in labels_dfs[1][1].iterrows():\n    if(timeDiffCol[idx] < 0.025) : \n        labels_dfs[1][1].at[idx,'frameNum'] = j\n    else:\n        j += 1\n        labels_dfs[1][1].at[idx,'frameNum'] = j\nprint ('time:  ', time.time()-t0)\n\n\nunited = labels_dfs[1][1].groupby('frameNum',axis=0).sum()\nunited['Time'] = np.cumsum(united['Time'])\n\nplt.figure(2, figsize=(15,6))\nplt.title(\"Frame size(time)\", fontsize = 20)\nplt.xlabel('Time (sec)', fontsize=16); plt.ylabel('Frame size', fontsize=16)\nplt.xlim(0,20)\nplt.plot(united['Time'],united['Length'])\n","b3895662":"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom math import ceil\nimport timeit\nfrom skimage import filters\nimport matplotlib.pyplot as plt\n\nthresholds = [0]*num_labels\ncombined_DF= pd.DataFrame()\n\n#%%\ntimeDiffCol = pd.Series()\nn=0\n\nfor i in range(num_labels) :\n    thresholds[i] = [0]*len(labels_dfs[i])\n    \n    for j in range(len(labels_dfs[i])) :\n        thresholds[i][j] = filters.threshold_otsu(labels_dfs[i][j]['Time'],nbins=30)\n        df_size = len(labels_dfs[i][j])\n        \n        for idx,row in labels_dfs[i][j].iterrows():\n\n            if(labels_dfs[i][j].at[idx,'Time'] < thresholds[i][j]) : \n                labels_dfs[i][j].at[idx,'frameNum'] = n\n            else:\n                n += 1\n                labels_dfs[i][j].at[idx,'frameNum'] = n\n                labels_dfs[i][j].at[idx,'Time diff pre'] = labels_dfs[i][j].at[idx,'Time']\n        \n        combined_DF = pd.concat([combined_DF , labels_dfs[i][j]])\n\nunited = combined_DF.groupby('frameNum' ,sort = 'False').agg({'Time': ['std' ,'mean'],\n                                                                  'Length' : ['std' , 'mean' , 'sum'],\n                                                                  'Label' : 'first',\n                                                                  'Time diff pre':'first'}).fillna(0)\nunited.columns = [\"\".join(x) for x in united.columns.ravel()]\n\nunited.head(15)","1b9ad39e":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom statistics import mean \n\nnum_labels = len(allFolderPaths);\nlabels_dfs = [0]*num_labels\nfileNames = [0]*num_labels\n\ncategories_or_singles = \"cat\"\n\n#to read multiple CSVs automatically\nimport glob\npath = r'..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\/sitting' \nallFolderPaths = glob.glob(path + \"\/*\")\n\nplt.figure(figsize=(20, 13))\nlegendTitles = []\nax = plt.gca() \n#max_spec_bitrate = [512]*1200\nmax_observed_bitrate = [458]*600\navgs = [0]*num_labels\n\nfor i in range(num_labels) :\n    labels_dfs[i] = [pd.read_csv(f) for f in glob.glob(allFolderPaths[i] + \"\/*.csv\")]\n    fileNames[i] = [f for f in glob.glob(allFolderPaths[i] + \"\/*.csv\")]\n    plt.xlim((0,600))\n    color = next(ax._get_lines.prop_cycler)['color']\n    avgs[i] = []\n\n#    legendTitles = []\n\n    for j in range(len(labels_dfs[i])) :\n        labels_dfs[i][j].drop(['Source' , 'Destination' , 'Protocol' , 'Info' , 'No.'], axis=1, inplace=True)\n        labels_dfs[i][j] = labels_dfs[i][j][labels_dfs[i][j].Time > 15]\n        labels_dfs[i][j] = labels_dfs[i][j][labels_dfs[i][j].Time < labels_dfs[i][j][\"Time\"].iloc[-1] - 15]\n        labels_dfs[i][j]['Time'] -= 15\n        labels_dfs[i][j]['Label'] = i\n        labels_dfs[i][j]['location'] = j\n        #print(str(i))\n        short_fileName = fileNames[i][j].replace('..\/input\/d_e_f_e_v_s\/D_E_f_E_V_S\/sitting\/', '')\n        \n        short_fileName = short_fileName.replace('.csv', '')\n        legendTitles.append(short_fileName) #'vid ' + str(i) + '.' + str(j+1))\n        df = labels_dfs[i][j]\n        df['key'] = np.array(df['Time']).astype(int)\n        df = df.groupby('key',axis=0).sum()\n        \n        #VR_funcs.PlotXYZ(df['Time'], df['Length'], [1]*len(df['Time']))\n        df['bytes'] = df['Length'].cumsum()  \n        #df['timeSUM'] = df['Time'].cumsum()  \n        df['BPS'] = df['bytes']\/df['Time']\n        bps = float(\"{:.1f}\".format(df['Length'].sum() \/ (len(df['Length'])*1000)))\n#        df['Length'].sum() \/ df['Time'].sum()\n#        location = df['location'][0]\n        avgs[i].append(bps)\n        \n        df['rollLen'] = df['Length'].rolling(20).mean()\n        df['rollLen'] = df['rollLen']\/1000\n        \n        if(categories_or_singles == \"cat\"):\n            if j == 2:\n                plt.plot(range(len(df['Length'])), df['rollLen'] , linestyle = '-', color = color, linewidth=4.0)\n            else:    \n                plt.plot(range(len(df['Length'])), df['rollLen'] , color = color)\n        else:\n            if j == 2:\n                plt.plot(range(len(df['Length'])), df['rollLen'], linestyle = '-', linewidth=4.0)\n            else:  \n                plt.plot(range(len(df['Length'])), df['rollLen'])\n#            plt.ylim((0,350))\n        \n        #legend = plt.legend(handles=[one, two, three], title=\"title\", loc=4, fontsize='small', fancybox=True)\n        plt.xlabel('Time (sec)', fontsize=16); plt.ylabel('KB', fontsize=16)\n#        break\n        \n\n    avgs[i] = int(mean(avgs[i]))\n    avgLine = [avgs[i]]*600\n    legendTitles.append(\"avg, label = \" + str(i))\n    plt.plot(range(len(avgLine)), avgLine)\n#legendTitles.append(\"max_spec_bitrate\") #'vid ' + str(i) + '.' + str(j+1))    \n#plt.plot(range(len(max_spec_bitrate)), max_spec_bitrate)\n#legendTitles.append(\"max_observed_bitrate\") #'vid ' + str(i) + '.' + str(j+1))    \n#plt.plot(range(len(max_observed_bitrate)), max_observed_bitrate)\nplt.title(\"Videos' bitrates\", fontsize=18)\nplt.legend(legendTitles)\nplt.show()\n\n\n","b891a9e3":"start = timeit.default_timer() #to measure runtime\n\ntime_slices = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]; #in seconds\nacc_scores = []\nmaes = []\n        \nfor s in range(len(time_slices)) :\n    time_sliced = pd.DataFrame()\n    for i in range(num_labels) :\n        for j in range(len(labels_dfs[i])) :\n            df = labels_dfs[i][j] \n            df['TimeSlice'] = (np.array(labels_dfs[i][j]['Time'])\/time_slices[s]).astype(int)\n            df = df.groupby('TimeSlice',axis=0 ,sort = 'False').agg(\n            {'Time'     : ['count', 'std', 'mean'],\n             'Length'   : ['mean', 'sum', 'std'],\n             'Label'    : 'first',\n             'location'    : 'first'}).fillna(0) \n            time_sliced = time_sliced.append(df)\n    \n    time_sliced.columns = [\"_\".join(x) for x in df.columns.ravel()]\n    \n    \n    train_data = []; test_data = []\n        \n    train_data.append(time_sliced[time_sliced['location_first'] == LAB])  #lab\n    train_data.append(time_sliced[time_sliced['location_first'] == TSUR])  #tsur\n    test_data.append(time_sliced[time_sliced['location_first'] == VIC])   #vic\n    \n    train_data  = pd.concat(train_data, axis=0) \n    test_data   = pd.concat(test_data, axis=0)   \n    train_data.drop('location_first', axis=1, inplace=True)\n    test_data.drop('location_first', axis=1, inplace=True)\n    \n    train_labels = train_data['Label_first'] #get labels\n    test_labels = test_data['Label_first'] #get labels\n    train_data = train_data.drop('Label_first',axis=1) #remove labels from data\n    test_data = test_data.drop('Label_first',axis=1) #remove labels from data    \n        \n    \n    clf = RandomForestClassifier(n_estimators = 100)\n    clf.fit(train_data ,train_labels)\n    pred = clf.predict(test_data)\n    \n    acc_score = \"{:.2f}\".format(accuracy_score(test_labels , pred))\n    mean_absolute_err = \"{:.3f}\".format(mean_absolute_error(test_labels , pred))\n    acc_scores.append(int(float(acc_score)*100))\n    maes.append(float(float(mean_absolute_err)*100))\n    print('slice size:', time_slices[s], 'sec.')\n    #print ('acc_score:',int(float(acc_score)*100), '%, mean_abs_err:', mean_absolute_err, '\\n')\n    \n\nstop = timeit.default_timer() #to measure runtime\nprint('RunTime:', \"{:.1f}\".format(stop - start), 'sec.')\n\n\nplt.figure(3,figsize=(15,6))\nplt.title('Mean abs. error(time slice size)',fontsize=16)\nplt.xlabel('time slice size'); plt.ylabel('Mean abs. error * 100')\nplt.xticks(np.arange(0,20), np.arange(0,20).astype(int))\nplt.ylim([0,200])\nplt.grid()\nplt.scatter(time_slices,maes)\n#plt.plot(time_slices,maes)\n\nplt.figure(4,figsize=(15,6))\nplt.title('accuracy score(time slice size)',fontsize=16)\nplt.xlabel('time slice size'); plt.ylabel('accuracy score (%)')\nplt.xticks(np.arange(0,20), np.arange(0,20).astype(int))\nplt.grid()\nplt.ylim([0,100])\nplt.scatter(time_slices,acc_scores)\n#plt.plot(time_slices,acc_scores)\n","010a1cff":"#  **show one of the estimators created (maxDepth set as 4)**","eeff3881":"# Different approach - splitting to H.264 frames: analisys  graphs - 1. how to decide which packet belongs to which frame. 2. frame size reconstruction.","7f51f28e":"# graphs for \"crazy square\" test","cf8bf52e":"# splitting to H.264 frames","1455dda5":"# show count for each label in the dataset","929126e7":"# data exploration - look at saved csv file for video","c81b28cb":"# This notebook describes (some of) our work on the \"Data Extraction from Encrypted Video Streams\" Engineering project.","16a301f9":"# fitting and predicting using random forest clasifier (training on lab and tsur's room, testing on vic's room - smaller one)","bc33c527":"# we can see the I frames and the P frames from the above graph. \nthe other graph is the graph by which we determined to which frame does a packet belong","e227aafd":"# predicting sitting for different time-slices","ef6e2b4d":"# bitrate graph for sitting experiment","fd797e9a":"# confusion matrix plot (will be used later)","c039f2c2":"# graphs for motion increase test","7df6b8c8":"# bitrate graph by category (or without categories)","63e51d6c":"# time sliced dataframe with features extracted (for time-slice time_slice)","cd37a631":"# trying different time-slices","33b2b329":"# graphs for experiments","ef086468":"# obtaining labels_dfs list - list of all dfs, per each label \nfirst index indicates label. second one: the location. for instance, labels_dfs[2][1] = label 2, location 1","fb642f54":"list(map(str, range(4 + 1)))"}}