{"cell_type":{"b05f0af7":"code","fb4bde06":"code","8b220da9":"code","c284a5ea":"code","9a9d8995":"code","873a0c61":"code","19cfd7a4":"code","69cb614c":"code","f4b5d6ab":"code","16aec63f":"code","09dfe69b":"code","19373711":"code","2717cdb2":"code","7b5896fb":"code","47bbee0f":"code","fc7c8a63":"code","49f4a090":"code","06f9b549":"code","8bff3ac1":"code","bb848f91":"code","bdedc8df":"code","a16c535c":"code","6828d906":"code","c524765e":"code","fe11e2d4":"code","7a17eaa9":"code","8ddb9255":"code","47d64ea8":"code","033c03ee":"code","692db7f1":"code","3f84a1be":"code","2df3e306":"code","56afdf91":"code","6dc5eba1":"code","0643677e":"code","1dcdbb00":"code","308fe34f":"code","98b49275":"code","e0470c9e":"code","bed34e5c":"code","9d0bed07":"code","e7d31f14":"code","e638e58f":"code","344723d8":"code","0c4943a8":"code","e3013246":"code","6d00bf6a":"code","55a18397":"code","b4f623ee":"code","1c2d2a63":"code","a73d3942":"code","6950cc8c":"code","d5574bac":"code","5a8e1f36":"code","660fdee8":"code","14940044":"code","62186f41":"code","33e7f46d":"code","0865d5e0":"code","134b187a":"code","65b64ffd":"code","ee59b365":"code","d7a12e16":"code","e81eb20a":"code","f2a2012a":"code","b807dbd8":"code","bbb69522":"code","d803f509":"code","e69683fd":"code","b9176b77":"code","f8fe6e00":"markdown","965a5fd8":"markdown","f81301d9":"markdown","e4c44b8f":"markdown","40991789":"markdown","694a9759":"markdown","89c571a3":"markdown","2c991d08":"markdown","3a0275ae":"markdown","468946e6":"markdown","8493c17e":"markdown","0fc19ec1":"markdown","54b7f660":"markdown","10c48ff4":"markdown","2fd9e545":"markdown","6f15eb1c":"markdown","46b4ca10":"markdown","a785ba02":"markdown","d41de523":"markdown","de68032f":"markdown","af9a77fd":"markdown","f085908b":"markdown","21bcd118":"markdown","fdeb8476":"markdown"},"source":{"b05f0af7":"# importing pandas for reading the datasets\nimport pandas as pd","fb4bde06":"# reading the training dataset with a ';' delimiter\nbdata=pd.read_csv('..\/input\/mlworkshop\/bank-full.csv',delimiter=';')","8b220da9":"# displaying first 10 observations from the dataset\nbdata.head(10)","c284a5ea":"# describing the pandas dataframe bdata\nbdata.describe()","9a9d8995":"# getting details of no of attributes and observations\nprint('No of observations :',bdata.shape[0])\nprint('No of attributes :',bdata.shape[1])\nprint('No of numerical attributes :',bdata.describe().shape[1])\nprint('No of categorical attributes :',bdata.shape[1]-bdata.describe().shape[1])","873a0c61":"# getting list of attributes\nbdata.columns.tolist()","19cfd7a4":"# importing matplotlib for plotting the graphs\nimport matplotlib.pyplot as plt","69cb614c":"bdata['y'].value_counts().plot(kind='bar')\nplt.title('Subscriptions')\nplt.xlabel('Term Deposit')\nplt.ylabel('No of Subscriptions')\nplt.show()","f4b5d6ab":"pd.crosstab(bdata.job,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Job')\nplt.xlabel('Job')\nplt.ylabel('No of Subscriptions')\nplt.show()","16aec63f":"pd.crosstab(bdata.marital,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Marital Status')\nplt.xlabel('Marital Status')\nplt.ylabel('No of Subscriptions')\nplt.show()","09dfe69b":"pd.crosstab(bdata.education,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Education')\nplt.xlabel('Education')\nplt.ylabel('No of Subscriptions')\nplt.show()","19373711":"pd.crosstab(bdata.housing,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Housing Credit')\nplt.xlabel('Housing Credit')\nplt.ylabel('No of Subscriptions')\nplt.show()","2717cdb2":"pd.crosstab(bdata.loan,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Personal Loan')\nplt.xlabel('Personal Loan')\nplt.ylabel('No of Subscriptions')\nplt.show()","7b5896fb":"pd.crosstab(bdata.poutcome,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Outcome of Previous Campaign')\nplt.xlabel('Outcome of Previous Campaign')\nplt.ylabel('No of Subscriptions')\nplt.show()","47bbee0f":"pd.crosstab(bdata.month,bdata.y).plot(kind='bar')\nplt.title('Monthly Subscriptions')\nplt.xlabel('Month')\nplt.ylabel('No of Subscriptions')\nplt.show()","fc7c8a63":"# creating dummy variables for categorical variables\n\n# creating a list of categorical variables to be transformed into dummy variables\ncategory=['job','marital','education','default','housing','loan','contact',\n          'month','poutcome']\n\n# creating a backup\nbdata_new = bdata\n\n# creating dummy variables and joining it to the training set\nfor c in category:\n    new_column = pd.get_dummies(bdata_new[c], prefix=c)\n    bdata_dummy=bdata_new.join(new_column)\n    bdata_new=bdata_dummy","49f4a090":"bdata_new.head(10)","06f9b549":"# see the dummy setup of one categorical variable\nbdata_new[[col for col in bdata_new if col.startswith('education')]].head(10)","8bff3ac1":"# drop the initial categorical variable\nbdata_final=bdata_new.drop(category,axis=1)","bb848f91":"bdata_final.head(10)","bdedc8df":"# coding no as '0' and yes as '1'\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nlabels = le.fit_transform(bdata_final['y'])\nbdata_final['y'] = labels","a16c535c":"bdata_final.y.value_counts()","6828d906":"bdata_final.head(10)","c524765e":"# feature selection to reduce dimensionality\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\n\n# creating dataframe of features\nX=bdata_final.drop(['y'],axis=1)\n# creating dataframe of output variable\ny=bdata_final['y']\n\n# standard scaling\nX_norm = MinMaxScaler().fit_transform(X)\n\nrfe_selector = RFE(estimator=LogisticRegression(solver='liblinear',max_iter=100,multi_class='ovr',n_jobs=1), n_features_to_select=30, step=10, verbose=5)\nrfe_selector.fit(X_norm, y)\nrfe_support = rfe_selector.get_support()\nrfe_feature = X.loc[:,rfe_support].columns.tolist()\nprint(str(len(rfe_feature)), 'selected features')","fe11e2d4":"rfe_feature","7a17eaa9":"# dropping age and pdays\nbdata_final=bdata_final.drop(['age','pdays'],axis=1)","8ddb9255":"bdata_final.head(10)","47d64ea8":"cat=[col for col in bdata_final if col.startswith('job')]\nmar_cat=[col for col in bdata_final if col.startswith('marital')]\nedu_cat=[col for col in bdata_final if col.startswith('education')]\nloan_cat=[col for col in bdata_final if col.startswith('loan')]\ncat.extend(mar_cat)\ncat.extend(edu_cat)\ncat.extend(loan_cat)","033c03ee":"cat","692db7f1":"# creating a dataframe with lesser dimension\nbdata_dr=bdata_final.drop(cat,axis=1)","3f84a1be":"bdata_dr.head(10)","2df3e306":"# importing sklearn for train test split\nfrom sklearn.model_selection import train_test_split","56afdf91":"# creating training set of features\nX=bdata_final.drop(['y'],axis=1)\n# creating training set of output variable\ny=pd.DataFrame(bdata_final['y'])","6dc5eba1":"# splitting the dataset into train and test for both input and output variable\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)","0643677e":"X_train.head(10)","1dcdbb00":"y_train.head(10)","308fe34f":"X_test.head(10)","98b49275":"y_test.head(10)","e0470c9e":"# importing the Standard Scaler from sklearn\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\ny_train = y_train.values.ravel()\ny_test = y_test.values.ravel()","bed34e5c":"X_train","9d0bed07":"X_test","e7d31f14":"y_train","e638e58f":"y_test","344723d8":"# importing imblearn for Synthetic Minority Over Sampling Technique\n# NOTE : SMOTE technique needs the dataset to be numpy array\n\n# from imblearn.over_sampling import SMOTE\n# sm = SMOTE(sampling_strategy='auto', k_neighbors=1, random_state=0)\n# X_res, y_res = sm.fit_resample(X_train, y_train)\n# import numpy as np\n# np.savetxt('xres.txt', X_res, fmt='%f')\n# np.savetxt('yres.txt', y_res, fmt='%d')\n\n# SMOTE applied dataset\nimport numpy as np\nX_res = np.loadtxt('..\/input\/smotedata\/xres.txt', dtype=float)\ny_res = np.loadtxt('..\/input\/smotedata\/yres.txt', dtype=int)","0c4943a8":"print('No 0f 0 case :',y_res[y_res==0].shape[0])\nprint('No of 1 case :',y_res[y_res==1].shape[0])","e3013246":"from sklearn.ensemble import RandomForestClassifier\n# Create the model with 100 trees\nmodelrf = RandomForestClassifier(n_estimators=100, \n                               bootstrap = True,\n                               max_features = 'sqrt')","6d00bf6a":"# Fit on training data\nmodelrf.fit(X_res, y_res)","55a18397":"# predicting the testing set results\ny_pred = modelrf.predict(X_test)\ny_pred = (y_pred > 0.50)","b4f623ee":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","1c2d2a63":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","a73d3942":"from sklearn.svm import LinearSVC\nmodelsv = LinearSVC(max_iter=100,random_state=0)","6950cc8c":"modelsv.fit(X_res, y_res)","d5574bac":"# predicting the testing set results\ny_pred = modelsv.predict(X_test)\ny_pred = (y_pred > 0.50)","5a8e1f36":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","660fdee8":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","14940044":"from sklearn.neighbors import KNeighborsClassifier\nmodelkn = KNeighborsClassifier(n_neighbors=3)","62186f41":"modelkn.fit(X_res, y_res)","33e7f46d":"# predicting the testing set results\ny_pred = modelkn.predict(X_test)\ny_pred = (y_pred > 0.50)","0865d5e0":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","134b187a":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","65b64ffd":"from sklearn.linear_model import LogisticRegression\nmodellr = LogisticRegression()","ee59b365":"modellr.fit(X_res, y_res)","d7a12e16":"# predicting the testing set results\ny_pred = modellr.predict(X_test)\ny_pred = (y_pred > 0.50)","e81eb20a":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","f2a2012a":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","b807dbd8":"from sklearn.naive_bayes import GaussianNB\nmodelnb = GaussianNB()","bbb69522":"modelnb.fit(X_res, y_res)","d803f509":"# predicting the testing set results\ny_pred = modelnb.predict(X_test)\ny_pred = (y_pred > 0.50)","e69683fd":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","b9176b77":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","f8fe6e00":"__Outcome of Previous Campaign vs Subscription__","965a5fd8":"__Housing Credit vs Subscription__","f81301d9":"<h4>READING DATASET<\/h4>","e4c44b8f":"<h4>DATA PREPROCESSING<\/h4>","40991789":"**Logistic Regression**","694a9759":"__Job vs Subscription__","89c571a3":"__Month vs Subscription__","2c991d08":"__Marital Status vs Subscription__","3a0275ae":"Since the data preprocessing steps are same for both testing and training dataset, we first perform the data preprocessing and then divide the data into training data and testing data.","468946e6":"We observe that the data is highly imbalanced, however we need a balanced data only for training.","8493c17e":"<h4>STANDARDIZING TRAINING AND TESTING SET<\/h4>","0fc19ec1":"__Random Forest Classifier__","54b7f660":"**BALANCING THE DATASET**","10c48ff4":"__Personal loan vs Subscription__","2fd9e545":"**Naive Bayes Classifier**","6f15eb1c":"__Education vs Subscription__","46b4ca10":"**K-Nearest Neighbour Classifier**","a785ba02":"<h4>VISUALIZATION<\/h4>","d41de523":"<h4>FITTING MODEL<\/h4>","de68032f":"<p>features to be eliminated : age, pdays (30 selected features)<\/p>\n<p>features that may be eliminated : job, marital, education, loan (20 selected features)<\/p>","af9a77fd":"**Support Vector Classifier**","f085908b":"__Outcome variable__","21bcd118":"<h4>TRAIN TEST SPLIT<\/h4>","fdeb8476":"<h4>UNDERSTANDING FEATURES OF DATASET<\/h4>\n\n__default__: has credit in default?\n\n__housing__: has housing loan? \n\n__loan__: has personal loan?\n\n__day__: last contact day of the week\n\n__month__: last contact month of year \n\n__duration__: last contact duration, in seconds \n\n__campaign__: number of contacts performed during this campaign and for this client \n\n__pdays__: number of days that passed by after the client was last contacted from a previous campaign\n\n__previous__: number of contacts performed before this campaign and for this client\n\n__poutcome__: outcome of the previous marketing campaign"}}