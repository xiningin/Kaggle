{"cell_type":{"d04f1073":"code","b18a7706":"code","5cc65cd4":"code","6621aa8c":"code","faeb09ff":"code","cf828235":"code","779de688":"code","98970df7":"code","b9f01a69":"code","538eb80a":"code","ac0ee550":"code","7ed5394d":"code","10a09b34":"code","2e5f8eb8":"code","31fd2eab":"code","a05de53e":"markdown","159a44db":"markdown","1d93273d":"markdown","3d6c3bac":"markdown","f52cc1f7":"markdown","eed7f78b":"markdown","1583a8c5":"markdown"},"source":{"d04f1073":"# Standard imports\nimport os\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import trange\nfrom colorama import Fore\nfrom glob import glob\nimport json\nfrom pprint import pprint\nimport time\nimport cv2\nfrom enum import Enum\nfrom IPython.display import display\nimport random\nimport inspect\n\n# For Data preparation\nfrom sklearn.preprocessing import *\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\n\n# Tensorflow modules\nimport tensorflow as tf\nfrom tensorflow.keras import layers as tf_l\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \nfrom tensorflow.keras.metrics import RootMeanSquaredError\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model, save_model, Model\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Input\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# To ignore tensorflow warnings\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nprint(f\"GPU is available : {tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)}\")","b18a7706":"class Config(Enum):\n    DATA_CSV = \"..\/input\/petfinder-cv-dataset\/data.csv\"\n    TEST_CSV = \"..\/input\/petfinder-cv-dataset\/test.csv\"\n    IMG_SHAPE = 224\n    BATCH_SIZE = 64\n    EPOCHS = 10\n\n    META_FEATURES = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n    LABEL = \"Pawpularity\"","5cc65cd4":"def setSeed(seed):\n    \"\"\"\n    Setting the seed of all the random function to maintain reproducibility\n    \n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(seed)\n    tf.random.set_seed(seed)\n    print('SEEDITIZATION DONE !')\n\nsetSeed(0)","6621aa8c":"data_df = pd.read_csv(Config.DATA_CSV.value)\ntest_df = pd.read_csv(Config.TEST_CSV.value)","faeb09ff":"data_df.head()","cf828235":"test_df.head()","779de688":"class CustomModel:\n    def __init__(self, filters : list, kernel_sizes : list, img_dim = 512, use_dropout = False):\n        INPUT = tf_l.Input(shape = [img_dim, img_dim, 3])\n        \n        x = tf_l.Conv2D(\n                filters = filters[0],\n                kernel_size = kernel_sizes[0],\n                padding = 'same',\n                activation = \"relu\",\n            )(INPUT)\n\n        x = tf_l.BatchNormalization()(x)\n        x = tf_l.MaxPooling2D(pool_size = (2, 2))(x)\n\n        if use_dropout:\n            x = tf_l.Dropout(rate = 0.2)(x)\n        \n        for i in range(1, len(filters)):\n            x = tf_l.Conv2D(\n                filters = filters[i],\n                kernel_size = kernel_sizes[i],\n                padding = 'same',\n                activation = \"relu\",\n            )(x)\n\n            x = tf_l.BatchNormalization()(x)\n            x = tf_l.MaxPooling2D(pool_size = (2, 2))(x)\n\n            if use_dropout:\n                x = tf_l.Dropout(rate = 0.2)(x)\n                \n        x = tf_l.GlobalMaxPooling2D()(x)\n        \n        x = tf_l.Dense(128, kernel_initializer = \"he_uniform\", activation = \"relu\")(x)\n        x = tf_l.Dense(32, kernel_initializer = \"he_uniform\", activation = \"relu\")(x)\n        OUTPUT = tf_l.Dense(1, kernel_initializer = \"he_uniform\", activation = \"relu\")(x)\n        \n        self.model = tf.keras.Model(inputs = INPUT, outputs = OUTPUT)\n    \n    def __call__(self):\n        return self.model\n    ","98970df7":"custom_model = CustomModel(\n    filters = [32, 64, 128],\n    kernel_sizes = [3, 3, 3],\n    img_dim = Config.IMG_SHAPE.value,\n    use_dropout= True\n)()\n\n# plot_model(custom_model, show_shapes=True, show_layer_names=True)","b9f01a69":"custom_model.summary()","538eb80a":"class ImgDataLoader:\n    \"\"\"\n    Gives img data in the form of batches\n\n    \"\"\"\n\n    def __init__(self,\n                 df: \"Data_File\",\n                 path_col: list,\n                 target_col: str,\n                 regression_type=True,\n                 rescale=False,\n                 batch_size=32,\n                 img_shape=224,\n                 resize_with_pad = False,\n                 do_augment = False,\n                 repeat = False,\n                 shuffle = False\n                 ):\n        \n        self.df = df\n        self.path_col = path_col\n        self.target_col = target_col\n        self.regression_type = regression_type\n        self.rescale = rescale\n        self.batch_size = batch_size\n        self.img_shape = img_shape        \n        self.resize_with_pad = resize_with_pad\n        self.do_augment = do_augment\n        self.repeat = repeat\n        self.shuffle = shuffle\n        \n    @tf.function\n    def doAugment(self, img : \"Tensor\"):\n        \"\"\"\n        Perform augmentation over the image tensor\n        \"\"\"\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.95, 1.05)\n        img = tf.image.random_brightness(img, 0.05)\n        img = tf.image.random_contrast(img, 0.95, 1.05)\n        img = tf.image.random_hue(img, 0.05)        \n        \n        return img\n    \n    @tf.function\n    def process_img(self, path : str, label = None):\n        \"\"\"\n        A function to apply augmentation and process the images\n        \n        \"\"\"\n        img = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(img, channels = 3)\n        img = tf.cast(img, dtype = tf.float32)\n        \n        if self.rescale:\n            img = img\/255.0\n        \n        if self.resize_with_pad:\n            img = tf.image.resize_with_pad(img, self.img_shape, self.img_shape)\n        else:\n            img = tf.image.resize(img, (self.img_shape, self.img_shape))\n        \n        if self.do_augment:\n            img = self.doAugment(img)\n        \n        if label is not None:\n            return img, label\n        \n        return img\n    \n    def __call__(self):\n        if self.target_col is not None:\n            data_gen = tf.data.Dataset.from_tensor_slices((self.df[self.path_col].values, self.df[self.target_col].values))\n        else:\n            data_gen = tf.data.Dataset.from_tensor_slices((self.df[self.path_col].values))\n        \n        AUTOTUNE = tf.data.experimental.AUTOTUNE\n        \n        data_gen = data_gen.map(self.process_img, num_parallel_calls = AUTOTUNE)\n        if self.repeat:\n            data_gen = data_gen.repeat()\n        \n        if self.shuffle:\n            data_gen = data_gen.shuffle(1024, reshuffle_each_iteration = True)\n        \n        return data_gen.batch(self.batch_size).prefetch(AUTOTUNE)\n ","ac0ee550":"# Just testing\n\ndata_gen = ImgDataLoader(\n    data_df, \n    \"path\", \n    \"Pawpularity\", \n    rescale = True, \n    img_shape = Config.IMG_SHAPE.value,\n    do_augment = True,\n    repeat = False,\n    shuffle = False\n)()\n\n# catch a few image of data_gen.\nfor x, y in data_gen:\n    plt.figure(figsize=(12, 9))\n    for k, (img, lbl) in enumerate(zip(x, y)):\n        if(k + 1 > 4*4):\n            break\n        plt.subplot(4, 4, k+1)\n        plt.imshow(img)\n        plt.title(f\"GT : {lbl}, {img.shape}\")\n        plt.axis('off')\n    break\n    ","7ed5394d":"def trainEngine(tf_model : \"tf compiled model\", tf_model_name : \"give a name to model\", data_df : \"cv dataframe\"):\n    \"\"\"\n    It will take the model and will perfrom the full k-folds training\n        > model : can be a class with __call__ method or a function\n    \n    \"\"\"\n    \n    def givePlotsInOne(training_summary : dict, useDark = False, title = \"Plot\"):\n        \"\"\"\n        Helper function to plot the training result\n        \"\"\"\n\n        fig = go.Figure()\n        for k in summary.keys():\n            if(k != \"epochs\"):\n                fig.add_trace(go.Scatter(x=summary[\"epochs\"], y=summary[k],\n                            mode='lines+markers',\n                            name=k))\n\n                fig.update_layout(\n                    title_text = title,\n                    title_x = .5,\n                    xaxis_title = \"Epochs\",\n                    yaxis_title = \"Values\",\n                    template = \"plotly_dark\" if useDark else \"ggplot2\"\n                )\n\n        fig.show()  \n    \n    def train_model(tf_model : \"TF model\", fold : int):\n        model = tf_model()\n        \n        K.clear_session()\n        LEARNING_RATE = 1e-2\n        DECAY_STEPS = 100\n        DECAY_RATE = 0.99\n\n        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n            initial_learning_rate=LEARNING_RATE,\n            decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n            staircase=True\n        )\n\n        # Creating Callbacks\n        early_stop = EarlyStopping(\n            monitor='val_loss', patience = 3, restore_best_weights=True\n        )\n        \n        if not os.path.exists(f\".\/{tf_model_name}\"):\n            os.mkdir(f\".\/{tf_model_name}\")\n            \n        model_chkpt = ModelCheckpoint(\n            monitor = 'val_loss', \n            patient = 3, \n            mode = 'min', \n            save_best_only = True, \n            filepath = f\".\/{tf_model_name}\/{fold}.h5\"\n        )\n\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n            loss=tf.keras.losses.MeanSquaredError(),\n            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n        )\n    \n        \n        training_history = model.fit_generator(\n            train_data_gen,\n            validation_data = val_data_gen,\n            epochs = Config.EPOCHS.value,\n            verbose = 1,\n            use_multiprocessing=True,\n            workers=-1,\n            callbacks = [early_stop, model_chkpt]\n        )\n        return training_history\n        \n    \n    folds = max(data_df['kfold']) + 1\n    for fold in range(folds):\n        print(Fore.BLUE)\n        print(\"_ \"*20, \"\\n\")\n        print(f\"{' '*11}Current Fold : {fold + 1}\")\n        print(\"_ \"*20, \"\\n\")\n        \n        train_data = data_df.loc[data_df.kfold != fold]\n        val_data = data_df.loc[data_df.kfold == fold]\n        \n        train_data_gen = ImgDataLoader(\n                                    train_data, \n                                    \"path\", \n                                    \"Pawpularity\", \n                                    rescale = True, \n                                    img_shape = Config.IMG_SHAPE.value,\n                                    do_augment = True,\n                                    repeat = False,\n                                    shuffle = True,\n                                    batch_size = 32,\n                                )()\n        val_data_gen = ImgDataLoader(\n                                    val_data, \n                                    \"path\", \n                                    \"Pawpularity\", \n                                    rescale = True, \n                                    img_shape = Config.IMG_SHAPE.value,\n                                    do_augment = False,\n                                    repeat = False,\n                                    shuffle = False,\n                                    batch_size = 16\n                                )()\n        \n        training_history = train_model(tf_model, fold)\n        \n        summary = {\n            \"epochs\" : [d for d in range(1, Config.EPOCHS.value + 1)],\n            \"loss\" : training_history.history['loss'],\n            \"val_loss\" : training_history.history['val_loss'],\n#             \"lr\" : training_history.history['lr']\n        }\n        \n        givePlotsInOne(training_summary = summary, useDark = False, title = f\"For Fold {fold + 1}\")","10a09b34":"trainEngine(tf_model = CustomModel(\n                        filters = [32, 64, 128],\n                        kernel_sizes = [3, 3, 3],\n                        img_dim = Config.IMG_SHAPE.value,\n                        use_dropout= True\n                    ),\n            tf_model_name = \"Custom_CNN\", \n            data_df = data_df)","2e5f8eb8":"def saveModelsKaggle(dir_name: str, title: \"title of dataset\", token_path=\"..\/input\/kaggletoken\/kaggle.json\"):\n    \"\"\"\n     > Helper function to automate the process of saving models \n        as kaggle datasets using kaggle API   \n     > dir_name should be compatible with hyperlink formats\n\n    \"\"\"\n    if not os.path.exists(token_path):\n        print(\"Token doesn't exist\")\n        return\n\n    if not os.path.exists(f\".\/{dir_name}\"):\n        print(\"Directory doesn't exist\")\n        return\n\n    os.system(\n        f\"\"\"\n        \n        pip install kaggle\n        cp {token_path} .\/\n        cp .\/kaggle.json ..\/..\/root\/\n        mkdir ..\/..\/root\/.kaggle\n        mv ..\/..\/root\/kaggle.json ..\/..\/root\/.kaggle\/kaggle.json\n\n        chmod 600 \/root\/.kaggle\/kaggle.json\n        kaggle datasets init -p .\/{dir_name}\n        \n        \"\"\"\n    )\n    # Upto this we will be having a meta data file in the form of a json\n    with open(f\".\/{dir_name}\/dataset-metadata.json\", 'r+') as file_:\n        meta_data = json.load(file_)\n        meta_data['title'] = f'{title}'\n        meta_data['id'] = f'hotsonhonet\/{title}'\n        file_.seek(0)\n        json.dump(meta_data, file_, indent=4)\n        file_.truncate()\n\n    os.system(f\"\"\"\n        kaggle datasets create -p .\/{dir_name} --dir-mode zip\n    \"\"\")\n\n    print(\"[INFO] Dataset saved successfully\")","31fd2eab":"saveModelsKaggle(dir_name = \"Custom_CNN\", title =  \"petfinderCustomModel\")","a05de53e":"# Building a custom neural network","159a44db":"# Saving Model Weights\n","1d93273d":"#  Lets create a data loader class","3d6c3bac":"# Configs and helper functions","f52cc1f7":"# Importing Modules","eed7f78b":"# Lets train","1583a8c5":"# Training Engine \ud83d\ude82\ud83c\udf2b"}}