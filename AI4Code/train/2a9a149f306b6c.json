{"cell_type":{"67f086b7":"code","bc2f6906":"code","5244ef32":"code","7e43f94f":"code","b14ac5a2":"code","e44c37ea":"code","bffa7e11":"code","3b7b8ec6":"code","3199b9ac":"code","63d7e2a9":"code","aaf73b32":"code","b431e547":"code","3ea240a4":"code","b2198ed6":"code","e13b4777":"code","680c0ee7":"code","d4eb9061":"code","2fda911a":"code","a3fa48f0":"code","230d35e8":"code","9589523b":"markdown","2053e9f0":"markdown","17796d66":"markdown","5b28a446":"markdown","0dd06ee7":"markdown"},"source":{"67f086b7":"#the data is deployed twice...\n!ls \/kaggle\/input\/skin-cancer-malignant-vs-benign\/","bc2f6906":"from fastai.vision import *\nimport torchvision","5244ef32":"path = Path('\/kaggle\/input\/skin-cancer-malignant-vs-benign\/data')\nclasses = ['malignant','benign']\nImageList.from_folder(path)","7e43f94f":"tfms = get_transforms(do_flip=True,flip_vert=True)\ndata = (ImageList.from_folder(path) #Where to find the data? -> in path and its subfolders\n        .split_by_folder('train','test')              #How to split in train\/valid? -> use the folders\n        .label_from_folder()            #How to label? -> depending on the folder of the filenames\n        .transform(tfms, size=224)       #Data augmentation? -> use tfms with a size of 64\n        .databunch(bs=32))","b14ac5a2":"data","e44c37ea":"data.classes","bffa7e11":"data.show_batch(rows=3, figsize=(7,8))","3b7b8ec6":"data.classes, data.c, len(data.train_ds), len(data.valid_ds)","3199b9ac":"# model loading implemented thanks to https:\/\/www.kaggle.com\/faizu07\/kannada-mnist-with-fastai\n!mkdir -p \/tmp\/.cache\/torch\/checkpoints\n!cp \/kaggle\/input\/fastai-pretrained-models\/resnet50-19c8e357.pth \/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth\nlearn = cnn_learner(data, models.resnet50, metrics=[error_rate, accuracy], model_dir = Path('..\/kaggle\/working'),path = Path(\".\"),pretrained=True)","63d7e2a9":"learn.summary() ","aaf73b32":"learn.fit_one_cycle(4)","b431e547":"learn.save('stage-1')","3ea240a4":"learn.load('stage-1')\nlearn.unfreeze()","b2198ed6":"learn.lr_find(start_lr=1e-9, end_lr=1e-1)","e13b4777":"learn.recorder.plot(suggestion=True)","680c0ee7":"learn.fit_one_cycle(6, max_lr=slice(1e-04,1e-05)) ","d4eb9061":"learn.save('stage-2')\n#learn.export('skin_classifier.pkl')","2fda911a":"learn.load('stage-2');interp = ClassificationInterpretation.from_learner(learn)","a3fa48f0":"interp.plot_confusion_matrix()","230d35e8":"interp.plot_top_losses(12)","9589523b":"## Train model with transfer learning","2053e9f0":"For pretrained==True -> check out the trainable layers, currently only  the batchnorm parameters and the last layer weights can be trained!","17796d66":"Using the data_block api to create a databunch. The images in the test folder become the validation set.","5b28a446":"## Interpretation","0dd06ee7":"# Skin cancer classification with fastai library\n\nCheck out the awesome [fastai](https:\/\/docs.fast.ai) libary and the great [online courses](https:\/\/course.fast.ai\/). \n\nThe obtained accuracy with fastai is >90% using transfer learning with a pre-trained resnet50 and just a few lines of code!"}}