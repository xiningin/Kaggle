{"cell_type":{"733f93f2":"code","0b7482a6":"code","d08029ad":"code","b932efff":"code","92b27653":"code","13a592be":"code","374c4761":"code","485eeb9d":"code","d21efa31":"code","230def43":"code","e808378c":"code","df96f984":"code","efce2fb9":"code","036ba899":"code","71b21195":"code","0a821d4d":"code","fc6d8a18":"code","3080e7b0":"code","8145bad5":"code","0b293119":"code","525c3fde":"code","32b5a582":"code","1747dc62":"code","8b59f7eb":"code","ca9df04c":"code","735adad0":"code","5c587a40":"code","08949ce5":"code","18880d45":"code","617c7408":"code","a0f4a947":"code","62113901":"code","02f8a92a":"code","d7f96610":"code","cdcb1341":"code","cfca4eff":"code","404e1671":"code","8b8a4467":"code","2ce44d20":"code","85e3a56d":"code","3dc241fd":"code","3d8b04a5":"code","1f1bea52":"code","c3b2edd2":"code","63476a6a":"code","2a0125b8":"code","a036e667":"code","eda9c286":"code","052e6995":"markdown","8a0f2419":"markdown","42cce5cd":"markdown","b6129d06":"markdown","c1a19fb7":"markdown","f205b92d":"markdown","5bf63c8a":"markdown","4dde9de2":"markdown","26892d87":"markdown","c7c01e3f":"markdown","7f342bc1":"markdown","cba2eae1":"markdown","26123fc3":"markdown","81b68c1b":"markdown","f77ea066":"markdown","b04c0098":"markdown","a076d49a":"markdown","53d1c655":"markdown"},"source":{"733f93f2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport gc\nimport seaborn as sns\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, classification_report, roc_auc_score\nimport matplotlib.dates as mdates\nfrom matplotlib.collections import LineCollection\nfrom matplotlib.colors import ListedColormap, BoundaryNorm","0b7482a6":"q_df = pd.read_csv(\"..\/input\/ai4digigov2021\/queue_dataset_train.csv\")\nq_df.describe()","d08029ad":"q_df.drop(q_df.query('service_canceled == 0').sample(frac=.50).index, inplace=True)","b932efff":"q_df.describe()","92b27653":"q_df.head()","13a592be":"q_df_test = pd.read_csv(\"..\/input\/ai4digigov2021\/queue_dataset_test.csv\")","374c4761":"q_df[\"date_converted\"] = pd.to_datetime(q_df[\"date\"], format='%Y-%m-%d')\nq_df_test[\"date_converted\"] = pd.to_datetime(q_df_test[\"date\"], format='%Y-%m-%d')","485eeb9d":"q_df[\"customer_age_appl\"].value_counts()","d21efa31":"q_df_test[\"customer_age_appl\"].value_counts()","230def43":"################################# Handle Missing Data #########################\nq_df.isna().sum()","e808378c":"# previous customer count of Null means 0 previous costumers\nq_df[\"previous_customer_count\"].isna().sum()\nq_df[\"previous_customer_count\"].fillna(0, inplace=True)\nq_df[\"customer_age_appl\"].fillna(q_df[\"customer_age_appl\"].mode().iloc[0], inplace=True) \nq_df[\"time_start_process\"].fillna(method='ffill', inplace=True)","df96f984":"## Service result distribution\nq_df[\"service_canceled\"].value_counts()\nq_df[\"service_canceled\"].value_counts(normalize=True)","efce2fb9":"q_df.dropna(inplace=True)","036ba899":"def season_of_date(date):\n    year = str(date.year)\n    seasons = {'spring': pd.date_range(start='21\/03\/'+year, end='20\/06\/'+year),\n               'summer': pd.date_range(start='21\/06\/'+year, end='22\/09\/'+year),\n               'autumn': pd.date_range(start='23\/09\/'+year, end='20\/12\/'+year)}\n    if date in seasons['spring']:\n        return 'spring'\n    if date in seasons['summer']:\n        return 'summer'\n    if date in seasons['autumn']:\n        return 'autumn'\n    else:\n        return 'winter'","71b21195":"def season_of_date_mn(date):\n    mnt = date.month\n    if (1<=mnt<=3):\n      return 1\n    elif (4<=mnt<=5):\n      return 2\n    elif (6<=mnt<=9):\n      return 3\n    elif (10<=mnt<=11):\n      return 4\n    elif (mnt==12):\n      return 1\n    print(mnt)","0a821d4d":"q_df.info()","fc6d8a18":"################### Feature Engineering #######################################\nq_df[\"approach_month\"] = q_df[\"date_converted\"].dt.month.astype(str)\n\nq_df[\"week_day\"] = q_df[\"date_converted\"].dt.dayofweek\nq_df[\"season\"] = q_df.date_converted.map(season_of_date_mn)\n\n\nq_df[\"ticket_taking_time_hour\"] = q_df['time_start_process'].str[:2] \nq_df[\"ticket_taking_time_hour\"] = q_df[\"ticket_taking_time_hour\"].astype(str)","3080e7b0":"######################### Handle categorical variables ########################\nencoded_categorical = pd.get_dummies(q_df[[\"branch_name\", \"customer_gender\", 'customer_age_appl',\n                         'customer_city', \"approach_month\", \"ticket_taking_time_hour\", \"service_name_organization\", \"service_name\"]])","8145bad5":"######################### Handle numeric variables #############################\ndataset = pd.concat([q_df, encoded_categorical], axis=1)","0b293119":"################################ Train-Test Splitting ######################################\nlabels = dataset['service_canceled']\n# for reproducible results \nseed = 42\n\n# drop non numerical columns\ndataset.drop(['id', 'branch_name', 'date', 'date_converted', 'customer_gender','customer_age_appl','customer_city','service_name_organization','service_name','service_name_2','time_start_process','service_canceled'], axis=1, inplace=True)\n\ndataset = dataset.astype({\"approach_month\": int, \"ticket_taking_time_hour\": int})\n\n\nx_train, x_test, y_train, y_test = train_test_split(dataset, labels,\n                                                    test_size=0.33,\n                                                    random_state=seed)","525c3fde":"x_train.info()","32b5a582":"x_train.isna().sum()","1747dc62":"y_test.value_counts()\ny_test.value_counts(normalize=True)","8b59f7eb":"y_train.value_counts()\ny_train.value_counts(normalize=True)","ca9df04c":"from sklearn.metrics import roc_curve, roc_auc_score\n\n\ndef get_auc_scores(clf, X_train, X_test, y_train, y_test):\n    y_train_score = clf.predict_proba(X_train)[:, 1]\n    y_test_score = clf.predict_proba(X_test)[:, 1]\n    auc_train = roc_auc_score(y_train, y_train_score)\n    auc_test = roc_auc_score(y_test, y_test_score)\n    print(f\"\"\"        Training AUC: {auc_train} Testing AUC: {auc_test}\"\"\")\n\n    return y_test_score","735adad0":"from sklearn.metrics import (roc_curve, auc, roc_auc_score, confusion_matrix)\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\n\n\ndef plot_roc_curve(fpr, tpr, roc_auc):\n    \"\"\"\n    Plots the roc curve.\n    \"\"\"\n    plt.plot(fpr, tpr)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve (area = %0.6f)' % roc_auc)\n    plt.show()","5c587a40":"q_df_test[\"time_start_process\"].fillna(method='ffill', inplace=True)\nq_df_test[\"customer_age_appl\"].fillna(q_df[\"customer_age_appl\"].mode().iloc[0], inplace=True) \n\nq_df_test[\"approach_month\"] = q_df_test[\"date_converted\"].dt.month.astype(str)\nq_df_test[\"week_day\"] = q_df_test[\"date_converted\"].dt.dayofweek\nq_df_test['season'] = q_df_test.date_converted.map(season_of_date_mn)\nq_df_test[\"ticket_taking_time_hour\"] = q_df_test['time_start_process'].str[:2] \nq_df_test[\"ticket_taking_time_hour\"] = q_df_test[\"ticket_taking_time_hour\"].astype(str)\n\n\nencoded_categorical_test = pd.get_dummies(q_df_test[[\"branch_name\", \"customer_gender\", 'customer_age_appl',\n                         'customer_city', \"approach_month\", \"ticket_taking_time_hour\", \"service_name_organization\", \"service_name\"]])\n\ndataset_test = pd.concat([q_df_test, encoded_categorical_test], axis=1)\ndataset_test = dataset_test.astype({\"approach_month\": int, \"ticket_taking_time_hour\": int})\n#dataset_test.drop(['id', 'branch_name', 'date', 'date_converted', 'customer_gender','customer_age_appl','customer_city','service_name_organization','service_name','service_name_2','time_start_process'], axis=1, inplace=True)","08949ce5":"train_cols = list(dataset.columns)\ntest_cols = list(dataset_test.columns)\nm_cols = set( train_cols ) - set( test_cols )\n# Add a missing column in test set with default value equal to 0\nfor c in m_cols:\n    dataset_test[c] = 0\n# Ensure the order of column in the test set is in the same order as in train set\ndataset_test = dataset_test[train_cols]","18880d45":"from sklearn.metrics import confusion_matrix","617c7408":"#Training 2nd Model - Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)","a0f4a947":"### Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Naive Bayes\")\nprint(cm)\nprint('Accurancy: {:.0f}%'.format(classifier.score(x_test, y_test)*100))","62113901":"#Training 3rd Model - DecisionTree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n#parameters={'max_depth': range(10,20,5), 'criterion':['entropy'], 'random_state' : [0]}\n#model_tree=DecisionTreeClassifier()\n#clf = GridSearchCV(model_tree, parameters, verbose=10)\n#clf.fit(x_train,y_train,)\n#clf.best_params_\n\nmodel_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 10, random_state=1)\nmodel_tree.fit(x_train, y_train)\ny_pred = model_tree.predict(x_test)","02f8a92a":"### Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"DecisionTree\")\nprint(cm)\nprint('Accurancy: {:.0f}%'.format(model_tree.score(x_test, y_test)*100))","d7f96610":"get_auc_scores(model_tree, x_train, x_test, y_train, y_test)","cdcb1341":"############## AUC score Baseline Model ##########################\nY_pred = model_tree.predict_proba(x_test)\ny_true = np.array(y_test)\ny_scores = Y_pred[:, 1]\n\n# plotting the roc curve\nfpr, tpr, _ = roc_curve(y_test, y_scores)\nroc_auc = auc(fpr, tpr)\nplot_roc_curve(fpr, tpr, roc_auc)\n\n# calculating roc auc score\nroc_auc_score(y_test, Y_pred[:, 1])\n# AUC score of baseline model:  0.7157968741854305\nprint(\"AUC score of baseline model: \", roc_auc_score(y_test, y_scores))","cfca4eff":"y_pred_test = model_tree.predict_proba(dataset_test)\ny_scores_test = y_pred_test[:, 1]\n\nq_df_test['service_canceled'] = y_scores_test\nq_df_test[[\"id\", \"service_canceled\"]].to_csv(\"baseline_submission_guru_dt.csv\", index=False)","404e1671":"model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.6, gamma=5, learning_rate=0.02, max_delta_step=0,\n       max_depth=15, min_child_weight=5, missing=5, n_estimators=5,\n       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=10, seed=42,\n       silent=True, subsample=1.0)\n#(base_score=0.5, booster='gbtree', colsample_bylevel=0.7,\n#              colsample_bynode=0.7, colsample_bytree=0.6, gamma=0,\n#              importance_type='gain', interaction_constraints='',\n#              learning_rate=0.0100000012, max_delta_step=0, max_depth=10,\n#              min_child_weight=1, missing=np.nan,\n#              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=0,\n#              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=1,\n#              tree_method='approx', validate_parameters=1,\n#              use_label_encoder=False)","8b8a4467":"model.fit(x_train, y_train,\n        eval_set=[(x_train, y_train), (x_test, y_test)],\n        eval_metric=['auc', \"logloss\"],\n        verbose=True)\n\nprint(model)","2ce44d20":"################# Model Learning Visualization ################################\n\n# retrieve performance metrics\nresults = model.evals_result()\nepochs = len(results['validation_0']['auc'])\nx_axis = range(0, epochs)\n\n# plot AUC score evolution\nfig, ax = plt.subplots(figsize=(12,12))\nax.plot(x_axis, results['validation_0']['auc'], label='Train')\nax.plot(x_axis, results['validation_1']['auc'], label='Test')\nax.legend()\n\nplt.ylabel('AUC Score')\nplt.title('XGBoost AUC evolution')\nplt.show()","85e3a56d":"model.get_booster().get_score(importance_type='gain')\nfeature_importances = model.get_booster().get_score(importance_type='total_gain')\n\nmodel.get_xgb_params()\n\nxgb.plot_importance(model,max_num_features=20,importance_type='gain',xlabel='gain')\n","3dc241fd":"print (xgb.__version__)","3d8b04a5":"############## AUC score Baseline Model ##########################\nY_pred = model.predict_proba(x_test)\ny_true = np.array(y_test)\ny_scores = Y_pred[:, 1]\n\n# plotting the roc curve\nfpr, tpr, _ = roc_curve(y_test, y_scores)\nroc_auc = auc(fpr, tpr)\nplot_roc_curve(fpr, tpr, roc_auc)\n\n# calculating roc auc score\nroc_auc_score(y_test, Y_pred[:, 1])\n# AUC score of baseline model:  0.7157968741854305\nprint(\"AUC score of baseline model: \", roc_auc_score(y_test, y_scores))\n","1f1bea52":"y_pred_test = model.predict_proba(dataset_test)\ny_scores_test = y_pred_test[:, 1]\n\nq_df_test['service_canceled'] = y_scores_test\nq_df_test[[\"id\", \"service_canceled\"]].to_csv(\"baseline_submission_guru_xg.csv\", index=False)","c3b2edd2":"q_df_test[[\"id\", \"service_canceled\"]].head()","63476a6a":"from sklearn.ensemble import RandomForestClassifier\nmodel_rf = RandomForestClassifier(n_estimators = 50, random_state = 1)\nmodel_rf.fit(x_train, y_train)\ny_pred = model_rf.predict(x_test).round(0)","2a0125b8":"### Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"DecisionTree\")\nprint(cm)\nprint('Accurancy: {:.0f}%'.format(model_rf.score(x_test, y_test)*100))","a036e667":"############## AUC score Baseline Model ##########################\nY_pred = model_rf.predict_proba(x_test)\ny_true = np.array(y_test)\ny_scores = Y_pred[:, 1]\n\n# plotting the roc curve\nfpr, tpr, _ = roc_curve(y_test, y_scores)\nroc_auc = auc(fpr, tpr)\nplot_roc_curve(fpr, tpr, roc_auc)\n\n# calculating roc auc score\nroc_auc_score(y_test, Y_pred[:, 1])\n# AUC score of baseline model:  0.7157968741854305\nprint(\"AUC score of baseline model: \", roc_auc_score(y_test, y_scores))","eda9c286":"y_pred_test = model_rf.predict_proba(dataset_test)\ny_scores_test = y_pred_test[:, 1]\n\nq_df_test['service_canceled'] = y_scores_test\nq_df_test[[\"id\", \"service_canceled\"]].to_csv(\"baseline_submission_guru_rf.csv\", index=False)","052e6995":"Predicting on the public test dataset.","8a0f2419":"#**Training 3rd Model - XGBClassifier**","42cce5cd":"### Dataset s\u00fctunlar\n\n-\tid: S\u0259trin id-si, unikald\u0131r\n-\tdate: \u015e\u0259xsin xidm\u0259t\u0259 m\u00fcraci\u0259t tarixi (tarixin format\u0131: ay\/g\u00fcn\/il)\n-\tbranch_name: \u015e\u0259xsin xidm\u0259t \u00fc\u00e7\u00fcn yax\u0131nla\u015fd\u0131\u011f\u0131 m\u0259rk\u0259zin ad\u0131\n-\tcustomer_gender: \u015e\u0259xsin cinsi\n-\tcustomer_age_appl: \u015e\u0259xsin xidm\u0259t\u0259 m\u00fcraci\u0259t tarixind\u0259 qeyd edil\u0259n ya\u015f\u0131\n-\tcustomer_city: \u015e\u0259xsin qeydiyyatda oldu\u011fu \u015f\u0259h\u0259r\n-\tservice_name_organization: Xidm\u0259ti t\u0259min ed\u0259n d\u00f6vl\u0259t orqan\u0131n\u0131n ad\u0131\n-\tservice_name: Xidm\u0259tin ad\u0131, \u00fcst kateqoriya\n-\tservice_name_2: Xidm\u0259tin ad\u0131, alt kateqoriya\n-\ttime_start_process: \u015e\u0259xsin xidm\u0259t almaq \u00fc\u00e7\u00fcn m\u00fcraci\u0259t etm\u0259 vaxt\u0131 (saat:d\u0259qiq\u0259:saniy\u0259)\n-\toperator_count: \u015e\u0259xsin n\u00f6vb\u0259 g\u00f6t\u00fcrd\u00fcy\u00fc zaman m\u00fcraci\u0259t etdiyi xidm\u0259t \u00fczr\u0259 i\u015fl\u0259y\u0259n aktiv operator say\u0131\n-\tprevious_customer_count: \u015e\u0259xsin n\u00f6vb\u0259 g\u00f6t\u00fcrd\u00fcy\u00fc zaman m\u00fcraci\u0259t etdiyi xidm\u0259t \u00fczr\u0259 n\u00f6vb\u0259d\u0259 olan \u015f\u0259xsl\u0259rin say\u0131 \n-\tservice_canceled: \u015e\u0259xsin xidm\u0259td\u0259n imtina edib-etm\u0259m\u0259si [Xidm\u0259td\u0259n imtina edildi = 1, xidm\u0259td\u0259n imtina edilm\u0259di, y\u0259ni xidm\u0259t g\u00f6st\u0259rildi = 0]\n\n##### *Dataset-d\u0259 anomaliya v\u0259 \u0259skik (missing) data hallar\u0131n\u0131n olma ehtimal\u0131 vard\u0131r.","b6129d06":"#**Training 2nd Model - DecisionTree**","c1a19fb7":"Techniques for Handling Imbalanced Dataset:\n- Oversampling and Udersampling\n- Generate Synthetic Samples\n- Using Tree Algorithms\n- Using Penalized Models\n","f205b92d":"### Modeling","5bf63c8a":"### \tExploratory Data Analysis ","4dde9de2":"An imbalanced classification problem is an example of a classification problem where the distribution of examples across the known classes is biased or skewed. The distribution can vary from a slight bias to a severe imbalance where there is one example in the minority class for hundreds, thousands, or millions of examples in the majority class or classes.\n\nImbalanced classifications pose a challenge for predictive modeling as most of the machine learning algorithms used for classification were designed around the assumption of an equal number of examples for each class. This results in models that have poor predictive performance, specifically for the minority class. This is a problem because typically, the minority class is more important and therefore the problem is more sensitive to classification errors for the minority class than the majority class.","26892d87":"#**Training 1st Model - Naive Bayes**","c7c01e3f":"### Handle Missing Data","7f342bc1":"### Predicting on the public test data","cba2eae1":"\nWe need to apply same feature engineering precedures to the test dataset.","26123fc3":"#### *Note that baseline model is made worse intentionally.","81b68c1b":"We need to make sure columns are same and in the same order both in train and test datasets.","f77ea066":"# <center> AI4DIGIGOV Conference Workshop <\/center>","b04c0098":"### Feature Engineering\n***\n\n<div style=\"text-align: right \"> <i>Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away. <\/i><\/div>\n<div style=\"text-align: right \"> - Antoine de Saint-Exupery<\/div>","a076d49a":"#**Training 4th Model - RandomForest**","53d1c655":"##### Model Feature Importance Analysis"}}