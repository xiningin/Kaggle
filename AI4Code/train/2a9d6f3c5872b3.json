{"cell_type":{"d443ca89":"code","f45df883":"code","ab0d6adb":"code","54ef0df6":"code","06d950f5":"code","698a281b":"code","0ae8725b":"code","8a5069b4":"code","be549764":"code","fb771213":"code","6b9ba6b8":"code","ab2cbc45":"code","3fae5a22":"code","f31eae24":"code","edf921cb":"code","56ca5d91":"code","d753bb82":"code","19c5326d":"code","c537cb0a":"code","de1c10e0":"code","d0e2afe1":"code","3c6bc5e6":"code","dbb6219a":"code","b3179162":"code","5be401b6":"code","f71f35d3":"code","a9d0ac8d":"code","35825c2a":"code","db5ff3f0":"code","4ad874d8":"code","9ad7c1a1":"code","91929d75":"code","715a31df":"markdown","c3406fa4":"markdown","ed805cbf":"markdown","dae97b2d":"markdown","773599a6":"markdown","87aeb6a0":"markdown","d60e1dc8":"markdown","c470452f":"markdown","b49cf70c":"markdown","78383b28":"markdown","a8fe318c":"markdown","c886d57d":"markdown","37740fd1":"markdown","0d7b7e66":"markdown","4f320df3":"markdown","c9bd74d5":"markdown","46fdabd7":"markdown","f4282345":"markdown","96ba3aa9":"markdown","349fc563":"markdown","cf78c821":"markdown","634f8c99":"markdown","819a6574":"markdown","af1722ed":"markdown","cf09a859":"markdown","cbd048e8":"markdown","804d69c9":"markdown","fe1b3734":"markdown","b49cd286":"markdown","2cf3b3b1":"markdown","bb75cf47":"markdown","e4c1a27a":"markdown","f9511615":"markdown","e33b0548":"markdown","0d96a3b7":"markdown","e6a2af09":"markdown","4c2c2d43":"markdown","4bec1b51":"markdown","81292e92":"markdown","c023f69b":"markdown","c6c1d4cd":"markdown","bd3db170":"markdown"},"source":{"d443ca89":"# Ignore warnings :\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Handle table-like data and matrices :\nimport numpy as np\nimport pandas as pd\nimport math \nimport itertools\n\n\n\n# Modelling Algorithms :\n\n# Classification\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis , QuadraticDiscriminantAnalysis\n\n# Regression\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor \nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n\n\n\n# Modelling Helpers :\nfrom sklearn.preprocessing import Imputer , Normalizer , scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n\n\n\n#preprocessing :\nfrom sklearn.preprocessing import MinMaxScaler , StandardScaler, Imputer, LabelEncoder\n\n\n\n#evaluation metrics :\n\n# Regression\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n\n# Classification\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  \n\n\n# Deep Learning Libraries\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\nfrom keras.utils import to_categorical\n\n\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport missingno as msno\n\n\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\nparams = { \n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplt.rcParams.update(params)","f45df883":"# Center all plots\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\");","ab0d6adb":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ndf = train.copy()\ndf_test = test.copy()","54ef0df6":"# How the Data looks\ndf.head()","06d950f5":"print(\"Train: \", df.shape)\nprint(\"Test: \", df_test.shape)","698a281b":"df.describe()","0ae8725b":"# Train\ndf.isnull().any().sum()","8a5069b4":"# Test\ndf_test.isnull().any().sum()","be549764":"# Generate Random Numbers\nrdm = np.random.randint(0,42000,size=4)\nprint(rdm)","fb771213":"fig, ax = plt.subplots(2,2, figsize=(12,6))\nfig.set_size_inches(10,10)\nax[0,0].imshow(df.drop('label',axis=1).values[rdm[0]].reshape(28,28),cmap='gray')\nax[0,1].imshow(df.drop('label',axis=1).values[rdm[1]].reshape(28,28),cmap='gray')\nax[1,0].imshow(df.drop('label',axis=1).values[rdm[2]].reshape(28,28),cmap='gray')\nax[1,1].imshow(df.drop('label',axis=1).values[rdm[3]].reshape(28,28),cmap='gray')","6b9ba6b8":"df['label'].value_counts()","ab2cbc45":"plt.figure(figsize=(13,7))\nplt.hist( x=df['label'] , bins=19 ,color='c')\nplt.xlabel('Digits')\nplt.ylabel('Frequency')\nplt.title('Distribution of Label\\'s')","3fae5a22":"## Setting the seeds for Reproducibility.\nseed = 66\nnp.random.seed(seed)","f31eae24":"X = train.iloc[:,1:]\nY = train.iloc[:,0]\nx_train , x_test , y_train , y_test = train_test_split(X, Y , test_size=0.1, random_state=seed)","edf921cb":"# The first parameter in reshape indicates the number of examples.\n# We pass it as -1, which means that it is an unknown dimension and we want numpy to figure it out.\n\n# reshape(examples, height, width, channels)\nx_train = x_train.values.reshape(-1, 28, 28, 1)\nx_test = x_test.values.reshape(-1, 28, 28, 1)\ndf_test=df_test.values.reshape(-1,28,28,1)","56ca5d91":"\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images","d753bb82":"df.dtypes.head()","19c5326d":"# You need to make sure that your Image is cast into double\/float from int before you do this scaling \n# as you will most likely generate floating point numbers.\n# And had it been int, the values will be truncated to zero.\n\nx_train = x_train.astype(\"float32\")\/255\nx_test = x_test.astype(\"float32\")\/255\ndf_test = df_test.astype(\"float32\")\/255","c537cb0a":"datagen.fit(x_train)","de1c10e0":"y_train = to_categorical(y_train, num_classes=10)\ny_test = to_categorical(y_test, num_classes=10)\n\nprint(y_train[0])","d0e2afe1":"# Building ConvNet\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last',\n                 input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid' ))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu', data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='valid', strides=2))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","3c6bc5e6":"# Optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999 )","dbb6219a":"# Compiling the model\nmodel.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","b3179162":"model.summary()","5be401b6":"reduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)","f71f35d3":"batch_size = 64\nepochs = 20","a9d0ac8d":"# Fit the Model\nhistory = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, \n                              validation_data = (x_test, y_test), verbose=2, \n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n                              callbacks = [reduce_lr])","35825c2a":"model.evaluate(x_test, y_test)","db5ff3f0":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(\"Model Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Test'])\nplt.show()","4ad874d8":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train','Test'])\nplt.show()","9ad7c1a1":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(x_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10))","91929d75":"pred_digits_test=np.argmax(model.predict(df_test),axis=1)\nimage_id_test=[]\nfor i in range (len(pred_digits_test)):\n    image_id_test.append(i+1)\nd={'ImageId':image_id_test,'Label':pred_digits_test}\nanswer=pd.DataFrame(d)\nanswer.to_csv('answer.csv',index=False)","715a31df":"The Pixel Values are often stored as __*Integer*__ Numbers in the range 0 to 255, the range that a single 8-bit byte can offer.","c3406fa4":"<a id=\"there_you_go_1.4\"><\/a>\n## 1.4) Examine Dimensions","ed805cbf":"**We can clearly see that the Validation Accuracy and Training Accuracy are close enough. This concludes that our model is not Overfitting the Data.**","dae97b2d":"<a id=\"there_you_go_2.2\"><\/a>\n## 2.2) Distribution of Labels\n**Let's look at the Distribution of labels to visualize if there are any Skewed Classes.**","773599a6":"**Our model did pretty good job in classifying the Images. But it seems that it got confused and misclassified digit 4 as 9.**","87aeb6a0":"1. Normalization is performed on the Dataset to Scale the values within a Range. [0,1]\n2. This helps Gradient Descent to Converge much faster.\n3. Normalization is important to bring all the features to equal level and give all of them equal weigthage.\n4. Normalization helps remove distortions caused by Light and Shadows in an Image.\n\n\n5. Normalization is carried out as follows:\n\n> x = (x - min) \/ (max - min)  ;  Here min=0 and max=255","d60e1dc8":"<a id=\"there_you_go_3.1\"><\/a>\n## 3.1) Setting the Random Seeds","c470452f":"<a id=\"there_you_go_3.3\"><\/a>\n## 3.3) Reshape the Images\n* Note that we have Images as 1D vector each containing 784 pixels. Before we feed the data to the CNN we must reshape the data into (28x28x1) 3D matrices.\n* This is because Keras wants an Extra Dimension in the end, for channels. If this had been RGB images, there would have been 3 channels, but as MNIST is gray scale it only uses one.","b49cf70c":"* **So, there are 42000 Train Examples and 28000 Test Examples.**\n* **Each image is 28 pixels in height and 28 pixels in width, with 784 pixels in total.**\n> * Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. \n> * This pixel-value is an integer between 0 and 255, inclusive.\n* **There is one extra column in Training sample called \"Label\" which is the Digit drawn by the user.**","78383b28":"<a id=\"there_you_go_4.1\"><\/a>\n## 4.1) Why CNN?\n* **Because when it comes to Image Recognition, then CNN's are the best.**\n\n* **It became successful in the late 90's after Yann LeCun used it on MNIST and acheived 99.5% accuracy.**\n\n* **You can try other Models like Support Vector Machines, K-Nearest Neighbour, Random Forest but the accuracy acheived is 96-97%, which is not that good.**\n\n* **The Biggest Challenge is picking the Right model by understanding the Data rather than Tuning parameters of other models.**\n\n* **And the last point, A large Training data really helps in improving Neural Networks Accuracy.**","a8fe318c":"<a id=\"there_you_go_4.3\"><\/a>\n## 4.3) Compiling the Model\n1) Before Training the model, we need to configure the Learning process, which is done via the compile method in Keras.\n\n2) We need to specify the Optimizer. Optimization Algorithms help us minimize the Error Function. The internal parameters of a Model play a very important role in efficiently and effectively training a Model and produce accurate results. This is why we use various Optimization strategies and algorithms to update and calculate appropriate and optimum values of such model\u2019s parameters \n\nThere are a lot of Optimization Algos available, You can use RMSprop, Adam, AdaGrad, AdaDelta etc. I have used Adam (Adaptive Moment Estimation) here as it converges very fast and the learning speed of the Model is quiet Fast and efficient and also it rectifies every problem that is faced in other optimization techniques such as vanishing Learning rate , slow convergence or High variance in the parameter updates which leads to fluctuating Loss function.\n\n3) Next we Specify Loss Function. For Binary Classification we use \"binary_crossentropy\" and for Multi-class Classification we use \"categorical_crossentropy\".\n\n4) Atlast we specify the metrics to Evaluate the model performance.","c886d57d":"![](https:\/\/i.imgur.com\/4m7Zw1T.png)","37740fd1":"**Steps:**\n\n1) At First, we use **Sequential Keras API** which is just a linear stack of layers. We add one layer at a time starting from input.\n\n2) Next We add **Convolutional Layers**, which are the Building blocks of ConvNets. Convolutional Layers has set of Independent Filters whose depth is equal to Input and other dimensions can be set manually. These Filters when convolved over the Input Image produce *Feature Maps*. \n\nIt includes some HyperParameters such as **The number of filters, Dimensions of Filter (F), Stride (S), Padding(P) , Activation Function etc. which we input manually. Let the Input Volume Size be deonted by (W) ,**\n\n**Then, the Output will have Dimensions given by -->**\n\n**(Height, Width) = ( ( W \u2212 F + 2P ) \/ S ) + 1 **\n\nAnd the Depth will be equal to Number of Filters Specified.\n\n3) Next We add **Pooling Layers**, which are used for Dimensionality Reduction or DownSampling the Input. These are used where we have lot of Input Features. It reduces the amount of Parameters and Computational power required drastically, thus reducing Overfitting. These along with Convolutional layers are able to learn more Complex features of the Image.\n\n4) We add **Batch Normalization** where we acheive Zero mean and Variance one. It scales down outliers and forces the network to learn features in a distributed way, not relying too much on a Particular Weight and makes the model better Generalize the Images.\n\n5) To avoid Overfitting We add **Dropout**. This randomly drops some percentage of neurons, and thus the weights gets Re-Aligned. The remaining Neurons learn more features and this reduces the dependency on any one Neuron. DropOut is a Regularization Technique, which Penalizes the Parameters. Generally we set the DropOutRate between 0.2-0.5 .\n\n6) Finally we add **Flatten layer** to map the input to a 1D vector. We then add Fully connected Layers after some convolutional\/pooling layers. It combines all the Features of the Previous Layers.\n\n7) Lastly, we add the **Output Layer**. It has units equal to the number of classes to be identified. Here, we use 'sigmoid' function if it is Binary Classification otherwise 'softmax' activation function in case of Multi-Class Classification.","0d7b7e66":"<a id=\"there_you_go_4.6\"><\/a>\n## 4.6) Fitting the model","4f320df3":"<a id=\"there_you_go_1.3\"><\/a>\n## 1.3) Features\n* **Label: ** The Target variable.\n* **Pixels: ** The smallest unit of a Digital Image or Graphic that can be displayed on Digital Display Device.\n\nWhere humans can see the objects due to the Light Receptors in their Eyes which send Signals via the Optic Nerve to the Primary Visual Cortex, where the input is processed ,\n\nComputers on the other hand, see the Image as 2-dimensional arrays of numbers, known as pixels. They Classify Images based on Boundaries and Curvatures of the Object (Represented by pixel values, either RGB or GrayScale) .","c9bd74d5":"**So, there are No Null Values in Train and Test set.**","46fdabd7":"![](https:\/\/i.imgur.com\/Rlh3FGT.png)","f4282345":"## Topics\n1. [**Exploring the Dataset**](#there_you_go_1)\n> *  [1.1 Importing Libraries ](#there_you_go_1.1)\n  * [1.2 Load dataset ](#there_you_go_1.2)\n  * [1.3 Features ](#there_you_go_1.3)\n  * [1.4 Examine Dimensions ](#there_you_go_1.4)\n  * [1.5 Examine NaN values ](#there_you_go_1.5)\n2. [**Visualizing the Dataset**](#there_you_go_2)\n> * [2.1 Plotting Random Images ](#there_you_go_2.1)\n  * [2.2 Distribution of Labels ](#there_you_go_2.2)\n3. [**Data PreProcessing**](#there_you_go_3)\n> * [3.1 Setting Random Seeds ](#there_you_go_3.1)\n * [3.2 Splitting Data ](#there_you_go_3.2)\n * [3.3 Reshaping Images ](#there_you_go_3.3)\n * [3.4 Data Augmentation ](#there_you_go_3.4)\n * [3.5 Normalization ](#there_you_go_3.5)\n * [3.6 One Hot Encoding ](#there_you_go_3.6)\n4. [**Training ConvNet**](#there_you_go_4)\n> * [4.1 Why CNN ? ](#there_you_go_4.1)\n * [4.2 Building a ConvNet ](#there_you_go_4.2)\n * [4.3 Compiling Model ](#there_you_go_4.3)\n * [4.4 Model Summary ](#there_you_go_4.4)\n * [4.5 Learning Rate Decay ](#there_you_go_4.5)\n * [4.6 Fitting the Model](#there_you_go_4.6)\n5. [**Evaluating the Model**](#there_you_go_5)\n> * [5.1 Plotting Train and Validation curves ](#there_you_go_5.1)\n6. [**Plotting Confusion Matrix**](#there_you_go_6)\n7. [**Generating CSV File**](#there_you_go_7)\n8. [**Resources**](#there_you_go_8)","96ba3aa9":"### Convolution Operation\n![Imgur](https:\/\/i.imgur.com\/LMmTCdJ.gif)","349fc563":"<a id=\"there_you_go_7\"><\/a>\n# 7) Generating CSV File","cf78c821":"* **We can see that all the classes from 0-9 are distributed almost equally.**\n* **So, there is no need for OverSampling or UnderSampling.**","634f8c99":"<a id=\"there_you_go_6\"><\/a>\n# 6) Confusion Matrix\nLet's view the the Performance of our classification model on the data using Confusion Matrix.","819a6574":"<a id=\"there_you_go_3.5\"><\/a>\n## 3.5) Normalization","af1722ed":"<a id=\"there_you_go_5.1\"><\/a>\n## 5.1) Plotting the Train and Validation Curves\nLet's plot \"Accuracy as a function of number of Epochs\" and also \"Loss as a function of number of Epochs\".","cf09a859":"<a id=\"there_you_go_4.2\"><\/a>\n## 4.2) Building a ConvNet","cbd048e8":"# MNIST-Digit-Recognizer-CNN-Keras\n* **You can also view and contribute to the notebook below ->**\n* **Github - [Digit-Recognizer-CNN](https:\/\/github.com\/Chinmayrane16\/MNIST-Digit-Recognizer-CNN-Keras-99.66)**\n* **Do Star\/Upvote if you like it :)**","804d69c9":"<a id=\"there_you_go_1.2\"><\/a>\n## 1.2) Load Dataset\n* Specify the location to the Dataset and import them.","fe1b3734":"<a id=\"there_you_go_5\"><\/a>\n# 5) Evaluating the Model","b49cd286":"<a id=\"there_you_go_3.4\"><\/a>\n## 3.4) Data Augmentation\nData Augmentation simply means increasing the number of Data points. in terms of Images it means the increasing number of images in the Dataset.\n\nIn order to avoid the overfitting problem, we need expand the dataset. This can be acheived by Rotating the Image, Flipping the Image, Zooming the Image, Changing light conditions, Cropping it etc.  The more the data, the better our models would perform.\n\nA CNN that can robustly classify objects even if its placed in different orientations is said to have the property called Invariance. In the real world scenario, we may have a dataset of images taken in a limited set of conditions. But, our target application may exist in a variety of conditions, such as different orientation, location, scale, brightness etc. We account for these situations by training our neural network with additional synthetically modified data.\n\n[Click here to read more about Data Augmentation.](https:\/\/medium.com\/nanonets\/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)","2cf3b3b1":"<a id=\"there_you_go_3\"><\/a>\n# 3) Data Preprocessing","bb75cf47":"<a id=\"there_you_go_8\"><\/a>\n# 8) Resources\n\n1. Deep Learning ([Blog](https:\/\/medium.com\/intro-to-artificial-intelligence\/deep-learning-series-1-intro-to-deep-learning-abb1780ee20)) ([Video](https:\/\/www.youtube.com\/watch?v=6M5VXKLf4D4&ab_channel=Simplilearn))\n2. Neural Network ([Blog](https:\/\/medium.com\/@purnasaigudikandula\/a-beginner-intro-to-neural-networks-543267bda3c8)) ([Video](https:\/\/www.youtube.com\/watch?v=aircAruvnKk&ab_channel=3Blue1Brown))\n3. Convolutions Explained ([Blog 1](https:\/\/towardsdatascience.com\/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)) ([Blog 2](https:\/\/towardsdatascience.com\/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5)) ([Blog 3](https:\/\/cs231n.github.io\/convolutional-networks\/)) ([Blog 4](https:\/\/adeshpande3.github.io\/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks\/)) ([Blog 5](https:\/\/adeshpande3.github.io\/adeshpande3.github.io\/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2\/)) ([Video](https:\/\/www.youtube.com\/watch?v=YRhxdVk_sIs&ab_channel=deeplizard))\n4. Data Augmentation ([Blog](https:\/\/medium.com\/nanonets\/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)) ([Video](https:\/\/www.youtube.com\/watch?v=14syUbL16k4&ab_channel=deeplizard))\n\nComplete Deep Learning Specialization ([Coursera](https:\/\/www.coursera.org\/specializations\/deep-learning))","e4c1a27a":"<a id=\"there_you_go_2\"><\/a>\n# 2) Visualizing The Dataset","f9511615":"<a id=\"there_you_go_2.1\"><\/a>\n## 2.1) Plotting Random Images","e33b0548":"<a id=\"there_you_go_3.2\"><\/a>\n## 3.2) Split Data into Train and Validation \nWe split the data into a Training set and a Validation set, so that we can Evaluate the performance of our model.","0d96a3b7":"![](https:\/\/i.imgur.com\/PJTTKtB.jpg)","e6a2af09":"<a id=\"there_you_go_4.4\"><\/a>\n## 4.4) Model Summary\n**Prints the summary representation of your model.**","4c2c2d43":"<a id=\"there_you_go_1\"><\/a>\n# 1) Exploring the Dataset","4bec1b51":"<a id=\"there_you_go_1.1\"><\/a>\n## 1.1) Importing Libraries","81292e92":"<a id=\"there_you_go_4.5\"><\/a>\n## 4.5) Learning Rate Decay\n* Learning Rate plays a vital role in minimizing the Cost Function. Learning Rate is a Descent step which the Optimizing Algorithms take in order to Converge to a local optimum. \n* The Learning rate should be properly tuned , such that it is not too high to take very large steps, neither it should be too small , which would not alter the Weights and Biases.\n* Many Optimization Algorithms have a constant Learning Rate, which many a times do not converge to local optimum, and therefore we need to use Learning Rate such that it starts with a good learning rate and eventually reduces in oder to reach downhill.\n\n* To implement Learning Rate Decay, we can use either **LearningRateScheduler** or **ReduceLRonPlateau**.\n* **LearningRateScheduler** takes the step decay function as argument and return the updated learning rates for use in optimzer at every epoch stage.\n* **ReduceLRonPlateau** monitors a quantity and if no improvement is seen for a 'patience' number of epochs, then the learning rate is reduced by a factor specified manually.","c023f69b":"<a id=\"there_you_go_3.6\"><\/a>\n## 3.6) One Hot Encoding\nThe labels are given as integers between 0-9. We need to one hot encode them , Eg 4 [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] . \n\nThis is done so that we have labels for all the classes, and we can easily carry out the Error\/Cost during BackPropogation.\n\nWe have 10 digits [0-9] or classes, therefore we one-hot-encode the target variable with 10 classes","c6c1d4cd":"<a id=\"there_you_go_1.5\"><\/a>\n## 1.5) Examine NaN Values","bd3db170":"<a id=\"there_you_go_4\"><\/a>\n# 4) Training Convolutional Neural Network"}}