{"cell_type":{"1e516c4d":"code","31a020de":"code","e124365a":"code","fa53d60e":"code","90f93834":"code","3b96f4e0":"code","7bd2e5bd":"code","355273f9":"code","0256cc3a":"code","bf510a68":"code","62d5b0f8":"code","789b0688":"code","0cec6238":"code","4f78bbf8":"code","a4ba7a01":"code","f5874441":"code","6901cacd":"code","a1b668d4":"code","3af5ff74":"code","f8c93fd4":"markdown","b536c08f":"markdown"},"source":{"1e516c4d":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","31a020de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n\n# load help packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # additional plotting functionality\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running the below code (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))","e124365a":"# load data\nxray_data = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\n\n# see how many observations there are\nnum_obs = len(xray_data)\nprint('Number of observations:',num_obs)\n\n# examine the raw data before performing pre-processing\nxray_data.head(5) # view first 5 rows\n#xray_data.sample(5) # view 5 randomly sampled rows","fa53d60e":"from glob import glob\n#import os # already imported earlier\n\nmy_glob = glob('..\/input\/data\/images*\/images\/*.png')\nprint('Number of Observations: ', len(my_glob))","90f93834":"full_img_paths = {os.path.basename(x): x for x in my_glob}\nxray_data['full_path'] = xray_data['Image Index'].map(full_img_paths.get)","3b96f4e0":"# Q: how many unique labels are there? A: many (836) because of co-occurence\n# Note: co-occurence will turn out to be a real pain to deal with later, but there are several techniques that help us work with it successfully\nnum_unique_labels = xray_data['Finding Labels'].nunique()\nprint('Number of unique labels:',num_unique_labels)","7bd2e5bd":"# let's look at the label distribution to better plan our next step\ncount_per_unique_label = xray_data['Finding Labels'].value_counts() # get frequency counts per label\ndf_count_per_unique_label = count_per_unique_label.to_frame() # convert series to dataframe for plotting purposes\nprint(df_count_per_unique_label) # view tabular results","355273f9":"sns.barplot(x = df_count_per_unique_label.index[:20], y=\"Finding Labels\", data=df_count_per_unique_label[:20], color = \"green\"), plt.xticks(rotation = 90) # visualize results graphically","0256cc3a":"# define dummy labels for one hot encoding - simplifying to 14 primary classes (excl. No Finding)\ndummy_labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening', \n'Cardiomegaly', 'Nodule', 'Mass', 'Hernia'] # taken from paper\n\n# One Hot Encoding of Finding Labels to dummy_labels\nfor label in dummy_labels:\n    xray_data[label] = xray_data['Finding Labels'].map(lambda result: 1.0 if label in result else 0)\nxray_data.head(20) # check the data, looking good!","bf510a68":"# now, let's see how many cases present for each of of our 14 clean classes (which excl. 'No Finding')\nclean_labels = xray_data[dummy_labels].sum().sort_values(ascending= False) # get sorted value_count for clean labels\nprint(clean_labels) # view tabular results\n\n# plot cases using seaborn barchart\nclean_labels_df = clean_labels.to_frame() # convert to dataframe for plotting purposes\nsns.barplot(x = clean_labels_df.index[::], y= 0, data = clean_labels_df[::], color = \"green\"), plt.xticks(rotation = 90) # visualize results graphically","62d5b0f8":"# create vector as ground-truth, will use as actuals to compare against our predictions later\nxray_data['target_vector'] = xray_data.apply(lambda target: [target[dummy_labels].values], 1).map(lambda target: target[0])","789b0688":"# take a look to ensure target_vector makes sense\nxray_data.head() ","0cec6238":"# split the data into a training and testing set\nfrom sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(xray_data, test_size = 0.2, random_state = 1993)\n\n# quick check to see that the training and test set were split properly\nprint('training set - # of observations: ', len(train_set))\nprint('test set - # of observations): ', len(test_set))\nprint('prior, full data set - # of observations): ', len(xray_data))","4f78bbf8":"from keras.preprocessing.image import ImageDataGenerator\ndata_gen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True)","a4ba7a01":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","f5874441":"image_size = (128, 128) # image re-sizing target\ntrain_gen = flow_from_dataframe(data_gen, train_set, path_col = 'full_path', y_col = 'target_vector', target_size = image_size, color_mode = 'grayscale', batch_size = 32)\nvalid_gen = flow_from_dataframe(data_gen, test_set, path_col = 'full_path', y_col = 'target_vector', target_size = image_size, color_mode = 'grayscale', batch_size = 128)\n\n","6901cacd":"test_set","a1b668d4":"# define test sets\n# test_X, test_Y = next(flow_from_dataframe(data_gen, test_set, path_col = 'full_path', y_col = 'target_vector', target_size = image_size, color_mode = 'grayscale', batch_size = 128))\n\ntest_X, test_Y = flow_from_dataframe(data_gen, test_set, path_col = 'full_path', y_col = 'target_vector', target_size = image_size, color_mode = 'grayscale', batch_size = 128)","3af5ff74":"# Import relevant libraries\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\n\n# Create CNN model\n# Will use a combination of convolutional, max pooling, and dropout layers for this purpose\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 8, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = test_X.shape[1:]))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Dropout(0.2))\n          \nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Dropout(0.2))\n          \nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 3))\nmodel.add(Dropout(0.2))\n\n# add in fully connected dense layers to model, then output classifiction probabilities using a softmax activation function\nmodel.add(Flatten())\nmodel.add(Dense(500, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(len(dummy_labels), activation = 'softmax'))\n\n# compile model, run summary\n# https:\/\/www.kaggle.com\/adamjgoren\/nih-chest-x-ray-multi-classification\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","f8c93fd4":"# Explore the dataset a bit","b536c08f":"# Model"}}