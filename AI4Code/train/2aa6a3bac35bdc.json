{"cell_type":{"210e2d35":"code","4c36434a":"code","66e17f4e":"code","a1d40fe7":"code","23781959":"code","fb1ce89d":"code","33b33ab7":"code","8f7b6686":"code","e1c5a59d":"code","b578a9b1":"code","a79e15cd":"code","ebe3e5c0":"code","26460395":"code","6a027296":"code","463d3a1e":"code","facf7a1f":"code","316a1774":"code","c498c708":"code","2123f721":"code","a2c54b81":"code","23c93d58":"markdown","ceba9820":"markdown","8f0f6cb3":"markdown","36057567":"markdown","eb8ab4f7":"markdown","85dad6e2":"markdown","5051a1a6":"markdown","2734aa41":"markdown","fbdfe16c":"markdown","9b73df29":"markdown","f60a3114":"markdown"},"source":{"210e2d35":"import numpy as np \nimport pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Flatten, Dense, Dropout\n%matplotlib inline","4c36434a":"print(\"Importing Train Data\")\ntrain_data = pd.read_csv('..\/input\/train.csv')\nnum_labels = len(np.unique(train_data['label'].values))\ntrain_x = train_data[train_data.columns[1:]].values\ntrain_y = train_data['label'].values\ntr_ex, tr_pixels = train_x.shape\n\nsqrt_dim = int(np.sqrt(tr_pixels))\nchannel = 1 # Grayscale\n\nprint(\"Importing Test Data\")\ntest_data = pd.read_csv('..\/input\/test.csv')\ntest_x = test_data.values\nte_ex, te_pixels = test_x.shape\nassert tr_pixels == te_pixels","66e17f4e":"train_data.head(5)","a1d40fe7":"train_data.describe()","23781959":"sns.distplot(train_y, bins=num_labels, kde=False)\nplt.show()","fb1ce89d":"def plot_images(pixels, indexes, labels=None, image_size=(28, 28)):\n    \"\"\"Given a dataset, its labels (if they exist)\n    and the indexes to plot, plots the image(s).\"\"\"\n    \n    plots_num = len(indexes)\n    current_plot = 1\n    for idx in indexes:\n        image = pixels[idx].reshape(image_size)\n        ax = plt.subplot(1, plots_num, current_plot)\n        ax.imshow(image, cmap=plt.get_cmap('gray'))\n        label = -1 if labels is None else labels[idx]\n        ax.set_title(\"label:%i\" %label)\n        current_plot +=1\n    plt.show()\n","33b33ab7":"fig = plt.gcf()\nfig.set_size_inches(20, 20)\nplot_images(train_x, np.random.randint(0, train_x.shape[0], 15), train_y)","8f7b6686":"test_data.head(5)","e1c5a59d":"test_data.describe()","b578a9b1":"plt.gcf().set_size_inches(20, 20)\nplot_images(test_x, np.random.randint(0, test_x.shape[0], 15))","a79e15cd":"validation_split = 0.2\ntrain_datagen = ImageDataGenerator(\n    validation_split=0.2, \n    rescale=1.\/255,\n    rotation_range=40,\n    zoom_range=0.02,\n)\n\ntrain_batch_size = 150\nreshaped_train_x = train_x.reshape((tr_ex, sqrt_dim, sqrt_dim, channel))\n\ntrain_iterator= train_datagen.flow(\n    x=reshaped_train_x,\n    y=train_y,\n    batch_size=train_batch_size,\n    subset='training'\n)\n\nvalidation_iterator= train_datagen.flow(\n    x=reshaped_train_x,\n    y=train_y,\n    batch_size=train_batch_size,\n    subset='validation'\n)\n\n# Quick look at the some resulting images\nplt.gcf().set_size_inches(10, 10)\nfor x_batch, y_batch in train_iterator:\n    for i in range(0, 25):\n        plt.subplot(5, 5, i+1)\n        plt.imshow(x_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n    break\n\n","ebe3e5c0":"test_data_normalized = (test_x * 1.\/255).reshape((te_ex, sqrt_dim, sqrt_dim, channel))","26460395":"# Callback on validation accuracy\nclass AccuracyCallback(tf.keras.callbacks.Callback):\n    \"\"\"Callback that stops training on requested accuracy.\"\"\"\n    def __init__(self, target_accuracy=0.997):\n        self.target_accuracy = target_accuracy\n    def on_epoch_end(self, epoch, logs):\n        if logs.get('val_acc') >= self.target_accuracy:\n            print(\"Target validation accuracy (%f) reached !\" % self.target_accuracy )\n            self.model.stop_training = True","6a027296":"print(\"\\nSetting up the model\")\nmodel = tf.keras.models.Sequential([    \n    Conv2D(filters=32, kernel_size=5, padding='same', activation='relu', input_shape=(sqrt_dim, sqrt_dim, 1)),\n    BatchNormalization(),\n    MaxPool2D(2),\n    \n    Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'),\n    BatchNormalization(),\n    MaxPool2D(2),\n  \n    Conv2D(filters=90, kernel_size=5, padding='same', activation='relu'),\n    BatchNormalization(),\n    MaxPool2D(2),\n    \n    Flatten(),\n    Dense(units=1024, activation='relu'),\n    Dropout(0.35),\n    Dense(units=num_labels, activation='softmax'),\n])\nmodel.summary()\n\n","463d3a1e":"model.compile(\n    optimizer=tf.keras.optimizers.Adagrad(),\n    loss=tf.keras.losses.sparse_categorical_crossentropy,\n    metrics=['accuracy']\n) ","facf7a1f":"target_accuracy = 0.999\nmax_epochs = 40\nprint(\"\\nTraining untill accuracy reaches %s or for %i epochs\" %(target_accuracy, max_epochs))\nvalid_input_length = int(len(train_x)*validation_split)\ntrain_input_length = int(len(train_x)-valid_input_length)\nmodel.fit_generator(\n    generator=train_iterator,\n    steps_per_epoch= train_input_length \/\/ train_batch_size,\n    validation_data=validation_iterator,\n    validation_steps= valid_input_length \/\/ train_batch_size,\n    epochs=max_epochs, \n    callbacks=[AccuracyCallback(target_accuracy)]\n)","316a1774":"print(\"Predicting Test labels\")\npredictions = model.predict(test_data_normalized)","c498c708":"pred_df = test_data.copy()\npred_df['Label'] = np.argmax(predictions, axis=1)\npred_df['ImageId'] = pred_df.index +1\n","2123f721":"fig = plt.gcf()\nfig.set_size_inches(20, 20)\npred_x = pred_df[[p for p in pred_df.columns if 'pixel' in p]].values\npred_y = pred_df['Label'].values\nplot_images(pred_x, np.random.randint(0, pred_x.shape[0], 15), pred_y)","a2c54b81":"print(\"Saving Test labels\")\n#pred_df.to_csv('3by3Same70filters_paxpool2_twice_Dense150.csv', index=True)\nres = pred_df[['ImageId', 'Label']]\nres.to_csv('test3.csv', header=True, index=False)","23c93d58":"# Using ImageDataGenerator to augment the training and validation sets\n\nImageDataGenerator is a way to generate transformed images on the go. The final aim is to reduce the model over-fitting. \n\nFor data normalization, dividing by the max value is a quick and easy solution for normalisation because the minimum and maximum values are known and constant (comprised between 0 and 255).\nI chose a set of parameters for data augmentation that fits the MNIST dataset: randomly rotate no more than 40\u00b0 and the possibility to zoom or unzoom a little bit.","ceba9820":"For train data, we do not use a generator. We normalize the data using the same technique.","8f0f6cb3":"# Importing Train and Test Data","36057567":"#### Some images in the test set","eb8ab4f7":"# What's in the dataset ?\n\n## Train","85dad6e2":"#### Distribution of the labels in the training set","5051a1a6":"## Test","2734aa41":"#### Some images in the train set","fbdfe16c":"A simple convolutional neural network","9b73df29":"The classes to predict are balaced.","f60a3114":"# Training and choosing the right Model\n"}}