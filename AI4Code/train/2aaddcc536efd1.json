{"cell_type":{"1fe3aed3":"code","6cfcae27":"code","f01bce0d":"code","04372576":"code","08f0e17e":"code","7634bcf4":"code","23d80b2d":"code","ba991e2c":"code","ae76b92d":"code","a47c5f45":"code","fbff2e0c":"markdown","c80f562b":"markdown","a1d61d6a":"markdown","a4695855":"markdown","1b4850b3":"markdown","8f65251e":"markdown","d0a6f126":"markdown","f0473128":"markdown"},"source":{"1fe3aed3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6cfcae27":"!pip install tokenizers","f01bce0d":"!pip install transformers","04372576":"from __future__ import print_function\nimport ipywidgets as widgets\nfrom transformers import pipeline","08f0e17e":"import glob\ntxt_files = glob.glob(\"\/kaggle\/input\/toi-2018-news-articles\/data\/*.txt\")\n","7634bcf4":"txt_files[0:10]","23d80b2d":"from collections import defaultdict\ncount = len(txt_files)\ndata = defaultdict(list)\nfor i in txt_files:\n    date = i.split('\/')[-1].split('_')[0]\n    topic = '_'.join(i.split('\/')[-1].split('_')[1:-1])\n    headline = i.split('\/')[-1].split('_')[-1][0:-4]\n    \n    with open(i, 'rt') as fd:\n        data[date].append([topic,headline,fd.read().strip('[]')])\n    count-=1\n    if(count%10000==0):\n        print('{} files are left to be processed...'.format(count))\n","ba991e2c":"article = data['201824'][0][2]\nprint(article)","ae76b92d":"nlp_sentence_classif = pipeline('sentiment-analysis')\nnlp_sentence_classif(','.join(article))","a47c5f45":"nlp_qa = pipeline('question-answering')\nnlp_qa(context=article , question='What does the police think about the wherebaouts of the thieves ?')","fbff2e0c":"#  **In this Notebook we will do some Natural Language Processing tasks on the TOI_2018_News dataset using the Huggingface Transformers models**","c80f562b":"# HuggingFace Transformers models come with various 'pipelines' to do tasks like Sentiment Analysis, Summarization, Question Answering. Let's see how to do such tasks on one of the articles","a1d61d6a":"# 1.  Sentiment Analysis","a4695855":"This model was not fine-tuned on our data but still is able to perform well. We can further **'fine-tune' the model by performing Language modelling **over our dataset and then using the trained model to ask questions from our data but more on that later :)","1b4850b3":" # Let's take a random article from the dataset dated 2nd April 2018","8f65251e":"# As we can see the question answering system is performing really well and even though a lot of areas and cities are mentioned in the article, and the question asked is framed carefully so as not to match any keywords in the actual article, still the answer is very accurate. ","d0a6f126":"# Let's store our articles (.txt files) in a dictionary","f0473128":"# 2. Question-Answering"}}