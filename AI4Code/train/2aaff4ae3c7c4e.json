{"cell_type":{"56bfba7c":"code","1f992468":"code","770da09f":"code","59469dbe":"code","04125d1f":"code","60111629":"code","86696bc3":"code","fee572be":"code","d62b04bc":"code","f49fba1f":"code","7db9d9d5":"code","dd3d81e2":"code","c37c2c24":"code","f3389cb3":"code","d4a7a6eb":"code","d37b7bfa":"code","31ffe936":"code","59fe1ba6":"markdown","4be83e41":"markdown","7f6866a8":"markdown","17f27808":"markdown","65b0d3ce":"markdown","1ef00713":"markdown","a631ad25":"markdown","f5c45a55":"markdown","2212170f":"markdown","94306cd6":"markdown"},"source":{"56bfba7c":"import random\nimport os\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport category_encoders as ce\nfrom xgboost import XGBClassifier\nimport h2o\nfrom h2o.automl import H2OAutoML\n\n# set seed for reproducability\nrandom.seed(42)\n\ntraining_data = pd.read_csv(\"..\/input\/practical-model-evaluation-day-2\/train_data_2019.csv\")\ntesting_data = pd.read_csv(\"..\/input\/practical-model-evaluation-day-2\/test_data_2019.csv\")\n\n\n\n# save out copy of testing data to use w\/ GCP\nwith open(\"test_data_2019.csv\", \"+w\") as file:\n    testing_data.to_csv(file, index=False, na_rep='NA')\n\n# split into predictors & target variables\nX_training = training_data.drop('job_title', axis=1)\ny_training = training_data['job_title']\n\nX_testing = testing_data.drop('job_title', axis=1)\ny_testing = testing_data['job_title']\n\n# encoded copy of our training data for training TPOT model\nencoder_X = ce.OrdinalEncoder()\nX_encoded = encoder_X.fit_transform(X_training)\nX_testing_encoded = encoder_X.transform(X_testing)\n\nencoder_y = ce.OrdinalEncoder()\ny_encoded = encoder_y.fit_transform(y_training)","1f992468":"# load our saved XGBoost model\nxgboost_model = XGBClassifier()\nxgboost_model.load_model(\"..\/input\/practical-model-evaluation-day-2\/xgboost_baseline.model\")\nxgboost_model._le = LabelEncoder().fit(training_data[\"job_title\"])\n\n# initilaize H2o instance & load winning AutoML model\nh2o.init()\nh2o_model = h2o.load_model(\"..\/input\/practical-model-evaluation-day-2\/DeepLearning_grid_1_AutoML_20191206_142351_model_1\")\n\n# convert our data to h20Frame, an alternative to pandas datatables\n# (required for h20 AutoMl)\ntrain_data = h2o.H2OFrame(X_testing)\ntest_data = h2o.H2OFrame(list(y_testing))\ntest_data_h2o = train_data.cbind(test_data)\n\n# train new model using the pipeline generated by TPOT \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\n\ntraining_features, testing_features, training_target, testing_target = \\\n            train_test_split(X_encoded.values, y_encoded.values, random_state=None)\n\nexported_pipeline = GradientBoostingClassifier(learning_rate=0.1, max_depth=4, max_features=0.7500000000000001, min_samples_leaf=3, min_samples_split=2, n_estimators=100, subsample=0.45)\nexported_pipeline.fit(training_features, training_target)","770da09f":"%%time\n\ntpot_predictions = exported_pipeline.predict(X_testing_encoded)","59469dbe":"%%time\n\nxgb_predictions = xgboost_model.predict(X_testing_encoded)","04125d1f":"xgb_predictions","60111629":"%%time\n\nh20_predictions = h2o_model.predict(test_data_h2o)","86696bc3":"# TPOT Accuracy\ntpot_predictions_df = pd.DataFrame(data= {'job_title': tpot_predictions})\ntpot_predictions_unencoded = encoder_y.inverse_transform(tpot_predictions_df)\nprint(\"TPOT: \" + str(accuracy_score(y_testing, tpot_predictions_unencoded)))\n\n# H2O accuracy\nh20_predictions_df = h20_predictions.as_data_frame()\nprint(\"H2O: \" + str(accuracy_score(y_testing, h20_predictions_df.predict)))\n\n# XGBoost accuracy\nprint(\"XGBoost: \" + str(accuracy_score(y_testing, xgb_predictions)))\n","fee572be":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.multiclass import unique_labels\n\n# function based one from SciKitLearn documention (https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html)\n# and is modified and redistributed here under a BSD liscense, https:\/\/opensource.org\/licenses\/BSD-2-Clause\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Only use the labels that appear in the data\n    #classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    \n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n    return ax","d62b04bc":"plot_confusion_matrix(xgb_predictions, testing_data[\"job_title\"], \n                      classes=unique_labels(testing_data[\"job_title\"]),\n                      normalize=True,\n                      title='XGBoost Confusion Matrix')\n\nplot_confusion_matrix(tpot_predictions_unencoded, testing_data[\"job_title\"], \n                      classes=unique_labels(testing_data[\"job_title\"]),\n                      normalize=True,\n                      title='TPOT Confusion Matrix')\n\nplot_confusion_matrix(h20_predictions_df[\"predict\"], testing_data[\"job_title\"], \n                      classes=unique_labels(testing_data[\"job_title\"]),\n                      normalize=True,\n                      title='H2O AutoML Confusion Matrix')\n\n# plot_confusion_matrix(predicted_titles_cloud, cloud_predictions_df.job_title, \n#                       classes=unique_labels(cloud_predictions_df[\"job_title\"]),\n#                       normalize=True,\n#                       title='Cloud AutoML Confusion Matrix')","f49fba1f":"\n# set seed for reproducability\nrandom.seed(42)\n\ntraining_data = pd.read_csv(\"..\/input\/practical-model-evaluation-day-2\/train_data_2019.csv\")\ntesting_data = pd.read_csv(\"..\/input\/practical-model-evaluation-day-2\/test_data_2019.csv\")\n\n# modifying the column 'do_research_that_advances_the_state_of_the_art_of_machine_learning'\n#print(testing_data.columns)\ntesting_data['do_research_that_advances_the_state_of_the_art_of_machine_learning'] =  \"Do research that advances the state of the art of machine learning\"\n\n#print(testing_data['do_research_that_advances_the_state_of_the_art_of_machine_learning'].describe())\n\n# save out copy of testing data to use w\/ GCP\nwith open(\"test_data_2019.csv\", \"+w\") as file:\n    testing_data.to_csv(file, index=False, na_rep='NA')\n\n# split into predictors & target variables\nX_training = training_data.drop('job_title', axis=1)\ny_training = training_data['job_title']\n\nX_testing = testing_data.drop('job_title', axis=1)\ny_testing = testing_data['job_title']\n\n# encoded copy of our training data for training TPOT model\nencoder_X = ce.OrdinalEncoder()\nX_encoded = encoder_X.fit_transform(X_training)\nX_testing_encoded = encoder_X.transform(X_testing)\n\nencoder_y = ce.OrdinalEncoder()\ny_encoded = encoder_y.fit_transform(y_training)","7db9d9d5":"# load our saved XGBoost model\nxgboost_model = XGBClassifier()\nxgboost_model.load_model(\"..\/input\/practical-model-evaluation-day-2\/xgboost_baseline.model\")\nxgboost_model._le = LabelEncoder().fit(training_data[\"job_title\"])\n\n# initilaize H2o instance & load winning AutoML model\nh2o.init()\nh2o_model = h2o.load_model(\"..\/input\/practical-model-evaluation-day-2\/DeepLearning_grid_1_AutoML_20191206_142351_model_1\")\n\n# convert our data to h20Frame, an alternative to pandas datatables\n# (required for h20 AutoMl)\ntrain_data = h2o.H2OFrame(X_testing)\ntest_data = h2o.H2OFrame(list(y_testing))\ntest_data_h2o = train_data.cbind(test_data)\n\n# train new model using the pipeline generated by TPOT \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\n\ntraining_features, testing_features, training_target, testing_target = \\\n            train_test_split(X_encoded.values, y_encoded.values, random_state=None)\n\nexported_pipeline = GradientBoostingClassifier(learning_rate=0.1, max_depth=4, max_features=0.7500000000000001, min_samples_leaf=3, min_samples_split=2, n_estimators=100, subsample=0.45)\nexported_pipeline.fit(training_features, training_target)\n","dd3d81e2":"%%time\n\ntpot_predictions = exported_pipeline.predict(X_testing_encoded)","c37c2c24":"%%time\n\nxgb_predictions = xgboost_model.predict(X_testing_encoded)","f3389cb3":"xgb_predictions","d4a7a6eb":"%%time\n\nh20_predictions = h2o_model.predict(test_data_h2o)","d37b7bfa":"# TPOT Accuracy\ntpot_predictions_df = pd.DataFrame(data= {'job_title': tpot_predictions})\ntpot_predictions_unencoded = encoder_y.inverse_transform(tpot_predictions_df)\nprint(\"TPOT: \" + str(accuracy_score(y_testing, tpot_predictions_unencoded)))\n\n# H2O accuracy\nh20_predictions_df = h20_predictions.as_data_frame()\nprint(\"H2O: \" + str(accuracy_score(y_testing, h20_predictions_df.predict)))\n\n# XGBoost accuracy\nprint(\"XGBoost: \" + str(accuracy_score(y_testing, xgb_predictions)))\n","31ffe936":"plot_confusion_matrix(xgb_predictions, testing_data[\"job_title\"], \n                      classes=unique_labels(testing_data[\"job_title\"]),\n                      normalize=True,\n                      title='XGBoost Confusion Matrix')\n\nplot_confusion_matrix(tpot_predictions_unencoded, testing_data[\"job_title\"], \n                      classes=unique_labels(testing_data[\"job_title\"]),\n                      normalize=True,\n                      title='TPOT Confusion Matrix')\n\nplot_confusion_matrix(h20_predictions_df[\"predict\"], testing_data[\"job_title\"], \n                      classes=unique_labels(testing_data[\"job_title\"]),\n                      normalize=True,\n                      title='H2O AutoML Confusion Matrix')","59fe1ba6":"This notebook is for evaluating the models created in my precedent notebook that you can find here.\nhttps:\/\/www.kaggle.com\/amelnozieres\/practical-model-evaluation-day-2\/","4be83e41":"# Comparing metrics\n\nNow that we've got our predictions, let's compare the performance of these models in terms of metrics. For this example, I'm just going to look at raw accuracy: what proportion of job titles did each model assign correctly? (If we were looking at probabilities per class instead of predicted category we could use [log loss](https:\/\/www.kaggle.com\/dansbecker\/what-is-log-loss) instead, but let's just use accuracy here for simplicity.)\n","7f6866a8":"# Final Exercise!\n\nIf you were a data scientist working on this problem at a company, which model would you pick to put into production? You might want to consider:\n\n1. How long did they take to train?\n\n|   | Model        | Train time                   |\n|---|--------------|------------------------------------|\n| 1 | XGBoost      | 1min (using %%timeit)  |\n| 2 | TPOT         | 10min (using %%timeit) |\n| 3 | H2o AutoML   | 25min (using %%timeit)     |\n\n\n\n\n2. How long does it take them to do batch inference on the held out data?\n\n\n|   | Model        | inference time                   |\n|---|--------------|------------------------------------|\n| 1 | XGBoost      | 70.5ms (using %%timeit)  |\n| 2 | TPOT         | 56.3ms (using %%timeit) |\n| 3 | H2o AutoML   | 748 ms (using %%timeit)     |\n\n3. What's their overall accuracy? \nAfter adding the column for researchers \nTPOT 0.41\nH2O 0.42\nXgboost 0.11\n\n4. How well do they perform across cases?\n\nacross the cases or the classes? After modifying the researchers column the TPOT and H2O lost accuracy but there're doing better that our baseline\n\n5. How does their performance change if we change one of our input features?\nAfter modifying the researchers column the TPOT and H2O lost accuracy but there're doing better that our baseline\n\n6. Other factors not included here: what else do you think is important to consider?\n\n","17f27808":"Conculsion on the confusion matrix:\nWorking on it but here are my first conclusion:\n\nMy H2O model isn't predicting the class Business Analyst so this is bad. I need to look at it!\nTPOT and H2O are doing pretty well with the majority with classes compared to xgboost. xgboost is good only for the classes : 'Data scientist', 'Research Scientist' and 'Sorftware Engineer'.","65b0d3ce":"# Comparing time\n\nFirst we'll think about how much time each of these models took.\n\n## Training\/retraining time\n\nFor each of these four types of models, you'll probably have to retrain from scratch if you want to do something like add a new class. Here are the training times for each of the models we trained yesterday:\n\n|   | Model        | Time to Train                      |\n|---|--------------|------------------------------------|\n| 1 | XGBoost      | 10.2 s \u00b1 71.7 ms (using %%timeit)  |\n| 2 | TPOT         | 10 - 15 minutes (depending on run) |\n| 3 | H2o AutoML   | 36 minutes (HT Erin LeDell)     |\n         |\n\nSo, if what you really care about is training a model as fast a possible, the XGBoost baseline is probably your best bet. But what about inference time?\n\n## Inference time\n\nBut what about how quickly each model can be used to make predictions? To figure this out, I'm going to be using the `%%time` magic, which runs a cell and reports how long it took to run.","1ef00713":"# Load in our models\n\nNext we need to load in all our models that we trained yesterday.\nFor the TPOT model, we're training a new version of the winning pipeline.","a631ad25":"We're going to be evaluating our models using several different metrics: \n\n1. How long did they take to train?\n2. How long does it take them to do batch inference on the held out data?\n3. What's their overall accuracy? \n4. How well do they perform across cases?\n5. How does their performance change if we change one of our input features?\n\nLet's get coding! First, we'll need to load in all the libraries and data we'll need.","f5c45a55":"So, based on just inference time, it looks the TPOT model is the fastest of the three, followed by XGBoost,and then AutoML.","2212170f":"## Counterfactuals","94306cd6":"# Error analysis\n\nFor our error analysis, we're going to be using confusion matrices. The idea of a confusion matrix is that you have the actual labels on on axis, the predicted labels on the other axis and then the count or proportion of classifications in the matrix itself. They're mostly handy for quickly comparing performance across multiple classes, which is how we'll use them here.\n\nI've written a custom function, based on one\u00a0[from the SciKitLearn documentation](https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html), to plot confusion matrices for us and I'm going to use it to compare classifications from the four different models. (I've collapsed the code for this so we can focus on the matrices themselves."}}