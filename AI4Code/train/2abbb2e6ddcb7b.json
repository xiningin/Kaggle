{"cell_type":{"699f065e":"code","053d4a80":"code","e7ad02b9":"code","9a4269c8":"code","5b37f6dc":"code","2fc2195b":"code","666e21ff":"code","d333bd13":"code","40635025":"code","49d6c392":"code","b3b295f6":"code","a4b8f00f":"code","65b15bef":"code","98846ca6":"code","64e2bc15":"code","a343cf48":"code","11410193":"code","f7d5ad59":"code","1cf5b0ff":"code","314f8c98":"code","e861c094":"code","8c332884":"code","7deedb2e":"code","1bcc5a64":"markdown","fd49ea6c":"markdown","89745dce":"markdown","8d273c7c":"markdown","b38ddf79":"markdown","42a7439c":"markdown","7743f628":"markdown","cbeb09c4":"markdown","5b1033a3":"markdown","1f653a75":"markdown","cc7a434a":"markdown","15f61599":"markdown","03a078d3":"markdown","cb685a9e":"markdown","465a635d":"markdown","22175afb":"markdown","09f27877":"markdown"},"source":{"699f065e":"import numpy as np\nimport pandas as pd\nimport seaborn as sea\nimport random\nimport os\nimport glob\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Activation\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.layers import BatchNormalization, SpatialDropout2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec","053d4a80":"sea.set_style(\"darkgrid\")    ","e7ad02b9":"def get_file_paths(path):\n    p_folder = os.path.join(path, \"PNEUMONIA\")\n    p_file_paths = glob.glob(os.path.join(p_folder, \"*.jpeg\"))\n    n_folder = os.path.join(path, \"NORMAL\")\n    n_file_paths = glob.glob(os.path.join(n_folder, \"*.jpeg\"))    \n    return p_file_paths, n_file_paths","9a4269c8":"train_path = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\"\nval_path = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\"\ntest_path = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\"\n\ntrain_p_paths, train_n_paths = get_file_paths(train_path)\nval_p_paths, val_n_paths = get_file_paths(val_path)\ntest_p_paths, test_n_paths = get_file_paths(test_path)","5b37f6dc":"#input image resolution\nres = 256\ndef read_image(path):  \n    image = tf.io.read_file(path)\n    image = tf.io.decode_jpeg(image, channels=1)\n    image = tf.image.resize(image, [res,res], method=\"bicubic\")\n    image = tf.cast(image, tf.float32)    \n    return image\n\ndef plot_samples(paths, title):\n    fig = plt.figure(constrained_layout = True, figsize=(10, 9))\n    gs = gridspec.GridSpec(nrows=3, ncols=3, figure=fig)\n    for i in range(9):\n        y, x = i\/\/3, i%3 \n        ax = fig.add_subplot(gs[y,x])\n        file_name = os.path.basename(paths[i*10])\n        image = read_image(paths[i*10])       \n        ax.imshow(tf.cast(tf.squeeze(image), tf.uint8),\n                  cmap=\"gray\", aspect=\"auto\", vmin=0, vmax=255)\n        ax.axis(\"off\")\n        ax.title.set_text(file_name)\n    plt.suptitle(title, fontsize = 16, y=1.05)","2fc2195b":"plot_samples(train_p_paths, \"Positive Training Images\")\nplot_samples(train_n_paths, \"Negative Training Images\")","666e21ff":"train_p_count = len(train_p_paths)\ntrain_n_count = len(train_n_paths)\n\nprint(\"Number of negative training images: {}\".format(train_n_count))\nprint(\"Number of positive training images: {}\".format(train_p_count))\nprint(\"\\nNegative to Positive class ratio {:.1f}:{:.1f}\".\n      format((train_p_count+train_n_count)\/train_p_count,\n             (train_p_count+train_n_count)\/train_n_count))","d333bd13":"def apply_mat(image, transform_mat):\n    \n    # move origin to image midpoint\n    # get lists of rows and cols as list\n    rows = tf.range(-res\/2, res\/2)\n    cols = tf.range(-res\/2, res\/2)\n    \n    # compute cartesian product rows x cols\n    # tf.repeat repeats each tensor element\n    # tf.tile replicates whole tensor\n    # rows are repeated as the number of columns\n    coords = tf.stack([tf.repeat(rows, len(cols)), \n                       tf.tile(cols, [len(rows)])], axis=1)\n    \n    trn_coords = tf.transpose(tf.linalg.matmul(transform_mat,\n                                            tf.transpose(coords)))\n    \n    # add offsets to move origin to topleft\n    offset = tf.stack([tf.repeat(res\/2, len(trn_coords)), \n                       tf.repeat(res\/2, len(trn_coords))], axis=1)\n    \n    trn_coords = tf.math.add(trn_coords, offset)\n    trn_coords = tf.clip_by_value(trn_coords, 0, res-1)\n    \n    # get transformed pixels\n    trn_pixels = tf.gather_nd(image, tf.cast(trn_coords, tf.int32))    \n    trn_image = tf.reshape(trn_pixels, [res,res,1])\n    \n    return trn_image","40635025":"# transformation parameters\ntheta_low = -0.3\ntheta_high = 0.3\nhrz_shift = 40\nver_shift = 40\nsize_low = 0.8\nsize_high = 1.3\ncont_low = 0.7\ncont_high = 1.3\n\ndef random_rotate(image):\n    # tf.math.cos and tf.math.sin expect radian input\n    theta = tf.random.uniform([], minval=theta_low,\n                                  maxval=theta_high,\n                                  dtype=tf.float32)\n    # rotation matrix\n    transform_mat = tf.convert_to_tensor([[tf.math.cos(theta),\n                                          -tf.math.sin(theta)],\n                                          [tf.math.sin(theta),\n                                           tf.math.cos(theta)]])\n\n    return apply_mat(image, transform_mat)\n\ndef random_shift(image):\n    h1 = tf.random.uniform([], minval=0, maxval=hrz_shift, dtype=tf.int32)\n    h2 = tf.random.uniform([], minval=0, maxval=hrz_shift, dtype=tf.int32)    \n    w1 = tf.random.uniform([], minval=0, maxval=ver_shift, dtype=tf.int32)    \n    w2 = tf.random.uniform([], minval=0, maxval=ver_shift, dtype=tf.int32)\n    trn_image = tf.image.crop_to_bounding_box(image, h1, w1,\n                                              res-h1-h2, res-w1-w2)\n    trn_image = tf.image.resize(trn_image, size=[res, res],\n                                            method=\"bicubic\")  \n    return tf.reshape(trn_image, [res, res, 1])\n\ndef random_zoom(image):\n    size_factor = tf.random.uniform([], minval=size_low,\n                                        maxval=size_high,\n                                        dtype=tf.float32)\n    r_size = tf.cast(size_factor*res, tf.int32)\n    s_image = tf.image.resize(image, size=[r_size,r_size],\n                                          method=\"bicubic\")\n    trn_image = tf.image.resize_with_crop_or_pad(s_image, res, res)    \n    return tf.reshape(trn_image, [res, res, 1])\n\ndef random_contrast(image, max_val=1, min_val=-1):\n    cont_factor = tf.random.uniform([], minval=cont_low,\n                                        maxval=cont_high,\n                                        dtype=tf.float32)\n\n    trn_image = tf.image.adjust_contrast(image, cont_factor)  \n    trn_image = tf.minimum(trn_image, max_val)\n    trn_image = tf.maximum(trn_image, min_val)\n    return tf.reshape(trn_image, [res, res, 1])","49d6c392":"fig, axes = plt.subplots(constrained_layout = True,\n                         nrows=6, ncols=5, figsize=(10,14))\nindex = [99, 128, 150, 175, 200, 225]\n\nfor i in range(6):     \n    image = read_image(train_p_paths[index[i]])\n    \n    sample_results = []\n    sample_results.append(image)\n    sample_results.append(random_rotate(image))\n    sample_results.append(random_shift(image))\n    sample_results.append(random_zoom(image))\n    sample_results.append(random_contrast(image, 255, 0))\n    for s in range(5):\n        axes[i][s].imshow(tf.cast(tf.squeeze(sample_results[s]), tf.uint8),\n                  cmap=\"gray\", aspect=\"auto\", vmin=0, vmax=255)\n        axes[i][s].axis(\"off\")\n\naxes[0][0].title.set_text(\"Original\")\naxes[0][1].title.set_text(\"Random Rotation\")\naxes[0][2].title.set_text(\"Random Shift\")\naxes[0][3].title.set_text(\"Random Zoom\")\naxes[0][4].title.set_text(\"Random Contrast\")","b3b295f6":"def prepare(p_paths, n_paths):\n    data_p = np.array(p_paths)\n    data_n = np.array(n_paths)\n\n    # combine positive and negative paths\n    data_X = np.concatenate([data_p, data_n])\n\n    # create labels\n    data_Y = np.zeros(len(data_X), dtype=np.float32)\n    data_Y[:len(data_p)] = 1\n\n    # shuffle\n    for s in range(50):\n        data_X, data_Y = shuffle(data_X, data_Y)\n\n    return data_X, data_Y  ","a4b8f00f":"train_X, train_Y = prepare(train_p_paths, train_n_paths)\nval_X, val_Y = prepare(val_p_paths, val_n_paths)\ntest_X, test_Y = prepare(test_p_paths, test_n_paths)","65b15bef":"train_data = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\nval_data = tf.data.Dataset.from_tensor_slices((val_X, val_Y))\ntest_data = tf.data.Dataset.from_tensor_slices((test_X, test_Y))","98846ca6":"train_size = tf.data.experimental.cardinality(train_data).numpy()\nval_size = tf.data.experimental.cardinality(val_data).numpy()\ntest_size = tf.data.experimental.cardinality(test_data).numpy()\nprint(\"Training set size   : {}\".format(train_size))\nprint(\"Validation set size : {}\".format(val_size))\nprint(\"Test set size       : {}\".format(test_size))","64e2bc15":"def read_process(path, label):\n    image = read_image(path)\n    image = (image - 127.5) \/ 255.0\n    return image, label\n\ndef augment(image, label):    \n    functions = [random_rotate, random_shift, random_zoom, random_contrast]\n    trn_image = random.choice(functions)(image)      \n    return trn_image, label  ","a343cf48":"epoch = 120\nbatch_size = 64","11410193":"train_data = train_data.map(read_process,\n                num_parallel_calls = tf.data.experimental.AUTOTUNE)\ntrain_data = train_data.map(augment,\n                num_parallel_calls = tf.data.experimental.AUTOTUNE)\ntrain_data = train_data.repeat().shuffle(1024).batch(batch_size) \\\n                .prefetch(tf.data.experimental.AUTOTUNE)\n\nval_data = val_data.map(read_process,\n                num_parallel_calls = tf.data.experimental.AUTOTUNE)\nval_data = val_data.batch(batch_size) \\\n                .prefetch(tf.data.experimental.AUTOTUNE)\n\ntest_data = test_data.map(read_process,\n                num_parallel_calls = tf.data.experimental.AUTOTUNE)\ntest_data = test_data.batch(len(test_X))","f7d5ad59":"def create_model():   \n    sd = 0.3\n    inp_tensor = Input(shape=(res,res,1), name=\"input\")\n    \n    x = Conv2D(32,(3,3), padding=\"same\", name=\"conv2d_0\")(inp_tensor)\n    x = BatchNormalization(name=\"batchnorm_0\")(x)\n    x = Activation(\"relu\", name=\"act_0\")(x)\n    x = MaxPooling2D(pool_size=(2,2), name=\"maxpool2d_0\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(32,(3,3), padding=\"same\", name=\"conv2d_1\")(x)\n    x = BatchNormalization(name=\"batchnorm_1\")(x)\n    x = Activation(\"relu\", name=\"act_1\")(x)\n    x = MaxPooling2D(pool_size=(2,2), name=\"maxpool2d_1\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(64,(3,3), padding=\"same\", name=\"conv2d_20\")(x)\n    x = BatchNormalization(name=\"batchnorm_2\")(x)\n    x = Activation(\"relu\", name=\"act_2\")(x)\n    x = MaxPooling2D(pool_size=(2,2), name=\"maxpool2d_2\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(64,(3,3), padding=\"same\", name=\"conv2d_30\")(x)\n    x = BatchNormalization(name=\"batchnorm_3\")(x)\n    x = Activation(\"relu\", name=\"act_3\")(x)\n    x = MaxPooling2D(pool_size=(2,2), name=\"maxpool2d_3\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(128,(3,3), padding=\"same\", name=\"conv2d_40\")(x)\n    x = BatchNormalization(name=\"batchnorm_4\")(x)\n    x = Activation(\"relu\", name=\"act_4\")(x)\n    x = MaxPooling2D(pool_size=(2,2), name=\"maxpool2d_4\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(256,(3,3), padding=\"same\", name=\"conv2d_5\")(x)\n    x = BatchNormalization(name=\"batchnorm_5\")(x)\n    x = Activation(\"relu\", name=\"act_5\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(128,(1,1), padding=\"same\", name=\"conv2d_6\")(x)\n    x = BatchNormalization(name=\"batchnorm_6\")(x)\n    x = Activation(\"relu\", name=\"act_6\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(256,(3,3), padding=\"same\", name=\"conv2d_7\")(x)\n    x = BatchNormalization(name=\"batchnorm_7\")(x)\n    x = Activation(\"relu\", name=\"act_7\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(128,(1,1), padding=\"same\", name=\"conv2d_8\")(x)\n    x = BatchNormalization(name=\"batchnorm_8\")(x)\n    x = Activation(\"relu\", name=\"act_8\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(256,(3,3), padding=\"same\", name=\"conv2d_9\")(x)\n    x = BatchNormalization(name=\"batchnorm_9\")(x)\n    x = Activation(\"relu\", name=\"act_9\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(512,(3,3), padding=\"same\", name=\"conv2d_10\")(x)\n    x = BatchNormalization(name=\"batchnorm_10\")(x)\n    x = Activation(\"relu\", name=\"act_10\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(256,(1,1), padding=\"same\", name=\"conv2d_11\")(x)\n    x = BatchNormalization(name=\"batchnorm_11\")(x)\n    x = Activation(\"relu\", name=\"act_11\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = Conv2D(512,(3,3), padding=\"same\", name=\"conv2d_12\")(x)\n    x = BatchNormalization(name=\"batchnorm_12\")(x)\n    x = Activation(\"relu\", name=\"act_12\")(x)\n    x = SpatialDropout2D(sd)(x)\n    \n    x = GlobalAveragePooling2D(name=\"gap\")(x)\n    \n    x = Dense(128, name=\"d0\")(x)\n    x = BatchNormalization(name=\"batchnorm_d0\")(x)\n    x = Activation(\"relu\", name=\"act_d0\")(x)\n    x = Dropout(0.3, name=\"dropout_0\")(x)\n    \n    x = Dense(128, name=\"d1\")(x)\n    x = BatchNormalization(name=\"batchnorm_d1\")(x)\n    x = Activation(\"relu\", name=\"act_d1\")(x)\n    x = Dropout(0.3, name=\"dropout_1\")(x)\n \n    diagnose = Dense(1, activation=\"sigmoid\", name=\"proba\")(x)\n    \n    model = Model(inputs=inp_tensor, outputs=diagnose,\n                  name=\"Pneumonia_Detector\")\n    \n    model.summary()\n    \n    opt = tf.keras.optimizers.Adam()\n    loss_ent = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.2)     \n    model.compile(loss=loss_ent,\n                optimizer=opt,\n                metrics=[tf.keras.metrics.Precision(name=\"precision\"),\n                         tf.keras.metrics.Recall(name=\"recall\")])\n    \n    return model\n\nmodel = create_model()","1cf5b0ff":"tf.config.experimental.list_physical_devices(\"GPU\")","314f8c98":"def decay(input):    \n    initial_lr = 0.0003\n    lr = initial_lr * np.exp(-0.015*input)\n    return lr\n\nlrs = LearningRateScheduler(decay)\nplt.figure(figsize=(8,5))\nx = np.linspace(1,epoch + 1)\ny = [decay(i) for i in x]\nplt.plot(x,y);\nplt.ylabel(\"Learning Rate\")\nplt.xlabel(\"epoch\")\nplt.xticks(range(0,epoch+1,10));","e861c094":"step_per_epoch = train_size \/\/ batch_size\nclass_weights = {0:3.0, 1:1.0}\nhistory = model.fit(train_data, validation_data = val_data,\n                       steps_per_epoch = step_per_epoch,\n                       epochs = epoch,\n                       class_weight = class_weights,\n                       verbose = 1, callbacks=[lrs])","8c332884":"e = np.linspace(1, epoch + 1, epoch)\nfig, axes = plt.subplots(1, 1, figsize=(8,5))\nsea.lineplot(x = e, y = history.history[\"loss\"], ax=axes, label=\"train\");\nsea.lineplot(x = e, y = history.history[\"val_loss\"], ax=axes, label=\"val\");\naxes.set_ylabel(\"Loss\")\naxes.set_xlabel(\"epoch\")\nplt.xticks(range(0,epoch+1,10));","7deedb2e":"y_prob = model.predict(test_data);\ny_pred = [1 if x >= 0.5 else 0 for x in y_prob]\nprint(classification_report(test_Y, y_pred, digits = 2,\n                            target_names=[\"Not Pneumonia\", \"Pneumonia\"]))","1bcc5a64":"Training data is repeated, shuffled and divided into batches after augmentation. While one batch is in progress, next one is prefetched. Validation and test datasets are not repeated and not shuffled.","fd49ea6c":"## Create Data Pipelines","89745dce":"## Convolutional Neural Network Model Design\n\nBinary classifier is designed using **Functional API** of **Keras**. Single neuron at the last layer gives the probability of being from positive class. Dropout layers are used after convolutional and dense layers to prevent overfitting.","8d273c7c":"Plot of training and validation loss:","b38ddf79":"## Read Image Names From Folders\n\n**Pneumonia** and **normal** cases are **positive** and **negative** classes respectively. File paths for both are collected using glob.","42a7439c":"## Test\n\nModel is evaluated and classification report is printed.","7743f628":"## Image Transformation Functions\n\nTraining images are not aligned, some images are rotated, shifted and zoom levels are different. Also contrast levels of images are quite different. Four types of transformation functions are applied to training images for augmentation. These are **rotation**, **shift**, **zoom** and **contrast adjustment**.","cbeb09c4":"## Prepare Datasets\n\nPositive and negative class filepaths are concatenated and labels are created.","5b1033a3":"## Visualize Positive and Negative Training Images\n\nSome of the positive and negative class training images are shown below.","1f653a75":"Sizes of training, validation and test datasets:","cc7a434a":"Convolutional neural network classifier is designed to detect pneumonia on X-Ray images from **Chest X-Ray Images (Pneumonia)** dataset. There are train, val and test folders, each having pneumonia and normal subfolders. Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old.\n\nConvolutional Neural Network Model is designed from scratch and **TensorFlow tf.data API** is used to create data pipeline. Since number of training images is low, image augmentation is used in training. We take our images from folders, do necessary preprocessing, do image augmentation and feed data to our model via data pipeline.\n\nItems listed below are detailed in the following chapters:\n\n* How to create a pipeline using tf.data\n* How to create image transformation functions with TensorFlow\n* How to incorporate transformation functions for augmentation into tf.data pipeline\n* How to create and train a custom CNN image classifier from scratch\n\nOutline of the work is as follows:\n\n* Read Image Names From Folders\n* Visualize Positive and Negative Training Images\n* Image Transformation Functions\n* Visualize Transformations\n* Prepare Datasets\n* Create Data Pipelines\n* Convolutional Neural Network Model Design\n* Training and Validation\n* Test","15f61599":"And their counts are","03a078d3":"## Visualize Transformations\n\nSome training images and their randomly transformed versions are shown below. Note that for random shift, image is cropped from left, right, top or bottom randomly and resized instead of padding.","cb685a9e":"**tf.data API** is used to create datasets.","465a635d":"We define our custom learning rate decay function.","22175afb":"## Training","09f27877":"Class weights are incorporated into training to compensate for dataset imbalance. "}}