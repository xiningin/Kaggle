{"cell_type":{"c6f224d6":"code","dc60ddb0":"code","557253f9":"code","b64b3dde":"code","eafcfa64":"code","98ae4f45":"code","5915710c":"code","c53a6b83":"code","cc75ac64":"code","c83fe86b":"code","56ff2639":"code","5973a5d7":"code","e705c667":"code","8bc6d63a":"code","edb570a2":"markdown","83656f08":"markdown","99da8778":"markdown","9067ff9f":"markdown","9978b2a8":"markdown"},"source":{"c6f224d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc60ddb0":"df = pd.read_csv('\/kaggle\/input\/real-estate-dataset\/data.csv')","557253f9":"df.isnull().sum()","b64b3dde":"i1 = np.random.choice(a=df.index, size=40)\ni2 = np.random.choice(a=df.index, size=25)","eafcfa64":"df.loc[i1, 'INDUS'] = np.nan\ndf.loc[i2, 'TAX'] = np.nan","98ae4f45":"df.isnull().sum()","5915710c":"from sklearn.impute import KNNImputer\n\nimputer = KNNImputer(n_neighbors=3)\nimputed = imputer.fit_transform(df)\ndf_imputed = pd.DataFrame(imputed, columns=df.columns)","c53a6b83":"df_imputed","cc75ac64":"df_imputed.isnull().sum()","c83fe86b":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nrmse = lambda y, yhat: np.sqrt(mean_squared_error(y, yhat))","56ff2639":"def optimize_k(data, target):\n    errors = []\n    for k in range(1, 20, 2):\n        imputer = KNNImputer(n_neighbors=k)\n        imputed = imputer.fit_transform(data)\n        df_imputed = pd.DataFrame(imputed, columns=df.columns)\n        \n        X = df_imputed.drop(target, axis=1)\n        y = df_imputed[target]\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n        model = RandomForestRegressor()\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n        error = rmse(y_test, preds)\n        errors.append({'K': k, 'RMSE': error})\n        \n    return errors","5973a5d7":"k_errors = optimize_k(data=df, target='MEDV')\nk_errors","e705c667":"k_errors_df = pd.DataFrame(k_errors)\nk_errors_df","8bc6d63a":"import matplotlib.pyplot as plt\nplt.plot(k_errors_df['K'],k_errors_df['RMSE'])\nplt.show()","edb570a2":"Original dataset has no missing value but I try to create null values and I will show you how I handle the missing values with KNN imputation.","83656f08":"# KNN imputation","99da8778":"When K=17, we have the optimal value!","9067ff9f":"Thanks to [Reference](https:\/\/towardsdatascience.com\/missing-value-imputation-with-python-and-k-nearest-neighbors-308e7abd273d)","9978b2a8":"# Imputer optimization"}}