{"cell_type":{"2f5345c3":"code","0bf7378c":"code","d4ea3cb5":"code","37ca3355":"code","03f9b7f1":"code","3c9f4521":"code","77d48333":"code","69e48241":"code","79ee469e":"code","83940595":"code","f7b7b803":"code","7aee6f2b":"markdown","1baa0de9":"markdown","be93c7d7":"markdown","4309a05c":"markdown","7f4c2eab":"markdown","9d6bcb07":"markdown","7eb42b4e":"markdown","27f581dd":"markdown","15d172c8":"markdown","06e54bed":"markdown","c9ea4332":"markdown"},"source":{"2f5345c3":"!pip install scikit-learn-intelex -q --progress-bar off","0bf7378c":"import numpy as np\nimport time\nimport pandas as pd\nimport optuna\nfrom sklearn.pipeline import Pipeline\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","d4ea3cb5":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\n\ny_train = train['target']\nx_train = train.drop(['id','target'], axis=1)\nx_test = test.drop(['id'], axis=1)\n\nfrom sklearn.model_selection import train_test_split\nx_train_sub, x_val, y_train_sub, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\nprint(x_train_sub.shape, x_val.shape)","37ca3355":"def logreg_model(params, x_train, y_train, x_test):\n    from sklearn.preprocessing import QuantileTransformer\n    from sklearn.linear_model import LogisticRegression\n\n    params_quantile = {\n        'n_quantiles': params['n_quantiles'],\n        'random_state': 46,\n    }\n    params_logreg = {\n        'C': params['C'],\n    }\n    \n    pipe = Pipeline([\n        ('quantile', QuantileTransformer(**params_quantile)),\n        ('logreg',   LogisticRegression(**params_logreg))\n    ])\n    pipe.fit(x_train, y_train)\n    y_pred = pipe.predict_proba(x_test)\n    return y_pred\n\ndef objective(trial):\n    from sklearn.metrics import log_loss\n    \n    params = {\n        'n_quantiles': trial.suggest_int('n_quantiles', 3, 10),\n        'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n    }\n    \n    y_pred = logreg_model(params, x_train_sub, y_train_sub, x_val)\n    return log_loss(y_val, y_pred)","03f9b7f1":"from sklearnex import patch_sklearn\npatch_sklearn()","3c9f4521":"%%time\nt0 = time.time()\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())\nstudy.optimize(objective, n_trials=40, show_progress_bar=True)\nt1 = time.time()","77d48333":"print(f\"Time for search optimal params: {t1 - t0} sec\")\nprint(f\"Best Value: {study.best_trial.value}\")\nprint(f\"Best Params: {study.best_params}\")","69e48241":"from sklearnex import unpatch_sklearn\nunpatch_sklearn()","79ee469e":"%%time\nt0 = time.time()\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())\nstudy.optimize(objective, n_trials=40, show_progress_bar=True)\nt1 = time.time()","83940595":"print(f\"Time for search optimal params: {t1 - t0} sec\")\nprint(f\"Best Value: {study.best_trial.value}\")\nprint(f\"Best Params: {study.best_params}\")","f7b7b803":"patch_sklearn()\ny_pred = logreg_model(study.best_params, x_train, y_train, x_test)\nsample_submission[['Class_1','Class_2', 'Class_3', 'Class_4','Class_5','Class_6', 'Class_7', 'Class_8', 'Class_9']] = y_pred\nsample_submission.to_csv(f'logreg.csv', index=False)","7aee6f2b":"# \ud83d\udd28 Installing Intel(R) Extension for Scikit-learn\n\nLet's try to use Intel(R) Extension for Scikit-learn. First, download it. Package also avaialble in conda - please refer to details https:\/\/github.com\/intel\/scikit-learn-intelex","1baa0de9":"# \ud83c\udfaf Fit final model and submit result","be93c7d7":"# \ud83d\udcdc Conclusions\n\nWith Intel(R) Extension for Scikit-learn patching you can:\n\n- Use your scikit-learn code for training and inference without modification;\n- Train and predict scikit-learn models and get more time for experiments;\n- Get the same quality of predictions.\n\n*Please, upvote if you like.*","4309a05c":"# \ud83d\udccb Reading data and splitting on training and validation datasets","7f4c2eab":"# \u23f3 Logistic Regression Optuna Optimization with original Scikit-learn\n\nIn order to cancel Intel(R) Extension for Scikit-learn optimizations to run the original Scikit-learn, need to use *unpatch_sklearn*:","9d6bcb07":"<br>\n<h1 style = \"font-size:25px; font-family:cursive ; font-weight : bold; color : #020296; text-align: center; border-radius: 10px 15px;\"> \ud83d\ude80 Fast Logistic Regression with Intel(R) Extension for Scikit-learn  <\/h1>\n<br>\n\nFor classical machine learning algorithms, we often use the most popular Python library, Scikit-learn. We use it to fit models and search for optimal parameters, but\u202fscikit-learn\u202fsometimes works for hours, if not days. Speeding up this process is something anyone who uses Scikit-learn would be interested in.\n\nI want to show you how to get results faster without changing the code. To do this, we will use another Python library,\u202f**[Intel(R) Extension for Scikit-learn](https:\/\/github.com\/intel\/scikit-learn-intelex)**. It accelerates Scikit-learn and does not require you changing the code written for scikit-learn.\n\nI will show you how to speed up your kernel from **14 minutes to 2 minutes** without changes of code!","7eb42b4e":"Intel(R) Extension for Scikit-learn patching affects performance of specific Scikit-learn functionality. Refer to the [list of supported algorithms and parameters](https:\/\/intel.github.io\/scikit-learn-intelex\/algorithms.html) for details. In cases when unsupported parameters are used, the package fallbacks into original Scikit-learn.","27f581dd":"The search optimal parameters for Logistic Regression model for original Logistic Regression took **almost 14 minutes**. However, the same search using Intel(R) Extension for Scikit-learn took **a little over two minutes**. And most importantly, **the optimal model and quality on the validation dataset are equal**.","15d172c8":"# \ud83d\udd0d Defining model and parameters for search optimal model\n\nAs Intel(R) Extension for Scikit-learn have pretty fast Logistic Regression now - I can try running optune for with a sufficiently large search to find the optimal model. For prepocessing I use Quantile transformer and for it I will also select the most optimal number of quantiles.","06e54bed":"We can take advantage of the performance optimizations of Intel Extension for Scikit-learn by adding just two lines of code before the usual scikit-learn imports:","c9ea4332":"# \u26a1 Logistic Regression Optuna Optimization with Intel(R) Extension for Scikit-learn"}}