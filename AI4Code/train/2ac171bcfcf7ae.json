{"cell_type":{"a1b96994":"code","a21c1d85":"code","09c3be23":"code","27ed5654":"code","2d657f6b":"code","fc61f1ac":"code","28a30628":"code","2ad068bf":"code","f65e4336":"code","132ae3a8":"markdown","333e5b18":"markdown","e710e71f":"markdown","8ffa93f8":"markdown","984e9f42":"markdown","34f07f07":"markdown","93b97122":"markdown","ce21ac39":"markdown","5962eabd":"markdown"},"source":{"a1b96994":"# Imports for data manipulation and data vizualization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\n\nwarnings.filterwarnings('ignore')\nscaler = MinMaxScaler()\nimport os\nprint(os.listdir(\"..\/input\"))\n\nprint (\"Hello World\")\n\ntrain = pd.read_csv(\"..\/input\/train.csv\")\n","a21c1d85":"train.head(5)","09c3be23":"#Scaling the data\nimport gc \ntrainN = train.loc[:, train.dtypes == np.float64]\ntrainN['seat'] = train.seat\ntrainN['crew'] = train.crew\ntrainN[:] = scaler.fit_transform(trainN[:])\ntrainN['experiment'] = train['experiment'].map({'CA': -1, 'DA': 0,'SS':1})\n\n","27ed5654":"trainA = trainN[train.event=='A']\ntrainB = trainN[train.event=='B']\ntrainC = trainN[train.event=='C']\ntrainD = trainN[train.event=='D']\n\nfig = plt.figure(figsize=(65,65))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nplt.grid()\n\nfor row,i in zip(trainN,range(0,len(trainN.columns))):\n    \n    plt.subplot(len(trainN.columns)\/3, 4, i+1)\n    plt.hist(trainA[row],label='A',alpha=0.4)\n    plt.hist(trainB[row],label='B',alpha=0.4)\n    plt.hist(trainC[row],label='C',alpha=0.4)\n    plt.hist(trainD[row],label='D',alpha=0.4)\n    plt.xlabel(row,size=26)\n    plt.legend(fontsize=26)\n\n","2d657f6b":"fig = plt.figure(figsize=(55,25))\n#fig.subplots_adjust(hspace=0.4, wspace=0.4)\nplt.subplot(2, 2, 1)\ncorr = trainA.corr()\n\na = sns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\nplt.tick_params(axis='y', which='major', labelsize=26)\nplt.tick_params(axis='x', labelrotation = 90,which='major', labelsize=26)\n\nplt.subplot(2, 2, 2)\ncorr = trainB.corr()\nb = sns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\nplt.tick_params(axis='y', which='major', labelsize=26)\nplt.tick_params(axis='x', labelrotation = 90,which='major', labelsize=26)\nplt.subplot(2, 2, 3)\ncorr = trainC.corr()\nc = sns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\nplt.tick_params(axis='y', which='major', labelsize=26)\nplt.tick_params(axis='x', labelrotation = 90,which='major', labelsize=26)\nplt.subplot(2, 2, 4)\ncorr = trainD.corr()\nd = sns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\nplt.tick_params(axis='y', which='major', labelsize=26)\nplt.tick_params(axis='x', labelrotation = 90,which='major', labelsize=26)\n \n","fc61f1ac":"crews = np.unique(train.crew)\ngrCrews = []\nfor c in crews:\n    grCrews.append(trainN[train.crew==c])\nfig = plt.figure(figsize=(65,65))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nplt.grid()\nfor row,i in zip(trainN,range(0,len(trainN.columns))):\n    \n    plt.subplot(len(trainN.columns)\/3, 4, i+1)\n    for gr,l in zip(grCrews,np.unique(train.crew)):\n        plt.hist(gr[row].values,label=str(l),alpha=0.4)\n    plt.xlabel(row,size=26)\n    plt.legend(fontsize=26)\n","28a30628":"cov_mat = np.cov(trainN.values.T)\neigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n\ntot = sum(eigen_vals)\nvar_exp = [(i \/ tot) for i in sorted(eigen_vals, reverse=True)]\ncum_var_exp = np.cumsum(var_exp)\n\nplt.bar(range(1,len(trainN.columns)+1), var_exp, alpha=0.5, align='center',label='individual explained variance')\nplt.step(range(1,len(trainN.columns)+1), cum_var_exp, where='mid',label='cumulative explained variance')\n\nplt.ylabel('Explained variance ratio')\nplt.xlabel('Principal components')\nplt.legend(loc='best')\nplt.grid()\nplt.show()","2ad068bf":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nspace2D = pca.fit_transform(trainN.values)\nlabels = train.event.map({\"A\":0,\"B\":1,\"C\":2,\"D\":3}).values\nplt.scatter(space2D[:,0],space2D[:,1],c=labels)\nplt.grid()","f65e4336":"\n'''\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\ni = 0\neeg_features  = trainN.columns\nfor eeg in eeg_features:\n    i += 1\n    plt.subplot(len(test.columns)\/4+1, 4, i)\n    sns.distplot(train[eeg], label='Test set', hist=False)\n    sns.distplot(test[eeg], label='Train set', hist=False)\n    #plt.xlim((-500, 500))\n    plt.legend()\n    plt.xlabel(eeg, fontsize=12)\n\nplt.show()\n'''\n## No space left in disk","132ae3a8":"#### it seems like every crew have your on characteristics, special in the features more relevant, by variance, showed in the first histogram\n\n#### lets see now the most important features by variance found by PCA technique","333e5b18":"# Reducing Commercial Aviation Fatalities","e710e71f":"#### lets see now how every crew features are distributed ","8ffa93f8":"#### Let's see how features are distributed by class","984e9f42":"#### Now lets see if the data in test set seems like that train data , thereby, we can see if  the distribution in train data sounds equal to test data.","34f07f07":"### EDA for the competition Aviation Fatalities on Kaggle","93b97122":"#### In this plot we can see that some features represents more embracing values,in this way, we also can notice that a lot of represents values with low variance. As this plot was divided by classes, in this group of histograms we can observe that some features could be useless \n\n#### Now lets see how are the correlation of the features ","ce21ac39":"#### Looks like ok! In this way, we can conclude that cluster analysis could be a good solution for this problem","5962eabd":"#### only with 5\\4 features with explained more than 90% of the data!!!\n#### lets see how data looks like in 2D dimension"}}