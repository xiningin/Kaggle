{"cell_type":{"4c608491":"code","37a47691":"code","764fcabe":"code","a2d8a010":"code","a379fd51":"code","4f78f1b1":"code","dd7e516a":"code","ea85d195":"code","e22d6e79":"code","2d966f02":"code","612ed98a":"code","ea1382e6":"code","bd19324e":"code","37a83869":"code","79fff277":"code","2a50165a":"code","5d7c8fab":"code","eb48e1d8":"code","30d8bcb0":"code","745f512b":"code","eea84d67":"code","7ac0bb3e":"code","fcd71e07":"code","1e31921b":"code","c5c9de32":"code","ee2f9210":"code","25745b30":"code","a329e724":"code","1696ce0b":"code","0cd2e7e5":"code","15114a2c":"code","057c8d53":"code","c6ff77ef":"code","1208111c":"code","180c61b7":"code","5cf78536":"code","d4d1a7c6":"code","ad943bf3":"code","0ddd420e":"code","884ed37d":"code","af84774b":"code","5468cc4b":"code","df500c51":"code","3340dec2":"code","4df38e99":"code","1e3bf26b":"code","d2264094":"code","9d51241a":"code","ff28755e":"code","47fa64a6":"code","4a93fafa":"code","886733ca":"code","7e7fe6b1":"code","255a4c65":"code","f1a07dca":"code","5d3c1056":"code","f3715344":"code","ca1a7292":"code","b1c005b7":"code","be5f4728":"code","a26397a5":"code","0c9e0e19":"code","a92766dc":"code","1e2470ea":"code","b5f0df47":"code","b7b9e8c6":"code","5ef950a9":"code","41545ab2":"code","bed12f98":"code","7857b0a7":"code","e349957c":"code","9c4c316a":"code","f891af7e":"code","cb6e84d5":"code","052e39fd":"code","72a8f027":"code","6a442e51":"code","1c2e1e80":"code","da3d9ce7":"code","6daea4e6":"code","1ec62608":"code","2b77c7e0":"code","cbd624e8":"code","d27446c8":"code","87178eaa":"code","9c054f63":"code","0cf0ffde":"code","69a7ee48":"code","93a0385e":"code","3d732038":"code","536e6e56":"code","acbe8aca":"code","efcd0b1b":"code","b681e766":"code","cff1ffb8":"code","9e2f1cf7":"code","8919f17a":"code","c48bda3c":"code","35d38e33":"code","d03e41f4":"code","d4b3cc32":"code","9c29d881":"markdown","df0b53ef":"markdown","27899c77":"markdown","8ff1fca6":"markdown","3e48b568":"markdown","7db0ffab":"markdown","ca5cf556":"markdown","3089ab72":"markdown","e27202d3":"markdown","8ba9c9bb":"markdown","3233bc47":"markdown","f12c6271":"markdown","2ae4fa71":"markdown","c3b77151":"markdown","aa395430":"markdown","5ecfed1c":"markdown","770d3379":"markdown","8cf393e3":"markdown","a13b41a0":"markdown","29731bc0":"markdown","61f8c1a2":"markdown","0bd290af":"markdown","b6b5a7c1":"markdown","f249ec8b":"markdown","275f827e":"markdown","31d50f04":"markdown","717ac727":"markdown","8f7ac257":"markdown","02408ad1":"markdown","0378db28":"markdown","fb1a93ac":"markdown","e0935a21":"markdown","c99b94d6":"markdown","95f68e53":"markdown","534e2dd3":"markdown","54b4c08c":"markdown","f613896c":"markdown","67a7ad90":"markdown","e39bc374":"markdown","f94313e0":"markdown","3c00a724":"markdown","d60b2daf":"markdown","67736ba3":"markdown","0bb90971":"markdown","5cbffb57":"markdown","afc4631a":"markdown","bfea24c6":"markdown","2414c3a2":"markdown","dc37765f":"markdown","c95af918":"markdown","3c8f1220":"markdown","0a88bd22":"markdown","2ea113b4":"markdown","24ceb253":"markdown","6ef59648":"markdown","8343a964":"markdown","27596366":"markdown","2b4213b1":"markdown","78a80354":"markdown","fd81c353":"markdown","5c7695d0":"markdown","010637cd":"markdown","8bcf7944":"markdown","3ae397af":"markdown","ba616bd7":"markdown","78d74a99":"markdown","76016db3":"markdown","d3273ed7":"markdown","6c1d7784":"markdown","426a48f6":"markdown","9be5ab72":"markdown","c3eed3c9":"markdown","0ab4e938":"markdown"},"source":{"4c608491":"import pandas as pd\ndf=pd.read_csv('..\/input\/titanic\/train.csv')\ndf1=pd.read_csv('..\/input\/titanic\/test.csv')\n\ndf","37a47691":"df1","764fcabe":"df.isnull().sum()","a2d8a010":"df1.isnull().sum()","a379fd51":"for n in df['Name']:\n  if n[-5:] == 'James':\n    print(n)","4f78f1b1":"for n in df1['Name']:\n  if n[-5:] == 'James':\n    print(n)","dd7e516a":"first_name=pd.DataFrame()\nlast_name=pd.DataFrame()\n\nfor a in df['Name']:\n  b,c = a.split(',')\n  first_name=first_name.append([b])\n  last_name=last_name.append([c])","ea85d195":"first_name","e22d6e79":"last_name","2d966f02":"first_name1=pd.DataFrame()\nlast_name1=pd.DataFrame()\n\nfor a in df1['Name']:\n  b,c = a.split(',')\n  first_name1=first_name1.append([b])\n  last_name1=last_name1.append([c])","612ed98a":"first_name1","ea1382e6":"last_name1","bd19324e":"for aa in first_name1[0].unique():\n  if (aa in first_name[0].unique()) == True:\n    print(aa)","37a83869":"for aa in first_name1[0].unique():\n  if (aa in first_name[0].unique()) == False:\n    print(aa)","79fff277":"for aa in last_name1[0].unique():\n  if (aa in last_name[0].unique()) == True:\n    print(aa)","2a50165a":"for aa in last_name1[0].unique():\n  if (aa in last_name[0].unique()) == False:\n    print(aa)","5d7c8fab":"last=pd.DataFrame()\nname=pd.DataFrame()\n\nlast1=pd.DataFrame()\nname1=pd.DataFrame()\n\nfor i in last_name[0]:\n  l,n = i.split('.',maxsplit=1)\n  last=last.append([l])\n  name=name.append([n])\n\nfor i in last_name1[0]:\n  l,n = i.split('.',maxsplit=1)\n  last1=last1.append([l])\n  name1=name1.append([n])","eb48e1d8":"for aa in last1[0].unique():\n  if (aa in last[0].unique()) == True:\n    print(aa)","30d8bcb0":"for aa in last1[0].unique():\n  if (aa in last[0].unique()) == False:\n    print(aa)","745f512b":"last[0].unique()","eea84d67":"last1[0].unique()","7ac0bb3e":"last=last.reset_index().drop(['index'],axis=1)\nlast.columns=['reference']\n\nlast1=last1.reset_index().drop(['index'],axis=1)\nlast1.columns=['reference']","fcd71e07":"df['Name'] = last['reference']\ndf","1e31921b":"df1['Name'] = last1['reference']\ndf1","c5c9de32":"train_y=df['Survived']\ndf=df.drop(['Survived'],axis=1)\ndf","ee2f9210":"train_test=pd.concat([df,df1],axis=0)\ntrain_test","25745b30":"train_test.isnull().sum()","a329e724":"train_test['Ticket'].unique()","1696ce0b":"ticket_number=pd.DataFrame()\nticket_name = pd.DataFrame()\nfor i in train_test['Ticket']:\n  a = i.split(' ',maxsplit=-1)\n  if len(a) == 1:\n    ticket_number=ticket_number.append([a[-1]])\n    ticket_name=ticket_name.append([0])\n  else:\n    ticket_number=ticket_number.append([a[-1]])\n    ticket_name=ticket_name.append([1])","0cd2e7e5":"ticket_number","15114a2c":"ticket_number[0]=ticket_number.replace('LINE', 0)\nticket_number","057c8d53":"ticket_name","c6ff77ef":"ticket_number=ticket_number.reset_index().drop(['index'],axis=1)\nticket_name=ticket_name.reset_index().drop(['index'],axis=1)","1208111c":"ticket_number","180c61b7":"ticket_name","5cf78536":"train_test","d4d1a7c6":"train_test=train_test.reset_index().drop(['index'],axis=1)","ad943bf3":"train_test['Ticket']=ticket_name\ntrain_test['Ticket_number']=ticket_number\ntrain_test","0ddd420e":"import seaborn as sns\nsns.countplot(last['reference'])","884ed37d":"sns.countplot(last1['reference'])","af84774b":"train_test['Name'].value_counts()","5468cc4b":"train_test['Name']=train_test['Name'].replace(' Mr', 1)\ntrain_test['Name']=train_test['Name'].replace(' Mrs', 2)\ntrain_test['Name']=train_test['Name'].replace(' Miss', 3)\ntrain_test['Name']=train_test['Name'].replace(' Master', 4)\ntrain_test['Name']=train_test['Name'].replace(' Ms', 0)\ntrain_test['Name']=train_test['Name'].replace(' Col', 0)\ntrain_test['Name']=train_test['Name'].replace(' Rev', 0)\ntrain_test['Name']=train_test['Name'].replace(' Dr', 0)\ntrain_test['Name']=train_test['Name'].replace(' Dona', 0)\ntrain_test['Name']=train_test['Name'].replace(' Mlle', 0)\ntrain_test['Name']=train_test['Name'].replace(' Major', 0)\ntrain_test['Name']=train_test['Name'].replace(' Lady', 0)\ntrain_test['Name']=train_test['Name'].replace(' Don', 0)\ntrain_test['Name']=train_test['Name'].replace(' Mme', 0)\ntrain_test['Name']=train_test['Name'].replace(' the Countess', 0)\ntrain_test['Name']=train_test['Name'].replace(' Capt', 0)\ntrain_test['Name']=train_test['Name'].replace(' Sir', 0)\ntrain_test['Name']=train_test['Name'].replace(' Jonkheer', 0)","df500c51":"sns.countplot(train_test['Name'])","3340dec2":"train_test","4df38e99":"sns.countplot(train_test['Sex'])","1e3bf26b":"train_test['Sex']=train_test['Sex'].replace('male', 0)\ntrain_test['Sex']=train_test['Sex'].replace('female', 1)\ntrain_test","d2264094":"train_test['Cabin'].value_counts()","9d51241a":"train_test[train_test['Cabin'] == train_test['Cabin'].value_counts().index[0]]","ff28755e":"train_test[train_test['Cabin'] == train_test['Cabin'].value_counts().index[1]]","47fa64a6":"train_test[train_test['Cabin'] == train_test['Cabin'].value_counts().index[2]]","4a93fafa":"train_test=train_test.reset_index().drop(['index'],axis=1)\ntrain_test","886733ca":"import numpy as np\ntrain_test[train_test['Embarked'].isnull() == True]","7e7fe6b1":"train_test['Embarked'].unique()","255a4c65":"train_test['Embarked']=train_test['Embarked'].replace('S',0)\ntrain_test['Embarked']=train_test['Embarked'].replace('C',1)\ntrain_test['Embarked']=train_test['Embarked'].replace('Q',2)\ntrain_test","f1a07dca":"imputation_x=train_test[['Pclass','Name','Sex','SibSp','Parch','Ticket','Embarked','Ticket_number']]\nimputation_x","5d3c1056":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscale_imputation_x=pd.DataFrame(scaler.fit_transform(imputation_x.drop(['Embarked'],axis=1)))\nscale_imputation_x.columns=imputation_x.drop(['Embarked'],axis=1).columns\nscale_imputation_x","f3715344":"k=3\n\nfrom sklearn.cluster import KMeans\n\nkmeans=KMeans(n_clusters=k,algorithm='full')\nkmean_result=kmeans.fit_transform(scale_imputation_x)\nkmean_result","ca1a7292":"idx_61=np.argmin(kmean_result[61])\nidx_829=np.argmin(kmean_result[829])","b1c005b7":"print(idx_61)\nprint(idx_829)","be5f4728":"pd.DataFrame(np.argmin(kmean_result,axis=1))[pd.DataFrame(np.argmin(kmean_result,axis=1))[0] == 0].index","a26397a5":"sns.countplot(train_test['Embarked'].iloc[pd.DataFrame(np.argmin(kmean_result,axis=1))[pd.DataFrame(np.argmin(kmean_result,axis=1))[0] == 0].index])","0c9e0e19":"train_test['Embarked']=train_test['Embarked'].fillna(0)\ntrain_test.isnull().sum()","a92766dc":"train_test['Age']","1e2470ea":"from sklearn.linear_model import LinearRegression\n\nage_x = train_test[['Pclass','Name','Sex','SibSp','Parch','Ticket','Embarked','Ticket_number']]\n\nage_y = pd.DataFrame(train_test['Age'])\n\nage_train_y = age_y[age_y['Age'].isnull()==False]\nage_test_y = age_y[age_y['Age'].isnull()==True]\nage_test_x = age_x.iloc[age_test_y.index]\nage_train_x = age_x.iloc[age_train_y.index]\nage_model=LinearRegression()\nage_model.fit(age_train_x, age_train_y)","b5f0df47":"from sklearn.metrics import r2_score\nr2_score(age_train_y, age_model.predict(age_train_x))","b7b9e8c6":"train_test","5ef950a9":"sns.distplot(train_test['Age'])","41545ab2":"print(train_test['Age'].min())\nprint(train_test['Age'].max())","bed12f98":"age=pd.DataFrame()\n\nfor i in train_test['Age']:\n  i = str(i)[0]\n  age=age.append([i])\nage","7857b0a7":"age=age.reset_index().drop(['index'],axis=1)\nage.columns=['Age']\nage","e349957c":"age=age.replace('n',np.NaN)\nage_x = train_test[['Pclass','Name','Sex','SibSp','Parch','Ticket','Embarked','Ticket_number']]\nscaler=StandardScaler()\nage_xx=pd.DataFrame(scaler.fit_transform(age_x))\nage_xx.columns=age_x.columns\n\n\n\nage_y = pd.DataFrame(age['Age'])\n\nage_train_y = age_y[age_y['Age'].isnull()==False]\nage_test_y = age_y[age_y['Age'].isnull()==True]\nage_test_x = age_xx.iloc[age_test_y.index]\nage_train_x = age_xx.iloc[age_train_y.index]","9c4c316a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nmodel = LogisticRegression()\nmodel.fit(age_train_x, age_train_y)\naccuracy_score(age_train_y, model.predict(age_train_x))","f891af7e":"train_test['Age']=age['Age']\ntrain_test['Age']=train_test['Age'].fillna(-1)\ntrain_test","cb6e84d5":"sns.distplot(train_test['Fare'])","052e39fd":"train_test[train_test['Fare'].isnull()==True]","72a8f027":"train_test[train_test['Ticket_number'] == '3701']","6a442e51":"fare_imputation=train_test[(train_test['Pclass'] == 3) & (train_test['Embarked'] == 0)]['Fare'].mean()\nfare_imputation","1c2e1e80":"train_test['Fare']=train_test['Fare'].fillna(fare_imputation)","da3d9ce7":"train_test['Ticket_number']","6daea4e6":"train_test[train_test['Ticket_number'] == '21171']","1ec62608":"train_test[train_test['Ticket_number'] == '17599']","2b77c7e0":"train_test[train_test['Ticket_number'] == '3101282']","cbd624e8":"train_test[train_test['Ticket_number'] == '113803']","d27446c8":"train_test[train_test['Cabin'].isnull()== True]['Ticket_number']","87178eaa":"for i in pd.DataFrame(train_test.groupby(by=['Ticket','Ticket_number']))[1]:\n  print(i)","9c054f63":"train_test","0cf0ffde":"for i in train_test['Cabin']:\n  i = str(i).split(' ')\n  print(i)","69a7ee48":"cabin=pd.DataFrame()\ntrain_test['Cabin']=train_test['Cabin'].fillna(-1)\nfor i in train_test['Cabin']:\n  if i != -1:\n    i = str(i).split(' ')\n    cabin=cabin.append([i[0][0]])\n  else:\n    cabin=cabin.append([i])\ncabin","93a0385e":"cabin.value_counts()","3d732038":"cabin=cabin.replace('C', 0)\ncabin=cabin.replace('B', 1)\ncabin=cabin.replace('D', 2)\ncabin=cabin.replace('E', 3)\ncabin=cabin.replace('A', 4)\ncabin=cabin.replace('F', 5)\ncabin=cabin.replace('G', 6)\ncabin=cabin.replace('T', 7)\ncabin","536e6e56":"cabin.value_counts()","acbe8aca":"cabin=cabin.reset_index().drop(['index'],axis=1)\ncabin.columns=['Cabin']\ncabin","efcd0b1b":"train_test['Cabin'] = cabin['Cabin']\ntrain_test","b681e766":"train_test.isnull().sum()","cff1ffb8":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\n\nscale_data = pd.DataFrame(scaler.fit_transform(train_test.drop(['PassengerId'],axis=1)))\nscale_data.columns=[train_test.drop(['PassengerId'],axis=1).columns]\ntrain_data=scale_data.iloc[:891]\ntest_data=scale_data.iloc[891:]","9e2f1cf7":"train_data","8919f17a":"test_data","c48bda3c":"from sklearn.model_selection import train_test_split\n\ntrain_x, val_x, train_yy ,val_yy = train_test_split(train_data, train_y, test_size=0.2,random_state=2016251029)\n\ntrain_x=train_x.reset_index().drop(['index'],axis=1)\nval_x=val_x.reset_index().drop(['index'],axis=1)\ntest_data=test_data.reset_index().drop(['index'],axis=1)\n\ntrain_yy=pd.DataFrame(train_yy).reset_index().drop(['index'],axis=1)\nval_yy=pd.DataFrame(val_yy).reset_index().drop(['index'],axis=1)","35d38e33":"train_x","d03e41f4":"val_x","d4b3cc32":"train_x.to_csv('.\/train_x.csv', index=False, encoding='utf-8-sig')\nval_x.to_csv('.\/val_x.csv', index=False, encoding='utf-8-sig')\n\ntrain_yy.to_csv('.\/train_y.csv', index=False, encoding='utf-8-sig')\nval_yy.to_csv('.\/val_y.csv', index=False, encoding='utf-8-sig')\n\ntest_data.to_csv('.\/test_x.csv', index=False, encoding='utf-8-sig')\n","9c29d881":"## Ticket_number and ticket_name reindexing","df0b53ef":"## Both two null values are 0 group.\n\nThen, search what values are. in 0 group.","27899c77":"## Find the clue and relationship from Cabin.","8ff1fca6":"## Dona is in test but, not in train.","3e48b568":"## Train, test dataset reindexing before concatenating pre-processed ticket data into train_test dataset.","7db0ffab":"## Logistic regression doesn't work well, either.\n\nSo, we won't imputate the null values and just keep going.\n\nThat is, non value is just non value and this is a part of data.\n\nThus, we will convert null values into -1 which is not shown in Age.\n\n-1 means this value is non value.\n","ca5cf556":"## Find the rule of dataset, what is the clue in name?\n\n> I think there are many James.....\n\nHow can I handle this column to make tidy dataset?","3089ab72":"## Find whether a reference in test data is in train or not.\n\nMr, Mrs, Miss, Master, Ms, Col, Rev, and Dr are in train and test.","e27202d3":"## Embarked is split with 3 groups (S, C, and O) so, we determine the number of clusters is 3.","8ba9c9bb":"## However, many cases show that we couldn't find any clues about null values of Cabin. Accordingly, we will replace the null values to -1.\n\n-1 means that the value is null value of Cabin.\n","3233bc47":"Sex count plot","f12c6271":"## But it doesn't work well. because age is discrete value.","2ae4fa71":"## Test dataset contains the non values in Age, Cabin, and Fare, not Embarked.","c3b77151":"## Identify the distribution from count plot\n\n> train dataset","aa395430":"## Now, It is end of pre-processing.","5ecfed1c":"# Load pandas to handle the dataset","770d3379":"## By grouping the ticket, ticket number values, we try to find the clues for null values for Cabin.","8cf393e3":"## Anyway, insert our name data into train, test dataset respectively.","a13b41a0":"## Convert the values into 0, 1, 2....","29731bc0":"## In train dataset, there are many references compared with test dataset.","61f8c1a2":"## Find the cluster of null index.","0bd290af":"## Find the clue from same ticket number.","b6b5a7c1":"## Name data pre-processing\n\nWe will convert name value such as 'Mr','Miss', ... into 1,2,3... as in:**\uad75\uc740 \ud14d\uc2a4\ud2b8**","f249ec8b":"## Fare imputation","275f827e":"## Make a dataset for imputation.","31d50f04":"## Insert the pre-processed cabin data into train_test dataset.","717ac727":"## Find the relationships between train dataset names and test's one.\n\nWhethere the name (first and last) in test dataset is in train dataset or not?\n\n> first_name1 - first name from test dataset\n\n> first_name = first name from train dataset\n\n> last_name1 = last name from test dataset\n\n> last_name = last name from train dataset","8f7ac257":"## Total null value?","02408ad1":"In this case, null value is alone. So, we will replace the null value of Fare to the average of Pclass and Ebarked.","0378db28":"## We will covert male into 0 and female into 1","fb1a93ac":"## Pre-processing Name values","e0935a21":"## Countplot of Name","c99b94d6":"## First, split the names into fist name, last name.","95f68e53":"## We will estimate the null values of Embarked by cluster analysis.","534e2dd3":"## Cabin pre-processing.\n\nCabin has high probability that is related to Ticket.","54b4c08c":"## Train dataset contains some non values in Age, Cabin, and Embarked columns.","f613896c":"## The case of Cabin value.\n\n> A passenger has a couple of seats\n\n> Unknown seat type\n\n> Unknown seat number\n\nHence, if we don't know the value, we will replace as -1, otherwise, we will take only the initial of seat as below:","67a7ad90":"## Use the fillna method to imputate the null value.","e39bc374":"## From now on, we will concatenate train without target value and test dataset. \nBecause data pre-processing will be applied to both train and test at the same time.","f94313e0":"## Spliting train and test.","3c00a724":"> test dataset","d60b2daf":"## Age distribution","67736ba3":"## The optimal cluster is 3.","0bb90971":"Let's count the values of Cabin.","5cbffb57":"## Take the initial character or -1.","afc4631a":"## We'll devide the ticket value into ticket number and ticket name.\n\nIf ticket name has 1 value, the ticket was combined with stirng and numbering.\n\nOtherwise, if ticket name is 0 value, the ticket was only numeric ticket.","bfea24c6":"## So, we will imputate the null values by deviding the age values into group age.\n\nAnd we try to estimate the null values using with logistic regression ( with softmax).","2414c3a2":"## See the value count","dc37765f":"## Cabin has many information and plenty of clues.\n\nIf cabin is same each other, the passengers might be a family or couple.\n\nSo, we could find the clues about the null value.","c95af918":"## Apply to test dataset with same method","3c8f1220":"## Estimate the null values of Age with logistic regression","0a88bd22":"## check the test dataset","2ea113b4":"## PassengerId 892 is the start point to test dataset.\n","24ceb253":"## There are only a few values except for 'Mr', 'Miss',' Mrs', and 'Master'.\n\nSo, we will convert these four values (Mr, Miss, Mrs, and Master) into numeric and the others will be clustered in one group.","6ef59648":"## Age pre-processing","8343a964":"## Same kinds of ticket mean same fare, cabin, and embarked.\n","27596366":"## Min-Max scaling the values before clustering.","2b4213b1":"## Now, you are ready to build your model to predict the survival.","78a80354":"## Split train and validation from train dataset.","fd81c353":"## Concatenating the pre-processed ticket data into train_test dataset.","5c7695d0":"## It is better to use their references.\n\nIn the name data, there are many last names so it will be hard to find the clue.\n\nHowever, the references such as Mr., Miss., and so on are easy to find.\n\nSo, we are going to capture and convert these references into numeric.","010637cd":"## We try to imputate the null value of Age with linear regression.","8bcf7944":"## We will handle the data with Min-Max scaling and devide the dataset into train, validation, test dataet.\n\nAnd, we will rid of PassengerID because it is unnecessary.","3ae397af":"## Fare pre-processing","ba616bd7":"## Converting the Embarked values into numeric.","78d74a99":"## Next, we've got data pre-preocessing in Ticket column","76016db3":"## Most values of this group represent the 0 values, that is, S.\n\nSo, we convet non value into 0.","d3273ed7":"## The min, max values","6c1d7784":"## Sex pre-processing","426a48f6":"## Cabin pre-processing","9be5ab72":"Fare distribution","c3eed3c9":"## LINE, the value in ticket column, must be coverted another value like 0 which represents only LINE as 0.\n\nSo, we can write the code as in:","0ab4e938":"## check the train dataset"}}