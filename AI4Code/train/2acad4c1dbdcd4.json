{"cell_type":{"01e76c2f":"code","9ef312fa":"code","d558379a":"code","db2d57c7":"code","715a38ce":"code","ff312736":"code","4bd0259a":"code","c408e183":"code","44955257":"code","0d7af525":"code","ab6340ef":"code","a26e7a23":"code","2b97932e":"code","5a25c4cd":"code","bb712ae5":"code","b72659bd":"code","8b9ad6c1":"code","045b9893":"code","8830cafd":"code","ee89e94b":"code","d45f4fac":"code","f6cd3f76":"code","d945fe92":"code","b8affbc8":"code","b0a7af25":"markdown","33f71414":"markdown","e0125c37":"markdown","a39d78c6":"markdown","63837480":"markdown","c1800da4":"markdown","c846875d":"markdown","e318d549":"markdown","59df035d":"markdown","08cb298f":"markdown","4152ecb0":"markdown","5553d6ba":"markdown","0166a6a0":"markdown","e6b315ec":"markdown","86a49687":"markdown","ade1a89b":"markdown","2b9a2c72":"markdown","28cb2405":"markdown","0e5a6b78":"markdown","221c9a4e":"markdown","0e700fd6":"markdown","29b7dd90":"markdown","482ea233":"markdown","eba100af":"markdown","1864651c":"markdown","bb9b4f11":"markdown","6e4f16e9":"markdown","a09c47e4":"markdown","d3f3221d":"markdown","554a8d27":"markdown"},"source":{"01e76c2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9ef312fa":"#pip install yfinance --upgrade --no-cache-dir","d558379a":"#Loading libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression","db2d57c7":"gold = pd.read_csv(\"..\/input\/gold-and-shares-gold\/gold.csv\")\ngold['Date'] = pd.to_datetime(gold['Date'])","715a38ce":"gold.columns = [\"Date\",\"gold_price\"]","ff312736":"gold[\"gold_price\"] = gold[\"gold_price\"].shift(1)","4bd0259a":"shares=[\"NMM.SG\",\"GOLD\",\"AU\",\"KGC\",\"NCM.AX\",\"PLZL.ME\",\"POLY.ME\",\"SELG.ME\"]\ndata = pd.read_csv(\"..\/input\/gold-and-shares-gold\/shares.csv\")\ndata['Date'] = pd.to_datetime(data['Date'])","c408e183":"#creating an array that will store all the data\nall_data=pd.DataFrame()","44955257":"#creating an array with quotes\nfor index in range(len(shares)):\n    stock=pd.DataFrame()\n    # transform the data\n    stock=data.loc[:, (\"Date\",shares[index])]\n    stock[\"Date\"]=stock[\"Date\"].astype('datetime64[ns]')\n    stock.columns=[\"Date\",\"share_price\"]\n    test=pd.DataFrame(gold) \n    output=stock.merge(test,on=\"Date\",how=\"left\") #combining two data sets\n    stock[\"gold_price\"]=output[\"gold_price\"]\n    stock['share_price']=pd.to_numeric(stock['share_price'], errors='coerce').dropna(0)\n    stock['gold_price']=pd.to_numeric(stock['gold_price'], errors='coerce').dropna(0)\n    stock[\"year\"]=pd.to_datetime(stock[\"Date\"]).dt.year #Create a column with years for subsequent filtering\n    stock[\"name\"]=shares[index]\n    stock = stock.dropna() #delete all NAN lines\n    #creating a column with a scaled share price\n    scaler=MinMaxScaler()\n    stock[\"share_price_scaled\"]=scaler.fit_transform(stock[\"share_price\"].to_frame())\n    #add data to the main dataframe\n    all_data=all_data.append(stock) #add the data","0d7af525":"#leave data only from 2015 to 2019\nall_data_15 = all_data[(all_data['year']>2014)&(all_data['year']<2020)]\nall_data_15.head()","ab6340ef":"gold[['Date','gold_price']].set_index('Date').plot(color=\"green\", linewidth=1.0)\nplt.show()","a26e7a23":"palette=sns.cubehelix_palette(18, start=2, rot=0, dark=0, light=.95, reverse=False)\ng = sns.pairplot(all_data[(all_data['name']==\"POLY.ME\")&(all_data['year']>2014)&(all_data['year']<2020)].\\\n             drop([\"share_price_scaled\"],axis=1), hue=\"year\",height=4)\ng.fig.suptitle(\"Polyuse\", y=1.08)\n\npalette=sns.cubehelix_palette(18, start=2, rot=0, dark=0, light=.95, reverse=False)\nf = sns.pairplot(all_data[(all_data['name']==\"GOLD\")&(all_data['year']>2014)&(all_data['year']<2020)].\\\n             drop([\"share_price_scaled\"],axis=1), hue=\"year\",height=4)\nf.fig.suptitle('Barrick Gold', y=1.08)\n\nplt.show()","2b97932e":"plt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\npalette=sns.cubehelix_palette(5, start=2.8, rot=0, dark=0.2, light=0.8, reverse=False)\n\nsns.violinplot(x=\"year\", y=\"gold_price\", data=all_data_15[[\"gold_price\",\"year\"]],\n               inner=\"quart\", palette=palette, trim=True)\nplt.xlabel(\"Year\")\nplt.ylabel(\"Price gold\")\n\nplt.show()","5a25c4cd":"sns.catplot(x=\"year\", y=\"share_price_scaled\", col='name', col_wrap=3,kind=\"violin\",\n               split=True, data=all_data_15,inner=\"quart\", palette=palette, trim=True, height=4, aspect=1.2)\nsns.despine(left=True)","bb712ae5":"sns.jointplot(\"gold_price\", \"share_price\",data=all_data_15[all_data_15['name']==\"POLY.ME\"],kind=\"kde\",\n              height=6,ratio=2,color=\"red\").plot_joint(sns.kdeplot, zorder=0, n_levels=20)\n\nsns.jointplot(\"gold_price\", \"share_price\",data=all_data_15[all_data_15['name']==\"GOLD\"],kind=\"kde\",\n              height=6,ratio=2,color=\"red\").plot_joint(sns.kdeplot, zorder=0, n_levels=20)\nplt.show()","b72659bd":"sns.lmplot(x=\"gold_price\", y=\"share_price_scaled\", col=\"name\",ci=None, col_wrap=3, \n           data=all_data_15, order=1,line_kws={'color': 'blue'},scatter_kws={'color': 'grey'}).set(ylim=(0, 1))\n\nplt.show()","8b9ad6c1":"palette=sns.cubehelix_palette(5, start=2, rot=0, dark=0, light=.95, reverse=False)\nsns.lmplot(x=\"gold_price\", y=\"share_price_scaled\",hue=\"year\", col=\"name\",ci=None, \n           col_wrap=3, data=all_data_15, order=1,palette=palette,height=4).set(ylim=(0, 1))\n\nplt.show()","045b9893":"from sklearn.cluster import KMeans\n\npoly=all_data_15[all_data_15['name']==\"GOLD\"]\n# We need to scale also gold price, so clustering is not influenced by the relative size of one axis.\npoly=pd.DataFrame(poly)\npoly['gold_price_scaled'] = scaler.fit_transform(poly[\"gold_price\"].to_frame())\npoly[\"cluster\"] = KMeans(n_clusters=5, random_state=1).fit_predict(poly[[\"share_price_scaled\",\"gold_price_scaled\"]])\n\n# The 954 most common RGB monitor colors https:\/\/xkcd.com\/color\/rgb\/\ncolors = [\"baby blue\", \"amber\", \"scarlet\", \"grey\",\"milk chocolate\", \"windows blue\"]\npalette=sns.xkcd_palette(colors)\n\nsns.lmplot(x=\"gold_price\", y=\"share_price_scaled\",ci=None,palette=palette, hue=\"cluster\",fit_reg=0 ,data=poly)\n\nplt.show()","8830cafd":"for sh in shares:\n  print(sh)\n  #Data Preparation\n  share_18=pd.DataFrame()\n  share_18=all_data_15[(all_data_15['name']==sh)] # Get data 2018\/19\n  share_18=share_18[[\"share_price\",\"gold_price\"]].reset_index()\n  # Just using 1 variable for linear regression. Split the data into training\/testing sets\n  train = share_18[:-100]\n  test = share_18[-100:]\n\n  x_train=train[\"gold_price\"].to_frame() \n  y_train=train['share_price'].to_frame()\n  x_test=test[\"gold_price\"].to_frame() \n  y_test=test['share_price'].to_frame()\n\n  \n  regr = LinearRegression() #Create linear regression object\n\n    \n  regr.fit(x_train,y_train) #Train the model using the training sets\n\n  print(\"Coefficients: \",  float(regr.coef_))\n  print(np.corrcoef(x_train,y_train, rowvar=False))\n\n  y_pred = regr.predict(x_test)\n  print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n  print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n  print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n  \n  # Plot outputs using matplotlib\n  plt_train=plt.scatter(x_train[\"gold_price\"],y_train,   color='grey')\n  plt_test=plt.scatter(x_test[\"gold_price\"],y_test,   color='green')\n  plt_pred=plt.scatter(x_test[\"gold_price\"], y_pred,  color='black')\n\n  plt.xlabel(\"gold_price\")\n  plt.ylabel(\"share_price\")\n  plt.legend((plt_train, plt_test,plt_pred),(\"train data\", \"test data\",\"prediction\"))\n  plt.show()\n","ee89e94b":"from sklearn.ensemble import RandomForestRegressor\n# 1.- Data Preparation\nnmm15=pd.DataFrame()\nnmm15=all_data_15[(all_data_15['name']==\"NMM.SG\") & (all_data_15['year']>2016 )]\nnmm15=nmm15[[\"share_price\",\"gold_price\"]].reset_index()\n\n# Load share price of other variables\nnmm15['GOLD']=all_data_15[(all_data_15['name']==\"GOLD\")][-980:].reset_index()['share_price']\nnmm15['GOLD'] = nmm15['GOLD'].shift(1)\nnmm15['AU']=all_data_15[(all_data_15['name']==\"AU\")][-980:].reset_index()['share_price']\nnmm15['AU'] = nmm15['AU'].shift(1)\nnmm15['KGC']=all_data_15[(all_data_15['name']==\"KGC\")][-980:].reset_index()['share_price']\nnmm15['KGC'] = nmm15['KGC'].shift(1)\nnmm15['NCM.AX']=all_data_15[(all_data_15['name']==\"NCM.AX\")][-980:].reset_index()['share_price']\nnmm15['NCM.AX'] = nmm15['NCM.AX'].shift(1)\n\nnmm15 = nmm15.drop(nmm15.index[0])\n\ntrain = nmm15[:-100]\ntest = nmm15[-100:]\n\nx_train=train[[\"gold_price\",\"GOLD\",\"AU\",\"KGC\",\"NCM.AX\"]]\ny_train=train['share_price']\n\nx_test=test[[\"gold_price\",\"GOLD\",\"AU\",\"KGC\",\"NCM.AX\",]] \ny_test=test['share_price'].to_frame()\n\n\n# 2.- Create Randomforest object usinig a max depth=5\nregressor = RandomForestRegressor(n_estimators=200, max_depth=5 )\n\n# 3.- Train data\nclf=regressor.fit(x_train, y_train)\n\n# 4.- Predict!\ny_pred=regressor.predict(x_test)\ny_pred_list = list(y_pred)\ny_pred=pd.DataFrame(y_pred)","d45f4fac":"# We are going to have a look at how fitted data looks like:\n\nplt_train=plt.scatter(x_train[\"gold_price\"],y_train,   color='grey')\nplt_pred=plt.scatter(nmm15[\"gold_price\"], regressor.predict(nmm15[[\"gold_price\",\"GOLD\",\"AU\",\"KGC\",\"NCM.AX\"]]),  color='black')\n\nplt.xlabel(\"gold_price\")\nplt.ylabel(\"share_price\")\nplt.legend((plt_train,plt_pred),(\"train data\",\"prediction\"))\nplt.show()","f6cd3f76":"plt_train=plt.scatter(x_train[\"gold_price\"],y_train,   color='grey')\nplt_test=plt.scatter(x_test[\"gold_price\"],y_test,   color='green')\nplt_pred=plt.scatter(x_test[\"gold_price\"], y_pred,  color='black')\n\nplt.xlabel(\"gold_price\")\nplt.ylabel(\"share_price\")\nplt.legend((plt_train, plt_test,plt_pred),(\"train data\", \"test data\",\"prediction\"))\nplt.show()","d945fe92":"  # Get error\n  y_pred = clf.predict(x_test)\n  print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n  print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n  print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","b8affbc8":"importances=regressor.feature_importances_\n\nindices=list(x_train)\nprint(\"Feature ranking:\")\n\nfor f in range(x_train.shape[1]):\n    print(\"Feature %s (%f)\" % (indices[f], importances[f]))\n\nf, (ax1) = plt.subplots(1, 1, figsize=(8, 6), sharex=True)\nsns.barplot(indices, importances, palette=\"BrBG\", ax=ax1)\nax1.set_ylabel(\"Importance\")","b0a7af25":"Random forest is a machine learning algorithm that uses a Committee (ensemble) of decision trees. The main idea is to use a large ensemble of decision trees, each of which in itself gives a very low quality of classification, but due to their large number, the result is good.\n\nThe random forest algorithm accepts more than one variable in the input data to predict the output data. It works very efficiently on large amounts of data, can handle many input variables, has efficient methods for estimating missing data, and many other advantages. The main disadvantages are:\n1. Random forests is slow to generate forecasts because it has many decision trees. Whenever it makes a forecast, all the trees in the forest must make a forecast for the same given input and then vote on it. This whole process takes a long time.\n2. the Model is difficult to interpret compared to the decision tree, where you can easily make a decision by following the path in the tree.\n\nOne of the great advantages of a random forest is that it can be used for both classification and regression problems, which make up most of today's machine learning systems. I will talk about random forests in classification, since classification is sometimes considered a building block of machine learning. Below you can see what a random forest with two trees looks like:\n\nIn addition to the gold price, we will use other variables to forecast the Newmont Goldcorp share price. This will be the share prices of other foreign gold mining companies. I know it doesn't make a lot of sense, but we just want to see how to build this type of model. This will allow us to see the impact of each of them on the final forecast.Random forest is a machine learning algorithm that uses a Committee (ensemble) of decision trees. The main idea is to use a large ensemble of decision trees, each of which in itself gives a very low quality of classification, but due to their large number, the result is good.\n","33f71414":"### 3.1. Cluster analysis for Barrick Gold stock","e0125c37":"### 2.3 Violinplot for the gold price","a39d78c6":"## 3 Machine learning and prediction","63837480":"A paired graph allows you to see the distribution of data by showing the paired relationships in the data set and the univariate distribution of data for each variable. You can also use the palette to see how this data changed in different years.\n\nThe chart is particularly interesting for 2016 and 2019, as it looks like the price of the Pole stock, Barrick Gold and the price of gold are lined up along the same line. We can also conclude from the distribution charts that the price of gold and stocks moved gradually towards higher values.","c1800da4":"### 2.1 Chart of gold price changes","c846875d":"Here the picture is a little better in the sense that some companies have a data cloud stretching along a straight line in some years, which may indicate the existence of a dependency.","e318d549":"### 2.2. Plotting the pairplot chart for the price of Polyus and Barrick Gold shares over the past five years","59df035d":"The resulting model looks really good in addition, we must remember that Random Forest has many more parameters to configure, but the key one is the maximum depth, which is unlimited by default. Next, we'll check how this model predicts or tests data.","08cb298f":"Next, we will build a regular linear regression using training with a teacher. The goal is to estimate the forecast of data for the last 100 days of 2019 based on data from 2018\/2019 (excluding estimated ones). Training data is the data used to build the model, and test data is the data that we will try to predict.","4152ecb0":"## 1. Loading data","5553d6ba":"By the importance of the signs, it immediately becomes clear how strong the value of gold is.\n\nIn short, I hope I was able to reveal to you the beginnings of a project on using machine learning to study stock prices, and I hope to hear your comments.","0166a6a0":"### 2.5 Charts of the dependence of the share price of various companies on the price of gold","e6b315ec":"I will give a definition for machine learning from Wikipedia: Machine learning is a class of artificial intelligence methods that are characterized not by direct problem solving, but by learning in the process of applying solutions to many similar problems. To build such methods, we use mathematical statistics, numerical methods, optimization methods, probability theory, graph theory, and various techniques for working with data in digital form.\n\nUsually, machine learning algorithms can be classified into the following categories: learning with a teacher and learning without a teacher. Here is their definition from one of the sites:\n\nSupervised learning is one of the sections of machine learning dedicated to solving the following problem. There is a set of objects (situations) and the set of possible answers (responses, reactions). There is some relationship between responses and objects, but it is unknown. Only a finite set of use cases is known \u2014 the \"object, response\" pairs, called the training sample. Based on this data, you need to restore the dependency, that is, build an algorithm that can give a fairly accurate answer for any object. To measure the accuracy of responses, a quality functional is introduced in a certain way. see the Links)\n\nUnsupervised learning is one of the sections of machine learning. Studies a wide class of data processing problems in which only descriptions of a set of objects (training sample) are known, and it is required to detect internal relationships, dependencies, and patterns that exist between objects. Learning without a teacher is often contrasted with learning with a teacher, when each training object is given a \"correct answer\", and you need to find the relationship between the objects and the answers. see links)\n\nThe following machine learning methods will be discussed later:\n\n* Cluster analysis\n* Linear regression\n* Random forest\n\nUsing these algorithms, you can evaluate overvalued or undervalued stocks relative to the price of gold and possible movement on the next day. I remind you that you must be very careful and use the conclusions from this post at your own risk. I also remind you that my main goal is to show the potential of machine learning for stock valuation.","86a49687":"## 2. Data analysis","ade1a89b":"From the above charts, we can conclude that the price of gold predicts the price of shares of foreign companies on the next day quite well. In Russian companies, this picture looks much worse. Of course, there may be a false impression about Seligdar shares. But visual analysis of the chart allows you to discard this assumption.","2b9a2c72":"# Using machine learning to predict gold mining stock prices","28cb2405":"It is necessary to move the price of gold, as we will be interested in how yesterday's price affected today's stock price.","0e5a6b78":"It is best to start analyzing data by presenting it visually, which will help you understand it better.","221c9a4e":"### 3.2. Linear regression between Barrick Gold shares and the gold price","0e700fd6":"For the price of gold, take the value of the exchange-traded investment Fund SPDR Gold Trust, whose shares are 100% backed by precious metal. The quotes will be compared with the prices of gold mining companies ' shares:\n* Newmont Goldcorp (NMM)\n* Barrick Gold (GOLD)\n* AngloGold Ashanti (AU)\n* Kinross Gold (KGC)\n* Newcrest Mining (ENC)\n* Polyus (PLZL)\n* Polymetal (POLY)\n* Seligdar (SELG)","29b7dd90":"As a basis, I took a notebook published on github of pythonbravo for oil. This notebook examines the analysis of gold prices and shares of gold mining companies using machine analysis methods: linear regression, cluster analysis, and random forest. I immediately warn you that this post does not attempt to show the current situation and predict the future direction. Just like the author for oil, this article does not aim to raise or refute the possibilities of machine learning for analyzing stock prices or other tools. I upgraded the code for gold research in order to encourage those who are interested in further reflection and listen to constructive criticism in their address.","482ea233":"A large fluctuation in gold prices was noted according to the charts in 2016 and 2019. As you can see from the graphs in the following figure, some companies such as Newmont Mining, Barrick Gold, AngloGold Ashanti, Newcrest Mining and Polymetal were also affected. It should also be noted that all prices are marked in the range from 0 to 1 and this may lead to inaccuracies in the interpretation.","eba100af":"Next, we will build distribution charts for one Russian company - Polymetal and one foreign company - Barrick Gold","1864651c":"In fact, you won't be able to see much on these charts, although some stocks seem to have a relationship.\n\nThe next step is to try to color the charts depending on the years.","bb9b4f11":"### 3.3 Random forest on Newmont Goldcorp shares against the price of gold and shares of gold companies","6e4f16e9":"It is necessary to pay attention to the distribution of the share price for the two companies and it will become clear that the shape of the density graph is the same for them.","a09c47e4":"Cluster analysis is used in a large number of machine learning tasks. But I have given it only for informational purposes, since in this form it does not bring much benefit to our analysis.","d3f3221d":"Clustering is the task of dividing a set of objects into groups called clusters. Each group should contain \"similar\" objects, and objects from different groups should be as different as possible.","554a8d27":"### 2.4 Violinplot for multiple shares"}}