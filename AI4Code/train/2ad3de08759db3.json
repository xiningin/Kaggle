{"cell_type":{"2792a812":"code","f3b22b24":"code","e8f83237":"code","8cc04a7a":"code","0d10a998":"code","efcb67e5":"code","1cdbc44f":"code","63cf4dc3":"code","936a64ff":"code","0e787975":"code","b17bff1e":"code","1cc087c6":"markdown","0093e06c":"markdown","13c0a227":"markdown","34e18ac2":"markdown","c8b9d201":"markdown","c5022489":"markdown","fac6824e":"markdown","d9401080":"markdown","db41ce7f":"markdown","96a4667d":"markdown","3bebb84b":"markdown"},"source":{"2792a812":"import pandas as pd\nimport spacy\nfrom spacy import displacy","f3b22b24":"cols = list(pd.read_csv('..\/input\/test_stage_1.tsv', delimiter='\\t', nrows =1))\ndata = pd.read_csv('..\/input\/test_stage_1.tsv', delimiter='\\t', usecols =[i for i in cols if i != 'URL']).rename(columns={'Pronoun-offset': 'Pronoun_offset', 'A-offset': 'A_offset', 'B-offset': 'B_offset'})\ndata.head()","e8f83237":"nlp = spacy.load('en_core_web_lg')","8cc04a7a":"docs = list(map(nlp, data.Text))\ndocs[0]","0d10a998":"docs[1]","efcb67e5":"doc_index = 1\ndoc = docs[doc_index]\ntokens = pd.DataFrame(\n    [[token.text, token.sent, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, [child for child in token.children], [ancestor for ancestor in token.ancestors]] for token in doc],\n    columns=['text', 'span', 'lemma', 'pos', 'tag', 'dep', 'shape', 'is_alpha', 'is_stop', 'child', 'ancestors'])\ntokens","1cdbc44f":"pronoun_span = doc.char_span(data.Pronoun_offset.get(doc_index), data.Pronoun_offset.get(doc_index) + len(data.Pronoun.get(doc_index)), label = 'Pronoun')\npronoun_tokens = pd.DataFrame(\n    [[token.text, token.sent, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, [child for child in token.children], [ancestor for ancestor in token.ancestors]] for token in pronoun_span],\n    columns=['text', 'span', 'lemma', 'pos', 'tag', 'dep', 'shape', 'is_alpha', 'is_stop', 'child', 'ancestors'])\npronoun_tokens\n","63cf4dc3":"a_span = doc.char_span(data.A_offset.get(doc_index), data.A_offset.get(doc_index) + len(data.A.get(doc_index)), label = 'A')\nb_span = doc.char_span(data.B_offset.get(doc_index), data.B_offset.get(doc_index) + len(data.B.get(doc_index)), label = 'B')\na_tokens = pd.DataFrame(\n    [[token.text, token.sent, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, [child for child in token.children], [ancestor for ancestor in token.ancestors]] for token in a_span],\n    columns=['text', 'span', 'lemma', 'pos', 'tag', 'dep', 'shape', 'is_alpha', 'is_stop', 'child', 'ancestors'])\na_tokens","936a64ff":"b_span = doc.char_span(data.B_offset.get(doc_index), data.B_offset.get(doc_index) + len(data.B.get(doc_index)), label = 'B')\nb_tokens = pd.DataFrame(\n    [[token.text, token.sent, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, [child for child in token.children], [ancestor for ancestor in token.ancestors]] for token in b_span],\n    columns=['text', 'span', 'lemma', 'pos', 'tag', 'dep', 'shape', 'is_alpha', 'is_stop', 'child', 'ancestors'])\nb_tokens","0e787975":"sentence_spans = list(doc.sents)\ndisplacy.render(sentence_spans, style='dep', jupyter=True, options ={ 'compact': True, 'distance': 100, 'bg': '#09a3d5', 'color': '#FFFFFF'})","b17bff1e":"doc.print_tree()","1cc087c6":"## Calculate pronoun Span","0093e06c":"## Apply NLP to the sentences","13c0a227":"# Display Spacy renders of sentences","34e18ac2":"## Initialize environment","c8b9d201":"## Calculate B Span","c5022489":"## Initialize Spacy NLP","fac6824e":"## Extract token information from doc","d9401080":"# Show the document tree","db41ce7f":"## Calculate A Span","96a4667d":"## Load data","3bebb84b":"> # Extract some information with Spacy"}}