{"cell_type":{"c5e10f8e":"code","78515ec8":"code","0f45801f":"code","77e43088":"code","66613fe1":"code","bf7189c2":"code","f945f93f":"code","eb4870ec":"code","67873ca3":"code","3a655a36":"code","f22c0a1b":"code","90d1688d":"code","8c4d5986":"code","e12cb898":"code","c7ba024c":"code","0ed15ca1":"code","b2ef5c7d":"code","1adfbcf2":"code","b171b56c":"code","0fa0f4a7":"code","c0eb27dc":"code","69aee3e1":"code","b88e1b33":"code","b135d0f0":"code","d6b4a027":"code","1bd33610":"code","ba248cbf":"code","a65444c9":"code","36745394":"code","89693c72":"code","8afae555":"code","783092db":"code","fc80c015":"code","33e40284":"code","74f9de38":"code","7da9c250":"code","e06c401a":"code","ceeca41e":"code","16a2accb":"code","39257b79":"code","4faa06cd":"code","126ff266":"code","5d8b58ab":"code","46e5deec":"code","b97c3ac3":"code","4cd391a6":"code","d98f5c2b":"code","17978792":"code","19c56b5c":"code","1778b40f":"code","f5e5da57":"code","9a106b59":"code","5b282456":"code","d43e28f0":"code","b9e36872":"code","84cfa44b":"code","0dcdc4d7":"code","58968ef7":"code","f4513ff0":"code","7c300a27":"code","0175c66a":"code","ed085768":"code","7bc5d091":"code","283a89bf":"code","b10d440e":"code","9b6db61c":"code","8d0b6091":"code","ea0e39b1":"code","4c43865d":"code","11eb100d":"code","9e1f6347":"code","8a0bd4ac":"code","545090e1":"code","583076f5":"code","d46210ed":"code","129d8d00":"code","e840d7a3":"code","be3212de":"code","afa0c70c":"code","224decd2":"code","308836d6":"code","4f622014":"code","35c31641":"code","4e941048":"markdown","59941ed7":"markdown","8eedce7c":"markdown","67d97a04":"markdown","6bd8038c":"markdown","e42dc995":"markdown","e8e69222":"markdown","120aa876":"markdown","4fcf5253":"markdown","b646bea1":"markdown","db8f9948":"markdown"},"source":{"c5e10f8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error,explained_variance_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","78515ec8":"df = pd.read_csv('..\/input\/housesalesprediction\/kc_house_data.csv')","0f45801f":"df.head(2)","77e43088":"df.shape","66613fe1":"df.info()","bf7189c2":"df.describe().transpose()","f945f93f":"df.isnull().sum()","eb4870ec":"plt.figure(figsize=(10,5))\nsns.distplot(df[\"price\"])","67873ca3":"sns.countplot(df[\"bedrooms\"])","3a655a36":"df.corr()[\"price\"].sort_values() ### Looking for the highly correkated features with price","f22c0a1b":"plt.figure(figsize=(10,5))\nsns.scatterplot(x='price',y='sqft_living',data=df)","90d1688d":"plt.figure(figsize=(10,5))\nsns.boxplot(x='bedrooms',y='price',data=df)","8c4d5986":"plt.figure(figsize=(10,5))\nsns.scatterplot(x='price',y='long',data=df)","e12cb898":"plt.figure(figsize=(10,5))\nsns.scatterplot(x='price',y='lat',data=df)","c7ba024c":"plt.figure(figsize=(12,7))\nsns.scatterplot(x='long',y='lat',data=df)","0ed15ca1":"plt.figure(figsize=(12,7))\nsns.scatterplot(x='long',y='lat',data=df,hue='price')","b2ef5c7d":"df.sort_values('price',ascending=False).head(20)","1adfbcf2":"len(df)*0.01","b171b56c":"non_top_1_perc = df.sort_values('price',ascending=False).iloc[216:]","0fa0f4a7":"non_top_1_perc.head(20)","c0eb27dc":"print(f'Minimum value of price is {non_top_1_perc[\"price\"].min()}')\nprint(f'Maximum value of price is {non_top_1_perc[\"price\"].max()}')","69aee3e1":"plt.figure(figsize=(10,5))\nsns.distplot(non_top_1_perc['price'])","b88e1b33":"plt.figure(figsize=(10,5))\nsns.countplot(x='bedrooms',data=non_top_1_perc)","b135d0f0":"non_top_1_perc.sort_values(\"bedrooms\",ascending=False).head(20)","d6b4a027":"plt.figure(figsize=(12,6))\nsns.scatterplot(x='long',y='lat',data=non_top_1_perc,hue='price',edgecolor=None,alpha=0.2,palette='plasma')","1bd33610":"plt.figure(figsize=(10,5))\nsns.boxplot(x='waterfront',y='price',data=non_top_1_perc)","ba248cbf":"plt.figure(figsize=(12,5))\nsns.boxplot(x='bedrooms',y='price',data=non_top_1_perc)","a65444c9":"def get_distro(df,df2,col,col2):\n    plt.figure(figsize=(18,6))\n    \n    plt.subplot(1,2,1)\n    sns.boxplot(df[col],df[col2])\n    plt.title(\"Raw Data\",fontweight='bold')\n    \n    plt.subplot(1,2,2)\n    sns.boxplot(df2[col],df2[col2])\n    plt.title(\"Filter Data\",fontweight='bold')\n    \n    plt.show()\n    ","36745394":"get_distro(df,non_top_1_perc,'waterfront','price')\n# sns.boxplot(df['waterfront'],df['price'])","89693c72":"df.head()","8afae555":"df = df.drop('id',axis=1)","783092db":"df['date'] = pd.to_datetime(df['date'])","fc80c015":"df[\"year\"] = df['date'].apply(lambda date: date.year)\ndf[\"month\"] = df[\"date\"].apply(lambda date: date.month)","33e40284":"df.head()","74f9de38":"plt.figure(figsize=(12,5))\nsns.boxplot(x='month',y='price',data=df)","7da9c250":"plt.figure(figsize=(12,5))\nsns.boxplot(x='year',y='price',data=df)","e06c401a":"df.groupby(\"month\").mean()[\"price\"].plot(figsize=(12,6))\nplt.ylabel(\"Price Mean\",fontweight='bold')\nplt.autoscale(tight=True)","ceeca41e":"df.groupby(\"year\").mean()[\"price\"].plot(figsize=(12,6))\nplt.ylabel(\"Price Mean\",fontweight='bold')\nplt.autoscale(tight=True)","16a2accb":"df = df.drop(\"date\",axis=1)","39257b79":"df.head()","4faa06cd":"df= df.drop(\"zipcode\",axis=1)","126ff266":"X = df.drop('price',axis=1).values\ny = df[\"price\"].values","5d8b58ab":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=101)","46e5deec":"scaler = MinMaxScaler()","b97c3ac3":"X_train = scaler.fit_transform(X_train)","4cd391a6":"X_test = scaler.transform(X_test)","d98f5c2b":"X_train.shape","17978792":"model = Sequential()\n\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam',loss='mse')","19c56b5c":"model.fit(x=X_train,y=y_train,epochs=400,validation_data=(X_test,y_test),batch_size=128)","1778b40f":"loss_df = pd.DataFrame(model.history.history)","f5e5da57":"loss_df.plot()","9a106b59":"predictions = model.predict(X_test)","5b282456":"print(f\"MAE for the model predicted is {mean_absolute_error(y_test,predictions)}\")\nprint(f\"MSE for the model predicted is {mean_squared_error(y_test,predictions)}\")\nprint(f\"RMSE for the model predicted is {np.sqrt(mean_squared_error(y_test,predictions))}\")\nprint(f\"Explained variance Score for the model predicted is {explained_variance_score(y_test,predictions)}\")","d43e28f0":"plt.figure(figsize=(12,6))\nplt.scatter(y_test,predictions)\nplt.plot(y_test,y_test,'r')\nplt.xlabel(\"True Value\",fontweight='bold')\nplt.ylabel(\"Predicted Value\",fontweight='bold')","b9e36872":"single_house = df.drop('price',axis=1).iloc[0]","84cfa44b":"single_house = scaler.transform(single_house.values.reshape(-1,19))","0dcdc4d7":"model.predict(single_house)","58968ef7":"df['price'].iloc[0]","f4513ff0":"non_top_1_perc.head()","7c300a27":"non_top_1_perc['date'] = pd.to_datetime(non_top_1_perc['date'])","0175c66a":"non_top_1_perc.head(2)","ed085768":"non_top_1_perc[\"month\"] = non_top_1_perc['date'].apply(lambda date:date.month)\nnon_top_1_perc[\"year\"] = non_top_1_perc['date'].apply(lambda date:date.year)","7bc5d091":"non_top_1_perc.head(2)","283a89bf":"plt.figure(figsize=(12,5))\nsns.boxplot(x='month',y='price',data=non_top_1_perc)","b10d440e":"plt.figure(figsize=(12,5))\nnon_top_1_perc.groupby('month').mean()['price'].plot()\nplt.autoscale(tight=True)","9b6db61c":"plt.figure(figsize=(12,5))\nnon_top_1_perc.groupby('year').mean()['price'].plot()\nplt.autoscale(tight=True)","8d0b6091":"non_top_1_perc = non_top_1_perc.drop([\"id\",'date','zipcode'],axis=1)","ea0e39b1":"X1 = non_top_1_perc.drop('price',axis=1).values\ny1 = non_top_1_perc[\"price\"].values","4c43865d":"X1_train, X1_test, y1_train, y1_test = train_test_split( X1, y1, test_size=0.3, random_state=101)","11eb100d":"scaler_1 = MinMaxScaler()","9e1f6347":"X1_train = scaler_1.fit_transform(X1_train)","8a0bd4ac":"X1_test = scaler_1.transform(X1_test)","545090e1":"model_retrain = Sequential()\n\nmodel_retrain.add(Dense(19,activation='relu'))\nmodel_retrain.add(Dense(19,activation='relu'))\nmodel_retrain.add(Dense(19,activation='relu'))\nmodel_retrain.add(Dense(19,activation='relu'))\n\nmodel_retrain.add(Dense(1))\n\nmodel_retrain.compile(optimizer='adam',loss='mse')","583076f5":"model_retrain.fit(X1_train,y1_train,validation_data=(X1_test,y1_test),epochs=400,batch_size=128)","d46210ed":"losses_retrain = pd.DataFrame(model_retrain.history.history)","129d8d00":"losses_retrain.plot()","e840d7a3":"predictions_retrain = model_retrain.predict(X1_test)","be3212de":"print(f\"MAE for the model predicted is {mean_absolute_error(y1_test,predictions_retrain)}\")\nprint(f\"MSE for the model predicted is {mean_squared_error(y1_test,predictions_retrain)}\")\nprint(f\"RMSE for the model predicted is {np.sqrt(mean_squared_error(y1_test,predictions_retrain))}\")\nprint(f\"Explained variance Score for the model predicted is {explained_variance_score(y1_test,predictions_retrain)}\")","afa0c70c":"plt.scatter(y1_test,predictions_retrain)\nplt.plot(y1_test,y1_test,'r')\nplt.xlabel(\"True Value\",fontweight='bold')\nplt.ylabel(\"Predicted Value\",fontweight='bold')","224decd2":"single_house_retrain = non_top_1_perc.drop('price',axis=1).iloc[0]","308836d6":"single_house_retrain = scaler_1.transform(single_house_retrain.values.reshape(-1,19))","4f622014":"model_retrain.predict(single_house_retrain)","35c31641":" non_top_1_perc['price'].iloc[0]","4e941048":"### Data Preprocessing","59941ed7":"#### Seems to have an outlier with 33 bedrooms","8eedce7c":"### Removing the top 1% of the data - Outliers","67d97a04":"### Retrain the model with `non_top_1_perc`\n","6bd8038c":"#### We can conclude that Model with explainable variance of 0.8013325822336658 is better over moddel retrained with removing top 1% with explainable variance of 0.7379875841167598","e42dc995":"### Visualization","e8e69222":"#### Price range is falling between 0 and 2000000 majorly","120aa876":"### Checking the data for the presence of Null Values","4fcf5253":"### Model Building","b646bea1":"### Exploratory Data Analysis","db8f9948":"### Feataure Engineering"}}