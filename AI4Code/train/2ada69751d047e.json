{"cell_type":{"a009622e":"code","28dcc4be":"code","c4f9ef29":"code","70de245e":"code","724721a6":"code","5160f712":"code","7cbd33a9":"code","89259555":"code","3240b565":"code","b3a2e941":"code","ffd24318":"code","a146b15f":"code","2899e76a":"code","cc82b8c9":"code","9d3e3508":"code","d6e96f54":"code","4aaf0b7d":"code","5f44e664":"code","00a83dcd":"code","329accdf":"code","dbf72938":"code","141e27ac":"code","0da4ba17":"code","77064f65":"code","b5a65e77":"code","41fa7e3a":"code","f185dfc5":"code","806e474b":"code","d0810ca2":"code","5d7e17aa":"code","a5dc015c":"code","108d0a2e":"code","e6b9d5af":"code","374fa5c2":"code","7a9f70fe":"code","db439daf":"code","a7f0eca0":"code","77b1aca3":"code","a6643e57":"code","58575691":"code","d9869bcb":"code","c68e3d74":"code","09702bb7":"code","6e40afbb":"code","24e25f10":"code","68ba48ad":"code","53e06a9b":"markdown","636fc8f2":"markdown","9e050cb5":"markdown","2f6e271a":"markdown","b4fa826f":"markdown","6547369d":"markdown","b1286ad7":"markdown","4da0a98c":"markdown","ba7c082f":"markdown","78dffd64":"markdown","3f9e093a":"markdown","6e04cc2a":"markdown","1053eb13":"markdown","50a9515e":"markdown","974ff1e8":"markdown"},"source":{"a009622e":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('..\/input\/ibm-sql-course-chicago-crime-and-public-schools\/Census_Data_-_Selected_socioeconomic_indicators_in_Chicago__2008___2012-v2.csv')","28dcc4be":"df.dtypes","c4f9ef29":"df_num = df.drop(['COMMUNITY_AREA_NAME'], axis = 1)\ndf_cat = df['COMMUNITY_AREA_NAME'].copy()","70de245e":"df_num = df_num.astype(np.float64).head()","724721a6":"df.rename(columns = {\"PERCENT HOUSEHOLDS BELOW POVERTY\":\"household_BPL\"},inplace = True )\n","5160f712":"df.rename(columns = {\"COMMUNITY_AREA_NUMBER\":'comm_area_no'}, inplace = True)","7cbd33a9":"df.dtypes","89259555":"df.rename(columns = {\"COMMUNITY_AREA_NAME\":'comm_area_name'}, inplace = True)\ndf.rename(columns = {\"PERCENT OF HOUSING CROWDED\":'percent_housing_crowded'}, inplace=True)\ndf.rename(columns = {\"PERCENT AGED 16+ UNEMPLOYED\":'per_16_unemp'}, inplace=True)\ndf.rename(columns = {\"PERCENT AGED 25+ WITHOUT HIGH SCHOOL DIPLOMA\":'per_25_without_highschool'}, inplace=True)\ndf.rename(columns = {\"PERCENT AGED UNDER 18 OR OVER 64\":'per_under18_over64'}, inplace=True)\ndf.rename(columns = {\"PER_CAPITA_INCOME \":'per_capita_income'}, inplace = True)\ndf.rename(columns = {\"HARDSHIP_INDEX\":'hardship_index'}, inplace = True)","3240b565":"df.head()","b3a2e941":"#simple feature scaling on per_capita_income - Range 0 to 1\ndf_norm = df\ndf_norm['per_capita_income'] = df_norm['per_capita_income']\/df_norm['per_capita_income'].max()","ffd24318":"# min-max scaling\ndf_min_max = df\ndf_min_max['per_capita_income'] = (df_min_max['per_capita_income'] - df_min_max['per_capita_income'].min())\/(\n    df_min_max['per_capita_income'].max() - df_min_max['per_capita_income'].min() )","a146b15f":"df_min_max.head()","2899e76a":"# z scores range -3 to 3 usually\ndf_z = df\ndf_z[\"per_capita_income\"] = ( df_z[\"per_capita_income\"] - df_z[\"per_capita_income\"].mean() )\/df_z[\"per_capita_income\"].std(ddof=1)\ndf_z.head()","cc82b8c9":"# drop missing values - dropna()\n\n#df_norm.dropna().info()","9d3e3508":"# Identify the column with missing value and replace the values there\ndf_z.info()","d6e96f54":"df_z[[\"comm_area_no\"]].isna().tail()","4aaf0b7d":"df_z[[\"comm_area_no\"]].tail()","5f44e664":"df_z[\"comm_area_no\"]  =  df_z[\"comm_area_no\"].replace(np.nan, np.float(78))","00a83dcd":"df_z[[\"comm_area_no\"]].tail()","329accdf":"df_z.head()","dbf72938":"df_z['hardship_index'].isna().tail()","141e27ac":"df_z['hardship_index'].tail()","0da4ba17":"print(\"The mean is\", df_z['hardship_index'].mean(),\"and median is\", df_z['hardship_index'].median(),\n     \"and the max is\", df_z['hardship_index'].max(), \"and the min is\", df_z['hardship_index'].min())","77064f65":"import matplotlib.pyplot as plt\n%matplotlib inline\ndf_z.hist('hardship_index', bins=25)","b5a65e77":"mean = round(df_z['hardship_index'].mean(),1)\n#df_z['hardship_index'].replace(np.nan, mean)\nmean","41fa7e3a":"df_z['hardship_index'] = df_z['hardship_index'].astype(np.float64)","f185dfc5":"df_z['hardship_index'].dtypes","806e474b":"df_z['hardship_index'].replace(np.nan, mean)","d0810ca2":"df_z.info()","5d7e17aa":"bins = np.linspace(min(df_z['hardship_index']),max(df_z['hardship_index']), 4)\nprint(bins)\n#bins = np.linspace(min(df_z['hardship_index']), max(df_z['hardship_index']), 4)","a5dc015c":"group_names = [\"Easy\", \"Medium\", \"High\"]\ndf_z['hardship_binned'] = pd.cut(df_z['hardship_index'], bins = bins, labels = group_names)","108d0a2e":"df_z.head()","e6b9d5af":"# One hot encoded dataframe\ndf_demo = pd.get_dummies(df_z['hardship_binned'])","374fa5c2":"# Column binding it with the original data frame\ndf_onehot = pd.concat([df_z, df_demo], axis = 1)","7a9f70fe":"df_onehot.head()","db439daf":"%%capture\n\n! pip install seaborn","a7f0eca0":"import seaborn as sns","77b1aca3":"df.columns","a6643e57":"# Using group_by (Per capita income by community area name)\nboxp = df.groupby(['comm_area_name'], as_index=False)[['comm_area_name','per_capita_income']].mean()","58575691":"from scipy import stats","d9869bcb":"#Pearson correlation coefficient\n\ndf['hardship_index'] = df['hardship_index'].replace(np.nan,mean)\npearsonr, pvalue = stats.pearsonr(df['per_capita_income'], df['hardship_index'])\nprint(\"The Pearson r is:\", pearsonr,\"and the p-value is:\", pvalue)","c68e3d74":"# pre-ANOVA grouping\n\nbins = np.linspace(df['hardship_index'].min(), df['hardship_index'].max(), 4)\ndf.drop(['hardship_binned'], inplace=True, axis = 1)\ndf['hardship_binned'] = pd.cut(df['hardship_index'], bins = bins, labels = [\"Low\", \"Medium\", \"high\"], include_lowest=True)\ngrouped = df[['hardship_binned', 'per_capita_income']].groupby(['hardship_binned'])\n\n# To get a value at 0 index of a column\ndf.at[0,'per_capita_income']","09702bb7":"grouped.get_group('Low')['per_capita_income']","6e40afbb":"# ANOVA\n\nfval, pval = stats.f_oneway(grouped.get_group('Low')['per_capita_income'], \n               grouped.get_group('Low')['per_capita_income'],\n               grouped.get_group('Low')['per_capita_income'])\nprint(\"The f val is:\", fval,\"and the p-value is\", pval)","24e25f10":"# To find the number of rows and columns of a dataframe\n\ndf.shape[0] #rows\ndf.shape[1] #columns","68ba48ad":"# To find the column names as a list\n\ndf.columns.values","53e06a9b":"<span style = \"color:Blue\">One hot encoding of the categorial variables<\/span>","636fc8f2":"<span style = \"color:Blue\">Separating the object type from the integers<\/span>","9e050cb5":"<span style = \"color:blue\">Dealing with missing values:<\/span>\n1. Ask the team which collected the data if missing values can be collected\n2. Drop missing values\n3. Replace the values with mean\/mode\n4. Leave the missing values as they are","2f6e271a":"hardship_index and comm_area_no seem to have missing values","b4fa826f":"Let us tackle the hardship_index now","6547369d":"### <span style = \"color:Blue\">The below wrangling methods will be used in this practice session:<\/span>\n1. dtypes\n2. drop()\n3. astype()\n4. rename(columns = {})\n5. min()\n6. max()\n7. mean()\n8. std()\n9. replace()\n10. isna()\n11. np.linspace()\n12. pd.cut()\n13. round()\n14. pd.to_numeric()\n15. pd.get_dummies()\n16. pd.concat([df1,df2],axis)\n17. groupby\n18. pearsonr\n19. at[]\n20. get_group()['colname']\n21. f_oneway\n22. .shape\n23. .values\n24. map()","b1286ad7":"So this is basically an incremental value which can be replaced with 78.0","4da0a98c":"<span style = \"color:Blue\">Binning the hardship index into 3 categories<\/span>","ba7c082f":"As we see, the last entry is a NaN","78dffd64":"<span style = \"color:Blue\">Basic ways of normalizing the data:<\/span>\n1. Simple Feature scaling\n2. Min-max scaling\n3. z scores","3f9e093a":"<span style = \"color:Blue\">Renaming the column names<\/span>","6e04cc2a":"Let us replace the value by its mean since the distribution is uniform","1053eb13":"Let us check the mean, median, min and max values and the skewness of the distribution","50a9515e":"<span style = \"color:Blue\">Converting all the numeric data types to float64<\/span>","974ff1e8":"The last value is NaN. Let us find what the values before it are"}}