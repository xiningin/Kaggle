{"cell_type":{"c993b1c6":"code","4433a110":"code","bb17f33a":"code","4c46f823":"code","2e164a88":"code","0e4ff1ed":"code","75f0a75a":"code","577000b0":"code","42a8cbbc":"code","3b5e9c0a":"code","2e65e2f4":"code","3ae2d150":"code","b3ae4c20":"code","8c511a26":"code","b04defe6":"code","b3871e87":"code","80225d98":"code","b1961914":"code","d0598755":"code","7bc47cfe":"code","49f5a776":"code","35f18768":"markdown","c62a0f24":"markdown","f34cf5a3":"markdown","4c42eb43":"markdown","aa4ee93e":"markdown","5ebba0db":"markdown","0d5e5b86":"markdown","38520f60":"markdown","feefeba6":"markdown","3f6bcd21":"markdown","8c6b7d31":"markdown","b1c18a05":"markdown","8219e93a":"markdown"},"source":{"c993b1c6":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4433a110":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nimport xgboost as xg\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")","bb17f33a":"data = pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")","4c46f823":"data.head()","2e164a88":"data.info()","0e4ff1ed":"data.shape","75f0a75a":"data.columns","577000b0":"data.dtypes","42a8cbbc":"data.describe()","3b5e9c0a":"labels = data['target'].value_counts()\nplt.pie(labels, labels = ['Presence','Absence'], explode = [0.1,0])\nplt.show() ","2e65e2f4":"data_cp=data['cp'].map({0:'Typical Angina',1:'Atypical Angina', 2:'Non-Anginal Pain',3:'Asymptomatic'})\nplt.figure(figsize = (10,10))\nplt.title(\"Chest Pain Types Counts\")\n    \nsns.countplot(data_cp)\nplt.show()\n\n","3ae2d150":"sns.catplot(x =\"target\",hue=\"sex\", col=\"target\",\n                data= data , kind=\"count\")\nplt.title(\"Precence Of Heart Disease By Gender\")\nplt.show()","b3ae4c20":"x = data.drop(['target'], axis = 1)\ny = data['target']","8c511a26":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3)\n\nx_train, x_val, y_train, y_val = train_test_split(x,y, test_size = 0.3)","b04defe6":"def gridSearchCrossValidation(tunedParams,\n                              scores,\n                              x_train,\n                              x_val,\n                              y_train,\n                              y_val,\n                              modelType = \"KNN\"\n                              ):\n  ###\n  ### Cross Validation for test model metric and hyper-parameter tuning\n  ### @params = {tunedParams: hyper-parameters for dataset, scores: accuracy metrics, x_train\/y_train\/x_val\/y_val: datasets, modelType: algorithm type (KNN, RF, XGB)}\n  ###\n  for score in scores:\n    print(f\"Hyper-Parameter Tuning for {score}\")\n    if modelType == \"KNN\":\n      model = GridSearchCV(KNeighborsClassifier(),\n                           tunedParams,\n                           scoring = f\"{score}\")\n    elif modelType == \"RF\":\n      model = GridSearchCV((RandomForestClassifier()),\n                           tunedParams,\n                           scoring = f\"{score}\")\n    elif modelType == \"XGB\":\n      model = GridSearchCV(xg.XGBClassifier(),\n                           tunedParams,\n                           scoring = f\"{score}\")\n    \n    model.fit(x_train, y_train)\n    print(\"Best parameters set found on development set:\")\n    print(model.best_params_)\n    print(\"Grid scores on development set:\")\n    means = model.cv_results_['mean_test_score']\n    stds = model.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n        print(\"%0.3f (+\/-%0.03f) for %r\"\n              % (mean, std * 2, params))\n    print(\"Detailed classification report:\")\n    y_true, y_pred = y_val, model.predict(x_val)\n    print(classification_report(y_true, y_pred))","b3871e87":"tunedParams = [{\"n_neighbors\": [3,5,7],\n                \"weights\": [\"uniform\", \"distance\"],\n                \"p\": [1,2]}]","80225d98":"scores = [\"accuracy\",\"precision_macro\",\"recall_macro\"]\n\ngridSearchCrossValidation(tunedParams, scores, x_train , x_val, y_train, y_val)","b1961914":"tunedParams = [{\"min_child_weight\": [5, 10],\n                \"colsample_bytree\": [0.6, 0.8]}]\nscores = [\"accuracy\",\"precision_macro\",\"recall_macro\"]\ngridSearchCrossValidation(tunedParams,\n                          scores,\n                          x_train,\n                          x_val,\n                          y_train,\n                          y_val,\n                          modelType = \"XGB\")","d0598755":"tunedParams = [{\"n_estimators\": [10, 50, 100],\n                \"criterion\": [\"gini\", \"entropy\"],\n                \"max_features\": [\"auto\", \"sqrt\", \"log2\"]}]\nscores = [\"accuracy\"]","7bc47cfe":"gridSearchCrossValidation(tunedParams,\n                          scores,\n                          x_train,\n                          x_val,\n                          y_train,\n                          y_val,\n                          modelType = \"RF\")","49f5a776":"model = XGBClassifier(colsample_bytree = 0.8, min_child_weight = 5)\nmodel.fit(x_train,y_train)\nmodel.score(x_test,y_test)","35f18768":"In the function below, there are 3 machine learning algorithms. These are K-Neighbors Classifier, Random Forest Classifier and XGBoost Classifier. When I run this function, we can see the scores we will get when we apply these algorithms to the data and we can choose an algorithm accordingly.","c62a0f24":"# Importing Libraries","f34cf5a3":"# Model","4c42eb43":"# Visualization ","aa4ee93e":"# Information About Data","5ebba0db":"![485800-Heart-Disease-Facts-Statistics-and-You-1200x628-Facebook.png](attachment:b81f6e13-1eea-4b53-84c3-aaa08a3cfbd2.png)","0d5e5b86":"# For Random Forest","38520f60":"# For KNN","feefeba6":"This dataset contains 14 columns and uses absence and presence of disease as the target column. These columns contain data that plays an important role in heart disease, such as age, gender, cholesterol, type of chest pain. So I created a model in this notebook that predicts whether a person has a heart disease or not.","3f6bcd21":"# For XGBoost ","8c6b7d31":"# Grid Search","b1c18a05":"# Heart Disease Prediction","8219e93a":"# Train-Test Split"}}