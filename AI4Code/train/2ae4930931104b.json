{"cell_type":{"c6ce3f36":"code","c30dc67e":"code","e7897a9b":"code","cab41392":"code","b8993e33":"code","a1fcc658":"code","948c03cd":"code","92ba6678":"code","80282392":"code","0600ef74":"code","157ab3ad":"code","9b879aa6":"code","8d0cb79f":"code","3cee5fd8":"code","2ab45960":"code","8eb69081":"code","9e2b2ca2":"code","a9449866":"code","91ece084":"code","29a07229":"code","692135dc":"code","e4dce51b":"code","26de2537":"code","e7895df3":"code","a856bb70":"code","3b63a841":"code","dd30ff4c":"code","120a0194":"code","31320032":"code","6e0ace9b":"code","93460fda":"markdown","d063ec8f":"markdown"},"source":{"c6ce3f36":"import re\nimport os\nimport cv2\nimport csv              \nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL  import  Image\nimport matplotlib.pyplot as plt","c30dc67e":"train=pd.read_csv('..\/input\/global-wheat-detection\/train.csv')\nsample_output = pd.read_csv('..\/input\/global-wheat-detection\/sample_submission.csv')\ntrain_dir = '..\/input\/global-wheat-detection\/train\/'\ntest_dir ='..\/input\/global-wheat-detection\/test\/'","e7897a9b":"train.head()","cab41392":"df = pd.read_csv('..\/input\/global-wheat-detection\/train.csv')\nbboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\nfor i, column in enumerate(['xmin', 'ymin', 'w', 'h']):\n    df[column] = bboxs[:,i]\n\ndf.drop(columns=['bbox'], inplace=True)\ndf['xmax'] = df['xmin'] + df['w']\ndf['ymax'] = df['ymin'] + df['h']\n# df['x_center'] = df['xmin'] + df['w']\/2\n# df['y_center'] = df['ymin'] + df['h']\/2\n\ndf['classes'] = 0\ndf = df[['image_id','xmin', 'ymin','xmax', 'ymax', 'w', 'h','classes']]\ndf.head()","b8993e33":"# exporting cleaned dataframe\ndf.to_csv(\"data.csv\")","a1fcc658":"index = list(set(df.image_id))\n# print(index)","948c03cd":"import shutil\ntry:\n    shutil.copytree('..\/input\/global-wheat-detection\/train','.\/images','.\/images')\nexcept:\n  print(\"error or maybe file Already exsist\")","92ba6678":"from pathlib import Path\nPath(\".\/annots\").mkdir(parents=True, exist_ok=True)","80282392":"f = open('.\/data.csv')\ncsv_f = csv.reader(f)   \ndata = []\n\nfor row in csv_f: \n   data.append(row)\nf.close()\nprint(data[:4])","0600ef74":"import xml.etree.ElementTree as gfg \nf = open('.\/data.csv')\ncsv_f = csv.reader(f)   \ndata = []\n\nfor row in csv_f: \n   data.append(row)\nf.close()\n\ndef GenerateXML(annots_dir,img_dir,image_id) :\n    fileName = image_id+\".xml\"\n    root = gfg.Element(\"annotation\") \n\n    b1 = gfg.SubElement(root, \"folder\")\n    b1.text = \"wheat_heads\"\n    b2 = gfg.SubElement(root, \"filename\") \n    b2.text = image_id+\".jpg\"\n    b3 = gfg.SubElement(root, \"path\") \n    b3.text = img_dir+image_id+\".jpg\"\n    \n    m3 = gfg.Element(\"size\") \n    root.append (m3) \n    \n    d1 = gfg.SubElement(m3, \"width\") \n    d1.text = \"1024\"\n    d2 = gfg.SubElement(m3, \"height\") \n    d2.text = \"1024\"\n    d3 = gfg.SubElement(m3, \"depth\") \n    d3.text = \"3\"\n\n    for row in data[1:] :\n        if row[1]== image_id:\n\n            m4 = gfg.Element(\"object\") \n            root.append (m4) \n            \n            d1 = gfg.SubElement(m4, \"name\") \n            d1.text = \"wheat_head\"\n            \n            m5=gfg.Element(\"bndbox\")\n            m4.append(m5)\n            d1 = gfg.SubElement(m5,\"xmin\")\n            d1.text= str(int(float(row[2])))\n            d2 = gfg.SubElement(m5,\"ymin\")\n            d2.text= str(int(float(row[3])))\n            d3 = gfg.SubElement(m5,\"xmax\")\n            d3.text= str(int(float(row[4])))\n            d4 = gfg.SubElement(m5,\"ymax\")\n            d4.text= str(int(float(row[5])))\n\n    tree = gfg.ElementTree(root) \n    \n    with open (annots_dir+fileName, \"wb\") as files :\n        tree.write(files)","157ab3ad":"# os.listdir('.\/images')","9b879aa6":"#wait for a long time\nfor image_id in index:\n    GenerateXML(\".\/annots\/\",\".\/images\/\", image_id) ","8d0cb79f":"## count xml files\n# os.listdir('.\/annots')\n\ni=0\nfor j in (os.listdir('.\/annots')):\n    i+=1\nprint(i)","3cee5fd8":"from PIL  import  Image\nimg = Image.open('.\/images\/7f01525b1.jpg')\nplt.imshow(img)","2ab45960":"!git clone https:\/\/github.com\/mmaithani\/Mask_RCNN.git","8eb69081":"cd Mask_RCNN","9e2b2ca2":"!python setup.py install","a9449866":"!pip install imutils\nfrom mrcnn.config import Config\nfrom mrcnn import model as modellib\nfrom mrcnn import visualize\nimport mrcnn\nfrom mrcnn.utils import Dataset\nfrom mrcnn.model import MaskRCNN\nimport numpy as np\nfrom numpy import zeros\nfrom numpy import asarray\nimport colorsys\nimport argparse\nimport imutils\nimport random\nimport cv2\nimport os\nimport time\nfrom matplotlib import pyplot\nfrom matplotlib.patches import Rectangle\nfrom keras.models import load_model\n%matplotlib inline\nfrom os import listdir\nfrom xml.etree import ElementTree","91ece084":"class myMaskRCNNConfig(Config):\n    # give the configuration a recognizable name\n    NAME = \"MaskRCNN_config\"\n \n    # set the number of GPUs to use along with the number of images\n    # per GPU\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n \n    # number of classes (we would normally add +1 for the background)\n     # kangaroo + BG\n    NUM_CLASSES = 1+1\n   \n    # Number of training steps per epoch\n    STEPS_PER_EPOCH = 131\n    \n    # Learning rate\n    LEARNING_RATE=0.006\n    \n    # Skip detections with < 90% confidence\n    DETECTION_MIN_CONFIDENCE = 0.9\n    \n    # setting Max ground truth instances\n    MAX_GT_INSTANCES=10","29a07229":"config = myMaskRCNNConfig()","692135dc":"config.display()","e4dce51b":"class WheatData(Dataset):\n    # load the dataset definitions\n    def load_dataset(self, dataset_dir, is_train=True):\n\n        # Add classes. We have only one class to add.\n        self.add_class(\"dataset\", 1, \"wheat_head\")\n        \n        # define data locations for images and annotations\n        images_dir = '.\/images\/'\n        annotations_dir = '.\/annots\/'\n        \n        # Iterate through all files in the folder to \n        #add class, images and annotaions\n        for filename in listdir(images_dir):\n            \n            # extract image id\n            image_id = filename[:-4]\n            \n#             # skip bad images\n#             if image_id in ['00090']:\n#                 continue\n#             # skip all images after 150 if we are building the train set\n#             if is_train and int(image_id) >= 150:\n#                 continue\n\n           # setting image file\n            img_path = images_dir + filename\n            \n            # setting annotations file\n            ann_path = annotations_dir + image_id + '.xml'\n            \n            # adding images and annotations to dataset\n            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n# extract bounding boxes from an annotation file\n    def extract_boxes(self, filename):\n        \n        # load and parse the file\n        tree = ElementTree.parse(filename)\n        # get the root of the document\n        root = tree.getroot()\n        # extract each bounding box\n        boxes = list()\n        for box in root.findall('.\/\/bndbox'):\n            xmin = int(box.find('xmin').text)\n            ymin = int(box.find('ymin').text)\n            xmax = int(box.find('xmax').text)\n            ymax = int(box.find('ymax').text)\n            coors = [xmin, ymin, xmax, ymax]\n            boxes.append(coors)\n        \n        # extract image dimensions\n        width = int(root.find('.\/\/size\/width').text)\n        height = int(root.find('.\/\/size\/height').text)\n        return boxes, width, height\n# load the masks for an image\n    \"\"\"Generate instance masks for an image.\n       Returns:\n        masks: A bool array of shape [height, width, instance count] with\n            one mask per instance.\n        class_ids: a 1D array of class IDs of the instance masks.\n     \"\"\"\n    def load_mask(self, image_id):\n        # get details of image\n        info = self.image_info[image_id]\n        \n        # define anntation  file location\n        path = info['annotation']\n        \n        # load XML\n        boxes, w, h = self.extract_boxes(path)\n       \n        # create one array for all masks, each on a different channel\n        masks = zeros([h, w, len(boxes)], dtype='uint8')\n        \n        # create masks\n        class_ids = list()\n        for i in range(len(boxes)):\n            box = boxes[i]\n            row_s, row_e = box[1], box[3]\n            col_s, col_e = box[0], box[2]\n            masks[row_s:row_e, col_s:col_e, i] = 1\n            class_ids.append(self.class_names.index('kangaroo'))\n        return masks, asarray(class_ids, dtype='int32')\n# load an image reference\n#      \"\"\"Return the path of the image.\"\"\"\n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        print(info)\n        return info['path']","26de2537":"cd ..","e7895df3":"os.getcwd()","a856bb70":"os.listdir(train_dir)","3b63a841":"# prepare train set\ntrain_set = WheatData()\ntrain_set.load_dataset(\".\/\", is_train=True)\ntrain_set.prepare()\nprint('Train: %d' % len(train_set.image_id))\n\n# prepare test\/val set\ntest_set = WheatData()\ntest_set.load_dataset(\".\/\", is_train=False)\ntest_set.prepare()\nprint('Test: %d' % len(test_set.image_id))","dd30ff4c":"print(\"Loading Mask R-CNN model...\")\nmodel = modellib.MaskRCNN(mode=\"training\", config=config, model_dir='.\/')","120a0194":"os.listdir('.\/Mask_RCNN')","31320032":"#load the weights for COCO\nmodel.load_weights('.\\\\Mask_RCNN\\\\mask_rcnn_coco.h5', \n                   by_name=True, \n                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])","6e0ace9b":"## train heads with higher lr to speedup the learning\nmodel.train(train_set, test_set, learning_rate=2*config.LEARNING_RATE, epochs=5, layers=\u2019heads\u2019)\nhistory = model.keras_model.history.history","93460fda":"# Creating Required annotation file\n* each image has corresponding annotation file -[image_id.xml] contain bbox elements\n* we will feed the inputs as they were expected no change in Mast R-cnn config","d063ec8f":"## XML file conversion code"}}