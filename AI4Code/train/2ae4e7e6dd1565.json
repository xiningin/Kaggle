{"cell_type":{"d64ee920":"code","4fb3d9a7":"code","0a2c7249":"code","6917835f":"code","78ed212e":"code","9f831f70":"code","16b40d49":"code","5c634d6d":"code","153448af":"code","93a60d03":"code","b61cd2b7":"code","988e12d2":"code","ad05b182":"code","e9507da1":"code","33aa0e06":"code","ad0bd49d":"code","50143e86":"code","d7774c10":"code","417dfa41":"code","c3c704d0":"code","619a4187":"code","3514882e":"code","16275264":"code","75c67164":"code","7ac02c61":"code","774c0212":"code","412a5e34":"code","667d2147":"code","a8aa9dc6":"code","6b0bb152":"code","2a07e502":"code","ffdc27d5":"code","03a95924":"code","8bc0fcf8":"markdown","1cf284a2":"markdown","2881e840":"markdown","a422c37a":"markdown","9e797eee":"markdown","58872797":"markdown","6a1357ac":"markdown","454f3ba3":"markdown"},"source":{"d64ee920":"import math\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns \nimport matplotlib \nimport matplotlib.pyplot as plt\n%matplotlib inline\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\n\nimport missingno as msno\n\n# !pip install xlrd\n\n# !pip install autoviz\nfrom autoviz.AutoViz_Class import AutoViz_Class\n\n# !pip install dtale\nimport dtale\n\nimport folium\nfrom folium.plugins import MarkerCluster\n\nfrom scipy import stats\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4fb3d9a7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0a2c7249":"#Check the shape of the dataset after loading it.\ndf = pd.read_csv('\/kaggle\/input\/zameencom-property-data-pakistan\/Property_with_Feature_Engineering.csv')\ndf.shape","6917835f":"df.sample(5)","78ed212e":"df1 = df.drop(['property_id', 'location_id', 'page_url', 'area', 'area_marla', 'locality', 'agency', 'agent'], axis='columns')\ndf1.shape","9f831f70":"#Remove the day and save it in the date_added column.\ndf1['date_added'] = pd.to_datetime(df1['date_added'])\ndf1 = df1.reset_index()\ndf1['date_added'] = df1['date_added'].apply(lambda x: x.strftime('%Y-%m'))","16b40d49":"#This function removes outliers from one or more columns.\ndef remove_outlier(df, column_lst):\n    df_in = df\n    for col in column_lst:\n        q1 = df_in[col].quantile(0.25)\n        q3 = df_in[col].quantile(0.75)\n        iqr = q3-q1\n        fence_low  = q1-1.5*iqr\n        fence_high = q3+1.5*iqr\n        df_in = df_in.loc[(df_in[col] > fence_low) & (df_in[col] < fence_high)]\n    return df_in","5c634d6d":"#Boxplots from one or more columns are shown using this function.\ndef show_graphs(df, lst, title=\"\"):\n    if len(lst) > 1:\n        fig, axs = plt.subplots(1, len(lst), figsize=(16, 5))\n        for i in range(0, len(lst)):\n            axs[i].boxplot(df[lst[i]])\n            axs[i].set_title(lst[i])\n        fig.suptitle(title)\n    else:\n        fig, axs = plt.subplots(figsize=(16, 8))\n        axs.boxplot(df[lst[0]])\n        axs.set_title(lst[0])\n        fig.suptitle(title)","153448af":"#Examine the values that are missing.\nmsno.matrix(df1)","93a60d03":"df1.sample(5)","b61cd2b7":"#Check the Outliers\nshow_graphs(df1,['price','baths','area_sqft'])","988e12d2":"#Remove Ouliers\ndf2 = remove_outlier(df1, ['price','baths','area_sqft'])","ad05b182":"#Check the Outliers\nshow_graphs(df2,['price','baths','area_sqft'])","e9507da1":"#Add a column called price_per_sqft that contains price divided area_sqft values.\ndf3 = df2.copy()\ndf3['price_per_sqft'] = df2['price']\/df2['area_sqft']","33aa0e06":"#Check the Outliers\nshow_graphs(df3,['price', 'area_sqft', 'price_per_sqft'])","ad0bd49d":"#Remove Outliers\ndf4 = remove_outlier(df3, ['price_per_sqft'])","50143e86":"#Check the Outliers\nshow_graphs(df4,['price', 'area_sqft', 'price_per_sqft'])","d7774c10":"df4.to_csv(\"df4.csv\",index=False)","417dfa41":"#EDA using Autoviz\nautoviz = AutoViz_Class().AutoViz('df4.csv')","c3c704d0":"#EDA using dtale Lib\ndtale.show(df4)","619a4187":"# Remove outliers\nindex = df4[(df4['baths']==0) & (df4['bedrooms']>1)].index\ndf5 = df4.drop(index) \n\nindex = df5[(df5['property_type']=='Room') & ((df5['baths']>1) | (df5['bedrooms']>1))].index\ndf6 = df5.drop(index)\n\nindex = df6[(df6['bedrooms']==0)].index\ndf7 = df6.drop(index)\n\nindex = df7[((df7['bedrooms'])+3)<df7['baths']].index\ndf8 = df7.drop(index)","3514882e":"#Remove outliers from Square Feet, Bedrooms and bathrooms\ndef remove_outliers(df,p_type,area,bedrooms,baths):\n    sqft = np.sort(df[area].unique())\n    for sq in sqft:\n        rooms = int(((0.5*sq)\/171)+2)\n        df.loc[(df[p_type]!='Room') & (df[area]==sq) & (df[bedrooms]>rooms), [bedrooms]] = rooms\n        df.loc[(df[p_type]!='Room') & (df[area]==sq) & (df[baths]>(rooms+2)), [baths]] = rooms+2\n\nremove_outliers(df8,'property_type','area_sqft','bedrooms','baths')","16275264":"#The available data includes both selling and renting items, but I'm only interested in selling items because buyers are aware of the true value of homes, flats, and other properties based on location and rooms.\n#That's why i drop the Rental Rows and save into df9 \nindex = df8[df8['purpose']=='For Rent'].index\ndf9 = df8.drop(index)\n\n#Since there are so many outliers in the price_bin column, it should be removed.\ndf10 = df9.drop(['price_bin'], axis='columns')\n\n#Add a price_bin column based on this criterion.\ndf10['price_bin'] = 'Low'\ndf10.loc[(df10['price']>2500000) & (df10['price']<=5000000),['price_bin']] = 'Medium'\ndf10.loc[(df10['price']>5000000) & (df10['price']<=10000000),['price_bin']] = 'High'\ndf10.loc[(df10['price']>10000000),['price_bin']] = 'Very High'\n\n#Drop below 50 thousand price rows\ndf11 = df10[df10['price']>50000]","75c67164":"#Check the Outliers\nshow_graphs(df11,['price', 'area_sqft', 'price_per_sqft'])\n\n#These columns are now better at predicting unseen data by using machine learning algorithms.","7ac02c61":"def selling_by_date(df):\n    df = df.sort_values(by=\"date_added\")\n    date = df['date_added'].unique()\n    p_type_dict = {}\n    grouped_p_type = df.groupby('property_type')\n    for pt in grouped_p_type.groups.keys():\n        lst = []\n        for dt in date:\n            df_dt = df[(df[\"date_added\"] == dt) & (df['property_type']==pt)]\n            df_dt_sum = len(df_dt)\n\n            if df_dt_sum > 0:\n                lst.append(df_dt_sum)\n            else:\n                lst.append(0)\n        p_type_dict[pt] = lst\n    \n    return date, p_type_dict","774c0212":"labels, p_type = selling_by_date(df11)\n\nx = np.arange(len(labels))\nwidth = 0.35\nfig, ax = plt.subplots(len(p_type), 1, figsize=(16, 60),)\ncount = 0 \nfor pt in p_type.keys():\n    ax[count].plot(x - width\/2, p_type.get(pt), label = pt)\n    ax[count].set_xticks(x)\n    ax[count].set_xticklabels(labels, rotation=90)\n    ax[count].legend()\n    count+=1\n\n    \nplt.show()","412a5e34":"def heatMap(df):\n    #Create Correlation df\n    corr = df.corr()\n    #Plot figsize\n    fig, ax = plt.subplots(figsize=(20, 10))\n    #Generate Color Map\n    colormap = sns.diverging_palette(220, 10, as_cmap=True)\n    #Generate Heat Map, allow annotations and place floats in map\n    sns.heatmap(corr, cmap=colormap, annot=True, fmt=\".2f\")\n    #Apply xticks\n    plt.xticks(range(len(corr.columns)), corr.columns);\n    #Apply yticks\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    #show plot\n    plt.show()\n    \nheatMap(df11)","667d2147":"dummy1 = pd.get_dummies(df11.property_type)\ndummy2 = pd.get_dummies(df11.price_bin)\ndummy3 = pd.get_dummies(df11.location)\ndummy4 = pd.get_dummies(df11.city)\ndummy5 = pd.get_dummies(df11.province_name)\n\ndf12 = pd.concat([df11.drop(['property_type','price_bin','location','latitude','longitude','city','province_name','purpose','date_added','year','month','day'], axis='columns'),dummy1,dummy2,dummy3,dummy4,dummy5],axis='columns')\ndf12.sample(5)","a8aa9dc6":"X = df12.drop(['price'], axis='columns')\ny = df12.price","6b0bb152":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)","2a07e502":"# create a regressor object\nregressor = DecisionTreeRegressor(random_state = 0) \n  \n# fit the regressor with X and Y data\nregressor.fit(X, y)","ffdc27d5":"def predict_price(location,baths,area_sqft,bedrooms):    \n    loc_index = np.where(X.columns==location)[0][0]\n    x = np.zeros(len(X.columns))\n    x[0] = baths\n    x[1] = area_sqft\n    x[2] = bedrooms\n    if loc_index >= 0:\n        x[loc_index] = 1\n    return regressor.predict([x])[0]","03a95924":"#First argument is location\n#Second argument is bathrooms\n#Third argument is area of square feet\n#Last and fourth argument is bedrooms\nprint(\"Rs:\",predict_price('Bahria Town Karachi',5, 2778, 5))","8bc0fcf8":"### Visualization","1cf284a2":"##### By date, sell a house, a farm house, a flat, and other things.","2881e840":"<p><strong><span style=\"font-size: 20px; color: rgb(124, 112, 107);\">Background<\/span><\/strong><\/p>\n<p><span style=\"color: rgb(0, 0, 0);\">The data obtained from Kaggle. Propertyid, location_id, page_url property_type, price, location, city, province_name, latitude, longitude, baths, area, pupose, bedrooms, date_added,agency, and agent are all included in the dataset. This data spans the periods 2018-8 to 2019-8.<\/span><\/p>","a422c37a":"<h1 style='color:purple' align='center'>Thank you so much for taking the time to look at my notebook. Please upvote if you like my Notebook.<h1\/>","9e797eee":"### EDA","58872797":"### Build a Machine Learning Model","6a1357ac":"### Use one Hot Encoding","454f3ba3":"### Test the Model"}}