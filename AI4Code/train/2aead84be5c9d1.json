{"cell_type":{"3fff273d":"code","8c7ccad8":"code","fbaedfaf":"code","dfc27ff9":"code","605ae5c2":"markdown","ee5f6cd7":"markdown","0319365b":"markdown"},"source":{"3fff273d":"\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBRegressor, XGBClassifier\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Set up code checking\nimport os\nif not os.path.exists(\"..\/input\/train.csv\"):\n    os.symlink(\"..\/input\/home-data-for-ml-course\/train.csv\", \"..\/input\/train.csv\")  \n    os.symlink(\"..\/input\/home-data-for-ml-course\/test.csv\", \"..\/input\/test.csv\") \nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex7 import *\n\n# Path of the file to read. We changed the directory structure to simplify submitting to a competition\niowa_file_path = '..\/input\/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)\n\n\n#create y\ny =home_data.SalePrice\n\n# Create X\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'BedroomAbvGr','HouseStyle', \n            'TotRmsAbvGrd','GarageCars','KitchenAbvGr','FullBath','GrLivArea','MSZoning',\n            'TotalBsmtSF','GarageYrBlt','GarageType','ScreenPorch','SaleCondition','BsmtUnfSF','HouseStyle',\n            'RoofStyle','Neighborhood','BsmtFinSF1','BsmtQual','LowQualFinSF','FireplaceQu','Fireplaces',\n            'YearRemodAdd','OverallCond','OverallQual','YrSold']\n\n\nX = home_data[features]\n\n#dealing with missing data \n\nfrom sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer(strategy='constant') #constant is the best strategy to be used here\n\n\n\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n#to deal with categorical data, get_dummies\none_hot_encoded_training_predictors = pd.get_dummies(train_X)\none_hot_encoded_test_predictors = pd.get_dummies(val_X)\nfinal_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n                                                                    join='left', \n                                                                    axis=1)\n\n\n\n# print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n# print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())\n\n\n\n#imputing missing values\nimputed_X_train = my_imputer.fit_transform(final_train)\nimputed_X_test = my_imputer.transform(final_test)\n\n\n# Specify Model\niowa_model = DecisionTreeRegressor(random_state=1)\n\n\n# Fit Model\niowa_model.fit(imputed_X_train, train_y)\n\n\n\n# Make validation predictions and calculate mean absolute error\nval_predictions = iowa_model.predict(imputed_X_test)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n\n\n# Using best value for max_leaf_nodes\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\niowa_model.fit(imputed_X_train, train_y)\nval_predictions = iowa_model.predict(imputed_X_test)\n\n#getiing mean absolute error\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n\n\n#Logistic regressor (it takes much time and didn't produce good result)\n# from sklearn.linear_model import LogisticRegression\n# lr_model=LogisticRegression().fit(imputed_X_train,train_y)\n# lr_predictions=lr_model.predict(imputed_X_test)\n# lr_mae=mean_absolute_error(lr_predictions,val_y)\n# print('validation mae for LR model: {:,.0f}'.format(lr_mae))\n\n\n# Random forest regressor\nrf_model = RandomForestRegressor(random_state=1)\nrf_model.fit(imputed_X_train, train_y)\nrf_val_predictions = rf_model.predict(imputed_X_test)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n\n\n\n#XGBREGRESSOR model\nxgbr= XGBRegressor(n_estimators=1150,learning_rate=0.05)\nxgbr.fit(imputed_X_train, train_y)\npredicts=xgbr.predict(imputed_X_test)\nxgbr_mae=mean_absolute_error(predicts,val_y)\nprint(\"Validation MAE for XGBRegressor Model: {:,.0f}\".format(xgbr_mae))","8c7ccad8":"#dealing with missing values and categorical data\none_hot_encoded_training_predictors = pd.get_dummies(X)\nimputed_X_train = my_imputer.fit_transform(one_hot_encoded_training_predictors)\n\n#defining a XGBR model\n\nxgbr= XGBClassifier(n_estimators=1000,learning_rate=0.05)\nxgbr.fit(imputed_X_train, y)\n","fbaedfaf":"# path to file you will use for predictions\ntest_data_path = '..\/input\/test.csv'\n\n# read test data file using pandas\ntest_data = pd.read_csv(test_data_path)\n\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\ntest_X = test_data[features]\n\n","dfc27ff9":"#dealing with categorical values\none_hot_encoded_training_predictors = pd.get_dummies(X)\none_hot_encoded_test_predictors = pd.get_dummies(test_X)\n\nfinal_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n                                                                    join='left', \n                                                                    axis=1)\n\n#dealing with missing values\nimputed_X_train = my_imputer.fit_transform(final_train)\nimputed_X_test = my_imputer.transform(final_test)\n# fit rf_model_on_full_data on all data from the training data\nxgbr.fit(imputed_X_train,y)\n\n\n\n# make predictions which we will submit. \npredicts=xgbr.predict(imputed_X_test)\n\n#submit\n\n\noutput = pd.DataFrame({'Id': test_data.Id,\n                      'SalePrice': predicts})\noutput.to_csv('submission.csv', index=False)","605ae5c2":"Here I build an XGBR model and also shown comparison with some other models \n\nIf it takes time to run then\nTurn on GPU from top right corner of the Option tab in accelerator bar just left to restart session button","ee5f6cd7":"# Make Predictions\nRead the file of \"test\" data. And apply your model to make predictions","0319365b":"# Submitting the model\n\nAs the XGBR gives the best result we will use it"}}