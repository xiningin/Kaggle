{"cell_type":{"3ca1fdc1":"code","25680942":"code","847fb311":"code","b2ad8489":"code","631839f6":"code","039d8933":"code","ade85683":"code","ad61a0c3":"code","c1cd1364":"code","fefed041":"code","759ed111":"code","8b6ca490":"code","2d863c2c":"code","e5d10b87":"code","cb21c195":"code","327899c8":"code","4d521304":"code","6d506763":"code","059258e2":"code","5d189a98":"code","54c0df3c":"code","f0f8d78a":"markdown","505923d5":"markdown","e49b412e":"markdown","200838a8":"markdown","61f0ad87":"markdown","200c8949":"markdown","9fc568b9":"markdown","b28bea59":"markdown","c80b3cac":"markdown","5fb10583":"markdown","b42ccdf0":"markdown","498eaf6b":"markdown","75d6479a":"markdown","1d0851b0":"markdown","daa303c1":"markdown","144817e6":"markdown","ef109ff4":"markdown","2904949f":"markdown","9590e238":"markdown","23fe74c0":"markdown","b36dd70b":"markdown"},"source":{"3ca1fdc1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action='ignore')\nplt.style.use(['seaborn-bright','dark_background'])","25680942":"data = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndata.head()","847fb311":"data.isnull().sum()","b2ad8489":"data.info()","631839f6":"data.nunique()","039d8933":"correlation = data.corr()\ncorrelation","ade85683":"sns.set(rc = {'figure.figsize':(8,8)})\nsns.heatmap(correlation,cmap=\"PiYG\")\nplt.title(\"Heatmap\")\nplt.show()","ad61a0c3":"X = data.drop(columns=['DEATH_EVENT'])\nY = data['DEATH_EVENT']","c1cd1364":"from sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\ncolumn = X.columns\nscaled_X = scale.fit_transform(X)\nscaled_X = pd.DataFrame(scaled_X,columns=column)\nscaled_X.head()","fefed041":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(scaled_X,Y,test_size=0.2,random_state=101)","759ed111":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble  import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier","8b6ca490":"models = []\nmodels.append((\"LogisticRegression\",LogisticRegression()))\nmodels.append((\"DescisionTree\",DecisionTreeClassifier()))\nmodels.append((\"RandomForest\",RandomForestClassifier()))\nmodels.append((\"SupportVector\",SVC()))\nmodels.append((\"KNeighbors\",KNeighborsClassifier()))","2d863c2c":"for name,model in models:\n    model.fit(X_train,Y_train)\n    train_score = model.score(X_train,Y_train)\n    test_score = model.score(X_test,Y_test)\n    print(name,\"train score =\",train_score)\n    print(name,\"test score =\",test_score)","e5d10b87":"for i in range(1,20):\n    model = RandomForestClassifier(max_depth=i)\n    model.fit(X_train,Y_train)\n    score = model.score(X_test,Y_test)\n    print(\"for max depth \",i,\"score =\",score)","cb21c195":"model = RandomForestClassifier(max_depth=3)\nmodel.fit(X_train,Y_train)\nprediction = model.predict(X_test)\nprobablities = model.predict_proba(X_test)\nmodel.score(X_test,Y_test)","327899c8":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(Y_test,prediction))","4d521304":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test,prediction))","6d506763":"from sklearn.metrics import precision_recall_curve\nprecision_points, recall_points, threshold_points = precision_recall_curve(Y_test,probablities[:,1])\nprecision_points.shape, recall_points.shape, threshold_points.shape","059258e2":"plt.style.use(['seaborn-dark','dark_background'])\nplt.figure(dpi =100, figsize=(6,6))\nplt.plot(threshold_points, precision_points[:-1], color = 'r', label = 'Precision')\nplt.plot(threshold_points, recall_points[:-1], color = 'b', label = 'Recall')\nplt.xlabel('Threshold')\nplt.ylabel('Frequency')\nplt.title('Precision-Recall Curve')\nplt.legend()\nplt.show()","5d189a98":"from sklearn.metrics import roc_curve,roc_auc_score\nfpr, tpr, threshold = roc_curve(Y_test ,probablities[:,1])","54c0df3c":"plt.style.use(['seaborn-dark','dark_background'])\nplt.figure(dpi = 100, figsize=(8,6))\nplt.plot(fpr,tpr, color = 'r', label='FPR-TPR')\nplt.plot([0,1],[0,1], color = 'g', label = 'Baseline')\nplt.title('AUC-ROC Curve')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend()\nplt.show()","f0f8d78a":"#### Here in our dataset DEATH EVENT is our dependent feature which consists of binary values so it will be classification problem and we will consider it as our target variable. Also, other  features are our independent variable.\n\n### Cheacking null values if any present in our dataset.","505923d5":"### Cheacking data type of all features present in our data set","e49b412e":"#### Creating classification report","200838a8":"#### For max depth 3 it gives maximum score","61f0ad87":"## Importing required dataset of heart failure record downloaded from the Kaggle dataset.","200c8949":"#### Scaling the X dataset","9fc568b9":"### Finding  number of unique values present in each feature.","b28bea59":"#### It looks like Random Forest leads score comparision on our dataset against logistic regression,descisiontree,svm and KNN.","c80b3cac":"### For better visualization ploting a heatmap with the seaborn library.","5fb10583":"## Ploting AUC-ROC curve","b42ccdf0":"#### In our dataset features like anaemia,diabetes,high_blood_pressure,sex,smoking consists of bianary values just because they consists only two unique values.","498eaf6b":"#### Dividing out data into two parts as independent variables and target variable.","75d6479a":"#### Creating confusion matrix","1d0851b0":"## Importing required libraries","daa303c1":"#### Visualization of correlation between independent features and target variable.","144817e6":"### We have created a model using RandomForestClassifier with accuracy score 0.934 i.e 93.4%","ef109ff4":"#### Spliting data as train and test data.","2904949f":"#### Importing the different classification models for compairing score with each other.","9590e238":"## Ploting the Precision-Recall Curve","23fe74c0":"### It seems like the feature age and serum creatinine has little bit positive correlation and ejection fraction also has little negetive correlation on death event, on other hand time has better negetive correlation with target.But others features dosen't impact that much.","b36dd70b":"#### Cheacking score of our Random Forest model on our test data set for different max_depth."}}