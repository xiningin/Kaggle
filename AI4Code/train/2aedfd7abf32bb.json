{"cell_type":{"e85cd479":"code","b368343c":"code","50f93038":"code","2e513e66":"code","05de6d0b":"code","a661d6a5":"code","cb580577":"code","54eeafd1":"code","106f7b2f":"code","e38dcc57":"code","bd95cf01":"code","3bb999e5":"code","16659836":"code","972bb3ed":"code","6333d2bc":"code","3a3dcf3c":"code","6a740b9d":"code","073b8367":"code","2d43e364":"code","dda4a6ac":"code","ed72f0ca":"code","e3497962":"code","e3911e6d":"code","8fcc7a71":"code","e7fe2b5d":"code","ce1b927c":"code","0004993a":"code","078ef1e1":"code","0a6897f4":"code","cd39cf90":"code","ec6cb454":"code","92e360d3":"code","2332423a":"code","5fbd02f8":"code","e9cfdb59":"code","d1aa8a34":"code","c6b51dea":"code","352db6fa":"code","bb49bb58":"code","585e9f35":"code","ff5c79df":"code","b8a9f64a":"code","81615b66":"code","d27f15a9":"code","ef5418df":"code","0acc24db":"code","6a926b01":"code","38866817":"code","c607e5fd":"code","eea58662":"code","d9f32d41":"code","3ff67ff0":"code","60061958":"code","cb0119f2":"code","dc74bd2b":"code","ef10193c":"code","c08ba639":"code","0bbd3646":"code","21b41416":"code","25557fdc":"code","4413b72b":"code","67393f30":"code","362bb1af":"code","77027f06":"code","0cd6cc19":"code","cd326943":"code","fa2a7f3b":"code","f7e316b6":"code","3aa2bd53":"code","419b58e9":"code","3fd3c01e":"code","41406005":"code","60c3edb2":"code","fcbffd60":"code","422265a0":"code","b79d979a":"code","97e80754":"code","7a7d03d1":"code","c471e10e":"code","e4026972":"code","227bcf48":"code","f78040b9":"code","52f71722":"code","fcf62aca":"code","b634a84a":"code","c13c5395":"code","155d64a3":"code","b5f05c52":"code","a2c50054":"code","d07126a0":"code","6457cee1":"code","a93c7423":"code","cb273fb1":"code","8aac22f9":"code","0718f6f0":"code","e61eafec":"code","ebb5a29a":"code","d1e658a6":"code","302d3ef5":"code","44b45dbf":"code","be9630aa":"code","6b4f02e2":"code","bb05402f":"code","d5b5f02f":"code","3d1b10be":"code","3210a940":"code","286bdb37":"code","ec9c3f56":"code","a545a05f":"code","0ca5e031":"code","296f4292":"code","ead25f0f":"code","14a43680":"code","3afa954b":"code","3b1ffbac":"code","237b7d8b":"code","d3b36be9":"code","39263d03":"code","db878a7e":"code","c0714c14":"code","9278907a":"code","892bb153":"code","b65aadd4":"code","118b0ad8":"code","acafb999":"code","cec5f37e":"code","ae6a1a5c":"code","e3c8bf4c":"code","2831e999":"code","e5497441":"code","a318fffa":"code","a95ab4bc":"code","6edf738c":"code","e6414c70":"code","b501a728":"code","0e5f029c":"code","6e4abed5":"code","7976c4cc":"code","2f7fc384":"code","ff529406":"code","07114661":"code","cbc8956c":"markdown","ffe1ea05":"markdown","c464c118":"markdown","c8b444d9":"markdown","f36fd7e5":"markdown","489270f0":"markdown","d025d4cd":"markdown","fc5be5de":"markdown","67573643":"markdown","86c0198a":"markdown","42dadebb":"markdown","1e187411":"markdown","f19bf38d":"markdown","f09afb1a":"markdown","86ba6eef":"markdown","f397ddae":"markdown","c7142dc2":"markdown","23ef4bb1":"markdown","a8edddb5":"markdown","a62c6fca":"markdown","a567c0e0":"markdown","fbb5ed0d":"markdown","5d45e848":"markdown","a8160b66":"markdown","fba17e1a":"markdown","e3c679df":"markdown","8840c1f3":"markdown","f924375a":"markdown","e6e154b8":"markdown","7f06df60":"markdown","42e1572d":"markdown","f08dc1ea":"markdown","5288e84e":"markdown","8f26d605":"markdown","6bef1c6c":"markdown","a32c2911":"markdown","be62d4b4":"markdown","9b45323e":"markdown","c32e8fc5":"markdown"},"source":{"e85cd479":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n%time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b368343c":"df = pd.read_csv(\"\/kaggle\/input\/bluebook-for-bulldozers\/Train.zip\")","50f93038":"pd.set_option('display.max_columns', None)\ndf.head(5)","2e513e66":"operations = []","05de6d0b":"will_drop = []\nmaybe_will_drop = []","a661d6a5":"will_drop.append(\"MachineID\")\nwill_drop.append(\"ModelID\")\nwill_drop.append(\"datasource\")","cb580577":"from pylab import rcParams\n\nrcParams['figure.figsize'] = 18, 8","54eeafd1":"df.isna().sum()","106f7b2f":"import matplotlib.pyplot as plt","e38dcc57":"df.YearMade.value_counts()","bd95cf01":"df = df[df.YearMade > 1000]","3bb999e5":"a = list(df.YearMade.unique())\nb = [df.SalePrice[df.YearMade == i].sum() \/ df.SalePrice[df.YearMade == i].count()  for i in a]\nplt.bar(a,b)","16659836":"def editYearMade(df):\n    return df[df.YearMade > 1000]\noperations.append(editYearMade)","972bb3ed":"df.MachineHoursCurrentMeter.isnull().sum()","6333d2bc":"len(list(df.MachineHoursCurrentMeter.unique()))","3a3dcf3c":"df.MachineHoursCurrentMeter = df.MachineHoursCurrentMeter.apply(lambda x : x \/\/ 10000)","6a740b9d":"a = list(df.MachineHoursCurrentMeter.unique())\nb = [df.SalePrice[df.MachineHoursCurrentMeter == i].sum() \/ df.SalePrice[df.MachineHoursCurrentMeter == i].count()  for i in a]\nplt.bar(a,b)","073b8367":"will_drop.append('MachineHoursCurrentMeter')","2d43e364":"df.UsageBand.isnull().sum()","dda4a6ac":"a = [\"Low\" , \"Medium\", \"High\"]\nb = []\nfor i in a:\n    b.append(df.SalePrice[df.UsageBand == i].sum() \/ df.SalePrice[df.UsageBand == i].count())\nplt.bar(a,b)","ed72f0ca":"df[df.UsageBand == \"Low\"].describe().YearMade","e3497962":"df[df.UsageBand == \"Medium\"].describe().YearMade","e3911e6d":"df[df.UsageBand == \"High\"].describe().YearMade","8fcc7a71":"df[df.UsageBand == \"Low\"].describe().MachineHoursCurrentMeter","e7fe2b5d":"df[df.UsageBand == \"Medium\"].describe().MachineHoursCurrentMeter","ce1b927c":"df[df.UsageBand == \"High\"].describe().MachineHoursCurrentMeter","0004993a":"df[df.UsageBand == \"Low\"].describe().SalePrice","078ef1e1":"df[df.UsageBand == \"Medium\"].describe().SalePrice","0a6897f4":"df[df.UsageBand == \"High\"].describe().SalePrice","cd39cf90":"df.UsageBand.isnull().sum()","ec6cb454":"def predictUsageBand(ref, low, medium, high):\n    x1 = abs(ref - low)\n    x2 = abs(ref - medium)\n    x3 = abs(ref - high)\n    min_ = min(x1, x2, x3)\n    if min_ == x1:\n        return \"Low\"\n    elif min_ == x2:\n        return \"Medium\"\n    else:\n        return \"High\"","92e360d3":"def predictUsage(hours, usageBand, price, yearMade):\n    if not pd.isna(usageBand):\n        return usageBand\n    if not pd.isna(hours):\n        return predictUsageBand(hours, 2, 5, 248)\n    if not pd.isna(price):\n        return predictUsageBand(price, 29000, 37000, 44000)\n    if not pd.isna(yearMade):\n        return predictUsageBand(yearMade, 1999, 2001, 2002)\n    return None\n    ","2332423a":"df.UsageBand = df.apply(lambda x : predictUsage(x['MachineHoursCurrentMeter'], \n                                                x['UsageBand'], x['SalePrice'], x['YearMade']), axis = 1)","5fbd02f8":"df.UsageBand.isnull().sum()","e9cfdb59":"a = [\"Low\" , \"Medium\", \"High\"]\nb = []\nfor i in a:\n    b.append(df.SalePrice[df.UsageBand == i].sum() \/ df.SalePrice[df.UsageBand == i].count())\nplt.bar(a,b)","d1aa8a34":"def editUsageBand(df):\n    df.UsageBand = df.apply(lambda x : predictUsage(x['MachineHoursCurrentMeter'], \n                                                x['UsageBand'], x['SalePrice'], x['YearMade']), axis = 1)\n    return df\noperations.append(editUsageBand)","c6b51dea":"df.auctioneerID.isnull().sum()","352db6fa":"df.auctioneerID.value_counts()","bb49bb58":"df.auctioneerID.fillna(1.0, inplace = True)","585e9f35":"def editAuctioneerID(df):\n    df.auctioneerID = df.auctioneerID.fillna(1.0)\n    return df\noperations.append(editAuctioneerID)","ff5c79df":"df.auctioneerID.isnull().sum()","b8a9f64a":"df.auctioneerID.unique()","81615b66":"a = list(df.auctioneerID.unique())\nb = []\nfor i in a:\n    b.append(df.SalePrice[df.auctioneerID == i].sum() \/ df.SalePrice[df.auctioneerID == i].count())\nplt.bar(a,b)","d27f15a9":"maybe_will_drop.append('auctioneerID')","ef5418df":"df.saledate.isnull().sum()","0acc24db":"df.saledate","6a926b01":"df.saledate = df.saledate.apply(lambda x : int(x.split(\"\/\")[-1][:4]) + (int(x.split(\"\/\")[0]) * (1\/12)))\ndf.saledate","38866817":"df[\"Age\"] = df.saledate - df.YearMade\ndf.Age","c607e5fd":"df.Age = df.Age.apply(lambda x : x \/\/ 0.25)","eea58662":"a = list(df.Age.unique())\nb = []\nfor i in a:\n    b.append(df.SalePrice[df.Age == i].sum() \/ df.SalePrice[df.Age == i].count())\nplt.bar(a,b)","d9f32d41":"def editAge(df):\n    df.saledate = df.saledate.apply(lambda x : int(x.split(\"\/\")[-1][:4]) + (int(x.split(\"\/\")[0]) * (1\/12)))\n    df[\"Age\"] = df.saledate - df.YearMade\n    df.Age = df.Age.apply(lambda x : x \/\/ 0.25)\n    return df\noperations.append(editAge)","3ff67ff0":"will_drop.append(\"saledate\")","60061958":"df.fiBaseModel.isnull().sum(), len(df.fiBaseModel.unique())","cb0119f2":"base_model = { base:dict() for base in list(df.fiBaseModel.unique()) }","dc74bd2b":"x = 0\nwhile x != 100000:\n    index = (x \/\/ 10000) + 1\n    for k,v in dict(df[(df.SalePrice >= x) & (df.SalePrice < (x + 10000))].fiBaseModel.value_counts()).items():\n        base_model[k][index] = v\n    x += 10000\n    \n# 100K and more\nfor k,v in dict(df[df.SalePrice >= 100000].fiBaseModel.value_counts()).items():\n        base_model[k][11] = v\n\nfor k,v in base_model.items():\n    try:\n        base_model[k] = sorted(base_model[k].items(), key = lambda x : x[1], reverse = True)[0][0]\n    except:\n        print(k,v)\n        break\n#base_model","ef10193c":"df.fiBaseModel = df.fiBaseModel.apply(lambda x : base_model[x])\ndf.fiBaseModel","c08ba639":"def editBaseModel(df):\n    df.fiBaseModel = df.fiBaseModel.apply(lambda x : base_model[x])\n    return df\noperations.append(df)","0bbd3646":"df.fiBaseModel.isnull().sum(), len(df.fiBaseModel.unique())","21b41416":"df.fiSecondaryDesc.isnull().sum(), len(df.fiSecondaryDesc.unique())","25557fdc":"df.fiModelDesc.isnull().sum() ,len(df.fiModelDesc.unique())","4413b72b":"df.fiModelDescriptor.isnull().sum(), len(df.fiModelDescriptor.unique())","67393f30":"maybe_will_drop.append('fiBaseModel')\nwill_drop.append('fiModelDesc')\nwill_drop.append(\"fiSecondaryDesc\")\nwill_drop.append(\"fiModelDescriptor\")\nwill_drop.append(\"fiModelSeries\")","362bb1af":"df.ProductSize.isnull().sum(), len(df.ProductSize.unique())","77027f06":"df.ProductSize.dropna().unique()","0cd6cc19":"a = list(df.ProductSize.dropna().unique())\nb = []\nfor i in a:\n    b.append(df.SalePrice[df.ProductSize == i].sum() \/ df.SalePrice[df.ProductSize == i].count())\nplt.bar(a,b)","cd326943":"len(df.fiProductClassDesc.dropna().unique())","fa2a7f3b":"a = [\"Medium\", \"Small\", \"Large \/ Medium\", \"Mini\", \"Compact\", \"Large\"]\nb = []\nfor i in a:\n    b.append( df[df.ProductSize == i].SalePrice.describe().mean() )\nplt.bar(a,b)","f7e316b6":"a = [\"Medium\", \"Small\", \"Large \/ Medium\", \"Mini\", \"Compact\", \"Large\"]\nproduct_size_dict = {}\nfor i in a:\n    f = df[df.ProductSize == i].fiProductClassDesc.value_counts()\n    for index,count in zip(list(f.index), f):\n        if index not in product_size_dict:\n            product_size_dict[index] = {}\n        if i not in product_size_dict[index]:\n            product_size_dict[index][i] = 0\n        product_size_dict[index][i] += count\nfor k,v in product_size_dict.items():\n    dict_ = sorted(product_size_dict[k].items(), key = lambda x : x[1], reverse = True)\n    product_size_dict[k] = dict_[0][0]\nproduct_size_dict","3aa2bd53":"a = [\"Medium\", \"Small\", \"Large \/ Medium\", \"Mini\", \"Compact\", \"Large\"]\nproduct_size_dict_2 = {}\nfor i in a:\n    f = df[df.ProductSize == i].fiBaseModel.value_counts()\n    for index,count in zip(list(f.index), f):\n        if index not in product_size_dict_2:\n            product_size_dict_2[index] = {}\n        if i not in product_size_dict_2[index]:\n            product_size_dict_2[index][i] = 0\n        product_size_dict_2[index][i] += count\nfor k,v in product_size_dict_2.items():\n    dict_ = sorted(product_size_dict_2[k].items(), key = lambda x : x[1], reverse = True)\n    product_size_dict_2[k] = dict_[0][0]\nproduct_size_dict_2","419b58e9":"def fillProductSize(productSize,sale_price, base_model, product_class_desc):\n    if not pd.isna(productSize):\n        return productSize\n    if not pd.isna(base_model):\n        if base_model in product_size_dict_2:\n            return product_size_dict_2[base_model]\n    if not pd.isna(product_class_desc):\n        if product_class_desc in product_size_dict:\n            return product_size_dict[product_class_desc]\n    if not pd.isna(sale_price):\n        if sale_price > 25000:\n            return \"Large\"\n        return \"Mini\"\n    return None","3fd3c01e":"df.ProductSize = df.apply(lambda x : fillProductSize( x['ProductSize'],\n                            x['SalePrice'], x['fiBaseModel'], x['fiProductClassDesc'] ), axis = 1)","41406005":"def editProductSize(df):\n    df.ProductSize = df.apply(lambda x : fillProductSize( x['ProductSize'],\n                            x['SalePrice'], x['fiBaseModel'], x['fiProductClassDesc'] ), axis = 1)\n    return df\noperations.append(editProductSize)","60c3edb2":"df.ProductSize.isnull().sum()","fcbffd60":"df.fiProductClassDesc.isnull().sum()\n","422265a0":"len(list(df.fiProductClassDesc.unique()))","b79d979a":"df.groupby([\"state\"]).describe().SalePrice","97e80754":"maybe_will_drop.append(\"state\")","7a7d03d1":"df.ProductGroup.isnull().sum(), len(list(df.ProductGroup.unique()))","c471e10e":"a = list(df.ProductGroup.unique())\nb = []\nfor i in a:\n    b.append( df[df.ProductGroup == i].SalePrice.mean()  )\nplt.bar(a,b)","e4026972":"df.ProductGroupDesc.isnull().sum(), len(list(df.ProductGroupDesc.unique()))","227bcf48":"a = list(df.ProductGroupDesc.unique())\nb = []\nfor i in a:\n    b.append( df[df.ProductGroupDesc == i].SalePrice.mean()  )\nplt.bar(a,b)","f78040b9":"will_drop.append(\"ProductGroupDesc\")","52f71722":"df.Drive_System.isnull().sum(), len(list(df.Drive_System.unique()))","fcf62aca":"a = list(df.Drive_System.dropna().unique())\nb = []\nfor i in a:\n    b.append( df[df.Drive_System == i].SalePrice.mean()  )\nplt.bar(a,b)","b634a84a":"will_drop.append(\"Drive_System\")","c13c5395":"def printNullAndUnique(a):\n    print(a.isnull().sum(), len(list(a.unique())))","155d64a3":"def graphSalePrice(x):\n    a = list(x.dropna().unique())\n    b = []\n    for i in a:\n        b.append( df[x == i].SalePrice.mean()  )\n    plt.bar(a,b)","b5f05c52":"printNullAndUnique(df.Enclosure)","a2c50054":"graphSalePrice(df.Enclosure)","d07126a0":"df.Enclosure.describe()","6457cee1":"df.Enclosure.fillna(\"OROPS\", inplace = True)","a93c7423":"def editEnclosure(df):\n    df.Enclosure.fillna(\"OROPS\", inplace = True)\n    return df\noperations.append(editEnclosure)","cb273fb1":"df.Enclosure.isnull().sum()","8aac22f9":"printNullAndUnique(df.Forks)","0718f6f0":"graphSalePrice(df.Forks)","e61eafec":"a = [\"Yes\", \"None or Unspecified\"]\nforks_dict = {}\nfor i in a:\n    f = df[df.Forks == i].fiBaseModel.value_counts()\n    for index,count in zip(list(f.index), f):\n        if index not in forks_dict:\n            forks_dict[index] = {}\n        if i not in forks_dict[index]:\n            forks_dict[index][i] = 0\n        forks_dict[index][i] += count\nfor k,v in forks_dict.items():\n    dict_ = sorted(forks_dict[k].items(), key = lambda x : x[1], reverse = True)\n    forks_dict[k] = dict_[0][0]\nforks_dict","ebb5a29a":"def checkForks(forks, base_model):\n    if not pd.isna(forks):\n        return forks\n    if base_model in forks_dict:\n        return forks_dict[base_model]\n    return \"None or Unspecified\"\ndf.Forks = df.apply(lambda x : checkForks(x[\"Forks\"], x[\"fiBaseModel\"]), axis = 1)","d1e658a6":"def editForks(df):\n    df.Forks = df.apply(lambda x : checkForks(x[\"Forks\"], x[\"fiBaseModel\"]), axis = 1)\n    return df\noperations.append(editForks)","302d3ef5":"printNullAndUnique(df.Forks)","44b45dbf":"graphSalePrice(df.Forks)","be9630aa":"printNullAndUnique(df.Pad_Type)","6b4f02e2":"graphSalePrice(df.Pad_Type)","bb05402f":"will_drop.append(\"Pad_Type\")","d5b5f02f":"printNullAndUnique(df.Ride_Control)","3d1b10be":"graphSalePrice(df.Ride_Control)","3210a940":"df.Ride_Control.fillna(\"None or Unspecified\",inplace= True)\ngraphSalePrice(df.Ride_Control)","286bdb37":"def editRideControl(df):\n    df.Ride_Control.fillna(\"None or Unspecified\",inplace= True)\n    return df\noperations.append(editRideControl)","ec9c3f56":"printNullAndUnique(df.Stick)","a545a05f":"graphSalePrice(df.Stick)","0ca5e031":"will_drop.append(\"Stick\")","296f4292":"printNullAndUnique(df.Transmission)","ead25f0f":"graphSalePrice(df.Transmission)","14a43680":"df.Transmission = df.Transmission.apply(lambda x : 1 if x == \"AutoShift\" else 0)","3afa954b":"def editTransmission(df):\n    df.Transmission = df.Transmission.apply(lambda x : 1 if x == \"AutoShift\" else 0)\n    return df\noperations.append(editTransmission)","3b1ffbac":"df2 = df.iloc[: , :27]\ndf2[\"Age\"] = df[\"Age\"]","237b7d8b":"will_drop.append(\"SalesID\")","d3b36be9":"df2.drop(columns = will_drop, inplace= True)\ndf2","39263d03":"def editDF(df):\n    df2 = df.iloc[: , :27]\n    df2.drop(columns = will_drop, inplace= True)\n    df2[\"Age\"] = df[\"Age\"]\n    return df2\noperations.append(df)","db878a7e":"df2.isnull().sum()","c0714c14":"categoricals = [\"YearMade\", \"UsageBand\", \"fiBaseModel\", \"ProductSize\", \"fiProductClassDesc\", \"state\", \"ProductGroup\",\n               \"Forks\", \"Ride_Control\", \"Enclosure\"]\nfor c in categoricals:\n    df2[c] = df2[c].astype(\"category\").cat.codes\ndf2","9278907a":"df2 = df2.reset_index().drop(columns=\"index\")\ndf2","892bb153":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder(handle_unknown='ignore')\n\n\nfor c in categoricals:\n    enc_df = pd.DataFrame(enc.fit_transform(df2[[c]]).toarray())\n    df2 = df2.drop(columns = c).join(enc_df, lsuffix = c[0])\ndf2","b65aadd4":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(df2.drop(columns = \"SalePrice\"), df2.SalePrice,train_size = 0.8)","118b0ad8":"X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, train_size = 0.5)","acafb999":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nclf = RandomForestRegressor()","cec5f37e":"nums = [1000, 3000, 5000, 10000, 20000]\nstds = []\naccs = []\nfor i in nums:\n    acc = []\n    for k in range(5):\n        per = np.random.permutation(X_train.shape[0])[:i]\n        clf = RandomForestRegressor()\n        clf.fit(X_train.iloc[per], y_train.iloc[per])\n        acc.append(r2_score( y_val, clf.predict(X_val) ))\n    stds.append(np.std(acc))\n    accs.append(np.mean(acc))\nstds, accs","ae6a1a5c":"plt.bar(nums, stds, width = 1000)\nplt.title(\"Standard Deviation of Subsamples\")","e3c8bf4c":"plt.bar(nums, accs, width = 1000)\nplt.ylim(0.7, 1)\nplt.title(\"Accuracy of Subsamples\")","2831e999":"per = np.random.permutation(X_train.shape[0])[:10000]\ntest_x = X_train.iloc[per]\ntest_y = y_train.iloc[per]\nnums = [1, 3, 10, 15, 30, 50, 75, 100]\nacc_val = []\nacc_test = []\nfor i in nums:\n    clf = RandomForestRegressor(n_estimators=i)\n    clf.fit(test_x, test_y)\n    acc_val.append(r2_score( y_val, clf.predict(X_val) ))\n    acc_test.append( r2_score( y_test, clf.predict(X_test) ) )","e5497441":"plt.plot(nums, acc_val)\nplt.plot(nums, acc_test)","a318fffa":"%%time\nclf = RandomForestRegressor(n_estimators=30)\nclf.fit(X_train, y_train)","a95ab4bc":"print(\"R2 Validation : \", r2_score(y_val, clf.predict(X_val) ))\nprint(\"R2 Test : \", r2_score(y_test, clf.predict(X_test) ))","6edf738c":"from sklearn.linear_model import LinearRegression\nclf = LinearRegression()","e6414c70":"clf.fit(X_train, y_train)","b501a728":"def get_r2_score(clf):\n    print(\"R2 Validation : \", r2_score(y_val, clf.predict(X_val) ))\n    print(\"R2 Test : \", r2_score(y_test, clf.predict(X_test) ))\nget_r2_score(clf)","0e5f029c":"from tensorflow import keras","6e4abed5":"model = keras.Sequential()\nmodel.add(keras.layers.Dense(256, input_dim = X_train.shape[1], activation = \"relu\"))\nmodel.add(keras.layers.Dense(256, activation = \"relu\"))\nmodel.add(keras.layers.Dense(256, activation = \"relu\"))\nmodel.add(keras.layers.Dense(1 ,activation = \"linear\"))\nmodel.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['mean_squared_logarithmic_error'])\nmodel.summary()","7976c4cc":"learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(\n    monitor = \"val_mean_squared_logarithmic_error\",\n    factor = 0.5,\n    patience = 3,\n    verbose = 1,\n)","2f7fc384":"model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size = 32,\n         callbacks = [learning_rate_reduction])","ff529406":"get_r2_score(model)","07114661":"from sklearn.metrics import mean_squared_log_error\nfrom math import sqrt\ndef rmsle(clf):\n    print(\"R2 Validation : \", sqrt(mean_squared_log_error(y_val, clf.predict(X_val)) ))\n    print(\"R2 Test : \", sqrt(mean_squared_log_error(y_test, clf.predict(X_test)) ))\nrmsle(model)","cbc8956c":"### MachineHoursCurrentMeter","ffe1ea05":"### Enclosure","c464c118":"# Prepare to Train","c8b444d9":"We can choose 10000 as subsample size","f36fd7e5":"### Pad_Type","489270f0":"### UsageBand","d025d4cd":"### Neural Network","fc5be5de":"! We Can extract new feature from saledate and yearMade","67573643":"### fiProductClassDesc","86c0198a":"### ProductGroupDesc","42dadebb":"### ProductGroup","1e187411":"! We have a lot of null valus on this feature but we will try to fill nulls. This feature looks like good to model.","f19bf38d":"# Feature Selection","f09afb1a":"### Choose Subsample Size","86ba6eef":"### Product Size","f397ddae":"As we can see product size is helpful for model. We try to fill null variables","c7142dc2":"We will fill null variables","23ef4bb1":"### state","a8edddb5":"### Linear Regression","a62c6fca":"Maybe We must drop this feature","a567c0e0":"### Forks","fbb5ed0d":"### Drive_System","5d45e848":"### Choose Parameters for RF","a8160b66":"### auctioneerID","fba17e1a":"### Transmission","e3c679df":"### fiBaseModel","8840c1f3":"### saledate","f924375a":"### Stick","e6e154b8":"! We will drop datas that have year value of 1000.","7f06df60":"First we must choose a subsumple number that resemble our data. Because we have a lot of data we lose time while parameter tuning.","42e1572d":"Product Group and Product Group Desc Same features we will drop that one","f08dc1ea":"# Train and Hyperparameter Tuning","5288e84e":"### Ride_Control","8f26d605":"I think this feature lack of information because of that we will drop this feature","6bef1c6c":"We will group baseModels by SalePrice feature because we have 1783 group and this number will slow our train algorithm","a32c2911":"YearMade, UsageBand, fiModelDesc, fiBaseModel, ProductSize,\n\nfiProductClassDesc, state, ProductGroup, Enclosure, Forks,\n\nRide_Control are categorical features. We have to convert with label encoding","be62d4b4":"### Year Made","9b45323e":"We can choose n_estimator 30, Okay let's look our r2-score on whole dataset.","c32e8fc5":"Forks looks helpful for model we can try to fill null variables"}}