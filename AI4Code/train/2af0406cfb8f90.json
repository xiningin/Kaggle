{"cell_type":{"a5c45235":"code","60c5b8c4":"code","d6f4b3cd":"code","dcb0eac1":"code","e0f9c3ff":"code","b0465a0a":"code","418923c4":"code","8ba60e87":"code","690f8468":"code","33534a1f":"code","ac1b72fa":"code","b88923aa":"code","3bad32cd":"code","d9641494":"code","36271879":"code","c12ec93e":"code","75192820":"code","f2f887c0":"code","c0fd454c":"code","0272c2c1":"code","05a41a94":"code","f44ac77c":"markdown","16297985":"markdown"},"source":{"a5c45235":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","60c5b8c4":"pip install livelossplot","d6f4b3cd":"import numpy as np \nimport tensorflow as tf\n%matplotlib inline\nfrom matplotlib import pyplot as plt # to view digits images from array object\nfrom keras import  backend as K\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nimport tensorflow_addons as tfa\nfrom keras.models import  Sequential\nfrom keras.layers.core import  Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom livelossplot import PlotLossesKerasTF\nfrom keras.layers import BatchNormalization, Conv2D , MaxPooling2D ,Activation\nfrom keras.optimizers import Adam ,RMSprop","dcb0eac1":"train_set = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_set = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\nimg_col = 28\nimg_row = 28","e0f9c3ff":"train_set.head()","b0465a0a":"test_set.head()","418923c4":"X_train_df = train_set.drop(['label'],axis = 1)\ny_train_df = train_set['label']\nX_test_df = test_set\n\nX_tr = np.asarray(X_train_df)\/255\ny_tr = np.asarray(y_train_df)\nX_te = np.asarray(X_test_df)\/255\nprint(type(X_tr))\nprint(X_tr.shape)\nprint(X_te.shape)","8ba60e87":"train_set['label'].value_counts().sort_index()","690f8468":"X_trainplot = X_tr.reshape(42000 , img_col , img_row)\nX_testplot = X_te.reshape(28000, img_col,img_row)\nprint(X_trainplot.shape)\nprint(X_testplot.shape)","33534a1f":"rand_img = np.random.randint(42000,size = 3)\nfig = plt.figure()\n\nfor i,idx in enumerate(rand_img,1):\n    arr1 = X_trainplot[idx]\n    ax1 = fig.add_subplot(2,3,i)\n    ax1.imshow(arr1 )\n    ax1.set_title(y_tr[idx])\n    \nrand_img = np.random.randint(28000,size = 3)\nfor i,idx in enumerate(rand_img,4):\n    arr1 = X_testplot[idx]\n    ax1 = fig.add_subplot(2,3,i)\n    ax1.imshow(arr1 )\n","ac1b72fa":"X_train_f = X_tr.reshape(42000,img_col,img_row,1)\nX_test_f= X_te.reshape(28000,img_col,img_row,1)\ny_train_f = to_categorical(y_tr)\ny_train_f.shape[1]","b88923aa":"model = Sequential()\n\nmodel.add(Conv2D(64,(2,2),padding = 'same', input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128,(2,2),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128,(2,2),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# model.add(Dropout(0.1))\n\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# model.add(Dropout(0.15))\n\nmodel.add(Dense(128))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# model.add(Dropout(0.1))\n\nmodel.add(Dense(64))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n# model.add(Dropout(0.15))\n\nmodel.add(Dense(10 , activation = 'softmax'))","3bad32cd":"opt = Adam(learning_rate=0.00005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","d9641494":"epochs = 200\nbatch_size = 64\n\nX_train, X_val, y_train, y_val = train_test_split(X_train_f, y_train_f, test_size=0.3 , random_state = 5)\nimage_gen = ImageDataGenerator(rotation_range = 25 ,shear_range = 0.25,zoom_range = [1.25,0.75],width_shift_range= 0.1,height_shift_range=0.1)\nimage_gen2 = ImageDataGenerator()\ntrain_batches = image_gen.flow(X_train,y_train,batch_size = batch_size)\nval_batches =image_gen2.flow(X_val,y_val,batch_size = batch_size)","36271879":"# x_p, y_p = next(train_batches)\n# x_p = x_p.reshape(64,28,28)","c12ec93e":"# for i in range (0,32):\n#     print(x_p.shape)\n#     plt.imshow(x_p[i])\n#     plt.show()","75192820":"steps_per_epoch = train_batches.n\/\/train_batches.batch_size\nvalidation_steps = val_batches.n\/\/val_batches.batch_size\ncheckpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75,patience=3, min_lr=0.00001, mode='auto',verbose=1)\ncallbacks = [PlotLossesKerasTF(), reduce_lr, checkpoint]","f2f887c0":"history=model.fit_generator(generator=train_batches, steps_per_epoch = steps_per_epoch, epochs=epochs, \n                    validation_data=val_batches, validation_steps=validation_steps , callbacks=callbacks)","c0fd454c":"predictions = model.predict_classes(X_test_f, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"mysub5.csv\", index=False, header=True)","0272c2c1":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport seaborn as sns\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\ny_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","05a41a94":"# Display some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (y_pred_classes - y_true != 0)\nprint(sum(errors))\ny_pred_classes_errors = y_pred_classes[errors]\ny_pred_errors = y_pred[errors]\ny_true_errors = y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\ny_pred_errors_prob = np.max(y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[:6]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, y_pred_classes_errors, y_true_errors)","f44ac77c":"### Display Errors","16297985":"### Identify MissPredicted Values\nConfusion Matrix \n\nReference from Introduction to CNN Keras (Notebook) by Yassine Ghouzam"}}